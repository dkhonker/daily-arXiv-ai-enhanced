{"id": "2507.11595", "pdf": "https://arxiv.org/pdf/2507.11595", "abs": "https://arxiv.org/abs/2507.11595", "authors": ["Hengyue Zhao"], "title": "A Study on the Application of Artificial Intelligence in Ecological Design", "categories": ["cs.AI", "cs.CY", "I.4.8; I.2.6"], "comment": null, "summary": "This paper asks whether our relationship with nature can move from human\ndominance to genuine interdependence, and whether artificial intelligence (AI)\ncan mediate that shift. We examine a new ecological-design paradigm in which AI\ninteracts with non-human life forms. Through case studies we show how artists\nand designers apply AI for data analysis, image recognition, and ecological\nrestoration, producing results that differ from conventional media. We argue\nthat AI not only expands creative methods but also reframes the theory and\npractice of ecological design. Building on the author's prototype for\nAI-assisted water remediation, the study proposes design pathways that couple\nreinforcement learning with plant-based phytoremediation. The findings\nhighlight AI's potential to link scientific insight, artistic practice, and\nenvironmental stewardship, offering a roadmap for future research on\nsustainable, technology-enabled ecosystems."}
{"id": "2507.11633", "pdf": "https://arxiv.org/pdf/2507.11633", "abs": "https://arxiv.org/abs/2507.11633", "authors": ["Yuxuan Zhang", "Haoyang Yu", "Lanxiang Hu", "Haojian Jin", "Hao Zhang"], "title": "General Modular Harness for LLM Agents in Multi-Turn Gaming Environments", "categories": ["cs.AI"], "comment": "8 pages, ICML MAS workshop", "summary": "We introduce a modular harness design for LLM agents that composes of\nperception, memory, and reasoning components, enabling a single LLM or VLM\nbackbone to tackle a wide spectrum of multi turn gaming environments without\ndomain-specific engineering. Using classic and modern game suites as\nlow-barrier, high-diversity testbeds, our framework provides a unified workflow\nfor analyzing how each module affects performance across dynamic interactive\nsettings. Extensive experiments demonstrate that the harness lifts gameplay\nperformance consistently over un-harnessed baselines and reveals distinct\ncontribution patterns, for example, memory dominates in long-horizon puzzles\nwhile perception is critical in vision noisy arcades. These findings highlight\nthe effectiveness of our modular harness design in advancing general-purpose\nagent, given the familiarity and ubiquity of games in everyday human\nexperience."}
{"id": "2507.11662", "pdf": "https://arxiv.org/pdf/2507.11662", "abs": "https://arxiv.org/abs/2507.11662", "authors": ["Moises Andrade", "Joonhyuk Cha", "Brandon Ho", "Vriksha Srihari", "Karmesh Yadav", "Zsolt Kira"], "title": "Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "cs.RO"], "comment": "Our code and data are publicly available at\n  https://github.com/mshalimay/mllm-verifiers-abias-sgv", "summary": "Verifiers -- functions assigning rewards to agent behavior -- have been key\nfor AI progress in domains like math and board games. However, extending these\ngains to domains without clear-cut success criteria (e.g.,computer use) remains\na challenge: while humans can recognize suitable outcomes, translating this\nintuition into scalable rules is non-trivial. Multimodal Large Language\nModels(MLLMs) emerge as a promising solution, given their world knowledge,\nhuman-preference alignment, and reasoning skills. We evaluate MLLMs as\nverifiers of agent trajectories across web navigation, computer use, and\nrobotic manipulation, and identify a critical limitation: agreement bias, a\nstrong tendency for MLLMs to favor information in their context window, often\ngenerating chains of thought to rationalize flawed behavior. This bias is\npervasive across models, resilient to test-time scaling, and can impact several\nmethods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs\ndespite MLLMs showing strong, human-aligned priors on desired behavior. To\naddress this, we propose Self-Grounded Verification (SGV), a lightweight method\nthat enables more effective use of MLLMs' knowledge and reasoning by harnessing\ntheir own sampling mechanisms via unconditional and conditional generation. SGV\noperates in two steps: first, the MLLM is elicited to retrieve broad priors\nabout task completion, independent of the data under evaluation. Then,\nconditioned on self-generated priors, it reasons over and evaluates a candidate\ntrajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in\naccuracy and failure detection rates, and can perform real-time supervision of\nheterogeneous agents, boosting task completion of a GUI specialist in OSWorld,\na diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting\na new state of the art on the benchmark, surpassing the previous best by 48%."}
{"id": "2507.11733", "pdf": "https://arxiv.org/pdf/2507.11733", "abs": "https://arxiv.org/abs/2507.11733", "authors": ["Srikanth Vemula"], "title": "ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making", "categories": ["cs.AI"], "comment": null, "summary": "This Study introduces Clarity and Reasoning Interface for Artificial\nIntelligence(ClarifAI), a novel approach designed to augment the transparency\nand interpretability of artificial intelligence (AI) in the realm of improved\ndecision making. Leveraging the Case-Based Reasoning (CBR) methodology and\nintegrating an ontology-driven approach, ClarifAI aims to meet the intricate\nexplanatory demands of various stakeholders involved in AI-powered\napplications. The paper elaborates on ClarifAI's theoretical foundations,\ncombining CBR and ontologies to furnish exhaustive explanation mechanisms. It\nfurther elaborates on the design principles and architectural blueprint,\nhighlighting ClarifAI's potential to enhance AI interpretability across\ndifferent sectors and its applicability in high-stake environments. This\nresearch delineates the significant role of ClariAI in advancing the\ninterpretability of AI systems, paving the way for its deployment in critical\ndecision-making processes."}
{"id": "2507.11547", "pdf": "https://arxiv.org/pdf/2507.11547", "abs": "https://arxiv.org/abs/2507.11547", "authors": ["Yingxue Zhao", "Qianyi Chen", "Haoran Li", "Haosu Zhou", "Hamid Reza Attar", "Tobias Pfaff", "Tailin Wu", "Nan Li"], "title": "Recurrent U-Net-Based Graph Neural Network (RUGNN) for Accurate Deformation Predictions in Sheet Material Forming", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, various artificial intelligence-based surrogate models have\nbeen proposed to provide rapid manufacturability predictions of material\nforming processes. However, traditional AI-based surrogate models, typically\nbuilt with scalar or image-based neural networks, are limited in their ability\nto capture complex 3D spatial relationships and to operate in a\npermutation-invariant manner. To overcome these issues, emerging graph-based\nsurrogate models are developed using graph neural networks. This study\ndeveloped a new graph neural network surrogate model named Recurrent U\nNet-based Graph Neural Network (RUGNN). The RUGNN model can achieve accurate\npredictions of sheet material deformation fields across multiple forming\ntimesteps. The RUGNN model incorporates Gated Recurrent Units (GRUs) to model\ntemporal dynamics and a U-Net inspired graph-based downsample/upsample\nmechanism to handle spatial long-range dependencies. A novel 'node-to-surface'\ncontact representation method was proposed, offering significant improvements\nin computational efficiency for large-scale contact interactions. The RUGNN\nmodel was validated using a cold forming case study and a more complex hot\nforming case study using aluminium alloys. Results demonstrate that the RUGNN\nmodel provides accurate deformation predictions closely matching ground truth\nFE simulations and outperforming several baseline GNN architectures. Model\ntuning was also performed to identify suitable hyperparameters, training\nstrategies, and input feature representations. These results demonstrate that\nRUGNN is a reliable approach to support sheet material forming design by\nenabling accurate manufacturability predictions."}
{"id": "2507.11630", "pdf": "https://arxiv.org/pdf/2507.11630", "abs": "https://arxiv.org/abs/2507.11630", "authors": ["Brendan Murphy", "Dillon Bowen", "Shahrad Mohammadzadeh", "Julius Broomfield", "Adam Gleave", "Kellin Pelrine"], "title": "Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "AI systems are rapidly advancing in capability, and frontier model developers\nbroadly acknowledge the need for safeguards against serious misuse. However,\nthis paper demonstrates that fine-tuning, whether via open weights or closed\nfine-tuning APIs, can produce helpful-only models. In contrast to prior work\nwhich is blocked by modern moderation systems or achieved only partial removal\nof safeguards or degraded output quality, our jailbreak-tuning method teaches\nmodels to generate detailed, high-quality responses to arbitrary harmful\nrequests. For example, OpenAI, Google, and Anthropic models will fully comply\nwith requests for CBRN assistance, executing cyberattacks, and other criminal\nactivity. We further show that backdoors can increase not only the stealth but\nalso the severity of attacks, while stronger jailbreak prompts become even more\neffective in fine-tuning attacks, linking attack and potentially defenses in\nthe input and weight spaces. Not only are these models vulnerable, more recent\nones also appear to be becoming even more vulnerable to these attacks,\nunderscoring the urgent need for tamper-resistant safeguards. Until such\nsafeguards are discovered, companies and policymakers should view the release\nof any fine-tunable model as simultaneously releasing its evil twin: equally\ncapable as the original model, and usable for any malicious purpose within its\ncapabilities."}
{"id": "2507.11737", "pdf": "https://arxiv.org/pdf/2507.11737", "abs": "https://arxiv.org/abs/2507.11737", "authors": ["Chenyu Zhou", "Jingyuan Yang", "Linwei Xin", "Yitian Chen", "Ziyan He", "Dongdong Ge"], "title": "Auto-Formulating Dynamic Programming Problems with Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Dynamic programming (DP) is a fundamental method in operations research, but\nformulating DP models has traditionally required expert knowledge of both the\nproblem context and DP techniques. Large Language Models (LLMs) offer the\npotential to automate this process. However, DP problems pose unique challenges\ndue to their inherently stochastic transitions and the limited availability of\ntraining data. These factors make it difficult to directly apply existing\nLLM-based models or frameworks developed for other optimization problems, such\nas linear or integer programming. We introduce DP-Bench, the first benchmark\ncovering a wide range of textbook-level DP problems to enable systematic\nevaluation. We present Dynamic Programming Language Model (DPLM), a\n7B-parameter specialized model that achieves performance comparable to\nstate-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on\nhard problems. Central to DPLM's effectiveness is DualReflect, our novel\nsynthetic data generation pipeline, designed to scale up training data from a\nlimited set of initial examples. DualReflect combines forward generation for\ndiversity and backward generation for reliability. Our results reveal a key\ninsight: backward generation is favored in low-data regimes for its strong\ncorrectness guarantees, while forward generation, though lacking such\nguarantees, becomes increasingly valuable at scale for introducing diverse\nformulations. This trade-off highlights the complementary strengths of both\napproaches and the importance of combining them."}
{"id": "2507.11570", "pdf": "https://arxiv.org/pdf/2507.11570", "abs": "https://arxiv.org/abs/2507.11570", "authors": ["Ha Na Cho", "Sairam Sutari", "Alexander Lopez", "Hansen Bow", "Kai Zheng"], "title": "SurgeryLSTM: A Time-Aware Neural Model for Accurate and Explainable Length of Stay Prediction After Spine Surgery", "categories": ["cs.LG", "cs.AI", "eess.IV"], "comment": null, "summary": "Objective: To develop and evaluate machine learning (ML) models for\npredicting length of stay (LOS) in elective spine surgery, with a focus on the\nbenefits of temporal modeling and model interpretability. Materials and\nMethods: We compared traditional ML models (e.g., linear regression, random\nforest, support vector machine (SVM), and XGBoost) with our developed model,\nSurgeryLSTM, a masked bidirectional long short-term memory (BiLSTM) with an\nattention, using structured perioperative electronic health records (EHR) data.\nPerformance was evaluated using the coefficient of determination (R2), and key\npredictors were identified using explainable AI. Results: SurgeryLSTM achieved\nthe highest predictive accuracy (R2=0.86), outperforming XGBoost (R2 = 0.85)\nand baseline models. The attention mechanism improved interpretability by\ndynamically identifying influential temporal segments within preoperative\nclinical sequences, allowing clinicians to trace which events or features most\ncontributed to each LOS prediction. Key predictors of LOS included bone\ndisorder, chronic kidney disease, and lumbar fusion identified as the most\nimpactful predictors of LOS. Discussion: Temporal modeling with attention\nmechanisms significantly improves LOS prediction by capturing the sequential\nnature of patient data. Unlike static models, SurgeryLSTM provides both higher\naccuracy and greater interpretability, which are critical for clinical\nadoption. These results highlight the potential of integrating attention-based\ntemporal models into hospital planning workflows. Conclusion: SurgeryLSTM\npresents an effective and interpretable AI solution for LOS prediction in\nelective spine surgery. Our findings support the integration of temporal,\nexplainable ML approaches into clinical decision support systems to enhance\ndischarge readiness and individualized patient care."}
{"id": "2507.11721", "pdf": "https://arxiv.org/pdf/2507.11721", "abs": "https://arxiv.org/abs/2507.11721", "authors": ["Endong Liu", "Mark Ryan", "Liyi Zhou", "Pascal Berrang"], "title": "Evasion Under Blockchain Sanctions", "categories": ["cs.CR", "C.2.4"], "comment": null, "summary": "Sanctioning blockchain addresses has become a common regulatory response to\nmalicious activities. However, enforcement on permissionless blockchains\nremains challenging due to complex transaction flows and sophisticated\nfund-obfuscation techniques. Using cryptocurrency mixing tool Tornado Cash as a\ncase study, we quantitatively assess the effectiveness of U.S. Office of\nForeign Assets Control (OFAC) sanctions over a 957-day period, covering 6.79\nmillion Ethereum blocks and 1.07 billion transactions. Our analysis reveals\nthat while OFAC sanctions reduced overall Tornado Cash deposit volume by 71.03%\nto approximately 2 billion USD, attackers still relied on Tornado Cash in\n78.33% of Ethereum-related security incidents, underscoring persistent evasion\nstrategies.\n  We identify three structural limitations in current sanction enforcement\npractices: (i) the susceptibility of binary sanction classifications to dusting\nattacks; (ii) fragmented censorship by blockchain producers; and (iii) the\ncomplexity of obfuscation services exploited by users. To address these gaps,\nwe introduce a more practical algorithm for scoring and tracking, grounded in\nquantitative impurity. On average, our algorithm processes Ethereum blocks\nwithin 0.07 $\\pm$ 0.03 seconds and achieves 97.61% precision and 74.08% recall\nwhen evaluated on the Bybit exploit. Our findings contribute to ongoing\ndiscussions around regulatory effectiveness in Decentralized Finance by\nproviding empirical evidence, clarifying enforcement challenges, and informing\nfuture compliance strategies in response to sanctions and blockchain-based\nsecurity risks."}
{"id": "2507.11787", "pdf": "https://arxiv.org/pdf/2507.11787", "abs": "https://arxiv.org/abs/2507.11787", "authors": ["Chandrashekar Muniyappa", "Eunjin Kim"], "title": "Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity", "categories": ["cs.AI", "68-68W50"], "comment": "CSAIDE '25: Proceedings of the 2025 4th International Conference on\n  Cyber Security, Artificial Intelligence and the Digital Economy", "summary": "Swarm Intelligence (SI) is gaining a lot of popularity in artificial\nintelligence, where the natural behavior of animals and insects is observed and\ntranslated into computer algorithms called swarm computing to solve real-world\nproblems. Due to their effectiveness, they are applied in solving various\ncomputer optimization problems. This survey will review all the latest\ndevelopments in Searching for documents based on semantic similarity using\nSwarm Intelligence algorithms and recommend future research directions."}
{"id": "2507.11574", "pdf": "https://arxiv.org/pdf/2507.11574", "abs": "https://arxiv.org/abs/2507.11574", "authors": ["Kazuma Kobayashi", "Shailesh Garg", "Farid Ahmed", "Souvik Chakraborty", "Syed Bahauddin Alam"], "title": "Distribution-Free Uncertainty-Aware Virtual Sensing via Conformalized Neural Operators", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Robust uncertainty quantification (UQ) remains a critical barrier to the safe\ndeployment of deep learning in real-time virtual sensing, particularly in\nhigh-stakes domains where sparse, noisy, or non-collocated sensor data are the\nnorm. We introduce the Conformalized Monte Carlo Operator (CMCO), a framework\nthat transforms neural operator-based virtual sensing with calibrated,\ndistribution-free prediction intervals. By unifying Monte Carlo dropout with\nsplit conformal prediction in a single DeepONet architecture, CMCO achieves\nspatially resolved uncertainty estimates without retraining, ensembling, or\ncustom loss design. Our method addresses a longstanding challenge: how to endow\noperator learning with efficient and reliable UQ across heterogeneous domains.\nThrough rigorous evaluation on three distinct applications: turbulent flow,\nelastoplastic deformation, and global cosmic radiation dose estimation-CMCO\nconsistently attains near-nominal empirical coverage, even in settings with\nstrong spatial gradients and proxy-based sensing. This breakthrough offers a\ngeneral-purpose, plug-and-play UQ solution for neural operators, unlocking\nreal-time, trustworthy inference in digital twins, sensor fusion, and\nsafety-critical monitoring. By bridging theory and deployment with minimal\ncomputational overhead, CMCO establishes a new foundation for scalable,\ngeneralizable, and uncertainty-aware scientific machine learning."}
{"id": "2507.11763", "pdf": "https://arxiv.org/pdf/2507.11763", "abs": "https://arxiv.org/abs/2507.11763", "authors": ["Jose Luis Castanon Remy", "Caleb Chang", "Ekzhin Ear", "Shouhuai Xu"], "title": "Space Cybersecurity Testbed: Fidelity Framework, Example Implementation, and Characterization", "categories": ["cs.CR"], "comment": null, "summary": "Cyber threats against space infrastructures, including satellites and systems\non the ground, have not been adequately understood. Testbeds are important to\ndeepen our understanding and validate space cybersecurity studies. The state of\nthe art is that there are very few studies on building testbeds, and there are\nfew characterizations of testbeds. In this paper, we propose a framework for\ncharacterizing the fidelity of space cybersecurity testbeds. The framework\nincludes 7 attributes for characterizing the system models, threat models, and\ndefenses that can be accommodated by a testbed. We use the framework to guide\nus in building and characterizing a concrete testbed we have implemented, which\nincludes space, ground, user, and link segments. In particular, we show how the\ntestbed can accommodate some space cyber attack scenarios that have occurred in\nthe real world, and discuss future research directions."}
{"id": "2507.11916", "pdf": "https://arxiv.org/pdf/2507.11916", "abs": "https://arxiv.org/abs/2507.11916", "authors": ["Ehsan Futuhi", "Nathan R. Sturtevant"], "title": "A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS", "categories": ["cs.AI", "cs.DC"], "comment": null, "summary": "The rapid advancement of GPU technology has unlocked powerful parallel\nprocessing capabilities, creating new opportunities to enhance classic search\nalgorithms. A recent successful application of GPUs is in compressing large\npattern database (PDB) heuristics using neural networks while preserving\nheuristic admissibility. However, very few algorithms have been designed to\nexploit GPUs during search. Several variants of A* exist that batch GPU\ncomputations. In this paper we introduce a method for batching GPU computations\nin depth first search. In particular, we describe a new cost-bounded\ndepth-first search (CB-DFS) method that leverages the combined parallelism of\nmodern CPUs and GPUs. This is used to create algorithms like \\emph{Batch IDA*},\nan extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an\nextensions of Budgeted Tree Search. Our approach builds on the general approach\nused by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality\nguarantees. We evaluate the approach on the 3x3 Rubik's Cube and 4x4 sliding\ntile puzzle (STP), showing that GPU operations can be efficiently batched in\nDFS. Additionally, we conduct extensive experiments to analyze the effects of\nhyperparameters, neural network heuristic size, and hardware resources on\nperformance."}
{"id": "2507.11589", "pdf": "https://arxiv.org/pdf/2507.11589", "abs": "https://arxiv.org/abs/2507.11589", "authors": ["Sandeep Suresh Cranganore", "Andrei Bodnar", "Arturs Berzins", "Johannes Brandstetter"], "title": "Einstein Fields: A Neural Perspective To Computational General Relativity", "categories": ["cs.LG", "gr-qc"], "comment": "63 pages, 22 figures, 10 Tables, Github:\n  https://github.com/AndreiB137/EinFields", "summary": "We introduce Einstein Fields, a neural representation that is designed to\ncompress computationally intensive four-dimensional numerical relativity\nsimulations into compact implicit neural network weights. By modeling the\n\\emph{metric}, which is the core tensor field of general relativity, Einstein\nFields enable the derivation of physical quantities via automatic\ndifferentiation. However, unlike conventional neural fields (e.g., signed\ndistance, occupancy, or radiance fields), Einstein Fields are \\emph{Neural\nTensor Fields} with the key difference that when encoding the spacetime\ngeometry of general relativity into neural field representations, dynamics\nemerge naturally as a byproduct. Einstein Fields show remarkable potential,\nincluding continuum modeling of 4D spacetime, mesh-agnosticity, storage\nefficiency, derivative accuracy, and ease of use. We address these challenges\nacross several canonical test beds of general relativity and release an open\nsource JAX-based library, paving the way for more scalable and expressive\napproaches to numerical relativity. Code is made available at\nhttps://github.com/AndreiB137/EinFields"}
{"id": "2507.11772", "pdf": "https://arxiv.org/pdf/2507.11772", "abs": "https://arxiv.org/abs/2507.11772", "authors": ["Ifiyemi Leigha", "Basak Comlekcioglu", "Maria Pilar Bezanilla"], "title": "How To Mitigate And Defend Against DDoS Attacks In IoT Devices", "categories": ["cs.CR", "C.2.0; C.2.1; D.4.6"], "comment": null, "summary": "Distributed Denial of Service (DDoS) attacks have become increasingly\nprevalent and dangerous in the context of Internet of Things (IoT) networks,\nprimarily due to the low-security configurations of many connected devices.\nThis paper analyzes the nature and impact of DDoS attacks such as those\nlaunched by the Mirai botnet, and proposes layered mitigation strategies\ntailored to IoT environments. Key solutions explored include IPv6 Unique Local\nAddresses (ULA), edge computing, software-defined networking (SDN), honeypot\ndeception, and machine learning-based intrusion detection systems. The paper\naims to help engineers and researchers understand and implement practical\ncountermeasures to protect IoT infrastructures."}
{"id": "2507.11988", "pdf": "https://arxiv.org/pdf/2507.11988", "abs": "https://arxiv.org/abs/2507.11988", "authors": ["Yexuan Shi", "Mingyu Wang", "Yunxiang Cao", "Hongjie Lai", "Junjian Lan", "Xin Han", "Yu Wang", "Jie Geng", "Zhenan Li", "Zihao Xia", "Xiang Chen", "Chen Li", "Jian Xu", "Wenbo Duan", "Yuanshuo Zhu"], "title": "Aime: Towards Fully-Autonomous Multi-Agent Framework", "categories": ["cs.AI"], "comment": "14 pages, 1 figures,", "summary": "Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are\nemerging as a powerful paradigm for solving complex, multifaceted problems.\nHowever, the potential of these systems is often constrained by the prevalent\nplan-and-execute framework, which suffers from critical limitations: rigid plan\nexecution, static agent capabilities, and inefficient communication. These\nweaknesses hinder their adaptability and robustness in dynamic environments.\nThis paper introduces Aime, a novel multi-agent framework designed to overcome\nthese challenges through dynamic, reactive planning and execution. Aime\nreplaces the conventional static workflow with a fluid and adaptive\narchitecture. Its core innovations include: (1) a Dynamic Planner that\ncontinuously refines the overall strategy based on real-time execution\nfeedback; (2) an Actor Factory that implements Dynamic Actor instantiation,\nassembling specialized agents on-demand with tailored tools and knowledge; and\n(3) a centralized Progress Management Module that serves as a single source of\ntruth for coherent, system-wide state awareness. We empirically evaluated Aime\non a diverse suite of benchmarks spanning general reasoning (GAIA), software\nengineering (SWE-bench Verified), and live web navigation (WebVoyager). The\nresults demonstrate that Aime consistently outperforms even highly specialized\nstate-of-the-art agents in their respective domains. Its superior adaptability\nand task success rate establish Aime as a more resilient and effective\nfoundation for multi-agent collaboration."}
{"id": "2507.11590", "pdf": "https://arxiv.org/pdf/2507.11590", "abs": "https://arxiv.org/abs/2507.11590", "authors": ["Raju Challagundla", "Mohsen Dorodchi", "Pu Wang", "Minwoo Lee"], "title": "Synthetic Tabular Data Generation: A Comparative Survey for Modern Techniques", "categories": ["cs.LG"], "comment": null, "summary": "As privacy regulations become more stringent and access to real-world data\nbecomes increasingly constrained, synthetic data generation has emerged as a\nvital solution, especially for tabular datasets, which are central to domains\nlike finance, healthcare and the social sciences. This survey presents a\ncomprehensive and focused review of recent advances in synthetic tabular data\ngeneration, emphasizing methods that preserve complex feature relationships,\nmaintain statistical fidelity, and satisfy privacy requirements. A key\ncontribution of this work is the introduction of a novel taxonomy based on\npractical generation objectives, including intended downstream applications,\nprivacy guarantees, and data utility, directly informing methodological design\nand evaluation strategies. Therefore, this review prioritizes the actionable\ngoals that drive synthetic data creation, including conditional generation and\nrisk-sensitive modeling. Additionally, the survey proposes a benchmark\nframework to align technical innovation with real-world demands. By bridging\ntheoretical foundations with practical deployment, this work serves as both a\nroadmap for future research and a guide for implementing synthetic tabular data\nin privacy-critical environments."}
{"id": "2507.11775", "pdf": "https://arxiv.org/pdf/2507.11775", "abs": "https://arxiv.org/abs/2507.11775", "authors": ["Wesley dos Reis Bezerra", "Lais Machado Bezerra", "Carlos Becker Westphall"], "title": "Challenges in GenAI and Authentication: a scoping review", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Authentication and authenticity have been a security challenge since the\nbeginning of information sharing, especially in the context of digital\ninformation. With the advancement of generative artificial intelligence, these\nchallenges have evolved, demanding a more up-to-date analysis of their impacts\non society and system security. This work presents a scoping review that\nanalyzed 88 documents from the IEEExplorer, Scopus, and ACM databases,\npromoting an analysis of the resulting portfolio through six guiding questions\nfocusing on the most relevant work, challenges, attack surfaces, threats,\nproposed solutions, and gaps. Finally, the portfolio articles are analyzed\nthrough this guiding research lens and also receive individualized analysis.\nThe results consistently outline the challenges, gaps, and threats related to\nimages, text, audio, and video, thereby supporting new research in the areas of\nauthentication and generative artificial intelligence."}
{"id": "2507.11992", "pdf": "https://arxiv.org/pdf/2507.11992", "abs": "https://arxiv.org/abs/2507.11992", "authors": ["Pranav Rajbhandari", "Abhi Veda", "Matthew Garratt", "Mandayam Srinivasan", "Sridhar Ravi"], "title": "Understanding visual attention beehind bee-inspired UAV navigation", "categories": ["cs.AI"], "comment": null, "summary": "Bio-inspired design is often used in autonomous UAV navigation due to the\ncapacity of biological systems for flight and obstacle avoidance despite\nlimited sensory and computational capabilities. In particular, honeybees mainly\nuse the sensory input of optic flow, the apparent motion of objects in their\nvisual field, to navigate cluttered environments. In our work, we train a\nReinforcement Learning agent to navigate a tunnel with obstacles using only\noptic flow as sensory input. We inspect the attention patterns of trained\nagents to determine the regions of optic flow on which they primarily base\ntheir motor decisions. We find that agents trained in this way pay most\nattention to regions of discontinuity in optic flow, as well as regions with\nlarge optic flow magnitude. The trained agents appear to navigate a cluttered\ntunnel by avoiding the obstacles that produce large optic flow, while\nmaintaining a centered position in their environment, which resembles the\nbehavior seen in flying insects. This pattern persists across independently\ntrained agents, which suggests that this could be a good strategy for\ndeveloping a simple explicit control law for physical UAVs."}
{"id": "2507.11620", "pdf": "https://arxiv.org/pdf/2507.11620", "abs": "https://arxiv.org/abs/2507.11620", "authors": ["Steven Dillmann", "Juan Rafael Martínez-Galarza"], "title": "Learning Representations of Event Time Series with Sparse Autoencoders for Anomaly Detection, Similarity Search, and Unsupervised Classification", "categories": ["cs.LG", "astro-ph.HE", "astro-ph.IM", "cs.AI"], "comment": "Accepted at the 2025 ICML Workshop on Machine Learning for\n  Astrophysics, Code available at:\n  https://github.com/StevenDillmann/ml-xraytransients-mnras", "summary": "Event time series are sequences of discrete events occurring at irregular\ntime intervals, each associated with a domain-specific observational modality.\nThey are common in domains such as high-energy astrophysics, computational\nsocial science, cybersecurity, finance, healthcare, neuroscience, and\nseismology. Their unstructured and irregular structure poses significant\nchallenges for extracting meaningful patterns and identifying salient phenomena\nusing conventional techniques. We propose novel two- and three-dimensional\ntensor representations for event time series, coupled with sparse autoencoders\nthat learn physically meaningful latent representations. These embeddings\nsupport a variety of downstream tasks, including anomaly detection,\nsimilarity-based retrieval, semantic clustering, and unsupervised\nclassification. We demonstrate our approach on a real-world dataset from X-ray\nastronomy, showing that these representations successfully capture temporal and\nspectral signatures and isolate diverse classes of X-ray transients. Our\nframework offers a flexible, scalable, and generalizable solution for analyzing\ncomplex, irregular event time series across scientific and industrial domains."}
{"id": "2507.11908", "pdf": "https://arxiv.org/pdf/2507.11908", "abs": "https://arxiv.org/abs/2507.11908", "authors": ["Rahat Masood", "Sunday Oyinlola Ogundoyin", "Muhammad Ikram", "Alex Ye"], "title": "Unveiling Usability Challenges in Web Privacy Controls", "categories": ["cs.CR"], "comment": null, "summary": "With the increasing concerns around privacy and the enforcement of data\nprivacy laws, many websites now provide users with privacy controls. However,\nlocating these controls can be challenging, as they are frequently hidden\nwithin multiple settings and layers. Moreover, the lack of standardization\nmeans these controls can vary widely across services. The technical or\nconfusing terminology used to describe these controls further complicates\nusers' ability to understand and use them effectively. This paper presents a\nlarge-scale empirical analysis investigating usability challenges of web\nprivacy controls across 18,628 websites. While aiming for a multi-scenario\nview, our automated data collection faced significant hurdles, particularly in\nsimulating sign-up and authenticated user visits, leading to more focused\ninsights on guest visit scenarios and challenges in automated capture of\ndynamic user interactions. Our heuristic evaluation of three different user\nvisit scenarios identifies significant website usability issues. Our results\nshow that privacy policies are most common across all visit scenarios, with\nnudges and notices being prevalent in sign-up situations. We recommend\ndesigning privacy controls that: enhance awareness through pop-up nudges and\nnotices; offer a table of contents as navigational aids and customized settings\nlinks in policies for more informed choice; and ensure accessibility via direct\nlinks to privacy settings from nudges."}
{"id": "2507.12110", "pdf": "https://arxiv.org/pdf/2507.12110", "abs": "https://arxiv.org/abs/2507.12110", "authors": ["Ye Han", "Lijun Zhang", "Dejian Meng", "Zhuang Zhang"], "title": "Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs", "categories": ["cs.AI"], "comment": "16 pages, 16 figures", "summary": "The exploration-exploitation trade-off constitutes one of the fundamental\nchallenges in reinforcement learning (RL), which is exacerbated in multi-agent\nreinforcement learning (MARL) due to the exponential growth of joint\nstate-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL)\nmethod for optimizing cooperative decision-making of connected and autonomous\nvehicles (CAVs) in mixed traffic. This work presents two primary contributions:\nFirst, we construct a game topology tensor for dynamic traffic flow,\neffectively compressing high-dimensional traffic state information and decrease\nthe search space for MARL algorithms. Second, building upon the designed game\ntopology tensor and using QMIX as the backbone RL algorithm, we establish a\ntopology-enhanced MARL framework incorporating visit counts and agent mutual\ninformation. Extensive simulations across varying traffic densities and CAV\npenetration rates demonstrate the effectiveness of TPE-MARL. Evaluations\nencompassing training dynamics, exploration patterns, macroscopic traffic\nperformance metrics, and microscopic vehicle behaviors reveal that TPE-MARL\nsuccessfully balances exploration and exploitation. Consequently, it exhibits\nsuperior performance in terms of traffic efficiency, safety, decision\nsmoothness, and task completion. Furthermore, the algorithm demonstrates\ndecision-making rationality comparable to or exceeding that of human drivers in\nboth mixed-autonomy and fully autonomous traffic scenarios. Code of our work is\navailable at\n\\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}."}
{"id": "2507.11639", "pdf": "https://arxiv.org/pdf/2507.11639", "abs": "https://arxiv.org/abs/2507.11639", "authors": ["Fouad Oubari", "Raphael Meunier", "Rodrigue Décatoire", "Mathilde Mougeot"], "title": "Deep Generative Methods and Tire Architecture Design", "categories": ["cs.LG"], "comment": null, "summary": "As deep generative models proliferate across the AI landscape, industrial\npractitioners still face critical yet unanswered questions about which deep\ngenerative models best suit complex manufacturing design tasks. This work\naddresses this question through a complete study of five representative models\n(Variational Autoencoder, Generative Adversarial Network, multimodal\nVariational Autoencoder, Denoising Diffusion Probabilistic Model, and\nMultinomial Diffusion Model) on industrial tire architecture generation. Our\nevaluation spans three key industrial scenarios: (i) unconditional generation\nof complete multi-component designs, (ii) component-conditioned generation\n(reconstructing architectures from partial observations), and (iii)\ndimension-constrained generation (creating designs that satisfy specific\ndimensional requirements). To enable discrete diffusion models to handle\nconditional scenarios, we introduce categorical inpainting, a mask-aware\nreverse diffusion process that preserves known labels without requiring\nadditional training. Our evaluation employs geometry-aware metrics specifically\ncalibrated for industrial requirements, quantifying spatial coherence,\ncomponent interaction, structural connectivity, and perceptual fidelity. Our\nfindings reveal that diffusion models achieve the strongest overall\nperformance; a masking-trained VAE nonetheless outperforms the multimodal\nvariant MMVAE\\textsuperscript{+} on nearly all component-conditioned metrics,\nand within the diffusion family MDM leads in-distribution whereas DDPM\ngeneralises better to out-of-distribution dimensional constraints."}
{"id": "2507.11943", "pdf": "https://arxiv.org/pdf/2507.11943", "abs": "https://arxiv.org/abs/2507.11943", "authors": ["Haiwei Lin", "Shoko Imaizumi", "Hitoshi Kiya"], "title": "Effective Fine-Tuning of Vision Transformers with Low-Rank Adaptation for Privacy-Preserving Image Classification", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": "3 pages, 3 figures, conference", "summary": "We propose a low-rank adaptation method for training privacy-preserving\nvision transformer (ViT) models that efficiently freezes pre-trained ViT model\nweights. In the proposed method, trainable rank decomposition matrices are\ninjected into each layer of the ViT architecture, and moreover, the patch\nembedding layer is not frozen, unlike in the case of the conventional low-rank\nadaptation methods. The proposed method allows us not only to reduce the number\nof trainable parameters but to also maintain almost the same accuracy as that\nof full-time tuning."}
{"id": "2507.12186", "pdf": "https://arxiv.org/pdf/2507.12186", "abs": "https://arxiv.org/abs/2507.12186", "authors": ["Edward Kim", "Hanna Kurniawati"], "title": "Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation", "categories": ["cs.AI", "I.2.8; I.2.9"], "comment": "8 pages, 2 tables, 3 figures. To be presented at International Joint\n  Conference on Artificial Intelligence 2025", "summary": "This paper proposes Partially Observable Reference Policy Programming, a\nnovel anytime online approximate POMDP solver which samples meaningful future\nhistories very deeply while simultaneously forcing a gradual policy update. We\nprovide theoretical guarantees for the algorithm's underlying scheme which say\nthat the performance loss is bounded by the average of the sampling\napproximation errors rather than the usual maximum, a crucial requirement given\nthe sampling sparsity of online planning. Empirical evaluations on two\nlarge-scale problems with dynamically evolving environments -- including a\nhelicopter emergency scenario in the Corsica region requiring approximately 150\nplanning steps -- corroborate the theoretical results and indicate that our\nsolver considerably outperforms current online benchmarks."}
{"id": "2507.11645", "pdf": "https://arxiv.org/pdf/2507.11645", "abs": "https://arxiv.org/abs/2507.11645", "authors": ["Ahmed Salah", "David Yevick"], "title": "Tracing the Path to Grokking: Embeddings, Dropout, and Network Activation", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages, 11 figures", "summary": "Grokking refers to delayed generalization in which the increase in test\naccuracy of a neural network occurs appreciably after the improvement in\ntraining accuracy This paper introduces several practical metrics including\nvariance under dropout, robustness, embedding similarity, and sparsity\nmeasures, that can forecast grokking behavior. Specifically, the resilience of\nneural networks to noise during inference is estimated from a Dropout\nRobustness Curve (DRC) obtained from the variation of the accuracy with the\ndropout rate as the model transitions from memorization to generalization. The\nvariance of the test accuracy under stochastic dropout across training\ncheckpoints further exhibits a local maximum during the grokking. Additionally,\nthe percentage of inactive neurons decreases during generalization, while the\nembeddings tend to a bimodal distribution independent of initialization that\ncorrelates with the observed cosine similarity patterns and dataset symmetries.\nThese metrics additionally provide valuable insight into the origin and\nbehaviour of grokking."}
{"id": "2507.12003", "pdf": "https://arxiv.org/pdf/2507.12003", "abs": "https://arxiv.org/abs/2507.12003", "authors": ["Cara Ellen Appel"], "title": "Expanding ML-Documentation Standards For Better Security", "categories": ["cs.CR", "cs.LG", "cs.SE"], "comment": "Accepted for publication at the 33rd IEEE International Requirements\n  Engineering Workshop (REW 2025)", "summary": "This article presents the current state of ML-security and of the\ndocumentation of ML-based systems, models and datasets in research and practice\nbased on an extensive review of the existing literature. It shows a generally\nlow awareness of security aspects among ML-practitioners and organizations and\nan often unstandardized approach to documentation, leading to overall low\nquality of ML-documentation. Existing standards are not regularly adopted in\npractice and IT-security aspects are often not included in documentation. Due\nto these factors, there is a clear need for improved security documentation in\nML, as one step towards addressing the existing gaps in ML-security. To achieve\nthis, we propose expanding existing documentation standards for\nML-documentation to include a security section with specific security relevant\ninformation. Implementing this, a novel expanded method of documenting security\nrequirements in ML-documentation is presented, based on the existing Model\nCards and Datasheets for Datasets standards, but with the recommendation to\nadopt these findings in all ML-documentation."}
{"id": "2507.12207", "pdf": "https://arxiv.org/pdf/2507.12207", "abs": "https://arxiv.org/abs/2507.12207", "authors": ["Subin Lin", "Chuanbo Hua"], "title": "BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution", "categories": ["cs.AI", "cs.NE"], "comment": "ICML 2025 CO-Build Workshop Poster", "summary": "Accurate building energy forecasting is essential, yet traditional heuristics\noften lack precision, while advanced models can be opaque and struggle with\ngeneralization by neglecting physical principles. This paper introduces\nBuildEvo, a novel framework that uses Large Language Models (LLMs) to\nautomatically design effective and interpretable energy prediction heuristics.\nWithin an evolutionary process, BuildEvo guides LLMs to construct and enhance\nheuristics by systematically incorporating physical insights from building\ncharacteristics and operational data (e.g., from the Building Data Genome\nProject 2). Evaluations show BuildEvo achieves state-of-the-art performance on\nbenchmarks, offering improved generalization and transparent prediction logic.\nThis work advances the automated design of robust, physically grounded\nheuristics, promoting trustworthy models for complex energy systems."}
{"id": "2507.11649", "pdf": "https://arxiv.org/pdf/2507.11649", "abs": "https://arxiv.org/abs/2507.11649", "authors": ["Daniel Commey", "Benjamin Appiah", "Griffith S. Klogo", "Garth V. Crosby"], "title": "ZKP-FedEval: Verifiable and Privacy-Preserving Federated Evaluation using Zero-Knowledge Proofs", "categories": ["cs.LG", "cs.DC", "cs.NI"], "comment": null, "summary": "Federated Learning (FL) enables collaborative model training on decentralized\ndata without exposing raw data. However, the evaluation phase in FL may leak\nsensitive information through shared performance metrics. In this paper, we\npropose a novel protocol that incorporates Zero-Knowledge Proofs (ZKPs) to\nenable privacy-preserving and verifiable evaluation for FL. Instead of\nrevealing raw loss values, clients generate a succinct proof asserting that\ntheir local loss is below a predefined threshold. Our approach is implemented\nwithout reliance on external APIs, using self-contained modules for federated\nlearning simulation, ZKP circuit design, and experimental evaluation on both\nthe MNIST and Human Activity Recognition (HAR) datasets. We focus on a\nthreshold-based proof for a simple Convolutional Neural Network (CNN) model\n(for MNIST) and a multi-layer perceptron (MLP) model (for HAR), and evaluate\nthe approach in terms of computational overhead, communication cost, and\nverifiability."}
{"id": "2507.12050", "pdf": "https://arxiv.org/pdf/2507.12050", "abs": "https://arxiv.org/abs/2507.12050", "authors": ["Sunpill Kim", "Seunghun Paik", "Chanwoo Hwang", "Dongsoo Kim", "Junbum Shin", "Jae Hong Seo"], "title": "IDFace: Face Template Protection for Efficient and Secure Identification", "categories": ["cs.CR", "cs.CV", "I.5.4; K.6.5; D.4.6; I.4.7"], "comment": "Accepted to ICCV 2025", "summary": "As face recognition systems (FRS) become more widely used, user privacy\nbecomes more important. A key privacy issue in FRS is protecting the user's\nface template, as the characteristics of the user's face image can be recovered\nfrom the template. Although recent advances in cryptographic tools such as\nhomomorphic encryption (HE) have provided opportunities for securing the FRS,\nHE cannot be used directly with FRS in an efficient plug-and-play manner. In\nparticular, although HE is functionally complete for arbitrary programs, it is\nbasically designed for algebraic operations on encrypted data of predetermined\nshape, such as a polynomial ring. Thus, a non-tailored combination of HE and\nthe system can yield very inefficient performance, and many previous HE-based\nface template protection methods are hundreds of times slower than plain\nsystems without protection. In this study, we propose IDFace, a new HE-based\nsecure and efficient face identification method with template protection.\nIDFace is designed on the basis of two novel techniques for efficient searching\non a (homomorphically encrypted) biometric database with an angular metric. The\nfirst technique is a template representation transformation that sharply\nreduces the unit cost for the matching test. The second is a space-efficient\nencoding that reduces wasted space from the encryption algorithm, thus saving\nthe number of operations on encrypted templates. Through experiments, we show\nthat IDFace can identify a face template from among a database of 1M encrypted\ntemplates in 126ms, showing only 2X overhead compared to the identification\nover plaintexts."}
{"id": "2507.12215", "pdf": "https://arxiv.org/pdf/2507.12215", "abs": "https://arxiv.org/abs/2507.12215", "authors": ["Yuhao Chen", "Shuochen Liu", "Yuanjie Lyu", "Chao Zhang", "Jiayao Shi", "Tong Xu"], "title": "Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning", "categories": ["cs.AI"], "comment": "10 pages, 7 figures", "summary": "Game playing has long served as a fundamental benchmark for evaluating\nArtificial General Intelligence (AGI). While Large Language Models (LLMs) have\ndemonstrated impressive capabilities in general reasoning, their effectiveness\nin spatial strategic reasoning, which is critical for complex and fully\nobservable board games, remains insufficiently explored. In this work, we adopt\nChinese Chess (Xiangqi) as a challenging and rich testbed due to its intricate\nrules and spatial complexity. To advance LLMs' strategic competence in such\nenvironments, we propose a training framework tailored to Xiangqi, built upon a\nlarge-scale dataset of five million board-move pairs enhanced with expert\nannotations and engine evaluations. Building on this foundation, we introduce\nXiangqi-R1, a 7B-parameter model trained in multi-stage manner: (1) fine-tuning\nfor legal move prediction to capture basic spatial rules, (2) incorporating\nstrategic annotations to improve decision-making, and (3) applying\nreinforcement learning via Group Relative Policy Optimization (GRPO) with\nmulti-dimensional reward signals to enhance reasoning stability. Our\nExperimental results indicate that, despite their size and power,\ngeneral-purpose LLMs struggle to achieve satisfactory performance in these\ntasks. Compared to general-purpose LLMs, Xiangqi-R1 greatly advances with an\n18% rise in move legality and a 22% boost in analysis accuracy. Our results\npoint to a promising path for creating general strategic intelligence in\nspatially complex areas."}
{"id": "2507.11660", "pdf": "https://arxiv.org/pdf/2507.11660", "abs": "https://arxiv.org/abs/2507.11660", "authors": ["Joao F. Rocha", "Ke Xu", "Xingzhi Sun", "Ananya Krishna", "Dhananjay Bhaskar", "Blanche Mongeon", "Morgan Craig", "Mark Gerstein", "Smita Krishnaswamy"], "title": "STAGED: A Multi-Agent Neural Network for Learning Cellular Interaction Dynamics", "categories": ["cs.LG", "cs.MA", "q-bio.QM"], "comment": null, "summary": "The advent of single-cell technology has significantly improved our\nunderstanding of cellular states and subpopulations in various tissues under\nnormal and diseased conditions by employing data-driven approaches such as\nclustering and trajectory inference. However, these methods consider cells as\nindependent data points of population distributions. With spatial\ntranscriptomics, we can represent cellular organization, along with dynamic\ncell-cell interactions that lead to changes in cell state. Still, key\ncomputational advances are necessary to enable the data-driven learning of such\ncomplex interactive cellular dynamics. While agent-based modeling (ABM)\nprovides a powerful framework, traditional approaches rely on handcrafted rules\nderived from domain knowledge rather than data-driven approaches. To address\nthis, we introduce Spatio Temporal Agent-Based Graph Evolution Dynamics(STAGED)\nintegrating ABM with deep learning to model intercellular communication, and\nits effect on the intracellular gene regulatory network. Using graph ODE\nnetworks (GDEs) with shared weights per cell type, our approach represents\ngenes as vertices and interactions as directed edges, dynamically learning\ntheir strengths through a designed attention mechanism. Trained to match\ncontinuous trajectories of simulated as well as inferred trajectories from\nspatial transcriptomics data, the model captures both intercellular and\nintracellular interactions, enabling a more adaptive and accurate\nrepresentation of cellular dynamics."}
{"id": "2507.12061", "pdf": "https://arxiv.org/pdf/2507.12061", "abs": "https://arxiv.org/abs/2507.12061", "authors": ["Zequan Huang", "Jacques Robin", "Nicolas Herbaut", "Nourhène Ben Rabah", "Bénédicte Le Grand"], "title": "Toward an Intent-Based and Ontology-Driven Autonomic Security Response in Security Orchestration Automation and Response", "categories": ["cs.CR"], "comment": null, "summary": "Modern Security Orchestration, Automation, and Response (SOAR) platforms must\nrapidly adapt to continuously evolving cyber attacks. Intent-Based Networking\nhas emerged as a promising paradigm for cyber attack mitigation through\nhigh-level declarative intents, which offer greater flexibility and persistency\nthan procedural actions. In this paper, we bridge the gap between two active\nresearch directions: Intent-Based Cyber Defense and Autonomic Cyber Defense, by\nproposing a unified, ontology-driven security intent definition leveraging the\nMITRE-D3FEND cybersecurity ontology. We also propose a general two-tiered\nmethodology for integrating such security intents into decision-theoretic\nAutonomic Cyber Defense systems, enabling hierarchical and context-aware\nautomated response capabilities. The practicality of our approach is\ndemonstrated through a concrete use case, showcasing its integration within\nnext-generation Security Orchestration, Automation, and Response platforms."}
{"id": "2507.11570", "pdf": "https://arxiv.org/pdf/2507.11570", "abs": "https://arxiv.org/abs/2507.11570", "authors": ["Ha Na Cho", "Sairam Sutari", "Alexander Lopez", "Hansen Bow", "Kai Zheng"], "title": "SurgeryLSTM: A Time-Aware Neural Model for Accurate and Explainable Length of Stay Prediction After Spine Surgery", "categories": ["cs.LG", "cs.AI", "eess.IV"], "comment": null, "summary": "Objective: To develop and evaluate machine learning (ML) models for\npredicting length of stay (LOS) in elective spine surgery, with a focus on the\nbenefits of temporal modeling and model interpretability. Materials and\nMethods: We compared traditional ML models (e.g., linear regression, random\nforest, support vector machine (SVM), and XGBoost) with our developed model,\nSurgeryLSTM, a masked bidirectional long short-term memory (BiLSTM) with an\nattention, using structured perioperative electronic health records (EHR) data.\nPerformance was evaluated using the coefficient of determination (R2), and key\npredictors were identified using explainable AI. Results: SurgeryLSTM achieved\nthe highest predictive accuracy (R2=0.86), outperforming XGBoost (R2 = 0.85)\nand baseline models. The attention mechanism improved interpretability by\ndynamically identifying influential temporal segments within preoperative\nclinical sequences, allowing clinicians to trace which events or features most\ncontributed to each LOS prediction. Key predictors of LOS included bone\ndisorder, chronic kidney disease, and lumbar fusion identified as the most\nimpactful predictors of LOS. Discussion: Temporal modeling with attention\nmechanisms significantly improves LOS prediction by capturing the sequential\nnature of patient data. Unlike static models, SurgeryLSTM provides both higher\naccuracy and greater interpretability, which are critical for clinical\nadoption. These results highlight the potential of integrating attention-based\ntemporal models into hospital planning workflows. Conclusion: SurgeryLSTM\npresents an effective and interpretable AI solution for LOS prediction in\nelective spine surgery. Our findings support the integration of temporal,\nexplainable ML approaches into clinical decision support systems to enhance\ndischarge readiness and individualized patient care."}
{"id": "2507.11688", "pdf": "https://arxiv.org/pdf/2507.11688", "abs": "https://arxiv.org/abs/2507.11688", "authors": ["Travis Pence", "Daisuke Yamada", "Vikas Singh"], "title": "Composing Linear Layers from Irreducibles", "categories": ["cs.LG", "I.2.6"], "comment": "27 Pages, 13 Tables, 8 Figures", "summary": "Contemporary large models often exhibit behaviors suggesting the presence of\nlow-level primitives that compose into modules with richer functionality, but\nthese fundamental building blocks remain poorly understood. We investigate this\ncompositional structure in linear layers by asking: can we identify/synthesize\nlinear transformations from a minimal set of geometric primitives? Using\nClifford algebra, we show that linear layers can be expressed as compositions\nof bivectors -- geometric objects encoding oriented planes -- and introduce a\ndifferentiable algorithm that decomposes them into products of rotors. This\nconstruction uses only O(log^2 d) parameters, versus O(d^2) required by dense\nmatrices. Applied to the key, query, and value projections in LLM attention\nlayers, our rotor-based layers match the performance of strong baselines such\nas block-Hadamard and low-rank approximations. Our findings provide an\nalgebraic perspective on how these geometric primitives can compose into\nhigher-level functions within deep models."}
{"id": "2507.12098", "pdf": "https://arxiv.org/pdf/2507.12098", "abs": "https://arxiv.org/abs/2507.12098", "authors": ["Xiang Li", "Yifan Lin", "Yuanzhe Zhang"], "title": "A Privacy-Preserving Framework for Advertising Personalization Incorporating Federated Learning and Differential Privacy", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "To mitigate privacy leakage and performance issues in personalized\nadvertising, this paper proposes a framework that integrates federated learning\nand differential privacy. The system combines distributed feature extraction,\ndynamic privacy budget allocation, and robust model aggregation to balance\nmodel accuracy, communication overhead, and privacy protection. Multi-party\nsecure computing and anomaly detection mechanisms further enhance system\nresilience against malicious attacks. Experimental results demonstrate that the\nframework achieves dual optimization of recommendation accuracy and system\nefficiency while ensuring privacy, providing both a practical solution and a\ntheoretical foundation for applying privacy protection technologies in\nadvertisement recommendation."}
{"id": "2507.11574", "pdf": "https://arxiv.org/pdf/2507.11574", "abs": "https://arxiv.org/abs/2507.11574", "authors": ["Kazuma Kobayashi", "Shailesh Garg", "Farid Ahmed", "Souvik Chakraborty", "Syed Bahauddin Alam"], "title": "Distribution-Free Uncertainty-Aware Virtual Sensing via Conformalized Neural Operators", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Robust uncertainty quantification (UQ) remains a critical barrier to the safe\ndeployment of deep learning in real-time virtual sensing, particularly in\nhigh-stakes domains where sparse, noisy, or non-collocated sensor data are the\nnorm. We introduce the Conformalized Monte Carlo Operator (CMCO), a framework\nthat transforms neural operator-based virtual sensing with calibrated,\ndistribution-free prediction intervals. By unifying Monte Carlo dropout with\nsplit conformal prediction in a single DeepONet architecture, CMCO achieves\nspatially resolved uncertainty estimates without retraining, ensembling, or\ncustom loss design. Our method addresses a longstanding challenge: how to endow\noperator learning with efficient and reliable UQ across heterogeneous domains.\nThrough rigorous evaluation on three distinct applications: turbulent flow,\nelastoplastic deformation, and global cosmic radiation dose estimation-CMCO\nconsistently attains near-nominal empirical coverage, even in settings with\nstrong spatial gradients and proxy-based sensing. This breakthrough offers a\ngeneral-purpose, plug-and-play UQ solution for neural operators, unlocking\nreal-time, trustworthy inference in digital twins, sensor fusion, and\nsafety-critical monitoring. By bridging theory and deployment with minimal\ncomputational overhead, CMCO establishes a new foundation for scalable,\ngeneralizable, and uncertainty-aware scientific machine learning."}
{"id": "2507.11690", "pdf": "https://arxiv.org/pdf/2507.11690", "abs": "https://arxiv.org/abs/2507.11690", "authors": ["Amaya Dharmasiri", "William Yang", "Polina Kirichenko", "Lydia Liu", "Olga Russakovsky"], "title": "The Impact of Coreset Selection on Spurious Correlations and Group Robustness", "categories": ["cs.LG", "cs.CV"], "comment": "10 pages, 9 additional pages for Appendix", "summary": "Coreset selection methods have shown promise in reducing the training data\nsize while maintaining model performance for data-efficient machine learning.\nHowever, as many datasets suffer from biases that cause models to learn\nspurious correlations instead of causal features, it is important to understand\nwhether and how dataset reduction methods may perpetuate, amplify, or mitigate\nthese biases. In this work, we conduct the first comprehensive analysis of the\nimplications of data selection on the spurious bias levels of the selected\ncoresets and the robustness of downstream models trained on them. We use an\nextensive experimental setting spanning ten different spurious correlations\nbenchmarks, five score metrics to characterize sample importance/ difficulty,\nand five data selection policies across a broad range of coreset sizes.\nThereby, we unravel a series of nontrivial nuances in interactions between\nsample difficulty and bias alignment, as well as dataset bias and resultant\nmodel robustness. For example, we find that selecting coresets using\nembedding-based sample characterization scores runs a comparatively lower risk\nof inadvertently exacerbating bias than selecting using characterizations based\non learning dynamics. Most importantly, our analysis reveals that although some\ncoreset selection methods could achieve lower bias levels by prioritizing\ndifficult samples, they do not reliably guarantee downstream robustness."}
{"id": "2507.12185", "pdf": "https://arxiv.org/pdf/2507.12185", "abs": "https://arxiv.org/abs/2507.12185", "authors": ["Rina Mishra", "Gaurav Varshney"], "title": "Exploiting Jailbreaking Vulnerabilities in Generative AI to Bypass Ethical Safeguards for Facilitating Phishing Attacks", "categories": ["cs.CR"], "comment": null, "summary": "The advent of advanced Generative AI (GenAI) models such as DeepSeek and\nChatGPT has significantly reshaped the cybersecurity landscape, introducing\nboth promising opportunities and critical risks. This study investigates how\nGenAI powered chatbot services can be exploited via jailbreaking techniques to\nbypass ethical safeguards, enabling the generation of phishing content,\nrecommendation of hacking tools, and orchestration of phishing campaigns. In\nethically controlled experiments, we used ChatGPT 4o Mini selected for its\naccessibility and status as the latest publicly available model at the time of\nexperimentation, as a representative GenAI system. Our findings reveal that the\nmodel could successfully guide novice users in executing phishing attacks\nacross various vectors, including web, email, SMS (smishing), and voice\n(vishing). Unlike automated phishing campaigns that typically follow detectable\npatterns, these human-guided, AI assisted attacks are capable of evading\ntraditional anti phishing mechanisms, thereby posing a growing security threat.\nWe focused on DeepSeek and ChatGPT due to their widespread adoption and\ntechnical relevance in 2025. The study further examines common jailbreaking\ntechniques and the specific vulnerabilities exploited in these models. Finally,\nwe evaluate a range of mitigation strategies such as user education, advanced\nauthentication mechanisms, and regulatory policy measures and discuss emerging\ntrends in GenAI facilitated phishing, outlining future research directions to\nstrengthen cybersecurity defenses in the age of artificial intelligence."}
{"id": "2507.11620", "pdf": "https://arxiv.org/pdf/2507.11620", "abs": "https://arxiv.org/abs/2507.11620", "authors": ["Steven Dillmann", "Juan Rafael Martínez-Galarza"], "title": "Learning Representations of Event Time Series with Sparse Autoencoders for Anomaly Detection, Similarity Search, and Unsupervised Classification", "categories": ["cs.LG", "astro-ph.HE", "astro-ph.IM", "cs.AI"], "comment": "Accepted at the 2025 ICML Workshop on Machine Learning for\n  Astrophysics, Code available at:\n  https://github.com/StevenDillmann/ml-xraytransients-mnras", "summary": "Event time series are sequences of discrete events occurring at irregular\ntime intervals, each associated with a domain-specific observational modality.\nThey are common in domains such as high-energy astrophysics, computational\nsocial science, cybersecurity, finance, healthcare, neuroscience, and\nseismology. Their unstructured and irregular structure poses significant\nchallenges for extracting meaningful patterns and identifying salient phenomena\nusing conventional techniques. We propose novel two- and three-dimensional\ntensor representations for event time series, coupled with sparse autoencoders\nthat learn physically meaningful latent representations. These embeddings\nsupport a variety of downstream tasks, including anomaly detection,\nsimilarity-based retrieval, semantic clustering, and unsupervised\nclassification. We demonstrate our approach on a real-world dataset from X-ray\nastronomy, showing that these representations successfully capture temporal and\nspectral signatures and isolate diverse classes of X-ray transients. Our\nframework offers a flexible, scalable, and generalizable solution for analyzing\ncomplex, irregular event time series across scientific and industrial domains."}
{"id": "2507.11702", "pdf": "https://arxiv.org/pdf/2507.11702", "abs": "https://arxiv.org/abs/2507.11702", "authors": ["Hein de Wilde", "Ali Mohammed Mansoor Alsahag", "Pierre Blanchet"], "title": "Time series classification of satellite data using LSTM networks: an approach for predicting leaf-fall to minimize railroad traffic disruption", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Railroad traffic disruption as a result of leaf-fall cost the UK rail\nindustry over 300 million per year and measures to mitigate such disruptions\nare employed on a large scale, with 1.67 million kilometers of track being\ntreated in the UK in 2021 alone. Therefore, the ability to anticipate the\ntiming of leaf-fall would offer substantial benefits for rail network\noperators, enabling the efficient scheduling of such mitigation measures.\nHowever, current methodologies for predicting leaf-fall exhibit considerable\nlimitations in terms of scalability and reliability. This study endeavors to\ndevise a prediction system that leverages specialized prediction methods and\nthe latest satellite data sources to generate both scalable and reliable\ninsights into leaf-fall timings. An LSTM network trained on ground-truth\nleaf-falling data combined with multispectral and meteorological satellite data\ndemonstrated a root-mean-square error of 6.32 days for predicting the start of\nleaf-fall and 9.31 days for predicting the end of leaf-fall. The model, which\nimproves upon previous work on the topic, offers promising opportunities for\nthe optimization of leaf mitigation measures in the railway industry and the\nimprovement of our understanding of complex ecological systems."}
{"id": "2507.12345", "pdf": "https://arxiv.org/pdf/2507.12345", "abs": "https://arxiv.org/abs/2507.12345", "authors": ["Liam Tyler", "Adam Caulfield", "Ivan De Oliveira Nunes"], "title": "Efficient Control Flow Attestation by Speculating on Control Flow Path Representations", "categories": ["cs.CR"], "comment": null, "summary": "Control Flow Attestation (CFA) allows remote verification of run-time\nsoftware integrity in embedded systems. However, CFA is limited by the\nstorage/transmission costs of generated control flow logs (CFlog). Recent work\nhas proposed application-specific optimizations by speculating on likely\nsub-paths in CFlog and replacing them with reserved symbols at runtime. Albeit\neffective, prior approaches do not consider the representation of addresses in\na control flow path for speculation. This work proposes RESPEC-CFA, an\narchitectural extension for CFA allowing for speculation on (1) the locality of\ncontrol flows and (2) their Huffman encoding. Alone, RESPEC-CFA reduces CFlog\nsizes by up to 90.1%. Combined with prior methods, RESPEC-CFA yields reductions\nof up to 99.7%, representing a significant step toward practical CFA."}
{"id": "2507.11630", "pdf": "https://arxiv.org/pdf/2507.11630", "abs": "https://arxiv.org/abs/2507.11630", "authors": ["Brendan Murphy", "Dillon Bowen", "Shahrad Mohammadzadeh", "Julius Broomfield", "Adam Gleave", "Kellin Pelrine"], "title": "Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility", "categories": ["cs.CR", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "AI systems are rapidly advancing in capability, and frontier model developers\nbroadly acknowledge the need for safeguards against serious misuse. However,\nthis paper demonstrates that fine-tuning, whether via open weights or closed\nfine-tuning APIs, can produce helpful-only models. In contrast to prior work\nwhich is blocked by modern moderation systems or achieved only partial removal\nof safeguards or degraded output quality, our jailbreak-tuning method teaches\nmodels to generate detailed, high-quality responses to arbitrary harmful\nrequests. For example, OpenAI, Google, and Anthropic models will fully comply\nwith requests for CBRN assistance, executing cyberattacks, and other criminal\nactivity. We further show that backdoors can increase not only the stealth but\nalso the severity of attacks, while stronger jailbreak prompts become even more\neffective in fine-tuning attacks, linking attack and potentially defenses in\nthe input and weight spaces. Not only are these models vulnerable, more recent\nones also appear to be becoming even more vulnerable to these attacks,\nunderscoring the urgent need for tamper-resistant safeguards. Until such\nsafeguards are discovered, companies and policymakers should view the release\nof any fine-tunable model as simultaneously releasing its evil twin: equally\ncapable as the original model, and usable for any malicious purpose within its\ncapabilities."}
{"id": "2507.11706", "pdf": "https://arxiv.org/pdf/2507.11706", "abs": "https://arxiv.org/abs/2507.11706", "authors": ["Taira Tsuchiya", "Shinji Ito", "Haipeng Luo"], "title": "Reinforcement Learning from Adversarial Preferences in Tabular MDPs", "categories": ["cs.LG", "stat.ML"], "comment": "40 pages", "summary": "We introduce a new framework of episodic tabular Markov decision processes\n(MDPs) with adversarial preferences, which we refer to as preference-based MDPs\n(PbMDPs). Unlike standard episodic MDPs with adversarial losses, where the\nnumerical value of the loss is directly observed, in PbMDPs the learner instead\nobserves preferences between two candidate arms, which represent the choices\nbeing compared. In this work, we focus specifically on the setting where the\nreward functions are determined by Borda scores. We begin by establishing a\nregret lower bound for PbMDPs with Borda scores. As a preliminary step, we\npresent a simple instance to prove a lower bound of $\\Omega(\\sqrt{HSAT})$ for\nepisodic MDPs with adversarial losses, where $H$ is the number of steps per\nepisode, $S$ is the number of states, $A$ is the number of actions, and $T$ is\nthe number of episodes. Leveraging this construction, we then derive a regret\nlower bound of $\\Omega( (H^2 S K)^{1/3} T^{2/3} )$ for PbMDPs with Borda\nscores, where $K$ is the number of arms. Next, we develop algorithms that\nachieve a regret bound of order $T^{2/3}$. We first propose a global\noptimization approach based on online linear optimization over the set of all\noccupancy measures, achieving a regret bound of $\\tilde{O}((H^2 S^2 K)^{1/3}\nT^{2/3} )$ under known transitions. However, this approach suffers from\nsuboptimal dependence on the potentially large number of states $S$ and\ncomputational inefficiency. To address this, we propose a policy optimization\nalgorithm whose regret is roughly bounded by $\\tilde{O}( (H^6 S K^5)^{1/3}\nT^{2/3} )$ under known transitions, and further extend the result to the\nunknown-transition setting."}
{"id": "2507.12364", "pdf": "https://arxiv.org/pdf/2507.12364", "abs": "https://arxiv.org/abs/2507.12364", "authors": ["Adrien Ghosn", "Charly Castes", "Neelu S. Kalani", "Yuchen Qian", "Marios Kogias", "Edouard Bugnion"], "title": "Rethinking the confidential cloud through a unified low-level abstraction for composable isolation", "categories": ["cs.CR", "cs.OS"], "comment": null, "summary": "Securing sensitive cloud workloads requires composing confidential virtual\nmachines (CVMs) with nested enclaves or sandboxes. Unfortunately, each new\nisolation boundary adds ad-hoc access control mechanisms, hardware extensions,\nand trusted software. This escalating complexity bloats the TCB, complicates\nend-to-end attestation, and leads to fragmentation across platforms and cloud\nservice providers (CSPs).\n  We introduce a unified isolation model that delegates enforceable,\ncomposable, and attestable isolation to a single trusted security monitor:\nTyche. Tyche provides an API for partitioning, sharing, attesting, and\nreclaiming resources through its core abstraction, trust domains (TDs). To\nprovide fine-grain isolation, TDs can recursively create and manage sub-TDs.\nTyche captures these relationships in attestations, allowing cloud tenants to\nreason about end-to-end security. TDs serve as the building blocks for\nconstructing composable enclaves, sandboxes, and CVMs.\n  Tyche runs on commodity x86_64 without hardware security extensions and can\nmaintain backward compatibility with existing software. We provide an SDK to\nrun and compose unmodified workloads as sandboxes, enclaves, and CVMs with\nminimal overhead compared to native Linux execution. Tyche supports complex\ncloud scenarios, such as confidential inference with mutually distrustful\nusers, model owners, and CSPs. An additional RISC-V prototype demonstrates\nTyche's portability across platforms."}
{"id": "2507.11645", "pdf": "https://arxiv.org/pdf/2507.11645", "abs": "https://arxiv.org/abs/2507.11645", "authors": ["Ahmed Salah", "David Yevick"], "title": "Tracing the Path to Grokking: Embeddings, Dropout, and Network Activation", "categories": ["cs.LG", "cs.AI"], "comment": "15 pages, 11 figures", "summary": "Grokking refers to delayed generalization in which the increase in test\naccuracy of a neural network occurs appreciably after the improvement in\ntraining accuracy This paper introduces several practical metrics including\nvariance under dropout, robustness, embedding similarity, and sparsity\nmeasures, that can forecast grokking behavior. Specifically, the resilience of\nneural networks to noise during inference is estimated from a Dropout\nRobustness Curve (DRC) obtained from the variation of the accuracy with the\ndropout rate as the model transitions from memorization to generalization. The\nvariance of the test accuracy under stochastic dropout across training\ncheckpoints further exhibits a local maximum during the grokking. Additionally,\nthe percentage of inactive neurons decreases during generalization, while the\nembeddings tend to a bimodal distribution independent of initialization that\ncorrelates with the observed cosine similarity patterns and dataset symmetries.\nThese metrics additionally provide valuable insight into the origin and\nbehaviour of grokking."}
{"id": "2507.11710", "pdf": "https://arxiv.org/pdf/2507.11710", "abs": "https://arxiv.org/abs/2507.11710", "authors": ["Jay Revolinsky", "Harry Shomer", "Jiliang Tang"], "title": "Subgraph Generation for Generalizing on Out-of-Distribution Links", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 7 figures, preprint", "summary": "Graphs Neural Networks (GNNs) demonstrate high-performance on the link\nprediction (LP) task. However, these models often rely on all dataset samples\nbeing drawn from the same distribution. In addition, graph generative models\n(GGMs) show a pronounced ability to generate novel output graphs. Despite this,\nGGM applications remain largely limited to domain-specific tasks. To bridge\nthis gap, we propose FLEX as a GGM framework which leverages two mechanism: (1)\nstructurally-conditioned graph generation, and (2) adversarial co-training\nbetween an auto-encoder and GNN. As such, FLEX ensures structural-alignment\nbetween sample distributions to enhance link-prediction performance in\nout-of-distribution (OOD) scenarios. Notably, FLEX does not require expert\nknowledge to function in different OOD scenarios. Numerous experiments are\nconducted in synthetic and real-world OOD settings to demonstrate FLEX's\nperformance-enhancing ability, with further analysis for understanding the\neffects of graph data augmentation on link structures. The source code is\navailable here: https://github.com/revolins/FlexOOD."}
{"id": "2507.12456", "pdf": "https://arxiv.org/pdf/2507.12456", "abs": "https://arxiv.org/abs/2507.12456", "authors": ["Omri Shmueli", "Mark Zhandry"], "title": "On One-Shot Signatures, Quantum vs Classical Binding, and Obfuscating Permutations", "categories": ["cs.CR", "quant-ph"], "comment": null, "summary": "One-shot signatures (OSS) were defined by Amos, Georgiou, Kiayias, and\nZhandry (STOC'20). These allow for signing exactly one message, after which the\nsigning key self-destructs, preventing a second message from ever being signed.\nWhile such an object is impossible classically, Amos et al observe that OSS may\nbe possible using quantum signing keys by leveraging the no-cloning principle.\nOSS has since become an important conceptual tool with many applications in\ndecentralized settings and for quantum cryptography with classical\ncommunication. OSS are also closely related to separations between\nclassical-binding and collapse-binding for post-quantum hashing and\ncommitments. Unfortunately, the only known OSS construction due to Amos et al.\nwas only justified in a classical oracle model, and moreover their\njustification was ultimately found to contain a fatal bug. Thus, the existence\nof OSS, even in a classical idealized model, has remained open.\n  We give the first standard-model OSS, with provable security assuming\n(sub-exponential) indistinguishability obfuscation (iO) and LWE. This also\ngives the first standard-model separation between classical and\ncollapse-binding post-quantum commitments/hashing, solving a decade-old open\nproblem. Along the way, we also give the first construction with unconditional\nsecurity relative to a classical oracle. To achieve our standard-model\nconstruction, we develop a notion of permutable pseudorandom permutations\n(permutable PRPs), and show how they are useful for translating oracle proofs\ninvolving random permutations into obfuscation-based proofs. In particular,\nobfuscating permutable PRPs gives a trapdoor one-way permutation that is\n\\emph{full-domain}, solving another decade-old-problem of constructing this\nobject from (sub-exponential) iO and one-way functions."}
{"id": "2507.11702", "pdf": "https://arxiv.org/pdf/2507.11702", "abs": "https://arxiv.org/abs/2507.11702", "authors": ["Hein de Wilde", "Ali Mohammed Mansoor Alsahag", "Pierre Blanchet"], "title": "Time series classification of satellite data using LSTM networks: an approach for predicting leaf-fall to minimize railroad traffic disruption", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Railroad traffic disruption as a result of leaf-fall cost the UK rail\nindustry over 300 million per year and measures to mitigate such disruptions\nare employed on a large scale, with 1.67 million kilometers of track being\ntreated in the UK in 2021 alone. Therefore, the ability to anticipate the\ntiming of leaf-fall would offer substantial benefits for rail network\noperators, enabling the efficient scheduling of such mitigation measures.\nHowever, current methodologies for predicting leaf-fall exhibit considerable\nlimitations in terms of scalability and reliability. This study endeavors to\ndevise a prediction system that leverages specialized prediction methods and\nthe latest satellite data sources to generate both scalable and reliable\ninsights into leaf-fall timings. An LSTM network trained on ground-truth\nleaf-falling data combined with multispectral and meteorological satellite data\ndemonstrated a root-mean-square error of 6.32 days for predicting the start of\nleaf-fall and 9.31 days for predicting the end of leaf-fall. The model, which\nimproves upon previous work on the topic, offers promising opportunities for\nthe optimization of leaf mitigation measures in the railway industry and the\nimprovement of our understanding of complex ecological systems."}
{"id": "2507.11729", "pdf": "https://arxiv.org/pdf/2507.11729", "abs": "https://arxiv.org/abs/2507.11729", "authors": ["Amirhossein Ahmadi", "Hamidreza Zareipour", "Henry Leung"], "title": "Globalization for Scalable Short-term Load Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "63 pages with 22 figures", "summary": "Forecasting load in power transmission networks is essential across various\nhierarchical levels, from the system level down to individual points of\ndelivery (PoD). While intuitive and locally accurate, traditional local\nforecasting models (LFMs) face significant limitations, particularly in\nhandling generalizability, overfitting, data drift, and the cold start problem.\nThese methods also struggle with scalability, becoming computationally\nexpensive and less efficient as the network's size and data volume grow. In\ncontrast, global forecasting models (GFMs) offer a new approach to enhance\nprediction generalizability, scalability, accuracy, and robustness through\nglobalization and cross-learning. This paper investigates global load\nforecasting in the presence of data drifts, highlighting the impact of\ndifferent modeling techniques and data heterogeneity. We explore\nfeature-transforming and target-transforming models, demonstrating how\nglobalization, data heterogeneity, and data drift affect each differently. In\naddition, we examine the role of globalization in peak load forecasting and its\npotential for hierarchical forecasting. To address data heterogeneity and the\nbalance between globality and locality, we propose separate time series\nclustering (TSC) methods, introducing model-based TSC for feature-transforming\nmodels and new weighted instance-based TSC for target-transforming models.\nThrough extensive experiments on a real-world dataset of Alberta's electricity\nload, we demonstrate that global target-transforming models consistently\noutperform their local counterparts, especially when enriched with global\nfeatures and clustering techniques. In contrast, global feature-transforming\nmodels face challenges in balancing local and global dynamics, often requiring\nTSC to manage data heterogeneity effectively."}
{"id": "2507.12314", "pdf": "https://arxiv.org/pdf/2507.12314", "abs": "https://arxiv.org/abs/2507.12314", "authors": ["Zihao Xue", "Zhen Bi", "Long Ma", "Zhenlin Hu", "Yan Wang", "Zhenfang Liu", "Qing Sheng", "Jie Xiao", "Jungang Lou"], "title": "Thought Purity: Defense Paradigm For Chain-of-Thought Attack", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.CR"], "comment": null, "summary": "While reinforcement learning-trained Large Reasoning Models (LRMs, e.g.,\nDeepseek-R1) demonstrate advanced reasoning capabilities in the evolving Large\nLanguage Models (LLMs) domain, their susceptibility to security threats remains\na critical vulnerability. This weakness is particularly evident in\nChain-of-Thought (CoT) generation processes, where adversarial methods like\nbackdoor prompt attacks can systematically subvert the model's core reasoning\nmechanisms. The emerging Chain-of-Thought Attack (CoTA) reveals this\nvulnerability through exploiting prompt controllability, simultaneously\ndegrading both CoT safety and task performance with low-cost interventions. To\naddress this compounded security-performance vulnerability, we propose Thought\nPurity (TP): a defense paradigm that systematically strengthens resistance to\nmalicious content while preserving operational efficacy. Our solution achieves\nthis through three synergistic components: (1) a safety-optimized data\nprocessing pipeline (2) reinforcement learning-enhanced rule constraints (3)\nadaptive monitoring metrics. Our approach establishes the first comprehensive\ndefense mechanism against CoTA vulnerabilities in reinforcement\nlearning-aligned reasoning systems, significantly advancing the\nsecurity-functionality equilibrium for next-generation AI architectures."}
{"id": "2507.11710", "pdf": "https://arxiv.org/pdf/2507.11710", "abs": "https://arxiv.org/abs/2507.11710", "authors": ["Jay Revolinsky", "Harry Shomer", "Jiliang Tang"], "title": "Subgraph Generation for Generalizing on Out-of-Distribution Links", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 7 figures, preprint", "summary": "Graphs Neural Networks (GNNs) demonstrate high-performance on the link\nprediction (LP) task. However, these models often rely on all dataset samples\nbeing drawn from the same distribution. In addition, graph generative models\n(GGMs) show a pronounced ability to generate novel output graphs. Despite this,\nGGM applications remain largely limited to domain-specific tasks. To bridge\nthis gap, we propose FLEX as a GGM framework which leverages two mechanism: (1)\nstructurally-conditioned graph generation, and (2) adversarial co-training\nbetween an auto-encoder and GNN. As such, FLEX ensures structural-alignment\nbetween sample distributions to enhance link-prediction performance in\nout-of-distribution (OOD) scenarios. Notably, FLEX does not require expert\nknowledge to function in different OOD scenarios. Numerous experiments are\nconducted in synthetic and real-world OOD settings to demonstrate FLEX's\nperformance-enhancing ability, with further analysis for understanding the\neffects of graph data augmentation on link structures. The source code is\navailable here: https://github.com/revolins/FlexOOD."}
{"id": "2507.11732", "pdf": "https://arxiv.org/pdf/2507.11732", "abs": "https://arxiv.org/abs/2507.11732", "authors": ["Shiyu Chen", "Cencheng Shen", "Youngser Park", "Carey E. Priebe"], "title": "Graph Neural Networks Powered by Encoder Embedding for Improved Node Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Graph neural networks (GNNs) have emerged as a powerful framework for a wide\nrange of node-level graph learning tasks. However, their performance is often\nconstrained by reliance on random or minimally informed initial feature\nrepresentations, which can lead to slow convergence and suboptimal solutions.\nIn this paper, we leverage a statistically grounded method, one-hot graph\nencoder embedding (GEE), to generate high-quality initial node features that\nenhance the end-to-end training of GNNs. We refer to this integrated framework\nas the GEE-powered GNN (GG), and demonstrate its effectiveness through\nextensive simulations and real-world experiments across both unsupervised and\nsupervised settings. In node clustering, GG consistently achieves\nstate-of-the-art performance, ranking first across all evaluated real-world\ndatasets, while exhibiting faster convergence compared to the standard GNN. For\nnode classification, we further propose an enhanced variant, GG-C, which\nconcatenates the outputs of GG and GEE and outperforms competing baselines.\nThese results confirm the importance of principled, structure-aware feature\ninitialization in realizing the full potential of GNNs."}
{"id": "2507.12439", "pdf": "https://arxiv.org/pdf/2507.12439", "abs": "https://arxiv.org/abs/2507.12439", "authors": ["Daniel Commey", "Rebecca A. Sarpong", "Griffith S. Klogo", "Winful Bagyl-Bac", "Garth V. Crosby"], "title": "A Bayesian Incentive Mechanism for Poison-Resilient Federated Learning", "categories": ["cs.LG", "cs.CR", "cs.GT"], "comment": null, "summary": "Federated learning (FL) enables collaborative model training across\ndecentralized clients while preserving data privacy. However, its\nopen-participation nature exposes it to data-poisoning attacks, in which\nmalicious actors submit corrupted model updates to degrade the global model.\nExisting defenses are often reactive, relying on statistical aggregation rules\nthat can be computationally expensive and that typically assume an honest\nmajority. This paper introduces a proactive, economic defense: a lightweight\nBayesian incentive mechanism that makes malicious behavior economically\nirrational. Each training round is modeled as a Bayesian game of incomplete\ninformation in which the server, acting as the principal, uses a small, private\nvalidation dataset to verify update quality before issuing payments. The design\nsatisfies Individual Rationality (IR) for benevolent clients, ensuring their\nparticipation is profitable, and Incentive Compatibility (IC), making poisoning\nan economically dominated strategy. Extensive experiments on non-IID partitions\nof MNIST and FashionMNIST demonstrate robustness: with 50% label-flipping\nadversaries on MNIST, the mechanism maintains 96.7% accuracy, only 0.3\npercentage points lower than in a scenario with 30% label-flipping adversaries.\nThis outcome is 51.7 percentage points better than standard FedAvg, which\ncollapses under the same 50% attack. The mechanism is computationally light,\nbudget-bounded, and readily integrates into existing FL frameworks, offering a\npractical route to economically robust and sustainable FL ecosystems."}
{"id": "2507.11729", "pdf": "https://arxiv.org/pdf/2507.11729", "abs": "https://arxiv.org/abs/2507.11729", "authors": ["Amirhossein Ahmadi", "Hamidreza Zareipour", "Henry Leung"], "title": "Globalization for Scalable Short-term Load Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": "63 pages with 22 figures", "summary": "Forecasting load in power transmission networks is essential across various\nhierarchical levels, from the system level down to individual points of\ndelivery (PoD). While intuitive and locally accurate, traditional local\nforecasting models (LFMs) face significant limitations, particularly in\nhandling generalizability, overfitting, data drift, and the cold start problem.\nThese methods also struggle with scalability, becoming computationally\nexpensive and less efficient as the network's size and data volume grow. In\ncontrast, global forecasting models (GFMs) offer a new approach to enhance\nprediction generalizability, scalability, accuracy, and robustness through\nglobalization and cross-learning. This paper investigates global load\nforecasting in the presence of data drifts, highlighting the impact of\ndifferent modeling techniques and data heterogeneity. We explore\nfeature-transforming and target-transforming models, demonstrating how\nglobalization, data heterogeneity, and data drift affect each differently. In\naddition, we examine the role of globalization in peak load forecasting and its\npotential for hierarchical forecasting. To address data heterogeneity and the\nbalance between globality and locality, we propose separate time series\nclustering (TSC) methods, introducing model-based TSC for feature-transforming\nmodels and new weighted instance-based TSC for target-transforming models.\nThrough extensive experiments on a real-world dataset of Alberta's electricity\nload, we demonstrate that global target-transforming models consistently\noutperform their local counterparts, especially when enriched with global\nfeatures and clustering techniques. In contrast, global feature-transforming\nmodels face challenges in balancing local and global dynamics, often requiring\nTSC to manage data heterogeneity effectively."}
{"id": "2507.11739", "pdf": "https://arxiv.org/pdf/2507.11739", "abs": "https://arxiv.org/abs/2507.11739", "authors": ["Urban Fasel"], "title": "Sparse Identification of Nonlinear Dynamics with Conformal Prediction", "categories": ["cs.LG", "cs.CE", "math.DS"], "comment": null, "summary": "The Sparse Identification of Nonlinear Dynamics (SINDy) is a method for\ndiscovering nonlinear dynamical system models from data. Quantifying\nuncertainty in SINDy models is essential for assessing their reliability,\nparticularly in safety-critical applications. While various uncertainty\nquantification methods exist for SINDy, including Bayesian and ensemble\napproaches, this work explores the integration of Conformal Prediction, a\nframework that can provide valid prediction intervals with coverage guarantees\nbased on minimal assumptions like data exchangeability. We introduce three\napplications of conformal prediction with Ensemble-SINDy (E-SINDy): (1)\nquantifying uncertainty in time series prediction, (2) model selection based on\nlibrary feature importance, and (3) quantifying the uncertainty of identified\nmodel coefficients using feature conformal prediction. We demonstrate the three\napplications on stochastic predator-prey dynamics and several chaotic dynamical\nsystems. We show that conformal prediction methods integrated with E-SINDy can\nreliably achieve desired target coverage for time series forecasting,\neffectively quantify feature importance, and produce more robust uncertainty\nintervals for model coefficients, even under non-Gaussian noise, compared to\nstandard E-SINDy coefficient estimates."}
{"id": "2507.11775", "pdf": "https://arxiv.org/pdf/2507.11775", "abs": "https://arxiv.org/abs/2507.11775", "authors": ["Wesley dos Reis Bezerra", "Lais Machado Bezerra", "Carlos Becker Westphall"], "title": "Challenges in GenAI and Authentication: a scoping review", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Authentication and authenticity have been a security challenge since the\nbeginning of information sharing, especially in the context of digital\ninformation. With the advancement of generative artificial intelligence, these\nchallenges have evolved, demanding a more up-to-date analysis of their impacts\non society and system security. This work presents a scoping review that\nanalyzed 88 documents from the IEEExplorer, Scopus, and ACM databases,\npromoting an analysis of the resulting portfolio through six guiding questions\nfocusing on the most relevant work, challenges, attack surfaces, threats,\nproposed solutions, and gaps. Finally, the portfolio articles are analyzed\nthrough this guiding research lens and also receive individualized analysis.\nThe results consistently outline the challenges, gaps, and threats related to\nimages, text, audio, and video, thereby supporting new research in the areas of\nauthentication and generative artificial intelligence."}
{"id": "2507.11757", "pdf": "https://arxiv.org/pdf/2507.11757", "abs": "https://arxiv.org/abs/2507.11757", "authors": ["Yuehua Song", "Yong Gao"], "title": "A Graph-in-Graph Learning Framework for Drug-Target Interaction Prediction", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Accurately predicting drug-target interactions (DTIs) is pivotal for\nadvancing drug discovery and target validation techniques. While machine\nlearning approaches including those that are based on Graph Neural Networks\n(GNN) have achieved notable success in DTI prediction, many of them have\ndifficulties in effectively integrating the diverse features of drugs, targets\nand their interactions. To address this limitation, we introduce a novel\nframework to take advantage of the power of both transductive learning and\ninductive learning so that features at molecular level and drug-target\ninteraction network level can be exploited. Within this framework is a\nGNN-based model called Graph-in-Graph (GiG) that represents graphs of drug and\ntarget molecular structures as meta-nodes in a drug-target interaction graph,\nenabling a detailed exploration of their intricate relationships. To evaluate\nthe proposed model, we have compiled a special benchmark comprising drug\nSMILES, protein sequences, and their interaction data, which is interesting in\nits own right. Our experimental results demonstrate that the GiG model\nsignificantly outperforms existing approaches across all evaluation metrics,\nhighlighting the benefits of integrating different learning paradigms and\ninteraction data."}
{"id": "2507.11776", "pdf": "https://arxiv.org/pdf/2507.11776", "abs": "https://arxiv.org/abs/2507.11776", "authors": ["Merel Kampere", "Ali Mohammed Mansoor Alsahag"], "title": "Predicting Delayed Trajectories Using Network Features: A Study on the Dutch Railway Network", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The Dutch railway network is one of the busiest in the world, with delays\nbeing a prominent concern for the principal passenger railway operator NS. This\nresearch addresses a gap in delay prediction studies within the Dutch railway\nnetwork by employing an XGBoost Classifier with a focus on topological\nfeatures. Current research predominantly emphasizes short-term predictions and\nneglects the broader network-wide patterns essential for mitigating ripple\neffects. This research implements and improves an existing methodology,\noriginally designed to forecast the evolution of the fast-changing US air\nnetwork, to predict delays in the Dutch Railways. By integrating Node\nCentrality Measures and comparing multiple classifiers like RandomForest,\nDecisionTree, GradientBoosting, AdaBoost, and LogisticRegression, the goal is\nto predict delayed trajectories. However, the results reveal limited\nperformance, especially in non-simultaneous testing scenarios, suggesting the\nnecessity for more context-specific adaptations. Regardless, this research\ncontributes to the understanding of transportation network evaluation and\nproposes future directions for developing more robust predictive models for\ndelays."}
{"id": "2507.11759", "pdf": "https://arxiv.org/pdf/2507.11759", "abs": "https://arxiv.org/abs/2507.11759", "authors": ["Alexandra Volokhova", "Léna Néhale Ezzine", "Piotr Gaiński", "Luca Scimeca", "Emmanuel Bengio", "Prudencio Tossou", "Yoshua Bengio", "Alex Hernandez-Garcia"], "title": "Torsional-GFN: a conditional conformation generator for small molecules", "categories": ["cs.LG"], "comment": "The two first authors are Alexandra Volokhova and L\\'ena N\\'ehale\n  Ezzine, with equal contribution", "summary": "Generating stable molecular conformations is crucial in several drug\ndiscovery applications, such as estimating the binding affinity of a molecule\nto a target. Recently, generative machine learning methods have emerged as a\npromising, more efficient method than molecular dynamics for sampling of\nconformations from the Boltzmann distribution. In this paper, we introduce\nTorsional-GFN, a conditional GFlowNet specifically designed to sample\nconformations of molecules proportionally to their Boltzmann distribution,\nusing only a reward function as training signal. Conditioned on a molecular\ngraph and its local structure (bond lengths and angles), Torsional-GFN samples\nrotations of its torsion angles. Our results demonstrate that Torsional-GFN is\nable to sample conformations approximately proportional to the Boltzmann\ndistribution for multiple molecules with a single model, and allows for\nzero-shot generalization to unseen bond lengths and angles coming from the MD\nsimulations for such molecules. Our work presents a promising avenue for\nscaling the proposed approach to larger molecular systems, achieving zero-shot\ngeneralization to unseen molecules, and including the generation of the local\nstructure into the GFlowNet model."}
{"id": "2507.11807", "pdf": "https://arxiv.org/pdf/2507.11807", "abs": "https://arxiv.org/abs/2507.11807", "authors": ["Ruofan Hu", "Dongyu Zhang", "Huayi Zhang", "Elke Rundensteiner"], "title": "CLID-MU: Cross-Layer Information Divergence Based Meta Update Strategy for Learning with Noisy Labels", "categories": ["cs.LG", "cs.AI"], "comment": "KDD 2025, 12 pages, 7 figures", "summary": "Learning with noisy labels (LNL) is essential for training deep neural\nnetworks with imperfect data. Meta-learning approaches have achieved success by\nusing a clean unbiased labeled set to train a robust model. However, this\napproach heavily depends on the availability of a clean labeled meta-dataset,\nwhich is difficult to obtain in practice. In this work, we thus tackle the\nchallenge of meta-learning for noisy label scenarios without relying on a clean\nlabeled dataset. Our approach leverages the data itself while bypassing the\nneed for labels. Building on the insight that clean samples effectively\npreserve the consistency of related data structures across the last hidden and\nthe final layer, whereas noisy samples disrupt this consistency, we design the\nCross-layer Information Divergence-based Meta Update Strategy (CLID-MU).\nCLID-MU leverages the alignment of data structures across these diverse feature\nspaces to evaluate model performance and use this alignment to guide training.\nExperiments on benchmark datasets with varying amounts of labels under both\nsynthetic and real-world noise demonstrate that CLID-MU outperforms\nstate-of-the-art methods. The code is released at\nhttps://github.com/ruofanhu/CLID-MU."}
{"id": "2507.11771", "pdf": "https://arxiv.org/pdf/2507.11771", "abs": "https://arxiv.org/abs/2507.11771", "authors": ["Sheikh Abdur Raheem Ali", "Justin Xu", "Ivory Yang", "Jasmine Xinze Li", "Ayse Arslan", "Clark Benham"], "title": "Scaling laws for activation steering with Llama 2 models and refusal mechanisms", "categories": ["cs.LG"], "comment": null, "summary": "As large language models (LLMs) evolve in complexity and capability, the\nefficacy of less widely deployed alignment techniques are uncertain. Building\non previous work on activation steering and contrastive activation addition\n(CAA), this paper explores the effectiveness of CAA with model scale using the\nfamily of Llama 2 models (7B, 13B, and 70B). CAA works by finding desirable\n'directions' in the model's residual stream vector space using contrastive\npairs (for example, hate to love) and adding this direction to the residual\nstream during the forward pass. It directly manipulates the residual stream and\naims to extract features from language models to better control their outputs.\nUsing answer matching questions centered around the refusal behavior, we found\nthat 1) CAA is most effective when applied at early-mid layers. 2) The\neffectiveness of CAA diminishes with model size. 3) Negative steering has more\npronounced effects than positive steering across all model sizes."}
{"id": "2507.11821", "pdf": "https://arxiv.org/pdf/2507.11821", "abs": "https://arxiv.org/abs/2507.11821", "authors": ["Pouya Shaeri", "Arash Karimi", "Ariane Middel"], "title": "MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.HC"], "comment": "Submitted to a computer science conference", "summary": "Neural networks are often benchmarked using standard datasets such as MNIST,\nFashionMNIST, or other variants of MNIST, which, while accessible, are limited\nto generic classes such as digits or clothing items. For researchers working on\ndomain-specific tasks, such as classifying trees, food items, or other\nreal-world objects, these data sets are insufficient and irrelevant.\nAdditionally, creating and publishing a custom dataset can be time consuming,\nlegally constrained, or beyond the scope of individual projects. We present\nMNIST-Gen, an automated, modular, and adaptive framework for generating\nMNIST-style image datasets tailored to user-specified categories using\nhierarchical semantic categorization. The system combines CLIP-based semantic\nunderstanding with reinforcement learning and human feedback to achieve\nintelligent categorization with minimal manual intervention. Our hierarchical\napproach supports complex category structures with semantic characteristics,\nenabling fine-grained subcategorization and multiple processing modes:\nindividual review for maximum control, smart batch processing for large\ndatasets, and fast batch processing for rapid creation. Inspired by category\ntheory, MNIST-Gen models each data transformation stage as a composable\nmorphism, enhancing clarity, modularity, and extensibility. As proof of\nconcept, we generate and benchmark two novel datasets-\\textit{Tree-MNIST} and\n\\textit{Food-MNIST}-demonstrating MNIST-Gen's utility for producing\ntask-specific evaluation data while achieving 85\\% automatic categorization\naccuracy and 80\\% time savings compared to manual approaches."}
{"id": "2507.11776", "pdf": "https://arxiv.org/pdf/2507.11776", "abs": "https://arxiv.org/abs/2507.11776", "authors": ["Merel Kampere", "Ali Mohammed Mansoor Alsahag"], "title": "Predicting Delayed Trajectories Using Network Features: A Study on the Dutch Railway Network", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The Dutch railway network is one of the busiest in the world, with delays\nbeing a prominent concern for the principal passenger railway operator NS. This\nresearch addresses a gap in delay prediction studies within the Dutch railway\nnetwork by employing an XGBoost Classifier with a focus on topological\nfeatures. Current research predominantly emphasizes short-term predictions and\nneglects the broader network-wide patterns essential for mitigating ripple\neffects. This research implements and improves an existing methodology,\noriginally designed to forecast the evolution of the fast-changing US air\nnetwork, to predict delays in the Dutch Railways. By integrating Node\nCentrality Measures and comparing multiple classifiers like RandomForest,\nDecisionTree, GradientBoosting, AdaBoost, and LogisticRegression, the goal is\nto predict delayed trajectories. However, the results reveal limited\nperformance, especially in non-simultaneous testing scenarios, suggesting the\nnecessity for more context-specific adaptations. Regardless, this research\ncontributes to the understanding of transportation network evaluation and\nproposes future directions for developing more robust predictive models for\ndelays."}
{"id": "2507.11943", "pdf": "https://arxiv.org/pdf/2507.11943", "abs": "https://arxiv.org/abs/2507.11943", "authors": ["Haiwei Lin", "Shoko Imaizumi", "Hitoshi Kiya"], "title": "Effective Fine-Tuning of Vision Transformers with Low-Rank Adaptation for Privacy-Preserving Image Classification", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": "3 pages, 3 figures, conference", "summary": "We propose a low-rank adaptation method for training privacy-preserving\nvision transformer (ViT) models that efficiently freezes pre-trained ViT model\nweights. In the proposed method, trainable rank decomposition matrices are\ninjected into each layer of the ViT architecture, and moreover, the patch\nembedding layer is not frozen, unlike in the case of the conventional low-rank\nadaptation methods. The proposed method allows us not only to reduce the number\nof trainable parameters but to also maintain almost the same accuracy as that\nof full-time tuning."}
{"id": "2507.11789", "pdf": "https://arxiv.org/pdf/2507.11789", "abs": "https://arxiv.org/abs/2507.11789", "authors": ["Alessandro Palma", "Sergei Rybakov", "Leon Hetzel", "Stephan Günnemann", "Fabian J. Theis"], "title": "Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation", "categories": ["cs.LG", "q-bio.QM"], "comment": "31 pages, 14 figures", "summary": "Latent space interpolations are a powerful tool for navigating deep\ngenerative models in applied settings. An example is single-cell RNA\nsequencing, where existing methods model cellular state transitions as latent\nspace interpolations with variational autoencoders, often assuming linear\nshifts and Euclidean geometry. However, unless explicitly enforced, linear\ninterpolations in the latent space may not correspond to geodesic paths on the\ndata manifold, limiting methods that assume Euclidean geometry in the data\nrepresentations. We introduce FlatVI, a novel training framework that\nregularises the latent manifold of discrete-likelihood variational autoencoders\ntowards Euclidean geometry, specifically tailored for modelling single-cell\ncount data. By encouraging straight lines in the latent space to approximate\ngeodesic interpolations on the decoded single-cell manifold, FlatVI enhances\ncompatibility with downstream approaches that assume Euclidean latent geometry.\nExperiments on synthetic data support the theoretical soundness of our\napproach, while applications to time-resolved single-cell RNA sequencing data\ndemonstrate improved trajectory reconstruction and manifold interpolation."}
{"id": "2507.11948", "pdf": "https://arxiv.org/pdf/2507.11948", "abs": "https://arxiv.org/abs/2507.11948", "authors": ["Carlo Baronio", "Pietro Marsella", "Ben Pan", "Simon Guo", "Silas Alberti"], "title": "Kevin: Multi-Turn RL for Generating CUDA Kernels", "categories": ["cs.LG", "cs.AI", "cs.PF", "cs.SE"], "comment": null, "summary": "Writing GPU kernels is a challenging task and critical for AI systems'\nefficiency. It is also highly iterative: domain experts write code and improve\nperformance through execution feedback. Moreover, it presents verifiable\nrewards like correctness and speedup, making it a natural environment to apply\nReinforcement Learning (RL). To explicitly incorporate the iterative nature of\nthis process into training, we develop a flexible multi-turn RL recipe that\naddresses unique challenges encountered in real-world settings, such as\nlearning from long trajectories and effective reward attribution across turns.\nWe present Kevin - K(ernel D)evin, the first model trained with multi-turn RL\nfor CUDA kernel generation and optimization. In our evaluation setup, Kevin\nshows significant gains over its base model (QwQ-32B), improving correctness of\ngenerated kernels (in pure CUDA) from 56% to 82% and mean speedup from 0.53x to\n1.10x of baseline (PyTorch Eager), and surpassing frontier models like o4-mini\n(0.78x). Finally, we study its behavior across test-time scaling axes: we found\nscaling serial refinement more beneficial than parallel sampling. In\nparticular, when given more refinement turns, Kevin shows a higher rate of\nimprovement."}
{"id": "2507.11807", "pdf": "https://arxiv.org/pdf/2507.11807", "abs": "https://arxiv.org/abs/2507.11807", "authors": ["Ruofan Hu", "Dongyu Zhang", "Huayi Zhang", "Elke Rundensteiner"], "title": "CLID-MU: Cross-Layer Information Divergence Based Meta Update Strategy for Learning with Noisy Labels", "categories": ["cs.LG", "cs.AI"], "comment": "KDD 2025, 12 pages, 7 figures", "summary": "Learning with noisy labels (LNL) is essential for training deep neural\nnetworks with imperfect data. Meta-learning approaches have achieved success by\nusing a clean unbiased labeled set to train a robust model. However, this\napproach heavily depends on the availability of a clean labeled meta-dataset,\nwhich is difficult to obtain in practice. In this work, we thus tackle the\nchallenge of meta-learning for noisy label scenarios without relying on a clean\nlabeled dataset. Our approach leverages the data itself while bypassing the\nneed for labels. Building on the insight that clean samples effectively\npreserve the consistency of related data structures across the last hidden and\nthe final layer, whereas noisy samples disrupt this consistency, we design the\nCross-layer Information Divergence-based Meta Update Strategy (CLID-MU).\nCLID-MU leverages the alignment of data structures across these diverse feature\nspaces to evaluate model performance and use this alignment to guide training.\nExperiments on benchmark datasets with varying amounts of labels under both\nsynthetic and real-world noise demonstrate that CLID-MU outperforms\nstate-of-the-art methods. The code is released at\nhttps://github.com/ruofanhu/CLID-MU."}
{"id": "2507.11975", "pdf": "https://arxiv.org/pdf/2507.11975", "abs": "https://arxiv.org/abs/2507.11975", "authors": ["Valentin Frank Ingmar Guenter", "Athanasios Sideris"], "title": "Online Training and Pruning of Deep Reinforcement Learning Networks", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "25 pages, 5 figures, 4 tables", "summary": "Scaling deep neural networks (NN) of reinforcement learning (RL) algorithms\nhas been shown to enhance performance when feature extraction networks are used\nbut the gained performance comes at the significant expense of increased\ncomputational and memory complexity. Neural network pruning methods have\nsuccessfully addressed this challenge in supervised learning. However, their\napplication to RL is underexplored. We propose an approach to integrate\nsimultaneous training and pruning within advanced RL methods, in particular to\nRL algorithms enhanced by the Online Feature Extractor Network (OFENet). Our\nnetworks (XiNet) are trained to solve stochastic optimization problems over the\nRL networks' weights and the parameters of variational Bernoulli distributions\nfor 0/1 Random Variables $\\xi$ scaling each unit in the networks. The\nstochastic problem formulation induces regularization terms that promote\nconvergence of the variational parameters to 0 when a unit contributes little\nto the performance. In this case, the corresponding structure is rendered\npermanently inactive and pruned from its network. We propose a cost-aware,\nsparsity-promoting regularization scheme, tailored to the DenseNet architecture\nof OFENets expressing the parameter complexity of involved networks in terms of\nthe parameters of the RVs in these networks. Then, when matching this cost with\nthe regularization terms, the many hyperparameters associated with them are\nautomatically selected, effectively combining the RL objectives and network\ncompression. We evaluate our method on continuous control benchmarks (MuJoCo)\nand the Soft Actor-Critic RL agent, demonstrating that OFENets can be pruned\nconsiderably with minimal loss in performance. Furthermore, our results confirm\nthat pruning large networks during training produces more efficient and higher\nperforming RL agents rather than training smaller networks from scratch."}
{"id": "2507.11818", "pdf": "https://arxiv.org/pdf/2507.11818", "abs": "https://arxiv.org/abs/2507.11818", "authors": ["Andrei Rekesh", "Miruna Cretu", "Dmytro Shevchuk", "Vignesh Ram Somnath", "Pietro Liò", "Robert A. Batey", "Mike Tyers", "Michał Koziarski", "Cheng-Hao Liu"], "title": "SynCoGen: Synthesizable 3D Molecule Generation via Joint Reaction and Coordinate Modeling", "categories": ["cs.LG"], "comment": null, "summary": "Ensuring synthesizability in generative small molecule design remains a major\nchallenge. While recent developments in synthesizable molecule generation have\ndemonstrated promising results, these efforts have been largely confined to 2D\nmolecular graph representations, limiting the ability to perform geometry-based\nconditional generation. In this work, we present SynCoGen (Synthesizable\nCo-Generation), a single framework that combines simultaneous masked graph\ndiffusion and flow matching for synthesizable 3D molecule generation. SynCoGen\nsamples from the joint distribution of molecular building blocks, chemical\nreactions, and atomic coordinates. To train the model, we curated SynSpace, a\ndataset containing over 600K synthesis-aware building block graphs and 3.3M\nconformers. SynCoGen achieves state-of-the-art performance in unconditional\nsmall molecule graph and conformer generation, and the model delivers\ncompetitive performance in zero-shot molecular linker design for protein ligand\ngeneration in drug discovery. Overall, this multimodal formulation represents a\nfoundation for future applications enabled by non-autoregressive molecular\ngeneration, including analog expansion, lead optimization, and direct structure\nconditioning."}
{"id": "2507.11997", "pdf": "https://arxiv.org/pdf/2507.11997", "abs": "https://arxiv.org/abs/2507.11997", "authors": ["Tairan Huang", "Yili Wang"], "title": "Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph fraud detection has garnered significant attention as Graph Neural\nNetworks (GNNs) have proven effective in modeling complex relationships within\nmultimodal data. However, existing graph fraud detection methods typically use\npreprocessed node embeddings and predefined graph structures to reveal\nfraudsters, which ignore the rich semantic cues contained in raw textual\ninformation. Although Large Language Models (LLMs) exhibit powerful\ncapabilities in processing textual information, it remains a significant\nchallenge to perform multimodal fusion of processed textual embeddings with\ngraph structures. In this paper, we propose a \\textbf{M}ulti-level \\textbf{L}LM\n\\textbf{E}nhanced Graph Fraud \\textbf{D}etection framework called MLED. In\nMLED, we utilize LLMs to extract external knowledge from textual information to\nenhance graph fraud detection methods. To integrate LLMs with graph structure\ninformation and enhance the ability to distinguish fraudsters, we design a\nmulti-level LLM enhanced framework including type-level enhancer and\nrelation-level enhancer. One is to enhance the difference between the\nfraudsters and the benign entities, the other is to enhance the importance of\nthe fraudsters in different relations. The experiments on four real-world\ndatasets show that MLED achieves state-of-the-art performance in graph fraud\ndetection as a generalized framework that can be applied to existing methods."}
{"id": "2507.11821", "pdf": "https://arxiv.org/pdf/2507.11821", "abs": "https://arxiv.org/abs/2507.11821", "authors": ["Pouya Shaeri", "Arash Karimi", "Ariane Middel"], "title": "MNIST-Gen: A Modular MNIST-Style Dataset Generation Using Hierarchical Semantics, Reinforcement Learning, and Category Theory", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.HC"], "comment": "Submitted to a computer science conference", "summary": "Neural networks are often benchmarked using standard datasets such as MNIST,\nFashionMNIST, or other variants of MNIST, which, while accessible, are limited\nto generic classes such as digits or clothing items. For researchers working on\ndomain-specific tasks, such as classifying trees, food items, or other\nreal-world objects, these data sets are insufficient and irrelevant.\nAdditionally, creating and publishing a custom dataset can be time consuming,\nlegally constrained, or beyond the scope of individual projects. We present\nMNIST-Gen, an automated, modular, and adaptive framework for generating\nMNIST-style image datasets tailored to user-specified categories using\nhierarchical semantic categorization. The system combines CLIP-based semantic\nunderstanding with reinforcement learning and human feedback to achieve\nintelligent categorization with minimal manual intervention. Our hierarchical\napproach supports complex category structures with semantic characteristics,\nenabling fine-grained subcategorization and multiple processing modes:\nindividual review for maximum control, smart batch processing for large\ndatasets, and fast batch processing for rapid creation. Inspired by category\ntheory, MNIST-Gen models each data transformation stage as a composable\nmorphism, enhancing clarity, modularity, and extensibility. As proof of\nconcept, we generate and benchmark two novel datasets-\\textit{Tree-MNIST} and\n\\textit{Food-MNIST}-demonstrating MNIST-Gen's utility for producing\ntask-specific evaluation data while achieving 85\\% automatic categorization\naccuracy and 80\\% time savings compared to manual approaches."}
{"id": "2507.12011", "pdf": "https://arxiv.org/pdf/2507.12011", "abs": "https://arxiv.org/abs/2507.12011", "authors": ["Yao Lu", "Hongyu Gao", "Zhuangzhi Chen", "Dongwei Xu", "Yun Lin", "Qi Xuan", "Guan Gui"], "title": "DUSE: A Data Expansion Framework for Low-resource Automatic Modulation Recognition based on Active Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Although deep neural networks have made remarkable achievements in the field\nof automatic modulation recognition (AMR), these models often require a large\namount of labeled data for training. However, in many practical scenarios, the\navailable target domain data is scarce and difficult to meet the needs of model\ntraining. The most direct way is to collect data manually and perform expert\nannotation, but the high time and labor costs are unbearable. Another common\nmethod is data augmentation. Although it can enrich training samples to a\ncertain extent, it does not introduce new data and therefore cannot\nfundamentally solve the problem of data scarcity. To address these challenges,\nwe introduce a data expansion framework called Dynamic Uncertainty-driven\nSample Expansion (DUSE). Specifically, DUSE uses an uncertainty scoring\nfunction to filter out useful samples from relevant AMR datasets and employs an\nactive learning strategy to continuously refine the scorer. Extensive\nexperiments demonstrate that DUSE consistently outperforms 8 coreset selection\nbaselines in both class-balance and class-imbalance settings. Besides, DUSE\nexhibits strong cross-architecture generalization for unseen models."}
{"id": "2507.11836", "pdf": "https://arxiv.org/pdf/2507.11836", "abs": "https://arxiv.org/abs/2507.11836", "authors": ["Jian Gao", "Jianshe Wu", "JingYi Ding"], "title": "HyperEvent:Learning Cohesive Events for Large-scale Dynamic Link Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Dynamic link prediction in continuous-time dynamic graphs is a fundamental\ntask for modeling evolving complex systems. Existing node-centric and\nevent-centric methods focus on individual interactions or atomic states,\nfailing to capture the structural cohesion of composite hyper-events, groups of\ncausally related events. To address this, we propose HyperEvent, a framework\nreframing dynamic link prediction as hyper-event recognition. Central to\nHyperEvent is the dynamic construction of an association sequence using event\ncorrelation vectors. These vectors quantify pairwise dependencies between the\nquery event and relevant historical events, thereby characterizing the\nstructural cohesion of a potential hyper-event. The framework predicts the\noccurrence of the query event by evaluating whether it collectively forms a\nvalid hyper-event with these historical events. Notably, HyperEvent outperforms\nstate-of-the-art methods on 4 out of 5 datasets in the official leaderboard.\nFor scalability, we further introduce an efficient parallel training algorithm\nthat segments large event streams to enable concurrent training. Experiments\nvalidate HyperEvent's superior accuracy and efficiency on large-scale graphs.\nAmong which HyperEvent achieves a 6.95% improvement in Mean Reciprocal Rank\nover state-of-the-art baseline on the large-scale Flight dataset while\nutilizing only 10.17% of the training time."}
{"id": "2507.12145", "pdf": "https://arxiv.org/pdf/2507.12145", "abs": "https://arxiv.org/abs/2507.12145", "authors": ["Muhammad Azlan Qazi", "Alexandros Iosifidis", "Qi Zhang"], "title": "PRISM: Distributed Inference for Foundation Models at Edge", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Foundation models (FMs) have achieved remarkable success across a wide range\nof applications, from image classification to natural langurage processing, but\npose significant challenges for deployment at edge. This has sparked growing\ninterest in developing practical and efficient strategies for bringing\nfoundation models to edge environments. In this work, we propose PRISM, a\ncommunication-efficient and compute-aware strategy for distributed Transformer\ninference on edge devices. Our method leverages a Segment Means representation\nto approximate intermediate output features, drastically reducing inter-device\ncommunication. Additionally, we restructure the self-attention mechanism to\neliminate redundant computations caused by per-device Key/Value calculation in\nposition-wise partitioning and design a partition-aware causal masking scheme\ntailored for autoregressive models. We evaluate PRISM on ViT, BERT, and GPT-2\nacross diverse datasets, namely CIFAR-10, CIFAR-100, ImageNet-1k, GLUE, and\nCBT. Our results demonstrate substantial reductions in communication overhead\n(up to 99.2% for BERT at compression rate CR = 128) and per-device computation\n(51.24% for BERT at the same setting), with only minor accuracy degradation.\nThis method offers a scalable and practical solution for deploying foundation\nmodels in distributed resource-constrained environments."}
{"id": "2507.11839", "pdf": "https://arxiv.org/pdf/2507.11839", "abs": "https://arxiv.org/abs/2507.11839", "authors": ["Chengyue Gong", "Xinshi Chen", "Yuxuan Zhang", "Yuxuan Song", "Hao Zhou", "Wenzhi Xiao"], "title": "Protenix-Mini: Efficient Structure Predictor via Compact Architecture, Few-Step Diffusion and Switchable pLM", "categories": ["cs.LG", "q-bio.QM"], "comment": null, "summary": "Lightweight inference is critical for biomolecular structure prediction and\nother downstream tasks, enabling efficient real-world deployment and\ninference-time scaling for large-scale applications. In this work, we address\nthe challenge of balancing model efficiency and prediction accuracy by making\nseveral key modifications, 1) Multi-step AF3 sampler is replaced by a few-step\nODE sampler, significantly reducing computational overhead for the diffusion\nmodule part during inference; 2) In the open-source Protenix framework, a\nsubset of pairformer or diffusion transformer blocks doesn't make contributions\nto the final structure prediction, presenting opportunities for architectural\npruning and lightweight redesign; 3) A model incorporating an ESM module is\ntrained to substitute the conventional MSA module, reducing MSA preprocessing\ntime. Building on these key insights, we present Protenix-Mini, a compact and\noptimized model designed for efficient protein structure prediction. This\nstreamlined version incorporates a more efficient architectural design with a\ntwo-step Ordinary Differential Equation (ODE) sampling strategy. By eliminating\nredundant Transformer components and refining the sampling process,\nProtenix-Mini significantly reduces model complexity with slight accuracy drop.\nEvaluations on benchmark datasets demonstrate that it achieves high-fidelity\npredictions, with only a negligible 1 to 5 percent decrease in performance on\nbenchmark datasets compared to its full-scale counterpart. This makes\nProtenix-Mini an ideal choice for applications where computational resources\nare limited but accurate structure prediction remains crucial."}
{"id": "2507.12196", "pdf": "https://arxiv.org/pdf/2507.12196", "abs": "https://arxiv.org/abs/2507.12196", "authors": ["Nikolaos Louloudakis", "Ajitha Rajan"], "title": "Selective Quantization Tuning for ONNX Models", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": "5 pages, 3 figures, 2 tables", "summary": "Quantization is a process that reduces the precision of deep neural network\nmodels to lower model size and computational demands, often at the cost of\naccuracy. However, fully quantized models may exhibit sub-optimal performance\nbelow acceptable levels and face deployment challenges on low-end hardware\naccelerators due to practical constraints. To address these issues,\nquantization can be selectively applied to only a subset of layers, but\nselecting which layers to exclude is non-trivial. To this direction, we propose\nTuneQn, a suite enabling selective quantization, deployment and execution of\nONNX models across various CPU and GPU devices, combined with profiling and\nmulti-objective optimization. TuneQn generates selectively quantized ONNX\nmodels, deploys them on different hardware, measures performance on metrics\nlike accuracy and size, performs Pareto Front minimization to identify the best\nmodel candidate and visualizes the results. To demonstrate the effectiveness of\nTuneQn, we evaluated TuneQn on four ONNX models with two quantization settings\nacross CPU and GPU devices. As a result, we demonstrated that our utility\neffectively performs selective quantization and tuning, selecting ONNX model\ncandidates with up to a $54.14$% reduction in accuracy loss compared to the\nfully quantized model, and up to a $72.9$% model size reduction compared to the\noriginal model."}
{"id": "2507.11847", "pdf": "https://arxiv.org/pdf/2507.11847", "abs": "https://arxiv.org/abs/2507.11847", "authors": ["Yu-Jie Zhang", "Sheng-An Xu", "Peng Zhao", "Masashi Sugiyama"], "title": "Generalized Linear Bandits: Almost Optimal Regret with One-Pass Update", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We study the generalized linear bandit (GLB) problem, a contextual\nmulti-armed bandit framework that extends the classical linear model by\nincorporating a non-linear link function, thereby modeling a broad class of\nreward distributions such as Bernoulli and Poisson. While GLBs are widely\napplicable to real-world scenarios, their non-linear nature introduces\nsignificant challenges in achieving both computational and statistical\nefficiency. Existing methods typically trade off between two objectives, either\nincurring high per-round costs for optimal regret guarantees or compromising\nstatistical efficiency to enable constant-time updates. In this paper, we\npropose a jointly efficient algorithm that attains a nearly optimal regret\nbound with $\\mathcal{O}(1)$ time and space complexities per round. The core of\nour method is a tight confidence set for the online mirror descent (OMD)\nestimator, which is derived through a novel analysis that leverages the notion\nof mix loss from online prediction. The analysis shows that our OMD estimator,\neven with its one-pass updates, achieves statistical efficiency comparable to\nmaximum likelihood estimation, thereby leading to a jointly efficient\noptimistic method."}
{"id": "2507.12262", "pdf": "https://arxiv.org/pdf/2507.12262", "abs": "https://arxiv.org/abs/2507.12262", "authors": ["Zachary James", "Joseph Guinness"], "title": "A Framework for Nonstationary Gaussian Processes with Neural Network Parameters", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "comment": null, "summary": "Gaussian processes have become a popular tool for nonparametric regression\nbecause of their flexibility and uncertainty quantification. However, they\noften use stationary kernels, which limit the expressiveness of the model and\nmay be unsuitable for many datasets. We propose a framework that uses\nnonstationary kernels whose parameters vary across the feature space, modeling\nthese parameters as the output of a neural network that takes the features as\ninput. The neural network and Gaussian process are trained jointly using the\nchain rule to calculate derivatives. Our method clearly describes the behavior\nof the nonstationary parameters and is compatible with approximation methods\nfor scaling to large datasets. It is flexible and easily adapts to different\nnonstationary kernels without needing to redesign the optimization procedure.\nOur methods are implemented with the GPyTorch library and can be readily\nmodified. We test a nonstationary variance and noise variant of our method on\nseveral machine learning datasets and find that it achieves better accuracy and\nlog-score than both a stationary model and a hierarchical model approximated\nwith variational inference. Similar results are observed for a model with only\nnonstationary variance. We also demonstrate our approach's ability to recover\nthe nonstationary parameters of a spatial dataset."}
{"id": "2507.11855", "pdf": "https://arxiv.org/pdf/2507.11855", "abs": "https://arxiv.org/abs/2507.11855", "authors": ["Davin Hill", "Brian L. Hill", "Aria Masoomi", "Vijay S. Nori", "Robert E. Tillman", "Jennifer Dy"], "title": "OrdShap: Feature Position Importance for Sequential Black-Box Models", "categories": ["cs.LG"], "comment": null, "summary": "Sequential deep learning models excel in domains with temporal or sequential\ndependencies, but their complexity necessitates post-hoc feature attribution\nmethods for understanding their predictions. While existing techniques quantify\nfeature importance, they inherently assume fixed feature ordering - conflating\nthe effects of (1) feature values and (2) their positions within input\nsequences. To address this gap, we introduce OrdShap, a novel attribution\nmethod that disentangles these effects by quantifying how a model's predictions\nchange in response to permuting feature position. We establish a game-theoretic\nconnection between OrdShap and Sanchez-Berganti\\~nos values, providing a\ntheoretically grounded approach to position-sensitive attribution. Empirical\nresults from health, natural language, and synthetic datasets highlight\nOrdShap's effectiveness in capturing feature value and feature position\nattributions, and provide deeper insight into model behavior."}
{"id": "2507.12305", "pdf": "https://arxiv.org/pdf/2507.12305", "abs": "https://arxiv.org/abs/2507.12305", "authors": ["M. Anwar Ma'sum", "Mahardhika Pratama", "Savitha Ramasamy", "Lin Liu", "Habibullah Habibullah", "Ryszard Kowalczyk"], "title": "PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "ICCV 2025", "summary": "The data privacy constraint in online continual learning (OCL), where the\ndata can be seen only once, complicates the catastrophic forgetting problem in\nstreaming data. A common approach applied by the current SOTAs in OCL is with\nthe use of memory saving exemplars or features from previous classes to be\nreplayed in the current task. On the other hand, the prompt-based approach\nperforms excellently in continual learning but with the cost of a growing\nnumber of trainable parameters. The first approach may not be applicable in\npractice due to data openness policy, while the second approach has the issue\nof throughput associated with the streaming data. In this study, we propose a\nnovel prompt-based method for online continual learning that includes 4 main\ncomponents: (1) single light-weight prompt generator as a general knowledge,\n(2) trainable scaler-and-shifter as specific knowledge, (3) pre-trained model\n(PTM) generalization preserving, and (4) hard-soft updates mechanism. Our\nproposed method achieves significantly higher performance than the current\nSOTAs in CIFAR100, ImageNet-R, ImageNet-A, and CUB dataset. Our complexity\nanalysis shows that our method requires a relatively smaller number of\nparameters and achieves moderate training time, inference time, and throughput.\nFor further study, the source code of our method is available at\nhttps://github.com/anwarmaxsum/PROL."}
{"id": "2507.11865", "pdf": "https://arxiv.org/pdf/2507.11865", "abs": "https://arxiv.org/abs/2507.11865", "authors": ["Hanwen Dai", "Chang Gao", "Fang He", "Congyuan Ji", "Yanni Yang"], "title": "A Policy-Improved Deep Deterministic Policy Gradient Framework for the Discount Order Acceptance Strategy of Ride-hailing Drivers", "categories": ["cs.LG"], "comment": null, "summary": "The rapid expansion of platform integration has emerged as an effective\nsolution to mitigate market fragmentation by consolidating multiple\nride-hailing platforms into a single application. To address heterogeneous\npassenger preferences, third-party integrators provide Discount Express service\ndelivered by express drivers at lower trip fares. For the individual platform,\nencouraging broader participation of drivers in Discount Express services has\nthe potential to expand the accessible demand pool and improve matching\nefficiency, but often at the cost of reduced profit margins. This study aims to\ndynamically manage drivers' acceptance of Discount Express from the perspective\nof individual platforms. The lack of historical data under the new business\nmodel necessitates online learning. However, early-stage exploration through\ntrial and error can be costly in practice, highlighting the need for reliable\nearly-stage performance in real-world deployment. To address these challenges,\nthis study formulates the decision regarding the proportion of drivers'\nacceptance behavior as a continuous control task. In response to the high\nstochasticity, the opaque matching mechanisms employed by third-party\nintegrator, and the limited availability of historical data, we propose a\npolicy-improved deep deterministic policy gradient (pi-DDPG) framework. The\nproposed framework incorporates a refiner module to boost policy performance\nduring the early training phase, leverages a convolutional long short-term\nmemory network to effectively capture complex spatiotemporal patterns, and\nadopts a prioritized experience replay mechanism to enhance learning\nefficiency. A simulator based on a real-world dataset is developed to validate\nthe effectiveness of the proposed pi-DDPG. Numerical experiments demonstrate\nthat pi-DDPG achieves superior learning efficiency and significantly reduces\nearly-stage training losses."}
{"id": "2507.12314", "pdf": "https://arxiv.org/pdf/2507.12314", "abs": "https://arxiv.org/abs/2507.12314", "authors": ["Zihao Xue", "Zhen Bi", "Long Ma", "Zhenlin Hu", "Yan Wang", "Zhenfang Liu", "Qing Sheng", "Jie Xiao", "Jungang Lou"], "title": "Thought Purity: Defense Paradigm For Chain-of-Thought Attack", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.CR"], "comment": null, "summary": "While reinforcement learning-trained Large Reasoning Models (LRMs, e.g.,\nDeepseek-R1) demonstrate advanced reasoning capabilities in the evolving Large\nLanguage Models (LLMs) domain, their susceptibility to security threats remains\na critical vulnerability. This weakness is particularly evident in\nChain-of-Thought (CoT) generation processes, where adversarial methods like\nbackdoor prompt attacks can systematically subvert the model's core reasoning\nmechanisms. The emerging Chain-of-Thought Attack (CoTA) reveals this\nvulnerability through exploiting prompt controllability, simultaneously\ndegrading both CoT safety and task performance with low-cost interventions. To\naddress this compounded security-performance vulnerability, we propose Thought\nPurity (TP): a defense paradigm that systematically strengthens resistance to\nmalicious content while preserving operational efficacy. Our solution achieves\nthis through three synergistic components: (1) a safety-optimized data\nprocessing pipeline (2) reinforcement learning-enhanced rule constraints (3)\nadaptive monitoring metrics. Our approach establishes the first comprehensive\ndefense mechanism against CoTA vulnerabilities in reinforcement\nlearning-aligned reasoning systems, significantly advancing the\nsecurity-functionality equilibrium for next-generation AI architectures."}
{"id": "2507.11901", "pdf": "https://arxiv.org/pdf/2507.11901", "abs": "https://arxiv.org/abs/2507.11901", "authors": ["Juscimara G. Avelino", "George D. C. Cavalcanti", "Rafael M. O. Cruz"], "title": "Imbalanced Regression Pipeline Recommendation", "categories": ["cs.LG"], "comment": null, "summary": "Imbalanced problems are prevalent in various real-world scenarios and are\nextensively explored in classification tasks. However, they also present\nchallenges for regression tasks due to the rarity of certain target values. A\ncommon alternative is to employ balancing algorithms in preprocessing to\naddress dataset imbalance. However, due to the variety of resampling methods\nand learning models, determining the optimal solution requires testing many\ncombinations. Furthermore, the learning model, dataset, and evaluation metric\naffect the best strategies. This work proposes the Meta-learning for Imbalanced\nRegression (Meta-IR) framework, which diverges from existing literature by\ntraining meta-classifiers to recommend the best pipeline composed of the\nresampling strategy and learning model per task in a zero-shot fashion. The\nmeta-classifiers are trained using a set of meta-features to learn how to map\nthe meta-features to the classes indicating the best pipeline. We propose two\nformulations: Independent and Chained. Independent trains the meta-classifiers\nto separately indicate the best learning algorithm and resampling strategy.\nChained involves a sequential procedure where the output of one meta-classifier\nis used as input for another to model intrinsic relationship factors. The\nChained scenario showed superior performance, suggesting a relationship between\nthe learning algorithm and the resampling strategy per task. Compared with\nAutoML frameworks, Meta-IR obtained better results. Moreover, compared with\nbaselines of six learning algorithms and six resampling algorithms plus no\nresampling, totaling 42 (6 X 7) configurations, Meta-IR outperformed all of\nthem. The code, data, and further information of the experiments can be found\non GitHub: https://github.com/JusciAvelino/Meta-IR."}
{"id": "2507.12412", "pdf": "https://arxiv.org/pdf/2507.12412", "abs": "https://arxiv.org/abs/2507.12412", "authors": ["Dzung Dinh", "Boqi Chen", "Marc Niethammer", "Junier Oliva"], "title": "NOCTA: Non-Greedy Objective Cost-Tradeoff Acquisition for Longitudinal Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In many critical applications, resource constraints limit the amount of\ninformation that can be gathered to make predictions. For example, in\nhealthcare, patient data often spans diverse features ranging from lab tests to\nimaging studies. Each feature may carry different information and must be\nacquired at a respective cost of time, money, or risk to the patient. Moreover,\ntemporal prediction tasks, where both instance features and labels evolve over\ntime, introduce additional complexity in deciding when or what information is\nimportant. In this work, we propose NOCTA, a Non-Greedy Objective Cost-Tradeoff\nAcquisition method that sequentially acquires the most informative features at\ninference time while accounting for both temporal dynamics and acquisition\ncost. We first introduce a cohesive estimation target for our NOCTA setting,\nand then develop two complementary estimators: 1) a non-parametric method based\non nearest neighbors to guide the acquisition (NOCTA-NP), and 2) a parametric\nmethod that directly predicts the utility of potential acquisitions (NOCTA-P).\nExperiments on synthetic and real-world medical datasets demonstrate that both\nNOCTA variants outperform existing baselines."}
{"id": "2507.11902", "pdf": "https://arxiv.org/pdf/2507.11902", "abs": "https://arxiv.org/abs/2507.11902", "authors": ["Juscimara G. Avelino", "George D. C. Cavalcanti", "Rafael M. O. Cruz"], "title": "Resampling strategies for imbalanced regression: a survey and empirical analysis", "categories": ["cs.LG"], "comment": null, "summary": "Imbalanced problems can arise in different real-world situations, and to\naddress this, certain strategies in the form of resampling or balancing\nalgorithms are proposed. This issue has largely been studied in the context of\nclassification, and yet, the same problem features in regression tasks, where\ntarget values are continuous. This work presents an extensive experimental\nstudy comprising various balancing and predictive models, and wich uses metrics\nto capture important elements for the user and to evaluate the predictive model\nin an imbalanced regression data context. It also proposes a taxonomy for\nimbalanced regression approaches based on three crucial criteria: regression\nmodel, learning process, and evaluation metrics. The study offers new insights\ninto the use of such strategies, highlighting the advantages they bring to each\nmodel's learning process, and indicating directions for further studies. The\ncode, data and further information related to the experiments performed herein\ncan be found on GitHub: https://github.com/JusciAvelino/imbalancedRegression."}
{"id": "2507.12419", "pdf": "https://arxiv.org/pdf/2507.12419", "abs": "https://arxiv.org/abs/2507.12419", "authors": ["Andrea Perin", "Giacomo Lagomarsini", "Claudio Gallicchio", "Giuseppe Nuti"], "title": "Mixture of Raytraced Experts", "categories": ["cs.LG", "cs.AI"], "comment": "Preliminary version (pre-submission)", "summary": "We introduce a Mixture of Raytraced Experts, a stacked Mixture of Experts\n(MoE) architecture which can dynamically select sequences of experts, producing\ncomputational graphs of variable width and depth. Existing MoE architectures\ngenerally require a fixed amount of computation for a given sample. Our\napproach, in contrast, yields predictions with increasing accuracy as the\ncomputation cycles through the experts' sequence. We train our model by\niteratively sampling from a set of candidate experts, unfolding the sequence\nakin to how Recurrent Neural Networks are trained. Our method does not require\nload-balancing mechanisms, and preliminary experiments show a reduction in\ntraining epochs of 10\\% to 40\\% with a comparable/higher accuracy. These\nresults point to new research directions in the field of MoEs, allowing the\ndesign of potentially faster and more expressive models. The code is available\nat https://github.com/nutig/RayTracing"}
{"id": "2507.11926", "pdf": "https://arxiv.org/pdf/2507.11926", "abs": "https://arxiv.org/abs/2507.11926", "authors": ["Max Hopkins", "Sihan Liu", "Christopher Ye", "Yuichi Yoshida"], "title": "From Generative to Episodic: Sample-Efficient Replicable Reinforcement Learning", "categories": ["cs.LG"], "comment": "67 pages", "summary": "The epidemic failure of replicability across empirical science and machine\nlearning has recently motivated the formal study of replicable learning\nalgorithms [Impagliazzo et al. (2022)]. In batch settings where data comes from\na fixed i.i.d. source (e.g., hypothesis testing, supervised learning), the\ndesign of data-efficient replicable algorithms is now more or less understood.\nIn contrast, there remain significant gaps in our knowledge for control\nsettings like reinforcement learning where an agent must interact directly with\na shifting environment. Karbasi et. al show that with access to a generative\nmodel of an environment with $S$ states and $A$ actions (the RL 'batch\nsetting'), replicably learning a near-optimal policy costs only\n$\\tilde{O}(S^2A^2)$ samples. On the other hand, the best upper bound without a\ngenerative model jumps to $\\tilde{O}(S^7 A^7)$ [Eaton et al. (2024)] due to the\nsubstantial difficulty of environment exploration. This gap raises a key\nquestion in the broader theory of replicability: Is replicable exploration\ninherently more expensive than batch learning? Is sample-efficient replicable\nRL even possible?\n  In this work, we (nearly) resolve this problem (for low-horizon tabular\nMDPs): exploration is not a significant barrier to replicable learning! Our\nmain result is a replicable RL algorithm on $\\tilde{O}(S^2A)$ samples, bridging\nthe gap between the generative and episodic settings. We complement this with a\nmatching $\\tilde{\\Omega}(S^2A)$ lower bound in the generative setting (under\nthe common parallel sampling assumption) and an unconditional lower bound in\nthe episodic setting of $\\tilde{\\Omega}(S^2)$ showcasing the near-optimality of\nour algorithm with respect to the state space $S$."}
{"id": "2507.11928", "pdf": "https://arxiv.org/pdf/2507.11928", "abs": "https://arxiv.org/abs/2507.11928", "authors": ["Abhishek Sriram", "Neal Tuffy"], "title": "Accelerating RF Power Amplifier Design via Intelligent Sampling and ML-Based Parameter Tuning", "categories": ["cs.LG"], "comment": "This paper is a pre-print version and has been submitted to the IEEE\n  International Conference on Future Machine Learning and Data Science (FMLDS\n  2025)", "summary": "This paper presents a machine learning-accelerated optimization framework for\nRF power amplifier design that reduces simulation requirements by 65% while\nmaintaining $\\pm0.3$ to $\\pm0.4$ dBm accuracy. The proposed method combines\nMaxMin Latin Hypercube Sampling with CatBoost gradient boosting to\nintelligently explore multidimensional parameter spaces. Instead of\nexhaustively simulating all parameter combinations to achieve target P2dB\ncompression specifications, our approach strategically selects approximately\n35% of critical simulation points. The framework processes ADS netlists,\nexecutes harmonic balance simulations on the reduced dataset, and trains a\nCatBoost model to predict P2dB performance across the entire design space.\nValidation across 15 PA operating modes yields an average $R^2$ of 0.901, with\nthe system ranking parameter combinations by their likelihood of meeting target\nspecifications. The integrated solution delivers 58.24% to 77.78% reduction in\nsimulation time through automated GUI-based workflows, enabling rapid design\niterations without compromising accuracy standards required for production RF\ncircuits."}
{"id": "2507.11948", "pdf": "https://arxiv.org/pdf/2507.11948", "abs": "https://arxiv.org/abs/2507.11948", "authors": ["Carlo Baronio", "Pietro Marsella", "Ben Pan", "Simon Guo", "Silas Alberti"], "title": "Kevin: Multi-Turn RL for Generating CUDA Kernels", "categories": ["cs.LG", "cs.AI", "cs.PF", "cs.SE"], "comment": null, "summary": "Writing GPU kernels is a challenging task and critical for AI systems'\nefficiency. It is also highly iterative: domain experts write code and improve\nperformance through execution feedback. Moreover, it presents verifiable\nrewards like correctness and speedup, making it a natural environment to apply\nReinforcement Learning (RL). To explicitly incorporate the iterative nature of\nthis process into training, we develop a flexible multi-turn RL recipe that\naddresses unique challenges encountered in real-world settings, such as\nlearning from long trajectories and effective reward attribution across turns.\nWe present Kevin - K(ernel D)evin, the first model trained with multi-turn RL\nfor CUDA kernel generation and optimization. In our evaluation setup, Kevin\nshows significant gains over its base model (QwQ-32B), improving correctness of\ngenerated kernels (in pure CUDA) from 56% to 82% and mean speedup from 0.53x to\n1.10x of baseline (PyTorch Eager), and surpassing frontier models like o4-mini\n(0.78x). Finally, we study its behavior across test-time scaling axes: we found\nscaling serial refinement more beneficial than parallel sampling. In\nparticular, when given more refinement turns, Kevin shows a higher rate of\nimprovement."}
{"id": "2507.11975", "pdf": "https://arxiv.org/pdf/2507.11975", "abs": "https://arxiv.org/abs/2507.11975", "authors": ["Valentin Frank Ingmar Guenter", "Athanasios Sideris"], "title": "Online Training and Pruning of Deep Reinforcement Learning Networks", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "25 pages, 5 figures, 4 tables", "summary": "Scaling deep neural networks (NN) of reinforcement learning (RL) algorithms\nhas been shown to enhance performance when feature extraction networks are used\nbut the gained performance comes at the significant expense of increased\ncomputational and memory complexity. Neural network pruning methods have\nsuccessfully addressed this challenge in supervised learning. However, their\napplication to RL is underexplored. We propose an approach to integrate\nsimultaneous training and pruning within advanced RL methods, in particular to\nRL algorithms enhanced by the Online Feature Extractor Network (OFENet). Our\nnetworks (XiNet) are trained to solve stochastic optimization problems over the\nRL networks' weights and the parameters of variational Bernoulli distributions\nfor 0/1 Random Variables $\\xi$ scaling each unit in the networks. The\nstochastic problem formulation induces regularization terms that promote\nconvergence of the variational parameters to 0 when a unit contributes little\nto the performance. In this case, the corresponding structure is rendered\npermanently inactive and pruned from its network. We propose a cost-aware,\nsparsity-promoting regularization scheme, tailored to the DenseNet architecture\nof OFENets expressing the parameter complexity of involved networks in terms of\nthe parameters of the RVs in these networks. Then, when matching this cost with\nthe regularization terms, the many hyperparameters associated with them are\nautomatically selected, effectively combining the RL objectives and network\ncompression. We evaluate our method on continuous control benchmarks (MuJoCo)\nand the Soft Actor-Critic RL agent, demonstrating that OFENets can be pruned\nconsiderably with minimal loss in performance. Furthermore, our results confirm\nthat pruning large networks during training produces more efficient and higher\nperforming RL agents rather than training smaller networks from scratch."}
{"id": "2507.11997", "pdf": "https://arxiv.org/pdf/2507.11997", "abs": "https://arxiv.org/abs/2507.11997", "authors": ["Tairan Huang", "Yili Wang"], "title": "Can LLMs Find Fraudsters? Multi-level LLM Enhanced Graph Fraud Detection", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph fraud detection has garnered significant attention as Graph Neural\nNetworks (GNNs) have proven effective in modeling complex relationships within\nmultimodal data. However, existing graph fraud detection methods typically use\npreprocessed node embeddings and predefined graph structures to reveal\nfraudsters, which ignore the rich semantic cues contained in raw textual\ninformation. Although Large Language Models (LLMs) exhibit powerful\ncapabilities in processing textual information, it remains a significant\nchallenge to perform multimodal fusion of processed textual embeddings with\ngraph structures. In this paper, we propose a \\textbf{M}ulti-level \\textbf{L}LM\n\\textbf{E}nhanced Graph Fraud \\textbf{D}etection framework called MLED. In\nMLED, we utilize LLMs to extract external knowledge from textual information to\nenhance graph fraud detection methods. To integrate LLMs with graph structure\ninformation and enhance the ability to distinguish fraudsters, we design a\nmulti-level LLM enhanced framework including type-level enhancer and\nrelation-level enhancer. One is to enhance the difference between the\nfraudsters and the benign entities, the other is to enhance the importance of\nthe fraudsters in different relations. The experiments on four real-world\ndatasets show that MLED achieves state-of-the-art performance in graph fraud\ndetection as a generalized framework that can be applied to existing methods."}
{"id": "2507.12002", "pdf": "https://arxiv.org/pdf/2507.12002", "abs": "https://arxiv.org/abs/2507.12002", "authors": ["Alice Zhang", "Callihan Bertley", "Dawei Liang", "Edison Thomaz"], "title": "Detecting In-Person Conversations in Noisy Real-World Environments with Smartwatch Audio and Motion Sensing", "categories": ["cs.LG", "I.2.0; J.4"], "comment": null, "summary": "Social interactions play a crucial role in shaping human behavior,\nrelationships, and societies. It encompasses various forms of communication,\nsuch as verbal conversation, non-verbal gestures, facial expressions, and body\nlanguage. In this work, we develop a novel computational approach to detect a\nfoundational aspect of human social interactions, in-person verbal\nconversations, by leveraging audio and inertial data captured with a commodity\nsmartwatch in acoustically-challenging scenarios. To evaluate our approach, we\nconducted a lab study with 11 participants and a semi-naturalistic study with\n24 participants. We analyzed machine learning and deep learning models with 3\ndifferent fusion methods, showing the advantages of fusing audio and inertial\ndata to consider not only verbal cues but also non-verbal gestures in\nconversations. Furthermore, we perform a comprehensive set of evaluations\nacross activities and sampling rates to demonstrate the benefits of multimodal\nsensing in specific contexts. Overall, our framework achieved 82.0$\\pm$3.0%\nmacro F1-score when detecting conversations in the lab and 77.2$\\pm$1.8% in the\nsemi-naturalistic setting."}
{"id": "2507.12011", "pdf": "https://arxiv.org/pdf/2507.12011", "abs": "https://arxiv.org/abs/2507.12011", "authors": ["Yao Lu", "Hongyu Gao", "Zhuangzhi Chen", "Dongwei Xu", "Yun Lin", "Qi Xuan", "Guan Gui"], "title": "DUSE: A Data Expansion Framework for Low-resource Automatic Modulation Recognition based on Active Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Although deep neural networks have made remarkable achievements in the field\nof automatic modulation recognition (AMR), these models often require a large\namount of labeled data for training. However, in many practical scenarios, the\navailable target domain data is scarce and difficult to meet the needs of model\ntraining. The most direct way is to collect data manually and perform expert\nannotation, but the high time and labor costs are unbearable. Another common\nmethod is data augmentation. Although it can enrich training samples to a\ncertain extent, it does not introduce new data and therefore cannot\nfundamentally solve the problem of data scarcity. To address these challenges,\nwe introduce a data expansion framework called Dynamic Uncertainty-driven\nSample Expansion (DUSE). Specifically, DUSE uses an uncertainty scoring\nfunction to filter out useful samples from relevant AMR datasets and employs an\nactive learning strategy to continuously refine the scorer. Extensive\nexperiments demonstrate that DUSE consistently outperforms 8 coreset selection\nbaselines in both class-balance and class-imbalance settings. Besides, DUSE\nexhibits strong cross-architecture generalization for unseen models."}
{"id": "2507.12041", "pdf": "https://arxiv.org/pdf/2507.12041", "abs": "https://arxiv.org/abs/2507.12041", "authors": ["Anmol Kagrecha", "Henrik Marklund", "Potsawee Manakul", "Richard Zeckhauser", "Benjamin Van Roy"], "title": "Granular feedback merits sophisticated aggregation", "categories": ["cs.LG"], "comment": "31 pages, 8 figures", "summary": "Human feedback is increasingly used across diverse applications like training\nAI models, developing recommender systems, and measuring public opinion -- with\ngranular feedback often being preferred over binary feedback for its greater\ninformativeness. While it is easy to accurately estimate a population's\ndistribution of feedback given feedback from a large number of individuals,\ncost constraints typically necessitate using smaller groups. A simple method to\napproximate the population distribution is regularized averaging: compute the\nempirical distribution and regularize it toward a prior. Can we do better? As\nwe will discuss, the answer to this question depends on feedback granularity.\n  Suppose one wants to predict a population's distribution of feedback using\nfeedback from a limited number of individuals. We show that, as feedback\ngranularity increases, one can substantially improve upon predictions of\nregularized averaging by combining individuals' feedback in ways more\nsophisticated than regularized averaging.\n  Our empirical analysis using questions on social attitudes confirms this\npattern. In particular, with binary feedback, sophistication barely reduces the\nnumber of individuals required to attain a fixed level of performance. By\ncontrast, with five-point feedback, sophisticated methods match the performance\nof regularized averaging with about half as many individuals."}
{"id": "2507.12043", "pdf": "https://arxiv.org/pdf/2507.12043", "abs": "https://arxiv.org/abs/2507.12043", "authors": ["Wen Wen", "Tieliang Gong", "Yunjiao Zhang", "Zeyu Gao", "Weizhan Zhang", "Yong-Jin Liu"], "title": "Information-Theoretic Generalization Bounds of Replay-based Continual Learning", "categories": ["cs.LG"], "comment": null, "summary": "Continual learning (CL) has emerged as a dominant paradigm for acquiring\nknowledge from sequential tasks while avoiding catastrophic forgetting.\nAlthough many CL methods have been proposed to show impressive empirical\nperformance, the theoretical understanding of their generalization behavior\nremains limited, particularly for replay-based approaches. In this paper, we\nestablish a unified theoretical framework for replay-based CL, deriving a\nseries of information-theoretic bounds that explicitly characterize how the\nmemory buffer interacts with the current task to affect generalization.\nSpecifically, our hypothesis-based bounds reveal that utilizing the limited\nexemplars of previous tasks alongside the current task data, rather than\nexhaustive replay, facilitates improved generalization while effectively\nmitigating catastrophic forgetting. Furthermore, our prediction-based bounds\nyield tighter and computationally tractable upper bounds of the generalization\ngap through the use of low-dimensional variables. Our analysis is general and\nbroadly applicable to a wide range of learning algorithms, exemplified by\nstochastic gradient Langevin dynamics (SGLD) as a representative method.\nComprehensive experimental evaluations demonstrate the effectiveness of our\nderived bounds in capturing the generalization dynamics in replay-based CL\nsettings."}
{"id": "2507.12053", "pdf": "https://arxiv.org/pdf/2507.12053", "abs": "https://arxiv.org/abs/2507.12053", "authors": ["Seanglidet Yean", "Jiazu Zhou", "Bu-Sung Lee", "Markus Schläpfer"], "title": "FloGAN: Scenario-Based Urban Mobility Flow Generation via Conditional GANs and Dynamic Region Decoupling", "categories": ["cs.LG"], "comment": "International Conference on Intelligent Digitization of Systems and\n  Services, Valencia, Spain, 2025 (IDSS 2025)", "summary": "The mobility patterns of people in cities evolve alongside changes in land\nuse and population. This makes it crucial for urban planners to simulate and\nanalyze human mobility patterns for purposes such as transportation\noptimization and sustainable urban development. Existing generative models\nborrowed from machine learning rely heavily on historical trajectories and\noften overlook evolving factors like changes in population density and land\nuse. Mechanistic approaches incorporate population density and facility\ndistribution but assume static scenarios, limiting their utility for future\nprojections where historical data for calibration is unavailable. This study\nintroduces a novel, data-driven approach for generating origin-destination\nmobility flows tailored to simulated urban scenarios. Our method leverages\nadaptive factors such as dynamic region sizes and land use archetypes, and it\nutilizes conditional generative adversarial networks (cGANs) to blend\nhistorical data with these adaptive parameters. The approach facilitates rapid\nmobility flow generation with adjustable spatial granularity based on regions\nof interest, without requiring extensive calibration data or complex behavior\nmodeling. The promising performance of our approach is demonstrated by its\napplication to mobile phone data from Singapore, and by its comparison with\nexisting methods."}
{"id": "2507.12070", "pdf": "https://arxiv.org/pdf/2507.12070", "abs": "https://arxiv.org/abs/2507.12070", "authors": ["George Bird"], "title": "Emergence of Quantised Representations Isolated to Anisotropic Functions", "categories": ["cs.LG", "I.5.1; F.1.1; I.2.6"], "comment": "36 pages, 31 figures", "summary": "This paper describes a novel methodology for determining representational\nalignment, developed upon the existing Spotlight Resonance method. Using this,\nit is found that algebraic symmetries of network primitives are a strong\npredictor for task-agnostic structure in representations. Particularly, this\nnew tool is used to gain insight into how discrete representations can form and\narrange in autoencoder models, through an ablation study where only the\nactivation function is altered. Representations are found to tend to discretise\nwhen the activation functions are defined through a discrete algebraic\npermutation-equivariant symmetry. In contrast, they remain continuous under a\ncontinuous algebraic orthogonal-equivariant definition. These findings\ncorroborate the hypothesis that functional form choices can carry unintended\ninductive biases which produce task-independent artefactual structures in\nrepresentations, particularly that contemporary forms induce discretisation of\notherwise continuous structure -- a quantisation effect. Moreover, this\nsupports a general causal model for one mode in which discrete representations\nmay form, and could constitute a prerequisite for downstream interpretability\nphenomena, including grandmother neurons, discrete coding schemes, general\nlinear features and possibly Superposition. Hence, this tool and proposed\nmechanism for the influence of functional form on representations may provide\nseveral insights into emergent interpretability research. Finally, preliminary\nresults indicate that quantisation of representations appears to correlate with\na measurable increase in reconstruction error, reinforcing previous conjectures\nthat this collapse can be detrimental."}
{"id": "2507.12094", "pdf": "https://arxiv.org/pdf/2507.12094", "abs": "https://arxiv.org/abs/2507.12094", "authors": ["Yiding Feng", "Wei Tang"], "title": "Measuring Informativeness Gap of (Mis)Calibrated Predictors", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "In many applications, decision-makers must choose between multiple predictive\nmodels that may all be miscalibrated. Which model (i.e., predictor) is more\n\"useful\" in downstream decision tasks? To answer this, our first contribution\nintroduces the notion of the informativeness gap between any two predictors,\ndefined as the maximum normalized payoff advantage one predictor offers over\nthe other across all decision-making tasks. Our framework strictly generalizes\nseveral existing notions: it subsumes U-Calibration [KLST-23] and Calibration\nDecision Loss [HW-24], which compare a miscalibrated predictor to its\ncalibrated counterpart, and it recovers Blackwell informativeness [Bla-51,\nBla-53] as a special case when both predictors are perfectly calibrated. Our\nsecond contribution is a dual characterization of the informativeness gap,\nwhich gives rise to a natural informativeness measure that can be viewed as a\nrelaxed variant of the earth mover's distance (EMD) between two prediction\ndistributions. We show that this measure satisfies natural desiderata: it is\ncomplete and sound, and it can be estimated sample-efficiently in the\nprediction-only access setting. Along the way, we also obtain novel\ncombinatorial structural results when applying this measure to perfectly\ncalibrated predictors."}
{"id": "2507.12127", "pdf": "https://arxiv.org/pdf/2507.12127", "abs": "https://arxiv.org/abs/2507.12127", "authors": ["Ngoc Duy Pham", "Thusitha Dayaratne", "Viet Vo", "Shangqi Lai", "Sharif Abuadbba", "Hajime Suzuki", "Xingliang Yuan", "Carsten Rudolph"], "title": "Self-Adaptive and Robust Federated Spectrum Sensing without Benign Majority for Cellular Networks", "categories": ["cs.LG"], "comment": null, "summary": "Advancements in wireless and mobile technologies, including 5G advanced and\nthe envisioned 6G, are driving exponential growth in wireless devices. However,\nthis rapid expansion exacerbates spectrum scarcity, posing a critical\nchallenge. Dynamic spectrum allocation (DSA)--which relies on sensing and\ndynamically sharing spectrum--has emerged as an essential solution to address\nthis issue. While machine learning (ML) models hold significant potential for\nimproving spectrum sensing, their adoption in centralized ML-based DSA systems\nis limited by privacy concerns, bandwidth constraints, and regulatory\nchallenges. To overcome these limitations, distributed ML-based approaches such\nas Federated Learning (FL) offer promising alternatives. This work addresses\ntwo key challenges in FL-based spectrum sensing (FLSS). First, the scarcity of\nlabeled data for training FL models in practical spectrum sensing scenarios is\ntackled with a semi-supervised FL approach, combined with energy detection,\nenabling model training on unlabeled datasets. Second, we examine the security\nvulnerabilities of FLSS, focusing on the impact of data poisoning attacks. Our\nanalysis highlights the shortcomings of existing majority-based defenses in\ncountering such attacks. To address these vulnerabilities, we propose a novel\ndefense mechanism inspired by vaccination, which effectively mitigates data\npoisoning attacks without relying on majority-based assumptions. Extensive\nexperiments on both synthetic and real-world datasets validate our solutions,\ndemonstrating that FLSS can achieve near-perfect accuracy on unlabeled datasets\nand maintain Byzantine robustness against both targeted and untargeted data\npoisoning attacks, even when a significant proportion of participants are\nmalicious."}
{"id": "2507.12133", "pdf": "https://arxiv.org/pdf/2507.12133", "abs": "https://arxiv.org/abs/2507.12133", "authors": ["Hanwen Liu", "Yuhe Huang", "Yifeng Gong", "Yanjie Zhai", "Jiaxuan Lu"], "title": "HyDRA: A Hybrid Dual-Mode Network for Closed- and Open-Set RFFI with Optimized VMD", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Device recognition is vital for security in wireless communication systems,\nparticularly for applications like access control. Radio Frequency Fingerprint\nIdentification (RFFI) offers a non-cryptographic solution by exploiting\nhardware-induced signal distortions. This paper proposes HyDRA, a Hybrid\nDual-mode RF Architecture that integrates an optimized Variational Mode\nDecomposition (VMD) with a novel architecture based on the fusion of\nConvolutional Neural Networks (CNNs), Transformers, and Mamba components,\ndesigned to support both closed-set and open-set classification tasks. The\noptimized VMD enhances preprocessing efficiency and classification accuracy by\nfixing center frequencies and using closed-form solutions. HyDRA employs the\nTransformer Dynamic Sequence Encoder (TDSE) for global dependency modeling and\nthe Mamba Linear Flow Encoder (MLFE) for linear-complexity processing, adapting\nto varying conditions. Evaluation on public datasets demonstrates\nstate-of-the-art (SOTA) accuracy in closed-set scenarios and robust performance\nin our proposed open-set classification method, effectively identifying\nunauthorized devices. Deployed on NVIDIA Jetson Xavier NX, HyDRA achieves\nmillisecond-level inference speed with low power consumption, providing a\npractical solution for real-time wireless authentication in real-world\nenvironments."}
{"id": "2507.12142", "pdf": "https://arxiv.org/pdf/2507.12142", "abs": "https://arxiv.org/abs/2507.12142", "authors": ["Vladimir Bogachev", "Vladimir Aletov", "Alexander Molozhavenko", "Denis Bobkov", "Vera Soboleva", "Aibek Alanov", "Maxim Rakhuba"], "title": "RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization", "categories": ["cs.LG", "cs.CL", "cs.NA", "math.DG", "math.NA", "68T07, 65F55, 53Z50"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) has become a widely adopted standard for\nparameter-efficient fine-tuning of large language models (LLMs), significantly\nreducing memory and computational demands. However, challenges remain,\nincluding finding optimal initialization strategies or mitigating\noverparametrization in low-rank matrix factorization. In this work, we propose\na novel approach that addresses both of the challenges simultaneously within a\nunified framework. Our method treats a set of fixed-rank LoRA matrices as a\nsmooth manifold. Considering adapters as elements on this manifold removes\noverparametrization, while determining the direction of the fastest loss\ndecrease along the manifold provides initialization. Special care is taken to\nobtain numerically stable and computationally efficient implementation of our\nmethod, using best practices from numerical linear algebra and Riemannian\noptimization. Experimental results on LLM and diffusion model architectures\ndemonstrate that RiemannLoRA consistently improves both convergence speed and\nfinal performance over standard LoRA and its state-of-the-art modifications."}
{"id": "2507.12144", "pdf": "https://arxiv.org/pdf/2507.12144", "abs": "https://arxiv.org/abs/2507.12144", "authors": ["Boris Bonev", "Thorsten Kurth", "Ankur Mahesh", "Mauro Bisson", "Jean Kossaifi", "Karthik Kashinath", "Anima Anandkumar", "William D. Collins", "Michael S. Pritchard", "Alexander Keller"], "title": "FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale", "categories": ["cs.LG", "physics.ao-ph", "86-10, 68T07", "I.2.1; I.6.5; G.3"], "comment": null, "summary": "FourCastNet 3 advances global weather modeling by implementing a scalable,\ngeometric machine learning (ML) approach to probabilistic ensemble forecasting.\nThe approach is designed to respect spherical geometry and to accurately model\nthe spatially correlated probabilistic nature of the problem, resulting in\nstable spectra and realistic dynamics across multiple scales. FourCastNet 3\ndelivers forecasting accuracy that surpasses leading conventional ensemble\nmodels and rivals the best diffusion-based methods, while producing forecasts 8\nto 60 times faster than these approaches. In contrast to other ML approaches,\nFourCastNet 3 demonstrates excellent probabilistic calibration and retains\nrealistic spectra, even at extended lead times of up to 60 days. All of these\nadvances are realized using a purely convolutional neural network architecture\ntailored for spherical geometry. Scalable and efficient large-scale training on\n1024 GPUs and more is enabled by a novel training paradigm for combined model-\nand data-parallelism, inspired by domain decomposition methods in classical\nnumerical models. Additionally, FourCastNet 3 enables rapid inference on a\nsingle GPU, producing a 90-day global forecast at 0.25{\\deg}, 6-hourly\nresolution in under 20 seconds. Its computational efficiency, medium-range\nprobabilistic skill, spectral fidelity, and rollout stability at subseasonal\ntimescales make it a strong candidate for improving meteorological forecasting\nand early warning systems through large ensemble predictions."}
{"id": "2507.12145", "pdf": "https://arxiv.org/pdf/2507.12145", "abs": "https://arxiv.org/abs/2507.12145", "authors": ["Muhammad Azlan Qazi", "Alexandros Iosifidis", "Qi Zhang"], "title": "PRISM: Distributed Inference for Foundation Models at Edge", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Foundation models (FMs) have achieved remarkable success across a wide range\nof applications, from image classification to natural langurage processing, but\npose significant challenges for deployment at edge. This has sparked growing\ninterest in developing practical and efficient strategies for bringing\nfoundation models to edge environments. In this work, we propose PRISM, a\ncommunication-efficient and compute-aware strategy for distributed Transformer\ninference on edge devices. Our method leverages a Segment Means representation\nto approximate intermediate output features, drastically reducing inter-device\ncommunication. Additionally, we restructure the self-attention mechanism to\neliminate redundant computations caused by per-device Key/Value calculation in\nposition-wise partitioning and design a partition-aware causal masking scheme\ntailored for autoregressive models. We evaluate PRISM on ViT, BERT, and GPT-2\nacross diverse datasets, namely CIFAR-10, CIFAR-100, ImageNet-1k, GLUE, and\nCBT. Our results demonstrate substantial reductions in communication overhead\n(up to 99.2% for BERT at compression rate CR = 128) and per-device computation\n(51.24% for BERT at the same setting), with only minor accuracy degradation.\nThis method offers a scalable and practical solution for deploying foundation\nmodels in distributed resource-constrained environments."}
{"id": "2507.12165", "pdf": "https://arxiv.org/pdf/2507.12165", "abs": "https://arxiv.org/abs/2507.12165", "authors": ["Fouad Oubari", "Mohamed El-Baha", "Raphael Meunier", "Rodrigue Décatoire", "Mathilde Mougeot"], "title": "Multi-Component VAE with Gaussian Markov Random Field", "categories": ["cs.LG"], "comment": null, "summary": "Multi-component datasets with intricate dependencies, like industrial\nassemblies or multi-modal imaging, challenge current generative modeling\ntechniques. Existing Multi-component Variational AutoEncoders typically rely on\nsimplified aggregation strategies, neglecting critical nuances and consequently\ncompromising structural coherence across generated components. To explicitly\naddress this gap, we introduce the Gaussian Markov Random Field Multi-Component\nVariational AutoEncoder , a novel generative framework embedding Gaussian\nMarkov Random Fields into both prior and posterior distributions. This design\nchoice explicitly models cross-component relationships, enabling richer\nrepresentation and faithful reproduction of complex interactions. Empirically,\nour GMRF MCVAE achieves state-of-the-art performance on a synthetic Copula\ndataset specifically constructed to evaluate intricate component relationships,\ndemonstrates competitive results on the PolyMNIST benchmark, and significantly\nenhances structural coherence on the real-world BIKED dataset. Our results\nindicate that the GMRF MCVAE is especially suited for practical applications\ndemanding robust and realistic modeling of multi-component coherence"}
{"id": "2507.12166", "pdf": "https://arxiv.org/pdf/2507.12166", "abs": "https://arxiv.org/abs/2507.12166", "authors": ["Xiucheng Wang", "Qiming Zhang", "Nan Cheng", "Junting Chen", "Zezhong Zhang", "Zan Li", "Shuguang Cui", "Xuemin Shen"], "title": "RadioDiff-3D: A 3D$\\times$3D Radio Map Dataset and Generative Diffusion Based Benchmark for 6G Environment-Aware Communication", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Radio maps (RMs) serve as a critical foundation for enabling\nenvironment-aware wireless communication, as they provide the spatial\ndistribution of wireless channel characteristics. Despite recent progress in RM\nconstruction using data-driven approaches, most existing methods focus solely\non pathloss prediction in a fixed 2D plane, neglecting key parameters such as\ndirection of arrival (DoA), time of arrival (ToA), and vertical spatial\nvariations. Such a limitation is primarily due to the reliance on static\nlearning paradigms, which hinder generalization beyond the training data\ndistribution. To address these challenges, we propose UrbanRadio3D, a\nlarge-scale, high-resolution 3D RM dataset constructed via ray tracing in\nrealistic urban environments. UrbanRadio3D is over 37$\\times$3 larger than\nprevious datasets across a 3D space with 3 metrics as pathloss, DoA, and ToA,\nforming a novel 3D$\\times$33D dataset with 7$\\times$3 more height layers than\nprior state-of-the-art (SOTA) dataset. To benchmark 3D RM construction, a UNet\nwith 3D convolutional operators is proposed. Moreover, we further introduce\nRadioDiff-3D, a diffusion-model-based generative framework utilizing the 3D\nconvolutional architecture. RadioDiff-3D supports both radiation-aware\nscenarios with known transmitter locations and radiation-unaware settings based\non sparse spatial observations. Extensive evaluations on UrbanRadio3D validate\nthat RadioDiff-3D achieves superior performance in constructing rich,\nhigh-dimensional radio maps under diverse environmental dynamics. This work\nprovides a foundational dataset and benchmark for future research in 3D\nenvironment-aware communication. The dataset is available at\nhttps://github.com/UNIC-Lab/UrbanRadio3D."}
{"id": "2507.12192", "pdf": "https://arxiv.org/pdf/2507.12192", "abs": "https://arxiv.org/abs/2507.12192", "authors": ["Victor F. Lopes de Souza", "Karima Bakhti", "Sofiane Ramdani", "Denis Mottet", "Abdelhak Imoussaten"], "title": "Explainable Evidential Clustering", "categories": ["cs.LG"], "comment": null, "summary": "Unsupervised classification is a fundamental machine learning problem.\nReal-world data often contain imperfections, characterized by uncertainty and\nimprecision, which are not well handled by traditional methods. Evidential\nclustering, based on Dempster-Shafer theory, addresses these challenges. This\npaper explores the underexplored problem of explaining evidential clustering\nresults, which is crucial for high-stakes domains such as healthcare. Our\nanalysis shows that, in the general case, representativity is a necessary and\nsufficient condition for decision trees to serve as abductive explainers.\nBuilding on the concept of representativity, we generalize this idea to\naccommodate partial labeling through utility functions. These functions enable\nthe representation of \"tolerable\" mistakes, leading to the definition of\nevidential mistakeness as explanation cost and the construction of explainers\ntailored to evidential classifiers. Finally, we propose the Iterative\nEvidential Mistake Minimization (IEMM) algorithm, which provides interpretable\nand cautious decision tree explanations for evidential clustering functions. We\nvalidate the proposed algorithm on synthetic and real-world data. Taking into\naccount the decision-maker's preferences, we were able to provide an\nexplanation that was satisfactory up to 93% of the time."}
{"id": "2507.12196", "pdf": "https://arxiv.org/pdf/2507.12196", "abs": "https://arxiv.org/abs/2507.12196", "authors": ["Nikolaos Louloudakis", "Ajitha Rajan"], "title": "Selective Quantization Tuning for ONNX Models", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": "5 pages, 3 figures, 2 tables", "summary": "Quantization is a process that reduces the precision of deep neural network\nmodels to lower model size and computational demands, often at the cost of\naccuracy. However, fully quantized models may exhibit sub-optimal performance\nbelow acceptable levels and face deployment challenges on low-end hardware\naccelerators due to practical constraints. To address these issues,\nquantization can be selectively applied to only a subset of layers, but\nselecting which layers to exclude is non-trivial. To this direction, we propose\nTuneQn, a suite enabling selective quantization, deployment and execution of\nONNX models across various CPU and GPU devices, combined with profiling and\nmulti-objective optimization. TuneQn generates selectively quantized ONNX\nmodels, deploys them on different hardware, measures performance on metrics\nlike accuracy and size, performs Pareto Front minimization to identify the best\nmodel candidate and visualizes the results. To demonstrate the effectiveness of\nTuneQn, we evaluated TuneQn on four ONNX models with two quantization settings\nacross CPU and GPU devices. As a result, we demonstrated that our utility\neffectively performs selective quantization and tuning, selecting ONNX model\ncandidates with up to a $54.14$% reduction in accuracy loss compared to the\nfully quantized model, and up to a $72.9$% model size reduction compared to the\noriginal model."}
{"id": "2507.12218", "pdf": "https://arxiv.org/pdf/2507.12218", "abs": "https://arxiv.org/abs/2507.12218", "authors": ["Tomohisa Okazaki"], "title": "Physics-Informed Linear Model (PILM): Analytical Representations and Application to Crustal Strain Rate Estimation", "categories": ["cs.LG", "physics.geo-ph"], "comment": null, "summary": "Many physical systems are described by partial differential equations (PDEs),\nand solving these equations and estimating their coefficients or boundary\nconditions (BCs) from observational data play a crucial role in understanding\nthe associated phenomena. Recently, a machine learning approach known as\nphysics-informed neural network, which solves PDEs using neural networks by\nminimizing the sum of residuals from the PDEs, BCs, and data, has gained\nsignificant attention in the scientific community. In this study, we\ninvestigate a physics-informed linear model (PILM) that uses linear\ncombinations of basis functions to represent solutions, thereby enabling an\nanalytical representation of optimal solutions. The PILM was formulated and\nverified for illustrative forward and inverse problems including cases with\nuncertain BCs. Furthermore, the PILM was applied to estimate crustal strain\nrates using geodetic data. Specifically, physical regularization that enforces\nelastic equilibrium on the velocity fields was compared with mathematical\nregularization that imposes smoothness constraints. From a Bayesian\nperspective, mathematical regularization exhibited superior performance. The\nPILM provides an analytically solvable framework applicable to linear forward\nand inverse problems, underdetermined systems, and physical regularization."}
{"id": "2507.12224", "pdf": "https://arxiv.org/pdf/2507.12224", "abs": "https://arxiv.org/abs/2507.12224", "authors": ["Razvan Pascanu", "Clare Lyle", "Ionut-Vlad Modoranu", "Naima Elosegui Borras", "Dan Alistarh", "Petar Velickovic", "Sarath Chandar", "Soham De", "James Martens"], "title": "Optimizers Qualitatively Alter Solutions And We Should Leverage This", "categories": ["cs.LG"], "comment": null, "summary": "Due to the nonlinear nature of Deep Neural Networks (DNNs), one can not\nguarantee convergence to a unique global minimum of the loss when using\noptimizers relying only on local information, such as SGD. Indeed, this was a\nprimary source of skepticism regarding the feasibility of DNNs in the early\ndays of the field. The past decades of progress in deep learning have revealed\nthis skepticism to be misplaced, and a large body of empirical evidence shows\nthat sufficiently large DNNs following standard training protocols exhibit\nwell-behaved optimization dynamics that converge to performant solutions. This\nsuccess has biased the community to use convex optimization as a mental model\nfor learning, leading to a focus on training efficiency, either in terms of\nrequired iteration, FLOPs or wall-clock time, when improving optimizers. We\nargue that, while this perspective has proven extremely fruitful, another\nperspective specific to DNNs has received considerably less attention: the\noptimizer not only influences the rate of convergence, but also the qualitative\nproperties of the learned solutions. Restated, the optimizer can and will\nencode inductive biases and change the effective expressivity of a given class\nof models. Furthermore, we believe the optimizer can be an effective way of\nencoding desiderata in the learning process. We contend that the community\nshould aim at understanding the biases of already existing methods, as well as\naim to build new optimizers with the explicit intent of inducing certain\nproperties of the solution, rather than solely judging them based on their\nconvergence rates. We hope our arguments will inspire research to improve our\nunderstanding of how the learning process can impact the type of solution we\nconverge to, and lead to a greater recognition of optimizers design as a\ncritical lever that complements the roles of architecture and data in shaping\nmodel outcomes."}
{"id": "2507.12257", "pdf": "https://arxiv.org/pdf/2507.12257", "abs": "https://arxiv.org/abs/2507.12257", "authors": ["Matteo Tusoni", "Giuseppe Masi", "Andrea Coletta", "Aldo Glielmo", "Viviana Arrigoni", "Novella Bartolini"], "title": "Robust Causal Discovery in Real-World Time Series with Power-Laws", "categories": ["cs.LG", "physics.data-an", "stat.ML", "stat.OT"], "comment": null, "summary": "Exploring causal relationships in stochastic time series is a challenging yet\ncrucial task with a vast range of applications, including finance, economics,\nneuroscience, and climate science. Many algorithms for Causal Discovery (CD)\nhave been proposed, but they often exhibit a high sensitivity to noise,\nresulting in misleading causal inferences when applied to real data. In this\npaper, we observe that the frequency spectra of typical real-world time series\nfollow a power-law distribution, notably due to an inherent self-organizing\nbehavior. Leveraging this insight, we build a robust CD method based on the\nextraction of power -law spectral features that amplify genuine causal signals.\nOur method consistently outperforms state-of-the-art alternatives on both\nsynthetic benchmarks and real-world datasets with known causal structures,\ndemonstrating its robustness and practical relevance."}
{"id": "2507.12262", "pdf": "https://arxiv.org/pdf/2507.12262", "abs": "https://arxiv.org/abs/2507.12262", "authors": ["Zachary James", "Joseph Guinness"], "title": "A Framework for Nonstationary Gaussian Processes with Neural Network Parameters", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "comment": null, "summary": "Gaussian processes have become a popular tool for nonparametric regression\nbecause of their flexibility and uncertainty quantification. However, they\noften use stationary kernels, which limit the expressiveness of the model and\nmay be unsuitable for many datasets. We propose a framework that uses\nnonstationary kernels whose parameters vary across the feature space, modeling\nthese parameters as the output of a neural network that takes the features as\ninput. The neural network and Gaussian process are trained jointly using the\nchain rule to calculate derivatives. Our method clearly describes the behavior\nof the nonstationary parameters and is compatible with approximation methods\nfor scaling to large datasets. It is flexible and easily adapts to different\nnonstationary kernels without needing to redesign the optimization procedure.\nOur methods are implemented with the GPyTorch library and can be readily\nmodified. We test a nonstationary variance and noise variant of our method on\nseveral machine learning datasets and find that it achieves better accuracy and\nlog-score than both a stationary model and a hierarchical model approximated\nwith variational inference. Similar results are observed for a model with only\nnonstationary variance. We also demonstrate our approach's ability to recover\nthe nonstationary parameters of a spatial dataset."}
{"id": "2507.12297", "pdf": "https://arxiv.org/pdf/2507.12297", "abs": "https://arxiv.org/abs/2507.12297", "authors": ["Yuan-Chen Shu", "Zhiwei Lin", "Yongtao Wang"], "title": "RegCL: Continual Adaptation of Segment Anything Model via Model Merging", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "To address the performance limitations of the Segment Anything Model (SAM) in\nspecific domains, existing works primarily adopt adapter-based one-step\nadaptation paradigms. However, some of these methods are specific developed for\nspecific domains. If used on other domains may lead to performance degradation.\nThis issue of catastrophic forgetting severely limits the model's scalability.\nTo address this issue, this paper proposes RegCL, a novel non-replay continual\nlearning (CL) framework designed for efficient multi-domain knowledge\nintegration through model merging. Specifically, RegCL incorporates the model\nmerging algorithm into the continual learning paradigm by merging the\nparameters of SAM's adaptation modules (e.g., LoRA modules) trained on\ndifferent domains. The merging process is guided by weight optimization, which\nminimizes prediction discrepancies between the merged model and each of the\ndomain-specific models. RegCL effectively consolidates multi-domain knowledge\nwhile maintaining parameter efficiency, i.e., the model size remains constant\nregardless of the number of tasks, and no historical data storage is required.\nExperimental results demonstrate that RegCL achieves favorable continual\nlearning performance across multiple downstream datasets, validating its\neffectiveness in dynamic scenarios."}
{"id": "2507.12305", "pdf": "https://arxiv.org/pdf/2507.12305", "abs": "https://arxiv.org/abs/2507.12305", "authors": ["M. Anwar Ma'sum", "Mahardhika Pratama", "Savitha Ramasamy", "Lin Liu", "Habibullah Habibullah", "Ryszard Kowalczyk"], "title": "PROL : Rehearsal Free Continual Learning in Streaming Data via Prompt Online Learning", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "ICCV 2025", "summary": "The data privacy constraint in online continual learning (OCL), where the\ndata can be seen only once, complicates the catastrophic forgetting problem in\nstreaming data. A common approach applied by the current SOTAs in OCL is with\nthe use of memory saving exemplars or features from previous classes to be\nreplayed in the current task. On the other hand, the prompt-based approach\nperforms excellently in continual learning but with the cost of a growing\nnumber of trainable parameters. The first approach may not be applicable in\npractice due to data openness policy, while the second approach has the issue\nof throughput associated with the streaming data. In this study, we propose a\nnovel prompt-based method for online continual learning that includes 4 main\ncomponents: (1) single light-weight prompt generator as a general knowledge,\n(2) trainable scaler-and-shifter as specific knowledge, (3) pre-trained model\n(PTM) generalization preserving, and (4) hard-soft updates mechanism. Our\nproposed method achieves significantly higher performance than the current\nSOTAs in CIFAR100, ImageNet-R, ImageNet-A, and CUB dataset. Our complexity\nanalysis shows that our method requires a relatively smaller number of\nparameters and achieves moderate training time, inference time, and throughput.\nFor further study, the source code of our method is available at\nhttps://github.com/anwarmaxsum/PROL."}
{"id": "2507.12314", "pdf": "https://arxiv.org/pdf/2507.12314", "abs": "https://arxiv.org/abs/2507.12314", "authors": ["Zihao Xue", "Zhen Bi", "Long Ma", "Zhenlin Hu", "Yan Wang", "Zhenfang Liu", "Qing Sheng", "Jie Xiao", "Jungang Lou"], "title": "Thought Purity: Defense Paradigm For Chain-of-Thought Attack", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.CR"], "comment": null, "summary": "While reinforcement learning-trained Large Reasoning Models (LRMs, e.g.,\nDeepseek-R1) demonstrate advanced reasoning capabilities in the evolving Large\nLanguage Models (LLMs) domain, their susceptibility to security threats remains\na critical vulnerability. This weakness is particularly evident in\nChain-of-Thought (CoT) generation processes, where adversarial methods like\nbackdoor prompt attacks can systematically subvert the model's core reasoning\nmechanisms. The emerging Chain-of-Thought Attack (CoTA) reveals this\nvulnerability through exploiting prompt controllability, simultaneously\ndegrading both CoT safety and task performance with low-cost interventions. To\naddress this compounded security-performance vulnerability, we propose Thought\nPurity (TP): a defense paradigm that systematically strengthens resistance to\nmalicious content while preserving operational efficacy. Our solution achieves\nthis through three synergistic components: (1) a safety-optimized data\nprocessing pipeline (2) reinforcement learning-enhanced rule constraints (3)\nadaptive monitoring metrics. Our approach establishes the first comprehensive\ndefense mechanism against CoTA vulnerabilities in reinforcement\nlearning-aligned reasoning systems, significantly advancing the\nsecurity-functionality equilibrium for next-generation AI architectures."}
{"id": "2507.12341", "pdf": "https://arxiv.org/pdf/2507.12341", "abs": "https://arxiv.org/abs/2507.12341", "authors": ["Antoine Saillenfest", "Pirmin Lemberger"], "title": "Nonlinear Concept Erasure: a Density Matching Approach", "categories": ["cs.LG", "cs.CL"], "comment": "17 pages, 10 figures, accepted for publication in ECAI 2025 (28th\n  European Conference on Artificial Intelligence)", "summary": "Ensuring that neural models used in real-world applications cannot infer\nsensitive information, such as demographic attributes like gender or race, from\ntext representations is a critical challenge when fairness is a concern. We\naddress this issue through concept erasure, a process that removes information\nrelated to a specific concept from distributed representations while preserving\nas much of the remaining semantic information as possible. Our approach\ninvolves learning an orthogonal projection in the embedding space, designed to\nmake the class-conditional feature distributions of the discrete concept to\nerase indistinguishable after projection. By adjusting the rank of the\nprojector, we control the extent of information removal, while its\northogonality ensures strict preservation of the local structure of the\nembeddings. Our method, termed $\\overline{\\mathrm{L}}$EOPARD, achieves\nstate-of-the-art performance in nonlinear erasure of a discrete attribute on\nclassic natural language processing benchmarks. Furthermore, we demonstrate\nthat $\\overline{\\mathrm{L}}$EOPARD effectively mitigates bias in deep nonlinear\nclassifiers, thereby promoting fairness."}
{"id": "2507.12380", "pdf": "https://arxiv.org/pdf/2507.12380", "abs": "https://arxiv.org/abs/2507.12380", "authors": ["Maximilian Krahn", "Vikas Garg"], "title": "Heat Kernel Goes Topological", "categories": ["cs.LG"], "comment": null, "summary": "Topological neural networks have emerged as powerful successors of graph\nneural networks. However, they typically involve higher-order message passing,\nwhich incurs significant computational expense. We circumvent this issue with a\nnovel topological framework that introduces a Laplacian operator on\ncombinatorial complexes (CCs), enabling efficient computation of heat kernels\nthat serve as node descriptors. Our approach captures multiscale information\nand enables permutation-equivariant representations, allowing easy integration\ninto modern transformer-based architectures.\n  Theoretically, the proposed method is maximally expressive because it can\ndistinguish arbitrary non-isomorphic CCs. Empirically, it significantly\noutperforms existing topological methods in terms of computational efficiency.\nBesides demonstrating competitive performance with the state-of-the-art\ndescriptors on standard molecular datasets, it exhibits superior capability in\ndistinguishing complex topological structures and avoiding blind spots on\ntopological benchmarks. Overall, this work advances topological deep learning\nby providing expressive yet scalable representations, thereby opening up\nexciting avenues for molecular classification and property prediction tasks."}
{"id": "2507.12383", "pdf": "https://arxiv.org/pdf/2507.12383", "abs": "https://arxiv.org/abs/2507.12383", "authors": ["Mohit Prashant", "Arvind Easwaran"], "title": "Improving Reinforcement Learning Sample-Efficiency using Local Approximation", "categories": ["cs.LG"], "comment": "Preprint", "summary": "In this study, we derive Probably Approximately Correct (PAC) bounds on the\nasymptotic sample-complexity for RL within the infinite-horizon Markov Decision\nProcess (MDP) setting that are sharper than those in existing literature. The\npremise of our study is twofold: firstly, the further two states are from each\nother, transition-wise, the less relevant the value of the first state is when\nlearning the $\\epsilon$-optimal value of the second; secondly, the amount of\n'effort', sample-complexity-wise, expended in learning the $\\epsilon$-optimal\nvalue of a state is independent of the number of samples required to learn the\n$\\epsilon$-optimal value of a second state that is a sufficient number of\ntransitions away from the first. Inversely, states within each other's vicinity\nhave values that are dependent on each other and will require a similar number\nof samples to learn. By approximating the original MDP using smaller MDPs\nconstructed using subsets of the original's state-space, we are able to reduce\nthe sample-complexity by a logarithmic factor to $O(SA \\log A)$ timesteps,\nwhere $S$ and $A$ are the state and action space sizes. We are able to extend\nthese results to an infinite-horizon, model-free setting by constructing a\nPAC-MDP algorithm with the aforementioned sample-complexity. We conclude with\nshowing how significant the improvement is by comparing our algorithm against\nprior work in an experimental setting."}
{"id": "2507.12384", "pdf": "https://arxiv.org/pdf/2507.12384", "abs": "https://arxiv.org/abs/2507.12384", "authors": ["Bo Wen", "Guoyun Gao", "Zhicheng Xu", "Ruibin Mao", "Xiaojuan Qi", "X. Sharon Hu", "Xunzhao Yin", "Can Li"], "title": "Trustworthy Tree-based Machine Learning by $MoS_2$ Flash-based Analog CAM with Inherent Soft Boundaries", "categories": ["cs.LG", "cs.ET"], "comment": null, "summary": "The rapid advancement of artificial intelligence has raised concerns\nregarding its trustworthiness, especially in terms of interpretability and\nrobustness. Tree-based models like Random Forest and XGBoost excel in\ninterpretability and accuracy for tabular data, but scaling them remains\ncomputationally expensive due to poor data locality and high data dependence.\nPrevious efforts to accelerate these models with analog content addressable\nmemory (CAM) have struggled, due to the fact that the difficult-to-implement\nsharp decision boundaries are highly susceptible to device variations, which\nleads to poor hardware performance and vulnerability to adversarial attacks.\nThis work presents a novel hardware-software co-design approach using $MoS_2$\nFlash-based analog CAM with inherent soft boundaries, enabling efficient\ninference with soft tree-based models. Our soft tree model inference\nexperiments on $MoS_2$ analog CAM arrays show this method achieves exceptional\nrobustness against device variation and adversarial attacks while achieving\nstate-of-the-art accuracy. Specifically, our fabricated analog CAM arrays\nachieve $96\\%$ accuracy on Wisconsin Diagnostic Breast Cancer (WDBC) database,\nwhile maintaining decision explainability. Our experimentally calibrated model\nvalidated only a $0.6\\%$ accuracy drop on the MNIST dataset under $10\\%$ device\nthreshold variation, compared to a $45.3\\%$ drop for traditional decision\ntrees. This work paves the way for specialized hardware that enhances AI's\ntrustworthiness and efficiency."}
{"id": "2507.12399", "pdf": "https://arxiv.org/pdf/2507.12399", "abs": "https://arxiv.org/abs/2507.12399", "authors": ["Florian E. Dorner", "Yatong Chen", "André F. Cruz", "Fanny Yang"], "title": "ROC-n-reroll: How verifier imperfection affects test-time scaling", "categories": ["cs.LG", "stat.ML"], "comment": "35 pages, 9 Figures", "summary": "Test-time scaling aims to improve language model performance by leveraging\nadditional compute during inference. While many works have empirically studied\ntechniques like Best-of-N (BoN) and rejection sampling that make use of a\nverifier to enable test-time scaling, there is little theoretical understanding\nof how verifier imperfection affects performance. In this work, we address this\ngap. Specifically, we prove how instance-level accuracy of these methods is\nprecisely characterized by the geometry of the verifier's ROC curve.\nInterestingly, while scaling is determined by the local geometry of the ROC\ncurve for rejection sampling, it depends on global properties of the ROC curve\nfor BoN. As a consequence when the ROC curve is unknown, it is impossible to\nextrapolate the performance of rejection sampling based on the low-compute\nregime. Furthermore, while rejection sampling outperforms BoN for fixed\ncompute, in the infinite-compute limit both methods converge to the same level\nof accuracy, determined by the slope of the ROC curve near the origin. Our\ntheoretical results are confirmed by experiments on GSM8K using different\nversions of Llama and Qwen to generate and verify solutions."}
{"id": "2507.12412", "pdf": "https://arxiv.org/pdf/2507.12412", "abs": "https://arxiv.org/abs/2507.12412", "authors": ["Dzung Dinh", "Boqi Chen", "Marc Niethammer", "Junier Oliva"], "title": "NOCTA: Non-Greedy Objective Cost-Tradeoff Acquisition for Longitudinal Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In many critical applications, resource constraints limit the amount of\ninformation that can be gathered to make predictions. For example, in\nhealthcare, patient data often spans diverse features ranging from lab tests to\nimaging studies. Each feature may carry different information and must be\nacquired at a respective cost of time, money, or risk to the patient. Moreover,\ntemporal prediction tasks, where both instance features and labels evolve over\ntime, introduce additional complexity in deciding when or what information is\nimportant. In this work, we propose NOCTA, a Non-Greedy Objective Cost-Tradeoff\nAcquisition method that sequentially acquires the most informative features at\ninference time while accounting for both temporal dynamics and acquisition\ncost. We first introduce a cohesive estimation target for our NOCTA setting,\nand then develop two complementary estimators: 1) a non-parametric method based\non nearest neighbors to guide the acquisition (NOCTA-NP), and 2) a parametric\nmethod that directly predicts the utility of potential acquisitions (NOCTA-P).\nExperiments on synthetic and real-world medical datasets demonstrate that both\nNOCTA variants outperform existing baselines."}
{"id": "2507.12419", "pdf": "https://arxiv.org/pdf/2507.12419", "abs": "https://arxiv.org/abs/2507.12419", "authors": ["Andrea Perin", "Giacomo Lagomarsini", "Claudio Gallicchio", "Giuseppe Nuti"], "title": "Mixture of Raytraced Experts", "categories": ["cs.LG", "cs.AI"], "comment": "Preliminary version (pre-submission)", "summary": "We introduce a Mixture of Raytraced Experts, a stacked Mixture of Experts\n(MoE) architecture which can dynamically select sequences of experts, producing\ncomputational graphs of variable width and depth. Existing MoE architectures\ngenerally require a fixed amount of computation for a given sample. Our\napproach, in contrast, yields predictions with increasing accuracy as the\ncomputation cycles through the experts' sequence. We train our model by\niteratively sampling from a set of candidate experts, unfolding the sequence\nakin to how Recurrent Neural Networks are trained. Our method does not require\nload-balancing mechanisms, and preliminary experiments show a reduction in\ntraining epochs of 10\\% to 40\\% with a comparable/higher accuracy. These\nresults point to new research directions in the field of MoEs, allowing the\ndesign of potentially faster and more expressive models. The code is available\nat https://github.com/nutig/RayTracing"}
{"id": "2507.12435", "pdf": "https://arxiv.org/pdf/2507.12435", "abs": "https://arxiv.org/abs/2507.12435", "authors": ["Yi Li", "David Mccoy", "Nolan Gunter", "Kaitlyn Lee", "Alejandro Schuler", "Mark van der Laan"], "title": "Targeted Deep Architectures: A TMLE-Based Framework for Robust Causal Inference in Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Modern deep neural networks are powerful predictive tools yet often lack\nvalid inference for causal parameters, such as treatment effects or entire\nsurvival curves. While frameworks like Double Machine Learning (DML) and\nTargeted Maximum Likelihood Estimation (TMLE) can debias machine-learning fits,\nexisting neural implementations either rely on \"targeted losses\" that do not\nguarantee solving the efficient influence function equation or computationally\nexpensive post-hoc \"fluctuations\" for multi-parameter settings. We propose\nTargeted Deep Architectures (TDA), a new framework that embeds TMLE directly\ninto the network's parameter space with no restrictions on the backbone\narchitecture. Specifically, TDA partitions model parameters - freezing all but\na small \"targeting\" subset - and iteratively updates them along a targeting\ngradient, derived from projecting the influence functions onto the span of the\ngradients of the loss with respect to weights. This procedure yields plug-in\nestimates that remove first-order bias and produce asymptotically valid\nconfidence intervals. Crucially, TDA easily extends to multi-dimensional causal\nestimands (e.g., entire survival curves) by merging separate targeting\ngradients into a single universal targeting update. Theoretically, TDA inherits\nclassical TMLE properties, including double robustness and semiparametric\nefficiency. Empirically, on the benchmark IHDP dataset (average treatment\neffects) and simulated survival data with informative censoring, TDA reduces\nbias and improves coverage relative to both standard neural-network estimators\nand prior post-hoc approaches. In doing so, TDA establishes a direct, scalable\npathway toward rigorous causal inference within modern deep architectures for\ncomplex multi-parameter targets."}
{"id": "2507.12439", "pdf": "https://arxiv.org/pdf/2507.12439", "abs": "https://arxiv.org/abs/2507.12439", "authors": ["Daniel Commey", "Rebecca A. Sarpong", "Griffith S. Klogo", "Winful Bagyl-Bac", "Garth V. Crosby"], "title": "A Bayesian Incentive Mechanism for Poison-Resilient Federated Learning", "categories": ["cs.LG", "cs.CR", "cs.GT"], "comment": null, "summary": "Federated learning (FL) enables collaborative model training across\ndecentralized clients while preserving data privacy. However, its\nopen-participation nature exposes it to data-poisoning attacks, in which\nmalicious actors submit corrupted model updates to degrade the global model.\nExisting defenses are often reactive, relying on statistical aggregation rules\nthat can be computationally expensive and that typically assume an honest\nmajority. This paper introduces a proactive, economic defense: a lightweight\nBayesian incentive mechanism that makes malicious behavior economically\nirrational. Each training round is modeled as a Bayesian game of incomplete\ninformation in which the server, acting as the principal, uses a small, private\nvalidation dataset to verify update quality before issuing payments. The design\nsatisfies Individual Rationality (IR) for benevolent clients, ensuring their\nparticipation is profitable, and Incentive Compatibility (IC), making poisoning\nan economically dominated strategy. Extensive experiments on non-IID partitions\nof MNIST and FashionMNIST demonstrate robustness: with 50% label-flipping\nadversaries on MNIST, the mechanism maintains 96.7% accuracy, only 0.3\npercentage points lower than in a scenario with 30% label-flipping adversaries.\nThis outcome is 51.7 percentage points better than standard FedAvg, which\ncollapses under the same 50% attack. The mechanism is computationally light,\nbudget-bounded, and readily integrates into existing FL frameworks, offering a\npractical route to economically robust and sustainable FL ecosystems."}
{"id": "2507.12453", "pdf": "https://arxiv.org/pdf/2507.12453", "abs": "https://arxiv.org/abs/2507.12453", "authors": ["Qian Xie", "Linda Cai", "Alexander Terenin", "Peter I. Frazier", "Ziv Scully"], "title": "Cost-aware Stopping for Bayesian Optimization", "categories": ["cs.LG"], "comment": null, "summary": "In automated machine learning, scientific discovery, and other applications\nof Bayesian optimization, deciding when to stop evaluating expensive black-box\nfunctions is an important practical consideration. While several adaptive\nstopping rules have been proposed, in the cost-aware setting they lack\nguarantees ensuring they stop before incurring excessive function evaluation\ncosts. We propose a cost-aware stopping rule for Bayesian optimization that\nadapts to varying evaluation costs and is free of heuristic tuning. Our rule is\ngrounded in a theoretical connection to state-of-the-art cost-aware acquisition\nfunctions, namely the Pandora's Box Gittins Index (PBGI) and log expected\nimprovement per cost. We prove a theoretical guarantee bounding the expected\ncumulative evaluation cost incurred by our stopping rule when paired with these\ntwo acquisition functions. In experiments on synthetic and empirical tasks,\nincluding hyperparameter optimization and neural architecture size search, we\nshow that combining our stopping rule with the PBGI acquisition function\nconsistently matches or outperforms other acquisition-function--stopping-rule\npairs in terms of cost-adjusted simple regret, a metric capturing trade-offs\nbetween solution quality and cumulative evaluation cost."}
{"id": "2507.11662", "pdf": "https://arxiv.org/pdf/2507.11662", "abs": "https://arxiv.org/abs/2507.11662", "authors": ["Moises Andrade", "Joonhyuk Cha", "Brandon Ho", "Vriksha Srihari", "Karmesh Yadav", "Zsolt Kira"], "title": "Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "cs.RO"], "comment": "Our code and data are publicly available at\n  https://github.com/mshalimay/mllm-verifiers-abias-sgv", "summary": "Verifiers -- functions assigning rewards to agent behavior -- have been key\nfor AI progress in domains like math and board games. However, extending these\ngains to domains without clear-cut success criteria (e.g.,computer use) remains\na challenge: while humans can recognize suitable outcomes, translating this\nintuition into scalable rules is non-trivial. Multimodal Large Language\nModels(MLLMs) emerge as a promising solution, given their world knowledge,\nhuman-preference alignment, and reasoning skills. We evaluate MLLMs as\nverifiers of agent trajectories across web navigation, computer use, and\nrobotic manipulation, and identify a critical limitation: agreement bias, a\nstrong tendency for MLLMs to favor information in their context window, often\ngenerating chains of thought to rationalize flawed behavior. This bias is\npervasive across models, resilient to test-time scaling, and can impact several\nmethods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs\ndespite MLLMs showing strong, human-aligned priors on desired behavior. To\naddress this, we propose Self-Grounded Verification (SGV), a lightweight method\nthat enables more effective use of MLLMs' knowledge and reasoning by harnessing\ntheir own sampling mechanisms via unconditional and conditional generation. SGV\noperates in two steps: first, the MLLM is elicited to retrieve broad priors\nabout task completion, independent of the data under evaluation. Then,\nconditioned on self-generated priors, it reasons over and evaluates a candidate\ntrajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in\naccuracy and failure detection rates, and can perform real-time supervision of\nheterogeneous agents, boosting task completion of a GUI specialist in OSWorld,\na diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting\na new state of the art on the benchmark, surpassing the previous best by 48%."}
{"id": "2507.12003", "pdf": "https://arxiv.org/pdf/2507.12003", "abs": "https://arxiv.org/abs/2507.12003", "authors": ["Cara Ellen Appel"], "title": "Expanding ML-Documentation Standards For Better Security", "categories": ["cs.CR", "cs.LG", "cs.SE"], "comment": "Accepted for publication at the 33rd IEEE International Requirements\n  Engineering Workshop (REW 2025)", "summary": "This article presents the current state of ML-security and of the\ndocumentation of ML-based systems, models and datasets in research and practice\nbased on an extensive review of the existing literature. It shows a generally\nlow awareness of security aspects among ML-practitioners and organizations and\nan often unstandardized approach to documentation, leading to overall low\nquality of ML-documentation. Existing standards are not regularly adopted in\npractice and IT-security aspects are often not included in documentation. Due\nto these factors, there is a clear need for improved security documentation in\nML, as one step towards addressing the existing gaps in ML-security. To achieve\nthis, we propose expanding existing documentation standards for\nML-documentation to include a security section with specific security relevant\ninformation. Implementing this, a novel expanded method of documenting security\nrequirements in ML-documentation is presented, based on the existing Model\nCards and Datasheets for Datasets standards, but with the recommendation to\nadopt these findings in all ML-documentation."}
{"id": "2507.12098", "pdf": "https://arxiv.org/pdf/2507.12098", "abs": "https://arxiv.org/abs/2507.12098", "authors": ["Xiang Li", "Yifan Lin", "Yuanzhe Zhang"], "title": "A Privacy-Preserving Framework for Advertising Personalization Incorporating Federated Learning and Differential Privacy", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "To mitigate privacy leakage and performance issues in personalized\nadvertising, this paper proposes a framework that integrates federated learning\nand differential privacy. The system combines distributed feature extraction,\ndynamic privacy budget allocation, and robust model aggregation to balance\nmodel accuracy, communication overhead, and privacy protection. Multi-party\nsecure computing and anomaly detection mechanisms further enhance system\nresilience against malicious attacks. Experimental results demonstrate that the\nframework achieves dual optimization of recommendation accuracy and system\nefficiency while ensuring privacy, providing both a practical solution and a\ntheoretical foundation for applying privacy protection technologies in\nadvertisement recommendation."}
