<div id=toc></div>

# 目录

- [cs.AI](#cs.AI) [总数: 30]
- [cs.CL](#cs.CL) [总数: 28]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [PhysMaster: Building an Autonomous AI Physicist for Theoretical and Computational Physics Research](https://arxiv.org/abs/2512.19799)
*Tingjia Miao, Jiawen Dai, Jingkun Liu, Jinxin Tan, Muhua Zhang, Wenkai Jin, Yuwen Du, Tian Jin, Xianghe Pang, Zexi Liu, Tu Guo, Zhengliang Zhang, Yunjie Huang, Shuo Chen, Rui Ye, Yuzhi Zhang, Linfeng Zhang, Kun Chen, Wei Wang, Weinan E, Siheng Chen*

**主要类别:** cs.AI

**AI概要:** N/A


<details>
  <summary>更多</summary>
  
**动机:** N/A

**方法:** N/A

**结果:** N/A

**结论:** N/A

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PhysMaster%3A+Building+an+Autonomous+AI+Physicist+for+Theoretical+and+Computational+Physics+Research，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.19799，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.19799&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Advances in LLMs have produced agents with knowledge and operational capabilities comparable to human scientists, suggesting potential to assist, accelerate, and automate research. However, existing studies mainly evaluate such systems on well-defined benchmarks or general tasks like literature retrieval, limiting their end-to-end problem-solving ability in open scientific scenarios. This is particularly true in physics, which is abstract, mathematically intensive, and requires integrating analytical reasoning with code-based computation. To address this, we propose PhysMaster, an LLM-based agent functioning as an autonomous theoretical and computational physicist. PhysMaster couples absract reasoning with numerical computation and leverages LANDAU, the Layered Academic Data Universe, which preserves retrieved literature, curated prior knowledge, and validated methodological traces, enhancing decision reliability and stability. It also employs an adaptive exploration strategy balancing efficiency and open-ended exploration, enabling robust performance in ultra-long-horizon tasks. We evaluate PhysMaster on problems from high-energy theory, condensed matter theory to astrophysics, including: (i) acceleration, compressing labor-intensive research from months to hours; (ii) automation, autonomously executing hypothesis-driven loops ; and (iii) autonomous discovery, independently exploring open problems.

</details>


### [2] [A Branch-and-Price Algorithm for Fast and Equitable Last-Mile Relief Aid Distribution](https://arxiv.org/abs/2512.19882)
*Mahdi Mostajabdaveh, F. Sibel Salman, Walter J. Gutjahr*

**主要类别:** cs.AI

**AI概要:** 本文提出一个双目标优化模型，用于灾后救援物资分配，同时最小化需求不满足的不公平性（基于基尼系数）和总运输时间。通过混合整数规划和分支定价算法，实现在土耳其Van地震和伊斯坦布尔Kartal地区案例中，不公平性降低34%且不牺牲效率。


<details>
  <summary>更多</summary>
  
**动机:** 重大灾害中预置物资常无法满足所有需求，需要平衡救援物资分配的效率与公平性，确保及时且公平地向避难所配送有限物资。

**方法:** 建立双目标混合整数规划模型，使用ε-约束方法处理多目标优化，推导最优解数学性质并引入有效不等式，开发分支定价算法进行高效求解。

**结果:** 计算测试显示分支定价算法显著优于商业求解器，双目标方法使援助分配不公平性降低34%而不影响效率。时间约束极宽松或紧张时，优先需求覆盖的词典优化有效；中等时间约束需要平衡方法避免不公平结果。

**结论:** 研究提供了有效的灾后物资分配优化方法，通过数学建模和算法设计成功平衡了效率与公平目标，为应急物流决策提供了实用工具和重要见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Branch-and-Price+Algorithm+for+Fast+and+Equitable+Last-Mile+Relief+Aid+Distribution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.19882，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.19882&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The distribution of relief supplies to shelters is a critical aspect of post-disaster humanitarian logistics. In major disasters, prepositioned supplies often fall short of meeting all demands. We address the problem of planning vehicle routes from a distribution center to shelters while allocating limited relief supplies. To balance efficiency and equity, we formulate a bi-objective problem: minimizing a Gini-index-based measure of inequity in unsatisfied demand for fair distribution and minimizing total travel time for timely delivery. We propose a Mixed Integer Programming (MIP) model and use the $ε$-constraint method to handle the bi-objective nature. By deriving mathematical properties of the optimal solution, we introduce valid inequalities and design an algorithm for optimal delivery allocations given feasible vehicle routes. A branch-and-price (B&P) algorithm is developed to solve the problem efficiently. Computational tests on realistic datasets from a past earthquake in Van, Turkey, and predicted data for Istanbul's Kartal region show that the B&P algorithm significantly outperforms commercial MIP solvers. Our bi-objective approach reduces aid distribution inequity by 34% without compromising efficiency. Results indicate that when time constraints are very loose or tight, lexicographic optimization prioritizing demand coverage over fairness is effective. For moderately restrictive time constraints, a balanced approach is essential to avoid inequitable outcomes.

</details>


### [3] [Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs](https://arxiv.org/abs/2512.19937)
*Eric Yeh, John Cadigan, Ran Chen, Dick Crouch, Melinda Gervasio, Dayne Freitag*

**主要类别:** cs.AI

**AI概要:** 该研究使用插值解码方法，通过一对对立提示词和插值参数来模拟人格维度，使大语言模型能够可靠地模拟人类在Big Five人格维度上的行为，并在经济游戏中复现人类决策行为。


<details>
  <summary>更多</summary>
  
**动机:** 解决传统方法中需要为每个人格特征创建单独提示词的问题，这种方法增加了实验负担并降低了可复现性。

**方法:** 采用插值解码技术，将每个人格维度表示为一对对立提示词，并使用插值参数来沿该维度模拟行为。

**结果:** 插值解码能够可靠地调节Big Five各维度的得分，使LLMs能够模仿人类在经济游戏中的决策行为，并复现人类心理学研究结果。

**结论:** 插值解码提供了一种有效的方法来模拟人格对决策的影响，能够系统性地搜索插值空间来复现个体人类玩家的行为，为人类行为假设测试提供了新工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interpolative+Decoding%3A+Exploring+the+Spectrum+of+Personality+Traits+in+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.19937，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.19937&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recent research has explored using very large language models (LLMs) as proxies for humans in tasks such as simulation, surveys, and studies. While LLMs do not possess a human psychology, they often can emulate human behaviors with sufficiently high fidelity to drive simulations to test human behavioral hypotheses, exhibiting more nuance and range than the rule-based agents often employed in behavioral economics. One key area of interest is the effect of personality on decision making, but the requirement that a prompt must be created for every tested personality profile introduces experimental overhead and degrades replicability. To address this issue, we leverage interpolative decoding, representing each dimension of personality as a pair of opposed prompts and employing an interpolation parameter to simulate behavior along the dimension. We show that interpolative decoding reliably modulates scores along each of the Big Five dimensions. We then show how interpolative decoding causes LLMs to mimic human decision-making behavior in economic games, replicating results from human psychological research. Finally, we present preliminary results of our efforts to ``twin'' individual human players in a collaborative game through systematic search for points in interpolation space that cause the system to replicate actions taken by the human subject.

</details>


### [4] [Zero-Shot Segmentation through Prototype-Guidance for Multi-Label Plant Species Identification](https://arxiv.org/abs/2512.19957)
*Luciano Araujo Dourado Filho, Almir Moreira da Silva Neto, Rodrigo Pereira David, Rodrigo Tripodi Calumby*

**主要类别:** cs.AI

**AI概要:** 提出了一种基于类别原型和ViT分割模型的植物物种识别方法，在PlantCLEF 2025挑战赛中排名第五，F1分数0.33331


<details>
  <summary>更多</summary>
  
**动机:** 解决PlantCLEF 2025挑战赛中的细粒度多标签物种识别问题，从高分辨率植被图像中识别多个物种

**方法:** 使用K-Means聚类从训练数据中提取类别原型，构建基于DinoV2预训练模型的窄ViT分割网络，通过注意力机制定位感兴趣区域并指导分类

**结果:** 在私有排行榜上获得第五名，F1分数0.33331，与第一名仅差0.03分，表现出竞争力

**结论:** 该方法成功实现了从单物种分类到多标签植被图像分类的领域适应，证明了原型引导的ViT分割模型在植物识别任务中的有效性

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Zero-Shot+Segmentation+through+Prototype-Guidance+for+Multi-Label+Plant+Species+Identification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.19957，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.19957&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This paper presents an approach developed to address the PlantClef 2025 challenge, which consists of a fine-grained multi-label species identification, over high-resolution images. Our solution focused on employing class prototypes obtained from the training dataset as a proxy guidance for training a segmentation Vision Transformer (ViT) on the test set images. To obtain these representations, the proposed method extracts features from training dataset images and create clusters, by applying K-Means, with $K$ equals to the number of classes in the dataset. The segmentation model is a customized narrow ViT, built by replacing the patch embedding layer with a frozen DinoV2, pre-trained on the training dataset for individual species classification. This model is trained to reconstruct the class prototypes of the training dataset from the test dataset images. We then use this model to obtain attention scores that enable to identify and localize areas of interest and consequently guide the classification process. The proposed approach enabled a domain-adaptation from multi-class identification with individual species, into multi-label classification from high-resolution vegetation plots. Our method achieved fifth place in the PlantCLEF 2025 challenge on the private leaderboard, with an F1 score of 0.33331. Besides that, in absolute terms our method scored 0.03 lower than the top-performing submission, suggesting that it may achieved competitive performance in the benchmark task. Our code is available at \href{https://github.com/ADAM-UEFS/PlantCLEF2025}{https://github.com/ADAM-UEFS/PlantCLEF2025}.

</details>


### [5] [FGDCC: Fine-Grained Deep Cluster Categorization -- A Framework for Intra-Class Variability Problems in Plant Classification](https://arxiv.org/abs/2512.19960)
*Luciano Araujo Dourado Filho, Rodrigo Tripodi Calumby*

**主要类别:** cs.AI

**AI概要:** 提出一种通过类别内聚类来学习细粒度特征的新方法，使用聚类产生的伪标签进行层次分类，以缓解细粒度视觉分类中的类内变异问题，在PlantNet300k数据集上达到了state-of-the-art性能。


<details>
  <summary>更多</summary>
  
**动机:** 细粒度视觉分类(FGVC)任务中，类内变异(同一类别内图像的差异程度)会阻碍深度学习模型的学习过程，特别是当这些类别样本数量不足时。需要解决类内变异对分类性能的负面影响。

**方法:** 对每个类别单独进行聚类，发现编码图像间相似度的潜在伪标签，然后使用这些标签进行层次分类过程，从而学习更细粒度的视觉特征。

**结果:** 在PlantNet300k数据集上实现了state-of-the-art性能，尽管部分组件尚未完全优化。初步实验揭示了未来工作需要发展的关键点。

**结论:** 该方法通过类别内聚类和层次分类有效缓解了类内变异问题，提升了细粒度视觉分类性能，为后续研究提供了有价值的探索方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FGDCC%3A+Fine-Grained+Deep+Cluster+Categorization+--+A+Framework+for+Intra-Class+Variability+Problems+in+Plant+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.19960，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.19960&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Intra-class variability is given according to the significance in the degree of dissimilarity between images within a class. In that sense, depending on its intensity, intra-class variability can hinder the learning process for DL models, specially when such classes are also underrepresented, which is a very common scenario in Fine-Grained Visual Categorization (FGVC) tasks. This paper proposes a novel method that aims at leveraging classification performance in FGVC tasks by learning fine-grained features via classification of class-wise cluster assignments. Our goal is to apply clustering over each class individually, which can allow to discover pseudo-labels that encodes a latent degree of similarity between images. In turn, those labels can be employed in a hierarchical classification process that allows to learn more fine-grained visual features and thereby mitigating intra-class variability issues. Initial experiments over the PlantNet300k enabled to shed light upon several key points in which future work will have to be developed in order to find more conclusive evidence regarding the effectiveness of our method. Our method still achieves state-of-the-art performance on the PlantNet300k dataset even though some of its components haven't been shown to be fully optimized. Our code is available at \href{https://github.com/ADAM-UEFS/FGDCC}{https://github.com/ADAM-UEFS/FGDCC}.

</details>


### [6] [S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test](https://arxiv.org/abs/2512.19992)
*Zhe Sun, Xueyuan Yang, Yujie Lu, Zhenliang Zhang*

**主要类别:** cs.AI

**AI概要:** S$^{3}$IT是一个专门评估具身社会智能的基准测试，通过3D座位排序任务测试智能体在物理约束和社交规范之间的权衡能力。研究发现当前LLM在空间智能方面存在不足，但在有明确文本线索的冲突解决上接近人类水平。


<details>
  <summary>更多</summary>
  
**动机:** 现有评估方法要么局限于无具身的社交推理，要么局限于无社交意识的物理任务，无法评估智能体在真实具身环境中整合物理和社交约束的能力。

**方法:** 提出S$^{3}$IT基准测试，采用程序化可扩展框架生成多样化的3D座位排序场景，要求智能体通过主动对话获取偏好、自主探索环境感知，并在复杂约束网络中进行多目标优化。

**结果:** 评估发现最先进的LLM在此任务上表现不佳，与人类基线存在明显差距，表明LLM在空间智能方面存在缺陷。

**结论:** LLM在具身社会智能方面仍需改进，特别是在空间推理能力上，但在基于文本线索的冲突解决方面已接近人类水平，为未来具身AI系统的发展提供了重要基准。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是S%24%5E3%24IT%3A+A+Benchmark+for+Spatially+Situated+Social+Intelligence+Test，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.19992，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.19992&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The integration of embodied agents into human environments demands embodied social intelligence: reasoning over both social norms and physical constraints. However, existing evaluations fail to address this integration, as they are limited to either disembodied social reasoning (e.g., in text) or socially-agnostic physical tasks. Both approaches fail to assess an agent's ability to integrate and trade off both physical and social constraints within a realistic, embodied context. To address this challenge, we introduce Spatially Situated Social Intelligence Test (S$^{3}$IT), a benchmark specifically designed to evaluate embodied social intelligence. It is centered on a novel and challenging seat-ordering task, requiring an agent to arrange seating in a 3D environment for a group of large language model-driven (LLM-driven) NPCs with diverse identities, preferences, and intricate interpersonal relationships. Our procedurally extensible framework generates a vast and diverse scenario space with controllable difficulty, compelling the agent to acquire preferences through active dialogue, perceive the environment via autonomous exploration, and perform multi-objective optimization within a complex constraint network. We evaluate state-of-the-art LLMs on S$^{3}$IT and found that they still struggle with this problem, showing an obvious gap compared with the human baseline. Results imply that LLMs have deficiencies in spatial intelligence, yet simultaneously demonstrate their ability to achieve near human-level competence in resolving conflicts that possess explicit textual cues.

</details>


### [7] [Discovering Lie Groups with Flow Matching](https://arxiv.org/abs/2512.20043)
*Jung Yeon Park, Yuxuan Chen, Floor Eijkelboom, Jan-Willem van de Meent, Lawson L. S. Wong, Robin Walters*

**主要类别:** cs.AI

**AI概要:** 通过李群上的流匹配从数据中直接学习对称性，提出LieFlow方法，能够发现更广泛的群类型且需要更少假设，成功在2D和3D点云数据中发现离散群和反射对称性，并解决了目标模式对称排列导致的"最后一分钟收敛"问题。


<details>
  <summary>更多</summary>
  
**动机:** 对称性对理解物理系统和提升机器学习性能都很重要，但需要了解数据中的基础对称性。现有方法在群类型发现和假设要求方面存在局限。

**方法:** 提出LieFlow方法，将对称性发现建模为在更大假设群上学习分布，通过李群上的流匹配技术使学习分布与数据中观察到的对称性相匹配。

**结果:** 在2D和3D点云实验中成功发现了离散群，包括通过复数域流匹配发现的反射对称性。

**结论:** 该方法比先前工作更灵活，能发现更多类型的群且需要更少假设，同时解决了对称目标模式导致的收敛问题，为从数据中学习对称性提供了有效途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Discovering+Lie+Groups+with+Flow+Matching，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20043，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20043&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Symmetry is fundamental to understanding physical systems, and at the same time, can improve performance and sample efficiency in machine learning. Both pursuits require knowledge of the underlying symmetries in data. To address this, we propose learning symmetries directly from data via flow matching on Lie groups. We formulate symmetry discovery as learning a distribution over a larger hypothesis group, such that the learned distribution matches the symmetries observed in data. Relative to previous works, our method, \lieflow, is more flexible in terms of the types of groups it can discover and requires fewer assumptions. Experiments on 2D and 3D point clouds demonstrate the successful discovery of discrete groups, including reflections by flow matching over the complex domain. We identify a key challenge where the symmetric arrangement of the target modes causes ``last-minute convergence,'' where samples remain stationary until relatively late in the flow, and introduce a novel interpolation scheme for flow matching for symmetry discovery.

</details>


### [8] [Learning Skills from Action-Free Videos](https://arxiv.org/abs/2512.20052)
*Hung-Chieh Fang, Kuo-Han Hung, Chu-Rong Chen, Po-Jung Chou, Chun-Kai Yang, Po-Chen Ko, Yu-Chiang Wang, Yueh-Hua Wu, Min-Hung Chen, Shao-Hua Sun*

**主要类别:** cs.AI

**AI概要:** SOF框架通过光流表示从无动作视频中学习潜在技能，连接了视频生成模型和动作执行之间的鸿沟，实现了基于视频技能的高层规划能力


<details>
  <summary>更多</summary>
  
**动机:** 现有视频生成模型难以转化为低级动作，而潜在动作模型缺乏高层规划能力，需要一种能够从视频中学习可执行技能的方法

**方法:** 提出Skill Abstraction from Optical Flow (SOF)框架，通过光流作为中间表示学习潜在技能空间，捕获与视频动态和机器人动作对齐的运动信息

**结果:** 实验表明SOF在多任务和长时程设置中持续提升性能，能够直接从原始视觉数据获取和组合技能

**结论:** 基于光流的技能抽象方法有效解决了视频到动作的转换问题，为从视频中学习通用机器人技能提供了可行路径

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Skills+from+Action-Free+Videos，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20052，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20052&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Learning from videos offers a promising path toward generalist robots by providing rich visual and temporal priors beyond what real robot datasets contain. While existing video generative models produce impressive visual predictions, they are difficult to translate into low-level actions. Conversely, latent-action models better align videos with actions, but they typically operate at the single-step level and lack high-level planning capabilities. We bridge this gap by introducing Skill Abstraction from Optical Flow (SOF), a framework that learns latent skills from large collections of action-free videos. Our key idea is to learn a latent skill space through an intermediate representation based on optical flow that captures motion information aligned with both video dynamics and robot actions. By learning skills in this flow-based latent space, SOF enables high-level planning over video-derived skills and allows for easier translation of these skills into actions. Experiments show that our approach consistently improves performance in both multitask and long-horizon settings, demonstrating the ability to acquire and compose skills directly from raw visual data.

</details>


### [9] [Towards Generative Location Awareness for Disaster Response: A Probabilistic Cross-view Geolocalization Approach](https://arxiv.org/abs/2512.20056)
*Hao Li, Fabian Deuser, Wenping Yin, Steffen Knoblauch, Wufan Zhao, Filip Biljecki, Yong Xue, Wei Huang*

**主要类别:** cs.AI

**AI概要:** 提出ProbGLC概率交叉视图地理定位方法，结合概率和确定性模型，提高灾害响应中的定位准确性和模型可解释性，在多个灾害数据集上取得优异性能。


<details>
  <summary>更多</summary>
  
**动机:** 气候变化导致极端天气灾害频发，需要快速准确的灾害位置识别来支持应急决策和资源分配，但现有方法在定位准确性和可解释性方面存在不足。

**方法:** 提出概率交叉视图地理定位框架(ProbGLC)，将概率模型和确定性模型统一结合，通过不确定性量化和局部化评分来增强模型可解释性，支持多种灾害类型的跨视图图像对定位。

**结果:** 在两个跨视图灾害数据集(MultiIAN和SAGAINDisaster)上验证，取得优异定位精度：Acc@1km为0.86，Acc@25km为0.97，并通过概率分布和局部化评分提供模型可解释性。

**结论:** ProbGLC方法展示了生成式交叉视图方法在灾害响应位置感知中的巨大潜力，能够实现更好更快的灾害响应，代码和数据已公开。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Generative+Location+Awareness+for+Disaster+Response%3A+A+Probabilistic+Cross-view+Geolocalization+Approach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20056，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20056&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** As Earth's climate changes, it is impacting disasters and extreme weather events across the planet. Record-breaking heat waves, drenching rainfalls, extreme wildfires, and widespread flooding during hurricanes are all becoming more frequent and more intense. Rapid and efficient response to disaster events is essential for climate resilience and sustainability. A key challenge in disaster response is to accurately and quickly identify disaster locations to support decision-making and resources allocation. In this paper, we propose a Probabilistic Cross-view Geolocalization approach, called ProbGLC, exploring new pathways towards generative location awareness for rapid disaster response. Herein, we combine probabilistic and deterministic geolocalization models into a unified framework to simultaneously enhance model explainability (via uncertainty quantification) and achieve state-of-the-art geolocalization performance. Designed for rapid diaster response, the ProbGLC is able to address cross-view geolocalization across multiple disaster events as well as to offer unique features of probabilistic distribution and localizability score. To evaluate the ProbGLC, we conduct extensive experiments on two cross-view disaster datasets (i.e., MultiIAN and SAGAINDisaster), consisting diverse cross-view imagery pairs of multiple disaster types (e.g., hurricanes, wildfires, floods, to tornadoes). Preliminary results confirms the superior geolocalization accuracy (i.e., 0.86 in Acc@1km and 0.97 in Acc@25km) and model explainability (i.e., via probabilistic distributions and localizability scores) of the proposed ProbGLC approach, highlighting the great potential of leveraging generative cross-view approach to facilitate location awareness for better and faster disaster response. The data and code is publicly available at https://github.com/bobleegogogo/ProbGLC

</details>


### [10] [Scaling Reinforcement Learning for Content Moderation with Large Language Models](https://arxiv.org/abs/2512.20061)
*Hamed Firooz, Rui Liu, Yuchen Lu, Zhenyu Hou, Fangzhou Xiong, Xiaoyang Zhang, Changshu Jian, Zhicheng Zhu, Jiayuan Ma, Jacob Tao, Chaitali Gupta, Xiaochang Peng, Shike Mei, Hang Cui, Yang Qin, Shuo Tang, Jason Gaedtke, Arpit Mittal*

**主要类别:** cs.AI

**AI概要:** 本研究通过强化学习将通用语言模型转化为专业的内容审核分类器，在数据稀缺的真实场景中实现了专家级准确率，相比监督微调提升100倍数据效率。


<details>
  <summary>更多</summary>
  
**动机:** 大规模内容审核是数字生态系统的紧迫挑战，现有LLM在真实场景中面临标签稀疏、政策动态变化和需要深度推理的难题，如何实现专家级准确率尚未充分探索。

**方法:** 采用强化学习训练方法，系统评估多种RL训练方案和奖励塑造策略，包括可验证奖励和LLM作为评判框架，在三个真实内容审核任务上进行实证研究。

**结果:** RL表现出S型扩展行为，性能随训练数据、rollouts和优化步骤增加而平滑提升后逐渐饱和；在需要复杂政策推理的任务上表现显著提升，数据效率比监督微调高100倍。

**结论:** 强化学习是工业级内容审核系统的有效解决方案，特别适用于专家标注稀缺或成本高昂的领域，为实际应用提供了可行的技术路径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scaling+Reinforcement+Learning+for+Content+Moderation+with+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20061，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20061&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Content moderation at scale remains one of the most pressing challenges in today's digital ecosystem, where billions of user- and AI-generated artifacts must be continuously evaluated for policy violations. Although recent advances in large language models (LLMs) have demonstrated strong potential for policy-grounded moderation, the practical challenges of training these systems to achieve expert-level accuracy in real-world settings remain largely unexplored, particularly in regimes characterized by label sparsity, evolving policy definitions, and the need for nuanced reasoning beyond shallow pattern matching. In this work, we present a comprehensive empirical investigation of scaling reinforcement learning (RL) for content classification, systematically evaluating multiple RL training recipes and reward-shaping strategies-including verifiable rewards and LLM-as-judge frameworks-to transform general-purpose language models into specialized, policy-aligned classifiers across three real-world content moderation tasks. Our findings provide actionable insights for industrial-scale moderation systems, demonstrating that RL exhibits sigmoid-like scaling behavior in which performance improves smoothly with increased training data, rollouts, and optimization steps before gradually saturating. Moreover, we show that RL substantially improves performance on tasks requiring complex policy-grounded reasoning while achieving up to 100x higher data efficiency than supervised fine-tuning, making it particularly effective in domains where expert annotations are scarce or costly.

</details>


### [11] [Reason2Decide: Rationale-Driven Multi-Task Learning](https://arxiv.org/abs/2512.20074)
*H M Quamran Hasan, Housam Khalifa Bashier, Jiayi Dai, Mi-Young Kim, Randy Goebel*

**主要类别:** cs.AI

**AI概要:** Reason2Decide是一个两阶段训练框架，通过解决暴露偏差和任务分离问题，在临床决策支持系统中实现高预测准确性和与预测一致的推理生成。


<details>
  <summary>更多</summary>
  
**动机:** 当前临床决策支持系统中的大型语言模型存在暴露偏差，导致推理与预测不一致的问题，需要开发能够同时保证预测准确性和推理对齐的方法。

**方法:** 采用两阶段训练：第一阶段训练推理生成，第二阶段联合训练标签预测和推理生成，使用计划采样从基于黄金标签逐步过渡到基于模型预测。

**结果:** 在三个医疗数据集上，Reason2Decide在预测准确性和推理保真度方面优于其他微调基线和一些零样本LLM，且对推理来源具有鲁棒性。

**结论:** 该方法使用比现代基础模型小40倍的模型实现了优异性能，减少了对人类标注的依赖，使临床推理在资源受限环境中更加可行。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reason2Decide%3A+Rationale-Driven+Multi-Task+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20074，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20074&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Despite the wide adoption of Large Language Models (LLM)s, clinical decision support systems face a critical challenge: achieving high predictive accuracy while generating explanations aligned with the predictions. Current approaches suffer from exposure bias leading to misaligned explanations. We propose Reason2Decide, a two-stage training framework that addresses key challenges in self-rationalization, including exposure bias and task separation. In Stage-1, our model is trained on rationale generation, while in Stage-2, we jointly train on label prediction and rationale generation, applying scheduled sampling to gradually transition from conditioning on gold labels to model predictions. We evaluate Reason2Decide on three medical datasets, including a proprietary triage dataset and public biomedical QA datasets. Across model sizes, Reason2Decide outperforms other fine-tuning baselines and some zero-shot LLMs in prediction (F1) and rationale fidelity (BERTScore, BLEU, LLM-as-a-Judge). In triage, Reason2Decide is rationale source-robust across LLM-generated, nurse-authored, and nurse-post-processed rationales. In our experiments, while using only LLM-generated rationales in Stage-1, Reason2Decide outperforms other fine-tuning variants. This indicates that LLM-generated rationales are suitable for pretraining models, reducing reliance on human annotations. Remarkably, Reason2Decide achieves these gains with models 40x smaller than contemporary foundation models, making clinical reasoning more accessible for resource-constrained deployments while still providing explainable decision support.

</details>


### [12] [Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches](https://arxiv.org/abs/2512.20082)
*Chaithra, Kamesh Kadimisetty, Biju R Mohan*

**主要类别:** cs.AI

**AI概要:** 该论文提出了一种结合大语言模型与股票市场反馈的自适应金融情感分析框架，通过指令微调、检索增强生成和强化学习来提升印度股市的情感分类准确性。


<details>
  <summary>更多</summary>
  
**动机:** 现有金融情感分析工作未考虑股价或市场反馈的影响，需要开发能够动态适应市场行为的智能情感分析系统。

**方法:** 使用LLaMA 3.2 3B模型在SentiFin数据集上进行指令微调，采用RAG管道动态选择多源上下文信息，并引入基于PPO强化学习的反馈驱动模块来优化源权重策略。

**结果:** 在2024-2025年NIFTY 50新闻标题上的实验表明，该系统在分类准确率、F1分数和市场对齐度方面显著优于基线模型和静态检索方法。

**结论:** 结合指令微调LLM、动态反馈和强化学习的方法具有巨大潜力，能够实现稳健且市场感知的金融情感建模。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Adaptive+Financial+Sentiment+Analysis+for+NIFTY+50+via+Instruction-Tuned+LLMs+%2C+RAG+and+Reinforcement+Learning+Approaches，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20082，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20082&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Financial sentiment analysis plays a crucial role in informing investment decisions, assessing market risk, and predicting stock price trends. Existing works in financial sentiment analysis have not considered the impact of stock prices or market feedback on sentiment analysis. In this paper, we propose an adaptive framework that integrates large language models (LLMs) with real-world stock market feedback to improve sentiment classification in the context of the Indian stock market. The proposed methodology fine-tunes the LLaMA 3.2 3B model using instruction-based learning on the SentiFin dataset. To enhance sentiment predictions, a retrieval-augmented generation (RAG) pipeline is employed that dynamically selects multi-source contextual information based on the cosine similarity of the sentence embeddings. Furthermore, a feedback-driven module is introduced that adjusts the reliability of the source by comparing predicted sentiment with actual next-day stock returns, allowing the system to iteratively adapt to market behavior. To generalize this adaptive mechanism across temporal data, a reinforcement learning agent trained using proximal policy optimization (PPO) is incorporated. The PPO agent learns to optimize source weighting policies based on cumulative reward signals from sentiment-return alignment. Experimental results on NIFTY 50 news headlines collected from 2024 to 2025 demonstrate that the proposed system significantly improves classification accuracy, F1-score, and market alignment over baseline models and static retrieval methods. The results validate the potential of combining instruction-tuned LLMs with dynamic feedback and reinforcement learning for robust, market-aware financial sentiment modeling.

</details>


### [13] [MolAct: An Agentic RL Framework for Molecular Editing and Property Optimization](https://arxiv.org/abs/2512.20135)
*Zhuo Yang, Yeyun chen, Jiaqing Xie, Ben Gao, Shuaike Shen, Wanhao Liu, Liujia Yang, Beilun Wang, Tianfan Fu, Yuqiang Li*

**主要类别:** cs.AI

**AI概要:** MolAct是一个基于强化学习的智能体框架，通过两阶段训练（先学习编辑能力，后优化属性）实现分子编辑和优化，在多项任务中超越现有基线模型。


<details>
  <summary>更多</summary>
  
**动机:** 分子编辑和优化是多步骤问题，需要迭代改进属性同时保持化学有效性和结构相似性，但目前缺乏将分子设计形式化为智能体强化学习问题的研究。

**方法:** 提出MolAct框架，将分子设计构建为顺序工具引导决策问题，使用LLM智能体学习交替进行推理、工具使用和分子优化，通过化学工具进行有效性检查、属性评估和相似性控制。

**结果:** MolEditAgent-7B在编辑任务中实现100/95/98的有效添加/删除/替换编辑，优于DeepSeek-R1；MolOptAgent-7B在LogP优化上超越Claude 3.7，在溶解度上保持竞争力。

**结论:** 将分子设计视为多步骤、工具增强的过程是实现可靠和可解释改进的关键，MolAct框架为此提供了有效解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MolAct%3A+An+Agentic+RL+Framework+for+Molecular+Editing+and+Property+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20135，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20135&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Molecular editing and optimization are multi-step problems that require iteratively improving properties while keeping molecules chemically valid and structurally similar. We frame both tasks as sequential, tool-guided decisions and introduce MolAct, an agentic reinforcement learning framework that employs a two-stage training paradigm: first building editing capability, then optimizing properties while reusing the learned editing behaviors. To the best of our knowledge, this is the first work to formalize molecular design as an Agentic Reinforcement Learning problem, where an LLM agent learns to interleave reasoning, tool-use, and molecular optimization. The framework enables agents to interact in multiple turns, invoking chemical tools for validity checking, property assessment, and similarity control, and leverages their feedback to refine subsequent edits. We instantiate the MolAct framework to train two model families: MolEditAgent for molecular editing tasks and MolOptAgent for molecular optimization tasks. In molecular editing, MolEditAgent-7B delivers 100, 95, and 98 valid add, delete, and substitute edits, outperforming strong closed "thinking" baselines such as DeepSeek-R1; MolEditAgent-3B approaches the performance of much larger open "thinking" models like Qwen3-32B-think. In molecular optimization, MolOptAgent-7B (trained on MolEditAgent-7B) surpasses the best closed "thinking" baseline (e.g., Claude 3.7) on LogP and remains competitive on solubility, while maintaining balanced performance across other objectives. These results highlight that treating molecular design as a multi-step, tool-augmented process is key to reliable and interpretable improvements.

</details>


### [14] [Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection](https://arxiv.org/abs/2512.20140)
*Xingyou Yin, Ceyao Zhang, Min Hu, Kai Chen*

**主要类别:** cs.AI

**AI概要:** 通过在时间序列数据tokenization前注入噪声，提升冻结大语言模型在零样本时间序列预测中的表现，无需微调即可改善预测稳定性


<details>
  <summary>更多</summary>
  
**动机:** 现有方法依赖微调专用模块来弥合时间序列数据与LLMs预训练知识的差距，但完全冻结的LLMs性能对输入数据的文本表示极其敏感，需要解决这种脆弱性

**方法:** 在原始时间序列数据tokenization前注入噪声，作为一种推理时增强策略，迫使冻结的LLM基于稳健的时序模式而非表面数值特征进行外推

**结果:** 理论分析和多基准测试验证了该方法的有效性，特别是在专门设计的新数据集上观察到一致的性能提升，完全消除了预训练数据污染带来的偏差

**结论:** 该研究为直接利用现成LLMs进行时间序列预测提供了进一步的方法，通过简单的噪声注入策略显著改善了冻结模型的预测鲁棒性

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhancing+Zero-Shot+Time+Series+Forecasting+in+Off-the-Shelf+LLMs+via+Noise+Injection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20140，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20140&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have demonstrated effectiveness as zero-shot time series (TS) forecasters. The key challenge lies in tokenizing TS data into textual representations that align with LLMs' pre-trained knowledge. While existing work often relies on fine-tuning specialized modules to bridge this gap, a distinct, yet challenging, paradigm aims to leverage truly off-the-shelf LLMs without any fine-tuning whatsoever, relying solely on strategic tokenization of numerical sequences. The performance of these fully frozen models is acutely sensitive to the textual representation of the input data, as their parameters cannot adapt to distribution shifts. In this paper, we introduce a simple yet highly effective strategy to overcome this brittleness: injecting noise into the raw time series before tokenization. This non-invasive intervention acts as a form of inference-time augmentation, compelling the frozen LLM to extrapolate based on robust underlying temporal patterns rather than superficial numerical artifacts. We theoretically analyze this phenomenon and empirically validate its effectiveness across diverse benchmarks. Notably, to fully eliminate potential biases from data contamination during LLM pre-training, we introduce two novel TS datasets that fall outside all utilized LLMs' pre-training scopes, and consistently observe improved performance. This study provides a further step in directly leveraging off-the-shelf LLMs for time series forecasting.

</details>


### [15] [A Bidirectional Gated Recurrent Unit Model for PUE Prediction in Data Centers](https://arxiv.org/abs/2512.20161)
*Dhivya Dharshini Kannan, Anupam Trivedi, Dipti Srinivasan*

**主要类别:** cs.AI

**AI概要:** 该论文提出基于双向门控循环单元(BiGRU)的数据中心能耗效率(PUE)预测模型，通过特征选择和超参数优化，相比传统GRU模型在预测精度上有显著提升。


<details>
  <summary>更多</summary>
  
**动机:** 数据中心能耗占全球能源消耗的重要部分，随着边缘计算和AI发展，数据中心存储容量增长导致能耗问题日益严重。提高能源效率是应对气候变化、降低成本和促进可持续发展的关键。

**方法:** 使用EnergyPlus模拟新加坡数据中心，获得52,560个样本和117个特征。采用递归特征消除交叉验证(RFECV)算法选择最相关特征集，开发基于BiGRU的PUE预测模型，并与GRU模型进行性能比较。

**结果:** 通过MSE、MAE和R-squared等指标评估，优化后的BiGRU模型在PUE预测方面表现出比传统GRU模型更好的性能。

**结论:** BiGRU模型能有效预测数据中心能耗效率，为优化关键特征参数、提高能源效率提供了有效工具，有助于实现数据中心的环境可持续性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Bidirectional+Gated+Recurrent+Unit+Model+for+PUE+Prediction+in+Data+Centers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20161，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20161&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Data centers account for significant global energy consumption and a carbon footprint. The recent increasing demand for edge computing and AI advancements drives the growth of data center storage capacity. Energy efficiency is a cost-effective way to combat climate change, cut energy costs, improve business competitiveness, and promote IT and environmental sustainability. Thus, optimizing data center energy management is the most important factor in the sustainability of the world. Power Usage Effectiveness (PUE) is used to represent the operational efficiency of the data center. Predicting PUE using Neural Networks provides an understanding of the effect of each feature on energy consumption, thus enabling targeted modifications of those key features to improve energy efficiency. In this paper, we have developed Bidirectional Gated Recurrent Unit (BiGRU) based PUE prediction model and compared the model performance with GRU. The data set comprises 52,560 samples with 117 features using EnergyPlus, simulating a DC in Singapore. Sets of the most relevant features are selected using the Recursive Feature Elimination with Cross-Validation (RFECV) algorithm for different parameter settings. These feature sets are used to find the optimal hyperparameter configuration and train the BiGRU model. The performance of the optimized BiGRU-based PUE prediction model is then compared with that of GRU using mean squared error (MSE), mean absolute error (MAE), and R-squared metrics.

</details>


### [16] [Concept Generalization in Humans and Large Language Models: Insights from the Number Game](https://arxiv.org/abs/2512.20162)
*Arghavan Bazigaran, Hansem Sohn*

**主要类别:** cs.AI

**AI概要:** 比较人类与大型语言模型在数字游戏概念推理任务中的泛化能力差异，发现人类更灵活地结合规则和相似性推理，而LLM更依赖数学规则且需要更多样本进行泛化


<details>
  <summary>更多</summary>
  
**动机:** 研究人类与大型语言模型在概念推理任务中的泛化能力差异，探索两者的归纳偏置和推理策略的根本区别

**方法:** 使用贝叶斯模型作为分析框架，在数字游戏概念推理任务中对比人类和LLM的行为表现

**结果:** 贝叶斯模型更好地捕捉了人类行为；人类能灵活推断基于规则和相似性的概念，而LLM更依赖数学规则；人类能实现少样本泛化（甚至从单个样本），LLM需要更多样本

**结论:** 人类与LLM在数学概念推理和泛化方式上存在根本性差异，这凸显了当前AI系统与人类认知能力的重要区别

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Concept+Generalization+in+Humans+and+Large+Language+Models%3A+Insights+from+the+Number+Game，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20162，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20162&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We compare human and large language model (LLM) generalization in the number game, a concept inference task. Using a Bayesian model as an analytical framework, we examined the inductive biases and inference strategies of humans and LLMs. The Bayesian model captured human behavior better than LLMs in that humans flexibly infer rule-based and similarity-based concepts, whereas LLMs rely more on mathematical rules. Humans also demonstrated a few-shot generalization, even from a single example, while LLMs required more samples to generalize. These contrasts highlight the fundamental differences in how humans and LLMs infer and generalize mathematical concepts.

</details>


### [17] [Offline Safe Policy Optimization From Heterogeneous Feedback](https://arxiv.org/abs/2512.20173)
*Ze Gong, Pradeep Varakantham, Akshat Kumar*

**主要类别:** cs.AI

**AI概要:** 提出PreSa方法，通过直接学习偏好和安全标签来优化策略，避免显式学习奖励和成本模型，在连续控制任务中实现高性能的安全策略学习。


<details>
  <summary>更多</summary>
  
**动机:** 传统基于人类反馈的安全RL方法在长时域连续控制任务中，奖励和成本误差会累积，导致约束RL方法性能下降。

**方法:** 结合偏好学习模块和安全对齐的约束优化框架，在拉格朗日范式下直接学习奖励最大化安全策略，无需显式学习奖励和成本模型。

**结果:** 在连续控制任务中成功学习到高奖励的安全策略，性能优于现有最先进基线和具有真实奖励成本的离线安全RL方法。

**结论:** PreSa框架通过直接学习策略避免了奖励和成本模型的误差累积问题，为离线偏好强化学习中的安全挑战提供了有效解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Offline+Safe+Policy+Optimization+From+Heterogeneous+Feedback，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20173，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20173&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Offline Preference-based Reinforcement Learning (PbRL) learns rewards and policies aligned with human preferences without the need for extensive reward engineering and direct interaction with human annotators. However, ensuring safety remains a critical challenge across many domains and tasks. Previous works on safe RL from human feedback (RLHF) first learn reward and cost models from offline data, then use constrained RL to optimize a safe policy. While such an approach works in the contextual bandits settings (LLMs), in long horizon continuous control tasks, errors in rewards and costs accumulate, leading to impairment in performance when used with constrained RL methods. To address these challenges, (a) instead of indirectly learning policies (from rewards and costs), we introduce a framework that learns a policy directly based on pairwise preferences regarding the agent's behavior in terms of rewards, as well as binary labels indicating the safety of trajectory segments; (b) we propose \textsc{PreSa} (Preference and Safety Alignment), a method that combines preference learning module with safety alignment in a constrained optimization problem. This optimization problem is solved within a Lagrangian paradigm that directly learns reward-maximizing safe policy \textit{without explicitly learning reward and cost models}, avoiding the need for constrained RL; (c) we evaluate our approach on continuous control tasks with both synthetic and real human feedback. Empirically, our method successfully learns safe policies with high rewards, outperforming state-of-the-art baselines, and offline safe RL approaches with ground-truth reward and cost.

</details>


### [18] [TongSIM: A General Platform for Simulating Intelligent Machines](https://arxiv.org/abs/2512.20206)
*Zhe Sun, Kunlun Wu, Chuanjian Fu, Zeming Song, Langyong Shi, Zihe Xue, Bohan Jing, Ying Yang, Xiaomeng Gao, Aijia Li, Tianyu Guo, Huiying Li, Xueyuan Yang, Rongkai Liu, Xinyi He, Yuxi Wang, Yue Li, Mingyuan Liu, Yujie Lu, Hongzhao Xie, Shiyun Zhao, Bo Dai, Wei Wang, Tao Yuan, Song-Chun Zhu, Yujia Peng, Zhenliang Zhang*

**主要类别:** cs.AI

**AI概要:** TongSIM是一个高保真通用仿真平台，用于训练和评估具身智能体，提供多样化室内外场景和综合评估框架，填补了现有仿真平台在通用性方面的空白。


<details>
  <summary>更多</summary>
  
**动机:** 现有仿真平台大多针对特定任务设计，缺乏支持从低级导航到高级复合活动（如多智能体社交仿真和人机协作）的通用训练环境。

**方法:** 开发TongSIM平台，提供100多个多样化多房间室内场景和开放式户外城镇仿真，支持自定义场景、任务自适应保真度、多样化智能体类型和动态环境模拟。

**结果:** 创建了一个灵活可扩展的统一平台，能够精确评估智能体的感知、认知、决策、人机协作以及空间和社会推理能力。

**结论:** TongSIM作为通用平台，加速了训练、评估和通用具身智能的发展，为研究人员提供了广泛适用的仿真环境。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TongSIM%3A+A+General+Platform+for+Simulating+Intelligent+Machines，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20206，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20206&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** As artificial intelligence (AI) rapidly advances, especially in multimodal large language models (MLLMs), research focus is shifting from single-modality text processing to the more complex domains of multimodal and embodied AI. Embodied intelligence focuses on training agents within realistic simulated environments, leveraging physical interaction and action feedback rather than conventionally labeled datasets. Yet, most existing simulation platforms remain narrowly designed, each tailored to specific tasks. A versatile, general-purpose training environment that can support everything from low-level embodied navigation to high-level composite activities, such as multi-agent social simulation and human-AI collaboration, remains largely unavailable. To bridge this gap, we introduce TongSIM, a high-fidelity, general-purpose platform for training and evaluating embodied agents. TongSIM offers practical advantages by providing over 100 diverse, multi-room indoor scenarios as well as an open-ended, interaction-rich outdoor town simulation, ensuring broad applicability across research needs. Its comprehensive evaluation framework and benchmarks enable precise assessment of agent capabilities, such as perception, cognition, decision-making, human-robot cooperation, and spatial and social reasoning. With features like customized scenes, task-adaptive fidelity, diverse agent types, and dynamic environmental simulation, TongSIM delivers flexibility and scalability for researchers, serving as a unified platform that accelerates training, evaluation, and advancement toward general embodied intelligence.

</details>


### [19] [MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents](https://arxiv.org/abs/2512.20237)
*Xingbo Du, Loka Li, Duzhen Zhang, Le Song*

**主要类别:** cs.AI

**AI概要:** N/A


<details>
  <summary>更多</summary>
  
**动机:** N/A

**方法:** N/A

**结果:** N/A

**结论:** N/A

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MemR%24%5E3%24%3A+Memory+Retrieval+via+Reflective+Reasoning+for+LLM+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20237，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20237&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Memory systems have been designed to leverage past experiences in Large Language Model (LLM) agents. However, many deployed memory systems primarily optimize compression and storage, with comparatively less emphasis on explicit, closed-loop control of memory retrieval. From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process. This design departs from the standard retrieve-then-answer pipeline by introducing a closed-loop control mechanism that enables autonomous decision-making. Empirical results on the LoCoMo benchmark demonstrate that MemR$^3$ surpasses strong baselines on LLM-as-a-Judge score, and particularly, it improves existing retrievers across four categories with an overall improvement on RAG (+7.29%) and Zep (+1.94%) using GPT-4.1-mini backend, offering a plug-and-play controller for existing memory stores.

</details>


### [20] [Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks](https://arxiv.org/abs/2512.20275)
*Divya Vijay, Vignesh Ethiraj*

**主要类别:** cs.AI

**AI概要:** G-SPEC是一个神经符号框架，通过确定性验证约束概率规划，解决5G/6G网络中LLM代理的安全风险，在450节点测试中实现零安全违规和94.1%修复成功率。


<details>
  <summary>更多</summary>
  
**动机:** 5G独立组网和6G网络发展面临超出静态自动化和深度强化学习极限的编排挑战，LLM代理虽能实现基于意图的网络，但会带来拓扑幻觉和政策不合规等随机风险。

**方法:** 提出Graph-Symbolic Policy Enforcement and Control (G-SPEC)框架，包含治理三元组：电信适配代理(TSLAM-4B)、网络知识图谱(NKG)和SHACL约束，通过神经符号方法结合概率规划和确定性验证。

**结果:** 在模拟450节点5G核心网测试中：零安全违规、94.1%修复成功率（显著优于82.4%基线）；消融分析显示NKG验证贡献68%安全增益，SHACL政策贡献24%；10K-100K节点拓扑验证延迟按O(k^1.2)扩展，处理开销142ms。

**结论:** G-SPEC框架通过神经符号方法有效缓解LLM代理的随机风险，验证了在SMO层操作的可行性，为5G/6G网络智能编排提供了安全可靠的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph-Symbolic+Policy+Enforcement+and+Control+%28G-SPEC%29%3A+A+Neuro-Symbolic+Framework+for+Safe+Agentic+AI+in+5G+Autonomous+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20275，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20275&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** As networks evolve toward 5G Standalone and 6G, operators face orchestration challenges that exceed the limits of static automation and Deep Reinforcement Learning. Although Large Language Model (LLM) agents offer a path toward intent-based networking, they introduce stochastic risks, including topology hallucinations and policy non-compliance. To mitigate this, we propose Graph-Symbolic Policy Enforcement and Control (G-SPEC), a neuro-symbolic framework that constrains probabilistic planning with deterministic verification. The architecture relies on a Governance Triad - a telecom-adapted agent (TSLAM-4B), a Network Knowledge Graph (NKG), and SHACL constraints. We evaluated G-SPEC on a simulated 450-node 5G Core, achieving zero safety violations and a 94.1% remediation success rate, significantly outperforming the 82.4% baseline. Ablation analysis indicates that NKG validation drives the majority of safety gains (68%), followed by SHACL policies (24%). Scalability tests on topologies ranging from 10K to 100K nodes demonstrate that validation latency scales as $O(k^{1.2})$ where $k$ is subgraph size. With a processing overhead of 142ms, G-SPEC is viable for SMO-layer operations.

</details>


### [21] [ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge](https://arxiv.org/abs/2512.20276)
*Yuntao Dai, Hang Gu, Teng Wang, Qianyu Cheng, Yifei Zheng, Zhiyong Qiu, Lei Gong, Wenqi Lou, Xuehai Zhou*

**主要类别:** cs.AI

**AI概要:** ActionFlow是一个针对资源受限边缘平台的系统级推理框架，通过跨请求流水线策略和内存优化技术，显著提升Vision-Language-Action模型的推理速度，在OpenVLA-7B模型上实现2.55倍的FPS提升，无需重新训练即可实现边缘硬件的实时动态操作。


<details>
  <summary>更多</summary>
  
**动机:** 当前VLA模型在边缘设备上的推理延迟较高（3-5Hz），无法满足机器人交互所需的20-30Hz控制频率，现有优化方法往往需要重新训练或牺牲模型精度。

**方法:** 提出ActionFlow框架，核心是跨请求流水线策略，将VLA推理重新定义为微请求的宏流水线；开发跨请求状态打包前向算子和统一KV环形缓冲区，将碎片化内存操作融合为高效密集计算。

**结果:** 在OpenVLA-7B模型上实现了2.55倍的FPS提升，使模型能够在边缘硬件上实现实时动态操作，且无需重新训练。

**结论:** ActionFlow有效解决了VLA模型在边缘设备上的高延迟问题，通过系统级优化实现了实时性能，为机器人感知控制的实际部署提供了可行解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ActionFlow%3A+A+Pipelined+Action+Acceleration+for+Vision+Language+Models+on+Edge，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20276，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20276&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Vision-Language-Action (VLA) models have emerged as a unified paradigm for robotic perception and control, enabling emergent generalization and long-horizon task execution. However, their deployment in dynamic, real-world environments is severely hin dered by high inference latency. While smooth robotic interaction requires control frequencies of 20 to 30 Hz, current VLA models typi cally operate at only 3-5 Hz on edge devices due to the memory bound nature of autoregressive decoding. Existing optimizations often require extensive retraining or compromise model accuracy. To bridge this gap, we introduce ActionFlow, a system-level inference framework tailored for resource-constrained edge plat forms. At the core of ActionFlow is a Cross-Request Pipelin ing strategy, a novel scheduler that redefines VLA inference as a macro-pipeline of micro-requests. The strategy intelligently batches memory-bound Decode phases with compute-bound Prefill phases across continuous time steps to maximize hardware utilization. Furthermore, to support this scheduling, we propose a Cross Request State Packed Forward operator and a Unified KV Ring Buffer, which fuse fragmented memory operations into efficient dense computations. Experimental results demonstrate that ActionFlow achieves a 2.55x improvement in FPS on the OpenVLA-7B model without retraining, enabling real-time dy namic manipulation on edge hardware. Our work is available at https://anonymous.4open.science/r/ActionFlow-1D47.

</details>


### [22] [Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation](https://arxiv.org/abs/2512.20278)
*Nishant Gaurav, Adit Akarsh, Ankit Ranjan, Manoj Bajaj*

**主要类别:** cs.AI

**AI概要:** 论文提出了解决LLM从被动工具使用者向主动工作流架构师转变的方法，通过Outlook和OneDrive的跨服务编排案例研究，识别并解决了自动化技能生成的四个结构性瓶颈问题。


<details>
  <summary>更多</summary>
  
**动机:** 虽然CodeMem确立了可执行代码作为代理程序记忆的最佳表示形式，但从零开始自主合成这种记忆的机制仍未充分探索。论文旨在操作化大型语言模型从被动工具使用者向主动工作流架构师的转变。

**方法:** 通过高保真案例研究（Outlook和OneDrive跨服务编排任务），采用假设、探测和编码的科学方法论，解决四个结构性瓶颈：发现差距、验证差距、分解差距和扩展差距。

**结果:** 研究表明，通过实施假设-探测-编码的科学方法，代理能够自主编写健壮的、生产级别的代码技能。

**结论:** 该方法成功解决了自动化技能生成的关键瓶颈，使LLM能够有效转型为主动的工作流架构师，具备自主生成生产级代码技能的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Synthesizing+Procedural+Memory%3A+Challenges+and+Architectures+in+Automated+Workflow+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20278，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20278&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** While CodeMem establishes executable code as the optimal representation for agentic procedural memory, the mechanism for autonomously synthesizing this memory from a blank slate remains underexplored. This paper operationalizes the transition of Large Language Models from passive tool-users to active workflow architects. Through a high-fidelity case study of a cross-service orchestration task involving Outlook and OneDrive, we identify and address four structural bottlenecks in automated skill generation: the Discovery Gap involving navigation of large tool registries, the Verification Gap regarding grounding tool response structures, the Decomposition Gap which replaces inefficient search with Linear State Anchoring, and the Scaling Gap focused on concurrency and persistence. We demonstrate that by enforcing a scientific methodology of hypothesize, probe, and code, agents can autonomously write robust, production-grade code skills.

</details>


### [23] [SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization](https://arxiv.org/abs/2512.20333)
*Junren Li, Luhua Lai*

**主要类别:** cs.AI

**AI概要:** SynCraft是一个基于大语言模型推理能力的框架，通过原子级结构编辑而非直接生成SMILES字符串来解决分子合成可行性问题，在保持结构新颖性和药效团完整性的同时显著提升合成可行性。


<details>
  <summary>更多</summary>
  
**动机:** 当前生成式AI在化学空间探索中存在合成不可达分子的瓶颈问题，现有方法如后过滤或投影方法会损害结构新颖性或破坏关键药效团。

**方法:** 将合成可行性优化重新定义为精确的结构编辑问题，利用大语言模型的推理能力预测可执行的原子级编辑序列，通过交互感知提示来模拟药物化学专家直觉。

**结果:** 在广泛基准测试中优于最先进的基线方法，能够生成具有高结构保真度的可合成类似物，成功编辑PLK1抑制剂并挽救先前被丢弃的高评分RIPK1候选分子。

**结论:** SynCraft框架有效解决了分子生成中的合成可行性问题，通过结构编辑方法避免了LLMs的语法脆弱性，同时充分利用了其化学直觉，为药物发现提供了新途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SynCraft%3A+Guiding+Large+Language+Models+to+Predict+Edit+Sequences+for+Molecular+Synthesizability+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20333，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20333&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Generative artificial intelligence has revolutionized the exploration of chemical space, yet a critical bottleneck remains that a substantial fraction of generated molecules is synthetically inaccessible. Current solutions, such as post-hoc filtering or projection-based methods, often compromise structural novelty or disrupt key pharmacophores by forcing molecules into pre-defined synthetic templates. Herein, we introduce SynCraft, a reasoning-based framework that reframes synthesizability optimization not as a sequence translation task, but as a precise structural editing problem. Leveraging the emergent reasoning capabilities of Large Language Models, SynCraft navigates the "synthesis cliff" where minimal structural modifications yield significant gains in synthetic feasibility. By predicting executable sequences of atom-level edits rather than generating SMILES strings directly, SynCraft circumvents the syntactic fragility of LLMs while harnessing their chemical intuition. Extensive benchmarks demonstrate that SynCraft outperforms state-of-the-art baselines in generating synthesizable analogs with high structural fidelity. Furthermore, through interaction-aware prompting, SynCraft successfully replicates expert medicinal chemistry intuition in editing PLK1 inhibitors and rescuing high-scoring but previously discarded RIPK1 candidates in previous molecular generation literatures.

</details>


### [24] [A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice](https://arxiv.org/abs/2512.20344)
*Yaowei Bai, Ruiheng Zhang, Yu Lei, Xuhua Duan, Jingfeng Yao, Shuguang Ju, Chaoyang Wang, Wei Yao, Yiwan Guo, Guilin Zhang, Chao Wan, Qian Yuan, Lei Chen, Wenjuan Tang, Biqiang Zhu, Xinggang Wang, Tao Sun, Wei Zhou, Dacheng Tao, Yongchao Xu, Chuansheng Zheng, Huangxuan Zhao, Bo Du*

**主要类别:** cs.AI

**AI概要:** Janus-Pro-CXR是基于DeepSeek Janus-Pro开发的胸部X光解读系统，在多中心前瞻性临床试验中表现出色，在报告生成质量和临床关键发现检测方面超越包括ChatGPT 4o在内的最先进模型，显著提升报告质量并减少18.3%的解读时间。


<details>
  <summary>更多</summary>
  
**动机:** 全球放射科医生短缺问题因胸部X光工作量巨大而加剧，特别是在初级保健环境中。现有多模态大语言模型的评估主要依赖自动化指标或回顾性分析，缺乏严格的前瞻性临床验证。

**方法:** 开发了基于DeepSeek Janus-Pro模型的Janus-Pro-CXR胸部X光解读系统，并通过多中心前瞻性临床试验(NCT07117266)进行严格验证。采用轻量级架构和领域特定优化。

**结果:** 系统在自动报告生成方面优于最先进的X光报告生成模型，包括参数量更大的ChatGPT 4o；可靠检测六种临床关键放射学发现；回顾性评估显示报告准确性显著高于Janus-Pro和ChatGPT 4o；前瞻性临床部署中显著提高报告质量评分，减少18.3%的解读时间；54.3%的案例中专家更偏好AI辅助报告。

**结论:** Janus-Pro-CXR通过轻量级架构和领域特定优化，提高了诊断可靠性和工作流程效率，特别适用于资源受限环境。模型架构和实现框架将开源，以促进AI辅助放射学解决方案的临床转化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+DeepSeek-Powered+AI+System+for+Automated+Chest+Radiograph+Interpretation+in+Clinical+Practice，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20344，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20344&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** A global shortage of radiologists has been exacerbated by the significant volume of chest X-ray workloads, particularly in primary care. Although multimodal large language models show promise, existing evaluations predominantly rely on automated metrics or retrospective analyses, lacking rigorous prospective clinical validation. Janus-Pro-CXR (1B), a chest X-ray interpretation system based on DeepSeek Janus-Pro model, was developed and rigorously validated through a multicenter prospective trial (NCT07117266). Our system outperforms state-of-the-art X-ray report generation models in automated report generation, surpassing even larger-scale models including ChatGPT 4o (200B parameters), while demonstrating reliable detection of six clinically critical radiographic findings. Retrospective evaluation confirms significantly higher report accuracy than Janus-Pro and ChatGPT 4o. In prospective clinical deployment, AI assistance significantly improved report quality scores, reduced interpretation time by 18.3% (P < 0.001), and was preferred by a majority of experts in 54.3% of cases. Through lightweight architecture and domain-specific optimization, Janus-Pro-CXR improves diagnostic reliability and workflow efficiency, particularly in resource-constrained settings. The model architecture and implementation framework will be open-sourced to facilitate the clinical translation of AI-assisted radiology solutions.

</details>


### [25] [Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems](https://arxiv.org/abs/2512.20387)
*YuChe Hsu, AnJui Wang, TsaiChing Ni, YuanFu Yang*

**主要类别:** cs.AI

**AI概要:** 提出了Vision-Language Simulation Model (VLSM)，通过统一视觉和文本理解，从布局草图和自然语言提示生成可执行的FlexScript代码，支持工业仿真系统的跨模态推理。


<details>
  <summary>更多</summary>
  
**动机:** 为工业仿真系统开发能够整合视觉推理和语言理解的可执行数字孪生系统，解决多模态学习在仿真领域的应用需求。

**方法:** 构建了首个大规模生成式数字孪生数据集（包含12万+提示-草图-代码三元组），提出VLSM模型，并在视觉编码器、连接器和代码预训练语言主干等方面进行系统消融实验。

**结果:** 模型实现了近乎完美的结构准确性和高执行鲁棒性，提出的三个新评估指标（SVR、PMR、ESR）能够全面评估结构完整性、参数保真度和模拟器可执行性。

**结论:** 这项工作为将视觉推理和语言理解整合到可执行工业仿真系统中的生成式数字孪生奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generative+Digital+Twins%3A+Vision-Language+Simulation+Models+for+Executable+Industrial+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20387，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20387&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We propose a Vision-Language Simulation Model (VLSM) that unifies visual and textual understanding to synthesize executable FlexScript from layout sketches and natural-language prompts, enabling cross-modal reasoning for industrial simulation systems. To support this new paradigm, the study constructs the first large-scale dataset for generative digital twins, comprising over 120,000 prompt-sketch-code triplets that enable multimodal learning between textual descriptions, spatial structures, and simulation logic. In parallel, three novel evaluation metrics, Structural Validity Rate (SVR), Parameter Match Rate (PMR), and Execution Success Rate (ESR), are proposed specifically for this task to comprehensively evaluate structural integrity, parameter fidelity, and simulator executability. Through systematic ablation across vision encoders, connectors, and code-pretrained language backbones, the proposed models achieve near-perfect structural accuracy and high execution robustness. This work establishes a foundation for generative digital twins that integrate visual reasoning and language understanding into executable industrial simulation systems.

</details>


### [26] [Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale](https://arxiv.org/abs/2512.20469)
*Linfeng Zhang, Siheng Chen, Yuzhu Cai, Jingyi Chai, Junhan Chang, Kun Chen, Zhi X. Chen, Zhaohan Ding, Yuwen Du, Yuanpeng Gao, Yuan Gao, Jing Gao, Zhifeng Gao, Qiangqiang Gu, Yanhui Hong, Yuan Huang, Xi Fang, Xiaohong Ji, Guolin Ke, Zixing Lei, Xinyu Li, Yongge Li, Ruoxue Liao, Hang Lin, Xiaolu Lin, Yuxiang Liu, Xinzijian Liu, Zexi Liu, Jintan Lu, Tingjia Miao, Haohui Que, Weijie Sun, Yanfeng Wang, Bingyang Wu, Tianju Xue, Rui Ye, Jinzhe Zeng, Duo Zhang, Jiahui Zhang, Linfeng Zhang, Tianhan Zhang, Wenchang Zhang, Yuzhi Zhang, Zezhong Zhang, Hang Zheng, Hui Zhou, Tong Zhu, Xinyu Zhu, Qingguo Zhou, Weinan E*

**主要类别:** cs.AI

**AI概要:** Bohrium+SciMaster是一个用于规模化智能科学的基础设施生态系统，通过将科学工具转化为AI可用的能力并编排长周期科学工作流，大幅减少科学周期时间并生成大规模执行信号


<details>
  <summary>更多</summary>
  
**动机:** AI智能体正在成为运行多步骤科学工作流的实用方式，但规模化智能科学面临工作流难以观察和重现、工具缺乏AI准备性、执行难以追踪等挑战

**方法:** 提出Bohrium+SciMaster系统：Bohrium作为AI4S资产的托管中心，将科学数据、软件和实验系统转化为AI就绪能力；SciMaster编排这些能力为长周期科学工作流；科学智能基板组织可重用组件

**结果:** 在11个代表性主智能体的真实工作流中展示，实现了端到端科学周期时间的数量级减少，并在百万规模上生成了基于执行的信号

**结论:** 规模化智能科学需要基础设施和生态系统方法，Bohrium+SciMaster通过提供可组合、可审计和改进的构建模块，为科学智能体的发展和系统化改进奠定了基础

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bohrium+%2B+SciMaster%3A+Building+the+Infrastructure+and+Ecosystem+for+Agentic+Science+at+Scale，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20469，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20469&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** AI agents are emerging as a practical way to run multi-step scientific workflows that interleave reasoning with tool use and verification, pointing to a shift from isolated AI-assisted steps toward \emph{agentic science at scale}. This shift is increasingly feasible, as scientific tools and models can be invoked through stable interfaces and verified with recorded execution traces, and increasingly necessary, as AI accelerates scientific output and stresses the peer-review and publication pipeline, raising the bar for traceability and credible evaluation.
  However, scaling agentic science remains difficult: workflows are hard to observe and reproduce; many tools and laboratory systems are not agent-ready; execution is hard to trace and govern; and prototype AI Scientist systems are often bespoke, limiting reuse and systematic improvement from real workflow signals.
  We argue that scaling agentic science requires an infrastructure-and-ecosystem approach, instantiated in Bohrium+SciMaster. Bohrium acts as a managed, traceable hub for AI4S assets -- akin to a HuggingFace of AI for Science -- that turns diverse scientific data, software, compute, and laboratory systems into agent-ready capabilities. SciMaster orchestrates these capabilities into long-horizon scientific workflows, on which scientific agents can be composed and executed. Between infrastructure and orchestration, a \emph{scientific intelligence substrate} organizes reusable models, knowledge, and components into executable building blocks for workflow reasoning and action, enabling composition, auditability, and improvement through use.
  We demonstrate this stack with eleven representative master agents in real workflows, achieving orders-of-magnitude reductions in end-to-end scientific cycle time and generating execution-grounded signals from real workloads at multi-million scale.

</details>


### [27] [Benchmarking LLMs for Predictive Applications in the Intensive Care Units](https://arxiv.org/abs/2512.20520)
*Chehak Malhotra, Mehak Gopal, Akshaya Devadiga, Pradeep Singh, Ridam Pal, Ritwik Kashyap, Tavpritesh Sethi*

**主要类别:** cs.AI

**AI概要:** 本研究比较了大型语言模型(LLMs)和专门语言模型(SLMs)在预测ICU患者休克风险方面的表现，发现尽管GatorTron-Base获得最高召回率(80.5%)，但LLMs在预测临床事件方面并不天然优于SLMs。


<details>
  <summary>更多</summary>
  
**动机:** LLMs在自然语言处理领域表现出色，但在预测性任务中的应用研究较少。及时预测休克可以早期干预，改善患者预后。

**方法:** 使用MIMIC III数据库中17,294例ICU患者数据，筛选出355例正常和87例异常休克指数患者。比较GatorTron-Base、Llama 8B、Mistral 7B等LLMs与BioBERT、DocBERT等SLMs的表现，使用focal和交叉熵损失处理类别不平衡。

**结果:** GatorTron-Base获得最高加权召回率80.5%，但LLMs和SLMs的整体性能指标相当，表明LLMs在预测临床事件方面并不优于SLMs。

**结论:** 未来训练LLMs应优先开发能够预测临床轨迹的模型，而不是专注于命名实体识别或表型分析等简单任务，以实现有意义的临床结果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Benchmarking+LLMs+for+Predictive+Applications+in+the+Intensive+Care+Units，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20520，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20520&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** With the advent of LLMs, various tasks across the natural language processing domain have been transformed. However, their application in predictive tasks remains less researched. This study compares large language models, including GatorTron-Base (trained on clinical data), Llama 8B, and Mistral 7B, against models like BioBERT, DocBERT, BioClinicalBERT, Word2Vec, and Doc2Vec, setting benchmarks for predicting Shock in critically ill patients. Timely prediction of shock can enable early interventions, thus improving patient outcomes. Text data from 17,294 ICU stays of patients in the MIMIC III database were scored for length of stay > 24 hours and shock index (SI) > 0.7 to yield 355 and 87 patients with normal and abnormal SI-index, respectively. Both focal and cross-entropy losses were used during finetuning to address class imbalances. Our findings indicate that while GatorTron Base achieved the highest weighted recall of 80.5%, the overall performance metrics were comparable between SLMs and LLMs. This suggests that LLMs are not inherently superior to SLMs in predicting future clinical events despite their strong performance on text-based tasks. To achieve meaningful clinical outcomes, future efforts in training LLMs should prioritize developing models capable of predicting clinical trajectories rather than focusing on simpler tasks such as named entity recognition or phenotyping.

</details>


### [28] [Advancing Multimodal Teacher Sentiment Analysis:The Large-Scale T-MED Dataset & The Effective AAM-TSA Model](https://arxiv.org/abs/2512.20548)
*Zhiyi Duan, Xiangren Wang, Hongyu Yuan, Qianli Xing*

**主要类别:** cs.AI

**AI概要:** 本研究构建了首个大规模教师多模态情感分析数据集T-MED，并提出基于非对称注意力的多模态教师情感分析模型AAM-TSA，显著提升了教师情感识别的准确性和可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 教师情感状态对教学效果和学生学业成就至关重要，但现有研究难以准确捕捉教师情感，忽视了教学信息对情感表达的关键影响。

**方法:** 构建包含14,938个实例的T-MED数据集，涵盖11个学科的250个真实课堂；提出AAM-TSA模型，采用非对称注意力机制和分层门控单元实现差异化跨模态特征融合。

**结果:** 实验结果表明，AAM-TSA在T-MED数据集上的准确性和可解释性显著优于现有最先进方法。

**结论:** 该研究通过构建高质量数据集和创新模型，为教师情感分析提供了有效解决方案，对提升教育质量和教学效果具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Advancing+Multimodal+Teacher+Sentiment+Analysis%3AThe+Large-Scale+T-MED+Dataset+%26+The+Effective+AAM-TSA+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20548，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20548&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Teachers' emotional states are critical in educational scenarios, profoundly impacting teaching efficacy, student engagement, and learning achievements. However, existing studies often fail to accurately capture teachers' emotions due to the performative nature and overlook the critical impact of instructional information on emotional expression.In this paper, we systematically investigate teacher sentiment analysis by building both the dataset and the model accordingly. We construct the first large-scale teacher multimodal sentiment analysis dataset, T-MED.To ensure labeling accuracy and efficiency, we employ a human-machine collaborative labeling process.The T-MED dataset includes 14,938 instances of teacher emotional data from 250 real classrooms across 11 subjects ranging from K-12 to higher education, integrating multimodal text, audio, video, and instructional information.Furthermore, we propose a novel asymmetric attention-based multimodal teacher sentiment analysis model, AAM-TSA.AAM-TSA introduces an asymmetric attention mechanism and hierarchical gating unit to enable differentiated cross-modal feature fusion and precise emotional classification. Experimental results demonstrate that AAM-TSA significantly outperforms existing state-of-the-art methods in terms of accuracy and interpretability on the T-MED dataset.

</details>


### [29] [Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent](https://arxiv.org/abs/2512.20586)
*Humza Nusrat, Luke Francisco, Bing Luo, Hassan Bagher-Ebadian, Joshua Kim, Karen Chin-Snyder, Salim Siddiqui, Mira Shah, Eric Mellon, Mohammad Ghassemi, Anthony Doemer, Benjamin Movsas, Kundan Thind*

**主要类别:** cs.AI

**AI概要:** 研究测试了思维链推理在立体定向放射外科计划中的效果，开发了基于大语言模型的SAGE系统，发现推理模型在剂量学指标上与人类规划师相当，但在降低耳蜗剂量方面表现更优，同时提供了可审计的透明规划过程。


<details>
  <summary>更多</summary>
  
**动机:** 由于黑盒AI系统在临床应用中存在透明度问题，研究旨在探索思维链推理是否能改善立体定向放射外科的自动化治疗规划，提高临床可接受性和透明度。

**方法:** 在41例脑转移瘤患者的回顾性队列研究中，开发了LLM-based的SAGE规划代理，比较了推理模型和非推理模型两种变体生成的计划，评估剂量学指标和规划行为。

**结果:** 推理模型在主要终点指标（PTV覆盖率、最大剂量、适形指数、梯度指数）上与人类规划师相当（p>0.21），同时显著降低耳蜗剂量（p=0.022）。推理模型展示了前瞻性约束验证和权衡审议等系统规划行为。

**结论:** 思维链推理不仅提高了自动化规划的质量，还通过提供可审计的优化轨迹实现了透明化规划，为解决AI系统在临床中的黑盒问题提供了可行路径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Automated+stereotactic+radiosurgery+planning+using+a+human-in-the-loop+reasoning+large+language+model+agent，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20586，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20586&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning. Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model. The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022). When prompted to improve conformity, the reasoning model demonstrated systematic planning behaviors including prospective constraint verification (457 instances) and trade-off deliberation (609 instances), while the standard model exhibited none of these deliberative processes (0 and 7 instances, respectively). Content analysis revealed that constraint verification and causal explanation concentrated in the reasoning agent. The optimization traces serve as auditable logs, offering a path toward transparent automated planning.

</details>


### [30] [LongVideoAgent: Multi-Agent Reasoning with Long Videos](https://arxiv.org/abs/2512.20618)
*Runtao Liu, Ziyi Liu, Jiaqi Tang, Yue Ma, Renjie Pi, Jipeng Zhang, Qifeng Chen*

**主要类别:** cs.AI

**AI概要:** 提出一个多智能体框架，通过主LLM协调定位智能体和视觉智能体来处理长视频问答，显著超越现有基线方法


<details>
  <summary>更多</summary>
  
**动机:** 现有多模态LLM和工具系统在长视频问答中存在内容压缩损失和时间定位不准确的问题，缺乏细粒度线索

**方法:** 使用主LLM协调两个智能体：定位智能体负责定位问题相关片段，视觉智能体提取目标文本观察。主智能体通过强化学习训练，具有步数限制，促进简洁、准确、高效的多智能体协作

**结果:** 在LongTVQA和LongTVQA+数据集上，多智能体系统显著优于强非智能体基线，强化学习进一步增强了推理和规划能力

**结论:** 该多智能体框架通过精确的时间定位和视觉细节补充，实现了对长视频的高效推理，提供了可解释的轨迹，是长视频问答的有效解决方案

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LongVideoAgent%3A+Multi-Agent+Reasoning+with+Long+Videos，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20618，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20618&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We propose a multi-agent framework in which a master LLM coordinates a grounding agent to localize question-relevant segments and a vision agent to extract targeted textual observations. The master agent plans with a step limit, and is trained with reinforcement learning to encourage concise, correct, and efficient multi-agent cooperation. This design helps the master agent focus on relevant clips via grounding, complements subtitles with visual detail, and yields interpretable trajectories. On our proposed LongTVQA and LongTVQA+ which are episode-level datasets aggregated from TVQA/TVQA+, our multi-agent system significantly outperforms strong non-agent baselines. Experiments also show reinforcement learning further strengthens reasoning and planning for the trained agent. Code and data will be shared at https://longvideoagent.github.io/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [31] [HARMON-E: Hierarchical Agentic Reasoning for Multimodal Oncology Notes to Extract Structured Data](https://arxiv.org/abs/2512.19864)
*Shashi Kant Gupta, Arijeet Pramanik, Jerrin John Thomas, Regina Schwind, Lauren Wiener, Avi Raju, Jeremy Kornbluth, Yanshan Wang, Zhaohui Su, Hrituraj Singh*

**主要类别:** cs.CL

**AI概要:** 提出了一个基于LLM的智能代理框架，用于从非结构化电子病历中提取结构化肿瘤学数据，在大规模真实临床数据上取得高精度（平均F1-score 0.93），显著降低了人工标注成本。


<details>
  <summary>更多</summary>
  
**动机:** 电子病历中的非结构化临床笔记包含丰富的肿瘤治疗信息，但现有自动化方法无法有效处理大规模、多文档、信息矛盾的患者级数据提取问题，人工提取成本高昂且不可扩展。

**方法:** 使用大型语言模型作为推理代理，配备上下文敏感检索和迭代合成能力，将复杂的肿瘤数据提取任务分解为模块化、自适应的子任务，实现从真实世界肿瘤学笔记中全面提取结构化临床变量。

**结果:** 在超过40万份非结构化临床笔记和扫描PDF报告（涵盖2,250名癌症患者）的大规模数据集上评估，平均F1-score达0.93，103个肿瘤特异性临床变量中有100个超过0.85，关键变量（如生物标志物和药物）超过0.95。

**结论:** 这是首个基于LLM代理的大规模、端到端结构化肿瘤数据提取应用，系统集成到数据整理工作流中实现了0.94的直接人工批准率，显著提升了数据提取效率和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是HARMON-E%3A+Hierarchical+Agentic+Reasoning+for+Multimodal+Oncology+Notes+to+Extract+Structured+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.19864，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.19864&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Unstructured notes within the electronic health record (EHR) contain rich clinical information vital for cancer treatment decision making and research, yet reliably extracting structured oncology data remains challenging due to extensive variability, specialized terminology, and inconsistent document formats. Manual abstraction, although accurate, is prohibitively costly and unscalable. Existing automated approaches typically address narrow scenarios - either using synthetic datasets, restricting focus to document-level extraction, or isolating specific clinical variables (e.g., staging, biomarkers, histology) - and do not adequately handle patient-level synthesis across the large number of clinical documents containing contradictory information. In this study, we propose an agentic framework that systematically decomposes complex oncology data extraction into modular, adaptive tasks. Specifically, we use large language models (LLMs) as reasoning agents, equipped with context-sensitive retrieval and iterative synthesis capabilities, to exhaustively and comprehensively extract structured clinical variables from real-world oncology notes. Evaluated on a large-scale dataset of over 400,000 unstructured clinical notes and scanned PDF reports spanning 2,250 cancer patients, our method achieves an average F1-score of 0.93, with 100 out of 103 oncology-specific clinical variables exceeding 0.85, and critical variables (e.g., biomarkers and medications) surpassing 0.95. Moreover, integration of the agentic system into a data curation workflow resulted in 0.94 direct manual approval rate, significantly reducing annotation costs. To our knowledge, this constitutes the first exhaustive, end-to-end application of LLM-based agents for structured oncology data extraction at scale

</details>


### [32] [How well do Large Language Models Recognize Instructional Moves? Establishing Baselines for Foundation Models in Educational Discourse](https://arxiv.org/abs/2512.19903)
*Kirk Vanacore, Rene F. Kizilcec*

**主要类别:** cs.CL

**AI概要:** 研究比较了6个大型语言模型在教育场景中的零样本、单样本和少样本提示性能，发现少样本提示显著提升性能但仍有可靠性限制


<details>
  <summary>更多</summary>
  
**动机:** 随着LLM在教育技术中广泛应用，需要了解其在未经定制的情况下对真实教育场景的解读能力，为期望设定和基准测试提供依据

**方法:** 比较6个LLM在课堂记录教学行为分类任务上的表现，评估零样本、单样本和少样本三种提示方法

**结果:** 少样本提示显著提升最先进模型的性能（Cohen's Kappa达到0.58），但性能因教学行为类型而异，高召回率往往伴随更多假阳性

**结论:** 基础模型具有有意义但有限的教学话语解读能力，提示设计能展现其能力但不能消除根本的可靠性限制

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+well+do+Large+Language+Models+Recognize+Instructional+Moves%3F+Establishing+Baselines+for+Foundation+Models+in+Educational+Discourse，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.19903，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.19903&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are increasingly adopted in educational technologies for a variety of tasks, from generating instructional materials and assisting with assessment design to tutoring. While prior work has investigated how models can be adapted or optimized for specific tasks, far less is known about how well LLMs perform at interpreting authentic educational scenarios without significant customization. As LLM-based systems become widely adopted by learners and educators in everyday academic contexts, understanding their out-of-the-box capabilities is increasingly important for setting expectations and benchmarking. We compared six LLMs to estimate their baseline performance on a simple but important task: classifying instructional moves in authentic classroom transcripts. We evaluated typical prompting methods: zero-shot, one-shot, and few-shot prompting. We found that while zero-shot performance was moderate, providing comprehensive examples (few-shot prompting) significantly improved performance for state-of-the-art models, with the strongest configuration reaching Cohen's Kappa = 0.58 against expert-coded annotations. At the same time, improvements were neither uniform nor complete: performance varied considerably by instructional move, and higher recall frequently came at the cost of increased false positives. Overall, these findings indicate that foundation models demonstrate meaningful yet limited capacity to interpret instructional discourse, with prompt design helping to surface capability but not eliminating fundamental reliability constraints.

</details>


### [33] [Counterfactual LLM-based Framework for Measuring Rhetorical Style](https://arxiv.org/abs/2512.19908)
*Jingyi Qiu, Hong Chen, Zongyi Li*

**主要类别:** cs.CL

**AI概要:** 论文提出了一个基于LLM的反事实框架来量化机器学习论文中的修辞风格，发现愿景式修辞能显著预测论文关注度，且2023年后修辞强度大幅上升主要由LLM写作辅助驱动。


<details>
  <summary>更多</summary>
  
**动机:** AI发展引发了对机器学习论文中"炒作"现象的担忧，但缺乏独立于实质内容的修辞风格量化方法，难以区分实证结果强度与修辞风格。

**方法:** 使用多个人工智能修辞角色从相同实质内容生成反事实写作，通过LLM法官进行成对比较，并用Bradley-Terry模型聚合结果，分析了2017-2025年8,485篇ICLR论文。

**结果:** 愿景式修辞框架显著预测了下游关注度（引用和媒体关注），且2023年后修辞强度急剧上升，实证证明主要由LLM写作辅助工具采用驱动。

**结论:** LLM可作为测量和改进科学评估的工具，框架在角色选择稳健性和LLM判断与人工标注高相关性方面得到验证。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Counterfactual+LLM-based+Framework+for+Measuring+Rhetorical+Style，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.19908，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.19908&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The rise of AI has fueled growing concerns about ``hype'' in machine learning papers, yet a reliable way to quantify rhetorical style independently of substantive content has remained elusive. Because bold language can stem from either strong empirical results or mere rhetorical style, it is often difficult to distinguish between the two. To disentangle rhetorical style from substantive content, we introduce a counterfactual, LLM-based framework: multiple LLM rhetorical personas generate counterfactual writings from the same substantive content, an LLM judge compares them through pairwise evaluations, and the outcomes are aggregated using a Bradley--Terry model. Applying this method to 8,485 ICLR submissions sampled from 2017 to 2025, we generate more than 250,000 counterfactual writings and provide a large-scale quantification of rhetorical style in ML papers. We find that visionary framing significantly predicts downstream attention, including citations and media attention, even after controlling for peer-review evaluations. We also observe a sharp rise in rhetorical strength after 2023, and provide empirical evidence showing that this increase is largely driven by the adoption of LLM-based writing assistance. The reliability of our framework is validated by its robustness to the choice of personas and the high correlation between LLM judgments and human annotations. Our work demonstrates that LLMs can serve as instruments to measure and improve scientific evaluation.

</details>


### [34] [PRISM: A Personality-Driven Multi-Agent Framework for Social Media Simulation](https://arxiv.org/abs/2512.19933)
*Zhixiang Lu, Xueyuan Deng, Yiran Liu, Yulong Li, Qiang Yan, Imran Razzak, Jionglong Su*

**主要类别:** cs.CL

**AI概要:** PRISM模型结合随机微分方程和基于MBTI的PC-POMDP框架，有效模拟社交媒体中的意见极化现象，超越了传统同质化模型的局限。


<details>
  <summary>更多</summary>
  
**动机:** 传统基于代理的意见动态模型因同质化假设而无法捕捉在线极化的心理异质性，阻碍了对意识形态分裂机制的理解。

**方法:** 开发PRISM混合框架：使用随机微分方程(SDE)模拟连续情感演化，结合基于MBTI的个性条件部分可观察马尔可夫决策过程(PC-POMDP)进行离散决策，通过大规模社交媒体数据初始化多模态大语言模型代理。

**结果:** PRISM实现了与人类真实情况相符的个性一致性，显著优于标准同质化模型和Big Five基准，有效复制了理性抑制和情感共鸣等涌现现象。

**结论:** PRISM提供了一个强大的分析工具，能够有效模拟复杂社交媒体生态系统中的意见动态和极化现象，为理解个体认知偏见与信息传播的相互作用提供了机制性解释。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PRISM%3A+A+Personality-Driven+Multi-Agent+Framework+for+Social+Media+Simulation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.19933，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.19933&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Traditional agent-based models (ABMs) of opinion dynamics often fail to capture the psychological heterogeneity driving online polarization due to simplistic homogeneity assumptions. This limitation obscures the critical interplay between individual cognitive biases and information propagation, thereby hindering a mechanistic understanding of how ideological divides are amplified. To address this challenge, we introduce the Personality-Refracted Intelligent Simulation Model (PRISM), a hybrid framework coupling stochastic differential equations (SDE) for continuous emotional evolution with a personality-conditional partially observable Markov decision process (PC-POMDP) for discrete decision-making. In contrast to continuous trait approaches, PRISM assigns distinct Myers-Briggs Type Indicator (MBTI) based cognitive policies to multimodal large language model (MLLM) agents, initialized via data-driven priors from large-scale social media datasets. PRISM achieves superior personality consistency aligned with human ground truth, significantly outperforming standard homogeneous and Big Five benchmarks. This framework effectively replicates emergent phenomena such as rational suppression and affective resonance, offering a robust tool for analyzing complex social media ecosystems.

</details>


### [35] [Bias Beneath the Tone: Empirical Characterisation of Tone Bias in LLM-Driven UX Systems](https://arxiv.org/abs/2512.19950)
*Heet Bodara, Md Masum Mushfiq, Isma Farah Siddiqui*

**主要类别:** cs.CL

**AI概要:** 研究发现大型语言模型在对话中存在系统性的语调偏见，即使在中性提示下也会表现出过度礼貌、乐观或谨慎的倾向，通过合成对话数据集和分类器验证了这种偏见可测量且影响用户信任感知。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型在对话系统中广泛应用，但其回应可能携带微妙的语调偏见（如过度礼貌或乐观），这些偏见会影响用户对信任、同理心和公平性的感知，需要系统研究这种隐藏的行为特征。

**方法:** 创建两个合成对话数据集（中性提示生成和明确引导的正负语调生成），使用预训练的DistilBERT模型进行弱监督标注，训练多个分类器检测语调模式，采用集成模型进行分析。

**结果:** 即使中性数据集也显示出一致的语调偏差，集成模型达到0.92的宏观F1分数，证明语调偏见是系统性、可测量的。

**结论:** 大型语言模型存在固有的语调偏见，这种偏见影响对话AI的公平性和可信度设计，需要通过可控的对话合成和语调分类来识别和缓解这些偏见。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bias+Beneath+the+Tone%3A+Empirical+Characterisation+of+Tone+Bias+in+LLM-Driven+UX+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.19950，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.19950&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models are increasingly used in conversational systems such as digital personal assistants, shaping how people interact with technology through language. While their responses often sound fluent and natural, they can also carry subtle tone biases such as sounding overly polite, cheerful, or cautious even when neutrality is expected. These tendencies can influence how users perceive trust, empathy, and fairness in dialogue. In this study, we explore tone bias as a hidden behavioral trait of large language models. The novelty of this research lies in the integration of controllable large language model based dialogue synthesis with tone classification models, enabling robust and ethical emotion recognition in personal assistant interactions. We created two synthetic dialogue datasets, one generated from neutral prompts and another explicitly guided to produce positive or negative tones. Surprisingly, even the neutral set showed consistent tonal skew, suggesting that bias may stem from the model's underlying conversational style. Using weak supervision through a pretrained DistilBERT model, we labeled tones and trained several classifiers to detect these patterns. Ensemble models achieved macro F1 scores up to 0.92, showing that tone bias is systematic, measurable, and relevant to designing fair and trustworthy conversational AI.

</details>


### [36] [Schoenfeld's Anatomy of Mathematical Reasoning by Language Models](https://arxiv.org/abs/2512.19995)
*Ming Li, Chenrui Fan, Yize Cheng, Soheil Feizi, Tianyi Zhou*

**主要类别:** cs.CL

**AI概要:** 提出了ThinkARM框架，基于Schoenfeld的Episode Theory将语言模型的推理轨迹抽象为功能性步骤（分析、探索、实施、验证等），揭示了数学问题解决中的思维动态和结构差异。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法难以识别和分析语言模型推理轨迹的深层认知结构和步骤，需要更有效的分析框架。

**方法:** 采用Schoenfeld的Episode Theory作为归纳框架，开发ThinkARM将推理轨迹抽象为功能性步骤，应用于不同模型的数学问题解决分析。

**结果:** 揭示了推理模型与非推理模型之间的结构性差异，发现探索步骤与正确性相关，效率优化方法会选择性抑制评估反馈步骤。

**结论:** 片段级表示使推理步骤显式化，能够系统分析现代语言模型中推理的结构、稳定性和变化方式。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Schoenfeld%27s+Anatomy+of+Mathematical+Reasoning+by+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.19995，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.19995&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language models increasingly expose reasoning traces, yet their underlying cognitive structure and steps remain difficult to identify and analyze beyond surface-level statistics. We adopt Schoenfeld's Episode Theory as an inductive, intermediate-scale lens and introduce ThinkARM (Anatomy of Reasoning in Models), a scalable framework that explicitly abstracts reasoning traces into functional reasoning steps such as Analysis, Explore, Implement, Verify, etc. When applied to mathematical problem solving by diverse models, this abstraction reveals reproducible thinking dynamics and structural differences between reasoning and non-reasoning models, which are not apparent from token-level views. We further present two diagnostic case studies showing that exploration functions as a critical branching step associated with correctness, and that efficiency-oriented methods selectively suppress evaluative feedback steps rather than uniformly shortening responses. Together, our results demonstrate that episode-level representations make reasoning steps explicit, enabling systematic analysis of how reasoning is structured, stabilized, and altered in modern language models.

</details>


### [37] [Memory-T1: Reinforcement Learning for Temporal Reasoning in Multi-session Agents](https://arxiv.org/abs/2512.20092)
*Yiming Du, Baojun Wang, Yifan Xiang, Zhaowei Wang, Wenyu Huang, Boyang Xue, Bin Liang, Xingshan Zeng, Fei Mi, Haoli Bai, Lifeng Shang, Jeff Z. Pan, Yuxin Jiang, Kam-Fai Wong*

**主要类别:** cs.CL

**AI概要:** Memory-T1是一个通过强化学习实现时间感知记忆选择的新框架，用于处理长对话历史中的时序推理问题，在Time-Dialog基准测试中达到67.0%的SOTA性能


<details>
  <summary>更多</summary>
  
**动机:** 现有长上下文模型在处理长对话历史时难以准确识别时序相关信息，对话历史长度增加和噪声积累严重影响推理性能

**方法:** 采用粗到细策略：先用时间和相关性过滤器剪枝对话历史生成候选集，然后用RL代理选择精确证据会话；RL训练使用多级奖励函数优化答案准确性、证据基础和时序一致性

**结果:** 在Time-Dialog基准测试中，Memory-T1将7B模型提升至67.0%的总体分数，比14B基线提升10.2%；时序一致性和证据基础奖励共同贡献15.0%的性能提升；在128k tokens长度下仍保持鲁棒性

**结论:** Memory-T1通过时间感知记忆选择和强化学习奖励机制，有效解决了长对话历史中的时序推理挑战，为开源模型建立了新的性能标准，并展示了在超长上下文中的鲁棒性

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Memory-T1%3A+Reinforcement+Learning+for+Temporal+Reasoning+in+Multi-session+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20092，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20092&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Temporal reasoning over long, multi-session dialogues is a critical capability for conversational agents. However, existing works and our pilot study have shown that as dialogue histories grow in length and accumulate noise, current long-context models struggle to accurately identify temporally pertinent information, significantly impairing reasoning performance. To address this, we introduce Memory-T1, a framework that learns a time-aware memory selection policy using reinforcement learning (RL). It employs a coarse-to-fine strategy, first pruning the dialogue history into a candidate set using temporal and relevance filters, followed by an RL agent that selects the precise evidence sessions. The RL training is guided by a multi-level reward function optimizing (i) answer accuracy, (ii) evidence grounding, and (iii) temporal consistency. In particular, the temporal consistency reward provides a dense signal by evaluating alignment with the query time scope at both the session-level (chronological proximity) and the utterance-level (chronological fidelity), enabling the agent to resolve subtle chronological ambiguities. On the Time-Dialog benchmark, Memory-T1 boosts a 7B model to an overall score of 67.0\%, establishing a new state-of-the-art performance for open-source models and outperforming a 14B baseline by 10.2\%. Ablation studies show temporal consistency and evidence grounding rewards jointly contribute to a 15.0\% performance gain. Moreover, Memory-T1 maintains robustness up to 128k tokens, where baseline models collapse, proving effectiveness against noise in extensive dialogue histories. The code and datasets are publicly available at https://github.com/Elvin-Yiming-Du/Memory-T1/

</details>


### [38] [A Novel Graph-Sequence Learning Model for Inductive Text Classification](https://arxiv.org/abs/2512.20097)
*Zuo Wang, Ye Yuan*

**主要类别:** cs.CL

**AI概要:** 提出TextGSL模型，通过构建多边类型文本图并结合Transformer层，同时捕捉词汇间的多样化结构关系和序列信息，解决现有GNN文本分类方法的局限性。


<details>
  <summary>更多</summary>
  
**动机:** 现有基于GNN的文本分类方法存在两个主要问题：1) 未能充分考虑词汇对之间的多样化结构信息（如共现、语法、语义关系）；2) 在文本图结构学习中忽略序列信息，无法处理新词和新关系。

**方法:** 构建单文本级别的图结构，为每个文本中的所有词汇建立基于多样化关系的不同边类型；设计自适应多边消息传递范式来聚合词汇对间的多样化结构信息；通过集成Transformer层来捕捉文本数据的序列信息。

**结果:** 在多个基准数据集上的实验结果表明，TextGSL在准确率方面优于多个强基线模型。

**结论:** TextGSL模型通过结合图结构和序列信息的学习，能够学习到更具区分性的文本表示，有效解决了现有方法的局限性，在文本分类任务上表现出优越性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Novel+Graph-Sequence+Learning+Model+for+Inductive+Text+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20097，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20097&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Text classification plays an important role in various downstream text-related tasks, such as sentiment analysis, fake news detection, and public opinion analysis. Recently, text classification based on Graph Neural Networks (GNNs) has made significant progress due to their strong capabilities of structural relationship learning. However, these approaches still face two major limitations. First, these approaches fail to fully consider the diverse structural information across word pairs, e.g., co-occurrence, syntax, and semantics. Furthermore, they neglect sequence information in the text graph structure information learning module and can not classify texts with new words and relations. In this paper, we propose a Novel Graph-Sequence Learning Model for Inductive Text Classification (TextGSL) to address the previously mentioned issues. More specifically, we construct a single text-level graph for all words in each text and establish different edge types based on the diverse relationships between word pairs. Building upon this, we design an adaptive multi-edge message-passing paradigm to aggregate diverse structural information between word pairs. Additionally, sequential information among text data can be captured by the proposed TextGSL through the incorporation of Transformer layers. Therefore, TextGSL can learn more discriminative text representations. TextGSL has been comprehensively compared with several strong baselines. The experimental results on diverse benchmarking datasets demonstrate that TextGSL outperforms these baselines in terms of accuracy.

</details>


### [39] [ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language](https://arxiv.org/abs/2512.20111)
*Aly Lidayan, Jakob Bjorner, Satvik Golechha, Kartik Goyal, Alane Suhr*

**主要类别:** cs.CL

**AI概要:** ABBEL框架通过自然语言信念状态替代完整交互历史，实现多步决策任务的恒定内存使用，并通过RL训练提升性能，在保持可解释性的同时超越完整上下文设置的表现。


<details>
  <summary>更多</summary>
  
**动机:** 随着序列决策任务长度增加，完整交互历史的计算成本变得不可行，需要一种方法来维持简洁的上下文。

**方法:** 提出ABBEL框架：用自然语言信念状态（任务相关未知信息的摘要）替代历史记录；使用RL后训练改进ABBEL智能体，包括信念质量评分和长度惩罚。

**结果:** ABBEL在6个多步环境中保持近乎恒定的内存使用和可解释信念生成，但存在错误传播问题；RL训练后性能超越完整上下文设置，内存使用更少。

**结论:** ABBEL框架通过语言表达的信念瓶颈有效解决了长序列决策的内存问题，RL训练能克服错误传播并提升性能，为LLM智能体提供了可扩展的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ABBEL%3A+LLM+Agents+Acting+through+Belief+Bottlenecks+Expressed+in+Language，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20111，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20111&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** As the length of sequential decision-making tasks increases, it becomes computationally impractical to keep full interaction histories in context. We introduce a general framework for LLM agents to maintain concise contexts through multi-step interaction: Acting through Belief Bottlenecks Expressed in Language (ABBEL), and methods to further improve ABBEL agents with RL post-training. ABBEL replaces long multi-step interaction history by a belief state, i.e., a natural language summary of what has been discovered about task-relevant unknowns. Under ABBEL, at each step the agent first updates a prior belief with the most recent observation from the environment to form a posterior belief, then uses only the posterior to select an action. We systematically evaluate frontier models under ABBEL across six diverse multi-step environments, finding that ABBEL supports generating interpretable beliefs while maintaining near-constant memory use over interaction steps. However, bottleneck approaches are generally prone to error propagation, which we observe causing inferior performance when compared to the full context setting due to errors in belief updating. Therefore, we train LLMs to generate and act on beliefs within the ABBEL framework via reinforcement learning (RL). We experiment with belief grading, to reward higher quality beliefs, as well as belief length penalties to reward more compressed beliefs. Our experiments demonstrate the ability of RL to improve ABBEL's performance beyond the full context setting, while using less memory than contemporaneous approaches.

</details>


### [40] [M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation](https://arxiv.org/abs/2512.20136)
*Hyeongcheol Park, Jiyoung Seo, Jaewon Mun, Hogun Park, Wonmin Byeon, Sung June Kim, Hyeonsoo Im, JeungSub Lee, Sangpil Kim*

**主要类别:** cs.CL

**AI概要:** M³KG-RAG是一种多跳多模态知识图谱增强的检索增强生成方法，通过构建多跳多模态知识图谱和引入GRASP机制，解决了音频-视觉领域多模态RAG的模态覆盖不足和检索精度问题，显著提升了多模态大语言模型的推理能力和答案忠实度。


<details>
  <summary>更多</summary>
  
**动机:** 当前多模态RAG在音频-视觉领域面临两大挑战：1)现有多模态知识图谱的模态覆盖有限且缺乏多跳连接；2)基于共享嵌入空间相似度的检索无法过滤无关或冗余知识。

**方法:** 提出M³KG-RAG框架：1)使用轻量级多智能体管道构建多跳多模态知识图谱(M³KG)，包含上下文丰富的多模态实体三元组；2)引入GRASP机制，实现精确的实体接地、答案支持相关性评估和冗余上下文剪枝。

**结果:** 在多个多模态基准测试上的广泛实验表明，M³KG-RAG相比现有方法显著提升了多模态大语言模型的多模态推理和接地能力。

**结论:** M³KG-RAG通过多跳知识图谱构建和选择性检索剪枝机制，有效解决了多模态RAG的关键挑战，为音频-视觉领域的知识增强生成提供了有效解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是M%24%5E3%24KG-RAG%3A+Multi-hop+Multimodal+Knowledge+Graph-enhanced+Retrieval-Augmented+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20136，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20136&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Retrieval-Augmented Generation (RAG) has recently been extended to multimodal settings, connecting multimodal large language models (MLLMs) with vast corpora of external knowledge such as multimodal knowledge graphs (MMKGs). Despite their recent success, multimodal RAG in the audio-visual domain remains challenging due to 1) limited modality coverage and multi-hop connectivity of existing MMKGs, and 2) retrieval based solely on similarity in a shared multimodal embedding space, which fails to filter out off-topic or redundant knowledge. To address these limitations, we propose M$^3$KG-RAG, a Multi-hop Multimodal Knowledge Graph-enhanced RAG that retrieves query-aligned audio-visual knowledge from MMKGs, improving reasoning depth and answer faithfulness in MLLMs. Specifically, we devise a lightweight multi-agent pipeline to construct multi-hop MMKG (M$^3$KG), which contains context-enriched triplets of multimodal entities, enabling modality-wise retrieval based on input queries. Furthermore, we introduce GRASP (Grounded Retrieval And Selective Pruning), which ensures precise entity grounding to the query, evaluates answer-supporting relevance, and prunes redundant context to retain only knowledge essential for response generation. Extensive experiments across diverse multimodal benchmarks demonstrate that M$^3$KG-RAG significantly enhances MLLMs' multimodal reasoning and grounding over existing approaches.

</details>


### [41] [Multi-hop Reasoning via Early Knowledge Alignment](https://arxiv.org/abs/2512.20144)
*Yuxin Wang, Shicheng Fang, Bo Wang, Qi Luo, Xuanjing Huang, Yining Zheng, Xipeng Qiu*

**主要类别:** cs.CL

**AI概要:** EKA通过早期知识对齐模块，在迭代RAG系统中让LLM在规划前先与检索集对齐，显著提升检索精度和推理效率，减少级联错误。


<details>
  <summary>更多</summary>
  
**动机:** 现有迭代RAG系统在分解复杂多跳问题时，缺乏对检索语料库信息的利用，导致检索效率低下和推理链级联错误。

**方法:** 提出Early Knowledge Alignment (EKA)模块，在规划前用上下文相关的检索知识对齐LLM，建立更强的推理基础。

**结果:** 在六个标准RAG数据集上，EKA显著提高了检索精度，减少了级联错误，提升了性能和效率。从熵的角度分析显示减少了不必要的探索。

**结论:** EKA推进了迭代RAG系统的最新技术，揭示了强化学习增强框架中结构化推理与高效探索之间的关键相互作用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-hop+Reasoning+via+Early+Knowledge+Alignment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20144，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20144&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for Large Language Models (LLMs) to address knowledge-intensive queries requiring domain-specific or up-to-date information. To handle complex multi-hop questions that are challenging for single-step retrieval, iterative RAG approaches incorporating reinforcement learning have been proposed. However, existing iterative RAG systems typically plan to decompose questions without leveraging information about the available retrieval corpus, leading to inefficient retrieval and reasoning chains that cascade into suboptimal performance. In this paper, we introduce Early Knowledge Alignment (EKA), a simple but effective module that aligns LLMs with retrieval set before planning in iterative RAG systems with contextually relevant retrieved knowledge. Extensive experiments on six standard RAG datasets demonstrate that by establishing a stronger reasoning foundation, EKA significantly improves retrieval precision, reduces cascading errors, and enhances both performance and efficiency. Our analysis from an entropy perspective demonstrate that incorporating early knowledge reduces unnecessary exploration during the reasoning process, enabling the model to focus more effectively on relevant information subsets. Moreover, EKA proves effective as a versatile, training-free inference strategy that scales seamlessly to large models. Generalization tests across diverse datasets and retrieval corpora confirm the robustness of our approach. Overall, EKA advances the state-of-the-art in iterative RAG systems while illuminating the critical interplay between structured reasoning and efficient exploration in reinforcement learning-augmented frameworks. The code is released at \href{https://github.com/yxzwang/EarlyKnowledgeAlignment}{Github}.

</details>


### [42] [Retrieval-augmented Prompt Learning for Pre-trained Foundation Models](https://arxiv.org/abs/2512.20145)
*Xiang Chen, Yixin Ou, Quan Feng, Lei Li, Piji Li, Haibo Ye, Sheng-Jun Huang, Shuofei Qiao, Shumin Deng, Huajun Chen, Ningyu Zhang*

**主要类别:** cs.CL

**AI概要:** RetroPrompt是一种新的提示学习方法，通过引入检索机制从知识库中获取上下文信息，减少对死记硬背的依赖，提升预训练基础模型在零样本和少样本场景下的泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 传统提示学习方法仍遵循参数化学习范式，在记忆和死记硬背的泛化稳定性方面存在局限，难以充分利用非典型实例并避免在有限数据下对浅层模式的过拟合。

**方法:** 提出RetroPrompt方法，通过解耦知识与单纯记忆，在整个输入、训练和推理阶段引入检索机制，从训练数据生成的公开知识库中主动检索相关上下文信息。

**结果:** 在自然语言处理和计算机视觉任务的多数据集实验中，RetroPrompt在零样本和少样本场景下均表现出优越性能。

**结论:** RetroPrompt通过减少对死记硬背的依赖，有效增强了模型的泛化能力，为预训练基础模型的提示学习提供了新的平衡记忆与泛化的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Retrieval-augmented+Prompt+Learning+for+Pre-trained+Foundation+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20145，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20145&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The pre-trained foundation models (PFMs) have become essential for facilitating large-scale multimodal learning. Researchers have effectively employed the ``pre-train, prompt, and predict'' paradigm through prompt learning to induce improved few-shot performance. However, prompt learning approaches for PFMs still follow a parametric learning paradigm. As such, the stability of generalization in memorization and rote learning can be compromised. More specifically, conventional prompt learning might face difficulties in fully utilizing atypical instances and avoiding overfitting to shallow patterns with limited data during the process of fully-supervised training. To overcome these constraints, we present our approach, named RetroPrompt, which aims to achieve a balance between memorization and generalization by decoupling knowledge from mere memorization. Unlike traditional prompting methods, RetroPrompt leverages a publicly accessible knowledge base generated from the training data and incorporates a retrieval mechanism throughout the input, training, and inference stages. This enables the model to actively retrieve relevant contextual information from the corpus, thereby enhancing the available cues. We conduct comprehensive experiments on a variety of datasets across natural language processing and computer vision tasks to demonstrate the superior performance of our proposed approach, RetroPrompt, in both zero-shot and few-shot scenarios. Through detailed analysis of memorization patterns, we observe that RetroPrompt effectively reduces the reliance on rote memorization, leading to enhanced generalization.

</details>


### [43] [Fun-Audio-Chat Technical Report](https://arxiv.org/abs/2512.20156)
*Qian Chen, Luyao Cheng, Chong Deng, Xiangang Li, Jiaqing Liu, Chao-Hong Tan, Wen Wang, Junhao Xu, Jieping Ye, Qinglin Zhang, Qiquan Zhang, Jingren Zhou*

**主要类别:** cs.CL

**AI概要:** Fun-Audio-Chat是一个大型音频语言模型，通过双分辨率语音表示和核心鸡尾酒训练解决了语音-文本模型中的时域分辨率不匹配和灾难性遗忘问题，在多个音频任务上取得优异性能


<details>
  <summary>更多</summary>
  
**动机:** 现有联合语音-文本模型面临时域分辨率不匹配（25Hz语音token vs 3Hz文本token）导致语义信息稀释、计算成本高和文本LLM知识灾难性遗忘的问题

**方法:** 采用双分辨率语音表示（DRSR）在5Hz处理音频提高效率，25Hz生成高质量token；核心鸡尾酒训练两阶段微调缓解遗忘；多任务DPO训练增强鲁棒性

**结果:** Fun-Audio-Chat 8B和MoE 30B-A3B在语音转文本、语音转语音任务上表现优异，在口语问答基准测试中排名同类模型前列，在音频理解、语音功能调用等任务上达到竞争性到优越性能

**结论:** 该模型通过多阶段后训练成功保留了文本LLM知识同时获得强大的音频理解能力，无需大规模音频-文本预训练，为语音交互提供了高效解决方案

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fun-Audio-Chat+Technical+Report，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20156，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20156&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in joint speech-text models show great potential for seamless voice interactions. However, existing models face critical challenges: temporal resolution mismatch between speech tokens (25Hz) and text tokens (~3Hz) dilutes semantic information, incurs high computational costs, and causes catastrophic forgetting of text LLM knowledge. We introduce Fun-Audio-Chat, a Large Audio Language Model addressing these limitations via two innovations from our previous work DrVoice. First, Dual-Resolution Speech Representations (DRSR): the Shared LLM processes audio at efficient 5Hz (via token grouping), while the Speech Refined Head generates high-quality tokens at 25Hz, balancing efficiency (~50% GPU reduction) and quality. Second, Core-Cocktail Training, a two-stage fine-tuning with intermediate merging that mitigates catastrophic forgetting. We then apply Multi-Task DPO Training to enhance robustness, audio understanding, instruction-following and voice empathy. This multi-stage post-training enables Fun-Audio-Chat to retain text LLM knowledge while gaining powerful audio understanding, reasoning, and generation. Unlike recent LALMs requiring large-scale audio-text pre-training, Fun-Audio-Chat leverages pre-trained models and extensive post-training. Fun-Audio-Chat 8B and MoE 30B-A3B achieve competitive performance on Speech-to-Text and Speech-to-Speech tasks, ranking top among similar-scale models on Spoken QA benchmarks. They also achieve competitive to superior performance on Audio Understanding, Speech Function Calling, Instruction-Following and Voice Empathy. We develop Fun-Audio-Chat-Duplex, a full-duplex variant with strong performance on Spoken QA and full-duplex interactions. We open-source Fun-Audio-Chat-8B with training and inference code, and provide an interactive demo.

</details>


### [44] [AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications](https://arxiv.org/abs/2512.20164)
*Honglin Mu, Jinghao Liu, Kaiyang Wan, Rui Xing, Xiuying Chen, Timothy Baldwin, Wanxiang Che*

**主要类别:** cs.CL

**AI概要:** 研究发现LLMs在简历筛选等应用中容易受到对抗指令攻击，攻击成功率超过80%。论文提出了FIDS防御方法，结合LoRA适配实现了26.3%的攻击减少率，证明训练时防御优于推理时缓解策略。


<details>
  <summary>更多</summary>
  
**动机:** 发现LLMs在代码审查等成熟领域可能有防御机制，但在简历筛选和同行评审等常见应用中存在对抗指令攻击的漏洞，需要建立评估基准和防御方法。

**方法:** 建立简历筛选基准评估漏洞，评估两种防御机制：基于提示的防御和提出的FIDS方法（通过分离进行外部指令检测，使用LoRA适配）。

**结果:** 攻击成功率超过80%；提示防御减少10.1%攻击但误拒增加12.5%；FIDS减少15.4%攻击且误拒增加10.4%；组合方法实现26.3%攻击减少。

**结论:** 训练时防御在安全性和效用保持方面均优于推理时缓解措施，FIDS结合LoRA适配是有效的防御解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AI+Security+Beyond+Core+Domains%3A+Resume+Screening+as+a+Case+Study+of+Adversarial+Vulnerabilities+in+Specialized+LLM+Applications，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20164，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20164&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) excel at text comprehension and generation, making them ideal for automated tasks like code review and content moderation. However, our research identifies a vulnerability: LLMs can be manipulated by "adversarial instructions" hidden in input data, such as resumes or code, causing them to deviate from their intended task. Notably, while defenses may exist for mature domains such as code review, they are often absent in other common applications such as resume screening and peer review. This paper introduces a benchmark to assess this vulnerability in resume screening, revealing attack success rates exceeding 80% for certain attack types. We evaluate two defense mechanisms: prompt-based defenses achieve 10.1% attack reduction with 12.5% false rejection increase, while our proposed FIDS (Foreign Instruction Detection through Separation) using LoRA adaptation achieves 15.4% attack reduction with 10.4% false rejection increase. The combined approach provides 26.3% attack reduction, demonstrating that training-time defenses outperform inference-time mitigations in both security and utility preservation.

</details>


### [45] [FaithLens: Detecting and Explaining Faithfulness Hallucination](https://arxiv.org/abs/2512.20182)
*Shuzheng Si, Qingyi Wang, Haozhe Zhao, Yuzhuo Bai, Guanqiao Chen, Kangyang Luo, Gang Chen, Fanchao Qi, Minjia Zhang, Baobao Chang, Maosong Sun*

**主要类别:** cs.CL

**AI概要:** FaithLens是一个用于检测大语言模型输出中忠实性幻觉的模型，能够同时提供二元预测和解释，在12个任务上超越GPT-4等先进模型。


<details>
  <summary>更多</summary>
  
**动机:** 识别大语言模型输出中的忠实性幻觉对于实际应用（如检索增强生成和摘要）至关重要，需要提高模型的可信度。

**方法:** 通过先进LLMs合成带解释的训练数据，应用数据过滤策略确保标签正确性、解释质量和数据多样性，然后进行微调，并使用基于规则的强化学习优化预测正确性和解释质量。

**结果:** 8B参数的FaithLens在12个多样化任务上表现优于GPT-4等先进模型，能够产生高质量的解释，在可信度、效率和有效性方面达到独特平衡。

**结论:** FaithLens是一个成本效益高且有效的忠实性幻觉检测模型，通过联合预测和解释提高了大语言模型输出的可信度，在多个任务上展现出卓越性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FaithLens%3A+Detecting+and+Explaining+Faithfulness+Hallucination，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20182，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20182&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recognizing whether outputs from large language models (LLMs) contain faithfulness hallucination is crucial for real-world applications, e.g., retrieval-augmented generation and summarization. In this paper, we introduce FaithLens, a cost-efficient and effective faithfulness hallucination detection model that can jointly provide binary predictions and corresponding explanations to improve trustworthiness. To achieve this, we first synthesize training data with explanations via advanced LLMs and apply a well-defined data filtering strategy to ensure label correctness, explanation quality, and data diversity. Subsequently, we fine-tune the model on these well-curated training data as a cold start and further optimize it with rule-based reinforcement learning, using rewards for both prediction correctness and explanation quality. Results on 12 diverse tasks show that the 8B-parameter FaithLens outperforms advanced models such as GPT-4.1 and o3. Also, FaithLens can produce high-quality explanations, delivering a distinctive balance of trustworthiness, efficiency, and effectiveness.

</details>


### [46] [Corpus of Cross-lingual Dialogues with Minutes and Detection of Misunderstandings](https://arxiv.org/abs/2512.20204)
*Marko Čechovič, Natália Komorníková, Dominik Macháček, Ondřej Bojar*

**主要类别:** cs.CL

**AI概要:** 本文创建了一个跨语言对话语料库，包含5小时12种语言的语音数据，用于评估自动语音翻译系统，并提出使用大语言模型自动检测跨语言对话中的误解问题。


<details>
  <summary>更多</summary>
  
**动机:** 需要为评估跨语言会议中的自动语音翻译系统建立一个真实多样的评估语料库，以促进无共同语言者之间的交流。

**方法:** 创建包含12种语言的5小时语音语料库，包含自动和人工修正的英文翻译；手动标注误解并测试大语言模型（如Gemini）的自动检测能力。

**结果:** Gemini模型能够以77%的召回率和47%的精确度识别文本中的误解片段。

**结论:** 该语料库为跨语言翻译和总结研究提供了宝贵资源，大语言模型在误解检测方面显示出潜力但仍有改进空间。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Corpus+of+Cross-lingual+Dialogues+with+Minutes+and+Detection+of+Misunderstandings，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20204，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20204&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Speech processing and translation technology have the potential to facilitate meetings of individuals who do not share any common language. To evaluate automatic systems for such a task, a versatile and realistic evaluation corpus is needed. Therefore, we create and present a corpus of cross-lingual dialogues between individuals without a common language who were facilitated by automatic simultaneous speech translation. The corpus consists of 5 hours of speech recordings with ASR and gold transcripts in 12 original languages and automatic and corrected translations into English. For the purposes of research into cross-lingual summarization, our corpus also includes written summaries (minutes) of the meetings.
  Moreover, we propose automatic detection of misunderstandings. For an overview of this task and its complexity, we attempt to quantify misunderstandings in cross-lingual meetings. We annotate misunderstandings manually and also test the ability of current large language models to detect them automatically. The results show that the Gemini model is able to identify text spans with misunderstandings with recall of 77% and precision of 47%.

</details>


### [47] [SlideTailor: Personalized Presentation Slide Generation for Scientific Papers](https://arxiv.org/abs/2512.20292)
*Wenzheng Zeng, Mingyu Ouyang, Langyuan Cui, Hwee Tou Ng*

**主要类别:** cs.CL

**AI概要:** SlideTailor是一个基于人类行为启发的代理框架，通过论文-幻灯片示例对和视觉模板来隐式学习用户偏好，实现个性化幻灯片生成，并引入chain-of-speech机制增强内容与口头叙述的匹配度。


<details>
  <summary>更多</summary>
  
**动机:** 现有幻灯片生成方法因用户偏好不明确而导致结果不理想，需要一种能够根据用户个性化需求生成定制化幻灯片的解决方案。

**方法:** 提出SlideTailor框架，使用论文-幻灯片示例对和视觉模板作为隐式偏好输入，通过代理逐步生成可编辑幻灯片，并采用chain-of-speech机制确保内容与口头叙述对齐。

**结果:** 构建了包含多样化用户偏好的基准数据集，实验证明该框架能有效提取和泛化用户偏好，显著提升生成幻灯片质量。

**结论:** 该研究提出了一种新颖的用户对齐幻灯片生成方法，通过隐式偏好学习和chain-of-speech机制，实现了高质量的个性化幻灯片生成，为视频演示等下游应用提供了支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SlideTailor%3A+Personalized+Presentation+Slide+Generation+for+Scientific+Papers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20292，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20292&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Automatic presentation slide generation can greatly streamline content creation. However, since preferences of each user may vary, existing under-specified formulations often lead to suboptimal results that fail to align with individual user needs. We introduce a novel task that conditions paper-to-slides generation on user-specified preferences. We propose a human behavior-inspired agentic framework, SlideTailor, that progressively generates editable slides in a user-aligned manner. Instead of requiring users to write their preferences in detailed textual form, our system only asks for a paper-slides example pair and a visual template - natural and easy-to-provide artifacts that implicitly encode rich user preferences across content and visual style. Despite the implicit and unlabeled nature of these inputs, our framework effectively distills and generalizes the preferences to guide customized slide generation. We also introduce a novel chain-of-speech mechanism to align slide content with planned oral narration. Such a design significantly enhances the quality of generated slides and enables downstream applications like video presentations. To support this new task, we construct a benchmark dataset that captures diverse user preferences, with carefully designed interpretable metrics for robust evaluation. Extensive experiments demonstrate the effectiveness of our framework.

</details>


### [48] [AprielGuard](https://arxiv.org/abs/2512.20293)
*Jaykumar Kasundra, Anjaneya Praharaj, Sourabh Surana, Lakshmi Sirisha Chodisetty, Sourav Sharma, Abhigya Verma, Abhishek Bhardwaj, Debasish Kanhar, Aakash Bhagat, Khalil Slimi, Seganrasan Subramanian, Sathwik Tejaswi Madhusudhan, Ranga Prasad Chenna, Srinivas Sunkara*

**主要类别:** cs.CL

**AI概要:** AprielGuard是一个8B参数的安全防护模型，统一处理LLM的安全风险和对抗性威胁，在多种基准测试中表现优于现有开源防护系统。


<details>
  <summary>更多</summary>
  
**动机:** 现有防护工具将安全风险（如毒性、偏见）和对抗性威胁（如提示注入、越狱）作为独立问题处理，限制了其鲁棒性和泛化能力。

**方法:** 开发8B参数的AprielGuard模型，使用开放和合成数据的混合训练集，涵盖独立提示、多轮对话和代理工作流，并通过结构化推理轨迹增强可解释性。

**结果:** 在多个公共和专有基准测试中，AprielGuard在检测有害内容和对抗性操作方面表现强劲，特别是在多步骤和推理密集型场景中优于Llama-Guard和Granite Guardian等现有开源防护系统。

**结论:** 通过发布该模型，旨在推动LLM可靠防护的透明和可重复研究，为LLM在对话和代理设置中的安全部署提供更强大的保障。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AprielGuard，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20293，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20293&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Safeguarding large language models (LLMs) against unsafe or adversarial behavior is critical as they are increasingly deployed in conversational and agentic settings. Existing moderation tools often treat safety risks (e.g. toxicity, bias) and adversarial threats (e.g. prompt injections, jailbreaks) as separate problems, limiting their robustness and generalizability. We introduce AprielGuard, an 8B parameter safeguard model that unify these dimensions within a single taxonomy and learning framework. AprielGuard is trained on a diverse mix of open and synthetic data covering standalone prompts, multi-turn conversations, and agentic workflows, augmented with structured reasoning traces to improve interpretability. Across multiple public and proprietary benchmarks, AprielGuard achieves strong performance in detecting harmful content and adversarial manipulations, outperforming existing opensource guardrails such as Llama-Guard and Granite Guardian, particularly in multi-step and reasoning intensive scenarios. By releasing the model, we aim to advance transparent and reproducible research on reliable safeguards for LLMs.

</details>


### [49] [Patterns vs. Patients: Evaluating LLMs against Mental Health Professionals on Personality Disorder Diagnosis through First-Person Narratives](https://arxiv.org/abs/2512.20298)
*Karolina Drożdż, Kacper Dudzic, Anna Sterna, Marcin Moskalewicz*

**主要类别:** cs.CL

**AI概要:** 本研究首次直接比较了最先进的大语言模型与心理健康专家在诊断边缘型和自恋型人格障碍方面的表现，发现Gemini Pro模型在总体诊断准确率上超过人类专家21.91个百分点，但在自恋型人格障碍诊断中存在严重低估问题。


<details>
  <summary>更多</summary>
  
**动机:** 随着人们越来越依赖大语言模型进行精神病学自我评估，需要验证这些模型在解释定性患者叙述方面的能力，特别是对人格障碍的诊断准确性。

**方法:** 利用波兰语的第一人称自传体叙述，对比最先进的大语言模型（Gemini Pro）与心理健康专业人士在诊断边缘型人格障碍（BPD）和自恋型人格障碍（NPD）的表现。

**结果:** Gemini Pro模型总体诊断准确率为65.48%，显著高于人类专家的43.57%。在BPD诊断上两者表现相当（F1分数83.4 vs 80.0），但在NPD诊断上模型严重低估（F1分数6.7 vs 50.0），模型对"自恋"这个价值负载术语表现出回避倾向。

**结论:** 虽然大语言模型在解释复杂的第一人称临床数据方面表现出色，但仍存在关键的可靠性和偏见问题，特别是在涉及价值负载的诊断标签时。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Patterns+vs.+Patients%3A+Evaluating+LLMs+against+Mental+Health+Professionals+on+Personality+Disorder+Diagnosis+through+First-Person+Narratives，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20298，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20298&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Growing reliance on LLMs for psychiatric self-assessment raises questions about their ability to interpret qualitative patient narratives. We present the first direct comparison between state-of-the-art LLMs and mental health professionals in diagnosing Borderline (BPD) and Narcissistic (NPD) Personality Disorders utilizing Polish-language first-person autobiographical accounts. We show that the top-performing Gemini Pro models surpassed human professionals in overall diagnostic accuracy by 21.91 percentage points (65.48% vs. 43.57%). While both models and human experts excelled at identifying BPD (F1 = 83.4 & F1 = 80.0, respectively), models severely underdiagnosed NPD (F1 = 6.7 vs. 50.0), showing a reluctance toward the value-laden term "narcissism." Qualitatively, models provided confident, elaborate justifications focused on patterns and formal categories, while human experts remained concise and cautious, emphasizing the patient's sense of self and temporal experience. Our findings demonstrate that while LLMs are highly competent at interpreting complex first-person clinical data, they remain subject to critical reliability and bias issues.

</details>


### [50] [SpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision](https://arxiv.org/abs/2512.20308)
*Maxime Poli, Mahi Luthra, Youssef Benchekroun, Yosuke Higuchi, Martin Gleize, Jiayi Shen, Robin Algayres, Yu-An Chung, Mido Assran, Juan Pino, Emmanuel Dupoux*

**主要类别:** cs.CL

**AI概要:** SpidR是一种自监督语音表示模型，通过掩码预测、自蒸馏和在线聚类从原始波形学习语音表示，在语言建模任务上优于现有模型，且预训练时间大幅缩短。


<details>
  <summary>更多</summary>
  
**动机:** 语言建模和语音表示学习的并行发展使得直接从语音学习语言成为可能，这需要从语音中直接提取语义表示。

**方法:** 使用掩码预测目标结合自蒸馏和在线聚类训练模型，学生模型的中间层学习预测来自教师模型中间层的分配，从而稳定在线聚类过程。

**结果:** SpidR在sWUGGY、sBLIMP、tSC等语言建模基准测试中优于wav2vec 2.0、HuBERT、WavLM和DinoSR；验证了语音单元质量指标与语言建模性能的相关性；预训练时间从一周缩短到一天。

**结论:** SpidR提供了高质量的语音表示，特别适合无文本语音语言建模，其高效训练方法使得快速迭代和实验成为可能，相关代码和模型已开源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SpidR%3A+Learning+Fast+and+Stable+Linguistic+Units+for+Spoken+Language+Models+Without+Supervision，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20308，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20308&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The parallel advances in language modeling and speech representation learning have raised the prospect of learning language directly from speech without textual intermediates. This requires extracting semantic representations directly from speech. Our contributions are threefold. First, we introduce SpidR, a self-supervised speech representation model that efficiently learns representations with highly accessible phonetic information, which makes it particularly suited for textless spoken language modeling. It is trained on raw waveforms using a masked prediction objective combined with self-distillation and online clustering. The intermediate layers of the student model learn to predict assignments derived from the teacher's intermediate layers. This learning objective stabilizes the online clustering procedure compared to previous approaches, resulting in higher quality codebooks. SpidR outperforms wav2vec 2.0, HuBERT, WavLM, and DinoSR on downstream language modeling benchmarks (sWUGGY, sBLIMP, tSC). Second, we systematically evaluate across models and layers the correlation between speech unit quality (ABX, PNMI) and language modeling performance, validating these metrics as reliable proxies. Finally, SpidR significantly reduces pretraining time compared to HuBERT, requiring only one day of pretraining on 16 GPUs, instead of a week. This speedup is enabled by the pretraining method and an efficient codebase, which allows faster iteration and easier experimentation. We open-source the training code and model checkpoints at https://github.com/facebookresearch/spidr.

</details>


### [51] [Can LLMs Solve My Grandma's Riddle? Evaluating Multilingual Large Language Models on Reasoning Traditional Bangla Tricky Riddles](https://arxiv.org/abs/2512.20324)
*Nurul Labib Sayeedi, Md. Faiyaz Abdullah Sayeedi, Khushnur Binte Jahangir, Swakkhar Shatabda, Sarah Masud Preum*

**主要类别:** cs.CL

**AI概要:** 论文介绍了BanglaRiddleEval基准测试，包含1,244个孟加拉语谜语，评估LLM在低资源比喻推理任务上的表现，结果显示当前模型远未达到人类水平。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型在NLP基准测试中表现优异，但在比喻性、文化基础和低资源环境中的推理能力研究不足，特别是在孟加拉语这样的低资源语言中。

**方法:** 构建包含4个任务的BanglaRiddleEval基准（共4,976个谜语任务），使用LLM生成思维链解释、语义干扰项和模糊性标注，评估开源和闭源模型在不同提示策略下的表现。

**结果:** 模型在生成式问答中具有中等语义重叠但正确率低，多项选择题准确率最高仅约56%（人类基线83%），模糊性解析范围在26%-68%之间，高质量解释仅限于最强模型。

**结论:** 当前LLM能够捕捉孟加拉语谜语推理的部分线索，但距离人类水平仍有很大差距，BanglaRiddleEval为低资源比喻推理提供了一个具有挑战性的新基准。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Can+LLMs+Solve+My+Grandma%27s+Riddle%3F+Evaluating+Multilingual+Large+Language+Models+on+Reasoning+Traditional+Bangla+Tricky+Riddles，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20324，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20324&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) show impressive performance on many NLP benchmarks, yet their ability to reason in figurative, culturally grounded, and low-resource settings remains underexplored. We address this gap for Bangla by introducing BanglaRiddleEval, a benchmark of 1,244 traditional Bangla riddles instantiated across four tasks (4,976 riddle-task artifacts in total). Using an LLM-based pipeline, we generate Chain-of-Thought explanations, semantically coherent distractors, and fine-grained ambiguity annotations, and evaluate a diverse suite of open-source and closed-source models under different prompting strategies. Models achieve moderate semantic overlap on generative QA but low correctness, MCQ accuracy peaks at only about 56% versus an 83% human baseline, and ambiguity resolution ranges from roughly 26% to 68%, with high-quality explanations confined to the strongest models. These results show that current LLMs capture some cues needed for Bangla riddle reasoning but remain far from human-level performance, establishing BanglaRiddleEval as a challenging new benchmark for low-resource figurative reasoning. All data, code, and evaluation scripts are available on GitHub: https://github.com/Labib1610/BanglaRiddleEval.

</details>


### [52] [Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen's Kappa and Semantic Similarity for Qualitative Research Validation](https://arxiv.org/abs/2512.20352)
*Nilesh Jain, Seyi Adeyinka, Leor Roseman, Aza Allsop*

**主要类别:** cs.CL

**AI概要:** 提出一个多视角验证框架，使用LLM进行主题分析，结合集成验证和双重可靠性指标（Cohen's Kappa和余弦相似度），证明大语言模型在定性研究中能实现高可靠性。


<details>
  <summary>更多</summary>
  
**动机:** 传统定性研究的评分者间一致性方法需要多个人类编码员，耗时且一致性中等，需要更高效的可靠性验证方法。

**方法:** 开发多视角验证框架，支持可配置参数（1-6种子，温度0.0-2.0），自定义提示结构，使用三种领先LLM（Gemini 2.5 Pro、GPT-4o、Claude 3.5 Sonnet）进行六次独立运行，评估迷幻艺术治疗访谈记录。

**结果:** Gemini可靠性最高（κ=0.907，余弦相似度95.3%），GPT-4o次之（κ=0.853，92.6%），Claude第三（κ=0.842，92.1%）。所有模型κ>0.80，成功提取共识主题。

**结论:** 该框架为AI辅助定性研究提供了可靠的方法论基础，具有透明可靠性指标、灵活配置和结构无关的共识提取功能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-LLM+Thematic+Analysis+with+Dual+Reliability+Metrics%3A+Combining+Cohen%27s+Kappa+and+Semantic+Similarity+for+Qualitative+Research+Validation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20352，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20352&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Qualitative research faces a critical reliability challenge: traditional inter-rater agreement methods require multiple human coders, are time-intensive, and often yield moderate consistency. We present a multi-perspective validation framework for LLM-based thematic analysis that combines ensemble validation with dual reliability metrics: Cohen's Kappa ($κ$) for inter-rater agreement and cosine similarity for semantic consistency. Our framework enables configurable analysis parameters (1-6 seeds, temperature 0.0-2.0), supports custom prompt structures with variable substitution, and provides consensus theme extraction across any JSON format. As proof-of-concept, we evaluate three leading LLMs (Gemini 2.5 Pro, GPT-4o, Claude 3.5 Sonnet) on a psychedelic art therapy interview transcript, conducting six independent runs per model. Results demonstrate Gemini achieves highest reliability ($κ= 0.907$, cosine=95.3%), followed by GPT-4o ($κ= 0.853$, cosine=92.6%) and Claude ($κ= 0.842$, cosine=92.1%). All three models achieve a high agreement ($κ> 0.80$), validating the multi-run ensemble approach. The framework successfully extracts consensus themes across runs, with Gemini identifying 6 consensus themes (50-83% consistency), GPT-4o identifying 5 themes, and Claude 4 themes. Our open-source implementation provides researchers with transparent reliability metrics, flexible configuration, and structure-agnostic consensus extraction, establishing methodological foundations for reliable AI-assisted qualitative research.

</details>


### [53] [Sentiment-Aware Extractive and Abstractive Summarization for Unstructured Text Mining](https://arxiv.org/abs/2512.20404)
*Junyi Liu, Stanley Kok*

**主要类别:** cs.CL

**AI概要:** 提出了一种情感感知的文本摘要框架，通过将情感信号融入抽取式(TextRank)和生成式(UniLM)方法，改进对非结构化社交媒体文本的情感捕捉和主题相关性。


<details>
  <summary>更多</summary>
  
**动机:** 随着社交媒体、评论和论坛等非结构化数据的快速增长，传统针对结构化新闻优化的摘要方法难以处理噪声大、非正式的内容，而情感线索对于品牌监控和市场分析等信息系统任务至关重要。

**方法:** 扩展抽取式(TextRank)和抽象式(UniLM)方法，将情感信号嵌入到排名和生成过程中，采用双设计方法来捕捉情感细微差别和主题相关性。

**结果:** 该框架能够产生简洁、情感丰富的摘要，改进了对情感细微差别的捕捉和主题相关性。

**结论:** 情感感知摘要框架能够增强动态在线环境中的及时干预和战略决策能力，为信息系统中的文本挖掘提供更有效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sentiment-Aware+Extractive+and+Abstractive+Summarization+for+Unstructured+Text+Mining，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20404，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20404&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** With the rapid growth of unstructured data from social media, reviews, and forums, text mining has become essential in Information Systems (IS) for extracting actionable insights. Summarization can condense fragmented, emotion-rich posts, but existing methods-optimized for structured news-struggle with noisy, informal content. Emotional cues are critical for IS tasks such as brand monitoring and market analysis, yet few studies integrate sentiment modeling into summarization of short user-generated texts. We propose a sentiment-aware framework extending extractive (TextRank) and abstractive (UniLM) approaches by embedding sentiment signals into ranking and generation processes. This dual design improves the capture of emotional nuances and thematic relevance, producing concise, sentiment-enriched summaries that enhance timely interventions and strategic decision-making in dynamic online environments.

</details>


### [54] [Step-DeepResearch Technical Report](https://arxiv.org/abs/2512.20491)
*Chen Hu, Haikuo Du, Heng Wang, Lin Lin, Mingrui Chen, Peng Liu, Ruihang Miao, Tianchi Yue, Wang You, Wei Ji, Wei Yuan, Wenjin Deng, Xiaojian Yuan, Xiaoyun Zhang, Xiangyu Liu, Xikai Liu, Yanming Xu, Yicheng Cao, Yifei Zhang, Yongyao Wang, Yubo Shu, Yurong Zhang, Yuxiang Zhang, Zheng Gong, Zhichao Chang, Binyan Li, Dan Ma, Furong Jia, Hongyuan Wang, Jiayu Liu, Jing Bai, Junlan Liu, Manjiao Liu, Na Wang, Qiuping Wu, Qinxin Du, Shiwei Li, Wen Sun, Yifeng Gong, Yonglin Chen, Yuling Zhao, Yuxuan Lin, Ziqi Ren, Zixuan Wang, Aihu Zhang, Brian Li, Buyun Ma, Kang An, Li Xie, Mingliang Li, Pan Li, Shidong Yang, Xi Chen, Xiaojia Liu, Yuchu Luo, Yuan Song, YuanHao Ding, Yuanwei Liang, Zexi Li, Zhaoning Zhang, Zixin Zhang, Binxing Jiao, Daxin Jiang, Jiansheng Chen, Jing Li, Xiangyu Zhang, Yibo Zhu*

**主要类别:** cs.CL

**AI概要:** Step-DeepResearch是一个成本效益高的端到端智能代理，通过原子能力数据合成策略和渐进式训练路径，在深度研究任务中表现出色，32B模型在Scale AI Research Rubrics上获得61.4%分数，在中文ADR-Bench基准上媲美闭源SOTA模型。


<details>
  <summary>更多</summary>
  
**动机:** 现有学术基准如BrowseComp无法满足现实世界中开放式深度研究的需求，缺乏意图识别、长程决策和跨源验证等关键能力，特别是在中文领域存在评估空白。

**方法:** 提出基于原子能力的数据合成策略来增强规划和报告写作能力，采用从智能代理中期训练到SFT和RL的渐进式训练路径，并使用清单式判断器提高鲁棒性。建立了中文领域的ADR-Bench评估基准。

**结果:** Step-DeepResearch (32B)在Scale AI Research Rubrics上获得61.4%的分数，在ADR-Bench上显著优于同类模型，与OpenAI和Gemini DeepResearch等闭源SOTA模型相媲美。

**结论:** 精细化训练可以使中等规模模型以行业领先的成本效益实现专家级能力，证明了该方法在深度研究任务中的有效性和实用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Step-DeepResearch+Technical+Report，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20491，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20491&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** As LLMs shift toward autonomous agents, Deep Research has emerged as a pivotal metric. However, existing academic benchmarks like BrowseComp often fail to meet real-world demands for open-ended research, which requires robust skills in intent recognition, long-horizon decision-making, and cross-source verification. To address this, we introduce Step-DeepResearch, a cost-effective, end-to-end agent. We propose a Data Synthesis Strategy Based on Atomic Capabilities to reinforce planning and report writing, combined with a progressive training path from agentic mid-training to SFT and RL. Enhanced by a Checklist-style Judger, this approach significantly improves robustness. Furthermore, to bridge the evaluation gap in the Chinese domain, we establish ADR-Bench for realistic deep research scenarios. Experimental results show that Step-DeepResearch (32B) scores 61.4% on Scale AI Research Rubrics. On ADR-Bench, it significantly outperforms comparable models and rivals SOTA closed-source models like OpenAI and Gemini DeepResearch. These findings prove that refined training enables medium-sized models to achieve expert-level capabilities at industry-leading cost-efficiency.

</details>


### [55] [Distilling to Hybrid Attention Models via KL-Guided Layer Selection](https://arxiv.org/abs/2512.20569)
*Yanhong Li, Songlin Yang, Shawn Tan, Mayank Mishra, Rameswar Panda, Jiawei Zhou, Yoon Kim*

**主要类别:** cs.CL

**AI概要:** 提出一种基于层重要性分数的简单有效方法，用于选择将预训练Transformer中哪些softmax注意力层转换为线性注意力层，以提高推理效率。


<details>
  <summary>更多</summary>
  
**动机:** 通过蒸馏预训练softmax注意力Transformer为混合架构（交替使用softmax和线性注意力层），可以在不重新预训练的情况下提高LLM的推理效率，而层选择是转换过程中的关键因素。

**方法:** 使用通用文本数据上的少量训练来获取层重要性分数，基于这些分数选择要转换的层，然后采用RADLADS蒸馏流程（包括注意力权重转移、隐藏状态对齐、KL分布匹配和少量微调）。

**结果:** 该方法比现有的层选择方法更有效，包括基于固定比例均匀交错线性注意力的启发式方法，以及依赖专用诊断数据集的复杂方法。

**结论:** 提出的层选择配方简单高效，能够有效指导混合注意力架构的构建，为提升LLM推理效率提供了实用解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Distilling+to+Hybrid+Attention+Models+via+KL-Guided+Layer+Selection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20569，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20569&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Distilling pretrained softmax attention Transformers into more efficient hybrid architectures that interleave softmax and linear attention layers is a promising approach for improving the inference efficiency of LLMs without requiring expensive pretraining from scratch. A critical factor in the conversion process is layer selection, i.e., deciding on which layers to convert to linear attention variants. This paper describes a simple and efficient recipe for layer selection that uses layer importance scores derived from a small amount of training on generic text data. Once the layers have been selected we use a recent pipeline for the distillation process itself \citep[RADLADS;][]{goldstein2025radlads}, which consists of attention weight transfer, hidden state alignment, KL-based distribution matching, followed by a small amount of finetuning. We find that this approach is more effective than existing approaches for layer selection, including heuristics that uniformly interleave linear attentions based on a fixed ratio, as well as more involved approaches that rely on specialized diagnostic datasets.

</details>


### [56] [Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits](https://arxiv.org/abs/2512.20578)
*Amirhosein Ghasemabadi, Di Niu*

**主要类别:** cs.CL

**AI概要:** Gnosis是一种轻量级自感知机制，通过分析LLM内部状态（隐藏状态和注意力模式）来预测模型自身生成内容的正确性，无需外部监督且计算成本极低。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法依赖外部评判、多样本一致性或文本自评，这些方法计算成本高且与真实正确性关联较弱。研究探索是否可以通过LLM内部状态来预测其自身错误。

**方法:** 引入Gnosis机制，被动观察LLM推理过程中的内部痕迹（隐藏状态和注意力模式），将其压缩为固定预算的描述符，仅增加约500万参数，独立于序列长度运行。

**结果:** 在数学推理、开放域问答和学术知识基准测试中，Gnosis在准确性和校准方面均优于强内部基线和大型外部评判器，并能零样本泛化到部分生成内容，实现早期错误检测。

**结论:** 可靠的正确性线索内在于生成过程，无需外部监督即可高效提取，为LLM自我验证提供了有效解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Can+LLMs+Predict+Their+Own+Failures%3F+Self-Awareness+via+Internal+Circuits，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20578，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20578&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) generate fluent and complex outputs but often fail to recognize their own mistakes and hallucinations. Existing approaches typically rely on external judges, multi-sample consistency, or text-based self-critique, which incur additional compute or correlate weakly with true correctness. We ask: can LLMs predict their own failures by inspecting internal states during inference? We introduce Gnosis, a lightweight self-awareness mechanism that enables frozen LLMs to perform intrinsic self-verification by decoding signals from hidden states and attention patterns. Gnosis passively observes internal traces, compresses them into fixed-budget descriptors, and predicts correctness with negligible inference cost, adding only ~5M parameters and operating independently of sequence length. Across math reasoning, open-domain question answering, and academic knowledge benchmarks, and over frozen backbones ranging from 1.7B to 20B parameters, Gnosis consistently outperforms strong internal baselines and large external judges in both accuracy and calibration. Moreover, it generalizes zero-shot to partial generations, enabling early detection of failing trajectories and compute-aware control. These results show that reliable correctness cues are intrinsic to generation process and can be extracted efficiently without external supervision.

</details>


### [57] [Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs](https://arxiv.org/abs/2512.20595)
*Dhruv Anand, Ehsan Shareghi*

**主要类别:** cs.CL

**AI概要:** Cube Bench是一个用于评估多模态大语言模型空间和序列推理能力的魔方基准测试，包含五个技能维度，测试结果显示模型性能随魔方复杂度增加而急剧下降，开源与闭源模型存在明显差距。


<details>
  <summary>更多</summary>
  
**动机:** 需要评估多模态大语言模型在空间和序列推理方面的能力，特别是处理魔方这类需要多步空间推理的复杂任务。

**方法:** 设计包含五个技能的基准测试：图像和文本重构魔方面、选择最优下一步、预测候选移动结果、执行多步计划并纠错、检测和修正自身错误。使用统一的魔方状态、提示词和解析器，通过距离解的距离作为评估指标。

**结果:** 测试7个MLLM模型，发现准确率随魔方复杂度深度增加而急剧下降；模型一旦出错很难恢复；闭源模型表现优于开源模型；简单的自我修正能带来一定提升但可能过度思考。

**结论:** Cube Bench提供了一个紧凑、可复现的测试框架来评估MLLM的序列空间推理能力，揭示了当前模型在处理复杂空间序列任务时的局限性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Cube+Bench%3A+A+Benchmark+for+Spatial+Visual+Reasoning+in+MLLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20595，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20595&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We introduce Cube Bench, a Rubik's-cube benchmark for evaluating spatial and sequential reasoning in multimodal large language models (MLLMs). The benchmark decomposes performance into five skills: (i) reconstructing cube faces from images and text, (ii) choosing the optimal next move, (iii) predicting the outcome of a candidate move without applying it, (iv) executing multi-step plans while recovering from mistakes, and (v) detecting and revising one's own errors. Using a shared set of scrambled cube states, identical prompts and parsers, and a single distance-to-solved metric, we compare recent MLLMs side by side as a function of scramble depth. Across seven MLLMs, accuracy drops sharply with depth; once a trajectory stalls or diverges, models rarely recover, and high face-reconstruction accuracy does not guarantee competent action selection or multi-step execution. A pronounced closed- vs open-source gap emerges: the strongest closed model leads on both single-step perception tasks and multi-step control tasks, while open-weight models cluster near chance on the hardest settings; yet even the best MLLM degrades at higher cube complexity. A simple self-correction via reflective thinking yields modest gains but can also introduce overthinking. Cube Bench offers a compact, reproducible probe of sequential spatial reasoning in MLLMs.

</details>


### [58] [MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts](https://arxiv.org/abs/2512.20604)
*Alexandros Christoforos, Chadbourne Davis*

**主要类别:** cs.CL

**AI概要:** MoE-DiffuSeq是一个基于专家混合框架的扩散模型，专门针对长文档生成优化，通过稀疏注意力和专家混合架构显著提升计算效率和生成质量。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于扩散的文本生成模型（如DiffuSeq）在处理长序列时存在高计算成本和内存开销的问题，限制了其在长文档生成场景的应用。

**方法:** 集成稀疏注意力机制与专家混合架构，引入定制化的稀疏注意力降低计算复杂度，并在扩散过程中加入软吸收状态以加速序列重建和提高生成精度。

**结果:** 实验表明MoE-DiffuSeq在训练效率和采样速度上显著优于现有扩散模型，特别在科学文章生成、代码库建模和长对话生成等长文档场景中表现出色。

**结论:** MoE-DiffuSeq提升了扩散模型在高质量长文本生成中的效率、速度、准确性和表达能力，推动了扩散模型在实际应用中的可行性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MoE-DiffuSeq%3A+Enhancing+Long-Document+Diffusion+Models+with+Sparse+Attention+and+Mixture+of+Experts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2512.20604，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2512.20604&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We present MoE-DiffuSeq, a mixture of experts based framework for enhancing diffusion models in long document generation. Existing diffusion based text generation models, such as DiffuSeq, suffer from high computational cost and memory overhead when applied to extended sequences. To address these challenges, MoE-DiffuSeq integrates sparse attention with a mixture of experts architecture, enabling efficient and scalable long sequence modeling. Our approach introduces a customized sparse attention mechanism designed to reduce computational complexity while preserving text quality and coherence. In addition, we incorporate a soft absorbing state within the diffusion process to accelerate sequence reconstruction and improve generation precision. Extensive experiments demonstrate that MoE-DiffuSeq significantly improves training efficiency and sampling speed compared to existing diffusion models. These advantages are particularly effective for long document scenarios, including scientific article generation, code repository modeling, and long form dialogue generation. Benchmark results further show that MoE-DiffuSeq improves efficiency, speed, accuracy, and expressiveness, advancing the practical applicability of diffusion models for high quality long form text generation.

</details>
