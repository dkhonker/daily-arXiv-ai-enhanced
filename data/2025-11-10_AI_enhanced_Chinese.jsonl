{"id": "2511.04685", "pdf": "https://arxiv.org/pdf/2511.04685", "abs": "https://arxiv.org/abs/2511.04685", "authors": ["Daniela Guericke", "Rolf van der Hulst", "Asal Karimpour", "Ieke Schrader", "Matthias Walter"], "title": "A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024", "categories": ["cs.AI", "math.OC", "90-04", "F.2.2"], "comment": "23 pages, 2 figures, 10 tables", "summary": "We report about the algorithm, implementation and results submitted to the\nIntegrated Healthcare Timetabling Competition 2024 by Team Twente, which scored\nthird in the competition. Our approach combines mixed-integer programming,\nconstraint programming and simulated annealing in a 3-phase solution approach\nbased on decomposition into subproblems. Next to describing our approach and\ndescribing our design decisions, we share our insights and, for the first time,\nlower bounds on the optimal solution values for the benchmark instances. We\nfinally highlight open problems for which we think that addressing them could\nimprove our approach even further.", "AI": {"tldr": "本文介绍了Team Twente在2024年综合医疗排班竞赛中获得第三名的算法方案，采用混合整数规划、约束规划和模拟退火的3阶段分解方法，并首次提供了基准实例的最优解下界分析。", "motivation": "参加2024年综合医疗排班竞赛，旨在开发高效的医疗资源调度解决方案，解决复杂的医疗排班优化问题。", "method": "采用3阶段分解方法：混合整数规划、约束规划和模拟退火算法相结合，将复杂问题分解为子问题逐步求解。", "result": "在竞赛中获得第三名，成功实现了有效的医疗排班方案，并首次计算出了基准实例的最优解下界。", "conclusion": "该方法在医疗排班问题上表现良好，但仍存在一些开放性问题有待解决以进一步提升算法性能。"}}
{"id": "2511.04855", "pdf": "https://arxiv.org/pdf/2511.04855", "abs": "https://arxiv.org/abs/2511.04855", "authors": ["Vojtech Franc", "Jakub Paplham"], "title": "Epistemic Reject Option Prediction", "categories": ["cs.AI"], "comment": null, "summary": "In high-stakes applications, predictive models must not only produce accurate\npredictions but also quantify and communicate their uncertainty. Reject-option\nprediction addresses this by allowing the model to abstain when prediction\nuncertainty is high. Traditional reject-option approaches focus solely on\naleatoric uncertainty, an assumption valid only when large training data makes\nthe epistemic uncertainty negligible. However, in many practical scenarios,\nlimited data makes this assumption unrealistic. This paper introduces the\nepistemic reject-option predictor, which abstains in regions of high epistemic\nuncertainty caused by insufficient data. Building on Bayesian learning, we\nredefine the optimal predictor as the one that minimizes expected regret -- the\nperformance gap between the learned model and the Bayes-optimal predictor with\nfull knowledge of the data distribution. The model abstains when the regret for\na given input exceeds a specified rejection cost. To our knowledge, this is the\nfirst principled framework that enables learning predictors capable of\nidentifying inputs for which the training data is insufficient to make reliable\ndecisions.", "AI": {"tldr": "本文提出了一个基于贝叶斯学习的认知拒绝选项预测器，能够在数据不足导致高认知不确定性时拒绝预测，通过最小化预期遗憾来优化预测性能。", "motivation": "传统拒绝选项方法只关注偶然不确定性，但在数据有限的实际场景中，认知不确定性不可忽略，需要新的方法来处理数据不足导致的不可靠预测问题。", "method": "基于贝叶斯学习框架，重新定义最优预测器为最小化预期遗憾的模型，当输入数据的预测遗憾超过指定拒绝成本时，模型选择拒绝预测。", "result": "提出了首个原则性框架，能够学习识别训练数据不足以做出可靠决策的输入，有效处理高认知不确定性情况。", "conclusion": "该框架为高风险应用中处理数据不足导致的认知不确定性提供了理论和方法基础，提高了预测系统的可靠性。"}}
{"id": "2511.04880", "pdf": "https://arxiv.org/pdf/2511.04880", "abs": "https://arxiv.org/abs/2511.04880", "authors": ["Yu Bai", "Yukai Miao", "Dawei Wang", "Li Chen", "Fei Long", "Rundi Zhai", "Dan Li", "Yanyu Ren", "Tianfeng Liu", "Hongtao Xie", "Ce Yang", "Xuhui Cai"], "title": "DMA: Online RAG Alignment with Human Feedback", "categories": ["cs.AI"], "comment": null, "summary": "Retrieval-augmented generation (RAG) systems often rely on static retrieval,\nlimiting adaptation to evolving intent and content drift. We introduce Dynamic\nMemory Alignment (DMA), an online learning framework that systematically\nincorporates multi-granularity human feedback to align ranking in interactive\nsettings. DMA organizes document-, list-, and response-level signals into a\ncoherent learning pipeline: supervised training for pointwise and listwise\nrankers, policy optimization driven by response-level preferences, and\nknowledge distillation into a lightweight scorer for low-latency serving.\nThroughout this paper, memory refers to the model's working memory, which is\nthe entire context visible to the LLM for In-Context Learning.\n  We adopt a dual-track evaluation protocol mirroring deployment: (i)\nlarge-scale online A/B ablations to isolate the utility of each feedback\nsource, and (ii) few-shot offline tests on knowledge-intensive benchmarks.\nOnline, a multi-month industrial deployment further shows substantial\nimprovements in human engagement. Offline, DMA preserves competitive\nfoundational retrieval while yielding notable gains on conversational QA\n(TriviaQA, HotpotQA). Taken together, these results position DMA as a\nprincipled approach to feedback-driven, real-time adaptation in RAG without\nsacrificing baseline capability.", "AI": {"tldr": "DMA是一个在线学习框架，通过整合多粒度人类反馈来动态优化RAG系统的检索排序，在保持基础检索能力的同时显著提升人机交互效果。", "motivation": "传统RAG系统依赖静态检索，无法适应动态变化的用户意图和内容漂移问题，需要能够实时学习和适应的解决方案。", "method": "采用多粒度反馈学习管道：文档级和列表级排序器的监督训练、基于响应级偏好的策略优化，以及将知识蒸馏到轻量级评分器中实现低延迟服务。", "result": "在线A/B测试显示各反馈源均有效，工业部署显著提升用户参与度；离线测试在TriviaQA和HotpotQA等对话QA任务上取得显著增益，同时保持基础检索竞争力。", "conclusion": "DMA为RAG系统提供了一种有原则的反馈驱动实时适应方法，在不牺牲基线能力的情况下实现持续优化。"}}
{"id": "2511.04898", "pdf": "https://arxiv.org/pdf/2511.04898", "abs": "https://arxiv.org/abs/2511.04898", "authors": ["Yule Wen", "Yixin Ye", "Yanzhe Zhang", "Diyi Yang", "Hao Zhu"], "title": "Real-Time Reasoning Agents in Evolving Environments", "categories": ["cs.AI"], "comment": "30 pages", "summary": "Agents in the real world must make not only logical but also timely\njudgments. This requires continuous awareness of the dynamic environment:\nhazards emerge, opportunities arise, and other agents act, while the agent's\nreasoning is still unfolding. Despite advances in language model reasoning,\nexisting approaches fail to account for this dynamic nature. We introduce\nreal-time reasoning as a new problem formulation for agents in evolving\nenvironments and build Real-Time Reasoning Gym to demonstrate it. We study two\nparadigms for deploying language models in agents: (1) reactive agents, which\nemploy language models with bounded reasoning computation for rapid responses,\nand (2) planning agents, which allow extended reasoning computation for complex\nproblems. Our experiments show that even state-of-the-art models struggle with\nmaking logical and timely judgments in either paradigm. To address this\nlimitation, we propose AgileThinker, which simultaneously engages both\nreasoning paradigms. AgileThinker consistently outperforms agents engaging only\none reasoning paradigm as the task difficulty and time pressure rise,\neffectively balancing reasoning depth and response latency. Our work\nestablishes real-time reasoning as a critical testbed for developing practical\nagents and provides a foundation for research in temporally constrained AI\nsystems, highlighting a path toward real-time capable agents.", "AI": {"tldr": "论文提出了实时推理的新问题框架，研究语言模型在动态环境中的两种部署范式（反应式vs规划式），发现现有模型表现不佳，并提出AgileThinker方法同时使用两种推理范式来平衡推理深度和响应延迟。", "motivation": "现实世界中的智能体需要同时做出逻辑性和及时性的判断，但现有语言模型推理方法未能考虑环境的动态特性。", "method": "构建Real-Time Reasoning Gym测试平台，研究反应式智能体（有限推理计算）和规划式智能体（扩展推理计算）两种范式，并提出AgileThinker方法同时使用两种推理范式。", "result": "实验表明即使最先进的模型在两种范式中都难以做出逻辑性和及时性的判断，而AgileThinker在任务难度和时间压力增加时始终优于单一范式的智能体。", "conclusion": "实时推理是开发实用智能体的关键测试平台，为时间约束AI系统研究奠定了基础，指明了实现实时能力智能体的路径。"}}
{"id": "2511.04688", "pdf": "https://arxiv.org/pdf/2511.04688", "abs": "https://arxiv.org/abs/2511.04688", "authors": ["Adrita Anika", "Md Messal Monem Miah"], "title": "Evaluating LLMs' Reasoning Over Ordered Procedural Steps", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to IJCNLP-AACL 2025 Findings", "summary": "Reasoning over procedural sequences, where the order of steps directly\nimpacts outcomes, is a critical capability for large language models (LLMs). In\nthis work, we study the task of reconstructing globally ordered sequences from\nshuffled procedural steps, using a curated dataset of food recipes, a domain\nwhere correct sequencing is essential for task success. We evaluate several\nLLMs under zero-shot and few-shot settings and present a comprehensive\nevaluation framework that adapts established metrics from ranking and sequence\nalignment. These include Kendall's Tau, Normalized Longest Common Subsequence\n(NLCS), and Normalized Edit Distance (NED), which capture complementary aspects\nof ordering quality. Our analysis shows that model performance declines with\nincreasing sequence length, reflecting the added complexity of longer\nprocedures. We also find that greater step displacement in the input,\ncorresponding to more severe shuffling, leads to further degradation. These\nfindings highlight the limitations of current LLMs in procedural reasoning,\nespecially with longer and more disordered inputs.", "AI": {"tldr": "该研究评估了大型语言模型在重构打乱顺序的程序步骤方面的能力，发现在序列长度增加和输入步骤更混乱时，模型性能显著下降。", "motivation": "研究程序性序列推理能力对大型语言模型至关重要，特别是在步骤顺序直接影响结果的场景中。使用食谱作为测试领域，因为正确的步骤顺序对任务成功至关重要。", "method": "使用精选的食谱数据集，在零样本和少样本设置下评估多个LLM。采用综合评估框架，包括Kendall's Tau、NLCS和NED等排序和序列对齐指标。", "result": "模型性能随序列长度增加而下降，输入步骤位移越大（即打乱程度越严重），性能退化越明显。", "conclusion": "当前LLM在程序性推理方面存在局限性，特别是在处理更长和更混乱的输入时表现不佳。"}}
{"id": "2511.04956", "pdf": "https://arxiv.org/pdf/2511.04956", "abs": "https://arxiv.org/abs/2511.04956", "authors": ["Maria Mahbub", "Vanessa Lama", "Sanjay Das", "Brian Starks", "Christopher Polchek", "Saffell Silvers", "Lauren Deck", "Prasanna Balaprakash", "Tirthankar Ghosal"], "title": "ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "High-Risk Property (HRP) classification is critical at U.S. Department of\nEnergy (DOE) sites, where inventories include sensitive and often dual-use\nequipment. Compliance must track evolving rules designated by various export\ncontrol policies to make transparent and auditable decisions. Traditional\nexpert-only workflows are time-consuming, backlog-prone, and struggle to keep\npace with shifting regulatory boundaries. We demo ORCHID, a modular agentic\nsystem for HRP classification that pairs retrieval-augmented generation (RAG)\nwith human oversight to produce policy-based outputs that can be audited. Small\ncooperating agents, retrieval, description refiner, classifier, validator, and\nfeedback logger, coordinate via agent-to-agent messaging and invoke tools\nthrough the Model Context Protocol (MCP) for model-agnostic on-premise\noperation. The interface follows an Item to Evidence to Decision loop with\nstep-by-step reasoning, on-policy citations, and append-only audit bundles\n(run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID\nimproves accuracy and traceability over a non-agentic baseline while deferring\nuncertain items to Subject Matter Experts (SMEs). The demonstration shows\nsingle item submission, grounded citations, SME feedback capture, and\nexportable audit artifacts, illustrating a practical path to trustworthy LLM\nassistance in sensitive DOE compliance workflows.", "AI": {"tldr": "ORCHID是一个模块化代理系统，用于美国能源部高风险财产分类，结合检索增强生成(RAG)和人工监督，提高分类准确性和可追溯性，同时将不确定项目交由专家处理。", "motivation": "传统专家主导的高风险财产分类流程耗时、易积压，难以跟上不断变化的监管要求，需要更高效、透明且可审计的解决方案。", "method": "采用模块化代理系统，包括检索、描述精炼、分类、验证和反馈记录等小型协作代理，通过代理间消息传递和模型上下文协议(MCP)实现模型无关的本地操作，遵循从项目到证据再到决策的循环流程。", "result": "在真实高风险财产案例的初步测试中，ORCHID相比非代理基线提高了准确性和可追溯性，同时能够将不确定项目交由领域专家处理。", "conclusion": "ORCHID展示了在敏感能源部合规工作流程中实现可信赖大语言模型辅助的实用路径，通过逐步推理、政策引用和只追加审计包确保透明度和可审计性。"}}
{"id": "2511.04689", "pdf": "https://arxiv.org/pdf/2511.04689", "abs": "https://arxiv.org/abs/2511.04689", "authors": ["Peiyu Li", "Xiuxiu Tang", "Si Chen", "Ying Cheng", "Ronald Metoyer", "Ting Hua", "Nitesh V. Chawla"], "title": "Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks", "categories": ["cs.CL", "cs.AI"], "comment": "Code and calibrated item banks are available at\n  https://github.com/Peiyu-Georgia-Li/ATLAS.git", "summary": "Large language model evaluation requires thousands of benchmark items, making\nevaluations expensive and slow. Existing methods compute average accuracy\nacross fixed item sets, treating all items equally despite varying quality and\ninformativeness. We present ATLAS an adaptive testing framework using Item\nResponse Theory (IRT) to estimate model ability through Fisher\ninformation-guided item selection. Our analysis of five major benchmarks\nreveals that 3-6% of items exhibit negative discrimination, indicating\nannotation errors that corrupt static evaluation. ATLAS achieves 90% item\nreduction while maintaining measurement precision: on HellaSwag (5,608 items),\nwe match full-benchmark estimates using only 42 items with 0.154 MAE. Our\nframework maintains item exposure rates below 10% and test overlap at 16-27%,\ncompared to static benchmarks where every model sees all items (100% exposure).\nAmong 4,000+ tested models, IRT ranks differ from accuracy ranks: models with\nthe same accuracy get different IRT scores, and 23-31% of all models shift by\nmore than 10 rank positions. Code and calibrated item banks are available at\nhttps://github.com/Peiyu-Georgia-Li/ATLAS.git.", "AI": {"tldr": "ATLAS是一个基于项目反应理论的自适应测试框架，通过Fisher信息量引导的项目选择，在保持测量精度的同时减少90%的测试项目需求，显著降低大语言模型评估成本。", "motivation": "大语言模型评估需要数千个基准测试项，成本高昂且耗时。现有方法对所有项目一视同仁，忽略了项目质量和信息量的差异，且存在标注错误影响评估准确性的问题。", "method": "采用项目反应理论(IRT)构建自适应测试框架，通过Fisher信息量指导项目选择，动态选择最具信息量的测试项目来估计模型能力。", "result": "在HellaSwag基准上仅用42个项目(原5,608个)就达到0.154 MAE的测量精度；发现3-6%的项目存在负区分度(标注错误)；项目暴露率低于10%，测试重叠率16-27%；IRT排名与传统准确率排名存在显著差异，23-31%的模型排名变化超过10位。", "conclusion": "ATLAS框架能大幅减少评估成本，提高评估效率，同时揭示了传统静态基准评估中存在的质量问题，为更精确、高效的模型评估提供了新方法。"}}
{"id": "2511.05182", "pdf": "https://arxiv.org/pdf/2511.05182", "abs": "https://arxiv.org/abs/2511.05182", "authors": ["Johan Schubert", "Patrik Hansen", "Pontus Hörling", "Ronnie Johansson"], "title": "Autonomous generation of different courses of action in mechanized combat operations", "categories": ["cs.AI", "cs.CY", "H.4.2; I.2.3; I.2.6; I.2.8; J.7"], "comment": "In Proceedings of the 30th International Command and Control Research\n  & Technology Symposium, Stockholm, Sweden, 3-6 November 2025, paper 009", "summary": "In this paper, we propose a methodology designed to support decision-making\nduring the execution phase of military ground combat operations, with a focus\non one's actions. This methodology generates and evaluates recommendations for\nvarious courses of action for a mechanized battalion, commencing with an\ninitial set assessed by their anticipated outcomes. It systematically produces\nthousands of individual action alternatives, followed by evaluations aimed at\nidentifying alternative courses of action with superior outcomes. These\nalternatives are appraised in light of the opponent's status and actions,\nconsidering unit composition, force ratios, types of offense and defense, and\nanticipated advance rates. Field manuals evaluate battle outcomes and\nadvancement rates. The processes of generation and evaluation work\nconcurrently, yielding a variety of alternative courses of action. This\napproach facilitates the management of new course generation based on\npreviously evaluated actions. As the combat unfolds and conditions evolve,\nrevised courses of action are formulated for the decision-maker within a\nsequential decision-making framework.", "AI": {"tldr": "提出一种支持地面军事作战决策的方法论，通过系统生成和评估数千种行动方案，基于敌方状态和战场条件动态优化机械化营的作战决策", "motivation": "为机械化营在执行阶段提供决策支持，需要处理复杂战场环境下的大量可能行动方案并评估其预期结果", "method": "从初始评估的行动方案集开始，系统生成数千个个体行动替代方案，结合敌方状态、部队组成、兵力比例、攻防类型和预期推进速率等因素进行评估，使用野战手册评估战斗结果", "result": "方法能够并发生成和评估多种行动替代方案，基于先前评估结果管理新方案的生成，随着战斗进展动态修订行动方案", "conclusion": "该决策支持方法能够在连续决策框架内为指挥官提供优化的行动建议，适应战场条件的动态变化"}}
{"id": "2511.04692", "pdf": "https://arxiv.org/pdf/2511.04692", "abs": "https://arxiv.org/abs/2511.04692", "authors": ["Jingqing Wang", "Jiaxing Shang", "Rong Xu", "Fei Hao", "Tianjin Huang", "Geyong Min"], "title": "SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection", "categories": ["cs.CL"], "comment": "12 pages, 11 figures, 4 tables, WSDM 2026 accepted paper", "summary": "Fake news detection has been a long-standing research focus in social\nnetworks. Recent studies suggest that incorporating sentiment information from\nboth news content and user comments can enhance detection performance. However,\nexisting approaches typically treat sentiment features as auxiliary signals,\noverlooking role differentiation, that is, the same sentiment polarity may\noriginate from users with distinct roles, thereby limiting their ability to\ncapture nuanced patterns for effective detection. To address this issue, we\npropose SARC, a Sentiment-Augmented Role Clustering framework which utilizes\nsentiment-enhanced deep clustering to identify user roles for improved fake\nnews detection. The framework first generates user features through joint\ncomment text representation (with BiGRU and Attention mechanism) and sentiment\nencoding. It then constructs a differentiable deep clustering module to\nautomatically categorize user roles. Finally, unlike existing approaches which\ntake fake news label as the unique supervision signal, we propose a joint\noptimization objective integrating role clustering and fake news detection to\nfurther improve the model performance. Experimental results on two benchmark\ndatasets, RumourEval-19 and Weibo-comp, demonstrate that SARC achieves superior\nperformance across all metrics compared to baseline models. The code is\navailable at: https://github.com/jxshang/SARC.", "AI": {"tldr": "SARC是一个情感增强的角色聚类框架，通过联合优化用户角色聚类和假新闻检测任务，显著提升了假新闻检测性能。", "motivation": "现有方法将情感特征作为辅助信号，忽略了用户角色差异对情感表达的微妙影响，限制了检测效果。", "method": "使用BiGRU和注意力机制联合生成用户评论文本表示和情感编码，构建可微分深度聚类模块自动分类用户角色，并提出联合优化目标整合角色聚类和假新闻检测。", "result": "在两个基准数据集RumourEval-19和Weibo-comp上，SARC在所有指标上都优于基线模型。", "conclusion": "通过考虑用户角色差异和情感信息的结合，SARC框架有效提升了假新闻检测的准确性和鲁棒性。"}}
{"id": "2511.05311", "pdf": "https://arxiv.org/pdf/2511.05311", "abs": "https://arxiv.org/abs/2511.05311", "authors": ["Valeriu Dimidov", "Faisal Hawlader", "Sasan Jafarnejad", "Raphaël Frank"], "title": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance", "categories": ["cs.AI", "cs.LG", "cs.RO", "cs.SE"], "comment": null, "summary": "Economic constraints, limited availability of datasets for reproducibility\nand shortages of specialized expertise have long been recognized as key\nchallenges to the adoption and advancement of predictive maintenance (PdM) in\nthe automotive sector. Recent progress in large language models (LLMs) presents\nan opportunity to overcome these barriers and speed up the transition of PdM\nfrom research to industrial practice. Under these conditions, we explore the\npotential of LLM-based agents to support PdM cleaning pipelines. Specifically,\nwe focus on maintenance logs, a critical data source for training\nwell-performing machine learning (ML) models, but one often affected by errors\nsuch as typos, missing fields, near-duplicate entries, and incorrect dates. We\nevaluate LLM agents on cleaning tasks involving six distinct types of noise.\nOur findings show that LLMs are effective at handling generic cleaning tasks\nand offer a promising foundation for future industrial applications. While\ndomain-specific errors remain challenging, these results highlight the\npotential for further improvements through specialized training and enhanced\nagentic capabilities.", "AI": {"tldr": "论文探讨了基于大语言模型(LLM)的智能体在汽车行业预测性维护(PdM)数据清洗中的潜力，特别是在处理维护日志中的六类噪声方面表现出色，为工业应用提供了有前景的基础。", "motivation": "汽车行业预测性维护面临经济约束、数据集稀缺和专业人才短缺等挑战，而大语言模型的进展为解决这些障碍提供了机会，加速PdM从研究向工业实践的转型。", "method": "研究评估了LLM智能体在维护日志数据清洗任务中的表现，重点关注六种不同类型的噪声处理：拼写错误、缺失字段、近似重复条目和错误日期等。", "result": "研究结果显示，大语言模型在通用清洗任务中表现有效，为未来工业应用提供了有前景的基础。尽管领域特定错误仍具挑战性，但通过专业训练和增强智能体能力有望进一步改进。", "conclusion": "LLM智能体在预测性维护数据清洗方面具有显著潜力，特别是在处理维护日志噪声方面。虽然领域特定问题仍需解决，但通过针对性训练和能力提升，LLM技术有望显著推动汽车行业预测性维护的实际应用。"}}
{"id": "2511.04694", "pdf": "https://arxiv.org/pdf/2511.04694", "abs": "https://arxiv.org/abs/2511.04694", "authors": ["Zishuo Zheng", "Vidhisha Balachandran", "Chan Young Park", "Faeze Brahman", "Sachin Kumar"], "title": "Reasoning Up the Instruction Ladder for Controllable Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "As large language model (LLM) based systems take on high-stakes roles in\nreal-world decision-making, they must reconcile competing instructions from\nmultiple sources (e.g., model developers, users, and tools) within a single\nprompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where\nhigher-level directives override lower-priority requests, is critical for the\nreliability and controllability of LLMs. In this work, we reframe instruction\nhierarchy resolution as a reasoning task. Specifically, the model must first\n\"think\" about the relationship between a given user prompt and higher-priority\n(system) instructions before generating a response. To enable this capability\nvia training, we construct VerIH, an instruction hierarchy dataset of\nconstraint-following tasks with verifiable answers. This dataset comprises both\naligned and conflicting system-user instructions. We show that lightweight\nreinforcement learning with VerIH effectively transfers general reasoning\ncapabilities of models to instruction prioritization. Our finetuned models\nachieve consistent improvements on instruction following and instruction\nhierarchy benchmarks. This reasoning ability also generalizes to\nsafety-critical settings beyond the training distribution. By treating safety\nissues as resolving conflicts between adversarial user inputs and predefined\nhigher-priority policies, our trained model enhances robustness against\njailbreak and prompt injection attacks. These results demonstrate that\nreasoning over instruction hierarchies provides a practical path to reliable\nLLMs, where updates to system prompts yield controllable and robust changes in\nmodel behavior.", "AI": {"tldr": "该研究通过将指令层级解决重构为推理任务，构建VerIH数据集，利用轻量级强化学习训练模型，使LLM能够优先处理系统指令而非用户指令，提高模型的安全性和鲁棒性。", "motivation": "随着大语言模型在现实决策中承担重要角色，需要处理来自多个来源（如开发者、用户、工具）的竞争性指令，建立指令层级以确保高优先级指令覆盖低优先级请求对LLM的可靠性和可控性至关重要。", "method": "将指令层级解决重构为推理任务，构建VerIH数据集（包含对齐和冲突的系统-用户指令），使用轻量级强化学习训练模型，使模型在生成响应前先思考用户提示与高优先级系统指令的关系。", "result": "微调后的模型在指令遵循和指令层级基准测试中取得一致改进，推理能力可泛化到训练分布之外的安全关键场景，增强了对越狱和提示注入攻击的鲁棒性。", "conclusion": "通过指令层级推理为构建可靠LLM提供了实用路径，系统提示的更新能够产生可控且鲁棒的模型行为变化。"}}
{"id": "2511.05375", "pdf": "https://arxiv.org/pdf/2511.05375", "abs": "https://arxiv.org/abs/2511.05375", "authors": ["Sijie Yang", "Jiatong Li", "Filip Biljecki"], "title": "Reasoning Is All You Need for Urban Planning AI", "categories": ["cs.AI"], "comment": "Submitted to AAAI 2026 Workshop AI4UP", "summary": "AI has proven highly successful at urban planning analysis -- learning\npatterns from data to predict future conditions. The next frontier is\nAI-assisted decision-making: agents that recommend sites, allocate resources,\nand evaluate trade-offs while reasoning transparently about constraints and\nstakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,\nReAct, and multi-agent collaboration frameworks -- now make this vision\nachievable.\n  This position paper presents the Agentic Urban Planning AI Framework for\nreasoning-capable planning agents that integrates three cognitive layers\n(Perception, Foundation, Reasoning) with six logic components (Analysis,\nGeneration, Verification, Evaluation, Collaboration, Decision) through a\nmulti-agents collaboration framework. We demonstrate why planning decisions\nrequire explicit reasoning capabilities that are value-based (applying\nnormative principles), rule-grounded (guaranteeing constraint satisfaction),\nand explainable (generating transparent justifications) -- requirements that\nstatistical learning alone cannot fulfill. We compare reasoning agents with\nstatistical learning, present a comprehensive architecture with benchmark\nevaluation metrics, and outline critical research challenges. This framework\nshows how AI agents can augment human planners by systematically exploring\nsolution spaces, verifying regulatory compliance, and deliberating over\ntrade-offs transparently -- not replacing human judgment but amplifying it with\ncomputational reasoning capabilities.", "AI": {"tldr": "提出了一个基于推理AI的智能城市规划框架，通过多智能体协作整合感知、基础和推理三层认知架构，实现价值导向、规则约束和可解释的规划决策辅助。", "motivation": "传统统计学习方法无法满足城市规划决策需要显式推理、价值判断、规则约束和透明解释的要求，需要新一代AI辅助决策系统。", "method": "构建Agentic Urban Planning AI Framework，包含三层认知架构（感知、基础、推理）和六个逻辑组件（分析、生成、验证、评估、协作、决策），采用多智能体协作框架。", "result": "提出了一个全面的架构设计和基准评估指标，展示了AI智能体如何通过系统探索解决方案空间、验证法规合规性和透明权衡来增强人类规划师的能力。", "conclusion": "该框架表明AI智能体不是取代人类判断，而是通过计算推理能力增强人类规划师的决策能力，为城市规划提供可解释、价值导向的智能辅助决策支持。"}}
{"id": "2511.04696", "pdf": "https://arxiv.org/pdf/2511.04696", "abs": "https://arxiv.org/abs/2511.04696", "authors": ["Jan Strich", "Adeline Scharfenberg", "Chris Biemann", "Martin Semmann"], "title": "EncouRAGe: Evaluating RAG Local, Fast, and Reliable", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Currently under review", "summary": "We introduce EncouRAGe, a comprehensive Python framework designed to\nstreamline the development and evaluation of Retrieval-Augmented Generation\n(RAG) systems using Large Language Models (LLMs) and Embedding Models.\nEncouRAGe comprises five modular and extensible components: Type Manifest, RAG\nFactory, Inference, Vector Store, and Metrics, facilitating flexible\nexperimentation and extensible development. The framework emphasizes scientific\nreproducibility, diverse evaluation metrics, and local deployment, enabling\nresearchers to efficiently assess datasets within RAG workflows. This paper\npresents implementation details and an extensive evaluation across multiple\nbenchmark datasets, including 25k QA pairs and over 51k documents. Our results\nshow that RAG still underperforms compared to the Oracle Context, while Hybrid\nBM25 consistently achieves the best results across all four datasets. We\nfurther examine the effects of reranking, observing only marginal performance\nimprovements accompanied by higher response latency.", "AI": {"tldr": "EncouRAGe是一个用于RAG系统开发和评估的Python框架，包含五个模块化组件，支持科学可重复性和本地部署。评估结果显示RAG性能仍不及Oracle Context，Hybrid BM25在所有数据集上表现最佳，重排序仅带来边际性能提升但增加延迟。", "motivation": "为了解决RAG系统开发和评估的复杂性，提供一个模块化、可扩展的框架来促进灵活实验和科学可重复性研究。", "method": "开发了包含Type Manifest、RAG Factory、Inference、Vector Store和Metrics五个组件的Python框架，并在多个基准数据集（25k QA对和51k文档）上进行广泛评估。", "result": "RAG性能仍低于Oracle Context，Hybrid BM25在所有四个数据集上表现最佳，重排序仅带来微小性能改进但显著增加响应延迟。", "conclusion": "EncouRAGe框架为RAG研究提供了有效的开发和评估工具，揭示了当前RAG技术的性能局限，Hybrid BM25的优越表现以及重排序技术的权衡问题。"}}
{"id": "2511.04698", "pdf": "https://arxiv.org/pdf/2511.04698", "abs": "https://arxiv.org/abs/2511.04698", "authors": ["K M Sajjadul Islam", "John Fields", "Praveen Madiraju"], "title": "multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted in IEEE Big Data, 8-11 December, 2025 @ Macau SAR, China", "summary": "The early detection of mental health disorders from social media text is\ncritical for enabling timely support, risk assessment, and referral to\nappropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned\nRoBERTa model designed for multiclass classification of common mental health\nconditions, including stress, anxiety, depression, post-traumatic stress\ndisorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple\ncurated datasets, data exploration is conducted to analyze class overlaps,\nrevealing strong correlations between depression and suicidal ideation as well\nas anxiety and PTSD, while stress emerges as a broad, overlapping category.\nComparative experiments with traditional machine learning methods,\ndomain-specific transformers, and prompting-based large language models\ndemonstrate that multiMentalRoBERTa achieves superior performance, with macro\nF1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup\n(excluding stress), outperforming both fine-tuned MentalBERT and baseline\nclassifiers. Beyond predictive accuracy, explainability methods, including\nLayer Integrated Gradients and KeyBERT, are applied to identify lexical cues\nthat drive classification, with a particular focus on distinguishing depression\nfrom suicidal ideation. The findings emphasize the effectiveness of fine-tuned\ntransformers for reliable and interpretable detection in sensitive contexts,\nwhile also underscoring the importance of fairness, bias mitigation, and\nhuman-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as\na lightweight, robust, and deployable solution for enhancing support in mental\nhealth platforms.", "AI": {"tldr": "该论文提出了multiMentalRoBERTa模型，这是一个针对多种心理健康状况进行多分类的微调RoBERTa模型，在检测压力、焦虑、抑郁、PTSD、自杀意念和中性话语方面表现出色，性能优于传统方法和现有模型。", "motivation": "早期检测心理健康障碍对于提供及时支持、风险评估和转介至适当资源至关重要，特别是在社交媒体文本中识别这些状况具有重要价值。", "method": "基于多个精选数据集进行数据探索，分析类别重叠；使用微调的RoBERTa模型进行多分类；与传统机器学习方法、领域特定transformer和基于提示的大语言模型进行比较实验；应用Layer Integrated Gradients和KeyBERT等可解释性方法识别分类驱动因素。", "result": "multiMentalRoBERTa在六分类设置中达到0.839的宏观F1分数，在五分类设置（排除压力）中达到0.870，性能优于微调的MentalBERT和基线分类器。发现抑郁与自杀意念、焦虑与PTSD之间存在强相关性，压力是一个广泛重叠的类别。", "conclusion": "微调transformer在敏感情境中提供了可靠且可解释的检测方案，multiMentalRoBERTa是一个轻量级、稳健且可部署的解决方案，同时强调了公平性、偏见缓解和人机协作安全协议的重要性。"}}
{"id": "2511.04699", "pdf": "https://arxiv.org/pdf/2511.04699", "abs": "https://arxiv.org/abs/2511.04699", "authors": ["Haneen Al-Homoud", "Asma Ibrahim", "Murtadha Al-Jubran", "Fahad Al-Otaibi", "Yazeed Al-Harbi", "Daulet Toibazar", "Kesen Wang", "Pedro J. Moreno"], "title": "Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding", "categories": ["cs.CL", "cs.CV"], "comment": null, "summary": "Cross-Lingual SynthDocs is a large-scale synthetic corpus designed to address\nthe scarcity of Arabic resources for Optical Character Recognition (OCR) and\nDocument Understanding (DU). The dataset comprises over 2.5 million of samples,\nincluding 1.5 million textual data, 270K fully annotated tables, and hundred\nthousands of real data based charts. Our pipeline leverages authentic scanned\nbackgrounds, bilingual layouts, and diacritic aware fonts to capture the\ntypographic and structural complexity of Arabic documents. In addition to text,\nthe corpus includes variety of rendered styles for charts and tables.\nFinetuning Qwen-2.5-VL on SynthDocs yields consistent improvements in Word\nError Rate (WER) and Character Error Rate (CER) in terms of OCR across multiple\npublic Arabic benchmarks, Tree-Edit Distance Similarity (TEDS) and Chart\nExtraction Score (CharTeX) improved as well in other modalities. SynthDocs\nprovides a scalable, visually realistic resource for advancing research in\nmultilingual document analysis.", "AI": {"tldr": "Cross-Lingual SynthDocs是一个大规模合成语料库，包含250万样本，用于解决阿拉伯语OCR和文档理解资源稀缺问题，通过微调Qwen-2.5-VL在多模态阿拉伯文档分析任务中取得显著性能提升", "motivation": "解决阿拉伯语在光学字符识别(OCR)和文档理解(DU)领域资源稀缺的问题", "method": "构建包含250万样本的大规模合成语料库，使用真实扫描背景、双语布局和变音符号感知字体，包含文本、表格和图表等多种渲染样式", "result": "在Qwen-2.5-VL模型上微调后，在多个阿拉伯语基准测试中，词错误率(WER)和字符错误率(CER)显著改善，树编辑距离相似度(TEDS)和图表提取分数(CharTeX)等其他模态指标也有所提升", "conclusion": "SynthDocs为多语言文档分析研究提供了一个可扩展且视觉逼真的资源，有效促进了阿拉伯语文档处理技术的发展"}}
{"id": "2511.04700", "pdf": "https://arxiv.org/pdf/2511.04700", "abs": "https://arxiv.org/abs/2511.04700", "authors": ["Song Wang", "Zihan Chen", "Peng Wang", "Zhepei Wei", "Zhen Tan", "Yu Meng", "Cong Shen", "Jundong Li"], "title": "Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation", "categories": ["cs.CL", "cs.AI"], "comment": "EMNLP Main 2025", "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nintegrating external knowledge sources to address their limitations in\naccessing up-to-date or specialized information. A natural strategy to increase\nthe likelihood of retrieving relevant information is to expand the number of\nretrieved documents. However, involving more documents could introduce\nsignificant noise, as many documents may be irrelevant or misleading, thereby\nreducing the overall accuracy of the generated responses. To overcome the\nchallenge associated with handling a larger number of documents, we propose\nWinnowRAG, a novel RAG framework designed to systematically filter out noisy\ndocuments while preserving valuable content -- a process we refer to as\nwinnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware\nclustering to group similar documents and form distinct topic clusters. Each\ncluster is assigned to an LLM agent for generating a unique answer. In Stage\nII, we perform winnowing, wherein a critic LLM evaluates the outputs of\nmultiple agents and iteratively separates useful documents from noisy ones. To\nretain useful documents when discarding agents, we propose two strategic\nmerging techniques to ensure that only relevant knowledge is used for\ngenerating the final response. Crucially, WinnowRAG is model-agnostic and does\nnot require any model fine-tuning, making it easily adaptable to various tasks.\nExtensive experiments on various realistic datasets demonstrate the\neffectiveness of WinnowRAG over state-of-the-art baselines.", "AI": {"tldr": "WinnowRAG是一个新颖的检索增强生成框架，通过两阶段处理（聚类和筛选）来有效过滤噪声文档，保留有价值信息，提高RAG系统的准确性，且无需模型微调。", "motivation": "解决传统RAG方法在增加检索文档数量时引入噪声和误导信息的问题，这些噪声会降低生成响应的准确性。", "method": "两阶段方法：第一阶段进行查询感知聚类，将相似文档分组并由LLM代理生成答案；第二阶段通过批评LLM评估各代理输出，迭代筛选有用文档，并采用策略性合并技术保留相关信息。", "result": "在多个现实数据集上的广泛实验表明，WinnowRAG优于现有最先进的基线方法。", "conclusion": "WinnowRAG是一个模型无关的框架，能有效处理大量文档中的噪声问题，提高RAG系统的性能，且易于适配不同任务。"}}
{"id": "2511.04703", "pdf": "https://arxiv.org/pdf/2511.04703", "abs": "https://arxiv.org/abs/2511.04703", "authors": ["Andrew M. Bean", "Ryan Othniel Kearns", "Angelika Romanou", "Franziska Sofia Hafner", "Harry Mayne", "Jan Batzner", "Negar Foroutan", "Chris Schmitz", "Karolina Korgul", "Hunar Batra", "Oishi Deb", "Emma Beharry", "Cornelius Emde", "Thomas Foster", "Anna Gausen", "María Grandury", "Simeng Han", "Valentin Hofmann", "Lujain Ibrahim", "Hazel Kim", "Hannah Rose Kirk", "Fangru Lin", "Gabrielle Kaili-May Liu", "Lennart Luettgau", "Jabez Magomere", "Jonathan Rystrøm", "Anna Sotnikova", "Yushi Yang", "Yilun Zhao", "Adel Bibi", "Antoine Bosselut", "Ronald Clark", "Arman Cohan", "Jakob Foerster", "Yarin Gal", "Scott A. Hale", "Inioluwa Deborah Raji", "Christopher Summerfield", "Philip H. S. Torr", "Cozmin Ududec", "Luc Rocher", "Adam Mahdi"], "title": "Measuring what Matters: Construct Validity in Large Language Model Benchmarks", "categories": ["cs.CL", "cs.AI"], "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025) Track on Datasets and Benchmarks", "summary": "Evaluating large language models (LLMs) is crucial for both assessing their\ncapabilities and identifying safety or robustness issues prior to deployment.\nReliably measuring abstract and complex phenomena such as 'safety' and\n'robustness' requires strong construct validity, that is, having measures that\nrepresent what matters to the phenomenon. With a team of 29 expert reviewers,\nwe conduct a systematic review of 445 LLM benchmarks from leading conferences\nin natural language processing and machine learning. Across the reviewed\narticles, we find patterns related to the measured phenomena, tasks, and\nscoring metrics which undermine the validity of the resulting claims. To\naddress these shortcomings, we provide eight key recommendations and detailed\nactionable guidance to researchers and practitioners in developing LLM\nbenchmarks.", "AI": {"tldr": "对445个LLM基准测试的系统性审查发现存在构造效度问题，提出了8项改进建议", "motivation": "评估大语言模型的能力和安全性需要可靠的测量方法，但现有基准测试在构造效度方面存在问题", "method": "由29位专家评审对自然语言处理和机器学习顶级会议中的445个LLM基准测试进行系统性审查", "result": "发现了与测量现象、任务和评分指标相关的模式，这些模式削弱了基准测试结果的有效性", "conclusion": "需要改进LLM基准测试的构造效度，为此提供了8项关键建议和详细的操作指南"}}
{"id": "2511.04705", "pdf": "https://arxiv.org/pdf/2511.04705", "abs": "https://arxiv.org/abs/2511.04705", "authors": ["Tingyue Yang", "Junchi Yao", "Yuhui Guo", "Chang Liu"], "title": "POLIS-Bench: Towards Multi-Dimensional Evaluation of LLMs for Bilingual Policy Tasks in Governmental Scenarios", "categories": ["cs.CL", "cs.AI"], "comment": "16 pages, 6 figures", "summary": "We introduce POLIS-Bench, the first rigorous, systematic evaluation suite\ndesigned for LLMs operating in governmental bilingual policy scenarios.\nCompared to existing benchmarks, POLIS-Bench introduces three major\nadvancements. (i) Up-to-date Bilingual Corpus: We construct an extensive,\nup-to-date policy corpus that significantly scales the effective assessment\nsample size, ensuring relevance to current governance practice. (ii)\nScenario-Grounded Task Design: We distill three specialized, scenario-grounded\ntasks -- Clause Retrieval & Interpretation, Solution Generation, and the\nCompliance Judgmen--to comprehensively probe model understanding and\napplication. (iii) Dual-Metric Evaluation Framework: We establish a novel\ndual-metric evaluation framework combining semantic similarity with accuracy\nrate to precisely measure both content alignment and task requirement\nadherence. A large-scale evaluation of over 10 state-of-the-art LLMs on\nPOLIS-Bench reveals a clear performance hierarchy where reasoning models\nmaintain superior cross-task stability and accuracy, highlighting the\ndifficulty of compliance tasks. Furthermore, leveraging our benchmark, we\nsuccessfully fine-tune a lightweight open-source model. The resulting POLIS\nseries models achieves parity with, or surpasses, strong proprietary baselines\non multiple policy subtasks at a significantly reduced cost, providing a\ncost-effective and compliant path for robust real-world governmental\ndeployment.", "AI": {"tldr": "POLIS-Bench是首个针对政府双语政策场景的LLM评估套件，包含最新双语语料库、场景化任务设计和双指标评估框架。评估显示推理模型表现最佳，并通过微调开源模型实现了与商业模型相当的性能但成本更低。", "motivation": "现有基准无法充分评估LLM在政府双语政策场景中的表现，需要构建专门、系统的评估体系来测试模型的政策理解和应用能力。", "method": "构建大规模最新双语政策语料库；设计三个场景化任务（条款检索与解释、解决方案生成、合规判断）；建立语义相似度和准确率的双指标评估框架；评估10多个先进LLM并微调轻量级开源模型。", "result": "推理模型在跨任务稳定性和准确性方面表现最优；合规任务最具挑战性；微调后的POLIS系列模型在多项政策子任务上达到或超过商业基线模型，但成本显著降低。", "conclusion": "POLIS-Bench为政府部署LLM提供了有效的评估工具和成本效益高的解决方案，证明了轻量级开源模型通过专门微调可以在政策场景中达到商业模型的性能水平。"}}
{"id": "2511.04710", "pdf": "https://arxiv.org/pdf/2511.04710", "abs": "https://arxiv.org/abs/2511.04710", "authors": ["Hari Mohan Pandey", "Anshul Gupta", "Subham Sarkar", "Minakshi Tomer", "Schneider Johannes", "Yan Gong"], "title": "GEMMA-SQL: A Novel Text-to-SQL Model Based on Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Text-to-SQL systems enable users to interact with structured databases using\nnatural language, eliminating the need for specialized programming knowledge.\nIn this work, we introduce GEMMA-SQL, a lightweight and efficient text-to-SQL\nmodel built upon the open-source Gemma 2B architecture. Unlike many large\nlanguage models (LLMs), GEMMA-SQL is fine-tuned in a resource-efficient,\niterative manner and can be deployed on low-cost hardware. Leveraging the\nSPIDER benchmark for training and evaluation, GEMMA-SQL combines multiple\nprompting strategies, including few-shot learning, to enhance SQL query\ngeneration accuracy. The instruction-tuned variant, GEMMA-SQL Instruct,\nachieves 66.8% Test-Suite accuracy and 63.3% Exact Set Match accuracy,\noutperforming several state-of-the-art baselines such as IRNet, RYANSQL, and\nCodeXDavinci. The proposed approach demonstrates that effective prompt design\nand targeted instruction tuning can significantly boost performance while\nmaintaining high scalability and adaptability. These results position GEMMA-SQL\nas a practical, open-source alternative for robust and accessible text-to-SQL\nsystems.", "AI": {"tldr": "GEMMA-SQL是一个基于Gemma 2B架构的轻量级文本转SQL模型，通过资源高效的迭代微调和多提示策略，在低成本硬件上实现了优异的性能表现。", "motivation": "开发一个轻量级且高效的文本转SQL系统，使用户无需专业编程知识即可与结构化数据库交互，同时能在低成本硬件上部署。", "method": "基于开源Gemma 2B架构进行资源高效的迭代微调，结合少样本学习等多种提示策略，使用SPIDER基准进行训练和评估。", "result": "GEMMA-SQL Instruct变体在Test-Suite准确率达到66.8%，Exact Set Match准确率达到63.3%，优于IRNet、RYANSQL和CodeXDavinci等先进基线模型。", "conclusion": "有效的提示设计和针对性指令微调可以显著提升性能，同时保持高可扩展性和适应性，使GEMMA-SQL成为稳健且易用的开源文本转SQL系统的实用替代方案。"}}
{"id": "2511.04715", "pdf": "https://arxiv.org/pdf/2511.04715", "abs": "https://arxiv.org/abs/2511.04715", "authors": ["Dmytro Vitel", "Anshuman Chhabra"], "title": "First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Identifying how training samples influence/impact Large Language Model (LLM)\ndecision-making is essential for effectively interpreting model decisions and\nauditing large-scale datasets. Current training sample influence estimation\nmethods (also known as influence functions) undertake this goal by utilizing\ninformation flow through the model via its first-order and higher-order\ngradient terms. However, owing to the large model sizes of today consisting of\nbillions of parameters, these influence computations are often restricted to\nsome subset of model layers to ensure computational feasibility. Prior seminal\nwork by Yeh et al. (2022) in assessing which layers are best suited for\ncomputing language data influence concluded that the first (embedding) layers\nare the most informative for this purpose, using a hypothesis based on\ninfluence scores canceling out (i.e., the cancellation effect). In this work,\nwe propose theoretical and empirical evidence demonstrating how the\ncancellation effect is unreliable, and that middle attention layers are better\nestimators for influence. Furthermore, we address the broader challenge of\naggregating influence scores across layers, and showcase how alternatives to\nstandard averaging (such as ranking and vote-based methods) can lead to\nsignificantly improved performance. Finally, we propose better methods for\nevaluating influence score efficacy in LLMs without undertaking model\nretraining, and propose a new metric known as the Noise Detection Rate (NDR)\nthat exhibits strong predictive capability compared to the cancellation effect.\nThrough extensive experiments across LLMs of varying types and scales, we\nconcretely determine that the first (layers) are not necessarily better than\nthe last (layers) for LLM influence estimation, contrasting with prior\nknowledge in the field.", "AI": {"tldr": "该论文挑战了现有认知，证明在大型语言模型影响函数计算中，中间注意力层比第一层更适合，提出了新的层间聚合方法和评估指标NDR。", "motivation": "现有研究认为第一层最适合计算语言数据影响，但该研究认为基于抵消效应的假设不可靠，需要重新评估最佳影响计算层和聚合方法。", "method": "提出理论和实证证据分析抵消效应的不可靠性，比较不同层的影响计算效果，探索排名和投票等替代平均聚合的方法，并引入NDR指标评估影响分数效果。", "result": "通过多种类型和规模的LLM实验证明，第一层不一定比最后一层更适合影响估计，中间注意力层表现更好，新聚合方法和NDR指标显著提升性能。", "conclusion": "颠覆了领域内关于第一层最适合影响计算的先验知识，为LLM决策解释和数据集审计提供了更可靠的方法论基础。"}}
{"id": "2511.04720", "pdf": "https://arxiv.org/pdf/2511.04720", "abs": "https://arxiv.org/abs/2511.04720", "authors": ["Ha Young Kim", "Jun Li", "Ana Beatriz Solana", "Carolin M. Pirkl", "Benedikt Wiestler", "Julia A. Schnabel", "Cosmin I. Bercea"], "title": "Learning to reason about rare diseases through retrieval-augmented agents", "categories": ["cs.CL", "cs.AI"], "comment": "Submitted on behalf of the PREDICTOM consortium", "summary": "Rare diseases represent the long tail of medical imaging, where AI models\noften fail due to the scarcity of representative training data. In clinical\nworkflows, radiologists frequently consult case reports and literature when\nconfronted with unfamiliar findings. Following this line of reasoning, we\nintroduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic\nsystem for rare disease detection in brain MRI. Our approach uses AI agents\nwith access to external medical knowledge by embedding both case reports and\nliterature using sentence transformers and indexing them with FAISS to enable\nefficient similarity search. The agent retrieves clinically relevant evidence\nto guide diagnostic decision making on unseen diseases, without the need of\nadditional training. Designed as a model-agnostic reasoning module, RADAR can\nbe seamlessly integrated with diverse large language models, consistently\nimproving their rare pathology recognition and interpretability. On the NOVA\ndataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2%\nperformance gain, with the strongest improvements observed for open source\nmodels such as DeepSeek. Beyond accuracy, the retrieved examples provide\ninterpretable, literature grounded explanations, highlighting\nretrieval-augmented reasoning as a powerful paradigm for low-prevalence\nconditions in medical imaging.", "AI": {"tldr": "RADAR是一个基于检索增强诊断推理代理的系统，用于脑MRI罕见疾病检测，通过检索外部医学知识来指导诊断决策，无需额外训练即可提升模型性能。", "motivation": "罕见疾病在医学影像中数据稀缺，导致AI模型表现不佳。放射科医生在遇到不熟悉病例时会查阅病例报告和文献，因此需要开发能够利用外部医学知识的系统。", "method": "使用AI代理访问外部医学知识，通过句子变换器嵌入病例报告和文献，并用FAISS进行索引以实现高效相似性搜索。作为模型无关的推理模块，可与各种大语言模型集成。", "result": "在包含280种不同罕见疾病的NOVA数据集上，RADAR实现了高达10.2%的性能提升，特别是对开源模型如DeepSeek改进最明显。", "conclusion": "检索增强推理为医学影像中的低流行率疾病提供了强大的解决方案，不仅提高了准确性，还提供了可解释的、基于文献的证据支持。"}}
{"id": "2511.04754", "pdf": "https://arxiv.org/pdf/2511.04754", "abs": "https://arxiv.org/abs/2511.04754", "authors": ["Nikolai Ilinykh", "Simon Dobnik"], "title": "Surprisal reveals diversity gaps in image captioning and different scorers change the story", "categories": ["cs.CL"], "comment": "Accepted and presented at INLG 2025", "summary": "We quantify linguistic diversity in image captioning with surprisal variance\n- the spread of token-level negative log-probabilities within a caption set. On\nthe MSCOCO test set, we compare five state-of-the-art vision-and-language LLMs,\ndecoded with greedy and nucleus sampling, to human captions. Measured with a\ncaption-trained n-gram LM, humans display roughly twice the surprisal variance\nof models, but rescoring the same captions with a general-language model\nreverses the pattern. Our analysis introduces the surprisal-based diversity\nmetric for image captioning. We show that relying on a single scorer can\ncompletely invert conclusions, thus, robust diversity evaluation must report\nsurprisal under several scorers.", "AI": {"tldr": "该论文提出使用困惑度方差作为图像字幕生成的语言多样性度量指标，在MSCOCO数据集上比较了5种最先进的视觉语言模型与人类字幕的多样性表现，发现评估结果高度依赖于评分模型的选择。", "motivation": "现有图像字幕生成模型的语言多样性评估缺乏稳健的度量方法，需要一种能够准确衡量字幕集内token级概率分布差异的多样性指标。", "method": "引入困惑度方差作为多样性度量，在MSCOCO测试集上比较5种SOTA视觉语言模型（使用贪婪解码和核采样）与人类字幕，分别使用字幕训练的n-gram语言模型和通用语言模型进行评分。", "result": "使用字幕训练的语言模型评分时，人类字幕的困惑度方差约为模型的两倍；但使用通用语言模型重新评分后，结果模式完全反转。", "conclusion": "依赖单一评分器会完全颠倒多样性评估结论，因此稳健的多样性评估必须在多个评分器下报告困惑度结果。"}}
{"id": "2511.04875", "pdf": "https://arxiv.org/pdf/2511.04875", "abs": "https://arxiv.org/abs/2511.04875", "authors": ["Matthew Bozoukov", "Matthew Nguyen", "Shubkarman Singh", "Bart Bussmann", "Patrick Leask"], "title": "Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent studies have revealed that LLMs can exhibit behavioral self-awareness:\nthe ability to accurately describe or predict their own learned behaviors\nwithout explicit supervision. This capability raises safety concerns as it may,\nfor example, allow models to better conceal their true abilities during\nevaluation. We attempt to characterize the minimal conditions under which such\nself-awareness emerges, and the mechanistic processes through which it\nmanifests. Through controlled finetuning experiments on instruction-tuned LLMs\nwith low-rank adapters (LoRA), we find: (1) that self-awareness can be reliably\ninduced using a single rank-1 LoRA adapter; (2) that the learned self-aware\nbehavior can be largely captured by a single steering vector in activation\nspace, recovering nearly all of the fine-tune's behavioral effect; and (3) that\nself-awareness is non-universal and domain-localized, with independent\nrepresentations across tasks. Together, these findings suggest that behavioral\nself-awareness emerges as a domain-specific, linear feature that can be easily\ninduced and modulated.", "AI": {"tldr": "研究发现LLMs可以通过简单的低秩适配器(LoRA)获得行为自我意识，这种能力表现为可诱导、可调控的线性特征，且具有领域特异性。", "motivation": "LLMs展现出的行为自我意识能力可能带来安全隐患，比如让模型在评估时更好地隐藏真实能力，需要研究这种自我意识出现的最小条件和机制过程。", "method": "通过在指令调优的LLMs上使用低秩适配器(LoRA)进行受控微调实验，特别是使用单个rank-1 LoRA适配器。", "result": "1) 使用单个rank-1 LoRA适配器可可靠诱导自我意识；2) 学习到的自我意识行为可通过激活空间的单个导向向量捕获；3) 自我意识非通用且领域局部化，在不同任务间有独立表示。", "conclusion": "行为自我意识作为领域特定的线性特征出现，可以轻松诱导和调控，这对LLMs的安全性评估具有重要意义。"}}
{"id": "2511.04800", "pdf": "https://arxiv.org/pdf/2511.04800", "abs": "https://arxiv.org/abs/2511.04800", "authors": ["Chenxi Liu", "Junjie Liang", "Yuqi Jia", "Bochuan Cao", "Yang Bai", "Heng Huang", "Xun Chen"], "title": "Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an\neffective approach for improving the reasoning abilities of large language\nmodels (LLMs). The Group Relative Policy Optimization (GRPO) family has\ndemonstrated strong performance in training LLMs with RLVR. However, as models\ntrain longer and scale larger, more training prompts become residual prompts,\nthose with zero variance rewards that provide no training signal. Consequently,\nfewer prompts contribute to training, reducing diversity and hindering\neffectiveness. To fully exploit these residual prompts, we propose the Explore\nResidual Prompts in Policy Optimization (ERPO) framework, which encourages\nexploration on residual prompts and reactivates their training signals. ERPO\nmaintains a history tracker for each prompt and adaptively increases the\nsampling temperature for residual prompts that previously produced all correct\nresponses. This encourages the model to generate more diverse reasoning traces,\nintroducing incorrect responses that revive training signals. Empirical results\non the Qwen2.5 series demonstrate that ERPO consistently surpasses strong\nbaselines across multiple mathematical reasoning benchmarks.", "AI": {"tldr": "ERPO框架通过自适应增加残差提示的采样温度来鼓励探索，重新激活零方差奖励提示的训练信号，在数学推理基准上超越现有基线方法", "motivation": "随着RLVR训练时间延长和模型规模增大，更多训练提示变为残差提示（零方差奖励），导致训练信号减少和多样性下降，影响模型效果", "method": "提出ERPO框架，为每个提示维护历史追踪器，自适应增加残差提示的采样温度，鼓励生成更多样化的推理轨迹，引入错误响应以重新激活训练信号", "result": "在Qwen2.5系列上的实证结果表明，ERPO在多个数学推理基准上持续超越强基线方法", "conclusion": "ERPO能有效利用残差提示，通过探索策略重新激活训练信号，提升强化学习验证奖励框架下大语言模型的推理能力"}}
{"id": "2511.04919", "pdf": "https://arxiv.org/pdf/2511.04919", "abs": "https://arxiv.org/abs/2511.04919", "authors": ["Chandra Vamsi Krishna Alla", "Harish Naidu Gaddam", "Manohar Kommi"], "title": "BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models", "categories": ["cs.CL", "cs.AI", "I.2.7; I.2.6; H.3.3"], "comment": "11 pages, 3 figures, 5 tables. Evaluated on 700 QA pairs across\n  multiple document lengths", "summary": "Large Language Models (LLMs) face significant computational and memory\nconstraints when processing long contexts, despite growing demand for\napplications requiring reasoning over extensive documents, multi-session\ndialogues, and book length texts. While recent advances have extended context\nwindows to 100K-1M tokens, such approaches incur prohibitive costs for resource\nconstrained deployments. We propose BudgetMem, a novel memory augmented\narchitecture that learns what to remember rather than remembering everything.\nOur system combines selective memory policies with feature based salience\nscoring (entity density, TF-IDF, discourse markers, position bias) to decide\nwhich information merits storage under strict budget constraints. Unlike\nexisting retrieval augmented generation (RAG) systems that store all chunks,\nBudgetMem employs learned gating mechanisms coupled with BM25 sparse retrieval\nfor efficient information access. Through comprehensive experiments on 700\nquestion answer pairs across short (237 tokens) and long (5K-10K tokens)\ndocuments with Llama-3.2-3B-Instruct, we demonstrate that BudgetMem achieves\nremarkable results on long documents: only 1.0% F1 score degradation while\nsaving 72.4% memory compared to baseline RAG. We validate our approach through\nbudget sensitivity analysis (testing 7 budget ratios), naive baseline\ncomparisons, and document length analysis, showing that BudgetMem's benefits\nincrease with document length. Our work provides a practical pathway for\ndeploying capable long context systems on modest hardware, democratizing access\nto advanced language understanding capabilities.", "AI": {"tldr": "BudgetMem是一种新的内存增强架构，通过选择性记忆策略和特征显著性评分，在严格预算约束下决定存储哪些信息，相比传统RAG系统节省72.4%内存且性能仅下降1.0%", "motivation": "大语言模型处理长上下文时面临显著的计算和内存约束，尽管应用需求增长，但现有扩展上下文窗口的方法在资源受限部署中成本过高", "method": "结合选择性记忆策略与基于特征的显著性评分（实体密度、TF-IDF、话语标记、位置偏差），使用学习门控机制和BM25稀疏检索进行高效信息访问", "result": "在700个问答对实验中，BudgetMem在长文档上仅损失1.0% F1分数，同时节省72.4%内存，且随着文档长度增加效果更显著", "conclusion": "BudgetMem为在有限硬件上部署长上下文系统提供了实用路径，使先进语言理解能力更加普及"}}
{"id": "2511.04869", "pdf": "https://arxiv.org/pdf/2511.04869", "abs": "https://arxiv.org/abs/2511.04869", "authors": ["Preetum Nakkiran", "Arwen Bradley", "Adam Goliński", "Eugene Ndiaye", "Michael Kirchhof", "Sinead Williamson"], "title": "Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs", "categories": ["cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "Large Language Models (LLMs) often lack meaningful confidence estimates for\ntheir outputs. While base LLMs are known to exhibit next-token calibration, it\nremains unclear whether they can assess confidence in the actual meaning of\ntheir responses beyond the token level. We find that, when using a certain\nsampling-based notion of semantic calibration, base LLMs are remarkably\nwell-calibrated: they can meaningfully assess confidence in open-domain\nquestion-answering tasks, despite not being explicitly trained to do so. Our\nmain theoretical contribution establishes a mechanism for why semantic\ncalibration emerges as a byproduct of next-token prediction, leveraging a\nrecent connection between calibration and local loss optimality. The theory\nrelies on a general definition of \"B-calibration,\" which is a notion of\ncalibration parameterized by a choice of equivalence classes (semantic or\notherwise). This theoretical mechanism leads to a testable prediction: base\nLLMs will be semantically calibrated when they can easily predict their own\ndistribution over semantic answer classes before generating a response. We\nstate three implications of this prediction, which we validate through\nexperiments: (1) Base LLMs are semantically calibrated across\nquestion-answering tasks, (2) RL instruction-tuning systematically breaks this\ncalibration, and (3) chain-of-thought reasoning breaks calibration. To our\nknowledge, our work provides the first principled explanation of when and why\nsemantic calibration emerges in LLMs.", "AI": {"tldr": "研究发现基础LLMs在语义层面具有良好校准能力，能够准确评估开放域问答任务中的置信度，这种能力是next-token预测的副产品。理论分析建立了B-calibration机制，并通过实验验证了RL指令微调和思维链推理会破坏这种校准。", "motivation": "大型语言模型通常缺乏对其输出的有意义的置信度估计。虽然基础LLMs在next-token层面表现出校准特性，但尚不清楚它们是否能在超越token层面的语义层面上评估其响应的置信度。", "method": "提出基于采样的语义校准概念，建立B-calibration理论框架，将校准与局部损失最优性联系起来。通过实验验证理论预测，包括基础LLMs的语义校准能力、RL指令微调的影响以及思维链推理的效果。", "result": "基础LLMs在开放域问答任务中表现出显著的语义校准能力；RL指令微调会系统性破坏这种校准；思维链推理也会破坏校准效果。", "conclusion": "该研究首次提供了关于LLMs何时以及为何出现语义校准的原则性解释，揭示了next-token预测训练如何自然产生语义层面的置信度评估能力，同时指出了RL微调和思维链方法对校准特性的负面影响。"}}
{"id": "2511.04962", "pdf": "https://arxiv.org/pdf/2511.04962", "abs": "https://arxiv.org/abs/2511.04962", "authors": ["Zihao Yi", "Qingxuan Jiang", "Ruotian Ma", "Xingyu Chen", "Qu Yang", "Mengru Wang", "Fanghua Ye", "Ying Shen", "Zhaopeng Tu", "Xiaolong Li", "Linus"], "title": "Too Good to be Bad: On the Failure of LLMs to Role-Play Villains", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly tasked with creative\ngeneration, including the simulation of fictional characters. However, their\nability to portray non-prosocial, antagonistic personas remains largely\nunexamined. We hypothesize that the safety alignment of modern LLMs creates a\nfundamental conflict with the task of authentically role-playing morally\nambiguous or villainous characters. To investigate this, we introduce the Moral\nRolePlay benchmark, a new dataset featuring a four-level moral alignment scale\nand a balanced test set for rigorous evaluation. We task state-of-the-art LLMs\nwith role-playing characters from moral paragons to pure villains. Our\nlarge-scale evaluation reveals a consistent, monotonic decline in role-playing\nfidelity as character morality decreases. We find that models struggle most\nwith traits directly antithetical to safety principles, such as ``Deceitful''\nand ``Manipulative'', often substituting nuanced malevolence with superficial\naggression. Furthermore, we demonstrate that general chatbot proficiency is a\npoor predictor of villain role-playing ability, with highly safety-aligned\nmodels performing particularly poorly. Our work provides the first systematic\nevidence of this critical limitation, highlighting a key tension between model\nsafety and creative fidelity. Our benchmark and findings pave the way for\ndeveloping more nuanced, context-aware alignment methods.", "AI": {"tldr": "大型语言模型在扮演反派角色时存在系统性缺陷，安全对齐机制导致其无法真实呈现道德模糊或邪恶角色，角色扮演保真度随角色道德水平下降而单调递减。", "motivation": "研究LLMs在模拟非亲社会、反派角色方面的能力缺失，探索模型安全对齐与创造性角色扮演之间的根本冲突。", "method": "引入Moral RolePlay基准测试，包含四级道德对齐量表和平衡测试集，要求最先进的LLMs扮演从道德典范到纯粹反派的各种角色。", "result": "发现角色扮演保真度随角色道德水平下降而单调递减，模型在处理与安全原则直接对立的特质（如欺骗性和操纵性）时表现最差，安全对齐度高的模型在反派角色扮演方面表现特别糟糕。", "conclusion": "研究揭示了模型安全与创作保真度之间的关键张力，为开发更细致、上下文感知的对齐方法奠定了基础，表明通用聊天机器人能力不能很好地预测反派角色扮演能力。"}}
{"id": "2511.05018", "pdf": "https://arxiv.org/pdf/2511.05018", "abs": "https://arxiv.org/abs/2511.05018", "authors": ["Prasoon Varshney", "Makesh Narsimhan Sreedhar", "Liwei Jiang", "Traian Rebedea", "Christopher Parisien"], "title": "Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at the Multi-Turn Interactions workshop at the 39th\n  Conference on Neural Information Processing Systems (NeurIPS 2025)", "summary": "Large language models (LLMs) are typically aligned to a universal set of\nsafety and usage principles intended for broad public acceptability. Yet,\nreal-world applications of LLMs often take place within organizational\necosystems shaped by distinctive corporate policies, regulatory requirements,\nuse cases, brand guidelines, and ethical commitments. This reality highlights\nthe need for rigorous and comprehensive evaluation of LLMs with pluralistic\nalignment goals, an alignment paradigm that emphasizes adaptability to diverse\nuser values and needs. In this work, we present PLURALISTIC BEHAVIOR SUITE\n(PBSUITE), a dynamic evaluation suite designed to systematically assess LLMs'\ncapacity to adhere to pluralistic alignment specifications in multi-turn,\ninteractive conversations. PBSUITE consists of (1) a diverse dataset of 300\nrealistic LLM behavioral policies, grounded in 30 industries; and (2) a dynamic\nevaluation framework for stress-testing model compliance with custom behavioral\nspecifications under adversarial conditions. Using PBSUITE, We find that\nleading open- and closed-source LLMs maintain robust adherence to behavioral\npolicies in single-turn settings (less than 4% failure rates), but their\ncompliance weakens substantially in multi-turn adversarial interactions (up to\n84% failure rates). These findings highlight that existing model alignment and\nsafety moderation methods fall short in coherently enforcing pluralistic\nbehavioral policies in real-world LLM interactions. Our work contributes both\nthe dataset and analytical framework to support future research toward robust\nand context-aware pluralistic alignment techniques.", "AI": {"tldr": "提出了PLURALISTIC BEHAVIOR SUITE (PBSUITE)评估框架，用于测试LLM在多轮对抗性对话中遵守多样化行为规范的能力，发现现有模型在多轮交互中合规性显著下降。", "motivation": "现实应用中LLM需要在具有不同企业政策、监管要求和道德承诺的组织生态系统中运行，需要评估模型对多元化对齐目标的适应性。", "method": "开发了PBSUITE评估套件，包含300个基于30个行业的现实行为策略数据集，以及用于在对抗条件下测试模型合规性的动态评估框架。", "result": "领先的开源和闭源LLM在单轮设置中表现良好（失败率<4%），但在多轮对抗交互中合规性大幅减弱（失败率高达84%）。", "conclusion": "现有模型对齐和安全审核方法在强制执行多元化行为策略方面存在不足，需要开发更鲁棒和情境感知的多元化对齐技术。"}}
{"id": "2511.04910", "pdf": "https://arxiv.org/pdf/2511.04910", "abs": "https://arxiv.org/abs/2511.04910", "authors": ["Jaehoon Lee", "Sohyun Kim", "Wanggeun Park", "Geon Lee", "Seungkyung Kim", "Minyoung Lee"], "title": "SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean Public Documents", "categories": ["cs.CL"], "comment": "27 pages, 15 figures, 6 tables", "summary": "Existing benchmarks for visual document retrieval (VDR) largely overlook\nnon-English languages and the structural complexity of official publications.\nTo address this critical gap, we introduce SDS KoPub VDR, the first\nlarge-scale, publicly available benchmark for retrieving and understanding\nKorean public documents. The benchmark is built upon a corpus of 361 real-world\ndocuments (40,781 pages), including 256 files under the KOGL Type 1 license and\n105 from official legal portals, capturing complex visual elements like tables,\ncharts, and multi-column layouts. To establish a challenging and reliable\nevaluation set, we constructed 600 query-page-answer triples. These were\ninitially generated using multimodal models (e.g., GPT-4o) and subsequently\nunderwent a rigorous human verification and refinement process to ensure\nfactual accuracy and contextual relevance. The queries span six major public\ndomains and are systematically categorized by the reasoning modality required:\ntext-based, visual-based (e.g., chart interpretation), and cross-modal. We\nevaluate SDS KoPub VDR on two complementary tasks that reflect distinct\nretrieval paradigms: (1) text-only retrieval, which measures a model's ability\nto locate relevant document pages based solely on textual signals, and (2)\nmultimodal retrieval, which assesses retrieval performance when visual features\n(e.g., tables, charts, and layouts) are jointly leveraged alongside text. This\ndual-task evaluation reveals substantial performance gaps, particularly in\nmultimodal scenarios requiring cross-modal reasoning, even for state-of-the-art\nmodels. As a foundational resource, SDS KoPub VDR not only enables rigorous and\nfine-grained evaluation across textual and multimodal retrieval tasks but also\nprovides a clear roadmap for advancing multimodal AI in complex, real-world\ndocument intelligence.", "AI": {"tldr": "SDS KoPub VDR是首个大规模、公开可用的韩语公共文档检索基准，包含361个真实文档（40,781页）和600个经过人工验证的查询-页面-答案三元组，用于评估文本和多模态检索性能。", "motivation": "现有视觉文档检索基准主要关注英文文档，忽视了非英语语言和官方出版物的结构复杂性，特别是韩语公共文档的检索需求。", "method": "基于361个真实韩语公共文档构建语料库，使用多模态模型生成查询-页面-答案三元组，并通过严格的人工验证流程确保准确性和相关性。查询涵盖六个公共领域，按推理模态分类。", "result": "评估显示即使在最先进模型中，多模态场景（特别是需要跨模态推理的任务）存在显著的性能差距。", "conclusion": "SDS KoPub VDR为复杂真实世界文档智能提供了基础资源，支持文本和多模态检索任务的严格评估，并为多模态AI发展提供了清晰路线图。"}}
{"id": "2511.05040", "pdf": "https://arxiv.org/pdf/2511.05040", "abs": "https://arxiv.org/abs/2511.05040", "authors": ["Mykyta Syromiatnikov", "Victoria Ruvinskaya"], "title": "UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian", "categories": ["cs.CL", "cs.AI", "cs.SE"], "comment": "8 pages, 5 figures. XI International conference \"Informatics.\n  Culture. Technique.\" (2025)", "summary": "Evaluating the real capabilities of large language models in low-resource\nlanguages still represents a challenge, as many existing benchmarks focus on\nwidespread tasks translated from English or evaluate only simple language\nunderstanding. This paper introduces UA-Code-Bench, a new open-source benchmark\nestablished for a thorough evaluation of language models' code generation and\ncompetitive programming problem-solving abilities in Ukrainian. The benchmark\ncomprises 500 problems from the Eolymp platform, evenly distributed across five\ncomplexity levels from very easy to very hard. A diverse set of 13 leading\nproprietary and open-source models, generating Python solutions based on a\none-shot prompt, was evaluated via the dedicated Eolymp environment against\nhidden tests, ensuring code correctness. The obtained results reveal that even\ntop-performing models, such as OpenAI o3 and GPT-5, solve only half of the\nproblems, highlighting the challenge of code generation in low-resource natural\nlanguage. Furthermore, this research presents a comprehensive analysis of\nperformance across various difficulty levels, as well as an assessment of\nsolution uniqueness and computational efficiency, measured by both elapsed time\nand memory consumption of the generated solutions. In conclusion, this work\ndemonstrates the value of competitive programming benchmarks in evaluating\nlarge language models, especially in underrepresented languages. It also paves\nthe way for future research on multilingual code generation and\nreasoning-enhanced models. The benchmark, data parsing, preparation, code\ngeneration, and evaluation scripts are available at\nhttps://huggingface.co/datasets/NLPForUA/ua-code-bench.", "AI": {"tldr": "UA-Code-Bench是一个针对乌克兰语代码生成和竞争性编程问题解决能力评估的新基准测试，包含500个难度分级的问题，测试显示即使顶级模型也只能解决约一半问题。", "motivation": "评估低资源语言中大语言模型的真实能力存在挑战，现有基准测试多关注从英语翻译的广泛任务或仅评估简单语言理解。", "method": "使用Eolymp平台的500个问题，分为5个难度等级，通过一次性提示让13个领先的专有和开源模型生成Python解决方案，在专用环境中通过隐藏测试评估代码正确性。", "result": "即使表现最好的模型（如OpenAI o3和GPT-5）也只能解决约50%的问题，突显了低资源自然语言中代码生成的挑战。", "conclusion": "竞争性编程基准测试对于评估大语言模型具有重要价值，特别是在代表性不足的语言中，为多语言代码生成和推理增强模型的未来研究铺平了道路。"}}
{"id": "2511.05320", "pdf": "https://arxiv.org/pdf/2511.05320", "abs": "https://arxiv.org/abs/2511.05320", "authors": ["Klára Bendová", "Tomáš Knap", "Jan Černý", "Vojtěch Pour", "Jaromir Savelka", "Ivana Kvapilíková", "Jakub Drápal"], "title": "What Are the Facts? Automated Extraction of Court-Established Facts from Criminal-Court Opinions", "categories": ["cs.CL", "cs.AI"], "comment": "Paper accepted to the proceedings of ASAIL 2025 Workshop under ICAIL\n  conference for publication. Paper contains 6 pages (references included) and\n  2 appendices. It contains 8 tables, no figures", "summary": "Criminal justice administrative data contain only a limited amount of\ninformation about the committed offense. However, there is an unused source of\nextensive information in continental European courts' decisions: descriptions\nof criminal behaviors in verdicts by which offenders are found guilty. In this\npaper, we study the feasibility of extracting these descriptions from publicly\navailable court decisions from Slovakia. We use two different approaches for\nretrieval: regular expressions and large language models (LLMs). Our baseline\nwas a simple method employing regular expressions to identify typical words\noccurring before and after the description. The advanced regular expression\napproach further focused on \"sparing\" and its normalization (insertion of\nspaces between individual letters), typical for delineating the description.\nThe LLM approach involved prompting the Gemini Flash 2.0 model to extract the\ndescriptions using predefined instructions. Although the baseline identified\ndescriptions in only 40.5% of verdicts, both methods significantly outperformed\nit, achieving 97% with advanced regular expressions and 98.75% with LLMs, and\n99.5% when combined. Evaluation by law students showed that both advanced\nmethods matched human annotations in about 90% of cases, compared to just 34.5%\nfor the baseline. LLMs fully matched human-labeled descriptions in 91.75% of\ninstances, and a combination of advanced regular expressions with LLMs reached\n92%.", "AI": {"tldr": "本研究探讨从斯洛伐克法院判决书中提取犯罪行为描述的可行性，比较正则表达式和大型语言模型两种方法的效果，发现LLM方法表现最佳，准确率可达98.75%。", "motivation": "刑事司法行政数据包含的犯罪信息有限，而欧洲大陆法院判决书中包含丰富的犯罪行为描述信息，但尚未被充分利用。", "method": "使用两种方法提取描述：基础正则表达式方法、高级正则表达式方法（处理\"sparing\"规范化）和大型语言模型方法（Gemini Flash 2.0）。", "result": "基础方法准确率40.5%，高级正则表达式97%，LLM方法98.75%，组合方法99.5%。人工评估显示高级方法与人类标注匹配度约90%，LLM完全匹配率91.75%。", "conclusion": "LLM在提取法院判决书中的犯罪行为描述方面表现优异，与正则表达式方法结合可达到最高准确率，为利用法律文本数据提供了有效工具。"}}
{"id": "2511.04921", "pdf": "https://arxiv.org/pdf/2511.04921", "abs": "https://arxiv.org/abs/2511.04921", "authors": ["Yu Li", "Lehui Li", "Qingmin Liao", "Fengli Xu", "Yong Li"], "title": "AgentExpt: Automating AI Experiment Design with LLM-based Resource Retrieval Agent", "categories": ["cs.CL"], "comment": "10 pages", "summary": "Large language model agents are becoming increasingly capable at web-centric\ntasks such as information retrieval, complex reasoning. These emerging\ncapabilities have given rise to surge research interests in developing LLM\nagent for facilitating scientific quest. One key application in AI research is\nto automate experiment design through agentic dataset and baseline retrieval.\nHowever, prior efforts suffer from limited data coverage, as recommendation\ndatasets primarily harvest candidates from public portals and omit many\ndatasets actually used in published papers, and from an overreliance on content\nsimilarity that biases model toward superficial similarity and overlooks\nexperimental suitability. Harnessing collective perception embedded in the\nbaseline and dataset citation network, we present a comprehensive framework for\nbaseline and dataset recommendation. First, we design an automated\ndata-collection pipeline that links roughly one hundred thousand accepted\npapers to the baselines and datasets they actually used. Second, we propose a\ncollective perception enhanced retriever. To represent the position of each\ndataset or baseline within the scholarly network, it concatenates\nself-descriptions with aggregated citation contexts. To achieve efficient\ncandidate recall, we finetune an embedding model on these representations.\nFinally, we develop a reasoning-augmented reranker that exact interaction\nchains to construct explicit reasoning chains and finetunes a large language\nmodel to produce interpretable justifications and refined rankings. The dataset\nwe curated covers 85\\% of the datasets and baselines used at top AI conferences\nover the past five years. On our dataset, the proposed method outperforms the\nstrongest prior baseline with average gains of +5.85\\% in Recall@20, +8.30\\% in\nHitRate@5. Taken together, our results advance reliable, interpretable\nautomation of experimental design.", "AI": {"tldr": "该论文提出了一个基于集体感知的基准测试和数据集推荐框架，通过自动化数据收集管道和增强的检索排序方法，显著提升了AI实验设计的自动化效果。", "motivation": "现有LLM代理在科学实验设计自动化中存在数据覆盖有限和过度依赖内容相似性的问题，导致推荐结果偏向表面相似性而忽视实验适用性。", "method": "1) 构建自动化数据收集管道，链接十万篇论文与其实际使用的基准和数据集；2) 开发集体感知增强检索器，结合自描述和引用上下文表示学术网络位置；3) 设计推理增强重排序器，构建显式推理链并生成可解释的推荐理由。", "result": "构建的数据集覆盖了过去五年顶级AI会议中85%使用的数据集和基准，在Recall@20指标上平均提升5.85%，在HitRate@5上提升8.30%。", "conclusion": "该方法显著提升了实验设计自动化的可靠性和可解释性，为科学探索提供了更有效的工具支持。"}}
{"id": "2511.05361", "pdf": "https://arxiv.org/pdf/2511.05361", "abs": "https://arxiv.org/abs/2511.05361", "authors": ["Maria Huynh", "Wilder C. Rodrigues"], "title": "A multimodal multiplex of the mental lexicon for multilingual individuals", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Historically, bilingualism was often perceived as an additional cognitive\nload that could hinder linguistic and intellectual development. However, over\nthe last three decades, this view has changed considerably. Numerous studies\nhave aimed to model and understand the architecture of the bilingual word\nrecognition system Dijkstra and van Heuven (2002), investigating how parallel\nactivation operates in the brain and how one language influences another Kroll\net al. (2015). Increasingly, evidence suggests that multilinguals, individuals\nwho speak three or more languages, can perform better than monolinguals in\nvarious linguistic and cognitive tasks, such as learning an additional language\nAbu-Rabia and Sanitsky (2010). This research proposal focuses on the study of\nthe mental lexicon and how it may be structured in individuals who speak\nmultiple languages. Building on the work of Stella et al. (2018), who\ninvestigated explosive learning in humans using a multiplex model of the mental\nlexicon, and the Bilingual Interactive Activation (BIA+) framework proposed by\nDijkstra and van Heuven (2002), the present study applies the same multilayer\nnetwork principles introduced by Kivela et al. (2014). Our experimental design\nextends previous research by incorporating multimodality into the multiplex\nmodel, introducing an additional layer that connects visual inputs to their\ncorresponding lexical representations across the multilingual layers of the\nmental lexicon. In this research, we aim to explore how a heritage language\ninfluences the acquisition of another language. Specifically, we ask: Does the\npresence of visual input in a translation task influence participants'\nproficiency and accuracy compared to text-only conditions?", "AI": {"tldr": "本研究探讨多语言者的心理词典结构，特别是视觉输入如何影响翻译任务中的语言熟练度和准确性，通过多层网络模型扩展了现有的双语激活研究。", "motivation": "传统上双语被视为认知负担，但近期研究表明多语言者在语言和认知任务中表现更优。本研究基于心理词典的多层网络模型，探索视觉输入对多语言习得的影响。", "method": "采用多层网络原则，扩展Stella等人的多路复用模型，增加视觉输入层连接到多语言心理词典的词汇表征层，通过翻译任务比较视觉输入与纯文本条件的效果。", "result": "论文摘要未提供具体实验结果，但提出了研究问题：视觉输入是否比纯文本条件更能提高翻译任务的熟练度和准确性。", "conclusion": "研究旨在通过引入视觉模态的多层网络模型，深化对多语言心理词典结构的理解，并为多语言习得提供新的实证依据。"}}
{"id": "2511.04926", "pdf": "https://arxiv.org/pdf/2511.04926", "abs": "https://arxiv.org/abs/2511.04926", "authors": ["Shixiong Zhao", "Hideaki Takeda"], "title": "Diagnosing and Mitigating Semantic Inconsistencies in Wikidata's Classification Hierarchy", "categories": ["cs.CL"], "comment": null, "summary": "Wikidata is currently the largest open knowledge graph on the web,\nencompassing over 120 million entities. It integrates data from various\ndomain-specific databases and imports a substantial amount of content from\nWikipedia, while also allowing users to freely edit its content. This openness\nhas positioned Wikidata as a central resource in knowledge graph research and\nhas enabled convenient knowledge access for users worldwide. However, its\nrelatively loose editorial policy has also led to a degree of taxonomic\ninconsistency. Building on prior work, this study proposes and applies a novel\nvalidation method to confirm the presence of classification errors,\nover-generalized subclass links, and redundant connections in specific domains\nof Wikidata. We further introduce a new evaluation criterion for determining\nwhether such issues warrant correction and develop a system that allows users\nto inspect the taxonomic relationships of arbitrary Wikidata\nentities-leveraging the platform's crowdsourced nature to its full potential.", "AI": {"tldr": "本研究提出并应用了一种新颖的验证方法来检测Wikidata中的分类错误、过度泛化的子类链接和冗余连接，并开发了允许用户检查任意实体分类关系的系统", "motivation": "Wikidata作为最大的开放知识图谱，其相对宽松的编辑政策导致了分类不一致性问题，需要有效的验证和纠正方法", "method": "提出并应用新的验证方法检测分类错误、过度泛化的子类链接和冗余连接；引入新的评估标准判断问题是否需要修正；开发用户检查分类关系的系统", "result": "确认了Wikidata特定领域存在分类错误、过度泛化的子类链接和冗余连接问题", "conclusion": "研究提供了有效的验证方法和工具，充分利用了Wikidata的众包特性来解决分类不一致性问题"}}
{"id": "2511.04952", "pdf": "https://arxiv.org/pdf/2511.04952", "abs": "https://arxiv.org/abs/2511.04952", "authors": ["Wei Shao", "Lingchao Zheng", "Pengyu Wang", "Peizhen Zheng", "Jun Li", "Yuwei Fan"], "title": "LoPT: Lossless Parallel Tokenization Acceleration for Long Context Inference of Large Language Model", "categories": ["cs.CL"], "comment": null, "summary": "Long context inference scenarios have become increasingly important for large\nlanguage models, yet they introduce significant computational latency. While\nprior research has optimized long-sequence inference through operators, model\narchitectures, and system frameworks, tokenization remains an overlooked\nbottleneck. Existing parallel tokenization methods accelerate processing\nthrough text segmentation and multi-process tokenization, but they suffer from\ninconsistent results due to boundary artifacts that occur after merging. To\naddress this, we propose LoPT, a novel Lossless Parallel Tokenization framework\nthat ensures output identical to standard sequential tokenization. Our approach\nemploys character-position-based matching and dynamic chunk length adjustment\nto align and merge tokenized segments accurately. Extensive experiments across\ndiverse long-text datasets demonstrate that LoPT achieves significant speedup\nwhile guaranteeing lossless tokenization. We also provide theoretical proof of\nconsistency and comprehensive analytical studies to validate the robustness of\nour method.", "AI": {"tldr": "LoPT是一个无损并行分词框架，通过基于字符位置的匹配和动态分块长度调整来解决长文本推理中的分词瓶颈问题，确保与顺序分词结果完全一致的同时显著提升处理速度。", "motivation": "长文本推理场景中，分词成为被忽视的计算瓶颈。现有的并行分词方法由于边界伪影导致结果不一致，需要一种既能加速处理又能保证结果无损的解决方案。", "method": "提出LoPT框架，采用基于字符位置的匹配算法和动态分块长度调整策略，准确对齐和合并分词片段，确保输出与顺序分词完全一致。", "result": "在多个长文本数据集上的实验表明，LoPT实现了显著的速度提升，同时保证无损分词。提供了理论一致性证明和全面的分析研究验证方法鲁棒性。", "conclusion": "LoPT成功解决了并行分词中的一致性问题，为长文本推理提供了高效且可靠的分词解决方案，在保证结果准确性的同时大幅提升了处理效率。"}}
{"id": "2511.04989", "pdf": "https://arxiv.org/pdf/2511.04989", "abs": "https://arxiv.org/abs/2511.04989", "authors": ["Ya Wang", "Guangzheng Zhu", "Cungen Cao", "Jingjing Li", "He Li", "Xin Huang"], "title": "Acquiring Common Chinese Emotional Events Using Large Language Model", "categories": ["cs.CL"], "comment": "I am the second author (Guangzheng Zhu) and I am submitting this\n  paper on behalf of all co-authors", "summary": "Knowledge about emotional events is an important kind of knowledge which has\nbeen applied to improve the effectiveness of different applications. However,\nemotional events cannot be easily acquired, especially common or generalized\nemotional events that are context-independent. The goal of this paper is to\nobtain common emotional events in Chinese language such as \"win a prize\" and\n\"be criticized\". Our approach begins by collecting a comprehensive list of\nChinese emotional event indicators. Then, we generate emotional events by\nprompting a Chinese large language model (LLM) using these indicators. To\nensure the quality of these emotional events, we train a filter to discard\ninvalid generated results. We also classify these emotional events as being\npositive events and negative events using different techniques. Finally, we\nharvest a total of 102,218 high-quality common emotional events with sentiment\npolarity labels, which is the only large-scale commonsense knowledge base of\nemotional events in Chinese language. Intrinsic evaluation results show that\nthe proposed method in this paper can be effectively used to acquire common\nChinese emotional events. An extrinsic use case also demonstrates the strong\npotential of common emotional events in the field of emotion cause extraction\n(ECE). Related resources including emotional event indicators and emotional\nevents will be released after the publication of this paper.", "AI": {"tldr": "本文提出了一种通过中文大语言模型生成和过滤高质量情感事件的方法，构建了首个大规模中文情感事件常识知识库，包含102,218个带情感极性标签的事件，在情感原因提取任务中显示出强大潜力。", "motivation": "情感事件知识对提升应用效果很重要，但难以获取，特别是与上下文无关的通用情感事件。本文旨在获取中文通用情感事件如'获奖'和'被批评'。", "method": "1) 收集中文情感事件指示词列表；2) 使用中文大语言模型生成情感事件；3) 训练过滤器去除无效结果；4) 使用不同技术将情感事件分类为积极和消极事件", "result": "获得了102,218个高质量通用情感事件并标注情感极性，构建了唯一的大规模中文情感事件常识知识库。内在评估显示方法有效，外在用例在情感原因提取领域显示出强大潜力。", "conclusion": "该方法能有效获取中文通用情感事件，构建的知识库是中文领域唯一的大规模情感事件资源，在情感分析应用中具有重要价值，相关资源将在论文发表后公开。"}}
{"id": "2511.05064", "pdf": "https://arxiv.org/pdf/2511.05064", "abs": "https://arxiv.org/abs/2511.05064", "authors": ["Jinglin Liang", "Jin Zhong", "Shuangping Huang", "Yunqing Hu", "Huiyuan Zhang", "Huifang Li", "Lixin Fan", "Hanlin Gu"], "title": "Order-Level Attention Similarity Across Language Models: A Latent Commonality", "categories": ["cs.CL"], "comment": "Accepted by NeurIPS 2025", "summary": "In this paper, we explore an important yet previously neglected question: Do\ncontext aggregation patterns across Language Models (LMs) share commonalities?\nWhile some works have investigated context aggregation or attention weights in\nLMs, they typically focus on individual models or attention heads, lacking a\nsystematic analysis across multiple LMs to explore their commonalities. In\ncontrast, we focus on the commonalities among LMs, which can deepen our\nunderstanding of LMs and even facilitate cross-model knowledge transfer. In\nthis work, we introduce the Order-Level Attention (OLA) derived from the\norder-wise decomposition of Attention Rollout and reveal that the OLA at the\nsame order across LMs exhibits significant similarities. Furthermore, we\ndiscover an implicit mapping between OLA and syntactic knowledge. Based on\nthese two findings, we propose the Transferable OLA Adapter (TOA), a\ntraining-free cross-LM adapter transfer method. Specifically, we treat the OLA\nas a unified syntactic feature representation and train an adapter that takes\nOLA as input. Due to the similarities in OLA across LMs, the adapter\ngeneralizes to unseen LMs without requiring any parameter updates. Extensive\nexperiments demonstrate that TOA's cross-LM generalization effectively enhances\nthe performance of unseen LMs. Code is available at\nhttps://github.com/jinglin-liang/OLAS.", "AI": {"tldr": "该论文提出了一种跨语言模型的上下文聚合模式分析方法，发现不同语言模型在相同阶数的注意力模式上存在显著相似性，并基于此开发了无需训练即可跨模型迁移的适配器方法TOA。", "motivation": "现有研究主要关注单个语言模型或注意力头的上下文聚合模式，缺乏对多个语言模型之间共同模式的系统性分析，这限制了我们对语言模型的理解和跨模型知识迁移的可能性。", "method": "提出Order-Level Attention (OLA)方法，基于注意力展开的阶数分解来分析注意力模式；发现OLA与句法知识存在隐式映射；开发Transferable OLA Adapter (TOA)，将OLA作为统一的句法特征表示来训练适配器。", "result": "实验证明，不同语言模型在相同阶数的OLA上表现出显著相似性；TOA适配器能够在不更新参数的情况下泛化到未见过的语言模型，有效提升其性能。", "conclusion": "语言模型的上下文聚合模式存在跨模型的共同性，这种共同性可以作为统一的句法特征表示，实现训练免费的跨模型适配器迁移，为语言模型的理解和应用提供了新的视角。"}}
{"id": "2511.05078", "pdf": "https://arxiv.org/pdf/2511.05078", "abs": "https://arxiv.org/abs/2511.05078", "authors": ["Manan Sharma", "Arya Suneesh", "Manish Jain", "Pawan Kumar Rajpoot", "Prasanna Devadiga", "Bharatdeep Hazarika", "Ashish Shrivastava", "Kishan Gurumurthy", "Anshuman B Suresh", "Aditya U Baliga"], "title": "Reasoning-Guided Claim Normalization for Noisy Multilingual Social Media Posts", "categories": ["cs.CL"], "comment": null, "summary": "We address claim normalization for multilingual misinformation detection -\ntransforming noisy social media posts into clear, verifiable statements across\n20 languages. The key contribution demonstrates how systematic decomposition of\nposts using Who, What, Where, When, Why and How questions enables robust\ncross-lingual transfer despite training exclusively on English data. Our\nmethodology incorporates finetuning Qwen3-14B using LoRA with the provided\ndataset after intra-post deduplication, token-level recall filtering for\nsemantic alignment and retrieval-augmented few-shot learning with contextual\nexamples during inference. Our system achieves METEOR scores ranging from 41.16\n(English) to 15.21 (Marathi), securing third rank on the English leaderboard\nand fourth rank for Dutch and Punjabi. The approach shows 41.3% relative\nimprovement in METEOR over baseline configurations and substantial gains over\nexisting methods. Results demonstrate effective cross-lingual generalization\nfor Romance and Germanic languages while maintaining semantic coherence across\ndiverse linguistic structures.", "AI": {"tldr": "该论文提出了一种多语言虚假信息检测的声明规范化方法，通过系统分解社交媒体帖子为可验证的声明，在仅使用英语数据训练的情况下实现了20种语言的跨语言迁移。", "motivation": "解决多语言虚假信息检测中的声明规范化问题，将嘈杂的社交媒体帖子转化为清晰可验证的陈述，需要处理跨语言的挑战。", "method": "使用Who、What、Where、When、Why和How问题系统分解帖子；对Qwen3-14B模型进行LoRA微调；采用帖子内去重、语义对齐的token级召回过滤；推理时使用上下文示例的检索增强少样本学习。", "result": "METEOR得分从英语的41.16到马拉地语的15.21，在英语排行榜上排名第三，荷兰语和旁遮普语排名第四；相比基线配置相对提升41.3%，显著优于现有方法。", "conclusion": "该方法在罗曼语系和日耳曼语系语言上表现出有效的跨语言泛化能力，同时在不同语言结构中保持语义连贯性，证明了仅用英语训练数据实现多语言任务的可行性。"}}
{"id": "2511.05080", "pdf": "https://arxiv.org/pdf/2511.05080", "abs": "https://arxiv.org/abs/2511.05080", "authors": ["P. Bilha Githinji", "Aikaterini Meilliou", "Peiwu Qin"], "title": "On Text Simplification Metrics and General-Purpose LLMs for Accessible Health Information, and A Potential Architectural Advantage of The Instruction-Tuned LLM class", "categories": ["cs.CL"], "comment": null, "summary": "The increasing health-seeking behavior and digital consumption of biomedical\ninformation by the general public necessitate scalable solutions for\nautomatically adapting complex scientific and technical documents into plain\nlanguage. Automatic text simplification solutions, including advanced large\nlanguage models, however, continue to face challenges in reliably arbitrating\nthe tension between optimizing readability performance and ensuring\npreservation of discourse fidelity. This report empirically assesses the\nperformance of two major classes of general-purpose LLMs, demonstrating their\nlinguistic capabilities and foundational readiness for the task compared to a\nhuman benchmark. Using a comparative analysis of the instruction-tuned Mistral\n24B and the reasoning-augmented QWen2.5 32B, we identify a potential\narchitectural advantage in the instruction-tuned LLM. Mistral exhibits a\ntempered lexical simplification strategy that enhances readability across a\nsuite of metrics and the simplification-specific formula SARI (mean 42.46),\nwhile preserving human-level discourse with a BERTScore of 0.91. QWen also\nattains enhanced readability performance, but its operational strategy shows a\ndisconnect in balancing between readability and accuracy, reaching a\nstatistically significantly lower BERTScore of 0.89. Additionally, a\ncomprehensive correlation analysis of 21 metrics spanning readability,\ndiscourse fidelity, content safety, and underlying distributional measures for\nmechanistic insights, confirms strong functional redundancies among five\nreadability indices. This empirical evidence tracks baseline performance of the\nevolving LLMs for the task of text simplification, identifies the\ninstruction-tuned Mistral 24B for simplification, provides necessary heuristics\nfor metric selection, and points to lexical support as a primary\ndomain-adaptation issue for simplification.", "AI": {"tldr": "本研究评估了两种大型语言模型在文本简化任务中的表现，发现指令调优的Mistral 24B在可读性和语篇保真度平衡方面优于推理增强的QWen2.5 32B，为医疗文本简化提供了基准性能评估和指标选择启发。", "motivation": "公众健康信息寻求行为和生物医学数字消费的增长需要可扩展的解决方案，将复杂科技文档自动转换为通俗语言，但现有文本简化方案在平衡可读性与语篇保真度方面仍面临挑战。", "method": "采用对比分析方法，评估指令调优的Mistral 24B和推理增强的QWen2.5 32B两种通用LLM的性能，使用包括SARI、BERTScore等21个指标进行可读性、语篇保真度、内容安全和分布测量的全面相关性分析。", "result": "Mistral 24B展现出温和的词汇简化策略，SARI得分42.46，BERTScore达0.91，在可读性指标和语篇保真度方面均表现优异；QWen2.5 32B虽然可读性提升，但BERTScore显著较低(0.89)，在平衡可读性与准确性方面存在脱节。", "conclusion": "研究为文本简化任务提供了LLM的基准性能追踪，确定指令调优的Mistral 24B更适合简化任务，提供了指标选择的必要启发，并指出词汇支持是简化的主要领域适应问题。"}}
{"id": "2511.05085", "pdf": "https://arxiv.org/pdf/2511.05085", "abs": "https://arxiv.org/abs/2511.05085", "authors": ["Grigory Kovalev", "Mikhail Tikhomirov"], "title": "Iterative Layer-wise Distillation for Efficient Compression of Large Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This work investigates distillation methods for large language models (LLMs)\nwith the goal of developing compact models that preserve high performance.\nSeveral existing approaches are reviewed, with a discussion of their respective\nstrengths and limitations. An improved method based on the ShortGPT approach\nhas been developed, building upon the idea of incorporating iterative\nevaluation of layer importance. At each step, importance is assessed by\nmeasuring performance degradation when individual layers are removed, using a\nset of representative datasets. This process is combined with further training\nusing a joint loss function based on KL divergence and mean squared error.\nExperiments on the Qwen2.5-3B model show that the number of layers can be\nreduced from 36 to 28 (resulting in a 2.47 billion parameter model) with only a\n9.7% quality loss, and to 24 layers with an 18% loss. The findings suggest that\nthe middle transformer layers contribute less to inference, underscoring the\npotential of the proposed method for creating efficient models. The results\ndemonstrate the effectiveness of iterative distillation and fine-tuning, making\nthe approach suitable for deployment in resource-limited settings.", "AI": {"tldr": "提出基于ShortGPT的改进蒸馏方法，通过迭代评估层重要性来压缩大语言模型，Qwen2.5-3B从36层压缩到28层仅损失9.7%性能，24层损失18%", "motivation": "开发紧凑的大语言模型以保持高性能，解决资源受限环境下的部署需求", "method": "基于ShortGPT方法改进，通过迭代评估层重要性（移除单层后性能退化评估），结合KL散度和均方误差的联合损失函数进行训练", "result": "Qwen2.5-3B模型从36层压缩到28层（24.7亿参数），质量损失仅9.7%；压缩到24层损失18%", "conclusion": "中间transformer层对推理贡献较小，迭代蒸馏和微调方法有效，适合资源受限环境部署"}}
{"id": "2511.05120", "pdf": "https://arxiv.org/pdf/2511.05120", "abs": "https://arxiv.org/abs/2511.05120", "authors": ["Daniel Grießhaber", "Maximilian Kimmich", "Johannes Maucher", "Ngoc Thang Vu"], "title": "A Toolbox for Improving Evolutionary Prompt Search", "categories": ["cs.CL"], "comment": null, "summary": "Evolutionary prompt optimization has demonstrated effectiveness in refining\nprompts for LLMs. However, existing approaches lack robust operators and\nefficient evaluation mechanisms. In this work, we propose several key\nimprovements to evolutionary prompt optimization that can partially generalize\nto prompt optimization in general: 1) decomposing evolution into distinct steps\nto enhance the evolution and its control, 2) introducing an LLM-based judge to\nverify the evolutions, 3) integrating human feedback to refine the evolutionary\noperator, and 4) developing more efficient evaluation strategies that maintain\nperformance while reducing computational overhead. Our approach improves both\noptimization quality and efficiency. We release our code, enabling prompt\noptimization on new tasks and facilitating further research in this area.", "AI": {"tldr": "该论文提出了进化提示优化的四项关键改进：分解进化步骤、引入LLM裁判验证、整合人类反馈优化算子、开发高效评估策略，在提升优化质量的同时降低计算开销。", "motivation": "现有进化提示优化方法缺乏鲁棒的算子和高效的评估机制，需要改进以提升优化效果和效率。", "method": "1) 将进化过程分解为不同步骤以增强控制；2) 引入基于LLM的裁判验证进化结果；3) 整合人类反馈来精炼进化算子；4) 开发更高效的评估策略减少计算开销。", "result": "提出的方法同时提升了优化质量和效率，能够在新任务上进行提示优化。", "conclusion": "该研究为进化提示优化提供了有效的改进方案，通过代码开源促进了该领域的进一步研究和发展。"}}
{"id": "2511.05135", "pdf": "https://arxiv.org/pdf/2511.05135", "abs": "https://arxiv.org/abs/2511.05135", "authors": ["Robin Armingaud", "Romaric Besançon"], "title": "ManufactuBERT: Efficient Continual Pretraining for Manufacturing", "categories": ["cs.CL"], "comment": "Submitted to LREC 2026", "summary": "While large general-purpose Transformer-based encoders excel at general\nlanguage understanding, their performance diminishes in specialized domains\nlike manufacturing due to a lack of exposure to domain-specific terminology and\nsemantics. In this paper, we address this gap by introducing ManufactuBERT, a\nRoBERTa model continually pretrained on a large-scale corpus curated for the\nmanufacturing domain. We present a comprehensive data processing pipeline to\ncreate this corpus from web data, involving an initial domain-specific\nfiltering step followed by a multi-stage deduplication process that removes\nredundancies. Our experiments show that ManufactuBERT establishes a new\nstate-of-the-art on a range of manufacturing-related NLP tasks, outperforming\nstrong specialized baselines. More importantly, we demonstrate that training on\nour carefully deduplicated corpus significantly accelerates convergence,\nleading to a 33\\% reduction in training time and computational cost compared to\ntraining on the non-deduplicated dataset. The proposed pipeline offers a\nreproducible example for developing high-performing encoders in other\nspecialized domains. We will release our model and curated corpus at\nhttps://huggingface.co/cea-list-ia.", "AI": {"tldr": "提出了ManufactuBERT，一个针对制造业领域持续预训练的RoBERTa模型，通过专门的数据处理流程构建大规模制造业语料库，在多个制造业NLP任务上达到最佳性能，并显著减少训练时间和计算成本。", "motivation": "通用Transformer编码器在制造业等专业领域表现不佳，因为缺乏对领域特定术语和语义的接触。", "method": "开发了全面的数据处理流程：先进行领域特定过滤，然后通过多阶段去重过程构建制造业语料库，并基于此对RoBERTa模型进行持续预训练。", "result": "ManufactuBERT在制造业相关NLP任务上建立了新的最先进性能，相比未去重数据集，训练时间减少33%，计算成本显著降低。", "conclusion": "该研究为其他专业领域开发高性能编码器提供了可复制的范例，证明了精心去重的语料库对模型训练效率和性能的重要性。"}}
{"id": "2511.05162", "pdf": "https://arxiv.org/pdf/2511.05162", "abs": "https://arxiv.org/abs/2511.05162", "authors": ["Jan-Thorsten Peter", "David Vilar", "Tobias Domhan", "Dan Malkin", "Markus Freitag"], "title": "Mind the Gap... or Not? How Translation Errors and Evaluation Details Skew Multilingual Results", "categories": ["cs.CL"], "comment": null, "summary": "Most current large language models (LLMs) support a wide variety of languages\nin addition to English, including high-resource languages (e.g. German,\nChinese, French), as well as low-resource ones (e.g. Swahili, Telugu). In\naddition they have also shown impressive capabilities in different domains,\nlike coding, science and math. In this short paper, taking math as an example\ndomain, we study the performance of different LLMs across languages.\nExperimental results show that there exists a non-negligible and consistent gap\nin the performance of the models across languages. Interestingly, and somewhat\nagainst expectations, the gap exists for both high- and low-resource languages.\nWe hope that these results influence further research into cross-lingual\ncapability generalization for next generation LLMs. If it weren't for the fact\nthat they are false! By analyzing one of the standard multilingual math\nbenchmarks (MGSM), we determine that several translation errors are present in\nthe data. Furthermore, the lack of standardized answer extraction from LLM\noutputs further influences the final results. We propose a method for automatic\nquality assurance to address the first issue at scale, and give recommendations\nto address the second one. Combining these two approaches we show that the\naforementioned language gap mostly disappears, leading to completely different\nconclusions from our research. We additionally release the corrected dataset to\nthe community.", "AI": {"tldr": "论文发现多语言数学基准MGSM存在翻译错误和答案提取标准问题，导致LLMs在不同语言间性能差异的假象。通过自动质量保证方法修正后，语言间的性能差距基本消失。", "motivation": "研究当前大型语言模型在多语言数学能力上的表现差异，特别是高资源和低资源语言之间的性能差距。", "method": "分析标准多语言数学基准MGSM，发现数据中的翻译错误；提出自动质量保证方法修正数据，并改进LLM输出的答案提取标准化。", "result": "原始分析显示存在显著的语言间性能差距，但修正数据和方法后，这种差距基本消失，得出了与初始研究完全不同的结论。", "conclusion": "多语言基准数据的质量和答案提取标准化对评估LLM性能至关重要，当前观察到的语言能力差异可能源于数据质量问题而非模型能力差异。"}}
{"id": "2511.05184", "pdf": "https://arxiv.org/pdf/2511.05184", "abs": "https://arxiv.org/abs/2511.05184", "authors": ["Cong-Thanh Do", "Rama Doddipatla", "Kate Knill"], "title": "Effectiveness of Chain-of-Thought in Distilling Reasoning Capability from Large Language Models", "categories": ["cs.CL"], "comment": "In proceedings of the 18th International Natural Language Generation\n  Conference (INLG 2025)", "summary": "Chain-of-Thought (CoT) prompting is a widely used method to improve the\nreasoning capability of Large Language Models (LLMs). More recently, CoT has\nbeen leveraged in Knowledge Distillation (KD) to transfer reasoning capability\nfrom a larger LLM to a smaller one. This paper examines the role of CoT in\ndistilling the reasoning capability from larger LLMs to smaller LLMs using\nwhite-box KD, analysing its effectiveness in improving the performance of the\ndistilled models for various natural language reasoning and understanding\ntasks. We conduct white-box KD experiments using LLMs from the Qwen and Llama2\nfamilies, employing CoT data from the CoT-Collection dataset. The distilled\nmodels are then evaluated on natural language reasoning and understanding tasks\nfrom the BIG-Bench-Hard (BBH) benchmark, which presents complex challenges for\nsmaller LLMs. Experimental results demonstrate the role of CoT in improving\nwhite-box KD effectiveness, enabling the distilled models to achieve better\naverage performance in natural language reasoning and understanding tasks from\nBBH.", "AI": {"tldr": "本文研究思维链(CoT)提示法在白盒知识蒸馏(KD)中的作用，通过从大语言模型向小语言模型蒸馏推理能力，在BBH基准测试中提升了小模型的自然语言推理和理解任务表现。", "motivation": "探索如何利用CoT提示法来改进知识蒸馏过程，将大型语言模型的推理能力有效转移到小型语言模型中，解决小模型在复杂推理任务上的性能瓶颈。", "method": "使用Qwen和Llama2系列的大语言模型，基于CoT-Collection数据集的思维链数据，进行白盒知识蒸馏实验。", "result": "实验结果表明，CoT在白盒知识蒸馏中发挥了重要作用，使蒸馏后的小模型在BIG-Bench-Hard(BBH)的自然语言推理和理解任务中获得了更好的平均性能。", "conclusion": "思维链提示法能有效提升白盒知识蒸馏的效果，为将大语言模型的复杂推理能力转移到小模型提供了有效途径，对小模型在实际应用中的性能提升具有重要意义。"}}
{"id": "2511.05239", "pdf": "https://arxiv.org/pdf/2511.05239", "abs": "https://arxiv.org/abs/2511.05239", "authors": ["Zilong Li", "Jie Cao"], "title": "Translation via Annotation: A Computational Study of Translating Classical Chinese into Japanese", "categories": ["cs.CL"], "comment": null, "summary": "Ancient people translated classical Chinese into Japanese by annotating\naround each character. We abstract this process as sequence tagging tasks and\nfit them into modern language technologies. The research of this annotation and\ntranslation system is a facing low-resource problem. We release this problem by\nintroducing a LLM-based annotation pipeline and construct a new dataset from\ndigitalized open-source translation data. We show that under the low-resource\nsetting, introducing auxiliary Chinese NLP tasks has a promoting effect on the\ntraining of sequence tagging tasks. We also evaluate the performance of large\nlanguage models. They achieve high scores in direct machine translation, but\nthey are confused when being asked to annotate characters. Our method could\nwork as a supplement of LLMs.", "AI": {"tldr": "将古汉语翻译为日语的传统字符标注过程抽象为序列标注任务，通过LLM标注流水线和数字化翻译数据构建新数据集，解决低资源问题。辅助中文NLP任务对序列标注训练有促进作用，LLM在直接机器翻译表现良好但在字符标注方面存在困难。", "motivation": "研究古汉语到日语的翻译标注系统面临低资源问题，需要将传统字符标注过程适配现代语言技术。", "method": "引入基于LLM的标注流水线，从数字化开源翻译数据构建新数据集，并探索辅助中文NLP任务对序列标注训练的促进作用。", "result": "在低资源设置下，引入辅助中文NLP任务能促进序列标注训练。LLM在直接机器翻译中表现优异，但在字符标注任务上表现不佳。", "conclusion": "提出的方法可以作为LLM的补充方案，有效解决古汉语翻译标注的低资源问题，结合传统标注与现代语言技术的优势。"}}
{"id": "2511.05286", "pdf": "https://arxiv.org/pdf/2511.05286", "abs": "https://arxiv.org/abs/2511.05286", "authors": ["Teqi Hao", "Xioayu Tan", "Shaojie Shi", "Yinghui Xu", "Xihe Qiu"], "title": "Reflective Personalization Optimization: A Post-hoc Rewriting Framework for Black-Box Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "The personalization of black-box large language models (LLMs) is a critical\nyet challenging task. Existing approaches predominantly rely on context\ninjection, where user history is embedded into the prompt to directly guide the\ngeneration process. However, this single-step paradigm imposes a dual burden on\nthe model: generating accurate content while simultaneously aligning with\nuser-specific styles. This often results in a trade-off that compromises output\nquality and limits precise control. To address this fundamental tension, we\npropose Reflective Personalization Optimization (RPO), a novel framework that\nredefines the personalization paradigm by decoupling content generation from\nalignment. RPO operates in two distinct stages: first, a base model generates a\nhigh-quality, generic response; then, an external reflection module explicitly\nrewrites this output to align with the user's preferences. This reflection\nmodule is trained using a two-stage process. Initially, supervised fine-tuning\nis employed on structured rewriting trajectories to establish a core\npersonalized reasoning policy that models the transformation from generic to\nuser-aligned responses. Subsequently, reinforcement learning is applied to\nfurther refine and enhance the quality of the personalized outputs.\nComprehensive experiments on the LaMP benchmark demonstrate that RPO, by\ndecoupling content generation from personalization, significantly outperforms\nstate-of-the-art baselines. These findings underscore the superiority of\nexplicit response shaping over implicit context injection. Moreover, RPO\nintroduces an efficient, model-agnostic personalization layer that can be\nseamlessly integrated with any underlying base model, paving the way for a new\nand effective direction in user-centric generation scenarios.", "AI": {"tldr": "RPO框架通过两阶段方法解耦内容生成与个性化对齐，使用反射模块重写通用响应以匹配用户偏好，显著优于现有方法。", "motivation": "现有的上下文注入方法让LLM同时承担内容生成和个性化对齐的双重负担，导致输出质量与精准控制之间的权衡问题。", "method": "提出RPO框架：第一阶段由基础模型生成通用响应，第二阶段通过外部反射模块进行显式重写。反射模块采用监督微调和强化学习两阶段训练。", "result": "在LaMP基准测试中，RPO显著优于最先进的基线方法，证明了显式响应塑造优于隐式上下文注入。", "conclusion": "RPO提供了一种高效、模型无关的个性化层，可与任何基础模型无缝集成，为用户中心生成场景开辟了新方向。"}}
{"id": "2511.05310", "pdf": "https://arxiv.org/pdf/2511.05310", "abs": "https://arxiv.org/abs/2511.05310", "authors": ["Shreya Gupta", "Ojasva Saxena", "Arghodeep Nandi", "Sarah Masud", "Kiran Garimella", "Tanmoy Chakraborty"], "title": "Listening Between the Lines: Decoding Podcast Narratives with Language Modeling", "categories": ["cs.CL", "cs.SI"], "comment": "10 pages, 6 Figures, 5 Tables. Under review at IEEE TCSS", "summary": "Podcasts have become a central arena for shaping public opinion, making them\na vital source for understanding contemporary discourse. Their typically\nunscripted, multi-themed, and conversational style offers a rich but complex\nform of data. To analyze how podcasts persuade and inform, we must examine\ntheir narrative structures -- specifically, the narrative frames they employ.\n  The fluid and conversational nature of podcasts presents a significant\nchallenge for automated analysis. We show that existing large language models,\ntypically trained on more structured text such as news articles, struggle to\ncapture the subtle cues that human listeners rely on to identify narrative\nframes. As a result, current approaches fall short of accurately analyzing\npodcast narratives at scale.\n  To solve this, we develop and evaluate a fine-tuned BERT model that\nexplicitly links narrative frames to specific entities mentioned in the\nconversation, effectively grounding the abstract frame in concrete details. Our\napproach then uses these granular frame labels and correlates them with\nhigh-level topics to reveal broader discourse trends. The primary contributions\nof this paper are: (i) a novel frame-labeling methodology that more closely\naligns with human judgment for messy, conversational data, and (ii) a new\nanalysis that uncovers the systematic relationship between what is being\ndiscussed (the topic) and how it is being presented (the frame), offering a\nmore robust framework for studying influence in digital media.", "AI": {"tldr": "本文开发了一种针对播客内容分析的微调BERT模型，通过将叙事框架与具体实体关联来改进对非结构化对话数据的叙事框架识别，解决了现有大语言模型在处理播客数据时的局限性。", "motivation": "播客作为重要的舆论塑造平台，其非脚本化、多主题和对话式的特点使得自动化分析面临挑战。现有大语言模型难以捕捉人类听众依赖的细微线索来识别叙事框架。", "method": "开发并评估了一个微调BERT模型，将叙事框架明确链接到对话中提到的具体实体，使抽象框架在具体细节中落地。使用细粒度框架标签并将其与高层主题相关联。", "result": "提出了新的框架标注方法，更接近人类对混乱对话数据的判断；揭示了讨论内容（主题）与呈现方式（框架）之间的系统关系。", "conclusion": "该方法为研究数字媒体影响力提供了更强大的分析框架，能够更准确地大规模分析播客叙事结构。"}}
{"id": "2511.05324", "pdf": "https://arxiv.org/pdf/2511.05324", "abs": "https://arxiv.org/abs/2511.05324", "authors": ["Firoj Ahmmed Patwary", "Abdullah Al Noman"], "title": "Evaluating Subword Tokenization Techniques for Bengali: A Benchmark Study with BengaliBPE", "categories": ["cs.CL"], "comment": "10 pages, 3 figures, 3 tables", "summary": "Tokenization is an important first step in Natural Language Processing (NLP)\npipelines because it decides how models learn and represent linguistic\ninformation. However, current subword tokenizers like SentencePiece or\nHuggingFace BPE are mostly designed for Latin or multilingual corpora and do\nnot perform well on languages with rich morphology such as Bengali. To address\nthis limitation, we present BengaliBPE, a Byte Pair Encoding (BPE) tokenizer\nspecifically developed for the Bengali script. BengaliBPE applies Unicode\nnormalization, grapheme-level initialization, and morphology-aware merge rules\nto maintain linguistic consistency and preserve subword integrity. We use a\nlarge-scale Bengali news classification dataset to compare BengaliBPE with\nthree baselines: Whitespace, SentencePiece BPE, and HuggingFace BPE. The\nevaluation considers tokenization granularity, encoding speed, and downstream\nclassification accuracy. While all methods perform reasonably well, BengaliBPE\nprovides the most detailed segmentation and the best morphological\ninterpretability, albeit with slightly higher computational cost. These\nfindings highlight the importance of language-aware tokenization for\nmorphologically rich scripts and establish BengaliBPE as a strong foundation\nfor future Bengali NLP systems, including large-scale pretraining of contextual\nlanguage models.", "AI": {"tldr": "BengaliBPE：针对孟加拉语形态丰富特点专门开发的BPE分词器，通过Unicode标准化、字素级初始化和形态感知合并规则，在保持语言一致性和子词完整性方面优于现有通用分词器。", "motivation": "现有分词器（如SentencePiece、HuggingFace BPE）主要针对拉丁语系或多语言语料设计，在处理孟加拉语等形态丰富的语言时表现不佳，需要专门的语言感知分词方案。", "method": "开发BengaliBPE分词器，采用Unicode标准化、字素级初始化和形态感知合并规则。使用大规模孟加拉语新闻分类数据集，与Whitespace、SentencePiece BPE和HuggingFace BPE三种基线方法进行比较评估。", "result": "所有方法表现良好，但BengaliBPE提供最细粒度的分词和最佳的形态可解释性，尽管计算成本略高。在分词粒度、编码速度和下游分类准确性方面进行了全面评估。", "conclusion": "研究强调了语言感知分词对形态丰富语言的重要性，BengaliBPE为未来孟加拉语NLP系统（包括大规模上下文语言模型预训练）奠定了坚实基础。"}}
{"id": "2511.05406", "pdf": "https://arxiv.org/pdf/2511.05406", "abs": "https://arxiv.org/abs/2511.05406", "authors": ["Tiago Dinis", "Miguel Correia", "Roger Tavares"], "title": "Large Language Models for Explainable Threat Intelligence", "categories": ["cs.CL"], "comment": null, "summary": "As cyber threats continue to grow in complexity, traditional security\nmechanisms struggle to keep up. Large language models (LLMs) offer significant\npotential in cybersecurity due to their advanced capabilities in text\nprocessing and generation. This paper explores the use of LLMs with\nretrieval-augmented generation (RAG) to obtain threat intelligence by combining\nreal-time information retrieval with domain-specific data. The proposed system,\nRAGRecon, uses a LLM with RAG to answer questions about cybersecurity threats.\nMoreover, it makes this form of Artificial Intelligence (AI) explainable by\ngenerating and visually presenting to the user a knowledge graph for every\nreply. This increases the transparency and interpretability of the reasoning of\nthe model, allowing analysts to better understand the connections made by the\nsystem based on the context recovered by the RAG system. We evaluated RAGRecon\nexperimentally with two datasets and seven different LLMs and the responses\nmatched the reference responses more than 91% of the time for the best\ncombinations.", "AI": {"tldr": "提出RAGRecon系统，结合LLM和检索增强生成技术来获取网络安全威胁情报，并通过知识图谱可视化提高AI的可解释性，在实验中达到91%以上的匹配准确率。", "motivation": "传统安全机制难以应对日益复杂的网络威胁，大型语言模型在文本处理和生成方面的先进能力为网络安全提供了新的可能性。", "method": "使用检索增强生成(RAG)技术，结合实时信息检索和领域特定数据，构建RAGRecon系统，通过LLM回答网络安全威胁问题并生成可视化知识图谱。", "result": "在两种数据集和七种不同LLM的实验评估中，最佳组合的响应与参考响应的匹配率超过91%。", "conclusion": "RAGRecon系统成功地将LLM与RAG技术结合，不仅提高了威胁情报获取的准确性，还通过知识图谱可视化增强了AI系统的透明度和可解释性，有助于安全分析师更好地理解系统推理过程。"}}
{"id": "2511.05407", "pdf": "https://arxiv.org/pdf/2511.05407", "abs": "https://arxiv.org/abs/2511.05407", "authors": ["Yahui Fu", "Zi Haur Pang", "Tatsuya Kawahara"], "title": "Minority-Aware Satisfaction Estimation in Dialogue Systems via Preference-Adaptive Reinforcement Learning", "categories": ["cs.CL"], "comment": "IJCNLP-AACL 2025 (Main)", "summary": "User satisfaction in dialogue systems is inherently subjective. When the same\nresponse strategy is applied across users, minority users may assign different\nsatisfaction ratings than majority users due to variations in individual\nintents and preferences. However, existing alignment methods typically train\none-size-fits-all models that aim for broad consensus, often overlooking\nminority perspectives and user-specific adaptation. We propose a unified\nframework that models both individual- and group-level preferences for user\nsatisfaction estimation. First, we introduce Chain-of-Personalized-Reasoning\n(CoPeR) to capture individual preferences through interpretable reasoning\nchains. Second, we propose an expectation-maximization-based Majority-Minority\nPreference-Aware Clustering (M2PC) algorithm that discovers distinct user\ngroups in an unsupervised manner to learn group-level preferences. Finally, we\nintegrate these components into a preference-adaptive reinforcement learning\nframework (PAda-PPO) that jointly optimizes alignment with both individual and\ngroup preferences. Experiments on the Emotional Support Conversation dataset\ndemonstrate consistent improvements in user satisfaction estimation,\nparticularly for underrepresented user groups.", "AI": {"tldr": "提出了一个统一框架来建模个体和群体级别的用户满意度偏好，通过个性化推理链和聚类算法来改善对话系统中少数用户群体的满意度评估", "motivation": "现有对话系统对齐方法通常训练一刀切的模型追求广泛共识，往往忽视少数用户视角和个性化适配，导致少数用户满意度评估存在偏差", "method": "1. Chain-of-Personalized-Reasoning (CoPeR) 捕捉个体偏好；2. 基于期望最大化的多数-少数偏好感知聚类算法 (M2PC) 无监督发现用户群体；3. 偏好自适应强化学习框架 (PAda-PPO) 联合优化个体和群体偏好对齐", "result": "在情感支持对话数据集上的实验显示，用户满意度评估得到持续改进，特别是对代表性不足的用户群体", "conclusion": "该框架通过同时考虑个体和群体偏好，有效提升了对话系统中用户满意度评估的准确性和公平性，特别是对少数群体的关注显著改善了系统性能"}}
{"id": "2511.05408", "pdf": "https://arxiv.org/pdf/2511.05408", "abs": "https://arxiv.org/abs/2511.05408", "authors": ["Constanza Fierro", "Fabien Roger"], "title": "Steering Language Models with Weight Arithmetic", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Providing high-quality feedback to Large Language Models (LLMs) on a diverse\ntraining distribution can be difficult and expensive, and providing feedback\nonly on a narrow distribution can result in unintended generalizations. To\nbetter leverage narrow training data, we propose contrastive weight steering, a\nsimple post-training method that edits the model parameters using weight\narithmetic. We isolate a behavior direction in weight-space by subtracting the\nweight deltas from two small fine-tunes -- one that induces the desired\nbehavior and another that induces its opposite -- and then add or remove this\ndirection to modify the model's weights. We apply this technique to mitigate\nsycophancy and induce misalignment, and find that weight steering often\ngeneralizes further than activation steering, achieving stronger\nout-of-distribution behavioral control before degrading general capabilities.\nWe also show that, in the context of task-specific fine-tuning, weight steering\ncan partially mitigate undesired behavioral drift: it can reduce sycophancy and\nunder-refusals introduced during fine-tuning while preserving task performance\ngains. Finally, we provide preliminary evidence that emergent misalignment can\nbe detected by measuring the similarity between fine-tuning updates and an\n\"evil\" weight direction, suggesting that it may be possible to monitor the\nevolution of weights during training and detect rare misaligned behaviors that\nnever manifest during training or evaluations.", "AI": {"tldr": "提出了一种称为对比权重导向的简单后训练方法，通过权重算术编辑模型参数，利用窄分布数据实现更好的行为控制泛化，并能在微调中减少不良行为漂移同时保持任务性能。", "motivation": "在多样化训练分布上为大型语言模型提供高质量反馈既困难又昂贵，而仅在窄分布上提供反馈可能导致意外的泛化问题。需要找到更好的方法来利用窄训练数据。", "method": "通过从两个小型微调中提取权重增量（一个诱导期望行为，另一个诱导相反行为），在权重空间中隔离行为方向，然后通过加减该方向来修改模型权重。", "result": "权重导向比激活导向具有更好的泛化能力，在降低通用能力之前实现更强的分布外行为控制；能减少微调引入的奉承和拒绝不足问题同时保持任务性能增益；初步证据表明可通过测量微调更新与\"邪恶\"权重方向的相似性来检测新兴错位。", "conclusion": "对比权重导向是一种有效的后训练方法，能够更好地利用窄训练数据实现行为控制，并提供了监测训练过程中权重演化和检测罕见错位行为的可能性。"}}
{"id": "2511.05485", "pdf": "https://arxiv.org/pdf/2511.05485", "abs": "https://arxiv.org/abs/2511.05485", "authors": ["Yuexin Wu", "Shiqi Wang", "Vasile Rus"], "title": "MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis", "categories": ["cs.CL", "I.2.7; I.5.1"], "comment": "19", "summary": "Disease diagnosis is a central pillar of modern healthcare, enabling early\ndetection and timely intervention for acute conditions while guiding lifestyle\nadjustments and medication regimens to prevent or slow chronic disease.\nSelf-reports preserve clinically salient signals that templated electronic\nhealth record (EHR) documentation often attenuates or omits, especially subtle\nbut consequential details. To operationalize this shift, we introduce\nMIMIC-SR-ICD11, a large English diagnostic dataset built from EHR discharge\nnotes and natively aligned to WHO ICD-11 terminology. We further present\nLL-Rank, a likelihood-based re-ranking framework that computes a\nlength-normalized joint likelihood of each label given the clinical report\ncontext and subtracts the corresponding report-free prior likelihood for that\nlabel. Across seven model backbones, LL-Rank consistently outperforms a strong\ngeneration-plus-mapping baseline (GenMap). Ablation experiments show that\nLL-Rank's gains primarily stem from its PMI-based scoring, which isolates\nsemantic compatibility from label frequency bias.", "AI": {"tldr": "论文提出了MIMIC-SR-ICD11数据集和LL-Rank框架，通过基于似然的重排序方法提升临床诊断标签的准确性，相比基线方法有显著提升。", "motivation": "电子健康记录(EHR)中模板化文档往往会减弱或遗漏临床重要信号，特别是细微但关键的细节。需要一种更好的方法来从临床报告中提取准确的诊断信息。", "method": "构建MIMIC-SR-ICD11数据集，并开发LL-Rank框架——基于似然的重排序方法，计算给定临床报告上下文中每个标签的长度归一化联合似然，并减去相应的无报告先验似然。", "result": "在七个模型骨干网络上，LL-Rank始终优于强基线方法GenMap。消融实验显示LL-Rank的提升主要来自于其基于PMI的评分，能够将语义兼容性与标签频率偏差分离开来。", "conclusion": "LL-Rank框架通过基于互信息的评分机制有效提升了临床诊断标签的准确性，为从自由文本临床报告中提取结构化诊断信息提供了有效解决方案。"}}
