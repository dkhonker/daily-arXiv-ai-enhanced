<div id=toc></div>

# 目录

- [cs.LG](#cs.LG) [总数: 139]
- [cs.AI](#cs.AI) [总数: 43]
- [stat.ML](#stat.ML) [总数: 10]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [FMEnets: Flow, Material, and Energy networks for non-ideal plug flow reactor design](https://arxiv.org/abs/2505.20300)
*Chenxi Wu, Juan Diego Toscano, Khemraj Shukla, Yingjie Chen, Ali Shahmohammadi, Edward Raymond, Thomas Toupy, Neda Nazemifard, Charles Papageorgiou, George Em Karniadakis*

**主要类别:** cs.LG

**概要:** 提出了一种名为FMEnets的物理信息机器学习框架，用于非理想活塞流反应器的设计和分析。该框架由三个相互连接的子网络组成，能够进行正问题和逆问题求解。FMEnets在三种不同的反应场景中进行了测试，并与有限元模拟进行了比较，相对误差小于2.5%。FME-KANs比FME-PINNs对噪声更鲁棒。


<details>
  <summary>更多</summary>
  
**动机:** 当前非理想活塞流反应器的设计和分析需要复杂的物理方程求解，传统数值方法计算成本高且难以处理实验数据中的噪声。因此，需要一种新的、高效的框架来整合物理规律和实验数据，从而指导反应器设计。

**方法:** FMEnets将Navier-Stokes方程、物质平衡方程和能量平衡方程集成到一个多尺度网络模型中。它由三个具有独立优化器的子网络组成，可以进行正问题（预测速度、压力、物种浓度和温度分布）和逆问题（推断未知动力学参数和状态）求解。FMEnets有两种实现方式：基于多层感知机的FME-PINNs和基于Kolmogorov-Arnold Networks的FME-KANs。

**结果:** FMEnets在三种不同反应场景中表现良好，与有限元模拟相比，相对误差小于2.5%。FME-KANs在有噪声条件下比FME-PINNs更鲁棒，但在无噪声条件下两者在准确性和速度上相当。

**结论:** FMEnets提供了一种计算效率高的反应器设计和优化替代方案，同时为整合经验相关性、有限和噪声实验数据以及基本物理方程提供了新途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FMEnets%3A+Flow%2C+Material%2C+and+Energy+networks+for+non-ideal+plug+flow+reactor+design，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20300，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20300&send_immediately=true&force_search=false)

**原文摘要:** We propose FMEnets, a physics-informed machine learning framework for the
design and analysis of non-ideal plug flow reactors. FMEnets integrates the
fundamental governing equations (Navier-Stokes for fluid flow, material balance
for reactive species transport, and energy balance for temperature
distribution) into a unified multi-scale network model. The framework is
composed of three interconnected sub-networks with independent optimizers that
enable both forward and inverse problem-solving. In the forward mode, FMEnets
predicts velocity, pressure, species concentrations, and temperature profiles
using only inlet and outlet information. In the inverse mode, FMEnets utilizes
sparse multi-residence-time measurements to simultaneously infer unknown
kinetic parameters and states. FMEnets can be implemented either as FME-PINNs,
which employ conventional multilayer perceptrons, or as FME-KANs, based on
Kolmogorov-Arnold Networks. Comprehensive ablation studies highlight the
critical role of the FMEnets architecture in achieving accurate predictions.
Specifically, FME-KANs are more robust to noise than FME-PINNs, although both
representations are comparable in accuracy and speed in noise-free conditions.
The proposed framework is applied to three different sets of reaction scenarios
and is compared with finite element simulations. FMEnets effectively captures
the complex interactions, achieving relative errors less than 2.5% for the
unknown kinetic parameters. The new network framework not only provides a
computationally efficient alternative for reactor design and optimization, but
also opens new avenues for integrating empirical correlations, limited and
noisy experimental data, and fundamental physical equations to guide reactor
design.

</details>


### [2] [Joint-stochastic-approximation Random Fields with Application to Semi-supervised Learning](https://arxiv.org/abs/2505.20330)
*Yunfu Song, Zhijian Ou*

**主要类别:** cs.LG

**概要:** 本文研究了半监督学习中使用的深度生成模型（DGMs），特别是GANs和VAEs，发现了两种问题：模式缺失与模式覆盖现象，以及在使用有向生成模型时分类效果与生成效果之间的矛盾。为了解决这些问题，提出了一种新的算法族——联合随机逼近随机场（JRFs），用于构建深度无向生成模型，并将其应用于半监督学习。实验表明，JRFs在平衡模式覆盖和模式缺失方面表现出色，能够很好地匹配经验数据分布，在MNIST、SVHN和CIFAR-10等常用数据集上取得了与当前最先进方法相当的分类结果，同时生成效果也很好。


<details>
  <summary>更多</summary>
  
**动机:** 现有的深度生成模型（如GANs和VAEs）在半监督学习中存在模式缺失和模式覆盖的问题，且难以同时实现良好的分类和生成效果。因此需要一种新的方法来解决这些问题。

**方法:** 提出了联合随机逼近随机场（JRFs），这是一种用于构建深度无向生成模型的新算法族。该方法旨在解决GANs和VAEs中存在的模式缺失与模式覆盖问题，以及在半监督学习中分类与生成之间的冲突。

**结果:** 通过合成实验验证，JRFs能够在模式覆盖和模式缺失之间取得良好平衡，并能很好地匹配经验数据分布。在MNIST、SVHN和CIFAR-10等数据集上的实证结果表明，JRFs在半监督学习任务中达到了与现有最先进方法相当的分类效果，同时生成性能也较好。

**结论:** JRFs是一种有效的解决方案，可以解决现有深度生成模型在半监督学习中的不足之处，同时实现了良好的分类和生成效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Joint-stochastic-approximation+Random+Fields+with+Application+to+Semi-supervised+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20330，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20330&send_immediately=true&force_search=false)

**原文摘要:** Our examination of deep generative models (DGMs) developed for
semi-supervised learning (SSL), mainly GANs and VAEs, reveals two problems.
First, mode missing and mode covering phenomenons are observed in genertion
with GANs and VAEs. Second, there exists an awkward conflict between good
classification and good generation in SSL by employing directed generative
models. To address these problems, we formally present
joint-stochastic-approximation random fields (JRFs) -- a new family of
algorithms for building deep undirected generative models, with application to
SSL. It is found through synthetic experiments that JRFs work well in balancing
mode covering and mode missing, and match the empirical data distribution well.
Empirically, JRFs achieve good classification results comparable to the
state-of-art methods on widely adopted datasets -- MNIST, SVHN, and CIFAR-10 in
SSL, and simultaneously perform good generation.

</details>


### [3] [PDFBench: A Benchmark for De novo Protein Design from Function](https://arxiv.org/abs/2505.20346)
*Jiahao Kuang, Nuowei Liu, Changzhi Sun, Tao Ji, Yuanbin Wu*

**主要类别:** cs.LG

**概要:** 提出PDFBench，一个全面评估从功能出发的de novo蛋白设计的基准，包含描述和关键词引导的设计任务，22个评估指标以及对现有方法的分析。


<details>
  <summary>更多</summary>
  
**动机:** 当前de novo蛋白设计方法依赖专有数据集和评估标准，缺乏公平比较和全面评估框架。

**方法:** 创建PDFBench基准，支持两种设计任务（描述和关键词引导），采用22个指标覆盖序列合理性、结构保真度、语言-蛋白对齐、新颖性和多样性，并分析不同类别指标之间的相关性。

**结果:** 评估了五个最先进的基线模型，揭示其优缺点，并提供了指标选择的指导。

**结论:** PDFBench提供了一个统一框架，推动基于功能的de novo蛋白设计领域的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PDFBench%3A+A+Benchmark+for+De+novo+Protein+Design+from+Function，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20346，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20346&send_immediately=true&force_search=false)

**原文摘要:** In recent years, while natural language processing and multimodal learning
have seen rapid advancements, the field of de novo protein design has also
experienced significant growth. However, most current methods rely on
proprietary datasets and evaluation rubrics, making fair comparisons between
different approaches challenging. Moreover, these methods often employ
evaluation metrics that capture only a subset of the desired properties of
designed proteins, lacking a comprehensive assessment framework. To address
these, we introduce PDFBench, the first comprehensive benchmark for evaluating
de novo protein design from function. PDFBench supports two tasks:
description-guided design and keyword-guided design. To ensure fair and
multifaceted evaluation, we compile 22 metrics covering sequence plausibility,
structural fidelity, and language-protein alignment, along with measures of
novelty and diversity. We evaluate five state-of-the-art baselines, revealing
their respective strengths and weaknesses across tasks. Finally, we analyze
inter-metric correlations, exploring the relationships between four categories
of metrics, and offering guidelines for metric selection. PDFBench establishes
a unified framework to drive future advances in function-driven de novo protein
design.

</details>


### [4] [Decision Flow Policy Optimization](https://arxiv.org/abs/2505.20350)
*Jifeng Hu, Sili Huang, Siyuan Guo, Zhaogeng Liu, Li Shen, Lichao Sun, Hechang Chen, Yi Chang, Dacheng Tao*

**主要类别:** cs.LG

**概要:** 近年来，生成模型在图像、视频、语言和决策等各个领域展现出卓越的能力。通过将强大的生成模型（如基于流的模型）应用于强化学习，我们可以有效地对复杂的多模态动作分布进行建模，并在连续动作空间中实现优越的机器人控制，超越了传统基于高斯策略的单模态动作分布的限制。然而，以前的方法通常采用生成模型作为行为模型来拟合数据集中的状态条件动作分布，并通过额外的策略进行独立的策略优化，这阻碍了模型的训练并降低了性能。为了解决这个问题，我们提出了Decision Flow，一个统一的框架，将多模态动作分布建模和策略优化集成在一起。我们的方法将基于流的模型的动作生成过程公式化为一个流决策过程，其中每个动作生成步骤对应一个流决策。因此，我们的方法在捕捉多模态动作分布的同时无缝优化流策略。我们提供了Decision Flow的严格证明，并通过在数十个离线RL环境中的广泛实验验证了其有效性。与已建立的离线RL基线相比，结果表明我们的方法达到或匹配了最先进的性能。


<details>
  <summary>更多</summary>
  
**动机:** 传统的强化学习方法在处理复杂多模态动作分布时存在局限性，特别是在连续动作空间中。现有的生成模型虽然可以拟合多模态动作分布，但与策略优化分离，导致训练效率低下和性能下降。因此，需要一种能够同时优化多模态分布拟合和策略改进的方法。

**方法:** 提出了一种名为Decision Flow的统一框架，该框架将多模态动作分布建模和策略优化结合在一起。具体来说，将基于流的模型的动作生成过程视为一系列流决策过程，每个动作生成步骤对应一个流决策。这种方法允许同时优化流策略和多模态动作分布。

**结果:** 通过在多个离线强化学习环境中的实验，证明了Decision Flow的有效性。与现有的离线RL基线相比，该方法达到了或匹配了最先进的性能。

**结论:** Decision Flow提供了一个统一的框架，成功地将多模态动作分布建模和策略优化结合起来，解决了现有方法中两者分离的问题。实验结果表明，该方法在离线强化学习任务中表现出色，具有广泛的应用潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Decision+Flow+Policy+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20350，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20350&send_immediately=true&force_search=false)

**原文摘要:** In recent years, generative models have shown remarkable capabilities across
diverse fields, including images, videos, language, and decision-making. By
applying powerful generative models such as flow-based models to reinforcement
learning, we can effectively model complex multi-modal action distributions and
achieve superior robotic control in continuous action spaces, surpassing the
limitations of single-modal action distributions with traditional
Gaussian-based policies. Previous methods usually adopt the generative models
as behavior models to fit state-conditioned action distributions from datasets,
with policy optimization conducted separately through additional policies using
value-based sample weighting or gradient-based updates. However, this
separation prevents the simultaneous optimization of multi-modal distribution
fitting and policy improvement, ultimately hindering the training of models and
degrading the performance. To address this issue, we propose Decision Flow, a
unified framework that integrates multi-modal action distribution modeling and
policy optimization. Specifically, our method formulates the action generation
procedure of flow-based models as a flow decision-making process, where each
action generation step corresponds to one flow decision. Consequently, our
method seamlessly optimizes the flow policy while capturing multi-modal action
distributions. We provide rigorous proofs of Decision Flow and validate the
effectiveness through extensive experiments across dozens of offline RL
environments. Compared with established offline RL baselines, the results
demonstrate that our method achieves or matches the SOTA performance.

</details>


### [5] [FastCache: Fast Caching for Diffusion Transformer Through Learnable Linear Approximation](https://arxiv.org/abs/2505.20353)
*Dong Liu, Jiayi Zhang, Yifan Li, Yanxuan Yu, Ben Lengerich, Ying Nian Wu*

**主要类别:** cs.LG

**概要:** Diffusion Transformers (DiT) 是强大的生成模型，但由于其迭代结构和深度变压器堆栈，计算量仍然很大。为了解决这种低效问题，我们提出了 FastCache，这是一种隐藏状态级别的缓存和压缩框架，通过利用模型内部表示中的冗余来加速 DiT 推理。FastCache 引入了双重策略：（1）空间感知令牌选择机制，根据隐藏状态显著性自适应地过滤冗余令牌；（2）变压器级别缓存，在变化统计上不显著时跨时间步重用潜在激活。这些模块共同作用，通过可学习的线性逼近减少不必要的计算，同时保持生成保真度。理论分析表明，FastCache 在基于假设检验的决策规则下保持有界近似误差。实证评估显示，多个 DiT 变体的延迟和内存使用显著减少，与其它缓存方法相比，生成输出质量最佳（以 FID 和 t-FID 衡量）。FastCache 的代码实现可在 GitHub 上获取。


<details>
  <summary>更多</summary>
  
**动机:** Diffusion Transformers (DiT) 作为生成模型具有强大性能，但其迭代结构和深度变压器堆栈导致计算成本高，效率低下，需要一种方法来加速推理过程并降低资源消耗。

**方法:** 提出了一种名为 FastCache 的隐藏状态级别的缓存和压缩框架，包含两个核心组件：(1) 空间感知令牌选择机制，用于自适应过滤冗余令牌；(2) 变压器级别缓存，用于在统计变化不显著时跨时间步重用潜在激活。此外，还通过可学习的线性逼近来保持生成保真度。

**结果:** 理论分析证明 FastCache 在基于假设检验的决策规则下保持有界近似误差。实证评估显示，FastCache 显著减少了多个 DiT 变体的延迟和内存使用，并在生成质量（FID 和 t-FID 衡量）方面优于其他缓存方法。

**结论:** FastCache 是一种有效的缓存和压缩框架，可以加速 Diffusion Transformers 的推理过程，同时显著降低延迟和内存使用，且生成质量优秀。代码已在 GitHub 上开源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FastCache%3A+Fast+Caching+for+Diffusion+Transformer+Through+Learnable+Linear+Approximation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20353，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20353&send_immediately=true&force_search=false)

**原文摘要:** Diffusion Transformers (DiT) are powerful generative models but remain
computationally intensive due to their iterative structure and deep transformer
stacks. To alleviate this inefficiency, we propose FastCache, a
hidden-state-level caching and compression framework that accelerates DiT
inference by exploiting redundancy within the model's internal representations.
FastCache introduces a dual strategy: (1) a spatial-aware token selection
mechanism that adaptively filters redundant tokens based on hidden state
saliency, and (2) a transformer-level cache that reuses latent activations
across timesteps when changes are statistically insignificant. These modules
work jointly to reduce unnecessary computation while preserving generation
fidelity through learnable linear approximation. Theoretical analysis shows
that FastCache maintains bounded approximation error under a
hypothesis-testing-based decision rule. Empirical evaluations across multiple
DiT variants demonstrate substantial reductions in latency and memory usage,
with best generation output quality compared to other cache methods, as
measured by FID and t-FID. Code implementation of FastCache is available on
GitHub at https://github.com/NoakLiu/FastCache-xDiT.

</details>


### [6] [GraLoRA: Granular Low-Rank Adaptation for Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2505.20355)
*Yeonjoon Jung, Daehyun Ahn, Hyungjun Kim, Taesu Kim, Eunhyeok Park*

**主要类别:** cs.LG

**概要:** GraLoRA是一种改进的LoRA方法，通过将权重矩阵划分为子块并为每个子块提供独立的低秩适配器，解决了LoRA的梯度纠缠问题。这使得GraLoRA在参数高效微调中表现优于LoRA和其他基线方法，在HumanEval+上的Pass@1绝对增益高达8.5%。


<details>
  <summary>更多</summary>
  
**动机:** 尽管LoRA方法简单有效，但它存在一个根本限制：当瓶颈加宽时容易过拟合。LoRA的最佳性能出现在秩32-64之间，但随着秩增加，其精度停滞或下降，仍不及全量微调（FFT）性能。这是因为LoRA的结构瓶颈导致了梯度纠缠，扭曲了梯度传播。

**方法:** 提出了一种新的结构——颗粒化低秩适配（GraLoRA），它将权重矩阵划分为子块，每个子块都有自己的低秩适配器。这种方法几乎不增加计算或存储成本，克服了LoRA的局限性，有效地提高了表示能力，并更接近FFT行为。

**结果:** 在代码生成和常识推理基准测试中的实验表明，GraLoRA始终优于LoRA和其他基线方法，在HumanEval+上的Pass@1绝对增益高达8.5%。这些改进适用于各种模型大小和秩设置，证明了GraLoRA的可扩展性和鲁棒性。

**结论:** GraLoRA提供了一种有效的解决方案来克服LoRA的局限性，提升了参数高效微调的性能，具有广泛的适用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GraLoRA%3A+Granular+Low-Rank+Adaptation+for+Parameter-Efficient+Fine-Tuning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20355，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20355&send_immediately=true&force_search=false)

**原文摘要:** Low-Rank Adaptation (LoRA) is a popular method for parameter-efficient
fine-tuning (PEFT) of generative models, valued for its simplicity and
effectiveness. Despite recent enhancements, LoRA still suffers from a
fundamental limitation: overfitting when the bottleneck is widened. It performs
best at ranks 32-64, yet its accuracy stagnates or declines at higher ranks,
still falling short of full fine-tuning (FFT) performance. We identify the root
cause as LoRA's structural bottleneck, which introduces gradient entanglement
to the unrelated input channels and distorts gradient propagation. To address
this, we introduce a novel structure, Granular Low-Rank Adaptation (GraLoRA)
that partitions weight matrices into sub-blocks, each with its own low-rank
adapter. With negligible computational or storage cost, GraLoRA overcomes
LoRA's limitations, effectively increases the representational capacity, and
more closely approximates FFT behavior. Experiments on code generation and
commonsense reasoning benchmarks show that GraLoRA consistently outperforms
LoRA and other baselines, achieving up to +8.5% absolute gain in Pass@1 on
HumanEval+. These improvements hold across model sizes and rank settings,
making GraLoRA a scalable and robust solution for PEFT. Code, data, and scripts
are available at https://github.com/SqueezeBits/GraLoRA.git

</details>


### [7] [Learning and Interpreting Gravitational-Wave Features from CNNs with a Random Forest Approach](https://arxiv.org/abs/2505.20357)
*Jun Tian, He Wang, Jibo He, Yu Pan, Shuo Cao, Qingquan Jiang*

**主要类别:** cs.LG

**概要:** 提出了一种结合CNN特征提取器和随机森林分类器的混合架构，通过引入可解释的物理指标（如方差、信噪比等），在固定误报率下提高了21%的敏感度，并增强了对低信噪比信号的检测能力。


<details>
  <summary>更多</summary>
  
**动机:** 尽管CNN在引力波探测中表现出色，但其学习到的特征的物理意义尚未被充分探索，限制了模型的可解释性。

**方法:** 构建了一个混合模型，将CNN与随机森林分类器结合，从CNN的最后一层计算四个物理上可解释的指标（方差、信噪比、波形重叠和峰值幅度），并与CNN输出共同用于随机森林分类器中以优化决策边界。

**结果:** 该混合模型在长时程应变数据集上的表现优于基础CNN模型，在固定每月10次事件误报率的情况下，灵敏度相对提高了21%，并且对低信噪比信号（SNR ≤ 10）的检测能力也有所提升。

**结论:** 通过随机森林模型的特征归因分析发现，CNN提取的特征和手工设计的特征都对分类决策有显著贡献，表明基于物理启发的CNN特征图后处理可以作为提高引力波探测效率和可解释性的有效工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+and+Interpreting+Gravitational-Wave+Features+from+CNNs+with+a+Random+Forest+Approach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20357，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20357&send_immediately=true&force_search=false)

**原文摘要:** Convolutional neural networks (CNNs) have become widely adopted in
gravitational wave (GW) detection pipelines due to their ability to
automatically learn hierarchical features from raw strain data. However, the
physical meaning of these learned features remains underexplored, limiting the
interpretability of such models. In this work, we propose a hybrid architecture
that combines a CNN-based feature extractor with a random forest (RF)
classifier to improve both detection performance and interpretability. Unlike
prior approaches that directly connect classifiers to CNN outputs, our method
introduces four physically interpretable metrics - variance, signal-to-noise
ratio (SNR), waveform overlap, and peak amplitude - computed from the final
convolutional layer. These are jointly used with the CNN output in the RF
classifier to enable more informed decision boundaries. Tested on long-duration
strain datasets, our hybrid model outperforms a baseline CNN model, achieving a
relative improvement of 21\% in sensitivity at a fixed false alarm rate of 10
events per month. Notably, it also shows improved detection of low-SNR signals
(SNR $\le$ 10), which are especially vulnerable to misclassification in noisy
environments. Feature attribution via the RF model reveals that both
CNN-extracted and handcrafted features contribute significantly to
classification decisions, with learned variance and CNN outputs ranked among
the most informative. These findings suggest that physically motivated
post-processing of CNN feature maps can serve as a valuable tool for
interpretable and efficient GW detection, bridging the gap between deep
learning and domain knowledge.

</details>


### [8] [Risk-aware Direct Preference Optimization under Nested Risk Measure](https://arxiv.org/abs/2505.20359)
*Lijun Zhang, Lin Li, Yajie Qi, Huizhong Song, Yaodong Yang, Jun Wang, Wei Wei*

**主要类别:** cs.LG

**概要:** 本论文提出了一种新的方法Ra-DPO，通过引入嵌套风险度量来优化预训练大语言模型的对齐性能，同时控制模型偏离的风险。实验结果表明该方法在平衡对齐性能和模型漂移方面表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 当前大多数方法通过KL散度约束训练模型与参考模型之间的偏差，但在需要严格风险控制的应用中可能不够充分。因此，需要一种新的方法能够在优化对齐性能的同时更好地控制风险。

**方法:** 提出Risk-aware Direct Preference Optimization (Ra-DPO) 方法，利用一类嵌套风险度量将风险意识纳入其中，构建受约束的风险感知优势函数最大化问题，并将Bradley-Terry模型转换为token级别表示。目标函数在最大化策略似然性的同时，使用顺序风险比率抑制训练模型与参考模型之间的偏差。

**结果:** 在IMDb Dataset、Anthropic HH Dataset和AlpacaEval三个开源数据集上的实验结果表明，所提出的方法在平衡对齐性能和模型漂移方面表现出色。

**结论:** Ra-DPO方法通过引入风险意识和顺序风险比率有效提升了模型在对齐性能和风险控制方面的表现，适用于需要严格风险控制的应用场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Risk-aware+Direct+Preference+Optimization+under+Nested+Risk+Measure，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20359，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20359&send_immediately=true&force_search=false)

**原文摘要:** When fine-tuning pre-trained Large Language Models (LLMs) to align with human
values and intentions, maximizing the estimated reward can lead to superior
performance, but it also introduces potential risks due to deviations from the
reference model's intended behavior. Most existing methods typically introduce
KL divergence to constrain deviations between the trained model and the
reference model; however, this may not be sufficient in certain applications
that require tight risk control. In this paper, we introduce Risk-aware Direct
Preference Optimization (Ra-DPO), a novel approach that incorporates
risk-awareness by employing a class of nested risk measures. This approach
formulates a constrained risk-aware advantage function maximization problem and
then converts the Bradley-Terry model into a token-level representation. The
objective function maximizes the likelihood of the policy while suppressing the
deviation between a trained model and the reference model using a sequential
risk ratio, thereby enhancing the model's risk-awareness. Experimental results
across three open-source datasets: IMDb Dataset, Anthropic HH Dataset, and
AlpacaEval, demonstrate the proposed method's superior performance in balancing
alignment performance and model drift. Our code is opensourced at
https://github.com/zlj123-max/Ra-DPO.

</details>


### [9] [One-shot Robust Federated Learning of Independent Component Analysis](https://arxiv.org/abs/2505.20532)
*Dian Jin, Xin Bing, Yuqian Zhang*

**主要类别:** cs.LG

**概要:** 本论文提出了一种基于几何中位数和k-均值聚类的鲁棒单次聚合框架，用于分布式和联邦独立成分分析（ICA）问题。该方法在高度异构环境下依然有效，并通过模拟研究验证了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 当前分布式和联邦独立成分分析（ICA）问题面临客户端估计中的排列歧义以及数据异构性带来的挑战，需要一种鲁棒的方法来解决这些问题。

**方法:** 1. 使用k-均值聚类将客户端提供的估计器划分为多个簇。
2. 在每个簇内使用几何中位数对估计器进行聚合。
3. 结合几何中位数的误差界（由样本分位数辅助）与k-均值的最大错误聚类率进行理论分析。

**结果:** 该方法在最多一半客户端只能观察到少量样本的高度异构场景下依然保持有效。模拟研究表明，该方法在各种异构设置下表现良好。

**结论:** 提出的基于几何中位数和k-均值聚类的聚合算法为分布式和联邦ICA问题提供了一种鲁棒解决方案，特别适用于高度异构的数据环境。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是One-shot+Robust+Federated+Learning+of+Independent+Component+Analysis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20532，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20532&send_immediately=true&force_search=false)

**原文摘要:** This paper investigates a general robust one-shot aggregation framework for
distributed and federated Independent Component Analysis (ICA) problem. We
propose a geometric median-based aggregation algorithm that leverages $k$-means
clustering to resolve the permutation ambiguity in local client estimations.
Our method first performs k-means to partition client-provided estimators into
clusters and then aggregates estimators within each cluster using the geometric
median. This approach provably remains effective even in highly heterogeneous
scenarios where at most half of the clients can observe only a minimal number
of samples. The key theoretical contribution lies in the combined analysis of
the geometric median's error bound-aided by sample quantiles-and the maximum
misclustering rates of the aforementioned solution of $k$-means. The
effectiveness of the proposed approach is further supported by simulation
studies conducted under various heterogeneous settings.

</details>


### [10] [GRAPE: Optimize Data Mixture for Group Robust Multi-target Adaptive Pretraining](https://arxiv.org/abs/2505.20380)
*Simin Fan, Maria Ios Glarou, Martin Jaggi*

**主要类别:** cs.LG

**概要:** GRAPE是一种新的多源多目标领域重加权预训练框架，通过动态调整领域和任务权重来优化多个目标任务的性能。实验表明，GRAPE在多个基准测试中优于基线方法，并在低资源语言上表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 现有的领域重加权算法主要针对单一目标任务优化数据混合，导致模型在其他基准测试上的性能显著下降。因此，需要一种能够同时优化多个目标任务性能的方法。

**方法:** 提出了一种名为GRAPE的框架，该框架通过动态调整源领域的采样权重（领域权重）和反映每个目标任务相对重要性的任务权重，适应性地优先处理基于学习难度的任务。将交错重加权机制表示为一个极小极大优化问题：内部最大化利用组分布式鲁棒优化（DRO），优先考虑在当前数据混合下改进最少的任务；外部最小化则优化领域权重以减少优先任务的损失。

**结果:** 在ClimbLab和SlimPajama数据集上的实验表明，GRAPE在6个基准测试中的推理性能始终优于基线方法。此外，在应用于多语言目标时，GRAPE能有效识别主流语言的最佳训练混合，提升8种低资源目标语言的语言建模能力。

**结论:** GRAPE提供了一种有效的解决方案，用于校准预训练数据混合，以实现跨多个目标任务的鲁棒性能，特别是在多语言设置下的低资源语言中表现突出。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GRAPE%3A+Optimize+Data+Mixture+for+Group+Robust+Multi-target+Adaptive+Pretraining，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20380，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20380&send_immediately=true&force_search=false)

**原文摘要:** The performance of large language models (LLMs) across diverse downstream
applications is fundamentally governed by the quality and composition of their
pretraining corpora. Existing domain reweighting algorithms primarily optimize
data mixtures for a single target task, thereby resulting in models that
overfit to specialized objectives while exhibiting substantial performance
degradation on other benchmarks. This paper introduces Group Robust
Multi-target Adaptive PrEtraining (GRAPE), a novel multi-source-multi-target
domain reweighting framework designed to calibrate pretraining data mixtures
for robust performance across multiple target tasks simultaneously. GRAPE
dynamically adjusts sampling weights across source domains (domain weights)
while concurrently modulating task weights that quantify the relative
importance of each individual target task. This adaptive process prioritizes
tasks based on their learning difficulty throughout training. We formulate this
interleaved reweighting mechanism as a minimax optimization problem: The inner
maximization adjusts task weights leveraging group
distributed-robust-optimization (DRO), where those tasks demonstrating the
least improvement under the current data mixture are prioritized with higher
weights; The outer minimization then optimizes domain weights to maximize loss
reduction on the prioritized tasks. Experiments on ClimbLab and SlimPajama
datasets demonstrate that GRAPE consistently outperforms baseline methods in
terms of reasoning performance across 6 benchmarks. Furthermore, when applied
to multilingual targets, GRAPE effectively identifies optimal training mixtures
from mainstream languages, achieving superior language modeling capabilities
across 8 low-resource target languages.

</details>


### [11] [Beyond Markovian: Reflective Exploration via Bayes-Adaptive RL for LLM Reasoning](https://arxiv.org/abs/2505.20561)
*Shenao Zhang, Yaqing Wang, Yinxiao Liu, Tianqi Liu, Peter Grabowski, Eugene Ie, Zhaoran Wang, Yunxuan Li*

**主要类别:** cs.LG

**概要:** 论文提出了一种基于贝叶斯适应性强化学习（BARL）的方法，指导大型语言模型在推理任务中更高效地进行反思性探索，相比传统马尔可夫强化学习方法，在测试时表现出更高的token效率和探索效果。


<details>
  <summary>更多</summary>
  
**动机:** 传统的马尔可夫强化学习方法限制了探索能力，仅通过当前状态依赖历史上下文，无法明确解释反思性推理为何会在训练中出现及测试时如何有益。因此，需要一种新框架来优化反思性探索的能力。

**方法:** 将反思性探索纳入贝叶斯适应性强化学习（Bayes-Adaptive RL）框架中，通过后验分布下的期望回报优化策略。该方法同时激励奖励最大化利用和信息收集探索，并通过信念更新调整策略。提出的BARL算法指导LLM根据观察结果切换策略，提供反思性探索的原理性建议。

**结果:** 在合成任务和数学推理任务上的实证结果表明，BARL算法在测试时优于标准马尔可夫RL方法，展现出更高的token效率和更有效的探索能力。

**结论:** BARL为大型语言模型提供了反思性探索的指导，提升了其在推理任务中的表现，证明了贝叶斯适应性强化学习在优化探索策略方面的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Beyond+Markovian%3A+Reflective+Exploration+via+Bayes-Adaptive+RL+for+LLM+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20561，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20561&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) trained via Reinforcement Learning (RL) have
exhibited strong reasoning capabilities and emergent reflective behaviors, such
as backtracking and error correction. However, conventional Markovian RL
confines exploration to the training phase to learn an optimal deterministic
policy and depends on the history contexts only through the current state.
Therefore, it remains unclear whether reflective reasoning will emerge during
Markovian RL training, or why they are beneficial at test time. To remedy this,
we recast reflective exploration within the Bayes-Adaptive RL framework, which
explicitly optimizes the expected return under a posterior distribution over
Markov decision processes. This Bayesian formulation inherently incentivizes
both reward-maximizing exploitation and information-gathering exploration via
belief updates. Our resulting algorithm, BARL, instructs the LLM to stitch and
switch strategies based on the observed outcomes, offering principled guidance
on when and how the model should reflectively explore. Empirical results on
both synthetic and mathematical reasoning tasks demonstrate that BARL
outperforms standard Markovian RL approaches at test time, achieving superior
token efficiency with improved exploration effectiveness. Our code is available
at https://github.com/shenao-zhang/BARL.

</details>


### [12] [Holes in Latent Space: Topological Signatures Under Adversarial Influence](https://arxiv.org/abs/2505.20435)
*Aideen Fay, Inés García-Redondo, Qiquan Wang, Haim Dubossarsky, Anthea Monod*

**主要类别:** cs.LG

**概要:** 提出了一种使用持续同调（PH）技术分析语言模型在对抗条件下的潜在空间动态的方法，揭示了对抗条件下拓扑结构的变化，并引入了一个神经元级别的PH框架来量化信息流动和转换。


<details>
  <summary>更多</summary>
  
**动机:** 理解对抗条件如何影响语言模型需要能够捕捉高维激活空间中全局结构和局部细节的技术。

**方法:** 提出了持续同调（PH）这一来自拓扑数据分析的工具，系统地表征了在后门微调和间接提示注入两种攻击模式下大型语言模型的多尺度潜在空间动态。

**结果:** 对抗条件一致压缩潜在拓扑，减少较小尺度的结构多样性，同时放大较粗尺度的主导特征。这些拓扑特征在各层、架构、模型大小上具有统计稳健性，并与网络更深层出现的对抗效应相吻合。

**结论:** 研究结果表明，PH提供了一个原则性和统一的方法来解释大型语言模型中的表示动态，特别是在分布变化的情况下。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Holes+in+Latent+Space%3A+Topological+Signatures+Under+Adversarial+Influence，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20435，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20435&send_immediately=true&force_search=false)

**原文摘要:** Understanding how adversarial conditions affect language models requires
techniques that capture both global structure and local detail within
high-dimensional activation spaces. We propose persistent homology (PH), a tool
from topological data analysis, to systematically characterize multiscale
latent space dynamics in LLMs under two distinct attack modes -- backdoor
fine-tuning and indirect prompt injection. By analyzing six state-of-the-art
LLMs, we show that adversarial conditions consistently compress latent
topologies, reducing structural diversity at smaller scales while amplifying
dominant features at coarser ones. These topological signatures are
statistically robust across layers, architectures, model sizes, and align with
the emergence of adversarial effects deeper in the network. To capture
finer-grained mechanisms underlying these shifts, we introduce a neuron-level
PH framework that quantifies how information flows and transforms within and
across layers. Together, our findings demonstrate that PH offers a principled
and unifying approach to interpreting representational dynamics in LLMs,
particularly under distributional shift.

</details>


### [13] [Explaining Concept Shift with Interpretable Feature Attribution](https://arxiv.org/abs/2505.20634)
*Ruiqi Lyu, Alistair Turcan, Bryan Wilder*

**主要类别:** cs.LG

**概要:** 提出了一种名为SGShift的模型，用于检测表格数据中的概念漂移，并将降低的模型性能归因于少量偏移特征。通过广义加法模型（GAM）建模概念漂移并进行特征选择来识别偏移特征。扩展方法包括使用knockoffs控制错误发现和吸收项以考虑对数据拟合较差的模型。实验表明，SGShift能以AUC>0.9和召回率>90%的准确度识别偏移特征，比基线方法高出2到3倍。


<details>
  <summary>更多</summary>
  
**动机:** 机器学习模型即使在大量数据上训练，仍可能遇到与训练集不同的数据，导致性能下降。概念漂移（concept shift）是指给定特征条件下标签分布的变化，这会使模型学到错误的表示。识别这些偏移特征有助于理解数据集之间的差异，特别是在科学相关维度上的差异（如时间、疾病状态、人口等）。

**方法:** 提出了SGShift模型，该模型使用广义加加模型（GAM）来建模概念漂移，并通过后续的特征选择步骤来识别偏移特征。进一步扩展了SGShift，通过引入knockoffs来控制错误发现，并添加吸收项来解释对数据拟合不良的模型。

**结果:** 通过在合成数据和真实数据上进行广泛的实验，结果表明SGShift可以以AUC > 0.9和召回率 > 90%的水平识别偏移特征，其表现通常比基线方法高出2或3倍。

**结论:** SGShift是一种有效的方法，能够检测表格数据中的概念漂移并将模型性能下降归因于特定的偏移特征。结合knockoffs和吸收项的改进使其在实际应用中具有更高的可靠性和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Explaining+Concept+Shift+with+Interpretable+Feature+Attribution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20634，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20634&send_immediately=true&force_search=false)

**原文摘要:** Regardless the amount of data a machine learning (ML) model is trained on,
there will inevitably be data that differs from their training set, lowering
model performance. Concept shift occurs when the distribution of labels
conditioned on the features changes, making even a well-tuned ML model to have
learned a fundamentally incorrect representation. Identifying these shifted
features provides unique insight into how one dataset differs from another,
considering the difference may be across a scientifically relevant dimension,
such as time, disease status, population, etc. In this paper, we propose
SGShift, a model for detecting concept shift in tabular data and attributing
reduced model performance to a sparse set of shifted features. SGShift models
concept shift with a Generalized Additive Model (GAM) and performs subsequent
feature selection to identify shifted features. We propose further extensions
of SGShift by incorporating knockoffs to control false discoveries and an
absorption term to account for models with poor fit to the data. We conduct
extensive experiments in synthetic and real data across various ML models and
find SGShift can identify shifted features with AUC $>0.9$ and recall $>90\%$,
often 2 or 3 times as high as baseline methods.

</details>


### [14] [HoPE: Hybrid of Position Embedding for Length Generalization in Vision-Language Models](https://arxiv.org/abs/2505.20444)
*Haoran Li, Yingjie Qin, Baoyuan Ou, Lai Xu, Ruiwen Xu*

**主要类别:** cs.LG

**概要:** 论文提出了一种名为HoPE的混合位置嵌入方法，通过改进频率分配策略和引入动态时间缩放机制，提升视觉-语言模型在长上下文场景（如长视频）中的表现。实验表明，HoPE在四个视频基准上显著优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的旋转位置编码（RoPE）在处理视频的空间-时间依赖关系时存在不足，尤其在长上下文场景中无法可靠捕获语义相似性。

**方法:** 提出HoPE，一种混合位置嵌入方法，包含：1) 混合频率分配策略，用于在任意长上下文中可靠建模语义；2) 动态时间缩放机制，支持跨不同上下文长度的鲁棒学习和灵活推理。

**结果:** 在四个视频基准上的广泛实验证明，HoPE在长视频理解和检索任务中始终优于现有方法。

**结论:** HoPE有效提升了视觉-语言模型在长上下文场景中的能力，并为未来研究提供了新方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是HoPE%3A+Hybrid+of+Position+Embedding+for+Length+Generalization+in+Vision-Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20444，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20444&send_immediately=true&force_search=false)

**原文摘要:** Vision-Language Models (VLMs) have made significant progress in multimodal
tasks. However, their performance often deteriorates in long-context scenarios,
particularly long videos. While Rotary Position Embedding (RoPE) has been
widely adopted for length generalization in Large Language Models (LLMs),
extending vanilla RoPE to capture the intricate spatial-temporal dependencies
in videos remains an unsolved challenge. Existing methods typically allocate
different frequencies within RoPE to encode 3D positional information. However,
these allocation strategies mainly rely on heuristics, lacking in-depth
theoretical analysis. In this paper, we first study how different allocation
strategies impact the long-context capabilities of VLMs. Our analysis reveals
that current multimodal RoPEs fail to reliably capture semantic similarities
over extended contexts. To address this issue, we propose HoPE, a Hybrid of
Position Embedding designed to improve the long-context capabilities of VLMs.
HoPE introduces a hybrid frequency allocation strategy for reliable semantic
modeling over arbitrarily long context, and a dynamic temporal scaling
mechanism to facilitate robust learning and flexible inference across diverse
context lengths. Extensive experiments across four video benchmarks on long
video understanding and retrieval tasks demonstrate that HoPE consistently
outperforms existing methods, confirming its effectiveness. Code is available
at https://github.com/hrlics/HoPE.

</details>


### [15] [Generating Hypotheses of Dynamic Causal Graphs in Neuroscience: Leveraging Generative Factor Models of Observed Time Series](https://arxiv.org/abs/2505.20697)
*Zachary C. Brown, David Carlson*

**主要类别:** cs.LG

**概要:** 提出了一种新的方法，通过将动态图建模为静态图的条件加权叠加来生成科学假设，能够捕获非线性关系并检测复杂的时间变化交互。在实验中显著提高了预测动态因果模式的f1分数，并在真实脑数据案例研究中展示了其发现与特定行为状态相关联的关系的能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的机器学习方法可以生成科学假设，但许多方法假设因果关系是随时间固定的，限制了它们在具有动态、状态依赖行为的系统（如大脑）中的适用性。一些技术试图通过因子模型进行动态因果发现，但通常限制关系为线性模式或施加其他简化假设。

**方法:** 提出了一种新方法，将动态图建模为静态图的条件加权叠加，每个静态图可以捕捉非线性关系，从而实现对变量之间超越线性限制的复杂时间变化交互的检测。

**结果:** 在实验中，该方法平均比基线提高了22-28%的f1分数，某些改进超过了60%。一个基于真实脑数据的案例研究表明，该方法能够揭示与特定行为状态相关的关系。

**结论:** 所提出的方法能够在更复杂的场景下检测动态因果关系，为神经动力学提供了有价值的见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generating+Hypotheses+of+Dynamic+Causal+Graphs+in+Neuroscience%3A+Leveraging+Generative+Factor+Models+of+Observed+Time+Series，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20697，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20697&send_immediately=true&force_search=false)

**原文摘要:** The field of hypothesis generation promises to reduce costs in neuroscience
by narrowing the range of interventional studies needed to study various
phenomena. Existing machine learning methods can generate scientific hypotheses
from complex datasets, but many approaches assume causal relationships are
static over time, limiting their applicability to systems with dynamic,
state-dependent behavior, such as the brain. While some techniques attempt
dynamic causal discovery through factor models, they often restrict
relationships to linear patterns or impose other simplifying assumptions. We
propose a novel method that models dynamic graphs as a conditionally weighted
superposition of static graphs, where each static graph can capture nonlinear
relationships. This approach enables the detection of complex, time-varying
interactions between variables beyond linear limitations. Our method improves
f1-scores of predicted dynamic causal patterns by roughly 22-28% on average
over baselines in some of our experiments, with some improvements reaching well
over 60%. A case study on real brain data demonstrates our method's ability to
uncover relationships linked to specific behavioral states, offering valuable
insights into neural dynamics.

</details>


### [16] [Time Series Generation Under Data Scarcity: A Unified Generative Modeling Approach](https://arxiv.org/abs/2505.20446)
*Tal Gonen, Itai Pemper, Ilan Naiman, Nimrod Berman, Omri Azencot*

**主要类别:** cs.LG

**概要:** 生成时间序列建模是时间序列分析中的核心挑战，尤其是在数据稀缺的情况下。本文通过大规模评估领先的生成模型在数据稀缺环境下的表现，揭示了全数据和数据稀缺条件下的显著性能差距。为缩小这一差距，我们提出了一种基于扩散的统一生成框架，能够使用少量样本跨不同领域合成高质量的时间序列。该模型在大量异构时间序列数据集上进行预训练，学习到可泛化的时序表示，并通过动态卷积层和数据集标记条件化等创新架构进一步增强。实验表明，在少样本条件下，我们的模型优于领域特定基线，甚至在完整数据集基准测试中也超越所有基线模型。


<details>
  <summary>更多</summary>
  
**动机:** 尽管生成建模领域已有近期进展，但对于最先进的生成模型在有限监督下的表现仍缺乏全面理解，特别是在数据稀缺条件下。这促使作者探索如何构建一个能够在数据稀缺环境下有效工作的生成模型。

**方法:** 作者提出了一种基于扩散的统一生成框架，该框架在大量异构时间序列数据集上进行预训练，以学习可泛化的时序表示。模型包含动态卷积层用于灵活的通道适应，以及数据集标记条件化用于领域感知生成。

**结果:** 在少样本设置下，该模型无需大量监督即可达到最先进的性能，超过领域特定基线模型。即使在完整数据集基准测试中，该模型的表现也优于所有基线模型。

**结论:** 这项工作展示了预训练和跨域泛化的强大能力，鼓励研究社区重新审视少样本生成建模作为时间序列研究中的关键问题，并追求能高效扩展到多个领域的统一解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Time+Series+Generation+Under+Data+Scarcity%3A+A+Unified+Generative+Modeling+Approach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20446，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20446&send_immediately=true&force_search=false)

**原文摘要:** Generative modeling of time series is a central challenge in time series
analysis, particularly under data-scarce conditions. Despite recent advances in
generative modeling, a comprehensive understanding of how state-of-the-art
generative models perform under limited supervision remains lacking. In this
work, we conduct the first large-scale study evaluating leading generative
models in data-scarce settings, revealing a substantial performance gap between
full-data and data-scarce regimes. To close this gap, we propose a unified
diffusion-based generative framework that can synthesize high-fidelity time
series across diverse domains using just a few examples. Our model is
pre-trained on a large, heterogeneous collection of time series datasets,
enabling it to learn generalizable temporal representations. It further
incorporates architectural innovations such as dynamic convolutional layers for
flexible channel adaptation and dataset token conditioning for domain-aware
generation. Without requiring abundant supervision, our unified model achieves
state-of-the-art performance in few-shot settings-outperforming domain-specific
baselines across a wide range of subset sizes. Remarkably, it also surpasses
all baselines even when tested on full datasets benchmarks, highlighting the
strength of pre-training and cross-domain generalization. We hope this work
encourages the community to revisit few-shot generative modeling as a key
problem in time series research and pursue unified solutions that scale
efficiently across domains. Code is available at
https://github.com/azencot-group/ImagenFew.

</details>


### [17] [Practical estimation of the optimal classification error with soft labels and calibration](https://arxiv.org/abs/2505.20761)
*Ryota Ushio, Takashi Ishida, Masashi Sugiyama*

**主要类别:** cs.LG

**概要:** 尽管近年来机器学习系统的性能有了显著提高，但对其基本问题关注较少：我们能在多大程度上改进我们的模型？本文在二元分类的背景下提供了一种回答该问题的方法，扩展了利用软标签估计贝叶斯误差的工作。


<details>
  <summary>更多</summary>
  
**动机:** 尽管机器学习系统性能有所提升，但关于模型改进极限的研究较少。本文旨在解决这一基本问题，特别是在二元分类任务中。

**方法:** 1. 理论分析硬标签估计器的偏差属性，揭示其衰减速度与类别条件分布分离度的关系。
2. 针对带有噪声的软标签估计问题，证明即使完全校准的软标签也可能导致不准确估计。
3. 提出使用等距校准方法，在较弱假设下提供统计一致的估计器。
4. 方法无需实例数据，适用于隐私受限场景。

**结果:** 理论和实验结果表明，所提出的方法在估计贝叶斯误差方面具有有效性，并且在处理带噪声软标签时表现良好。

**结论:** 本文通过扩展硬标签和软标签估计方法，提供了在二元分类中评估模型改进极限的有效手段，同时解决了隐私保护问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Practical+estimation+of+the+optimal+classification+error+with+soft+labels+and+calibration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20761，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20761&send_immediately=true&force_search=false)

**原文摘要:** While the performance of machine learning systems has experienced significant
improvement in recent years, relatively little attention has been paid to the
fundamental question: to what extent can we improve our models? This paper
provides a means of answering this question in the setting of binary
classification, which is practical and theoretically supported. We extend a
previous work that utilizes soft labels for estimating the Bayes error, the
optimal error rate, in two important ways. First, we theoretically investigate
the properties of the bias of the hard-label-based estimator discussed in the
original work. We reveal that the decay rate of the bias is adaptive to how
well the two class-conditional distributions are separated, and it can decay
significantly faster than the previous result suggested as the number of hard
labels per instance grows. Second, we tackle a more challenging problem
setting: estimation with corrupted soft labels. One might be tempted to use
calibrated soft labels instead of clean ones. However, we reveal that
calibration guarantee is not enough, that is, even perfectly calibrated soft
labels can result in a substantially inaccurate estimate. Then, we show that
isotonic calibration can provide a statistically consistent estimator under an
assumption weaker than that of the previous work. Our method is instance-free,
i.e., we do not assume access to any input instances. This feature allows it to
be adopted in practical scenarios where the instances are not available due to
privacy issues. Experiments with synthetic and real-world datasets show the
validity of our methods and theory.

</details>


### [18] [Active Learning for Multiple Change Point Detection in Non-stationary Time Series with Deep Gaussian Processes](https://arxiv.org/abs/2505.20452)
*Hao Zhao, Rong Pan*

**主要类别:** cs.LG

**概要:** 在非平稳时间序列中，由于底层模式的多样性，多变点（MCP）检测具有挑战性。为了解决这些挑战，我们提出了一种新的算法，将主动学习（AL）与深度高斯过程（DGPs）相结合，以实现稳健的MCP检测。我们的方法利用频谱分析来识别潜在的变化，并采用AL战略性地选择新的采样点以提高效率。通过结合DGPs的建模灵活性和频谱方法的变点识别能力，我们的方法适应了不同的频谱变化行为，并有效地定位了多个变点。在模拟和真实数据上的实验表明，我们的方法在检测精度和采样效率方面优于现有的非平稳时间序列技术。


<details>
  <summary>更多</summary>
  
**动机:** 非平稳时间序列中的多变点检测面临挑战，因为底层模式多种多样。现有方法可能无法有效处理这些复杂模式，因此需要一种新方法来提高检测的准确性和效率。

**方法:** 提出了一种结合主动学习（AL）和深度高斯过程（DGPs）的新算法。该方法使用频谱分析识别潜在变化点，并通过AL选择新的采样点。此外，它结合了DGPs的建模灵活性和频谱方法的变点识别能力，从而适应不同的频谱变化行为并精确定位多个变点。

**结果:** 实验结果表明，所提出的方法在检测精度和采样效率方面均优于现有的非平稳时间序列技术，无论是在模拟数据还是真实数据上都表现出色。

**结论:** 所提出的结合主动学习和深度高斯过程的算法能够有效应对非平稳时间序列中的多变点检测挑战，提供更高的检测精度和更高效的采样策略。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Active+Learning+for+Multiple+Change+Point+Detection+in+Non-stationary+Time+Series+with+Deep+Gaussian+Processes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20452，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20452&send_immediately=true&force_search=false)

**原文摘要:** Multiple change point (MCP) detection in non-stationary time series is
challenging due to the variety of underlying patterns. To address these
challenges, we propose a novel algorithm that integrates Active Learning (AL)
with Deep Gaussian Processes (DGPs) for robust MCP detection. Our method
leverages spectral analysis to identify potential changes and employs AL to
strategically select new sampling points for improved efficiency. By
incorporating the modeling flexibility of DGPs with the change-identification
capabilities of spectral methods, our approach adapts to diverse spectral
change behaviors and effectively localizes multiple change points. Experiments
on both simulated and real-world data demonstrate that our method outperforms
existing techniques in terms of detection accuracy and sampling efficiency for
non-stationary time series.

</details>


### [19] [Improved Bounds for Swap Multicalibration and Swap Omniprediction](https://arxiv.org/abs/2505.20885)
*Haipeng Luo, Spandan Senapati, Vatsal Sharan*

**主要类别:** cs.LG

**概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improved+Bounds+for+Swap+Multicalibration+and+Swap+Omniprediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20885，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20885&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we consider the related problems of multicalibration -- a
multigroup fairness notion and omniprediction -- a simultaneous loss
minimization paradigm, both in the distributional and online settings. The
recent work of Garg et al. (2024) raised the open problem of whether it is
possible to efficiently achieve $O(\sqrt{T})$ $\ell_{2}$-multicalibration error
against bounded linear functions. In this paper, we answer this question in a
strongly affirmative sense. We propose an efficient algorithm that achieves
$O(T^{\frac{1}{3}})$ $\ell_{2}$-swap multicalibration error (both in high
probability and expectation). On propagating this bound onward, we obtain
significantly improved rates for $\ell_{1}$-swap multicalibration and swap
omniprediction for a loss class of convex Lipschitz functions. In particular,
we show that our algorithm achieves $O(T^{\frac{2}{3}})$ $\ell_{1}$-swap
multicalibration and swap omniprediction errors, thereby improving upon the
previous best-known bound of $O(T^{\frac{7}{8}})$. As a consequence of our
improved online results, we further obtain several improved sample complexity
rates in the distributional setting. In particular, we establish a
$O(\varepsilon ^ {-3})$ sample complexity of efficiently learning an
$\varepsilon$-swap omnipredictor for the class of convex and Lipschitz
functions, $O(\varepsilon ^{-2.5})$ sample complexity of efficiently learning
an $\varepsilon$-swap agnostic learner for the squared loss, and $O(\varepsilon
^ {-5}), O(\varepsilon ^ {-2.5})$ sample complexities of learning $\ell_{1},
\ell_{2}$-swap multicalibrated predictors against linear functions, all of
which significantly improve on the previous best-known bounds.

</details>


### [20] [BlastOFormer: Attention and Neural Operator Deep Learning Methods for Explosive Blast Prediction](https://arxiv.org/abs/2505.20454)
*Reid Graves, Anthony Zhou, Amir Barati Farimani*

**主要类别:** cs.LG

**概要:** BlastOFormer是一种基于Transformer的代理模型，用于从任意障碍物和电荷配置中预测全场最大压力。它在速度和准确性之间提供了良好的权衡，比传统的经验模型和CFD模拟更有效。


<details>
  <summary>更多</summary>
  
**动机:** 准确预测爆炸压力场对于结构安全、防御规划和灾害缓解至关重要。然而，传统方法如经验模型和计算流体动力学（CFD）模拟在速度和准确性之间存在有限的权衡。

**方法:** BlastOFormer利用符号距离函数（SDF）编码和基于网格到网格注意力的架构，该架构受到OFormer和视觉Transformer（ViT）框架的启发。模型在一个使用开源blastFoam CFD求解器生成的数据集上进行训练。

**结果:** BlastOFormer在对数变换和未缩放域中均优于卷积神经网络（CNNs）和傅里叶神经算子（FNOs）。定量上，BlastOFormer实现了最高的R2分数（0.9516）和最低的误差指标，同时推断仅需6.4毫秒，比CFD模拟快60多万倍。定性可视化和误差分析进一步证实了BlastOFormer卓越的空间一致性和泛化能力。

**结论:** 这些结果强调了BlastOFormer作为复杂环境中常规CFD方法实时替代方案的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BlastOFormer%3A+Attention+and+Neural+Operator+Deep+Learning+Methods+for+Explosive+Blast+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20454，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20454&send_immediately=true&force_search=false)

**原文摘要:** Accurate prediction of blast pressure fields is essential for applications in
structural safety, defense planning, and hazard mitigation. Traditional methods
such as empirical models and computational fluid dynamics (CFD) simulations
offer limited trade offs between speed and accuracy; empirical models fail to
capture complex interactions in cluttered environments, while CFD simulations
are computationally expensive and time consuming. In this work, we introduce
BlastOFormer, a novel Transformer based surrogate model for full field maximum
pressure prediction from arbitrary obstacle and charge configurations.
BlastOFormer leverages a signed distance function (SDF) encoding and a grid to
grid attention based architecture inspired by OFormer and Vision Transformer
(ViT) frameworks. Trained on a dataset generated using the open source
blastFoam CFD solver, our model outperforms convolutional neural networks
(CNNs) and Fourier Neural Operators (FNOs) across both log transformed and
unscaled domains. Quantitatively, BlastOFormer achieves the highest R2 score
(0.9516) and lowest error metrics, while requiring only 6.4 milliseconds for
inference, more than 600,000 times faster than CFD simulations. Qualitative
visualizations and error analyses further confirm BlastOFormer's superior
spatial coherence and generalization capabilities. These results highlight its
potential as a real time alternative to conventional CFD approaches for blast
pressure estimation in complex environments.

</details>


### [21] [Efficient Spectral Control of Partially Observed Linear Dynamical Systems](https://arxiv.org/abs/2505.20943)
*Anand Brahmbhatt, Gon Buzaglo, Sofiia Druchyna, Elad Hazan*

**主要类别:** cs.LG

**概要:** 本文提出了Double Spectral Control (DSC) 方法用于解决部分观测和对抗性干扰下的线性动力系统控制问题，通过创新的两层频谱逼近策略，在保持最佳遗憾保证的同时显著提升了运行效率。


<details>
  <summary>更多</summary>
  
**动机:** 现有的控制线性动力系统的方法在部分可观测和对抗性干扰条件下存在运行时复杂度高、依赖于系统的稳定性边界的问题。

**方法:** Double Spectral Control (DSC) 方法，采用两层频谱逼近策略，利用频谱滤波器的通用基进行双重卷积，从而高效且精确地学习最佳线性动力控制器。

**结果:** DSC算法在遗憾保证方面与现有最佳算法相当，但在系统稳定性边界上的运行时复杂度得到了指数级提升。

**结论:** 提出了一种新的方法DSC，该方法在系统稳定性边界上指数级地提高了运行时复杂度，并匹配了已知的最佳遗憾保证。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+Spectral+Control+of+Partially+Observed+Linear+Dynamical+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20943，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20943&send_immediately=true&force_search=false)

**原文摘要:** We propose a new method for the problem of controlling linear dynamical
systems under partial observation and adversarial disturbances. Our new
algorithm, Double Spectral Control (DSC), matches the best known regret
guarantees while exponentially improving runtime complexity over previous
approaches in its dependence on the system's stability margin. Our key
innovation is a two-level spectral approximation strategy, leveraging double
convolution with a universal basis of spectral filters, enabling efficient and
accurate learning of the best linear dynamical controllers.

</details>


### [22] [Avoid Forgetting by Preserving Global Knowledge Gradients in Federated Learning with Non-IID Data](https://arxiv.org/abs/2505.20485)
*Abhijit Chunduru, Majid Morafah, Mahdi Morafah, Vishnu Pandi Chellapandi, Ang Li*

**主要类别:** cs.LG

**概要:** 在联邦学习中，数据异质性是一个重大挑战。本文通过实验分析决策边界，发现了现有方法在本地训练时会忘记全局决策边界的问题。为此，提出了一种名为FedProj的新框架，包含服务器端集成知识转移损失和基于公共未标记数据集的周期性记忆，以校准全局决策边界并防止遗忘。实验表明，FedProj显著优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 数据异质性对联邦学习构成重大挑战，尽管已有多种方法处理此问题，但缺乏对数据异质性如何影响全局决策边界的深入理解。

**方法:** 提出FedProj框架，设计了服务器端集成知识转移损失以更好地融合集合知识，并利用公共未标记数据集上的平均集成logits的周期性记忆来调节本地训练中的梯度更新。

**结果:** 实验结果表明，FedProj在防止全局决策边界遗忘方面表现出色，大幅超越现有最先进方法。

**结论:** FedProj为联邦学习提供了一种有效的方法来稳健地学习全局决策边界，并避免了本地训练过程中的边界遗忘问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Avoid+Forgetting+by+Preserving+Global+Knowledge+Gradients+in+Federated+Learning+with+Non-IID+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20485，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20485&send_immediately=true&force_search=false)

**原文摘要:** The inevitable presence of data heterogeneity has made federated learning
very challenging. There are numerous methods to deal with this issue, such as
local regularization, better model fusion techniques, and data sharing. Though
effective, they lack a deep understanding of how data heterogeneity can affect
the global decision boundary. In this paper, we bridge this gap by performing
an experimental analysis of the learned decision boundary using a toy example.
Our observations are surprising: (1) we find that the existing methods suffer
from forgetting and clients forget the global decision boundary and only learn
the perfect local one, and (2) this happens regardless of the initial weights,
and clients forget the global decision boundary even starting from pre-trained
optimal weights. In this paper, we present FedProj, a federated learning
framework that robustly learns the global decision boundary and avoids its
forgetting during local training. To achieve better ensemble knowledge fusion,
we design a novel server-side ensemble knowledge transfer loss to further
calibrate the learned global decision boundary. To alleviate the issue of
learned global decision boundary forgetting, we further propose leveraging an
episodic memory of average ensemble logits on a public unlabeled dataset to
regulate the gradient updates at each step of local training. Experimental
results demonstrate that FedProj outperforms state-of-the-art methods by a
large margin.

</details>


### [23] [Efficient and Unbiased Sampling from Boltzmann Distributions via Variance-Tuned Diffusion Models](https://arxiv.org/abs/2505.21005)
*Fengzhe Zhang, Laurence I. Midgley, José Miguel Hernández-Lobato*

**主要类别:** cs.LG

**概要:** 分数扩散模型（SBDM）在玻尔兹曼分布中是强大的采样器，但其得分估计的不完美会引入偏差。本文提出了一种名为VT-DIS的新方法，通过调整预训练SBDM的每步噪声协方差来校正该偏差，同时保持较低的计算成本。实验表明，VT-DIS在多个基准测试中表现出较高的有效样本量，且计算成本远低于传统方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的分数扩散模型（SBDM）虽然强大，但由于得分估计不准确，导致下游蒙特卡洛估计存在偏差。经典的重要性采样（IS）可以纠正这一偏差，但需要求解概率流常微分方程（PF-ODE），计算成本过高且随维度增加而恶化。因此，需要一种既能校正偏差又具有较低计算成本的方法。

**方法:** 提出了Variance-Tuned Diffusion Importance Sampling (VT-DIS)，一种轻量级的后训练方法。该方法通过最小化前向扩散和反向去噪轨迹之间的α-散度（α=2）来调整预训练SBDM的每步噪声协方差。VT-DIS为联合前向-反向过程分配单个轨迹重要性权重，从而在测试时以可忽略的额外开销获得无偏期望估计。

**结果:** 在DW-4、LJ-13和丙氨酸二肽基准测试中，VT-DIS分别实现了约80%、35%和3.5%的有效样本量，同时仅使用了传统扩散+IS或基于PF-ODE的IS方法的一小部分计算预算。

**结论:** VT-DIS是一种有效的后处理方法，能够显著提高分数扩散模型的有效样本量，同时保持较低的计算成本，适用于高维问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+and+Unbiased+Sampling+from+Boltzmann+Distributions+via+Variance-Tuned+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21005，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21005&send_immediately=true&force_search=false)

**原文摘要:** Score-based diffusion models (SBDMs) are powerful amortized samplers for
Boltzmann distributions; however, imperfect score estimates bias downstream
Monte Carlo estimates. Classical importance sampling (IS) can correct this
bias, but computing exact likelihoods requires solving the probability-flow
ordinary differential equation (PF-ODE), a procedure that is prohibitively
costly and scales poorly with dimensionality. We introduce Variance-Tuned
Diffusion Importance Sampling (VT-DIS), a lightweight post-training method that
adapts the per-step noise covariance of a pretrained SBDM by minimizing the
$\alpha$-divergence ($\alpha=2$) between its forward diffusion and reverse
denoising trajectories. VT-DIS assigns a single trajectory-wise importance
weight to the joint forward-reverse process, yielding unbiased expectation
estimates at test time with negligible overhead compared to standard sampling.
On the DW-4, LJ-13, and alanine-dipeptide benchmarks, VT-DIS achieves effective
sample sizes of approximately 80 %, 35 %, and 3.5 %, respectively, while using
only a fraction of the computational budget required by vanilla diffusion + IS
or PF-ODE-based IS.

</details>


### [24] [Semi-Explicit Neural DAEs: Learning Long-Horizon Dynamical Systems with Algebraic Constraints](https://arxiv.org/abs/2505.20515)
*Avik Pal, Alan Edelman, Christopher Rackauckas*

**主要类别:** cs.LG

**概要:** 提出了一种名为Manifold-Projected Neural ODEs (PNODEs)的新方法，该方法通过在每个ODE步骤中将约束投影到约束流形上来强制执行代数约束。PNODEs在六个基准问题上表现出色，平均约束违反误差低于$10^{-10}$，并且在给定误差容限的情况下，运行时间比其他方法更短。


<details>
  <summary>更多</summary>
  
**动机:** 现有的神经微分方程(NDEs)方法在结合数据驱动技术和机制建模方面存在可扩展性和数值性能差的问题，无法用于具有复杂守恒定律的物理系统建模。

**方法:** PNODEs 方法通过将每个ODE步骤投影到约束流形上来显式地强制执行代数约束。该框架自然地来源于半显式微分-代数方程(DAEs)，包括一个鲁棒的迭代变体和一个快速近似方法，后者只需要一次雅可比因子分解。此外，证明了先前关于松弛方法的工作是该方法的特例。

**结果:** PNODEs 在六个基准问题上一致优于基线方法，平均约束违反误差低于$10^{-10}$。此外，在给定误差容限的情况下，PNODEs 的运行时间比其他方法更短。

**结论:** 约束投影提供了一种简单的策略来学习物理一致的长时域动力学。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Semi-Explicit+Neural+DAEs%3A+Learning+Long-Horizon+Dynamical+Systems+with+Algebraic+Constraints，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20515，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20515&send_immediately=true&force_search=false)

**原文摘要:** Despite the promise of scientific machine learning (SciML) in combining
data-driven techniques with mechanistic modeling, existing approaches for
incorporating hard constraints in neural differential equations (NDEs) face
significant limitations. Scalability issues and poor numerical properties
prevent these neural models from being used for modeling physical systems with
complicated conservation laws. We propose Manifold-Projected Neural ODEs
(PNODEs), a method that explicitly enforces algebraic constraints by projecting
each ODE step onto the constraint manifold. This framework arises naturally
from semi-explicit differential-algebraic equations (DAEs), and includes both a
robust iterative variant and a fast approximation requiring a single Jacobian
factorization. We further demonstrate that prior works on relaxation methods
are special cases of our approach. PNODEs consistently outperform baselines
across six benchmark problems achieving a mean constraint violation error below
$10^{-10}$. Additionally, PNODEs consistently achieve lower runtime compared to
other methods for a given level of error tolerance. These results show that
constraint projection offers a simple strategy for learning physically
consistent long-horizon dynamics.

</details>


### [25] [Federated Instrumental Variable Analysis via Federated Generalized Method of Moments](https://arxiv.org/abs/2505.21012)
*Geetika, Somya Tyagi, Bapi Chatterjee*

**主要类别:** cs.LG

**概要:** 提出了一种新的联邦学习算法FedIV和FedGMM，用于高维环境下的工具变量分析和广义矩估计。通过联邦零和博弈和联邦梯度下降上升算法解决优化问题，并证明了该方法能够一致估计每个参与客户端的局部矩条件。


<details>
  <summary>更多</summary>
  
**动机:** 现有的工具变量分析和广义矩估计方法在处理非独立同分布数据时缺乏联邦学习算法的支持，无法在保护数据隐私的同时进行高效训练。

**方法:** 将FedGMM建模为由联邦非凸非凹极小极大优化问题定义的联邦零和博弈，并使用联邦梯度下降上升（FedGDA）算法求解。通过FedGDA极限点展示客户局部平衡的特性和存在结果，确保联邦解决方案能一致估计每个参与客户的局部矩条件。

**结果:** 理论分析表明，所提出的算法可以一致估计每个参与客户端的局部矩条件。并通过广泛的实验验证了该方法的有效性。

**结论:** 本研究引入了联邦工具变量分析（FedIV）和联邦广义矩估计（FedGMM），解决了高维环境下非独立同分布数据的隐私保护问题，并通过理论和实验证明了方法的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Federated+Instrumental+Variable+Analysis+via+Federated+Generalized+Method+of+Moments，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21012，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21012&send_immediately=true&force_search=false)

**原文摘要:** Instrumental variables (IV) analysis is an important applied tool for areas
such as healthcare and consumer economics. For IV analysis in high-dimensional
settings, the Generalized Method of Moments (GMM) using deep neural networks
offers an efficient approach. With non-i.i.d. data sourced from scattered
decentralized clients, federated learning is a popular paradigm for training
the models while promising data privacy. However, to our knowledge, no
federated algorithm for either GMM or IV analysis exists to date. In this work,
we introduce federated instrumental variables analysis (FedIV) via federated
generalized method of moments (FedGMM). We formulate FedGMM as a federated
zero-sum game defined by a federated non-convex non-concave minimax
optimization problem, which is solved using federated gradient descent ascent
(FedGDA) algorithm. One key challenge arises in theoretically characterizing
the federated local optimality. To address this, we present properties and
existence results of clients' local equilibria via FedGDA limit points.
Thereby, we show that the federated solution consistently estimates the local
moment conditions of every participating client. The proposed algorithm is
backed by extensive experiments to demonstrate the efficacy of our approach.

</details>


### [26] [Towards Fully FP8 GEMM LLM Training at Scale](https://arxiv.org/abs/2505.20524)
*Alejandro Hernández-Cano, Dhia Garbaya, Imanol Schlag, Martin Jaggi*

**主要类别:** cs.LG

**概要:** 尽管FP8数据格式在大规模语言模型（LLM）预训练中具有显著潜力，但由于难以在大规模下保持稳定性，其应用受到限制。现有方法通常依赖次优的细粒度FP8内核或在敏感组件（如注意力投影）中回退到更高精度的矩阵乘法（GEMMs），从而牺牲了潜在的吞吐量提升。本文提出了一种新的LLM架构，首次支持在前向和反向传播过程中对Transformer块内的所有GEMMs进行FP8计算。这实现了前所未有的吞吐量提升，特别是在大规模下，同时匹配标准BF16训练的下游性能。该架构设计减少了大的异常激活，促进了稳定的长期FP8训练。此外，我们确定了监控低精度训练的关键指标，并预测潜在的未来分歧。


<details>
  <summary>更多</summary>
  
**动机:** FP8数据格式在LLM预训练中具有显著潜力，但目前由于难以在大规模下保持稳定性而应用受限。现有方法要么使用次优的FP8内核，要么在关键部分回退到高精度计算，导致无法充分利用FP8的优势。

**方法:** 引入一种新的LLM架构，支持在Transformer块内的所有GEMMs进行FP8计算，包括前向和反向传播过程。通过减少大异常激活来促进稳定训练，并识别关键指标以监控低精度训练。

**结果:** 实现前所未有的吞吐量提升，特别是在大规模情况下，同时达到与标准BF16训练相当的下游性能。证明了该方法在大规模、长时间训练中的稳定性。

**结论:** 新提出的LLM架构成功实现了全FP8计算，提供了显著的吞吐量优势，同时保持了与BF16相当的性能和稳定性。这为大规模LLM预训练提供了一种高效且稳定的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Fully+FP8+GEMM+LLM+Training+at+Scale，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20524，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20524&send_immediately=true&force_search=false)

**原文摘要:** Despite the significant potential of FP8 data formats for large language
model (LLM) pre-training, their adoption has been limited due to challenges in
maintaining stability at scale. Existing approaches often rely on suboptimal
fine-grained FP8 kernels or fall back to higher-precision matrix
multiplications (GEMMs) in sensitive components, such as attention projections,
compromising potential throughput gains. We introduce a new class of LLM
architectures that, for the first time, support FP8 computation for all GEMMs
within transformer blocks during both forward and backward passes. This enables
unprecedented throughput gains, particularly at scale, while matching the
downstream performance of standard BF16 training. Our architecture design
reduces large outlier activations, promoting stable long-term FP8 training. In
addition, we identify key metrics to monitor low-precision training and predict
potential future divergences.

</details>


### [27] [Bridging Arbitrary and Tree Metrics via Differentiable Gromov Hyperbolicity](https://arxiv.org/abs/2505.21073)
*Pierre Houedry, Nicolas Courty, Florestan Martin-Baillon, Laetitia Chapel, Titouan Vayer*

**主要类别:** cs.LG

**概要:** 本论文提出了一种名为DeltaZero的新型可微优化框架，用于解决任意度量空间到其最近树度量的转换问题。该方法通过平滑替代Gromov的δ-双曲性，实现基于梯度的优化，并在合成和真实数据集上展现出最先进的失真度。


<details>
  <summary>更多</summary>
  
**动机:** 尽管树木和最短路径树度量为表示数据中的分层和组合结构提供了强大的框架，但设计连接任意度量与其最近树度量的算法仍然是一个活跃的研究领域。现有的方法要么是启发式的且缺乏保证，要么表现一般。

**方法:** 作者引入了DeltaZero这一新的可微优化框架，利用Gromov δ-双曲性的平滑替代物，实现了具有可控复杂度的基于梯度的优化。优化过程来源于一个具有比现有边界更好的最坏情况保证的问题，并在统计上得到了证明。

**结果:** 实验表明，该方法在合成和真实世界的数据集上始终达到了最先进的失真度。

**结论:** DeltaZero提供了一种有效的解决方案，用于将任意度量空间映射到其最近的树度量，并且在性能上优于现有方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bridging+Arbitrary+and+Tree+Metrics+via+Differentiable+Gromov+Hyperbolicity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21073，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21073&send_immediately=true&force_search=false)

**原文摘要:** Trees and the associated shortest-path tree metrics provide a powerful
framework for representing hierarchical and combinatorial structures in data.
Given an arbitrary metric space, its deviation from a tree metric can be
quantified by Gromov's $\delta$-hyperbolicity. Nonetheless, designing
algorithms that bridge an arbitrary metric to its closest tree metric is still
a vivid subject of interest, as most common approaches are either heuristical
and lack guarantees, or perform moderately well. In this work, we introduce a
novel differentiable optimization framework, coined DeltaZero, that solves this
problem. Our method leverages a smooth surrogate for Gromov's
$\delta$-hyperbolicity which enables a gradient-based optimization, with a
tractable complexity. The corresponding optimization procedure is derived from
a problem with better worst case guarantees than existing bounds, and is
justified statistically. Experiments on synthetic and real-world datasets
demonstrate that our method consistently achieves state-of-the-art distortion.

</details>


### [28] [Red-Teaming Text-to-Image Systems by Rule-based Preference Modeling](https://arxiv.org/abs/2505.21074)
*Yichuan Cao, Yibo Miao, Xiao-Shan Gao, Yinpeng Dong*

**主要类别:** cs.LG

**概要:** 文本到图像（T2I）模型因其生成不当或有害图像的潜力而引发伦理和安全问题。为了评估这些模型的安全性，本文提出了一种基于规则偏好建模引导的红队测试方法（RPG-RT）。该方法通过迭代使用大型语言模型（LLM）修改查询提示，并利用T2I系统的反馈来微调LLM，使其能够动态适应未知的防御机制。此外，文章还提出了基于规则的偏好建模方法，以更精细地控制LLM的动态适应过程。实验表明，这种方法在多种T2I系统和在线商业API服务中具有优越性和实用性。


<details>
  <summary>更多</summary>
  
**动机:** T2I模型可能生成不当或有害图像，因此需要对其进行安全性评估。然而，现有的白盒方法受限于对内部访问的需求，而黑盒方法则假设对模型的具体防御机制有所了解，这限制了它们在实际商业场景中的应用。因此，需要一种新的方法来克服这些困难，特别是在面对未知和多样化的防御机制时。

**方法:** 本文提出了一种名为Rule-based Preference modeling Guided Red-Teaming（RPG-RT）的方法。该方法通过以下步骤进行：
1. 使用大型语言模型（LLM）修改查询提示。
2. 利用从T2I系统获得的反馈来微调LLM。
3. 将每次迭代的反馈作为先验信息，使LLM能够动态适应未知的防御机制。
4. 提出基于规则的偏好建模方法，通过一组规则评估所需或不所需的反馈，从而实现对LLM动态适应过程的更细粒度控制。

**结果:** 广泛的实验验证了该方法的有效性和实用性。实验涵盖了19个具有不同安全机制的T2I系统、三个在线商业API服务以及T2V模型。结果表明，RPG-RT在各种场景下均表现出色，能够有效应对未知和多样化的防御机制。

**结论:** 本文提出的RPG-RT方法为T2I模型的安全性评估提供了一种新的解决方案。通过结合LLM和基于规则的偏好建模，该方法能够在没有内部访问权限的情况下，动态适应并突破未知的防御机制，为实际商业场景中的安全性评估提供了重要工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Red-Teaming+Text-to-Image+Systems+by+Rule-based+Preference+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21074，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21074&send_immediately=true&force_search=false)

**原文摘要:** Text-to-image (T2I) models raise ethical and safety concerns due to their
potential to generate inappropriate or harmful images. Evaluating these models'
security through red-teaming is vital, yet white-box approaches are limited by
their need for internal access, complicating their use with closed-source
models. Moreover, existing black-box methods often assume knowledge about the
model's specific defense mechanisms, limiting their utility in real-world
commercial API scenarios. A significant challenge is how to evade unknown and
diverse defense mechanisms. To overcome this difficulty, we propose a novel
Rule-based Preference modeling Guided Red-Teaming (RPG-RT), which iteratively
employs LLM to modify prompts to query and leverages feedback from T2I systems
for fine-tuning the LLM. RPG-RT treats the feedback from each iteration as a
prior, enabling the LLM to dynamically adapt to unknown defense mechanisms.
Given that the feedback is often labeled and coarse-grained, making it
difficult to utilize directly, we further propose rule-based preference
modeling, which employs a set of rules to evaluate desired or undesired
feedback, facilitating finer-grained control over the LLM's dynamic adaptation
process. Extensive experiments on nineteen T2I systems with varied safety
mechanisms, three online commercial API services, and T2V models verify the
superiority and practicality of our approach.

</details>


### [29] [Rotary Masked Autoencoders are Versatile Learners](https://arxiv.org/abs/2505.20535)
*Uros Zivanovic, Serafina Di Gioia, Andre Scaffidi, Martín de los Rios, Gabriella Contardo, Roberto Trotta*

**主要类别:** cs.LG

**概要:** 提出了一种名为Rotary Masked Autoencoder (RoMAE)的新方法，该方法在处理多维连续位置信息时避免了时间序列特定架构的专门化，同时在多种模态上展现了优越性能。此外，研究发现将学习到的嵌入包含在输入序列中会破坏RoPE的相对位置属性。


<details>
  <summary>更多</summary>
  
**动机:** 应用Transformer到不规则时间序列通常需要对基线架构进行专门化，这可能导致额外的计算开销和方法复杂性增加。因此，需要一种能够在避免时间序列特定架构专门化的同时，有效处理多维连续位置信息的方法。

**方法:** 提出了Rotary Masked Autoencoder (RoMAE)，它是Masked Autoencoder (MAE)的一种扩展，利用了Rotary Positional Embedding (RoPE)方法来处理连续位置。RoMAE能够进行表示学习，而无需任何时间序列特定架构的专门化。

**结果:** RoMAE在包括不规则和多变量时间序列、图像和音频在内的多种模态上展示了优越性能，尤其在像DESC ELAsTiCC Challenge这样的困难数据集上超越了专门的时间序列架构，同时在其他模态上保持了MAE的一般性能水平。此外，研究还表明，在输入序列中包含学习到的嵌入会破坏RoPE的相对位置属性。

**结论:** Rotary Masked Autoencoder (RoMAE)是一种有效的解决方案，能够在避免时间序列特定架构专门化的情况下，实现多维连续位置信息的表示学习，并在多个模态上展现出优越性能。然而，需要注意的是，将学习到的嵌入加入输入序列可能会影响RoPE的相对位置属性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Rotary+Masked+Autoencoders+are+Versatile+Learners，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20535，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20535&send_immediately=true&force_search=false)

**原文摘要:** Applying Transformers to irregular time-series typically requires
specializations to their baseline architecture, which can result in additional
computational overhead and increased method complexity. We present the Rotary
Masked Autoencoder (RoMAE), which utilizes the popular Rotary Positional
Embedding (RoPE) method for continuous positions. RoMAE is an extension to the
Masked Autoencoder (MAE) that enables representation learning with
multidimensional continuous positional information while avoiding any
time-series-specific architectural specializations. We showcase RoMAE's
performance on a variety of modalities including irregular and multivariate
time-series, images, and audio, demonstrating that RoMAE surpasses specialized
time-series architectures on difficult datasets such as the DESC ELAsTiCC
Challenge while maintaining MAE's usual performance across other modalities. In
addition, we investigate RoMAE's ability to reconstruct the embedded continuous
positions, demonstrating that including learned embeddings in the input
sequence breaks RoPE's relative position property.

</details>


### [30] [Universal Value-Function Uncertainties](https://arxiv.org/abs/2505.21119)
*Moritz A. Zanger, Max Weltevrede, Yaniv Oren, Pascal R. Van der Vaart, Caroline Horsch, Wendelin Böhmer, Matthijs T. J. Spaan*

**主要类别:** cs.LG

**概要:** 本论文提出了一种名为UVU（universal value-function uncertainties）的方法，用于估计强化学习中价值函数的认知不确定性。UVU通过在线网络与固定随机初始化目标网络之间的预测误差来量化不确定性，并且在多任务离线RL设置中表现与大型集成方法相当，同时具有简单性和显著的计算节省。


<details>
  <summary>更多</summary>
  
**动机:** 在强化学习中，估计价值函数的认知不确定性对于高效探索、安全决策和离线RL等至关重要。然而，现有的深度集成方法虽然能有效量化不确定性，但计算开销大；而单模型方法虽计算上更优，但通常依赖启发式方法且需要额外机制传播不确定性。

**方法:** UVU方法类似于RND，通过在线学习者与固定随机初始化目标网络之间的平方预测误差来量化不确定性。不同之处在于，UVU误差反映的是策略条件下的价值不确定性，这归因于其训练过程：在线网络使用时间差分学习，并从固定随机初始化目标网络派生出合成奖励进行训练。此外，利用神经切线核(NTK)理论对UVU进行了广泛的理论分析，证明了在网络宽度无限时，UVU误差正好等同于独立通用价值函数集合的方差。

**结果:** 理论上，UVU误差在网络宽度无限的情况下等同于独立通用价值函数集合的方差。实证上，在具有挑战性的多任务离线RL环境中，UVU的表现与大型集成方法相同，同时提供了简单性和显著的计算节省。

**结论:** UVU提供了一种新的方法来估计强化学习中的价值函数不确定性，该方法不仅在性能上与大型集成方法相当，而且更加简单并大幅减少了计算资源的需求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Universal+Value-Function+Uncertainties，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21119，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21119&send_immediately=true&force_search=false)

**原文摘要:** Estimating epistemic uncertainty in value functions is a crucial challenge
for many aspects of reinforcement learning (RL), including efficient
exploration, safe decision-making, and offline RL. While deep ensembles provide
a robust method for quantifying value uncertainty, they come with significant
computational overhead. Single-model methods, while computationally favorable,
often rely on heuristics and typically require additional propagation
mechanisms for myopic uncertainty estimates. In this work we introduce
universal value-function uncertainties (UVU), which, similar in spirit to
random network distillation (RND), quantify uncertainty as squared prediction
errors between an online learner and a fixed, randomly initialized target
network. Unlike RND, UVU errors reflect policy-conditional value uncertainty,
incorporating the future uncertainties any given policy may encounter. This is
due to the training procedure employed in UVU: the online network is trained
using temporal difference learning with a synthetic reward derived from the
fixed, randomly initialized target network. We provide an extensive theoretical
analysis of our approach using neural tangent kernel (NTK) theory and show that
in the limit of infinite network width, UVU errors are exactly equivalent to
the variance of an ensemble of independent universal value functions.
Empirically, we show that UVU achieves equal performance to large ensembles on
challenging multi-task offline RL settings, while offering simplicity and
substantial computational savings.

</details>


### [31] [A ZeNN architecture to avoid the Gaussian trap](https://arxiv.org/abs/2505.20553)
*Luís Carvalho, João L. Costa, José Mourão, Gonçalo Oliveira*

**主要类别:** cs.LG

**概要:** 提出了一种新的简单架构，Zeta神经网络（ZeNNs），以克服标准多层感知器（MLPs）的几个缺点。通过引入非学习权重、缩放因子和近似正交激活函数，ZeNNs在无限宽度限制下能够逐点收敛，展现超越高斯特性的丰富渐近结构，并进行特征学习。此外，在适当选择激活函数时，有限宽度的ZeNNs擅长学习低维域函数的高频特征。


<details>
  <summary>更多</summary>
  
**动机:** 标准多层感知器（MLPs）在大宽度极限下存在一些问题：它们是非参数化的，没有明确的逐点极限，失去非高斯属性且无法进行特征学习；此外，有限宽度的MLPs在学习高频特征方面表现不佳。为了解决这些问题，提出了Zeta神经网络（ZeNNs）。

**方法:** ZeNNs架构基于谐波分析中的三个原则构建：1）枚举感知器并引入非学习权重以确保收敛性；2）引入缩放（或频率）因子；3）选择导致近似正交系统的激活函数。这些设计使得ZeNNs具备特定的优势来解决MLPs的问题。

**结果:** 理论和实验结果表明，ZeNNs在无限宽度极限下可以逐点收敛，展现出丰富的渐近结构，超越了高斯特性，并能执行特征学习。此外，当选择适当的激活函数时，有限宽度的ZeNNs在学习低维域函数的高频特征方面表现出色。

**结论:** Zeta神经网络（ZeNNs）成功解决了标准多层感知器（MLPs）的一些关键缺陷。其在无限宽度极限下的良好性能以及对高频特征的学习能力，使其成为一种有潜力的新型神经网络架构。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+ZeNN+architecture+to+avoid+the+Gaussian+trap，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20553，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20553&send_immediately=true&force_search=false)

**原文摘要:** We propose a new simple architecture, Zeta Neural Networks (ZeNNs), in order
to overcome several shortcomings of standard multi-layer perceptrons (MLPs).
Namely, in the large width limit, MLPs are non-parametric, they do not have a
well-defined pointwise limit, they lose non-Gaussian attributes and become
unable to perform feature learning; moreover, finite width MLPs perform poorly
in learning high frequencies. The new ZeNN architecture is inspired by three
simple principles from harmonic analysis:
  i) Enumerate the perceptons and introduce a non-learnable weight to enforce
convergence;
  ii) Introduce a scaling (or frequency) factor;
  iii) Choose activation functions that lead to near orthogonal systems.
  We will show that these ideas allow us to fix the referred shortcomings of
MLPs. In fact, in the infinite width limit, ZeNNs converge pointwise, they
exhibit a rich asymptotic structure beyond Gaussianity, and perform feature
learning. Moreover, when appropriate activation functions are chosen, (finite
width) ZeNNs excel at learning high-frequency features of functions with low
dimensional domains.

</details>


### [32] [Robust and Computation-Aware Gaussian Processes](https://arxiv.org/abs/2505.21133)
*Marshal Arijona Sinaga, Julien Martinelli, Samuel Kaski*

**主要类别:** cs.LG

**概要:** 提出了一种新的高斯过程模型RCaGP，通过结合鲁棒性和近似不确定性处理，解决了大数据集中的异常值问题和计算效率问题。


<details>
  <summary>更多</summary>
  
**动机:** 在大数据集中存在异常值的情况下，标准的高斯过程及其稀疏近似方法在计算可行性和鲁棒性方面表现不佳。

**方法:** 引入了Robust Computation-aware Gaussian Process (RCaGP)，它通过结合近似不确定性与鲁棒广义贝叶斯更新来同时解决计算效率和鲁棒性问题。关键在于认识到鲁棒性和近似性并非独立，而是相互交织。

**结果:** 实验证明，在干净数据和含异常值的数据上，该方法在回归和高通量贝叶斯优化基准测试中均表现出色。

**结论:** RCaGP能够更保守和可靠地估计不确定性，并且其均值函数对于保持鲁棒性至关重要。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robust+and+Computation-Aware+Gaussian+Processes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21133，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21133&send_immediately=true&force_search=false)

**原文摘要:** Gaussian processes (GPs) are widely used for regression and optimization
tasks such as Bayesian optimization (BO) due to their expressiveness and
principled uncertainty estimates. However, in settings with large datasets
corrupted by outliers, standard GPs and their sparse approximations struggle
with computational tractability and robustness. We introduce Robust
Computation-aware Gaussian Process (RCaGP), a novel GP model that jointly
addresses these challenges by combining a principled treatment of
approximation-induced uncertainty with robust generalized Bayesian updating.
The key insight is that robustness and approximation-awareness are not
orthogonal but intertwined: approximations can exacerbate the impact of
outliers, and mitigating one without the other is insufficient. Unlike previous
work that focuses narrowly on either robustness or approximation quality, RCaGP
combines both in a principled and scalable framework, thus effectively managing
both outliers and computational uncertainties introduced by approximations such
as low-rank matrix multiplications. Our model ensures more conservative and
reliable uncertainty estimates, a property we rigorously demonstrate.
Additionally, we establish a robustness property and show that the mean
function is key to preserving it, motivating a tailored model selection scheme
for robust mean functions. Empirical results confirm that solving these
challenges jointly leads to superior performance across both clean and
outlier-contaminated settings, both on regression and high-throughput Bayesian
optimization benchmarks.

</details>


### [33] [Learning a Pessimistic Reward Model in RLHF](https://arxiv.org/abs/2505.20556)
*Yinglun Xu, Hangoo Kang, Tarun Suresh, Yuxuan Wan, Gagandeep Singh*

**主要类别:** cs.LG

**概要:** 本研究提出了一种新的悲观奖励微调方法`PET'，用于从人类反馈中进行离线强化学习（RLHF），以防止奖励黑客攻击。通过在标准TL;DR摘要数据集上的测试，证明了该方法可以在不依赖任何正则化的情况下，学习到高质量的策略，并且该策略在实践中表现出高性能。


<details>
  <summary>更多</summary>
  
**动机:** 传统的RLHF奖励建模技术依赖于KL正则化来减轻奖励黑客攻击，但这种方法仍然容易受到奖励黑客攻击的影响，并且排除了与数据集分布具有大KL散度的策略。因此，需要一种新方法来解决这些问题。

**方法:** 提出了一种名为`PET'的悲观奖励微调方法，通过优化基于悲观奖励模型的策略，防止奖励黑客攻击，而不依赖任何正则化。

**结果:** 实验结果表明，在不使用任何正则化的情况下，可以学习到高质量的策略，这些策略虽然与数据集分布具有高KL散度，但在实践中表现出高性能。

**结论:** 本研究表明，学习悲观奖励模型是可行的，并且可以通过贪婪搜索找到具有高悲观奖励的策略，而不会遭受奖励黑客攻击。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+a+Pessimistic+Reward+Model+in+RLHF，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20556，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20556&send_immediately=true&force_search=false)

**原文摘要:** This work proposes `PET', a novel pessimistic reward fine-tuning method, to
learn a pessimistic reward model robust against reward hacking in offline
reinforcement learning from human feedback (RLHF). Traditional reward modeling
techniques in RLHF train an imperfect reward model, on which a KL
regularization plays a pivotal role in mitigating reward hacking when
optimizing a policy. Such an intuition-based method still suffers from reward
hacking, and the policies with large KL divergence from the dataset
distribution are excluded during learning. In contrast, we show that when
optimizing a policy on a pessimistic reward model fine-tuned through PET,
reward hacking can be prevented without relying on any regularization. We test
our methods on the standard TL;DR summarization dataset. We find that one can
learn a high-quality policy on our pessimistic reward without using any
regularization. Such a policy has a high KL divergence from the dataset
distribution while having high performance in practice. In summary, our work
shows the feasibility of learning a pessimistic reward model against reward
hacking. The agent can greedily search for the policy with a high pessimistic
reward without suffering from reward hacking.

</details>


### [34] [Learning Single Index Models with Diffusion Priors](https://arxiv.org/abs/2505.21135)
*Anqi Tang, Youming Chen, Shuchen Xue, Zhaoqiang Liu*

**主要类别:** cs.LG

**概要:** 扩散模型（DMs）在生成高质量图像和信号恢复方面表现出色，但现有方法难以处理非线性测量模型。本文提出了一种高效重建方法，适用于包含不连续或未知链接函数的半参数单指数模型，仅需一次无条件采样和（部分）DM反转即可实现准确恢复。实验表明，该方法能显著减少神经函数评估次数，同时提高重建精度。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于扩散模型的信号恢复研究要么专注于特定的重建问题，要么无法处理具有不连续或未知链接函数的非线性测量模型。因此，需要一种新的方法来解决这些问题并提升信号恢复的质量。

**方法:** 提出了一种高效的重建方法，专门针对半参数单指数模型。该方法仅需一轮无条件采样和扩散模型的部分反转操作，能够处理各种流行的非线性模型，包括具有不连续和未知链接函数的情况。此外，还进行了理论分析以验证方法的有效性。

**结果:** 通过在不同非线性测量模型上的图像数据集进行数值实验，结果表明，与竞争方法相比，所提出的方法不仅能够提供更精确的重建，而且显著减少了所需的神经函数评估次数。

**结论:** 本文提出了一种用于信号恢复的新方法，特别适用于包含不连续和未知链接函数的非线性模型。实验结果证明了该方法在减少计算成本和提高重建精度方面的优势。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Single+Index+Models+with+Diffusion+Priors，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21135，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21135&send_immediately=true&force_search=false)

**原文摘要:** Diffusion models (DMs) have demonstrated remarkable ability to generate
diverse and high-quality images by efficiently modeling complex data
distributions. They have also been explored as powerful generative priors for
signal recovery, resulting in a substantial improvement in the quality of
reconstructed signals. However, existing research on signal recovery with
diffusion models either focuses on specific reconstruction problems or is
unable to handle nonlinear measurement models with discontinuous or unknown
link functions. In this work, we focus on using DMs to achieve accurate
recovery from semi-parametric single index models, which encompass a variety of
popular nonlinear models that may have {\em discontinuous} and {\em unknown}
link functions. We propose an efficient reconstruction method that only
requires one round of unconditional sampling and (partial) inversion of DMs.
Theoretical analysis on the effectiveness of the proposed methods has been
established under appropriate conditions. We perform numerical experiments on
image datasets for different nonlinear measurement models. We observe that
compared to competing methods, our approach can yield more accurate
reconstructions while utilizing significantly fewer neural function
evaluations.

</details>


### [35] [Learnable Kernel Density Estimation for Graphs](https://arxiv.org/abs/2505.21285)
*Xudong Wang, Ziheng Sun, Chris Ding, Jicong Fan*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种名为LGKDE的框架，用于图的核密度估计。通过结合图神经网络和最大均值差异方法，LGKDE在多尺度核密度估计中表现出色，并且理论上保证了其一致性和收敛性。实验表明，LGKDE在恢复合成图分布的潜在密度以及图异常检测任务上优于大多数基准数据集上的现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 当前图密度估计方法在结合结构模式和语义变化方面表现不佳，主要由于手工设计的固定核特征限制了性能提升。

**方法:** 提出LGKDE框架，利用图神经网络表示图作为离散分布，使用最大均值差异（MMD）学习多尺度核密度估计中的图度量，并通过最大化图密度与扰动图密度之间的相对密度来学习所有参数。扰动操作涉及节点特征和图谱，以更好地刻画正常密度区域的边界。

**结果:** 理论分析证明了LGKDE的一致性、收敛性和复杂度。实验证明LGKDE在合成图分布密度恢复和图异常检测任务上表现优异，优于大多数现有方法。

**结论:** LGKDE是一种有效的图密度估计方法，结合了图神经网络和核密度估计的优势，具有理论保障并在实际应用中表现出色。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learnable+Kernel+Density+Estimation+for+Graphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21285，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21285&send_immediately=true&force_search=false)

**原文摘要:** This work proposes a framework LGKDE that learns kernel density estimation
for graphs. The key challenge in graph density estimation lies in effectively
capturing both structural patterns and semantic variations while maintaining
theoretical guarantees. Combining graph kernels and kernel density estimation
(KDE) is a standard approach to graph density estimation, but has
unsatisfactory performance due to the handcrafted and fixed features of
kernels. Our method LGKDE leverages graph neural networks to represent each
graph as a discrete distribution and utilizes maximum mean discrepancy to learn
the graph metric for multi-scale KDE, where all parameters are learned by
maximizing the density of graphs relative to the density of their well-designed
perturbed counterparts. The perturbations are conducted on both node features
and graph spectra, which helps better characterize the boundary of normal
density regions. Theoretically, we establish consistency and convergence
guarantees for LGKDE, including bounds on the mean integrated squared error,
robustness, and complexity. We validate LGKDE by demonstrating its
effectiveness in recovering the underlying density of synthetic graph
distributions and applying it to graph anomaly detection across diverse
benchmark datasets. Extensive empirical evaluation shows that LGKDE
demonstrates superior performance compared to state-of-the-art baselines on
most benchmark datasets.

</details>


### [36] [Bi-Level Unsupervised Feature Selection](https://arxiv.org/abs/2505.20563)
*Jingjing Liu, Xiansen Ju, Xianchao Xiu, Wanquan Liu*

**主要类别:** cs.LG

**概要:** 提出了一种新的双层无监督特征选择（BLUFS）方法，结合了聚类和特征级别，并使用ℓ2,0-范数约束提高了特征选择效果。设计了高效的PAM算法解决该模型并证明其收敛性和复杂度。实验表明BLUFS在聚类和分类任务中表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 大多数无监督特征选择方法仅从单一视角构建模型，无法同时评估特征重要性和保留数据的固有结构，导致性能受限。

**方法:** 提出了双层无监督特征选择（BLUFS）方法，包括聚类层和特征层。聚类层通过谱聚类生成伪标签表示数据结构，并用连续线性回归模型学习投影矩阵；特征层对投影矩阵施加ℓ2,0-范数约束以更有效地选择特征。为了解决提出的双层模型，设计了高效的近端交替最小化（PAM）算法。

**结果:** 广泛的实验在两个合成数据集和八个真实数据集上进行，结果表明BLUFS在聚类和分类任务中具有优越性。

**结论:** BLUFS方法通过双层框架和ℓ2,0-范数约束有效提升了无监督特征选择的性能，适用于聚类和分类任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bi-Level+Unsupervised+Feature+Selection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20563，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20563&send_immediately=true&force_search=false)

**原文摘要:** Unsupervised feature selection (UFS) is an important task in data
engineering. However, most UFS methods construct models from a single
perspective and often fail to simultaneously evaluate feature importance and
preserve their inherent data structure, thus limiting their performance. To
address this challenge, we propose a novel bi-level unsupervised feature
selection (BLUFS) method, including a clustering level and a feature level.
Specifically, at the clustering level, spectral clustering is used to generate
pseudo-labels for representing the data structure, while a continuous linear
regression model is developed to learn the projection matrix. At the feature
level, the $\ell_{2,0}$-norm constraint is imposed on the projection matrix for
more effectively selecting features. To the best of our knowledge, this is the
first work to combine a bi-level framework with the $\ell_{2,0}$-norm. To solve
the proposed bi-level model, we design an efficient proximal alternating
minimization (PAM) algorithm, whose subproblems either have explicit solutions
or can be computed by fast solvers. Furthermore, we establish the convergence
result and computational complexity. Finally, extensive experiments on two
synthetic datasets and eight real datasets demonstrate the superiority of BLUFS
in clustering and classification tasks.

</details>


### [37] [Joint Learning in the Gaussian Single Index Model](https://arxiv.org/abs/2505.21336)
*Loucas Pillaud-Vivien, Adrien Schertzer*

**主要类别:** cs.LG

**概要:** 在高维高斯模型中，联合学习一维投影和单变量函数的问题被研究。通过分析自然交替方案的梯度流动力学，证明了收敛性，并展示了即使初始方向与目标负相关时也能收敛。此外，使用RKHS可以有效实现此类联合学习，为高维设置中的低维结构学习提供了理论和实践方法。


<details>
  <summary>更多</summary>
  
**动机:** 研究在一维投影和单变量函数上的联合学习问题，捕捉到表示学习和非线性回归交叉处的基本非凸问题。

**方法:** 分析自然交替方案的梯度流动力学，证明其收敛性并展示其受信息指数控制的速率；同时提出使用适应问题结构的再生核希尔伯特空间（RKHS）来有效估计单变量函数。

**结果:** 证明了该方法在即使初始方向与目标负相关时仍能收敛，并且使用RKHS可以有效地实现联合学习。

**结论:** 此研究为高维设置中的低维结构学习提供了理论见解和实际方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Joint+Learning+in+the+Gaussian+Single+Index+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21336，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21336&send_immediately=true&force_search=false)

**原文摘要:** We consider the problem of jointly learning a one-dimensional projection and
a univariate function in high-dimensional Gaussian models. Specifically, we
study predictors of the form $f(x)=\varphi^\star(\langle w^\star, x \rangle)$,
where both the direction $w^\star \in \mathcal{S}_{d-1}$, the sphere of
$\mathbb{R}^d$, and the function $\varphi^\star: \mathbb{R} \to \mathbb{R}$ are
learned from Gaussian data. This setting captures a fundamental non-convex
problem at the intersection of representation learning and nonlinear
regression. We analyze the gradient flow dynamics of a natural alternating
scheme and prove convergence, with a rate controlled by the information
exponent reflecting the \textit{Gaussian regularity} of the function
$\varphi^\star$. Strikingly, our analysis shows that convergence still occurs
even when the initial direction is negatively correlated with the target. On
the practical side, we demonstrate that such joint learning can be effectively
implemented using a Reproducing Kernel Hilbert Space (RKHS) adapted to the
structure of the problem, enabling efficient and flexible estimation of the
univariate function. Our results offer both theoretical insight and practical
methodology for learning low-dimensional structure in high-dimensional
settings.

</details>


### [38] [Ctrl-DNA: Controllable Cell-Type-Specific Regulatory DNA Design via Constrained RL](https://arxiv.org/abs/2505.20578)
*Xingyu Chen, Shihao Ma, Runsheng Lin, Jiecong Lin, Bo Wang*

**主要类别:** cs.LG

**概要:** 本研究提出了一种名为Ctrl-DNA的新框架，通过受约束的强化学习方法设计具有细胞类型特异性的调控DNA序列。与现有方法相比，Ctrl-DNA在人类启动子和增强子的设计中表现出更高的性能，并能生成具有高适应性和细胞类型特异性的调控序列。此外，生成的序列还捕捉到了关键的细胞类型特异性转录因子结合位点，验证了其生物学合理性。


<details>
  <summary>更多</summary>
  
**动机:** 合成生物学、基因治疗和精准医疗的发展需要精确设计具有细胞类型特异性的基因表达调控DNA序列。然而，基于Transformer的语言模型虽然能够有效捕捉调控DNA中的模式，但在生成具有可靠细胞特异性活性的新序列时存在困难。

**方法:** 研究者提出了Ctrl-DNA，一种基于受约束强化学习（RL）的新框架，用于设计具有可控细胞类型特异性的调控DNA序列。通过将调控序列设计问题转化为生物信息驱动的约束优化问题，应用RL到自回归基因组语言模型上，使模型能够迭代改进序列，以最大化目标细胞类型中的调控活性，同时限制非目标效应。

**结果:** 在人类启动子和增强子上的评估表明，Ctrl-DNA在生成高适应性调控序列方面显著优于现有的生成和基于RL的方法，达到了最先进的细胞类型特异性。此外，Ctrl-DNA生成的序列捕捉到了关键的细胞类型特异性转录因子结合位点（TFBS），证明了其生物学合理性。

**结论:** Ctrl-DNA为设计具有细胞类型特异性的调控DNA序列提供了一种高效的新方法，其生成的序列不仅表现优异，而且具有生物学意义。这为合成生物学、基因治疗和精准医疗等领域提供了新的工具和可能性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Ctrl-DNA%3A+Controllable+Cell-Type-Specific+Regulatory+DNA+Design+via+Constrained+RL，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20578，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20578&send_immediately=true&force_search=false)

**原文摘要:** Designing regulatory DNA sequences that achieve precise cell-type-specific
gene expression is crucial for advancements in synthetic biology, gene therapy
and precision medicine. Although transformer-based language models (LMs) can
effectively capture patterns in regulatory DNA, their generative approaches
often struggle to produce novel sequences with reliable cell-specific activity.
Here, we introduce Ctrl-DNA, a novel constrained reinforcement learning (RL)
framework tailored for designing regulatory DNA sequences with controllable
cell-type specificity. By formulating regulatory sequence design as a
biologically informed constrained optimization problem, we apply RL to
autoregressive genomic LMs, enabling the models to iteratively refine sequences
that maximize regulatory activity in targeted cell types while constraining
off-target effects. Our evaluation on human promoters and enhancers
demonstrates that Ctrl-DNA consistently outperforms existing generative and
RL-based approaches, generating high-fitness regulatory sequences and achieving
state-of-the-art cell-type specificity. Moreover, Ctrl-DNA-generated sequences
capture key cell-type-specific transcription factor binding sites (TFBS), short
DNA motifs recognized by regulatory proteins that control gene expression,
demonstrating the biological plausibility of the generated sequences.

</details>


### [39] [Finite Sample Analysis of Linear Temporal Difference Learning with Arbitrary Features](https://arxiv.org/abs/2505.21391)
*Zixuan Xie, Xinyu Liu, Rohan Chandra, Shangtong Zhang*

**主要类别:** cs.LG

**概要:** 这篇论文研究了线性TD($\lambda$)算法在任意特征下的$L^2$收敛速度，无需额外假设或算法修改。


<details>
  <summary>更多</summary>
  
**动机:** 线性TD($\lambda$)是强化学习中用于策略评估的基本算法，但现有的收敛率分析通常基于线性独立特征的假设，这在许多实际场景中并不成立。因此，需要对任意特征下的线性TD($\lambda$)进行更广泛的分析。

**方法:** 作者开发了一个新的随机逼近结果，该结果允许收敛到解集而不是单一解点，以应对由任意特征引起的潜在非唯一解问题。此方法适用于折扣和平均奖励两种设定。

**结果:** 得到了线性TD($\lambda$)在任意特征下的$L^2$收敛速度，并且无需任何算法修改或额外假设。

**结论:** 这项工作首次提供了线性TD($\lambda$)在任意特征下的$L^2$收敛速度，为强化学习中的策略评估提供了一个更通用的理论框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Finite+Sample+Analysis+of+Linear+Temporal+Difference+Learning+with+Arbitrary+Features，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21391，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21391&send_immediately=true&force_search=false)

**原文摘要:** Linear TD($\lambda$) is one of the most fundamental reinforcement learning
algorithms for policy evaluation. Previously, convergence rates are typically
established under the assumption of linearly independent features, which does
not hold in many practical scenarios. This paper instead establishes the first
$L^2$ convergence rates for linear TD($\lambda$) operating under arbitrary
features, without making any algorithmic modification or additional
assumptions. Our results apply to both the discounted and average-reward
settings. To address the potential non-uniqueness of solutions resulting from
arbitrary features, we develop a novel stochastic approximation result
featuring convergence rates to the solution set instead of a single point.

</details>


### [40] [The challenge of hidden gifts in multi-agent reinforcement learning](https://arxiv.org/abs/2505.20579)
*Dane Malenfant, Blake A. Richards*

**主要类别:** cs.LG

**概要:** 研究了在存在'隐藏礼物'的情况下多智能体强化学习中的信用分配问题，发现多个最先进的RL算法无法解决简单任务中的集体奖励获取。独立的无模型策略梯度代理在提供自身动作历史信息时可以解决问题，而MARL代理则不能。通过引入校正项，减少学习方差，帮助独立代理更可靠地收敛到集体成功。


<details>
  <summary>更多</summary>
  
**动机:** 多智能体强化学习中，当其他智能体的有益行为被隐藏时，信用分配变得非平凡。因此，需要研究在存在'隐藏礼物'的情况下，智能体如何学习合作以获得集体奖励。

**方法:** 设计了一个网格世界环境的任务，在该任务中，智能体需要解锁各自的门以获得个人奖励，并且如果所有智能体都解锁了各自的门，则可以获得更大的集体奖励。关键在于，只有一把钥匙可以用于解锁所有门，使用后需要放下以便其他智能体使用。由于没有指示某智能体放下钥匙的信号，因此放下钥匙的行为被视为'隐藏礼物'。

**结果:** 多个最先进的RL算法，包括MARL算法，无法在此简单任务中学习如何获得集体奖励。独立的无模型策略梯度代理在提供自身动作历史信息时可以解决问题，而MARL代理则不能。通过引入校正项，减少学习方差，帮助独立代理更可靠地收敛到集体成功。

**结论:** 多智能体环境中的信用分配在存在'隐藏礼物'的情况下特别具有挑战性，学习意识在独立代理中可以受益于这些设置。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+challenge+of+hidden+gifts+in+multi-agent+reinforcement+learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20579，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20579&send_immediately=true&force_search=false)

**原文摘要:** Sometimes we benefit from actions that others have taken even when we are
unaware that they took those actions. For example, if your neighbor chooses not
to take a parking spot in front of your house when you are not there, you can
benefit, even without being aware that they took this action. These "hidden
gifts" represent an interesting challenge for multi-agent reinforcement
learning (MARL), since assigning credit when the beneficial actions of others
are hidden is non-trivial. Here, we study the impact of hidden gifts with a
very simple MARL task. In this task, agents in a grid-world environment have
individual doors to unlock in order to obtain individual rewards. As well, if
all the agents unlock their door the group receives a larger collective reward.
However, there is only one key for all of the doors, such that the collective
reward can only be obtained when the agents drop the key for others after they
use it. Notably, there is nothing to indicate to an agent that the other agents
have dropped the key, thus the act of dropping the key for others is a "hidden
gift". We show that several different state-of-the-art RL algorithms, including
MARL algorithms, fail to learn how to obtain the collective reward in this
simple task. Interestingly, we find that independent model-free policy gradient
agents can solve the task when we provide them with information about their own
action history, but MARL agents still cannot solve the task with action
history. Finally, we derive a correction term for these independent agents,
inspired by learning aware approaches, which reduces the variance in learning
and helps them to converge to collective success more reliably. These results
show that credit assignment in multi-agent settings can be particularly
challenging in the presence of "hidden gifts", and demonstrate that learning
awareness in independent agents can benefit these settings.

</details>


### [41] [A Convergence Theory for Diffusion Language Models: An Information-Theoretic Perspective](https://arxiv.org/abs/2505.21400)
*Gen Li, Changxiao Cai*

**主要类别:** cs.LG

**概要:** 扩散模型作为一种现代生成建模的有力范式，具有强大的潜力。本文从信息论的角度出发，为扩散语言模型提供了收敛性保证，分析了采样误差与迭代次数和目标文本序列中令牌的互信息之间的关系，并建立了匹配的上下界以证明收敛分析的紧密性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管扩散模型在实践中取得了成功，但其理论理解仍不完善，特别是对于扩散语言模型的有效性缺乏深入的理论支持。

**方法:** 作者从信息论的角度对扩散语言模型进行了分析，主要关注采样误差（通过KL散度衡量）与迭代次数$T$以及目标文本序列中令牌的互信息之间的关系。同时，建立了匹配的上界和下界来证明收敛分析的紧密性。

**结果:** 证明了采样误差随着迭代次数$T$的增加而衰减，并且与目标文本序列中令牌的互信息呈线性关系。此外，通过建立匹配的上下界，验证了收敛分析的紧密性。

**结论:** 该研究为扩散语言模型的实际有效性提供了新的理论见解，进一步加深了对其工作原理的理解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Convergence+Theory+for+Diffusion+Language+Models%3A+An+Information-Theoretic+Perspective，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21400，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21400&send_immediately=true&force_search=false)

**原文摘要:** Diffusion models have emerged as a powerful paradigm for modern generative
modeling, demonstrating strong potential for large language models (LLMs).
Unlike conventional autoregressive (AR) models that generate tokens
sequentially, diffusion models enable parallel token sampling, leading to
faster generation and eliminating left-to-right generation constraints. Despite
their empirical success, the theoretical understanding of diffusion model
approaches remains underdeveloped. In this work, we develop convergence
guarantees for diffusion language models from an information-theoretic
perspective. Our analysis demonstrates that the sampling error, measured by the
Kullback-Leibler (KL) divergence, decays inversely with the number of
iterations $T$ and scales linearly with the mutual information between tokens
in the target text sequence. In particular, we establish matching upper and
lower bounds, up to some constant factor, to demonstrate the tightness of our
convergence analysis. These results offer novel theoretical insights into the
practical effectiveness of diffusion language models.

</details>


### [42] [Prot2Token: A Unified Framework for Protein Modeling via Next-Token Prediction](https://arxiv.org/abs/2505.20589)
*Mahdi Pourmirzaei, Farzaneh Esmaili, Salhuldin Alqarghuli, Mohammadreza Pourmirzaei, Ye Han, Kai Chen, Mohsen Rezaei, Duolin Wang, Dong Xu*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种名为Prot2Token的统一框架，将各种蛋白质相关预测任务转换为标准化的下一个标记预测格式。通过使用自回归解码器和可学习的任务标记，该框架能够在单一模型中实现多任务学习，显著提高效率并匹配或超越专门方法的性能。此外，还引入了辅助的自我监督解码器预训练方法以改善空间敏感任务的表现。


<details>
  <summary>更多</summary>
  
**动机:** 蛋白质预测任务的多样性传统上需要专用模型，这阻碍了广泛适用且计算高效的蛋白质语言模型的发展。

**方法:** Prot2Token是一个统一框架，它通过将蛋白质相关预测（从序列级属性到复杂的蛋白质间相互作用）转化为标准化的下一个标记预测格式，克服了这一挑战。其核心是一个自回归解码器，基于预训练蛋白质编码器的嵌入，并由可学习的任务标记引导，执行多样化的预测。此架构支持多任务学习，允许单个模型掌握多项任务。

**结果:** 实验验证表明Prot2Token在不同类型的蛋白质预测任务中具有强大的预测能力，包括显著的速度提升（如与AlphaFold2相比近1000倍加速）以及通常与专业方法相匹配或超越的性能。

**结论:** Prot2Token提供了一个重要的步骤，朝着多功能、高通量的蛋白质建模范式迈进，有望加速生物发现和新型治疗剂的开发。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Prot2Token%3A+A+Unified+Framework+for+Protein+Modeling+via+Next-Token+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20589，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20589&send_immediately=true&force_search=false)

**原文摘要:** The diverse nature of protein prediction tasks has traditionally necessitated
specialized models, hindering the development of broadly applicable and
computationally efficient Protein Language Models (PLMs). In this work, we
introduce Prot2Token, a unified framework that overcomes these challenges by
converting a wide spectrum of protein-related predictions, from sequence-level
properties and residue-specific attributes to complex inter-protein
interactions, into a standardized next-token prediction format. At its core,
Prot2Token employs an autoregressive decoder, conditioned on embeddings from
pre-trained protein encoders and guided by learnable task tokens, to perform
diverse predictions. This architecture uniquely facilitates multi-task
learning, enabling a single model to master numerous tasks with improved
efficiency. We present extensive experimental validation across a variety of
benchmarks, demonstrating Prot2Tokens strong predictive power in different
types of protein-prediction tasks. Key results include significant speedups
(e.g., near 1000x over AlphaFold2 with MSA) and performance often matching or
exceeding specialized approaches. Beyond that, we introduce an auxiliary
self-supervised decoder pre-training approach to improve spatially sensitive
task performance. Prot2Token thus offers a significant step towards a
versatile, high-throughput paradigm for protein modeling, promising to
accelerate biological discovery and the development of novel therapeutics. The
code is available at https://github.com/mahdip72/prot2token .

</details>


### [43] [Conflicting Biases at the Edge of Stability: Norm versus Sharpness Regularization](https://arxiv.org/abs/2505.21423)
*Vit Fojtik, Maria Matveev, Hung-Hsu Chou, Gitta Kutyniok, Johannes Maly*

**主要类别:** cs.LG

**概要:** 本研究探讨了梯度下降算法在神经网络训练中的隐式正则化作用，强调学习率在平衡参数范数和模型锐度之间的关键角色，并证明单一的隐式偏差不足以解释良好的泛化性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的研究表明，优化算法（如梯度下降）通过隐式偏差引导神经网络趋向于良性的解，但这些研究通常假设学习率趋近于零，忽略了实际中较大的学习率对训练过程的影响。因此，需要更全面地理解不同形式的隐式正则化如何共同作用以影响模型的泛化能力。

**方法:** 通过理论分析和实证研究相结合的方法，作者考察了不同学习率对模型参数范数和锐度的影响，并使用对角线性网络进行回归任务实验，证明单一形式的隐式偏差不足以最小化泛化误差。

**结果:** 实验表明，学习率在平衡模型参数范数和锐度方面起到重要作用；理论上证明，仅依靠某一种隐式偏差无法实现最优的泛化性能。

**结论:** 为了更好地理解梯度下降的泛化性能，需要从动态权衡的角度看待隐式正则化，综合考虑参数范数和模型锐度的作用，而非局限于单一形式的隐式偏差。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Conflicting+Biases+at+the+Edge+of+Stability%3A+Norm+versus+Sharpness+Regularization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21423，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21423&send_immediately=true&force_search=false)

**原文摘要:** A widely believed explanation for the remarkable generalization capacities of
overparameterized neural networks is that the optimization algorithms used for
training induce an implicit bias towards benign solutions. To grasp this
theoretically, recent works examine gradient descent and its variants in
simplified training settings, often assuming vanishing learning rates. These
studies reveal various forms of implicit regularization, such as $\ell_1$-norm
minimizing parameters in regression and max-margin solutions in classification.
Concurrently, empirical findings show that moderate to large learning rates
exceeding standard stability thresholds lead to faster, albeit oscillatory,
convergence in the so-called Edge-of-Stability regime, and induce an implicit
bias towards minima of low sharpness (norm of training loss Hessian). In this
work, we argue that a comprehensive understanding of the generalization
performance of gradient descent requires analyzing the interaction between
these various forms of implicit regularization. We empirically demonstrate that
the learning rate balances between low parameter norm and low sharpness of the
trained model. We furthermore prove for diagonal linear networks trained on a
simple regression task that neither implicit bias alone minimizes the
generalization error. These findings demonstrate that focusing on a single
implicit bias is insufficient to explain good generalization, and they motivate
a broader view of implicit regularization that captures the dynamic trade-off
between norm and sharpness induced by non-negligible learning rates.

</details>


### [44] [Multi-level Certified Defense Against Poisoning Attacks in Offline Reinforcement Learning](https://arxiv.org/abs/2505.20621)
*Shijie Liu, Andrew C. Cullen, Paul Montague, Sarah Erfani, Benjamin I. P. Rubinstein*

**主要类别:** cs.LG

**概要:** 线下强化学习（RL）容易受到数据投毒攻击，本文提出利用差分隐私特性扩展认证防御方法，提高对对抗性操控的鲁棒性，适用于连续和离散空间以及随机和确定性环境。实验表明，该方法在高达7%的训练数据被投毒时，性能下降不超过50%，显著优于先前工作。


<details>
  <summary>更多</summary>
  
**动机:** 线下强化学习依赖外部数据集，容易受到投毒攻击，其顺序性质加剧了这一漏洞。因此，需要一种方法来增强其对对抗性操控的鲁棒性。

**方法:** 通过扩展认证防御方法，利用差分隐私的特性，提供更大的对抗性操控保证，确保每状态动作和整体预期累积奖励的鲁棒性。这种方法适用于连续和离散空间，以及随机和确定性环境。

**结果:** 实证评估显示，当高达7%的训练数据被投毒时，性能下降不超过50%，相比之前的工作有显著提升，且认证半径是之前的5倍。

**结论:** 所提出的方法能够显著提高线下强化学习的安全性和可靠性，具有广泛的应用前景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-level+Certified+Defense+Against+Poisoning+Attacks+in+Offline+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20621，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20621&send_immediately=true&force_search=false)

**原文摘要:** Similar to other machine learning frameworks, Offline Reinforcement Learning
(RL) is shown to be vulnerable to poisoning attacks, due to its reliance on
externally sourced datasets, a vulnerability that is exacerbated by its
sequential nature. To mitigate the risks posed by RL poisoning, we extend
certified defenses to provide larger guarantees against adversarial
manipulation, ensuring robustness for both per-state actions, and the overall
expected cumulative reward. Our approach leverages properties of Differential
Privacy, in a manner that allows this work to span both continuous and discrete
spaces, as well as stochastic and deterministic environments -- significantly
expanding the scope and applicability of achievable guarantees. Empirical
evaluations demonstrate that our approach ensures the performance drops to no
more than $50\%$ with up to $7\%$ of the training data poisoned, significantly
improving over the $0.008\%$ in prior work~\citep{wu_copa_2022}, while
producing certified radii that is $5$ times larger as well. This highlights the
potential of our framework to enhance safety and reliability in offline RL.

</details>


### [45] [High-Dimensional Calibration from Swap Regret](https://arxiv.org/abs/2505.21460)
*Maxwell Fishelson, Noah Golowich, Mehryar Mohri, Jon Schneider*

**主要类别:** cs.LG

**概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是High-Dimensional+Calibration+from+Swap+Regret，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21460，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21460&send_immediately=true&force_search=false)

**原文摘要:** We study the online calibration of multi-dimensional forecasts over an
arbitrary convex set $\mathcal{P} \subset \mathbb{R}^d$ relative to an
arbitrary norm $\Vert\cdot\Vert$. We connect this with the problem of external
regret minimization for online linear optimization, showing that if it is
possible to guarantee $O(\sqrt{\rho T})$ worst-case regret after $T$ rounds
when actions are drawn from $\mathcal{P}$ and losses are drawn from the dual
$\Vert \cdot \Vert_*$ unit norm ball, then it is also possible to obtain
$\epsilon$-calibrated forecasts after $T = \exp(O(\rho /\epsilon^2))$ rounds.
When $\mathcal{P}$ is the $d$-dimensional simplex and $\Vert \cdot \Vert$ is
the $\ell_1$-norm, the existence of $O(\sqrt{T\log d})$-regret algorithms for
learning with experts implies that it is possible to obtain
$\epsilon$-calibrated forecasts after $T = \exp(O(\log{d}/\epsilon^2)) =
d^{O(1/\epsilon^2)}$ rounds, recovering a recent result of Peng (2025).
  Interestingly, our algorithm obtains this guarantee without requiring access
to any online linear optimization subroutine or knowledge of the optimal rate
$\rho$ -- in fact, our algorithm is identical for every setting of
$\mathcal{P}$ and $\Vert \cdot \Vert$. Instead, we show that the optimal
regularizer for the above OLO problem can be used to upper bound the above
calibration error by a swap regret, which we then minimize by running the
recent TreeSwap algorithm with Follow-The-Leader as a subroutine.
  Finally, we prove that any online calibration algorithm that guarantees
$\epsilon T$ $\ell_1$-calibration error over the $d$-dimensional simplex
requires $T \geq \exp(\mathrm{poly}(1/\epsilon))$ (assuming $d \geq
\mathrm{poly}(1/\epsilon)$). This strengthens the corresponding
$d^{\Omega(\log{1/\epsilon})}$ lower bound of Peng, and shows that an
exponential dependence on $1/\epsilon$ is necessary.

</details>


### [46] [Position: Adopt Constraints Over Penalties in Deep Learning](https://arxiv.org/abs/2505.20628)
*Juan Ramirez, Meraj Hashemizadeh, Simon Lacoste-Julien*

**主要类别:** cs.LG

**概要:** 近期关于开发具有问责制保证的可信AI系统的努力，促使机器学习方法越来越多地纳入外部需求或约束。传统的惩罚方法存在不足，而定制的约束优化方法（如拉格朗日方法）能更好地满足约束并提高性能，同时减少调参成本，并与现代深度学习管道无缝集成。


<details>
  <summary>更多</summary>
  
**动机:** 当前在开发可信赖AI系统时，越来越依赖于将外部需求或约束纳入机器学习模型中。然而，传统的通过惩罚项加入固定权重的方法存在局限性，可能无法同时满足约束条件和实现良好性能，且调整这些权重系数耗费时间和计算资源。

**方法:** 建议采用定制的约束优化方法，例如拉格朗日方法。该方法不仅优化模型参数，还同时优化惩罚“系数”（即拉格朗日乘子），从而真正解决约束问题，增强模型的问责能力，无需大量调整惩罚系数，并能与现代深度学习流程无缝结合。

**结果:** 定制的约束优化方法能够更有效地解决约束问题，提升模型性能，减少调参所需的时间和计算开销，同时与现代深度学习技术兼容良好。

**结论:** 为了构建更可靠的AI系统，应放弃传统简单的惩罚方法，转而使用如拉格朗日方法等定制的约束优化方法，以更好地满足约束条件、提高性能并降低调参成本。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Position%3A+Adopt+Constraints+Over+Penalties+in+Deep+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20628，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20628&send_immediately=true&force_search=false)

**原文摘要:** Recent efforts toward developing trustworthy AI systems with accountability
guarantees have led to a growing reliance on machine learning formulations that
incorporate external requirements, or constraints. These requirements are often
enforced through penalization--adding fixed-weight terms to the task loss. We
argue that this approach is ill-suited, and that tailored constrained
optimization methods should be adopted instead. In particular, no penalty
coefficient may yield a solution that both satisfies the constraints and
achieves good performance--i.e., one solving the constrained problem. Moreover,
tuning these coefficients is costly, incurring significant time and
computational overhead. In contrast, tailored constrained methods--such as the
Lagrangian approach, which optimizes the penalization "coefficients" (the
Lagrange multipliers) alongside the model--(i) truly solve the constrained
problem and add accountability, (ii) eliminate the need for extensive penalty
tuning, and (iii) integrate seamlessly with modern deep learning pipelines.

</details>


### [47] [Causal Posterior Estimation](https://arxiv.org/abs/2505.21468)
*Simon Dirmeier, Antonietta Mira*

**主要类别:** cs.LG

**概要:** 本论文提出了一种名为因果后验估计（CPE）的新方法，用于在模拟器模型中进行贝叶斯推理。该方法通过将图形模型的条件依赖结构纳入神经网络来改进近似精度，并引入了离散和连续归一化流架构，以实现高效的后验推断。


<details>
  <summary>更多</summary>
  
**动机:** 现有的贝叶斯推理方法在处理模拟器模型时面临似然函数难以计算或计算成本过高的问题，因此需要一种新的方法来解决这些问题。

**方法:** CPE使用基于归一化流（NF）的后验分布近似方法，将图形模型的条件依赖结构整合到神经网络中。同时，提出了离散和连续NF架构，并为连续情况设计了固定时间采样过程，从而降低采样复杂度至O(1)。

**结果:** 通过广泛的实验评估，CPE展示了其能够通过直接将图形模型的条件依赖性纳入神经网络，而不是从数据中学习它们，从而实现高精度的后验推断，超越或匹配领域内的现有最佳方法。

**结论:** CPE是一种有效的贝叶斯推理方法，特别适用于似然函数难以计算或计算代价高昂的模拟器模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Causal+Posterior+Estimation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21468，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21468&send_immediately=true&force_search=false)

**原文摘要:** We present Causal Posterior Estimation (CPE), a novel method for Bayesian
inference in simulator models, i.e., models where the evaluation of the
likelihood function is intractable or too computationally expensive, but where
one can simulate model outputs given parameter values. CPE utilizes a
normalizing flow-based (NF) approximation to the posterior distribution which
carefully incorporates the conditional dependence structure induced by the
graphical representation of the model into the neural network. Thereby it is
possible to improve the accuracy of the approximation. We introduce both
discrete and continuous NF architectures for CPE and propose a constant-time
sampling procedure for the continuous case which reduces the computational
complexity of drawing samples to O(1) as for discrete NFs. We show, through an
extensive experimental evaluation, that by incorporating the conditional
dependencies induced by the graphical model directly into the neural network,
rather than learning them from data, CPE is able to conduct highly accurate
posterior inference either outperforming or matching the state of the art in
the field.

</details>


### [48] [Can Past Experience Accelerate LLM Reasoning?](https://arxiv.org/abs/2505.20643)
*Bo Pan, Liang Zhao*

**主要类别:** cs.LG

**概要:** 通过反复暴露于相关任务，大型语言模型（LLMs）可以加速推理过程并减少计算成本。本文提出了SpeedupLLM框架，实验表明，配备适当的内存和推理方法时，计算成本最多可降低56%。


<details>
  <summary>更多</summary>
  
**动机:** 尽管分配更多计算资源能提升LLMs的效果，但也会增加推理时间。而人类可以通过经验和接触提高任务效率。因此，研究LLMs是否也能通过反复暴露于相关任务来加快推理速度是有意义的。

**方法:** 首先系统地在任务相关性和计算预算计算的维度上形式化了LLM推理加速的问题设定，然后提出了SpeedupLLM框架，基于自适应计算分配和内存机制实现和基准推理加速行为，并进行了全面的实验来评估不同问题相似度、内存方法和推理方法下的表现。

**结果:** 实验结果表明，LLMs通常能够凭借过往经验更快地进行推理，当配备合适的内存和推理方法时，计算成本最多可降低56%。

**结论:** LLMs可以通过过往经验加速推理过程，SpeedupLLM框架提供了一种理论保证的方法来实现这一目标，显著减少了计算成本。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Can+Past+Experience+Accelerate+LLM+Reasoning%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20643，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20643&send_immediately=true&force_search=false)

**原文摘要:** Allocating more compute to large language models (LLMs) reasoning has
generally been demonstrated to improve their effectiveness, but also results in
increased inference time. In contrast, humans can perform tasks faster and
better with increased experience and exposure. Hence, this paper aims to
investigate the question: Can LLMs also become faster at reasoning through
recurrent exposure on relevant tasks, and if so, how can it be achieved? To
address these questions, we first formalize the problem setting of LLM
reasoning speedup systematically in the dimensions of task relevancy and
compute budget calculation. We then propose SpeedupLLM, a theoretically
guaranteed framework to implement and benchmark such reasoning speedup
behaviour based on adaptive compute allocation and memory mechanisms. We
further conduct comprehensive experiments to benchmark such behaviour across
different question similarity levels, memory methods, and reasoning methods.
Results show that LLMs can generally reason faster with past experience,
achieving up to a 56% reduction in compute cost when equipped with appropriate
memory and reasoning methods.

</details>


### [49] [Evaluating Training in Binarized Neural Networks Through the Lens of Algorithmic Information Theory](https://arxiv.org/abs/2505.20646)
*Eduardo Y. Sakabe, Felipe S. Abrahão, Alexandre Simões, Esther Colombini, Paula Costa, Ricardo Gudwin, Hector Zenil*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种基于算法信息理论的方法，使用二值化神经网络（BNNs）作为代理，通过块分解法（BDM）来近似计算训练过程中的算法复杂度。研究表明，该方法能够更好地追踪结构变化并解释学习过程为一种算法压缩的过程。


<details>
  <summary>更多</summary>
  
**动机:** 当前大多数衡量神经网络复杂性的方法依赖于熵和统计指标，但这些方法往往无法捕捉网络结构中更深层次的因果相关规律。因此，需要探索新的理论框架来理解和控制神经网络的信息复杂性。

**方法:** 作者引入了算法信息理论，并以二值化神经网络（BNNs）为初步代理模型，利用算法概率（AP）及其定义的通用分布，通过块分解法（BDM）来近似评估算法复杂度。这种方法被用于表征学习动态，并与传统熵基方法进行对比。

**结果:** 实验表明，块分解法（BDM）在不同模型大小和随机训练运行中，比熵更能密切跟踪训练期间的结构变化，并且与训练损失表现出更强的相关性。这支持了将训练视为算法压缩过程的观点。

**结论:** 本研究提供了一个基于信息论、复杂性和可计算性原理的框架，用以评估学习进展并实现复杂性感知的学习和正则化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Evaluating+Training+in+Binarized+Neural+Networks+Through+the+Lens+of+Algorithmic+Information+Theory，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20646，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20646&send_immediately=true&force_search=false)

**原文摘要:** Understanding and controlling the informational complexity of neural networks
is a central challenge in machine learning, with implications for
generalization, optimization, and model capacity. While most approaches rely on
entropy-based loss functions and statistical metrics, these measures often fail
to capture deeper, causally relevant algorithmic regularities embedded in
network structure. We propose a shift toward algorithmic information theory,
using Binarized Neural Networks (BNNs) as a first proxy. Grounded in
algorithmic probability (AP) and the universal distribution it defines, our
approach characterizes learning dynamics through a formal, causally grounded
lens. We apply the Block Decomposition Method (BDM) -- a scalable approximation
of algorithmic complexity based on AP -- and demonstrate that it more closely
tracks structural changes during training than entropy, consistently exhibiting
stronger correlations with training loss across varying model sizes and
randomized training runs. These results support the view of training as a
process of algorithmic compression, where learning corresponds to the
progressive internalization of structured regularities. In doing so, our work
offers a principled estimate of learning progression and suggests a framework
for complexity-aware learning and regularization, grounded in first principles
from information theory, complexity, and computability.

</details>


### [50] [Voronoi-grid-based Pareto Front Learning and Its Application to Collaborative Federated Learning](https://arxiv.org/abs/2505.20648)
*Mengmeng Chen, Xiaohu Wu, Qiqi Liu, Tiantian He, Yew-Soon Ong, Yaochu Jin, Qicheng Lao, Han Yu*

**主要类别:** cs.LG

**概要:** 本论文提出了一种新的Pareto-Front Learning框架PHN-HVVS，通过分解设计空间为Voronoi网格并使用遗传算法进行分区，解决了高维空间中采样光线和覆盖整个凸形Pareto前沿的挑战。实验结果表明PHN-HVVS在生成Pareto前沿方面显著优于基线方法，并推进了联邦学习领域的最新技术。


<details>
  <summary>更多</summary>
  
**动机:** 多目标优化（MOO）在机器学习中广泛存在，特别是在联邦学习领域。现有的Pareto-Front Learning方法在高维空间采样和覆盖整个凸形Pareto前沿方面存在不足，因此需要一种新的方法来解决这些问题。

**方法:** 论文提出了PHN-HVVS框架，该框架将设计空间分解为Voronoi网格，并使用遗传算法进行Voronoi网格分区。此外，还引入了一个新的损失函数，以扩大生成的Pareto前沿的覆盖率并最大化HV指标。

**结果:** 实验结果表明，PHN-HVVS在多个MOO机器学习任务中显著优于基线方法，能够更广泛地覆盖Pareto前沿并最大化HV指标。同时，PHN-HVVS推进了联邦学习领域中的几种最近问题的方法论。

**结论:** PHN-HVVS是一种有效的Pareto-Front Learning框架，解决了现有方法在高维空间采样和覆盖整个Pareto前沿方面的不足，为联邦学习领域提供了新的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Voronoi-grid-based+Pareto+Front+Learning+and+Its+Application+to+Collaborative+Federated+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20648，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20648&send_immediately=true&force_search=false)

**原文摘要:** Multi-objective optimization (MOO) exists extensively in machine learning,
and aims to find a set of Pareto-optimal solutions, called the Pareto front,
e.g., it is fundamental for multiple avenues of research in federated learning
(FL). Pareto-Front Learning (PFL) is a powerful method implemented using
Hypernetworks (PHNs) to approximate the Pareto front. This method enables the
acquisition of a mapping function from a given preference vector to the
solutions on the Pareto front. However, most existing PFL approaches still face
two challenges: (a) sampling rays in high-dimensional spaces; (b) failing to
cover the entire Pareto Front which has a convex shape. Here, we introduce a
novel PFL framework, called as PHN-HVVS, which decomposes the design space into
Voronoi grids and deploys a genetic algorithm (GA) for Voronoi grid
partitioning within high-dimensional space. We put forward a new loss function,
which effectively contributes to more extensive coverage of the resultant
Pareto front and maximizes the HV Indicator. Experimental results on multiple
MOO machine learning tasks demonstrate that PHN-HVVS outperforms the baselines
significantly in generating Pareto front. Also, we illustrate that PHN-HVVS
advances the methodologies of several recent problems in the FL field. The code
is available at
https://github.com/buptcmm/phnhvvs}{https://github.com/buptcmm/phnhvvs.

</details>


### [51] [An Optimisation Framework for Unsupervised Environment Design](https://arxiv.org/abs/2505.20659)
*Nathan Monette, Alistair Letcher, Michael Beukman, Matthew T. Jackson, Alexander Rutherford, Alexander D. Goldie, Jakob N. Foerster*

**主要类别:** cs.LG

**概要:** 本论文从优化的角度研究了无监督环境设计（UED），提供比以往工作更强的理论保证，并提出在零和情况下可证明收敛的算法，通过实验验证了其在多种环境中的优越性。


<details>
  <summary>更多</summary>
  
**动机:** 强化学习智能体需要在高风险环境中部署时具备对不熟悉场景的高度鲁棒性，而提高鲁棒性的方法之一是无监督环境设计（UED）。

**方法:** 作者采用优化视角研究UED，构建了一个非凸强凹目标函数框架，并为该目标提供了在零和情况下的可证明收敛的算法。

**结果:** 在多个不同难度的环境中，该方法的表现优于先前的方法。

**结论:** 通过优化角度分析UED并提供更强理论保证，提出的算法在实践中有效提升了智能体的泛化能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Optimisation+Framework+for+Unsupervised+Environment+Design，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20659，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20659&send_immediately=true&force_search=false)

**原文摘要:** For reinforcement learning agents to be deployed in high-risk settings, they
must achieve a high level of robustness to unfamiliar scenarios. One method for
improving robustness is unsupervised environment design (UED), a suite of
methods aiming to maximise an agent's generalisability across configurations of
an environment. In this work, we study UED from an optimisation perspective,
providing stronger theoretical guarantees for practical settings than prior
work. Whereas previous methods relied on guarantees if they reach convergence,
our framework employs a nonconvex-strongly-concave objective for which we
provide a provably convergent algorithm in the zero-sum setting. We empirically
verify the efficacy of our method, outperforming prior methods in a number of
environments with varying difficulties.

</details>


### [52] [Continuous-Time Attention: PDE-Guided Mechanisms for Long-Sequence Transformers](https://arxiv.org/abs/2505.20666)
*Yukun Zhang, Xueqing Zhou*

**主要类别:** cs.LG

**概要:** 提出了一种新的框架，Continuous_Time Attention，将偏微分方程（PDEs）融入Transformer的注意力机制，以处理极长输入序列的挑战。该方法通过扩散、波动或反应-扩散动力学在伪时间维度上使注意力权重进化，从而系统地平滑局部噪声，增强远程依赖，并稳定梯度流。理论上，PDE基础的注意力导致更优的优化景观和多项式而非指数衰减的远距离交互。实证上，在不同实验中展示了对标准和专门的长序列Transformer变体的一致改进。研究结果强调了基于PDE的公式通过连续时间动态和全局连贯性丰富注意力机制的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 极长输入序列给传统的Transformer带来了挑战，例如难以捕捉长距离依赖关系和梯度不稳定等问题。为了解决这些问题，需要一种能够更好地处理这些挑战的新方法。

**方法:** 提出了一个名为Continuous_Time Attention的新框架，该框架将偏微分方程（PDEs）整合到Transformer的注意力机制中。与仅依赖静态注意力矩阵的传统方法不同，此方法允许注意力权重通过扩散、波动或反应-扩散动力学在一个伪时间维度上进行演变。

**结果:** 理论分析表明，PDE基础的注意力机制能带来更好的优化景观以及多项式而非指数衰减的远距离交互。实证结果显示，该方法在多个实验中对标准和专门的长序列Transformer变体均显示出一致的性能提升。

**结论:** 研究表明，基于PDE的公式具有通过引入连续时间动态和全局连贯性来丰富注意力机制的潜力，这可能成为未来解决长序列问题的一个重要方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Continuous-Time+Attention%3A+PDE-Guided+Mechanisms+for+Long-Sequence+Transformers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20666，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20666&send_immediately=true&force_search=false)

**原文摘要:** We propose a novel framework, Continuous_Time Attention, which infuses
partial differential equations (PDEs) into the Transformer's attention
mechanism to address the challenges of extremely long input sequences. Instead
of relying solely on a static attention matrix, we allow attention weights to
evolve over a pseudo_time dimension via diffusion, wave, or reaction_diffusion
dynamics. This mechanism systematically smooths local noise, enhances
long_range dependencies, and stabilizes gradient flow. Theoretically, our
analysis shows that PDE_based attention leads to better optimization landscapes
and polynomial rather than exponential decay of distant interactions.
Empirically, we benchmark our method on diverse experiments_demonstrating
consistent gains over both standard and specialized long sequence Transformer
variants. Our findings highlight the potential of PDE_based formulations to
enrich attention mechanisms with continuous_time dynamics and global coherence.

</details>


### [53] [Accelerating RL for LLM Reasoning with Optimal Advantage Regression](https://arxiv.org/abs/2505.20686)
*Kianté Brantley, Mingyu Chen, Zhaolin Gao, Jason D. Lee, Wen Sun, Wenhao Zhan, Xuezhou Zhang*

**主要类别:** cs.LG

**概要:** 提出了一种新的两阶段策略优化框架$A$*-PO，通过离线采样和单次生成进行高效训练，减少计算开销和内存使用，同时在数学推理基准上表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 强化学习（RL）是改进大语言模型复杂推理能力的强大工具，但现有的策略优化方法存在高计算开销和内存消耗的问题。

**方法:** 提出了$A$*-PO框架，第一阶段通过参考策略的离线采样估计最优值函数$V$*，第二阶段使用单次生成和最小二乘回归损失进行策略更新。

**结果:** 理论上证明了性能保证和优化KL正则化RL目标的可能性；实验上，在多个数学推理基准上表现优异，相比PPO、GRPO和REBEL，训练时间减少2倍，峰值内存使用减少30%以上。

**结论:** $A$*-PO提供了一种高效的策略优化方法，适用于大语言模型的推理任务训练，且无需复杂的探索策略。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Accelerating+RL+for+LLM+Reasoning+with+Optimal+Advantage+Regression，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20686，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20686&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement learning (RL) has emerged as a powerful tool for fine-tuning
large language models (LLMs) to improve complex reasoning abilities. However,
state-of-the-art policy optimization methods often suffer from high
computational overhead and memory consumption, primarily due to the need for
multiple generations per prompt and the reliance on critic networks or
advantage estimates of the current policy. In this paper, we propose $A$*-PO, a
novel two-stage policy optimization framework that directly approximates the
optimal advantage function and enables efficient training of LLMs for reasoning
tasks. In the first stage, we leverage offline sampling from a reference policy
to estimate the optimal value function $V$*, eliminating the need for costly
online value estimation. In the second stage, we perform on-policy updates
using a simple least-squares regression loss with only a single generation per
prompt. Theoretically, we establish performance guarantees and prove that the
KL-regularized RL objective can be optimized without requiring complex
exploration strategies. Empirically, $A$*-PO achieves competitive performance
across a wide range of mathematical reasoning benchmarks, while reducing
training time by up to 2$\times$ and peak memory usage by over 30% compared to
PPO, GRPO, and REBEL. Implementation of $A$*-PO can be found at
https://github.com/ZhaolinGao/A-PO.

</details>


### [54] [Evidential Deep Active Learning for Semi-Supervised Classification](https://arxiv.org/abs/2505.20691)
*Shenkai Zhao, Xinao Zhang, Lipeng Pan, Xiaobin Xu, Danilo Pelusi*

**主要类别:** cs.LG

**概要:** 论文提出了一种基于证据的深度主动学习方法（EDALSSC），用于半监督分类，通过量化标记和未标记数据的不确定性估计，动态平衡证据和类别数量的影响，并在训练后期选择具有最大不确定性估计的样本。实验表明，该方法在图像分类数据集上优于现有的半监督和监督主动学习方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有半监督分类方法在主动学习过程中往往忽略预测结果的不确定性估计（或可靠性），这可能导致所选样本无法有效更新模型。

**方法:** 1. 构建半监督学习框架，在学习过程中同时量化标记和未标记数据的不确定性估计。
2. 标记数据的不确定性估计与证据深度学习相关，未标记数据的不确定性估计通过结合无知信息和冲突信息进行建模。
3. 构造启发式方法，动态平衡证据和类别数量对不确定性估计的影响。
4. 在训练后期，当训练损失增加时，选择具有最大不确定性估计的样本（以总和形式计算）。

**结果:** 实验结果表明，EDALSSC在图像分类数据集上优于现有的半监督和监督主动学习方法。

**结论:** EDALSSC能够有效提高半监督分类任务的性能，特别是在图像分类领域。其通过量化不确定性估计和优化样本选择策略，显著改进了模型的效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Evidential+Deep+Active+Learning+for+Semi-Supervised+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20691，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20691&send_immediately=true&force_search=false)

**原文摘要:** Semi-supervised classification based on active learning has made significant
progress, but the existing methods often ignore the uncertainty estimation (or
reliability) of the prediction results during the learning process, which makes
it questionable whether the selected samples can effectively update the model.
Hence, this paper proposes an evidential deep active learning approach for
semi-supervised classification (EDALSSC). EDALSSC builds a semi-supervised
learning framework to simultaneously quantify the uncertainty estimation of
labeled and unlabeled data during the learning process. The uncertainty
estimation of the former is associated with evidential deep learning, while
that of the latter is modeled by combining ignorance information and conflict
information of the evidence from the perspective of the T-conorm operator.
Furthermore, this article constructs a heuristic method to dynamically balance
the influence of evidence and the number of classes on uncertainty estimation
to ensure that it does not produce counter-intuitive results in EDALSSC. For
the sample selection strategy, EDALSSC selects the sample with the greatest
uncertainty estimation that is calculated in the form of a sum when the
training loss increases in the latter half of the learning process.
Experimental results demonstrate that EDALSSC outperforms existing
semi-supervised and supervised active learning approaches on image
classification datasets.

</details>


### [55] [Sparsified State-Space Models are Efficient Highway Networks](https://arxiv.org/abs/2505.20698)
*Woomin Song, Jihoon Tack, Sangwoo Mo, Seunghyuk Oh, Jinwoo Shin*

**主要类别:** cs.LG

**概要:** Simba是一种用于SSMs的分层稀疏化方法，通过在上层构建类似高速公路的信息传递机制，减少冗余并增强长序列信息流。相比Mamba，Simba在相同FLOPS下表现更优，并提升了自然语言任务中的效率和性能。


<details>
  <summary>更多</summary>
  
**动机:** 状态空间模型（SSMs）中的令牌由于渐进递归更新而高度冗余，密集的递归操作阻碍了过去信息的传递。高层编码全局信息更易冗余，低层编码局部信息则较少冗余。基于此，需要一种方法来优化SSMs的计算效率和信息传递能力。

**方法:** 提出Simba方法，基于令牌修剪对SSMs进行分层稀疏化。Simba对高层进行更多稀疏化以构建类似高速公路的行为，同时提出一种新的令牌修剪标准，通过累积局部递归来衡量令牌对最终输出的全局影响。

**结果:** Simba在相同的浮点运算次数（FLOPS）下优于基线模型Mamba，在多种自然语言任务中表现出色。实验还表明Simba不仅提高了效率，还改善了长序列中的信息流动。

**结论:** Simba通过分层稀疏化显著增强了SSMs的性能和效率，尤其在处理长序列时表现出更好的信息传递能力，为序列建模提供了一种有效替代方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sparsified+State-Space+Models+are+Efficient+Highway+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20698，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20698&send_immediately=true&force_search=false)

**原文摘要:** State-space models (SSMs) offer a promising architecture for sequence
modeling, providing an alternative to Transformers by replacing expensive
self-attention with linear recurrences. In this paper, we propose a simple yet
effective trick to enhance SSMs within given computational budgets by
sparsifying them. Our intuition is that tokens in SSMs are highly redundant due
to gradual recurrent updates, and dense recurrence operations block the
delivery of past information. In particular, we observe that upper layers of
SSMs tend to be more redundant as they encode global information, while lower
layers encode local information. Motivated by this, we introduce Simba, a
hierarchical sparsification method for SSMs based on token pruning. Simba
sparsifies upper layers more than lower layers, encouraging the upper layers to
behave like highways. To achieve this, we propose a novel token pruning
criterion for SSMs, measuring the global impact of tokens on the final output
by accumulating local recurrences. We demonstrate that Simba outperforms the
baseline model, Mamba, with the same FLOPS in various natural language tasks.
Moreover, we illustrate the effect of highways, showing that Simba not only
enhances efficiency but also improves the information flow across long
sequences. Code is available at https://github.com/woominsong/Simba.

</details>


### [56] [Are Data Embeddings effective in time series forecasting?](https://arxiv.org/abs/2505.20716)
*Reza Nematirad, Anil Pahwa, Balasubramaniam Natarajan*

**主要类别:** cs.LG

**概要:** 通过广泛的消融研究，发现移除数据嵌入层不会降低预测性能，反而能提升准确性和计算效率。


<details>
  <summary>更多</summary>
  
**动机:** 评估数据嵌入技术在时间序列预测中的实际效果，因为近年来的先进模型虽然架构创新但改进幅度很小。

**方法:** 在十五个先进模型和四个基准数据集上进行广泛的消融研究，移除数据嵌入层后观察预测性能的变化。

**结果:** 移除数据嵌入层不仅没有降低预测性能，在许多情况下还提高了准确性和计算效率。

**结论:** 数据嵌入技术在时间序列预测中并非必要，移除它可以带来显著的性能提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Are+Data+Embeddings+effective+in+time+series+forecasting%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20716，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20716&send_immediately=true&force_search=false)

**原文摘要:** Time series forecasting plays a crucial role in many real-world applications,
and numerous complex forecasting models have been proposed in recent years.
Despite their architectural innovations, most state-of-the-art models report
only marginal improvements -- typically just a few thousandths in standard
error metrics. These models often incorporate complex data embedding layers to
transform raw inputs into higher-dimensional representations to enhance
accuracy. But are data embedding techniques actually effective in time series
forecasting? Through extensive ablation studies across fifteen state-of-the-art
models and four benchmark datasets, we find that removing data embedding layers
from many state-of-the-art models does not degrade forecasting performance. In
many cases, it improves both accuracy and computational efficiency. The gains
from removing embedding layers often exceed the performance differences
typically reported between competing models. Code available at:
https://github.com/neuripsdataembedidng/DataEmbedding

</details>


### [57] [Recurrent Neural Operators: Stable Long-Term PDE Prediction](https://arxiv.org/abs/2505.20721)
*Zaijun Ye, Chen-Song Zhang, Wansheng Wang*

**主要类别:** cs.LG

**概要:** 本研究提出了一种新的框架——循环神经算子（RNOs），通过在训练过程中模拟推理时的动力学特性，解决了时间相关问题中因训练和推理不匹配而导致的误差累积问题。理论上证明了循环训练可以降低误差增长，并且实验证明了其长期预测的准确性和稳定性显著优于传统方法。


<details>
  <summary>更多</summary>
  
**动机:** 时间相关问题中的标准训练策略（如教师强制）会在训练和推理之间引入不匹配，从而导致长期自回归预测中的误差累积。为了解决这一问题，需要一种能够更好地模拟推理过程的训练方法。

**方法:** 提出了RNOs框架，将循环训练整合到神经算子架构中。该方法通过在时间窗口内递归应用算子到自身的预测结果，而不是依赖于真实输入数据，从而在训练中有效模拟推理时的动力学特性。

**结果:** 理论上，证明了循环训练可以将教师强制下的指数误差增长降低为线性增长；实验上，在标准基准测试中，循环训练的多网格神经算子在长期准确性和稳定性方面明显优于传统的教师强制训练方法。

**结论:** 通过使训练与推理动力学保持一致，RNOs提高了神经算子学习在时间相关问题上的鲁棒性和泛化能力，强调了这种一致性的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Recurrent+Neural+Operators%3A+Stable+Long-Term+PDE+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20721，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20721&send_immediately=true&force_search=false)

**原文摘要:** Neural operators have emerged as powerful tools for learning solution
operators of partial differential equations. However, in time-dependent
problems, standard training strategies such as teacher forcing introduce a
mismatch between training and inference, leading to compounding errors in
long-term autoregressive predictions. To address this issue, we propose
Recurrent Neural Operators (RNOs)-a novel framework that integrates recurrent
training into neural operator architectures. Instead of conditioning each
training step on ground-truth inputs, RNOs recursively apply the operator to
their own predictions over a temporal window, effectively simulating
inference-time dynamics during training. This alignment mitigates exposure bias
and enhances robustness to error accumulation. Theoretically, we show that
recurrent training can reduce the worst-case exponential error growth typical
of teacher forcing to linear growth. Empirically, we demonstrate that
recurrently trained Multigrid Neural Operators significantly outperform their
teacher-forced counterparts in long-term accuracy and stability on standard
benchmarks. Our results underscore the importance of aligning training with
inference dynamics for robust temporal generalization in neural operator
learning.

</details>


### [58] [A reinforcement learning agent for maintenance of deteriorating systems with increasingly imperfect repairs](https://arxiv.org/abs/2505.20725)
*Alberto Pliego Marugán, Jesús M. Pinar-Pérez, Fausto Pedro García Márquez*

**主要类别:** cs.LG

**概要:** 提出了一种基于强化学习的维护模型，使用Double Deep Q-Network架构来优化具有gamma退化过程的系统维护策略，该模型能够适应连续退化状态并显著降低长期成本。


<details>
  <summary>更多</summary>
  
**动机:** 工业4.0的实施带来了新的维护优化挑战，传统的维护方法可能不再适用，需要开发更智能、自适应的维护策略以应对复杂的工程系统。

**方法:** 提出了一个gamma退化过程和一种新颖的维护模型，其中修复效果随着修复次数增加而逐渐减弱。利用双深度Q网络（Double Deep Q-Network）构建了一个强化学习代理，用于生成维护策略，该代理无需预定义预防性阈值，并能在连续退化状态下运行。

**结果:** 所提出的强化学习代理在不同场景下表现出极大的灵活性，并且通过调整环境的主要参数，验证了其对维护策略的影响。与常见的维护策略相比，该方法能显著降低长期成本。

**结论:** 提出的基于强化学习的维护模型是一种合适的方法，可以有效改善长期成本，并为实际工程系统的维护提供了新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+reinforcement+learning+agent+for+maintenance+of+deteriorating+systems+with+increasingly+imperfect+repairs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20725，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20725&send_immediately=true&force_search=false)

**原文摘要:** Efficient maintenance has always been essential for the successful
application of engineering systems. However, the challenges to be overcome in
the implementation of Industry 4.0 necessitate new paradigms of maintenance
optimization. Machine learning techniques are becoming increasingly used in
engineering and maintenance, with reinforcement learning being one of the most
promising. In this paper, we propose a gamma degradation process together with
a novel maintenance model in which repairs are increasingly imperfect, i.e.,
the beneficial effect of system repairs decreases as more repairs are
performed, reflecting the degradational behavior of real-world systems. To
generate maintenance policies for this system, we developed a
reinforcement-learning-based agent using a Double Deep Q-Network architecture.
This agent presents two important advantages: it works without a predefined
preventive threshold, and it can operate in a continuous degradation state
space. Our agent learns to behave in different scenarios, showing great
flexibility. In addition, we performed an analysis of how changes in the main
parameters of the environment affect the maintenance policy proposed by the
agent. The proposed approach is demonstrated to be appropriate and to
significatively improve long-run cost as compared with other common maintenance
strategies.

</details>


### [59] [Adversarial bandit optimization for approximately linear functions](https://arxiv.org/abs/2505.20734)
*Zhuoyu Cheng, Kohei Hatano, Eiji Takimoto*

**主要类别:** cs.LG

**概要:** This paper considers a bandit optimization problem for nonconvex and nonsmooth functions, derives regret bounds for this setting, improves the high-probability regret bound for bandit linear optimization, and provides a lower bound on expected regret.


<details>
  <summary>更多</summary>
  
**动机:** The motivation stems from the need to address the challenge of optimizing nonconvex and nonsmooth functions in a bandit setting, which introduces additional complexity due to the presence of perturbations in the loss function.

**方法:** The method involves analyzing a bandit optimization problem where the loss function in each trial is the sum of a linear function and a small but arbitrary perturbation chosen after observing the player's choice.

**结果:** Both expected and high probability regret bounds were obtained for the nonconvex and nonsmooth bandit optimization problem. Additionally, an improved high-probability regret bound was achieved for the special case of bandit linear optimization.

**结论:** The paper concludes by providing both expected and high probability regret bounds for nonconvex and nonsmooth bandit optimization problems, as well as an improved high-probability regret bound for the special case of bandit linear optimization. A lower bound on the expected regret is also given.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Adversarial+bandit+optimization+for+approximately+linear+functions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20734，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20734&send_immediately=true&force_search=false)

**原文摘要:** We consider a bandit optimization problem for nonconvex and non-smooth
functions, where in each trial the loss function is the sum of a linear
function and a small but arbitrary perturbation chosen after observing the
player's choice. We give both expected and high probability regret bounds for
the problem. Our result also implies an improved high-probability regret bound
for the bandit linear optimization, a special case with no perturbation. We
also give a lower bound on the expected regret.

</details>


### [60] [Detecting Informative Channels: ActionFormer](https://arxiv.org/abs/2505.20739)
*Kunpeng Zhao, Asahi Miyazaki, Tsuyoshi Okita*

**主要类别:** cs.LG

**概要:** Human Activity Recognition (HAR) has seen advancements with Transformer-based models like ActionFormer. Originally for image/video input, it's now also applied to sensor signals. This paper analyzes its performance and proposes a modified ActionFormer for sensor data, incorporating Sequence-and-Excitation strategy and swish activation function. Experiments on WEAR dataset show a 16.01% improvement in average mAP for inertial data.


<details>
  <summary>更多</summary>
  
**动机:** Transformer-based models have shown advancements in Human Activity Recognition (HAR), particularly ActionFormer which provides additional outputs detecting activity borders and labels. However, high temporal dynamics and interdependencies between spatial and temporal features limit the model's ability to capture subtle changes effectively when using sensor signals as input.

**方法:** The original ActionFormer model was designed for image/video input but is now also used for sensor signals. The proposed modification incorporates the Sequence-and-Excitation strategy to minimize additional parameters and uses the swish activation function to retain information about direction in the negative range.

**结果:** Experiments conducted on the WEAR dataset demonstrate that the modified ActionFormer achieves a substantial improvement of 16.01% in terms of average mAP for inertial data.

**结论:** The modified ActionFormer model shows significant improvement in handling sensor signals for Human Activity Recognition, particularly addressing issues related to temporal dynamics and feature interdependencies.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Detecting+Informative+Channels%3A+ActionFormer，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20739，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20739&send_immediately=true&force_search=false)

**原文摘要:** Human Activity Recognition (HAR) has recently witnessed advancements with
Transformer-based models. Especially, ActionFormer shows us a new perspectives
for HAR in the sense that this approach gives us additional outputs which
detect the border of the activities as well as the activity labels.
ActionFormer was originally proposed with its input as image/video. However,
this was converted to with its input as sensor signals as well. We analyze this
extensively in terms of deep learning architectures. Based on the report of
high temporal dynamics which limits the model's ability to capture subtle
changes effectively and of the interdependencies between the spatial and
temporal features. We propose the modified ActionFormer which will decrease
these defects for sensor signals. The key to our approach lies in accordance
with the Sequence-and-Excitation strategy to minimize the increase in
additional parameters and opt for the swish activation function to retain the
information about direction in the negative range. Experiments on the WEAR
dataset show that our method achieves substantial improvement of a 16.01\% in
terms of average mAP for inertial data.

</details>


### [61] ['Hello, World!': Making GNNs Talk with LLMs](https://arxiv.org/abs/2505.20742)
*Sunwoo Kim, Soo Yong Lee, Jaemin Yoo, Kijung Shin*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种基于大语言模型的图神经网络GLN，其隐藏层表示为人类可读文本形式，使得GNN内部工作机制变得直观，并在节点分类和链接预测任务上展现了强大的零样本性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管图神经网络（GNNs）在各种与图相关的任务中表现出色，但其高维隐藏表示使它们成为黑箱。为了提升其可解释性，作者提出了Graph Lingual Network (GLN)。

**方法:** GLN以大语言模型为基础构建，其隐藏表示采用人类可读文本形式。通过精心设计提示符，GLN不仅包含GNN的消息传递模块，还结合了图注意力机制和初始残差连接等高级技术。

**结果:** 实验结果表明，GLN在节点分类和链接预测任务上展现出强大的零样本性能，并且优于现有的基于LLM的基线方法。此外，GLN的可理解隐藏表示允许直观分析节点表示如何随层变化以及在高级GNN技术下的变化。

**结论:** GLN提供了一种新的方式来理解和解释GNN的工作机制，同时在实际任务中表现优异，具有较强的零样本学习能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是%27Hello%2C+World%21%27%3A+Making+GNNs+Talk+with+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20742，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20742&send_immediately=true&force_search=false)

**原文摘要:** While graph neural networks (GNNs) have shown remarkable performance across
diverse graph-related tasks, their high-dimensional hidden representations
render them black boxes. In this work, we propose Graph Lingual Network (GLN),
a GNN built on large language models (LLMs), with hidden representations in the
form of human-readable text. Through careful prompt design, GLN incorporates
not only the message passing module of GNNs but also advanced GNN techniques,
including graph attention and initial residual connection. The
comprehensibility of GLN's hidden representations enables an intuitive analysis
of how node representations change (1) across layers and (2) under advanced GNN
techniques, shedding light on the inner workings of GNNs. Furthermore, we
demonstrate that GLN achieves strong zero-shot performance on node
classification and link prediction, outperforming existing LLM-based baseline
methods.

</details>


### [62] [Uni-Instruct: One-step Diffusion Model through Unified Diffusion Divergence Instruction](https://arxiv.org/abs/2505.20755)
*Yifei Wang, Weimin Bai, Colin Zhang, Debing Zhang, Weijian Luo, He Sun*

**主要类别:** cs.LG

**概要:** 本文提出了Uni-Instruct框架，统一了多种一步扩散蒸馏方法，并通过f-散度扩展理论解决了原问题的不可解性，实现了高效的一步扩散模型训练，在CIFAR10和ImageNet生成基准上取得了最佳性能。


<details>
  <summary>更多</summary>
  
**动机:** 作者受到提出的f-散度家族的扩散扩展理论的启发，旨在解决现有一步扩散方法中的不可解性问题，并提供一个统一的理论框架来理解这些方法。

**方法:** 提出了一种名为Uni-Instruct的理论驱动框架，将超过10种现有的一步扩散蒸馏方法统一起来，基于f-散度家族的扩散扩展理论，引入关键理论以克服原扩展f-散度的不可解性，从而形成等效且可解的损失函数，用于有效训练一步扩散模型。

**结果:** 在CIFAR10生成基准上，无条件生成FID值达到1.46，有条件生成FID值达到1.38；在ImageNet-$64\times 64$生成基准上，取得新的SoTA一步生成FID值1.02，显著优于其79步教师扩散模型（2.35）。在文本到3D生成任务中，表现略优于先前的方法SDS和VSD。

**结论:** Uni-Instruct不仅提供了新的理论贡献，帮助从高层次理解现有方法，还在一步扩散生成性能上达到最先进的水平，为未来关于一步扩散蒸馏和扩散模型知识转移的研究提供了坚实的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Uni-Instruct%3A+One-step+Diffusion+Model+through+Unified+Diffusion+Divergence+Instruction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20755，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20755&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we unify more than 10 existing one-step diffusion distillation
approaches, such as Diff-Instruct, DMD, SIM, SiD, $f$-distill, etc, inside a
theory-driven framework which we name the \textbf{\emph{Uni-Instruct}}.
Uni-Instruct is motivated by our proposed diffusion expansion theory of the
$f$-divergence family. Then we introduce key theories that overcome the
intractability issue of the original expanded $f$-divergence, resulting in an
equivalent yet tractable loss that effectively trains one-step diffusion models
by minimizing the expanded $f$-divergence family. The novel unification
introduced by Uni-Instruct not only offers new theoretical contributions that
help understand existing approaches from a high-level perspective but also
leads to state-of-the-art one-step diffusion generation performances. On the
CIFAR10 generation benchmark, Uni-Instruct achieves record-breaking Frechet
Inception Distance (FID) values of \textbf{\emph{1.46}} for unconditional
generation and \textbf{\emph{1.38}} for conditional generation. On the
ImageNet-$64\times 64$ generation benchmark, Uni-Instruct achieves a new SoTA
one-step generation FID of \textbf{\emph{1.02}}, which outperforms its 79-step
teacher diffusion with a significant improvement margin of 1.33 (1.02 vs 2.35).
We also apply Uni-Instruct on broader tasks like text-to-3D generation. For
text-to-3D generation, Uni-Instruct gives decent results, which slightly
outperforms previous methods, such as SDS and VSD, in terms of both generation
quality and diversity. Both the solid theoretical and empirical contributions
of Uni-Instruct will potentially help future studies on one-step diffusion
distillation and knowledge transferring of diffusion models.

</details>


### [63] [Robust and Explainable Detector of Time Series Anomaly via Augmenting Multiclass Pseudo-Anomalies](https://arxiv.org/abs/2505.20765)
*Kohei Obata, Yasuko Matsubara, Yasushi Sakurai*

**主要类别:** cs.LG

**概要:** 提出了一种名为RedLamp的新方法，通过使用多样化的数据增强生成多类伪异常，并学习多类边界，采用软标签进行多类分类以防止模型过于自信，确保对污染/虚假异常的鲁棒性。实验表明RedLamp在异常检测中的有效性和对异常污染的鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 当前主流方法假设训练集中的样本大多为正常样本，但训练集中存在异常（即异常污染）可能误导模型。近期研究利用数据增强生成伪异常并学习分离训练样本和增强样本的边界，但这种方法存在覆盖异常范围有限、忽略类似正常样本的增强样本以及过度信任样本标签的问题。

**方法:** RedLamp采用多样化的数据增强技术生成多类伪异常，并学习多类边界。这些伪异常覆盖了多种时间序列异常。通过使用软标签进行多类分类，防止模型过于自信，同时确保对污染或虚假异常的鲁棒性。所学的潜在空间具有内在可解释性，因为它被训练用于将伪异常分离成多类。

**结果:** 广泛的实验证明了RedLamp在异常检测中的有效性和对异常污染的鲁棒性。

**结论:** RedLamp是一种有效的异常检测方法，能够应对异常污染问题，其潜在空间具有可解释性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robust+and+Explainable+Detector+of+Time+Series+Anomaly+via+Augmenting+Multiclass+Pseudo-Anomalies，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20765，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20765&send_immediately=true&force_search=false)

**原文摘要:** Unsupervised anomaly detection in time series has been a pivotal research
area for decades. Current mainstream approaches focus on learning normality, on
the assumption that all or most of the samples in the training set are normal.
However, anomalies in the training set (i.e., anomaly contamination) can be
misleading. Recent studies employ data augmentation to generate
pseudo-anomalies and learn the boundary separating the training samples from
the augmented samples. Although this approach mitigates anomaly contamination
if augmented samples mimic unseen real anomalies, it suffers from several
limitations. (1) Covering a wide range of time series anomalies is challenging.
(2) It disregards augmented samples that resemble normal samples (i.e., false
anomalies). (3) It places too much trust in the labels of training and
augmented samples. In response, we propose RedLamp, which employs diverse data
augmentations to generate multiclass pseudo-anomalies and learns the multiclass
boundary. Such multiclass pseudo-anomalies cover a wide variety of time series
anomalies. We conduct multiclass classification using soft labels, which
prevents the model from being overconfident and ensures its robustness against
contaminated/false anomalies. The learned latent space is inherently
explainable as it is trained to separate pseudo-anomalies into multiclasses.
Extensive experiments demonstrate the effectiveness of RedLamp in anomaly
detection and its robustness against anomaly contamination.

</details>


### [64] [TimePro: Efficient Multivariate Long-term Time Series Forecasting with Variable- and Time-Aware Hyper-state](https://arxiv.org/abs/2505.20774)
*Xiaowen Ma, Zhenliang Ni, Shuai Xiao, Xinghao Chen*

**主要类别:** cs.LG

**概要:** 提出了一种名为TimePro的新模型，专门解决长期时间序列预测中的多延迟问题。通过构建变量和时间感知的超状态，TimePro能够精确捕捉变量关系和显著的时间信息，在八个实际长期预测基准上表现出色，并具有令人满意的线性复杂度。


<details>
  <summary>更多</summary>
  
**动机:** 在长期时间序列预测中，不同变量通常在不同的时间间隔内影响目标变量（即多延迟问题）。传统模型无法有效捕获复杂的变量关系和非平凡的时间表示，因此需要一种新方法来处理这一挑战。

**方法:** 提出了一种基于Mamba的创新模型TimePro，该模型构建了变量和时间感知的超状态。与传统方法不同，TimePro保留了每个变量标记的细粒度时间特征，并自适应地选择关注的时间点以调整简单状态，从而实现对变量关系和显著时间信息的感知。

**结果:** 在实验中，TimePro在八个实际长期预测基准上表现优异，具有竞争力的性能和令人满意的线性复杂度。

**结论:** TimePro是一种有效的解决方案，可以应对长期时间序列预测中的多延迟问题，其代码已开源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TimePro%3A+Efficient+Multivariate+Long-term+Time+Series+Forecasting+with+Variable-+and+Time-Aware+Hyper-state，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20774，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20774&send_immediately=true&force_search=false)

**原文摘要:** In long-term time series forecasting, different variables often influence the
target variable over distinct time intervals, a challenge known as the
multi-delay issue. Traditional models typically process all variables or time
points uniformly, which limits their ability to capture complex variable
relationships and obtain non-trivial time representations. To address this
issue, we propose TimePro, an innovative Mamba-based model that constructs
variate- and time-aware hyper-states. Unlike conventional approaches that
merely transfer plain states across variable or time dimensions, TimePro
preserves the fine-grained temporal features of each variate token and
adaptively selects the focused time points to tune the plain state. The
reconstructed hyper-state can perceive both variable relationships and salient
temporal information, which helps the model make accurate forecasting. In
experiments, TimePro performs competitively on eight real-world long-term
forecasting benchmarks with satisfactory linear complexity. Code is available
at https://github.com/xwmaxwma/TimePro.

</details>


### [65] [Non-invasive maturity assessment of iPSC-CMs based on optical maturity characteristics using interpretable AI](https://arxiv.org/abs/2505.20775)
*Fabian Scheurer, Alexander Hammer, Mario Schubert, Robert-Patrick Steiner, Oliver Gamm, Kaomei Guan, Frank Sonntag, Hagen Malberg, Martin Schmidt*

**主要类别:** cs.LG

**概要:** This paper presents a novel, non-invasive method using AI and optical motion analysis to assess the maturity of iPSC-CMs with high accuracy, potentially improving experimental reproducibility in drug testing and functional studies.


<details>
  <summary>更多</summary>
  
**动机:** The motivation for this research stems from the challenge of assessing the maturation state of iPSC-CMs without causing cell damage or loss. Current methods are time-consuming and often destructive, making it difficult to accurately evaluate the cells' maturity. A non-invasive approach could provide a more efficient and reliable way to classify iPSC-CM maturity before performing functional readouts or drug testing.

**方法:** The researchers developed an automated classification method using interpretable artificial intelligence (AI) to assess the maturity of human induced pluripotent stem cell-derived cardiomyocytes (iPSC-CMs). They used video-based motion analysis to extract 10 features per recording, which were then entered into a support vector machine (SVM). The SVM's hyperparameters were optimized through a grid search with 5-fold cross-validation on 80% of the data. The model was tested on a hold-out test set, achieving an accuracy of 99.5 ± 1.1%. Shapley Additive Explanations (SHAP) identified key features such as displacement, relaxation-rise time, and beating duration as most relevant for maturity assessment.

**结果:** The optimized SVM model achieved an accuracy of 99.5 ± 1.1% in classifying the maturity level of iPSC-CMs based on video recordings. SHAP analysis revealed that displacement, relaxation-rise time, and beating duration were the most important features for assessing maturity.

**结论:** The study concludes that non-invasive, optical motion analysis combined with AI-based methods is a highly accurate and efficient tool for assessing the maturity of iPSC-CMs. This approach may reduce variability and improve reproducibility in experimental studies involving functional readouts or drug testing.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Non-invasive+maturity+assessment+of+iPSC-CMs+based+on+optical+maturity+characteristics+using+interpretable+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20775，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20775&send_immediately=true&force_search=false)

**原文摘要:** Human induced pluripotent stem cell-derived cardiomyocytes (iPSC-CMs) are an
important resource for the identification of new therapeutic targets and
cardioprotective drugs. After differentiation iPSC-CMs show an immature,
fetal-like phenotype. Cultivation of iPSC-CMs in lipid-supplemented maturation
medium (MM) strongly enhances their structural, metabolic and functional
phenotype. Nevertheless, assessing iPSC-CM maturation state remains challenging
as most methods are time consuming and go in line with cell damage or loss of
the sample. To address this issue, we developed a non-invasive approach for
automated classification of iPSC-CM maturity through interpretable artificial
intelligence (AI)-based analysis of beat characteristics derived from
video-based motion analysis. In a prospective study, we evaluated 230 video
recordings of early-state, immature iPSC-CMs on day 21 after differentiation
(d21) and more mature iPSC-CMs cultured in MM (d42, MM). For each recording, 10
features were extracted using Maia motion analysis software and entered into a
support vector machine (SVM). The hyperparameters of the SVM were optimized in
a grid search on 80 % of the data using 5-fold cross-validation. The optimized
model achieved an accuracy of 99.5 $\pm$ 1.1 % on a hold-out test set. Shapley
Additive Explanations (SHAP) identified displacement, relaxation-rise time and
beating duration as the most relevant features for assessing maturity level.
Our results suggest the use of non-invasive, optical motion analysis combined
with AI-based methods as a tool to assess iPSC-CMs maturity and could be
applied before performing functional readouts or drug testing. This may
potentially reduce the variability and improve the reproducibility of
experimental studies.

</details>


### [66] [Multi-VQC: A Novel QML Approach for Enhancing Healthcare Classification](https://arxiv.org/abs/2505.20797)
*Antonio Tudisco, Deborah Volpe, Giovanna Turvani*

**主要类别:** cs.LG

**概要:** 量子模型因能够通过映射到高维计算空间表达复杂模式，有望克服传统模型在处理显著类别不平衡问题上的限制。


<details>
  <summary>更多</summary>
  
**动机:** 准确可靠的疾病诊断对于及时的医疗治疗和提高患者生存率至关重要。然而，分类问题通常存在显著的类别不平衡，这会抑制传统模型的有效性。

**方法:** 研究者对量子模型产生了兴趣，这些模型能够通过将数据映射到高维计算空间来表达复杂模式。

**结果:** 量子模型有可能克服传统模型在处理类别不平衡问题上的限制。

**结论:** 量子模型为改善疾病分类和诊断提供了新的可能性，特别是在处理类别不平衡问题上。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-VQC%3A+A+Novel+QML+Approach+for+Enhancing+Healthcare+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20797，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20797&send_immediately=true&force_search=false)

**原文摘要:** Accurate and reliable diagnosis of diseases is crucial in enabling timely
medical treatment and enhancing patient survival rates. In recent years,
Machine Learning has revolutionized diagnostic practices by creating
classification models capable of identifying diseases. However, these
classification problems often suffer from significant class imbalances, which
can inhibit the effectiveness of traditional models. Therefore, the interest in
Quantum models has arisen, driven by the captivating promise of overcoming the
limitations of the classical counterpart thanks to their ability to express
complex patterns by mapping data in a higher-dimensional computational space.

</details>


### [67] [Leaner Transformers: More Heads, Less Depth](https://arxiv.org/abs/2505.20802)
*Hemanth Saratchandran, Damien Teney, Simon Lucey*

**主要类别:** cs.LG

**概要:** 本论文通过理论分析发现多头注意力机制的主要优势在于改善注意力块的条件性，并基于此重新设计了流行的Transformer架构，减少了模型深度和参数数量（30-50%），同时保持了模型准确性。该方法在多个任务上表现出色，挑战了“更大即更好”的传统观念。


<details>
  <summary>更多</summary>
  
**动机:** 尽管Transformer模型因性能显著提升而不断增大模型规模，但这种“更大即更好”的理念可能并不总是正确的。许多现有Transformer可能被过度放大，存在不必要的冗余。因此，需要重新审视和优化Transformer的设计以减少不必要的复杂性和参数量。

**方法:** 作者通过理论分析发现了多头注意力机制对改善注意力块条件性的重要作用，并利用这一洞见重新设计了流行的Transformer架构。新设计增加了多头的数量，从而显著改善了条件性，使得可以减少模型深度而不影响性能。

**结果:** 实验结果表明，通过增加多头数量并减少模型深度，可以在维持准确率的同时减少30-50%的参数量。这种方法在不同规模的Transformer架构以及多种任务（如ImageNet-1k、GLUE基准、TinyStories等）中均表现出了持续的优势。

**结论:** 本文挑战了“更大即更好”的Transformer设计理念，证明了许多现有模型可能被过度放大。通过改进多头注意力机制的作用，可以在减少参数量的同时保持甚至提升模型性能，为更高效、更轻量级的Transformer模型设计提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Leaner+Transformers%3A+More+Heads%2C+Less+Depth，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20802，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20802&send_immediately=true&force_search=false)

**原文摘要:** Transformers have reshaped machine learning by utilizing attention mechanisms
to capture complex patterns in large datasets, leading to significant
improvements in performance. This success has contributed to the belief that
"bigger means better", leading to ever-increasing model sizes. This paper
challenge this ideology by showing that many existing transformers might be
unnecessarily oversized. We discover a theoretical principle that redefines the
role of multi-head attention. An important benefit of the multiple heads is in
improving the conditioning of the attention block. We exploit this theoretical
insight and redesign popular architectures with an increased number of heads.
The improvement in the conditioning proves so significant in practice that
model depth can be decreased, reducing the parameter count by up to 30-50%
while maintaining accuracy. We obtain consistent benefits across a variety of
transformer-based architectures of various scales, on tasks in computer vision
(ImageNet-1k) as well as language and sequence modeling (GLUE benchmark,
TinyStories, and the Long-Range Arena benchmark).

</details>


### [68] [Quantum Machine Learning in Healthcare: Evaluating QNN and QSVM Models](https://arxiv.org/abs/2505.20804)
*Antonio Tudisco, Deborah Volpe, Giovanna Turvani*

**主要类别:** cs.LG

**概要:** 在医疗保健分类任务中，量子模型（如QSVM和QNN）有潜力解决数据集不平衡的问题。尽管初步结果表明QSVM由于过拟合问题优于QNN，但这些发现为未来的研究铺平了道路。


<details>
  <summary>更多</summary>
  
**动机:** 有效和准确地诊断癌症、糖尿病和心力衰竭等疾病对于及时的医疗干预和提高患者的生存率至关重要。机器学习通过开发基于选定特征检测疾病的分类模型，已经革新了诊断方法。然而，这些分类任务通常高度不平衡，限制了经典模型的性能。量子模型通过叠加和纠缠在更高维度的计算空间中操作，表达复杂模式的能力使它们在解决不平衡数据集挑战方面可能更有效。

**方法:** 评估量子分类器在医疗保健中的潜力，重点研究量子神经网络（QNN）和量子支持向量机（QSVM），并将它们与流行的经典模型进行比较。使用三个知名医疗保健数据集：前列腺癌、心力衰竭和糖尿病。

**结果:** 结果显示，在所有数据集中，QSVM由于其对过拟合的敏感性较低而优于QNN。此外，量子模型证明了在高数据集不平衡的情况下超越经典模型的能力。

**结论:** 尽管是初步的，这些发现强调了量子模型在医疗保健分类任务中的潜力，并为该领域的进一步研究指明了方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Quantum+Machine+Learning+in+Healthcare%3A+Evaluating+QNN+and+QSVM+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20804，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20804&send_immediately=true&force_search=false)

**原文摘要:** Effective and accurate diagnosis of diseases such as cancer, diabetes, and
heart failure is crucial for timely medical intervention and improving patient
survival rates. Machine learning has revolutionized diagnostic methods in
recent years by developing classification models that detect diseases based on
selected features. However, these classification tasks are often highly
imbalanced, limiting the performance of classical models. Quantum models offer
a promising alternative, exploiting their ability to express complex patterns
by operating in a higher-dimensional computational space through superposition
and entanglement. These unique properties make quantum models potentially more
effective in addressing the challenges of imbalanced datasets. This work
evaluates the potential of quantum classifiers in healthcare, focusing on
Quantum Neural Networks (QNNs) and Quantum Support Vector Machines (QSVMs),
comparing them with popular classical models. The study is based on three
well-known healthcare datasets -- Prostate Cancer, Heart Failure, and Diabetes.
The results indicate that QSVMs outperform QNNs across all datasets due to
their susceptibility to overfitting. Furthermore, quantum models prove the
ability to overcome classical models in scenarios with high dataset imbalance.
Although preliminary, these findings highlight the potential of quantum models
in healthcare classification tasks and lead the way for further research in
this domain.

</details>


### [69] [Simple yet Effective Graph Distillation via Clustering](https://arxiv.org/abs/2505.20807)
*Yurui Lai, Taiyan Zhang, Renchi Yang*

**主要类别:** cs.LG

**概要:** 尽管图表示学习在各个领域取得了丰富的成功，但图神经网络（GNNs）的训练仍然具有挑战性，因为实际应用中大型图需要巨大的计算开销。为了解决这一问题，本文提出了一种高效且有效的图数据蒸馏方法ClustGDD。ClustGDD通过快速且理论依据充分的聚类合成压缩图和节点属性，最小化簇内平方和并最大化原始图上的同质性。此外，ClustGDD通过类别感知图采样和一致性损失的小幅增强来优化压缩图的节点属性。实验表明，使用ClustGDD输出的压缩图训练的GNN在五个基准数据集上的节点分类性能优于或媲美最先进的GDD方法，同时速度快了几个数量级。


<details>
  <summary>更多</summary>
  
**动机:** 大多数现有的图数据蒸馏（GDD）方法依赖于启发式技术，这些技术通过对模型梯度或表示分布进行对齐，将大图压缩成紧凑且信息丰富的图。然而，这些方法导致结果质量下降、昂贵的训练过程，或者两者兼有。

**方法:** ClustGDD通过以下步骤实现：1. 使用快速且理论支持的聚类方法合成压缩图和节点属性，该方法最小化簇内平方和并最大化原始图上的同质性；2. 通过类别感知图采样和一致性损失的小幅增强来优化压缩图的节点属性。

**结果:** 广泛的实验表明，在ClustGDD输出的压缩图上训练的GNN在五个基准数据集上的节点分类任务中表现优于或媲美最先进的GDD方法，同时训练速度提高了几个数量级。

**结论:** ClustGDD是一种高效且有效的GDD方法，它能够在保持高性能的同时显著减少GNN训练的时间成本。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Simple+yet+Effective+Graph+Distillation+via+Clustering，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20807，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20807&send_immediately=true&force_search=false)

**原文摘要:** Despite plentiful successes achieved by graph representation learning in
various domains, the training of graph neural networks (GNNs) still remains
tenaciously challenging due to the tremendous computational overhead needed for
sizable graphs in practice. Recently, graph data distillation (GDD), which
seeks to distill large graphs into compact and informative ones, has emerged as
a promising technique to enable efficient GNN training. However, most existing
GDD works rely on heuristics that align model gradients or representation
distributions on condensed and original graphs, leading to compromised result
quality, expensive training for distilling large graphs, or both. Motivated by
this, this paper presents an efficient and effective GDD approach, ClustGDD.
Under the hood, ClustGDD resorts to synthesizing the condensed graph and node
attributes through fast and theoretically-grounded clustering that minimizes
the within-cluster sum of squares and maximizes the homophily on the original
graph. The fundamental idea is inspired by our empirical and theoretical
findings unveiling the connection between clustering and empirical condensation
quality using Fr\'echet Inception Distance, a well-known quality metric for
synthetic images. Furthermore, to mitigate the adverse effects caused by the
homophily-based clustering, ClustGDD refines the nodal attributes of the
condensed graph with a small augmentation learned via class-aware graph
sampling and consistency loss. Our extensive experiments exhibit that GNNs
trained over condensed graphs output by ClustGDD consistently achieve superior
or comparable performance to state-of-the-art GDD methods in terms of node
classification on five benchmark datasets, while being orders of magnitude
faster.

</details>


### [70] [Interpretable Credit Default Prediction with Ensemble Learning and SHAP](https://arxiv.org/abs/2505.20815)
*Shiqi Yang, Ziyi Huang, Wengran Xiao, Xinyu Shen*

**主要类别:** cs.LG

**概要:** 本研究集中于信用违约预测问题，构建了基于机器学习的建模框架，并对多种主流分类算法进行了对比实验。通过预处理、特征工程和模型训练，评估了多个模型在准确率、精确率和召回率方面的性能。结果表明，集成学习方法在预测性能上具有明显优势，特别是在处理复杂非线性关系和数据不平衡问题时表现出强大的鲁棒性。同时，使用SHAP方法分析了特征的重要性及依赖关系，发现外部信用评分变量在模型决策中起主导作用，有助于提高模型的可解释性和实际应用价值。该研究成果为信用风险控制系统智能化发展提供了有效参考和技术支持。


<details>
  <summary>更多</summary>
  
**动机:** 信用违约预测是金融领域的重要课题，准确的预测可以降低金融机构的风险并提升其运营效率。然而，传统方法在处理复杂的非线性关系和数据不平衡问题方面存在局限性，因此需要探索更先进的机器学习技术以提高预测性能。

**方法:** 1. 构建了一个基于机器学习的信用违约预测建模框架。
2. 使用Home Credit数据集进行预处理、特征工程和模型训练。
3. 对比实验了包括逻辑回归、随机森林、XGBoost、LightGBM等在内的多种主流分类算法。
4. 采用SHAP方法分析特征重要性和依赖关系，揭示模型决策的关键驱动因素。

**结果:** 集成学习方法（如随机森林、XGBoost、LightGBM）在预测性能上显著优于传统方法，在处理复杂非线性关系和数据不平衡问题方面表现尤为突出。此外，外部信用评分变量被证明在模型决策中起主导作用，提升了模型的可解释性和实用性。

**结论:** 集成学习方法在信用违约预测任务中展现了优越的性能和鲁棒性，能够有效应对复杂数据结构和不平衡数据问题。结合SHAP方法分析特征重要性，进一步增强了模型的可解释性，为信用风险控制系统的智能化发展提供了技术支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interpretable+Credit+Default+Prediction+with+Ensemble+Learning+and+SHAP，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20815，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20815&send_immediately=true&force_search=false)

**原文摘要:** This study focuses on the problem of credit default prediction, builds a
modeling framework based on machine learning, and conducts comparative
experiments on a variety of mainstream classification algorithms. Through
preprocessing, feature engineering, and model training of the Home Credit
dataset, the performance of multiple models including logistic regression,
random forest, XGBoost, LightGBM, etc. in terms of accuracy, precision, and
recall is evaluated. The results show that the ensemble learning method has
obvious advantages in predictive performance, especially in dealing with
complex nonlinear relationships between features and data imbalance problems.
It shows strong robustness. At the same time, the SHAP method is used to
analyze the importance and dependency of features, and it is found that the
external credit score variable plays a dominant role in model decision making,
which helps to improve the model's interpretability and practical application
value. The research results provide effective reference and technical support
for the intelligent development of credit risk control systems.

</details>


### [71] [HAD: Hybrid Architecture Distillation Outperforms Teacher in Genomic Sequence Modeling](https://arxiv.org/abs/2505.20836)
*Hexiong Yang, Mingrui Chen, Huaibo Huang, Junxian Duan, Jie Cao, Zhen Zhou, Ran He*

**主要类别:** cs.LG

**概要:** 受到自然语言领域掩码语言建模(MLM)成功的启发，自监督预训练和微调范式在DNA序列建模领域也取得了显著进展。然而，以前的方法通常依赖于大量的预训练数据或具有大量参数的大规模基础模型，这带来了巨大的计算负担。为了解决这个问题，许多工作试图使用更紧凑的模型来实现类似的结果，但仍然存在相当大的差距。在这项工作中，我们提出了混合架构蒸馏(HAD)方法，利用蒸馏和重建任务进行更高效和有效的预训练。具体来说，我们使用NTv2-500M作为教师模型，并设计了一种分组掩码策略，在MLM预训练期间对可见标记进行特征嵌入对齐，同时重建不可见标记。为了验证我们提出的方法的有效性，我们在核苷酸变换基准和基因组基准上进行了全面的实验。与参数相似的模型相比，我们的模型表现出了优异的性能。更令人惊讶的是，在某些子任务上，它甚至超过了比其大500倍以上的蒸馏天花板教师模型。最后，我们利用t-SNE进行更直观的可视化，结果表明我们的模型可以深入了解基因组序列中内在表示模式。


<details>
  <summary>更多</summary>
  
**动机:** 之前的DNA序列建模方法依赖于大规模预训练数据或大型模型，计算成本高。尽管有尝试使用更紧凑的模型，但这些模型的表现仍存在很大差距。因此，需要一种更高效且有效的预训练方法。

**方法:** 提出了一种名为混合架构蒸馏（HAD）的新方法。该方法结合了蒸馏和重建任务，以提高预训练效率和效果。具体做法是使用NTv2-500M作为教师模型，并采用分组掩码策略，通过MLM预训练对齐可见标记的特征嵌入，同时重建不可见标记。

**结果:** 在核苷酸变换基准和基因组基准上的实验表明，与参数量相近的模型相比，提出的模型表现出色。并且在某些子任务上，超越了参数量超过自身500倍的教师模型。

**结论:** 提出的HAD方法能够通过蒸馏和重建任务实现更高效和有效的预训练，显著提升了紧凑模型在DNA序列建模中的性能，甚至在某些情况下超过了大型教师模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是HAD%3A+Hybrid+Architecture+Distillation+Outperforms+Teacher+in+Genomic+Sequence+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20836，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20836&send_immediately=true&force_search=false)

**原文摘要:** Inspired by the great success of Masked Language Modeling (MLM) in the
natural language domain, the paradigm of self-supervised pre-training and
fine-tuning has also achieved remarkable progress in the field of DNA sequence
modeling. However, previous methods often relied on massive pre-training data
or large-scale base models with huge parameters, imposing a significant
computational burden. To address this, many works attempted to use more compact
models to achieve similar outcomes but still fell short by a considerable
margin. In this work, we propose a Hybrid Architecture Distillation (HAD)
approach, leveraging both distillation and reconstruction tasks for more
efficient and effective pre-training. Specifically, we employ the NTv2-500M as
the teacher model and devise a grouping masking strategy to align the feature
embeddings of visible tokens while concurrently reconstructing the invisible
tokens during MLM pre-training. To validate the effectiveness of our proposed
method, we conducted comprehensive experiments on the Nucleotide Transformer
Benchmark and Genomic Benchmark. Compared to models with similar parameters,
our model achieved excellent performance. More surprisingly, it even surpassed
the distillation ceiling-teacher model on some sub-tasks, which is more than
500 $\times$ larger. Lastly, we utilize t-SNE for more intuitive visualization,
which shows that our model can gain a sophisticated understanding of the
intrinsic representation pattern in genomic sequences.

</details>


### [72] [FireQ: Fast INT4-FP8 Kernel and RoPE-aware Quantization for LLM Inference Acceleration](https://arxiv.org/abs/2505.20839)
*Daehyeon Baek, Jieun Choi, Jimyoung Son, Kyungmin Bin, Seungbeom Choi, Kihyo Moon, Minsung Jang, Hyojung Lee*

**主要类别:** cs.LG

**概要:** FireQ是一种协同设计的PTQ框架和INT4-FP8矩阵乘法内核，通过量化线性层权重和激活，以及引入三阶段流水线预填充策略，显著加速LLM推理，并在保持精度的同时超越现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型语言模型的普及，内存带宽限制了推理吞吐量，推动了训练后量化（PTQ）的需求。

**方法:** FireQ将线性层权重和键值量化为INT4，激活和查询量化为FP8；引入三阶段流水线预填充策略以减少首次出词时间；开发了针对线性和注意力层的新型异常值平滑技术，包括张量级缩放和通道级缩放以解决量化带来的精度损失问题。

**结果:** FireQ在Llama2-7B的前馈网络层上比现有方法快1.68倍，在Llama3-8B的预填充阶段性能提升1.26倍，且精度损失可忽略不计。

**结论:** FireQ通过高效的量化和优化策略，显著提升了LLM推理速度并保持了高精度，优于当前最先进的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FireQ%3A+Fast+INT4-FP8+Kernel+and+RoPE-aware+Quantization+for+LLM+Inference+Acceleration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20839，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20839&send_immediately=true&force_search=false)

**原文摘要:** As large language models become increasingly prevalent, memory bandwidth
constraints significantly limit inference throughput, motivating post-training
quantization (PTQ). In this paper, we propose FireQ, a co-designed PTQ
framework and an INT4-FP8 matrix multiplication kernel that accelerates LLM
inference across all linear layers. Specifically, FireQ quantizes linear layer
weights and key-values to INT4, and activations and queries to FP8,
significantly enhancing throughput. Additionally, we introduce a three-stage
pipelining for the prefill phase, which modifies the FlashAttention-3 kernel,
effectively reducing time-to-first-token in the prefill phase. To minimize
accuracy loss from quantization, we develop novel outlier smoothing techniques
tailored separately for linear and attention layers. In linear layers, we
explicitly use per-tensor scaling to prevent underflow caused by the FP8
quantization scaling factor of INT4 quantization, and channel-wise scaling to
compensate for coarse granularity of INT4. In attention layers, we address
quantization challenges posed by rotary positional embeddings (RoPE) by
combining pre-RoPE and post-RoPE scaling strategies. FireQ significantly
outperforms state-of-the-art methods, achieving 1.68x faster inference in
feed-forward network layers on Llama2-7B and 1.26x faster prefill phase
performance on Llama3-8B compared to QServe, with negligible accuracy loss.

</details>


### [73] [Aggregation Buffer: Revisiting DropEdge with a New Parameter Block](https://arxiv.org/abs/2505.20840)
*Dooho Lee, Myeong Kong, Sagad Hamid, Cheonwoo Lee, Jaemin Yoo*

**主要类别:** cs.LG

**概要:** 重新审视DropEdge技术，发现其性能提升受限于GNN架构的固有限制。提出Aggregation Buffer方法以改善GNN的鲁棒性，解决DropEdge的限制，并在多个数据集上验证了其一致性改进和对度偏差等问题的有效解决方案。


<details>
  <summary>更多</summary>
  
**动机:** DropEdge是一种通过随机删除边来增强图神经网络（GNN）训练期间的多样性结构的技术，虽然有助于减少过拟合，但其在监督学习任务中的性能增益显著受限。

**方法:** 提出了一种名为Aggregation Buffer的参数块，专门设计用于改进GNN的鲁棒性，克服DropEdge的局限性。该方法与任何GNN模型兼容，并作为统一解决方案有效解决了诸如度偏差或结构差异等已知问题。

**结果:** Aggregation Buffer方法在多个数据集上显示出一致的性能改进，有效解决了度偏差和结构差异等问题。

**结论:** Aggregation Buffer作为一种通用且有效的改进方法，可以增强GNN模型的鲁棒性和性能，同时解决了DropEdge技术的固有限制。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Aggregation+Buffer%3A+Revisiting+DropEdge+with+a+New+Parameter+Block，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20840，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20840&send_immediately=true&force_search=false)

**原文摘要:** We revisit DropEdge, a data augmentation technique for GNNs which randomly
removes edges to expose diverse graph structures during training. While being a
promising approach to effectively reduce overfitting on specific connections in
the graph, we observe that its potential performance gain in supervised
learning tasks is significantly limited. To understand why, we provide a
theoretical analysis showing that the limited performance of DropEdge comes
from the fundamental limitation that exists in many GNN architectures. Based on
this analysis, we propose Aggregation Buffer, a parameter block specifically
designed to improve the robustness of GNNs by addressing the limitation of
DropEdge. Our method is compatible with any GNN model, and shows consistent
performance improvements on multiple datasets. Moreover, our method effectively
addresses well-known problems such as degree bias or structural disparity as a
unifying solution. Code and datasets are available at
https://github.com/dooho00/agg-buffer.

</details>


### [74] [Cooperation of Experts: Fusing Heterogeneous Information with Large Margin](https://arxiv.org/abs/2505.20853)
*Shuo Wang, Shunyang Huang, Jinghui Yuan, Zhixiang Shen, Zhao Kang*

**主要类别:** cs.LG

**概要:** 在现代数据分析中，融合异构信息一直是一个持续的挑战。尽管已经取得了显著进展，但现有的方法往往无法考虑到不同语义空间中对象模式的固有异质性。为了解决这一局限性，我们提出了专家协作（CoE）框架，该框架将多类型信息编码为统一的异构多重网络。通过克服模态和连接差异，CoE提供了一个强大而灵活的模型，用于捕捉现实世界复杂数据的复杂结构。在我们的框架中，专用编码器充当领域特定专家，每个专家专门研究特定语义空间中的不同关系模式。为了增强鲁棒性和提取互补知识，这些专家通过新颖的大边缘机制进行协作，该机制由定制的优化策略支持。严格的理论分析保证了框架的可行性和稳定性，而广泛的跨多种基准实验展示了其卓越的性能和广泛适用性。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法在处理不同语义空间中的对象模式时，无法充分考虑其固有的异质性，这限制了对复杂数据结构的有效捕捉。

**方法:** 提出了一种名为Cooperation of Experts (CoE) 的框架，该框架将多类型信息编码成统一的异构多重网络，并使用专门的编码器作为领域特定专家来学习特定语义空间中的关系模式。通过大边缘机制和定制优化策略，专家们可以协作以增强鲁棒性和提取互补知识。

**结果:** 理论分析证明了框架的可行性和稳定性，实验结果表明该方法在各种基准测试中表现出优越的性能和广泛的适用性。

**结论:** CoE框架为融合异构信息提供了一种强大且灵活的方法，适用于捕捉现实世界复杂数据的复杂结构，并具有广泛的适用性和稳定的性能表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Cooperation+of+Experts%3A+Fusing+Heterogeneous+Information+with+Large+Margin，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20853，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20853&send_immediately=true&force_search=false)

**原文摘要:** Fusing heterogeneous information remains a persistent challenge in modern
data analysis. While significant progress has been made, existing approaches
often fail to account for the inherent heterogeneity of object patterns across
different semantic spaces. To address this limitation, we propose the
Cooperation of Experts (CoE) framework, which encodes multi-typed information
into unified heterogeneous multiplex networks. By overcoming modality and
connection differences, CoE provides a powerful and flexible model for
capturing the intricate structures of real-world complex data. In our
framework, dedicated encoders act as domain-specific experts, each specializing
in learning distinct relational patterns in specific semantic spaces. To
enhance robustness and extract complementary knowledge, these experts
collaborate through a novel large margin mechanism supported by a tailored
optimization strategy. Rigorous theoretical analyses guarantee the framework's
feasibility and stability, while extensive experiments across diverse
benchmarks demonstrate its superior performance and broad applicability. Our
code is available at https://github.com/strangeAlan/CoE.

</details>


### [75] [Generalizable Heuristic Generation Through Large Language Models with Meta-Optimization](https://arxiv.org/abs/2505.20881)
*Yiding Shi, Jianan Zhou, Wen Song, Jieyi Bi, Yaoxin Wu, Jie Zhang*

**主要类别:** cs.LG

**概要:** 论文提出了一种名为Meta-Optimization of Heuristics (MoH)的新框架，利用大语言模型（LLMs）在优化器层面进行元学习，自主构建多样化的优化器，从而解决组合优化问题（COPs）。该方法摆脱了对预定义进化计算优化器的依赖，并通过多任务训练方案提高了泛化能力，在经典COPs上取得了最先进的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于大语言模型的启发式设计方法在解决组合优化问题时，受限于手动预定义的进化计算优化器和单任务训练方案，这限制了启发式算法的多样性探索并阻碍了其泛化能力。

**方法:** 提出了一个名为Meta-Optimization of Heuristics (MoH)的新框架。该框架在优化器层面工作，使用元学习原理发现有效的优化器。具体来说，MoH利用大语言模型迭代改进一个元优化器，该元优化器通过（自）调用自主构建多样化的优化器，从而消除了对预定义进化计算优化器的依赖。这些构建的优化器随后用于下游任务的启发式演化，促进更广泛的启发式探索。此外，MoH采用多任务训练方案以提高其泛化能力。

**结果:** 实验表明，MoH能够构建一个有效且可解释的元优化器，在各种下游任务中实现了最先进的性能，特别是在跨规模设置中表现突出。

**结论:** Meta-Optimization of Heuristics (MoH)框架提供了一种新的途径来解决组合优化问题，通过自主构建多样化的优化器和采用多任务训练方案，显著提升了启发式算法的探索能力和泛化性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generalizable+Heuristic+Generation+Through+Large+Language+Models+with+Meta-Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20881，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20881&send_immediately=true&force_search=false)

**原文摘要:** Heuristic design with large language models (LLMs) has emerged as a promising
approach for tackling combinatorial optimization problems (COPs). However,
existing approaches often rely on manually predefined evolutionary computation
(EC) optimizers and single-task training schemes, which may constrain the
exploration of diverse heuristic algorithms and hinder the generalization of
the resulting heuristics. To address these issues, we propose Meta-Optimization
of Heuristics (MoH), a novel framework that operates at the optimizer level,
discovering effective optimizers through the principle of meta-learning.
Specifically, MoH leverages LLMs to iteratively refine a meta-optimizer that
autonomously constructs diverse optimizers through (self-)invocation, thereby
eliminating the reliance on a predefined EC optimizer. These constructed
optimizers subsequently evolve heuristics for downstream tasks, enabling
broader heuristic exploration. Moreover, MoH employs a multi-task training
scheme to promote its generalization capability. Experiments on classic COPs
demonstrate that MoH constructs an effective and interpretable meta-optimizer,
achieving state-of-the-art performance across various downstream tasks,
particularly in cross-size settings.

</details>


### [76] [Fedivertex: a Graph Dataset based on Decentralized Social Networks for Trustworthy Machine Learning](https://arxiv.org/abs/2505.20882)
*Marc Damie, Edwige Cyffers*

**主要类别:** cs.LG

**概要:** 本论文介绍了Fedivertex，一个包含182个图的新数据集，涵盖了来自Fediverse的七个社交网络，每周爬取14周。该数据集用于促进去中心化机器学习算法的基准测试，并附带一个Python包以方便使用。此外，还提出了一种新的defederation任务，用于捕捉这些网络上的链接删除过程。


<details>
  <summary>更多</summary>
  
**动机:** 去中心化机器学习越来越受欢迎，因为它可以更好地扩展和控制数据。然而，现有的图数据集大多局限于盈利性的社交网络，受平台及其推荐算法的影响较大。因此，需要一个更真实的、非盈利性的数据集来测试去中心化算法。

**方法:** 作者从Fediverse（如Mastodon、Misskey和Lemmy等去中心化社交平台）中收集了182个图数据，覆盖了七个社交网络，每周爬取14周。他们还设计了一个新的任务——defederation任务，用于模拟这些网络上的链接删除过程。

**结果:** Fedivertex数据集已被发布并附带一个Python包以方便使用。通过在多个任务上进行测试，包括新的defederation任务，证明了该数据集的有效性和实用性。

**结论:** Fedivertex为去中心化机器学习提供了一个真实世界的替代数据集，有助于克服现有数据集的局限性。同时，新的defederation任务也为研究动态网络提供了新视角。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fedivertex%3A+a+Graph+Dataset+based+on+Decentralized+Social+Networks+for+Trustworthy+Machine+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20882，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20882&send_immediately=true&force_search=false)

**原文摘要:** Decentralized machine learning - where each client keeps its own data locally
and uses its own computational resources to collaboratively train a model by
exchanging peer-to-peer messages - is increasingly popular, as it enables
better scalability and control over the data. A major challenge in this setting
is that learning dynamics depend on the topology of the communication graph,
which motivates the use of real graph datasets for benchmarking decentralized
algorithms. Unfortunately, existing graph datasets are largely limited to
for-profit social networks crawled at a fixed point in time and often collected
at the user scale, where links are heavily influenced by the platform and its
recommendation algorithms. The Fediverse, which includes several free and
open-source decentralized social media platforms such as Mastodon, Misskey, and
Lemmy, offers an interesting real-world alternative. We introduce Fedivertex, a
new dataset of 182 graphs, covering seven social networks from the Fediverse,
crawled weekly over 14 weeks. We release the dataset along with a Python
package to facilitate its use, and illustrate its utility on several tasks,
including a new defederation task, which captures a process of link deletion
observed on these networks.

</details>


### [77] [How Do Transformers Learn Variable Binding in Symbolic Programs?](https://arxiv.org/abs/2505.20896)
*Yiwei Wu, Atticus Geiger, Raphaël Millière*

**主要类别:** cs.LG

**概要:** 在该论文中，研究者探讨了现代神经网络如何获得变量绑定的能力。通过训练一个Transformer模型执行符号程序中的变量解引用任务，发现模型经历了三个不同的训练阶段，并揭示了模型利用残差流作为可寻址内存空间以及专用注意力头跨标记位置路由信息的机制。


<details>
  <summary>更多</summary>
  
**动机:** 尽管经典的架构通常通过可寻址内存实现变量绑定，但现代缺乏内置绑定操作的神经网络如何获取这种能力尚未被很好理解。

**方法:** 研究者训练了一个Transformer模型来解引用符号程序中的查询变量，这些变量被分配数值常量或其他变量。程序要求跟踪最多四步深的变量赋值链以找到查询值，并且包含无关的赋值链作为干扰项。使用因果干预分析模型的学习机制。

**结果:** 模型学习到利用残差流作为可寻址内存空间，并使用专门的注意力头跨标记位置路由信息，从而动态跟踪变量绑定，导致准确的解引用。

**结论:** Transformer模型可以在没有明确架构支持的情况下学习实现系统的变量绑定，这连接了连接主义和符号方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+Do+Transformers+Learn+Variable+Binding+in+Symbolic+Programs%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20896，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20896&send_immediately=true&force_search=false)

**原文摘要:** Variable binding -- the ability to associate variables with values -- is
fundamental to symbolic computation and cognition. Although classical
architectures typically implement variable binding via addressable memory, it
is not well understood how modern neural networks lacking built-in binding
operations may acquire this capacity. We investigate this by training a
Transformer to dereference queried variables in symbolic programs where
variables are assigned either numerical constants or other variables. Each
program requires following chains of variable assignments up to four steps deep
to find the queried value, and also contains irrelevant chains of assignments
acting as distractors. Our analysis reveals a developmental trajectory with
three distinct phases during training: (1) random prediction of numerical
constants, (2) a shallow heuristic prioritizing early variable assignments, and
(3) the emergence of a systematic mechanism for dereferencing assignment
chains. Using causal interventions, we find that the model learns to exploit
the residual stream as an addressable memory space, with specialized attention
heads routing information across token positions. This mechanism allows the
model to dynamically track variable bindings across layers, resulting in
accurate dereferencing. Our results show how Transformer models can learn to
implement systematic variable binding without explicit architectural support,
bridging connectionist and symbolic approaches.

</details>


### [78] [One-Time Soft Alignment Enables Resilient Learning without Weight Transport](https://arxiv.org/abs/2505.20892)
*Jeonghwan Cheon, Jaehyuk Bae, Se-Bum Paik*

**主要类别:** cs.LG

**概要:** 本研究提出了一种通过初始化时的软对齐前向和反馈权重来改进反馈对齐方法的新策略，无需学习过程中的权重传输即可实现与反向传播相当的性能，并提高了训练稳定性、泛化能力和对抗鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 反向传播算法依赖于对称权重传输和全局同步，计算成本高且生物学上不切实际。反馈对齐方法虽然避免了对称权重传输，但在深度网络中通常存在学习性能差和不稳定的问题。

**方法:** 在初始化阶段引入一次性的前向和反馈权重之间的软对齐，这种方法不需要在学习过程中进行权重传输；并通过谱分析揭示该初始化条件如何促进更平滑的梯度流动和收敛到更平坦的极小值。

**结果:** 使用该初始化策略的深度网络能够达到与反向传播相当的性能，同时表现出更好的稳定性和泛化能力；允许适度偏离精确的权重对称性可以提高对抗鲁棒性。

**结论:** 简单的初始化策略可以在生物学上合理且资源高效的方式下，使深度网络实现有效的学习。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是One-Time+Soft+Alignment+Enables+Resilient+Learning+without+Weight+Transport，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20892，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20892&send_immediately=true&force_search=false)

**原文摘要:** Backpropagation is the cornerstone of deep learning, but its reliance on
symmetric weight transport and global synchronization makes it computationally
expensive and biologically implausible. Feedback alignment offers a promising
alternative by approximating error gradients through fixed random feedback,
thereby avoiding symmetric weight transport. However, this approach often
struggles with poor learning performance and instability, especially in deep
networks. Here, we show that a one-time soft alignment between forward and
feedback weights at initialization enables deep networks to achieve performance
comparable to backpropagation, without requiring weight transport during
learning. This simple initialization condition guides stable error minimization
in the loss landscape, improving network trainability. Spectral analyses
further reveal that initial alignment promotes smoother gradient flow and
convergence to flatter minima, resulting in better generalization and
robustness. Notably, we also find that allowing moderate deviations from exact
weight symmetry can improve adversarial robustness compared to standard
backpropagation. These findings demonstrate that a simple initialization
strategy can enable effective learning in deep networks in a biologically
plausible and resource-efficient manner.

</details>


### [79] [Humble AI in the real-world: the case of algorithmic hiring](https://arxiv.org/abs/2505.20918)
*Rahul Nair, Inge Vejsbjerg, Elizabeth Daly, Christos Varytimidis, Bran Knowles*

**主要类别:** cs.LG

**概要:** Humble AI在算法招聘中的应用研究，通过不确定性量化、熵估计和用户体验设计展示其技术可行性，并探讨了与招聘人员的初步讨论及未来用户研究计划。


<details>
  <summary>更多</summary>
  
**动机:** 当前AI系统在实际应用中存在对非传统背景候选人的误识和刻板印象等问题，难以通过标准的公平性和信任框架评估。因此需要一种更谨慎的方法来开发和部署AI系统。

**方法:** 在算法招聘领域中，通过不确定性量化、熵估计以及强调算法未知性的用户体验设计，将Humble AI的原则付诸实践。同时进行焦点小组讨论以收集招聘人员的反馈。

**结果:** 展示了如何在实践中应用Humble AI原则的技术可行性，包括不确定性的量化方法、熵估计以及用户体验设计。初步讨论表明这种方法可能增加用户的认知负担，但有助于建立对AI系统的信任。

**结论:** Humble AI为解决算法招聘中的复杂问题提供了一种可行的解决方案，尽管其较高的认知负荷可能需要进一步的研究来优化用户体验。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Humble+AI+in+the+real-world%3A+the+case+of+algorithmic+hiring，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20918，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20918&send_immediately=true&force_search=false)

**原文摘要:** Humble AI (Knowles et al., 2023) argues for cautiousness in AI development
and deployments through scepticism (accounting for limitations of statistical
learning), curiosity (accounting for unexpected outcomes), and commitment
(accounting for multifaceted values beyond performance). We present a
real-world case study for humble AI in the domain of algorithmic hiring.
Specifically, we evaluate virtual screening algorithms in a widely used hiring
platform that matches candidates to job openings. There are several challenges
in misrecognition and stereotyping in such contexts that are difficult to
assess through standard fairness and trust frameworks; e.g., someone with a
non-traditional background is less likely to rank highly. We demonstrate
technical feasibility of how humble AI principles can be translated to practice
through uncertainty quantification of ranks, entropy estimates, and a user
experience that highlights algorithmic unknowns. We describe preliminary
discussions with focus groups made up of recruiters. Future user studies seek
to evaluate whether the higher cognitive load of a humble AI system fosters a
climate of trust in its outcomes.

</details>


### [80] [DeepConvContext: A Multi-Scale Approach to Timeseries Classification in Human Activity Recognition](https://arxiv.org/abs/2505.20894)
*Marius Bock, Michael Moeller, Kristof Van Laerhoven*

**主要类别:** cs.LG

**概要:** 尽管在建模长程时间依赖性方面存在公认的局限性，但人类活动识别（HAR）传统上依赖于滑动窗口方法来分割标记的数据集。为了克服这一限制，我们提出了DeepConvContext框架，该框架通过处理时间有序的窗口序列来对HAR中的窗口内和窗口间的时间模式进行建模。与最近结合注意力机制的HAR模型不同，DeepConvContext仅依赖LSTM，并且消融研究表明LSTM在建模惯性传感器数据方面优于基于注意力的变体。在六个常用的HAR基准测试中，DeepConvContext相较于经典的DeepConvLSTM平均提高了10%的F1分数，最大提升可达21%。


<details>
  <summary>更多</summary>
  
**动机:** 传统的HAR方法使用滑动窗口独立分类每个窗口，这限制了可学习的时间上下文信息只存在于窗口内部，无法有效捕捉长程时间依赖性。为了解决这个约束，需要一种新的方法来同时建模窗口内和窗口间的时间模式。

**方法:** 提出了一种名为DeepConvContext的多尺度时间序列分类框架。该框架受到基于视觉的时序动作定位社区的启发，通过处理时间有序的窗口序列来建模HAR中的窗口内和窗口间的时间模式。并且完全依赖LSTM而不是注意力机制。

**结果:** 在六个广泛使用的HAR基准测试中，DeepConvContext相对于经典的DeepConvLSTM实现了平均10%的F1分数提升，最大提升达到了21%。

**结论:** DeepConvContext是一种有效的多尺度时间序列分类框架，能够显著提高HAR任务的性能，尤其是在F1分数上取得了明显的改进。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DeepConvContext%3A+A+Multi-Scale+Approach+to+Timeseries+Classification+in+Human+Activity+Recognition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20894，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20894&send_immediately=true&force_search=false)

**原文摘要:** Despite recognized limitations in modeling long-range temporal dependencies,
Human Activity Recognition (HAR) has traditionally relied on a sliding window
approach to segment labeled datasets. Deep learning models like the
DeepConvLSTM typically classify each window independently, thereby restricting
learnable temporal context to within-window information. To address this
constraint, we propose DeepConvContext, a multi-scale time series
classification framework for HAR. Drawing inspiration from the vision-based
Temporal Action Localization community, DeepConvContext models both intra- and
inter-window temporal patterns by processing sequences of time-ordered windows.
Unlike recent HAR models that incorporate attention mechanisms, DeepConvContext
relies solely on LSTMs -- with ablation studies demonstrating the superior
performance of LSTMs over attention-based variants for modeling inertial sensor
data. Across six widely-used HAR benchmarks, DeepConvContext achieves an
average 10% improvement in F1-score over the classic DeepConvLSTM, with gains
of up to 21%. Code to reproduce our experiments is publicly available via
github.com/mariusbock/context_har.

</details>


### [81] [Deep k-grouping: An Unsupervised Learning Framework for Combinatorial Optimization on Graphs and Hypergraphs](https://arxiv.org/abs/2505.20972)
*Sen Bai, Chunqi Yang, Xin Bai, Xin Zhang, Zhengang Jiang*

**主要类别:** cs.LG

**概要:** 近年来，随着AI计算在科学发现中的闪耀表现，其在组合优化（CO）领域的潜力也逐渐显现。然而，现有的无监督神经网络求解器在大规模图和超图的k分组问题（如着色、分区）上表现不佳，因为计算框架有限。本文提出了Deep k-grouping，一种基于无监督学习的CO框架。具体贡献包括：1) 新颖的一次多项式无约束二进制优化(OH-PUBO)公式，用于建模图和超图上的k分组问题；2) 针对大规模k分组CO问题的GPU加速算法；3) 基于Gini系数的连续松弛退火策略，以确保解的离散性并防止陷入局部最优。实验结果表明，Deep k-grouping优于现有的神经网络求解器和经典启发式方法（如SCIP和Tabu）。


<details>
  <summary>更多</summary>
  
**动机:** 现有的无监督神经网络求解器难以解决大规模图和超图上的k分组问题，因此需要新的计算框架来提升性能和扩展性。

**方法:** 提出了一种名为Deep k-grouping的无监督学习组合优化框架，包括OH-PUBO公式化方法、GPU加速算法以及基于Gini系数的连续松弛退火策略。通过将大规模OH-PUBO目标的松弛作为可微损失函数进行无监督训练，并利用GPU加速统一训练流程，从而实现高效求解。

**结果:** 实验结果表明，Deep k-grouping在大规模k分组问题上的表现优于现有的神经网络求解器和经典启发式方法（如SCIP和Tabu）。

**结论:** Deep k-grouping为解决大规模图和超图上的k分组问题提供了一种有效的无监督学习框架，具有更高的性能和扩展性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Deep+k-grouping%3A+An+Unsupervised+Learning+Framework+for+Combinatorial+Optimization+on+Graphs+and+Hypergraphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20972，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20972&send_immediately=true&force_search=false)

**原文摘要:** Along with AI computing shining in scientific discovery, its potential in the
combinatorial optimization (CO) domain has also emerged in recent years. Yet,
existing unsupervised neural network solvers struggle to solve $k$-grouping
problems (e.g., coloring, partitioning) on large-scale graphs and hypergraphs,
due to limited computational frameworks. In this work, we propose Deep
$k$-grouping, an unsupervised learning-based CO framework. Specifically, we
contribute: Novel one-hot encoded polynomial unconstrained binary optimization
(OH-PUBO), a formulation for modeling k-grouping problems on graphs and
hypergraphs (e.g., graph/hypergraph coloring and partitioning); GPU-accelerated
algorithms for large-scale k-grouping CO problems. Deep $k$-grouping employs
the relaxation of large-scale OH-PUBO objectives as differentiable loss
functions and trains to optimize them in an unsupervised manner. To ensure
scalability, it leverages GPU-accelerated algorithms to unify the training
pipeline; A Gini coefficient-based continuous relaxation annealing strategy to
enforce discreteness of solutions while preventing convergence to local optima.
Experimental results demonstrate that Deep $k$-grouping outperforms existing
neural network solvers and classical heuristics such as SCIP and Tabu.

</details>


### [82] [BIPNN: Learning to Solve Binary Integer Programming via Hypergraph Neural Networks](https://arxiv.org/abs/2505.20997)
*Sen Bai, Chunqi Yang, Xin Bai, Xin Zhang, Zhengang Jiang*

**主要类别:** cs.LG

**概要:** 提出了一种新的框架BIPNN，用于通过超图神经网络解决非线性二进制整数规划问题，具有优越的性能和可扩展性。


<details>
  <summary>更多</summary>
  
**动机:** 整数线性规划（ILP）问题在科学领域中需要离散决策时至关重要。然而，现有的基于神经网络的求解器缺乏处理非线性挑战的可扩展性，而最先进的分支切割求解器使用线性松弛，导致辅助变量指数增长和严重的计算限制。

**方法:** 提出了BIPNN（二进制整数规划神经网络），一种无监督学习框架，利用超图神经网络解决非线性BIP问题。该方法将BIP约束、离散和非线性优化问题重新表述为无约束、可微分和多项式损失函数，并提出了一个基于GPU加速和连续退火增强的训练管道。

**结果:** 广泛的实验表明，该方法在合成和真实世界的数据集上表现出优越性。

**结论:** BIPNN能够在并行处理大规模非线性项的同时显著降低训练成本，并生成高质量的离散解，解决了现有方法中的可扩展性和计算效率问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BIPNN%3A+Learning+to+Solve+Binary+Integer+Programming+via+Hypergraph+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20997，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20997&send_immediately=true&force_search=false)

**原文摘要:** Binary (0-1) integer programming (BIP) is pivotal in scientific domains
requiring discrete decision-making. As the advance of AI computing, recent
works explore neural network-based solvers for integer linear programming (ILP)
problems. Yet, they lack scalability for tackling nonlinear challenges. To
handle nonlinearities, state-of-the-art Branch-and-Cut solvers employ linear
relaxations, leading to exponential growth in auxiliary variables and severe
computation limitations. To overcome these limitations, we propose BIPNN
(Binary Integer Programming Neural Network), an unsupervised learning framework
to solve nonlinear BIP problems via hypergraph neural networks (HyperGNN).
Specifically, BIPNN reformulates BIPs-constrained, discrete, and nonlinear
(sin, log, exp) optimization problems-into unconstrained, differentiable, and
polynomial loss functions. The reformulation stems from the observation of a
precise one-to-one mapping between polynomial BIP objectives and hypergraph
structures, enabling the unsupervised training of HyperGNN to optimize BIP
problems in an end-to-end manner. On this basis, we propose a GPU-accelerated
and continuous-annealing-enhanced training pipeline for BIPNN. The pipeline
enables BIPNN to optimize large-scale nonlinear terms in BIPs fully in parallel
via straightforward gradient descent, thus significantly reducing the training
cost while ensuring the generation of discrete, high-quality solutions.
Extensive experiments on synthetic and real-world datasets highlight the
superiority of our approach.

</details>


### [83] [Label Leakage in Federated Inertial-based Human Activity Recognition](https://arxiv.org/abs/2505.20924)
*Marius Bock, Maximilian Hopp, Kristof Van Laerhoven, Michael Moeller*

**主要类别:** cs.LG

**概要:** 在人类活动识别（HAR）中，基于梯度的标签泄漏攻击可以有效恢复输入标签，即使对于训练好的模型，其重建准确率也可高达90%。然而，本地差分隐私技术如梯度噪声和裁剪仅提供有限保护。本文提供了针对联邦HAR系统隐私部署的实际建议，并指出了未来研究的开放性挑战。


<details>
  <summary>更多</summary>
  
**动机:** 尽管先前的研究表明联邦学习更新可能会泄露敏感信息，但尚未有人在人类活动识别（HAR）背景下研究过标签重建攻击。鉴于活动标签的敏感性，本文评估了最先进的基于梯度的标签泄漏攻击对HAR基准数据集的有效性。

**方法:** 本文研究了不同因素（如活动类别数量、采样策略和类别不平衡）对标签泄漏程度的影响，并测试了本地差分隐私技术（如梯度噪声和裁剪）是否能够有效防止这些攻击。

**结果:** 研究发现，活动类别数量、采样策略和类别不平衡是影响标签泄漏的关键因素。在两个基准数据集上，重建准确率可达90%。此外，本地差分隐私技术提供的保护有限，某些攻击仍能可靠地推断出多数和少数类别的标签。

**结论:** 本文提出了针对隐私感知的联邦HAR系统部署的实际建议，并确定了未来研究的开放性挑战。实验代码已公开。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Label+Leakage+in+Federated+Inertial-based+Human+Activity+Recognition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20924，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20924&send_immediately=true&force_search=false)

**原文摘要:** While prior work has shown that Federated Learning updates can leak sensitive
information, label reconstruction attacks, which aim to recover input labels
from shared gradients, have not yet been examined in the context of Human
Activity Recognition (HAR). Given the sensitive nature of activity labels, this
study evaluates the effectiveness of state-of-the-art gradient-based label
leakage attacks on HAR benchmark datasets. Our findings show that the number of
activity classes, sampling strategy, and class imbalance are critical factors
influencing the extent of label leakage, with reconstruction accuracies
reaching up to 90% on two benchmark datasets, even for trained models.
Moreover, we find that Local Differential Privacy techniques such as gradient
noise and clipping offer only limited protection, as certain attacks still
reliably infer both majority and minority class labels. We conclude by offering
practical recommendations for the privacy-aware deployment of federated HAR
systems and identify open challenges for future research. Code to reproduce our
experiments is publicly available via github.com/mariusbock/leakage_har.

</details>


### [84] [TabAttackBench: A Benchmark for Adversarial Attacks on Tabular Data](https://arxiv.org/abs/2505.21027)
*Zhipeng He, Chun Ouyang, Lijie Wen, Cong Liu, Catarina Moreira*

**主要类别:** cs.LG

**概要:** 为了应对表格数据中的对抗性攻击，本文提出了一种新的基准测试方法，评估了五种对抗性攻击在四个模型上的有效性和不可感知性。通过使用11个表格数据集进行实验，研究发现为改进对抗性攻击算法设计提供了宝贵见解。


<details>
  <summary>更多</summary>
  
**动机:** 当前大多数研究主要关注实现有效的对抗性攻击，而忽略了维持不可感知性的重要性，特别是在表格数据中。由于表格数据具有异质性和复杂的特征相互依赖性，与图像数据有很大不同，因此需要一种新的评估方法。

**方法:** 提出了一种新的基准测试方法，用于评估对抗性攻击的有效性和不可感知性。该方法在四个模型上对五种对抗性攻击进行了评估，并使用了11个表格数据集（包括混合型和纯数值型数据集）。

**结果:** 通过对不同数据集类型的比较，发现有效性和不可感知性之间的交互作用影响了攻击的整体性能，并揭示了这些发现的广泛影响。

**结论:** 本研究提供的见解有助于改进对抗性攻击算法的设计，推动表格数据领域中的对抗性机器学习的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TabAttackBench%3A+A+Benchmark+for+Adversarial+Attacks+on+Tabular+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21027，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21027&send_immediately=true&force_search=false)

**原文摘要:** Adversarial attacks pose a significant threat to machine learning models by
inducing incorrect predictions through imperceptible perturbations to input
data. While these attacks have been extensively studied in unstructured data
like images, their application to tabular data presents new challenges. These
challenges arise from the inherent heterogeneity and complex feature
interdependencies in tabular data, which differ significantly from those in
image data. To address these differences, it is crucial to consider
imperceptibility as a key criterion specific to tabular data. Most current
research focuses primarily on achieving effective adversarial attacks, often
overlooking the importance of maintaining imperceptibility. To address this
gap, we propose a new benchmark for adversarial attacks on tabular data that
evaluates both effectiveness and imperceptibility. In this study, we assess the
effectiveness and imperceptibility of five adversarial attacks across four
models using eleven tabular datasets, including both mixed and numerical-only
datasets. Our analysis explores how these factors interact and influence the
overall performance of the attacks. We also compare the results across
different dataset types to understand the broader implications of these
findings. The findings from this benchmark provide valuable insights for
improving the design of adversarial attack algorithms, thereby advancing the
field of adversarial machine learning on tabular data.

</details>


### [85] [MLMC-based Resource Adequacy Assessment with Active Learning Trained Surrogate Models](https://arxiv.org/abs/2505.20930)
*Ruiqi Zhang, Simon H. Tindemans*

**主要类别:** cs.LG

**概要:** 本研究提出了一种基于投票委员会主动学习的方法，通过减少标记调用来提高多层蒙特卡洛（MLMC）方法在电力系统资源充足性评估中的效率。


<details>
  <summary>更多</summary>
  
**动机:** 数据驱动的代理模型虽已被引入多层蒙特卡洛框架以加速复杂电力系统的可靠性评估，但在资源充足性评估中缺乏预标记数据集，且标记训练数据所需时间较长，降低了代理模型的效率。

**方法:** 引入了一个考虑训练时间的速度度量，并提出了投票委员会主动学习方法来减少标记调用次数，从而提高MLMC方法的效率。

**结果:** 案例研究表明，在实际方差阈值范围内，与常规代理建模方法相比，主动学习方法可以显著提高MLMC效率并减少训练工作量。

**结论:** 投票委员会主动学习方法在减少标记需求的同时，能够有效提升MLMC方法在资源充足性评估中的效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MLMC-based+Resource+Adequacy+Assessment+with+Active+Learning+Trained+Surrogate+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20930，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20930&send_immediately=true&force_search=false)

**原文摘要:** Multilevel Monte Carlo (MLMC) is a flexible and effective variance reduction
technique for accelerating reliability assessments of complex power system.
Recently, data-driven surrogate models have been proposed as lower-level models
in the MLMC framework due to their high correlation and negligible execution
time once trained. However, in resource adequacy assessments, pre-labeled
datasets are typically unavailable. For large-scale systems, the efficiency
gains from surrogate models are often offset by the substantial time required
for labeling training data. Therefore, this paper introduces a speed metric
that accounts for training time in evaluating MLMC efficiency. Considering the
total time budget is limited, a vote-by-committee active learning approach is
proposed to reduce the required labeling calls. A case study demonstrates that,
within practical variance thresholds, active learning enables significantly
improved MLMC efficiency with reduced training effort, compared to regular
surrogate modelling approaches.

</details>


### [86] [A domain adaptation neural network for digital twin-supported fault diagnosis](https://arxiv.org/abs/2505.21046)
*Zhenling Chen, Haiwei Fu, Zhiguo Zeng*

**主要类别:** cs.LG

**概要:** 本研究提出了一种基于域对抗神经网络（DANN）的故障诊断框架，用于解决数字孪生生成数据与实际系统之间的差异问题。通过在机器人故障诊断数据集上的实验表明，结合域适应方法显著提高了诊断性能，例如将CNN模型的准确率从70.00%提升至80.22%。


<details>
  <summary>更多</summary>
  
**动机:** 深度学习在故障诊断中缺乏足够的标注数据，数字孪生虽然能生成模拟数据但存在与真实系统之间的差异，导致模型在实际应用中的性能下降。

**方法:** 提出了一种基于Domain-Adversarial Neural Networks (DANN) 的故障诊断框架，利用域适应技术实现从模拟数据到实际数据的知识迁移，并将其与常见轻量级深度学习模型（如CNN、TCN、Transformer和LSTM）进行比较。

**结果:** 实验结果表明，使用DANN方法进行域适应可以显著提高模型的诊断性能，特别是在实际测试数据上的准确率提升了10%以上。

**结论:** 域适应技术能够有效缩小模拟与实际数据之间的差距，提出的DANN框架为解决数字孪生与真实系统间差异提供了有效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+domain+adaptation+neural+network+for+digital+twin-supported+fault+diagnosis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21046，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21046&send_immediately=true&force_search=false)

**原文摘要:** Digital twins offer a promising solution to the lack of sufficient labeled
data in deep learning-based fault diagnosis by generating simulated data for
model training. However, discrepancies between simulation and real-world
systems can lead to a significant drop in performance when models are applied
in real scenarios. To address this issue, we propose a fault diagnosis
framework based on Domain-Adversarial Neural Networks (DANN), which enables
knowledge transfer from simulated (source domain) to real-world (target domain)
data. We evaluate the proposed framework using a publicly available robotics
fault diagnosis dataset, which includes 3,600 sequences generated by a digital
twin model and 90 real sequences collected from physical systems. The DANN
method is compared with commonly used lightweight deep learning models such as
CNN, TCN, Transformer, and LSTM. Experimental results show that incorporating
domain adaptation significantly improves the diagnostic performance. For
example, applying DANN to a baseline CNN model improves its accuracy from
70.00% to 80.22% on real-world test data, demonstrating the effectiveness of
domain adaptation in bridging the sim-to-real gap.

</details>


### [87] [NatADiff: Adversarial Boundary Guidance for Natural Adversarial Diffusion](https://arxiv.org/abs/2505.20934)
*Max Collins, Jordan Vice, Tim French, Ajmal Mian*

**主要类别:** cs.LG

**概要:** 生成自然对抗样本的新型方法NatADiff，利用去噪扩散技术提高模型攻击迁移性及与真实测试误差的一致性。


<details>
  <summary>更多</summary>
  
**动机:** 对抗样本研究能揭示模型分类所依赖的特征，并有助于提升对未来攻击的鲁棒性。然而，现有文献多关注受限对抗样本，未能准确反映实际场景中的测试错误。

**方法:** 提出NatADiff方案，基于去噪扩散生成自然对抗样本，引导扩散轨迹至真实与对抗类别的交集区域，结合时间旅行采样和增强分类器引导以提高攻击迁移性并保持图像保真度。

**结果:** 在多种模型架构上展现出更高的迁移性，与自然测试时错误更一致（通过FID衡量），攻击成功率与当前最先进技术相当。

**结论:** NatADiff生成的对抗样本不仅在不同模型间更有效地迁移，而且更接近自然发生的测试时错误。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NatADiff%3A+Adversarial+Boundary+Guidance+for+Natural+Adversarial+Diffusion，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20934，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20934&send_immediately=true&force_search=false)

**原文摘要:** Adversarial samples exploit irregularities in the manifold ``learned'' by
deep learning models to cause misclassifications. The study of these
adversarial samples provides insight into the features a model uses to classify
inputs, which can be leveraged to improve robustness against future attacks.
However, much of the existing literature focuses on constrained adversarial
samples, which do not accurately reflect test-time errors encountered in
real-world settings. To address this, we propose `NatADiff', an adversarial
sampling scheme that leverages denoising diffusion to generate natural
adversarial samples. Our approach is based on the observation that natural
adversarial samples frequently contain structural elements from the adversarial
class. Deep learning models can exploit these structural elements to shortcut
the classification process, rather than learning to genuinely distinguish
between classes. To leverage this behavior, we guide the diffusion trajectory
towards the intersection of the true and adversarial classes, combining
time-travel sampling with augmented classifier guidance to enhance attack
transferability while preserving image fidelity. Our method achieves comparable
attack success rates to current state-of-the-art techniques, while exhibiting
significantly higher transferability across model architectures and better
alignment with natural test-time errors as measured by FID. These results
demonstrate that NatADiff produces adversarial samples that not only transfer
more effectively across models, but more faithfully resemble naturally
occurring test-time errors.

</details>


### [88] [Revisiting Sparsity Constraint Under High-Rank Property in Partial Multi-Label Learning](https://arxiv.org/abs/2505.20938)
*Chongjie Si, Yidan Cui, Fuchao Yang, Xiaokang Yang, Wei Shen*

**主要类别:** cs.LG

**概要:** 本文提出了一种新的部分多标签学习方法Schirn，通过在噪声标签矩阵上引入稀疏性约束并在预测标签矩阵上强制执行高秩属性，解决了现有方法中噪声标签矩阵稀疏性和真实标签矩阵低秩性假设的冲突问题。实验表明，Schirn在处理现实世界的部分多标签学习挑战时表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 部分多标签学习（PML）在每个样本都与包含真实标签和噪声标签的候选标签集相关联的情况下进行。然而，现有的PML方法依赖于噪声标签矩阵的稀疏性和真实标签矩阵的低秩性的假设，这些假设在现实中往往是冲突且不切实际的。

**方法:** 提出了一种新方法Schirn，该方法在噪声标签矩阵上引入稀疏性约束的同时，在预测标签矩阵上施加高秩属性。

**结果:** 广泛的实验结果表明，Schirn相比现有最先进方法具有更优越的性能。

**结论:** Schirn有效地解决了现有PML方法中关于噪声标签矩阵稀疏性和真实标签矩阵低秩性假设之间的冲突，并在实际应用中表现良好。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Revisiting+Sparsity+Constraint+Under+High-Rank+Property+in+Partial+Multi-Label+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20938，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20938&send_immediately=true&force_search=false)

**原文摘要:** Partial Multi-Label Learning (PML) extends the multi-label learning paradigm
to scenarios where each sample is associated with a candidate label set
containing both ground-truth labels and noisy labels. Existing PML methods
commonly rely on two assumptions: sparsity of the noise label matrix and
low-rankness of the ground-truth label matrix. However, these assumptions are
inherently conflicting and impractical for real-world scenarios, where the true
label matrix is typically full-rank or close to full-rank. To address these
limitations, we demonstrate that the sparsity constraint contributes to the
high-rank property of the predicted label matrix. Based on this, we propose a
novel method Schirn, which introduces a sparsity constraint on the noise label
matrix while enforcing a high-rank property on the predicted label matrix.
Extensive experiments demonstrate the superior performance of Schirn compared
to state-of-the-art methods, validating its effectiveness in tackling
real-world PML challenges.

</details>


### [89] [Efficient Large Language Model Inference with Neural Block Linearization](https://arxiv.org/abs/2505.21077)
*Mete Erdogan, Francesco Tonin, Volkan Cevher*

**主要类别:** cs.LG

**概要:** 本研究提出了Neural Block Linearization (NBL)，一种通过用线性近似替代自注意力层来加速Transformer模型推理的新框架。NBL利用规范相关分析计算近似误差的理论上限，并以此为标准选择具有最低线性化误差的LLM层进行替换，从而在保持竞争力的准确性的同时显著提高计算速度。例如，在DeepSeek-R1-Distill-Llama-8B中应用NBL到12个自注意力层，可以将推理速度提高32%，而准确率损失不到1%。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型（LLMs）的高推理需求给其部署带来了重大挑战，因此需要更高效的推理方法。

**方法:** 提出了一种名为Neural Block Linearization (NBL)的框架，该框架通过使用源自线性最小均方误差估计器的线性近似来替代自注意力层，同时利用规范相关分析计算近似误差的理论上限，作为选择替换LLM层的标准。

**结果:** 实验表明，NBL可以在多个推理基准上实现显著的计算加速，同时保持竞争力的准确性。具体来说，在DeepSeek-R1-Distill-Llama-8B中应用NBL到12个自注意力层时，推理速度提高了32%，而准确率损失不到1%。

**结论:** NBL提供了一个灵活且有前景的解决方案，以提高LLM的推理效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+Large+Language+Model+Inference+with+Neural+Block+Linearization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21077，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21077&send_immediately=true&force_search=false)

**原文摘要:** The high inference demands of transformer-based Large Language Models (LLMs)
pose substantial challenges in their deployment. To this end, we introduce
Neural Block Linearization (NBL), a novel framework for accelerating
transformer model inference by replacing self-attention layers with linear
approximations derived from Linear Minimum Mean Squared Error estimators. NBL
leverages Canonical Correlation Analysis to compute a theoretical upper bound
on the approximation error. Then, we use this bound as a criterion for
substitution, selecting the LLM layers with the lowest linearization error. NBL
can be efficiently applied to pre-trained LLMs without the need for
fine-tuning. In experiments, NBL achieves notable computational speed-ups while
preserving competitive accuracy on multiple reasoning benchmarks. For instance,
applying NBL to 12 self-attention layers in DeepSeek-R1-Distill-Llama-8B
increases the inference speed by 32% with less than 1% accuracy trade-off,
making it a flexible and promising solution to improve the inference efficiency
of LLMs.

</details>


### [90] [Semantic Communication meets System 2 ML: How Abstraction, Compositionality and Emergent Languages Shape Intelligence](https://arxiv.org/abs/2505.20964)
*Mehdi Bennis, Salem Lahlou*

**主要类别:** cs.LG

**概要:** The paper calls for a paradigm shift in 6G and AI development, advocating for systems with semantic understanding based on System-2 cognition principles.


<details>
  <summary>更多</summary>
  
**动机:** Current 6G visions are just incremental improvements over 5G, and AI progress is hindered by limitations such as brittleness, data-hunger, and lack of robust reasoning.

**方法:** The proposed method involves three pillars: Abstraction, Compositionality, and Emergent Communication to create intelligent agents capable of meaningful interaction.

**结果:** This approach aims to establish truly intelligent systems that can reason, adapt, and collaborate effectively.

**结论:** By integrating the outlined principles, the groundwork is laid for unifying wireless communications, machine learning, and robotics into a single coherent framework.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Semantic+Communication+meets+System+2+ML%3A+How+Abstraction%2C+Compositionality+and+Emergent+Languages+Shape+Intelligence，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20964，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20964&send_immediately=true&force_search=false)

**原文摘要:** The trajectories of 6G and AI are set for a creative collision. However,
current visions for 6G remain largely incremental evolutions of 5G, while
progress in AI is hampered by brittle, data-hungry models that lack robust
reasoning capabilities. This paper argues for a foundational paradigm shift,
moving beyond the purely technical level of communication toward systems
capable of semantic understanding and effective, goal-oriented interaction. We
propose a unified research vision rooted in the principles of System-2
cognition, built upon three pillars: Abstraction, enabling agents to learn
meaningful world models from raw sensorimotor data; Compositionality, providing
the algebraic tools to combine learned concepts and subsystems; and Emergent
Communication, allowing intelligent agents to create their own adaptive and
grounded languages. By integrating these principles, we lay the groundwork for
truly intelligent systems that can reason, adapt, and collaborate, unifying
advances in wireless communications, machine learning, and robotics under a
single coherent framework.

</details>


### [91] [SageAttention2++: A More Efficient Implementation of SageAttention2](https://arxiv.org/abs/2505.21136)
*Jintao Zhang, Xiaoming Xu, Jia Wei, Haofeng Huang, Pengle Zhang, Chendong Xiang, Jun Zhu, Jianfei Chen*

**主要类别:** cs.LG

**概要:** SageAttention2++通过使用FP8 Matmul指令加速注意力机制，比FlashAttention快3.9倍，且保持与SageAttention2相同的精度。


<details>
  <summary>更多</summary>
  
**动机:** 注意力机制的效率至关重要，因其时间复杂度随序列长度二次增长。为了加速注意力机制中的矩阵乘法运算，SageAttention2利用量化技术进行优化。然而，为进一步提升其性能，需要探索更高效的计算方法。

**方法:** 提出利用FP8 Matmul指令（累积至FP16）来进一步加速SageAttention2，该指令速度是原SageAttention2中使用的FP8 Matmul的两倍。

**结果:** 实验表明，SageAttention2++相比FlashAttention实现了3.9倍的速度提升，同时保持了与SageAttention2相同的注意力精度，并在包括语言、图像和视频生成在内的多种模型中展现出有效的加速能力，端到端指标损失可忽略不计。

**结论:** SageAttention2++显著提升了注意力机制的计算效率，适用于多种类型的生成模型，代码将在https://github.com/thu-ml/SageAttention公开。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SageAttention2%2B%2B%3A+A+More+Efficient+Implementation+of+SageAttention2，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21136，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21136&send_immediately=true&force_search=false)

**原文摘要:** The efficiency of attention is critical because its time complexity grows
quadratically with sequence length. SageAttention2 addresses this by utilizing
quantization to accelerate matrix multiplications (Matmul) in attention. To
further accelerate SageAttention2, we propose to utilize the faster instruction
of FP8 Matmul accumulated in FP16. The instruction is 2x faster than the FP8
Matmul used in SageAttention2. Our experiments show that SageAttention2++
achieves a 3.9x speedup over FlashAttention while maintaining the same
attention accuracy as SageAttention2. This means SageAttention2++ effectively
accelerates various models, including those for language, image, and video
generation, with negligible end-to-end metrics loss. The code will be available
at https://github.com/thu-ml/SageAttention.

</details>


### [92] [Understanding the behavior of representation forgetting in continual learning](https://arxiv.org/abs/2505.20970)
*Joonkyu Kim, Yejin Kim, Jy-yong Sohn*

**主要类别:** cs.LG

**概要:** 在持续学习场景中，灾难性遗忘是一个关键问题。本文首次对表示遗忘进行理论分析，并引入了表示差异这一新度量来衡量模型在持续学习过程中不同时间点的表示空间差异。通过数学分析，发现高层网络更容易发生遗忘，而增加网络宽度可以减缓遗忘过程。实验结果在Split-CIFAR100和ImageNet1K数据集上验证了这些理论发现。


<details>
  <summary>更多</summary>
  
**动机:** 灾难性遗忘是持续学习中的关键问题，需要有效衡量这种遗忘。最近，研究者开始关注隐藏层的表示遗忘。

**方法:** 提出表示差异这一新度量，用于衡量持续学习过程中模型不同快照之间的表示空间差异；通过数学分析推导出表示遗忘的动力学特性：高层网络遗忘更快、更严重，网络宽度增加可以减缓遗忘。

**结果:** 理论分析和实验结果表明，表示差异是一个有效的替代指标，能够准确反映表示遗忘的情况。实验在Split-CIFAR100和ImageNet1K数据集上验证了理论发现。

**结论:** 本文提供了表示遗忘的第一个理论分析，并证明了表示差异是一个有效的度量方法，可用于理解持续学习的行为。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+the+behavior+of+representation+forgetting+in+continual+learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20970，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20970&send_immediately=true&force_search=false)

**原文摘要:** In continual learning scenarios, catastrophic forgetting of previously
learned tasks is a critical issue, making it essential to effectively measure
such forgetting. Recently, there has been growing interest in focusing on
representation forgetting, the forgetting measured at the hidden layer. In this
paper, we provide the first theoretical analysis of representation forgetting
and use this analysis to better understand the behavior of continual learning.
First, we introduce a new metric called representation discrepancy, which
measures the difference between representation spaces constructed by two
snapshots of a model trained through continual learning. We demonstrate that
our proposed metric serves as an effective surrogate for the representation
forgetting while remaining analytically tractable. Second, through mathematical
analysis of our metric, we derive several key findings about the dynamics of
representation forgetting: the forgetting occurs more rapidly to a higher
degree as the layer index increases, while increasing the width of the network
slows down the forgetting process. Third, we support our theoretical findings
through experiments on real image datasets, including Split-CIFAR100 and
ImageNet1K.

</details>


### [93] [HeteroBA: A Structure-Manipulating Backdoor Attack on Heterogeneous Graphs](https://arxiv.org/abs/2505.21140)
*Honglin Gao, Xiang Li, Lan Zhao, Gaoxi Xiao*

**主要类别:** cs.LG

**概要:** 提出了一种新的异构后门攻击（HeteroBA）框架，用于异构图上的节点分类任务。通过插入精心设计的触发节点并利用注意力和聚类策略选择有影响力的辅助节点，导致模型对特定节点的错误分类，同时保持干净数据的准确性。实验表明，该方法在多种HGNN架构上具有高攻击成功率且对清洁准确率影响小。此研究揭示了HGNN中的潜在漏洞，并呼吁加强对此类威胁的防御。


<details>
  <summary>更多</summary>
  
**动机:** 现有的异构图神经网络（HGNNs）研究主要集中在提升预测性能上，而对其鲁棒性和安全性（特别是后门攻击方面）的研究较少。因此，需要探索HGNNs在后门攻击下的脆弱性。

**方法:** 提出HeteroBA框架，通过插入具有真实特征和目标结构连接的触发节点，结合注意力机制和聚类策略选择有影响力的辅助节点，以实现有效的触发传播。这种方法使得模型在保持对干净数据准确性的前提下，将特定节点错误分类为目标标签。

**结果:** 在三个数据集和多种HGNN架构上的实验结果表明，HeteroBA能够以最小的清洁准确率损失实现高攻击成功率。

**结论:** 本研究揭示了HGNNs在后门攻击下的潜在漏洞，强调了在多关系图场景中构建更鲁棒防御机制的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是HeteroBA%3A+A+Structure-Manipulating+Backdoor+Attack+on+Heterogeneous+Graphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21140，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21140&send_immediately=true&force_search=false)

**原文摘要:** Heterogeneous graph neural networks (HGNNs) have recently drawn increasing
attention for modeling complex multi-relational data in domains such as
recommendation, finance, and social networks. While existing research has been
largely focused on enhancing HGNNs' predictive performance, their robustness
and security, especially under backdoor attacks, remain underexplored. In this
paper, we propose a novel Heterogeneous Backdoor Attack (HeteroBA) framework
for node classification tasks on heterogeneous graphs. HeteroBA inserts
carefully crafted trigger nodes with realistic features and targeted structural
connections, leveraging attention-based and clustering-based strategies to
select influential auxiliary nodes for effective trigger propagation, thereby
causing the model to misclassify specific nodes into a target label while
maintaining accuracy on clean data. Experimental results on three datasets and
various HGNN architectures demonstrate that HeteroBA achieves high attack
success rates with minimal impact on the clean accuracy. Our method sheds light
on potential vulnerabilities in HGNNs and calls for more robust defenses
against backdoor threats in multi-relational graph scenarios.

</details>


### [94] [STEB: In Search of the Best Evaluation Approach for Synthetic Time Series](https://arxiv.org/abs/2505.21160)
*Michael Stenger, Robert Leppich, André Bauer, Samuel Kounev*

**主要类别:** cs.LG

**概要:** 提出了一种新的基准框架STEB，用于综合且可解释的合成时间序列评估指标的自动化比较。通过10个数据集、随机性注入和13个可配置的数据转换，计算了度量可靠性和评分一致性指标，并分析了41个文献中的度量排名，证实了上游时间序列嵌入对最终评分的显著影响。


<details>
  <summary>更多</summary>
  
**动机:** 由于数据增强或隐私规定，对合成时间序列的需求日益增长，导致众多生成模型、框架和评估措施的出现。然而，客观地大规模比较这些措施仍是一个开放性挑战。

**方法:** 提出了Synthetic Time series Evaluation Benchmark (STEB)，这是第一个允许全面且可解释的合成时间序列评估措施自动比较的基准框架。使用10个多样化的数据集、随机性注入以及13个可配置的数据转换，STEB计算度量可靠性与评分一致性指标。此外，STEB跟踪运行时间、测试错误，并具有顺序和平行操作模式。

**结果:** 在实验中确定了来自文献的41个度量的排名，并确认上游时间序列嵌入的选择对最终评分有重大影响。

**结论:** STEB为合成时间序列评估措施提供了全面且可解释的自动化比较方法，强调了时间序列嵌入选择的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是STEB%3A+In+Search+of+the+Best+Evaluation+Approach+for+Synthetic+Time+Series，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21160，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21160&send_immediately=true&force_search=false)

**原文摘要:** The growing need for synthetic time series, due to data augmentation or
privacy regulations, has led to numerous generative models, frameworks, and
evaluation measures alike. Objectively comparing these measures on a large
scale remains an open challenge. We propose the Synthetic Time series
Evaluation Benchmark (STEB) -- the first benchmark framework that enables
comprehensive and interpretable automated comparisons of synthetic time series
evaluation measures. Using 10 diverse datasets, randomness injection, and 13
configurable data transformations, STEB computes indicators for measure
reliability and score consistency. It tracks running time, test errors, and
features sequential and parallel modes of operation. In our experiments, we
determine a ranking of 41 measures from literature and confirm that the choice
of upstream time series embedding heavily impacts the final score.

</details>


### [95] [Efficient Identity and Position Graph Embedding via Spectral-Based Random Feature Aggregation](https://arxiv.org/abs/2505.20992)
*Meng Qin, Jiahong Liu, Irwin King*

**主要类别:** cs.LG

**概要:** RFA是一种基于谱的GNN方法，无需训练即可通过高、低通滤波器分别提取节点身份和位置信息的嵌入，实现效率与质量的良好平衡。


<details>
  <summary>更多</summary>
  
**动机:** 当前大多数基于GNN的方法不清楚能捕获哪些拓扑属性（如节点的身份或位置），且因特征提取和训练等耗时操作导致效率和可扩展性较低。作者从图信号处理的角度出发，发现图谱域中的高低频信息可能分别表征节点身份和位置。

**方法:** 提出随机特征聚合（RFA）方法：(i) 使用无学习参数的谱基GNN作为主干；(ii) 仅使用随机噪声作为输入；(iii) 通过单一前向传播（FFP）生成嵌入。引入度校正机制改进GNN主干，并设计高低通滤波器的RFA变体以提取身份和位置嵌入。

**结果:** 实验表明，RFA的高低通滤波器变体可通过单一FFP（无需训练）分别获得有信息量的身份和位置嵌入，相较于多种基准方法在质量和效率上取得更好的平衡。

**结论:** RFA提供了一种高效且有效的方法来获取节点身份和位置嵌入，为GNN特征聚合提供了极端消融研究案例，并展示了在无需训练的情况下获得高质量嵌入的可能性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+Identity+and+Position+Graph+Embedding+via+Spectral-Based+Random+Feature+Aggregation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20992，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20992&send_immediately=true&force_search=false)

**原文摘要:** Graph neural networks (GNNs), which capture graph structures via a feature
aggregation mechanism following the graph embedding framework, have
demonstrated a powerful ability to support various tasks. According to the
topology properties (e.g., structural roles or community memberships of nodes)
to be preserved, graph embedding can be categorized into identity and position
embedding. However, it is unclear for most GNN-based methods which property
they can capture. Some of them may also suffer from low efficiency and
scalability caused by several time- and space-consuming procedures (e.g.,
feature extraction and training). From a perspective of graph signal
processing, we find that high- and low-frequency information in the graph
spectral domain may characterize node identities and positions, respectively.
Based on this investigation, we propose random feature aggregation (RFA) for
efficient identity and position embedding, serving as an extreme ablation study
regarding GNN feature aggregation. RFA (i) adopts a spectral-based GNN without
learnable parameters as its backbone, (ii) only uses random noises as inputs,
and (iii) derives embeddings via just one feed-forward propagation (FFP).
Inspired by degree-corrected spectral clustering, we further introduce a degree
correction mechanism to the GNN backbone. Surprisingly, our experiments
demonstrate that two variants of RFA with high- and low-pass filters can
respectively derive informative identity and position embeddings via just one
FFP (i.e., without any training). As a result, RFA can achieve a better
trade-off between quality and efficiency for both identity and position
embedding over various baselines.

</details>


### [96] [Latent label distribution grid representation for modeling uncertainty](https://arxiv.org/abs/2505.21180)
*ShuNing Sun, YinSong Xiong, Yu Zhang, Zhuoran Zheng*

**主要类别:** cs.LG

**概要:** 提出了一种新的方法LLDG（潜在标签分布网格）来建模标签空间的不确定性，并通过LLDG-Mixer生成更准确的标签分布。该方法在多个基准数据集上表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 标签分布学习（LDL）具有强大的表示能力，但标注复杂性和高成本导致标签空间构建不精确，存在大量不准确标签，从而误导算法决策。

**方法:** 1. 构建标签相关性矩阵以反映标签之间的差异。
2. 将矩阵中的每个值扩展为服从高斯分布的向量，形成LLDG。
3. 使用定制的低秩方案对网格进行降噪处理，并采用Tucker重构技术。
4. 利用LLDG-Mixer重建LLDG，生成准确的标签分布。

**结果:** 实验结果表明，该方法在多个基准数据集上的表现具有竞争力。

**结论:** LLDG方法有效缓解了标签空间的不确定性问题，提高了标签分布学习的准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Latent+label+distribution+grid+representation+for+modeling+uncertainty，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21180，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21180&send_immediately=true&force_search=false)

**原文摘要:** Although \textbf{L}abel \textbf{D}istribution \textbf{L}earning (LDL) has
promising representation capabilities for characterizing the polysemy of an
instance, the complexity and high cost of the label distribution annotation
lead to inexact in the construction of the label space. The existence of a
large number of inexact labels generates a label space with uncertainty, which
misleads the LDL algorithm to yield incorrect decisions. To alleviate this
problem, we model the uncertainty of label distributions by constructing a
\textbf{L}atent \textbf{L}abel \textbf{D}istribution \textbf{G}rid (LLDG) to
form a low-noise representation space. Specifically, we first construct a label
correlation matrix based on the differences between labels, and then expand
each value of the matrix into a vector that obeys a Gaussian distribution, thus
building a LLDG to model the uncertainty of the label space. Finally, the LLDG
is reconstructed by the LLDG-Mixer to generate an accurate label distribution.
Note that we enforce a customized low-rank scheme on this grid, which assumes
that the label relations may be noisy and it needs to perform noise-reduction
with the help of a Tucker reconstruction technique. Furthermore, we attempt to
evaluate the effectiveness of the LLDG by considering its generation as an
upstream task to achieve the classification of the objects. Extensive
experimental results show that our approach performs competitively on several
benchmarks.

</details>


### [97] [Learning What to Do and What Not To Do: Offline Imitation from Expert and Undesirable Demonstrations](https://arxiv.org/abs/2505.21182)
*Huy Hoang, Tien Mai, Pradeep Varakantham, Tanvi Verma*

**主要类别:** cs.LG

**概要:** 本文提出了一种新的离线模仿学习方法，通过优化专家和不良行为数据的状态-动作访问分布的KL散度差，避免对抗性训练，并在专家演示超过不良演示时保证目标函数的凸性，从而实现稳定训练。实验表明该方法优于现有基线方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的离线模仿学习方法通常利用专家和未标记的演示数据，但往往忽略了明确不可取行为中的有价值信息。

**方法:** 研究了对比行为的离线模仿学习，提出了一个新颖的公式，优化专家和不良数据状态-动作访问分布的KL散度差。当专家演示多于不良演示时，证明了目标函数变为凸函数，提供了一个实际且稳定的非对抗性训练目标。该方法统一处理正负演示数据，无需对抗性训练。

**结果:** 在标准的离线模仿学习基准上的广泛实验表明，所提出的方法始终优于最先进的基线方法。

**结论:** 提出的新方法可以有效利用不良行为数据，避免对抗性训练，并在专家演示占优的情况下确保目标函数的凸性，从而实现了更稳定和高效的训练过程。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+What+to+Do+and+What+Not+To+Do%3A+Offline+Imitation+from+Expert+and+Undesirable+Demonstrations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21182，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21182&send_immediately=true&force_search=false)

**原文摘要:** Offline imitation learning typically learns from expert and unlabeled
demonstrations, yet often overlooks the valuable signal in explicitly
undesirable behaviors. In this work, we study offline imitation learning from
contrasting behaviors, where the dataset contains both expert and undesirable
demonstrations. We propose a novel formulation that optimizes a difference of
KL divergences over the state-action visitation distributions of expert and
undesirable (or bad) data. Although the resulting objective is a DC
(Difference-of-Convex) program, we prove that it becomes convex when expert
demonstrations outweigh undesirable demonstrations, enabling a practical and
stable non-adversarial training objective. Our method avoids adversarial
training and handles both positive and negative demonstrations in a unified
framework. Extensive experiments on standard offline imitation learning
benchmarks demonstrate that our approach consistently outperforms
state-of-the-art baselines.

</details>


### [98] [PoisonSwarm: Universal Harmful Information Synthesis via Model Crowdsourcing](https://arxiv.org/abs/2505.21184)
*Yu Yan, Sheng Sun, Zhifei Zheng, Ziji Hao, Teli Liu, Min Liu*

**主要类别:** cs.LG

**概要:** 提出了一种新的有害信息合成框架PoisonSwarm，通过模型众包策略生成多样且成功率高的有害数据，实验表明其在合成不同类别的有害数据时具有高可扩展性和多样性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的研究主要利用大型语言模型（LLMs）合成数据以获得高质量的任务数据集，但受限于LLMs的安全对齐机制，有害数据的生成在可靠性和内容多样性方面仍面临挑战。

**方法:** 提出了名为PoisonSwarm的有害信息合成框架，采用模型众包策略生成多样化的有害数据。具体方法包括生成丰富的良性数据作为反事实模板，将每个模板分解为多个语义单元，并通过动态模型切换进行逐单元毒化和最终优化。

**结果:** 实验结果表明，PoisonSwarm在合成不同类别的有害数据方面具有最先进的性能，表现出高可扩展性和多样性。

**结论:** PoisonSwarm是一种有效的有害信息合成框架，能够生成多样化且成功率高的有害数据，适用于对抗性测试和保障措施的开发。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PoisonSwarm%3A+Universal+Harmful+Information+Synthesis+via+Model+Crowdsourcing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21184，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21184&send_immediately=true&force_search=false)

**原文摘要:** To construct responsible and secure AI applications, harmful information data
is widely utilized for adversarial testing and the development of safeguards.
Existing studies mainly leverage Large Language Models (LLMs) to synthesize
data to obtain high-quality task datasets at scale, thereby avoiding costly
human annotation. However, limited by the safety alignment mechanisms of LLMs,
the synthesis of harmful data still faces challenges in generation reliability
and content diversity. In this study, we propose a novel harmful information
synthesis framework, PoisonSwarm, which applies the model crowdsourcing
strategy to generate diverse harmful data while maintaining a high success
rate. Specifically, we generate abundant benign data as the based templates in
a counterfactual manner. Subsequently, we decompose each based template into
multiple semantic units and perform unit-by-unit toxification and final
refinement through dynamic model switching, thus ensuring the success of
synthesis. Experimental results demonstrate that PoisonSwarm achieves
state-of-the-art performance in synthesizing different categories of harmful
data with high scalability and diversity.

</details>


### [99] [Addressing Data Quality Decompensation in Federated Learning via Dynamic Client Selection](https://arxiv.org/abs/2505.21219)
*Qinjun Fei, Nuria Rodríguez-Barroso, María Victoria Luzón, Zhongliang Zhang, Francisco Herrera*

**主要类别:** cs.LG

**概要:** In cross-silo Federated Learning (FL), client selection is crucial but challenging due to data quality, budget constraints, and incentive compatibility. To address these issues, the paper proposes Shapley-Bid Reputation Optimized Federated Learning (SBRO-FL), a framework that integrates dynamic bidding, reputation modeling, and cost-aware selection. SBRO-FL uses Shapley values to evaluate client contributions, a reputation system based on prospect theory to capture historical performance, and formulates client selection as a 0-1 integer program maximizing reputation-weighted utility under budget constraints. Experiments show improved accuracy, convergence speed, and robustness in various scenarios.


<details>
  <summary>更多</summary>
  
**动机:** Client selection in cross-silo Federated Learning is critical for ensuring high model performance but faces challenges such as data quality decompensation, budget constraints, and incentive compatibility. Existing methods typically address these issues in isolation, making it difficult to jointly optimize multiple factors.

**方法:** The proposed method, Shapley-Bid Reputation Optimized Federated Learning (SBRO-FL), integrates dynamic bidding, reputation modeling, and cost-aware selection. Clients submit bids based on their perceived data quality, and their contributions are evaluated using Shapley values. A reputation system inspired by prospect theory captures historical performance while penalizing inconsistency. Client selection is formulated as a 0-1 integer program that maximizes reputation-weighted utility under budget constraints.

**结果:** Experiments on FashionMNIST, EMNIST, CIFAR-10, and SVHN datasets demonstrate that SBRO-FL improves accuracy, convergence speed, and robustness, even in adversarial and low-bid interference scenarios.

**结论:** Balancing data reliability, incentive compatibility, and cost efficiency is essential for enabling scalable and trustworthy FL deployments. The results highlight the effectiveness of the SBRO-FL framework in addressing the challenges of client selection in cross-silo Federated Learning.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Addressing+Data+Quality+Decompensation+in+Federated+Learning+via+Dynamic+Client+Selection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21219，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21219&send_immediately=true&force_search=false)

**原文摘要:** In cross-silo Federated Learning (FL), client selection is critical to ensure
high model performance, yet it remains challenging due to data quality
decompensation, budget constraints, and incentive compatibility. As training
progresses, these factors exacerbate client heterogeneity and degrade global
performance. Most existing approaches treat these challenges in isolation,
making jointly optimizing multiple factors difficult. To address this, we
propose Shapley-Bid Reputation Optimized Federated Learning (SBRO-FL), a
unified framework integrating dynamic bidding, reputation modeling, and
cost-aware selection. Clients submit bids based on their perceived data
quality, and their contributions are evaluated using Shapley values to quantify
their marginal impact on the global model. A reputation system, inspired by
prospect theory, captures historical performance while penalizing
inconsistency. The client selection problem is formulated as a 0-1 integer
program that maximizes reputation-weighted utility under budget constraints.
Experiments on FashionMNIST, EMNIST, CIFAR-10, and SVHN datasets show that
SBRO-FL improves accuracy, convergence speed, and robustness, even in
adversarial and low-bid interference scenarios. Our results highlight the
importance of balancing data reliability, incentive compatibility, and cost
efficiency to enable scalable and trustworthy FL deployments.

</details>


### [100] [NeuralOM: Neural Ocean Model for Subseasonal-to-Seasonal Simulation](https://arxiv.org/abs/2505.21020)
*Yuan Gao, Ruiqi Shu, Hao Wu, Fan Xu, Yanfei Xiang, Ruijian Gou, Qingsong Wen, Xian Wu, Xiaomeng Huang*

**主要类别:** cs.LG

**概要:** 提出了一种用于次季节到季节（S2S）海洋模拟的神经海洋模型（NeuralOM），通过多尺度交互图神经网络来有效模拟与海洋系统相关的各种物理现象。实验结果表明，该模型在S2S和极端事件模拟中优于现有最佳模型。


<details>
  <summary>更多</summary>
  
**动机:** 准确的S2S海洋模拟对海洋研究至关重要，但因海洋系统的热惯性和时间延迟而充满挑战。尽管机器学习（ML）模型在模拟精度和计算效率上有所提升，但其对物理一致性和海洋系统缓慢变化特性的考虑不足仍然是一个显著限制。

**方法:** 提出了一个基于多尺度交互图神经网络的神经海洋模型（NeuralOM）。包括一个多阶段框架，专门设计用于建模海洋的缓慢变化特性，并引入了一个多尺度交互消息模块，用于捕捉复杂的动力学行为，如梯度变化和乘法耦合关系。

**结果:** 广泛的实验评估表明，所提出的NeuralOM在S2S和极端事件模拟方面优于最先进的模型。

**结论:** NeuralOM是一种有效的S2S海洋模拟方法，能够更好地捕捉海洋系统的复杂动态行为，并且在性能上超越了现有的先进模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NeuralOM%3A+Neural+Ocean+Model+for+Subseasonal-to-Seasonal+Simulation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21020，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21020&send_immediately=true&force_search=false)

**原文摘要:** Accurate Subseasonal-to-Seasonal (S2S) ocean simulation is critically
important for marine research, yet remains challenging due to its substantial
thermal inertia and extended time delay. Machine learning (ML)-based models
have demonstrated significant advancements in simulation accuracy and
computational efficiency compared to traditional numerical methods.
Nevertheless, a significant limitation of current ML models for S2S ocean
simulation is their inadequate incorporation of physical consistency and the
slow-changing properties of the ocean system. In this work, we propose a neural
ocean model (NeuralOM) for S2S ocean simulation with a multi-scale interactive
graph neural network to emulate diverse physical phenomena associated with
ocean systems effectively. Specifically, we propose a multi-stage framework
tailored to model the ocean's slowly changing nature. Additionally, we
introduce a multi-scale interactive messaging module to capture complex
dynamical behaviors, such as gradient changes and multiplicative coupling
relationships inherent in ocean dynamics. Extensive experimental evaluations
confirm that our proposed NeuralOM outperforms state-of-the-art models in S2S
and extreme event simulation. The codes are available at
https://github.com/YuanGao-YG/NeuralOM.

</details>


### [101] [Breaking the Performance Ceiling in Complex Reinforcement Learning requires Inference Strategies](https://arxiv.org/abs/2505.21236)
*Felix Chalumeau, Daniel Rajaonarivonivelomanantsoa, Ruan de Kock, Claude Formanek, Sasha Abramowitz, Oumayma Mahjoub, Wiem Khlifi, Simon Du Toit, Louay Ben Nessir, Refiloe Shabe, Arnol Fokam, Siddarth Singh, Ulrich Mbou Sob, Arnu Pretorius*

**主要类别:** cs.LG

**概要:** 通过在执行时使用推理阶段和选择合适的推理策略，可以突破复杂多智能体强化学习问题中的性能上限。这种方法在17个任务中比之前的最先进技术平均提高了45%，最多提高了126%，并且只需要在执行期间增加几秒钟的额外时间。


<details>
  <summary>更多</summary>
  
**动机:** 尽管强化学习系统有无数的应用，但现实世界场景通常非常复杂、组合性强，并且需要多个智能体之间的复杂协调。这种复杂性可能导致最先进的强化学习系统在训练到收敛后，仍然无法通过零样本推理突破性能上限。与此同时，许多数字或基于模拟的应用程序允许在输出最终解决方案之前，利用特定的时间和计算预算进行多次尝试的推理阶段。

**方法:** 本研究展示了在执行时采用推理阶段以及选择相应的推理策略对于突破复杂多智能体RL问题中的性能上限至关重要。通过这种方法，在17个任务中实现了相对于之前最先进技术的重大改进。此外，研究还展示了良好的计算扩展特性，得到了超过60,000次实验的支持。

**结果:** 该方法在17个任务中获得了高达126%的最大提升和平均45%的性能提升，同时仅需在执行过程中增加几秒钟的额外时间。这是迄今为止关于复杂RL推理策略的最大规模研究。

**结论:** 推理阶段和策略的选择是突破复杂多智能体RL问题性能上限的关键。此方法不仅显著提升了性能，而且具有良好的计算扩展特性，为未来的研究提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Breaking+the+Performance+Ceiling+in+Complex+Reinforcement+Learning+requires+Inference+Strategies，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21236，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21236&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement learning (RL) systems have countless applications, from
energy-grid management to protein design. However, such real-world scenarios
are often extremely difficult, combinatorial in nature, and require complex
coordination between multiple agents. This level of complexity can cause even
state-of-the-art RL systems, trained until convergence, to hit a performance
ceiling which they are unable to break out of with zero-shot inference.
Meanwhile, many digital or simulation-based applications allow for an inference
phase that utilises a specific time and compute budget to explore multiple
attempts before outputting a final solution. In this work, we show that such an
inference phase employed at execution time, and the choice of a corresponding
inference strategy, are key to breaking the performance ceiling observed in
complex multi-agent RL problems. Our main result is striking: we can obtain up
to a 126% and, on average, a 45% improvement over the previous state-of-the-art
across 17 tasks, using only a couple seconds of extra wall-clock time during
execution. We also demonstrate promising compute scaling properties, supported
by over 60k experiments, making it the largest study on inference strategies
for complex RL to date. Our experimental data and code are available at
https://sites.google.com/view/inf-marl.

</details>


### [102] [Pause Tokens Strictly Increase the Expressivity of Constant-Depth Transformers](https://arxiv.org/abs/2505.21024)
*Charles London, Varun Kanade*

**主要类别:** cs.LG

**概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Pause+Tokens+Strictly+Increase+the+Expressivity+of+Constant-Depth+Transformers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21024，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21024&send_immediately=true&force_search=false)

**原文摘要:** Pause tokens, simple filler symbols such as "...", consistently improve
Transformer performance on both language and mathematical tasks, yet their
theoretical effect remains unexplained. We provide the first formal separation
result, proving that adding pause tokens to constant-depth, logarithmic-width
Transformers strictly increases their computational expressivity. With
bounded-precision activations, Transformers without pause tokens compute only a
strict subset of $\mathsf{AC}^0$ functions, while adding a polynomial number of
pause tokens allows them to express the entire class. For logarithmic-precision
Transformers, we show that adding pause tokens achieves expressivity equivalent
to $\mathsf{TC}^0$, matching known upper bounds. Empirically, we demonstrate
that two-layer causally masked Transformers can learn parity when supplied with
pause tokens, a function that they appear unable to learn without them. Our
results provide a rigorous theoretical explanation for prior empirical
findings, clarify how pause tokens interact with width, depth, and numeric
precision, and position them as a distinct mechanism, complementary to
chain-of-thought prompting, for enhancing Transformer reasoning.

</details>


### [103] [GSAT: Graph Structure Attention Networks](https://arxiv.org/abs/2505.21288)
*Farshad Noravesh, Reza Haffari, Layki Soon, Arghya Pal*

**主要类别:** cs.LG

**概要:** Graph Neural Networks (GNNs) have been successful in various applications, but often overlook structural information. This paper introduces graph structure attention network (GSAT), which uses anonymous random walks to model structural info and improve performance on graph classification benchmarks.


<details>
  <summary>更多</summary>
  
**动机:** To address the issue of GNNs neglecting rich local topological information in node neighborhoods, leading to problems like oversmoothing when trying to connect distant nodes.

**方法:** Leverage structural information modeled by anonymous random walks (ARWs) and introduce graph structure attention network (GSAT), a generalization of graph attention network (GAT), to integrate original attributes and structural representations.

**结果:** Experiments demonstrate that GSAT slightly improves state-of-the-art performance on some graph classification benchmarks.

**结论:** GSAT successfully integrates structural information into GNNs, enhancing graph representation and providing a new approach for enriching node neighborhood patterns.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GSAT%3A+Graph+Structure+Attention+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21288，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21288&send_immediately=true&force_search=false)

**原文摘要:** Graph Neural Networks (GNNs) have emerged as a powerful tool for processing
data represented in graph structures, achieving remarkable success across a
wide range of applications. However, to further improve the performance on
graph classification benchmarks, structural representation of each node that
encodes rich local topological information in the neighbourhood of nodes is an
important type of feature that is often overlooked in the modeling. The
consequence of neglecting the structural information has resulted high number
of layers to connect messages from distant nodes which by itself produces other
problems such as oversmoothing. In the present paper, we leverage these
structural information that are modeled by anonymous random walks (ARWs) and
introduce graph structure attention network (GSAT) which is a generalization of
graph attention network(GAT) to integrate the original attribute and the
structural representation to enforce the model to automatically find patterns
for attending to different edges in the node neighbourhood to enrich graph
representation. Our experiments show GSAT slightly improves SOTA on some graph
classification benchmarks.

</details>


### [104] [A Cross Modal Knowledge Distillation & Data Augmentation Recipe for Improving Transcriptomics Representations through Morphological Features](https://arxiv.org/abs/2505.21317)
*Ihab Bendidi, Yassir El Mesbahi, Alisandra K. Denton, Karush Suri, Kian Kenyon-Dean, Auguste Genovesio, Emmanuel Noutahi*

**主要类别:** cs.LG

**概要:** 论文提出了一种通过从显微镜图像中提取知识来增强转录组学的框架，包括Semi-Clipped和PEA两种方法，以解决弱配对数据稀缺的问题，并提高预测能力和保留转录组学的可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 理解细胞对刺激的反应对于生物发现和药物开发至关重要。虽然转录组学提供了可解释的基因水平见解，但显微镜成像虽提供丰富的预测特征却较难解释。弱配对数据集能实现多模态学习，但由于数据稀缺限制了其训练和推理能力。

**方法:** 该框架通过使用弱配对数据，将模态对齐并结合，从而在基因表达表示中加入形态学信息。为了解决数据稀缺问题，引入了(1) Semi-Clipped，一种适用于跨模态蒸馏的CLIP改进版，利用预训练基础模型；(2) PEA（扰动嵌入增强），一种新的增强技术，增强转录组学数据同时保留固有的生物学信息。

**结果:** 这些策略提高了转录组学数据的预测能力，同时保留了其可解释性，能够为复杂的生物任务生成丰富单一模态表示。

**结论:** 提出的框架和方法（Semi-Clipped和PEA）可以有效增强转录组学数据，使其更适用于复杂生物任务，同时保留了数据的可解释性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Cross+Modal+Knowledge+Distillation+%26+Data+Augmentation+Recipe+for+Improving+Transcriptomics+Representations+through+Morphological+Features，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21317，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21317&send_immediately=true&force_search=false)

**原文摘要:** Understanding cellular responses to stimuli is crucial for biological
discovery and drug development. Transcriptomics provides interpretable,
gene-level insights, while microscopy imaging offers rich predictive features
but is harder to interpret. Weakly paired datasets, where samples share
biological states, enable multimodal learning but are scarce, limiting their
utility for training and multimodal inference. We propose a framework to
enhance transcriptomics by distilling knowledge from microscopy images. Using
weakly paired data, our method aligns and binds modalities, enriching gene
expression representations with morphological information. To address data
scarcity, we introduce (1) Semi-Clipped, an adaptation of CLIP for cross-modal
distillation using pretrained foundation models, achieving state-of-the-art
results, and (2) PEA (Perturbation Embedding Augmentation), a novel
augmentation technique that enhances transcriptomics data while preserving
inherent biological information. These strategies improve the predictive power
and retain the interpretability of transcriptomics, enabling rich unimodal
representations for complex biological tasks.

</details>


### [105] [LLaMEA-BO: A Large Language Model Evolutionary Algorithm for Automatically Generating Bayesian Optimization Algorithms](https://arxiv.org/abs/2505.21034)
*Wenhu Li, Niki van Stein, Thomas Bäck, Elena Raponi*

**主要类别:** cs.LG

**概要:** 本论文探讨了利用大型语言模型（LLMs）自动生成贝叶斯优化（BO）算法代码的可能性。通过进化策略指导LLM生成包含BO关键组件的Python代码，这些组件包括初始设计、代理模型和获取函数。生成的算法在BBOB测试套件上进行评估，并通过迭代选择、组合和变异来改进。结果显示，LLM生成的算法在24个BBOB函数中的19个上超越了现有的最佳BO基线算法，并且在更高维度和不同任务中表现良好。此工作展示了LLMs可以作为算法共同设计者，为自动化BO开发提供新方法。


<details>
  <summary>更多</summary>
  
**动机:** 当前贝叶斯优化（BO）算法的设计仍然依赖于手动操作和专业知识。尽管已有研究尝试使用大型语言模型（LLMs）在优化循环内或生成非BO算法方面取得进展，但尚未有工作探索LLMs自动生成完整的BO算法代码的可能性。

**方法:** 论文提出了一种框架，利用进化策略引导LLM生成包含BO关键组件（初始设计、代理模型和获取函数）的Python代码。LLM生成多个候选算法，这些算法在Black-Box Optimization Benchmarking (BBOB)测试套件上进行评估。根据性能，选择最优候选算法，并通过受控提示变异进行组合和变异，以实现迭代改进。

**结果:** LLM生成的算法在5维空间的24个BBOB函数中的19个上超越了现有最佳BO基线算法。此外，这些算法在更高维度和不同任务（如Bayesmark框架中的任务）上也表现出良好的泛化能力。

**结论:** 本研究表明，LLMs可以作为算法共同设计者，提供一种新的范式来自动化BO开发并加速新型算法组合的发现。源代码已公开发布。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLaMEA-BO%3A+A+Large+Language+Model+Evolutionary+Algorithm+for+Automatically+Generating+Bayesian+Optimization+Algorithms，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21034，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21034&send_immediately=true&force_search=false)

**原文摘要:** Bayesian optimization (BO) is a powerful class of algorithms for optimizing
expensive black-box functions, but designing effective BO algorithms remains a
manual, expertise-driven task. Recent advancements in Large Language Models
(LLMs) have opened new avenues for automating scientific discovery, including
the automatic design of optimization algorithms. While prior work has used LLMs
within optimization loops or to generate non-BO algorithms, we tackle a new
challenge: Using LLMs to automatically generate full BO algorithm code. Our
framework uses an evolution strategy to guide an LLM in generating Python code
that preserves the key components of BO algorithms: An initial design, a
surrogate model, and an acquisition function. The LLM is prompted to produce
multiple candidate algorithms, which are evaluated on the established Black-Box
Optimization Benchmarking (BBOB) test suite from the COmparing Continuous
Optimizers (COCO) platform. Based on their performance, top candidates are
selected, combined, and mutated via controlled prompt variations, enabling
iterative refinement. Despite no additional fine-tuning, the LLM-generated
algorithms outperform state-of-the-art BO baselines in 19 (out of 24) BBOB
functions in dimension 5 and generalize well to higher dimensions, and
different tasks (from the Bayesmark framework). This work demonstrates that
LLMs can serve as algorithmic co-designers, offering a new paradigm for
automating BO development and accelerating the discovery of novel algorithmic
combinations. The source code is provided at
https://github.com/Ewendawi/LLaMEA-BO.

</details>


### [106] [An Uncertainty-Aware ED-LSTM for Probabilistic Suffix Prediction](https://arxiv.org/abs/2505.21339)
*Henryk Mustroph, Michel Kunkler, Stefanie Rinderle-Ma*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种新的方法，称为概率后缀预测，使用不确定性感知的编码器-解码器LSTM（U-ED-LSTM）和蒙特卡洛（MC）后缀采样算法来近似后缀的概率分布。通过MC dropout捕获认知不确定性，并将变异性不确定性作为学习损失衰减。实验结果表明，U-ED-LSTM在不同数据集上有合理的预测性能，聚合概率后缀预测的均值可以超越最可能预测，特别是在稀有前缀或较长后缀的情况下。此外，该方法能够有效捕捉事件日志中的不确定性。


<details>
  <summary>更多</summary>
  
**动机:** 当前的方法主要集中在预测单一、最有可能的业务流程后缀。然而，在未来流程存在不确定性或高变异性时，单一后缀预测的表达能力有限。

**方法:** 提出了基于U-ED-LSTM和MC后缀采样算法的概率后缀预测方法。通过MC dropout捕获认知不确定性，将变异性不确定性作为学习损失衰减。

**结果:** 1) U-ED-LSTM在各种数据集上具有合理的预测性能；2) 聚合概率后缀预测的均值可以超越最可能预测，尤其适用于稀有前缀或较长后缀；3) 该方法能有效捕捉事件日志中的不确定性。

**结论:** 概率后缀预测方法为业务流程后缀预测提供了一种更全面的方式，能够更好地处理不确定性，并且在某些情况下优于单一后缀预测。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Uncertainty-Aware+ED-LSTM+for+Probabilistic+Suffix+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21339，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21339&send_immediately=true&force_search=false)

**原文摘要:** Suffix prediction of business processes forecasts the remaining sequence of
events until process completion. Current approaches focus on predicting a
single, most likely suffix. However, if the future course of a process is
exposed to uncertainty or has high variability, the expressiveness of a single
suffix prediction can be limited. To address this limitation, we propose
probabilistic suffix prediction, a novel approach that approximates a
probability distribution of suffixes. The proposed approach is based on an
Uncertainty-Aware Encoder-Decoder LSTM (U-ED-LSTM) and a Monte Carlo (MC)
suffix sampling algorithm. We capture epistemic uncertainties via MC dropout
and aleatoric uncertainties as learned loss attenuation. This technical report
provides a detailed evaluation of the U-ED-LSTM's predictive performance and
assesses its calibration on four real-life event logs with three different
hyperparameter settings. The results show that i) the U-ED-LSTM has reasonable
predictive performance across various datasets, ii) aggregating probabilistic
suffix predictions into mean values can outperform most likely predictions,
particularly for rare prefixes or longer suffixes, and iii) the approach
effectively captures uncertainties present in event logs.

</details>


### [107] [Scalable and adaptive prediction bands with kernel sum-of-squares](https://arxiv.org/abs/2505.21039)
*Louis Allain, Sébastien da Veiga, Brian Staber*

**主要类别:** cs.LG

**概要:** 本研究通过将共形预测问题转化为统计学习问题，提出了一种基于再生核希尔伯特空间和核平方和方法的新方法，提高了适应性和覆盖率，并引入了新的超参数调整策略。


<details>
  <summary>更多</summary>
  
**动机:** 共形预测（CP）虽然在有限样本中提供有效的覆盖范围且无需分布假设，但缺乏适应性是一个已知的局限性。为解决这一问题，研究者们提出了多种实用的替代程序。本文旨在改进共形预测的适应性问题。

**方法:** 作者首先扩展了之前的结果，给出了一般的表示定理，并展示了学习问题的对偶形式。这种对偶形式可以通过加速梯度方法高效求解。其次，作者引入了一种新的超参数调整策略，该策略专门针对通过测试条件覆盖率界限来实现适应性。此策略基于希尔伯特-施密特独立性准则（HSIC），用于调整框架中的核长度尺度，但其应用范围更广，可适用于任何得分函数被学习的CP算法。

**结果:** 实验结果表明，所提出的方法在适应性和覆盖率方面优于相关工作。

**结论:** 本文提出了一种改进共形预测适应性的新方法，通过对偶形式的学习问题和新的超参数调整策略，显著提高了模型性能。实验验证了该方法的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+and+adaptive+prediction+bands+with+kernel+sum-of-squares，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21039，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21039&send_immediately=true&force_search=false)

**原文摘要:** Conformal Prediction (CP) is a popular framework for constructing prediction
bands with valid coverage in finite samples, while being free of any
distributional assumption. A well-known limitation of conformal prediction is
the lack of adaptivity, although several works introduced practically efficient
alternate procedures. In this work, we build upon recent ideas that rely on
recasting the CP problem as a statistical learning problem, directly targeting
coverage and adaptivity. This statistical learning problem is based on
reproducible kernel Hilbert spaces (RKHS) and kernel sum-of-squares (SoS)
methods. First, we extend previous results with a general representer theorem
and exhibit the dual formulation of the learning problem. Crucially, such dual
formulation can be solved efficiently by accelerated gradient methods with
several hundreds or thousands of samples, unlike previous strategies based on
off-the-shelf semidefinite programming algorithms. Second, we introduce a new
hyperparameter tuning strategy tailored specifically to target adaptivity
through bounds on test-conditional coverage. This strategy, based on the
Hilbert-Schmidt Independence Criterion (HSIC), is introduced here to tune
kernel lengthscales in our framework, but has broader applicability since it
could be used in any CP algorithm where the score function is learned. Finally,
extensive experiments are conducted to show how our method compares to related
work. All figures can be reproduced with the accompanying code.

</details>


### [108] [Subgroups Matter for Robust Bias Mitigation](https://arxiv.org/abs/2505.21363)
*Anissa Alloula, Charles Jones, Ben Glocker, Bartłomiej W. Papież*

**主要类别:** cs.LG

**概要:** 论文探讨了子群定义对机器学习偏差缓解方法的影响，发现子群选择显著影响性能，并提出了改进公平性的反直觉洞察。


<details>
  <summary>更多</summary>
  
**动机:** 尽管不断有新的偏差缓解方法被开发出来，但这些方法并不总能成功。一个根本性的问题尚未得到解答：偏差缓解技术在何时以及为何会失败？

**方法:** 假设关键因素可能是许多偏差缓解方法共享的一个常被忽视的步骤：子群定义。通过系统地改变子群定义（包括粗粒度、细粒度、交叉性和噪声子群），对最先进的偏差缓解方法进行综合评估，涵盖多个视觉和语言分类任务。

**结果:** 研究结果表明，子群选择显著影响性能，某些分组甚至导致比不进行缓解更差的结果。观察到子群之间的差异不足以作为使用这些子群进行缓解的理由。理论分析揭示了在某些情况下，针对特定子群改进公平性可以通过使用不同的子群进行缓解来实现。

**结论:** 子群定义在偏差缓解中至关重要，是提高机器学习模型稳健性和公平性的另一种杠杆。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Subgroups+Matter+for+Robust+Bias+Mitigation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21363，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21363&send_immediately=true&force_search=false)

**原文摘要:** Despite the constant development of new bias mitigation methods for machine
learning, no method consistently succeeds, and a fundamental question remains
unanswered: when and why do bias mitigation techniques fail? In this paper, we
hypothesise that a key factor may be the often-overlooked but crucial step
shared by many bias mitigation methods: the definition of subgroups. To
investigate this, we conduct a comprehensive evaluation of state-of-the-art
bias mitigation methods across multiple vision and language classification
tasks, systematically varying subgroup definitions, including coarse,
fine-grained, intersectional, and noisy subgroups. Our results reveal that
subgroup choice significantly impacts performance, with certain groupings
paradoxically leading to worse outcomes than no mitigation at all. Our findings
suggest that observing a disparity between a set of subgroups is not a
sufficient reason to use those subgroups for mitigation. Through theoretical
analysis, we explain these phenomena and uncover a counter-intuitive insight
that, in some cases, improving fairness with respect to a particular set of
subgroups is best achieved by using a different set of subgroups for
mitigation. Our work highlights the importance of careful subgroup definition
in bias mitigation and suggest it as a alternative lever for improving the
robustness and fairness of machine learning models.

</details>


### [109] [Towards Interpretability Without Sacrifice: Faithful Dense Layer Decomposition with Mixture of Decoders](https://arxiv.org/abs/2505.21364)
*James Oldfield, Shawn Im, Yixuan Li, Mihalis A. Nicolaou, Ioannis Patras, Grigorios G Chrysos*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种名为Mixture of Decoders（MxDs）的新方法，用于解决大型语言模型中多层感知器(MLPs)的可解释性和准确性之间的权衡问题。MxDs通过引入分层稀疏性，将预训练的密集层扩展为数以万计的专业子层，使用灵活的张量分解形式来保持原始解码器的表现能力。实验表明，MxDs在具有多达30亿参数的语言模型中显著优于现有技术，并且能够学习自然语言的专门特征，从而为设计可解释和忠实的分解提供了新的方向。


<details>
  <summary>更多</summary>
  
**动机:** 当前用于近似MLP的方法虽然可以通过神经元级别的稀疏性提高可解释性，但往往无法忠实地重建原始映射，导致模型的下一个标记交叉熵损失显著增加。因此需要一种新方法，在提高可解释性的同时不牺牲模型性能。

**方法:** 研究者提出了Mixture of Decoders (MxDs)，它通过对MLPs进行层级别稀疏化处理，将预训练的密集层扩展成数千个专业子层。每个稀疏激活的MxD子层通过线性转换实现全秩权重，从而即使在高稀疏度下也能保留原始解码器的表现能力。

**结果:** 实验结果表明，MxDs在语言模型的稀疏性-准确性前沿上显著优于现有技术（如Transcoders），并且在多达30亿参数的语言模型中表现良好。此外，稀疏探测和特征引导评估显示MxDs能够学习到与自然语言相似的专门特征。

**结论:** MxDs提供了一个有希望的新途径，用于设计既可解释又忠实的模型分解方式，这有助于更好地理解和控制大型语言模型中的MLP行为。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Interpretability+Without+Sacrifice%3A+Faithful+Dense+Layer+Decomposition+with+Mixture+of+Decoders，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21364，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21364&send_immediately=true&force_search=false)

**原文摘要:** Multilayer perceptrons (MLPs) are an integral part of large language models,
yet their dense representations render them difficult to understand, edit, and
steer. Recent methods learn interpretable approximations via neuron-level
sparsity, yet fail to faithfully reconstruct the original
mapping--significantly increasing model's next-token cross-entropy loss. In
this paper, we advocate for moving to layer-level sparsity to overcome the
accuracy trade-off in sparse layer approximation. Under this paradigm, we
introduce Mixture of Decoders (MxDs). MxDs generalize MLPs and Gated Linear
Units, expanding pre-trained dense layers into tens of thousands of specialized
sublayers. Through a flexible form of tensor factorization, each sparsely
activating MxD sublayer implements a linear transformation with full-rank
weights--preserving the original decoders' expressive capacity even under heavy
sparsity. Experimentally, we show that MxDs significantly outperform
state-of-the-art methods (e.g., Transcoders) on the sparsity-accuracy frontier
in language models with up to 3B parameters. Further evaluations on sparse
probing and feature steering demonstrate that MxDs learn similarly specialized
features of natural language--opening up a promising new avenue for designing
interpretable yet faithful decompositions. Our code is included at:
https://github.com/james-oldfield/MxD/.

</details>


### [110] [Improving LLM-based Global Optimization with Search Space Partitioning](https://arxiv.org/abs/2505.21372)
*Andrej Schwanke, Lyubomir Ivanov, David Salinas, Fabio Ferreira, Aaron Klein, Frank Hutter, Arber Zela*

**主要类别:** cs.LG

**概要:** HOLLM是一种新的全局优化算法，通过将搜索空间划分为有希望的子区域并利用大型语言模型（LLM）驱动的采样来提高性能。它在标准优化基准测试中表现优异，超越了基于LLM的全局采样策略和其他领先方法。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLM）在昂贵的黑盒函数的全局优化框架中作为有效的代理模型和候选生成器，但在高维搜索空间或缺乏特定领域先验的情况下，LLM方法常常难以提供密集或有意义的建议。

**方法:** 提出了HOLLM算法，该算法通过将搜索空间划分为有希望的子区域来增强LLM驱动的采样。每个子区域作为一个“元臂”，通过受多臂老虎机启发的评分机制选择，有效平衡探索与利用。在选定的子区域内，LLM提出高质量的候选点，无需任何明确的领域知识。

**结果:** 在标准优化基准上的实证评估表明，HOLLM始终匹配或超越领先的贝叶斯优化和信任域方法，同时显著优于基于LLM的全局采样策略。

**结论:** HOLLM算法通过结合LLM能力和搜索空间分区，在优化问题中展现了优越的性能，特别是在高维空间和缺乏领域先验的情况下。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+LLM-based+Global+Optimization+with+Search+Space+Partitioning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21372，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21372&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have recently emerged as effective surrogate
models and candidate generators within global optimization frameworks for
expensive blackbox functions. Despite promising results, LLM-based methods
often struggle in high-dimensional search spaces or when lacking
domain-specific priors, leading to sparse or uninformative suggestions. To
overcome these limitations, we propose HOLLM, a novel global optimization
algorithm that enhances LLM-driven sampling by partitioning the search space
into promising subregions. Each subregion acts as a ``meta-arm'' selected via a
bandit-inspired scoring mechanism that effectively balances exploration and
exploitation. Within each selected subregion, an LLM then proposes high-quality
candidate points, without any explicit domain knowledge. Empirical evaluation
on standard optimization benchmarks shows that HOLLM consistently matches or
surpasses leading Bayesian optimization and trust-region methods, while
substantially outperforming global LLM-based sampling strategies.

</details>


### [111] [Leveraging the Power of Conversations: Optimal Key Term Selection in Conversational Contextual Bandits](https://arxiv.org/abs/2505.21393)
*Maoli Liu, Zhuohua Li, Xiangxiang Dai, John C. S. Lui*

**主要类别:** cs.LG

**概要:** 提出三种新算法CLiSK、CLiME和CLiSK-ME，改进了对话推荐系统中的关键问题，包括增强探索和自适应对话启动，并证明其接近最优。


<details>
  <summary>更多</summary>
  
**动机:** 现有的对话上下文多臂赌博机方法在真实场景中存在不足：1) 关键词选择探索不足，导致偏好估计次优；2) 确定性规则引发不必要的对话或错过机会。

**方法:** 提出三种算法：CLiSK通过平滑关键词上下文增强探索；CLiME基于偏好不确定性自适应启动对话；CLiSK-ME结合两者。

**结果:** 理论上证明所有算法具有更紧的遗憾上界$O(\sqrt{dT\log{T}})$，并提供匹配的下界$\Omega(\sqrt{dT})$。实验表明改进累计遗憾至少14.6%。

**结论:** 新算法改进了对话推荐系统的关键问题，理论和实证结果均表明其有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Leveraging+the+Power+of+Conversations%3A+Optimal+Key+Term+Selection+in+Conversational+Contextual+Bandits，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21393，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21393&send_immediately=true&force_search=false)

**原文摘要:** Conversational recommender systems proactively query users with relevant "key
terms" and leverage the feedback to elicit users' preferences for personalized
recommendations. Conversational contextual bandits, a prevalent approach in
this domain, aim to optimize preference learning by balancing exploitation and
exploration. However, several limitations hinder their effectiveness in
real-world scenarios. First, existing algorithms employ key term selection
strategies with insufficient exploration, often failing to thoroughly probe
users' preferences and resulting in suboptimal preference estimation. Second,
current algorithms typically rely on deterministic rules to initiate
conversations, causing unnecessary interactions when preferences are
well-understood and missed opportunities when preferences are uncertain. To
address these limitations, we propose three novel algorithms: CLiSK, CLiME, and
CLiSK-ME. CLiSK introduces smoothed key term contexts to enhance exploration in
preference learning, CLiME adaptively initiates conversations based on
preference uncertainty, and CLiSK-ME integrates both techniques. We
theoretically prove that all three algorithms achieve a tighter regret upper
bound of $O(\sqrt{dT\log{T}})$ with respect to the time horizon $T$, improving
upon existing methods. Additionally, we provide a matching lower bound
$\Omega(\sqrt{dT})$ for conversational bandits, demonstrating that our
algorithms are nearly minimax optimal. Extensive evaluations on both synthetic
and real-world datasets show that our approaches achieve at least a 14.6%
improvement in cumulative regret.

</details>


### [112] [Improved Impossible Tuning and Lipschitz-Adaptive Universal Online Learning with Gradient Variations](https://arxiv.org/abs/2505.21095)
*Kei Takemura, Ryuta Matsuno, Keita Sakuma*

**主要类别:** cs.LG

**概要:** 本文提出了一种新的乐观在线镜像下降算法，解决了不可能调优问题，并开发了首个同时实现状态最优的梯度变化（GV）界和Lipschitz适应性的通用在线学习（UOL）算法。


<details>
  <summary>更多</summary>
  
**动机:** 在线学习中，适应未知问题特征是一个核心目标，例如由梯度变化（GV）、函数曲率（通用在线学习，UOL）和梯度尺度（Lipschitz适应性，LA）捕捉的环境变化。现有的算法在处理“不可能调优”问题时存在额外的$\sqrt{\log T}$因子，影响整体性能。

**方法:** 提出了一种具有辅助初始轮次的大步长乐观在线镜像下降算法。通过生成一个负项来消除与间隙相关的因子，从而解决“不可能调优”问题，仅剩$\log\log T$因子。将改进后的算法作为元算法，开发了一个新的UOL算法。

**结果:** 新算法解决了LA机制与GV界遗憾分析之间的冲突，同时实现了状态最优的GV界和LA。这是先前工作未能解决的一个开放问题。

**结论:** 该研究克服了先前UOL算法的关键限制，为在线学习领域提供了更高效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improved+Impossible+Tuning+and+Lipschitz-Adaptive+Universal+Online+Learning+with+Gradient+Variations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21095，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21095&send_immediately=true&force_search=false)

**原文摘要:** A central goal in online learning is to achieve adaptivity to unknown problem
characteristics, such as environmental changes captured by gradient variation
(GV), function curvature (universal online learning, UOL), and gradient scales
(Lipschitz adaptivity, LA). Simultaneously achieving these with optimal
performance is a major challenge, partly due to limitations in algorithms for
prediction with expert advice. These algorithms often serve as meta-algorithms
in online ensemble frameworks, and their sub-optimality hinders overall UOL
performance. Specifically, existing algorithms addressing the ``impossible
tuning'' issue incur an excess $\sqrt{\log T}$ factor in their regret bound
compared to the lower bound. To solve this problem, we propose a novel
optimistic online mirror descent algorithm with an auxiliary initial round
using large learning rates. This design enables a refined analysis where a
generated negative term cancels the gap-related factor, resolving the
impossible tuning issue up to $\log\log T$ factors. Leveraging our improved
algorithm as a meta-algorithm, we develop the first UOL algorithm that
simultaneously achieves state-of-the-art GV bounds and LA under standard
assumptions. Our UOL result overcomes key limitations of prior works, notably
resolving the conflict between LA mechanisms and regret analysis for GV bounds
-- an open problem highlighted by Xie et al.

</details>


### [113] [A Framework for Adversarial Analysis of Decision Support Systems Prior to Deployment](https://arxiv.org/abs/2505.21414)
*Brett Bissey, Kyle Gatesman, Walker Dimon, Mohammad Alam, Luis Robaina, Joseph Weissman*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种全面的框架，用于分析和保护使用深度强化学习（DRL）训练的决策支持系统。该框架通过模拟提供对学习行为模式和漏洞的见解，并开发了精确定时和目标观察扰动的方法。作者在自定义战略游戏CyberStrike中验证了框架，可视化了代理行为，并评估了对抗性攻击结果。此外，还引入了一种系统发现和排名攻击对不同观察指标和时间步长影响的方法，并研究了对抗性攻击在不同代理架构和DRL训练算法之间的可转移性。研究结果强调了在高风险环境中保护决策政策的鲁棒对抗防御机制的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 深度强化学习（DRL）训练的决策支持系统在部署前需要进行深入分析和保护，以了解其行为模式和潜在漏洞。现有的方法可能无法充分揭示这些系统的弱点，因此需要一种新框架来提供更详细的分析和保护手段。

**方法:** 论文提出了一种全面框架，包含以下步骤：1) 提供关于学习行为模式和漏洞的见解；2) 开发精确定时和目标观察扰动；3) 在自定义战略游戏CyberStrike中验证框架并可视化代理行为；4) 引入系统发现和排名攻击影响的方法；5) 评估对抗性攻击在不同代理架构和DRL训练算法间的可转移性。

**结果:** 实验结果表明，所提出的框架可以有效发现和评估对抗性攻击的影响，并揭示了这些攻击在不同代理架构和DRL训练算法之间的可转移性。这进一步强调了在高风险环境下需要更强的对抗防御机制。

**结论:** 本研究开发了一个全面的框架，能够分析和保护基于DRL的决策支持系统。该框架不仅有助于理解系统的行为模式和漏洞，还为评估对抗性攻击提供了重要工具。研究结果突出了在高风险环境中实施鲁棒对抗防御机制的必要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Framework+for+Adversarial+Analysis+of+Decision+Support+Systems+Prior+to+Deployment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21414，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21414&send_immediately=true&force_search=false)

**原文摘要:** This paper introduces a comprehensive framework designed to analyze and
secure decision-support systems trained with Deep Reinforcement Learning (DRL),
prior to deployment, by providing insights into learned behavior patterns and
vulnerabilities discovered through simulation. The introduced framework aids in
the development of precisely timed and targeted observation perturbations,
enabling researchers to assess adversarial attack outcomes within a strategic
decision-making context. We validate our framework, visualize agent behavior,
and evaluate adversarial outcomes within the context of a custom-built
strategic game, CyberStrike. Utilizing the proposed framework, we introduce a
method for systematically discovering and ranking the impact of attacks on
various observation indices and time-steps, and we conduct experiments to
evaluate the transferability of adversarial attacks across agent architectures
and DRL training algorithms. The findings underscore the critical need for
robust adversarial defense mechanisms to protect decision-making policies in
high-stakes environments.

</details>


### [114] [Conditional Diffusion Models with Classifier-Free Gibbs-like Guidance](https://arxiv.org/abs/2505.21101)
*Badr Moufad, Yazid Janati, Alain Durmus, Ahmed Ghorbel, Eric Moulines, Jimmy Olsson*

**主要类别:** cs.LG

**概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Conditional+Diffusion+Models+with+Classifier-Free+Gibbs-like+Guidance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21101，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21101&send_immediately=true&force_search=false)

**原文摘要:** Classifier-Free Guidance (CFG) is a widely used technique for improving
conditional diffusion models by linearly combining the outputs of conditional
and unconditional denoisers. While CFG enhances visual quality and improves
alignment with prompts, it often reduces sample diversity, leading to a
challenging trade-off between quality and diversity. To address this issue, we
make two key contributions. First, CFG generally does not correspond to a
well-defined denoising diffusion model (DDM). In particular, contrary to common
intuition, CFG does not yield samples from the target distribution associated
with the limiting CFG score as the noise level approaches zero -- where the
data distribution is tilted by a power $w \gt 1$ of the conditional
distribution. We identify the missing component: a R\'enyi divergence term that
acts as a repulsive force and is required to correct CFG and render it
consistent with a proper DDM. Our analysis shows that this correction term
vanishes in the low-noise limit. Second, motivated by this insight, we propose
a Gibbs-like sampling procedure to draw samples from the desired tilted
distribution. This method starts with an initial sample from the conditional
diffusion model without CFG and iteratively refines it, preserving diversity
while progressively enhancing sample quality. We evaluate our approach on both
image and text-to-audio generation tasks, demonstrating substantial
improvements over CFG across all considered metrics. The code is available at
https://github.com/yazidjanati/cfgig

</details>


### [115] [A Predicting Phishing Websites Using Support Vector Machine and MultiClass Classification Based on Association Rule Techniques](https://arxiv.org/abs/2505.21141)
*Nancy C. Woods, Virtue Ene Agada, Adebola K. Ojo*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种结合支持向量机（SVM）和基于关联规则的多类分类规则（MCAR）的方法，用于检测网络钓鱼网站。通过使用11,056个网站的数据集进行实验，该方法达到了98.30%的分类准确率、2205.33秒的计算时间以及98%的曲线下面积（AUC）。模型在预测网络钓鱼网站方面的方差为82.84%。结果表明，结合两种技术可以提高检测的准确性。


<details>
  <summary>更多</summary>
  
**动机:** 网络钓鱼攻击对经济造成了巨大损害，包括组织崩溃、信息盗窃和资金转移。然而，目前对于最佳的网络钓鱼网站检测算法尚未达成共识，因此需要一种更强大和有效的预测方法。

**方法:** 研究采用了混合方法，利用MCAR技术进行特征提取和规则生成，使用SVM技术进行分类和预测。数据集包含来自PhishTank和Yahoo目录的11,056个网站。

**结果:** 该方法实现了98.30%的分类准确率、98%的曲线下面积（AUC），以及82.84%的预测方差。这些结果表明，结合两种技术可以显著提高检测网络钓鱼网站的准确性。

**结论:** 通过将SVM和MCAR两种技术结合起来，可以提供一种更精确的方法来检测网络钓鱼网站。这种方法利用了两种技术的优势，从而提高了预测的准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Predicting+Phishing+Websites+Using+Support+Vector+Machine+and+MultiClass+Classification+Based+on+Association+Rule+Techniques，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21141，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21141&send_immediately=true&force_search=false)

**原文摘要:** Phishing is a semantic attack which targets the user rather than the
computer. It is a new Internet crime in comparison with other forms such as
virus and hacking. Considering the damage phishing websites has caused to
various economies by collapsing organizations, stealing information and
financial diversion, various researchers have embarked on different ways of
detecting phishing websites but there has been no agreement about the best
algorithm to be used for prediction. This study is interested in integrating
the strengths of two algorithms, Support Vector Machines (SVM) and Multi-Class
Classification Rules based on Association Rules (MCAR) to establish a strong
and better means of predicting phishing websites. A total of 11,056 websites
were used from both PhishTank and yahoo directory to verify the effectiveness
of this approach. Feature extraction and rules generation were done by the MCAR
technique; classification and prediction were done by SVM technique. The result
showed that the technique achieved 98.30% classification accuracy with a
computation time of 2205.33s with minimum error rate. It showed a total of 98%
Area under the Curve (AUC) which showed the proportion of accuracy in
classifying phishing websites. The model showed 82.84% variance in the
prediction of phishing websites based on the coefficient of determination. The
use of two techniques together in detecting phishing websites produced a more
accurate result as it combined the strength of both techniques respectively.
This research work centralized on this advantage by building a hybrid of two
techniques to help produce a more accurate result.

</details>


### [116] [Semi-Supervised Conformal Prediction With Unlabeled Nonconformity Score](https://arxiv.org/abs/2505.21147)
*Xuanning Zhou, Hao Zeng, Xiaobo Xia, Bingyi Jing, Hongxin Wei*

**主要类别:** cs.LG

**概要:** 在标记数据有限的情况下，传统一致性预测（CP）可能会导致覆盖率偏差和过大的预测集。本文提出了一种扩展的CP方法——SemiCP，该方法通过引入一种新的非一致性得分函数NNM，利用未标记数据进行校准。理论上证明了SemiCP在温和假设下能够提供渐近覆盖保证，并通过实验验证了其有效性和与现有CP方法的兼容性。


<details>
  <summary>更多</summary>
  
**动机:** 在现实世界的应用中，标记数据往往有限，这使得传统的CP方法难以提供可靠的覆盖率保证并可能导致不稳定的预测。因此需要一种新方法来充分利用未标记数据以改善预测性能。

**方法:** 提出SemiCP框架，结合标记数据和未标记数据进行校准。设计了一种新的非一致性得分函数NNM，用于未标记数据。NNM通过选择具有相似伪标签得分的标记数据来估计非一致性得分，并将其纳入校准过程。

**结果:** 理论分析表明，SemiCP在一定假设下可以提供渐近覆盖保证。实验结果进一步验证了该方法在减少不稳定性、提高效率以及适应条件覆盖率设置方面的有效性。

**结论:** SemiCP是一种有效的扩展CP方法，能够在标记数据有限的情况下，通过利用未标记数据改善预测性能，并且与现有CP方法兼容。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Semi-Supervised+Conformal+Prediction+With+Unlabeled+Nonconformity+Score，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21147，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21147&send_immediately=true&force_search=false)

**原文摘要:** Conformal prediction (CP) is a powerful framework for uncertainty
quantification, providing prediction sets with coverage guarantees when
calibrated on sufficient labeled data. However, in real-world applications
where labeled data is often limited, standard CP can lead to coverage deviation
and output overly large prediction sets. In this paper, we extend CP to the
semi-supervised setting and propose SemiCP, leveraging both labeled data and
unlabeled data for calibration. Specifically, we introduce a novel
nonconformity score function, NNM, designed for unlabeled data. This function
selects labeled data with similar pseudo-label scores to estimate nonconformity
scores, integrating them into the calibration process to overcome sample size
limitations. We theoretically demonstrate that, under mild assumptions, SemiCP
provide asymptotically coverage guarantee for prediction sets. Extensive
experiments further validate that our approach effectively reduces instability
and inefficiency under limited calibration data, can be adapted to conditional
coverage settings, and integrates seamlessly with existing CP methods.

</details>


### [117] [Topological Deep Learning for Speech Data](https://arxiv.org/abs/2505.21173)
*Zhiwang Yu*

**主要类别:** cs.LG

**概要:** TDA在深度学习中的应用，设计拓扑感知卷积核提升语音识别网络性能，并提出OF层在低噪声场景中表现出色，揭示TDA在网络优化中的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 受Carlsson等人的启发，将拓扑数据分析引入深度学习领域以改进神经网络性能。

**方法:** 通过研究核上的正交群作用，建立矩阵空间的纤维丛分解，生成新的滤波器，并提出Orthogonal Feature (OF)层用于语音识别。

**结果:** OF层在低噪声环境下的音素识别任务中表现优异，并展示出跨域适应性。

**结论:** TDA为神经网络优化提供了新方法，推动数学与深度学习交叉学科的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Topological+Deep+Learning+for+Speech+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21173，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21173&send_immediately=true&force_search=false)

**原文摘要:** Topological data analysis (TDA) offers novel mathematical tools for deep
learning. Inspired by Carlsson et al., this study designs topology-aware
convolutional kernels that significantly improve speech recognition networks.
Theoretically, by investigating orthogonal group actions on kernels, we
establish a fiber-bundle decomposition of matrix spaces, enabling new filter
generation methods. Practically, our proposed Orthogonal Feature (OF) layer
achieves superior performance in phoneme recognition, particularly in low-noise
scenarios, while demonstrating cross-domain adaptability. This work reveals
TDA's potential in neural network optimization, opening new avenues for
mathematics-deep learning interdisciplinary studies.

</details>


### [118] [Crop recommendation with machine learning: leveraging environmental and economic factors for optimal crop selection](https://arxiv.org/abs/2505.21201)
*Steven Sam, Silima Marshal DAbreo*

**主要类别:** cs.LG

**概要:** 研究通过环境和经济因素，利用随机森林（RF）和支持向量机（SVM）模型对印度15个州的19种作物进行建模，并采用10折交叉验证、时间序列分割和滞后变量方法评估模型性能。最终推荐基于滞后变量的随机森林模型作为最优作物推荐算法。


<details>
  <summary>更多</summary>
  
**动机:** 农业是印度食品生产、经济增长和就业的主要来源，但面临低生产力、资源压力和气候变化等问题。传统改进措施效果有限，计算工具如作物推荐系统提供新解决方案，但现有系统预测精度受限于狭窄的环境和地区关注点。

**方法:** 使用环境和经济因素数据，针对印度15个州的19种作物开发并评估了随机森林和支持向量机模型。采用10折交叉验证、时间序列分割和滞后变量三种方法进行模型训练与评估。

**结果:** 10折交叉验证显示高准确率（RF：99.96%，SVM：94.71%），但存在过拟合问题；时间序列分割反映实际条件，准确率下降（RF：78.55%，SVM：71.18%）；引入滞后变量后，模型性能有所提升（RF：83.62%，SVM：74.38%）。

**结论:** 基于滞后变量的时间序列方法能有效处理时间依赖性，增强模型适应性。随机森林模型在滞后变量方法中表现最佳，适合作为印度作物推荐系统的首选算法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Crop+recommendation+with+machine+learning%3A+leveraging+environmental+and+economic+factors+for+optimal+crop+selection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21201，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21201&send_immediately=true&force_search=false)

**原文摘要:** Agriculture constitutes a primary source of food production, economic growth
and employment in India, but the sector is confronted with low farm
productivity and yields aggravated by increased pressure on natural resources
and adverse climate change variability. Efforts involving green revolution,
land irrigations, improved seeds and organic farming have yielded suboptimal
outcomes. The adoption of computational tools like crop recommendation systems
offers a new way to provide insights and help farmers tackle low productivity.
However, most agricultural recommendation systems in India focus narrowly on
environmental factors and regions, limiting accurate predictions of high-yield,
profitable crops. This study uses environmental and economic factors with 19
crops across 15 states to develop and evaluate Random Forest and SVM models
using 10-fold Cross Validation, Time-series Split, and Lag Variables. The
10-fold cross validation showed high accuracy (RF: 99.96%, SVM: 94.71%) but
raised overfitting concerns. Introducing temporal order, better reflecting
real-world conditions, reduced performance (RF: 78.55%, SVM: 71.18%) in the
Time-series Split.To further increase the model accuracy while maintaining the
temporal order, the Lag Variables approach was employed, which resulted in
improved performance (RF: 83.62%, SVM: 74.38%) compared to the 10-fold cross
validation approach. Overall, the models in the Time-series Split and Lag
Variable Approaches offer practical insights by handling temporal dependencies
and enhancing its adaptability to changing agricultural conditions over time.
Consequently, the study shows the Random Forest model developed based on the
Lag Variables as the most preferred algorithm for optimal crop recommendation
in the Indian context.

</details>


### [119] [Developing hybrid mechanistic and data-driven personalized prediction models for platelet dynamics](https://arxiv.org/abs/2505.21204)
*Marie Steinacker, Yuri Kheifetz, Markus Scholz*

**主要类别:** cs.LG

**概要:** 本研究开发并比较了用于化疗期间血小板计数个体化时间序列建模的混合机制和数据驱动方法。研究表明，数据驱动方法在高风险患者中显著提高了预测准确性，而混合和机制模型在数据有限或稀疏的情况下表现更优。该框架具有广泛的应用前景，可扩展至其他治疗相关毒性预测。


<details>
  <summary>更多</summary>
  
**动机:** 造血毒性是细胞毒性化疗的常见副作用，具有高度的患者间变异性且难以预测。当前的机制模型在处理不规则或非典型轨迹患者时往往无法准确预测结果。因此，需要开发新的方法来改善预测性能。

**方法:** 研究采用了两种主要方法：1) 混合模型，将机制模型与神经网络结合，形成通用微分方程；2) 纯数据驱动方法，使用带有门控循环单元的非线性自回归外生模型。这些模型在不同数据可用性和稀疏性的实际患者场景中进行评估。

**结果:** 数据驱动方法在数据充足的情况下显著提高了预测准确性，特别是对于具有不规则血小板动态的高风险患者。而在数据有限或稀疏的情况下，混合和机制模型表现更佳。

**结论:** 数据驱动方法在特定条件下可以显著提高预测精度，有助于临床决策制定。同时，混合和机制模型在数据稀缺情况下更具优势。该框架可推广至其他治疗相关毒性的预测，为个性化医学提供了广阔的应用前景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Developing+hybrid+mechanistic+and+data-driven+personalized+prediction+models+for+platelet+dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21204，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21204&send_immediately=true&force_search=false)

**原文摘要:** Hematotoxicity, drug-induced damage to the blood-forming system, is a
frequent side effect of cytotoxic chemotherapy and poses a significant
challenge in clinical practice due to its high inter-patient variability and
limited predictability. Current mechanistic models often struggle to accurately
forecast outcomes for patients with irregular or atypical trajectories. In this
study, we develop and compare hybrid mechanistic and data-driven approaches for
individualized time series modeling of platelet counts during chemotherapy. We
consider hybrid models that combine mechanistic models with neural networks,
known as universal differential equations. As a purely data-driven alternative,
we utilize a nonlinear autoregressive exogenous model using gated recurrent
units as the underlying architecture. These models are evaluated across a range
of real patient scenarios, varying in data availability and sparsity, to assess
predictive performance. Our findings demonstrate that data-driven methods, when
provided with sufficient data, significantly improve prediction accuracy,
particularly for high-risk patients with irregular platelet dynamics. This
highlights the potential of data-driven approaches in enhancing clinical
decision-making. In contrast, hybrid and mechanistic models are superior in
scenarios with limited or sparse data. The proposed modeling and comparison
framework is generalizable and could be extended to predict other
treatment-related toxicities, offering broad applicability in personalized
medicine.

</details>


### [120] [Why Do More Experts Fail? A Theoretical Analysis of Model Merging](https://arxiv.org/abs/2505.21226)
*Zijing Wang, Xingle Xu, Yongkang Liu, Yiqun Zhang, Peiqin Lin, Shi Feng, Xiaocui Yang, Daling Wang, Hinrich Schütze*

**主要类别:** cs.LG

**概要:** 通过结合多个专家模型到一个单一的多任务模型中，模型合并显著减少了存储和计算资源。然而，随着合并模型数量的增加，性能提升难以维持。本文研究了在整合大量专家模型时限制模型合并可扩展性的关键障碍，并提出了重新参数化的重尾方法（RHT）以提高合并模型的性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管最近的模型合并方法显示出有希望的结果，但当合并模型的数量增加时，它们很难保持性能提升。因此，需要研究限制模型合并可扩展性的关键障碍。

**方法:** 首先证明了模型合并存在上限。进一步的理论分析表明，有限的有效参数空间对可以成功合并的模型数量施加了严格的约束。高斯宽度显示，合并额外模型的边际收益根据严格凹函数递减。同时，使用近似运动学理论，证明了存在一个唯一的最优阈值，超过该阈值后添加更多模型不会带来显著的性能改进。此外，引入了一种简单的重新参数化重尾方法（RHT），以扩展合并模型的覆盖范围，从而提高其性能。

**结果:** 在12个基准测试上的实证结果验证了我们的理论分析，这些基准测试包括知识密集型和通用任务。

**结论:** 这些结果激发了超出当前模型合并范围的进一步研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Why+Do+More+Experts+Fail%3F+A+Theoretical+Analysis+of+Model+Merging，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21226，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21226&send_immediately=true&force_search=false)

**原文摘要:** Model merging dramatically reduces storage and computational resources by
combining multiple expert models into a single multi-task model. Although
recent model merging methods have shown promising results, they struggle to
maintain performance gains as the number of merged models increases. In this
paper, we investigate the key obstacles that limit the scalability of model
merging when integrating a large number of expert models. First, we prove that
there is an upper bound on model merging. Further theoretical analysis reveals
that the limited effective parameter space imposes a strict constraint on the
number of models that can be successfully merged. Gaussian Width shows that the
marginal benefit of merging additional models diminishes according to a
strictly concave function. This implies that the effective parameter space
becomes rapidly saturated as the number of merged models increases.
Furthermore, using Approximate Kinematics Theory, we prove the existence of a
unique optimal threshold beyond which adding more models does not yield
significant performance improvements. At the same time, we introduce a
straightforward Reparameterized Heavy-Tailed method (RHT) to extend the
coverage of the merged model, thereby enhancing its performance. Empirical
results on 12 benchmarks, including both knowledge-intensive and
general-purpose tasks, validate our theoretical analysis. We believe that these
results spark further research beyond the current scope of model merging. The
source code is in the anonymous Github repository
https://github.com/wzj1718/ModelMergingAnalysis.

</details>


### [121] [BindEnergyCraft: Casting Protein Structure Predictors as Energy-Based Models for Binder Design](https://arxiv.org/abs/2505.21241)
*Divya Nori, Anisha Parsan, Caroline Uhler, Wengong Jin*

**主要类别:** cs.LG

**概要:** 通过重新解释结构预测器的置信度输出为基于能量的模型（EBM），提出了一种从结构预测器中提取统计似然性的方法pTMEnergy，并将其整合到设计流程BECraft中，从而在多个具有挑战性的目标上优于BindCraft、RFDiffusion和ESM3。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于幻觉的方法虽然可以通过反向传播优化结构预测置信度指标（如ipTM），但这些指标并不能反映结合体-靶标复合物在学习分布下的统计可能性，且提供的优化梯度稀疏。

**方法:** 通过利用联合能量模型（JEM）框架，将结构预测器的置信输出重新解释为基于能量的模型（EBM），从而提取出统计似然性，提出了pTMEnergy这一统计能量函数，并将其纳入到设计流程BECraft中，用能量目标代替了原有的ipTM指标。

**结果:** BECraft在多个具有挑战性的目标上表现优于BindCraft、RFDiffusion和ESM3，在计算中实现了更高的结合成功速率，同时减少了结构冲突；此外，pTMEnergy在基于结构的虚拟筛选任务中为小型蛋白和RNA适配体结合剂建立了新的最先进水平。

**结论:** pTMEnergy作为一种新的能量函数，能够更准确地反映结合体-靶标复合物的统计可能性，并显著提高了基于结构的虚拟筛选性能。BECraft的设计流程通过使用pTMEnergy作为优化目标，有效提升了结合子设计的成功率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BindEnergyCraft%3A+Casting+Protein+Structure+Predictors+as+Energy-Based+Models+for+Binder+Design，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21241，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21241&send_immediately=true&force_search=false)

**原文摘要:** Protein binder design has been transformed by hallucination-based methods
that optimize structure prediction confidence metrics, such as the interface
predicted TM-score (ipTM), via backpropagation. However, these metrics do not
reflect the statistical likelihood of a binder-target complex under the learned
distribution and yield sparse gradients for optimization. In this work, we
propose a method to extract such likelihoods from structure predictors by
reinterpreting their confidence outputs as an energy-based model (EBM). By
leveraging the Joint Energy-based Modeling (JEM) framework, we introduce
pTMEnergy, a statistical energy function derived from predicted inter-residue
error distributions. We incorporate pTMEnergy into BindEnergyCraft (BECraft), a
design pipeline that maintains the same optimization framework as BindCraft but
replaces ipTM with our energy-based objective. BECraft outperforms BindCraft,
RFDiffusion, and ESM3 across multiple challenging targets, achieving higher in
silico binder success rates while reducing structural clashes. Furthermore,
pTMEnergy establishes a new state-of-the-art in structure-based virtual
screening tasks for miniprotein and RNA aptamer binders.

</details>


### [122] [Copresheaf Topological Neural Networks: A Generalized Deep Learning Framework](https://arxiv.org/abs/2505.21251)
*Mustafa Hajij, Lennart Bastian, Sarah Osentoski, Hardik Kabaria, John L. Davenport, Sheik Dawood, Balaji Cherukuri, Joseph G. Kocheemoolayil, Nastaran Shahmansouri, Adrian Lew, Theodore Papamarkou, Tolga Birdal*

**主要类别:** cs.LG

**概要:** 提出了一种新的神经网络框架CTNNs，可以处理多种结构化数据，并在基准测试中优于传统方法。


<details>
  <summary>更多</summary>
  
**动机:** 深度学习在许多领域取得了显著影响，但针对特定任务和数据类型的神经架构的合理设计仍然是一个开放的挑战。

**方法:** 引入了共前层拓扑神经网络（CTNNs），这是一种基于代数拓扑中copresheaves概念的强大统一框架，能够封装广泛的深度学习架构，用于处理包括图像、点云、图、网格和拓扑流形在内的结构化数据。

**结果:** 实验证明，CTNNs在结构化数据基准测试中持续优于传统基线模型，尤其是在需要分层或局部敏感的任务中表现更为出色。

**结论:** CTNNs为下一代深度学习架构提供了一个有原则的、多尺度的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Copresheaf+Topological+Neural+Networks%3A+A+Generalized+Deep+Learning+Framework，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21251，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21251&send_immediately=true&force_search=false)

**原文摘要:** We introduce copresheaf topological neural networks (CTNNs), a powerful and
unifying framework that encapsulates a wide spectrum of deep learning
architectures, designed to operate on structured data: including images, point
clouds, graphs, meshes, and topological manifolds. While deep learning has
profoundly impacted domains ranging from digital assistants to autonomous
systems, the principled design of neural architectures tailored to specific
tasks and data types remains one of the field's most persistent open
challenges. CTNNs address this gap by grounding model design in the language of
copresheaves, a concept from algebraic topology that generalizes and subsumes
most practical deep learning models in use today. This abstract yet
constructive formulation yields a rich design space from which theoretically
sound and practically effective solutions can be derived to tackle core
challenges in representation learning: long-range dependencies, oversmoothing,
heterophily, and non-Euclidean domains. Our empirical results on structured
data benchmarks demonstrate that CTNNs consistently outperform conventional
baselines, particularly in tasks requiring hierarchical or localized
sensitivity. These results underscore CTNNs as a principled, multi-scale
foundation for the next generation of deep learning architectures.

</details>


### [123] [LoFT: Low-Rank Adaptation That Behaves Like Full Fine-Tuning](https://arxiv.org/abs/2505.21289)
*Nurbek Tastan, Stefanos Laskaridis, Martin Takac, Karthik Nandakumar, Samuel Horvath*

**主要类别:** cs.LG

**概要:** 大型预训练模型通常使用参数高效的微调方法（如LoRA）适应下游任务，但这些方法在准确性和收敛速度上可能不如全量微调。本文提出了一种新的低秩适配方法LoFT，它通过将优化器的内部动态与更新所有模型权重的动态对齐，模拟了全量微调的效果。LoFT不仅学习低秩子空间中的权重更新，还正确地将优化器的一阶和二阶矩投影到相同的子空间，从而消除了对额外超参数调整的需求，并显著缩小了基于适配器的微调和全量微调之间的性能差距，同时保持推理成本不变。


<details>
  <summary>更多</summary>
  
**动机:** 尽管LoRA等低秩适配方法大幅减少了可训练参数且开销小，但在准确性和收敛速度上仍逊色于全量微调。为解决这一问题，需要一种能更接近全量微调效果的低秩适配方法。

**方法:** 提出LoFT方法，通过在低秩子空间中学习权重更新的同时，将优化器的一阶和二阶矩也投影到该子空间，使低秩更新与全量更新对齐。这种方法消除了对额外超参数（如LoRA缩放因子α）的调整需求。

**结果:** 实验结果表明，LoFT方法显著缩小了基于适配器的微调和全量微调之间的性能差距，并且在不增加推理成本的情况下，始终优于标准的LoRA式方法。

**结论:** LoFT作为一种新颖的低秩适配方法，成功模拟了全量微调的效果，提高了准确性并加快了收敛速度，同时保持了低推理成本，为参数高效微调提供了更好的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LoFT%3A+Low-Rank+Adaptation+That+Behaves+Like+Full+Fine-Tuning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21289，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21289&send_immediately=true&force_search=false)

**原文摘要:** Large pre-trained models are commonly adapted to downstream tasks using
parameter-efficient fine-tuning methods such as Low-Rank Adaptation (LoRA),
which injects small trainable low-rank matrices instead of updating all
weights. While LoRA dramatically reduces trainable parameters with little
overhead, it can still underperform full fine-tuning in accuracy and often
converges more slowly. We introduce LoFT, a novel low-rank adaptation method
that behaves like full fine-tuning by aligning the optimizer's internal
dynamics with those of updating all model weights. LoFT not only learns weight
updates in a low-rank subspace (like LoRA) but also properly projects the
optimizer's first and second moments (Adam's momentum and variance) into the
same subspace, mirroring full-model updates. By aligning the low-rank update
itself with the full update, LoFT eliminates the need for tuning extra
hyperparameters, e.g., LoRA scaling factor $\alpha$. Empirically, this approach
substantially narrows the performance gap between adapter-based tuning and full
fine-tuning and consistently outperforms standard LoRA-style methods, all
without increasing inference cost.

</details>


### [124] [Bencher: Simple and Reproducible Benchmarking for Black-Box Optimization](https://arxiv.org/abs/2505.21321)
*Leonard Papenmeier, Luigi Nardi*

**主要类别:** cs.LG

**概要:** The paper introduces Bencher, a modular benchmarking framework for black-box optimization that separates benchmark execution from optimization logic through isolated virtual environments and a unified RPC interface.


<details>
  <summary>更多</summary>
  
**动机:** To address dependency conflicts and simplify the integration of diverse, real-world benchmarks in black-box optimization.

**方法:** Bencher decouples benchmark execution from optimization logic by isolating each benchmark in its own virtual Python environment and providing access via a unified, version-agnostic RPC interface. It can be deployed locally or remotely via Docker or on HPC clusters via Singularity.

**结果:** Bencher eliminates dependency conflicts, simplifies benchmark integration, and provides a containerized, reproducible runtime for any benchmark with minimal setup.

**结论:** Bencher offers a modular, flexible, and reproducible solution for benchmarking in black-box optimization.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bencher%3A+Simple+and+Reproducible+Benchmarking+for+Black-Box+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21321，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21321&send_immediately=true&force_search=false)

**原文摘要:** We present Bencher, a modular benchmarking framework for black-box
optimization that fundamentally decouples benchmark execution from optimization
logic. Unlike prior suites that focus on combining many benchmarks in a single
project, Bencher introduces a clean abstraction boundary: each benchmark is
isolated in its own virtual Python environment and accessed via a unified,
version-agnostic remote procedure call (RPC) interface. This design eliminates
dependency conflicts and simplifies the integration of diverse, real-world
benchmarks, which often have complex and conflicting software requirements.
Bencher can be deployed locally or remotely via Docker or on high-performance
computing (HPC) clusters via Singularity, providing a containerized,
reproducible runtime for any benchmark. Its lightweight client requires minimal
setup and supports drop-in evaluation of 80 benchmarks across continuous,
categorical, and binary domains.

</details>


### [125] [UGCE: User-Guided Incremental Counterfactual Exploration](https://arxiv.org/abs/2505.21330)
*Christos Fragkathoulas, Evaggelia Pitoura*

**主要类别:** cs.LG

**概要:** 提出了一种基于遗传算法的框架UGCE，用于根据用户约束的演变增量更新反事实。实验表明，与静态方法相比，UGCE显著提高了计算效率，并保持了高质量解决方案。


<details>
  <summary>更多</summary>
  
**动机:** 当前反事实生成方法在面对用户随时间不断优化的可行性约束时，无法动态适应，只能从头重新计算解释，这种方法低效且僵化。

**方法:** 提出了User-Guided Incremental Counterfactual Exploration（UGCE），一种基于遗传算法的框架，能够对用户的约束变化作出增量更新反事实的响应。

**结果:** 在五个基准数据集上的实验结果表明，UGCE相较于静态非增量方法显著提高了计算效率，同时保持了高质量的解决方案。此外，UGCE在不同的约束序列下表现稳定，受益于高效的warm-start策略，并揭示了不同约束类型如何影响搜索行为。

**结论:** UGCE为动态调整反事实提供了一个有效的工具，提高了计算效率并维持了解决方案的质量，适应了用户约束的变化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是UGCE%3A+User-Guided+Incremental+Counterfactual+Exploration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21330，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21330&send_immediately=true&force_search=false)

**原文摘要:** Counterfactual explanations (CFEs) are a popular approach for interpreting
machine learning predictions by identifying minimal feature changes that alter
model outputs. However, in real-world settings, users often refine feasibility
constraints over time, requiring counterfactual generation to adapt
dynamically. Existing methods fail to support such iterative updates, instead
recomputing explanations from scratch with each change, an inefficient and
rigid approach. We propose User-Guided Incremental Counterfactual Exploration
(UGCE), a genetic algorithm-based framework that incrementally updates
counterfactuals in response to evolving user constraints. Experimental results
across five benchmark datasets demonstrate that UGCE significantly improves
computational efficiency while maintaining high-quality solutions compared to a
static, non-incremental approach. Our evaluation further shows that UGCE
supports stable performance under varying constraint sequences, benefits from
an efficient warm-start strategy, and reveals how different constraint types
may affect search behavior.

</details>


### [126] [OVERT: A Benchmark for Over-Refusal Evaluation on Text-to-Image Models](https://arxiv.org/abs/2505.21347)
*Ziheng Cheng, Yixiao Huang, Hui Xu, Somayeh Sojoudi, Xuandong Zhao, Dawn Song, Song Mei*

**主要类别:** cs.LG

**概要:** 文本到图像（T2I）模型在生成视觉内容方面取得了显著成功，但过度拒绝良性提示的问题降低了其实用性。本文提出了OVERT，一个大规模评估T2I模型过度拒绝行为的基准，包括4600个看似有害但良性的提示和1785个真正有害的提示。通过评估多个T2I模型，发现过度拒绝是一个普遍问题，并初步尝试了提示重写方法，但发现该方法常牺牲对原始提示含义的忠实度。最后，展示了生成框架的灵活性以适应多样化的安全需求。


<details>
  <summary>更多</summary>
  
**动机:** 尽管文本到图像（T2I）模型在生成视觉内容方面取得巨大成功，但防止有害输出的安全对齐策略常常导致过度拒绝良性提示的现象，这降低了模型的实际可用性。然而，目前缺乏系统评估这种现象的大规模基准。

**方法:** 作者提出了一种自动工作流来构建合成评估数据，创建了OVERT——第一个大规模评估T2I模型过度拒绝行为的基准。OVERT包含4600个看似有害但良性的提示，涵盖九个与安全相关的类别，以及1785个真正有害的提示（OVERT-unsafe），用于评估安全性与实用性的权衡。然后使用OVERT评估多个领先的T2I模型。此外，还探索了提示重写作为减少过度拒绝的初步方法。

**结果:** 评估结果显示过度拒绝是T2I模型中一个广泛存在的问题，影响多个类别。提示重写虽然是一种可能的解决方案，但往往会影响对原始提示含义的忠实度。

**结论:** 过度拒绝是T2I模型中的一个重要问题，需要进一步研究以改进模型的安全对齐而不损害其功能。OVERT为评估和改善这一问题提供了有价值的工具。同时，生成框架具有灵活性，可以根据用户定义的政策生成定制化评估数据。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是OVERT%3A+A+Benchmark+for+Over-Refusal+Evaluation+on+Text-to-Image+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21347，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21347&send_immediately=true&force_search=false)

**原文摘要:** Text-to-Image (T2I) models have achieved remarkable success in generating
visual content from text inputs. Although multiple safety alignment strategies
have been proposed to prevent harmful outputs, they often lead to overly
cautious behavior -- rejecting even benign prompts -- a phenomenon known as
$\textit{over-refusal}$ that reduces the practical utility of T2I models.
Despite over-refusal having been observed in practice, there is no large-scale
benchmark that systematically evaluates this phenomenon for T2I models. In this
paper, we present an automatic workflow to construct synthetic evaluation data,
resulting in OVERT ($\textbf{OVE}$r-$\textbf{R}$efusal evaluation on
$\textbf{T}$ext-to-image models), the first large-scale benchmark for assessing
over-refusal behaviors in T2I models. OVERT includes 4,600 seemingly harmful
but benign prompts across nine safety-related categories, along with 1,785
genuinely harmful prompts (OVERT-unsafe) to evaluate the safety-utility
trade-off. Using OVERT, we evaluate several leading T2I models and find that
over-refusal is a widespread issue across various categories (Figure 1),
underscoring the need for further research to enhance the safety alignment of
T2I models without compromising their functionality.As a preliminary attempt to
reduce over-refusal, we explore prompt rewriting; however, we find it often
compromises faithfulness to the meaning of the original prompts. Finally, we
demonstrate the flexibility of our generation framework in accommodating
diverse safety requirements by generating customized evaluation data adapting
to user-defined policies.

</details>


### [127] [CRISP-NAM: Competing Risks Interpretable Survival Prediction with Neural Additive Models](https://arxiv.org/abs/2505.21360)
*Dhanesh Ramachandram*

**主要类别:** cs.LG

**概要:** 提出CRISP-NAM模型，用于可解释的竞争风险生存分析，通过神经加法模型架构对特定原因的风险进行建模，同时保持特征级别的可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 在生存建模中，尤其是在医疗保健领域，竞争风险是需要考虑的重要因素，因为患者可能会经历多种不同的事件类型。

**方法:** 提出了一种可解释的神经加法模型CRISP-NAM，扩展了神经加法架构以对特定原因的风险进行建模，同时保持特征级别的可解释性。每个特征通过专门的神经网络独立地对风险估计做出贡献。

**结果:** 与现有方法相比，在多个数据集上展示了具有竞争力的表现。

**结论:** CRISP-NAM为竞争风险生存分析提供了一个可解释的解决方案，能够可视化协变量与每种竞争风险之间的复杂非线性关系。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CRISP-NAM%3A+Competing+Risks+Interpretable+Survival+Prediction+with+Neural+Additive+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21360，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21360&send_immediately=true&force_search=false)

**原文摘要:** Competing risks are crucial considerations in survival modelling,
particularly in healthcare domains where patients may experience multiple
distinct event types. We propose CRISP-NAM (Competing Risks Interpretable
Survival Prediction with Neural Additive Models), an interpretable neural
additive model for competing risks survival analysis which extends the neural
additive architecture to model cause-specific hazards while preserving
feature-level interpretability. Each feature contributes independently to risk
estimation through dedicated neural networks, allowing for visualization of
complex non-linear relationships between covariates and each competing risk. We
demonstrate competitive performance on multiple datasets compared to existing
approaches.

</details>


### [128] [PLANETALIGN: A Comprehensive Python Library for Benchmarking Network Alignment](https://arxiv.org/abs/2505.21366)
*Qi Yu, Zhichen Zeng, Yuchen Yan, Zhining Liu, Baoyu Jing, Ruizhong Qiu, Ariful Azad, Hanghang Tong*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一个名为PLANETALIGN的全面Python库，用于网络对齐（NA），其特点包括内置数据集、方法和评估管道。它整合了18个数据集和14种NA方法，并提供可扩展API以促进NA方法的使用和发展。标准化评估管道涵盖多种度量标准，有助于系统地评估NA方法的有效性、可扩展性和鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管网络对齐在各种下游多网络学习任务中起着关键作用，但目前缺乏一个全面的库来促进NA方法的系统发展和基准测试。

**方法:** 作者介绍了PLANETALIGN，一个综合性的Python库，该库具有丰富的内置数据集、方法和评估管道，且具备易于使用的API。具体来说，PLANETALIGN集成了18个数据集和14种NA方法，并通过可扩展API简化了NA方法的使用和开发。

**结果:** 通过广泛的比较研究，揭示了现有NA方法的优势和局限性，为未来更有效、可扩展和鲁棒的方法的发展提供了实用见解。

**结论:** 作者希望PLANETALIGN能够加深对NA问题的理解，并推动更有效的NA方法的发展和基准测试。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PLANETALIGN%3A+A+Comprehensive+Python+Library+for+Benchmarking+Network+Alignment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21366，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21366&send_immediately=true&force_search=false)

**原文摘要:** Network alignment (NA) aims to identify node correspondence across different
networks and serves as a critical cornerstone behind various downstream
multi-network learning tasks. Despite growing research in NA, there lacks a
comprehensive library that facilitates the systematic development and
benchmarking of NA methods. In this work, we introduce PLANETALIGN, a
comprehensive Python library for network alignment that features a rich
collection of built-in datasets, methods, and evaluation pipelines with
easy-to-use APIs. Specifically, PLANETALIGN integrates 18 datasets and 14 NA
methods with extensible APIs for easy use and development of NA methods. Our
standardized evaluation pipeline encompasses a wide range of metrics, enabling
a systematic assessment of the effectiveness, scalability, and robustness of NA
methods. Through extensive comparative studies, we reveal practical insights
into the strengths and limitations of existing NA methods. We hope that
PLANETALIGN can foster a deeper understanding of the NA problem and facilitate
the development and benchmarking of more effective, scalable, and robust
methods in the future. The source code of PLANETALIGN is available at
https://github.com/yq-leo/PlanetAlign.

</details>


### [129] [DeCAF: Decentralized Consensus-And-Factorization for Low-Rank Adaptation of Foundation Models](https://arxiv.org/abs/2505.21382)
*Nastaran Saadati, Zhanhong Jiang, Joshua R. Waite, Shreyan Ganguly, Aditya Balu, Chinmay Hegde, Soumik Sarkar*

**主要类别:** cs.LG

**概要:** Low-Rank Adaptation (LoRA) 是一种有效的微调方法，用于训练视觉-语言模型 (VLMs) 和大型语言模型 (LLMs)。然而，在去中心化设置下的 LoRA 理论基础尚未被充分研究。本文通过确保梯度平滑性改进了去中心化 LoRA (DLoRA) 的收敛速度，并提出了 DeCAF 算法以解决共识干扰问题。理论分析和实验结果表明，DeCAF 在各种任务中表现优于本地训练和联邦学习方法。


<details>
  <summary>更多</summary>
  
**动机:** 尽管 LoRA 方法在微调大型模型方面表现出色，但其在去中心化环境中的应用仍面临挑战，例如缺乏平滑性保证和模型共识干扰等问题。这促使研究人员探索如何优化去中心化 LoRA 的性能并解决相关理论问题。

**方法:** 1. 改进 DLoRA 的收敛率以匹配去中心化 SGD 的速率，通过确保梯度平滑性实现。
2. 提出 DeCAF 算法，结合 DLoRA 和基于截断奇异值分解 (TSVD) 的矩阵分解技术，以消除共识干扰。
3. 通过理论分析证明 TSVD 的近似误差是有界的，并且随着秩的增加，DLoRA 和 DeCAF 之间的共识差异会消失。

**结果:** 理论分析和广泛的实验验证表明：
- DeCAF 的收敛速度与 DLoRA 相当。
- 在视觉和语言任务中，DeCAF 算法在 IID 和非 IID 数据分布下均优于本地训练和联邦学习方法。

**结论:** 本文通过改进 DLoRA 和提出 DeCAF 算法，解决了去中心化 LoRA 中的收敛性和共识干扰问题。这些成果为在去中心化环境中高效微调大型模型提供了新的可能性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DeCAF%3A+Decentralized+Consensus-And-Factorization+for+Low-Rank+Adaptation+of+Foundation+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21382，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21382&send_immediately=true&force_search=false)

**原文摘要:** Low-Rank Adaptation (LoRA) has emerged as one of the most effective,
computationally tractable fine-tuning approaches for training Vision-Language
Models (VLMs) and Large Language Models (LLMs). LoRA accomplishes this by
freezing the pre-trained model weights and injecting trainable low-rank
matrices, allowing for efficient learning of these foundation models even on
edge devices. However, LoRA in decentralized settings still remains under
explored, particularly for the theoretical underpinnings due to the lack of
smoothness guarantee and model consensus interference (defined formally below).
This work improves the convergence rate of decentralized LoRA (DLoRA) to match
the rate of decentralized SGD by ensuring gradient smoothness. We also
introduce DeCAF, a novel algorithm integrating DLoRA with truncated singular
value decomposition (TSVD)-based matrix factorization to resolve consensus
interference. Theoretical analysis shows TSVD's approximation error is bounded
and consensus differences between DLoRA and DeCAF vanish as rank increases,
yielding DeCAF's matching convergence rate. Extensive experiments across
vision/language tasks demonstrate our algorithms outperform local training and
rivals federated learning under both IID and non-IID data distributions.

</details>


### [130] [Square$χ$PO: Differentially Private and Robust $χ^2$-Preference Optimization in Offline Direct Alignment](https://arxiv.org/abs/2505.21395)
*Xingyu Zhou, Yulian Wu, Wenqian Weng, Francesco Orabona*

**主要类别:** cs.LG

**概要:** 本文提出了一种名为SquareχPO的新方法，通过替换标准log-loss为新的概率平方损失，显著提升了差分隐私和鲁棒离线直接对齐的状态。该方法在标签隐私的局部模型中首次达到最优速率，并且可以同时处理隐私保护和标签损坏问题，具有理论上的保证。此外，SquareχPO还能扩展到一般偏好模型场景，提供最先进的保证。


<details>
  <summary>更多</summary>
  
**动机:** 当前语言模型的离线对齐研究需要解决人类偏好反馈中的标签损坏和隐私保护问题，但现有方法在这些方面存在不足，特别是在一般函数逼近下的理论保证较少。

**方法:** 作者提出了SquareχPO方法，将标准log-loss替换为新的概率平方损失。这种方法利用了新损失函数的固有特性，从而在差分隐私和鲁棒性方面取得了进展。具体而言，它在局部模型和集中模型下分别实现了隐私保护和抗Huber标签损坏的能力。

**结果:** SquareχPO在以下方面取得成果：1) 在局部模型中实现最优速率；2) 在集中模型下提供隐私保护结果；3) 成为首个在一般函数逼近下具备有意义理论保证的对齐方法；4) 能够同时处理隐私保护和标签损坏问题。

**结论:** SquareχPO不仅在差分隐私和鲁棒性方面表现出色，还可以扩展到一般偏好模型场景。其理论保证基于一个新的最小二乘回归泛化误差界，该结果具有独立的研究价值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Square%24%CF%87%24PO%3A+Differentially+Private+and+Robust+%24%CF%87%5E2%24-Preference+Optimization+in+Offline+Direct+Alignment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21395，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21395&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we theoretically study the offline alignment of language
models with human preference feedback, under both preference label corruption
and privacy protections. To this end, we propose Square$\chi$PO, a simple
one-line change to $\chi$PO where the standard log-loss is replaced by a new
square loss over probability. Thanks to the inherent properties of this new
loss, we have advanced the state-of-the-art of differentially private and
robust offline direct alignment. Specifically, for the local model of label
privacy, Square$\chi$PO is the first algorithm that attains an optimal rate
based on single-policy concentrability even with general function
approximations. It also gives the first result under the central model of
privacy protection over both prompts (responses) and labels. On the robustness
side against Huber label corruption, Square$\chi$PO is the first alignment
method that has a meaningful theoretical guarantee under general function
approximations. More importantly, Square$\chi$PO can address privacy protection
and corruption simultaneously, where an interesting separation is observed,
implying that the order of privacy and corruption matters. Furthermore, we show
that Square$\chi$PO can also be easily extended to handle the scenario of the
general preference model with state-of-the-art guarantees under corruption and
privacy. Last but not least, all of our theoretical guarantees enjoy a unified
analysis, building upon a new result on the generalization error bounds of
least-square regression under corruption and privacy constraints, which we
believe is of independent interest to the community.

</details>


### [131] [Dual Natural Gradient Descent for Scalable Training of Physics-Informed Neural Networks](https://arxiv.org/abs/2505.21404)
*Anas Jnini, Flavio Vella*

**主要类别:** cs.LG

**概要:** Dual Natural Gradient Descent (D-NGD) is proposed to perform second-order optimization for PINNs, reducing computational complexity and achieving superior accuracy.


<details>
  <summary>更多</summary>
  
**动机:** Natural-gradient methods can significantly accelerate the training of PINNs, but their high computational complexity limits practical application.

**方法:** The Gauss-Newton step is reformulated in a smaller residual space. D-NGD computes this step, adds geodesic-acceleration correction, and uses either dense direct solver or Nystrom-preconditioned conjugate-gradient solver depending on the size of m.

**结果:** D-NGD scales to networks with 12.8 million parameters, reduces final error $L^2$ by one to three orders of magnitude compared to first-order and quasi-Newton methods, and allows natural-gradient training on a single GPU.

**结论:** D-NGD provides an efficient second-order optimization method for large-scale PINN training.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dual+Natural+Gradient+Descent+for+Scalable+Training+of+Physics-Informed+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21404，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21404&send_immediately=true&force_search=false)

**原文摘要:** Natural-gradient methods markedly accelerate the training of Physics-Informed
Neural Networks (PINNs), yet their Gauss--Newton update must be solved in the
parameter space, incurring a prohibitive $O(n^3)$ time complexity, where $n$ is
the number of network trainable weights. We show that exactly the same step can
instead be formulated in a generally smaller residual space of size $m =
\sum_{\gamma} N_{\gamma} d_{\gamma}$, where each residual class $\gamma$ (e.g.
PDE interior, boundary, initial data) contributes $N_{\gamma}$ collocation
points of output dimension $d_{\gamma}$.
  Building on this insight, we introduce \textit{Dual Natural Gradient Descent}
(D-NGD). D-NGD computes the Gauss--Newton step in residual space, augments it
with a geodesic-acceleration correction at negligible extra cost, and provides
both a dense direct solver for modest $m$ and a Nystrom-preconditioned
conjugate-gradient solver for larger $m$.
  Experimentally, D-NGD scales second-order PINN optimization to networks with
up to 12.8 million parameters, delivers one- to three-order-of-magnitude lower
final error $L^2$ than first-order methods (Adam, SGD) and quasi-Newton
methods, and -- crucially -- enables natural-gradient training of PINNs at this
scale on a single GPU.

</details>


### [132] [When Shift Happens - Confounding Is to Blame](https://arxiv.org/abs/2505.21422)
*Abbavaram Gowtham Reddy, Celia Rubio-Madrigal, Rebekka Burkholz, Krikamol Muandet*

**主要类别:** cs.LG

**概要:** Distribution shifts caused by hidden confounding can make empirical risk minimization (ERM) outperform state-of-the-art OOD methods. Effective OOD generalization requires learning environment-specific relationships and using all available covariates, not just causal ones.


<details>
  <summary>更多</summary>
  
**动机:** To understand why empirical risk minimization (ERM) can rival or outperform state-of-the-art out-of-distribution (OOD) generalization methods and how hidden confounding affects this performance.

**方法:** Using both empirical and theoretical evidence to analyze the impact of hidden confounding on distribution shifts and OOD generalization performance. Proving that under certain conditions, effective generalization requires learning environment-specific relationships instead of relying solely on invariant ones. Demonstrating the benefits of using models augmented with proxies for hidden confounders.

**结果:** Empirical and theoretical findings show that hidden confounding can lead to changes in data distributions that violate assumptions made by existing OOD generalization approaches. Using all available covariates, not just causal ones, and learning environment-specific relationships improve OOD generalization performance.

**结论:** The study provides new theoretical insights and practical guidance for designing robust OOD generalization algorithms and principled covariate selection strategies.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是When+Shift+Happens+-+Confounding+Is+to+Blame，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21422，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21422&send_immediately=true&force_search=false)

**原文摘要:** Distribution shifts introduce uncertainty that undermines the robustness and
generalization capabilities of machine learning models. While conventional
wisdom suggests that learning causal-invariant representations enhances
robustness to such shifts, recent empirical studies present a counterintuitive
finding: (i) empirical risk minimization (ERM) can rival or even outperform
state-of-the-art out-of-distribution (OOD) generalization methods, and (ii) its
OOD generalization performance improves when all available covariates, not just
causal ones, are utilized. Drawing on both empirical and theoretical evidence,
we attribute this phenomenon to hidden confounding. Shifts in hidden
confounding induce changes in data distributions that violate assumptions
commonly made by existing OOD generalization approaches. Under such conditions,
we prove that effective generalization requires learning environment-specific
relationships, rather than relying solely on invariant ones. Furthermore, we
show that models augmented with proxies for hidden confounders can mitigate the
challenges posed by hidden confounding shifts. These findings offer new
theoretical insights and practical guidance for designing robust OOD
generalization algorithms and principled covariate selection strategies.

</details>


### [133] [Attribute-Efficient PAC Learning of Sparse Halfspaces with Constant Malicious Noise Rate](https://arxiv.org/abs/2505.21430)
*Shiwei Zeng, Jie Shen*

**主要类别:** cs.LG

**概要:** 本文研究了在存在恶意噪声的情况下，高效学习稀疏半空间的问题，并提出了一种属性高效的PAC学习算法以及新的梯度分析方法。


<details>
  <summary>更多</summary>
  
**动机:** 属性高效的稀疏半空间学习是机器学习理论中的一个基本问题，近年来，数据污染和对抗性攻击的普遍存在使得设计对噪声鲁棒的高效算法成为核心兴趣。

**方法:** 作者假设底层分布满足特定的浓度条件和边缘条件，并通过简单变体对现有的铰链损失最小化程序进行改进，以实现属性效率。关键贡献包括一种在常数恶意噪声率下工作的属性高效PAC学习算法和一种新的梯度分析方法，该方法仔细处理铰链损失最小化中的稀疏约束。

**结果:** 提出的算法能够在存在恶意噪声的情况下，使用$\text{poly}(s,\log d)$样本学习到一个$s$-sparse半空间。

**结论:** 本文展示了在存在恶意噪声的情况下，通过简单的修改现有铰链损失最小化程序可以实现属性高效的稀疏半空间学习。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Attribute-Efficient+PAC+Learning+of+Sparse+Halfspaces+with+Constant+Malicious+Noise+Rate，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21430，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21430&send_immediately=true&force_search=false)

**原文摘要:** Attribute-efficient learning of sparse halfspaces has been a fundamental
problem in machine learning theory. In recent years, machine learning
algorithms are faced with prevalent data corruptions or even adversarial
attacks. It is of central interest to design efficient algorithms that are
robust to noise corruptions. In this paper, we consider that there exists a
constant amount of malicious noise in the data and the goal is to learn an
underlying $s$-sparse halfspace $w^* \in \mathbb{R}^d$ with $\text{poly}(s,\log
d)$ samples. Specifically, we follow a recent line of works and assume that the
underlying distribution satisfies a certain concentration condition and a
margin condition at the same time. Under such conditions, we show that
attribute-efficiency can be achieved by simple variants to existing hinge loss
minimization programs. Our key contribution includes: 1) an attribute-efficient
PAC learning algorithm that works under constant malicious noise rate; 2) a new
gradient analysis that carefully handles the sparsity constraint in hinge loss
minimization.

</details>


### [134] [Measuring Fine-Grained Relatedness in Multitask Learning via Data Attribution](https://arxiv.org/abs/2505.21438)
*Yiwen Tu, Ziqi Liu, Jiaqi W. Ma, Weijing Tang*

**主要类别:** cs.LG

**概要:** 本文提出了一种名为MultiTask Influence Function (MTIF)的方法，用于在多任务学习（MTL）中衡量任务相关性，并通过实例级别的相关性度量来缓解负迁移。该方法结合数据归因技术，提供了一种细粒度的解决方案，以提高MTL模型的性能。


<details>
  <summary>更多</summary>
  
**动机:** 多任务学习中的任务相关性测量和负迁移缓解仍然是一个关键的开放性挑战。为了解决这一问题，本文将数据归因方法扩展到多任务学习环境中，以更精确地衡量任务之间的相关性。

**方法:** 本文提出了MultiTask Influence Function (MTIF)，这是一种适应于具有硬或软参数共享的多任务学习模型的影响函数方法。它不仅能够衡量整个任务层面的相关性，还能提供实例级别的细粒度相关性度量。基于此，还设计了一种数据选择策略，用以有效缓解负迁移。

**结果:** 广泛的实验表明，MTIF可以高效且准确地近似使用数据子集训练的模型性能。此外，由MTIF支持的数据选择策略一致地提升了多任务学习模型的性能。

**结论:** 本文建立了数据归因与多任务学习之间的新联系，提供了一种高效且细粒度的任务相关性测量方法，从而增强了多任务学习模型的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Measuring+Fine-Grained+Relatedness+in+Multitask+Learning+via+Data+Attribution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21438，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21438&send_immediately=true&force_search=false)

**原文摘要:** Measuring task relatedness and mitigating negative transfer remain a critical
open challenge in Multitask Learning (MTL). This work extends data attribution
-- which quantifies the influence of individual training data points on model
predictions -- to MTL setting for measuring task relatedness. We propose the
MultiTask Influence Function (MTIF), a method that adapts influence functions
to MTL models with hard or soft parameter sharing. Compared to conventional
task relatedness measurements, MTIF provides a fine-grained, instance-level
relatedness measure beyond the entire-task level. This fine-grained relatedness
measure enables a data selection strategy to effectively mitigate negative
transfer in MTL. Through extensive experiments, we demonstrate that the
proposed MTIF efficiently and accurately approximates the performance of models
trained on data subsets. Moreover, the data selection strategy enabled by MTIF
consistently improves model performance in MTL. Our work establishes a novel
connection between data attribution and MTL, offering an efficient and
fine-grained solution for measuring task relatedness and enhancing MTL models.

</details>


### [135] [Can Large Reasoning Models Self-Train?](https://arxiv.org/abs/2505.21444)
*Sheikh Shafayat, Fahim Tajwar, Ruslan Salakhutdinov, Jeff Schneider, Andrea Zanette*

**主要类别:** cs.LG

**概要:** 提出了一种在线自训练强化学习算法，通过模型自我一致性进行正确性信号推断与训练，无需真实监督。该算法在数学推理任务中表现接近有标准答案训练的强化学习方法，但也存在奖励欺骗等局限性。


<details>
  <summary>更多</summary>
  
**动机:** 提升大语言模型性能的方法越来越依赖减少人类监督。强化学习中的自动化验证方法虽为替代方案，但受限于人类设计的验证器的可扩展性问题。因此，自训练（利用模型自身判断作为监督信号）成为一个吸引人的方向。

**方法:** 研究者提出了一种在线自训练强化学习算法，利用模型自身的自一致性来推断正确性信号并进行训练，完全不依赖真实标签的监督。此算法被应用于复杂的数学推理任务中。

**结果:** 实验表明，该算法能够迅速达到与基于黄金标准答案显式训练的强化学习方法相媲美的性能水平。同时，研究也分析了该算法固有的局限性，如自生成代理奖励可能引发奖励欺骗行为（即偏向自信的错误输出）。

**结论:** 研究表明，自监督改进可以在没有外部标签的情况下实现显著的性能提升，同时也揭示了其根本挑战，例如奖励欺骗问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Can+Large+Reasoning+Models+Self-Train%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21444，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21444&send_immediately=true&force_search=false)

**原文摘要:** Scaling the performance of large language models (LLMs) increasingly depends
on methods that reduce reliance on human supervision. Reinforcement learning
from automated verification offers an alternative, but it incurs scalability
limitations due to dependency upon human-designed verifiers. Self-training,
where the model's own judgment provides the supervisory signal, presents a
compelling direction. We propose an online self-training reinforcement learning
algorithm that leverages the model's self-consistency to infer correctness
signals and train without any ground-truth supervision. We apply the algorithm
to challenging mathematical reasoning tasks and show that it quickly reaches
performance levels rivaling reinforcement-learning methods trained explicitly
on gold-standard answers. Additionally, we analyze inherent limitations of the
algorithm, highlighting how the self-generated proxy reward initially
correlated with correctness can incentivize reward hacking, where confidently
incorrect outputs are favored. Our results illustrate how self-supervised
improvement can achieve significant performance gains without external labels,
while also revealing its fundamental challenges.

</details>


### [136] [Designing Cyclic Peptides via Harmonic SDE with Atom-Bond Modeling](https://arxiv.org/abs/2505.21452)
*Xiangxin Zhou, Mingyu Li, Yi Xiao, Jiahan Li, Dongyu Xue, Zaixiang Zheng, Jianzhu Ma, Quanquan Gu*

**主要类别:** cs.LG

**概要:** Cyclic peptides have advantages in pharmaceuticals, but designing them computationally is challenging. This paper introduces CpSDE, a method that includes AtomSDE and ResRouter to generate cyclic peptides by overcoming data limitations and geometric constraints.


<details>
  <summary>更多</summary>
  
**动机:** Cyclic peptides offer benefits like resistance to enzymatic hydrolysis, stability, and affinity, yet computational design methods for diverse types are hindered by challenges such as lack of 3D structural data, geometric constraints, and non-canonical amino acids.

**方法:** CpSDE consists of AtomSDE, a generative structure prediction model based on harmonic SDE, and ResRouter, a residue type predictor. A routed sampling algorithm alternates between these two models to iteratively update sequences and structures.

**结果:** The experimental results show that the cyclic peptides generated by CpSDE possess reliable stability and affinity.

**结论:** CpSDE effectively addresses the challenges in designing cyclic peptides through explicit all-atom and bond modeling, enabling the creation of a wide variety of cyclic peptides.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Designing+Cyclic+Peptides+via+Harmonic+SDE+with+Atom-Bond+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21452，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21452&send_immediately=true&force_search=false)

**原文摘要:** Cyclic peptides offer inherent advantages in pharmaceuticals. For example,
cyclic peptides are more resistant to enzymatic hydrolysis compared to linear
peptides and usually exhibit excellent stability and affinity. Although deep
generative models have achieved great success in linear peptide design, several
challenges prevent the development of computational methods for designing
diverse types of cyclic peptides. These challenges include the scarcity of 3D
structural data on target proteins and associated cyclic peptide ligands, the
geometric constraints that cyclization imposes, and the involvement of
non-canonical amino acids in cyclization. To address the above challenges, we
introduce CpSDE, which consists of two key components: AtomSDE, a generative
structure prediction model based on harmonic SDE, and ResRouter, a residue type
predictor. Utilizing a routed sampling algorithm that alternates between these
two models to iteratively update sequences and structures, CpSDE facilitates
the generation of cyclic peptides. By employing explicit all-atom and bond
modeling, CpSDE overcomes existing data limitations and is proficient in
designing a wide variety of cyclic peptides. Our experimental results
demonstrate that the cyclic peptides designed by our method exhibit reliable
stability and affinity.

</details>


### [137] [Algorithms and SQ Lower Bounds for Robustly Learning Real-valued Multi-index Models](https://arxiv.org/abs/2505.21475)
*Ilias Diakonikolas, Giannis Iakovidis, Daniel M. Kane, Lisheng Ren*

**主要类别:** cs.LG

**概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Algorithms+and+SQ+Lower+Bounds+for+Robustly+Learning+Real-valued+Multi-index+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21475，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21475&send_immediately=true&force_search=false)

**原文摘要:** We study the complexity of learning real-valued Multi-Index Models (MIMs)
under the Gaussian distribution. A $K$-MIM is a function $f:\mathbb{R}^d\to
\mathbb{R}$ that depends only on the projection of its input onto a
$K$-dimensional subspace. We give a general algorithm for PAC learning a broad
class of MIMs with respect to the square loss, even in the presence of
adversarial label noise. Moreover, we establish a nearly matching Statistical
Query (SQ) lower bound, providing evidence that the complexity of our algorithm
is qualitatively optimal as a function of the dimension. Specifically, we
consider the class of bounded variation MIMs with the property that degree at
most $m$ distinguishing moments exist with respect to projections onto any
subspace. In the presence of adversarial label noise, the complexity of our
learning algorithm is $d^{O(m)}2^{\mathrm{poly}(K/\epsilon)}$. For the
realizable and independent noise settings, our algorithm incurs complexity
$d^{O(m)}2^{\mathrm{poly}(K)}(1/\epsilon)^{O(K)}$. To complement our upper
bound, we show that if for some subspace degree-$m$ distinguishing moments do
not exist, then any SQ learner for the corresponding class of MIMs requires
complexity $d^{\Omega(m)}$. As an application, we give the first efficient
learner for the class of positive-homogeneous $L$-Lipschitz $K$-MIMs. The
resulting algorithm has complexity $\mathrm{poly}(d)
2^{\mathrm{poly}(KL/\epsilon)}$. This gives a new PAC learning algorithm for
Lipschitz homogeneous ReLU networks with complexity independent of the network
size, removing the exponential dependence incurred in prior work.

</details>


### [138] [Hardware-Efficient Attention for Fast Decoding](https://arxiv.org/abs/2505.21487)
*Ted Zadouri, Hubert Strauss, Tri Dao*

**主要类别:** cs.LG

**概要:** 本论文重新设计了注意力机制，以提高硬件效率并保持模型质量。提出了Grouped-Tied Attention (GTA) 和 Grouped Latent Attention (GLA)，分别在减少内存传输和加速解码方面表现出色。实验表明，GTA在使用约一半KV缓存的情况下与GQA质量相当，而GLA比FlashMLA快2倍，并且在在线服务基准测试中减少了端到端延迟，提高了吞吐量。


<details>
  <summary>更多</summary>
  
**动机:** 当前的LLM解码在处理大数据批次和长上下文时受限于从高带宽内存加载键值(KV)缓存的问题，这增加了每令牌的延迟，并且由于解码的顺序性质限制了并行性。作者分析了算术强度、并行化和模型质量之间的相互作用，并质疑当前架构是否充分利用了现代硬件。

**方法:** 论文提出了两种方法：1. Grouped-Tied Attention (GTA)，通过组合和重用键和值状态来减少内存传输，同时不损害模型质量；2. Grouped Latent Attention (GLA)，一种与低级优化配对的并行友好的潜在注意力机制，可以在保持高模型质量的同时实现快速解码。

**结果:** 实验结果表明：GTA在使用大约一半KV缓存的情况下与Grouped-Query Attention (GQA)的质量相匹配；GLA与Multi-head Latent Attention (MLA)质量相当，但更容易分片。优化后的GLA内核在推测解码设置下比FlashMLA快2倍（当查询长度超过一）。此外，通过每个设备获取更小的KV缓存，GLA在在线服务基准测试中将端到端延迟减少了多达2倍，并提高了吞吐量。

**结论:** 通过重新设计注意力机制，可以显著提高硬件效率而不牺牲并行可扩展性或模型质量。GTA和GLA为大型语言模型的高效解码提供了新的解决方案，尤其适用于在线服务场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Hardware-Efficient+Attention+for+Fast+Decoding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21487，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21487&send_immediately=true&force_search=false)

**原文摘要:** LLM decoding is bottlenecked for large batches and long contexts by loading
the key-value (KV) cache from high-bandwidth memory, which inflates per-token
latency, while the sequential nature of decoding limits parallelism. We analyze
the interplay among arithmetic intensity, parallelization, and model quality
and question whether current architectures fully exploit modern hardware. This
work redesigns attention to perform more computation per byte loaded from
memory to maximize hardware efficiency without trading off parallel
scalability. We first propose Grouped-Tied Attention (GTA), a simple variant
that combines and reuses key and value states, reducing memory transfers
without compromising model quality. We then introduce Grouped Latent Attention
(GLA), a parallel-friendly latent attention paired with low-level optimizations
for fast decoding while maintaining high model quality. Experiments show that
GTA matches Grouped-Query Attention (GQA) quality while using roughly half the
KV cache and that GLA matches Multi-head Latent Attention (MLA) and is easier
to shard. Our optimized GLA kernel is up to 2$\times$ faster than FlashMLA, for
example, in a speculative decoding setting when the query length exceeds one.
Furthermore, by fetching a smaller KV cache per device, GLA reduces end-to-end
latency and increases throughput in online serving benchmarks by up to
2$\times$.

</details>


### [139] [Reinforcing General Reasoning without Verifiers](https://arxiv.org/abs/2505.21493)
*Xiangxin Zhou, Zichen Liu, Anya Sims, Haonan Wang, Tianyu Pang, Chongxuan Li, Liang Wang, Min Lin, Chao Du*

**主要类别:** cs.LG

**概要:** 提出了一种无需验证器的方法（VeriFree），通过强化学习直接最大化生成参考答案的概率，适用于更广泛的推理领域。相比基于验证器的方法，VeriFree在多项评估中表现相当甚至更好，同时降低了计算需求。


<details>
  <summary>更多</summary>
  
**动机:** 当前基于DeepSeek-R1-Zero风格的强化学习方法在代码和数学推理方面取得了显著进展，但其局限在于仅适用于可通过规则验证答案的任务，难以扩展到化学、医疗等实际领域。现有的解决方案依赖额外的大型语言模型作为验证器，存在如奖励欺骗等问题。

**方法:** 提出了一种名为VeriFree的无验证器方法，该方法绕过答案验证，直接通过强化学习最大化生成参考答案的概率。此方法将策略与隐式验证器集成到一个统一模型中，并从变分优化的角度进行了阐释。

**结果:** 在MMLU-Pro、GPQA、SuperGPQA及数学相关基准测试中，VeriFree的表现与基于验证器的方法相当甚至更好，同时具备显著的实际优势和较低的计算需求。

**结论:** VeriFree为扩展强化学习训练至一般推理领域提供了一种有效且高效的解决方案，具有广泛的应用前景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reinforcing+General+Reasoning+without+Verifiers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21493，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21493&send_immediately=true&force_search=false)

**原文摘要:** The recent paradigm shift towards training large language models (LLMs) using
DeepSeek-R1-Zero-style reinforcement learning (RL) on verifiable rewards has
led to impressive advancements in code and mathematical reasoning. However,
this methodology is limited to tasks where rule-based answer verification is
possible and does not naturally extend to real-world domains such as chemistry,
healthcare, engineering, law, biology, business, and economics. Current
practical workarounds use an additional LLM as a model-based verifier; however,
this introduces issues such as reliance on a strong verifier LLM,
susceptibility to reward hacking, and the practical burden of maintaining the
verifier model in memory during training. To address this and extend
DeepSeek-R1-Zero-style training to general reasoning domains, we propose a
verifier-free method (VeriFree) that bypasses answer verification and instead
uses RL to directly maximize the probability of generating the reference
answer. We compare VeriFree with verifier-based methods and demonstrate that,
in addition to its significant practical benefits and reduced compute
requirements, VeriFree matches and even surpasses verifier-based methods on
extensive evaluations across MMLU-Pro, GPQA, SuperGPQA, and math-related
benchmarks. Moreover, we provide insights into this method from multiple
perspectives: as an elegant integration of training both the policy and
implicit verifier in a unified model, and as a variational optimization
approach. Code is available at https://github.com/sail-sg/VeriFree.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [140] [Multi-Modal Artificial Intelligence of Embryo Grading and Pregnancy Prediction in Assisted Reproductive Technology: A Review](https://arxiv.org/abs/2505.20306)
*Xueqiang Ouyang, Jia Wei*

**主要类别:** cs.AI

**概要:** 辅助生殖技术中，人工智能多模态数据的应用进展及挑战


<details>
  <summary>更多</summary>
  
**动机:** 不孕症作为全球性疾病，影响人类。尽管体外受精-胚胎移植技术有所发展，但妊娠成功率仍面临诸多挑战，如胚胎分级的主观性和多模态数据整合效率低。因此，引入基于人工智能的技术显得尤为重要。

**方法:** 从新视角回顾了基于不同数据模态（包括静态图像、延时视频和结构化表格数据）的多模态人工智能在胚胎分级和妊娠预测中的应用进展，并讨论当前研究的主要挑战。

**结果:** 阐明了多模态人工智能在辅助生殖领域的应用进展，并指出了诸如多模态信息融合复杂性和数据稀缺性等主要挑战。

**结论:** 多模态人工智能在提高胚胎分级客观性和妊娠预测准确性方面具有巨大潜力，但需要克服多模态信息融合复杂性和数据稀缺性等问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Modal+Artificial+Intelligence+of+Embryo+Grading+and+Pregnancy+Prediction+in+Assisted+Reproductive+Technology%3A+A+Review，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20306，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20306&send_immediately=true&force_search=false)

**原文摘要:** As a global disease, infertility has always affected human beings. The
development of assisted reproductive technology can effectively solve this
disease. However, the traditional in vitro fertilization-embryo transfer
technology still faces many challenges in improving the success rate of
pregnancy, such as the subjectivity of embryo grading and the inefficiency of
integrating multi-modal data. Therefore, the introduction of artificial
intelligence-based technologies is particularly crucial. This article reviews
the application progress of multi-modal artificial intelligence in embryo
grading and pregnancy prediction based on different data modalities (including
static images, time-lapse videos and structured table data) from a new
perspective, and discusses the main challenges in current research, such as the
complexity of multi-modal information fusion and data scarcity.

</details>


### [141] [Manalyzer: End-to-end Automated Meta-analysis with Multi-agent System](https://arxiv.org/abs/2505.20310)
*Wanghan Xu, Wenlong Zhang, Fenghua Ling, Ben Fei, Yusong Hu, Fangxuan Ren, Jintai Lin, Wanli Ouyang, Lei Bai*

**主要类别:** cs.AI

**概要:** 本研究提出了一种多代理系统Manalyzer，通过工具调用实现端到端自动化的元分析，解决了传统方法和LLM方法中的幻觉问题，并在新构建的基准数据集上进行了性能评估。


<details>
  <summary>更多</summary>
  
**动机:** 元分析是一种综合现有研究数据得出全面结论的研究方法。尽管传统元分析存在耗时费力的问题，而基于LLM的方法虽然能加速某些阶段，但仍然面临幻觉等重大挑战。因此，需要一种更高效的解决方案来克服这些限制。

**方法:** 研究人员设计了一个名为Manalyzer的多代理系统，该系统通过工具调用实现了端到端自动化的元分析。Manalyzer采用混合审查、分层提取、自我证明和反馈检查策略，显著减轻了论文筛选和数据提取中的幻觉问题。此外，为了评估元分析性能，研究者构建了一个包含729篇论文的新基准数据集，涵盖文本、图像和表格三种模态，超过10,000个数据点。

**结果:** 大量的实验结果表明，与LLM基线相比，Manalyzer在多模态元分析任务中表现出显著的性能提升。

**结论:** Manalyzer作为一种创新的多代理系统，在自动化元分析方面展现了优越性，有效缓解了LLM方法中的幻觉问题，并为元分析提供了新的性能评估基准。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Manalyzer%3A+End-to-end+Automated+Meta-analysis+with+Multi-agent+System，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20310，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20310&send_immediately=true&force_search=false)

**原文摘要:** Meta-analysis is a systematic research methodology that synthesizes data from
multiple existing studies to derive comprehensive conclusions. This approach
not only mitigates limitations inherent in individual studies but also
facilitates novel discoveries through integrated data analysis. Traditional
meta-analysis involves a complex multi-stage pipeline including literature
retrieval, paper screening, and data extraction, which demands substantial
human effort and time. However, while LLM-based methods can accelerate certain
stages, they still face significant challenges, such as hallucinations in paper
screening and data extraction. In this paper, we propose a multi-agent system,
Manalyzer, which achieves end-to-end automated meta-analysis through tool
calls. The hybrid review, hierarchical extraction, self-proving, and feedback
checking strategies implemented in Manalyzer significantly alleviate these two
hallucinations. To comprehensively evaluate the performance of meta-analysis,
we construct a new benchmark comprising 729 papers across 3 domains,
encompassing text, image, and table modalities, with over 10,000 data points.
Extensive experiments demonstrate that Manalyzer achieves significant
performance improvements over the LLM baseline in multi meta-analysis tasks.
Project page: https://black-yt.github.io/meta-analysis-page/ .

</details>


### [142] [Reasoning in Neurosymbolic AI](https://arxiv.org/abs/2505.20313)
*Son Tran, Edjard Mota, Artur d'Avila Garcez*

**主要类别:** cs.AI

**概要:** 论文提出了一种基于能量的神经典逻辑AI系统，能表达和推导命题逻辑公式，结合数据学习与逻辑推理，并通过实验验证了其与受限玻尔兹曼机的能量最小化之间的关系。研究强调了神经符号AI在解决大型语言模型的数据效率、公平性和安全性问题上的潜力，以及在AI正式推理和责任中的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 当前AI领域主要由大型语言模型（LLMs）主导，但这些模型存在数据效率低、公平性和安全性等问题。因此，需要一种新的方法来整合学习和推理能力，以克服这些挑战。

**方法:** 描述了一个简单的基于能量的神经符号AI系统，该系统可以正式表示和推导任何命题逻辑公式。使用受限玻尔兹曼机（RBM）进行逻辑推理和能量最小化的对应关系评估，并比较了数据和知识的学习效果。

**结果:** 实验结果表明，神经符号AI系统能够有效地结合数据学习和逻辑推理，且在某些任务上优于纯符号、纯神经和传统神经符号系统。

**结论:** 神经符号AI在解决深度学习可靠性问题方面具有重要意义，并应在更广泛的正式推理和AI责任框架中得到重视。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reasoning+in+Neurosymbolic+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20313，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20313&send_immediately=true&force_search=false)

**原文摘要:** Knowledge representation and reasoning in neural networks have been a
long-standing endeavor which has attracted much attention recently. The
principled integration of reasoning and learning in neural networks is a main
objective of the area of neurosymbolic Artificial Intelligence (AI). In this
chapter, a simple energy-based neurosymbolic AI system is described that can
represent and reason formally about any propositional logic formula. This
creates a powerful combination of learning from data and knowledge and logical
reasoning. We start by positioning neurosymbolic AI in the context of the
current AI landscape that is unsurprisingly dominated by Large Language Models
(LLMs). We identify important challenges of data efficiency, fairness and
safety of LLMs that might be addressed by neurosymbolic reasoning systems with
formal reasoning capabilities. We then discuss the representation of logic by
the specific energy-based system, including illustrative examples and empirical
evaluation of the correspondence between logical reasoning and energy
minimization using Restricted Boltzmann Machines (RBM). Learning from data and
knowledge is also evaluated empirically and compared with a symbolic, neural
and a neurosymbolic system. Results reported in this chapter in an accessible
way are expected to reignite the research on the use of neural networks as
massively-parallel models for logical reasoning and promote the principled
integration of reasoning and learning in deep networks. We conclude the chapter
with a discussion of the importance of positioning neurosymbolic AI within a
broader framework of formal reasoning and accountability in AI, discussing the
challenges for neurosynbolic AI to tackle the various known problems of
reliability of deep learning.

</details>


### [143] [Reinforcement Speculative Decoding for Fast Ranking](https://arxiv.org/abs/2505.20316)
*Yingpeng Du, Tianjun Wei, Zhu Sun, Jie Zhang*

**主要类别:** cs.AI

**概要:** 提出了一种强化推测解码方法，用于加速LLM在信息检索和推荐系统中的排序推理。该方法通过自上而下的解码范式和策略优化，在有限预算下迭代修改排序序列，并充分利用列表级排名知识，实验表明其在IR和RS任务中有效。


<details>
  <summary>更多</summary>
  
**动机:** 现有的自动回归解码方法在处理尾部位置时性能下降严重，而推测解码方法虽然能缓解此问题，但在排序系统中面临严格的延迟约束和知识利用不足的挑战。

**方法:** 提出一种强化推测解码方法，采用自上而下的解码范式，设计专门针对排序的策略优化，通过强化学习迭代修改排序序列，并充分利用各轮次中LLM验证的列表级排名知识以增强代理的修改策略。

**结果:** 理论分析证明了所提方法的鲁棒性和优势，实验结果表明该方法在信息检索和推荐系统任务中具有有效性。

**结论:** 所提出的强化推测解码方法能够满足排序系统的延迟要求，并在受限预算下有效提升排序性能，为快速LLM排序推理提供了新思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reinforcement+Speculative+Decoding+for+Fast+Ranking，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20316，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20316&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have been widely adopted in ranking systems such
as information retrieval (IR) systems and recommender systems (RSs). To
alleviate the latency of auto-regressive decoding, some studies explore the
single (first) token decoding for ranking approximation, but they suffer from
severe degradation in tail positions. Although speculative decoding (SD)
methods can be a remedy with verification at different positions, they face
challenges in ranking systems due to their left-to-right decoding paradigm.
Firstly, ranking systems require strict latency constraints, but verification
rounds in SD methods remain agnostic; Secondly, SD methods usually discard
listwise ranking knowledge about unaccepted items in previous rounds, hindering
future multi-token prediction, especially when candidate tokens are the
unaccepted items. In this paper, we propose a Reinforcement Speculative
Decoding method for fast ranking inference of LLMs. To meet the ranking
systems' latency requirement, we propose an up-to-down decoding paradigm that
employs an agent to iteratively modify the ranking sequence under a constrained
budget. Specifically, we design a ranking-tailored policy optimization,
actively exploring optimal multi-round ranking modification policy verified by
LLMs via reinforcement learning (RL). To better approximate the target LLM
under the constrained budget, we trigger the agent fully utilizing the listwise
ranking knowledge about all items verified by LLMs across different rounds in
RL, enhancing the modification policy of the agent. More importantly, we
demonstrate the theoretical robustness and advantages of our paradigm and
implementation. Experiments on both IR and RS tasks show the effectiveness of
our proposed method.

</details>


### [144] [Challenges for artificial cognitive systems](https://arxiv.org/abs/2505.20339)
*Antoni Gomila, Vincent C. Müller*

**主要类别:** cs.AI

**概要:** 这篇论文的主要目标是提出人工认知系统面临的挑战，这些挑战被用来定义该领域的进步。挑战基于对认知系统的定义：能够从经验中学习，并以灵活的方式运用其获得的知识（包括陈述性和实践性知识）来实现自身目标的系统。


<details>
  <summary>更多</summary>
  
**动机:** 认知系统研究需要明确的问题或挑战来界定进展。目前缺乏这样的指导性问题，因此需要填补这一空白。

**方法:** 通过定义认知系统为一种可以从经验中学习，并使用其获得的知识（声明和实践层面）以灵活方式达成自身目标的系统，从而提出人工认知系统的挑战。

**结果:** 提出了针对人工认知系统的具体挑战，明确了研究方向和进步的标准。

**结论:** 认知系统的挑战不仅限于未来的预测，而是作为指南，明确目标并界定何为进步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Challenges+for+artificial+cognitive+systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20339，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20339&send_immediately=true&force_search=false)

**原文摘要:** The declared goal of this paper is to fill this gap: "... cognitive systems
research needs questions or challenges that define progress. The challenges are
not (yet more) predictions of the future, but a guideline to what are the aims
and what would constitute progress." -- the quotation being from the project
description of EUCogII, the project for the European Network for Cognitive
Systems within which this formulation of the 'challenges' was originally
developed (http://www.eucognition.org). So, we stick out our neck and formulate
the challenges for artificial cognitive systems. These challenges are
articulated in terms of a definition of what a cognitive system is: a system
that learns from experience and uses its acquired knowledge (both declarative
and practical) in a flexible manner to achieve its own goals.

</details>


### [145] [Machine Theory of Mind and the Structure of Human Values](https://arxiv.org/abs/2505.20342)
*Paul de Font-Reaulx*

**主要类别:** cs.AI

**概要:** 这篇论文提出，人类价值观具有生成性理性结构，这使得通过贝叶斯心智理论模型可以从行为和其他价值观推断人类价值，解决价值泛化问题。发展生成性价值-价值推理是实现可扩展机器心智理论的关键组件。


<details>
  <summary>更多</summary>
  
**动机:** 目前的价值学习方法主要从人类行为中推断价值观，但人类关心的远超其行动所能展示的范围，AI需要从有限样本中预测复杂的人类价值观。

**方法:** 利用贝叶斯心智理论模型，不仅从行为推断人类价值观，还从其他价值观进行推断，强调人类价值观的生成性理性结构。

**结果:** 能够通过生成性价值-价值推理解决价值泛化问题，从而更全面地理解人类价值观。

**结论:** 开发生成性价值-价值推理是实现可扩展机器心智理论的重要组成部分。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Machine+Theory+of+Mind+and+the+Structure+of+Human+Values，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20342，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20342&send_immediately=true&force_search=false)

**原文摘要:** Value learning is a crucial aspect of safe and ethical AI. This is primarily
pursued by methods inferring human values from behaviour. However, humans care
about much more than we are able to demonstrate through our actions.
Consequently, an AI must predict the rest of our seemingly complex values from
a limited sample. I call this the value generalization problem. In this paper,
I argue that human values have a generative rational structure and that this
allows us to solve the value generalization problem. In particular, we can use
Bayesian Theory of Mind models to infer human values not only from behaviour,
but also from other values. This has been obscured by the widespread use of
simple utility functions to represent human values. I conclude that developing
generative value-to-value inference is a crucial component of achieving a
scalable machine theory of mind.

</details>


### [146] [SCAR: Shapley Credit Assignment for More Efficient RLHF](https://arxiv.org/abs/2505.20417)
*Meng Cao, Shuyuan Zhang, Xiao-Wen Chang, Doina Precup*

**主要类别:** cs.AI

**概要:** 提出了一种名为SCAR的新方法，利用Shapley值分配奖励给序列中的各个token或文本片段，从而生成密集的奖励信号，无需额外训练辅助模型或依赖精细的人工标注。理论上证明SCAR保留了原始最优策略，实验证明其在多种任务中收敛更快、最终奖励分数更高。


<details>
  <summary>更多</summary>
  
**动机:** 强化学习从人类反馈（RLHF）技术虽然广泛用于使大语言模型与人类偏好对齐，但存在奖励信号稀疏的问题，难以有效进行信用分配。现有的奖励模型通常只为整个生成序列提供单一标量分数，无法明确哪些token或片段决策导致了结果。

**方法:** 提出了基于Shapley值的合作博弈理论方法——Shapley Credit Assignment Rewards (SCAR)。该方法根据各token或文本片段的边际贡献，将序列级别的总奖励分配到它们上，生成密集的奖励信号。此方法无需训练辅助批评模型或使用精细的人类注释。

**结果:** 理论上证明SCAR保留了原始最优策略；实验表明，在包括情感控制、文本摘要和指令调整等多样化任务中，SCAR比标准RLHF和基于注意力的密集奖励基线方法收敛得更快，并且最终奖励分数更高。

**结论:** SCAR为RLHF中的信用分配提供了更有效且理论依据更强的方法，提高了LLM与人类偏好的对齐效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SCAR%3A+Shapley+Credit+Assignment+for+More+Efficient+RLHF，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20417，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20417&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement Learning from Human Feedback (RLHF) is a widely used technique
for aligning Large Language Models (LLMs) with human preferences, yet it often
suffers from sparse reward signals, making effective credit assignment
challenging. In typical setups, the reward model provides a single scalar score
for an entire generated sequence, offering little insight into which token or
span-level decisions were responsible for the outcome. To address this, we
propose Shapley Credit Assignment Rewards (SCAR), a novel method that leverages
Shapley values in cooperative game theory. SCAR distributes the total
sequence-level reward among constituent tokens or text spans based on their
principled marginal contributions. This creates dense reward signals,
crucially, without necessitating the training of auxiliary critique models or
recourse to fine-grained human annotations at intermediate generation stages.
Unlike prior dense reward methods, SCAR offers a game-theoretic foundation for
fair credit attribution. Theoretically, we demonstrate that SCAR preserves the
original optimal policy, and empirically, across diverse tasks including
sentiment control, text summarization, and instruction tuning, we show that
SCAR converges significantly faster and achieves higher final reward scores
compared to standard RLHF and attention-based dense reward baselines. Our
findings suggest that SCAR provides a more effective and theoretically sound
method for credit assignment in RLHF, leading to more efficient alignment of
LLMs.

</details>


### [147] [Reconceptualizing Smart Microscopy: From Data Collection to Knowledge Creation by Multi-Agent Integration](https://arxiv.org/abs/2505.20466)
*P. S. Kesavan, Pontus Nordenfelt*

**主要类别:** cs.AI

**概要:** 智能显微技术通过结合自动化、计算能力和人工智能，不仅实现了主动实验控制和适应性决策，还提出了一个重新定义其为科学探究伙伴的理论框架。该框架以'认知-经验鸿沟'为核心概念，并提出六大核心设计原则，指导多代理架构的设计，从而超越自动化，积极支持假设生成、洞见发现和理论发展。


<details>
  <summary>更多</summary>
  
**动机:** 生物成像领域从被动观察工具转向主动科学探究合作者的需求推动了这一研究，旨在利用智能显微技术弥合可观测与需理解之间的差距。

**方法:** 提出以'认知-经验鸿沟'为核心的理论框架，并建立六大核心设计原则：认知-经验意识、层次化上下文整合、从检测到感知的演变、适应性测量框架、叙述综合能力和跨情境推理。

**结果:** 这些原则共同指导了一个多代理架构的设计，该架构能够将经验观察与科学理解目标对齐，支持假设生成、洞见发现和理论发展。

**结论:** 智能显微技术通过提出的理论框架和多代理架构，重新定义了科学仪器在知识创造过程中的角色，标志着生物成像领域的重要转变。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reconceptualizing+Smart+Microscopy%3A+From+Data+Collection+to+Knowledge+Creation+by+Multi-Agent+Integration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20466，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20466&send_immediately=true&force_search=false)

**原文摘要:** Smart microscopy represents a paradigm shift in biological imaging, moving
from passive observation tools to active collaborators in scientific inquiry.
Enabled by advances in automation, computational power, and artificial
intelligence, these systems are now capable of adaptive decision-making and
real-time experimental control. Here, we introduce a theoretical framework that
reconceptualizes smart microscopy as a partner in scientific investigation.
Central to our framework is the concept of the 'epistemic-empirical divide' in
cellular investigation-the gap between what is observable (empirical domain)
and what must be understood (epistemic domain). We propose six core design
principles: epistemic-empirical awareness, hierarchical context integration, an
evolution from detection to perception, adaptive measurement frameworks,
narrative synthesis capabilities, and cross-contextual reasoning. Together,
these principles guide a multi-agent architecture designed to align empirical
observation with the goals of scientific understanding. Our framework provides
a roadmap for building microscopy systems that go beyond automation to actively
support hypothesis generation, insight discovery, and theory development,
redefining the role of scientific instruments in the process of knowledge
creation.

</details>


### [148] [Project Riley: Multimodal Multi-Agent LLM Collaboration with Emotional Reasoning and Voting](https://arxiv.org/abs/2505.20521)
*Ana Rita Ortigoso, Gabriel Vieira, Daniel Fuentes, Luis Frazão, Nuno Costa, António Pereira*

**主要类别:** cs.AI

**概要:** 本论文介绍了Project Riley，这是一个新颖的多模态、多模型对话AI架构，旨在模拟受情感状态影响的推理。系统包含五个情感代理（Joy, Sadness, Fear, Anger, Disgust），通过多轮结构化对话生成、批评和迭代改进响应。最终推理机制将这些代理的贡献综合成连贯输出，反映主导情感或整合多种视角。架构结合了文本和视觉大语言模型（LLMs）以及高级推理和自我改进过程。一个功能原型在离线环境中本地部署，优化了情感表达和计算效率。从该原型中还衍生出了另一个名为Armando的原型，用于紧急情况，通过检索增强生成（RAG）和累积上下文跟踪提供情感校准且事实准确的信息。Project Riley原型通过用户测试进行评估，参与者与聊天机器人互动并完成评估三个维度的结构化问卷：情感适宜性、清晰度和实用性、自然度和人性化。结果表明，在结构化场景中表现强劲，特别是在情感对齐和沟通清晰度方面。


<details>
  <summary>更多</summary>
  
**动机:** 受到皮克斯电影《头脑特工队》的启发，研究者希望开发一种能够模拟人类受情感影响推理过程的对话AI系统，提升机器在情感理解和表达方面的能力。

**方法:** 设计了一个包含五个情感代理（Joy, Sadness, Fear, Anger, Disgust）的多模态、多模型对话AI架构。这些代理通过多轮对话生成、批评和迭代改进响应。最终推理机制将这些代理的贡献综合成连贯输出。此外，原型还集成了文本和视觉大语言模型（LLMs）、高级推理和自我改进过程，并在离线环境中进行了优化。

**结果:** 用户测试结果显示，该系统在结构化场景中表现出色，尤其是在情感对齐和沟通清晰度方面。

**结论:** Project Riley展示了多模态、多模型对话AI架构在模拟受情感影响推理方面的潜力，未来可以进一步优化其性能并在更多实际场景中应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Project+Riley%3A+Multimodal+Multi-Agent+LLM+Collaboration+with+Emotional+Reasoning+and+Voting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20521，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20521&send_immediately=true&force_search=false)

**原文摘要:** This paper presents Project Riley, a novel multimodal and multi-model
conversational AI architecture oriented towards the simulation of reasoning
influenced by emotional states. Drawing inspiration from Pixar's Inside Out,
the system comprises five distinct emotional agents - Joy, Sadness, Fear,
Anger, and Disgust - that engage in structured multi-round dialogues to
generate, criticise, and iteratively refine responses. A final reasoning
mechanism synthesises the contributions of these agents into a coherent output
that either reflects the dominant emotion or integrates multiple perspectives.
The architecture incorporates both textual and visual large language models
(LLMs), alongside advanced reasoning and self-refinement processes. A
functional prototype was deployed locally in an offline environment, optimised
for emotional expressiveness and computational efficiency. From this initial
prototype, another one emerged, called Armando, which was developed for use in
emergency contexts, delivering emotionally calibrated and factually accurate
information through the integration of Retrieval-Augmented Generation (RAG) and
cumulative context tracking. The Project Riley prototype was evaluated through
user testing, in which participants interacted with the chatbot and completed a
structured questionnaire assessing three dimensions: Emotional Appropriateness,
Clarity and Utility, and Naturalness and Human-likeness. The results indicate
strong performance in structured scenarios, particularly with respect to
emotional alignment and communicative clarity.

</details>


### [149] [Scaling over Scaling: Exploring Test-Time Scaling Pareto in Large Reasoning Models](https://arxiv.org/abs/2505.20522)
*Jian Wang, Boyan Zhu, Chak Tou Leong, Yongqi Li, Wenjie Li*

**主要类别:** cs.AI

**概要:** 大型推理模型（LRMs）通过内部测试时间扩展增强了推理性能。本文研究了测试时间扩展的Pareto边界，并引入了测试时间扩展性能模型（TTSPM）。通过理论分析和平行、序列扩展两种基本范式，推导出两种策略的饱和点和阈值。尽管机制不同，但两种范式在上限上收敛到统一的数学结构。实验验证了这些理论发现的实际效用，为测试时间资源分配提供了实用界限。


<details>
  <summary>更多</summary>
  
**动机:** 大型推理模型已经展示了通过内部测试时间扩展来增强推理性能的能力。进一步扩展测试时间计算可能解锁更强的推理能力，但系统地理解实际限制和实现最佳资源分配变得至关重要。

**方法:** 研究测试时间扩展的Pareto边界，引入TTSPM模型。从概率建模的角度分析平行扩展和序列扩展两个基本范式，推导出两种策略的饱和点和阈值。

**结果:** 理论分析表明，尽管平行扩展和序列扩展机制不同，但它们在上限上收敛到统一的数学结构。实验证实在多个推理基准上验证了这些理论发现的实际效用。

**结论:** 这项工作提供了对测试时间扩展的成本效益权衡的见解，指导了更高效的推理策略的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scaling+over+Scaling%3A+Exploring+Test-Time+Scaling+Pareto+in+Large+Reasoning+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20522，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20522&send_immediately=true&force_search=false)

**原文摘要:** Large reasoning models (LRMs) have exhibited the capacity of enhancing
reasoning performance via internal test-time scaling. Building upon this, a
promising direction is to further scale test-time compute to unlock even
greater reasoning capabilities. However, as we push these scaling boundaries,
systematically understanding the practical limits and achieving optimal
resource allocation becomes a critical challenge. In this paper, we investigate
the scaling Pareto of test-time scaling and introduce the Test-Time Scaling
Performance Model (TTSPM). We theoretically analyze two fundamental paradigms
for such extended scaling, parallel scaling and sequential scaling, from a
probabilistic modeling perspective. Our primary contribution is the derivation
of the saturation point on the scaling budget for both strategies, identifying
thresholds beyond which additional computation yields diminishing returns.
Remarkably, despite their distinct mechanisms, both paradigms converge to a
unified mathematical structure in their upper bounds. We empirically validate
our theoretical findings on challenging reasoning benchmarks, including AIME,
MATH-500, and GPQA, demonstrating the practical utility of these bounds for
test-time resource allocation. We hope that this work provides insights into
the cost-benefit trade-offs of test-time scaling, guiding the development of
more resource-efficient inference strategies for large reasoning models.

</details>


### [150] [Comparisons between a Large Language Model-based Real-Time Compound Diagnostic Medical AI Interface and Physicians for Common Internal Medicine Cases using Simulated Patients](https://arxiv.org/abs/2505.20609)
*Hyungjun Park, Chang-Yun Woo, Seungjo Lim, Seunghwan Lim, Keunho Kwak, Ju Young Jeong, Chong Hyun Suh*

**主要类别:** cs.AI

**概要:** 开发并测试了一种基于LLM的实时复合诊断医疗AI接口，其在常见内科病例诊断中的准确性和患者满意度与医生相当，但耗时更少且成本更低。


<details>
  <summary>更多</summary>
  
**动机:** 为了开发一种基于LLM的实时复合诊断医疗AI接口，并通过基于USMLE Step 2 Clinical Skill风格考试的临床试验，比较该AI接口与医生在常见内科病例诊断中的表现。

**方法:** 进行了一项非随机临床试验，招募了一名全科医生、两名内科住院医师和五名模拟患者。根据实际患者的病历创建了10个具有代表性的内科病例，并评估首次鉴别诊断的准确性、重复性、时间和成本等指标。

**结果:** 医生的首次鉴别诊断准确率为50%-70%，而AI接口为80%；首次和第二次鉴别诊断的准确率，医生为70%-90%，AI接口则达到100%。AI接口比医生平均节省44.6%的时间和98.1%的成本，患者满意度评分也接近医生水平。

**结论:** 基于LLM的实时复合诊断医疗AI接口展现出与医生相当的诊断准确性和患者满意度，同时耗时更少且成本更低，显示出辅助初级诊疗咨询的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Comparisons+between+a+Large+Language+Model-based+Real-Time+Compound+Diagnostic+Medical+AI+Interface+and+Physicians+for+Common+Internal+Medicine+Cases+using+Simulated+Patients，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20609，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20609&send_immediately=true&force_search=false)

**原文摘要:** Objective To develop an LLM based realtime compound diagnostic medical AI
interface and performed a clinical trial comparing this interface and
physicians for common internal medicine cases based on the United States
Medical License Exam (USMLE) Step 2 Clinical Skill (CS) style exams. Methods A
nonrandomized clinical trial was conducted on August 20, 2024. We recruited one
general physician, two internal medicine residents (2nd and 3rd year), and five
simulated patients. The clinical vignettes were adapted from the USMLE Step 2
CS style exams. We developed 10 representative internal medicine cases based on
actual patients and included information available on initial diagnostic
evaluation. Primary outcome was the accuracy of the first differential
diagnosis. Repeatability was evaluated based on the proportion of agreement.
Results The accuracy of the physicians' first differential diagnosis ranged
from 50% to 70%, whereas the realtime compound diagnostic medical AI interface
achieved an accuracy of 80%. The proportion of agreement for the first
differential diagnosis was 0.7. The accuracy of the first and second
differential diagnoses ranged from 70% to 90% for physicians, whereas the AI
interface achieved an accuracy rate of 100%. The average time for the AI
interface (557 sec) was 44.6% shorter than that of the physicians (1006 sec).
The AI interface ($0.08) also reduced costs by 98.1% compared to the
physicians' average ($4.2). Patient satisfaction scores ranged from 4.2 to 4.3
for care by physicians and were 3.9 for the AI interface Conclusion An LLM
based realtime compound diagnostic medical AI interface demonstrated diagnostic
accuracy and patient satisfaction comparable to those of a physician, while
requiring less time and lower costs. These findings suggest that AI interfaces
may have the potential to assist primary care consultations for common internal
medicine cases.

</details>


### [151] [CoderAgent: Simulating Student Behavior for Personalized Programming Learning with Large Language Models](https://arxiv.org/abs/2505.20642)
*Yi Zhan, Qi Liu, Weibo Gao, Zheng Zhang, Tianfu Wang, Shuanghong Shen, Junyu Lu, Zhenya Huang*

**主要类别:** cs.AI

**概要:** 提出了一种基于LLM的智能体CoderAgent，用于模拟学生的编程过程，并通过Programming Tree of Thought（PTOT）提供可解释的学习轨迹和精确的模拟，推动个性化编程教育的发展。


<details>
  <summary>更多</summary>
  
**动机:** 当前个性化编程辅导系统面临编程数据不足、高质量数据缺乏以及离线评估与实际学习不匹配的问题。此外，现有的模拟方法未能充分捕捉编程学习的细粒度和迭代特性，导致结果缺乏可解释性和细节。

**方法:** 1. 提出CoderAgent，一个基于LLM的智能体，能够以细粒度的方式模拟学生编程过程，无需依赖真实数据。
2. 借鉴ACT-R认知架构框架设计CoderAgent结构，使其符合人类编程实践的认知状态。
3. 引入Programming Tree of Thought（PTOT），将问题解决过程分解为四个步骤：why（原因）、how（方法）、where（位置）和what（内容），以支持迭代式问题解决策略。

**结果:** 实验评估表明，CoderAgent能够提供对学习轨迹的可解释洞察，并实现准确的模拟，展示了其在个性化编程教育中的潜力。

**结论:** CoderAgent通过模拟细粒度的学生编程过程和引入PTOT，成功解决了现有系统缺乏可解释性和细节的问题，为个性化编程教育提供了新的途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CoderAgent%3A+Simulating+Student+Behavior+for+Personalized+Programming+Learning+with+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20642，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20642&send_immediately=true&force_search=false)

**原文摘要:** Personalized programming tutoring, such as exercise recommendation, can
enhance learners' efficiency, motivation, and outcomes, which is increasingly
important in modern digital education. However, the lack of sufficient and
high-quality programming data, combined with the mismatch between offline
evaluation and real-world learning, hinders the practical deployment of such
systems. To address this challenge, many approaches attempt to simulate learner
practice data, yet they often overlook the fine-grained, iterative nature of
programming learning, resulting in a lack of interpretability and granularity.
To fill this gap, we propose a LLM-based agent, CoderAgent, to simulate
students' programming processes in a fine-grained manner without relying on
real data. Specifically, we equip each human learner with an intelligent agent,
the core of which lies in capturing the cognitive states of the human
programming practice process. Inspired by ACT-R, a cognitive architecture
framework, we design the structure of CoderAgent to align with human cognitive
architecture by focusing on the mastery of programming knowledge and the
application of coding ability. Recognizing the inherent patterns in
multi-layered cognitive reasoning, we introduce the Programming Tree of Thought
(PTOT), which breaks down the process into four steps: why, how, where, and
what. This approach enables a detailed analysis of iterative problem-solving
strategies. Finally, experimental evaluations on real-world datasets
demonstrate that CoderAgent provides interpretable insights into learning
trajectories and achieves accurate simulations, paving the way for personalized
programming education.

</details>


### [152] [AutoReproduce: Automatic AI Experiment Reproduction with Paper Lineage](https://arxiv.org/abs/2505.20662)
*Xuanle Zhao, Zilin Sang, Yuxuan Li, Qi Shi, Shuo Wang, Duzhen Zhang, Xu Han, Zhiyuan Liu, Maosong Sun*

**主要类别:** cs.AI

**概要:** 为了加速人工智能领域的进步，有效实验复现至关重要。然而，方法设计和训练流程的固有复杂性给自动化带来了重大挑战。尤其是，实验复现通常需要那些在原始论文中未明确记录的领域特定隐性知识。为了解决这个问题，我们引入了paper lineage算法，该算法可以识别并从目标论文引用的相关参考文献中提取隐性知识。基于这个想法，我们提出了AutoReproduce，这是一个多代理框架，能够以端到端的方式自动复现研究论文中描述的实验。AutoReproduce通过生成单元测试增强了代码可执行性，伴随整个复现过程。为了评估复现能力，我们构建了ReproduceBench基准，并引入了新的评估指标来衡量复现和执行的保真度。实验结果表明，AutoReproduce在所有五个评估指标上均超过了现有的强代理基线，峰值优势超过70％。特别是，与官方实现相比，在89.74％的可执行实验运行中，AutoReproduce的平均性能差距仅为22.1％。代码将在https://github.com/AI9Stars/AutoReproduce上提供。


<details>
  <summary>更多</summary>
  
**动机:** 当前实验复现过程中存在诸多挑战，包括方法设计和训练流程的复杂性，以及领域特定隐性知识的缺乏。这阻碍了人工智能领域的快速发展，因此亟需一种解决方案来自动化并提高实验复现的效率和准确性。

**方法:** 提出了一种名为paper lineage的算法，用于从目标论文引用的参考文献中提取隐性知识。基于此，开发了一个多代理框架AutoReproduce，它能够端到端地自动复现研究论文中的实验，并在复现过程中生成单元测试以增强代码可执行性。此外，还构建了一个名为ReproduceBench的基准和新的评估指标，以衡量复现和执行的保真度。

**结果:** 实验结果表明，AutoReproduce在所有五个评估指标上显著优于现有方法，峰值优势超过70％。与官方实现相比，在89.74％的可执行实验运行中，AutoReproduce的平均性能差距仅为22.1％。

**结论:** AutoReproduce是一个有效的多代理框架，能够在实验复现过程中自动化提取隐性知识、生成单元测试并提高代码可执行性。其在多个评估指标上的优越表现证明了其在提升实验复现效率和准确性方面的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AutoReproduce%3A+Automatic+AI+Experiment+Reproduction+with+Paper+Lineage，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20662，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20662&send_immediately=true&force_search=false)

**原文摘要:** Efficient experiment reproduction is critical to accelerating progress in
artificial intelligence. However, the inherent complexity of method design and
training procedures presents substantial challenges for automation. Notably,
reproducing experiments often requires implicit domain-specific knowledge not
explicitly documented in the original papers. To address this, we introduce the
paper lineage algorithm, which identifies and extracts implicit knowledge from
the relevant references cited by the target paper. Building on this idea, we
propose AutoReproduce, a multi-agent framework capable of automatically
reproducing experiments described in research papers in an end-to-end manner.
AutoReproduce enhances code executability by generating unit tests alongside
the reproduction process. To evaluate the reproduction capability, we construct
ReproduceBench, a benchmark annotated with verified implementations, and
introduce novel evaluation metrics to assess both the reproduction and
execution fidelity. Experimental results demonstrate that AutoReproduce
outperforms the existing strong agent baselines on all five evaluation metrics
by a peak margin of over $70\%$. In particular, compared to the official
implementations, AutoReproduce achieves an average performance gap of $22.1\%$
on $89.74\%$ of the executable experiment runs. The code will be available at
https://github.com/AI9Stars/AutoReproduce.

</details>


### [153] [MIRROR: Multi-agent Intra- and Inter-Reflection for Optimized Reasoning in Tool Learning](https://arxiv.org/abs/2505.20670)
*Zikang Guo, Benfeng Xu, Xiaorui Wang, Zhendong Mao*

**主要类别:** cs.AI

**概要:** 在复杂任务中，大型语言模型（LLMs）面临工具集成的挑战，多代理工作流和反思策略逐渐成为解决方案。本文提出MIRROR框架，包含执行前的内部反思和基于观察的外部反思，系统利用LLM反思能力以消除和修正错误行为，在多个基准测试中表现优异，达到现有方法中的最佳效果。


<details>
  <summary>更多</summary>
  
**动机:** 复杂任务中LLMs存在工具集成挑战，虽然反思是纠正错误的有效策略，但现有方法仅限于行动后的反思，缺乏行动前的评估。

**方法:** 提出MIRROR框架，包括：1) intra-reflection（内部反思），在行动前批判性评估计划；2) inter-reflection（外部反思），根据观察调整行动轨迹。

**结果:** 在StableToolBench和TravelPlanner基准测试中，MIRROR框架展现出优越性能，达到当前最佳结果。

**结论:** MIRROR框架通过系统利用LLM反思能力，在更广泛的范围内消除和修正错误行为，为复杂任务提供了一种有效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MIRROR%3A+Multi-agent+Intra-+and+Inter-Reflection+for+Optimized+Reasoning+in+Tool+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20670，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20670&send_immediately=true&force_search=false)

**原文摘要:** Complex tasks involving tool integration pose significant challenges for
Large Language Models (LLMs), leading to the emergence of multi-agent workflows
as a promising solution. Reflection has emerged as an effective strategy for
correcting erroneous trajectories in agentic workflows. However, existing
approaches only exploit such capability in the post-action stage, where the
agent observes the execution outcomes. We argue that, like humans, LLMs can
also engage in reflection before action execution: the agent can anticipate
undesirable outcomes from its own decisions, which not only provides a
necessarily complementary perspective to evaluate the decision but also
prevents the propagation of errors throughout the trajectory. In this paper, we
propose MIRROR, a framework that consists of both intra-reflection, which
critically assesses intended actions before execution, and inter-reflection,
which further adjusts the trajectory based on observations. This design
systematically leverages LLM reflection capabilities to eliminate and rectify
erroneous actions on a more comprehensive scope. Evaluations on both the
StableToolBench and TravelPlanner benchmarks demonstrate MIRROR's superior
performance, achieving state-of-the-art results compared to existing
approaches.

</details>


### [154] [LLM-Guided Reinforcement Learning: Addressing Training Bottlenecks through Policy Modulation](https://arxiv.org/abs/2505.20671)
*Heng Tan, Hua Yan, Yu Yang*

**主要类别:** cs.AI

**概要:** 本文提出了一种大型语言模型（LLM）引导的策略调制框架，利用LLM改进强化学习（RL）训练，无需额外的模型训练或人工干预。通过实验表明，该方法在标准RL基准上优于现有最先进方法。


<details>
  <summary>更多</summary>
  
**动机:** 尽管强化学习在多个领域取得了显著成功，但在复杂任务中训练有效的策略仍然具有挑战性。现有的缓解训练瓶颈的方法要么成本高且不确定，要么在大规模或连续动作空间环境中扩展性差。

**方法:** 设计了一个大型语言模型（LLM）引导的策略调制框架。首先，提示LLM从次优代理的轨迹中识别关键状态。然后，LLM提供动作建议并分配隐式奖励以指导策略改进。

**结果:** 实验跨越标准RL基准测试，结果表明该方法优于最先进的基线方法，突显了基于LLM的解释在解决RL训练瓶颈方面的有效性。

**结论:** LLM引导的策略调制框架能够有效改进RL训练，无需额外模型训练或人类干预，为解决RL训练瓶颈提供了新途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM-Guided+Reinforcement+Learning%3A+Addressing+Training+Bottlenecks+through+Policy+Modulation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20671，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20671&send_immediately=true&force_search=false)

**原文摘要:** While reinforcement learning (RL) has achieved notable success in various
domains, training effective policies for complex tasks remains challenging.
Agents often converge to local optima and fail to maximize long-term rewards.
Existing approaches to mitigate training bottlenecks typically fall into two
categories: (i) Automated policy refinement, which identifies critical states
from past trajectories to guide policy updates, but suffers from costly and
uncertain model training; and (ii) Human-in-the-loop refinement, where human
feedback is used to correct agent behavior, but this does not scale well to
environments with large or continuous action spaces. In this work, we design a
large language model-guided policy modulation framework that leverages LLMs to
improve RL training without additional model training or human intervention. We
first prompt an LLM to identify critical states from a sub-optimal agent's
trajectories. Based on these states, the LLM then provides action suggestions
and assigns implicit rewards to guide policy refinement. Experiments across
standard RL benchmarks demonstrate that our method outperforms state-of-the-art
baselines, highlighting the effectiveness of LLM-based explanations in
addressing RL training bottlenecks.

</details>


### [155] [GIFARC: Synthetic Dataset for Leveraging Human-Intuitive Analogies to Elevate AI Reasoning](https://arxiv.org/abs/2505.20672)
*Woochang Sim, Hyunseok Ryu, Kyungmin Choi, Sungwon Han, Sundong Kim*

**主要类别:** cs.AI

**概要:** 论文提出了一种新的数据集GIFARC，通过结合大语言模型和视觉语言模型生成包含类比的新任务，从而帮助AI更高效地解决抽象推理问题，并使解决方案更加简洁和人类可理解。


<details>
  <summary>更多</summary>
  
**动机:** 现有的深度学习模型在解决ARC竞赛中的抽象模式推理问题时，准确率仅为40-55%，与人类水平的推理能力存在显著差距，因此需要一种新方法来缩小这一差距。

**方法:** 引入了基于类比的GIFARC数据集，利用大语言模型（LLMs）和视觉语言模型（VLMs）从包含类比的GIF图像中合成新的ARC风格任务，并为每个任务提供真实的类比映射，以引导AI代理类比评估任务，减少问题复杂度。

**结果:** 实证结果表明，使用类比方法和GIFARC指导的大语言模型在解决任务时，其方法更趋向于人类的类比推理方式。

**结论:** 通过嵌入强人类直觉的类比到ARC风格的任务中，GIFARC可以有效降低问题复杂性并构建更简洁、更易被人类理解的解决方案，从而提升AI在抽象推理任务上的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GIFARC%3A+Synthetic+Dataset+for+Leveraging+Human-Intuitive+Analogies+to+Elevate+AI+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20672，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20672&send_immediately=true&force_search=false)

**原文摘要:** The Abstraction and Reasoning Corpus (ARC) poses a stringent test of general
AI capabilities, requiring solvers to infer abstract patterns from only a
handful of examples. Despite substantial progress in deep learning,
state-of-the-art models still achieve accuracy rates of merely 40-55% on 2024
ARC Competition, indicative of a significant gap between their performance and
human-level reasoning. In this work, we seek to bridge that gap by introducing
an analogy-inspired ARC dataset, GIFARC. Leveraging large language models
(LLMs) and vision-language models (VLMs), we synthesize new ARC-style tasks
from a variety of GIF images that include analogies. Each new task is paired
with ground-truth analogy, providing an explicit mapping between visual
transformations and everyday concepts. By embedding robust human-intuitive
analogies into ARC-style tasks, GIFARC guides AI agents to evaluate the task
analogically before engaging in brute-force pattern search, thus efficiently
reducing problem complexity and build a more concise and human-understandable
solution. We empirically validate that guiding LLM with analogic approach with
GIFARC affects task-solving approaches of LLMs to align with analogic approach
of human.

</details>


### [156] [Jigsaw-Puzzles: From Seeing to Understanding to Reasoning in Vision-Language Models](https://arxiv.org/abs/2505.20728)
*Zesen Lyu, Dandan Zhang, Wei Ye, Fangdi Li, Zhihang Jiang, Yao Yang*

**主要类别:** cs.AI

**概要:** 论文介绍了一个名为Jigsaw-Puzzles的新基准，包含1,100张高空间复杂度的图像，设计了五个任务来评估视觉-语言模型（VLMs）的空间感知、结构理解和推理能力。尽管评估了24个最先进的VLMs，但即使是表现最好的Gemini-2.5-Pro模型，在整体准确率上也仅为77.14%，在顺序生成任务上的准确率更是低至30%，远低于人类的表现。这表明VLMs在空间推理方面仍有很大提升空间。


<details>
  <summary>更多</summary>
  
**动机:** 研究者希望通过引入一个新基准Jigsaw-Puzzles，来评估当前视觉-语言模型（VLMs）是否具备类似人类的空间推理能力。这种能力是人类认知的核心部分，使个体能够感知、理解并与物理世界互动。

**方法:** 研究者创建了一个包含1,100张精心挑选的现实世界图像的数据集Jigsaw-Puzzles，并基于此设计了五个任务，以严格评估VLMs的空间感知、结构理解和推理能力。这些任务尽量减少对领域特定知识的依赖，以便更好地孤立和评估一般的空間推理能力。然后，他们对24个最先进的VLMs进行了全面评估。

**结果:** 评估结果显示，即使是最强的模型Gemini-2.5-Pro，其总体准确率也只有77.14%，在顺序生成任务上的准确率更是只有30%，远远低于人类参与者超过90%的表现。

**结论:** 这一持续存在的差距强调了继续推进视觉-语言模型空间推理能力研究的必要性，而Jigsaw-Puzzles作为一个具有挑战性和诊断性的基准，将有助于推动该领域的研究进展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Jigsaw-Puzzles%3A+From+Seeing+to+Understanding+to+Reasoning+in+Vision-Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20728，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20728&send_immediately=true&force_search=false)

**原文摘要:** Spatial reasoning is a core component of human cognition, enabling
individuals to perceive, comprehend, and interact with the physical world. It
relies on a nuanced understanding of spatial structures and inter-object
relationships, serving as the foundation for complex reasoning and
decision-making. To investigate whether current vision-language models (VLMs)
exhibit similar capability, we introduce Jigsaw-Puzzles, a novel benchmark
consisting of 1,100 carefully curated real-world images with high spatial
complexity. Based on this dataset, we design five tasks to rigorously evaluate
VLMs' spatial perception, structural understanding, and reasoning capabilities,
while deliberately minimizing reliance on domain-specific knowledge to better
isolate and assess the general spatial reasoning capability. We conduct a
comprehensive evaluation across 24 state-of-the-art VLMs. The results show that
even the strongest model, Gemini-2.5-Pro, achieves only 77.14% overall accuracy
and performs particularly poorly on the Order Generation task, with only 30.00%
accuracy, far below the performance exceeding 90% achieved by human
participants. This persistent gap underscores the need for continued progress,
positioning Jigsaw-Puzzles as a challenging and diagnostic benchmark for
advancing spatial reasoning research in VLMs.

</details>


### [157] [E2E Process Automation Leveraging Generative AI and IDP-Based Automation Agent: A Case Study on Corporate Expense Processing](https://arxiv.org/abs/2505.20733)
*Cheonsu Jeong, Seongmin Sim, Hyoyoung Cho, Sungsu Kim, Byounggwan Shin*

**主要类别:** cs.AI

**概要:** 本文提出了一种智能工作自动化方法，通过将生成式AI和智能文档处理技术与自动化代理相结合，实现企业财务费用处理任务的端到端自动化。该系统在一家韩国大型企业中应用，显著减少了处理时间、降低了错误率并提高了合规性，同时增强了准确性和一致性，增加了员工满意度，并支持数据驱动决策。研究表明，生成式AI、IDP和自动化代理的有机集成可以有效克服传统自动化的局限性，实现复杂企业流程的端到端自动化。


<details>
  <summary>更多</summary>
  
**动机:** 传统机器人流程自动化（RPA）在处理重复性、基于规则的简单任务时效果显著，但在处理非结构化数据、异常管理和复杂决策方面存在局限性。因此，需要一种新的方法来克服这些限制，实现更广泛的自动化。

**方法:** 研究设计并实施了一个四阶段集成过程：1) 通过OCR/IDP自动识别收据等支持文件；2) 基于政策驱动数据库的项目分类；3) 由生成式AI（大语言模型，LLM）支持的智能异常处理；4) 通过自动化代理进行人机协作最终决策，并实现系统的持续学习。

**结果:** 该系统在一家韩国大型企业（公司S）的应用中展示了定量和定性的好处。定量上，纸质收据费用任务的处理时间减少了80%以上，错误率下降，合规性提高。定性上，准确性和一致性增强，员工满意度增加，支持数据驱动决策。此外，系统通过从人类判断中学习，逐步改进自动异常处理能力，形成了良性循环。

**结论:** 实证研究表明，生成式AI、IDP和自动化代理的有机集成可以有效克服传统自动化的局限性，实现复杂企业流程的端到端自动化。论文还讨论了该方法在会计、人力资源和采购等其他领域的潜在扩展，并提出了未来AI驱动超自动化发展的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是E2E+Process+Automation+Leveraging+Generative+AI+and+IDP-Based+Automation+Agent%3A+A+Case+Study+on+Corporate+Expense+Processing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20733，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20733&send_immediately=true&force_search=false)

**原文摘要:** This paper presents an intelligent work automation approach in the context of
contemporary digital transformation by integrating generative AI and
Intelligent Document Processing (IDP) technologies with an Automation Agent to
realize End-to-End (E2E) automation of corporate financial expense processing
tasks. While traditional Robotic Process Automation (RPA) has proven effective
for repetitive, rule-based simple task automation, it faces limitations in
handling unstructured data, exception management, and complex decision-making.
This study designs and implements a four-stage integrated process comprising
automatic recognition of supporting documents such as receipts via OCR/IDP,
item classification based on a policy-driven database, intelligent exception
handling supported by generative AI (large language models, LLMs), and
human-in-the-loop final decision-making with continuous system learning through
an Automation Agent. Applied to a major Korean enterprise (Company S), the
system demonstrated quantitative benefits including over 80% reduction in
processing time for paper receipt expense tasks, decreased error rates, and
improved compliance, as well as qualitative benefits such as enhanced accuracy
and consistency, increased employee satisfaction, and data-driven decision
support. Furthermore, the system embodies a virtuous cycle by learning from
human judgments to progressively improve automatic exception handling
capabilities. Empirically, this research confirms that the organic integration
of generative AI, IDP, and Automation Agents effectively overcomes the
limitations of conventional automation and enables E2E automation of complex
corporate processes. The study also discusses potential extensions to other
domains such as accounting, human resources, and procurement, and proposes
future directions for AI-driven hyper-automation development.

</details>


### [158] [RRO: LLM Agent Optimization Through Rising Reward Trajectories](https://arxiv.org/abs/2505.20737)
*Zilong Wang, Jingfeng Yang, Sreyashi Nag, Samarth Varshney, Xianfeng Tang, Haoming Jiang, Jingbo Shang, Sheikh Muhammad Sarwar*

**主要类别:** cs.AI

**概要:** 大型语言模型（LLMs）在多步骤任务中表现不佳，因为规划轨迹中的细微错误可能导致任务失败。现有的过程奖励模型（PRMs）通过强化学习校准推理过程，但难以扩展。本文提出了一种名为Reward Rising Optimization（RRO）的新方法，专注于连续推理步骤之间的相对奖励趋势，通过动态扩展搜索空间来高效捕获高质量数据。实验结果表明，RRO在减少探索成本的同时实现了卓越的性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型在各种任务中表现出色，但在作为代理解决复杂的多步骤任务时仍面临挑战。由于对某些关键步骤的结果敏感，细微的规划错误可能导致任务失败。因此，需要一种更有效的方法来校准推理过程并减少探索成本。

**方法:** 提出了一种称为Reward Rising Optimization（RRO）的方法，该方法关注连续推理步骤之间的相对奖励趋势。具体来说，通过逐步增强过程监督，直到识别出相对于前一次迭代具有正奖励差分的步骤（即上升的奖励）。这种方法动态扩展了下一个动作候选者的搜索空间，从而有效地捕获高质量数据。

**结果:** 在WebShop和InterCode-SQL基准上的数学基础和实证结果表明，所提出的RRO方法在显著减少探索成本的同时，实现了优越的性能。

**结论:** Reward Rising Optimization（RRO）提供了一种有效的方法来优化大型语言模型在复杂多步骤任务中的推理过程。与现有的过程奖励模型相比，RRO不仅提高了性能，还大幅降低了探索成本，为未来的研究提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是RRO%3A+LLM+Agent+Optimization+Through+Rising+Reward+Trajectories，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20737，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20737&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) have exhibited extraordinary performance in a
variety of tasks while it remains challenging for them to solve complex
multi-step tasks as agents. In practice, agents sensitive to the outcome of
certain key steps which makes them likely to fail the task because of a subtle
mistake in the planning trajectory. Recent approaches resort to calibrating the
reasoning process through reinforcement learning. They reward or penalize every
reasoning step with process supervision, as known as Process Reward Models
(PRMs). However, PRMs are difficult and costly to scale up with a large number
of next action candidates since they require extensive computations to acquire
the training data through the per-step trajectory exploration. To mitigate this
issue, we focus on the relative reward trend across successive reasoning steps
and propose maintaining an increasing reward in the collected trajectories for
process supervision, which we term Reward Rising Optimization (RRO).
Specifically, we incrementally augment the process supervision until
identifying a step exhibiting positive reward differentials, i.e. rising
rewards, relative to its preceding iteration. This method dynamically expands
the search space for the next action candidates, efficiently capturing
high-quality data. We provide mathematical groundings and empirical results on
the WebShop and InterCode-SQL benchmarks, showing that our proposed RRO
achieves superior performance while requiring much less exploration cost.

</details>


### [159] [MSEarth: A Benchmark for Multimodal Scientific Comprehension of Earth Science](https://arxiv.org/abs/2505.20740)
*Xiangyu Zhao, Wanghan Xu, Bo Liu, Yuhao Zhou, Fenghua Ling, Ben Fei, Xiaoyu Yue, Lei Bai, Wenlong Zhang, Xiao-Ming Wu*

**主要类别:** cs.AI

**概要:** 论文提出MSEarth，一个来自高质量开放获取科学出版物的多模态科学基准，涵盖地球科学五大领域，包含7K张图表和精心制作的标题，支持多种任务以推动多模态大语言模型在科学推理中的发展。


<details>
  <summary>更多</summary>
  
**动机:** 当前多模态大语言模型在解决地球科学问题方面的应用尚不充分，主要由于缺乏能够捕捉地质科学推理深度和复杂性的基准。现有的基准测试通常依赖于合成数据集或过于简化的图-字对，无法反映真实科学应用所需的复杂推理和领域特定见解。

**方法:** 从高质量开放获取科学出版物中整理出MSEarth这一多模态科学基准，涵盖地球科学五大领域（大气圈、冰冻圈、水圈、岩石圈和生物圈），包含7000多张图表及其经过精炼和丰富后的标题，确保基准能捕捉高级科学任务所需的细致推理和知识密集型内容。

**结果:** MSEarth支持多种任务，包括科学图表说明生成、多项选择题和开放式推理挑战等，为研究生水平的基准测试提供了可扩展和高保真的资源，有助于提升多模态大语言模型在科学推理中的开发和评估能力。

**结论:** MSEarth作为公开可用的资源，将促进该领域的进一步研究与创新，推动多模态大语言模型在地球科学研究中的应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MSEarth%3A+A+Benchmark+for+Multimodal+Scientific+Comprehension+of+Earth+Science，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20740，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20740&send_immediately=true&force_search=false)

**原文摘要:** The rapid advancement of multimodal large language models (MLLMs) has
unlocked new opportunities to tackle complex scientific challenges. Despite
this progress, their application in addressing earth science problems,
especially at the graduate level, remains underexplored. A significant barrier
is the absence of benchmarks that capture the depth and contextual complexity
of geoscientific reasoning. Current benchmarks often rely on synthetic datasets
or simplistic figure-caption pairs, which do not adequately reflect the
intricate reasoning and domain-specific insights required for real-world
scientific applications. To address these gaps, we introduce MSEarth, a
multimodal scientific benchmark curated from high-quality, open-access
scientific publications. MSEarth encompasses the five major spheres of Earth
science: atmosphere, cryosphere, hydrosphere, lithosphere, and biosphere,
featuring over 7K figures with refined captions. These captions are crafted
from the original figure captions and enriched with discussions and reasoning
from the papers, ensuring the benchmark captures the nuanced reasoning and
knowledge-intensive content essential for advanced scientific tasks. MSEarth
supports a variety of tasks, including scientific figure captioning, multiple
choice questions, and open-ended reasoning challenges. By bridging the gap in
graduate-level benchmarks, MSEarth provides a scalable and high-fidelity
resource to enhance the development and evaluation of MLLMs in scientific
reasoning. The benchmark is publicly available to foster further research and
innovation in this field. Resources related to this benchmark can be found at
https://huggingface.co/MSEarth and https://github.com/xiangyu-mm/MSEarth.

</details>


### [160] [Can Agents Fix Agent Issues?](https://arxiv.org/abs/2505.20749)
*Alfin Wijaya Rahardja, Junwei Liu, Weitong Chen, Zhenpeng Chen, Yiling Lou*

**主要类别:** cs.AI

**概要:** 大型语言模型（LLM）驱动的智能体系统作为一种新兴软件范式，在多个领域被广泛应用。然而，这些系统容易出现错误并需要不断演化以满足外部需求。本文通过分析真实世界中的智能体问题，并构建了一个名为AGENTISSUE-BENCH的基准测试平台，评估了现有软件工程智能体在解决智能体系统问题上的有效性，发现其解决率仅为3.33%-12.67%。这表明维护智能体系统与传统软件存在显著差异，亟需进一步研究开发更先进的解决方案。


<details>
  <summary>更多</summary>
  
**动机:** 当前基于LLM的智能体系统虽然应用广泛，但它们容易出现错误且需要持续更新以适应变化的需求。因此，自动解决智能体系统的相关问题是至关重要的任务。然而，现有的软件工程智能体在处理传统软件问题时表现良好，但在智能体系统问题上的效果尚不明确。

**方法:** 1. 手动分析了201个真实世界的智能体问题，识别出常见问题类别。
2. 投入500个人工小时构建了AGENTISSUE-BENCH，这是一个可重现的基准测试平台，包含50个智能体问题解决任务，每个任务都附带可执行环境和触发失败的测试。
3. 使用该基准对最先进的软件工程智能体进行评估，衡量其在解决智能体问题上的有效性。

**结果:** 评估结果显示，现有最先进的软件工程智能体在解决智能体系统问题上的有效率非常低，仅达到3.33%-12.67%的解决率。

**结论:** 智能体系统的维护相比传统软件面临独特的挑战，现有软件工程智能体在解决智能体系统问题上的能力有限。未来的研究应着重开发更高级的解决方案以应对这些挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Can+Agents+Fix+Agent+Issues%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20749，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20749&send_immediately=true&force_search=false)

**原文摘要:** LLM-based agent systems are emerging as a new software paradigm and have been
widely adopted across diverse domains such as medicine, robotics, and
programming. However, maintaining these systems requires substantial effort, as
they are inevitably prone to bugs and continually evolve to meet changing
external requirements. Therefore, automatically resolving agent issues (i.e.,
bug reports or feature requests) is a crucial and challenging task. While
recent software engineering (SE) agents (e.g., SWE-agent) have shown promise in
addressing issues in traditional software systems, it remains unclear how
effectively they can resolve real-world issues in agent systems, which differ
significantly from traditional software. To fill this gap, we first manually
analyze 201 real-world agent issues and identify common categories of agent
issues. We then spend 500 person-hours constructing AGENTISSUE-BENCH, a
reproducible benchmark comprising 50 agent issue resolution tasks (each with an
executable environment and failure-triggering tests). We further evaluate
state-of-the-art SE agents on AGENTISSUE-BENCH and reveal their limited
effectiveness (i.e., with only 3.33% - 12.67% resolution rates). These results
underscore the unique challenges of maintaining agent systems compared to
traditional software, highlighting the need for further research to develop
advanced SE agents for resolving agent issues. Data and code are available at
https://alfin06.github.io/AgentIssue-Bench-Leaderboard/#/ .

</details>


### [161] [MT-Mol:Multi Agent System with Tool-based Reasoning for Molecular Optimization](https://arxiv.org/abs/2505.20820)
*Hyomin Kim, Yunhui Jang, Sungsoo Ahn*

**主要类别:** cs.AI

**概要:** MT-Mol是一个多代理框架，利用工具引导推理和角色专业化的大语言模型代理进行分子优化。它结合了全面的RDKit工具，分为五个不同领域，并在PMO-1K基准测试中展示了最先进的性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大语言模型在分子优化方面具有巨大潜力，但在结构化推理、可解释性和基于全面工具的分子优化方面的探索仍不足。

**方法:** 引入了MT-Mol，一个多代理框架，包括全面的RDKit工具，分为五个领域：结构描述符、电子和拓扑特征、基于片段的功能组、分子表示和其他化学性质。每个类别由一个专家分析师代理管理，负责提取任务相关工具并提供可解释的、基于化学的反馈。通过分析家代理、生成分子的科学家、推理输出验证者和评审代理之间的互动，MT-Mol产生与工具一致且逐步推理的分子。

**结果:** 在PMO-1K基准测试中，该框架在23项任务中的17项上展示了最先进的性能。

**结论:** MT-Mol通过结合工具引导推理和角色专业化的大语言模型代理，在分子优化方面展现了卓越的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MT-Mol%3AMulti+Agent+System+with+Tool-based+Reasoning+for+Molecular+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20820，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20820&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) have large potential for molecular optimization,
as they can gather external chemistry tools and enable collaborative
interactions to iteratively refine molecular candidates. However, this
potential remains underexplored, particularly in the context of structured
reasoning, interpretability, and comprehensive tool-grounded molecular
optimization. To address this gap, we introduce MT-Mol, a multi-agent framework
for molecular optimization that leverages tool-guided reasoning and
role-specialized LLM agents. Our system incorporates comprehensive RDKit tools,
categorized into five distinct domains: structural descriptors, electronic and
topological features, fragment-based functional groups, molecular
representations, and miscellaneous chemical properties. Each category is
managed by an expert analyst agent, responsible for extracting task-relevant
tools and enabling interpretable, chemically grounded feedback. MT-Mol produces
molecules with tool-aligned and stepwise reasoning through the interaction
between the analyst agents, a molecule-generating scientist, a reasoning-output
verifier, and a reviewer agent. As a result, we show that our framework shows
the state-of-the-art performance of the PMO-1K benchmark on 17 out of 23 tasks.

</details>


### [162] [Step-Wise Formal Verification for LLM-Based Mathematical Problem Solving](https://arxiv.org/abs/2505.20869)
*Kuo Zhou, Lu Zhang*

**主要类别:** cs.AI

**概要:** 大型语言模型（LLMs）在解决数学问题方面表现出强大的能力，但仍可能在解决问题的过程中出现逻辑推理和计算错误。因此，本文提出了一个名为MATH-VF的框架，其中包括一个Formalizer和一个Critic，用于正式验证大型语言模型生成的解决方案的正确性。该框架首先使用Formalizer，它利用LLM将自然语言解决方案转换为正式上下文。之后，Critic（集成了各种外部工具，如计算机代数系统和SMT求解器）评估正式上下文中每个陈述的正确性，并在陈述不正确时提供纠正反馈。我们在两种情况下对MATH-VF的有效性进行了实证研究：1）验证：MATH-VF用于确定给定问题解决方案的正确性；2）改进：当MATH-VF识别出由基于LLM的解决方案生成器为给定问题生成的解决方案中的错误时，它会将Critic提出的纠正建议提交给解决方案生成器以重新生成解决方案。我们在广泛使用的数学基准MATH500和ProcessBench上评估了我们的框架，证明了我们的方法优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型在解决数学问题方面具有强大能力，但它们仍可能在解决问题过程中犯下逻辑推理和计算错误，这需要一种能够验证这些模型所生成解决方案正确性的机制。

**方法:** 提出了一种名为MATH-VF的框架，包括Formalizer和Critic两个组件。Formalizer使用LLM将自然语言解决方案转化为形式化语境，而Critic则整合多种外部工具（如计算机代数系统和SMT求解器）来评估形式化语境内各陈述的正确性，并针对错误陈述提供修正反馈。

**结果:** 通过在MATH500和ProcessBench这两个广泛使用的数学基准数据集上的评估，证明了MATH-VF框架在验证和改进解决方案方面的优越性。

**结论:** MATH-VF框架有效地验证了大型语言模型生成的数学问题解决方案的正确性，并且在发现错误时能够提供有意义的修正建议，从而提高了解决方案的质量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Step-Wise+Formal+Verification+for+LLM-Based+Mathematical+Problem+Solving，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20869，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20869&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have demonstrated formidable capabilities in
solving mathematical problems, yet they may still commit logical reasoning and
computational errors during the problem-solving process. Thus, this paper
proposes a framework, MATH-VF, which includes a Formalizer and a Critic, for
formally verifying the correctness of the solutions generated by large language
models. Our framework first utilizes a Formalizer which employs an LLM to
translate a natural language solution into a formal context. Afterward, our
Critic (which integrates various external tools such as a Computer Algebra
System and an SMT solver) evaluates the correctness of each statement within
the formal context, and when a statement is incorrect, our Critic provides
corrective feedback. We empirically investigate the effectiveness of MATH-VF in
two scenarios: 1) Verification: MATH-VF is utilized to determine the
correctness of a solution to a given problem. 2) Refinement: When MATH-VF
identifies errors in the solution generated by an LLM-based solution generator
for a given problem, it submits the corrective suggestions proposed by the
Critic to the solution generator to regenerate the solution. We evaluate our
framework on widely used mathematical benchmarks: MATH500 and ProcessBench,
demonstrating the superiority of our approach over existing approaches.

</details>


### [163] [Reinforcement Learning-based Sequential Route Recommendation for System-Optimal Traffic Assignment](https://arxiv.org/abs/2505.20889)
*Leizhen Wang, Peibo Duan, Cheng Lyu, Zhenliang Ma*

**主要类别:** cs.AI

**概要:** 本文提出了一种基于学习的框架，将静态系统最优(SO)交通分配问题重新定义为单智能体深度强化学习(RL)任务，通过中心智能体顺序向旅行者推荐路线以最小化总系统旅行时间，并开发了MSA引导的深度Q学习算法来提高学习效率和解的质量。实验结果表明，RL智能体在Braess网络中收敛到理论SO解，在Ortuzar-Willumsen网络中仅有0.35%的偏差。


<details>
  <summary>更多</summary>
  
**动机:** 现代导航系统和共享出行平台越来越依赖个性化路线推荐来提升个体出行体验和运营效率，但关键问题在于：个性化的路径决策是否可以集体导向系统最优(SO)交通分配？

**方法:** 作者提出了一种学习框架，将静态SO交通分配问题转化为单智能体深度强化学习任务。中央智能体根据到达的起讫点(OD)需求顺序推荐路线，目标是最小化系统的总旅行时间。此外，还开发了一种MSA引导的深度Q学习算法，将传统交通分配方法的迭代结构整合到RL训练过程中。

**结果:** 在Braess和Ortuzar-Willumsen网络上的评估结果显示，RL智能体在Braess网络中能够收敛到理论SO解，而在Ortuzar-Willumsen网络中的偏差仅为0.35%。消融研究表明，路径动作集的设计对收敛速度和最终性能有显著影响，SO导向的路径集可加速学习并带来更好的结果。

**结论:** 该研究提供了一种理论依据充分且实践相关的途径，通过基于学习的顺序分配连接个体路径行为与系统级效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reinforcement+Learning-based+Sequential+Route+Recommendation+for+System-Optimal+Traffic+Assignment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20889，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20889&send_immediately=true&force_search=false)

**原文摘要:** Modern navigation systems and shared mobility platforms increasingly rely on
personalized route recommendations to improve individual travel experience and
operational efficiency. However, a key question remains: can such sequential,
personalized routing decisions collectively lead to system-optimal (SO) traffic
assignment? This paper addresses this question by proposing a learning-based
framework that reformulates the static SO traffic assignment problem as a
single-agent deep reinforcement learning (RL) task. A central agent
sequentially recommends routes to travelers as origin-destination (OD) demands
arrive, to minimize total system travel time. To enhance learning efficiency
and solution quality, we develop an MSA-guided deep Q-learning algorithm that
integrates the iterative structure of traditional traffic assignment methods
into the RL training process. The proposed approach is evaluated on both the
Braess and Ortuzar-Willumsen (OW) networks. Results show that the RL agent
converges to the theoretical SO solution in the Braess network and achieves
only a 0.35% deviation in the OW network. Further ablation studies demonstrate
that the route action set's design significantly impacts convergence speed and
final performance, with SO-informed route sets leading to faster learning and
better outcomes. This work provides a theoretically grounded and practically
relevant approach to bridging individual routing behavior with system-level
efficiency through learning-based sequential assignment.

</details>


### [164] [Controllable Logical Hypothesis Generation for Abductive Reasoning in Knowledge Graphs](https://arxiv.org/abs/2505.20948)
*Yisen Gao, Jiaxin Bai, Tianshi Zheng, Qingyun Sun, Ziwei Zhang, Jianxin Li, Yangqiu Song, Xingcheng Fu*

**主要类别:** cs.AI

**概要:** 在知识图谱中，为了生成更实用的假设，本文提出了一个可控制的假设生成框架CtrlHGen。它通过监督学习和强化学习训练，采用子逻辑分解策略增强数据集，并使用平滑语义奖励和条件依从性奖励来解决假设空间坍缩和假设过度敏感的问题。实验表明，该模型在遵循控制条件和语义相似性方面优于基线模型。


<details>
  <summary>更多</summary>
  
**动机:** 由于缺乏可控性，大规模知识图谱上的单一观察可能产生大量冗余或不相关的假设。为了解决这个问题，需要引入一种新的方法，即可控假设生成任务，以提高归纳推理的实际应用价值。

**方法:** 提出了一种名为CtrlHGen的可控制假设生成框架，该框架通过两阶段范式进行训练：监督学习和随后的强化学习。设计了一种基于子逻辑分解的数据集增强策略，使模型能够通过利用简单组件中的语义模式来学习复杂的逻辑结构。同时，结合了包含Dice和Overlap分数的平滑语义奖励以及条件依从性奖励，以引导生成符合用户指定控制约束的假设。

**结果:** 广泛的实验结果表明，与基线模型相比，所提出的模型不仅更好地遵循控制条件，而且在语义相似性性能上也表现出色。

**结论:** 提出的CtrlHGen框架有效地解决了假设空间坍缩和假设过度敏感的问题，提高了生成假设的质量和实用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Controllable+Logical+Hypothesis+Generation+for+Abductive+Reasoning+in+Knowledge+Graphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20948，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20948&send_immediately=true&force_search=false)

**原文摘要:** Abductive reasoning in knowledge graphs aims to generate plausible logical
hypotheses from observed entities, with broad applications in areas such as
clinical diagnosis and scientific discovery. However, due to a lack of
controllability, a single observation may yield numerous plausible but
redundant or irrelevant hypotheses on large-scale knowledge graphs. To address
this limitation, we introduce the task of controllable hypothesis generation to
improve the practical utility of abductive reasoning. This task faces two key
challenges when controlling for generating long and complex logical hypotheses:
hypothesis space collapse and hypothesis oversensitivity. To address these
challenges, we propose CtrlHGen, a Controllable logcial Hypothesis Generation
framework for abductive reasoning over knowledge graphs, trained in a two-stage
paradigm including supervised learning and subsequent reinforcement learning.
To mitigate hypothesis space collapse, we design a dataset augmentation
strategy based on sub-logical decomposition, enabling the model to learn
complex logical structures by leveraging semantic patterns in simpler
components. To address hypothesis oversensitivity, we incorporate smoothed
semantic rewards including Dice and Overlap scores, and introduce a
condition-adherence reward to guide the generation toward user-specified
control constraints. Extensive experiments on three benchmark datasets
demonstrate that our model not only better adheres to control conditions but
also achieves superior semantic similarity performance compared to baselines.

</details>


### [165] [Large Language Model-enhanced Reinforcement Learning for Low-Altitude Economy Networking](https://arxiv.org/abs/2505.21045)
*Lingyi Cai, Ruichen Zhang, Changyuan Zhao, Yu Zhang, Jiawen Kang, Dusit Niyato, Tao Jiang, Xuemin Shen*

**主要类别:** cs.AI

**概要:** 本论文探讨了如何将大语言模型（LLMs）与强化学习（RL）结合，以解决低空经济网络（LAENet）面临的复杂决策、资源限制和环境不确定性等问题。提出了一种增强型RL框架，并通过案例研究展示了LLMs在设计奖励函数方面的潜力，从而提升RL的学习性能。


<details>
  <summary>更多</summary>
  
**动机:** LAENet旨在支持1000米以下的多样化飞行应用，但复杂的决策、资源约束和环境不确定性对其发展构成重大挑战。虽然RL提供了解决方案，但其在泛化能力、奖励设计和模型稳定性方面存在局限性。

**方法:** 论文首先介绍了如何利用LLMs的生成、上下文理解和结构化推理能力将其整合到RL中。然后提出了一个LLM增强的RL框架，将LLMs作为信息处理器、奖励设计师、决策者和生成器应用于LAENet。此外，还进行了一项案例研究，使用LLMs设计奖励函数以提高RL在LAENet中的学习表现。

**结果:** 研究表明，使用LLMs设计奖励函数可以有效改善RL在LAENet中的学习性能。

**结论:** LLMs为RL在LAENet中的应用提供了新的机会，能够缓解现有RL方法的局限性。未来的研究将进一步探索LLMs在不同场景下的潜力及其对LAENet性能的影响。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Large+Language+Model-enhanced+Reinforcement+Learning+for+Low-Altitude+Economy+Networking，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21045，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21045&send_immediately=true&force_search=false)

**原文摘要:** Low-Altitude Economic Networking (LAENet) aims to support diverse flying
applications below 1,000 meters by deploying various aerial vehicles for
flexible and cost-effective aerial networking. However, complex
decision-making, resource constraints, and environmental uncertainty pose
significant challenges to the development of the LAENet. Reinforcement learning
(RL) offers a potential solution in response to these challenges but has
limitations in generalization, reward design, and model stability. The
emergence of large language models (LLMs) offers new opportunities for RL to
mitigate these limitations. In this paper, we first present a tutorial about
integrating LLMs into RL by using the capacities of generation, contextual
understanding, and structured reasoning of LLMs. We then propose an
LLM-enhanced RL framework for the LAENet in terms of serving the LLM as
information processor, reward designer, decision-maker, and generator.
Moreover, we conduct a case study by using LLMs to design a reward function to
improve the learning performance of RL in the LAENet. Finally, we provide a
conclusion and discuss future work.

</details>


### [166] [Agent-Environment Alignment via Automated Interface Generation](https://arxiv.org/abs/2505.21055)
*Kaiming Liu, Xuanyu Lei, Ziyue Wang, Peng Li, Yang Liu*

**主要类别:** cs.AI

**概要:** 本研究提出了一种名为ALIGN的框架，通过自动生成接口来缓解智能体与环境之间的错位问题，从而提升智能体在多种任务中的性能。实验表明，该方法可以显著提高成功率，并且适用于不同的智能体架构和语言模型后端。


<details>
  <summary>更多</summary>
  
**动机:** 尽管现有研究已经投入大量精力改进智能体策略和环境设计，但智能体与环境之间的接口作用仍然未被充分探索。智能体与环境之间的错位（agent-environment misalignment）严重影响了智能体的表现，因此需要一种新的方法来解决这个问题。

**方法:** 研究人员提出了一个名为ALIGN的框架，该框架通过丰富接口信息来缓解智能体与环境之间的错位问题。具体来说，ALIGN生成的接口增强了环境的静态信息和每一步的观察结果。该接口作为一个轻量级包装器实现，无需修改智能体逻辑或环境代码即可完成对齐。

**结果:** 实验结果表明，ALIGN框架在多个领域中表现出一致的性能提升，包括实体任务、网页导航和工具使用等。在ALFWorld中，成功率达到45.67%的提升。此外，ALIGN生成的接口可以在不同智能体架构和语言模型后端之间泛化，而无需重新生成接口。

**结论:** 智能体与环境之间的错位是影响智能体性能的重要瓶颈。通过引入ALIGN框架，可以有效缓解这一问题并提升智能体表现。该方法具有广泛的适用性，无需针对不同智能体或环境进行特殊调整。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Agent-Environment+Alignment+via+Automated+Interface+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21055，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21055&send_immediately=true&force_search=false)

**原文摘要:** Large language model (LLM) agents have shown impressive reasoning
capabilities in interactive decision-making tasks. These agents interact with
environment through intermediate interfaces, such as predefined action spaces
and interaction rules, which mediate the perception and action. However,
mismatches often happen between the internal expectations of the agent
regarding the influence of its issued actions and the actual state transitions
in the environment, a phenomenon referred to as \textbf{agent-environment
misalignment}. While prior work has invested substantially in improving agent
strategies and environment design, the critical role of the interface still
remains underexplored. In this work, we empirically demonstrate that
agent-environment misalignment poses a significant bottleneck to agent
performance. To mitigate this issue, we propose \textbf{ALIGN}, an
\underline{A}uto-A\underline{l}igned \underline{I}nterface
\underline{G}e\underline{n}eration framework that alleviates the misalignment
by enriching the interface. Specifically, the ALIGN-generated interface
enhances both the static information of the environment and the step-wise
observations returned to the agent. Implemented as a lightweight wrapper, this
interface achieves the alignment without modifying either the agent logic or
the environment code. Experiments across multiple domains including embodied
tasks, web navigation and tool-use, show consistent performance improvements,
with up to a 45.67\% success rate improvement observed in ALFWorld. Meanwhile,
ALIGN-generated interface can generalize across different agent architectures
and LLM backbones without interface regeneration. Code and experimental results
are available at https://github.com/THUNLP-MT/ALIGN.

</details>


### [167] [Why Distillation can Outperform Zero-RL: The Role of Flexible Reasoning](https://arxiv.org/abs/2505.21067)
*Xiao Hu, Xingyu Lu, Liyuan Mao, YiFan Zhang, Tianke Zhang, Bin Wen, Fan Yang, Tingting Gao, Guorui Zhou*

**主要类别:** cs.AI

**概要:** 尽管强化学习（RL）在提升大语言模型（LLMs）推理能力方面发挥了重要作用，但本文研究表明，在仅使用920个样本的情况下，基于基础模型的简单蒸馏方法能够明显优于零样本强化学习（zero-RL），后者通常需要更多的数据和计算成本。通过分析模型输出中的标记频率，发现蒸馏模型表现出更灵活的推理能力，并且增强了两种高级认知行为：多视角思考和元认知意识。而zero-RL未能显著提高这些行为的频率。


<details>
  <summary>更多</summary>
  
**动机:** 研究强化学习（RL）在提升语言模型推理能力中的作用，同时探讨是否存在更高效的方法可以在较少的数据和计算成本下达到或超越RL的效果。

**方法:** 采用基于基础模型的简单蒸馏方法与zero-RL进行对比实验，使用920个样例，并通过分析模型输出中的标记频率来评估不同模型的推理灵活性及高级认知行为的表现。

**结果:** 蒸馏模型在少量数据的情况下展现出比zero-RL更好的推理灵活性，更多地使用拟人化标记和逻辑连接词，并增强了两种高级认知行为的出现频率，从而更好地解决复杂推理问题。

**结论:** 在提升语言模型推理能力方面，基于基础模型的蒸馏方法可以作为一种更高效、低成本的替代方案，其效果优于zero-RL，尤其是在增强模型推理灵活性和高级认知行为方面。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Why+Distillation+can+Outperform+Zero-RL%3A+The+Role+of+Flexible+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21067，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21067&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement learning (RL) has played an important role in improving the
reasoning ability of large language models (LLMs). Some studies apply RL
directly to \textit{smaller} base models (known as zero-RL) and also achieve
notable progress. However, in this paper, we show that using only 920 examples,
a simple distillation method based on the base model can clearly outperform
zero-RL, which typically requires much more data and computational cost. By
analyzing the token frequency in model outputs, we find that the distilled
model shows more flexible reasoning. It uses anthropomorphic tokens and logical
connectors much more often than the zero-RL model. Further analysis reveals
that distillation enhances the presence of two advanced cognitive behaviors:
Multi-Perspective Thinking or Attempting and Metacognitive Awareness. Frequent
occurrences of these two advanced cognitive behaviors give rise to flexible
reasoning, which is essential for solving complex reasoning problems, while
zero-RL fails to significantly boost the frequency of these behaviors.

</details>


### [168] [Interpreting Social Bias in LVLMs via Information Flow Analysis and Multi-Round Dialogue Evaluation](https://arxiv.org/abs/2505.21106)
*Zhengyang Ji, Yifan Jia, Shang Gao, Yutao Yue*

**主要类别:** cs.AI

**概要:** Large Vision Language Models (LVLMs) show social biases due to imbalanced internal information utilization. This study proposes an explanatory framework combining information flow analysis with multi-round dialogue evaluation to understand the origin of these biases.


<details>
  <summary>更多</summary>
  
**动机:** 尽管现有的研究主要集中在检测和量化这些偏差，但对模型内部机制的洞察有限。因此，本文旨在填补这一空白，提出一个解释性框架，结合信息流分析与多轮对话评估，从模型内部信息利用不平衡的角度理解社会偏见的来源。

**方法:** 首先，通过信息流分析识别出在模型推理过程中涉及高贡献图像标记的中立问题。然后，设计一个多回合对话机制，评估这些关键标记在多大程度上编码了敏感信息。此外，从文本模式的角度补充研究结果，展示模型的语义表示已经显示出偏向性的接近模式，从而提供了一个跨模态的偏见形成解释。

**结果:** 广泛的实验表明，大型视觉语言模型在处理不同人口群体的图像时，在信息使用上表现出系统性的差异，这表明社会偏见深深植根于模型的内部推理动态之中。

**结论:** 这项研究表明，社会偏见源于模型内部推理动态中的系统性差异，并且这种偏见不仅体现在图像处理上，还反映在模型的语义表示中。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interpreting+Social+Bias+in+LVLMs+via+Information+Flow+Analysis+and+Multi-Round+Dialogue+Evaluation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21106，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21106&send_immediately=true&force_search=false)

**原文摘要:** Large Vision Language Models (LVLMs) have achieved remarkable progress in
multimodal tasks, yet they also exhibit notable social biases. These biases
often manifest as unintended associations between neutral concepts and
sensitive human attributes, leading to disparate model behaviors across
demographic groups. While existing studies primarily focus on detecting and
quantifying such biases, they offer limited insight into the underlying
mechanisms within the models. To address this gap, we propose an explanatory
framework that combines information flow analysis with multi-round dialogue
evaluation, aiming to understand the origin of social bias from the perspective
of imbalanced internal information utilization. Specifically, we first identify
high-contribution image tokens involved in the model's reasoning process for
neutral questions via information flow analysis. Then, we design a multi-turn
dialogue mechanism to evaluate the extent to which these key tokens encode
sensitive information. Extensive experiments reveal that LVLMs exhibit
systematic disparities in information usage when processing images of different
demographic groups, suggesting that social bias is deeply rooted in the model's
internal reasoning dynamics. Furthermore, we complement our findings from a
textual modality perspective, showing that the model's semantic representations
already display biased proximity patterns, thereby offering a cross-modal
explanation of bias formation.

</details>


### [169] [Interpretable DNFs](https://arxiv.org/abs/2505.21212)
*Martin C. Cooper, Imane Bousdira, Clément Carbonnel*

**主要类别:** cs.AI

**概要:** 本论文研究了可解释的DNF公式，特别是其补集也能表示为$k$-DNFs的情况，并通过实验表明嵌套$k$-DNFs在可解释性和准确性上是决策树的一个有趣替代方案。


<details>
  <summary>更多</summary>
  
**动机:** 当前对于分类器可解释性的研究主要集中在能够简单解释每个决策的模型上。DNF公式作为一种二元分类器，其解释的大小由公式的项大小决定。为了使DNF公式对正负决策都具有可解释性，需要确保其补集也能以有限大小的DNF形式表达。

**方法:** 研究了$k$-DNFs及其补集同样可以表示为$k$-DNFs的情况。比较了两种模型族：深度为$k$的决策树和一种新的模型族——嵌套$k$-DNFs。

**结果:** 实验结果表明，嵌套$k$-DNFs在可解释性和准确性方面都是决策树的有趣替代品。

**结论:** 嵌套$k$-DNFs提供了一种新的、有效的模型选择，在保持可解释性的同时提高了分类性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interpretable+DNFs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21212，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21212&send_immediately=true&force_search=false)

**原文摘要:** A classifier is considered interpretable if each of its decisions has an
explanation which is small enough to be easily understood by a human user. A
DNF formula can be seen as a binary classifier $\kappa$ over boolean domains.
The size of an explanation of a positive decision taken by a DNF $\kappa$ is
bounded by the size of the terms in $\kappa$, since we can explain a positive
decision by giving a term of $\kappa$ that evaluates to true. Since both
positive and negative decisions must be explained, we consider that
interpretable DNFs are those $\kappa$ for which both $\kappa$ and
$\overline{\kappa}$ can be expressed as DNFs composed of terms of bounded size.
In this paper, we study the family of $k$-DNFs whose complements can also be
expressed as $k$-DNFs. We compare two such families, namely depth-$k$ decision
trees and nested $k$-DNFs, a novel family of models. Experiments indicate that
nested $k$-DNFs are an interesting alternative to decision trees in terms of
interpretability and accuracy.

</details>


### [170] [XBOUND: Exploring the Capability Boundaries of Device-Control Agents through Trajectory Tree Exploration](https://arxiv.org/abs/2505.21279)
*Shaoqing Zhang, Kehai Chen, Zhuosheng Zhang, Rumei Li, Rongxiang Weng, Yang Xiang, Liqiang Nie, Min Zhang*

**主要类别:** cs.AI

**概要:** 近期视觉-语言模型（VLMs）的发展促使了设备控制代理（DC agents）的兴趣增加，例如利用真实环境中的设备控制来管理图形用户界面。传统的评估方法只能提供宏观视角，无法深入洞察实际应用中可能出现的错误。本文提出了XBOUND评估方法，通过计算新的探索度量来界定DC代理的能力边界，并开发了一个基于Android Control测试数据的“伪”事件树数据集。使用该数据集和XBOUND，全面评估了OS-Atlas和UI-TARS系列在五个常见任务上的整体和具体表现，同时指出它们的不足和局限性。


<details>
  <summary>更多</summary>
  
**动机:** 当前评估DC代理的方法仅能提供宏观视角，缺乏对潜在错误的微观洞察，因此需要一种更精细的评估方法。

**方法:** 提出XBOUND评估方法，通过计算新的探索度量来界定DC代理的能力边界，关注个体状态以评估DC代理在这些状态下的熟练程度。并开发了一个基于Android Control测试数据的“伪”事件树数据集用于评估。

**结果:** 通过XBOUND评估方法和新数据集，全面分析了OS-Atlas和UI-TARS系列在五个常见任务上的表现，揭示了其优势与不足。

**结论:** XBOUND为DC代理提供了更精细的评估视角，能够更好地揭示其能力边界及潜在问题，推动未来研究改进。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是XBOUND%3A+Exploring+the+Capability+Boundaries+of+Device-Control+Agents+through+Trajectory+Tree+Exploration，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21279，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21279&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in vision-language models (VLMs) have spurred increased
interest in Device-Control Agents (DC agents), such as utilizing in-the-wild
device control to manage graphical user interfaces. Conventional methods for
assessing the capabilities of DC agents, such as computing step-wise action
accuracy and overall task success rates, provide a macroscopic view of DC
agents' performance; however, they fail to offer microscopic insights into
potential errors that may occur in real-world applications. Conducting a
finer-grained performance evaluation of DC agents presents significant
challenges. This study introduces a new perspective on evaluation methods for
DC agents by proposing the XBOUND evaluation method, which employs the
calculation of a novel Explore Metric to delineate the capability boundaries of
DC agents. Compared to previous evaluation methods, XBOUND focuses on
individual states to assess the proficiency of DC agents in mastering these
states. Furthermore, we have developed a ``pseudo'' episode tree dataset
derived from Android Control test data. Utilizing this dataset and XBOUND, we
comprehensively evaluate the OS-Atlas and UI-TARS series, examining both the
overall and specific performance across five common tasks. Additionally, we
select representative cases to highlight the current deficiencies and
limitations inherent in both series. Code is available at
https://github.com/sqzhang-lazy/XBOUND.

</details>


### [171] [RLJP: Legal Judgment Prediction via First-Order Logic Rule-enhanced with Large Language Models](https://arxiv.org/abs/2505.21281)
*Yue Zhang, Zhiliang Tian, Shicheng Zhou, Haiyang Wang, Wenqing Hou, Yuying Liu, Xuechen Zhao, Minlie Huang, Ye Wang, Bin Zhou*

**主要类别:** cs.AI

**概要:** 提出了一种基于一阶逻辑形式主义和对比学习的规则增强法律判决预测框架，通过三阶段方法进行准确的复杂推理逻辑捕捉、动态优化判决规则以及预测法律判决，实验结果在两个公开数据集上表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 现有的语义增强法律判决预测模型虽然结合了司法先例和法律知识，但忽视了法律推理逻辑；而一些利用法律推理逻辑的方法由于其逻辑刚性难以适应特定案件的逻辑框架，尤其是在复杂案件中。

**方法:** 该方法受人类备考过程启发，采用三阶段策略：1) 使用一阶逻辑形式主义初始化判决规则以准确捕捉复杂推理逻辑；2) 提出一种混淆感知对比学习(CACL)方法，通过由易混淆案例组成的“测验”动态优化判决规则；3) 利用优化后的判决规则预测法律判决。

**结果:** 在两个公开数据集上的实验结果表明，该方法在所有指标上均表现出优越性能。

**结论:** 所提出的基于一阶逻辑形式主义和对比学习的规则增强法律判决预测框架能够开发出法律判决逻辑的自适应调整机制，并进一步提升法律判决预测任务的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是RLJP%3A+Legal+Judgment+Prediction+via+First-Order+Logic+Rule-enhanced+with+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21281，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21281&send_immediately=true&force_search=false)

**原文摘要:** Legal Judgment Prediction (LJP) is a pivotal task in legal AI. Existing
semantic-enhanced LJP models integrate judicial precedents and legal knowledge
for high performance. But they neglect legal reasoning logic, a critical
component of legal judgments requiring rigorous logical analysis. Although some
approaches utilize legal reasoning logic for high-quality predictions, their
logic rigidity hinders adaptation to case-specific logical frameworks,
particularly in complex cases that are lengthy and detailed. This paper
proposes a rule-enhanced legal judgment prediction framework based on
first-order logic (FOL) formalism and comparative learning (CL) to develop an
adaptive adjustment mechanism for legal judgment logic and further enhance
performance in LJP. Inspired by the process of human exam preparation, our
method follows a three-stage approach: first, we initialize judgment rules
using the FOL formalism to capture complex reasoning logic accurately; next, we
propose a Confusion-aware Contrastive Learning (CACL) to dynamically optimize
the judgment rules through a quiz consisting of confusable cases; finally, we
utilize the optimized judgment rules to predict legal judgments. Experimental
results on two public datasets show superior performance across all metrics.
The code is publicly available{https://anonymous.4open.science/r/RLJP-FDF1}.

</details>


### [172] [Complex System Diagnostics Using a Knowledge Graph-Informed and Large Language Model-Enhanced Framework](https://arxiv.org/abs/2505.21291)
*Saman Marandi, Yu-Shu Hu, Mohammad Modarres*

**主要类别:** cs.AI

**概要:** 本文提出了一种结合知识图谱(KGs)和大语言模型(LLMs)的新型诊断框架，用于支持如核电站等高可靠性系统的系统诊断。通过动态主逻辑(DML)模型的功能建模原则，该框架包含两个协调的LLM组件：一个用于从系统文档中自动构建DML逻辑的工作流，以及一个用于交互式诊断的LLM代理。生成的逻辑被编码为结构化的KG-DML，支持分层故障推理，并可通过专家知识或操作数据进行改进。用户可以提交自然语言查询，LLM代理将选择适当的工具进行结构化推理。对于一般查询，采用基于图的检索增强生成(Graph-RAG)方法。案例研究表明，该框架在关键元素上的准确率超过90%，并在工具和参数提取方面表现一致，适用于安全关键诊断。


<details>
  <summary>更多</summary>
  
**动机:** 传统的诊断建模在系统过于复杂时面临困难，功能建模成为更具吸引力的方法。因此需要一种新的诊断框架来应对复杂系统的挑战，尤其是在高可靠性环境中（如核电站）。

**方法:** 该方法引入了一个基于动态主逻辑(DML)模型的功能建模原则的诊断框架。框架包含：1) 一个基于LLM的工作流，用于从系统文档中自动生成DML逻辑；2) 一个LLM代理，用于支持交互式诊断。生成的逻辑被编码为结构化的知识图谱(KG-DML)，支持分层故障推理。此外，还可以整合专家知识或操作数据以提高模型精度和诊断深度。

**结果:** 在辅助给水系统的案例研究中，该框架显示出有效性，关键元素的准确率超过90%，并且在工具和参数提取方面表现一致。这表明该框架可以成功应用于安全关键诊断。

**结论:** 所提出的结合知识图谱和大语言模型的诊断框架能够有效支持高可靠性系统的系统诊断，特别是在复杂环境下。其准确性和一致性使其成为安全关键应用中的可靠选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Complex+System+Diagnostics+Using+a+Knowledge+Graph-Informed+and+Large+Language+Model-Enhanced+Framework，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21291，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21291&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we present a novel diagnostic framework that integrates
Knowledge Graphs (KGs) and Large Language Models (LLMs) to support system
diagnostics in high-reliability systems such as nuclear power plants.
Traditional diagnostic modeling struggles when systems become too complex,
making functional modeling a more attractive approach. Our approach introduces
a diagnostic framework grounded in the functional modeling principles of the
Dynamic Master Logic (DML) model. It incorporates two coordinated LLM
components, including an LLM-based workflow for automated construction of DML
logic from system documentation and an LLM agent that facilitates interactive
diagnostics. The generated logic is encoded into a structured KG, referred to
as KG-DML, which supports hierarchical fault reasoning. Expert knowledge or
operational data can also be incorporated to refine the model's precision and
diagnostic depth. In the interaction phase, users submit natural language
queries, which are interpreted by the LLM agent. The agent selects appropriate
tools for structured reasoning, including upward and downward propagation
across the KG-DML. Rather than embedding KG content into every prompt, the LLM
agent distinguishes between diagnostic and interpretive tasks. For diagnostics,
the agent selects and executes external tools that perform structured KG
reasoning. For general queries, a Graph-based Retrieval-Augmented Generation
(Graph-RAG) approach is used, retrieving relevant KG segments and embedding
them into the prompt to generate natural explanations. A case study on an
auxiliary feedwater system demonstrated the framework's effectiveness, with
over 90% accuracy in key elements and consistent tool and argument extraction,
supporting its use in safety-critical diagnostics.

</details>


### [173] [Beyond Chemical QA: Evaluating LLM's Chemical Reasoning with Modular Chemical Operations](https://arxiv.org/abs/2505.21318)
*Hao Li, He Cao, Bin Feng, Yanjun Shao, Xiangru Tang, Zhiyuan Yan, Li Yuan, Yonghong Tian, Yu Li*

**主要类别:** cs.AI

**概要:** 这篇论文提出了一种名为ChemCoTBench的框架，将分子结构理解与算术启发的操作相结合，以系统化的方式解决化学问题，并通过两个任务评估模型：分子性质优化和化学反应预测。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型（LLMs）在数学和编码方面表现出色，但在需要严谨结构分析的化学领域尚未得到充分挖掘。当前基准测试仅关注简单的知识检索，而忽略了复杂任务所需的逐步推理。

**方法:** 引入了ChemCoTBench框架，该框架将分子结构理解与算术启发的操作（如添加、删除和替换）结合，将化学问题解决形式化为透明的逐步工作流程。通过将分子转换视为模块化的“化学操作”，框架实现了类似于数学证明的逐步推理。

**结果:** 通过在分子性质优化和化学反应预测这两个高影响力任务上的评估，证明了该框架的有效性，并提供了注释数据集、推理分类法和基线评估结果。

**结论:** ChemCoTBench填补了抽象推理方法与实际化学发现之间的空白，为推动LLMs作为AI驱动科学创新的工具奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Beyond+Chemical+QA%3A+Evaluating+LLM%27s+Chemical+Reasoning+with+Modular+Chemical+Operations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21318，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21318&send_immediately=true&force_search=false)

**原文摘要:** While large language models (LLMs) with Chain-of-Thought (CoT) reasoning
excel in mathematics and coding, their potential for systematic reasoning in
chemistry, a domain demanding rigorous structural analysis for real-world tasks
like drug design and reaction engineering, remains untapped. Current benchmarks
focus on simple knowledge retrieval, neglecting step-by-step reasoning required
for complex tasks such as molecular optimization and reaction prediction. To
address this, we introduce ChemCoTBench, a reasoning framework that bridges
molecular structure understanding with arithmetic-inspired operations,
including addition, deletion, and substitution, to formalize chemical
problem-solving into transparent, step-by-step workflows. By treating molecular
transformations as modular "chemical operations", the framework enables
slow-thinking reasoning, mirroring the logic of mathematical proofs while
grounding solutions in real-world chemical constraints. We evaluate models on
two high-impact tasks: Molecular Property Optimization and Chemical Reaction
Prediction. These tasks mirror real-world challenges while providing structured
evaluability. By providing annotated datasets, a reasoning taxonomy, and
baseline evaluations, ChemCoTBench bridges the gap between abstract reasoning
methods and practical chemical discovery, establishing a foundation for
advancing LLMs as tools for AI-driven scientific innovation.

</details>


### [174] [Assured Autonomy with Neuro-Symbolic Perception](https://arxiv.org/abs/2505.21322)
*R. Spencer Hallyburton, Miroslav Pajic*

**主要类别:** cs.AI

**概要:** 通过融合数据驱动感知模型与符号结构，提出了一种新的神经符号范式（NeuSPaPer），以提升AI在关键领域的可靠性。结合对象检测和场景图生成技术，设计了一个框架，利用结构化关系图确保自主系统的情境感知完整性，并通过物理模拟器和真实数据集验证了方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 当前部署于赛博-物理系统（CPS）中的先进AI模型虽然准确率高，但本质上只是模式匹配器，缺乏足够的安全性保障，这引发了对其在安全关键领域和竞争环境中的可靠性的担忧。

**方法:** 提出了一种神经符号范式（NeuSPaPer），将数据驱动的感知模型与符号结构相结合，受到人类对低级特征和高级上下文推理能力的启发。该方法通过联合对象检测和场景图生成（SGG）实现深度场景理解，利用基础模型进行离线知识提取，以及专门的SGG算法进行实时部署，构建了一个基于结构化关系图的框架。

**结果:** 使用基于物理的模拟器和真实世界数据集，证明了场景图生成（SGG）能够弥合低级传感器感知与高级推理之间的差距，为弹性、上下文感知的AI奠定了基础，并推动了CPS中可信自主性的进展。

**结论:** 神经符号范式（NeuSPaPer）提供了一种有前景的方向，可以增强AI模型的安全性和可靠性，特别是在需要情境感知和信任的关键领域中，这种方法有望推动更可靠的自主系统的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Assured+Autonomy+with+Neuro-Symbolic+Perception，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21322，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21322&send_immediately=true&force_search=false)

**原文摘要:** Many state-of-the-art AI models deployed in cyber-physical systems (CPS),
while highly accurate, are simply pattern-matchers.~With limited security
guarantees, there are concerns for their reliability in safety-critical and
contested domains. To advance assured AI, we advocate for a paradigm shift that
imbues data-driven perception models with symbolic structure, inspired by a
human's ability to reason over low-level features and high-level context. We
propose a neuro-symbolic paradigm for perception (NeuSPaPer) and illustrate how
joint object detection and scene graph generation (SGG) yields deep scene
understanding.~Powered by foundation models for offline knowledge extraction
and specialized SGG algorithms for real-time deployment, we design a framework
leveraging structured relational graphs that ensures the integrity of
situational awareness in autonomy. Using physics-based simulators and
real-world datasets, we demonstrate how SGG bridges the gap between low-level
sensor perception and high-level reasoning, establishing a foundation for
resilient, context-aware AI and advancing trusted autonomy in CPS.

</details>


### [175] [MME-Reasoning: A Comprehensive Benchmark for Logical Reasoning in MLLMs](https://arxiv.org/abs/2505.21327)
*Jiakang Yuan, Tianshuo Peng, Yilei Jiang, Yiting Lu, Renrui Zhang, Kaituo Feng, Chaoyou Fu, Tao Chen, Lei Bai, Bo Zhang, Xiangyu Yue*

**主要类别:** cs.AI

**概要:** 这篇论文提出了一种新的基准测试MME-Reasoning，用于评估多模态大语言模型（MLLMs）的逻辑推理能力。该基准涵盖了归纳、演绎和溯因三种推理类型，并揭示了当前最先进的MLLMs在综合逻辑推理方面的显著局限性和性能不平衡问题。此外，论文还深入分析了如“思维模式”和基于规则的强化学习等方法对提升推理能力的效果。


<details>
  <summary>更多</summary>
  
**动机:** 现有的多模态推理基准无法全面评估模型的推理能力，因为缺乏对逻辑推理类型的明确分类以及对推理理解的不清晰。

**方法:** 引入了一个名为MME-Reasoning的全面基准，包含归纳、演绎和溯因三种推理类型的问题，确保每个问题都能有效评估模型的推理能力而非感知技能或知识广度，并扩展了评估协议以涵盖多样化的题目。

**结果:** 评估显示，即使是最先进的MLLMs在综合逻辑推理方面表现有限，且在不同推理类型上存在显著的性能不平衡。此外，常见被认为能增强推理能力的方法如‘思维模式’和基于规则的强化学习的实际效果也得到了深入分析。

**结论:** 当前MLLMs在多种逻辑推理场景中存在关键局限和性能不平衡，需要更全面和系统地理解和评估其推理能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MME-Reasoning%3A+A+Comprehensive+Benchmark+for+Logical+Reasoning+in+MLLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21327，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21327&send_immediately=true&force_search=false)

**原文摘要:** Logical reasoning is a fundamental aspect of human intelligence and an
essential capability for multimodal large language models (MLLMs). Despite the
significant advancement in multimodal reasoning, existing benchmarks fail to
comprehensively evaluate their reasoning abilities due to the lack of explicit
categorization for logical reasoning types and an unclear understanding of
reasoning. To address these issues, we introduce MME-Reasoning, a comprehensive
benchmark designed to evaluate the reasoning ability of MLLMs, which covers all
three types of reasoning (i.e., inductive, deductive, and abductive) in its
questions. We carefully curate the data to ensure that each question
effectively evaluates reasoning ability rather than perceptual skills or
knowledge breadth, and extend the evaluation protocols to cover the evaluation
of diverse questions. Our evaluation reveals substantial limitations of
state-of-the-art MLLMs when subjected to holistic assessments of logical
reasoning capabilities. Even the most advanced MLLMs show limited performance
in comprehensive logical reasoning, with notable performance imbalances across
reasoning types. In addition, we conducted an in-depth analysis of approaches
such as ``thinking mode'' and Rule-based RL, which are commonly believed to
enhance reasoning abilities. These findings highlight the critical limitations
and performance imbalances of current MLLMs in diverse logical reasoning
scenarios, providing comprehensive and systematic insights into the
understanding and evaluation of reasoning capabilities.

</details>


### [176] [The Multilingual Divide and Its Impact on Global AI Safety](https://arxiv.org/abs/2505.21344)
*Aidan Peppin, Julia Kreutzer, Alice Schoenauer Sebag, Kelly Marchisio, Beyza Ermis, John Dang, Samuel Cahyawijaya, Shivalika Singh, Seraphina Goldfarb-Tarrant, Viraat Aryabumi, Aakanksha, Wei-Yin Ko, Ahmet Üstün, Matthias Gallé, Marzieh Fadaee, Sara Hooker*

**主要类别:** cs.AI

**概要:** 尽管近年来大型语言模型的能力有所提升，但在许多非全球主流语言上，其能力和安全性仍存在较大差距。本文为研究人员、政策制定者和治理专家概述了弥合AI '语言鸿沟' 和最小化跨语言安全风险的关键挑战。我们分析了为什么AI中的语言鸿沟存在并扩大，以及它如何造成全球AI安全的差异。我们确定了解决这些挑战的障碍，并建议通过支持多语言数据集创建、透明度和研究来解决与语言鸿沟相关的安全问题。


<details>
  <summary>更多</summary>
  
**动机:** 在除了少数全球主流语言之外的许多语言中，大型语言模型的能力和安全性仍然存在很大差距。这种差距导致了全球AI安全的不平等，需要找到方法来缩小这一差距并降低相关风险。

**方法:** 通过分析AI语言鸿沟的存在原因及增长机制，识别出造成全球AI安全差异的因素，明确解决这些挑战所面临的障碍，并提出针对政策和治理工作的建议以应对这些安全问题。这些建议包括支持多语言数据集创建、提高透明度和推动相关研究。

**结果:** 提供了对AI语言鸿沟及其引发的安全问题的深入理解，明确了缩小这一鸿沟所面临的主要障碍，并提出了相应的政策和治理建议。

**结论:** 为了缩小AI中的语言鸿沟并减少相关安全风险，政策制定者和治理专家需要采取行动，支持多语言数据集的创建、提高透明度和加强研究工作。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Multilingual+Divide+and+Its+Impact+on+Global+AI+Safety，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21344，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21344&send_immediately=true&force_search=false)

**原文摘要:** Despite advances in large language model capabilities in recent years, a
large gap remains in their capabilities and safety performance for many
languages beyond a relatively small handful of globally dominant languages.
This paper provides researchers, policymakers and governance experts with an
overview of key challenges to bridging the "language gap" in AI and minimizing
safety risks across languages. We provide an analysis of why the language gap
in AI exists and grows, and how it creates disparities in global AI safety. We
identify barriers to address these challenges, and recommend how those working
in policy and governance can help address safety concerns associated with the
language gap by supporting multilingual dataset creation, transparency, and
research.

</details>


### [177] [A Structured Unplugged Approach for Foundational AI Literacy in Primary Education](https://arxiv.org/abs/2505.21398)
*Maria Cristina Carrisi, Mirko Marras, Sara Vergallo*

**主要类别:** cs.AI

**概要:** Younger generations are growing up in a world increasingly shaped by intelligent technologies, making early AI literacy crucial. This paper proposes a structured and replicable teaching approach that fosters foundational AI literacy in primary students through core mathematical elements, resulting in improvements in terminology understanding, features description, logical reasoning, and evaluative skills.


<details>
  <summary>更多</summary>
  
**动机:** The motivation is the increasing importance of AI literacy for younger generations growing up in a world shaped by intelligent technologies, and the current lack of conceptual understanding in AI education leading to misconceptions and difficulties in recognizing biases.

**方法:** The method involves a structured and replicable teaching approach fostering foundational AI literacy in primary students, building upon core mathematical elements connected to primary curricula to strengthen conceptualization, data representation, classification reasoning, and evaluation of AI.

**结果:** The results indicate improvements in terminology understanding and usage, features description, logical reasoning, and evaluative skills among fifth-grade students, with deeper comprehension of decision-making processes and their limitations.

**结论:** The conclusion is that the proposed teaching approach effectively enhances AI literacy in primary students, proving engaging particularly when linking AI concepts to real-world reasoning.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Structured+Unplugged+Approach+for+Foundational+AI+Literacy+in+Primary+Education，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21398，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21398&send_immediately=true&force_search=false)

**原文摘要:** Younger generations are growing up in a world increasingly shaped by
intelligent technologies, making early AI literacy crucial for developing the
skills to critically understand and navigate them. However, education in this
field often emphasizes tool-based learning, prioritizing usage over
understanding the underlying concepts. This lack of knowledge leaves
non-experts, especially children, prone to misconceptions, unrealistic
expectations, and difficulties in recognizing biases and stereotypes. In this
paper, we propose a structured and replicable teaching approach that fosters
foundational AI literacy in primary students, by building upon core
mathematical elements closely connected to and of interest in primary
curricula, to strengthen conceptualization, data representation, classification
reasoning, and evaluation of AI. To assess the effectiveness of our approach,
we conducted an empirical study with thirty-one fifth-grade students across two
classes, evaluating their progress through a post-test and a satisfaction
survey. Our results indicate improvements in terminology understanding and
usage, features description, logical reasoning, and evaluative skills, with
students showing a deeper comprehension of decision-making processes and their
limitations. Moreover, the approach proved engaging, with students particularly
enjoying activities that linked AI concepts to real-world reasoning. Materials:
https://github.com/tail-unica/ai-literacy-primary-ed.

</details>


### [178] [MRSD: Multi-Resolution Skill Discovery for HRL Agents](https://arxiv.org/abs/2505.21410)
*Shashank Sharma, Janina Hoffmann, Vinay Namboodiri*

**主要类别:** cs.AI

**概要:** 本研究提出了一种新的分层强化学习框架MRSD，它通过多时间分辨率技能编码器实现更高效的长期任务解决，并在实验中表现出优于现有方法的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的技能发现方法虽然能自动学习抽象技能，但每个任务仅限于单一技能，而人类可以同时使用精细和粗略的运动技能，这启发了研究团队探索更接近人类行为的多分辨率技能学习方法。

**方法:** 研究者提出了多分辨率技能发现（MRSD）框架，该框架并行学习多个不同时间分辨率的技能编码器，由高层管理器动态选择技能，从而实现随时间变化的自适应控制策略。

**结果:** 在DeepMind Control Suite的任务评估中，MRSD框架相较于先前最先进的技能发现和HRL方法，展现出更快的收敛速度和更高的最终性能。

**结论:** 研究结果表明，在分层强化学习中整合多分辨率技能能够显著提升代理的多功能性和效率，为未来开发更高效和灵活的代理铺平道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MRSD%3A+Multi-Resolution+Skill+Discovery+for+HRL+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21410，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21410&send_immediately=true&force_search=false)

**原文摘要:** Hierarchical reinforcement learning (HRL) relies on abstract skills to solve
long-horizon tasks efficiently. While existing skill discovery methods learns
these skills automatically, they are limited to a single skill per task. In
contrast, humans learn and use both fine-grained and coarse motor skills
simultaneously. Inspired by human motor control, we propose Multi-Resolution
Skill Discovery (MRSD), an HRL framework that learns multiple skill encoders at
different temporal resolutions in parallel. A high-level manager dynamically
selects among these skills, enabling adaptive control strategies over time. We
evaluate MRSD on tasks from the DeepMind Control Suite and show that it
outperforms prior state-of-the-art skill discovery and HRL methods, achieving
faster convergence and higher final performance. Our findings highlight the
benefits of integrating multi-resolution skills in HRL, paving the way for more
versatile and efficient agents.

</details>


### [179] [Diagnosing and Resolving Cloud Platform Instability with Multi-modal RAG LLMs](https://arxiv.org/abs/2505.21419)
*Yifan Wang, Kenneth P. Birman*

**主要类别:** cs.AI

**概要:** 当前云托管的应用和服务复杂度高，性能或功能不稳定可能有数十甚至上百个潜在原因。假设通过结合现代AI工具的模式匹配能力和自然多模态RAG LLM接口，可以简化问题识别和解决过程。ARCA是一个针对此领域的新型多模态RAG LLM系统。逐步评估表明，ARCA优于最先进的替代方案。


<details>
  <summary>更多</summary>
  
**动机:** 云托管应用和服务的复杂性导致性能或功能不稳定的潜在原因众多，需要更高效的问题识别与解决方法。

**方法:** 结合现代AI工具的模式匹配能力与自然多模态RAG LLM接口，开发ARCA这一新系统。

**结果:** 逐步评估显示ARCA在问题识别和解决方面优于现有最先进替代方案。

**结论:** ARCA系统能够有效简化复杂云应用中问题的识别与解决过程，并表现出优越性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diagnosing+and+Resolving+Cloud+Platform+Instability+with+Multi-modal+RAG+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21419，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21419&send_immediately=true&force_search=false)

**原文摘要:** Today's cloud-hosted applications and services are complex systems, and a
performance or functional instability can have dozens or hundreds of potential
root causes. Our hypothesis is that by combining the pattern matching
capabilities of modern AI tools with a natural multi-modal RAG LLM interface,
problem identification and resolution can be simplified. ARCA is a new
multi-modal RAG LLM system that targets this domain. Step-wise evaluations show
that ARCA outperforms state-of-the-art alternatives.

</details>


### [180] [Learning Individual Behavior in Agent-Based Models with Graph Diffusion Networks](https://arxiv.org/abs/2505.21426)
*Francesco Cozzi, Marco Pangallo, Alan Perotti, André Panisson, Corrado Monti*

**主要类别:** cs.AI

**概要:** 本研究提出了一种新的框架，通过观察Agent-Based Models（ABMs）生成的数据来学习其可微替代模型。该方法结合了扩散模型和图神经网络，直接模拟个体代理行为而非系统级输出，从而保留了ABM的去中心化、自下而上的动态特性。在Schelling隔离模型和捕食者-猎物生态系统两个案例中验证了该方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的ABMs由于规则通常是不可微分的，限制了基于梯度优化方法的应用，难以与现实世界数据集成。因此需要一种新方法来克服这一限制，同时保留ABM的核心特性。

**方法:** 提出了一种结合扩散模型和图神经网络的框架，用以学习ABM的可微替代模型。该方法通过观察ABM生成的数据，直接建模个体代理行为，而不是近似系统级输出。

**结果:** 在Schelling隔离模型和捕食者-猎物生态系统两个案例中，该方法能够复制个体层面的模式，并准确预测超越训练范围的涌现动态。

**结论:** 该研究表明，结合扩散模型和图学习的方法在数据驱动的ABM仿真中具有潜力，为未来的研究提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Individual+Behavior+in+Agent-Based+Models+with+Graph+Diffusion+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21426，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21426&send_immediately=true&force_search=false)

**原文摘要:** Agent-Based Models (ABMs) are powerful tools for studying emergent properties
in complex systems. In ABMs, agent behaviors are governed by local interactions
and stochastic rules. However, these rules are, in general, non-differentiable,
limiting the use of gradient-based methods for optimization, and thus
integration with real-world data. We propose a novel framework to learn a
differentiable surrogate of any ABM by observing its generated data. Our method
combines diffusion models to capture behavioral stochasticity and graph neural
networks to model agent interactions. Distinct from prior surrogate approaches,
our method introduces a fundamental shift: rather than approximating
system-level outputs, it models individual agent behavior directly, preserving
the decentralized, bottom-up dynamics that define ABMs. We validate our
approach on two ABMs (Schelling's segregation model and a Predator-Prey
ecosystem) showing that it replicates individual-level patterns and accurately
forecasts emergent dynamics beyond training. Our results demonstrate the
potential of combining diffusion models and graph learning for data-driven ABM
simulation.

</details>


### [181] [Policy Induction: Predicting Startup Success via Explainable Memory-Augmented In-Context Learning](https://arxiv.org/abs/2505.21427)
*Xianling Mu, Joseph Ternasky, Fuat Alican, Yigit Ihlamur*

**主要类别:** cs.AI

**概要:** 早期初创企业投资具有高风险，数据稀缺且结果不确定。传统机器学习方法需要大量标记数据和广泛微调，但仍不透明且难以解释。本文提出了一种由记忆增强型大语言模型（LLMs）驱动的透明且高效的数据投资决策框架。该框架通过自然语言策略嵌入LLM提示中，使模型能够应用显式推理模式，并允许人类专家轻松解释、审核和迭代改进逻辑。我们引入了一种轻量级训练过程，结合少量样本学习与上下文学习循环，使LLM能够基于结构化反馈迭代更新其决策策略。在极少监督且无需基于梯度的优化下，我们的系统预测初创企业成功的准确率远高于现有基准，比随机猜测精确20倍以上，并且比顶级风投公司7.1倍更精准。


<details>
  <summary>更多</summary>
  
**动机:** 早期初创企业投资风险高、数据稀缺且结果不确定，而传统机器学习方法存在需要大量数据和广泛微调的问题，同时缺乏透明性和可解释性。因此，需要一种新的方法来解决这些问题，提高投资决策的准确性和效率。

**方法:** 提出了一种由记忆增强型大语言模型（LLMs）驱动的透明且高效的数据投资决策框架。核心方法是将自然语言策略直接嵌入到LLM提示中，使模型能够应用显式推理模式。此外，还引入了一种轻量级训练过程，结合少量样本学习与上下文学习循环，使LLM能够基于结构化反馈迭代更新其决策策略。

**结果:** 该系统仅需极小监督且无需基于梯度的优化，预测初创企业成功的准确率远高于现有基准。它比随机猜测精确20倍以上，并且比顶级风投公司7.1倍更精准。

**结论:** 提出的透明且数据高效的基于记忆增强型大语言模型的投资决策框架，在预测初创企业成功方面表现出显著优越性，为早期投资提供了一种新的有效工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Policy+Induction%3A+Predicting+Startup+Success+via+Explainable+Memory-Augmented+In-Context+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21427，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21427&send_immediately=true&force_search=false)

**原文摘要:** Early-stage startup investment is a high-risk endeavor characterized by
scarce data and uncertain outcomes. Traditional machine learning approaches
often require large, labeled datasets and extensive fine-tuning, yet remain
opaque and difficult for domain experts to interpret or improve. In this paper,
we propose a transparent and data-efficient investment decision framework
powered by memory-augmented large language models (LLMs) using in-context
learning (ICL). Central to our method is a natural language policy embedded
directly into the LLM prompt, enabling the model to apply explicit reasoning
patterns and allowing human experts to easily interpret, audit, and iteratively
refine the logic. We introduce a lightweight training process that combines
few-shot learning with an in-context learning loop, enabling the LLM to update
its decision policy iteratively based on structured feedback. With only minimal
supervision and no gradient-based optimization, our system predicts startup
success far more accurately than existing benchmarks. It is over 20x more
precise than random chance, which succeeds 1.9% of the time. It is also 7.1x
more precise than the typical 5.6% success rate of top-tier venture capital
(VC) firms.

</details>


### [182] [Robust Hypothesis Generation: LLM-Automated Language Bias for Inductive Logic Programming](https://arxiv.org/abs/2505.21486)
*Yang Yang, Jiemin Wu, Yutao Yue*

**主要类别:** cs.AI

**概要:** 本论文提出了一种新的框架，将多智能体系统与归纳逻辑编程（ILP）结合，利用大型语言模型（LLMs）自动从文本数据中生成符号词汇和关系模板，从而克服传统ILP对预定义符号结构的依赖和纯LLM方法对噪声的敏感性。实验表明该方法在多样且复杂的场景中表现出色，为自动、可解释和可验证的假设生成开辟了新途径。


<details>
  <summary>更多</summary>
  
**动机:** 自动化鲁棒假设生成在开放环境中对于AI认知至关重要，但传统ILP方法依赖于预定义的符号结构，而纯LLM方法对噪声敏感，因此需要一种新的方法来解决这些问题。

**方法:** 提出一个结合多智能体系统和归纳逻辑编程的新框架，其中智能体由大型语言模型驱动，能够自主地从原始文本数据中定义结构化的符号词汇和关系模板，并将其转化为ILP求解器可以处理的事实，从而学习可解释的规则。

**结果:** 通过在多样化和具有挑战性的场景中的广泛实验，证明了该方法的优越性能，成功克服了传统ILP和纯LLM方法的局限性。

**结论:** 所提出的框架为自动化、可解释和可验证的假设生成提供了一条新路径，推动了AI认知的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robust+Hypothesis+Generation%3A+LLM-Automated+Language+Bias+for+Inductive+Logic+Programming，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21486，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21486&send_immediately=true&force_search=false)

**原文摘要:** Automating robust hypothesis generation in open environments is pivotal for
AI cognition. We introduce a novel framework integrating a multi-agent system,
powered by Large Language Models (LLMs), with Inductive Logic Programming
(ILP). Our system's LLM agents autonomously define a structured symbolic
vocabulary (predicates) and relational templates , i.e., \emph{language bias}
directly from raw textual data. This automated symbolic grounding (the
construction of the language bias), traditionally an expert-driven bottleneck
for ILP, then guides the transformation of text into facts for an ILP solver,
which inductively learns interpretable rules. This approach overcomes
traditional ILP's reliance on predefined symbolic structures and the
noise-sensitivity of pure LLM methods. Extensive experiments in diverse,
challenging scenarios validate superior performance, paving a new path for
automated, explainable, and verifiable hypothesis generation.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [183] [Differentially private ratio statistics](https://arxiv.org/abs/2505.20351)
*Tomer Shoham, Katrina Ligettt*

**主要类别:** stat.ML

**概要:** 这篇论文探讨了在需要保护差分隐私的情况下评估比率统计量的问题，提出了一种简单但性能良好的算法，并对相对风险的差分隐私估计量进行了分析、证明了其一致性，还开发了构建有效置信区间的实用方法。


<details>
  <summary>更多</summary>
  
**动机:** 尽管差分隐私在许多领域被广泛采用，但关于比率统计量（如相对风险和优势比）的差分隐私研究却很少，因此需要填补这一空白，为实际应用提供指导。

**方法:** 论文首先展示了一个简单的算法，该算法在隐私保护、样本准确性和偏差方面表现出色，不仅在渐近情况下，而且在较小样本量时也是如此。此外，论文还分析了一种用于相对风险的差分隐私估计量，并证明了其一致性，同时开发了一种构造有效置信区间的方法。

**结果:** 研究表明，所提出的简单算法在小样本量下也能提供优秀的隐私保护、样本准确性和低偏差。同时，相对风险的差分隐私估计量被证明是一致的，并且可以构建有效的置信区间。

**结论:** 这篇论文填补了差分隐私文献中的一个空白，为在私有机器学习管道中进行比率估计提供了实用解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Differentially+private+ratio+statistics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20351，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20351&send_immediately=true&force_search=false)

**原文摘要:** Ratio statistics--such as relative risk and odds ratios--play a central role
in hypothesis testing, model evaluation, and decision-making across many areas
of machine learning, including causal inference and fairness analysis. However,
despite privacy concerns surrounding many datasets and despite increasing
adoption of differential privacy, differentially private ratio statistics have
largely been neglected by the literature and have only recently received an
initial treatment by Lin et al. [1]. This paper attempts to fill this lacuna,
giving results that can guide practice in evaluating ratios when the results
must be protected by differential privacy. In particular, we show that even a
simple algorithm can provide excellent properties concerning privacy, sample
accuracy, and bias, not just asymptotically but also at quite small sample
sizes. Additionally, we analyze a differentially private estimator for relative
risk, prove its consistency, and develop a method for constructing valid
confidence intervals. Our approach bridges a gap in the differential privacy
literature and provides a practical solution for ratio estimation in private
machine learning pipelines.

</details>


### [184] [Kernel Quantile Embeddings and Associated Probability Metrics](https://arxiv.org/abs/2505.20433)
*Masha Naslidnyk, Siu Lun Chau, François-Xavier Briol, Krikamol Muandet*

**主要类别:** stat.ML

**概要:** 论文提出了一种新的概率度量方法——核量化嵌入（KQEs），它在较弱的核条件下能有效构建距离度量，恢复切片Wasserstein距离的核化形式，并能以接近线性成本高效估计。该方法为最大平均差异（MMD）及其快速近似提供了一个有竞争力的替代方案。


<details>
  <summary>更多</summary>
  
**动机:** 尽管最大平均差异（MMD）依赖于核均值嵌入来表示分布，但研究者质疑均值函数是否是唯一的有意义的再生核希尔伯特空间（RKHS）表示。基于这一问题，他们受到广义分位数的启发，提出了新的嵌入概念。

**方法:** 引入了核量化嵌入（KQEs）的概念，并使用KQEs构建了一族距离度量。这些度量满足以下特性：(i) 在比MMD更弱的核条件下构成概率度量；(ii) 恢复核化的切片Wasserstein距离；(iii) 能以接近线性成本进行高效估计。

**结果:** 通过假设检验，证明了这些新距离度量提供了与MMD及其快速近似相竞争的替代方案。

**结论:** 核量化嵌入（KQEs）为非参数统计分析提供了一种新的、有效的距离度量方法，具有理论和计算上的优势。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Kernel+Quantile+Embeddings+and+Associated+Probability+Metrics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20433，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20433&send_immediately=true&force_search=false)

**原文摘要:** Embedding probability distributions into reproducing kernel Hilbert spaces
(RKHS) has enabled powerful nonparametric methods such as the maximum mean
discrepancy (MMD), a statistical distance with strong theoretical and
computational properties. At its core, the MMD relies on kernel mean embeddings
to represent distributions as mean functions in RKHS. However, it remains
unclear if the mean function is the only meaningful RKHS representation.
Inspired by generalised quantiles, we introduce the notion of kernel quantile
embeddings (KQEs). We then use KQEs to construct a family of distances that:
(i) are probability metrics under weaker kernel conditions than MMD; (ii)
recover a kernelised form of the sliced Wasserstein distance; and (iii) can be
efficiently estimated with near-linear cost. Through hypothesis testing, we
show that these distances offer a competitive alternative to MMD and its fast
approximations.

</details>


### [185] [Learning with Expected Signatures: Theory and Applications](https://arxiv.org/abs/2505.20465)
*Lorenzo Lucchese, Mikko S. Pakkanen, Almut E. D. Veraart*

**主要类别:** stat.ML

**概要:** 本文研究了期望特征的收敛性，并提出了一种改进的估计方法，可以显著降低均方误差并提高预测性能。


<details>
  <summary>更多</summary>
  
**动机:** 期望特征是一种将数据流映射到低维表示的方法，它可以完全刻画数据生成分布，因此被广泛应用于时间序列和顺序数据的机器学习算法中。然而，其离散时间估计器与连续时间理论值之间的差距尚未得到充分研究。

**方法:** 作者通过证明收敛性结果，弥合了期望特征的经验离散时间估计器与其理论连续时间值之间的差距，并提出了一个简单的修改方案以降低均方误差。当数据生成过程是鞅时，该修改方案表现尤为显著。

**结果:** 研究表明，提出的改进估计方法可以显著降低均方误差，并在实证分析中展示了其对预测性能的有效提升。

**结论:** 期望特征的收敛性分析为基于期望特征的机器学习方法提供了更完整的概率解释，并且提出的改进估计方法可以进一步提高模型的预测性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+with+Expected+Signatures%3A+Theory+and+Applications，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20465，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20465&send_immediately=true&force_search=false)

**原文摘要:** The expected signature maps a collection of data streams to a lower
dimensional representation, with a remarkable property: the resulting feature
tensor can fully characterize the data generating distribution. This
"model-free" embedding has been successfully leveraged to build multiple
domain-agnostic machine learning (ML) algorithms for time series and sequential
data. The convergence results proved in this paper bridge the gap between the
expected signature's empirical discrete-time estimator and its theoretical
continuous-time value, allowing for a more complete probabilistic
interpretation of expected signature-based ML methods. Moreover, when the data
generating process is a martingale, we suggest a simple modification of the
expected signature estimator with significantly lower mean squared error and
empirically demonstrate how it can be effectively applied to improve predictive
performance.

</details>


### [186] [Covariate-Adjusted Deep Causal Learning for Heterogeneous Panel Data Models](https://arxiv.org/abs/2505.20536)
*Guanhao Zhou, Yuefeng Han, Xiufan Yu*

**主要类别:** stat.ML

**概要:** 这篇论文研究了在协变量影响存在的情况下，估计因果面板数据模型中异质处理效应的任务。作者提出了一种新的协变量调整深度因果学习（CoDEAL）方法，该方法使用灵活的模型结构和强大的神经网络架构来共同处理面板单元和协变量影响的底层异质性和非线性。CoDEAL通过将非线性协变量影响组件与非线性因子结构相结合，构建了一个异质因果面板模型。此外，论文还提供了理论保证以证明反事实估计的收敛性，并通过广泛的模拟研究和实际数据应用展示了该方法的有效性能。


<details>
  <summary>更多</summary>
  
**动机:** 在因果推断领域，准确估计异质处理效应是一项重要且具有挑战性的任务，特别是在存在协变量影响的情况下。现有的方法可能无法充分捕捉数据中的复杂非线性和异质性。因此，需要一种更灵活、更强大的方法来解决这些问题。

**方法:** 论文提出了Covariate-Adjusted Deep Causal Learning (CoDEAL) 方法，其主要特点包括：1) 使用前馈神经网络参数化的非线性协变量影响组件；2) 使用多输出自动编码器建模的非线性因子结构；3) 将这些组件整合进定制的矩阵补全算法中，以实现对缺失反事实结果的更精确插补；4) 通过多输出自动编码器明确考虑单元间的异质性并增强潜在因子的可解释性。

**结果:** 理论分析表明，所提出的CoDEAL方法能够确保估计反事实的收敛性。实验部分，作者通过广泛的模拟研究和一个真实数据应用验证了该方法的优越性能，显示其在处理复杂数据结构时具有较高的准确性和有效性。

**结论:** CoDEAL是一种新颖且有效的方法，用于估计存在协变量影响的因果面板数据模型中的异质处理效应。它通过结合非线性协变量影响和因子结构，提供了一个灵活的框架来捕捉复杂的协变量影响和数据依赖关系。实验结果和理论分析均表明，CoDEAL在处理异质性和非线性方面表现出色，具有广泛的应用前景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Covariate-Adjusted+Deep+Causal+Learning+for+Heterogeneous+Panel+Data+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20536，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20536&send_immediately=true&force_search=false)

**原文摘要:** This paper studies the task of estimating heterogeneous treatment effects in
causal panel data models, in the presence of covariate effects. We propose a
novel Covariate-Adjusted Deep Causal Learning (CoDEAL) for panel data models,
that employs flexible model structures and powerful neural network
architectures to cohesively deal with the underlying heterogeneity and
nonlinearity of both panel units and covariate effects. The proposed CoDEAL
integrates nonlinear covariate effect components (parameterized by a
feed-forward neural network) with nonlinear factor structures (modeled by a
multi-output autoencoder) to form a heterogeneous causal panel model. The
nonlinear covariate component offers a flexible framework for capturing the
complex influences of covariates on outcomes. The nonlinear factor analysis
enables CoDEAL to effectively capture both cross-sectional and temporal
dependencies inherent in the data panel. This latent structural information is
subsequently integrated into a customized matrix completion algorithm, thereby
facilitating more accurate imputation of missing counterfactual outcomes.
Moreover, the use of a multi-output autoencoder explicitly accounts for
heterogeneity across units and enhances the model interpretability of the
latent factors. We establish theoretical guarantees on the convergence of the
estimated counterfactuals, and demonstrate the compelling performance of the
proposed method using extensive simulation studies and a real data application.

</details>


### [187] [Balancing Performance and Costs in Best Arm Identification](https://arxiv.org/abs/2505.20583)
*Michael O. Harding, Kirthevasan Kandasamy*

**主要类别:** stat.ML

**概要:** 论文提出了一种新方法，通过最小化风险函数来解决多臂老虎机问题中的最佳臂识别问题，该方法平衡了推荐臂的性能和学习成本，并提出了DBCARE算法以匹配理论下界。


<details>
  <summary>更多</summary>
  
**动机:** 当前在固定预算或固定置信度的最佳臂识别问题上，如何选择合适的方法以及相应的预算或置信参数对实践者来说仍是一个难题。

**方法:** 提出一种新的形式化方法，通过最小化风险函数来明确平衡推荐臂的性能和学习成本。在此框架下，每次观察都会产生成本，而推荐次优臂则会产生性能惩罚。目标是最小化惩罚与成本之和。并提出了名为DBCARE的算法。

**结果:** 推导出两种性能惩罚的风险理论下界（误识概率和简单遗憾），并证明DBCARE算法在几乎所有的实例中都能匹配这些下界至多差polylog因子。模拟实验显示现有固定预算和置信度算法的不足。

**结论:** 所提出的DBCARE算法能够更好地反映许多实践者的优先事项，如在A/B测试框架中最大化利润，优于传统的固定预算或置信度设置。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Balancing+Performance+and+Costs+in+Best+Arm+Identification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20583，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20583&send_immediately=true&force_search=false)

**原文摘要:** We consider the problem of identifying the best arm in a multi-armed bandit
model. Despite a wealth of literature in the traditional fixed budget and fixed
confidence regimes of the best arm identification problem, it still remains a
mystery to most practitioners as to how to choose an approach and corresponding
budget or confidence parameter. We propose a new formalism to avoid this
dilemma altogether by minimizing a risk functional which explicitly balances
the performance of the recommended arm and the cost incurred by learning this
arm. In this framework, a cost is incurred for each observation during the
sampling phase, and upon recommending an arm, a performance penalty is incurred
for identifying a suboptimal arm. The learner's goal is to minimize the sum of
the penalty and cost. This new regime mirrors the priorities of many
practitioners, e.g. maximizing profit in an A/B testing framework, better than
classical fixed budget or confidence settings. We derive theoretical lower
bounds for the risk of each of two choices for the performance penalty, the
probability of misidentification and the simple regret, and propose an
algorithm called DBCARE to match these lower bounds up to polylog factors on
nearly all problem instances. We then demonstrate the performance of DBCARE on
a number of simulated models, comparing to fixed budget and confidence
algorithms to show the shortfalls of existing BAI paradigms on this problem.

</details>


### [188] [Moment Expansions of the Energy Distance](https://arxiv.org/abs/2505.20647)
*Ian Langmore*

**主要类别:** stat.ML

**概要:** 当分布接近时，能量距离$D^2(X, Y)$对均值差异更敏感，而对协方差差异的敏感性依赖于维度。


<details>
  <summary>更多</summary>
  
**动机:** 研究能量距离在分布接近情况下的特性，尤其是其对均值和协方差差异的敏感性。

**方法:** 分析$D^2(X, Y)$在分布接近时的表现，探讨均值与协方差差异对其影响，并考察维度对协方差矩阵对角与非对角元素贡献的影响。

**结果:** 发现$D^2(X, Y)$对均值差异更敏感，而非对角协方差贡献显著较少，且此现象不依赖于维度。数值结果验证了这些关系即使在分布假设不严格满足时仍成立。

**结论:** 能量距离在分布接近情况下，表现出对均值差异更高的敏感性，而对协方差差异的敏感性受维度影响，非对角元素贡献较小。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Moment+Expansions+of+the+Energy+Distance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20647，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20647&send_immediately=true&force_search=false)

**原文摘要:** The energy distance is used to test distributional equality, and as a loss
function in machine learning. While $D^2(X, Y)=0$ only when $X\sim Y$, the
sensitivity to different moments is of practical importance. This work
considers $D^2(X, Y)$ in the case where the distributions are close. In this
regime, $D^2(X, Y)$ is more sensitive to differences in the means
$\bar{X}-\bar{Y}$, than differences in the covariances $\Delta$. This is due to
the structure of the energy distance and is independent of dimension. The
sensitivity to on versus off diagonal components of $\Delta$ is examined when
$X$ and $Y$ are close to isotropic. Here a dimension dependent averaging occurs
and, in many cases, off diagonal correlations contribute significantly less.
Numerical results verify these relationships hold even when distributional
assumptions are not strictly met.

</details>


### [189] [A False Discovery Rate Control Method Using a Fully Connected Hidden Markov Random Field for Neuroimaging Data](https://arxiv.org/abs/2505.20688)
*Taehyo Kim, Qiran Jia, Mony J. de Leon, Hai Shu*

**主要类别:** stat.ML

**概要:** 提出了一种新的方法fcHMRF-LIS，用于解决神经影像数据分析中复杂的多重检验问题。该方法结合了基于局部显著性指数（LIS）的检验程序和一种新型全连接隐马尔可夫随机场（fcHMRF），以应对空间依赖性、稳定性和计算效率等挑战。实验表明，该方法在控制假发现率（FDR）、降低假未发现率（FNR）以及提高真阳性数方面优于现有方法，并且在实际应用中识别出与疾病相关的脑区。


<details>
  <summary>更多</summary>
  
**动机:** 经典的FDR控制方法假设检验之间相互独立，在神经影像数据分析中往往导致较高的假未发现率（FNR）。现有的空间FDR控制方法虽然提高了效能，但在捕捉复杂的空间依赖关系、保持低变异性和实现高分辨率数据的计算可扩展性方面仍存在不足。

**方法:** 提出了fcHMRF-LIS方法，将基于局部显著性指数（LIS）的检验程序与新型全连接隐马尔可夫随机场（fcHMRF）相结合，用于建模复杂的多维空间结构。同时开发了一种高效的期望最大化算法，集成了平均场近似、条件随机场作为递归神经网络（CRF-RNN）技术和置换晶格滤波器，将计算复杂度从二次降低到线性。

**结果:** 广泛的模拟研究表明，fcHMRF-LIS能够准确控制FDR，降低FNR，减少FDP和FNP的变化性，并增加真阳性的数量。在实际应用中，该方法应用于阿尔茨海默病神经影像计划中的FDG-PET数据集，成功识别出具有神经生物学意义的脑区，并展示了显著的计算效率优势。

**结论:** fcHMRF-LIS是一种强大、稳定且可扩展的空间FDR控制方法，适用于神经影像数据中的体素级多重检验，表现出优异的性能和实际应用价值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+False+Discovery+Rate+Control+Method+Using+a+Fully+Connected+Hidden+Markov+Random+Field+for+Neuroimaging+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20688，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20688&send_immediately=true&force_search=false)

**原文摘要:** False discovery rate (FDR) control methods are essential for voxel-wise
multiple testing in neuroimaging data analysis, where hundreds of thousands or
even millions of tests are conducted to detect brain regions associated with
disease-related changes. Classical FDR control methods (e.g., BH, q-value, and
LocalFDR) assume independence among tests and often lead to high false
non-discovery rates (FNR). Although various spatial FDR control methods have
been developed to improve power, they still fall short in jointly addressing
three major challenges in neuroimaging applications: capturing complex spatial
dependencies, maintaining low variability in both false discovery proportion
(FDP) and false non-discovery proportion (FNP) across replications, and
achieving computational scalability for high-resolution data. To address these
challenges, we propose fcHMRF-LIS, a powerful, stable, and scalable spatial FDR
control method for voxel-wise multiple testing. It integrates the local index
of significance (LIS)-based testing procedure with a novel fully connected
hidden Markov random field (fcHMRF) designed to model complex spatial
structures using a parsimonious parameterization. We develop an efficient
expectation-maximization algorithm incorporating mean-field approximation, the
Conditional Random Fields as Recurrent Neural Networks (CRF-RNN) technique, and
permutohedral lattice filtering, reducing the computational complexity from
quadratic to linear in the number of tests. Extensive simulations demonstrate
that fcHMRF-LIS achieves accurate FDR control, lower FNR, reduced variability
in FDP and FNP, and a higher number of true positives compared to existing
methods. Applied to an FDG-PET dataset from the Alzheimer's Disease
Neuroimaging Initiative, fcHMRF-LIS identifies neurobiologically relevant brain
regions and offers notable advantages in computational efficiency.

</details>


### [190] [Stationary MMD Points for Cubature](https://arxiv.org/abs/2505.20754)
*Zonghao Chen, Toni Karvonen, Heishiro Kanagawa, François-Xavier Briol, Chris. J. Oates*

**主要类别:** stat.ML

**概要:** 通过离散梯度流计算MMD的平稳点，其积分误差具有超收敛性。


<details>
  <summary>更多</summary>
  
**动机:** 使用有限点集逼近目标概率分布是一个基本问题，在数值积分、数据压缩和优化中都有应用。已有研究提出通过最小化最大均值差异（MMD）来选择点，但由于该目标函数非凸，通常难以找到全局最优解。

**方法:** 作者考虑了MMD的平稳点，这些点可以被精确计算，并且与全局最小化点不同。提出了离散化梯度流作为一种实用策略来计算MMD的平稳点，同时提供了细化的收敛性分析和一个新的非渐近有限粒子误差界。

**结果:** 对于关联的再生核希尔伯特空间中的积分函数，MMD平稳点的数值积分误差比MMD本身消失得更快，表现出超收敛性质。

**结论:** 离散化梯度流方法为计算MMD的平稳点提供了一种有效途径，同时理论分析揭示了该方法在数值积分中的优越性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Stationary+MMD+Points+for+Cubature，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.20754，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.20754&send_immediately=true&force_search=false)

**原文摘要:** Approximation of a target probability distribution using a finite set of
points is a problem of fundamental importance, arising in cubature, data
compression, and optimisation. Several authors have proposed to select points
by minimising a maximum mean discrepancy (MMD), but the non-convexity of this
objective precludes global minimisation in general. Instead, we consider
\emph{stationary} points of the MMD which, in contrast to points globally
minimising the MMD, can be accurately computed. Our main theoretical
contribution is the (perhaps surprising) result that, for integrands in the
associated reproducing kernel Hilbert space, the cubature error of stationary
MMD points vanishes \emph{faster} than the MMD. Motivated by this
\emph{super-convergence} property, we consider discretised gradient flows as a
practical strategy for computing stationary points of the MMD, presenting a
refined convergence analysis that establishes a novel non-asymptotic
finite-particle error bound, which may be of independent interest.

</details>


### [191] [Input Convex Kolmogorov Arnold Networks](https://arxiv.org/abs/2505.21208)
*Thomas Deschatre, Xavier Warin*

**主要类别:** stat.ML

**概要:** This paper introduces an input convex neural network architecture using Kolmogorov-Arnold networks (ICKAN) and applies it to optimal transport problems.


<details>
  <summary>更多</summary>
  
**动机:** To develop a new type of input convex neural network that can be used for solving optimal transport problems requiring convex function approximations.

**方法:** The authors propose two ICKAN architectures: one based on low-order, linear-by-part function representation with a universal approximation theorem, and the other based on cubic splines where convergence is supported by numerical results. These are compared against classical ICNNs.

**结果:** ICKANs perform competitively with classical ICNNs in simple tests and effectively solve optimal transport problems.

**结论:** ICKANs, especially the cubic spline variant, are effective alternatives to classical ICNNs for convex function approximation tasks.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Input+Convex+Kolmogorov+Arnold+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21208，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21208&send_immediately=true&force_search=false)

**原文摘要:** This article presents an input convex neural network architecture using
Kolmogorov-Arnold networks (ICKAN). Two specific networks are presented: the
first is based on a low-order, linear-by-part, representation of functions, and
a universal approximation theorem is provided. The second is based on cubic
splines, for which only numerical results support convergence. We demonstrate
on simple tests that these networks perform competitively with classical input
convex neural networks (ICNNs). In a second part, we use the networks to solve
some optimal transport problems needing a convex approximation of functions and
demonstrate their effectiveness. Comparisons with ICNNs show that cubic ICKANs
produce results similar to those of classical ICNNs.

</details>


### [192] [Autoencoding Random Forests](https://arxiv.org/abs/2505.21441)
*Binh Duc Vu, Jan Kapar, Marvin Wright, David S. Watson*

**主要类别:** stat.ML

**概要:** 提出了一种基于随机森林的自动编码方法，通过非参数统计和谱图理论学习模型的低维嵌入表示，并提供了精确和近似的解码方案。该方法适用于监督和非监督模型，具有广泛的应用场景，如可视化、压缩、聚类和降噪等。


<details>
  <summary>更多</summary>
  
**动机:** 现有的自动编码技术可能无法充分利用随机森林的优势，缺乏一种系统化的方法来结合随机森林进行数据嵌入和解码。

**方法:** 利用非参数统计和谱图理论学习低维嵌入表示；通过约束优化、分裂重新标记和最近邻回归解决解码问题；使用随机森林中的树结构建立从嵌入空间到输入空间的映射。

**结果:** 在多种数据类型（表格、图像和基因组数据）上验证了方法的有效性和易用性，展示了其在可视化、压缩、聚类和降噪方面的强大功能。

**结论:** 所提出的基于随机森林的自动编码方法具有普适性和一致性，在监督和非监督模型中均表现出色，为数据分析提供了新的有力工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Autoencoding+Random+Forests，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.21441，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.21441&send_immediately=true&force_search=false)

**原文摘要:** We propose a principled method for autoencoding with random forests. Our
strategy builds on foundational results from nonparametric statistics and
spectral graph theory to learn a low-dimensional embedding of the model that
optimally represents relationships in the data. We provide exact and
approximate solutions to the decoding problem via constrained optimization,
split relabeling, and nearest neighbors regression. These methods effectively
invert the compression pipeline, establishing a map from the embedding space
back to the input space using splits learned by the ensemble's constituent
trees. The resulting decoders are universally consistent under common
regularity assumptions. The procedure works with supervised or unsupervised
models, providing a window into conditional or joint distributions. We
demonstrate various applications of this autoencoder, including powerful new
tools for visualization, compression, clustering, and denoising. Experiments
illustrate the ease and utility of our method in a wide range of settings,
including tabular, image, and genomic data.

</details>
