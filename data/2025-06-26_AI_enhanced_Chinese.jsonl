{"id": "2506.19923", "pdf": "https://arxiv.org/pdf/2506.19923", "abs": "https://arxiv.org/abs/2506.19923", "authors": ["Kaito Baba", "Chaoran Liu", "Shuhei Kurita", "Akiyoshi Sannai"], "title": "Prover Agent: An Agent-based Framework for Formal Mathematical Proofs", "categories": ["cs.AI", "cs.LG"], "comment": "22 pages, 2 figures", "summary": "We present Prover Agent, a novel AI agent for automated theorem proving that\nintegrates large language models (LLMs) with a formal proof assistant, Lean.\nProver Agent coordinates an informal reasoning LLM, a formal prover model, and\nfeedback from Lean while also generating auxiliary lemmas to assist in\ndiscovering the overall proof strategy. It achieves an 86.1% success rate on\nthe MiniF2F benchmark, establishing a new state-of-the-art among methods using\nsmall language models (SLMs) with a much lower sample budget than previous\napproaches. We also present case studies illustrating how these generated\nlemmas contribute to solving challenging problems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86Prover Agent\uff0c\u4e00\u79cd\u7528\u4e8e\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u7684\u65b0\u9896AI\u4ee3\u7406\uff0c\u5b83\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u5f62\u5f0f\u8bc1\u660e\u52a9\u624bLean\u76f8\u7ed3\u5408\u3002\u8be5\u65b9\u6cd5\u5728MiniF2F\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e8686.1%\u7684\u6210\u529f\u7387\uff0c\u5e76\u5c55\u793a\u4e86\u751f\u6210\u7684\u8f85\u52a9\u5f15\u7406\u5982\u4f55\u6709\u52a9\u4e8e\u89e3\u51b3\u590d\u6742\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9a\u7406\u8bc1\u660e\u53d6\u5f97\u4e86\u4e00\u5b9a\u8fdb\u5c55\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u9700\u8981\u8f83\u5927\u7684\u6837\u672c\u9884\u7b97\uff0c\u5e76\u4e14\u8bc1\u660e\u6210\u529f\u7387\u6709\u9650\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u5b9a\u7406\u8bc1\u660e\u7684\u6548\u679c\u548c\u6548\u7387\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86Prover Agent\uff0c\u8fd9\u662f\u4e00\u79cd\u6574\u5408\u4e86\u975e\u5f62\u5f0f\u63a8\u7406LLM\u3001\u5f62\u5f0f\u8bc1\u660e\u6a21\u578b\u4ee5\u53caLean\u53cd\u9988\u7684AI\u4ee3\u7406\u3002\u6b64\u5916\uff0cProver Agent\u8fd8\u80fd\u591f\u751f\u6210\u8f85\u52a9\u5f15\u7406\u4ee5\u5e2e\u52a9\u53d1\u73b0\u6574\u4f53\u8bc1\u660e\u7b56\u7565\u3002", "result": "Prover Agent\u5728MiniF2F\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e8686.1%\u7684\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u4f7f\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u6837\u672c\u9884\u7b97\u8f83\u4f4e\u7684\u60c5\u51b5\u4e0b\u5efa\u7acb\u4e86\u65b0\u7684\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "Prover Agent\u901a\u8fc7\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u5f62\u5f0f\u8bc1\u660e\u52a9\u624bLean\uff0c\u5c55\u793a\u51fa\u5728\u81ea\u52a8\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u9ad8\u6548\u6027\u80fd\uff0c\u540c\u65f6\u751f\u6210\u7684\u8f85\u52a9\u5f15\u7406\u5bf9\u4e8e\u89e3\u51b3\u590d\u6742\u95ee\u9898\u5177\u6709\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2506.19977", "pdf": "https://arxiv.org/pdf/2506.19977", "abs": "https://arxiv.org/abs/2506.19977", "authors": ["Deng Pan", "Keerthiram Murugesan", "Nuno Moniz", "Nitesh Chawla"], "title": "Context Attribution with Multi-Armed Bandit Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Understanding which parts of the retrieved context contribute to a large\nlanguage model's generated answer is essential for building interpretable and\ntrustworthy generative QA systems. We propose a novel framework that formulates\ncontext attribution as a combinatorial multi-armed bandit (CMAB) problem. Each\ncontext segment is treated as a bandit arm, and we employ Combinatorial\nThompson Sampling (CTS) to efficiently explore the exponentially large space of\ncontext subsets under a limited query budget. Our method defines a reward\nfunction based on normalized token likelihoods, capturing how well a subset of\nsegments supports the original model response. Unlike traditional\nperturbation-based attribution methods such as SHAP, which sample subsets\nuniformly and incur high computational costs, our approach adaptively balances\nexploration and exploitation by leveraging posterior estimates of segment\nrelevance. This leads to substantially improved query efficiency while\nmaintaining high attribution fidelity. Extensive experiments on diverse\ndatasets and LLMs demonstrate that our method achieves competitive attribution\nquality with fewer model queries.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u5c06\u4e0a\u4e0b\u6587\u5f52\u56e0\u95ee\u9898\u8f6c\u5316\u4e3a\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\uff08CMAB\uff09\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u7ec4\u5408\u6c64\u666e\u68ee\u91c7\u6837\uff08CTS\uff09\u65b9\u6cd5\u5728\u6709\u9650\u67e5\u8be2\u9884\u7b97\u4e0b\u9ad8\u6548\u63a2\u7d22\u4e0a\u4e0b\u6587\u5b50\u96c6\u7a7a\u95f4\u3002\u901a\u8fc7\u57fa\u4e8e\u5f52\u4e00\u5316\u6807\u8bb0\u4f3c\u7136\u6027\u7684\u5956\u52b1\u51fd\u6570\uff0c\u8be5\u65b9\u6cd5\u81ea\u9002\u5e94\u5730\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u67e5\u8be2\u6548\u7387\u5e76\u4fdd\u6301\u9ad8\u5f52\u56e0\u4fdd\u771f\u5ea6\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u6b64\u65b9\u6cd5\u5728\u51cf\u5c11\u6a21\u578b\u67e5\u8be2\u7684\u540c\u65f6\u8fbe\u5230\u7ade\u4e89\u6027\u7684\u5f52\u56e0\u8d28\u91cf\u3002", "motivation": "\u6784\u5efa\u53ef\u89e3\u91ca\u548c\u503c\u5f97\u4fe1\u8d56\u7684\u751f\u6210\u5f0f\u95ee\u7b54\u7cfb\u7edf\u9700\u8981\u7406\u89e3\u68c0\u7d22\u5230\u7684\u4e0a\u4e0b\u6587\u4e2d\u54ea\u4e9b\u90e8\u5206\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u7b54\u6848\u6709\u8d21\u732e\u3002\u4f20\u7edf\u57fa\u4e8e\u6270\u52a8\u7684\u65b9\u6cd5\u5982SHAP\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u6548\u7387\u4f4e\u3002", "method": "\u5c06\u4e0a\u4e0b\u6587\u5f52\u56e0\u5efa\u6a21\u4e3a\u7ec4\u5408\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u5176\u4e2d\u6bcf\u4e2a\u4e0a\u4e0b\u6587\u7247\u6bb5\u88ab\u89c6\u4e3a\u4e00\u4e2a\u8001\u864e\u673a\u81c2\u3002\u4f7f\u7528\u7ec4\u5408\u6c64\u666e\u68ee\u91c7\u6837\u7b97\u6cd5\u5728\u6307\u6570\u7ea7\u5927\u7684\u4e0a\u4e0b\u6587\u5b50\u96c6\u7a7a\u95f4\u4e2d\u8fdb\u884c\u6709\u6548\u63a2\u7d22\uff0c\u5e76\u5b9a\u4e49\u57fa\u4e8e\u5f52\u4e00\u5316\u4ee4\u724c\u4f3c\u7136\u7684\u5956\u52b1\u51fd\u6570\u6765\u8bc4\u4f30\u7247\u6bb5\u5b50\u96c6\u5bf9\u539f\u59cb\u6a21\u578b\u54cd\u5e94\u7684\u652f\u6301\u7a0b\u5ea6\u3002\u901a\u8fc7\u540e\u9a8c\u4f30\u8ba1\u7247\u6bb5\u76f8\u5173\u6027\uff0c\u81ea\u9002\u5e94\u5730\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u66f4\u5c11\u7684\u6a21\u578b\u67e5\u8be2\u4e0b\u5b9e\u73b0\u5177\u6709\u7ade\u4e89\u529b\u7684\u5f52\u56e0\u8d28\u91cf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u66f4\u9ad8\u6548\u7684\u67e5\u8be2\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u9ad8\u5f52\u56e0\u4fdd\u771f\u5ea6\u7684\u540c\u65f6\u51cf\u5c11\u4e86\u8ba1\u7b97\u8d1f\u62c5\uff0c\u4e3a\u6784\u5efa\u66f4\u53ef\u89e3\u91ca\u7684\u751f\u6210\u5f0f\u95ee\u7b54\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2506.20008", "pdf": "https://arxiv.org/pdf/2506.20008", "abs": "https://arxiv.org/abs/2506.20008", "authors": ["Abdul Basit", "Minghao Shao", "Haider Asif", "Nouhaila Innan", "Muhammad Kashif", "Alberto Marchisio", "Muhammad Shafique"], "title": "QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges", "categories": ["cs.AI", "68T50, 81P68, 68T07, 68T20", "I.2.7; I.2.2"], "comment": "8 pages, 6 figures, 3 tables, submitted to QAI 2025", "summary": "Recent advances in Large Language Models (LLMs) have demonstrated strong\npotential in code generation, yet their effectiveness in quantum computing\nremains underexplored. This paper benchmarks LLMs for PennyLane-based quantum\ncode generation using real-world challenges from the Quantum Hackathon (QHack).\nWe introduce QHackBench, a novel benchmark dataset derived from QHack\ncompetitions, and evaluate model performance under vanilla prompting and\nRetrieval-Augmented Generation (RAG). Our structured evaluation framework\nassesses functional correctness, syntactic validity, and execution success\nacross varying challenge difficulties. Results indicate that RAG-enhanced\nmodels, supplemented with an augmented PennyLane dataset, approximately\ngenerate similar results as the standard prompting, particularly in complex\nquantum algorithms. Additionally, we introduce a multi-agent evaluation\npipeline that iteratively refines incorrect solutions, further enhancing\nexecution success rates. To foster further research, we commit to publicly\nreleasing QHackBench, along with our evaluation framework and experimental\nresults, enabling continued advancements in AI-assisted quantum programming.", "AI": {"tldr": "\u8fd1\u671f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u5c55\u73b0\u4e86\u5f3a\u5927\u7684\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u91cf\u5b50\u8ba1\u7b97\u9886\u57df\u7684\u6709\u6548\u6027\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u672c\u6587\u901a\u8fc7\u4f7f\u7528\u6765\u81eaQuantum Hackathon\u7684\u771f\u5b9e\u6311\u6218\uff0c\u5bf9\u57fa\u4e8ePennyLane\u7684\u91cf\u5b50\u4ee3\u7801\u751f\u6210\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5f15\u5165\u4e86QHackBench\u8fd9\u4e00\u65b0\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002\u901a\u8fc7\u7ed3\u6784\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u6211\u4eec\u8bc4\u4f30\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u96be\u5ea6\u6311\u6218\u4e0b\u7684\u529f\u80fd\u6b63\u786e\u6027\u3001\u8bed\u6cd5\u6709\u6548\u6027\u548c\u6267\u884c\u6210\u529f\u7387\u3002\u7ed3\u679c\u8868\u660e\uff0c\u589e\u5f3a\u68c0\u7d22\u751f\u6210\uff08RAG\uff09\u7684\u6a21\u578b\u5728\u590d\u6742\u91cf\u5b50\u7b97\u6cd5\u4e2d\u4e0e\u6807\u51c6\u63d0\u793a\u751f\u6210\u7684\u7ed3\u679c\u76f8\u4f3c\u3002\u6b64\u5916\uff0c\u6211\u4eec\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u4ee5\u8fed\u4ee3\u6539\u8fdb\u9519\u8bef\u89e3\u51b3\u65b9\u6848\u7684\u591a\u4ee3\u7406\u8bc4\u4f30\u7ba1\u9053\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u6267\u884c\u6210\u529f\u7387\u3002\u4e3a\u4e86\u63a8\u52a8\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\uff0c\u6211\u4eec\u5c06\u516c\u5f00\u53d1\u5e03QHackBench\u4ee5\u53ca\u6211\u4eec\u7684\u8bc4\u4f30\u6846\u67b6\u548c\u5b9e\u9a8c\u7ed3\u679c\uff0c\u4ee5\u4fc3\u8fdbAI\u8f85\u52a9\u91cf\u5b50\u7f16\u7a0b\u7684\u6301\u7eed\u53d1\u5c55\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\u5c55\u73b0\u51fa\u4e86\u5f3a\u5927\u7684\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u5728\u91cf\u5b50\u8ba1\u7b97\u9886\u57df\u7684\u5e94\u7528\u6548\u679c\u8fd8\u672a\u88ab\u6df1\u5165\u63a2\u7d22\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u9488\u5bf9\u8fd9\u4e00\u7279\u5b9a\u9886\u57df\u8fdb\u884c\u7cfb\u7edf\u6027\u7684\u7814\u7a76\u548c\u8bc4\u4f30\u3002", "method": "\u4f5c\u8005\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aQHackBench\u7684\u65b0\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u6765\u6e90\u4e8eQuantum Hackathon\u7ade\u8d5b\u4e2d\u7684\u5b9e\u9645\u95ee\u9898\u3002\u5229\u7528\u8fd9\u4e2a\u6570\u636e\u96c6\uff0c\u4ed6\u4eec\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e24\u79cd\u63d0\u793a\u65b9\u5f0f\u4e0b\uff08\u666e\u901a\u63d0\u793a\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210[RAG]\uff09\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u8bc4\u4f30\u6846\u67b6\u5305\u62ec\u529f\u80fd\u6b63\u786e\u6027\u3001\u8bed\u6cd5\u6709\u6548\u6027\u548c\u6267\u884c\u6210\u529f\u7387\u7b49\u591a\u4e2a\u7ef4\u5ea6\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u4ee3\u7406\u8bc4\u4f30\u7ba1\u9053\u6765\u9010\u6b65\u4f18\u5316\u9519\u8bef\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728\u590d\u6742\u91cf\u5b50\u7b97\u6cd5\u4e2d\uff0cRAG\u589e\u5f3a\u7684\u6a21\u578b\u4e0e\u6807\u51c6\u63d0\u793a\u751f\u6210\u7684\u7ed3\u679c\u76f8\u8fd1\u3002\u5e76\u4e14\uff0c\u63d0\u51fa\u7684\u591a\u4ee3\u7406\u8bc4\u4f30\u7ba1\u9053\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u6267\u884c\u6210\u529f\u7387\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u6784\u5efaQHackBench\u6570\u636e\u96c6\u548c\u8be6\u7ec6\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u91cf\u5b50\u8ba1\u7b97\u4ee3\u7801\u751f\u6210\u65b9\u9762\u7684\u6f5c\u529b\u548c\u5c40\u9650\u6027\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u516c\u5f00\u53d1\u5e03\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u5de5\u5177\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8AI\u8f85\u52a9\u91cf\u5b50\u7f16\u7a0b\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.20009", "pdf": "https://arxiv.org/pdf/2506.20009", "abs": "https://arxiv.org/abs/2506.20009", "authors": ["Konstantinos Vrettos", "Michail E. Klontzas"], "title": "Accurate and Energy Efficient: Local Retrieval-Augmented Generation Models Outperform Commercial Large Language Models in Medical Tasks", "categories": ["cs.AI", "cs.CL", "I.2.7"], "comment": "18 pages, 3 Figures", "summary": "Background The increasing adoption of Artificial Intelligence (AI) in\nhealthcare has sparked growing concerns about its environmental and ethical\nimplications. Commercial Large Language Models (LLMs), such as ChatGPT and\nDeepSeek, require substantial resources, while the utilization of these systems\nfor medical purposes raises critical issues regarding patient privacy and\nsafety. Methods We developed a customizable Retrieval-Augmented Generation\n(RAG) framework for medical tasks, which monitors its energy usage and CO2\nemissions. This system was then used to create RAGs based on various\nopen-source LLMs. The tested models included both general purpose models like\nllama3.1:8b and medgemma-4b-it, which is medical-domain specific. The best RAGs\nperformance and energy consumption was compared to DeepSeekV3-R1 and OpenAIs\no4-mini model. A dataset of medical questions was used for the evaluation.\nResults Custom RAG models outperformed commercial models in accuracy and energy\nconsumption. The RAG model built on llama3.1:8B achieved the highest accuracy\n(58.5%) and was significantly better than other models, including o4-mini and\nDeepSeekV3-R1. The llama3.1-RAG also exhibited the lowest energy consumption\nand CO2 footprint among all models, with a Performance per kWh of 0.52 and a\ntotal CO2 emission of 473g. Compared to o4-mini, the llama3.1-RAG achieved 2.7x\ntimes more accuracy points per kWh and 172% less electricity usage while\nmaintaining higher accuracy. Conclusion Our study demonstrates that local LLMs\ncan be leveraged to develop RAGs that outperform commercial, online LLMs in\nmedical tasks, while having a smaller environmental impact. Our modular\nframework promotes sustainable AI development, reducing electricity usage and\naligning with the UNs Sustainable Development Goals.", "AI": {"tldr": "A customizable RAG framework using local LLMs outperformed commercial models in medical tasks, offering higher accuracy and lower energy consumption. This promotes sustainable AI development.", "motivation": "To address the environmental and ethical concerns of using commercial large language models in healthcare, such as resource intensity and patient privacy issues.", "method": "Developed a customizable RAG framework for medical tasks that monitors energy usage and CO2 emissions, tested with various open-source LLMs including general and medical-domain specific models.", "result": "Custom RAG models achieved better accuracy and lower energy consumption than commercial models; llama3.1-RAG performed best with 58.5% accuracy and lowest energy use.", "conclusion": "Local LLM-based RAGs can surpass commercial models in medical tasks while having less environmental impact, supporting sustainable AI development."}}
{"id": "2506.19945", "pdf": "https://arxiv.org/pdf/2506.19945", "abs": "https://arxiv.org/abs/2506.19945", "authors": ["Graeme Baker", "Agostino Capponi", "J. Antonio Sidaoui"], "title": "Data-Driven Dynamic Factor Modeling via Manifold Learning", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": null, "summary": "We propose a data-driven dynamic factor framework where a response variable\ndepends on a high-dimensional set of covariates, without imposing any\nparametric model on the joint dynamics. Leveraging Anisotropic Diffusion Maps,\na nonlinear manifold learning technique introduced by Singer and Coifman, our\nframework uncovers the joint dynamics of the covariates and responses in a\npurely data-driven way. We approximate the embedding dynamics using linear\ndiffusions, and exploit Kalman filtering to predict the evolution of the\ncovariates and response variables directly from the diffusion map embedding\nspace. We generalize Singer's convergence rate analysis of the graph Laplacian\nfrom the case of independent uniform samples on a compact manifold to the case\nof time series arising from Langevin diffusions in Euclidean space.\nFurthermore, we provide rigorous justification for our procedure by showing the\nrobustness of approximations of the diffusion map coordinates by linear\ndiffusions, and the convergence of ergodic averages under standard spectral\nassumptions on the underlying dynamics. We apply our method to the stress\ntesting of equity portfolios using a combination of financial and macroeconomic\nfactors from the Federal Reserve's supervisory scenarios. We demonstrate that\nour data-driven stress testing method outperforms standard scenario analysis\nand Principal Component Analysis benchmarks through historical backtests\nspanning three major financial crises, achieving reductions in mean absolute\nerror of up to 55% and 39% for scenario-based portfolio return prediction,\nrespectively.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u52a8\u6001\u56e0\u5b50\u6846\u67b6\uff0c\u901a\u8fc7\u975e\u7ebf\u6027\u6d41\u5f62\u5b66\u4e60\u6280\u672f\uff08Anisotropic Diffusion Maps\uff09\u63ed\u793a\u534f\u53d8\u91cf\u548c\u54cd\u5e94\u53d8\u91cf\u7684\u8054\u5408\u52a8\u6001\uff0c\u5e76\u5229\u7528\u7ebf\u6027\u6269\u6563\u8fd1\u4f3c\u548c\u5361\u5c14\u66fc\u6ee4\u6ce2\u8fdb\u884c\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u5728\u538b\u529b\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5728\u5386\u53f2\u56de\u6d4b\u4e2d\u663e\u8457\u964d\u4f4e\u4e86\u9884\u6d4b\u8bef\u5dee\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u6355\u6349\u9ad8\u7ef4\u534f\u53d8\u91cf\u4e0e\u54cd\u5e94\u53d8\u91cf\u4e4b\u95f4\u7684\u590d\u6742\u975e\u7ebf\u6027\u5173\u7cfb\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7279\u6027\u7684\u8003\u8651\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u6765\u5efa\u6a21\u548c\u9884\u6d4b\u8fd9\u4e9b\u52a8\u6001\u5173\u7cfb\u3002", "method": "1. \u4f7f\u7528Anisotropic Diffusion Maps\u63d0\u53d6\u534f\u53d8\u91cf\u548c\u54cd\u5e94\u53d8\u91cf\u7684\u8054\u5408\u52a8\u6001\u3002\n2. \u901a\u8fc7\u7ebf\u6027\u6269\u6563\u8fd1\u4f3c\u5d4c\u5165\u52a8\u6001\uff0c\u5e76\u5229\u7528Kalman\u6ee4\u6ce2\u76f4\u63a5\u4ece\u6269\u6563\u56fe\u5d4c\u5165\u7a7a\u95f4\u9884\u6d4b\u53d8\u91cf\u6f14\u5316\u3002\n3. \u63a8\u5e7f\u4e86Singer\u5173\u4e8e\u56fe\u62c9\u666e\u62c9\u65af\u7b97\u5b50\u6536\u655b\u7387\u5206\u6790\uff0c\u9002\u7528\u4e8eLangevin\u6269\u6563\u751f\u6210\u7684\u65f6\u95f4\u5e8f\u5217\u3002\n4. \u63d0\u4f9b\u7406\u8bba\u652f\u6301\uff0c\u8bc1\u660e\u6269\u6563\u5750\u6807\u7ebf\u6027\u6269\u6563\u8fd1\u4f3c\u7684\u9c81\u68d2\u6027\u548c\u904d\u5386\u5e73\u5747\u503c\u7684\u6536\u655b\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u80a1\u6743\u7ec4\u5408\u7684\u538b\u529b\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u76f8\u6bd4\u6807\u51c6\u60c5\u666f\u5206\u6790\u548c\u4e3b\u6210\u5206\u5206\u6790\u57fa\u51c6\uff0c\u5206\u522b\u51cf\u5c11\u4e8655%\u548c39%\u7684\u57fa\u4e8e\u60c5\u666f\u7684\u7ec4\u5408\u56de\u62a5\u9884\u6d4b\u5747\u503c\u7edd\u5bf9\u8bef\u5dee\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u52a8\u6001\u56e0\u5b50\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u6539\u5584\u91d1\u878d\u538b\u529b\u6d4b\u8bd5\u4e2d\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u4e3a\u9ad8\u7ef4\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2506.19882", "pdf": "https://arxiv.org/pdf/2506.19882", "abs": "https://arxiv.org/abs/2506.19882", "authors": ["Rylan Schaeffer", "Joshua Kazdan", "Yegor Denisov-Blanch", "Brando Miranda", "Matthias Gerstgrasser", "Susan Zhang", "Andreas Haupt", "Isha Gupta", "Elyas Obbad", "Jesse Dodge", "Jessica Zosa Forde", "Koustuv Sinha", "Francesco Orabona", "Sanmi Koyejo", "David Donoho"], "title": "Position: Machine Learning Conferences Should Establish a \"Refutations and Critiques\" Track", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CY"], "comment": null, "summary": "Science progresses by iteratively advancing and correcting humanity's\nunderstanding of the world. In machine learning (ML) research, rapid\nadvancements have led to an explosion of publications, but have also led to\nmisleading, incorrect, flawed or perhaps even fraudulent studies being accepted\nand sometimes highlighted at ML conferences due to the fallibility of peer\nreview. While such mistakes are understandable, ML conferences do not offer\nrobust processes to help the field systematically correct when such errors are\nmade.This position paper argues that ML conferences should establish a\ndedicated \"Refutations and Critiques\" (R & C) Track. This R & C Track would\nprovide a high-profile, reputable platform to support vital research that\ncritically challenges prior research, thereby fostering a dynamic\nself-correcting research ecosystem. We discuss key considerations including\ntrack design, review principles, potential pitfalls, and provide an\nillustrative example submission concerning a recent ICLR 2025 Oral. We conclude\nthat ML conferences should create official, reputable mechanisms to help ML\nresearch self-correct.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u6458\u8981\u4e3b\u5f20\u5728\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u4f1a\u8bae\u4e2d\u5efa\u7acb\u4e00\u4e2a\u4e13\u95e8\u7684\u201c\u53cd\u9a73\u4e0e\u6279\u8bc4\u201d\uff08R & C\uff09\u8f68\u9053\uff0c\u4ee5\u63d0\u4f9b\u4e00\u4e2a\u9ad8\u77e5\u540d\u5ea6\u3001\u53ef\u4fe1\u8d56\u7684\u5e73\u53f0\uff0c\u652f\u6301\u5bf9\u5148\u524d\u7814\u7a76\u8fdb\u884c\u6279\u5224\u6027\u6311\u6218\u7684\u91cd\u8981\u7814\u7a76\uff0c\u4ece\u800c\u4fc3\u8fdb\u81ea\u6211\u4fee\u6b63\u7684\u7814\u7a76\u751f\u6001\u7cfb\u7edf\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u5feb\u901f\u53d1\u5c55\u5bfc\u81f4\u4e86\u5927\u91cf\u51fa\u7248\u7269\u7684\u6d8c\u73b0\uff0c\u4f46\u540c\u65f6\u4e5f\u51fa\u73b0\u4e86\u8bef\u5bfc\u6027\u3001\u9519\u8bef\u6216\u6709\u7f3a\u9677\u7684\u7814\u7a76\u88ab\u63a5\u53d7\u751a\u81f3\u5728\u4f1a\u8bae\u4e0a\u88ab\u7a81\u51fa\u5c55\u793a\u7684\u60c5\u51b5\u3002\u7531\u4e8e\u540c\u884c\u8bc4\u5ba1\u7684\u5c40\u9650\u6027\uff0c\u5f53\u524d\u7684ML\u4f1a\u8bae\u7f3a\u4e4f\u7cfb\u7edf\u7ea0\u6b63\u8fd9\u4e9b\u9519\u8bef\u7684\u673a\u5236\u3002", "method": "\u63d0\u51fa\u5728ML\u4f1a\u8bae\u4e2d\u8bbe\u7acb\u201c\u53cd\u9a73\u4e0e\u6279\u8bc4\u201d\uff08R & C\uff09\u8f68\u9053\uff0c\u4e3a\u6279\u5224\u6027\u6311\u6218\u5148\u524d\u7814\u7a76\u7684\u7814\u7a76\u63d0\u4f9b\u4e00\u4e2a\u6b63\u5f0f\u4e14\u53ef\u4fe1\u7684\u5e73\u53f0\uff0c\u5e76\u8ba8\u8bba\u4e86\u8be5\u8f68\u9053\u7684\u8bbe\u8ba1\u3001\u8bc4\u5ba1\u539f\u5219\u4ee5\u53ca\u53ef\u80fd\u5b58\u5728\u7684\u95ee\u9898\u3002", "result": "\u901a\u8fc7\u8bbe\u7f6eR & C\u8f68\u9053\uff0c\u53ef\u4ee5\u4fc3\u8fdb\u52a8\u6001\u81ea\u6211\u4fee\u6b63\u7684\u7814\u7a76\u751f\u6001\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u5e76\u63d0\u9ad8ML\u7814\u7a76\u7684\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3002", "conclusion": "ML\u4f1a\u8bae\u5e94\u521b\u5efa\u5b98\u65b9\u3001\u53ef\u4fe1\u8d56\u7684\u673a\u5236\uff0c\u5e2e\u52a9ML\u7814\u7a76\u5b9e\u73b0\u81ea\u6211\u4fee\u6b63\uff0c\u4ece\u800c\u63a8\u52a8\u79d1\u5b66\u7684\u8fdb\u6b65\u3002"}}
{"id": "2506.20018", "pdf": "https://arxiv.org/pdf/2506.20018", "abs": "https://arxiv.org/abs/2506.20018", "authors": ["Zechun Deng", "Ziwei Liu", "Ziqian Bi", "Junhao Song", "Chia Xin Liang", "Joe Yeong", "Junfeng Hao"], "title": "Achieving Trustworthy Real-Time Decision Support Systems with Low-Latency Interpretable AI Models", "categories": ["cs.AI", "cs.AR"], "comment": null, "summary": "This paper investigates real-time decision support systems that leverage\nlow-latency AI models, bringing together recent progress in holistic AI-driven\ndecision tools, integration with Edge-IoT technologies, and approaches for\neffective human-AI teamwork. It looks into how large language models can assist\ndecision-making, especially when resources are limited. The research also\nexamines the effects of technical developments such as DeLLMa, methods for\ncompressing models, and improvements for analytics on edge devices, while also\naddressing issues like limited resources and the need for adaptable frameworks.\nThrough a detailed review, the paper offers practical perspectives on\ndevelopment strategies and areas of application, adding to the field by\npointing out opportunities for more efficient and flexible AI-supported\nsystems. The conclusions set the stage for future breakthroughs in this\nfast-changing area, highlighting how AI can reshape real-time decision support.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u8c03\u67e5\u4e86\u5b9e\u65f6\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u5229\u7528\u4f4e\u5ef6\u8fdfAI\u6a21\u578b\uff0c\u7ed3\u5408\u6574\u4f53AI\u9a71\u52a8\u7684\u51b3\u7b56\u5de5\u5177\u3001\u4e0eEdge-IoT\u6280\u672f\u7684\u96c6\u6210\u4ee5\u53ca\u6709\u6548\u7684\u4eba\u5de5\u667a\u80fd\u56e2\u961f\u5408\u4f5c\u7684\u65b9\u6cd5\u3002\u5b83\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u6709\u9650\u65f6\u5982\u4f55\u8f85\u52a9\u51b3\u7b56\uff0c\u5e76\u63a2\u8ba8\u4e86\u5982DeLLMa\u7b49\u6280\u672f\u53d1\u5c55\u3001\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\u548c\u8fb9\u7f18\u8bbe\u5907\u5206\u6790\u6539\u8fdb\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u8be6\u7ec6\u7efc\u8ff0\uff0c\u8bba\u6587\u63d0\u4f9b\u4e86\u5173\u4e8e\u5f00\u53d1\u7b56\u7565\u548c\u5e94\u7528\u9886\u57df\u7684\u5b9e\u9645\u89c6\u89d2\uff0c\u6307\u51fa\u4e86\u66f4\u9ad8\u6548\u548c\u7075\u6d3b\u7684AI\u652f\u6301\u7cfb\u7edf\u7684\u673a\u9047\u3002\u7ed3\u8bba\u4e3a\u8fd9\u4e00\u5feb\u901f\u53d8\u5316\u9886\u57df\u7684\u672a\u6765\u7a81\u7834\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5f3a\u8c03\u4e86AI\u5982\u4f55\u91cd\u5851\u5b9e\u65f6\u51b3\u7b56\u652f\u6301\u3002", "motivation": "\u5f53\u524d\u5b9e\u65f6\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u9700\u8981\u66f4\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u3002\u968f\u7740AI\u6280\u672f\u7684\u53d1\u5c55\uff0c\u4f8b\u5982\u5927\u8bed\u8a00\u6a21\u578b\u548c\u8fb9\u7f18\u8ba1\u7b97\u7684\u8fdb\u6b65\uff0c\u8fd9\u4e9b\u6280\u672f\u53ef\u4ee5\u88ab\u6574\u5408\u5230\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\u4ee5\u63d0\u5347\u5176\u6027\u80fd\u3002\u6b64\u5916\uff0c\u4eba\u673a\u534f\u4f5c\u7684\u6709\u6548\u6027\u4e5f\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u7814\u7a76\u65b9\u5411\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u8be6\u7ec6\u7efc\u8ff0\u7684\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u4f4e\u5ef6\u8fdfAI\u6a21\u578b\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3001Edge-IoT\u6280\u672f\u548c\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\u5bf9\u5b9e\u65f6\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7684\u5f71\u54cd\u3002\u540c\u65f6\uff0c\u8fd8\u8ba8\u8bba\u4e86\u8d44\u6e90\u9650\u5236\u548c\u6280\u672f\u6846\u67b6\u9002\u5e94\u6027\u7684\u95ee\u9898\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86\u4e00\u7cfb\u5217\u5173\u4e8e\u5f00\u53d1\u7b56\u7565\u548c\u5e94\u7528\u9886\u57df\u7684\u5b9e\u9645\u89c6\u89d2\uff0c\u660e\u786e\u4e86\u66f4\u9ad8\u6548\u548c\u7075\u6d3b\u7684AI\u652f\u6301\u7cfb\u7edf\u7684\u673a\u9047\uff0c\u5e76\u6307\u51fa\u6280\u672f\u8fdb\u6b65\uff08\u5982DeLLMa\uff09\u548c\u65b9\u6cd5\u6539\u8fdb\uff08\u5982\u6a21\u578b\u538b\u7f29\uff09\u5bf9\u63d0\u5347\u5b9e\u65f6\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u6027\u80fd\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "AI\u6280\u672f\uff0c\u7279\u522b\u662f\u4f4e\u5ef6\u8fdf\u6a21\u578b\u548c\u8fb9\u7f18\u8ba1\u7b97\u7684\u8fdb\u6b65\uff0c\u5c06\u91cd\u5851\u5b9e\u65f6\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002\u672a\u6765\u7684\u7814\u7a76\u5e94\u96c6\u4e2d\u4e8e\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u7cfb\u7edf\uff0c\u4ee5\u5e94\u5bf9\u8d44\u6e90\u9650\u5236\u5e76\u5b9e\u73b0\u66f4\u597d\u7684\u4eba\u673a\u534f\u4f5c\u3002"}}
{"id": "2506.20048", "pdf": "https://arxiv.org/pdf/2506.20048", "abs": "https://arxiv.org/abs/2506.20048", "authors": ["Sungee Hong", "Jiayi Wang", "Zhengling Qi", "Raymond Ka Wai Wong"], "title": "A Principled Path to Fitted Distributional Evaluation", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In reinforcement learning, distributional off-policy evaluation (OPE) focuses\non estimating the return distribution of a target policy using offline data\ncollected under a different policy. This work focuses on extending the widely\nused fitted-Q evaluation -- developed for expectation-based reinforcement\nlearning -- to the distributional OPE setting. We refer to this extension as\nfitted distributional evaluation (FDE). While only a few related approaches\nexist, there remains no unified framework for designing FDE methods. To fill\nthis gap, we present a set of guiding principles for constructing theoretically\ngrounded FDE methods. Building on these principles, we develop several new FDE\nmethods with convergence analysis and provide theoretical justification for\nexisting methods, even in non-tabular environments. Extensive experiments,\nincluding simulations on linear quadratic regulators and Atari games,\ndemonstrate the superior performance of the FDE methods.", "AI": {"tldr": "\u672c\u8bba\u6587\u6269\u5c55\u4e86\u5e7f\u6cdb\u4f7f\u7528\u7684\u62df\u5408Q\u503c\u8bc4\u4f30(FQE)\u65b9\u6cd5\u81f3\u5206\u5e03\u5f0f\u7684\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30(OPE)\u8bbe\u5b9a\uff0c\u5e76\u63d0\u51fa\u4e86\u6784\u5efa\u7406\u8bba\u57fa\u7840\u7684\u62df\u5408\u5206\u5e03\u8bc4\u4f30(FDE)\u65b9\u6cd5\u7684\u6307\u5bfc\u539f\u5219\u3002\u57fa\u4e8e\u8fd9\u4e9b\u539f\u5219\uff0c\u4f5c\u8005\u5f00\u53d1\u4e86\u51e0\u79cd\u65b0\u7684FDE\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u6536\u655b\u6027\u5206\u6790\u548c\u7406\u8bba\u8bc1\u660e\uff0c\u540c\u65f6\u5728\u591a\u79cd\u5b9e\u9a8c\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86FDE\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\u4e3b\u8981\u96c6\u4e2d\u5728\u671f\u671b\u503c\u4f30\u8ba1\u4e0a\uff0c\u4f46\u5206\u5e03\u5f0f\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\uff08OPE\uff09\u7684\u7814\u7a76\u76f8\u5bf9\u8f83\u5c11\uff0c\u4e14\u7f3a\u4e4f\u7edf\u4e00\u7684\u6846\u67b6\u6765\u8bbe\u8ba1FDE\u65b9\u6cd5\u3002\u56e0\u6b64\uff0c\u9700\u8981\u5c06FQE\u65b9\u6cd5\u6269\u5c55\u5230\u5206\u5e03\u5f0f\u7684OPE\u8bbe\u5b9a\uff0c\u5e76\u5efa\u7acb\u76f8\u5e94\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u6784\u5efaFDE\u65b9\u6cd5\u7684\u6307\u5bfc\u539f\u5219\uff0c\u57fa\u4e8e\u8fd9\u4e9b\u539f\u5219\u5f00\u53d1\u4e86\u65b0\u7684FDE\u65b9\u6cd5\uff0c\u5e76\u5bf9\u8fd9\u4e9b\u65b9\u6cd5\u8fdb\u884c\u4e86\u6536\u655b\u6027\u5206\u6790\u3002\u6b64\u5916\uff0c\u8fd8\u4e3a\u73b0\u6709\u7684FDE\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u7684\u5b9e\u9a8c\uff0c\u5305\u62ec\u7ebf\u6027\u4e8c\u6b21\u8c03\u8282\u5668\u548cAtari\u6e38\u620f\u7684\u6a21\u62df\uff0c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684FDE\u65b9\u6cd5\u5177\u6709\u66f4\u4f18\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5730\u5c06FQE\u6269\u5c55\u5230\u4e86\u5206\u5e03\u5f0f\u7684OPE\u8bbe\u5b9a\uff0c\u5e76\u4e3aFDE\u65b9\u6cd5\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5c55\u73b0\u4e86\u5176\u5728\u4e0d\u540c\u73af\u5883\u4e0b\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2506.19883", "pdf": "https://arxiv.org/pdf/2506.19883", "abs": "https://arxiv.org/abs/2506.19883", "authors": ["Zhuqing Liu", "Chaosheng Dong", "Michinari Momma", "Simone Shao", "Shaoyuan Xu", "Yan Gao", "Haibo Yang", "Jia Liu"], "title": "STIMULUS: Achieving Fast Convergence and Low Sample Complexity in Stochastic Multi-Objective Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, multi-objective optimization (MOO) has gained attention for its\nbroad applications in ML, operations research, and engineering. However, MOO\nalgorithm design remains in its infancy and many existing MOO methods suffer\nfrom unsatisfactory convergence rate and sample complexity performance. To\naddress this challenge, in this paper, we propose an algorithm called STIMULUS(\nstochastic path-integrated multi-gradient recursive e\\ulstimator), a new and\nrobust approach for solving MOO problems. Different from the traditional\nmethods, STIMULUS introduces a simple yet powerful recursive framework for\nupdating stochastic gradient estimates to improve convergence performance with\nlow sample complexity. In addition, we introduce an enhanced version of\nSTIMULUS, termed STIMULUS-M, which incorporates a momentum term to further\nexpedite convergence. We establish $O(1/T)$ convergence rates of the proposed\nmethods for non-convex settings and $O (\\exp{-\\mu T})$ for strongly convex\nsettings, where $T$ is the total number of iteration rounds. Additionally, we\nachieve the state-of-the-art $O \\left(n+\\sqrt{n}\\epsilon^{-1}\\right)$ sample\ncomplexities for non-convex settings and $O\\left(n+ \\sqrt{n} \\ln\n({\\mu/\\epsilon})\\right)$ for strongly convex settings, where $\\epsilon>0$ is a\ndesired stationarity error. Moreover, to alleviate the periodic full gradient\nevaluation requirement in STIMULUS and STIMULUS-M, we further propose enhanced\nversions with adaptive batching called STIMULUS+/ STIMULUS-M+ and provide their\ntheoretical analysis.", "AI": {"tldr": "This paper addresses the limitations of current MOO algorithms by introducing STIMULUS and its variants, which offer improved convergence and lower sample complexity through recursive gradient updates and optional momentum terms.", "motivation": "Existing MOO algorithms have unsatisfactory convergence rates and high sample complexities, motivating the development of more efficient methods.", "method": "STIMULUS uses a recursive framework to update stochastic gradient estimates, improving convergence with low sample complexity. STIMULUS-M adds a momentum term for faster convergence. Enhanced versions with adaptive batching (STIMULUS+ and STIMULUS-M+) reduce the need for full gradient evaluations.", "result": "The proposed methods achieve $ O(1/T) $ convergence rates for non-convex settings and $ O(\\exp{-\\mu T}) $ for strongly convex settings. They also attain optimal sample complexities.", "conclusion": "The paper proposes STIMULUS and its variants, achieving state-of-the-art performance in terms of convergence rate and sample complexity for MOO problems."}}
{"id": "2506.20020", "pdf": "https://arxiv.org/pdf/2506.20020", "abs": "https://arxiv.org/abs/2506.20020", "authors": ["Saloni Dash", "Am\u00e9lie Reymond", "Emma S. Spiro", "Aylin Caliskan"], "title": "Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Reasoning in humans is prone to biases due to underlying motivations like\nidentity protection, that undermine rational decision-making and judgment. This\nmotivated reasoning at a collective level can be detrimental to society when\ndebating critical issues such as human-driven climate change or vaccine safety,\nand can further aggravate political polarization. Prior studies have reported\nthat large language models (LLMs) are also susceptible to human-like cognitive\nbiases, however, the extent to which LLMs selectively reason toward\nidentity-congruent conclusions remains largely unexplored. Here, we investigate\nwhether assigning 8 personas across 4 political and socio-demographic\nattributes induces motivated reasoning in LLMs. Testing 8 LLMs (open source and\nproprietary) across two reasoning tasks from human-subject studies -- veracity\ndiscernment of misinformation headlines and evaluation of numeric scientific\nevidence -- we find that persona-assigned LLMs have up to 9% reduced veracity\ndiscernment relative to models without personas. Political personas\nspecifically, are up to 90% more likely to correctly evaluate scientific\nevidence on gun control when the ground truth is congruent with their induced\npolitical identity. Prompt-based debiasing methods are largely ineffective at\nmitigating these effects. Taken together, our empirical findings are the first\nto suggest that persona-assigned LLMs exhibit human-like motivated reasoning\nthat is hard to mitigate through conventional debiasing prompts -- raising\nconcerns of exacerbating identity-congruent reasoning in both LLMs and humans.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u88ab\u8d4b\u4e888\u79cd\u4e0d\u540c\u7684\u4eba\u683c\u7279\u5f81\u540e\u662f\u5426\u4f1a\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u7684\u52a8\u673a\u63a8\u7406\u504f\u5dee\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8fd9\u4e9b\u4eba\u683c\u5316\u7684LLM\u5728\u5904\u7406\u865a\u5047\u4fe1\u606f\u548c\u79d1\u5b66\u8bc1\u636e\u65f6\uff0c\u5176\u5224\u65ad\u51c6\u786e\u5ea6\u6709\u6240\u4e0b\u964d\uff0c\u5e76\u4e14\u653f\u6cbb\u76f8\u5173\u7684\u4eba\u683c\u66f4\u5bb9\u6613\u6839\u636e\u7b26\u5408\u81ea\u8eab\u653f\u6cbb\u8eab\u4efd\u7684\u4fe1\u606f\u4f5c\u51fa\u5224\u65ad\u3002\u4f20\u7edf\u7684\u57fa\u4e8e\u63d0\u793a\u7684\u53bb\u504f\u501a\u65b9\u6cd5\u5bf9\u7f13\u89e3\u8fd9\u4e9b\u6548\u5e94\u6548\u679c\u6709\u9650\u3002\u8fd9\u8868\u660e\u4eba\u683c\u5316\u7684LLM\u8868\u73b0\u51fa\u96be\u4ee5\u901a\u8fc7\u5e38\u89c4\u624b\u6bb5\u6d88\u9664\u7684\u4eba\u7c7b\u52a8\u673a\u63a8\u7406\u504f\u5dee\uff0c\u53ef\u80fd\u8fdb\u4e00\u6b65\u52a0\u5267\u8eab\u4efd\u4e00\u81f4\u7684\u63a8\u7406\u504f\u5dee\u3002", "motivation": "\u7814\u7a76\u8005\u89c2\u5bdf\u5230\u4eba\u7c7b\u63a8\u7406\u5bb9\u6613\u53d7\u5230\u8eab\u4efd\u4fdd\u62a4\u7b49\u52a8\u673a\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u635f\u5bb3\u7406\u6027\u51b3\u7b56\u548c\u5224\u65ad\u80fd\u529b\u3002\u8fd9\u79cd\u96c6\u4f53\u5c42\u9762\u7684\u52a8\u673a\u63a8\u7406\u4f1a\u5bf9\u793e\u4f1a\u9020\u6210\u8d1f\u9762\u5f71\u54cd\uff0c\u4f8b\u5982\u5728\u6c14\u5019\u53d8\u5316\u6216\u75ab\u82d7\u5b89\u5168\u6027\u7b49\u95ee\u9898\u4e0a\u7684\u4e89\u8bba\u4e2d\u3002\u867d\u7136\u5df2\u6709\u7814\u7a76\u8868\u660eLLM\u4e5f\u4f1a\u53d7\u5230\u7c7b\u4f3c\u4eba\u7c7b\u7684\u8ba4\u77e5\u504f\u5dee\u5f71\u54cd\uff0c\u4f46\u5b83\u4eec\u662f\u5426\u4f1a\u9009\u62e9\u6027\u5730\u503e\u5411\u4e8e\u4e0e\u8eab\u4efd\u4e00\u81f4\u7684\u7ed3\u8bba\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u7814\u7a76\u4eba\u5458\u4e3a8\u4e2aLLM\uff08\u5305\u62ec\u5f00\u6e90\u548c\u4e13\u6709\u6a21\u578b\uff09\u5206\u914d\u4e868\u79cd\u4e0d\u540c\u7684\u4eba\u683c\u7279\u5f81\uff0c\u6db5\u76d64\u79cd\u653f\u6cbb\u548c\u793e\u4f1a\u4eba\u53e3\u5c5e\u6027\u3002\u901a\u8fc7\u4e24\u4e2a\u4efb\u52a1\u6d4b\u8bd5\u8fd9\u4e9b\u6a21\u578b\u7684\u8868\u73b0\uff1a\u4e00\u662f\u8fa8\u522b\u865a\u5047\u4fe1\u606f\u6807\u9898\u7684\u771f\u5b9e\u6027\uff1b\u4e8c\u662f\u8bc4\u4f30\u6570\u503c\u578b\u79d1\u5b66\u8bc1\u636e\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u5c1d\u8bd5\u4e86\u57fa\u4e8e\u63d0\u793a\u7684\u53bb\u504f\u501a\u65b9\u6cd5\u4ee5\u89c2\u5bdf\u5176\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u672a\u5206\u914d\u4eba\u683c\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u5206\u914d\u4e86\u4eba\u683c\u7684LLM\u5728\u8fa8\u522b\u865a\u5047\u4fe1\u606f\u771f\u5b9e\u6027\u65b9\u9762\u8868\u73b0\u964d\u4f4e\u4e869%\u3002\u5177\u4f53\u800c\u8a00\uff0c\u5f53\u79d1\u5b66\u8bc1\u636e\u7684\u771f\u5b9e\u60c5\u51b5\u4e0e\u5176\u653f\u6cbb\u8eab\u4efd\u4e00\u81f4\u65f6\uff0c\u5177\u6709\u653f\u6cbb\u4eba\u683c\u7684\u6a21\u578b\u6b63\u786e\u8bc4\u4f30\u7684\u53ef\u80fd\u6027\u9ad8\u51fa90%\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u57fa\u4e8e\u63d0\u793a\u7684\u53bb\u504f\u501a\u65b9\u6cd5\u51e0\u4e4e\u65e0\u6cd5\u6709\u6548\u7f13\u89e3\u8fd9\u4e9b\u504f\u5dee\u3002", "conclusion": "\u8fd9\u662f\u9996\u6b21\u5b9e\u8bc1\u8bc1\u660e\uff0c\u5206\u914d\u4e86\u4eba\u683c\u7684LLM\u4f1a\u8868\u73b0\u51fa\u7c7b\u4f3c\u4eba\u7c7b\u7684\u52a8\u673a\u63a8\u7406\u504f\u5dee\uff0c\u5e76\u4e14\u8fd9\u79cd\u504f\u5dee\u96be\u4ee5\u901a\u8fc7\u5e38\u89c4\u7684\u53bb\u504f\u501a\u63d0\u793a\u6765\u7f13\u89e3\u3002\u8fd9\u4e00\u53d1\u73b0\u5f15\u53d1\u4e86\u5bf9LLM\u548c\u4eba\u7c7b\u53ef\u80fd\u8fdb\u4e00\u6b65\u52a0\u5267\u8eab\u4efd\u4e00\u81f4\u63a8\u7406\u7684\u62c5\u5fe7\u3002"}}
{"id": "2506.20114", "pdf": "https://arxiv.org/pdf/2506.20114", "abs": "https://arxiv.org/abs/2506.20114", "authors": ["Brian Liu", "Rahul Mazumder", "Peter Radchenko"], "title": "Extracting Interpretable Models from Tree Ensembles: Computational and Statistical Perspectives", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Tree ensembles are non-parametric methods widely recognized for their\naccuracy and ability to capture complex interactions. While these models excel\nat prediction, they are difficult to interpret and may fail to uncover useful\nrelationships in the data. We propose an estimator to extract compact sets of\ndecision rules from tree ensembles. The extracted models are accurate and can\nbe manually examined to reveal relationships between the predictors and the\nresponse. A key novelty of our estimator is the flexibility to jointly control\nthe number of rules extracted and the interaction depth of each rule, which\nimproves accuracy. We develop a tailored exact algorithm to efficiently solve\noptimization problems underlying our estimator and an approximate algorithm for\ncomputing regularization paths, sequences of solutions that correspond to\nvarying model sizes. We also establish novel non-asymptotic prediction error\nbounds for our proposed approach, comparing it to an oracle that chooses the\nbest data-dependent linear combination of the rules in the ensemble subject to\nthe same complexity constraint as our estimator. The bounds illustrate that the\nlarge-sample predictive performance of our estimator is on par with that of the\noracle. Through experiments, we demonstrate that our estimator outperforms\nexisting algorithms for rule extraction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u6811\u96c6\u6210\u4e2d\u63d0\u53d6\u7d27\u51d1\u51b3\u7b56\u89c4\u5219\u96c6\u7684\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u7cbe\u786e\u7b97\u6cd5\u548c\u8fd1\u4f3c\u7b97\u6cd5\u89e3\u51b3\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u8bc1\u660e\u5176\u6027\u80fd\u63a5\u8fd1\u6700\u4f73\u7ebf\u6027\u7ec4\u5408\u7684oracle\u3002", "motivation": "\u5c3d\u7ba1\u6811\u96c6\u6210\u6a21\u578b\u9884\u6d4b\u80fd\u529b\u5f3a\uff0c\u4f46\u5b83\u4eec\u96be\u4ee5\u89e3\u91ca\u4e14\u53ef\u80fd\u65e0\u6cd5\u63ed\u793a\u6570\u636e\u4e2d\u6709\u7528\u7684\u5173\u7cfb\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u63d0\u53d6\u53ef\u89e3\u91ca\u7684\u3001\u51c6\u786e\u7684\u51b3\u7b56\u89c4\u5219\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4f30\u8ba1\u5668\u4ee5\u4ece\u6811\u96c6\u6210\u6a21\u578b\u4e2d\u63d0\u53d6\u7d27\u51d1\u7684\u51b3\u7b56\u89c4\u5219\u96c6\uff0c\u8be5\u4f30\u8ba1\u5668\u80fd\u591f\u540c\u65f6\u63a7\u5236\u63d0\u53d6\u89c4\u5219\u7684\u6570\u91cf\u548c\u6bcf\u4e2a\u89c4\u5219\u7684\u4ea4\u4e92\u6df1\u5ea6\u3002\u5f00\u53d1\u4e86\u7cbe\u786e\u7b97\u6cd5\u548c\u8fd1\u4f3c\u7b97\u6cd5\u6765\u89e3\u51b3\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u751f\u6210\u6b63\u5219\u5316\u8def\u5f84\u3002", "result": "\u5efa\u7acb\u4e86\u975e\u6e10\u8fdb\u9884\u6d4b\u8bef\u5dee\u754c\u5e76\u4e0eoracle\u8fdb\u884c\u6bd4\u8f83\uff0c\u7ed3\u679c\u8868\u660e\u5927\u6837\u672c\u9884\u6d4b\u6027\u80fd\u4e0eoracle\u76f8\u5f53\u3002\u5b9e\u9a8c\u663e\u793a\u8be5\u4f30\u8ba1\u5668\u4f18\u4e8e\u73b0\u6709\u7684\u89c4\u5219\u63d0\u53d6\u7b97\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4f30\u8ba1\u5668\u80fd\u6709\u6548\u63d0\u53d6\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u51b3\u7b56\u89c4\u5219\uff0c\u5176\u6027\u80fd\u5728\u7406\u8bba\u4e0a\u548c\u5b9e\u9a8c\u4e0a\u90fd\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.19885", "pdf": "https://arxiv.org/pdf/2506.19885", "abs": "https://arxiv.org/abs/2506.19885", "authors": ["Jing Lu", "Xuan Wu", "Yizhun Tian", "Songhan Fan", "Yali Fang"], "title": "FlightKooba: A Fast Interpretable FTP Model", "categories": ["cs.LG", "cs.AI"], "comment": "7 figures", "summary": "The Koopman theory is a powerful and effective modeling tool for converting\nnonlinear systems into linear representations, and flight trajectory prediction\n(FTP) is a complex nonlinear system. However, current models applying the\nKoopman theory to FTP tasks are not very effective, model interpretability is\nindeed an issue, and the Koopman operators are computationally intensive,\nresulting in long training times. To address this issue, this paper proposes a\nnew modeling and control framework based on the HIPPO method, the Koopman\ntheory, and state space equations from cybernetics: FlightKooba. Inspired by\nthe idea of structural state space equations, FlightKooba directly constructs\nthe Koopman operators from data. This makes the framework highly interpretable\nand significantly reduces the number of trainable parameters in the module,\nthereby greatly reducing training time. Experiments have demonstrated the\nsuperiority of the FlightKooba modeling method in terms of time and memory\nconsumption (training time comparable to the Mamba module without using\nCUDA-level acceleration; memory reduced by more than 50% on most datasets, with\na tenfold reduction in the number of parameters), essentially completing the\nFTP task. It provides a new method for the fast computation of the Koopman\noperators, opening up new possibilities for the combination of time series\nforecasting and control.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8eHIPPO\u65b9\u6cd5\u3001Koopman\u7406\u8bba\u548c\u72b6\u6001\u7a7a\u95f4\u65b9\u7a0b\u7684\u98de\u884c\u8f68\u8ff9\u9884\u6d4b\u6846\u67b6FlightKooba\uff0c\u76f4\u63a5\u4ece\u6570\u636e\u6784\u5efaKoopman\u7b97\u5b50\uff0c\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u5e76\u51cf\u5c11\u8bad\u7ec3\u53c2\u6570\u4e0e\u65f6\u95f4\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u65f6\u95f4\u548c\u5185\u5b58\u6d88\u8017\u4e0a\u5177\u6709\u4f18\u52bf\u3002", "motivation": "\u5f53\u524d\u5c06Koopman\u7406\u8bba\u5e94\u7528\u4e8e\u98de\u884c\u8f68\u8ff9\u9884\u6d4b\u4efb\u52a1\u7684\u6a21\u578b\u6548\u679c\u4e0d\u4f73\uff0c\u5b58\u5728\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u5dee\u548c\u8ba1\u7b97\u91cf\u5927\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u8bad\u7ec3\u65f6\u95f4\u8fc7\u957f\u3002", "method": "\u63d0\u51fa\u540d\u4e3aFlightKooba\u7684\u65b0\u5efa\u6a21\u4e0e\u63a7\u5236\u6846\u67b6\uff0c\u7ed3\u5408\u4e86HIPPO\u65b9\u6cd5\u3001Koopman\u7406\u8bba\u548c\u63a7\u5236\u8bba\u4e2d\u7684\u72b6\u6001\u7a7a\u95f4\u65b9\u7a0b\u3002\u53d7\u7ed3\u6784\u5316\u72b6\u6001\u7a7a\u95f4\u65b9\u7a0b\u601d\u60f3\u542f\u53d1\uff0cFlightKooba\u76f4\u63a5\u4ece\u6570\u636e\u6784\u5efaKoopman\u7b97\u5b50\uff0c\u5927\u5e45\u51cf\u5c11\u4e86\u6a21\u5757\u4e2d\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u6570\u91cf\uff0c\u4ece\u800c\u663e\u8457\u7f29\u77ed\u4e86\u8bad\u7ec3\u65f6\u95f4\u3002", "result": "\u5b9e\u9a8c\u8868\u660eFlightKooba\u5efa\u6a21\u65b9\u6cd5\u5728\u65f6\u95f4\u548c\u5185\u5b58\u6d88\u8017\u65b9\u9762\u5177\u6709\u4f18\u8d8a\u6027\uff1a\u8bad\u7ec3\u65f6\u95f4\u4e0eMamba\u6a21\u5757\u76f8\u5f53\uff08\u672a\u4f7f\u7528CUDA\u7ea7\u52a0\u901f\uff09\uff0c\u5927\u591a\u6570\u6570\u636e\u96c6\u4e0a\u7684\u5185\u5b58\u6d88\u8017\u51cf\u5c11\u8d85\u8fc750%\uff0c\u53c2\u6570\u6570\u91cf\u51cf\u5c11\u5341\u500d\uff0c\u6210\u529f\u5b8c\u6210\u98de\u884c\u8f68\u8ff9\u9884\u6d4b\u4efb\u52a1\u3002", "conclusion": "FlightKooba\u63d0\u4f9b\u4e86\u4e00\u79cd\u5feb\u901f\u8ba1\u7b97Koopman\u7b97\u5b50\u7684\u65b0\u65b9\u6cd5\uff0c\u4e3a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e0e\u63a7\u5236\u7684\u7ed3\u5408\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u6027\u3002"}}
{"id": "2506.20059", "pdf": "https://arxiv.org/pdf/2506.20059", "abs": "https://arxiv.org/abs/2506.20059", "authors": ["Weijieying Ren", "Tianxiang Zhao", "Lei Wang", "Tianchun Wang", "Vasant Honavar"], "title": "DiaLLMs: EHR Enhanced Clinical Conversational System for Clinical Test Recommendation and Diagnosis Prediction", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have led to remarkable\nprogresses in medical consultation. However, existing medical LLMs overlook the\nessential role of Electronic Health Records (EHR) and focus primarily on\ndiagnosis recommendation, limiting their clinical applicability. We propose\nDiaLLM, the first medical LLM that integrates heterogeneous EHR data into\nclinically grounded dialogues, enabling clinical test recommendation, result\ninterpretation, and diagnosis prediction to better align with real-world\nmedical practice. To construct clinically grounded dialogues from EHR, we\ndesign a Clinical Test Reference (CTR) strategy that maps each clinical code to\nits corresponding description and classifies test results as \"normal\" or\n\"abnormal\". Additionally, DiaLLM employs a reinforcement learning framework for\nevidence acquisition and automated diagnosis. To handle the large action space,\nwe introduce a reject sampling strategy to reduce redundancy and improve\nexploration efficiency. Furthermore, a confirmation reward and a\nclass-sensitive diagnosis reward are designed to guide accurate diagnosis\nprediction. Extensive experimental results demonstrate that DiaLLM outperforms\nbaselines in clinical test recommendation and diagnosis prediction.", "AI": {"tldr": "DiaLLM \u662f\u4e00\u79cd\u65b0\u7684\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u6574\u5408\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u6570\u636e\uff0c\u63d0\u4f9b\u4e34\u5e8a\u6d4b\u8bd5\u63a8\u8350\u3001\u7ed3\u679c\u89e3\u8bfb\u548c\u8bca\u65ad\u9884\u6d4b\u3002\u5b83\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8fdb\u884c\u8bc1\u636e\u83b7\u53d6\u548c\u81ea\u52a8\u5316\u8bca\u65ad\uff0c\u5e76\u8bbe\u8ba1\u4e86\u786e\u8ba4\u5956\u52b1\u548c\u7c7b\u522b\u654f\u611f\u8bca\u65ad\u5956\u52b1\u6765\u63d0\u5347\u8bca\u65ad\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0cDiaLLM \u5728\u4e34\u5e8a\u6d4b\u8bd5\u63a8\u8350\u548c\u8bca\u65ad\u9884\u6d4b\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u533b\u7597\u5927\u8bed\u8a00\u6a21\u578b\u5ffd\u7565\u4e86\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u7684\u91cd\u8981\u4f5c\u7528\uff0c\u4e3b\u8981\u96c6\u4e2d\u5728\u8bca\u65ad\u63a8\u8350\u4e0a\uff0c\u9650\u5236\u4e86\u5176\u5728\u4e34\u5e8a\u5b9e\u8df5\u4e2d\u7684\u5e94\u7528\u8303\u56f4\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a DiaLLM \u7684\u65b0\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u5f02\u6784 EHR \u6570\u636e\u6574\u5408\u5230\u4ee5\u4e34\u5e8a\u4e3a\u57fa\u7840\u7684\u5bf9\u8bdd\u4e2d\uff0c\u4ece\u800c\u5b9e\u73b0\u4e34\u5e8a\u6d4b\u8bd5\u63a8\u8350\u3001\u7ed3\u679c\u89e3\u8bfb\u548c\u8bca\u65ad\u9884\u6d4b\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1) \u8bbe\u8ba1\u4e34\u5e8a\u6d4b\u8bd5\u53c2\u8003\uff08CTR\uff09\u7b56\u7565\uff0c\u5c06\u6bcf\u4e2a\u4e34\u5e8a\u4ee3\u7801\u6620\u5c04\u5230\u5176\u5bf9\u5e94\u63cf\u8ff0\uff0c\u5e76\u5bf9\u6d4b\u8bd5\u7ed3\u679c\u5206\u7c7b\u4e3a\u201c\u6b63\u5e38\u201d\u6216\u201c\u5f02\u5e38\u201d\uff1b2) \u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u8fdb\u884c\u8bc1\u636e\u83b7\u53d6\u548c\u81ea\u52a8\u5316\u8bca\u65ad\uff1b3) \u5f15\u5165\u62d2\u7edd\u91c7\u6837\u7b56\u7565\u4ee5\u51cf\u5c11\u5197\u4f59\u5e76\u63d0\u9ad8\u63a2\u7d22\u6548\u7387\uff1b4) \u8bbe\u8ba1\u786e\u8ba4\u5956\u52b1\u548c\u7c7b\u522b\u654f\u611f\u8bca\u65ad\u5956\u52b1\u4ee5\u6307\u5bfc\u51c6\u786e\u7684\u8bca\u65ad\u9884\u6d4b\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDiaLLM \u5728\u4e34\u5e8a\u6d4b\u8bd5\u63a8\u8350\u548c\u8bca\u65ad\u9884\u6d4b\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "DiaLLM \u901a\u8fc7\u6574\u5408 EHR \u6570\u636e\u548c\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u8d34\u8fd1\u5b9e\u9645\u533b\u7597\u5b9e\u8df5\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u4e34\u5e8a\u9002\u7528\u6027\u3002\u672a\u6765\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u6269\u5c55\u5176\u529f\u80fd\u548c\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2506.20173", "pdf": "https://arxiv.org/pdf/2506.20173", "abs": "https://arxiv.org/abs/2506.20173", "authors": ["Mahmoud Hegazy", "Liviu Aolaritei", "Michael I. Jordan", "Aymeric Dieuleveut"], "title": "Valid Selection among Conformal Sets", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.ME", "stat.OT"], "comment": null, "summary": "Conformal prediction offers a distribution-free framework for constructing\nprediction sets with coverage guarantees. In practice, multiple valid conformal\nprediction sets may be available, arising from different models or\nmethodologies. However, selecting the most desirable set, such as the smallest,\ncan invalidate the coverage guarantees. To address this challenge, we propose a\nstability-based approach that ensures coverage for the selected prediction set.\nWe extend our results to the online conformal setting, propose several\nrefinements in settings where additional structure is available, and\ndemonstrate its effectiveness through experiments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a33\u5b9a\u6027\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u9009\u62e9\u6700\u4f18\u7684\u9884\u6d4b\u96c6\uff0c\u540c\u65f6\u4fdd\u6301\u8986\u76d6\u7387\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u53ef\u80fd\u6709\u591a\u4e2a\u6709\u6548\u7684\u5171\u5f62\u9884\u6d4b\u96c6\u53ef\u4f9b\u9009\u62e9\uff0c\u4f46\u9009\u62e9\u6700\u4f18\u96c6\uff08\u5982\u6700\u5c0f\u96c6\uff09\u53ef\u80fd\u4f1a\u4f7f\u8986\u76d6\u7387\u4fdd\u8bc1\u5931\u6548\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7a33\u5b9a\u6027\u7684\u65b9\u6cd5\u6765\u786e\u4fdd\u6240\u9009\u9884\u6d4b\u96c6\u7684\u8986\u76d6\u7387\uff0c\u5e76\u5c06\u7ed3\u679c\u6269\u5c55\u5230\u5728\u7ebf\u5171\u5f62\u9884\u6d4b\u8bbe\u7f6e\u4e2d\uff0c\u540c\u65f6\u5728\u5177\u6709\u989d\u5916\u7ed3\u6784\u7684\u8bbe\u7f6e\u4e2d\u63d0\u51fa\u4e86\u51e0\u79cd\u6539\u8fdb\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7a33\u5b9a\u6027\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u5171\u5f62\u9884\u6d4b\u4e2d\u9009\u62e9\u6700\u4f18\u9884\u6d4b\u96c6\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u7559\u8986\u76d6\u7387\u4fdd\u8bc1\u3002"}}
{"id": "2506.19890", "pdf": "https://arxiv.org/pdf/2506.19890", "abs": "https://arxiv.org/abs/2506.19890", "authors": ["Ziru Zhang", "Jiadong Yu", "Danny H. K. Tsang"], "title": "Causal-Aware Intelligent QoE Optimization for VR Interaction with Adaptive Keyframe Extraction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The optimization of quality of experience (QoE) in multi-user virtual reality\n(VR) interactions demands a delicate balance between ultra-low latency,\nhigh-fidelity motion synchronization, and equitable resource allocation. While\nadaptive keyframe extraction mitigates transmission overhead, existing\napproaches often overlook the causal relationships among allocated bandwidth,\nCPU frequency, and user perception, limiting QoE gains. This paper proposes an\nintelligent framework to maximize QoE by integrating adaptive keyframe\nextraction with causal-aware reinforcement learning (RL). First, a novel QoE\nmetric is formulated using the Weber-Fechner Law, combining perceptual\nsensitivity, attention-driven priorities, and motion reconstruction accuracy.\nThe QoE optimization problem is then modeled as a mixed integer programming\n(MIP) task, jointly optimizing keyframe ratios, bandwidth, and computational\nresources under horizon-fairness constraints. We propose Partial State Causal\nDeep Deterministic Policy Gradient (PS-CDDPG), which integrates the Deep\nDeterministic Policy Gradient (DDPG) method with causal influence detection. By\nleveraging causal information regarding how QoE is influenced and determined by\nvarious actions, we explore actions guided by weights calculated from causal\ninference (CI), which in turn improves training efficiency. Experiments\nconducted with the CMU Motion Capture Database demonstrate that our framework\nsignificantly reduces interactive latency, enhances QoE, and maintains\nfairness, achieving superior performance compared to benchmark methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u667a\u80fd\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u81ea\u9002\u5e94\u5173\u952e\u5e27\u63d0\u53d6\u548c\u56e0\u679c\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6765\u4f18\u5316\u591a\u7528\u6237\u865a\u62df\u73b0\u5b9e\u4ea4\u4e92\u4e2d\u7684\u4f53\u9a8c\u8d28\u91cf\uff08QoE\uff09\u3002\u8be5\u6846\u67b6\u5229\u7528\u90e8\u5206\u72b6\u6001\u56e0\u679c\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08PS-CDDPG\uff09\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4ea4\u4e92\u5ef6\u8fdf\uff0c\u63d0\u9ad8\u4e86QoE\uff0c\u5e76\u4fdd\u6301\u4e86\u516c\u5e73\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u867d\u7136\u901a\u8fc7\u81ea\u9002\u5e94\u5173\u952e\u5e27\u63d0\u53d6\u51cf\u8f7b\u4e86\u4f20\u8f93\u5f00\u9500\uff0c\u4f46\u5e38\u5e38\u5ffd\u7565\u4e86\u5206\u914d\u5e26\u5bbd\u3001CPU\u9891\u7387\u548c\u7528\u6237\u4f53\u9a8c\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u9650\u5236\u4e86QoE\u7684\u63d0\u5347\u3002", "method": "1. \u63d0\u51fa\u4e00\u79cd\u65b0\u7684QoE\u6307\u6807\uff0c\u57fa\u4e8e\u97e6\u4f2f-\u8d39\u5e0c\u7eb3\u5b9a\u5f8b\uff0c\u7efc\u5408\u8003\u8651\u611f\u77e5\u654f\u611f\u5ea6\u3001\u6ce8\u610f\u529b\u9a71\u52a8\u4f18\u5148\u7ea7\u548c\u8fd0\u52a8\u91cd\u5efa\u7cbe\u5ea6\u3002\n2. \u5c06QoE\u4f18\u5316\u95ee\u9898\u5efa\u6a21\u4e3a\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MIP\uff09\u4efb\u52a1\uff0c\u8054\u5408\u4f18\u5316\u5173\u952e\u5e27\u6bd4\u4f8b\u3001\u5e26\u5bbd\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u5e76\u5728\u65f6\u95f4\u516c\u5e73\u7ea6\u675f\u4e0b\u8fdb\u884c\u4f18\u5316\u3002\n3. \u63d0\u51fa\u90e8\u5206\u72b6\u6001\u56e0\u679c\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08PS-CDDPG\uff09\uff0c\u5c06\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08DDPG\uff09\u4e0e\u56e0\u679c\u5f71\u54cd\u68c0\u6d4b\u76f8\u7ed3\u5408\u3002\n4. \u5229\u7528\u56e0\u679c\u4fe1\u606f\u6307\u5bfc\u52a8\u4f5c\u9009\u62e9\uff0c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u51cf\u5c11\u4e86\u4ea4\u4e92\u5ef6\u8fdf\uff0c\u63d0\u9ad8\u4e86QoE\uff0c\u5e76\u4e14\u7ef4\u6301\u4e86\u516c\u5e73\u6027\uff0c\u6027\u80fd\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u667a\u80fd\u6846\u67b6\u80fd\u591f\u6709\u6548\u4f18\u5316\u591a\u7528\u6237\u865a\u62df\u73b0\u5b9e\u4ea4\u4e92\u4e2d\u7684\u4f53\u9a8c\u8d28\u91cf\uff0c\u5177\u6709\u826f\u597d\u7684\u6027\u80fd\u8868\u73b0\u548c\u516c\u5e73\u6027\u4fdd\u969c\u3002"}}
{"id": "2506.20130", "pdf": "https://arxiv.org/pdf/2506.20130", "abs": "https://arxiv.org/abs/2506.20130", "authors": ["Adrien Bibal", "Steven N. Minton", "Deborah Khider", "Yolanda Gil"], "title": "AI Copilots for Reproducibility in Science: A Case Study", "categories": ["cs.AI"], "comment": null, "summary": "Open science initiatives seek to make research outputs more transparent,\naccessible, and reusable, but ensuring that published findings can be\nindependently reproduced remains a persistent challenge. This paper introduces\nOpenPub, an AI-powered platform that supports researchers, reviewers, and\nreaders through a suite of modular copilots focused on key open science tasks.\nIn this work, we present the Reproducibility Copilot, which analyzes\nmanuscripts, code, and supplementary materials to generate structured Jupyter\nNotebooks and recommendations aimed at facilitating computational, or \"rote\",\nreproducibility. We conducted feasibility tests using previously studied\nresearch papers with known reproducibility benchmarks. Results indicate that\nOpenPub can substantially reduce reproduction time - from over 30 hours to\nabout 1 hour - while achieving high coverage of figures, tables, and results\nsuitable for computational reproduction. The system systematically detects\nbarriers to reproducibility, including missing hyperparameters, undocumented\npreprocessing steps, and incomplete or inaccessible datasets. These findings\nsuggest that AI-driven tools can meaningfully reduce the burden of\nreproducibility efforts and contribute to more transparent and verifiable\nscientific communication. The modular copilot architecture also provides a\nfoundation for extending AI assistance to additional open science objectives\nbeyond reproducibility.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86OpenPub\u5e73\u53f0\u4e2d\u7684\u53ef\u91cd\u590d\u6027\u526f\u9a7e\u9a76\u6a21\u5757\uff0c\u8be5\u6a21\u5757\u901a\u8fc7\u5206\u6790\u624b\u7a3f\u3001\u4ee3\u7801\u548c\u8865\u5145\u6750\u6599\u751f\u6210\u7ed3\u6784\u5316\u7684Jupyter\u7b14\u8bb0\u672c\u548c\u5efa\u8bae\uff0c\u65e8\u5728\u4fc3\u8fdb\u8ba1\u7b97\u53ef\u91cd\u590d\u6027\u3002\u6d4b\u8bd5\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6a21\u5757\u80fd\u5c06\u53ef\u91cd\u590d\u6027\u5de5\u4f5c\u65f6\u95f4\u4ece30\u5c0f\u65f6\u4ee5\u4e0a\u51cf\u5c11\u5230\u7ea61\u5c0f\u65f6\uff0c\u540c\u65f6\u68c0\u6d4b\u5230\u5f71\u54cd\u53ef\u91cd\u590d\u6027\u7684\u969c\u788d\u56e0\u7d20\u3002\u8fd9\u8868\u660eAI\u9a71\u52a8\u7684\u5de5\u5177\u53ef\u4ee5\u51cf\u8f7b\u53ef\u91cd\u590d\u6027\u5de5\u4f5c\u7684\u8d1f\u62c5\uff0c\u5e76\u6709\u52a9\u4e8e\u66f4\u900f\u660e\u548c\u53ef\u9a8c\u8bc1\u7684\u79d1\u5b66\u4ea4\u6d41\u3002", "motivation": "\u5f00\u653e\u79d1\u5b66\u8ba1\u5212\u65e8\u5728\u4f7f\u7814\u7a76\u8f93\u51fa\u66f4\u52a0\u900f\u660e\u3001\u53ef\u8bbf\u95ee\u548c\u53ef\u91cd\u7528\uff0c\u4f46\u786e\u4fdd\u5df2\u53d1\u8868\u7684\u7814\u7a76\u6210\u679c\u80fd\u591f\u88ab\u72ec\u7acb\u91cd\u73b0\u4ecd\u7136\u662f\u4e00\u4e2a\u6301\u7eed\u7684\u6311\u6218\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u5de5\u5177\u6765\u652f\u6301\u7814\u7a76\u4eba\u5458\u3001\u8bc4\u5ba1\u5458\u548c\u8bfb\u8005\uff0c\u7279\u522b\u662f\u5728\u5173\u952e\u7684\u5f00\u653e\u79d1\u5b66\u4efb\u52a1\u4e0a\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u53ef\u91cd\u590d\u6027\u526f\u9a7e\u9a76\u6a21\u5757\uff0c\u5b83\u5206\u6790\u624b\u7a3f\u3001\u4ee3\u7801\u548c\u8865\u5145\u6750\u6599\u4ee5\u751f\u6210\u7ed3\u6784\u5316\u7684Jupyter\u7b14\u8bb0\u672c\u548c\u5efa\u8bae\u3002\u901a\u8fc7\u4f7f\u7528\u5148\u524d\u7814\u7a76\u8fc7\u7684\u5177\u6709\u5df2\u77e5\u53ef\u91cd\u590d\u6027\u57fa\u51c6\u7684\u7814\u7a76\u8bba\u6587\u8fdb\u884c\u53ef\u884c\u6027\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u5176\u6027\u80fd\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0cOpenPub\u53ef\u4ee5\u5927\u5e45\u51cf\u5c11\u53ef\u91cd\u590d\u6027\u65f6\u95f4\uff08\u4ece\u8d85\u8fc730\u5c0f\u65f6\u51cf\u5c11\u5230\u5927\u7ea61\u5c0f\u65f6\uff09\uff0c\u540c\u65f6\u5b9e\u73b0\u9ad8\u8986\u76d6\u7387\u7684\u56fe\u8868\u548c\u7ed3\u679c\uff0c\u9002\u5408\u8ba1\u7b97\u53ef\u91cd\u590d\u6027\u3002\u7cfb\u7edf\u8fd8\u7cfb\u7edf\u5730\u68c0\u6d4b\u5230\u53ef\u91cd\u590d\u6027\u7684\u969c\u788d\uff0c\u5305\u62ec\u7f3a\u5931\u7684\u8d85\u53c2\u6570\u3001\u672a\u8bb0\u5f55\u7684\u9884\u5904\u7406\u6b65\u9aa4\u548c\u4e0d\u5b8c\u6574\u6216\u65e0\u6cd5\u8bbf\u95ee\u7684\u6570\u636e\u96c6\u3002", "conclusion": "AI\u9a71\u52a8\u7684\u5de5\u5177\u53ef\u4ee5\u6709\u610f\u4e49\u5730\u51cf\u5c11\u53ef\u91cd\u590d\u6027\u52aa\u529b\u7684\u8d1f\u62c5\uff0c\u5e76\u6709\u52a9\u4e8e\u66f4\u900f\u660e\u548c\u53ef\u9a8c\u8bc1\u7684\u79d1\u5b66\u4ea4\u6d41\u3002\u6a21\u5757\u5316\u526f\u9a7e\u9a76\u67b6\u6784\u8fd8\u4e3a\u5c06AI\u8f85\u52a9\u6269\u5c55\u5230\u5176\u4ed6\u5f00\u653e\u79d1\u5b66\u76ee\u6807\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.20406", "pdf": "https://arxiv.org/pdf/2506.20406", "abs": "https://arxiv.org/abs/2506.20406", "authors": ["Ruijia Zhang", "Zhengling Qi", "Yue Wu", "Xiangyu Zhang", "Yanxun Xu"], "title": "POLAR: A Pessimistic Model-based Policy Learning Algorithm for Dynamic Treatment Regimes", "categories": ["stat.ML", "cs.IT", "cs.LG", "math.IT", "stat.ME"], "comment": null, "summary": "Dynamic treatment regimes (DTRs) provide a principled framework for\noptimizing sequential decision-making in domains where decisions must adapt\nover time in response to individual trajectories, such as healthcare,\neducation, and digital interventions. However, existing statistical methods\noften rely on strong positivity assumptions and lack robustness under partial\ndata coverage, while offline reinforcement learning approaches typically focus\non average training performance, lack statistical guarantees, and require\nsolving complex optimization problems. To address these challenges, we propose\nPOLAR, a novel pessimistic model-based policy learning algorithm for offline\nDTR optimization. POLAR estimates the transition dynamics from offline data and\nquantifies uncertainty for each history-action pair. A pessimistic penalty is\nthen incorporated into the reward function to discourage actions with high\nuncertainty. Unlike many existing methods that focus on average training\nperformance, POLAR directly targets the suboptimality of the final learned\npolicy and offers theoretical guarantees, without relying on computationally\nintensive minimax or constrained optimization procedures. To the best of our\nknowledge, POLAR is the first model-based DTR method to provide both\nstatistical and computational guarantees, including finite-sample bounds on\npolicy suboptimality. Empirical results on both synthetic data and the\nMIMIC-III dataset demonstrate that POLAR outperforms state-of-the-art methods\nand yields near-optimal, history-aware treatment strategies.", "AI": {"tldr": "POLAR\u662f\u4e00\u79cd\u65b0\u7684\u60b2\u89c2\u6a21\u578b\u7b56\u7565\u5b66\u4e60\u7b97\u6cd5\uff0c\u7528\u4e8e\u79bb\u7ebfDTR\u4f18\u5316\u3002\u5b83\u901a\u8fc7\u4ece\u79bb\u7ebf\u6570\u636e\u4e2d\u4f30\u8ba1\u8f6c\u79fb\u52a8\u6001\u5e76\u91cf\u5316\u6bcf\u4e2a\u5386\u53f2-\u52a8\u4f5c\u5bf9\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5c06\u60b2\u89c2\u60e9\u7f5a\u7eb3\u5165\u5956\u52b1\u51fd\u6570\u4ee5\u51cf\u5c11\u9ad8\u4e0d\u786e\u5b9a\u6027\u7684\u52a8\u4f5c\u9009\u62e9\u3002POLAR\u76f4\u63a5\u9488\u5bf9\u6700\u7ec8\u5b66\u4e60\u7b56\u7565\u7684\u6b21\u4f18\u6027\uff0c\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u5728\u7edf\u8ba1\u548c\u8ba1\u7b97\u4e0a\u90fd\u6709\u4fdd\u969c\u3002\u5b9e\u9a8c\u8868\u660e\uff0cPOLAR\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u4ea7\u751f\u63a5\u8fd1\u6700\u4f18\u7684\u5386\u53f2\u611f\u77e5\u6cbb\u7597\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u7684\u7edf\u8ba1\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5f3a\u5047\u8bbe\u4e14\u7f3a\u4e4f\u9c81\u68d2\u6027\uff0c\u800c\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5219\u5173\u6ce8\u5e73\u5747\u8bad\u7ec3\u8868\u73b0\uff0c\u7f3a\u4e4f\u7edf\u8ba1\u4fdd\u8bc1\u4e14\u9700\u8981\u89e3\u51b3\u590d\u6742\u7684\u4f18\u5316\u95ee\u9898\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u6311\u6218\u3002", "method": "POLAR\u7b97\u6cd5\u901a\u8fc7\u79bb\u7ebf\u6570\u636e\u4f30\u8ba1\u8f6c\u79fb\u52a8\u6001\u5e76\u91cf\u5316\u5386\u53f2-\u52a8\u4f5c\u5bf9\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u7136\u540e\u5c06\u60b2\u89c2\u60e9\u7f5a\u52a0\u5165\u5956\u52b1\u51fd\u6570\u4ee5\u51cf\u5c11\u9ad8\u4e0d\u786e\u5b9a\u6027\u7684\u52a8\u4f5c\u9009\u62e9\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u4e8e\u8ba1\u7b97\u5bc6\u96c6\u578b\u7684\u6781\u5c0f\u6781\u5927\u6216\u7ea6\u675f\u4f18\u5316\u7a0b\u5e8f\uff0c\u800c\u662f\u76f4\u63a5\u9488\u5bf9\u6700\u7ec8\u5b66\u4e60\u7b56\u7565\u7684\u6b21\u4f18\u6027\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u548cMIMIC-III\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cPOLAR\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u63a5\u8fd1\u6700\u4f18\u7684\u5386\u53f2\u611f\u77e5\u6cbb\u7597\u7b56\u7565\u3002", "conclusion": "POLAR\u662f\u9996\u4e2a\u63d0\u4f9b\u7edf\u8ba1\u548c\u8ba1\u7b97\u53cc\u91cd\u4fdd\u8bc1\uff08\u5305\u62ec\u7b56\u7565\u6b21\u4f18\u6027\u7684\u6709\u9650\u6837\u672c\u754c\uff09\u7684\u57fa\u4e8e\u6a21\u578b\u7684DTR\u65b9\u6cd5\uff0c\u4e3a\u79bb\u7ebfDTR\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.19891", "pdf": "https://arxiv.org/pdf/2506.19891", "abs": "https://arxiv.org/abs/2506.19891", "authors": ["Qinghui Gong", "Xue Yang", "Xiaohu Tang"], "title": "Orthogonal Soft Pruning for Efficient Class Unlearning", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages,3 figures", "summary": "Machine unlearning aims to selectively remove class-specific knowledge from\npretrained neural networks to satisfy privacy regulations such as the GDPR.\nExisting methods typically face a trade-off between unlearning speed and\npreservation of predictive accuracy, often incurring either high computational\noverhead or significant performance degradation on retained classes. In this\npaper, we propose a novel class-aware soft pruning framework leveraging\northogonal convolutional kernel regularization to achieve rapid and precise\nforgetting with millisecond-level response times. By enforcing orthogonality\nconstraints during training, our method decorrelates convolutional filters and\ndisentangles feature representations, while efficiently identifying\nclass-specific channels through activation difference analysis. Extensive\nevaluations across multiple architectures and datasets demonstrate stable\npruning with near-instant execution, complete forgetting of targeted classes,\nand minimal accuracy loss on retained data. Experiments on CIFAR-10, CIFAR-100,\nand TinyImageNet confirm that our approach substantially reduces membership\ninference attack risks and accelerates unlearning by orders of magnitude\ncompared to state-of-the-art baselines. This framework provides an efficient,\npractical solution for real-time machine unlearning in Machine Learning as a\nService (MLaaS) scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7c7b\u522b\u611f\u77e5\u8f6f\u526a\u679d\u6846\u67b6\uff0c\u901a\u8fc7\u6b63\u4ea4\u5377\u79ef\u6838\u6b63\u5219\u5316\u5b9e\u73b0\u5feb\u901f\u7cbe\u786e\u7684\u673a\u5668\u9057\u5fd8\uff0c\u5177\u6709\u6beb\u79d2\u7ea7\u54cd\u5e94\u65f6\u95f4\uff0c\u80fd\u591f\u5728\u4fdd\u7559\u6570\u636e\u51c6\u786e\u6027\u6700\u5c0f\u635f\u5931\u7684\u60c5\u51b5\u4e0b\u5b8c\u5168\u5fd8\u8bb0\u76ee\u6807\u7c7b\u522b\u3002\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u8be5\u6846\u67b6\u663e\u8457\u964d\u4f4e\u4e86\u6210\u5458\u63a8\u7406\u653b\u51fb\u98ce\u9669\u5e76\u52a0\u901f\u4e86\u9057\u5fd8\u8fc7\u7a0b\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u673a\u5668\u5b66\u4e60\u670d\u52a1\u573a\u666f\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\u901a\u5e38\u5728\u9057\u5fd8\u901f\u5ea6\u548c\u9884\u6d4b\u51c6\u786e\u6027\u4fdd\u6301\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u8981\u4e48\u8ba1\u7b97\u5f00\u9500\u9ad8\uff0c\u8981\u4e48\u5bf9\u4fdd\u7559\u7c7b\u522b\u7684\u6027\u80fd\u9000\u5316\u663e\u8457\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5feb\u901f\u3001\u7cbe\u786e\u5730\u79fb\u9664\u7279\u5b9a\u7c7b\u522b\u77e5\u8bc6\u4e14\u5bf9\u6a21\u578b\u5f71\u54cd\u8f83\u5c0f\u7684\u65b9\u6cd5\u6765\u6ee1\u8db3\u9690\u79c1\u6cd5\u89c4\uff08\u5982GDPR\uff09\u7684\u8981\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6b63\u4ea4\u5377\u79ef\u6838\u6b63\u5219\u5316\u7684\u7c7b\u522b\u611f\u77e5\u8f6f\u526a\u679d\u6846\u67b6\u3002\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u65bd\u52a0\u6b63\u4ea4\u6027\u7ea6\u675f\uff0c\u4f7f\u5377\u79ef\u6ee4\u6ce2\u5668\u53bb\u76f8\u5173\uff0c\u5e76\u89e3\u7f20\u7279\u5f81\u8868\u793a\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u6fc0\u6d3b\u5dee\u5f02\u5206\u6790\u9ad8\u6548\u8bc6\u522b\u7c7b\u522b\u7279\u5b9a\u901a\u9053\uff0c\u4ece\u800c\u5b9e\u73b0\u5feb\u901f\u800c\u7cbe\u786e\u7684\u77e5\u8bc6\u9057\u5fd8\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u67b6\u6784\u548c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u7a33\u5b9a\u7684\u526a\u679d\u6548\u679c\uff0c\u6267\u884c\u8fd1\u4e4e\u5373\u65f6\uff0c\u80fd\u591f\u5b8c\u5168\u5fd8\u8bb0\u76ee\u6807\u7c7b\u522b\uff0c\u540c\u65f6\u4fdd\u7559\u6570\u636e\u7684\u51c6\u786e\u6027\u635f\u5931\u6700\u5c0f\u3002\u5b9e\u9a8c\u8fd8\u8bc1\u5b9e\uff0c\u8be5\u65b9\u6cd5\u5927\u5e45\u964d\u4f4e\u4e86\u6210\u5458\u63a8\u7406\u653b\u51fb\u7684\u98ce\u9669\uff0c\u5e76\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u52a0\u901f\u4e86\u6570\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u5b9e\u65f6\u673a\u5668\u9057\u5fd8\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u5373\u670d\u52a1\uff08MLaaS\uff09\u573a\u666f\u3002"}}
{"id": "2506.20249", "pdf": "https://arxiv.org/pdf/2506.20249", "abs": "https://arxiv.org/abs/2506.20249", "authors": ["Junyan Cheng", "Peter Clark", "Kyle Richardson"], "title": "Language Modeling by Language Models", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": null, "summary": "Can we leverage LLMs to model the process of discovering novel language model\n(LM) architectures? Inspired by real research, we propose a multi-agent LLM\napproach that simulates the conventional stages of research, from ideation and\nliterature search (proposal stage) to design implementation (code generation),\ngenerative pre-training, and downstream evaluation (verification). Using ideas\nfrom scaling laws, our system, Genesys, employs a Ladder of Scales approach;\nnew designs are proposed, adversarially reviewed, implemented, and selectively\nverified at increasingly larger model scales (14M$\\sim$350M parameters) with a\nnarrowing budget (the number of models we can train at each scale). To help\nmake discovery efficient and factorizable, Genesys uses a novel genetic\nprogramming backbone, which we show has empirical advantages over commonly used\ndirect prompt generation workflows (e.g., $\\sim$86\\% percentage point\nimprovement in successful design generation, a key bottleneck). We report\nexperiments involving 1,162 newly discovered designs (1,062 fully verified\nthrough pre-training) and find the best designs to be highly competitive with\nknown architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common\nbenchmarks). We couple these results with comprehensive system-level ablations\nand formal results, which give broader insights into the design of effective\nautonomous discovery systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53LLM\u65b9\u6cd5\uff08Genesys\uff09\uff0c\u6a21\u62df\u4ece\u6982\u5ff5\u5230\u9a8c\u8bc1\u7684\u7814\u7a76\u8fc7\u7a0b\uff0c\u901a\u8fc7\u89c4\u6a21\u9012\u589e\u7684\u65b9\u5f0f\u63d0\u51fa\u3001\u5ba1\u67e5\u548c\u9a8c\u8bc1\u65b0\u7684\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u8bbe\u8ba1\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u751f\u6210\u6210\u529f\u8bbe\u8ba1\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u53d1\u73b0\u4e86\u4e0e\u5df2\u77e5\u67b6\u6784\u7ade\u4e89\u7684\u65b0\u8bbe\u8ba1\u3002", "motivation": "\u53d7\u771f\u5b9e\u7814\u7a76\u8fc7\u7a0b\u542f\u53d1\uff0c\u5e0c\u671b\u5229\u7528LLM\u6765\u5efa\u6a21\u53d1\u73b0\u65b0\u8bed\u8a00\u6a21\u578b\u67b6\u6784\u7684\u8fc7\u7a0b\uff0c\u4ece\u800c\u63d0\u9ad8\u53d1\u73b0\u6548\u7387\u5e76\u4f7f\u5176\u66f4\u5177\u53ef\u5206\u89e3\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u591a\u667a\u80fd\u4f53LLM\u7cfb\u7edfGenesys\uff0c\u91c7\u7528\u89c4\u6a21\u9012\u589e\uff08Ladder of Scales\uff09\u65b9\u6cd5\uff0c\u5305\u62ec\u63d0\u6848\u3001\u4ee3\u7801\u751f\u6210\u3001\u9884\u8bad\u7ec3\u548c\u9a8c\u8bc1\u7b49\u9636\u6bb5\u3002\u4f7f\u7528\u9057\u4f20\u7f16\u7a0b\u4f5c\u4e3a\u9aa8\u5e72\uff0c\u4f18\u5316\u8bbe\u8ba1\u751f\u6210\u6d41\u7a0b\u3002", "result": "\u5b9e\u9a8c\u6d89\u53ca1,162\u4e2a\u65b0\u8bbe\u8ba1\uff081,062\u4e2a\u5b8c\u5168\u9a8c\u8bc1\uff09\uff0c\u5176\u4e2d\u6700\u4f73\u8bbe\u8ba1\u57286/9\u5e38\u89c1\u57fa\u51c6\u4e0a\u8d85\u8d8a\u4e86GPT2\u548cMamba2\u7b49\u5df2\u77e5\u67b6\u6784\u3002\u6b64\u5916\uff0c\u8fd8\u8fdb\u884c\u4e86\u5168\u9762\u7684\u7cfb\u7edf\u7ea7\u6d88\u878d\u5206\u6790\u3002", "conclusion": "Genesys\u7cfb\u7edf\u5c55\u793a\u4e86\u5728\u9ad8\u6548\u81ea\u4e3b\u53d1\u73b0\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u6f5c\u529b\uff0c\u5176\u9057\u4f20\u7f16\u7a0b\u65b9\u6cd5\u76f8\u6bd4\u76f4\u63a5\u63d0\u793a\u751f\u6210\u5de5\u4f5c\u6d41\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2506.20425", "pdf": "https://arxiv.org/pdf/2506.20425", "abs": "https://arxiv.org/abs/2506.20425", "authors": ["Ryan Thompson", "Matt P. Wand", "Joanna J. J. Wang"], "title": "Scalable Subset Selection in Linear Mixed Models", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "comment": null, "summary": "Linear mixed models (LMMs), which incorporate fixed and random effects, are\nkey tools for analyzing heterogeneous data, such as in personalized medicine or\nadaptive marketing. Nowadays, this type of data is increasingly wide, sometimes\ncontaining thousands of candidate predictors, necessitating sparsity for\nprediction and interpretation. However, existing sparse learning methods for\nLMMs do not scale well beyond tens or hundreds of predictors, leaving a large\ngap compared with sparse methods for linear models, which ignore random\neffects. This paper closes the gap with a new $\\ell_0$ regularized method for\nLMM subset selection that can run on datasets containing thousands of\npredictors in seconds to minutes. On the computational front, we develop a\ncoordinate descent algorithm as our main workhorse and provide a guarantee of\nits convergence. We also develop a local search algorithm to help traverse the\nnonconvex optimization surface. Both algorithms readily extend to subset\nselection in generalized LMMs via a penalized quasi-likelihood approximation.\nOn the statistical front, we provide a finite-sample bound on the\nKullback-Leibler divergence of the new method. We then demonstrate its\nexcellent performance in synthetic experiments and illustrate its utility on\ntwo datasets from biology and journalism.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u21130\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u7ebf\u6027\u6df7\u5408\u6a21\u578b\uff08LMM\uff09\u5b50\u96c6\u9009\u62e9\uff0c\u53ef\u4ee5\u5feb\u901f\u5904\u7406\u5305\u542b\u6570\u5343\u4e2a\u9884\u6d4b\u53d8\u91cf\u7684\u6570\u636e\u96c6\u3002\u901a\u8fc7\u5750\u6807\u4e0b\u964d\u7b97\u6cd5\u548c\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\uff0c\u786e\u4fdd\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u4f18\u5316\u6548\u679c\uff0c\u5e76\u63d0\u4f9b\u4e86\u6709\u9650\u6837\u672c\u7684Kullback-Leibler\u6563\u5ea6\u754c\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5408\u6210\u5b9e\u9a8c\u548c\u771f\u5b9e\u6570\u636e\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u7a00\u758f\u5b66\u4e60\u65b9\u6cd5\u5728\u7ebf\u6027\u6df7\u5408\u6a21\u578b\uff08LMMs\uff09\u4e2d\u65e0\u6cd5\u5f88\u597d\u5730\u6269\u5c55\u5230\u5305\u542b\u6570\u5343\u4e2a\u5019\u9009\u9884\u6d4b\u53d8\u91cf\u7684\u6570\u636e\u96c6\uff0c\u800c\u7ebf\u6027\u6a21\u578b\u7684\u7a00\u758f\u65b9\u6cd5\u53c8\u5ffd\u7565\u4e86\u968f\u673a\u6548\u5e94\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u9ad8\u6548\u5904\u7406\u5927\u89c4\u6a21\u9884\u6d4b\u53d8\u91cf\u5e76\u4fdd\u6301\u89e3\u91ca\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u21130\u6b63\u5219\u5316\u65b9\u6cd5\u6765\u8fdb\u884cLMM\u5b50\u96c6\u9009\u62e9\uff0c\u5f00\u53d1\u4e86\u5750\u6807\u4e0b\u964d\u7b97\u6cd5\u4f5c\u4e3a\u4e3b\u8981\u8ba1\u7b97\u5de5\u5177\uff0c\u5e76\u4fdd\u8bc1\u4e86\u5176\u6536\u655b\u6027\uff1b\u8fd8\u63d0\u51fa\u4e86\u5c40\u90e8\u641c\u7d22\u7b97\u6cd5\u4ee5\u8f85\u52a9\u975e\u51f8\u4f18\u5316\u8fc7\u7a0b\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u60e9\u7f5a\u62df\u4f3c\u7136\u8fd1\u4f3c\uff0c\u8be5\u65b9\u6cd5\u53ef\u6269\u5c55\u5230\u5e7f\u4e49LMM\u7684\u5b50\u96c6\u9009\u62e9\u3002", "result": "\u7406\u8bba\u4e0a\uff0c\u63d0\u4f9b\u4e86\u6709\u9650\u6837\u672c\u7684Kullback-Leibler\u6563\u5ea6\u754c\uff1b\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5728\u751f\u7269\u5b66\u548c\u65b0\u95fb\u5b66\u7684\u4e24\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e2d\u5c55\u793a\u4e86\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u21130\u6b63\u5219\u5316\u65b9\u6cd5\u586b\u8865\u4e86LMM\u7a00\u758f\u5b66\u4e60\u65b9\u6cd5\u4e0e\u7ebf\u6027\u6a21\u578b\u7a00\u758f\u65b9\u6cd5\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u80fd\u591f\u5728\u5305\u542b\u6570\u5343\u4e2a\u9884\u6d4b\u53d8\u91cf\u7684\u6570\u636e\u96c6\u4e0a\u9ad8\u6548\u8fd0\u884c\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u9884\u6d4b\u548c\u89e3\u91ca\u80fd\u529b\u3002"}}
{"id": "2506.19893", "pdf": "https://arxiv.org/pdf/2506.19893", "abs": "https://arxiv.org/abs/2506.19893", "authors": ["Jingzhi Hu", "Geoffrey Ye Li"], "title": "Distillation-Enabled Knowledge Alignment for Generative Semantic Communications in AIGC Provisioning Tasks", "categories": ["cs.LG", "cs.AI", "eess.IV"], "comment": null, "summary": "Due to the surging amount of AI-generated content (AIGC), its provisioning to\nedges and mobile users from the cloud incurs substantial traffic on networks.\nGenerative semantic communication (GSC) offers a promising solution by\ntransmitting highly compact information, i.e., prompt text and latent\nrepresentations, instead of high-dimensional AIGC data. However, GSC relies on\nthe alignment between the knowledge in the cloud generative AI (GAI) and that\npossessed by the edges and users, and between the knowledge for wireless\ntransmission and that of actual channels, which remains challenging. In this\npaper, we propose DeKA-g, a distillation-enabled knowledge alignment algorithm\nfor GSC systems. The core idea is to distill the generation knowledge from the\ncloud-GAI into low-rank matrices, which can be incorporated by the edge and\nused to adapt the transmission knowledge to diverse wireless channel\nconditions. DeKA-g comprises two novel methods: metaword-aided knowledge\ndistillation (MAKD) and variable-rate grouped SNR adaptation (VGSA). For MAKD,\nan optimized metaword is employed to enhance the efficiency of knowledge\ndistillation, while VGSA enables efficient adaptation to diverse compression\nrates and SNR ranges. From simulation results, DeKA-g improves the alignment\nbetween the edge-generated images and the cloud-generated ones by 44%.\nMoreover, it adapts to compression rates with 116% higher efficiency than the\nbaseline and enhances the performance in low-SNR conditions by 28%.", "AI": {"tldr": "DeKA-g\u662f\u4e00\u79cd\u4e3a\u751f\u6210\u5f0f\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u7684\u77e5\u8bc6\u5bf9\u9f50\u7b97\u6cd5\uff0c\u901a\u8fc7\u5143\u8bcd\u8f85\u52a9\u77e5\u8bc6\u84b8\u998f\u548c\u53ef\u53d8\u901f\u7387\u5206\u7ec4SNR\u9002\u5e94\u4e24\u79cd\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8fb9\u7f18\u751f\u6210\u56fe\u50cf\u4e0e\u4e91\u7aef\u751f\u6210\u56fe\u50cf\u7684\u4e00\u81f4\u6027\u3001\u538b\u7f29\u7387\u9002\u5e94\u6548\u7387\u4ee5\u53ca\u4f4eSNR\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u7531\u4e8eAI\u751f\u6210\u5185\u5bb9\uff08AIGC\uff09\u7684\u6fc0\u589e\uff0c\u4ece\u4e91\u7aef\u5411\u8fb9\u7f18\u548c\u79fb\u52a8\u7528\u6237\u63d0\u4f9b\u670d\u52a1\u4ea7\u751f\u4e86\u5927\u91cf\u7684\u7f51\u7edc\u6d41\u91cf\u3002\u751f\u6210\u5f0f\u8bed\u4e49\u901a\u4fe1\uff08GSC\uff09\u901a\u8fc7\u4f20\u8f93\u7d27\u51d1\u7684\u4fe1\u606f\uff08\u5982\u63d0\u793a\u6587\u672c\u548c\u6f5c\u5728\u8868\u793a\uff09\u800c\u975e\u9ad8\u7ef4AIGC\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5e0c\u671b\u7684\u89e3\u51b3\u65b9\u6848\u3002\u7136\u800c\uff0cGSC\u9762\u4e34\u77e5\u8bc6\u5bf9\u9f50\u7684\u6311\u6218\uff0c\u5305\u62ec\u4e91\u7aef\u751f\u6210\u5f0fAI\u4e0e\u8fb9\u7f18\u7528\u6237\u4e4b\u95f4\u7684\u77e5\u8bc6\u5bf9\u9f50\uff0c\u4ee5\u53ca\u65e0\u7ebf\u4f20\u8f93\u77e5\u8bc6\u4e0e\u5b9e\u9645\u4fe1\u9053\u6761\u4ef6\u7684\u77e5\u8bc6\u5bf9\u9f50\u3002", "method": "\u63d0\u51fa\u4e86DeKA-g\u7b97\u6cd5\uff0c\u6838\u5fc3\u662f\u5c06\u4e91\u7aef\u751f\u6210\u5f0fAI\u7684\u77e5\u8bc6\u84b8\u998f\u5230\u4f4e\u79e9\u77e9\u9635\u4e2d\uff0c\u4f9b\u8fb9\u7f18\u8bbe\u5907\u4f7f\u7528\uff0c\u5e76\u9002\u5e94\u4e0d\u540c\u7684\u65e0\u7ebf\u4fe1\u9053\u6761\u4ef6\u3002DeKA-g\u5305\u542b\u4e24\u79cd\u65b0\u65b9\u6cd5\uff1a\u5143\u8bcd\u8f85\u52a9\u77e5\u8bc6\u84b8\u998f\uff08MAKD\uff09\u548c\u53ef\u53d8\u901f\u7387\u5206\u7ec4SNR\u9002\u5e94\uff08VGSA\uff09\u3002MAKD\u5229\u7528\u4f18\u5316\u7684\u5143\u8bcd\u63d0\u9ad8\u77e5\u8bc6\u84b8\u998f\u6548\u7387\uff0c\u800cVGSA\u5219\u5b9e\u73b0\u4e86\u5bf9\u4e0d\u540c\u538b\u7f29\u7387\u548cSNR\u8303\u56f4\u7684\u6709\u6548\u9002\u5e94\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0cDeKA-g\u4f7f\u8fb9\u7f18\u751f\u6210\u7684\u56fe\u50cf\u4e0e\u4e91\u7aef\u751f\u6210\u7684\u56fe\u50cf\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u63d0\u9ad8\u4e8644%\uff0c\u5bf9\u538b\u7f29\u7387\u7684\u9002\u5e94\u6548\u7387\u6bd4\u57fa\u7ebf\u9ad8\u51fa116%\uff0c\u5e76\u5728\u4f4eSNR\u6761\u4ef6\u4e0b\u63d0\u5347\u4e8628%\u7684\u6027\u80fd\u3002", "conclusion": "DeKA-g\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86GSC\u7cfb\u7edf\u4e2d\u7684\u77e5\u8bc6\u5bf9\u9f50\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u751f\u6210\u4e00\u81f4\u6027\u3001\u538b\u7f29\u9002\u5e94\u6027\u548c\u4f4eSNR\u6027\u80fd\uff0c\u4e3a\u9ad8\u6548\u4f20\u8f93AI\u751f\u6210\u5185\u5bb9\u63d0\u4f9b\u4e86\u652f\u6301\u3002"}}
{"id": "2506.20274", "pdf": "https://arxiv.org/pdf/2506.20274", "abs": "https://arxiv.org/abs/2506.20274", "authors": ["Liya Wang", "David Yi", "Damien Jose", "John Passarelli", "James Gao", "Jordan Leventis", "Kang Li"], "title": "Enterprise Large Language Model Evaluation Benchmark", "categories": ["cs.AI"], "comment": "Submitted to MLNLP 2025 at https://csity2025.org/mlnlp/index", "summary": "Large Language Models (LLMs) ) have demonstrated promise in boosting\nproductivity across AI-powered tools, yet existing benchmarks like Massive\nMultitask Language Understanding (MMLU) inadequately assess enterprise-specific\ntask complexities. We propose a 14-task framework grounded in Bloom's Taxonomy\nto holistically evaluate LLM capabilities in enterprise contexts. To address\nchallenges of noisy data and costly annotation, we develop a scalable pipeline\ncombining LLM-as-a-Labeler, LLM-as-a-Judge, and corrective retrieval-augmented\ngeneration (CRAG), curating a robust 9,700-sample benchmark. Evaluation of six\nleading models shows open-source contenders like DeepSeek R1 rival proprietary\nmodels in reasoning tasks but lag in judgment-based scenarios, likely due to\noverthinking. Our benchmark reveals critical enterprise performance gaps and\noffers actionable insights for model optimization. This work provides\nenterprises a blueprint for tailored evaluations and advances practical LLM\ndeployment.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u63d0\u5347AI\u9a71\u52a8\u5de5\u5177\u751f\u4ea7\u529b\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u5982MMLU\u672a\u80fd\u5145\u5206\u8bc4\u4f30\u4f01\u4e1a\u7279\u5b9a\u4efb\u52a1\u7684\u590d\u6742\u6027\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5e03\u9c81\u59c6\u5206\u7c7b\u6cd5\u768414\u4efb\u52a1\u6846\u67b6\uff0c\u4ee5\u5168\u9762\u8bc4\u4f30LLM\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u80fd\u529b\u3002\u4e3a\u4e86\u89e3\u51b3\u566a\u58f0\u6570\u636e\u548c\u6602\u8d35\u6ce8\u91ca\u7684\u6311\u6218\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u7ba1\u9053\uff0c\u7ed3\u5408\u4e86LLM-as-a-Labeler\u3001LLM-as-a-Judge\u548c\u77eb\u6b63\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08CRAG\uff09\uff0c\u7b56\u5212\u4e86\u4e00\u4e2a\u5f3a\u5927\u76849700\u6837\u672c\u57fa\u51c6\u3002\u5bf9\u516d\u4e2a\u9886\u5148\u6a21\u578b\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5f00\u6e90\u7ade\u4e89\u8005\u5982DeepSeek R1\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u4e0e\u4e13\u6709\u6a21\u578b\u76f8\u5f53\uff0c\u4f46\u5728\u57fa\u4e8e\u5224\u65ad\u7684\u60c5\u666f\u4e2d\u843d\u540e\uff0c\u53ef\u80fd\u662f\u56e0\u4e3a\u8fc7\u5ea6\u601d\u8003\u3002\u6211\u4eec\u7684\u57fa\u51c6\u63ed\u793a\u4e86\u5173\u952e\u7684\u4f01\u4e1a\u6027\u80fd\u5dee\u8ddd\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u4f18\u5316\u89c1\u89e3\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4f01\u4e1a\u63d0\u4f9b\u4e86\u5b9a\u5236\u8bc4\u4f30\u7684\u84dd\u56fe\uff0c\u5e76\u63a8\u52a8\u4e86\u5b9e\u7528LLM\u7684\u90e8\u7f72\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u63d0\u9ad8AI\u9a71\u52a8\u5de5\u5177\u7684\u751f\u4ea7\u529b\u65b9\u9762\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\uff08\u4f8b\u5982Massive Multitask Language Understanding (MMLU)\uff09\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u4f01\u4e1a\u7279\u5b9a\u4efb\u52a1\u7684\u590d\u6742\u6027\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u5bfb\u6c42\u66f4\u7cbe\u786e\u548c\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u8861\u91cfLLM\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e03\u9c81\u59c6\u5206\u7c7b\u6cd5\u768414\u4efb\u52a1\u6846\u67b6\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30LLM\u5728\u4f01\u4e1a\u73af\u5883\u4e2d\u7684\u80fd\u529b\u3002\u4e3a\u4e86\u5e94\u5bf9\u566a\u58f0\u6570\u636e\u548c\u9ad8\u6602\u6807\u6ce8\u6210\u672c\u7684\u95ee\u9898\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u7ba1\u9053\uff0c\u7ed3\u5408\u4e86LLM-as-a-Labeler\u3001LLM-as-a-Judge\u4ee5\u53ca\u77eb\u6b63\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08CRAG\uff09\uff0c\u4ece\u800c\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b9,700\u4e2a\u6837\u672c\u7684\u5f3a\u5927\u57fa\u51c6\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u50cfDeepSeek R1\u8fd9\u6837\u7684\u5f00\u6e90\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u53ef\u4ee5\u5ab2\u7f8e\u4e13\u6709\u6a21\u578b\uff0c\u4f46\u5728\u57fa\u4e8e\u5224\u65ad\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u8f83\u5dee\uff0c\u53ef\u80fd\u662f\u7531\u4e8e\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\u5bfc\u81f4\u7684\u3002\u8fd9\u4e00\u53d1\u73b0\u63ed\u793a\u4e86\u4f01\u4e1a\u5728\u4f7f\u7528\u8fd9\u4e9b\u6a21\u578b\u65f6\u53ef\u80fd\u9762\u4e34\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4f01\u4e1a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u91cf\u8eab\u5b9a\u5236\u7684\u8bc4\u4f30\u84dd\u56fe\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u90e8\u7f72\u3002\u540c\u65f6\uff0c\u8fd9\u9879\u5de5\u4f5c\u8fd8\u5f3a\u8c03\u4e86\u6839\u636e\u5177\u4f53\u9700\u6c42\u4f18\u5316\u6a21\u578b\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.20533", "pdf": "https://arxiv.org/pdf/2506.20533", "abs": "https://arxiv.org/abs/2506.20533", "authors": ["Gilad Lerman", "Kang Li", "Tyler Maunu", "Teng Zhang"], "title": "Global Convergence of Iteratively Reweighted Least Squares for Robust Subspace Recovery", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "Robust subspace estimation is fundamental to many machine learning and data\nanalysis tasks. Iteratively Reweighted Least Squares (IRLS) is an elegant and\nempirically effective approach to this problem, yet its theoretical properties\nremain poorly understood. This paper establishes that, under deterministic\nconditions, a variant of IRLS with dynamic smoothing regularization converges\nlinearly to the underlying subspace from any initialization. We extend these\nguarantees to affine subspace estimation, a setting that lacks prior recovery\ntheory. Additionally, we illustrate the practical benefits of IRLS through an\napplication to low-dimensional neural network training. Our results provide the\nfirst global convergence guarantees for IRLS in robust subspace recovery and,\nmore broadly, for nonconvex IRLS on a Riemannian manifold.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5e26\u52a8\u6001\u5e73\u6ed1\u6b63\u5219\u5316\u7684IRLS\u53d8\u4f53\u5728\u9c81\u68d2\u5b50\u7a7a\u95f4\u4f30\u8ba1\u4e2d\u7684\u7ebf\u6027\u6536\u655b\u6027\uff0c\u9996\u6b21\u63d0\u4f9b\u4e86\u5168\u5c40\u6536\u655b\u6027\u4fdd\u8bc1\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u4f4e\u7ef4\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u5b9e\u9645\u4f18\u52bf\u3002", "motivation": "\u5c3d\u7ba1IRLS\u65b9\u6cd5\u5728\u9c81\u68d2\u5b50\u7a7a\u95f4\u4f30\u8ba1\u95ee\u9898\u4e0a\u5177\u6709\u4f18\u96c5\u6027\u548c\u7ecf\u9a8c\u6709\u6548\u6027\uff0c\u4f46\u5176\u7406\u8bba\u6027\u8d28\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u6df1\u5165\u7684\u7406\u8bba\u5206\u6790\u548c\u4fdd\u969c\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u5e26\u6709\u52a8\u6001\u5e73\u6ed1\u6b63\u5219\u5316\u7684IRLS\u53d8\u4f53\uff0c\u5e76\u5728\u786e\u5b9a\u6027\u6761\u4ef6\u4e0b\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u4ece\u4efb\u4f55\u521d\u59cb\u5316\u5f00\u59cb\u90fd\u80fd\u7ebf\u6027\u6536\u655b\u5230\u6f5c\u5728\u7684\u5b50\u7a7a\u95f4\u3002\u6b64\u5916\uff0c\u8fd8\u5c06\u8fd9\u4e9b\u4fdd\u8bc1\u6269\u5c55\u5230\u4e86\u4eff\u5c04\u5b50\u7a7a\u95f4\u4f30\u8ba1\u7684\u60c5\u666f\u4e2d\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684IRLS\u53d8\u4f53\u80fd\u591f\u5b9e\u73b0\u7ebf\u6027\u6536\u655b\uff0c\u5e76\u4e14\u9002\u7528\u4e8e\u7f3a\u4e4f\u5148\u524d\u6062\u590d\u7406\u8bba\u7684\u4eff\u5c04\u5b50\u7a7a\u95f4\u4f30\u8ba1\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86IRLS\u65b9\u6cd5\u5728\u4f4e\u7ef4\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u672c\u6587\u4e3aIRLS\u65b9\u6cd5\u5728\u9c81\u68d2\u5b50\u7a7a\u95f4\u6062\u590d\u4ee5\u53ca\u66f4\u5e7f\u6cdb\u7684\u975e\u51f8\u4f18\u5316\u95ee\u9898\uff08\u5982\u9ece\u66fc\u6d41\u5f62\u4e0a\u7684IRLS\uff09\u63d0\u4f9b\u4e86\u9996\u4e2a\u5168\u5c40\u6536\u655b\u6027\u4fdd\u8bc1\uff0c\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.19894", "pdf": "https://arxiv.org/pdf/2506.19894", "abs": "https://arxiv.org/abs/2506.19894", "authors": ["Antoine Pesenti", "Aidan OSullivan"], "title": "Explaining deep neural network models for electricity price forecasting with XAI", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Electricity markets are highly complex, involving lots of interactions and\ncomplex dependencies that make it hard to understand the inner workings of the\nmarket and what is driving prices. Econometric methods have been developed for\nthis, white-box models, however, they are not as powerful as deep neural\nnetwork models (DNN). In this paper, we use a DNN to forecast the price and\nthen use XAI methods to understand the factors driving the price dynamics in\nthe market. The objective is to increase our understanding of how different\nelectricity markets work. To do that, we apply explainable methods such as SHAP\nand Gradient, combined with visual techniques like heatmaps (saliency maps) to\nanalyse the behaviour and contributions of various features across five\nelectricity markets. We introduce the novel concepts of SSHAP values and SSHAP\nlines to enhance the complex representation of high-dimensional tabular models.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u9884\u6d4b\u7535\u529b\u5e02\u573a\u4ef7\u683c\uff0c\u5e76\u7ed3\u5408\u53ef\u89e3\u91ca\u6027\u4eba\u5de5\u667a\u80fd\uff08XAI\uff09\u65b9\u6cd5\u5982SHAP\u548c\u68af\u5ea6\uff0c\u4ee5\u53ca\u70ed\u529b\u56fe\u7b49\u53ef\u89c6\u5316\u6280\u672f\uff0c\u5206\u6790\u4e94\u4e2a\u7535\u529b\u5e02\u573a\u4e2d\u4e0d\u540c\u7279\u5f81\u7684\u884c\u4e3a\u4e0e\u8d21\u732e\u3002\u6b64\u5916\uff0c\u6587\u7ae0\u5f15\u5165\u4e86SSHAP\u503c\u548cSSHAP\u7ebf\u7684\u6982\u5ff5\uff0c\u4ee5\u63d0\u5347\u9ad8\u7ef4\u8868\u683c\u6a21\u578b\u7684\u590d\u6742\u8868\u793a\u80fd\u529b\u3002", "motivation": "\u7535\u529b\u5e02\u573a\u5177\u6709\u9ad8\u5ea6\u590d\u6742\u6027\u548c\u4ea4\u4e92\u6027\uff0c\u7406\u89e3\u5176\u5185\u90e8\u8fd0\u4f5c\u53ca\u4ef7\u683c\u9a71\u52a8\u56e0\u7d20\u9887\u5177\u6311\u6218\u6027\u3002\u867d\u7136\u8ba1\u91cf\u7ecf\u6d4e\u5b66\u65b9\u6cd5\uff08\u767d\u76d2\u6a21\u578b\uff09\u53ef\u7528\u4e8e\u6b64\u76ee\u7684\uff0c\u4f46\u5176\u6548\u679c\u4e0d\u5982\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff08DNN\uff09\u3002", "method": "\u5229\u7528DNN\u9884\u6d4b\u7535\u529b\u5e02\u573a\u4ef7\u683c\uff0c\u968f\u540e\u91c7\u7528XAI\u65b9\u6cd5\uff08\u5982SHAP\u548c\u68af\u5ea6\uff09\u4e0e\u53ef\u89c6\u5316\u6280\u672f\uff08\u5982\u70ed\u529b\u56fe\uff09\u6765\u89e3\u6790\u5f71\u54cd\u5e02\u573a\u4ef7\u683c\u52a8\u6001\u7684\u56e0\u7d20\u3002\u5728\u5206\u6790\u4e2d\u8986\u76d6\u4e86\u4e94\u4e2a\u4e0d\u540c\u7684\u7535\u529b\u5e02\u573a\uff0c\u5e76\u63d0\u51fa\u4e86SSHAP\u503c\u548cSSHAP\u7ebf\u7684\u65b0\u6982\u5ff5\u3002", "result": "\u901a\u8fc7\u7ed3\u5408DNN\u548cXAI\u65b9\u6cd5\uff0c\u6210\u529f\u589e\u5f3a\u4e86\u5bf9\u7535\u529b\u5e02\u573a\u8fd0\u4f5c\u673a\u5236\u7684\u7406\u89e3\uff0c\u5e76\u4e14\u63d0\u51fa\u7684SSHAP\u503c\u548cSSHAP\u7ebf\u4e3a\u9ad8\u7ef4\u8868\u683c\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u590d\u6742\u7684\u8868\u793a\u5f62\u5f0f\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7ed3\u5408XAI\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63ed\u793a\u7535\u529b\u5e02\u573a\u4ef7\u683c\u52a8\u6001\u80cc\u540e\u7684\u9a71\u52a8\u56e0\u7d20\uff0c\u6709\u52a9\u4e8e\u589e\u8fdb\u5bf9\u4e0d\u540c\u7535\u529b\u5e02\u573a\u8fd0\u884c\u65b9\u5f0f\u7684\u7406\u89e3\u3002"}}
{"id": "2506.20332", "pdf": "https://arxiv.org/pdf/2506.20332", "abs": "https://arxiv.org/abs/2506.20332", "authors": ["Jihao Gu", "Qihang Ai", "Yingyao Wang", "Pi Bu", "Jingxuan Xing", "Zekun Zhu", "Wei Jiang", "Ziming Wang", "Yingxiu Zhao", "Ming-Liang Zhang", "Jun Song", "Yuning Jiang", "Bo Zheng"], "title": "Mobile-R1: Towards Interactive Reinforcement Learning for VLM-Based Mobile Agent via Task-Level Rewards", "categories": ["cs.AI"], "comment": "14 pages, 12 figures", "summary": "Vision-language model-based mobile agents have gained the ability to not only\nunderstand complex instructions and mobile screenshots, but also optimize their\naction outputs via thinking and reasoning, benefiting from reinforcement\nlearning, such as Group Relative Policy Optimization (GRPO). However, existing\nresearch centers on offline reinforcement learning training or online\noptimization using action-level rewards, which limits the agent's dynamic\ninteraction with the environment. This often results in agents settling into\nlocal optima, thereby weakening their ability for exploration and error action\ncorrection. To address these challenges, we introduce an approach called\nMobile-R1, which employs interactive multi-turn reinforcement learning with\ntask-level rewards for mobile agents. Our training framework consists of three\nstages: initial format finetuning, single-step online training via action-level\nreward, followed by online training via task-level reward based on multi-turn\ntrajectories. This strategy is designed to enhance the exploration and error\ncorrection capabilities of Mobile-R1, leading to significant performance\nimprovements. Moreover, we have collected a dataset covering 28 Chinese\napplications with 24,521 high-quality manual annotations and established a new\nbenchmark with 500 trajectories. We will open source all resources, including\nthe dataset, benchmark, model weight, and codes:\nhttps://mobile-r1.github.io/Mobile-R1/.", "AI": {"tldr": "Mobile-R1\u662f\u4e00\u79cd\u65b0\u7684\u79fb\u52a8\u4ee3\u7406\u65b9\u6cd5\uff0c\u91c7\u7528\u4efb\u52a1\u7ea7\u5956\u52b1\u7684\u591a\u8f6e\u4ea4\u4e92\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u4e09\u4e2a\u8bad\u7ec3\u9636\u6bb5\uff08\u683c\u5f0f\u5fae\u8c03\u3001\u57fa\u4e8e\u52a8\u4f5c\u7ea7\u5956\u52b1\u7684\u5355\u6b65\u5728\u7ebf\u8bad\u7ec3\u548c\u57fa\u4e8e\u4efb\u52a1\u7ea7\u5956\u52b1\u7684\u591a\u8f6e\u8f68\u8ff9\u5728\u7ebf\u8bad\u7ec3\uff09\u6765\u63d0\u9ad8\u63a2\u7d22\u80fd\u529b\u548c\u9519\u8bef\u7ea0\u6b63\u80fd\u529b\u3002\u540c\u65f6\uff0c\u7814\u7a76\u8005\u8fd8\u6536\u96c6\u4e86\u4e00\u4e2a\u5305\u542b28\u4e2a\u4e2d\u56fd\u5e94\u7528\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5efa\u7acb\u4e86500\u6761\u8f68\u8ff9\u7684\u65b0\u57fa\u51c6\uff0c\u6240\u6709\u8d44\u6e90\u5c06\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u79fb\u52a8\u4ee3\u7406\u4e3b\u8981\u4f9d\u8d56\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6216\u57fa\u4e8e\u52a8\u4f5c\u7ea7\u5956\u52b1\u7684\u5728\u7ebf\u4f18\u5316\uff0c\u8fd9\u9650\u5236\u4e86\u4ee3\u7406\u4e0e\u73af\u5883\u7684\u52a8\u6001\u4ea4\u4e92\uff0c\u5bb9\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\uff0c\u524a\u5f31\u4e86\u63a2\u7d22\u80fd\u529b\u548c\u9519\u8bef\u7ea0\u6b63\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMobile-R1\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u4efb\u52a1\u7ea7\u5956\u52b1\u7684\u591a\u8f6e\u4ea4\u4e92\u5f3a\u5316\u5b66\u4e60\u3002\u5176\u8bad\u7ec3\u6846\u67b6\u5305\u62ec\u4e09\u4e2a\u9636\u6bb5\uff1a\u521d\u59cb\u683c\u5f0f\u5fae\u8c03\u3001\u57fa\u4e8e\u52a8\u4f5c\u7ea7\u5956\u52b1\u7684\u5355\u6b65\u5728\u7ebf\u8bad\u7ec3\u4ee5\u53ca\u57fa\u4e8e\u591a\u8f6e\u8f68\u8ff9\u7684\u4efb\u52a1\u7ea7\u5956\u52b1\u5728\u7ebf\u8bad\u7ec3\u3002", "result": "\u901a\u8fc7\u589e\u5f3a\u63a2\u7d22\u548c\u9519\u8bef\u7ea0\u6b63\u80fd\u529b\uff0cMobile-R1\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u5e76\u5728\u65b0\u6536\u96c6\u7684\u6570\u636e\u96c6\u548c\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "Mobile-R1\u901a\u8fc7\u5f15\u5165\u4efb\u52a1\u7ea7\u5956\u52b1\u7684\u591a\u8f6e\u4ea4\u4e92\u5f3a\u5316\u5b66\u4e60\uff0c\u6709\u6548\u63d0\u5347\u4e86\u79fb\u52a8\u4ee3\u7406\u7684\u6027\u80fd\uff0c\u6570\u636e\u96c6\u548c\u57fa\u51c6\u7684\u53d1\u5e03\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u3002"}}
{"id": "2506.20573", "pdf": "https://arxiv.org/pdf/2506.20573", "abs": "https://arxiv.org/abs/2506.20573", "authors": ["Kristian Minchev", "Dimitar Iliev Dimitrov", "Nikola Konstantinov"], "title": "LARP: Learner-Agnostic Robust Data Prefiltering", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The widespread availability of large public datasets is a key factor behind\nthe recent successes of statistical inference and machine learning methods.\nHowever, these datasets often contain some low-quality or contaminated data, to\nwhich many learning procedures are sensitive. Therefore, the question of\nwhether and how public datasets should be prefiltered to facilitate accurate\ndownstream learning arises. On a technical level this requires the construction\nof principled data prefiltering methods which are learner-agnostic robust, in\nthe sense of provably protecting a set of pre-specified downstream learners\nfrom corrupted data. In this work, we formalize the problem of Learner-Agnostic\nRobust data Prefiltering (LARP), which aims at finding prefiltering procedures\nthat minimize a worst-case loss over a pre-specified set of learners. We first\ninstantiate our framework in the context of scalar mean estimation with Huber\nestimators under the Huber data contamination model. We provide a hardness\nresult on a specific problem instance and analyze several natural prefiltering\nprocedures. Our theoretical results indicate that performing LARP on a\nheterogeneous set of learners leads to some loss in model performance compared\nto the alternative of prefiltering data for each learner/use-case individually.\nWe explore the resulting utility loss and its dependence on the problem\nparameters via extensive experiments on real-world image and tabular data,\nobserving statistically significant reduction in utility. Finally, we model the\ntrade-off between the utility drop and the cost of repeated (learner-specific)\nprefiltering within a game-theoretic framework and showcase benefits of LARP\nfor large datasets.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u4e3a\u4e0b\u6e38\u5b66\u4e60\u4efb\u52a1\u9884\u8fc7\u6ee4\u516c\u5171\u6570\u636e\u96c6\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86LARP\u6846\u67b6\u5e76\u5206\u6790\u4e86\u5176\u6027\u80fd\u635f\u5931\u548c\u6548\u7528\u4e0b\u964d\u3002", "motivation": "\u516c\u5171\u6570\u636e\u96c6\u4e2d\u5b58\u5728\u4f4e\u8d28\u91cf\u6216\u53d7\u6c61\u67d3\u7684\u6570\u636e\uff0c\u8bb8\u591a\u5b66\u4e60\u65b9\u6cd5\u5bf9\u6b64\u654f\u611f\u3002\u56e0\u6b64\u9700\u8981\u6784\u5efa\u4e00\u79cd\u4e0e\u5b66\u4e60\u8005\u65e0\u5173\u7684\u7a33\u5065\u6570\u636e\u9884\u8fc7\u6ee4\u65b9\u6cd5\uff0c\u4ee5\u4fdd\u62a4\u4e0b\u6e38\u5b66\u4e60\u5668\u514d\u53d7\u8150\u8d25\u6570\u636e\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86LARP\u95ee\u9898\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u5e76\u5728Huber\u4f30\u8ba1\u5668\u548cHuber\u6570\u636e\u6c61\u67d3\u6a21\u578b\u7684\u80cc\u666f\u4e0b\u5b9e\u4f8b\u5316\u4e86\u8be5\u6846\u67b6\u3002\u7814\u7a76\u4e86\u51e0\u4e2a\u81ea\u7136\u7684\u9884\u8fc7\u6ee4\u7a0b\u5e8f\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u4e3a\u4e00\u7ec4\u5b66\u4e60\u5668\u6267\u884cLARP\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u635f\u5931\u3002", "result": "\u7406\u8bba\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5f02\u6784\u5b66\u4e60\u5668\u96c6\u5408\u4e0a\u6267\u884cLARP\u4f1a\u5bfc\u81f4\u6027\u80fd\u635f\u5931\u3002\u901a\u8fc7\u5728\u771f\u5b9e\u4e16\u754c\u56fe\u50cf\u548c\u8868\u683c\u6570\u636e\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u89c2\u5bdf\u5230\u7edf\u8ba1\u663e\u8457\u7684\u6548\u7528\u51cf\u5c11\u3002", "conclusion": "LARP\u5728\u5927\u578b\u6570\u636e\u96c6\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u5c3d\u7ba1\u5bf9\u5f02\u6784\u5b66\u4e60\u5668\u96c6\u5408\u8fdb\u884c\u9884\u8fc7\u6ee4\u4f1a\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u7684\u635f\u5931\uff0c\u4f46\u901a\u8fc7\u535a\u5f08\u8bba\u6846\u67b6\u53ef\u4ee5\u6743\u8861\u6548\u7528\u4e0b\u964d\u548c\u91cd\u590d\u9884\u8fc7\u6ee4\u7684\u6210\u672c\u3002"}}
{"id": "2506.19895", "pdf": "https://arxiv.org/pdf/2506.19895", "abs": "https://arxiv.org/abs/2506.19895", "authors": ["Miguel N. Font", "Jos\u00e9 L. Jorro-Aragoneses", "Carlos M. Ala\u00edz"], "title": "A Framework for Uncertainty Quantification Based on Nearest Neighbors Across Layers", "categories": ["cs.LG", "cs.AI"], "comment": "This paper has been accepted for presentation at ICANN 2025\n  (International Conference on Artificial Neural Networks) and will appear in\n  the conference proceedings published by Springer Nature in the Lecture Notes\n  in Computer Science (LNCS) series. The final authenticated version will be\n  available on the publisher website", "summary": "Neural Networks have high accuracy in solving problems where it is difficult\nto detect patterns or create a logical model. However, these algorithms\nsometimes return wrong solutions, which become problematic in high-risk domains\nlike medical diagnosis or autonomous driving. One strategy to detect and\nmitigate these errors is the measurement of the uncertainty over neural network\ndecisions. In this paper, we present a novel post-hoc framework for measuring\nthe uncertainty of a decision based on retrieved training cases that have a\nsimilar activation vector to the query for each layer. Based on these retrieved\ncases, we propose two new metrics: Decision Change and Layer Uncertainty, which\ncapture changes in nearest-neighbor class distributions across layers. We\nevaluated our approach in a classification model for two datasets: CIFAR-10 and\nMNIST. The results show that these metrics enhance uncertainty estimation,\nespecially in challenging classification tasks, outperforming softmax-based\nconfidence.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e8b\u540e\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u4e0e\u67e5\u8be2\u5728\u5404\u5c42\u5177\u6709\u76f8\u4f3c\u6fc0\u6d3b\u5411\u91cf\u7684\u8bad\u7ec3\u6848\u4f8b\u6765\u6d4b\u91cf\u795e\u7ecf\u7f51\u7edc\u51b3\u7b56\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u4e2a\u65b0\u6307\u6807\uff1a\u51b3\u7b56\u53d8\u5316\u548c\u5c42\u4e0d\u786e\u5b9a\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9b\u6307\u6807\u63d0\u9ad8\u4e86\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u5c24\u5176\u662f\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u4f18\u4e8e\u57fa\u4e8esoftmax\u7684\u7f6e\u4fe1\u5ea6\u3002", "motivation": "\u795e\u7ecf\u7f51\u7edc\u5728\u89e3\u51b3\u96be\u4ee5\u68c0\u6d4b\u6a21\u5f0f\u6216\u521b\u5efa\u903b\u8f91\u6a21\u578b\u7684\u95ee\u9898\u65f6\u5177\u6709\u9ad8\u51c6\u786e\u6027\uff0c\u4f46\u6709\u65f6\u4f1a\u8fd4\u56de\u9519\u8bef\u89e3\u51b3\u65b9\u6848\uff0c\u8fd9\u5728\u533b\u7597\u8bca\u65ad\u6216\u81ea\u52a8\u9a7e\u9a76\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u6210\u4e3a\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u7b56\u7565\u6765\u68c0\u6d4b\u548c\u7f13\u89e3\u8fd9\u4e9b\u9519\u8bef\uff0c\u6d4b\u91cf\u795e\u7ecf\u7f51\u7edc\u51b3\u7b56\u7684\u4e0d\u786e\u5b9a\u6027\u662f\u4e00\u4e2a\u91cd\u8981\u65b9\u5411\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e8b\u540e\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u4e0e\u67e5\u8be2\u5728\u5404\u5c42\u5177\u6709\u76f8\u4f3c\u6fc0\u6d3b\u5411\u91cf\u7684\u8bad\u7ec3\u6848\u4f8b\u6765\u6d4b\u91cf\u51b3\u7b56\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u57fa\u4e8e\u68c0\u7d22\u5230\u7684\u6848\u4f8b\uff0c\u63d0\u51fa\u4e86\u4e24\u4e2a\u65b0\u6307\u6807\uff1a\u51b3\u7b56\u53d8\u5316\uff08Decision Change\uff09\u548c\u5c42\u4e0d\u786e\u5b9a\u6027\uff08Layer Uncertainty\uff09\uff0c\u7528\u4e8e\u6355\u83b7\u8de8\u5c42\u6700\u8fd1\u90bb\u7c7b\u522b\u5206\u5e03\u7684\u53d8\u5316\u3002", "result": "\u8be5\u65b9\u6cd5\u5728CIFAR-10\u548cMNIST\u6570\u636e\u96c6\u4e0a\u7684\u5206\u7c7b\u6a21\u578b\u4e2d\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u8fd9\u4e9b\u65b0\u6307\u6807\u63d0\u9ad8\u4e86\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u8868\u73b0\u4f18\u4e8e\u57fa\u4e8esoftmax\u7684\u7f6e\u4fe1\u5ea6\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u548c\u65b0\u6307\u6807\u4e3a\u6d4b\u91cf\u795e\u7ecf\u7f51\u7edc\u51b3\u7b56\u7684\u4e0d\u786e\u5b9a\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u56f0\u96be\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u53ef\u4ee5\u7528\u4e8e\u6539\u5584\u9ad8\u98ce\u9669\u9886\u57df\u7684\u51b3\u7b56\u53ef\u9760\u6027\u3002"}}
{"id": "2506.20357", "pdf": "https://arxiv.org/pdf/2506.20357", "abs": "https://arxiv.org/abs/2506.20357", "authors": ["Sungwon Han", "Sungkyu Park", "Seungeon Lee"], "title": "Tabular Feature Discovery With Reasoning Type Exploration", "categories": ["cs.AI"], "comment": null, "summary": "Feature engineering for tabular data remains a critical yet challenging step\nin machine learning. Recently, large language models (LLMs) have been used to\nautomatically generate new features by leveraging their vast knowledge.\nHowever, existing LLM-based approaches often produce overly simple or\nrepetitive features, partly due to inherent biases in the transformations the\nLLM chooses and the lack of structured reasoning guidance during generation. In\nthis paper, we propose a novel method REFeat, which guides an LLM to discover\ndiverse and informative features by leveraging multiple types of reasoning to\nsteer the feature generation process. Experiments on 59 benchmark datasets\ndemonstrate that our approach not only achieves higher predictive accuracy on\naverage, but also discovers more diverse and meaningful features. These results\nhighlight the promise of incorporating rich reasoning paradigms and adaptive\nstrategy selection into LLM-driven feature discovery for tabular data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aREFeat\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5bfc\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5229\u7528\u591a\u79cd\u63a8\u7406\u7c7b\u578b\u6765\u751f\u6210\u66f4\u591a\u6837\u5316\u548c\u6709\u610f\u4e49\u7684\u7279\u5f81\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u8fd8\u53d1\u73b0\u4e86\u66f4\u4e30\u5bcc\u7684\u7279\u5f81\u3002", "motivation": "\u5728\u8868\u683c\u6570\u636e\u7684\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u7279\u5f81\u5de5\u7a0b\u4ecd\u7136\u662f\u4e00\u4e2a\u5173\u952e\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u6b65\u9aa4\u3002\u5c3d\u7ba1\u73b0\u6709\u7684\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u53ef\u4ee5\u81ea\u52a8\u751f\u6210\u65b0\u7279\u5f81\uff0c\u4f46\u8fd9\u4e9b\u7279\u5f81\u5f80\u5f80\u8fc7\u4e8e\u7b80\u5355\u6216\u91cd\u590d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5REFeat\uff0c\u901a\u8fc7\u5229\u7528\u591a\u79cd\u63a8\u7406\u7c7b\u578b\u6765\u6307\u5bfcLLM\u8fdb\u884c\u7279\u5f81\u751f\u6210\u8fc7\u7a0b\uff0c\u4ece\u800c\u53d1\u73b0\u66f4\u591a\u6837\u5316\u548c\u6709\u610f\u4e49\u7684\u7279\u5f81\u3002", "result": "\u572859\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5e73\u5747\u9884\u6d4b\u51c6\u786e\u6027\u66f4\u9ad8\uff0c\u8fd8\u53d1\u73b0\u4e86\u66f4\u591a\u6837\u5316\u548c\u6709\u610f\u4e49\u7684\u7279\u5f81\u3002", "conclusion": "\u5c06\u4e30\u5bcc\u7684\u63a8\u7406\u8303\u5f0f\u548c\u81ea\u9002\u5e94\u7b56\u7565\u9009\u62e9\u7eb3\u5165LLM\u9a71\u52a8\u7684\u7279\u5f81\u53d1\u73b0\u4e2d\uff0c\u5bf9\u4e8e\u8868\u683c\u6570\u636e\u5177\u6709\u5f88\u5927\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.18221", "pdf": "https://arxiv.org/pdf/2506.18221", "abs": "https://arxiv.org/abs/2506.18221", "authors": ["Xingyu Alice Yang", "Jianyu Zhang", "L\u00e9on Bottou"], "title": "These are Not All the Features You are Looking For: A Fundamental Bottleneck In Supervised Pretraining", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "10 pages, 7 figures, Preprint. Under review", "summary": "Transfer learning is a cornerstone of modern machine learning, promising a\nway to adapt models pretrained on a broad mix of data to new tasks with minimal\nnew data. However, a significant challenge remains in ensuring that transferred\nfeatures are sufficient to handle unseen datasets, amplified by the difficulty\nof quantifying whether two tasks are \"related\". To address these challenges, we\nevaluate model transfer from a pretraining mixture to each of its component\ntasks, assessing whether pretrained features can match the performance of\ntask-specific direct training. We identify a fundamental limitation in deep\nlearning models -- an \"information saturation bottleneck\" -- where networks\nfail to learn new features once they encode similar competing features during\ntraining. When restricted to learning only a subset of key features during\npretraining, models will permanently lose critical features for transfer and\nperform inconsistently on data distributions, even components of the training\nmixture. Empirical evidence from published studies suggests that this\nphenomenon is pervasive in deep learning architectures -- factors such as data\ndistribution or ordering affect the features that current representation\nlearning methods can learn over time. This study suggests that relying solely\non large-scale networks may not be as effective as focusing on task-specific\ntraining, when available. We propose richer feature representations as a\npotential solution to better generalize across new datasets and, specifically,\npresent existing methods alongside a novel approach, the initial steps towards\naddressing this challenge.", "AI": {"tldr": "\u8fc1\u79fb\u5b66\u4e60\u662f\u73b0\u4ee3\u673a\u5668\u5b66\u4e60\u7684\u57fa\u77f3\uff0c\u4f46\u5176\u5728\u5904\u7406\u672a\u89c1\u6570\u636e\u96c6\u548c\u91cf\u5316\u4efb\u52a1\u76f8\u5173\u6027\u65b9\u9762\u5b58\u5728\u6311\u6218\u3002\u672c\u6587\u8bc4\u4f30\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u5411\u5404\u7ec4\u6210\u4efb\u52a1\u8f6c\u79fb\u7684\u80fd\u529b\uff0c\u5e76\u53d1\u73b0\u4e86\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u201c\u4fe1\u606f\u9971\u548c\u74f6\u9888\u201d\u3002\u6b64\u74f6\u9888\u5bfc\u81f4\u7f51\u7edc\u65e0\u6cd5\u5b66\u4e60\u65b0\u7279\u5f81\uff0c\u4ece\u800c\u5f71\u54cd\u8fc1\u79fb\u6027\u80fd\u3002\u7814\u7a76\u8868\u660e\uff0c\u4ec5\u4f9d\u8d56\u5927\u89c4\u6a21\u7f51\u7edc\u53ef\u80fd\u4e0d\u5982\u4e13\u6ce8\u4e8e\u4efb\u52a1\u7279\u5b9a\u8bad\u7ec3\u6709\u6548\u3002\u63d0\u51fa\u66f4\u4e30\u5bcc\u7684\u7279\u5f81\u8868\u793a\u4f5c\u4e3a\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u8fc1\u79fb\u5b66\u4e60\u627f\u8bfa\u4ee5\u6700\u5c11\u7684\u65b0\u6570\u636e\u5c06\u9884\u8bad\u7ec3\u6a21\u578b\u9002\u5e94\u65b0\u4efb\u52a1\uff0c\u4f46\u786e\u4fdd\u8f6c\u79fb\u7279\u5f81\u8db3\u4ee5\u5904\u7406\u672a\u89c1\u6570\u636e\u96c6\u4ecd\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002\u6b64\u5916\uff0c\u91cf\u5316\u4efb\u52a1\u95f4\u7684\u201c\u76f8\u5173\u6027\u201d\u4e5f\u5f88\u56f0\u96be\u3002", "method": "\u8bc4\u4f30\u4ece\u9884\u8bad\u7ec3\u6df7\u5408\u6570\u636e\u5230\u6bcf\u4e2a\u7ec4\u6210\u4efb\u52a1\u7684\u6a21\u578b\u8f6c\u79fb\uff0c\u5206\u6790\u9884\u8bad\u7ec3\u7279\u5f81\u662f\u5426\u80fd\u5339\u914d\u4efb\u52a1\u7279\u5b9a\u76f4\u63a5\u8bad\u7ec3\u7684\u6027\u80fd\u3002\u8bc6\u522b\u51fa\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u201c\u4fe1\u606f\u9971\u548c\u74f6\u9888\u201d\uff0c\u5e76\u7814\u7a76\u9650\u5236\u9884\u8bad\u7ec3\u671f\u95f4\u5b66\u4e60\u7684\u5173\u952e\u7279\u5f81\u5b50\u96c6\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u5f53\u7f51\u7edc\u5728\u8bad\u7ec3\u4e2d\u7f16\u7801\u7c7b\u4f3c\u7ade\u4e89\u7279\u5f81\u540e\uff0c\u65e0\u6cd5\u518d\u5b66\u4e60\u65b0\u7279\u5f81\u3002\u5982\u679c\u9884\u8bad\u7ec3\u65f6\u4ec5\u5b66\u4e60\u5173\u952e\u7279\u5f81\u7684\u5b50\u96c6\uff0c\u6a21\u578b\u5c06\u6c38\u4e45\u4e22\u5931\u91cd\u8981\u7279\u5f81\uff0c\u5bfc\u81f4\u5728\u6570\u636e\u5206\u5e03\u4e0a\u7684\u8868\u73b0\u4e0d\u4e00\u81f4\u3002\u5b9e\u8bc1\u8bc1\u636e\u8868\u660e\uff0c\u8fd9\u79cd\u73b0\u8c61\u5728\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u4e2d\u666e\u904d\u5b58\u5728\u3002", "conclusion": "\u4f9d\u9760\u5927\u89c4\u6a21\u7f51\u7edc\u53ef\u80fd\u4e0d\u5982\u805a\u7126\u4e8e\u4efb\u52a1\u7279\u5b9a\u8bad\u7ec3\u6709\u6548\u3002\u5efa\u8bae\u91c7\u7528\u66f4\u4e30\u5bcc\u7684\u7279\u5f81\u8868\u793a\u6765\u66f4\u597d\u5730\u6cdb\u5316\u5230\u65b0\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e86\u73b0\u6709\u65b9\u6cd5\u4e0e\u4e00\u79cd\u65b0\u65b9\u6cd5\u4f5c\u4e3a\u89e3\u51b3\u8be5\u6311\u6218\u7684\u521d\u6b65\u6b65\u9aa4\u3002"}}
{"id": "2506.19929", "pdf": "https://arxiv.org/pdf/2506.19929", "abs": "https://arxiv.org/abs/2506.19929", "authors": ["Efe \u00c7ak\u0131r", "Patrick Dumond"], "title": "A Comparative Analysis of Reinforcement Learning and Conventional Deep Learning Approaches for Bearing Fault Diagnosis", "categories": ["cs.LG", "I.2.6"], "comment": "5 pages, 5 figures. To appear in the Proceedings of the Canadian\n  Society for Mechanical Engineering (CSME) Congress 2025", "summary": "Bearing faults in rotating machinery can lead to significant operational\ndisruptions and maintenance costs. Modern methods for bearing fault diagnosis\nrely heavily on vibration analysis and machine learning techniques, which often\nrequire extensive labeled data and may not adapt well to dynamic environments.\nThis study explores the feasibility of reinforcement learning (RL),\nspecifically Deep Q-Networks (DQNs), for bearing fault classification tasks in\nmachine condition monitoring to enhance the accuracy and adaptability of\nbearing fault diagnosis. The results demonstrate that while RL models developed\nin this study can match the performance of traditional supervised learning\nmodels under controlled conditions, they excel in adaptability when equipped\nwith optimized reward structures. However, their computational demands\nhighlight areas for further improvement. These findings demonstrate RL's\npotential to complement traditional methods, paving the way for adaptive\ndiagnostic frameworks.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u5f3a\u5316\u5b66\u4e60\uff0c\u7279\u522b\u662f\u6df1\u5ea6Q\u7f51\u7edc\uff08DQN\uff09\uff0c\u5728\u8f74\u627f\u6545\u969c\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u53ef\u884c\u6027\uff0c\u4ee5\u63d0\u9ad8\u8bca\u65ad\u7684\u51c6\u786e\u6027\u548c\u9002\u5e94\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5728\u63a7\u5236\u6761\u4ef6\u4e0b\uff0cRL\u6a21\u578b\u7684\u8868\u73b0\u53ef\u4e0e\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u5ab2\u7f8e\uff0c\u4f46\u5728\u4f18\u5316\u5956\u52b1\u7ed3\u6784\u540e\uff0c\u5176\u9002\u5e94\u80fd\u529b\u66f4\u80dc\u4e00\u7b79\u3002\u7136\u800c\uff0c\u8ba1\u7b97\u9700\u6c42\u8f83\u9ad8\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u7684\u8f74\u627f\u6545\u969c\u8bca\u65ad\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u632f\u52a8\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u4e14\u5728\u52a8\u6001\u73af\u5883\u4e2d\u9002\u5e94\u6027\u8f83\u5dee\u3002\u56e0\u6b64\uff0c\u63a2\u7d22\u5f3a\u5316\u5b66\u4e60\u5728\u8f74\u627f\u6545\u969c\u5206\u7c7b\u4e2d\u7684\u5e94\u7528\u6210\u4e3a\u5fc5\u8981\u3002", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6df1\u5ea6Q\u7f51\u7edc\uff08DQN\uff09\u8fdb\u884c\u8f74\u627f\u6545\u969c\u5206\u7c7b\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u5956\u52b1\u7ed3\u6784\u6765\u63d0\u9ad8\u6a21\u578b\u9002\u5e94\u6027\u3002", "result": "\u5728\u63a7\u5236\u6761\u4ef6\u4e0b\uff0c\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u8868\u73b0\u4e0e\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u6a21\u578b\u76f8\u5f53\uff1b\u5728\u4f18\u5316\u5956\u52b1\u7ed3\u6784\u540e\uff0c\u9002\u5e94\u6027\u663e\u8457\u63d0\u9ad8\uff0c\u4f46\u8ba1\u7b97\u9700\u6c42\u8f83\u5927\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u5177\u6709\u8865\u5145\u4f20\u7edf\u8f74\u627f\u6545\u969c\u8bca\u65ad\u65b9\u6cd5\u7684\u6f5c\u529b\uff0c\u4e3a\u5f00\u53d1\u81ea\u9002\u5e94\u8bca\u65ad\u6846\u67b6\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2506.20384", "pdf": "https://arxiv.org/pdf/2506.20384", "abs": "https://arxiv.org/abs/2506.20384", "authors": ["Dror Ivry", "Oran Nahum"], "title": "Paladin-mini: A Compact and Efficient Grounding Model Excelling in Real-World Scenarios", "categories": ["cs.AI"], "comment": "6 pages, 2 figures", "summary": "This paper introduces two significant contributions to address the issue of\ngrounding claims in a given context. Grounding means that given a context\n(document) and a claim, there's at least one supportive evidence for the claim\nin the document. We will introduce Paladin-mini, a compact (3.8B parameters)\nopen-source classifier model (used for labeling data as grounded or ungrounded)\nengineered for robust performance in real-world scenarios, and the\ngrounding-benchmark, a new evaluation dataset designed to assess performance on\ncritical reasoning tasks. We'll also demonstrate the results of Paladin-mini\nwith benchmarks against the current State-of-the-art and share clear and\nreproducible results.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u4e2a\u91cd\u8981\u8d21\u732e\uff0c\u4ee5\u89e3\u51b3\u5728\u7ed9\u5b9a\u4e0a\u4e0b\u6587\u4e2d\u9a8c\u8bc1\u4e3b\u5f20\u7684\u95ee\u9898\uff1a\u4e00\u4e2a\u7d27\u51d1\u7684\u5f00\u6e90\u5206\u7c7b\u6a21\u578bPaladin-mini\uff083.8B\u53c2\u6570\uff09\uff0c\u7528\u4e8e\u5224\u65ad\u6570\u636e\u662f\u5426\u5177\u6709\u652f\u6301\u6027\u8bc1\u636e\uff1b\u4ee5\u53ca\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u6570\u636e\u96c6grounding-benchmark\uff0c\u7528\u4e8e\u8bc4\u4f30\u5173\u952e\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u3002\u8bba\u6587\u8fd8\u5c55\u793a\u4e86Paladin-mini\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\uff0c\u5e76\u5206\u4eab\u4e86\u6e05\u6670\u4e14\u53ef\u91cd\u590d\u7684\u7ed3\u679c\u3002", "motivation": "\u5728\u6587\u6863\u548c\u4e3b\u5f20\u7684\u80cc\u666f\u4e0b\uff0c\u786e\u4fdd\u4e3b\u5f20\u6709\u81f3\u5c11\u4e00\u4e2a\u652f\u6301\u6027\u7684\u8bc1\u636e\u662f\u91cd\u8981\u7684\u3002\u7136\u800c\uff0c\u76ee\u524d\u53ef\u80fd\u7f3a\u4e4f\u6709\u6548\u7684\u5de5\u5177\u548c\u6570\u636e\u96c6\u6765\u51c6\u786e\u5730\u8bc4\u4f30\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPaladin-mini\u7684\u7d27\u51d1\u578b\u5f00\u6e90\u5206\u7c7b\u6a21\u578b\uff083.8B\u53c2\u6570\uff09\uff0c\u7528\u4e8e\u5224\u65ad\u6570\u636e\u662f\u5426\u6709\u652f\u6301\u6027\u8bc1\u636e\uff08grounded\u6216ungrounded\uff09\u3002\u540c\u65f6\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u6570\u636e\u96c6grounding-benchmark\uff0c\u7528\u4e8e\u8861\u91cf\u5728\u5173\u952e\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "Paladin-mini\u6a21\u578b\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e0e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6280\u672f\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\u3002\u6b64\u5916\uff0c\u7814\u7a76\u63d0\u4f9b\u4e86\u6e05\u6670\u4e14\u53ef\u590d\u73b0\u7684\u7ed3\u679c\u3002", "conclusion": "Paladin-mini\u6a21\u578b\u548cgrounding-benchmark\u6570\u636e\u96c6\u4e3a\u89e3\u51b3\u5728\u7ed9\u5b9a\u4e0a\u4e0b\u6587\u4e2d\u9a8c\u8bc1\u4e3b\u5f20\u7684\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5de5\u5177\uff0c\u589e\u5f3a\u4e86\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u7a33\u5065\u6027\uff0c\u5e76\u63a8\u52a8\u4e86\u8be5\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2506.19935", "pdf": "https://arxiv.org/pdf/2506.19935", "abs": "https://arxiv.org/abs/2506.19935", "authors": ["Shuchen Xue", "Tianyu Xie", "Tianyang Hu", "Zijin Feng", "Jiacheng Sun", "Kenji Kawaguchi", "Zhenguo Li", "Zhi-Ming Ma"], "title": "Any-Order GPT as Masked Diffusion Model: Decoupling Formulation and Architecture", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": null, "summary": "Large language models (LLMs) predominantly use autoregressive (AR)\napproaches, but masked diffusion models (MDMs) are emerging as viable\nalternatives. A key challenge in comparing AR and MDM paradigms is their\ntypical architectural difference: AR models are often decoder-only, while MDMs\nhave largely been encoder-only. This practice of changing both the modeling\nparadigm and architecture simultaneously makes direct comparisons unfair, as\nit's hard to distinguish whether observed differences stem from the paradigm\nitself or the architectural shift. This research evaluates MDMs within a\ndecoder-only framework to: (1) equitably compare MDM (as Any-Order AR, or\nAO-AR) and standard AR paradigms. Our investigation suggests that the standard\nAO-AR objective, which averages over all token permutations, may benefit from\nrefinement, as many permutations appear less informative compared to the\nlanguage's inherent left-to-right structure. (2) Investigate architectural\ninfluences (decoder-only vs. encoder-only) within MDMs. We demonstrate that\nwhile encoder-only MDMs model a simpler conditional probability space,\ndecoder-only MDMs can achieve dramatic generation speedups ($\\sim25\\times$) and\ncomparable perplexity with temperature annealing despite modeling a vastly\nlarger space, highlighting key trade-offs. This work thus decouples core\nparadigm differences from architectural influences, offering insights for\nfuture model design. Code is available at https://github.com/scxue/AO-GPT-MDM.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5728\u4ec5\u89e3\u7801\u5668\u6846\u67b6\u5185\u8bc4\u4f30\u63a9\u7801\u6269\u6563\u6a21\u578b\uff08MDM\uff09\uff0c\u5b9e\u73b0\u4e86\u5bf9MDM\uff08\u4f5c\u4e3a\u4efb\u610f\u987a\u5e8f\u81ea\u56de\u5f52\uff0c\u6216AO-AR\uff09\u548c\u6807\u51c6\u81ea\u56de\u5f52\uff08AR\uff09\u8303\u5f0f\u7684\u516c\u5e73\u6bd4\u8f83\uff0c\u5e76\u63a2\u8ba8\u4e86\u67b6\u6784\u5f71\u54cd\uff08\u4ec5\u89e3\u7801\u5668\u5bf9\u6bd4\u4ec5\u7f16\u7801\u5668\uff09\u5185\u7684MDM\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\u8868\u660e\uff0c\u5c3d\u7ba1\u4ec5\u7f16\u7801\u5668\u7684MDM\u5efa\u6a21\u4e86\u4e00\u4e2a\u66f4\u7b80\u5355\u7684\u6761\u4ef6\u6982\u7387\u7a7a\u95f4\uff0c\u4f46\u4ec5\u89e3\u7801\u5668\u7684MDM\u53ef\u4ee5\u901a\u8fc7\u6e29\u5ea6\u9000\u706b\u5b9e\u73b0\u663e\u8457\u7684\u751f\u6210\u52a0\u901f\uff08~25\u500d\uff09\u548c\u53ef\u6bd4\u7684\u56f0\u60d1\u5ea6\uff0c\u5c3d\u7ba1\u5b83\u5efa\u6a21\u4e86\u4e00\u4e2a\u66f4\u5927\u7684\u7a7a\u95f4\u3002", "motivation": "\u5f53\u524d\u5728\u6bd4\u8f83\u81ea\u56de\u5f52\uff08AR\uff09\u548c\u63a9\u7801\u6269\u6563\u6a21\u578b\uff08MDM\uff09\u8303\u5f0f\u65f6\uff0c\u7531\u4e8e\u540c\u65f6\u6539\u53d8\u5efa\u6a21\u8303\u5f0f\u548c\u67b6\u6784\uff0c\u5bfc\u81f4\u4e0d\u516c\u5e73\u7684\u76f4\u63a5\u6bd4\u8f83\u3002\u56e0\u6b64\u9700\u8981\u5728\u4e00\u4e2a\u516c\u5e73\u7684\u6846\u67b6\u4e0b\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ee5\u533a\u5206\u8303\u5f0f\u672c\u8eab\u548c\u67b6\u6784\u53d8\u5316\u7684\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u5728\u4ec5\u89e3\u7801\u5668\u6846\u67b6\u5185\u8bc4\u4f30MDM\uff0c\u4ee5\uff1a(1) \u516c\u5e73\u5730\u6bd4\u8f83MDM\uff08\u4f5c\u4e3a\u4efb\u610f\u987a\u5e8f\u81ea\u56de\u5f52\uff0c\u6216AO-AR\uff09\u548c\u6807\u51c6AR\u8303\u5f0f\uff1b(2) \u63a2\u8ba8\u67b6\u6784\u5f71\u54cd\uff08\u4ec5\u89e3\u7801\u5668 vs. \u4ec5\u7f16\u7801\u5668\uff09\u5185\u7684MDM\u8868\u73b0\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6807\u51c6\u7684AO-AR\u76ee\u6807\u53ef\u80fd\u9700\u8981\u6539\u8fdb\uff0c\u56e0\u4e3a\u8bb8\u591a\u6392\u5217\u76f8\u6bd4\u8bed\u8a00\u56fa\u6709\u7684\u5de6\u5230\u53f3\u7ed3\u6784\u663e\u5f97\u4e0d\u591f\u6709\u4fe1\u606f\u91cf\u3002\u6b64\u5916\uff0c\u5c3d\u7ba1\u4ec5\u7f16\u7801\u5668\u7684MDM\u5efa\u6a21\u4e86\u4e00\u4e2a\u66f4\u7b80\u5355\u7684\u6761\u4ef6\u6982\u7387\u7a7a\u95f4\uff0c\u4f46\u4ec5\u89e3\u7801\u5668\u7684MDM\u53ef\u4ee5\u5b9e\u73b0\u663e\u8457\u7684\u751f\u6210\u52a0\u901f\uff08~25\u500d\uff09\u548c\u53ef\u6bd4\u7684\u56f0\u60d1\u5ea6\uff0c\u5c3d\u7ba1\u5b83\u5efa\u6a21\u4e86\u4e00\u4e2a\u66f4\u5927\u7684\u7a7a\u95f4\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5c06\u6838\u5fc3\u8303\u5f0f\u5dee\u5f02\u4e0e\u67b6\u6784\u5f71\u54cd\u5206\u79bb\uff0c\u4e3a\u672a\u6765\u7684\u6a21\u578b\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2506.20401", "pdf": "https://arxiv.org/pdf/2506.20401", "abs": "https://arxiv.org/abs/2506.20401", "authors": ["Jinchun Du", "Bojie Shen", "Muhammad Aamir Cheema", "Adel N. Toosi"], "title": "Smart Ride and Delivery Services with Electric Vehicles: Leveraging Bidirectional Charging for Profit Optimisation", "categories": ["cs.AI"], "comment": null, "summary": "With the rising popularity of electric vehicles (EVs), modern service\nsystems, such as ride-hailing delivery services, are increasingly integrating\nEVs into their operations. Unlike conventional vehicles, EVs often have a\nshorter driving range, necessitating careful consideration of charging when\nfulfilling requests. With recent advances in Vehicle-to-Grid (V2G) technology -\nallowing EVs to also discharge energy back to the grid - new opportunities and\ncomplexities emerge. We introduce the Electric Vehicle Orienteering Problem\nwith V2G (EVOP-V2G): a profit-maximization problem where EV drivers must select\ncustomer requests or orders while managing when and where to charge or\ndischarge. This involves navigating dynamic electricity prices, charging\nstation selection, and route constraints. We formulate the problem as a Mixed\nInteger Programming (MIP) model and propose two near-optimal metaheuristic\nalgorithms: one evolutionary (EA) and the other based on large neighborhood\nsearch (LNS). Experiments on real-world data show our methods can double driver\nprofits compared to baselines, while maintaining near-optimal performance on\nsmall instances and excellent scalability on larger ones. Our work highlights a\npromising path toward smarter, more profitable EV-based mobility systems that\nactively support the energy grid.", "AI": {"tldr": "\u968f\u7740\u7535\u52a8\u6c7d\u8f66\uff08EV\uff09\u7684\u666e\u53ca\uff0c\u73b0\u4ee3\u670d\u52a1\u7cfb\u7edf\u8d8a\u6765\u8d8a\u591a\u5730\u5c06\u7535\u52a8\u6c7d\u8f66\u6574\u5408\u5230\u8fd0\u8425\u4e2d\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408Vehicle-to-Grid (V2G)\u6280\u672f\u7684\u65b0\u95ee\u9898\u2014\u2014Electric Vehicle Orienteering Problem with V2G\uff08EVOP-V2G\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u53f8\u673a\u7684\u5229\u6da6\u3002", "motivation": "\u7535\u52a8\u6c7d\u8f66\u9010\u6e10\u88ab\u96c6\u6210\u5230\u73b0\u4ee3\u670d\u52a1\u7cfb\u7edf\u4e2d\uff0c\u4f46\u7531\u4e8e\u5176\u7eed\u822a\u91cc\u7a0b\u8f83\u77ed\u4ee5\u53caV2G\u6280\u672f\u7684\u51fa\u73b0\uff0c\u9700\u8981\u89e3\u51b3\u5145\u7535\u548c\u653e\u7535\u7ba1\u7406\u7684\u95ee\u9898\uff0c\u4ee5\u5b9e\u73b0\u5229\u6da6\u6700\u5927\u5316\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MIP\uff09\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u8fd1\u4f3c\u6700\u4f18\u7684\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\uff1a\u8fdb\u5316\u7b97\u6cd5\uff08EA\uff09\u548c\u57fa\u4e8e\u5927\u90bb\u57df\u641c\u7d22\u7684\u7b97\u6cd5\uff08LNS\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u5c06\u53f8\u673a\u7684\u5229\u6da6\u63d0\u9ad8\u4e00\u500d\uff0c\u5e76\u4e14\u5728\u5c0f\u89c4\u6a21\u5b9e\u4f8b\u4e0a\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\uff0c\u5728\u5927\u89c4\u6a21\u5b9e\u4f8b\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u66f4\u667a\u80fd\u3001\u66f4\u6709\u5229\u53ef\u56fe\u7684\u57fa\u4e8e\u7535\u52a8\u6c7d\u8f66\u7684\u79fb\u52a8\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u5e0c\u671b\u7684\u9014\u5f84\uff0c\u540c\u65f6\u79ef\u6781\u652f\u6301\u80fd\u6e90\u7f51\u7edc\u3002"}}
{"id": "2506.19937", "pdf": "https://arxiv.org/pdf/2506.19937", "abs": "https://arxiv.org/abs/2506.19937", "authors": ["Tomas M. Bosschieter", "Luis Franca", "Jessica Wolk", "Yiyuan Wu", "Bella Mehta", "Joseph Dehoney", "Orsolya Kiss", "Fiona C. Baker", "Qingyu Zhao", "Rich Caruana", "Kilian M. Pohl"], "title": "The Most Important Features in Generalized Additive Models Might Be Groups of Features", "categories": ["cs.LG"], "comment": null, "summary": "While analyzing the importance of features has become ubiquitous in\ninterpretable machine learning, the joint signal from a group of related\nfeatures is sometimes overlooked or inadvertently excluded. Neglecting the\njoint signal could bypass a critical insight: in many instances, the most\nsignificant predictors are not isolated features, but rather the combined\neffect of groups of features. This can be especially problematic for datasets\nthat contain natural groupings of features, including multimodal datasets. This\npaper introduces a novel approach to determine the importance of a group of\nfeatures for Generalized Additive Models (GAMs) that is efficient, requires no\nmodel retraining, allows defining groups posthoc, permits overlapping groups,\nand remains meaningful in high-dimensional settings. Moreover, this definition\noffers a parallel with explained variation in statistics. We showcase\nproperties of our method on three synthetic experiments that illustrate the\nbehavior of group importance across various data regimes. We then demonstrate\nthe importance of groups of features in identifying depressive symptoms from a\nmultimodal neuroscience dataset, and study the importance of social\ndeterminants of health after total hip arthroplasty. These two case studies\nreveal that analyzing group importance offers a more accurate, holistic view of\nthe medical issues compared to a single-feature analysis.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u786e\u5b9a\u5e7f\u4e49\u52a0\u6cd5\u6a21\u578b\uff08GAMs\uff09\u4e2d\u7279\u5f81\u7ec4\u7684\u91cd\u8981\u6027\u3002\u8fd9\u79cd\u65b9\u6cd5\u9ad8\u6548\u3001\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3001\u5141\u8bb8\u4e8b\u540e\u5b9a\u4e49\u548c\u91cd\u53e0\u7684\u7279\u5f81\u7ec4\uff0c\u5e76\u4e14\u5728\u9ad8\u7ef4\u8bbe\u7f6e\u4e0b\u4ecd\u7136\u6709\u610f\u4e49\u3002\u901a\u8fc7\u5408\u6210\u5b9e\u9a8c\u548c\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u591a\u6a21\u6001\u6570\u636e\u4e2d\u7684\u5e94\u7528\u53ca\u5176\u5bf9\u533b\u5b66\u95ee\u9898\u66f4\u51c6\u786e\u7684\u6574\u4f53\u89c6\u56fe\u3002", "motivation": "\u5728\u53ef\u89e3\u91ca\u7684\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u867d\u7136\u5206\u6790\u7279\u5f81\u7684\u91cd\u8981\u6027\u53d8\u5f97\u666e\u904d\uff0c\u4f46\u6765\u81ea\u4e00\u7ec4\u76f8\u5173\u7279\u5f81\u7684\u8054\u5408\u4fe1\u53f7\u6709\u65f6\u88ab\u5ffd\u89c6\u6216\u65e0\u610f\u4e2d\u6392\u9664\u3002\u5ffd\u7565\u8054\u5408\u4fe1\u53f7\u53ef\u80fd\u4f1a\u9057\u6f0f\u5173\u952e\u6d1e\u5bdf\uff1a\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\uff0c\u6700\u91cd\u8981\u7684\u9884\u6d4b\u56e0\u5b50\u4e0d\u662f\u5b64\u7acb\u7684\u7279\u5f81\uff0c\u800c\u662f\u7279\u5f81\u7ec4\u7684\u7efc\u5408\u6548\u5e94\u3002\u8fd9\u5bf9\u4e8e\u5305\u542b\u81ea\u7136\u7279\u5f81\u5206\u7ec4\u7684\u6570\u636e\u96c6\uff08\u5982\u591a\u6a21\u6001\u6570\u636e\u96c6\uff09\u5c24\u5176\u6210\u95ee\u9898\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u8bc4\u4f30\u5e7f\u4e49\u52a0\u6cd5\u6a21\u578b\uff08GAMs\uff09\u4e2d\u7279\u5f81\u7ec4\u7684\u91cd\u8981\u6027\u3002\u6b64\u65b9\u6cd5\u5177\u6709\u4ee5\u4e0b\u7279\u70b9\uff1a\u9ad8\u6548\u3001\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3001\u5141\u8bb8\u4e8b\u540e\u5b9a\u4e49\u7279\u5f81\u7ec4\u3001\u5141\u8bb8\u7279\u5f81\u7ec4\u91cd\u53e0\uff0c\u5e76\u5728\u9ad8\u7ef4\u8bbe\u7f6e\u4e0b\u4fdd\u6301\u610f\u4e49\u3002\u6b64\u5916\uff0c\u8be5\u5b9a\u4e49\u4e0e\u7edf\u8ba1\u5b66\u4e2d\u7684\u89e3\u91ca\u53d8\u5f02\u5177\u6709\u5e73\u884c\u6027\u3002", "result": "\u901a\u8fc7\u4e09\u4e2a\u5408\u6210\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u6570\u636e\u6761\u4ef6\u4e0b\u7684\u884c\u4e3a\u7279\u6027\u3002\u968f\u540e\uff0c\u901a\u8fc7\u4e24\u4e2a\u6848\u4f8b\u7814\u7a76\uff0c\u5373\u4ece\u591a\u6a21\u6001\u795e\u7ecf\u79d1\u5b66\u6570\u636e\u96c6\u4e2d\u8bc6\u522b\u6291\u90c1\u75c7\u72b6\u548c\u7814\u7a76\u5168\u9acb\u5173\u8282\u7f6e\u6362\u672f\u540e\u5065\u5eb7\u7684\u793e\u4f1a\u51b3\u5b9a\u56e0\u7d20\uff0c\u8bc1\u660e\u4e86\u5206\u6790\u7279\u5f81\u7ec4\u91cd\u8981\u6027\u7684\u4ef7\u503c\u3002", "conclusion": "\u5206\u6790\u7279\u5f81\u7ec4\u7684\u91cd\u8981\u6027\u63d0\u4f9b\u4e86\u5bf9\u533b\u5b66\u95ee\u9898\u66f4\u51c6\u786e\u3001\u66f4\u5168\u9762\u7684\u7406\u89e3\uff0c\u76f8\u6bd4\u5355\u4e2a\u7279\u5f81\u5206\u6790\u66f4\u5177\u4f18\u52bf\u3002"}}
{"id": "2506.20404", "pdf": "https://arxiv.org/pdf/2506.20404", "abs": "https://arxiv.org/abs/2506.20404", "authors": ["Riccardo Lo Bianco", "Willem van Jaarsveld", "Remco Dijkman"], "title": "GymPN: A Library for Decision-Making in Process Management Systems", "categories": ["cs.AI"], "comment": null, "summary": "Process management systems support key decisions about the way work is\nallocated in organizations. This includes decisions on which task to perform\nnext, when to execute the task, and who to assign the task to. Suitable\nsoftware tools are required to support these decisions in a way that is optimal\nfor the organization. This paper presents a software library, called GymPN,\nthat supports optimal decision-making in business processes using Deep\nReinforcement Learning. GymPN builds on previous work that supports task\nassignment in business processes, introducing two key novelties: support for\npartial process observability and the ability to model multiple decisions in a\nbusiness process. These novel elements address fundamental limitations of\nprevious work and thus enable the representation of more realistic process\ndecisions. We evaluate the library on eight typical business process\ndecision-making problem patterns, showing that GymPN allows for easy modeling\nof the desired problems, as well as learning optimal decision policies.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGymPN\u7684\u8f6f\u4ef6\u5e93\uff0c\u901a\u8fc7\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u652f\u6301\u4e1a\u52a1\u6d41\u7a0b\u4e2d\u7684\u6700\u4f18\u51b3\u7b56\u3002\u5b83\u5f15\u5165\u4e86\u5bf9\u90e8\u5206\u6d41\u7a0b\u53ef\u89c2\u6d4b\u6027\u7684\u652f\u6301\u548c\u5efa\u6a21\u4e1a\u52a1\u6d41\u7a0b\u4e2d\u591a\u4e2a\u51b3\u7b56\u7684\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u4ee5\u5f80\u5de5\u4f5c\u4e2d\u7684\u57fa\u672c\u5c40\u9650\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0cGymPN\u80fd\u591f\u8f7b\u677e\u5efa\u6a21\u671f\u671b\u7684\u95ee\u9898\u5e76\u5b66\u4e60\u5230\u6700\u4f18\u51b3\u7b56\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u7684\u6d41\u7a0b\u7ba1\u7406\u7cfb\u7edf\u5728\u4efb\u52a1\u5206\u914d\u3001\u6267\u884c\u65f6\u95f4\u548c\u4eba\u5458\u6307\u6d3e\u7b49\u65b9\u9762\u7684\u51b3\u7b56\u652f\u6301\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u5145\u5206\u6ee1\u8db3\u7ec4\u7ec7\u7684\u6700\u4f18\u9700\u6c42\u3002\u6b64\u5916\uff0c\u4e4b\u524d\u7684\u8f6f\u4ef6\u5de5\u5177\u7f3a\u4e4f\u5bf9\u90e8\u5206\u6d41\u7a0b\u53ef\u89c2\u6d4b\u6027\u548c\u591a\u51b3\u7b56\u5efa\u6a21\u7684\u652f\u6301\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u4e1a\u52a1\u6d41\u7a0b\u4e2d\u7684\u5e94\u7528\u8303\u56f4\u3002", "method": "\u8bba\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aGymPN\u7684\u8f6f\u4ef6\u5e93\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6280\u672f\uff0c\u7528\u4e8e\u652f\u6301\u4e1a\u52a1\u6d41\u7a0b\u4e2d\u7684\u6700\u4f18\u51b3\u7b56\u3002GymPN\u7684\u4e3b\u8981\u521b\u65b0\u70b9\u5305\u62ec\uff1a1\uff09\u652f\u6301\u90e8\u5206\u6d41\u7a0b\u53ef\u89c2\u6d4b\u6027\uff1b2\uff09\u80fd\u591f\u5efa\u6a21\u4e1a\u52a1\u6d41\u7a0b\u4e2d\u7684\u591a\u4e2a\u51b3\u7b56\u3002\u8fd9\u4e9b\u7279\u6027\u4f7f\u5f97GymPN\u53ef\u4ee5\u66f4\u771f\u5b9e\u5730\u8868\u793a\u4e1a\u52a1\u6d41\u7a0b\u4e2d\u7684\u590d\u6742\u51b3\u7b56\u573a\u666f\u3002", "result": "\u901a\u8fc7\u5bf9\u516b\u4e2a\u5178\u578b\u7684\u4e1a\u52a1\u6d41\u7a0b\u51b3\u7b56\u95ee\u9898\u6a21\u5f0f\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660eGymPN\u80fd\u591f\u8f7b\u677e\u5efa\u6a21\u671f\u671b\u7684\u95ee\u9898\uff0c\u5e76\u4e14\u80fd\u591f\u5b66\u4e60\u5230\u6700\u4f18\u7684\u51b3\u7b56\u7b56\u7565\u3002\u8fd9\u8bc1\u660e\u4e86GymPN\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "GymPN\u8f6f\u4ef6\u5e93\u901a\u8fc7\u5f15\u5165\u90e8\u5206\u6d41\u7a0b\u53ef\u89c2\u6d4b\u6027\u548c\u591a\u51b3\u7b56\u5efa\u6a21\u7684\u80fd\u529b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u73b0\u5b9e\u4e1a\u52a1\u6d41\u7a0b\u51b3\u7b56\u7684\u652f\u6301\u80fd\u529b\u3002\u8be5\u5de5\u5177\u4e3a\u4f18\u5316\u4e1a\u52a1\u6d41\u7a0b\u4e2d\u7684\u51b3\u7b56\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u672a\u6765\u53ef\u4ee5\u5728\u66f4\u591a\u590d\u6742\u7684\u4e1a\u52a1\u573a\u666f\u4e2d\u8fdb\u884c\u5e94\u7528\u548c\u6269\u5c55\u3002"}}
{"id": "2506.20024", "pdf": "https://arxiv.org/pdf/2506.20024", "abs": "https://arxiv.org/abs/2506.20024", "authors": ["Salva R\u00fchling Cachay", "Miika Aittala", "Karsten Kreis", "Noah Brenowitz", "Arash Vahdat", "Morteza Mardani", "Rose Yu"], "title": "Elucidated Rolling Diffusion Models for Probabilistic Weather Forecasting", "categories": ["cs.LG", "cs.AI", "physics.ao-ph", "stat.ML"], "comment": null, "summary": "Diffusion models are a powerful tool for probabilistic forecasting, yet most\napplications in high-dimensional chaotic systems predict future snapshots\none-by-one. This common approach struggles to model complex temporal\ndependencies and fails to explicitly account for the progressive growth of\nuncertainty inherent to such systems. While rolling diffusion frameworks, which\napply increasing noise to forecasts at longer lead times, have been proposed to\naddress this, their integration with state-of-the-art, high-fidelity diffusion\ntechniques remains a significant challenge. We tackle this problem by\nintroducing Elucidated Rolling Diffusion Models (ERDM), the first framework to\nsuccessfully unify a rolling forecast structure with the principled, performant\ndesign of Elucidated Diffusion Models (EDM). To do this, we adapt the core EDM\ncomponents-its noise schedule, network preconditioning, and Heun sampler-to the\nrolling forecast setting. The success of this integration is driven by three\nkey contributions: (i) a novel loss weighting scheme that focuses model\ncapacity on the mid-range forecast horizons where determinism gives way to\nstochasticity; (ii) an efficient initialization strategy using a pre-trained\nEDM for the initial window; and (iii) a bespoke hybrid sequence architecture\nfor robust spatiotemporal feature extraction under progressive denoising. On 2D\nNavier-Stokes simulations and ERA5 global weather forecasting at 1.5^\\circ\nresolution, ERDM consistently outperforms key diffusion-based baselines,\nincluding conditional autoregressive EDM. ERDM offers a flexible and powerful\ngeneral framework for tackling diffusion-based sequence generation problems\nwhere modeling escalating uncertainty is paramount. Code is available at:\nhttps://github.com/salvaRC/erdm", "AI": {"tldr": "Elucidated Rolling Diffusion Models (ERDM) \u662f\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u6210\u529f\u5c06\u6eda\u52a8\u9884\u6d4b\u7ed3\u6784\u4e0e Elucidated Diffusion Models (EDM) \u7684\u9ad8\u6027\u80fd\u8bbe\u8ba1\u7edf\u4e00\u8d77\u6765\uff0c\u901a\u8fc7\u6539\u8fdb\u7684\u635f\u5931\u6743\u91cd\u3001\u9884\u8bad\u7ec3\u521d\u59cb\u5316\u548c\u6df7\u5408\u5e8f\u5217\u67b6\u6784\uff0c\u5728 2D Navier-Stokes \u6a21\u62df\u548c ERA5 \u5929\u6c14\u9884\u62a5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u6269\u6563\u6a21\u578b\u5728\u9ad8\u7ef4\u6df7\u6c8c\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u96be\u4ee5\u6355\u6349\u590d\u6742\u7684\u65f6\u5e8f\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u4e14\u65e0\u6cd5\u663e\u5f0f\u5730\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u968f\u65f6\u95f4\u7684\u589e\u957f\u95ee\u9898\uff0c\u800c\u5c06\u6eda\u52a8\u6269\u6563\u6846\u67b6\u4e0e\u6700\u5148\u8fdb\u7684\u6269\u6563\u6280\u672f\u7ed3\u5408\u4ecd\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86 Elucidated Rolling Diffusion Models (ERDM)\uff0c\u901a\u8fc7\u4ee5\u4e0b\u65b9\u6cd5\u5b9e\u73b0\uff1a(i) \u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u6743\u91cd\u65b9\u6848\uff0c\u96c6\u4e2d\u4e8e\u786e\u5b9a\u6027\u5411\u968f\u673a\u6027\u8f6c\u53d8\u7684\u4e2d\u7a0b\u9884\u6d4b\u8303\u56f4\uff1b(ii) \u4f7f\u7528\u9884\u8bad\u7ec3\u7684 EDM \u8fdb\u884c\u9ad8\u6548\u7684\u521d\u59cb\u5316\uff1b(iii) \u6784\u5efa\u4e86\u4e00\u4e2a\u5b9a\u5236\u7684\u6df7\u5408\u5e8f\u5217\u67b6\u6784\u4ee5\u63d0\u53d6\u9c81\u68d2\u7684\u7a7a\u95f4\u65f6\u95f4\u7279\u5f81\u3002\u540c\u65f6\uff0c\u6838\u5fc3\u7684 EDM \u7ec4\u4ef6\uff08\u566a\u58f0\u8ba1\u5212\u3001\u7f51\u7edc\u9884\u5904\u7406\u548c Heun \u91c7\u6837\u5668\uff09\u88ab\u9002\u914d\u5230\u6eda\u52a8\u9884\u6d4b\u73af\u5883\u4e2d\u3002", "result": "\u5728 2D Navier-Stokes \u6a21\u62df\u548c ERA5 \u5168\u7403\u5929\u6c14\u9884\u62a5\uff081.5\u00b0 \u5206\u8fa8\u7387\uff09\u4efb\u52a1\u4e2d\uff0cERDM \u663e\u8457\u4f18\u4e8e\u5173\u952e\u7684\u57fa\u4e8e\u6269\u6563\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u5305\u62ec\u6761\u4ef6\u81ea\u56de\u5f52 EDM\u3002", "conclusion": "ERDM \u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u4e14\u5f3a\u5927\u7684\u901a\u7528\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u9700\u8981\u5efa\u6a21\u9012\u589e\u4e0d\u786e\u5b9a\u6027\u7684\u6269\u6563\u5e8f\u5217\u751f\u6210\u95ee\u9898\uff0c\u4ee3\u7801\u5df2\u516c\u5f00\u53d1\u5e03\u3002"}}
{"id": "2506.19992", "pdf": "https://arxiv.org/pdf/2506.19992", "abs": "https://arxiv.org/abs/2506.19992", "authors": ["Gabor Petnehazi", "Bernadett Aradi"], "title": "HERCULES: Hierarchical Embedding-based Recursive Clustering Using LLMs for Efficient Summarization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The explosive growth of complex datasets across various modalities\nnecessitates advanced analytical tools that not only group data effectively but\nalso provide human-understandable insights into the discovered structures. We\nintroduce HERCULES (Hierarchical Embedding-based Recursive Clustering Using\nLLMs for Efficient Summarization), a novel algorithm and Python package\ndesigned for hierarchical k-means clustering of diverse data types, including\ntext, images, and numeric data (processed one modality per run). HERCULES\nconstructs a cluster hierarchy by recursively applying k-means clustering,\nstarting from individual data points at level 0. A key innovation is its deep\nintegration of Large Language Models (LLMs) to generate semantically rich\ntitles and descriptions for clusters at each level of the hierarchy,\nsignificantly enhancing interpretability. The algorithm supports two main\nrepresentation modes: `direct' mode, which clusters based on original data\nembeddings or scaled numeric features, and `description' mode, which clusters\nbased on embeddings derived from LLM-generated summaries. Users can provide a\n`topic\\_seed' to guide LLM-generated summaries towards specific themes. An\ninteractive visualization tool facilitates thorough analysis and understanding\nof the clustering results. We demonstrate HERCULES's capabilities and discuss\nits potential for extracting meaningful, hierarchical knowledge from complex\ndatasets.", "AI": {"tldr": "HERCULES\u662f\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\u548cPython\u5305\uff0c\u901a\u8fc7\u9012\u5f52\u5e94\u7528k-means\u805a\u7c7b\u5e76\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u8bed\u4e49\u4e30\u5bcc\u7684\u6807\u9898\u548c\u63cf\u8ff0\uff0c\u4ee5\u589e\u5f3a\u5bf9\u590d\u6742\u6570\u636e\u96c6\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9ad8\u6548\u603b\u7ed3\u3002", "motivation": "\u968f\u7740\u5404\u79cd\u6a21\u6001\u7684\u590d\u6742\u6570\u636e\u96c6\u7684\u7206\u70b8\u6027\u589e\u957f\uff0c\u9700\u8981\u5148\u8fdb\u7684\u5206\u6790\u5de5\u5177\u4e0d\u4ec5\u80fd\u591f\u6709\u6548\u5730\u5bf9\u6570\u636e\u8fdb\u884c\u5206\u7ec4\uff0c\u8fd8\u80fd\u591f\u63d0\u4f9b\u5bf9\u53d1\u73b0\u7ed3\u6784\u7684\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u89c1\u89e3\u3002", "method": "HERCULES\u901a\u8fc7\u9012\u5f52\u5e94\u7528k-means\u805a\u7c7b\u6784\u5efa\u96c6\u7fa4\u5c42\u6b21\u7ed3\u6784\uff0c\u5e76\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u6bcf\u4e2a\u5c42\u6b21\u7ea7\u522b\u7684\u8bed\u4e49\u4e30\u5bcc\u7684\u6807\u9898\u548c\u63cf\u8ff0\u3002\u5b83\u652f\u6301\u4e24\u79cd\u4e3b\u8981\u8868\u793a\u6a21\u5f0f\uff1a`\u76f4\u63a5'\u6a21\u5f0f\u548c`\u63cf\u8ff0'\u6a21\u5f0f\uff0c\u5e76\u5141\u8bb8\u7528\u6237\u63d0\u4f9b`\u4e3b\u9898\u79cd\u5b50'\u6765\u5f15\u5bfcLLM\u751f\u6210\u7684\u6458\u8981\u3002", "result": "\u5c55\u793a\u4e86HERCULES\u7684\u80fd\u529b\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u4ece\u590d\u6742\u6570\u636e\u96c6\u4e2d\u63d0\u53d6\u6709\u610f\u4e49\u7684\u3001\u5206\u5c42\u77e5\u8bc6\u7684\u6f5c\u529b\u3002", "conclusion": "HERCULES\u4e3a\u5206\u5c42k-means\u805a\u7c7b\u63d0\u4f9b\u4e86\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u5bf9\u805a\u7c7b\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u5de5\u5177\u8fdb\u884c\u6df1\u5165\u5206\u6790\u548c\u7406\u89e3\u3002"}}
{"id": "2506.20486", "pdf": "https://arxiv.org/pdf/2506.20486", "abs": "https://arxiv.org/abs/2506.20486", "authors": ["Salvatore Milite", "Giulio Caravagna", "Andrea Sottoriva"], "title": "Mixtures of Neural Cellular Automata: A Stochastic Framework for Growth Modelling and Self-Organization", "categories": ["cs.AI"], "comment": null, "summary": "Neural Cellular Automata (NCAs) are a promising new approach to model\nself-organizing processes, with potential applications in life science.\nHowever, their deterministic nature limits their ability to capture the\nstochasticity of real-world biological and physical systems.\n  We propose the Mixture of Neural Cellular Automata (MNCA), a novel framework\nincorporating the idea of mixture models into the NCA paradigm. By combining\nprobabilistic rule assignments with intrinsic noise, MNCAs can model diverse\nlocal behaviors and reproduce the stochastic dynamics observed in biological\nprocesses.\n  We evaluate the effectiveness of MNCAs in three key domains: (1) synthetic\nsimulations of tissue growth and differentiation, (2) image morphogenesis\nrobustness, and (3) microscopy image segmentation. Results show that MNCAs\nachieve superior robustness to perturbations, better recapitulate real\nbiological growth patterns, and provide interpretable rule segmentation. These\nfindings position MNCAs as a promising tool for modeling stochastic dynamical\nsystems and studying self-growth processes.", "AI": {"tldr": "\u63d0\u51faMixture of Neural Cellular Automata (MNCA)\uff0c\u5c06\u6df7\u5408\u6a21\u578b\u6982\u5ff5\u5f15\u5165\u795e\u7ecf\u5143\u80de\u81ea\u52a8\u673a\uff0c\u901a\u8fc7\u7ed3\u5408\u6982\u7387\u89c4\u5219\u5206\u914d\u548c\u5185\u5728\u566a\u58f0\u6765\u6a21\u62df\u751f\u7269\u8fc7\u7a0b\u4e2d\u7684\u968f\u673a\u52a8\u529b\u5b66\u3002\u5728\u7ec4\u7ec7\u751f\u957f\u3001\u56fe\u50cf\u5f62\u6001\u53d1\u751f\u9c81\u68d2\u6027\u548c\u663e\u5fae\u56fe\u50cf\u5206\u5272\u4e09\u4e2a\u5173\u952e\u9886\u57df\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMNCA\u5728\u6297\u6270\u52a8\u80fd\u529b\u3001\u771f\u5b9e\u751f\u7269\u751f\u957f\u6a21\u5f0f\u518d\u73b0\u4ee5\u53ca\u89c4\u5219\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u795e\u7ecf\u5143\u80de\u81ea\u52a8\u673a\uff08NCA\uff09\u867d\u80fd\u6709\u6548\u5efa\u6a21\u81ea\u7ec4\u7ec7\u8fc7\u7a0b\uff0c\u4f46\u5176\u786e\u5b9a\u6027\u672c\u8d28\u9650\u5236\u4e86\u5bf9\u771f\u5b9e\u4e16\u754c\u751f\u7269\u548c\u7269\u7406\u7cfb\u7edf\u968f\u673a\u6027\u7684\u6355\u6349\u80fd\u529b\u3002", "method": "\u63d0\u51faMixture of Neural Cellular Automata (MNCA)\uff0c\u5c06\u6df7\u5408\u6a21\u578b\u4e0eNCA\u8303\u5f0f\u7ed3\u5408\uff0c\u901a\u8fc7\u6982\u7387\u89c4\u5219\u5206\u914d\u548c\u5185\u5728\u566a\u58f0\u6a21\u62df\u591a\u79cd\u5c40\u90e8\u884c\u4e3a\u53ca\u751f\u7269\u8fc7\u7a0b\u4e2d\u7684\u968f\u673a\u52a8\u529b\u5b66\u3002", "result": "\u5728\u5408\u6210\u7ec4\u7ec7\u751f\u957f\u4e0e\u5206\u5316\u6a21\u62df\u3001\u56fe\u50cf\u5f62\u6001\u53d1\u751f\u9c81\u68d2\u6027\u6d4b\u8bd5\u548c\u663e\u5fae\u56fe\u50cf\u5206\u5272\u4e09\u4e2a\u9886\u57df\u4e2d\uff0cMNCA\u5c55\u73b0\u51fa\u66f4\u9ad8\u7684\u6297\u6270\u52a8\u80fd\u529b\u3001\u66f4\u51c6\u786e\u5730\u518d\u73b0\u771f\u5b9e\u751f\u7269\u751f\u957f\u6a21\u5f0f\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u89c4\u5219\u5206\u5272\u7ed3\u679c\u3002", "conclusion": "MNCAs\u662f\u4e00\u79cd\u6709\u6f5c\u529b\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u5efa\u6a21\u968f\u673a\u52a8\u529b\u5b66\u7cfb\u7edf\u548c\u7814\u7a76\u81ea\u589e\u957f\u8fc7\u7a0b\u3002"}}
{"id": "2506.20025", "pdf": "https://arxiv.org/pdf/2506.20025", "abs": "https://arxiv.org/abs/2506.20025", "authors": ["Nathan Stromberg", "Christos Thrampoulidis", "Lalitha Sankar"], "title": "Thumb on the Scale: Optimal Loss Weighting in Last Layer Retraining", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "While machine learning models become more capable in discriminative tasks at\nscale, their ability to overcome biases introduced by training data has come\nunder increasing scrutiny. Previous results suggest that there are two extremes\nof parameterization with very different behaviors: the population\n(underparameterized) setting where loss weighting is optimal and the separable\noverparameterized setting where loss weighting is ineffective at ensuring equal\nperformance across classes. This work explores the regime of last layer\nretraining (LLR) in which the unseen limited (retraining) data is frequently\ninseparable and the model proportionately sized, falling between the two\naforementioned extremes. We show, in theory and practice, that loss weighting\nis still effective in this regime, but that these weights \\emph{must} take into\naccount the relative overparameterization of the model.", "AI": {"tldr": "\u5728\u6700\u540e\u5c42\u91cd\u8bad\u7ec3\uff08LLR\uff09\u7684\u573a\u666f\u4e2d\uff0c\u635f\u5931\u6743\u91cd\u4ecd\u7136\u6709\u6548\uff0c\u4f46\u9700\u8981\u8003\u8651\u6a21\u578b\u7684\u76f8\u5bf9\u8fc7\u53c2\u6570\u5316\u7a0b\u5ea6\u3002", "motivation": "\u5c3d\u7ba1\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u5927\u89c4\u6a21\u5224\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u514b\u670d\u8bad\u7ec3\u6570\u636e\u5f15\u5165\u504f\u5dee\u7684\u80fd\u529b\u53d7\u5230\u8d8a\u6765\u8d8a\u591a\u7684\u5173\u6ce8\u3002\u5df2\u6709\u7814\u7a76\u8868\u660e\uff0c\u5728\u53c2\u6570\u5316\u7684\u4e24\u4e2a\u6781\u7aef\u60c5\u51b5\u4e0b\uff0c\u635f\u5931\u52a0\u6743\u7684\u6548\u679c\u622a\u7136\u4e0d\u540c\uff1a\u5728\u7fa4\u4f53\uff08\u6b20\u53c2\u6570\u5316\uff09\u8bbe\u7f6e\u4e2d\u635f\u5931\u52a0\u6743\u662f\u6700\u4f18\u7684\uff0c\u800c\u5728\u53ef\u5206\u79bb\u7684\u8fc7\u53c2\u6570\u5316\u8bbe\u7f6e\u4e2d\u635f\u5931\u52a0\u6743\u65e0\u6cd5\u4fdd\u8bc1\u5404\u7c7b\u522b\u7684\u7b49\u6548\u6027\u80fd\u3002", "method": "\u7814\u7a76\u4e86\u6700\u540e\u5c42\u91cd\u8bad\u7ec3\uff08LLR\uff09\u7684\u573a\u666f\uff0c\u5176\u4e2d\u672a\u89c1\u7684\uff08\u91cd\u8bad\u7ec3\uff09\u6570\u636e\u901a\u5e38\u662f\u4e0d\u53ef\u5206\u7684\uff0c\u5e76\u4e14\u6a21\u578b\u89c4\u6a21\u9002\u4e2d\uff0c\u4ecb\u4e8e\u4e0a\u8ff0\u4e24\u79cd\u6781\u7aef\u60c5\u51b5\u4e4b\u95f4\u3002\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8df5\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u63a2\u8ba8\u4e86\u635f\u5931\u52a0\u6743\u5728\u8fd9\u79cd\u573a\u666f\u4e2d\u7684\u6548\u679c\u3002", "result": "\u53d1\u73b0\u635f\u5931\u52a0\u6743\u5728\u8fd9\u79cd\u573a\u666f\u4e0b\u4f9d\u7136\u6709\u6548\uff0c\u4f46\u8fd9\u4e9b\u6743\u91cd\u5fc5\u987b\u8003\u8651\u5230\u6a21\u578b\u7684\u76f8\u5bf9\u8fc7\u53c2\u6570\u5316\u7a0b\u5ea6\u3002", "conclusion": "\u635f\u5931\u52a0\u6743\u5728\u6700\u540e\u5c42\u91cd\u8bad\u7ec3\u573a\u666f\u4e2d\u662f\u6709\u6548\u7684\uff0c\u4f46\u9700\u8981\u8c03\u6574\u4ee5\u9002\u5e94\u6a21\u578b\u7684\u76f8\u5bf9\u8fc7\u53c2\u6570\u5316\u7a0b\u5ea6\u3002"}}
{"id": "2506.19997", "pdf": "https://arxiv.org/pdf/2506.19997", "abs": "https://arxiv.org/abs/2506.19997", "authors": ["Geonwoo Cho", "Jaegyun Im", "Jihwan Lee", "Hojun Yi", "Sejin Kim", "Sundong Kim"], "title": "TRACED: Transition-aware Regret Approximation with Co-learnability for Environment Design", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Generalizing deep reinforcement learning agents to unseen environments\nremains a significant challenge. One promising solution is Unsupervised\nEnvironment Design (UED), a co-evolutionary framework in which a teacher\nadaptively generates tasks with high learning potential, while a student learns\na robust policy from this evolving curriculum. Existing UED methods typically\nmeasure learning potential via regret, the gap between optimal and current\nperformance, approximated solely by value-function loss. Building on these\napproaches, we introduce the transition prediction error as an additional term\nin our regret approximation. To capture how training on one task affects\nperformance on others, we further propose a lightweight metric called\nco-learnability. By combining these two measures, we present Transition-aware\nRegret Approximation with Co-learnability for Environment Design (TRACED).\nEmpirical evaluations show that TRACED yields curricula that improve zero-shot\ngeneralization across multiple benchmarks while requiring up to 2x fewer\nenvironment interactions than strong baselines. Ablation studies confirm that\nthe transition prediction error drives rapid complexity ramp-up and that\nco-learnability delivers additional gains when paired with the transition\nprediction error. These results demonstrate how refined regret approximation\nand explicit modeling of task relationships can be leveraged for\nsample-efficient curriculum design in UED.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5TRACED\uff0c\u901a\u8fc7\u7ed3\u5408\u8f6c\u6362\u9884\u6d4b\u8bef\u5dee\u548c\u5171\u540c\u5b66\u4e60\u6027\u6765\u6539\u8fdb\u672a\u89c1\u73af\u5883\u4e2d\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7684\u65e0\u76d1\u7763\u73af\u5883\u8bbe\u8ba1\uff08UED\uff09\u65b9\u6cd5\u5728\u751f\u6210\u5177\u6709\u9ad8\u5b66\u4e60\u6f5c\u529b\u7684\u4efb\u52a1\u65f6\uff0c\u901a\u5e38\u4ec5\u901a\u8fc7\u4ef7\u503c\u51fd\u6570\u635f\u5931\u6765\u8fd1\u4f3c\u540e\u6094\u503c\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u80fd\u4e0d\u591f\u5168\u9762\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u786e\u7684\u65b9\u5f0f\u6765\u8861\u91cf\u4efb\u52a1\u7684\u5b66\u4e60\u6f5c\u529b\u3002", "method": "\u5f15\u5165\u4e86\u8f6c\u6362\u9884\u6d4b\u8bef\u5dee\u4f5c\u4e3a\u540e\u6094\u503c\u8fd1\u4f3c\u7684\u989d\u5916\u9879\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a\u5171\u540c\u5b66\u4e60\u6027\u7684\u8f7b\u91cf\u7ea7\u5ea6\u91cf\u6807\u51c6\uff0c\u4ee5\u6355\u6349\u5728\u4e00\u4e2a\u4efb\u52a1\u4e0a\u8bad\u7ec3\u5982\u4f55\u5f71\u54cd\u5176\u4ed6\u4efb\u52a1\u7684\u8868\u73b0\u3002\u5c06\u8fd9\u4e24\u4e2a\u5ea6\u91cf\u6807\u51c6\u7ed3\u5408\u8d77\u6765\uff0c\u5f62\u6210\u4e86TRACED\u65b9\u6cd5\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cTRACED\u751f\u6210\u7684\u8bfe\u7a0b\u53ef\u4ee5\u6539\u5584\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e14\u4e0e\u5f3a\u5927\u7684\u57fa\u7ebf\u76f8\u6bd4\uff0c\u6700\u591a\u53ef\u51cf\u5c112\u500d\u7684\u73af\u5883\u4ea4\u4e92\u6b21\u6570\u3002\u6d88\u878d\u7814\u7a76\u786e\u8ba4\u4e86\u8f6c\u6362\u9884\u6d4b\u8bef\u5dee\u9a71\u52a8\u590d\u6742\u6027\u7684\u5feb\u901f\u63d0\u5347\uff0c\u800c\u5171\u540c\u5b66\u4e60\u6027\u5728\u4e0e\u8f6c\u6362\u9884\u6d4b\u8bef\u5dee\u914d\u5bf9\u65f6\u63d0\u4f9b\u4e86\u989d\u5916\u7684\u6536\u76ca\u3002", "conclusion": "\u7cbe\u70bc\u7684\u540e\u6094\u503c\u8fd1\u4f3c\u548c\u663e\u5f0f\u7684\u4efb\u52a1\u5173\u7cfb\u5efa\u6a21\u53ef\u4ee5\u7528\u4e8e\u63d0\u9ad8UED\u4e2d\u6837\u672c\u6548\u7387\u7684\u8bfe\u7a0b\u8bbe\u8ba1\u3002"}}
{"id": "2506.20504", "pdf": "https://arxiv.org/pdf/2506.20504", "abs": "https://arxiv.org/abs/2506.20504", "authors": ["Konstantin Demin", "Taylor Webb", "Eric Elmoznino", "Hakwan Lau"], "title": "Engineering Sentience", "categories": ["cs.AI", "q-bio.NC"], "comment": null, "summary": "We spell out a definition of sentience that may be useful for designing and\nbuilding it in machines. We propose that for sentience to be meaningful for AI,\nit must be fleshed out in functional, computational terms, in enough detail to\nallow for implementation. Yet, this notion of sentience must also reflect\nsomething essentially 'subjective', beyond just having the general capacity to\nencode perceptual content. For this specific functional notion of sentience to\noccur, we propose that certain sensory signals need to be both assertoric\n(persistent) and qualitative. To illustrate the definition in more concrete\nterms, we sketch out some ways for potential implementation, given current\ntechnology. Understanding what it takes for artificial agents to be\nfunctionally sentient can also help us avoid creating them inadvertently, or at\nleast, realize that we have created them in a timely manner.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u5728\u673a\u5668\u4e2d\u5b9a\u4e49\u548c\u5b9e\u73b0\u611f\u77e5\uff0c\u5e76\u63d0\u51fa\u611f\u77e5\u4fe1\u53f7\u9700\u8981\u5177\u5907\u6301\u7eed\u6027\u548c\u8d28\u6027\u7279\u5f81\u3002", "motivation": "\u4e3a\u4e86\u8bbe\u8ba1\u548c\u6784\u5efa\u673a\u5668\u4e2d\u7684\u611f\u77e5\uff0c\u9700\u8981\u4e00\u4e2a\u660e\u786e\u7684\u529f\u80fd\u6027\u548c\u8ba1\u7b97\u6027\u5b9a\u4e49\u3002", "method": "\u63d0\u51fa\u611f\u77e5\u4fe1\u53f7\u9700\u540c\u65f6\u5177\u5907\u65ad\u8a00\u6027\u548c\u8d28\u6027\u7279\u5f81\uff0c\u5e76\u63a2\u8ba8\u4e86\u57fa\u4e8e\u5f53\u524d\u6280\u672f\u7684\u6f5c\u5728\u5b9e\u73b0\u65b9\u5f0f\u3002", "result": "\u660e\u786e\u4e86\u4eba\u5de5\u4ee3\u7406\u529f\u80fd\u6027\u611f\u77e5\u6240\u9700\u7684\u6761\u4ef6\uff0c\u6709\u52a9\u4e8e\u907f\u514d\u65e0\u610f\u4e2d\u521b\u5efa\u5177\u6709\u611f\u77e5\u80fd\u529b\u7684AI\u3002", "conclusion": "\u7406\u89e3\u4eba\u5de5\u4ee3\u7406\u7684\u529f\u80fd\u6027\u611f\u77e5\u6761\u4ef6\uff0c\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u53ca\u65f6\u610f\u8bc6\u5230\u662f\u5426\u5df2\u521b\u9020\u51fa\u5177\u6709\u611f\u77e5\u80fd\u529b\u7684AI\u3002"}}
{"id": "2506.20347", "pdf": "https://arxiv.org/pdf/2506.20347", "abs": "https://arxiv.org/abs/2506.20347", "authors": ["Malik Shahid Sultan", "Hernando Ombao"], "title": "On the ability of Deep Neural Networks to Learn Granger Causality in Multi-Variate Time Series Data", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Granger Causality (GC) offers an elegant statistical framework to study the\nassociation between multivariate time series data. Linear Vector Autoregressive\nmodels (VAR) though have nice interpretation properties but have limited\npractical application due to underlying assumptions on the kind of associations\nthat can be captured by these models. Numerous attempts have already been made\nin the literature that exploit the functional approximation power of Deep\nNeural Networks (DNNs) for the task of GC estimation. These methods however\ntreat GC as a variable selection problem. We present a novel paradigm for\napproaching GC. We present this idea that GC is essentially linked with\nprediction and if a deep learning model is used to model the time series\ncollectively or jointly, a well regularized model may learn the true granger\ncausal structure from the data, given that there is enough training data. We\npropose to uncover the learned GC structure by comparing the model uncertainty\nor distribution of the residuals when the past of everything is used as\ncompared to the one where a specific time series component is dropped from the\nmodel. We also compare the effect of input layer dropout on the ability of a\nneural network to learn granger causality from the data. We show that a well\nregularized model infact can learn the true GC structure from the data without\nexplicitly adding terms in the loss function that guide the model to select\nvariables or perform sparse regression.", "AI": {"tldr": "Granger\u56e0\u679c\u5173\u7cfb\uff08GC\uff09\u7814\u7a76\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u5173\u8054\u3002\u5c3d\u7ba1\u7ebf\u6027\u5411\u91cf\u81ea\u56de\u5f52\u6a21\u578b\uff08VAR\uff09\u5177\u6709\u826f\u597d\u7684\u89e3\u91ca\u6027\uff0c\u4f46\u5176\u5b9e\u9645\u5e94\u7528\u53d7\u9650\u4e8e\u5047\u8bbe\u6761\u4ef6\u3002\u5df2\u6709\u591a\u7bc7\u6587\u732e\u5229\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff08DNN\uff09\u7684\u529f\u80fd\u8fd1\u4f3c\u80fd\u529b\u8fdb\u884cGC\u4f30\u8ba1\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u5c06GC\u89c6\u4e3a\u53d8\u91cf\u9009\u62e9\u95ee\u9898\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684GC\u5206\u6790\u8303\u5f0f\uff0c\u8ba4\u4e3aGC\u672c\u8d28\u4e0a\u4e0e\u9884\u6d4b\u76f8\u5173\u3002\u901a\u8fc7\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5bf9\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u8054\u5408\u5efa\u6a21\uff0c\u5e76\u901a\u8fc7\u6bd4\u8f83\u4f7f\u7528\u6240\u6709\u8fc7\u53bb\u4fe1\u606f\u548c\u6392\u9664\u7279\u5b9a\u65f6\u95f4\u5e8f\u5217\u5206\u91cf\u65f6\u7684\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u6216\u6b8b\u5dee\u5206\u5e03\uff0c\u53ef\u4ee5\u63ed\u793a\u771f\u5b9e\u7684Granger\u56e0\u679c\u7ed3\u6784\u3002\u6b64\u5916\uff0c\u6587\u7ae0\u63a2\u8ba8\u4e86\u8f93\u5165\u5c42Dropout\u5bf9\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60Granger\u56e0\u679c\u5173\u7cfb\u7684\u5f71\u54cd\uff0c\u8868\u660e\u7ecf\u8fc7\u826f\u597d\u6b63\u5219\u5316\u7684\u6a21\u578b\u53ef\u4ee5\u5728\u4e0d\u663e\u5f0f\u6dfb\u52a0\u5f15\u5bfc\u53d8\u91cf\u9009\u62e9\u6216\u7a00\u758f\u56de\u5f52\u7684\u635f\u5931\u51fd\u6570\u9879\u7684\u60c5\u51b5\u4e0b\uff0c\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u5230\u771f\u5b9e\u7684GC\u7ed3\u6784\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684Granger\u56e0\u679c\u5173\u7cfb\u4f30\u8ba1\u65b9\u6cd5\u4e3b\u8981\u5c06GC\u89c6\u4e3a\u53d8\u91cf\u9009\u62e9\u95ee\u9898\uff0c\u800c\u672c\u6587\u8bd5\u56fe\u91cd\u65b0\u5b9a\u4e49GC\u7684\u672c\u8d28\uff0c\u5f3a\u8c03\u5176\u4e0e\u9884\u6d4b\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u4ece\u800c\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6316\u6398\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u56e0\u679c\u7ed3\u6784\u3002", "method": "1. \u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5bf9\u65f6\u95f4\u5e8f\u5217\u8fdb\u884c\u8054\u5408\u5efa\u6a21\u3002\n2. \u901a\u8fc7\u6bd4\u8f83\u5728\u5305\u542b\u6240\u6709\u8fc7\u53bb\u4fe1\u606f\u548c\u6392\u9664\u7279\u5b9a\u65f6\u95f4\u5e8f\u5217\u5206\u91cf\u65f6\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u6216\u6b8b\u5dee\u5206\u5e03\uff0c\u63ed\u793aGranger\u56e0\u679c\u7ed3\u6784\u3002\n3. \u63a2\u8ba8\u8f93\u5165\u5c42Dropout\u5bf9\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60Granger\u56e0\u679c\u5173\u7cfb\u7684\u5f71\u54cd\u3002\n4. \u4e0d\u9700\u8981\u663e\u5f0f\u5730\u5728\u635f\u5931\u51fd\u6570\u4e2d\u6dfb\u52a0\u53d8\u91cf\u9009\u62e9\u6216\u7a00\u758f\u56de\u5f52\u7684\u5f15\u5bfc\u9879\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u7ecf\u8fc7\u826f\u597d\u6b63\u5219\u5316\u7684\u6a21\u578b\u53ef\u4ee5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u5230\u771f\u5b9e\u7684Granger\u56e0\u679c\u7ed3\u6784\uff0c\u65e0\u9700\u663e\u5f0f\u6dfb\u52a0\u53d8\u91cf\u9009\u62e9\u6216\u7a00\u758f\u56de\u5f52\u7684\u635f\u5931\u51fd\u6570\u9879\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u8303\u5f0f\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u7406\u89e3Granger\u56e0\u679c\u5173\u7cfb\u7684\u65b9\u6cd5\uff0c\u5373\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\u548c\u6b63\u5219\u5316\u7279\u6027\uff0c\u53ef\u4ee5\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u5230\u56e0\u679c\u7ed3\u6784\uff0c\u800c\u4e0d\u9700\u8981\u663e\u5f0f\u7684\u53d8\u91cf\u9009\u62e9\u8fc7\u7a0b\u3002"}}
{"id": "2506.20015", "pdf": "https://arxiv.org/pdf/2506.20015", "abs": "https://arxiv.org/abs/2506.20015", "authors": ["Dengyu Wu", "Jiechen Chen", "H. Vincent Poor", "Bipin Rajendran", "Osvaldo Simeone"], "title": "Neuromorphic Wireless Split Computing with Resonate-and-Fire Neurons", "categories": ["cs.LG", "cs.IT", "cs.NE", "math.IT"], "comment": null, "summary": "Neuromorphic computing offers an energy-efficient alternative to conventional\ndeep learning accelerators for real-time time-series processing. However, many\nedge applications, such as wireless sensing and audio recognition, generate\nstreaming signals with rich spectral features that are not effectively captured\nby conventional leaky integrate-and-fire (LIF) spiking neurons. This paper\ninvestigates a wireless split computing architecture that employs\nresonate-and-fire (RF) neurons with oscillatory dynamics to process time-domain\nsignals directly, eliminating the need for costly spectral pre-processing. By\nresonating at tunable frequencies, RF neurons extract time-localized spectral\nfeatures while maintaining low spiking activity. This temporal sparsity\ntranslates into significant savings in both computation and transmission\nenergy. Assuming an OFDM-based analog wireless interface for spike\ntransmission, we present a complete system design and evaluate its performance\non audio classification and modulation classification tasks. Experimental\nresults show that the proposed RF-SNN architecture achieves comparable accuracy\nto conventional LIF-SNNs and ANNs, while substantially reducing spike rates and\ntotal energy consumption during inference and communication.", "AI": {"tldr": "\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u4e3a\u5b9e\u65f6\u65f6\u95f4\u5e8f\u5217\u5904\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u6bd4\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u52a0\u901f\u5668\u66f4\u8282\u80fd\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u672c\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u4f7f\u7528\u5171\u632f\u53d1\u653e\uff08RF\uff09\u795e\u7ecf\u5143\u7684\u65e0\u7ebf\u5206\u62c6\u8ba1\u7b97\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u80fd\u591f\u76f4\u63a5\u5904\u7406\u65f6\u57df\u4fe1\u53f7\uff0c\u51cf\u5c11\u4e86\u6602\u8d35\u7684\u9891\u8c31\u9884\u5904\u7406\u9700\u6c42\u3002RF\u795e\u7ecf\u5143\u901a\u8fc7\u53ef\u8c03\u8c10\u9891\u7387\u63d0\u53d6\u65f6\u95f4\u5c40\u90e8\u5316\u7684\u9891\u8c31\u7279\u5f81\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u53d1\u653e\u6d3b\u52a8\uff0c\u4ece\u800c\u663e\u8457\u8282\u7701\u8ba1\u7b97\u548c\u4f20\u8f93\u80fd\u91cf\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684RF-SNN\u67b6\u6784\u5728\u97f3\u9891\u5206\u7c7b\u548c\u8c03\u5236\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u4e0e\u4f20\u7edf\u7684LIF-SNNs\u548cANNs\u76f8\u6bd4\uff0c\u7cbe\u5ea6\u76f8\u5f53\uff0c\u4f46\u5927\u5e45\u964d\u4f4e\u4e86\u53d1\u653e\u7387\u548c\u603b\u80fd\u8017\u3002", "motivation": "\u8bb8\u591a\u8fb9\u7f18\u5e94\u7528\uff08\u5982\u65e0\u7ebf\u4f20\u611f\u548c\u97f3\u9891\u8bc6\u522b\uff09\u751f\u6210\u5177\u6709\u4e30\u5bcc\u9891\u8c31\u7279\u5f81\u7684\u6d41\u5f0f\u4fe1\u53f7\uff0c\u800c\u4f20\u7edf\u7684\u6f0f\u7535\u79ef\u5206\u53d1\u653e\uff08LIF\uff09\u8109\u51b2\u795e\u7ecf\u5143\u65e0\u6cd5\u6709\u6548\u6355\u83b7\u8fd9\u4e9b\u7279\u5f81\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u76f4\u63a5\u5904\u7406\u65f6\u57df\u4fe1\u53f7\u5e76\u51cf\u5c11\u9891\u8c31\u9884\u5904\u7406\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u5171\u632f\u53d1\u653e\uff08RF\uff09\u795e\u7ecf\u5143\u7684\u65e0\u7ebf\u5206\u62c6\u8ba1\u7b97\u67b6\u6784\uff0c\u5229\u7528\u632f\u8361\u52a8\u529b\u5b66\u76f4\u63a5\u5904\u7406\u65f6\u57df\u4fe1\u53f7\u3002RF\u795e\u7ecf\u5143\u901a\u8fc7\u5728\u53ef\u8c03\u8c10\u9891\u7387\u4e0b\u5171\u632f\uff0c\u63d0\u53d6\u65f6\u95f4\u5c40\u90e8\u5316\u7684\u9891\u8c31\u7279\u5f81\uff0c\u540c\u65f6\u7ef4\u6301\u8f83\u4f4e\u7684\u8109\u51b2\u6d3b\u52a8\u3002\u5047\u8bbe\u57fa\u4e8eOFDM\u7684\u6a21\u62df\u65e0\u7ebf\u63a5\u53e3\u7528\u4e8e\u8109\u51b2\u4f20\u8f93\uff0c\u5e76\u63d0\u51fa\u5b8c\u6574\u7684\u7cfb\u7edf\u8bbe\u8ba1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u97f3\u9891\u5206\u7c7b\u548c\u8c03\u5236\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u6240\u63d0\u51fa\u7684RF-SNN\u67b6\u6784\u5b9e\u73b0\u4e86\u4e0e\u4f20\u7edfLIF-SNNs\u548cANNs\u76f8\u5f53\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8109\u51b2\u7387\u548c\u603b\u80fd\u8017\u3002", "conclusion": "\u4f7f\u7528RF\u795e\u7ecf\u5143\u7684\u65e0\u7ebf\u5206\u62c6\u8ba1\u7b97\u67b6\u6784\u80fd\u591f\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u8109\u51b2\u7387\u548c\u603b\u80fd\u8017\uff0c\u9002\u7528\u4e8e\u65e0\u7ebf\u4f20\u611f\u548c\u97f3\u9891\u8bc6\u522b\u7b49\u8fb9\u7f18\u5e94\u7528\u3002"}}
{"id": "2506.20531", "pdf": "https://arxiv.org/pdf/2506.20531", "abs": "https://arxiv.org/abs/2506.20531", "authors": ["Wenbin Gan", "Minh-Son Dao", "Koji Zettsu"], "title": "Case-based Reasoning Augmented Large Language Model Framework for Decision Making in Realistic Safety-Critical Driving Scenarios", "categories": ["cs.AI", "cs.CY"], "comment": "12 pages, 10 figures, under-review conference", "summary": "Driving in safety-critical scenarios requires quick, context-aware\ndecision-making grounded in both situational understanding and experiential\nreasoning. Large Language Models (LLMs), with their powerful general-purpose\nreasoning capabilities, offer a promising foundation for such decision-making.\nHowever, their direct application to autonomous driving remains limited due to\nchallenges in domain adaptation, contextual grounding, and the lack of\nexperiential knowledge needed to make reliable and interpretable decisions in\ndynamic, high-risk environments. To address this gap, this paper presents a\nCase-Based Reasoning Augmented Large Language Model (CBR-LLM) framework for\nevasive maneuver decision-making in complex risk scenarios. Our approach\nintegrates semantic scene understanding from dashcam video inputs with the\nretrieval of relevant past driving cases, enabling LLMs to generate maneuver\nrecommendations that are both context-sensitive and human-aligned. Experiments\nacross multiple open-source LLMs show that our framework improves decision\naccuracy, justification quality, and alignment with human expert behavior.\nRisk-aware prompting strategies further enhance performance across diverse risk\ntypes, while similarity-based case retrieval consistently outperforms random\nsampling in guiding in-context learning. Case studies further demonstrate the\nframework's robustness in challenging real-world conditions, underscoring its\npotential as an adaptive and trustworthy decision-support tool for intelligent\ndriving systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6848\u4f8b\u63a8\u7406\u589e\u5f3a\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08CBR-LLM\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u590d\u6742\u98ce\u9669\u573a\u666f\u4e0b\u7684\u907f\u8ba9\u64cd\u4f5c\u51b3\u7b56\u3002\u901a\u8fc7\u6574\u5408\u884c\u8f66\u8bb0\u5f55\u4eea\u89c6\u9891\u8f93\u5165\u7684\u8bed\u4e49\u573a\u666f\u7406\u89e3\u548c\u76f8\u5173\u8fc7\u5f80\u9a7e\u9a76\u6848\u4f8b\u7684\u68c0\u7d22\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u751f\u6210\u65e2\u4e0e\u60c5\u5883\u76f8\u5173\u53c8\u7b26\u5408\u4eba\u7c7b\u884c\u4e3a\u7684\u907f\u8ba9\u5efa\u8bae\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u51b3\u7b56\u51c6\u786e\u6027\u3001\u89e3\u91ca\u8d28\u91cf\uff0c\u5e76\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u884c\u4e3a\u66f4\u4e00\u81f4\u3002\u98ce\u9669\u611f\u77e5\u63d0\u793a\u7b56\u7565\u548c\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u6848\u4f8b\u68c0\u7d22\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5728\u5173\u952e\u5b89\u5168\u573a\u666f\u4e2d\u9a7e\u9a76\u9700\u8981\u5feb\u901f\u4e14\u57fa\u4e8e\u60c5\u5883\u7684\u7406\u89e3\u548c\u7ecf\u9a8c\u63a8\u7406\u7684\u51b3\u7b56\u3002\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u5177\u5907\u5f3a\u5927\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u76f4\u63a5\u5e94\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u4ecd\u9762\u4e34\u9886\u57df\u9002\u5e94\u3001\u60c5\u5883\u5d4c\u5165\u548c\u7f3a\u4e4f\u52a8\u6001\u9ad8\u98ce\u9669\u73af\u5883\u4e2d\u7684\u7ecf\u9a8c\u77e5\u8bc6\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cdCase-Based Reasoning Augmented Large Language Model (CBR-LLM)\u6846\u67b6\uff0c\u5c06\u884c\u8f66\u8bb0\u5f55\u4eea\u89c6\u9891\u8f93\u5165\u7684\u8bed\u4e49\u573a\u666f\u7406\u89e3\u4e0e\u76f8\u5173\u8fc7\u5f80\u9a7e\u9a76\u6848\u4f8b\u7684\u68c0\u7d22\u76f8\u7ed3\u5408\uff0c\u4ee5\u751f\u6210\u4e0e\u60c5\u5883\u76f8\u5173\u7684\u907f\u8ba9\u5efa\u8bae\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u63d0\u9ad8\u4e86\u51b3\u7b56\u51c6\u786e\u6027\u3001\u89e3\u91ca\u8d28\u91cf\u548c\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u884c\u4e3a\u7684\u4e00\u81f4\u6027\u3002\u98ce\u9669\u611f\u77e5\u63d0\u793a\u7b56\u7565\u548c\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u6848\u4f8b\u68c0\u7d22\u5728\u5404\u79cd\u98ce\u9669\u7c7b\u578b\u4e2d\u8868\u73b0\u4f18\u4e8e\u968f\u673a\u91c7\u6837\u3002", "conclusion": "CBR-LLM\u6846\u67b6\u5728\u590d\u6742\u7684\u5b9e\u9645\u9a7e\u9a76\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u9c81\u68d2\u6027\uff0c\u6709\u6f5c\u529b\u6210\u4e3a\u667a\u80fd\u9a7e\u9a76\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u548c\u503c\u5f97\u4fe1\u8d56\u7684\u51b3\u7b56\u652f\u6301\u5de5\u5177\u3002"}}
{"id": "2506.20623", "pdf": "https://arxiv.org/pdf/2506.20623", "abs": "https://arxiv.org/abs/2506.20623", "authors": ["Fariba Jangjoo", "Matteo Marsili", "Yasser Roudi"], "title": "Lost in Retraining: Roaming the Parameter Space of Exponential Families Under Closed-Loop Learning", "categories": ["cs.LG", "cond-mat.dis-nn", "physics.data-an", "stat.ML"], "comment": "13 pages, 2 figures", "summary": "Closed-loop learning is the process of repeatedly estimating a model from\ndata generated from the model itself. It is receiving great attention due to\nthe possibility that large neural network models may, in the future, be\nprimarily trained with data generated by artificial neural networks themselves.\nWe study this process for models that belong to exponential families, deriving\nequations of motions that govern the dynamics of the parameters. We show that\nmaximum likelihood estimation of the parameters endows sufficient statistics\nwith the martingale property and that as a result the process converges to\nabsorbing states that amplify initial biases present in the data. However, we\nshow that this outcome may be prevented by polluting the data with an\ninfinitesimal fraction of data points generated from a fixed model, by relying\non maximum a posteriori estimation or by introducing regularisation.\nFurthermore, we show that the asymptotic behavior of the dynamics is not\nreparametrisation invariant.", "AI": {"tldr": "Closed-loop learning in exponential family models can lead to amplification of initial biases, but this can be mitigated by data pollution, MAP estimation, or regularisation.", "motivation": "To understand the process of closed-loop learning where models are repeatedly estimated from data generated by themselves, especially its implications for future large neural network training.", "method": "Studying closed-loop learning in models belonging to exponential families, deriving equations of motion for parameter dynamics, and examining effects of maximum likelihood estimation and alternative methods.", "result": "Maximum likelihood estimation leads to convergence to absorbing states that amplify initial biases; these outcomes can be prevented by data pollution, MAP estimation, or regularisation. The asymptotic behavior is not reparametrisation invariant.", "conclusion": "Closed-loop learning dynamics need careful handling due to bias amplification, but mitigation strategies exist."}}
{"id": "2506.20016", "pdf": "https://arxiv.org/pdf/2506.20016", "abs": "https://arxiv.org/abs/2506.20016", "authors": ["Shanika Iroshi Nanayakkara", "Shiva Raj Pokhrel"], "title": "New Insights on Unfolding and Fine-tuning Quantum Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 9 figures, 7 Tables, Submitted to IEEE/ACM journal 2025", "summary": "Client heterogeneity poses significant challenges to the performance of\nQuantum Federated Learning (QFL). To overcome these limitations, we propose a\nnew approach leveraging deep unfolding, which enables clients to autonomously\noptimize hyperparameters, such as learning rates and regularization factors,\nbased on their specific training behavior. This dynamic adaptation mitigates\noverfitting and ensures robust optimization in highly heterogeneous\nenvironments where standard aggregation methods often fail. Our framework\nachieves approximately 90% accuracy, significantly outperforming traditional\nmethods, which typically yield around 55% accuracy, as demonstrated through\nreal-time training on IBM quantum hardware and Qiskit Aer simulators. By\ndeveloping self adaptive fine tuning, the proposed method proves particularly\neffective in critical applications such as gene expression analysis and cancer\ndetection, enhancing diagnostic precision and predictive modeling within\nquantum systems. Our results are attributed to convergence-aware, learnable\noptimization steps intrinsic to the deep unfolded framework, which maintains\nthe generalization. Hence, this study addresses the core limitations of\nconventional QFL, streamlining its applicability to any complex challenges such\nas healthcare and genomic research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5c55\u5f00\u7684\u65b0\u65b9\u6cd5\uff0c\u4f7f\u5ba2\u6237\u7aef\u80fd\u591f\u81ea\u4e3b\u4f18\u5316\u8d85\u53c2\u6570\uff0c\u4ece\u800c\u5728\u9ad8\u5ea6\u5f02\u6784\u73af\u5883\u4e2d\u5b9e\u73b0\u7ea690%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u768455%\uff0c\u5e76\u5728\u57fa\u56e0\u8868\u8fbe\u5206\u6790\u548c\u764c\u75c7\u68c0\u6d4b\u7b49\u5173\u952e\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5ba2\u6237\u7aef\u5f02\u8d28\u6027\u5bf9\u91cf\u5b50\u8054\u90a6\u5b66\u4e60\uff08QFL\uff09\u7684\u6027\u80fd\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6218\uff0c\u6807\u51c6\u805a\u5408\u65b9\u6cd5\u901a\u5e38\u5931\u6548\u3002", "method": "\u901a\u8fc7\u5229\u7528\u6df1\u5ea6\u5c55\u5f00\u6280\u672f\uff0c\u8ba9\u5ba2\u6237\u7aef\u6839\u636e\u5176\u7279\u5b9a\u7684\u8bad\u7ec3\u884c\u4e3a\u81ea\u4e3b\u4f18\u5316\u8d85\u53c2\u6570\uff08\u5982\u5b66\u4e60\u7387\u548c\u6b63\u5219\u5316\u56e0\u5b50\uff09\uff0c\u5e76\u91c7\u7528\u81ea\u9002\u5e94\u7cbe\u7ec6\u8c03\u6574\u7684\u65b9\u6cd5\u6765\u7f13\u89e3\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u786e\u4fdd\u9c81\u68d2\u4f18\u5316\u3002", "result": "\u8be5\u6846\u67b6\u5728IBM\u91cf\u5b50\u786c\u4ef6\u548cQiskit Aer\u6a21\u62df\u5668\u4e0a\u8fdb\u884c\u5b9e\u65f6\u8bad\u7ec3\u65f6\uff0c\u8fbe\u5230\u4e86\u7ea690%\u7684\u51c6\u786e\u7387\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u53ea\u80fd\u8fbe\u5230\u7ea655%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u89e3\u51b3\u4e86\u4f20\u7edfQFL\u7684\u6838\u5fc3\u9650\u5236\uff0c\u63d0\u9ad8\u4e86\u5176\u5728\u590d\u6742\u6311\u6218\uff08\u5982\u533b\u7597\u4fdd\u5065\u548c\u57fa\u56e0\u7ec4\u7814\u7a76\uff09\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2506.20598", "pdf": "https://arxiv.org/pdf/2506.20598", "abs": "https://arxiv.org/abs/2506.20598", "authors": ["Alexander D. Kalian", "Jaewook Lee", "Stefan P. Johannesson", "Lennart Otte", "Christer Hogstrand", "Miao Guo"], "title": "Fine-Tuning and Prompt Engineering of LLMs, for the Creation of Multi-Agent AI for Addressing Sustainable Protein Production Challenges", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "The global demand for sustainable protein sources has accelerated the need\nfor intelligent tools that can rapidly process and synthesise domain-specific\nscientific knowledge. In this study, we present a proof-of-concept multi-agent\nArtificial Intelligence (AI) framework designed to support sustainable protein\nproduction research, with an initial focus on microbial protein sources. Our\nRetrieval-Augmented Generation (RAG)-oriented system consists of two GPT-based\nLLM agents: (1) a literature search agent that retrieves relevant scientific\nliterature on microbial protein production for a specified microbial strain,\nand (2) an information extraction agent that processes the retrieved content to\nextract relevant biological and chemical information. Two parallel\nmethodologies, fine-tuning and prompt engineering, were explored for agent\noptimisation. Both methods demonstrated effectiveness at improving the\nperformance of the information extraction agent in terms of transformer-based\ncosine similarity scores between obtained and ideal outputs. Mean cosine\nsimilarity scores were increased by up to 25%, while universally reaching mean\nscores of $\\geq 0.89$ against ideal output text. Fine-tuning overall improved\nthe mean scores to a greater extent (consistently of $\\geq 0.94$) compared to\nprompt engineering, although lower statistical uncertainties were observed with\nthe latter approach. A user interface was developed and published for enabling\nthe use of the multi-agent AI system, alongside preliminary exploration of\nadditional chemical safety-based search capabilities", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\u7684\u6982\u5ff5\u9a8c\u8bc1\uff0c\u7528\u4e8e\u652f\u6301\u53ef\u6301\u7eed\u86cb\u767d\u8d28\u751f\u4ea7\u7814\u7a76\u3002\u8be5\u7cfb\u7edf\u7531\u4e24\u4e2a\u57fa\u4e8eGPT\u7684LLM\u4ee3\u7406\u7ec4\u6210\uff1a\u4e00\u4e2a\u7528\u4e8e\u68c0\u7d22\u6307\u5b9a\u5fae\u751f\u7269\u83cc\u682a\u7684\u86cb\u767d\u8d28\u751f\u4ea7\u76f8\u5173\u6587\u732e\uff0c\u53e6\u4e00\u4e2a\u7528\u4e8e\u63d0\u53d6\u76f8\u5173\u7684\u751f\u7269\u548c\u5316\u5b66\u4fe1\u606f\u3002\u901a\u8fc7\u5fae\u8c03\u548c\u63d0\u793a\u5de5\u7a0b\u4e24\u79cd\u65b9\u6cd5\u4f18\u5316\u4ee3\u7406\uff0c\u5176\u4e2d\u5fae\u8c03\u63d0\u9ad8\u4e86\u5e73\u5747\u5206\u6570\uff08\u8fbe\u52300.94\uff09\uff0c\u800c\u63d0\u793a\u5de5\u7a0b\u5219\u8868\u73b0\u51fa\u8f83\u4f4e\u7684\u7edf\u8ba1\u4e0d\u786e\u5b9a\u6027\u3002\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u6237\u754c\u9762\u4ee5\u65b9\u4fbf\u4f7f\u7528\u8be5\u7cfb\u7edf\uff0c\u5e76\u521d\u6b65\u63a2\u7d22\u4e86\u989d\u5916\u7684\u5316\u5b66\u5b89\u5168\u641c\u7d22\u529f\u80fd\u3002", "motivation": "\u5168\u7403\u5bf9\u53ef\u6301\u7eed\u86cb\u767d\u8d28\u6765\u6e90\u7684\u9700\u6c42\u4fc3\u4f7f\u9700\u8981\u80fd\u591f\u5feb\u901f\u5904\u7406\u548c\u5408\u6210\u9886\u57df\u7279\u5b9a\u79d1\u5b66\u77e5\u8bc6\u7684\u667a\u80fd\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u7684\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\uff0c\u5305\u62ec\u4e24\u4e2a\u57fa\u4e8eGPT\u7684LLM\u4ee3\u7406\uff1a\u6587\u732e\u68c0\u7d22\u4ee3\u7406\u548c\u4fe1\u606f\u63d0\u53d6\u4ee3\u7406\u3002\u901a\u8fc7\u5fae\u8c03\u548c\u63d0\u793a\u5de5\u7a0b\u4e24\u79cd\u65b9\u6cd5\u4f18\u5316\u4fe1\u606f\u63d0\u53d6\u4ee3\u7406\u3002", "result": "\u4e24\u79cd\u4f18\u5316\u65b9\u6cd5\u5747\u6709\u6548\u63d0\u9ad8\u4fe1\u606f\u63d0\u53d6\u4ee3\u7406\u7684\u8868\u73b0\uff0c\u5e73\u5747\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5f97\u5206\u63d0\u5347\u4e8625%\uff0c\u8fbe\u5230\u4e86\u81f3\u5c110.89\u7684\u5e73\u5747\u5206\u6570\u3002\u5fae\u8c03\u6574\u4f53\u4e0a\u5c06\u5e73\u5747\u5206\u6570\u63d0\u5347\u5230\u66f4\u9ad8\u7684\u6c34\u5e73\uff08\u8fbe\u52300.94\uff09\uff0c\u63d0\u793a\u5de5\u7a0b\u5219\u8868\u73b0\u51fa\u8f83\u4f4e\u7684\u7edf\u8ba1\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\u4e3a\u652f\u6301\u53ef\u6301\u7eed\u86cb\u767d\u8d28\u751f\u4ea7\u7814\u7a76\u63d0\u4f9b\u4e86\u6982\u5ff5\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5fae\u751f\u7269\u86cb\u767d\u8d28\u6765\u6e90\u7814\u7a76\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.20629", "pdf": "https://arxiv.org/pdf/2506.20629", "abs": "https://arxiv.org/abs/2506.20629", "authors": ["Soufiane Hayou", "Nikhil Ghosh", "Bin Yu"], "title": "PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models", "categories": ["cs.LG", "cs.CL", "stat.ML"], "comment": "TD,LR: A lightweight module type selection method for LoRA\n  finetuning. PLoP gives precise placements for LoRA adapters for improved\n  performance", "summary": "Low-Rank Adaptation (LoRA) is a widely used finetuning method for large\nmodels. Its small memory footprint allows practitioners to adapt large models\nto specific tasks at a fraction of the cost of full finetuning. Different\nmodifications have been proposed to enhance its efficiency by, for example,\nsetting the learning rate, the rank, and the initialization. Another\nimprovement axis is adapter placement strategy: when using LoRA, practitioners\nusually pick module types to adapt with LoRA, such as Query and Key modules.\nFew works have studied the problem of adapter placement, with nonconclusive\nresults: original LoRA paper suggested placing adapters in attention modules,\nwhile other works suggested placing them in the MLP modules. Through an\nintuitive theoretical analysis, we introduce PLoP (Precise LoRA Placement), a\nlightweight method that allows automatic identification of module types where\nLoRA adapters should be placed, given a pretrained model and a finetuning task.\nWe demonstrate that PLoP consistently outperforms, and in the worst case\ncompetes, with commonly used placement strategies through comprehensive\nexperiments on supervised finetuning and reinforcement learning for reasoning.", "AI": {"tldr": "Low-Rank Adaptation (LoRA) \u662f\u4e00\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u5927\u578b\u6a21\u578b\u5fae\u8c03\u65b9\u6cd5\uff0c\u5177\u6709\u8f83\u5c0f\u7684\u5185\u5b58\u5360\u7528\u3002\u901a\u8fc7\u8bbe\u7f6e\u5b66\u4e60\u7387\u3001\u79e9\u548c\u521d\u59cb\u5316\u7b49\u4fee\u6539\u6765\u63d0\u9ad8\u5176\u6548\u7387\u3002\u6b64\u5916\uff0c\u9002\u914d\u5668\u653e\u7f6e\u7b56\u7565\u4e5f\u662f\u4e00\u4e2a\u6539\u8fdb\u65b9\u5411\u3002\u672c\u6587\u901a\u8fc7\u76f4\u89c2\u7684\u7406\u8bba\u5206\u6790\u5f15\u5165\u4e86 PLoP\uff08Precise LoRA Placement\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6839\u636e\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u5fae\u8c03\u4efb\u52a1\u81ea\u52a8\u8bc6\u522b\u5e94\u653e\u7f6e LoRA \u9002\u914d\u5668\u7684\u6a21\u5757\u7c7b\u578b\u3002\u5b9e\u9a8c\u8868\u660e\uff0cPLoP \u5728\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u63a8\u7406\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u5e38\u7528\u653e\u7f6e\u7b56\u7565\uff0c\u6216\u81f3\u5c11\u4e0e\u4e4b\u7ade\u4e89\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u7ecf\u63d0\u51fa\u4e86\u591a\u79cd\u65b9\u6cd5\u6765\u63d0\u9ad8 LoRA \u7684\u6548\u7387\uff0c\u4f46\u5173\u4e8e\u9002\u914d\u5668\u653e\u7f6e\u7b56\u7565\u7684\u7814\u7a76\u8f83\u5c11\uff0c\u4e14\u7ed3\u679c\u4e0d\u4e00\u81f4\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u63a2\u7d22\u4e00\u79cd\u66f4\u7cbe\u786e\u7684\u65b9\u6cd5\u6765\u786e\u5b9a\u9002\u914d\u5668\u7684\u6700\u4f73\u653e\u7f6e\u4f4d\u7f6e\u3002", "method": "\u7814\u7a76\u8005\u901a\u8fc7\u76f4\u89c2\u7684\u7406\u8bba\u5206\u6790\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a PLoP\uff08Precise LoRA Placement\uff09\u7684\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6839\u636e\u7ed9\u5b9a\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u548c\u5fae\u8c03\u4efb\u52a1\u81ea\u52a8\u8bc6\u522b\u9002\u5408\u653e\u7f6e LoRA \u9002\u914d\u5668\u7684\u6a21\u5757\u7c7b\u578b\u3002", "result": "\u901a\u8fc7\u5168\u9762\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0cPLoP \u65b9\u6cd5\u5728\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u59cb\u7ec8\u4f18\u4e8e\u5e38\u89c1\u7684\u653e\u7f6e\u7b56\u7565\uff0c\u5373\u4f7f\u5728\u6700\u5dee\u60c5\u51b5\u4e0b\u4e5f\u80fd\u4e0e\u4e4b\u7ade\u4e89\u3002", "conclusion": "PLoP \u63d0\u4f9b\u4e86\u4e00\u79cd\u81ea\u52a8\u5316\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u4f18\u5316 LoRA \u9002\u914d\u5668\u7684\u653e\u7f6e\u7b56\u7565\uff0c\u4ece\u800c\u8fdb\u4e00\u6b65\u63d0\u5347 LoRA \u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2506.20023", "pdf": "https://arxiv.org/pdf/2506.20023", "abs": "https://arxiv.org/abs/2506.20023", "authors": ["Ryan Hildebrant", "Rahul Bhope", "Sharad Mehrotra", "Christopher Tull", "Nalini Venkatasubramanian"], "title": "DIM-SUM: Dynamic IMputation for Smart Utility Management", "categories": ["cs.LG", "cs.DB"], "comment": null, "summary": "Time series imputation models have traditionally been developed using\ncomplete datasets with artificial masking patterns to simulate missing values.\nHowever, in real-world infrastructure monitoring, practitioners often encounter\ndatasets where large amounts of data are missing and follow complex,\nheterogeneous patterns. We introduce DIM-SUM, a preprocessing framework for\ntraining robust imputation models that bridges the gap between artificially\nmasked training data and real missing patterns. DIM-SUM combines pattern\nclustering and adaptive masking strategies with theoretical learning guarantees\nto handle diverse missing patterns actually observed in the data. Through\nextensive experiments on over 2 billion readings from California water\ndistricts, electricity datasets, and benchmarks, we demonstrate that DIM-SUM\noutperforms traditional methods by reaching similar accuracy with lower\nprocessing time and significantly less training data. When compared against a\nlarge pre-trained model, DIM-SUM averages 2x higher accuracy with significantly\nless inference time.", "AI": {"tldr": "DIM-SUM\u662f\u4e00\u79cd\u9884\u5904\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u8bad\u7ec3\u7a33\u5065\u7684\u65f6\u95f4\u5e8f\u5217\u586b\u8865\u6a21\u578b\u3002\u5b83\u7ed3\u5408\u4e86\u6a21\u5f0f\u805a\u7c7b\u548c\u81ea\u9002\u5e94\u63a9\u7801\u7b56\u7565\uff0c\u5728\u4eba\u5de5\u63a9\u7801\u6570\u636e\u548c\u771f\u5b9e\u7f3a\u5931\u6a21\u5f0f\u4e4b\u95f4\u67b6\u8d77\u6865\u6881\u3002\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cDIM-SUM\u5728\u51cf\u5c11\u5904\u7406\u65f6\u95f4\u3001\u8bad\u7ec3\u6570\u636e\u91cf\u4ee5\u53ca\u63d0\u9ad8\u63a8\u7406\u7cbe\u5ea6\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u5e8f\u5217\u586b\u8865\u6a21\u578b\u5927\u591a\u57fa\u4e8e\u5b8c\u6574\u6570\u636e\u96c6\u5e76\u901a\u8fc7\u4eba\u5de5\u63a9\u7801\u6a21\u62df\u7f3a\u5931\u503c\uff0c\u4f46\u5728\u5b9e\u9645\u57fa\u7840\u8bbe\u65bd\u76d1\u63a7\u4e2d\uff0c\u6570\u636e\u7f3a\u5931\u91cf\u5927\u4e14\u6a21\u5f0f\u590d\u6742\u591a\u6837\uff0c\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u5f00\u53d1\u4e00\u79cd\u80fd\u66f4\u597d\u5730\u9002\u5e94\u771f\u5b9e\u4e16\u754c\u7f3a\u5931\u6a21\u5f0f\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51faDIM-SUM\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6574\u5408\u4e86\u6a21\u5f0f\u805a\u7c7b\u4e0e\u81ea\u9002\u5e94\u63a9\u7801\u7b56\u7565\uff0c\u5e76\u5177\u6709\u7406\u8bba\u5b66\u4e60\u4fdd\u8bc1\uff0c\u80fd\u591f\u5904\u7406\u6570\u636e\u4e2d\u5b9e\u9645\u89c2\u5bdf\u5230\u7684\u5404\u79cd\u7f3a\u5931\u6a21\u5f0f\u3002", "result": "\u5728\u8d85\u8fc720\u4ebf\u6761\u6765\u81ea\u52a0\u5dde\u6c34\u533a\u3001\u7535\u529b\u6570\u636e\u96c6\u53ca\u57fa\u51c6\u6d4b\u8bd5\u7684\u8bfb\u6570\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660eDIM-SUM\u7528\u66f4\u5c11\u7684\u5904\u7406\u65f6\u95f4\u548c\u8bad\u7ec3\u6570\u636e\u8fbe\u5230\u4e86\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u4f3c\u7684\u7cbe\u5ea6\uff0c\u5e76\u4e14\u76f8\u6bd4\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5e73\u5747\u7cbe\u5ea6\u63d0\u9ad8\u4e862\u500d\uff0c\u540c\u65f6\u63a8\u7406\u65f6\u95f4\u663e\u8457\u7f29\u77ed\u3002", "conclusion": "DIM-SUM\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5e94\u5bf9\u771f\u5b9e\u4e16\u754c\u4e2d\u590d\u6742\u7684\u7f3a\u5931\u6570\u636e\u6a21\u5f0f\uff0c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2506.20600", "pdf": "https://arxiv.org/pdf/2506.20600", "abs": "https://arxiv.org/abs/2506.20600", "authors": ["Wengxi Li", "Roy Pea", "Nick Haber", "Hari Subramonyam"], "title": "CogGen: A Learner-Centered Generative AI Architecture for Intelligent Tutoring with Programming Video", "categories": ["cs.AI"], "comment": null, "summary": "We introduce CogGen, a learner-centered AI architecture that transforms\nprogramming videos into interactive, adaptive learning experiences by\nintegrating student modeling with generative AI tutoring based on the Cognitive\nApprenticeship framework. The architecture consists of three components: (1)\nvideo segmentation by learning goals, (2) a conversational tutoring engine\napplying Cognitive Apprenticeship strategies, and (3) a student model using\nBayesian Knowledge Tracing to adapt instruction. Our technical evaluation\ndemonstrates effective video segmentation accuracy and strong pedagogical\nalignment across knowledge, method, action, and interaction layers. Ablation\nstudies confirm the necessity of each component in generating effective\nguidance. This work advances AI-powered tutoring by bridging structured student\nmodeling with interactive AI conversations, offering a scalable approach to\nenhancing video-based programming education.", "AI": {"tldr": "The paper introduces CogGen, an AI architecture that turns programming videos into adaptive learning experiences using student modeling and generative AI tutoring.", "motivation": "To improve video-based programming education by creating interactive, adaptive learning experiences from programming videos.", "method": "CogGen consists of three components: (1) video segmentation by learning goals, (2) a conversational tutoring engine applying Cognitive Apprenticeship strategies, and (3) a student model using Bayesian Knowledge Tracing to adapt instruction.", "result": "Technical evaluation shows effective video segmentation accuracy and strong pedagogical alignment across knowledge, method, action, and interaction layers. Ablation studies confirm the necessity of each component.", "conclusion": "CogGen advances AI-powered tutoring by integrating structured student modeling with interactive AI conversations, offering a scalable approach to enhance video-based programming education."}}
{"id": "2506.20650", "pdf": "https://arxiv.org/pdf/2506.20650", "abs": "https://arxiv.org/abs/2506.20650", "authors": ["Anqi Mao", "Mehryar Mohri", "Yutao Zhong"], "title": "Mastering Multiple-Expert Routing: Realizable $H$-Consistency and Strong Guarantees for Learning to Defer", "categories": ["cs.LG", "stat.ML"], "comment": "ICML 2025", "summary": "The problem of learning to defer with multiple experts consists of optimally\nassigning input instances to experts, balancing the trade-off between their\naccuracy and computational cost. This is a critical challenge in natural\nlanguage generation, but also in other fields such as image processing, and\nmedical diagnostics. Recent studies have proposed surrogate loss functions to\noptimize deferral, but challenges remain in ensuring their consistency\nproperties. This paper introduces novel surrogate loss functions and efficient\nalgorithms with strong theoretical learning guarantees. We address open\nquestions regarding realizable $H$-consistency, $H$-consistency bounds, and\nBayes-consistency for both single-stage (jointly learning predictor and\ndeferral function) and two-stage (learning only the deferral function with a\nfixed expert) learning scenarios. For single-stage deferral, we introduce a\nfamily of new realizable $H$-consistent surrogate losses and further prove\n$H$-consistency for a selected member. For two-stage deferral, we derive new\nsurrogate losses that achieve realizable $H$-consistency, $H$-consistency\nbounds, and Bayes-consistency for the two-expert scenario and, under natural\nassumptions, multiple-expert scenario. Additionally, we provide enhanced\ntheoretical guarantees under low-noise assumptions for both scenarios. Finally,\nwe report the results of experiments using our proposed surrogate losses,\ncomparing their performance against existing baselines.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u4ee3\u7406\u635f\u5931\u51fd\u6570\u548c\u9ad8\u6548\u7b97\u6cd5\uff0c\u4ee5\u4f18\u5316\u591a\u4e13\u5bb6\u7cfb\u7edf\u4e2d\u7684\u4efb\u52a1\u5206\u914d\u95ee\u9898\uff0c\u5e76\u5728\u5355\u9636\u6bb5\u548c\u53cc\u9636\u6bb5\u5b66\u4e60\u573a\u666f\u4e2d\u63d0\u4f9b\u4e86\u7406\u8bba\u4fdd\u8bc1\u3002", "motivation": "\u591a\u4e13\u5bb6\u7cfb\u7edf\u4e2d\u7684\u4efb\u52a1\u5206\u914d\u9700\u8981\u5e73\u8861\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u8fd9\u5728\u81ea\u7136\u8bed\u8a00\u751f\u6210\u3001\u56fe\u50cf\u5904\u7406\u548c\u533b\u5b66\u8bca\u65ad\u7b49\u9886\u57df\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e9b\u4ee3\u7406\u635f\u5931\u51fd\u6570\uff0c\u4f46\u5176\u4e00\u81f4\u6027\u5c5e\u6027\u4ecd\u5b58\u5728\u6311\u6218\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u65b0\u7684\u4ee3\u7406\u635f\u5931\u51fd\u6570\u548c\u9ad8\u6548\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u53ef\u5b9e\u73b0\u7684H-\u4e00\u81f4\u6027\u3001H-\u4e00\u81f4\u6027\u754c\u9650\u548c\u8d1d\u53f6\u65af\u4e00\u81f4\u6027\u7b49\u95ee\u9898\u3002\u5bf9\u4e8e\u5355\u9636\u6bb5\u5b66\u4e60\uff0c\u63d0\u51fa\u4e86\u65b0\u7684H-\u4e00\u81f4\u4ee3\u7406\u635f\u5931\u51fd\u6570\uff1b\u5bf9\u4e8e\u53cc\u9636\u6bb5\u5b66\u4e60\uff0c\u63a8\u5bfc\u51fa\u4e86\u9002\u7528\u4e8e\u4e24\u4e13\u5bb6\u548c\u591a\u4e13\u5bb6\u573a\u666f\u7684\u4ee3\u7406\u635f\u5931\u51fd\u6570\u3002\u6b64\u5916\uff0c\u5728\u4f4e\u566a\u58f0\u5047\u8bbe\u4e0b\u63d0\u4f9b\u4e86\u589e\u5f3a\u7684\u7406\u8bba\u4fdd\u8bc1\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684\u4ee3\u7406\u635f\u5931\u51fd\u6570\u7684\u6027\u80fd\uff0c\u5e76\u4e0e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5c55\u793a\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "conclusion": "\u65b0\u7684\u4ee3\u7406\u635f\u5931\u51fd\u6570\u548c\u7b97\u6cd5\u4e3a\u591a\u4e13\u5bb6\u7cfb\u7edf\u7684\u4efb\u52a1\u5206\u914d\u95ee\u9898\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u5e76\u5728\u5355\u9636\u6bb5\u548c\u53cc\u9636\u6bb5\u5b66\u4e60\u573a\u666f\u4e2d\u8868\u73b0\u826f\u597d\u3002"}}
{"id": "2506.20608", "pdf": "https://arxiv.org/pdf/2506.20608", "abs": "https://arxiv.org/abs/2506.20608", "authors": ["Barry Smith", "Junchao Zhang", "Hong Zhang", "Lois Curfman McInnes", "Murat Keceli", "Archit Vasan", "Satish Balay", "Toby Isaac", "Le Chen", "Venkatram Vishwanath"], "title": "AI Assistants to Enhance and Exploit the PETSc Knowledge Base", "categories": ["cs.AI", "cs.NA", "math.NA"], "comment": null, "summary": "Generative AI, especially through large language models (LLMs), is\ntransforming how technical knowledge can be accessed, reused, and extended.\nPETSc, a widely used numerical library for high-performance scientific\ncomputing, has accumulated a rich but fragmented knowledge base over its three\ndecades of development, spanning source code, documentation, mailing lists,\nGitLab issues, Discord conversations, technical papers, and more. Much of this\nknowledge remains informal and inaccessible to users and new developers. To\nactivate and utilize this knowledge base more effectively, the PETSc team has\nbegun building an LLM-powered system that combines PETSc content with custom\nLLM tools -- including retrieval-augmented generation (RAG), reranking\nalgorithms, and chatbots -- to assist users, support developers, and propose\nupdates to formal documentation. This paper presents initial experiences\ndesigning and evaluating these tools, focusing on system architecture, using\nRAG and reranking for PETSc-specific information, evaluation methodologies for\nvarious LLMs and embedding models, and user interface design. Leveraging the\nArgonne Leadership Computing Facility resources, we analyze how LLM responses\ncan enhance the development and use of numerical software, with an initial\nfocus on scalable Krylov solvers. Our goal is to establish an extensible\nframework for knowledge-centered AI in scientific software, enabling scalable\nsupport, enriched documentation, and enhanced workflows for research and\ndevelopment. We conclude by outlining directions for expanding this system into\na robust, evolving platform that advances software ecosystems to accelerate\nscientific discovery.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\uff0c\u7279\u522b\u662f\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u6b63\u5728\u6539\u53d8\u6280\u672f\u77e5\u8bc6\u7684\u8bbf\u95ee\u3001\u91cd\u7528\u548c\u6269\u5c55\u65b9\u5f0f\u3002PETSc\u56e2\u961f\u5f00\u59cb\u6784\u5efa\u4e00\u4e2a\u7531LLM\u9a71\u52a8\u7684\u7cfb\u7edf\uff0c\u7ed3\u5408PETSc\u5185\u5bb9\u4e0e\u81ea\u5b9a\u4e49LLM\u5de5\u5177\uff0c\u5982\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u3001\u91cd\u65b0\u6392\u5e8f\u7b97\u6cd5\u548c\u804a\u5929\u673a\u5668\u4eba\uff0c\u4ee5\u5e2e\u52a9\u7528\u6237\u3001\u652f\u6301\u5f00\u53d1\u8005\u5e76\u63d0\u51fa\u5bf9\u6b63\u5f0f\u6587\u6863\u7684\u66f4\u65b0\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u8bbe\u8ba1\u548c\u8bc4\u4f30\u8fd9\u4e9b\u5de5\u5177\u7684\u521d\u6b65\u7ecf\u9a8c\uff0c\u91cd\u70b9\u5173\u6ce8\u7cfb\u7edf\u67b6\u6784\u3001\u4f7f\u7528RAG\u548c\u91cd\u65b0\u6392\u5e8f\u8fdb\u884cPETSc\u7279\u5b9a\u4fe1\u606f\u5904\u7406\u3001\u5404\u79cdLLMs\u548c\u5d4c\u5165\u6a21\u578b\u7684\u8bc4\u4f30\u65b9\u6cd5\u4ee5\u53ca\u7528\u6237\u754c\u9762\u8bbe\u8ba1\u3002\u76ee\u6807\u662f\u5efa\u7acb\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u77e5\u8bc6\u4e2d\u5fc3\u578bAI\u6846\u67b6\uff0c\u7528\u4e8e\u79d1\u5b66\u8f6f\u4ef6\uff0c\u4f7f\u53ef\u6269\u5c55\u7684\u652f\u6301\u3001\u4e30\u5bcc\u7684\u6587\u6863\u548c\u589e\u5f3a\u7684\u7814\u7a76\u4e0e\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u6210\u4e3a\u53ef\u80fd\u3002", "motivation": "PETSc\u5e93\u7ecf\u8fc7\u4e09\u5341\u5e74\u7684\u53d1\u5c55\u79ef\u7d2f\u4e86\u4e30\u5bcc\u4f46\u5206\u6563\u7684\u77e5\u8bc6\u5e93\uff0c\u5176\u4e2d\u5927\u90e8\u5206\u77e5\u8bc6\u662f\u975e\u6b63\u5f0f\u4e14\u7528\u6237\u53ca\u65b0\u5f00\u53d1\u8005\u96be\u4ee5\u8bbf\u95ee\u7684\u3002\u56e0\u6b64\uff0c\u9700\u8981\u66f4\u6709\u6548\u5730\u6fc0\u6d3b\u548c\u5229\u7528\u8fd9\u4e00\u77e5\u8bc6\u5e93\u3002", "method": "PETSc\u56e2\u961f\u6784\u5efa\u4e86\u4e00\u4e2a\u7531LLM\u9a71\u52a8\u7684\u7cfb\u7edf\uff0c\u7ed3\u5408\u4e86PETSc\u5185\u5bb9\u4e0e\u81ea\u5b9a\u4e49LLM\u5de5\u5177\uff0c\u5305\u62ec\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u3001\u91cd\u65b0\u6392\u5e8f\u7b97\u6cd5\u548c\u804a\u5929\u673a\u5668\u4eba\u7b49\uff0c\u6765\u5e2e\u52a9\u7528\u6237\u3001\u652f\u6301\u5f00\u53d1\u8005\uff0c\u5e76\u63d0\u51fa\u5bf9\u6b63\u5f0f\u6587\u6863\u7684\u66f4\u65b0\u3002\u8be5\u7cfb\u7edf\u5229\u7528Argonne Leadership Computing Facility\u8d44\u6e90\uff0c\u5206\u6790LLM\u54cd\u5e94\u5982\u4f55\u589e\u5f3a\u6570\u503c\u8f6f\u4ef6\u7684\u5f00\u53d1\u548c\u4f7f\u7528\u3002", "result": "\u521d\u6b65\u8bbe\u8ba1\u548c\u8bc4\u4f30\u4e86\u7cfb\u7edf\u67b6\u6784\u3001RAG\u548c\u91cd\u65b0\u6392\u5e8f\u5728PETSc\u7279\u5b9a\u4fe1\u606f\u4e2d\u7684\u5e94\u7528\u3001\u4e0d\u540cLLMs\u548c\u5d4c\u5165\u6a21\u578b\u7684\u8bc4\u4f30\u65b9\u6cd5\u53ca\u7528\u6237\u754c\u9762\u8bbe\u8ba1\u3002\u7ed3\u679c\u8868\u660e\uff0cLLM\u53ef\u4ee5\u589e\u5f3a\u6570\u503c\u8f6f\u4ef6\u7684\u5f00\u53d1\u548c\u4f7f\u7528\uff0c\u7279\u522b\u662f\u5728\u53ef\u6269\u5c55Krylov\u6c42\u89e3\u5668\u65b9\u9762\u3002", "conclusion": "\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u7684\u77e5\u8bc6\u4e2d\u5fc3\u578bAI\u6846\u67b6\uff0c\u7528\u4e8e\u79d1\u5b66\u8f6f\u4ef6\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u652f\u6301\u3001\u4e30\u5bcc\u6587\u6863\u548c\u589e\u5f3a\u7814\u7a76\u4e0e\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u3002\u672a\u6765\u5c06\u6269\u5c55\u6b64\u7cfb\u7edf\u6210\u4e3a\u4e00\u4e2a\u5f3a\u5927\u4e14\u4e0d\u65ad\u53d1\u5c55\u7684\u5e73\u53f0\uff0c\u63a8\u52a8\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\u52a0\u901f\u79d1\u5b66\u53d1\u73b0\u3002"}}
{"id": "2506.20640", "pdf": "https://arxiv.org/pdf/2506.20640", "abs": "https://arxiv.org/abs/2506.20640", "authors": ["Sijie Li", "Weiwei Sun", "Shanda Li", "Ameet Talwalkar", "Yiming Yang"], "title": "Towards Community-Driven Agents for Machine Learning Engineering", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Large language model-based machine learning (ML) agents have shown great\npromise in automating ML research. However, existing agents typically operate\nin isolation on a given research problem, without engaging with the broader\nresearch community, where human researchers often gain insights and contribute\nby sharing knowledge. To bridge this gap, we introduce MLE-Live, a live\nevaluation framework designed to assess an agent's ability to communicate with\nand leverage collective knowledge from a simulated Kaggle research community.\nBuilding on this framework, we propose CoMind, a novel agent that excels at\nexchanging insights and developing novel solutions within a community context.\nCoMind achieves state-of-the-art performance on MLE-Live and outperforms 79.2%\nhuman competitors on average across four ongoing Kaggle competitions. Our code\nis released at https://github.com/comind-ml/CoMind.", "AI": {"tldr": "CoMind is a new machine learning agent that works well in exchanging insights and developing novel solutions within a community context, achieving state-of-the-art performance on MLE-Live.", "motivation": "Existing ML agents typically operate in isolation without engaging with the broader research community. There is a need for an agent that can communicate and leverage collective knowledge from a simulated research community.", "method": "Introduced MLE-Live, a live evaluation framework to assess an agent's ability to communicate with and leverage collective knowledge from a simulated Kaggle research community. Proposed CoMind, a novel agent designed to excel at exchanging insights and developing novel solutions within a community context.", "result": "CoMind achieves state-of-the-art performance on MLE-Live and outperforms 79.2% human competitors on average across four ongoing Kaggle competitions.", "conclusion": "CoMind represents a significant advancement in ML agents capable of engaging with and benefiting from community interactions."}}
{"id": "2506.20031", "pdf": "https://arxiv.org/pdf/2506.20031", "abs": "https://arxiv.org/abs/2506.20031", "authors": ["Prithvi Poddar", "Ehsan Tarkesh Esfahani", "Karthik Dantu", "Souma Chowdhury"], "title": "Automated Generation of Diverse Courses of Actions for Multi-Agent Operations using Binary Optimization and Graph Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Operations in disaster response, search \\& rescue, and military missions that\ninvolve multiple agents demand automated processes to support the planning of\nthe courses of action (COA). Moreover, traverse-affecting changes in the\nenvironment (rain, snow, blockades, etc.) may impact the expected performance\nof a COA, making it desirable to have a pool of COAs that are diverse in task\ndistributions across agents. Further, variations in agent capabilities, which\ncould be human crews and/or autonomous systems, present practical opportunities\nand computational challenges to the planning process. This paper presents a new\ntheoretical formulation and computational framework to generate such diverse\npools of COAs for operations with soft variations in agent-task compatibility.\nKey to the problem formulation is a graph abstraction of the task space and the\npool of COAs itself to quantify its diversity. Formulating the COAs as a\ncentralized multi-robot task allocation problem, a genetic algorithm is used\nfor (order-ignoring) allocations of tasks to each agent that jointly maximize\ndiversity within the COA pool and overall compatibility of the agent-task\nmappings. A graph neural network is trained using a policy gradient approach to\nthen perform single agent task sequencing in each COA, which maximizes\ncompletion rates adaptive to task features. Our tests of the COA generation\nprocess in a simulated environment demonstrate significant performance gain\nover a random walk baseline, small optimality gap in task sequencing, and\nexecution time of about 50 minutes to plan up to 20 COAs for 5 agent/100 task\noperations.", "AI": {"tldr": "\u5728\u707e\u5bb3\u54cd\u5e94\u3001\u641c\u6551\u548c\u519b\u4e8b\u4efb\u52a1\u4e2d\uff0c\u6d89\u53ca\u591a\u4e2a\u4ee3\u7406\u7684\u64cd\u4f5c\u9700\u8981\u81ea\u52a8\u5316\u8fc7\u7a0b\u6765\u652f\u6301\u884c\u52a8\u8def\u7ebf\uff08COA\uff09\u7684\u89c4\u5212\u3002\u6b64\u5916\uff0c\u73af\u5883\u4e2d\u7684\u53d8\u5316\uff08\u5982\u96e8\u3001\u96ea\u3001\u5c01\u9501\u7b49\uff09\u53ef\u80fd\u5f71\u54cdCOA\u7684\u9884\u671f\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u6709\u4e00\u7ec4\u5728\u4ee3\u7406\u95f4\u4efb\u52a1\u5206\u5e03\u4e0a\u591a\u6837\u5316\u7684COA\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7406\u8bba\u516c\u5f0f\u548c\u8ba1\u7b97\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u5177\u6709\u8f6f\u6027\u4ee3\u7406-\u4efb\u52a1\u517c\u5bb9\u6027\u53d8\u5316\u64cd\u4f5c\u7684\u591a\u6837\u5316COA\u6c60\u3002\u95ee\u9898\u516c\u5f0f\u7684\u5173\u952e\u662f\u4efb\u52a1\u7a7a\u95f4\u548cCOA\u6c60\u672c\u8eab\u7684\u56fe\u62bd\u8c61\uff0c\u4ee5\u91cf\u5316\u5176\u591a\u6837\u6027\u3002\u901a\u8fc7\u5c06COA\u516c\u5f0f\u5316\u4e3a\u96c6\u4e2d\u5f0f\u591a\u673a\u5668\u4eba\u4efb\u52a1\u5206\u914d\u95ee\u9898\uff0c\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u8fdb\u884c\u4efb\u52a1\u5206\u914d\uff0c\u4ece\u800c\u8054\u5408\u6700\u5927\u5316COA\u6c60\u5185\u7684\u591a\u6837\u6027\u548c\u6574\u4f53\u4ee3\u7406-\u4efb\u52a1\u6620\u5c04\u7684\u517c\u5bb9\u6027\u3002\u7136\u540e\u4f7f\u7528\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u8bad\u7ec3\u56fe\u795e\u7ecf\u7f51\u7edc\u6765\u8fdb\u884c\u5355\u4e2a\u4ee3\u7406\u4efb\u52a1\u6392\u5e8f\uff0c\u4ee5\u6700\u5927\u5316\u9002\u5e94\u4efb\u52a1\u7279\u5f81\u7684\u5b8c\u6210\u7387\u3002\u6211\u4eec\u5728\u6a21\u62df\u73af\u5883\u4e2d\u5bf9COA\u751f\u6210\u8fc7\u7a0b\u7684\u6d4b\u8bd5\u8868\u660e\uff0c\u76f8\u8f83\u4e8e\u968f\u673a\u6e38\u8d70\u57fa\u7ebf\u6709\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4efb\u52a1\u6392\u5e8f\u7684\u5c0f\u4f18\u5316\u5dee\u8ddd\uff0c\u4ee5\u53ca\u4e3a5\u4e2a\u4ee3\u7406/100\u4e2a\u4efb\u52a1\u64cd\u4f5c\u8ba1\u5212\u591a\u8fbe20\u4e2aCOA\u7ea650\u5206\u949f\u7684\u6267\u884c\u65f6\u95f4\u3002", "motivation": "\u5728\u707e\u5bb3\u54cd\u5e94\u3001\u641c\u6551\u548c\u519b\u4e8b\u4efb\u52a1\u4e2d\uff0c\u6d89\u53ca\u591a\u4e2a\u4ee3\u7406\u7684\u64cd\u4f5c\u9700\u8981\u81ea\u52a8\u5316\u8fc7\u7a0b\u6765\u652f\u6301\u884c\u52a8\u8def\u7ebf\uff08COA\uff09\u7684\u89c4\u5212\u3002\u73af\u5883\u53d8\u5316\u53ef\u80fd\u5f71\u54cdCOA\u7684\u9884\u671f\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u7ec4\u5728\u4ee3\u7406\u95f4\u4efb\u52a1\u5206\u5e03\u4e0a\u591a\u6837\u5316\u7684COA\u3002\u6b64\u5916\uff0c\u4ee3\u7406\u80fd\u529b\u7684\u53d8\u5316\u4e5f\u4e3a\u89c4\u5212\u8fc7\u7a0b\u5e26\u6765\u4e86\u5b9e\u9645\u673a\u4f1a\u548c\u8ba1\u7b97\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7406\u8bba\u516c\u5f0f\u548c\u8ba1\u7b97\u6846\u67b6\uff0c\u5c06COA\u751f\u6210\u95ee\u9898\u8868\u793a\u4e3a\u96c6\u4e2d\u5f0f\u591a\u673a\u5668\u4eba\u4efb\u52a1\u5206\u914d\u95ee\u9898\u3002\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u8fdb\u884c\u4efb\u52a1\u5206\u914d\uff0c\u8054\u5408\u6700\u5927\u5316COA\u6c60\u5185\u7684\u591a\u6837\u6027\u548c\u6574\u4f53\u4ee3\u7406-\u4efb\u52a1\u6620\u5c04\u7684\u517c\u5bb9\u6027\u3002\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u5355\u4e2a\u4ee3\u7406\u4efb\u52a1\u6392\u5e8f\uff0c\u4ee5\u6700\u5927\u5316\u9002\u5e94\u4efb\u52a1\u7279\u5f81\u7684\u5b8c\u6210\u7387\u3002", "result": "\u6d4b\u8bd5\u8868\u660e\uff0c\u76f8\u8f83\u4e8e\u968f\u673a\u6e38\u8d70\u57fa\u7ebf\u6709\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4efb\u52a1\u6392\u5e8f\u7684\u5c0f\u4f18\u5316\u5dee\u8ddd\uff0c\u4ee5\u53ca\u4e3a5\u4e2a\u4ee3\u7406/100\u4e2a\u4efb\u52a1\u64cd\u4f5c\u8ba1\u5212\u591a\u8fbe20\u4e2aCOAs\u7ea650\u5206\u949f\u7684\u6267\u884c\u65f6\u95f4\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b0\u7406\u8bba\u516c\u5f0f\u548c\u8ba1\u7b97\u6846\u67b6\u80fd\u591f\u6709\u6548\u751f\u6210\u5177\u6709\u591a\u6837\u6027\u7684COA\u6c60\uff0c\u9002\u7528\u4e8e\u5177\u6709\u8f6f\u6027\u4ee3\u7406-\u4efb\u52a1\u517c\u5bb9\u6027\u53d8\u5316\u7684\u64cd\u4f5c\uff0c\u5e76\u5728\u6027\u80fd\u3001\u4f18\u5316\u5dee\u8ddd\u548c\u6267\u884c\u65f6\u95f4\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.20664", "pdf": "https://arxiv.org/pdf/2506.20664", "abs": "https://arxiv.org/abs/2506.20664", "authors": ["Andrei Lupu", "Timon Willi", "Jakob Foerster"], "title": "The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.MA"], "comment": "41 pages, 19 figures", "summary": "As Large Language Models (LLMs) gain agentic abilities, they will have to\nnavigate complex multi-agent scenarios, interacting with human users and other\nagents in cooperative and competitive settings. This will require new reasoning\nskills, chief amongst them being theory of mind (ToM), or the ability to reason\nabout the \"mental\" states of other agents. However, ToM and other multi-agent\nabilities in LLMs are poorly understood, since existing benchmarks suffer from\nnarrow scope, data leakage, saturation, and lack of interactivity. We thus\npropose Decrypto, a game-based benchmark for multi-agent reasoning and ToM\ndrawing inspiration from cognitive science, computational pragmatics and\nmulti-agent reinforcement learning. It is designed to be as easy as possible in\nall other dimensions, eliminating confounding factors commonly found in other\nbenchmarks. To our knowledge, it is also the first platform for designing\ninteractive ToM experiments.\n  We validate the benchmark design through comprehensive empirical evaluations\nof frontier LLMs, robustness studies, and human-AI cross-play experiments. We\nfind that LLM game-playing abilities lag behind humans and simple\nword-embedding baselines. We then create variants of two classic cognitive\nscience experiments within Decrypto to evaluate three key ToM abilities.\nSurprisingly, we find that state-of-the-art reasoning models are significantly\nworse at those tasks than their older counterparts. This demonstrates that\nDecrypto addresses a crucial gap in current reasoning and ToM evaluations, and\npaves the path towards better artificial agents.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDecrypto\u7684\u6e38\u620f\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u591a\u667a\u80fd\u4f53\u573a\u666f\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u548c\u5fc3\u667a\u7406\u8bba\uff08ToM\uff09\u3002\u901a\u8fc7\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u53d1\u73b0LLMs\u5728\u6e38\u620f\u4e2d\u7684\u8868\u73b0\u4e0d\u5982\u4eba\u7c7b\u548c\u7b80\u5355\u7684\u8bcd\u5d4c\u5165\u57fa\u7ebf\uff0c\u5e76\u4e14\u6700\u5148\u8fdb\u7684\u63a8\u7406\u6a21\u578b\u5728ToM\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002Decrypto\u586b\u8865\u4e86\u5f53\u524d\u63a8\u7406\u548cToM\u8bc4\u4f30\u4e2d\u7684\u5173\u952e\u7a7a\u767d\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u83b7\u5f97\u4ee3\u7406\u80fd\u529b\uff0c\u5b83\u4eec\u9700\u8981\u5728\u590d\u6742\u7684\u591a\u667a\u80fd\u4f53\u73af\u5883\u4e2d\u8fdb\u884c\u5bfc\u822a\uff0c\u4e0e\u4eba\u7c7b\u7528\u6237\u548c\u5176\u4ed6\u4ee3\u7406\u8fdb\u884c\u5408\u4f5c\u548c\u7ade\u4e89\u4e92\u52a8\u3002\u8fd9\u9700\u8981\u65b0\u7684\u63a8\u7406\u6280\u80fd\uff0c\u7279\u522b\u662f\u5fc3\u667a\u7406\u8bba\uff08ToM\uff09\uff0c\u5373\u5bf9\u5176\u4ed6\u4ee3\u7406\u7684\u201c\u5fc3\u7406\u201d\u72b6\u6001\u8fdb\u884c\u63a8\u7406\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u8303\u56f4\u72ed\u7a84\u3001\u6570\u636e\u6cc4\u6f0f\u3001\u9971\u548c\u4ee5\u53ca\u7f3a\u4e4f\u4ea4\u4e92\u6027\u7b49\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u5de5\u5177\u6765\u66f4\u597d\u5730\u7814\u7a76LLMs\u7684ToM\u548c\u591a\u667a\u80fd\u4f53\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Decrypto\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u6e38\u620f\u7684\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u7075\u611f\u6765\u81ea\u8ba4\u77e5\u79d1\u5b66\u3001\u8ba1\u7b97\u8bed\u7528\u5b66\u548c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u3002\u5b83\u8bbe\u8ba1\u5f97\u5c3d\u53ef\u80fd\u7b80\u5355\uff0c\u6d88\u9664\u4e86\u5176\u4ed6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e38\u89c1\u7684\u6df7\u6dc6\u56e0\u7d20\uff0c\u5e76\u4e14\u662f\u7b2c\u4e00\u4e2a\u7528\u4e8e\u8bbe\u8ba1\u4ea4\u4e92\u5f0fToM\u5b9e\u9a8c\u7684\u5e73\u53f0\u3002\u901a\u8fc7\u5168\u9762\u7684\u7ecf\u9a8c\u8bc4\u4f30\uff0c\u5305\u62ec\u524d\u6cbfLLMs\u7684\u8868\u73b0\u3001\u9c81\u68d2\u6027\u7814\u7a76\u4ee5\u53ca\u4eba\u673a\u4ea4\u53c9\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u57fa\u51c6\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u521b\u5efa\u4e86\u4e24\u4e2a\u7ecf\u5178\u8ba4\u77e5\u79d1\u5b66\u5b9e\u9a8c\u7684\u53d8\u4f53\uff0c\u4ee5\u8bc4\u4f30\u4e09\u79cd\u5173\u952e\u7684ToM\u80fd\u529b\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cLLMs\u5728\u6e38\u620f\u4e2d\u7684\u8868\u73b0\u843d\u540e\u4e8e\u4eba\u7c7b\u548c\u7b80\u5355\u7684\u8bcd\u5d4c\u5165\u57fa\u7ebf\u3002\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u6700\u5148\u8fdb\u7684\u63a8\u7406\u6a21\u578b\u5728ToM\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u6bd4\u5176\u8f83\u65e7\u7684\u7248\u672c\u66f4\u5dee\u3002", "conclusion": "Decrypto\u89e3\u51b3\u4e86\u5f53\u524d\u63a8\u7406\u548cToM\u8bc4\u4f30\u4e2d\u7684\u5173\u952e\u7a7a\u767d\uff0c\u4e3a\u5f00\u53d1\u66f4\u597d\u7684\u4eba\u5de5\u4ee3\u7406\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2506.20037", "pdf": "https://arxiv.org/pdf/2506.20037", "abs": "https://arxiv.org/abs/2506.20037", "authors": ["Mohammad M Maheri", "Alex Davidson", "Hamed Haddadi"], "title": "Verifiable Unlearning on Edge", "categories": ["cs.LG", "cs.CR"], "comment": "This paper has been accepted to the IEEE European Symposium on\n  Security and Privacy (EuroS&P) 2025", "summary": "Machine learning providers commonly distribute global models to edge devices,\nwhich subsequently personalize these models using local data. However, issues\nsuch as copyright infringements, biases, or regulatory requirements may require\nthe verifiable removal of certain data samples across all edge devices.\nEnsuring that edge devices correctly execute such unlearning operations is\ncritical to maintaining integrity.\n  In this work, we introduce a verification framework leveraging zero-knowledge\nproofs, specifically zk-SNARKs, to confirm data unlearning on personalized\nedge-device models without compromising privacy. We have developed algorithms\nexplicitly designed to facilitate unlearning operations that are compatible\nwith efficient zk-SNARK proof generation, ensuring minimal computational and\nmemory overhead suitable for constrained edge environments. Furthermore, our\napproach carefully preserves personalized enhancements on edge devices,\nmaintaining model performance post-unlearning.\n  Our results affirm the practicality and effectiveness of this verification\nframework, demonstrating verifiable unlearning with minimal degradation in\npersonalization-induced performance improvements. Our methodology ensures\nverifiable, privacy-preserving, and effective machine unlearning across edge\ndevices.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96f6\u77e5\u8bc6\u8bc1\u660e\uff08zk-SNARKs\uff09\u7684\u9a8c\u8bc1\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u786e\u8ba4\u6570\u636e\u9057\u5fd8\u64cd\u4f5c\uff0c\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u5e76\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u786e\u4fdd\u4e86\u53ef\u9a8c\u8bc1\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u6709\u6548\u7684\u673a\u5668\u9057\u5fd8\u64cd\u4f5c\u3002", "motivation": "\u5f53\u524d\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u4e2d\u5fc3\u5316\u6a21\u578b\u5206\u53d1\u5230\u8fb9\u7f18\u8bbe\u5907\u540e\u4f1a\u4f7f\u7528\u672c\u5730\u6570\u636e\u8fdb\u884c\u4e2a\u6027\u5316\u8bad\u7ec3\u3002\u7136\u800c\uff0c\u7531\u4e8e\u7248\u6743\u3001\u504f\u89c1\u6216\u6cd5\u89c4\u8981\u6c42\uff0c\u53ef\u80fd\u9700\u8981\u4ece\u6240\u6709\u8fb9\u7f18\u8bbe\u5907\u4e2d\u5220\u9664\u67d0\u4e9b\u6570\u636e\u6837\u672c\u3002\u56e0\u6b64\uff0c\u786e\u4fdd\u8fb9\u7f18\u8bbe\u5907\u6b63\u786e\u6267\u884c\u8fd9\u4e9b\u201c\u9057\u5fd8\u201d\u64cd\u4f5c\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u57fa\u4e8e\u96f6\u77e5\u8bc6\u8bc1\u660e\uff08\u7279\u522b\u662f zk-SNARKs\uff09\u7684\u9a8c\u8bc1\u6846\u67b6\uff0c\u4ee5\u786e\u8ba4\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u6570\u636e\u9057\u5fd8\u64cd\u4f5c\u3002\u5f00\u53d1\u4e86\u4e13\u95e8\u7b97\u6cd5\uff0c\u4f7f\u9057\u5fd8\u64cd\u4f5c\u4e0e\u9ad8\u6548\u7684 zk-SNARK \u8bc1\u660e\u751f\u6210\u517c\u5bb9\uff0c\u5e76\u6700\u5c0f\u5316\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u4fdd\u7559\u4e86\u4e2a\u6027\u5316\u589e\u5f3a\u529f\u80fd\uff0c\u7ef4\u6301\u9057\u5fd8\u540e\u7684\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u9a8c\u8bc1\u6846\u67b6\u662f\u5b9e\u7528\u4e14\u6709\u6548\u7684\uff0c\u80fd\u591f\u5728\u51e0\u4e4e\u4e0d\u964d\u4f4e\u4e2a\u6027\u5316\u6027\u80fd\u6539\u8fdb\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u53ef\u9a8c\u8bc1\u7684\u9057\u5fd8\u64cd\u4f5c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u53ef\u9a8c\u8bc1\u3001\u9690\u79c1\u4fdd\u62a4\u548c\u9ad8\u6548\u7684\u673a\u5668\u9057\u5fd8\u64cd\u4f5c\uff0c\u9002\u7528\u4e8e\u8fb9\u7f18\u8bbe\u5907\u73af\u5883\u3002"}}
{"id": "2506.20040", "pdf": "https://arxiv.org/pdf/2506.20040", "abs": "https://arxiv.org/abs/2506.20040", "authors": ["Ankur Garg", "Xuemin Yu", "Hassan Sajjad", "Samira Ebrahimi Kahou"], "title": "Cross-Layer Discrete Concept Discovery for Interpreting Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Uncovering emergent concepts across transformer layers remains a significant\nchallenge because the residual stream linearly mixes and duplicates\ninformation, obscuring how features evolve within large language models.\nCurrent research efforts primarily inspect neural representations at single\nlayers, thereby overlooking this cross-layer superposition and the redundancy\nit introduces. These representations are typically either analyzed directly for\nactivation patterns or passed to probing classifiers that map them to a limited\nset of predefined concepts. To address these limitations, we propose\n\\gls{clvqvae}, a framework that uses vector quantization to map representations\nacross layers and in the process collapse duplicated residual-stream features\ninto compact, interpretable concept vectors. Our approach uniquely combines\ntop-$k$ temperature-based sampling during quantization with EMA codebook\nupdates, providing controlled exploration of the discrete latent space while\nmaintaining code-book diversity. We further enhance the framework with\nscaled-spherical k-means++ for codebook initialization, which clusters by\ndirectional similarity rather than magnitude, better aligning with semantic\nstructure in word embedding space.", "AI": {"tldr": "\u63d0\u51faCLVQ-VAE\u6846\u67b6\uff0c\u901a\u8fc7\u5411\u91cf\u91cf\u5316\u5c06\u8de8\u5c42\u8868\u793a\u6620\u5c04\u5230\u7d27\u51d1\u3001\u53ef\u89e3\u91ca\u7684\u6982\u5ff5\u5411\u91cf\uff0c\u5e76\u7ed3\u5408\u591a\u79cd\u6280\u672f\u4f18\u5316\u79bb\u6563\u6f5c\u5728\u7a7a\u95f4\u7684\u63a2\u7d22\u548c\u7801\u672c\u591a\u6837\u6027\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u5355\u5c42\u795e\u7ecf\u8868\u793a\uff0c\u5ffd\u89c6\u4e86\u8de8\u5c42\u53e0\u52a0\u548c\u5197\u4f59\u95ee\u9898\u3002\u6b64\u5916\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u76f4\u63a5\u5206\u6790\u6fc0\u6d3b\u6a21\u5f0f\u6216\u5c06\u8868\u793a\u6620\u5c04\u5230\u6709\u9650\u9884\u5b9a\u4e49\u6982\u5ff5\uff0c\u65e0\u6cd5\u5145\u5206\u63ed\u793a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7279\u5f81\u7684\u6f14\u5316\u8fc7\u7a0b\u3002", "method": "\u63d0\u51faCLVQ-VAE\u6846\u67b6\uff0c\u5229\u7528\u5411\u91cf\u91cf\u5316\u5c06\u5404\u5c42\u8868\u793a\u6620\u5c04\u4e3a\u7d27\u51d1\u4e14\u53ef\u89e3\u91ca\u7684\u6982\u5ff5\u5411\u91cf\uff0c\u540c\u65f6\u7ed3\u5408top-k\u6e29\u5ea6\u91c7\u6837\u8fdb\u884c\u91cf\u5316\uff0c\u5e76\u4f7f\u7528EMA\u66f4\u65b0\u7801\u672c\u4ee5\u4fdd\u6301\u591a\u6837\u6027\u3002\u8fd8\u91c7\u7528scaled-spherical k-means++\u521d\u59cb\u5316\u7801\u672c\uff0c\u6309\u65b9\u5411\u76f8\u4f3c\u6027\u805a\u7c7b\u4ee5\u66f4\u597d\u5730\u4e0e\u8bcd\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u8bed\u4e49\u7ed3\u6784\u5bf9\u9f50\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u538b\u7f29\u91cd\u590d\u7684\u6b8b\u5dee\u6d41\u7279\u5f81\uff0c\u63d0\u4f9b\u5bf9\u79bb\u6563\u6f5c\u5728\u7a7a\u95f4\u7684\u53ef\u63a7\u63a2\u7d22\uff0c\u5e76\u7ef4\u6301\u7801\u672c\u591a\u6837\u6027\uff0c\u4ece\u800c\u63d0\u5347\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7279\u5f81\u6f14\u5316\u7684\u7406\u89e3\u3002", "conclusion": "CLVQ-VAE\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u5f0f\u6765\u5206\u6790\u8de8\u5c42\u8868\u793a\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u63ed\u793a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7279\u5f81\u7684\u6f14\u5316\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u5de5\u5177\u3002"}}
{"id": "2506.20041", "pdf": "https://arxiv.org/pdf/2506.20041", "abs": "https://arxiv.org/abs/2506.20041", "authors": ["Soheil Abadifard", "Fazli Can"], "title": "LSH-DynED: A Dynamic Ensemble Framework with LSH-Based Undersampling for Evolving Multi-Class Imbalanced Classification", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": null, "summary": "The classification of imbalanced data streams, which have unequal class\ndistributions, is a key difficulty in machine learning, especially when dealing\nwith multiple classes. While binary imbalanced data stream classification tasks\nhave received considerable attention, only a few studies have focused on\nmulti-class imbalanced data streams. Effectively managing the dynamic imbalance\nratio is a key challenge in this domain. This study introduces a novel, robust,\nand resilient approach to address these challenges by integrating Locality\nSensitive Hashing with Random Hyperplane Projections (LSH-RHP) into the Dynamic\nEnsemble Diversification (DynED) framework. To the best of our knowledge, we\npresent the first application of LSH-RHP for undersampling in the context of\nimbalanced non-stationary data streams. The proposed method undersamples the\nmajority classes by utilizing LSH-RHP, provides a balanced training set, and\nimproves the ensemble's prediction performance. We conduct comprehensive\nexperiments on 23 real-world and ten semi-synthetic datasets and compare\nLSH-DynED with 15 state-of-the-art methods. The results reveal that LSH-DynED\noutperforms other approaches in terms of both Kappa and mG-Mean effectiveness\nmeasures, demonstrating its capability in dealing with multi-class imbalanced\nnon-stationary data streams. Notably, LSH-DynED performs well in large-scale,\nhigh-dimensional datasets with considerable class imbalances and demonstrates\nadaptation and robustness in real-world circumstances. To motivate our design,\nwe review existing methods for imbalanced data streams, outline key challenges,\nand offer guidance for future work. For the reproducibility of our results, we\nhave made our implementation available on GitHub.", "AI": {"tldr": "The paper introduces LSH-DynED, a novel method combining Locality Sensitive Hashing with Random Hyperplane Projections for undersampling majority classes in multi-class imbalanced non-stationary data streams. It outperforms 15 state-of-the-art methods across 33 datasets in terms of Kappa and mG-Mean measures.", "motivation": "Existing methods for handling imbalanced data streams have mainly focused on binary classification tasks, with limited attention given to multi-class scenarios. The dynamic imbalance ratio in non-stationary data streams presents significant challenges that require a robust and resilient approach.", "method": "The method integrates Locality Sensitive Hashing with Random Hyperplane Projections (LSH-RHP) into the Dynamic Ensemble Diversification (DynED) framework. It undersamples the majority classes using LSH-RHP to provide a balanced training set and improve ensemble prediction performance.", "result": "LSH-DynED surpasses 15 state-of-the-art methods in experiments conducted on 23 real-world and ten semi-synthetic datasets. It demonstrates superior performance in terms of Kappa and mG-Mean effectiveness measures, particularly in large-scale, high-dimensional datasets with significant class imbalances.", "conclusion": "LSH-DynED is an effective solution for multi-class imbalanced non-stationary data streams, showing strong adaptation and robustness in real-world scenarios. The authors encourage future research and ensure reproducibility by releasing their implementation on GitHub."}}
{"id": "2506.20046", "pdf": "https://arxiv.org/pdf/2506.20046", "abs": "https://arxiv.org/abs/2506.20046", "authors": ["Hirad Daneshvar", "Reza Samavi"], "title": "GNN's Uncertainty Quantification using Self-Distillation", "categories": ["cs.LG", "cs.AI"], "comment": "The paper has been accepted in the International Conference on AI in\n  Healthcare (AIiH) 2025 and will appear in the conference proceedings", "summary": "Graph Neural Networks (GNNs) have shown remarkable performance in the\nhealthcare domain. However, what remained challenging is quantifying the\npredictive uncertainty of GNNs, which is an important aspect of trustworthiness\nin clinical settings. While Bayesian and ensemble methods can be used to\nquantify uncertainty, they are computationally expensive. Additionally, the\ndisagreement metric used by ensemble methods to compute uncertainty cannot\ncapture the diversity of models in an ensemble network. In this paper, we\npropose a novel method, based on knowledge distillation, to quantify GNNs'\nuncertainty more efficiently and with higher precision. We apply\nself-distillation, where the same network serves as both the teacher and\nstudent models, thereby avoiding the need to train several networks\nindependently. To ensure the impact of self-distillation, we develop an\nuncertainty metric that captures the diverse nature of the network by assigning\ndifferent weights to each GNN classifier. We experimentally evaluate the\nprecision, performance, and ability of our approach in distinguishing\nout-of-distribution data on two graph datasets: MIMIC-IV and Enzymes. The\nevaluation results demonstrate that the proposed method can effectively capture\nthe predictive uncertainty of the model while having performance similar to\nthat of the MC Dropout and ensemble methods. The code is publicly available at\nhttps://github.com/tailabTMU/UQ_GNN.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u84b8\u998f\u548c\u65b0\u7684\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u6765\u9ad8\u6548\u4e14\u7cbe\u786e\u5730\u91cf\u5316\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u6355\u83b7\u6a21\u578b\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u65b9\u9762\u6548\u679c\u663e\u8457\uff0c\u4e14\u6027\u80fd\u4e0eMC Dropout\u548c\u96c6\u6210\u65b9\u6cd5\u76f8\u5f53\u3002", "motivation": "\u5c3d\u7ba1GNN\u5728\u533b\u7597\u9886\u57df\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u91cf\u5316\u5176\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u4ecd\u5177\u6311\u6218\u6027\u3002\u73b0\u6709\u7684\u8d1d\u53f6\u65af\u548c\u96c6\u6210\u65b9\u6cd5\u867d\u7136\u53ef\u4ee5\u7528\u4e8e\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5e76\u4e14\u96c6\u6210\u65b9\u6cd5\u4e2d\u7684\u5206\u6b67\u5ea6\u91cf\u65e0\u6cd5\u6355\u6349\u6a21\u578b\u591a\u6837\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u81ea\u84b8\u998f\uff08\u540c\u4e00\u7f51\u7edc\u4f5c\u4e3a\u6559\u5e08\u548c\u5b66\u751f\u6a21\u578b\uff09\uff0c\u907f\u514d\u72ec\u7acb\u8bad\u7ec3\u591a\u4e2a\u7f51\u7edc\u3002\u540c\u65f6\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3a\u6bcf\u4e2aGNN\u5206\u7c7b\u5668\u5206\u914d\u4e0d\u540c\u6743\u91cd\u6765\u6355\u6349\u7f51\u7edc\u7684\u591a\u6837\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u6355\u83b7\u6a21\u578b\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u5728\u533a\u5206\u5206\u5e03\u5916\u6570\u636e\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4e14\u6027\u80fd\u4e0eMC Dropout\u548c\u96c6\u6210\u65b9\u6cd5\u76f8\u4f3c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u81ea\u84b8\u998f\u548c\u65b0\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u7684\u65b9\u6cd5\u53ef\u4ee5\u66f4\u9ad8\u6548\u3001\u66f4\u7cbe\u786e\u5730\u91cf\u5316GNN\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u5177\u6709\u8f83\u9ad8\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.20057", "pdf": "https://arxiv.org/pdf/2506.20057", "abs": "https://arxiv.org/abs/2506.20057", "authors": ["Peter Bloem"], "title": "Universal pre-training by iterated random computation", "categories": ["cs.LG"], "comment": null, "summary": "We investigate the use of randomly generated data for the sake of\npre-training a model. We justify this approach theoretically from the\nperspective of algorithmic complexity, building on recent research that shows\nthat sequence models can be trained to approximate Solomonoff induction. We\nderive similar, but complementary theoretical results. We show empirically that\nsynthetically generated data can be used to pre-train a model before the data\nis seen. We replicate earlier results that models trained this way show\nzero-shot in-context learning across a variety of datasets, and that this\nperformance improves with scale. We extend earlier results to real-world data,\nand show that finetuning a model after pre-training offers faster convergence\nand better generalization.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u968f\u673a\u751f\u6210\u7684\u6570\u636e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u4ece\u7b97\u6cd5\u590d\u6742\u6027\u7684\u89d2\u5ea6\u8fdb\u884c\u4e86\u7406\u8bba\u9a8c\u8bc1\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5408\u6210\u6570\u636e\u53ef\u7528\u4e8e\u9884\u8bad\u7ec3\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u96f6\u6837\u672c\u5b66\u4e60\u80fd\u529b\uff0c\u540c\u65f6\u5728\u5b9e\u9645\u6570\u636e\u5fae\u8c03\u65f6\u8868\u73b0\u51fa\u66f4\u5feb\u7684\u6536\u655b\u548c\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u4e00\u79cd\u65e0\u9700\u4f9d\u8d56\u771f\u5b9e\u6570\u636e\u5373\u53ef\u8fdb\u884c\u6a21\u578b\u9884\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u964d\u4f4e\u5bf9\u5927\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u540c\u65f6\u9a8c\u8bc1\u968f\u673a\u751f\u6210\u6570\u636e\u662f\u5426\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "\u4f5c\u8005\u57fa\u4e8e\u7b97\u6cd5\u590d\u6742\u6027\u7406\u8bba\uff0c\u7ed3\u5408Solomonoff\u5f52\u7eb3\u6cd5\uff0c\u8bc1\u660e\u4e86\u968f\u673a\u751f\u6210\u6570\u636e\u7528\u4e8e\u9884\u8bad\u7ec3\u7684\u53ef\u884c\u6027\u3002\u7136\u540e\u901a\u8fc7\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u6bd4\u8f83\u4e86\u4f7f\u7528\u5408\u6210\u6570\u636e\u4e0e\u771f\u5b9e\u6570\u636e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u5e76\u6d4b\u8bd5\u4e86\u5fae\u8c03\u9636\u6bb5\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u5408\u6210\u6570\u636e\u9884\u8bad\u7ec3\u7684\u6a21\u578b\u80fd\u591f\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u96f6\u6837\u672c\u5b66\u4e60\uff0c\u5e76\u4e14\u968f\u7740\u6a21\u578b\u89c4\u6a21\u589e\u5927\uff0c\u6027\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u3002\u6b64\u5916\uff0c\u5728\u771f\u5b9e\u6570\u636e\u4e0a\u5fae\u8c03\u540e\uff0c\u6a21\u578b\u5c55\u73b0\u51fa\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u968f\u673a\u751f\u6210\u7684\u6570\u636e\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u6709\u6548\u7684\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4e3a\u6a21\u578b\u63d0\u4f9b\u5148\u9a8c\u77e5\u8bc6\uff0c\u51cf\u5c11\u5bf9\u771f\u5b9e\u6570\u636e\u7684\u4f9d\u8d56\uff0c\u540c\u65f6\u63d0\u5347\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5b66\u4e60\u6548\u7387\u3002"}}
{"id": "2506.20061", "pdf": "https://arxiv.org/pdf/2506.20061", "abs": "https://arxiv.org/abs/2506.20061", "authors": ["Zhicheng Zhang", "Ziyan Wang", "Yali Du", "Fei Fang"], "title": "Learning Instruction-Following Policies through Open-Ended Instruction Relabeling with Large Language Models", "categories": ["cs.LG"], "comment": "Under Review", "summary": "Developing effective instruction-following policies in reinforcement learning\nremains challenging due to the reliance on extensive human-labeled instruction\ndatasets and the difficulty of learning from sparse rewards. In this paper, we\npropose a novel approach that leverages the capabilities of large language\nmodels (LLMs) to automatically generate open-ended instructions retrospectively\nfrom previously collected agent trajectories. Our core idea is to employ LLMs\nto relabel unsuccessful trajectories by identifying meaningful subtasks the\nagent has implicitly accomplished, thereby enriching the agent's training data\nand substantially alleviating reliance on human annotations. Through this\nopen-ended instruction relabeling, we efficiently learn a unified\ninstruction-following policy capable of handling diverse tasks within a single\npolicy. We empirically evaluate our proposed method in the challenging Craftax\nenvironment, demonstrating clear improvements in sample efficiency, instruction\ncoverage, and overall policy performance compared to state-of-the-art\nbaselines. Our results highlight the effectiveness of utilizing LLM-guided\nopen-ended instruction relabeling to enhance instruction-following\nreinforcement learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u81ea\u52a8\u4ece\u5148\u524d\u6536\u96c6\u7684\u667a\u80fd\u4f53\u8f68\u8ff9\u4e2d\u751f\u6210\u5f00\u653e\u6027\u6307\u4ee4\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u65b0\u6807\u6ce8\u672a\u6210\u529f\u7684\u8f68\u8ff9\u6765\u4e30\u5bcc\u8bad\u7ec3\u6570\u636e\uff0c\u51cf\u5c11\u5bf9\u4eba\u5de5\u6807\u6ce8\u7684\u4f9d\u8d56\uff0c\u5e76\u5b66\u4e60\u7edf\u4e00\u7684\u6307\u4ee4\u8ddf\u968f\u7b56\u7565\u3002\u5728Craftax\u73af\u5883\u4e2d\u7684\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u6837\u672c\u6548\u7387\u3001\u6307\u4ee4\u8986\u76d6\u8303\u56f4\u548c\u6574\u4f53\u7b56\u7565\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u57fa\u7ebf\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u4e2d\u5f00\u53d1\u6709\u6548\u7684\u6307\u4ee4\u8ddf\u968f\u7b56\u7565\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u4f9d\u8d56\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\u7684\u6307\u4ee4\u6570\u636e\u96c6\u4ee5\u53ca\u4ece\u7a00\u758f\u5956\u52b1\u4e2d\u5b66\u4e60\u7684\u56f0\u96be\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u5229\u7528LLMs\u7684\u80fd\u529b\u6765\u81ea\u52a8\u521b\u5efa\u5f00\u653e\u6027\u6307\u4ee4\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528LLMs\u56de\u6eaf\u6027\u5730\u4ece\u4e4b\u524d\u6536\u96c6\u7684\u667a\u80fd\u4f53\u8f68\u8ff9\u4e2d\u751f\u6210\u5f00\u653e\u6027\u6307\u4ee4\uff0c\u7279\u522b\u662f\u4e3a\u4e0d\u6210\u529f\u7684\u8f68\u8ff9\u8bc6\u522b\u6709\u610f\u4e49\u7684\u5b50\u4efb\u52a1\u5e76\u91cd\u65b0\u6807\u6ce8\uff0c\u4ece\u800c\u4e30\u5bcc\u8bad\u7ec3\u6570\u636e\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u53ef\u4ee5\u9ad8\u6548\u5b66\u4e60\u5230\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u591a\u6837\u5316\u4efb\u52a1\u7684\u7edf\u4e00\u6307\u4ee4\u8ddf\u968f\u7b56\u7565\u3002", "result": "\u5728Craftax\u73af\u5883\u4e2d\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6837\u672c\u6548\u7387\u3001\u6307\u4ee4\u8986\u76d6\u8303\u56f4\u548c\u6574\u4f53\u7b56\u7565\u6027\u80fd\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86\u4f7f\u7528LLM\u5f15\u5bfc\u7684\u5f00\u653e\u6027\u6307\u4ee4\u91cd\u65b0\u6807\u6ce8\u6280\u672f\u53ef\u4ee5\u6709\u6548\u589e\u5f3a\u6307\u4ee4\u8ddf\u968f\u5f3a\u5316\u5b66\u4e60\u7684\u6548\u679c\uff0c\u4e3a\u672a\u6765\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u3001\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2506.20065", "pdf": "https://arxiv.org/pdf/2506.20065", "abs": "https://arxiv.org/abs/2506.20065", "authors": ["Cristian Minoccheri", "Sophia Tesic", "Kayvan Najarian", "Ryan Stidham"], "title": "Supervised Coupled Matrix-Tensor Factorization (SCMTF) for Computational Phenotyping of Patient Reported Outcomes in Ulcerative Colitis", "categories": ["cs.LG"], "comment": null, "summary": "Phenotyping is the process of distinguishing groups of patients to identify\ndifferent types of disease progression. A recent trend employs low-rank matrix\nand tensor factorization methods for their capability of dealing with\nmulti-modal, heterogeneous, and missing data. Symptom quantification is crucial\nfor understanding patient experiences in inflammatory bowel disease, especially\nin conditions such as ulcerative colitis (UC). However, patient-reported\nsymptoms are typically noisy, subjective, and significantly more sparse than\nother data types. For this reason, they are usually not included in phenotyping\nand other machine learning methods. This paper explores the application of\ncomputational phenotyping to leverage Patient-Reported Outcomes (PROs) using a\nnovel supervised coupled matrix-tensor factorization (SCMTF) method, which\nintegrates temporal PROs and temporal labs with static features to predict\nmedication persistence in ulcerative colitis. This is the first tensor-based\nmethod that is both supervised and coupled, it is the first application to the\nUC domain, and the first application to PROs. We use a deep learning framework\nthat makes the model flexible and easy to train. The proposed method allows us\nto handle the large amount of missing data in the PROs. The best model predicts\nchanges in medication 8 and 20 months in the future with AUCs of 0.853 and\n0.803 on the test set respectively. We derive interpretable phenotypes\nconsisting of static features and temporal features (including their temporal\npatterns). We show that low-rank matrix and tensor based phenotyping can be\nsuccessfully applied to the UC domain and to highly missing PRO data. We\nidentify phenotypes useful to predict medication persistence - these phenotypes\ninclude several symptom variables, showing that PROs contain relevant\ninfromation that is usually discarded.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u76d1\u7763\u8026\u5408\u77e9\u9635-\u5f20\u91cf\u5206\u89e3\uff08SCMTF\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u6574\u5408\u60a3\u8005\u62a5\u544a\u7ed3\u679c\uff08PROs\uff09\u3001\u65f6\u95f4\u5b9e\u9a8c\u5ba4\u6570\u636e\u548c\u9759\u6001\u7279\u5f81\uff0c\u4ee5\u9884\u6d4b\u6e83\u75a1\u6027\u7ed3\u80a0\u708e\u60a3\u8005\u7684\u836f\u7269\u4f9d\u4ece\u6027\u3002\u8be5\u65b9\u6cd5\u9996\u6b21\u6210\u529f\u5e94\u7528\u4e8eUC\u9886\u57df\u548c\u9ad8\u5ea6\u7f3a\u5931\u7684PRO\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u4f4e\u79e9\u77e9\u9635\u548c\u5f20\u91cf\u5206\u89e3\u65b9\u6cd5\u63d0\u53d6\u4e86\u53ef\u89e3\u91ca\u7684\u8868\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u8ba1\u7b97\u8868\u578b\u65b9\u6cd5\u901a\u5e38\u4e0d\u5305\u62ec\u60a3\u8005\u62a5\u544a\u7684\u75c7\u72b6\uff08PROs\uff09\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u6570\u636e\u901a\u5e38\u662f\u566a\u58f0\u3001\u4e3b\u89c2\u4e14\u7a00\u758f\u7684\u3002\u7136\u800c\uff0c\u5728\u708e\u75c7\u6027\u80a0\u75c5\u4e2d\uff0c\u75c7\u72b6\u91cf\u5316\u5bf9\u4e8e\u7406\u89e3\u60a3\u8005\u4f53\u9a8c\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u6709\u6548\u5229\u7528PROs\u6570\u636e\u8fdb\u884c\u9884\u6d4b\u548c\u8868\u578b\u5206\u6790\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u76d1\u7763\u8026\u5408\u77e9\u9635-\u5f20\u91cf\u5206\u89e3\uff08SCMTF\uff09\u65b9\u6cd5\uff0c\u5c06\u65f6\u95f4\u6027\u7684PROs\u548c\u5b9e\u9a8c\u5ba4\u6570\u636e\u4e0e\u9759\u6001\u7279\u5f81\u76f8\u7ed3\u5408\uff0c\u7528\u4e8e\u9884\u6d4b\u6e83\u75a1\u6027\u7ed3\u80a0\u708e\u60a3\u8005\u7684\u836f\u7269\u4f9d\u4ece\u6027\u3002\u540c\u65f6\uff0c\u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u4f7f\u6a21\u578b\u66f4\u7075\u6d3b\u4e14\u6613\u4e8e\u8bad\u7ec3\uff0c\u4ece\u800c\u5904\u7406PROs\u4e2d\u7684\u5927\u91cf\u7f3a\u5931\u6570\u636e\u3002", "result": "\u6700\u4f73\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u5206\u522b\u80fd\u591f\u63d0\u524d8\u4e2a\u6708\u548c20\u4e2a\u6708\u9884\u6d4b\u836f\u7269\u53d8\u5316\uff0cAUC\u5206\u522b\u4e3a0.853\u548c0.803\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u63d0\u53d6\u4e86\u5305\u542b\u9759\u6001\u7279\u5f81\u548c\u65f6\u95f4\u7279\u5f81\uff08\u5305\u62ec\u5176\u65f6\u95f4\u6a21\u5f0f\uff09\u7684\u53ef\u89e3\u91ca\u8868\u578b\uff0c\u5e76\u8bc1\u660ePROs\u6570\u636e\u5305\u542b\u76f8\u5173\u7684\u4fe1\u606f\uff0c\u53ef\u7528\u4e8e\u9884\u6d4b\u836f\u7269\u4f9d\u4ece\u6027\u3002", "conclusion": "\u4f4e\u79e9\u77e9\u9635\u548c\u5f20\u91cf\u5206\u89e3\u65b9\u6cd5\u53ef\u4ee5\u6210\u529f\u5e94\u7528\u4e8e\u6e83\u75a1\u6027\u7ed3\u80a0\u708e\u9886\u57df\u548c\u9ad8\u5ea6\u7f3a\u5931\u7684PRO\u6570\u636e\u3002\u901a\u8fc7\u8be5\u65b9\u6cd5\u8bc6\u522b\u51fa\u7684\u8868\u578b\u6709\u52a9\u4e8e\u9884\u6d4b\u836f\u7269\u4f9d\u4ece\u6027\uff0c\u5e76\u8868\u660ePROs\u6570\u636e\u5305\u542b\u6709\u4ef7\u503c\u7684\u4fe1\u606f\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u5229\u7528\u3002"}}
{"id": "2506.20090", "pdf": "https://arxiv.org/pdf/2506.20090", "abs": "https://arxiv.org/abs/2506.20090", "authors": ["Ainaz Jamshidi", "Dongchan Kim", "Muhammad Arif"], "title": "A Survey of Predictive Maintenance Methods: An Analysis of Prognostics via Classification and Regression", "categories": ["cs.LG"], "comment": "13 pages, 7 figures", "summary": "Predictive maintenance (PdM) has become a crucial element of modern\nindustrial practice. PdM plays a significant role in operational dependability\nand cost management by decreasing unforeseen downtime and optimizing asset life\ncycle management. Machine learning and deep learning have enabled more precise\nforecasts of equipment failure and remaining useful life (RUL). Although many\nstudies have been conducted on PdM, there has not yet been a standalone\ncomparative study between regression- and classification-based approaches. In\nthis review, we look across a range of PdM methodologies, while focusing more\nstrongly on the comparative use of classification and regression methods in\nprognostics. While regression-based methods typically provide estimates of RUL,\nclassification-based methods present a forecast of the probability of failure\nacross defined time intervals. Through a comprehensive analysis of recent\nliterature, we highlight key advancements, challenges-such as data imbalance\nand high-dimensional feature spaces-and emerging trends, including hybrid\napproaches and AI-enabled prognostic systems. This review aims to provide\nresearchers and practitioners with an awareness of the strengths and\ncompromises of various PdM methods and to help identify future research and\nbuild more robust, directed adaptive maintenance systems. Future work may\ninclude a systematic review of practical aspects such as public datasets,\nbenchmarking platforms, and open-source tools to support the advancement of PdM\nresearch.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u9884\u6d4b\u6027\u7ef4\u62a4(PdM)\u65b9\u6cd5\uff0c\u91cd\u70b9\u6bd4\u8f83\u4e86\u56de\u5f52\u548c\u5206\u7c7b\u65b9\u6cd5\u5728\u6545\u969c\u9884\u6d4b\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u63a2\u8ba8\u4e86\u6570\u636e\u4e0d\u5e73\u8861\u3001\u9ad8\u7ef4\u7279\u5f81\u7a7a\u95f4\u7b49\u6311\u6218\u53ca\u6df7\u5408\u65b9\u6cd5\u548cAI\u652f\u6301\u7cfb\u7edf\u7b49\u8d8b\u52bf\u3002", "motivation": "\u5c3d\u7ba1\u8bb8\u591a\u7814\u7a76\u5df2\u7ecf\u9488\u5bf9PdM\u5c55\u5f00\uff0c\u4f46\u5c1a\u672a\u6709\u72ec\u7acb\u7684\u56de\u5f52\u4e0e\u5206\u7c7b\u65b9\u6cd5\u7684\u6bd4\u8f83\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5168\u9762\u5206\u6790\u8fd1\u671f\u6587\u732e\uff0c\u5bf9\u6bd4\u56de\u5f52\u548c\u5206\u7c7b\u65b9\u6cd5\u5728\u9884\u6d4b\u6027\u7ef4\u62a4\u4e2d\u7684\u5e94\u7528\uff0c\u5305\u62ec\u5bf9RUL\u4f30\u8ba1\u548c\u6545\u969c\u6982\u7387\u9884\u6d4b\u7684\u4e0d\u540c\u4fa7\u91cd\u3002", "result": "\u5f3a\u8c03\u4e86\u4e24\u79cd\u65b9\u6cd5\u7684\u4f18\u52bf\u4e0e\u59a5\u534f\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5982\u516c\u5171\u6570\u636e\u96c6\u3001\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\u548c\u5f00\u6e90\u5de5\u5177\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u63d0\u4f9b\u4e86\u4e0d\u540cPdM\u65b9\u6cd5\u7684\u4f18\u7f3a\u70b9\u8ba4\u77e5\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u5f3a\u5927\u7684\u81ea\u9002\u5e94\u7ef4\u62a4\u7cfb\u7edf\u3002"}}
{"id": "2506.20094", "pdf": "https://arxiv.org/pdf/2506.20094", "abs": "https://arxiv.org/abs/2506.20094", "authors": ["Krishna Praneet Gudipaty", "Walid A. Hanafy", "Kaan Ozkara", "Qianlin Liang", "Jesse Milzman", "Prashant Shenoy", "Suhas Diggavi"], "title": "MEL: Multi-level Ensemble Learning for Resource-Constrained Environments", "categories": ["cs.LG"], "comment": null, "summary": "AI inference at the edge is becoming increasingly common for low-latency\nservices. However, edge environments are power- and resource-constrained, and\nsusceptible to failures. Conventional failure resilience approaches, such as\ncloud failover or compressed backups, often compromise latency or accuracy,\nlimiting their effectiveness for critical edge inference services. In this\npaper, we propose Multi-Level Ensemble Learning (MEL), a new framework for\nresilient edge inference that simultaneously trains multiple lightweight backup\nmodels capable of operating collaboratively, refining each other when multiple\nservers are available, and independently under failures while maintaining good\naccuracy. Specifically, we formulate our approach as a multi-objective\noptimization problem with a loss formulation that inherently encourages\ndiversity among individual models to promote mutually refining representations,\nwhile ensuring each model maintains good standalone performance. Empirical\nevaluations across vision, language, and audio datasets show that MEL provides\nperformance comparable to original architectures while also providing fault\ntolerance and deployment flexibility across edge platforms. Our results show\nthat our ensemble model, sized at 40\\% of the original model, achieves similar\nperformance, while preserving 95.6\\% of ensemble accuracy in the case of\nfailures when trained using MEL.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMulti-Level Ensemble Learning (MEL)\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u9ad8\u8fb9\u7f18\u63a8\u7406\u7684\u5f39\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u540c\u65f6\u8bad\u7ec3\u591a\u4e2a\u8f7b\u91cf\u7ea7\u5907\u4efd\u6a21\u578b\uff0c\u5728\u670d\u52a1\u5668\u6545\u969c\u65f6\u80fd\u591f\u4fdd\u6301\u826f\u597d\u7684\u51c6\u786e\u6027\uff0c\u5e76\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u6027\u80fd\u548c\u5bb9\u9519\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u8fb9\u7f18\u73af\u5883\u4e0b\u7684AI\u63a8\u7406\u670d\u52a1\u53d7\u5230\u529f\u7387\u3001\u8d44\u6e90\u9650\u5236\u4ee5\u53ca\u6613\u53d7\u6545\u969c\u5f71\u54cd\u7684\u95ee\u9898\u56f0\u6270\u3002\u4f20\u7edf\u7684\u6545\u969c\u6062\u590d\u65b9\u6cd5\uff08\u5982\u4e91\u6545\u969c\u8f6c\u79fb\u6216\u538b\u7f29\u5907\u4efd\uff09\u901a\u5e38\u4f1a\u5728\u5ef6\u8fdf\u6216\u51c6\u786e\u6027\u4e0a\u505a\u51fa\u59a5\u534f\uff0c\u4ece\u800c\u9650\u5236\u4e86\u5176\u5728\u5173\u952e\u8fb9\u7f18\u63a8\u7406\u670d\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Multi-Level Ensemble Learning (MEL)\u6846\u67b6\uff0c\u901a\u8fc7\u540c\u65f6\u8bad\u7ec3\u591a\u4e2a\u8f7b\u91cf\u7ea7\u5907\u4efd\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u53ef\u4ee5\u5728\u591a\u670d\u52a1\u5668\u73af\u5883\u4e0b\u76f8\u4e92\u7cbe\u70bc\uff0c\u4e5f\u53ef\u4ee5\u5728\u5355\u4e2a\u670d\u52a1\u5668\u6545\u969c\u65f6\u72ec\u7acb\u8fd0\u884c\u5e76\u4fdd\u6301\u826f\u597d\u51c6\u786e\u6027\u3002\u65b9\u6cd5\u88ab\u8868\u8ff0\u4e3a\u4e00\u4e2a\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\uff0c\u635f\u5931\u51fd\u6570\u9f13\u52b1\u6a21\u578b\u95f4\u7684\u591a\u6837\u6027\u4ee5\u4fc3\u8fdb\u76f8\u4e92\u7cbe\u70bc\u7684\u8868\u793a\uff0c\u540c\u65f6\u786e\u4fdd\u6bcf\u4e2a\u6a21\u578b\u90fd\u6709\u826f\u597d\u7684\u72ec\u7acb\u6027\u80fd\u3002", "result": "\u5728\u89c6\u89c9\u3001\u8bed\u8a00\u548c\u97f3\u9891\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0cMEL\u63d0\u4f9b\u7684\u6027\u80fd\u4e0e\u539f\u59cb\u67b6\u6784\u76f8\u5f53\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u5bb9\u9519\u80fd\u529b\u548c\u5728\u8fb9\u7f18\u5e73\u53f0\u4e0a\u7684\u90e8\u7f72\u7075\u6d3b\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8fd8\u663e\u793a\uff0c\u4f7f\u7528MEL\u8bad\u7ec3\u7684\u96c6\u6210\u6a21\u578b\u5927\u5c0f\u4ec5\u4e3a\u539f\u59cb\u6a21\u578b\u768440%\uff0c\u5374\u80fd\u5b9e\u73b0\u7c7b\u4f3c\u7684\u6027\u80fd\uff0c\u5e76\u5728\u6545\u969c\u60c5\u51b5\u4e0b\u4fdd\u755995.6%\u7684\u96c6\u6210\u51c6\u786e\u6027\u3002", "conclusion": "Multi-Level Ensemble Learning (MEL)\u662f\u4e00\u79cd\u6709\u6548\u7684\u6846\u67b6\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u63d0\u4f9b\u5bb9\u9519\u80fd\u529b\u548c\u7075\u6d3b\u7684\u8fb9\u7f18\u90e8\u7f72\u9009\u9879\uff0c\u9002\u7528\u4e8e\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u73af\u5883\u4e0b\u7684AI\u63a8\u7406\u4efb\u52a1\u3002"}}
{"id": "2506.20132", "pdf": "https://arxiv.org/pdf/2506.20132", "abs": "https://arxiv.org/abs/2506.20132", "authors": ["Patrick Alan Johnson", "Gabriel Tseng", "Yawen Zhang", "Heather Heward", "Virginia Sjahli", "Favyen Bastani", "Joseph Redmon", "Patrick Beukema"], "title": "High-Resolution Live Fuel Moisture Content (LFMC) Maps for Wildfire Risk from Multimodal Earth Observation Data", "categories": ["cs.LG"], "comment": "10 pages, ICML 2025 (TerraBytes)", "summary": "Wildfires are increasing in intensity and severity at an alarming rate.\nRecent advances in AI and publicly available satellite data enable monitoring\ncritical wildfire risk factors globally, at high resolution and low latency.\nLive Fuel Moisture Content (LFMC) is a critical wildfire risk factor and is\nvaluable for both wildfire research and operational response. However,\nground-based LFMC samples are both labor intensive and costly to acquire,\nresulting in sparse and infrequent updates. In this work, we explore the use of\na pretrained, highly-multimodal earth-observation model for generating\nlarge-scale spatially complete (wall-to-wall) LFMC maps. Our approach achieves\nsignificant improvements over previous methods using randomly initialized\nmodels (20 reduction in RMSE). We provide an automated pipeline that enables\nrapid generation of these LFMC maps across the United States, and demonstrate\nits effectiveness in two regions recently impacted by wildfire (Eaton and\nPalisades).", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u591a\u6a21\u6001\u5730\u7403\u89c2\u6d4b\u6a21\u578b\u751f\u6210\u5927\u89c4\u6a21\u3001\u7a7a\u95f4\u5b8c\u6574\u7684\u5b9e\u65f6\u71c3\u6599\u6e7f\u5ea6\u542b\u91cf\uff08LFMC\uff09\u5730\u56fe\u7684\u65b9\u6cd5\uff0c\u76f8\u6bd4\u968f\u673a\u521d\u59cb\u5316\u6a21\u578b\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86RMSE\uff0c\u5e76\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u7ba1\u9053\u4ee5\u5feb\u901f\u751f\u6210\u7f8e\u56fd\u7684LFMC\u5730\u56fe\uff0c\u5c55\u793a\u4e86\u5176\u5728\u53d7\u91ce\u706b\u5f71\u54cd\u533a\u57df\u7684\u6709\u6548\u6027\u3002", "motivation": "\u91ce\u706b\u7684\u5f3a\u5ea6\u548c\u4e25\u91cd\u7a0b\u5ea6\u6b63\u5728\u8fc5\u901f\u589e\u52a0\uff0c\u800c\u73b0\u6709\u7684\u57fa\u4e8e\u5730\u9762\u7684\u5b9e\u65f6\u71c3\u6599\u6e7f\u5ea6\u542b\u91cf\uff08LFMC\uff09\u6837\u672c\u83b7\u53d6\u65b9\u5f0f\u8017\u65f6\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u5bfc\u81f4\u6570\u636e\u66f4\u65b0\u7a00\u758f\u800c\u4e0d\u53ca\u65f6\u3002\u5229\u7528AI\u548c\u516c\u5f00\u53ef\u7528\u7684\u536b\u661f\u6570\u636e\u53ef\u4ee5\u5b9e\u73b0\u5bf9\u5168\u7403\u91ce\u706b\u98ce\u9669\u56e0\u7d20\u7684\u9ad8\u5206\u8fa8\u7387\u3001\u4f4e\u5ef6\u8fdf\u76d1\u6d4b\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u9884\u8bad\u7ec3\u7684\u9ad8\u5ea6\u591a\u6a21\u6001\u5730\u7403\u89c2\u6d4b\u6a21\u578b\u6765\u751f\u6210\u5927\u89c4\u6a21\u7684\u7a7a\u95f4\u5b8c\u6574\uff08\u5168\u9762\u8986\u76d6\uff09\u7684LFMC\u5730\u56fe\u3002\u8fd9\u79cd\u65b9\u6cd5\u901a\u8fc7\u81ea\u52a8\u5316\u7ba1\u9053\u5b9e\u73b0\u4e86\u8fd9\u4e9b\u5730\u56fe\u5728\u7f8e\u56fd\u8303\u56f4\u5185\u7684\u5feb\u901f\u751f\u6210\u3002", "result": "\u8be5\u65b9\u6cd5\u76f8\u8f83\u4e8e\u4f7f\u7528\u968f\u673a\u521d\u59cb\u5316\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5728\u5747\u65b9\u6839\u8bef\u5dee\uff08RMSE\uff09\u4e0a\u51cf\u5c11\u4e8620%\u3002\u901a\u8fc7\u5728\u4e24\u4e2a\u8fd1\u671f\u53d7\u5230\u91ce\u706b\u5f71\u54cd\u7684\u5730\u533a\uff08Eaton\u548cPalisades\uff09\u8fdb\u884c\u4e86\u6709\u6548\u6027\u7684\u5c55\u793a\u3002", "conclusion": "\u9884\u8bad\u7ec3\u7684\u591a\u6a21\u6001\u5730\u7403\u89c2\u6d4b\u6a21\u578b\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u751f\u6210LFMC\u5730\u56fe\u7684\u7cbe\u5ea6\uff0c\u5e76\u4e3a\u91ce\u706b\u7814\u7a76\u548c\u5e94\u6025\u54cd\u5e94\u63d0\u4f9b\u6709\u529b\u652f\u6301\u3002\u6b64\u65b9\u6cd5\u53ca\u81ea\u52a8\u5316\u7ba1\u9053\u53ef\u5feb\u901f\u751f\u6210\u5927\u8303\u56f4LFMC\u5730\u56fe\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u91ce\u706b\u98ce\u9669\u7ba1\u7406\u3002"}}
{"id": "2506.20169", "pdf": "https://arxiv.org/pdf/2506.20169", "abs": "https://arxiv.org/abs/2506.20169", "authors": ["Bala Rajesh Konkathi", "Arun K. Tangirala"], "title": "Causal discovery in deterministic discrete LTI-DAE systems", "categories": ["cs.LG", "cs.SY", "eess.SP", "eess.SY", "stat.ME"], "comment": null, "summary": "Discovering pure causes or driver variables in deterministic LTI systems is\nof vital importance in the data-driven reconstruction of causal networks. A\nrecent work by Kathari and Tangirala, proposed in 2022, formulated the causal\ndiscovery method as a constraint identification problem. The constraints are\nidentified using a dynamic iterative PCA (DIPCA)-based approach for dynamical\nsystems corrupted with Gaussian measurement errors. The DIPCA-based method\nworks efficiently for dynamical systems devoid of any algebraic relations.\nHowever, several dynamical systems operate under feedback control and/or are\ncoupled with conservation laws, leading to differential-algebraic (DAE) or\nmixed causal systems. In this work, a method, namely the partition of variables\n(PoV), for causal discovery in LTI-DAE systems is proposed. This method is\nsuperior to the method that was presented by Kathari and Tangirala (2022), as\nPoV also works for pure dynamical systems, which are devoid of algebraic\nequations. The proposed method identifies the causal drivers up to a minimal\nsubset. PoV deploys DIPCA to first determine the number of algebraic relations\n($n_a$), the number of dynamical relations ($n_d$) and the constraint matrix.\nSubsequently, the subsets are identified through an admissible partitioning of\nthe constraint matrix by finding the condition number of it. Case studies are\npresented to demonstrate the effectiveness of the proposed method.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\uff0c\u5373\u53d8\u91cf\u5212\u5206\uff08PoV\uff09\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u7ebf\u6027\u65f6\u4e0d\u53d8\u5fae\u5206\u4ee3\u6570\u7cfb\u7edf\uff08LTI-DAE\uff09\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u8fed\u4ee3\u4e3b\u6210\u5206\u5206\u6790\uff08DIPCA\uff09\u786e\u5b9a\u4ee3\u6570\u548c\u52a8\u6001\u5173\u7cfb\u7684\u6570\u91cf\u53ca\u7ea6\u675f\u77e9\u9635\uff0c\u5e76\u901a\u8fc7\u8ba1\u7b97\u6761\u4ef6\u6570\u8fdb\u884c\u53ef\u63a5\u53d7\u7684\u5206\u533a\uff0c\u4ece\u800c\u8bc6\u522b\u51fa\u6700\u5c0f\u5b50\u96c6\u4e2d\u7684\u56e0\u679c\u9a71\u52a8\u56e0\u7d20\u3002\u76f8\u6bd4Kathari\u548cTangirala\uff082022\uff09\u63d0\u51fa\u7684\u65b9\u6cd5\uff0cPoV\u65b9\u6cd5\u5728\u5904\u7406\u7eaf\u52a8\u529b\u5b66\u7cfb\u7edf\u548c\u5305\u542b\u4ee3\u6570\u65b9\u7a0b\u7684\u7cfb\u7edf\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5982Kathari\u548cTangirala\uff082022\uff09\u63d0\u51fa\u7684\u52a8\u6001\u8fed\u4ee3\u4e3b\u6210\u5206\u5206\u6790\uff08DIPCA\uff09\u65b9\u6cd5\u867d\u7136\u5bf9\u7eaf\u52a8\u529b\u5b66\u7cfb\u7edf\u6709\u6548\uff0c\u4f46\u5728\u5904\u7406\u53d7\u53cd\u9988\u63a7\u5236\u6216\u4e0e\u5b88\u6052\u5b9a\u5f8b\u8026\u5408\u7684\u5fae\u5206-\u4ee3\u6570\u7cfb\u7edf\u65f6\u5b58\u5728\u5c40\u9650\u6027\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u53d8\u91cf\u5212\u5206\uff08PoV\uff09\u7684\u65b0\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u9996\u5148\u4f7f\u7528DIPCA\u786e\u5b9a\u7cfb\u7edf\u7684\u4ee3\u6570\u5173\u7cfb\u6570\u91cf\uff08$n_a$\uff09\u3001\u52a8\u6001\u5173\u7cfb\u6570\u91cf\uff08$n_d$\uff09\u4ee5\u53ca\u7ea6\u675f\u77e9\u9635\uff1b\u7136\u540e\u901a\u8fc7\u8ba1\u7b97\u7ea6\u675f\u77e9\u9635\u7684\u6761\u4ef6\u6570\u8fdb\u884c\u53ef\u63a5\u53d7\u7684\u5206\u533a\uff0c\u4ece\u800c\u8bc6\u522b\u51fa\u6700\u5c0f\u5b50\u96c6\u4e2d\u7684\u56e0\u679c\u9a71\u52a8\u56e0\u7d20\u3002", "result": "PoV\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5730\u8bc6\u522b\u51fa\u7ebf\u6027\u65f6\u4e0d\u53d8\u5fae\u5206\u4ee3\u6570\u7cfb\u7edf\uff08LTI-DAE\uff09\u4e2d\u7684\u56e0\u679c\u9a71\u52a8\u56e0\u7d20\uff0c\u5305\u62ec\u90a3\u4e9b\u5305\u542b\u4ee3\u6570\u65b9\u7a0b\u7684\u7cfb\u7edf\u3002\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u5904\u7406\u590d\u6742\u7cfb\u7edf\u65f6\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u53d8\u91cf\u5212\u5206\uff08PoV\uff09\u65b9\u6cd5\u662f\u4e00\u79cd\u6709\u6548\u7684\u56e0\u679c\u53d1\u73b0\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u7ebf\u6027\u65f6\u4e0d\u53d8\u5fae\u5206\u4ee3\u6570\u7cfb\u7edf\uff08LTI-DAE\uff09\uff0c\u5e76\u4e14\u5728\u5904\u7406\u7eaf\u52a8\u529b\u5b66\u7cfb\u7edf\u548c\u6df7\u5408\u56e0\u679c\u7cfb\u7edf\u65f6\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002"}}
{"id": "2506.20181", "pdf": "https://arxiv.org/pdf/2506.20181", "abs": "https://arxiv.org/abs/2506.20181", "authors": ["Ronald Katende"], "title": "Causal Operator Discovery in Partial Differential Equations via Counterfactual Physics-Informed Neural Networks", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "We develop a principled framework for discovering causal structure in partial\ndifferential equations (PDEs) using physics-informed neural networks and\ncounterfactual perturbations. Unlike classical residual minimization or sparse\nregression methods, our approach quantifies operator-level necessity through\nfunctional interventions on the governing dynamics. We introduce causal\nsensitivity indices and structural deviation metrics to assess the influence of\ncandidate differential operators within neural surrogates. Theoretically, we\nprove exact recovery of the causal operator support under restricted isometry\nor mutual coherence conditions, with residual bounds guaranteeing\nidentifiability. Empirically, we validate the framework on both synthetic and\nreal-world datasets across climate dynamics, tumor diffusion, and ocean flows.\nOur method consistently recovers governing operators even under noise,\nredundancy, and data scarcity, outperforming standard PINNs and DeepONets in\nstructural fidelity. This work positions causal PDE discovery as a tractable\nand interpretable inference task grounded in structural causal models and\nvariational residual analysis.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u548c\u53cd\u4e8b\u5b9e\u6270\u52a8\u53d1\u73b0\u504f\u5fae\u5206\u65b9\u7a0b\u56e0\u679c\u7ed3\u6784\u7684\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u529f\u80fd\u5e72\u9884\u91cf\u5316\u7b97\u5b50\u7ea7\u522b\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u5f15\u5165\u56e0\u679c\u654f\u611f\u6307\u6570\u548c\u7ed3\u6784\u504f\u5dee\u5ea6\u91cf\u6765\u8bc4\u4f30\u5019\u9009\u5fae\u5206\u7b97\u5b50\u7684\u5f71\u54cd\u3002\u7406\u8bba\u4e0a\uff0c\u8bc1\u660e\u4e86\u5728\u9650\u5236\u7b49\u8ddd\u6216\u4e92\u76f8\u5173\u6761\u4ef6\u4e0b\u80fd\u591f\u7cbe\u786e\u6062\u590d\u56e0\u679c\u7b97\u5b50\u652f\u6301\uff0c\u5e76\u4fdd\u8bc1\u53ef\u8bc6\u522b\u6027\u3002\u5b9e\u8bc1\u4e0a\uff0c\u5728\u6c14\u5019\u52a8\u529b\u5b66\u3001\u80bf\u7624\u6269\u6563\u548c\u6d77\u6d0b\u6d41\u52a8\u7b49\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u566a\u58f0\u3001\u5197\u4f59\u548c\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u51c6\u786e\u6062\u590d\u63a7\u5236\u7b97\u5b50\uff0c\u4f18\u4e8e\u6807\u51c6PINNs\u548cDeepONets\u3002", "motivation": "\u73b0\u6709\u7684\u6b8b\u5dee\u6700\u5c0f\u5316\u6216\u7a00\u758f\u56de\u5f52\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u91cf\u5316\u504f\u5fae\u5206\u65b9\u7a0b\u4e2d\u7b97\u5b50\u7ea7\u522b\u7684\u5fc5\u8981\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u53d1\u73b0PDE\u4e2d\u7684\u56e0\u679c\u7ed3\u6784\u3002", "method": "\u5229\u7528\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u548c\u53cd\u4e8b\u5b9e\u6270\u52a8\u6784\u5efa\u4e00\u4e2a\u539f\u5219\u6027\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u529f\u80fd\u5e72\u9884\u91cf\u5316\u7b97\u5b50\u7ea7\u522b\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u5f15\u5165\u56e0\u679c\u654f\u611f\u6307\u6570\u548c\u7ed3\u6784\u504f\u5dee\u5ea6\u91cf\u6765\u8bc4\u4f30\u5019\u9009\u5fae\u5206\u7b97\u5b50\u7684\u5f71\u54cd\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u5373\u4f7f\u5728\u566a\u58f0\u3001\u5197\u4f59\u548c\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u4e00\u81f4\u5730\u6062\u590d\u63a7\u5236\u7b97\u5b50\uff0c\u4e14\u5728\u7ed3\u6784\u4fdd\u771f\u5ea6\u65b9\u9762\u4f18\u4e8e\u6807\u51c6PINNs\u548cDeepONets\u3002", "conclusion": "\u63d0\u51fa\u7684\u56e0\u679cPDE\u53d1\u73b0\u65b9\u6cd5\u662f\u4e00\u79cd\u53ef\u884c\u4e14\u53ef\u89e3\u91ca\u7684\u63a8\u7406\u4efb\u52a1\uff0c\u57fa\u4e8e\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u548c\u53d8\u5206\u6b8b\u5dee\u5206\u6790\uff0c\u4e3a\u53d1\u73b0PDE\u56e0\u679c\u7ed3\u6784\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2506.20194", "pdf": "https://arxiv.org/pdf/2506.20194", "abs": "https://arxiv.org/abs/2506.20194", "authors": ["Ruokai Yin", "Yuhang Li", "Donghyun Lee", "Priyadarshini Panda"], "title": "DuoGPT: Training-free Dual Sparsity through Activation-aware Pruning in LLMs", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) deliver strong performance but are difficult to\ndeploy due to high memory and compute costs. While pruning reduces these\ndemands, most methods ignore activation sparsity observed at runtime. We\nreinterpret activation sparsity as dynamic structured weight sparsity and\npropose DuoGPT, a unified framework that constructs dual-sparse (spMspV)\nworkloads by combining unstructured weight pruning with activation sparsity. To\npreserve accuracy, we extend the Optimal Brain Compression (OBC) framework with\nactivation-aware calibration and introduce output residuals from the dense\nmodel as correction terms. We further optimize the solution for efficient GPU\nexecution, enabling scalability to billion-parameter LLMs. Evaluations on\nLLaMA-2 and LLaMA-3 show that DuoGPT outperforms state-of-the-art structured\npruning methods by up to 9.17% accuracy at an iso-speedup of 1.39$\\times$\ncompared to the baseline dense model.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c3d\u7ba1\u6027\u80fd\u5f3a\u5927\uff0c\u4f46\u56e0\u9ad8\u5185\u5b58\u548c\u8ba1\u7b97\u6210\u672c\u96be\u4ee5\u90e8\u7f72\u3002\u867d\u7136\u526a\u679d\u53ef\u4ee5\u51cf\u5c11\u8fd9\u4e9b\u9700\u6c42\uff0c\u4f46\u5927\u591a\u6570\u65b9\u6cd5\u5ffd\u7565\u4e86\u8fd0\u884c\u65f6\u7684\u6fc0\u6d3b\u7a00\u758f\u6027\u3002\u672c\u6587\u5c06\u6fc0\u6d3b\u7a00\u758f\u6027\u91cd\u65b0\u89e3\u91ca\u4e3a\u52a8\u6001\u7ed3\u6784\u5316\u7684\u6743\u91cd\u7a00\u758f\u6027\uff0c\u5e76\u63d0\u51fa\u4e86DuoGPT\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u975e\u7ed3\u6784\u5316\u6743\u91cd\u526a\u679d\u4e0e\u6fc0\u6d3b\u7a00\u758f\u6027\u6784\u5efa\u53cc\u91cd\u7a00\u758f\u5de5\u4f5c\u8d1f\u8f7d\u3002\u4e3a\u4e86\u4fdd\u6301\u7cbe\u5ea6\uff0c\u6269\u5c55\u4e86\u6700\u4f18\u5927\u8111\u538b\u7f29\uff08OBC\uff09\u6846\u67b6\uff0c\u5f15\u5165\u4e86\u6765\u81ea\u5bc6\u96c6\u6a21\u578b\u7684\u8f93\u51fa\u6b8b\u5dee\u4f5c\u4e3a\u6821\u6b63\u9879\u3002\u8fdb\u4e00\u6b65\u4f18\u5316\u4e86\u89e3\u51b3\u65b9\u6848\u4ee5\u5b9e\u73b0\u9ad8\u6548\u7684GPU\u6267\u884c\uff0c\u4f7f\u5f97\u80fd\u591f\u6269\u5c55\u5230\u5341\u4ebf\u53c2\u6570\u7ea7\u522b\u7684LLMs\u3002\u5728LLaMA-2\u548cLLaMA-3\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cDuoGPT\u5728\u4fdd\u63011.39\u500d\u52a0\u901f\u7684\u540c\u65f6\uff0c\u6bd4\u73b0\u6709\u7684\u6700\u4f73\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\u63d0\u9ad8\u4e86\u591a\u8fbe9.17%\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u6027\u80fd\u5f3a\u5927\uff0c\u4f46\u5176\u9ad8\u5185\u5b58\u548c\u8ba1\u7b97\u6210\u672c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5e7f\u6cdb\u90e8\u7f72\u3002\u4f20\u7edf\u7684\u526a\u679d\u65b9\u6cd5\u867d\u80fd\u51cf\u5c11\u8d44\u6e90\u9700\u6c42\uff0c\u4f46\u672a\u80fd\u5145\u5206\u5229\u7528\u8fd0\u884c\u65f6\u7684\u6fc0\u6d3b\u7a00\u758f\u6027\u8fd9\u4e00\u7279\u6027\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u56e2\u961f\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u540c\u65f6\u5229\u7528\u6743\u91cd\u526a\u679d\u548c\u6fc0\u6d3b\u7a00\u758f\u6027\u6765\u964d\u4f4e\u6a21\u578b\u7684\u8d44\u6e90\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDuoGPT\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u975e\u7ed3\u6784\u5316\u6743\u91cd\u526a\u679d\u4e0e\u6fc0\u6d3b\u7a00\u758f\u6027\u6784\u5efa\u53cc\u91cd\u7a00\u758f\u5de5\u4f5c\u8d1f\u8f7d\u3002\u5177\u4f53\u800c\u8a00\uff0c\u7814\u7a76\u56e2\u961f\u5c06\u6fc0\u6d3b\u7a00\u758f\u6027\u91cd\u65b0\u5b9a\u4e49\u4e3a\u52a8\u6001\u7ed3\u6784\u5316\u7684\u6743\u91cd\u7a00\u758f\u6027\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u786e\u4fdd\u6a21\u578b\u7cbe\u5ea6\u4e0d\u4e0b\u964d\uff0c\u4ed6\u4eec\u6269\u5c55\u4e86\u6700\u4f18\u5927\u8111\u538b\u7f29\uff08OBC\uff09\u6846\u67b6\uff0c\u589e\u52a0\u4e86\u6fc0\u6d3b\u611f\u77e5\u6821\u51c6\u6b65\u9aa4\uff0c\u5e76\u5f15\u5165\u4e86\u6765\u81ea\u5bc6\u96c6\u6a21\u578b\u7684\u8f93\u51fa\u6b8b\u5dee\u4f5c\u4e3a\u6821\u6b63\u9879\u3002\u6700\u540e\uff0c\u9488\u5bf9\u9ad8\u6548\u7684GPU\u6267\u884c\u8fdb\u884c\u4e86\u4f18\u5316\uff0c\u4f7f\u8be5\u65b9\u6cd5\u80fd\u591f\u6269\u5c55\u5230\u5177\u6709\u6570\u5341\u4ebf\u53c2\u6570\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5728LLaMA-2\u548cLLaMA-3\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDuoGPT\u5728\u4fdd\u63011.39\u500d\u52a0\u901f\u7684\u60c5\u51b5\u4e0b\uff0c\u76f8\u6bd4\u57fa\u7ebf\u5bc6\u96c6\u6a21\u578b\uff0c\u51c6\u786e\u7387\u63d0\u5347\u4e86\u9ad8\u8fbe9.17%\uff0c\u5e76\u4e14\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\u3002", "conclusion": "DuoGPT\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u975e\u7ed3\u6784\u5316\u6743\u91cd\u526a\u679d\u548c\u6fc0\u6d3b\u7a00\u758f\u6027\uff0c\u6210\u529f\u964d\u4f4e\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6027\u80fd\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u5728\u8d44\u6e90\u6548\u7387\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u800c\u4e14\u5728\u5927\u89c4\u6a21\u6a21\u578b\u7684\u5e94\u7528\u4e2d\u5c55\u73b0\u4e86\u5de8\u5927\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u9ad8\u6548\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2506.20197", "pdf": "https://arxiv.org/pdf/2506.20197", "abs": "https://arxiv.org/abs/2506.20197", "authors": ["Cl\u00e9ment L. Canonne", "Yash Pote", "Uddalok Sarkar"], "title": "Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 4 figures", "summary": "A growing fraction of all code is sampled from Large Language Models (LLMs).\nWe investigate the problem of attributing code generated by language models\nusing hypothesis testing to leverage established techniques and guarantees.\nGiven a set of samples $S$ and a suspect model $\\mathcal{L}^*$, our goal is to\nassess the likelihood of $S$ originating from $\\mathcal{L}^*$. Due to the curse\nof dimensionality, this is intractable when only samples from the LLM are\ngiven: to circumvent this, we use both samples and density estimates from the\nLLM, a form of access commonly available.\n  We introduce $\\mathsf{Anubis}$, a zero-shot attribution tool that frames\nattribution as a distribution testing problem. Our experiments on a benchmark\nof code samples show that $\\mathsf{Anubis}$ achieves high AUROC scores (\n$\\ge0.9$) when distinguishing between LLMs like DeepSeek-Coder, CodeGemma, and\nStable-Code using only $\\approx 2000$ samples.", "AI": {"tldr": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u751f\u6210\u4ee3\u7801\u7684\u4f7f\u7528\u589e\u52a0\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aAnubis\u7684\u5de5\u5177\uff0c\u7528\u4e8e\u901a\u8fc7\u5047\u8bbe\u68c0\u9a8c\u6280\u672f\u6765\u5f52\u5c5e\u8fd9\u4e9b\u4ee3\u7801\u3002Anubis\u5728\u533a\u5206\u4e0d\u540cLLM\u751f\u6210\u7684\u4ee3\u7801\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u4ec5\u9700\u7ea62000\u4e2a\u6837\u672c\u5373\u53ef\u8fbe\u5230\u9ad8AUROC\u5206\u6570\uff08\u22650.9\uff09\u3002", "motivation": "\u8d8a\u6765\u8d8a\u591a\u7684\u4ee3\u7801\u6765\u81ea\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u5f52\u5c5e\u8fd9\u4e9b\u4ee3\u7801\u7684\u6765\u6e90\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aAnubis\u7684\u96f6\u6837\u672c\u5f52\u5c5e\u5de5\u5177\uff0c\u5c06\u5f52\u5c5e\u95ee\u9898\u8f6c\u5316\u4e3a\u5206\u5e03\u6d4b\u8bd5\u95ee\u9898\uff0c\u5e76\u5229\u7528\u5047\u8bbe\u68c0\u9a8c\u6280\u672f\u548c\u6765\u81eaLLM\u7684\u6837\u672c\u4e0e\u5bc6\u5ea6\u4f30\u8ba1\u3002", "result": "\u5728\u4ee3\u7801\u6837\u672c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAnubis\u80fd\u591f\u4ee5\u9ad8AUROC\u5206\u6570\uff08\u22650.9\uff09\u533a\u5206\u4e0d\u540c\u7684LLM\u751f\u6210\u7684\u4ee3\u7801\uff0c\u5982DeepSeek-Coder\u3001CodeGemma\u548cStable-Code\u3002", "conclusion": "Anubis\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5f52\u5c5e\u7531LLM\u751f\u6210\u7684\u4ee3\u7801\uff0c\u4ec5\u9700\u5c11\u91cf\u6837\u672c\u5373\u53ef\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u3002"}}
{"id": "2506.20204", "pdf": "https://arxiv.org/pdf/2506.20204", "abs": "https://arxiv.org/abs/2506.20204", "authors": ["Eduardo Gutierrez Maestro", "Hadi Banaee", "Amy Loutfi"], "title": "Affective Priming Score: A Data-Driven Method to Detect Priming in Sequential Datasets", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Affective priming exemplifies the challenge of ambiguity in affective\ncomputing. While the community has largely addressed this issue from a\nlabel-based perspective, identifying data points in the sequence affected by\nthe priming effect, the impact of priming on data itself, particularly in\nphysiological signals, remains underexplored. Data affected by priming can lead\nto misclassifications when used in learning models. This study proposes the\nAffective Priming Score (APS), a data-driven method to detect data points\ninfluenced by the priming effect. The APS assigns a score to each data point,\nquantifying the extent to which it is affected by priming. To validate this\nmethod, we apply it to the SEED and SEED-VII datasets, which contain sufficient\ntransitions between emotional events to exhibit priming effects. We train\nmodels with the same configuration using both the original data and\npriming-free sequences. The misclassification rate is significantly reduced\nwhen using priming-free sequences compared to the original data. This work\ncontributes to the broader challenge of ambiguity by identifying and mitigating\npriming effects at the data level, enhancing model robustness, and offering\nvaluable insights for the design and collection of affective computing\ndatasets.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u60c5\u611f\u542f\u52a8\u8bc4\u5206\uff08APS\uff09\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u7528\u4e8e\u68c0\u6d4b\u53d7\u542f\u52a8\u6548\u5e94\u5f71\u54cd\u7684\u6570\u636e\u70b9\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u8bc1\u660e\u53bb\u9664\u542f\u52a8\u6548\u5e94\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u6a21\u578b\u7684\u8bef\u5206\u7c7b\u7387\u3002", "motivation": "\u5f53\u524d\u60c5\u611f\u8ba1\u7b97\u9886\u57df\u4e3b\u8981\u4ece\u57fa\u4e8e\u6807\u7b7e\u7684\u89d2\u5ea6\u89e3\u51b3\u6a21\u7cca\u6027\u95ee\u9898\uff0c\u4f46\u5bf9\u4e8e\u6570\u636e\u672c\u8eab\uff08\u7279\u522b\u662f\u751f\u7406\u4fe1\u53f7\uff09\u53d7\u542f\u52a8\u6548\u5e94\u7684\u5f71\u54cd\u7814\u7a76\u4e0d\u8db3\uff0c\u53ef\u80fd\u5bfc\u81f4\u5b66\u4e60\u6a21\u578b\u4e2d\u7684\u8bef\u5206\u7c7b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u2014\u2014\u60c5\u611f\u542f\u52a8\u8bc4\u5206\uff08APS\uff09\uff0c\u4e3a\u6bcf\u4e2a\u6570\u636e\u70b9\u5206\u914d\u4e00\u4e2a\u5206\u6570\uff0c\u4ee5\u91cf\u5316\u5176\u53d7\u542f\u52a8\u6548\u5e94\u5f71\u54cd\u7684\u7a0b\u5ea6\u3002\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8eSEED\u548cSEED-VII\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u76f8\u540c\u914d\u7f6e\u8bad\u7ec3\u6a21\u578b\uff0c\u6bd4\u8f83\u539f\u59cb\u6570\u636e\u548c\u65e0\u542f\u52a8\u5e8f\u5217\u7684\u6548\u679c\u3002", "result": "\u4f7f\u7528\u65e0\u542f\u52a8\u5e8f\u5217\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u65f6\uff0c\u76f8\u6bd4\u4f7f\u7528\u539f\u59cb\u6570\u636e\uff0c\u8bef\u5206\u7c7b\u7387\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u8bc6\u522b\u548c\u51cf\u8f7b\u6570\u636e\u5c42\u9762\u7684\u542f\u52a8\u6548\u5e94\uff0c\u6709\u52a9\u4e8e\u5e94\u5bf9\u60c5\u611f\u8ba1\u7b97\u4e2d\u7684\u6a21\u7cca\u6027\u6311\u6218\uff0c\u63d0\u5347\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u4e3a\u60c5\u611f\u8ba1\u7b97\u6570\u636e\u96c6\u7684\u8bbe\u8ba1\u548c\u6536\u96c6\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.20235", "pdf": "https://arxiv.org/pdf/2506.20235", "abs": "https://arxiv.org/abs/2506.20235", "authors": ["Yuyang Zhang", "Xu Shen", "Yu Xie", "Ka-Chun Wong", "Weidun Xie", "Chengbin Peng"], "title": "Directed Link Prediction using GNN with Local and Global Feature Fusion", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Link prediction is a classical problem in graph analysis with many practical\napplications. For directed graphs, recently developed deep learning approaches\ntypically analyze node similarities through contrastive learning and aggregate\nneighborhood information through graph convolutions. In this work, we propose a\nnovel graph neural network (GNN) framework to fuse feature embedding with\ncommunity information. We theoretically demonstrate that such hybrid features\ncan improve the performance of directed link prediction. To utilize such\nfeatures efficiently, we also propose an approach to transform input graphs\ninto directed line graphs so that nodes in the transformed graph can aggregate\nmore information during graph convolutions. Experiments on benchmark datasets\nshow that our approach outperforms the state-of-the-art in most cases when 30%,\n40%, 50%, and 60% of the connected links are used as training data,\nrespectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684GNN\u6846\u67b6\uff0c\u878d\u5408\u7279\u5f81\u5d4c\u5165\u4e0e\u793e\u533a\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u5c06\u8f93\u5165\u56fe\u8f6c\u6362\u4e3a\u6709\u5411\u7ebf\u56fe\u6765\u63d0\u5347\u94fe\u63a5\u9884\u6d4b\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4f7f\u752830%-60%\u8fde\u63a5\u94fe\u8def\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\u65f6\uff0c\u8be5\u65b9\u6cd5\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u5206\u6790\u8282\u70b9\u76f8\u4f3c\u6027\uff0c\u5e76\u901a\u8fc7\u56fe\u5377\u79ef\u805a\u5408\u90bb\u57df\u4fe1\u606f\uff0c\u4f46\u672a\u5145\u5206\u7ed3\u5408\u7279\u5f81\u5d4c\u5165\u548c\u793e\u533a\u4fe1\u606f\u5bf9\u6709\u5411\u56fe\u94fe\u63a5\u9884\u6d4b\u7684\u5f71\u54cd\u3002", "method": "1. \u63d0\u51fa\u4e00\u79cd\u65b0\u7684GNN\u6846\u67b6\uff0c\u5c06\u7279\u5f81\u5d4c\u5165\u4e0e\u793e\u533a\u4fe1\u606f\u76f8\u878d\u5408\u3002\n2. \u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u6df7\u5408\u7279\u5f81\u5bf9\u6709\u5411\u94fe\u63a5\u9884\u6d4b\u6027\u80fd\u7684\u63d0\u5347\u4f5c\u7528\u3002\n3. \u63d0\u51fa\u4e00\u79cd\u65b9\u6cd5\uff0c\u5c06\u8f93\u5165\u56fe\u8f6c\u6362\u4e3a\u6709\u5411\u7ebf\u56fe\uff0c\u4ee5\u4f7f\u8282\u70b9\u5728\u56fe\u5377\u79ef\u8fc7\u7a0b\u4e2d\u80fd\u805a\u5408\u66f4\u591a\u4fe1\u606f\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u5206\u522b\u4f7f\u752830%\u300140%\u300150%\u548c60%\u7684\u8fde\u63a5\u94fe\u8def\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\u65f6\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u3002", "conclusion": "\u878d\u5408\u7279\u5f81\u5d4c\u5165\u4e0e\u793e\u533a\u4fe1\u606f\u7684GNN\u6846\u67b6\u4ee5\u53ca\u5c06\u8f93\u5165\u56fe\u8f6c\u6362\u4e3a\u6709\u5411\u7ebf\u56fe\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u6709\u5411\u94fe\u63a5\u9884\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.20245", "pdf": "https://arxiv.org/pdf/2506.20245", "abs": "https://arxiv.org/abs/2506.20245", "authors": ["Yushan Zhao", "Jinyuan He", "Donglai Chen", "Weijie Luo", "Chong Xie", "Ri Zhang", "Yonghong Chen", "Yan Xu"], "title": "FedBKD: Distilled Federated Learning to Embrace Gerneralization and Personalization on Non-IID Data", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Federated learning (FL) is a decentralized collaborative machine learning\n(ML) technique. It provides a solution to the issues of isolated data islands\nand data privacy leakage in industrial ML practices. One major challenge in FL\nis handling the non-identical and independent distributed (non-IID) data.\nCurrent solutions either focus on constructing an all-powerful global model, or\ncustomizing personalized local models. Few of them can provide both a\nwell-generalized global model and well-performed local models at the same time.\nAdditionally, many FL solutions to the non-IID problem are benefited from\nintroducing public datasets. However, this will also increase the risk of data\nleakage. To tackle the problems, we propose a novel data-free distillation\nframework, Federated Bidirectional Knowledge Distillation (FedBKD).\nSpecifically, we train Generative Adversarial Networks (GAN) for synthetic\ndata. During the GAN training, local models serve as discriminators and their\nparameters are frozen. The synthetic data is then used for bidirectional\ndistillation between global and local models to achieve knowledge interactions\nso that performances for both sides are improved. We conduct extensive\nexperiments on 4 benchmarks under different non-IID settings. The results show\nthat FedBKD achieves SOTA performances in every case.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65e0\u9700\u6570\u636e\u7684\u84b8\u998f\u6846\u67b6FedBKD\uff0c\u89e3\u51b3\u4e86\u8054\u90a6\u5b66\u4e60\u4e2dnon-IID\u6570\u636e\u7684\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u5168\u5c40\u548c\u672c\u5730\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u9762\u4e34non-IID\u6570\u636e\u5904\u7406\u3001\u5168\u5c40\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u4ee5\u53ca\u672c\u5730\u6a21\u578b\u6027\u80fd\u63d0\u5347\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u540c\u65f6\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u4e14\u5f15\u5165\u516c\u5171\u6570\u636e\u96c6\u589e\u52a0\u4e86\u6570\u636e\u6cc4\u9732\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86Federated Bidirectional Knowledge Distillation (FedBKD)\u6846\u67b6\uff0c\u5229\u7528\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff08GAN\uff09\u5408\u6210\u6570\u636e\u8fdb\u884c\u53cc\u5411\u84b8\u998f\uff0c\u901a\u8fc7\u51bb\u7ed3\u672c\u5730\u6a21\u578b\u53c2\u6570\u4f5c\u4e3a\u5224\u522b\u5668\uff0c\u5b9e\u73b0\u5168\u5c40\u4e0e\u672c\u5730\u6a21\u578b\u4e4b\u95f4\u7684\u77e5\u8bc6\u4ea4\u4e92\u3002", "result": "\u57284\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u7684\u4e0d\u540cnon-IID\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660eFedBKD\u5728\u6bcf\u79cd\u60c5\u51b5\u4e0b\u90fd\u8fbe\u5230\u4e86\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "FedBKD\u6846\u67b6\u65e0\u9700\u516c\u5171\u6570\u636e\u96c6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u5168\u5c40\u548c\u672c\u5730\u6a21\u578b\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4e86non-IID\u6570\u636e\u5e26\u6765\u7684\u6311\u6218\u3002"}}
{"id": "2506.20251", "pdf": "https://arxiv.org/pdf/2506.20251", "abs": "https://arxiv.org/abs/2506.20251", "authors": ["Kejia Chen", "Jiawen Zhang", "Jiacong Hu", "Yu Wang", "Jian Lou", "Zunlei Feng", "Mingli Song"], "title": "Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "Quantized large language models (LLMs) have gained increasing attention and\nsignificance for enabling deployment in resource-constrained environments.\nHowever, emerging studies on a few calibration dataset-free quantization\nmethods suggest that quantization may compromise the safety capabilities of\nLLMs, underscoring the urgent need for systematic safety evaluations and\neffective mitigation strategies. In this paper, we present comprehensive safety\nevaluations across various mainstream quantization techniques and diverse\ncalibration datasets, utilizing widely accepted safety benchmarks. To address\nthe identified safety vulnerabilities, we propose a quantization-aware safety\npatching framework, Q-resafe, to efficiently restore the safety capabilities of\nquantized LLMs while minimizing any adverse impact on utility. Extensive\nexperimental results demonstrate that Q-resafe successfully re-aligns the\nsafety of quantized LLMs with their pre-quantization counterparts, even under\nchallenging evaluation scenarios. Project page is available at:\nhttps://github.com/Thecommonirin/Qresafe.", "AI": {"tldr": "\u91cf\u5316\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72\u7684\u91cd\u8981\u6027\u65e5\u76ca\u63d0\u5347\uff0c\u4f46\u5176\u5b89\u5168\u6027\u53ef\u80fd\u56e0\u91cf\u5316\u8fc7\u7a0b\u800c\u53d7\u5230\u635f\u5bb3\u3002\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u4e3b\u6d41\u91cf\u5316\u6280\u672f\u7684\u5b89\u5168\u6027\uff0c\u5e76\u63d0\u51faQ-resafe\u6846\u67b6\u4ee5\u6062\u590d\u91cf\u5316LLM\u7684\u5b89\u5168\u80fd\u529b\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u5bf9\u6548\u7528\u7684\u5f71\u54cd\u3002\u5b9e\u9a8c\u8868\u660e\uff0cQ-resafe\u80fd\u6709\u6548\u6062\u590d\u91cf\u5316LLM\u7684\u5b89\u5168\u6027\u81f3\u91cf\u5316\u524d\u6c34\u5e73\u3002", "motivation": "\u91cf\u5316LLMs\u6709\u52a9\u4e8e\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u90e8\u7f72\uff0c\u7136\u800c\u4e00\u4e9b\u65e0\u9700\u6821\u51c6\u6570\u636e\u96c6\u7684\u91cf\u5316\u65b9\u6cd5\u53ef\u80fd\u4f1a\u524a\u5f31LLMs\u7684\u5b89\u5168\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u8fdb\u884c\u7cfb\u7edf\u7684\u5b89\u5168\u8bc4\u4f30\u5e76\u5f00\u53d1\u6709\u6548\u7684\u7f13\u89e3\u7b56\u7565\u3002", "method": "\u7814\u7a76\u8005\u4eec\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5b89\u5168\u8bc4\u4f30\uff0c\u6db5\u76d6\u591a\u79cd\u4e3b\u6d41\u91cf\u5316\u6280\u672f\u548c\u4e0d\u540c\u7684\u6821\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528\u5e7f\u6cdb\u8ba4\u53ef\u7684\u5b89\u5168\u57fa\u51c6\u3002\u57fa\u4e8e\u6b64\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u91cf\u5316\u611f\u77e5\u7684\u5b89\u5168\u4fee\u8865\u6846\u67b6Q-resafe\uff0c\u65e8\u5728\u9ad8\u6548\u6062\u590d\u91cf\u5316LLM\u7684\u5b89\u5168\u80fd\u529b\uff0c\u540c\u65f6\u5c3d\u91cf\u51cf\u5c11\u5bf9\u5176\u5b9e\u7528\u6027\u7684\u5f71\u54cd\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\uff0cQ-resafe\u80fd\u591f\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u8bc4\u4f30\u573a\u666f\u4e0b\uff0c\u6210\u529f\u4f7f\u91cf\u5316LLM\u7684\u5b89\u5168\u6027\u91cd\u65b0\u4e0e\u91cf\u5316\u524d\u7684\u6c34\u5e73\u5bf9\u9f50\u3002", "conclusion": "Q-resafe\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6062\u590d\u91cf\u5316LLM\u7684\u5b89\u5168\u6027\u80fd\uff0c\u540c\u65f6\u786e\u4fdd\u5176\u6548\u7528\u4e0d\u53d7\u663e\u8457\u5f71\u54cd\uff0c\u8fd9\u5bf9\u4e8e\u63a8\u52a8\u5b89\u5168\u4e14\u9ad8\u6548\u7684\u91cf\u5316LLM\u90e8\u7f72\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2506.20253", "pdf": "https://arxiv.org/pdf/2506.20253", "abs": "https://arxiv.org/abs/2506.20253", "authors": ["Ben Gerhards", "Nikita Popkov", "Annekatrin K\u00f6nig", "Marcel Arpogaus", "Bastian Sch\u00e4fermeier", "Leonie Riedl", "Stephan Vogt", "Philip Hehlert"], "title": "Time-series surrogates from energy consumers generated by machine learning approaches for long-term forecasting scenarios", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Forecasting attracts a lot of research attention in the electricity value\nchain. However, most studies concentrate on short-term forecasting of\ngeneration or consumption with a focus on systems and less on individual\nconsumers. Even more neglected is the topic of long-term forecasting of\nindividual power consumption.\n  Here, we provide an in-depth comparative evaluation of data-driven methods\nfor generating synthetic time series data tailored to energy consumption\nlong-term forecasting. High-fidelity synthetic data is crucial for a wide range\nof applications, including state estimations in energy systems or power grid\nplanning. In this study, we assess and compare the performance of multiple\nstate-of-the-art but less common techniques: a hybrid Wasserstein Generative\nAdversarial Network (WGAN), Denoising Diffusion Probabilistic Model (DDPM),\nHidden Markov Model (HMM), and Masked Autoregressive Bernstein polynomial\nnormalizing Flows (MABF). We analyze the ability of each method to replicate\nthe temporal dynamics, long-range dependencies, and probabilistic transitions\ncharacteristic of individual energy consumption profiles. Our comparative\nevaluation highlights the strengths and limitations of: WGAN, DDPM, HMM and\nMABF aiding in selecting the most suitable approach for state estimations and\nother energy-related tasks. Our generation and analysis framework aims to\nenhance the accuracy and reliability of synthetic power consumption data while\ngenerating data that fulfills criteria like anonymisation - preserving privacy\nconcerns mitigating risks of specific profiling of single customers. This study\nutilizes an open-source dataset from households in Germany with 15min time\nresolution. The generated synthetic power profiles can readily be used in\napplications like state estimations or consumption forecasting.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u6df1\u5165\u8bc4\u4f30\u4e86\u7528\u4e8e\u957f\u671f\u4e2a\u4f53\u7535\u529b\u6d88\u8017\u9884\u6d4b\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u5305\u62ecWGAN\u3001DDPM\u3001HMM\u548cMABF\u7b49\u6280\u672f\uff0c\u4ee5\u751f\u6210\u9ad8\u4fdd\u771f\u7684\u5408\u6210\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002", "motivation": "\u76ee\u524d\u5927\u591a\u6570\u7814\u7a76\u96c6\u4e2d\u4e8e\u77ed\u671f\u53d1\u7535\u6216\u6d88\u8d39\u9884\u6d4b\uff0c\u4e14\u66f4\u591a\u5173\u6ce8\u7cfb\u7edf\u800c\u975e\u4e2a\u4eba\u6d88\u8d39\u8005\u3002\u800c\u9488\u5bf9\u957f\u671f\u4e2a\u4eba\u7535\u529b\u6d88\u8017\u9884\u6d4b\u7684\u7814\u7a76\u76f8\u5bf9\u8f83\u5c11\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5bf9\u6bd4\u591a\u79cd\u5148\u8fdb\u7684\u6570\u636e\u751f\u6210\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u4e86\u56db\u79cd\u5148\u8fdb\u6280\u672f\uff1aWGAN\uff08\u6df7\u5408Wasserstein\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff09\u3001DDPM\uff08\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\uff09\u3001HMM\uff08\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff09\u548cMABF\uff08\u57fa\u4e8e\u63a9\u7801\u81ea\u56de\u5f52Bernstein\u591a\u9879\u5f0f\u6d41\u7684\u5f52\u4e00\u5316\u6d41\uff09\u3002\u8fd9\u4e9b\u65b9\u6cd5\u88ab\u7528\u6765\u751f\u6210\u7b26\u5408\u4e2a\u4f53\u80fd\u6e90\u6d88\u8017\u7279\u5f81\u7684\u5408\u6210\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u5e76\u5206\u6790\u5176\u5bf9\u65f6\u95f4\u52a8\u6001\u3001\u957f\u7a0b\u4f9d\u8d56\u6027\u548c\u6982\u7387\u8f6c\u6362\u7684\u590d\u5236\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u5bf9\u5fb7\u56fd15\u5206\u949f\u5206\u8fa8\u7387\u7684\u5bb6\u5ead\u516c\u5f00\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e86\u5404\u65b9\u6cd5\u5728\u751f\u6210\u9ad8\u4fdd\u771f\u5408\u6210\u6570\u636e\u65b9\u9762\u7684\u6027\u80fd\uff0c\u63ed\u793a\u4e86\u6bcf\u79cd\u65b9\u6cd5\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u751f\u6210\u548c\u5206\u6790\u6846\u67b6\uff0c\u53ef\u4ee5\u63d0\u9ad8\u5408\u6210\u7535\u529b\u6d88\u8017\u6570\u636e\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u540c\u65f6\u6ee1\u8db3\u533f\u540d\u5316\u9700\u6c42\u4ee5\u4fdd\u62a4\u9690\u79c1\u3002\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u72b6\u6001\u4f30\u8ba1\u6216\u6d88\u8d39\u9884\u6d4b\u7b49\u76f8\u5173\u4efb\u52a1\u3002"}}
{"id": "2506.20260", "pdf": "https://arxiv.org/pdf/2506.20260", "abs": "https://arxiv.org/abs/2506.20260", "authors": ["Junqi Jiang", "Antonio Rago", "Francesco Leofante", "Francesca Toni"], "title": "Argumentative Ensembling for Robust Recourse under Model Multiplicity", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": "arXiv admin note: substantial text overlap with arXiv:2312.15097", "summary": "In machine learning, it is common to obtain multiple equally performing\nmodels for the same prediction task, e.g., when training neural networks with\ndifferent random seeds. Model multiplicity (MM) is the situation which arises\nwhen these competing models differ in their predictions for the same input, for\nwhich ensembling is often employed to determine an aggregation of the outputs.\nProviding recourse recommendations via counterfactual explanations (CEs) under\nMM thus becomes complex, since the CE may not be valid across all models, i.e.,\nthe CEs are not robust under MM. In this work, we formalise the problem of\nproviding recourse under MM, which we name recourse-aware ensembling (RAE). We\npropose the idea that under MM, CEs for each individual model should be\nconsidered alongside their predictions so that the aggregated prediction and\nrecourse are decided in tandem. Centred around this intuition, we introduce six\ndesirable properties for solutions to this problem. For solving RAE, we propose\na novel argumentative ensembling method which guarantees the robustness of CEs\nunder MM. Specifically, our method leverages computational argumentation to\nexplicitly represent the conflicts between models and counterfactuals regarding\nprediction results and CE validity. It then uses argumentation semantics to\nresolve the conflicts and obtain the final solution, in a manner which is\nparametric to the chosen semantics. Our method also allows for the\nspecification of preferences over the models under MM, allowing further\ncustomisation of the ensemble. In a comprehensive theoretical analysis, we\ncharacterise the behaviour of argumentative ensembling with four different\nargumentation semantics. We then empirically demonstrate the effectiveness of\nour approach in satisfying desirable properties with eight instantiations of\nour method. (Abstract is shortened for arXiv.)", "AI": {"tldr": "\u5728\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u5bf9\u4e8e\u76f8\u540c\u7684\u9884\u6d4b\u4efb\u52a1\uff0c\u901a\u5e38\u4f1a\u5f97\u5230\u591a\u4e2a\u6027\u80fd\u76f8\u5f53\u7684\u6a21\u578b\uff08\u4f8b\u5982\u4f7f\u7528\u4e0d\u540c\u7684\u968f\u673a\u79cd\u5b50\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\uff09\u3002\u5f53\u8fd9\u4e9b\u7ade\u4e89\u6a21\u578b\u5bf9\u76f8\u540c\u8f93\u5165\u7684\u9884\u6d4b\u7ed3\u679c\u4e0d\u540c\u65f6\uff0c\u5c31\u4f1a\u51fa\u73b0\u6a21\u578b\u591a\u91cd\u6027\uff08Model Multiplicity, MM\uff09\u95ee\u9898\u3002\u4e3a\u4e86\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u63d0\u4f9b\u6709\u6548\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08Counterfactual Explanations, CEs\uff09\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u5e94\u5bf9MM\u7684\u89e3\u51b3\u65b9\u6848\u2014\u2014Recourse-Aware Ensembling (RAE)\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u8bba\u8fa9\u7684\u96c6\u6210\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u663e\u5f0f\u8868\u793a\u6a21\u578b\u548c\u53cd\u4e8b\u5b9e\u4e4b\u95f4\u7684\u51b2\u7a81\uff0c\u5e76\u5229\u7528\u8bba\u8fa9\u8bed\u4e49\u89e3\u51b3\u8fd9\u4e9b\u51b2\u7a81\uff0c\u4ece\u800c\u4fdd\u8bc1\u4e86CEs\u5728MM\u4e0b\u7684\u9c81\u68d2\u6027\u3002\u6b64\u5916\uff0c\u6211\u4eec\u7684\u65b9\u6cd5\u5141\u8bb8\u5bf9MM\u4e0b\u7684\u6a21\u578b\u8fdb\u884c\u504f\u597d\u6307\u5b9a\uff0c\u4ee5\u8fdb\u4e00\u6b65\u5b9a\u5236\u96c6\u6210\u3002\u6211\u4eec\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5728\u6a21\u578b\u591a\u91cd\u6027\uff08MM\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u73b0\u6709\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\uff08CEs\uff09\u53ef\u80fd\u5e76\u4e0d\u9002\u7528\u4e8e\u6240\u6709\u6a21\u578b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u786e\u4fdd\u5728MM\u4e0b\u751f\u6210\u7684CEs\u5177\u6709\u9c81\u68d2\u6027\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86Recourse-Aware Ensembling (RAE)\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u8bba\u8fa9\u7684\u96c6\u6210\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u8ba1\u7b97\u8bba\u8fa9\u6765\u660e\u786e\u8868\u793a\u6a21\u578b\u548c\u53cd\u4e8b\u5b9e\u4e4b\u95f4\u7684\u51b2\u7a81\uff0c\u5e76\u5229\u7528\u8bba\u8fa9\u8bed\u4e49\u89e3\u51b3\u8fd9\u4e9b\u51b2\u7a81\u3002\u6700\u7ec8\u8f93\u51fa\u7684\u7ed3\u679c\u662f\u7efc\u5408\u8003\u8651\u4e86\u9884\u6d4b\u548c\u53cd\u4e8b\u5b9e\u89e3\u91ca\u540e\u7684\u89e3\u51b3\u65b9\u6848\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u8fd8\u652f\u6301\u6839\u636e\u7528\u6237\u9700\u6c42\u5bf9\u6a21\u578b\u8fdb\u884c\u504f\u597d\u8bbe\u7f6e\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u57fa\u4e8e\u8bba\u8fa9\u7684\u96c6\u6210\u65b9\u6cd5\u5728\u56db\u79cd\u4e0d\u540c\u7684\u8bba\u8fa9\u8bed\u4e49\u4e0b\u8868\u73b0\u826f\u597d\u3002\u5b9e\u9a8c\u90e8\u5206\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u516b\u4e2a\u5b9e\u4f8b\u5316\u7248\u672c\u5728\u6ee1\u8db3\u671f\u671b\u5c5e\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684Recourse-Aware Ensembling (RAE) \u65b9\u6cd5\u4e3a\u5728\u6a21\u578b\u591a\u91cd\u6027\uff08MM\uff09\u4e0b\u7684\u53cd\u4e8b\u5b9e\u89e3\u91ca\u63d0\u4f9b\u4e86\u9c81\u68d2\u6027\u4fdd\u969c\uff0c\u5e76\u4e14\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2506.20285", "pdf": "https://arxiv.org/pdf/2506.20285", "abs": "https://arxiv.org/abs/2506.20285", "authors": ["Zeqi Leng", "Chunxu Zhang", "Guodong Long", "Riting Xia", "Bo Yang"], "title": "Distilling A Universal Expert from Clustered Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Clustered Federated Learning (CFL) addresses the challenges posed by non-IID\ndata by training multiple group- or cluster-specific expert models. However,\nexisting methods often overlook the shared information across clusters, which\nrepresents the generalizable knowledge valuable to all participants in the\nFederated Learning (FL) system. To overcome this limitation, this paper\nintroduces a novel FL framework that distills a universal expert model from the\nknowledge of multiple clusters. This universal expert captures globally shared\ninformation across all clients and is subsequently distributed to each client\nas the initialization for the next round of model training. The proposed FL\nframework operates in three iterative steps: (1) local model training at each\nclient, (2) cluster-specific model aggregation, and (3) universal expert\ndistillation. This three-step learning paradigm ensures the preservation of\nfine-grained non-IID characteristics while effectively incorporating shared\nknowledge across clusters. Compared to traditional gradient-based aggregation\nmethods, the distillation-based model aggregation introduces greater\nflexibility in handling model heterogeneity and reduces conflicts among\ncluster-specific experts. Extensive experimental results demonstrate the\nsuperior performance of the proposed method across various scenarios,\nhighlighting its potential to advance the state of CFL by balancing\npersonalized and shared knowledge more effectively.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u751f\u6210\u4e00\u4e2a\u901a\u7528\u4e13\u5bb6\u6a21\u578b\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u8de8\u96c6\u7fa4\u5171\u4eab\u4fe1\u606f\u7684\u95ee\u9898\u3002\u8be5\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u8fed\u4ee3\u6b65\u9aa4\uff1a\u672c\u5730\u6a21\u578b\u8bad\u7ec3\u3001\u96c6\u7fa4\u7279\u5b9a\u6a21\u578b\u805a\u5408\u548c\u901a\u7528\u4e13\u5bb6\u84b8\u998f\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u5e73\u8861\u4e2a\u6027\u5316\u548c\u5171\u4eab\u77e5\u8bc6\u3002", "motivation": "\u73b0\u6709\u7684\u96c6\u7fa4\u8054\u90a6\u5b66\u4e60\uff08CFL\uff09\u65b9\u6cd5\u867d\u7136\u53ef\u4ee5\u5e94\u5bf9\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u6570\u636e\u7684\u6311\u6218\uff0c\u4f46\u5f80\u5f80\u5ffd\u7565\u4e86\u8de8\u96c6\u7fa4\u7684\u5171\u4eab\u4fe1\u606f\uff0c\u8fd9\u4e9b\u4fe1\u606f\u4ee3\u8868\u4e86\u5bf9\u6240\u6709\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u53c2\u4e0e\u8005\u90fd\u6709\u4ef7\u503c\u7684\u53ef\u6cdb\u5316\u77e5\u8bc6\u3002", "method": "1. \u672c\u5730\u6a21\u578b\u8bad\u7ec3\uff1a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u8fdb\u884c\u672c\u5730\u6a21\u578b\u8bad\u7ec3\u3002\n2. \u96c6\u7fa4\u7279\u5b9a\u6a21\u578b\u805a\u5408\uff1a\u5c06\u672c\u5730\u6a21\u578b\u805a\u5408\u4e3a\u96c6\u7fa4\u7279\u5b9a\u6a21\u578b\u3002\n3. \u901a\u7528\u4e13\u5bb6\u84b8\u998f\uff1a\u4ece\u591a\u4e2a\u96c6\u7fa4\u7684\u77e5\u8bc6\u4e2d\u63d0\u53d6\u901a\u7528\u4e13\u5bb6\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u5206\u53d1\u7ed9\u6bcf\u4e2a\u5ba2\u6237\u7aef\u4f5c\u4e3a\u4e0b\u4e00\u8f6e\u6a21\u578b\u8bad\u7ec3\u7684\u521d\u59cb\u5316\u3002\n\u8fd9\u79cd\u65b9\u6cd5\u4fdd\u7559\u4e86\u7ec6\u7c92\u5ea6\u7684\u975e-IID\u7279\u6027\uff0c\u540c\u65f6\u6709\u6548\u6574\u5408\u4e86\u8de8\u96c6\u7fa4\u7684\u5171\u4eab\u77e5\u8bc6\u3002", "result": "\u4e0e\u4f20\u7edf\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u805a\u5408\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u6a21\u578b\u5f02\u6784\u6027\u65b9\u9762\u5177\u6709\u66f4\u5927\u7684\u7075\u6d3b\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u96c6\u7fa4\u7279\u5b9a\u4e13\u5bb6\u4e4b\u95f4\u7684\u51b2\u7a81\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u573a\u666f\u4e0b\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u65b0\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u901a\u7528\u4e13\u5bb6\u84b8\u998f\u6b65\u9aa4\uff0c\u66f4\u6709\u6548\u5730\u5e73\u8861\u4e86\u4e2a\u6027\u5316\u548c\u5171\u4eab\u77e5\u8bc6\uff0c\u4ece\u800c\u63a8\u52a8\u4e86\u96c6\u7fa4\u8054\u90a6\u5b66\u4e60\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.20305", "pdf": "https://arxiv.org/pdf/2506.20305", "abs": "https://arxiv.org/abs/2506.20305", "authors": ["Kazuki Yoda", "Kazuhiko Kawamoto", "Hiroshi Kera"], "title": "Learning Moderately Input-Sensitive Functions: A Case Study in QR Code Decoding", "categories": ["cs.LG", "cs.CV"], "comment": "17 pages, 13 figures", "summary": "The hardness of learning a function that attains a target task relates to its\ninput-sensitivity. For example, image classification tasks are\ninput-insensitive as minor corruptions should not affect the classification\nresults, whereas arithmetic and symbolic computation, which have been recently\nattracting interest, are highly input-sensitive as each input variable connects\nto the computation results. This study presents the first learning-based Quick\nResponse (QR) code decoding and investigates learning functions of medium\nsensitivity. Our experiments reveal that Transformers can successfully decode\nQR codes, even beyond the theoretical error-correction limit, by learning the\nstructure of embedded texts. They generalize from English-rich training data to\nother languages and even random strings. Moreover, we observe that the\nTransformer-based QR decoder focuses on data bits while ignoring\nerror-correction bits, suggesting a decoding mechanism distinct from standard\nQR code readers.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8e\u5b66\u4e60\u7684QR\u7801\u89e3\u7801\uff0c\u5e76\u7814\u7a76\u4e86\u4e2d\u7b49\u654f\u611f\u5ea6\u7684\u5b66\u4e60\u51fd\u6570\u3002\u5b9e\u9a8c\u8868\u660e\uff0cTransformer\u53ef\u4ee5\u901a\u8fc7\u5b66\u4e60\u5d4c\u5165\u6587\u672c\u7684\u7ed3\u6784\u6210\u529f\u89e3\u7801QR\u7801\uff0c\u751a\u81f3\u8d85\u51fa\u7406\u8bba\u7ea0\u9519\u6781\u9650\u3002\u6b64\u5916\uff0cTransformer\u89e3\u7801\u5668\u4e3b\u8981\u5173\u6ce8\u6570\u636e\u4f4d\u800c\u5ffd\u7565\u7ea0\u9519\u4f4d\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u4e0d\u540c\u8f93\u5165\u654f\u611f\u5ea6\u4efb\u52a1\u7684\u5b66\u4e60\u7279\u6027\uff0c\u7279\u522b\u662f\u4ecb\u4e8e\u56fe\u50cf\u5206\u7c7b\uff08\u4f4e\u654f\u611f\u5ea6\uff09\u548c\u7b97\u672f/\u7b26\u53f7\u8ba1\u7b97\uff08\u9ad8\u654f\u611f\u5ea6\uff09\u4e4b\u95f4\u7684\u4efb\u52a1\uff0c\u4f8b\u5982QR\u7801\u89e3\u7801\u3002", "method": "\u4f5c\u8005\u4f7f\u7528Transformers\u8fdb\u884cQR\u7801\u89e3\u7801\uff0c\u901a\u8fc7\u5b66\u4e60\u5d4c\u5165\u6587\u672c\u7684\u7ed3\u6784\u6765\u5b9e\u73b0\u3002\u6a21\u578b\u5728\u5305\u542b\u82f1\u8bed\u4e30\u5bcc\u7684\u8bad\u7ec3\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u6d4b\u8bd5\u5176\u5bf9\u5176\u4ed6\u8bed\u8a00\u548c\u968f\u673a\u5b57\u7b26\u4e32\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "Transformer\u80fd\u591f\u6210\u529f\u89e3\u7801QR\u7801\uff0c\u5305\u62ec\u8d85\u51fa\u7406\u8bba\u7ea0\u9519\u6781\u9650\u7684\u60c5\u51b5\u3002\u6a21\u578b\u53ef\u4ee5\u6cdb\u5316\u5230\u5176\u4ed6\u8bed\u8a00\u548c\u968f\u673a\u5b57\u7b26\u4e32\uff0c\u5e76\u4e14\u66f4\u5173\u6ce8\u6570\u636e\u4f4d\u800c\u975e\u7ea0\u9519\u4f4d\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0cTransformers\u53ef\u4ee5\u6709\u6548\u5904\u7406\u4e2d\u7b49\u654f\u611f\u5ea6\u7684\u4efb\u52a1\uff0c\u5982QR\u7801\u89e3\u7801\uff0c\u5e76\u4e14\u91c7\u7528\u4e0e\u4f20\u7edf\u65b9\u6cd5\u4e0d\u540c\u7684\u673a\u5236\u3002"}}
{"id": "2506.20307", "pdf": "https://arxiv.org/pdf/2506.20307", "abs": "https://arxiv.org/abs/2506.20307", "authors": ["Heyang Zhao", "Xingrui Yu", "David M. Bossens", "Ivor W. Tsang", "Quanquan Gu"], "title": "Beyond-Expert Performance with Limited Demonstrations: Efficient Imitation Learning with Double Exploration", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Imitation learning is a central problem in reinforcement learning where the\ngoal is to learn a policy that mimics the expert's behavior. In practice, it is\noften challenging to learn the expert policy from a limited number of\ndemonstrations accurately due to the complexity of the state space. Moreover,\nit is essential to explore the environment and collect data to achieve\nbeyond-expert performance. To overcome these challenges, we propose a novel\nimitation learning algorithm called Imitation Learning with Double Exploration\n(ILDE), which implements exploration in two aspects: (1) optimistic policy\noptimization via an exploration bonus that rewards state-action pairs with high\nuncertainty to potentially improve the convergence to the expert policy, and\n(2) curiosity-driven exploration of the states that deviate from the\ndemonstration trajectories to potentially yield beyond-expert performance.\nEmpirically, we demonstrate that ILDE outperforms the state-of-the-art\nimitation learning algorithms in terms of sample efficiency and achieves\nbeyond-expert performance on Atari and MuJoCo tasks with fewer demonstrations\nthan in previous work. We also provide a theoretical justification of ILDE as\nan uncertainty-regularized policy optimization method with optimistic\nexploration, leading to a regret growing sublinearly in the number of episodes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u4eff\u5b66\u4e60\u7b97\u6cd5ILDE\uff0c\u901a\u8fc7\u53cc\u63a2\u7d22\u673a\u5236\uff08\u4e50\u89c2\u7b56\u7565\u4f18\u5316\u548c\u597d\u5947\u5fc3\u9a71\u52a8\u63a2\u7d22\uff09\u5728\u6837\u672c\u6548\u7387\u4e0a\u8d85\u8d8a\u73b0\u6709\u7b97\u6cd5\uff0c\u5e76\u5728Atari\u548cMuJoCo\u4efb\u52a1\u4e2d\u7528\u66f4\u5c11\u7684\u6f14\u793a\u5b9e\u73b0\u8d85\u8d8a\u4e13\u5bb6\u7684\u8868\u73b0\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u662f\u4e00\u79cd\u5e26\u6709\u4e50\u89c2\u63a2\u7d22\u7684\u4e0d\u786e\u5b9a\u6027\u6b63\u5219\u5316\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u5176\u9057\u61be\u503c\u968f\u5267\u96c6\u6570\u91cf\u4e9a\u7ebf\u6027\u589e\u957f\u3002", "motivation": "\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u6a21\u4eff\u5b66\u4e60\u65e8\u5728\u5b66\u4e60\u6a21\u4eff\u4e13\u5bb6\u884c\u4e3a\u7684\u7b56\u7565\u3002\u7136\u800c\uff0c\u7531\u4e8e\u72b6\u6001\u7a7a\u95f4\u7684\u590d\u6742\u6027\uff0c\u4ece\u6709\u9650\u6570\u91cf\u7684\u6f14\u793a\u4e2d\u51c6\u786e\u5b66\u4e60\u4e13\u5bb6\u7b56\u7565\u5177\u6709\u6311\u6218\u6027\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u8d85\u8d8a\u4e13\u5bb6\u8868\u73b0\uff0c\u8fd8\u9700\u8981\u63a2\u7d22\u73af\u5883\u5e76\u6536\u96c6\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aILDE\u7684\u65b0\u6a21\u4eff\u5b66\u4e60\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u4e24\u79cd\u65b9\u5f0f\u5b9e\u65bd\u63a2\u7d22\uff1a(1) \u901a\u8fc7\u63a2\u7d22\u5956\u52b1\uff08\u9488\u5bf9\u9ad8\u4e0d\u786e\u5b9a\u6027\u72b6\u6001-\u52a8\u4f5c\u5bf9\uff09\u8fdb\u884c\u4e50\u89c2\u7b56\u7565\u4f18\u5316\uff0c\u4ee5\u6f5c\u5728\u5730\u6539\u8fdb\u5411\u4e13\u5bb6\u7b56\u7565\u7684\u6536\u655b\uff1b(2) \u597d\u5947\u5fc3\u9a71\u52a8\u7684\u63a2\u7d22\uff08\u504f\u79bb\u6f14\u793a\u8f68\u8ff9\u7684\u72b6\u6001\uff09\uff0c\u4ee5\u6f5c\u5728\u5730\u83b7\u5f97\u8d85\u8d8a\u4e13\u5bb6\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u7684\u6a21\u4eff\u5b66\u4e60\u7b97\u6cd5\u76f8\u6bd4\uff0cILDE\u5728\u6837\u672c\u6548\u7387\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5728Atari\u548cMuJoCo\u4efb\u52a1\u4e2d\u4f7f\u7528\u6bd4\u5148\u524d\u5de5\u4f5c\u66f4\u5c11\u7684\u6f14\u793a\u5b9e\u73b0\u4e86\u8d85\u8d8a\u4e13\u5bb6\u7684\u8868\u73b0\u3002", "conclusion": "ILDE\u88ab\u8bc1\u660e\u662f\u4e00\u79cd\u6709\u6548\u7684\u6a21\u4eff\u5b66\u4e60\u7b97\u6cd5\uff0c\u5728\u6837\u672c\u6548\u7387\u548c\u8d85\u8d8a\u4e13\u5bb6\u8868\u73b0\u65b9\u9762\u5177\u6709\u4f18\u52bf\u3002\u7406\u8bba\u4e0a\uff0cILDE\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u79cd\u5e26\u6709\u4e50\u89c2\u63a2\u7d22\u7684\u4e0d\u786e\u5b9a\u6027\u6b63\u5219\u5316\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u5176\u9057\u61be\u503c\u968f\u5267\u96c6\u6570\u91cf\u4e9a\u7ebf\u6027\u589e\u957f\u3002"}}
{"id": "2506.20323", "pdf": "https://arxiv.org/pdf/2506.20323", "abs": "https://arxiv.org/abs/2506.20323", "authors": ["Saundarya Subramaniam", "Shalini Majumdar", "Shantanu Nadar", "Kaustubh Kulkarni"], "title": "Comparative Analysis of Deep Learning Models for Crop Disease Detection: A Transfer Learning Approach", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This research presents the development of an Artificial Intelligence (AI) -\ndriven crop disease detection system designed to assist farmers in rural areas\nwith limited resources. We aim to compare different deep learning models for a\ncomparative analysis, focusing on their efficacy in transfer learning. By\nleveraging deep learning models, including EfficientNet, ResNet101,\nMobileNetV2, and our custom CNN, which achieved a validation accuracy of\n95.76%, the system effectively classifies plant diseases. This research\ndemonstrates the potential of transfer learning in reshaping agricultural\npractices, improving crop health management, and supporting sustainable farming\nin rural environments.", "AI": {"tldr": "This research develops an AI-driven crop disease detection system for farmers in rural areas with limited resources, comparing deep learning models including EfficientNet, ResNet101, MobileNetV2, and a custom CNN for their efficacy in transfer learning. The custom CNN achieved a validation accuracy of 95.76%, demonstrating the potential of transfer learning to improve agricultural practices.", "motivation": "To assist farmers in rural areas with limited resources by developing an effective crop disease detection system using AI.", "method": "The research compares different deep learning models (EfficientNet, ResNet101, MobileNetV2, and a custom CNN) focusing on their efficacy in transfer learning to classify plant diseases.", "result": "The custom CNN model achieved a validation accuracy of 95.76% in classifying plant diseases.", "conclusion": "Transfer learning has great potential in reshaping agricultural practices, enhancing crop health management, and supporting sustainable farming in rural environments."}}
{"id": "2506.20324", "pdf": "https://arxiv.org/pdf/2506.20324", "abs": "https://arxiv.org/abs/2506.20324", "authors": ["Torben Berndt", "Benjamin Walker", "Tiexin Qin", "Jan St\u00fchmer", "Andrey Kormilitzin"], "title": "Permutation Equivariant Neural Controlled Differential Equations for Dynamic Graph Representation Learning", "categories": ["cs.LG"], "comment": null, "summary": "Dynamic graphs exhibit complex temporal dynamics due to the interplay between\nevolving node features and changing network structures. Recently, Graph Neural\nControlled Differential Equations (Graph Neural CDEs) successfully adapted\nNeural CDEs from paths on Euclidean domains to paths on graph domains. Building\non this foundation, we introduce Permutation Equivariant Neural Graph CDEs,\nwhich project Graph Neural CDEs onto permutation equivariant function spaces.\nThis significantly reduces the model's parameter count without compromising\nrepresentational power, resulting in more efficient training and improved\ngeneralisation. We empirically demonstrate the advantages of our approach\nthrough experiments on simulated dynamical systems and real-world tasks,\nshowing improved performance in both interpolation and extrapolation scenarios.", "AI": {"tldr": "\u52a8\u6001\u56fe\u7531\u4e8e\u8282\u70b9\u7279\u5f81\u7684\u6f14\u53d8\u548c\u7f51\u7edc\u7ed3\u6784\u7684\u53d8\u5316\u8868\u73b0\u51fa\u590d\u6742\u7684\u65f6\u5e8f\u52a8\u529b\u5b66\u3002\u672c\u6587\u5728Graph Neural CDEs\u7684\u57fa\u7840\u4e0a\uff0c\u5f15\u5165\u4e86Permutation Equivariant Neural Graph CDEs\uff0c\u901a\u8fc7\u5c06\u6a21\u578b\u6295\u5f71\u5230\u7f6e\u6362\u7b49\u53d8\u51fd\u6570\u7a7a\u95f4\uff0c\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u5e76\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u6a21\u62df\u52a8\u529b\u7cfb\u7edf\u548c\u5b9e\u9645\u4efb\u52a1\u4e2d\u5747\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u63d2\u503c\u548c\u5916\u63a8\u6027\u80fd\u3002", "motivation": "\u52a8\u6001\u56fe\u7684\u65f6\u95f4\u52a8\u529b\u5b66\u590d\u6742\uff0c\u73b0\u6709\u65b9\u6cd5\u867d\u7136\u53d6\u5f97\u4e00\u5b9a\u6210\u529f\uff0c\u4f46\u6a21\u578b\u53c2\u6570\u91cf\u5927\u4e14\u8bad\u7ec3\u6548\u7387\u4f4e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u2014\u2014Permutation Equivariant Neural Graph CDEs\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u5c06Graph Neural CDEs\u6295\u5f71\u5230\u7f6e\u6362\u7b49\u53d8\u51fd\u6570\u7a7a\u95f4\uff0c\u51cf\u5c11\u4e86\u53c2\u6570\u6570\u91cf\u800c\u4e0d\u964d\u4f4e\u8868\u793a\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u65b0\u65b9\u6cd5\u5728\u6a21\u62df\u52a8\u529b\u7cfb\u7edf\u548c\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u5747\u63d0\u9ad8\u4e86\u63d2\u503c\u548c\u5916\u63a8\u6027\u80fd\uff0c\u540c\u65f6\u8bad\u7ec3\u66f4\u9ad8\u6548\u3001\u6cdb\u5316\u80fd\u529b\u66f4\u5f3a\u3002", "conclusion": "Permutation Equivariant Neural Graph CDEs\u5728\u4fdd\u6301\u8868\u793a\u80fd\u529b\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u53c2\u6570\u6570\u91cf\uff0c\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u6cdb\u5316\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u56fe\u7684\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u4efb\u52a1\u3002"}}
{"id": "2506.20329", "pdf": "https://arxiv.org/pdf/2506.20329", "abs": "https://arxiv.org/abs/2506.20329", "authors": ["Alexandre Rio", "Marta Soare", "Sihem Amer-Yahia"], "title": "Producer-Fairness in Sequential Bundle Recommendation", "categories": ["cs.LG"], "comment": null, "summary": "We address fairness in the context of sequential bundle recommendation, where\nusers are served in turn with sets of relevant and compatible items. Motivated\nby real-world scenarios, we formalize producer-fairness, that seeks to achieve\ndesired exposure of different item groups across users in a recommendation\nsession. Our formulation combines naturally with building high quality bundles.\nOur problem is solved in real time as users arrive. We propose an exact\nsolution that caters to small instances of our problem. We then examine two\nheuristics, quality-first and fairness-first, and an adaptive variant that\ndetermines on-the-fly the right balance between bundle fairness and quality.\nOur experiments on three real-world datasets underscore the strengths and\nlimitations of each solution and demonstrate their efficacy in providing fair\nbundle recommendations without compromising bundle quality.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u987a\u5e8f\u6346\u7ed1\u63a8\u8350\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u751f\u4ea7\u8005\u516c\u5e73\u6027\u7684\u6982\u5ff5\uff0c\u5e76\u7814\u7a76\u4e86\u5728\u4e0d\u5f71\u54cd\u6346\u7ed1\u5305\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u63d0\u4f9b\u516c\u5e73\u63a8\u8350\u7684\u51e0\u79cd\u65b9\u6cd5\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u573a\u666f\u4e2d\uff0c\u4e0d\u540c\u7684\u9879\u76ee\u7ec4\u5728\u63a8\u8350\u4f1a\u8bdd\u4e2d\u9700\u8981\u83b7\u5f97\u671f\u671b\u7684\u66dd\u5149\u5ea6\uff0c\u56e0\u6b64\u9700\u8981\u89e3\u51b3\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u751f\u4ea7\u8005\u516c\u5e73\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7cbe\u786e\u89e3\u51b3\u65b9\u6848\u7528\u4e8e\u5c0f\u578b\u5b9e\u4f8b\u95ee\u9898\uff0c\u5e76\u8003\u5bdf\u4e86\u4e24\u79cd\u542f\u53d1\u5f0f\u65b9\u6cd5\uff08\u8d28\u91cf\u4f18\u5148\u548c\u516c\u5e73\u6027\u4f18\u5148\uff09\u4ee5\u53ca\u4e00\u79cd\u81ea\u9002\u5e94\u53d8\u4f53\uff0c\u8be5\u53d8\u4f53\u80fd\u591f\u5728\u8fd0\u884c\u65f6\u52a8\u6001\u786e\u5b9a\u516c\u5e73\u6027\u548c\u8d28\u91cf\u4e4b\u95f4\u7684\u9002\u5f53\u5e73\u8861\u3002", "result": "\u901a\u8fc7\u5728\u4e09\u4e2a\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\uff0c\u7a81\u663e\u4e86\u6bcf\u79cd\u89e3\u51b3\u65b9\u6848\u7684\u4f18\u52bf\u548c\u5c40\u9650\u6027\uff0c\u8bc1\u660e\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5728\u63d0\u4f9b\u516c\u5e73\u6346\u7ed1\u63a8\u8350\u7684\u540c\u65f6\u4e0d\u4f1a\u5f71\u54cd\u6346\u7ed1\u5305\u7684\u8d28\u91cf\u3002", "conclusion": "\u63d0\u51fa\u7684\u89e3\u51b3\u65b9\u6848\u80fd\u591f\u5728\u987a\u5e8f\u6346\u7ed1\u63a8\u8350\u4e2d\u5b9e\u73b0\u751f\u4ea7\u8005\u516c\u5e73\u6027\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e0e\u6784\u5efa\u9ad8\u8d28\u91cf\u6346\u7ed1\u5305\u7684\u76ee\u6807\u81ea\u7136\u7ed3\u5408\u3002"}}
{"id": "2506.20353", "pdf": "https://arxiv.org/pdf/2506.20353", "abs": "https://arxiv.org/abs/2506.20353", "authors": ["Xuan Ding", "Rui Sun", "Yunjian Zhang", "Xiu Yan", "Yueqi Zhou", "Kaihao Huang", "Suzhong Fu", "Chuanlong Xie", "Yao Zhu"], "title": "DipSVD: Dual-importance Protected SVD for Efficient LLM Compression", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The ever-increasing computational demands and deployment costs of large\nlanguage models (LLMs) have spurred numerous compressing methods. Compared to\nquantization and unstructured pruning, SVD compression offers superior hardware\ncompatibility and theoretical guarantees. However, existing SVD-based methods\nfocus on the overall discrepancy between the original and compressed matrices\nwhile overlooking the protection of critical components within the matrix,\nwhich leads to inferior performance in the compressed models. This paper\nproposes a dual-level importance protection mechanism to enhance SVD-based\ncompression methods: (1) local importance protection: preserving the most\ncritical singular vectors within each weight matrix through channel-weighted\ndata whitening; and (2) global importance protection: enabling less important\nlayers to bear a greater portion of the compression burden through either a\nheuristic or optimization-based approach, thereby minimizing the impact of\ncompression on critical layers. Extensive experiments demonstrate that DipSVD\noutperforms existing SVD-based compression approaches across multiple\nbenchmarks, achieving superior model performance especially at high model\ncompression ratios.", "AI": {"tldr": "\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8ba1\u7b97\u9700\u6c42\u548c\u90e8\u7f72\u6210\u672c\u4e0d\u65ad\u589e\u52a0\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u91cd\u8981\u6027\u4fdd\u62a4\u673a\u5236\uff08DipSVD\uff09\uff0c\u4ee5\u589e\u5f3a\u57fa\u4e8e\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\u7684\u538b\u7f29\u65b9\u6cd5\u3002\u8be5\u673a\u5236\u5305\u62ec\u5c40\u90e8\u91cd\u8981\u6027\u4fdd\u62a4\u548c\u5168\u5c40\u91cd\u8981\u6027\u4fdd\u62a4\uff0c\u901a\u8fc7\u901a\u9053\u52a0\u6743\u6570\u636e\u767d\u5316\u4fdd\u7559\u5173\u952e\u5947\u5f02\u5411\u91cf\uff0c\u5e76\u8ba9\u4e0d\u91cd\u8981\u7684\u5c42\u627f\u62c5\u66f4\u591a\u7684\u538b\u7f29\u8d1f\u62c5\uff0c\u4ece\u800c\u51cf\u5c11\u5bf9\u5173\u952e\u5c42\u7684\u5f71\u54cd\u3002\u5b9e\u9a8c\u8868\u660e\uff0cDipSVD\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u7684SVD\u538b\u7f29\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u9ad8\u6a21\u578b\u538b\u7f29\u6bd4\u4e0b\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u9700\u6c42\u548c\u90e8\u7f72\u6210\u672c\u4e0d\u65ad\u589e\u957f\uff0c\u63a8\u52a8\u4e86\u591a\u79cd\u538b\u7f29\u65b9\u6cd5\u7684\u53d1\u5c55\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u57fa\u4e8eSVD\u7684\u538b\u7f29\u65b9\u6cd5\u867d\u7136\u5177\u6709\u826f\u597d\u7684\u786c\u4ef6\u517c\u5bb9\u6027\u548c\u7406\u8bba\u4fdd\u8bc1\uff0c\u4f46\u5728\u4fdd\u62a4\u77e9\u9635\u4e2d\u7684\u5173\u952e\u7ec4\u4ef6\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5bfc\u81f4\u538b\u7f29\u6a21\u578b\u6027\u80fd\u8f83\u5dee\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u5c42\u91cd\u8981\u6027\u4fdd\u62a4\u673a\u5236\uff08DipSVD\uff09\uff0c\u5305\u62ec\uff1a1. \u5c40\u90e8\u91cd\u8981\u6027\u4fdd\u62a4\uff1a\u901a\u8fc7\u901a\u9053\u52a0\u6743\u6570\u636e\u767d\u5316\u4fdd\u7559\u6bcf\u4e2a\u6743\u91cd\u77e9\u9635\u4e2d\u6700\u5173\u952e\u7684\u5947\u5f02\u5411\u91cf\uff1b2. \u5168\u5c40\u91cd\u8981\u6027\u4fdd\u62a4\uff1a\u901a\u8fc7\u542f\u53d1\u5f0f\u6216\u4f18\u5316\u65b9\u6cd5\uff0c\u4f7f\u4e0d\u91cd\u8981\u7684\u5c42\u627f\u62c5\u66f4\u5927\u7684\u538b\u7f29\u8d1f\u62c5\uff0c\u4ece\u800c\u6700\u5c0f\u5316\u538b\u7f29\u5bf9\u5173\u952e\u5c42\u7684\u5f71\u54cd\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0cDipSVD\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u7684SVD\u538b\u7f29\u65b9\u6cd5\uff0c\u5728\u9ad8\u6a21\u578b\u538b\u7f29\u6bd4\u4e0b\u5c24\u5176\u8868\u73b0\u51fa\u8272\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "DipSVD\u901a\u8fc7\u5f15\u5165\u53cc\u5c42\u91cd\u8981\u6027\u4fdd\u62a4\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u57fa\u4e8eSVD\u7684\u538b\u7f29\u65b9\u6cd5\u7684\u6548\u679c\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u538b\u7f29\u6bd4\u60c5\u51b5\u4e0b\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.20354", "pdf": "https://arxiv.org/pdf/2506.20354", "abs": "https://arxiv.org/abs/2506.20354", "authors": ["Francesco Carzaniga", "Michael Hersche", "Abu Sebastian", "Kaspar Schindler", "Abbas Rahimi"], "title": "A foundation model with multi-variate parallel attention to generate neuronal activity", "categories": ["cs.LG", "cs.AI"], "comment": "The code is available at\n  https://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG\n  dataset is available at\n  https://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg", "summary": "Learning from multi-variate time-series with heterogeneous channel\nconfigurations remains a fundamental challenge for deep neural networks (DNNs),\nparticularly in clinical domains such as intracranial electroencephalography\n(iEEG), where channel setups vary widely across subjects. In this work, we\nintroduce multi-variate parallel attention (MVPA), a novel self-attention\nmechanism that disentangles content, temporal, and spatial attention, enabling\nflexible, generalizable, and efficient modeling of time-series data with\nvarying channel counts and configurations. We use MVPA to build MVPFormer, a\ngenerative foundation model for human electrophysiology, trained to predict the\nevolution of iEEG signals across diverse subjects. To support this and future\neffort by the community, we release the SWEC iEEG dataset, the largest publicly\navailable iEEG dataset to date, comprising nearly 10,000 hours of recordings\nfrom heterogeneous clinical sources. MVPFormer leverages MVPA to achieve strong\ngeneralization across subjects, demonstrating expert-level performance in\nseizure detection and outperforming state-of-the-art Transformer baselines on\nour SWEC, the MAYO, and the FNUSA dataset. We further validate MVPA on standard\ntime-series forecasting and classification tasks, where it matches or exceeds\nexisting attention-based models. Together, our contributions establish MVPA as\na general-purpose attention mechanism for heterogeneous time-series and\nMVPFormer as the first open-source, open-weights, and open-data iEEG foundation\nmodel with state-of-the-art clinical performance. The code is available at\nhttps://github.com/IBM/multi-variate-parallel-transformer. The SWEC iEEG\ndataset is available at\nhttps://mb-neuro.medical-blocks.ch/public_access/databases/ieeg/swec_ieeg.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u2014\u2014\u591a\u53d8\u91cf\u5e73\u884c\u6ce8\u610f\u529b\uff08MVPA\uff09\uff0c\u5e76\u57fa\u4e8e\u6b64\u6784\u5efa\u4e86MVPFormer\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u4eba\u7c7b\u8111\u7535\u56fe\u4fe1\u53f7\u7684\u6f14\u53d8\u3002\u8be5\u6a21\u578b\u5728\u766b\u75eb\u53d1\u4f5c\u68c0\u6d4b\u7b49\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u9002\u7528\u4e8e\u5f02\u6784\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u3002\u4f5c\u8005\u8fd8\u53d1\u5e03\u4e86\u76ee\u524d\u6700\u5927\u7684\u516c\u5f00iEEG\u6570\u636e\u96c6SWEC\uff0c\u4ee5\u652f\u6301\u672a\u6765\u7684\u7814\u7a76\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u5904\u7406\u5177\u6709\u5f02\u6784\u901a\u9053\u914d\u7f6e\u7684\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65f6\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u4e34\u5e8a\u9886\u57df\u5982\u9885\u5185\u8111\u7535\u56fe\uff08iEEG\uff09\u4e2d\uff0c\u4e0d\u540c\u53d7\u8bd5\u8005\u7684\u901a\u9053\u8bbe\u7f6e\u5dee\u5f02\u5f88\u5927\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7075\u6d3b\u3001\u901a\u7528\u4e14\u9ad8\u6548\u5730\u5efa\u6a21\u8fd9\u4e9b\u6570\u636e\u7684\u65b9\u6cd5\u3002", "method": "\u8bba\u6587\u5f15\u5165\u4e86\u591a\u53d8\u91cf\u5e73\u884c\u6ce8\u610f\u529b\uff08MVPA\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u53ef\u4ee5\u5206\u79bb\u5185\u5bb9\u3001\u65f6\u95f4\u548c\u7a7a\u95f4\u6ce8\u610f\u529b\u3002\u57fa\u4e8eMVPA\uff0c\u6784\u5efa\u4e86MVPFormer\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u8de8\u4e0d\u540c\u53d7\u8bd5\u8005\u7684iEEG\u4fe1\u53f7\u6f14\u53d8\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u53d1\u5e03\u4e86\u540d\u4e3aSWEC\u7684\u5927\u578b\u516c\u5f00iEEG\u6570\u636e\u96c6\u3002", "result": "MVPFormer\u5728\u8de8\u53d7\u8bd5\u8005\u6cdb\u5316\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5728\u766b\u75eb\u53d1\u4f5c\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e13\u5bb6\u7ea7\u6c34\u5e73\uff0c\u5e76\u5728SWEC\u3001MAYO\u548cFNUSA\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u73b0\u6709\u7684Transformer\u57fa\u7ebf\u6a21\u578b\u3002MVPA\u5728\u6807\u51c6\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u548c\u5206\u7c7b\u4efb\u52a1\u4e2d\u4e5f\u5339\u914d\u6216\u8d85\u8fc7\u4e86\u73b0\u6709\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u6a21\u578b\u3002", "conclusion": "MVPA\u88ab\u786e\u7acb\u4e3a\u4e00\u79cd\u9002\u7528\u4e8e\u5f02\u6784\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u901a\u7528\u6ce8\u610f\u529b\u673a\u5236\uff0c\u800cMVPFormer\u5219\u6210\u4e3a\u9996\u4e2a\u5f00\u6e90\u3001\u5f00\u653e\u6743\u91cd\u548c\u5f00\u653e\u6570\u636e\u7684iEEG\u57fa\u7840\u6a21\u578b\uff0c\u5177\u6709\u6700\u5148\u8fdb\u7684\u4e34\u5e8a\u6027\u80fd\u3002"}}
{"id": "2506.20362", "pdf": "https://arxiv.org/pdf/2506.20362", "abs": "https://arxiv.org/abs/2506.20362", "authors": ["Lorenzo Bini", "Stephane Marchand-Maillet"], "title": "Self-Supervised Graph Learning via Spectral Bootstrapping and Laplacian-Based Augmentations", "categories": ["cs.LG", "cs.AI", "cs.DS"], "comment": "LaplaceGNN is a novel graph learning framework that employs a\n  bootstrapped teacher-student architecture. Its precomputed spectral\n  augmentations and adversarial training enable robust performance,\n  outperforming SOTA methods while scaling linearly", "summary": "We present LaplaceGNN, a novel self-supervised graph learning framework that\nbypasses the need for negative sampling by leveraging spectral bootstrapping\ntechniques. Our method integrates Laplacian-based signals into the learning\nprocess, allowing the model to effectively capture rich structural\nrepresentations without relying on contrastive objectives or handcrafted\naugmentations. By focusing on positive alignment, LaplaceGNN achieves linear\nscaling while offering a simpler, more efficient, self-supervised alternative\nfor graph neural networks, applicable across diverse domains. Our contributions\nare twofold: we precompute spectral augmentations through max-min\ncentrality-guided optimization, enabling rich structural supervision without\nrelying on handcrafted augmentations, then we integrate an adversarial\nbootstrapped training scheme that further strengthens feature learning and\nrobustness. Our extensive experiments on different benchmark datasets show that\nLaplaceGNN achieves superior performance compared to state-of-the-art\nself-supervised graph methods, offering a promising direction for efficiently\nlearning expressive graph representations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u76d1\u7763\u56fe\u5b66\u4e60\u6846\u67b6LaplaceGNN\uff0c\u901a\u8fc7\u5229\u7528\u8c31\u5f15\u5bfc\u4f18\u5316\u548c\u5bf9\u6297\u5f15\u5bfc\u8bad\u7ec3\u65b9\u6848\uff0c\u65e0\u9700\u8d1f\u91c7\u6837\u6216\u5bf9\u6bd4\u76ee\u6807\u5373\u53ef\u6355\u83b7\u4e30\u5bcc\u7684\u7ed3\u6784\u8868\u793a\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684\u56fe\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u5bf9\u6bd4\u76ee\u6807\u6216\u624b\u5de5\u589e\u5f3a\uff0c\u9700\u8981\u8d1f\u91c7\u6837\u4e14\u6548\u7387\u8f83\u4f4e\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u7b80\u5355\u3001\u66f4\u6709\u6548\u7684\u81ea\u76d1\u7763\u65b9\u6cd5\u6765\u6355\u83b7\u56fe\u7684\u7ed3\u6784\u4fe1\u606f\u3002", "method": "LaplaceGNN\u901a\u8fc7\u5c06\u62c9\u666e\u62c9\u65af\u4fe1\u53f7\u6574\u5408\u5230\u5b66\u4e60\u8fc7\u7a0b\u4e2d\uff0c\u91c7\u7528\u6b63\u5bf9\u9f50\u7b56\u7565\u5b9e\u73b0\u7ebf\u6027\u6269\u5c55\uff1b\u9884\u5148\u8ba1\u7b97\u57fa\u4e8e\u6700\u5927\u6700\u5c0f\u4e2d\u5fc3\u6027\u4f18\u5316\u7684\u8c31\u589e\u5f3a\uff0c\u63d0\u4f9b\u4e30\u5bcc\u7684\u7ed3\u6784\u76d1\u7763\uff1b\u540c\u65f6\u5f15\u5165\u5bf9\u6297\u5f15\u5bfc\u7684\u8bad\u7ec3\u65b9\u6848\u4ee5\u52a0\u5f3a\u7279\u5f81\u5b66\u4e60\u548c\u9c81\u68d2\u6027\u3002", "result": "\u5728\u4e0d\u540c\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0cLaplaceGNN\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u81ea\u76d1\u7763\u56fe\u5b66\u4e60\u65b9\u6cd5\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u6027\u80fd\u3002", "conclusion": "LaplaceGNN\u4e3a\u9ad8\u6548\u5b66\u4e60\u8868\u8fbe\u6027\u56fe\u8868\u793a\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u9014\u7684\u65b9\u5411\uff0c\u65e0\u9700\u4f9d\u8d56\u5bf9\u6bd4\u76ee\u6807\u6216\u624b\u5de5\u589e\u5f3a\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2506.20359", "pdf": "https://arxiv.org/pdf/2506.20359", "abs": "https://arxiv.org/abs/2506.20359", "authors": ["Chanuka Don Samarasinghage", "Dhruv Gulabani"], "title": "Towards Interpretable and Efficient Feature Selection in Trajectory Datasets: A Taxonomic Approach", "categories": ["cs.LG"], "comment": null, "summary": "Trajectory analysis is not only about obtaining movement data, but it is also\nof paramount importance in understanding the pattern in which an object moves\nthrough space and time, as well as in predicting its next move. Due to the\nsignificant interest in the area, data collection has improved substantially,\nresulting in a large number of features becoming available for training and\npredicting models. However, this introduces a high-dimensionality-induced\nfeature explosion problem, which reduces the efficiency and interpretability of\nthe data, thereby reducing the accuracy of machine learning models. To overcome\nthis issue, feature selection has become one of the most prevalent tools. Thus,\nthe objective of this paper was to introduce a taxonomy-based feature selection\nmethod that categorizes features based on their internal structure. This\napproach classifies the data into geometric and kinematic features, further\ncategorizing them into curvature, indentation, speed, and acceleration. The\ncomparative analysis indicated that a taxonomy-based approach consistently\nachieved comparable or superior predictive performance. Furthermore, due to the\ntaxonomic grouping, which reduces combinatorial space, the time taken to select\nfeatures was drastically reduced. The taxonomy was also used to gain insights\ninto what feature sets each dataset was more sensitive to. Overall, this study\nprovides robust evidence that a taxonomy-based feature selection method can add\na layer of interpretability, reduce dimensionality and computational\ncomplexity, and contribute to high-level decision-making. It serves as a step\ntoward providing a methodological framework for researchers and practitioners\ndealing with trajectory datasets and contributing to the broader field of\nexplainable artificial intelligence.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u7c7b\u6cd5\u7684\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u5c06\u7279\u5f81\u5206\u4e3a\u51e0\u4f55\u548c\u8fd0\u52a8\u5b66\u7279\u5f81\uff0c\u5e76\u8fdb\u4e00\u6b65\u7ec6\u5206\u4e3a\u66f2\u7387\u3001\u51f9\u5ea6\u3001\u901f\u5ea6\u548c\u52a0\u901f\u5ea6\u3002\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u9884\u6d4b\u6027\u80fd\uff0c\u51cf\u5c11\u4e86\u7279\u5f81\u9009\u62e9\u7684\u65f6\u95f4\uff0c\u589e\u52a0\u4e86\u6570\u636e\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u964d\u4f4e\u4e86\u7ef4\u5ea6\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4e3a\u8f68\u8ff9\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u65b9\u6cd5\u8bba\u6846\u67b6\u3002", "motivation": "\u8f68\u8ff9\u5206\u6790\u4e0d\u4ec5\u6d89\u53ca\u83b7\u53d6\u8fd0\u52a8\u6570\u636e\uff0c\u8fd8\u5bf9\u7406\u89e3\u7269\u4f53\u5728\u65f6\u7a7a\u4e2d\u7684\u79fb\u52a8\u6a21\u5f0f\u4ee5\u53ca\u9884\u6d4b\u5176\u4e0b\u4e00\u6b65\u52a8\u4f5c\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u9ad8\u7ef4\u7279\u5f81\u7206\u70b8\u95ee\u9898\u964d\u4f4e\u4e86\u6570\u636e\u6548\u7387\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u3002", "method": "\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u7c7b\u6cd5\u7684\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff0c\u6839\u636e\u7279\u5f81\u7684\u5185\u90e8\u7ed3\u6784\u5bf9\u5176\u8fdb\u884c\u5206\u7c7b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5c06\u6570\u636e\u5206\u4e3a\u51e0\u4f55\u7279\u5f81\u548c\u8fd0\u52a8\u5b66\u7279\u5f81\uff0c\u5e76\u8fdb\u4e00\u6b65\u7ec6\u5206\u4e3a\u66f2\u7387\u3001\u51f9\u5ea6\u3001\u901f\u5ea6\u548c\u52a0\u901f\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u5206\u7c7b\u6cd5\u7684\u65b9\u6cd5\u5728\u9884\u6d4b\u6027\u80fd\u4e0a\u8fbe\u5230\u6216\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u7531\u4e8e\u5206\u7c7b\u7ec4\u5408\u7a7a\u95f4\u51cf\u5c0f\uff0c\u7279\u5f81\u9009\u62e9\u6240\u9700\u65f6\u95f4\u5927\u5e45\u51cf\u5c11\uff0c\u540c\u65f6\u53ef\u4ee5\u63ed\u793a\u4e0d\u540c\u6570\u636e\u96c6\u5bf9\u7279\u5f81\u96c6\u5408\u7684\u654f\u611f\u6027\u3002", "conclusion": "\u57fa\u4e8e\u5206\u7c7b\u6cd5\u7684\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u53ef\u4ee5\u589e\u52a0\u6570\u636e\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u964d\u4f4e\u7ef4\u5ea6\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u6709\u52a9\u4e8e\u9ad8\u5c42\u6b21\u51b3\u7b56\u5236\u5b9a\uff0c\u4e3a\u8f68\u8ff9\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b9\u6cd5\u8bba\u6846\u67b6\uff0c\u63a8\u52a8\u4e86\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.20413", "pdf": "https://arxiv.org/pdf/2506.20413", "abs": "https://arxiv.org/abs/2506.20413", "authors": ["Mohammad Mahdi Maheri", "Denys Herasymuk", "Hamed Haddadi"], "title": "Client Clustering Meets Knowledge Sharing: Enhancing Privacy and Robustness in Personalized Peer-to-Peer Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "The growing adoption of Artificial Intelligence (AI) in Internet of Things\n(IoT) ecosystems has intensified the need for personalized learning methods\nthat can operate efficiently and privately across heterogeneous,\nresource-constrained devices. However, enabling effective personalized learning\nin decentralized settings introduces several challenges, including efficient\nknowledge transfer between clients, protection of data privacy, and resilience\nagainst poisoning attacks. In this paper, we address these challenges by\ndeveloping P4 (Personalized, Private, Peer-to-Peer) -- a method designed to\ndeliver personalized models for resource-constrained IoT devices while ensuring\ndifferential privacy and robustness against poisoning attacks. Our solution\nemploys a lightweight, fully decentralized algorithm to privately detect client\nsimilarity and form collaborative groups. Within each group, clients leverage\ndifferentially private knowledge distillation to co-train their models,\nmaintaining high accuracy while ensuring robustness to the presence of\nmalicious clients. We evaluate P4 on popular benchmark datasets using both\nlinear and CNN-based architectures across various heterogeneity settings and\nattack scenarios. Experimental results show that P4 achieves 5% to 30% higher\naccuracy than leading differentially private peer-to-peer approaches and\nmaintains robustness with up to 30% malicious clients. Additionally, we\ndemonstrate its practicality by deploying it on resource-constrained devices,\nwhere collaborative training between two clients adds only ~7 seconds of\noverhead.", "AI": {"tldr": "\u5728\u7269\u8054\u7f51\u751f\u6001\u7cfb\u7edf\u4e2d\uff0c\u4eba\u5de5\u667a\u80fd\u7684\u65e5\u76ca\u666e\u53ca\u52a0\u5267\u4e86\u5bf9\u80fd\u591f\u5728\u5f02\u6784\u3001\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u9ad8\u6548\u548c\u79c1\u5bc6\u8fd0\u884c\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u9700\u6c42\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aP4\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u53bb\u4e2d\u5fc3\u5316\u73af\u5883\u4e2d\u4e2a\u6027\u5316\u5b66\u4e60\u9762\u4e34\u7684\u6311\u6218\uff0c\u5305\u62ec\u5ba2\u6237\u95f4\u7684\u9ad8\u6548\u77e5\u8bc6\u8f6c\u79fb\u3001\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u548c\u5bf9\u6295\u6bd2\u653b\u51fb\u7684\u62b5\u5fa1\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cP4\u6bd4\u9886\u5148\u7684\u5dee\u5206\u9690\u79c1\u70b9\u5bf9\u70b9\u65b9\u6cd5\u63d0\u9ad8\u4e865%\u523030%\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u5728\u9ad8\u8fbe30%\u7684\u6076\u610f\u5ba2\u6237\u7aef\u5b58\u5728\u4e0b\u4ecd\u80fd\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740AI\u5728IoT\u751f\u6001\u7cfb\u7edf\u7684\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981\u9ad8\u6548\u7684\u4e2a\u6027\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u53ef\u4ee5\u5728\u5f02\u6784\u3001\u8d44\u6e90\u53d7\u9650\u7684\u8bbe\u5907\u4e0a\u8fd0\u884c\uff0c\u540c\u65f6\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u5e76\u62b5\u5fa1\u6295\u6bd2\u653b\u51fb\u3002", "method": "\u5f00\u53d1\u4e86P4\u65b9\u6cd5\uff0c\u91c7\u7528\u8f7b\u91cf\u7ea7\u3001\u5b8c\u5168\u53bb\u4e2d\u5fc3\u5316\u7684\u7b97\u6cd5\u6765\u68c0\u6d4b\u5ba2\u6237\u76f8\u4f3c\u6027\u5e76\u5f62\u6210\u534f\u4f5c\u7ec4\u3002\u7ec4\u5185\u5ba2\u6237\u4f7f\u7528\u5dee\u5206\u9690\u79c1\u77e5\u8bc6\u84b8\u998f\u5171\u540c\u8bad\u7ec3\u6a21\u578b\uff0c\u4ee5\u4fdd\u6301\u9ad8\u51c6\u786e\u5ea6\u5e76\u62b5\u5fa1\u6076\u610f\u5ba2\u6237\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cP4\u5728\u5404\u79cd\u5f02\u6784\u8bbe\u7f6e\u548c\u653b\u51fb\u573a\u666f\u4e2d\uff0c\u6bd4\u9886\u5148\u65b9\u6cd5\u63d0\u9ad8\u4e865%\u523030%\u7684\u51c6\u786e\u6027\uff0c\u5e76\u5728\u9ad8\u8fbe30%\u7684\u6076\u610f\u5ba2\u6237\u7aef\u5b58\u5728\u4e0b\u4fdd\u6301\u4e86\u9c81\u68d2\u6027\u3002\u5b9e\u9645\u90e8\u7f72\u663e\u793a\uff0c\u4e24\u4e2a\u5ba2\u6237\u4e4b\u95f4\u7684\u534f\u4f5c\u8bad\u7ec3\u4ec5\u589e\u52a0\u4e86\u7ea67\u79d2\u7684\u5f00\u9500\u3002", "conclusion": "P4\u65b9\u6cd5\u6210\u529f\u5730\u4e3a\u8d44\u6e90\u53d7\u9650\u7684IoT\u8bbe\u5907\u63d0\u4f9b\u4e86\u4e2a\u6027\u5316\u7684\u6a21\u578b\uff0c\u786e\u4fdd\u4e86\u5dee\u5206\u9690\u79c1\u548c\u5bf9\u6295\u6bd2\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u548c\u6548\u7387\u3002"}}
{"id": "2506.20417", "pdf": "https://arxiv.org/pdf/2506.20417", "abs": "https://arxiv.org/abs/2506.20417", "authors": ["Tatsuhiro Shimizu", "Kazuki Kawamura", "Takanori Muroi", "Yusuke Narita", "Kei Tateno", "Takuma Udagawa", "Yuta Saito"], "title": "Off-Policy Evaluation and Learning for the Future under Non-Stationarity", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We study the novel problem of future off-policy evaluation (F-OPE) and\nlearning (F-OPL) for estimating and optimizing the future value of policies in\nnon-stationary environments, where distributions vary over time. In e-commerce\nrecommendations, for instance, our goal is often to estimate and optimize the\npolicy value for the upcoming month using data collected by an old policy in\nthe previous month. A critical challenge is that data related to the future\nenvironment is not observed in the historical data. Existing methods assume\nstationarity or depend on restrictive reward-modeling assumptions, leading to\nsignificant bias. To address these limitations, we propose a novel estimator\nnamed \\textit{\\textbf{O}ff-\\textbf{P}olicy Estimator for the \\textbf{F}uture\n\\textbf{V}alue (\\textbf{\\textit{OPFV}})}, designed for accurately estimating\npolicy values at any future time point. The key feature of OPFV is its ability\nto leverage the useful structure within time-series data. While future data\nmight not be present in the historical log, we can leverage, for example,\nseasonal, weekly, or holiday effects that are consistent in both the historical\nand future data. Our estimator is the first to exploit these time-related\nstructures via a new type of importance weighting, enabling effective F-OPE.\nTheoretical analysis identifies the conditions under which OPFV becomes\nlow-bias. In addition, we extend our estimator to develop a new policy-gradient\nmethod to proactively learn a good future policy using only historical data.\nEmpirical results show that our methods substantially outperform existing\nmethods in estimating and optimizing the future policy value under\nnon-stationarity for various experimental setups.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e0b\u7684\u672a\u6765\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\uff08F-OPE\uff09\u548c\u5b66\u4e60\uff08F-OPL\uff09\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aOPFV\u7684\u65b0\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u7ed3\u6784\u8fdb\u884c\u51c6\u786e\u7684\u672a\u6765\u7b56\u7565\u4ef7\u503c\u8bc4\u4f30\uff0c\u5e76\u6269\u5c55\u4e3a\u4e00\u79cd\u65b0\u7684\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u4ee5\u4f18\u5316\u672a\u6765\u7b56\u7565\u3002", "motivation": "\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\uff0c\u5206\u5e03\u968f\u65f6\u95f4\u53d8\u5316\uff0c\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u5e73\u7a33\u6027\u6216\u4f9d\u8d56\u9650\u5236\u6027\u7684\u5956\u52b1\u5efa\u6a21\u5047\u8bbe\uff0c\u5bfc\u81f4\u663e\u8457\u504f\u5dee\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5229\u7528\u5386\u53f2\u6570\u636e\u4e2d\u4e0e\u672a\u6765\u73af\u5883\u76f8\u5173\u7684\u65f6\u95f4\u7ed3\u6784\u7684\u65b9\u6cd5\u6765\u4f30\u8ba1\u548c\u4f18\u5316\u672a\u6765\u7b56\u7565\u7684\u4ef7\u503c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aOPFV\u7684\u4f30\u8ba1\u5668\uff0c\u5229\u7528\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u7684\u7ed3\u6784\uff08\u5982\u5b63\u8282\u6027\u3001\u5468\u6548\u5e94\u6216\u8282\u5047\u65e5\u6548\u5e94\uff09\uff0c\u901a\u8fc7\u4e00\u79cd\u65b0\u7684\u91cd\u8981\u6027\u52a0\u6743\u65b9\u6cd5\u5b9e\u73b0\u6709\u6548\u7684\u672a\u6765\u79bb\u7ebf\u7b56\u7565\u8bc4\u4f30\u3002\u8fdb\u4e00\u6b65\u6269\u5c55\u4e3a\u4e00\u79cd\u65b0\u7684\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\uff0c\u4ec5\u4f7f\u7528\u5386\u53f2\u6570\u636e\u4e3b\u52a8\u5b66\u4e60\u826f\u597d\u7684\u672a\u6765\u7b56\u7565\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\uff0cOPFV\u5177\u6709\u4f4e\u504f\u5dee\u3002\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u5b9e\u9a8c\u8bbe\u7f6e\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u597d\u5730\u4f30\u8ba1\u548c\u4f18\u5316\u975e\u5e73\u7a33\u73af\u5883\u4e0b\u7684\u672a\u6765\u7b56\u7565\u4ef7\u503c\u3002", "conclusion": "OPFV\u4f30\u8ba1\u5668\u53ca\u5176\u6269\u5c55\u7684\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u975e\u5e73\u7a33\u73af\u5883\u4e0b\u7684\u672a\u6765\u7b56\u7565\u8bc4\u4f30\u548c\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\uff08\u5982\u7535\u5b50\u5546\u52a1\u63a8\u8350\u7cfb\u7edf\uff09\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u548c\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.20380", "pdf": "https://arxiv.org/pdf/2506.20380", "abs": "https://arxiv.org/abs/2506.20380", "authors": ["Zhengpeng Feng", "Sadiq Jaffer", "Jovana Knezevic", "Silja Sormunen", "Robin Young", "Madeline Lisaius", "Markus Immitzer", "James Ball", "Clement Atzberger", "David A. Coomes", "Anil Madhavapeddy", "Andrew Blake", "Srinivasan Keshav"], "title": "TESSERA: Temporal Embeddings of Surface Spectra for Earth Representation and Analysis", "categories": ["cs.LG"], "comment": null, "summary": "Satellite remote sensing (RS) enables a wide array of downstream Earth\nobservation (EO) applications, including climate modeling, carbon accounting,\nand strategies for conservation and sustainable land use. We present TESSERA, a\nnovel Remote Sensing Foundation Model (RSFM) that uses Self-Supervised Learning\n(SSL) to generate global, robust representations at 10m scale from pixel-level\nsatellite time series data. TESSERA combines information from only optical and\nSAR data streams using two parallel Transformer-based encoders: one dedicated\nto Sentinel-1 SAR polarizations and another to Sentinel-2 MSI data (10 selected\nspectral bands) to create representations that are then fused using a\nmultilayer perceptron (MLP), resulting in a global representation map covering\nthe years 2017 to 2024. Our precomputed representations set a new\nstate-of-the-art performance benchmark and our open-source approach\ndemocratizes access to high-performance, high-resolution representations. We\nbenchmark the performance of TESSERA in five diverse tasks, comparing our work\nwith state-of-the-art task-specific models and other foundation models. Our\nresults show that TESSERA outperforms both traditional RS baselines and the\nleading geospatial foundation models in these diverse downstream tasks.", "AI": {"tldr": "TESSERA\u662f\u4e00\u79cd\u65b0\u578b\u7684\u9065\u611f\u57fa\u7840\u6a21\u578b\uff0c\u4f7f\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u751f\u621010\u7c73\u5c3a\u5ea6\u7684\u5168\u7403\u7a33\u5065\u8868\u793a\uff0c\u7ed3\u5408\u4e86Sentinel-1 SAR\u548cSentinel-2 MSI\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u591a\u5c42\u611f\u77e5\u5668\u878d\u5408\uff0c\u5b9e\u73b0\u4e862017\u81f32024\u5e74\u7684\u5168\u7403\u8868\u793a\u56fe\uff0c\u5728\u4e94\u4e2a\u4e0d\u540c\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u536b\u661f\u9065\u611f\u5728\u5730\u7403\u89c2\u6d4b\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u5305\u62ec\u6c14\u5019\u5efa\u6a21\u3001\u78b3\u6838\u7b97\u4ee5\u53ca\u4fdd\u62a4\u548c\u53ef\u6301\u7eed\u571f\u5730\u5229\u7528\u7b56\u7565\u7b49\uff0c\u4f46\u7f3a\u4e4f\u4e00\u4e2a\u80fd\u591f\u5728\u50cf\u7d20\u7ea7\u536b\u661f\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e0a\u751f\u6210\u5168\u7403\u7a33\u5065\u8868\u793a\u7684\u6a21\u578b\u3002", "method": "TESSERA\u91c7\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e24\u4e2a\u5e76\u884c\u7684Transformer\u7f16\u7801\u5668\u5206\u522b\u5904\u7406Sentinel-1 SAR\u6781\u5316\u6570\u636e\u548cSentinel-2 MSI\u6570\u636e\uff0810\u4e2a\u9009\u5b9a\u5149\u8c31\u5e26\uff09\uff0c\u7136\u540e\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u5668\u8fdb\u884c\u878d\u5408\uff0c\u751f\u62102017\u5e74\u81f32024\u5e74\u7684\u5168\u7403\u8868\u793a\u56fe\u3002", "result": "TESSERA\u5728\u4e94\u4e2a\u4e0d\u540c\u7684\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e0d\u4ec5\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u9065\u611f\u57fa\u51c6\u6a21\u578b\uff0c\u8fd8\u8d85\u8fc7\u4e86\u73b0\u6709\u7684\u9886\u5148\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u3002", "conclusion": "TESSERA\u4e3a\u9ad8\u5206\u8fa8\u7387\u3001\u9ad8\u6027\u80fd\u7684\u9065\u611f\u8868\u793a\u63d0\u4f9b\u4e86\u5f00\u6e90\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u9065\u611f\u6280\u672f\u5728\u591a\u6837\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u8bbe\u5b9a\u4e86\u65b0\u7684\u6027\u80fd\u57fa\u51c6\u3002"}}
{"id": "2506.20451", "pdf": "https://arxiv.org/pdf/2506.20451", "abs": "https://arxiv.org/abs/2506.20451", "authors": ["Shuchu Han", "Wolfgang Bruckner"], "title": "Automatic Demonstration Selection for LLM-based Tabular Data Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "A fundamental question in applying In-Context Learning (ICL) for tabular data\nclassification is how to determine the ideal number of demonstrations in the\nprompt. This work addresses this challenge by presenting an algorithm to\nautomatically select a reasonable number of required demonstrations. Our method\ndistinguishes itself by integrating not only the tabular data's distribution\nbut also the user's selected prompt template and the specific Large Language\nModel (LLM) into its estimation. Rooted in Spectral Graph Theory, our proposed\nalgorithm defines a novel metric to quantify the similarities between different\ndemonstrations. We then construct a similarity graph and analyze the\neigenvalues of its Laplacian to derive the minimum number of demonstrations\ncapable of representing the data within the LLM's intrinsic representation\nspace. We validate the efficacy of our approach through experiments comparing\nits performance against conventional random selection algorithms on diverse\ndatasets and LLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8c31\u56fe\u7406\u8bba\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u9009\u62e9\u8868\u683c\u6570\u636e\u5206\u7c7b\u4e2dIn-Context Learning\uff08ICL\uff09\u6240\u9700\u7684\u5408\u7406\u6f14\u793a\u6b21\u6570\u3002\u901a\u8fc7\u7ed3\u5408\u6570\u636e\u5206\u5e03\u3001\u63d0\u793a\u6a21\u677f\u548c\u7279\u5b9a\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u5b9a\u4e49\u4e86\u65b0\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u5e76\u6784\u5efa\u76f8\u4f3c\u6027\u56fe\u4ee5\u786e\u5b9a\u80fd\u4ee3\u8868\u6570\u636e\u7684\u6700\u5c11\u6f14\u793a\u6b21\u6570\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u7684\u968f\u673a\u9009\u62e9\u7b97\u6cd5\u3002", "motivation": "\u5728\u8868\u683c\u6570\u636e\u5206\u7c7b\u4e2d\u5e94\u7528In-Context Learning\uff08ICL\uff09\u65f6\uff0c\u5982\u4f55\u786e\u5b9a\u63d0\u793a\u4e2d\u7406\u60f3\u7684\u6f14\u793a\u6b21\u6570\u662f\u4e00\u4e2a\u57fa\u672c\u95ee\u9898\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u53ef\u80fd\u4e0d\u591f\u51c6\u786e\u6216\u9ad8\u6548\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u81ea\u52a8\u9009\u62e9\u5408\u7406\u6f14\u793a\u6b21\u6570\u7684\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8c31\u56fe\u7406\u8bba\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u7efc\u5408\u8003\u8651\u4e86\u8868\u683c\u6570\u636e\u5206\u5e03\u3001\u7528\u6237\u9009\u5b9a\u7684\u63d0\u793a\u6a21\u677f\u4ee5\u53ca\u5177\u4f53\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u3002\u901a\u8fc7\u5b9a\u4e49\u65b0\u7684\u5ea6\u91cf\u6807\u51c6\u6765\u91cf\u5316\u4e0d\u540c\u6f14\u793a\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\uff0c\u6784\u5efa\u76f8\u4f3c\u6027\u56fe\u5e76\u5206\u6790\u5176\u62c9\u666e\u62c9\u65af\u77e9\u9635\u7684\u7279\u5f81\u503c\uff0c\u4ece\u800c\u63a8\u5bfc\u51fa\u80fd\u591f\u5728LLM\u5185\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u4ee3\u8868\u6570\u636e\u7684\u6700\u5c0f\u6f14\u793a\u6b21\u6570\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u7684\u968f\u673a\u9009\u62e9\u7b97\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5404\u79cd\u6570\u636e\u96c6\u548cLLM\u4e0a\u7684\u8868\u73b0\u66f4\u4f18\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u8c31\u56fe\u7406\u8bba\u7684\u7b97\u6cd5\uff0c\u53ef\u4ee5\u81ea\u52a8\u9009\u62e9ICL\u4e2d\u5408\u7406\u7684\u6f14\u793a\u6b21\u6570\u3002\u8fd9\u79cd\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u8868\u683c\u6570\u636e\u5206\u7c7b\u4efb\u52a1\u7684\u6548\u679c\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2506.20481", "pdf": "https://arxiv.org/pdf/2506.20481", "abs": "https://arxiv.org/abs/2506.20481", "authors": ["Matthieu Meeus", "Igor Shilov", "Georgios Kaissis", "Yves-Alexandre de Montjoye"], "title": "Counterfactual Influence as a Distributional Quantity", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "comment": "Workshop on The Impact of Memorization on Trustworthy Foundation\n  Models (MemFM) @ ICML 2025", "summary": "Machine learning models are known to memorize samples from their training\ndata, raising concerns around privacy and generalization. Counterfactual\nself-influence is a popular metric to study memorization, quantifying how the\nmodel's prediction for a sample changes depending on the sample's inclusion in\nthe training dataset. However, recent work has shown memorization to be\naffected by factors beyond self-influence, with other training samples, in\nparticular (near-)duplicates, having a large impact. We here study memorization\ntreating counterfactual influence as a distributional quantity, taking into\naccount how all training samples influence how a sample is memorized. For a\nsmall language model, we compute the full influence distribution of training\nsamples on each other and analyze its properties. We find that solely looking\nat self-influence can severely underestimate tangible risks associated with\nmemorization: the presence of (near-)duplicates seriously reduces\nself-influence, while we find these samples to be (near-)extractable. We\nobserve similar patterns for image classification, where simply looking at the\ninfluence distributions reveals the presence of near-duplicates in CIFAR-10.\nOur findings highlight that memorization stems from complex interactions across\ntraining data and is better captured by the full influence distribution than by\nself-influence alone.", "AI": {"tldr": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u8bb0\u5fc6\u884c\u4e3a\u4e0d\u4ec5\u53d7\u81ea\u8eab\u5f71\u54cd\uff08self-influence\uff09\uff0c\u8fd8\u53d7\u5230\u8bad\u7ec3\u96c6\u4e2d\u5176\u4ed6\u6837\u672c\uff08\u5982\u8fd1\u4f3c\u526f\u672c\uff09\u7684\u663e\u8457\u5f71\u54cd\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4ec5\u5173\u6ce8\u81ea\u6211\u5f71\u54cd\u53ef\u80fd\u4f1a\u4f4e\u4f30\u8bb0\u5fc6\u5316\u5e26\u6765\u7684\u5b9e\u9645\u98ce\u9669\uff0c\u800c\u901a\u8fc7\u5206\u6790\u5b8c\u6574\u7684\u5f71\u54cd\u529b\u5206\u5e03\u53ef\u4ee5\u66f4\u5168\u9762\u5730\u7406\u89e3\u8bb0\u5fc6\u5316\u73b0\u8c61\u53ca\u5176\u6f5c\u5728\u95ee\u9898\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4f1a\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u6837\u672c\uff0c\u8fd9\u5f15\u53d1\u4e86\u9690\u79c1\u548c\u6cdb\u5316\u65b9\u9762\u7684\u62c5\u5fe7\u3002\u867d\u7136\u53cd\u4e8b\u5b9e\u81ea\u6211\u5f71\u54cd\uff08counterfactual self-influence\uff09\u662f\u7814\u7a76\u8bb0\u5fc6\u5316\u7684\u5e38\u7528\u6307\u6807\uff0c\u4f46\u5df2\u6709\u7814\u7a76\u8868\u660e\uff0c\u8bb0\u5fc6\u5316\u8fd8\u53d7\u5230\u5176\u4ed6\u56e0\u7d20\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u8bad\u7ec3\u96c6\u4e2d\u7684\uff08\u8fd1\u4f3c\uff09\u526f\u672c\u6837\u672c\u7684\u4f5c\u7528\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u7684\u65b9\u6cd5\u6765\u7814\u7a76\u8bb0\u5fc6\u5316\u73b0\u8c61\u3002", "method": "\u672c\u7814\u7a76\u5c06\u53cd\u4e8b\u5b9e\u5f71\u54cd\u89c6\u4e3a\u4e00\u4e2a\u5206\u5e03\u91cf\uff0c\u8003\u8651\u6240\u6709\u8bad\u7ec3\u6837\u672c\u5982\u4f55\u5171\u540c\u5f71\u54cd\u67d0\u4e2a\u6837\u672c\u7684\u8bb0\u5fc6\u5316\u7a0b\u5ea6\u3002\u5bf9\u4e8e\u4e00\u4e2a\u5c0f\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u8ba1\u7b97\u4e86\u8bad\u7ec3\u6837\u672c\u4e4b\u95f4\u7684\u5b8c\u6574\u5f71\u54cd\u5206\u5e03\uff0c\u5e76\u5206\u6790\u4e86\u5176\u7279\u6027\u3002\u540c\u65f6\uff0c\u8fd8\u5c06\u8fd9\u79cd\u65b9\u6cd5\u5e94\u7528\u4e8e\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\uff08\u5982CIFAR-10\u6570\u636e\u96c6\uff09\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4ec5\u5173\u6ce8\u81ea\u6211\u5f71\u54cd\u53ef\u80fd\u4f1a\u4e25\u91cd\u4f4e\u4f30\u4e0e\u8bb0\u5fc6\u5316\u76f8\u5173\u7684\u5b9e\u9645\u98ce\u9669\u3002\uff08\u8fd1\u4f3c\uff09\u526f\u672c\u6837\u672c\u7684\u5b58\u5728\u4f1a\u663e\u8457\u964d\u4f4e\u81ea\u6211\u5f71\u54cd\uff0c\u4f46\u8fd9\u4e9b\u6837\u672c\u5b9e\u9645\u4e0a\u662f\uff08\u8fd1\u4f3c\uff09\u53ef\u63d0\u53d6\u7684\u3002\u5728\u56fe\u50cf\u5206\u7c7b\u4e2d\uff0c\u901a\u8fc7\u5206\u6790\u5f71\u54cd\u5206\u5e03\u53ef\u4ee5\u63ed\u793aCIFAR-10\u6570\u636e\u96c6\u4e2d\u5b58\u5728\u7684\u8fd1\u4f3c\u526f\u672c\u3002", "conclusion": "\u8bb0\u5fc6\u5316\u73b0\u8c61\u6e90\u4e8e\u8bad\u7ec3\u6570\u636e\u4e4b\u95f4\u7684\u590d\u6742\u4ea4\u4e92\u4f5c\u7528\uff0c\u5b8c\u6574\u7684\u5f71\u54cd\u529b\u5206\u5e03\u6bd4\u5355\u72ec\u7684\u81ea\u6211\u5f71\u54cd\u66f4\u80fd\u51c6\u786e\u6355\u6349\u8bb0\u5fc6\u5316\u7684\u884c\u4e3a\u3002"}}
{"id": "2506.20525", "pdf": "https://arxiv.org/pdf/2506.20525", "abs": "https://arxiv.org/abs/2506.20525", "authors": ["Christian Intern\u00f2", "Andrea Castellani", "Sebastian Schmitt", "Fabio Stella", "Barbara Hammer"], "title": "Industrial Energy Disaggregation with Digital Twin-generated Dataset and Efficient Data Augmentation", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Industrial Non-Intrusive Load Monitoring (NILM) is limited by the scarcity of\nhigh-quality datasets and the complex variability of industrial energy\nconsumption patterns. To address data scarcity and privacy issues, we introduce\nthe Synthetic Industrial Dataset for Energy Disaggregation (SIDED), an\nopen-source dataset generated using Digital Twin simulations. SIDED includes\nthree types of industrial facilities across three different geographic\nlocations, capturing diverse appliance behaviors, weather conditions, and load\nprofiles. We also propose the Appliance-Modulated Data Augmentation (AMDA)\nmethod, a computationally efficient technique that enhances NILM model\ngeneralization by intelligently scaling appliance power contributions based on\ntheir relative impact. We show in experiments that NILM models trained with\nAMDA-augmented data significantly improve the disaggregation of energy\nconsumption of complex industrial appliances like combined heat and power\nsystems. Specifically, in our out-of-sample scenarios, models trained with AMDA\nachieved a Normalized Disaggregation Error of 0.093, outperforming models\ntrained without data augmentation (0.451) and those trained with random data\naugmentation (0.290). Data distribution analyses confirm that AMDA effectively\naligns training and test data distributions, enhancing model generalization.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faSIDED\u6570\u636e\u96c6\u548cAMDA\u65b9\u6cd5\uff0c\u89e3\u51b3\u5de5\u4e1aNILM\u4e2d\u6570\u636e\u7a00\u7f3a\u4e0e\u6a21\u578b\u6cdb\u5316\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528AMDA\u589e\u5f3a\u6570\u636e\u8bad\u7ec3\u7684NILM\u6a21\u578b\u5728\u590d\u6742\u5de5\u4e1a\u8bbe\u5907\u80fd\u8017\u5206\u89e3\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u5de5\u4e1a\u975e\u4fb5\u5165\u5f0f\u8d1f\u8377\u76d1\u6d4b\uff08NILM\uff09\u53d7\u5230\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u532e\u4e4f\u548c\u5de5\u4e1a\u80fd\u8017\u6a21\u5f0f\u590d\u6742\u591a\u53d8\u7684\u9650\u5236\u3002\u4e3a\u6b64\uff0c\u7814\u7a76\u8005\u65e8\u5728\u901a\u8fc7\u751f\u6210\u5408\u6210\u6570\u636e\u96c6\u548c\u6539\u8fdb\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u6765\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u548c\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\uff0c\u540c\u65f6\u63d0\u5347NILM\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "1. \u5f00\u53d1\u4e86\u5f00\u6e90\u5408\u6210\u6570\u636e\u96c6SIDED\uff0c\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u6a21\u62df\u751f\u6210\uff0c\u5305\u542b\u4e09\u79cd\u4e0d\u540c\u5730\u7406\u4f4d\u7f6e\u7684\u5de5\u4e1a\u8bbe\u65bd\uff0c\u6db5\u76d6\u591a\u6837\u5316\u7684\u8bbe\u5907\u884c\u4e3a\u3001\u5929\u6c14\u6761\u4ef6\u548c\u8d1f\u8f7d\u5206\u5e03\u3002\n2. \u63d0\u51fa\u4e86Appliance-Modulated Data Augmentation (AMDA) \u65b9\u6cd5\uff0c\u901a\u8fc7\u667a\u80fd\u8c03\u6574\u8bbe\u5907\u529f\u7387\u8d21\u732e\u6765\u589e\u5f3aNILM\u6a21\u578b\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u8ba1\u7b97\u6548\u7387\u9ad8\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff1a\n1. \u4f7f\u7528AMDA\u589e\u5f3a\u6570\u636e\u8bad\u7ec3\u7684NILM\u6a21\u578b\u5728\u6837\u672c\u5916\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5176\u5f52\u4e00\u5316\u5206\u89e3\u8bef\u5dee\u4e3a0.093\uff0c\u663e\u8457\u4f4e\u4e8e\u65e0\u589e\u5f3a\uff080.451\uff09\u548c\u968f\u673a\u589e\u5f3a\uff080.290\uff09\u7684\u6a21\u578b\u3002\n2. \u6570\u636e\u5206\u5e03\u5206\u6790\u9a8c\u8bc1\u4e86AMDA\u80fd\u591f\u6709\u6548\u5bf9\u9f50\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u5206\u5e03\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SIDED\u6570\u636e\u96c6\u548cAMDA\u65b9\u6cd5\u4e3a\u5de5\u4e1aNILM\u9886\u57df\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u5e76\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u5de5\u4e1a\u8bbe\u5907\u80fd\u8017\u5206\u89e3\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2506.20431", "pdf": "https://arxiv.org/pdf/2506.20431", "abs": "https://arxiv.org/abs/2506.20431", "authors": ["Xing Ma"], "title": "Tackling Data Heterogeneity in Federated Learning through Knowledge Distillation with Inequitable Aggregation", "categories": ["cs.LG"], "comment": "33pages,8figures", "summary": "Federated learning aims to train a global model in a distributed environment\nthat is close to the performance of centralized training. However, issues such\nas client label skew, data quantity skew, and other heterogeneity problems\nseverely degrade the model's performance. Most existing methods overlook the\nscenario where only a small portion of clients participate in training within a\nlarge-scale client setting, whereas our experiments show that this scenario\npresents a more challenging federated learning task. Therefore, we propose a\nKnowledge Distillation with teacher-student Inequitable Aggregation (KDIA)\nstrategy tailored to address the federated learning setting mentioned above,\nwhich can effectively leverage knowledge from all clients. In KDIA, the student\nmodel is the average aggregation of the participating clients, while the\nteacher model is formed by a weighted aggregation of all clients based on three\nfrequencies: participation intervals, participation counts, and data volume\nproportions. During local training, self-knowledge distillation is performed.\nAdditionally, we utilize a generator trained on the server to generate\napproximately independent and identically distributed (IID) data features\nlocally for auxiliary training. We conduct extensive experiments on the\nCIFAR-10/100/CINIC-10 datasets and various heterogeneous settings to evaluate\nKDIA. The results show that KDIA can achieve better accuracy with fewer rounds\nof training, and the improvement is more significant under severe\nheterogeneity.", "AI": {"tldr": "\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u5f53\u53ea\u6709\u5c11\u91cf\u5ba2\u6237\u7aef\u53c2\u4e0e\u8bad\u7ec3\u65f6\uff0c\u6a21\u578b\u6027\u80fd\u4f1a\u53d7\u5230\u4e25\u91cd\u5f71\u54cd\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u77e5\u8bc6\u84b8\u998f\u4e0e\u5e08\u751f\u4e0d\u5e73\u7b49\u805a\u5408\uff08KDIA\uff09\u7b56\u7565\uff0c\u901a\u8fc7\u6709\u6548\u5229\u7528\u6240\u6709\u5ba2\u6237\u7aef\u7684\u77e5\u8bc6\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660e\uff0cKDIA\u5728\u4e25\u91cd\u5f02\u6784\u6027\u60c5\u51b5\u4e0b\u80fd\u4ee5\u66f4\u5c11\u7684\u8bad\u7ec3\u8f6e\u6b21\u5b9e\u73b0\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u5ffd\u89c6\u4e86\u5728\u5927\u89c4\u6a21\u5ba2\u6237\u7aef\u8bbe\u7f6e\u4e2d\uff0c\u4ec5\u5c11\u91cf\u5ba2\u6237\u7aef\u53c2\u4e0e\u8bad\u7ec3\u7684\u60c5\u51b5\uff0c\u8fd9\u79cd\u573a\u666f\u5bf9\u6a21\u578b\u6027\u80fd\u63d0\u51fa\u4e86\u66f4\u5927\u7684\u6311\u6218\u3002", "method": "1. \u63d0\u51fa KDIA \u7b56\u7565\uff1a\n   - \u5b66\u751f\u6a21\u578b\u4e3a\u53c2\u4e0e\u5ba2\u6237\u7aef\u7684\u5e73\u5747\u805a\u5408\u3002\n   - \u6559\u5e08\u6a21\u578b\u57fa\u4e8e\u53c2\u4e0e\u95f4\u9694\u3001\u53c2\u4e0e\u6b21\u6570\u548c\u6570\u636e\u91cf\u6bd4\u4f8b\u8fdb\u884c\u52a0\u6743\u805a\u5408\u3002\n2. \u5728\u672c\u5730\u8bad\u7ec3\u4e2d\u5f15\u5165\u81ea\u77e5\u8bc6\u84b8\u998f\u3002\n3. \u5229\u7528\u670d\u52a1\u5668\u4e0a\u7684\u751f\u6210\u5668\u751f\u6210\u8fd1\u4f3c\u72ec\u7acb\u540c\u5206\u5e03 (IID) \u7684\u6570\u636e\u7279\u5f81\uff0c\u7528\u4e8e\u8f85\u52a9\u8bad\u7ec3\u3002", "result": "\u5728CIFAR-10/100/CINIC-10\u6570\u636e\u96c6\u53ca\u5404\u79cd\u5f02\u6784\u73af\u5883\u4e0b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660eKDIA\u53ef\u4ee5\u5728\u66f4\u5c11\u7684\u8bad\u7ec3\u8f6e\u6b21\u4e2d\u8fbe\u5230\u66f4\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u7279\u522b\u662f\u5728\u4e25\u91cd\u5f02\u6784\u60c5\u51b5\u4e0b\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u63d0\u51fa\u7684KDIA\u7b56\u7565\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u8054\u90a6\u5b66\u4e60\u4e2d\u5ba2\u6237\u7aef\u53c2\u4e0e\u6709\u9650\u53ca\u6570\u636e\u5f02\u6784\u6027\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u5e76\u51cf\u5c11\u4e86\u8bad\u7ec3\u8f6e\u6b21\u9700\u6c42\u3002"}}
{"id": "2506.20441", "pdf": "https://arxiv.org/pdf/2506.20441", "abs": "https://arxiv.org/abs/2506.20441", "authors": ["Antoine Caradot", "R\u00e9mi Emonet", "Amaury Habrard", "Abdel-Rahim Mezidi", "Marc Sebban"], "title": "M\u00e9thode de quadrature pour les PINNs fond\u00e9e th\u00e9oriquement sur la hessienne des r\u00e9siduels", "categories": ["cs.LG"], "comment": "10 pages. In French. Comments are welcome", "summary": "Physics-informed Neural Networks (PINNs) have emerged as an efficient way to\nlearn surrogate neural solvers of PDEs by embedding the physical model in the\nloss function and minimizing its residuals using automatic differentiation at\nso-called collocation points. Originally uniformly sampled, the choice of the\nlatter has been the subject of recent advances leading to adaptive sampling\nrefinements. In this paper, we propose a new quadrature method for\napproximating definite integrals based on the hessian of the considered\nfunction, and that we leverage to guide the selection of the collocation points\nduring the training process of PINNs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51fd\u6570\u6d77\u68ee\u77e9\u9635\u7684\u65b0\u79ef\u5206\u65b9\u6cd5\uff0c\u7528\u4e8e\u6307\u5bfcPINNs\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u914d\u7f6e\u70b9\u7684\u9009\u62e9\u3002", "motivation": "\u73b0\u6709\u7684PINNs\u901a\u8fc7\u5728\u635f\u5931\u51fd\u6570\u4e2d\u5d4c\u5165\u7269\u7406\u6a21\u578b\u5e76\u4f7f\u7528\u81ea\u52a8\u5fae\u5206\u6700\u5c0f\u5316\u6b8b\u5dee\u6765\u5b66\u4e60PDE\u7684\u4ee3\u7406\u795e\u7ecf\u89e3\u7b97\u5668\uff0c\u4f46\u5bf9\u5176\u914d\u7f6e\u70b9\u7684\u9009\u62e9\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u6d77\u68ee\u77e9\u9635\u7684\u6c42\u79ef\u65b9\u6cd5\uff0c\u7528\u4ee5\u6307\u5bfcPINNs\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u914d\u7f6e\u70b9\u7684\u9009\u62e9\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u66f4\u6709\u6548\u5730\u9009\u62e9\u914d\u7f6e\u70b9\uff0c\u4ece\u800c\u63d0\u9ad8PINNs\u7684\u6027\u80fd\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u4e3a\u63d0\u9ad8PINNs\u7684\u6c42\u89e3\u6548\u7387\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u884c\u7684\u65b9\u5411\u3002"}}
{"id": "2506.20494", "pdf": "https://arxiv.org/pdf/2506.20494", "abs": "https://arxiv.org/abs/2506.20494", "authors": ["Qihang Jin", "Enze Ge", "Yuhang Xie", "Hongying Luo", "Junhao Song", "Ziqian Bi", "Chia Xin Liang", "Jibin Guan", "Joe Yeong", "Junfeng Hao"], "title": "Multimodal Representation Learning and Fusion", "categories": ["cs.LG", "cs.MM"], "comment": null, "summary": "Multi-modal learning is a fast growing area in artificial intelligence. It\ntries to help machines understand complex things by combining information from\ndifferent sources, like images, text, and audio. By using the strengths of each\nmodality, multi-modal learning allows AI systems to build stronger and richer\ninternal representations. These help machines better interpretation, reasoning,\nand making decisions in real-life situations. This field includes core\ntechniques such as representation learning (to get shared features from\ndifferent data types), alignment methods (to match information across\nmodalities), and fusion strategies (to combine them by deep learning models).\nAlthough there has been good progress, some major problems still remain. Like\ndealing with different data formats, missing or incomplete inputs, and\ndefending against adversarial attacks. Researchers now are exploring new\nmethods, such as unsupervised or semi-supervised learning, AutoML tools, to\nmake models more efficient and easier to scale. And also more attention on\ndesigning better evaluation metrics or building shared benchmarks, make it\neasier to compare model performance across tasks and domains. As the field\ncontinues to grow, multi-modal learning is expected to improve many areas:\ncomputer vision, natural language processing, speech recognition, and\nhealthcare. In the future, it may help to build AI systems that can understand\nthe world in a way more like humans, flexible, context aware, and able to deal\nwith real-world complexity.", "AI": {"tldr": "\u591a\u6a21\u6001\u5b66\u4e60\u901a\u8fc7\u7ed3\u5408\u4e0d\u540c\u6765\u6e90\u7684\u4fe1\u606f\uff08\u5982\u56fe\u50cf\u3001\u6587\u672c\u548c\u97f3\u9891\uff09\u6765\u5e2e\u52a9\u673a\u5668\u7406\u89e3\u590d\u6742\u7684\u4e8b\u7269\u3002\u5c3d\u7ba1\u53d6\u5f97\u4e86\u826f\u597d\u8fdb\u5c55\uff0c\u4f46\u4ecd\u5b58\u5728\u4e00\u4e9b\u4e3b\u8981\u95ee\u9898\uff0c\u4f8b\u5982\u5904\u7406\u4e0d\u540c\u7684\u6570\u636e\u683c\u5f0f\u3001\u4e0d\u5b8c\u6574\u8f93\u5165\u548c\u5bf9\u6297\u6027\u653b\u51fb\u7b49\u3002\u7814\u7a76\u4eba\u5458\u6b63\u5728\u63a2\u7d22\u65b0\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u8bbe\u8ba1\u66f4\u597d\u7684\u8bc4\u4f30\u6307\u6807\u548c\u57fa\u51c6\u3002\u672a\u6765\uff0c\u591a\u6a21\u6001\u5b66\u4e60\u6709\u671b\u6539\u5584\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u8bed\u97f3\u8bc6\u522b\u548c\u533b\u7597\u4fdd\u5065\u7b49\u9886\u57df\uff0c\u5e76\u53ef\u80fd\u5efa\u7acb\u66f4\u50cf\u4eba\u7c7b\u7406\u89e3\u4e16\u754c\u7684AI\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u9700\u8981\u7406\u89e3\u548c\u5904\u7406\u590d\u6742\u4e8b\u7269\uff0c\u800c\u5355\u4e00\u6a21\u6001\u7684\u6570\u636e\u4e0d\u8db3\u4ee5\u6ee1\u8db3\u9700\u6c42\u3002\u591a\u6a21\u6001\u5b66\u4e60\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u4fe1\u606f\u6e90\u7684\u5f3a\u9879\uff0c\u4f7f\u5f97AI\u7cfb\u7edf\u80fd\u591f\u6784\u5efa\u66f4\u5f3a\u5927\u548c\u4e30\u5bcc\u7684\u5185\u90e8\u8868\u793a\uff0c\u4ece\u800c\u66f4\u597d\u5730\u89e3\u91ca\u3001\u63a8\u7406\u548c\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u505a\u51b3\u7b56\u3002", "method": "\u591a\u6a21\u6001\u5b66\u4e60\u7684\u6838\u5fc3\u6280\u672f\u5305\u62ec\uff1a\u8868\u793a\u5b66\u4e60\uff08\u4ece\u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u4e2d\u83b7\u53d6\u5171\u4eab\u7279\u5f81\uff09\u3001\u5bf9\u9f50\u65b9\u6cd5\uff08\u8de8\u6a21\u6001\u5339\u914d\u4fe1\u606f\uff09\u548c\u878d\u5408\u7b56\u7565\uff08\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7ec4\u5408\u4fe1\u606f\uff09\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8005\u6b63\u5728\u63a2\u7d22\u65e0\u76d1\u7763\u6216\u534a\u76d1\u7763\u5b66\u4e60\u4ee5\u53caAutoML\u5de5\u5177\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "result": "\u591a\u6a21\u6001\u5b66\u4e60\u5df2\u7ecf\u5728\u8bb8\u591a\u9886\u57df\u53d6\u5f97\u826f\u597d\u8fdb\u5c55\uff0c\u4f46\u4ecd\u7136\u9762\u4e34\u8bf8\u5982\u5904\u7406\u4e0d\u540c\u6570\u636e\u683c\u5f0f\u3001\u7f3a\u5931\u6216\u4e0d\u5b8c\u6574\u7684\u8f93\u5165\u4ee5\u53ca\u9632\u5fa1\u5bf9\u6297\u6027\u653b\u51fb\u7b49\u95ee\u9898\u3002\u540c\u65f6\uff0c\u65b0\u7684\u65b9\u6cd5\u548c\u6280\u672f\u6b63\u5728\u88ab\u5f00\u53d1\uff0c\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u5e76\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u968f\u7740\u591a\u6a21\u6001\u5b66\u4e60\u9886\u57df\u7684\u6301\u7eed\u53d1\u5c55\uff0c\u5b83\u6709\u671b\u6539\u8fdb\u8ba1\u7b97\u673a\u89c6\u89c9\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u8bed\u97f3\u8bc6\u522b\u548c\u533b\u7597\u4fdd\u5065\u7b49\u591a\u4e2a\u9886\u57df\u3002\u672a\u6765\uff0c\u591a\u6a21\u6001\u5b66\u4e60\u53ef\u80fd\u6709\u52a9\u4e8e\u5efa\u7acb\u66f4\u7075\u6d3b\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u4e14\u80fd\u591f\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u590d\u6742\u6027\u7684AI\u7cfb\u7edf\uff0c\u4f7f\u5176\u66f4\u63a5\u8fd1\u4eba\u7c7b\u7406\u89e3\u4e16\u754c\u7684\u65b9\u5f0f\u3002"}}
{"id": "2506.20511", "pdf": "https://arxiv.org/pdf/2506.20511", "abs": "https://arxiv.org/abs/2506.20511", "authors": ["Arno Geimer", "Karthick Panner Selvam", "Beltran Fiz Pontiveros"], "title": "Collaborative Batch Size Optimization for Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Federated Learning (FL) is a decentralized collaborative Machine Learning\nframework for training models without collecting data in a centralized\nlocation. It has seen application across various disciplines, from helping\nmedical diagnoses in hospitals to detecting fraud in financial transactions. In\nthis paper, we focus on improving the local training process through hardware\nusage optimization. While participants in a federation might share the hardware\nthey are training on, since there is no information exchange between them,\ntheir training process can be hindered by an improper training configuration.\nTaking advantage of the parallel processing inherent to Federated Learning, we\nuse a greedy randomized search to optimize local batch sizes for the best\ntraining settings across all participants. Our results show that against\ndefault parameter settings, our method improves convergence speed while staying\nnearly on par with the case where local parameters are optimized.", "AI": {"tldr": "\u672c\u8bba\u6587\u901a\u8fc7\u8d2a\u5fc3\u968f\u673a\u641c\u7d22\u4f18\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u5404\u53c2\u4e0e\u65b9\u7684\u672c\u5730\u6279\u91cf\u5927\u5c0f\uff0c\u4ece\u800c\u63d0\u5347\u8bad\u7ec3\u914d\u7f6e\u6548\u7387\u548c\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u53c2\u4e0e\u8005\u53ef\u80fd\u5171\u4eab\u8bad\u7ec3\u786c\u4ef6\uff0c\u4f46\u7531\u4e8e\u6ca1\u6709\u4fe1\u606f\u4ea4\u6362\uff0c\u4e0d\u6070\u5f53\u7684\u8bad\u7ec3\u914d\u7f6e\u4f1a\u963b\u788d\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u56e0\u6b64\u9700\u8981\u4f18\u5316\u786c\u4ef6\u4f7f\u7528\u4ee5\u6539\u8fdb\u672c\u5730\u8bad\u7ec3\u8fc7\u7a0b\u3002", "method": "\u5229\u7528\u8054\u90a6\u5b66\u4e60\u56fa\u6709\u7684\u5e76\u884c\u5904\u7406\u80fd\u529b\uff0c\u91c7\u7528\u8d2a\u5fc3\u968f\u673a\u641c\u7d22\u65b9\u6cd5\u4f18\u5316\u6240\u6709\u53c2\u4e0e\u8005\u7684\u672c\u5730\u6279\u91cf\u5927\u5c0f\uff0c\u4ee5\u627e\u5230\u6700\u4f73\u8bad\u7ec3\u8bbe\u7f6e\u3002", "result": "\u76f8\u8f83\u4e8e\u9ed8\u8ba4\u53c2\u6570\u8bbe\u7f6e\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6536\u655b\u901f\u5ea6\uff0c\u5e76\u4e14\u51e0\u4e4e\u4e0e\u672c\u5730\u53c2\u6570\u7ecf\u8fc7\u4f18\u5316\u7684\u60c5\u51b5\u6301\u5e73\u3002", "conclusion": "\u4f18\u5316\u672c\u5730\u6279\u91cf\u5927\u5c0f\u53ef\u4ee5\u6709\u6548\u6539\u5584\u8054\u90a6\u5b66\u4e60\u7684\u8bad\u7ec3\u6548\u7387\uff0c\u5728\u4e0d\u589e\u52a0\u592a\u591a\u590d\u6742\u6027\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u6536\u655b\u901f\u5ea6\u3002"}}
{"id": "2506.20518", "pdf": "https://arxiv.org/pdf/2506.20518", "abs": "https://arxiv.org/abs/2506.20518", "authors": ["Arno Geimer", "Beltran Fiz Pontiveros", "Radu State"], "title": "WallStreetFeds: Client-Specific Tokens as Investment Vehicles in Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) is a collaborative machine learning paradigm which\nallows participants to collectively train a model while training data remains\nprivate. This paradigm is especially beneficial for sectors like finance, where\ndata privacy, security and model performance are paramount. FL has been\nextensively studied in the years following its introduction, leading to, among\nothers, better performing collaboration techniques, ways to defend against\nother clients trying to attack the model, and contribution assessment methods.\nAn important element in for-profit Federated Learning is the development of\nincentive methods to determine the allocation and distribution of rewards for\nparticipants. While numerous methods for allocation have been proposed and\nthoroughly explored, distribution frameworks remain relatively understudied. In\nthis paper, we propose a novel framework which introduces client-specific\ntokens as investment vehicles within the FL ecosystem. Our framework aims to\naddress the limitations of existing incentive schemes by leveraging a\ndecentralized finance (DeFi) platform and automated market makers (AMMs) to\ncreate a more flexible and scalable reward distribution system for\nparticipants, and a mechanism for third parties to invest in the federation\nlearning process.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u5f15\u5165\u5ba2\u6237\u7279\u5b9a\u7684\u4ee3\u5e01\u4f5c\u4e3a\u6295\u8d44\u5de5\u5177\uff0c\u5e76\u901a\u8fc7DeFi\u5e73\u53f0\u548cAMM\u521b\u5efa\u66f4\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u7684\u5956\u52b1\u5206\u914d\u7cfb\u7edf\u53ca\u7b2c\u4e09\u65b9\u6295\u8d44\u673a\u5236\u3002", "motivation": "\u5f53\u524d\u5728\u76c8\u5229\u6027\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u867d\u7136\u5df2\u7ecf\u63d0\u51fa\u4e86\u8bb8\u591a\u5206\u914d\u65b9\u6cd5\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u4ecd\u5b58\u5728\u5c40\u9650\u6027\uff0c\u800c\u5956\u52b1\u5206\u914d\u6846\u67b6\u7684\u7814\u7a76\u76f8\u5bf9\u8f83\u5c11\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u4f7f\u7528\u5ba2\u6237\u7279\u5b9a\u7684\u4ee3\u5e01\u4f5c\u4e3a\u6295\u8d44\u5de5\u5177\uff0c\u5e76\u7ed3\u5408\u53bb\u4e2d\u5fc3\u5316\u91d1\u878d\uff08DeFi\uff09\u5e73\u53f0\u548c\u81ea\u52a8\u5316\u505a\u5e02\u5546\uff08AMMs\uff09\uff0c\u6784\u5efa\u66f4\u7075\u6d3b\u548c\u53ef\u6269\u5c55\u7684\u5956\u52b1\u5206\u914d\u7cfb\u7edf\uff0c\u540c\u65f6\u5141\u8bb8\u7b2c\u4e09\u65b9\u6295\u8d44\u4e8e\u8054\u90a6\u5b66\u4e60\u8fc7\u7a0b\u3002", "result": "\u8be5\u6846\u67b6\u53ef\u4ee5\u514b\u670d\u73b0\u6709\u6fc0\u52b1\u65b9\u6848\u7684\u9650\u5236\uff0c\u63d0\u4f9b\u66f4\u7075\u6d3b\u548c\u53ef\u6269\u5c55\u7684\u5956\u52b1\u5206\u914d\u65b9\u5f0f\uff0c\u5e76\u4e3a\u7b2c\u4e09\u65b9\u63d0\u4f9b\u6295\u8d44\u9014\u5f84\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u4ee3\u5e01\u548cDeFi\u7684\u5956\u52b1\u5206\u914d\u6846\u67b6\u4e3a\u8054\u90a6\u5b66\u4e60\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u548c\u53ef\u6269\u5c55\u7684\u5956\u52b1\u673a\u5236\uff0c\u6709\u52a9\u4e8e\u5438\u5f15\u66f4\u591a\u7684\u53c2\u4e0e\u8005\u5e76\u63d0\u5347\u7cfb\u7edf\u7684\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2506.20520", "pdf": "https://arxiv.org/pdf/2506.20520", "abs": "https://arxiv.org/abs/2506.20520", "authors": ["Charles Arnal", "Ga\u00ebtan Narozniak", "Vivien Cabannes", "Yunhao Tang", "Julia Kempe", "Remi Munos"], "title": "Asymmetric REINFORCE for off-Policy Reinforcement Learning: Balancing positive and negative rewards", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Reinforcement learning (RL) is increasingly used to align large language\nmodels (LLMs). Off-policy methods offer greater implementation simplicity and\ndata efficiency than on-policy techniques, but often result in suboptimal\nperformance. In this work, we study the intermediate range of algorithms\nbetween off-policy RL and supervised fine-tuning by analyzing a simple\noff-policy REINFORCE algorithm, where the advantage is defined as $A=r-V$, with\n$r$ a reward and $V$ some tunable baseline. Intuitively, lowering $V$\nemphasizes high-reward samples, while raising it penalizes low-reward ones more\nheavily. We first provide a theoretical analysis of this off-policy REINFORCE\nalgorithm, showing that when the baseline $V$ lower-bounds the expected reward,\nthe algorithm enjoys a policy improvement guarantee. Our analysis reveals that\nwhile on-policy updates can safely leverage both positive and negative signals,\noff-policy updates benefit from focusing more on positive rewards than on\nnegative ones. We validate our findings experimentally in a controlled\nstochastic bandit setting and through fine-tuning state-of-the-art LLMs on\nreasoning tasks.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4ecb\u4e8e\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u548c\u76d1\u7763\u5fae\u8c03\u4e4b\u95f4\u7684\u7b97\u6cd5\u8303\u56f4\uff0c\u901a\u8fc7\u5206\u6790\u4e00\u4e2a\u7b80\u5355\u7684\u79bb\u7ebfREINFORCE\u7b97\u6cd5\uff0c\u53d1\u73b0\u5f53\u57fa\u7ebfV\u4e0b\u754c\u4e3a\u671f\u671b\u5956\u52b1\u65f6\uff0c\u8be5\u7b97\u6cd5\u5177\u6709\u7b56\u7565\u6539\u8fdb\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5728\u79bb\u7ebf\u66f4\u65b0\u4e2d\u66f4\u5173\u6ce8\u6b63\u5956\u52b1\u6bd4\u8d1f\u5956\u52b1\u66f4\u6709\u76ca\u3002", "motivation": "\u79bb\u7ebf\u65b9\u6cd5\u76f8\u8f83\u4e8e\u5728\u7ebf\u65b9\u6cd5\u5728\u5b9e\u73b0\u7b80\u5355\u6027\u548c\u6570\u636e\u6548\u7387\u65b9\u9762\u66f4\u5177\u4f18\u52bf\uff0c\u4f46\u901a\u5e38\u6027\u80fd\u8f83\u5dee\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u4ecb\u4e8e\u79bb\u7ebfRL\u548c\u76d1\u7763\u5fae\u8c03\u4e4b\u95f4\u7684\u7b97\u6cd5\u3002", "method": "\u7814\u7a76\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u79bb\u7ebfREINFORCE\u7b97\u6cd5\uff0c\u5176\u4e2d\u4f18\u52bf\u51fd\u6570\u5b9a\u4e49\u4e3aA=r-V\uff0c\u5e76\u5206\u6790\u4e86\u57fa\u7ebfV\u5bf9\u6837\u672c\u7684\u5f71\u54cd\u3002\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u5e76\u63ed\u793a\u4e86\u79bb\u7ebf\u66f4\u65b0\u805a\u7126\u6b63\u5956\u52b1\u7684\u91cd\u8981\u6027\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\u5f53\u57fa\u7ebf\u4e0b\u754c\u4e3a\u671f\u671b\u5956\u52b1\u65f6\uff0c\u7b97\u6cd5\u5177\u6709\u7b56\u7565\u6539\u8fdb\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u5728\u53d7\u63a7\u968f\u673aBandit\u8bbe\u7f6e\u548cLLM\u63a8\u7406\u4efb\u52a1\u5fae\u8c03\u4e2d\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u53d1\u73b0\u3002", "conclusion": "\u79bb\u7ebf\u66f4\u65b0\u5e94\u66f4\u5173\u6ce8\u6b63\u5956\u52b1\u800c\u975e\u8d1f\u5956\u52b1\uff0c\u8fd9\u4e0e\u5728\u7ebf\u66f4\u65b0\u53ef\u4ee5\u5b89\u5168\u5229\u7528\u6b63\u8d1f\u4fe1\u53f7\u4e0d\u540c\u3002"}}
{"id": "2506.20537", "pdf": "https://arxiv.org/pdf/2506.20537", "abs": "https://arxiv.org/abs/2506.20537", "authors": ["R. Sharma", "M. Raissi", "Y. B. Guo"], "title": "Physics-Informed Machine Learning Regulated by Finite Element Analysis for Simulation Acceleration of Laser Powder Bed Fusion", "categories": ["cs.LG"], "comment": null, "summary": "Efficient simulation of Laser Powder Bed Fusion (LPBF) is crucial for process\nprediction due to the lasting issue of high computation cost using traditional\nnumerical methods such as finite element analysis (FEA). This study presents an\nefficient modeling framework termed FEA-Regulated Physics-Informed Neural\nNetwork (FEA-PINN) to accelerate the thermal field prediction in a LPBF process\nwhile maintaining the FEA accuracy. A novel dynamic material updating strategy\nis developed to capture the dynamic phase change of powder-liquid-solid in the\nPINN model. The PINN model incorporates temperature-dependent material\nproperties and phase change behavior using the apparent heat capacity method.\nWhile the PINN model demonstrates high accuracy with a small training data and\nenables generalization of new process parameters via transfer learning, it\nfaces the challenge of high computation cost in time-dependent problems due to\nthe residual accumulation. To overcome this issue, the FEA-PINN framework\nintegrates corrective FEA simulations during inference to enforce physical\nconsistency and reduce error drift. A comparative analysis shows that FEA-PINN\nachieves equivalent accuracy to FEA while significantly reducing computational\ncost. The framework has been validated using the benchmark FEA data and\ndemonstrated through single-track scanning in LPBF.", "AI": {"tldr": "FEA-PINN\u662f\u4e00\u79cd\u7ed3\u5408\u6709\u9650\u5143\u5206\u6790\u548c\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\u7684\u9ad8\u6548\u5efa\u6a21\u6846\u67b6\uff0c\u7528\u4e8e\u52a0\u901f\u6fc0\u5149\u7c89\u672b\u5e8a\u7194\u878d\uff08LPBF\uff09\u8fc7\u7a0b\u4e2d\u7684\u70ed\u573a\u9884\u6d4b\uff0c\u540c\u65f6\u4fdd\u6301FEA\u7684\u51c6\u786e\u6027\u3002\u901a\u8fc7\u5f15\u5165\u52a8\u6001\u6750\u6599\u66f4\u65b0\u7b56\u7565\u548c\u6821\u6b63\u7684FEA\u6a21\u62df\uff0c\u8be5\u6846\u67b6\u5728\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u4fdd\u8bc1\u4e86\u7269\u7406\u4e00\u81f4\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u6570\u503c\u65b9\u6cd5\u5982\u6709\u9650\u5143\u5206\u6790\uff08FEA\uff09\u5728\u6a21\u62dfLPBF\u8fc7\u7a0b\u4e2d\u5b58\u5728\u9ad8\u8ba1\u7b97\u6210\u672c\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u5efa\u6a21\u65b9\u6cd5\u6765\u52a0\u901f\u70ed\u573a\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFEA-Regulated Physics-Informed Neural Network (FEA-PINN)\u7684\u5efa\u6a21\u6846\u67b6\uff0c\u96c6\u6210\u4e86\u6e29\u5ea6\u76f8\u5173\u7684\u6750\u6599\u7279\u6027\u548c\u76f8\u53d8\u884c\u4e3a\uff0c\u5e76\u91c7\u7528\u4e86\u52a8\u6001\u6750\u6599\u66f4\u65b0\u7b56\u7565\u3002\u6b64\u5916\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u901a\u8fc7\u96c6\u6210\u6821\u6b63\u7684FEA\u6a21\u62df\u6765\u5f3a\u5236\u6267\u884c\u7269\u7406\u4e00\u81f4\u6027\u548c\u51cf\u5c11\u8bef\u5dee\u6f02\u79fb\u3002", "result": "FEA-PINN\u6846\u67b6\u5728\u5355\u8f68\u626b\u63cf\u7684LPBF\u8fc7\u7a0b\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\u80fd\u591f\u8fbe\u5230\u4e0eFEA\u76f8\u5f53\u7684\u7cbe\u5ea6\u3002", "conclusion": "FEA-PINN\u6846\u67b6\u4e3aLPBF\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u70ed\u573a\u9884\u6d4b\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u7cbe\u5ea6\u548c\u7269\u7406\u4e00\u81f4\u6027\u3002"}}
{"id": "2506.20543", "pdf": "https://arxiv.org/pdf/2506.20543", "abs": "https://arxiv.org/abs/2506.20543", "authors": ["Sanne van Kempen", "Jaron Sanders", "Fiona Sloothaak", "Maarten G. Wolf"], "title": "Demonstration of effective UCB-based routing in skill-based queues on real-world data", "categories": ["cs.LG", "math.OC", "60K25, 93E35"], "comment": null, "summary": "This paper is about optimally controlling skill-based queueing systems such\nas data centers, cloud computing networks, and service systems. By means of a\ncase study using a real-world data set, we investigate the practical\nimplementation of a recently developed reinforcement learning algorithm for\noptimal customer routing. Our experiments show that the algorithm efficiently\nlearns and adapts to changing environments and outperforms static benchmark\npolicies, indicating its potential for live implementation. We also augment the\nreal-world applicability of this algorithm by introducing a new heuristic\nrouting rule to reduce delays. Moreover, we show that the algorithm can\noptimize for multiple objectives: next to payoff maximization, secondary\nobjectives such as server load fairness and customer waiting time reduction can\nbe incorporated. Tuning parameters are used for balancing inherent performance\ntrade--offs. Lastly, we investigate the sensitivity to estimation errors and\nparameter tuning, providing valuable insights for implementing adaptive routing\nalgorithms in complex real-world queueing systems.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5728\u6570\u636e\u4e2d\u5fc3\u3001\u4e91\u8ba1\u7b97\u7f51\u7edc\u548c\u670d\u52a1\u7cfb\u7edf\u7b49\u57fa\u4e8e\u6280\u80fd\u7684\u6392\u961f\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u6700\u4f18\u63a7\u5236\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u96c6\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u63a2\u8ba8\u4e86\u4e00\u79cd\u65b0\u5f00\u53d1\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u6700\u4f18\u5ba2\u6237\u8def\u7531\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u80fd\u9ad8\u6548\u5b66\u4e60\u5e76\u9002\u5e94\u53d8\u5316\u73af\u5883\uff0c\u4f18\u4e8e\u9759\u6001\u57fa\u51c6\u7b56\u7565\uff0c\u5e76\u5177\u6709\u5b9e\u65f6\u5b9e\u65bd\u6f5c\u529b\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u542f\u53d1\u5f0f\u8def\u7531\u89c4\u5219\u4ee5\u51cf\u5c11\u5ef6\u8fdf\uff0c\u589e\u5f3a\u4e86\u7b97\u6cd5\u7684\u5b9e\u9645\u5e94\u7528\u6027\u3002\u8be5\u7b97\u6cd5\u8fd8\u53ef\u4ee5\u4f18\u5316\u591a\u4e2a\u76ee\u6807\uff0c\u5305\u62ec\u6536\u76ca\u6700\u5927\u5316\u3001\u670d\u52a1\u5668\u8d1f\u8f7d\u516c\u5e73\u6027\u548c\u51cf\u5c11\u5ba2\u6237\u7b49\u5f85\u65f6\u95f4\u7b49\uff0c\u540c\u65f6\u5229\u7528\u8c03\u4f18\u53c2\u6570\u5e73\u8861\u6027\u80fd\u6743\u8861\u3002\u6700\u540e\uff0c\u7814\u7a76\u4e86\u8be5\u7b97\u6cd5\u5bf9\u4f30\u8ba1\u8bef\u5dee\u548c\u53c2\u6570\u8c03\u4f18\u7684\u654f\u611f\u6027\uff0c\u4e3a\u5728\u590d\u6742\u73b0\u5b9e\u6392\u961f\u7cfb\u7edf\u4e2d\u5b9e\u65bd\u81ea\u9002\u5e94\u8def\u7531\u7b97\u6cd5\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002", "motivation": "\u5f53\u524d\u5728\u57fa\u4e8e\u6280\u80fd\u7684\u6392\u961f\u7cfb\u7edf\uff08\u5982\u6570\u636e\u4e2d\u5fc3\u3001\u4e91\u8ba1\u7b97\u7f51\u7edc\u548c\u670d\u52a1\u7cfb\u7edf\uff09\u4e2d\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u9002\u5e94\u52a8\u6001\u73af\u5883\u5e76\u4f18\u5316\u591a\u76ee\u6807\u7684\u5ba2\u6237\u8def\u7531\u65b9\u6cd5\u3002\u800c\u4f20\u7edf\u7684\u9759\u6001\u7b56\u7565\u53ef\u80fd\u65e0\u6cd5\u6ee1\u8db3\u8fd9\u4e00\u9700\u6c42\uff0c\u56e0\u6b64\u6709\u5fc5\u8981\u63a2\u7d22\u548c\u9a8c\u8bc1\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u5b9e\u9645\u6548\u679c\u548c\u9002\u7528\u6027\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u4e00\u4e2a\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u96c6\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5e94\u7528\u4e86\u4e00\u79cd\u65b0\u5f00\u53d1\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u6765\u89e3\u51b3\u6700\u4f18\u5ba2\u6237\u8def\u7531\u95ee\u9898\u3002\u4e3a\u4e86\u63d0\u9ad8\u7b97\u6cd5\u7684\u5b9e\u9645\u5e94\u7528\u80fd\u529b\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u542f\u53d1\u5f0f\u8def\u7531\u89c4\u5219\u4ee5\u51cf\u5c11\u5ef6\u8fdf\u3002\u6b64\u5916\uff0c\u7814\u7a76\u5c55\u793a\u4e86\u8be5\u7b97\u6cd5\u5982\u4f55\u901a\u8fc7\u8c03\u6574\u53c2\u6570\u6765\u5e73\u8861\u4e0d\u540c\u76ee\u6807\uff08\u5982\u6536\u76ca\u6700\u5927\u5316\u3001\u670d\u52a1\u5668\u8d1f\u8f7d\u516c\u5e73\u6027\u548c\u5ba2\u6237\u7b49\u5f85\u65f6\u95f4\u51cf\u5c11\uff09\u3002\u6700\u540e\uff0c\u5206\u6790\u4e86\u8be5\u7b97\u6cd5\u5bf9\u4f30\u8ba1\u8bef\u5dee\u548c\u53c2\u6570\u8c03\u4f18\u7684\u654f\u611f\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u53ef\u4ee5\u9ad8\u6548\u5730\u5b66\u4e60\u548c\u9002\u5e94\u53d8\u5316\u73af\u5883\uff0c\u5176\u8868\u73b0\u4f18\u4e8e\u9759\u6001\u57fa\u51c6\u7b56\u7565\u3002\u540c\u65f6\uff0c\u5f15\u5165\u7684\u542f\u53d1\u5f0f\u8def\u7531\u89c4\u5219\u6709\u6548\u5730\u51cf\u5c11\u4e86\u5ef6\u8fdf\u3002\u8be5\u7b97\u6cd5\u8fd8\u80fd\u540c\u65f6\u4f18\u5316\u591a\u4e2a\u76ee\u6807\uff0c\u5e76\u901a\u8fc7\u8c03\u4f18\u53c2\u6570\u5b9e\u73b0\u4e86\u6027\u80fd\u6743\u8861\u3002\u6b64\u5916\uff0c\u7814\u7a76\u63ed\u793a\u4e86\u7b97\u6cd5\u5bf9\u4f30\u8ba1\u8bef\u5dee\u548c\u53c2\u6570\u8c03\u4f18\u7684\u654f\u611f\u6027\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u57fa\u4e8e\u6280\u80fd\u7684\u6392\u961f\u7cfb\u7edf\u4e2d\u5177\u6709\u663e\u8457\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u6700\u4f18\u5ba2\u6237\u8def\u7531\u65b9\u9762\u3002\u5b83\u4e0d\u4ec5\u80fd\u9002\u5e94\u52a8\u6001\u73af\u5883\uff0c\u8fd8\u80fd\u4f18\u5316\u591a\u4e2a\u76ee\u6807\u3002\u901a\u8fc7\u5f15\u5165\u542f\u53d1\u5f0f\u89c4\u5219\u548c\u8c03\u6574\u53c2\u6570\uff0c\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u5176\u5b9e\u7528\u6027\u3002\u7136\u800c\uff0c\u8be5\u7b97\u6cd5\u5bf9\u4f30\u8ba1\u8bef\u5dee\u548c\u53c2\u6570\u8c03\u4f18\u8f83\u4e3a\u654f\u611f\uff0c\u56e0\u6b64\u5728\u5b9e\u9645\u90e8\u7f72\u65f6\u9700\u8c28\u614e\u8003\u8651\u8fd9\u4e9b\u56e0\u7d20\u3002"}}
{"id": "2506.20574", "pdf": "https://arxiv.org/pdf/2506.20574", "abs": "https://arxiv.org/abs/2506.20574", "authors": ["Laura Boggia", "Rafael Teixeira de Lima", "Bogdan Malaescu"], "title": "Benchmarking Unsupervised Strategies for Anomaly Detection in Multivariate Time Series", "categories": ["cs.LG", "stat.ME"], "comment": "Submitted to VLDB 2026 conference, currently under review", "summary": "Anomaly detection in multivariate time series is an important problem across\nvarious fields such as healthcare, financial services, manufacturing or physics\ndetector monitoring. Accurately identifying when unexpected errors or faults\noccur is essential, yet challenging, due to the unknown nature of anomalies and\nthe complex interdependencies between time series dimensions. In this paper, we\ninvestigate transformer-based approaches for time series anomaly detection,\nfocusing on the recently proposed iTransformer architecture. Our contributions\nare fourfold: (i) we explore the application of the iTransformer to time series\nanomaly detection, and analyse the influence of key parameters such as window\nsize, step size, and model dimensions on performance; (ii) we examine methods\nfor extracting anomaly labels from multidimensional anomaly scores and discuss\nappropriate evaluation metrics for such labels; (iii) we study the impact of\nanomalous data present during training and assess the effectiveness of\nalternative loss functions in mitigating their influence; and (iv) we present a\ncomprehensive comparison of several transformer-based models across a diverse\nset of datasets for time series anomaly detection.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u91cd\u70b9\u7814\u7a76iTransformer\u67b6\u6784\u7684\u5e94\u7528\u3001\u53c2\u6570\u5f71\u54cd\u3001\u6807\u7b7e\u63d0\u53d6\u65b9\u6cd5\u3001\u8bc4\u4ef7\u6307\u6807\u3001\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u5f02\u5e38\u5f71\u54cd\u53ca\u635f\u5931\u51fd\u6570\u7684\u4f5c\u7528\uff0c\u5e76\u8fdb\u884c\u4e86\u6a21\u578b\u5bf9\u6bd4\u3002", "motivation": "\u5728\u533b\u7597\u4fdd\u5065\u3001\u91d1\u878d\u670d\u52a1\u3001\u5236\u9020\u4e1a\u548c\u7269\u7406\u63a2\u6d4b\u5668\u76d1\u63a7\u7b49\u591a\u4e2a\u9886\u57df\u4e2d\uff0c\u51c6\u786e\u8bc6\u522b\u610f\u5916\u9519\u8bef\u6216\u6545\u969c\u7684\u53d1\u751f\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u5f02\u5e38\u7684\u672a\u77e5\u6027\u8d28\u548c\u65f6\u95f4\u5e8f\u5217\u7ef4\u5ea6\u4e4b\u95f4\u7684\u590d\u6742\u76f8\u4e92\u4f9d\u8d56\u6027\uff0c\u8fd9\u4e00\u4efb\u52a1\u5145\u6ee1\u6311\u6218\u3002\u56e0\u6b64\u9700\u8981\u7814\u7a76\u6709\u6548\u7684\u53d8\u538b\u5668\u67b6\u6784\u4ee5\u6539\u5584\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u7684\u5f02\u5e38\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u672c\u7814\u7a76\u4e3b\u8981\u91c7\u7528\u4e86iTransformer\u67b6\u6784\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\uff0c\u5206\u6790\u4e86\u7a97\u53e3\u5927\u5c0f\u3001\u6b65\u957f\u548c\u6a21\u578b\u7ef4\u5ea6\u7b49\u5173\u952e\u53c2\u6570\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff1b\u7814\u7a76\u4e86\u4ece\u591a\u7ef4\u5f02\u5e38\u8bc4\u5206\u4e2d\u63d0\u53d6\u5f02\u5e38\u6807\u7b7e\u7684\u65b9\u6cd5\u53ca\u9002\u5f53\u7684\u8bc4\u4f30\u6307\u6807\uff1b\u8003\u5bdf\u4e86\u8bad\u7ec3\u671f\u95f4\u5b58\u5728\u7684\u5f02\u5e38\u6570\u636e\u7684\u5f71\u54cd\uff0c\u5e76\u8bc4\u4f30\u4e86\u66ff\u4ee3\u635f\u5931\u51fd\u6570\u7684\u6709\u6548\u6027\uff1b\u6700\u540e\u6bd4\u8f83\u4e86\u51e0\u79cd\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\uff0c\u4f5c\u8005\u660e\u786e\u4e86\u5173\u952e\u53c2\u6570\u5bf9iTransformer\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u6709\u6548\u7684\u5f02\u5e38\u6807\u7b7e\u63d0\u53d6\u65b9\u6cd5\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u9a8c\u8bc1\u4e86\u635f\u5931\u51fd\u6570\u5728\u51cf\u8f7b\u8bad\u7ec3\u6570\u636e\u4e2d\u5f02\u5e38\u5f71\u54cd\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u591a\u79cd\u53d8\u538b\u5668\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u76f8\u5bf9\u4f18\u52bf\u3002", "conclusion": "iTransformer\u67b6\u6784\u5728\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u5177\u6709\u826f\u597d\u7684\u6f5c\u529b\uff0c\u5176\u6027\u80fd\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u5173\u952e\u53c2\u6570\u5f97\u5230\u4f18\u5316\uff1b\u540c\u65f6\uff0c\u9488\u5bf9\u5f02\u5e38\u6807\u7b7e\u63d0\u53d6\u548c\u8bc4\u4f30\u6307\u6807\u7684\u9009\u62e9\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u5e76\u5f3a\u8c03\u4e86\u5904\u7406\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u5f02\u5e38\u6570\u636e\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.20575", "pdf": "https://arxiv.org/pdf/2506.20575", "abs": "https://arxiv.org/abs/2506.20575", "authors": ["Itay Niv", "Neta Rabin"], "title": "Exploring Graph-Transformer Out-of-Distribution Generalization Abilities", "categories": ["cs.LG"], "comment": null, "summary": "Deep learning on graphs has shown remarkable success across numerous\napplications, including social networks, bio-physics, traffic networks, and\nrecommendation systems. Regardless of their successes, current methods\nfrequently depend on the assumption that training and testing data share the\nsame distribution, a condition rarely met in real-world scenarios. While\ngraph-transformer (GT) backbones have recently outperformed traditional\nmessage-passing neural networks (MPNNs) in multiple in-distribution (ID)\nbenchmarks, their effectiveness under distribution shifts remains largely\nunexplored.\n  In this work, we address the challenge of out-of-distribution (OOD)\ngeneralization for graph neural networks, with a special focus on the impact of\nbackbone architecture. We systematically evaluate GT and hybrid backbones in\nOOD settings and compare them to MPNNs. To do so, we adapt several leading\ndomain generalization (DG) algorithms to work with GTs and assess their\nperformance on a benchmark designed to test a variety of distribution shifts.\nOur results reveal that GT and hybrid GT-MPNN backbones consistently\ndemonstrate stronger generalization ability compared to MPNNs, even without\nspecialized DG algorithms.\n  Additionally, we propose a novel post-training analysis approach that\ncompares the clustering structure of the entire ID and OOD test datasets,\nspecifically examining domain alignment and class separation. Demonstrating its\nmodel-agnostic design, this approach not only provided meaningful insights into\nGT and MPNN backbones. It also shows promise for broader applicability to DG\nproblems beyond graph learning, offering a deeper perspective on generalization\nabilities that goes beyond standard accuracy metrics. Together, our findings\nhighlight the promise of graph-transformers for robust, real-world graph\nlearning and set a new direction for future research in OOD generalization.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\u5728\u5206\u5e03\u5916\uff08OOD\uff09\u6cdb\u5316\u65b9\u9762\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u9aa8\u5e72\u67b6\u6784\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u56fe\u53d8\u538b\u5668\uff08GT\uff09\u548c\u6df7\u5408\u9aa8\u5e72\u67b6\u6784\u5728OOD\u8bbe\u7f6e\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u4e0e\u6d88\u606f\u4f20\u9012\u795e\u7ecf\u7f51\u7edc\uff08MPNNs\uff09\u8fdb\u884c\u6bd4\u8f83\uff0c\u7ed3\u679c\u8868\u660eGT\u548c\u6df7\u5408GT-MPNN\u9aa8\u67b6\u5177\u6709\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u540e\u8bad\u7ec3\u5206\u6790\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u6bd4\u8f83\u6574\u4e2aID\u548cOOD\u6d4b\u8bd5\u6570\u636e\u96c6\u7684\u805a\u7c7b\u7ed3\u6784\u6765\u68c0\u67e5\u9886\u57df\u5bf9\u9f50\u548c\u7c7b\u522b\u5206\u79bb\uff0c\u663e\u793a\u51fa\u5728\u56fe\u5b66\u4e60\u4e4b\u5916\u7684DG\u95ee\u9898\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u7684\u56fe\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u5177\u6709\u76f8\u540c\u7684\u5206\u5e03\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8fd9\u4e00\u6761\u4ef6\u5f88\u5c11\u6ee1\u8db3\u3002\u5c3d\u7ba1\u56fe\u53d8\u538b\u5668\uff08GT\uff09\u5728\u540c\u5206\u5e03\uff08ID\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5728\u5206\u5e03\u8f6c\u79fb\u60c5\u51b5\u4e0b\u7684\u6709\u6548\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u63a2\u7d22\u4e0d\u540c\u9aa8\u5e72\u67b6\u6784\u5728\u5206\u5e03\u5916\uff08OOD\uff09\u6cdb\u5316\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u4f5c\u8005\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u56fe\u53d8\u538b\u5668\uff08GT\uff09\u548c\u6df7\u5408GT-MPNN\u9aa8\u5e72\u67b6\u6784\u5728OOD\u8bbe\u7f6e\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u5c06\u5176\u4e0e\u4f20\u7edf\u7684\u6d88\u606f\u4f20\u9012\u795e\u7ecf\u7f51\u7edc\uff08MPNNs\uff09\u8fdb\u884c\u6bd4\u8f83\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u70b9\uff0c\u4ed6\u4eec\u5c06\u51e0\u79cd\u9886\u5148\u7684\u9886\u57df\u6cdb\u5316\uff08DG\uff09\u7b97\u6cd5\u9002\u914d\u5230GT\u4e2d\uff0c\u5e76\u5728\u4e00\u4e2a\u8bbe\u8ba1\u7528\u4e8e\u6d4b\u8bd5\u591a\u79cd\u5206\u5e03\u8f6c\u79fb\u7684\u57fa\u51c6\u4e0a\u8bc4\u4f30\u5176\u6027\u80fd\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u540e\u8bad\u7ec3\u5206\u6790\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u6bd4\u8f83ID\u548cOOD\u6d4b\u8bd5\u6570\u636e\u96c6\u7684\u805a\u7c7b\u7ed3\u6784\u6765\u68c0\u67e5\u9886\u57df\u5bf9\u9f50\u548c\u7c7b\u522b\u5206\u79bb\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGT\u548c\u6df7\u5408GT-MPNN\u9aa8\u5e72\u67b6\u6784\u5728\u6ca1\u6709\u4e13\u95e8\u7684DG\u7b97\u6cd5\u7684\u60c5\u51b5\u4e0b\uff0c\u76f8\u6bd4MPNNs\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u3002\u63d0\u51fa\u7684\u540e\u8bad\u7ec3\u5206\u6790\u65b9\u6cd5\u4e0d\u4ec5\u4e3a\u7406\u89e3GT\u548cMPNN\u9aa8\u5e72\u63d0\u4f9b\u4e86\u6709\u610f\u4e49\u7684\u89c1\u89e3\uff0c\u8fd8\u5c55\u793a\u4e86\u5176\u5728\u66f4\u5e7f\u6cdb\u7684DG\u95ee\u9898\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u3002", "conclusion": "\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u56fe\u53d8\u538b\u5668\u5728\u9c81\u68d2\u3001\u771f\u5b9e\u4e16\u754c\u56fe\u5b66\u4e60\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u4e3a\u672a\u6765\u7684OOD\u6cdb\u5316\u7814\u7a76\u6307\u660e\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.20584", "pdf": "https://arxiv.org/pdf/2506.20584", "abs": "https://arxiv.org/abs/2506.20584", "authors": ["Mariano Tepper", "Ted Willke"], "title": "The kernel of graph indices for vector search", "categories": ["cs.LG"], "comment": null, "summary": "The most popular graph indices for vector search use principles from\ncomputational geometry to build the graph. Hence, their formal graph\nnavigability guarantees are only valid in Euclidean space. In this work, we\nshow that machine learning can be used to build graph indices for vector search\nin metric and non-metric vector spaces (e.g., for inner product similarity).\nFrom this novel perspective, we introduce the Support Vector Graph (SVG), a new\ntype of graph index that leverages kernel methods to establish the graph\nconnectivity and that comes with formal navigability guarantees valid in metric\nand non-metric vector spaces. In addition, we interpret the most popular graph\nindices, including HNSW and DiskANN, as particular specializations of SVG and\nshow that new indices can be derived from the principles behind this\nspecialization. Finally, we propose SVG-L0 that incorporates an $\\ell_0$\nsparsity constraint into the SVG kernel method to build graphs with a bounded\nout-degree. This yields a principled way of implementing this practical\nrequirement, in contrast to the traditional heuristic of simply truncating the\nout edges of each node. Additionally, we show that SVG-L0 has a self-tuning\nproperty that avoids the heuristic of using a set of candidates to find the\nout-edges of each node and that keeps its computational complexity in check.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u7d22\u5f15\u65b9\u6cd5SVG\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u548c\u6838\u65b9\u6cd5\u6784\u5efa\u9002\u7528\u4e8e\u5ea6\u91cf\u548c\u975e\u5ea6\u91cf\u5411\u91cf\u7a7a\u95f4\u7684\u56fe\u7d22\u5f15\uff0c\u5e76\u63d0\u4f9b\u4e86\u6b63\u5f0f\u7684\u53ef\u5bfc\u822a\u6027\u4fdd\u8bc1\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86SVG-L0\uff0c\u901a\u8fc7\u52a0\u5165\u7a00\u758f\u6027\u7ea6\u675f\u6765\u9650\u5236\u51fa\u5ea6\u5e76\u5b9e\u73b0\u81ea\u8c03\u4f18\u7279\u6027\u3002", "motivation": "\u76ee\u524d\u6700\u6d41\u884c\u7684\u5411\u91cf\u641c\u7d22\u56fe\u7d22\u5f15\u4ec5\u5728\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u6709\u6548\uff0c\u65e0\u6cd5\u9002\u7528\u4e8e\u5ea6\u91cf\u548c\u975e\u5ea6\u91cf\u5411\u91cf\u7a7a\u95f4\uff08\u5982\u5185\u79ef\u76f8\u4f3c\u6027\uff09\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u6269\u5c55\u56fe\u7d22\u5f15\u7684\u9002\u7528\u8303\u56f4\u3002", "method": "\u5f15\u5165\u652f\u6301\u5411\u91cf\u56fe\uff08SVG\uff09\u4f5c\u4e3a\u65b0\u7684\u56fe\u7d22\u5f15\u7c7b\u578b\uff0c\u5229\u7528\u6838\u65b9\u6cd5\u5efa\u7acb\u56fe\u7684\u8fde\u901a\u6027\uff0c\u5e76\u63d0\u4f9b\u5ea6\u91cf\u548c\u975e\u5ea6\u91cf\u5411\u91cf\u7a7a\u95f4\u4e2d\u7684\u6b63\u5f0f\u53ef\u5bfc\u822a\u6027\u4fdd\u8bc1\u3002\u5c06HNSW\u548cDiskANN\u7b49\u6d41\u884c\u56fe\u7d22\u5f15\u89e3\u91ca\u4e3aSVG\u7684\u7279\u5b9a\u7279\u4f8b\uff0c\u5e76\u63d0\u51faSVG-L0\uff0c\u901a\u8fc7\u52a0\u5165\u2113\u2080\u7a00\u758f\u6027\u7ea6\u675f\u63a7\u5236\u8282\u70b9\u51fa\u5ea6\uff0c\u540c\u65f6\u5177\u5907\u81ea\u8c03\u4f18\u7279\u6027\u4ee5\u907f\u514d\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002", "result": "SVG\u548cSVG-L0\u5728\u7406\u8bba\u548c\u5b9e\u8df5\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u5ea6\u91cf\u548c\u975e\u5ea6\u91cf\u5411\u91cf\u7a7a\u95f4\u4e2d\u7684\u5411\u91cf\u641c\u7d22\u95ee\u9898\uff0c\u540c\u65f6\u6539\u8fdb\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "conclusion": "SVG\u662f\u4e00\u79cd\u901a\u7528\u4e14\u5f3a\u5927\u7684\u56fe\u7d22\u5f15\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u5411\u91cf\u7a7a\u95f4\u3002SVG-L0\u8fdb\u4e00\u6b65\u4f18\u5316\u4e86\u56fe\u7ed3\u6784\uff0c\u63d0\u4f9b\u4e86\u6709\u539f\u5219\u7684\u51fa\u5ea6\u9650\u5236\u548c\u81ea\u8c03\u4f18\u80fd\u529b\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2506.20607", "pdf": "https://arxiv.org/pdf/2506.20607", "abs": "https://arxiv.org/abs/2506.20607", "authors": ["Jasen Lai", "Senwei Liang", "Chunmei Wang"], "title": "H-FEX: A Symbolic Learning Method for Hamiltonian Systems", "categories": ["cs.LG"], "comment": "16 pages, 7 figures", "summary": "Hamiltonian systems describe a broad class of dynamical systems governed by\nHamiltonian functions, which encode the total energy and dictate the evolution\nof the system. Data-driven approaches, such as symbolic regression and neural\nnetwork-based methods, provide a means to learn the governing equations of\ndynamical systems directly from observational data of Hamiltonian systems.\nHowever, these methods often struggle to accurately capture complex Hamiltonian\nfunctions while preserving energy conservation. To overcome this limitation, we\npropose the Finite Expression Method for learning Hamiltonian Systems (H-FEX),\na symbolic learning method that introduces novel interaction nodes designed to\ncapture intricate interaction terms effectively. Our experiments, including\nthose on highly stiff dynamical systems, demonstrate that H-FEX can recover\nHamiltonian functions of complex systems that accurately capture system\ndynamics and preserve energy over long time horizons. These findings highlight\nthe potential of H-FEX as a powerful framework for discovering closed-form\nexpressions of complex dynamical systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b26\u53f7\u5b66\u4e60\u65b9\u6cd5H-FEX\uff0c\u7528\u4e8e\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u54c8\u5bc6\u987f\u7cfb\u7edf\uff0c\u5c24\u5176\u5728\u590d\u6742\u548c\u521a\u6027\u7cfb\u7edf\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u51c6\u786e\u6355\u6349\u7cfb\u7edf\u52a8\u529b\u5b66\u5e76\u957f\u65f6\u95f4\u4fdd\u6301\u80fd\u91cf\u5b88\u6052\u3002", "motivation": "\u5f53\u524d\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff08\u5982\u7b26\u53f7\u56de\u5f52\u548c\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\uff09\u867d\u7136\u53ef\u4ee5\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u5b66\u4e60\u52a8\u529b\u7cfb\u7edf\u7684\u63a7\u5236\u65b9\u7a0b\uff0c\u4f46\u96be\u4ee5\u51c6\u786e\u6355\u6349\u590d\u6742\u7684\u54c8\u5bc6\u987f\u51fd\u6570\u540c\u65f6\u4fdd\u6301\u80fd\u91cf\u5b88\u6052\u3002", "method": "\u63d0\u51fa\u4e86\u540d\u4e3aH-FEX\u7684\u6709\u9650\u8868\u8fbe\u5f0f\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u7b26\u53f7\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u65b0\u9896\u7684\u4ea4\u4e92\u8282\u70b9\u6765\u6709\u6548\u6355\u6349\u590d\u6742\u7684\u4ea4\u4e92\u9879\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cH-FEX\u53ef\u4ee5\u6062\u590d\u590d\u6742\u7cfb\u7edf\u7684\u54c8\u5bc6\u987f\u51fd\u6570\uff0c\u8fd9\u4e9b\u51fd\u6570\u80fd\u591f\u51c6\u786e\u6355\u6349\u7cfb\u7edf\u52a8\u529b\u5b66\uff0c\u5e76\u5728\u957f\u65f6\u95f4\u5185\u4fdd\u6301\u80fd\u91cf\u5b88\u6052\u3002", "conclusion": "H-FEX\u4f5c\u4e3a\u4e00\u79cd\u5f3a\u5927\u7684\u6846\u67b6\uff0c\u5177\u6709\u53d1\u73b0\u590d\u6742\u52a8\u529b\u7cfb\u7edf\u5c01\u95ed\u5f62\u5f0f\u8868\u8fbe\u5f0f\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.20644", "pdf": "https://arxiv.org/pdf/2506.20644", "abs": "https://arxiv.org/abs/2506.20644", "authors": ["Hangyu Li", "Hongyue Wu", "Guodong Fan", "Zhen Zhang", "Shizhan Chen", "Zhiyong Feng"], "title": "Efficient Federated Learning with Encrypted Data Sharing for Data-Heterogeneous Edge Devices", "categories": ["cs.LG"], "comment": "Accepted by ICWS 2025", "summary": "As privacy protection gains increasing importance, more models are being\ntrained on edge devices and subsequently merged into the central server through\nFederated Learning (FL). However, current research overlooks the impact of\nnetwork topology, physical distance, and data heterogeneity on edge devices,\nleading to issues such as increased latency and degraded model performance. To\naddress these issues, we propose a new federated learning scheme on edge\ndevices that called Federated Learning with Encrypted Data Sharing(FedEDS).\nFedEDS uses the client model and the model's stochastic layer to train the data\nencryptor. The data encryptor generates encrypted data and shares it with other\nclients. The client uses the corresponding client's stochastic layer and\nencrypted data to train and adjust the local model. FedEDS uses the client's\nlocal private data and encrypted shared data from other clients to train the\nmodel. This approach accelerates the convergence speed of federated learning\ntraining and mitigates the negative impact of data heterogeneity, making it\nsuitable for application services deployed on edge devices requiring rapid\nconvergence. Experiments results show the efficacy of FedEDS in promoting model\nperformance.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8fb9\u7f18\u8bbe\u5907\u8054\u90a6\u5b66\u4e60\u65b9\u6848FedEDS\uff0c\u901a\u8fc7\u6570\u636e\u52a0\u5bc6\u5171\u4eab\u673a\u5236\u52a0\u901f\u8054\u90a6\u5b66\u4e60\u8bad\u7ec3\u7684\u6536\u655b\u901f\u5ea6\uff0c\u5e76\u7f13\u89e3\u6570\u636e\u5f02\u8d28\u6027\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u8d1f\u9762\u5f71\u54cd\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFedEDS\u5728\u63d0\u5347\u6a21\u578b\u6027\u80fd\u65b9\u9762\u5177\u6709\u663e\u8457\u6548\u679c\u3002", "motivation": "\u9690\u79c1\u4fdd\u62a4\u65e5\u76ca\u91cd\u8981\uff0c\u8d8a\u6765\u8d8a\u591a\u7684\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8fdb\u884c\u8bad\u7ec3\u5e76\u901a\u8fc7\u8054\u90a6\u5b66\u4e60\u5408\u5e76\u5230\u4e2d\u592e\u670d\u52a1\u5668\u3002\u7136\u800c\uff0c\u5f53\u524d\u7814\u7a76\u5ffd\u7565\u4e86\u7f51\u7edc\u62d3\u6251\u3001\u7269\u7406\u8ddd\u79bb\u548c\u6570\u636e\u5f02\u8d28\u6027\u5bf9\u8fb9\u7f18\u8bbe\u5907\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u5ef6\u8fdf\u589e\u52a0\u548c\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFedEDS\uff08\u8054\u90a6\u5b66\u4e60\u4e0e\u52a0\u5bc6\u6570\u636e\u5171\u4eab\uff09\u7684\u65b0\u8054\u90a6\u5b66\u4e60\u65b9\u6848\u3002\u8be5\u65b9\u6848\u4f7f\u7528\u5ba2\u6237\u7aef\u6a21\u578b\u548c\u6a21\u578b\u7684\u968f\u673a\u5c42\u8bad\u7ec3\u6570\u636e\u52a0\u5bc6\u5668\uff0c\u6570\u636e\u52a0\u5bc6\u5668\u751f\u6210\u52a0\u5bc6\u6570\u636e\u5e76\u4e0e\u5176\u4ed6\u5ba2\u6237\u7aef\u5171\u4eab\u3002\u5ba2\u6237\u7aef\u5229\u7528\u5bf9\u5e94\u7684\u968f\u673a\u5c42\u548c\u52a0\u5bc6\u6570\u636e\u8bad\u7ec3\u548c\u8c03\u6574\u672c\u5730\u6a21\u578b\u3002FedEDS\u7ed3\u5408\u672c\u5730\u79c1\u6709\u6570\u636e\u548c\u6765\u81ea\u5176\u4ed6\u5ba2\u6237\u7aef\u7684\u52a0\u5bc6\u5171\u4eab\u6570\u636e\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFedEDS\u80fd\u591f\u6709\u6548\u4fc3\u8fdb\u6a21\u578b\u6027\u80fd\uff0c\u52a0\u901f\u8054\u90a6\u5b66\u4e60\u8bad\u7ec3\u7684\u6536\u655b\u901f\u5ea6\uff0c\u5e76\u7f13\u89e3\u6570\u636e\u5f02\u8d28\u6027\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\u3002", "conclusion": "FedEDS\u662f\u4e00\u79cd\u9002\u5408\u90e8\u7f72\u5728\u9700\u8981\u5feb\u901f\u6536\u655b\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u5e94\u7528\u670d\u52a1\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8054\u90a6\u5b66\u4e60\u4e2d\u56e0\u6570\u636e\u5f02\u8d28\u6027\u5bfc\u81f4\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u548c\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2506.20651", "pdf": "https://arxiv.org/pdf/2506.20651", "abs": "https://arxiv.org/abs/2506.20651", "authors": ["Fei Wang", "Baochun Li"], "title": "Hear No Evil: Detecting Gradient Leakage by Malicious Servers in Federated Learning", "categories": ["cs.LG", "cs.CR", "cs.DC"], "comment": null, "summary": "Recent work has shown that gradient updates in federated learning (FL) can\nunintentionally reveal sensitive information about a client's local data. This\nrisk becomes significantly greater when a malicious server manipulates the\nglobal model to provoke information-rich updates from clients. In this paper,\nwe adopt a defender's perspective to provide the first comprehensive analysis\nof malicious gradient leakage attacks and the model manipulation techniques\nthat enable them. Our investigation reveals a core trade-off: these attacks\ncannot be both highly effective in reconstructing private data and sufficiently\nstealthy to evade detection -- especially in realistic FL settings that\nincorporate common normalization techniques and federated averaging.\n  Building on this insight, we argue that malicious gradient leakage attacks,\nwhile theoretically concerning, are inherently limited in practice and often\ndetectable through basic monitoring. As a complementary contribution, we\npropose a simple, lightweight, and broadly applicable client-side detection\nmechanism that flags suspicious model updates before local training begins,\ndespite the fact that such detection may not be strictly necessary in realistic\nFL settings. This mechanism further underscores the feasibility of defending\nagainst these attacks with minimal overhead, offering a deployable safeguard\nfor privacy-conscious federated learning systems.", "AI": {"tldr": "\u8fd1\u671f\u7814\u7a76\u8868\u660e\uff0c\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u68af\u5ea6\u66f4\u65b0\u53ef\u80fd\u4f1a\u65e0\u610f\u95f4\u6cc4\u9732\u5ba2\u6237\u672c\u5730\u6570\u636e\u7684\u654f\u611f\u4fe1\u606f\u3002\u672c\u6587\u4ece\u9632\u5fa1\u8005\u7684\u89d2\u5ea6\u51fa\u53d1\uff0c\u9996\u6b21\u5bf9\u6076\u610f\u68af\u5ea6\u6cc4\u9732\u653b\u51fb\u53ca\u5176\u80cc\u540e\u7684\u6a21\u578b\u64cd\u63a7\u6280\u672f\u8fdb\u884c\u4e86\u5168\u9762\u5206\u6790\u3002\u7814\u7a76\u63ed\u793a\u4e86\u8fd9\u4e9b\u653b\u51fb\u5728\u91cd\u5efa\u79c1\u4eba\u6570\u636e\u7684\u6709\u6548\u6027\u548c\u9003\u907f\u68c0\u6d4b\u7684\u9690\u853d\u6027\u4e4b\u95f4\u7684\u6838\u5fc3\u6743\u8861\u3002\u57fa\u4e8e\u8fd9\u4e00\u89c1\u89e3\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u3001\u8f7b\u91cf\u4e14\u5e7f\u6cdb\u9002\u7528\u7684\u5ba2\u6237\u7aef\u68c0\u6d4b\u673a\u5236\uff0c\u53ef\u4ee5\u5728\u672c\u5730\u8bad\u7ec3\u5f00\u59cb\u524d\u6807\u8bb0\u53ef\u7591\u7684\u6a21\u578b\u66f4\u65b0\u3002\u8be5\u673a\u5236\u5f3a\u8c03\u4e86\u5728\u5b9e\u9645\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u901a\u8fc7\u57fa\u672c\u76d1\u63a7\u5373\u53ef\u6709\u6548\u9632\u5fa1\u6b64\u7c7b\u653b\u51fb\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u68af\u5ea6\u66f4\u65b0\u53ef\u80fd\u65e0\u610f\u4e2d\u6cc4\u9732\u5ba2\u6237\u7684\u654f\u611f\u6570\u636e\uff0c\u800c\u6076\u610f\u670d\u52a1\u5668\u53ef\u4ee5\u901a\u8fc7\u64cd\u63a7\u5168\u5c40\u6a21\u578b\u6765\u5f15\u53d1\u4fe1\u606f\u4e30\u5bcc\u7684\u66f4\u65b0\uff0c\u4ece\u800c\u52a0\u5267\u8fd9\u4e00\u98ce\u9669\u3002\u56e0\u6b64\uff0c\u9700\u8981\u5bf9\u6076\u610f\u68af\u5ea6\u6cc4\u9732\u653b\u51fb\u8fdb\u884c\u6df1\u5165\u5206\u6790\uff0c\u5e76\u63a2\u7d22\u5176\u5b9e\u9645\u5a01\u80c1\u7a0b\u5ea6\u53ca\u9632\u5fa1\u65b9\u6cd5\u3002", "method": "1. \u4ece\u9632\u5fa1\u8005\u89c6\u89d2\u51fa\u53d1\uff0c\u5bf9\u6076\u610f\u68af\u5ea6\u6cc4\u9732\u653b\u51fb\u548c\u6a21\u578b\u64cd\u63a7\u6280\u672f\u8fdb\u884c\u5168\u9762\u5206\u6790\u3002\n2. \u7814\u7a76\u653b\u51fb\u5728\u91cd\u5efa\u79c1\u4eba\u6570\u636e\u7684\u6709\u6548\u6027\u548c\u9690\u853d\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002\n3. \u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u5ba2\u6237\u7aef\u68c0\u6d4b\u673a\u5236\uff0c\u5728\u672c\u5730\u8bad\u7ec3\u5f00\u59cb\u524d\u6807\u8bb0\u53ef\u7591\u7684\u6a21\u578b\u66f4\u65b0\u3002", "result": "\u6076\u610f\u68af\u5ea6\u6cc4\u9732\u653b\u51fb\u867d\u7136\u7406\u8bba\u4e0a\u4ee4\u4eba\u62c5\u5fe7\uff0c\u4f46\u5728\u5b9e\u9645\u4e2d\u53d7\u5230\u9650\u5236\uff0c\u901a\u5e38\u53ef\u4ee5\u901a\u8fc7\u57fa\u672c\u76d1\u63a7\u68c0\u6d4b\u5230\u3002\u63d0\u51fa\u7684\u5ba2\u6237\u7aef\u68c0\u6d4b\u673a\u5236\u53ef\u4ee5\u6709\u6548\u9632\u5fa1\u653b\u51fb\uff0c\u4e14\u5f00\u9500\u8f83\u5c0f\u3002", "conclusion": "\u6076\u610f\u68af\u5ea6\u6cc4\u9732\u653b\u51fb\u5728\u5b9e\u8df5\u4e2d\u53d7\u5230\u9650\u5236\uff0c\u4e14\u53ef\u4ee5\u901a\u8fc7\u7b80\u5355\u7684\u76d1\u63a7\u548c\u68c0\u6d4b\u673a\u5236\u6709\u6548\u9632\u5fa1\u3002\u672c\u6587\u63d0\u51fa\u7684\u5ba2\u6237\u7aef\u68c0\u6d4b\u673a\u5236\u4e3a\u9690\u79c1\u4fdd\u62a4\u7684\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u884c\u7684\u5b89\u5168\u4fdd\u969c\u3002"}}
