{"id": "2505.15927", "pdf": "https://arxiv.org/pdf/2505.15927", "abs": "https://arxiv.org/abs/2505.15927", "authors": ["Awni Altabaa", "Omar Montasser", "John Lafferty"], "title": "CoT Information: Improved Sample Complexity under Chain-of-Thought Supervision", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Learning complex functions that involve multi-step reasoning poses a\nsignificant challenge for standard supervised learning from input-output\nexamples. Chain-of-thought (CoT) supervision, which provides intermediate\nreasoning steps together with the final output, has emerged as a powerful\nempirical technique, underpinning much of the recent progress in the reasoning\ncapabilities of large language models. This paper develops a statistical theory\nof learning under CoT supervision. A key characteristic of the CoT setting, in\ncontrast to standard supervision, is the mismatch between the training\nobjective (CoT risk) and the test objective (end-to-end risk). A central part\nof our analysis, distinguished from prior work, is explicitly linking those two\ntypes of risk to achieve sharper sample complexity bounds. This is achieved via\nthe *CoT information measure* $\\mathcal{I}_{\\mathcal{D},\nh_\\star}^{\\mathrm{CoT}}(\\epsilon; \\calH)$, which quantifies the additional\ndiscriminative power gained from observing the reasoning process. The main\ntheoretical results demonstrate how CoT supervision can yield significantly\nfaster learning rates compared to standard E2E supervision. Specifically, it is\nshown that the sample complexity required to achieve a target E2E error\n$\\epsilon$ scales as $d/\\mathcal{I}_{\\mathcal{D},\nh_\\star}^{\\mathrm{CoT}}(\\epsilon; \\calH)$, where $d$ is a measure of hypothesis\nclass complexity, which can be much faster than standard $d/\\epsilon$ rates.\nInformation-theoretic lower bounds in terms of the CoT information are also\nobtained. Together, these results suggest that CoT information is a fundamental\nmeasure of statistical complexity for learning under chain-of-thought\nsupervision.", "AI": {"tldr": "\u672c\u6587\u53d1\u5c55\u4e86\u94fe\u5f0f\u601d\u7ef4(CoT)\u76d1\u7763\u4e0b\u7684\u7edf\u8ba1\u5b66\u4e60\u7406\u8bba\uff0c\u901a\u8fc7CoT\u4fe1\u606f\u5ea6\u91cf\u91cf\u5316\u63a8\u7406\u8fc7\u7a0b\u5e26\u6765\u7684\u989d\u5916\u5224\u522b\u80fd\u529b\uff0c\u5e76\u8bc1\u660e\u4e86CoT\u76d1\u7763\u53ef\u4ee5\u6bd4\u6807\u51c6\u7aef\u5230\u7aef(E2E)\u76d1\u7763\u5b9e\u73b0\u66f4\u5feb\u7684\u5b66\u4e60\u901f\u7387\u3002", "motivation": "\u5b66\u4e60\u6d89\u53ca\u591a\u6b65\u63a8\u7406\u7684\u590d\u6742\u51fd\u6570\u9762\u4e34\u663e\u8457\u6311\u6218\uff0c\u800cCoT\u76d1\u7763\u63d0\u4f9b\u4e86\u4e2d\u95f4\u63a8\u7406\u6b65\u9aa4\u548c\u6700\u7ec8\u8f93\u51fa\uff0c\u6210\u4e3a\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u5f3a\u5927\u7ecf\u9a8c\u6280\u672f\u3002", "method": "\u5f15\u5165\u4e86CoT\u4fe1\u606f\u5ea6\u91cf\u6765\u8fde\u63a5\u8bad\u7ec3\u76ee\u6807\uff08CoT\u98ce\u9669\uff09\u548c\u6d4b\u8bd5\u76ee\u6807\uff08\u7aef\u5230\u7aef\u98ce\u9669\uff09\uff0c\u5e76\u5206\u6790\u5176\u5bf9\u6837\u672c\u590d\u6742\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u8bc1\u660e\u4e86\u5728CoT\u76d1\u7763\u4e0b\uff0c\u8fbe\u5230\u76ee\u6807\u7aef\u5230\u7aef\u9519\u8bef\u6240\u9700\u7684\u6837\u672c\u590d\u6742\u5ea6\u53ef\u4ee5\u663e\u8457\u5c0f\u4e8e\u6807\u51c6\u7aef\u5230\u7aef\u76d1\u7763\u6240\u9700\u7684\u590d\u6742\u5ea6\u3002", "conclusion": "CoT\u4fe1\u606f\u662f\u94fe\u5f0f\u601d\u7ef4\u76d1\u7763\u4e0b\u7edf\u8ba1\u590d\u6742\u6027\u7684\u57fa\u672c\u5ea6\u91cf\u3002"}}
{"id": "2505.16051", "pdf": "https://arxiv.org/pdf/2505.16051", "abs": "https://arxiv.org/abs/2505.16051", "authors": ["Dongze Wu", "David I. Inouye", "Yao Xie"], "title": "PO-Flow: Flow-based Generative Models for Sampling Potential Outcomes and Counterfactuals", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We propose PO-Flow, a novel continuous normalizing flow (CNF) framework for\ncausal inference that jointly models potential outcomes and counterfactuals.\nTrained via flow matching, PO-Flow provides a unified framework for\nindividualized potential outcome prediction, counterfactual predictions, and\nuncertainty-aware density learning. Among generative models, it is the first to\nenable density learning of potential outcomes without requiring explicit\ndistributional assumptions (e.g., Gaussian mixtures), while also supporting\ncounterfactual prediction conditioned on factual outcomes in general\nobservational datasets. On benchmarks such as ACIC, IHDP, and IBM, it\nconsistently outperforms prior methods across a range of causal inference\ntasks. Beyond that, PO-Flow succeeds in high-dimensional settings, including\ncounterfactual image generation, demonstrating its broad applicability.", "AI": {"tldr": "\u63d0\u51faPO-Flow\u6846\u67b6\u7528\u4e8e\u56e0\u679c\u63a8\u65ad\uff0c\u80fd\u591f\u540c\u65f6\u5efa\u6a21\u6f5c\u5728\u7ed3\u679c\u548c\u53cd\u4e8b\u5b9e\uff0c\u65e0\u9700\u663e\u5f0f\u5206\u5e03\u5047\u8bbe\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u8fde\u7eed\u5f52\u4e00\u5316\u6d41(CNF)\u6846\u67b6\u6765\u89e3\u51b3\u56e0\u679c\u63a8\u7406\u95ee\u9898\uff0c\u7279\u522b\u662f\u6f5c\u5728\u7ed3\u679c\u548c\u53cd\u4e8b\u5b9e\u7684\u8054\u5408\u5efa\u6a21\u3002", "method": "\u63d0\u51faPO-Flow\u6846\u67b6\uff0c\u901a\u8fc7\u6d41\u5339\u914d\u8bad\u7ec3\uff0c\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u6f5c\u5728\u7ed3\u679c\u9884\u6d4b\u3001\u53cd\u4e8b\u5b9e\u9884\u6d4b\u4ee5\u53ca\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u5bc6\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u3002", "result": "\u5728ACIC\u3001IHDP\u3001IBM\u7b49\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cPO-Flow\u5728\u591a\u79cd\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5148\u524d\u65b9\u6cd5\uff0c\u5e76\u4e14\u80fd\u591f\u5728\u9ad8\u7ef4\u8bbe\u7f6e\u4e0b\u6210\u529f\u5e94\u7528\uff0c\u4f8b\u5982\u53cd\u4e8b\u5b9e\u56fe\u50cf\u751f\u6210\u3002", "conclusion": "PO-Flow\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u4e8e\u663e\u5f0f\u5206\u5e03\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u6f5c\u5728\u7ed3\u679c\u7684\u5bc6\u5ea6\u5b66\u4e60\uff0c\u5e76\u652f\u6301\u57fa\u4e8e\u4e8b\u5b9e\u7ed3\u679c\u7684\u53cd\u4e8b\u5b9e\u9884\u6d4b\uff0c\u5c55\u793a\u4e86\u5176\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2505.16082", "pdf": "https://arxiv.org/pdf/2505.16082", "abs": "https://arxiv.org/abs/2505.16082", "authors": ["Renato Berlinghieri", "Yunyi Shen", "Jialong Jiang", "Tamara Broderick"], "title": "Oh SnapMMD! Forecasting Stochastic Dynamics Beyond the Schr\u00f6dinger Bridge's End", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "43 pages, 26 figures, 21 tables", "summary": "Scientists often want to make predictions beyond the observed time horizon of\n\"snapshot\" data following latent stochastic dynamics. For example, in time\ncourse single-cell mRNA profiling, scientists have access to cellular\ntranscriptional state measurements (snapshots) from different biological\nreplicates at different time points, but they cannot access the trajectory of\nany one cell because measurement destroys the cell. Researchers want to\nforecast (e.g.) differentiation outcomes from early state measurements of stem\ncells. Recent Schr\\\"odinger-bridge (SB) methods are natural for interpolating\nbetween snapshots. But past SB papers have not addressed forecasting -- likely\nsince existing methods either (1) reduce to following pre-set reference\ndynamics (chosen before seeing data) or (2) require the user to choose a fixed,\nstate-independent volatility since they minimize a Kullback-Leibler divergence.\nEither case can lead to poor forecasting quality. In the present work, we\npropose a new framework, SnapMMD, that learns dynamics by directly fitting the\njoint distribution of both state measurements and observation time with a\nmaximum mean discrepancy (MMD) loss. Unlike past work, our method allows us to\ninfer unknown and state-dependent volatilities from the observed data. We show\nin a variety of real and synthetic experiments that our method delivers\naccurate forecasts. Moreover, our approach allows us to learn in the presence\nof incomplete state measurements and yields an $R^2$-style statistic that\ndiagnoses fit. We also find that our method's performance at interpolation (and\ngeneral velocity-field reconstruction) is at least as good as (and often better\nthan) state-of-the-art in almost all of our experiments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6SnapMMD\uff0c\u7528\u4e8e\u5b66\u4e60\u6f5c\u4f0f\u968f\u673a\u52a8\u529b\u5b66\u4e2d\u7684\u72b6\u6001\u6d4b\u91cf\u548c\u89c2\u6d4b\u65f6\u95f4\u7684\u8054\u5408\u5206\u5e03\uff0c\u63d0\u4f9b\u51c6\u786e\u7684\u9884\u6d4b\u5e76\u6539\u5584\u4e86\u63d2\u503c\u548c\u901f\u5ea6\u573a\u91cd\u5efa\u7684\u8868\u73b0\u3002", "motivation": "\u79d1\u5b66\u5bb6\u4eec\u7ecf\u5e38\u5e0c\u671b\u6839\u636e\u201c\u5feb\u7167\u201d\u6570\u636e\u7684\u6f5c\u4f0f\u968f\u673a\u52a8\u529b\u5b66\u505a\u51fa\u8d85\u51fa\u89c2\u5bdf\u65f6\u95f4\u8303\u56f4\u7684\u9884\u6d4b\u3002\u7136\u800c\uff0c\u8fc7\u53bb\u7684Schr\u00f6dinger-bridge (SB) \u65b9\u6cd5\u6ca1\u6709\u89e3\u51b3\u9884\u6d4b\u95ee\u9898\uff0c\u56e0\u4e3a\u73b0\u6709\u7684\u65b9\u6cd5\u8981\u4e48\u9075\u5faa\u9884\u8bbe\u7684\u53c2\u8003\u52a8\u529b\u5b66\uff0c\u8981\u4e48\u8981\u6c42\u7528\u6237\u9009\u62e9\u56fa\u5b9a\u7684\u72b6\u6001\u65e0\u5173\u7684\u6ce2\u52a8\u6027\uff0c\u8fd9\u4e9b\u90fd\u53ef\u80fd\u5bfc\u81f4\u9884\u6d4b\u8d28\u91cf\u5dee\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6SnapMMD\uff0c\u5b83\u901a\u8fc7\u6700\u5927\u5747\u503c\u5dee\u5f02(MMD)\u635f\u5931\u76f4\u63a5\u62df\u5408\u72b6\u6001\u6d4b\u91cf\u548c\u89c2\u6d4b\u65f6\u95f4\u7684\u8054\u5408\u5206\u5e03\u6765\u5b66\u4e60\u52a8\u529b\u5b66\u3002", "result": "\u5728\u5404\u79cd\u771f\u5b9e\u548c\u5408\u6210\u5b9e\u9a8c\u4e2d\uff0cSnapMMD\u65b9\u6cd5\u63d0\u4f9b\u4e86\u51c6\u786e\u7684\u9884\u6d4b\uff0c\u5e76\u4e14\u5728\u63d2\u503c\uff08\u548c\u4e00\u822c\u901f\u5ea6\u573a\u91cd\u5efa\uff09\u65b9\u9762\u7684\u8868\u73b0\u81f3\u5c11\u4e0e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u4e00\u6837\u597d\uff0c\u901a\u5e38\u66f4\u597d\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u5141\u8bb8\u6211\u4eec\u5728\u5b58\u5728\u4e0d\u5b8c\u6574\u72b6\u6001\u6d4b\u91cf\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u5b66\u4e60\uff0c\u5e76\u4ea7\u751f\u4e86\u4e00\u4e2a\u8bca\u65ad\u62df\u5408\u7684R\u00b2\u6837\u5f0f\u7edf\u8ba1\u91cf\u3002", "conclusion": "SnapMMD\u65b9\u6cd5\u901a\u8fc7\u76f4\u63a5\u62df\u5408\u72b6\u6001\u6d4b\u91cf\u548c\u89c2\u6d4b\u65f6\u95f4\u7684\u8054\u5408\u5206\u5e03\u6765\u5b66\u4e60\u52a8\u529b\u5b66\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5141\u8bb8\u6211\u4eec\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u63a8\u65ad\u672a\u77e5\u4e14\u72b6\u6001\u76f8\u5173\u7684\u6ce2\u52a8\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u771f\u5b9e\u548c\u5408\u6210\u5b9e\u9a8c\u4e2d\u63d0\u4f9b\u4e86\u51c6\u786e\u7684\u9884\u6d4b\uff0c\u5e76\u4e14\u5141\u8bb8\u6211\u4eec\u5728\u5b58\u5728\u4e0d\u5b8c\u6574\u72b6\u6001\u6d4b\u91cf\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u5b66\u4e60\uff0c\u8fd8\u4ea7\u751f\u4e86\u4e00\u4e2a\u8bca\u65ad\u62df\u5408\u7684R\u00b2\u6837\u5f0f\u7edf\u8ba1\u91cf\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u5728\u63d2\u503c\uff08\u548c\u4e00\u822c\u901f\u5ea6\u573a\u91cd\u5efa\uff09\u65b9\u9762\u7684\u8868\u73b0\u81f3\u5c11\u4e0e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u4e00\u6837\u597d\uff0c\u901a\u5e38\u66f4\u597d\u3002"}}
{"id": "2505.16098", "pdf": "https://arxiv.org/pdf/2505.16098", "abs": "https://arxiv.org/abs/2505.16098", "authors": ["Damien Ferbach", "Katie Everett", "Gauthier Gidel", "Elliot Paquette", "Courtney Paquette"], "title": "Dimension-adapted Momentum Outscales SGD", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "We investigate scaling laws for stochastic momentum algorithms with small\nbatch on the power law random features model, parameterized by data complexity,\ntarget complexity, and model size. When trained with a stochastic momentum\nalgorithm, our analysis reveals four distinct loss curve shapes determined by\nvarying data-target complexities. While traditional stochastic gradient descent\nwith momentum (SGD-M) yields identical scaling law exponents to SGD,\ndimension-adapted Nesterov acceleration (DANA) improves these exponents by\nscaling momentum hyperparameters based on model size and data complexity. This\noutscaling phenomenon, which also improves compute-optimal scaling behavior, is\nachieved by DANA across a broad range of data and target complexities, while\ntraditional methods fall short. Extensive experiments on high-dimensional\nsynthetic quadratics validate our theoretical predictions and large-scale text\nexperiments with LSTMs show DANA's improved loss exponents over SGD hold in a\npractical setting.", "AI": {"tldr": "\u7814\u7a76\u4e86\u968f\u673a\u52a8\u91cf\u7b97\u6cd5\u5728\u5e42\u5f8b\u968f\u673a\u7279\u5f81\u6a21\u578b\u4e2d\u7684\u7f29\u653e\u89c4\u5f8b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u52a8\u91cf\u8d85\u53c2\u6570\u8c03\u6574\u65b9\u6cd5\uff08DANA\uff09\uff0c\u5728\u591a\u79cd\u590d\u6742\u5ea6\u4e0b\u4f18\u4e8e\u4f20\u7edfSGD-M\u3002", "motivation": "\u63a2\u7d22\u968f\u673a\u52a8\u91cf\u7b97\u6cd5\u7684\u7f29\u653e\u89c4\u5f8b\u53ca\u5176\u5728\u4e0d\u540c\u6570\u636e\u548c\u76ee\u6807\u590d\u6742\u5ea6\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u5bf9\u5e42\u5f8b\u968f\u673a\u7279\u5f81\u6a21\u578b\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u63d0\u51faDANA\u65b9\u6cd5\u6765\u4f18\u5316\u52a8\u91cf\u8d85\u53c2\u6570\u3002", "result": "\u53d1\u73b0\u56db\u79cd\u4e0d\u540c\u7684\u635f\u5931\u66f2\u7ebf\u5f62\u72b6\uff0c\u5e76\u8bc1\u660eDANA\u5728\u6539\u5584\u8ba1\u7b97\u6700\u4f18\u7f29\u653e\u884c\u4e3a\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "DANA\u5728\u591a\u79cd\u590d\u6742\u5ea6\u4e0b\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u635f\u5931\u6307\u6570\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u6587\u672c\u5b9e\u9a8c\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002"}}
{"id": "2505.15845", "pdf": "https://arxiv.org/pdf/2505.15845", "abs": "https://arxiv.org/abs/2505.15845", "authors": ["Zhibiao Wang", "Yunlong Zhou", "Ziwei Zhang", "Mengmei Zhang", "Shirui Pan", "Chunming Hu", "Xiao Wang"], "title": "Adaptive Tokenization: On the Hop-Overpriority Problem in Tokenized Graph Learning Models", "categories": ["cs.LG"], "comment": null, "summary": "Graph Transformers, leveraging the global attention to capture long-range\ndependencies in graph structures, have significantly advanced graph machine\nlearning, but face prohibitive computational complexity. Tokenized Graph\nLearning Models (TGLMs) address this issue by converting graphs into ordered\ntoken lists for scalable processing. Besides, TGLMs also empower Large Language\nModels (LLMs) to handle text-attributed graphs more effectively and thus are\nalso employed in Graph LLMs. However, existing TGLMs rely on hand-designed\ntoken lists and their adaptability to diverse graph learning scenarios remains\nunexplored. In this paper, we first conduct extensive empirical and theoretical\npreliminary studies for hand-designed token lists. Surprisingly, we identify an\nunexplored hop-overpriority problem: the common pre-defined token lists\noveremphasize nearby nodes and overwhelm the ability of TGLMs to balance local\nand global signals. This phenomenon is especially harmful for heterophilic\ngraphs. To address this problem, we propose the Learnable Graph Token List\n(LGTL), a plug-and-play module to replace hand-designed token lists in TGLMs.\nSpecifically, LGTL adaptively adjusts the weights across hops and prioritizes\ninformative nodes within hops through a graph attention gate module and a\nselection module, respectively. In this way, contextually informative nodes can\nbe adaptively emphasized for both homophilic and heterophilic graphs. Besides,\nwe theoretically show that LGTL can address the hop-overpriority problem.\nExtensive experiments on benchmarks validate the efficacy of LGTL across both\nGraph Transformers and Graph LLM backbones.", "AI": {"tldr": "\u63d0\u51faLearnable Graph Token List (LGTL)\uff0c\u89e3\u51b3\u73b0\u6709Tokenized Graph Learning Models\u4e2d\u624b\u52a8\u751f\u6210\u7684token\u5217\u8868\u5728\u5f02\u8d28\u56fe\u4e0a\u7684hop-overpriority\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684Tokenized Graph Learning Models\u4f9d\u8d56\u4e8e\u624b\u5de5\u8bbe\u8ba1\u7684token\u5217\u8868\uff0c\u8fd9\u4e9b\u5217\u8868\u5728\u5904\u7406\u5f02\u8d28\u56fe\u65f6\u5b58\u5728\u4f18\u5148\u5173\u6ce8\u8fd1\u90bb\u8282\u70b9\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u6a21\u578b\u5e73\u8861\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u53f7\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faLearnable Graph Token List (LGTL)\uff0c\u901a\u8fc7\u56fe\u6ce8\u610f\u529b\u95e8\u6a21\u5757\u548c\u9009\u62e9\u6a21\u5757\u81ea\u9002\u5e94\u8c03\u6574\u8de8\u8df3\u6743\u91cd\u5e76\u4f18\u5148\u9009\u62e9\u4fe1\u606f\u91cf\u5927\u7684\u8282\u70b9\u3002", "result": "LGTL\u5728\u591a\u79cd\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u9002\u7528\u4e8e\u57fa\u4e8eGraph Transformers\u548cGraph LLM\u7684\u4e3b\u5e72\u7f51\u7edc\u3002", "conclusion": "LGTL\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684hop-overpriority\u95ee\u9898\uff0c\u5e76\u63d0\u9ad8\u4e86\u5bf9\u5f02\u8d28\u56fe\u7684\u9002\u5e94\u6027\u3002"}}
{"id": "2505.15862", "pdf": "https://arxiv.org/pdf/2505.15862", "abs": "https://arxiv.org/abs/2505.15862", "authors": ["Long Wanga", "Jiongzhi Zheng", "Zhengda Xiong", "ChuMin Li", "Kun He"], "title": "Bandit based Dynamic Candidate Edge Selection in Solving Traveling Salesman Problems", "categories": ["cs.AI"], "comment": null, "summary": "Algorithms designed for routing problems typically rely on high-quality\ncandidate edges to guide their search, aiming to reduce the search space and\nenhance the search efficiency. However, many existing algorithms, like the\nclassical Lin-Kernighan-Helsgaun (LKH) algorithm for the Traveling Salesman\nProblem (TSP), often use predetermined candidate edges that remain static\nthroughout local searches. This rigidity could cause the algorithm to get\ntrapped in local optima, limiting its potential to find better solutions. To\naddress this issue, we propose expanding the candidate sets to include other\npromising edges, providing them an opportunity for selection. Specifically, we\nincorporate multi-armed bandit models to dynamically select the most suitable\ncandidate edges in each iteration, enabling LKH to make smarter choices and\nlead to improved solutions. Extensive experiments on multiple TSP benchmarks\nshow the excellent performance of our method. Moreover, we employ this\nbandit-based method to LKH-3, an extension of LKH tailored for solving various\nTSP variant problems, and our method also significantly enhances LKH-3's\nperformance across typical TSP variants.", "AI": {"tldr": "This paper proposes a method using multi-armed bandit models to dynamically select candidate edges in the Lin-Kernighan-Helsgaun (LKH) algorithm for solving the Traveling Salesman Problem (TSP). The approach improves solution quality by avoiding getting trapped in local optima.", "motivation": "Existing routing algorithms often use static candidate edges which can limit finding better solutions due to being stuck in local optima.", "method": "Incorporating multi-armed bandit models to dynamically choose candidate edges in LKH iterations.", "result": "The proposed method shows excellent performance on multiple TSP benchmarks and also improves LKH-3's performance on various TSP variant problems.", "conclusion": "Dynamic selection of candidate edges using multi-armed bandit models enhances the LKH algorithm's ability to find better solutions for the TSP."}}
{"id": "2505.16145", "pdf": "https://arxiv.org/pdf/2505.16145", "abs": "https://arxiv.org/abs/2505.16145", "authors": ["Arghya Datta", "Philippe Gagnon", "Florian Maire"], "title": "Exponential Convergence of CAVI for Bayesian PCA", "categories": ["stat.ML", "cs.LG"], "comment": "28 pages, 3 figures", "summary": "Probabilistic principal component analysis (PCA) and its Bayesian variant\n(BPCA) are widely used for dimension reduction in machine learning and\nstatistics. The main advantage of probabilistic PCA over the traditional\nformulation is allowing uncertainty quantification. The parameters of BPCA are\ntypically learned using mean-field variational inference, and in particular,\nthe coordinate ascent variational inference (CAVI) algorithm. So far, the\nconvergence speed of CAVI for BPCA has not been characterized. In our paper, we\nfill this gap in the literature. Firstly, we prove a precise exponential\nconvergence result in the case where the model uses a single principal\ncomponent (PC). Interestingly, this result is established through a connection\nwith the classical $\\textit{power iteration algorithm}$ and it indicates that\ntraditional PCA is retrieved as points estimates of the BPCA parameters.\nSecondly, we leverage recent tools to prove exponential convergence of CAVI for\nthe model with any number of PCs, thus leading to a more general result, but\none that is of a slightly different flavor. To prove the latter result, we\nadditionally needed to introduce a novel lower bound for the symmetric\nKullback--Leibler divergence between two multivariate normal distributions,\nwhich, we believe, is of independent interest in information theory.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8d1d\u53f6\u65af\u6982\u7387\u4e3b\u6210\u5206\u5206\u6790(BPCA)\u4e2d\u5750\u6807\u4e0a\u5347\u53d8\u5206\u63a8\u65ad(CAVI)\u7b97\u6cd5\u7684\u6536\u655b\u6027\u95ee\u9898\uff0c\u586b\u8865\u4e86\u73b0\u6709\u6587\u732e\u4e2d\u7684\u7a7a\u767d\u3002", "motivation": "\u586b\u8865\u4e86\u73b0\u6709\u6587\u732e\u4e2d\u5173\u4e8eBPCA\u4e2dCAVI\u6536\u655b\u901f\u5ea6\u672a\u88ab\u8868\u5f81\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u4e0e\u7ecf\u5178\u5e42\u8fed\u4ee3\u7b97\u6cd5\u7684\u8054\u7cfb\u4ee5\u53ca\u5229\u7528\u6700\u8fd1\u7684\u4fe1\u606f\u8bba\u5de5\u5177\uff0c\u5206\u522b\u8bc1\u660e\u4e86\u5355\u4e3b\u6210\u5206\u548c\u4efb\u610f\u6570\u91cf\u4e3b\u6210\u5206\u60c5\u51b5\u4e0b\u7684\u6307\u6570\u6536\u655b\u6027\u3002", "result": "\u8bc1\u660e\u4e86\u5355\u4e3b\u6210\u5206\u60c5\u51b5\u4e0bCAVI\u7684\u7cbe\u786e\u6307\u6570\u6536\u655b\u7ed3\u679c\uff1b\u8bc1\u660e\u4e86\u4efb\u610f\u6570\u91cf\u4e3b\u6210\u5206\u60c5\u51b5\u4e0bCAVI\u7684\u6307\u6570\u6536\u655b\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u4fe1\u606f\u8bba\u5de5\u5177\u3002", "conclusion": "\u8bc1\u660e\u4e86\u5750\u6807\u4e0a\u5347\u53d8\u5206\u63a8\u65ad(CAVI)\u7b97\u6cd5\u5728BPCA\u6a21\u578b\u4e2d\u7684\u6307\u6570\u6536\u655b\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u591a\u5143\u6b63\u6001\u5206\u5e03\u4e4b\u95f4\u7684\u5bf9\u79f0KL\u6563\u5ea6\u4e0b\u754c\u3002"}}
{"id": "2505.15888", "pdf": "https://arxiv.org/pdf/2505.15888", "abs": "https://arxiv.org/abs/2505.15888", "authors": ["Valentin Villecroze", "Yixin Wang", "Gabriel Loaiza-Ganem"], "title": "Last Layer Empirical Bayes", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at the ICBINB Worshop at ICLR 2025", "summary": "The task of quantifying the inherent uncertainty associated with neural\nnetwork predictions is a key challenge in artificial intelligence. Bayesian\nneural networks (BNNs) and deep ensembles are among the most prominent\napproaches to tackle this task. Both approaches produce predictions by\ncomputing an expectation of neural network outputs over some distribution on\nthe corresponding weights; this distribution is given by the posterior in the\ncase of BNNs, and by a mixture of point masses for ensembles. Inspired by\nrecent work showing that the distribution used by ensembles can be understood\nas a posterior corresponding to a learned data-dependent prior, we propose last\nlayer empirical Bayes (LLEB). LLEB instantiates a learnable prior as a\nnormalizing flow, which is then trained to maximize the evidence lower bound;\nto retain tractability we use the flow only on the last layer. We show why LLEB\nis well motivated, and how it interpolates between standard BNNs and ensembles\nin terms of the strength of the prior that they use. LLEB performs on par with\nexisting approaches, highlighting that empirical Bayes is a promising direction\nfor future research in uncertainty quantification.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5LLEB\uff0c\u5b83\u901a\u8fc7\u4f7f\u7528\u5f52\u4e00\u5316\u6d41\u6765\u5b9e\u4f8b\u5316\u53ef\u5b66\u4e60\u5148\u9a8c\uff0c\u5e76\u5728\u6700\u540e\u4e00\u5c42\u4e0a\u8bad\u7ec3\u4ee5\u6700\u5927\u5316\u8bc1\u636e\u4e0b\u754c\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u91cf\u5316\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u6240\u56fa\u6709\u7684\u4e0d\u786e\u5b9a\u6027\u662f\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5LLEB\uff0c\u5b83\u901a\u8fc7\u4f7f\u7528\u5f52\u4e00\u5316\u6d41\u6765\u5b9e\u4f8b\u5316\u53ef\u5b66\u4e60\u5148\u9a8c\uff0c\u5e76\u5728\u6700\u540e\u4e00\u5c42\u4e0a\u8bad\u7ec3\u4ee5\u6700\u5927\u5316\u8bc1\u636e\u4e0b\u754c\u3002", "result": "LLEB\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u9762\u8868\u73b0\u826f\u597d\u3002", "conclusion": "LLEB\u662f\u7ecf\u9a8c\u8d1d\u53f6\u65af\u7684\u4e00\u4e2a\u6709\u524d\u9014\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2505.15929", "pdf": "https://arxiv.org/pdf/2505.15929", "abs": "https://arxiv.org/abs/2505.15929", "authors": ["Hui Shen", "Taiqiang Wu", "Qi Han", "Yunta Hsieh", "Jizhou Wang", "Yuyue Zhang", "Yuxin Cheng", "Zijian Hao", "Yuansheng Ni", "Xin Wang", "Zhongwei Wan", "Kai Zhang", "Wendong Xu", "Jing Xiong", "Ping Luo", "Wenhu Chen", "Chaofan Tao", "Zhuoqing Mao", "Ngai Wong"], "title": "PhyX: Does Your Model Have the \"Wits\" for Physical Reasoning?", "categories": ["cs.AI"], "comment": null, "summary": "Existing benchmarks fail to capture a crucial aspect of intelligence:\nphysical reasoning, the integrated ability to combine domain knowledge,\nsymbolic reasoning, and understanding of real-world constraints. To address\nthis gap, we introduce PhyX: the first large-scale benchmark designed to assess\nmodels capacity for physics-grounded reasoning in visual scenarios. PhyX\nincludes 3K meticulously curated multimodal questions spanning 6 reasoning\ntypes across 25 sub-domains and 6 core physics domains: thermodynamics,\nelectromagnetism, mechanics, modern physics, optics, and wave\\&acoustics. In\nour comprehensive evaluation, even state-of-the-art models struggle\nsignificantly with physical reasoning. GPT-4o, Claude3.7-Sonnet, and\nGPT-o4-mini achieve only 32.5\\%, 42.2\\%, and 45.8\\% accuracy\nrespectively-performance gaps exceeding 29\\% compared to human experts. Our\nanalysis exposes critical limitations in current models: over-reliance on\nmemorized disciplinary knowledge, excessive dependence on mathematical\nformulations, and surface-level visual pattern matching rather than genuine\nphysical understanding. We provide in-depth analysis through fine-grained\nstatistics, detailed case studies, and multiple evaluation paradigms to\nthoroughly examine physical reasoning capabilities. To ensure reproducibility,\nwe implement a compatible evaluation protocol based on widely-used toolkits\nsuch as VLMEvalKit, enabling one-click evaluation.", "AI": {"tldr": "Introducing PhyX, a new benchmark that tests AI's physical reasoning in visual scenarios, reveals significant performance gaps between top AI models and humans.", "motivation": "To address the lack of benchmarks capturing physical reasoning, an essential aspect of intelligence.", "method": "The introduction of PhyX, a large-scale benchmark that evaluates models' capacity for physics-grounded reasoning in visual scenarios.", "result": "State-of-the-art models perform poorly on PhyX, with accuracy below 50% compared to human experts.", "conclusion": "PhyX benchmark highlights the significant gap between current AI models and human-level physical reasoning capabilities."}}
{"id": "2505.16156", "pdf": "https://arxiv.org/pdf/2505.16156", "abs": "https://arxiv.org/abs/2505.16156", "authors": ["Siu Lun Chau", "Michele Caprio", "Krikamol Muandet"], "title": "Integral Imprecise Probability Metrics", "categories": ["stat.ML", "cs.LG"], "comment": "50 pages, 2 figures", "summary": "Quantifying differences between probability distributions is fundamental to\nstatistics and machine learning, primarily for comparing statistical\nuncertainty. In contrast, epistemic uncertainty (EU) -- due to incomplete\nknowledge -- requires richer representations than those offered by classical\nprobability. Imprecise probability (IP) theory offers such models, capturing\nambiguity and partial belief. This has driven growing interest in imprecise\nprobabilistic machine learning (IPML), where inference and decision-making rely\non broader uncertainty models -- highlighting the need for metrics beyond\nclassical probability. This work introduces the Integral Imprecise Probability\nMetric (IIPM) framework, a Choquet integral-based generalisation of classical\nIntegral Probability Metric (IPM) to the setting of capacities -- a broad class\nof IP models encompassing many existing ones, including lower probabilities,\nprobability intervals, belief functions, and more. Theoretically, we establish\nconditions under which IIPM serves as a valid metric and metrises a form of\nweak convergence of capacities. Practically, IIPM not only enables comparison\nacross different IP models but also supports the quantification of epistemic\nuncertainty within a single IP model. In particular, by comparing an IP model\nwith its conjugate, IIPM gives rise to a new class of EU measures -- Maximum\nMean Imprecision -- which satisfy key axiomatic properties proposed in the\nUncertainty Quantification literature. We validate MMI through selective\nclassification experiments, demonstrating strong empirical performance against\nestablished EU measures, and outperforming them when classical methods struggle\nto scale to a large number of classes. Our work advances both theory and\npractice in IPML, offering a principled framework for comparing and quantifying\nepistemic uncertainty under imprecision.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79ef\u5206\u4e0d\u7cbe\u786e\u6982\u7387\u5ea6\u91cf\uff08IIPM\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u6bd4\u8f83\u548c\u91cf\u5316\u8ba4\u8bc6\u4e0d\u786e\u5b9a\u6027\uff08EU\uff09\u3002", "motivation": "\u7ecf\u5178\u6982\u7387\u4e0d\u8db3\u4ee5\u8868\u793a\u8ba4\u8bc6\u4e0d\u786e\u5b9a\u6027\uff08EU\uff09\uff0c\u800c\u6a21\u7cca\u6982\u7387\uff08IP\uff09\u7406\u8bba\u63d0\u4f9b\u4e86\u8fd9\u6837\u7684\u6a21\u578b\uff0c\u56e0\u6b64\u9700\u8981\u8d85\u8d8a\u7ecf\u5178\u6982\u7387\u7684\u5ea6\u91cf\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eChoquet\u79ef\u5206\u7684\u79ef\u5206\u4e0d\u7cbe\u786e\u6982\u7387\u5ea6\u91cf\uff08IIPM\uff09\u6846\u67b6\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u4f5c\u4e3a\u6709\u6548\u5ea6\u91cf\u7684\u6761\u4ef6\u4ee5\u53ca\u652f\u6301\u5f31\u6536\u655b\u7684\u5ea6\u91cf\u5316\u3002", "result": "IIPM\u80fd\u591f\u8de8\u4e0d\u540c\u7684IP\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\uff0c\u5e76\u5728\u4e00\u4e2a\u5355\u4e00\u7684IP\u6a21\u578b\u5185\u652f\u6301\u5bf9\u8ba4\u8bc6\u4e0d\u786e\u5b9a\u6027\u7684\u91cf\u5316\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u6700\u5927\u5747\u503c\u4e0d\u7cbe\u786e\u6027\uff08MMI\uff09\u5ea6\u91cf\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u9009\u62e9\u6027\u5206\u7c7b\u5b9e\u9a8c\u4e2d\u7684\u8868\u73b0\u3002", "conclusion": "\u63d0\u51fa\u4e86\u79ef\u5206\u4e0d\u7cbe\u786e\u6982\u7387\u5ea6\u91cf\uff08IIPM\uff09\u6846\u67b6\uff0c\u5b83\u5728\u80fd\u529b\u8bbe\u7f6e\u4e0a\u63a8\u5e7f\u4e86\u7ecf\u5178\u7684\u79ef\u5206\u6982\u7387\u5ea6\u91cf\uff08IPM\uff09\uff0c\u5e76\u4e14\u5728\u7406\u8bba\u4e0a\u5efa\u7acb\u4e86IIPM\u4f5c\u4e3a\u6709\u6548\u5ea6\u91cf\u7684\u6761\u4ef6\uff0c\u5e76\u4e14\u652f\u6301\u5f31\u6536\u655b\u7684\u5ea6\u91cf\u5316\u3002\u5b9e\u8df5\u4e0a\uff0cIIPM\u4e0d\u4ec5\u80fd\u591f\u8de8\u4e0d\u540c\u7684IP\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\uff0c\u8fd8\u80fd\u5728\u4e00\u4e2a\u5355\u4e00\u7684IP\u6a21\u578b\u5185\u652f\u6301\u5bf9\u8ba4\u8bc6\u4e0d\u786e\u5b9a\u6027\uff08EU\uff09\u7684\u91cf\u5316\u3002\u901a\u8fc7\u9009\u62e9\u6027\u5206\u7c7b\u5b9e\u9a8c\u9a8c\u8bc1\u4e86IIPM\u7684\u8868\u73b0\u3002"}}
{"id": "2505.15909", "pdf": "https://arxiv.org/pdf/2505.15909", "abs": "https://arxiv.org/abs/2505.15909", "authors": ["Alex Kogan"], "title": "Is (Selective) Round-To-Nearest Quantization All You Need?", "categories": ["cs.LG", "I.2.7; D.4.8; G.4"], "comment": null, "summary": "Quantization became a necessary tool for serving ever-increasing Large\nLanguage Models (LLMs). RTN (Round-to-Nearest) is perhaps the simplest\nquantization technique that has been around well before LLMs surged to the\nforefront of machine learning (ML) research. Yet, it has been largely dismissed\nby recent and more advanced quantization methods that claim superiority over\nRTN in nearly every aspect of performance. This work aims to dispel this\nestablished point of view, showing that RTN is not only much cheaper to apply,\nbut also its token generation throughput can be better than and accuracy can be\nsimilar to more advanced alternatives. In particular, we discuss our\nimplementation of RTN based on the recent Marlin kernels and demonstrate how\nthe accuracy of RTN can be gradually improved by selectively increasing the\ndata precision format of certain model layers and modules. Based on our\nresults, we argue that RTN presents a viable and practical choice for\nquantizing LLMs.", "AI": {"tldr": "This work shows that the Round-to-Nearest (RTN) quantization method, despite being considered outdated, is cost-effective and comparable in performance to more advanced methods when properly optimized.", "motivation": "To challenge the established viewpoint that RTN is inferior to more advanced quantization methods.", "method": "Implementation of RTN based on Marlin kernels and selective increase in data precision format.", "result": "RTN is shown to be cheaper to apply with better token generation throughput and similar accuracy after optimization.", "conclusion": "RTN is a viable and practical choice for quantizing large language models."}}
{"id": "2505.15998", "pdf": "https://arxiv.org/pdf/2505.15998", "abs": "https://arxiv.org/abs/2505.15998", "authors": ["Thomas Michel", "Marko Cvjetko", "Gautier Hamon", "Pierre-Yves Oudeyer", "Cl\u00e9ment Moulin-Frier"], "title": "Exploring Flow-Lenia Universes with a Curiosity-driven AI Scientist: Discovering Diverse Ecosystem Dynamics", "categories": ["cs.AI"], "comment": "10 pages, 10 figures, submitted to ALIFE 2025 Conference", "summary": "We present a method for the automated discovery of system-level dynamics in\nFlow-Lenia$-$a continuous cellular automaton (CA) with mass conservation and\nparameter localization$-$using a curiosity-driven AI scientist. This method\naims to uncover processes leading to self-organization of evolutionary and\necosystemic dynamics in CAs. We build on previous work which uses diversity\nsearch algorithms in Lenia to find self-organized individual patterns, and\nextend it to large environments that support distinct interacting patterns. We\nadapt Intrinsically Motivated Goal Exploration Processes (IMGEPs) to drive\nexploration of diverse Flow-Lenia environments using simulation-wide metrics,\nsuch as evolutionary activity, compression-based complexity, and multi-scale\nentropy. We test our method in two experiments, showcasing its ability to\nilluminate significantly more diverse dynamics compared to random search. We\nshow qualitative results illustrating how ecosystemic simulations enable\nself-organization of complex collective behaviors not captured by previous\nindividual pattern search and analysis. We complement automated discovery with\nan interactive exploration tool, creating an effective human-AI collaborative\nworkflow for scientific investigation. Though demonstrated specifically with\nFlow-Lenia, this methodology provides a framework potentially applicable to\nother parameterizable complex systems where understanding emergent collective\nproperties is of interest.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u597d\u5947\u5fc3\u9a71\u52a8\u7684\u4eba\u5de5\u667a\u80fd\u79d1\u5b66\u5bb6\u81ea\u52a8\u53d1\u73b0Flow-Lenia\u7cfb\u7edf\u7ea7\u52a8\u6001\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u63ed\u793a\u5bfc\u81f4\u7ec6\u80de\u81ea\u52a8\u673a\u81ea\u7ec4\u7ec7\u6f14\u5316\u7684\u52a8\u529b\u8fc7\u7a0b\uff0c\u5e76\u4e14\u5728\u5927\u73af\u5883\u4e2d\u652f\u6301\u4e0d\u540c\u4ea4\u4e92\u6a21\u5f0f\u3002\u901a\u8fc7\u9002\u5e94\u5185\u5728\u52a8\u673a\u76ee\u6807\u63a2\u7d22\u8fc7\u7a0b\u6765\u9a71\u52a8\u591a\u6837\u5316\u7684Flow-Lenia\u73af\u5883\u63a2\u7d22\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u968f\u673a\u641c\u7d22\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u80fd\u63ed\u793a\u51fa\u66f4\u52a0\u591a\u6837\u7684\u52a8\u6001\u3002\u540c\u65f6\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e92\u52a8\u63a2\u7d22\u5de5\u5177\uff0c\u5f62\u6210\u4e86\u6709\u6548\u7684\u4eba\u5de5\u667a\u80fd\u8f85\u52a9\u79d1\u5b66\u7814\u7a76\u5de5\u4f5c\u6d41\u7a0b\u3002\u867d\u7136\u8be5\u65b9\u6cd5\u662f\u5728Flow-Lenia\u4e0a\u5c55\u793a\u7684\uff0c\u4f46\u5b83\u4e5f\u4e3a\u7406\u89e3\u5176\u4ed6\u53ef\u53c2\u6570\u5316\u590d\u6742\u7cfb\u7edf\u7684\u6d8c\u73b0\u96c6\u4f53\u5c5e\u6027\u63d0\u4f9b\u4e86\u6846\u67b6\u3002", "motivation": "\u7814\u7a76Flow-Lenia\u7cfb\u7edf\u7ea7\u52a8\u6001\uff0c\u7279\u522b\u662f\u81ea\u7ec4\u7ec7\u6f14\u5316\u548c\u751f\u6001\u7cfb\u7edf\u52a8\u529b\u5b66\u7684\u8fc7\u7a0b\u3002", "method": "\u4f7f\u7528\u597d\u5947\u5fc3\u9a71\u52a8\u7684\u4eba\u5de5\u667a\u80fd\u79d1\u5b66\u5bb6\uff0c\u7ed3\u5408\u5185\u5728\u52a8\u673a\u76ee\u6807\u63a2\u7d22\u8fc7\u7a0b\uff08IMGEPs\uff09\uff0c\u901a\u8fc7\u6a21\u62df\u8303\u56f4\u5185\u7684\u6307\u6807\uff08\u5982\u8fdb\u5316\u6d3b\u52a8\u3001\u57fa\u4e8e\u538b\u7f29\u7684\u590d\u6742\u6027\u548c\u591a\u5c3a\u5ea6\u71b5\uff09\u6765\u9a71\u52a8\u5bf9Flow-Lenia\u73af\u5883\u7684\u63a2\u7d22\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e24\u4e2a\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u5176\u80fd\u529b\uff0c\u53ef\u4ee5\u63ed\u793a\u6bd4\u968f\u673a\u641c\u7d22\u66f4\u591a\u7684\u591a\u6837\u5316\u52a8\u6001\u3002\u6b64\u5916\uff0c\u8fd8\u5c55\u793a\u4e86\u751f\u6001\u6a21\u62df\u5982\u4f55\u4fc3\u8fdb\u590d\u6742\u96c6\u4f53\u884c\u4e3a\u7684\u81ea\u7ec4\u7ec7\uff0c\u8fd9\u4e9b\u884c\u4e3a\u672a\u88ab\u4ee5\u524d\u7684\u4e2a\u4f53\u6a21\u5f0f\u641c\u7d22\u548c\u5206\u6790\u6355\u6349\u5230\u3002", "conclusion": "\u6b64\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8eFlow-Lenia\uff0c\u4e5f\u4e3a\u7406\u89e3\u5176\u4ed6\u53ef\u53c2\u6570\u5316\u590d\u6742\u7cfb\u7edf\u7684\u6d8c\u73b0\u96c6\u4f53\u5c5e\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6f5c\u5728\u9002\u7528\u7684\u6846\u67b6\u3002"}}
{"id": "2505.16244", "pdf": "https://arxiv.org/pdf/2505.16244", "abs": "https://arxiv.org/abs/2505.16244", "authors": ["Masanari Kimura", "Howard Bondell"], "title": "Generalized Power Priors for Improved Bayesian Inference with Historical Data", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "The power prior is a class of informative priors designed to incorporate\nhistorical data alongside current data in a Bayesian framework. It includes a\npower parameter that controls the influence of historical data, providing\nflexibility and adaptability. A key property of the power prior is that the\nresulting posterior minimizes a linear combination of KL divergences between\ntwo pseudo-posterior distributions: one ignoring historical data and the other\nfully incorporating it. We extend this framework by identifying the posterior\ndistribution as the minimizer of a linear combination of Amari's\n$\\alpha$-divergence, a generalization of KL divergence. We show that this\ngeneralization can lead to improved performance by allowing for the data to\nadapt to appropriate choices of the $\\alpha$ parameter. Theoretical properties\nof this generalized power posterior are established, including behavior as a\ngeneralized geodesic on the Riemannian manifold of probability distributions,\noffering novel insights into its geometric interpretation.", "AI": {"tldr": "This paper extends the power prior framework by using Amari's \u03b1-divergence instead of KL divergence, showing potential for improved performance and offering new geometric insights.", "motivation": "To enhance the power prior framework by generalizing it with a more flexible divergence measure.", "method": "Reformulating the power prior as the minimizer of a linear combination of Amari's \u03b1-divergence.", "result": "Improved performance due to better adaptation to data via appropriate \u03b1 parameter choices.", "conclusion": "This generalized power prior provides deeper geometric understanding and potentially better performance in Bayesian analysis."}}
{"id": "2505.15931", "pdf": "https://arxiv.org/pdf/2505.15931", "abs": "https://arxiv.org/abs/2505.15931", "authors": ["Morteza Alizadeh", "Mehrdad Oveisi", "Sonya Falahati", "Ghazal Mousavi", "Mohsen Alambardar Meybodi", "Somayeh Sadat Mehrnia", "Ilker Hacihaliloglu", "Arman Rahmim", "Mohammad R. Salmanpour"], "title": "AllMetrics: A Unified Python Library for Standardized Metric Evaluation and Robust Data Validation in Machine Learning", "categories": ["cs.LG", "F.2.2; I.2.7"], "comment": null, "summary": "Machine learning (ML) models rely heavily on consistent and accurate\nperformance metrics to evaluate and compare their effectiveness. However,\nexisting libraries often suffer from fragmentation, inconsistent\nimplementations, and insufficient data validation protocols, leading to\nunreliable results. Existing libraries have often been developed independently\nand without adherence to a unified standard, particularly concerning the\nspecific tasks they aim to support. As a result, each library tends to adopt\nits conventions for metric computation, input/output formatting, error\nhandling, and data validation protocols. This lack of standardization leads to\nboth implementation differences (ID) and reporting differences (RD), making it\ndifficult to compare results across frameworks or ensure reliable evaluations.\nTo address these issues, we introduce AllMetrics, an open-source unified Python\nlibrary designed to standardize metric evaluation across diverse ML tasks,\nincluding regression, classification, clustering, segmentation, and\nimage-to-image translation. The library implements class-specific reporting for\nmulti-class tasks through configurable parameters to cover all use cases, while\nincorporating task-specific parameters to resolve metric computation\ndiscrepancies across implementations. Various datasets from domains like\nhealthcare, finance, and real estate were applied to our library and compared\nwith Python, Matlab, and R components to identify which yield similar results.\nAllMetrics combines a modular Application Programming Interface (API) with\nrobust input validation mechanisms to ensure reproducibility and reliability in\nmodel evaluation. This paper presents the design principles, architectural\ncomponents, and empirical analyses demonstrating the ability to mitigate\nevaluation errors and to enhance the trustworthiness of ML workflows.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aAllMetrics\u7684\u65b0\u5e93\uff0c\u5b83\u662f\u4e00\u4e2a\u5f00\u6e90\u7684Python\u5e93\uff0c\u65e8\u5728\u901a\u8fc7\u7edf\u4e00\u7684\u6807\u51c6\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u6027\u80fd\u8bc4\u4f30\u4e2d\u7684\u4e0d\u4e00\u81f4\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u673a\u5668\u5b66\u4e60\u6027\u80fd\u8bc4\u4f30\u5e93\u5b58\u5728\u788e\u7247\u5316\u3001\u4e0d\u4e00\u81f4\u7684\u5b9e\u73b0\u4ee5\u53ca\u6570\u636e\u9a8c\u8bc1\u534f\u8bae\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u65e0\u6cd5\u53ef\u9760\u5730\u6bd4\u8f83\u4e0d\u540c\u6846\u67b6\u7684\u7ed3\u679c\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u540d\u4e3aAllMetrics\u7684\u5f00\u6e90Python\u5e93\uff0c\u8be5\u5e93\u7edf\u4e00\u4e86\u591a\u79cd\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u7684\u6027\u80fd\u5ea6\u91cf\u6807\u51c6\uff0c\u5e76\u901a\u8fc7\u6a21\u5757\u5316API\u548c\u5f3a\u5927\u7684\u8f93\u5165\u9a8c\u8bc1\u673a\u5236\u786e\u4fdd\u4e86\u8bc4\u4f30\u7684\u53ef\u91cd\u590d\u6027\u548c\u53ef\u9760\u6027\u3002", "result": "AllMetrics\u5728\u591a\u4e2a\u9886\u57df\uff08\u5982\u533b\u7597\u4fdd\u5065\u3001\u91d1\u878d\u548c\u623f\u5730\u4ea7\uff09\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u5e76\u4e0ePython\u3001Matlab\u548cR\u4e2d\u7684\u7ec4\u4ef6\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u53d1\u73b0\u5176\u80fd\u591f\u4ea7\u751f\u76f8\u4f3c\u7684\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51faAllMetrics\u5e93\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u673a\u5668\u5b66\u4e60\u6027\u80fd\u8bc4\u4f30\u4e2d\u7684\u6807\u51c6\u5316\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u8bc4\u4ef7\u7684\u53ef\u9760\u6027\u548c\u4e00\u81f4\u6027\u3002"}}
{"id": "2505.16031", "pdf": "https://arxiv.org/pdf/2505.16031", "abs": "https://arxiv.org/abs/2505.16031", "authors": ["Aayushi Dangol", "Robert Wolfe", "Runhua Zhao", "JaeWon Kim", "Trushaa Ramanan", "Katie Davis", "Julie A. Kientz"], "title": "Children's Mental Models of AI Reasoning: Implications for AI Literacy Education", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "As artificial intelligence (AI) advances in reasoning capabilities, most\nrecently with the emergence of Large Reasoning Models (LRMs), understanding how\nchildren conceptualize AI's reasoning processes becomes critical for fostering\nAI literacy. While one of the \"Five Big Ideas\" in AI education highlights\nreasoning algorithms as central to AI decision-making, less is known about\nchildren's mental models in this area. Through a two-phase approach, consisting\nof a co-design session with 8 children followed by a field study with 106\nchildren (grades 3-8), we identified three models of AI reasoning: Deductive,\nInductive, and Inherent. Our findings reveal that younger children (grades 3-5)\noften attribute AI's reasoning to inherent intelligence, while older children\n(grades 6-8) recognize AI as a pattern recognizer. We highlight three tensions\nthat surfaced in children's understanding of AI reasoning and conclude with\nimplications for scaffolding AI curricula and designing explainable AI tools.", "AI": {"tldr": "\u7814\u7a76\u4e86\u513f\u7ae5\u5bf9\u4eba\u5de5\u667a\u80fd\u63a8\u7406\u8fc7\u7a0b\u7684\u7406\u89e3\uff0c\u8bc6\u522b\u51fa\u4e09\u79cd\u6a21\u578b\uff1a\u6f14\u7ece\u3001\u5f52\u7eb3\u548c\u56fa\u6709\u3002\u53d1\u73b0\u5e74\u5e7c\u7684\u5b69\u5b50\u8ba4\u4e3aAI\u6709\u56fa\u6709\u7684\u667a\u80fd\uff0c\u800c\u5e74\u957f\u7684\u5b69\u5b50\u8ba4\u8bc6\u5230AI\u662f\u4e00\u4e2a\u6a21\u5f0f\u8bc6\u522b\u5668\u3002\u63d0\u51fa\u4e86\u652f\u6301AI\u8bfe\u7a0b\u548c\u8bbe\u8ba1\u53ef\u89e3\u91caAI\u5de5\u5177\u7684\u542f\u793a\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u63a8\u7406\u80fd\u529b\u7684\u53d1\u5c55\uff0c\u7279\u522b\u662f\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u7684\u51fa\u73b0\uff0c\u7406\u89e3\u513f\u7ae5\u5982\u4f55\u6982\u5ff5\u5316AI\u7684\u63a8\u7406\u8fc7\u7a0b\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u4fc3\u8fdbAI\u7d20\u517b\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u5305\u62ec\u4e0e8\u4e2a\u5b69\u5b50\u8fdb\u884c\u534f\u540c\u8bbe\u8ba1\u4f1a\u8bae\uff0c\u7136\u540e\u4e0e106\u4e2a\u5b69\u5b50\uff083-8\u5e74\u7ea7\uff09\u8fdb\u884c\u5b9e\u5730\u7814\u7a76\u3002", "result": "\u8bc6\u522b\u51fa\u4e09\u79cdAI\u63a8\u7406\u6a21\u578b\uff1a\u6f14\u7ece\u3001\u5f52\u7eb3\u548c\u56fa\u6709\u3002\u53d1\u73b0\u5e74\u5e7c\u7684\u5b69\u5b50\uff083-5\u5e74\u7ea7\uff09\u901a\u5e38\u5c06AI\u7684\u63a8\u7406\u5f52\u56e0\u4e8e\u56fa\u6709\u7684\u667a\u80fd\uff0c\u800c\u5e74\u957f\u7684\u5b69\u5b50\uff086-8\u5e74\u7ea7\uff09\u5219\u8ba4\u8bc6\u5230AI\u662f\u4e00\u4e2a\u6a21\u5f0f\u8bc6\u522b\u5668\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5728\u652f\u6301AI\u8bfe\u7a0b\u548c\u8bbe\u8ba1\u53ef\u89e3\u91caAI\u5de5\u5177\u65b9\u9762\u7684\u542f\u793a\u3002"}}
{"id": "2505.16251", "pdf": "https://arxiv.org/pdf/2505.16251", "abs": "https://arxiv.org/abs/2505.16251", "authors": ["Masanari Kimura"], "title": "Graph-Smoothed Bayesian Black-Box Shift Estimator and Its Information Geometry", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Label shift adaptation aims to recover target class priors when the labelled\nsource distribution $P$ and the unlabelled target distribution $Q$ share $P(X\n\\mid Y) = Q(X \\mid Y)$ but $P(Y) \\neq Q(Y)$. Classical black-box shift\nestimators invert an empirical confusion matrix of a frozen classifier,\nproducing a brittle point estimate that ignores sampling noise and similarity\namong classes. We present Graph-Smoothed Bayesian BBSE (GS-B$^3$SE), a fully\nprobabilistic alternative that places Laplacian-Gaussian priors on both target\nlog-priors and confusion-matrix columns, tying them together on a\nlabel-similarity graph. The resulting posterior is tractable with HMC or a fast\nblock Newton-CG scheme. We prove identifiability, $N^{-1/2}$ contraction,\nvariance bounds that shrink with the graph's algebraic connectivity, and\nrobustness to Laplacian misspecification. We also reinterpret GS-B$^3$SE\nthrough information geometry, showing that it generalizes existing shift\nestimators.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u56fe\u5e73\u6ed1\u8d1d\u53f6\u65af\u65b9\u6cd5(GS-B\u00b3SE)\u89e3\u51b3\u6807\u7b7e\u8f6c\u79fb\u9002\u5e94\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728\u76ee\u6807\u5148\u9a8c\u548c\u6df7\u6dc6\u77e9\u9635\u5217\u4e0a\u653e\u7f6e\u62c9\u666e\u62c9\u65af-\u9ad8\u65af\u5148\u9a8c\uff0c\u5e76\u5728\u6807\u8bb0\u76f8\u4f3c\u6027\u56fe\u4e0a\u8fdb\u884c\u5173\u8054\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b8c\u5168\u6982\u7387\u6027\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7ecf\u5178\u9ed1\u76d2\u79fb\u4f4d\u4f30\u8ba1\u5668\u5b58\u5728\u8106\u5f31\u6027\uff0c\u4f1a\u5ffd\u7565\u91c7\u6837\u566a\u58f0\u548c\u7c7b\u522b\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u3002", "method": "GS-B\u00b3SE\u65b9\u6cd5\u5728\u76ee\u6807\u5148\u9a8c\u548c\u6df7\u6dc6\u77e9\u9635\u5217\u4e0a\u653e\u7f6e\u62c9\u666e\u62c9\u65af-\u9ad8\u65af\u5148\u9a8c\uff0c\u5e76\u5728\u6807\u7b7e\u76f8\u4f3c\u6027\u56fe\u4e0a\u8fdb\u884c\u5173\u8054\uff0c\u63d0\u4f9b\u4e86\u5b8c\u5168\u6982\u7387\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u8bc1\u660e\u4e86\u53ef\u8bc6\u522b\u6027\u3001N\u207b\u00b9/\u00b2\u6536\u655b\u3001\u968f\u56fe\u4ee3\u6570\u8fde\u901a\u6027\u589e\u52a0\u7684\u65b9\u5dee\u754c\u7f29\u5c0f\u4ee5\u53ca\u62c9\u666e\u62c9\u65af\u8bef\u6307\u5b9a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "GS-B\u00b3SE\u65b9\u6cd5\u91cd\u65b0\u89e3\u91ca\u4e86\u4fe1\u606f\u51e0\u4f55\uff0c\u63a8\u5e7f\u4e86\u73b0\u6709\u7684\u79fb\u4f4d\u4f30\u8ba1\u5668\u3002"}}
{"id": "2505.15946", "pdf": "https://arxiv.org/pdf/2505.15946", "abs": "https://arxiv.org/abs/2505.15946", "authors": ["Yuxiang Wei", "Yanteng Zhang", "Xi Xiao", "Tianyang Wang", "Xiao Wang", "Vince D. Calhoun"], "title": "MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.HC"], "comment": null, "summary": "Decoding visual experiences from fMRI offers a powerful avenue to understand\nhuman perception and develop advanced brain-computer interfaces. However,\ncurrent progress often prioritizes maximizing reconstruction fidelity while\noverlooking interpretability, an essential aspect for deriving neuroscientific\ninsight. To address this gap, we propose MoRE-Brain, a neuro-inspired framework\ndesigned for high-fidelity, adaptable, and interpretable visual reconstruction.\nMoRE-Brain uniquely employs a hierarchical Mixture-of-Experts architecture\nwhere distinct experts process fMRI signals from functionally related voxel\ngroups, mimicking specialized brain networks. The experts are first trained to\nencode fMRI into the frozen CLIP space. A finetuned diffusion model then\nsynthesizes images, guided by expert outputs through a novel dual-stage routing\nmechanism that dynamically weighs expert contributions across the diffusion\nprocess. MoRE-Brain offers three main advancements: First, it introduces a\nnovel Mixture-of-Experts architecture grounded in brain network principles for\nneuro-decoding. Second, it achieves efficient cross-subject generalization by\nsharing core expert networks while adapting only subject-specific routers.\nThird, it provides enhanced mechanistic insight, as the explicit routing\nreveals precisely how different modeled brain regions shape the semantic and\nspatial attributes of the reconstructed image. Extensive experiments validate\nMoRE-Brain's high reconstruction fidelity, with bottleneck analyses further\ndemonstrating its effective utilization of fMRI signals, distinguishing genuine\nneural decoding from over-reliance on generative priors. Consequently,\nMoRE-Brain marks a substantial advance towards more generalizable and\ninterpretable fMRI-based visual decoding. Code will be publicly available soon:\nhttps://github.com/yuxiangwei0808/MoRE-Brain.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMoRE-Brain\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u529f\u80fd\u78c1\u5171\u632f\u6210\u50cf(fMRI)\u4fe1\u53f7\u4e2d\u89e3\u7801\u89c6\u89c9\u4f53\u9a8c\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u8111\u542f\u53d1\u7684Mixture-of-Experts\u67b6\u6784\u4e0e\u6269\u6563\u6a21\u578b\uff0c\u65e8\u5728\u5b9e\u73b0\u9ad8\u4fdd\u771f\u5ea6\u3001\u53ef\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u89c6\u89c9\u91cd\u5efa\u3002", "motivation": "\u5f53\u524dfMRI\u89c6\u89c9\u89e3\u7801\u7814\u7a76\u8fc7\u4e8e\u5173\u6ce8\u91cd\u5efa\u4fdd\u771f\u5ea6\u800c\u5ffd\u89c6\u4e86\u89e3\u91ca\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u795e\u7ecf\u79d1\u5b66\u6d1e\u89c1\u7684\u83b7\u53d6\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8111\u7f51\u7edc\u539f\u7406\u7684\u5c42\u7ea7\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\uff0c\u5e76\u5f15\u5165\u4e86\u53cc\u9636\u6bb5\u8def\u7531\u673a\u5236\u6765\u52a8\u6001\u8c03\u6574\u4e0d\u540c\u4e13\u5bb6\u7684\u8d21\u732e\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86MoRE-Brain\u5728\u9ad8\u4fdd\u771f\u89c6\u89c9\u91cd\u5efa\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u74f6\u9888\u5206\u6790\u8bc1\u660e\u4e86\u5176\u5bf9fMRI\u4fe1\u53f7\u7684\u6709\u6548\u5229\u7528\u3002", "conclusion": "MoRE-Brain\u5b9e\u73b0\u4e86\u66f4\u901a\u7528\u4e14\u53ef\u89e3\u91ca\u7684fMRI\u89c6\u89c9\u89e3\u7801\uff0c\u6807\u5fd7\u7740\u8be5\u9886\u57df\u7684\u91cd\u8981\u8fdb\u6b65\u3002"}}
{"id": "2505.16037", "pdf": "https://arxiv.org/pdf/2505.16037", "abs": "https://arxiv.org/abs/2505.16037", "authors": ["Asterios Tsiourvas", "Wei Sun", "Georgia Perakis"], "title": "Causal LLM Routing: End-to-End Regret Minimization from Observational Data", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "LLM routing aims to select the most appropriate model for each query,\nbalancing competing performance metrics such as accuracy and cost across a pool\nof language models. Prior approaches typically adopt a decoupled strategy,\nwhere the metrics are first predicted and the model is then selected based on\nthese estimates. This setup is prone to compounding errors and often relies on\nfull-feedback data, where each query is evaluated by all candidate models,\nwhich is costly to obtain and maintain in practice. In contrast, we learn from\nobservational data, which records only the outcome of the model actually\ndeployed. We propose a causal end-to-end framework that learns routing policies\nby minimizing decision-making regret from observational data. To enable\nefficient optimization, we introduce two theoretically grounded surrogate\nobjectives: a classification-based upper bound, and a softmax-weighted regret\napproximation shown to recover the optimal policy at convergence. We further\nextend our framework to handle heterogeneous cost preferences via an\ninterval-conditioned architecture. Experiments on public benchmarks show that\nour method outperforms existing baselines, achieving state-of-the-art\nperformance across different embedding models.", "AI": {"tldr": "This paper introduces a causal end-to-end framework for LLM routing that learns from observational data, introducing two surrogate objectives for efficient optimization and extending the framework to handle heterogeneous cost preferences.", "motivation": "Existing methods for LLM routing rely on decoupled strategies and full-feedback data, which can lead to compounding errors and high costs.", "method": "Proposes a causal end-to-end framework that minimizes decision-making regret from observational data, with two surrogate objectives: a classification-based upper bound and a softmax-weighted regret approximation.", "result": "The proposed method outperforms existing baselines on public benchmarks, achieving state-of-the-art performance across different embedding models.", "conclusion": "The proposed framework provides a more efficient and effective approach to LLM routing by learning from observational data and handling heterogeneous cost preferences."}}
{"id": "2505.16257", "pdf": "https://arxiv.org/pdf/2505.16257", "abs": "https://arxiv.org/abs/2505.16257", "authors": ["Masanari Kimura"], "title": "Higher-Order Asymptotics of Test-Time Adaptation for Batch Normalization Statistics", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This study develops a higher-order asymptotic framework for test-time\nadaptation (TTA) of Batch Normalization (BN) statistics under distribution\nshift by integrating classical Edgeworth expansion and saddlepoint\napproximation techniques with a novel one-step M-estimation perspective. By\nanalyzing the statistical discrepancy between training and test distributions,\nwe derive an Edgeworth expansion for the normalized difference in BN means and\nobtain an optimal weighting parameter that minimizes the mean-squared error of\nthe adapted statistic. Reinterpreting BN TTA as a one-step M-estimator allows\nus to derive higher-order local asymptotic normality results, which incorporate\nskewness and other higher moments into the estimator's behavior. Moreover, we\nquantify the trade-offs among bias, variance, and skewness in the adaptation\nprocess and establish a corresponding generalization bound on the model risk.\nThe refined saddlepoint approximations further deliver uniformly accurate\ndensity and tail probability estimates for the BN TTA statistic. These\ntheoretical insights provide a comprehensive understanding of how higher-order\ncorrections and robust one-step updating can enhance the reliability and\nperformance of BN layers in adapting to changing data distributions.", "AI": {"tldr": "This study develops a new framework for test-time adaptation of Batch Normalization statistics under distribution shift using advanced statistical methods.", "motivation": "To improve the reliability and performance of BN layers when adapting to changing data distributions.", "method": "Integrating Edgeworth expansion, saddlepoint approximation techniques, and a novel one-step M-estimation perspective.", "result": "Derives an optimal weighting parameter, higher-order local asymptotic normality results, and establishes a generalization bound on model risk.", "conclusion": "Higher-order corrections and robust one-step updating enhance the reliability and performance of BN layers."}}
{"id": "2505.15987", "pdf": "https://arxiv.org/pdf/2505.15987", "abs": "https://arxiv.org/abs/2505.15987", "authors": ["Aaron Zweig", "Zaikang Lin", "Elham Azizi", "David Knowles"], "title": "Towards Identifiability of Interventional Stochastic Differential Equations", "categories": ["cs.LG"], "comment": null, "summary": "We study identifiability of stochastic differential equation (SDE) models\nunder multiple interventions. Our results give the first provable bounds for\nunique recovery of SDE parameters given samples from their stationary\ndistributions. We give tight bounds on the number of necessary interventions\nfor linear SDEs, and upper bounds for nonlinear SDEs in the small noise regime.\nWe experimentally validate the recovery of true parameters in synthetic data,\nand motivated by our theoretical results, demonstrate the advantage of\nparameterizations with learnable activation functions.", "AI": {"tldr": "\u7814\u7a76\u4e86\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u6a21\u578b\u5728\u591a\u79cd\u5e72\u9884\u4e0b\u7684\u53ef\u8bc6\u522b\u6027\u3002\u7ed9\u51fa\u4e86\u7ebf\u6027\u548c\u975e\u7ebf\u6027SDEs\u5728\u5c0f\u566a\u58f0\u60c5\u51b5\u4e0b\u7684\u5fc5\u8981\u5e72\u9884\u6b21\u6570\u7684\u7d27\u754c\u548c\u4e0a\u754c\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5408\u6210\u6570\u636e\u4e2d\u771f\u5b9e\u53c2\u6570\u7684\u6062\u590d\u3002", "motivation": "\u7814\u7a76\u591a\u4e2a\u5e72\u9884\u4e0b\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u6a21\u578b\u7684\u53ef\u8bc6\u522b\u6027\u3002", "method": "\u5206\u6790\u4e86\u7ebf\u6027\u548c\u975e\u7ebf\u6027SDEs\u7684\u53c2\u6570\u53ef\u8bc6\u522b\u6027\u5e76\u7ed9\u51fa\u4e86\u5fc5\u8981\u5e72\u9884\u6b21\u6570\u7684\u754c\u3002", "result": "\u7ed9\u51fa\u4e86\u552f\u4e00\u6062\u590dSDE\u53c2\u6570\u7684\u53ef\u8bc1\u660e\u754c\u9650\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5408\u6210\u6570\u636e\u4e2d\u7684\u53c2\u6570\u6062\u590d\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86SDE\u53c2\u6570\u53ef\u8bc6\u522b\u6027\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u5c55\u793a\u4e86\u5177\u6709\u53ef\u5b66\u4e60\u6fc0\u6d3b\u51fd\u6570\u7684\u53c2\u6570\u5316\u7684\u4f18\u52bf\u3002"}}
{"id": "2505.16048", "pdf": "https://arxiv.org/pdf/2505.16048", "abs": "https://arxiv.org/abs/2505.16048", "authors": ["Philipp D. Siedler"], "title": "SPhyR: Spatial-Physical Reasoning Benchmark on Material Distribution", "categories": ["cs.AI"], "comment": null, "summary": "We introduce a novel dataset designed to benchmark the physical and spatial\nreasoning capabilities of Large Language Models (LLM) based on topology\noptimization, a method for computing optimal material distributions within a\ndesign space under prescribed loads and supports. In this dataset, LLMs are\nprovided with conditions such as 2D boundary, applied forces and supports, and\nmust reason about the resulting optimal material distribution. The dataset\nincludes a variety of tasks, ranging from filling in masked regions within\npartial structures to predicting complete material distributions. Solving these\ntasks requires understanding the flow of forces and the required material\ndistribution under given constraints, without access to simulation tools or\nexplicit physical models, challenging models to reason about structural\nstability and spatial organization. Our dataset targets the evaluation of\nspatial and physical reasoning abilities in 2D settings, offering a\ncomplementary perspective to traditional language and logic benchmarks.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u7684\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8e\u62d3\u6251\u4f18\u5316\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7269\u7406\u548c\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u3002\u8be5\u6570\u636e\u96c6\u5305\u542b\u5404\u79cd\u4efb\u52a1\uff0c\u8981\u6c42\u6a21\u578b\u5728\u6ca1\u6709\u6a21\u62df\u5de5\u5177\u6216\u663e\u5f0f\u7269\u7406\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u63a8\u7406\u51fa\u7ed9\u5b9a\u7ea6\u675f\u4e0b\u7684\u6700\u4f18\u6750\u6599\u5206\u5e03\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7269\u7406\u548c\u7a7a\u95f4\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b", "method": "\u63d0\u4f9b\u8fb9\u754c\u3001\u53d7\u529b\u60c5\u51b5\u548c\u652f\u6491\u6761\u4ef6\u7b49\u6761\u4ef6\uff0c\u8ba9\u6a21\u578b\u63a8\u7406\u51fa\u6700\u4f18\u6750\u6599\u5206\u5e03", "result": "\u6570\u636e\u96c6\u5305\u62ec\u586b\u5145\u90e8\u5206\u7ed3\u6784\u4e2d\u7684\u63a9\u853d\u533a\u57df\u4ee5\u53ca\u9884\u6d4b\u5b8c\u6574\u7684\u6750\u6599\u5206\u5e03\u7b49\u4efb\u52a1", "conclusion": "\u6b64\u6570\u636e\u96c6\u65e8\u5728\u8bc4\u4f302D\u8bbe\u7f6e\u4e2d\u7684\u7a7a\u95f4\u548c\u7269\u7406\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u4f20\u7edf\u8bed\u8a00\u548c\u903b\u8f91\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u8865\u5145\u89c6\u89d2"}}
{"id": "2505.16311", "pdf": "https://arxiv.org/pdf/2505.16311", "abs": "https://arxiv.org/abs/2505.16311", "authors": ["Marc Brooks", "Gabriel Durham", "Kihyuk Hong", "Ambuj Tewari"], "title": "Generator-Mediated Bandits: Thompson Sampling for GenAI-Powered Adaptive Interventions", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "39 pages, 12 figures", "summary": "Recent advances in generative artificial intelligence (GenAI) models have\nenabled the generation of personalized content that adapts to up-to-date user\ncontext. While personalized decision systems are often modeled using bandit\nformulations, the integration of GenAI introduces new structure into otherwise\nclassical sequential learning problems. In GenAI-powered interventions, the\nagent selects a query, but the environment experiences a stochastic response\ndrawn from the generative model. Standard bandit methods do not explicitly\naccount for this structure, where actions influence rewards only through\nstochastic, observed treatments. We introduce generator-mediated\nbandit-Thompson sampling (GAMBITTS), a bandit approach designed for this\naction/treatment split, using mobile health interventions with large language\nmodel-generated text as a motivating case study. GAMBITTS explicitly models\nboth the treatment and reward generation processes, using information in the\ndelivered treatment to accelerate policy learning relative to standard methods.\nWe establish regret bounds for GAMBITTS by decomposing sources of uncertainty\nin treatment and reward, identifying conditions where it achieves stronger\nguarantees than standard bandit approaches. In simulation studies, GAMBITTS\nconsistently outperforms conventional algorithms by leveraging observed\ntreatments to more accurately estimate expected rewards.", "AI": {"tldr": "This paper introduces GAMBITTS, a novel bandit approach for personalized GenAI-powered interventions. It improves policy learning by modeling both treatment and reward processes.", "motivation": "To address the limitations of standard bandit methods in handling the unique structure of GenAI-powered interventions.", "method": "Introduces GAMBITTS, which models both treatment and reward generation processes and uses information from delivered treatments to speed up policy learning.", "result": "In simulations, GAMBITTS outperforms traditional algorithms by more accurately estimating expected rewards.", "conclusion": "GAMBITTS provides a promising solution for personalization in GenAI-powered interventions."}}
{"id": "2505.16004", "pdf": "https://arxiv.org/pdf/2505.16004", "abs": "https://arxiv.org/abs/2505.16004", "authors": ["Aaron J. Li", "Suraj Srinivas", "Usha Bhalla", "Himabindu Lakkaraju"], "title": "Interpretability Illusions with Sparse Autoencoders: Evaluating Robustness of Concept Representations", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Sparse autoencoders (SAEs) are commonly used to interpret the internal\nactivations of large language models (LLMs) by mapping them to\nhuman-interpretable concept representations. While existing evaluations of SAEs\nfocus on metrics such as the reconstruction-sparsity tradeoff, human\n(auto-)interpretability, and feature disentanglement, they overlook a critical\naspect: the robustness of concept representations to input perturbations. We\nargue that robustness must be a fundamental consideration for concept\nrepresentations, reflecting the fidelity of concept labeling. To this end, we\nformulate robustness quantification as input-space optimization problems and\ndevelop a comprehensive evaluation framework featuring realistic scenarios in\nwhich adversarial perturbations are crafted to manipulate SAE representations.\nEmpirically, we find that tiny adversarial input perturbations can effectively\nmanipulate concept-based interpretations in most scenarios without notably\naffecting the outputs of the base LLMs themselves. Overall, our results suggest\nthat SAE concept representations are fragile and may be ill-suited for\napplications in model monitoring and oversight.", "AI": {"tldr": "This paper examines the robustness of sparse autoencoder (SAE) concept representations against input perturbations, finding that small adversarial changes can significantly alter SAE-based interpretations without affecting the underlying large language model's outputs.", "motivation": "To address the overlooked aspect of robustness in evaluating SAE concept representations which is crucial for their reliability and applicability in model monitoring and oversight.", "method": "Formulating robustness quantification as input-space optimization problems and developing an evaluation framework with realistic adversarial perturbation scenarios.", "result": "Most SAE concept representations are sensitive to tiny adversarial input perturbations, leading to altered interpretations without noticeable impact on the base large language model's outputs.", "conclusion": "The fragility of SAE concept representations suggests they may not be suitable for tasks requiring stable interpretations such as model monitoring and oversight."}}
{"id": "2505.16067", "pdf": "https://arxiv.org/pdf/2505.16067", "abs": "https://arxiv.org/abs/2505.16067", "authors": ["Zidi Xiong", "Yuping Lin", "Wenya Xie", "Pengfei He", "Jiliang Tang", "Himabindu Lakkaraju", "Zhen Xiang"], "title": "How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior", "categories": ["cs.AI"], "comment": null, "summary": "Memory is a critical component in large language model (LLM)-based agents,\nenabling them to store and retrieve past executions to improve task performance\nover time. In this paper, we conduct an empirical study on how memory\nmanagement choices impact the LLM agents' behavior, especially their long-term\nperformance. Specifically, we focus on two fundamental memory operations that\nare widely used by many agent frameworks-addition, which incorporates new\nexperiences into the memory base, and deletion, which selectively removes past\nexperiences-to systematically study their impact on the agent behavior. Through\nour quantitative analysis, we find that LLM agents display an\nexperience-following property: high similarity between a task input and the\ninput in a retrieved memory record often results in highly similar agent\noutputs. Our analysis further reveals two significant challenges associated\nwith this property: error propagation, where inaccuracies in past experiences\ncompound and degrade future performance, and misaligned experience replay,\nwhere outdated or irrelevant experiences negatively influence current tasks.\nThrough controlled experiments, we show that combining selective addition and\ndeletion strategies can help mitigate these negative effects, yielding an\naverage absolute performance gain of 10% compared to naive memory growth.\nFurthermore, we highlight how memory management choices affect agents' behavior\nunder challenging conditions such as task distribution shifts and constrained\nmemory resources. Our findings offer insights into the behavioral dynamics of\nLLM agent memory systems and provide practical guidance for designing memory\ncomponents that support robust, long-term agent performance. We also release\nour code to facilitate further study.", "AI": {"tldr": "\u7814\u7a76\u4e86\u8bb0\u5fc6\u7ba1\u7406\u9009\u62e9\u5bf9\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5b83\u4eec\u7684\u957f\u671f\u6027\u80fd\u3002\u53d1\u73b0LLM\u4ee3\u7406\u5177\u6709\u7ecf\u9a8c\u8ddf\u968f\u7279\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u4e0e\u6b64\u7279\u6027\u76f8\u5173\u7684\u4e24\u4e2a\u6311\u6218\uff1a\u8bef\u5dee\u4f20\u64ad\u548c\u4e0d\u4e00\u81f4\u7684\u7ecf\u9a8c\u91cd\u653e\u3002\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u8868\u660e\uff0c\u7ed3\u5408\u9009\u62e9\u6027\u6dfb\u52a0\u548c\u5220\u9664\u7b56\u7565\u53ef\u4ee5\u7f13\u89e3\u8fd9\u4e9b\u8d1f\u9762\u5f71\u54cd\uff0c\u5e73\u5747\u7edd\u5bf9\u6027\u80fd\u63d0\u534710%\u3002\u6b64\u5916\uff0c\u8fd8\u5c55\u793a\u4e86\u8bb0\u5fc6\u7ba1\u7406\u9009\u62e9\u5982\u4f55\u5f71\u54cd\u4ee3\u7406\u5728\u4efb\u52a1\u5206\u5e03\u53d8\u5316\u548c\u5185\u5b58\u8d44\u6e90\u53d7\u9650\u7b49\u56f0\u96be\u6761\u4ef6\u4e0b\u7684\u884c\u4e3a\u3002", "motivation": "\u7406\u89e3\u8bb0\u5fc6\u7ba1\u7406\u9009\u62e9\u5bf9\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u957f\u671f\u6027\u80fd\u3002", "method": "\u4e13\u6ce8\u4e8e\u4e24\u79cd\u57fa\u672c\u7684\u8bb0\u5fc6\u64cd\u4f5c\uff1a\u6dfb\u52a0\u548c\u5220\u9664\uff0c\u7cfb\u7edf\u5730\u7814\u7a76\u5b83\u4eec\u5bf9\u4ee3\u7406\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0LLM\u4ee3\u7406\u5177\u6709\u7ecf\u9a8c\u8ddf\u968f\u7279\u6027\uff0c\u5373\u4efb\u52a1\u8f93\u5165\u4e0e\u68c0\u7d22\u5230\u7684\u8bb0\u5fc6\u8bb0\u5f55\u4e2d\u7684\u8f93\u5165\u9ad8\u5ea6\u76f8\u4f3c\u65f6\uff0c\u4ee3\u7406\u8f93\u51fa\u4e5f\u5f80\u5f80\u9ad8\u5ea6\u76f8\u4f3c\u3002\u63ed\u793a\u4e86\u8bef\u5dee\u4f20\u64ad\u548c\u4e0d\u4e00\u81f4\u7684\u7ecf\u9a8c\u91cd\u653e\u8fd9\u4e24\u4e2a\u6311\u6218\u3002\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u663e\u793a\uff0c\u7ed3\u5408\u9009\u62e9\u6027\u6dfb\u52a0\u548c\u5220\u9664\u7b56\u7565\u53ef\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u4e8eLLM\u4ee3\u7406\u8bb0\u5fc6\u7cfb\u7edf\u884c\u4e3a\u52a8\u6001\u7684\u89c1\u89e3\uff0c\u5e76\u4e3a\u8bbe\u8ba1\u652f\u6301\u7a33\u5065\u3001\u957f\u671f\u4ee3\u7406\u6027\u80fd\u7684\u8bb0\u5fc6\u7ec4\u4ef6\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002\u540c\u65f6\u53d1\u5e03\u4e86\u4ee3\u7801\u4ee5\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2505.16329", "pdf": "https://arxiv.org/pdf/2505.16329", "abs": "https://arxiv.org/abs/2505.16329", "authors": ["Simone Bombari", "Inbar Seroussi", "Marco Mondelli"], "title": "Better Rates for Private Linear Regression in the Proportional Regime via Aggressive Clipping", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Differentially private (DP) linear regression has received significant\nattention in the recent theoretical literature, with several works aimed at\nobtaining improved error rates. A common approach is to set the clipping\nconstant much larger than the expected norm of the per-sample gradients. While\nsimplifying the analysis, this is however in sharp contrast with what empirical\nevidence suggests to optimize performance. Our work bridges this gap between\ntheory and practice: we provide sharper rates for DP stochastic gradient\ndescent (DP-SGD) by crucially operating in a regime where clipping happens\nfrequently. Specifically, we consider the setting where the data is\nmultivariate Gaussian, the number of training samples $n$ is proportional to\nthe input dimension $d$, and the algorithm guarantees constant-order zero\nconcentrated DP. Our method relies on establishing a deterministic equivalent\nfor the trajectory of DP-SGD in terms of a family of ordinary differential\nequations (ODEs). As a consequence, the risk of DP-SGD is bounded between two\nODEs, with upper and lower bounds matching for isotropic data. By studying\nthese ODEs when $n / d$ is large enough, we demonstrate the optimality of\naggressive clipping, and we uncover the benefits of decaying learning rate and\nprivate noise scheduling.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7814\u7a76\uff0c\u89e3\u51b3\u4e86\u5dee\u5206\u9690\u79c1\u7ebf\u6027\u56de\u5f52\u4e2d\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u6fc0\u8fdb\u88c1\u526a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u7406\u8bba\u5de5\u4f5c\u548c\u5b9e\u9645\u8868\u73b0\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\uff0c\u7279\u522b\u662fDP\u7ebf\u6027\u56de\u5f52\u4e2d\u7684\u8bef\u5dee\u7387\u6539\u8fdb\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5efa\u7acbDP-SGD\u8f68\u8ff9\u7684\u786e\u5b9a\u6027\u7b49\u4ef7\u4e8e\u4e00\u65cf\u5e38\u5fae\u5206\u65b9\u7a0b\uff08ODEs\uff09\uff0c\u5e76\u7814\u7a76\u8fd9\u4e9bODEs\u5728n/d\u8db3\u591f\u5927\u65f6\u7684\u884c\u4e3a\u3002", "result": "\u63d0\u4f9b\u4e86DP-SGD\u7684\u66f4\u5c16\u9510\u7684\u901f\u7387\uff0c\u5728\u9891\u7e41\u88c1\u526a\u7684\u6761\u4ef6\u4e0b\uff0c\u5bf9\u4e8e\u591a\u53d8\u91cf\u9ad8\u65af\u6570\u636e\u548c\u7279\u5b9a\u6bd4\u4f8b\u7684\u8bad\u7ec3\u6837\u672c\u6570\uff0c\u4fdd\u8bc1\u5e38\u91cf\u9636\u96f6\u96c6\u4e2dDP\u3002", "conclusion": "\u63d0\u51fa\u4e86\u65b0\u7684\u7406\u8bba\u65b9\u6cd5\u6765\u89e3\u91caDP-SGD\u5728\u5b9e\u9645\u4e2d\u7684\u8868\u73b0\uff0c\u8bc1\u660e\u4e86\u6fc0\u8fdb\u88c1\u526a\u7684\u6700\u4f18\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u8870\u51cf\u5b66\u4e60\u7387\u548c\u79c1\u6709\u566a\u58f0\u8c03\u5ea6\u7684\u597d\u5904\u3002"}}
{"id": "2505.16017", "pdf": "https://arxiv.org/pdf/2505.16017", "abs": "https://arxiv.org/abs/2505.16017", "authors": ["Mariia Seleznova", "Hung-Hsu Chou", "Claudio Mayrink Verdun", "Gitta Kutyniok"], "title": "GradPCA: Leveraging NTK Alignment for Reliable Out-of-Distribution Detection", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We introduce GradPCA, an Out-of-Distribution (OOD) detection method that\nexploits the low-rank structure of neural network gradients induced by Neural\nTangent Kernel (NTK) alignment. GradPCA applies Principal Component Analysis\n(PCA) to gradient class-means, achieving more consistent performance than\nexisting methods across standard image classification benchmarks. We provide a\ntheoretical perspective on spectral OOD detection in neural networks to support\nGradPCA, highlighting feature-space properties that enable effective detection\nand naturally emerge from NTK alignment. Our analysis further reveals that\nfeature quality -- particularly the use of pretrained versus non-pretrained\nrepresentations -- plays a crucial role in determining which detectors will\nsucceed. Extensive experiments validate the strong performance of GradPCA, and\nour theoretical framework offers guidance for designing more principled\nspectral OOD detectors.", "AI": {"tldr": "\u63d0\u51faGradPCA\u65b9\u6cd5\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684Out-of-Distribution\u68c0\u6d4b\uff0c\u901a\u8fc7\u68af\u5ea6\u7684\u4f4e\u79e9\u7ed3\u6784\u548c\u4e3b\u6210\u5206\u5206\u6790\u5b9e\u73b0\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u4e00\u81f4\u7684\u8868\u73b0\u3002\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86\u7279\u5f81\u7a7a\u95f4\u6027\u8d28\u4e0eNTK\u5bf9\u9f50\u7684\u5173\u7cfb\uff0c\u5e76\u5f3a\u8c03\u9884\u8bad\u7ec3\u8868\u793a\u7684\u91cd\u8981\u6027\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86GradPCA\u7684\u6709\u6548\u6027\u5e76\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u65b0\u65b9\u6cd5\u7684\u6307\u5bfc\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6807\u51c6\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u4e0d\u4e00\u81f4\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u68c0\u6d4b\u6027\u80fd\u3002", "method": "GradPCA\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u68af\u5ea6\u7684\u4f4e\u79e9\u7ed3\u6784\uff0c\u5e94\u7528\u4e3b\u6210\u5206\u5206\u6790\u4e8e\u68af\u5ea6\u7c7b\u5747\u503c\u4e0a\u3002", "result": "GradPCA\u5728\u6807\u51c6\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4e14\u5176\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86\u7279\u5f81\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "conclusion": "GradPCA\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u4e00\u81f4\u7684Out-of-Distribution\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u6307\u5bfc\u672a\u6765\u65b9\u6cd5\u7684\u8bbe\u8ba1\u3002"}}
{"id": "2505.16080", "pdf": "https://arxiv.org/pdf/2505.16080", "abs": "https://arxiv.org/abs/2505.16080", "authors": ["Jiayue Liu", "Zhongchao Yi", "Zhengyang Zhou", "Qihe Huang", "Kuo Yang", "Xu Wang", "Yang Wang"], "title": "SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation", "categories": ["cs.AI"], "comment": "16 pages, 7 figures", "summary": "Discovering regularities from spatiotemporal systems can benefit various\nscientific and social planning. Current spatiotemporal learners usually train\nan independent model from a specific source data that leads to limited\ntransferability among sources, where even correlated tasks requires new design\nand training. The key towards increasing cross-domain knowledge is to enable\ncollective intelligence and model evolution. In this paper, inspired by\nneuroscience theories, we theoretically derive the increased information\nboundary via learning cross-domain collective intelligence and propose a\nSynaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the\nmodel independence and enables cross-domain knowledge to be shared and\naggregated. Specifically, we first re-order the sample groups to imitate the\nhuman curriculum learning, and devise two complementary learners, elastic\ncommon container and task-independent extractor to allow model growth and\ntask-wise commonality and personality disentanglement. Then an adaptive dynamic\ncoupler with a new difference metric determines whether the new sample group\nshould be incorporated into common container to achieve model evolution under\nvarious domains. Experiments show that SynEVO improves the generalization\ncapacity by at most 42% under cross-domain scenarios and SynEVO provides a\nparadigm of NeuroAI for knowledge transfer and adaptation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSynEVO\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u5b66\u4e60\u8de8\u57df\u96c6\u4f53\u667a\u80fd\u6765\u63d0\u5347\u4fe1\u606f\u8fb9\u754c\uff0c\u5e76\u5b9e\u73b0\u4e86\u8de8\u57df\u77e5\u8bc6\u5171\u4eab\u548c\u805a\u5408\u3002\u5b9e\u9a8c\u8868\u660e\uff0cSynEVO\u5728\u8de8\u57df\u573a\u666f\u4e0b\u6700\u591a\u63d0\u9ad8\u4e8642%\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u65f6\u7a7a\u5b66\u4e60\u5668\u901a\u5e38\u4ece\u7279\u5b9a\u6e90\u6570\u636e\u8bad\u7ec3\u72ec\u7acb\u6a21\u578b\uff0c\u5bfc\u81f4\u8de8\u6e90\u8fc1\u79fb\u6027\u6709\u9650\uff0c\u5373\u4f7f\u76f8\u5173\u4efb\u52a1\u4e5f\u9700\u8981\u65b0\u7684\u8bbe\u8ba1\u548c\u8bad\u7ec3\u3002", "method": "\u53d7\u795e\u7ecf\u79d1\u5b66\u7406\u8bba\u542f\u53d1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSynEVO\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u91c7\u7528\u4eba\u7c7b\u8bfe\u7a0b\u5b66\u4e60\u7684\u6837\u672c\u5206\u7ec4\u91cd\u6392\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u4e92\u8865\u7684\u5b66\u4e60\u5668\uff08\u5f39\u6027\u516c\u5171\u5bb9\u5668\u548c\u4efb\u52a1\u65e0\u5173\u63d0\u53d6\u5668\uff09\u4ee5\u53ca\u4e00\u4e2a\u81ea\u9002\u5e94\u52a8\u6001\u8026\u5408\u5668\u3002", "result": "\u5b9e\u9a8c\u663e\u793aSynEVO\u5728\u8de8\u57df\u573a\u666f\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u63d0\u5347\u4e86\u6700\u591a42%\u3002", "conclusion": "SynEVO\u63d0\u4f9b\u4e86\u4e00\u4e2a\u795e\u7ecf\u4eba\u5de5\u667a\u80fd\u7684\u77e5\u8bc6\u8f6c\u79fb\u548c\u9002\u5e94\u8303\u4f8b\u3002"}}
{"id": "2505.16644", "pdf": "https://arxiv.org/pdf/2505.16644", "abs": "https://arxiv.org/abs/2505.16644", "authors": ["Stephen Y. Zhang", "Michael P H Stumpf"], "title": "Learning non-equilibrium diffusions with Schr\u00f6dinger bridges: from exactly solvable to simulation-free", "categories": ["stat.ML", "cs.LG", "math.OC", "62M45, 49N10"], "comment": "9 pages, 5 figures", "summary": "We consider the Schr\\\"odinger bridge problem which, given ensemble\nmeasurements of the initial and final configurations of a stochastic dynamical\nsystem and some prior knowledge on the dynamics, aims to reconstruct the \"most\nlikely\" evolution of the system compatible with the data. Most existing\nliterature assume Brownian reference dynamics and are implicitly limited to\npotential-driven dynamics. We depart from this regime and consider reference\nprocesses described by a multivariate Ornstein-Uhlenbeck process with generic\ndrift matrix $\\mathbf{A} \\in \\mathbb{R}^{d \\times d}$. When $\\mathbf{A}$ is\nasymmetric, this corresponds to a non-equilibrium system with non-conservative\nforces at play: this is important for applications to biological systems, which\nare naturally exist out-of-equilibrium. In the case of Gaussian marginals, we\nderive explicit expressions that characterise the solution of both the static\nand dynamic Schr\\\"odinger bridge. For general marginals, we propose mvOU-OTFM,\na simulation-free algorithm based on flow and score matching for learning the\nSchr\\\"odinger bridge. In application to a range of problems based on synthetic\nand real single cell data, we demonstrate that mvOU-OTFM achieves higher\naccuracy compared to competing methods, whilst being significantly faster to\ntrain.", "AI": {"tldr": "This paper studies the Schr\u00f6dinger bridge problem using multivariate Ornstein-Uhlenbeck processes, proposing a novel method (mvOU-OTFM) for both static and dynamic cases, showing high accuracy and efficiency in synthetic and real single-cell data.", "motivation": "To develop a more general approach for the Schr\u00f6dinger bridge problem that can handle non-equilibrium systems with non-conservative forces, particularly relevant for biological applications.", "method": "Derives explicit solutions for Gaussian marginals and proposes a simulation-free algorithm called mvOU-OTFM for general marginals using flow and score matching.", "result": "The proposed method mvOU-OTFM shows higher accuracy and faster training times compared to other methods when applied to synthetic and real single-cell data.", "conclusion": "The study successfully extends the Schr\u00f6dinger bridge framework to non-equilibrium systems using multivariate Ornstein-Uhlenbeck processes, demonstrating practical utility through efficient and accurate algorithms."}}
{"id": "2505.16024", "pdf": "https://arxiv.org/pdf/2505.16024", "abs": "https://arxiv.org/abs/2505.16024", "authors": ["Weiguo Gao", "Ming Li"], "title": "Toward Theoretical Insights into Diffusion Trajectory Distillation via Operator Merging", "categories": ["cs.LG", "cs.AI"], "comment": "31 pages, 19 figures", "summary": "Diffusion trajectory distillation methods aim to accelerate sampling in\ndiffusion models, which produce high-quality outputs but suffer from slow\nsampling speeds. These methods train a student model to approximate the\nmulti-step denoising process of a pretrained teacher model in a single step,\nenabling one-shot generation. However, theoretical insights into the trade-off\nbetween different distillation strategies and generative quality remain\nlimited, complicating their optimization and selection. In this work, we take a\nfirst step toward addressing this gap. Specifically, we reinterpret trajectory\ndistillation as an operator merging problem in the linear regime, where each\nstep of the teacher model is represented as a linear operator acting on noisy\ndata. These operators admit a clear geometric interpretation as projections and\nrescalings corresponding to the noise schedule. During merging, signal\nshrinkage occurs as a convex combination of operators, arising from both\ndiscretization and limited optimization time of the student model. We propose a\ndynamic programming algorithm to compute the optimal merging strategy that\nmaximally preserves signal fidelity. Additionally, we demonstrate the existence\nof a sharp phase transition in the optimal strategy, governed by data\ncovariance structures. Our findings enhance the theoretical understanding of\ndiffusion trajectory distillation and offer practical insights for improving\ndistillation strategies.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u89e3\u91ca\u6269\u6563\u8f68\u8ff9\u84b8\u998f\u4e3a\u64cd\u4f5c\u5408\u5e76\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u4ee5\u627e\u5230\u6700\u4f18\u5408\u5e76\u7b56\u7565\uff0c\u63ed\u793a\u4e86\u76f8\u53d8\u73b0\u8c61\u5e76\u589e\u5f3a\u7406\u8bba\u7406\u89e3\u3002", "motivation": "\u52a0\u901f\u91c7\u6837\u5728\u6269\u6563\u6a21\u578b\u4e2d\u7684\u5e94\u7528\uff0c\u89e3\u51b3\u4e0d\u540c\u84b8\u998f\u7b56\u7565\u4e0e\u751f\u6210\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u4f18\u5316\u548c\u9009\u62e9\u84b8\u998f\u7b56\u7565\u3002", "method": "\u5c06\u8f68\u8ff9\u84b8\u998f\u91cd\u65b0\u89e3\u91ca\u4e3a\u7ebf\u6027\u9636\u6bb5\u7684\u64cd\u4f5c\u5408\u5e76\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u8ba1\u7b97\u6700\u4f18\u5408\u5e76\u7b56\u7565\u3002", "result": "\u53d1\u73b0\u4e86\u6700\u4f18\u7b56\u7565\u4e2d\u5b58\u5728\u7684\u5c16\u9510\u76f8\u53d8\u73b0\u8c61\uff0c\u53d7\u6570\u636e\u534f\u65b9\u5dee\u7ed3\u6784\u63a7\u5236\uff1b\u589e\u5f3a\u4e86\u5bf9\u6269\u6563\u8f68\u8ff9\u84b8\u998f\u7684\u7406\u8bba\u7406\u89e3\uff1b\u4e3a\u6539\u8fdb\u84b8\u998f\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u91cd\u65b0\u89e3\u91ca\u8f68\u8ff9\u84b8\u998f\u4e3a\u7ebf\u6027\u9636\u6bb5\u7684\u64cd\u4f5c\u5408\u5e76\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u6765\u8ba1\u7b97\u6700\u4f18\u5408\u5e76\u7b56\u7565\uff0c\u4ee5\u6700\u5927\u7a0b\u5ea6\u5730\u4fdd\u6301\u4fe1\u53f7\u4fdd\u771f\u5ea6\uff0c\u5e76\u5c55\u793a\u4e86\u6700\u4f18\u7b56\u7565\u4e2d\u5b58\u5728\u7684\u5c16\u9510\u76f8\u53d8\u73b0\u8c61\uff0c\u53d7\u6570\u636e\u534f\u65b9\u5dee\u7ed3\u6784\u63a7\u5236\u3002\u8fd9\u4e9b\u53d1\u73b0\u589e\u5f3a\u4e86\u5bf9\u6269\u6563\u8f68\u8ff9\u84b8\u998f\u7684\u7406\u8bba\u7406\u89e3\uff0c\u5e76\u4e3a\u6539\u8fdb\u84b8\u998f\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\u3002"}}
{"id": "2505.16086", "pdf": "https://arxiv.org/pdf/2505.16086", "abs": "https://arxiv.org/abs/2505.16086", "authors": ["Ming Shen", "Raphael Shu", "Anurag Pratik", "James Gung", "Yubin Ge", "Monica Sunkara", "Yi Zhang"], "title": "Optimizing LLM-Based Multi-Agent System with Textual Feedback: A Case Study on Software Development", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "We have seen remarkable progress in large language models (LLMs) empowered\nmulti-agent systems solving complex tasks necessitating cooperation among\nexperts with diverse skills. However, optimizing LLM-based multi-agent systems\nremains challenging. In this work, we perform an empirical case study on group\noptimization of role-based multi-agent systems utilizing natural language\nfeedback for challenging software development tasks under various evaluation\ndimensions. We propose a two-step agent prompts optimization pipeline:\nidentifying underperforming agents with their failure explanations utilizing\ntextual feedback and then optimizing system prompts of identified agents\nutilizing failure explanations. We then study the impact of various\noptimization settings on system performance with two comparison groups: online\nagainst offline optimization and individual against group optimization. For\ngroup optimization, we study two prompting strategies: one-pass and multi-pass\nprompting optimizations. Overall, we demonstrate the effectiveness of our\noptimization method for role-based multi-agent systems tackling software\ndevelopment tasks evaluated on diverse evaluation dimensions, and we\ninvestigate the impact of diverse optimization settings on group behaviors of\nthe multi-agent systems to provide practical insights for future development.", "AI": {"tldr": "This paper studies the optimization of role-based multi-agent systems using natural language feedback for software development tasks.", "motivation": "Optimizing large language model-based multi-agent systems remains challenging.", "method": "Proposes a two-step agent prompts optimization pipeline that identifies underperforming agents and optimizes their system prompts using failure explanations.", "result": "Demonstrates the effectiveness of the proposed optimization method for role-based multi-agent systems tackling software development tasks evaluated on diverse evaluation dimensions.", "conclusion": "Investigates the impact of diverse optimization settings on group behaviors of multi-agent systems to provide practical insights for future development."}}
{"id": "2505.16713", "pdf": "https://arxiv.org/pdf/2505.16713", "abs": "https://arxiv.org/abs/2505.16713", "authors": ["Shogo Nakakita"], "title": "Sharp concentration of uniform generalization errors in binary linear classification", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": "26 pages, 1 figure", "summary": "We examine the concentration of uniform generalization errors around their\nexpectation in binary linear classification problems via an isoperimetric\nargument. In particular, we establish Poincar\\'{e} and log-Sobolev inequalities\nfor the joint distribution of the output labels and the label-weighted input\nvectors, which we apply to derive concentration bounds. The derived\nconcentration bounds are sharp up to moderate multiplicative constants by those\nunder well-balanced labels. In asymptotic analysis, we also show that almost\nsure convergence of uniform generalization errors to their expectation occurs\nin very broad settings, such as proportionally high-dimensional regimes. Using\nthis convergence, we establish uniform laws of large numbers under\ndimension-free conditions.", "AI": {"tldr": "\u901a\u8fc7\u7b49\u5468\u8bba\u8bc1\uff0c\u7814\u7a76\u4e8c\u5143\u7ebf\u6027\u5206\u7c7b\u95ee\u9898\u4e2d\u5747\u5300\u63a8\u5e7f\u8bef\u5dee\u7684\u96c6\u4e2d\u60c5\u51b5\uff0c\u5e76\u8bc1\u660e\u4e86Poincar\u00e9\u548clog-Sobolev\u4e0d\u7b49\u5f0f\uff0c\u5f97\u5230\u96c6\u4e2d\u754c\u9650\u3002", "motivation": "\u7814\u7a76\u4e8c\u5143\u7ebf\u6027\u5206\u7c7b\u95ee\u9898\u4e2d\u5747\u5300\u63a8\u5e7f\u8bef\u5dee\u56f4\u7ed5\u5176\u671f\u671b\u7684\u96c6\u4e2d\u60c5\u51b5\u3002", "method": "\u4f7f\u7528\u7b49\u5468\u8bba\u70b9\u548c\u4e8c\u5143\u7ebf\u6027\u5206\u7c7b\u95ee\u9898\u4e2d\u7684\u8054\u5408\u5206\u5e03\u8f93\u51fa\u6807\u7b7e\u548c\u6807\u8bb0\u52a0\u6743\u8f93\u5165\u5411\u91cf\u3002", "result": "\u5f97\u5230\u4e86\u5173\u4e8e\u5747\u5300\u63a8\u5e7f\u8bef\u5dee\u7684\u96c6\u4e2d\u754c\u9650\uff0c\u4e14\u8fd9\u4e9b\u754c\u9650\u5728\u9002\u5ea6\u7684\u4e58\u6cd5\u5e38\u6570\u5185\u662f\u5c16\u9510\u7684\u3002", "conclusion": "\u8bc1\u660e\u4e86Poincar\u00e9\u548clog-Sobolev\u4e0d\u7b49\u5f0f\uff0c\u5e76\u5f97\u5230\u4e86\u5173\u4e8e\u5747\u5300\u63a8\u5e7f\u8bef\u5dee\u7684\u96c6\u4e2d\u754c\u9650\u3002\u5728\u6e10\u8fd1\u5206\u6790\u4e2d\uff0c\u5c55\u793a\u4e86\u51e0\u4e4e\u786e\u5b9a\u7684\u6536\u655b\u6027\uff0c\u5e76\u5efa\u7acb\u4e86\u65e0\u7ef4\u5ea6\u6761\u4ef6\u4e0b\u7684\u5747\u5300\u5927\u6570\u5b9a\u5f8b\u3002"}}
{"id": "2505.16035", "pdf": "https://arxiv.org/pdf/2505.16035", "abs": "https://arxiv.org/abs/2505.16035", "authors": ["Alejandro Garc\u00eda-Castellanos", "David R. Wessels", "Nicky J. van den Berg", "Remco Duits", "Dani\u00ebl M. Pelt", "Erik J. Bekkers"], "title": "Equivariant Eikonal Neural Networks: Grid-Free, Scalable Travel-Time Prediction on Homogeneous Spaces", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce Equivariant Neural Eikonal Solvers, a novel framework that\nintegrates Equivariant Neural Fields (ENFs) with Neural Eikonal Solvers. Our\napproach employs a single neural field where a unified shared backbone is\nconditioned on signal-specific latent variables - represented as point clouds\nin a Lie group - to model diverse Eikonal solutions. The ENF integration\nensures equivariant mapping from these latent representations to the solution\nfield, delivering three key benefits: enhanced representation efficiency\nthrough weight-sharing, robust geometric grounding, and solution steerability.\nThis steerability allows transformations applied to the latent point cloud to\ninduce predictable, geometrically meaningful modifications in the resulting\nEikonal solution. By coupling these steerable representations with\nPhysics-Informed Neural Networks (PINNs), our framework accurately models\nEikonal travel-time solutions while generalizing to arbitrary Riemannian\nmanifolds with regular group actions. This includes homogeneous spaces such as\nEuclidean, position-orientation, spherical, and hyperbolic manifolds. We\nvalidate our approach through applications in seismic travel-time modeling of\n2D and 3D benchmark datasets. Experimental results demonstrate superior\nperformance, scalability, adaptability, and user controllability compared to\nexisting Neural Operator-based Eikonal solver methods.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6Equivalant Neural Eikonal Solvers\uff0c\u5b83\u7ed3\u5408\u4e86\u7b49\u53d8\u795e\u7ecf\u573a\u548c\u795e\u7ecfEikonal\u6c42\u89e3\u5668\uff0c\u80fd\u591f\u9ad8\u6548\u5730\u5efa\u6a21Eikonal\u65b9\u7a0b\u7684\u89e3\uff0c\u5e76\u4e14\u53ef\u4ee5\u63a8\u5e7f\u5230\u4efb\u610f\u9ece\u66fc\u6d41\u5f62\u3002", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u7b97\u5b50\u65b9\u6cd5\u5728\u5efa\u6a21Eikonal\u65b9\u7a0b\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u3001\u53ef\u63a8\u5e7f\u4e14\u53ef\u63a7\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u5355\u4e2a\u795e\u7ecf\u573a\uff0c\u901a\u8fc7\u6761\u4ef6\u5316\u4fe1\u53f7\u7279\u5b9a\u7684\u6f5c\u5728\u53d8\u91cf\u6765\u6a21\u62df\u591a\u6837\u7684Eikonal\u89e3\u3002\u8fd9\u79cd\u65b9\u6cd5\u786e\u4fdd\u4e86\u4ece\u6f5c\u5728\u8868\u793a\u5230\u89e3\u573a\u7684\u7b49\u53d8\u6620\u5c04\u3002", "result": "\u5728\u4e8c\u7ef4\u548c\u4e09\u7ef4\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5bf9\u5730\u9707\u65c5\u884c\u65f6\u95f4\u5efa\u6a21\u7684\u5e94\u7528\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5176\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u548c\u9002\u5e94\u6027\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u795e\u7ecf\u7b97\u5b50\u7684\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u8868\u793a\u6548\u7387\uff0c\u800c\u4e14\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u51e0\u4f55\u57fa\u7840\u548c\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u63a7\u6027\uff0c\u80fd\u591f\u5728\u4efb\u610f\u9ece\u66fc\u6d41\u5f62\u4e0a\u51c6\u786e\u5efa\u6a21Eikonal\u65c5\u884c\u65f6\u95f4\u89e3\u3002"}}
{"id": "2505.16090", "pdf": "https://arxiv.org/pdf/2505.16090", "abs": "https://arxiv.org/abs/2505.16090", "authors": ["Dominick Kubica", "Dylan T. Gordon", "Nanami Emura", "Derleen Saini", "Charlie Goldenberg"], "title": "Can AI Read Between The Lines? Benchmarking LLMs On Financial Nuance", "categories": ["cs.AI", "cs.CL", "I.2.6; I.2.7"], "comment": "6 pages, 4 figures. Research conducted as part of a\n  Microsoft-sponsored Capstone Project at Santa Clara University", "summary": "As of 2025, Generative Artificial Intelligence (GenAI) has become a central\ntool for productivity across industries. Beyond text generation, GenAI now\nplays a critical role in coding, data analysis, and research workflows. As\nlarge language models (LLMs) continue to evolve, it is essential to assess the\nreliability and accuracy of their outputs, especially in specialized,\nhigh-stakes domains like finance. Most modern LLMs transform text into\nnumerical vectors, which are used in operations such as cosine similarity\nsearches to generate responses. However, this abstraction process can lead to\nmisinterpretation of emotional tone, particularly in nuanced financial\ncontexts. While LLMs generally excel at identifying sentiment in everyday\nlanguage, these models often struggle with the nuanced, strategically ambiguous\nlanguage found in earnings call transcripts. Financial disclosures frequently\nembed sentiment in hedged statements, forward-looking language, and\nindustry-specific jargon, making it difficult even for human analysts to\ninterpret consistently, let alone AI models. This paper presents findings from\nthe Santa Clara Microsoft Practicum Project, led by Professor Charlie\nGoldenberg, which benchmarks the performance of Microsoft's Copilot, OpenAI's\nChatGPT, Google's Gemini, and traditional machine learning models for sentiment\nanalysis of financial text. Using Microsoft earnings call transcripts, the\nanalysis assesses how well LLM-derived sentiment correlates with market\nsentiment and stock movements and evaluates the accuracy of model outputs.\nPrompt engineering techniques are also examined to improve sentiment analysis\nresults. Visualizations of sentiment consistency are developed to evaluate\nalignment between tone and stock performance, with sentiment trends analyzed\nacross Microsoft's lines of business to determine which segments exert the\ngreatest influence.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u91d1\u878d\u6587\u672c\u60c5\u611f\u5206\u6790\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u6bd4\u8f83\u4e86\u5fae\u8f6fCopilot\u3001OpenAI\u7684ChatGPT\u3001Google\u7684Gemini\u4ee5\u53ca\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u4f7f\u7528\u5fae\u8f6f\u7684\u6536\u76ca\u7535\u8bdd\u4f1a\u8bae\u8bb0\u5f55\u8bc4\u4f30\u4e86LLM\u884d\u751f\u60c5\u611f\u4e0e\u5e02\u573a\u60c5\u7eea\u548c\u80a1\u7968\u8d70\u52bf\u7684\u76f8\u5173\u6027\uff0c\u5e76\u5bf9\u6a21\u578b\u8f93\u51fa\u7684\u51c6\u786e\u6027\u8fdb\u884c\u4e86\u8bc4\u4ef7\u3002\u6b64\u5916\uff0c\u8fd8\u7814\u7a76\u4e86\u63d0\u793a\u5de5\u7a0b\u65b9\u6cd5\u4ee5\u6539\u5584\u60c5\u611f\u5206\u6790\u7ed3\u679c\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u5728\u5404\u884c\u4e1a\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u7279\u522b\u662f\u5176\u5728\u7f16\u7801\u3001\u6570\u636e\u5206\u6790\u548c\u7814\u7a76\u5de5\u4f5c\u6d41\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u8bc4\u4f30LLMs\u5728\u9ad8\u98ce\u9669\u9886\u57df\u5982\u91d1\u878d\u4e2d\u7684\u53ef\u9760\u6027\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0cLLMs\u5728\u5904\u7406\u91d1\u878d\u8bed\u5883\u4e2d\u5fae\u5999\u4e14\u7b56\u7565\u4e0a\u542b\u7cca\u7684\u8bed\u8a00\u65f6\u5b58\u5728\u56f0\u96be\u3002", "method": "\u672c\u7814\u7a76\u4f7f\u7528\u4e86\u7531Charlie Goldenberg\u6559\u6388\u9886\u5bfc\u7684\u5723\u514b\u62c9\u62c9\u5fae\u8f6f\u5b9e\u4e60\u9879\u76ee\uff0c\u5bf9Microsoft Copilot\u3001OpenAI ChatGPT\u3001Google Gemini\u53ca\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u91c7\u7528\u5fae\u8f6f\u6536\u76ca\u7535\u8bdd\u4f1a\u8bae\u8bb0\u5f55\u4f5c\u4e3a\u6570\u636e\u6e90\uff0c\u901a\u8fc7\u53ef\u89c6\u5316\u624b\u6bb5\u5206\u6790\u60c5\u611f\u4e00\u81f4\u6027\u4e0e\u80a1\u7968\u8868\u73b0\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u8de8\u5fae\u8f6f\u4e1a\u52a1\u7ebf\u5206\u6790\u60c5\u611f\u8d8b\u52bf\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLMs\u5728\u91d1\u878d\u6587\u672c\u60c5\u611f\u5206\u6790\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u51c6\u786e\u6027\u4ecd\u6709\u5f85\u63d0\u9ad8\u3002\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u53ef\u4ee5\u4f18\u5316\u60c5\u611f\u5206\u6790\u7ed3\u679c\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u4e0d\u540c\u4e1a\u52a1\u90e8\u95e8\u5bf9\u6574\u4f53\u5e02\u573a\u60c5\u7eea\u7684\u5f71\u54cd\u7a0b\u5ea6\u3002", "conclusion": "\u5c3d\u7ba1LLMs\u5728\u60c5\u611f\u5206\u6790\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u91d1\u878d\u9886\u57df\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u548c\u6a21\u7cca\u7684\u8bed\u8a00\u73af\u5883\u4e2d\u3002\u672a\u6765\u7684\u5de5\u4f5c\u5e94\u96c6\u4e2d\u5728\u6539\u8fdb\u8fd9\u4e9b\u6a21\u578b\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u548c\u89e3\u91ca\u91d1\u878d\u6587\u672c\u7684\u60c5\u611f\u5185\u6db5\u3002"}}
{"id": "2505.16879", "pdf": "https://arxiv.org/pdf/2505.16879", "abs": "https://arxiv.org/abs/2505.16879", "authors": ["Hannah Sansford", "Nick Whiteley", "Patrick Rubin-Delanchy"], "title": "How high is `high'? Rethinking the roles of dimensionality in topological data analysis and manifold learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We present a generalised Hanson-Wright inequality and use it to establish new\nstatistical insights into the geometry of data point-clouds. In the setting of\na general random function model of data, we clarify the roles played by three\nnotions of dimensionality: ambient intrinsic dimension $p_{\\mathrm{int}}$,\nwhich measures total variability across orthogonal feature directions;\ncorrelation rank, which measures functional complexity across samples; and\nlatent intrinsic dimension, which is the dimension of manifold structure hidden\nin data. Our analysis shows that in order for persistence diagrams to reveal\nlatent homology and for manifold structure to emerge it is sufficient that\n$p_{\\mathrm{int}}\\gg \\log n$, where $n$ is the sample size. Informed by these\ntheoretical perspectives, we revisit the ground-breaking neuroscience discovery\nof toroidal structure in grid-cell activity made by Gardner et al. (Nature,\n2022): our findings reveal, for the first time, evidence that this structure is\nin fact isometric to physical space, meaning that grid cell activity conveys a\ngeometrically faithful representation of the real world.", "AI": {"tldr": "This paper introduces a generalized Hanson-Wright inequality and applies it to understand the geometry of data clouds, defining three types of dimensions and showing conditions under which latent structures can be revealed.", "motivation": "To provide statistical insights into the geometry of data point-clouds using a generalized Hanson-Wright inequality.", "method": "Analyzing the roles of three notions of dimensionality in a general random function model of data.", "result": "Sufficient condition for persistence diagrams to reveal latent homology and for manifold structure to emerge is $p_{\\mathrm{int}}\\gg \\log n$.", "conclusion": "Theoretical findings support that grid cell activity conveys a geometrically accurate representation of the real world."}}
{"id": "2505.16053", "pdf": "https://arxiv.org/pdf/2505.16053", "abs": "https://arxiv.org/abs/2505.16053", "authors": ["Jan T\u00f6nshoff", "Martin Grohe"], "title": "Learning from Algorithm Feedback: One-Shot SAT Solver Guidance with GNNs", "categories": ["cs.LG"], "comment": null, "summary": "Boolean Satisfiability (SAT) solvers are foundational to computer science,\nyet their performance typically hinges on hand-crafted heuristics. This work\nintroduces Reinforcement Learning from Algorithm Feedback (RLAF) as a paradigm\nfor learning to guide SAT solver branching heuristics with Graph Neural\nNetworks (GNNs). Central to our approach is a novel and generic mechanism for\ninjecting inferred variable weights and polarities into the branching\nheuristics of existing SAT solvers. In a single forward pass, a GNN assigns\nthese parameters to all variables. Casting this one-shot guidance as a\nreinforcement learning problem lets us train the GNN with off-the-shelf\npolicy-gradient methods, such as GRPO, directly using the solver's\ncomputational cost as the sole reward signal. Extensive evaluations demonstrate\nthat RLAF-trained policies significantly reduce the mean solve times of\ndifferent base solvers across diverse SAT problem distributions, achieving more\nthan a 2x speedup in some cases, while generalizing effectively to larger and\nharder problems after training. Notably, these policies consistently outperform\nexpert-supervised approaches based on learning handcrafted weighting\nheuristics, offering a promising path towards data-driven heuristic design in\ncombinatorial optimization.", "AI": {"tldr": "This paper introduces Reinforcement Learning from Algorithm Feedback (RLAF) to improve Boolean Satisfiability (SAT) solvers' performance by learning branching heuristics with Graph Neural Networks.", "motivation": "Current SAT solvers rely heavily on hand-crafted heuristics, which may not be optimal.", "method": "Using RLAF to train GNNs that inject variable weights and polarities into existing SAT solvers' branching heuristics.", "result": "RLAF-trained policies reduce mean solve times by over 2x in some cases and generalize well to larger and harder problems.", "conclusion": "The proposed method outperforms expert-supervised approaches and shows promise for data-driven heuristic design in combinatorial optimization."}}
{"id": "2505.16097", "pdf": "https://arxiv.org/pdf/2505.16097", "abs": "https://arxiv.org/abs/2505.16097", "authors": ["Zifeng Wang", "Qiao Jin", "Jiacheng Lin", "Junyi Gao", "Jathurshan Pradeepkumar", "Pengcheng Jiang", "Benjamin Danek", "Zhiyong Lu", "Jimeng Sun"], "title": "TrialPanorama: Database and Benchmark for Systematic Review and Design of Clinical Trials", "categories": ["cs.AI"], "comment": null, "summary": "Developing artificial intelligence (AI) for vertical domains requires a solid\ndata foundation for both training and evaluation. In this work, we introduce\nTrialPanorama, a large-scale, structured database comprising 1,657,476 clinical\ntrial records aggregated from 15 global sources. The database captures key\naspects of trial design and execution, including trial setups, interventions,\nconditions, biomarkers, and outcomes, and links them to standard biomedical\nontologies such as DrugBank and MedDRA. This structured and ontology-grounded\ndesign enables TrialPanorama to serve as a unified, extensible resource for a\nwide range of clinical trial tasks, including trial planning, design, and\nsummarization. To demonstrate its utility, we derive a suite of benchmark tasks\ndirectly from the TrialPanorama database. The benchmark spans eight tasks\nacross two categories: three for systematic review (study search, study\nscreening, and evidence summarization) and five for trial design (arm design,\neligibility criteria, endpoint selection, sample size estimation, and trial\ncompletion assessment). The experiments using five state-of-the-art large\nlanguage models (LLMs) show that while general-purpose LLMs exhibit some\nzero-shot capability, their performance is still inadequate for high-stakes\nclinical trial workflows. We release TrialPanorama database and the benchmark\nto facilitate further research on AI for clinical trials.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5305\u542b1,657,476\u4e2a\u4e34\u5e8a\u8bd5\u9a8c\u8bb0\u5f55\u7684\u5927\u89c4\u6a21\u7ed3\u6784\u5316\u6570\u636e\u5e93TrialPanorama\uff0c\u5b83\u80fd\u652f\u6301\u591a\u79cd\u4e34\u5e8a\u8bd5\u9a8c\u4efb\u52a1\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u516b\u4e2a\u57fa\u51c6\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002\u5b9e\u9a8c\u8868\u660e\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u9886\u57df\u8868\u73b0\u6709\u9650\u3002", "motivation": "\u4e3a\u5782\u76f4\u9886\u57df\u7684\u4eba\u5de5\u667a\u80fd\u5f00\u53d1\u63d0\u4f9b\u575a\u5b9e\u7684\u6570\u636e\u57fa\u7840\uff0c\u7279\u522b\u662f\u9488\u5bf9\u4e34\u5e8a\u8bd5\u9a8c\u7684\u4efb\u52a1\u3002", "method": "\u6784\u5efa\u4e86TrialPanorama\u6570\u636e\u5e93\uff0c\u8be5\u6570\u636e\u5e93\u4ece15\u4e2a\u5168\u7403\u6765\u6e90\u6c47\u603b\u6570\u636e\u5e76\u94fe\u63a5\u5230\u6807\u51c6\u751f\u7269\u533b\u5b66\u672c\u4f53\u8bba\u3002\u6b64\u5916\uff0c\u8fd8\u5b9a\u4e49\u4e86\u4e00\u5957\u57fa\u51c6\u4efb\u52a1\u6765\u5c55\u793a\u6570\u636e\u5e93\u7684\u5e94\u7528\u3002", "result": "\u8bd5\u9a8c\u663e\u793a\uff0c\u867d\u7136\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6709\u4e00\u5b9a\u7684\u96f6\u6837\u672c\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u7684\u8868\u73b0\u8fd8\u4e0d\u8db3\u4ee5\u6ee1\u8db3\u9ad8\u98ce\u9669\u7684\u4e34\u5e8a\u8bd5\u9a8c\u5de5\u4f5c\u6d41\u7a0b\u7684\u9700\u6c42\u3002", "conclusion": "\u53d1\u5e03TrialPanorama\u6570\u636e\u5e93\u548c\u57fa\u51c6\u4efb\u52a1\uff0c\u4ee5\u4fc3\u8fdb\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u7684\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u3002"}}
{"id": "2505.16893", "pdf": "https://arxiv.org/pdf/2505.16893", "abs": "https://arxiv.org/abs/2505.16893", "authors": ["Shuichi Nishino", "Tomohiro Shiraishi", "Teruyuki Katsuoka", "Ichiro Takeuchi"], "title": "Statistical Test for Saliency Maps of Graph Neural Networks via Selective Inference", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have gained prominence for their ability to\nprocess graph-structured data across various domains. However, interpreting GNN\ndecisions remains a significant challenge, leading to the adoption of saliency\nmaps for identifying influential nodes and edges. Despite their utility, the\nreliability of GNN saliency maps has been questioned, particularly in terms of\ntheir robustness to noise. In this study, we propose a statistical testing\nframework to rigorously evaluate the significance of saliency maps. Our main\ncontribution lies in addressing the inflation of the Type I error rate caused\nby double-dipping of data, leveraging the framework of Selective Inference. Our\nmethod provides statistically valid $p$-values while controlling the Type I\nerror rate, ensuring that identified salient subgraphs contain meaningful\ninformation rather than random artifacts. To demonstrate the effectiveness of\nour method, we conduct experiments on both synthetic and real-world datasets,\nshowing its effectiveness in assessing the reliability of GNN interpretations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7edf\u8ba1\u6d4b\u8bd5\u6846\u67b6\u8bc4\u4f30\u56fe\u795e\u7ecf\u7f51\u7edc\u663e\u8457\u6027\u56fe\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u89e3\u51b3\u56fe\u795e\u7ecf\u7f51\u7edc\u51b3\u7b56\u89e3\u91ca\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u663e\u8457\u6027\u56fe\u5bf9\u566a\u58f0\u7684\u9c81\u68d2\u6027\u3002", "method": "\u5229\u7528\u9009\u62e9\u6027\u63a8\u65ad\u6846\u67b6\u6784\u5efa\u7edf\u8ba1\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u63a7\u5236I\u578b\u9519\u8bef\u7387\u5e76\u63d0\u4f9b\u6709\u6548\u7684p\u503c\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u786e\u4fdd\u8bc6\u522b\u51fa\u7684\u663e\u8457\u5b50\u56fe\u5305\u542b\u6709\u610f\u4e49\u7684\u4fe1\u606f\u3002"}}
{"id": "2505.16056", "pdf": "https://arxiv.org/pdf/2505.16056", "abs": "https://arxiv.org/abs/2505.16056", "authors": ["Jingcong Liang", "Siyuan Wang", "Miren Tian", "Yitong Li", "Duyu Tang", "Zhongyu Wei"], "title": "Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) enables efficient scaling of large language models\n(LLMs) with sparsely activated experts during inference. To effectively deploy\nlarge MoE models on memory-constrained devices, many systems introduce *expert\noffloading* that caches a subset of experts in fast memory, leaving others on\nslow memory to run on CPU or load on demand. While some research has exploited\nthe locality of expert activations, where consecutive tokens activate similar\nexperts, the degree of this **local routing consistency** varies across models\nand remains understudied. In this paper, we propose two metrics to measure\nlocal routing consistency of MoE models: (1) **Segment Routing Best Performance\n(SRP)**, which evaluates how well a fixed group of experts can cover the needs\nof a segment of tokens, and (2) **Segment Cache Best Hit Rate (SCH)**, which\nmeasures the optimal segment-level cache hit rate under a given cache size\nlimit. We analyzed 20 MoE LLMs with diverse sizes and architectures and found\nthat models that apply MoE on every layer and do not use shared experts exhibit\nthe highest local routing consistency. We further showed that\ndomain-specialized experts contribute more to routing consistency than\nvocabulary-specialized ones, and that most models can balance between cache\neffectiveness and efficiency with cache sizes approximately 2x the active\nexperts. These findings pave the way for memory-efficient MoE design and\ndeployment without compromising inference speed. We publish the code for\nreplicating experiments at https://github.com/ljcleo/moe-lrc .", "AI": {"tldr": "\u63d0\u51fa\u4e24\u79cd\u5ea6\u91cf\u65b9\u6cd5\u6765\u8861\u91cfMoE\u6a21\u578b\u7684\u5c40\u90e8\u8def\u7531\u4e00\u81f4\u6027\uff0c\u5e76\u5bf920\u4e2a\u4e0d\u540c\u5927\u5c0f\u548c\u67b6\u6784\u7684MoE LLMs\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u53d1\u73b0\u67d0\u4e9b\u8bbe\u8ba1\u7279\u70b9\u80fd\u63d0\u9ad8\u4e00\u81f4\u6027\uff0c\u4e14\u5927\u591a\u6570\u6a21\u578b\u5728\u7f13\u5b58\u5927\u5c0f\u7ea6\u4e3a\u6d3b\u8dc3\u4e13\u5bb6\u6570\u91cf\u4e24\u500d\u65f6\u53ef\u4ee5\u5e73\u8861\u7f13\u5b58\u6548\u7387\u4e0e\u6548\u679c\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u7814\u7a76MoE\u6a21\u578b\u5728\u5185\u5b58\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u9ad8\u6548\u90e8\u7f72\uff0c\u7279\u522b\u662f\u5c40\u90e8\u8def\u7531\u4e00\u81f4\u6027\u7684\u5ea6\u91cf\u4e0e\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86SRP\u548cSCH\u4e24\u4e2a\u5ea6\u91cf\u6307\u6807\uff0c\u5e76\u5206\u6790\u4e8620\u4e2aMoE LLMs\u3002", "result": "\u53d1\u73b0\u7279\u5b9a\u8bbe\u8ba1\uff08\u5982\u6bcf\u5c42\u5e94\u7528MoE\u4e14\u4e0d\u4f7f\u7528\u5171\u4eab\u4e13\u5bb6\uff09\u80fd\u63d0\u9ad8\u5c40\u90e8\u8def\u7531\u4e00\u81f4\u6027\uff1b\u9886\u57df\u4e13\u7528\u4e13\u5bb6\u6bd4\u8bcd\u6c47\u4e13\u7528\u4e13\u5bb6\u5bf9\u4e00\u81f4\u6027\u8d21\u732e\u66f4\u5927\uff1b\u5927\u591a\u6570\u6a21\u578b\u5728\u7f13\u5b58\u5927\u5c0f\u7ea6\u4e3a\u6d3b\u8dc3\u4e13\u5bb6\u6570\u91cf\u4e24\u500d\u65f6\u53ef\u5e73\u8861\u7f13\u5b58\u6548\u679c\u4e0e\u6548\u7387\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u6709\u52a9\u4e8e\u8bbe\u8ba1\u548c\u90e8\u7f72\u5185\u5b58\u9ad8\u6548\u7684MoE\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u63a8\u7406\u901f\u5ea6\u3002"}}
{"id": "2505.16100", "pdf": "https://arxiv.org/pdf/2505.16100", "abs": "https://arxiv.org/abs/2505.16100", "authors": ["Zifeng Wang", "Benjamin Danek", "Jimeng Sun"], "title": "BioDSA-1K: Benchmarking Data Science Agents for Biomedical Research", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Validating scientific hypotheses is a central challenge in biomedical\nresearch, and remains difficult for artificial intelligence (AI) agents due to\nthe complexity of real-world data analysis and evidence interpretation. In this\nwork, we present BioDSA-1K, a benchmark designed to evaluate AI agents on\nrealistic, data-driven biomedical hypothesis validation tasks. BioDSA-1K\nconsists of 1,029 hypothesis-centric tasks paired with 1,177 analysis plans,\ncurated from over 300 published biomedical studies to reflect the structure and\nreasoning found in authentic research workflows. Each task includes a\nstructured hypothesis derived from the original study's conclusions, expressed\nin the affirmative to reflect the language of scientific reporting, and one or\nmore pieces of supporting evidence grounded in empirical data tables. While\nthese hypotheses mirror published claims, they remain testable using standard\nstatistical or machine learning methods. The benchmark enables evaluation along\nfour axes: (1) hypothesis decision accuracy, (2) alignment between evidence and\nconclusion, (3) correctness of the reasoning process, and (4) executability of\nthe AI-generated analysis code. Importantly, BioDSA-1K includes non-verifiable\nhypotheses: cases where the available data are insufficient to support or\nrefute a claim, reflecting a common yet underexplored scenario in real-world\nscience. We propose BioDSA-1K as a foundation for building and evaluating\ngeneralizable, trustworthy AI agents for biomedical discovery.", "AI": {"tldr": "\u63d0\u51faBioDSA-1K\u57fa\u51c6\u6765\u8bc4\u4f30AI\u5728\u771f\u5b9e\u6570\u636e\u9a71\u52a8\u7684\u751f\u7269\u533b\u5b66\u5047\u8bbe\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u8be5\u57fa\u51c6\u5305\u542b\u4ece300\u591a\u7bc7\u5df2\u53d1\u8868\u7684\u7814\u7a76\u4e2d\u63d0\u53d6\u76841029\u4e2a\u5047\u8bbe\u4efb\u52a1\u548c1177\u4e2a\u5206\u6790\u8ba1\u5212\u3002", "motivation": "\u79d1\u5b66\u5047\u8bbe\u9a8c\u8bc1\u5728\u751f\u7269\u533b\u5b66\u7814\u7a76\u4e2d\u5f88\u91cd\u8981\uff0c\u4f46\u5bf9AI\u6765\u8bf4\u4ecd\u7136\u5f88\u56f0\u96be\u3002", "method": "\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aBioDSA-1K\u7684\u57fa\u51c6\uff0c\u5b83\u5305\u542b\u4e86\u4ece300\u591a\u7bc7\u7814\u7a76\u4e2d\u63d0\u53d6\u7684\u4efb\u52a1\u548c\u5206\u6790\u8ba1\u5212\u3002", "result": "BioDSA-1K\u53ef\u4ee5\u6cbf\u7740\u56db\u4e2a\u8f74\u8fdb\u884c\u8bc4\u4f30\uff0c\u5e76\u4e14\u5305\u62ec\u4e0d\u53ef\u9a8c\u8bc1\u7684\u5047\u8bbe\u60c5\u51b5\u3002", "conclusion": "\u5efa\u8bae\u4f7f\u7528BioDSA-1K\u4f5c\u4e3a\u6784\u5efa\u548c\u8bc4\u4f30\u53ef\u63a8\u5e7f\u3001\u53ef\u4fe1\u7684AI\u4ee3\u7406\u7684\u57fa\u7840\u3002"}}
{"id": "2505.16923", "pdf": "https://arxiv.org/pdf/2505.16923", "abs": "https://arxiv.org/abs/2505.16923", "authors": ["Yuhui Zhang", "Dongshen Wu", "Yuichiro Wada", "Takafumi Kanamori"], "title": "TULiP: Test-time Uncertainty Estimation via Linearization and Weight Perturbation", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "A reliable uncertainty estimation method is the foundation of many modern\nout-of-distribution (OOD) detectors, which are critical for safe deployments of\ndeep learning models in the open world. In this work, we propose TULiP, a\ntheoretically-driven post-hoc uncertainty estimator for OOD detection. Our\napproach considers a hypothetical perturbation applied to the network before\nconvergence. Based on linearized training dynamics, we bound the effect of such\nperturbation, resulting in an uncertainty score computable by perturbing model\nparameters. Ultimately, our approach computes uncertainty from a set of sampled\npredictions. We visualize our bound on synthetic regression and classification\ndatasets. Furthermore, we demonstrate the effectiveness of TULiP using\nlarge-scale OOD detection benchmarks for image classification. Our method\nexhibits state-of-the-art performance, particularly for near-distribution\nsamples.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTULiP\u7684\u7406\u8bba\u9a71\u52a8\u540e\u9a8c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\u7528\u4e8e\u5f02\u5e38\u68c0\u6d4b\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ebf\u6027\u5316\u8bad\u7ec3\u52a8\u6001\u6765\u9650\u5236\u7f51\u7edc\u5728\u6536\u655b\u524d\u5047\u8bbe\u6270\u52a8\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u8ba1\u7b97\u4e0d\u786e\u5b9a\u6027\u5f97\u5206\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\uff0c\u5c24\u5176\u662f\u5728\u8fd1\u4f3c\u5206\u5e03\u6837\u672c\u7684\u68c0\u6d4b\u4e2d\u8868\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u53ef\u9760\u5730\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\u5bf9\u4e8e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5f00\u653e\u4e16\u754c\u7684\u5b89\u5168\u90e8\u7f72\u81f3\u5173\u91cd\u8981\uff0c\u800c\u73b0\u6709\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51fa\u4e86TULiP\u65b9\u6cd5\uff0c\u8003\u8651\u4e86\u7f51\u7edc\u5728\u6536\u655b\u524d\u7684\u5047\u8bbe\u6270\u52a8\uff0c\u5e76\u57fa\u4e8e\u7ebf\u6027\u5316\u8bad\u7ec3\u52a8\u529b\u5b66\u9650\u5b9a\u4e86\u8fd9\u79cd\u6270\u52a8\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u8ba1\u7b97\u51fa\u53ef\u7531\u6a21\u578b\u53c2\u6570\u6270\u52a8\u5f97\u5230\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u6570\u3002", "result": "TULiP\u65b9\u6cd5\u5728\u5408\u6210\u56de\u5f52\u548c\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u53ef\u89c6\u5316\u4e86\u5176\u754c\u9650\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u5f02\u5e38\u68c0\u6d4b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u8fd1\u4f3c\u5206\u5e03\u6837\u672c\u65f6\u8868\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "TULiP\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u7406\u8bba\u9a71\u52a8\u7684\u540e\u9a8c\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5bf9\u4e8e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u5b89\u5168\u90e8\u7f72\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2505.16058", "pdf": "https://arxiv.org/pdf/2505.16058", "abs": "https://arxiv.org/abs/2505.16058", "authors": ["Mars Liyao Gao", "J. Nathan Kutz", "Bernat Font"], "title": "Mesh-free sparse identification of nonlinear dynamics", "categories": ["cs.LG", "cs.AI", "physics.data-an"], "comment": "17 pages, 13 figures, 14 tables", "summary": "Identifying the governing equations of a dynamical system is one of the most\nimportant tasks for scientific modeling. However, this procedure often requires\nhigh-quality spatio-temporal data uniformly sampled on structured grids. In\nthis paper, we propose mesh-free SINDy, a novel algorithm which leverages the\npower of neural network approximation as well as auto-differentiation to\nidentify governing equations from arbitrary sensor placements and non-uniform\ntemporal data sampling. We show that mesh-free SINDy is robust to high noise\nlevels and limited data while remaining computationally efficient. In our\nimplementation, the training procedure is straight-forward and nearly free of\nhyperparameter tuning, making mesh-free SINDy widely applicable to many\nscientific and engineering problems. In the experiments, we demonstrate its\neffectiveness on a series of PDEs including the Burgers' equation, the heat\nequation, the Korteweg-De Vries equation and the 2D advection-diffusion\nequation. We conduct detailed numerical experiments on all datasets, varying\nthe noise levels and number of samples, and we also compare our approach to\nprevious state-of-the-art methods. It is noteworthy that, even in high-noise\nand low-data scenarios, mesh-free SINDy demonstrates robust PDE discovery,\nachieving successful identification with up to 75% noise for the Burgers'\nequation using 5,000 samples and with as few as 100 samples and 1% noise. All\nof this is achieved within a training time of under one minute.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5mesh-free SINDy\uff0c\u53ef\u4ee5\u4ece\u4efb\u610f\u4f20\u611f\u5668\u653e\u7f6e\u548c\u975e\u5747\u5300\u65f6\u95f4\u6570\u636e\u91c7\u6837\u4e2d\u8bc6\u522b\u63a7\u5236\u65b9\u7a0b\u3002\u8be5\u7b97\u6cd5\u5728\u9ad8\u566a\u58f0\u6c34\u5e73\u548c\u6709\u9650\u6570\u636e\u4e0b\u8868\u73b0\u51fa\u4e86\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u5728\u591a\u79cd\u504f\u5fae\u5206\u65b9\u7a0b\u4e0a\u8fdb\u884c\u4e86\u6709\u6548\u7684\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u7684\u52a8\u529b\u7cfb\u7edf\u79d1\u5b66\u5efa\u6a21\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u9ad8\u8d28\u91cf\u7684\u7a7a\u95f4-\u65f6\u95f4\u6570\u636e\u5728\u7ed3\u6784\u5316\u7f51\u683c\u4e0a\u7684\u5747\u5300\u91c7\u6837\uff0c\u800c\u73b0\u5b9e\u4e2d\u7684\u6570\u636e\u5f80\u5f80\u4e0d\u7b26\u5408\u8fd9\u4e9b\u8981\u6c42\u3002", "method": "\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u903c\u8fd1\u548c\u81ea\u52a8\u5fae\u5206\u6280\u672f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3amesh-free SINDy\u7684\u65b0\u7b97\u6cd5\uff0c\u53ef\u4ee5\u5904\u7406\u4efb\u610f\u4f20\u611f\u5668\u653e\u7f6e\u548c\u975e\u5747\u5300\u65f6\u95f4\u6570\u636e\u91c7\u6837\u3002", "result": "\u5728\u591a\u79cd\u504f\u5fae\u5206\u65b9\u7a0b\u4e0a\u8fdb\u884c\u4e86\u6709\u6548\u7684\u9a8c\u8bc1\uff0c\u5305\u62ecBurgers\u65b9\u7a0b\u3001\u70ed\u65b9\u7a0b\u3001Korteweg-De Vries\u65b9\u7a0b\u548c\u4e8c\u7ef4\u5bf9\u6d41-\u6269\u6563\u65b9\u7a0b\u3002\u5373\u4f7f\u5728\u9ad8\u566a\u58f0\u548c\u4f4e\u6570\u636e\u60c5\u51b5\u4e0b\uff0cmesh-free SINDy\u4e5f\u80fd\u6210\u529f\u8bc6\u522b\u63a7\u5236\u65b9\u7a0b\u3002", "conclusion": "mesh-free SINDy\u662f\u4e00\u79cd\u5e7f\u6cdb\u9002\u7528\u4e8e\u79d1\u5b66\u548c\u5de5\u7a0b\u95ee\u9898\u7684\u7b97\u6cd5\uff0c\u5176\u8bad\u7ec3\u8fc7\u7a0b\u7b80\u5355\uff0c\u51e0\u4e4e\u4e0d\u9700\u8981\u8d85\u53c2\u6570\u8c03\u6574\u3002"}}
{"id": "2505.16114", "pdf": "https://arxiv.org/pdf/2505.16114", "abs": "https://arxiv.org/abs/2505.16114", "authors": ["Naiqi Li", "Peiyuan Liu", "Zheng Liu", "Tao Dai", "Yong Jiang", "Shu-Tao Xia"], "title": "Logic-of-Thought: Empowering Large Language Models with Logic Programs for Solving Puzzles in Natural Language", "categories": ["cs.AI"], "comment": null, "summary": "Solving puzzles in natural language poses a long-standing challenge in AI.\nWhile large language models (LLMs) have recently shown impressive capabilities\nin a variety of tasks, they continue to struggle with complex puzzles that\ndemand precise reasoning and exhaustive search. In this paper, we propose\nLogic-of-Thought (Logot), a novel framework that bridges LLMs with logic\nprogramming to address this problem. Our method leverages LLMs to translate\npuzzle rules and states into answer set programs (ASPs), the solution of which\nare then accurately and efficiently inferred by an ASP interpreter. This hybrid\napproach combines the natural language understanding of LLMs with the precise\nreasoning capabilities of logic programs. We evaluate our method on various\ngrid puzzles and dynamic puzzles involving actions, demonstrating near-perfect\naccuracy across all tasks. Our code and data are available at:\nhttps://github.com/naiqili/Logic-of-Thought.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLogic-of-Thought\uff08Logot\uff09\u7684\u65b0\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u903b\u8f91\u7f16\u7a0b\u89e3\u51b3\u590d\u6742\u81ea\u7136\u8bed\u8a00\u8c1c\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9700\u8981\u7cbe\u786e\u63a8\u7406\u548c\u5168\u9762\u641c\u7d22\u7684\u590d\u6742\u8c1c\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u5c06\u8c1c\u9898\u89c4\u5219\u548c\u72b6\u6001\u8f6c\u6362\u4e3a\u7b54\u6848\u96c6\u7a0b\u5e8f\uff0c\u5e76\u901a\u8fc7ASP\u89e3\u91ca\u5668\u63a8\u65ad\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5728\u591a\u79cd\u7f51\u683c\u8c1c\u9898\u548c\u6d89\u53ca\u52a8\u4f5c\u7684\u52a8\u6001\u8c1c\u9898\u4e0a\u8868\u73b0\u51fa\u63a5\u8fd1\u5b8c\u7f8e\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u7ed3\u5408\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7406\u89e3\u80fd\u529b\u548c\u903b\u8f91\u7a0b\u5e8f\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2505.17000", "pdf": "https://arxiv.org/pdf/2505.17000", "abs": "https://arxiv.org/abs/2505.17000", "authors": ["Simmaco Di Lillo"], "title": "Critical Points of Random Neural Networks", "categories": ["stat.ML", "cs.LG", "math.PR", "60G60, 62B10, 62M45"], "comment": null, "summary": "This work investigates the expected number of critical points of random\nneural networks with different activation functions as the depth increases in\nthe infinite-width limit. Under suitable regularity conditions, we derive\nprecise asymptotic formulas for the expected number of critical points of fixed\nindex and those exceeding a given threshold. Our analysis reveals three\ndistinct regimes depending on the value of the first derivative of the\ncovariance evaluated at 1: the expected number of critical points may converge,\ngrow polynomially, or grow exponentially with depth. The theoretical\npredictions are supported by numerical experiments. Moreover, we provide\nnumerical evidence suggesting that, when the regularity condition is not\nsatisfied (e.g. for neural networks with ReLU as activation function), the\nnumber of critical points increases as the map resolution increases, indicating\na potential divergence in the number of critical points.", "AI": {"tldr": "\u7814\u7a76\u4e86\u65e0\u9650\u5bbd\u5ea6\u9650\u5236\u4e0b\u4e0d\u540c\u6fc0\u6d3b\u51fd\u6570\u968f\u673a\u795e\u7ecf\u7f51\u7edc\u7684\u4e34\u754c\u70b9\u6570\u91cf\u968f\u6df1\u5ea6\u53d8\u5316\u7684\u60c5\u51b5\u3002\u5728\u9002\u5f53\u6b63\u5219\u6761\u4ef6\u4e0b\uff0c\u63a8\u5bfc\u51fa\u56fa\u5b9a\u6307\u6570\u548c\u8d85\u8fc7\u7ed9\u5b9a\u9608\u503c\u7684\u4e34\u754c\u70b9\u671f\u671b\u6570\u91cf\u7684\u7cbe\u786e\u6e10\u8fd1\u516c\u5f0f\u3002\u63ed\u793a\u4e86\u4e09\u4e2a\u4e0d\u540c\u7684\u533a\u57df\uff0c\u5176\u53d6\u51b3\u4e8e\u534f\u65b9\u5dee\u57281\u5904\u7684\u4e00\u9636\u5bfc\u6570\u503c\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u652f\u6301\u7406\u8bba\u9884\u6d4b\u3002\u6b64\u5916\uff0c\u63d0\u4f9b\u4e86\u5f53\u6b63\u5219\u6761\u4ef6\u4e0d\u6ee1\u8db3\u65f6\u4e34\u754c\u70b9\u6570\u91cf\u589e\u52a0\u7684\u6570\u503c\u8bc1\u636e\u3002", "motivation": "\u7814\u7a76\u968f\u673a\u795e\u7ecf\u7f51\u7edc\u4e34\u754c\u70b9\u6570\u91cf\u7684\u53d8\u5316\u89c4\u5f8b\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u6fc0\u6d3b\u51fd\u6570\u548c\u65e0\u9650\u5bbd\u5ea6\u9650\u5236\u4e0b\u7684\u884c\u4e3a\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u5206\u6790\u63a8\u5bfc\u51fa\u7cbe\u786e\u7684\u6e10\u8fd1\u516c\u5f0f\uff0c\u5e76\u7ed3\u5408\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u9884\u6d4b\u3002", "result": "\u63ed\u793a\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u589e\u957f\u6a21\u5f0f\uff08\u6536\u655b\u3001\u591a\u9879\u5f0f\u589e\u957f\u3001\u6307\u6570\u589e\u957f\uff09\u53d6\u51b3\u4e8e\u534f\u65b9\u5dee\u7684\u4e00\u9636\u5bfc\u6570\uff0c\u5e76\u53d1\u73b0ReLU\u6fc0\u6d3b\u51fd\u6570\u7b49\u60c5\u51b5\u4e0b\u4e34\u754c\u70b9\u6570\u91cf\u53ef\u80fd\u53d1\u6563\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u968f\u673a\u795e\u7ecf\u7f51\u7edc\u5728\u4e0d\u540c\u6fc0\u6d3b\u51fd\u6570\u548c\u65e0\u9650\u5bbd\u5ea6\u9650\u5236\u4e0b\u4e34\u754c\u70b9\u6570\u91cf\u7684\u589e\u957f\u89c4\u5f8b\uff0c\u5bf9\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u4f18\u5316\u666f\u89c2\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2505.16060", "pdf": "https://arxiv.org/pdf/2505.16060", "abs": "https://arxiv.org/abs/2505.16060", "authors": ["Shangding Gu", "Donghao Ying", "Ming Jin", "Yu Joe Lu", "Jun Wang", "Javad Lavaei", "Costas Spanos"], "title": "Few-Shot Test-Time Optimization Without Retraining for Semiconductor Recipe Generation and Beyond", "categories": ["cs.LG"], "comment": null, "summary": "We introduce Model Feedback Learning (MFL), a novel test-time optimization\nframework for optimizing inputs to pre-trained AI models or deployed hardware\nsystems without requiring any retraining of the models or modifications to the\nhardware. In contrast to existing methods that rely on adjusting model\nparameters, MFL leverages a lightweight reverse model to iteratively search for\noptimal inputs, enabling efficient adaptation to new objectives under\ndeployment constraints. This framework is particularly advantageous in\nreal-world settings, such as semiconductor manufacturing recipe generation,\nwhere modifying deployed systems is often infeasible or cost-prohibitive. We\nvalidate MFL on semiconductor plasma etching tasks, where it achieves target\nrecipe generation in just five iterations, significantly outperforming both\nBayesian optimization and human experts. Beyond semiconductor applications, MFL\nalso demonstrates strong performance in chemical processes (e.g., chemical\nvapor deposition) and electronic systems (e.g., wire bonding), highlighting its\nbroad applicability. Additionally, MFL incorporates stability-aware\noptimization, enhancing robustness to process variations and surpassing\nconventional supervised learning and random search methods in high-dimensional\ncontrol settings. By enabling few-shot adaptation, MFL provides a scalable and\nefficient paradigm for deploying intelligent control in real-world\nenvironments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aModel Feedback Learning (MFL)\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e0d\u4fee\u6539\u6a21\u578b\u6216\u786c\u4ef6\u7684\u60c5\u51b5\u4e0b\u4f18\u5316\u9884\u8bad\u7ec3AI\u6a21\u578b\u6216\u90e8\u7f72\u7684\u786c\u4ef6\u7cfb\u7edf\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u8f7b\u91cf\u7ea7\u53cd\u5411\u6a21\u578b\u8fed\u4ee3\u5bfb\u627e\u6700\u4f18\u8f93\u5165\uff0c\u5728\u534a\u5bfc\u4f53\u5236\u9020\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e14\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5176\u4ed6\u4f18\u5316\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u8c03\u6574\u6a21\u578b\u53c2\u6570\uff0c\u800c\u5728\u8bb8\u591a\u5b9e\u9645\u573a\u666f\u4e2d\u4fee\u6539\u90e8\u7f72\u7684\u7cfb\u7edf\u662f\u4e0d\u53ef\u884c\u6216\u6210\u672c\u9ad8\u6602\u7684\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u65b9\u6cd5\u6765\u9002\u5e94\u65b0\u76ee\u6807\u3002", "method": "MFL\u5229\u7528\u8f7b\u91cf\u7ea7\u53cd\u5411\u6a21\u578b\u8fed\u4ee3\u641c\u7d22\u6700\u4f18\u8f93\u5165\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u6216\u66f4\u6539\u786c\u4ef6\u3002", "result": "\u5728\u534a\u5bfc\u4f53\u523b\u8680\u4efb\u52a1\u4e2d\uff0cMFL\u4ec5\u9700\u4e94\u6b21\u8fed\u4ee3\u5373\u53ef\u5b9e\u73b0\u76ee\u6807\u914d\u65b9\u751f\u6210\uff0c\u663e\u8457\u4f18\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u4eba\u7c7b\u4e13\u5bb6\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u5728\u5316\u5b66\u8fc7\u7a0b\u548c\u7535\u5b50\u7cfb\u7edf\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "MFL\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u8303\u4f8b\uff0c\u7528\u4e8e\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u90e8\u7f72\u667a\u80fd\u63a7\u5236\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5c11\u91cf\u6837\u672c\u9002\u5e94\u7684\u573a\u666f\u4e2d\u3002"}}
{"id": "2505.16120", "pdf": "https://arxiv.org/pdf/2505.16120", "abs": "https://arxiv.org/abs/2505.16120", "authors": ["Guannan Liang", "Qianqian Tong"], "title": "LLM-Powered AI Agent Systems and Their Applications in Industry", "categories": ["cs.AI"], "comment": "This is the author's accepted version of the paper accepted to appear\n  at IEEE AIIoT 2025. The final version will be available via IEEE Xplore.\n  \\c{opyright}2025 IEEE. Personal use of this material is permitted", "summary": "The emergence of Large Language Models (LLMs) has reshaped agent systems.\nUnlike traditional rule-based agents with limited task scope, LLM-powered\nagents offer greater flexibility, cross-domain reasoning, and natural language\ninteraction. Moreover, with the integration of multi-modal LLMs, current agent\nsystems are highly capable of processing diverse data modalities, including\ntext, images, audio, and structured tabular data, enabling richer and more\nadaptive real-world behavior. This paper comprehensively examines the evolution\nof agent systems from the pre-LLM era to current LLM-powered architectures. We\ncategorize agent systems into software-based, physical, and adaptive hybrid\nsystems, highlighting applications across customer service, software\ndevelopment, manufacturing automation, personalized education, financial\ntrading, and healthcare. We further discuss the primary challenges posed by\nLLM-powered agents, including high inference latency, output uncertainty, lack\nof evaluation metrics, and security vulnerabilities, and propose potential\nsolutions to mitigate these concerns.", "AI": {"tldr": "Large Language Models (LLMs) have transformed agent systems, offering flexible, cross-domain reasoning and natural language interaction. Current systems can process multiple data modalities. The paper reviews the development of agent systems from pre-LLM to current architectures, categorizing them into software-based, physical, and hybrid types with various applications. It also addresses challenges like latency, uncertainty, lack of metrics, and security issues.", "motivation": "To examine the evolution of agent systems from pre-LLM to current LLM-powered architectures and address challenges posed by LLM-powered agents.", "method": "Categorizing agent systems into software-based, physical, and adaptive hybrid systems and discussing their applications in different fields.", "result": "Current agent systems powered by LLMs can process diverse data modalities and exhibit rich, adaptive behaviors. They have been applied in customer service, software development, manufacturing, education, finance, and healthcare.", "conclusion": "LLMs have significantly enhanced agent systems, but challenges such as high inference latency, output uncertainty, lack of evaluation metrics, and security issues need to be addressed."}}
{"id": "2505.16066", "pdf": "https://arxiv.org/pdf/2505.16066", "abs": "https://arxiv.org/abs/2505.16066", "authors": ["Zhixu Silvia Tao", "Kasper Vinken", "Hao-Wei Yeh", "Avi Cooper", "Xavier Boix"], "title": "Merge to Mix: Mixing Datasets via Model Merging", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Mixing datasets for fine-tuning large models (LMs) has become critical for\nmaximizing performance on downstream tasks. However, composing effective\ndataset mixtures typically relies on heuristics and trial-and-error, often\nrequiring multiple fine-tuning runs to achieve the desired outcome. We propose\na novel method, $\\textit{Merge to Mix}$, that accelerates composing dataset\nmixtures through model merging. Model merging is a recent technique that\ncombines the abilities of multiple individually fine-tuned LMs into a single LM\nby using a few simple arithmetic operations. Our key insight is that merging\nmodels individually fine-tuned on each dataset in a mixture can effectively\nserve as a surrogate for a model fine-tuned on the entire mixture. Merge to Mix\nleverages this insight to accelerate selecting dataset mixtures without\nrequiring full fine-tuning on each candidate mixture. Our experiments\ndemonstrate that Merge to Mix surpasses state-of-the-art methods in dataset\nselection for fine-tuning LMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a'Merge to Mix'\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6a21\u578b\u5408\u5e76\u52a0\u901f\u6570\u636e\u96c6\u6df7\u5408\u7684\u7ec4\u6210\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u4e86\u5c06\u5355\u72ec\u5fae\u8c03\u5728\u6bcf\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u6a21\u578b\u5408\u5e76\u6765\u66ff\u4ee3\u5bf9\u6574\u4e2a\u6df7\u5408\u6570\u636e\u96c6\u8fdb\u884c\u5fae\u8c03\u7684\u89c1\u89e3\uff0c\u4ece\u800c\u65e0\u9700\u5bf9\u6bcf\u4e2a\u5019\u9009\u6df7\u5408\u8fdb\u884c\u5b8c\u6574\u7684\u5fae\u8c03\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u636e\u96c6\u9009\u62e9\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u96c6\u6df7\u5408\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u542f\u53d1\u5f0f\u548c\u8bd5\u9519\u6cd5\uff0c\u901a\u5e38\u9700\u8981\u591a\u6b21\u5fae\u8c03\u8fd0\u884c\u624d\u80fd\u8fbe\u5230\u9884\u671f\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86'Merge to Mix'\u65b9\u6cd5\uff0c\u5229\u7528\u6a21\u578b\u5408\u5e76\u6280\u672f\u6765\u52a0\u901f\u6570\u636e\u96c6\u6df7\u5408\u7684\u7ec4\u6210\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a'Merge to Mix'\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u636e\u96c6\u9009\u62e9\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u6a21\u578b\u5408\u5e76\u52a0\u901f\u6570\u636e\u96c6\u6df7\u5408\u7684\u65b9\u6cd5\u5728\u63d0\u9ad8\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u65b9\u9762\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2505.16135", "pdf": "https://arxiv.org/pdf/2505.16135", "abs": "https://arxiv.org/abs/2505.16135", "authors": ["Jeffrey Seely", "Yuki Imajuku", "Tianyu Zhao", "Edoardo Cetin", "Llion Jones"], "title": "Sudoku-Bench: Evaluating creative reasoning with Sudoku variants", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Existing reasoning benchmarks for large language models (LLMs) frequently\nfail to capture authentic creativity, often rewarding memorization of\npreviously observed patterns. We address this shortcoming with Sudoku-Bench, a\ncurated benchmark of challenging and unconventional Sudoku variants\nspecifically selected to evaluate creative, multi-step logical reasoning.\nSudoku variants form an unusually effective domain for reasoning research: each\npuzzle introduces unique or subtly interacting constraints, making memorization\ninfeasible and requiring solvers to identify novel logical breakthroughs\n(``break-ins''). Despite their diversity, Sudoku variants maintain a common and\ncompact structure, enabling clear and consistent evaluation. Sudoku-Bench\nincludes a carefully chosen puzzle set, a standardized text-based puzzle\nrepresentation, and flexible tools compatible with thousands of publicly\navailable puzzles -- making it easy to extend into a general research\nenvironment. Baseline experiments show that state-of-the-art LLMs solve fewer\nthan 15\\% of puzzles unaided, highlighting significant opportunities to advance\nlong-horizon, strategic reasoning capabilities.", "AI": {"tldr": "Introduces Sudoku-Bench, a benchmark for evaluating creative, multi-step logical reasoning in large language models, showing current models solve less than 15% of puzzles unaided.", "motivation": "Existing reasoning benchmarks often reward memorization rather than creativity; aim to address this by creating a challenging Sudoku-based benchmark.", "method": "Develops Sudoku-Bench with curated puzzles, standardized representations, and tools for diverse yet consistent evaluation.", "result": "State-of-the-art LLMs solve less than 15% of puzzles without assistance, indicating room for improvement in long-horizon reasoning.", "conclusion": "Sudoku-Bench provides an effective domain for advancing creative and strategic reasoning in large language models."}}
{"id": "2505.16074", "pdf": "https://arxiv.org/pdf/2505.16074", "abs": "https://arxiv.org/abs/2505.16074", "authors": ["Bart Kosko", "Olaoluwa Adigun"], "title": "Bidirectional Variational Autoencoders", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "10 pages, 6 figures", "summary": "We present the new bidirectional variational autoencoder (BVAE) network\narchitecture. The BVAE uses a single neural network both to encode and decode\ninstead of an encoder-decoder network pair. The network encodes in the forward\ndirection and decodes in the backward direction through the same synaptic web.\nSimulations compared BVAEs and ordinary VAEs on the four image tasks of image\nreconstruction, classification, interpolation, and generation. The image\ndatasets included MNIST handwritten digits, Fashion-MNIST, CIFAR-10, and\nCelebA-64 face images. The bidirectional structure of BVAEs cut the parameter\ncount by almost 50% and still slightly outperformed the unidirectional VAEs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u53cc\u5411\u53d8\u5206\u81ea\u7f16\u7801\u5668(BVAE)\u7f51\u7edc\u67b6\u6784\uff0c\u4e0e\u666e\u901aVAE\u76f8\u6bd4\uff0c\u5728\u56db\u4e2a\u56fe\u50cf\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\u7684\u540c\u65f6\uff0c\u53c2\u6570\u6570\u91cf\u51cf\u5c11\u8fd150%\u3002", "motivation": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4ee5\u63d0\u9ad8\u6548\u7387\u548c\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u5355\u4e2a\u795e\u7ecf\u7f51\u7edc\u65e2\u7528\u4e8e\u7f16\u7801\u53c8\u7528\u4e8e\u89e3\u7801\u7684\u53cc\u5411\u53d8\u5206\u81ea\u7f16\u7801\u5668(BVAE)\uff0c\u800c\u4e0d\u662f\u4f20\u7edf\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u5bf9\u3002", "result": "\u5728MNIST\u624b\u5199\u6570\u5b57\u3001Fashion-MNIST\u3001CIFAR-10\u548cCelebA-64\u4eba\u8138\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u56fe\u50cf\u91cd\u5efa\u3001\u5206\u7c7b\u3001\u63d2\u503c\u548c\u751f\u6210\u4efb\u52a1\u4e2d\uff0cBVAE\u7684\u53cc\u5411\u7ed3\u6784\u4f7f\u5176\u53c2\u6570\u6570\u91cf\u51cf\u5c11\u8fd150%\uff0c\u5e76\u4e14\u7a0d\u5fae\u4f18\u4e8e\u5355\u5411VAE\u3002", "conclusion": "\u63d0\u51fa\u7684BVAE\u7f51\u7edc\u67b6\u6784\u5728\u4fdd\u6301\u751a\u81f3\u7565\u5fae\u63d0\u5347\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u53c2\u6570\u6570\u91cf\uff0c\u663e\u793a\u51fa\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2505.16147", "pdf": "https://arxiv.org/pdf/2505.16147", "abs": "https://arxiv.org/abs/2505.16147", "authors": ["Le Ma", "Shirao Yang", "Zihao Wang", "Yinggui Wang", "Lei Wang", "Tao Wei", "Kejun Zhang"], "title": "Losing is for Cherishing: Data Valuation Based on Machine Unlearning and Shapley Value", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The proliferation of large models has intensified the need for efficient data\nvaluation methods to quantify the contribution of individual data providers.\nTraditional approaches, such as game-theory-based Shapley value and\ninfluence-function-based techniques, face prohibitive computational costs or\nrequire access to full data and model training details, making them hardly\nachieve partial data valuation. To address this, we propose Unlearning Shapley,\na novel framework that leverages machine unlearning to estimate data values\nefficiently. By unlearning target data from a pretrained model and measuring\nperformance shifts on a reachable test set, our method computes Shapley values\nvia Monte Carlo sampling, avoiding retraining and eliminating dependence on\nfull data. Crucially, Unlearning Shapley supports both full and partial data\nvaluation, making it scalable for large models (e.g., LLMs) and practical for\ndata markets. Experiments on benchmark datasets and large-scale text corpora\ndemonstrate that our approach matches the accuracy of state-of-the-art methods\nwhile reducing computational overhead by orders of magnitude. Further analysis\nconfirms a strong correlation between estimated values and the true impact of\ndata subsets, validating its reliability in real-world scenarios. This work\nbridges the gap between data valuation theory and practical deployment,\noffering a scalable, privacy-compliant solution for modern AI ecosystems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aUnlearning Shapley\u7684\u65b0\u6846\u67b6\uff0c\u5229\u7528\u673a\u5668\u9057\u5fd8\u6280\u672f\u9ad8\u6548\u4f30\u8ba1\u6570\u636e\u4ef7\u503c\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u5220\u9664\u76ee\u6807\u6570\u636e\u5e76\u6d4b\u91cf\u53ef\u8fbe\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6027\u80fd\u53d8\u5316\u6765\u8ba1\u7b97Shapley\u503c\uff0c\u907f\u514d\u4e86\u91cd\u65b0\u8bad\u7ec3\u5e76\u6d88\u9664\u4e86\u5bf9\u5b8c\u6574\u6570\u636e\u7684\u4f9d\u8d56\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u5f00\u9500\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u5927\u578b\u6a21\u578b\u7684\u666e\u53ca\uff0c\u91cf\u5316\u5355\u4e2a\u6570\u636e\u63d0\u4f9b\u8005\u8d21\u732e\u7684\u9700\u6c42\u53d8\u5f97\u66f4\u52a0\u8feb\u5207\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u65b9\u6cd5\u5982\u57fa\u4e8e\u535a\u5f08\u8bba\u7684Shapley\u503c\u548c\u57fa\u4e8e\u5f71\u54cd\u51fd\u6570\u7684\u6280\u672f\u9762\u4e34\u9ad8\u6602\u7684\u8ba1\u7b97\u6210\u672c\u6216\u9700\u8981\u8bbf\u95ee\u5b8c\u6574\u7684\u6570\u636e\u548c\u6a21\u578b\u8bad\u7ec3\u7ec6\u8282\u7684\u95ee\u9898\uff0c\u96be\u4ee5\u5b9e\u73b0\u90e8\u5206\u6570\u636e\u4f30\u503c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6Unlearning Shapley\uff0c\u5b83\u5229\u7528\u673a\u5668\u9057\u5fd8\u6280\u672f\u6765\u9ad8\u6548\u4f30\u8ba1\u6570\u636e\u4ef7\u503c\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u5220\u9664\u76ee\u6807\u6570\u636e\u5e76\u6d4b\u91cf\u53ef\u8fbe\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6027\u80fd\u53d8\u5316\u6765\u8ba1\u7b97Shapley\u503c\uff0c\u907f\u514d\u4e86\u91cd\u65b0\u8bad\u7ec3\u5e76\u6d88\u9664\u4e86\u5bf9\u5b8c\u6574\u6570\u636e\u7684\u4f9d\u8d56\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u57fa\u51c6\u6570\u636e\u96c6\u548c\u5927\u89c4\u6a21\u6587\u672c\u8bed\u6599\u5e93\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5176\u51c6\u786e\u6027\u4e0e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u76f8\u5f53\uff0c\u4f46\u8ba1\u7b97\u5f00\u9500\u51cf\u5c11\u4e86\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002\u8fdb\u4e00\u6b65\u7684\u5206\u6790\u8bc1\u5b9e\u4e86\u4f30\u8ba1\u503c\u4e0e\u6570\u636e\u5b50\u96c6\u771f\u5b9e\u5f71\u54cd\u4e4b\u95f4\u7684\u5f3a\u76f8\u5173\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f25\u5408\u4e86\u6570\u636e\u4f30\u503c\u7406\u8bba\u4e0e\u5b9e\u9645\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u73b0\u4ee3AI\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u7b26\u5408\u9690\u79c1\u4fdd\u62a4\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.16077", "pdf": "https://arxiv.org/pdf/2505.16077", "abs": "https://arxiv.org/abs/2505.16077", "authors": ["Soham Gadgil", "Chris Lin", "Su-In Lee"], "title": "Ensembling Sparse Autoencoders", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Sparse autoencoders (SAEs) are used to decompose neural network activations\ninto human-interpretable features. Typically, features learned by a single SAE\nare used for downstream applications. However, it has recently been shown that\nSAEs trained with different initial weights can learn different features,\ndemonstrating that a single SAE captures only a limited subset of features that\ncan be extracted from the activation space. Motivated by this limitation, we\npropose to ensemble multiple SAEs through naive bagging and boosting.\nSpecifically, SAEs trained with different weight initializations are ensembled\nin naive bagging, whereas SAEs sequentially trained to minimize the residual\nerror are ensembled in boosting. We evaluate our ensemble approaches with three\nsettings of language models and SAE architectures. Our empirical results\ndemonstrate that ensembling SAEs can improve the reconstruction of language\nmodel activations, diversity of features, and SAE stability. Furthermore,\nensembling SAEs performs better than applying a single SAE on downstream tasks\nsuch as concept detection and spurious correlation removal, showing improved\npractical utility.", "AI": {"tldr": "This paper proposes methods to ensemble multiple sparse autoencoders (SAEs) through naive bagging and boosting to improve the reconstruction of language model activations, feature diversity, and SAE stability, which also performs better than a single SAE on downstream tasks.", "motivation": "A single SAE captures only a limited subset of features that can be extracted from the activation space, so the authors want to overcome this limitation by ensembling multiple SAEs.", "method": "The authors propose to ensemble multiple SAEs through naive bagging and boosting. In naive bagging, SAEs trained with different weight initializations are ensembled. In boosting, SAEs sequentially trained to minimize the residual error are ensembled.", "result": "Ensembling SAEs improves the reconstruction of language model activations, diversity of features, and SAE stability. It also performs better than a single SAE on downstream tasks such as concept detection and spurious correlation removal.", "conclusion": "Ensembling multiple SAEs can enhance practical utility and performance on various tasks."}}
{"id": "2505.16176", "pdf": "https://arxiv.org/pdf/2505.16176", "abs": "https://arxiv.org/abs/2505.16176", "authors": ["Jun Rao", "Xuebo Liu", "Hexuan Deng", "Zepeng Lin", "Zixiong Yu", "Jiansheng Wei", "Xiaojun Meng", "Min Zhang"], "title": "Dynamic Sampling that Adapts: Iterative DPO for Self-Aware Mathematical Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "In the realm of data selection for reasoning tasks, existing approaches\npredominantly rely on externally predefined static metrics such as difficulty\nand diversity, which are often designed for supervised fine-tuning (SFT) and\nlack adaptability to continuous training processes. A critical limitation of\nthese methods is their inability to dynamically align with the evolving\ncapabilities of models during online training, a gap that becomes increasingly\npronounced with the rise of dynamic training paradigms and online reinforcement\nlearning (RL) frameworks (e.g., R1 models). To address this, we introduce\nSAI-DPO, an algorithm that dynamically selects training data by continuously\nassessing a model's stage-specific reasoning abilities across different\ntraining phases. By integrating real-time model performance feedback, SAI-DPO\nadaptively adapts data selection to the evolving strengths and weaknesses of\nthe model, thus enhancing both data utilization efficiency and final task\nperformance. Extensive experiments on three state-of-the-art models and eight\nmathematical reasoning benchmarks, including challenging competition-level\ndatasets (e.g., AIME24 and AMC23), demonstrate that SAI-DPO achieves an average\nperformance boost of up to 21.3 percentage points, with particularly notable\nimprovements of 10 and 15 points on AIME24 and AMC23, respectively. These\nresults highlight the superiority of dynamic, model-adaptive data selection\nover static, externally defined strategies in advancing reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSAI-DPO\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8bc4\u4f30\u6a21\u578b\u5728\u4e0d\u540c\u8bad\u7ec3\u9636\u6bb5\u7684\u63a8\u7406\u80fd\u529b\u6765\u9009\u62e9\u8bad\u7ec3\u6570\u636e\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u6839\u636e\u6a21\u578b\u5b9e\u65f6\u6027\u80fd\u53cd\u9988\u8c03\u6574\u6570\u636e\u9009\u62e9\uff0c\u4ece\u800c\u63d0\u9ad8\u6570\u636e\u5229\u7528\u6548\u7387\u548c\u4efb\u52a1\u8868\u73b0\u3002\u5b9e\u9a8c\u663e\u793aSAI-DPO\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5e26\u6765\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u9884\u5148\u5b9a\u4e49\u7684\u9759\u6001\u6307\u6807\uff0c\u7f3a\u4e4f\u9002\u5e94\u8fde\u7eed\u8bad\u7ec3\u8fc7\u7a0b\u7684\u80fd\u529b\uff0c\u5c24\u5176\u5728\u52a8\u6001\u8bad\u7ec3\u8303\u5f0f\u548c\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e0b\u8868\u73b0\u4e0d\u8db3\u3002", "method": "\u5f15\u5165SAI-DPO\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u5b9e\u65f6\u8bc4\u4f30\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5728\u4e0d\u540c\u8bad\u7ec3\u9636\u6bb5\u52a8\u6001\u8c03\u6574\u6570\u636e\u9009\u62e9\u3002", "result": "SAI-DPO\u5728\u4e09\u4e2a\u6700\u5148\u8fdb\u7684\u6a21\u578b\u548c\u516b\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728AIME24\u548cAMC23\u6570\u636e\u96c6\u4e0a\u5206\u522b\u63d0\u5347\u4e8610\u548c15\u4e2a\u767e\u5206\u70b9\uff0c\u5e73\u5747\u63d0\u534721.3\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u52a8\u6001\u3001\u6a21\u578b\u81ea\u9002\u5e94\u7684\u6570\u636e\u9009\u62e9\u4f18\u4e8e\u9759\u6001\u3001\u5916\u90e8\u5b9a\u4e49\u7684\u7b56\u7565\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u63a8\u7406\u4efb\u52a1\u7684\u53d1\u5c55\u3002"}}
{"id": "2505.16204", "pdf": "https://arxiv.org/pdf/2505.16204", "abs": "https://arxiv.org/abs/2505.16204", "authors": ["Ichiro Hashimoto"], "title": "Directional Convergence, Benign Overfitting of Gradient Descent in leaky ReLU two-layer Neural Networks", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH", "68T07 (primary)"], "comment": "34 pages", "summary": "In this paper, we prove directional convergence of network parameters of\nfixed width leaky ReLU two-layer neural networks optimized by gradient descent\nwith exponential loss, which was previously only known for gradient flow. By a\ncareful analysis of the convergent direction, we establish sufficient\nconditions of benign overfitting and discover a new phase transition in the\ntest error bound. All of these results hold beyond the nearly orthogonal data\nsetting which was studied in prior works. As an application, we demonstrate\nthat benign overfitting occurs with high probability in sub-Gaussian mixture\nmodels.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u56fa\u5b9a\u5bbd\u5ea6\u7684\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u7684\u65b9\u5411\u6536\u655b\u6027\uff0c\u5e76\u53d1\u73b0\u4e86\u65b0\u7684\u6d4b\u8bd5\u8bef\u5dee\u754c\u76f8\u53d8\uff0c\u5176\u9002\u7528\u8303\u56f4\u8d85\u51fa\u4e86\u5148\u524d\u7684\u7814\u7a76\u3002", "motivation": "\u4e4b\u524d\u4ec5\u5bf9\u4e8e\u68af\u5ea6\u6d41\u5df2\u77e5\u7684\u7ed3\u679c\uff0c\u672c\u6587\u5c06\u5176\u6269\u5c55\u5230\u68af\u5ea6\u4e0b\u964d\u7684\u60c5\u51b5\u3002\u5e76\u4e14\u7814\u7a76\u8d85\u8d8a\u4e86\u5148\u524d\u5de5\u4f5c\u4e2d\u7814\u7a76\u8fc7\u7684\u8fd1\u4f3c\u6b63\u4ea4\u6570\u636e\u8bbe\u5b9a\u3002", "method": "\u5bf9\u6536\u655b\u65b9\u5411\u8fdb\u884c\u4e86\u4ed4\u7ec6\u5206\u6790\uff0c\u5efa\u7acb\u4e86\u826f\u6027\u8fc7\u62df\u5408\u7684\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u53d1\u73b0\u6d4b\u8bd5\u8bef\u5dee\u754c\u4e2d\u7684\u65b0\u76f8\u53d8\u3002", "result": "\u6240\u6709\u7ed3\u679c\u90fd\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u573a\u666f\uff0c\u5e76\u4e14\u5728\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u4e2d\u5c55\u793a\u4e86\u826f\u6027\u8fc7\u62df\u5408\u7684\u53d1\u751f\u6982\u7387\u5f88\u9ad8\u3002", "conclusion": "\u8bc1\u660e\u4e86\u56fa\u5b9a\u5bbd\u5ea6\u7684\u6cc4\u6f0fReLU\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u5728\u6307\u6570\u635f\u5931\u4e0b\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u7684\u65b9\u5411\u6536\u655b\u6027\u3002"}}
{"id": "2505.16083", "pdf": "https://arxiv.org/pdf/2505.16083", "abs": "https://arxiv.org/abs/2505.16083", "authors": ["Jiahuan Long", "Wenzhe Zhang", "Ning Wang", "Tingsong Jiang", "Wen Yao"], "title": "FR-Mamba: Time-Series Physical Field Reconstruction Based on State Space Model", "categories": ["cs.LG"], "comment": null, "summary": "Physical field reconstruction (PFR) aims to predict the state distribution of\nphysical quantities (e.g., velocity, pressure, and temperature) based on\nlimited sensor measurements. It plays a critical role in domains such as fluid\ndynamics and thermodynamics. However, existing deep learning methods often fail\nto capture long-range temporal dependencies, resulting in suboptimal\nperformance on time-evolving physical systems. To address this, we propose\nFR-Mamba, a novel spatiotemporal flow field reconstruction framework based on\nstate space modeling. Specifically, we design a hybrid neural network\narchitecture that combines Fourier Neural Operator (FNO) and State Space Model\n(SSM) to capture both global spatial features and long-range temporal\ndependencies. We adopt Mamba, a recently proposed efficient SSM architecture,\nto model long-range temporal dependencies with linear time complexity. In\nparallel, the FNO is employed to capture non-local spatial features by\nleveraging frequency-domain transformations. The spatiotemporal representations\nextracted by these two components are then fused to reconstruct the full-field\ndistribution of the physical system. Extensive experiments demonstrate that our\napproach significantly outperforms existing PFR methods in flow field\nreconstruction tasks, achieving high-accuracy performance on long sequences.", "AI": {"tldr": "This paper introduces FR-Mamba, a new method for reconstructing physical field states using a hybrid neural network combining Fourier Neural Operator and State Space Model to improve long-range temporal dependency handling.", "motivation": "Existing deep learning methods often fail to capture long-range temporal dependencies in time-evolving physical systems like those in fluid dynamics and thermodynamics.", "method": "Proposes FR-Mamba which uses a combination of Fourier Neural Operator (for spatial features) and Mamba (a State Space Model for temporal dependencies) to reconstruct physical field states.", "result": "The approach shows superior performance in reconstructing flow fields, particularly on long sequences, compared to other Physical Field Reconstruction methods.", "conclusion": "FR-Mamba effectively captures both global spatial features and long-range temporal dependencies, leading to improved accuracy in physical field reconstructions."}}
{"id": "2505.16186", "pdf": "https://arxiv.org/pdf/2505.16186", "abs": "https://arxiv.org/abs/2505.16186", "authors": ["Kaiwen Zhou", "Xuandong Zhao", "Gaowen Liu", "Jayanth Srinivasa", "Aosong Feng", "Dawn Song", "Xin Eric Wang"], "title": "SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning", "categories": ["cs.AI", "cs.CL", "cs.CR"], "comment": null, "summary": "Large Reasoning Models (LRMs) introduce a new generation paradigm of\nexplicitly reasoning before answering, leading to remarkable improvements in\ncomplex tasks. However, they pose great safety risks against harmful queries\nand adversarial attacks. While recent mainstream safety efforts on LRMs,\nsupervised fine-tuning (SFT), improve safety performance, we find that\nSFT-aligned models struggle to generalize to unseen jailbreak prompts. After\nthorough investigation of LRMs' generation, we identify a safety aha moment\nthat can activate safety reasoning and lead to a safe response. This aha moment\ntypically appears in the `key sentence', which follows models' query\nunderstanding process and can indicate whether the model will proceed safely.\nBased on these insights, we propose SafeKey, including two complementary\nobjectives to better activate the safety aha moment in the key sentence: (1) a\nDual-Path Safety Head to enhance the safety signal in the model's internal\nrepresentations before the key sentence, and (2) a Query-Mask Modeling\nobjective to improve the models' attention on its query understanding, which\nhas important safety hints. Experiments across multiple safety benchmarks\ndemonstrate that our methods significantly improve safety generalization to a\nwide range of jailbreak attacks and out-of-distribution harmful prompts,\nlowering the average harmfulness rate by 9.6\\%, while maintaining general\nabilities. Our analysis reveals how SafeKey enhances safety by reshaping\ninternal attention and improving the quality of hidden representations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SafeKey\u65b9\u6cd5\u4ee5\u589e\u5f3a\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u7279\u522b\u662f\u5728\u5e94\u5bf9\u672a\u89c1\u8fc7\u7684\u8d8a\u72f1\u63d0\u793a\u65f6\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u867d\u7136\u76d1\u7763\u5fae\u8c03(SFT)\u6539\u5584\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b(LRMs)\u7684\u5b89\u5168\u6027\u80fd\uff0c\u4f46SFT\u5bf9\u9f50\u7684\u6a21\u578b\u5728\u672a\u89c1\u8fc7\u7684\u8d8a\u72f1\u63d0\u793a\u4e0a\u6cdb\u5316\u80fd\u529b\u8f83\u5f31\u3002", "method": "\u63d0\u51faSafeKey\u65b9\u6cd5\uff0c\u5305\u62ec\u4e24\u4e2a\u4e92\u8865\u7684\u76ee\u6807\uff1a(1) Dual-Path Safety Head \u548c (2) Query-Mask Modeling objective\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSafeKey\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5b89\u5168\u6cdb\u5316\u80fd\u529b\uff0c\u964d\u4f4e\u4e86\u6709\u5bb3\u7387\uff0c\u5e76\u4e14\u901a\u8fc7\u5206\u6790\u63ed\u793a\u4e86SafeKey\u5982\u4f55\u901a\u8fc7\u91cd\u5851\u5185\u90e8\u6ce8\u610f\u529b\u548c\u63d0\u9ad8\u9690\u85cf\u8868\u793a\u7684\u8d28\u91cf\u6765\u589e\u5f3a\u5b89\u5168\u6027\u3002", "conclusion": "SafeKey\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u5bf9\u591a\u79cd\u8d8a\u72f1\u653b\u51fb\u548c\u5206\u5e03\u5916\u6709\u5bb3\u63d0\u793a\u7684\u5b89\u5168\u6cdb\u5316\u80fd\u529b\uff0c\u964d\u4f4e\u4e86\u5e73\u5747\u6709\u5bb3\u73879.6%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u4e00\u822c\u80fd\u529b\u3002"}}
{"id": "2505.16363", "pdf": "https://arxiv.org/pdf/2505.16363", "abs": "https://arxiv.org/abs/2505.16363", "authors": ["Huishuai Zhang", "Bohan Wang", "Luoxin Chen"], "title": "AdamS: Momentum Itself Can Be A Normalizer for LLM Pretraining and Post-training", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We introduce AdamS, a simple yet effective alternative to Adam for large\nlanguage model (LLM) pretraining and post-training. By leveraging a novel\ndenominator, i.e., the root of weighted sum of squares of the momentum and the\ncurrent gradient, AdamS eliminates the need for second-moment estimates. Hence,\nAdamS is efficient, matching the memory and compute footprint of SGD with\nmomentum while delivering superior optimization performance. Moreover, AdamS is\neasy to adopt: it can directly inherit hyperparameters of AdamW, and is\nentirely model-agnostic, integrating seamlessly into existing pipelines without\nmodifications to optimizer APIs or architectures. The motivation behind AdamS\nstems from the observed $(L_0, L_1)$ smoothness properties in transformer\nobjectives, where local smoothness is governed by gradient magnitudes that can\nbe further approximated by momentum magnitudes. We establish rigorous\ntheoretical convergence guarantees and provide practical guidelines for\nhyperparameter selection. Empirically, AdamS demonstrates strong performance in\nvarious tasks, including pre-training runs on GPT-2 and Llama2 (up to 13B\nparameters) and reinforcement learning in post-training regimes. With its\nefficiency, simplicity, and theoretical grounding, AdamS stands as a compelling\nalternative to existing optimizers.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAdamS\u7684\u65b0\u4f18\u5316\u5668\uff0c\u5b83\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684Adam\u66ff\u4ee3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u548c\u540e\u8bad\u7ec3\u3002AdamS\u901a\u8fc7\u5229\u7528\u65b0\u7684\u5206\u6bcd\uff08\u52a8\u91cf\u4e0e\u5f53\u524d\u68af\u5ea6\u5e73\u65b9\u7684\u52a0\u6743\u548c\u7684\u5e73\u65b9\u6839\uff09\u6d88\u9664\u4e86\u5bf9\u4e8c\u9636\u77e9\u4f30\u8ba1\u7684\u9700\u6c42\uff0c\u6548\u7387\u9ad8\u4e14\u6613\u4e8e\u91c7\u7528\u3002", "motivation": "\u89c2\u5bdf\u5230Transformer\u76ee\u6807\u51fd\u6570\u4e2d\u7684(L0, L1)\u5e73\u6ed1\u6027\u7279\u6027\uff0c\u5176\u4e2d\u5c40\u90e8\u5e73\u6ed1\u6027\u7531\u68af\u5ea6\u5927\u5c0f\u63a7\u5236\uff0c\u68af\u5ea6\u5927\u5c0f\u53ef\u4ee5\u8fdb\u4e00\u6b65\u8fd1\u4f3c\u4e3a\u52a8\u91cf\u5927\u5c0f\u3002", "method": "\u5f15\u5165AdamS\u4f18\u5316\u5668\uff0c\u5b83\u4f7f\u7528\u52a8\u91cf\u4e0e\u5f53\u524d\u68af\u5ea6\u5e73\u65b9\u7684\u52a0\u6743\u548c\u7684\u5e73\u65b9\u6839\u4f5c\u4e3a\u5206\u6bcd\uff0c\u65e0\u9700\u4e8c\u9636\u77e9\u4f30\u8ba1\u3002", "result": "AdamS\u5728\u5404\u79cd\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5305\u62ecGPT-2\u548cLlama2\u7684\u9884\u8bad\u7ec3\uff08\u9ad8\u8fbe13B\u53c2\u6570\uff09\u4ee5\u53ca\u540e\u8bad\u7ec3\u4e2d\u7684\u5f3a\u5316\u5b66\u4e60\u3002", "conclusion": "AdamS\u56e0\u5176\u6548\u7387\u3001\u7b80\u5355\u6027\u548c\u7406\u8bba\u57fa\u7840\uff0c\u6210\u4e3a\u73b0\u6709\u4f18\u5316\u5668\u7684\u4e00\u4e2a\u6709\u5438\u5f15\u529b\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2505.16094", "pdf": "https://arxiv.org/pdf/2505.16094", "abs": "https://arxiv.org/abs/2505.16094", "authors": ["Ziqing Wang", "Kexin Zhang", "Zihan Zhao", "Yibo Wen", "Abhishek Pandey", "Han Liu", "Kaize Ding"], "title": "A Survey of Large Language Models for Text-Guided Molecular Discovery: from Molecule Generation to Optimization", "categories": ["cs.LG", "cs.CL"], "comment": "Under review", "summary": "Large language models (LLMs) are introducing a paradigm shift in molecular\ndiscovery by enabling text-guided interaction with chemical spaces through\nnatural language, symbolic notations, with emerging extensions to incorporate\nmulti-modal inputs. To advance the new field of LLM for molecular discovery,\nthis survey provides an up-to-date and forward-looking review of the emerging\nuse of LLMs for two central tasks: molecule generation and molecule\noptimization. Based on our proposed taxonomy for both problems, we analyze\nrepresentative techniques in each category, highlighting how LLM capabilities\nare leveraged across different learning settings. In addition, we include the\ncommonly used datasets and evaluation protocols. We conclude by discussing key\nchallenges and future directions, positioning this survey as a resource for\nresearchers working at the intersection of LLMs and molecular science. A\ncontinuously updated reading list is available at\nhttps://github.com/REAL-Lab-NU/Awesome-LLM-Centric-Molecular-Discovery.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u63d0\u4f9b\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5206\u5b50\u53d1\u73b0\u4e2d\u7684\u65b0\u5174\u5e94\u7528\u7684\u6700\u65b0\u4e14\u524d\u77bb\u6027\u7684\u56de\u987e\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u5206\u5b50\u751f\u6210\u548c\u4f18\u5316\u4e24\u5927\u4efb\u52a1\u3002\u901a\u8fc7\u63d0\u51fa\u7684\u95ee\u9898\u5206\u7c7b\uff0c\u5206\u6790\u4e86\u6bcf\u79cd\u7c7b\u522b\u4e2d\u7684\u4ee3\u8868\u6027\u6280\u672f\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u4e0d\u540c\u5b66\u4e60\u8bbe\u7f6e\u4e0b\u5982\u4f55\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u3002\u6b64\u5916\uff0c\u8fd8\u5305\u542b\u4e86\u5e38\u7528\u7684\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u534f\u8bae\u3002\u6700\u540e\u8ba8\u8bba\u4e86\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u63a8\u52a8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5206\u5b50\u53d1\u73b0\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u57fa\u4e8e\u63d0\u51fa\u7684\u5206\u7c7b\u5bf9\u4ee3\u8868\u6027\u6280\u672f\u8fdb\u884c\u5206\u6790\u3002", "result": "\u63d0\u4f9b\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5206\u5b50\u751f\u6210\u548c\u4f18\u5316\u65b9\u9762\u7684\u5e94\u7528\u56de\u987e\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\uff0c\u4e3a\u4ece\u4e8b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u5206\u5b50\u79d1\u5b66\u4ea4\u53c9\u9886\u57df\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u8d44\u6e90\u3002"}}
{"id": "2505.16199", "pdf": "https://arxiv.org/pdf/2505.16199", "abs": "https://arxiv.org/abs/2505.16199", "authors": ["Rikuhei Umemoto", "Keisuke Fujii"], "title": "Velocity Completion Task and Method for Event-based Player Positional Data in Soccer", "categories": ["cs.AI"], "comment": "24 pages, 7 figures", "summary": "In many real-world complex systems, the behavior can be observed as a\ncollection of discrete events generated by multiple interacting agents.\nAnalyzing the dynamics of these multi-agent systems, especially team sports,\noften relies on understanding the movement and interactions of individual\nagents. However, while providing valuable snapshots, event-based positional\ndata typically lacks the continuous temporal information needed to directly\ncalculate crucial properties such as velocity. This absence severely limits the\ndepth of dynamic analysis, preventing a comprehensive understanding of\nindividual agent behaviors and emergent team strategies. To address this\nchallenge, we propose a new method to simultaneously complete the velocity of\nall agents using only the event-based positional data from team sports. Based\non this completed velocity information, we investigate the applicability of\nexisting team sports analysis and evaluation methods. Experiments using soccer\nevent data demonstrate that neural network-based approaches outperformed\nrule-based methods regarding velocity completion error, considering the\nunderlying temporal dependencies and graph structure of player-to-player or\nplayer-to-ball interaction. Moreover, the space evaluation results obtained\nusing the completed velocity are closer to those derived from complete tracking\ndata, highlighting our method's potential for enhanced team sports system\nanalysis.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u4e8b\u4ef6\u9a71\u52a8\u7684\u4f4d\u7f6e\u6570\u636e\u540c\u65f6\u5b8c\u6210\u6240\u6709\u8fd0\u52a8\u5458\u7684\u901f\u5ea6\u4f30\u8ba1\uff0c\u5e76\u9a8c\u8bc1\u4e86\u795e\u7ecf\u7f51\u7edc\u5728\u901f\u5ea6\u8865\u5168\u4efb\u52a1\u4e0a\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4e8b\u4ef6\u7684\u4f4d\u7f6e\u6570\u636e\u7f3a\u4e4f\u8fde\u7eed\u7684\u65f6\u95f4\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u5bf9\u4e2a\u4f53\u884c\u4e3a\u548c\u56e2\u961f\u7b56\u7565\u7684\u6df1\u5165\u52a8\u6001\u5206\u6790\u3002", "method": "\u63d0\u51fa\u7684\u65b0\u65b9\u6cd5\u57fa\u4e8e\u4e8b\u4ef6\u9a71\u52a8\u7684\u4f4d\u7f6e\u6570\u636e\u6765\u5b8c\u6210\u901f\u5ea6\u4f30\u8ba1\uff0c\u5e76\u7814\u7a76\u5176\u5728\u56e2\u961f\u8fd0\u52a8\u5206\u6790\u4e2d\u7684\u9002\u7528\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\u5728\u901f\u5ea6\u8865\u5168\u8bef\u5dee\u4e0a\u4f18\u4e8e\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u4f7f\u7528\u5b8c\u6210\u7684\u901f\u5ea6\u8bc4\u4f30\u7a7a\u95f4\u7684\u7ed3\u679c\u66f4\u63a5\u8fd1\u4e8e\u5b8c\u6574\u7684\u8ddf\u8e2a\u6570\u636e\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u589e\u5f3a\u56e2\u961f\u8fd0\u52a8\u7cfb\u7edf\u7684\u52a8\u6001\u5206\u6790\u80fd\u529b\u3002"}}
{"id": "2505.16481", "pdf": "https://arxiv.org/pdf/2505.16481", "abs": "https://arxiv.org/abs/2505.16481", "authors": ["Xinxing Shi", "Xiaoyu Jiang", "Mauricio A. \u00c1lvarez"], "title": "Neighbour-Driven Gaussian Process Variational Autoencoders for Scalable Structured Latent Modelling", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Gaussian Process (GP) Variational Autoencoders (VAEs) extend standard VAEs by\nreplacing the fully factorised Gaussian prior with a GP prior, thereby\ncapturing richer correlations among latent variables. However, performing exact\nGP inference in large-scale GPVAEs is computationally prohibitive, often\nforcing existing approaches to rely on restrictive kernel assumptions or large\nsets of inducing points. In this work, we propose a neighbour-driven\napproximation strategy that exploits local adjacencies in the latent space to\nachieve scalable GPVAE inference. By confining computations to the nearest\nneighbours of each data point, our method preserves essential latent\ndependencies, allowing more flexible kernel choices and mitigating the need for\nnumerous inducing points. Through extensive experiments on tasks including\nrepresentation learning, data imputation, and conditional generation, we\ndemonstrate that our approach outperforms other GPVAE variants in both\npredictive performance and computational efficiency.", "AI": {"tldr": "This work introduces a scalable Gaussian Process Variational Autoencoder (GPVAE) by using a neighbor-driven approximation strategy that reduces computation while maintaining performance.", "motivation": "Standard GPVAEs cannot handle large-scale data due to computational limitations.", "method": "A neighbor-driven approximation strategy that limits computations to nearest neighbors in the latent space.", "result": "The proposed method improves predictive performance and computational efficiency compared to other GPVAE variants.", "conclusion": "The neighbor-driven approximation strategy allows more flexible kernel choices and fewer inducing points, making GPVAEs more practical for large-scale data."}}
{"id": "2505.16099", "pdf": "https://arxiv.org/pdf/2505.16099", "abs": "https://arxiv.org/abs/2505.16099", "authors": ["Ziyi", "Zhou", "Nicholas Stern", "Julien Laasri"], "title": "Reinforcement Learning for Stock Transactions", "categories": ["cs.LG", "68T05", "I.2.6"], "comment": "14 pages, 6 figures, paper dated December 19, 2018", "summary": "Much research has been done to analyze the stock market. After all, if one\ncan determine a pattern in the chaotic frenzy of transactions, then they could\nmake a hefty profit from capitalizing on these insights. As such, the goal of\nour project was to apply reinforcement learning (RL) to determine the best time\nto buy a stock within a given time frame. With only a few adjustments, our\nmodel can be extended to identify the best time to sell a stock as well. In\norder to use the format of free, real-world data to train the model, we define\nour own Markov Decision Process (MDP) problem. These two papers [5] [6] helped\nus in formulating the state space and the reward system of our MDP problem. We\ntrain a series of agents using Q-Learning, Q-Learning with linear function\napproximation, and deep Q-Learning. In addition, we try to predict the stock\nprices using machine learning regression and classification models. We then\ncompare our agents to see if they converge on a policy, and if so, which one\nlearned the best policy to maximize profit on the stock market.", "AI": {"tldr": "This paper applies reinforcement learning methods including Q-Learning and deep Q-Learning to determine optimal buying times for stocks based on a defined Markov Decision Process problem.", "motivation": "To make profit by identifying patterns in stock market transactions using reinforcement learning.", "method": "Defining a custom Markov Decision Process problem and training agents using various Q-Learning techniques as well as machine learning models for stock price prediction.", "result": "Agents trained with different reinforcement learning methods converge on policies, and their performances are compared to find the best strategy for maximizing profit.", "conclusion": "Reinforcement learning can effectively determine optimal times to buy stocks, and the approach can potentially be extended to selling decisions."}}
{"id": "2505.16221", "pdf": "https://arxiv.org/pdf/2505.16221", "abs": "https://arxiv.org/abs/2505.16221", "authors": ["Yifan Zhang", "Xinkui Zhao", "Zuxin Wang", "Guanjie Cheng", "Yueshen Xu", "Shuiguang Deng", "Jianwei Yin"], "title": "LightRouter: Towards Efficient LLM Collaboration with Minimal Overhead", "categories": ["cs.AI"], "comment": null, "summary": "The rapid advancement of large language models has unlocked remarkable\ncapabilities across a diverse array of natural language processing tasks.\nHowever, the considerable differences among available LLMs-in terms of cost,\nperformance, and computational demands-pose significant challenges for users\naiming to identify the most suitable model for specific tasks. In this work, we\npresent LightRouter, a novel framework designed to systematically select and\nintegrate a small subset of LLMs from a larger pool, with the objective of\njointly optimizing both task performance and cost efficiency. LightRouter\nleverages an adaptive selection mechanism to identify models that require only\na minimal number of boot tokens, thereby reducing costs, and further employs an\neffective integration strategy to combine their outputs. Extensive experiments\nacross multiple benchmarks demonstrate that LightRouter matches or outperforms\nwidely-used ensemble baselines, achieving up to a 25% improvement in accuracy.\nCompared with leading high-performing models, LightRouter achieves comparable\nperformance while reducing inference costs by up to 27%. Importantly, our\nframework operates without any prior knowledge of individual models and relies\nexclusively on inexpensive, lightweight models. This work introduces a\npractical approach for efficient LLM selection and provides valuable insights\ninto optimal strategies for model combination.", "AI": {"tldr": "LightRouter\u662f\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6c60\u4e2d\u9009\u62e9\u548c\u96c6\u6210\u5c0f\u90e8\u5206\u6a21\u578b\uff0c\u4ee5\u4f18\u5316\u4efb\u52a1\u6027\u80fd\u548c\u6210\u672c\u6548\u7387\u3002\u5b83\u901a\u8fc7\u51cf\u5c11\u542f\u52a8\u4ee4\u724c\u6570\u91cf\u964d\u4f4e\u6210\u672c\uff0c\u5e76\u7ed3\u5408\u8f93\u51fa\u63d0\u9ad8\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6210\u672c\u3001\u6027\u80fd\u548c\u8ba1\u7b97\u9700\u6c42\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u7528\u6237\u96be\u4ee5\u627e\u5230\u9002\u5408\u7279\u5b9a\u4efb\u52a1\u7684\u6700\u4f73\u6a21\u578b\u3002", "method": "\u63d0\u51faLightRouter\u6846\u67b6\uff0c\u5229\u7528\u81ea\u9002\u5e94\u9009\u62e9\u673a\u5236\u51cf\u5c11\u542f\u52a8\u4ee4\u724c\u6570\u91cf\u5e76\u964d\u4f4e\u8d39\u7528\uff0c\u540c\u65f6\u91c7\u7528\u6709\u6548\u6574\u5408\u7b56\u7565\u6765\u7ec4\u5408\u6a21\u578b\u8f93\u51fa\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLightRouter\u7684\u8868\u73b0\u4f18\u4e8e\u5e7f\u6cdb\u4f7f\u7528\u7684\u96c6\u6210\u57fa\u7ebf\uff0c\u63d0\u5347\u4e86\u6700\u591a25%\u7684\u51c6\u786e\u6027\uff1b\u4e0e\u9ad8\u6027\u80fd\u6a21\u578b\u76f8\u6bd4\uff0c\u5b83\u5728\u4fdd\u6301\u76f8\u4f3c\u6027\u80fd\u7684\u540c\u65f6\u51cf\u5c11\u4e86\u9ad8\u8fbe27%\u7684\u63a8\u7406\u6210\u672c\u3002", "conclusion": "\u6b64\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9009\u62e9\u7684\u5b9e\u9645\u65b9\u6cd5\uff0c\u5e76\u5bf9\u6a21\u578b\u7ec4\u5408\u7684\u6700\u4f73\u7b56\u7565\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2505.16548", "pdf": "https://arxiv.org/pdf/2505.16548", "abs": "https://arxiv.org/abs/2505.16548", "authors": ["Lucas Maystre", "Gabriel Barello", "Tudor Berariu", "Aleix Cambray", "Rares Dolga", "Alvaro Ortega Gonzalez", "Andrei Nica", "David Barber"], "title": "Incremental Sequence Classification with Temporal Consistency", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We address the problem of incremental sequence classification, where\npredictions are updated as new elements in the sequence are revealed. Drawing\non temporal-difference learning from reinforcement learning, we identify a\ntemporal-consistency condition that successive predictions should satisfy. We\nleverage this condition to develop a novel loss function for training\nincremental sequence classifiers. Through a concrete example, we demonstrate\nthat optimizing this loss can offer substantial gains in data efficiency. We\napply our method to text classification tasks and show that it improves\npredictive accuracy over competing approaches on several benchmark datasets. We\nfurther evaluate our approach on the task of verifying large language model\ngenerations for correctness in grade-school math problems. Our results show\nthat models trained with our method are better able to distinguish promising\ngenerations from unpromising ones after observing only a few tokens.", "AI": {"tldr": "This paper introduces a new method for incremental sequence classification using a novel loss function derived from a temporal-consistency condition. The method is shown to improve data efficiency and predictive accuracy in text classification and verifying large language model generations.", "motivation": "To improve the efficiency and accuracy of incremental sequence classification by leveraging temporal-difference learning.", "method": "Developing a novel loss function based on a temporal-consistency condition and applying it to text classification and verifying large language model generations.", "result": "The method shows substantial gains in data efficiency and improves predictive accuracy over competing approaches on several benchmark datasets.", "conclusion": "The proposed method can effectively distinguish promising generations from unpromising ones after observing only a few tokens, demonstrating its potential in various applications."}}
{"id": "2505.16103", "pdf": "https://arxiv.org/pdf/2505.16103", "abs": "https://arxiv.org/abs/2505.16103", "authors": ["Monirul Islam Mahmud"], "title": "Towards Trustworthy Keylogger detection: A Comprehensive Analysis of Ensemble Techniques and Feature Selections through Explainable AI", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Keylogger detection involves monitoring for unusual system behaviors such as\ndelays between typing and character display, analyzing network traffic patterns\nfor data exfiltration. In this study, we provide a comprehensive analysis for\nkeylogger detection with traditional machine learning models - SVC, Random\nForest, Decision Tree, XGBoost, AdaBoost, Logistic Regression and Naive Bayes\nand advanced ensemble methods including Stacking, Blending and Voting.\nMoreover, feature selection approaches such as Information gain, Lasso L1 and\nFisher Score are thoroughly assessed to improve predictive performance and\nlower computational complexity. The Keylogger Detection dataset from publicly\navailable Kaggle website is used in this project. In addition to accuracy-based\nclassification, this study implements the approach for model interpretation\nusing Explainable AI (XAI) techniques namely SHAP (Global) and LIME (Local) to\ndeliver finer explanations for how much each feature contributes in assisting\nor hindering the detection process. To evaluate the models result, we have used\nAUC score, sensitivity, Specificity, Accuracy and F1 score. The best\nperformance was achieved by AdaBoost with 99.76% accuracy, F1 score of 0.99,\n100% precision, 98.6% recall, 1.0 specificity and 0.99 of AUC that is\nnear-perfect classification with Fisher Score.", "AI": {"tldr": "This study explores keylogger detection using various machine learning models and feature selection methods, achieving high accuracy mainly through AdaBoost with Fisher Score.", "motivation": "To provide a comprehensive analysis for keylogger detection with traditional and advanced machine learning models and assess feature selection approaches to enhance predictive performance.", "method": "Using traditional models (SVC, Random Forest, etc.), ensemble methods, and feature selection approaches (Information gain, Lasso L1, Fisher Score). Implementing XAI techniques for model interpretation.", "result": "Achieved best performance with AdaBoost: 99.76% accuracy, 0.99 F1 score, 100% precision, 98.6% recall, 1.0 specificity, and 0.99 AUC.", "conclusion": "The study successfully identifies keyloggers with near-perfect classification using AdaBoost combined with Fisher Score."}}
{"id": "2505.16223", "pdf": "https://arxiv.org/pdf/2505.16223", "abs": "https://arxiv.org/abs/2505.16223", "authors": ["Sangyong Lee", "Subo Hwang", "Dohoon Kim"], "title": "MADCluster: Model-agnostic Anomaly Detection with Self-supervised Clustering Network", "categories": ["cs.AI", "cs.LG"], "comment": "24 pages, 9 figures", "summary": "In this paper, we propose MADCluster, a novel model-agnostic anomaly\ndetection framework utilizing self-supervised clustering. MADCluster is\napplicable to various deep learning architectures and addresses the\n'hypersphere collapse' problem inherent in existing deep learning-based anomaly\ndetection methods. The core idea is to cluster normal pattern data into a\n'single cluster' while simultaneously learning the cluster center and mapping\ndata close to this center. Also, to improve expressiveness and enable effective\nsingle clustering, we propose a new 'One-directed Adaptive loss'. The\noptimization of this loss is mathematically proven. MADCluster consists of\nthree main components: Base Embedder capturing high-dimensional temporal\ndynamics, Cluster Distance Mapping, and Sequence-wise Clustering for continuous\ncenter updates. Its model-agnostic characteristics are achieved by applying\nvarious architectures to the Base Embedder. Experiments on four time series\nbenchmark datasets demonstrate that applying MADCluster improves the overall\nperformance of comparative models. In conclusion, the compatibility of\nMADCluster shows potential for enhancing model performance across various\narchitectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMADCluster\u7684\u65b0\u6a21\u578b\u4e0d\u53ef\u77e5\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u5b83\u5229\u7528\u81ea\u76d1\u7763\u805a\u7c7b\u89e3\u51b3\u4e86\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e2d\u7684'\u8d85\u7403\u584c\u9677'\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e2d\u7684'\u8d85\u7403\u584c\u9677'\u95ee\u9898\u3002", "method": "\u5229\u7528\u81ea\u76d1\u7763\u805a\u7c7b\uff0c\u901a\u8fc7\u5f15\u5165'\u5355\u5411\u81ea\u9002\u5e94\u635f\u5931'\u548c\u4e09\u4e2a\u4e3b\u8981\u7ec4\u4ef6\uff08\u57fa\u7840\u5d4c\u5165\u5668\u3001\u805a\u7c7b\u8ddd\u79bb\u6620\u5c04\u548c\u5e8f\u5217\u805a\u7c7b\uff09\u6765\u5b9e\u73b0\u6a21\u578b\u4e0d\u53ef\u77e5\u7279\u6027\u3002", "result": "\u5728\u56db\u4e2a\u65f6\u95f4\u5e8f\u5217\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5e94\u7528MADCluster\u53ef\u4ee5\u63d0\u9ad8\u6bd4\u8f83\u6a21\u578b\u7684\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "MADCluster\u5728\u5404\u79cd\u67b6\u6784\u4e2d\u663e\u793a\u51fa\u589e\u5f3a\u6a21\u578b\u6027\u80fd\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.16638", "pdf": "https://arxiv.org/pdf/2505.16638", "abs": "https://arxiv.org/abs/2505.16638", "authors": ["Benedikt H\u00f6ltgen", "Nuria Oliver"], "title": "Reconsidering Fairness Through Unawareness from the Perspective of Model Multiplicity", "categories": ["cs.LG", "cs.CY", "stat.ML"], "comment": null, "summary": "Fairness through Unawareness (FtU) describes the idea that discrimination\nagainst demographic groups can be avoided by not considering group membership\nin the decisions or predictions. This idea has long been criticized in the\nmachine learning literature as not being sufficient to ensure fairness. In\naddition, the use of additional features is typically thought to increase the\naccuracy of the predictions for all groups, so that FtU is sometimes thought to\nbe detrimental to all groups. In this paper, we show both theoretically and\nempirically that FtU can reduce algorithmic discrimination without necessarily\nreducing accuracy. We connect this insight with the literature on Model\nMultiplicity, to which we contribute with novel theoretical and empirical\nresults. Furthermore, we illustrate how, in a real-life application, FtU can\ncontribute to the deployment of more equitable policies without losing\nefficacy. Our findings suggest that FtU is worth considering in practical\napplications, particularly in high-risk scenarios, and that the use of\nprotected attributes such as gender in predictive models should be accompanied\nby a clear and well-founded justification.", "AI": {"tldr": "This paper challenges the traditional view that fairness through unawareness (FtU) reduces model accuracy while addressing discrimination.", "motivation": "To explore whether FtU can effectively reduce algorithmic discrimination without sacrificing accuracy.", "method": "Theoretical analysis and empirical experiments.", "result": "FtU can indeed reduce discrimination without reducing accuracy, and it contributes to equitable policy deployment.", "conclusion": "FtU deserves consideration in practical applications, especially in high-risk situations, with proper justification for using protected attributes."}}
{"id": "2505.16113", "pdf": "https://arxiv.org/pdf/2505.16113", "abs": "https://arxiv.org/abs/2505.16113", "authors": ["Panagiotis Lymperopoulos", "Vasanth Sarathy"], "title": "Tools in the Loop: Quantifying Uncertainty of LLM Question Answering Systems That Use Tools", "categories": ["cs.LG", "cs.CL"], "comment": "10 pages 3 figures 3 tables", "summary": "Modern Large Language Models (LLMs) often require external tools, such as\nmachine learning classifiers or knowledge retrieval systems, to provide\naccurate answers in domains where their pre-trained knowledge is insufficient.\nThis integration of LLMs with external tools expands their utility but also\nintroduces a critical challenge: determining the trustworthiness of responses\ngenerated by the combined system. In high-stakes applications, such as medical\ndecision-making, it is essential to assess the uncertainty of both the LLM's\ngenerated text and the tool's output to ensure the reliability of the final\nresponse. However, existing uncertainty quantification methods do not account\nfor the tool-calling scenario, where both the LLM and external tool contribute\nto the overall system's uncertainty. In this work, we present a novel framework\nfor modeling tool-calling LLMs that quantifies uncertainty by jointly\nconsidering the predictive uncertainty of the LLM and the external tool. We\nextend previous methods for uncertainty quantification over token sequences to\nthis setting and propose efficient approximations that make uncertainty\ncomputation practical for real-world applications. We evaluate our framework on\ntwo new synthetic QA datasets, derived from well-known machine learning\ndatasets, which require tool-calling for accurate answers. Additionally, we\napply our method to retrieval-augmented generation (RAG) systems and conduct a\nproof-of-concept experiment demonstrating the effectiveness of our uncertainty\nmetrics in scenarios where external information retrieval is needed. Our\nresults show that the framework is effective in enhancing trust in LLM-based\nsystems, especially in cases where the LLM's internal knowledge is insufficient\nand external tools are required.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u91cf\u5316\u5de5\u5177\u8c03\u7528\u578b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u8be5\u6846\u67b6\u5728\u5408\u6210\u95ee\u7b54\u6570\u636e\u96c6\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\u5176\u5728\u63d0\u9ad8\u57fa\u4e8eLLM\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u65b9\u9762\u662f\u6709\u6548\u7684\u3002", "motivation": "\u73b0\u6709\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u65e0\u6cd5\u5904\u7406\u5de5\u5177\u8c03\u7528\u573a\u666f\u4e0b\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u786e\u4fdd\u6700\u7ec8\u54cd\u5e94\u53ef\u9760\u6027\u65f6\u9700\u8981\u8bc4\u4f30LLM\u751f\u6210\u6587\u672c\u548c\u5de5\u5177\u8f93\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u6846\u67b6\uff0c\u8054\u5408\u8003\u8651LLM\u548c\u5916\u90e8\u5de5\u5177\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u6269\u5c55\u4e86\u4ee5\u524d\u7684\u5e8f\u5217\u6807\u8bb0\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u8fd1\u4f3c\u65b9\u6cd5\u3002", "result": "\u5728\u4e24\u4e2a\u65b0\u7684\u5408\u6210QA\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e86\u8be5\u6846\u67b6\uff0c\u5e76\u5728\u4e00\u4e2a\u8bc1\u660e\u6982\u5ff5\u5b9e\u9a8c\u4e2d\u5e94\u7528\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u5728\u9700\u8981\u5916\u90e8\u4fe1\u606f\u68c0\u7d22\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u57fa\u4e8eLLM\u7cfb\u7edf\u7684\u4fe1\u4efb\u5ea6\uff0c\u5c24\u5176\u662f\u5728LLM\u5185\u90e8\u77e5\u8bc6\u4e0d\u8db3\u4e14\u9700\u8981\u5916\u90e8\u5de5\u5177\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2505.16225", "pdf": "https://arxiv.org/pdf/2505.16225", "abs": "https://arxiv.org/abs/2505.16225", "authors": ["Zihan Chen", "Song Wang", "Zhen Tan", "Jundong Li", "Cong Shen"], "title": "MAPLE: Many-Shot Adaptive Pseudo-Labeling for In-Context Learning", "categories": ["cs.AI"], "comment": null, "summary": "In-Context Learning (ICL) empowers Large Language Models (LLMs) to tackle\ndiverse tasks by incorporating multiple input-output examples, known as\ndemonstrations, into the input of LLMs. More recently, advancements in the\nexpanded context windows of LLMs have led to many-shot ICL, which uses hundreds\nof demonstrations and outperforms few-shot ICL, which relies on fewer examples.\nHowever, this approach is often hindered by the high cost of obtaining large\namounts of labeled data. To address this challenge, we propose Many-Shot\nAdaptive Pseudo-LabEling, namely MAPLE, a novel influence-based many-shot ICL\nframework that utilizes pseudo-labeled samples to compensate for the lack of\nlabel information. We first identify a subset of impactful unlabeled samples\nand perform pseudo-labeling on them by querying LLMs. These pseudo-labeled\nsamples are then adaptively selected and tailored to each test query as input\nto improve the performance of many-shot ICL, without significant labeling\ncosts. Extensive experiments on real-world datasets demonstrate the\neffectiveness of our framework, showcasing its ability to enhance LLM\nadaptability and performance with limited labeled data.", "AI": {"tldr": "\u63d0\u51faMAPLE\u6846\u67b6\uff0c\u5229\u7528\u4f2a\u6807\u7b7e\u6837\u672c\u89e3\u51b3\u5927\u91cf\u6807\u6ce8\u6570\u636e\u83b7\u53d6\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u63d0\u5347\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u8bb8\u591a\u793a\u4f8b\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u7684\u9002\u5e94\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u8bb8\u591a\u793a\u4f8b\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u56e0\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u5bfc\u81f4\u7684\u6210\u672c\u9ad8\u6602\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faMAPLE\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u6709\u5f71\u54cd\u529b\u7684\u672a\u6807\u8bb0\u6837\u672c\u5e76\u8fdb\u884c\u4f2a\u6807\u7b7e\u5904\u7406\u6765\u589e\u5f3a\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMAPLE\u6846\u67b6\u80fd\u6709\u6548\u63d0\u9ad8\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u9002\u5e94\u6027\u548c\u6027\u80fd\uff0c\u4e14\u65e0\u9700\u663e\u8457\u589e\u52a0\u6807\u6ce8\u6210\u672c\u3002", "conclusion": "MAPLE\u662f\u4e00\u79cd\u521b\u65b0\u7684\u57fa\u4e8e\u5f71\u54cd\u7684\u8bb8\u591a\u793a\u4f8b\u4e0a\u4e0b\u6587\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u5728\u6709\u9650\u6807\u6ce8\u6570\u636e\u60c5\u51b5\u4e0b\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2505.16732", "pdf": "https://arxiv.org/pdf/2505.16732", "abs": "https://arxiv.org/abs/2505.16732", "authors": ["Hany Abdulsamad", "Sahel Iqbal", "Simo S\u00e4rkk\u00e4"], "title": "Sequential Monte Carlo for Policy Optimization in Continuous POMDPs", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Optimal decision-making under partial observability requires agents to\nbalance reducing uncertainty (exploration) against pursuing immediate\nobjectives (exploitation). In this paper, we introduce a novel policy\noptimization framework for continuous partially observable Markov decision\nprocesses (POMDPs) that explicitly addresses this challenge. Our method casts\npolicy learning as probabilistic inference in a non-Markovian Feynman--Kac\nmodel that inherently captures the value of information gathering by\nanticipating future observations, without requiring extrinsic exploration\nbonuses or handcrafted heuristics. To optimize policies under this model, we\ndevelop a nested sequential Monte Carlo~(SMC) algorithm that efficiently\nestimates a history-dependent policy gradient under samples from the optimal\ntrajectory distribution induced by the POMDP. We demonstrate the effectiveness\nof our algorithm across standard continuous POMDP benchmarks, where existing\nmethods struggle to act under uncertainty.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b56\u7565\u4f18\u5316\u6846\u67b6\u7528\u4e8e\u89e3\u51b3\u8fde\u7eed\u90e8\u5206\u53ef\u89c2\u5bdf\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u63a2\u7d22\u4e0e\u5229\u7528\u5e73\u8861\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u975e\u9a6c\u5c14\u53ef\u592b\u8d39\u66fc-\u5361\u8328\u6a21\u578b\u5c06\u7b56\u7565\u5b66\u4e60\u89c6\u4e3a\u6982\u7387\u63a8\u65ad\uff0c\u5e76\u5f00\u53d1\u4e86\u5d4c\u5957\u5e8f\u5217\u8499\u7279\u5361\u6d1b\u7b97\u6cd5\u6765\u4f30\u8ba1\u5386\u53f2\u76f8\u5173\u7684\u7b56\u7565\u68af\u5ea6\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u7b97\u6cd5\u5728\u6807\u51c6\u8fde\u7eed\u90e8\u5206\u53ef\u89c2\u5bdf\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u51b3\u7b56\u4e2d\u63a2\u7d22\u4e0e\u5229\u7528\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\u3002", "method": "\u5f15\u5165\u65b0\u7684\u7b56\u7565\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u975e\u9a6c\u5c14\u53ef\u592b\u8d39\u66fc-\u5361\u8328\u6a21\u578b\u8fdb\u884c\u6982\u7387\u63a8\u65ad\uff0c\u5e76\u91c7\u7528\u5d4c\u5957\u5e8f\u5217\u8499\u7279\u5361\u6d1b\u7b97\u6cd5\u4f30\u8ba1\u653f\u7b56\u68af\u5ea6\u3002", "result": "\u7b97\u6cd5\u5728\u6807\u51c6\u8fde\u7eed\u90e8\u5206\u53ef\u89c2\u5bdf\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b56\u7565\u4f18\u5316\u6846\u67b6\u80fd\u591f\u6709\u6548\u5904\u7406\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u7684\u51b3\u7b56\u95ee\u9898\u3002"}}
{"id": "2505.16115", "pdf": "https://arxiv.org/pdf/2505.16115", "abs": "https://arxiv.org/abs/2505.16115", "authors": ["Aditya T. Vadlamani", "Anutam Srinivasan", "Pranav Maneriker", "Ali Payani", "Srinivasan Parthasarathy"], "title": "A Generic Framework for Conformal Fairness", "categories": ["cs.LG"], "comment": "ICLR 2025 Camera Ready Version", "summary": "Conformal Prediction (CP) is a popular method for uncertainty quantification\nwith machine learning models. While conformal prediction provides probabilistic\nguarantees regarding the coverage of the true label, these guarantees are\nagnostic to the presence of sensitive attributes within the dataset. In this\nwork, we formalize \\textit{Conformal Fairness}, a notion of fairness using\nconformal predictors, and provide a theoretically well-founded algorithm and\nassociated framework to control for the gaps in coverage between different\nsensitive groups. Our framework leverages the exchangeability assumption\n(implicit to CP) rather than the typical IID assumption, allowing us to apply\nthe notion of Conformal Fairness to data types and tasks that are not IID, such\nas graph data. Experiments were conducted on graph and tabular datasets to\ndemonstrate that the algorithm can control fairness-related gaps in addition to\ncoverage aligned with theoretical expectations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e00\u81f4\u6027\u9884\u6d4b\u7684\u516c\u5e73\u6027\u6982\u5ff5\uff08\u4e00\u81f4\u6027\u516c\u5e73\u6027\uff09\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b97\u6cd5\u6846\u67b6\u6765\u63a7\u5236\u4e0d\u540c\u654f\u611f\u7ec4\u4e4b\u95f4\u7684\u8986\u76d6\u7387\u5dee\u8ddd\u3002\u8be5\u6846\u67b6\u9002\u7528\u4e8e\u975e\u72ec\u7acb\u540c\u5206\u5e03\u7684\u6570\u636e\u7c7b\u578b\uff0c\u5982\u56fe\u6570\u636e\uff0c\u5e76\u5728\u56fe\u548c\u8868\u683c\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u4e00\u81f4\u6027\u9884\u6d4b\u5bf9\u6570\u636e\u96c6\u4e2d\u654f\u611f\u5c5e\u6027\u7684\u5b58\u5728\u4e0d\u63d0\u4f9b\u4fdd\u8bc1\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u4e00\u81f4\u6027\u9884\u6d4b\u7684\u516c\u5e73\u6027\u6982\u5ff5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7b97\u6cd5\u6846\u67b6\u6765\u63a7\u5236\u4e0d\u540c\u654f\u611f\u7ec4\u4e4b\u95f4\u7684\u8986\u76d6\u7387\u5dee\u8ddd\u3002", "result": "\u5728\u56fe\u6570\u636e\u548c\u8868\u683c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u63a7\u5236\u4e0e\u516c\u5e73\u6027\u76f8\u5173\u7684\u5dee\u8ddd\uff0c\u5e76\u4e14\u8986\u76d6\u7387\u7b26\u5408\u7406\u8bba\u9884\u671f\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5b9e\u73b0\u4e00\u81f4\u6027\u516c\u5e73\u6027\uff0c\u5e76\u4e14\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2505.16276", "pdf": "https://arxiv.org/pdf/2505.16276", "abs": "https://arxiv.org/abs/2505.16276", "authors": ["Desiree Heim", "Lars-Peter Meyer", "Markus Schr\u00f6der", "Johannes Frey", "Andreas Dengel"], "title": "How do Scaling Laws Apply to Knowledge Graph Engineering Tasks? The Impact of Model Size on Large Language Model Performance", "categories": ["cs.AI", "cs.CL"], "comment": "Peer reviewed and to appear in the ESWC 2025 Workshops and Tutorials\n  Joint Proceedings (Workshop on Evaluation of Language Models in Knowledge\n  Engineering [ELMKE])", "summary": "When using Large Language Models (LLMs) to support Knowledge Graph\nEngineering (KGE), one of the first indications when searching for an\nappropriate model is its size. According to the scaling laws, larger models\ntypically show higher capabilities. However, in practice, resource costs are\nalso an important factor and thus it makes sense to consider the ratio between\nmodel performance and costs. The LLM-KG-Bench framework enables the comparison\nof LLMs in the context of KGE tasks and assesses their capabilities of\nunderstanding and producing KGs and KG queries. Based on a dataset created in\nan LLM-KG-Bench run covering 26 open state-of-the-art LLMs, we explore the\nmodel size scaling laws specific to KGE tasks. In our analyses, we assess how\nbenchmark scores evolve between different model size categories. Additionally,\nwe inspect how the general score development of single models and families of\nmodels correlates to their size. Our analyses revealed that, with a few\nexceptions, the model size scaling laws generally also apply to the selected\nKGE tasks. However, in some cases, plateau or ceiling effects occurred, i.e.,\nthe task performance did not change much between a model and the next larger\nmodel. In these cases, smaller models could be considered to achieve high\ncost-effectiveness. Regarding models of the same family, sometimes larger\nmodels performed worse than smaller models of the same family. These effects\noccurred only locally. Hence it is advisable to additionally test the next\nsmallest and largest model of the same family.", "AI": {"tldr": "This study explores the relationship between model size and performance in large language models used for knowledge graph engineering tasks.", "motivation": "To investigate whether larger models always perform better in knowledge graph engineering tasks and to find cost-effective solutions.", "method": "Using the LLM-KG-Bench framework, the researchers compared 26 open state-of-the-art LLMs and analyzed how benchmark scores evolved across different model size categories.", "result": "The results showed that the model size scaling laws generally apply to KGE tasks, but there were exceptions where performance plateaus or ceilings occurred, suggesting smaller models can be more cost-effective in some cases.", "conclusion": "While larger models tend to perform better, there are instances where smaller models can be more efficient, especially when considering resource costs and performance plateaus."}}
{"id": "2505.16741", "pdf": "https://arxiv.org/pdf/2505.16741", "abs": "https://arxiv.org/abs/2505.16741", "authors": ["Pilhwa Lee", "Shashank Gupta"], "title": "Meta-reinforcement learning with minimum attention", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "10 pages, 7 figures", "summary": "Minimum attention applies the least action principle in the changes of\ncontrol concerning state and time, first proposed by Brockett. The involved\nregularization is highly relevant in emulating biological control, such as\nmotor learning. We apply minimum attention in reinforcement learning (RL) as\npart of the rewards and investigate its connection to meta-learning and\nstabilization. Specifically, model-based meta-learning with minimum attention\nis explored in high-dimensional nonlinear dynamics. Ensemble-based model\nlearning and gradient-based meta-policy learning are alternately performed.\nEmpirically, we show that the minimum attention does show outperforming\ncompetence in comparison to the state-of-the-art algorithms in model-free and\nmodel-based RL, i.e., fast adaptation in few shots and variance reduction from\nthe perturbations of the model and environment. Furthermore, the minimum\nattention demonstrates the improvement in energy efficiency.", "AI": {"tldr": "Minimum attention is applied in reinforcement learning as part of the rewards, showing better performance than state-of-the-art algorithms.", "motivation": "To emulate biological control and improve reinforcement learning performance.", "method": "Using minimum attention in reinforcement learning, alternating ensemble-based model learning and gradient-based meta-policy learning.", "result": "Outperforms state-of-the-art algorithms in model-free and model-based RL in terms of fast adaptation and variance reduction.", "conclusion": "Minimum attention improves energy efficiency and provides a promising approach for reinforcement learning."}}
{"id": "2505.16122", "pdf": "https://arxiv.org/pdf/2505.16122", "abs": "https://arxiv.org/abs/2505.16122", "authors": ["Junhong Lin", "Xinyue Zeng", "Jie Zhu", "Song Wang", "Julian Shun", "Jun Wu", "Dawei Zhou"], "title": "Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success in complex\nreasoning tasks, but their inference remains computationally inefficient. We\nobserve a common failure mode in many prevalent LLMs, overthinking, where\nmodels generate verbose and tangential reasoning traces even for simple\nqueries. Recent works have tried to mitigate this by enforcing fixed token\nbudgets, however, this can lead to underthinking, especially on harder\nproblems. Through empirical analysis, we identify that this inefficiency often\nstems from unclear problem-solving strategies. To formalize this, we develop a\ntheoretical model, BBAM (Bayesian Budget Allocation Model), which models\nreasoning as a sequence of sub-questions with varying uncertainty, and\nintroduce the $E^3$ metric to capture the trade-off between correctness and\ncomputation efficiency. Building on theoretical results from BBAM, we propose\nPlan-and-Budget, a model-agnostic, test-time framework that decomposes complex\nqueries into sub-questions and allocates token budgets based on estimated\ncomplexity using adaptive scheduling. Plan-and-Budget improves reasoning\nefficiency across a range of tasks and models, achieving up to +70% accuracy\ngains, -39% token reduction, and +187.5% improvement in $E^3$. Notably, it\nelevates a smaller model (DS-Qwen-32B) to match the efficiency of a larger\nmodel (DS-LLaMA-70B)-demonstrating Plan-and-Budget's ability to close\nperformance gaps without retraining. Our code is available at\nanonymous.4open.science/r/P-and-B-6513/.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPlan-and-Budget\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u590d\u6742\u67e5\u8be2\u548c\u57fa\u4e8e\u4f30\u8ba1\u590d\u6742\u5ea6\u7684\u81ea\u9002\u5e94\u8c03\u5ea6\u6765\u5206\u914d\u4ee4\u724c\u9884\u7b97\uff0c\u63d0\u9ad8\u4e86\u5404\u79cd\u4efb\u52a1\u548c\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\u4f46\u63a8\u7406\u8ba1\u7b97\u6548\u7387\u4f4e\uff0c\u5b58\u5728\u8fc7\u5ea6\u601d\u8003\u548c\u6b20\u601d\u8003\u7684\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86BBAM\uff08\u8d1d\u53f6\u65af\u9884\u7b97\u5206\u914d\u6a21\u578b\uff09\uff0c\u63d0\u51fa\u4e86E\u00b3\u6307\u6807\uff0c\u5e76\u63d0\u51fa\u4e86Plan-and-Budget\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u662f\u4e00\u79cd\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u6d4b\u8bd5\u65f6\u6846\u67b6\u3002", "result": "Plan-and-Budget\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\uff0c\u63d0\u5347\u4e86\u8f83\u5c0f\u6a21\u578b\u7684\u8868\u73b0\uff0c\u4f7f\u5176\u63a5\u8fd1\u66f4\u5927\u6a21\u578b\u7684\u6548\u7387\u3002", "conclusion": "Plan-and-Budget\u80fd\u591f\u63d0\u9ad8\u63a8\u7406\u6548\u7387\u5e76\u7f29\u5c0f\u6027\u80fd\u5dee\u8ddd\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002"}}
{"id": "2505.16288", "pdf": "https://arxiv.org/pdf/2505.16288", "abs": "https://arxiv.org/abs/2505.16288", "authors": ["Xiaoxue Han", "Pengfei Hu", "Jun-En Ding", "Chang Lu", "Feng Liu", "Yue Ning"], "title": "No Black Boxes: Interpretable and Interactable Predictive Healthcare with Knowledge-Enhanced Agentic Causal Discovery", "categories": ["cs.AI"], "comment": null, "summary": "Deep learning models trained on extensive Electronic Health Records (EHR)\ndata have achieved high accuracy in diagnosis prediction, offering the\npotential to assist clinicians in decision-making and treatment planning.\nHowever, these models lack two crucial features that clinicians highly value:\ninterpretability and interactivity. The ``black-box'' nature of these models\nmakes it difficult for clinicians to understand the reasoning behind\npredictions, limiting their ability to make informed decisions. Additionally,\nthe absence of interactive mechanisms prevents clinicians from incorporating\ntheir own knowledge and experience into the decision-making process. To address\nthese limitations, we propose II-KEA, a knowledge-enhanced agent-driven causal\ndiscovery framework that integrates personalized knowledge databases and\nagentic LLMs. II-KEA enhances interpretability through explicit reasoning and\ncausal analysis, while also improving interactivity by allowing clinicians to\ninject their knowledge and experience through customized knowledge bases and\nprompts. II-KEA is evaluated on both MIMIC-III and MIMIC-IV, demonstrating\nsuperior performance along with enhanced interpretability and interactivity, as\nevidenced by its strong results from extensive case studies.", "AI": {"tldr": "\u63d0\u51faII-KEA\u6846\u67b6\uff0c\u7ed3\u5408\u4e2a\u6027\u5316\u77e5\u8bc6\u5e93\u548c\u4e3b\u52a8LLMs\uff0c\u63d0\u5347\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u533b\u7597\u8bca\u65ad\u9884\u6d4b\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u4e92\u52a8\u6027\uff0c\u5e76\u5728MIMIC\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u867d\u7136\u5728\u8bca\u65ad\u9884\u6d4b\u4e0a\u51c6\u786e\u7387\u9ad8\uff0c\u4f46\u7f3a\u4e4f\u4e34\u5e8a\u533b\u751f\u91cd\u89c6\u7684\u53ef\u89e3\u91ca\u6027\u548c\u4e92\u52a8\u6027\u3002", "method": "\u63d0\u51faII-KEA\u6846\u67b6\uff0c\u901a\u8fc7\u77e5\u8bc6\u589e\u5f3a\u7684\u4e3b\u52a8\u4ee3\u7406\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e2a\u6027\u5316\u77e5\u8bc6\u5e93\u548c\u4e3b\u52a8LLMs\u6765\u63d0\u9ad8\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u4e92\u52a8\u6027\u3002", "result": "II-KEA\u5728MIMIC-III\u548cMIMIC-IV\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u589e\u5f3a\u7684\u53ef\u89e3\u91ca\u6027\u548c\u4e92\u52a8\u6027\u3002", "conclusion": "II-KEA\u6846\u67b6\u6210\u529f\u63d0\u5347\u4e86\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7684\u53ef\u89e3\u91ca\u6027\u548c\u4e92\u52a8\u6027\uff0c\u6709\u52a9\u4e8e\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u3002"}}
{"id": "2505.16953", "pdf": "https://arxiv.org/pdf/2505.16953", "abs": "https://arxiv.org/abs/2505.16953", "authors": ["Young Sang Choi", "Vincent Jeanselme", "Pierre Elias", "Shalmali Joshi"], "title": "ICYM2I: The illusion of multimodal informativeness under missingness", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multimodal learning is of continued interest in artificial intelligence-based\napplications, motivated by the potential information gain from combining\ndifferent types of data. However, modalities collected and curated during\ndevelopment may differ from the modalities available at deployment due to\nmultiple factors including cost, hardware failure, or -- as we argue in this\nwork -- the perceived informativeness of a given modality. Na{\\\"i}ve estimation\nof the information gain associated with including an additional modality\nwithout accounting for missingness may result in improper estimates of that\nmodality's value in downstream tasks. Our work formalizes the problem of\nmissingness in multimodal learning and demonstrates the biases resulting from\nignoring this process. To address this issue, we introduce ICYM2I (In Case You\nMultimodal Missed It), a framework for the evaluation of predictive performance\nand information gain under missingness through inverse probability\nweighting-based correction. We demonstrate the importance of the proposed\nadjustment to estimate information gain under missingness on synthetic,\nsemi-synthetic, and real-world medical datasets.", "AI": {"tldr": "This paper addresses the issue of missing modalities in multimodal learning and introduces ICYM2I, a framework using inverse probability weighting to correct and evaluate predictive performance and information gain.", "motivation": "The paper aims to tackle the problem of information gain estimation when modalities are missing due to various factors such as cost or hardware failure.", "method": "Introduces ICYM2I, a framework based on inverse probability weighting to adjust for missingness in multimodal learning.", "result": "Demonstrates the importance of the adjustment in estimating information gain under missingness on different datasets including synthetic, semi-synthetic, and real-world medical datasets.", "conclusion": "The work formalizes the problem of missingness in multimodal learning and shows how ignoring this can lead to biased results."}}
{"id": "2505.16126", "pdf": "https://arxiv.org/pdf/2505.16126", "abs": "https://arxiv.org/abs/2505.16126", "authors": ["Kotaro Yoshida", "Slavakis Konstantinos"], "title": "Robust Invariant Representation Learning by Distribution Extrapolation", "categories": ["cs.LG"], "comment": null, "summary": "Invariant risk minimization (IRM) aims to enable out-of-distribution (OOD)\ngeneralization in deep learning by learning invariant representations. As IRM\nposes an inherently challenging bi-level optimization problem, most existing\napproaches -- including IRMv1 -- adopt penalty-based single-level\napproximations. However, empirical studies consistently show that these methods\noften fail to outperform well-tuned empirical risk minimization (ERM),\nhighlighting the need for more robust IRM implementations. This work\ntheoretically identifies a key limitation common to many IRM variants: their\npenalty terms are highly sensitive to limited environment diversity and\nover-parameterization, resulting in performance degradation. To address this\nissue, a novel extrapolation-based framework is proposed that enhances\nenvironmental diversity by augmenting the IRM penalty through synthetic\ndistributional shifts. Extensive experiments -- ranging from synthetic setups\nto realistic, over-parameterized scenarios -- demonstrate that the proposed\nmethod consistently outperforms state-of-the-art IRM variants, validating its\neffectiveness and robustness.", "AI": {"tldr": "This paper addresses the limitations of current IRM approaches by introducing a new method based on synthetic distributional shifts, which improves environmental diversity and outperforms existing IRM variants.", "motivation": "To enable out-of-distribution generalization in deep learning by learning invariant representations, overcoming the challenges of bi-level optimization and improving upon the limitations of existing IRM approaches.", "method": "Proposes a novel extrapolation-based framework that enhances environmental diversity by augmenting the IRM penalty with synthetic distributional shifts.", "result": "The proposed method consistently outperforms state-of-the-art IRM variants across various experimental settings, from synthetic setups to realistic over-parameterized scenarios.", "conclusion": "The study theoretically identifies a key limitation of many IRM variants and introduces a robust solution that enhances the effectiveness and reliability of invariant risk minimization."}}
{"id": "2505.16312", "pdf": "https://arxiv.org/pdf/2505.16312", "abs": "https://arxiv.org/abs/2505.16312", "authors": ["Jiawei Liu", "Qisi Chen", "Jianshu Zhang", "Quan Liu", "Defu Lian"], "title": "EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via Action Pruning", "categories": ["cs.AI", "cs.CL"], "comment": "11 pages, 4 figures", "summary": "Large Language Models (LLMs) excel at complex reasoning through search\nalgorithms, yet current strategies often suffer from massive token consumption\ndue to redundant exploration of semantically equivalent steps. Existing\nsemantic similarity methods struggle to accurately identify such equivalence in\ndomain-specific contexts like mathematical reasoning. To address this, we\npropose EquivPruner, a simple yet effective approach that identifies and prunes\nsemantically equivalent actions during LLM reasoning search. We also introduce\nMathEquiv, the first dataset we created for mathematical statement equivalence,\nwhich enables the training of a lightweight equivalence detector. Extensive\nexperiments across various models and tasks demonstrate that EquivPruner\nsignificantly reduces token consumption, improving searching efficiency and\noften bolstering reasoning accuracy. For instance, when applied to\nQwen2.5-Math-7B-Instruct on GSM8K, EquivPruner reduced token consumption by\n48.1\\% while also improving accuracy. Our code is available at\nhttps://github.com/Lolo1222/EquivPruner.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEquivPruner\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u4ee4\u724c\u6d88\u8017\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u63a8\u7406\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u7b56\u7565\u7531\u4e8e\u8bed\u4e49\u7b49\u6548\u6b65\u9aa4\u7684\u5197\u4f59\u63a2\u7d22\u800c\u5bfc\u81f4\u5927\u91cf\u4ee4\u724c\u6d88\u8017\uff0c\u5c24\u5176\u662f\u5728\u6570\u5b66\u63a8\u7406\u7b49\u7279\u5b9a\u9886\u57df\u4e2d\uff0c\u73b0\u6709\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u8bc6\u522b\u8fd9\u79cd\u7b49\u6548\u6027\u3002", "method": "\u63d0\u51faEquivPruner\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u548c\u526a\u679d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u641c\u7d22\u8fc7\u7a0b\u4e2d\u7684\u8bed\u4e49\u7b49\u6548\u52a8\u4f5c\uff0c\u5e76\u521b\u5efa\u4e86MathEquiv\u6570\u636e\u96c6\u4ee5\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u7b49\u6548\u68c0\u6d4b\u5668\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEquivPruner\u663e\u8457\u51cf\u5c11\u4e86\u4ee4\u724c\u6d88\u8017\uff0c\u63d0\u9ad8\u4e86\u641c\u7d22\u6548\u7387\uff0c\u5e76\u4e14\u5e38\u5e38\u589e\u5f3a\u4e86\u63a8\u7406\u51c6\u786e\u6027\u3002\u4f8b\u5982\uff0c\u5728GSM8K\u4e0a\u5e94\u7528\u5230Qwen2.5-Math-7B-Instruct\u65f6\uff0cEquivPruner\u5c06\u4ee4\u724c\u6d88\u8017\u51cf\u5c11\u4e8648.1\uff05\uff0c\u5e76\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684EquivPruner\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u4ee4\u724c\u6d88\u8017\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2505.16959", "pdf": "https://arxiv.org/pdf/2505.16959", "abs": "https://arxiv.org/abs/2505.16959", "authors": ["Alessandro Favero", "Antonio Sclocchi", "Matthieu Wyart"], "title": "Bigger Isn't Always Memorizing: Early Stopping Overparameterized Diffusion Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Diffusion probabilistic models have become a cornerstone of modern generative\nAI, yet the mechanisms underlying their generalization remain poorly\nunderstood. In fact, if these models were perfectly minimizing their training\nloss, they would just generate data belonging to their training set, i.e.,\nmemorize, as empirically found in the overparameterized regime. We revisit this\nview by showing that, in highly overparameterized diffusion models,\ngeneralization in natural data domains is progressively achieved during\ntraining before the onset of memorization. Our results, ranging from image to\nlanguage diffusion models, systematically support the empirical law that\nmemorization time is proportional to the dataset size. Generalization vs.\nmemorization is then best understood as a competition between time scales. We\nshow that this phenomenology is recovered in diffusion models learning a simple\nprobabilistic context-free grammar with random rules, where generalization\ncorresponds to the hierarchical acquisition of deeper grammar rules as training\ntime grows, and the generalization cost of early stopping can be characterized.\nWe summarize these results in a phase diagram. Overall, our results support\nthat a principled early-stopping criterion - scaling with dataset size - can\neffectively optimize generalization while avoiding memorization, with direct\nimplications for hyperparameter transfer and privacy-sensitive applications.", "AI": {"tldr": "Diffusion probabilistic models generalize in natural data domains during training before memorization occurs, with memorization time proportional to dataset size. A phase diagram summarizes these findings.", "motivation": "Understanding the mechanisms behind generalization in overparameterized diffusion models.", "method": "Analyzing the relationship between generalization, memorization, and dataset size in diffusion models.", "result": "Generalization happens before memorization in overparameterized diffusion models, with memorization time proportional to dataset size. This is also observed in models learning a probabilistic context-free grammar.", "conclusion": "A principled early-stopping criterion based on dataset size can optimize generalization and avoid memorization, with implications for hyperparameter transfer and privacy-sensitive applications."}}
{"id": "2505.16130", "pdf": "https://arxiv.org/pdf/2505.16130", "abs": "https://arxiv.org/abs/2505.16130", "authors": ["Zehong Wang", "Zheyuan Zhang", "Tianyi Ma", "Chuxu Zhang", "Yanfang Ye"], "title": "Scalable Graph Generative Modeling via Substructure Sequences", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": null, "summary": "Graph neural networks (GNNs) has been predominantly driven by\nmessage-passing, where node representations are iteratively updated via local\nneighborhood aggregation. Despite their success, message-passing suffers from\nfundamental limitations -- including constrained expressiveness,\nover-smoothing, over-squashing, and limited capacity to model long-range\ndependencies. These issues hinder scalability: increasing data size or model\nsize often fails to yield improved performance, limiting the viability of GNNs\nas backbones for graph foundation models. In this work, we explore pathways\nbeyond message-passing and introduce Generative Graph Pattern Machine\n(G$^2$PM), a generative Transformer pre-training framework for graphs. G$^2$PM\nrepresents graph instances (nodes, edges, or entire graphs) as sequences of\nsubstructures, and employs generative pre-training over the sequences to learn\ngeneralizable, transferable representations. Empirically, G$^2$PM demonstrates\nstrong scalability: on the ogbn-arxiv benchmark, it continues to improve with\nmodel sizes up to 60M parameters, outperforming prior generative approaches\nthat plateau at significantly smaller scales (e.g., 3M). In addition, we\nsystematically analyze the model design space, highlighting key architectural\nchoices that contribute to its scalability and generalization. Across diverse\ntasks -- including node classification, graph classification, and transfer\nlearning -- G$^2$PM consistently outperforms strong baselines, establishing a\ncompelling foundation for scalable graph learning. The code and dataset are\navailable at https://github.com/Zehong-Wang/G2PM.", "AI": {"tldr": "This paper introduces G$^2$PM, a scalable graph representation learning method using generative pre-training beyond traditional message-passing.", "motivation": "Traditional message-passing GNNs have fundamental limitations like limited expressiveness and inability to model long-range dependencies.", "method": "Generative Graph Pattern Machine (G$^2$PM) represents graph instances as sequences of substructures and uses generative pre-training to learn representations.", "result": "G$^2$PM shows strong scalability and better performance than previous methods across various tasks.", "conclusion": "G$^2$PM is a new approach beyond message-passing for graph neural networks."}}
{"id": "2505.16315", "pdf": "https://arxiv.org/pdf/2505.16315", "abs": "https://arxiv.org/abs/2505.16315", "authors": ["Xiaoxue Cheng", "Junyi Li", "Zhenduo Zhang", "Xinyu Tang", "Wayne Xin Zhao", "Xinyu Kong", "Zhiqiang Zhang"], "title": "Incentivizing Dual Process Thinking for Efficient Large Language Model Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "work in progress", "summary": "Large reasoning models (LRMs) have demonstrated strong performance on complex\nreasoning tasks, but often suffer from overthinking, generating redundant\ncontent regardless of task difficulty. Inspired by the dual process theory in\ncognitive science, we propose Adaptive Cognition Policy Optimization (ACPO), a\nreinforcement learning framework that enables LRMs to achieve efficient\nreasoning through adaptive cognitive allocation and dynamic system switch. ACPO\nincorporates two key components: (1) introducing system-aware reasoning tokens\nto explicitly represent the thinking modes thereby making the model's cognitive\nprocess transparent, and (2) integrating online difficulty estimation and token\nlength budget to guide adaptive system switch and reasoning during\nreinforcement learning. To this end, we propose a two-stage training strategy.\nThe first stage begins with supervised fine-tuning to cold start the model,\nenabling it to generate reasoning paths with explicit thinking modes. In the\nsecond stage, we apply ACPO to further enhance adaptive system switch for\ndifficulty-aware reasoning. Experimental results demonstrate that ACPO\neffectively reduces redundant reasoning while adaptively adjusting cognitive\nallocation based on task complexity, achieving efficient hybrid reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aACPO\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u8ba4\u77e5\u5206\u914d\u548c\u52a8\u6001\u7cfb\u7edf\u5207\u6362\u4f7f\u5927\u578b\u63a8\u7406\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cACPO\u5728\u51cf\u5c11\u5197\u4f59\u63a8\u7406\u7684\u540c\u65f6\uff0c\u80fd\u6839\u636e\u4efb\u52a1\u590d\u6742\u6027\u81ea\u9002\u5e94\u8c03\u6574\u8ba4\u77e5\u5206\u914d\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6df7\u5408\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5e38\u5e38\u56e0\u4e3a\u8fc7\u5ea6\u601d\u8003\u800c\u4ea7\u751f\u5197\u4f59\u5185\u5bb9\uff0c\u4e0d\u8bba\u4efb\u52a1\u96be\u5ea6\u5982\u4f55\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aACPO\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a\u5f15\u5165\u7cfb\u7edf\u611f\u77e5\u63a8\u7406\u6807\u8bb0\u4ee5\u660e\u786e\u8868\u793a\u601d\u7ef4\u6a21\u5f0f\uff0c\u4ee5\u53ca\u6574\u5408\u5728\u7ebf\u96be\u5ea6\u4f30\u8ba1\u548c\u6807\u8bb0\u957f\u5ea6\u9884\u7b97\u4ee5\u6307\u5bfc\u81ea\u9002\u5e94\u7cfb\u7edf\u5207\u6362\u548c\u63a8\u7406\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u5f00\u59cb\u6a21\u578b\u8bad\u7ec3\uff0c\u7b2c\u4e8c\u9636\u6bb5\u5e94\u7528ACPO\u8fdb\u4e00\u6b65\u589e\u5f3a\u81ea\u9002\u5e94\u7cfb\u7edf\u5207\u6362\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cACPO\u80fd\u591f\u6709\u6548\u51cf\u5c11\u5197\u4f59\u63a8\u7406\uff0c\u540c\u65f6\u6839\u636e\u4efb\u52a1\u590d\u6742\u6027\u81ea\u9002\u5e94\u8c03\u6574\u8ba4\u77e5\u5206\u914d\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u6df7\u5408\u63a8\u7406\u3002", "conclusion": "ACPO\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u89e3\u51b3\u73b0\u6709\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8ba4\u77e5\u5206\u914d\u548c\u52a8\u6001\u7cfb\u7edf\u5207\u6362\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u3002"}}
{"id": "2505.17004", "pdf": "https://arxiv.org/pdf/2505.17004", "abs": "https://arxiv.org/abs/2505.17004", "authors": ["Jiachen Yao", "Abbas Mammadov", "Julius Berner", "Gavin Kerrigan", "Jong Chul Ye", "Kamyar Azizzadenesheli", "Anima Anandkumar"], "title": "Guided Diffusion Sampling on Function Spaces with Applications to PDEs", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "stat.ML"], "comment": null, "summary": "We propose a general framework for conditional sampling in PDE-based inverse\nproblems, targeting the recovery of whole solutions from extremely sparse or\nnoisy measurements. This is accomplished by a function-space diffusion model\nand plug-and-play guidance for conditioning. Our method first trains an\nunconditional discretization-agnostic denoising model using neural operator\narchitectures. At inference, we refine the samples to satisfy sparse\nobservation data via a gradient-based guidance mechanism. Through rigorous\nmathematical analysis, we extend Tweedie's formula to infinite-dimensional\nHilbert spaces, providing the theoretical foundation for our posterior sampling\napproach. Our method (FunDPS) accurately captures posterior distributions in\nfunction spaces under minimal supervision and severe data scarcity. Across five\nPDE tasks with only 3% observation, our method achieves an average 32% accuracy\nimprovement over state-of-the-art fixed-resolution diffusion baselines while\nreducing sampling steps by 4x. Furthermore, multi-resolution fine-tuning\nensures strong cross-resolution generalizability. To the best of our knowledge,\nthis is the first diffusion-based framework to operate independently of\ndiscretization, offering a practical and flexible solution for forward and\ninverse problems in the context of PDEs. Code is available at\nhttps://github.com/neuraloperator/FunDPS", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u57fa\u4e8ePDE\u7684\u9006\u95ee\u9898\u6761\u4ef6\u91c7\u6837\u7684\u901a\u7528\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u51fd\u6570\u7a7a\u95f4\u6269\u6563\u6a21\u578b\u548c\u63d2\u4ef6\u5f0f\u6307\u5bfc\u5b9e\u73b0\u4ece\u6781\u7a00\u758f\u6216\u566a\u58f0\u6d4b\u91cf\u4e2d\u6062\u590d\u6574\u4e2a\u89e3\u3002\u6570\u5b66\u5206\u6790\u6269\u5c55\u4e86Tweedie\u516c\u5f0f\u5230\u65e0\u9650\u7ef4Hilbert\u7a7a\u95f4\uff0c\u63d0\u4f9b\u4e86\u540e\u9a8c\u91c7\u6837\u7684\u7406\u8bba\u57fa\u7840\u3002\u5b9e\u9a8c\u663e\u793a\u5728\u4e94\u4e2aPDE\u4efb\u52a1\u4e2d\uff0c\u65b9\u6cd5\u6bd4\u6700\u5148\u8fdb\u7684\u56fa\u5b9a\u5206\u8fa8\u7387\u6269\u6563\u57fa\u51c6\u63d0\u9ad8\u4e8632%\u7684\u51c6\u786e\u6027\uff0c\u540c\u65f6\u51cf\u5c11\u4e864\u500d\u7684\u91c7\u6837\u6b65\u9aa4\u3002\u8fd9\u662f\u9996\u4e2a\u4e0d\u4f9d\u8d56\u79bb\u6563\u5316\u7684\u6269\u6563\u6846\u67b6\uff0c\u9002\u7528\u4e8ePDE\u7684\u6b63\u5411\u548c\u53cd\u5411\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u57fa\u4e8ePDE\u7684\u9006\u95ee\u9898\u65f6\uff0c\u901a\u5e38\u9700\u8981\u5927\u91cf\u7684\u89c2\u6d4b\u6570\u636e\uff0c\u800c\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u4ece\u6781\u7a00\u758f\u6216\u566a\u58f0\u6d4b\u91cf\u4e2d\u6062\u590d\u6574\u4e2a\u89e3\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7684\u65b9\u6cd5\u9996\u5148\u8bad\u7ec3\u4e00\u4e2a\u65e0\u6761\u4ef6\u7684\u3001\u4e0e\u79bb\u6563\u65e0\u5173\u7684\u53bb\u566a\u6a21\u578b\uff0c\u7136\u540e\u5728\u63a8\u7406\u9636\u6bb5\u901a\u8fc7\u68af\u5ea6\u5f15\u5bfc\u673a\u5236\u6765\u8c03\u6574\u6837\u672c\uff0c\u4f7f\u5176\u7b26\u5408\u7a00\u758f\u89c2\u6d4b\u6570\u636e\u3002\u6b64\u5916\uff0c\u8fd8\u6269\u5c55\u4e86Tweedie\u516c\u5f0f\u5230\u65e0\u9650\u7ef4Hilbert\u7a7a\u95f4\u3002", "result": "\u5728\u4e94\u4e2aPDE\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5e73\u574732%\u7684\u51c6\u786e\u6027\u63d0\u5347\uff0c\u5e76\u4e14\u51cf\u5c11\u4e864\u500d\u7684\u91c7\u6837\u6b65\u9aa4\u3002", "conclusion": "\u8fd9\u662f\u9996\u4e2a\u4e0d\u4f9d\u8d56\u79bb\u6563\u5316\u7684\u6269\u6563\u6846\u67b6\uff0c\u4e3a\u57fa\u4e8ePDE\u7684\u6b63\u5411\u548c\u9006\u5411\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.16138", "pdf": "https://arxiv.org/pdf/2505.16138", "abs": "https://arxiv.org/abs/2505.16138", "authors": ["Heqiang Wang", "Xiang Liu", "Xiaoxiong Zhong", "Lixing Chen", "Fangming Liu", "Weizhe Zhang"], "title": "Multimodal Online Federated Learning with Modality Missing in Internet of Things", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "The Internet of Things (IoT) ecosystem generates vast amounts of multimodal\ndata from heterogeneous sources such as sensors, cameras, and microphones. As\nedge intelligence continues to evolve, IoT devices have progressed from simple\ndata collection units to nodes capable of executing complex computational\ntasks. This evolution necessitates the adoption of distributed learning\nstrategies to effectively handle multimodal data in an IoT environment.\nFurthermore, the real-time nature of data collection and limited local storage\non edge devices in IoT call for an online learning paradigm. To address these\nchallenges, we introduce the concept of Multimodal Online Federated Learning\n(MMO-FL), a novel framework designed for dynamic and decentralized multimodal\nlearning in IoT environments. Building on this framework, we further account\nfor the inherent instability of edge devices, which frequently results in\nmissing modalities during the learning process. We conduct a comprehensive\ntheoretical analysis under both complete and missing modality scenarios,\nproviding insights into the performance degradation caused by missing\nmodalities. To mitigate the impact of modality missing, we propose the\nPrototypical Modality Mitigation (PMM) algorithm, which leverages prototype\nlearning to effectively compensate for missing modalities. Experimental results\non two multimodal datasets further demonstrate the superior performance of PMM\ncompared to benchmarks.", "AI": {"tldr": "This paper introduces MMO-FL, a new framework for multimodal online federated learning in IoT environments, and the PMM algorithm to handle missing modalities, showing improved performance.", "motivation": "To handle large amounts of multimodal data generated by IoT devices and the challenges of real-time data processing with limited storage.", "method": "Developing MMO-FL framework and PMM algorithm for compensating missing modalities in decentralized multimodal learning.", "result": "Superior performance of PMM algorithm compared to benchmarks on two multimodal datasets.", "conclusion": "MMO-FL framework addresses the challenges of handling multimodal data in IoT environments, and PMM algorithm effectively mitigates the impact of missing modalities."}}
{"id": "2505.16388", "pdf": "https://arxiv.org/pdf/2505.16388", "abs": "https://arxiv.org/abs/2505.16388", "authors": ["Nandini Doreswamy", "Louise Horstmanshof"], "title": "Serious Games: Human-AI Interaction, Evolution, and Coevolution", "categories": ["cs.AI", "cs.GT", "91A22 (Primary), 68T99 (Secondary)", "J.4; I.2.0; K.4.1; J.3; K.4.0"], "comment": "8 pages, 1 table", "summary": "The serious games between humans and AI have only just begun. Evolutionary\nGame Theory (EGT) models the competitive and cooperative strategies of\nbiological entities. EGT could help predict the potential evolutionary\nequilibrium of humans and AI. The objective of this work was to examine some of\nthe EGT models relevant to human-AI interaction, evolution, and coevolution. Of\nthirteen EGT models considered, three were examined: the Hawk-Dove Game,\nIterated Prisoner's Dilemma, and the War of Attrition. This selection was based\non the widespread acceptance and clear relevance of these models to potential\nhuman-AI evolutionary dynamics and coevolutionary trajectories. The Hawk-Dove\nGame predicts balanced mixed-strategy equilibria based on the costs of\nconflict. It also shows the potential for balanced coevolution rather than\ndominance. Iterated Prisoner's Dilemma suggests that repeated interaction may\nlead to cognitive coevolution. It demonstrates how memory and reciprocity can\nlead to cooperation. The War of Attrition suggests that competition for\nresources may result in strategic coevolution, asymmetric equilibria, and\nconventions on sharing resources. Therefore, EGT may provide a suitable\nframework to understand and predict the human-AI evolutionary dynamic. However,\nfuture research could extend beyond EGT and explore additional frameworks,\nempirical validation methods, and interdisciplinary perspectives. AI is being\nshaped by human input and is evolving in response to it. So too,\nneuroplasticity allows the human brain to grow and evolve in response to\nstimuli. If humans and AI converge in future, what might be the result of human\nneuroplasticity combined with an ever-evolving AI? Future research should be\nmindful of the ethical and cognitive implications of human-AI interaction,\nevolution, and coevolution.", "AI": {"tldr": "This paper examines three Evolutionary Game Theory (EGT) models (Hawk-Dove Game, Iterated Prisoner's Dilemma, and War of Attrition) relevant to human-AI interaction, evolution, and coevolution. It suggests that EGT could help predict the potential evolutionary equilibrium of humans and AI.", "motivation": "To understand and predict the human-AI evolutionary dynamic using EGT models.", "method": "Examining three selected EGT models: Hawk-Dove Game, Iterated Prisoner's Dilemma, and War of Attrition.", "result": "These models predict balanced coevolution, cognitive coevolution, and strategic coevolution respectively. They suggest that EGT provides a suitable framework for understanding human-AI evolutionary dynamics.", "conclusion": "Future research should explore beyond EGT, consider empirical validation methods, interdisciplinary perspectives, and ethical/cognitive implications of human-AI interaction, evolution, and coevolution."}}
{"id": "2505.17010", "pdf": "https://arxiv.org/pdf/2505.17010", "abs": "https://arxiv.org/abs/2505.17010", "authors": ["Tim Genewein", "Kevin Wenliang Li", "Jordi Grau-Moya", "Anian Ruoss", "Laurent Orseau", "Marcus Hutter"], "title": "Understanding Prompt Tuning and In-Context Learning via Meta-Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Prompting is one of the main ways to adapt a pretrained model to target\ntasks. Besides manually constructing prompts, many prompt optimization methods\nhave been proposed in the literature. Method development is mainly empirically\ndriven, with less emphasis on a conceptual understanding of prompting. In this\npaper we discuss how optimal prompting can be understood through a Bayesian\nview, which also implies some fundamental limitations of prompting that can\nonly be overcome by tuning weights. The paper explains in detail how\nmeta-trained neural networks behave as Bayesian predictors over the pretraining\ndistribution, whose hallmark feature is rapid in-context adaptation. Optimal\nprompting can be studied formally as conditioning these Bayesian predictors,\nyielding criteria for target tasks where optimal prompting is and is not\npossible. We support the theory with educational experiments on LSTMs and\nTransformers, where we compare different versions of prefix-tuning and\ndifferent weight-tuning methods. We also confirm that soft prefixes, which are\nsequences of real-valued vectors outside the token alphabet, can lead to very\neffective prompts for trained and even untrained networks by manipulating\nactivations in ways that are not achievable by hard tokens. This adds an\nimportant mechanistic aspect beyond the conceptual Bayesian theory.", "AI": {"tldr": "\u672c\u6587\u4ece\u8d1d\u53f6\u65af\u89c6\u89d2\u63a2\u8ba8\u4e86\u6700\u4f18\u63d0\u793a\u7684\u7406\u89e3\u53ca\u5176\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8f6f\u63d0\u793a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u4e3b\u8981\u57fa\u4e8e\u7ecf\u9a8c\u53d1\u5c55\uff0c\u7f3a\u4e4f\u5bf9\u63d0\u793a\u6982\u5ff5\u6027\u7684\u7406\u89e3\u3002", "method": "\u4ece\u8d1d\u53f6\u65af\u9884\u6d4b\u5668\u7684\u89d2\u5ea6\u89e3\u91ca\u5143\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u7684\u884c\u4e3a\uff0c\u5e76\u7814\u7a76\u6700\u4f18\u63d0\u793a\u7684\u6807\u51c6\u3002", "result": "\u901a\u8fc7\u6559\u80b2\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\uff0c\u5728LSTMs\u548cTransformers\u4e0a\u6bd4\u8f83\u4e86\u4e0d\u540c\u7684\u524d\u7f00\u5fae\u8c03\u7248\u672c\u548c\u4e0d\u540c\u7684\u6743\u91cd\u8c03\u6574\u65b9\u6cd5\uff0c\u8bc1\u5b9e\u4e86\u8f6f\u63d0\u793a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4ece\u8d1d\u53f6\u65af\u89c6\u89d2\u7406\u89e3\u6700\u4f18\u63d0\u793a\u7684\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u4e86\u4ec5\u901a\u8fc7\u8c03\u6574\u6743\u91cd\u624d\u80fd\u514b\u670d\u7684\u63d0\u793a\u7684\u57fa\u672c\u9650\u5236\u3002"}}
{"id": "2505.16148", "pdf": "https://arxiv.org/pdf/2505.16148", "abs": "https://arxiv.org/abs/2505.16148", "authors": ["Chongjie Si", "Kangtao Lv", "Jingjing Jiang", "Yadao Wang", "Yongwei Wang", "Xiaokang Yang", "Wenbo Su", "Bo Zheng", "Wei Shen"], "title": "NAN: A Training-Free Solution to Coefficient Estimation in Model Merging", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Model merging offers a training-free alternative to multi-task learning by\ncombining independently fine-tuned models into a unified one without access to\nraw data. However, existing approaches often rely on heuristics to determine\nthe merging coefficients, limiting their scalability and generality. In this\nwork, we revisit model merging through the lens of least-squares optimization\nand show that the optimal merging weights should scale with the amount of\ntask-specific information encoded in each model. Based on this insight, we\npropose NAN, a simple yet effective method that estimates model merging\ncoefficients via the inverse of parameter norm. NAN is training-free,\nplug-and-play, and applicable to a wide range of merging strategies. Extensive\nexperiments on show that NAN consistently improves performance of baseline\nmethods.", "AI": {"tldr": "This work proposes NAN, a novel approach for model merging that uses least-squares optimization and parameter norm inversion to estimate merging coefficients, showing consistent performance improvements across various tasks.", "motivation": "Existing model merging approaches often rely on heuristics, which limits their scalability and generality.", "method": "NAN estimates merging coefficients via the inverse of parameter norm based on the insight that optimal merging weights should scale with task-specific information.", "result": "NAN improves the performance of baseline methods in extensive experiments.", "conclusion": "NAN provides a training-free, plug-and-play method for model merging that is applicable to a wide range of merging strategies."}}
{"id": "2505.16409", "pdf": "https://arxiv.org/pdf/2505.16409", "abs": "https://arxiv.org/abs/2505.16409", "authors": ["Chaeeun Kim", "Seungone Kim"], "title": "FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS", "categories": ["cs.AI"], "comment": "Work In Progress", "summary": "Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in\nmulti-step reasoning and calling search engines at appropriate steps. However,\nexisting retrieval-augmented reasoning approaches rely on separate retrieval\nmodels, limiting the LRM's role in retrieval to deciding when to retrieve and\nhow to query. This separation not only increases hardware and operational costs\nbut also leads to errors in the retrieval process due to the representation\nbottleneck, a phenomenon where the retriever's embedding space is not\nexpressive enough to meet the generator's requirements. To address this, we\nshift our perspective from sequence-to-sequence matching to locating the\nanswer-containing paths within the corpus, and propose a novel framework called\nFREESON (Retriever-FREE Retrieval-Augmented ReaSONing). This framework enables\nLRMs to retrieve relevant knowledge on their own by acting as both a generator\nand retriever. To achieve this, we introduce a variant of the MCTS algorithm\nspecialized for the retrieval task, which we call CT-MCTS (Corpus-Traversing\nMonte Carlo Tree Search). In this algorithm, LRMs traverse through the corpus\ntoward answer-containing regions. Our results on five open-domain QA\nbenchmarks, including single-hop and multi-hop questions, show that FREESON\nachieves an average improvement of 14.4% in EM and F1 over four multi-step\nreasoning models with a separate retriever, and it also performs comparably to\nthe strongest baseline, surpassing it by 3% on PopQA and 2WikiMultihopQA.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6FREESON\uff0c\u8be5\u6846\u67b6\u5141\u8bb8\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u81ea\u884c\u68c0\u7d22\u76f8\u5173\u4fe1\u606f\uff0c\u4ece\u800c\u63d0\u9ad8\u591a\u6b65\u63a8\u7406\u548c\u5f00\u653e\u57df\u95ee\u7b54\u4efb\u52a1\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u68c0\u7d22\u589e\u5f3a\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5355\u72ec\u7684\u68c0\u7d22\u6a21\u578b\uff0c\u8fd9\u9650\u5236\u4e86LRMs\u5728\u68c0\u7d22\u4e2d\u7684\u4f5c\u7528\uff0c\u5e76\u5bfc\u81f4\u786c\u4ef6\u548c\u8fd0\u8425\u6210\u672c\u589e\u52a0\u4ee5\u53ca\u68c0\u7d22\u9519\u8bef\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6846\u67b6FREESON\uff0c\u5b83\u4f7fLRMs\u80fd\u591f\u540c\u65f6\u4f5c\u4e3a\u751f\u6210\u5668\u548c\u68c0\u7d22\u5668\u5de5\u4f5c\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u540d\u4e3aCT-MCTS\u7684\u7b97\u6cd5\u6765\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002", "result": "\u5728\u4e94\u4e2a\u5f00\u653e\u57df\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFREESON\u5e73\u5747\u63d0\u9ad8\u4e8614.4\uff05\u7684EM\u548cF1\u5f97\u5206\uff0c\u5e76\u4e14\u5728PopQA\u548c2WikiMultihopQA\u4e0a\u6bd4\u6700\u5f3a\u57fa\u7ebf\u9ad8\u51fa3\uff05\u3002", "conclusion": "\u901a\u8fc7\u6539\u53d8\u89c6\u89d2\u5e76\u63d0\u51fa\u65b0\u7684\u6846\u67b6\u548c\u7b97\u6cd5\uff0c\u6210\u529f\u5730\u63d0\u9ad8\u4e86LRMs\u5728\u591a\u6b65\u63a8\u7406\u548c\u5f00\u653e\u57df\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2505.16159", "pdf": "https://arxiv.org/pdf/2505.16159", "abs": "https://arxiv.org/abs/2505.16159", "authors": ["Chongjie Si", "Yidan Cui", "Fuchao Yang", "Xiaokang Yang", "Wei Shen"], "title": "Why Can Accurate Models Be Learned from Inaccurate Annotations?", "categories": ["cs.LG"], "comment": null, "summary": "Learning from inaccurate annotations has gained significant attention due to\nthe high cost of precise labeling. However, despite the presence of erroneous\nlabels, models trained on noisy data often retain the ability to make accurate\npredictions. This intriguing phenomenon raises a fundamental yet largely\nunexplored question: why models can still extract correct label information\nfrom inaccurate annotations remains unexplored. In this paper, we conduct a\ncomprehensive investigation into this issue. By analyzing weight matrices from\nboth empirical and theoretical perspectives, we find that label inaccuracy\nprimarily accumulates noise in lower singular components and subtly perturbs\nthe principal subspace. Within a certain range, the principal subspaces of\nweights trained on inaccurate labels remain largely aligned with those learned\nfrom clean labels, preserving essential task-relevant information. We formally\nprove that the angles of principal subspaces exhibit minimal deviation under\nmoderate label inaccuracy, explaining why models can still generalize\neffectively. Building on these insights, we propose LIP, a lightweight plug-in\ndesigned to help classifiers retain principal subspace information while\nmitigating noise induced by label inaccuracy. Extensive experiments on tasks\nwith various inaccuracy conditions demonstrate that LIP consistently enhances\nthe performance of existing algorithms. We hope our findings can offer valuable\ntheoretical and practical insights to understand of model robustness under\ninaccurate supervision.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4ece\u4e0d\u51c6\u786e\u6807\u6ce8\u4e2d\u5b66\u4e60\u7684\u73b0\u8c61\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u63d2\u4ef6LIP\u6765\u5e2e\u52a9\u5206\u7c7b\u5668\u5728\u5b58\u5728\u6807\u7b7e\u4e0d\u51c6\u786e\u7684\u60c5\u51b5\u4e0b\u4fdd\u6301\u4e3b\u5b50\u7a7a\u95f4\u4fe1\u606f\u5e76\u51cf\u8f7b\u566a\u58f0\u5f71\u54cd\u3002", "motivation": "\u7531\u4e8e\u7cbe\u786e\u6807\u8bb0\u7684\u6210\u672c\u9ad8\u6602\uff0c\u57fa\u4e8e\u4e0d\u51c6\u786e\u6807\u6ce8\u7684\u5b66\u4e60\u5f15\u8d77\u4e86\u5e7f\u6cdb\u5173\u6ce8\u3002\u7136\u800c\uff0c\u5c3d\u7ba1\u5b58\u5728\u9519\u8bef\u6807\u7b7e\uff0c\u6a21\u578b\u4ecd\u80fd\u4fdd\u7559\u51c6\u786e\u9884\u6d4b\u7684\u80fd\u529b\uff0c\u8fd9\u4e00\u73b0\u8c61\u80cc\u540e\u7684\u539f\u56e0\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u901a\u8fc7\u4ece\u7ecf\u9a8c\u6027\u548c\u7406\u8bba\u6027\u4e24\u4e2a\u89d2\u5ea6\u5206\u6790\u6743\u91cd\u77e9\u9635\uff0c\u53d1\u73b0\u6807\u7b7e\u4e0d\u51c6\u786e\u6027\u4e3b\u8981\u7d2f\u79ef\u5728\u8f83\u4f4e\u5947\u5f02\u503c\u5206\u91cf\u4e2d\uff0c\u5e76\u5fae\u5999\u5730\u6270\u52a8\u4e3b\u5b50\u7a7a\u95f4\u3002\u63d0\u51fa\u4e86LIP\u63d2\u4ef6\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u9002\u5ea6\u6807\u7b7e\u4e0d\u51c6\u786e\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3b\u5b50\u7a7a\u95f4\u7684\u89d2\u5ea6\u504f\u5dee\u6700\u5c0f\uff0c\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u6a21\u578b\u4ecd\u7136\u53ef\u4ee5\u6709\u6548\u5730\u63a8\u5e7f\u3002\u5b9e\u9a8c\u8868\u660e\uff0cLIP\u5728\u5404\u79cd\u4e0d\u51c6\u786e\u6761\u4ef6\u4e0b\u90fd\u80fd\u63d0\u9ad8\u73b0\u6709\u7b97\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u63d0\u4f9b\u4e86\u5bf9\u6a21\u578b\u5728\u4e0d\u51c6\u786e\u76d1\u7763\u4e0b\u9c81\u68d2\u6027\u7684\u6709\u4ef7\u503c\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u89c1\u89e3\u3002"}}
{"id": "2505.16448", "pdf": "https://arxiv.org/pdf/2505.16448", "abs": "https://arxiv.org/abs/2505.16448", "authors": ["Renfei Dang", "Shujian Huang", "Jiajun Chen"], "title": "Internal Bias in Reasoning Models leads to Overthinking", "categories": ["cs.AI"], "comment": null, "summary": "While current reasoning models possess strong exploratory capabilities, they\nare often criticized for overthinking due to redundant and unnecessary\nreflections. In this work, we reveal for the first time that overthinking in\nreasoning models may stem from their internal bias towards input texts. Upon\nencountering a reasoning problem, the model immediately forms a preliminary\nguess about the answer, which we term as an internal bias since it is not\nderived through actual reasoning. When this guess conflicts with its reasoning\nresult, the model tends to engage in reflection, leading to the waste of\ncomputational resources. Through further interpretability experiments, we find\nthat this behavior is largely driven by the model's excessive attention to the\ninput section, which amplifies the influence of internal bias on its\ndecision-making process. Additionally, by masking out the original input\nsection, the affect of internal bias can be effectively alleviated and the\nreasoning length could be reduced by 31%-53% across different complex reasoning\ntasks. Notably, in most cases, this approach also leads to improvements in\naccuracy. These findings demonstrate a causal relationship between internal\nbias and overthinking.", "AI": {"tldr": "This paper explores the issue of overthinking in reasoning models, identifying internal bias as the cause and demonstrating that reducing attention to input text can mitigate overthinking while improving accuracy.", "motivation": "To address the problem of overthinking in reasoning models due to internal bias.", "method": "Analyzing the impact of internal bias on reasoning models and experimenting with masking input sections.", "result": "Reduction in reasoning length by 31%-53% and improvement in accuracy in most cases.", "conclusion": "Internal bias significantly contributes to overthinking in reasoning models, and mitigating this bias can enhance efficiency and performance."}}
{"id": "2505.16190", "pdf": "https://arxiv.org/pdf/2505.16190", "abs": "https://arxiv.org/abs/2505.16190", "authors": ["Navid Seidi", "Satyaki Roy", "Sajal Das"], "title": "Enhancing Federated Survival Analysis through Peer-Driven Client Reputation in Healthcare", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) holds great promise for digital health by enabling\ncollaborative model training without compromising patient data privacy.\nHowever, heterogeneity across institutions, lack of sustained reputation, and\nunreliable contributions remain major challenges. In this paper, we propose a\nrobust, peer-driven reputation mechanism for federated healthcare that employs\na hybrid communication model to integrate decentralized peer feedback with\nclustering-based noise handling to enhance model aggregation. Crucially, our\napproach decouples the federated aggregation and reputation mechanisms by\napplying differential privacy to client-side model updates before sharing them\nfor peer evaluation. This ensures sensitive information remains protected\nduring reputation computation, while unaltered updates are sent to the server\nfor global model training. Using the Cox Proportional Hazards model for\nsurvival analysis across multiple federated nodes, our framework addresses both\ndata heterogeneity and reputation deficit by dynamically adjusting trust scores\nbased on local performance improvements measured via the concordance index.\nExperimental evaluations on both synthetic datasets and the SEER dataset\ndemonstrate that our method consistently achieves high and stable C-index\nvalues, effectively down-weighing noisy client updates and outperforming FL\nmethods that lack a reputation system.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8054\u90a6\u533b\u7597\u4fdd\u5065\u7684\u9c81\u68d2\u540c\u884c\u9a71\u52a8\u7684\u58f0\u8a89\u673a\u5236\uff0c\u8be5\u673a\u5236\u91c7\u7528\u6df7\u5408\u901a\u4fe1\u6a21\u578b\u6574\u5408\u5206\u6563\u7684\u540c\u884c\u53cd\u9988\uff0c\u5e76\u901a\u8fc7\u5dee\u5206\u9690\u79c1\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\uff0c\u540c\u65f6\u52a8\u6001\u8c03\u6574\u4fe1\u4efb\u5206\u6570\u4ee5\u5e94\u5bf9\u6570\u636e\u5f02\u8d28\u6027\u548c\u58f0\u8a89\u8d64\u5b57\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u6570\u636e\u96c6\u548cSEER\u6570\u636e\u96c6\u4e0a\u5747\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u5728\u6570\u5b57\u5065\u5eb7\u4e2d\u7684\u673a\u6784\u5f02\u8d28\u6027\u3001\u6301\u7eed\u58f0\u8a89\u7f3a\u4e4f\u53ca\u8d21\u732e\u4e0d\u53ef\u9760\u7b49\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u901a\u4fe1\u6a21\u578b\u7684\u58f0\u8a89\u673a\u5236\uff0c\u91c7\u7528\u5dee\u5206\u9690\u79c1\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u5e76\u52a8\u6001\u8c03\u6574\u4fe1\u4efb\u5206\u6570\u3002", "result": "\u5728\u591a\u4e2a\u8054\u90a6\u8282\u70b9\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u4e14\u7a33\u5b9a\u7684C-index\u503c\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u566a\u58f0\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u5f71\u54cd\u3002", "conclusion": "\u63d0\u51fa\u7684\u58f0\u8a89\u673a\u5236\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u5f02\u8d28\u6027\u548c\u58f0\u8a89\u95ee\u9898\u3002"}}
{"id": "2505.16455", "pdf": "https://arxiv.org/pdf/2505.16455", "abs": "https://arxiv.org/abs/2505.16455", "authors": ["Mengzhu Liu", "Zhengqiu Zhu", "Chuan Ai", "Chen Gao", "Xinghong Li", "Lingnan He", "Kaisheng Lai", "Yingfeng Chen", "Xin Lu", "Yong Li", "Quanjun Yin"], "title": "Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media during Sudden Disaster Events", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "During sudden disaster events, accurately predicting public panic sentiment\non social media is crucial for proactive governance and crisis management.\nCurrent efforts on this problem face three main challenges: lack of finely\nannotated data hinders emotion prediction studies, unmodeled risk perception\ncauses prediction inaccuracies, and insufficient interpretability of panic\nformation mechanisms. We address these issues by proposing a Psychology-driven\ngenerative Agent framework (PsychoAgent) for explainable panic prediction based\non emotion arousal theory. Specifically, we first construct a fine-grained open\npanic emotion dataset (namely COPE) via human-large language models (LLMs)\ncollaboration to mitigate semantic bias. Then, we develop a framework\nintegrating cross-domain heterogeneous data grounded in psychological\nmechanisms to model risk perception and cognitive differences in emotion\ngeneration. To enhance interpretability, we design an LLM-based role-playing\nagent that simulates individual psychological chains through dedicatedly\ndesigned prompts. Experimental results on our annotated dataset show that\nPsychoAgent improves panic emotion prediction performance by 12.6% to 21.7%\ncompared to baseline models. Furthermore, the explainability and generalization\nof our approach is validated. Crucially, this represents a paradigm shift from\nopaque \"data-driven fitting\" to transparent \"role-based simulation with\nmechanistic interpretation\" for panic emotion prediction during emergencies.\nOur implementation is publicly available at:\nhttps://anonymous.4open.science/r/PsychoAgent-19DD.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u60c5\u7eea\u5524\u9192\u7406\u8bba\u7684\u5fc3\u7406\u9a71\u52a8\u751f\u6210\u4ee3\u7406\u6846\u67b6\uff08PsychoAgent\uff09\uff0c\u7528\u4e8e\u53ef\u89e3\u91ca\u7684\u6050\u614c\u9884\u6d4b\uff0c\u89e3\u51b3\u4e86\u6807\u6ce8\u6570\u636e\u4e0d\u8db3\u3001\u98ce\u9669\u611f\u77e5\u672a\u5efa\u6a21\u548c\u6050\u614c\u5f62\u6210\u673a\u5236\u89e3\u91ca\u6027\u5dee\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0cPsychoAgent\u5728\u6050\u614c\u60c5\u7eea\u9884\u6d4b\u6027\u80fd\u4e0a\u63d0\u9ad8\u4e8612.6%\u523021.7%\u3002", "motivation": "\u51c6\u786e\u9884\u6d4b\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u516c\u4f17\u6050\u614c\u60c5\u7eea\u5bf9\u4e8e\u7a81\u53d1\u4e8b\u4ef6\u4e2d\u7684\u4e3b\u52a8\u6cbb\u7406\u548c\u5371\u673a\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u5b58\u5728\u6807\u6ce8\u6570\u636e\u4e0d\u8db3\u3001\u98ce\u9669\u611f\u77e5\u672a\u5efa\u6a21\u548c\u9884\u6d4b\u89e3\u91ca\u6027\u5dee\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u60c5\u7eea\u5524\u9192\u7406\u8bba\u7684\u5fc3\u7406\u9a71\u52a8\u751f\u6210\u4ee3\u7406\u6846\u67b6\uff08PsychoAgent\uff09\uff0c\u5305\u62ec\u6784\u5efa\u7ec6\u7c92\u5ea6\u5f00\u653e\u6050\u614c\u60c5\u7eea\u6570\u636e\u96c6\uff08COPE\uff09\u4ee5\u51cf\u8f7b\u8bed\u4e49\u504f\u5dee\uff0c\u5f00\u53d1\u6574\u5408\u8de8\u9886\u57df\u5f02\u6784\u6570\u636e\u7684\u5fc3\u7406\u5b66\u673a\u5236\u6846\u67b6\u4ee5\u5efa\u6a21\u98ce\u9669\u611f\u77e5\u548c\u8ba4\u77e5\u5dee\u5f02\uff0c\u4ee5\u53ca\u8bbe\u8ba1\u57fa\u4e8eLLM\u7684\u89d2\u8272\u626e\u6f14\u6e38\u620f\u4ee3\u7406\u4ee5\u589e\u5f3a\u89e3\u91ca\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cPsychoAgent\u6bd4\u57fa\u7ebf\u6a21\u578b\u5728\u6050\u614c\u60c5\u7eea\u9884\u6d4b\u6027\u80fd\u4e0a\u63d0\u5347\u4e8612.6%\u523021.7%\uff0c\u5e76\u4e14\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4ee3\u8868\u4e86\u4ece\u201c\u6570\u636e\u9a71\u52a8\u62df\u5408\u201d\u5230\u201c\u57fa\u4e8e\u89d2\u8272\u6a21\u62df\u5e76\u5177\u6709\u673a\u5236\u89e3\u91ca\u201d\u7684\u6050\u614c\u60c5\u7eea\u9884\u6d4b\u8303\u5f0f\u8f6c\u53d8\u3002"}}
{"id": "2505.16459", "pdf": "https://arxiv.org/pdf/2505.16459", "abs": "https://arxiv.org/abs/2505.16459", "authors": ["Guiyao Tie", "Xueyang Zhou", "Tianhe Gu", "Ruihang Zhang", "Chaoran Hu", "Sizhe Zhang", "Mengqu Sun", "Yan Zhang", "Pan Zhou", "Lichao Sun"], "title": "MMMR: Benchmarking Massive Multi-Modal Reasoning Tasks", "categories": ["cs.AI"], "comment": "39 pages, 28 figures, 4 tables", "summary": "Recent advances in Multi-Modal Large Language Models (MLLMs) have enabled\nunified processing of language, vision, and structured inputs, opening the door\nto complex tasks such as logical deduction, spatial reasoning, and scientific\nanalysis. Despite their promise, the reasoning capabilities of MLLMs,\nparticularly those augmented with intermediate thinking traces (MLLMs-T),\nremain poorly understood and lack standardized evaluation benchmarks. Existing\nwork focuses primarily on perception or final answer correctness, offering\nlimited insight into how models reason or fail across modalities. To address\nthis gap, we introduce the MMMR, a new benchmark designed to rigorously\nevaluate multi-modal reasoning with explicit thinking. The MMMR comprises 1) a\nhigh-difficulty dataset of 1,083 questions spanning six diverse reasoning types\nwith symbolic depth and multi-hop demands and 2) a modular Reasoning Trace\nEvaluation Pipeline (RTEP) for assessing reasoning quality beyond accuracy\nthrough metrics like relevance, consistency, and structured error annotations.\nEmpirical results show that MLLMs-T overall outperform non-thinking\ncounterparts, but even top models like Claude-3.7-Sonnet and Gemini-2.5 Pro\nsuffer from reasoning pathologies such as inconsistency and overthinking. This\nbenchmark reveals persistent gaps between accuracy and reasoning quality and\nprovides an actionable evaluation pipeline for future model development.\nOverall, the MMMR offers a scalable foundation for evaluating, comparing, and\nimproving the next generation of multi-modal reasoning systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6MMMR\u6765\u8bc4\u4f30\u591a\u6a21\u6001\u63a8\u7406\uff0c\u5305\u542b\u9ad8\u96be\u5ea6\u6570\u636e\u96c6\u548c\u63a8\u7406\u75d5\u8ff9\u8bc4\u4f30\u6d41\u7a0b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u6709\u4e2d\u95f4\u601d\u7ef4\u75d5\u8ff9\u7684\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u9876\u7ea7\u6a21\u578b\u4ecd\u5b58\u5728\u63a8\u7406\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u7406\u89e3\u6709\u9650\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u51c6\u3002", "method": "\u5f15\u5165MMMR\u57fa\u51c6\uff0c\u5305\u62ec\u9ad8\u96be\u5ea6\u6570\u636e\u96c6\u548c\u63a8\u7406\u75d5\u8ff9\u8bc4\u4f30\u6d41\u7a0b\u3002", "result": "\u6709\u4e2d\u95f4\u601d\u7ef4\u75d5\u8ff9\u7684\u6a21\u578b\u6574\u4f53\u8868\u73b0\u4f18\u4e8e\u65e0\u601d\u7ef4\u75d5\u8ff9\u7684\u6a21\u578b\uff0c\u4f46\u9876\u7ea7\u6a21\u578b\u5728\u4e00\u81f4\u6027\u7b49\u65b9\u9762\u5b58\u5728\u95ee\u9898\u3002", "conclusion": "MMMR\u4e3a\u4e0b\u4e00\u4ee3\u591a\u6a21\u6001\u63a8\u7406\u7cfb\u7edf\u7684\u8bc4\u4f30\u3001\u6bd4\u8f83\u548c\u6539\u8fdb\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2505.16210", "pdf": "https://arxiv.org/pdf/2505.16210", "abs": "https://arxiv.org/abs/2505.16210", "authors": ["Zhihang Cai", "Xingjun Zhang", "Zhendong Tan", "Zheng Wei"], "title": "NQKV: A KV Cache Quantization Scheme Based on Normal Distribution Characteristics", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "11 pages, 9 figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable proficiency across\na wide range of tasks. However, LLMs often require larger batch sizes to\nenhance throughput or longer context lengths to meet task demands, which\nsignificantly increases the memory resource consumption of the Key-Value (KV)\ncache during inference, becoming a major bottleneck in LLM deployment. To\naddress this issue, quantization is a common and straightforward approach.\nCurrently, quantization methods for activations are limited to 8-bit, and\nquantization to even lower bits can lead to substantial accuracy drops. To\nfurther save space by quantizing the KV cache to even lower bits, we analyzed\nthe element distribution of the KV cache and designed the NQKV algorithm. Since\nthe elements within each block of the KV cache follow a normal distribution,\nNQKV employs per-block quantile quantization to achieve\ninformation-theoretically optimal quantization error. Without significantly\ncompromising model output quality, NQKV enables the OPT model to perform\ninference with an 2x larger batch size or a 4x longer context length, and it\nimproves throughput by 9.3x compared to when the KV cache is not used.", "AI": {"tldr": "This paper presents NQKV, a new algorithm that uses per-block quantile quantization to enable more efficient inference in large language models.", "motivation": "To reduce memory resource consumption of the Key-Value (KV) cache during inference which has become a major bottleneck in LLM deployment.", "method": "Analyzed the element distribution of the KV cache and designed the NQKV algorithm which employs per-block quantile quantization to achieve information-theoretically optimal quantization error.", "result": "Without significantly compromising model output quality, NQKV enables the OPT model to perform inference with an 2x larger batch size or a 4x longer context length, and it improves throughput by 9.3x compared to when the KV cache is not used.", "conclusion": "The proposed NQKV algorithm achieves significant improvements in throughput while maintaining model output quality."}}
{"id": "2505.16475", "pdf": "https://arxiv.org/pdf/2505.16475", "abs": "https://arxiv.org/abs/2505.16475", "authors": ["Jiaqi Li", "Xinyi Dong", "Yang Liu", "Zhizhuo Yang", "Quansen Wang", "Xiaobo Wang", "SongChun Zhu", "Zixia Jia", "Zilong Zheng"], "title": "ReflectEvo: Improving Meta Introspection of Small LLMs by Learning Self-Reflection", "categories": ["cs.AI"], "comment": null, "summary": "We present a novel pipeline, ReflectEvo, to demonstrate that small language\nmodels (SLMs) can enhance meta introspection through reflection learning. This\nprocess iteratively generates self-reflection for self-training, fostering a\ncontinuous and self-evolving process. Leveraging this pipeline, we construct\nReflectEvo-460k, a large-scale, comprehensive, self-generated reflection\ndataset with broadened instructions and diverse multi-domain tasks. Building\nupon this dataset, we demonstrate the effectiveness of reflection learning to\nimprove SLMs' reasoning abilities using SFT and DPO with remarkable\nperformance, substantially boosting Llama-3 from 52.4% to 71.2% and Mistral\nfrom 44.4% to 71.1%. It validates that ReflectEvo can rival or even surpass the\nreasoning capability of the three prominent open-sourced models on BIG-bench\nwithout distillation from superior models or fine-grained human annotation. We\nfurther conduct a deeper analysis of the high quality of self-generated\nreflections and their impact on error localization and correction. Our work\nhighlights the potential of continuously enhancing the reasoning performance of\nSLMs through iterative reflection learning in the long run.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ba1\u9053ReflectEvo\uff0c\u8bc1\u660e\u5c0f\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u53cd\u5c04\u5b66\u4e60\u589e\u5f3a\u5143\u5185\u7701\u80fd\u529b\u3002\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21\u81ea\u6211\u751f\u6210\u7684\u53cd\u5c04\u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528SFT\u548cDPO\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86Llama-3\u548cMistral\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u65e0\u9700\u4ece\u66f4\u4f18\u6a21\u578b\u84b8\u998f\u6216\u7cbe\u7ec6\u7684\u4eba\u7c7b\u6ce8\u91ca\u3002", "motivation": "\u8bc1\u660e\u5c0f\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u53cd\u5c04\u5b66\u4e60\u589e\u5f3a\u5143\u5185\u7701\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aReflectEvo\u7684\u65b0\u7ba1\u9053\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u5168\u9762\u7684\u81ea\u6211\u751f\u6210\u53cd\u5c04\u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528\u4e86SFT\u548cDPO\u65b9\u6cd5\u3002", "result": "\u663e\u8457\u63d0\u9ad8\u4e86Llama-3\u548cMistral\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5206\u522b\u4ece52.4%\u63d0\u5347\u523071.2%\uff0c\u4ece44.4%\u63d0\u5347\u523071.1%\uff0c\u4e14\u5728BIG-bench\u4e0a\u4e0e\u4e09\u4e2a\u5f00\u6e90\u6a21\u578b\u76f8\u5f53\u751a\u81f3\u8d85\u8d8a\u3002", "conclusion": "\u6301\u7eed\u901a\u8fc7\u8fed\u4ee3\u53cd\u5c04\u5b66\u4e60\u53ef\u4ee5\u63d0\u9ad8\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u3002"}}
{"id": "2505.16217", "pdf": "https://arxiv.org/pdf/2505.16217", "abs": "https://arxiv.org/abs/2505.16217", "authors": ["Hon Tik Tse", "Siddarth Chandrasekar", "Marlos C. Machado"], "title": "Reward-Aware Proto-Representations in Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, the successor representation (SR) has attracted increasing\nattention in reinforcement learning (RL), and it has been used to address some\nof its key challenges, such as exploration, credit assignment, and\ngeneralization. The SR can be seen as representing the underlying credit\nassignment structure of the environment by implicitly encoding its induced\ntransition dynamics. However, the SR is reward-agnostic. In this paper, we\ndiscuss a similar representation that also takes into account the reward\ndynamics of the problem. We study the default representation (DR), a recently\nproposed representation with limited theoretical (and empirical) analysis.\nHere, we lay some of the theoretical foundation underlying the DR in the\ntabular case by (1) deriving dynamic programming and (2) temporal-difference\nmethods to learn the DR, (3) characterizing the basis for the vector space of\nthe DR, and (4) formally extending the DR to the function approximation case\nthrough default features. Empirically, we analyze the benefits of the DR in\nmany of the settings in which the SR has been applied, including (1) reward\nshaping, (2) option discovery, (3) exploration, and (4) transfer learning. Our\nresults show that, compared to the SR, the DR gives rise to qualitatively\ndifferent, reward-aware behaviour and quantitatively better performance in\nseveral settings.", "AI": {"tldr": "This paper introduces the Default Representation (DR), which extends the Successor Representation (SR) by incorporating reward dynamics. The authors provide theoretical foundations for the DR in tabular and function approximation cases and empirically demonstrate its advantages in various RL tasks.", "motivation": "To address the limitation of the SR being reward-agnostic and introduce a reward-aware representation.", "method": "Theoretical derivation of dynamic programming and temporal-difference methods for DR, characterization of its vector space basis, and extension to function approximation through default features.", "result": "DR shows qualitatively different and quantitatively better performance than SR in tasks like reward shaping, option discovery, exploration, and transfer learning.", "conclusion": "The DR offers a reward-aware alternative to the SR with improved performance in several reinforcement learning settings."}}
{"id": "2505.16477", "pdf": "https://arxiv.org/pdf/2505.16477", "abs": "https://arxiv.org/abs/2505.16477", "authors": ["Yanbo Zhang", "Sumeer A. Khan", "Adnan Mahmud", "Huck Yang", "Alexander Lavin", "Michael Levin", "Jeremy Frey", "Jared Dunnmon", "James Evans", "Alan Bundy", "Saso Dzeroski", "Jesper Tegner", "Hector Zenil"], "title": "Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery", "categories": ["cs.AI"], "comment": "45 pages", "summary": "With recent Nobel Prizes recognising AI contributions to science, Large\nLanguage Models (LLMs) are transforming scientific research by enhancing\nproductivity and reshaping the scientific method. LLMs are now involved in\nexperimental design, data analysis, and workflows, particularly in chemistry\nand biology. However, challenges such as hallucinations and reliability\npersist. In this contribution, we review how Large Language Models (LLMs) are\nredefining the scientific method and explore their potential applications\nacross different stages of the scientific cycle, from hypothesis testing to\ndiscovery. We conclude that, for LLMs to serve as relevant and effective\ncreative engines and productivity enhancers, their deep integration into all\nsteps of the scientific process should be pursued in collaboration and\nalignment with human scientific goals, with clear evaluation metrics. The\ntransition to AI-driven science raises ethical questions about creativity,\noversight, and responsibility. With careful guidance, LLMs could evolve into\ncreative engines, driving transformative breakthroughs across scientific\ndisciplines responsibly and effectively. However, the scientific community must\nalso decide how much it leaves to LLMs to drive science, even when associations\nwith 'reasoning', mostly currently undeserved, are made in exchange for the\npotential to explore hypothesis and solution regions that might otherwise\nremain unexplored by human exploration alone.", "AI": {"tldr": "Large Language Models (LLMs) are revolutionizing scientific research by improving productivity and altering the scientific method, especially in chemistry and biology. Despite challenges like hallucinations and reliability issues, they have potential applications throughout the scientific process. For LLMs to be effective creative tools, their integration needs to align with human scientific goals and include clear evaluation metrics. Ethical considerations around oversight and responsibility are necessary as AI-driven science evolves.", "motivation": "AI contributions recognized by Nobel Prizes motivate the exploration of how LLMs can enhance productivity and reshape the scientific method.", "method": "Reviewing how LLMs redefine the scientific method and exploring their potential applications across various stages of the scientific cycle.", "result": "LLMs show promise in experimental design, data analysis, and workflows but face challenges such as hallucinations and reliability issues.", "conclusion": "For LLMs to become effective creative engines and productivity enhancers, their integration into the scientific process must align with human goals and include clear evaluation metrics. Ethical considerations about creativity, oversight, and responsibility are essential."}}
{"id": "2505.16226", "pdf": "https://arxiv.org/pdf/2505.16226", "abs": "https://arxiv.org/abs/2505.16226", "authors": ["Zi-Jian Cheng", "Zi-Yi Jia", "Zhi Zhou", "Yu-Feng Li", "Lan-Zhe Guo"], "title": "Realistic Evaluation of TabPFN v2 in Open Environments", "categories": ["cs.LG"], "comment": null, "summary": "Tabular data, owing to its ubiquitous presence in real-world domains, has\ngarnered significant attention in machine learning research. While tree-based\nmodels have long dominated tabular machine learning tasks, the recently\nproposed deep learning model TabPFN v2 has emerged, demonstrating unparalleled\nperformance and scalability potential. Although extensive research has been\nconducted on TabPFN v2 to further improve performance, the majority of this\nresearch remains confined to closed environments, neglecting the challenges\nthat frequently arise in open environments. This raises the question: Can\nTabPFN v2 maintain good performance in open environments? To this end, we\nconduct the first comprehensive evaluation of TabPFN v2's adaptability in open\nenvironments. We construct a unified evaluation framework covering various\nreal-world challenges and assess the robustness of TabPFN v2 under open\nenvironments scenarios using this framework. Empirical results demonstrate that\nTabPFN v2 shows significant limitations in open environments but is suitable\nfor small-scale, covariate-shifted, and class-balanced tasks. Tree-based models\nremain the optimal choice for general tabular tasks in open environments. To\nfacilitate future research on open environments challenges, we advocate for\nopen environments tabular benchmarks, multi-metric evaluation, and universal\nmodules to strengthen model robustness. We publicly release our evaluation\nframework at https://anonymous.4open.science/r/tabpfn-ood-4E65.", "AI": {"tldr": "This paper evaluates TabPFN v2's adaptability in open environments and finds it unsuitable for most real-world challenges, though it can handle small-scale, covariate-shifted, and class-balanced tasks.", "motivation": "To investigate whether TabPFN v2 maintains good performance in open environments where real-world challenges like data distribution shifts are common.", "method": "Constructing a unified evaluation framework covering various real-world challenges to assess TabPFN v2's robustness in open environment scenarios.", "result": "TabPFN v2 shows significant limitations in open environments, being only suitable for small-scale, covariate-shifted, and class-balanced tasks.", "conclusion": "Tree-based models remain superior for general tabular tasks in open environments, and open environments tabular benchmarks, multi-metric evaluation, and universal modules are recommended to enhance model robustness."}}
{"id": "2505.16482", "pdf": "https://arxiv.org/pdf/2505.16482", "abs": "https://arxiv.org/abs/2505.16482", "authors": ["Huynh Thi Thanh Binh", "Le Van Cuong", "Dang Hai Dang", "Le Trong Vinh"], "title": "Minimizing the energy depletion in wireless rechargeable sensor networks using bi-level metaheuristic charging schemes", "categories": ["cs.AI", "cs.NE"], "comment": null, "summary": "Recently, Wireless Rechargeable Sensor Networks (WRSNs) that leveraged the\nadvantage of wireless energy transfer technology have opened a promising\nopportunity in solving the limited energy issue. However, an ineffective\ncharging strategy may reduce the charging performance. Although many practical\ncharging algorithms have been introduced, these studies mainly focus on\noptimizing the charging path with a fully charging approach. This approach may\nlead to the death of a series of sensors due to their extended charging\nlatency. This paper introduces a novel partial charging approach that follows a\nbi-level optimized scheme to minimize energy depletion in WRSNs. We aim at\noptimizing simultaneously two factors: the charging path and time. To\naccomplish this, we first formulate a mathematical model of the investigated\nproblem. We then propose two approximate algorithms in which the optimization\nof the charging path and the charging time are considered as the upper and\nlower level, respectively. The first algorithm combines a Multi-start Local\nSearch method and a Genetic Algorithm to find a solution. The second algorithm\nadopts a nested approach that utilizes the advantages of the Multitasking and\nCovariance Matrix Adaptation Evolutionary Strategies. Experimental validations\non various network scenarios demonstrate that our proposed algorithms\noutperform the existing works.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u90e8\u5206\u5145\u7535\u65b9\u6cd5\uff0c\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u65b9\u6848\u4ee5\u6700\u5c0f\u5316WRSNs\u4e2d\u7684\u80fd\u91cf\u6d88\u8017\u3002\u540c\u65f6\u4f18\u5316\u4e86\u5145\u7535\u8def\u5f84\u548c\u65f6\u95f4\uff0c\u5e76\u901a\u8fc7\u6570\u5b66\u6a21\u578b\u548c\u4e24\u79cd\u8fd1\u4f3c\u7b97\u6cd5\u5b9e\u73b0\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\u6240\u63d0\u7b97\u6cd5\u4f18\u4e8e\u73b0\u6709\u5de5\u4f5c\u3002", "motivation": "\u89e3\u51b3\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u6280\u672f\u5728WRSNs\u4e2d\u7684\u6709\u9650\u80fd\u91cf\u95ee\u9898\uff0c\u907f\u514d\u56e0\u65e0\u6548\u5145\u7535\u7b56\u7565\u5bfc\u81f4\u7684\u4f20\u611f\u5668\u80fd\u8017\u8fc7\u5ea6\u53ca\u6b7b\u4ea1\u73b0\u8c61\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u90e8\u5206\u5145\u7535\u65b9\u6cd5\uff0c\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u65b9\u6848\uff0c\u7ed3\u5408\u591a\u8d77\u70b9\u5c40\u90e8\u641c\u7d22\u4e0e\u9057\u4f20\u7b97\u6cd5\u4ee5\u53ca\u5d4c\u5957\u7684\u591a\u4efb\u52a1\u4e0e\u534f\u65b9\u5dee\u77e9\u9635\u9002\u5e94\u8fdb\u5316\u7b56\u7565\u3002", "result": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u5404\u79cd\u7f51\u7edc\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u6bd4\u73b0\u6709\u5de5\u4f5c\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u51cf\u5c11WRSNs\u7684\u80fd\u91cf\u6d88\u8017\uff0c\u4f18\u5316\u5145\u7535\u8def\u5f84\u548c\u65f6\u95f4\u3002"}}
{"id": "2505.16242", "pdf": "https://arxiv.org/pdf/2505.16242", "abs": "https://arxiv.org/abs/2505.16242", "authors": ["Runze Yan", "Xun Shen", "Akifumi Wachi", "Sebastien Gros", "Anni Zhao", "Xiao Hu"], "title": "Offline Guarded Safe Reinforcement Learning for Medical Treatment Optimization Strategies", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "When applying offline reinforcement learning (RL) in healthcare scenarios,\nthe out-of-distribution (OOD) issues pose significant risks, as inappropriate\ngeneralization beyond clinical expertise can result in potentially harmful\nrecommendations. While existing methods like conservative Q-learning (CQL)\nattempt to address the OOD issue, their effectiveness is limited by only\nconstraining action selection by suppressing uncertain actions. This\naction-only regularization imitates clinician actions that prioritize\nshort-term rewards, but it fails to regulate downstream state trajectories,\nthereby limiting the discovery of improved long-term treatment strategies. To\nsafely improve policy beyond clinician recommendations while ensuring that\nstate-action trajectories remain in-distribution, we propose \\textit{Offline\nGuarded Safe Reinforcement Learning} ($\\mathsf{OGSRL}$), a theoretically\ngrounded model-based offline RL framework. $\\mathsf{OGSRL}$ introduces a novel\ndual constraint mechanism for improving policy with reliability and safety.\nFirst, the OOD guardian is established to specify clinically validated regions\nfor safe policy exploration. By constraining optimization within these regions,\nit enables the reliable exploration of treatment strategies that outperform\nclinician behavior by leveraging the full patient state history, without\ndrifting into unsupported state-action trajectories. Second, we introduce a\nsafety cost constraint that encodes medical knowledge about physiological\nsafety boundaries, providing domain-specific safeguards even in areas where\ntraining data might contain potentially unsafe interventions. Notably, we\nprovide theoretical guarantees on safety and near-optimality: policies that\nsatisfy these constraints remain in safe and reliable regions and achieve\nperformance close to the best possible policy supported by the data.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.16507", "pdf": "https://arxiv.org/pdf/2505.16507", "abs": "https://arxiv.org/abs/2505.16507", "authors": ["Anshu Xiong", "Songmao Zhang"], "title": "Relevance for Stability of Verification Status of a Set of Arguments in Incomplete Argumentation Frameworks (with Proofs)", "categories": ["cs.AI"], "comment": "This is a version of paper 'Relevance for Stability of Verification\n  Status of a Set of Arguments in Incomplete Argumentation Frameworks' extented\n  with proofs of the results in the paper", "summary": "The notion of relevance was proposed for stability of justification status of\na single argument in incomplete argumentation frameworks (IAFs) in 2024 by\nOdekerken et al. To extend the notion, we study the relevance for stability of\nverification status of a set of arguments in this paper, i.e., the\nuncertainties in an IAF that have to be resolved in some situations so that\nanswering whether a given set of arguments is an extension obtains the same\nresult in every completion of the IAF. Further we propose the notion of strong\nrelevance for describing the necessity of resolution in all situations reaching\nstability. An analysis of complexity reveals that detecting the (strong)\nrelevance for stability of sets of arguments can be accomplished in P time\nunder the most semantics discussed in the paper. We also discuss the difficulty\nin finding tractable methods for relevance detection under grounded semantics.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u4e0d\u5b8c\u6574\u8bba\u8bc1\u6846\u67b6\u4e2d\u76f8\u5173\u6027\u7684\u6982\u5ff5\uff0c\u7814\u7a76\u4e86\u4e00\u7ec4\u8bba\u8bc1\u9a8c\u8bc1\u72b6\u6001\u7684\u7a33\u5b9a\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u5f3a\u76f8\u5173\u6027\u7684\u6982\u5ff5\u6765\u63cf\u8ff0\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u89e3\u51b3\u4e0d\u786e\u5b9a\u6027\u7684\u5fc5\u8981\u6027\u3002\u590d\u6742\u6027\u5206\u6790\u8868\u660e\uff0c\u5728\u5927\u591a\u6570\u8bed\u4e49\u4e0b\u68c0\u6d4b\u8bba\u8bc1\u96c6\u7684\u76f8\u5173\u6027\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u5b8c\u6210\u3002", "motivation": "\u5728\u4e0d\u5b8c\u6574\u8bba\u8bc1\u6846\u67b6\u4e2d\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u5355\u4e00\u8bba\u8bc1\u5408\u7406\u6027\u7684\u7a33\u5b9a\u6027\uff0c\u63d0\u51fa\u4e86\u76f8\u5173\u6027\u7684\u6982\u5ff5\u3002\u672c\u6587\u65e8\u5728\u8fdb\u4e00\u6b65\u6269\u5c55\u8fd9\u4e00\u6982\u5ff5\u3002", "method": "\u7814\u7a76\u4e86\u4e00\u7ec4\u8bba\u8bc1\u9a8c\u8bc1\u72b6\u6001\u7684\u7a33\u5b9a\u6027\uff0c\u63d0\u51fa\u4e86\u5f3a\u76f8\u5173\u6027\u7684\u6982\u5ff5\uff0c\u5e76\u8fdb\u884c\u4e86\u590d\u6742\u6027\u5206\u6790\u3002", "result": "\u53d1\u73b0\u68c0\u6d4b\u8bba\u8bc1\u96c6\u76f8\u5173\u6027\u53ef\u4ee5\u5728P\u65f6\u95f4\u5185\u5b8c\u6210\uff0c\u4f46\u5728grounded\u8bed\u4e49\u4e0b\u627e\u5230\u53ef\u5904\u7406\u7684\u76f8\u5173\u6027\u68c0\u6d4b\u65b9\u6cd5\u8f83\u4e3a\u56f0\u96be\u3002", "conclusion": "\u672c\u6587\u6269\u5c55\u4e86\u4e0d\u5b8c\u6574\u8bba\u8bc1\u6846\u67b6\u4e2d\u76f8\u5173\u6027\u7684\u6982\u5ff5\uff0c\u63d0\u51fa\u4e86\u5f3a\u76f8\u5173\u6027\u7684\u6982\u5ff5\uff0c\u5e76\u5206\u6790\u4e86\u5176\u590d\u6742\u6027\u3002"}}
{"id": "2505.16248", "pdf": "https://arxiv.org/pdf/2505.16248", "abs": "https://arxiv.org/abs/2505.16248", "authors": ["Wenxuan Zhu", "Qiyuan Wu", "Tengda Tang", "Renzi Meng", "Sheng Chai", "Xuehui Quan"], "title": "Graph Neural Network-Based Collaborative Perception for Adaptive Scheduling in Distributed Systems", "categories": ["cs.LG"], "comment": null, "summary": "This paper addresses the limitations of multi-node perception and delayed\nscheduling response in distributed systems by proposing a GNN-based multi-node\ncollaborative perception mechanism. The system is modeled as a graph structure.\nMessage-passing and state-update modules are introduced. A multi-layer graph\nneural network is constructed to enable efficient information aggregation and\ndynamic state inference among nodes. In addition, a perception representation\nmethod is designed by fusing local states with global features. This improves\neach node's ability to perceive the overall system status. The proposed method\nis evaluated within a customized experimental framework. A dataset featuring\nheterogeneous task loads and dynamic communication topologies is used.\nPerformance is measured in terms of task completion rate, average latency, load\nbalancing, and transmission efficiency. Experimental results show that the\nproposed method outperforms mainstream algorithms under various conditions,\nincluding limited bandwidth and dynamic structural changes. It demonstrates\nsuperior perception capabilities and cooperative scheduling performance. The\nmodel achieves rapid convergence and efficient responses to complex system\nstates.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u591a\u8282\u70b9\u534f\u4f5c\u611f\u77e5\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u591a\u8282\u70b9\u611f\u77e5\u548c\u5ef6\u8fdf\u8c03\u5ea6\u54cd\u5e94\u7684\u95ee\u9898\u3002\u901a\u8fc7\u6784\u9020\u591a\u5c42\u56fe\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u9ad8\u6548\u7684\u4fe1\u606f\u805a\u5408\u548c\u52a8\u6001\u72b6\u6001\u63a8\u7406\uff0c\u5e76\u8bbe\u8ba1\u4e86\u878d\u5408\u5c40\u90e8\u72b6\u6001\u4e0e\u5168\u5c40\u7279\u5f81\u7684\u611f\u77e5\u8868\u793a\u65b9\u6cd5\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4efb\u52a1\u5b8c\u6210\u7387\u3001\u5e73\u5747\u5ef6\u8fdf\u3001\u8d1f\u8f7d\u5747\u8861\u548c\u4f20\u8f93\u6548\u7387\u7b49\u65b9\u9762\u4f18\u4e8e\u4e3b\u6d41\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u7684\u591a\u8282\u70b9\u611f\u77e5\u548c\u5ef6\u8fdf\u8c03\u5ea6\u54cd\u5e94\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u591a\u8282\u70b9\u534f\u4f5c\u611f\u77e5\u673a\u5236\uff0c\u5305\u62ec\u6d88\u606f\u4f20\u9012\u548c\u72b6\u6001\u66f4\u65b0\u6a21\u5757\uff0c\u4ee5\u53ca\u878d\u5408\u5c40\u90e8\u72b6\u6001\u4e0e\u5168\u5c40\u7279\u5f81\u7684\u611f\u77e5\u8868\u793a\u65b9\u6cd5\u3002", "result": "\u63d0\u51fa\u7684\u673a\u5236\u5728\u4efb\u52a1\u5b8c\u6210\u7387\u3001\u5e73\u5747\u5ef6\u8fdf\u3001\u8d1f\u8f7d\u5747\u8861\u548c\u4f20\u8f93\u6548\u7387\u7b49\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u4e3b\u6d41\u7b97\u6cd5\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u80fd\u591f\u5feb\u901f\u6536\u655b\u5e76\u6709\u6548\u5e94\u5bf9\u590d\u6742\u7cfb\u7edf\u72b6\u6001\uff0c\u5177\u6709\u4f18\u8d8a\u7684\u611f\u77e5\u80fd\u529b\u548c\u534f\u540c\u8c03\u5ea6\u6027\u80fd\u3002"}}
{"id": "2505.16579", "pdf": "https://arxiv.org/pdf/2505.16579", "abs": "https://arxiv.org/abs/2505.16579", "authors": ["Siqu Ou", "Hongcheng Liu", "Pingjie Wang", "Yusheng Liao", "Chuan Xuan", "Yanfeng Wang", "Yu Wang"], "title": "Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning", "categories": ["cs.AI", "cs.CV"], "comment": "19 pages, 8 figures", "summary": "While chains-of-thought (CoT) have advanced complex reasoning in multimodal\nlarge language models (MLLMs), existing methods remain confined to text or\nstatic visual domains, often faltering in dynamic spatial reasoning tasks. To\nbridge this gap, we present GRASSLAND, a novel maze navigation benchmark\ndesigned to evaluate dynamic spatial reasoning. Our experiments show that\naugmenting textual reasoning chains with dynamic visual drafts, overlaid on\ninput images, significantly outperforms conventional approaches, offering new\ninsights into spatial reasoning in evolving environments. To generalize this\ncapability, we propose D2R (Dynamic Draft-Augmented Reasoning), a training-free\nframework that seamlessly integrates textual CoT with corresponding visual\ndrafts into MLLMs. Extensive evaluations demonstrate that D2R consistently\nenhances performance across diverse tasks, establishing a robust baseline for\ndynamic spatial reasoning without requiring model fine-tuning. Project is open\nat https://github.com/Cratileo/D2R.", "AI": {"tldr": "\u63d0\u51faGRASSLAND\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u8bc4\u4f30\u52a8\u6001\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u63d0\u51faD2R\u6846\u67b6\u6765\u589e\u5f3a\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u7a7a\u95f4\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u4e8e\u6587\u672c\u6216\u9759\u6001\u89c6\u89c9\u9886\u57df\uff0c\u5728\u52a8\u6001\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faD2R\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6587\u672c\u63a8\u7406\u94fe\u4e0e\u8f93\u5165\u56fe\u50cf\u4e0a\u7684\u52a8\u6001\u89c6\u89c9\u8349\u56fe\u76f8\u7ed3\u5408\u6765\u589e\u5f3a\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cD2R\u6846\u67b6\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u6301\u7eed\u63d0\u5347\u6027\u80fd\uff0c\u4e3a\u52a8\u6001\u7a7a\u95f4\u63a8\u7406\u5efa\u7acb\u4e86\u7a33\u5065\u7684\u57fa\u7ebf\u3002", "conclusion": "D2R\u65e0\u9700\u6a21\u578b\u5fae\u8c03\u5373\u53ef\u6709\u6548\u63d0\u5347\u591a\u6a21\u6001\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u52a8\u6001\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2505.16260", "pdf": "https://arxiv.org/pdf/2505.16260", "abs": "https://arxiv.org/abs/2505.16260", "authors": ["Alaa Khaddaj", "Logan Engstrom", "Aleksander Madry"], "title": "Small-to-Large Generalization: Data Influences Models Consistently Across Scale", "categories": ["cs.LG"], "comment": null, "summary": "Choice of training data distribution greatly influences model behavior. Yet,\nin large-scale settings, precisely characterizing how changes in training data\naffects predictions is often difficult due to model training costs. Current\npractice is to instead extrapolate from scaled down, inexpensive-to-train proxy\nmodels. However, changes in data do not influence smaller and larger models\nidentically. Therefore, understanding how choice of data affects large-scale\nmodels raises the question: how does training data distribution influence model\nbehavior across compute scale? We find that small- and large-scale language\nmodel predictions (generally) do highly correlate across choice of training\ndata. Equipped with these findings, we characterize how proxy scale affects\neffectiveness in two downstream proxy model applications: data attribution and\ndataset selection.", "AI": {"tldr": "This paper investigates how training data distribution influences model behavior across different compute scales for large-scale language models.", "motivation": "To understand how choice of training data affects large-scale models since changes in data do not influence smaller and larger models identically.", "method": "Correlating small- and large-scale language model predictions across choice of training data.", "result": "Small- and large-scale language model predictions generally highly correlate across choice of training data.", "conclusion": "Proxy scale affects effectiveness in downstream proxy model applications such as data attribution and dataset selection."}}
{"id": "2505.16619", "pdf": "https://arxiv.org/pdf/2505.16619", "abs": "https://arxiv.org/abs/2505.16619", "authors": ["Gavin Farrell", "Eleni Adamidi", "Rafael Andrade Buono", "Mihail Anton", "Omar Abdelghani Attafi", "Salvador Capella Gutierrez", "Emidio Capriotti", "Leyla Jael Castro", "Davide Cirillo", "Lisa Crossman", "Christophe Dessimoz", "Alexandros Dimopoulos", "Raul Fernandez-Diaz", "Styliani-Christina Fragkouli", "Carole Goble", "Wei Gu", "John M. Hancock", "Alireza Khanteymoori", "Tom Lenaerts", "Fabio G. Liberante", "Peter Maccallum", "Alexander Miguel Monzon", "Magnus Palmblad", "Lucy Poveda", "Ovidiu Radulescu", "Denis C. Shields", "Shoaib Sufi", "Thanasis Vergoulis", "Fotis Psomopoulos", "Silvio C. E. Tosatto"], "title": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences", "categories": ["cs.AI", "q-bio.OT", "92", "J.3"], "comment": "1 PDF, 24 Pages, 2 figures within. Co-corresponding authors:\n  Institute of Applied Biosciences, Centre for Research and Technology Hellas,\n  Thessaloniki, Greece and Department of Biomedical Sciences, University of\n  Padova, Padova, Italy. E-mails: fpsom@certh.gr, silvio.tosatto@unipd.it", "summary": "Artificial intelligence (AI) has recently seen transformative breakthroughs\nin the life sciences, expanding possibilities for researchers to interpret\nbiological information at an unprecedented capacity, with novel applications\nand advances being made almost daily. In order to maximise return on the\ngrowing investments in AI-based life science research and accelerate this\nprogress, it has become urgent to address the exacerbation of long-standing\nresearch challenges arising from the rapid adoption of AI methods. We review\nthe increased erosion of trust in AI research outputs, driven by the issues of\npoor reusability and reproducibility, and highlight their consequent impact on\nenvironmental sustainability. Furthermore, we discuss the fragmented components\nof the AI ecosystem and lack of guiding pathways to best support Open and\nSustainable AI (OSAI) model development. In response, this perspective\nintroduces a practical set of OSAI recommendations directly mapped to over 300\ncomponents of the AI ecosystem. Our work connects researchers with relevant AI\nresources, facilitating the implementation of sustainable, reusable and\ntransparent AI. Built upon life science community consensus and aligned to\nexisting efforts, the outputs of this perspective are designed to aid the\nfuture development of policy and structured pathways for guiding AI\nimplementation.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u751f\u547d\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u53ca\u5176\u5e26\u6765\u7684\u4fe1\u4efb\u5371\u673a\u548c\u751f\u6001\u788e\u7247\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u5957\u5f00\u653e\u4e14\u53ef\u6301\u7eed\u7684\u4eba\u5de5\u667a\u80fd\uff08OSAI\uff09\u5efa\u8bae\uff0c\u5e76\u5c06\u5176\u6620\u5c04\u5230\u8d85\u8fc7300\u4e2aAI\u751f\u6001\u7cfb\u7edf\u7ec4\u4ef6\u4e0a\uff0c\u65e8\u5728\u4fc3\u8fdb\u53ef\u6301\u7eed\u3001\u53ef\u91cd\u7528\u548c\u900f\u660e\u7684AI\u53d1\u5c55\u3002", "motivation": "\u52a0\u901fAI\u5728\u751f\u547d\u79d1\u5b66\u9886\u57df\u7684\u8fdb\u5c55\uff0c\u89e3\u51b3\u56e0\u5feb\u901f\u91c7\u7528AI\u65b9\u6cd5\u800c\u52a0\u5267\u7684\u957f\u671f\u7814\u7a76\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u5f00\u653e\u4e14\u53ef\u6301\u7eed\u7684\u4eba\u5de5\u667a\u80fd\uff08OSAI\uff09\u5efa\u8bae\uff0c\u5e76\u5c06\u5176\u6620\u5c04\u5230\u8d85\u8fc7300\u4e2aAI\u751f\u6001\u7cfb\u7edf\u7ec4\u4ef6\u4e0a\u3002", "result": "\u63ed\u793a\u4e86AI\u7814\u7a76\u8f93\u51fa\u4fe1\u4efb\u5ea6\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u8ba8\u8bba\u4e86AI\u751f\u6001\u7cfb\u7edf\u7684\u788e\u7247\u5316\u53ca\u7f3a\u4e4f\u6307\u5bfc\u8def\u5f84\u7684\u60c5\u51b5\u3002", "conclusion": "\u672c\u7814\u7a76\u8fde\u63a5\u7814\u7a76\u4eba\u5458\u4e0e\u76f8\u5173AI\u8d44\u6e90\uff0c\u4e3a\u672a\u6765\u5236\u5b9a\u653f\u7b56\u548c\u6307\u5bfcAI\u5b9e\u65bd\u7684\u7ed3\u6784\u5316\u8def\u5f84\u63d0\u4f9b\u5e2e\u52a9\u3002"}}
{"id": "2505.16265", "pdf": "https://arxiv.org/pdf/2505.16265", "abs": "https://arxiv.org/abs/2505.16265", "authors": ["Ilgee Hong", "Changlong Yu", "Liang Qiu", "Weixiang Yan", "Zhenghao Xu", "Haoming Jiang", "Qingru Zhang", "Qin Lu", "Xin Liu", "Chao Zhang", "Tuo Zhao"], "title": "Think-RM: Enabling Long-Horizon Reasoning in Generative Reward Models", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning from human feedback (RLHF) has become a powerful\npost-training paradigm for aligning large language models with human\npreferences. A core challenge in RLHF is constructing accurate reward signals,\nwhere the conventional Bradley-Terry reward models (BT RMs) often suffer from\nsensitivity to data size and coverage, as well as vulnerability to reward\nhacking. Generative reward models (GenRMs) offer a more robust alternative by\ngenerating chain-of-thought (CoT) rationales followed by a final reward.\nHowever, existing GenRMs rely on shallow, vertically scaled reasoning, limiting\ntheir capacity to handle nuanced or complex (e.g., reasoning-intensive) tasks.\nMoreover, their pairwise preference outputs are incompatible with standard RLHF\nalgorithms that require pointwise reward signals. In this work, we introduce\nThink-RM, a training framework that enables long-horizon reasoning in GenRMs by\nmodeling an internal thinking process. Rather than producing structured,\nexternally provided rationales, Think-RM generates flexible, self-guided\nreasoning traces that support advanced capabilities such as self-reflection,\nhypothetical reasoning, and divergent reasoning. To elicit these reasoning\nabilities, we first warm-up the models by supervised fine-tuning (SFT) over\nlong CoT data. We then further improve the model's long-horizon abilities by\nrule-based reinforcement learning (RL). In addition, we propose a novel\npairwise RLHF pipeline that directly optimizes policies using pairwise\npreference rewards, eliminating the need for pointwise reward conversion and\nenabling more effective use of Think-RM outputs. Experiments show that Think-RM\nachieves state-of-the-art results on RM-Bench, outperforming both BT RM and\nvertically scaled GenRM by 8%. When combined with our pairwise RLHF pipeline,\nit demonstrates superior end-policy performance compared to traditional\napproaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aThink-RM\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5efa\u6a21\u5185\u90e8\u601d\u8003\u8fc7\u7a0b\u6765\u589e\u5f3a\u751f\u6210\u5956\u52b1\u6a21\u578b\uff08GenRMs\uff09\u7684\u957f\u671f\u63a8\u7406\u80fd\u529b\u3002Think-RM\u751f\u6210\u7075\u6d3b\u7684\u81ea\u6211\u6307\u5bfc\u63a8\u7406\u8f68\u8ff9\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u6210\u5bf9\u504f\u597d\u7684\u5f3a\u5316\u5b66\u4e60\u4ece\u4eba\u7c7b\u53cd\u9988\uff08RLHF\uff09\u7ba1\u9053\uff0c\u76f4\u63a5\u4f18\u5316\u7b56\u7565\u4f7f\u7528\u6210\u5bf9\u504f\u597d\u5956\u52b1\u3002\u5b9e\u9a8c\u8868\u660e\uff0cThink-RM\u5728RM-Bench\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u6bd4Bradley-Terry\u5956\u52b1\u6a21\u578b\u548c\u5782\u76f4\u6269\u5c55\u7684GenRM\u5206\u522b\u9ad8\u51fa8%\u548c10%\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u6210\u5956\u52b1\u6a21\u578b\uff08GenRMs\uff09\u5b58\u5728\u63a8\u7406\u6df1\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e14\u5176\u8f93\u51fa\u4e0e\u6807\u51c6RLHF\u7b97\u6cd5\u4e0d\u517c\u5bb9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u6846\u67b6Think-RM\uff0c\u901a\u8fc7\u5efa\u6a21\u5185\u90e8\u601d\u8003\u8fc7\u7a0b\u589e\u5f3aGenRMs\u7684\u957f\u671f\u63a8\u7406\u80fd\u529b\uff0c\u5305\u62ec\u81ea\u6211\u53cd\u601d\u3001\u5047\u8bbe\u63a8\u7406\u548c\u53d1\u6563\u63a8\u7406\u7b49\u9ad8\u7ea7\u80fd\u529b\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u6210\u5bf9\u504f\u597d\u7684RLHF\u7ba1\u9053\uff0c\u76f4\u63a5\u4f18\u5316\u7b56\u7565\u4f7f\u7528\u6210\u5bf9\u504f\u597d\u5956\u52b1\u3002", "result": "Think-RM\u5728RM-Bench\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u6bd4Bradley-Terry\u5956\u52b1\u6a21\u578b\u548c\u5782\u76f4\u6269\u5c55\u7684GenRM\u5206\u522b\u9ad8\u51fa8%\u548c10%\u3002\u5f53\u4e0e\u65b0\u7684RLHF\u7ba1\u9053\u7ed3\u5408\u65f6\uff0c\u5176\u7aef\u5230\u7aef\u7b56\u7565\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "Think-RM\u663e\u8457\u63d0\u9ad8\u4e86GenRMs\u7684\u63a8\u7406\u80fd\u529b\u548cRLHF\u7684\u6548\u679c\uff0c\u4e3a\u672a\u6765\u7684\u5956\u52b1\u5efa\u6a21\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2505.16646", "pdf": "https://arxiv.org/pdf/2505.16646", "abs": "https://arxiv.org/abs/2505.16646", "authors": ["Yujie Hou", "Ting Zhang", "Mei Wang", "Xuetao Ma", "Hu Huang"], "title": "SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models have achieved remarkable results on a variety of\nmathematical benchmarks. However, concerns remain as to whether these successes\nreflect genuine mathematical reasoning or superficial pattern recognition.\nCommon evaluation metrics, such as final answer accuracy, fail to disentangle\nthe underlying competencies involved, offering limited diagnostic value. To\naddress these limitations, we introduce SMART: a Self-Generating and\nSelf-Validating Multi-Dimensional Assessment Framework. SMART decomposes\nmathematical problem solving into four distinct dimensions: understanding,\nreasoning, arithmetic, and reflection \\& refinement. Each dimension is\nevaluated independently through tailored tasks, enabling interpretable and\nfine-grained analysis of LLM behavior. Crucially, SMART integrates an automated\nself-generating and self-validating mechanism to produce and verify benchmark\ndata, ensuring both scalability and reliability. We apply SMART to 21\nstate-of-the-art open- and closed-source LLMs, uncovering significant\ndiscrepancies in their abilities across different dimensions. Our findings\ndemonstrate the inadequacy of final answer accuracy as a sole metric and\nmotivate a new holistic metric to better capture true problem-solving\ncapabilities. Code and benchmarks will be released upon acceptance.", "AI": {"tldr": "\u63d0\u51faSMART\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u4e3a\u56db\u4e2a\u7ef4\u5ea6\u6765\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u884c\u4e3a\uff0c\u53d1\u73b0\u4ec5\u7528\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u6027\u4f5c\u4e3a\u8861\u91cf\u6807\u51c6\u662f\u4e0d\u591f\u7684\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u6307\u6807\u65e0\u6cd5\u533a\u5206\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u7684\u771f\u5b9e\u80fd\u529b\u4e0e\u8868\u9762\u6a21\u5f0f\u8bc6\u522b\u3002", "method": "\u5f15\u5165SMART\u6846\u67b6\uff0c\u5206\u89e3\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u4e3a\u7406\u89e3\u3001\u63a8\u7406\u3001\u7b97\u672f\u548c\u53cd\u601d\u4e0e\u7cbe\u70bc\u56db\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u96c6\u6210\u81ea\u52a8\u81ea\u6211\u751f\u6210\u548c\u9a8c\u8bc1\u673a\u5236\u3002", "result": "\u5e94\u7528SMART\u6846\u67b6\u8bc4\u4f30\u4e8621\u4e2a\u6700\u5148\u8fdb\u7684\u5f00\u6e90\u548c\u95ed\u6e90LLMs\uff0c\u5728\u4e0d\u540c\u7ef4\u5ea6\u4e0a\u53d1\u73b0\u4e86\u663e\u8457\u7684\u80fd\u529b\u5dee\u5f02\u3002", "conclusion": "\u8bc1\u660e\u4e86\u4ec5\u7528\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u6027\u4f5c\u4e3a\u552f\u4e00\u5ea6\u91cf\u6807\u51c6\u7684\u4e0d\u8db3\uff0c\u5e76\u4fc3\u4f7f\u91c7\u7528\u65b0\u7684\u6574\u4f53\u5ea6\u91cf\u6807\u51c6\u6765\u66f4\u597d\u5730\u6355\u6349\u771f\u6b63\u7684\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002"}}
{"id": "2505.16284", "pdf": "https://arxiv.org/pdf/2505.16284", "abs": "https://arxiv.org/abs/2505.16284", "authors": ["Josh Alman", "Zhao Song"], "title": "Only Large Weights (And Not Skip Connections) Can Prevent the Perils of Rank Collapse", "categories": ["cs.LG"], "comment": null, "summary": "Attention mechanisms lie at the heart of modern large language models (LLMs).\nStraightforward algorithms for forward and backward (gradient) computation take\nquadratic time, and a line of work initiated by [Alman and Song NeurIPS 2023]\nand [Alman and Song NeurIPS 2024] has shown that quadratic time is necessary\nunless the model weights are small, in which case almost linear time algorithms\nare possible. In this paper, we show that large weights are necessary to avoid\na strong preclusion to representational strength we call layer collapse, which\nmeans that the entire network can be approximated well by a network with only a\nsingle layer. Thus, the quadratic running time of attention is unavoidable for\nexpressive transformers.\n  The notion of layer collapse that we introduce is a variant on the notion of\nrank collapse from the work of [Dong, Cordonnier, and Loukas ICML 2021]. They\nshowed that in Self Attention Networks with small weights and with skip\nconnections, rank collapse must occur. This is typically interpreted as\njustifying the necessity of skip connections in expressive networks. However,\nour result shows that even with skip connections, if the weights are small,\nthen layer collapse still occurs. Thus, only large weights, and not skip\nconnections, can prevent these representational weaknesses.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u6ce8\u610f\u529b\u673a\u5236\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u6307\u51fa\u4e3a\u4e86\u4fdd\u6301\u8868\u8fbe\u80fd\u529b\uff0c\u6743\u91cd\u5fc5\u987b\u8db3\u591f\u5927\uff0c\u5426\u5219\u4f1a\u51fa\u73b0\u5c42\u574d\u584c\u73b0\u8c61\uff0c\u8fd9\u4f7f\u5f97\u5177\u6709\u8868\u73b0\u529b\u7684Transformer\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\u65f6\u95f4\u4e0d\u53ef\u907f\u514d\u5730\u4e3a\u4e8c\u6b21\u7ea7\u3002", "motivation": "\u7814\u7a76\u7684\u52a8\u673a\u5728\u4e8e\u7406\u89e3\u4e3a\u4ec0\u4e48\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u6ce8\u610f\u529b\u673a\u5236\u7684\u524d\u5411\u548c\u540e\u5411\u8ba1\u7b97\u9700\u8981\u4e8c\u6b21\u65f6\u95f4\uff0c\u4ee5\u53ca\u5982\u4f55\u907f\u514d\u8868\u793a\u80fd\u529b\u7684\u51cf\u5f31\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5f15\u5165\u5c42\u574d\u584c\u7684\u6982\u5ff5\uff0c\u7814\u7a76\u4e86\u4e0d\u540c\u6761\u4ef6\u4e0b\u6ce8\u610f\u529b\u673a\u5236\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u3002", "result": "\u53d1\u73b0\u5373\u4f7f\u6709\u8df3\u8dc3\u8fde\u63a5\uff0c\u5982\u679c\u6743\u91cd\u8f83\u5c0f\uff0c\u5c42\u574d\u584c\u4ecd\u7136\u4f1a\u53d1\u751f\uff1b\u53ea\u6709\u8f83\u5927\u7684\u6743\u91cd\u624d\u80fd\u9632\u6b62\u8fd9\u4e9b\u8868\u793a\u5f31\u70b9\u3002", "conclusion": "\u4e3a\u4e86\u4fdd\u6301\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u9700\u8981\u8f83\u5927\u7684\u6743\u91cd\uff0c\u56e0\u6b64\u4e8c\u6b21\u8fd0\u884c\u65f6\u95f4\u5bf9\u4e8e\u8868\u8fbe\u6027\u7684Transformer\u662f\u4e0d\u53ef\u907f\u514d\u7684\u3002"}}
{"id": "2505.16667", "pdf": "https://arxiv.org/pdf/2505.16667", "abs": "https://arxiv.org/abs/2505.16667", "authors": ["Xinwei Yang", "Zhaofeng Liu", "Chen Huang", "Jiashuai Zhang", "Tong Zhang", "Yifan Zhang", "Wenqiang Lei"], "title": "ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming", "categories": ["cs.AI"], "comment": "ACL 2025 Main. Our code and dataset are available at\n  https://github.com/SCUNLP/ELABORATION", "summary": "While recent research increasingly emphasizes the value of human-LLM\ncollaboration in competitive programming and proposes numerous empirical\nmethods, a comprehensive understanding remains elusive due to the fragmented\nnature of existing studies and their use of diverse, application-specific human\nfeedback. Thus, our work serves a three-fold purpose: First, we present the\nfirst taxonomy of human feedback consolidating the entire programming process,\nwhich promotes fine-grained evaluation. Second, we introduce ELABORATIONSET, a\nnovel programming dataset specifically designed for human-LLM collaboration,\nmeticulously annotated to enable large-scale simulated human feedback and\nfacilitate costeffective real human interaction studies. Third, we introduce\nELABORATION, a novel benchmark to facilitate a thorough assessment of human-LLM\ncompetitive programming. With ELABORATION, we pinpoint strengthes and\nweaknesses of existing methods, thereby setting the foundation for future\nimprovement. Our code and dataset are available at\nhttps://github.com/SCUNLP/ELABORATION", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f16\u7a0b\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u6765\u8bc4\u4f30\u4eba\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u7ade\u4e89\u6027\u7f16\u7a0b\u4e2d\u7684\u534f\u4f5c\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8fc7\u4e8e\u788e\u7247\u5316\u4e14\u4f7f\u7528\u591a\u6837\u5316\u7684\u5e94\u7528\u7279\u5b9a\u53cd\u9988\uff0c\u7f3a\u4e4f\u5bf9\u4eba-LLM\u534f\u4f5c\u7684\u5168\u9762\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7f16\u7a0b\u8fc7\u7a0b\u7684\u4eba\u7c7b\u53cd\u9988\u5206\u7c7b\u6cd5\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u540d\u4e3aELABORATIONSET\u7684\u65b0\u7f16\u7a0b\u6570\u636e\u96c6\uff0c\u5e76\u5f15\u5165\u4e86ELABORATION\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u901a\u8fc7ELABORATION\uff0c\u786e\u5b9a\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4f18\u52bf\u548c\u52a3\u52bf\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u672c\u7814\u7a76\u586b\u8865\u4e86\u4eba-LLM\u534f\u4f5c\u7814\u7a76\u4e2d\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u4ee3\u7801\u548c\u6570\u636e\u96c6\u4f9b\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2505.16291", "pdf": "https://arxiv.org/pdf/2505.16291", "abs": "https://arxiv.org/abs/2505.16291", "authors": ["Ronen Gradwohl", "Eilam Shapira", "Moshe Tennenholtz"], "title": "Fairness under Competition", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "Algorithmic fairness has emerged as a central issue in ML, and it has become\nstandard practice to adjust ML algorithms so that they will satisfy fairness\nrequirements such as Equal Opportunity. In this paper we consider the effects\nof adopting such fair classifiers on the overall level of ecosystem fairness.\nSpecifically, we introduce the study of fairness with competing firms, and\ndemonstrate the failure of fair classifiers in yielding fair ecosystems. Our\nresults quantify the loss of fairness in systems, under a variety of\nconditions, based on classifiers' correlation and the level of their data\noverlap. We show that even if competing classifiers are individually fair, the\necosystem's outcome may be unfair; and that adjusting biased algorithms to\nimprove their individual fairness may lead to an overall decline in ecosystem\nfairness. In addition to these theoretical results, we also provide supporting\nexperimental evidence. Together, our model and results provide a novel and\nessential call for action.", "AI": {"tldr": "This paper studies the impact of fair classifiers on ecosystem fairness in competitive environments, demonstrating that even fair individual classifiers can lead to unfair outcomes at the ecosystem level.", "motivation": "To address the growing concern over algorithmic fairness in machine learning and examine how fair classifiers affect overall ecosystem fairness.", "method": "Introduces a study of fairness with competing firms, analyzing classifier correlation and data overlap.", "result": "Fair individual classifiers can result in an unfair ecosystem, and improving individual fairness might worsen ecosystem fairness.", "conclusion": "The paper calls for a new approach to ensure fairness across ecosystems rather than just at the individual classifier level."}}
{"id": "2505.16686", "pdf": "https://arxiv.org/pdf/2505.16686", "abs": "https://arxiv.org/abs/2505.16686", "authors": ["Lars Benedikt Kaesberg", "Jan Philip Wahle", "Terry Ruas", "Bela Gipp"], "title": "SPaRC: A Spatial Pathfinding Reasoning Challenge", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Existing reasoning datasets saturate and fail to test abstract, multi-step\nproblems, especially pathfinding and complex rule constraint satisfaction. We\nintroduce SPaRC (Spatial Pathfinding Reasoning Challenge), a dataset of 1,000\n2D grid pathfinding puzzles to evaluate spatial and symbolic reasoning,\nrequiring step-by-step planning with arithmetic and geometric rules. Humans\nachieve near-perfect accuracy (98.0%; 94.5% on hard puzzles), while the best\nreasoning models, such as o4-mini, struggle (15.8%; 1.1% on hard puzzles).\nModels often generate invalid paths (>50% of puzzles for o4-mini), and\nreasoning tokens reveal they make errors in navigation and spatial logic.\nUnlike humans, who take longer on hard puzzles, models fail to scale test-time\ncompute with difficulty. Allowing models to make multiple solution attempts\nimproves accuracy, suggesting potential for better spatial reasoning with\nimproved training and efficient test-time scaling methods. SPaRC can be used as\na window into models' spatial reasoning limitations and drive research toward\nnew methods that excel in abstract, multi-step problem-solving.", "AI": {"tldr": "This paper introduces SPaRC, a new dataset of 1,000 2D grid pathfinding puzzles designed to evaluate spatial and symbolic reasoning. Humans outperform current reasoning models significantly.", "motivation": "Current reasoning datasets fail to effectively test abstract, multi-step problems like pathfinding. Existing models struggle with these types of challenges.", "method": "Developed SPaRC dataset containing 1,000 puzzles requiring step-by-step planning with arithmetic and geometric rules.", "result": "Human performance is near-perfect (98.0%), whereas the best models achieve only 15.8%. Models also generate many invalid paths and make navigation errors.", "conclusion": "SPaRC highlights limitations in current models' spatial reasoning abilities and suggests potential improvements through better training and test-time scaling methods."}}
{"id": "2505.16305", "pdf": "https://arxiv.org/pdf/2505.16305", "abs": "https://arxiv.org/abs/2505.16305", "authors": ["Bingyang Cheng", "Zhongtao Chen", "Yichen Jin", "Hao Zhang", "Chen Zhang", "Edmud Y. Lam", "Yik-Chung Wu"], "title": "Large-Scale Bayesian Tensor Reconstruction: An Approximate Message Passing Solution", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Tensor CANDECOMP/PARAFAC decomposition (CPD) is a fundamental model for\ntensor reconstruction. Although the Bayesian framework allows for principled\nuncertainty quantification and automatic hyperparameter learning, existing\nmethods do not scale well for large tensors because of high-dimensional matrix\ninversions. To this end, we introduce CP-GAMP, a scalable Bayesian CPD\nalgorithm. This algorithm leverages generalized approximate message passing\n(GAMP) to avoid matrix inversions and incorporates an expectation-maximization\nroutine to jointly infer the tensor rank and noise power. Through multiple\nexperiments, for synthetic 100x100x100 rank 20 tensors with only 20% elements\nobserved, the proposed algorithm reduces runtime by 82.7% compared to the\nstate-of-the-art variational Bayesian CPD method, while maintaining comparable\nreconstruction accuracy.", "AI": {"tldr": "This paper introduces CP-GAMP, a scalable Bayesian Tensor CPD algorithm that avoids high-dimensional matrix inversions using GAMP and jointly infers tensor rank and noise power, showing significant runtime reduction compared to previous methods.", "motivation": "Existing Bayesian methods for tensor CPD do not scale well for large tensors due to high-dimensional matrix inversions.", "method": "Introduces CP-GAMP which uses GAMP to avoid matrix inversions and includes an expectation-maximization routine for joint inference of tensor rank and noise power.", "result": "The proposed algorithm reduces runtime by 82.7% compared to the state-of-the-art variational Bayesian CPD method while maintaining similar reconstruction accuracy.", "conclusion": "CP-GAMP provides a scalable solution for Bayesian tensor CPD with efficient computation."}}
{"id": "2505.16700", "pdf": "https://arxiv.org/pdf/2505.16700", "abs": "https://arxiv.org/abs/2505.16700", "authors": ["Xuanqi Gao", "Siyi Xie", "Juan Zhai", "Shqing Ma", "Chao Shen"], "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "As Large Language Models (LLMs) evolve from passive text generators to active\nreasoning agents capable of tool interaction, the Model Context Protocol (MCP)\nhas emerged as a standardized framework for dynamic tool discovery and\norchestration. Despite widespread industry adoption, existing evaluation\nmethodologies fail to adequately assess tool utilization capabilities within\nthis new paradigm. This paper introduces MCP-RADAR, the first comprehensive\nbenchmark specifically designed to evaluate LLM performance in the MCP\nframework through a novel five-dimensional approach measuring: answer accuracy,\ntool selection efficiency, computational resource efficiency, parameter\nconstruction accuracy, and execution speed. Unlike conventional benchmarks that\nrely on subjective human evaluations or binary success metrics, MCP-RADAR\nemploys objective, quantifiable measurements across multiple task domains\nincluding software engineering, mathematical reasoning, and general\nproblem-solving. Our evaluations of leading commercial and open-source LLMs\nreveal distinctive capability profiles with significant trade-offs between\naccuracy, efficiency, and speed, challenging traditional single-metric\nperformance rankings. Besides, we provide valuable guidance for developers to\noptimize their tools for maximum model compatibility and effectiveness. While\nfocused on MCP due to its standardized approach, our methodology remains\napplicable across all LLM agent tool integration frameworks, providing valuable\ninsights for both LLM developers and tool creators to optimize the entire\nLLM-tool interaction ecosystem. The implementation, configurations, and\ndatasets used in our evaluation are publicly available at\nhttps://anonymous.4open.science/r/MCPRadar-B143.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6MCP-RADAR\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u6846\u67b6\u5185\u7684\u5de5\u5177\u5229\u7528\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u8bc4\u4f30\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u8bc4\u4f30LLMs\u5728\u65b0\u8303\u5f0f\u4e2d\u7684\u5de5\u5177\u5229\u7528\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aMCP-RADAR\u7684\u65b0\u57fa\u51c6\uff0c\u91c7\u7528\u4e94\u7ef4\u65b9\u6cd5\u6d4b\u91cf\u7b54\u6848\u51c6\u786e\u6027\u3001\u5de5\u5177\u9009\u62e9\u6548\u7387\u3001\u8ba1\u7b97\u8d44\u6e90\u6548\u7387\u3001\u53c2\u6570\u6784\u5efa\u51c6\u786e\u6027\u548c\u6267\u884c\u901f\u5ea6\u3002", "result": "MCP-RADAR\u8bc4\u4f30\u663e\u793a\u4e86\u9886\u5148\u5546\u4e1a\u548c\u5f00\u6e90LLMs\u7684\u72ec\u7279\u80fd\u529b\u7279\u5f81\uff0c\u5e76\u63ed\u793a\u4e86\u51c6\u786e\u5ea6\u3001\u6548\u7387\u548c\u901f\u5ea6\u4e4b\u95f4\u7684\u663e\u8457\u6743\u8861\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u51c6MCP-RADAR\u6765\u8bc4\u4f30LLMs\u5728MCP\u6846\u67b6\u4e0b\u7684\u6027\u80fd\uff0c\u5e76\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u5728\u51c6\u786e\u5ea6\u3001\u6548\u7387\u548c\u901f\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8eMCP\uff0c\u4e5f\u4e3a\u4f18\u5316\u6574\u4e2aLLM-\u5de5\u5177\u4ea4\u4e92\u751f\u6001\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2505.16308", "pdf": "https://arxiv.org/pdf/2505.16308", "abs": "https://arxiv.org/abs/2505.16308", "authors": ["Xingyu Zhang", "Wenwen Qiang", "Siyu Zhao", "Huijie Guo", "Jiangmeng Li", "Chuxiong Sun", "Changwen Zheng"], "title": "CAIFormer: A Causal Informed Transformer for Multivariate Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Most existing multivariate time series forecasting methods adopt an\nall-to-all paradigm that feeds all variable histories into a unified model to\npredict their future values without distinguishing their individual roles.\nHowever, this undifferentiated paradigm makes it difficult to identify\nvariable-specific causal influences and often entangles causally relevant\ninformation with spurious correlations. To address this limitation, we propose\nan all-to-one forecasting paradigm that predicts each target variable\nseparately. Specifically, we first construct a Structural Causal Model from\nobservational data and then, for each target variable, we partition the\nhistorical sequence into four sub-segments according to the inferred causal\nstructure: endogenous, direct causal, collider causal, and spurious\ncorrelation. The prediction relies solely on the first three causally relevant\nsub-segments, while the spurious correlation sub-segment is excluded.\nFurthermore, we propose Causal Informed Transformer (CAIFormer), a novel\nforecasting model comprising three components: Endogenous Sub-segment\nPrediction Block, Direct Causal Sub-segment Prediction Block, and Collider\nCausal Sub-segment Prediction Block, which process the endogenous, direct\ncausal, and collider causal sub-segments, respectively. Their outputs are then\ncombined to produce the final prediction. Extensive experiments on multiple\nbenchmark datasets demonstrate the effectiveness of the CAIFormer.", "AI": {"tldr": "This paper introduces a new forecasting paradigm and model, CAIFormer, which improves forecasting accuracy by focusing on causally relevant information.", "motivation": "Existing multivariate time series forecasting methods have difficulty identifying variable-specific causal influences due to undifferentiated paradigms.", "method": "The paper proposes an all-to-one forecasting paradigm and a novel forecasting model called CAIFormer.", "result": "The proposed method can effectively exclude spurious correlations and improve forecasting accuracy.", "conclusion": "Extensive experiments show that the proposed CAIFormer outperforms other state-of-the-art methods."}}
{"id": "2505.16771", "pdf": "https://arxiv.org/pdf/2505.16771", "abs": "https://arxiv.org/abs/2505.16771", "authors": ["Beyazit Bestami Yuksel", "Ayse Yilmazer Metin"], "title": "Data-Driven Breakthroughs and Future Directions in AI Infrastructure: A Comprehensive Review", "categories": ["cs.AI"], "comment": "10 pages, 6 figures, 3 tables", "summary": "This paper presents a comprehensive synthesis of major breakthroughs in\nartificial intelligence (AI) over the past fifteen years, integrating\nhistorical, theoretical, and technological perspectives. It identifies key\ninflection points in AI' s evolution by tracing the convergence of\ncomputational resources, data access, and algorithmic innovation. The analysis\nhighlights how researchers enabled GPU based model training, triggered a data\ncentric shift with ImageNet, simplified architectures through the Transformer,\nand expanded modeling capabilities with the GPT series. Rather than treating\nthese advances as isolated milestones, the paper frames them as indicators of\ndeeper paradigm shifts. By applying concepts from statistical learning theory\nsuch as sample complexity and data efficiency, the paper explains how\nresearchers translated breakthroughs into scalable solutions and why the field\nmust now embrace data centric approaches. In response to rising privacy\nconcerns and tightening regulations, the paper evaluates emerging solutions\nlike federated learning, privacy enhancing technologies (PETs), and the data\nsite paradigm, which reframe data access and security. In cases where real\nworld data remains inaccessible, the paper also assesses the utility and\nconstraints of mock and synthetic data generation. By aligning technical\ninsights with evolving data infrastructure, this study offers strategic\nguidance for future AI research and policy development.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u8fc7\u53bb\u5341\u4e94\u5e74\u4e2d\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u91cd\u5927\u7a81\u7834\uff0c\u4ece\u5386\u53f2\u3001\u7406\u8bba\u548c\u6280\u672f\u89d2\u5ea6\u6574\u5408\u4e86\u8fd9\u4e9b\u8fdb\u5c55\u3002\u901a\u8fc7\u8ffd\u8e2a\u8ba1\u7b97\u8d44\u6e90\u3001\u6570\u636e\u8bbf\u95ee\u548c\u7b97\u6cd5\u521b\u65b0\u7684\u4ea4\u6c47\u70b9\u6765\u8bc6\u522bAI\u53d1\u5c55\u7684\u5173\u952e\u8f6c\u6298\u70b9\u3002\u6587\u7ae0\u5f3a\u8c03\u4e86\u7814\u7a76\u4eba\u5458\u5982\u4f55\u5229\u7528GPU\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u3001\u901a\u8fc7ImageNet\u89e6\u53d1\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u8f6c\u53d8\u3001\u7b80\u5316\u67b6\u6784\u4e3aTransformer\uff0c\u5e76\u6269\u5c55\u4e86GPT\u7cfb\u5217\u7684\u5efa\u6a21\u80fd\u529b\u3002\u9664\u4e86\u5b64\u7acb\u5730\u770b\u5f85\u8fd9\u4e9b\u8fdb\u6b65\u5916\uff0c\u8fd8\u5c06\u5176\u89c6\u4e3a\u66f4\u6df1\u5c42\u6b21\u8303\u5f0f\u8f6c\u6362\u7684\u6307\u6807\u3002\u8fd0\u7528\u7edf\u8ba1\u5b66\u4e60\u7406\u8bba\u4e2d\u7684\u6837\u672c\u590d\u6742\u6027\u548c\u6570\u636e\u6548\u7387\u7b49\u6982\u5ff5\u89e3\u91ca\u4e86\u7814\u7a76\u8005\u5982\u4f55\u5c06\u7a81\u7834\u8f6c\u5316\u4e3a\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u63a2\u8ba8\u4e86\u9690\u79c1\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\u7684\u60c5\u51b5\u4e0b\u65b0\u5174\u7684\u6570\u636e\u4e2d\u5fc3\u5316\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u5bf9\u4e8e\u65e0\u6cd5\u83b7\u5f97\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u7684\u60c5\u51b5\uff0c\u8bc4\u4f30\u4e86\u6a21\u62df\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u5b9e\u7528\u6027\u548c\u9650\u5236\u3002\u8fd9\u9879\u7814\u7a76\u7ed3\u5408\u6280\u672f\u6d1e\u5bdf\u4e0e\u4e0d\u65ad\u53d1\u5c55\u7684\u6570\u636e\u57fa\u7840\u8bbe\u65bd\uff0c\u4e3a\u672a\u6765\u7684AI\u7814\u7a76\u548c\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u4e86\u6218\u7565\u6307\u5bfc\u3002", "motivation": "\u603b\u7ed3\u8fc7\u53bb\u5341\u4e94\u5e74\u4e2d\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u91cd\u8981\u8fdb\u5c55\uff0c\u5e76\u4ece\u591a\u4e2a\u89c6\u89d2\u7406\u89e3\u8fd9\u4e9b\u7a81\u7834\u7684\u672c\u8d28\u53ca\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u8ffd\u8e2a\u8ba1\u7b97\u8d44\u6e90\u3001\u6570\u636e\u8bbf\u95ee\u548c\u7b97\u6cd5\u521b\u65b0\u7684\u4ea4\u6c47\u70b9\u6765\u8bc6\u522bAI\u53d1\u5c55\u7684\u5173\u952e\u8f6c\u6298\u70b9\uff0c\u540c\u65f6\u8fd0\u7528\u7edf\u8ba1\u5b66\u4e60\u7406\u8bba\u7684\u6982\u5ff5\u6765\u89e3\u91ca\u8fd9\u4e9b\u8fdb\u5c55\u3002", "result": "\u8bc6\u522b\u51fa\u4e86\u51e0\u4e2a\u91cd\u8981\u7684\u8f6c\u6298\u70b9\uff0c\u5982GPU\u6a21\u578b\u8bad\u7ec3\u3001ImageNet\u5f15\u53d1\u7684\u6570\u636e\u4e2d\u5fc3\u5316\u8f6c\u53d8\u3001Transformer\u7b80\u5316\u67b6\u6784\u4ee5\u53caGPT\u7cfb\u5217\u6269\u5c55\u5efa\u6a21\u80fd\u529b\u3002\u63d0\u51fa\u4e86\u6570\u636e\u4e2d\u5fc3\u5316\u65b9\u6cd5\u7684\u91cd\u8981\u6027\uff0c\u5e76\u8bc4\u4f30\u4e86\u6a21\u62df\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u5728\u7279\u5b9a\u60c5\u51b5\u4e0b\u7684\u5e94\u7528\u3002", "conclusion": "\u672c\u7814\u7a76\u4e0d\u4ec5\u603b\u7ed3\u4e86AI\u9886\u57df\u7684\u91cd\u5927\u8fdb\u5c55\uff0c\u8fd8\u63ed\u793a\u4e86\u8fd9\u4e9b\u8fdb\u6b65\u80cc\u540e\u7684\u6df1\u5c42\u6a21\u5f0f\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u548c\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u4e86\u6218\u7565\u5efa\u8bae\u3002"}}
{"id": "2505.16319", "pdf": "https://arxiv.org/pdf/2505.16319", "abs": "https://arxiv.org/abs/2505.16319", "authors": ["Yangyang Wang", "Jiawei Gu", "Li Long", "Xin Li", "Li Shen", "Zhouyu Fu", "Xiangjun Zhou", "Xu Jiang"], "title": "FreshRetailNet-50K: A Stockout-Annotated Censored Demand Dataset for Latent Demand Recovery and Forecasting in Fresh Retail", "categories": ["cs.LG"], "comment": "10 pages, 5 figures", "summary": "Accurate demand estimation is critical for the retail business in guiding the\ninventory and pricing policies of perishable products. However, it faces\nfundamental challenges from censored sales data during stockouts, where\nunobserved demand creates systemic policy biases. Existing datasets lack the\ntemporal resolution and annotations needed to address this censoring effect. To\nfill this gap, we present FreshRetailNet-50K, the first large-scale benchmark\nfor censored demand estimation. It comprises 50,000 store-product time series\nof detailed hourly sales data from 898 stores in 18 major cities, encompassing\n863 perishable SKUs meticulously annotated for stockout events. The hourly\nstock status records unique to this dataset, combined with rich contextual\ncovariates, including promotional discounts, precipitation, and temporal\nfeatures, enable innovative research beyond existing solutions. We demonstrate\none such use case of two-stage demand modeling: first, we reconstruct the\nlatent demand during stockouts using precise hourly annotations. We then\nleverage the recovered demand to train robust demand forecasting models in the\nsecond stage. Experimental results show that this approach achieves a 2.73\\%\nimprovement in prediction accuracy while reducing the systematic demand\nunderestimation from 7.37\\% to near-zero bias. With unprecedented temporal\ngranularity and comprehensive real-world information, FreshRetailNet-50K opens\nnew research directions in demand imputation, perishable inventory\noptimization, and causal retail analytics. The unique annotation quality and\nscale of the dataset address long-standing limitations in retail AI, providing\nimmediate solutions and a platform for future methodological innovation. The\ndata (https://huggingface.co/datasets/Dingdong-Inc/FreshRetailNet-50K) and code\n(https://github.com/Dingdong-Inc/frn-50k-baseline}) are openly released.", "AI": {"tldr": "This paper introduces FreshRetailNet-50K, a large-scale benchmark for censored demand estimation in perishable products. It presents a two-stage demand modeling approach that improves prediction accuracy and addresses long-standing limitations in retail AI.", "motivation": "Existing datasets lack the temporal resolution and annotations needed to address the censoring effect in censored sales data during stockouts, which leads to systemic policy biases.", "method": "Two-stage demand modeling: 1) Reconstruct latent demand during stockouts using precise hourly annotations. 2) Train robust demand forecasting models using recovered demand.", "result": "The approach achieves a 2.73% improvement in prediction accuracy and reduces systematic demand underestimation from 7.37% to near-zero bias.", "conclusion": "The dataset FreshRetailNet-50K improves prediction accuracy and reduces systematic demand underestimation. It opens new research directions in demand imputation, perishable inventory optimization, and causal retail analytics."}}
{"id": "2505.16781", "pdf": "https://arxiv.org/pdf/2505.16781", "abs": "https://arxiv.org/abs/2505.16781", "authors": ["Qianlei Jia", "Xinliang Zhou", "Ondrej Krejcar", "Enrique Herrera-Viedma"], "title": "Fuzzy Information Evolution with Three-Way Decision in Social Network Group Decision-Making", "categories": ["cs.AI"], "comment": null, "summary": "In group decision-making (GDM) scenarios, uncertainty, dynamic social\nstructures, and vague information present major challenges for traditional\nopinion dynamics models. To address these issues, this study proposes a novel\nsocial network group decision-making (SNGDM) framework that integrates\nthree-way decision (3WD) theory, dynamic network reconstruction, and linguistic\nopinion representation. First, the 3WD mechanism is introduced to explicitly\nmodel hesitation and ambiguity in agent judgments, thereby preventing\nirrational decisions. Second, a connection adjustment rule based on opinion\nsimilarity is developed, enabling agents to adaptively update their\ncommunication links and better reflect the evolving nature of social\nrelationships. Third, linguistic terms are used to describe agent opinions,\nallowing the model to handle subjective, vague, or incomplete information more\neffectively. Finally, an integrated multi-agent decision-making framework is\nconstructed, which simultaneously considers individual uncertainty, opinion\nevolution, and network dynamics. The proposed model is applied to a multi-UAV\ncooperative decision-making scenario, where simulation results and consensus\nanalysis demonstrate its effectiveness. Experimental comparisons further verify\nthe advantages of the algorithm in enhancing system stability and representing\nrealistic decision-making behaviors.", "AI": {"tldr": "This study proposes a new SNGDM framework integrating three-way decision theory, dynamic network reconstruction, and linguistic opinion representation to handle uncertainty and dynamic social structures in GDM.", "motivation": "To address challenges in traditional opinion dynamics models regarding uncertainty, dynamic social structures, and vague information in GDM scenarios.", "method": "Integrates three-way decision theory, develops a connection adjustment rule based on opinion similarity, uses linguistic terms for opinions, and constructs a multi-agent decision-making framework.", "result": "The model is effective in a multi-UAV cooperative decision-making scenario, with simulation results and consensus analysis demonstrating its performance.", "conclusion": "The proposed framework enhances system stability and represents realistic decision-making behaviors better than traditional models."}}
{"id": "2505.16322", "pdf": "https://arxiv.org/pdf/2505.16322", "abs": "https://arxiv.org/abs/2505.16322", "authors": ["Woosung Koh", "Wonbeen Oh", "Jaein Jang", "MinHyung Lee", "Hyeongjin Kim", "Ah Yeon Kim", "Joonkee Kim", "Junghyun Lee", "Taehyeon Kim", "Se-Young Yun"], "title": "AdaSTaR: Adaptive Data Sampling for Training Self-Taught Reasoners", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Pre-print", "summary": "Self-Taught Reasoners (STaR), synonymously known as Rejection sampling\nFine-Tuning (RFT), is an integral part of the training pipeline of\nself-improving reasoning Language Models (LMs). The self-improving mechanism\noften employs random observation (data) sampling. However, this results in\ntrained observation imbalance; inefficiently over-training on solved examples\nwhile under-training on challenging ones. In response, we introduce Adaptive\nSTaR (AdaSTaR), a novel algorithm that rectifies this by integrating two\nadaptive sampling principles: (1) Adaptive Sampling for Diversity: promoting\nbalanced training across observations, and (2) Adaptive Sampling for\nCurriculum: dynamically adjusting data difficulty to match the model's evolving\nstrength. Across six benchmarks, AdaSTaR achieves best test accuracy in all\ninstances (6/6) and reduces training FLOPs by an average of 58.6% against an\nextensive list of baselines. These improvements in performance and efficiency\ngeneralize to different pre-trained LMs and larger models, paving the way for\nmore efficient and effective self-improving LMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u9002\u5e94\u91c7\u6837\u7b97\u6cd5AdaSTaR\uff0c\u7528\u4e8e\u6539\u8fdb\u81ea\u6211\u63d0\u5347\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAdaSTaR\u5728\u6240\u6709\u60c5\u51b5\u4e0b\u90fd\u8fbe\u5230\u4e86\u6700\u4f73\u6d4b\u8bd5\u51c6\u786e\u7387\uff0c\u5e76\u4e14\u51cf\u5c11\u4e86\u5e73\u574758.6%\u7684\u8bad\u7ec3\u6d6e\u70b9\u8fd0\u7b97\u6b21\u6570\uff08FLOPs\uff09\u3002", "motivation": "\u73b0\u6709\u7684\u968f\u673a\u89c2\u5bdf\u91c7\u6837\u65b9\u6cd5\u4f1a\u5bfc\u81f4\u8bad\u7ec3\u6837\u672c\u4e0d\u5e73\u8861\uff0c\u5373\u8fc7\u5ea6\u8bad\u7ec3\u4e8e\u7b80\u5355\u793a\u4f8b\u800c\u8bad\u7ec3\u4e0d\u8db3\u4e8e\u56f0\u96be\u793a\u4f8b\u3002", "method": "\u5f15\u5165\u4e86AdaSTaR\u7b97\u6cd5\uff0c\u5305\u542b\u4e24\u4e2a\u81ea\u9002\u5e94\u91c7\u6837\u539f\u5219\uff1a(1) \u591a\u6837\u6027\u81ea\u9002\u5e94\u91c7\u6837\uff1b(2) \u8bfe\u7a0b\u81ea\u9002\u5e94\u91c7\u6837\uff0c\u52a8\u6001\u8c03\u6574\u6570\u636e\u96be\u5ea6\u4ee5\u5339\u914d\u6a21\u578b\u7684\u6f14\u5316\u80fd\u529b\u3002", "result": "\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAdaSTaR\u53d6\u5f97\u4e86\u6700\u4f73\u7684\u6d4b\u8bd5\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u663e\u8457\u51cf\u5c11\u4e86\u8bad\u7ec3\u6240\u9700\u7684\u8ba1\u7b97\u8d44\u6e90\u3002", "conclusion": "AdaSTaR\u63d0\u5347\u4e86\u81ea\u6211\u63d0\u5347\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u548c\u6548\u7387\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u548c\u66f4\u5927\u89c4\u6a21\u7684\u6a21\u578b\u3002"}}
{"id": "2505.16787", "pdf": "https://arxiv.org/pdf/2505.16787", "abs": "https://arxiv.org/abs/2505.16787", "authors": ["Ashish Sundar", "Chunbo Luo", "Xiaoyang Wang"], "title": "Gaze Into the Abyss -- Planning to Seek Entropy When Reward is Scarce", "categories": ["cs.AI"], "comment": "9 pages without appendix, 15 Figures, preprint", "summary": "Model-based reinforcement learning (MBRL) offers an intuitive way to increase\nthe sample efficiency of model-free RL methods by simultaneously training a\nworld model that learns to predict the future. MBRL methods have progressed by\nlargely prioritising the actor; optimising the world model learning has been\nneglected meanwhile. Improving the fidelity of the world model and reducing its\ntime to convergence can yield significant downstream benefits, one of which is\nimproving the ensuing performance of any actor it may train. We propose a novel\napproach that anticipates and actively seeks out high-entropy states using\nshort-horizon latent predictions generated by the world model, offering a\nprincipled alternative to traditional curiosity-driven methods that chase\nonce-novel states well after they were stumbled into. While many model\npredictive control (MPC) based methods offer similar alternatives, they\ntypically lack commitment, synthesising multi step plans after every step. To\nmitigate this, we present a hierarchical planner that dynamically decides when\nto replan, planning horizon length, and the weighting between reward and\nentropy. While our method can theoretically be applied to any model that trains\nits own actors with solely model generated data, we have applied it to just\nDreamer as a proof of concept. Our method finishes the Miniworld procedurally\ngenerated mazes 50% faster than base Dreamer at convergence and the policy\ntrained in imagination converges in only 60% of the environment steps that base\nDreamer needs.", "AI": {"tldr": "This paper proposes a novel approach for model-based reinforcement learning (MBRL) that improves the world model's fidelity and reduces its time to convergence by seeking out high-entropy states.", "motivation": "To address the neglect of optimizing the world model learning in MBRL methods and improve the sample efficiency of model-free RL methods.", "method": "Anticipating and actively seeking out high-entropy states using short-horizon latent predictions generated by the world model, and presenting a hierarchical planner that dynamically decides when to replan, planning horizon length, and the weighting between reward and entropy.", "result": "The proposed method finishes the Miniworld procedurally generated mazes 50% faster than base Dreamer at convergence and the policy trained in imagination converges in only 60% of the environment steps that base Dreamer needs.", "conclusion": "The proposed method significantly improves the performance of MBRL methods by enhancing the world model and reducing its time to convergence."}}
{"id": "2505.16326", "pdf": "https://arxiv.org/pdf/2505.16326", "abs": "https://arxiv.org/abs/2505.16326", "authors": ["Qian Tan", "Dongzhan Zhou", "Peng Xia", "Wanhao Liu", "Wanli Ouyang", "Lei Bai", "Yuqiang Li", "Tianfan Fu"], "title": "ChemMLLM: Chemical Multimodal Large Language Model", "categories": ["cs.LG"], "comment": "25 pages", "summary": "Multimodal large language models (MLLMs) have made impressive progress in\nmany applications in recent years. However, chemical MLLMs that can handle\ncross-modal understanding and generation remain underexplored. To fill this\ngap, in this paper, we propose ChemMLLM, a unified chemical multimodal large\nlanguage model for molecule understanding and generation. Also, we design five\nmultimodal tasks across text, molecular SMILES strings, and image, and curate\nthe datasets. We benchmark ChemMLLM against a range of general leading MLLMs\nand Chemical LLMs on these tasks. Experimental results show that ChemMLLM\nachieves superior performance across all evaluated tasks. For example, in\nmolecule image optimization task, ChemMLLM outperforms the best baseline\n(GPT-4o) by 118.9\\% (4.27 vs 1.95 property improvement). The code is publicly\navailable at https://github.com/bbsbz/ChemMLLM.git.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5206\u5b50\u7406\u89e3\u548c\u751f\u6210\u7684\u7edf\u4e00\u5316\u5b66\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578bChemMLLM\uff0c\u5e76\u5728\u4e94\u4e2a\u8de8\u6587\u672c\u3001\u5206\u5b50SMILES\u5b57\u7b26\u4e32\u548c\u56fe\u50cf\u7684\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aChemMLLM\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u90fd\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u8868\u73b0\u3002", "motivation": "\u586b\u8865\u5316\u5b66\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ea4\u53c9\u6a21\u6001\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\u7684\u7a7a\u767d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aChemMLLM\u7684\u7edf\u4e00\u5316\u5b66\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e94\u4e2a\u8de8\u6a21\u6001\u4efb\u52a1\u4ee5\u53ca\u76f8\u5e94\u7684\u6570\u636e\u96c6\u3002", "result": "ChemMLLM\u5728\u6240\u6709\u8bc4\u4f30\u7684\u4efb\u52a1\u4e2d\u90fd\u8868\u73b0\u51fa\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u4f8b\u5982\u5728\u5206\u5b50\u56fe\u50cf\u4f18\u5316\u4efb\u52a1\u4e2d\u6bd4\u6700\u597d\u7684\u57fa\u7ebf\u6a21\u578bGPT-4o\u9ad8\u51fa118.9%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684ChemMLLM\u5728\u5316\u5b66\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8868\u660e\u5176\u5728\u5206\u5b50\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.16826", "pdf": "https://arxiv.org/pdf/2505.16826", "abs": "https://arxiv.org/abs/2505.16826", "authors": ["Wei Sun", "Wen Yang", "Pu Jian", "Qianlong Du", "Fuwei Cui", "Shuo Ren", "Jiajun Zhang"], "title": "KTAE: A Model-Free Algorithm to Key-Tokens Advantage Estimation in Mathematical Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances have demonstrated that integrating reinforcement learning\nwith rule-based rewards can significantly enhance the reasoning capabilities of\nlarge language models, even without supervised fine-tuning. However, prevalent\nreinforcement learning algorithms such as GRPO and its variants like DAPO,\nsuffer from a coarse granularity issue when computing the advantage.\nSpecifically, they compute rollout-level advantages that assign identical\nvalues to every token within a sequence, failing to capture token-specific\ncontributions and hindering effective learning. To address this limitation, we\npropose Key-token Advantage Estimation (KTAE) - a novel algorithm that\nestimates fine-grained, token-level advantages without introducing additional\nmodels. KTAE leverages the correctness of sampled rollouts and applies\nstatistical analysis to quantify the importance of individual tokens within a\nsequence to the final outcome. This quantified token-level importance is then\ncombined with the rollout-level advantage to obtain a more fine-grained\ntoken-level advantage estimation. Empirical results show that models trained\nwith GRPO+KTAE and DAPO+KTAE outperform baseline methods across five\nmathematical reasoning benchmarks. Notably, they achieve higher accuracy with\nshorter responses and even surpass R1-Distill-Qwen-1.5B using the same base\nmodel.", "AI": {"tldr": "Proposes Key-token Advantage Estimation (KTAE) to improve token-level advantage estimation in reinforcement learning for large language models.", "motivation": "Existing reinforcement learning algorithms suffer from coarse granularity issues when computing advantages, failing to capture token-specific contributions.", "method": "Introduces KTAE, which estimates fine-grained, token-level advantages by leveraging sampled rollouts and statistical analysis.", "result": "Models trained with GRPO+KTAE and DAPO+KTAE outperform baseline methods on five mathematical reasoning benchmarks.", "conclusion": "KTAE improves the reasoning capabilities of large language models without introducing additional models or requiring supervised fine-tuning."}}
{"id": "2505.16333", "pdf": "https://arxiv.org/pdf/2505.16333", "abs": "https://arxiv.org/abs/2505.16333", "authors": ["Chaerin Kong", "Jiho Jang", "Nojun Kwak"], "title": "Understanding Differential Transformer Unchains Pretrained Self-Attentions", "categories": ["cs.LG"], "comment": "9 pages", "summary": "Differential Transformer has recently gained significant attention for its\nimpressive empirical performance, often attributed to its ability to perform\nnoise canceled attention. However, precisely how differential attention\nachieves its empirical benefits remains poorly understood. Moreover,\nDifferential Transformer architecture demands large-scale training from\nscratch, hindering utilization of open pretrained weights. In this work, we\nconduct an in-depth investigation of Differential Transformer, uncovering three\nkey factors behind its success: (1) enhanced expressivity via negative\nattention, (2) reduced redundancy among attention heads, and (3) improved\nlearning dynamics. Based on these findings, we propose DEX, a novel method to\nefficiently integrate the advantages of differential attention into pretrained\nlanguage models. By reusing the softmax attention scores and adding a\nlightweight differential operation on the output value matrix, DEX effectively\nincorporates the key advantages of differential attention while remaining\nlightweight in both training and inference. Evaluations confirm that DEX\nsubstantially improves the pretrained LLMs across diverse benchmarks, achieving\nsignificant performance gains with minimal adaptation data (< 0.01\\%).", "AI": {"tldr": "This paper investigates Differential Transformer and proposes DEX, which efficiently integrates differential attention into pretrained language models and significantly improves their performance with minimal adaptation data.", "motivation": "Precisely how differential attention achieves its empirical benefits remains poorly understood. Differential Transformer architecture demands large-scale training from scratch, hindering utilization of open pretrained weights.", "method": "DEX efficiently integrates the advantages of differential attention into pretrained language models by reusing the softmax attention scores and adding a lightweight differential operation on the output value matrix.", "result": "DEX effectively incorporates the key advantages of differential attention while remaining lightweight in both training and inference.", "conclusion": "DEX substantially improves the pretrained LLMs across diverse benchmarks, achieving significant performance gains with minimal adaptation data."}}
{"id": "2505.16827", "pdf": "https://arxiv.org/pdf/2505.16827", "abs": "https://arxiv.org/abs/2505.16827", "authors": ["Bin Xie", "Rui Shao", "Gongwei Chen", "Kaiwen Zhou", "Yinchuan Li", "Jie Liu", "Min Zhang", "Liqiang Nie"], "title": "GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent", "categories": ["cs.AI"], "comment": "ACL 2025. Github: https://github.com/JiuTian-VL/GUI-explorer", "summary": "GUI automation faces critical challenges in dynamic environments. MLLMs\nsuffer from two key issues: misinterpreting UI components and outdated\nknowledge. Traditional fine-tuning methods are costly for app-specific\nknowledge updates. We propose GUI-explorer, a training-free GUI agent that\nincorporates two fundamental mechanisms: (1) Autonomous Exploration of\nFunction-aware Trajectory. To comprehensively cover all application\nfunctionalities, we design a Function-aware Task Goal Generator that\nautomatically constructs exploration goals by analyzing GUI structural\ninformation (e.g., screenshots and activity hierarchies). This enables\nsystematic exploration to collect diverse trajectories. (2) Unsupervised Mining\nof Transition-aware Knowledge. To establish precise screen-operation logic, we\ndevelop a Transition-aware Knowledge Extractor that extracts effective\nscreen-operation logic through unsupervised analysis the state transition of\nstructured interaction triples (observation, action, outcome). This eliminates\nthe need for human involvement in knowledge extraction. With a task success\nrate of 53.7% on SPA-Bench and 47.4% on AndroidWorld, GUI-explorer shows\nsignificant improvements over SOTA agents. It requires no parameter updates for\nnew apps. GUI-explorer is open-sourced and publicly available at\nhttps://github.com/JiuTian-VL/GUI-explorer.", "AI": {"tldr": "A novel training-free GUI agent, GUI-explorer, addresses challenges in GUI automation by incorporating two mechanisms, achieving better performance than current state-of-the-art agents without needing parameter updates for new apps.", "motivation": "To address the challenges faced by MLLMs in dynamic environments, including misinterpreting UI components and outdated knowledge, and the high cost of traditional fine-tuning methods for app-specific knowledge updates.", "method": "GUI-explorer incorporates two mechanisms: Autonomous Exploration of Function-aware Trajectory and Unsupervised Mining of Transition-aware Knowledge.", "result": "GUI-explorer achieves a task success rate of 53.7% on SPA-Bench and 47.4% on AndroidWorld, outperforming other state-of-the-art agents.", "conclusion": "GUI-explorer demonstrates significant improvements over state-of-the-art agents without requiring parameter updates for new apps."}}
{"id": "2505.16340", "pdf": "https://arxiv.org/pdf/2505.16340", "abs": "https://arxiv.org/abs/2505.16340", "authors": ["Yunhui Jang", "Jaehyung Kim", "Sungsoo Ahn"], "title": "Improving Chemical Understanding of LLMs via SMILES Parsing", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) are increasingly recognized as powerful tools\nfor scientific discovery, particularly in molecular science. A fundamental\nrequirement for these models is the ability to accurately understand molecular\nstructures, commonly encoded in the SMILES representation. However, current\nLLMs struggle to interpret SMILES, even failing to carry out basic tasks such\nas counting molecular rings. To address this limitation, we introduce CLEANMOL,\na novel framework that formulates SMILES parsing into a suite of clean and\ndeterministic tasks explicitly designed to promote graph-level molecular\ncomprehension. These tasks span from subgraph matching to global graph\nmatching, providing structured supervision aligned with molecular structural\nproperties. We construct a molecular pretraining dataset with adaptive\ndifficulty scoring and pre-train open-source LLMs on these tasks. Our results\nshow that CLEANMOL not only enhances structural comprehension but also achieves\nthe best or competes with the baseline on the Mol-Instructions benchmark.", "AI": {"tldr": "CLEANMOL is a new method that improves large language models' understanding of molecular structures in SMILES format by turning it into a set of clear tasks.", "motivation": "Current large language models struggle to interpret SMILES, even for simple tasks like counting molecular rings.", "method": "Introduce CLEANMOL, which transforms SMILES parsing into various tasks promoting molecular comprehension, and pre-trains models on these tasks.", "result": "CLEANMOL improves structural comprehension and performs well on the Mol-Instructions benchmark.", "conclusion": "CLEANMOL effectively enhances large language models' ability to understand molecular structures."}}
{"id": "2505.16832", "pdf": "https://arxiv.org/pdf/2505.16832", "abs": "https://arxiv.org/abs/2505.16832", "authors": ["Haonian Ji", "Shi Qiu", "Siyang Xin", "Siwei Han", "Zhaorun Chen", "Hongyi Wang", "Dake Zhang", "Huaxiu Yao"], "title": "From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Pedagogical Visualization", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": "16 pages; 7 figures", "summary": "While foundation models (FMs), such as diffusion models and large\nvision-language models (LVLMs), have been widely applied in educational\ncontexts, their ability to generate pedagogically effective visual explanations\nremains limited. Most existing approaches focus primarily on textual reasoning,\noverlooking the critical role of structured and interpretable visualizations in\nsupporting conceptual understanding. To better assess the visual reasoning\ncapabilities of FMs in educational settings, we introduce EduVisBench, a\nmulti-domain, multi-level benchmark. EduVisBench features diverse STEM problem\nsets requiring visually grounded solutions, along with a fine-grained\nevaluation rubric informed by pedagogical theory. Our empirical analysis\nreveals that existing models frequently struggle with the inherent challenge of\ndecomposing complex reasoning and translating it into visual representations\naligned with human cognitive processes. To address these limitations, we\npropose EduVisAgent, a multi-agent collaborative framework that coordinates\nspecialized agents for instructional planning, reasoning decomposition,\nmetacognitive prompting, and visualization design. Experimental results show\nthat EduVisAgent substantially outperforms all baselines, achieving a 40.2%\nimprovement and delivering more educationally aligned visualizations.\nEduVisBench and EduVisAgent are available at\nhttps://github.com/aiming-lab/EduVisBench and\nhttps://github.com/aiming-lab/EduVisAgent.", "AI": {"tldr": "\u63d0\u51faEduVisBench\u57fa\u51c6\u6d4b\u8bd5\u96c6\u548cEduVisAgent\u6846\u67b6\u6765\u8bc4\u4f30\u548c\u63d0\u5347\u57fa\u7840\u6a21\u578b\u5728\u6559\u80b2\u573a\u666f\u4e2d\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6587\u672c\u63a8\u7406\uff0c\u5ffd\u89c6\u4e86\u7ed3\u6784\u5316\u53ef\u89c6\u5316\u5728\u6982\u5ff5\u7406\u89e3\u4e2d\u7684\u91cd\u8981\u4f5c\u7528\u3002", "method": "\u5f15\u5165EduVisBench\u57fa\u51c6\u6d4b\u8bd5\u96c6\u548cEduVisAgent\u591a\u4ee3\u7406\u534f\u4f5c\u6846\u67b6\u3002", "result": "EduVisAgent\u6bd4\u57fa\u7ebf\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u63d0\u9ad8\u4e8640.2%\u3002", "conclusion": "EduVisBench\u548cEduVisAgent\u6709\u52a9\u4e8e\u63d0\u9ad8\u57fa\u7840\u6a21\u578b\u751f\u6210\u6559\u80b2\u4e0a\u6709\u6548\u7684\u89c6\u89c9\u89e3\u91ca\u7684\u80fd\u529b\u3002"}}
{"id": "2505.16341", "pdf": "https://arxiv.org/pdf/2505.16341", "abs": "https://arxiv.org/abs/2505.16341", "authors": ["Yaxin Hou", "Yuheng Jia"], "title": "A Square Peg in a Square Hole: Meta-Expert for Long-Tailed Semi-Supervised Learning", "categories": ["cs.LG"], "comment": "The paper is accepted by ICML 2025", "summary": "This paper studies the long-tailed semi-supervised learning (LTSSL) with\ndistribution mismatch, where the class distribution of the labeled training\ndata follows a long-tailed distribution and mismatches with that of the\nunlabeled training data. Most existing methods introduce auxiliary classifiers\n(experts) to model various unlabeled data distributions and produce\npseudo-labels, but the expertises of various experts are not fully utilized. We\nobserve that different experts are good at predicting different intervals of\nsamples, e.g., long-tailed expert is skilled in samples located in the head\ninterval and uniform expert excels in samples located in the medium interval.\nTherefore, we propose a dynamic expert assignment module that can estimate the\nclass membership (i.e., head, medium, or tail class) of samples, and\ndynamically assigns suitable expert to each sample based on the estimated\nmembership to produce high-quality pseudo-label in the training phase and\nproduce prediction in the testing phase. We also theoretically reveal that\nintegrating different experts' strengths will lead to a smaller generalization\nerror bound. Moreover, we find that the deeper features are more biased toward\nthe head class but with more discriminative ability, while the shallower\nfeatures are less biased but also with less discriminative ability. We,\ntherefore, propose a multi-depth feature fusion module to utilize different\ndepth features to mitigate the model bias. Our method demonstrates its\neffectiveness through comprehensive experiments on the CIFAR-10-LT, STL-10-LT,\nand SVHN-LT datasets across various settings. The code is available at\nhttps://github.com/yaxinhou/Meta-Expert.", "AI": {"tldr": "This paper proposes a method to improve semi-supervised learning for long-tailed data by dynamically assigning experts and fusing multi-depth features.", "motivation": "Existing methods do not fully utilize the expertise of different auxiliary classifiers in LTSSL with distribution mismatch.", "method": "Proposes a dynamic expert assignment module and a multi-depth feature fusion module.", "result": "The proposed method leads to a smaller generalization error bound and improves performance on CIFAR-10-LT, STL-10-LT, and SVHN-LT datasets.", "conclusion": "Our method shows its effectiveness through extensive experiments."}}
{"id": "2505.16854", "pdf": "https://arxiv.org/pdf/2505.16854", "abs": "https://arxiv.org/abs/2505.16854", "authors": ["Jiaqi Wang", "Kevin Qinghong Lin", "James Cheng", "Mike Zheng Shou"], "title": "Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Reinforcement Learning (RL) has proven to be an effective post-training\nstrategy for enhancing reasoning in vision-language models (VLMs). Group\nRelative Policy Optimization (GRPO) is a recent prominent method that\nencourages models to generate complete reasoning traces before answering,\nleading to increased token usage and computational cost. Inspired by the\nhuman-like thinking process-where people skip reasoning for easy questions but\nthink carefully when needed-we explore how to enable VLMs to first decide when\nreasoning is necessary. To realize this, we propose TON, a two-stage training\nstrategy: (i) a supervised fine-tuning (SFT) stage with a simple yet effective\n'thought dropout' operation, where reasoning traces are randomly replaced with\nempty thoughts. This introduces a think-or-not format that serves as a cold\nstart for selective reasoning; (ii) a GRPO stage that enables the model to\nfreely explore when to think or not, while maximizing task-aware outcome\nrewards. Experimental results show that TON can reduce the completion length by\nup to 90% compared to vanilla GRPO, without sacrificing performance or even\nimproving it. Further evaluations across diverse vision-language tasks-covering\na range of reasoning difficulties under both 3B and 7B models-consistently\nreveal that the model progressively learns to bypass unnecessary reasoning\nsteps as training advances. These findings shed light on the path toward\nhuman-like reasoning patterns in reinforcement learning approaches. Our code is\navailable at https://github.com/kokolerk/TON.", "AI": {"tldr": "A novel two-stage training strategy named TON is proposed to improve reasoning efficiency in vision-language models.", "motivation": "To enable vision-language models to determine when reasoning is necessary, inspired by human-like thinking processes.", "method": "TON includes a supervised fine-tuning stage with 'thought dropout' and a Group Relative Policy Optimization stage allowing models to freely decide when to reason.", "result": "TON reduces completion length by up to 90% compared to vanilla GRPO, improving efficiency without losing performance.", "conclusion": "The study suggests that TON helps vision-language models learn human-like reasoning patterns, which is beneficial for various vision-language tasks."}}
{"id": "2505.16353", "pdf": "https://arxiv.org/pdf/2505.16353", "abs": "https://arxiv.org/abs/2505.16353", "authors": ["C\u00e9line Comte", "Pascal Moyal"], "title": "Arrival Control in Quasi-Reversible Queueing Systems: Optimization and Reinforcement Learning", "categories": ["cs.LG", "math.OC", "math.PR"], "comment": null, "summary": "In this paper, we introduce a versatile scheme for optimizing the arrival\nrates of quasi-reversible queueing systems. We first propose an alternative\ndefinition of quasi-reversibility that encompasses reversibility and highlights\nthe importance of the definition of customer classes. In a second time, we\nintroduce balanced arrival control policies, which generalize the notion of\nbalanced arrival rates introduced in the context of Whittle networks, to the\nmuch broader class of quasi-reversible queueing systems. We prove that\nsupplementing a quasi-reversible queueing system with a balanced\narrival-control policy preserves the quasi-reversibility, and we specify the\nform of the stationary measures. We revisit two canonical examples of\nquasi-reversible queueing systems, Whittle networks and order-independent\nqueues. Lastly, we focus on the problem of admission control and leverage our\nresults in the frameworks of optimization and reinforcement learning.", "AI": {"tldr": "This paper introduces a new method for optimizing arrival rates in quasi-reversible queueing systems by defining balanced arrival control policies.", "motivation": "To improve the efficiency and performance of quasi-reversible queueing systems through better arrival rate optimization.", "method": "Proposes a new definition of quasi-reversibility and balanced arrival control policies, proving their impact on preserving quasi-reversibility and specifying stationary measures.", "result": "Successfully applies the method to Whittle networks and order-independent queues, also addresses admission control using optimization and reinforcement learning.", "conclusion": "The proposed scheme effectively optimizes arrival rates in a broad class of queueing systems, with potential applications in admission control."}}
{"id": "2505.16877", "pdf": "https://arxiv.org/pdf/2505.16877", "abs": "https://arxiv.org/abs/2505.16877", "authors": ["Yuqicheng Zhu", "Daniel Hern\u00e1ndez", "Yuan He", "Zifeng Ding", "Bo Xiong", "Evgeny Kharlamov", "Steffen Staab"], "title": "Predicate-Conditional Conformalized Answer Sets for Knowledge Graph Embeddings", "categories": ["cs.AI"], "comment": "Accepted to the Finding of ACL 2025", "summary": "Uncertainty quantification in Knowledge Graph Embedding (KGE) methods is\ncrucial for ensuring the reliability of downstream applications. A recent work\napplies conformal prediction to KGE methods, providing uncertainty estimates by\ngenerating a set of answers that is guaranteed to include the true answer with\na predefined confidence level. However, existing methods provide probabilistic\nguarantees averaged over a reference set of queries and answers (marginal\ncoverage guarantee). In high-stakes applications such as medical diagnosis, a\nstronger guarantee is often required: the predicted sets must provide\nconsistent coverage per query (conditional coverage guarantee). We propose\nCondKGCP, a novel method that approximates predicate-conditional coverage\nguarantees while maintaining compact prediction sets. CondKGCP merges\npredicates with similar vector representations and augments calibration with\nrank information. We prove the theoretical guarantees and demonstrate empirical\neffectiveness of CondKGCP by comprehensive evaluations.", "AI": {"tldr": "\u63d0\u51faCondKGCP\u65b9\u6cd5\uff0c\u63d0\u4f9b\u57fa\u4e8e\u8c13\u8bcd\u7684\u6761\u4ef6\u8986\u76d6\u4fdd\u8bc1\uff0c\u540c\u65f6\u4fdd\u6301\u7d27\u51d1\u7684\u9884\u6d4b\u96c6\uff0c\u8bc1\u660e\u4e86\u7406\u8bba\u4fdd\u969c\u5e76\u5c55\u793a\u4e86\u5b9e\u8bc1\u6709\u6548\u6027\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\u9700\u8981\u66f4\u5f3a\u7684\u9884\u6d4b\u96c6\u4e00\u81f4\u6027\u8986\u76d6\u4fdd\u8bc1\uff08\u6761\u4ef6\u8986\u76d6\u4fdd\u8bc1\uff09\u800c\u975e\u5e73\u5747\u8986\u76d6\u4fdd\u8bc1\uff08\u8fb9\u9645\u8986\u76d6\u4fdd\u8bc1\uff09\u3002", "method": "\u901a\u8fc7\u5408\u5e76\u5177\u6709\u76f8\u4f3c\u5411\u91cf\u8868\u793a\u7684\u8c13\u8bcd\u548c\u4f7f\u7528\u6392\u540d\u4fe1\u606f\u589e\u5f3a\u6821\u51c6\u6765\u8fd1\u4f3c\u63d0\u4f9b\u6761\u4ef6\u8986\u76d6\u4fdd\u8bc1\u3002", "result": "CondKGCP\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u5f3a\u7684\u6761\u4ef6\u8986\u76d6\u4fdd\u8bc1\u5e76\u4e14\u4fdd\u6301\u9884\u6d4b\u96c6\u7d27\u51d1\uff0c\u5728\u5168\u9762\u8bc4\u4f30\u4e2d\u8bc1\u660e\u4e86\u5176\u7406\u8bba\u4fdd\u969c\u548c\u5b9e\u8bc1\u6709\u6548\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5CondKGCP\u80fd\u591f\u5728\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u65b9\u6cd5\u4e2d\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5f3a\u9884\u6d4b\u4fdd\u8bc1\u7684\u9ad8\u98ce\u9669\u5e94\u7528\u573a\u666f\u4e2d\u3002"}}
{"id": "2505.16899", "pdf": "https://arxiv.org/pdf/2505.16899", "abs": "https://arxiv.org/abs/2505.16899", "authors": ["Kerem Oktar", "Katherine M. Collins", "Jose Hernandez-Orallo", "Diane Coyle", "Stephen Cave", "Adrian Weller", "Ilia Sucholutsky"], "title": "Identifying, Evaluating, and Mitigating Risks of AI Thought Partnerships", "categories": ["cs.AI"], "comment": null, "summary": "Artificial Intelligence (AI) systems have historically been used as tools\nthat execute narrowly defined tasks. Yet recent advances in AI have unlocked\npossibilities for a new class of models that genuinely collaborate with humans\nin complex reasoning, from conceptualizing problems to brainstorming solutions.\nSuch AI thought partners enable novel forms of collaboration and extended\ncognition, yet they also pose major risks-including and beyond risks of typical\nAI tools and agents. In this commentary, we systematically identify risks of AI\nthought partners through a novel framework that identifies risks at multiple\nlevels of analysis, including Real-time, Individual, and Societal risks arising\nfrom collaborative cognition (RISc). We leverage this framework to propose\nconcrete metrics for risk evaluation, and finally suggest specific mitigation\nstrategies for developers and policymakers. As AI thought partners continue to\nproliferate, these strategies can help prevent major harms and ensure that\nhumans actively benefit from productive thought partnerships.", "AI": {"tldr": "This commentary discusses the risks of AI thought partners and proposes evaluation metrics and mitigation strategies for developers and policymakers.", "motivation": "To explore the risks of AI thought partners and provide actionable suggestions for risk management.", "method": "A novel framework is used to identify risks at multiple levels of analysis, including real-time, individual, and societal risks.", "result": "The framework helps to propose concrete metrics for risk evaluation and suggests specific mitigation strategies.", "conclusion": "As AI thought partners become more common, these strategies can help prevent major harms and ensure human benefits."}}
{"id": "2505.16365", "pdf": "https://arxiv.org/pdf/2505.16365", "abs": "https://arxiv.org/abs/2505.16365", "authors": ["Manuel Ruiz-Botella", "Marta Sales-Pardo", "Roger Guimer\u00e0"], "title": "A collaborative constrained graph diffusion model for the generation of realistic synthetic molecules", "categories": ["cs.LG", "cs.AI", "physics.comp-ph", "q-bio.QM"], "comment": "28 pages, 10 figures, 4 tables", "summary": "Developing new molecular compounds is crucial to address pressing challenges,\nfrom health to environmental sustainability. However, exploring the molecular\nspace to discover new molecules is difficult due to the vastness of the space.\nHere we introduce CoCoGraph, a collaborative and constrained graph diffusion\nmodel capable of generating molecules that are guaranteed to be chemically\nvalid. Thanks to the constraints built into the model and to the collaborative\nmechanism, CoCoGraph outperforms state-of-the-art approaches on standard\nbenchmarks while requiring up to an order of magnitude fewer parameters.\nAnalysis of 36 chemical properties also demonstrates that CoCoGraph generates\nmolecules with distributions more closely matching real molecules than current\nmodels. Leveraging the model's efficiency, we created a database of 8.2M\nmillion synthetically generated molecules and conducted a Turing-like test with\norganic chemistry experts to further assess the plausibility of the generated\nmolecules, and potential biases and limitations of CoCoGraph.", "AI": {"tldr": "CoCoGraph is a novel graph diffusion model that efficiently generates chemically valid molecules, surpassing existing methods in performance and accuracy while using fewer parameters.", "motivation": "To address the challenge of exploring the vast molecular space for new compounds.", "method": "Introducing CoCoGraph, which uses collaborative and constrained graph diffusion.", "result": "Outperforms state-of-the-art approaches on benchmarks and creates a database of synthetic molecules.", "conclusion": "CoCoGraph is efficient and accurate in generating plausible molecules, with potential biases and limitations assessed through expert evaluation."}}
