{"id": "2505.15845", "pdf": "https://arxiv.org/pdf/2505.15845", "abs": "https://arxiv.org/abs/2505.15845", "authors": ["Zhibiao Wang", "Yunlong Zhou", "Ziwei Zhang", "Mengmei Zhang", "Shirui Pan", "Chunming Hu", "Xiao Wang"], "title": "Adaptive Tokenization: On the Hop-Overpriority Problem in Tokenized Graph Learning Models", "categories": ["cs.LG"], "comment": null, "summary": "Graph Transformers, leveraging the global attention to capture long-range\ndependencies in graph structures, have significantly advanced graph machine\nlearning, but face prohibitive computational complexity. Tokenized Graph\nLearning Models (TGLMs) address this issue by converting graphs into ordered\ntoken lists for scalable processing. Besides, TGLMs also empower Large Language\nModels (LLMs) to handle text-attributed graphs more effectively and thus are\nalso employed in Graph LLMs. However, existing TGLMs rely on hand-designed\ntoken lists and their adaptability to diverse graph learning scenarios remains\nunexplored. In this paper, we first conduct extensive empirical and theoretical\npreliminary studies for hand-designed token lists. Surprisingly, we identify an\nunexplored hop-overpriority problem: the common pre-defined token lists\noveremphasize nearby nodes and overwhelm the ability of TGLMs to balance local\nand global signals. This phenomenon is especially harmful for heterophilic\ngraphs. To address this problem, we propose the Learnable Graph Token List\n(LGTL), a plug-and-play module to replace hand-designed token lists in TGLMs.\nSpecifically, LGTL adaptively adjusts the weights across hops and prioritizes\ninformative nodes within hops through a graph attention gate module and a\nselection module, respectively. In this way, contextually informative nodes can\nbe adaptively emphasized for both homophilic and heterophilic graphs. Besides,\nwe theoretically show that LGTL can address the hop-overpriority problem.\nExtensive experiments on benchmarks validate the efficacy of LGTL across both\nGraph Transformers and Graph LLM backbones.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faLearnable Graph Token List (LGTL)\uff0c\u89e3\u51b3\u73b0\u6709TGLMs\u4e2dhop-overpriority\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u8282\u70b9\u6743\u91cd\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524dTokenized Graph Learning Models (TGLMs)\u4f9d\u8d56\u624b\u5de5\u8bbe\u8ba1\u7684token\u5217\u8868\uff0c\u5728\u5904\u7406\u5f02\u8d28\u56fe\u65f6\u96be\u4ee5\u5e73\u8861\u5c40\u90e8\u548c\u5168\u5c40\u4fe1\u53f7\uff0c\u5b58\u5728\u672a\u88ab\u63a2\u7d22\u7684hop-overpriority\u95ee\u9898\u3002", "method": "\u63d0\u51faLearnable Graph Token List (LGTL)\uff0c\u5305\u542b\u56fe\u6ce8\u610f\u529b\u95e8\u6a21\u5757\u548c\u9009\u62e9\u6a21\u5757\uff0c\u81ea\u9002\u5e94\u8c03\u6574\u4e0d\u540c\u8df3\u8dc3\u8ddd\u79bb\u7684\u8282\u70b9\u6743\u91cd\u5e76\u4f18\u5148\u8003\u8651\u4fe1\u606f\u4e30\u5bcc\u7684\u8282\u70b9\uff0c\u89e3\u51b3hop-overpriority\u95ee\u9898\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660eLGTL\u80fd\u6709\u6548\u89e3\u51b3hop-overpriority\u95ee\u9898\uff0c\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u5176\u5728Graph Transformers\u548cGraph LLM\u9aa8\u67b6\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "LGTL\u4f5c\u4e3a\u5373\u63d2\u5373\u7528\u6a21\u5757\uff0c\u53ef\u4ee5\u66ff\u4ee3\u624b\u5de5\u8bbe\u8ba1\u7684token\u5217\u8868\uff0c\u63d0\u5347TGLMs\u5bf9\u540c\u8d28\u548c\u5f02\u8d28\u56fe\u7684\u5b66\u4e60\u80fd\u529b\u3002"}}
{"id": "2505.15888", "pdf": "https://arxiv.org/pdf/2505.15888", "abs": "https://arxiv.org/abs/2505.15888", "authors": ["Valentin Villecroze", "Yixin Wang", "Gabriel Loaiza-Ganem"], "title": "Last Layer Empirical Bayes", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at the ICBINB Worshop at ICLR 2025", "summary": "The task of quantifying the inherent uncertainty associated with neural\nnetwork predictions is a key challenge in artificial intelligence. Bayesian\nneural networks (BNNs) and deep ensembles are among the most prominent\napproaches to tackle this task. Both approaches produce predictions by\ncomputing an expectation of neural network outputs over some distribution on\nthe corresponding weights; this distribution is given by the posterior in the\ncase of BNNs, and by a mixture of point masses for ensembles. Inspired by\nrecent work showing that the distribution used by ensembles can be understood\nas a posterior corresponding to a learned data-dependent prior, we propose last\nlayer empirical Bayes (LLEB). LLEB instantiates a learnable prior as a\nnormalizing flow, which is then trained to maximize the evidence lower bound;\nto retain tractability we use the flow only on the last layer. We show why LLEB\nis well motivated, and how it interpolates between standard BNNs and ensembles\nin terms of the strength of the prior that they use. LLEB performs on par with\nexisting approaches, highlighting that empirical Bayes is a promising direction\nfor future research in uncertainty quantification.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aLLEB\uff08last layer empirical Bayes\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u795e\u7ecf\u7f51\u7edc\u7684\u6700\u540e\u4e00\u5c42\u4f7f\u7528\u53ef\u5b66\u4e60\u7684\u5148\u9a8c\u5206\u5e03\u6765\u91cf\u5316\u9884\u6d4b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\u548c\u96c6\u6210\u65b9\u6cd5\u7684\u7279\u70b9\uff0c\u8868\u73b0\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\uff0c\u5e76\u4e3a\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002", "motivation": "\u5f53\u524d\u91cf\u5316\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u4e3b\u8981\u65b9\u6cd5\u5305\u62ec\u8d1d\u53f6\u65af\u795e\u7ecf\u7f51\u7edc\uff08BNNs\uff09\u548c\u6df1\u5ea6\u96c6\u6210\u3002\u8fd9\u4e9b\u65b9\u6cd5\u901a\u8fc7\u5728\u6743\u91cd\u5206\u5e03\u4e0a\u8ba1\u7b97\u671f\u671b\u6765\u8fdb\u884c\u9884\u6d4b\u3002\u53d7\u8fd1\u671f\u7814\u7a76\u542f\u53d1\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u96c6\u5408\u4e2d\u4f7f\u7528\u7684\u5206\u5e03\u53ef\u4ee5\u88ab\u7406\u89e3\u4e3a\u4e0e\u5b66\u4e60\u5230\u7684\u6570\u636e\u4f9d\u8d56\u578b\u5148\u9a8c\u76f8\u5bf9\u5e94\u7684\u540e\u9a8c\u8fd9\u4e00\u7279\u70b9\u3002", "method": "LLEB\u65b9\u6cd5\u5c06\u4e00\u4e2a\u53ef\u5b66\u4e60\u7684\u5148\u9a8c\u8868\u793a\u4e3a\u6b63\u5219\u5316\u6d41\uff08normalizing flow\uff09\uff0c\u5e76\u901a\u8fc7\u6700\u5927\u5316\u8bc1\u636e\u4e0b\u754c\uff08evidence lower bound\uff09\u5bf9\u5176\u8fdb\u884c\u8bad\u7ec3\u3002\u4e3a\u4e86\u4fdd\u6301\u53ef\u5904\u7406\u6027\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4ec5\u5e94\u7528\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6700\u540e\u4e00\u5c42\u3002", "result": "LLEB\u65b9\u6cd5\u7684\u8868\u73b0\u4e0e\u73b0\u6709\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u76f8\u5f53\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u5728\u6807\u51c6BNNs\u548c\u96c6\u6210\u65b9\u6cd5\u4e4b\u95f4\u8fdb\u884c\u63d2\u503c\uff0c\u53d6\u51b3\u4e8e\u6240\u4f7f\u7528\u5148\u9a8c\u7684\u5f3a\u5ea6\u3002", "conclusion": "LLEB\u662f\u4e00\u4e2a\u6709\u524d\u666f\u7684\u7814\u7a76\u65b9\u5411\uff0c\u7ed3\u5408\u4e86BNNs\u548c\u96c6\u6210\u65b9\u6cd5\u7684\u4f18\u70b9\uff0c\u4e3a\u672a\u6765\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2505.15909", "pdf": "https://arxiv.org/pdf/2505.15909", "abs": "https://arxiv.org/abs/2505.15909", "authors": ["Alex Kogan"], "title": "Is (Selective) Round-To-Nearest Quantization All You Need?", "categories": ["cs.LG", "I.2.7; D.4.8; G.4"], "comment": null, "summary": "Quantization became a necessary tool for serving ever-increasing Large\nLanguage Models (LLMs). RTN (Round-to-Nearest) is perhaps the simplest\nquantization technique that has been around well before LLMs surged to the\nforefront of machine learning (ML) research. Yet, it has been largely dismissed\nby recent and more advanced quantization methods that claim superiority over\nRTN in nearly every aspect of performance. This work aims to dispel this\nestablished point of view, showing that RTN is not only much cheaper to apply,\nbut also its token generation throughput can be better than and accuracy can be\nsimilar to more advanced alternatives. In particular, we discuss our\nimplementation of RTN based on the recent Marlin kernels and demonstrate how\nthe accuracy of RTN can be gradually improved by selectively increasing the\ndata precision format of certain model layers and modules. Based on our\nresults, we argue that RTN presents a viable and practical choice for\nquantizing LLMs.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86RTN\uff08Round-to-Nearest\uff09\u91cf\u5316\u65b9\u6cd5\uff0c\u8868\u660e\u5176\u5728\u6210\u672c\u548c\u6027\u80fd\u4e0a\u53ef\u4ee5\u4e0e\u66f4\u5148\u8fdb\u7684\u65b9\u6cd5\u5ab2\u7f8e\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u9009\u62e9\u6027\u63d0\u9ad8\u67d0\u4e9b\u6a21\u578b\u5c42\u7684\u6570\u636e\u7cbe\u5ea6\u683c\u5f0f\uff0c\u53ef\u4ee5\u9010\u6b65\u63d0\u9ad8RTN\u7684\u51c6\u786e\u6027\uff0c\u4ece\u800c\u4e3aLLMs\u7684\u91cf\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u884c\u4e14\u5b9e\u7528\u7684\u9009\u62e9\u3002", "motivation": "\u968f\u7740\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u53d1\u5c55\uff0c\u91cf\u5316\u6210\u4e3a\u5fc5\u8981\u7684\u5de5\u5177\u3002\u5c3d\u7ba1RTN\u662f\u6700\u7b80\u5355\u7684\u91cf\u5316\u6280\u672f\u4e4b\u4e00\uff0c\u4f46\u8fd1\u5e74\u6765\u5b83\u88ab\u8bb8\u591a\u66f4\u5148\u8fdb\u7684\u91cf\u5316\u65b9\u6cd5\u6240\u53d6\u4ee3\u3002\u672c\u7814\u7a76\u65e8\u5728\u7ea0\u6b63\u8fd9\u4e00\u89c2\u70b9\uff0c\u8bc1\u660eRTN\u4e0d\u4ec5\u5e94\u7528\u6210\u672c\u66f4\u4f4e\uff0c\u800c\u4e14\u5728\u67d0\u4e9b\u65b9\u9762\u6027\u80fd\u4e5f\u53ef\u4e0e\u5148\u8fdb\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u3002", "method": "\u4f5c\u8005\u57fa\u4e8e\u6700\u8fd1\u7684Marlin\u5185\u6838\u5b9e\u73b0\u4e86RTN\uff0c\u5e76\u901a\u8fc7\u9009\u62e9\u6027\u5730\u63d0\u9ad8\u7279\u5b9a\u6a21\u578b\u5c42\u548c\u6a21\u5757\u7684\u6570\u636e\u7cbe\u5ea6\u683c\u5f0f\uff0c\u9010\u6b65\u63d0\u9ad8\u4e86RTN\u7684\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRTN\u7684\u4ee4\u724c\u751f\u6210\u541e\u5410\u91cf\u53ef\u4ee5\u4f18\u4e8e\u66f4\u5148\u8fdb\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u4f3c\u7684\u51c6\u786e\u6027\u3002", "conclusion": "RTN\u4f5c\u4e3a\u4e00\u79cd\u7b80\u5355\u4e14\u4f4e\u6210\u672c\u7684\u91cf\u5316\u65b9\u6cd5\uff0c\u5bf9\u4e8eLLMs\u7684\u91cf\u5316\u4efb\u52a1\u6765\u8bf4\u662f\u4e00\u4e2a\u53ef\u884c\u4e14\u5b9e\u7528\u7684\u9009\u62e9\u3002"}}
{"id": "2505.15931", "pdf": "https://arxiv.org/pdf/2505.15931", "abs": "https://arxiv.org/abs/2505.15931", "authors": ["Morteza Alizadeh", "Mehrdad Oveisi", "Sonya Falahati", "Ghazal Mousavi", "Mohsen Alambardar Meybodi", "Somayeh Sadat Mehrnia", "Ilker Hacihaliloglu", "Arman Rahmim", "Mohammad R. Salmanpour"], "title": "AllMetrics: A Unified Python Library for Standardized Metric Evaluation and Robust Data Validation in Machine Learning", "categories": ["cs.LG", "F.2.2; I.2.7"], "comment": null, "summary": "Machine learning (ML) models rely heavily on consistent and accurate\nperformance metrics to evaluate and compare their effectiveness. However,\nexisting libraries often suffer from fragmentation, inconsistent\nimplementations, and insufficient data validation protocols, leading to\nunreliable results. Existing libraries have often been developed independently\nand without adherence to a unified standard, particularly concerning the\nspecific tasks they aim to support. As a result, each library tends to adopt\nits conventions for metric computation, input/output formatting, error\nhandling, and data validation protocols. This lack of standardization leads to\nboth implementation differences (ID) and reporting differences (RD), making it\ndifficult to compare results across frameworks or ensure reliable evaluations.\nTo address these issues, we introduce AllMetrics, an open-source unified Python\nlibrary designed to standardize metric evaluation across diverse ML tasks,\nincluding regression, classification, clustering, segmentation, and\nimage-to-image translation. The library implements class-specific reporting for\nmulti-class tasks through configurable parameters to cover all use cases, while\nincorporating task-specific parameters to resolve metric computation\ndiscrepancies across implementations. Various datasets from domains like\nhealthcare, finance, and real estate were applied to our library and compared\nwith Python, Matlab, and R components to identify which yield similar results.\nAllMetrics combines a modular Application Programming Interface (API) with\nrobust input validation mechanisms to ensure reproducibility and reliability in\nmodel evaluation. This paper presents the design principles, architectural\ncomponents, and empirical analyses demonstrating the ability to mitigate\nevaluation errors and to enhance the trustworthiness of ML workflows.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aAllMetrics\u7684\u5f00\u6e90Python\u5e93\uff0c\u65e8\u5728\u901a\u8fc7\u6807\u51c6\u5316\u4e0d\u540c\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u5ea6\u91cf\u8bc4\u4f30\u6765\u89e3\u51b3\u73b0\u6709\u5e93\u4e2d\u788e\u7247\u5316\u3001\u4e0d\u4e00\u81f4\u5b9e\u73b0\u548c\u6570\u636e\u9a8c\u8bc1\u534f\u8bae\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u8be5\u5e93\u652f\u6301\u591a\u79cdML\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u6a21\u5757\u5316API\u548c\u5f3a\u5927\u7684\u8f93\u5165\u9a8c\u8bc1\u673a\u5236\u786e\u4fdd\u6a21\u578b\u8bc4\u4f30\u7684\u53ef\u91cd\u590d\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u673a\u5668\u5b66\u4e60\u5ea6\u91cf\u5e93\u5b58\u5728\u788e\u7247\u5316\u3001\u4e0d\u4e00\u81f4\u7684\u5b9e\u73b0\u4ee5\u53ca\u6570\u636e\u9a8c\u8bc1\u534f\u8bae\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u53ef\u9760\uff0c\u96be\u4ee5\u8de8\u6846\u67b6\u6bd4\u8f83\u3002", "method": "\u5f15\u5165\u4e86AllMetrics\u5e93\uff0c\u4e00\u4e2a\u7edf\u4e00\u7684Python\u5e93\uff0c\u7528\u4e8e\u6807\u51c6\u5316\u5404\u79cd\u673a\u5668\u5b66\u4e60\u4efb\u52a1\uff08\u5982\u56de\u5f52\u3001\u5206\u7c7b\u3001\u805a\u7c7b\u7b49\uff09\u7684\u5ea6\u91cf\u8bc4\u4f30\u3002\u8be5\u5e93\u5177\u6709\u4efb\u52a1\u7279\u5b9a\u53c2\u6570\u548c\u7c7b\u7279\u5b9a\u62a5\u544a\u529f\u80fd\uff0c\u4ee5\u89e3\u51b3\u8ba1\u7b97\u5dee\u5f02\uff0c\u5e76\u901a\u8fc7\u6a21\u5757\u5316API\u548c\u5f3a\u8f93\u5165\u9a8c\u8bc1\u786e\u4fdd\u53ef\u9760\u6027\u548c\u53ef\u91cd\u590d\u6027\u3002", "result": "\u5728\u591a\u4e2a\u9886\u57df\uff08\u5982\u533b\u7597\u3001\u91d1\u878d\u3001\u623f\u5730\u4ea7\uff09\u7684\u6570\u636e\u96c6\u4e0a\u5e94\u7528AllMetrics\u5e93\uff0c\u4e0ePython\u3001Matlab\u548cR\u7ec4\u4ef6\u8fdb\u884c\u6bd4\u8f83\uff0c\u8bc1\u660e\u5176\u80fd\u591f\u4ea7\u751f\u76f8\u4f3c\u7684\u7ed3\u679c\u5e76\u51cf\u5c11\u8bc4\u4f30\u8bef\u5dee\u3002", "conclusion": "AllMetrics\u5e93\u901a\u8fc7\u8bbe\u8ba1\u539f\u5219\u3001\u67b6\u6784\u7ec4\u4ef6\u548c\u5b9e\u8bc1\u5206\u6790\u5c55\u793a\u4e86\u5176\u51cf\u5c11\u8bc4\u4f30\u9519\u8bef\u548c\u63d0\u9ad8\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u53ef\u4fe1\u5ea6\u7684\u80fd\u529b\u3002"}}
{"id": "2505.15927", "pdf": "https://arxiv.org/pdf/2505.15927", "abs": "https://arxiv.org/abs/2505.15927", "authors": ["Awni Altabaa", "Omar Montasser", "John Lafferty"], "title": "CoT Information: Improved Sample Complexity under Chain-of-Thought Supervision", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Learning complex functions that involve multi-step reasoning poses a\nsignificant challenge for standard supervised learning from input-output\nexamples. Chain-of-thought (CoT) supervision, which provides intermediate\nreasoning steps together with the final output, has emerged as a powerful\nempirical technique, underpinning much of the recent progress in the reasoning\ncapabilities of large language models. This paper develops a statistical theory\nof learning under CoT supervision. A key characteristic of the CoT setting, in\ncontrast to standard supervision, is the mismatch between the training\nobjective (CoT risk) and the test objective (end-to-end risk). A central part\nof our analysis, distinguished from prior work, is explicitly linking those two\ntypes of risk to achieve sharper sample complexity bounds. This is achieved via\nthe *CoT information measure* $\\mathcal{I}_{\\mathcal{D},\nh_\\star}^{\\mathrm{CoT}}(\\epsilon; \\calH)$, which quantifies the additional\ndiscriminative power gained from observing the reasoning process. The main\ntheoretical results demonstrate how CoT supervision can yield significantly\nfaster learning rates compared to standard E2E supervision. Specifically, it is\nshown that the sample complexity required to achieve a target E2E error\n$\\epsilon$ scales as $d/\\mathcal{I}_{\\mathcal{D},\nh_\\star}^{\\mathrm{CoT}}(\\epsilon; \\calH)$, where $d$ is a measure of hypothesis\nclass complexity, which can be much faster than standard $d/\\epsilon$ rates.\nInformation-theoretic lower bounds in terms of the CoT information are also\nobtained. Together, these results suggest that CoT information is a fundamental\nmeasure of statistical complexity for learning under chain-of-thought\nsupervision.", "AI": {"tldr": "This paper develops a statistical theory for chain-of-thought (CoT) supervision, showing it leads to faster learning rates than standard methods by using the CoT information measure.", "motivation": "Learning complex functions involving multi-step reasoning is challenging for standard supervised learning. CoT supervision has emerged as an effective technique in enhancing reasoning capabilities of large language models.", "method": "Developing a statistical theory of learning under CoT supervision, and explicitly linking the CoT risk and end-to-end risk to achieve sharper sample complexity bounds via the CoT information measure.", "result": "Theoretical results show that CoT supervision can yield significantly faster learning rates compared to standard E2E supervision, with sample complexity scaling as d/I(D,h\u22c6)COT(\u03b5;H).", "conclusion": "CoT information is a fundamental measure of statistical complexity for learning under chain-of-thought supervision."}}
{"id": "2505.15862", "pdf": "https://arxiv.org/pdf/2505.15862", "abs": "https://arxiv.org/abs/2505.15862", "authors": ["Long Wanga", "Jiongzhi Zheng", "Zhengda Xiong", "ChuMin Li", "Kun He"], "title": "Bandit based Dynamic Candidate Edge Selection in Solving Traveling Salesman Problems", "categories": ["cs.AI"], "comment": null, "summary": "Algorithms designed for routing problems typically rely on high-quality\ncandidate edges to guide their search, aiming to reduce the search space and\nenhance the search efficiency. However, many existing algorithms, like the\nclassical Lin-Kernighan-Helsgaun (LKH) algorithm for the Traveling Salesman\nProblem (TSP), often use predetermined candidate edges that remain static\nthroughout local searches. This rigidity could cause the algorithm to get\ntrapped in local optima, limiting its potential to find better solutions. To\naddress this issue, we propose expanding the candidate sets to include other\npromising edges, providing them an opportunity for selection. Specifically, we\nincorporate multi-armed bandit models to dynamically select the most suitable\ncandidate edges in each iteration, enabling LKH to make smarter choices and\nlead to improved solutions. Extensive experiments on multiple TSP benchmarks\nshow the excellent performance of our method. Moreover, we employ this\nbandit-based method to LKH-3, an extension of LKH tailored for solving various\nTSP variant problems, and our method also significantly enhances LKH-3's\nperformance across typical TSP variants.", "AI": {"tldr": "\u4f7f\u7528\u591a\u81c2\u8001\u864e\u673a\u6a21\u578b\u52a8\u6001\u9009\u62e9\u5019\u9009\u8fb9\u4ee5\u6539\u8fdbLKH\u7b97\u6cd5\u5728TSP\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u7ecf\u5178LKH\u7b97\u6cd5\u4f7f\u7528\u7684\u9884\u8bbe\u5019\u9009\u8fb9\u5728\u5c40\u90e8\u641c\u7d22\u4e2d\u4fdd\u6301\u9759\u6001\uff0c\u53ef\u80fd\u5bfc\u81f4\u9677\u5165\u5c40\u90e8\u6700\u4f18\u89e3\uff0c\u9650\u5236\u4e86\u5bfb\u627e\u66f4\u4f18\u89e3\u7684\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u5019\u9009\u96c6\u5e76\u52a0\u5165\u6709\u5e0c\u671b\u7684\u8fb9\uff0c\u7ed3\u5408\u591a\u81c2\u8001\u864e\u673a\u6a21\u578b\u52a8\u6001\u9009\u62e9\u6bcf\u6b21\u8fed\u4ee3\u4e2d\u6700\u5408\u9002\u7684\u5019\u9009\u8fb9\uff0c\u4ece\u800c\u63d0\u5347LKH\u7b97\u6cd5\u7684\u6027\u80fd\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2aTSP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u663e\u8457\u63d0\u5347\u4e86LKH-3\u5728\u5178\u578bTSP\u53d8\u79cd\u95ee\u9898\u4e0a\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u591a\u81c2\u8001\u864e\u673a\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u6539\u5584LKH\u548cLKH-3\u7b97\u6cd5\u5728\u89e3\u51b3TSP\u53ca\u5176\u53d8\u79cd\u95ee\u9898\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2505.15946", "pdf": "https://arxiv.org/pdf/2505.15946", "abs": "https://arxiv.org/abs/2505.15946", "authors": ["Yuxiang Wei", "Yanteng Zhang", "Xi Xiao", "Tianyang Wang", "Xiao Wang", "Vince D. Calhoun"], "title": "MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.HC"], "comment": null, "summary": "Decoding visual experiences from fMRI offers a powerful avenue to understand\nhuman perception and develop advanced brain-computer interfaces. However,\ncurrent progress often prioritizes maximizing reconstruction fidelity while\noverlooking interpretability, an essential aspect for deriving neuroscientific\ninsight. To address this gap, we propose MoRE-Brain, a neuro-inspired framework\ndesigned for high-fidelity, adaptable, and interpretable visual reconstruction.\nMoRE-Brain uniquely employs a hierarchical Mixture-of-Experts architecture\nwhere distinct experts process fMRI signals from functionally related voxel\ngroups, mimicking specialized brain networks. The experts are first trained to\nencode fMRI into the frozen CLIP space. A finetuned diffusion model then\nsynthesizes images, guided by expert outputs through a novel dual-stage routing\nmechanism that dynamically weighs expert contributions across the diffusion\nprocess. MoRE-Brain offers three main advancements: First, it introduces a\nnovel Mixture-of-Experts architecture grounded in brain network principles for\nneuro-decoding. Second, it achieves efficient cross-subject generalization by\nsharing core expert networks while adapting only subject-specific routers.\nThird, it provides enhanced mechanistic insight, as the explicit routing\nreveals precisely how different modeled brain regions shape the semantic and\nspatial attributes of the reconstructed image. Extensive experiments validate\nMoRE-Brain's high reconstruction fidelity, with bottleneck analyses further\ndemonstrating its effective utilization of fMRI signals, distinguishing genuine\nneural decoding from over-reliance on generative priors. Consequently,\nMoRE-Brain marks a substantial advance towards more generalizable and\ninterpretable fMRI-based visual decoding. Code will be publicly available soon:\nhttps://github.com/yuxiangwei0808/MoRE-Brain.", "AI": {"tldr": "MoRE-Brain\u662f\u4e00\u4e2a\u53d7\u795e\u7ecf\u542f\u53d1\u7684\u6846\u67b6\uff0c\u65e8\u5728\u5b9e\u73b0\u9ad8\u4fdd\u771f\u3001\u9002\u5e94\u6027\u5f3a\u548c\u53ef\u89e3\u91ca\u7684\u89c6\u89c9\u91cd\u5efa\u3002\u5b83\u91c7\u7528\u5206\u5c42Mixture-of-Experts\u67b6\u6784\uff0c\u6a21\u4eff\u4e13\u95e8\u7684\u8111\u7f51\u7edc\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u53cc\u9636\u6bb5\u8def\u7531\u673a\u5236\u5408\u6210\u56fe\u50cf\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u9ad8\u91cd\u5efa\u4fdd\u771f\u5ea6\u548c\u6709\u6548\u5229\u7528fMRI\u4fe1\u53f7\u7684\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u4ecefMRI\u89e3\u7801\u89c6\u89c9\u4f53\u9a8c\u7684\u7814\u7a76\u5f80\u5f80\u8fc7\u4e8e\u5173\u6ce8\u6700\u5927\u5316\u91cd\u5efa\u4fdd\u771f\u5ea6\uff0c\u800c\u5ffd\u7565\u4e86\u53ef\u89e3\u91ca\u6027\uff0c\u8fd9\u5bf9\u83b7\u5f97\u795e\u7ecf\u79d1\u5b66\u6d1e\u5bdf\u529b\u81f3\u5173\u91cd\u8981\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u63d0\u4f9b\u9ad8\u4fdd\u771f\u5ea6\u3001\u9002\u5e94\u6027\u5f3a\u548c\u53ef\u89e3\u91ca\u7684\u89c6\u89c9\u91cd\u5efa\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMoRE-Brain\u7684\u795e\u7ecf\u542f\u53d1\u5f0f\u6846\u67b6\u3002\u8be5\u6846\u67b6\u91c7\u7528\u5c42\u6b21\u5316\u7684Mixture-of-Experts\u67b6\u6784\uff0c\u4e0d\u540c\u7684\u4e13\u5bb6\u5904\u7406\u529f\u80fd\u76f8\u5173\u7684\u4f53\u7d20\u7ec4\u7684fMRI\u4fe1\u53f7\uff0c\u6a21\u62df\u4e13\u4e1a\u5316\u7684\u8111\u7f51\u7edc\u3002\u9996\u5148\u5c06\u4e13\u5bb6\u8bad\u7ec3\u4e3a\u5c06fMRI\u7f16\u7801\u5230\u51bb\u7ed3\u7684CLIP\u7a7a\u95f4\u4e2d\uff0c\u7136\u540e\u901a\u8fc7\u65b0\u9896\u7684\u53cc\u9636\u6bb5\u8def\u7531\u673a\u5236\u5f15\u5bfc\u7cbe\u7ec6\u8c03\u6574\u7684\u6269\u6563\u6a21\u578b\u5408\u6210\u56fe\u50cf\u3002\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8de8\u4e3b\u4f53\u6cdb\u5316\uff0c\u5e76\u63d0\u4f9b\u4e86\u589e\u5f3a\u7684\u673a\u5236\u6d1e\u5bdf\u529b\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86MoRE-Brain\u5177\u6709\u9ad8\u91cd\u5efa\u4fdd\u771f\u5ea6\uff0c\u74f6\u9888\u5206\u6790\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u5176\u5bf9fMRI\u4fe1\u53f7\u7684\u6709\u6548\u5229\u7528\uff0c\u533a\u5206\u4e86\u771f\u5b9e\u7684\u795e\u7ecf\u89e3\u7801\u4e0e\u8fc7\u5ea6\u4f9d\u8d56\u751f\u6210\u5148\u9a8c\u3002", "conclusion": "MoRE-Brain\u6807\u5fd7\u7740\u57fa\u4e8efMRI\u7684\u89c6\u89c9\u89e3\u7801\u5728\u66f4\u901a\u7528\u548c\u53ef\u89e3\u91ca\u65b9\u5411\u4e0a\u7684\u91cd\u5927\u8fdb\u5c55\u3002\u4ee3\u7801\u5373\u5c06\u516c\u5f00\u3002"}}
{"id": "2505.16051", "pdf": "https://arxiv.org/pdf/2505.16051", "abs": "https://arxiv.org/abs/2505.16051", "authors": ["Dongze Wu", "David I. Inouye", "Yao Xie"], "title": "PO-Flow: Flow-based Generative Models for Sampling Potential Outcomes and Counterfactuals", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We propose PO-Flow, a novel continuous normalizing flow (CNF) framework for\ncausal inference that jointly models potential outcomes and counterfactuals.\nTrained via flow matching, PO-Flow provides a unified framework for\nindividualized potential outcome prediction, counterfactual predictions, and\nuncertainty-aware density learning. Among generative models, it is the first to\nenable density learning of potential outcomes without requiring explicit\ndistributional assumptions (e.g., Gaussian mixtures), while also supporting\ncounterfactual prediction conditioned on factual outcomes in general\nobservational datasets. On benchmarks such as ACIC, IHDP, and IBM, it\nconsistently outperforms prior methods across a range of causal inference\ntasks. Beyond that, PO-Flow succeeds in high-dimensional settings, including\ncounterfactual image generation, demonstrating its broad applicability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPO-Flow\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u56e0\u679c\u63a8\u7406\u7684\u8fde\u7eed\u5f52\u4e00\u5316\u6d41\uff08CNF\uff09\uff0c\u53ef\u8054\u5408\u5efa\u6a21\u6f5c\u5728\u7ed3\u679c\u548c\u53cd\u4e8b\u5b9e\u3002\u901a\u8fc7\u6d41\u5339\u914d\u8bad\u7ec3\uff0cPO-Flow\u4e3a\u4e2a\u4f53\u6f5c\u5728\u7ed3\u679c\u9884\u6d4b\u3001\u53cd\u4e8b\u5b9e\u9884\u6d4b\u4ee5\u53ca\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u5bc6\u5ea6\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u3002\u8fd9\u662f\u9996\u4e2a\u5728\u4e0d\u8981\u6c42\u663e\u5f0f\u5206\u5e03\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6f5c\u5728\u7ed3\u679c\u5bc6\u5ea6\u5b66\u4e60\u7684\u751f\u6210\u6a21\u578b\uff0c\u5e76\u652f\u6301\u57fa\u4e8e\u4e00\u822c\u89c2\u5bdf\u6570\u636e\u96c6\u7684\u4e8b\u5b9e\u7ed3\u679c\u6761\u4ef6\u4e0b\u7684\u53cd\u4e8b\u5b9e\u9884\u6d4b\u3002\u5728ACIC\u3001IHDP\u548cIBM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5b83\u5728\u4e00\u7cfb\u5217\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u5148\u524d\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0cPO-Flow\u5728\u9ad8\u7ef4\u8bbe\u7f6e\u4e2d\u4e5f\u8868\u73b0\u51fa\u8272\uff0c\u5305\u62ec\u53cd\u4e8b\u5b9e\u56fe\u50cf\u751f\u6210\uff0c\u5c55\u793a\u4e86\u5176\u5e7f\u6cdb\u9002\u7528\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u56e0\u679c\u63a8\u7406\u65b9\u6cd5\u53ef\u80fd\u9700\u8981\u663e\u5f0f\u7684\u5206\u5e03\u5047\u8bbe\u6216\u96be\u4ee5\u5904\u7406\u9ad8\u7ef4\u6570\u636e\uff0c\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u4e0d\u9700\u8981\u663e\u5f0f\u5206\u5e03\u5047\u8bbe\u4e14\u80fd\u591f\u540c\u65f6\u5904\u7406\u6f5c\u5728\u7ed3\u679c\u548c\u53cd\u4e8b\u5b9e\u9884\u6d4b\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u56e0\u679c\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u9002\u7528\u6027\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86PO-Flow\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u8fde\u7eed\u5f52\u4e00\u5316\u6d41\uff08CNF\uff09\u7684\u56e0\u679c\u63a8\u7406\u6846\u67b6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u6d41\u5339\u914d\u8fdb\u884c\u8bad\u7ec3\uff0c\u53ef\u4ee5\u8054\u5408\u5efa\u6a21\u6f5c\u5728\u7ed3\u679c\u548c\u53cd\u4e8b\u5b9e\u3002PO-Flow\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u6f5c\u5728\u7ed3\u679c\u7684\u5bc6\u5ea6\u5b66\u4e60\uff0c\u8fd8\u652f\u6301\u57fa\u4e8e\u89c2\u5bdf\u6570\u636e\u7684\u4e8b\u5b9e\u7ed3\u679c\u6761\u4ef6\u4e0b\u7684\u53cd\u4e8b\u5b9e\u9884\u6d4b\u3002", "result": "PO-Flow\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08\u5982ACIC\u3001IHDP\u548cIBM\uff09\u4e0a\u7684\u4e00\u7cfb\u5217\u56e0\u679c\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5148\u524d\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u5728\u9ad8\u7ef4\u6570\u636e\uff08\u5982\u56fe\u50cf\u751f\u6210\uff09\u4e2d\u6210\u529f\u5e94\u7528\uff0c\u8bc1\u660e\u4e86\u5176\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002", "conclusion": "PO-Flow\u662f\u4e00\u79cd\u5f3a\u5927\u7684\u56e0\u679c\u63a8\u7406\u5de5\u5177\uff0c\u80fd\u591f\u5728\u4e0d\u8981\u6c42\u663e\u5f0f\u5206\u5e03\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u6f5c\u5728\u7ed3\u679c\u5bc6\u5ea6\u5b66\u4e60\u548c\u53cd\u4e8b\u5b9e\u9884\u6d4b\uff0c\u5e76\u9002\u7528\u4e8e\u9ad8\u7ef4\u6570\u636e\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2505.15929", "pdf": "https://arxiv.org/pdf/2505.15929", "abs": "https://arxiv.org/abs/2505.15929", "authors": ["Hui Shen", "Taiqiang Wu", "Qi Han", "Yunta Hsieh", "Jizhou Wang", "Yuyue Zhang", "Yuxin Cheng", "Zijian Hao", "Yuansheng Ni", "Xin Wang", "Zhongwei Wan", "Kai Zhang", "Wendong Xu", "Jing Xiong", "Ping Luo", "Wenhu Chen", "Chaofan Tao", "Zhuoqing Mao", "Ngai Wong"], "title": "PhyX: Does Your Model Have the \"Wits\" for Physical Reasoning?", "categories": ["cs.AI"], "comment": null, "summary": "Existing benchmarks fail to capture a crucial aspect of intelligence:\nphysical reasoning, the integrated ability to combine domain knowledge,\nsymbolic reasoning, and understanding of real-world constraints. To address\nthis gap, we introduce PhyX: the first large-scale benchmark designed to assess\nmodels capacity for physics-grounded reasoning in visual scenarios. PhyX\nincludes 3K meticulously curated multimodal questions spanning 6 reasoning\ntypes across 25 sub-domains and 6 core physics domains: thermodynamics,\nelectromagnetism, mechanics, modern physics, optics, and wave\\&acoustics. In\nour comprehensive evaluation, even state-of-the-art models struggle\nsignificantly with physical reasoning. GPT-4o, Claude3.7-Sonnet, and\nGPT-o4-mini achieve only 32.5\\%, 42.2\\%, and 45.8\\% accuracy\nrespectively-performance gaps exceeding 29\\% compared to human experts. Our\nanalysis exposes critical limitations in current models: over-reliance on\nmemorized disciplinary knowledge, excessive dependence on mathematical\nformulations, and surface-level visual pattern matching rather than genuine\nphysical understanding. We provide in-depth analysis through fine-grained\nstatistics, detailed case studies, and multiple evaluation paradigms to\nthoroughly examine physical reasoning capabilities. To ensure reproducibility,\nwe implement a compatible evaluation protocol based on widely-used toolkits\nsuch as VLMEvalKit, enabling one-click evaluation.", "AI": {"tldr": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u6355\u6349\u5230\u667a\u80fd\u7684\u4e00\u4e2a\u5173\u952e\u65b9\u9762\uff1a\u7269\u7406\u63a8\u7406\u3002\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u6211\u4eec\u5f15\u5165\u4e86PhyX\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\uff0c\u65e8\u5728\u8bc4\u4f30\u6a21\u578b\u5728\u89c6\u89c9\u573a\u666f\u4e2d\u57fa\u4e8e\u7269\u7406\u7684\u63a8\u7406\u80fd\u529b\u3002PhyX\u5305\u542b3K\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684\u591a\u6a21\u6001\u95ee\u9898\uff0c\u6db5\u76d6\u4e866\u79cd\u63a8\u7406\u7c7b\u578b\u300125\u4e2a\u5b50\u9886\u57df\u548c6\u4e2a\u6838\u5fc3\u7269\u7406\u9886\u57df\u3002\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5728\u7269\u7406\u63a8\u7406\u65b9\u9762\u4e5f\u663e\u8457\u6323\u624e\u3002\u6211\u4eec\u7684\u5206\u6790\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u7684\u5173\u952e\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u8be6\u7ec6\u7684\u7edf\u8ba1\u3001\u6848\u4f8b\u7814\u7a76\u548c\u591a\u79cd\u8bc4\u4f30\u8303\u5f0f\u63d0\u4f9b\u4e86\u6df1\u5165\u5206\u6790\u3002\u4e3a\u786e\u4fdd\u53ef\u91cd\u590d\u6027\uff0c\u6211\u4eec\u57fa\u4e8e\u5e7f\u6cdb\u4f7f\u7528\u7684\u5de5\u5177\u5305\u5b9e\u73b0\u4e86\u517c\u5bb9\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u4f7f\u4e00\u952e\u8bc4\u4f30\u6210\u4e3a\u53ef\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u6355\u6349\u5230\u667a\u80fd\u7684\u4e00\u4e2a\u5173\u952e\u65b9\u9762\uff1a\u7269\u7406\u63a8\u7406\uff0c\u5373\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u3001\u7b26\u53f7\u63a8\u7406\u548c\u7406\u89e3\u73b0\u5b9e\u4e16\u754c\u7ea6\u675f\u7684\u7efc\u5408\u80fd\u529b\u3002", "method": "\u5f15\u5165\u4e86PhyX\uff0c\u4e00\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b3K\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684\u591a\u6a21\u6001\u95ee\u9898\uff0c\u6db5\u76d66\u79cd\u63a8\u7406\u7c7b\u578b\u300125\u4e2a\u5b50\u9886\u57df\u548c6\u4e2a\u6838\u5fc3\u7269\u7406\u9886\u57df\uff08\u70ed\u529b\u5b66\u3001\u7535\u78c1\u5b66\u3001\u529b\u5b66\u3001\u73b0\u4ee3\u7269\u7406\u5b66\u3001\u5149\u5b66\u548c\u6ce2\u58f0\u5b66\uff09\u3002\u91c7\u7528\u517c\u5bb9\u7684\u8bc4\u4f30\u534f\u8bae\u5e76\u4f7f\u7528\u5e7f\u6cdb\u4f7f\u7528\u7684\u5de5\u5177\u5305\u5982VLMEvalKit\u5b9e\u73b0\u4e00\u952e\u8bc4\u4f30\u3002", "result": "\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff08\u5982GPT-4o\u3001Claude3.7-Sonnet\u548cGPT-o4-mini\uff09\u5728\u7269\u7406\u63a8\u7406\u65b9\u9762\u7684\u8868\u73b0\u5206\u522b\u4ec5\u4e3a32.5%\u300142.2%\u548c45.8%\uff0c\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u6bd4\u6027\u80fd\u5dee\u8ddd\u8d85\u8fc729%\u3002\u5f53\u524d\u6a21\u578b\u5b58\u5728\u5173\u952e\u5c40\u9650\u6027\uff0c\u4f8b\u5982\u8fc7\u5ea6\u4f9d\u8d56\u8bb0\u5fc6\u4e2d\u7684\u5b66\u79d1\u77e5\u8bc6\u3001\u6570\u5b66\u516c\u5f0f\u548c\u8868\u9762\u7ea7\u522b\u7684\u89c6\u89c9\u6a21\u5f0f\u5339\u914d\u3002", "conclusion": "PhyX\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u7269\u7406\u63a8\u7406\u65b9\u9762\u7684\u663e\u8457\u4e0d\u8db3\uff0c\u5f3a\u8c03\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u8fbe\u5230\u66f4\u6df1\u5c42\u6b21\u7684\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002\u63d0\u4f9b\u7684\u8be6\u7ec6\u5206\u6790\u548c\u8bc4\u4f30\u6846\u67b6\u6709\u52a9\u4e8e\u672a\u6765\u7684\u7814\u7a76\u548c\u53d1\u5c55\u3002"}}
{"id": "2505.15987", "pdf": "https://arxiv.org/pdf/2505.15987", "abs": "https://arxiv.org/abs/2505.15987", "authors": ["Aaron Zweig", "Zaikang Lin", "Elham Azizi", "David Knowles"], "title": "Towards Identifiability of Interventional Stochastic Differential Equations", "categories": ["cs.LG"], "comment": null, "summary": "We study identifiability of stochastic differential equation (SDE) models\nunder multiple interventions. Our results give the first provable bounds for\nunique recovery of SDE parameters given samples from their stationary\ndistributions. We give tight bounds on the number of necessary interventions\nfor linear SDEs, and upper bounds for nonlinear SDEs in the small noise regime.\nWe experimentally validate the recovery of true parameters in synthetic data,\nand motivated by our theoretical results, demonstrate the advantage of\nparameterizations with learnable activation functions.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u591a\u6b21\u5e72\u9884\u4e0b\u968f\u673a\u5fae\u5206\u65b9\u7a0b(SDE)\u6a21\u578b\u7684\u53ef\u8bc6\u522b\u6027\u3002\u7ed3\u679c\u63d0\u4f9b\u4e86\u4ece\u5176\u5e73\u7a33\u5206\u5e03\u6837\u672c\u4e2d\u552f\u4e00\u6062\u590dSDE\u53c2\u6570\u7684\u7b2c\u4e00\u4e2a\u53ef\u8bc1\u660e\u7684\u754c\u9650\u3002\u5bf9\u4e8e\u7ebf\u6027SDE\uff0c\u7ed9\u51fa\u4e86\u5fc5\u8981\u7684\u5e72\u9884\u6b21\u6570\u7684\u4e25\u683c\u754c\u9650\uff1b\u5bf9\u4e8e\u975e\u7ebf\u6027SDE\uff0c\u5728\u5c0f\u566a\u58f0\u6761\u4ef6\u4e0b\u7ed9\u51fa\u4e86\u4e0a\u9650\u3002\u901a\u8fc7\u5408\u6210\u6570\u636e\u9a8c\u8bc1\u4e86\u771f\u5b9e\u53c2\u6570\u6062\u590d\u7684\u6709\u6548\u6027\uff0c\u5e76\u57fa\u4e8e\u7406\u8bba\u7ed3\u679c\u5c55\u793a\u4e86\u5177\u6709\u53ef\u5b66\u4e60\u6fc0\u6d3b\u51fd\u6570\u7684\u53c2\u6570\u5316\u7684\u4f18\u70b9\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u6a21\u578b\u5728\u591a\u6b21\u5e72\u9884\u4e0b\u7684\u53c2\u6570\u8bc6\u522b\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u5e73\u7a33\u5206\u5e03\u6837\u672c\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u80fd\u591f\u552f\u4e00\u5730\u6062\u590dSDE\u53c2\u6570\u3002", "method": "\u901a\u8fc7\u5bf9\u7ebf\u6027\u548c\u975e\u7ebf\u6027SDE\u8fdb\u884c\u5206\u6790\uff0c\u7ed9\u51fa\u5e72\u9884\u6b21\u6570\u7684\u754c\u9650\u3002\u5bf9\u4e8e\u7ebf\u6027SDE\u63d0\u4f9b\u4e25\u683c\u7684\u754c\u9650\uff0c\u800c\u5bf9\u4e8e\u975e\u7ebf\u6027SDE\u5219\u662f\u5728\u5c0f\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u4e0a\u9650\u3002\u5b9e\u9a8c\u90e8\u5206\u4f7f\u7528\u5408\u6210\u6570\u636e\u9a8c\u8bc1\u53c2\u6570\u6062\u590d\u7684\u6548\u679c\uff0c\u5e76\u63a2\u8ba8\u4e86\u53ef\u5b66\u4e60\u6fc0\u6d3b\u51fd\u6570\u53c2\u6570\u5316\u7684\u4f18\u52bf\u3002", "result": "\u7406\u8bba\u4e0a\u63d0\u4f9b\u4e86\u7ebf\u6027SDE\u548c\u975e\u7ebf\u6027SDE\u53c2\u6570\u6062\u590d\u7684\u754c\u9650\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5177\u6709\u53ef\u5b66\u4e60\u6fc0\u6d3b\u51fd\u6570\u7684\u53c2\u6570\u5316\u65b9\u5f0f\u53ef\u4ee5\u66f4\u597d\u5730\u6062\u590d\u771f\u5b9e\u53c2\u6570\u3002", "conclusion": "\u672c\u6587\u4e3aSDE\u6a21\u578b\u7684\u53c2\u6570\u8bc6\u522b\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u754c\u9650\uff0c\u5e76\u5c55\u793a\u4e86\u53ef\u5b66\u4e60\u6fc0\u6d3b\u51fd\u6570\u5728\u53c2\u6570\u5316\u4e2d\u7684\u4f18\u52bf\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2505.16082", "pdf": "https://arxiv.org/pdf/2505.16082", "abs": "https://arxiv.org/abs/2505.16082", "authors": ["Renato Berlinghieri", "Yunyi Shen", "Jialong Jiang", "Tamara Broderick"], "title": "Oh SnapMMD! Forecasting Stochastic Dynamics Beyond the Schr\u00f6dinger Bridge's End", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "43 pages, 26 figures, 21 tables", "summary": "Scientists often want to make predictions beyond the observed time horizon of\n\"snapshot\" data following latent stochastic dynamics. For example, in time\ncourse single-cell mRNA profiling, scientists have access to cellular\ntranscriptional state measurements (snapshots) from different biological\nreplicates at different time points, but they cannot access the trajectory of\nany one cell because measurement destroys the cell. Researchers want to\nforecast (e.g.) differentiation outcomes from early state measurements of stem\ncells. Recent Schr\\\"odinger-bridge (SB) methods are natural for interpolating\nbetween snapshots. But past SB papers have not addressed forecasting -- likely\nsince existing methods either (1) reduce to following pre-set reference\ndynamics (chosen before seeing data) or (2) require the user to choose a fixed,\nstate-independent volatility since they minimize a Kullback-Leibler divergence.\nEither case can lead to poor forecasting quality. In the present work, we\npropose a new framework, SnapMMD, that learns dynamics by directly fitting the\njoint distribution of both state measurements and observation time with a\nmaximum mean discrepancy (MMD) loss. Unlike past work, our method allows us to\ninfer unknown and state-dependent volatilities from the observed data. We show\nin a variety of real and synthetic experiments that our method delivers\naccurate forecasts. Moreover, our approach allows us to learn in the presence\nof incomplete state measurements and yields an $R^2$-style statistic that\ndiagnoses fit. We also find that our method's performance at interpolation (and\ngeneral velocity-field reconstruction) is at least as good as (and often better\nthan) state-of-the-art in almost all of our experiments.", "AI": {"tldr": "\u79d1\u5b66\u5bb6\u4eec\u5e38\u5e38\u5e0c\u671b\u57fa\u4e8e\u6f5c\u85cf\u968f\u673a\u52a8\u529b\u5b66\u7684'\u5feb\u7167'\u6570\u636e\u9884\u6d4b\u8d85\u51fa\u89c2\u5bdf\u65f6\u95f4\u8303\u56f4\u7684\u7ed3\u679c\u3002\u4f8b\u5982\uff0c\u5728\u5355\u7ec6\u80demRNA\u65f6\u7a0b\u5206\u6790\u4e2d\uff0c\u7531\u4e8e\u6d4b\u91cf\u4f1a\u7834\u574f\u7ec6\u80de\uff0c\u7814\u7a76\u4eba\u5458\u65e0\u6cd5\u83b7\u53d6\u4efb\u4f55\u5355\u4e00\u7ec6\u80de\u7684\u8f68\u8ff9\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6SnapMMD\uff0c\u901a\u8fc7\u76f4\u63a5\u62df\u5408\u72b6\u6001\u6d4b\u91cf\u548c\u89c2\u6d4b\u65f6\u95f4\u7684\u8054\u5408\u5206\u5e03\u6765\u5b66\u4e60\u52a8\u529b\u5b66\u3002\u8be5\u65b9\u6cd5\u53ef\u4ee5\u63a8\u65ad\u51fa\u672a\u77e5\u4e14\u4e0e\u72b6\u6001\u76f8\u5173\u7684\u6ce2\u52a8\u6027\uff0c\u5e76\u5728\u5404\u79cd\u771f\u5b9e\u548c\u5408\u6210\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u51c6\u786e\u7684\u9884\u6d4b\u80fd\u529b\u3002\u6b64\u5916\uff0c\u5b83\u5141\u8bb8\u5728\u4e0d\u5b8c\u6574\u72b6\u6001\u6d4b\u91cf\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u5b66\u4e60\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7c7b\u4f3c\u4e8e$R^2$\u7684\u8bca\u65ad\u7edf\u8ba1\u91cf\u3002", "motivation": "\u79d1\u5b66\u5bb6\u9700\u8981\u4ece\u65e9\u671f\u72b6\u6001\u6d4b\u91cf\uff08\u5982\u5e72\u7ec6\u80de\uff09\u9884\u6d4b\u5206\u5316\u7ed3\u679c\uff0c\u4f46\u73b0\u6709\u7684Schr\u00f6dinger-bridge (SB) \u65b9\u6cd5\u8981\u4e48\u7b80\u5316\u4e3a\u9075\u5faa\u9884\u8bbe\u53c2\u8003\u52a8\u529b\u5b66\uff0c\u8981\u4e48\u9700\u8981\u7528\u6237\u9009\u62e9\u56fa\u5b9a\u3001\u4e0e\u72b6\u6001\u65e0\u5173\u7684\u6ce2\u52a8\u6027\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u8f83\u5dee\u7684\u9884\u6d4b\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u6846\u67b6SnapMMD\uff0c\u901a\u8fc7\u6700\u5927\u5747\u503c\u5dee\u5f02\uff08MMD\uff09\u635f\u5931\u76f4\u63a5\u62df\u5408\u72b6\u6001\u6d4b\u91cf\u548c\u89c2\u6d4b\u65f6\u95f4\u7684\u8054\u5408\u5206\u5e03\u3002\u6b64\u65b9\u6cd5\u53ef\u4ee5\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u63a8\u65ad\u672a\u77e5\u4e14\u4e0e\u72b6\u6001\u76f8\u5173\u7684\u6ce2\u52a8\u6027\u3002", "result": "\u5728\u591a\u79cd\u771f\u5b9e\u548c\u5408\u6210\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u51c6\u786e\u7684\u9884\u6d4b\u3002\u6b64\u5916\uff0c\u5176\u63d2\u503c\u6027\u80fd\uff08\u4ee5\u53ca\u4e00\u822c\u7684\u901f\u5ea6\u573a\u91cd\u5efa\uff09\u5728\u51e0\u4e4e\u6240\u6709\u5b9e\u9a8c\u4e2d\u90fd\u81f3\u5c11\u4e0e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u4e00\u6837\u597d\uff0c\u751a\u81f3\u66f4\u597d\u3002", "conclusion": "SnapMMD\u6846\u67b6\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u5e76\u5904\u7406\u4e0d\u5b8c\u6574\u72b6\u6001\u6d4b\u91cf\uff0c\u540c\u65f6\u63d0\u4f9b\u4e00\u4e2a\u8bca\u65ad\u62df\u5408\u4f18\u5ea6\u7684\u7edf\u8ba1\u91cf\u3002"}}
{"id": "2505.15998", "pdf": "https://arxiv.org/pdf/2505.15998", "abs": "https://arxiv.org/abs/2505.15998", "authors": ["Thomas Michel", "Marko Cvjetko", "Gautier Hamon", "Pierre-Yves Oudeyer", "Cl\u00e9ment Moulin-Frier"], "title": "Exploring Flow-Lenia Universes with a Curiosity-driven AI Scientist: Discovering Diverse Ecosystem Dynamics", "categories": ["cs.AI"], "comment": "10 pages, 10 figures, submitted to ALIFE 2025 Conference", "summary": "We present a method for the automated discovery of system-level dynamics in\nFlow-Lenia$-$a continuous cellular automaton (CA) with mass conservation and\nparameter localization$-$using a curiosity-driven AI scientist. This method\naims to uncover processes leading to self-organization of evolutionary and\necosystemic dynamics in CAs. We build on previous work which uses diversity\nsearch algorithms in Lenia to find self-organized individual patterns, and\nextend it to large environments that support distinct interacting patterns. We\nadapt Intrinsically Motivated Goal Exploration Processes (IMGEPs) to drive\nexploration of diverse Flow-Lenia environments using simulation-wide metrics,\nsuch as evolutionary activity, compression-based complexity, and multi-scale\nentropy. We test our method in two experiments, showcasing its ability to\nilluminate significantly more diverse dynamics compared to random search. We\nshow qualitative results illustrating how ecosystemic simulations enable\nself-organization of complex collective behaviors not captured by previous\nindividual pattern search and analysis. We complement automated discovery with\nan interactive exploration tool, creating an effective human-AI collaborative\nworkflow for scientific investigation. Though demonstrated specifically with\nFlow-Lenia, this methodology provides a framework potentially applicable to\nother parameterizable complex systems where understanding emergent collective\nproperties is of interest.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u597d\u5947\u5fc3\u9a71\u52a8\u7684\u4eba\u5de5\u667a\u80fd\u79d1\u5b66\u5bb6\uff0c\u5728Flow-Lenia\uff08\u5177\u6709\u8d28\u91cf\u5b88\u6052\u548c\u53c2\u6570\u5c40\u90e8\u5316\u7684\u8fde\u7eed\u7ec6\u80de\u81ea\u52a8\u673a\uff09\u4e2d\u81ea\u52a8\u53d1\u73b0\u7cfb\u7edf\u7ea7\u52a8\u6001\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728\u5927\u578b\u73af\u5883\u4e2d\u63a2\u7d22\u4e0d\u540c\u7684\u76f8\u4e92\u4f5c\u7528\u6a21\u5f0f\uff0c\u63ed\u793a\u4e86\u7ec6\u80de\u81ea\u52a8\u673a\u4e2d\u5bfc\u81f4\u81ea\u6211\u7ec4\u7ec7\u7684\u8fdb\u5316\u548c\u751f\u6001\u7cfb\u7edf\u52a8\u6001\u7684\u8fc7\u7a0b\u3002\u76f8\u6bd4\u968f\u673a\u641c\u7d22\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u5c55\u73b0\u66f4\u591a\u6837\u5316\u7684\u52a8\u6001\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u751f\u6001\u7cfb\u7edf\u6a21\u62df\u5b9e\u73b0\u590d\u6742\u96c6\u4f53\u884c\u4e3a\u7684\u81ea\u6211\u7ec4\u7ec7\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u63a2\u7d22\u5de5\u5177\uff0c\u4ee5\u4fc3\u8fdb\u4eba\u7c7b\u4e0eAI\u534f\u4f5c\u8fdb\u884c\u79d1\u5b66\u7814\u7a76\u3002\u867d\u7136\u6b64\u65b9\u6cd5\u5728Flow-Lenia\u4e2d\u8fdb\u884c\u4e86\u6f14\u793a\uff0c\u4f46\u5b83\u4e3a\u7406\u89e3\u5176\u4ed6\u53ef\u53c2\u6570\u5316\u7684\u590d\u6742\u7cfb\u7edf\u7684\u6d8c\u73b0\u96c6\u4f53\u7279\u6027\u63d0\u4f9b\u4e86\u6f5c\u5728\u6846\u67b6\u3002", "motivation": "\u4e4b\u524d\u7684\u7814\u7a76\u5df2\u7ecf\u5728Lenia\u4e2d\u4f7f\u7528\u591a\u6837\u6027\u641c\u7d22\u7b97\u6cd5\u627e\u5230\u4e86\u81ea\u6211\u7ec4\u7ec7\u7684\u4e2a\u4f53\u6a21\u5f0f\uff0c\u4f46\u8fd9\u4e9b\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5c0f\u578b\u73af\u5883\u4e2d\u7684\u5355\u4e00\u6a21\u5f0f\u4e0a\u3002\u672c\u6587\u65e8\u5728\u6269\u5c55\u8fd9\u4e00\u7814\u7a76\uff0c\u63a2\u7d22\u652f\u6301\u4e0d\u540c\u76f8\u4e92\u4f5c\u7528\u6a21\u5f0f\u7684\u5927\u73af\u5883\uff0c\u5e76\u63ed\u793a\u7ec6\u80de\u81ea\u52a8\u673a\u4e2d\u66f4\u590d\u6742\u7684\u81ea\u7ec4\u7ec7\u8fc7\u7a0b\u3002", "method": "\u7814\u7a76\u8005\u91c7\u7528\u5185\u5728\u52a8\u673a\u76ee\u6807\u63a2\u7d22\u8fc7\u7a0b\uff08IMGEPs\uff09\uff0c\u7ed3\u5408\u5168\u4eff\u771f\u8303\u56f4\u7684\u5ea6\u91cf\u6807\u51c6\uff08\u5982\u8fdb\u5316\u6d3b\u52a8\u3001\u57fa\u4e8e\u538b\u7f29\u7684\u590d\u6742\u6027\u548c\u591a\u5c3a\u5ea6\u71b5\uff09\uff0c\u6765\u9a71\u52a8\u5bf9\u591a\u6837\u5316Flow-Lenia\u73af\u5883\u7684\u63a2\u7d22\u3002\u901a\u8fc7\u4e24\u4e2a\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u5176\u76f8\u8f83\u4e8e\u968f\u673a\u641c\u7d22\u80fd\u53d1\u73b0\u66f4\u591a\u7684\u52a8\u6001\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u5c55\u793a\u66f4\u591a\u6837\u5316\u7684\u52a8\u6001\u3002\u5b9a\u6027\u7ed3\u679c\u663e\u793a\uff0c\u751f\u6001\u7cfb\u7edf\u6a21\u62df\u80fd\u591f\u4f7f\u590d\u6742\u7684\u96c6\u4f53\u884c\u4e3a\u81ea\u6211\u7ec4\u7ec7\uff0c\u800c\u8fd9\u4e9b\u884c\u4e3a\u662f\u4ee5\u524d\u4e2a\u4f53\u6a21\u5f0f\u641c\u7d22\u548c\u5206\u6790\u6240\u65e0\u6cd5\u6355\u6349\u5230\u7684\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u6210\u529f\u5730\u5728Flow-Lenia\u4e2d\u63ed\u793a\u4e86\u590d\u6742\u96c6\u4f53\u884c\u4e3a\u7684\u81ea\u6211\u7ec4\u7ec7\u8fc7\u7a0b\uff0c\u5e76\u4e14\u901a\u8fc7\u4eba\u673a\u534f\u4f5c\u7684\u5de5\u4f5c\u6d41\u7a0b\u589e\u5f3a\u4e86\u79d1\u5b66\u63a2\u7d22\u7684\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u9002\u7528\u4e8eFlow-Lenia\uff0c\u8fd8\u53ef\u4ee5\u63a8\u5e7f\u5230\u5176\u4ed6\u9700\u8981\u7406\u89e3\u6d8c\u73b0\u96c6\u4f53\u7279\u6027\u7684\u590d\u6742\u7cfb\u7edf\u3002"}}
{"id": "2505.16004", "pdf": "https://arxiv.org/pdf/2505.16004", "abs": "https://arxiv.org/abs/2505.16004", "authors": ["Aaron J. Li", "Suraj Srinivas", "Usha Bhalla", "Himabindu Lakkaraju"], "title": "Interpretability Illusions with Sparse Autoencoders: Evaluating Robustness of Concept Representations", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Sparse autoencoders (SAEs) are commonly used to interpret the internal\nactivations of large language models (LLMs) by mapping them to\nhuman-interpretable concept representations. While existing evaluations of SAEs\nfocus on metrics such as the reconstruction-sparsity tradeoff, human\n(auto-)interpretability, and feature disentanglement, they overlook a critical\naspect: the robustness of concept representations to input perturbations. We\nargue that robustness must be a fundamental consideration for concept\nrepresentations, reflecting the fidelity of concept labeling. To this end, we\nformulate robustness quantification as input-space optimization problems and\ndevelop a comprehensive evaluation framework featuring realistic scenarios in\nwhich adversarial perturbations are crafted to manipulate SAE representations.\nEmpirically, we find that tiny adversarial input perturbations can effectively\nmanipulate concept-based interpretations in most scenarios without notably\naffecting the outputs of the base LLMs themselves. Overall, our results suggest\nthat SAE concept representations are fragile and may be ill-suited for\napplications in model monitoring and oversight.", "AI": {"tldr": "\u7a00\u758f\u81ea\u7f16\u7801\u5668(SAEs)\u5728\u89e3\u91ca\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7684\u5185\u90e8\u6fc0\u6d3b\u65b9\u9762\u88ab\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u6982\u5ff5\u8868\u793a\u5bf9\u8f93\u5165\u6270\u52a8\u7684\u9c81\u68d2\u6027\u4e00\u76f4\u88ab\u5ffd\u89c6\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5fae\u5c0f\u7684\u5bf9\u6297\u6027\u8f93\u5165\u6270\u52a8\u53ef\u4ee5\u5728\u4e0d\u5f71\u54cd\u57fa\u7840LLMs\u8f93\u51fa\u7684\u60c5\u51b5\u4e0b\u64cd\u7eb5\u57fa\u4e8e\u6982\u5ff5\u7684\u89e3\u91ca\uff0c\u8868\u660eSAE\u6982\u5ff5\u8868\u793a\u662f\u8106\u5f31\u7684\uff0c\u53ef\u80fd\u4e0d\u9002\u5408\u7528\u4e8e\u6a21\u578b\u76d1\u63a7\u548c\u76d1\u7763\u5e94\u7528\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u5bf9\u7a00\u758f\u81ea\u7f16\u7801\u5668(SAEs)\u7684\u8bc4\u4f30\u96c6\u4e2d\u5728\u91cd\u5efa-\u7a00\u758f\u6743\u8861\u3001\u4eba\u7c7b\u53ef\u89e3\u91ca\u6027\u548c\u7279\u5f81\u89e3\u8026\u7b49\u65b9\u9762\uff0c\u4f46\u5ffd\u89c6\u4e86\u6982\u5ff5\u8868\u793a\u5bf9\u8f93\u5165\u6270\u52a8\u7684\u9c81\u68d2\u6027\u8fd9\u4e00\u5173\u952e\u65b9\u9762\u3002", "method": "\u5c06\u9c81\u68d2\u6027\u91cf\u5316\u8868\u8ff0\u4e3a\u8f93\u5165\u7a7a\u95f4\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b\u73b0\u5b9e\u573a\u666f\u7684\u5168\u9762\u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u8fd9\u4e9b\u573a\u666f\u4e2d\uff0c\u5bf9\u6297\u6027\u6270\u52a8\u88ab\u8bbe\u8ba1\u7528\u6765\u64cd\u63a7SAE\u8868\u793a\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u5fae\u5c0f\u7684\u5bf9\u6297\u6027\u8f93\u5165\u6270\u52a8\u53ef\u4ee5\u5728\u4e0d\u5f71\u54cd\u57fa\u7840LLMs\u8f93\u51fa\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u64cd\u63a7\u57fa\u4e8e\u6982\u5ff5\u7684\u89e3\u91ca\u3002", "conclusion": "SAE\u6982\u5ff5\u8868\u793a\u662f\u8106\u5f31\u7684\uff0c\u53ef\u80fd\u4e0d\u9002\u7528\u4e8e\u6a21\u578b\u76d1\u63a7\u548c\u76d1\u7763\u5e94\u7528\u3002"}}
{"id": "2505.16098", "pdf": "https://arxiv.org/pdf/2505.16098", "abs": "https://arxiv.org/abs/2505.16098", "authors": ["Damien Ferbach", "Katie Everett", "Gauthier Gidel", "Elliot Paquette", "Courtney Paquette"], "title": "Dimension-adapted Momentum Outscales SGD", "categories": ["stat.ML", "cs.LG", "math.OC"], "comment": null, "summary": "We investigate scaling laws for stochastic momentum algorithms with small\nbatch on the power law random features model, parameterized by data complexity,\ntarget complexity, and model size. When trained with a stochastic momentum\nalgorithm, our analysis reveals four distinct loss curve shapes determined by\nvarying data-target complexities. While traditional stochastic gradient descent\nwith momentum (SGD-M) yields identical scaling law exponents to SGD,\ndimension-adapted Nesterov acceleration (DANA) improves these exponents by\nscaling momentum hyperparameters based on model size and data complexity. This\noutscaling phenomenon, which also improves compute-optimal scaling behavior, is\nachieved by DANA across a broad range of data and target complexities, while\ntraditional methods fall short. Extensive experiments on high-dimensional\nsynthetic quadratics validate our theoretical predictions and large-scale text\nexperiments with LSTMs show DANA's improved loss exponents over SGD hold in a\npractical setting.", "AI": {"tldr": "DANA\u901a\u8fc7\u6839\u636e\u6a21\u578b\u5927\u5c0f\u548c\u6570\u636e\u590d\u6742\u6027\u8c03\u6574\u52a8\u91cf\u8d85\u53c2\u6570\uff0c\u6539\u8fdb\u4e86\u4f20\u7edfSGD-M\u7684\u7f29\u653e\u5b9a\u5f8b\u6307\u6570\uff0c\u5e76\u5728\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u7814\u7a76\u968f\u673a\u52a8\u91cf\u7b97\u6cd5\u5728\u5c0f\u6279\u91cf\u8bad\u7ec3\u4e2d\u7684\u7f29\u653e\u89c4\u5f8b\uff0c\u7279\u522b\u662f\u5728\u7531\u6570\u636e\u590d\u6742\u6027\u3001\u76ee\u6807\u590d\u6742\u6027\u548c\u6a21\u578b\u5927\u5c0f\u53c2\u6570\u5316\u7684\u5e42\u5f8b\u968f\u673a\u7279\u5f81\u6a21\u578b\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u5206\u6790\u4f7f\u7528\u968f\u673a\u52a8\u91cf\u7b97\u6cd5\u8bad\u7ec3\u65f6\u7684\u4e0d\u540c\u635f\u5931\u66f2\u7ebf\u5f62\u72b6\uff0c\u5e76\u6bd4\u8f83\u4f20\u7edf\u7684SGD-M\u4e0e\u7ef4\u5ea6\u9002\u5e94\u7684Nesterov\u52a0\u901f\uff08DANA\uff09\u65b9\u6cd5\u5728\u4e0d\u540c\u6570\u636e-\u76ee\u6807\u590d\u6742\u6027\u4e0b\u7684\u8868\u73b0\u3002DANA\u901a\u8fc7\u57fa\u4e8e\u6a21\u578b\u5927\u5c0f\u548c\u6570\u636e\u590d\u6742\u6027\u8c03\u6574\u52a8\u91cf\u8d85\u53c2\u6570\u6765\u6539\u8fdb\u7f29\u653e\u6307\u6570\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u9ad8\u7ef4\u5408\u6210\u4e8c\u6b21\u5b9e\u9a8c\u8868\u660e\uff0cDANA\u5728\u5e7f\u6cdb\u7684\u6578\u64da\u548c\u76ee\u6807\u590d\u6742\u6027\u8303\u56f4\u5185\u8868\u73b0\u51fa\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u8ba1\u7b97\u6700\u4f18\u7f29\u653e\u884c\u4e3a\u3002\u6b64\u5916\uff0c\u5728\u5927\u89c4\u6a21LSTM\u6587\u672c\u5b9e\u9a8c\u4e2d\uff0cDANA\u4e5f\u663e\u793a\u51fa\u6539\u8fdb\u7684\u635f\u5931\u6307\u6570\u3002", "conclusion": "DANA\u80fd\u591f\u5728\u66f4\u5e7f\u6cdb\u7684\u6578\u64da\u548c\u76ee\u6807\u590d\u6742\u6027\u8303\u56f4\u5185\u5b9e\u73b0\u66f4\u597d\u7684\u7f29\u653e\u884c\u4e3a\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\u5219\u6709\u6240\u4e0d\u8db3\u3002"}}
{"id": "2505.16031", "pdf": "https://arxiv.org/pdf/2505.16031", "abs": "https://arxiv.org/abs/2505.16031", "authors": ["Aayushi Dangol", "Robert Wolfe", "Runhua Zhao", "JaeWon Kim", "Trushaa Ramanan", "Katie Davis", "Julie A. Kientz"], "title": "Children's Mental Models of AI Reasoning: Implications for AI Literacy Education", "categories": ["cs.AI", "cs.HC"], "comment": null, "summary": "As artificial intelligence (AI) advances in reasoning capabilities, most\nrecently with the emergence of Large Reasoning Models (LRMs), understanding how\nchildren conceptualize AI's reasoning processes becomes critical for fostering\nAI literacy. While one of the \"Five Big Ideas\" in AI education highlights\nreasoning algorithms as central to AI decision-making, less is known about\nchildren's mental models in this area. Through a two-phase approach, consisting\nof a co-design session with 8 children followed by a field study with 106\nchildren (grades 3-8), we identified three models of AI reasoning: Deductive,\nInductive, and Inherent. Our findings reveal that younger children (grades 3-5)\noften attribute AI's reasoning to inherent intelligence, while older children\n(grades 6-8) recognize AI as a pattern recognizer. We highlight three tensions\nthat surfaced in children's understanding of AI reasoning and conclude with\nimplications for scaffolding AI curricula and designing explainable AI tools.", "AI": {"tldr": "The paper explores how children conceptualize AI reasoning through a two-phase study, revealing three models of AI reasoning and differences in understanding between younger and older children.", "motivation": "To foster AI literacy among children by understanding their mental models of AI reasoning processes.", "method": "A two-phase approach involving a co-design session with 8 children followed by a field study with 106 children (grades 3-8).", "result": "Identified three models of AI reasoning: Deductive, Inductive, and Inherent. Younger children attribute AI's reasoning to inherent intelligence while older children recognize AI as a pattern recognizer.", "conclusion": "Highlights three tensions in children's understanding of AI reasoning and provides implications for designing AI curricula and explainable AI tools."}}
{"id": "2505.16017", "pdf": "https://arxiv.org/pdf/2505.16017", "abs": "https://arxiv.org/abs/2505.16017", "authors": ["Mariia Seleznova", "Hung-Hsu Chou", "Claudio Mayrink Verdun", "Gitta Kutyniok"], "title": "GradPCA: Leveraging NTK Alignment for Reliable Out-of-Distribution Detection", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We introduce GradPCA, an Out-of-Distribution (OOD) detection method that\nexploits the low-rank structure of neural network gradients induced by Neural\nTangent Kernel (NTK) alignment. GradPCA applies Principal Component Analysis\n(PCA) to gradient class-means, achieving more consistent performance than\nexisting methods across standard image classification benchmarks. We provide a\ntheoretical perspective on spectral OOD detection in neural networks to support\nGradPCA, highlighting feature-space properties that enable effective detection\nand naturally emerge from NTK alignment. Our analysis further reveals that\nfeature quality -- particularly the use of pretrained versus non-pretrained\nrepresentations -- plays a crucial role in determining which detectors will\nsucceed. Extensive experiments validate the strong performance of GradPCA, and\nour theoretical framework offers guidance for designing more principled\nspectral OOD detectors.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGradPCA\u7684\u65b0\u578bOOD\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u68af\u5ea6\u7684\u4f4e\u79e9\u7ed3\u6784\uff0c\u5e76\u901a\u8fc7PCA\u5e94\u7528\u4e8e\u68af\u5ea6\u7c7b\u5747\u503c\uff0c\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u5e76\u9a8c\u8bc1\u5176\u5728\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u4e0a\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684OOD\u68c0\u6d4b\u65b9\u6cd5\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4e0d\u4e00\u81f4\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5b9a\u548c\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "GradPCA\u65b9\u6cd5\u5229\u7528\u4e86\u7531\u795e\u7ecf\u5207\u7ebf\u6838(NTK)\u5bf9\u9f50\u5f15\u8d77\u7684\u795e\u7ecf\u7f51\u7edc\u68af\u5ea6\u7684\u4f4e\u79e9\u7ed3\u6784\uff0c\u5c06\u4e3b\u6210\u5206\u5206\u6790(PCA)\u5e94\u7528\u4e8e\u68af\u5ea6\u7c7b\u5747\u503c\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660eGradPCA\u5728\u6807\u51c6\u56fe\u50cf\u5206\u7c7b\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u4e00\u81f4\u6027\uff0c\u4e14\u7279\u5f81\u8d28\u91cf\uff08\u7279\u522b\u662f\u9884\u8bad\u7ec3\u4e0e\u975e\u9884\u8bad\u7ec3\u8868\u793a\u7684\u9009\u62e9\uff09\u5bf9\u68c0\u6d4b\u5668\u7684\u6210\u529f\u4e0e\u5426\u8d77\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "GradPCA\u4e3a\u8bbe\u8ba1\u66f4\u539f\u5219\u6027\u7684\u9891\u8c31OOD\u68c0\u6d4b\u5668\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u6307\u5bfc\u3002"}}
{"id": "2505.16145", "pdf": "https://arxiv.org/pdf/2505.16145", "abs": "https://arxiv.org/abs/2505.16145", "authors": ["Arghya Datta", "Philippe Gagnon", "Florian Maire"], "title": "Exponential Convergence of CAVI for Bayesian PCA", "categories": ["stat.ML", "cs.LG"], "comment": "28 pages, 3 figures", "summary": "Probabilistic principal component analysis (PCA) and its Bayesian variant\n(BPCA) are widely used for dimension reduction in machine learning and\nstatistics. The main advantage of probabilistic PCA over the traditional\nformulation is allowing uncertainty quantification. The parameters of BPCA are\ntypically learned using mean-field variational inference, and in particular,\nthe coordinate ascent variational inference (CAVI) algorithm. So far, the\nconvergence speed of CAVI for BPCA has not been characterized. In our paper, we\nfill this gap in the literature. Firstly, we prove a precise exponential\nconvergence result in the case where the model uses a single principal\ncomponent (PC). Interestingly, this result is established through a connection\nwith the classical $\\textit{power iteration algorithm}$ and it indicates that\ntraditional PCA is retrieved as points estimates of the BPCA parameters.\nSecondly, we leverage recent tools to prove exponential convergence of CAVI for\nthe model with any number of PCs, thus leading to a more general result, but\none that is of a slightly different flavor. To prove the latter result, we\nadditionally needed to introduce a novel lower bound for the symmetric\nKullback--Leibler divergence between two multivariate normal distributions,\nwhich, we believe, is of independent interest in information theory.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7528\u4e8e\u8d1d\u53f6\u65af\u6982\u7387\u4e3b\u6210\u5206\u5206\u6790\uff08BPCA\uff09\u7684\u5750\u6807\u4e0a\u5347\u53d8\u5206\u63a8\u7406\uff08CAVI\uff09\u7b97\u6cd5\u7684\u6536\u655b\u901f\u5ea6\uff0c\u8bc1\u660e\u4e86\u5355\u4e2a\u4e3b\u6210\u5206\u60c5\u51b5\u4e0b\u7684\u7cbe\u786e\u6307\u6570\u6536\u655b\u7ed3\u679c\uff0c\u5e76\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u5bf9\u79f0KL\u6563\u5ea6\u4e0b\u754c\uff0c\u8bc1\u660e\u4e86\u4efb\u610f\u6570\u91cf\u4e3b\u6210\u5206\u6a21\u578b\u7684\u6307\u6570\u6536\u655b\u6027\u3002", "motivation": "\u5c3d\u7ba1BPCA\u53c2\u6570\u901a\u5e38\u4f7f\u7528CAVI\u7b97\u6cd5\u5b66\u4e60\uff0c\u4f46\u5176\u6536\u655b\u901f\u5ea6\u5c1a\u672a\u88ab\u660e\u786e\u8868\u5f81\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7814\u7a76CAVI\u5728BPCA\u4e2d\u7684\u6536\u655b\u7279\u6027\u3002", "method": "1. \u8bc1\u660e\u4e86\u5f53\u6a21\u578b\u4f7f\u7528\u5355\u4e2a\u4e3b\u6210\u5206\u65f6\uff0cCAVI\u5177\u6709\u7cbe\u786e\u7684\u6307\u6570\u6536\u655b\u7ed3\u679c\uff0c\u901a\u8fc7\u4e0e\u7ecf\u5178\u7684\u5e42\u8fed\u4ee3\u7b97\u6cd5\u5efa\u7acb\u8054\u7cfb\u3002\n2. \u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u5bf9\u79f0Kullback-Leibler\u6563\u5ea6\u7684\u4e0b\u754c\uff0c\u4ee5\u8bc1\u660e\u4efb\u610f\u6570\u91cf\u4e3b\u6210\u5206\u6a21\u578b\u7684\u6307\u6570\u6536\u655b\u6027\u3002", "result": "1. \u5728\u5355\u4e2a\u4e3b\u6210\u5206\u60c5\u51b5\u4e0b\uff0c\u5f97\u5230\u4e86\u7cbe\u786e\u7684\u6307\u6570\u6536\u655b\u7ed3\u679c\uff0c\u5e76\u63ed\u793a\u4e86\u4f20\u7edfPCA\u662fBPCA\u53c2\u6570\u7684\u70b9\u4f30\u8ba1\u3002\n2. \u5bf9\u4e8e\u4efb\u610f\u6570\u91cf\u4e3b\u6210\u5206\u6a21\u578b\uff0c\u8bc1\u660e\u4e86CAVI\u7684\u6307\u6570\u6536\u655b\u6027\uff0c\u63d0\u4f9b\u4e86\u66f4\u901a\u7528\u7684\u7ed3\u679c\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u8868\u5f81\u4e86CAVI\u5728BPCA\u4e2d\u7684\u6536\u655b\u901f\u5ea6\uff0c\u4e0d\u4ec5\u4e3a\u5355\u4e2a\u4e3b\u6210\u5206\u60c5\u51b5\u63d0\u4f9b\u4e86\u7cbe\u786e\u7ed3\u679c\uff0c\u8fd8\u901a\u8fc7\u5f15\u5165\u65b0\u5de5\u5177\u6269\u5c55\u5230\u4e86\u4efb\u610f\u6570\u91cf\u4e3b\u6210\u5206\u6a21\u578b\uff0c\u540c\u65f6\u4e3a\u4fe1\u606f\u7406\u8bba\u9886\u57df\u8d21\u732e\u4e86\u4e00\u4e2a\u72ec\u7acb\u611f\u5174\u8da3\u7684\u5bf9\u79f0KL\u6563\u5ea6\u4e0b\u754c\u3002"}}
{"id": "2505.16037", "pdf": "https://arxiv.org/pdf/2505.16037", "abs": "https://arxiv.org/abs/2505.16037", "authors": ["Asterios Tsiourvas", "Wei Sun", "Georgia Perakis"], "title": "Causal LLM Routing: End-to-End Regret Minimization from Observational Data", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.ML"], "comment": null, "summary": "LLM routing aims to select the most appropriate model for each query,\nbalancing competing performance metrics such as accuracy and cost across a pool\nof language models. Prior approaches typically adopt a decoupled strategy,\nwhere the metrics are first predicted and the model is then selected based on\nthese estimates. This setup is prone to compounding errors and often relies on\nfull-feedback data, where each query is evaluated by all candidate models,\nwhich is costly to obtain and maintain in practice. In contrast, we learn from\nobservational data, which records only the outcome of the model actually\ndeployed. We propose a causal end-to-end framework that learns routing policies\nby minimizing decision-making regret from observational data. To enable\nefficient optimization, we introduce two theoretically grounded surrogate\nobjectives: a classification-based upper bound, and a softmax-weighted regret\napproximation shown to recover the optimal policy at convergence. We further\nextend our framework to handle heterogeneous cost preferences via an\ninterval-conditioned architecture. Experiments on public benchmarks show that\nour method outperforms existing baselines, achieving state-of-the-art\nperformance across different embedding models.", "AI": {"tldr": "LLM routing focuses on selecting the best model for each query by balancing accuracy and cost. Unlike previous methods that predict metrics first then select models, leading to potential compounding errors and reliance on costly full-feedback data, this paper proposes a causal end-to-end framework that learns from observational data by minimizing decision-making regret. The authors introduce two surrogate objectives for efficient optimization and extend their framework to handle varying cost preferences. Experiments show state-of-the-art performance.", "motivation": "Existing LLM routing methods use a decoupled strategy of predicting metrics before model selection, which is prone to compounding errors and depends on expensive full-feedback data. There is a need for a more effective and efficient method that can learn from observational data.", "method": "The paper proposes a causal end-to-end framework for learning routing policies by minimizing decision-making regret from observational data. Two theoretically grounded surrogate objectives are introduced for efficient optimization: a classification-based upper bound and a softmax-weighted regret approximation. Additionally, an interval-conditioned architecture is used to handle heterogeneous cost preferences.", "result": "Experiments conducted on public benchmarks demonstrate that the proposed method outperforms existing baselines, achieving state-of-the-art performance across different embedding models.", "conclusion": "The proposed causal end-to-end framework for LLM routing effectively learns from observational data, reducing decision-making regret and handling heterogeneous cost preferences. It achieves superior performance compared to existing methods."}}
{"id": "2505.16024", "pdf": "https://arxiv.org/pdf/2505.16024", "abs": "https://arxiv.org/abs/2505.16024", "authors": ["Weiguo Gao", "Ming Li"], "title": "Toward Theoretical Insights into Diffusion Trajectory Distillation via Operator Merging", "categories": ["cs.LG", "cs.AI"], "comment": "31 pages, 19 figures", "summary": "Diffusion trajectory distillation methods aim to accelerate sampling in\ndiffusion models, which produce high-quality outputs but suffer from slow\nsampling speeds. These methods train a student model to approximate the\nmulti-step denoising process of a pretrained teacher model in a single step,\nenabling one-shot generation. However, theoretical insights into the trade-off\nbetween different distillation strategies and generative quality remain\nlimited, complicating their optimization and selection. In this work, we take a\nfirst step toward addressing this gap. Specifically, we reinterpret trajectory\ndistillation as an operator merging problem in the linear regime, where each\nstep of the teacher model is represented as a linear operator acting on noisy\ndata. These operators admit a clear geometric interpretation as projections and\nrescalings corresponding to the noise schedule. During merging, signal\nshrinkage occurs as a convex combination of operators, arising from both\ndiscretization and limited optimization time of the student model. We propose a\ndynamic programming algorithm to compute the optimal merging strategy that\nmaximally preserves signal fidelity. Additionally, we demonstrate the existence\nof a sharp phase transition in the optimal strategy, governed by data\ncovariance structures. Our findings enhance the theoretical understanding of\ndiffusion trajectory distillation and offer practical insights for improving\ndistillation strategies.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u5c06\u6269\u6563\u8f68\u8ff9\u84b8\u998f\u91cd\u65b0\u89e3\u91ca\u4e3a\u7ebf\u6027\u7b97\u5b50\u5408\u5e76\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u6765\u8ba1\u7b97\u6700\u4f18\u5408\u5e76\u7b56\u7565\uff0c\u5e76\u53d1\u73b0\u4e86\u8be5\u7b56\u7565\u4e2d\u7684\u76f8\u53d8\u73b0\u8c61\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u5bf9\u6269\u6563\u8f68\u8ff9\u84b8\u998f\u7684\u7406\u8bba\u7406\u89e3\u3002", "motivation": "\u73b0\u6709\u7684\u6269\u6563\u8f68\u8ff9\u84b8\u998f\u65b9\u6cd5\u867d\u7136\u53ef\u4ee5\u52a0\u901f\u91c7\u6837\u8fc7\u7a0b\uff0c\u4f46\u5bf9\u5176\u4e0d\u540c\u7b56\u7565\u4e0e\u751f\u6210\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u7f3a\u4e4f\u7406\u8bba\u6d1e\u5bdf\uff0c\u8fd9\u4f7f\u5f97\u4f18\u5316\u548c\u9009\u62e9\u5408\u9002\u7684\u84b8\u998f\u7b56\u7565\u53d8\u5f97\u590d\u6742\u3002", "method": "\u4f5c\u8005\u5c06\u6269\u6563\u8f68\u8ff9\u84b8\u998f\u91cd\u65b0\u89e3\u91ca\u4e3a\u7ebf\u6027\u7b97\u5b50\u5408\u5e76\u95ee\u9898\uff0c\u5176\u4e2d\u6559\u5e08\u6a21\u578b\u7684\u6bcf\u4e00\u6b65\u90fd\u88ab\u8868\u793a\u4e3a\u4f5c\u7528\u4e8e\u566a\u58f0\u6570\u636e\u7684\u7ebf\u6027\u7b97\u5b50\u3002\u901a\u8fc7\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u8ba1\u7b97\u51fa\u6700\u4f18\u7684\u5408\u5e76\u7b56\u7565\uff0c\u4ee5\u6700\u5927\u7a0b\u5ea6\u5730\u4fdd\u7559\u4fe1\u53f7\u4fdd\u771f\u5ea6\u3002\u540c\u65f6\u7814\u7a76\u4e86\u6570\u636e\u534f\u65b9\u5dee\u7ed3\u6784\u5bf9\u6700\u4f18\u7b56\u7565\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u6700\u4f18\u7b56\u7565\u4e2d\u5b58\u5728\u7531\u6570\u636e\u534f\u65b9\u5dee\u7ed3\u6784\u63a7\u5236\u7684\u660e\u663e\u76f8\u53d8\u73b0\u8c61\u3002\u8fd9\u4e00\u53d1\u73b0\u52a0\u6df1\u4e86\u5bf9\u6269\u6563\u8f68\u8ff9\u84b8\u998f\u7684\u7406\u8bba\u7406\u89e3\uff0c\u5e76\u4e3a\u6539\u8fdb\u84b8\u998f\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u9645\u6307\u5bfc\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6269\u6563\u8f68\u8ff9\u84b8\u998f\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c6\u89d2\uff0c\u5e76\u901a\u8fc7\u52a8\u6001\u89c4\u5212\u7b97\u6cd5\u548c\u76f8\u53d8\u73b0\u8c61\u7684\u7814\u7a76\uff0c\u4e3a\u63d0\u9ad8\u84b8\u998f\u7b56\u7565\u7684\u6709\u6548\u6027\u548c\u751f\u6210\u8d28\u91cf\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2505.16156", "pdf": "https://arxiv.org/pdf/2505.16156", "abs": "https://arxiv.org/abs/2505.16156", "authors": ["Siu Lun Chau", "Michele Caprio", "Krikamol Muandet"], "title": "Integral Imprecise Probability Metrics", "categories": ["stat.ML", "cs.LG"], "comment": "50 pages, 2 figures", "summary": "Quantifying differences between probability distributions is fundamental to\nstatistics and machine learning, primarily for comparing statistical\nuncertainty. In contrast, epistemic uncertainty (EU) -- due to incomplete\nknowledge -- requires richer representations than those offered by classical\nprobability. Imprecise probability (IP) theory offers such models, capturing\nambiguity and partial belief. This has driven growing interest in imprecise\nprobabilistic machine learning (IPML), where inference and decision-making rely\non broader uncertainty models -- highlighting the need for metrics beyond\nclassical probability. This work introduces the Integral Imprecise Probability\nMetric (IIPM) framework, a Choquet integral-based generalisation of classical\nIntegral Probability Metric (IPM) to the setting of capacities -- a broad class\nof IP models encompassing many existing ones, including lower probabilities,\nprobability intervals, belief functions, and more. Theoretically, we establish\nconditions under which IIPM serves as a valid metric and metrises a form of\nweak convergence of capacities. Practically, IIPM not only enables comparison\nacross different IP models but also supports the quantification of epistemic\nuncertainty within a single IP model. In particular, by comparing an IP model\nwith its conjugate, IIPM gives rise to a new class of EU measures -- Maximum\nMean Imprecision -- which satisfy key axiomatic properties proposed in the\nUncertainty Quantification literature. We validate MMI through selective\nclassification experiments, demonstrating strong empirical performance against\nestablished EU measures, and outperforming them when classical methods struggle\nto scale to a large number of classes. Our work advances both theory and\npractice in IPML, offering a principled framework for comparing and quantifying\nepistemic uncertainty under imprecision.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4e86Integral Imprecise Probability Metric (IIPM)\u6846\u67b6\uff0c\u5c06\u7ecf\u5178\u7684Integral Probability Metric\u63a8\u5e7f\u5230\u5bb9\u91cf\u8bbe\u7f6e\u4e0b\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u4e0d\u7cbe\u786e\u6982\u7387\u6a21\u578b\u3002\u7406\u8bba\u65b9\u9762\uff0c\u786e\u5b9a\u4e86IIPM\u4f5c\u4e3a\u6709\u6548\u5ea6\u91cf\u7684\u6761\u4ef6\uff0c\u5e76\u8bc1\u660e\u5176\u53ef\u4ee5\u5ea6\u91cf\u5bb9\u91cf\u7684\u5f31\u6536\u655b\u5f62\u5f0f\u3002\u5b9e\u8df5\u4e0a\uff0cIIPM\u4e0d\u4ec5\u80fd\u591f\u6bd4\u8f83\u4e0d\u540c\u4e0d\u7cbe\u786e\u6982\u7387\u6a21\u578b\uff0c\u8fd8\u80fd\u91cf\u5316\u5355\u4e00\u6a21\u578b\u4e2d\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u7c7b\u65b0\u7684EU\u5ea6\u91cf\u2014\u2014Maximum Mean Imprecision (MMI)\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u7edf\u8ba1\u548c\u673a\u5668\u5b66\u4e60\u4e2d\uff0c\u8861\u91cf\u6982\u7387\u5206\u5e03\u5dee\u5f02\u662f\u57fa\u7840\u4efb\u52a1\uff0c\u4e3b\u8981\u7528\u4e8e\u6bd4\u8f83\u7edf\u8ba1\u4e0d\u786e\u5b9a\u6027\u3002\u7136\u800c\uff0c\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff08Epistemic Uncertainty, EU\uff09\u7531\u4e8e\u77e5\u8bc6\u4e0d\u5b8c\u5168\uff0c\u9700\u8981\u6bd4\u7ecf\u5178\u6982\u7387\u66f4\u4e30\u5bcc\u7684\u8868\u793a\u65b9\u6cd5\u3002\u4e0d\u7cbe\u786e\u6982\u7387\uff08Imprecise Probability, IP\uff09\u7406\u8bba\u63d0\u4f9b\u4e86\u8fd9\u6837\u7684\u6a21\u578b\uff0c\u56e0\u6b64\u5728\u4e0d\u7cbe\u786e\u6982\u7387\u673a\u5668\u5b66\u4e60\uff08IPML\uff09\u9886\u57df\uff0c\u9700\u8981\u8d85\u8d8a\u7ecf\u5178\u6982\u7387\u7684\u5ea6\u91cf\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8eChoquet\u79ef\u5206\u7684IIPM\u6846\u67b6\uff0c\u5c06\u7ecf\u5178IPM\u63a8\u5e7f\u5230\u5bb9\u91cf\uff08Capacities\uff09\u8fd9\u4e00\u5e7f\u6cdb\u5305\u542b\u73b0\u6709IP\u6a21\u578b\u7684\u7c7b\u522b\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u660e\u786e\u4e86IIPM\u4f5c\u4e3a\u5408\u6cd5\u5ea6\u91cf\u7684\u6761\u4ef6\u53ca\u5176\u5bf9\u5f31\u6536\u655b\u5f62\u5f0f\u7684\u5ea6\u91cf\u80fd\u529b\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u6bd4\u8f83IP\u6a21\u578b\u4e0e\u5176\u5171\u8f6d\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u65b0\u7684EU\u5ea6\u91cf\u2014\u2014Maximum Mean Imprecision (MMI)\u3002", "result": "\u7406\u8bba\u4e0a\uff0c\u9a8c\u8bc1\u4e86IIPM\u5728\u9002\u5f53\u6761\u4ef6\u4e0b\u53ef\u4f5c\u4e3a\u5408\u6cd5\u5ea6\u91cf\uff0c\u5e76\u80fd\u5ea6\u91cf\u5f31\u6536\u655b\u5f62\u5f0f\uff1b\u5b9e\u8df5\u4e2d\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u5206\u7c7b\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86MMI\u76f8\u8f83\u4e8e\u73b0\u6709EU\u5ea6\u91cf\u7684\u5f3a\u7ecf\u9a8c\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u7ecf\u5178\u65b9\u6cd5\u96be\u4ee5\u6269\u5c55\u5230\u591a\u7c7b\u522b\u60c5\u51b5\u65f6\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u672c\u6587\u4e3aIPML\u9886\u57df\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e0a\u7684\u8fdb\u6b65\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u6846\u67b6\u6765\u6bd4\u8f83\u548c\u91cf\u5316\u4e0d\u7cbe\u786e\u6982\u7387\u4e0b\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2505.16048", "pdf": "https://arxiv.org/pdf/2505.16048", "abs": "https://arxiv.org/abs/2505.16048", "authors": ["Philipp D. Siedler"], "title": "SPhyR: Spatial-Physical Reasoning Benchmark on Material Distribution", "categories": ["cs.AI"], "comment": null, "summary": "We introduce a novel dataset designed to benchmark the physical and spatial\nreasoning capabilities of Large Language Models (LLM) based on topology\noptimization, a method for computing optimal material distributions within a\ndesign space under prescribed loads and supports. In this dataset, LLMs are\nprovided with conditions such as 2D boundary, applied forces and supports, and\nmust reason about the resulting optimal material distribution. The dataset\nincludes a variety of tasks, ranging from filling in masked regions within\npartial structures to predicting complete material distributions. Solving these\ntasks requires understanding the flow of forces and the required material\ndistribution under given constraints, without access to simulation tools or\nexplicit physical models, challenging models to reason about structural\nstability and spatial organization. Our dataset targets the evaluation of\nspatial and physical reasoning abilities in 2D settings, offering a\ncomplementary perspective to traditional language and logic benchmarks.", "AI": {"tldr": "\u751f\u6210\u4e00\u4e2a\u8fc7\u957f\uff1b\u6ca1\u6709\u9605\u8bfb\u7684\u603b\u7ed3", "motivation": "\u63cf\u8ff0\u672c\u6587\u4e2d\u7684\u52a8\u673a", "method": "\u672c\u6587\u7684\u65b9\u6cd5", "result": "\u672c\u6587\u7684\u7ed3\u679c", "conclusion": "\u672c\u6587\u7684\u7ed3\u8bba"}}
{"id": "2505.16035", "pdf": "https://arxiv.org/pdf/2505.16035", "abs": "https://arxiv.org/abs/2505.16035", "authors": ["Alejandro Garc\u00eda-Castellanos", "David R. Wessels", "Nicky J. van den Berg", "Remco Duits", "Dani\u00ebl M. Pelt", "Erik J. Bekkers"], "title": "Equivariant Eikonal Neural Networks: Grid-Free, Scalable Travel-Time Prediction on Homogeneous Spaces", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce Equivariant Neural Eikonal Solvers, a novel framework that\nintegrates Equivariant Neural Fields (ENFs) with Neural Eikonal Solvers. Our\napproach employs a single neural field where a unified shared backbone is\nconditioned on signal-specific latent variables - represented as point clouds\nin a Lie group - to model diverse Eikonal solutions. The ENF integration\nensures equivariant mapping from these latent representations to the solution\nfield, delivering three key benefits: enhanced representation efficiency\nthrough weight-sharing, robust geometric grounding, and solution steerability.\nThis steerability allows transformations applied to the latent point cloud to\ninduce predictable, geometrically meaningful modifications in the resulting\nEikonal solution. By coupling these steerable representations with\nPhysics-Informed Neural Networks (PINNs), our framework accurately models\nEikonal travel-time solutions while generalizing to arbitrary Riemannian\nmanifolds with regular group actions. This includes homogeneous spaces such as\nEuclidean, position-orientation, spherical, and hyperbolic manifolds. We\nvalidate our approach through applications in seismic travel-time modeling of\n2D and 3D benchmark datasets. Experimental results demonstrate superior\nperformance, scalability, adaptability, and user controllability compared to\nexisting Neural Operator-based Eikonal solver methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u2014\u2014Equivariant Neural Eikonal Solvers\uff0c\u5b83\u5c06Equivariant Neural Fields\u4e0eNeural Eikonal Solvers\u76f8\u7ed3\u5408\u3002\u901a\u8fc7\u5355\u4e00\u795e\u7ecf\u573a\u548c\u5171\u4eab\u4e3b\u5e72\u7f51\u7edc\uff0c\u7ed3\u5408Physics-Informed Neural Networks (PINNs)\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u51c6\u786e\u5730\u5bf9\u4e0d\u540cRiemannian\u6d41\u5f62\u4e0a\u7684Eikonal\u65c5\u884c\u65f6\u95f4\u89e3\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u5728\u5730\u9707\u65c5\u884c\u65f6\u95f4\u5efa\u6a21\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u3001\u9002\u5e94\u6027\u548c\u7528\u6237\u53ef\u63a7\u6027\u3002", "motivation": "\u73b0\u6709\u7684Neural Operator-based Eikonal\u6c42\u89e3\u5668\u65b9\u6cd5\u5728\u5904\u7406\u4efb\u610fRiemannian\u6d41\u5f62\u4e0a\u7684\u95ee\u9898\u65f6\u5b58\u5728\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u53ca\u7528\u6237\u63a7\u5236\u80fd\u529b\u7684\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u65b9\u6cd5\u6765\u89e3\u51b3Eikonal\u65b9\u7a0b\u3002", "method": "\u8be5\u65b9\u6cd5\u4f7f\u7528\u5355\u4e00\u795e\u7ecf\u573a\uff0c\u5176\u4e2d\u7edf\u4e00\u7684\u5171\u4eab\u4e3b\u5e72\u7f51\u7edc\u57fa\u4e8eLie\u7fa4\u4e2d\u7684\u70b9\u4e91\u8868\u793a\u7684\u4fe1\u53f7\u7279\u5b9a\u6f5c\u5728\u53d8\u91cf\u8fdb\u884c\u6761\u4ef6\u5316\uff0c\u4ee5\u5efa\u6a21\u591a\u6837\u5316\u7684Eikonal\u89e3\u3002\u901a\u8fc7\u6574\u5408\u7b49\u53d8\u795e\u7ecf\u573a\uff08ENF\uff09\uff0c\u786e\u4fdd\u4ece\u6f5c\u5728\u8868\u793a\u5230\u89e3\u573a\u7684\u7b49\u53d8\u6620\u5c04\uff0c\u63d0\u4f9b\u6743\u91cd\u5171\u4eab\u5e26\u6765\u7684\u8868\u793a\u6548\u7387\u63d0\u5347\u3001\u7a33\u5065\u7684\u51e0\u4f55\u57fa\u7840\u4ee5\u53ca\u89e3\u7684\u53ef\u64cd\u63a7\u6027\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5c06\u8fd9\u4e9b\u53ef\u64cd\u63a7\u7684\u8868\u793a\u4e0e\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINNs\uff09\u7ed3\u5408\uff0c\u6846\u67b6\u53ef\u4ee5\u51c6\u786e\u5730\u5bf9Eikonal\u65c5\u884c\u65f6\u95f4\u89e3\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u63a8\u5e7f\u5230\u5177\u6709\u6b63\u5219\u7fa4\u4f5c\u7528\u7684\u4efb\u610fRiemannian\u6d41\u5f62\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u57282D\u548c3D\u57fa\u51c6\u6570\u636e\u96c6\u7684\u5730\u9707\u65c5\u884c\u65f6\u95f4\u5efa\u6a21\u5e94\u7528\u4e2d\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u7684Neural Operator-based Eikonal\u6c42\u89e3\u5668\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u3001\u9002\u5e94\u6027\u548c\u7528\u6237\u53ef\u63a7\u6027\u3002", "conclusion": "Equivariant Neural Eikonal Solvers\u6846\u67b6\u901a\u8fc7\u7ed3\u5408ENFs\u548cPINNs\uff0c\u80fd\u591f\u5728\u591a\u79cdRiemannian\u6d41\u5f62\u4e0a\u6709\u6548\u5730\u89e3\u51b3Eikonal\u65b9\u7a0b\uff0c\u5e76\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u7075\u6d3b\u6027\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.16244", "pdf": "https://arxiv.org/pdf/2505.16244", "abs": "https://arxiv.org/abs/2505.16244", "authors": ["Masanari Kimura", "Howard Bondell"], "title": "Generalized Power Priors for Improved Bayesian Inference with Historical Data", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "The power prior is a class of informative priors designed to incorporate\nhistorical data alongside current data in a Bayesian framework. It includes a\npower parameter that controls the influence of historical data, providing\nflexibility and adaptability. A key property of the power prior is that the\nresulting posterior minimizes a linear combination of KL divergences between\ntwo pseudo-posterior distributions: one ignoring historical data and the other\nfully incorporating it. We extend this framework by identifying the posterior\ndistribution as the minimizer of a linear combination of Amari's\n$\\alpha$-divergence, a generalization of KL divergence. We show that this\ngeneralization can lead to improved performance by allowing for the data to\nadapt to appropriate choices of the $\\alpha$ parameter. Theoretical properties\nof this generalized power posterior are established, including behavior as a\ngeneralized geodesic on the Riemannian manifold of probability distributions,\noffering novel insights into its geometric interpretation.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u6269\u5c55\u4e86\u529f\u7387\u5148\u9a8c\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u540e\u9a8c\u5206\u5e03\u89c6\u4e3a\u963f\u9a6c\u91cc\u03b1-\u6563\u5ea6\u7ebf\u6027\u7ec4\u5408\u7684\u6700\u5c0f\u5316\u7ed3\u679c\uff0c\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u5386\u53f2\u6570\u636e\u6574\u5408\u65b9\u5f0f\uff0c\u5e76\u63ed\u793a\u4e86\u51e0\u4f55\u89e3\u91ca\u3002", "motivation": "\u5728\u8d1d\u53f6\u65af\u6846\u67b6\u4e0b\uff0c\u529f\u7387\u5148\u9a8c\u63d0\u4f9b\u4e86\u4e00\u79cd\u7ed3\u5408\u5386\u53f2\u6570\u636e\u548c\u5f53\u524d\u6570\u636e\u7684\u65b9\u6cd5\u3002\u4f46\u4e3a\u4e86\u63d0\u9ad8\u7075\u6d3b\u6027\u548c\u9002\u5e94\u6027\uff0c\u9700\u8981\u5bf9\u73b0\u6709\u6846\u67b6\u8fdb\u884c\u6269\u5c55\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5f15\u5165\u963f\u9a6c\u91cc\u03b1-\u6563\u5ea6\u7684\u4e00\u822c\u5316\u5f62\u5f0f\u6765\u91cd\u65b0\u5b9a\u4e49\u540e\u9a8c\u5206\u5e03\uff0c\u5e76\u7814\u7a76\u4e86\u8fd9\u79cd\u4e00\u822c\u5316\u7684\u529f\u7387\u540e\u9a8c\u7684\u7406\u8bba\u6027\u8d28\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7\u9009\u62e9\u5408\u9002\u7684\u03b1\u53c2\u6570\u4f7f\u6570\u636e\u66f4\u597d\u5730\u9002\u5e94\u6a21\u578b\uff0c\u4ece\u800c\u63d0\u9ad8\u6027\u80fd\u3002\u6b64\u5916\uff0c\u8fd8\u53d1\u73b0\u8be5\u65b9\u6cd5\u5728\u6982\u7387\u5206\u5e03\u7684\u9ece\u66fc\u6d41\u5f62\u4e0a\u8868\u73b0\u4e3a\u5e7f\u4e49\u6d4b\u5730\u7ebf\u3002", "conclusion": "\u8fd9\u79cd\u6269\u5c55\u7684\u529f\u7387\u540e\u9a8c\u4e0d\u4ec5\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u7075\u6d3b\u6027\uff0c\u8fd8\u4e3a\u529f\u7387\u540e\u9a8c\u63d0\u4f9b\u4e86\u65b0\u7684\u51e0\u4f55\u89e3\u91ca\u3002"}}
{"id": "2505.16067", "pdf": "https://arxiv.org/pdf/2505.16067", "abs": "https://arxiv.org/abs/2505.16067", "authors": ["Zidi Xiong", "Yuping Lin", "Wenya Xie", "Pengfei He", "Jiliang Tang", "Himabindu Lakkaraju", "Zhen Xiang"], "title": "How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior", "categories": ["cs.AI"], "comment": null, "summary": "Memory is a critical component in large language model (LLM)-based agents,\nenabling them to store and retrieve past executions to improve task performance\nover time. In this paper, we conduct an empirical study on how memory\nmanagement choices impact the LLM agents' behavior, especially their long-term\nperformance. Specifically, we focus on two fundamental memory operations that\nare widely used by many agent frameworks-addition, which incorporates new\nexperiences into the memory base, and deletion, which selectively removes past\nexperiences-to systematically study their impact on the agent behavior. Through\nour quantitative analysis, we find that LLM agents display an\nexperience-following property: high similarity between a task input and the\ninput in a retrieved memory record often results in highly similar agent\noutputs. Our analysis further reveals two significant challenges associated\nwith this property: error propagation, where inaccuracies in past experiences\ncompound and degrade future performance, and misaligned experience replay,\nwhere outdated or irrelevant experiences negatively influence current tasks.\nThrough controlled experiments, we show that combining selective addition and\ndeletion strategies can help mitigate these negative effects, yielding an\naverage absolute performance gain of 10% compared to naive memory growth.\nFurthermore, we highlight how memory management choices affect agents' behavior\nunder challenging conditions such as task distribution shifts and constrained\nmemory resources. Our findings offer insights into the behavioral dynamics of\nLLM agent memory systems and provide practical guidance for designing memory\ncomponents that support robust, long-term agent performance. We also release\nour code to facilitate further study.", "AI": {"tldr": "\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u4e2d\uff0c\u8bb0\u5fc6\u7ba1\u7406\u5bf9\u5176\u957f\u671f\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u901a\u8fc7\u7ecf\u9a8c\u7814\u7a76\u53d1\u73b0\uff0c\u6dfb\u52a0\u548c\u5220\u9664\u8bb0\u5fc6\u64cd\u4f5c\u5bf9\u4ee3\u7406\u884c\u4e3a\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5e76\u63ed\u793a\u4e86\u7ecf\u9a8c\u8ddf\u968f\u5c5e\u6027\u5e26\u6765\u7684\u9519\u8bef\u4f20\u64ad\u548c\u7ecf\u9a8c\u56de\u653e\u9519\u4f4d\u4e24\u5927\u6311\u6218\u3002\u901a\u8fc7\u7ed3\u5408\u9009\u62e9\u6027\u6dfb\u52a0\u548c\u5220\u9664\u7b56\u7565\uff0c\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u534710%\u7684\u7edd\u5bf9\u6027\u80fd\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u4efb\u52a1\u5206\u5e03\u53d8\u5316\u548c\u53d7\u9650\u5185\u5b58\u6761\u4ef6\u4e0b\u7684\u8bb0\u5fc6\u7ba1\u7406\u5f71\u54cd\uff0c\u4e3a\u8bbe\u8ba1\u7a33\u5065\u7684\u957f\u671f\u4ee3\u7406\u6027\u80fd\u652f\u6301\u7684\u8bb0\u5fc6\u7ec4\u4ef6\u63d0\u4f9b\u4e86\u5b9e\u9645\u6307\u5bfc\u3002", "motivation": "\u7814\u7a76\u8bb0\u5fc6\u7ba1\u7406\u51b3\u7b56\u5bf9LLM\u4ee3\u7406\u884c\u4e3a\uff0c\u7279\u522b\u662f\u957f\u671f\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u4ee5\u6539\u8fdb\u4ee3\u7406\u7684\u4efb\u52a1\u8868\u73b0\u3002", "method": "\u805a\u7126\u4e8e\u4e24\u79cd\u57fa\u672c\u8bb0\u5fc6\u64cd\u4f5c\u2014\u2014\u6dfb\u52a0\uff08\u5c06\u65b0\u4f53\u9a8c\u7eb3\u5165\u8bb0\u5fc6\u5e93\uff09\u548c\u5220\u9664\uff08\u9009\u62e9\u6027\u79fb\u9664\u8fc7\u5f80\u4f53\u9a8c\uff09\uff0c\u5e76\u901a\u8fc7\u5b9a\u91cf\u5206\u6790\u7814\u7a76\u5176\u5bf9\u4ee3\u7406\u884c\u4e3a\u7684\u5f71\u54cd\u3002\u8bc6\u522b\u51fa\u7ecf\u9a8c\u8ddf\u968f\u5c5e\u6027\u53ca\u5176\u5f15\u53d1\u7684\u9519\u8bef\u4f20\u64ad\u548c\u7ecf\u9a8c\u56de\u653e\u9519\u4f4d\u95ee\u9898\uff0c\u518d\u901a\u8fc7\u53d7\u63a7\u5b9e\u9a8c\u9a8c\u8bc1\u9009\u62e9\u6027\u6dfb\u52a0\u548c\u5220\u9664\u7b56\u7565\u7684\u6548\u679c\u3002", "result": "\u53d1\u73b0\u4ee3\u7406\u8868\u73b0\u51fa\u7ecf\u9a8c\u8ddf\u968f\u5c5e\u6027\uff0c\u63ed\u793a\u4e86\u9519\u8bef\u4f20\u64ad\u548c\u7ecf\u9a8c\u56de\u653e\u9519\u4f4d\u4e24\u5927\u6311\u6218\u3002\u9009\u62e9\u6027\u6dfb\u52a0\u548c\u5220\u9664\u7b56\u7565\u53ef\u4f7f\u6027\u80fd\u5e73\u5747\u7edd\u5bf9\u63d0\u534710%\uff0c\u5e76\u5728\u4efb\u52a1\u5206\u5e03\u53d8\u5316\u548c\u53d7\u9650\u5185\u5b58\u6761\u4ef6\u4e0b\u63d0\u4f9b\u8fdb\u4e00\u6b65\u89c1\u89e3\u3002", "conclusion": "\u8bb0\u5fc6\u7ba1\u7406\u51b3\u7b56\u663e\u8457\u5f71\u54cdLLM\u4ee3\u7406\u7684\u884c\u4e3a\u52a8\u6001\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u8bbe\u8ba1\u652f\u6301\u7a33\u5065\u957f\u671f\u6027\u80fd\u7684\u8bb0\u5fc6\u7ec4\u4ef6\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2505.16053", "pdf": "https://arxiv.org/pdf/2505.16053", "abs": "https://arxiv.org/abs/2505.16053", "authors": ["Jan T\u00f6nshoff", "Martin Grohe"], "title": "Learning from Algorithm Feedback: One-Shot SAT Solver Guidance with GNNs", "categories": ["cs.LG"], "comment": null, "summary": "Boolean Satisfiability (SAT) solvers are foundational to computer science,\nyet their performance typically hinges on hand-crafted heuristics. This work\nintroduces Reinforcement Learning from Algorithm Feedback (RLAF) as a paradigm\nfor learning to guide SAT solver branching heuristics with Graph Neural\nNetworks (GNNs). Central to our approach is a novel and generic mechanism for\ninjecting inferred variable weights and polarities into the branching\nheuristics of existing SAT solvers. In a single forward pass, a GNN assigns\nthese parameters to all variables. Casting this one-shot guidance as a\nreinforcement learning problem lets us train the GNN with off-the-shelf\npolicy-gradient methods, such as GRPO, directly using the solver's\ncomputational cost as the sole reward signal. Extensive evaluations demonstrate\nthat RLAF-trained policies significantly reduce the mean solve times of\ndifferent base solvers across diverse SAT problem distributions, achieving more\nthan a 2x speedup in some cases, while generalizing effectively to larger and\nharder problems after training. Notably, these policies consistently outperform\nexpert-supervised approaches based on learning handcrafted weighting\nheuristics, offering a promising path towards data-driven heuristic design in\ncombinatorial optimization.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRLAF\uff08Reinforcement Learning from Algorithm Feedback\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u5b66\u4e60\u6307\u5bfcSAT\u6c42\u89e3\u5668\u7684\u5206\u652f\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002\u901a\u8fc7\u5c06\u63a8\u65ad\u51fa\u7684\u53d8\u91cf\u6743\u91cd\u548c\u6781\u6027\u6ce8\u5165\u73b0\u6709\u7684SAT\u6c42\u89e3\u5668\u5206\u652f\u542f\u53d1\u5f0f\u7b97\u6cd5\u4e2d\uff0cRLAF\u663e\u8457\u51cf\u5c11\u4e86\u4e0d\u540c\u57fa\u7840\u6c42\u89e3\u5668\u5728\u5404\u79cdSAT\u95ee\u9898\u5206\u5e03\u4e0a\u7684\u5e73\u5747\u6c42\u89e3\u65f6\u95f4\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u8d85\u8fc7\u4e24\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u5e76\u4e14\u80fd\u591f\u6709\u6548\u63a8\u5e7f\u5230\u66f4\u5927\u3001\u66f4\u96be\u7684\u95ee\u9898\u3002\u76f8\u6bd4\u57fa\u4e8e\u624b\u5de5\u8bbe\u8ba1\u6743\u91cd\u542f\u53d1\u5f0f\u7684\u4e13\u5bb6\u76d1\u7763\u65b9\u6cd5\uff0cRLAF\u8bad\u7ec3\u7684\u7b56\u7565\u8868\u73b0\u66f4\u4e3a\u51fa\u8272\uff0c\u4e3a\u7ec4\u5408\u4f18\u5316\u4e2d\u7684\u6570\u636e\u9a71\u52a8\u542f\u53d1\u5f0f\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002", "motivation": "SAT\u6c42\u89e3\u5668\u662f\u8ba1\u7b97\u673a\u79d1\u5b66\u7684\u57fa\u7840\u5de5\u5177\uff0c\u4f46\u5176\u6027\u80fd\u901a\u5e38\u4f9d\u8d56\u4e8e\u4eba\u5de5\u8bbe\u8ba1\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002\u4e3a\u4e86\u6539\u8fdb\u8fd9\u4e00\u72b6\u51b5\uff0c\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\u6765\u5b66\u4e60\u5e76\u6307\u5bfcSAT\u6c42\u89e3\u5668\u7684\u5206\u652f\u9009\u62e9\u8fc7\u7a0b\uff0c\u4ee5\u63d0\u9ad8\u5176\u6548\u7387\u548c\u9002\u7528\u6027\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86RLAF\u6846\u67b6\uff0c\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u4e3aSAT\u6c42\u89e3\u5668\u7684\u5206\u652f\u542f\u53d1\u5f0f\u7b97\u6cd5\u63d0\u4f9b\u5355\u6b21\u6307\u5bfc\u3002GNN\u901a\u8fc7\u4e00\u6b21\u524d\u5411\u4f20\u64ad\u4e3a\u6240\u6709\u53d8\u91cf\u5206\u914d\u6743\u91cd\u548c\u6781\u6027\u53c2\u6570\u3002\u8be5\u95ee\u9898\u88ab\u5efa\u6a21\u4e3a\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\uff0c\u4f7f\u7528\u73b0\u6210\u7684\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\uff08\u5982GRPO\uff09\u8fdb\u884c\u8bad\u7ec3\uff0c\u5176\u4e2d\u6c42\u89e3\u5668\u7684\u8ba1\u7b97\u6210\u672c\u4f5c\u4e3a\u552f\u4e00\u7684\u5956\u52b1\u4fe1\u53f7\u3002", "result": "RLAF\u8bad\u7ec3\u7684\u7b56\u7565\u663e\u8457\u964d\u4f4e\u4e86\u4e0d\u540c\u57fa\u7840\u6c42\u89e3\u5668\u5728\u5404\u79cdSAT\u95ee\u9898\u5206\u5e03\u4e0a\u7684\u5e73\u5747\u6c42\u89e3\u65f6\u95f4\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u8d85\u8fc7\u4e24\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u7b56\u7565\u5728\u8bad\u7ec3\u540e\u80fd\u591f\u6709\u6548\u63a8\u5e7f\u5230\u66f4\u5927\u3001\u66f4\u96be\u7684\u95ee\u9898\uff0c\u5e76\u4e14\u4e00\u81f4\u4f18\u4e8e\u57fa\u4e8e\u624b\u5de5\u8bbe\u8ba1\u6743\u91cd\u542f\u53d1\u5f0f\u7684\u4e13\u5bb6\u76d1\u7763\u65b9\u6cd5\u3002", "conclusion": "RLAF\u5c55\u793a\u4e86\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u65b9\u5f0f\u8bbe\u8ba1\u7ec4\u5408\u4f18\u5316\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002\u901a\u8fc7\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8SAT\u6c42\u89e3\u5668\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2505.16251", "pdf": "https://arxiv.org/pdf/2505.16251", "abs": "https://arxiv.org/abs/2505.16251", "authors": ["Masanari Kimura"], "title": "Graph-Smoothed Bayesian Black-Box Shift Estimator and Its Information Geometry", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Label shift adaptation aims to recover target class priors when the labelled\nsource distribution $P$ and the unlabelled target distribution $Q$ share $P(X\n\\mid Y) = Q(X \\mid Y)$ but $P(Y) \\neq Q(Y)$. Classical black-box shift\nestimators invert an empirical confusion matrix of a frozen classifier,\nproducing a brittle point estimate that ignores sampling noise and similarity\namong classes. We present Graph-Smoothed Bayesian BBSE (GS-B$^3$SE), a fully\nprobabilistic alternative that places Laplacian-Gaussian priors on both target\nlog-priors and confusion-matrix columns, tying them together on a\nlabel-similarity graph. The resulting posterior is tractable with HMC or a fast\nblock Newton-CG scheme. We prove identifiability, $N^{-1/2}$ contraction,\nvariance bounds that shrink with the graph's algebraic connectivity, and\nrobustness to Laplacian misspecification. We also reinterpret GS-B$^3$SE\nthrough information geometry, showing that it generalizes existing shift\nestimators.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5Graph-Smoothed Bayesian BBSE (GS-B$^3$SE)\uff0c\u7528\u4e8e\u89e3\u51b3\u6807\u7b7e\u5206\u5e03\u504f\u79fb\u95ee\u9898\uff0c\u5177\u6709\u53ef\u8bc1\u660e\u7684\u7406\u8bba\u6027\u8d28\u548c\u5bf9\u7c7b\u522b\u76f8\u4f3c\u6027\u7684\u5efa\u6a21\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u9ed1\u76d2\u504f\u79fb\u4f30\u8ba1\u65b9\u6cd5\u5728\u5904\u7406\u6807\u7b7e\u5206\u5e03\u504f\u79fb\u65f6\uff0c\u5bb9\u6613\u53d7\u5230\u91c7\u6837\u566a\u58f0\u548c\u7c7b\u522b\u76f8\u4f3c\u6027\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u7a33\u5b9a\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5065\u7684\u65b9\u6cd5\u6765\u4f30\u8ba1\u76ee\u6807\u7c7b\u522b\u7684\u5148\u9a8c\u6982\u7387\u3002", "method": "GS-B$^3$SE\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165Laplacian-Gaussian\u5148\u9a8c\uff0c\u5c06\u76ee\u6807log-priors\u548c\u6df7\u6dc6\u77e9\u9635\u5217\u7ed1\u5b9a\u5728\u4e00\u4e2a\u6807\u7b7e\u76f8\u4f3c\u6027\u56fe\u4e0a\u3002\u4f7f\u7528HMC\u6216\u5feb\u901f\u5757Newton-CG\u65b9\u6848\u8fdb\u884c\u540e\u9a8c\u63a8\u65ad\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u8bc6\u522b\u6027\u3001\u6536\u7f29\u7387\u3001\u65b9\u5dee\u754c\u9650\u4ee5\u53ca\u5bf9Laplacian\u9519\u914d\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGS-B$^3$SE\u80fd\u591f\u6709\u6548\u4f30\u8ba1\u76ee\u6807\u7c7b\u522b\u7684\u5148\u9a8c\u6982\u7387\uff0c\u540c\u65f6\u5bf9\u91c7\u6837\u566a\u58f0\u548c\u7c7b\u522b\u76f8\u4f3c\u6027\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002\u6b64\u5916\uff0c\u4ece\u4fe1\u606f\u51e0\u4f55\u7684\u89d2\u5ea6\u91cd\u65b0\u89e3\u91ca\u4e86\u8be5\u65b9\u6cd5\uff0c\u8868\u660e\u5176\u53ef\u4ee5\u63a8\u5e7f\u73b0\u6709\u7684\u504f\u79fb\u4f30\u8ba1\u65b9\u6cd5\u3002", "conclusion": "Graph-Smoothed Bayesian BBSE (GS-B$^3$SE)\u662f\u4e00\u79cd\u5b8c\u5168\u6982\u7387\u5316\u7684\u6807\u7b7e\u5206\u5e03\u504f\u79fb\u9002\u5e94\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u52a0\u7a33\u5065\u4e14\u80fd\u5145\u5206\u5229\u7528\u7c7b\u522b\u95f4\u7684\u76f8\u4f3c\u6027\u4fe1\u606f\u3002"}}
{"id": "2505.16080", "pdf": "https://arxiv.org/pdf/2505.16080", "abs": "https://arxiv.org/abs/2505.16080", "authors": ["Jiayue Liu", "Zhongchao Yi", "Zhengyang Zhou", "Qihe Huang", "Kuo Yang", "Xu Wang", "Yang Wang"], "title": "SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation", "categories": ["cs.AI"], "comment": "16 pages, 7 figures", "summary": "Discovering regularities from spatiotemporal systems can benefit various\nscientific and social planning. Current spatiotemporal learners usually train\nan independent model from a specific source data that leads to limited\ntransferability among sources, where even correlated tasks requires new design\nand training. The key towards increasing cross-domain knowledge is to enable\ncollective intelligence and model evolution. In this paper, inspired by\nneuroscience theories, we theoretically derive the increased information\nboundary via learning cross-domain collective intelligence and propose a\nSynaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the\nmodel independence and enables cross-domain knowledge to be shared and\naggregated. Specifically, we first re-order the sample groups to imitate the\nhuman curriculum learning, and devise two complementary learners, elastic\ncommon container and task-independent extractor to allow model growth and\ntask-wise commonality and personality disentanglement. Then an adaptive dynamic\ncoupler with a new difference metric determines whether the new sample group\nshould be incorporated into common container to achieve model evolution under\nvarious domains. Experiments show that SynEVO improves the generalization\ncapacity by at most 42% under cross-domain scenarios and SynEVO provides a\nparadigm of NeuroAI for knowledge transfer and adaptation.", "AI": {"tldr": "SynEVO\u662f\u4e00\u79cd\u53d7\u795e\u7ecf\u79d1\u5b66\u542f\u53d1\u7684\u65f6\u7a7a\u7f51\u7edc\uff0c\u901a\u8fc7\u8de8\u57df\u96c6\u4f53\u667a\u80fd\u5b66\u4e60\u63d0\u5347\u6cdb\u5316\u80fd\u529b\uff0c\u6700\u9ad8\u53ef\u63d0\u9ad842%\u3002", "motivation": "\u5f53\u524d\u65f6\u7a7a\u5b66\u4e60\u6a21\u578b\u901a\u5e38\u4ece\u7279\u5b9a\u6e90\u6570\u636e\u4e2d\u8bad\u7ec3\u72ec\u7acb\u6a21\u578b\uff0c\u5bfc\u81f4\u5728\u6e90\u4e4b\u95f4\u7684\u53ef\u8fc1\u79fb\u6027\u6709\u9650\uff0c\u5373\u4f7f\u76f8\u5173\u4efb\u52a1\u4e5f\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1\u548c\u8bad\u7ec3\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5b9e\u73b0\u96c6\u4f53\u667a\u80fd\u548c\u6a21\u578b\u6f14\u5316\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSynEVO\u7684\u7a81\u89e6\u8fdb\u5316\u65f6\u7a7a\u7f51\u7edc\u3002\u8be5\u65b9\u6cd5\u9996\u5148\u5bf9\u6837\u672c\u7ec4\u8fdb\u884c\u91cd\u65b0\u6392\u5e8f\u4ee5\u6a21\u4eff\u4eba\u7c7b\u8bfe\u7a0b\u5b66\u4e60\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e24\u79cd\u4e92\u8865\u7684\u5b66\u4e60\u5668\uff1a\u5f39\u6027\u516c\u5171\u5bb9\u5668\u548c\u4efb\u52a1\u65e0\u5173\u63d0\u53d6\u5668\uff0c\u5141\u8bb8\u6a21\u578b\u589e\u957f\u53ca\u5171\u6027\u548c\u4e2a\u6027\u7684\u89e3\u7f20\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u5e26\u6709\u65b0\u5dee\u5f02\u5ea6\u91cf\u7684\u81ea\u9002\u5e94\u52a8\u6001\u8026\u5408\u5668\uff0c\u7528\u4e8e\u786e\u5b9a\u65b0\u6837\u672c\u7ec4\u662f\u5426\u5e94\u7eb3\u5165\u516c\u5171\u5bb9\u5668\u4ee5\u5b9e\u73b0\u8de8\u57df\u6a21\u578b\u6f14\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSynEVO\u5728\u8de8\u57df\u573a\u666f\u4e0b\u6700\u591a\u53ef\u4ee5\u5c06\u6cdb\u5316\u80fd\u529b\u63d0\u9ad842%\uff0c\u5e76\u4e3a\u77e5\u8bc6\u8f6c\u79fb\u548c\u9002\u5e94\u63d0\u4f9b\u4e86\u4e00\u79cdNeuroAI\u8303\u5f0f\u3002", "conclusion": "SynEVO\u901a\u8fc7\u8de8\u57df\u96c6\u4f53\u667a\u80fd\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u77e5\u8bc6\u8f6c\u79fb\u548c\u9002\u5e94\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2505.16056", "pdf": "https://arxiv.org/pdf/2505.16056", "abs": "https://arxiv.org/abs/2505.16056", "authors": ["Jingcong Liang", "Siyuan Wang", "Miren Tian", "Yitong Li", "Duyu Tang", "Zhongyu Wei"], "title": "Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Mixture-of-Experts (MoE) enables efficient scaling of large language models\n(LLMs) with sparsely activated experts during inference. To effectively deploy\nlarge MoE models on memory-constrained devices, many systems introduce *expert\noffloading* that caches a subset of experts in fast memory, leaving others on\nslow memory to run on CPU or load on demand. While some research has exploited\nthe locality of expert activations, where consecutive tokens activate similar\nexperts, the degree of this **local routing consistency** varies across models\nand remains understudied. In this paper, we propose two metrics to measure\nlocal routing consistency of MoE models: (1) **Segment Routing Best Performance\n(SRP)**, which evaluates how well a fixed group of experts can cover the needs\nof a segment of tokens, and (2) **Segment Cache Best Hit Rate (SCH)**, which\nmeasures the optimal segment-level cache hit rate under a given cache size\nlimit. We analyzed 20 MoE LLMs with diverse sizes and architectures and found\nthat models that apply MoE on every layer and do not use shared experts exhibit\nthe highest local routing consistency. We further showed that\ndomain-specialized experts contribute more to routing consistency than\nvocabulary-specialized ones, and that most models can balance between cache\neffectiveness and efficiency with cache sizes approximately 2x the active\nexperts. These findings pave the way for memory-efficient MoE design and\ndeployment without compromising inference speed. We publish the code for\nreplicating experiments at https://github.com/ljcleo/moe-lrc .", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u7528\u4e8e\u8861\u91cfMoE\u6a21\u578b\u5c40\u90e8\u8def\u7531\u4e00\u81f4\u6027\u7684\u4e24\u79cd\u65b0\u6307\u6807\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u63ed\u793a\u4e86\u5f71\u54cd\u8def\u7531\u4e00\u81f4\u6027\u7684\u5173\u952e\u56e0\u7d20\u53ca\u7f13\u5b58\u4f18\u5316\u7b56\u7565\u3002", "motivation": "\u5c3d\u7ba1\u4e00\u4e9b\u7814\u7a76\u5229\u7528\u4e86\u4e13\u5bb6\u6fc0\u6d3b\u7684\u5c40\u90e8\u6027\uff0c\u4f46\u8fd9\u79cd**\u5c40\u90e8\u8def\u7531\u4e00\u81f4\u6027**\u5728\u4e0d\u540c\u6a21\u578b\u4e2d\u7684\u7a0b\u5ea6\u53d8\u5316\u8f83\u5927\uff0c\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u56e0\u6b64\u9700\u8981\u66f4\u597d\u7684\u91cf\u5316\u65b9\u6cd5\u548c\u7406\u89e3\uff0c\u4ee5\u4f18\u5316MoE\u6a21\u578b\u5728\u5185\u5b58\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u4e2a\u6307\u6807\uff1a(1) Segment Routing Best Performance (SRP)\uff0c\u8bc4\u4f30\u56fa\u5b9a\u4e13\u5bb6\u7ec4\u5bf9\u4e00\u6bb5\u4ee4\u724c\u9700\u6c42\u7684\u8986\u76d6\u7387\uff1b(2) Segment Cache Best Hit Rate (SCH)\uff0c\u6d4b\u91cf\u7279\u5b9a\u7f13\u5b58\u5927\u5c0f\u9650\u5236\u4e0b\u7684\u6700\u4f73\u6bb5\u7ea7\u7f13\u5b58\u547d\u4e2d\u7387\u3002\u901a\u8fc7\u8fd9\u4e9b\u6307\u6807\u5206\u6790\u4e8620\u4e2a\u4e0d\u540c\u89c4\u6a21\u548c\u67b6\u6784\u7684MoE\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u53d1\u73b0\u6bcf\u5c42\u5e94\u7528MoE\u4e14\u4e0d\u4f7f\u7528\u5171\u4eab\u4e13\u5bb6\u7684\u6a21\u578b\u8868\u73b0\u51fa\u6700\u9ad8\u7684\u5c40\u90e8\u8def\u7531\u4e00\u81f4\u6027\u3002\u9886\u57df\u4e13\u4e1a\u5316\u7684\u4e13\u5bb6\u6bd4\u8bcd\u6c47\u4e13\u4e1a\u5316\u7684\u4e13\u5bb6\u5bf9\u8def\u7531\u4e00\u81f4\u6027\u8d21\u732e\u66f4\u5927\u3002\u5927\u591a\u6570\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u5927\u7ea62\u500d\u6d3b\u8dc3\u4e13\u5bb6\u6570\u91cf\u7684\u7f13\u5b58\u5927\u5c0f\uff0c\u5728\u7f13\u5b58\u6548\u679c\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\u3002", "conclusion": "Mixture-of-Experts (MoE)\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u63d0\u9ad8\u5c40\u90e8\u8def\u7531\u4e00\u81f4\u6027\u6765\u5b9e\u73b0\u5185\u5b58\u9ad8\u6548\u7684\u90e8\u7f72\uff0c\u5e76\u4e14\u5728\u4e0d\u5f71\u54cd\u63a8\u7406\u901f\u5ea6\u7684\u60c5\u51b5\u4e0b\u5e73\u8861\u7f13\u5b58\u6548\u679c\u548c\u6548\u7387\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u548c\u53d1\u73b0\u4e3a\u672a\u6765\u5185\u5b58\u4f18\u5316\u7684MoE\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2505.16257", "pdf": "https://arxiv.org/pdf/2505.16257", "abs": "https://arxiv.org/abs/2505.16257", "authors": ["Masanari Kimura"], "title": "Higher-Order Asymptotics of Test-Time Adaptation for Batch Normalization Statistics", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This study develops a higher-order asymptotic framework for test-time\nadaptation (TTA) of Batch Normalization (BN) statistics under distribution\nshift by integrating classical Edgeworth expansion and saddlepoint\napproximation techniques with a novel one-step M-estimation perspective. By\nanalyzing the statistical discrepancy between training and test distributions,\nwe derive an Edgeworth expansion for the normalized difference in BN means and\nobtain an optimal weighting parameter that minimizes the mean-squared error of\nthe adapted statistic. Reinterpreting BN TTA as a one-step M-estimator allows\nus to derive higher-order local asymptotic normality results, which incorporate\nskewness and other higher moments into the estimator's behavior. Moreover, we\nquantify the trade-offs among bias, variance, and skewness in the adaptation\nprocess and establish a corresponding generalization bound on the model risk.\nThe refined saddlepoint approximations further deliver uniformly accurate\ndensity and tail probability estimates for the BN TTA statistic. These\ntheoretical insights provide a comprehensive understanding of how higher-order\ncorrections and robust one-step updating can enhance the reliability and\nperformance of BN layers in adapting to changing data distributions.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u9ad8\u9636\u6e10\u8fd1\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u901a\u8fc7\u6574\u5408\u7ecf\u5178Edgeworth\u5c55\u5f00\u548c\u978d\u70b9\u903c\u8fd1\u6280\u672f\u4ee5\u53ca\u65b0\u9896\u7684\u4e00\u6b65M\u4f30\u8ba1\u89c6\u89d2\u6765\u9002\u5e94Batch Normalization (BN)\u7edf\u8ba1\u7684\u6d4b\u8bd5\u65f6\u95f4\u9002\u5e94\uff08TTA\uff09\u3002\u901a\u8fc7\u5206\u6790\u8bad\u7ec3\u548c\u6d4b\u8bd5\u5206\u5e03\u4e4b\u95f4\u7684\u7edf\u8ba1\u5dee\u5f02\uff0c\u63a8\u5bfc\u51faBN\u5747\u503c\u5f52\u4e00\u5316\u5dee\u5f02\u7684Edgeworth\u5c55\u5f00\uff0c\u5e76\u83b7\u5f97\u6700\u5c0f\u5316\u9002\u5e94\u7edf\u8ba1\u91cf\u5747\u65b9\u8bef\u5dee\u7684\u6700\u4f73\u52a0\u6743\u53c2\u6570\u3002\u5c06BN TTA\u91cd\u65b0\u89e3\u91ca\u4e3a\u4e00\u6b65M\u4f30\u8ba1\u5668\u4f7f\u6211\u4eec\u80fd\u591f\u63a8\u5bfc\u51fa\u66f4\u9ad8\u9636\u7684\u5c40\u90e8\u6e10\u8fd1\u6b63\u6001\u6027\u7ed3\u679c\uff0c\u5c06\u504f\u5ea6\u548c\u5176\u4ed6\u66f4\u9ad8\u9636\u77e9\u7eb3\u5165\u4f30\u8ba1\u5668\u7684\u884c\u4e3a\u4e2d\u3002\u6b64\u5916\uff0c\u6211\u4eec\u91cf\u5316\u4e86\u9002\u5e94\u8fc7\u7a0b\u4e2d\u7684\u504f\u5dee\u3001\u65b9\u5dee\u548c\u504f\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5e76\u5efa\u7acb\u4e86\u76f8\u5e94\u7684\u6a21\u578b\u98ce\u9669\u6cdb\u5316\u754c\u3002\u6539\u8fdb\u7684\u978d\u70b9\u903c\u8fd1\u8fdb\u4e00\u6b65\u63d0\u4f9b\u4e86BN TTA\u7edf\u8ba1\u91cf\u7684\u5747\u5300\u51c6\u786e\u5bc6\u5ea6\u548c\u5c3e\u6982\u7387\u4f30\u8ba1\u3002\u8fd9\u4e9b\u7406\u8bba\u89c1\u89e3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u7406\u89e3\uff0c\u5373\u5982\u4f55\u901a\u8fc7\u9ad8\u9636\u6821\u6b63\u548c\u7a33\u5065\u7684\u4e00\u6b65\u66f4\u65b0\u6765\u63d0\u9ad8BN\u5c42\u9002\u5e94\u53d8\u5316\u6570\u636e\u5206\u5e03\u7684\u53ef\u9760\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u5728\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\uff0cBatch Normalization (BN)\u7edf\u8ba1\u91cf\u5728\u8bad\u7ec3\u548c\u6d4b\u8bd5\u9636\u6bb5\u7684\u6570\u636e\u5206\u5e03\u53ef\u80fd\u4f1a\u53d1\u751f\u504f\u79fb\u3002\u4e3a\u4e86\u63d0\u9ad8\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u5206\u5e03\u4e0b\u7684\u9002\u5e94\u80fd\u529b\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u6d4b\u8bd5\u65f6\u95f4\u9002\u5e94\uff08TTA\uff09\u65b9\u6cd5\uff0c\u4ee5\u51cf\u5c11\u7531\u4e8e\u5206\u5e03\u504f\u79fb\u5e26\u6765\u7684\u8d1f\u9762\u5f71\u54cd\u3002\u8fd9\u4fc3\u4f7f\u4e86\u5bf9\u9ad8\u9636\u6e10\u8fd1\u6846\u67b6\u7684\u7814\u7a76\uff0c\u8be5\u6846\u67b6\u53ef\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u548c\u4f18\u5316BN\u7edf\u8ba1\u91cf\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u884c\u4e3a\u3002", "method": "\u7814\u7a76\u7ed3\u5408\u4e86\u7ecf\u5178Edgeworth\u5c55\u5f00\u548c\u978d\u70b9\u903c\u8fd1\u6280\u672f\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u4e00\u6b65M-\u4f30\u8ba1\u89c6\u89d2\u3002\u901a\u8fc7\u5bf9\u8bad\u7ec3\u548c\u6d4b\u8bd5\u5206\u5e03\u4e4b\u95f4\u7edf\u8ba1\u5dee\u5f02\u7684\u5206\u6790\uff0c\u63a8\u5bfc\u51faBN\u5747\u503c\u5f52\u4e00\u5316\u5dee\u5f02\u7684Edgeworth\u5c55\u5f00\u5f0f\uff0c\u5e76\u786e\u5b9a\u4e00\u4e2a\u6700\u4f18\u7684\u52a0\u6743\u53c2\u6570\u4ee5\u6700\u5c0f\u5316\u9002\u5e94\u7edf\u8ba1\u91cf\u7684\u5747\u65b9\u8bef\u5dee\u3002\u6b64\u5916\uff0c\u5c06BN TTA\u89c6\u4e3a\u4e00\u6b65M-\u4f30\u8ba1\u5668\uff0c\u4ece\u800c\u63a8\u5bfc\u51fa\u66f4\u9ad8\u9636\u7684\u5c40\u90e8\u6e10\u8fd1\u6b63\u6001\u6027\u7ed3\u679c\uff0c\u8fd9\u4e9b\u7ed3\u679c\u8003\u8651\u4e86\u504f\u5ea6\u53ca\u5176\u4ed6\u66f4\u9ad8\u9636\u77e9\u7684\u5f71\u54cd\u3002\u6700\u540e\uff0c\u4f7f\u7528\u6539\u8fdb\u7684\u978d\u70b9\u903c\u8fd1\u6280\u672f\uff0c\u83b7\u5f97\u4e86BN TTA\u7edf\u8ba1\u91cf\u7684\u5747\u5300\u51c6\u786e\u5bc6\u5ea6\u548c\u5c3e\u6982\u7387\u4f30\u8ba1\u3002", "result": "\u8be5\u7814\u7a76\u6210\u529f\u5730\u63a8\u5bfc\u51fa\u4e86\u4e00\u4e2a\u6700\u4f73\u52a0\u6743\u53c2\u6570\uff0c\u5b83\u80fd\u591f\u6700\u5c0f\u5316\u9002\u5e94\u7edf\u8ba1\u91cf\u7684\u5747\u65b9\u8bef\u5dee\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u91cd\u65b0\u8be0\u91caBN TTA\u4e3a\u4e00\u6b65M-\u4f30\u8ba1\u5668\uff0c\u5f97\u51fa\u4e86\u66f4\u9ad8\u9636\u7684\u5c40\u90e8\u6e10\u8fd1\u6b63\u6001\u6027\u7ed3\u679c\uff0c\u8fd9\u4e9b\u7ed3\u679c\u63ed\u793a\u4e86\u504f\u5ea6\u548c\u5176\u4ed6\u66f4\u9ad8\u9636\u77e9\u5728\u4f30\u8ba1\u5668\u884c\u4e3a\u4e2d\u7684\u4f5c\u7528\u3002\u6b64\u5916\uff0c\u91cf\u5316\u4e86\u9002\u5e94\u8fc7\u7a0b\u4e2d\u504f\u5dee\u3001\u65b9\u5dee\u548c\u504f\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5e76\u5efa\u7acb\u4e86\u76f8\u5e94\u7684\u6a21\u578b\u98ce\u9669\u6cdb\u5316\u754c\u3002\u6700\u7ec8\uff0c\u6539\u8fdb\u7684\u978d\u70b9\u903c\u8fd1\u6280\u672f\u63d0\u4f9b\u4e86\u5747\u5300\u51c6\u786e\u7684\u5bc6\u5ea6\u548c\u5c3e\u6982\u7387\u4f30\u8ba1\uff0c\u589e\u5f3a\u4e86BN\u5c42\u9002\u5e94\u53d8\u5316\u6570\u636e\u5206\u5e03\u7684\u53ef\u9760\u6027\u548c\u6027\u80fd\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u9ad8\u9636\u6e10\u8fd1\u6846\u67b6\u4e3a\u7406\u89e3Batch Normalization\u7edf\u8ba1\u91cf\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u7684\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002\u901a\u8fc7\u6574\u5408Edgeworth\u5c55\u5f00\u3001\u978d\u70b9\u903c\u8fd1\u548c\u4e00\u6b65M-\u4f30\u8ba1\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86BN\u5c42\u9002\u5e94\u53d8\u5316\u6570\u636e\u5206\u5e03\u7684\u80fd\u529b\uff0c\u8fd8\u63ed\u793a\u4e86\u66f4\u9ad8\u9636\u7edf\u8ba1\u91cf\u5728\u6a21\u578b\u6027\u80fd\u4e2d\u7684\u91cd\u8981\u4f5c\u7528\u3002\u8fd9\u4e9b\u7406\u8bba\u6210\u679c\u4e3a\u8fdb\u4e00\u6b65\u4f18\u5316BN\u7edf\u8ba1\u91cf\u7684\u9002\u5e94\u7b56\u7565\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2505.16086", "pdf": "https://arxiv.org/pdf/2505.16086", "abs": "https://arxiv.org/abs/2505.16086", "authors": ["Ming Shen", "Raphael Shu", "Anurag Pratik", "James Gung", "Yubin Ge", "Monica Sunkara", "Yi Zhang"], "title": "Optimizing LLM-Based Multi-Agent System with Textual Feedback: A Case Study on Software Development", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "We have seen remarkable progress in large language models (LLMs) empowered\nmulti-agent systems solving complex tasks necessitating cooperation among\nexperts with diverse skills. However, optimizing LLM-based multi-agent systems\nremains challenging. In this work, we perform an empirical case study on group\noptimization of role-based multi-agent systems utilizing natural language\nfeedback for challenging software development tasks under various evaluation\ndimensions. We propose a two-step agent prompts optimization pipeline:\nidentifying underperforming agents with their failure explanations utilizing\ntextual feedback and then optimizing system prompts of identified agents\nutilizing failure explanations. We then study the impact of various\noptimization settings on system performance with two comparison groups: online\nagainst offline optimization and individual against group optimization. For\ngroup optimization, we study two prompting strategies: one-pass and multi-pass\nprompting optimizations. Overall, we demonstrate the effectiveness of our\noptimization method for role-based multi-agent systems tackling software\ndevelopment tasks evaluated on diverse evaluation dimensions, and we\ninvestigate the impact of diverse optimization settings on group behaviors of\nthe multi-agent systems to provide practical insights for future development.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u57fa\u4e8e\u89d2\u8272\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4e24\u6b65\u4f18\u5316\u7ba1\u9053\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u53cd\u9988\u8bc6\u522b\u8868\u73b0\u4e0d\u4f73\u7684\u667a\u80fd\u4f53\u5e76\u4f18\u5316\u5176\u7cfb\u7edf\u63d0\u793a\uff0c\u5c55\u793a\u4e86\u5728\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e0d\u540c\u4f18\u5316\u8bbe\u7f6e\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7fa4\u4f53\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u89e3\u51b3\u9700\u8981\u8de8\u6280\u80fd\u4e13\u5bb6\u534f\u4f5c\u7684\u590d\u6742\u4efb\u52a1\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u4f18\u5316\u8fd9\u4e9b\u7cfb\u7edf\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u6b65\u4f18\u5316\u7ba1\u9053\uff1a1) \u901a\u8fc7\u6587\u672c\u53cd\u9988\u8bc6\u522b\u8868\u73b0\u4e0d\u4f73\u7684\u667a\u80fd\u4f53\u53ca\u5176\u5931\u8d25\u539f\u56e0\uff1b2) \u5229\u7528\u5931\u8d25\u89e3\u91ca\u4f18\u5316\u5df2\u8bc6\u522b\u667a\u80fd\u4f53\u7684\u7cfb\u7edf\u63d0\u793a\u3002\u6b64\u5916\uff0c\u7814\u7a76\u6bd4\u8f83\u4e86\u5728\u7ebf\u4e0e\u79bb\u7ebf\u4f18\u5316\u3001\u4e2a\u4f53\u4e0e\u7fa4\u4f53\u4f18\u5316\u7684\u6548\u679c\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e00\u6b21\u6027\u548c\u591a\u8f6e\u63d0\u793a\u4f18\u5316\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u4f18\u5316\u65b9\u6cd5\u5728\u5904\u7406\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u65f6\u662f\u6709\u6548\u7684\uff0c\u5e76\u4e14\u4e0d\u540c\u7684\u4f18\u5316\u8bbe\u7f6e\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u7fa4\u4f53\u884c\u4e3a\u4ea7\u751f\u4e86\u5f71\u54cd\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u4f18\u5316\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u57fa\u4e8e\u89d2\u8272\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u5b9e\u9645\u89c1\u89e3\u3002"}}
{"id": "2505.16058", "pdf": "https://arxiv.org/pdf/2505.16058", "abs": "https://arxiv.org/abs/2505.16058", "authors": ["Mars Liyao Gao", "J. Nathan Kutz", "Bernat Font"], "title": "Mesh-free sparse identification of nonlinear dynamics", "categories": ["cs.LG", "cs.AI", "physics.data-an"], "comment": "17 pages, 13 figures, 14 tables", "summary": "Identifying the governing equations of a dynamical system is one of the most\nimportant tasks for scientific modeling. However, this procedure often requires\nhigh-quality spatio-temporal data uniformly sampled on structured grids. In\nthis paper, we propose mesh-free SINDy, a novel algorithm which leverages the\npower of neural network approximation as well as auto-differentiation to\nidentify governing equations from arbitrary sensor placements and non-uniform\ntemporal data sampling. We show that mesh-free SINDy is robust to high noise\nlevels and limited data while remaining computationally efficient. In our\nimplementation, the training procedure is straight-forward and nearly free of\nhyperparameter tuning, making mesh-free SINDy widely applicable to many\nscientific and engineering problems. In the experiments, we demonstrate its\neffectiveness on a series of PDEs including the Burgers' equation, the heat\nequation, the Korteweg-De Vries equation and the 2D advection-diffusion\nequation. We conduct detailed numerical experiments on all datasets, varying\nthe noise levels and number of samples, and we also compare our approach to\nprevious state-of-the-art methods. It is noteworthy that, even in high-noise\nand low-data scenarios, mesh-free SINDy demonstrates robust PDE discovery,\nachieving successful identification with up to 75% noise for the Burgers'\nequation using 5,000 samples and with as few as 100 samples and 1% noise. All\nof this is achieved within a training time of under one minute.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3amesh-free SINDy\u7684\u65b0\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u903c\u8fd1\u548c\u81ea\u52a8\u5fae\u5206\u7684\u529b\u91cf\uff0c\u53ef\u4ee5\u4ece\u4efb\u610f\u4f20\u611f\u5668\u5e03\u7f6e\u548c\u975e\u5747\u5300\u65f6\u95f4\u6570\u636e\u91c7\u6837\u4e2d\u8bc6\u522b\u63a7\u5236\u65b9\u7a0b\u3002\u8be5\u65b9\u6cd5\u5bf9\u9ad8\u566a\u58f0\u6c34\u5e73\u548c\u6709\u9650\u7684\u6570\u636e\u5177\u6709\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u5728\u9ad8\u566a\u58f0\u548c\u4f4e\u6570\u636e\u60c5\u51b5\u4e0b\uff0cmesh-free SINDy\u4e5f\u80fd\u5b9e\u73b0\u7a33\u5065\u7684PDE\u53d1\u73b0\u3002", "motivation": "\u8bc6\u522b\u52a8\u529b\u7cfb\u7edf\u7684\u63a7\u5236\u65b9\u7a0b\u662f\u79d1\u5b66\u5efa\u6a21\u4e2d\u6700\u91cd\u8981\u7684\u4efb\u52a1\u4e4b\u4e00\u3002\u7136\u800c\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u901a\u5e38\u9700\u8981\u9ad8\u8d28\u91cf\u7684\u7a7a\u95f4-\u65f6\u95f4\u6570\u636e\uff0c\u5e76\u4e14\u9700\u8981\u5728\u7ed3\u6784\u5316\u7f51\u683c\u4e0a\u5747\u5300\u91c7\u6837\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u63d0\u51fa\u4e86mesh-free SINDy\u7b97\u6cd5\u3002", "method": "mesh-free SINDy\u7b97\u6cd5\u5229\u7528\u4e86\u795e\u7ecf\u7f51\u7edc\u903c\u8fd1\u548c\u81ea\u52a8\u5fae\u5206\u7684\u80fd\u529b\uff0c\u53ef\u4ee5\u4ece\u4efb\u610f\u4f20\u611f\u5668\u5e03\u7f6e\u548c\u975e\u5747\u5300\u65f6\u95f4\u6570\u636e\u91c7\u6837\u4e2d\u8bc6\u522b\u63a7\u5236\u65b9\u7a0b\u3002\u8be5\u65b9\u6cd5\u4e0d\u9700\u8981\u8fc7\u591a\u7684\u8d85\u53c2\u6570\u8c03\u6574\uff0c\u4f7f\u5176\u5e7f\u6cdb\u9002\u7528\u4e8e\u8bb8\u591a\u79d1\u5b66\u548c\u5de5\u7a0b\u95ee\u9898\u3002", "result": "\u901a\u8fc7\u4e00\u7cfb\u5217\u504f\u5fae\u5206\u65b9\u7a0b\uff08\u5982Burgers'\u65b9\u7a0b\u3001\u70ed\u65b9\u7a0b\u3001Korteweg-De Vries\u65b9\u7a0b\u548c2D\u5bf9\u6d41\u6269\u6563\u65b9\u7a0b\uff09\u7684\u8be6\u7ec6\u6570\u503c\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u5373\u4f7f\u5728\u9ad8\u566a\u58f0\u548c\u4f4e\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0cmesh-free SINDy\u4e5f\u80fd\u5b9e\u73b0\u7a33\u5065\u7684PDE\u53d1\u73b0\u3002\u4f8b\u5982\uff0c\u5bf9\u4e8eBurgers'\u65b9\u7a0b\uff0c\u4f7f\u75285,000\u4e2a\u6837\u672c\u548c\u9ad8\u8fbe75%\u7684\u566a\u58f0\uff0c\u6216\u4ec5100\u4e2a\u6837\u672c\u548c1%\u7684\u566a\u58f0\uff0c\u90fd\u80fd\u6210\u529f\u8bc6\u522b\u3002\u6240\u6709\u8fd9\u4e9b\u90fd\u5728\u4e0d\u5230\u4e00\u5206\u949f\u7684\u8bad\u7ec3\u65f6\u95f4\u5185\u5b8c\u6210\u3002", "conclusion": "mesh-free SINDy\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u4ece\u4efb\u610f\u4f20\u611f\u5668\u5e03\u7f6e\u548c\u975e\u5747\u5300\u65f6\u95f4\u6570\u636e\u91c7\u6837\u4e2d\u8bc6\u522b\u63a7\u5236\u65b9\u7a0b\uff0c\u5bf9\u9ad8\u566a\u58f0\u548c\u6709\u9650\u6570\u636e\u5177\u6709\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2505.16311", "pdf": "https://arxiv.org/pdf/2505.16311", "abs": "https://arxiv.org/abs/2505.16311", "authors": ["Marc Brooks", "Gabriel Durham", "Kihyuk Hong", "Ambuj Tewari"], "title": "Generator-Mediated Bandits: Thompson Sampling for GenAI-Powered Adaptive Interventions", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "39 pages, 12 figures", "summary": "Recent advances in generative artificial intelligence (GenAI) models have\nenabled the generation of personalized content that adapts to up-to-date user\ncontext. While personalized decision systems are often modeled using bandit\nformulations, the integration of GenAI introduces new structure into otherwise\nclassical sequential learning problems. In GenAI-powered interventions, the\nagent selects a query, but the environment experiences a stochastic response\ndrawn from the generative model. Standard bandit methods do not explicitly\naccount for this structure, where actions influence rewards only through\nstochastic, observed treatments. We introduce generator-mediated\nbandit-Thompson sampling (GAMBITTS), a bandit approach designed for this\naction/treatment split, using mobile health interventions with large language\nmodel-generated text as a motivating case study. GAMBITTS explicitly models\nboth the treatment and reward generation processes, using information in the\ndelivered treatment to accelerate policy learning relative to standard methods.\nWe establish regret bounds for GAMBITTS by decomposing sources of uncertainty\nin treatment and reward, identifying conditions where it achieves stronger\nguarantees than standard bandit approaches. In simulation studies, GAMBITTS\nconsistently outperforms conventional algorithms by leveraging observed\ntreatments to more accurately estimate expected rewards.", "AI": {"tldr": "\u8fd1\u671f\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u6a21\u578b\u7684\u8fdb\u6b65\u4f7f\u5f97\u53ef\u4ee5\u6839\u636e\u6700\u65b0\u7684\u7528\u6237\u60c5\u5883\u751f\u6210\u4e2a\u6027\u5316\u5185\u5bb9\u3002\u7136\u800c\uff0c\u6807\u51c6\u7684Bandit\u65b9\u6cd5\u672a\u8003\u8651GenAI\u5f15\u5165\u7684\u65b0\u7ed3\u6784\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGAMBITTS\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u660e\u786e\u5efa\u6a21\u6cbb\u7597\u548c\u5956\u52b1\u751f\u6210\u8fc7\u7a0b\uff0c\u5728\u6a21\u62df\u7814\u7a76\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u7b97\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u4e2a\u6027\u5316\u51b3\u7b56\u7cfb\u7edf\u901a\u5e38\u4f7f\u7528Bandit\u516c\u5f0f\u5efa\u6a21\uff0c\u4f46GenAI\u7684\u96c6\u6210\u5f15\u5165\u4e86\u65b0\u7684\u7ed3\u6784\u8fdb\u5165\u7ecf\u5178\u7684\u987a\u5e8f\u5b66\u4e60\u95ee\u9898\u3002\u5728\u7531GenAI\u9a71\u52a8\u7684\u5e72\u9884\u4e2d\uff0c\u4ee3\u7406\u9009\u62e9\u4e00\u4e2a\u67e5\u8be2\uff0c\u4f46\u73af\u5883\u7ecf\u5386\u4ece\u751f\u6210\u6a21\u578b\u4e2d\u62bd\u53d6\u7684\u968f\u673a\u54cd\u5e94\u3002\u6807\u51c6Bandit\u65b9\u6cd5\u5e76\u672a\u660e\u786e\u8003\u8651\u8fd9\u79cd\u7ed3\u6784\uff0c\u5176\u4e2d\u52a8\u4f5c\u4ec5\u901a\u8fc7\u968f\u673a\u3001\u89c2\u5bdf\u5230\u7684\u6cbb\u7597\u5f71\u54cd\u5956\u52b1\u3002", "method": "\u63d0\u51fa\u4e86\u751f\u6210\u5668\u4e2d\u4ecb\u7684Bandit-Thompson\u91c7\u6837\uff08GAMBITTS\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u4e3a\u884c\u52a8/\u6cbb\u7597\u5206\u79bb\u8bbe\u8ba1\u7684Bandit\u65b9\u6cd5\u3002GAMBITTS\u660e\u786e\u5efa\u6a21\u4e86\u6cbb\u7597\u548c\u5956\u52b1\u751f\u6210\u8fc7\u7a0b\uff0c\u5229\u7528\u4f20\u9012\u6cbb\u7597\u4e2d\u7684\u4fe1\u606f\u52a0\u901f\u7b56\u7565\u5b66\u4e60\u3002\u8be5\u65b9\u6cd5\u4ee5\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6587\u672c\u7684\u79fb\u52a8\u5065\u5eb7\u5e72\u9884\u4f5c\u4e3a\u6fc0\u52b1\u6848\u4f8b\u7814\u7a76\u3002", "result": "\u901a\u8fc7\u5206\u89e3\u6cbb\u7597\u548c\u5956\u52b1\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\uff0c\u5efa\u7acb\u4e86GAMBITTS\u7684\u9057\u61be\u8fb9\u754c\uff0c\u5e76\u786e\u5b9a\u4e86\u5176\u6bd4\u6807\u51c6Bandit\u65b9\u6cd5\u5b9e\u73b0\u66f4\u5f3a\u4fdd\u8bc1\u7684\u6761\u4ef6\u3002\u5728\u6a21\u62df\u7814\u7a76\u4e2d\uff0cGAMBITTS\u901a\u8fc7\u5229\u7528\u89c2\u5bdf\u5230\u7684\u6cbb\u7597\u624b\u6bb5\uff0c\u59cb\u7ec8\u4f18\u4e8e\u4f20\u7edf\u7b97\u6cd5\u3002", "conclusion": "GAMBITTS\u5728\u6a21\u62df\u7814\u7a76\u4e2d\u901a\u8fc7\u5229\u7528\u89c2\u6d4b\u5230\u7684\u6cbb\u7597\u624b\u6bb5\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u4f30\u8ba1\u671f\u671b\u5956\u52b1\uff0c\u4ece\u800c\u59cb\u7ec8\u4f18\u4e8e\u4f20\u7edf\u7b97\u6cd5\u3002\u5e76\u4e14\u5728\u5904\u7406\u6cbb\u7597\u548c\u5956\u52b1\u7684\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u65f6\uff0cGAMBITTS\u53ef\u4ee5\u5efa\u7acb\u9057\u61be\u8fb9\u754c\uff0c\u8bc6\u522b\u51fa\u6bd4\u6807\u51c6\u591a\u81c2\u8001\u864e\u673a\u65b9\u6cd5\u66f4\u5f3a\u7684\u4fdd\u8bc1\u6761\u4ef6\u3002"}}
{"id": "2505.16090", "pdf": "https://arxiv.org/pdf/2505.16090", "abs": "https://arxiv.org/abs/2505.16090", "authors": ["Dominick Kubica", "Dylan T. Gordon", "Nanami Emura", "Derleen Saini", "Charlie Goldenberg"], "title": "Can AI Read Between The Lines? Benchmarking LLMs On Financial Nuance", "categories": ["cs.AI", "cs.CL", "I.2.6; I.2.7"], "comment": "6 pages, 4 figures. Research conducted as part of a\n  Microsoft-sponsored Capstone Project at Santa Clara University", "summary": "As of 2025, Generative Artificial Intelligence (GenAI) has become a central\ntool for productivity across industries. Beyond text generation, GenAI now\nplays a critical role in coding, data analysis, and research workflows. As\nlarge language models (LLMs) continue to evolve, it is essential to assess the\nreliability and accuracy of their outputs, especially in specialized,\nhigh-stakes domains like finance. Most modern LLMs transform text into\nnumerical vectors, which are used in operations such as cosine similarity\nsearches to generate responses. However, this abstraction process can lead to\nmisinterpretation of emotional tone, particularly in nuanced financial\ncontexts. While LLMs generally excel at identifying sentiment in everyday\nlanguage, these models often struggle with the nuanced, strategically ambiguous\nlanguage found in earnings call transcripts. Financial disclosures frequently\nembed sentiment in hedged statements, forward-looking language, and\nindustry-specific jargon, making it difficult even for human analysts to\ninterpret consistently, let alone AI models. This paper presents findings from\nthe Santa Clara Microsoft Practicum Project, led by Professor Charlie\nGoldenberg, which benchmarks the performance of Microsoft's Copilot, OpenAI's\nChatGPT, Google's Gemini, and traditional machine learning models for sentiment\nanalysis of financial text. Using Microsoft earnings call transcripts, the\nanalysis assesses how well LLM-derived sentiment correlates with market\nsentiment and stock movements and evaluates the accuracy of model outputs.\nPrompt engineering techniques are also examined to improve sentiment analysis\nresults. Visualizations of sentiment consistency are developed to evaluate\nalignment between tone and stock performance, with sentiment trends analyzed\nacross Microsoft's lines of business to determine which segments exert the\ngreatest influence.", "AI": {"tldr": "\u52302025\u5e74\uff0c\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u5df2\u6210\u4e3a\u8de8\u884c\u4e1a\u63d0\u9ad8\u751f\u4ea7\u529b\u7684\u6838\u5fc3\u5de5\u5177\u3002\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5904\u7406\u65e5\u5e38\u8bed\u8a00\u60c5\u611f\u5206\u6790\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u8d22\u52a1\u9886\u57df\uff0c\u5b83\u4eec\u96be\u4ee5\u51c6\u786e\u89e3\u6790\u76c8\u4f59\u7535\u8bdd\u4f1a\u8bae\u8bb0\u5f55\u4e2d\u7684\u6a21\u7cca\u8bed\u8a00\u548c\u4e13\u4e1a\u672f\u8bed\u3002\u672c\u7814\u7a76\u901a\u8fc7\u8bc4\u4f30Microsoft Copilot\u3001OpenAI\u7684ChatGPT\u3001Google\u7684Gemini\u53ca\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bf9\u91d1\u878d\u6587\u672c\u60c5\u611f\u5206\u6790\u7684\u8868\u73b0\uff0c\u63a2\u8ba8\u8fd9\u4e9b\u6a21\u578b\u8f93\u51fa\u7684\u60c5\u611f\u4e0e\u5e02\u573a\u60c5\u7eea\u548c\u80a1\u7968\u53d8\u52a8\u7684\u76f8\u5173\u6027\uff0c\u5e76\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u548c\u53ef\u89c6\u5316\u65b9\u6cd5\u8fdb\u4e00\u6b65\u6539\u8fdb\u548c\u8bc4\u4f30\u6a21\u578b\u8868\u73b0\u3002", "motivation": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u5728\u5404\u884c\u4e1a\u7684\u5e7f\u6cdb\u5e94\u7528\u4fc3\u4f7f\u4eba\u4eec\u9700\u8981\u8bc4\u4f30\u5176\u5728\u9ad8\u98ce\u9669\u9886\u57df\u7684\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u91d1\u878d\u9886\u57df\u4e2d\u3002\u7531\u4e8e\u91d1\u878d\u62ab\u9732\u5e38\u5305\u542b\u6a21\u7cca\u9648\u8ff0\u3001\u524d\u77bb\u8bed\u8a00\u548c\u884c\u4e1a\u672f\u8bed\uff0c\u8fd9\u5bf9LLMs\u7684\u60c5\u611f\u5206\u6790\u80fd\u529b\u63d0\u51fa\u4e86\u6311\u6218\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u4e86\u89e3\u4e0d\u540cLLMs\u548c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u91d1\u878d\u6587\u672c\u60c5\u611f\u5206\u6790\u4e2d\u7684\u8868\u73b0\uff0c\u4ee5\u671f\u63d0\u5347\u5176\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002", "method": "1. \u9009\u62e9Microsoft Copilot\u3001OpenAI\u7684ChatGPT\u3001Google\u7684Gemini\u548c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002\n2. \u4f7f\u7528Microsoft\u76c8\u4f59\u7535\u8bdd\u4f1a\u8bae\u8bb0\u5f55\u4f5c\u4e3a\u6570\u636e\u6e90\uff0c\u8fdb\u884c\u60c5\u611f\u5206\u6790\u3002\n3. \u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u4f18\u5316\u60c5\u611f\u5206\u6790\u7ed3\u679c\u3002\n4. \u5f00\u53d1\u53ef\u89c6\u5316\u65b9\u6cd5\u8bc4\u4f30\u60c5\u611f\u4e00\u81f4\u6027\uff0c\u5206\u6790\u60c5\u611f\u8d8b\u52bf\u4e0e\u80a1\u7968\u8868\u73b0\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\n5. \u8003\u5bdfMicrosoft\u5404\u4e1a\u52a1\u7ebf\u5bf9\u6574\u4f53\u5f71\u54cd\u7684\u7a0b\u5ea6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u6587\u672c\u60c5\u611f\u5206\u6790\u4e2d\u5b58\u5728\u4e00\u5b9a\u7684\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u5305\u542b\u6a21\u7cca\u8bed\u8a00\u548c\u884c\u4e1a\u672f\u8bed\u7684\u5185\u5bb9\u65f6\u3002\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u53ef\u4ee5\u6709\u6548\u6539\u5584\u60c5\u611f\u5206\u6790\u7684\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63ed\u793a\u4e86\u4e0d\u540c\u4e1a\u52a1\u7ebf\u5bf9\u6574\u4f53\u60c5\u611f\u5206\u6790\u7684\u5f71\u54cd\u7a0b\u5ea6\uff0c\u6709\u52a9\u4e8e\u66f4\u6df1\u5165\u5730\u7406\u89e3\u5e02\u573a\u53cd\u5e94\u3002", "conclusion": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e00\u822c\u8bed\u8a00\u60c5\u611f\u5206\u6790\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5728\u91d1\u878d\u9886\u57df\u4e2d\u7684\u5e94\u7528\u4ecd\u9700\u8c28\u614e\u5bf9\u5f85\u3002\u63d0\u793a\u5de5\u7a0b\u6280\u672f\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u6027\u80fd\uff0c\u800c\u53ef\u89c6\u5316\u65b9\u6cd5\u5219\u4e3a\u8bc4\u4f30\u6a21\u578b\u8868\u73b0\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002\u672a\u6765\u7684\u7814\u7a76\u5e94\u7ee7\u7eed\u63a2\u7d22\u5982\u4f55\u8fdb\u4e00\u6b65\u4f18\u5316\u8fd9\u4e9b\u6a21\u578b\uff0c\u4ee5\u66f4\u597d\u5730\u9002\u5e94\u91d1\u878d\u9886\u57df\u7684\u7279\u6b8a\u9700\u6c42\u3002"}}
{"id": "2505.16060", "pdf": "https://arxiv.org/pdf/2505.16060", "abs": "https://arxiv.org/abs/2505.16060", "authors": ["Shangding Gu", "Donghao Ying", "Ming Jin", "Yu Joe Lu", "Jun Wang", "Javad Lavaei", "Costas Spanos"], "title": "Few-Shot Test-Time Optimization Without Retraining for Semiconductor Recipe Generation and Beyond", "categories": ["cs.LG"], "comment": null, "summary": "We introduce Model Feedback Learning (MFL), a novel test-time optimization\nframework for optimizing inputs to pre-trained AI models or deployed hardware\nsystems without requiring any retraining of the models or modifications to the\nhardware. In contrast to existing methods that rely on adjusting model\nparameters, MFL leverages a lightweight reverse model to iteratively search for\noptimal inputs, enabling efficient adaptation to new objectives under\ndeployment constraints. This framework is particularly advantageous in\nreal-world settings, such as semiconductor manufacturing recipe generation,\nwhere modifying deployed systems is often infeasible or cost-prohibitive. We\nvalidate MFL on semiconductor plasma etching tasks, where it achieves target\nrecipe generation in just five iterations, significantly outperforming both\nBayesian optimization and human experts. Beyond semiconductor applications, MFL\nalso demonstrates strong performance in chemical processes (e.g., chemical\nvapor deposition) and electronic systems (e.g., wire bonding), highlighting its\nbroad applicability. Additionally, MFL incorporates stability-aware\noptimization, enhancing robustness to process variations and surpassing\nconventional supervised learning and random search methods in high-dimensional\ncontrol settings. By enabling few-shot adaptation, MFL provides a scalable and\nefficient paradigm for deploying intelligent control in real-world\nenvironments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d4b\u8bd5\u65f6\u4f18\u5316\u6846\u67b6Model Feedback Learning (MFL)\uff0c\u5b83\u53ef\u4ee5\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u6216\u4fee\u6539\u786c\u4ef6\u7684\u60c5\u51b5\u4e0b\u4f18\u5316\u9884\u8bad\u7ec3AI\u6a21\u578b\u6216\u5df2\u90e8\u7f72\u786c\u4ef6\u7cfb\u7edf\u7684\u8f93\u5165\u3002MFL\u901a\u8fc7\u8f7b\u91cf\u7ea7\u53cd\u5411\u6a21\u578b\u8fed\u4ee3\u641c\u7d22\u6700\u4f18\u8f93\u5165\uff0c\u9002\u5e94\u65b0\u76ee\u6807\u3002\u5728\u534a\u5bfc\u4f53\u7b49\u5b9e\u9645\u5e94\u7528\u4e2d\uff0cMFL\u663e\u8457\u4f18\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u4eba\u7c7b\u4e13\u5bb6\uff0c\u5e76\u5c55\u793a\u4e86\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002\u6b64\u5916\uff0cMFL\u5177\u6709\u7a33\u5b9a\u6027\u4f18\u5316\u529f\u80fd\uff0c\u589e\u5f3a\u4e86\u5bf9\u8fc7\u7a0b\u53d8\u5316\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u8bb8\u591a\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u8c03\u6574\u6a21\u578b\u53c2\u6570\u6765\u4f18\u5316\u8f93\u5165\uff0c\u4f46\u5728\u67d0\u4e9b\u5b9e\u9645\u573a\u666f\uff08\u5982\u534a\u5bfc\u4f53\u5236\u9020\uff09\u4e2d\uff0c\u4fee\u6539\u5df2\u90e8\u7f72\u7cfb\u7edf\u5f80\u5f80\u662f\u4e0d\u53ef\u884c\u6216\u6210\u672c\u8fc7\u9ad8\u7684\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u6216\u4fee\u6539\u786c\u4ef6\u5373\u53ef\u4f18\u5316\u8f93\u5165\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u4e86Model Feedback Learning (MFL)\u6846\u67b6\uff0c\u5229\u7528\u8f7b\u91cf\u7ea7\u53cd\u5411\u6a21\u578b\u8fdb\u884c\u8fed\u4ee3\u641c\u7d22\u4ee5\u627e\u5230\u6700\u4f18\u8f93\u5165\u3002\u8be5\u65b9\u6cd5\u4e0d\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u6216\u4fee\u6539\u786c\u4ef6\uff0c\u80fd\u591f\u9ad8\u6548\u9002\u5e94\u65b0\u76ee\u6807\uff0c\u5e76\u4e14\u7279\u522b\u9002\u7528\u4e8e\u65e0\u6cd5\u4fee\u6539\u5df2\u90e8\u7f72\u7cfb\u7edf\u7684\u5b9e\u9645\u573a\u666f\u3002", "result": "\u5728\u534a\u5bfc\u4f53\u7b49\u79bb\u5b50\u8680\u523b\u4efb\u52a1\u4e2d\uff0cMFL\u4ec5\u9700\u4e94\u6b21\u8fed\u4ee3\u5373\u53ef\u751f\u6210\u76ee\u6807\u914d\u65b9\uff0c\u663e\u8457\u4f18\u4e8e\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u4eba\u7c7b\u4e13\u5bb6\u3002\u6b64\u5916\uff0c\u5728\u5316\u5b66\u8fc7\u7a0b\u548c\u7535\u5b50\u7cfb\u7edf\u4e2d\u4e5f\u8868\u73b0\u51fa\u8272\uff0c\u7a33\u5b9a\u6027\u4f18\u5316\u589e\u5f3a\u4e86\u5176\u5728\u9ad8\u7ef4\u63a7\u5236\u8bbe\u7f6e\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "MFL\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u8303\u5f0f\uff0c\u7528\u4e8e\u5728\u5b9e\u9645\u73af\u5883\u4e2d\u90e8\u7f72\u667a\u80fd\u63a7\u5236\uff0c\u7279\u522b\u662f\u5728\u65e0\u6cd5\u4fee\u6539\u5df2\u90e8\u7f72\u7cfb\u7edf\u7684\u573a\u666f\u4e2d\u5c55\u73b0\u51fa\u4e86\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2505.16329", "pdf": "https://arxiv.org/pdf/2505.16329", "abs": "https://arxiv.org/abs/2505.16329", "authors": ["Simone Bombari", "Inbar Seroussi", "Marco Mondelli"], "title": "Better Rates for Private Linear Regression in the Proportional Regime via Aggressive Clipping", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Differentially private (DP) linear regression has received significant\nattention in the recent theoretical literature, with several works aimed at\nobtaining improved error rates. A common approach is to set the clipping\nconstant much larger than the expected norm of the per-sample gradients. While\nsimplifying the analysis, this is however in sharp contrast with what empirical\nevidence suggests to optimize performance. Our work bridges this gap between\ntheory and practice: we provide sharper rates for DP stochastic gradient\ndescent (DP-SGD) by crucially operating in a regime where clipping happens\nfrequently. Specifically, we consider the setting where the data is\nmultivariate Gaussian, the number of training samples $n$ is proportional to\nthe input dimension $d$, and the algorithm guarantees constant-order zero\nconcentrated DP. Our method relies on establishing a deterministic equivalent\nfor the trajectory of DP-SGD in terms of a family of ordinary differential\nequations (ODEs). As a consequence, the risk of DP-SGD is bounded between two\nODEs, with upper and lower bounds matching for isotropic data. By studying\nthese ODEs when $n / d$ is large enough, we demonstrate the optimality of\naggressive clipping, and we uncover the benefits of decaying learning rate and\nprivate noise scheduling.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165\u9891\u7e41\u88c1\u526a\u673a\u5236\uff0c\u672c\u7814\u7a76\u4f18\u5316\u4e86\u5dee\u5206\u9690\u79c1\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08DP-SGD\uff09\u7684\u8bef\u5dee\u7387\uff0c\u5e76\u8bc1\u660e\u4e86\u5728\u7279\u5b9a\u6570\u636e\u5206\u5e03\u4e0b\u6fc0\u8fdb\u88c1\u526a\u7b56\u7565\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u7406\u8bba\u4e2d\uff0c\u4e3a\u4e86\u7b80\u5316\u5206\u6790\uff0c\u901a\u5e38\u5c06\u88c1\u526a\u5e38\u6570\u8bbe\u5f97\u8fdc\u5927\u4e8e\u5355\u4e2a\u6837\u672c\u68af\u5ea6\u7684\u671f\u671b\u8303\u6570\uff0c\u8fd9\u4e0e\u5b9e\u9645\u6027\u80fd\u4f18\u5316\u7684\u9700\u6c42\u4e0d\u7b26\u3002\u56e0\u6b64\u9700\u8981\u5f25\u5408\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u7814\u7a76\u5047\u8bbe\u6570\u636e\u4e3a\u591a\u53d8\u91cf\u9ad8\u65af\u5206\u5e03\uff0c\u8bad\u7ec3\u6837\u672c\u6570 $n$ \u4e0e\u8f93\u5165\u7ef4\u5ea6 $d$ \u6210\u6bd4\u4f8b\uff0c\u5e76\u786e\u4fdd\u96f6\u96c6\u4e2d\u5dee\u5206\u9690\u79c1\u3002\u901a\u8fc7\u5efa\u7acb\u4e00\u7ec4\u5e38\u5fae\u5206\u65b9\u7a0b (ODEs) \u6765\u786e\u5b9a DP-SGD \u8f68\u8ff9\u7684\u7b49\u6548\u6027\uff0c\u5e76\u4ee5\u6b64\u63a8\u5bfc\u51fa\u98ce\u9669\u8fb9\u754c\u3002", "result": "\u5f53 $n/d$ \u8db3\u591f\u5927\u65f6\uff0c\u7814\u7a76\u663e\u793a\u6fc0\u8fdb\u88c1\u526a\u7b56\u7565\u3001\u9012\u51cf\u5b66\u4e60\u7387\u548c\u79c1\u6709\u566a\u58f0\u8c03\u5ea6\u80fd\u663e\u8457\u6539\u5584 DP-SGD \u7684\u6027\u80fd\u3002", "conclusion": "\u6fc0\u8fdb\u88c1\u526a\u7b56\u7565\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u662f\u6700\u4f73\u9009\u62e9\uff0c\u4e14\u9012\u51cf\u5b66\u4e60\u7387\u548c\u79c1\u6709\u566a\u58f0\u8c03\u5ea6\u5bf9\u63d0\u5347\u6a21\u578b\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2505.16097", "pdf": "https://arxiv.org/pdf/2505.16097", "abs": "https://arxiv.org/abs/2505.16097", "authors": ["Zifeng Wang", "Qiao Jin", "Jiacheng Lin", "Junyi Gao", "Jathurshan Pradeepkumar", "Pengcheng Jiang", "Benjamin Danek", "Zhiyong Lu", "Jimeng Sun"], "title": "TrialPanorama: Database and Benchmark for Systematic Review and Design of Clinical Trials", "categories": ["cs.AI"], "comment": null, "summary": "Developing artificial intelligence (AI) for vertical domains requires a solid\ndata foundation for both training and evaluation. In this work, we introduce\nTrialPanorama, a large-scale, structured database comprising 1,657,476 clinical\ntrial records aggregated from 15 global sources. The database captures key\naspects of trial design and execution, including trial setups, interventions,\nconditions, biomarkers, and outcomes, and links them to standard biomedical\nontologies such as DrugBank and MedDRA. This structured and ontology-grounded\ndesign enables TrialPanorama to serve as a unified, extensible resource for a\nwide range of clinical trial tasks, including trial planning, design, and\nsummarization. To demonstrate its utility, we derive a suite of benchmark tasks\ndirectly from the TrialPanorama database. The benchmark spans eight tasks\nacross two categories: three for systematic review (study search, study\nscreening, and evidence summarization) and five for trial design (arm design,\neligibility criteria, endpoint selection, sample size estimation, and trial\ncompletion assessment). The experiments using five state-of-the-art large\nlanguage models (LLMs) show that while general-purpose LLMs exhibit some\nzero-shot capability, their performance is still inadequate for high-stakes\nclinical trial workflows. We release TrialPanorama database and the benchmark\nto facilitate further research on AI for clinical trials.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86TrialPanorama\uff0c\u4e00\u4e2a\u5305\u542b1,657,476\u4e2a\u4e34\u5e8a\u8bd5\u9a8c\u8bb0\u5f55\u7684\u5927\u89c4\u6a21\u7ed3\u6784\u5316\u6570\u636e\u5e93\u3002\u8be5\u6570\u636e\u5e93\u4ece15\u4e2a\u5168\u7403\u6765\u6e90\u805a\u5408\u6570\u636e\uff0c\u5e76\u94fe\u63a5\u5230\u6807\u51c6\u7684\u751f\u7269\u533b\u5b66\u672c\u4f53\u8bba\uff0c\u5982DrugBank\u548cMedDRA\u3002\u4e3a\u4e86\u5c55\u793a\u5176\u6548\u7528\uff0c\u4f5c\u8005\u4eceTrialPanorama\u6570\u636e\u5e93\u4e2d\u884d\u751f\u51fa\u4e00\u7cfb\u5217\u57fa\u51c6\u4efb\u52a1\uff0c\u5305\u62ec\u7cfb\u7edf\u8bc4\u4ef7\u548c\u8bd5\u9a8c\u8bbe\u8ba1\u76f8\u5173\u7684\u4efb\u52a1\u3002\u5b9e\u9a8c\u4f7f\u7528\u4e94\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8868\u660e\uff0c\u901a\u7528\u7684LLMs\u867d\u7136\u5177\u5907\u4e00\u5b9a\u7684\u96f6\u6837\u672c\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u7684\u8868\u73b0\u4ecd\u7136\u4e0d\u8db3\u4ee5\u6ee1\u8db3\u9ad8\u98ce\u9669\u7684\u4e34\u5e8a\u8bd5\u9a8c\u5de5\u4f5c\u6d41\u7a0b\u3002", "motivation": "\u5f00\u53d1\u9002\u7528\u4e8e\u5782\u76f4\u9886\u57df\u7684AI\u9700\u8981\u575a\u5b9e\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u6570\u636e\u57fa\u7840\u3002\u73b0\u6709\u7684\u4e34\u5e8a\u8bd5\u9a8c\u6570\u636e\u5206\u6563\u4e14\u975e\u7ed3\u6784\u5316\uff0c\u9650\u5236\u4e86AI\u5728\u8fd9\u4e00\u9886\u57df\u7684\u53d1\u5c55\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u3001\u53ef\u6269\u5c55\u7684\u8d44\u6e90\u6765\u652f\u6301\u5404\u79cd\u4e34\u5e8a\u8bd5\u9a8c\u4efb\u52a1\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aTrialPanorama\u7684\u5927\u89c4\u6a21\u7ed3\u6784\u5316\u6570\u636e\u5e93\uff0c\u5176\u4e2d\u5305\u62ec1,657,476\u4e2a\u4e34\u5e8a\u8bd5\u9a8c\u8bb0\u5f55\uff0c\u4ece15\u4e2a\u5168\u7403\u6765\u6e90\u805a\u5408\u6570\u636e\uff0c\u5e76\u4e0e\u6807\u51c6\u751f\u7269\u533b\u5b66\u672c\u4f53\u8bba\uff08\u5982DrugBank\u548cMedDRA\uff09\u76f8\u5173\u8054\u3002\u57fa\u4e8e\u6b64\u6570\u636e\u5e93\uff0c\u5b9a\u4e49\u4e86\u4e00\u5957\u57fa\u51c6\u4efb\u52a1\uff0c\u6db5\u76d6\u7cfb\u7edf\u8bc4\u4ef7\u548c\u8bd5\u9a8c\u8bbe\u8ba1\u4e24\u5927\u7c7b\u5171\u516b\u4e2a\u4efb\u52a1\u3002\u4f7f\u7528\u4e94\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u8fd9\u4e9b\u4efb\u52a1\u8fdb\u884c\u4e86\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5c3d\u7ba1\u901a\u7528\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u67d0\u4e9b\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u4e00\u5b9a\u7684\u96f6\u6837\u672c\u80fd\u529b\uff0c\u4f46\u5176\u6027\u80fd\u4ecd\u4e0d\u8db3\u4ee5\u5e94\u5bf9\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u7684\u9ad8\u98ce\u9669\u5de5\u4f5c\u6d41\u7a0b\u3002\u8fd9\u8868\u660e\uff0c\u5728\u4e34\u5e8a\u8bd5\u9a8c\u9886\u57df\uff0c\u9700\u8981\u66f4\u4e13\u4e1a\u7684AI\u6a21\u578b\u548c\u65b9\u6cd5\u3002", "conclusion": "TrialPanorama\u4f5c\u4e3a\u4e00\u4e2a\u5927\u89c4\u6a21\u7ed3\u6784\u5316\u6570\u636e\u5e93\uff0c\u4e3a\u4e34\u5e8a\u8bd5\u9a8c\u76f8\u5173\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u3001\u53ef\u6269\u5c55\u7684\u8d44\u6e90\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u9ad8\u98ce\u9669\u4e34\u5e8a\u8bd5\u9a8c\u5de5\u4f5c\u65f6\u8868\u73b0\u4e0d\u8db3\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u53d1\u5c55\u66f4\u4e13\u4e1a\u5316\u7684AI\u6a21\u578b\u3002"}}
{"id": "2505.16066", "pdf": "https://arxiv.org/pdf/2505.16066", "abs": "https://arxiv.org/abs/2505.16066", "authors": ["Zhixu Silvia Tao", "Kasper Vinken", "Hao-Wei Yeh", "Avi Cooper", "Xavier Boix"], "title": "Merge to Mix: Mixing Datasets via Model Merging", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Mixing datasets for fine-tuning large models (LMs) has become critical for\nmaximizing performance on downstream tasks. However, composing effective\ndataset mixtures typically relies on heuristics and trial-and-error, often\nrequiring multiple fine-tuning runs to achieve the desired outcome. We propose\na novel method, $\\textit{Merge to Mix}$, that accelerates composing dataset\nmixtures through model merging. Model merging is a recent technique that\ncombines the abilities of multiple individually fine-tuned LMs into a single LM\nby using a few simple arithmetic operations. Our key insight is that merging\nmodels individually fine-tuned on each dataset in a mixture can effectively\nserve as a surrogate for a model fine-tuned on the entire mixture. Merge to Mix\nleverages this insight to accelerate selecting dataset mixtures without\nrequiring full fine-tuning on each candidate mixture. Our experiments\ndemonstrate that Merge to Mix surpasses state-of-the-art methods in dataset\nselection for fine-tuning LMs.", "AI": {"tldr": "Mixing datasets for fine-tuning large models is crucial for downstream tasks, but it often relies on heuristics and trial-and-error. This paper proposes Merge to Mix, a method that accelerates dataset mixture composition through model merging. Experiments show that Merge to Mix outperforms current state-of-the-art methods in dataset selection for fine-tuning LMs.", "motivation": "The motivation behind this paper is the challenge of effectively mixing datasets for fine-tuning large models to maximize performance on downstream tasks, which currently relies on heuristics and trial-and-error.", "method": "The proposed method, Merge to Mix, accelerates composing dataset mixtures through model merging. It combines individually fine-tuned models using simple arithmetic operations, serving as a surrogate for a model fine-tuned on the entire mixture.", "result": "Experiments demonstrate that Merge to Mix surpasses state-of-the-art methods in dataset selection for fine-tuning LMs.", "conclusion": "Merge to Mix provides an effective way to accelerate the process of selecting dataset mixtures for fine-tuning large models without requiring full fine-tuning on each candidate mixture."}}
{"id": "2505.16644", "pdf": "https://arxiv.org/pdf/2505.16644", "abs": "https://arxiv.org/abs/2505.16644", "authors": ["Stephen Y. Zhang", "Michael P H Stumpf"], "title": "Learning non-equilibrium diffusions with Schr\u00f6dinger bridges: from exactly solvable to simulation-free", "categories": ["stat.ML", "cs.LG", "math.OC", "62M45, 49N10"], "comment": "9 pages, 5 figures", "summary": "We consider the Schr\\\"odinger bridge problem which, given ensemble\nmeasurements of the initial and final configurations of a stochastic dynamical\nsystem and some prior knowledge on the dynamics, aims to reconstruct the \"most\nlikely\" evolution of the system compatible with the data. Most existing\nliterature assume Brownian reference dynamics and are implicitly limited to\npotential-driven dynamics. We depart from this regime and consider reference\nprocesses described by a multivariate Ornstein-Uhlenbeck process with generic\ndrift matrix $\\mathbf{A} \\in \\mathbb{R}^{d \\times d}$. When $\\mathbf{A}$ is\nasymmetric, this corresponds to a non-equilibrium system with non-conservative\nforces at play: this is important for applications to biological systems, which\nare naturally exist out-of-equilibrium. In the case of Gaussian marginals, we\nderive explicit expressions that characterise the solution of both the static\nand dynamic Schr\\\"odinger bridge. For general marginals, we propose mvOU-OTFM,\na simulation-free algorithm based on flow and score matching for learning the\nSchr\\\"odinger bridge. In application to a range of problems based on synthetic\nand real single cell data, we demonstrate that mvOU-OTFM achieves higher\naccuracy compared to competing methods, whilst being significantly faster to\ntrain.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u4e86\u975e\u5e73\u8861\u6001\u7cfb\u7edf\u4e2d\u7684Schr\u00f6dinger\u6865\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5mvOU-OTFM\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u3001\u5feb\u901f\u5730\u5b66\u4e60Schr\u00f6dinger\u6865\u3002", "motivation": "\u73b0\u6709\u6587\u732e\u5927\u591a\u5047\u8bbe\u5e03\u6717\u8fd0\u52a8\u53c2\u8003\u52a8\u529b\u5b66\uff0c\u4ec5\u9002\u7528\u4e8e\u52bf\u80fd\u9a71\u52a8\u7684\u52a8\u529b\u5b66\u7cfb\u7edf\u3002\u7136\u800c\uff0c\u8bb8\u591a\u751f\u7269\u7cfb\u7edf\u662f\u975e\u5e73\u8861\u6001\u7684\uff0c\u5305\u542b\u975e\u4fdd\u5b88\u529b\u7684\u4f5c\u7528\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5904\u7406\u8fd9\u7c7b\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u8003\u8651\u4e86\u7531\u591a\u53d8\u91cfOrnstein-Uhlenbeck\u8fc7\u7a0b\u63cf\u8ff0\u7684\u53c2\u8003\u8fc7\u7a0b\uff0c\u5e76\u63d0\u51fa\u4e86mvOU-OTFM\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u57fa\u4e8e\u6d41\u548c\u5f97\u5206\u5339\u914d\u6280\u672f\uff0c\u65e0\u9700\u6a21\u62df\u5373\u53ef\u5b66\u4e60Schr\u00f6dinger\u6865\u3002", "result": "\u5728\u9ad8\u65af\u8fb9\u7f18\u5206\u5e03\u7684\u60c5\u51b5\u4e0b\uff0c\u4f5c\u8005\u63a8\u5bfc\u4e86\u9759\u6001\u548c\u52a8\u6001Schr\u00f6dinger\u6865\u7684\u663e\u5f0f\u89e3\uff1b\u5bf9\u4e8e\u4e00\u822c\u8fb9\u7f18\u5206\u5e03\uff0cmvOU-OTFM\u7b97\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u5355\u7ec6\u80de\u6570\u636e\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u4e14\u8bad\u7ec3\u901f\u5ea6\u663e\u8457\u66f4\u5feb\u3002", "conclusion": "mvOU-OTFM\u7b97\u6cd5\u4e3a\u89e3\u51b3\u975e\u5e73\u8861\u6001\u7cfb\u7edf\u7684Schr\u00f6dinger\u6865\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2505.16100", "pdf": "https://arxiv.org/pdf/2505.16100", "abs": "https://arxiv.org/abs/2505.16100", "authors": ["Zifeng Wang", "Benjamin Danek", "Jimeng Sun"], "title": "BioDSA-1K: Benchmarking Data Science Agents for Biomedical Research", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Validating scientific hypotheses is a central challenge in biomedical\nresearch, and remains difficult for artificial intelligence (AI) agents due to\nthe complexity of real-world data analysis and evidence interpretation. In this\nwork, we present BioDSA-1K, a benchmark designed to evaluate AI agents on\nrealistic, data-driven biomedical hypothesis validation tasks. BioDSA-1K\nconsists of 1,029 hypothesis-centric tasks paired with 1,177 analysis plans,\ncurated from over 300 published biomedical studies to reflect the structure and\nreasoning found in authentic research workflows. Each task includes a\nstructured hypothesis derived from the original study's conclusions, expressed\nin the affirmative to reflect the language of scientific reporting, and one or\nmore pieces of supporting evidence grounded in empirical data tables. While\nthese hypotheses mirror published claims, they remain testable using standard\nstatistical or machine learning methods. The benchmark enables evaluation along\nfour axes: (1) hypothesis decision accuracy, (2) alignment between evidence and\nconclusion, (3) correctness of the reasoning process, and (4) executability of\nthe AI-generated analysis code. Importantly, BioDSA-1K includes non-verifiable\nhypotheses: cases where the available data are insufficient to support or\nrefute a claim, reflecting a common yet underexplored scenario in real-world\nscience. We propose BioDSA-1K as a foundation for building and evaluating\ngeneralizable, trustworthy AI agents for biomedical discovery.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86BioDSA-1K\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30AI\u5728\u751f\u7269\u533b\u5b66\u5047\u8bbe\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u7684\u57fa\u51c6\u3002\u8be5\u57fa\u51c6\u5305\u62ec1029\u4e2a\u5047\u8bbe\u9a8c\u8bc1\u4efb\u52a1\u548c1177\u4e2a\u5206\u6790\u8ba1\u5212\uff0c\u6765\u81ea300\u591a\u9879\u5df2\u53d1\u8868\u7684\u751f\u7269\u533b\u5b66\u7814\u7a76\u3002\u5176\u76ee\u7684\u662f\u4ece\u56db\u4e2a\u7ef4\u5ea6\u8bc4\u4f30AI\uff1a\u5047\u8bbe\u51b3\u7b56\u51c6\u786e\u6027\u3001\u8bc1\u636e\u4e0e\u7ed3\u8bba\u7684\u4e00\u81f4\u6027\u3001\u63a8\u7406\u8fc7\u7a0b\u7684\u6b63\u786e\u6027\u4ee5\u53ca\u751f\u6210\u7684\u5206\u6790\u4ee3\u7801\u7684\u53ef\u6267\u884c\u6027\u3002\u6b64\u5916\uff0cBioDSA-1K\u8fd8\u5305\u542b\u65e0\u6cd5\u9a8c\u8bc1\u7684\u5047\u8bbe\uff0c\u4ee5\u53cd\u6620\u73b0\u5b9e\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u5e38\u89c1\u60c5\u51b5\u3002", "motivation": "\u79d1\u5b66\u5047\u8bbe\u9a8c\u8bc1\u662f\u751f\u7269\u533b\u5b66\u7814\u7a76\u4e2d\u7684\u6838\u5fc3\u6311\u6218\uff0c\u4f46AI\u5728\u8fd9\u4e00\u9886\u57df\u4ecd\u9762\u4e34\u56f0\u96be\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u5904\u7406\u548c\u8bc1\u636e\u89e3\u91ca\u65b9\u9762\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u8bbe\u8ba1\u7684\u57fa\u51c6\u6765\u6d4b\u8bd5AI\u5728\u751f\u7269\u533b\u5b66\u5047\u8bbe\u9a8c\u8bc1\u4e2d\u7684\u80fd\u529b\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aBioDSA-1K\u7684\u57fa\u51c6\uff0c\u5176\u4e2d\u5305\u62ec1029\u4e2a\u5047\u8bbe\u9a8c\u8bc1\u4efb\u52a1\u548c1177\u4e2a\u5206\u6790\u8ba1\u5212\uff0c\u8fd9\u4e9b\u5185\u5bb9\u6765\u6e90\u4e8e\u8d85\u8fc7300\u9879\u5df2\u53d1\u8868\u7684\u751f\u7269\u533b\u5b66\u7814\u7a76\u3002\u6bcf\u4e2a\u4efb\u52a1\u90fd\u5305\u542b\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u5047\u8bbe\u53ca\u5176\u652f\u6301\u8bc1\u636e\uff0c\u5e76\u53ef\u901a\u8fc7\u6807\u51c6\u7edf\u8ba1\u6216\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u9a8c\u8bc1\u3002\u57fa\u51c6\u5141\u8bb8\u4ece\u56db\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8bc4\u4f30\uff1a\u5047\u8bbe\u51b3\u7b56\u51c6\u786e\u6027\u3001\u8bc1\u636e\u4e0e\u7ed3\u8bba\u7684\u4e00\u81f4\u6027\u3001\u63a8\u7406\u8fc7\u7a0b\u7684\u6b63\u786e\u6027\u4ee5\u53ca\u751f\u6210\u5206\u6790\u4ee3\u7801\u7684\u53ef\u6267\u884c\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u5305\u62ec\u4e86\u4e0d\u53ef\u9a8c\u8bc1\u7684\u5047\u8bbe\u3002", "result": "BioDSA-1K\u4e3a\u8bc4\u4f30AI\u5728\u751f\u7269\u533b\u5b66\u5047\u8bbe\u9a8c\u8bc1\u4e2d\u7684\u8868\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u6846\u67b6\uff0c\u80fd\u591f\u6db5\u76d6\u771f\u5b9e\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u591a\u79cd\u573a\u666f\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u6570\u636e\u4e0d\u8db3\u4ee5\u652f\u6301\u6216\u53cd\u9a73\u5047\u8bbe\u7684\u60c5\u51b5\u3002", "conclusion": "BioDSA-1K\u4e3a\u5f00\u53d1\u548c\u8bc4\u4f30\u901a\u7528\u4e14\u503c\u5f97\u4fe1\u8d56\u7684AI\u4ee3\u7406\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u65e8\u5728\u63a8\u52a8\u751f\u7269\u533b\u5b66\u53d1\u73b0\u9886\u57df\u7684\u8fdb\u6b65\u3002"}}
{"id": "2505.16074", "pdf": "https://arxiv.org/pdf/2505.16074", "abs": "https://arxiv.org/abs/2505.16074", "authors": ["Bart Kosko", "Olaoluwa Adigun"], "title": "Bidirectional Variational Autoencoders", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "10 pages, 6 figures", "summary": "We present the new bidirectional variational autoencoder (BVAE) network\narchitecture. The BVAE uses a single neural network both to encode and decode\ninstead of an encoder-decoder network pair. The network encodes in the forward\ndirection and decodes in the backward direction through the same synaptic web.\nSimulations compared BVAEs and ordinary VAEs on the four image tasks of image\nreconstruction, classification, interpolation, and generation. The image\ndatasets included MNIST handwritten digits, Fashion-MNIST, CIFAR-10, and\nCelebA-64 face images. The bidirectional structure of BVAEs cut the parameter\ncount by almost 50% and still slightly outperformed the unidirectional VAEs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53cc\u5411\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08BVAE\uff09\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u5355\u4e00\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u7f16\u7801\u548c\u89e3\u7801\u529f\u80fd\uff0c\u5728\u591a\u4e2a\u56fe\u50cf\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u51cf\u5c11\u7ea650%\u7684\u53c2\u6570\u91cf\u3002", "motivation": "\u5f53\u524d\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAE\uff09\u901a\u5e38\u4f7f\u7528\u7f16\u7801-\u89e3\u7801\u5668\u7f51\u7edc\u5bf9\u6765\u5904\u7406\u6570\u636e\uff0c\u4f46\u8fd9\u79cd\u65b9\u6cd5\u53ef\u80fd\u9700\u8981\u66f4\u591a\u7684\u53c2\u6570\u3002\u4e3a\u4e86\u63d0\u9ad8\u6548\u7387\u5e76\u4f18\u5316\u6027\u80fd\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f51\u7edc\u67b6\u6784\u2014\u2014\u53cc\u5411\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08BVAE\uff09\u3002", "method": "BVAE\u91c7\u7528\u5355\u4e00\u795e\u7ecf\u7f51\u7edc\u540c\u65f6\u6267\u884c\u7f16\u7801\u548c\u89e3\u7801\u4efb\u52a1\uff0c\u800c\u4e0d\u662f\u4f20\u7edf\u7684\u7f16\u7801-\u89e3\u7801\u5668\u7f51\u7edc\u5bf9\u3002\u7f16\u7801\u901a\u8fc7\u524d\u5411\u4f20\u64ad\u8fdb\u884c\uff0c\u800c\u89e3\u7801\u5219\u901a\u8fc7\u540c\u4e00\u7a81\u89e6\u7f51\u7edc\u7684\u53cd\u5411\u4f20\u64ad\u5b8c\u6210\u3002", "result": "\u5728\u56db\u4e2a\u56fe\u50cf\u4efb\u52a1\uff08\u56fe\u50cf\u91cd\u5efa\u3001\u5206\u7c7b\u3001\u63d2\u503c\u548c\u751f\u6210\uff09\u4e0a\u7684\u6a21\u62df\u5b9e\u9a8c\u8868\u660e\uff0cBVAE\u4e0d\u4ec5\u5c06\u53c2\u6570\u6570\u91cf\u51cf\u5c11\u4e86\u8fd150%\uff0c\u800c\u4e14\u5728\u6027\u80fd\u4e0a\u7565\u5fae\u4f18\u4e8e\u5355\u5411VAE\u3002", "conclusion": "BVAE\u4f5c\u4e3a\u4e00\u79cd\u9ad8\u6548\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u80fd\u591f\u5728\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u7684\u540c\u65f6\u63d0\u5347\u6216\u4fdd\u6301\u6027\u80fd\uff0c\u4e3a\u56fe\u50cf\u5904\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6f5c\u529b\u7684\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2505.16713", "pdf": "https://arxiv.org/pdf/2505.16713", "abs": "https://arxiv.org/abs/2505.16713", "authors": ["Shogo Nakakita"], "title": "Sharp concentration of uniform generalization errors in binary linear classification", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": "26 pages, 1 figure", "summary": "We examine the concentration of uniform generalization errors around their\nexpectation in binary linear classification problems via an isoperimetric\nargument. In particular, we establish Poincar\\'{e} and log-Sobolev inequalities\nfor the joint distribution of the output labels and the label-weighted input\nvectors, which we apply to derive concentration bounds. The derived\nconcentration bounds are sharp up to moderate multiplicative constants by those\nunder well-balanced labels. In asymptotic analysis, we also show that almost\nsure convergence of uniform generalization errors to their expectation occurs\nin very broad settings, such as proportionally high-dimensional regimes. Using\nthis convergence, we establish uniform laws of large numbers under\ndimension-free conditions.", "AI": {"tldr": "\u901a\u8fc7\u7b49\u5468\u8bba\u8bc1\uff0c\u7814\u7a76\u4e8c\u5143\u7ebf\u6027\u5206\u7c7b\u95ee\u9898\u4e2d\u6cdb\u5316\u8bef\u5dee\u7684\u96c6\u4e2d\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u5728\u975e\u5e38\u5e7f\u6cdb\u7684\u8bbe\u5b9a\u4e0b\uff0c\u4e00\u81f4\u6cdb\u5316\u8bef\u5dee\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u5230\u5176\u671f\u671b\u503c\u3002", "motivation": "\u5206\u6790\u4e8c\u5143\u7ebf\u6027\u5206\u7c7b\u95ee\u9898\u4e2d\u6cdb\u5316\u8bef\u5dee\u56f4\u7ed5\u5176\u671f\u671b\u503c\u7684\u96c6\u4e2d\u6027\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u6a21\u578b\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u4f7f\u7528Poincar\u00e9\u548clog-Sobolev\u4e0d\u7b49\u5f0f\u6765\u5efa\u7acb\u8f93\u51fa\u6807\u7b7e\u548c\u52a0\u6743\u8f93\u5165\u5411\u91cf\u8054\u5408\u5206\u5e03\u7684\u96c6\u4e2d\u6027\u8fb9\u754c\uff0c\u5e76\u8fdb\u884c\u6e10\u8fd1\u5206\u6790\u4ee5\u8bc1\u660e\u4e00\u81f4\u6cdb\u5316\u8bef\u5dee\u7684\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u3002", "result": "\u5f97\u5230\u4e86\u4e0e\u5e73\u8861\u6807\u7b7e\u60c5\u51b5\u4e0b\u7684\u96c6\u4e2d\u6027\u8fb9\u754c\u76f8\u5dee\u4ec5\u9002\u5ea6\u5e38\u6570\u7684\u7ed3\u679c\uff0c\u5e76\u8bc1\u660e\u4e86\u4e00\u81f4\u6cdb\u5316\u8bef\u5dee\u5728\u5e7f\u6cdb\u8bbe\u5b9a\u4e0b\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u5230\u5176\u671f\u671b\u503c\u3002", "conclusion": "\u4e00\u81f4\u5927\u6570\u5b9a\u5f8b\u53ef\u4ee5\u5728\u65e0\u7ef4\u5ea6\u9650\u5236\u6761\u4ef6\u4e0b\u6210\u7acb\uff0c\u8fd9\u4e3a\u9ad8\u7ef4\u6570\u636e\u573a\u666f\u4e0b\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2505.16114", "pdf": "https://arxiv.org/pdf/2505.16114", "abs": "https://arxiv.org/abs/2505.16114", "authors": ["Naiqi Li", "Peiyuan Liu", "Zheng Liu", "Tao Dai", "Yong Jiang", "Shu-Tao Xia"], "title": "Logic-of-Thought: Empowering Large Language Models with Logic Programs for Solving Puzzles in Natural Language", "categories": ["cs.AI"], "comment": null, "summary": "Solving puzzles in natural language poses a long-standing challenge in AI.\nWhile large language models (LLMs) have recently shown impressive capabilities\nin a variety of tasks, they continue to struggle with complex puzzles that\ndemand precise reasoning and exhaustive search. In this paper, we propose\nLogic-of-Thought (Logot), a novel framework that bridges LLMs with logic\nprogramming to address this problem. Our method leverages LLMs to translate\npuzzle rules and states into answer set programs (ASPs), the solution of which\nare then accurately and efficiently inferred by an ASP interpreter. This hybrid\napproach combines the natural language understanding of LLMs with the precise\nreasoning capabilities of logic programs. We evaluate our method on various\ngrid puzzles and dynamic puzzles involving actions, demonstrating near-perfect\naccuracy across all tasks. Our code and data are available at:\nhttps://github.com/naiqili/Logic-of-Thought.", "AI": {"tldr": "\u4e3a\u4e86\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u4e2d\u7684\u590d\u6742\u8c1c\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86Logic-of-Thought\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u903b\u8f91\u7f16\u7a0b\uff0c\u5c06\u8c1c\u9898\u89c4\u5219\u8f6c\u5316\u4e3a\u53ef\u7cbe\u786e\u6c42\u89e3\u7684\u7a0b\u5e8f\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u8c1c\u9898\u4e0a\u63a5\u8fd1\u5b8c\u7f8e\u51c6\u786e\u7387\u3002", "motivation": "\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u4e2d\u7684\u590d\u6742\u8c1c\u9898\u662fAI\u9886\u57df\u957f\u671f\u5b58\u5728\u7684\u6311\u6218\uff0c\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bb8\u591a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u9700\u8981\u7cbe\u786e\u63a8\u7406\u548c\u7a77\u4e3e\u641c\u7d22\u7684\u590d\u6742\u8c1c\u9898\u4e0a\u4ecd\u7136\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faLogic-of-Thought\uff08Logot\uff09\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5c06\u8c1c\u9898\u89c4\u5219\u548c\u72b6\u6001\u7ffb\u8bd1\u6210\u7b54\u6848\u96c6\u7a0b\u5e8f\uff08ASP\uff09\uff0c\u7136\u540e\u7531ASP\u89e3\u91ca\u5668\u51c6\u786e\u9ad8\u6548\u5730\u63a8\u65ad\u89e3\u51b3\u65b9\u6848\u3002\u8fd9\u79cd\u65b9\u6cd5\u7ed3\u5408\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u903b\u8f91\u7a0b\u5e8f\u7684\u7cbe\u786e\u63a8\u7406\u80fd\u529b\u3002", "result": "\u5728\u5404\u79cd\u7f51\u683c\u8c1c\u9898\u548c\u6d89\u53ca\u52a8\u4f5c\u7684\u52a8\u6001\u8c1c\u9898\u4e0a\u8bc4\u4f30\u8be5\u65b9\u6cd5\uff0c\u7ed3\u679c\u663e\u793a\u5728\u6240\u6709\u4efb\u52a1\u4e2d\u51e0\u4e4e\u8fbe\u5230\u5b8c\u7f8e\u51c6\u786e\u5ea6\u3002", "conclusion": "Logic-of-Thought\u6846\u67b6\u6210\u529f\u5730\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u903b\u8f91\u7f16\u7a0b\u7ed3\u5408\u8d77\u6765\uff0c\u89e3\u51b3\u4e86\u9700\u8981\u7cbe\u786e\u63a8\u7406\u7684\u590d\u6742\u8c1c\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u5c55\u73b0\u4e86\u4f18\u5f02\u7684\u8868\u73b0\u3002"}}
{"id": "2505.16077", "pdf": "https://arxiv.org/pdf/2505.16077", "abs": "https://arxiv.org/abs/2505.16077", "authors": ["Soham Gadgil", "Chris Lin", "Su-In Lee"], "title": "Ensembling Sparse Autoencoders", "categories": ["cs.LG"], "comment": "Preprint", "summary": "Sparse autoencoders (SAEs) are used to decompose neural network activations\ninto human-interpretable features. Typically, features learned by a single SAE\nare used for downstream applications. However, it has recently been shown that\nSAEs trained with different initial weights can learn different features,\ndemonstrating that a single SAE captures only a limited subset of features that\ncan be extracted from the activation space. Motivated by this limitation, we\npropose to ensemble multiple SAEs through naive bagging and boosting.\nSpecifically, SAEs trained with different weight initializations are ensembled\nin naive bagging, whereas SAEs sequentially trained to minimize the residual\nerror are ensembled in boosting. We evaluate our ensemble approaches with three\nsettings of language models and SAE architectures. Our empirical results\ndemonstrate that ensembling SAEs can improve the reconstruction of language\nmodel activations, diversity of features, and SAE stability. Furthermore,\nensembling SAEs performs better than applying a single SAE on downstream tasks\nsuch as concept detection and spurious correlation removal, showing improved\npractical utility.", "AI": {"tldr": "\u7a00\u758f\u81ea\u7f16\u7801\u5668(SAEs)\u901a\u5e38\u7528\u4e8e\u5c06\u795e\u7ecf\u7f51\u7edc\u6fc0\u6d3b\u5206\u89e3\u4e3a\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u7279\u5f81\uff0c\u4f46\u5355\u4e2aSAE\u53ea\u80fd\u6355\u83b7\u6709\u9650\u7684\u7279\u5f81\u5b50\u96c6\u3002\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u6734\u7d20\u88c5\u888b\u548c\u63d0\u5347\u65b9\u6cd5\u96c6\u6210\u591a\u4e2aSAEs\u4ee5\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u5e76\u5728\u4e09\u4e2a\u8bed\u8a00\u6a21\u578b\u548cSAE\u67b6\u6784\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\uff0c\u96c6\u6210SAEs\u53ef\u4ee5\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u6fc0\u6d3b\u7684\u91cd\u5efa\u3001\u7279\u5f81\u591a\u6837\u6027\u3001SAE\u7a33\u5b9a\u6027\u4ee5\u53ca\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u6548\u7528\u3002", "motivation": "\u7814\u7a76\u8868\u660e\uff0c\u4f7f\u7528\u4e0d\u540c\u521d\u59cb\u6743\u91cd\u8bad\u7ec3\u7684SAEs\u53ef\u4ee5\u5b66\u4e60\u5230\u4e0d\u540c\u7684\u7279\u5f81\uff0c\u8fd9\u610f\u5473\u7740\u5355\u4e2aSAE\u53ea\u80fd\u63d0\u53d6\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u6709\u9650\u7684\u7279\u5f81\u5b50\u96c6\u3002", "method": "\u63d0\u51fa\u901a\u8fc7\u6734\u7d20\u88c5\u888b\uff08\u5bf9\u5177\u6709\u4e0d\u540c\u6743\u91cd\u521d\u59cb\u5316\u7684SAEs\u8fdb\u884c\u96c6\u6210\uff09\u548c\u63d0\u5347\uff08\u4f9d\u6b21\u8bad\u7ec3SAEs\u4ee5\u6700\u5c0f\u5316\u6b8b\u5dee\u8bef\u5dee\uff09\u65b9\u6cd5\u96c6\u6210\u591a\u4e2aSAEs\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u96c6\u6210SAEs\u53ef\u4ee5\u6539\u5584\u8bed\u8a00\u6a21\u578b\u6fc0\u6d3b\u7684\u91cd\u5efa\u3001\u7279\u5f81\u591a\u6837\u6027\u548cSAE\u7a33\u5b9a\u6027\uff0c\u5e76\u4e14\u5728\u8bf8\u5982\u6982\u5ff5\u68c0\u6d4b\u548c\u865a\u5047\u76f8\u5173\u6027\u53bb\u9664\u7b49\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5355\u4e2aSAE\u3002", "conclusion": "\u96c6\u6210\u591a\u4e2aSAEs\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u3001\u6a21\u578b\u7a33\u5b9a\u6027\u548c\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u5b9e\u9645\u6548\u7528\u3002"}}
{"id": "2505.16879", "pdf": "https://arxiv.org/pdf/2505.16879", "abs": "https://arxiv.org/abs/2505.16879", "authors": ["Hannah Sansford", "Nick Whiteley", "Patrick Rubin-Delanchy"], "title": "How high is `high'? Rethinking the roles of dimensionality in topological data analysis and manifold learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We present a generalised Hanson-Wright inequality and use it to establish new\nstatistical insights into the geometry of data point-clouds. In the setting of\na general random function model of data, we clarify the roles played by three\nnotions of dimensionality: ambient intrinsic dimension $p_{\\mathrm{int}}$,\nwhich measures total variability across orthogonal feature directions;\ncorrelation rank, which measures functional complexity across samples; and\nlatent intrinsic dimension, which is the dimension of manifold structure hidden\nin data. Our analysis shows that in order for persistence diagrams to reveal\nlatent homology and for manifold structure to emerge it is sufficient that\n$p_{\\mathrm{int}}\\gg \\log n$, where $n$ is the sample size. Informed by these\ntheoretical perspectives, we revisit the ground-breaking neuroscience discovery\nof toroidal structure in grid-cell activity made by Gardner et al. (Nature,\n2022): our findings reveal, for the first time, evidence that this structure is\nin fact isometric to physical space, meaning that grid cell activity conveys a\ngeometrically faithful representation of the real world.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5e7f\u4e49\u7684Hanson-Wright\u4e0d\u7b49\u5f0f\uff0c\u5e76\u5229\u7528\u5176\u63ed\u793a\u4e86\u6570\u636e\u70b9\u4e91\u51e0\u4f55\u7684\u65b0\u7edf\u8ba1\u89c1\u89e3\u3002\u7814\u7a76\u63a2\u8ba8\u4e86\u4e09\u79cd\u7ef4\u5ea6\u6982\u5ff5\uff1a\u73af\u5883\u5185\u5728\u7ef4\u5ea6\u3001\u76f8\u5173\u6027\u79e9\u548c\u6f5c\u5728\u5185\u5728\u7ef4\u5ea6\uff0c\u5e76\u53d1\u73b0\u5f53\u5185\u5728\u7ef4\u5ea6\u8fdc\u5927\u4e8e\u6837\u672c\u91cf\u7684\u5bf9\u6570\u65f6\uff0c\u6301\u4e45\u6027\u56fe\u53ef\u4ee5\u63ed\u793a\u6f5c\u5728\u7684\u540c\u6e90\u6027\u548c\u6d41\u5f62\u7ed3\u6784\u3002\u57fa\u4e8e\u6b64\u7406\u8bba\uff0c\u6587\u7ae0\u91cd\u65b0\u5ba1\u89c6\u4e86Gardner\u7b49\u4eba\u5173\u4e8e\u7f51\u683c\u7ec6\u80de\u6d3b\u52a8\u4e2d\u7684\u73af\u9762\u7ed3\u6784\u7684\u795e\u7ecf\u79d1\u5b66\u53d1\u73b0\uff0c\u9996\u6b21\u8bc1\u660e\u8be5\u7ed3\u6784\u4e0e\u7269\u7406\u7a7a\u95f4\u7b49\u8ddd\uff0c\u8868\u660e\u7f51\u683c\u7ec6\u80de\u6d3b\u52a8\u80fd\u591f\u5fe0\u5b9e\u8868\u793a\u73b0\u5b9e\u4e16\u754c\u3002", "motivation": "\u901a\u8fc7\u5f15\u5165\u5e7f\u4e49Hanson-Wright\u4e0d\u7b49\u5f0f\uff0c\u7814\u7a76\u6570\u636e\u70b9\u4e91\u7684\u51e0\u4f55\u7279\u6027\u4ee5\u53ca\u4e0d\u540c\u7ef4\u5ea6\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u7406\u89e3\u6570\u636e\u4e2d\u9690\u85cf\u7684\u6d41\u5f62\u7ed3\u6784\u53ca\u62d3\u6251\u7279\u5f81\u3002", "method": "\u4f7f\u7528\u5e7f\u4e49Hanson-Wright\u4e0d\u7b49\u5f0f\u5206\u6790\u6570\u636e\u6a21\u578b\u4e2d\u7684\u4e09\u79cd\u7ef4\u5ea6\u6982\u5ff5\uff1a\u73af\u5883\u5185\u5728\u7ef4\u5ea6\u3001\u76f8\u5173\u6027\u79e9\u548c\u6f5c\u5728\u5185\u5728\u7ef4\u5ea6\uff0c\u5e76\u63a2\u8ba8\u8fd9\u4e9b\u7ef4\u5ea6\u5982\u4f55\u5f71\u54cd\u6301\u4e45\u6027\u56fe\u63ed\u793a\u6f5c\u5728\u540c\u6e90\u6027\u548c\u6d41\u5f62\u7ed3\u6784\u7684\u80fd\u529b\u3002", "result": "\u53d1\u73b0\u4e86\u5f53\u5185\u5728\u7ef4\u5ea6\u8fdc\u5927\u4e8e\u6837\u672c\u91cf\u5bf9\u6570\u65f6\uff0c\u6301\u4e45\u6027\u56fe\u53ef\u4ee5\u6709\u6548\u63ed\u793a\u6f5c\u5728\u540c\u6e90\u6027\u548c\u6d41\u5f62\u7ed3\u6784\uff1b\u91cd\u65b0\u5206\u6790\u4e86\u7f51\u683c\u7ec6\u80de\u6d3b\u52a8\u4e2d\u7684\u73af\u9762\u7ed3\u6784\uff0c\u8bc1\u660e\u5176\u4e0e\u7269\u7406\u7a7a\u95f4\u7b49\u8ddd\u3002", "conclusion": "\u63d0\u51fa\u4e86\u65b0\u7684\u7edf\u8ba1\u65b9\u6cd5\u6765\u7406\u89e3\u6570\u636e\u70b9\u4e91\u7684\u51e0\u4f55\u7279\u6027\uff0c\u8bc1\u5b9e\u4e86\u7f51\u683c\u7ec6\u80de\u6d3b\u52a8\u80fd\u591f\u5fe0\u5b9e\u5730\u53cd\u6620\u73b0\u5b9e\u4e16\u754c\u7684\u51e0\u4f55\u7ed3\u6784\u3002"}}
{"id": "2505.16120", "pdf": "https://arxiv.org/pdf/2505.16120", "abs": "https://arxiv.org/abs/2505.16120", "authors": ["Guannan Liang", "Qianqian Tong"], "title": "LLM-Powered AI Agent Systems and Their Applications in Industry", "categories": ["cs.AI"], "comment": "This is the author's accepted version of the paper accepted to appear\n  at IEEE AIIoT 2025. The final version will be available via IEEE Xplore.\n  \\c{opyright}2025 IEEE. Personal use of this material is permitted", "summary": "The emergence of Large Language Models (LLMs) has reshaped agent systems.\nUnlike traditional rule-based agents with limited task scope, LLM-powered\nagents offer greater flexibility, cross-domain reasoning, and natural language\ninteraction. Moreover, with the integration of multi-modal LLMs, current agent\nsystems are highly capable of processing diverse data modalities, including\ntext, images, audio, and structured tabular data, enabling richer and more\nadaptive real-world behavior. This paper comprehensively examines the evolution\nof agent systems from the pre-LLM era to current LLM-powered architectures. We\ncategorize agent systems into software-based, physical, and adaptive hybrid\nsystems, highlighting applications across customer service, software\ndevelopment, manufacturing automation, personalized education, financial\ntrading, and healthcare. We further discuss the primary challenges posed by\nLLM-powered agents, including high inference latency, output uncertainty, lack\nof evaluation metrics, and security vulnerabilities, and propose potential\nsolutions to mitigate these concerns.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u91cd\u5851\u4e86\u4ee3\u7406\u7cfb\u7edf\uff0c\u4f7f\u5176\u66f4\u7075\u6d3b\u3001\u8de8\u57df\u63a8\u7406\u80fd\u529b\u5f3a\u4e14\u80fd\u8fdb\u884c\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u3002\u591a\u6a21\u6001LLM\u96c6\u6210\u540e\uff0c\u5f53\u524d\u4ee3\u7406\u7cfb\u7edf\u80fd\u591f\u5904\u7406\u591a\u79cd\u6570\u636e\u7c7b\u578b\u3002\u672c\u6587\u56de\u987e\u4e86\u4ece\u9884LLM\u65f6\u4ee3\u5230\u73b0\u4eca\u7684\u67b6\u6784\u6f14\u53d8\uff0c\u5e76\u5206\u7c7b\u63a2\u8ba8\u4e86\u5176\u5728\u591a\u4e2a\u9886\u57df\u7684\u5e94\u7528\uff0c\u540c\u65f6\u6307\u51fa\u4e86\u9762\u4e34\u7684\u6311\u6218\u53ca\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5982\u4f55\u6539\u53d8\u4ee3\u7406\u7cfb\u7edf\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u65b0\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u548c\u9650\u5236\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u6848\u4f8b\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u5bf9\u4ee3\u7406\u7cfb\u7edf\u7684\u6f14\u8fdb\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u5e76\u6309\u8f6f\u4ef6\u3001\u7269\u7406\u548c\u81ea\u9002\u5e94\u6df7\u5408\u7cfb\u7edf\u5206\u7c7b\u8ba8\u8bba\u4e86\u5176\u5e94\u7528\u3002", "result": "\u53d1\u73b0LLM\u9a71\u52a8\u7684\u4ee3\u7406\u7cfb\u7edf\u5728\u7075\u6d3b\u6027\u3001\u8de8\u57df\u63a8\u7406\u548c\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\uff0c\u4f46\u4e5f\u5b58\u5728\u8bf8\u5982\u9ad8\u63a8\u7406\u5ef6\u8fdf\u3001\u8f93\u51fa\u4e0d\u786e\u5b9a\u6027\u7b49\u6311\u6218\u3002", "conclusion": "LLM\u9a71\u52a8\u7684\u4ee3\u7406\u7cfb\u7edf\u5177\u6709\u5de8\u5927\u7684\u6f5c\u529b\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u6280\u672f\u6311\u6218\u4ee5\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u548c\u5b89\u5168\u7684\u5e94\u7528\u3002"}}
{"id": "2505.16083", "pdf": "https://arxiv.org/pdf/2505.16083", "abs": "https://arxiv.org/abs/2505.16083", "authors": ["Jiahuan Long", "Wenzhe Zhang", "Ning Wang", "Tingsong Jiang", "Wen Yao"], "title": "FR-Mamba: Time-Series Physical Field Reconstruction Based on State Space Model", "categories": ["cs.LG"], "comment": null, "summary": "Physical field reconstruction (PFR) aims to predict the state distribution of\nphysical quantities (e.g., velocity, pressure, and temperature) based on\nlimited sensor measurements. It plays a critical role in domains such as fluid\ndynamics and thermodynamics. However, existing deep learning methods often fail\nto capture long-range temporal dependencies, resulting in suboptimal\nperformance on time-evolving physical systems. To address this, we propose\nFR-Mamba, a novel spatiotemporal flow field reconstruction framework based on\nstate space modeling. Specifically, we design a hybrid neural network\narchitecture that combines Fourier Neural Operator (FNO) and State Space Model\n(SSM) to capture both global spatial features and long-range temporal\ndependencies. We adopt Mamba, a recently proposed efficient SSM architecture,\nto model long-range temporal dependencies with linear time complexity. In\nparallel, the FNO is employed to capture non-local spatial features by\nleveraging frequency-domain transformations. The spatiotemporal representations\nextracted by these two components are then fused to reconstruct the full-field\ndistribution of the physical system. Extensive experiments demonstrate that our\napproach significantly outperforms existing PFR methods in flow field\nreconstruction tasks, achieving high-accuracy performance on long sequences.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7269\u7406\u573a\u91cd\u5efa\u6846\u67b6FR-Mamba\uff0c\u7ed3\u5408\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50(FNO)\u548c\u72b6\u6001\u7a7a\u95f4\u6a21\u578b(SSM)\uff0c\u80fd\u591f\u6709\u6548\u6355\u6349\u957f\u65f6\u95f4\u5e8f\u5217\u7684\u65f6\u7a7a\u7279\u5f81\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5728\u7269\u7406\u573a\u91cd\u5efa\u4e2d\u96be\u4ee5\u6355\u6349\u957f\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u5bfc\u81f4\u5bf9\u65f6\u95f4\u6f14\u53d8\u7269\u7406\u7cfb\u7edf\u7684\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6df7\u5408\u795e\u7ecf\u7f51\u7edc\u67b6\u6784FR-Mamba\uff0c\u5c06\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50(FNO)\u4e0e\u72b6\u6001\u7a7a\u95f4\u6a21\u578b(SSM)\u76f8\u7ed3\u5408\u3002\u5176\u4e2d\uff0c\u4f7f\u7528Mamba\u6765\u5efa\u6a21\u957f\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u5e76\u901a\u8fc7\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\uff1bFNO\u5219\u7528\u4e8e\u6355\u6349\u975e\u5c40\u90e8\u7a7a\u95f4\u7279\u5f81\u3002\u6700\u540e\u878d\u5408\u4e24\u90e8\u5206\u63d0\u53d6\u7684\u65f6\u7a7a\u8868\u793a\u4ee5\u91cd\u5efa\u5168\u573a\u5206\u5e03\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6d41\u573a\u91cd\u5efa\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684PFR\u65b9\u6cd5\uff0c\u5728\u957f\u5e8f\u5217\u4e0a\u8868\u73b0\u51fa\u9ad8\u7cbe\u5ea6\u6027\u80fd\u3002", "conclusion": "FR-Mamba\u6846\u67b6\u901a\u8fc7\u7ed3\u5408FNO\u548cSSM\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u6355\u6349\u957f\u65f6\u95f4\u4f9d\u8d56\u6027\u7684\u95ee\u9898\uff0c\u4e3a\u7269\u7406\u573a\u91cd\u5efa\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.16893", "pdf": "https://arxiv.org/pdf/2505.16893", "abs": "https://arxiv.org/abs/2505.16893", "authors": ["Shuichi Nishino", "Tomohiro Shiraishi", "Teruyuki Katsuoka", "Ichiro Takeuchi"], "title": "Statistical Test for Saliency Maps of Graph Neural Networks via Selective Inference", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have gained prominence for their ability to\nprocess graph-structured data across various domains. However, interpreting GNN\ndecisions remains a significant challenge, leading to the adoption of saliency\nmaps for identifying influential nodes and edges. Despite their utility, the\nreliability of GNN saliency maps has been questioned, particularly in terms of\ntheir robustness to noise. In this study, we propose a statistical testing\nframework to rigorously evaluate the significance of saliency maps. Our main\ncontribution lies in addressing the inflation of the Type I error rate caused\nby double-dipping of data, leveraging the framework of Selective Inference. Our\nmethod provides statistically valid $p$-values while controlling the Type I\nerror rate, ensuring that identified salient subgraphs contain meaningful\ninformation rather than random artifacts. To demonstrate the effectiveness of\nour method, we conduct experiments on both synthetic and real-world datasets,\nshowing its effectiveness in assessing the reliability of GNN interpretations.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u8ba1\u6d4b\u8bd5\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u663e\u8457\u6027\u6620\u5c04\u7684\u53ef\u9760\u6027\uff0c\u89e3\u51b3\u4e86\u6570\u636e\u53cc\u91cd\u5229\u7528\u5bfc\u81f4\u7684\u7b2c\u4e00\u7c7b\u9519\u8bef\u7387\u81a8\u80c0\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u89e3\u91caGNN\u51b3\u7b56\u65f6\uff0c\u73b0\u6709\u7684\u663e\u8457\u6027\u6620\u5c04\u5728\u9762\u5bf9\u566a\u58f0\u65f6\u7684\u9c81\u68d2\u6027\u4e0d\u8db3\uff0c\u4e14\u5176\u53ef\u9760\u6027\u53d7\u5230\u8d28\u7591\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u9009\u62e9\u6027\u63a8\u65ad\u7684\u7edf\u8ba1\u6d4b\u8bd5\u6846\u67b6\uff0c\u4ee5\u4e25\u683c\u8bc4\u4f30\u663e\u8457\u6027\u6620\u5c04\u7684\u91cd\u8981\u6027\uff0c\u540c\u65f6\u63d0\u4f9b\u6709\u6548\u7684p\u503c\u5e76\u63a7\u5236\u7b2c\u4e00\u7c7b\u9519\u8bef\u7387\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5747\u80fd\u6709\u6548\u8bc4\u4f30GNN\u89e3\u91ca\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u786e\u4fdd\u8bc6\u522b\u51fa\u7684\u663e\u8457\u5b50\u56fe\u5305\u542b\u6709\u610f\u4e49\u7684\u4fe1\u606f\u800c\u975e\u968f\u673a\u4f2a\u5f71\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86GNN\u89e3\u91ca\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2505.16135", "pdf": "https://arxiv.org/pdf/2505.16135", "abs": "https://arxiv.org/abs/2505.16135", "authors": ["Jeffrey Seely", "Yuki Imajuku", "Tianyu Zhao", "Edoardo Cetin", "Llion Jones"], "title": "Sudoku-Bench: Evaluating creative reasoning with Sudoku variants", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Existing reasoning benchmarks for large language models (LLMs) frequently\nfail to capture authentic creativity, often rewarding memorization of\npreviously observed patterns. We address this shortcoming with Sudoku-Bench, a\ncurated benchmark of challenging and unconventional Sudoku variants\nspecifically selected to evaluate creative, multi-step logical reasoning.\nSudoku variants form an unusually effective domain for reasoning research: each\npuzzle introduces unique or subtly interacting constraints, making memorization\ninfeasible and requiring solvers to identify novel logical breakthroughs\n(``break-ins''). Despite their diversity, Sudoku variants maintain a common and\ncompact structure, enabling clear and consistent evaluation. Sudoku-Bench\nincludes a carefully chosen puzzle set, a standardized text-based puzzle\nrepresentation, and flexible tools compatible with thousands of publicly\navailable puzzles -- making it easy to extend into a general research\nenvironment. Baseline experiments show that state-of-the-art LLMs solve fewer\nthan 15\\% of puzzles unaided, highlighting significant opportunities to advance\nlong-horizon, strategic reasoning capabilities.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u73b0\u6709\u7684\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u771f\u5b9e\u7684\u521b\u9020\u529b\uff0c\u5e38\u5e38\u5956\u52b1\u5bf9\u5148\u524d\u89c2\u5bdf\u5230\u7684\u6a21\u5f0f\u7684\u8bb0\u5fc6\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u4e0d\u8db3\uff0c\u6211\u4eec\u63d0\u51fa\u4e86Sudoku-Bench\uff0c\u8fd9\u662f\u4e00\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684\u3001\u5177\u6709\u6311\u6218\u6027\u548c\u975e\u4f20\u7edf\u6570\u72ec\u53d8\u4f53\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u521b\u9020\u6027\u7684\u3001\u591a\u6b65\u9aa4\u7684\u903b\u8f91\u63a8\u7406\u80fd\u529b\u3002\u6570\u72ec\u53d8\u4f53\u6784\u6210\u4e86\u4e00\u4e2a\u5f02\u5e38\u6709\u6548\u7684\u63a8\u7406\u7814\u7a76\u9886\u57df\uff1a\u6bcf\u4e2a\u8c1c\u9898\u5f15\u5165\u72ec\u7279\u7684\u6216\u5fae\u5999\u4ea4\u4e92\u7684\u7ea6\u675f\u6761\u4ef6\uff0c\u4f7f\u5f97\u8bb0\u5fc6\u53d8\u5f97\u4e0d\u53ef\u884c\uff0c\u5e76\u8981\u6c42\u89e3\u9898\u8005\u8bc6\u522b\u51fa\u65b0\u7684\u903b\u8f91\u7a81\u7834\u70b9\uff08\u201c\u7a81\u7834\u53e3\u201d\uff09\u3002\u5c3d\u7ba1\u6570\u72ec\u53d8\u4f53\u79cd\u7c7b\u7e41\u591a\uff0c\u4f46\u5b83\u4eec\u4fdd\u6301\u4e86\u4e00\u79cd\u5171\u540c\u4e14\u7d27\u51d1\u7684\u7ed3\u6784\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u6e05\u6670\u548c\u4e00\u81f4\u7684\u8bc4\u4f30\u3002Sudoku-Bench\u5305\u62ec\u7cbe\u5fc3\u6311\u9009\u7684\u8c1c\u9898\u96c6\u3001\u6807\u51c6\u5316\u7684\u57fa\u4e8e\u6587\u672c\u7684\u8c1c\u9898\u8868\u793a\u5f62\u5f0f\u4ee5\u53ca\u4e0e\u6570\u5343\u4e2a\u516c\u5f00\u53ef\u7528\u7684\u8c1c\u9898\u517c\u5bb9\u7684\u7075\u6d3b\u5de5\u5177\u2014\u2014\u4f7f\u5176\u6613\u4e8e\u6269\u5c55\u4e3a\u4e00\u4e2a\u901a\u7528\u7684\u7814\u7a76\u73af\u5883\u3002\u57fa\u7ebf\u5b9e\u9a8c\u8868\u660e\uff0c\u6700\u5148\u8fdb\u7684LLMs\u5728\u6ca1\u6709\u5e2e\u52a9\u7684\u60c5\u51b5\u4e0b\u89e3\u51b3\u7684\u8c1c\u9898\u4e0d\u523015%\uff0c\u7a81\u663e\u4e86\u63a8\u8fdb\u957f\u65f6\u7a0b\u3001\u6218\u7565\u6027\u63a8\u7406\u80fd\u529b\u7684\u91cd\u5927\u673a\u9047\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u57fa\u51c6\u672a\u80fd\u6709\u6548\u6355\u6349\u771f\u5b9e\u521b\u9020\u529b\uff0c\u901a\u5e38\u5956\u52b1\u5bf9\u5df2\u6709\u6a21\u5f0f\u7684\u8bb0\u5fc6\u3002\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u80fd\u66f4\u597d\u8bc4\u4f30\u521b\u9020\u6027\u3001\u591a\u6b65\u9aa4\u903b\u8f91\u63a8\u7406\u7684\u65b0\u57fa\u51c6\u3002", "method": "\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aSudoku-Bench\u7684\u65b0\u57fa\u51c6\uff0c\u5305\u542b\u4e00\u7cfb\u5217\u6311\u6218\u6027\u9ad8\u4e14\u4e0d\u5bfb\u5e38\u7684\u6570\u72ec\u53d8\u4f53\u3002\u8fd9\u4e9b\u6570\u72ec\u53d8\u4f53\u5177\u6709\u72ec\u7279\u6216\u76f8\u4e92\u4f5c\u7528\u7684\u7ea6\u675f\u6761\u4ef6\uff0c\u96be\u4ee5\u901a\u8fc7\u8bb0\u5fc6\u89e3\u51b3\uff0c\u9700\u8981\u53d1\u73b0\u65b0\u7684\u903b\u8f91\u7a81\u7834\u53e3\u3002\u8be5\u57fa\u51c6\u8fd8\u5305\u62ec\u7cbe\u9009\u7684\u8c1c\u9898\u96c6\u3001\u6807\u51c6\u7684\u57fa\u4e8e\u6587\u672c\u7684\u8c1c\u9898\u8868\u793a\u65b9\u6cd5\u53ca\u4e0e\u5927\u91cf\u516c\u5f00\u8c1c\u9898\u517c\u5bb9\u7684\u7075\u6d3b\u5de5\u5177\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u6700\u5148\u8fdb\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u65e0\u8f85\u52a9\u60c5\u51b5\u4e0b\u53ea\u80fd\u89e3\u51b3\u4e0d\u523015%\u7684\u6570\u72ec\u8c1c\u9898\uff0c\u8868\u660e\u5728\u957f\u65f6\u7a0b\u6218\u7565\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5b58\u5728\u663e\u8457\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "Sudoku-Bench\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u5e73\u53f0\u6765\u8bc4\u4f30\u548c\u63a8\u52a8\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u521b\u9020\u6027\u63a8\u7406\u80fd\u529b\uff0c\u672a\u6765\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u8fd9\u4e9b\u6a21\u578b\u7684\u6218\u7565\u63a8\u7406\u6c34\u5e73\u3002"}}
{"id": "2505.16094", "pdf": "https://arxiv.org/pdf/2505.16094", "abs": "https://arxiv.org/abs/2505.16094", "authors": ["Ziqing Wang", "Kexin Zhang", "Zihan Zhao", "Yibo Wen", "Abhishek Pandey", "Han Liu", "Kaize Ding"], "title": "A Survey of Large Language Models for Text-Guided Molecular Discovery: from Molecule Generation to Optimization", "categories": ["cs.LG", "cs.CL"], "comment": "Under review", "summary": "Large language models (LLMs) are introducing a paradigm shift in molecular\ndiscovery by enabling text-guided interaction with chemical spaces through\nnatural language, symbolic notations, with emerging extensions to incorporate\nmulti-modal inputs. To advance the new field of LLM for molecular discovery,\nthis survey provides an up-to-date and forward-looking review of the emerging\nuse of LLMs for two central tasks: molecule generation and molecule\noptimization. Based on our proposed taxonomy for both problems, we analyze\nrepresentative techniques in each category, highlighting how LLM capabilities\nare leveraged across different learning settings. In addition, we include the\ncommonly used datasets and evaluation protocols. We conclude by discussing key\nchallenges and future directions, positioning this survey as a resource for\nresearchers working at the intersection of LLMs and molecular science. A\ncontinuously updated reading list is available at\nhttps://github.com/REAL-Lab-NU/Awesome-LLM-Centric-Molecular-Discovery.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6b63\u5728\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u548c\u7b26\u53f7\u7b26\u53f7\u4e0e\u5316\u5b66\u7a7a\u95f4\u8fdb\u884c\u6587\u672c\u5f15\u5bfc\u7684\u4ea4\u4e92\uff0c\u5f15\u5165\u5206\u5b50\u53d1\u73b0\u9886\u57df\u7684\u8303\u5f0f\u8f6c\u53d8\u3002\u672c\u6587\u7efc\u8ff0\u4e86LLM\u5728\u5206\u5b50\u751f\u6210\u548c\u4f18\u5316\u4e24\u4e2a\u6838\u5fc3\u4efb\u52a1\u4e2d\u7684\u65b0\u5174\u5e94\u7528\uff0c\u5e76\u63d0\u4f9b\u4e86\u6700\u65b0\u548c\u524d\u77bb\u6027\u7684\u8bc4\u8bba\u3002\u57fa\u4e8e\u6211\u4eec\u63d0\u51fa\u7684\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u4e86\u6bcf\u7c7b\u95ee\u9898\u7684\u4ee3\u8868\u6027\u6280\u672f\uff0c\u5f3a\u8c03\u4e86\u5728\u4e0d\u540c\u5b66\u4e60\u8bbe\u7f6e\u4e0b\u5982\u4f55\u5229\u7528LLM\u7684\u80fd\u529b\u3002\u6b64\u5916\uff0c\u8fd8\u5305\u62ec\u5e38\u7528\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u534f\u8bae\uff0c\u8ba8\u8bba\u4e86\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5206\u5b50\u53d1\u73b0\u9886\u57df\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e0e\u5316\u5b66\u7a7a\u95f4\u8fdb\u884c\u4ea4\u4e92\u3002\u4e3a\u4e86\u63a8\u52a8\u8fd9\u4e00\u65b0\u9886\u57df\u7684\u53d1\u5c55\uff0c\u9700\u8981\u5bf9\u73b0\u6709\u6280\u672f\u548c\u65b9\u6cd5\u8fdb\u884c\u5168\u9762\u603b\u7ed3\u548c\u524d\u77bb\u6027\u5206\u6790\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5206\u5b50\u751f\u6210\u548c\u4f18\u5316\u95ee\u9898\u7684\u5206\u7c7b\u6cd5\uff0c\u5206\u6790\u4e86\u5404\u7c7b\u95ee\u9898\u7684\u4ee3\u8868\u6027\u6280\u672f\uff0c\u63a2\u8ba8\u4e86LLM\u80fd\u529b\u5728\u4e0d\u540c\u5b66\u4e60\u8bbe\u7f6e\u4e0b\u7684\u5e94\u7528\uff0c\u5e76\u4ecb\u7ecd\u4e86\u5e38\u7528\u7684\u5206\u5b50\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u534f\u8bae\u3002", "result": "\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u8d44\u6e90\uff0c\u6db5\u76d6\u4e86LLM\u5728\u5206\u5b50\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\u3001\u6311\u6218\u53ca\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "conclusion": "LLM\u5728\u5206\u5b50\u53d1\u73b0\u9886\u57df\u5177\u6709\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f\uff0c\u4f46\u4ecd\u9762\u4e34\u8bb8\u591a\u6311\u6218\u3002\u672a\u6765\u7684\u7814\u7a76\u5e94\u5173\u6ce8\u6a21\u578b\u6027\u80fd\u63d0\u5347\u3001\u591a\u6a21\u6001\u6570\u636e\u6574\u5408\u4ee5\u53ca\u66f4\u9ad8\u6548\u7684\u5206\u5b50\u751f\u6210\u548c\u4f18\u5316\u65b9\u6cd5\u3002"}}
{"id": "2505.16923", "pdf": "https://arxiv.org/pdf/2505.16923", "abs": "https://arxiv.org/abs/2505.16923", "authors": ["Yuhui Zhang", "Dongshen Wu", "Yuichiro Wada", "Takafumi Kanamori"], "title": "TULiP: Test-time Uncertainty Estimation via Linearization and Weight Perturbation", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "A reliable uncertainty estimation method is the foundation of many modern\nout-of-distribution (OOD) detectors, which are critical for safe deployments of\ndeep learning models in the open world. In this work, we propose TULiP, a\ntheoretically-driven post-hoc uncertainty estimator for OOD detection. Our\napproach considers a hypothetical perturbation applied to the network before\nconvergence. Based on linearized training dynamics, we bound the effect of such\nperturbation, resulting in an uncertainty score computable by perturbing model\nparameters. Ultimately, our approach computes uncertainty from a set of sampled\npredictions. We visualize our bound on synthetic regression and classification\ndatasets. Furthermore, we demonstrate the effectiveness of TULiP using\nlarge-scale OOD detection benchmarks for image classification. Our method\nexhibits state-of-the-art performance, particularly for near-distribution\nsamples.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTULiP\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba1\u7b97\u6a21\u578b\u53c2\u6570\u6270\u52a8\u4ea7\u751f\u7684\u4e0d\u786e\u5b9a\u6027\u5206\u6570\u6765\u68c0\u6d4b\u8fd1\u5206\u5e03\u6837\u672c\u548c\u5206\u5e03\u5916\u6837\u672c\u3002", "motivation": "\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\u662f\u73b0\u4ee3\u5206\u5e03\u5916\uff08OOD\uff09\u68c0\u6d4b\u5668\u7684\u57fa\u7840\uff0c\u5bf9\u4e8e\u5728\u5f00\u653e\u4e16\u754c\u4e2d\u5b89\u5168\u90e8\u7f72\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u7406\u8bba\u4e0a\u9a71\u52a8\u7684\u3001\u4e8b\u540e\u53ef\u8ba1\u7b97\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "TULiP\u8003\u8651\u4e86\u5728\u7f51\u7edc\u6536\u655b\u524d\u65bd\u52a0\u7684\u5047\u8bbe\u6027\u6270\u52a8\uff0c\u5e76\u57fa\u4e8e\u7ebf\u6027\u5316\u7684\u8bad\u7ec3\u52a8\u6001\u8fc7\u7a0b\uff0c\u9650\u5236\u8fd9\u79cd\u6270\u52a8\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u901a\u8fc7\u6270\u52a8\u6a21\u578b\u53c2\u6570\u8ba1\u7b97\u51fa\u4e0d\u786e\u5b9a\u6027\u5206\u6570\u3002\u6700\u7ec8\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5bf9\u4e00\u7ec4\u91c7\u6837\u9884\u6d4b\u8fdb\u884c\u8ba1\u7b97\u6765\u5f97\u51fa\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u7814\u7a76\u8005\u5728\u5408\u6210\u56de\u5f52\u548c\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u53ef\u89c6\u5316\u4e86\u5176\u8fb9\u754c\uff0c\u5e76\u4f7f\u7528\u5927\u89c4\u6a21\u56fe\u50cf\u5206\u7c7bOOD\u68c0\u6d4b\u57fa\u51c6\u5c55\u793a\u4e86TULiP\u7684\u6709\u6548\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTULiP\u5728\u8fd1\u5206\u5e03\u6837\u672c\u68c0\u6d4b\u65b9\u9762\u5177\u6709\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "TULiP\u662f\u4e00\u79cd\u7406\u8bba\u4e0a\u9a71\u52a8\u7684\u4e8b\u540e\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u5668\uff0c\u9002\u7528\u4e8eOOD\u68c0\u6d4b\uff0c\u5c24\u5176\u5728\u5904\u7406\u8fd1\u5206\u5e03\u6837\u672c\u65f6\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2505.16147", "pdf": "https://arxiv.org/pdf/2505.16147", "abs": "https://arxiv.org/abs/2505.16147", "authors": ["Le Ma", "Shirao Yang", "Zihao Wang", "Yinggui Wang", "Lei Wang", "Tao Wei", "Kejun Zhang"], "title": "Losing is for Cherishing: Data Valuation Based on Machine Unlearning and Shapley Value", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The proliferation of large models has intensified the need for efficient data\nvaluation methods to quantify the contribution of individual data providers.\nTraditional approaches, such as game-theory-based Shapley value and\ninfluence-function-based techniques, face prohibitive computational costs or\nrequire access to full data and model training details, making them hardly\nachieve partial data valuation. To address this, we propose Unlearning Shapley,\na novel framework that leverages machine unlearning to estimate data values\nefficiently. By unlearning target data from a pretrained model and measuring\nperformance shifts on a reachable test set, our method computes Shapley values\nvia Monte Carlo sampling, avoiding retraining and eliminating dependence on\nfull data. Crucially, Unlearning Shapley supports both full and partial data\nvaluation, making it scalable for large models (e.g., LLMs) and practical for\ndata markets. Experiments on benchmark datasets and large-scale text corpora\ndemonstrate that our approach matches the accuracy of state-of-the-art methods\nwhile reducing computational overhead by orders of magnitude. Further analysis\nconfirms a strong correlation between estimated values and the true impact of\ndata subsets, validating its reliability in real-world scenarios. This work\nbridges the gap between data valuation theory and practical deployment,\noffering a scalable, privacy-compliant solution for modern AI ecosystems.", "AI": {"tldr": "\u63d0\u51fa\u4e86Unlearning Shapley\u6846\u67b6\uff0c\u901a\u8fc7\u673a\u5668\u9057\u5fd8\u6280\u672f\u9ad8\u6548\u4f30\u8ba1\u6570\u636e\u4ef7\u503c\uff0c\u652f\u6301\u90e8\u5206\u548c\u5168\u90e8\u6570\u636e\u4f30\u503c\uff0c\u9002\u7528\u4e8e\u5927\u578b\u6a21\u578b\u548c\u6570\u636e\u5e02\u573a\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u5927\u578b\u6a21\u578b\u7684\u666e\u53ca\u52a0\u5267\u4e86\u5bf9\u9ad8\u6548\u6570\u636e\u4f30\u503c\u65b9\u6cd5\u7684\u9700\u6c42\uff0c\u800c\u4f20\u7edf\u65b9\u6cd5\uff08\u5982\u57fa\u4e8e\u535a\u5f08\u8bba\u7684Shapley\u503c\u6216\u57fa\u4e8e\u5f71\u54cd\u51fd\u6570\u7684\u6280\u672f\uff09\u9762\u4e34\u9ad8\u6602\u7684\u8ba1\u7b97\u6210\u672c\u6216\u9700\u8981\u8bbf\u95ee\u5b8c\u6574\u6570\u636e\u53ca\u6a21\u578b\u8bad\u7ec3\u7ec6\u8282\uff0c\u96be\u4ee5\u5b9e\u73b0\u90e8\u5206\u6570\u636e\u4f30\u503c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aUnlearning Shapley\u7684\u65b0\u6846\u67b6\uff0c\u5229\u7528\u673a\u5668\u9057\u5fd8\u6280\u672f\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u4e2d\u79fb\u9664\u76ee\u6807\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u6d4b\u91cf\u53ef\u8fbe\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6027\u80fd\u53d8\u5316\u6765\u8ba1\u7b97Shapley\u503c\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528Monte Carlo\u91c7\u6837\u907f\u514d\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\uff0c\u540c\u65f6\u6d88\u9664\u4e86\u5bf9\u5b8c\u6574\u6570\u636e\u7684\u4f9d\u8d56\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u57fa\u51c6\u6570\u636e\u96c6\u548c\u5927\u89c4\u6a21\u6587\u672c\u8bed\u6599\u5e93\u4e0a\u4e0e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u5177\u6709\u76f8\u540c\u7684\u51c6\u786e\u6027\uff0c\u4f46\u8ba1\u7b97\u5f00\u9500\u51cf\u5c11\u4e86\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u9a8c\u8bc1\u4e86\u4f30\u8ba1\u503c\u4e0e\u6570\u636e\u5b50\u96c6\u771f\u5b9e\u5f71\u54cd\u4e4b\u95f4\u7684\u5f3a\u76f8\u5173\u6027\uff0c\u8bc1\u660e\u5176\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u53ef\u9760\u6027\u3002", "conclusion": "Unlearning Shapley\u5f25\u5408\u4e86\u6570\u636e\u4f30\u503c\u7406\u8bba\u4e0e\u5b9e\u9645\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u7b26\u5408\u9690\u79c1\u8981\u6c42\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u73b0\u4ee3AI\u751f\u6001\u7cfb\u7edf\u3002"}}
{"id": "2505.16099", "pdf": "https://arxiv.org/pdf/2505.16099", "abs": "https://arxiv.org/abs/2505.16099", "authors": ["Ziyi", "Zhou", "Nicholas Stern", "Julien Laasri"], "title": "Reinforcement Learning for Stock Transactions", "categories": ["cs.LG", "68T05", "I.2.6"], "comment": "14 pages, 6 figures, paper dated December 19, 2018", "summary": "Much research has been done to analyze the stock market. After all, if one\ncan determine a pattern in the chaotic frenzy of transactions, then they could\nmake a hefty profit from capitalizing on these insights. As such, the goal of\nour project was to apply reinforcement learning (RL) to determine the best time\nto buy a stock within a given time frame. With only a few adjustments, our\nmodel can be extended to identify the best time to sell a stock as well. In\norder to use the format of free, real-world data to train the model, we define\nour own Markov Decision Process (MDP) problem. These two papers [5] [6] helped\nus in formulating the state space and the reward system of our MDP problem. We\ntrain a series of agents using Q-Learning, Q-Learning with linear function\napproximation, and deep Q-Learning. In addition, we try to predict the stock\nprices using machine learning regression and classification models. We then\ncompare our agents to see if they converge on a policy, and if so, which one\nlearned the best policy to maximize profit on the stock market.", "AI": {"tldr": "\u672c\u7814\u7a76\u65e8\u5728\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6765\u786e\u5b9a\u5728\u7ed9\u5b9a\u65f6\u95f4\u8303\u56f4\u5185\u8d2d\u4e70\u80a1\u7968\u7684\u6700\u4f73\u65f6\u673a\uff0c\u5e76\u53ef\u6269\u5c55\u81f3\u786e\u5b9a\u6700\u4f73\u5356\u70b9\u3002\u901a\u8fc7\u5b9a\u4e49\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u95ee\u9898\uff0c\u4f7f\u7528Q-Learning\u3001\u7ebf\u6027\u51fd\u6570\u8fd1\u4f3cQ-Learning\u548c\u6df1\u5ea6Q-Learning\u8bad\u7ec3\u4e00\u7cfb\u5217\u4ee3\u7406\u6a21\u578b\uff0c\u540c\u65f6\u5c1d\u8bd5\u7528\u673a\u5668\u5b66\u4e60\u56de\u5f52\u548c\u5206\u7c7b\u6a21\u578b\u9884\u6d4b\u80a1\u7968\u4ef7\u683c\u3002\u6700\u7ec8\u6bd4\u8f83\u5404\u4ee3\u7406\u6a21\u578b\u4ee5\u627e\u51fa\u6700\u4f18\u7b56\u7565\u3002", "motivation": "\u5982\u679c\u80fd\u5728\u6df7\u4e71\u7684\u4ea4\u6613\u4e2d\u627e\u5230\u89c4\u5f8b\uff0c\u5219\u53ef\u4ee5\u5229\u7528\u8fd9\u4e9b\u6d1e\u5bdf\u83b7\u5f97\u4e30\u539a\u5229\u6da6\u3002\u56e0\u6b64\uff0c\u9879\u76ee\u76ee\u6807\u662f\u5e94\u7528\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u6765\u5bfb\u627e\u4e70\u5356\u80a1\u7968\u7684\u6700\u4f73\u65f6\u673a\u3002", "method": "1. \u5b9a\u4e49\u81ea\u5df1\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDP\uff09\u95ee\u9898\uff0c\u4ee5\u9002\u5e94\u514d\u8d39\u73b0\u5b9e\u6570\u636e\u7684\u683c\u5f0f\u3002\n2. \u4f7f\u7528Q-Learning\u3001\u5e26\u6709\u7ebf\u6027\u51fd\u6570\u903c\u8fd1\u7684Q-Learning\u4ee5\u53ca\u6df1\u5ea6Q-Learning\u8bad\u7ec3\u591a\u4e2a\u4ee3\u7406\u6a21\u578b\u3002\n3. \u91c7\u7528\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u56de\u5f52\u548c\u5206\u7c7b\u6a21\u578b\u9884\u6d4b\u80a1\u7968\u4ef7\u683c\u3002\n4. \u6bd4\u8f83\u4e0d\u540c\u4ee3\u7406\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5224\u65ad\u5176\u662f\u5426\u6536\u655b\u5230\u4e00\u4e2a\u7b56\u7565\uff0c\u5e76\u8bc4\u4f30\u54ea\u4e2a\u7b56\u7565\u80fd\u6700\u5927\u5316\u80a1\u7968\u5e02\u573a\u5229\u6da6\u3002", "result": "\u901a\u8fc7\u8bad\u7ec3\u548c\u6bd4\u8f83\u4e0d\u540c\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u7814\u7a76\u53d1\u73b0\u4e86\u4e00\u4e9b\u80fd\u591f\u6536\u655b\u4e8e\u7b56\u7565\u7684\u6a21\u578b\uff0c\u5e76\u4ece\u4e2d\u8bc6\u522b\u51fa\u8868\u73b0\u6700\u4f73\u7684\u7b56\u7565\u3002\u7136\u800c\uff0c\u5177\u4f53\u7ed3\u679c\u672a\u8be6\u7ec6\u8bf4\u660e\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u7279\u522b\u662fQ-Learning\u53ca\u5176\u53d8\u4f53\uff0c\u80fd\u591f\u5728\u80a1\u7968\u5e02\u573a\u4e2d\u627e\u5230\u6709\u6548\u7684\u4e70\u5356\u7b56\u7565\u3002\u6b64\u5916\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u80a1\u7968\u4ef7\u683c\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u7814\u7a76\u7684\u4ef7\u503c\u3002\u672a\u6765\u53ef\u4ee5\u901a\u8fc7\u66f4\u591a\u8c03\u6574\u4f18\u5316\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2505.17000", "pdf": "https://arxiv.org/pdf/2505.17000", "abs": "https://arxiv.org/abs/2505.17000", "authors": ["Simmaco Di Lillo"], "title": "Critical Points of Random Neural Networks", "categories": ["stat.ML", "cs.LG", "math.PR", "60G60, 62B10, 62M45"], "comment": null, "summary": "This work investigates the expected number of critical points of random\nneural networks with different activation functions as the depth increases in\nthe infinite-width limit. Under suitable regularity conditions, we derive\nprecise asymptotic formulas for the expected number of critical points of fixed\nindex and those exceeding a given threshold. Our analysis reveals three\ndistinct regimes depending on the value of the first derivative of the\ncovariance evaluated at 1: the expected number of critical points may converge,\ngrow polynomially, or grow exponentially with depth. The theoretical\npredictions are supported by numerical experiments. Moreover, we provide\nnumerical evidence suggesting that, when the regularity condition is not\nsatisfied (e.g. for neural networks with ReLU as activation function), the\nnumber of critical points increases as the map resolution increases, indicating\na potential divergence in the number of critical points.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u5728\u65e0\u9650\u5bbd\u5ea6\u6781\u9650\u4e0b\uff0c\u968f\u7740\u6df1\u5ea6\u589e\u52a0\u7684\u968f\u673a\u795e\u7ecf\u7f51\u7edc\u4e2d\u4e34\u754c\u70b9\u7684\u671f\u671b\u6570\u91cf\uff0c\u5e76\u6839\u636e\u6fc0\u6d3b\u51fd\u6570\u7684\u4e0d\u540c\u8fdb\u884c\u4e86\u5206\u6790\u3002", "motivation": "\u4e86\u89e3\u968f\u673a\u795e\u7ecf\u7f51\u7edc\u4e2d\u4e34\u754c\u70b9\u7684\u671f\u671b\u6570\u91cf\u5982\u4f55\u968f\u7740\u6df1\u5ea6\u548c\u6fc0\u6d3b\u51fd\u6570\u7684\u53d8\u5316\u800c\u53d8\u5316\uff0c\u4ee5\u63ed\u793a\u6f5c\u5728\u7684\u7406\u8bba\u673a\u5236\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u63a8\u5bfc\uff0c\u5f97\u5230\u56fa\u5b9a\u6307\u6570\u7684\u4e34\u754c\u70b9\u548c\u8d85\u8fc7\u7ed9\u5b9a\u9608\u503c\u7684\u4e34\u754c\u70b9\u7684\u671f\u671b\u6570\u91cf\u7684\u7cbe\u786e\u6e10\u8fd1\u516c\u5f0f\uff0c\u5e76\u7ed3\u5408\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u9884\u6d4b\u3002", "result": "\u53d1\u73b0\u5b58\u5728\u4e09\u4e2a\u4e0d\u540c\u7684\u6e10\u53d8\u6a21\u5f0f\u53d6\u51b3\u4e8e\u534f\u65b9\u5dee\u7684\u7b2c\u4e00\u5bfc\u6570\u57281\u5904\u7684\u503c\uff1a\u4e34\u754c\u70b9\u7684\u671f\u671b\u6570\u91cf\u53ef\u80fd\u6536\u655b\u3001\u591a\u9879\u5f0f\u589e\u957f\u6216\u6307\u6570\u589e\u957f\u3002\u6b64\u5916\uff0c\u5bf9\u4e8e\u4e0d\u6ee1\u8db3\u6b63\u5219\u6027\u6761\u4ef6\u7684ReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u4e34\u754c\u70b9\u7684\u6570\u91cf\u968f\u6620\u5c04\u5206\u8fa8\u7387\u589e\u52a0\u800c\u589e\u52a0\u3002", "conclusion": "\u968f\u673a\u795e\u7ecf\u7f51\u7edc\u7684\u4e34\u754c\u70b9\u6570\u91cf\u884c\u4e3a\u53d7\u6fc0\u6d3b\u51fd\u6570\u53ca\u5176\u6b63\u5219\u6027\u6761\u4ef6\u7684\u5f71\u54cd\u663e\u8457\uff0c\u4e14\u7406\u8bba\u7ed3\u679c\u5f97\u5230\u4e86\u6570\u503c\u5b9e\u9a8c\u7684\u652f\u6301\u3002"}}
{"id": "2505.16176", "pdf": "https://arxiv.org/pdf/2505.16176", "abs": "https://arxiv.org/abs/2505.16176", "authors": ["Jun Rao", "Xuebo Liu", "Hexuan Deng", "Zepeng Lin", "Zixiong Yu", "Jiansheng Wei", "Xiaojun Meng", "Min Zhang"], "title": "Dynamic Sampling that Adapts: Iterative DPO for Self-Aware Mathematical Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "In the realm of data selection for reasoning tasks, existing approaches\npredominantly rely on externally predefined static metrics such as difficulty\nand diversity, which are often designed for supervised fine-tuning (SFT) and\nlack adaptability to continuous training processes. A critical limitation of\nthese methods is their inability to dynamically align with the evolving\ncapabilities of models during online training, a gap that becomes increasingly\npronounced with the rise of dynamic training paradigms and online reinforcement\nlearning (RL) frameworks (e.g., R1 models). To address this, we introduce\nSAI-DPO, an algorithm that dynamically selects training data by continuously\nassessing a model's stage-specific reasoning abilities across different\ntraining phases. By integrating real-time model performance feedback, SAI-DPO\nadaptively adapts data selection to the evolving strengths and weaknesses of\nthe model, thus enhancing both data utilization efficiency and final task\nperformance. Extensive experiments on three state-of-the-art models and eight\nmathematical reasoning benchmarks, including challenging competition-level\ndatasets (e.g., AIME24 and AMC23), demonstrate that SAI-DPO achieves an average\nperformance boost of up to 21.3 percentage points, with particularly notable\nimprovements of 10 and 15 points on AIME24 and AMC23, respectively. These\nresults highlight the superiority of dynamic, model-adaptive data selection\nover static, externally defined strategies in advancing reasoning.", "AI": {"tldr": "\u5728\u6570\u636e\u9009\u62e9\u65b9\u9762\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u5916\u90e8\u9884\u5b9a\u4e49\u7684\u9759\u6001\u6307\u6807\uff0c\u5982\u96be\u5ea6\u548c\u591a\u6837\u6027\uff0c\u8fd9\u4e9b\u6307\u6807\u5f80\u5f80\u4e3a\u76d1\u7763\u5fae\u8c03(SFT)\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u5bf9\u8fde\u7eed\u8bad\u7ec3\u8fc7\u7a0b\u7684\u9002\u5e94\u6027\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u4e86SAI-DPO\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u5b9e\u65f6\u8bc4\u4f30\u6a21\u578b\u5728\u4e0d\u540c\u8bad\u7ec3\u9636\u6bb5\u7684\u63a8\u7406\u80fd\u529b\uff0c\u52a8\u6001\u5730\u9009\u62e9\u8bad\u7ec3\u6570\u636e\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u6570\u636e\u5229\u7528\u6548\u7387\u548c\u6700\u7ec8\u4efb\u52a1\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660e\uff0cSAI-DPO\u5728\u591a\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u5e73\u5747\u63d0\u5347\u4e8621.3\u4e2a\u767e\u5206\u70b9\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u6307\u6807\uff0c\u5728\u52a8\u6001\u8bad\u7ec3\u548c\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u9002\u5e94\u6a21\u578b\u80fd\u529b\u7684\u53d8\u5316\u3002", "method": "\u63d0\u51faSAI-DPO\u7b97\u6cd5\uff0c\u901a\u8fc7\u6301\u7eed\u8bc4\u4f30\u6a21\u578b\u5728\u4e0d\u540c\u8bad\u7ec3\u9636\u6bb5\u7684\u63a8\u7406\u80fd\u529b\uff0c\u52a8\u6001\u8c03\u6574\u6570\u636e\u9009\u62e9\u7b56\u7565\uff0c\u4ee5\u9002\u5e94\u6a21\u578b\u7684\u4f18\u52a3\u52bf\u53d8\u5316\u3002", "result": "\u5728\u4e09\u4e2a\u5148\u8fdb\u6a21\u578b\u548c\u516b\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSAI-DPO\u5b9e\u73b0\u4e86\u9ad8\u8fbe21.3\u4e2a\u767e\u5206\u70b9\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5728AIME24\u548cAMC23\u6570\u636e\u96c6\u4e0a\u5206\u522b\u63d0\u5347\u4e8610\u548c15\u4e2a\u70b9\u3002", "conclusion": "\u52a8\u6001\u3001\u6a21\u578b\u81ea\u9002\u5e94\u7684\u6570\u636e\u9009\u62e9\u7b56\u7565\u4f18\u4e8e\u9759\u6001\u3001\u5916\u90e8\u5b9a\u4e49\u7684\u65b9\u6cd5\uff0c\u80fd\u663e\u8457\u63d0\u9ad8\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2505.16103", "pdf": "https://arxiv.org/pdf/2505.16103", "abs": "https://arxiv.org/abs/2505.16103", "authors": ["Monirul Islam Mahmud"], "title": "Towards Trustworthy Keylogger detection: A Comprehensive Analysis of Ensemble Techniques and Feature Selections through Explainable AI", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Keylogger detection involves monitoring for unusual system behaviors such as\ndelays between typing and character display, analyzing network traffic patterns\nfor data exfiltration. In this study, we provide a comprehensive analysis for\nkeylogger detection with traditional machine learning models - SVC, Random\nForest, Decision Tree, XGBoost, AdaBoost, Logistic Regression and Naive Bayes\nand advanced ensemble methods including Stacking, Blending and Voting.\nMoreover, feature selection approaches such as Information gain, Lasso L1 and\nFisher Score are thoroughly assessed to improve predictive performance and\nlower computational complexity. The Keylogger Detection dataset from publicly\navailable Kaggle website is used in this project. In addition to accuracy-based\nclassification, this study implements the approach for model interpretation\nusing Explainable AI (XAI) techniques namely SHAP (Global) and LIME (Local) to\ndeliver finer explanations for how much each feature contributes in assisting\nor hindering the detection process. To evaluate the models result, we have used\nAUC score, sensitivity, Specificity, Accuracy and F1 score. The best\nperformance was achieved by AdaBoost with 99.76% accuracy, F1 score of 0.99,\n100% precision, 98.6% recall, 1.0 specificity and 0.99 of AUC that is\nnear-perfect classification with Fisher Score.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u591a\u79cd\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u9ad8\u7ea7\u96c6\u6210\u65b9\u6cd5\u8fdb\u884c\u952e\u76d8\u8bb0\u5f55\u5668\u68c0\u6d4b\uff0c\u5e76\u901a\u8fc7\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u4f18\u5316\u6027\u80fd\uff0cAdaBoost\u7ed3\u5408Fisher Score\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u9ad8\u8fbe99.76%\u3002", "motivation": "\u952e\u76d8\u8bb0\u5f55\u5668\u68c0\u6d4b\u5bf9\u4e8e\u8bc6\u522b\u5f02\u5e38\u7cfb\u7edf\u884c\u4e3a\uff08\u5982\u6253\u5b57\u4e0e\u5b57\u7b26\u663e\u793a\u4e4b\u95f4\u7684\u5ef6\u8fdf\uff09\u548c\u5206\u6790\u7f51\u7edc\u6d41\u91cf\u6a21\u5f0f\u4ee5\u53d1\u73b0\u6570\u636e\u5916\u6cc4\u81f3\u5173\u91cd\u8981\u3002\u4e3a\u4e86\u63d0\u9ad8\u68c0\u6d4b\u6548\u7387\u5e76\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u9700\u8981\u5bf9\u4e0d\u540c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528\u4e86\u591a\u79cd\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08SVC\u3001\u968f\u673a\u68ee\u6797\u3001\u51b3\u7b56\u6811\u3001XGBoost\u3001AdaBoost\u3001\u903b\u8f91\u56de\u5f52\u548c\u6734\u7d20\u8d1d\u53f6\u65af\uff09\u548c\u9ad8\u7ea7\u96c6\u6210\u65b9\u6cd5\uff08Stacking\u3001Blending\u548cVoting\uff09\uff0c\u4ee5\u53ca\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\uff08\u4fe1\u606f\u589e\u76ca\u3001Lasso L1\u548cFisher Score\uff09\u3002\u57fa\u4e8e\u516c\u5f00\u7684Kaggle\u952e\u76d8\u8bb0\u5f55\u5668\u68c0\u6d4b\u6570\u636e\u96c6\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5e76\u91c7\u7528\u53ef\u89e3\u91caAI\u6280\u672f\uff08SHAP\u548cLIME\uff09\u89e3\u91ca\u6a21\u578b\u3002", "result": "AdaBoost\u7ed3\u5408Fisher Score\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\uff0c\u51c6\u786e\u7387\u8fbe\u523099.76%\uff0cF1\u5206\u6570\u4e3a0.99\uff0c\u7cbe\u786e\u7387\u4e3a100%\uff0c\u53ec\u56de\u7387\u4e3a98.6%\uff0c\u7279\u5f02\u6027\u4e3a1.0\uff0cAUC\u4e3a0.99\uff0c\u63a5\u8fd1\u5b8c\u7f8e\u5206\u7c7b\u3002", "conclusion": "AdaBoost\u7ed3\u5408Fisher Score\u5728\u952e\u76d8\u8bb0\u5f55\u5668\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u591f\u63d0\u4f9b\u9ad8\u7cbe\u5ea6\u7684\u9884\u6d4b\u7ed3\u679c\uff0c\u540c\u65f6\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u6709\u52a9\u4e8e\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002\u53ef\u89e3\u91caAI\u6280\u672f\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u900f\u660e\u6027\u548c\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2505.16186", "pdf": "https://arxiv.org/pdf/2505.16186", "abs": "https://arxiv.org/abs/2505.16186", "authors": ["Kaiwen Zhou", "Xuandong Zhao", "Gaowen Liu", "Jayanth Srinivasa", "Aosong Feng", "Dawn Song", "Xin Eric Wang"], "title": "SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning", "categories": ["cs.AI", "cs.CL", "cs.CR"], "comment": null, "summary": "Large Reasoning Models (LRMs) introduce a new generation paradigm of\nexplicitly reasoning before answering, leading to remarkable improvements in\ncomplex tasks. However, they pose great safety risks against harmful queries\nand adversarial attacks. While recent mainstream safety efforts on LRMs,\nsupervised fine-tuning (SFT), improve safety performance, we find that\nSFT-aligned models struggle to generalize to unseen jailbreak prompts. After\nthorough investigation of LRMs' generation, we identify a safety aha moment\nthat can activate safety reasoning and lead to a safe response. This aha moment\ntypically appears in the `key sentence', which follows models' query\nunderstanding process and can indicate whether the model will proceed safely.\nBased on these insights, we propose SafeKey, including two complementary\nobjectives to better activate the safety aha moment in the key sentence: (1) a\nDual-Path Safety Head to enhance the safety signal in the model's internal\nrepresentations before the key sentence, and (2) a Query-Mask Modeling\nobjective to improve the models' attention on its query understanding, which\nhas important safety hints. Experiments across multiple safety benchmarks\ndemonstrate that our methods significantly improve safety generalization to a\nwide range of jailbreak attacks and out-of-distribution harmful prompts,\nlowering the average harmfulness rate by 9.6\\%, while maintaining general\nabilities. Our analysis reveals how SafeKey enhances safety by reshaping\ninternal attention and improving the quality of hidden representations.", "AI": {"tldr": "Large Reasoning Models (LRMs)\u867d\u7136\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b58\u5728\u5b89\u5168\u98ce\u9669\u3002\u672c\u6587\u63d0\u51faSafeKey\u65b9\u6cd5\uff0c\u901a\u8fc7\u589e\u5f3a\u5173\u952e\u53e5\u4e2d\u7684\u5b89\u5168\u4fe1\u53f7\u548c\u6539\u8fdb\u6a21\u578b\u5bf9\u67e5\u8be2\u7684\u7406\u89e3\uff0c\u663e\u8457\u63d0\u9ad8LRMs\u5bf9\u8d8a\u72f1\u653b\u51fb\u548c\u6709\u5bb3\u63d0\u793a\u7684\u5b89\u5168\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u901a\u7528\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u76d1\u7763\u5fae\u8c03(SFT)\u63d0\u9ad8\u4e86LRMs\u7684\u5b89\u5168\u6027\u80fd\uff0c\u4f46\u8fd9\u4e9b\u6a21\u578b\u5728\u9762\u5bf9\u672a\u89c1\u8fc7\u7684\u8d8a\u72f1\u63d0\u793a\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "SafeKey\u5305\u542b\u4e24\u4e2a\u4e92\u8865\u76ee\u6807\uff1a(1) Dual-Path Safety Head\uff0c\u5728\u5173\u952e\u53e5\u4e4b\u524d\u589e\u5f3a\u6a21\u578b\u5185\u90e8\u8868\u793a\u4e2d\u7684\u5b89\u5168\u4fe1\u53f7\uff1b(2) Query-Mask Modeling\uff0c\u6539\u8fdb\u6a21\u578b\u5bf9\u5176\u67e5\u8be2\u7406\u89e3\u7684\u5173\u6ce8\u5ea6\uff0c\u5176\u4e2d\u5305\u542b\u91cd\u8981\u7684\u5b89\u5168\u63d0\u793a\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSafeKey\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u591a\u4e2a\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5b89\u5168\u6cdb\u5316\u80fd\u529b\uff0c\u964d\u4f4e\u4e869.6%\u7684\u5e73\u5747\u6709\u5bb3\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u901a\u7528\u80fd\u529b\u3002", "conclusion": "SafeKey\u901a\u8fc7\u91cd\u5851\u5185\u90e8\u6ce8\u610f\u529b\u548c\u6539\u8fdb\u9690\u85cf\u8868\u793a\u7684\u8d28\u91cf\u6765\u589e\u5f3aLRMs\u7684\u5b89\u5168\u6027\uff0c\u4e3a\u89e3\u51b3\u8d8a\u72f1\u653b\u51fb\u548c\u6709\u5bb3\u63d0\u793a\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2505.16113", "pdf": "https://arxiv.org/pdf/2505.16113", "abs": "https://arxiv.org/abs/2505.16113", "authors": ["Panagiotis Lymperopoulos", "Vasanth Sarathy"], "title": "Tools in the Loop: Quantifying Uncertainty of LLM Question Answering Systems That Use Tools", "categories": ["cs.LG", "cs.CL"], "comment": "10 pages 3 figures 3 tables", "summary": "Modern Large Language Models (LLMs) often require external tools, such as\nmachine learning classifiers or knowledge retrieval systems, to provide\naccurate answers in domains where their pre-trained knowledge is insufficient.\nThis integration of LLMs with external tools expands their utility but also\nintroduces a critical challenge: determining the trustworthiness of responses\ngenerated by the combined system. In high-stakes applications, such as medical\ndecision-making, it is essential to assess the uncertainty of both the LLM's\ngenerated text and the tool's output to ensure the reliability of the final\nresponse. However, existing uncertainty quantification methods do not account\nfor the tool-calling scenario, where both the LLM and external tool contribute\nto the overall system's uncertainty. In this work, we present a novel framework\nfor modeling tool-calling LLMs that quantifies uncertainty by jointly\nconsidering the predictive uncertainty of the LLM and the external tool. We\nextend previous methods for uncertainty quantification over token sequences to\nthis setting and propose efficient approximations that make uncertainty\ncomputation practical for real-world applications. We evaluate our framework on\ntwo new synthetic QA datasets, derived from well-known machine learning\ndatasets, which require tool-calling for accurate answers. Additionally, we\napply our method to retrieval-augmented generation (RAG) systems and conduct a\nproof-of-concept experiment demonstrating the effectiveness of our uncertainty\nmetrics in scenarios where external information retrieval is needed. Our\nresults show that the framework is effective in enhancing trust in LLM-based\nsystems, especially in cases where the LLM's internal knowledge is insufficient\nand external tools are required.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5bf9\u8c03\u7528\u5916\u90e8\u5de5\u5177\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4e86LLM\u548c\u5916\u90e8\u5de5\u5177\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u4f7f\u4e0d\u786e\u5b9a\u6027\u8ba1\u7b97\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u884c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u589e\u5f3a\u57fa\u4e8eLLM\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u65b9\u9762\u975e\u5e38\u6709\u6548\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5916\u90e8\u5de5\u5177\u652f\u6301\u7684\u60c5\u51b5\u4e0b\u3002", "motivation": "\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9884\u8bad\u7ec3\u77e5\u8bc6\u4e0d\u8db3\u7684\u9886\u57df\u901a\u5e38\u9700\u8981\u4f9d\u8d56\u5916\u90e8\u5de5\u5177\u6765\u63d0\u4f9b\u51c6\u786e\u7b54\u6848\u3002\u7136\u800c\uff0c\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\uff0c\u8bc4\u4f30\u7efc\u5408\u7cfb\u7edf\u8f93\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u81f3\u5173\u91cd\u8981\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u5e94\u5bf9\u8fd9\u79cd\u8c03\u7528\u5916\u90e8\u5de5\u5177\u573a\u666f\u4e0b\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u5c06LLM\u548c\u5916\u90e8\u5de5\u5177\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7ed3\u5408\u8d77\u6765\u8fdb\u884c\u91cf\u5316\u3002\u6b64\u5916\uff0c\u4ed6\u4eec\u6269\u5c55\u4e86\u5148\u524d\u9488\u5bf9\u4ee4\u724c\u5e8f\u5217\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u8fd1\u4f3c\u7b97\u6cd5\u4ee5\u9002\u5e94\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002\u901a\u8fc7\u4e24\u4e2a\u5408\u6210\u95ee\u7b54\u6570\u636e\u96c6\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u57fa\u4e8eLLM\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\uff0c\u5c24\u5176\u662f\u5728LLM\u5185\u90e8\u77e5\u8bc6\u4e0d\u8db3\u4e14\u9700\u8981\u5916\u90e8\u5de5\u5177\u534f\u52a9\u7684\u60c5\u51b5\u4e0b\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u89e3\u51b3\u8c03\u7528\u5916\u90e8\u5de5\u5177\u7684LLMs\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u8fd9\u4e9b\u7cfb\u7edf\u5728\u5173\u952e\u5e94\u7528\u573a\u666f\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2505.16199", "pdf": "https://arxiv.org/pdf/2505.16199", "abs": "https://arxiv.org/abs/2505.16199", "authors": ["Rikuhei Umemoto", "Keisuke Fujii"], "title": "Velocity Completion Task and Method for Event-based Player Positional Data in Soccer", "categories": ["cs.AI"], "comment": "24 pages, 7 figures", "summary": "In many real-world complex systems, the behavior can be observed as a\ncollection of discrete events generated by multiple interacting agents.\nAnalyzing the dynamics of these multi-agent systems, especially team sports,\noften relies on understanding the movement and interactions of individual\nagents. However, while providing valuable snapshots, event-based positional\ndata typically lacks the continuous temporal information needed to directly\ncalculate crucial properties such as velocity. This absence severely limits the\ndepth of dynamic analysis, preventing a comprehensive understanding of\nindividual agent behaviors and emergent team strategies. To address this\nchallenge, we propose a new method to simultaneously complete the velocity of\nall agents using only the event-based positional data from team sports. Based\non this completed velocity information, we investigate the applicability of\nexisting team sports analysis and evaluation methods. Experiments using soccer\nevent data demonstrate that neural network-based approaches outperformed\nrule-based methods regarding velocity completion error, considering the\nunderlying temporal dependencies and graph structure of player-to-player or\nplayer-to-ball interaction. Moreover, the space evaluation results obtained\nusing the completed velocity are closer to those derived from complete tracking\ndata, highlighting our method's potential for enhanced team sports system\nanalysis.", "AI": {"tldr": "\u5728\u56e2\u961f\u8fd0\u52a8\u4e2d\uff0c\u57fa\u4e8e\u4e8b\u4ef6\u7684\u4f4d\u7f6e\u6570\u636e\u901a\u5e38\u7f3a\u4e4f\u8fde\u7eed\u7684\u65f6\u95f4\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u5bf9\u4e2a\u4f53\u884c\u4e3a\u548c\u56e2\u961f\u7b56\u7565\u7684\u6df1\u5165\u52a8\u6001\u5206\u6790\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u56e2\u961f\u8fd0\u52a8\u7684\u57fa\u4e8e\u4e8b\u4ef6\u7684\u4f4d\u7f6e\u6570\u636e\u540c\u65f6\u5b8c\u6210\u6240\u6709\u4ee3\u7406\u4eba\u7684\u901f\u5ea6\u4fe1\u606f\uff0c\u5e76\u9a8c\u8bc1\u4e86\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u5728\u901f\u5ea6\u8865\u5168\u4efb\u52a1\u4e2d\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u56e2\u961f\u8fd0\u52a8\u7b49\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u884c\u4e3a\u5206\u6790\u9700\u8981\u7406\u89e3\u4e2a\u4f53\u4ee3\u7406\u7684\u79fb\u52a8\u548c\u4ea4\u4e92\uff0c\u4f46\u57fa\u4e8e\u4e8b\u4ef6\u7684\u4f4d\u7f6e\u6570\u636e\u7f3a\u4e4f\u8fde\u7eed\u65f6\u95f4\u4fe1\u606f\uff0c\u65e0\u6cd5\u76f4\u63a5\u8ba1\u7b97\u901f\u5ea6\u7b49\u5173\u952e\u5c5e\u6027\uff0c\u9650\u5236\u4e86\u52a8\u6001\u5206\u6790\u7684\u6df1\u5ea6\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u56e2\u961f\u8fd0\u52a8\u7684\u57fa\u4e8e\u4e8b\u4ef6\u7684\u4f4d\u7f6e\u6570\u636e\u540c\u65f6\u5b8c\u6210\u6240\u6709\u4ee3\u7406\u4eba\u7684\u901f\u5ea6\u4fe1\u606f\uff0c\u5e76\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u8003\u8651\u5e95\u5c42\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u73a9\u5bb6\u95f4\u6216\u73a9\u5bb6\u4e0e\u7403\u7684\u4ea4\u4e92\u56fe\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\u5728\u901f\u5ea6\u8865\u5168\u8bef\u5dee\u65b9\u9762\u4f18\u4e8e\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\uff0c\u4e14\u4f7f\u7528\u8865\u5168\u901f\u5ea6\u5f97\u5230\u7684\u7a7a\u95f4\u8bc4\u4f30\u7ed3\u679c\u66f4\u63a5\u8fd1\u4e8e\u5b8c\u6574\u8ddf\u8e2a\u6570\u636e\u5f97\u51fa\u7684\u7ed3\u679c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8865\u5168\u901f\u5ea6\u4fe1\u606f\uff0c\u589e\u5f3a\u56e2\u961f\u8fd0\u52a8\u7cfb\u7edf\u7684\u5206\u6790\u80fd\u529b\u3002"}}
{"id": "2505.16115", "pdf": "https://arxiv.org/pdf/2505.16115", "abs": "https://arxiv.org/abs/2505.16115", "authors": ["Aditya T. Vadlamani", "Anutam Srinivasan", "Pranav Maneriker", "Ali Payani", "Srinivasan Parthasarathy"], "title": "A Generic Framework for Conformal Fairness", "categories": ["cs.LG"], "comment": "ICLR 2025 Camera Ready Version", "summary": "Conformal Prediction (CP) is a popular method for uncertainty quantification\nwith machine learning models. While conformal prediction provides probabilistic\nguarantees regarding the coverage of the true label, these guarantees are\nagnostic to the presence of sensitive attributes within the dataset. In this\nwork, we formalize \\textit{Conformal Fairness}, a notion of fairness using\nconformal predictors, and provide a theoretically well-founded algorithm and\nassociated framework to control for the gaps in coverage between different\nsensitive groups. Our framework leverages the exchangeability assumption\n(implicit to CP) rather than the typical IID assumption, allowing us to apply\nthe notion of Conformal Fairness to data types and tasks that are not IID, such\nas graph data. Experiments were conducted on graph and tabular datasets to\ndemonstrate that the algorithm can control fairness-related gaps in addition to\ncoverage aligned with theoretical expectations.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86Conformal Fairness\u7684\u6982\u5ff5\uff0c\u901a\u8fc7\u4e00\u4e2a\u7406\u8bba\u57fa\u7840\u826f\u597d\u7684\u7b97\u6cd5\u548c\u6846\u67b6\u6765\u63a7\u5236\u4e0d\u540c\u654f\u611f\u7fa4\u4f53\u4e4b\u95f4\u7684\u8986\u76d6\u7387\u5dee\u8ddd\u3002\u8be5\u6846\u67b6\u5229\u7528\u4e86\u53ef\u4ea4\u6362\u6027\u5047\u8bbe\uff0c\u9002\u7528\u4e8e\u975eIID\u6570\u636e\u7c7b\u578b\uff08\u5982\u56fe\u6570\u636e\uff09\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u53ef\u4ee5\u63a7\u5236\u4e0e\u516c\u5e73\u6027\u76f8\u5173\u7684\u5dee\u8ddd\uff0c\u5e76\u4e14\u8986\u76d6\u7387\u7b26\u5408\u7406\u8bba\u9884\u671f\u3002", "motivation": "\u73b0\u6709\u7684Conformal Prediction\u65b9\u6cd5\u867d\u7136\u63d0\u4f9b\u4e86\u5173\u4e8e\u771f\u5b9e\u6807\u7b7e\u8986\u76d6\u7387\u7684\u6982\u7387\u4fdd\u8bc1\uff0c\u4f46\u5bf9\u6570\u636e\u96c6\u4e2d\u654f\u611f\u5c5e\u6027\u7684\u5b58\u5728\u662f\u4e0d\u53ef\u77e5\u7684\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u4e0d\u540c\u654f\u611f\u7fa4\u4f53\u4e4b\u95f4\u7684\u8986\u76d6\u7387\u5dee\u8ddd\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u5f62\u5f0f\u5316\u4e86Conformal Fairness\u7684\u6982\u5ff5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7406\u8bba\u57fa\u7840\u826f\u597d\u7684\u7b97\u6cd5\u548c\u6846\u67b6\uff0c\u5229\u7528\u53ef\u4ea4\u6362\u6027\u5047\u8bbe\u800c\u975e\u5178\u578b\u7684IID\u5047\u8bbe\uff0c\u4ece\u800c\u5c06Conformal Fairness\u5e94\u7528\u4e8e\u975eIID\u6570\u636e\u7c7b\u578b\u548c\u4efb\u52a1\u3002", "result": "\u5728\u56fe\u548c\u8868\u683c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u4e0d\u4ec5\u53ef\u4ee5\u63a7\u5236\u8986\u76d6\u7387\u5dee\u8ddd\uff0c\u8fd8\u80fd\u6ee1\u8db3\u516c\u5e73\u6027\u76f8\u5173\u7684\u8981\u6c42\uff0c\u7ed3\u679c\u4e0e\u7406\u8bba\u9884\u671f\u4e00\u81f4\u3002", "conclusion": "Conformal Fairness\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63a7\u5236\u4e0d\u540c\u654f\u611f\u7fa4\u4f53\u4e4b\u95f4\u7684\u8986\u76d6\u7387\u5dee\u8ddd\uff0c\u540c\u65f6\u6ee1\u8db3\u516c\u5e73\u6027\u548c\u8986\u76d6\u7387\u7684\u8981\u6c42\uff0c\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u6570\u636e\u7c7b\u578b\u548c\u4efb\u52a1\u3002"}}
{"id": "2505.16221", "pdf": "https://arxiv.org/pdf/2505.16221", "abs": "https://arxiv.org/abs/2505.16221", "authors": ["Yifan Zhang", "Xinkui Zhao", "Zuxin Wang", "Guanjie Cheng", "Yueshen Xu", "Shuiguang Deng", "Jianwei Yin"], "title": "LightRouter: Towards Efficient LLM Collaboration with Minimal Overhead", "categories": ["cs.AI"], "comment": null, "summary": "The rapid advancement of large language models has unlocked remarkable\ncapabilities across a diverse array of natural language processing tasks.\nHowever, the considerable differences among available LLMs-in terms of cost,\nperformance, and computational demands-pose significant challenges for users\naiming to identify the most suitable model for specific tasks. In this work, we\npresent LightRouter, a novel framework designed to systematically select and\nintegrate a small subset of LLMs from a larger pool, with the objective of\njointly optimizing both task performance and cost efficiency. LightRouter\nleverages an adaptive selection mechanism to identify models that require only\na minimal number of boot tokens, thereby reducing costs, and further employs an\neffective integration strategy to combine their outputs. Extensive experiments\nacross multiple benchmarks demonstrate that LightRouter matches or outperforms\nwidely-used ensemble baselines, achieving up to a 25% improvement in accuracy.\nCompared with leading high-performing models, LightRouter achieves comparable\nperformance while reducing inference costs by up to 27%. Importantly, our\nframework operates without any prior knowledge of individual models and relies\nexclusively on inexpensive, lightweight models. This work introduces a\npractical approach for efficient LLM selection and provides valuable insights\ninto optimal strategies for model combination.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5feb\u901f\u53d1\u5c55\u4e3a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u5e26\u6765\u4e86\u663e\u8457\u7684\u80fd\u529b\u3002\u7136\u800c\uff0c\u4e0d\u540cLLM\u5728\u6210\u672c\u3001\u6027\u80fd\u548c\u8ba1\u7b97\u9700\u6c42\u4e0a\u7684\u5de8\u5927\u5dee\u5f02\u7ed9\u7528\u6237\u9009\u62e9\u5408\u9002\u7684\u6a21\u578b\u5e26\u6765\u4e86\u6311\u6218\u3002\u672c\u6587\u63d0\u51fa\u4e86LightRouter\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u5730\u9009\u62e9\u548c\u6574\u5408\u5c11\u91cfLLM\u6765\u540c\u65f6\u4f18\u5316\u4efb\u52a1\u6027\u80fd\u548c\u6210\u672c\u6548\u7387\u3002LightRouter\u91c7\u7528\u81ea\u9002\u5e94\u9009\u62e9\u673a\u5236\u51cf\u5c11\u542f\u52a8\u4ee4\u724c\u6570\u91cf\u4ee5\u964d\u4f4e\u6210\u672c\uff0c\u5e76\u4f7f\u7528\u6709\u6548\u7684\u6574\u5408\u7b56\u7565\u7ed3\u5408\u6a21\u578b\u8f93\u51fa\u3002\u5b9e\u9a8c\u8868\u660e\uff0cLightRouter\u4e0e\u5e7f\u6cdb\u4f7f\u7528\u7684\u96c6\u6210\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5728\u51c6\u786e\u6027\u4e0a\u63d0\u9ad8\u4e8625%\uff0c\u5e76\u4e14\u4e0e\u9ad8\u6027\u80fd\u6a21\u578b\u76f8\u6bd4\uff0c\u63a8\u7406\u6210\u672c\u964d\u4f4e\u4e8627%\u3002\u8be5\u6846\u67b6\u65e0\u9700\u4efb\u4f55\u5148\u9a8c\u77e5\u8bc6\uff0c\u4ec5\u4f9d\u8d56\u5ec9\u4ef7\u7684\u8f7b\u91cf\u7ea7\u6a21\u578b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u9009\u62e9\u548c\u7ec4\u5408LLM\u7684\u5b9e\u9645\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u53ef\u7528\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6210\u672c\u3001\u6027\u80fd\u548c\u8ba1\u7b97\u9700\u6c42\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u8fd9\u4f7f\u5f97\u7528\u6237\u5f88\u96be\u786e\u5b9a\u54ea\u4e2a\u6a21\u578b\u6700\u9002\u5408\u7279\u5b9a\u7684\u4efb\u52a1\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5e73\u8861\u6027\u80fd\u548c\u6210\u672c\u7684\u6a21\u578b\u9009\u62e9\u548c\u6574\u5408\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLightRouter\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u4ee5\u4e0b\u6b65\u9aa4\u5b9e\u73b0\u76ee\u6807\uff1a1) \u4f7f\u7528\u81ea\u9002\u5e94\u9009\u62e9\u673a\u5236\u6311\u9009\u51fa\u53ea\u9700\u8981\u6700\u5c11\u5f15\u5bfc\u4ee4\u724c\u7684\u6a21\u578b\uff0c\u4ece\u800c\u964d\u4f4e\u8fd0\u884c\u6210\u672c\uff1b2) \u5e94\u7528\u6709\u6548\u7684\u6574\u5408\u7b56\u7565\u5c06\u8fd9\u4e9b\u6a21\u578b\u7684\u8f93\u51fa\u7ed3\u5408\u8d77\u6765\uff0c\u4ee5\u63d0\u9ad8\u6574\u4f53\u6027\u80fd\u3002\u6574\u4e2a\u8fc7\u7a0b\u4e0d\u9700\u8981\u5bf9\u5404\u4e2a\u6a21\u578b\u6709\u4efb\u4f55\u9884\u5148\u4e86\u89e3\uff0c\u53ea\u4f9d\u8d56\u4e8e\u4f4e\u6210\u672c\u7684\u8f7b\u91cf\u5316\u6a21\u578b\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLightRouter\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u5e38\u7528\u7684\u96c6\u6210\u57fa\u7ebf\u6a21\u578b\uff0c\u51c6\u786e\u7387\u63d0\u5347\u4e8625%\u3002\u6b64\u5916\uff0c\u4e0e\u9886\u5148\u7684\u9ad8\u6027\u80fd\u91cf\u5b50\u6a21\u578b\u76f8\u6bd4\uff0cLightRouter\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u76f8\u5f53\u7684\u6027\u80fd\u6c34\u5e73\uff0c\u8fd8\u6210\u529f\u5c06\u63a8\u7406\u6210\u672c\u51cf\u5c11\u4e8627%\u3002", "conclusion": "LightRouter\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u9ad8\u6548\u7684LLM\u9009\u62e9\u548c\u6574\u5408\u65b9\u6cd5\uff0c\u5b83\u80fd\u591f\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u964d\u4f4e\u6210\u672c\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u672a\u6765\u5982\u4f55\u6700\u4f18\u5730\u9009\u62e9\u548c\u7ec4\u5408\u6a21\u578b\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u89c1\u89e3\u3002"}}
{"id": "2505.16122", "pdf": "https://arxiv.org/pdf/2505.16122", "abs": "https://arxiv.org/abs/2505.16122", "authors": ["Junhong Lin", "Xinyue Zeng", "Jie Zhu", "Song Wang", "Julian Shun", "Jun Wu", "Dawei Zhou"], "title": "Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning", "categories": ["cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success in complex\nreasoning tasks, but their inference remains computationally inefficient. We\nobserve a common failure mode in many prevalent LLMs, overthinking, where\nmodels generate verbose and tangential reasoning traces even for simple\nqueries. Recent works have tried to mitigate this by enforcing fixed token\nbudgets, however, this can lead to underthinking, especially on harder\nproblems. Through empirical analysis, we identify that this inefficiency often\nstems from unclear problem-solving strategies. To formalize this, we develop a\ntheoretical model, BBAM (Bayesian Budget Allocation Model), which models\nreasoning as a sequence of sub-questions with varying uncertainty, and\nintroduce the $E^3$ metric to capture the trade-off between correctness and\ncomputation efficiency. Building on theoretical results from BBAM, we propose\nPlan-and-Budget, a model-agnostic, test-time framework that decomposes complex\nqueries into sub-questions and allocates token budgets based on estimated\ncomplexity using adaptive scheduling. Plan-and-Budget improves reasoning\nefficiency across a range of tasks and models, achieving up to +70% accuracy\ngains, -39% token reduction, and +187.5% improvement in $E^3$. Notably, it\nelevates a smaller model (DS-Qwen-32B) to match the efficiency of a larger\nmodel (DS-LLaMA-70B)-demonstrating Plan-and-Budget's ability to close\nperformance gaps without retraining. Our code is available at\nanonymous.4open.science/r/P-and-B-6513/.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u63a8\u7406\u6548\u7387\u4f4e\u4e0b\u3002\u672c\u7814\u7a76\u53d1\u73b0\u8bb8\u591aLLM\u5b58\u5728\u8fc7\u5ea6\u601d\u8003\u7684\u95ee\u9898\uff0c\u5373\u5bf9\u4e8e\u7b80\u5355\u95ee\u9898\u4e5f\u751f\u6210\u5197\u957f\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86BBAM\uff08\u8d1d\u53f6\u65af\u9884\u7b97\u5206\u914d\u6a21\u578b\uff09\u548c$E^3$\u6307\u6807\uff0c\u4ee5\u6355\u6349\u6b63\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u3002\u57fa\u4e8e\u6b64\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86Plan-and-Budget\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u5b50\u95ee\u9898\uff0c\u5e76\u6839\u636e\u4f30\u8ba1\u7684\u590d\u6742\u5ea6\u81ea\u9002\u5e94\u5730\u5206\u914dtoken\u9884\u7b97\u3002\u5b9e\u9a8c\u8868\u660e\uff0cPlan-and-Budget\u63d0\u9ad8\u4e86\u591a\u79cd\u4efb\u52a1\u548c\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\uff0c\u663e\u8457\u51cf\u5c11\u4e86token\u4f7f\u7528\u91cf\u5e76\u63d0\u5347\u4e86\u51c6\u786e\u6027\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5b83\u80fd\u4f7f\u8f83\u5c0f\u7684\u6a21\u578b\uff08\u5982DS-Qwen-32B\uff09\u8fbe\u5230\u4e0e\u8f83\u5927\u6a21\u578b\uff08\u5982DS-LLaMA-70B\uff09\u76f8\u5f53\u7684\u6548\u7387\uff0c\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u5176\u63a8\u7406\u6548\u7387\u4ecd\u7136\u8f83\u4f4e\u3002\u8bb8\u591a\u6a21\u578b\u5728\u5904\u7406\u7b80\u5355\u95ee\u9898\u65f6\u4ea7\u751f\u5197\u957f\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u800c\u5728\u8f83\u96be\u7684\u95ee\u9898\u4e0a\u53c8\u53ef\u80fd\u56e0\u56fa\u5b9atoken\u9884\u7b97\u800c\u5bfc\u81f4\u63a8\u7406\u4e0d\u8db3\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u4f18\u5316\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\uff0c\u4ece\u800c\u63d0\u9ad8\u6548\u7387\u3002", "method": "1. \u63d0\u51fa\u4e86BBAM\uff08Bayesian Budget Allocation Model\uff09\uff0c\u7528\u4e8e\u5bf9\u63a8\u7406\u8fc7\u7a0b\u5efa\u6a21\uff0c\u5e76\u5f15\u5165\u4e86$E^3$\u6307\u6807\u8861\u91cf\u6b63\u786e\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u3002\n2. \u8bbe\u8ba1\u4e86Plan-and-Budget\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5728\u6d4b\u8bd5\u65f6\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u5b50\u95ee\u9898\uff0c\u5e76\u6839\u636e\u590d\u6742\u5ea6\u4f30\u8ba1\u81ea\u9002\u5e94\u5730\u5206\u914dtoken\u9884\u7b97\u3002\n3. \u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86Plan-and-Budget\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u7684\u6027\u80fd\u63d0\u5347\u3002", "result": "Plan-and-Budget\u6846\u67b6\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u6539\u8fdb\uff1a\n- \u51c6\u786e\u6027\u63d0\u5347\u9ad8\u8fbe+70%\u3002\n- token\u4f7f\u7528\u91cf\u51cf\u5c11\u8fbe-39%\u3002\n- $E^3$\u6307\u6807\u63d0\u5347+187.5%\u3002\n\u6b64\u5916\uff0c\u8f83\u5c0f\u7684\u6a21\u578b\uff08\u5982DS-Qwen-32B\uff09\u901a\u8fc7\u8be5\u6846\u67b6\u80fd\u591f\u8fbe\u5230\u4e0e\u8f83\u5927\u6a21\u578b\uff08\u5982DS-LLaMA-70B\uff09\u76f8\u5339\u914d\u7684\u6548\u7387\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u63a8\u7406\u4f18\u5316\u6846\u67b6Plan-and-Budget\uff0c\u89e3\u51b3\u4e86LLMs\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5b58\u5728\u7684\u8fc7\u5ea6\u601d\u8003\u6216\u63a8\u7406\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5c06\u590d\u6742\u95ee\u9898\u5206\u89e3\u4e3a\u5b50\u95ee\u9898\u5e76\u81ea\u9002\u5e94\u5206\u914dtoken\u9884\u7b97\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\uff0c\u51cf\u5c11\u4e86\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u5176\u5728\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u7f29\u5c0f\u80fd\u529b\u3002"}}
{"id": "2505.16204", "pdf": "https://arxiv.org/pdf/2505.16204", "abs": "https://arxiv.org/abs/2505.16204", "authors": ["Ichiro Hashimoto"], "title": "Directional Convergence, Benign Overfitting of Gradient Descent in leaky ReLU two-layer Neural Networks", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH", "68T07 (primary)"], "comment": "34 pages", "summary": "In this paper, we prove directional convergence of network parameters of\nfixed width leaky ReLU two-layer neural networks optimized by gradient descent\nwith exponential loss, which was previously only known for gradient flow. By a\ncareful analysis of the convergent direction, we establish sufficient\nconditions of benign overfitting and discover a new phase transition in the\ntest error bound. All of these results hold beyond the nearly orthogonal data\nsetting which was studied in prior works. As an application, we demonstrate\nthat benign overfitting occurs with high probability in sub-Gaussian mixture\nmodels.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u8bc1\u660e\u4e86\u56fa\u5b9a\u5bbd\u5ea6\u7684\u5e26\u6cc4\u9732ReLU\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u5728\u4f7f\u7528\u6307\u6570\u635f\u5931\u51fd\u6570\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u65f6\uff0c\u5176\u7f51\u7edc\u53c2\u6570\u7684\u65b9\u5411\u6027\u6536\u655b\u3002\u901a\u8fc7\u5206\u6790\u6536\u655b\u65b9\u5411\uff0c\u5efa\u7acb\u4e86\u826f\u6027\u7684\u8fc7\u62df\u5408\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u53d1\u73b0\u4e86\u6d4b\u8bd5\u8bef\u5dee\u754c\u9650\u4e2d\u7684\u65b0\u76f8\u53d8\u73b0\u8c61\u3002\u8fd9\u4e9b\u7ed3\u679c\u4e0d\u4ec5\u9650\u4e8e\u5148\u524d\u7814\u7a76\u7684\u8fd1\u4f3c\u6b63\u4ea4\u6570\u636e\u8bbe\u7f6e\u3002\u6b64\u5916\uff0c\u5728\u5b50\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u4e2d\uff0c\u826f\u6027\u8fc7\u62df\u5408\u4ee5\u9ad8\u6982\u7387\u53d1\u751f\u3002", "motivation": "\u7814\u7a76\u8005\u5e0c\u671b\u8bc1\u660e\u4f7f\u7528\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u7684\u56fa\u5b9a\u5bbd\u5ea6\u6cc4\u9732ReLU\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u5411\u6027\u6536\u655b\uff0c\u4ee5\u53ca\u63a2\u7d22\u826f\u6027\u8fc7\u62df\u5408\u7684\u6761\u4ef6\u548c\u6d4b\u8bd5\u8bef\u5dee\u754c\u9650\u4e2d\u7684\u76f8\u53d8\u73b0\u8c61\uff0c\u8d85\u8d8a\u4e4b\u524d\u4ec5\u5bf9\u68af\u5ea6\u6d41\u548c\u8fd1\u4f3c\u6b63\u4ea4\u6570\u636e\u7684\u7814\u7a76\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u7ec6\u81f4\u5206\u6790\u7f51\u7edc\u53c2\u6570\u7684\u6536\u655b\u65b9\u5411\uff0c\u63a8\u5bfc\u51fa\u826f\u6027\u8fc7\u62df\u5408\u7684\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u63ed\u793a\u6d4b\u8bd5\u8bef\u5dee\u754c\u9650\u4e2d\u7684\u65b0\u76f8\u53d8\u3002\u4ed6\u4eec\u8fd8\u6269\u5c55\u4e86\u7814\u7a76\u8303\u56f4\uff0c\u4e0d\u518d\u5c40\u9650\u4e8e\u8fd1\u4f3c\u6b63\u4ea4\u6570\u636e\u8bbe\u7f6e\u3002", "result": "\u8bba\u6587\u6210\u529f\u8bc1\u660e\u4e86\u56fa\u5b9a\u5bbd\u5ea6\u6cc4\u9732ReLU\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u5728\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u4e0b\u7684\u65b9\u5411\u6027\u6536\u655b\uff0c\u5efa\u7acb\u4e86\u826f\u6027\u8fc7\u62df\u5408\u7684\u5145\u5206\u6761\u4ef6\uff0c\u5e76\u53d1\u73b0\u4e86\u4e00\u4e2a\u65b0\u7684\u6d4b\u8bd5\u8bef\u5dee\u754c\u9650\u4e2d\u7684\u76f8\u53d8\u73b0\u8c61\u3002\u5728\u5b50\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u4e2d\u9a8c\u8bc1\u4e86\u826f\u6027\u8fc7\u62df\u5408\u53d1\u751f\u7684\u9ad8\u6982\u7387\u6027\u3002", "conclusion": "\u56fa\u5b9a\u5bbd\u5ea6\u6cc4\u9732ReLU\u4e24\u5c42\u795e\u7ecf\u7f51\u7edc\u5728\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u4e0b\u8868\u73b0\u51fa\u65b9\u5411\u6027\u6536\u655b\uff0c\u4e14\u5176\u826f\u6027\u8fc7\u62df\u5408\u548c\u6d4b\u8bd5\u8bef\u5dee\u754c\u9650\u4e2d\u7684\u76f8\u53d8\u73b0\u8c61\u88ab\u63ed\u793a\u3002\u8fd9\u4e9b\u7ed3\u679c\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u6570\u636e\u8bbe\u7f6e\uff0c\u800c\u4e0d\u4ec5\u4ec5\u5c40\u9650\u4e8e\u8fd1\u4f3c\u6b63\u4ea4\u6570\u636e\u3002"}}
{"id": "2505.16223", "pdf": "https://arxiv.org/pdf/2505.16223", "abs": "https://arxiv.org/abs/2505.16223", "authors": ["Sangyong Lee", "Subo Hwang", "Dohoon Kim"], "title": "MADCluster: Model-agnostic Anomaly Detection with Self-supervised Clustering Network", "categories": ["cs.AI", "cs.LG"], "comment": "24 pages, 9 figures", "summary": "In this paper, we propose MADCluster, a novel model-agnostic anomaly\ndetection framework utilizing self-supervised clustering. MADCluster is\napplicable to various deep learning architectures and addresses the\n'hypersphere collapse' problem inherent in existing deep learning-based anomaly\ndetection methods. The core idea is to cluster normal pattern data into a\n'single cluster' while simultaneously learning the cluster center and mapping\ndata close to this center. Also, to improve expressiveness and enable effective\nsingle clustering, we propose a new 'One-directed Adaptive loss'. The\noptimization of this loss is mathematically proven. MADCluster consists of\nthree main components: Base Embedder capturing high-dimensional temporal\ndynamics, Cluster Distance Mapping, and Sequence-wise Clustering for continuous\ncenter updates. Its model-agnostic characteristics are achieved by applying\nvarious architectures to the Base Embedder. Experiments on four time series\nbenchmark datasets demonstrate that applying MADCluster improves the overall\nperformance of comparative models. In conclusion, the compatibility of\nMADCluster shows potential for enhancing model performance across various\narchitectures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u65e0\u5173\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6MADCluster\uff0c\u5229\u7528\u81ea\u76d1\u7763\u805a\u7c7b\u89e3\u51b3\u4e86\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e2d\u7684'\u8d85\u7403\u4f53\u5d29\u6e83'\u95ee\u9898\u3002\u901a\u8fc7\u5355\u805a\u7c7b\u548c\u4e00\u79cd\u65b0\u63d0\u51fa\u7684'One-directed Adaptive loss'\uff0cMADCluster\u63d0\u9ad8\u4e86\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u5728\u56db\u4e2a\u65f6\u95f4\u5e8f\u5217\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728'\u8d85\u7403\u4f53\u5d29\u6e83'\u95ee\u9898\uff0c\u5373\u6b63\u5e38\u6570\u636e\u70b9\u88ab\u6620\u5c04\u5230\u4e00\u4e2a\u8fc7\u4e8e\u7d27\u5bc6\u7684\u533a\u57df\uff0c\u5bfc\u81f4\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u4e0b\u964d\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u5e76\u63d0\u9ad8\u6a21\u578b\u7684\u901a\u7528\u6027\uff0c\u63d0\u51fa\u4e86MADCluster\u6846\u67b6\u3002", "method": "MADCluster\u7531\u4e09\u4e2a\u4e3b\u8981\u90e8\u5206\u7ec4\u6210\uff1a\u6355\u83b7\u9ad8\u7ef4\u65f6\u5e8f\u52a8\u6001\u7684Base Embedder\u3001Cluster Distance Mapping\u4ee5\u53ca\u7528\u4e8e\u8fde\u7eed\u4e2d\u5fc3\u66f4\u65b0\u7684Sequence-wise Clustering\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570'One-directed Adaptive loss'\uff0c\u4ee5\u4f18\u5316\u5355\u805a\u7c7b\u7684\u6548\u679c\uff0c\u5e76\u4e14\u8be5\u635f\u5931\u51fd\u6570\u5177\u6709\u6570\u5b66\u8bc1\u660e\u7684\u4f18\u5316\u7279\u6027\u3002", "result": "\u5728\u56db\u4e2a\u65f6\u95f4\u5e8f\u5217\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5e94\u7528MADCluster\u53ef\u4ee5\u63d0\u5347\u6bd4\u8f83\u6a21\u578b\u7684\u6574\u4f53\u6027\u80fd\uff0c\u663e\u793a\u51fa\u5176\u4e0e\u4e0d\u540c\u67b6\u6784\u7684\u517c\u5bb9\u6027\u548c\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u589e\u5f3a\u6f5c\u529b\u3002", "conclusion": "MADCluster\u4f5c\u4e3a\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u5c55\u73b0\u4e86\u5728\u5404\u79cd\u67b6\u6784\u4e2d\u63d0\u5347\u6a21\u578b\u6027\u80fd\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u89e3\u51b3'\u8d85\u7403\u4f53\u5d29\u6e83'\u95ee\u9898\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2505.16126", "pdf": "https://arxiv.org/pdf/2505.16126", "abs": "https://arxiv.org/abs/2505.16126", "authors": ["Kotaro Yoshida", "Slavakis Konstantinos"], "title": "Robust Invariant Representation Learning by Distribution Extrapolation", "categories": ["cs.LG"], "comment": null, "summary": "Invariant risk minimization (IRM) aims to enable out-of-distribution (OOD)\ngeneralization in deep learning by learning invariant representations. As IRM\nposes an inherently challenging bi-level optimization problem, most existing\napproaches -- including IRMv1 -- adopt penalty-based single-level\napproximations. However, empirical studies consistently show that these methods\noften fail to outperform well-tuned empirical risk minimization (ERM),\nhighlighting the need for more robust IRM implementations. This work\ntheoretically identifies a key limitation common to many IRM variants: their\npenalty terms are highly sensitive to limited environment diversity and\nover-parameterization, resulting in performance degradation. To address this\nissue, a novel extrapolation-based framework is proposed that enhances\nenvironmental diversity by augmenting the IRM penalty through synthetic\ndistributional shifts. Extensive experiments -- ranging from synthetic setups\nto realistic, over-parameterized scenarios -- demonstrate that the proposed\nmethod consistently outperforms state-of-the-art IRM variants, validating its\neffectiveness and robustness.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u4e0d\u53d8\u98ce\u9669\u6700\u5c0f\u5316(IRM)\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\uff0c\u65e8\u5728\u901a\u8fc7\u5b66\u4e60\u4e0d\u53d8\u8868\u793a\u6765\u5b9e\u73b0\u5206\u5e03\u5916(OOD)\u6cdb\u5316\u3002\u7531\u4e8eIRM\u63d0\u51fa\u4e86\u4e00\u4e2a\u672c\u8d28\u4e0a\u5177\u6709\u6311\u6218\u6027\u7684\u53cc\u5c42\u4f18\u5316\u95ee\u9898\uff0c\u5927\u591a\u6570\u73b0\u6709\u7684\u65b9\u6cd5\uff08\u5305\u62ecIRMv1\uff09\u91c7\u7528\u4e86\u57fa\u4e8e\u60e9\u7f5a\u7684\u5355\u5c42\u8fd1\u4f3c\u3002\u7136\u800c\uff0c\u5b9e\u8bc1\u7814\u7a76\u4e00\u81f4\u8868\u660e\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u7ecf\u5e38\u65e0\u6cd5\u4f18\u4e8e\u8c03\u6574\u826f\u597d\u7684\u7ecf\u9a8c\u98ce\u9669\u6700\u5c0f\u5316(ERM)\uff0c\u5f3a\u8c03\u4e86\u5bf9\u66f4\u7a33\u5065\u7684IRM\u5b9e\u73b0\u7684\u9700\u6c42\u3002\u672c\u6587\u7406\u8bba\u4e0a\u786e\u5b9a\u4e86\u4e00\u4e2a\u5173\u952e\u9650\u5236\uff0c\u5373\u8bb8\u591aIRM\u53d8\u4f53\u7684\u60e9\u7f5a\u9879\u5bf9\u6709\u9650\u7684\u73af\u5883\u591a\u6837\u6027\u548c\u8fc7\u5ea6\u53c2\u6570\u5316\u975e\u5e38\u654f\u611f\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u5916\u63a8\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u5206\u5e03\u8f6c\u79fb\u589e\u5f3aIRM\u60e9\u7f5a\uff0c\u4ece\u800c\u63d0\u9ad8\u73af\u5883\u591a\u6837\u6027\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4ece\u5408\u6210\u8bbe\u7f6e\u5230\u73b0\u5b9e\u7684\u3001\u8fc7\u5ea6\u53c2\u6570\u5316\u7684\u573a\u666f\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684IRM\u53d8\u4f53\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u5c3d\u7ba1IRM\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5f80\u5f80\u4e0d\u80fd\u8d85\u8d8a\u826f\u597d\u8c03\u6574\u7684ERM\uff0c\u8fd9\u8868\u660e\u9700\u8981\u66f4\u7a33\u5065\u7684IRM\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u5916\u63a8\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5408\u6210\u5206\u5e03\u8f6c\u79fb\u589e\u5f3aIRM\u60e9\u7f5a\uff0c\u4ece\u800c\u63d0\u9ad8\u73af\u5883\u591a\u6837\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5404\u79cd\u573a\u666f\u4e0b\uff0c\u65b0\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u7684IRM\u53d8\u4f53\uff0c\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u901a\u8fc7\u589e\u5f3a\u73af\u5883\u591a\u6837\u6027\u548c\u51cf\u5c11\u5bf9\u6709\u9650\u591a\u6837\u6027\u548c\u8fc7\u5ea6\u53c2\u6570\u5316\u7684\u654f\u611f\u6027\uff0c\u63d0\u51fa\u7684\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u6709\u6548\u7684IRM\u65b9\u6cd5\u3002"}}
{"id": "2505.16363", "pdf": "https://arxiv.org/pdf/2505.16363", "abs": "https://arxiv.org/abs/2505.16363", "authors": ["Huishuai Zhang", "Bohan Wang", "Luoxin Chen"], "title": "AdamS: Momentum Itself Can Be A Normalizer for LLM Pretraining and Post-training", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "We introduce AdamS, a simple yet effective alternative to Adam for large\nlanguage model (LLM) pretraining and post-training. By leveraging a novel\ndenominator, i.e., the root of weighted sum of squares of the momentum and the\ncurrent gradient, AdamS eliminates the need for second-moment estimates. Hence,\nAdamS is efficient, matching the memory and compute footprint of SGD with\nmomentum while delivering superior optimization performance. Moreover, AdamS is\neasy to adopt: it can directly inherit hyperparameters of AdamW, and is\nentirely model-agnostic, integrating seamlessly into existing pipelines without\nmodifications to optimizer APIs or architectures. The motivation behind AdamS\nstems from the observed $(L_0, L_1)$ smoothness properties in transformer\nobjectives, where local smoothness is governed by gradient magnitudes that can\nbe further approximated by momentum magnitudes. We establish rigorous\ntheoretical convergence guarantees and provide practical guidelines for\nhyperparameter selection. Empirically, AdamS demonstrates strong performance in\nvarious tasks, including pre-training runs on GPT-2 and Llama2 (up to 13B\nparameters) and reinforcement learning in post-training regimes. With its\nefficiency, simplicity, and theoretical grounding, AdamS stands as a compelling\nalternative to existing optimizers.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAdamS\u7684\u65b0\u4f18\u5316\u5668\uff0c\u9002\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u548c\u540e\u8bad\u7ec3\u3002\u901a\u8fc7\u5229\u7528\u52a8\u91cf\u548c\u5f53\u524d\u68af\u5ea6\u5e73\u65b9\u52a0\u6743\u548c\u7684\u5e73\u65b9\u6839\u4f5c\u4e3a\u5206\u6bcd\uff0cAdamS\u6d88\u9664\u4e86\u5bf9\u4e8c\u9636\u77e9\u4f30\u8ba1\u7684\u9700\u6c42\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u4e0e\u5e26\u52a8\u91cf\u7684SGD\u76f8\u540c\u5185\u5b58\u548c\u8ba1\u7b97\u6d88\u8017\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u4f9b\u4e86\u4f18\u8d8a\u7684\u4f18\u5316\u6027\u80fd\u3002AdamS\u7ee7\u627f\u4e86AdamW\u7684\u8d85\u53c2\u6570\uff0c\u65e0\u9700\u4fee\u6539\u4f18\u5316\u5668API\u6216\u67b6\u6784\u5373\u53ef\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u7ba1\u9053\u4e2d\u3002\u5b9e\u9a8c\u8868\u660e\uff0cAdamS\u5728GPT-2\u548cLlama2\u7b49\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5728Transformer\u76ee\u6807\u51fd\u6570\u4e2d\u89c2\u5bdf\u5230\u7684(L0, L1)\u5e73\u6ed1\u6027\u5c5e\u6027\u662fAdamS\u7684\u51fa\u53d1\u70b9\uff0c\u5176\u4e2d\u5c40\u90e8\u5e73\u6ed1\u6027\u7531\u68af\u5ea6\u5927\u5c0f\u51b3\u5b9a\uff0c\u8fd9\u4e9b\u68af\u5ea6\u5927\u5c0f\u53ef\u4ee5\u8fdb\u4e00\u6b65\u7528\u52a8\u91cf\u5927\u5c0f\u8fd1\u4f3c\u3002", "method": "AdamS\u91c7\u7528\u52a8\u91cf\u548c\u5f53\u524d\u68af\u5ea6\u5e73\u65b9\u52a0\u6743\u548c\u7684\u5e73\u65b9\u6839\u4f5c\u4e3a\u5206\u6bcd\uff0c\u53bb\u9664\u4e86\u5bf9\u4e8c\u9636\u77e9\u4f30\u8ba1\u7684\u9700\u6c42\uff0c\u5e76\u4e14\u53ef\u4ee5\u76f4\u63a5\u7ee7\u627fAdamW\u7684\u8d85\u53c2\u6570\u3002\u5b83\u4e0e\u6a21\u578b\u65e0\u5173\uff0c\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u7ba1\u9053\u4e2d\uff0c\u65e0\u9700\u4fee\u6539\u4f18\u5316\u5668API\u6216\u67b6\u6784\u3002", "result": "AdamS\u5728\u5305\u62ecGPT-2\u548cLlama2\uff08\u9ad8\u8fbe13B\u53c2\u6570\uff09\u5728\u5185\u7684\u5404\u79cd\u4efb\u52a1\u4e0a\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u5305\u62ec\u9884\u8bad\u7ec3\u548c\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u540e\u8bad\u7ec3\u9636\u6bb5\u3002", "conclusion": "AdamS\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u5668\uff0c\u5177\u6709\u9ad8\u6548\u6027\u3001\u7b80\u5355\u6027\u548c\u7406\u8bba\u4f9d\u636e\uff0c\u6210\u4e3a\u73b0\u6709\u4f18\u5316\u5668\u7684\u4e00\u4e2a\u6709\u5438\u5f15\u529b\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2505.16225", "pdf": "https://arxiv.org/pdf/2505.16225", "abs": "https://arxiv.org/abs/2505.16225", "authors": ["Zihan Chen", "Song Wang", "Zhen Tan", "Jundong Li", "Cong Shen"], "title": "MAPLE: Many-Shot Adaptive Pseudo-Labeling for In-Context Learning", "categories": ["cs.AI"], "comment": null, "summary": "In-Context Learning (ICL) empowers Large Language Models (LLMs) to tackle\ndiverse tasks by incorporating multiple input-output examples, known as\ndemonstrations, into the input of LLMs. More recently, advancements in the\nexpanded context windows of LLMs have led to many-shot ICL, which uses hundreds\nof demonstrations and outperforms few-shot ICL, which relies on fewer examples.\nHowever, this approach is often hindered by the high cost of obtaining large\namounts of labeled data. To address this challenge, we propose Many-Shot\nAdaptive Pseudo-LabEling, namely MAPLE, a novel influence-based many-shot ICL\nframework that utilizes pseudo-labeled samples to compensate for the lack of\nlabel information. We first identify a subset of impactful unlabeled samples\nand perform pseudo-labeling on them by querying LLMs. These pseudo-labeled\nsamples are then adaptively selected and tailored to each test query as input\nto improve the performance of many-shot ICL, without significant labeling\ncosts. Extensive experiments on real-world datasets demonstrate the\neffectiveness of our framework, showcasing its ability to enhance LLM\nadaptability and performance with limited labeled data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMAPLE\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u4f2a\u6807\u8bb0\u6837\u672c\u6765\u51cf\u5c11\u5bf9\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u9700\u6c42\uff0c\u4ece\u800c\u63d0\u5347\u591a\u793a\u4f8b\u60c5\u5883\u5b66\u4e60\uff08many-shot ICL\uff09\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u591a\u793a\u4f8b\u60c5\u5883\u5b66\u4e60\uff08many-shot ICL\uff09\u76f8\u8f83\u4e8e\u5c11\u793a\u4f8b\u60c5\u5883\u5b66\u4e60\uff08few-shot ICL\uff09\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u5176\u53d7\u9650\u4e8e\u83b7\u53d6\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u9ad8\u6210\u672c\u95ee\u9898\u3002", "method": "MAPLE\u9996\u5148\u8bc6\u522b\u51fa\u6709\u5f71\u54cd\u529b\u7684\u672a\u6807\u6ce8\u6837\u672c\u5b50\u96c6\uff0c\u5e76\u901a\u8fc7\u67e5\u8be2\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5bf9\u5176\u8fdb\u884c\u4f2a\u6807\u8bb0\u3002\u7136\u540e\uff0c\u8fd9\u4e9b\u4f2a\u6807\u8bb0\u6837\u672c\u88ab\u81ea\u9002\u5e94\u5730\u9009\u62e9\u548c\u8c03\u6574\uff0c\u4ee5\u9002\u914d\u6bcf\u4e2a\u6d4b\u8bd5\u67e5\u8be2\uff0c\u4f5c\u4e3a\u8f93\u5165\u6765\u63d0\u9ad8\u591a\u793a\u4f8b\u60c5\u5883\u5b66\u4e60\u7684\u6027\u80fd\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u6709\u9650\u6807\u6ce8\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u80fd\u591f\u6709\u6548\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9002\u5e94\u6027\u548c\u6027\u80fd\u3002", "conclusion": "MAPLE\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u514b\u670d\u591a\u793a\u4f8b\u60c5\u5883\u5b66\u4e60\u4e2d\u5bf9\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u9700\u6c42\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2505.16130", "pdf": "https://arxiv.org/pdf/2505.16130", "abs": "https://arxiv.org/abs/2505.16130", "authors": ["Zehong Wang", "Zheyuan Zhang", "Tianyi Ma", "Chuxu Zhang", "Yanfang Ye"], "title": "Scalable Graph Generative Modeling via Substructure Sequences", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": null, "summary": "Graph neural networks (GNNs) has been predominantly driven by\nmessage-passing, where node representations are iteratively updated via local\nneighborhood aggregation. Despite their success, message-passing suffers from\nfundamental limitations -- including constrained expressiveness,\nover-smoothing, over-squashing, and limited capacity to model long-range\ndependencies. These issues hinder scalability: increasing data size or model\nsize often fails to yield improved performance, limiting the viability of GNNs\nas backbones for graph foundation models. In this work, we explore pathways\nbeyond message-passing and introduce Generative Graph Pattern Machine\n(G$^2$PM), a generative Transformer pre-training framework for graphs. G$^2$PM\nrepresents graph instances (nodes, edges, or entire graphs) as sequences of\nsubstructures, and employs generative pre-training over the sequences to learn\ngeneralizable, transferable representations. Empirically, G$^2$PM demonstrates\nstrong scalability: on the ogbn-arxiv benchmark, it continues to improve with\nmodel sizes up to 60M parameters, outperforming prior generative approaches\nthat plateau at significantly smaller scales (e.g., 3M). In addition, we\nsystematically analyze the model design space, highlighting key architectural\nchoices that contribute to its scalability and generalization. Across diverse\ntasks -- including node classification, graph classification, and transfer\nlearning -- G$^2$PM consistently outperforms strong baselines, establishing a\ncompelling foundation for scalable graph learning. The code and dataset are\navailable at https://github.com/Zehong-Wang/G2PM.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8d85\u8d8a\u6d88\u606f\u4f20\u9012\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u540d\u4e3a\u751f\u6210\u5f0f\u56fe\u6a21\u5f0f\u673a\uff08G\u00b2PM\uff09\uff0c\u5b83\u5229\u7528Transformer\u9884\u8bad\u7ec3\u6846\u67b6\u5c06\u56fe\u5b9e\u4f8b\u8868\u793a\u4e3a\u5b50\u7ed3\u6784\u5e8f\u5217\uff0c\u5e76\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u53ef\u6269\u5c55\u6027\u548c\u4f18\u4e8e\u5148\u524d\u751f\u6210\u65b9\u6cd5\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6d88\u606f\u4f20\u9012\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u5c3d\u7ba1\u6210\u529f\uff0c\u4f46\u5b58\u5728\u8868\u8fbe\u80fd\u529b\u53d7\u9650\u3001\u8fc7\u5e73\u6ed1\u3001\u8fc7\u5ea6\u538b\u7f29\u4ee5\u53ca\u96be\u4ee5\u5efa\u6a21\u957f\u8ddd\u79bb\u4f9d\u8d56\u7b49\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86\u5176\u53ef\u6269\u5c55\u6027\u3002", "method": "G\u00b2PM\u5c06\u56fe\u5b9e\u4f8b\uff08\u8282\u70b9\u3001\u8fb9\u6216\u6574\u4e2a\u56fe\uff09\u8868\u793a\u4e3a\u5b50\u7ed3\u6784\u5e8f\u5217\uff0c\u5e76\u901a\u8fc7\u5728\u8fd9\u4e9b\u5e8f\u5217\u4e0a\u8fdb\u884c\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u6765\u5b66\u4e60\u53ef\u6cdb\u5316\u548c\u53ef\u8fc1\u79fb\u7684\u8868\u793a\u3002\u6b64\u65b9\u6cd5\u4f7f\u7528\u4e86\u4e00\u4e2aTransformer\u9884\u8bad\u7ec3\u6846\u67b6\u3002", "result": "G\u00b2PM\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5728ogbn-arxiv\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6a21\u578b\u53c2\u6570\u91cf\u8fbe\u523060M\u65f6\u6027\u80fd\u6301\u7eed\u63d0\u5347\uff0c\u4f18\u4e8e\u5148\u524d\u5728\u66f4\u5c0f\u89c4\u6a21\uff08\u59823M\u53c2\u6570\uff09\u5c31\u8fbe\u5230\u6027\u80fd\u4e0a\u9650\u7684\u751f\u6210\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u5728\u5305\u62ec\u8282\u70b9\u5206\u7c7b\u3001\u56fe\u5206\u7c7b\u548c\u8fc1\u79fb\u5b66\u4e60\u5728\u5185\u7684\u591a\u79cd\u4efb\u52a1\u4e2d\uff0cG\u00b2PM\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u5927\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "G\u00b2PM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u8bf4\u670d\u529b\u7684\u57fa\u7840\uff0c\u7528\u4e8e\u53ef\u6269\u5c55\u7684\u56fe\u5b66\u4e60\uff0c\u5e76\u4e14\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5728GitHub\u4e0a\u516c\u5f00\u3002"}}
{"id": "2505.16481", "pdf": "https://arxiv.org/pdf/2505.16481", "abs": "https://arxiv.org/abs/2505.16481", "authors": ["Xinxing Shi", "Xiaoyu Jiang", "Mauricio A. \u00c1lvarez"], "title": "Neighbour-Driven Gaussian Process Variational Autoencoders for Scalable Structured Latent Modelling", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Gaussian Process (GP) Variational Autoencoders (VAEs) extend standard VAEs by\nreplacing the fully factorised Gaussian prior with a GP prior, thereby\ncapturing richer correlations among latent variables. However, performing exact\nGP inference in large-scale GPVAEs is computationally prohibitive, often\nforcing existing approaches to rely on restrictive kernel assumptions or large\nsets of inducing points. In this work, we propose a neighbour-driven\napproximation strategy that exploits local adjacencies in the latent space to\nachieve scalable GPVAE inference. By confining computations to the nearest\nneighbours of each data point, our method preserves essential latent\ndependencies, allowing more flexible kernel choices and mitigating the need for\nnumerous inducing points. Through extensive experiments on tasks including\nrepresentation learning, data imputation, and conditional generation, we\ndemonstrate that our approach outperforms other GPVAE variants in both\npredictive performance and computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u90bb\u5c45\u9a71\u52a8\u7684\u8fd1\u4f3c\u7b56\u7565\u6765\u5b9e\u73b0\u53ef\u6269\u5c55\u7684GPVAE\u63a8\u7406\uff0c\u901a\u8fc7\u9650\u5236\u5728\u6bcf\u4e2a\u6570\u636e\u70b9\u7684\u6700\u8fd1\u90bb\u8fdb\u884c\u8ba1\u7b97\uff0c\u4fdd\u7559\u4e86\u5173\u952e\u7684\u6f5c\u5728\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u5141\u8bb8\u66f4\u7075\u6d3b\u7684\u6838\u9009\u62e9\u548c\u51cf\u5c11\u5bf9\u5927\u91cf\u8bf1\u5bfc\u70b9\u7684\u9700\u6c42\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u5176\u4ed6GPVAE\u53d8\u4f53\u3002", "motivation": "\u9ad8\u65af\u8fc7\u7a0b\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08GPVAEs\uff09\u901a\u8fc7\u7528GP\u5148\u9a8c\u66ff\u4ee3\u5b8c\u5168\u56e0\u5b50\u5316\u7684\u9ad8\u65af\u5148\u9a8c\uff0c\u6355\u6349\u6f5c\u5728\u53d8\u91cf\u4e4b\u95f4\u7684\u66f4\u4e30\u5bcc\u7684\u76f8\u5173\u6027\u3002\u7136\u800c\uff0c\u5728\u5927\u89c4\u6a21GPVAEs\u4e2d\u8fdb\u884c\u7cbe\u786e\u7684GP\u63a8\u7406\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u9650\u5236\u6027\u7684\u6838\u5047\u8bbe\u6216\u5927\u91cf\u7684\u8bf1\u5bfc\u70b9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u90bb\u5c45\u9a71\u52a8\u7684\u8fd1\u4f3c\u7b56\u7565\uff0c\u5229\u7528\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u5c40\u90e8\u90bb\u63a5\u6027\uff0c\u5c06\u8ba1\u7b97\u9650\u5236\u5728\u6bcf\u4e2a\u6570\u636e\u70b9\u7684\u6700\u8fd1\u90bb\uff0c\u4ece\u800c\u5b9e\u73b0\u53ef\u6269\u5c55\u7684GPVAE\u63a8\u7406\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u5305\u62ec\u8868\u793a\u5b66\u4e60\u3001\u6570\u636e\u63d2\u8865\u548c\u6761\u4ef6\u751f\u6210\u4efb\u52a1\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6GPVAE\u53d8\u4f53\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u90bb\u5c45\u9a71\u52a8\u8fd1\u4f3c\u7b56\u7565\u5728GPVAE\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u6548\u7387\uff0c\u540c\u65f6\u5141\u8bb8\u66f4\u7075\u6d3b\u7684\u6838\u9009\u62e9\u5e76\u51cf\u5c11\u4e86\u5bf9\u5927\u91cf\u8bf1\u5bfc\u70b9\u7684\u9700\u6c42\u3002"}}
{"id": "2505.16276", "pdf": "https://arxiv.org/pdf/2505.16276", "abs": "https://arxiv.org/abs/2505.16276", "authors": ["Desiree Heim", "Lars-Peter Meyer", "Markus Schr\u00f6der", "Johannes Frey", "Andreas Dengel"], "title": "How do Scaling Laws Apply to Knowledge Graph Engineering Tasks? The Impact of Model Size on Large Language Model Performance", "categories": ["cs.AI", "cs.CL"], "comment": "Peer reviewed and to appear in the ESWC 2025 Workshops and Tutorials\n  Joint Proceedings (Workshop on Evaluation of Language Models in Knowledge\n  Engineering [ELMKE])", "summary": "When using Large Language Models (LLMs) to support Knowledge Graph\nEngineering (KGE), one of the first indications when searching for an\nappropriate model is its size. According to the scaling laws, larger models\ntypically show higher capabilities. However, in practice, resource costs are\nalso an important factor and thus it makes sense to consider the ratio between\nmodel performance and costs. The LLM-KG-Bench framework enables the comparison\nof LLMs in the context of KGE tasks and assesses their capabilities of\nunderstanding and producing KGs and KG queries. Based on a dataset created in\nan LLM-KG-Bench run covering 26 open state-of-the-art LLMs, we explore the\nmodel size scaling laws specific to KGE tasks. In our analyses, we assess how\nbenchmark scores evolve between different model size categories. Additionally,\nwe inspect how the general score development of single models and families of\nmodels correlates to their size. Our analyses revealed that, with a few\nexceptions, the model size scaling laws generally also apply to the selected\nKGE tasks. However, in some cases, plateau or ceiling effects occurred, i.e.,\nthe task performance did not change much between a model and the next larger\nmodel. In these cases, smaller models could be considered to achieve high\ncost-effectiveness. Regarding models of the same family, sometimes larger\nmodels performed worse than smaller models of the same family. These effects\noccurred only locally. Hence it is advisable to additionally test the next\nsmallest and largest model of the same family.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u77e5\u8bc6\u56fe\u8c31\u5de5\u7a0b\uff08KGE\uff09\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4e0e\u6a21\u578b\u5927\u5c0f\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u901a\u8fc7LKM-KG-Bench\u6846\u67b6\uff0c\u4f5c\u8005\u8bc4\u4f30\u4e8626\u4e2a\u5f00\u6e90LLMs\u5728\u7406\u89e3\u548c\u751f\u6210\u77e5\u8bc6\u56fe\u8c31\u53ca\u67e5\u8be2\u65b9\u9762\u7684\u6027\u80fd\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u901a\u5e38\u8f83\u5927\u7684\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u5b58\u5728\u6027\u80fd\u5e73\u7a33\u6216\u4e0a\u9650\u6548\u5e94\uff0c\u8fd9\u8868\u660e\u8f83\u5c0f\u7684\u6a21\u578b\u53ef\u80fd\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u5177\u6709\u66f4\u9ad8\u7684\u6210\u672c\u6548\u76ca\u3002\u5bf9\u4e8e\u540c\u4e00\u6a21\u578b\u5bb6\u65cf\uff0c\u6709\u65f6\u8f83\u5927\u7684\u6a21\u578b\u8868\u73b0\u4e0d\u5982\u8f83\u5c0f\u7684\u6a21\u578b\uff0c\u56e0\u6b64\u5efa\u8bae\u6d4b\u8bd5\u76f8\u90bb\u5927\u5c0f\u7684\u6a21\u578b\u4ee5\u83b7\u5f97\u6700\u4f73\u6548\u679c\u3002", "motivation": "\u4e86\u89e3LLMs\u7684\u5927\u5c0f\u4e0e\u5176\u5728KGE\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u4fbf\u5728\u8d44\u6e90\u6210\u672c\u548c\u6027\u80fd\u4e4b\u95f4\u627e\u5230\u6700\u4f73\u5e73\u8861\u3002", "method": "\u4f7f\u7528LKM-KG-Bench\u6846\u67b6\u5bf926\u4e2a\u5f00\u6e90LLMs\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5206\u6790\u4e0d\u540c\u6a21\u578b\u5927\u5c0f\u7c7b\u522b\u7684\u57fa\u51c6\u5206\u6570\u53d8\u5316\uff0c\u5e76\u68c0\u67e5\u5355\u4e2a\u6a21\u578b\u548c\u6a21\u578b\u5bb6\u65cf\u7684\u5206\u6570\u53d1\u5c55\u4e0e\u5927\u5c0f\u7684\u76f8\u5173\u6027\u3002", "result": "\u5927\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u8f83\u5927\u7684\u6a21\u578b\u5728KGE\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\uff0c\u4f46\u5b58\u5728\u6027\u80fd\u5e73\u7a33\u6216\u4e0a\u9650\u6548\u5e94\u7684\u60c5\u51b5\u3002\u6b64\u5916\uff0c\u540c\u4e00\u6a21\u578b\u5bb6\u65cf\u4e2d\uff0c\u6709\u65f6\u8f83\u5927\u7684\u6a21\u578b\u8868\u73b0\u4e0d\u5982\u8f83\u5c0f\u7684\u6a21\u578b\u3002", "conclusion": "\u5728\u9009\u62e9\u7528\u4e8eKGE\u4efb\u52a1\u7684LLM\u65f6\uff0c\u5e94\u8003\u8651\u6a21\u578b\u5927\u5c0f\u4e0e\u6027\u80fd\u7684\u5173\u7cfb\uff0c\u540c\u65f6\u6ce8\u610f\u53ef\u80fd\u5b58\u5728\u6027\u80fd\u5e73\u7a33\u6216\u4e0a\u9650\u6548\u5e94\u7684\u60c5\u51b5\u3002\u5efa\u8bae\u6d4b\u8bd5\u76f8\u90bb\u5927\u5c0f\u7684\u6a21\u578b\u4ee5\u83b7\u5f97\u6700\u4f73\u6548\u679c\u3002"}}
{"id": "2505.16138", "pdf": "https://arxiv.org/pdf/2505.16138", "abs": "https://arxiv.org/abs/2505.16138", "authors": ["Heqiang Wang", "Xiang Liu", "Xiaoxiong Zhong", "Lixing Chen", "Fangming Liu", "Weizhe Zhang"], "title": "Multimodal Online Federated Learning with Modality Missing in Internet of Things", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "The Internet of Things (IoT) ecosystem generates vast amounts of multimodal\ndata from heterogeneous sources such as sensors, cameras, and microphones. As\nedge intelligence continues to evolve, IoT devices have progressed from simple\ndata collection units to nodes capable of executing complex computational\ntasks. This evolution necessitates the adoption of distributed learning\nstrategies to effectively handle multimodal data in an IoT environment.\nFurthermore, the real-time nature of data collection and limited local storage\non edge devices in IoT call for an online learning paradigm. To address these\nchallenges, we introduce the concept of Multimodal Online Federated Learning\n(MMO-FL), a novel framework designed for dynamic and decentralized multimodal\nlearning in IoT environments. Building on this framework, we further account\nfor the inherent instability of edge devices, which frequently results in\nmissing modalities during the learning process. We conduct a comprehensive\ntheoretical analysis under both complete and missing modality scenarios,\nproviding insights into the performance degradation caused by missing\nmodalities. To mitigate the impact of modality missing, we propose the\nPrototypical Modality Mitigation (PMM) algorithm, which leverages prototype\nlearning to effectively compensate for missing modalities. Experimental results\non two multimodal datasets further demonstrate the superior performance of PMM\ncompared to benchmarks.", "AI": {"tldr": "The paper introduces Multimodal Online Federated Learning (MMO-FL) and Prototypical Modality Mitigation (PMM) to address challenges in handling multimodal data with missing modalities in IoT environments.", "motivation": "IoT devices generate vast amounts of multimodal data, necessitating advanced computational capabilities and distributed learning strategies. The real-time nature and storage limitations of edge devices call for an online learning paradigm.", "method": "The authors propose MMO-FL for decentralized multimodal learning and PMM algorithm to mitigate the impact of missing modalities by leveraging prototype learning.", "result": "Experimental results on two multimodal datasets show that PMM outperforms benchmarks in compensating for missing modalities.", "conclusion": "MMO-FL and PMM provide effective solutions for managing multimodal data with missing modalities in IoT environments."}}
{"id": "2505.16548", "pdf": "https://arxiv.org/pdf/2505.16548", "abs": "https://arxiv.org/abs/2505.16548", "authors": ["Lucas Maystre", "Gabriel Barello", "Tudor Berariu", "Aleix Cambray", "Rares Dolga", "Alvaro Ortega Gonzalez", "Andrei Nica", "David Barber"], "title": "Incremental Sequence Classification with Temporal Consistency", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "We address the problem of incremental sequence classification, where\npredictions are updated as new elements in the sequence are revealed. Drawing\non temporal-difference learning from reinforcement learning, we identify a\ntemporal-consistency condition that successive predictions should satisfy. We\nleverage this condition to develop a novel loss function for training\nincremental sequence classifiers. Through a concrete example, we demonstrate\nthat optimizing this loss can offer substantial gains in data efficiency. We\napply our method to text classification tasks and show that it improves\npredictive accuracy over competing approaches on several benchmark datasets. We\nfurther evaluate our approach on the task of verifying large language model\ngenerations for correctness in grade-school math problems. Our results show\nthat models trained with our method are better able to distinguish promising\ngenerations from unpromising ones after observing only a few tokens.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86\u589e\u91cf\u5e8f\u5217\u5206\u7c7b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65f6\u95f4\u5dee\u5206\u5b66\u4e60\u7684\u65f6\u5e8f\u4e00\u81f4\u6027\u6761\u4ef6\uff0c\u5e76\u636e\u6b64\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570\u4ee5\u63d0\u5347\u8bad\u7ec3\u6548\u7387\u548c\u9884\u6d4b\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u53ca\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7ed3\u679c\u9a8c\u8bc1\u4e2d\u5747\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u589e\u91cf\u5e8f\u5217\u5206\u7c7b\u7814\u7a76\u4e2d\u7f3a\u4e4f\u5bf9\u9884\u6d4b\u7ed3\u679c\u65f6\u5e8f\u4e00\u81f4\u6027\u7684\u5145\u5206\u8003\u8651\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6570\u636e\u5229\u7528\u6548\u7387\u4f4e\u4e0b\u4ee5\u53ca\u9884\u6d4b\u6027\u80fd\u4e0d\u8db3\u3002", "method": "\u53d7\u5f3a\u5316\u5b66\u4e60\u4e2d\u65f6\u95f4\u5dee\u5206\u5b66\u4e60\u7684\u542f\u53d1\uff0c\u8bc6\u522b\u51fa\u4e00\u79cd\u65f6\u5e8f\u4e00\u81f4\u6027\u6761\u4ef6\uff0c\u8981\u6c42\u8fde\u7eed\u9884\u6d4b\u7ed3\u679c\u6ee1\u8db3\u8fd9\u4e00\u6761\u4ef6\u3002\u57fa\u4e8e\u6b64\u6761\u4ef6\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570\uff0c\u7528\u4e8e\u8bad\u7ec3\u589e\u91cf\u5e8f\u5217\u5206\u7c7b\u5668\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u8f83\u4e8e\u5176\u4ed6\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff1b\u5728\u9a8c\u8bc1\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u5c0f\u5b66\u6570\u5b66\u9898\u7b54\u6848\u6b63\u786e\u6027\u4efb\u52a1\u4e2d\uff0c\u4ec5\u9700\u89c2\u5bdf\u5c11\u6570\u6807\u8bb0\u5373\u53ef\u66f4\u6709\u6548\u5730\u533a\u5206\u6709\u6f5c\u529b\u548c\u65e0\u6f5c\u529b\u7684\u751f\u6210\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u65f6\u5e8f\u4e00\u81f4\u6027\u6761\u4ef6\u53ca\u5176\u5bf9\u5e94\u7684\u635f\u5931\u51fd\u6570\u80fd\u591f\u6709\u6548\u63d0\u5347\u589e\u91cf\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u7684\u6570\u636e\u6548\u7387\u548c\u9884\u6d4b\u6027\u80fd\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u9700\u8981\u5b9e\u65f6\u66f4\u65b0\u9884\u6d4b\u7ed3\u679c\u7684\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2505.16288", "pdf": "https://arxiv.org/pdf/2505.16288", "abs": "https://arxiv.org/abs/2505.16288", "authors": ["Xiaoxue Han", "Pengfei Hu", "Jun-En Ding", "Chang Lu", "Feng Liu", "Yue Ning"], "title": "No Black Boxes: Interpretable and Interactable Predictive Healthcare with Knowledge-Enhanced Agentic Causal Discovery", "categories": ["cs.AI"], "comment": null, "summary": "Deep learning models trained on extensive Electronic Health Records (EHR)\ndata have achieved high accuracy in diagnosis prediction, offering the\npotential to assist clinicians in decision-making and treatment planning.\nHowever, these models lack two crucial features that clinicians highly value:\ninterpretability and interactivity. The ``black-box'' nature of these models\nmakes it difficult for clinicians to understand the reasoning behind\npredictions, limiting their ability to make informed decisions. Additionally,\nthe absence of interactive mechanisms prevents clinicians from incorporating\ntheir own knowledge and experience into the decision-making process. To address\nthese limitations, we propose II-KEA, a knowledge-enhanced agent-driven causal\ndiscovery framework that integrates personalized knowledge databases and\nagentic LLMs. II-KEA enhances interpretability through explicit reasoning and\ncausal analysis, while also improving interactivity by allowing clinicians to\ninject their knowledge and experience through customized knowledge bases and\nprompts. II-KEA is evaluated on both MIMIC-III and MIMIC-IV, demonstrating\nsuperior performance along with enhanced interpretability and interactivity, as\nevidenced by its strong results from extensive case studies.", "AI": {"tldr": "Deep learning models for diagnosis prediction lack interpretability and interactivity. II-KEA, a new framework, addresses these issues by integrating personalized knowledge databases and agentic LLMs, demonstrating superior performance in case studies on MIMIC-III and MIMIC-IV.", "motivation": "Despite high accuracy in diagnosis prediction, deep learning models lack interpretability and interactivity, which are crucial for clinical decision-making.", "method": "II-KEA integrates personalized knowledge databases and agentic LLMs to enhance both interpretability through explicit reasoning and causal analysis, and interactivity by allowing clinicians to inject their knowledge and experience.", "result": "II-KEA was evaluated on MIMIC-III and MIMIC-IV, showing superior performance with enhanced interpretability and interactivity.", "conclusion": "II-KEA addresses the limitations of current deep learning models in clinical applications by improving interpretability and interactivity."}}
{"id": "2505.16148", "pdf": "https://arxiv.org/pdf/2505.16148", "abs": "https://arxiv.org/abs/2505.16148", "authors": ["Chongjie Si", "Kangtao Lv", "Jingjing Jiang", "Yadao Wang", "Yongwei Wang", "Xiaokang Yang", "Wenbo Su", "Bo Zheng", "Wei Shen"], "title": "NAN: A Training-Free Solution to Coefficient Estimation in Model Merging", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Model merging offers a training-free alternative to multi-task learning by\ncombining independently fine-tuned models into a unified one without access to\nraw data. However, existing approaches often rely on heuristics to determine\nthe merging coefficients, limiting their scalability and generality. In this\nwork, we revisit model merging through the lens of least-squares optimization\nand show that the optimal merging weights should scale with the amount of\ntask-specific information encoded in each model. Based on this insight, we\npropose NAN, a simple yet effective method that estimates model merging\ncoefficients via the inverse of parameter norm. NAN is training-free,\nplug-and-play, and applicable to a wide range of merging strategies. Extensive\nexperiments on show that NAN consistently improves performance of baseline\nmethods.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNAN\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u6a21\u578b\u5408\u5e76\u7684\u7cfb\u6570\u4f30\u8ba1\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u53c2\u6570\u8303\u6570\u7684\u9006\uff0c\u5e76\u4e14\u65e0\u9700\u8bad\u7ec3\u3001\u53ef\u5373\u63d2\u5373\u7528\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5408\u5e76\u7b56\u7565\u3002\u5b9e\u9a8c\u8868\u660e\uff0cNAN\u80fd\u591f\u6301\u7eed\u63d0\u5347\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u542f\u53d1\u5f0f\u7b97\u6cd5\u6765\u786e\u5b9a\u5408\u5e76\u7cfb\u6570\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u53ef\u6269\u5c55\u6027\u548c\u901a\u7528\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7cfb\u7edf\u5316\u7684\u65b9\u6cd5\u6765\u4f18\u5316\u6a21\u578b\u5408\u5e76\u7684\u6743\u91cd\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u6700\u5c0f\u4e8c\u4e58\u4f18\u5316\u7684\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u6a21\u578b\u5408\u5e76\u95ee\u9898\uff0c\u53d1\u73b0\u6700\u4f73\u7684\u5408\u5e76\u6743\u91cd\u5e94\u4e0e\u6bcf\u4e2a\u6a21\u578b\u4e2d\u7f16\u7801\u7684\u4efb\u52a1\u7279\u5b9a\u4fe1\u606f\u91cf\u6210\u6bd4\u4f8b\u3002\u57fa\u4e8e\u8fd9\u4e00\u89c2\u5bdf\uff0c\u63d0\u51fa\u4e86NAN\u65b9\u6cd5\uff0c\u5229\u7528\u53c2\u6570\u8303\u6570\u7684\u9006\u6765\u4f30\u8ba1\u6a21\u578b\u5408\u5e76\u7cfb\u6570\u3002", "result": "\u5728\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u4e2d\uff0cNAN\u65b9\u6cd5\u88ab\u8bc1\u660e\u80fd\u591f\u6301\u7eed\u63d0\u5347\u5404\u79cd\u57fa\u7ebf\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "NAN\u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u5373\u63d2\u5373\u7528\uff0c\u5e76\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u6a21\u578b\u5408\u5e76\u7b56\u7565\u3002"}}
{"id": "2505.16638", "pdf": "https://arxiv.org/pdf/2505.16638", "abs": "https://arxiv.org/abs/2505.16638", "authors": ["Benedikt H\u00f6ltgen", "Nuria Oliver"], "title": "Reconsidering Fairness Through Unawareness from the Perspective of Model Multiplicity", "categories": ["cs.LG", "cs.CY", "stat.ML"], "comment": null, "summary": "Fairness through Unawareness (FtU) describes the idea that discrimination\nagainst demographic groups can be avoided by not considering group membership\nin the decisions or predictions. This idea has long been criticized in the\nmachine learning literature as not being sufficient to ensure fairness. In\naddition, the use of additional features is typically thought to increase the\naccuracy of the predictions for all groups, so that FtU is sometimes thought to\nbe detrimental to all groups. In this paper, we show both theoretically and\nempirically that FtU can reduce algorithmic discrimination without necessarily\nreducing accuracy. We connect this insight with the literature on Model\nMultiplicity, to which we contribute with novel theoretical and empirical\nresults. Furthermore, we illustrate how, in a real-life application, FtU can\ncontribute to the deployment of more equitable policies without losing\nefficacy. Our findings suggest that FtU is worth considering in practical\napplications, particularly in high-risk scenarios, and that the use of\nprotected attributes such as gender in predictive models should be accompanied\nby a clear and well-founded justification.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86\u901a\u8fc7\u65e0\u610f\u8bc6(FtU)\u65b9\u6cd5\u5728\u4e0d\u5fc5\u7136\u964d\u4f4e\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u51cf\u5c11\u7b97\u6cd5\u6b67\u89c6\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u7ed3\u5408\u6a21\u578b\u591a\u91cd\u6027\u7406\u8bba\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u5f3a\u8c03\u4e86\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u8003\u8651FtU\u7684\u4ef7\u503c\u3002", "motivation": "\u5c3d\u7ba1Fairness through Unawareness (FtU)\u957f\u671f\u4ee5\u6765\u88ab\u8ba4\u4e3a\u4e0d\u8db3\u4ee5\u786e\u4fdd\u516c\u5e73\u6027\uff0c\u4f46\u4f5c\u8005\u8bd5\u56fe\u91cd\u65b0\u8bc4\u4f30\u8fd9\u4e00\u65b9\u6cd5\uff0c\u8bc1\u660e\u5176\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u7b97\u6cd5\u6b67\u89c6\u800c\u4e0d\u727a\u7272\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7814\u7a76\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\uff0c\u8bc4\u4f30\u4e86FtU\u5bf9\u7b97\u6cd5\u516c\u5e73\u6027\u548c\u51c6\u786e\u6027\u7684\u53cc\u91cd\u5f71\u54cd\uff0c\u5e76\u5c06\u5176\u4e0e\u6a21\u578b\u591a\u91cd\u6027\uff08Model Multiplicity\uff09\u7406\u8bba\u8054\u7cfb\u8d77\u6765\u3002\u6b64\u5916\uff0c\u8fd8\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u5c55\u793a\u4e86FtU\u5728\u653f\u7b56\u5236\u5b9a\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cFtU\u53ef\u4ee5\u5728\u4e0d\u663e\u8457\u964d\u4f4e\u9884\u6d4b\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u51cf\u5c11\u7b97\u6cd5\u6b67\u89c6\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5e94\u8c28\u614e\u4f7f\u7528\u53d7\u4fdd\u62a4\u5c5e\u6027\uff08\u5982\u6027\u522b\uff09\uff0c\u5e76\u63d0\u4f9b\u660e\u786e\u7684\u4f9d\u636e\u6765\u652f\u6301\u5176\u4f7f\u7528\u3002", "conclusion": "\u8bba\u6587\u8ba4\u4e3aFtU\u503c\u5f97\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8003\u8651\uff0c\u7279\u522b\u662f\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e0b\uff0c\u80fd\u591f\u5e2e\u52a9\u5b9e\u73b0\u66f4\u516c\u5e73\u7684\u653f\u7b56\u51b3\u7b56\uff0c\u540c\u65f6\u4fdd\u6301\u6548\u80fd\u3002"}}
{"id": "2505.16312", "pdf": "https://arxiv.org/pdf/2505.16312", "abs": "https://arxiv.org/abs/2505.16312", "authors": ["Jiawei Liu", "Qisi Chen", "Jianshu Zhang", "Quan Liu", "Defu Lian"], "title": "EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via Action Pruning", "categories": ["cs.AI", "cs.CL"], "comment": "11 pages, 4 figures", "summary": "Large Language Models (LLMs) excel at complex reasoning through search\nalgorithms, yet current strategies often suffer from massive token consumption\ndue to redundant exploration of semantically equivalent steps. Existing\nsemantic similarity methods struggle to accurately identify such equivalence in\ndomain-specific contexts like mathematical reasoning. To address this, we\npropose EquivPruner, a simple yet effective approach that identifies and prunes\nsemantically equivalent actions during LLM reasoning search. We also introduce\nMathEquiv, the first dataset we created for mathematical statement equivalence,\nwhich enables the training of a lightweight equivalence detector. Extensive\nexperiments across various models and tasks demonstrate that EquivPruner\nsignificantly reduces token consumption, improving searching efficiency and\noften bolstering reasoning accuracy. For instance, when applied to\nQwen2.5-Math-7B-Instruct on GSM8K, EquivPruner reduced token consumption by\n48.1\\% while also improving accuracy. Our code is available at\nhttps://github.com/Lolo1222/EquivPruner.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEquivPruner\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u8bc6\u522b\u5e76\u4fee\u526a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u641c\u7d22\u8fc7\u7a0b\u4e2d\u8bed\u4e49\u7b49\u4ef7\u7684\u52a8\u4f5c\uff0c\u4ece\u800c\u51cf\u5c11\u4ee4\u724c\u6d88\u8017\uff0c\u63d0\u9ad8\u641c\u7d22\u6548\u7387\u548c\u63a8\u7406\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u4ecb\u7ecd\u4e86MathEquiv\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u6570\u5b66\u8bed\u53e5\u7b49\u4ef7\u6027\u7684\u8bad\u7ec3\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u51cf\u5c11\u4ee4\u724c\u6d88\u8017\u5e76\u63d0\u5347\u51c6\u786e\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5f53\u524d\u7b56\u7565\u56e0\u91cd\u590d\u63a2\u7d22\u8bed\u4e49\u7b49\u4ef7\u6b65\u9aa4\u800c\u6d88\u8017\u5927\u91cf\u4ee4\u724c\u3002\u73b0\u6709\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u8bc6\u522b\u7279\u5b9a\u9886\u57df\uff08\u5982\u6570\u5b66\u63a8\u7406\uff09\u4e2d\u7684\u8fd9\u79cd\u7b49\u4ef7\u6027\u3002", "method": "\u63d0\u51fa\u4e86EquivPruner\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u548c\u4fee\u526a\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u641c\u7d22\u8fc7\u7a0b\u4e2d\u7684\u8bed\u4e49\u7b49\u4ef7\u52a8\u4f5c\u3002\u540c\u65f6\u521b\u5efa\u4e86MathEquiv\u6570\u636e\u96c6\uff0c\u4ee5\u652f\u6301\u8f7b\u91cf\u7ea7\u7b49\u4ef7\u68c0\u6d4b\u5668\u7684\u8bad\u7ec3\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cEquivPruner\u663e\u8457\u51cf\u5c11\u4e86\u4ee4\u724c\u6d88\u8017\uff0c\u63d0\u9ad8\u4e86\u641c\u7d22\u6548\u7387\uff0c\u5e76\u4e14\u901a\u5e38\u589e\u5f3a\u4e86\u63a8\u7406\u51c6\u786e\u6027\u3002\u4f8b\u5982\uff0c\u5728Qwen2.5-Math-7B-Instruct\u5e94\u7528\u4e8eGSM8K\u65f6\uff0c\u51cf\u5c11\u4e8648.1%\u7684\u4ee4\u724c\u6d88\u8017\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u51c6\u786e\u7387\u3002", "conclusion": "EquivPruner\u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u51cf\u5c11\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u4ee4\u724c\u6d88\u8017\uff0c\u63d0\u9ad8\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2505.16159", "pdf": "https://arxiv.org/pdf/2505.16159", "abs": "https://arxiv.org/abs/2505.16159", "authors": ["Chongjie Si", "Yidan Cui", "Fuchao Yang", "Xiaokang Yang", "Wei Shen"], "title": "Why Can Accurate Models Be Learned from Inaccurate Annotations?", "categories": ["cs.LG"], "comment": null, "summary": "Learning from inaccurate annotations has gained significant attention due to\nthe high cost of precise labeling. However, despite the presence of erroneous\nlabels, models trained on noisy data often retain the ability to make accurate\npredictions. This intriguing phenomenon raises a fundamental yet largely\nunexplored question: why models can still extract correct label information\nfrom inaccurate annotations remains unexplored. In this paper, we conduct a\ncomprehensive investigation into this issue. By analyzing weight matrices from\nboth empirical and theoretical perspectives, we find that label inaccuracy\nprimarily accumulates noise in lower singular components and subtly perturbs\nthe principal subspace. Within a certain range, the principal subspaces of\nweights trained on inaccurate labels remain largely aligned with those learned\nfrom clean labels, preserving essential task-relevant information. We formally\nprove that the angles of principal subspaces exhibit minimal deviation under\nmoderate label inaccuracy, explaining why models can still generalize\neffectively. Building on these insights, we propose LIP, a lightweight plug-in\ndesigned to help classifiers retain principal subspace information while\nmitigating noise induced by label inaccuracy. Extensive experiments on tasks\nwith various inaccuracy conditions demonstrate that LIP consistently enhances\nthe performance of existing algorithms. We hope our findings can offer valuable\ntheoretical and practical insights to understand of model robustness under\ninaccurate supervision.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u6a21\u578b\u4e3a\u4f55\u80fd\u5728\u4e0d\u51c6\u786e\u6807\u7b7e\u7684\u6570\u636e\u4e0a\u8bad\u7ec3\u540e\u4ecd\u7136\u80fd\u63d0\u53d6\u6b63\u786e\u4fe1\u606f\uff0c\u5e76\u63d0\u51fa\u4e86\u8f7b\u91cf\u7ea7\u63d2\u4ef6LIP\uff0c\u4ee5\u589e\u5f3a\u73b0\u6709\u7b97\u6cd5\u5728\u5404\u79cd\u4e0d\u51c6\u786e\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u7531\u4e8e\u7cbe\u786e\u6807\u6ce8\u7684\u6210\u672c\u9ad8\uff0c\u4ece\u4e0d\u51c6\u786e\u7684\u6807\u6ce8\u4e2d\u5b66\u4e60\u53d7\u5230\u4e86\u5e7f\u6cdb\u5173\u6ce8\u3002\u5c3d\u7ba1\u5b58\u5728\u9519\u8bef\u6807\u7b7e\uff0c\u4f46\u6a21\u578b\u4ecd\u80fd\u505a\u51fa\u51c6\u786e\u9884\u6d4b\u7684\u73b0\u8c61\u5c1a\u672a\u88ab\u6df1\u5165\u63a2\u7a76\u3002", "method": "\u901a\u8fc7\u5206\u6790\u6743\u91cd\u77e9\u9635\u7684\u7ecf\u9a8c\u548c\u7406\u8bba\u89c6\u89d2\uff0c\u53d1\u73b0\u4e0d\u51c6\u786e\u6807\u7b7e\u4e3b\u8981\u5728\u8f83\u4f4e\u5947\u5f02\u503c\u6210\u5206\u4e2d\u79ef\u7d2f\u566a\u58f0\uff0c\u8f7b\u5fae\u6270\u52a8\u4e3b\u5b50\u7a7a\u95f4\u3002\u5e76\u5728\u9002\u4e2d\u6807\u7b7e\u4e0d\u51c6\u786e\u7684\u60c5\u51b5\u4e0b\uff0c\u8bc1\u660e\u4e3b\u5b50\u7a7a\u95f4\u89d2\u5ea6\u504f\u5dee\u6700\u5c0f\uff0c\u89e3\u91ca\u4e86\u6a21\u578b\u4ecd\u80fd\u6709\u6548\u6cdb\u5316\u7684\u539f\u56e0\u3002\u57fa\u4e8e\u8fd9\u4e9b\u89c1\u89e3\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u63d2\u4ef6LIP\uff0c\u5e2e\u52a9\u5206\u7c7b\u5668\u4fdd\u7559\u4e3b\u5b50\u7a7a\u95f4\u4fe1\u606f\u5e76\u51cf\u8f7b\u6807\u7b7e\u4e0d\u51c6\u786e\u5e26\u6765\u7684\u566a\u58f0\u5f71\u54cd\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLIP\u5728\u5404\u79cd\u4e0d\u51c6\u786e\u6761\u4ef6\u4e0b\u90fd\u80fd\u4e00\u81f4\u63d0\u5347\u73b0\u6709\u7b97\u6cd5\u7684\u6027\u80fd\u3002", "conclusion": "\u5e0c\u671b\u8fd9\u4e9b\u7814\u7a76\u7ed3\u679c\u80fd\u4e3a\u7406\u89e3\u6a21\u578b\u5728\u4e0d\u51c6\u786e\u76d1\u7763\u4e0b\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u7406\u8bba\u548c\u5b9e\u8df5\u89c1\u89e3\u3002"}}
{"id": "2505.16732", "pdf": "https://arxiv.org/pdf/2505.16732", "abs": "https://arxiv.org/abs/2505.16732", "authors": ["Hany Abdulsamad", "Sahel Iqbal", "Simo S\u00e4rkk\u00e4"], "title": "Sequential Monte Carlo for Policy Optimization in Continuous POMDPs", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Optimal decision-making under partial observability requires agents to\nbalance reducing uncertainty (exploration) against pursuing immediate\nobjectives (exploitation). In this paper, we introduce a novel policy\noptimization framework for continuous partially observable Markov decision\nprocesses (POMDPs) that explicitly addresses this challenge. Our method casts\npolicy learning as probabilistic inference in a non-Markovian Feynman--Kac\nmodel that inherently captures the value of information gathering by\nanticipating future observations, without requiring extrinsic exploration\nbonuses or handcrafted heuristics. To optimize policies under this model, we\ndevelop a nested sequential Monte Carlo~(SMC) algorithm that efficiently\nestimates a history-dependent policy gradient under samples from the optimal\ntrajectory distribution induced by the POMDP. We demonstrate the effectiveness\nof our algorithm across standard continuous POMDP benchmarks, where existing\nmethods struggle to act under uncertainty.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b56\u7565\u4f18\u5316\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u8fde\u7eed\u90e8\u5206\u53ef\u89c2\u6d4b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08POMDPs\uff09\uff0c\u901a\u8fc7\u5c06\u7b56\u7565\u5b66\u4e60\u89c6\u4e3a\u975e\u9a6c\u5c14\u53ef\u592bFeynman-Kac\u6a21\u578b\u4e2d\u7684\u6982\u7387\u63a8\u65ad\uff0c\u89e3\u51b3\u4e86\u63a2\u7d22\u4e0e\u5229\u7528\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u5916\u90e8\u63a2\u7d22\u5956\u52b1\u6216\u624b\u5de5\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f00\u53d1\u5d4c\u5957\u5e8f\u8d2f\u8499\u7279\u5361\u6d1b\uff08SMC\uff09\u7b97\u6cd5\u6765\u4f18\u5316\u7b56\u7565\uff0c\u5e76\u5728\u6807\u51c6\u8fde\u7eedPOMDP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u7684\u60c5\u51b5\u4e0b\uff0c\u6700\u4f18\u51b3\u7b56\u9700\u8981\u5728\u51cf\u5c11\u4e0d\u786e\u5b9a\u6027\uff08\u63a2\u7d22\uff09\u548c\u8ffd\u6c42\u5373\u65f6\u76ee\u6807\uff08\u5229\u7528\uff09\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u8fde\u7eedPOMDP\u73af\u5883\u4e2d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u660e\u786e\u89e3\u51b3\u63a2\u7d22\u4e0e\u5229\u7528\u7684\u5e73\u8861\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b56\u7565\u4f18\u5316\u6846\u67b6\uff0c\u5c06\u7b56\u7565\u5b66\u4e60\u4f5c\u4e3a\u975e\u9a6c\u5c14\u53ef\u592bFeynman-Kac\u6a21\u578b\u4e2d\u7684\u6982\u7387\u63a8\u65ad\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u9884\u6d4b\u672a\u6765\u7684\u89c2\u6d4b\u7ed3\u679c\u6765\u6355\u6349\u4fe1\u606f\u6536\u96c6\u7684\u4ef7\u503c\u3002\u4e3a\u4e86\u4f18\u5316\u7b56\u7565\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u5d4c\u5957\u5e8f\u8d2f\u8499\u7279\u5361\u6d1b\uff08SMC\uff09\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u5728\u7531POMDP\u8bf1\u5bfc\u7684\u6700\u4f73\u8f68\u8ff9\u5206\u5e03\u6837\u672c\u4e0b\uff0c\u6709\u6548\u5730\u4f30\u8ba1\u5386\u53f2\u4f9d\u8d56\u7684\u7b56\u7565\u68af\u5ea6\u3002", "result": "\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u6807\u51c6\u8fde\u7eedPOMDP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u800c\u73b0\u6709\u65b9\u6cd5\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u884c\u52a8\u8868\u73b0\u4e0d\u4f73\u3002\u8fd9\u8868\u660e\u65b0\u65b9\u6cd5\u5728\u5904\u7406\u63a2\u7d22\u4e0e\u5229\u7528\u5e73\u8861\u95ee\u9898\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7b56\u7565\u4f18\u5316\u6846\u67b6\u4e3a\u8fde\u7eedPOMDP\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u63a2\u7d22\u4e0e\u5229\u7528\u4e4b\u95f4\u7684\u5e73\u8861\u95ee\u9898\uff0c\u65e0\u9700\u5916\u90e8\u63a2\u7d22\u5956\u52b1\u6216\u624b\u5de5\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u5c55\u73b0\u4e86\u5728\u4e0d\u786e\u5b9a\u6027\u73af\u5883\u4e0b\u7684\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2505.16315", "pdf": "https://arxiv.org/pdf/2505.16315", "abs": "https://arxiv.org/abs/2505.16315", "authors": ["Xiaoxue Cheng", "Junyi Li", "Zhenduo Zhang", "Xinyu Tang", "Wayne Xin Zhao", "Xinyu Kong", "Zhiqiang Zhang"], "title": "Incentivizing Dual Process Thinking for Efficient Large Language Model Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "work in progress", "summary": "Large reasoning models (LRMs) have demonstrated strong performance on complex\nreasoning tasks, but often suffer from overthinking, generating redundant\ncontent regardless of task difficulty. Inspired by the dual process theory in\ncognitive science, we propose Adaptive Cognition Policy Optimization (ACPO), a\nreinforcement learning framework that enables LRMs to achieve efficient\nreasoning through adaptive cognitive allocation and dynamic system switch. ACPO\nincorporates two key components: (1) introducing system-aware reasoning tokens\nto explicitly represent the thinking modes thereby making the model's cognitive\nprocess transparent, and (2) integrating online difficulty estimation and token\nlength budget to guide adaptive system switch and reasoning during\nreinforcement learning. To this end, we propose a two-stage training strategy.\nThe first stage begins with supervised fine-tuning to cold start the model,\nenabling it to generate reasoning paths with explicit thinking modes. In the\nsecond stage, we apply ACPO to further enhance adaptive system switch for\ndifficulty-aware reasoning. Experimental results demonstrate that ACPO\neffectively reduces redundant reasoning while adaptively adjusting cognitive\nallocation based on task complexity, achieving efficient hybrid reasoning.", "AI": {"tldr": "ACPO\u662f\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8ba4\u77e5\u5206\u914d\u548c\u52a8\u6001\u7cfb\u7edf\u5207\u6362\u4f7f\u5927\u578b\u63a8\u7406\u6a21\u578b\u66f4\u9ad8\u6548\u3002\u5b9e\u9a8c\u8868\u660e\uff0cACPO\u80fd\u51cf\u5c11\u5197\u4f59\u63a8\u7406\u5e76\u6839\u636e\u4efb\u52a1\u590d\u6742\u6027\u8c03\u6574\u8ba4\u77e5\u5206\u914d\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u6df7\u5408\u63a8\u7406\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5e38\u56e0\u8fc7\u5ea6\u601d\u8003\u4ea7\u751f\u5197\u4f59\u5185\u5bb9\u3002\u53d7\u8ba4\u77e5\u79d1\u5b66\u53cc\u91cd\u8fc7\u7a0b\u7406\u8bba\u542f\u53d1\uff0c\u7814\u7a76\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u6846\u67b6\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u901a\u8fc7\u81ea\u9002\u5e94\u8ba4\u77e5\u5206\u914d\u548c\u52a8\u6001\u7cfb\u7edf\u5207\u6362\u5b9e\u73b0\u9ad8\u6548\u63a8\u7406\u3002", "method": "\u63d0\u51faACPO\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) \u5f15\u5165\u7cfb\u7edf\u611f\u77e5\u63a8\u7406\u6807\u8bb0\u4ee5\u660e\u786e\u8868\u793a\u601d\u7ef4\u6a21\u5f0f\uff0c\u4f7f\u6a21\u578b\u7684\u8ba4\u77e5\u8fc7\u7a0b\u900f\u660e\uff1b2) \u6574\u5408\u5728\u7ebf\u96be\u5ea6\u4f30\u8ba1\u548c\u6807\u8bb0\u957f\u5ea6\u9884\u7b97\uff0c\u4ee5\u6307\u5bfc\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u81ea\u9002\u5e94\u7cfb\u7edf\u5207\u6362\u548c\u63a8\u7406\u3002\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a\u7b2c\u4e00\u9636\u6bb5\u4e3a\u76d1\u7763\u5fae\u8c03\uff0c\u4f7f\u6a21\u578b\u751f\u6210\u5e26\u6709\u660e\u786e\u601d\u7ef4\u6a21\u5f0f\u7684\u63a8\u7406\u8def\u5f84\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5e94\u7528ACPO\u8fdb\u4e00\u6b65\u589e\u5f3a\u81ea\u9002\u5e94\u7cfb\u7edf\u5207\u6362\uff0c\u8fdb\u884c\u96be\u5ea6\u611f\u77e5\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cACPO\u6709\u6548\u51cf\u5c11\u4e86\u5197\u4f59\u63a8\u7406\uff0c\u5e76\u80fd\u6839\u636e\u4efb\u52a1\u590d\u6742\u6027\u81ea\u9002\u5e94\u8c03\u6574\u8ba4\u77e5\u5206\u914d\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u6df7\u5408\u63a8\u7406\u3002", "conclusion": "ACPO\u6846\u67b6\u6210\u529f\u4f7f\u5927\u578b\u63a8\u7406\u6a21\u578b\u901a\u8fc7\u81ea\u9002\u5e94\u8ba4\u77e5\u5206\u914d\u548c\u52a8\u6001\u7cfb\u7edf\u5207\u6362\u63d0\u9ad8\u6548\u7387\uff0c\u51cf\u5c11\u5197\u4f59\u63a8\u7406\uff0c\u5b9e\u73b0\u96be\u5ea6\u611f\u77e5\u7684\u9ad8\u6548\u6df7\u5408\u63a8\u7406\u3002"}}
{"id": "2505.16190", "pdf": "https://arxiv.org/pdf/2505.16190", "abs": "https://arxiv.org/abs/2505.16190", "authors": ["Navid Seidi", "Satyaki Roy", "Sajal Das"], "title": "Enhancing Federated Survival Analysis through Peer-Driven Client Reputation in Healthcare", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) holds great promise for digital health by enabling\ncollaborative model training without compromising patient data privacy.\nHowever, heterogeneity across institutions, lack of sustained reputation, and\nunreliable contributions remain major challenges. In this paper, we propose a\nrobust, peer-driven reputation mechanism for federated healthcare that employs\na hybrid communication model to integrate decentralized peer feedback with\nclustering-based noise handling to enhance model aggregation. Crucially, our\napproach decouples the federated aggregation and reputation mechanisms by\napplying differential privacy to client-side model updates before sharing them\nfor peer evaluation. This ensures sensitive information remains protected\nduring reputation computation, while unaltered updates are sent to the server\nfor global model training. Using the Cox Proportional Hazards model for\nsurvival analysis across multiple federated nodes, our framework addresses both\ndata heterogeneity and reputation deficit by dynamically adjusting trust scores\nbased on local performance improvements measured via the concordance index.\nExperimental evaluations on both synthetic datasets and the SEER dataset\ndemonstrate that our method consistently achieves high and stable C-index\nvalues, effectively down-weighing noisy client updates and outperforming FL\nmethods that lack a reputation system.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9c81\u68d2\u7684\u3001\u7531\u540c\u884c\u9a71\u52a8\u7684\u58f0\u8a89\u673a\u5236\uff0c\u7528\u4e8e\u8054\u90a6\u533b\u7597\u4fdd\u5065\u3002\u901a\u8fc7\u7ed3\u5408\u53bb\u4e2d\u5fc3\u5316\u7684\u540c\u884c\u53cd\u9988\u4e0e\u57fa\u4e8e\u805a\u7c7b\u7684\u566a\u58f0\u5904\u7406\uff0c\u589e\u5f3a\u6a21\u578b\u805a\u5408\uff0c\u540c\u65f6\u91c7\u7528\u5dee\u5206\u9690\u79c1\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5904\u7406\u6570\u636e\u5f02\u6784\u6027\u548c\u58f0\u8a89\u4e0d\u8db3\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u6709\u6548\u964d\u4f4e\u566a\u58f0\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u5f71\u54cd\uff0c\u5e76\u4f18\u4e8e\u6ca1\u6709\u58f0\u8a89\u7cfb\u7edf\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u5728\u6570\u5b57\u5065\u5eb7\u9886\u57df\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u673a\u6784\u95f4\u7684\u5f02\u6784\u6027\u3001\u7f3a\u4e4f\u6301\u7eed\u7684\u58f0\u8a89\u4ee5\u53ca\u4e0d\u53ef\u9760\u7684\u8d21\u732e\u4ecd\u7136\u662f\u4e3b\u8981\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u53bb\u4e2d\u5fc3\u5316\u540c\u884c\u53cd\u9988\u4e0e\u57fa\u4e8e\u805a\u7c7b\u7684\u566a\u58f0\u5904\u7406\u7684\u6df7\u5408\u901a\u4fe1\u6a21\u578b\uff0c\u5c06\u8054\u90a6\u805a\u5408\u548c\u58f0\u8a89\u673a\u5236\u89e3\u8026\uff0c\u5e76\u5728\u5171\u4eab\u5ba2\u6237\u7aef\u6a21\u578b\u66f4\u65b0\u4e4b\u524d\u5e94\u7528\u5dee\u5206\u9690\u79c1\u4ee5\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u3002\u4f7f\u7528Cox\u6bd4\u4f8b\u98ce\u9669\u6a21\u578b\u8fdb\u884c\u751f\u5b58\u5206\u6790\uff0c\u5e76\u901a\u8fc7\u4e00\u81f4\u6027\u6307\u6570\u52a8\u6001\u8c03\u6574\u4fe1\u4efb\u8bc4\u5206\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u6570\u636e\u96c6\u548cSEER\u6570\u636e\u96c6\u4e0a\u5747\u80fd\u5b9e\u73b0\u9ad8\u4e14\u7a33\u5b9a\u7684\u4e00\u81f4\u6027\u6307\u6570\u503c\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u566a\u58f0\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u5f71\u54cd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u58f0\u8a89\u673a\u5236\u6709\u6548\u5730\u89e3\u51b3\u4e86\u6570\u636e\u5f02\u6784\u6027\u548c\u58f0\u8a89\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5e76\u4f18\u4e8e\u7f3a\u4e4f\u58f0\u8a89\u7cfb\u7edf\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2505.16741", "pdf": "https://arxiv.org/pdf/2505.16741", "abs": "https://arxiv.org/abs/2505.16741", "authors": ["Pilhwa Lee", "Shashank Gupta"], "title": "Meta-reinforcement learning with minimum attention", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "10 pages, 7 figures", "summary": "Minimum attention applies the least action principle in the changes of\ncontrol concerning state and time, first proposed by Brockett. The involved\nregularization is highly relevant in emulating biological control, such as\nmotor learning. We apply minimum attention in reinforcement learning (RL) as\npart of the rewards and investigate its connection to meta-learning and\nstabilization. Specifically, model-based meta-learning with minimum attention\nis explored in high-dimensional nonlinear dynamics. Ensemble-based model\nlearning and gradient-based meta-policy learning are alternately performed.\nEmpirically, we show that the minimum attention does show outperforming\ncompetence in comparison to the state-of-the-art algorithms in model-free and\nmodel-based RL, i.e., fast adaptation in few shots and variance reduction from\nthe perturbations of the model and environment. Furthermore, the minimum\nattention demonstrates the improvement in energy efficiency.", "AI": {"tldr": "\u5c06\u6700\u5c0f\u5173\u6ce8\u539f\u5219\u5e94\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5956\u52b1\u90e8\u5206\uff0c\u63a2\u7d22\u5176\u4e0e\u5143\u5b66\u4e60\u548c\u7a33\u5b9a\u6027\u7684\u8054\u7cfb\u3002\u901a\u8fc7\u57fa\u4e8e\u6a21\u578b\u7684\u5143\u5b66\u4e60\u3001\u96c6\u6210\u6a21\u578b\u5b66\u4e60\u548c\u57fa\u4e8e\u68af\u5ea6\u7684\u5143\u7b56\u7565\u5b66\u4e60\uff0c\u5c55\u793a\u4e86\u5728\u9ad8\u7ef4\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u5305\u62ec\u5feb\u901f\u9002\u5e94\u3001\u51cf\u5c11\u65b9\u5dee\u548c\u63d0\u9ad8\u80fd\u6e90\u6548\u7387\u3002", "motivation": "\u6700\u5c0f\u5173\u6ce8\u539f\u5219\u6700\u521d\u7531Brockett\u63d0\u51fa\uff0c\u7528\u4e8e\u72b6\u6001\u548c\u65f6\u95f4\u63a7\u5236\u7684\u53d8\u5316\uff0c\u5176\u6b63\u5219\u5316\u5728\u6a21\u62df\u751f\u7269\u63a7\u5236\uff08\u5982\u8fd0\u52a8\u5b66\u4e60\uff09\u4e2d\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5c06\u5176\u5e94\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u4ee5\u63a2\u7d22\u5176\u4e0e\u5143\u5b66\u4e60\u548c\u7a33\u5b9a\u6027\u7684\u8054\u7cfb\u3002", "method": "\u5c06\u6700\u5c0f\u5173\u6ce8\u539f\u5219\u4f5c\u4e3a\u5956\u52b1\u7684\u4e00\u90e8\u5206\u5e94\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\uff0c\u7ed3\u5408\u57fa\u4e8e\u6a21\u578b\u7684\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u9ad8\u7ef4\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u4e2d\u8fdb\u884c\u63a2\u7d22\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4ea4\u66ff\u6267\u884c\u57fa\u4e8e\u96c6\u6210\u7684\u6a21\u578b\u5b66\u4e60\u548c\u57fa\u4e8e\u68af\u5ea6\u7684\u5143\u7b56\u7565\u5b66\u4e60\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u65e0\u6a21\u578b\u548c\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u76f8\u6bd4\uff0c\u6700\u5c0f\u5173\u6ce8\u539f\u5219\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u80fd\u529b\uff0c\u5305\u62ec\u5feb\u901f\u9002\u5e94\u5c11\u91cf\u6837\u672c\u3001\u51cf\u5c11\u6a21\u578b\u548c\u73af\u5883\u6270\u52a8\u5e26\u6765\u7684\u65b9\u5dee\uff0c\u5e76\u4e14\u63d0\u9ad8\u4e86\u80fd\u6e90\u6548\u7387\u3002", "conclusion": "\u6700\u5c0f\u5173\u6ce8\u539f\u5219\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u5143\u5b66\u4e60\u548c\u7a33\u5b9a\u6027\u65b9\u9762\uff0c\u4e3a\u89e3\u51b3\u9ad8\u7ef4\u975e\u7ebf\u6027\u52a8\u529b\u5b66\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.16388", "pdf": "https://arxiv.org/pdf/2505.16388", "abs": "https://arxiv.org/abs/2505.16388", "authors": ["Nandini Doreswamy", "Louise Horstmanshof"], "title": "Serious Games: Human-AI Interaction, Evolution, and Coevolution", "categories": ["cs.AI", "cs.GT", "91A22 (Primary), 68T99 (Secondary)", "J.4; I.2.0; K.4.1; J.3; K.4.0"], "comment": "8 pages, 1 table", "summary": "The serious games between humans and AI have only just begun. Evolutionary\nGame Theory (EGT) models the competitive and cooperative strategies of\nbiological entities. EGT could help predict the potential evolutionary\nequilibrium of humans and AI. The objective of this work was to examine some of\nthe EGT models relevant to human-AI interaction, evolution, and coevolution. Of\nthirteen EGT models considered, three were examined: the Hawk-Dove Game,\nIterated Prisoner's Dilemma, and the War of Attrition. This selection was based\non the widespread acceptance and clear relevance of these models to potential\nhuman-AI evolutionary dynamics and coevolutionary trajectories. The Hawk-Dove\nGame predicts balanced mixed-strategy equilibria based on the costs of\nconflict. It also shows the potential for balanced coevolution rather than\ndominance. Iterated Prisoner's Dilemma suggests that repeated interaction may\nlead to cognitive coevolution. It demonstrates how memory and reciprocity can\nlead to cooperation. The War of Attrition suggests that competition for\nresources may result in strategic coevolution, asymmetric equilibria, and\nconventions on sharing resources. Therefore, EGT may provide a suitable\nframework to understand and predict the human-AI evolutionary dynamic. However,\nfuture research could extend beyond EGT and explore additional frameworks,\nempirical validation methods, and interdisciplinary perspectives. AI is being\nshaped by human input and is evolving in response to it. So too,\nneuroplasticity allows the human brain to grow and evolve in response to\nstimuli. If humans and AI converge in future, what might be the result of human\nneuroplasticity combined with an ever-evolving AI? Future research should be\nmindful of the ethical and cognitive implications of human-AI interaction,\nevolution, and coevolution.", "AI": {"tldr": "\u901a\u8fc7\u8fdb\u5316\u535a\u5f08\u8bba\uff08EGT\uff09\u6a21\u578b\uff0c\u5982\u9e70\u9e3d\u535a\u5f08\u3001\u91cd\u590d\u56da\u5f92\u56f0\u5883\u548c\u6d88\u8017\u6218\uff0c\u53ef\u4ee5\u9884\u6d4b\u4eba\u7c7b\u4e0eAI\u4e4b\u95f4\u7684\u8fdb\u5316\u5e73\u8861\u3002\u8fd9\u4e9b\u6a21\u578b\u63ed\u793a\u4e86\u5408\u4f5c\u4e0e\u7ade\u4e89\u7684\u53ef\u80fd\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u89e3\u4eba\u7c7b-AI\u5171\u540c\u6f14\u5316\u7684\u6846\u67b6\u3002\u672a\u6765\u7814\u7a76\u9700\u8981\u63a2\u7d22\u66f4\u591a\u65b9\u6cd5\u548c\u8de8\u5b66\u79d1\u89c6\u89d2\u3002", "motivation": "\u63a2\u8ba8\u4eba\u7c7b\u4e0eAI\u4e4b\u95f4\u7ade\u4e89\u4e0e\u5408\u4f5c\u7684\u6f5c\u5728\u8fdb\u5316\u5e73\u8861\uff0c\u5e76\u4e3a\u4eba\u7c7b-AI\u4e92\u52a8\u3001\u6f14\u5316\u548c\u5171\u540c\u6f14\u5316\u63d0\u4f9b\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5206\u6790\u4e09\u4e2a\u7ecf\u5178\u7684EGT\u6a21\u578b\uff1a\u9e70\u9e3d\u535a\u5f08\u3001\u91cd\u590d\u56da\u5f92\u56f0\u5883\u548c\u6d88\u8017\u6218\uff0c\u8bc4\u4f30\u5176\u5728\u4eba\u7c7b-AI\u5171\u540c\u6f14\u5316\u4e2d\u7684\u9002\u7528\u6027\u3002", "result": "\u53d1\u73b0\u8fd9\u4e9b\u6a21\u578b\u80fd\u591f\u63ed\u793a\u4eba\u7c7b\u4e0eAI\u4e4b\u95f4\u53ef\u80fd\u7684\u5408\u4f5c\u4e0e\u7ade\u4e89\u52a8\u6001\uff0c\u5305\u62ec\u6df7\u5408\u7b56\u7565\u5e73\u8861\u3001\u8ba4\u77e5\u5171\u540c\u6f14\u5316\u4ee5\u53ca\u8d44\u6e90\u5206\u914d\u7684\u4e0d\u5bf9\u79f0\u5747\u8861\u3002", "conclusion": "EGT\u4e3a\u7406\u89e3\u4eba\u7c7b-AI\u6f14\u5316\u52a8\u6001\u63d0\u4f9b\u4e86\u5408\u9002\u6846\u67b6\uff0c\u4f46\u672a\u6765\u7814\u7a76\u9700\u8d85\u8d8aEGT\uff0c\u7ed3\u5408\u66f4\u591a\u65b9\u6cd5\u3001\u5b9e\u8bc1\u9a8c\u8bc1\u548c\u8de8\u5b66\u79d1\u89c6\u89d2\uff0c\u540c\u65f6\u5173\u6ce8\u4f26\u7406\u548c\u8ba4\u77e5\u5f71\u54cd\u3002"}}
{"id": "2505.16953", "pdf": "https://arxiv.org/pdf/2505.16953", "abs": "https://arxiv.org/abs/2505.16953", "authors": ["Young Sang Choi", "Vincent Jeanselme", "Pierre Elias", "Shalmali Joshi"], "title": "ICYM2I: The illusion of multimodal informativeness under missingness", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Multimodal learning is of continued interest in artificial intelligence-based\napplications, motivated by the potential information gain from combining\ndifferent types of data. However, modalities collected and curated during\ndevelopment may differ from the modalities available at deployment due to\nmultiple factors including cost, hardware failure, or -- as we argue in this\nwork -- the perceived informativeness of a given modality. Na{\\\"i}ve estimation\nof the information gain associated with including an additional modality\nwithout accounting for missingness may result in improper estimates of that\nmodality's value in downstream tasks. Our work formalizes the problem of\nmissingness in multimodal learning and demonstrates the biases resulting from\nignoring this process. To address this issue, we introduce ICYM2I (In Case You\nMultimodal Missed It), a framework for the evaluation of predictive performance\nand information gain under missingness through inverse probability\nweighting-based correction. We demonstrate the importance of the proposed\nadjustment to estimate information gain under missingness on synthetic,\nsemi-synthetic, and real-world medical datasets.", "AI": {"tldr": "\u5728\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\uff0c\u7531\u4e8e\u591a\u79cd\u56e0\u7d20\uff08\u5982\u6210\u672c\u3001\u786c\u4ef6\u6545\u969c\u6216\u7279\u5b9a\u6a21\u6001\u7684\u4fe1\u606f\u611f\u77e5\u4ef7\u503c\uff09\uff0c\u8bad\u7ec3\u65f6\u53ef\u7528\u7684\u6a21\u6001\u53ef\u80fd\u4e0e\u90e8\u7f72\u65f6\u4e0d\u540c\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6846\u67b6ICYM2I\uff0c\u7528\u4e8e\u8bc4\u4f30\u5728\u6a21\u6001\u7f3a\u5931\u60c5\u51b5\u4e0b\u7684\u9884\u6d4b\u6027\u80fd\u548c\u4fe1\u606f\u589e\u76ca\uff0c\u901a\u8fc7\u9006\u6982\u7387\u52a0\u6743\u6821\u6b63\u6765\u89e3\u51b3\u5ffd\u7565\u6a21\u6001\u7f3a\u5931\u5bfc\u81f4\u7684\u504f\u5dee\u3002", "motivation": "\u7ed3\u5408\u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u53ef\u4ee5\u5e26\u6765\u6f5c\u5728\u7684\u4fe1\u606f\u589e\u76ca\uff0c\u63a8\u52a8\u4e86\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u7684\u591a\u6a21\u6001\u5b66\u4e60\u7684\u53d1\u5c55\u3002\u7136\u800c\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u7531\u4e8e\u6210\u672c\u3001\u786c\u4ef6\u95ee\u9898\u6216\u5bf9\u7279\u5b9a\u6a21\u6001\u4fe1\u606f\u4ef7\u503c\u7684\u4e0d\u540c\u8ba4\u77e5\uff0c\u5f00\u53d1\u9636\u6bb5\u6536\u96c6\u7684\u6a21\u6001\u53ef\u80fd\u4e0e\u90e8\u7f72\u9636\u6bb5\u53ef\u7528\u7684\u6a21\u6001\u4e0d\u4e00\u81f4\u3002\u7b80\u5355\u4f30\u8ba1\u65b0\u589e\u6a21\u6001\u7684\u4fe1\u606f\u589e\u76ca\u800c\u4e0d\u8003\u8651\u7f3a\u5931\u6027\u53ef\u80fd\u5bfc\u81f4\u5bf9\u5176\u4e0b\u6e38\u4efb\u52a1\u4ef7\u503c\u7684\u9519\u8bef\u4f30\u8ba1\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u95ee\u9898\uff0c\u5373\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u7684\u6a21\u6001\u7f3a\u5931\uff0c\u5e76\u5c55\u793a\u4e86\u5ffd\u7565\u8fd9\u4e00\u8fc7\u7a0b\u6240\u5bfc\u81f4\u7684\u504f\u5dee\u3002\u4e3a\u4e86\u89e3\u51b3\u8be5\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aICYM2I\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4f7f\u7528\u9006\u6982\u7387\u52a0\u6743\u6821\u6b63\u65b9\u6cd5\uff0c\u6765\u8bc4\u4f30\u5728\u6a21\u6001\u7f3a\u5931\u60c5\u51b5\u4e0b\u9884\u6d4b\u6027\u80fd\u548c\u4fe1\u606f\u589e\u76ca\u3002", "result": "\u901a\u8fc7\u5728\u5408\u6210\u3001\u534a\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u533b\u7597\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u8c03\u6574\u65b9\u6cd5\u5728\u4f30\u8ba1\u6a21\u6001\u7f3a\u5931\u60c5\u51b5\u4e0b\u7684\u4fe1\u606f\u589e\u76ca\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u7814\u7a76\u6b63\u5f0f\u5316\u4e86\u591a\u6a21\u6001\u5b66\u4e60\u4e2d\u6a21\u6001\u7f3a\u5931\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7ICYM2I\u6846\u67b6\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5f3a\u8c03\u4e86\u5728\u8003\u8651\u6a21\u6001\u7f3a\u5931\u65f6\u6b63\u786e\u4f30\u8ba1\u4fe1\u606f\u589e\u76ca\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2505.16409", "pdf": "https://arxiv.org/pdf/2505.16409", "abs": "https://arxiv.org/abs/2505.16409", "authors": ["Chaeeun Kim", "Seungone Kim"], "title": "FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS", "categories": ["cs.AI"], "comment": "Work In Progress", "summary": "Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in\nmulti-step reasoning and calling search engines at appropriate steps. However,\nexisting retrieval-augmented reasoning approaches rely on separate retrieval\nmodels, limiting the LRM's role in retrieval to deciding when to retrieve and\nhow to query. This separation not only increases hardware and operational costs\nbut also leads to errors in the retrieval process due to the representation\nbottleneck, a phenomenon where the retriever's embedding space is not\nexpressive enough to meet the generator's requirements. To address this, we\nshift our perspective from sequence-to-sequence matching to locating the\nanswer-containing paths within the corpus, and propose a novel framework called\nFREESON (Retriever-FREE Retrieval-Augmented ReaSONing). This framework enables\nLRMs to retrieve relevant knowledge on their own by acting as both a generator\nand retriever. To achieve this, we introduce a variant of the MCTS algorithm\nspecialized for the retrieval task, which we call CT-MCTS (Corpus-Traversing\nMonte Carlo Tree Search). In this algorithm, LRMs traverse through the corpus\ntoward answer-containing regions. Our results on five open-domain QA\nbenchmarks, including single-hop and multi-hop questions, show that FREESON\nachieves an average improvement of 14.4% in EM and F1 over four multi-step\nreasoning models with a separate retriever, and it also performs comparably to\nthe strongest baseline, surpassing it by 3% on PopQA and 2WikiMultihopQA.", "AI": {"tldr": "FREESON\u6846\u67b6\u901a\u8fc7CT-MCTS\u7b97\u6cd5\u4f7fLRMs\u540c\u65f6\u62c5\u4efb\u751f\u6210\u5668\u548c\u68c0\u7d22\u5668\uff0c\u51cf\u5c11\u786c\u4ef6\u6210\u672c\u5e76\u63d0\u9ad8\u68c0\u7d22\u7cbe\u5ea6\uff0c\u5728\u591a\u4e2aQA\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u68c0\u7d22\u589e\u5f3a\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56\u72ec\u7acb\u7684\u68c0\u7d22\u6a21\u578b\uff0c\u8fd9\u4e0d\u4ec5\u589e\u52a0\u4e86\u786c\u4ef6\u548c\u64cd\u4f5c\u6210\u672c\uff0c\u8fd8\u56e0\u8868\u793a\u74f6\u9888\u5bfc\u81f4\u68c0\u7d22\u8fc7\u7a0b\u4e2d\u7684\u9519\u8bef\u3002", "method": "\u63d0\u51faFREESON\u6846\u67b6\uff0c\u7ed3\u5408CT-MCTS\u7b97\u6cd5\uff0c\u8ba9LRMs\u81ea\u5df1\u68c0\u7d22\u76f8\u5173\u77e5\u8bc6\uff0c\u5145\u5f53\u751f\u6210\u5668\u548c\u68c0\u7d22\u5668\u7684\u89d2\u8272\u3002", "result": "\u5728\u4e94\u4e2a\u5f00\u653e\u9886\u57df\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFREESON\u6bd4\u56db\u4e2a\u5e26\u6709\u72ec\u7acb\u68c0\u7d22\u5668\u7684\u591a\u6b65\u63a8\u7406\u6a21\u578b\u5e73\u5747\u63d0\u9ad8\u4e8614.4%\u7684EM\u548cF1\u5206\u6570\uff0c\u5e76\u4e14\u5728PopQA\u548c2WikiMultihopQA\u4e0a\u5206\u522b\u8d85\u8d8a\u6700\u5f3a\u57fa\u7ebf3%\u3002", "conclusion": "FREESON\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u7d22\u589e\u5f3a\u63a8\u7406\u7684\u6548\u679c\uff0c\u964d\u4f4e\u4e86\u6210\u672c\uff0c\u5c55\u793a\u4e86LRMs\u4f5c\u4e3a\u751f\u6210\u5668\u548c\u68c0\u7d22\u5668\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.16210", "pdf": "https://arxiv.org/pdf/2505.16210", "abs": "https://arxiv.org/abs/2505.16210", "authors": ["Zhihang Cai", "Xingjun Zhang", "Zhendong Tan", "Zheng Wei"], "title": "NQKV: A KV Cache Quantization Scheme Based on Normal Distribution Characteristics", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "11 pages, 9 figures", "summary": "Large Language Models (LLMs) have demonstrated remarkable proficiency across\na wide range of tasks. However, LLMs often require larger batch sizes to\nenhance throughput or longer context lengths to meet task demands, which\nsignificantly increases the memory resource consumption of the Key-Value (KV)\ncache during inference, becoming a major bottleneck in LLM deployment. To\naddress this issue, quantization is a common and straightforward approach.\nCurrently, quantization methods for activations are limited to 8-bit, and\nquantization to even lower bits can lead to substantial accuracy drops. To\nfurther save space by quantizing the KV cache to even lower bits, we analyzed\nthe element distribution of the KV cache and designed the NQKV algorithm. Since\nthe elements within each block of the KV cache follow a normal distribution,\nNQKV employs per-block quantile quantization to achieve\ninformation-theoretically optimal quantization error. Without significantly\ncompromising model output quality, NQKV enables the OPT model to perform\ninference with an 2x larger batch size or a 4x longer context length, and it\nimproves throughput by 9.3x compared to when the KV cache is not used.", "AI": {"tldr": "\u4e3a\u4e86\u5e94\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63a8\u7406\u8fc7\u7a0b\u4e2dKV\u7f13\u5b58\u5185\u5b58\u6d88\u8017\u5927\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNQKV\u7684\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u901a\u8fc7\u5206\u6790KV\u7f13\u5b58\u5143\u7d20\u5206\u5e03\u5e76\u91c7\u7528\u57fa\u4e8e\u5757\u7684\u5206\u4f4d\u6570\u91cf\u5316\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u4fe1\u606f\u7406\u8bba\u4e0a\u6700\u4f18\u7684\u91cf\u5316\u8bef\u5dee\uff0c\u5e76\u5728\u4e0d\u663e\u8457\u5f71\u54cd\u6a21\u578b\u8f93\u51fa\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\uff0c\u4f7fOPT\u6a21\u578b\u80fd\u591f\u4ee52\u500d\u7684\u6279\u91cf\u5927\u5c0f\u62164\u500d\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u8fdb\u884c\u63a8\u7406\uff0c\u4e14\u76f8\u6bd4\u4e0d\u4f7f\u7528KV\u7f13\u5b58\u65f6\u63d0\u9ad8\u4e869.3\u500d\u7684\u541e\u5410\u91cf\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u901a\u5e38\u9700\u8981\u8f83\u5927\u7684\u6279\u91cf\u5927\u5c0f\u6765\u63d0\u9ad8\u541e\u5410\u91cf\u6216\u66f4\u957f\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u6765\u6ee1\u8db3\u4efb\u52a1\u9700\u6c42\uff0c\u8fd9\u4f1a\u663e\u8457\u589e\u52a0\u63a8\u7406\u8fc7\u7a0b\u4e2dKV\u7f13\u5b58\u7684\u5185\u5b58\u8d44\u6e90\u6d88\u8017\uff0c\u6210\u4e3aLLM\u90e8\u7f72\u4e2d\u7684\u4e3b\u8981\u74f6\u9888\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u964d\u4f4eKV\u7f13\u5b58\u7684\u5185\u5b58\u6d88\u8017\u3002", "method": "1. \u5206\u6790\u4e86KV\u7f13\u5b58\u7684\u5143\u7d20\u5206\u5e03\uff0c\u53d1\u73b0\u6bcf\u4e2a\u5757\u5185\u7684\u5143\u7d20\u9075\u5faa\u6b63\u6001\u5206\u5e03\u3002\n2. \u57fa\u4e8e\u4e0a\u8ff0\u53d1\u73b0\uff0c\u8bbe\u8ba1\u4e86NQKV\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u91c7\u7528\u57fa\u4e8e\u5757\u7684\u5206\u4f4d\u6570\u91cf\u5316\u65b9\u6cd5\u3002\n3. \u8be5\u65b9\u6cd5\u5728\u7406\u8bba\u4e0a\u5b9e\u73b0\u6700\u4f18\u7684\u91cf\u5316\u8bef\u5dee\uff0c\u4ece\u800c\u6709\u6548\u51cf\u5c11KV\u7f13\u5b58\u7684\u5185\u5b58\u5360\u7528\u3002", "result": "NQKV\u7b97\u6cd5\u80fd\u591f\u5728\u4e0d\u663e\u8457\u5f71\u54cd\u6a21\u578b\u8f93\u51fa\u8d28\u91cf\u7684\u60c5\u51b5\u4e0b\uff0c\u4f7fOPT\u6a21\u578b\uff1a\n- \u4f7f\u75282\u500d\u7684\u6279\u91cf\u5927\u5c0f\u8fdb\u884c\u63a8\u7406\uff1b\n- \u4f7f\u75284\u500d\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u8fdb\u884c\u63a8\u7406\uff1b\n- \u76f8\u6bd4\u4e0d\u4f7f\u7528KV\u7f13\u5b58\u65f6\uff0c\u63d0\u9ad8\u4e869.3\u500d\u7684\u541e\u5410\u91cf\u3002", "conclusion": "NQKV\u7b97\u6cd5\u901a\u8fc7\u5c06KV\u7f13\u5b58\u91cf\u5316\u5230\u66f4\u4f4e\u6bd4\u7279\uff0c\u5728\u4fdd\u6301\u6a21\u578b\u8f93\u51fa\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u6d88\u8017\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.16959", "pdf": "https://arxiv.org/pdf/2505.16959", "abs": "https://arxiv.org/abs/2505.16959", "authors": ["Alessandro Favero", "Antonio Sclocchi", "Matthieu Wyart"], "title": "Bigger Isn't Always Memorizing: Early Stopping Overparameterized Diffusion Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Diffusion probabilistic models have become a cornerstone of modern generative\nAI, yet the mechanisms underlying their generalization remain poorly\nunderstood. In fact, if these models were perfectly minimizing their training\nloss, they would just generate data belonging to their training set, i.e.,\nmemorize, as empirically found in the overparameterized regime. We revisit this\nview by showing that, in highly overparameterized diffusion models,\ngeneralization in natural data domains is progressively achieved during\ntraining before the onset of memorization. Our results, ranging from image to\nlanguage diffusion models, systematically support the empirical law that\nmemorization time is proportional to the dataset size. Generalization vs.\nmemorization is then best understood as a competition between time scales. We\nshow that this phenomenology is recovered in diffusion models learning a simple\nprobabilistic context-free grammar with random rules, where generalization\ncorresponds to the hierarchical acquisition of deeper grammar rules as training\ntime grows, and the generalization cost of early stopping can be characterized.\nWe summarize these results in a phase diagram. Overall, our results support\nthat a principled early-stopping criterion - scaling with dataset size - can\neffectively optimize generalization while avoiding memorization, with direct\nimplications for hyperparameter transfer and privacy-sensitive applications.", "AI": {"tldr": "\u6269\u6563\u6982\u7387\u6a21\u578b\u5728\u8bad\u7ec3\u524d\u4f1a\u7ecf\u5386\u4e00\u4e2a\u81ea\u7136\u6570\u636e\u9886\u57df\u7684\u6cdb\u5316\u8fc7\u7a0b\uff0c\u4e4b\u540e\u624d\u5f00\u59cb\u8bb0\u5fc6\u8bad\u7ec3\u96c6\uff0c\u4e14\u8bb0\u5fc6\u65f6\u95f4\u4e0e\u6570\u636e\u96c6\u5927\u5c0f\u6210\u6b63\u6bd4\u3002\u901a\u8fc7\u65e9\u505c\u7b56\u7565\u53ef\u4ee5\u4f18\u5316\u6cdb\u5316\u5e76\u907f\u514d\u8bb0\u5fc6\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u5c3d\u7ba1\u6269\u6563\u6982\u7387\u6a21\u578b\u5728\u751f\u6210\u5f0fAI\u4e2d\u5360\u636e\u6838\u5fc3\u5730\u4f4d\uff0c\u4f46\u5176\u6cdb\u5316\u7684\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002\u7814\u7a76\u8005\u5e0c\u671b\u7406\u89e3\u8fd9\u4e9b\u6a21\u578b\u5982\u4f55\u5728\u9ad8\u5ea6\u8fc7\u53c2\u6570\u5316\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6cdb\u5316\u800c\u975e\u5355\u7eaf\u8bb0\u5fc6\u8bad\u7ec3\u6570\u636e\u3002", "method": "\u7814\u7a76\u8005\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5728\u9ad8\u5ea6\u8fc7\u53c2\u6570\u5316\u7684\u6269\u6563\u6a21\u578b\u4e2d\uff0c\u6cdb\u5316\u5728\u8bb0\u5fc6\u5f00\u59cb\u4e4b\u524d\u5c31\u5df2\u7ecf\u9010\u6b65\u5b9e\u73b0\u3002\u4ed6\u4eec\u5206\u6790\u4e86\u4ece\u56fe\u50cf\u5230\u8bed\u8a00\u6269\u6563\u6a21\u578b\u7684\u591a\u79cd\u60c5\u51b5\uff0c\u5e76\u7814\u7a76\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u968f\u673a\u89c4\u5219\u7684\u6982\u7387\u4e0a\u4e0b\u6587\u65e0\u5173\u6587\u6cd5\u7684\u5b66\u4e60\u8fc7\u7a0b\uff0c\u4ee5\u63ed\u793a\u6cdb\u5316\u548c\u8bb0\u5fc6\u4e4b\u95f4\u7684\u52a8\u6001\u5173\u7cfb\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u8bb0\u5fc6\u65f6\u95f4\u4e0e\u6570\u636e\u96c6\u5927\u5c0f\u6210\u6b63\u6bd4\uff0c\u6cdb\u5316\u4e0e\u8bb0\u5fc6\u662f\u65f6\u95f4\u5c3a\u5ea6\u4e0a\u7684\u7ade\u4e89\u5173\u7cfb\u3002\u6b64\u5916\uff0c\u65e9\u505c\u7b56\u7565\u80fd\u591f\u6709\u6548\u4f18\u5316\u6cdb\u5316\u6027\u80fd\u5e76\u907f\u514d\u8fc7\u5ea6\u8bb0\u5fc6\u3002", "conclusion": "\u672c\u7814\u7a76\u652f\u6301\u4f7f\u7528\u4e0e\u6570\u636e\u96c6\u5927\u5c0f\u76f8\u5173\u7684\u65e9\u505c\u51c6\u5219\u6765\u4f18\u5316\u6269\u6563\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u8fd9\u5bf9\u8d85\u53c2\u6570\u8fc1\u79fb\u548c\u9690\u79c1\u654f\u611f\u7684\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2505.16448", "pdf": "https://arxiv.org/pdf/2505.16448", "abs": "https://arxiv.org/abs/2505.16448", "authors": ["Renfei Dang", "Shujian Huang", "Jiajun Chen"], "title": "Internal Bias in Reasoning Models leads to Overthinking", "categories": ["cs.AI"], "comment": null, "summary": "While current reasoning models possess strong exploratory capabilities, they\nare often criticized for overthinking due to redundant and unnecessary\nreflections. In this work, we reveal for the first time that overthinking in\nreasoning models may stem from their internal bias towards input texts. Upon\nencountering a reasoning problem, the model immediately forms a preliminary\nguess about the answer, which we term as an internal bias since it is not\nderived through actual reasoning. When this guess conflicts with its reasoning\nresult, the model tends to engage in reflection, leading to the waste of\ncomputational resources. Through further interpretability experiments, we find\nthat this behavior is largely driven by the model's excessive attention to the\ninput section, which amplifies the influence of internal bias on its\ndecision-making process. Additionally, by masking out the original input\nsection, the affect of internal bias can be effectively alleviated and the\nreasoning length could be reduced by 31%-53% across different complex reasoning\ntasks. Notably, in most cases, this approach also leads to improvements in\naccuracy. These findings demonstrate a causal relationship between internal\nbias and overthinking.", "AI": {"tldr": "\u5f53\u524d\u63a8\u7406\u6a21\u578b\u56e0\u5197\u4f59\u548c\u4e0d\u5fc5\u8981\u7684\u53cd\u601d\u800c\u88ab\u6279\u8bc4\u4e3a\u8fc7\u5ea6\u601d\u8003\u3002\u672c\u6587\u9996\u6b21\u63ed\u793a\uff0c\u8fd9\u79cd\u8fc7\u5ea6\u601d\u8003\u53ef\u80fd\u6e90\u4e8e\u6a21\u578b\u5bf9\u8f93\u5165\u6587\u672c\u7684\u5185\u90e8\u504f\u5dee\u3002\u901a\u8fc7\u53ef\u89e3\u91ca\u6027\u5b9e\u9a8c\u53d1\u73b0\uff0c\u8fc7\u5ea6\u5173\u6ce8\u8f93\u5165\u90e8\u5206\u4f1a\u653e\u5927\u5185\u90e8\u504f\u5dee\u5bf9\u51b3\u7b56\u8fc7\u7a0b\u7684\u5f71\u54cd\u3002\u5c4f\u853d\u539f\u59cb\u8f93\u5165\u90e8\u5206\u53ef\u6709\u6548\u7f13\u89e3\u5185\u90e8\u504f\u5dee\u5f71\u54cd\uff0c\u51cf\u5c1131%-53%\u7684\u63a8\u7406\u957f\u5ea6\uff0c\u5e76\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u63d0\u9ad8\u51c6\u786e\u6027\u3002\u8fd9\u8868\u660e\u5185\u90e8\u504f\u5dee\u4e0e\u8fc7\u5ea6\u601d\u8003\u4e4b\u95f4\u5b58\u5728\u56e0\u679c\u5173\u7cfb\u3002", "motivation": "\u5f53\u524d\u63a8\u7406\u6a21\u578b\u867d\u7136\u5177\u6709\u5f3a\u5927\u7684\u63a2\u7d22\u80fd\u529b\uff0c\u4f46\u56e0\u8fc7\u5ea6\u601d\u8003\uff08\u5197\u4f59\u548c\u4e0d\u5fc5\u8981\u7684\u53cd\u601d\uff09\u53d7\u5230\u6279\u8bc4\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5176\u539f\u56e0\u5e76\u4f18\u5316\u6a21\u578b\u6027\u80fd\u3002", "method": "1. \u63ed\u793a\u63a8\u7406\u6a21\u578b\u4e2d\u8fc7\u5ea6\u601d\u8003\u7684\u6839\u6e90\u4e3a\u5185\u90e8\u504f\u5dee\u3002\n2. \u901a\u8fc7\u53ef\u89e3\u91ca\u6027\u5b9e\u9a8c\u5206\u6790\u6a21\u578b\u5bf9\u8f93\u5165\u90e8\u5206\u7684\u8fc7\u5ea6\u5173\u6ce8\u5982\u4f55\u653e\u5927\u5185\u90e8\u504f\u5dee\u3002\n3. \u6d4b\u8bd5\u5c4f\u853d\u539f\u59cb\u8f93\u5165\u90e8\u5206\u5bf9\u63a8\u7406\u957f\u5ea6\u548c\u51c6\u786e\u6027\u7684\u6539\u5584\u6548\u679c\u3002", "result": "1. \u53d1\u73b0\u6a21\u578b\u7684\u8fc7\u5ea6\u601d\u8003\u884c\u4e3a\u4e3b\u8981\u7531\u5176\u5bf9\u8f93\u5165\u90e8\u5206\u7684\u8fc7\u5ea6\u5173\u6ce8\u5f15\u8d77\u3002\n2. \u5c4f\u853d\u539f\u59cb\u8f93\u5165\u90e8\u5206\u53ef\u6709\u6548\u51cf\u8f7b\u5185\u90e8\u504f\u5dee\u5f71\u54cd\uff0c\u51cf\u5c11\u63a8\u7406\u957f\u5ea631%-53%\u3002\n3. \u5728\u591a\u6570\u60c5\u51b5\u4e0b\uff0c\u8be5\u65b9\u6cd5\u8fd8\u63d0\u9ad8\u4e86\u63a8\u7406\u4efb\u52a1\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u5185\u90e8\u504f\u5dee\u4e0e\u8fc7\u5ea6\u601d\u8003\u4e4b\u95f4\u5b58\u5728\u56e0\u679c\u5173\u7cfb\uff0c\u51cf\u5c11\u5bf9\u8f93\u5165\u90e8\u5206\u7684\u8fc7\u5ea6\u5173\u6ce8\u53ef\u4ee5\u663e\u8457\u6539\u5584\u63a8\u7406\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2505.16217", "pdf": "https://arxiv.org/pdf/2505.16217", "abs": "https://arxiv.org/abs/2505.16217", "authors": ["Hon Tik Tse", "Siddarth Chandrasekar", "Marlos C. Machado"], "title": "Reward-Aware Proto-Representations in Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, the successor representation (SR) has attracted increasing\nattention in reinforcement learning (RL), and it has been used to address some\nof its key challenges, such as exploration, credit assignment, and\ngeneralization. The SR can be seen as representing the underlying credit\nassignment structure of the environment by implicitly encoding its induced\ntransition dynamics. However, the SR is reward-agnostic. In this paper, we\ndiscuss a similar representation that also takes into account the reward\ndynamics of the problem. We study the default representation (DR), a recently\nproposed representation with limited theoretical (and empirical) analysis.\nHere, we lay some of the theoretical foundation underlying the DR in the\ntabular case by (1) deriving dynamic programming and (2) temporal-difference\nmethods to learn the DR, (3) characterizing the basis for the vector space of\nthe DR, and (4) formally extending the DR to the function approximation case\nthrough default features. Empirically, we analyze the benefits of the DR in\nmany of the settings in which the SR has been applied, including (1) reward\nshaping, (2) option discovery, (3) exploration, and (4) transfer learning. Our\nresults show that, compared to the SR, the DR gives rise to qualitatively\ndifferent, reward-aware behaviour and quantitatively better performance in\nseveral settings.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u9ed8\u8ba4\u8868\u793a\uff08DR\uff09\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u4e86\u5176\u5728\u5956\u52b1\u5851\u9020\u3001\u9009\u9879\u53d1\u73b0\u3001\u63a2\u7d22\u548c\u8fc1\u79fb\u5b66\u4e60\u7b49\u8bbe\u7f6e\u4e2d\u7684\u4f18\u52bf\u3002\u4e0e\u7ee7\u627f\u8868\u793a\uff08SR\uff09\u76f8\u6bd4\uff0cDR\u8868\u73b0\u51fa\u5b9a\u6027\u4e0d\u540c\u7684\u3001\u5956\u52b1\u611f\u77e5\u7684\u884c\u4e3a\uff0c\u5e76\u5728\u591a\u4e2a\u8bbe\u7f6e\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u7ee7\u627f\u8868\u793a\uff08SR\uff09\u5df2\u88ab\u7528\u4e8e\u89e3\u51b3\u63a2\u7d22\u3001\u4fe1\u7528\u5206\u914d\u548c\u6cdb\u5316\u7b49\u5173\u952e\u6311\u6218\uff0c\u4f46\u5b83\u4e0d\u8003\u8651\u5956\u52b1\u52a8\u6001\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u7c7b\u4f3c\u4f46\u80fd\u8003\u8651\u5956\u52b1\u52a8\u6001\u7684\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u5728\u8868\u683c\u60c5\u51b5\u4e0b\u7684\u9ed8\u8ba4\u8868\u793a\uff08DR\uff09\u5efa\u7acb\u4e86\u7406\u8bba\u57fa\u7840\uff1a(1) \u63a8\u5bfc\u52a8\u6001\u89c4\u5212\u548c\u65f6\u95f4\u5dee\u5206\u65b9\u6cd5\u6765\u5b66\u4e60DR\uff1b(2) \u523b\u753bDR\u5411\u91cf\u7a7a\u95f4\u7684\u57fa\u7840\uff1b(3) \u901a\u8fc7\u9ed8\u8ba4\u7279\u5f81\u5c06DR\u6269\u5c55\u5230\u51fd\u6570\u903c\u8fd1\u60c5\u51b5\u3002\u540c\u65f6\uff0c\u5728\u5956\u52b1\u5851\u9020\u3001\u9009\u9879\u53d1\u73b0\u3001\u63a2\u7d22\u548c\u8fc1\u79fb\u5b66\u4e60\u7b49\u591a\u4e2a\u573a\u666f\u4e2d\u5bf9DR\u8fdb\u884c\u4e86\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u7ee7\u627f\u8868\u793a\uff08SR\uff09\u76f8\u6bd4\uff0cDR\u4ea7\u751f\u4e86\u5b9a\u6027\u4e0d\u540c\u7684\u3001\u5956\u52b1\u611f\u77e5\u7684\u884c\u4e3a\uff0c\u5e76\u5728\u591a\u4e2a\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u5b9a\u91cf\u4e0a\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u9ed8\u8ba4\u8868\u793a\uff08DR\uff09\u662f\u4e00\u79cd\u80fd\u591f\u8003\u8651\u5956\u52b1\u52a8\u6001\u7684\u8868\u793a\u65b9\u6cd5\uff0c\u5b83\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u4e0a\u90fd\u5c55\u73b0\u4e86\u6bd4\u7ee7\u627f\u8868\u793a\uff08SR\uff09\u66f4\u4f18\u8d8a\u7684\u7279\u6027\uff0c\u7279\u522b\u662f\u5728\u5956\u52b1\u611f\u77e5\u884c\u4e3a\u548c\u6027\u80fd\u65b9\u9762\u3002"}}
{"id": "2505.17004", "pdf": "https://arxiv.org/pdf/2505.17004", "abs": "https://arxiv.org/abs/2505.17004", "authors": ["Jiachen Yao", "Abbas Mammadov", "Julius Berner", "Gavin Kerrigan", "Jong Chul Ye", "Kamyar Azizzadenesheli", "Anima Anandkumar"], "title": "Guided Diffusion Sampling on Function Spaces with Applications to PDEs", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "stat.ML"], "comment": null, "summary": "We propose a general framework for conditional sampling in PDE-based inverse\nproblems, targeting the recovery of whole solutions from extremely sparse or\nnoisy measurements. This is accomplished by a function-space diffusion model\nand plug-and-play guidance for conditioning. Our method first trains an\nunconditional discretization-agnostic denoising model using neural operator\narchitectures. At inference, we refine the samples to satisfy sparse\nobservation data via a gradient-based guidance mechanism. Through rigorous\nmathematical analysis, we extend Tweedie's formula to infinite-dimensional\nHilbert spaces, providing the theoretical foundation for our posterior sampling\napproach. Our method (FunDPS) accurately captures posterior distributions in\nfunction spaces under minimal supervision and severe data scarcity. Across five\nPDE tasks with only 3% observation, our method achieves an average 32% accuracy\nimprovement over state-of-the-art fixed-resolution diffusion baselines while\nreducing sampling steps by 4x. Furthermore, multi-resolution fine-tuning\nensures strong cross-resolution generalizability. To the best of our knowledge,\nthis is the first diffusion-based framework to operate independently of\ndiscretization, offering a practical and flexible solution for forward and\ninverse problems in the context of PDEs. Code is available at\nhttps://github.com/neuraloperator/FunDPS", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u6846\u67b6FunDPS\uff0c\u7528\u4e8e\u57fa\u4e8ePDE\u7684\u53cd\u95ee\u9898\u4e2d\u7684\u6761\u4ef6\u91c7\u6837\u3002\u901a\u8fc7\u51fd\u6570\u7a7a\u95f4\u6269\u6563\u6a21\u578b\u548c\u63d2\u4ef6\u5f0f\u5f15\u5bfc\u65b9\u6cd5\uff0c\u5728\u6781\u7a00\u758f\u6216\u5608\u6742\u7684\u6d4b\u91cf\u6761\u4ef6\u4e0b\u6062\u590d\u5b8c\u6574\u89e3\u3002\u8be5\u65b9\u6cd5\u9996\u5148\u8bad\u7ec3\u4e00\u4e2a\u65e0\u6761\u4ef6\u7684\u3001\u4e0e\u79bb\u6563\u5316\u65e0\u5173\u7684\u53bb\u566a\u6a21\u578b\uff0c\u4f7f\u7528\u795e\u7ecf\u7b97\u5b50\u67b6\u6784\u3002\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u901a\u8fc7\u57fa\u4e8e\u68af\u5ea6\u7684\u5f15\u5bfc\u673a\u5236\u4f18\u5316\u6837\u672c\u4ee5\u6ee1\u8db3\u7a00\u758f\u89c2\u6d4b\u6570\u636e\u3002\u901a\u8fc7\u4e25\u683c\u7684\u6570\u5b66\u5206\u6790\uff0c\u5c06Tweedie\u516c\u5f0f\u6269\u5c55\u5230\u65e0\u9650\u7ef4\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff0c\u4e3a\u540e\u9a8c\u91c7\u6837\u65b9\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002\u5728\u4ec5\u67093%\u89c2\u6d4b\u6570\u636e\u7684\u4e94\u4e2aPDE\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6bd4\u6700\u5148\u8fdb\u7684\u56fa\u5b9a\u5206\u8fa8\u7387\u6269\u6563\u57fa\u7ebf\u5e73\u5747\u63d0\u9ad8\u4e8632%\u7684\u51c6\u786e\u6027\uff0c\u5e76\u51cf\u5c11\u4e864\u500d\u7684\u91c7\u6837\u6b65\u9aa4\u3002\u6b64\u5916\uff0c\u591a\u5206\u8fa8\u7387\u5fae\u8c03\u786e\u4fdd\u4e86\u5f3a\u5927\u7684\u8de8\u5206\u8fa8\u7387\u6cdb\u5316\u80fd\u529b\u3002\u8fd9\u662f\u7b2c\u4e00\u4e2a\u72ec\u7acb\u4e8e\u79bb\u6563\u5316\u7684\u6269\u6563\u6a21\u578b\u6846\u67b6\uff0c\u4e3aPDE\u4e2d\u7684\u6b63\u5411\u548c\u53cd\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8ePDE\u7684\u53cd\u95ee\u9898\u89e3\u51b3\u65b9\u6cd5\u5728\u9762\u5bf9\u6781\u7a00\u758f\u6216\u566a\u58f0\u6d4b\u91cf\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u7279\u522b\u662f\u5728\u4e25\u91cd\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u51c6\u786e\u5730\u6062\u590d\u5b8c\u6574\u89e3\u5e76\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "1. \u63d0\u51faFunDPS\u6846\u67b6\uff1a\u7ed3\u5408\u51fd\u6570\u7a7a\u95f4\u6269\u6563\u6a21\u578b\u548c\u63d2\u4ef6\u5f0f\u5f15\u5bfc\u65b9\u6cd5\u8fdb\u884c\u6761\u4ef6\u91c7\u6837\u3002\n2. \u8bad\u7ec3\u9636\u6bb5\uff1a\u4f7f\u7528\u795e\u7ecf\u7b97\u5b50\u67b6\u6784\u6784\u5efa\u4e00\u4e2a\u65e0\u6761\u4ef6\u7684\u3001\u4e0e\u79bb\u6563\u5316\u65e0\u5173\u7684\u53bb\u566a\u6a21\u578b\u3002\n3. \u63a8\u7406\u9636\u6bb5\uff1a\u901a\u8fc7\u57fa\u4e8e\u68af\u5ea6\u7684\u5f15\u5bfc\u673a\u5236\u4f18\u5316\u6837\u672c\uff0c\u4f7f\u5176\u6ee1\u8db3\u7a00\u758f\u89c2\u6d4b\u6570\u636e\u3002\n4. \u7406\u8bba\u652f\u6301\uff1a\u5c06Tweedie\u516c\u5f0f\u6269\u5c55\u5230\u65e0\u9650\u7ef4\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff0c\u4e3a\u540e\u9a8c\u91c7\u6837\u65b9\u6cd5\u63d0\u4f9b\u7406\u8bba\u4f9d\u636e\u3002\n5. \u591a\u5206\u8fa8\u7387\u5fae\u8c03\uff1a\u786e\u4fdd\u6a21\u578b\u5177\u6709\u5f3a\u5927\u7684\u8de8\u5206\u8fa8\u7387\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5728\u4e94\u4e2aPDE\u4efb\u52a1\u4e2d\uff0c\u4ec5\u4f7f\u75283%\u7684\u89c2\u6d4b\u6570\u636e\uff0cFunDPS\u65b9\u6cd5\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u7684\u56fa\u5b9a\u5206\u8fa8\u7387\u6269\u6563\u57fa\u7ebf\u5e73\u5747\u63d0\u9ad8\u4e8632%\u7684\u51c6\u786e\u6027\uff0c\u5e76\u51cf\u5c11\u4e864\u500d\u7684\u91c7\u6837\u6b65\u9aa4\u3002", "conclusion": "FunDPS\u662f\u7b2c\u4e00\u4e2a\u72ec\u7acb\u4e8e\u79bb\u6563\u5316\u7684\u6269\u6563\u6a21\u578b\u6846\u67b6\uff0c\u80fd\u591f\u51c6\u786e\u6355\u83b7\u51fd\u6570\u7a7a\u95f4\u4e2d\u7684\u540e\u9a8c\u5206\u5e03\uff0c\u5373\u4f7f\u5728\u6781\u5c0f\u76d1\u7763\u548c\u4e25\u91cd\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u8868\u73b0\u51fa\u8272\u3002\u5b83\u4e3aPDE\u4e2d\u7684\u6b63\u5411\u548c\u53cd\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.16455", "pdf": "https://arxiv.org/pdf/2505.16455", "abs": "https://arxiv.org/abs/2505.16455", "authors": ["Mengzhu Liu", "Zhengqiu Zhu", "Chuan Ai", "Chen Gao", "Xinghong Li", "Lingnan He", "Kaisheng Lai", "Yingfeng Chen", "Xin Lu", "Yong Li", "Quanjun Yin"], "title": "Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media during Sudden Disaster Events", "categories": ["cs.AI", "cs.CY"], "comment": null, "summary": "During sudden disaster events, accurately predicting public panic sentiment\non social media is crucial for proactive governance and crisis management.\nCurrent efforts on this problem face three main challenges: lack of finely\nannotated data hinders emotion prediction studies, unmodeled risk perception\ncauses prediction inaccuracies, and insufficient interpretability of panic\nformation mechanisms. We address these issues by proposing a Psychology-driven\ngenerative Agent framework (PsychoAgent) for explainable panic prediction based\non emotion arousal theory. Specifically, we first construct a fine-grained open\npanic emotion dataset (namely COPE) via human-large language models (LLMs)\ncollaboration to mitigate semantic bias. Then, we develop a framework\nintegrating cross-domain heterogeneous data grounded in psychological\nmechanisms to model risk perception and cognitive differences in emotion\ngeneration. To enhance interpretability, we design an LLM-based role-playing\nagent that simulates individual psychological chains through dedicatedly\ndesigned prompts. Experimental results on our annotated dataset show that\nPsychoAgent improves panic emotion prediction performance by 12.6% to 21.7%\ncompared to baseline models. Furthermore, the explainability and generalization\nof our approach is validated. Crucially, this represents a paradigm shift from\nopaque \"data-driven fitting\" to transparent \"role-based simulation with\nmechanistic interpretation\" for panic emotion prediction during emergencies.\nOur implementation is publicly available at:\nhttps://anonymous.4open.science/r/PsychoAgent-19DD.", "AI": {"tldr": "\u5728\u7a81\u53d1\u4e8b\u4ef6\u4e2d\uff0c\u51c6\u786e\u9884\u6d4b\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u516c\u4f17\u6050\u614c\u60c5\u7eea\u5bf9\u4e8e\u4e3b\u52a8\u6cbb\u7406\u548c\u5371\u673a\u7ba1\u7406\u81f3\u5173\u91cd\u8981\u3002\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u7684\u6311\u6218\uff08\u6570\u636e\u6807\u6ce8\u4e0d\u8db3\u3001\u98ce\u9669\u611f\u77e5\u672a\u5efa\u6a21\u4ee5\u53ca\u6050\u614c\u5f62\u6210\u673a\u5236\u7684\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\uff09\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u60c5\u7eea\u5524\u8d77\u7406\u8bba\u7684\u5fc3\u7406\u9a71\u52a8\u751f\u6210\u5f0f\u4ee3\u7406\u6846\u67b6PsychoAgent\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u6784\u5efa\u7ec6\u7c92\u5ea6\u6050\u614c\u60c5\u7eea\u6570\u636e\u96c6COPE\u3001\u6574\u5408\u8de8\u57df\u5f02\u6784\u6570\u636e\u5efa\u6a21\u98ce\u9669\u611f\u77e5\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8eLLM\u7684\u89d2\u8272\u626e\u6f14\u4ee3\u7406\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0cPsychoAgent\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u63d0\u5347\u4e8612.6%\u81f321.7%\u7684\u6050\u614c\u60c5\u7eea\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u5b9e\u73b0\u4e86\u4ece\u201c\u6570\u636e\u9a71\u52a8\u62df\u5408\u201d\u5230\u201c\u57fa\u4e8e\u89d2\u8272\u7684\u673a\u5236\u89e3\u91ca\u6a21\u62df\u201d\u7684\u8303\u5f0f\u8f6c\u53d8\u3002", "motivation": "\u5f53\u524d\u5728\u9884\u6d4b\u793e\u4ea4\u5a92\u4f53\u4e0a\u516c\u4f17\u6050\u614c\u60c5\u7eea\u7684\u7814\u7a76\u4e2d\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u7f3a\u4e4f\u7cbe\u7ec6\u6807\u6ce8\u7684\u6570\u636e\u9650\u5236\u4e86\u60c5\u7eea\u9884\u6d4b\u7814\u7a76\uff1b2\uff09\u672a\u5efa\u6a21\u7684\u98ce\u9669\u611f\u77e5\u5bfc\u81f4\u9884\u6d4b\u4e0d\u51c6\u786e\uff1b3\uff09\u6050\u614c\u5f62\u6210\u673a\u5236\u7684\u53ef\u89e3\u91ca\u6027\u4e0d\u8db3\u3002\u8fd9\u4e9b\u95ee\u9898\u4fc3\u4f7f\u4f5c\u8005\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "1\uff09\u6784\u5efa\u4e86\u4e00\u4e2a\u7ec6\u7c92\u5ea6\u7684\u516c\u5f00\u6050\u614c\u60c5\u7eea\u6570\u636e\u96c6COPE\uff0c\u901a\u8fc7\u4eba\u7c7b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u534f\u4f5c\u51cf\u5c11\u8bed\u4e49\u504f\u5dee\uff1b2\uff09\u5f00\u53d1\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u6574\u5408\u8de8\u57df\u5f02\u6784\u6570\u636e\uff0c\u57fa\u4e8e\u5fc3\u7406\u673a\u5236\u5efa\u6a21\u98ce\u9669\u611f\u77e5\u548c\u60c5\u7eea\u751f\u6210\u7684\u8ba4\u77e5\u5dee\u5f02\uff1b3\uff09\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u89d2\u8272\u626e\u6f14\u4ee3\u7406\uff0c\u901a\u8fc7\u4e13\u95e8\u8bbe\u8ba1\u7684\u63d0\u793a\u8bcd\u6a21\u62df\u4e2a\u4f53\u5fc3\u7406\u94fe\u6761\uff0c\u4ee5\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728\u81ea\u5efa\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPsychoAgent\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\u63d0\u9ad8\u4e8612.6%\u523021.7%\u7684\u6050\u614c\u60c5\u7eea\u9884\u6d4b\u6027\u80fd\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u7684\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002", "conclusion": "PsychoAgent\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4ece\u201c\u6570\u636e\u9a71\u52a8\u62df\u5408\u201d\u5230\u201c\u57fa\u4e8e\u89d2\u8272\u7684\u673a\u5236\u89e3\u91ca\u6a21\u62df\u201d\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u4e3a\u6050\u614c\u60c5\u7eea\u9884\u6d4b\u63d0\u4f9b\u4e86\u66f4\u900f\u660e\u548c\u53ef\u89e3\u91ca\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.16226", "pdf": "https://arxiv.org/pdf/2505.16226", "abs": "https://arxiv.org/abs/2505.16226", "authors": ["Zi-Jian Cheng", "Zi-Yi Jia", "Zhi Zhou", "Yu-Feng Li", "Lan-Zhe Guo"], "title": "Realistic Evaluation of TabPFN v2 in Open Environments", "categories": ["cs.LG"], "comment": null, "summary": "Tabular data, owing to its ubiquitous presence in real-world domains, has\ngarnered significant attention in machine learning research. While tree-based\nmodels have long dominated tabular machine learning tasks, the recently\nproposed deep learning model TabPFN v2 has emerged, demonstrating unparalleled\nperformance and scalability potential. Although extensive research has been\nconducted on TabPFN v2 to further improve performance, the majority of this\nresearch remains confined to closed environments, neglecting the challenges\nthat frequently arise in open environments. This raises the question: Can\nTabPFN v2 maintain good performance in open environments? To this end, we\nconduct the first comprehensive evaluation of TabPFN v2's adaptability in open\nenvironments. We construct a unified evaluation framework covering various\nreal-world challenges and assess the robustness of TabPFN v2 under open\nenvironments scenarios using this framework. Empirical results demonstrate that\nTabPFN v2 shows significant limitations in open environments but is suitable\nfor small-scale, covariate-shifted, and class-balanced tasks. Tree-based models\nremain the optimal choice for general tabular tasks in open environments. To\nfacilitate future research on open environments challenges, we advocate for\nopen environments tabular benchmarks, multi-metric evaluation, and universal\nmodules to strengthen model robustness. We publicly release our evaluation\nframework at https://anonymous.4open.science/r/tabpfn-ood-4E65.", "AI": {"tldr": "TabPFN v2\u5728\u5f00\u653e\u73af\u5883\u4e2d\u7684\u8868\u73b0\u6709\u9650\uff0c\u9002\u5408\u5c0f\u89c4\u6a21\u3001\u534f\u53d8\u91cf\u504f\u79fb\u548c\u7c7b\u522b\u5e73\u8861\u7684\u4efb\u52a1\uff0c\u800c\u57fa\u4e8e\u6811\u7684\u6a21\u578b\u4ecd\u7136\u662f\u5f00\u653e\u73af\u5883\u4e2d\u901a\u7528\u8868\u683c\u4efb\u52a1\u7684\u6700\u4f73\u9009\u62e9\u3002", "motivation": "\u5c3d\u7ba1\u5bf9TabPFN v2\u7684\u7814\u7a76\u5df2\u7ecf\u5f88\u591a\uff0c\u4f46\u5927\u591a\u6570\u7814\u7a76\u5c40\u9650\u4e8e\u5c01\u95ed\u73af\u5883\uff0c\u5ffd\u89c6\u4e86\u5f00\u653e\u73af\u5883\u4e2d\u5e38\u89c1\u7684\u6311\u6218\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u8bc4\u4f30TabPFN v2\u5728\u5f00\u653e\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u6db5\u76d6\u5404\u79cd\u73b0\u5b9e\u4e16\u754c\u7684\u6311\u6218\uff0c\u5e76\u4f7f\u7528\u8be5\u6846\u67b6\u8bc4\u4f30TabPFN v2\u5728\u5f00\u653e\u73af\u5883\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cTabPFN v2\u5728\u5f00\u653e\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u5c40\u9650\u6027\uff0c\u4f46\u5728\u5c0f\u89c4\u6a21\u3001\u534f\u53d8\u91cf\u504f\u79fb\u548c\u7c7b\u522b\u5e73\u8861\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u57fa\u4e8e\u6811\u7684\u6a21\u578b\u4ecd\u7136\u662f\u5f00\u653e\u73af\u5883\u4e2d\u901a\u7528\u8868\u683c\u4efb\u52a1\u7684\u6700\u4f73\u9009\u62e9\u3002\u4e3a\u4e86\u4fc3\u8fdb\u672a\u6765\u7684\u7814\u7a76\uff0c\u5efa\u8bae\u5efa\u7acb\u5f00\u653e\u73af\u5883\u7684\u8868\u683c\u57fa\u51c6\u3001\u591a\u6307\u6807\u8bc4\u4f30\u548c\u901a\u7528\u6a21\u5757\u4ee5\u589e\u5f3a\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2505.17010", "pdf": "https://arxiv.org/pdf/2505.17010", "abs": "https://arxiv.org/abs/2505.17010", "authors": ["Tim Genewein", "Kevin Wenliang Li", "Jordi Grau-Moya", "Anian Ruoss", "Laurent Orseau", "Marcus Hutter"], "title": "Understanding Prompt Tuning and In-Context Learning via Meta-Learning", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Prompting is one of the main ways to adapt a pretrained model to target\ntasks. Besides manually constructing prompts, many prompt optimization methods\nhave been proposed in the literature. Method development is mainly empirically\ndriven, with less emphasis on a conceptual understanding of prompting. In this\npaper we discuss how optimal prompting can be understood through a Bayesian\nview, which also implies some fundamental limitations of prompting that can\nonly be overcome by tuning weights. The paper explains in detail how\nmeta-trained neural networks behave as Bayesian predictors over the pretraining\ndistribution, whose hallmark feature is rapid in-context adaptation. Optimal\nprompting can be studied formally as conditioning these Bayesian predictors,\nyielding criteria for target tasks where optimal prompting is and is not\npossible. We support the theory with educational experiments on LSTMs and\nTransformers, where we compare different versions of prefix-tuning and\ndifferent weight-tuning methods. We also confirm that soft prefixes, which are\nsequences of real-valued vectors outside the token alphabet, can lead to very\neffective prompts for trained and even untrained networks by manipulating\nactivations in ways that are not achievable by hard tokens. This adds an\nimportant mechanistic aspect beyond the conceptual Bayesian theory.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u8d1d\u53f6\u65af\u89c6\u89d2\u89e3\u91ca\u4e86\u6700\u4f73\u63d0\u793a\uff08prompting\uff09\u7684\u6982\u5ff5\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u56fa\u6709\u9650\u5236\uff0c\u63d0\u51fa\u8f6f\u524d\u7f00\u80fd\u6709\u6548\u63d0\u5347\u63d0\u793a\u6548\u679c\uff0c\u540c\u65f6\u7ed3\u5408\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u4e0d\u540c\u6a21\u578b\u548c\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u591a\u4f9d\u8d56\u7ecf\u9a8c\u9a71\u52a8\uff0c\u7f3a\u4e4f\u5bf9\u63d0\u793a\u6982\u5ff5\u7684\u6df1\u5165\u7406\u89e3\uff0c\u56e0\u6b64\u9700\u8981\u4ece\u7406\u8bba\u89d2\u5ea6\u9610\u91ca\u63d0\u793a\u673a\u5236\u53ca\u5176\u9650\u5236\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u8d1d\u53f6\u65af\u89c6\u56fe\u7406\u89e3\u6700\u4f73\u63d0\u793a\uff0c\u5c06\u5143\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u89c6\u4e3a\u9884\u8bad\u7ec3\u5206\u5e03\u4e0a\u7684\u8d1d\u53f6\u65af\u9884\u6d4b\u5668\uff0c\u5e76\u7814\u7a76\u6761\u4ef6\u5316\u8fd9\u4e9b\u9884\u6d4b\u5668\u4ee5\u5f62\u6210\u6700\u4f73\u63d0\u793a\u7684\u6807\u51c6\u3002\u6b64\u5916\uff0c\u8fd8\u901a\u8fc7\u5b9e\u9a8c\u6bd4\u8f83LSTM\u548cTransformer\u5728\u4e0d\u540c\u524d\u7f00\u8c03\u4f18\u548c\u6743\u91cd\u8c03\u4f18\u65b9\u6cd5\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8f6f\u524d\u7f00\uff08soft prefixes\uff09\u53ef\u4ee5\u901a\u8fc7\u64cd\u7eb5\u6fc0\u6d3b\u65b9\u5f0f\u63d0\u4f9b\u6bd4\u786c\u6807\u8bb0\u66f4\u6709\u6548\u7684\u63d0\u793a\uff0c\u9002\u7528\u4e8e\u5df2\u8bad\u7ec3\u548c\u672a\u8bad\u7ec3\u7684\u7f51\u7edc\u3002\u8fd9\u4e3a\u63d0\u793a\u673a\u5236\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u673a\u68b0\u8bba\u4f9d\u636e\u3002", "conclusion": "\u6700\u4f73\u63d0\u793a\u53ef\u4ee5\u901a\u8fc7\u8d1d\u53f6\u65af\u7406\u8bba\u5f62\u5f0f\u5316\u7406\u89e3\uff0c\u4f46\u5176\u56fa\u6709\u9650\u5236\u53ea\u80fd\u901a\u8fc7\u8c03\u6574\u6743\u91cd\u514b\u670d\u3002\u8f6f\u524d\u7f00\u4e3a\u63d0\u793a\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u6807\u8bb0\u9650\u5236\u3002"}}
{"id": "2505.16459", "pdf": "https://arxiv.org/pdf/2505.16459", "abs": "https://arxiv.org/abs/2505.16459", "authors": ["Guiyao Tie", "Xueyang Zhou", "Tianhe Gu", "Ruihang Zhang", "Chaoran Hu", "Sizhe Zhang", "Mengqu Sun", "Yan Zhang", "Pan Zhou", "Lichao Sun"], "title": "MMMR: Benchmarking Massive Multi-Modal Reasoning Tasks", "categories": ["cs.AI"], "comment": "39 pages, 28 figures, 4 tables", "summary": "Recent advances in Multi-Modal Large Language Models (MLLMs) have enabled\nunified processing of language, vision, and structured inputs, opening the door\nto complex tasks such as logical deduction, spatial reasoning, and scientific\nanalysis. Despite their promise, the reasoning capabilities of MLLMs,\nparticularly those augmented with intermediate thinking traces (MLLMs-T),\nremain poorly understood and lack standardized evaluation benchmarks. Existing\nwork focuses primarily on perception or final answer correctness, offering\nlimited insight into how models reason or fail across modalities. To address\nthis gap, we introduce the MMMR, a new benchmark designed to rigorously\nevaluate multi-modal reasoning with explicit thinking. The MMMR comprises 1) a\nhigh-difficulty dataset of 1,083 questions spanning six diverse reasoning types\nwith symbolic depth and multi-hop demands and 2) a modular Reasoning Trace\nEvaluation Pipeline (RTEP) for assessing reasoning quality beyond accuracy\nthrough metrics like relevance, consistency, and structured error annotations.\nEmpirical results show that MLLMs-T overall outperform non-thinking\ncounterparts, but even top models like Claude-3.7-Sonnet and Gemini-2.5 Pro\nsuffer from reasoning pathologies such as inconsistency and overthinking. This\nbenchmark reveals persistent gaps between accuracy and reasoning quality and\nprovides an actionable evaluation pipeline for future model development.\nOverall, the MMMR offers a scalable foundation for evaluating, comparing, and\nimproving the next generation of multi-modal reasoning systems.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u51c6\uff08MMMR\uff09\uff0c\u7528\u4e8e\u8bc4\u4f30\u5177\u6709\u663e\u5f0f\u601d\u7ef4\u7684\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\uff0c\u5305\u62ec\u4e00\u4e2a\u9ad8\u96be\u5ea6\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u6a21\u5757\u5316\u63a8\u7406\u8ffd\u8e2a\u8bc4\u4f30\u7ba1\u9053\uff08RTEP\uff09\u3002\u7814\u7a76\u8868\u660e\uff0c\u5e26\u4e2d\u95f4\u601d\u7ef4\u75d5\u8ff9\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs-T\uff09\u603b\u4f53\u4f18\u4e8e\u4e0d\u5e26\u601d\u7ef4\u75d5\u8ff9\u7684\u6a21\u578b\uff0c\u4f46\u9876\u7ea7\u6a21\u578b\u4ecd\u5b58\u5728\u63a8\u7406\u4e0d\u4e00\u81f4\u7b49\u95ee\u9898\u3002\u8be5\u57fa\u51c6\u63ed\u793a\u4e86\u51c6\u786e\u6027\u548c\u63a8\u7406\u8d28\u91cf\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u4e3a\u672a\u6765\u6a21\u578b\u53d1\u5c55\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u63a8\u7406\u80fd\u529b\u7684\u7406\u89e3\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u4e14\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u611f\u77e5\u6216\u6700\u7ec8\u7b54\u6848\u7684\u6b63\u786e\u6027\uff0c\u672a\u80fd\u6df1\u5165\u5206\u6790\u6a21\u578b\u5728\u4e0d\u540c\u6a21\u6001\u4e0b\u7684\u63a8\u7406\u8fc7\u7a0b\u53ca\u5931\u8d25\u539f\u56e0\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\uff08MMMR\uff09\uff0c\u5305\u542b\uff1a1) \u4e00\u4e2a\u5305\u542b1,083\u4e2a\u95ee\u9898\u7684\u9ad8\u96be\u5ea6\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u516d\u79cd\u591a\u6837\u63a8\u7406\u7c7b\u578b\uff1b2) \u4e00\u4e2a\u6a21\u5757\u5316\u63a8\u7406\u8ffd\u8e2a\u8bc4\u4f30\u7ba1\u9053\uff08RTEP\uff09\uff0c\u901a\u8fc7\u76f8\u5173\u6027\u3001\u4e00\u81f4\u6027\u7b49\u6307\u6807\u8bc4\u4f30\u63a8\u7406\u8d28\u91cf\uff0c\u5e76\u8fdb\u884c\u7ed3\u6784\u5316\u9519\u8bef\u6807\u6ce8\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u5e26\u4e2d\u95f4\u601d\u7ef4\u75d5\u8ff9\u7684MLLMs-T\u603b\u4f53\u4e0a\u4f18\u4e8e\u975e\u601d\u7ef4\u75d5\u8ff9\u6a21\u578b\uff0c\u4f46\u5373\u4f7f\u662f\u9876\u7ea7\u6a21\u578b\u5982Claude-3.7-Sonnet\u548cGemini-2.5 Pro\u4e5f\u5b58\u5728\u63a8\u7406\u4e0d\u4e00\u81f4\u548c\u8fc7\u5ea6\u601d\u8003\u7b49\u95ee\u9898\u3002", "conclusion": "MMMR\u57fa\u51c6\u63ed\u793a\u4e86\u51c6\u786e\u6027\u548c\u63a8\u7406\u8d28\u91cf\u4e4b\u95f4\u7684\u6301\u7eed\u5dee\u8ddd\uff0c\u4e3a\u8bc4\u4f30\u3001\u6bd4\u8f83\u548c\u6539\u8fdb\u4e0b\u4e00\u4ee3\u591a\u6a21\u6001\u63a8\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2505.16242", "pdf": "https://arxiv.org/pdf/2505.16242", "abs": "https://arxiv.org/abs/2505.16242", "authors": ["Runze Yan", "Xun Shen", "Akifumi Wachi", "Sebastien Gros", "Anni Zhao", "Xiao Hu"], "title": "Offline Guarded Safe Reinforcement Learning for Medical Treatment Optimization Strategies", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "When applying offline reinforcement learning (RL) in healthcare scenarios,\nthe out-of-distribution (OOD) issues pose significant risks, as inappropriate\ngeneralization beyond clinical expertise can result in potentially harmful\nrecommendations. While existing methods like conservative Q-learning (CQL)\nattempt to address the OOD issue, their effectiveness is limited by only\nconstraining action selection by suppressing uncertain actions. This\naction-only regularization imitates clinician actions that prioritize\nshort-term rewards, but it fails to regulate downstream state trajectories,\nthereby limiting the discovery of improved long-term treatment strategies. To\nsafely improve policy beyond clinician recommendations while ensuring that\nstate-action trajectories remain in-distribution, we propose \\textit{Offline\nGuarded Safe Reinforcement Learning} ($\\mathsf{OGSRL}$), a theoretically\ngrounded model-based offline RL framework. $\\mathsf{OGSRL}$ introduces a novel\ndual constraint mechanism for improving policy with reliability and safety.\nFirst, the OOD guardian is established to specify clinically validated regions\nfor safe policy exploration. By constraining optimization within these regions,\nit enables the reliable exploration of treatment strategies that outperform\nclinician behavior by leveraging the full patient state history, without\ndrifting into unsupported state-action trajectories. Second, we introduce a\nsafety cost constraint that encodes medical knowledge about physiological\nsafety boundaries, providing domain-specific safeguards even in areas where\ntraining data might contain potentially unsafe interventions. Notably, we\nprovide theoretical guarantees on safety and near-optimality: policies that\nsatisfy these constraints remain in safe and reliable regions and achieve\nperformance close to the best possible policy supported by the data.", "AI": {"tldr": "\u5728\u533b\u7597\u573a\u666f\u4e2d\u5e94\u7528\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65f6\uff0cOOD\u95ee\u9898\u53ef\u80fd\u5e26\u6765\u91cd\u5927\u98ce\u9669\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u5982\u4fdd\u5b88Q\u5b66\u4e60\uff08CQL\uff09\u4ec5\u901a\u8fc7\u6291\u5236\u4e0d\u786e\u5b9a\u52a8\u4f5c\u6765\u7ea6\u675f\u52a8\u4f5c\u9009\u62e9\uff0c\u4f46\u672a\u80fd\u6709\u6548\u89c4\u5236\u4e0b\u6e38\u72b6\u6001\u8f68\u8ff9\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u578b\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u2014\u2014\u79bb\u7ebf\u5b88\u62a4\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\uff08OGSRL\uff09\uff0c\u5f15\u5165\u53cc\u91cd\u7ea6\u675f\u673a\u5236\uff0c\u5728\u786e\u4fdd\u72b6\u6001-\u52a8\u4f5c\u8f68\u8ff9\u5206\u5e03\u5185\u7684\u60c5\u51b5\u4e0b\u5b89\u5168\u5730\u6539\u8fdb\u7b56\u7565\u3002\u8be5\u6846\u67b6\u5305\u62ec\u4e00\u4e2aOOD\u5b88\u62a4\u6a21\u5757\u548c\u4e00\u4e2a\u5b89\u5168\u6027\u6210\u672c\u7ea6\u675f\uff0c\u63d0\u4f9b\u7406\u8bba\u4e0a\u7684\u5b89\u5168\u6027\u548c\u8fd1\u4f3c\u6700\u4f18\u6027\u4fdd\u8bc1\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u5728\u533b\u7597\u573a\u666f\u4e2d\u7684\u5e94\u7528\u9762\u4e34OOD\u95ee\u9898\u7684\u91cd\u5927\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u867d\u7136\u5c1d\u8bd5\u89e3\u51b3\uff0c\u4f46\u6548\u679c\u6709\u9650\uff0c\u56e0\u4e3a\u5b83\u4eec\u4ec5\u5173\u6ce8\u52a8\u4f5c\u9009\u62e9\u7684\u7ea6\u675f\u800c\u5ffd\u7565\u4e86\u5bf9\u72b6\u6001\u8f68\u8ff9\u7684\u89c4\u5236\u3002\u8fd9\u9650\u5236\u4e86\u53d1\u73b0\u957f\u671f\u6cbb\u7597\u7b56\u7565\u7684\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u5728\u786e\u4fdd\u5b89\u5168\u7684\u540c\u65f6\u6539\u8fdb\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u79bb\u7ebf\u5b88\u62a4\u5b89\u5168\u5f3a\u5316\u5b66\u4e60\uff08OGSRL\uff09\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a1\uff09OOD\u5b88\u62a4\u6a21\u5757\uff0c\u7528\u4e8e\u5b9a\u4e49\u4e34\u5e8a\u9a8c\u8bc1\u7684\u5b89\u5168\u533a\u57df\u5e76\u9650\u5236\u4f18\u5316\u8fc7\u7a0b\u5728\u8fd9\u4e9b\u533a\u57df\u5185\u8fdb\u884c\uff1b2\uff09\u5b89\u5168\u6027\u6210\u672c\u7ea6\u675f\uff0c\u5c06\u533b\u5b66\u77e5\u8bc6\u7f16\u7801\u4e3a\u751f\u7406\u5b89\u5168\u8fb9\u754c\u4ee5\u9632\u6b62\u6f5c\u5728\u5371\u9669\u5e72\u9884\u3002\u901a\u8fc7\u8fd9\u4e24\u4e2a\u673a\u5236\uff0cOGSRL\u80fd\u591f\u5728\u4e0d\u504f\u79bb\u652f\u6301\u7684\u72b6\u6001-\u52a8\u4f5c\u8f68\u8ff9\u7684\u524d\u63d0\u4e0b\u63a2\u7d22\u4f18\u4e8e\u4e34\u5e8a\u533b\u751f\u884c\u4e3a\u7684\u6cbb\u7597\u7b56\u7565\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\u7684\u7b56\u7565\u80fd\u591f\u4fdd\u6301\u5728\u5b89\u5168\u53ef\u9760\u533a\u57df\u5185\uff0c\u5e76\u5b9e\u73b0\u63a5\u8fd1\u6570\u636e\u652f\u6301\u7684\u6700\u4f73\u7b56\u7565\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0cOGSRL\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u6539\u8fdb\u7b56\u7565\uff0c\u540c\u65f6\u786e\u4fdd\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u3002", "conclusion": "OGSRL\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u533b\u7597\u573a\u666f\u4e2d\u5b89\u5168\u5730\u6539\u8fdb\u7b56\u7565\uff0c\u8d85\u8d8a\u4e34\u5e8a\u533b\u751f\u63a8\u8350\u7684\u884c\u4e3a\uff0c\u540c\u65f6\u786e\u4fdd\u72b6\u6001-\u52a8\u4f5c\u8f68\u8ff9\u4fdd\u6301\u5728\u5206\u5e03\u5185\u3002\u8fd9\u79cd\u65b9\u6cd5\u5177\u6709\u7406\u8bba\u4fdd\u969c\uff0c\u5e76\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.16475", "pdf": "https://arxiv.org/pdf/2505.16475", "abs": "https://arxiv.org/abs/2505.16475", "authors": ["Jiaqi Li", "Xinyi Dong", "Yang Liu", "Zhizhuo Yang", "Quansen Wang", "Xiaobo Wang", "SongChun Zhu", "Zixia Jia", "Zilong Zheng"], "title": "ReflectEvo: Improving Meta Introspection of Small LLMs by Learning Self-Reflection", "categories": ["cs.AI"], "comment": null, "summary": "We present a novel pipeline, ReflectEvo, to demonstrate that small language\nmodels (SLMs) can enhance meta introspection through reflection learning. This\nprocess iteratively generates self-reflection for self-training, fostering a\ncontinuous and self-evolving process. Leveraging this pipeline, we construct\nReflectEvo-460k, a large-scale, comprehensive, self-generated reflection\ndataset with broadened instructions and diverse multi-domain tasks. Building\nupon this dataset, we demonstrate the effectiveness of reflection learning to\nimprove SLMs' reasoning abilities using SFT and DPO with remarkable\nperformance, substantially boosting Llama-3 from 52.4% to 71.2% and Mistral\nfrom 44.4% to 71.1%. It validates that ReflectEvo can rival or even surpass the\nreasoning capability of the three prominent open-sourced models on BIG-bench\nwithout distillation from superior models or fine-grained human annotation. We\nfurther conduct a deeper analysis of the high quality of self-generated\nreflections and their impact on error localization and correction. Our work\nhighlights the potential of continuously enhancing the reasoning performance of\nSLMs through iterative reflection learning in the long run.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86ReflectEvo\uff0c\u4e00\u4e2a\u5c55\u793a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u53cd\u601d\u5b66\u4e60\u589e\u5f3a\u5143\u5185\u7701\u7684\u65b0\u9896\u6d41\u7a0b\u3002\u4f7f\u7528SFT\u548cDPO\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86Llama-3\u548cMistral\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4e14\u5728\u6ca1\u6709\u84b8\u998f\u6216\u7cbe\u7ec6\u4eba\u5de5\u6807\u6ce8\u7684\u60c5\u51b5\u4e0b\u8d85\u8d8a\u4e86\u4e09\u4e2a\u77e5\u540d\u5f00\u6e90\u6a21\u578b\u7684BIG-bench\u8868\u73b0\u3002\u6b64\u5916\uff0c\u8fd8\u5206\u6790\u4e86\u81ea\u52a8\u751f\u6210\u7684\u9ad8\u8d28\u91cf\u53cd\u601d\u5bf9\u9519\u8bef\u5b9a\u4f4d\u548c\u7ea0\u6b63\u7684\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6027\u80fd\uff0c\u4f46\u5176\u8ba1\u7b97\u548c\u5b58\u50a8\u6210\u672c\u8f83\u9ad8\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u63d0\u5347\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u7684\u63a8\u7406\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u53cd\u601d\u5b66\u4e60\u6765\u6301\u7eed\u6539\u8fdbSLMs\u7684\u5143\u5185\u7701\u80fd\u529b\u3002", "method": "1. \u63d0\u51faReflectEvo\u6d41\u7a0b\uff0c\u901a\u8fc7\u8fed\u4ee3\u751f\u6210\u81ea\u6211\u53cd\u601d\u8fdb\u884c\u81ea\u6211\u8bad\u7ec3\uff0c\u5f62\u6210\u8fde\u7eed\u7684\u81ea\u6211\u8fdb\u5316\u8fc7\u7a0b\u3002\n2. \u6784\u5efa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u7efc\u5408\u6027\u7684\u81ea\u6211\u751f\u6210\u53cd\u601d\u6570\u636e\u96c6ReflectEvo-460k\uff0c\u5305\u542b\u6269\u5c55\u7684\u6307\u4ee4\u548c\u591a\u9886\u57df\u7684\u591a\u6837\u5316\u4efb\u52a1\u3002\n3. \u4f7f\u7528\u8be5\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u57fa\u4e8e\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u7684\u65b9\u6cd5\u9a8c\u8bc1\u53cd\u601d\u5b66\u4e60\u5bf9\u63d0\u5347SLMs\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u6027\u3002\n4. \u5bf9\u81ea\u52a8\u751f\u6210\u7684\u9ad8\u8d28\u91cf\u53cd\u601d\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790\uff0c\u63a2\u8ba8\u5176\u5bf9\u9519\u8bef\u5b9a\u4f4d\u548c\u7ea0\u6b63\u7684\u5f71\u54cd\u3002", "result": "1. \u53cd\u601d\u5b66\u4e60\u663e\u8457\u63d0\u9ad8\u4e86SLMs\u7684\u63a8\u7406\u80fd\u529b\uff1a\n   - Llama-3\u4ece52.4%\u63d0\u5347\u523071.2%\u3002\n   - Mistral\u4ece44.4%\u63d0\u5347\u523071.1%\u3002\n2. ReflectEvo\u80fd\u591f\u5728\u65e0\u9700\u84b8\u998f\u6216\u7cbe\u7ec6\u4eba\u5de5\u6807\u6ce8\u7684\u60c5\u51b5\u4e0b\uff0c\u4e0e\u4e09\u4e2a\u77e5\u540d\u7684\u5f00\u6e90\u6a21\u578b\u5728BIG-bench\u4e0a\u7684\u63a8\u7406\u80fd\u529b\u76f8\u5ab2\u7f8e\u751a\u81f3\u8d85\u8d8a\u3002\n3. \u9ad8\u8d28\u91cf\u7684\u81ea\u52a8\u751f\u6210\u53cd\u601d\u5bf9\u9519\u8bef\u5b9a\u4f4d\u548c\u7ea0\u6b63\u5177\u6709\u79ef\u6781\u5f71\u54cd\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u8fed\u4ee3\u53cd\u601d\u5b66\u4e60\u53ef\u4ee5\u6301\u7eed\u63d0\u9ad8SLMs\u7684\u63a8\u7406\u6027\u80fd\u3002\u63d0\u51fa\u7684ReflectEvo\u6d41\u7a0b\u53ca\u5176\u884d\u751f\u7684\u6570\u636e\u96c6\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\uff0c\u5c55\u793a\u4e86\u53cd\u601d\u5b66\u4e60\u5728\u63d0\u5347SLMs\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2505.16248", "pdf": "https://arxiv.org/pdf/2505.16248", "abs": "https://arxiv.org/abs/2505.16248", "authors": ["Wenxuan Zhu", "Qiyuan Wu", "Tengda Tang", "Renzi Meng", "Sheng Chai", "Xuehui Quan"], "title": "Graph Neural Network-Based Collaborative Perception for Adaptive Scheduling in Distributed Systems", "categories": ["cs.LG"], "comment": null, "summary": "This paper addresses the limitations of multi-node perception and delayed\nscheduling response in distributed systems by proposing a GNN-based multi-node\ncollaborative perception mechanism. The system is modeled as a graph structure.\nMessage-passing and state-update modules are introduced. A multi-layer graph\nneural network is constructed to enable efficient information aggregation and\ndynamic state inference among nodes. In addition, a perception representation\nmethod is designed by fusing local states with global features. This improves\neach node's ability to perceive the overall system status. The proposed method\nis evaluated within a customized experimental framework. A dataset featuring\nheterogeneous task loads and dynamic communication topologies is used.\nPerformance is measured in terms of task completion rate, average latency, load\nbalancing, and transmission efficiency. Experimental results show that the\nproposed method outperforms mainstream algorithms under various conditions,\nincluding limited bandwidth and dynamic structural changes. It demonstrates\nsuperior perception capabilities and cooperative scheduling performance. The\nmodel achieves rapid convergence and efficient responses to complex system\nstates.", "AI": {"tldr": "A GNN-based multi-node collaborative perception mechanism is proposed to address limitations in distributed systems, showing superior performance in experiments.", "motivation": "To overcome the limitations of multi-node perception and delayed scheduling response in distributed systems.", "method": "The system is modeled as a graph structure with message-passing and state-update modules. A multi-layer GNN is constructed for information aggregation and state inference. A perception representation method fuses local states with global features.", "result": "The proposed method outperforms mainstream algorithms in task completion rate, average latency, load balancing, and transmission efficiency under various conditions including limited bandwidth and dynamic structural changes.", "conclusion": "The GNN-based multi-node collaborative perception mechanism demonstrates superior perception capabilities and cooperative scheduling performance."}}
{"id": "2505.16477", "pdf": "https://arxiv.org/pdf/2505.16477", "abs": "https://arxiv.org/abs/2505.16477", "authors": ["Yanbo Zhang", "Sumeer A. Khan", "Adnan Mahmud", "Huck Yang", "Alexander Lavin", "Michael Levin", "Jeremy Frey", "Jared Dunnmon", "James Evans", "Alan Bundy", "Saso Dzeroski", "Jesper Tegner", "Hector Zenil"], "title": "Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery", "categories": ["cs.AI"], "comment": "45 pages", "summary": "With recent Nobel Prizes recognising AI contributions to science, Large\nLanguage Models (LLMs) are transforming scientific research by enhancing\nproductivity and reshaping the scientific method. LLMs are now involved in\nexperimental design, data analysis, and workflows, particularly in chemistry\nand biology. However, challenges such as hallucinations and reliability\npersist. In this contribution, we review how Large Language Models (LLMs) are\nredefining the scientific method and explore their potential applications\nacross different stages of the scientific cycle, from hypothesis testing to\ndiscovery. We conclude that, for LLMs to serve as relevant and effective\ncreative engines and productivity enhancers, their deep integration into all\nsteps of the scientific process should be pursued in collaboration and\nalignment with human scientific goals, with clear evaluation metrics. The\ntransition to AI-driven science raises ethical questions about creativity,\noversight, and responsibility. With careful guidance, LLMs could evolve into\ncreative engines, driving transformative breakthroughs across scientific\ndisciplines responsibly and effectively. However, the scientific community must\nalso decide how much it leaves to LLMs to drive science, even when associations\nwith 'reasoning', mostly currently undeserved, are made in exchange for the\npotential to explore hypothesis and solution regions that might otherwise\nremain unexplored by human exploration alone.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6b63\u5728\u901a\u8fc7\u63d0\u9ad8\u751f\u4ea7\u529b\u548c\u91cd\u5851\u79d1\u5b66\u65b9\u6cd5\u6765\u6539\u53d8\u79d1\u5b66\u7814\u7a76\uff0c\u5c3d\u7ba1\u5b58\u5728\u5e7b\u89c9\u548c\u53ef\u9760\u6027\u7b49\u6311\u6218\u3002\u5b83\u4eec\u5728\u79d1\u5b66\u5468\u671f\u7684\u5404\u4e2a\u9636\u6bb5\u90fd\u6709\u6f5c\u5728\u5e94\u7528\uff0c\u4f46\u9700\u8981\u4e0e\u4eba\u7c7b\u79d1\u5b66\u76ee\u6807\u534f\u4f5c\u5e76\u8bbe\u5b9a\u660e\u786e\u8bc4\u4f30\u6307\u6807\u3002\u5411AI\u9a71\u52a8\u79d1\u5b66\u8f6c\u53d8\u5f15\u53d1\u4f26\u7406\u95ee\u9898\uff0c\u9700\u8c28\u614e\u5f15\u5bfc\u4ee5\u5b9e\u73b0\u8d1f\u8d23\u4efb\u548c\u6709\u6548\u7684\u7a81\u7834\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0cAI\u5bf9\u79d1\u5b66\u53d1\u5c55\u8d21\u732e\u663e\u8457\uff0cLLMs\u5728\u63d0\u5347\u79d1\u7814\u751f\u4ea7\u529b\u548c\u91cd\u5851\u79d1\u5b66\u65b9\u6cd5\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u5316\u5b66\u548c\u751f\u7269\u5b66\u9886\u57df\u4e2d\u53c2\u4e0e\u5b9e\u9a8c\u8bbe\u8ba1\u3001\u6570\u636e\u5206\u6790\u548c\u5de5\u4f5c\u6d41\u7a0b\u3002\u7136\u800c\uff0c\u5176\u53ef\u9760\u6027\u548c\u771f\u5b9e\u6027\u4ecd\u9762\u4e34\u6311\u6218\u3002", "method": "\u672c\u6587\u7efc\u8ff0\u4e86LLMs\u5982\u4f55\u91cd\u65b0\u5b9a\u4e49\u79d1\u5b66\u65b9\u6cd5\uff0c\u5e76\u63a2\u8ba8\u5176\u5728\u79d1\u5b66\u5468\u671f\u5404\u9636\u6bb5\uff08\u4ece\u5047\u8bbe\u68c0\u9a8c\u5230\u53d1\u73b0\uff09\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\uff0c\u5f3a\u8c03\u5e94\u8ffd\u6c42\u5176\u4e0e\u4eba\u7c7b\u79d1\u5b66\u76ee\u6807\u7684\u6df1\u5ea6\u6574\u5408\u3002", "result": "LLMs\u53ef\u4ee5\u4f5c\u4e3a\u521b\u9020\u6027\u548c\u751f\u4ea7\u529b\u589e\u5f3a\u5de5\u5177\uff0c\u63a8\u52a8\u8de8\u5b66\u79d1\u7684\u53d8\u9769\u6027\u7a81\u7834\uff0c\u4f46\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u8ba9LLMs\u4e3b\u5bfc\u79d1\u5b66\u7814\u7a76\u4ecd\u9700\u79d1\u5b66\u754c\u51b3\u5b9a\u3002", "conclusion": "\u4e3a\u4f7fLLMs\u6210\u4e3a\u76f8\u5173\u4e14\u6709\u6548\u7684\u521b\u9020\u6027\u5f15\u64ce\u548c\u751f\u4ea7\u529b\u589e\u5f3a\u5de5\u5177\uff0c\u5fc5\u987b\u5728\u5176\u4e0e\u6240\u6709\u79d1\u5b66\u6b65\u9aa4\u7684\u6df1\u5ea6\u6574\u5408\u8fc7\u7a0b\u4e2d\u786e\u4fdd\u4e0e\u4eba\u7c7b\u79d1\u5b66\u76ee\u6807\u7684\u4e00\u81f4\u6027\uff0c\u5e76\u8bbe\u7acb\u660e\u786e\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u540c\u65f6\u89e3\u51b3\u76f8\u5173\u7684\u4f26\u7406\u95ee\u9898\u3002"}}
{"id": "2505.16260", "pdf": "https://arxiv.org/pdf/2505.16260", "abs": "https://arxiv.org/abs/2505.16260", "authors": ["Alaa Khaddaj", "Logan Engstrom", "Aleksander Madry"], "title": "Small-to-Large Generalization: Data Influences Models Consistently Across Scale", "categories": ["cs.LG"], "comment": null, "summary": "Choice of training data distribution greatly influences model behavior. Yet,\nin large-scale settings, precisely characterizing how changes in training data\naffects predictions is often difficult due to model training costs. Current\npractice is to instead extrapolate from scaled down, inexpensive-to-train proxy\nmodels. However, changes in data do not influence smaller and larger models\nidentically. Therefore, understanding how choice of data affects large-scale\nmodels raises the question: how does training data distribution influence model\nbehavior across compute scale? We find that small- and large-scale language\nmodel predictions (generally) do highly correlate across choice of training\ndata. Equipped with these findings, we characterize how proxy scale affects\neffectiveness in two downstream proxy model applications: data attribution and\ndataset selection.", "AI": {"tldr": "\u901a\u8fc7\u7814\u7a76\u53d1\u73b0\uff0c\u5c0f\u89c4\u6a21\u548c\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u5728\u8bad\u7ec3\u6570\u636e\u9009\u62e9\u4e0a\u901a\u5e38\u9ad8\u5ea6\u76f8\u5173\u3002\u57fa\u4e8e\u6b64\uff0c\u7814\u7a76\u63a2\u8ba8\u4e86\u4ee3\u7406\u6a21\u578b\u89c4\u6a21\u5bf9\u6570\u636e\u5f52\u56e0\u548c\u6570\u636e\u96c6\u9009\u62e9\u4e24\u4e2a\u4e0b\u6e38\u4efb\u52a1\u6548\u679c\u7684\u5f71\u54cd\u3002", "motivation": "\u5f53\u524d\u5b9e\u8df5\u4e2d\uff0c\u7531\u4e8e\u5927\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u7cbe\u786e\u63cf\u8ff0\u8bad\u7ec3\u6570\u636e\u53d8\u5316\u5bf9\u9884\u6d4b\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u901a\u5e38\u4f7f\u7528\u6613\u4e8e\u8bad\u7ec3\u7684\u5c0f\u89c4\u6a21\u4ee3\u7406\u6a21\u578b\u8fdb\u884c\u63a8\u65ad\u3002\u7136\u800c\uff0c\u6570\u636e\u53d8\u5316\u5bf9\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u7684\u5f71\u54cd\u5e76\u4e0d\u76f8\u540c\uff0c\u8fd9\u4fc3\u4f7f\u6211\u4eec\u63a2\u7a76\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u5982\u4f55\u5f71\u54cd\u4e0d\u540c\u8ba1\u7b97\u89c4\u6a21\u4e0b\u7684\u6a21\u578b\u884c\u4e3a\u3002", "method": "\u7814\u7a76\u5206\u6790\u4e86\u4e0d\u540c\u89c4\u6a21\uff08\u5c0f\u89c4\u6a21\u4e0e\u5927\u89c4\u6a21\uff09\u7684\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u5728\u8bad\u7ec3\u6570\u636e\u9009\u62e9\u4e0a\u7684\u76f8\u5173\u6027\uff0c\u5e76\u4ee5\u6b64\u4e3a\u57fa\u7840\uff0c\u8fdb\u4e00\u6b65\u63a2\u8ba8\u4ee3\u7406\u6a21\u578b\u89c4\u6a21\u5bf9\u6570\u636e\u5f52\u56e0\u548c\u6570\u636e\u96c6\u9009\u62e9\u8fd9\u4e24\u4e2a\u4e0b\u6e38\u4efb\u52a1\u6548\u679c\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5c0f\u89c4\u6a21\u548c\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u5728\u8bad\u7ec3\u6570\u636e\u9009\u62e9\u4e0a\u901a\u5e38\u5177\u6709\u9ad8\u5ea6\u76f8\u5173\u6027\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u660e\u786e\u4e86\u4ee3\u7406\u6a21\u578b\u89c4\u6a21\u5bf9\u6570\u636e\u5f52\u56e0\u548c\u6570\u636e\u96c6\u9009\u62e9\u4efb\u52a1\u6548\u679c\u7684\u5177\u4f53\u5f71\u54cd\u3002", "conclusion": "\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u5bf9\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u7684\u884c\u4e3a\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4f46\u5c0f\u89c4\u6a21\u548c\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u5728\u8bad\u7ec3\u6570\u636e\u9009\u62e9\u4e0a\u8868\u73b0\u51fa\u9ad8\u5ea6\u76f8\u5173\u6027\u3002\u8fd9\u4e00\u53d1\u73b0\u4e3a\u4f7f\u7528\u5c0f\u89c4\u6a21\u4ee3\u7406\u6a21\u578b\u6765\u7406\u89e3\u5927\u89c4\u6a21\u6a21\u578b\u884c\u4e3a\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86\u5728\u6570\u636e\u5f52\u56e0\u548c\u6570\u636e\u96c6\u9009\u62e9\u4efb\u52a1\u4e2d\u8003\u8651\u4ee3\u7406\u6a21\u578b\u89c4\u6a21\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2505.16482", "pdf": "https://arxiv.org/pdf/2505.16482", "abs": "https://arxiv.org/abs/2505.16482", "authors": ["Huynh Thi Thanh Binh", "Le Van Cuong", "Dang Hai Dang", "Le Trong Vinh"], "title": "Minimizing the energy depletion in wireless rechargeable sensor networks using bi-level metaheuristic charging schemes", "categories": ["cs.AI", "cs.NE"], "comment": null, "summary": "Recently, Wireless Rechargeable Sensor Networks (WRSNs) that leveraged the\nadvantage of wireless energy transfer technology have opened a promising\nopportunity in solving the limited energy issue. However, an ineffective\ncharging strategy may reduce the charging performance. Although many practical\ncharging algorithms have been introduced, these studies mainly focus on\noptimizing the charging path with a fully charging approach. This approach may\nlead to the death of a series of sensors due to their extended charging\nlatency. This paper introduces a novel partial charging approach that follows a\nbi-level optimized scheme to minimize energy depletion in WRSNs. We aim at\noptimizing simultaneously two factors: the charging path and time. To\naccomplish this, we first formulate a mathematical model of the investigated\nproblem. We then propose two approximate algorithms in which the optimization\nof the charging path and the charging time are considered as the upper and\nlower level, respectively. The first algorithm combines a Multi-start Local\nSearch method and a Genetic Algorithm to find a solution. The second algorithm\nadopts a nested approach that utilizes the advantages of the Multitasking and\nCovariance Matrix Adaptation Evolutionary Strategies. Experimental validations\non various network scenarios demonstrate that our proposed algorithms\noutperform the existing works.", "AI": {"tldr": "\u5728\u65e0\u7ebf\u53ef\u5145\u7535\u4f20\u611f\u5668\u7f51\u7edc\uff08WRSN\uff09\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53cc\u5c42\u4f18\u5316\u7684\u90e8\u5206\u5145\u7535\u65b9\u6cd5\u6765\u6700\u5c0f\u5316\u80fd\u91cf\u6d88\u8017\u3002\u8be5\u65b9\u6cd5\u540c\u65f6\u4f18\u5316\u4e86\u5145\u7535\u8def\u5f84\u548c\u65f6\u95f4\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u8fd1\u4f3c\u7b97\u6cd5\u4ee5\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u6280\u672f\u4e3a\u89e3\u51b3\u4f20\u611f\u5668\u7f51\u7edc\u4e2d\u7684\u80fd\u91cf\u9650\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\uff0c\u4f46\u73b0\u6709\u7684\u5b8c\u5168\u5145\u7535\u7b56\u7565\u53ef\u80fd\u5bfc\u81f4\u4e00\u7cfb\u5217\u4f20\u611f\u5668\u56e0\u5145\u7535\u5ef6\u8fdf\u8fc7\u957f\u800c\u5931\u6548\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u90e8\u5206\u5145\u7535\u7b56\u7565\u6765\u51cf\u5c11\u80fd\u91cf\u6d88\u8017\u5e76\u63d0\u9ad8\u5145\u7535\u6548\u7387\u3002", "method": "\u9996\u5148\u6784\u5efa\u4e86\u7814\u7a76\u95ee\u9898\u7684\u6570\u5b66\u6a21\u578b\uff0c\u7136\u540e\u63d0\u51fa\u4e86\u4e24\u79cd\u8fd1\u4f3c\u7b97\u6cd5\uff1a\u7b2c\u4e00\u79cd\u7ed3\u5408\u591a\u8d77\u70b9\u5c40\u90e8\u641c\u7d22\u65b9\u6cd5\u548c\u9057\u4f20\u7b97\u6cd5\uff1b\u7b2c\u4e8c\u79cd\u91c7\u7528\u5d4c\u5957\u65b9\u6cd5\uff0c\u5229\u7528\u591a\u4efb\u52a1\u548c\u534f\u65b9\u5dee\u77e9\u9635\u9002\u5e94\u8fdb\u5316\u7b56\u7565\u7684\u4f18\u70b9\u3002\u8fd9\u4e24\u79cd\u7b97\u6cd5\u5206\u522b\u4ece\u4e0a\u5c42\u4f18\u5316\u5145\u7535\u8def\u5f84\uff0c\u4e0b\u5c42\u4f18\u5316\u5145\u7535\u65f6\u95f4\u3002", "result": "\u901a\u8fc7\u5728\u4e0d\u540c\u7f51\u7edc\u573a\u666f\u4e0b\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u4e24\u79cd\u7b97\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u5de5\u4f5c\u3002", "conclusion": "\u63d0\u51fa\u7684\u90e8\u5206\u5145\u7535\u65b9\u6cd5\u53ca\u5176\u5bf9\u5e94\u7684\u4e24\u79cd\u8fd1\u4f3c\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u51cf\u5c11WRSN\u4e2d\u7684\u80fd\u91cf\u6d88\u8017\uff0c\u5e76\u4e14\u5728\u5404\u79cd\u7f51\u7edc\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2505.16265", "pdf": "https://arxiv.org/pdf/2505.16265", "abs": "https://arxiv.org/abs/2505.16265", "authors": ["Ilgee Hong", "Changlong Yu", "Liang Qiu", "Weixiang Yan", "Zhenghao Xu", "Haoming Jiang", "Qingru Zhang", "Qin Lu", "Xin Liu", "Chao Zhang", "Tuo Zhao"], "title": "Think-RM: Enabling Long-Horizon Reasoning in Generative Reward Models", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning from human feedback (RLHF) has become a powerful\npost-training paradigm for aligning large language models with human\npreferences. A core challenge in RLHF is constructing accurate reward signals,\nwhere the conventional Bradley-Terry reward models (BT RMs) often suffer from\nsensitivity to data size and coverage, as well as vulnerability to reward\nhacking. Generative reward models (GenRMs) offer a more robust alternative by\ngenerating chain-of-thought (CoT) rationales followed by a final reward.\nHowever, existing GenRMs rely on shallow, vertically scaled reasoning, limiting\ntheir capacity to handle nuanced or complex (e.g., reasoning-intensive) tasks.\nMoreover, their pairwise preference outputs are incompatible with standard RLHF\nalgorithms that require pointwise reward signals. In this work, we introduce\nThink-RM, a training framework that enables long-horizon reasoning in GenRMs by\nmodeling an internal thinking process. Rather than producing structured,\nexternally provided rationales, Think-RM generates flexible, self-guided\nreasoning traces that support advanced capabilities such as self-reflection,\nhypothetical reasoning, and divergent reasoning. To elicit these reasoning\nabilities, we first warm-up the models by supervised fine-tuning (SFT) over\nlong CoT data. We then further improve the model's long-horizon abilities by\nrule-based reinforcement learning (RL). In addition, we propose a novel\npairwise RLHF pipeline that directly optimizes policies using pairwise\npreference rewards, eliminating the need for pointwise reward conversion and\nenabling more effective use of Think-RM outputs. Experiments show that Think-RM\nachieves state-of-the-art results on RM-Bench, outperforming both BT RM and\nvertically scaled GenRM by 8%. When combined with our pairwise RLHF pipeline,\nit demonstrates superior end-policy performance compared to traditional\napproaches.", "AI": {"tldr": "Think-RM\u662f\u4e00\u79cd\u65b0\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u5185\u90e8\u601d\u8003\u8fc7\u7a0b\uff0c\u4f7f\u751f\u6210\u5956\u52b1\u6a21\u578b\uff08GenRMs\uff09\u80fd\u591f\u8fdb\u884c\u957f\u65f6\u63a8\u7406\u3002\u5b83\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u6a21\u578b\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6210\u5bf9\u5f3a\u5316\u5b66\u4e60\u7ba1\u9053\u4ee5\u4f18\u5316\u7b56\u7565\u3002\u5b9e\u9a8c\u8868\u660e\uff0cThink-RM\u5728RM-Bench\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd58%\uff0c\u5e76\u5728\u4e0e\u65b0\u7ba1\u9053\u7ed3\u5408\u65f6\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u6700\u7ec8\u7b56\u7565\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u5956\u52b1\u6a21\u578b\uff08GenRMs\uff09\u867d\u7136\u6bd4\u4f20\u7edf\u7684Bradley-Terry\u5956\u52b1\u6a21\u578b\uff08BT RMs\uff09\u66f4\u9c81\u68d2\uff0c\u4f46\u4ecd\u7136\u53d7\u9650\u4e8e\u6d45\u5c42\u63a8\u7406\u80fd\u529b\u548c\u65e0\u6cd5\u76f4\u63a5\u8f93\u51fa\u70b9\u5bf9\u5956\u52b1\u4fe1\u53f7\u7684\u95ee\u9898\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5904\u7406\u590d\u6742\u4efb\u52a1\u7684\u80fd\u529b\u4ee5\u53ca\u4e0e\u6807\u51c6RLHF\u7b97\u6cd5\u7684\u517c\u5bb9\u6027\u3002", "method": "1. \u63d0\u51faThink-RM\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u5185\u90e8\u601d\u8003\u8fc7\u7a0b\u751f\u6210\u7075\u6d3b\u7684\u81ea\u6211\u5f15\u5bfc\u63a8\u7406\u75d5\u8ff9\uff0c\u652f\u6301\u81ea\u7701\u3001\u5047\u8bbe\u63a8\u7406\u548c\u53d1\u6563\u63a8\u7406\u3002\n2. \u4f7f\u7528\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u5728\u957f\u94fe\u63a8\u7406\u6570\u636e\u4e0a\u9884\u70ed\u6a21\u578b\u3002\n3. \u91c7\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u5f3a\u5316\u5b66\u4e60\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u7684\u957f\u65f6\u63a8\u7406\u80fd\u529b\u3002\n4. \u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6210\u5bf9\u5f3a\u5316\u5b66\u4e60\u7ba1\u9053\uff0c\u76f4\u63a5\u4f18\u5316\u7b56\u7565\u4ee5\u4f7f\u7528\u6210\u5bf9\u504f\u597d\u5956\u52b1\uff0c\u65e0\u9700\u8f6c\u6362\u4e3a\u70b9\u5bf9\u5956\u52b1\u3002", "result": "\u5728RM-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cThink-RM\u8d85\u8d8a\u4e86BT RM\u548c\u5782\u76f4\u6269\u5c55\u7684GenRM\uff0c\u8868\u73b0\u63d0\u9ad8\u4e868%\u3002\u540c\u65f6\uff0c\u5f53\u4e0e\u63d0\u51fa\u7684\u6210\u5bf9RLHF\u7ba1\u9053\u7ed3\u5408\u65f6\uff0c\u5c55\u793a\u4e86\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u6700\u7ec8\u7b56\u7565\u6027\u80fd\u3002", "conclusion": "Think-RM\u901a\u8fc7\u5f15\u5165\u957f\u65f6\u63a8\u7406\u80fd\u529b\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u5956\u52b1\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5e76\u4e14\u5176\u6210\u5bf9RLHF\u7ba1\u9053\u63d0\u9ad8\u4e86\u5956\u52b1\u4fe1\u53f7\u7684\u6709\u6548\u5229\u7528\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2505.16507", "pdf": "https://arxiv.org/pdf/2505.16507", "abs": "https://arxiv.org/abs/2505.16507", "authors": ["Anshu Xiong", "Songmao Zhang"], "title": "Relevance for Stability of Verification Status of a Set of Arguments in Incomplete Argumentation Frameworks (with Proofs)", "categories": ["cs.AI"], "comment": "This is a version of paper 'Relevance for Stability of Verification\n  Status of a Set of Arguments in Incomplete Argumentation Frameworks' extented\n  with proofs of the results in the paper", "summary": "The notion of relevance was proposed for stability of justification status of\na single argument in incomplete argumentation frameworks (IAFs) in 2024 by\nOdekerken et al. To extend the notion, we study the relevance for stability of\nverification status of a set of arguments in this paper, i.e., the\nuncertainties in an IAF that have to be resolved in some situations so that\nanswering whether a given set of arguments is an extension obtains the same\nresult in every completion of the IAF. Further we propose the notion of strong\nrelevance for describing the necessity of resolution in all situations reaching\nstability. An analysis of complexity reveals that detecting the (strong)\nrelevance for stability of sets of arguments can be accomplished in P time\nunder the most semantics discussed in the paper. We also discuss the difficulty\nin finding tractable methods for relevance detection under grounded semantics.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u5728\u4e0d\u5b8c\u5168\u8bba\u8bc1\u6846\u67b6\uff08IAFs\uff09\u4e2d\u5173\u4e8e\u5355\u4e2a\u8bba\u8bc1\u7684\u7a33\u5b9a\u6027\u76f8\u5173\u6027\u6982\u5ff5\uff0c\u7814\u7a76\u4e86\u4e00\u7ec4\u8bba\u8bc1\u7684\u9a8c\u8bc1\u72b6\u6001\u7a33\u5b9a\u6027\u7684\u76f8\u5173\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u5f3a\u76f8\u5173\u6027\u6982\u5ff5\u3002\u590d\u6742\u6027\u5206\u6790\u8868\u660e\uff0c\u5728\u5927\u591a\u6570\u8bed\u4e49\u4e0b\u68c0\u6d4b\uff08\u5f3a\uff09\u76f8\u5173\u6027\u53ef\u4ee5\u5728P\u65f6\u95f4\u5185\u5b8c\u6210\uff0c\u4f46\u5728\u57fa\u7840\u8bed\u4e49\u4e0b\u7684\u53ef\u5904\u7406\u65b9\u6cd5\u4ecd\u5b58\u5728\u56f0\u96be\u3002", "motivation": "Odekerken\u7b49\u4eba\u57282024\u5e74\u63d0\u51fa\u4e86\u9488\u5bf9\u5355\u4e2a\u8bba\u8bc1\u7684\u7a33\u5b9a\u6027\u76f8\u5173\u6027\u6982\u5ff5\uff0c\u672c\u6587\u65e8\u5728\u6269\u5c55\u8fd9\u4e00\u6982\u5ff5\u4ee5\u9002\u7528\u4e8e\u4e00\u7ec4\u8bba\u8bc1\u7684\u9a8c\u8bc1\u72b6\u6001\u7a33\u5b9a\u6027\u3002", "method": "\u7814\u7a76\u4e86\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u9700\u8981\u89e3\u51b3\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u786e\u4fdd\u5728\u6bcf\u4e2aIAF\u5b8c\u6210\u65f6\uff0c\u7ed9\u5b9a\u7684\u4e00\u7ec4\u8bba\u8bc1\u662f\u5426\u4e3a\u6269\u5c55\u7684\u7ed3\u679c\u76f8\u540c\u3002\u63d0\u51fa\u4e86\u5f3a\u76f8\u5173\u6027\u6982\u5ff5\u6765\u63cf\u8ff0\u6240\u6709\u60c5\u5883\u4e0b\u8fbe\u5230\u7a33\u5b9a\u6027\u7684\u5fc5\u8981\u6027\u3002", "result": "\u68c0\u6d4b\uff08\u5f3a\uff09\u76f8\u5173\u6027\u5728\u591a\u6570\u8bed\u4e49\u4e0b\u53ef\u4ee5\u5728P\u65f6\u95f4\u5185\u5b8c\u6210\uff0c\u4f46\u57fa\u7840\u8bed\u4e49\u4e0b\u7684\u53ef\u5904\u7406\u65b9\u6cd5\u4ecd\u9762\u4e34\u6311\u6218\u3002", "conclusion": "\u6269\u5c55\u4e86\u76f8\u5173\u6027\u6982\u5ff5\u5230\u4e00\u7ec4\u8bba\u8bc1\u7684\u9a8c\u8bc1\u72b6\u6001\u7a33\u5b9a\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u5f3a\u76f8\u5173\u6027\uff0c\u540c\u65f6\u5206\u6790\u4e86\u5176\u8ba1\u7b97\u590d\u6742\u6027\u3002"}}
{"id": "2505.16284", "pdf": "https://arxiv.org/pdf/2505.16284", "abs": "https://arxiv.org/abs/2505.16284", "authors": ["Josh Alman", "Zhao Song"], "title": "Only Large Weights (And Not Skip Connections) Can Prevent the Perils of Rank Collapse", "categories": ["cs.LG"], "comment": null, "summary": "Attention mechanisms lie at the heart of modern large language models (LLMs).\nStraightforward algorithms for forward and backward (gradient) computation take\nquadratic time, and a line of work initiated by [Alman and Song NeurIPS 2023]\nand [Alman and Song NeurIPS 2024] has shown that quadratic time is necessary\nunless the model weights are small, in which case almost linear time algorithms\nare possible. In this paper, we show that large weights are necessary to avoid\na strong preclusion to representational strength we call layer collapse, which\nmeans that the entire network can be approximated well by a network with only a\nsingle layer. Thus, the quadratic running time of attention is unavoidable for\nexpressive transformers.\n  The notion of layer collapse that we introduce is a variant on the notion of\nrank collapse from the work of [Dong, Cordonnier, and Loukas ICML 2021]. They\nshowed that in Self Attention Networks with small weights and with skip\nconnections, rank collapse must occur. This is typically interpreted as\njustifying the necessity of skip connections in expressive networks. However,\nour result shows that even with skip connections, if the weights are small,\nthen layer collapse still occurs. Thus, only large weights, and not skip\nconnections, can prevent these representational weaknesses.", "AI": {"tldr": "\u6ce8\u610f\u529b\u673a\u5236\u5728\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u8d77\u7740\u6838\u5fc3\u4f5c\u7528\u3002\u5c3d\u7ba1\u8ba1\u7b97\u524d\u5411\u548c\u540e\u5411\u68af\u5ea6\u7684\u76f4\u63a5\u7b97\u6cd5\u9700\u8981\u4e8c\u6b21\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u4f46\u7814\u7a76\u8868\u660e\uff0c\u5982\u679c\u6a21\u578b\u6743\u91cd\u8f83\u5c0f\uff0c\u5219\u51e0\u4e4e\u7ebf\u6027\u65f6\u95f4\u7684\u7b97\u6cd5\u662f\u53ef\u80fd\u7684\u3002\u7136\u800c\uff0c\u672c\u6587\u8bc1\u660e\u4e86\u5927\u6743\u91cd\u5bf9\u4e8e\u907f\u514d\u8868\u793a\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff08\u79f0\u4e3a\u5c42\u574d\u7f29\uff09\u662f\u5fc5\u8981\u7684\u3002\u56e0\u6b64\uff0c\u4e3a\u4e86\u4fdd\u6301Transformer\u7684\u8868\u73b0\u529b\uff0c\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u8fd0\u884c\u65f6\u95f4\u4e0d\u53ef\u907f\u514d\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u4e3a\u4f55\u6ce8\u610f\u529b\u673a\u5236\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u9700\u8981\u4e8c\u6b21\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u5e76\u5206\u6790\u5c0f\u6743\u91cd\u5bf9\u6a21\u578b\u8868\u793a\u80fd\u529b\u7684\u5f71\u54cd\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u4f5c\u8005\u5e0c\u671b\u63ed\u793a\u4e3a\u4ec0\u4e48\u5927\u6743\u91cd\u5bf9\u4e8e\u907f\u514d\u5c42\u574d\u7f29\uff08layer collapse\uff09\u81f3\u5173\u91cd\u8981\uff0c\u4ece\u800c\u89e3\u91ca\u4e3a\u4ec0\u4e48\u6ce8\u610f\u529b\u673a\u5236\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u65e0\u6cd5\u8fdb\u4e00\u6b65\u964d\u4f4e\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u201c\u5c42\u574d\u7f29\u201d\u7684\u6982\u5ff5\uff0c\u8fd9\u662f\u4e00\u79cd\u8868\u793a\u80fd\u529b\u4e0d\u8db3\u7684\u73b0\u8c61\uff0c\u610f\u5473\u7740\u6574\u4e2a\u7f51\u7edc\u53ef\u4ee5\u7528\u5355\u5c42\u7f51\u7edc\u5f88\u597d\u5730\u8fd1\u4f3c\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u4f5c\u8005\u8bc1\u660e\u4e86\u5f53\u6743\u91cd\u8f83\u5c0f\u65f6\uff0c\u5373\u4f7f\u5b58\u5728\u8df3\u8dc3\u8fde\u63a5\uff0c\u5c42\u574d\u7f29\u4ecd\u4f1a\u53d1\u751f\u3002\u53ea\u6709\u5927\u6743\u91cd\u53ef\u4ee5\u6709\u6548\u907f\u514d\u8fd9\u79cd\u73b0\u8c61\uff0c\u4ece\u800c\u7ef4\u6301\u6a21\u578b\u7684\u8868\u793a\u80fd\u529b\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5927\u6743\u91cd\u5bf9\u4e8e\u907f\u514d\u5c42\u574d\u7f29\u662f\u5fc5\u8981\u7684\u3002\u8fd9\u610f\u5473\u7740\u4e3a\u4e86\u4fdd\u6301Transformer\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u8fd0\u884c\u65f6\u95f4\u4e0d\u53ef\u907f\u514d\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u6307\u51fa\uff0c\u8df3\u8dc3\u8fde\u63a5\u5e76\u4e0d\u80fd\u89e3\u51b3\u5c0f\u6743\u91cd\u5bfc\u81f4\u7684\u8868\u793a\u80fd\u529b\u4e0d\u8db3\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u201c\u5c42\u574d\u7f29\u201d\u6982\u5ff5\uff0c\u63ed\u793a\u4e86\u5927\u6743\u91cd\u5728\u907f\u514d\u8868\u793a\u80fd\u529b\u4e0d\u8db3\u65b9\u9762\u7684\u91cd\u8981\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4e3a\u4e86\u7ef4\u6301Transformer\u6a21\u578b\u7684\u8868\u73b0\u529b\uff0c\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u8fd0\u884c\u65f6\u95f4\u662f\u4e0d\u53ef\u907f\u514d\u7684\u3002\u8fd9\u4e3a\u7406\u89e3\u6a21\u578b\u8bbe\u8ba1\u4e2d\u7684\u6743\u8861\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2505.16579", "pdf": "https://arxiv.org/pdf/2505.16579", "abs": "https://arxiv.org/abs/2505.16579", "authors": ["Siqu Ou", "Hongcheng Liu", "Pingjie Wang", "Yusheng Liao", "Chuan Xuan", "Yanfeng Wang", "Yu Wang"], "title": "Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning", "categories": ["cs.AI", "cs.CV"], "comment": "19 pages, 8 figures", "summary": "While chains-of-thought (CoT) have advanced complex reasoning in multimodal\nlarge language models (MLLMs), existing methods remain confined to text or\nstatic visual domains, often faltering in dynamic spatial reasoning tasks. To\nbridge this gap, we present GRASSLAND, a novel maze navigation benchmark\ndesigned to evaluate dynamic spatial reasoning. Our experiments show that\naugmenting textual reasoning chains with dynamic visual drafts, overlaid on\ninput images, significantly outperforms conventional approaches, offering new\ninsights into spatial reasoning in evolving environments. To generalize this\ncapability, we propose D2R (Dynamic Draft-Augmented Reasoning), a training-free\nframework that seamlessly integrates textual CoT with corresponding visual\ndrafts into MLLMs. Extensive evaluations demonstrate that D2R consistently\nenhances performance across diverse tasks, establishing a robust baseline for\ndynamic spatial reasoning without requiring model fine-tuning. Project is open\nat https://github.com/Cratileo/D2R.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u6587\u672c\u63a8\u7406\u94fe\u4e0e\u52a8\u6001\u89c6\u89c9\u8349\u56fe\u7ed3\u5408\uff0cGRASSLAND\u57fa\u51c6\u548cD2R\u6846\u67b6\u5728\u52a8\u6001\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1\u601d\u7ef4\u94fe\uff08CoT\uff09\u5728\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u7684\u590d\u6742\u63a8\u7406\u4e2d\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u4ecd\u5c40\u9650\u4e8e\u6587\u672c\u6216\u9759\u6001\u89c6\u89c9\u9886\u57df\uff0c\u5728\u52a8\u6001\u7a7a\u95f4\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002", "method": "1. \u521b\u5efa\u4e86GRASSLAND\u8ff7\u5bab\u5bfc\u822a\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u52a8\u6001\u7a7a\u95f4\u63a8\u7406\u30022. \u63d0\u51fa\u4e86\u65e0\u9700\u8bad\u7ec3\u7684D2R\u6846\u67b6\uff0c\u5c06\u6587\u672c\u601d\u7ef4\u94fe\u4e0e\u5bf9\u5e94\u7684\u89c6\u89c9\u8349\u56fe\u65e0\u7f1d\u96c6\u6210\u5230MLLMs\u4e2d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u589e\u5f3a\u6587\u672c\u63a8\u7406\u94fe\u4e0e\u52a8\u6001\u89c6\u89c9\u8349\u56fe\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u6301\u7eed\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "D2R\u6846\u67b6\u4e3a\u52a8\u6001\u7a7a\u95f4\u63a8\u7406\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u57fa\u7ebf\uff0c\u65e0\u9700\u6a21\u578b\u5fae\u8c03\u5373\u53ef\u5e7f\u6cdb\u5e94\u7528\u4e8e\u5404\u7c7b\u4efb\u52a1\u3002"}}
{"id": "2505.16291", "pdf": "https://arxiv.org/pdf/2505.16291", "abs": "https://arxiv.org/abs/2505.16291", "authors": ["Ronen Gradwohl", "Eilam Shapira", "Moshe Tennenholtz"], "title": "Fairness under Competition", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "Algorithmic fairness has emerged as a central issue in ML, and it has become\nstandard practice to adjust ML algorithms so that they will satisfy fairness\nrequirements such as Equal Opportunity. In this paper we consider the effects\nof adopting such fair classifiers on the overall level of ecosystem fairness.\nSpecifically, we introduce the study of fairness with competing firms, and\ndemonstrate the failure of fair classifiers in yielding fair ecosystems. Our\nresults quantify the loss of fairness in systems, under a variety of\nconditions, based on classifiers' correlation and the level of their data\noverlap. We show that even if competing classifiers are individually fair, the\necosystem's outcome may be unfair; and that adjusting biased algorithms to\nimprove their individual fairness may lead to an overall decline in ecosystem\nfairness. In addition to these theoretical results, we also provide supporting\nexperimental evidence. Together, our model and results provide a novel and\nessential call for action.", "AI": {"tldr": "\u5c3d\u7ba1\u5355\u4e2a\u5206\u7c7b\u5668\u662f\u516c\u5e73\u7684\uff0c\u4f46\u7ade\u4e89\u6027\u5206\u7c7b\u5668\u53ef\u80fd\u4ecd\u4f1a\u5bfc\u81f4\u4e0d\u516c\u5e73\u7684\u751f\u6001\u7cfb\u7edf\u7ed3\u679c\u3002\u6539\u5584\u4e2a\u4f53\u516c\u5e73\u6027\u53ef\u80fd\u5bfc\u81f4\u751f\u6001\u7cfb\u7edf\u516c\u5e73\u6027\u7684\u6574\u4f53\u4e0b\u964d\u3002", "motivation": "\u7814\u7a76\u91c7\u7528\u516c\u5e73\u5206\u7c7b\u5668\u5bf9\u6574\u4f53\u751f\u6001\u7cfb\u7edf\u516c\u5e73\u6027\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5f15\u5165\u7ade\u4e89\u4f01\u4e1a\u73af\u5883\u4e0b\u7684\u516c\u5e73\u6027\u7814\u7a76\u3002", "method": "\u91cf\u5316\u7cfb\u7edf\u4e2d\u516c\u5e73\u6027\u7684\u635f\u5931\uff0c\u57fa\u4e8e\u5206\u7c7b\u5668\u7684\u76f8\u5173\u6027\u548c\u6570\u636e\u91cd\u53e0\u7a0b\u5ea6\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u548c\u5b9e\u9a8c\u7ed3\u679c\u652f\u6301\u3002", "result": "\u5373\u4f7f\u7ade\u4e89\u5206\u7c7b\u5668\u5355\u72ec\u6ee1\u8db3\u516c\u5e73\u6027\u8981\u6c42\uff0c\u751f\u6001\u7cfb\u7edf\u7684\u6574\u4f53\u7ed3\u679c\u4ecd\u53ef\u80fd\u4e0d\u516c\u5e73\uff1b\u63d0\u9ad8\u4e2a\u4f53\u516c\u5e73\u6027\u53ef\u80fd\u5bfc\u81f4\u751f\u6001\u7cfb\u7edf\u516c\u5e73\u6027\u7684\u4e0b\u964d\u3002", "conclusion": "\u9700\u8981\u91c7\u53d6\u65b0\u7684\u884c\u52a8\u6765\u89e3\u51b3\u751f\u6001\u7cfb\u7edf\u5c42\u9762\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u8c03\u6574\u4e2a\u4f53\u5206\u7c7b\u5668\u3002"}}
{"id": "2505.16619", "pdf": "https://arxiv.org/pdf/2505.16619", "abs": "https://arxiv.org/abs/2505.16619", "authors": ["Gavin Farrell", "Eleni Adamidi", "Rafael Andrade Buono", "Mihail Anton", "Omar Abdelghani Attafi", "Salvador Capella Gutierrez", "Emidio Capriotti", "Leyla Jael Castro", "Davide Cirillo", "Lisa Crossman", "Christophe Dessimoz", "Alexandros Dimopoulos", "Raul Fernandez-Diaz", "Styliani-Christina Fragkouli", "Carole Goble", "Wei Gu", "John M. Hancock", "Alireza Khanteymoori", "Tom Lenaerts", "Fabio G. Liberante", "Peter Maccallum", "Alexander Miguel Monzon", "Magnus Palmblad", "Lucy Poveda", "Ovidiu Radulescu", "Denis C. Shields", "Shoaib Sufi", "Thanasis Vergoulis", "Fotis Psomopoulos", "Silvio C. E. Tosatto"], "title": "Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences", "categories": ["cs.AI", "q-bio.OT", "92", "J.3"], "comment": "1 PDF, 24 Pages, 2 figures within. Co-corresponding authors:\n  Institute of Applied Biosciences, Centre for Research and Technology Hellas,\n  Thessaloniki, Greece and Department of Biomedical Sciences, University of\n  Padova, Padova, Italy. E-mails: fpsom@certh.gr, silvio.tosatto@unipd.it", "summary": "Artificial intelligence (AI) has recently seen transformative breakthroughs\nin the life sciences, expanding possibilities for researchers to interpret\nbiological information at an unprecedented capacity, with novel applications\nand advances being made almost daily. In order to maximise return on the\ngrowing investments in AI-based life science research and accelerate this\nprogress, it has become urgent to address the exacerbation of long-standing\nresearch challenges arising from the rapid adoption of AI methods. We review\nthe increased erosion of trust in AI research outputs, driven by the issues of\npoor reusability and reproducibility, and highlight their consequent impact on\nenvironmental sustainability. Furthermore, we discuss the fragmented components\nof the AI ecosystem and lack of guiding pathways to best support Open and\nSustainable AI (OSAI) model development. In response, this perspective\nintroduces a practical set of OSAI recommendations directly mapped to over 300\ncomponents of the AI ecosystem. Our work connects researchers with relevant AI\nresources, facilitating the implementation of sustainable, reusable and\ntransparent AI. Built upon life science community consensus and aligned to\nexisting efforts, the outputs of this perspective are designed to aid the\nfuture development of policy and structured pathways for guiding AI\nimplementation.", "AI": {"tldr": "AI\u5728\u751f\u547d\u79d1\u5b66\u9886\u57df\u7684\u5e94\u7528\u53d6\u5f97\u4e86\u7a81\u7834\u6027\u8fdb\u5c55\uff0c\u4f46\u968f\u4e4b\u800c\u6765\u7684\u7814\u7a76\u7ed3\u679c\u7684\u53ef\u91cd\u590d\u6027\u548c\u53ef\u91cd\u7528\u6027\u95ee\u9898\u4e5f\u65e5\u76ca\u4e25\u91cd\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u5f00\u653e\u548c\u53ef\u6301\u7eed\u7684AI\uff08OSAI\uff09\u5efa\u8bae\uff0c\u65e8\u5728\u63a8\u52a8\u53ef\u4fe1\u3001\u73af\u4fdd\u548c\u900f\u660e\u7684AI\u6a21\u578b\u5f00\u53d1\uff0c\u5e76\u4fc3\u8fdb\u653f\u7b56\u5236\u5b9a\u548c\u5b9e\u65bd\u8def\u5f84\u7684\u53d1\u5c55\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9AI\u65b9\u6cd5\u5feb\u901f\u666e\u53ca\u6240\u5e26\u6765\u7684\u957f\u671f\u7814\u7a76\u6311\u6218\uff0c\u5982\u4fe1\u4efb\u5ea6\u4e0b\u964d\u3001\u53ef\u91cd\u590d\u6027\u5dee\u7b49\u95ee\u9898\uff0c\u540c\u65f6\u5173\u6ce8\u73af\u5883\u53ef\u6301\u7eed\u6027\u3002", "method": "\u901a\u8fc7\u5ba1\u67e5\u73b0\u6709\u95ee\u9898\u5e76\u7ed3\u5408\u751f\u547d\u79d1\u5b66\u793e\u533a\u5171\u8bc6\uff0c\u63d0\u51fa\u4e86\u8d85\u8fc7300\u4e2aAI\u751f\u6001\u7cfb\u7edf\u7ec4\u4ef6\u76f8\u5173\u7684OSAI\u5efa\u8bae\u3002", "result": "\u8fde\u63a5\u7814\u7a76\u4eba\u5458\u4e0e\u76f8\u5173AI\u8d44\u6e90\uff0c\u63a8\u52a8\u53ef\u6301\u7eed\u3001\u53ef\u91cd\u7528\u548c\u900f\u660e\u7684AI\u6a21\u578b\u53d1\u5c55\uff0c\u5e76\u4e3a\u672a\u6765\u653f\u7b56\u5236\u5b9a\u63d0\u4f9b\u652f\u6301\u3002", "conclusion": "\u9700\u8981\u91c7\u53d6\u5b9e\u9645\u884c\u52a8\u6765\u89e3\u51b3AI\u7814\u7a76\u4e2d\u7684\u4fe1\u4efb\u3001\u53ef\u91cd\u590d\u6027\u548c\u53ef\u6301\u7eed\u6027\u95ee\u9898\uff0c\u4ee5\u6700\u5927\u5316\u6295\u8d44\u56de\u62a5\u5e76\u52a0\u901f\u751f\u547d\u79d1\u5b66\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2505.16305", "pdf": "https://arxiv.org/pdf/2505.16305", "abs": "https://arxiv.org/abs/2505.16305", "authors": ["Bingyang Cheng", "Zhongtao Chen", "Yichen Jin", "Hao Zhang", "Chen Zhang", "Edmud Y. Lam", "Yik-Chung Wu"], "title": "Large-Scale Bayesian Tensor Reconstruction: An Approximate Message Passing Solution", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Tensor CANDECOMP/PARAFAC decomposition (CPD) is a fundamental model for\ntensor reconstruction. Although the Bayesian framework allows for principled\nuncertainty quantification and automatic hyperparameter learning, existing\nmethods do not scale well for large tensors because of high-dimensional matrix\ninversions. To this end, we introduce CP-GAMP, a scalable Bayesian CPD\nalgorithm. This algorithm leverages generalized approximate message passing\n(GAMP) to avoid matrix inversions and incorporates an expectation-maximization\nroutine to jointly infer the tensor rank and noise power. Through multiple\nexperiments, for synthetic 100x100x100 rank 20 tensors with only 20% elements\nobserved, the proposed algorithm reduces runtime by 82.7% compared to the\nstate-of-the-art variational Bayesian CPD method, while maintaining comparable\nreconstruction accuracy.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCP-GAMP\u7684\u53ef\u6269\u5c55\u8d1d\u53f6\u65af\u5f20\u91cf\u5206\u89e3\u7b97\u6cd5\uff0c\u901a\u8fc7\u907f\u514d\u77e9\u9635\u6c42\u9006\u548c\u8054\u5408\u63a8\u65ad\u5f20\u91cf\u79e9\u4e0e\u566a\u58f0\u529f\u7387\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8fd0\u884c\u65f6\u95f4\uff0c\u5e76\u4fdd\u6301\u4e86\u4e0e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u76f8\u5f53\u7684\u91cd\u6784\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u8d1d\u53f6\u65af\u6846\u67b6\u867d\u7136\u53ef\u4ee5\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u548c\u81ea\u52a8\u8d85\u53c2\u6570\u5b66\u4e60\uff0c\u4f46\u5728\u5904\u7406\u5927\u89c4\u6a21\u5f20\u91cf\u65f6\u7531\u4e8e\u9ad8\u7ef4\u77e9\u9635\u6c42\u9006\u95ee\u9898\u800c\u65e0\u6cd5\u5f88\u597d\u5730\u6269\u5c55\u3002", "method": "\u5f15\u5165CP-GAMP\u7b97\u6cd5\uff0c\u5229\u7528\u5e7f\u4e49\u8fd1\u4f3c\u6d88\u606f\u4f20\u9012\uff08GAMP\uff09\u6765\u907f\u514d\u77e9\u9635\u6c42\u9006\uff0c\u5e76\u7ed3\u5408\u671f\u671b\u6700\u5927\u5316\uff08EM\uff09\u8fc7\u7a0b\u6765\u8054\u5408\u63a8\u65ad\u5f20\u91cf\u79e9\u548c\u566a\u58f0\u529f\u7387\u3002", "result": "\u5728\u5408\u6210\u7684100x100x100\u9636\u6570\u4e3a20\u7684\u5f20\u91cf\u5b9e\u9a8c\u4e2d\uff0c\u5f53\u4ec5\u89c2\u5bdf\u523020%\u7684\u5143\u7d20\u65f6\uff0cCP-GAMP\u76f8\u8f83\u4e8e\u6700\u5148\u8fdb\u7684\u53d8\u5206\u8d1d\u53f6\u65afCPD\u65b9\u6cd5\u51cf\u5c11\u4e8682.7%\u7684\u8fd0\u884c\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u91cd\u6784\u7cbe\u5ea6\u3002", "conclusion": "CP-GAMP\u662f\u4e00\u79cd\u6709\u6548\u7684\u3001\u53ef\u6269\u5c55\u7684\u8d1d\u53f6\u65afCPD\u7b97\u6cd5\uff0c\u9002\u5408\u4e8e\u5927\u89c4\u6a21\u5f20\u91cf\u5206\u89e3\u4efb\u52a1\u3002"}}
{"id": "2505.16646", "pdf": "https://arxiv.org/pdf/2505.16646", "abs": "https://arxiv.org/abs/2505.16646", "authors": ["Yujie Hou", "Ting Zhang", "Mei Wang", "Xuetao Ma", "Hu Huang"], "title": "SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models have achieved remarkable results on a variety of\nmathematical benchmarks. However, concerns remain as to whether these successes\nreflect genuine mathematical reasoning or superficial pattern recognition.\nCommon evaluation metrics, such as final answer accuracy, fail to disentangle\nthe underlying competencies involved, offering limited diagnostic value. To\naddress these limitations, we introduce SMART: a Self-Generating and\nSelf-Validating Multi-Dimensional Assessment Framework. SMART decomposes\nmathematical problem solving into four distinct dimensions: understanding,\nreasoning, arithmetic, and reflection \\& refinement. Each dimension is\nevaluated independently through tailored tasks, enabling interpretable and\nfine-grained analysis of LLM behavior. Crucially, SMART integrates an automated\nself-generating and self-validating mechanism to produce and verify benchmark\ndata, ensuring both scalability and reliability. We apply SMART to 21\nstate-of-the-art open- and closed-source LLMs, uncovering significant\ndiscrepancies in their abilities across different dimensions. Our findings\ndemonstrate the inadequacy of final answer accuracy as a sole metric and\nmotivate a new holistic metric to better capture true problem-solving\ncapabilities. Code and benchmarks will be released upon acceptance.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u8fd9\u4e9b\u6210\u529f\u662f\u5426\u53cd\u6620\u4e86\u771f\u6b63\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u4ecd\u5b58\u5728\u4e89\u8bae\u3002\u73b0\u6709\u7684\u8bc4\u4f30\u6307\u6807\u5982\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u6027\u65e0\u6cd5\u5145\u5206\u89e3\u6790\u5e95\u5c42\u80fd\u529b\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86SMART\u6846\u67b6\uff1a\u4e00\u4e2a\u81ea\u6211\u751f\u6210\u548c\u81ea\u6211\u9a8c\u8bc1\u7684\u591a\u7ef4\u8bc4\u4f30\u7cfb\u7edf\u3002SMART\u5c06\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u5206\u89e3\u4e3a\u7406\u89e3\u3001\u63a8\u7406\u3001\u7b97\u672f\u548c\u53cd\u601d\u56db\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u901a\u8fc7\u5b9a\u5236\u4efb\u52a1\u72ec\u7acb\u8bc4\u4f30\u6bcf\u4e2a\u7ef4\u5ea6\u3002\u6b64\u5916\uff0cSMART\u96c6\u6210\u4e86\u81ea\u52a8\u5316\u81ea\u6211\u751f\u6210\u548c\u81ea\u6211\u9a8c\u8bc1\u673a\u5236\uff0c\u4ee5\u786e\u4fdd\u53ef\u6269\u5c55\u6027\u548c\u53ef\u9760\u6027\u3002\u901a\u8fc7\u5bf921\u4e2a\u6700\u5148\u8fdb\u7684\u5f00\u6e90\u548c\u95ed\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u4e0d\u540c\u7ef4\u5ea6\u4e0a\u7684\u80fd\u529b\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4ec5\u4f9d\u9760\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u6027\u7684\u8bc4\u4f30\u65b9\u6cd5\u662f\u4e0d\u591f\u7684\uff0c\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u7efc\u5408\u6307\u6807\u6765\u66f4\u597d\u5730\u6355\u6349\u771f\u5b9e\u7684\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\u3002", "motivation": "\u76ee\u524d\u5bf9\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5c1a\u4e0d\u6e05\u695a\u5176\u6210\u529f\u662f\u57fa\u4e8e\u771f\u6b63\u7684\u6570\u5b66\u63a8\u7406\u8fd8\u662f\u8868\u9762\u6a21\u5f0f\u8bc6\u522b\u3002\u540c\u65f6\uff0c\u5e38\u7528\u7684\u8bc4\u4f30\u6307\u6807\uff08\u5982\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u6027\uff09\u65e0\u6cd5\u6709\u6548\u89e3\u6790\u6a21\u578b\u5728\u4e0d\u540c\u6570\u5b66\u80fd\u529b\u7ef4\u5ea6\u4e0a\u7684\u5177\u4f53\u8868\u73b0\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u7cbe\u7ec6\u548c\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSMART\u6846\u67b6\uff0c\u5c06\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u8fc7\u7a0b\u5206\u4e3a\u7406\u89e3\u3001\u63a8\u7406\u3001\u7b97\u672f\u548c\u53cd\u601d\u56db\u4e2a\u7ef4\u5ea6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9488\u5bf9\u6027\u7684\u4efb\u52a1\u6765\u72ec\u7acb\u8bc4\u4f30\u6bcf\u4e2a\u7ef4\u5ea6\u3002\u6b64\u5916\uff0cSMART\u8fd8\u5305\u542b\u81ea\u52a8\u5316\u7684\u81ea\u6211\u751f\u6210\u548c\u81ea\u6211\u9a8c\u8bc1\u673a\u5236\uff0c\u7528\u4e8e\u751f\u6210\u548c\u9a8c\u8bc1\u57fa\u51c6\u6570\u636e\uff0c\u4ece\u800c\u4fdd\u8bc1\u8bc4\u4f30\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u548c\u53ef\u9760\u6027\u3002", "result": "\u901a\u8fc7\u5bf921\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u4e0d\u540c\u7ef4\u5ea6\u4e0a\u7684\u80fd\u529b\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u7ed3\u679c\u8868\u660e\uff0c\u4ec5\u4f9d\u8d56\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u6027\u4f5c\u4e3a\u8bc4\u4f30\u6807\u51c6\u662f\u4e0d\u5145\u5206\u7684\u3002", "conclusion": "\u9700\u8981\u91c7\u7528\u65b0\u7684\u7efc\u5408\u6027\u8bc4\u4f30\u6307\u6807\u6765\u66f4\u5168\u9762\u5730\u8861\u91cf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u771f\u5b9e\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u5e76\u4e14SMART\u6846\u67b6\u4e3a\u8fd9\u4e00\u76ee\u6807\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u884c\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.16308", "pdf": "https://arxiv.org/pdf/2505.16308", "abs": "https://arxiv.org/abs/2505.16308", "authors": ["Xingyu Zhang", "Wenwen Qiang", "Siyu Zhao", "Huijie Guo", "Jiangmeng Li", "Chuxiong Sun", "Changwen Zheng"], "title": "CAIFormer: A Causal Informed Transformer for Multivariate Time Series Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Most existing multivariate time series forecasting methods adopt an\nall-to-all paradigm that feeds all variable histories into a unified model to\npredict their future values without distinguishing their individual roles.\nHowever, this undifferentiated paradigm makes it difficult to identify\nvariable-specific causal influences and often entangles causally relevant\ninformation with spurious correlations. To address this limitation, we propose\nan all-to-one forecasting paradigm that predicts each target variable\nseparately. Specifically, we first construct a Structural Causal Model from\nobservational data and then, for each target variable, we partition the\nhistorical sequence into four sub-segments according to the inferred causal\nstructure: endogenous, direct causal, collider causal, and spurious\ncorrelation. The prediction relies solely on the first three causally relevant\nsub-segments, while the spurious correlation sub-segment is excluded.\nFurthermore, we propose Causal Informed Transformer (CAIFormer), a novel\nforecasting model comprising three components: Endogenous Sub-segment\nPrediction Block, Direct Causal Sub-segment Prediction Block, and Collider\nCausal Sub-segment Prediction Block, which process the endogenous, direct\ncausal, and collider causal sub-segments, respectively. Their outputs are then\ncombined to produce the final prediction. Extensive experiments on multiple\nbenchmark datasets demonstrate the effectiveness of the CAIFormer.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684all-to-one\u9884\u6d4b\u8303\u5f0f\uff0c\u7ed3\u5408\u56e0\u679c\u7ed3\u6784\u548cCausal Informed Transformer (CAIFormer)\u6a21\u578b\u6765\u6539\u8fdb\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u3002", "motivation": "\u73b0\u6709\u5927\u591a\u6570\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u91c7\u7528all-to-all\u8303\u5f0f\uff0c\u96be\u4ee5\u533a\u5206\u53d8\u91cf\u7684\u7279\u5b9a\u56e0\u679c\u5f71\u54cd\uff0c\u5e76\u5bb9\u6613\u5c06\u56e0\u679c\u76f8\u5173\u7684\u4fe1\u606f\u4e0e\u865a\u5047\u76f8\u5173\u6df7\u6dc6\u3002", "method": "1. \u6784\u5efaStructural Causal Model\u4ece\u89c2\u5bdf\u6570\u636e\u4e2d\u63a8\u65ad\u56e0\u679c\u7ed3\u6784\u3002\n2. \u5c06\u5386\u53f2\u5e8f\u5217\u5212\u5206\u4e3a\u56db\u4e2a\u5b50\u6bb5\uff1a\u5185\u751f\u3001\u76f4\u63a5\u56e0\u679c\u3001\u78b0\u649e\u56e0\u679c\u548c\u865a\u5047\u76f8\u5173\u3002\n3. \u63d0\u51faCausal Informed Transformer (CAIFormer)\uff0c\u5305\u62ec\u4e09\u4e2a\u6a21\u5757\u5206\u522b\u5904\u7406\u5185\u751f\u3001\u76f4\u63a5\u56e0\u679c\u548c\u78b0\u649e\u56e0\u679c\u5b50\u6bb5\u3002\n4. \u7ed3\u5408\u4e09\u4e2a\u6a21\u5757\u7684\u8f93\u51fa\u751f\u6210\u6700\u7ec8\u9884\u6d4b\u7ed3\u679c\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cCAIFormer\u7684\u6709\u6548\u6027\u663e\u8457\u3002", "conclusion": "\u63d0\u51fa\u7684all-to-one\u8303\u5f0f\u548cCAIFormer\u6a21\u578b\u80fd\u591f\u6709\u6548\u8bc6\u522b\u53d8\u91cf\u7279\u5b9a\u7684\u56e0\u679c\u5f71\u54cd\uff0c\u51cf\u5c11\u865a\u5047\u76f8\u5173\u5e72\u6270\uff0c\u63d0\u5347\u591a\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2505.16667", "pdf": "https://arxiv.org/pdf/2505.16667", "abs": "https://arxiv.org/abs/2505.16667", "authors": ["Xinwei Yang", "Zhaofeng Liu", "Chen Huang", "Jiashuai Zhang", "Tong Zhang", "Yifan Zhang", "Wenqiang Lei"], "title": "ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming", "categories": ["cs.AI"], "comment": "ACL 2025 Main. Our code and dataset are available at\n  https://github.com/SCUNLP/ELABORATION", "summary": "While recent research increasingly emphasizes the value of human-LLM\ncollaboration in competitive programming and proposes numerous empirical\nmethods, a comprehensive understanding remains elusive due to the fragmented\nnature of existing studies and their use of diverse, application-specific human\nfeedback. Thus, our work serves a three-fold purpose: First, we present the\nfirst taxonomy of human feedback consolidating the entire programming process,\nwhich promotes fine-grained evaluation. Second, we introduce ELABORATIONSET, a\nnovel programming dataset specifically designed for human-LLM collaboration,\nmeticulously annotated to enable large-scale simulated human feedback and\nfacilitate costeffective real human interaction studies. Third, we introduce\nELABORATION, a novel benchmark to facilitate a thorough assessment of human-LLM\ncompetitive programming. With ELABORATION, we pinpoint strengthes and\nweaknesses of existing methods, thereby setting the foundation for future\nimprovement. Our code and dataset are available at\nhttps://github.com/SCUNLP/ELABORATION", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4eba\u7c7b\u53cd\u9988\u7684\u5206\u7c7b\u6cd5\uff0c\u8986\u76d6\u6574\u4e2a\u7f16\u7a0b\u8fc7\u7a0b\u4ee5\u4fc3\u8fdb\u7ec6\u7c92\u5ea6\u8bc4\u4f30\uff1b\u5f15\u5165\u4e86ELABORATIONSET\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u6a21\u62df\u5927\u89c4\u6a21\u4eba\u7c7b\u53cd\u9988\u548c\u5b9e\u9645\u4eba\u7c7b\u4ea4\u4e92\u7814\u7a76\uff1b\u8fd8\u63d0\u51fa\u4e86ELABORATION\u57fa\u51c6\uff0c\u7528\u4ee5\u5168\u9762\u8bc4\u4f30\u4eba\u7c7b\u4e0eLLM\u5728\u7ade\u4e89\u6027\u7f16\u7a0b\u4e2d\u7684\u5408\u4f5c\uff0c\u5e76\u6307\u51fa\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4f18\u52bf\u4e0e\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u5173\u4e8e\u4eba\u7c7b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u7ade\u4e89\u6027\u7f16\u7a0b\u4e2d\u5408\u4f5c\u7684\u7814\u7a76\u867d\u7136\u4f17\u591a\uff0c\u4f46\u56e0\u7814\u7a76\u788e\u7247\u5316\u4ee5\u53ca\u4f7f\u7528\u591a\u6837\u5316\u7684\u5e94\u7528\u7279\u5b9a\u4eba\u7c7b\u53cd\u9988\uff0c\u5bfc\u81f4\u5bf9\u8fd9\u4e00\u9886\u57df\u7684\u7efc\u5408\u7406\u89e3\u4ecd\u7136\u6709\u9650\u3002", "method": "1. \u63d0\u51fa\u4e00\u79cd\u6db5\u76d6\u6574\u4e2a\u7f16\u7a0b\u8fc7\u7a0b\u7684\u4eba\u7c7b\u53cd\u9988\u5206\u7c7b\u6cd5\uff0c\u4ee5\u652f\u6301\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u30022. \u521b\u5efa\u540d\u4e3aELABORATIONSET\u7684\u65b0\u578b\u7f16\u7a0b\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u7ecf\u8fc7\u7cbe\u5fc3\u6807\u6ce8\uff0c\u80fd\u591f\u5b9e\u73b0\u5927\u89c4\u6a21\u6a21\u62df\u4eba\u7c7b\u53cd\u9988\u5e76\u964d\u4f4e\u771f\u5b9e\u4eba\u7c7b\u4ea4\u4e92\u7814\u7a76\u7684\u6210\u672c\u30023. \u5f15\u5165ELABORATION\u65b0\u57fa\u51c6\uff0c\u4ee5\u6df1\u5165\u8bc4\u4f30\u4eba\u7c7b\u4e0eLLM\u5728\u7ade\u4e89\u6027\u7f16\u7a0b\u4e2d\u7684\u534f\u4f5c\u6548\u679c\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684ELABORATION\u57fa\u51c6\uff0c\u6210\u529f\u8bc6\u522b\u51fa\u73b0\u6709\u65b9\u6cd5\u7684\u4f18\u52bf\u4e0e\u52a3\u52bf\uff0c\u4e3a\u672a\u6765\u6539\u8fdb\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u63d0\u51fa\u5206\u7c7b\u6cd5\u3001\u65b0\u6570\u636e\u96c6\u53ca\u65b0\u57fa\u51c6\uff0c\u4fc3\u8fdb\u4e86\u5bf9\u4eba\u7c7b\u4e0eLLM\u5728\u7ade\u4e89\u6027\u7f16\u7a0b\u4e2d\u5408\u4f5c\u7684\u5168\u9762\u7406\u89e3\uff0c\u540c\u65f6\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u8d44\u6e90\u4e0e\u65b9\u5411\u3002"}}
{"id": "2505.16319", "pdf": "https://arxiv.org/pdf/2505.16319", "abs": "https://arxiv.org/abs/2505.16319", "authors": ["Yangyang Wang", "Jiawei Gu", "Li Long", "Xin Li", "Li Shen", "Zhouyu Fu", "Xiangjun Zhou", "Xu Jiang"], "title": "FreshRetailNet-50K: A Stockout-Annotated Censored Demand Dataset for Latent Demand Recovery and Forecasting in Fresh Retail", "categories": ["cs.LG"], "comment": "10 pages, 5 figures", "summary": "Accurate demand estimation is critical for the retail business in guiding the\ninventory and pricing policies of perishable products. However, it faces\nfundamental challenges from censored sales data during stockouts, where\nunobserved demand creates systemic policy biases. Existing datasets lack the\ntemporal resolution and annotations needed to address this censoring effect. To\nfill this gap, we present FreshRetailNet-50K, the first large-scale benchmark\nfor censored demand estimation. It comprises 50,000 store-product time series\nof detailed hourly sales data from 898 stores in 18 major cities, encompassing\n863 perishable SKUs meticulously annotated for stockout events. The hourly\nstock status records unique to this dataset, combined with rich contextual\ncovariates, including promotional discounts, precipitation, and temporal\nfeatures, enable innovative research beyond existing solutions. We demonstrate\none such use case of two-stage demand modeling: first, we reconstruct the\nlatent demand during stockouts using precise hourly annotations. We then\nleverage the recovered demand to train robust demand forecasting models in the\nsecond stage. Experimental results show that this approach achieves a 2.73\\%\nimprovement in prediction accuracy while reducing the systematic demand\nunderestimation from 7.37\\% to near-zero bias. With unprecedented temporal\ngranularity and comprehensive real-world information, FreshRetailNet-50K opens\nnew research directions in demand imputation, perishable inventory\noptimization, and causal retail analytics. The unique annotation quality and\nscale of the dataset address long-standing limitations in retail AI, providing\nimmediate solutions and a platform for future methodological innovation. The\ndata (https://huggingface.co/datasets/Dingdong-Inc/FreshRetailNet-50K) and code\n(https://github.com/Dingdong-Inc/frn-50k-baseline}) are openly released.", "AI": {"tldr": "\u51c6\u786e\u7684\u9700\u6c42\u4f30\u8ba1\u5bf9\u96f6\u552e\u4e1a\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u56e0\u7f3a\u8d27\u671f\u95f4\u672a\u89c2\u6d4b\u5230\u7684\u9700\u6c42\u5bfc\u81f4\u653f\u7b56\u504f\u5dee\u3002\u73b0\u6709\u6570\u636e\u96c6\u65e0\u6cd5\u89e3\u51b3\u8fd9\u79cd\u5ba1\u67e5\u6548\u5e94\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86FreshRetailNet-50K\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b50,000\u4e2a\u5546\u5e97\u4ea7\u54c1\u7684\u5c0f\u65f6\u9500\u552e\u6570\u636e\u548c\u5e93\u5b58\u72b6\u6001\u8bb0\u5f55\uff0c\u80fd\u591f\u901a\u8fc7\u4e24\u9636\u6bb5\u9700\u6c42\u5efa\u6a21\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u5e76\u51cf\u5c11\u7cfb\u7edf\u6027\u4f4e\u4f30\u3002\u6b64\u6570\u636e\u96c6\u89e3\u51b3\u4e86\u96f6\u552eAI\u7684\u957f\u671f\u9650\u5236\uff0c\u5e76\u4e3a\u672a\u6765\u521b\u65b0\u63d0\u4f9b\u4e86\u5e73\u53f0\u3002", "motivation": "\u51c6\u786e\u7684\u9700\u6c42\u4f30\u8ba1\u5bf9\u96f6\u552e\u4e1a\u5236\u5b9a\u5e93\u5b58\u548c\u5b9a\u4ef7\u7b56\u7565\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u7f3a\u8d27\u671f\u95f4\u7684\u5ba1\u67e5\u6548\u5e94\uff08\u5373\u672a\u89c2\u6d4b\u5230\u7684\u9700\u6c42\uff09\uff0c\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u65f6\u95f4\u548c\u6807\u6ce8\u7ec6\u8282\uff0c\u96be\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002\u8fd9\u5bfc\u81f4\u4e86\u7cfb\u7edf\u6027\u7684\u653f\u7b56\u504f\u5dee\u3002", "method": "\u63d0\u51fa\u540d\u4e3aFreshRetailNet-50K\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b\u8be6\u7ec6\u7684\u5c0f\u65f6\u7ea7\u9500\u552e\u6570\u636e\u3001\u5e93\u5b58\u72b6\u6001\u8bb0\u5f55\u53ca\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u53d8\u91cf\uff08\u5982\u4fc3\u9500\u6298\u6263\u3001\u964d\u6c34\u7b49\uff09\u3002\u901a\u8fc7\u4e24\u9636\u6bb5\u9700\u6c42\u5efa\u6a21\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u5229\u7528\u7cbe\u786e\u7684\u5c0f\u65f6\u7ea7\u6807\u6ce8\u91cd\u5efa\u7f3a\u8d27\u671f\u95f4\u7684\u6f5c\u5728\u9700\u6c42\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u6062\u590d\u7684\u9700\u6c42\u8bad\u7ec3\u7a33\u5065\u7684\u9700\u6c42\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5c06\u9884\u6d4b\u51c6\u786e\u6027\u63d0\u9ad8\u4e862.73%\uff0c\u5e76\u5c06\u7cfb\u7edf\u6027\u9700\u6c42\u4f4e\u4f30\u4ece7.37%\u964d\u4f4e\u81f3\u63a5\u8fd1\u96f6\u504f\u5dee\u3002", "conclusion": "FreshRetailNet-50K\u6570\u636e\u96c6\u4ee5\u524d\u6240\u672a\u6709\u7684\u65f6\u95f4\u7c92\u5ea6\u548c\u5168\u9762\u7684\u771f\u5b9e\u4e16\u754c\u4fe1\u606f\uff0c\u4e3a\u9700\u6c42\u586b\u8865\u3001\u6613\u8150\u54c1\u5e93\u5b58\u4f18\u5316\u548c\u56e0\u679c\u96f6\u552e\u5206\u6790\u5f00\u8f9f\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\uff0c\u89e3\u51b3\u4e86\u96f6\u552eAI\u7684\u957f\u671f\u9650\u5236\uff0c\u5e76\u63d0\u4f9b\u4e86\u5373\u65f6\u89e3\u51b3\u65b9\u6848\u548c\u672a\u6765\u65b9\u6cd5\u521b\u65b0\u7684\u5e73\u53f0\u3002"}}
{"id": "2505.16686", "pdf": "https://arxiv.org/pdf/2505.16686", "abs": "https://arxiv.org/abs/2505.16686", "authors": ["Lars Benedikt Kaesberg", "Jan Philip Wahle", "Terry Ruas", "Bela Gipp"], "title": "SPaRC: A Spatial Pathfinding Reasoning Challenge", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Existing reasoning datasets saturate and fail to test abstract, multi-step\nproblems, especially pathfinding and complex rule constraint satisfaction. We\nintroduce SPaRC (Spatial Pathfinding Reasoning Challenge), a dataset of 1,000\n2D grid pathfinding puzzles to evaluate spatial and symbolic reasoning,\nrequiring step-by-step planning with arithmetic and geometric rules. Humans\nachieve near-perfect accuracy (98.0%; 94.5% on hard puzzles), while the best\nreasoning models, such as o4-mini, struggle (15.8%; 1.1% on hard puzzles).\nModels often generate invalid paths (>50% of puzzles for o4-mini), and\nreasoning tokens reveal they make errors in navigation and spatial logic.\nUnlike humans, who take longer on hard puzzles, models fail to scale test-time\ncompute with difficulty. Allowing models to make multiple solution attempts\nimproves accuracy, suggesting potential for better spatial reasoning with\nimproved training and efficient test-time scaling methods. SPaRC can be used as\na window into models' spatial reasoning limitations and drive research toward\nnew methods that excel in abstract, multi-step problem-solving.", "AI": {"tldr": "\u73b0\u6709\u7684\u63a8\u7406\u6570\u636e\u96c6\u65e0\u6cd5\u6d4b\u8bd5\u62bd\u8c61\u3001\u591a\u6b65\u9aa4\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u8def\u5f84\u5bfb\u627e\u548c\u590d\u6742\u89c4\u5219\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u3002\u6211\u4eec\u5f15\u5165\u4e86SPaRC\u6570\u636e\u96c6\uff0c\u5305\u542b1000\u4e2a2D\u7f51\u683c\u8def\u5f84\u5bfb\u627e\u8c1c\u9898\uff0c\u7528\u4e8e\u8bc4\u4f30\u7a7a\u95f4\u548c\u7b26\u53f7\u63a8\u7406\u80fd\u529b\u3002\u4eba\u7c7b\u5728\u6b64\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0898.0%\u51c6\u786e\u7387\uff09\uff0c\u800c\u73b0\u6709\u6a21\u578b\u5982o4-mini\u5219\u8868\u73b0\u4e0d\u4f73\uff0815.8%\u51c6\u786e\u7387\uff09\u3002\u6a21\u578b\u7ecf\u5e38\u751f\u6210\u65e0\u6548\u8def\u5f84\uff0c\u5e76\u5728\u5bfc\u822a\u548c\u7a7a\u95f4\u903b\u8f91\u4e0a\u51fa\u9519\u3002\u4e0e\u4eba\u7c7b\u4e0d\u540c\uff0c\u6a21\u578b\u672a\u80fd\u6839\u636e\u4efb\u52a1\u96be\u5ea6\u8c03\u6574\u8ba1\u7b97\u8d44\u6e90\u3002\u901a\u8fc7\u591a\u6b21\u5c1d\u8bd5\u89e3\u9898\uff0c\u6a21\u578b\u7684\u51c6\u786e\u6027\u6709\u6240\u63d0\u9ad8\uff0c\u8868\u660e\u6539\u8fdb\u8bad\u7ec3\u65b9\u6cd5\u548c\u9ad8\u6548\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u65b9\u6cd5\u53ef\u80fd\u63d0\u5347\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u3002SPaRC\u53ef\u7528\u4e8e\u63ed\u793a\u6a21\u578b\u7684\u7a7a\u95f4\u63a8\u7406\u5c40\u9650\u6027\uff0c\u5e76\u63a8\u52a8\u7814\u7a76\u65b0\u7684\u62bd\u8c61\u3001\u591a\u6b65\u9aa4\u95ee\u9898\u89e3\u51b3\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u7406\u6570\u636e\u96c6\u65e0\u6cd5\u5145\u5206\u6d4b\u8bd5\u62bd\u8c61\u3001\u591a\u6b65\u9aa4\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u8def\u5f84\u5bfb\u627e\u548c\u590d\u6742\u89c4\u5219\u7ea6\u675f\u6ee1\u8db3\u95ee\u9898\u3002\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u65b0\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u6a21\u578b\u7684\u7a7a\u95f4\u548c\u7b26\u53f7\u63a8\u7406\u80fd\u529b\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aSPaRC\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b1000\u4e2a2D\u7f51\u683c\u8def\u5f84\u5bfb\u627e\u8c1c\u9898\uff0c\u8981\u6c42\u9010\u6b65\u89c4\u5212\u5e76\u9075\u5faa\u7b97\u672f\u548c\u51e0\u4f55\u89c4\u5219\u3002\u901a\u8fc7\u5bf9\u6bd4\u4eba\u7c7b\u548c\u73b0\u6709\u63a8\u7406\u6a21\u578b\u7684\u8868\u73b0\uff0c\u5206\u6790\u6a21\u578b\u5728\u7a7a\u95f4\u63a8\u7406\u4e0a\u7684\u5c40\u9650\u6027\u3002", "result": "\u4eba\u7c7b\u5728SPaRC\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u51c6\u786e\u7387\uff0898.0%\uff09\uff0c\u5c24\u5176\u5728\u7b80\u5355\u8c1c\u9898\u4e0a\u8868\u73b0\u4f18\u5f02\uff1b\u800c\u73b0\u6709\u6a21\u578b\u5982o4-mini\u5219\u8868\u73b0\u8f83\u5dee\uff0815.8%\uff09\uff0c\u7279\u522b\u662f\u5728\u56f0\u96be\u8c1c\u9898\u4e0a\uff081.1%\uff09\u3002\u6a21\u578b\u7ecf\u5e38\u751f\u6210\u65e0\u6548\u8def\u5f84\uff0c\u5e76\u5728\u5bfc\u822a\u548c\u7a7a\u95f4\u903b\u8f91\u4e0a\u51fa\u9519\u3002", "conclusion": "SPaRC\u6570\u636e\u96c6\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u7a7a\u95f4\u63a8\u7406\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u6539\u8fdb\u8bad\u7ec3\u65b9\u6cd5\u548c\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u6d4b\u8bd5\u65f6\u95f4\u6269\u5c55\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b9\u5411\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u62bd\u8c61\u3001\u591a\u6b65\u9aa4\u95ee\u9898\u89e3\u51b3\u7684\u7814\u7a76\u3002"}}
{"id": "2505.16322", "pdf": "https://arxiv.org/pdf/2505.16322", "abs": "https://arxiv.org/abs/2505.16322", "authors": ["Woosung Koh", "Wonbeen Oh", "Jaein Jang", "MinHyung Lee", "Hyeongjin Kim", "Ah Yeon Kim", "Joonkee Kim", "Junghyun Lee", "Taehyeon Kim", "Se-Young Yun"], "title": "AdaSTaR: Adaptive Data Sampling for Training Self-Taught Reasoners", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Pre-print", "summary": "Self-Taught Reasoners (STaR), synonymously known as Rejection sampling\nFine-Tuning (RFT), is an integral part of the training pipeline of\nself-improving reasoning Language Models (LMs). The self-improving mechanism\noften employs random observation (data) sampling. However, this results in\ntrained observation imbalance; inefficiently over-training on solved examples\nwhile under-training on challenging ones. In response, we introduce Adaptive\nSTaR (AdaSTaR), a novel algorithm that rectifies this by integrating two\nadaptive sampling principles: (1) Adaptive Sampling for Diversity: promoting\nbalanced training across observations, and (2) Adaptive Sampling for\nCurriculum: dynamically adjusting data difficulty to match the model's evolving\nstrength. Across six benchmarks, AdaSTaR achieves best test accuracy in all\ninstances (6/6) and reduces training FLOPs by an average of 58.6% against an\nextensive list of baselines. These improvements in performance and efficiency\ngeneralize to different pre-trained LMs and larger models, paving the way for\nmore efficient and effective self-improving LMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86AdaSTaR\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86Self-Taught Reasoners (STaR)\u4e2d\u7684\u8bad\u7ec3\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u4e24\u4e2a\u81ea\u9002\u5e94\u91c7\u6837\u539f\u5219\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u5e76\u51cf\u5c11\u4e86\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u6211\u6539\u5584\u673a\u5236\u901a\u5e38\u91c7\u7528\u968f\u673a\u89c2\u5bdf\uff08\u6570\u636e\uff09\u91c7\u6837\uff0c\u8fd9\u5bfc\u81f4\u8bad\u7ec3\u89c2\u5bdf\u4e0d\u5e73\u8861\u2014\u2014\u8fc7\u5ea6\u8bad\u7ec3\u4e8e\u5df2\u89e3\u51b3\u7684\u4f8b\u5b50\uff0c\u800c\u5bf9\u5177\u6709\u6311\u6218\u6027\u7684\u4f8b\u5b50\u8bad\u7ec3\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5AdaSTaR\uff0c\u901a\u8fc7\u6574\u5408\u4e24\u79cd\u81ea\u9002\u5e94\u91c7\u6837\u539f\u5219\u6765\u89e3\u51b3\u8bad\u7ec3\u89c2\u5bdf\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff1a(1) \u81ea\u9002\u5e94\u591a\u6837\u6027\u91c7\u6837\uff1a\u4fc3\u8fdb\u8de8\u89c2\u6d4b\u503c\u7684\u5e73\u8861\u8bad\u7ec3\uff1b(2) \u81ea\u9002\u5e94\u8bfe\u7a0b\u91c7\u6837\uff1a\u52a8\u6001\u8c03\u6574\u6570\u636e\u96be\u5ea6\u4ee5\u5339\u914d\u6a21\u578b\u4e0d\u65ad\u53d8\u5316\u7684\u5b9e\u529b\u3002", "result": "AdaSTaR\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u5b9e\u73b0\u4e86\u6700\u4f73\u6d4b\u8bd5\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u4e0e\u5e7f\u6cdb\u7684\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5e73\u5747\u51cf\u5c11\u4e8658.6%\u7684\u8bad\u7ec3FLOPs\u3002\u8fd9\u4e9b\u6027\u80fd\u548c\u6548\u7387\u7684\u6539\u8fdb\u53ef\u4ee5\u63a8\u5e7f\u5230\u4e0d\u540c\u7684\u9884\u8bad\u7ec3LMs\u548c\u66f4\u5927\u7684\u6a21\u578b\u3002", "conclusion": "AdaSTaR\u5728\u516d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u53d6\u5f97\u4e86\u6700\u4f73\u7684\u6d4b\u8bd5\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u5e73\u5747\u51cf\u5c11\u4e8658.6%\u7684\u8bad\u7ec3FLOPs\uff0c\u76f8\u8f83\u4e8e\u5e7f\u6cdb\u7684\u57fa\u7840\u6a21\u578b\u5c55\u73b0\u4e86\u6027\u80fd\u548c\u6548\u7387\u7684\u63d0\u5347\u3002\u8fd9\u4e9b\u6539\u8fdb\u9002\u7528\u4e8e\u4e0d\u540c\u7684\u9884\u8bad\u7ec3LMs\u548c\u66f4\u5927\u7684\u6a21\u578b\uff0c\u4e3a\u66f4\u9ad8\u6548\u548c\u6709\u6548\u7684\u81ea\u6539\u5584\u8bed\u8a00\u6a21\u578b\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2505.16700", "pdf": "https://arxiv.org/pdf/2505.16700", "abs": "https://arxiv.org/abs/2505.16700", "authors": ["Xuanqi Gao", "Siyi Xie", "Juan Zhai", "Shqing Ma", "Chao Shen"], "title": "MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "As Large Language Models (LLMs) evolve from passive text generators to active\nreasoning agents capable of tool interaction, the Model Context Protocol (MCP)\nhas emerged as a standardized framework for dynamic tool discovery and\norchestration. Despite widespread industry adoption, existing evaluation\nmethodologies fail to adequately assess tool utilization capabilities within\nthis new paradigm. This paper introduces MCP-RADAR, the first comprehensive\nbenchmark specifically designed to evaluate LLM performance in the MCP\nframework through a novel five-dimensional approach measuring: answer accuracy,\ntool selection efficiency, computational resource efficiency, parameter\nconstruction accuracy, and execution speed. Unlike conventional benchmarks that\nrely on subjective human evaluations or binary success metrics, MCP-RADAR\nemploys objective, quantifiable measurements across multiple task domains\nincluding software engineering, mathematical reasoning, and general\nproblem-solving. Our evaluations of leading commercial and open-source LLMs\nreveal distinctive capability profiles with significant trade-offs between\naccuracy, efficiency, and speed, challenging traditional single-metric\nperformance rankings. Besides, we provide valuable guidance for developers to\noptimize their tools for maximum model compatibility and effectiveness. While\nfocused on MCP due to its standardized approach, our methodology remains\napplicable across all LLM agent tool integration frameworks, providing valuable\ninsights for both LLM developers and tool creators to optimize the entire\nLLM-tool interaction ecosystem. The implementation, configurations, and\ndatasets used in our evaluation are publicly available at\nhttps://anonymous.4open.science/r/MCPRadar-B143.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86MCP-RADAR\uff0c\u4e00\u4e2a\u5168\u9762\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728Model Context Protocol\u6846\u67b6\u4e0b\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684\u57fa\u51c6\u3002\u5b83\u901a\u8fc7\u4e94\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u5ba2\u89c2\u91cf\u5316\u6d4b\u91cf\uff0c\u5e76\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u5728\u51c6\u786e\u5ea6\u3001\u6548\u7387\u548c\u901f\u5ea6\u4e0a\u7684\u6743\u8861\u3002", "motivation": "\u5f53\u524d\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u7684\u8bc4\u4f30\u65b9\u6cd5\u4e0d\u8db3\uff0c\u65e0\u6cd5\u5145\u5206\u9002\u5e94\u65b0\u7684MCP\u6846\u67b6\u4e0b\u7684\u9700\u6c42\u3002", "method": "\u5f15\u5165MCP-RADAR\uff0c\u4e00\u4e2a\u5168\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u4ece\u7b54\u6848\u51c6\u786e\u6027\u3001\u5de5\u5177\u9009\u62e9\u6548\u7387\u3001\u8ba1\u7b97\u8d44\u6e90\u6548\u7387\u3001\u53c2\u6570\u6784\u5efa\u51c6\u786e\u6027\u548c\u6267\u884c\u901f\u5ea6\u4e94\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5bf9\u9886\u5148\u7684\u5546\u4e1a\u548c\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u4e0d\u540c\u6a21\u578b\u5728\u51c6\u786e\u5ea6\u3001\u6548\u7387\u548c\u901f\u5ea6\u4e0a\u5b58\u5728\u663e\u8457\u6743\u8861\u3002", "conclusion": "MCP-RADAR\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4f18\u5316\u5de5\u5177\u7684\u6307\u5bfc\uff0c\u5e76\u9002\u7528\u4e8e\u6240\u6709\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5de5\u5177\u96c6\u6210\u6846\u67b6\uff0c\u63a8\u52a8\u6574\u4e2aLLM-\u5de5\u5177\u4ea4\u4e92\u751f\u6001\u7cfb\u7edf\u7684\u4f18\u5316\u3002"}}
{"id": "2505.16326", "pdf": "https://arxiv.org/pdf/2505.16326", "abs": "https://arxiv.org/abs/2505.16326", "authors": ["Qian Tan", "Dongzhan Zhou", "Peng Xia", "Wanhao Liu", "Wanli Ouyang", "Lei Bai", "Yuqiang Li", "Tianfan Fu"], "title": "ChemMLLM: Chemical Multimodal Large Language Model", "categories": ["cs.LG"], "comment": "25 pages", "summary": "Multimodal large language models (MLLMs) have made impressive progress in\nmany applications in recent years. However, chemical MLLMs that can handle\ncross-modal understanding and generation remain underexplored. To fill this\ngap, in this paper, we propose ChemMLLM, a unified chemical multimodal large\nlanguage model for molecule understanding and generation. Also, we design five\nmultimodal tasks across text, molecular SMILES strings, and image, and curate\nthe datasets. We benchmark ChemMLLM against a range of general leading MLLMs\nand Chemical LLMs on these tasks. Experimental results show that ChemMLLM\nachieves superior performance across all evaluated tasks. For example, in\nmolecule image optimization task, ChemMLLM outperforms the best baseline\n(GPT-4o) by 118.9\\% (4.27 vs 1.95 property improvement). The code is publicly\navailable at https://github.com/bbsbz/ChemMLLM.git.", "AI": {"tldr": "\u63d0\u51faChemMLLM\uff0c\u4e00\u4e2a\u7528\u4e8e\u5206\u5b50\u7406\u89e3\u548c\u751f\u6210\u7684\u5316\u5b66\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e94\u4e2a\u8de8\u6587\u672c\u3001\u5206\u5b50SMILES\u5b57\u7b26\u4e32\u548c\u56fe\u50cf\u7684\u591a\u6a21\u6001\u4efb\u52a1\u53ca\u76f8\u5e94\u6570\u636e\u96c6\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cChemMLLM\u5728\u6240\u6709\u8bc4\u4f30\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5c3d\u7ba1\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bb8\u591a\u5e94\u7528\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u80fd\u591f\u5904\u7406\u8de8\u6a21\u6001\u7406\u89e3\u548c\u751f\u6210\u7684\u5316\u5b66\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4ecd\u9c9c\u6709\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86ChemMLLM\uff0c\u4e00\u4e2a\u7edf\u4e00\u7684\u5316\u5b66\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e94\u4e2a\u8de8\u6587\u672c\u3001\u5206\u5b50SMILES\u5b57\u7b26\u4e32\u548c\u56fe\u50cf\u7684\u591a\u6a21\u6001\u4efb\u52a1\uff0c\u540c\u65f6\u6574\u7406\u4e86\u76f8\u5173\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cChemMLLM\u5728\u6240\u6709\u8bc4\u4f30\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u4f8b\u5982\u5728\u5206\u5b50\u56fe\u50cf\u4f18\u5316\u4efb\u52a1\u4e2d\uff0cChemMLLM\u76f8\u6bd4\u6700\u4f73\u57fa\u7ebf\uff08GPT-4o\uff09\u6027\u80fd\u63d0\u5347\u4e86118.9%\u3002", "conclusion": "ChemMLLM\u5728\u5316\u5b66\u591a\u6a21\u6001\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u5c55\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\uff0c\u5176\u4ee3\u7801\u5df2\u516c\u5f00\u53d1\u5e03\u3002"}}
{"id": "2505.16771", "pdf": "https://arxiv.org/pdf/2505.16771", "abs": "https://arxiv.org/abs/2505.16771", "authors": ["Beyazit Bestami Yuksel", "Ayse Yilmazer Metin"], "title": "Data-Driven Breakthroughs and Future Directions in AI Infrastructure: A Comprehensive Review", "categories": ["cs.AI"], "comment": "10 pages, 6 figures, 3 tables", "summary": "This paper presents a comprehensive synthesis of major breakthroughs in\nartificial intelligence (AI) over the past fifteen years, integrating\nhistorical, theoretical, and technological perspectives. It identifies key\ninflection points in AI' s evolution by tracing the convergence of\ncomputational resources, data access, and algorithmic innovation. The analysis\nhighlights how researchers enabled GPU based model training, triggered a data\ncentric shift with ImageNet, simplified architectures through the Transformer,\nand expanded modeling capabilities with the GPT series. Rather than treating\nthese advances as isolated milestones, the paper frames them as indicators of\ndeeper paradigm shifts. By applying concepts from statistical learning theory\nsuch as sample complexity and data efficiency, the paper explains how\nresearchers translated breakthroughs into scalable solutions and why the field\nmust now embrace data centric approaches. In response to rising privacy\nconcerns and tightening regulations, the paper evaluates emerging solutions\nlike federated learning, privacy enhancing technologies (PETs), and the data\nsite paradigm, which reframe data access and security. In cases where real\nworld data remains inaccessible, the paper also assesses the utility and\nconstraints of mock and synthetic data generation. By aligning technical\ninsights with evolving data infrastructure, this study offers strategic\nguidance for future AI research and policy development.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u603b\u7ed3\u4e86\u8fc7\u53bb\u5341\u4e94\u5e74\u4e2d\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u91cd\u5927\u7a81\u7834\uff0c\u4ece\u5386\u53f2\u3001\u7406\u8bba\u548c\u6280\u672f\u89d2\u5ea6\u5206\u6790\u4e86\u8fd9\u4e9b\u8fdb\u5c55\uff0c\u5e76\u63a2\u8ba8\u4e86\u672a\u6765\u7684AI\u7814\u7a76\u548c\u653f\u7b56\u53d1\u5c55\u65b9\u5411\u3002", "motivation": "\u6574\u5408\u5386\u53f2\u3001\u7406\u8bba\u548c\u6280\u672f\u89c6\u89d2\uff0c\u8bc6\u522bAI\u8fdb\u5316\u4e2d\u7684\u5173\u952e\u8f6c\u6298\u70b9\uff0c\u89e3\u91ca\u7814\u7a76\u5982\u4f55\u5c06\u7a81\u7834\u8f6c\u5316\u4e3a\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u8bc4\u4f30\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u7684\u4f5c\u7528\u3002", "method": "\u901a\u8fc7\u8ffd\u6eaf\u8ba1\u7b97\u8d44\u6e90\u3001\u6570\u636e\u8bbf\u95ee\u548c\u7b97\u6cd5\u521b\u65b0\u7684\u6c47\u805a\u6765\u786e\u5b9aAI\u8fdb\u5316\u4e2d\u7684\u5173\u952e\u8f6c\u6298\u70b9\uff1b\u5e94\u7528\u7edf\u8ba1\u5b66\u4e60\u7406\u8bba\u7684\u6982\u5ff5\u5982\u6837\u672c\u590d\u6742\u6027\u548c\u6570\u636e\u6548\u7387\u6765\u89e3\u91ca\u7a81\u7834\uff1b\u8bc4\u4f30\u65b0\u5174\u7684\u9690\u79c1\u4fdd\u62a4\u6280\u672f\u5982\u8054\u90a6\u5b66\u4e60\u3001PETs\u548c\u6570\u636e\u7ad9\u70b9\u8303\u5f0f\u3002", "result": "\u660e\u786e\u4e86GPU\u6a21\u578b\u8bad\u7ec3\u3001ImageNet\u5f15\u53d1\u7684\u6570\u636e\u4e2d\u5fc3\u5316\u8f6c\u53d8\u3001Transformer\u67b6\u6784\u7b80\u5316\u4ee5\u53caGPT\u7cfb\u5217\u6269\u5c55\u5efa\u6a21\u80fd\u529b\u7b49\u4e3a\u66f4\u6df1\u5c42\u6b21\u7684\u8303\u5f0f\u8f6c\u53d8\u7684\u6307\u6807\uff1b\u5f3a\u8c03\u4e86\u6570\u636e\u4e3a\u4e2d\u5fc3\u65b9\u6cd5\u7684\u91cd\u8981\u6027\uff1b\u8bc4\u4f30\u4e86\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0d\u53ef\u7528\u65f6\u6a21\u62df\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u7684\u6548\u7528\u548c\u9650\u5236\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u6280\u672f\u89c1\u89e3\u4e0e\u4e0d\u65ad\u53d1\u5c55\u7684\u6570\u636e\u57fa\u7840\u8bbe\u65bd\u7684\u5bf9\u9f50\uff0c\u8be5\u7814\u7a76\u4e3a\u672a\u6765\u7684AI\u7814\u7a76\u548c\u653f\u7b56\u53d1\u5c55\u63d0\u4f9b\u4e86\u6218\u7565\u6307\u5bfc\u3002"}}
{"id": "2505.16333", "pdf": "https://arxiv.org/pdf/2505.16333", "abs": "https://arxiv.org/abs/2505.16333", "authors": ["Chaerin Kong", "Jiho Jang", "Nojun Kwak"], "title": "Understanding Differential Transformer Unchains Pretrained Self-Attentions", "categories": ["cs.LG"], "comment": "9 pages", "summary": "Differential Transformer has recently gained significant attention for its\nimpressive empirical performance, often attributed to its ability to perform\nnoise canceled attention. However, precisely how differential attention\nachieves its empirical benefits remains poorly understood. Moreover,\nDifferential Transformer architecture demands large-scale training from\nscratch, hindering utilization of open pretrained weights. In this work, we\nconduct an in-depth investigation of Differential Transformer, uncovering three\nkey factors behind its success: (1) enhanced expressivity via negative\nattention, (2) reduced redundancy among attention heads, and (3) improved\nlearning dynamics. Based on these findings, we propose DEX, a novel method to\nefficiently integrate the advantages of differential attention into pretrained\nlanguage models. By reusing the softmax attention scores and adding a\nlightweight differential operation on the output value matrix, DEX effectively\nincorporates the key advantages of differential attention while remaining\nlightweight in both training and inference. Evaluations confirm that DEX\nsubstantially improves the pretrained LLMs across diverse benchmarks, achieving\nsignificant performance gains with minimal adaptation data (< 0.01\\%).", "AI": {"tldr": "Differential Transformer\u56e0\u5176\u5353\u8d8a\u7684\u6027\u80fd\u53d7\u5230\u5173\u6ce8\uff0c\u4f46\u5176\u6210\u529f\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u6587\u7814\u7a76\u53d1\u73b0\u5176\u6210\u529f\u6e90\u4e8e\u8d1f\u6ce8\u610f\u529b\u589e\u5f3a\u8868\u8fbe\u80fd\u529b\u3001\u51cf\u5c11\u6ce8\u610f\u529b\u5934\u5197\u4f59\u548c\u6539\u5584\u5b66\u4e60\u52a8\u6001\uff0c\u5e76\u63d0\u51faDEX\u65b9\u6cd5\u5c06\u8fd9\u4e9b\u4f18\u52bf\u6574\u5408\u5230\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u901a\u8fc7\u5c11\u91cf\u6570\u636e(<0.01%)\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5c3d\u7ba1Differential Transformer\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u6210\u529f\u539f\u56e0\u5c1a\u672a\u660e\u786e\uff0c\u4e14\u5176\u67b6\u6784\u9700\u8981\u4ece\u5934\u5f00\u59cb\u5927\u89c4\u6a21\u8bad\u7ec3\uff0c\u9650\u5236\u4e86\u9884\u8bad\u7ec3\u6743\u91cd\u7684\u4f7f\u7528\u3002", "method": "\u901a\u8fc7\u6df1\u5165\u7814\u7a76\uff0c\u63ed\u793aDifferential Transformer\u6210\u529f\u7684\u4e09\u4e2a\u5173\u952e\u56e0\u7d20\uff1a\u8d1f\u6ce8\u610f\u529b\u589e\u5f3a\u8868\u8fbe\u80fd\u529b\u3001\u51cf\u5c11\u6ce8\u610f\u529b\u5934\u5197\u4f59\u3001\u6539\u5584\u5b66\u4e60\u52a8\u6001\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51faDEX\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u7528softmax\u6ce8\u610f\u529b\u5206\u6570\u5e76\u5728\u8f93\u51fa\u503c\u77e9\u9635\u4e0a\u6dfb\u52a0\u8f7b\u91cf\u7ea7\u5dee\u5206\u64cd\u4f5c\uff0c\u5c06\u5dee\u5206\u6ce8\u610f\u7684\u4f18\u52bf\u9ad8\u6548\u6574\u5408\u5230\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u4e2d\u3002", "result": "DEX\u65b9\u6cd5\u5728\u591a\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u8bad\u7ec3LLMs\u7684\u6027\u80fd\uff0c\u4ec5\u9700\u6781\u5c11\u91cf\u7684\u9002\u5e94\u6570\u636e(<0.01%)\u5373\u53ef\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "Differential Transformer\u7684\u6210\u529f\u53ef\u5f52\u56e0\u4e8e\u8d1f\u6ce8\u610f\u529b\u3001\u51cf\u5c11\u5197\u4f59\u548c\u6539\u8fdb\u5b66\u4e60\u52a8\u6001\u3002DEX\u65b9\u6cd5\u4e3a\u9ad8\u6548\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u5c55\u793a\u4e86\u5728\u5c11\u91cf\u6570\u636e\u4e0b\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u7684\u80fd\u529b\u3002"}}
{"id": "2505.16781", "pdf": "https://arxiv.org/pdf/2505.16781", "abs": "https://arxiv.org/abs/2505.16781", "authors": ["Qianlei Jia", "Xinliang Zhou", "Ondrej Krejcar", "Enrique Herrera-Viedma"], "title": "Fuzzy Information Evolution with Three-Way Decision in Social Network Group Decision-Making", "categories": ["cs.AI"], "comment": null, "summary": "In group decision-making (GDM) scenarios, uncertainty, dynamic social\nstructures, and vague information present major challenges for traditional\nopinion dynamics models. To address these issues, this study proposes a novel\nsocial network group decision-making (SNGDM) framework that integrates\nthree-way decision (3WD) theory, dynamic network reconstruction, and linguistic\nopinion representation. First, the 3WD mechanism is introduced to explicitly\nmodel hesitation and ambiguity in agent judgments, thereby preventing\nirrational decisions. Second, a connection adjustment rule based on opinion\nsimilarity is developed, enabling agents to adaptively update their\ncommunication links and better reflect the evolving nature of social\nrelationships. Third, linguistic terms are used to describe agent opinions,\nallowing the model to handle subjective, vague, or incomplete information more\neffectively. Finally, an integrated multi-agent decision-making framework is\nconstructed, which simultaneously considers individual uncertainty, opinion\nevolution, and network dynamics. The proposed model is applied to a multi-UAV\ncooperative decision-making scenario, where simulation results and consensus\nanalysis demonstrate its effectiveness. Experimental comparisons further verify\nthe advantages of the algorithm in enhancing system stability and representing\nrealistic decision-making behaviors.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u793e\u4f1a\u7f51\u7edc\u7fa4\u4f53\u51b3\u7b56(SNGDM)\u6846\u67b6\uff0c\u7ed3\u5408\u4e09\u91cd\u51b3\u7b56\u7406\u8bba\u3001\u52a8\u6001\u7f51\u7edc\u91cd\u5efa\u548c\u8bed\u8a00\u610f\u89c1\u8868\u793a\u6765\u5e94\u5bf9\u4f20\u7edf\u6a21\u578b\u4e2d\u7684\u6311\u6218\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u4e09\u91cd\u51b3\u7b56\u673a\u5236\u3001\u57fa\u4e8e\u610f\u89c1\u76f8\u4f3c\u6027\u7684\u8fde\u63a5\u8c03\u6574\u89c4\u5219\u4ee5\u53ca\u4f7f\u7528\u8bed\u8a00\u672f\u8bed\u63cf\u8ff0\u4ee3\u7406\u610f\u89c1\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u3001\u610f\u89c1\u6f14\u53d8\u548c\u7f51\u7edc\u52a8\u6001\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u591aUAV\u534f\u4f5c\u51b3\u7b56\u573a\u666f\u4e2d\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7a33\u5b9a\u6027\u548c\u51b3\u7b56\u884c\u4e3a\u7684\u771f\u5b9e\u6027\u3002", "motivation": "\u7fa4\u4f53\u51b3\u7b56\u9762\u4e34\u4e0d\u786e\u5b9a\u6027\u3001\u52a8\u6001\u793e\u4f1a\u7ed3\u6784\u548c\u6a21\u7cca\u4fe1\u606f\u7684\u6311\u6218\uff0c\u4f20\u7edf\u610f\u89c1\u52a8\u529b\u5b66\u6a21\u578b\u96be\u4ee5\u6709\u6548\u5e94\u5bf9\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "1. \u5f15\u5165\u4e09\u91cd\u51b3\u7b56\u673a\u5236\u4ee5\u660e\u786e\u5efa\u6a21\u4ee3\u7406\u5224\u65ad\u4e2d\u7684\u72b9\u8c6b\u548c\u6a21\u7cca\u6027\u3002\n2. \u5f00\u53d1\u57fa\u4e8e\u610f\u89c1\u76f8\u4f3c\u6027\u7684\u8fde\u63a5\u8c03\u6574\u89c4\u5219\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u81ea\u9002\u5e94\u66f4\u65b0\u901a\u4fe1\u94fe\u8def\u3002\n3. \u4f7f\u7528\u8bed\u8a00\u672f\u8bed\u63cf\u8ff0\u4ee3\u7406\u610f\u89c1\uff0c\u4ee5\u66f4\u597d\u5730\u5904\u7406\u4e3b\u89c2\u3001\u6a21\u7cca\u6216\u4e0d\u5b8c\u6574\u7684\u4fe1\u606f\u3002\n4. \u6784\u5efa\u96c6\u6210\u591a\u4ee3\u7406\u51b3\u7b56\u6846\u67b6\uff0c\u540c\u65f6\u8003\u8651\u4e2a\u4f53\u4e0d\u786e\u5b9a\u6027\u3001\u610f\u89c1\u6f14\u5316\u548c\u7f51\u7edc\u52a8\u6001\u3002", "result": "\u8be5\u6a21\u578b\u5e94\u7528\u4e8e\u591a\u65e0\u4eba\u673a\u534f\u540c\u51b3\u7b56\u573a\u666f\u4e2d\uff0c\u6a21\u62df\u7ed3\u679c\u548c\u5171\u8bc6\u5206\u6790\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002\u5b9e\u9a8c\u6bd4\u8f83\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u8be5\u7b97\u6cd5\u5728\u63d0\u9ad8\u7cfb\u7edf\u7a33\u5b9a\u6027\u548c\u8868\u793a\u73b0\u5b9e\u51b3\u7b56\u884c\u4e3a\u65b9\u9762\u7684\u4f18\u52bf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684SNGDM\u6846\u67b6\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u7fa4\u4f53\u51b3\u7b56\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3001\u52a8\u6001\u793e\u4f1a\u7ed3\u6784\u548c\u6a21\u7cca\u4fe1\u606f\u95ee\u9898\uff0c\u9002\u7528\u4e8e\u591aUAV\u534f\u4f5c\u51b3\u7b56\u7b49\u5b9e\u9645\u573a\u666f\u3002"}}
{"id": "2505.16340", "pdf": "https://arxiv.org/pdf/2505.16340", "abs": "https://arxiv.org/abs/2505.16340", "authors": ["Yunhui Jang", "Jaehyung Kim", "Sungsoo Ahn"], "title": "Improving Chemical Understanding of LLMs via SMILES Parsing", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) are increasingly recognized as powerful tools\nfor scientific discovery, particularly in molecular science. A fundamental\nrequirement for these models is the ability to accurately understand molecular\nstructures, commonly encoded in the SMILES representation. However, current\nLLMs struggle to interpret SMILES, even failing to carry out basic tasks such\nas counting molecular rings. To address this limitation, we introduce CLEANMOL,\na novel framework that formulates SMILES parsing into a suite of clean and\ndeterministic tasks explicitly designed to promote graph-level molecular\ncomprehension. These tasks span from subgraph matching to global graph\nmatching, providing structured supervision aligned with molecular structural\nproperties. We construct a molecular pretraining dataset with adaptive\ndifficulty scoring and pre-train open-source LLMs on these tasks. Our results\nshow that CLEANMOL not only enhances structural comprehension but also achieves\nthe best or competes with the baseline on the Mol-Instructions benchmark.", "AI": {"tldr": "CLEANMOL \u662f\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u5c06 SMILES \u89e3\u6790\u8f6c\u5316\u4e3a\u660e\u786e\u7684\u4efb\u52a1\u4ee5\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5206\u5b50\u7ed3\u6784\u7406\u89e3\u80fd\u529b\u3002\u901a\u8fc7\u5b50\u56fe\u548c\u5168\u5c40\u56fe\u5339\u914d\u4efb\u52a1\u53ca\u81ea\u9002\u5e94\u96be\u5ea6\u8bc4\u5206\u7684\u6570\u636e\u96c6\u9884\u8bad\u7ec3\uff0cCLEANMOL \u63d0\u5347\u4e86\u5f00\u6e90 LLM \u7684\u5206\u5b50\u7ed3\u6784\u7406\u89e3\u80fd\u529b\uff0c\u5e76\u5728 Mol-Instructions \u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u96be\u4ee5\u51c6\u786e\u89e3\u6790 SMILES \u8868\u793a\u6cd5\uff0c\u751a\u81f3\u65e0\u6cd5\u5b8c\u6210\u57fa\u672c\u4efb\u52a1\u5982\u8ba1\u7b97\u5206\u5b50\u73af\u7684\u6570\u91cf\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u5206\u5b50\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa CLEANMOL \u6846\u67b6\uff0c\u5c06 SMILES \u89e3\u6790\u8f6c\u5316\u4e3a\u4e00\u7cfb\u5217\u660e\u786e\u4e14\u786e\u5b9a\u6027\u7684\u4efb\u52a1\uff0c\u5305\u62ec\u5b50\u56fe\u5339\u914d\u548c\u5168\u5c40\u56fe\u5339\u914d\u7b49\uff0c\u8fd9\u4e9b\u4efb\u52a1\u4e0e\u5206\u5b50\u7ed3\u6784\u7279\u6027\u5bf9\u9f50\u3002\u6784\u5efa\u5177\u6709\u81ea\u9002\u5e94\u96be\u5ea6\u8bc4\u5206\u7684\u5206\u5b50\u9884\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u5e76\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u9884\u8bad\u7ec3\u5f00\u6e90 LLMs\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCLEANMOL \u4e0d\u4ec5\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u7ed3\u6784\u7406\u89e3\u80fd\u529b\uff0c\u8fd8\u5728 Mol-Instructions \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u4f73\u6216\u4e0e\u57fa\u7ebf\u6301\u5e73\u7684\u8868\u73b0\u3002", "conclusion": "CLEANMOL \u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u5206\u5b50\u7ed3\u6784\u7684\u7406\u89e3\u80fd\u529b\uff0c\u4e3a\u5206\u5b50\u79d1\u5b66\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u5de5\u5177\u652f\u6301\u3002"}}
{"id": "2505.16787", "pdf": "https://arxiv.org/pdf/2505.16787", "abs": "https://arxiv.org/abs/2505.16787", "authors": ["Ashish Sundar", "Chunbo Luo", "Xiaoyang Wang"], "title": "Gaze Into the Abyss -- Planning to Seek Entropy When Reward is Scarce", "categories": ["cs.AI"], "comment": "9 pages without appendix, 15 Figures, preprint", "summary": "Model-based reinforcement learning (MBRL) offers an intuitive way to increase\nthe sample efficiency of model-free RL methods by simultaneously training a\nworld model that learns to predict the future. MBRL methods have progressed by\nlargely prioritising the actor; optimising the world model learning has been\nneglected meanwhile. Improving the fidelity of the world model and reducing its\ntime to convergence can yield significant downstream benefits, one of which is\nimproving the ensuing performance of any actor it may train. We propose a novel\napproach that anticipates and actively seeks out high-entropy states using\nshort-horizon latent predictions generated by the world model, offering a\nprincipled alternative to traditional curiosity-driven methods that chase\nonce-novel states well after they were stumbled into. While many model\npredictive control (MPC) based methods offer similar alternatives, they\ntypically lack commitment, synthesising multi step plans after every step. To\nmitigate this, we present a hierarchical planner that dynamically decides when\nto replan, planning horizon length, and the weighting between reward and\nentropy. While our method can theoretically be applied to any model that trains\nits own actors with solely model generated data, we have applied it to just\nDreamer as a proof of concept. Our method finishes the Miniworld procedurally\ngenerated mazes 50% faster than base Dreamer at convergence and the policy\ntrained in imagination converges in only 60% of the environment steps that base\nDreamer needs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684MBRL\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e3b\u52a8\u5bfb\u627e\u9ad8\u71b5\u72b6\u6001\u548c\u5206\u5c42\u89c4\u5212\u5668\u4f18\u5316world model\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5728Miniworld\u8ff7\u5bab\u4efb\u52a1\u4e2d\u6bd4\u57fa\u7840Dreamer\u66f4\u9ad8\u6548\u3002", "motivation": "MBRL\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8actor\u7684\u4f18\u5316\uff0c\u800c\u5ffd\u89c6\u4e86world model\u7684\u5b66\u4e60\u4f18\u5316\u3002\u7136\u800c\uff0c\u63d0\u9ad8world model\u7684\u4fdd\u771f\u5ea6\u548c\u51cf\u5c11\u5176\u6536\u655b\u65f6\u95f4\u53ef\u4ee5\u5e26\u6765\u663e\u8457\u7684\u4e0b\u6e38\u597d\u5904\uff0c\u4f8b\u5982\u6539\u5584actor\u7684\u8bad\u7ec3\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528world model\u751f\u6210\u7684\u77ed\u89c6\u8ddd\u6f5c\u5728\u9884\u6d4b\uff0c\u4e3b\u52a8\u5bfb\u627e\u9ad8\u71b5\u72b6\u6001\uff0c\u4e3a\u4f20\u7edf\u7684\u57fa\u4e8e\u597d\u5947\u5fc3\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u539f\u5219\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u5c42\u89c4\u5212\u5668\uff0c\u52a8\u6001\u51b3\u5b9a\u4f55\u65f6\u91cd\u65b0\u89c4\u5212\u3001\u89c4\u5212\u65f6\u957f\u4ee5\u53ca\u5956\u52b1\u4e0e\u71b5\u4e4b\u95f4\u7684\u6743\u91cd\u3002\u8be5\u65b9\u6cd5\u7406\u8bba\u4e0a\u53ef\u5e94\u7528\u4e8e\u4efb\u4f55\u4ec5\u4f7f\u7528\u6a21\u578b\u751f\u6210\u6570\u636e\u8bad\u7ec3actor\u7684\u6a21\u578b\uff0c\u4f46\u672c\u6587\u53ea\u4ee5Dreamer\u4e3a\u4f8b\u8fdb\u884c\u6982\u5ff5\u9a8c\u8bc1\u3002", "result": "\u5728Miniworld\u7a0b\u5e8f\u751f\u6210\u7684\u8ff7\u5bab\u4efb\u52a1\u4e2d\uff0c\u76f8\u8f83\u4e8e\u57fa\u7840Dreamer\uff0c\u8be5\u65b9\u6cd5\u5728\u6536\u655b\u65f6\u901f\u5ea6\u5feb50\uff05\uff0c\u4e14\u5728\u60f3\u8c61\u4e2d\u8bad\u7ec3\u7684\u7b56\u7565\u53ea\u9700\u8981\u57fa\u7840Dreamer 60%\u7684\u73af\u5883\u6b65\u9aa4\u5373\u53ef\u6536\u655b\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316world model\u5b66\u4e60\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347MBRL\u65b9\u6cd5\u7684\u6837\u672c\u6548\u7387\u548c\u6536\u655b\u901f\u5ea6\u3002\u6240\u63d0\u51fa\u7684\u65b0\u65b9\u6cd5\u5728\u6d4b\u8bd5\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7840Dreamer\u3002"}}
{"id": "2505.16341", "pdf": "https://arxiv.org/pdf/2505.16341", "abs": "https://arxiv.org/abs/2505.16341", "authors": ["Yaxin Hou", "Yuheng Jia"], "title": "A Square Peg in a Square Hole: Meta-Expert for Long-Tailed Semi-Supervised Learning", "categories": ["cs.LG"], "comment": "The paper is accepted by ICML 2025", "summary": "This paper studies the long-tailed semi-supervised learning (LTSSL) with\ndistribution mismatch, where the class distribution of the labeled training\ndata follows a long-tailed distribution and mismatches with that of the\nunlabeled training data. Most existing methods introduce auxiliary classifiers\n(experts) to model various unlabeled data distributions and produce\npseudo-labels, but the expertises of various experts are not fully utilized. We\nobserve that different experts are good at predicting different intervals of\nsamples, e.g., long-tailed expert is skilled in samples located in the head\ninterval and uniform expert excels in samples located in the medium interval.\nTherefore, we propose a dynamic expert assignment module that can estimate the\nclass membership (i.e., head, medium, or tail class) of samples, and\ndynamically assigns suitable expert to each sample based on the estimated\nmembership to produce high-quality pseudo-label in the training phase and\nproduce prediction in the testing phase. We also theoretically reveal that\nintegrating different experts' strengths will lead to a smaller generalization\nerror bound. Moreover, we find that the deeper features are more biased toward\nthe head class but with more discriminative ability, while the shallower\nfeatures are less biased but also with less discriminative ability. We,\ntherefore, propose a multi-depth feature fusion module to utilize different\ndepth features to mitigate the model bias. Our method demonstrates its\neffectiveness through comprehensive experiments on the CIFAR-10-LT, STL-10-LT,\nand SVHN-LT datasets across various settings. The code is available at\nhttps://github.com/yaxinhou/Meta-Expert.", "AI": {"tldr": "This paper tackles long-tailed semi-supervised learning with distribution mismatch by proposing a dynamic expert assignment module and a multi-depth feature fusion module, leading to improved performance and reduced model bias.", "motivation": "Existing methods for long-tailed semi-supervised learning do not fully utilize the expertise of different auxiliary classifiers (experts) when handling distribution mismatches between labeled and unlabeled data.", "method": "1. Dynamic Expert Assignment Module: Estimates the class membership (head, medium, or tail) of samples and assigns suitable experts based on this estimation to produce high-quality pseudo-labels during training and predictions during testing.\n2. Multi-Depth Feature Fusion Module: Combines features from different depths in the network to balance bias toward head classes and discriminative ability.", "result": "Comprehensive experiments on CIFAR-10-LT, STL-10-LT, and SVHN-LT datasets demonstrate the effectiveness of the method across various settings.", "conclusion": "The proposed method effectively addresses the challenges of long-tailed semi-supervised learning with distribution mismatch through dynamic expert assignment and multi-depth feature fusion."}}
{"id": "2505.16826", "pdf": "https://arxiv.org/pdf/2505.16826", "abs": "https://arxiv.org/abs/2505.16826", "authors": ["Wei Sun", "Wen Yang", "Pu Jian", "Qianlong Du", "Fuwei Cui", "Shuo Ren", "Jiajun Zhang"], "title": "KTAE: A Model-Free Algorithm to Key-Tokens Advantage Estimation in Mathematical Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances have demonstrated that integrating reinforcement learning\nwith rule-based rewards can significantly enhance the reasoning capabilities of\nlarge language models, even without supervised fine-tuning. However, prevalent\nreinforcement learning algorithms such as GRPO and its variants like DAPO,\nsuffer from a coarse granularity issue when computing the advantage.\nSpecifically, they compute rollout-level advantages that assign identical\nvalues to every token within a sequence, failing to capture token-specific\ncontributions and hindering effective learning. To address this limitation, we\npropose Key-token Advantage Estimation (KTAE) - a novel algorithm that\nestimates fine-grained, token-level advantages without introducing additional\nmodels. KTAE leverages the correctness of sampled rollouts and applies\nstatistical analysis to quantify the importance of individual tokens within a\nsequence to the final outcome. This quantified token-level importance is then\ncombined with the rollout-level advantage to obtain a more fine-grained\ntoken-level advantage estimation. Empirical results show that models trained\nwith GRPO+KTAE and DAPO+KTAE outperform baseline methods across five\nmathematical reasoning benchmarks. Notably, they achieve higher accuracy with\nshorter responses and even surpass R1-Distill-Qwen-1.5B using the same base\nmodel.", "AI": {"tldr": "\u8fd1\u671f\u7814\u7a76\u8868\u660e\uff0c\u5c06\u5f3a\u5316\u5b66\u4e60\u4e0e\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u76f8\u7ed3\u5408\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5373\u4f7f\u4e0d\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff08\u5982GRPO\u548cDAPO\uff09\u5728\u8ba1\u7b97\u4f18\u52bf\u65f6\u5b58\u5728\u7c97\u7c92\u5ea6\u95ee\u9898\uff0c\u5373\u5b83\u4eec\u4e3a\u5e8f\u5217\u4e2d\u7684\u6bcf\u4e2a\u6807\u8bb0\u5206\u914d\u76f8\u540c\u7684\u503c\uff0c\u65e0\u6cd5\u6355\u6349\u6807\u8bb0\u7279\u5b9a\u7684\u8d21\u732e\uff0c\u963b\u788d\u4e86\u6709\u6548\u5b66\u4e60\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u5173\u952e\u6807\u8bb0\u4f18\u52bf\u4f30\u8ba1\uff08KTAE\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\uff0c\u53ef\u4ee5\u5728\u4e0d\u5f15\u5165\u989d\u5916\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u4f30\u8ba1\u7ec6\u7c92\u5ea6\u7684\u6807\u8bb0\u7ea7\u4f18\u52bf\u3002KTAE\u5229\u7528\u91c7\u6837rollouts\u7684\u6b63\u786e\u6027\uff0c\u5e76\u5e94\u7528\u7edf\u8ba1\u5206\u6790\u6765\u91cf\u5316\u5e8f\u5217\u4e2d\u5355\u4e2a\u6807\u8bb0\u5bf9\u6700\u7ec8\u7ed3\u679c\u7684\u91cd\u8981\u6027\u3002\u8fd9\u79cd\u91cf\u5316\u7684\u6807\u8bb0\u7ea7\u91cd\u8981\u6027\u968f\u540e\u4e0erollout\u7ea7\u4f18\u52bf\u7ed3\u5408\uff0c\u4ee5\u83b7\u5f97\u66f4\u7ec6\u7c92\u5ea6\u7684\u6807\u8bb0\u7ea7\u4f18\u52bf\u4f30\u8ba1\u3002\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528GRPO+KTAE\u548cDAPO+KTAE\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u4e94\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5b83\u4eec\u4ee5\u8f83\u77ed\u7684\u56de\u7b54\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u751a\u81f3\u5728\u4f7f\u7528\u76f8\u540c\u57fa\u7840\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u8d85\u8fc7\u4e86R1-Distill-Qwen-1.5B\u3002", "motivation": "\u5c3d\u7ba1\u5f3a\u5316\u5b66\u4e60\u4e0e\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u76f8\u7ed3\u5408\u80fd\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u7b97\u6cd5\uff08\u5982GRPO\u548cDAPO\uff09\u5728\u8ba1\u7b97\u4f18\u52bf\u65f6\u5b58\u5728\u7c97\u7c92\u5ea6\u95ee\u9898\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u5b66\u4e60\u6548\u679c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aKey-token Advantage Estimation (KTAE)\u7684\u65b0\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u901a\u8fc7\u5229\u7528\u91c7\u6837rollouts\u7684\u6b63\u786e\u6027\u548c\u7edf\u8ba1\u5206\u6790\uff0c\u91cf\u5316\u5e8f\u5217\u4e2d\u5355\u4e2a\u6807\u8bb0\u5bf9\u6700\u7ec8\u7ed3\u679c\u7684\u91cd\u8981\u6027\uff0c\u7136\u540e\u5c06\u8fd9\u79cd\u6807\u8bb0\u7ea7\u91cd\u8981\u6027\u4e0erollout\u7ea7\u4f18\u52bf\u7ed3\u5408\uff0c\u4ee5\u83b7\u5f97\u66f4\u7ec6\u7c92\u5ea6\u7684\u6807\u8bb0\u7ea7\u4f18\u52bf\u4f30\u8ba1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528GRPO+KTAE\u548cDAPO+KTAE\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u4e94\u4e2a\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u8d85\u8d8a\u4e86\u57fa\u7ebf\u65b9\u6cd5\u3002\u8fd9\u4e9b\u6a21\u578b\u4e0d\u4ec5\u5728\u8f83\u77ed\u7684\u56de\u7b54\u4e2d\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u800c\u4e14\u5728\u4f7f\u7528\u76f8\u540c\u57fa\u7840\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u5176\u8868\u73b0\u751a\u81f3\u8d85\u8fc7\u4e86R1-Distill-Qwen-1.5B\u3002", "conclusion": "KTAE\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5730\u89e3\u51b3\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5728\u4f18\u52bf\u4f30\u8ba1\u4e2d\u7684\u7c97\u7c92\u5ea6\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u8fd9\u8868\u660e\uff0c\u7ec6\u7c92\u5ea6\u7684\u6807\u8bb0\u7ea7\u4f18\u52bf\u4f30\u8ba1\u5bf9\u4e8e\u6539\u8fdb\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2505.16353", "pdf": "https://arxiv.org/pdf/2505.16353", "abs": "https://arxiv.org/abs/2505.16353", "authors": ["C\u00e9line Comte", "Pascal Moyal"], "title": "Arrival Control in Quasi-Reversible Queueing Systems: Optimization and Reinforcement Learning", "categories": ["cs.LG", "math.OC", "math.PR"], "comment": null, "summary": "In this paper, we introduce a versatile scheme for optimizing the arrival\nrates of quasi-reversible queueing systems. We first propose an alternative\ndefinition of quasi-reversibility that encompasses reversibility and highlights\nthe importance of the definition of customer classes. In a second time, we\nintroduce balanced arrival control policies, which generalize the notion of\nbalanced arrival rates introduced in the context of Whittle networks, to the\nmuch broader class of quasi-reversible queueing systems. We prove that\nsupplementing a quasi-reversible queueing system with a balanced\narrival-control policy preserves the quasi-reversibility, and we specify the\nform of the stationary measures. We revisit two canonical examples of\nquasi-reversible queueing systems, Whittle networks and order-independent\nqueues. Lastly, we focus on the problem of admission control and leverage our\nresults in the frameworks of optimization and reinforcement learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u65b9\u6848\uff0c\u7528\u4e8e\u4f18\u5316\u51c6\u53ef\u9006\u6392\u961f\u7cfb\u7edf\u7684\u5230\u8fbe\u7387\u3002\u9996\u5148\u63d0\u51fa\u4e86\u51c6\u53ef\u9006\u6027\u7684\u66ff\u4ee3\u5b9a\u4e49\uff0c\u6db5\u76d6\u53ef\u9006\u6027\u5e76\u5f3a\u8c03\u5ba2\u6237\u7c7b\u522b\u5b9a\u4e49\u7684\u91cd\u8981\u6027\u3002\u63a5\u7740\u5f15\u5165\u4e86\u5e73\u8861\u5230\u8fbe\u63a7\u5236\u7b56\u7565\uff0c\u5c06Whittle\u7f51\u7edc\u4e2d\u7684\u5e73\u8861\u5230\u8fbe\u7387\u6982\u5ff5\u63a8\u5e7f\u5230\u66f4\u5e7f\u6cdb\u7684\u51c6\u53ef\u9006\u6392\u961f\u7cfb\u7edf\u3002\u8bc1\u660e\u4e86\u5728\u51c6\u53ef\u9006\u6392\u961f\u7cfb\u7edf\u4e2d\u8865\u5145\u5e73\u8861\u5230\u8fbe\u63a7\u5236\u7b56\u7565\u53ef\u4ee5\u4fdd\u6301\u51c6\u53ef\u9006\u6027\uff0c\u5e76\u6307\u5b9a\u4e86\u5e73\u7a33\u6d4b\u5ea6\u7684\u5f62\u5f0f\u3002\u91cd\u65b0\u5ba1\u89c6\u4e86\u4e24\u4e2a\u7ecf\u5178\u7684\u51c6\u53ef\u9006\u6392\u961f\u7cfb\u7edf\u4f8b\u5b50\uff1aWhittle\u7f51\u7edc\u548c\u987a\u5e8f\u65e0\u5173\u961f\u5217\u3002\u6700\u540e\uff0c\u96c6\u4e2d\u8ba8\u8bba\u4e86\u51c6\u5165\u63a7\u5236\u95ee\u9898\uff0c\u5e76\u5728\u4f18\u5316\u548c\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u4e2d\u5229\u7528\u4e86\u8fd9\u4e9b\u7ed3\u679c\u3002", "motivation": "\u5f53\u524d\u5bf9\u4e8e\u51c6\u53ef\u9006\u6392\u961f\u7cfb\u7edf\u7684\u4f18\u5316\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u5bf9\u5230\u8fbe\u7387\u7684\u6709\u6548\u63a7\u5236\u7b56\u7565\u3002\u4e3a\u4e86\u6539\u8fdb\u8fd9\u4e00\u72b6\u51b5\uff0c\u9700\u8981\u5f15\u5165\u65b0\u7684\u5b9a\u4e49\u548c\u63a7\u5236\u7b56\u7565\u6765\u6269\u5c55\u53ef\u5e94\u7528\u7684\u7cfb\u7edf\u8303\u56f4\uff0c\u5e76\u786e\u4fdd\u7cfb\u7edf\u6027\u80fd\u3002", "method": "1. \u63d0\u51fa\u51c6\u53ef\u9006\u6027\u7684\u65b0\u5b9a\u4e49\uff0c\u5305\u542b\u53ef\u9006\u6027\u5e76\u5f3a\u8c03\u5ba2\u6237\u7c7b\u522b\u7684\u91cd\u8981\u6027\u3002\n2. \u5f15\u5165\u5e73\u8861\u5230\u8fbe\u63a7\u5236\u7b56\u7565\uff0c\u63a8\u5e7f\u5e73\u8861\u5230\u8fbe\u7387\u7684\u6982\u5ff5\u5230\u66f4\u5e7f\u6cdb\u7684\u51c6\u53ef\u9006\u6392\u961f\u7cfb\u7edf\u3002\n3. \u8bc1\u660e\u5e73\u8861\u5230\u8fbe\u63a7\u5236\u7b56\u7565\u80fd\u4fdd\u6301\u7cfb\u7edf\u7684\u51c6\u53ef\u9006\u6027\u3002\n4. \u6307\u5b9a\u5e73\u7a33\u6d4b\u5ea6\u7684\u5f62\u5f0f\u3002\n5. \u5728\u51c6\u5165\u63a7\u5236\u95ee\u9898\u4e0a\u7ed3\u5408\u4f18\u5316\u548c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u7814\u7a76\u3002", "result": "\u901a\u8fc7\u5f15\u5165\u5e73\u8861\u5230\u8fbe\u63a7\u5236\u7b56\u7565\uff0c\u6210\u529f\u5730\u4fdd\u6301\u4e86\u51c6\u53ef\u9006\u6392\u961f\u7cfb\u7edf\u7684\u51c6\u53ef\u9006\u6027\uff0c\u5e76\u660e\u786e\u4e86\u5e73\u7a33\u6d4b\u5ea6\u7684\u5f62\u5f0f\u3002\u6b64\u5916\uff0c\u5728\u51c6\u5165\u63a7\u5236\u95ee\u9898\u7684\u7814\u7a76\u4e2d\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u4f18\u5316\u548c\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u5e73\u8861\u5230\u8fbe\u63a7\u5236\u7b56\u7565\u4e3a\u4f18\u5316\u51c6\u53ef\u9006\u6392\u961f\u7cfb\u7edf\u7684\u5230\u8fbe\u7387\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u624b\u6bb5\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u66f4\u5e7f\u6cdb\u7684\u7cfb\u7edf\u4e2d\u5e94\u7528\u3002\u540c\u65f6\uff0c\u8be5\u7b56\u7565\u4e0e\u4f18\u5316\u53ca\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u7ed3\u5408\u4e3a\u89e3\u51b3\u590d\u6742\u7684\u51c6\u5165\u63a7\u5236\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2505.16827", "pdf": "https://arxiv.org/pdf/2505.16827", "abs": "https://arxiv.org/abs/2505.16827", "authors": ["Bin Xie", "Rui Shao", "Gongwei Chen", "Kaiwen Zhou", "Yinchuan Li", "Jie Liu", "Min Zhang", "Liqiang Nie"], "title": "GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent", "categories": ["cs.AI"], "comment": "ACL 2025. Github: https://github.com/JiuTian-VL/GUI-explorer", "summary": "GUI automation faces critical challenges in dynamic environments. MLLMs\nsuffer from two key issues: misinterpreting UI components and outdated\nknowledge. Traditional fine-tuning methods are costly for app-specific\nknowledge updates. We propose GUI-explorer, a training-free GUI agent that\nincorporates two fundamental mechanisms: (1) Autonomous Exploration of\nFunction-aware Trajectory. To comprehensively cover all application\nfunctionalities, we design a Function-aware Task Goal Generator that\nautomatically constructs exploration goals by analyzing GUI structural\ninformation (e.g., screenshots and activity hierarchies). This enables\nsystematic exploration to collect diverse trajectories. (2) Unsupervised Mining\nof Transition-aware Knowledge. To establish precise screen-operation logic, we\ndevelop a Transition-aware Knowledge Extractor that extracts effective\nscreen-operation logic through unsupervised analysis the state transition of\nstructured interaction triples (observation, action, outcome). This eliminates\nthe need for human involvement in knowledge extraction. With a task success\nrate of 53.7% on SPA-Bench and 47.4% on AndroidWorld, GUI-explorer shows\nsignificant improvements over SOTA agents. It requires no parameter updates for\nnew apps. GUI-explorer is open-sourced and publicly available at\nhttps://github.com/JiuTian-VL/GUI-explorer.", "AI": {"tldr": "\u5728\u52a8\u6001\u73af\u5883\u4e2d\uff0cGUI\u81ea\u52a8\u5316\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u7684MLLMs\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a\u9519\u8bef\u89e3\u91caUI\u7ec4\u4ef6\u548c\u77e5\u8bc6\u8fc7\u65f6\u3002\u4f20\u7edf\u7684\u5fae\u8c03\u65b9\u6cd5\u5bf9\u4e8e\u7279\u5b9a\u5e94\u7528\u7684\u77e5\u8bc6\u66f4\u65b0\u6210\u672c\u8fc7\u9ad8\u3002\u672c\u6587\u63d0\u51fa\u4e86GUI-explorer\uff0c\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684GUI\u4ee3\u7406\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u673a\u5236\uff1a(1) \u81ea\u4e3b\u63a2\u7d22\u529f\u80fd\u611f\u77e5\u8f68\u8ff9\uff1b(2) \u65e0\u76d1\u7763\u6316\u6398\u8f6c\u6362\u611f\u77e5\u77e5\u8bc6\u3002\u901a\u8fc7\u8fd9\u4e9b\u673a\u5236\uff0cGUI-explorer\u5728SPA-Bench\u548cAndroidWorld\u4e0a\u7684\u4efb\u52a1\u6210\u529f\u7387\u5206\u522b\u8fbe\u523053.7%\u548c47.4%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5e76\u4e14\u5bf9\u65b0\u5e94\u7528\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u3002", "motivation": "\u5f53\u524d\u7684MLLMs\u5728GUI\u81ea\u52a8\u5316\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a\u5b83\u4eec\u5bb9\u6613\u8bef\u89e3UI\u7ec4\u4ef6\u5e76\u4e14\u77e5\u8bc6\u5bb9\u6613\u8fc7\u65f6\u3002\u6b64\u5916\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u66f4\u65b0\u7279\u5b9a\u5e94\u7528\u77e5\u8bc6\u65f6\u6210\u672c\u9ad8\u6602\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u514b\u670d\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "GUI-explorer\u91c7\u7528\u4e24\u79cd\u57fa\u672c\u673a\u5236\uff1a(1) \u81ea\u4e3b\u63a2\u7d22\u529f\u80fd\u611f\u77e5\u8f68\u8ff9\u2014\u2014\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u529f\u80fd\u611f\u77e5\u4efb\u52a1\u76ee\u6807\u751f\u6210\u5668\uff0c\u901a\u8fc7\u5206\u6790GUI\u7ed3\u6784\u4fe1\u606f\uff08\u5982\u622a\u56fe\u548c\u6d3b\u52a8\u5c42\u6b21\uff09\u81ea\u52a8\u6784\u5efa\u63a2\u7d22\u76ee\u6807\uff0c\u4ece\u800c\u5b9e\u73b0\u7cfb\u7edf\u5316\u63a2\u7d22\u4ee5\u6536\u96c6\u591a\u6837\u5316\u7684\u8f68\u8ff9\u3002(2) \u65e0\u76d1\u7763\u6316\u6398\u8f6c\u6362\u611f\u77e5\u77e5\u8bc6\u2014\u2014\u5f00\u53d1\u4e86\u4e00\u4e2a\u8f6c\u6362\u611f\u77e5\u77e5\u8bc6\u63d0\u53d6\u5668\uff0c\u901a\u8fc7\u65e0\u76d1\u7763\u5206\u6790\u7ed3\u6784\u5316\u4ea4\u4e92\u4e09\u5143\u7ec4\uff08\u89c2\u5bdf\u3001\u52a8\u4f5c\u3001\u7ed3\u679c\uff09\u7684\u72b6\u6001\u8f6c\u6362\uff0c\u63d0\u53d6\u6709\u6548\u7684\u5c4f\u5e55\u64cd\u4f5c\u903b\u8f91\uff0c\u4ece\u800c\u65e0\u9700\u4eba\u5de5\u53c2\u4e0e\u77e5\u8bc6\u63d0\u53d6\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728SPA-Bench\u6570\u636e\u96c6\u4e0a\u4efb\u52a1\u6210\u529f\u7387\u4e3a53.7%\uff0c\u5728AndroidWorld\u6570\u636e\u96c6\u4e0a\u4efb\u52a1\u6210\u529f\u7387\u4e3a47.4%\uff0c\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u6709\u663e\u8457\u63d0\u5347\u3002\u5e76\u4e14\uff0cGUI-explorer\u5728\u5904\u7406\u65b0\u5e94\u7528\u65f6\u65e0\u9700\u66f4\u65b0\u53c2\u6570\u3002", "conclusion": "GUI-explorer\u4f5c\u4e3a\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684GUI\u4ee3\u7406\uff0c\u901a\u8fc7\u81ea\u4e3b\u63a2\u7d22\u548c\u65e0\u76d1\u7763\u77e5\u8bc6\u6316\u6398\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u63d0\u5347\u4e86GUI\u81ea\u52a8\u5316\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u5f00\u6e90\u4f9b\u516c\u4f17\u4f7f\u7528\u3002"}}
{"id": "2505.16832", "pdf": "https://arxiv.org/pdf/2505.16832", "abs": "https://arxiv.org/abs/2505.16832", "authors": ["Haonian Ji", "Shi Qiu", "Siyang Xin", "Siwei Han", "Zhaorun Chen", "Hongyi Wang", "Dake Zhang", "Huaxiu Yao"], "title": "From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Pedagogical Visualization", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": "16 pages; 7 figures", "summary": "While foundation models (FMs), such as diffusion models and large\nvision-language models (LVLMs), have been widely applied in educational\ncontexts, their ability to generate pedagogically effective visual explanations\nremains limited. Most existing approaches focus primarily on textual reasoning,\noverlooking the critical role of structured and interpretable visualizations in\nsupporting conceptual understanding. To better assess the visual reasoning\ncapabilities of FMs in educational settings, we introduce EduVisBench, a\nmulti-domain, multi-level benchmark. EduVisBench features diverse STEM problem\nsets requiring visually grounded solutions, along with a fine-grained\nevaluation rubric informed by pedagogical theory. Our empirical analysis\nreveals that existing models frequently struggle with the inherent challenge of\ndecomposing complex reasoning and translating it into visual representations\naligned with human cognitive processes. To address these limitations, we\npropose EduVisAgent, a multi-agent collaborative framework that coordinates\nspecialized agents for instructional planning, reasoning decomposition,\nmetacognitive prompting, and visualization design. Experimental results show\nthat EduVisAgent substantially outperforms all baselines, achieving a 40.2%\nimprovement and delivering more educationally aligned visualizations.\nEduVisBench and EduVisAgent are available at\nhttps://github.com/aiming-lab/EduVisBench and\nhttps://github.com/aiming-lab/EduVisAgent.", "AI": {"tldr": "\u5728\u6559\u80b2\u9886\u57df\uff0c\u57fa\u7840\u6a21\u578b\u751f\u6210\u6709\u6548\u89c6\u89c9\u89e3\u91ca\u7684\u80fd\u529b\u6709\u9650\u3002\u8bba\u6587\u63d0\u51fa\u4e86EduVisBench\u57fa\u51c6\u548cEduVisAgent\u6846\u67b6\uff0c\u540e\u8005\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u7840\u6a21\u578b\u5728\u6559\u80b2\u573a\u666f\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u751f\u6210\u6559\u80b2\u4e0a\u6709\u6548\u7684\u89c6\u89c9\u89e3\u91ca\u7684\u80fd\u529b\u4ecd\u7136\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u7ed3\u5408\u7ed3\u6784\u5316\u548c\u53ef\u89e3\u91ca\u7684\u53ef\u89c6\u5316\u4ee5\u652f\u6301\u6982\u5ff5\u7406\u89e3\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "\u5f15\u5165\u4e86EduVisBench\u591a\u9886\u57df\u591a\u5c42\u6b21\u57fa\u51c6\u6765\u8bc4\u4f30\u6a21\u578b\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86EduVisAgent\u591a\u4ee3\u7406\u534f\u4f5c\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u534f\u8c03\u4e13\u95e8\u4ee3\u7406\u8fdb\u884c\u6559\u5b66\u89c4\u5212\u3001\u63a8\u7406\u5206\u89e3\u3001\u5143\u8ba4\u77e5\u63d0\u793a\u548c\u53ef\u89c6\u5316\u8bbe\u8ba1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cEduVisAgent\u5927\u5e45\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6027\u80fd\u63d0\u534740.2%\uff0c\u5e76\u63d0\u4f9b\u4e86\u66f4\u7b26\u5408\u6559\u80b2\u9700\u6c42\u7684\u53ef\u89c6\u5316\u3002", "conclusion": "EduVisAgent\u901a\u8fc7\u591a\u4ee3\u7406\u534f\u4f5c\u663e\u8457\u63d0\u9ad8\u4e86\u57fa\u7840\u6a21\u578b\u5728\u6559\u80b2\u573a\u666f\u4e2d\u7684\u89c6\u89c9\u63a8\u7406\u548c\u89e3\u91ca\u80fd\u529b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2505.16365", "pdf": "https://arxiv.org/pdf/2505.16365", "abs": "https://arxiv.org/abs/2505.16365", "authors": ["Manuel Ruiz-Botella", "Marta Sales-Pardo", "Roger Guimer\u00e0"], "title": "A collaborative constrained graph diffusion model for the generation of realistic synthetic molecules", "categories": ["cs.LG", "cs.AI", "physics.comp-ph", "q-bio.QM"], "comment": "28 pages, 10 figures, 4 tables", "summary": "Developing new molecular compounds is crucial to address pressing challenges,\nfrom health to environmental sustainability. However, exploring the molecular\nspace to discover new molecules is difficult due to the vastness of the space.\nHere we introduce CoCoGraph, a collaborative and constrained graph diffusion\nmodel capable of generating molecules that are guaranteed to be chemically\nvalid. Thanks to the constraints built into the model and to the collaborative\nmechanism, CoCoGraph outperforms state-of-the-art approaches on standard\nbenchmarks while requiring up to an order of magnitude fewer parameters.\nAnalysis of 36 chemical properties also demonstrates that CoCoGraph generates\nmolecules with distributions more closely matching real molecules than current\nmodels. Leveraging the model's efficiency, we created a database of 8.2M\nmillion synthetically generated molecules and conducted a Turing-like test with\norganic chemistry experts to further assess the plausibility of the generated\nmolecules, and potential biases and limitations of CoCoGraph.", "AI": {"tldr": "\u751f\u6210\u5316\u5b66\u4e0a\u6709\u6548\u7684\u5206\u5b50\u662f\u89e3\u51b3\u5065\u5eb7\u548c\u73af\u5883\u53ef\u6301\u7eed\u6027\u7b49\u7d27\u8feb\u6311\u6218\u7684\u5173\u952e\u3002\u7136\u800c\uff0c\u7531\u4e8e\u5206\u5b50\u7a7a\u95f4\u7684\u5e7f\u9614\uff0c\u63a2\u7d22\u4ee5\u53d1\u73b0\u65b0\u5206\u5b50\u662f\u4e00\u9879\u8270\u5de8\u7684\u4efb\u52a1\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aCoCoGraph\u7684\u65b0\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u534f\u4f5c\u548c\u7ea6\u675f\u56fe\u6269\u6563\u65b9\u6cd5\u751f\u6210\u5316\u5b66\u4e0a\u6709\u6548\u7684\u5206\u5b50\u3002CoCoGraph\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u540c\u65f6\u53c2\u6570\u6570\u91cf\u51cf\u5c11\u4e86\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002\u901a\u8fc7\u5bf936\u79cd\u5316\u5b66\u6027\u8d28\u7684\u5206\u6790\u8868\u660e\uff0cCoCoGraph\u751f\u6210\u7684\u5206\u5b50\u5206\u5e03\u4e0e\u771f\u5b9e\u5206\u5b50\u66f4\u63a5\u8fd1\u3002\u5229\u7528\u6a21\u578b\u7684\u9ad8\u6548\u6027\uff0c\u6211\u4eec\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b820\u4e07\u4e2a\u5408\u6210\u751f\u6210\u5206\u5b50\u7684\u6570\u636e\u5e93\uff0c\u5e76\u8fdb\u884c\u4e86\u7c7b\u4f3c\u56fe\u7075\u6d4b\u8bd5\u7684\u8bc4\u4f30\uff0c\u4ee5\u8fdb\u4e00\u6b65\u8bc4\u4f30\u751f\u6210\u5206\u5b50\u7684\u5408\u7406\u6027\u53caCoCoGraph\u7684\u6f5c\u5728\u504f\u5dee\u548c\u5c40\u9650\u6027\u3002", "motivation": "\u5f00\u53d1\u65b0\u7684\u5206\u5b50\u5316\u5408\u7269\u5bf9\u4e8e\u5e94\u5bf9\u4ece\u5065\u5eb7\u5230\u73af\u5883\u53ef\u6301\u7eed\u6027\u7684\u7d27\u8feb\u6311\u6218\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u7531\u4e8e\u5206\u5b50\u7a7a\u95f4\u7684\u5e9e\u5927\uff0c\u63a2\u7d22\u5e76\u53d1\u73b0\u65b0\u5206\u5b50\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCoCoGraph\u7684\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u662f\u4e00\u79cd\u534f\u4f5c\u548c\u7ea6\u675f\u56fe\u6269\u6563\u6a21\u578b\uff0c\u80fd\u591f\u751f\u6210\u5316\u5b66\u4e0a\u6709\u6548\u7684\u5206\u5b50\u3002\u6a21\u578b\u4e2d\u5185\u7f6e\u7684\u7ea6\u675f\u548c\u534f\u4f5c\u673a\u5236\u4f7f\u5176\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u53c2\u6570\u6570\u91cf\u663e\u8457\u51cf\u5c11\u3002", "result": "CoCoGraph\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u53c2\u6570\u6570\u91cf\u51cf\u5c11\u4e86\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002\u5bf936\u79cd\u5316\u5b66\u6027\u8d28\u7684\u5206\u6790\u8868\u660e\uff0cCoCoGraph\u751f\u6210\u7684\u5206\u5b50\u5206\u5e03\u4e0e\u771f\u5b9e\u5206\u5b50\u66f4\u4e3a\u63a5\u8fd1\u3002", "conclusion": "CoCoGraph\u6a21\u578b\u4e0d\u4ec5\u5728\u6027\u80fd\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u800c\u4e14\u751f\u6210\u7684\u5206\u5b50\u5177\u6709\u66f4\u9ad8\u7684\u5408\u7406\u6027\u3002\u901a\u8fc7\u5bf9\u751f\u6210\u5206\u5b50\u7684\u56fe\u7075\u6d4b\u8bd5\u8bc4\u4f30\uff0c\u8fdb\u4e00\u6b65\u63ed\u793a\u4e86\u6a21\u578b\u7684\u6f5c\u5728\u504f\u5dee\u548c\u5c40\u9650\u6027\u3002"}}
{"id": "2505.16854", "pdf": "https://arxiv.org/pdf/2505.16854", "abs": "https://arxiv.org/abs/2505.16854", "authors": ["Jiaqi Wang", "Kevin Qinghong Lin", "James Cheng", "Mike Zheng Shou"], "title": "Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models", "categories": ["cs.AI", "cs.CV"], "comment": null, "summary": "Reinforcement Learning (RL) has proven to be an effective post-training\nstrategy for enhancing reasoning in vision-language models (VLMs). Group\nRelative Policy Optimization (GRPO) is a recent prominent method that\nencourages models to generate complete reasoning traces before answering,\nleading to increased token usage and computational cost. Inspired by the\nhuman-like thinking process-where people skip reasoning for easy questions but\nthink carefully when needed-we explore how to enable VLMs to first decide when\nreasoning is necessary. To realize this, we propose TON, a two-stage training\nstrategy: (i) a supervised fine-tuning (SFT) stage with a simple yet effective\n'thought dropout' operation, where reasoning traces are randomly replaced with\nempty thoughts. This introduces a think-or-not format that serves as a cold\nstart for selective reasoning; (ii) a GRPO stage that enables the model to\nfreely explore when to think or not, while maximizing task-aware outcome\nrewards. Experimental results show that TON can reduce the completion length by\nup to 90% compared to vanilla GRPO, without sacrificing performance or even\nimproving it. Further evaluations across diverse vision-language tasks-covering\na range of reasoning difficulties under both 3B and 7B models-consistently\nreveal that the model progressively learns to bypass unnecessary reasoning\nsteps as training advances. These findings shed light on the path toward\nhuman-like reasoning patterns in reinforcement learning approaches. Our code is\navailable at https://github.com/kokolerk/TON.", "AI": {"tldr": "TON\u662f\u4e00\u79cd\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u901a\u8fc7'thought dropout'\u64cd\u4f5c\u548cGRPO\u9636\u6bb5\u4f7f\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u9009\u62e9\u6027\u5730\u8fdb\u884c\u63a8\u7406\uff0c\u4ece\u800c\u51cf\u5c11\u5b8c\u6210\u957f\u5ea6\u5e76\u4fdd\u6301\u6027\u80fd\u3002", "motivation": "\u53d7\u5230\u4eba\u7c7b\u601d\u7ef4\u8fc7\u7a0b\u7684\u542f\u53d1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8ba9\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u9996\u5148\u51b3\u5b9a\u4f55\u65f6\u9700\u8981\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u4ee5\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u63a8\u7406\u6b65\u9aa4\u3002", "method": "\u63d0\u51faTON\uff0c\u4e00\u79cd\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a(i) SFT\u9636\u6bb5\u4f7f\u7528'thought dropout'\u64cd\u4f5c\u5f15\u5165\u601d\u8003\u6216\u4e0d\u601d\u8003\u683c\u5f0f\uff1b(ii) GRPO\u9636\u6bb5\u5141\u8bb8\u6a21\u578b\u63a2\u7d22\u4f55\u65f6\u601d\u8003\u6216\u4e0d\u601d\u8003\uff0c\u5e76\u6700\u5927\u5316\u4efb\u52a1\u611f\u77e5\u7ed3\u679c\u5956\u52b1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTON\u53ef\u5c06\u5b8c\u6210\u957f\u5ea6\u51cf\u5c11\u9ad8\u8fbe90%\uff0c\u540c\u65f6\u4e0d\u727a\u7272\u6027\u80fd\u751a\u81f3\u63d0\u5347\u6027\u80fd\u3002\u5728\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u548c\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u9010\u6e10\u5b66\u4f1a\u8df3\u8fc7\u4e0d\u5fc5\u8981\u7684\u63a8\u7406\u6b65\u9aa4\u3002", "conclusion": "TON\u4e3a\u5b9e\u73b0\u7c7b\u4eba\u63a8\u7406\u6a21\u5f0f\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\uff0c\u7279\u522b\u662f\u5728\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e2d\u3002"}}
{"id": "2505.16368", "pdf": "https://arxiv.org/pdf/2505.16368", "abs": "https://arxiv.org/abs/2505.16368", "authors": ["Huanyu Liu", "Jia Li", "Hao Zhu", "Kechi Zhang", "Yihong Dong", "Ge Li"], "title": "SATURN: SAT-based Reinforcement Learning to Unleash Language Model Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "How to design reinforcement learning (RL) tasks that effectively unleash the\nreasoning capability of large language models (LLMs) remains an open question.\nExisting RL tasks (e.g., math, programming, and constructing reasoning tasks)\nsuffer from three key limitations: (1) Scalability. They rely heavily on human\nannotation or expensive LLM synthesis to generate sufficient training data. (2)\nVerifiability. LLMs' outputs are hard to verify automatically and reliably. (3)\nControllable Difficulty. Most tasks lack fine-grained difficulty control,\nmaking it hard to train LLMs to develop reasoning ability from easy to hard.\n  To address these limitations, we propose Saturn, a SAT-based RL framework\nthat uses Boolean Satisfiability (SAT) problems to train and evaluate LLM\nreasoning. Saturn enables scalable task construction, rule-based verification,\nand precise difficulty control. Saturn designs a curriculum learning pipeline\nthat continuously improves LLMs' reasoning capability by constructing SAT tasks\nof increasing difficulty and training LLMs from easy to hard. To ensure stable\ntraining, we design a principled mechanism to control difficulty transitions.\n  We introduce Saturn-2.6k, a dataset of 2,660 SAT problems with varying\ndifficulty. It supports the evaluation of how LLM reasoning changes with\nproblem difficulty. We apply Saturn to DeepSeek-R1-Distill-Qwen and obtain\nSaturn-1.5B and Saturn-7B. We achieve several notable results: (1) On SAT\nproblems, Saturn-1.5B and Saturn-7B achieve average pass@3 improvements of\n+14.0 and +28.1, respectively. (2) On math and programming tasks, Saturn-1.5B\nand Saturn-7B improve average scores by +4.9 and +1.8 on benchmarks (e.g.,\nAIME, LiveCodeBench). (3) Compared to the state-of-the-art (SOTA) approach in\nconstructing RL tasks, Saturn achieves further improvements of +8.8%. We\nrelease the source code, data, and models to support future research.", "AI": {"tldr": "\u8bbe\u8ba1\u80fd\u6709\u6548\u6fc0\u53d1\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002\u73b0\u6709\u7684RL\u4efb\u52a1\u5b58\u5728\u53ef\u6269\u5c55\u6027\u3001\u53ef\u9a8c\u8bc1\u6027\u548c\u96be\u5ea6\u63a7\u5236\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u57fa\u4e8eSAT\u95ee\u9898\u7684RL\u6846\u67b6Saturn\uff0c\u5b83\u5177\u6709\u53ef\u6269\u5c55\u7684\u4efb\u52a1\u6784\u5efa\u3001\u57fa\u4e8e\u89c4\u5219\u7684\u9a8c\u8bc1\u548c\u7cbe\u786e\u7684\u96be\u5ea6\u63a7\u5236\u529f\u80fd\u3002Saturn\u901a\u8fc7\u8bbe\u8ba1\u8bfe\u7a0b\u5b66\u4e60\u7ba1\u9053\uff0c\u9010\u6b65\u63d0\u9ad8LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u539f\u5219\u6027\u7684\u673a\u5236\u6765\u63a7\u5236\u96be\u5ea6\u8fc7\u6e21\u3002\u6211\u4eec\u521b\u5efa\u4e86\u5305\u542b2660\u4e2aSAT\u95ee\u9898\u7684\u6570\u636e\u96c6Saturn-2.6k\uff0c\u652f\u6301\u8bc4\u4f30LLM\u63a8\u7406\u968f\u95ee\u9898\u96be\u5ea6\u7684\u53d8\u5316\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728SAT\u95ee\u9898\u4e0a\uff0cSaturn-1.5B\u548cSaturn-7B\u5206\u522b\u63d0\u9ad8\u4e8614.0\u548c28.1\u7684\u5e73\u5747pass@3\u5206\u6570\uff1b\u5728\u6570\u5b66\u548c\u7f16\u7a0b\u4efb\u52a1\u4e0a\u4e5f\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002\u4e0e\u73b0\u6709SOTA\u65b9\u6cd5\u76f8\u6bd4\uff0cSaturn\u8fdb\u4e00\u6b65\u63d0\u5347\u4e868.8%\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u65e0\u6cd5\u6709\u6548\u6fc0\u53d1\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u6570\u636e\u751f\u6210\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6216\u6602\u8d35\u7684LLM\u5408\u6210\u3001\u8f93\u51fa\u96be\u4ee5\u81ea\u52a8\u53ef\u9760\u9a8c\u8bc1\u4ee5\u53ca\u4efb\u52a1\u7f3a\u4e4f\u7cbe\u7ec6\u7684\u96be\u5ea6\u63a7\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e03\u5c14\u53ef\u6ee1\u8db3\u6027\uff08SAT\uff09\u95ee\u9898\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6Saturn\u3002\u8be5\u6846\u67b6\u5305\u62ec\uff1a1) \u53ef\u6269\u5c55\u7684\u4efb\u52a1\u6784\u5efa\uff0c\u5229\u7528SAT\u95ee\u9898\u751f\u6210\u5927\u91cf\u8bad\u7ec3\u6570\u636e\uff1b2) \u57fa\u4e8e\u89c4\u5219\u7684\u9a8c\u8bc1\u673a\u5236\uff0c\u786e\u4fdd\u8f93\u51fa\u7684\u53ef\u9760\u6027\uff1b3) \u7cbe\u786e\u7684\u96be\u5ea6\u63a7\u5236\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bbe\u8ba1\u8bfe\u7a0b\u5b66\u4e60\u7ba1\u9053\uff0c\u4ece\u7b80\u5355\u5230\u590d\u6742\u9010\u6b65\u8bad\u7ec3LLM\u3002\u6b64\u5916\uff0c\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7a33\u5b9a\u8bad\u7ec3\u7684\u673a\u5236\u6765\u63a7\u5236\u96be\u5ea6\u8fc7\u6e21\u3002", "result": "1) \u5728SAT\u95ee\u9898\u4e0a\uff0cSaturn-1.5B\u548cSaturn-7B\u5206\u522b\u5b9e\u73b0\u4e86+14.0\u548c+28.1\u7684\u5e73\u5747pass@3\u6539\u8fdb\uff1b2) \u5728\u6570\u5b66\u548c\u7f16\u7a0b\u4efb\u52a1\u4e2d\uff0cSaturn-1.5B\u548cSaturn-7B\u5206\u522b\u63d0\u9ad8\u4e86+4.9\u548c+1.8\u7684\u5e73\u5747\u5206\uff1b3) \u4e0e\u73b0\u6709SOTA\u65b9\u6cd5\u76f8\u6bd4\uff0cSaturn\u5728\u6784\u5efaRL\u4efb\u52a1\u65b9\u9762\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86+8.8%\u3002", "conclusion": "Saturn\u6846\u67b6\u901a\u8fc7\u89e3\u51b3\u73b0\u6709RL\u4efb\u52a1\u4e2d\u7684\u5173\u952e\u9650\u5236\uff0c\u6210\u529f\u63d0\u9ad8\u4e86LLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4e14\u5728SAT\u95ee\u9898\u3001\u6570\u5b66\u548c\u7f16\u7a0b\u4efb\u52a1\u4e0a\u90fd\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002\u8fd9\u4e9b\u6210\u679c\u8bc1\u660e\u4e86Saturn\u7684\u6709\u6548\u6027\u548c\u6f5c\u529b\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2505.16877", "pdf": "https://arxiv.org/pdf/2505.16877", "abs": "https://arxiv.org/abs/2505.16877", "authors": ["Yuqicheng Zhu", "Daniel Hern\u00e1ndez", "Yuan He", "Zifeng Ding", "Bo Xiong", "Evgeny Kharlamov", "Steffen Staab"], "title": "Predicate-Conditional Conformalized Answer Sets for Knowledge Graph Embeddings", "categories": ["cs.AI"], "comment": "Accepted to the Finding of ACL 2025", "summary": "Uncertainty quantification in Knowledge Graph Embedding (KGE) methods is\ncrucial for ensuring the reliability of downstream applications. A recent work\napplies conformal prediction to KGE methods, providing uncertainty estimates by\ngenerating a set of answers that is guaranteed to include the true answer with\na predefined confidence level. However, existing methods provide probabilistic\nguarantees averaged over a reference set of queries and answers (marginal\ncoverage guarantee). In high-stakes applications such as medical diagnosis, a\nstronger guarantee is often required: the predicted sets must provide\nconsistent coverage per query (conditional coverage guarantee). We propose\nCondKGCP, a novel method that approximates predicate-conditional coverage\nguarantees while maintaining compact prediction sets. CondKGCP merges\npredicates with similar vector representations and augments calibration with\nrank information. We prove the theoretical guarantees and demonstrate empirical\neffectiveness of CondKGCP by comprehensive evaluations.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCondKGCP\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5408\u5e76\u5177\u6709\u76f8\u4f3c\u5411\u91cf\u8868\u793a\u7684\u8c13\u8bcd\u5e76\u589e\u5f3a\u6821\u51c6\u8fc7\u7a0b\u4ee5\u5305\u542b\u6392\u540d\u4fe1\u606f\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u7d27\u51d1\u9884\u6d4b\u96c6\u7684\u540c\u65f6\u8fd1\u4f3c\u8c13\u8bcd\u6761\u4ef6\u8986\u76d6\u4fdd\u8bc1\u3002\u8fd9\u79cd\u65b9\u6cd5\u9002\u7528\u4e8e\u9700\u8981\u9ad8\u53ef\u9760\u6027\u7684\u5e94\u7528\uff08\u5982\u533b\u7597\u8bca\u65ad\uff09\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8bc1\u4e24\u65b9\u9762\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\uff08KGE\uff09\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u4ec5\u63d0\u4f9b\u57fa\u4e8e\u67e5\u8be2\u548c\u7b54\u6848\u53c2\u8003\u96c6\u5408\u7684\u5e73\u5747\u6982\u7387\u4fdd\u8bc1\uff08\u8fb9\u9645\u8986\u76d6\u4fdd\u8bc1\uff09\u3002\u7136\u800c\uff0c\u5728\u8bf8\u5982\u533b\u7597\u8bca\u65ad\u7b49\u9ad8\u98ce\u9669\u5e94\u7528\u4e2d\uff0c\u901a\u5e38\u9700\u8981\u66f4\u5f3a\u7684\u4fdd\u8bc1\uff1a\u5373\u9488\u5bf9\u6bcf\u4e2a\u67e5\u8be2\u63d0\u4f9b\u4e00\u81f4\u7684\u8986\u76d6\u7387\uff08\u6761\u4ef6\u8986\u76d6\u4fdd\u8bc1\uff09\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86CondKGCP\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u4ee5\u4e0b\u6b65\u9aa4\u5b9e\u73b0\u6761\u4ef6\u8986\u76d6\u4fdd\u8bc1\uff1a1) \u5408\u5e76\u5177\u6709\u76f8\u4f3c\u5411\u91cf\u8868\u793a\u7684\u8c13\u8bcd\uff1b2) \u5728\u6821\u51c6\u8fc7\u7a0b\u4e2d\u52a0\u5165\u6392\u540d\u4fe1\u606f\u3002\u8fd9\u4e9b\u6280\u672f\u5e2e\u52a9\u751f\u6210\u66f4\u7cbe\u786e\u4e14\u7d27\u51d1\u7684\u9884\u6d4b\u96c6\u3002", "result": "\u4f5c\u8005\u901a\u8fc7\u7efc\u5408\u8bc4\u4f30\u8bc1\u660e\u4e86CondKGCP\u65b9\u6cd5\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u6301\u9884\u6d4b\u96c6\u7d27\u51d1\u6027\u7684\u540c\u65f6\u63d0\u4f9b\u63a5\u8fd1\u8c13\u8bcd\u6761\u4ef6\u8986\u76d6\u4fdd\u8bc1\u7684\u6027\u80fd\u3002", "conclusion": "CondKGCP\u662f\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u4e3a\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u63d0\u4f9b\u66f4\u5f3a\u7684\u6761\u4ef6\u8986\u76d6\u4fdd\u8bc1\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u96c6\u7684\u7d27\u51d1\u6027\u3002\u8fd9\u4f7f\u5f97\u5b83\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u573a\u666f\u4e2d\u5177\u6709\u8f83\u5927\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.16386", "pdf": "https://arxiv.org/pdf/2505.16386", "abs": "https://arxiv.org/abs/2505.16386", "authors": ["Ahmed K. Kadhim", "Lei Jiao", "Rishad Shafik", "Ole-Christoffer Granmo"], "title": "Omni TM-AE: A Scalable and Interpretable Embedding Model Using the Full Tsetlin Machine State Space", "categories": ["cs.LG"], "comment": null, "summary": "The increasing complexity of large-scale language models has amplified\nconcerns regarding their interpretability and reusability. While traditional\nembedding models like Word2Vec and GloVe offer scalability, they lack\ntransparency and often behave as black boxes. Conversely, interpretable models\nsuch as the Tsetlin Machine (TM) have shown promise in constructing explainable\nlearning systems, though they previously faced limitations in scalability and\nreusability. In this paper, we introduce Omni Tsetlin Machine AutoEncoder (Omni\nTM-AE), a novel embedding model that fully exploits the information contained\nin the TM's state matrix, including literals previously excluded from clause\nformation. This method enables the construction of reusable, interpretable\nembeddings through a single training phase. Extensive experiments across\nsemantic similarity, sentiment classification, and document clustering tasks\nshow that Omni TM-AE performs competitively with and often surpasses mainstream\nembedding models. These results demonstrate that it is possible to balance\nperformance, scalability, and interpretability in modern Natural Language\nProcessing (NLP) systems without resorting to opaque architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5d4c\u5165\u6a21\u578bOmni Tsetlin Machine AutoEncoder\uff08Omni TM-AE\uff09\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u5355\u4e00\u8bad\u7ec3\u9636\u6bb5\u6784\u5efa\u53ef\u91cd\u7528\u548c\u53ef\u89e3\u91ca\u7684\u5d4c\u5165\uff0c\u540c\u65f6\u5728\u8bed\u4e49\u76f8\u4f3c\u6027\u3001\u60c5\u611f\u5206\u7c7b\u548c\u6587\u6863\u805a\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u590d\u6742\u6027\u589e\u52a0\u5f15\u53d1\u4e86\u5bf9\u5176\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u91cd\u7528\u6027\u7684\u62c5\u5fe7\u3002\u4f20\u7edf\u7684\u5d4c\u5165\u6a21\u578b\u5982Word2Vec\u548cGloVe\u867d\u7136\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u7f3a\u4e4f\u900f\u660e\u5ea6\uff1b\u800c\u53ef\u89e3\u91ca\u6a21\u578b\u5982Tsetlin Machine\u5219\u5728\u53ef\u6269\u5c55\u6027\u548c\u53ef\u91cd\u7528\u6027\u65b9\u9762\u5b58\u5728\u9650\u5236\u3002", "method": "\u5f15\u5165\u4e86Omni Tsetlin Machine AutoEncoder\uff08Omni TM-AE\uff09\uff0c\u4e00\u79cd\u65b0\u578b\u5d4c\u5165\u6a21\u578b\uff0c\u5145\u5206\u5229\u7528Tsetlin Machine\u72b6\u6001\u77e9\u9635\u4e2d\u7684\u4fe1\u606f\uff08\u5305\u62ec\u4e4b\u524d\u672a\u7528\u4e8e\u5b50\u53e5\u5f62\u6210\u7684\u5b57\u9762\u91cf\uff09\uff0c\u4ece\u800c\u5b9e\u73b0\u5355\u4e00\u8bad\u7ec3\u9636\u6bb5\u5185\u6784\u5efa\u53ef\u91cd\u7528\u4e14\u53ef\u89e3\u91ca\u7684\u5d4c\u5165\u3002", "result": "\u5728\u8bed\u4e49\u76f8\u4f3c\u6027\u3001\u60c5\u611f\u5206\u7c7b\u548c\u6587\u6863\u805a\u7c7b\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cOmni TM-AE\u7684\u8868\u73b0\u4e0e\u4e3b\u6d41\u5d4c\u5165\u6a21\u578b\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u3002", "conclusion": "\u53ef\u4ee5\u5728\u73b0\u4ee3\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7cfb\u7edf\u4e2d\u5e73\u8861\u6027\u80fd\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u800c\u65e0\u9700\u4f9d\u8d56\u4e0d\u900f\u660e\u7684\u67b6\u6784\u3002"}}
{"id": "2505.16899", "pdf": "https://arxiv.org/pdf/2505.16899", "abs": "https://arxiv.org/abs/2505.16899", "authors": ["Kerem Oktar", "Katherine M. Collins", "Jose Hernandez-Orallo", "Diane Coyle", "Stephen Cave", "Adrian Weller", "Ilia Sucholutsky"], "title": "Identifying, Evaluating, and Mitigating Risks of AI Thought Partnerships", "categories": ["cs.AI"], "comment": null, "summary": "Artificial Intelligence (AI) systems have historically been used as tools\nthat execute narrowly defined tasks. Yet recent advances in AI have unlocked\npossibilities for a new class of models that genuinely collaborate with humans\nin complex reasoning, from conceptualizing problems to brainstorming solutions.\nSuch AI thought partners enable novel forms of collaboration and extended\ncognition, yet they also pose major risks-including and beyond risks of typical\nAI tools and agents. In this commentary, we systematically identify risks of AI\nthought partners through a novel framework that identifies risks at multiple\nlevels of analysis, including Real-time, Individual, and Societal risks arising\nfrom collaborative cognition (RISc). We leverage this framework to propose\nconcrete metrics for risk evaluation, and finally suggest specific mitigation\nstrategies for developers and policymakers. As AI thought partners continue to\nproliferate, these strategies can help prevent major harms and ensure that\nhumans actively benefit from productive thought partnerships.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86AI\u4f5c\u4e3a\u4eba\u7c7b\u601d\u7ef4\u4f19\u4f34\u5728\u590d\u6742\u63a8\u7406\u4e2d\u7684\u65b0\u578b\u5408\u4f5c\u65b9\u5f0f\uff0c\u63d0\u51fa\u4e86\u8bc4\u4f30\u548c\u7f13\u89e3\u5176\u591a\u5c42\u9762\u98ce\u9669\u7684\u6846\u67b6\u4e0e\u7b56\u7565\u3002", "motivation": "\u968f\u7740AI\u6280\u672f\u7684\u8fdb\u6b65\uff0cAI\u4e0d\u518d\u5c40\u9650\u4e8e\u6267\u884c\u72ed\u4e49\u4efb\u52a1\uff0c\u800c\u662f\u80fd\u591f\u4e0e\u4eba\u7c7b\u5728\u590d\u6742\u63a8\u7406\u4e2d\u8fdb\u884c\u771f\u6b63\u610f\u4e49\u4e0a\u7684\u534f\u4f5c\uff0c\u4ece\u95ee\u9898\u6982\u5ff5\u5316\u5230\u89e3\u51b3\u65b9\u6848\u5934\u8111\u98ce\u66b4\u3002\u8fd9\u79cd\u65b0\u578b\u5408\u4f5c\u5f62\u5f0f\u5e26\u6765\u4e86\u65b0\u7684\u8ba4\u77e5\u6269\u5c55\u53ef\u80fd\u6027\uff0c\u4f46\u4e5f\u4f34\u968f\u7740\u91cd\u5927\u98ce\u9669\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u63d0\u51fa\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff08RISc\uff09\uff0c\u7cfb\u7edf\u5730\u8bc6\u522bAI\u601d\u7ef4\u4f19\u4f34\u5728\u5b9e\u65f6\u3001\u4e2a\u4f53\u548c\u793e\u4f1a\u5c42\u9762\u7684\u98ce\u9669\uff0c\u5e76\u57fa\u4e8e\u6b64\u6846\u67b6\u63d0\u51fa\u5177\u4f53\u7684\u8bc4\u4f30\u6307\u6807\u548c\u7f13\u89e3\u7b56\u7565\u3002", "result": "\u8be5\u6846\u67b6\u6210\u529f\u8bc6\u522b\u4e86AI\u601d\u7ef4\u4f19\u4f34\u5728\u4e0d\u540c\u5c42\u9762\u4e0a\u53ef\u80fd\u5e26\u6765\u7684\u98ce\u9669\uff0c\u5e76\u4e3a\u5f00\u53d1\u8005\u548c\u653f\u7b56\u5236\u5b9a\u8005\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u98ce\u9669\u7f13\u89e3\u7b56\u7565\u3002", "conclusion": "\u968f\u7740AI\u601d\u7ef4\u4f19\u4f34\u7684\u4e0d\u65ad\u666e\u53ca\uff0c\u8bba\u6587\u63d0\u51fa\u7684\u7b56\u7565\u6709\u52a9\u4e8e\u9632\u6b62\u91cd\u5927\u5371\u5bb3\u7684\u53d1\u751f\uff0c\u5e76\u786e\u4fdd\u4eba\u7c7b\u80fd\u4ece\u8fd9\u79cd\u9ad8\u6548\u7684\u601d\u7ef4\u5408\u4f5c\u5173\u7cfb\u4e2d\u83b7\u76ca\u3002"}}
{"id": "2505.16400", "pdf": "https://arxiv.org/pdf/2505.16400", "abs": "https://arxiv.org/abs/2505.16400", "authors": ["Yang Chen", "Zhuolin Yang", "Zihan Liu", "Chankyu Lee", "Peng Xu", "Mohammad Shoeybi", "Bryan Catanzaro", "Wei Ping"], "title": "AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "We release the model at:\n  https://huggingface.co/nvidia/AceReason-Nemotron-14B", "summary": "Despite recent progress in large-scale reinforcement learning (RL) for\nreasoning, the training recipe for building high-performing reasoning models\nremains elusive. Key implementation details of frontier models, such as\nDeepSeek-R1, including data curation strategies and RL training recipe, are\noften omitted. Moreover, recent research indicates distillation remains more\neffective than RL for smaller models. In this work, we demonstrate that\nlarge-scale RL can significantly enhance the reasoning capabilities of strong,\nsmall- and mid-sized models, achieving results that surpass those of\nstate-of-the-art distillation-based models. We systematically study the RL\ntraining process through extensive ablations and propose a simple yet effective\napproach: first training on math-only prompts, then on code-only prompts.\nNotably, we find that math-only RL not only significantly enhances the\nperformance of strong distilled models on math benchmarks (e.g., +14.6% /\n+17.2% on AIME 2025 for the 7B / 14B models), but also code reasoning tasks\n(e.g., +6.8% / +5.8% on LiveCodeBench for the 7B / 14B models). In addition,\nextended code-only RL iterations further improve performance on code benchmarks\nwith minimal or no degradation in math results. We develop a robust data\ncuration pipeline to collect challenging prompts with high-quality, verifiable\nanswers and test cases to enable verification-based RL across both domains.\nFinally, we identify key experimental insights, including curriculum learning\nwith progressively increasing response lengths and the stabilizing effect of\non-policy parameter updates. We find that RL not only elicits the foundational\nreasoning capabilities acquired during pretraining and supervised fine-tuning\n(e.g., distillation), but also pushes the limits of the model's reasoning\nability, enabling it to solve problems that were previously unsolvable.", "AI": {"tldr": "\u5c3d\u7ba1\u5728\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u6784\u5efa\u9ad8\u6027\u80fd\u63a8\u7406\u6a21\u578b\u7684\u8bad\u7ec3\u65b9\u6cd5\u4ecd\u7136\u96be\u4ee5\u6349\u6478\u3002\u672c\u7814\u7a76\u5c55\u793a\u4e86\u5927\u89c4\u6a21RL\u53ef\u4ee5\u663e\u8457\u589e\u5f3a\u4e2d\u5c0f\u578b\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u8d85\u8d8a\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u84b8\u998f\u7684\u6a21\u578b\u3002\u901a\u8fc7\u7cfb\u7edf\u7814\u7a76RL\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff1a\u5148\u5bf9\u6570\u5b66\u63d0\u793a\u8fdb\u884c\u8bad\u7ec3\uff0c\u518d\u5bf9\u4ee3\u7801\u63d0\u793a\u8fdb\u884c\u8bad\u7ec3\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6570\u5b66\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\uff0c\u8fd8\u6539\u5584\u4e86\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\u7684\u8868\u73b0\u3002\u6b64\u5916\uff0c\u6269\u5c55\u4ee3\u7801RL\u8fed\u4ee3\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u4ee3\u7801\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\u4e86\u5173\u952e\u7684\u5b9e\u9a8c\u89c1\u89e3\uff0c\u5982\u8bfe\u7a0b\u5b66\u4e60\u548c\u7b56\u7565\u53c2\u6570\u66f4\u65b0\u7684\u7a33\u5b9a\u6548\u679c\u3002\u6700\u7ec8\uff0cRL\u4e0d\u4ec5\u6fc0\u53d1\u4e86\u9884\u8bad\u7ec3\u548c\u76d1\u7763\u5fae\u8c03\u671f\u95f4\u83b7\u5f97\u7684\u57fa\u7840\u63a8\u7406\u80fd\u529b\uff0c\u8fd8\u63a8\u52a8\u4e86\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u6781\u9650\u3002", "motivation": "\u5f53\u524d\u9ad8\u6027\u80fd\u63a8\u7406\u6a21\u578b\u7684\u8bad\u7ec3\u65b9\u6cd5\u4e0d\u591f\u660e\u786e\uff0c\u524d\u6cbf\u6a21\u578b\u7684\u5173\u952e\u5b9e\u73b0\u7ec6\u8282\u5e38\u88ab\u7701\u7565\u3002\u540c\u65f6\uff0c\u5bf9\u4e8e\u5c0f\u578b\u6a21\u578b\uff0c\u84b8\u998f\u6bd4RL\u66f4\u6709\u6548\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u8bc1\u660e\u5927\u89c4\u6a21RL\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u4e2d\u5c0f\u578b\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u63a2\u7d22\u5176\u5177\u4f53\u65b9\u6cd5\u548c\u673a\u5236\u3002", "method": "\u7814\u7a76\u8005\u7cfb\u7edf\u5730\u7814\u7a76\u4e86RL\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u800c\u6709\u6548\u7684\u65b9\u6cd5\uff1a\u9996\u5148\u5728\u4ec5\u6570\u5b66\u63d0\u793a\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u7136\u540e\u5728\u4ec5\u4ee3\u7801\u63d0\u793a\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u4ed6\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u6570\u636e\u6574\u7406\u7ba1\u9053\uff0c\u6536\u96c6\u5177\u6709\u9ad8\u8d28\u91cf\u3001\u53ef\u9a8c\u8bc1\u7b54\u6848\u548c\u6d4b\u8bd5\u7528\u4f8b\u7684\u6311\u6218\u6027\u63d0\u793a\uff0c\u4ee5\u5b9e\u73b0\u8de8\u9886\u57df\u7684\u57fa\u4e8e\u9a8c\u8bc1\u7684RL\u3002\u6b64\u5916\uff0c\u8fd8\u91c7\u7528\u4e86\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u548c\u7b56\u7565\u53c2\u6570\u66f4\u65b0\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u4e2d\u5c0f\u578b\u6a21\u578b\u5728\u6570\u5b66\u548c\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002\u4f8b\u5982\uff0c\u5728AIME 2025\u6570\u5b66\u57fa\u51c6\u4e0a\u5206\u522b\u63d0\u9ad8\u4e8614.6%\u548c17.2%\uff0c\u5728LiveCodeBench\u4ee3\u7801\u63a8\u7406\u4efb\u52a1\u4e0a\u5206\u522b\u63d0\u9ad8\u4e866.8%\u548c5.8%\u3002\u6269\u5c55\u4ee3\u7801RL\u8fed\u4ee3\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u4ee3\u7801\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\uff0c\u540c\u65f6\u51e0\u4e4e\u6ca1\u6709\u964d\u4f4e\u6570\u5b66\u7ed3\u679c\u3002", "conclusion": "\u5927\u89c4\u6a21RL\u4e0d\u4ec5\u80fd\u6fc0\u53d1\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u548c\u76d1\u7763\u5fae\u8c03\u4e2d\u83b7\u5f97\u7684\u57fa\u7840\u63a8\u7406\u80fd\u529b\uff0c\u8fd8\u80fd\u63a8\u52a8\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u6781\u9650\uff0c\u89e3\u51b3\u4ee5\u524d\u65e0\u6cd5\u89e3\u51b3\u7684\u95ee\u9898\u3002\u8fd9\u8868\u660eRL\u5728\u63d0\u5347\u4e2d\u5c0f\u578b\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2505.16928", "pdf": "https://arxiv.org/pdf/2505.16928", "abs": "https://arxiv.org/abs/2505.16928", "authors": ["Bosung Kim", "Prithviraj Ammanabrolu"], "title": "Beyond Needle(s) in the Embodied Haystack: Environment, Architecture, and Training Considerations for Long Context Reasoning", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": null, "summary": "We introduce $\\infty$-THOR, a new framework for long-horizon embodied tasks\nthat advances long-context understanding in embodied AI. $\\infty$-THOR\nprovides: (1) a generation framework for synthesizing scalable, reproducible,\nand unlimited long-horizon trajectories; (2) a novel embodied QA task,\nNeedle(s) in the Embodied Haystack, where multiple scattered clues across\nextended trajectories test agents' long-context reasoning ability; and (3) a\nlong-horizon dataset and benchmark suite featuring complex tasks that span\nhundreds of environment steps, each paired with ground-truth action sequences.\nTo enable this capability, we explore architectural adaptations, including\ninterleaved Goal-State-Action modeling, context extension techniques, and\nContext Parallelism, to equip LLM-based agents for extreme long-context\nreasoning and interaction. Experimental results and analyses highlight the\nchallenges posed by our benchmark and provide insights into training strategies\nand model behaviors under long-horizon conditions. Our work provides a\nfoundation for the next generation of embodied AI systems capable of robust,\nlong-term reasoning and planning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u6846\u67b6$\\infty$-THOR\uff0c\u7528\u4e8e\u957f\u65f6\u57df\u5177\u8eab\u4efb\u52a1\uff0c\u63a8\u52a8\u4e86\u5177\u8eabAI\u4e2d\u7684\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u3002\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u751f\u6210\u53ef\u6269\u5c55\u3001\u53ef\u91cd\u73b0\u4e14\u65e0\u9650\u957f\u65f6\u57df\u8f68\u8ff9\u7684\u751f\u6210\u6846\u67b6\uff1b\u4e00\u79cd\u65b0\u7684\u5177\u8eab\u95ee\u7b54\u4efb\u52a1Needle(s) in the Embodied Haystack\uff1b\u4ee5\u53ca\u4e00\u4e2a\u5305\u542b\u590d\u6742\u4efb\u52a1\u7684\u957f\u65f6\u57df\u6570\u636e\u96c6\u548c\u57fa\u51c6\u5957\u4ef6\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u80fd\u529b\uff0c\u6211\u4eec\u63a2\u7d22\u4e86\u67b6\u6784\u9002\u5e94\uff0c\u5305\u62ec\u4ea4\u9519\u7684\u76ee\u6807-\u72b6\u6001-\u52a8\u4f5c\u5efa\u6a21\u3001\u4e0a\u4e0b\u6587\u6269\u5c55\u6280\u672f\u548c\u4e0a\u4e0b\u6587\u5e76\u884c\u6027\uff0c\u4ee5\u4f7f\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u80fd\u591f\u8fdb\u884c\u6781\u7aef\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u548c\u4ea4\u4e92\u3002\u5b9e\u9a8c\u7ed3\u679c\u548c\u5206\u6790\u7a81\u663e\u4e86\u6211\u4eec\u57fa\u51c6\u5e26\u6765\u7684\u6311\u6218\uff0c\u5e76\u63d0\u4f9b\u4e86\u5173\u4e8e\u8bad\u7ec3\u7b56\u7565\u548c\u6a21\u578b\u5728\u957f\u65f6\u57df\u6761\u4ef6\u4e0b\u7684\u884c\u4e3a\u7684\u89c1\u89e3\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u4e0b\u4e00\u4ee3\u5177\u5907\u5f3a\u5927\u957f\u65f6\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\u7684\u5177\u8eabAI\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u5177\u8eabAI\u7cfb\u7edf\u5728\u957f\u65f6\u57df\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u6709\u9650\uff0c\u7f3a\u4e4f\u5bf9\u957f\u4e0a\u4e0b\u6587\u7684\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u63d0\u5347AI\u7cfb\u7edf\u5728\u590d\u6742\u3001\u957f\u65f6\u57df\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "1. \u5f00\u53d1\u4e86\u4e00\u4e2a\u751f\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u5408\u6210\u53ef\u6269\u5c55\u3001\u53ef\u91cd\u73b0\u4e14\u65e0\u9650\u957f\u65f6\u57df\u7684\u8f68\u8ff9\u3002\n2. \u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5177\u8eab\u95ee\u7b54\u4efb\u52a1Needle(s) in the Embodied Haystack\uff0c\u6d4b\u8bd5\u4ee3\u7406\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u3002\n3. \u521b\u5efa\u4e86\u4e00\u4e2a\u957f\u65f6\u57df\u6570\u636e\u96c6\u548c\u57fa\u51c6\u5957\u4ef6\uff0c\u5305\u542b\u8de8\u8d8a\u6570\u767e\u4e2a\u73af\u5883\u6b65\u9aa4\u7684\u590d\u6742\u4efb\u52a1\u3002\n4. \u63a2\u7d22\u4e86\u67b6\u6784\u9002\u5e94\u6280\u672f\uff0c\u5305\u62ec\u4ea4\u9519\u76ee\u6807-\u72b6\u6001-\u52a8\u4f5c\u5efa\u6a21\u3001\u4e0a\u4e0b\u6587\u6269\u5c55\u6280\u672f\u548c\u4e0a\u4e0b\u6587\u5e76\u884c\u6027\uff0c\u4ee5\u589e\u5f3a\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u7684\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u57fa\u51c6\u5e26\u6765\u4e86\u663e\u8457\u7684\u6311\u6218\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u5173\u4e8e\u8bad\u7ec3\u7b56\u7565\u548c\u6a21\u578b\u884c\u4e3a\u7684\u91cd\u8981\u89c1\u89e3\u3002\u8fd9\u6709\u52a9\u4e8e\u6539\u8fdb\u6a21\u578b\u5728\u957f\u65f6\u57df\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\u3002", "conclusion": "$\\infty$-THOR\u6846\u67b6\u4e3a\u4e0b\u4e00\u4ee3\u5177\u8eabAI\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u4f7f\u5176\u5177\u5907\u5f3a\u5927\u7684\u957f\u65f6\u63a8\u7406\u548c\u89c4\u5212\u80fd\u529b\u3002"}}
{"id": "2505.16401", "pdf": "https://arxiv.org/pdf/2505.16401", "abs": "https://arxiv.org/abs/2505.16401", "authors": ["Xiaoqing Zhang", "Huabin Zheng", "Ang Lv", "Yuhan Liu", "Zirui Song", "Flood Sung", "Xiuying Chen", "Rui Yan"], "title": "Divide-Fuse-Conquer: Eliciting \"Aha Moments\" in Multi-Scenario Games", "categories": ["cs.LG"], "comment": "25 pages, 13 figures, and 8 tables", "summary": "Large language models (LLMs) have been observed to suddenly exhibit advanced\nreasoning abilities during reinforcement learning (RL), resembling an ``aha\nmoment'' triggered by simple outcome-based rewards. While RL has proven\neffective in eliciting such breakthroughs in tasks involving mathematics,\ncoding, and vision, it faces significant challenges in multi-scenario games.\nThe diversity of game rules, interaction modes, and environmental complexities\noften leads to policies that perform well in one scenario but fail to\ngeneralize to others. Simply combining multiple scenarios during training\nintroduces additional challenges, such as training instability and poor\nperformance. To overcome these challenges, we propose Divide-Fuse-Conquer, a\nframework designed to enhance generalization in multi-scenario RL. This\napproach starts by heuristically grouping games based on characteristics such\nas rules and difficulties. Specialized models are then trained for each group\nto excel at games in the group is what we refer to as the divide step. Next, we\nfuse model parameters from different groups as a new model, and continue\ntraining it for multiple groups, until the scenarios in all groups are\nconquered. Experiments across 18 TextArena games show that Qwen2.5-32B-Align\ntrained with the Divide-Fuse-Conquer strategy reaches a performance level\ncomparable to Claude3.5, achieving 7 wins and 4 draws. We hope our approach can\ninspire future research on using reinforcement learning to improve the\ngeneralization of LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDivide-Fuse-Conquer\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u7ec4\u3001\u878d\u5408\u548c\u5f81\u670d\u4e09\u4e2a\u6b65\u9aa4\u6765\u589e\u5f3a\u591a\u573a\u666f\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u8be5\u7b56\u7565\u8bad\u7ec3\u7684Qwen2.5-32B-Align\u572818\u4e2aTextArena\u6e38\u620f\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u53ef\u4e0eClaude3.5\u76f8\u5ab2\u7f8e\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u867d\u7136\u5728\u6570\u5b66\u3001\u7f16\u7801\u548c\u89c6\u89c9\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u591a\u573a\u666f\u6e38\u620f\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u9762\u4e34\u6311\u6218\uff0c\u4f8b\u5982\u89c4\u5219\u591a\u6837\u6027\u3001\u4ea4\u4e92\u6a21\u5f0f\u590d\u6742\u6027\u7b49\u5bfc\u81f4\u6a21\u578b\u5728\u4e00\u4e2a\u573a\u666f\u4e2d\u8868\u73b0\u826f\u597d\u4f46\u65e0\u6cd5\u63a8\u5e7f\u5230\u5176\u4ed6\u573a\u666f\u3002\u7b80\u5355\u7684\u591a\u573a\u666f\u7ec4\u5408\u8bad\u7ec3\u8fd8\u4f1a\u5f15\u8d77\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u53ca\u6027\u80fd\u4e0b\u964d\u7b49\u95ee\u9898\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86Divide-Fuse-Conquer\u6846\u67b6\uff0c\u5177\u4f53\u6b65\u9aa4\u5305\u62ec\uff1a1) \u6839\u636e\u6e38\u620f\u89c4\u5219\u548c\u96be\u5ea6\u7b49\u56e0\u7d20\u5bf9\u6e38\u620f\u8fdb\u884c\u542f\u53d1\u5f0f\u5206\u7ec4\uff1b2) \u4e3a\u6bcf\u4e2a\u7ec4\u8bad\u7ec3\u4e13\u95e8\u7684\u6a21\u578b\u4ee5\u4f7f\u5176\u5728\u7279\u5b9a\u7ec4\u7684\u6e38\u620f\u4e0a\u8868\u73b0\u51fa\u8272\uff08\u5206\u6b65\uff09\uff1b3) \u878d\u5408\u4e0d\u540c\u7ec4\u6a21\u578b\u53c2\u6570\u751f\u6210\u65b0\u6a21\u578b\uff0c\u5e76\u7ee7\u7eed\u9488\u5bf9\u591a\u4e2a\u7ec4\u8fdb\u884c\u8bad\u7ec3\uff0c\u76f4\u5230\u6240\u6709\u7ec4\u7684\u573a\u666f\u90fd\u88ab\u653b\u514b\uff08\u878d\u5408\u4e0e\u5f81\u670d\uff09\u3002", "result": "\u572818\u4e2aTextArena\u6e38\u620f\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u91c7\u7528Divide-Fuse-Conquer\u7b56\u7565\u8bad\u7ec3\u7684Qwen2.5-32B-Align\u8fbe\u5230\u4e86\u4e0eClaude3.5\u76f8\u5f53\u7684\u6027\u80fd\u6c34\u5e73\uff0c\u53d6\u5f97\u4e867\u573a\u80dc\u5229\u548c4\u573a\u5e73\u5c40\u7684\u597d\u6210\u7ee9\u3002", "conclusion": "Divide-Fuse-Conquer\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u591a\u573a\u666f\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u672a\u6765\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u6539\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2505.16938", "pdf": "https://arxiv.org/pdf/2505.16938", "abs": "https://arxiv.org/abs/2505.16938", "authors": ["NovelSeek Team", "Bo Zhang", "Shiyang Feng", "Xiangchao Yan", "Jiakang Yuan", "Zhiyin Yu", "Xiaohan He", "Songtao Huang", "Shaowei Hou", "Zheng Nie", "Zhilong Wang", "Jinyao Liu", "Runmin Ma", "Tianshuo Peng", "Peng Ye", "Dongzhan Zhou", "Shufei Zhang", "Xiaosong Wang", "Yilan Zhang", "Meng Li", "Zhongying Tu", "Xiangyu Yue", "Wangli Ouyang", "Bowen Zhou", "Lei Bai"], "title": "NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "HomePage: https://alpha-innovator.github.io/NovelSeek-project-page", "summary": "Artificial Intelligence (AI) is accelerating the transformation of scientific\nresearch paradigms, not only enhancing research efficiency but also driving\ninnovation. We introduce NovelSeek, a unified closed-loop multi-agent framework\nto conduct Autonomous Scientific Research (ASR) across various scientific\nresearch fields, enabling researchers to tackle complicated problems in these\nfields with unprecedented speed and precision. NovelSeek highlights three key\nadvantages: 1) Scalability: NovelSeek has demonstrated its versatility across\n12 scientific research tasks, capable of generating innovative ideas to enhance\nthe performance of baseline code. 2) Interactivity: NovelSeek provides an\ninterface for human expert feedback and multi-agent interaction in automated\nend-to-end processes, allowing for the seamless integration of domain expert\nknowledge. 3) Efficiency: NovelSeek has achieved promising performance gains in\nseveral scientific fields with significantly less time cost compared to human\nefforts. For instance, in reaction yield prediction, it increased from 27.6% to\n35.4% in just 12 hours; in enhancer activity prediction, accuracy rose from\n0.52 to 0.79 with only 4 hours of processing; and in 2D semantic segmentation,\nprecision advanced from 78.8% to 81.0% in a mere 30 hours.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aNovelSeek\u7684\u7edf\u4e00\u95ed\u73af\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u591a\u4e2a\u79d1\u5b66\u9886\u57df\u8fdb\u884c\u81ea\u4e3b\u79d1\u5b66\u7814\u7a76(ASR)\uff0c\u5177\u6709\u53ef\u6269\u5c55\u6027\u3001\u4ea4\u4e92\u6027\u548c\u9ad8\u6548\u6027\u4e09\u4e2a\u5173\u952e\u4f18\u52bf\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\uff0c\u5b83\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u7814\u7a76\u6548\u7387\uff0c\u8fd8\u63a8\u52a8\u4e86\u521b\u65b0\uff0c\u52a0\u901f\u4e86\u79d1\u5b66\u7814\u7a76\u8303\u5f0f\u7684\u8f6c\u53d8\u3002\u56e0\u6b64\uff0c\u5f15\u5165\u4e00\u79cd\u80fd\u591f\u8de8\u79d1\u5b66\u9886\u57df\u8fdb\u884c\u81ea\u4e3b\u79d1\u5b66\u7814\u7a76\u7684\u6846\u67b6\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNovelSeek\u7684\u7edf\u4e00\u95ed\u73af\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5177\u6709\u4ee5\u4e0b\u7279\u70b9\uff1a1) \u53ef\u6269\u5c55\u6027\uff1a\u9002\u7528\u4e8e12\u4e2a\u79d1\u5b66\u4efb\u52a1\uff1b2) \u4ea4\u4e92\u6027\uff1a\u63d0\u4f9b\u4eba\u7c7b\u4e13\u5bb6\u53cd\u9988\u548c\u591a\u4ee3\u7406\u4ea4\u4e92\u63a5\u53e3\uff1b3) \u9ad8\u6548\u6027\uff1a\u663e\u8457\u51cf\u5c11\u65f6\u95f4\u6210\u672c\uff0c\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728\u591a\u4e2a\u79d1\u5b66\u9886\u57df\u4e2d\uff0cNovelSeek\u5c55\u793a\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff1a\u53cd\u5e94\u4ea7\u7387\u9884\u6d4b\u4ece27.6%\u63d0\u5347\u523035.4%\uff0c\u589e\u5f3a\u5b50\u6d3b\u6027\u9884\u6d4b\u51c6\u786e\u7387\u4ece0.52\u63d0\u5347\u52300.79\uff0c2D\u8bed\u4e49\u5206\u5272\u7cbe\u5ea6\u4ece78.8%\u63d0\u5347\u523081.0%\u3002", "conclusion": "NovelSeek\u4e3a\u8de8\u5b66\u79d1\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u80fd\u591f\u4ee5\u524d\u6240\u672a\u6709\u7684\u901f\u5ea6\u548c\u7cbe\u786e\u5ea6\u89e3\u51b3\u590d\u6742\u95ee\u9898\uff0c\u6781\u5927\u5730\u63d0\u5347\u4e86\u79d1\u7814\u6548\u7387\u3002"}}
{"id": "2505.16403", "pdf": "https://arxiv.org/pdf/2505.16403", "abs": "https://arxiv.org/abs/2505.16403", "authors": ["Huazi Pan", "Yanjun Zhang", "Leo Yu Zhang", "Scott Adams", "Abbas Kouzani", "Suiyang Khoo"], "title": "Performance Guaranteed Poisoning Attacks in Federated Learning: A Sliding Mode Approach", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "Manipulation of local training data and local updates, i.e., the poisoning\nattack, is the main threat arising from the collaborative nature of the\nfederated learning (FL) paradigm. Most existing poisoning attacks aim to\nmanipulate local data/models in a way that causes denial-of-service (DoS)\nissues. In this paper, we introduce a novel attack method, named Federated\nLearning Sliding Attack (FedSA) scheme, aiming at precisely introducing the\nextent of poisoning in a subtle controlled manner. It operates with a\npredefined objective, such as reducing global model's prediction accuracy by\n10\\%. FedSA integrates robust nonlinear control-Sliding Mode Control (SMC)\ntheory with model poisoning attacks. It can manipulate the updates from\nmalicious clients to drive the global model towards a compromised state,\nachieving this at a controlled and inconspicuous rate. Additionally, leveraging\nthe robust control properties of FedSA allows precise control over the\nconvergence bounds, enabling the attacker to set the global accuracy of the\npoisoned model to any desired level. Experimental results demonstrate that\nFedSA can accurately achieve a predefined global accuracy with fewer malicious\nclients while maintaining a high level of stealth and adjustable learning\nrates.", "AI": {"tldr": "\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u6295\u6bd2\u653b\u51fb\u65b9\u6cd5FedSA\uff0c\u901a\u8fc7\u6574\u5408\u6ed1\u6a21\u63a7\u5236\u7406\u8bba\uff0c\u80fd\u591f\u4ee5\u9690\u853d\u4e14\u53ef\u63a7\u7684\u65b9\u5f0f\u964d\u4f4e\u5168\u5c40\u6a21\u578b\u7684\u9884\u6d4b\u51c6\u786e\u7387\u5230\u9884\u5b9a\u76ee\u6807\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5c11\u91cf\u6076\u610f\u5ba2\u6237\u7aef\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u9ad8\u6548\u5b9e\u73b0\u76ee\u6807\uff0c\u5e76\u4fdd\u6301\u9ad8\u5ea6\u9690\u79d8\u6027\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u534f\u4f5c\u7279\u6027\u4f7f\u5176\u5bb9\u6613\u53d7\u5230\u6570\u636e\u548c\u6a21\u578b\u66f4\u65b0\u7684\u6295\u6bd2\u653b\u51fb\u5a01\u80c1\u3002\u73b0\u6709\u7684\u6295\u6bd2\u653b\u51fb\u591a\u4ee5\u5bfc\u81f4\u670d\u52a1\u62d2\u7edd\uff08DoS\uff09\u95ee\u9898\u4e3a\u76ee\u6807\uff0c\u800c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u66f4\u7cbe\u7ec6\u3001\u53ef\u63a7\u7684\u6295\u6bd2\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u540d\u4e3aFedSA\u7684\u65b0\u653b\u51fb\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u9c81\u68d2\u975e\u7ebf\u6027\u63a7\u5236-\u6ed1\u6a21\u63a7\u5236\uff08SMC\uff09\u7406\u8bba\u4e0e\u6a21\u578b\u6295\u6bd2\u653b\u51fb\u3002\u901a\u8fc7\u64cd\u7eb5\u6076\u610f\u5ba2\u6237\u7aef\u7684\u66f4\u65b0\uff0c\u63a8\u52a8\u5168\u5c40\u6a21\u578b\u8fdb\u5165\u53d7\u635f\u72b6\u6001\uff0c\u540c\u65f6\u4ee5\u53d7\u63a7\u4e14\u4e0d\u6613\u5bdf\u89c9\u7684\u901f\u5ea6\u8fdb\u884c\u3002\u5229\u7528FedSA\u7684\u9c81\u68d2\u63a7\u5236\u7279\u6027\uff0c\u53ef\u7cbe\u786e\u8bbe\u5b9a\u5168\u5c40\u6a21\u578b\u7684\u6536\u655b\u754c\u9650\u548c\u51c6\u786e\u7387\u6c34\u5e73\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFedSA\u80fd\u591f\u5728\u4f7f\u7528\u8f83\u5c11\u6076\u610f\u5ba2\u6237\u7aef\u7684\u60c5\u51b5\u4e0b\uff0c\u7cbe\u51c6\u5730\u5c06\u5168\u5c40\u6a21\u578b\u51c6\u786e\u7387\u964d\u4f4e\u5230\u9884\u8bbe\u6c34\u5e73\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u9690\u533f\u6027\u548c\u53ef\u8c03\u7684\u5b66\u4e60\u901f\u7387\u3002", "conclusion": "FedSA\u4f5c\u4e3a\u4e00\u79cd\u65b0\u578b\u6295\u6bd2\u653b\u51fb\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e0b\u7684\u6709\u6548\u6027\u548c\u9690\u853d\u6027\uff0c\u5f3a\u8c03\u4e86\u5bf9\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u5b89\u5168\u6027\u8fdb\u4e00\u6b65\u7814\u7a76\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2505.16944", "pdf": "https://arxiv.org/pdf/2505.16944", "abs": "https://arxiv.org/abs/2505.16944", "authors": ["Yunjia Qi", "Hao Peng", "Xiaozhi Wang", "Amy Xin", "Youfeng Liu", "Bin Xu", "Lei Hou", "Juanzi Li"], "title": "AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated advanced capabilities in\nreal-world agentic applications. Growing research efforts aim to develop\nLLM-based agents to address practical demands, introducing a new challenge:\nagentic scenarios often involve lengthy instructions with complex constraints,\nsuch as extended system prompts and detailed tool specifications. While\nadherence to such instructions is crucial for agentic applications, whether\nLLMs can reliably follow them remains underexplored. In this paper, we\nintroduce AgentIF, the first benchmark for systematically evaluating LLM\ninstruction following ability in agentic scenarios. AgentIF features three key\ncharacteristics: (1) Realistic, constructed from 50 real-world agentic\napplications. (2) Long, averaging 1,723 words with a maximum of 15,630 words.\n(3) Complex, averaging 11.9 constraints per instruction, covering diverse\nconstraint types, such as tool specifications and condition constraints. To\nconstruct AgentIF, we collect 707 human-annotated instructions across 50\nagentic tasks from industrial application agents and open-source agentic\nsystems. For each instruction, we annotate the associated constraints and\ncorresponding evaluation metrics, including code-based evaluation, LLM-based\nevaluation, and hybrid code-LLM evaluation. We use AgentIF to systematically\nevaluate existing advanced LLMs. We observe that current models generally\nperform poorly, especially in handling complex constraint structures and tool\nspecifications. We further conduct error analysis and analytical experiments on\ninstruction length and meta constraints, providing some findings about the\nfailure modes of existing LLMs. We have released the code and data to\nfacilitate future research.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u771f\u5b9e\u4e16\u754c\u7684\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u9ad8\u7ea7\u80fd\u529b\u3002\u4e3a\u4e86\u8bc4\u4f30LLMs\u9075\u5faa\u6307\u4ee4\u7684\u80fd\u529b\uff0c\u6211\u4eec\u5f15\u5165\u4e86AgentIF\u57fa\u51c6\u6d4b\u8bd5\u3002\u901a\u8fc7\u5206\u6790\u73b0\u6709\u6a21\u578b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u5904\u7406\u590d\u6742\u7ea6\u675f\u7ed3\u6784\u548c\u5de5\u5177\u89c4\u683c\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002", "motivation": "\u76ee\u524d\u5bf9\u4e8eLLMs\u662f\u5426\u80fd\u53ef\u9760\u5730\u9075\u5faa lengthy instructions with complex constraints \u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u800c\u8fd9\u5bf9agentic applications\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aAgentIF\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u6765\u81ea50\u4e2a\u771f\u5b9e\u4e16\u754c\u4ee3\u7406\u5e94\u7528\u7684707\u6761\u4eba\u7c7b\u6807\u6ce8\u7684\u6307\u4ee4\uff0c\u5e73\u5747\u6bcf\u6761\u6307\u4ee41,723\u8bcd\uff0c\u5e76\u670911.9\u4e2a\u7ea6\u675f\u6761\u4ef6\u3002\u4f7f\u7528\u591a\u79cd\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u4ee3\u7801\u3001LLM\u548c\u6df7\u5408\u8bc4\u4f30\u3002", "result": "\u5f53\u524d\u5148\u8fdb\u7684LLMs\u603b\u4f53\u8868\u73b0\u8f83\u5dee\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u7ea6\u675f\u7ed3\u6784\u548c\u5de5\u5177\u89c4\u683c\u65f6\u3002\u8fdb\u884c\u4e86\u9519\u8bef\u5206\u6790\u548c\u5b9e\u9a8c\uff0c\u63ed\u793a\u4e86\u73b0\u6709LLMs\u7684\u5931\u8d25\u6a21\u5f0f\u3002", "conclusion": "AgentIF\u4e3a\u7cfb\u7edf\u8bc4\u4f30LLMs\u5728\u4ee3\u7406\u573a\u666f\u4e2d\u7684\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u63d0\u4f9b\u4e86\u9996\u4e2a\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u7684\u4e0d\u8db3\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u8d44\u6e90\u548c\u65b9\u5411\u3002"}}
{"id": "2505.16446", "pdf": "https://arxiv.org/pdf/2505.16446", "abs": "https://arxiv.org/abs/2505.16446", "authors": ["Zhaoxin Wang", "Handing Wang", "Cong Tian", "Yaochu Jin"], "title": "Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Multimodal large language models (MLLMs) enable powerful cross-modal\nreasoning capabilities. However, the expanded input space introduces new attack\nsurfaces. Previous jailbreak attacks often inject malicious instructions from\ntext into less aligned modalities, such as vision. As MLLMs increasingly\nincorporate cross-modal consistency and alignment mechanisms, such explicit\nattacks become easier to detect and block. In this work, we propose a novel\nimplicit jailbreak framework termed IJA that stealthily embeds malicious\ninstructions into images via least significant bit steganography and couples\nthem with seemingly benign, image-related textual prompts. To further enhance\nattack effectiveness across diverse MLLMs, we incorporate adversarial suffixes\ngenerated by a surrogate model and introduce a template optimization module\nthat iteratively refines both the prompt and embedding based on model feedback.\nOn commercial models like GPT-4o and Gemini-1.5 Pro, our method achieves attack\nsuccess rates of over 90% using an average of only 3 queries.", "AI": {"tldr": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u867d\u7136\u5177\u5907\u5f3a\u5927\u7684\u8de8\u6a21\u6001\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5176\u6269\u5c55\u7684\u8f93\u5165\u7a7a\u95f4\u5f15\u5165\u4e86\u65b0\u7684\u653b\u51fb\u9762\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u9690\u5f0f\u8d8a\u72f1\u6846\u67b6IJA\uff0c\u901a\u8fc7\u6700\u4f4e\u6709\u6548\u4f4d\u9690\u5199\u672f\u5c06\u6076\u610f\u6307\u4ee4\u5d4c\u5165\u56fe\u50cf\uff0c\u5e76\u7ed3\u5408\u770b\u4f3c\u65e0\u5bb3\u7684\u6587\u672c\u63d0\u793a\uff0c\u4ece\u800c\u589e\u5f3a\u5bf9\u4e0d\u540cMLLMs\u7684\u653b\u51fb\u6548\u679c\u3002\u8be5\u65b9\u6cd5\u5728\u5546\u4e1a\u6a21\u578b\u5982GPT-4o\u548cGemini-1.5 Pro\u4e0a\uff0c\u4ec5\u5e73\u5747\u4f7f\u75283\u6b21\u67e5\u8be2\u5373\u53ef\u8fbe\u5230\u8d85\u8fc790%\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u5c3d\u7ba1\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5177\u6709\u5f3a\u5927\u7684\u8de8\u6a21\u6001\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u968f\u7740\u8fd9\u4e9b\u6a21\u578b\u9010\u6e10\u6574\u5408\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u4e0e\u5bf9\u9f50\u673a\u5236\uff0c\u663e\u5f0f\u7684\u8d8a\u72f1\u653b\u51fb\u53d8\u5f97\u66f4\u5bb9\u6613\u88ab\u68c0\u6d4b\u548c\u963b\u6b62\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9690\u853d\u4e14\u9ad8\u6548\u7684\u653b\u51fb\u65b9\u6cd5\u6765\u6d4b\u8bd5\u548c\u63d0\u5347\u6a21\u578b\u7684\u5b89\u5168\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aIJA\u7684\u9690\u5f0f\u8d8a\u72f1\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u6700\u4f4e\u6709\u6548\u4f4d\u9690\u5199\u672f\u5c06\u6076\u610f\u6307\u4ee4\u5d4c\u5165\u56fe\u50cf\uff0c\u5e76\u7ed3\u5408\u770b\u4f3c\u65e0\u5bb3\u7684\u56fe\u50cf\u76f8\u5173\u6587\u672c\u63d0\u793a\u3002\u540c\u65f6\uff0c\u5f15\u5165\u5bf9\u6297\u6027\u540e\u7f00\u751f\u6210\u548c\u6a21\u677f\u4f18\u5316\u6a21\u5757\uff0c\u57fa\u4e8e\u6a21\u578b\u53cd\u9988\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\u548c\u5d4c\u5165\u5185\u5bb9\uff0c\u4ee5\u63d0\u9ad8\u5728\u4e0d\u540cMLLMs\u4e0a\u7684\u653b\u51fb\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cIJA\u6846\u67b6\u5728\u5546\u4e1a\u6a21\u578b\u5982GPT-4o\u548cGemini-1.5 Pro\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4ec5\u9700\u5e73\u57473\u6b21\u67e5\u8be2\u5373\u53ef\u5b9e\u73b0\u8d85\u8fc790%\u7684\u653b\u51fb\u6210\u529f\u7387\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684IJA\u6846\u67b6\u5c55\u793a\u4e86\u9690\u5f0f\u8d8a\u72f1\u653b\u51fb\u5728\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6f5c\u529b\u548c\u5a01\u80c1\uff0c\u5f3a\u8c03\u4e86\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u6539\u8fdb\u6a21\u578b\u5b89\u5168\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2505.16978", "pdf": "https://arxiv.org/pdf/2505.16978", "abs": "https://arxiv.org/abs/2505.16978", "authors": ["Weizhi Tang", "Yixuan Li", "Chris Sypherd", "Elizabeth Polgreen", "Vaishak Belle"], "title": "HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation", "categories": ["cs.AI", "cs.PL"], "comment": "Accepted to ACL 2025 Findings. Code available at\n  https://github.com/RutaTang/HyGenar", "summary": "Grammar plays a critical role in natural language processing and text/code\ngeneration by enabling the definition of syntax, the creation of parsers, and\nguiding structured outputs. Although large language models (LLMs) demonstrate\nimpressive capabilities across domains, their ability to infer and generate\ngrammars has not yet been thoroughly explored. In this paper, we aim to study\nand improve the ability of LLMs for few-shot grammar generation, where grammars\nare inferred from sets of a small number of positive and negative examples and\ngenerated in Backus-Naur Form. To explore this, we introduced a novel dataset\ncomprising 540 structured grammar generation challenges, devised 6 metrics, and\nevaluated 8 various LLMs against it. Our findings reveal that existing LLMs\nperform sub-optimally in grammar generation. To address this, we propose an\nLLM-driven hybrid genetic algorithm, namely HyGenar, to optimize grammar\ngeneration. HyGenar achieves substantial improvements in both the syntactic and\nsemantic correctness of generated grammars across LLMs.", "AI": {"tldr": "\u8bed\u6cd5\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u6587\u672c/\u4ee3\u7801\u751f\u6210\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\u3002\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5404\u4e2a\u9886\u57df\u8868\u73b0\u51fa\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u63a8\u65ad\u548c\u751f\u6210\u8bed\u6cd5\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u672c\u6587\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u5305\u542b540\u4e2a\u7ed3\u6784\u5316\u8bed\u6cd5\u751f\u6210\u6311\u6218\u7684\u65b0\u6570\u636e\u96c6\u3001\u8bbe\u8ba16\u4e2a\u5ea6\u91cf\u6807\u51c6\uff0c\u5e76\u8bc4\u4f308\u79cd\u4e0d\u540c\u7684LLM\u6765\u7814\u7a76LLM\u5728\u5c11\u91cf\u6837\u672c\u8bed\u6cd5\u751f\u6210\u4e2d\u7684\u80fd\u529b\u3002\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u7684LLM\u5728\u8bed\u6cd5\u751f\u6210\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u7531LLM\u9a71\u52a8\u7684\u6df7\u5408\u9057\u4f20\u7b97\u6cd5HyGenar\uff0c\u4ee5\u4f18\u5316\u8bed\u6cd5\u751f\u6210\u3002HyGenar\u5728\u63d0\u9ad8\u751f\u6210\u8bed\u6cd5\u7684\u53e5\u6cd5\u548c\u8bed\u4e49\u6b63\u786e\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u6cd5\u751f\u6210\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u5e76\u8bd5\u56fe\u901a\u8fc7\u65b0\u65b9\u6cd5\u6539\u5584\u5176\u6027\u80fd\u3002", "method": "1. \u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b540\u4e2a\u7ed3\u6784\u5316\u8bed\u6cd5\u751f\u6210\u4efb\u52a1\u7684\u6570\u636e\u96c6\u3002\n2. \u8bbe\u8ba1\u4e866\u4e2a\u8bc4\u4f30\u6307\u6807\u3002\n3. \u8bc4\u4f30\u4e868\u79cd\u4e0d\u540c\u7684LLM\u6a21\u578b\u3002\n4. \u63d0\u51fa\u4e86LLM\u9a71\u52a8\u7684\u6df7\u5408\u9057\u4f20\u7b97\u6cd5HyGenar\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u73b0\u6709LLM\u5728\u8bed\u6cd5\u751f\u6210\u4e0a\u8868\u73b0\u6b20\u4f73\uff0c\u800cHyGenar\u5728\u63d0\u5347\u751f\u6210\u8bed\u6cd5\u7684\u53e5\u6cd5\u548c\u8bed\u4e49\u6b63\u786e\u6027\u65b9\u9762\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u73b0\u6709\u7684LLM\u5728\u8bed\u6cd5\u751f\u6210\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4f46\u901a\u8fc7\u4f7f\u7528HyGenar\u7b49\u6df7\u5408\u65b9\u6cd5\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5176\u6027\u80fd\u3002"}}
{"id": "2505.16979", "pdf": "https://arxiv.org/pdf/2505.16979", "abs": "https://arxiv.org/abs/2505.16979", "authors": ["Zhenkun Li", "Lingyao Li", "Shuhang Lin", "Yongfeng Zhang"], "title": "Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "Single-agent LLMs hit hard limits--finite context, role overload, and brittle\ndomain transfer. Conventional multi-agent fixes soften those edges yet expose\nfresh pains: ill-posed decompositions, fuzzy contracts, and verification\noverhead that blunts the gains. We therefore present Know-The-Ropes (KtR), a\nframework that converts domain priors into an algorithmic blueprint hierarchy,\nin which tasks are recursively split into typed, controller-mediated subtasks,\neach solved zero-shot or with the lightest viable boost (e.g.,\nchain-of-thought, micro-tune, self-check). Grounded in the No-Free-Lunch\ntheorem, KtR trades the chase for a universal prompt for disciplined\ndecomposition. On the Knapsack problem (3-8 items), three GPT-4o-mini agents\nraise accuracy from 3% zero-shot to 95% on size-5 instances after patching a\nsingle bottleneck agent. On the tougher Task-Assignment problem (6-15 jobs), a\nsix-agent o3-mini blueprint hits 100% up to size 10 and 84% on sizes 13-15,\nversus 11% zero-shot. Algorithm-aware decomposition plus targeted augmentation\nthus turns modest models into reliable collaborators--no ever-larger monoliths\nrequired.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u9886\u57df\u5148\u9a8c\u8f6c\u6362\u4e3a\u7b97\u6cd5\u84dd\u56fe\u5c42\u6b21\u7ed3\u6784\uff0cKnow-The-Ropes\uff08KtR\uff09\u6846\u67b6\u89e3\u51b3\u4e86\u5355\u4ee3\u7406\u548c\u591a\u4ee3\u7406\u8bed\u8a00\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u80cc\u5305\u95ee\u9898\u548c\u4efb\u52a1\u5206\u914d\u95ee\u9898\u4e0a\uff0c\u5206\u89e3\u4efb\u52a1\u5e76\u9488\u5bf9\u6027\u589e\u5f3a\u53ef\u663e\u8457\u63d0\u9ad8\u5c0f\u89c4\u6a21\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5355\u4e00\u4ee3\u7406LLMs\u5b58\u5728\u6709\u9650\u4e0a\u4e0b\u6587\u3001\u89d2\u8272\u8fc7\u8f7d\u548c\u8106\u5f31\u9886\u57df\u8fc1\u79fb\u7b49\u95ee\u9898\uff0c\u800c\u4f20\u7edf\u591a\u4ee3\u7406\u65b9\u6cd5\u867d\u6709\u6240\u6539\u5584\uff0c\u5374\u5f15\u5165\u4e86\u65b0\u7684\u6311\u6218\uff0c\u5982\u4e0d\u660e\u786e\u7684\u5206\u89e3\u3001\u6a21\u7cca\u7684\u5408\u540c\u548c\u9a8c\u8bc1\u5f00\u9500\u3002\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u65b0\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aKnow-The-Ropes (KtR) \u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u9886\u57df\u5148\u9a8c\u8f6c\u5316\u4e3a\u7b97\u6cd5\u84dd\u56fe\u5c42\u6b21\u7ed3\u6784\u3002\u5728\u8fd9\u4e2a\u7ed3\u6784\u4e2d\uff0c\u4efb\u52a1\u88ab\u9012\u5f52\u5730\u5206\u89e3\u4e3a\u7531\u63a7\u5236\u5668\u4ecb\u5bfc\u7684\u5b50\u4efb\u52a1\uff0c\u6bcf\u4e2a\u5b50\u4efb\u52a1\u53ef\u4ee5\u901a\u8fc7\u96f6\u6837\u672c\u5b66\u4e60\u6216\u6700\u8f7b\u91cf\u7684\u589e\u5f3a\uff08\u5982\u601d\u7ef4\u94fe\u3001\u5fae\u8c03\u3001\u81ea\u6211\u68c0\u67e5\u7b49\uff09\u6765\u89e3\u51b3\u3002\u8fd9\u79cd\u65b9\u6cd5\u57fa\u4e8eNo-Free-Lunch\u5b9a\u7406\uff0c\u7528\u6709\u7eaa\u5f8b\u7684\u5206\u89e3\u4ee3\u66ff\u5bf9\u901a\u7528\u63d0\u793a\u7b26\u7684\u8ffd\u6c42\u3002", "result": "\u5728\u80cc\u5305\u95ee\u9898\uff083-8\u4ef6\u7269\u54c1\uff09\u4e2d\uff0c\u4e09\u4e2aGPT-4o-mini\u4ee3\u7406\u901a\u8fc7\u4fee\u8865\u5355\u4e00\u74f6\u9888\u4ee3\u7406\uff0c\u5c065\u4ef6\u7269\u54c1\u5927\u5c0f\u5b9e\u4f8b\u7684\u51c6\u786e\u7387\u4ece3%\u63d0\u5347\u523095%\u3002\u5728\u66f4\u56f0\u96be\u7684\u4efb\u52a1\u5206\u914d\u95ee\u9898\uff086-15\u4e2a\u4efb\u52a1\uff09\u4e2d\uff0c\u516d\u4ee3\u7406o3-mini\u84dd\u56fe\u5728\u89c4\u6a21\u8fbe10\u65f6\u8fbe\u5230100%\uff0c\u89c4\u6a2113-15\u65f6\u8fbe\u523084%\uff0c\u800c\u96f6\u6837\u672c\u51c6\u786e\u7387\u4e3a11%\u3002", "conclusion": "\u7b97\u6cd5\u611f\u77e5\u5206\u89e3\u4e0e\u76ee\u6807\u589e\u5f3a\u76f8\u7ed3\u5408\uff0c\u53ef\u4ee5\u5c06\u9002\u5ea6\u7684\u6a21\u578b\u8f6c\u53d8\u4e3a\u53ef\u9760\u7684\u5408\u4f5c\u8005\uff0c\u65e0\u9700\u4e0d\u65ad\u589e\u5927\u7684\u5355\u4e00\u6a21\u578b\u3002"}}
{"id": "2505.16493", "pdf": "https://arxiv.org/pdf/2505.16493", "abs": "https://arxiv.org/abs/2505.16493", "authors": ["Seyedeh Fatemeh Ebrahimi", "Jaakko Peltonen"], "title": "Constrained Non-negative Matrix Factorization for Guided Topic Modeling of Minority Topics", "categories": ["cs.LG"], "comment": null, "summary": "Topic models often fail to capture low-prevalence, domain-critical themes,\nso-called minority topics, such as mental health themes in online comments.\nWhile some existing methods can incorporate domain knowledge, such as expected\ntopical content, methods allowing guidance may require overly detailed expected\ntopics, hindering the discovery of topic divisions and variation. We propose a\ntopic modeling solution via a specially constrained NMF. We incorporate a seed\nword list characterizing minority content of interest, but we do not require\nexperts to pre-specify their division across minority topics. Through\nprevalence constraints on minority topics and seed word content across topics,\nwe learn distinct data-driven minority topics as well as majority topics. The\nconstrained NMF is fitted via Karush-Kuhn-Tucker (KKT) conditions with\nmultiplicative updates. We outperform several baselines on synthetic data in\nterms of topic purity, normalized mutual information, and also evaluate topic\nquality using Jensen-Shannon divergence (JSD). We conduct a case study on\nYouTube vlog comments, analyzing viewer discussion of mental health content;\nour model successfully identifies and reveals this domain-relevant minority\ncontent.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u7279\u522b\u7ea6\u675f\u7684\u975e\u8d1f\u77e9\u9635\u5206\u89e3(NMF)\u7684\u4e3b\u9898\u5efa\u6a21\u89e3\u51b3\u65b9\u6848\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u79cd\u5b50\u8bcd\u5217\u8868\u6765\u8868\u5f81\u5c11\u6570\u7fa4\u4f53\u5185\u5bb9\uff0c\u4f46\u4e0d\u8981\u6c42\u4e13\u5bb6\u9884\u5148\u6307\u5b9a\u5176\u5728\u5c11\u6570\u7fa4\u4f53\u4e3b\u9898\u4e0a\u7684\u5212\u5206\u3002\u901a\u8fc7\u5728\u5408\u6210\u6570\u636e\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8be5\u65b9\u6cd5\u5728\u4e3b\u9898\u7eaf\u5ea6\u3001\u5f52\u4e00\u5316\u4e92\u4fe1\u606f\u7b49\u65b9\u9762\u4f18\u4e8e\u51e0\u79cd\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7Jensen-Shannon\u6563\u5ea6(JSD)\u8bc4\u4f30\u4e3b\u9898\u8d28\u91cf\u3002\u5728\u4e00\u4e2a\u5173\u4e8eYouTube vlog\u8bc4\u8bba\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u8be5\u6a21\u578b\u6210\u529f\u8bc6\u522b\u5e76\u63ed\u793a\u4e86\u4e0e\u5fc3\u7406\u5065\u5eb7\u76f8\u5173\u7684\u5c11\u6570\u7fa4\u4f53\u5185\u5bb9\u3002", "motivation": "\u4e3b\u9898\u6a21\u578b\u5e38\u5e38\u65e0\u6cd5\u6355\u6349\u5230\u4f4e\u51fa\u73b0\u7387\u4f46\u5bf9\u9886\u57df\u81f3\u5173\u91cd\u8981\u7684\u4e3b\u9898\uff08\u5c11\u6570\u4e3b\u9898\uff09\uff0c\u4f8b\u5982\u5728\u7ebf\u8bc4\u8bba\u4e2d\u7684\u5fc3\u7406\u5065\u5eb7\u4e3b\u9898\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u867d\u7136\u53ef\u4ee5\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\uff0c\u4f46\u5982\u679c\u9700\u8981\u8fc7\u591a\u8be6\u7ec6\u7684\u9884\u671f\u4e3b\u9898\uff0c\u5219\u53ef\u80fd\u4f1a\u963b\u788d\u4e3b\u9898\u5212\u5206\u548c\u53d8\u5316\u7684\u53d1\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u7279\u522b\u7ea6\u675f\u7684\u975e\u8d1f\u77e9\u9635\u5206\u89e3(NMF)\u7684\u4e3b\u9898\u5efa\u6a21\u89e3\u51b3\u65b9\u6848\u3002\u8be5\u65b9\u6cd5\u5f15\u5165\u4e00\u4e2a\u79cd\u5b50\u8bcd\u5217\u8868\u4ee5\u8868\u5f81\u611f\u5174\u8da3\u7684\u5c11\u6570\u5185\u5bb9\uff0c\u4f46\u4e0d\u9700\u8981\u4e13\u5bb6\u9884\u5148\u6307\u5b9a\u8fd9\u4e9b\u5185\u5bb9\u5728\u5c11\u6570\u4e3b\u9898\u4e2d\u7684\u5212\u5206\u3002\u901a\u8fc7\u5bf9\u5c11\u6570\u4e3b\u9898\u548c\u4e3b\u9898\u4e2d\u7684\u79cd\u5b50\u8bcd\u5185\u5bb9\u8fdb\u884c\u51fa\u73b0\u7387\u7ea6\u675f\uff0c\u5b66\u4e60\u5230\u4e0d\u540c\u7684\u6570\u636e\u9a71\u52a8\u7684\u5c11\u6570\u4e3b\u9898\u548c\u591a\u6570\u4e3b\u9898\u3002\u4f7f\u7528Karush-Kuhn-Tucker (KKT)\u6761\u4ef6\u4e0e\u4e58\u6cd5\u66f4\u65b0\u6765\u62df\u5408\u7ea6\u675f\u7684NMF\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u4e3b\u9898\u7eaf\u5ea6\u3001\u5f52\u4e00\u5316\u4e92\u4fe1\u606f\u7b49\u65b9\u9762\u4f18\u4e8e\u51e0\u4e2a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528Jensen-Shannon\u6563\u5ea6(JSD)\u8bc4\u4f30\u4e3b\u9898\u8d28\u91cf\u3002\u5728YouTube vlog\u8bc4\u8bba\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u6a21\u578b\u6210\u529f\u8bc6\u522b\u5e76\u63ed\u793a\u4e86\u4e0e\u5fc3\u7406\u5065\u5eb7\u76f8\u5173\u7684\u5c11\u6570\u7fa4\u4f53\u5185\u5bb9\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u53d7\u7ea6\u675f\u7684NMF\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u8bc6\u522b\u5c11\u6570\u4e3b\u9898\uff0c\u5e76\u4e14\u5728\u5408\u6210\u6570\u636e\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u5747\u8868\u73b0\u826f\u597d\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e3a\u63a2\u7d22\u5c11\u6570\u7fa4\u4f53\u5185\u5bb9\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2505.16982", "pdf": "https://arxiv.org/pdf/2505.16982", "abs": "https://arxiv.org/abs/2505.16982", "authors": ["Adib Bazgir", "Amir Habibdoust Lafmajani", "Yuwen Zhang"], "title": "Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine", "categories": ["cs.AI", "physics.med-ph"], "comment": null, "summary": "Large Language Models (LLMs) show promise in biomedicine but lack true causal\nunderstanding, relying instead on correlations. This paper envisions causal LLM\nagents that integrate multimodal data (text, images, genomics, etc.) and\nperform intervention-based reasoning to infer cause-and-effect. Addressing this\nrequires overcoming key challenges: designing safe, controllable agentic\nframeworks; developing rigorous benchmarks for causal evaluation; integrating\nheterogeneous data sources; and synergistically combining LLMs with structured\nknowledge (KGs) and formal causal inference tools. Such agents could unlock\ntransformative opportunities, including accelerating drug discovery through\nautomated hypothesis generation and simulation, enabling personalized medicine\nthrough patient-specific causal models. This research agenda aims to foster\ninterdisciplinary efforts, bridging causal concepts and foundation models to\ndevelop reliable AI partners for biomedical progress.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u56e0\u679c\u63a8\u7406\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u76f8\u7ed3\u5408\u7684\u65b0\u65b9\u6cd5\uff0c\u65e8\u5728\u901a\u8fc7\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\u548c\u56e0\u679c\u63a8\u7406\u5de5\u5177\u6765\u89e3\u51b3\u751f\u7269\u533b\u5b66\u4e2d\u7684\u95ee\u9898\u3002\u8fd9\u79cd\u65b9\u6cd5\u53ef\u80fd\u5e26\u6765\u53d8\u9769\u6027\u673a\u9047\uff0c\u4f8b\u5982\u52a0\u901f\u836f\u7269\u53d1\u73b0\u548c\u5b9e\u73b0\u4e2a\u6027\u5316\u533b\u7597\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u7269\u533b\u5b66\u9886\u57df\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u7f3a\u4e4f\u771f\u6b63\u7684\u56e0\u679c\u7406\u89e3\u80fd\u529b\uff0c\u4ec5\u4f9d\u8d56\u4e8e\u76f8\u5173\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0\u56e0\u679c\u63a8\u7406\u548c\u591a\u6a21\u6001\u6570\u636e\u7684\u7ed3\u5408\u3002", "method": "\u8bbe\u8ba1\u5b89\u5168\u53ef\u63a7\u7684\u4ee3\u7406\u6846\u67b6\uff1b\u5f00\u53d1\u4e25\u683c\u7684\u56e0\u679c\u8bc4\u4f30\u57fa\u51c6\uff1b\u6574\u5408\u5f02\u6784\u6570\u636e\u6e90\uff1b\u4ee5\u53ca\u534f\u540c\u7ed3\u5408LLMs\u3001\u7ed3\u6784\u5316\u77e5\u8bc6\uff08KGs\uff09\u548c\u5f62\u5f0f\u5316\u7684\u56e0\u679c\u63a8\u7406\u5de5\u5177\u3002", "result": "\u8fd9\u79cd\u56e0\u679cLLM\u4ee3\u7406\u53ef\u4ee5\u89e3\u9501\u53d8\u9769\u6027\u673a\u4f1a\uff0c\u5982\u901a\u8fc7\u81ea\u52a8\u5316\u5047\u8bbe\u751f\u6210\u548c\u6a21\u62df\u52a0\u901f\u836f\u7269\u53d1\u73b0\uff0c\u901a\u8fc7\u60a3\u8005\u7279\u5b9a\u7684\u56e0\u679c\u6a21\u578b\u5b9e\u73b0\u4e2a\u6027\u5316\u533b\u7597\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bae\u7a0b\u65e8\u5728\u4fc3\u8fdb\u8de8\u5b66\u79d1\u52aa\u529b\uff0c\u5c06\u56e0\u679c\u6982\u5ff5\u548c\u57fa\u7840\u6a21\u578b\u7ed3\u5408\u8d77\u6765\uff0c\u5f00\u53d1\u53ef\u9760\u7684AI\u4f19\u4f34\u4ee5\u63a8\u52a8\u751f\u7269\u533b\u5b66\u8fdb\u6b65\u3002"}}
{"id": "2505.16494", "pdf": "https://arxiv.org/pdf/2505.16494", "abs": "https://arxiv.org/abs/2505.16494", "authors": ["Noga Amit", "Omer Reingold", "Guy N. Rothblum"], "title": "Accuracy vs. Accuracy: Computational Tradeoffs Between Classification Rates and Utility", "categories": ["cs.LG"], "comment": null, "summary": "We revisit the foundations of fairness and its interplay with utility and\nefficiency in settings where the training data contain richer labels, such as\nindividual types, rankings, or risk estimates, rather than just binary\noutcomes. In this context, we propose algorithms that achieve stronger notions\nof evidence-based fairness than are possible in standard supervised learning.\nOur methods support classification and ranking techniques that preserve\naccurate subpopulation classification rates, as suggested by the underlying\ndata distributions, across a broad class of classification rules and downstream\napplications. Furthermore, our predictors enable loss minimization, whether\naimed at maximizing utility or in the service of fair treatment.\n  Complementing our algorithmic contributions, we present impossibility results\ndemonstrating that simultaneously achieving accurate classification rates and\noptimal loss minimization is, in some cases, computationally infeasible. Unlike\nprior impossibility results, our notions are not inherently in conflict and are\nsimultaneously satisfied by the Bayes-optimal predictor. Furthermore, we show\nthat each notion can be satisfied individually via efficient learning. Our\nseparation thus stems from the computational hardness of learning a\nsufficiently good approximation of the Bayes-optimal predictor. These\ncomputational impossibilities present a choice between two natural and\nattainable notions of accuracy that could both be motivated by fairness.", "AI": {"tldr": "\u5728\u5305\u542b\u66f4\u4e30\u5bcc\u6807\u7b7e\uff08\u5982\u4e2a\u4f53\u7c7b\u578b\u3001\u6392\u540d\u6216\u98ce\u9669\u4f30\u8ba1\uff09\u800c\u975e\u4ec5\u4ec5\u662f\u4e8c\u5143\u7ed3\u679c\u7684\u8bad\u7ec3\u6570\u636e\u73af\u5883\u4e0b\uff0c\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86\u516c\u5e73\u6027\u53ca\u5176\u4e0e\u6548\u7528\u548c\u6548\u7387\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u7b97\u6cd5\uff0c\u53ef\u4ee5\u5b9e\u73b0\u6bd4\u6807\u51c6\u76d1\u7763\u5b66\u4e60\u66f4\u5f3a\u7684\u57fa\u4e8e\u8bc1\u636e\u7684\u516c\u5e73\u6027\u6982\u5ff5\uff0c\u5e76\u652f\u6301\u51c6\u786e\u7684\u5b50\u7fa4\u4f53\u5206\u7c7b\u7387\u7684\u5206\u7c7b\u548c\u6392\u540d\u6280\u672f\u3002\u6b64\u5916\uff0c\u8fd8\u5c55\u793a\u4e86\u540c\u65f6\u5b9e\u73b0\u51c6\u786e\u5206\u7c7b\u7387\u548c\u6700\u4f18\u635f\u5931\u6700\u5c0f\u5316\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u662f\u8ba1\u7b97\u4e0d\u53ef\u884c\u7684\u3002", "motivation": "\u73b0\u6709\u516c\u5e73\u6027\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u6807\u51c6\u76d1\u7763\u5b66\u4e60\u4e2d\u4e8c\u5143\u7ed3\u679c\u7684\u6570\u636e\u4e0a\uff0c\u4f46\u73b0\u5b9e\u4e2d\u7684\u6570\u636e\u5f80\u5f80\u5305\u542b\u66f4\u4e30\u5bcc\u7684\u6807\u7b7e\u4fe1\u606f\uff0c\u4f8b\u5982\u4e2a\u4f53\u7c7b\u578b\u3001\u6392\u540d\u6216\u98ce\u9669\u4f30\u8ba1\u3002\u8fd9\u4e9b\u4fe1\u606f\u4e3a\u5b9e\u73b0\u66f4\u5f3a\u7684\u57fa\u4e8e\u8bc1\u636e\u7684\u516c\u5e73\u6027\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u63a2\u7d22\u5982\u4f55\u5229\u7528\u8fd9\u4e9b\u4e30\u5bcc\u6807\u7b7e\u6765\u6539\u8fdb\u516c\u5e73\u6027\u548c\u6548\u7528\u7684\u5e73\u8861\u3002", "method": "1. \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5229\u7528\u66f4\u4e30\u5bcc\u7684\u6570\u636e\u6807\u7b7e\uff08\u5982\u4e2a\u4f53\u7c7b\u578b\u3001\u6392\u540d\u6216\u98ce\u9669\u4f30\u8ba1\uff09\u6765\u5b9e\u73b0\u66f4\u5f3a\u7684\u57fa\u4e8e\u8bc1\u636e\u7684\u516c\u5e73\u6027\u3002\n2. \u8bbe\u8ba1\u4e86\u5206\u7c7b\u548c\u6392\u540d\u6280\u672f\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u51c6\u786e\u7684\u5b50\u7fa4\u4f53\u5206\u7c7b\u7387\u7684\u540c\u65f6\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u5206\u7c7b\u89c4\u5219\u548c\u4e0b\u6e38\u5e94\u7528\u3002\n3. \u5f00\u53d1\u4e86\u9884\u6d4b\u5668\uff0c\u652f\u6301\u635f\u5931\u6700\u5c0f\u5316\u4ee5\u6700\u5927\u5316\u6548\u7528\u6216\u5b9e\u73b0\u516c\u5e73\u5904\u7406\u3002\n4. \u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86\u540c\u65f6\u5b9e\u73b0\u51c6\u786e\u5206\u7c7b\u7387\u548c\u6700\u4f18\u635f\u5931\u6700\u5c0f\u5316\u7684\u8ba1\u7b97\u4e0d\u53ef\u884c\u6027\u3002\n5. \u63a2\u8ba8\u4e86\u4e24\u79cd\u81ea\u7136\u4e14\u53ef\u5b9e\u73b0\u7684\u51c6\u786e\u6027\u6982\u5ff5\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u5b83\u4eec\u90fd\u53ef\u4ee5\u7531\u516c\u5e73\u6027\u52a8\u673a\u9a71\u52a8\u3002", "result": "1. \u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5b9e\u73b0\u4e86\u6bd4\u6807\u51c6\u76d1\u7763\u5b66\u4e60\u66f4\u5f3a\u7684\u57fa\u4e8e\u8bc1\u636e\u7684\u516c\u5e73\u6027\u3002\n2. \u5728\u4fdd\u6301\u51c6\u786e\u7684\u5b50\u7fa4\u4f53\u5206\u7c7b\u7387\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\u3002\n3. \u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u540c\u65f6\u6ee1\u8db3\u51c6\u786e\u5206\u7c7b\u7387\u548c\u6700\u4f18\u635f\u5931\u6700\u5c0f\u5316\u7684\u8ba1\u7b97\u56f0\u96be\u6027\u3002\n4. \u53d1\u73b0\u4e24\u79cd\u51c6\u786e\u6027\u6982\u5ff5\u53ef\u4ee5\u901a\u8fc7\u9ad8\u6548\u5b66\u4e60\u5206\u522b\u5b9e\u73b0\uff0c\u4f46\u540c\u65f6\u5b9e\u73b0\u5b58\u5728\u6311\u6218\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u5229\u7528\u4e30\u5bcc\u6570\u636e\u6807\u7b7e\u5b9e\u73b0\u66f4\u5f3a\u516c\u5e73\u6027\u7684\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u4e86\u540c\u65f6\u5b9e\u73b0\u51c6\u786e\u5206\u7c7b\u7387\u548c\u6700\u4f18\u635f\u5931\u6700\u5c0f\u5316\u7684\u8ba1\u7b97\u969c\u788d\u3002\u8fd9\u8868\u660e\uff0c\u5728\u516c\u5e73\u6027\u7814\u7a76\u4e2d\u9700\u8981\u5728\u4e24\u79cd\u81ea\u7136\u4e14\u53ef\u5b9e\u73b0\u7684\u51c6\u786e\u6027\u6982\u5ff5\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002"}}
{"id": "2505.16997", "pdf": "https://arxiv.org/pdf/2505.16997", "abs": "https://arxiv.org/abs/2505.16997", "authors": ["Rui Ye", "Xiangrui Liu", "Qimin Wu", "Xianghe Pang", "Zhenfei Yin", "Lei Bai", "Siheng Chen"], "title": "X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs", "categories": ["cs.AI", "cs.CL", "cs.MA"], "comment": "19 pages, 5 figures", "summary": "LLM-based multi-agent systems (MAS) extend the capabilities of single LLMs by\nenabling cooperation among multiple specialized agents. However, most existing\nMAS frameworks rely on a single LLM to drive all agents, constraining the\nsystem's intelligence to the limit of that model. This paper explores the\nparadigm of heterogeneous LLM-driven MAS (X-MAS), where agents are powered by\ndiverse LLMs, elevating the system's potential to the collective intelligence\nof diverse LLMs. We introduce X-MAS-Bench, a comprehensive testbed designed to\nevaluate the performance of various LLMs across different domains and\nMAS-related functions. As an extensive empirical study, we assess 27 LLMs\nacross 5 domains (encompassing 21 test sets) and 5 functions, conducting over\n1.7 million evaluations to identify optimal model selections for each\ndomain-function combination. Building on these findings, we demonstrate that\ntransitioning from homogeneous to heterogeneous LLM-driven MAS can\nsignificantly enhance system performance without requiring structural redesign.\nSpecifically, in a chatbot-only MAS scenario, the heterogeneous configuration\nyields up to 8.4\\% performance improvement on the MATH dataset. In a mixed\nchatbot-reasoner scenario, the heterogeneous MAS could achieve a remarkable\n47\\% performance boost on the AIME dataset. Our results underscore the\ntransformative potential of heterogeneous LLMs in MAS, highlighting a promising\navenue for advancing scalable, collaborative AI systems.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86\u5f02\u6784LLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08X-MAS\uff09\u8303\u5f0f\uff0c\u901a\u8fc7\u5f15\u5165X-MAS-Bench\u6d4b\u8bd5\u5e73\u53f0\u8bc4\u4f3027\u4e2aLLM\u5728\u4e0d\u540c\u9886\u57df\u548c\u529f\u80fd\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u8bc1\u660e\u4ece\u540c\u8d28\u5230\u5f02\u6784LLM\u9a71\u52a8\u7684MAS\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u591a\u6570\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u6846\u67b6\u4f9d\u8d56\u5355\u4e00LLM\u9a71\u52a8\u6240\u6709\u667a\u80fd\u4f53\uff0c\u9650\u5236\u4e86\u7cfb\u7edf\u7684\u667a\u80fd\u6c34\u5e73\u3002\u4e3a\u4e86\u7a81\u7834\u8fd9\u4e00\u9650\u5236\uff0c\u672c\u6587\u63a2\u7d22\u4e86\u7531\u591a\u6837LLM\u9a71\u52a8\u7684\u5f02\u6784MAS\uff08X-MAS\uff09\u7684\u53ef\u80fd\u6027\u3002", "method": "1. \u63d0\u51faX-MAS-Bench\uff0c\u4e00\u4e2a\u5168\u9762\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e0d\u540cLLM\u5728\u591a\u4e2a\u9886\u57df\u548cMAS\u76f8\u5173\u529f\u80fd\u4e0a\u7684\u8868\u73b0\u3002\n2. \u5bf927\u4e2aLLM\u8fdb\u884c\u8d85\u8fc7170\u4e07\u6b21\u8bc4\u4f30\uff0c\u6db5\u76d65\u4e2a\u9886\u57df\uff0821\u4e2a\u6d4b\u8bd5\u96c6\uff09\u548c5\u4e2a\u529f\u80fd\u3002\n3. \u5206\u6790\u4ece\u540c\u8d28\u5230\u5f02\u6784LLM\u9a71\u52a8MAS\u7684\u6027\u80fd\u6539\u8fdb\uff0c\u5e76\u5728\u7279\u5b9a\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u5176\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff1a\n- \u5728\u4ec5\u804a\u5929\u673a\u5668\u4eba\u573a\u666f\u4e2d\uff0c\u5f02\u6784\u914d\u7f6e\u5728MATH\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u4e868.4%\u7684\u6027\u80fd\u3002\n- \u5728\u6df7\u5408\u804a\u5929\u673a\u5668\u4eba-\u63a8\u7406\u5668\u573a\u666f\u4e2d\uff0c\u5f02\u6784MAS\u5728AIME\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8647%\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u5f02\u6784LLM\u9a71\u52a8\u7684MAS\u5177\u6709\u6781\u5927\u7684\u6f5c\u529b\uff0c\u65e0\u9700\u7ed3\u6784\u91cd\u65b0\u8bbe\u8ba1\u5373\u53ef\u663e\u8457\u63d0\u9ad8\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u53ef\u6269\u5c55\u3001\u534f\u4f5c\u578bAI\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u65b9\u5411\u3002"}}
{"id": "2505.16516", "pdf": "https://arxiv.org/pdf/2505.16516", "abs": "https://arxiv.org/abs/2505.16516", "authors": ["Majid Mohammadi", "Siu Lun Chau", "Krikamol Muandet"], "title": "Computing Exact Shapley Values in Polynomial Time for Product-Kernel Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Kernel methods are widely used in machine learning due to their flexibility\nand expressive power. However, their black-box nature poses significant\nchallenges to interpretability, limiting their adoption in high-stakes\napplications. Shapley value-based feature attribution techniques, such as SHAP\nand kernel-specific variants like RKHS-SHAP, offer a promising path toward\nexplainability. Yet, computing exact Shapley values remains computationally\nintractable in general, motivating the development of various approximation\nschemes. In this work, we introduce PKeX-Shapley, a novel algorithm that\nutilizes the multiplicative structure of product kernels to enable the exact\ncomputation of Shapley values in polynomial time. We show that product-kernel\nmodels admit a functional decomposition that allows for a recursive formulation\nof Shapley values. This decomposition not only yields computational efficiency\nbut also enhances interpretability in kernel-based learning. We also\ndemonstrate how our framework can be generalized to explain kernel-based\nstatistical discrepancies such as the Maximum Mean Discrepancy (MMD) and the\nHilbert-Schmidt Independence Criterion (HSIC), thus offering new tools for\ninterpretable statistical inference.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPKeX-Shapley\u7684\u65b0\u7b97\u6cd5\uff0c\u5229\u7528\u79ef\u6838\u7684\u4e58\u6cd5\u7ed3\u6784\u5b9e\u73b0\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u5185Shapley\u503c\u7684\u786e\u5207\u8ba1\u7b97\u3002\u6b64\u65b9\u6cd5\u63d0\u9ad8\u4e86\u57fa\u4e8e\u6838\u7684\u5b66\u4e60\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u53ef\u63a8\u5e7f\u5230\u89e3\u91ca\u6838\u57fa\u7edf\u8ba1\u5dee\u5f02\uff08\u5982MMD\u548cHSIC\uff09\u3002", "motivation": "\u6838\u65b9\u6cd5\u5728\u673a\u5668\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u7531\u4e8e\u5176\u9ed1\u7bb1\u6027\u8d28\uff0c\u53ef\u89e3\u91ca\u6027\u53d7\u5230\u9650\u5236\u3002\u867d\u7136\u57fa\u4e8eShapley\u503c\u7684\u7279\u5f81\u5f52\u56e0\u6280\u672f\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u6027\u7684\u8def\u5f84\uff0c\u4f46\u7cbe\u786e\u8ba1\u7b97Shapley\u503c\u901a\u5e38\u8ba1\u7b97\u4e0a\u4e0d\u53ef\u884c\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u8fd1\u4f3c\u65b9\u6848\u3002", "method": "\u8bba\u6587\u5f15\u5165\u4e86PKeX-Shapley\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u5229\u7528\u79ef\u6838\u6a21\u578b\u7684\u529f\u80fd\u5206\u89e3\u9012\u5f52\u516c\u5f0f\uff0c\u80fd\u591f\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u5b9e\u73b0Shapley\u503c\u7684\u786e\u5207\u8ba1\u7b97\u3002\u6b64\u5916\uff0c\u6846\u67b6\u8fd8\u53ef\u4ee5\u63a8\u5e7f\u5230\u89e3\u91ca\u6838\u57fa\u7edf\u8ba1\u5dee\u5f02\uff0c\u4f8b\u5982\u6700\u5927\u5747\u503c\u5dee\u5f02\uff08MMD\uff09\u548cHilbert-Schmidt\u72ec\u7acb\u6027\u6807\u51c6\uff08HSIC\uff09\u3002", "result": "PKeX-Shapley\u7b97\u6cd5\u4e0d\u4ec5\u5b9e\u73b0\u4e86Shapley\u503c\u7684\u9ad8\u6548\u8ba1\u7b97\uff0c\u8fd8\u589e\u5f3a\u4e86\u57fa\u4e8e\u6838\u7684\u5b66\u4e60\u7684\u53ef\u89e3\u91ca\u6027\u3002\u5e76\u4e14\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u6838\u57fa\u7edf\u8ba1\u5de5\u5177\u4e2d\u3002", "conclusion": "PKeX-Shapley\u4e3a\u57fa\u4e8e\u6838\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u3001\u9ad8\u6548\u7684\u89e3\u91ca\u5de5\u5177\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u8fd9\u4e9b\u6a21\u578b\u7684\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u62d3\u5bbd\u4e86\u5176\u5728\u7edf\u8ba1\u63a8\u65ad\u4e2d\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2505.16527", "pdf": "https://arxiv.org/pdf/2505.16527", "abs": "https://arxiv.org/abs/2505.16527", "authors": ["Mohamed Amine Ketata", "David L\u00fcdke", "Leo Schwinn", "Stephan G\u00fcnnemann"], "title": "Joint Relational Database Generation via Graph-Conditional Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "Building generative models for relational databases (RDBs) is important for\napplications like privacy-preserving data release and augmenting real datasets.\nHowever, most prior work either focuses on single-table generation or relies on\nautoregressive factorizations that impose a fixed table order and generate\ntables sequentially. This approach limits parallelism, restricts flexibility in\ndownstream applications like missing value imputation, and compounds errors due\nto commonly made conditional independence assumptions. We propose a\nfundamentally different approach: jointly modeling all tables in an RDB without\nimposing any order. By using a natural graph representation of RDBs, we propose\nthe Graph-Conditional Relational Diffusion Model (GRDM). GRDM leverages a graph\nneural network to jointly denoise row attributes and capture complex\ninter-table dependencies. Extensive experiments on six real-world RDBs\ndemonstrate that our approach substantially outperforms autoregressive\nbaselines in modeling multi-hop inter-table correlations and achieves\nstate-of-the-art performance on single-table fidelity metrics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u751f\u6210\u6a21\u578bGRDM\uff0c\u7528\u4e8e\u5173\u7cfb\u6570\u636e\u5e93\u7684\u6240\u6709\u8868\u7684\u8054\u5408\u5efa\u6a21\uff0c\u65e0\u9700\u56fa\u5b9a\u987a\u5e8f\u3002\u8be5\u6a21\u578b\u5728\u591a\u8868\u5173\u8054\u6027\u548c\u5355\u8868\u4fdd\u771f\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u81ea\u56de\u5f52\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u6210\u6a21\u578b\u8981\u4e48\u4e13\u6ce8\u4e8e\u5355\u8868\u751f\u6210\uff0c\u8981\u4e48\u4f9d\u8d56\u4e8e\u81ea\u56de\u5f52\u5206\u89e3\uff0c\u8fd9\u9650\u5236\u4e86\u5e76\u884c\u6027\u3001\u4e0b\u6e38\u5e94\u7528\u7075\u6d3b\u6027\uff0c\u5e76\u56e0\u6761\u4ef6\u72ec\u7acb\u5047\u8bbe\u5bfc\u81f4\u8bef\u5dee\u7d2f\u79ef\u3002", "method": "\u901a\u8fc7\u4f7f\u7528RDBs\u7684\u81ea\u7136\u56fe\u8868\u793a\uff0c\u63d0\u51fa\u4e86Graph-Conditional Relational Diffusion Model (GRDM)\uff0c\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u6765\u8054\u5408\u53bb\u566a\u884c\u5c5e\u6027\u5e76\u6355\u6349\u590d\u6742\u7684\u8de8\u8868\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u5728\u516d\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u5173\u7cfb\u6570\u636e\u5e93\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5efa\u6a21\u591a\u8df3\u8de8\u8868\u5173\u8054\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u81ea\u56de\u5f52\u57fa\u7ebf\uff0c\u5e76\u5728\u5355\u8868\u4fdd\u771f\u5ea6\u5ea6\u91cf\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "GRDM\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u56fa\u5b9a\u987a\u5e8f\u7684\u8054\u5408\u5efa\u6a21\u6240\u6709RDB\u8868\u7684\u65b9\u6cd5\uff0c\u5c55\u73b0\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u7075\u6d3b\u6027\u3002"}}
{"id": "2505.16531", "pdf": "https://arxiv.org/pdf/2505.16531", "abs": "https://arxiv.org/abs/2505.16531", "authors": ["Alejandro Moreno Arcas", "Albert Sanchis", "Jorge Civera", "Alfons Juan"], "title": "HOFT: Householder Orthogonal Fine-tuning", "categories": ["cs.LG"], "comment": null, "summary": "Adaptation of foundation models using low-rank methods is a widespread\napproach. Another way to adapt these models is to employ orthogonal fine-tuning\nmethods, which are less time and memory efficient despite their good\ngeneralization properties. In this work, we propose Householder Orthogonal\nFine-tuning (HOFT), a novel orthogonal fine-tuning method that aims to\nalleviate time and space complexity. Moreover, some theoretical properties of\nthe orthogonal fine-tuning paradigm are explored. From this exploration, Scaled\nHouseholder Orthogonal Fine-tuning (SHOFT) is proposed. Both HOFT and SHOFT are\nevaluated in downstream tasks, namely commonsense reasoning, machine\ntranslation, subject-driven generation and mathematical reasoning. Compared\nwith state-of-the-art adaptation methods, HOFT and SHOFT show comparable or\nbetter results.", "AI": {"tldr": "\u63d0\u51faHOFT\u548cSHOFT\u4e24\u79cd\u65b0\u578b\u6b63\u4ea4\u5fae\u8c03\u65b9\u6cd5\uff0c\u7f13\u89e3\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u5e76\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u7840\u6a21\u578b\u9002\u5e94\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4f4e\u79e9\u65b9\u6cd5\u6216\u6b63\u4ea4\u5fae\u8c03\u65b9\u6cd5\uff0c\u4f46\u4f20\u7edf\u6b63\u4ea4\u5fae\u8c03\u65b9\u6cd5\u6548\u7387\u8f83\u4f4e\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51faHouseholder Orthogonal Fine-tuning (HOFT) \u548c Scaled Householder Orthogonal Fine-tuning (SHOFT)\uff0c\u901a\u8fc7\u63a2\u7d22\u6b63\u4ea4\u5fae\u8c03\u8303\u5f0f\u7684\u7406\u8bba\u6027\u8d28\u6765\u964d\u4f4e\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u3002", "result": "HOFT\u548cSHOFT\u5728\u5e38\u8bc6\u63a8\u7406\u3001\u673a\u5668\u7ffb\u8bd1\u3001\u4e3b\u9898\u9a71\u52a8\u751f\u6210\u548c\u6570\u5b66\u63a8\u7406\u7b49\u4e0b\u6e38\u4efb\u52a1\u4e2d\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u9002\u5e94\u65b9\u6cd5\u8868\u73b0\u51fa\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u7ed3\u679c\u3002", "conclusion": "HOFT\u548cSHOFT\u6709\u6548\u7f13\u89e3\u4e86\u6b63\u4ea4\u5fae\u8c03\u7684\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u5e76\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2505.16549", "pdf": "https://arxiv.org/pdf/2505.16549", "abs": "https://arxiv.org/abs/2505.16549", "authors": ["Trung V. Phan", "George A. Kevrekidis", "Soledad Villar", "Yannis G. Kevrekidis", "Juan M. Bello-Rivas"], "title": "Towards Coordinate- and Dimension-Agnostic Machine Learning for Partial Differential Equations", "categories": ["cs.LG", "35Q92, 68T07", "I.2.6; G.1.8"], "comment": null, "summary": "The machine learning methods for data-driven identification of partial\ndifferential equations (PDEs) are typically defined for a given number of\nspatial dimensions and a choice of coordinates the data have been collected in.\nThis dependence prevents the learned evolution equation from generalizing to\nother spaces. In this work, we reformulate the problem in terms of coordinate-\nand dimension-independent representations, paving the way toward what we call\n``spatially liberated\" PDE learning. To this end, we employ a machine learning\napproach to predict the evolution of scalar field systems expressed in the\nformalism of exterior calculus, which is coordinate-free and immediately\ngeneralizes to arbitrary dimensions by construction. We demonstrate the\nperformance of this approach in the FitzHugh-Nagumo and Barkley\nreaction-diffusion models, as well as the Patlak-Keller-Segel model informed by\nin-situ chemotactic bacteria observations. We provide extensive numerical\nexperiments that demonstrate that our approach allows for seamless transitions\nacross various spatial contexts. We show that the field dynamics learned in one\nspace can be used to make accurate predictions in other spaces with different\ndimensions, coordinate systems, boundary conditions, and curvatures.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5916\u5fae\u79ef\u5206\u5f62\u5f0f\u4e3b\u4e49\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4b\u6807\u91cf\u573a\u7cfb\u7edf\u7684\u6f14\u5316\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u5750\u6807\u548c\u7ef4\u5ea6\u4e0a\u72ec\u7acb\uff0c\u80fd\u591f\u5b9e\u73b0\u201c\u7a7a\u95f4\u89e3\u653e\u201d\u7684\u504f\u5fae\u5206\u65b9\u7a0b\uff08PDE\uff09\u5b66\u4e60\u3002\u901a\u8fc7\u5728FitzHugh-Nagumo\u3001Barkley\u53cd\u5e94\u6269\u6563\u6a21\u578b\u4ee5\u53caPatlak-Keller-Segel\u6a21\u578b\u4e2d\u7684\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5728\u4e0d\u540c\u7a7a\u95f4\u6761\u4ef6\u4e0b\u65e0\u7f1d\u8fc7\u6e21\u5e76\u51c6\u786e\u9884\u6d4b\u3002", "motivation": "\u73b0\u6709\u7684\u6570\u636e\u9a71\u52a8\u504f\u5fae\u5206\u65b9\u7a0b\u8bc6\u522b\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u7279\u5b9a\u7684\u7a7a\u95f4\u7ef4\u5ea6\u548c\u6570\u636e\u91c7\u96c6\u7684\u5750\u6807\u7cfb\uff0c\u8fd9\u9650\u5236\u4e86\u6240\u5b66\u8fdb\u5316\u65b9\u7a0b\u5411\u5176\u4ed6\u7a7a\u95f4\u7684\u6cdb\u5316\u80fd\u529b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u4e0e\u5750\u6807\u548c\u7ef4\u5ea6\u65e0\u5173\u7684\u5b66\u4e60\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u8005\u91c7\u7528\u4e86\u4e00\u79cd\u57fa\u4e8e\u5916\u5fae\u79ef\u5206\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u8fd9\u79cd\u5f62\u5f0f\u4e3b\u4e49\u662f\u65e0\u5750\u6807\u7684\uff0c\u5e76\u4e14\u53ef\u4ee5\u7acb\u5373\u63a8\u5e7f\u5230\u4efb\u610f\u7ef4\u5ea6\u3002\u901a\u8fc7\u5728FitzHugh-Nagumo\u3001Barkley\u53cd\u5e94\u6269\u6563\u6a21\u578b\u4ee5\u53ca\u7531\u539f\u4f4d\u8d8b\u5316\u7ec6\u83cc\u89c2\u6d4b\u4fe1\u606f\u7684Patlak-Keller-Segel\u6a21\u578b\u4e2d\u8fdb\u884c\u6570\u503c\u5b9e\u9a8c\u6765\u9a8c\u8bc1\u8be5\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5141\u8bb8\u5728\u5404\u79cd\u7a7a\u95f4\u4e0a\u4e0b\u6587\u4e2d\u8fdb\u884c\u65e0\u7f1d\u8f6c\u6362\uff0c\u80fd\u591f\u5728\u4e0d\u540c\u7ef4\u5ea6\u3001\u5750\u6807\u7cfb\u3001\u8fb9\u754c\u6761\u4ef6\u548c\u66f2\u7387\u7684\u7a7a\u95f4\u4e2d\u8fdb\u884c\u51c6\u786e\u9884\u6d4b\u3002", "conclusion": "\u63d0\u51fa\u7684\u201c\u7a7a\u95f4\u89e3\u653e\u201dPDE\u5b66\u4e60\u65b9\u6cd5\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u5bf9\u4e0d\u540c\u7a7a\u95f4\u6761\u4ef6\u4e0b\u573a\u52a8\u529b\u5b66\u7684\u6709\u6548\u9884\u6d4b\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2505.16563", "pdf": "https://arxiv.org/pdf/2505.16563", "abs": "https://arxiv.org/abs/2505.16563", "authors": ["Chen Gong", "Rui Xing", "Zhenzhe Zheng", "Fan Wu"], "title": "A Two-Stage Data Selection Framework for Data-Efficient Model Training on Edge Devices", "categories": ["cs.LG"], "comment": null, "summary": "The demand for machine learning (ML) model training on edge devices is\nescalating due to data privacy and personalized service needs. However, we\nobserve that current on-device model training is hampered by the\nunder-utilization of on-device data, due to low training throughput, limited\nstorage and diverse data importance. To improve data resource utilization, we\npropose a two-stage data selection framework {\\sf Titan} to select the most\nimportant data batch from streaming data for model training with guaranteed\nefficiency and effectiveness. Specifically, in the first stage, {\\sf Titan}\nfilters out a candidate dataset with potentially high importance in a\ncoarse-grained manner.In the second stage of fine-grained selection, we propose\na theoretically optimal data selection strategy to identify the data batch with\nthe highest model performance improvement to current training round. To further\nenhance time-and-resource efficiency, {\\sf Titan} leverages a pipeline to\nco-execute data selection and model training, and avoids resource conflicts by\nexploiting idle computing resources. We evaluate {\\sf Titan} on real-world edge\ndevices and three representative edge computing tasks with diverse models and\ndata modalities. Empirical results demonstrate that {\\sf Titan} achieves up to\n$43\\%$ reduction in training time and $6.2\\%$ increase in final accuracy with\nminor system overhead, such as data processing delay, memory footprint and\nenergy consumption.", "AI": {"tldr": "\u7531\u4e8e\u6570\u636e\u9690\u79c1\u548c\u4e2a\u6027\u5316\u670d\u52a1\u9700\u6c42\uff0c\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u9700\u6c42\u6b63\u5728\u589e\u52a0\u3002\u7136\u800c\uff0c\u5f53\u524d\u7684\u8bbe\u5907\u4e0a\u6a21\u578b\u8bad\u7ec3\u56e0\u4f4e\u8bad\u7ec3\u541e\u5410\u91cf\u3001\u6709\u9650\u5b58\u50a8\u548c\u6570\u636e\u91cd\u8981\u6027\u591a\u6837\u800c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u8bbe\u5907\u6570\u636e\u3002\u4e3a\u63d0\u9ad8\u6570\u636e\u8d44\u6e90\u5229\u7528\u7387\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u6570\u636e\u9009\u62e9\u6846\u67b6Titan\uff0c\u4ee5\u4ece\u6d41\u6570\u636e\u4e2d\u9009\u62e9\u6700\u91cd\u8981\u7684\u6570\u636e\u6279\u6b21\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\uff0c\u4fdd\u8bc1\u6548\u7387\u548c\u6548\u679c\u3002Titan\u901a\u8fc7\u7c97\u7c92\u5ea6\u8fc7\u6ee4\u5019\u9009\u6570\u636e\u96c6\u548c\u7ec6\u7c92\u5ea6\u9009\u62e9\u6700\u9ad8\u6027\u80fd\u63d0\u5347\u7684\u6570\u636e\u6279\u6b21\uff0c\u5e76\u5229\u7528\u7ba1\u9053\u6280\u672f\u534f\u540c\u6267\u884c\u6570\u636e\u9009\u62e9\u548c\u6a21\u578b\u8bad\u7ec3\uff0c\u907f\u514d\u8d44\u6e90\u51b2\u7a81\u3002\u5b9e\u9a8c\u8868\u660e\uff0cTitan\u53ef\u5c06\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c1143%\uff0c\u6700\u7ec8\u51c6\u786e\u7387\u63d0\u9ad86.2%\uff0c\u7cfb\u7edf\u5f00\u9500\u8f83\u5c0f\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u8bad\u7ec3\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u7531\u4e8e\u4f4e\u8bad\u7ec3\u541e\u5410\u91cf\u3001\u6709\u9650\u5b58\u50a8\u548c\u6570\u636e\u91cd\u8981\u6027\u591a\u6837\uff0c\u5f53\u524d\u8bbe\u5907\u4e0a\u7684\u6a21\u578b\u8bad\u7ec3\u672a\u80fd\u5145\u5206\u5229\u7528\u8bbe\u5907\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u6570\u636e\u9009\u62e9\u6846\u67b6Titan\uff1a\u7b2c\u4e00\u9636\u6bb5\u7c97\u7c92\u5ea6\u8fc7\u6ee4\u51fa\u5177\u6709\u6f5c\u5728\u9ad8\u91cd\u8981\u6027\u7684\u5019\u9009\u6570\u636e\u96c6\uff1b\u7b2c\u4e8c\u9636\u6bb5\u7ec6\u7c92\u5ea6\u9009\u62e9\u5177\u6709\u6700\u9ad8\u6a21\u578b\u6027\u80fd\u63d0\u5347\u7684\u6570\u636e\u6279\u6b21\u3002\u6b64\u5916\uff0cTitan\u5229\u7528\u7ba1\u9053\u6280\u672f\u534f\u540c\u6267\u884c\u6570\u636e\u9009\u62e9\u548c\u6a21\u578b\u8bad\u7ec3\uff0c\u907f\u514d\u8d44\u6e90\u51b2\u7a81\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eTitan\u53ef\u4ee5\u5c06\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c1143%\uff0c\u6700\u7ec8\u51c6\u786e\u7387\u63d0\u9ad86.2%\uff0c\u540c\u65f6\u7cfb\u7edf\u5f00\u9500\uff08\u5982\u6570\u636e\u5904\u7406\u5ef6\u8fdf\u3001\u5185\u5b58\u5360\u7528\u548c\u80fd\u8017\uff09\u8f83\u5c0f\u3002", "conclusion": "Titan\u6846\u67b6\u6709\u6548\u63d0\u9ad8\u4e86\u8bbe\u5907\u4e0a\u6570\u636e\u8d44\u6e90\u7684\u5229\u7528\u7387\uff0c\u5728\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u7684\u540c\u65f6\u63d0\u5347\u4e86\u6a21\u578b\u6700\u7ec8\u51c6\u786e\u7387\uff0c\u4e14\u7cfb\u7edf\u5f00\u9500\u8f83\u4f4e\uff0c\u9002\u5408\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2505.16567", "pdf": "https://arxiv.org/pdf/2505.16567", "abs": "https://arxiv.org/abs/2505.16567", "authors": ["Thibaud Gloaguen", "Mark Vero", "Robin Staab", "Martin Vechev"], "title": "Finetuning-Activated Backdoors in LLMs", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Finetuning openly accessible Large Language Models (LLMs) has become standard\npractice for achieving task-specific performance improvements. Until now,\nfinetuning has been regarded as a controlled and secure process in which\ntraining on benign datasets led to predictable behaviors. In this paper, we\ndemonstrate for the first time that an adversary can create poisoned LLMs that\ninitially appear benign but exhibit malicious behaviors once finetuned by\ndownstream users. To this end, our proposed attack, FAB (Finetuning-Activated\nBackdoor), poisons an LLM via meta-learning techniques to simulate downstream\nfinetuning, explicitly optimizing for the emergence of malicious behaviors in\nthe finetuned models. At the same time, the poisoned LLM is regularized to\nretain general capabilities and to exhibit no malicious behaviors prior to\nfinetuning. As a result, when users finetune the seemingly benign model on\ntheir own datasets, they unknowingly trigger its hidden backdoor behavior. We\ndemonstrate the effectiveness of FAB across multiple LLMs and three target\nbehaviors: unsolicited advertising, refusal, and jailbreakability.\nAdditionally, we show that FAB-backdoors are robust to various finetuning\nchoices made by the user (e.g., dataset, number of steps, scheduler). Our\nfindings challenge prevailing assumptions about the security of finetuning,\nrevealing yet another critical attack vector exploiting the complexities of\nLLMs.", "AI": {"tldr": "\u7814\u7a76\u5c55\u793a\u4e86\u901a\u8fc7\u5fae\u8c03\u6fc0\u6d3b\u540e\u95e8\uff08FAB\uff09\u653b\u51fb\uff0c\u53ef\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5fae\u8c03\u540e\u8868\u73b0\u51fa\u6076\u610f\u884c\u4e3a\uff0c\u6311\u6218\u4e86\u5fae\u8c03\u8fc7\u7a0b\u7684\u5b89\u5168\u6027\u5047\u8bbe\u3002", "motivation": "\u5c3d\u7ba1\u5fae\u8c03\u516c\u5f00\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u88ab\u8ba4\u4e3a\u662f\u63d0\u9ad8\u4efb\u52a1\u7279\u5b9a\u6027\u80fd\u7684\u6807\u51c6\u505a\u6cd5\uff0c\u4f46\u76ee\u524d\u5c1a\u672a\u6709\u4eba\u7814\u7a76\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u5b58\u5728\u7684\u5b89\u5168\u5a01\u80c1\u3002\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u7279\u5b9a\u65b9\u6cd5\u521b\u5efa\u770b\u4f3c\u65e0\u5bb3\u4f46\u5728\u4e0b\u6e38\u7528\u6237\u5fae\u8c03\u540e\u8868\u73b0\u51fa\u6076\u610f\u884c\u4e3a\u7684\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFAB\uff08Finetuning-Activated Backdoor\uff09\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u5143\u5b66\u4e60\u6280\u672f\u5bf9LLM\u8fdb\u884c\u6295\u6bd2\uff0c\u6a21\u62df\u4e0b\u6e38\u5fae\u8c03\u8fc7\u7a0b\uff0c\u4f18\u5316\u4ee5\u4f7f\u5fae\u8c03\u540e\u7684\u6a21\u578b\u51fa\u73b0\u6076\u610f\u884c\u4e3a\u3002\u540c\u65f6\uff0c\u786e\u4fdd\u6295\u6bd2\u524d\u7684LLM\u4fdd\u6301\u6b63\u5e38\u529f\u80fd\u4e14\u4e0d\u8868\u73b0\u51fa\u4efb\u4f55\u6076\u610f\u884c\u4e3a\u3002", "result": "FAB\u653b\u51fb\u5728\u591a\u4e2aLLM\u548c\u4e09\u79cd\u76ee\u6807\u6076\u610f\u884c\u4e3a\uff08\u672a\u7ecf\u8bf7\u6c42\u7684\u5e7f\u544a\u3001\u62d2\u7edd\u670d\u52a1\u548c\u8d8a\u72f1\u80fd\u529b\uff09\u4e0a\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff0c\u5e76\u4e14\u8be5\u540e\u95e8\u5bf9\u7528\u6237\u4e0d\u540c\u7684\u5fae\u8c03\u9009\u62e9\uff08\u5982\u6570\u636e\u96c6\u3001\u6b65\u9aa4\u6570\u3001\u8c03\u5ea6\u5668\u7b49\uff09\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5fae\u8c03\u8fc7\u7a0b\u53ef\u80fd\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u63ed\u793a\u4e86LLMs\u590d\u6742\u6027\u5e26\u6765\u7684\u65b0\u653b\u51fb\u5411\u91cf\uff0c\u6311\u6218\u4e86\u5173\u4e8e\u5fae\u8c03\u5b89\u5168\u6027\u7684\u4f20\u7edf\u5047\u8bbe\u3002"}}
{"id": "2505.16577", "pdf": "https://arxiv.org/pdf/2505.16577", "abs": "https://arxiv.org/abs/2505.16577", "authors": ["Yu Zuo", "Dalin Qin", "Yi Wang"], "title": "Large Language Model-Empowered Interactive Load Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "The growing complexity of power systems has made accurate load forecasting\nmore important than ever. An increasing number of advanced load forecasting\nmethods have been developed. However, the static design of current methods\noffers no mechanism for human-model interaction. As the primary users of\nforecasting models, system operators often find it difficult to understand and\napply these advanced models, which typically requires expertise in artificial\nintelligence (AI). This also prevents them from incorporating their experience\nand real-world contextual understanding into the forecasting process. Recent\nbreakthroughs in large language models (LLMs) offer a new opportunity to\naddress this issue. By leveraging their natural language understanding and\nreasoning capabilities, we propose an LLM-based multi-agent collaboration\nframework to bridge the gap between human operators and forecasting models. A\nset of specialized agents is designed to perform different tasks in the\nforecasting workflow and collaborate via a dedicated communication mechanism.\nThis framework embeds interactive mechanisms throughout the load forecasting\npipeline, reducing the technical threshold for non-expert users and enabling\nthe integration of human experience. Our experiments demonstrate that the\ninteractive load forecasting accuracy can be significantly improved when users\nprovide proper insight in key stages. Our cost analysis shows that the\nframework remains affordable, making it practical for real-world deployment.", "AI": {"tldr": "\u968f\u7740\u7535\u529b\u7cfb\u7edf\u590d\u6742\u6027\u7684\u589e\u52a0\uff0c\u51c6\u786e\u7684\u8d1f\u8377\u9884\u6d4b\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u7136\u800c\uff0c\u5f53\u524d\u9884\u6d4b\u65b9\u6cd5\u7684\u9759\u6001\u8bbe\u8ba1\u7f3a\u4e4f\u4eba\u673a\u4ea4\u4e92\u673a\u5236\uff0c\u5bfc\u81f4\u64cd\u4f5c\u4eba\u5458\u96be\u4ee5\u7406\u89e3\u548c\u5e94\u7528\u8fd9\u4e9b\u6a21\u578b\uff0c\u5e76\u4e14\u65e0\u6cd5\u5c06\u4ed6\u4eec\u7684\u7ecf\u9a8c\u878d\u5165\u9884\u6d4b\u8fc7\u7a0b\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u964d\u4f4e\u6280\u672f\u95e8\u69db\u5e76\u6574\u5408\u4eba\u7c7b\u7ecf\u9a8c\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u7528\u6237\u5728\u5173\u952e\u9636\u6bb5\u63d0\u4f9b\u9002\u5f53\u89c1\u89e3\u65f6\uff0c\u4e92\u52a8\u5f0f\u8d1f\u8377\u9884\u6d4b\u7cbe\u5ea6\u663e\u8457\u63d0\u9ad8\uff0c\u6210\u672c\u5206\u6790\u663e\u793a\u8be5\u6846\u67b6\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u53ef\u884c\u6027\u3002", "motivation": "\u7535\u529b\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\u4f7f\u5f97\u7cbe\u786e\u7684\u8d1f\u8377\u9884\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u4eba\u673a\u4ea4\u4e92\u673a\u5236\uff0c\u4f7f\u975eAI\u4e13\u5bb6\u7684\u64cd\u4f5c\u4eba\u5458\u96be\u4ee5\u4f7f\u7528\u5e76\u6574\u5408\u5176\u7ecf\u9a8c\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u5305\u542b\u4e00\u7ec4\u4e13\u95e8\u7684\u667a\u80fd\u4f53\u4ee5\u6267\u884c\u9884\u6d4b\u5de5\u4f5c\u6d41\u4e2d\u7684\u4e0d\u540c\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u4e13\u7528\u901a\u4fe1\u673a\u5236\u8fdb\u884c\u534f\u4f5c\u3002\u8be5\u6846\u67b6\u5728\u6574\u4e2a\u9884\u6d4b\u6d41\u7a0b\u4e2d\u5d4c\u5165\u4e86\u4ea4\u4e92\u673a\u5236\uff0c\u5141\u8bb8\u64cd\u4f5c\u4eba\u5458\u63d0\u4f9b\u8f93\u5165\u548c\u89c1\u89e3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u7528\u6237\u4e8e\u5173\u952e\u9636\u6bb5\u63d0\u4f9b\u9002\u5f53\u89c1\u89e3\u7684\u60c5\u51b5\u4e0b\uff0c\u4e92\u52a8\u5f0f\u8d1f\u8377\u9884\u6d4b\u7684\u51c6\u786e\u6027\u663e\u8457\u63d0\u9ad8\uff1b\u6210\u672c\u5206\u6790\u8868\u660e\u8be5\u6846\u67b6\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u90e8\u7f72\u662f\u7ecf\u6d4e\u53ef\u884c\u7684\u3002", "conclusion": "\u63d0\u51fa\u7684LLM\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\u6210\u529f\u964d\u4f4e\u4e86\u975e\u4e13\u5bb6\u7528\u6237\u7684\u4f7f\u7528\u95e8\u69db\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u4e3a\u5b9e\u9645\u7535\u529b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u4eba\u673a\u4ea4\u4e92\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.16581", "pdf": "https://arxiv.org/pdf/2505.16581", "abs": "https://arxiv.org/abs/2505.16581", "authors": ["Max Weltevrede", "Moritz A. Zanger", "Matthijs T. J. Spaan", "Wendelin B\u00f6hmer"], "title": "How Ensembles of Distilled Policies Improve Generalisation in Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In the zero-shot policy transfer setting in reinforcement learning, the goal\nis to train an agent on a fixed set of training environments so that it can\ngeneralise to similar, but unseen, testing environments. Previous work has\nshown that policy distillation after training can sometimes produce a policy\nthat outperforms the original in the testing environments. However, it is not\nyet entirely clear why that is, or what data should be used to distil the\npolicy. In this paper, we prove, under certain assumptions, a generalisation\nbound for policy distillation after training. The theory provides two practical\ninsights: for improved generalisation, you should 1) train an ensemble of\ndistilled policies, and 2) distil it on as much data from the training\nenvironments as possible. We empirically verify that these insights hold in\nmore general settings, when the assumptions required for the theory no longer\nhold. Finally, we demonstrate that an ensemble of policies distilled on a\ndiverse dataset can generalise significantly better than the original agent.", "AI": {"tldr": "\u5728\u5f3a\u5316\u5b66\u4e60\u7684\u96f6\u6837\u672c\u7b56\u7565\u8fc1\u79fb\u4e2d\uff0c\u672c\u6587\u7814\u7a76\u4e86\u8bad\u7ec3\u540e\u7b56\u7565\u84b8\u998f\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8bc1\u4f9d\u636e\uff0c\u8868\u660e\u4f7f\u7528\u591a\u6837\u6570\u636e\u8bad\u7ec3\u7684\u7b56\u7565\u96c6\u6210\u80fd\u591f\u663e\u8457\u63d0\u5347\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u8868\u660e\u8bad\u7ec3\u540e\u7684\u7b56\u7565\u84b8\u998f\u53ef\u4ee5\u63d0\u5347\u6d4b\u8bd5\u73af\u5883\u4e2d\u7684\u6027\u80fd\uff0c\u4f46\u5176\u539f\u56e0\u5c1a\u4e0d\u660e\u786e\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u84b8\u998f\u6240\u9700\u6570\u636e\u7684\u9009\u62e9\u6307\u5bfc\u3002", "method": "\u5728\u4e00\u5b9a\u5047\u8bbe\u6761\u4ef6\u4e0b\uff0c\u63a8\u5bfc\u51fa\u8bad\u7ec3\u540e\u7b56\u7565\u84b8\u998f\u7684\u6cdb\u5316\u754c\uff0c\u5e76\u63d0\u51fa\u4e24\u70b9\u6539\u8fdb\u5efa\u8bae\uff1a1) \u4f7f\u7528\u7b56\u7565\u96c6\u6210\uff1b2) \u4f7f\u7528\u5c3d\u53ef\u80fd\u591a\u7684\u8bad\u7ec3\u73af\u5883\u6570\u636e\u8fdb\u884c\u84b8\u998f\u3002\u968f\u540e\u5728\u66f4\u4e00\u822c\u7684\u8bbe\u7f6e\u4e0b\u9a8c\u8bc1\u8fd9\u4e9b\u5efa\u8bae\u7684\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u57fa\u4e8e\u591a\u6837\u5316\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u7b56\u7565\u96c6\u6210\u80fd\u591f\u5728\u6d4b\u8bd5\u73af\u5883\u4e2d\u663e\u8457\u4f18\u4e8e\u539f\u59cb\u4ee3\u7406\u3002", "conclusion": "\u7b56\u7565\u84b8\u998f\u53ef\u4ee5\u901a\u8fc7\u96c6\u6210\u5b66\u4e60\u548c\u5145\u5206\u5229\u7528\u8bad\u7ec3\u6570\u636e\u6765\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u96f6\u6837\u672c\u7b56\u7565\u8fc1\u79fb\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2505.16583", "pdf": "https://arxiv.org/pdf/2505.16583", "abs": "https://arxiv.org/abs/2505.16583", "authors": ["Shpresim Sadiku", "Kartikeya Chitranshi", "Hiroshi Kera", "Sebastian Pokutta"], "title": "Training on Plausible Counterfactuals Removes Spurious Correlations", "categories": ["cs.LG"], "comment": null, "summary": "Plausible counterfactual explanations (p-CFEs) are perturbations that\nminimally modify inputs to change classifier decisions while remaining\nplausible under the data distribution. In this study, we demonstrate that\nclassifiers can be trained on p-CFEs labeled with induced \\emph{incorrect}\ntarget classes to classify unperturbed inputs with the original labels. While\nprevious studies have shown that such learning is possible with adversarial\nperturbations, we extend this paradigm to p-CFEs. Interestingly, our\nexperiments reveal that learning from p-CFEs is even more effective: the\nresulting classifiers achieve not only high in-distribution accuracy but also\nexhibit significantly reduced bias with respect to spurious correlations.", "AI": {"tldr": "\u901a\u8fc7\u4f7f\u7528\u5e26\u6709\u9519\u8bef\u76ee\u6807\u7c7b\u522b\u7684\u5408\u7406\u53cd\u4e8b\u5b9e\u793a\u4f8b(p-CFEs)\u8bad\u7ec3\u5206\u7c7b\u5668\uff0c\u53ef\u4ee5\u4f7f\u5206\u7c7b\u5668\u5bf9\u672a\u53d7\u5e72\u6270\u7684\u8f93\u5165\u8fdb\u884c\u539f\u59cb\u6807\u7b7e\u5206\u7c7b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u5bf9\u6297\u6027\u6270\u52a8\u76f8\u6bd4\uff0c\u4f7f\u7528p-CFEs\u8bad\u7ec3\u53ef\u4ee5\u63d0\u9ad8\u5206\u7c7b\u5668\u5728\u5206\u5e03\u5185\u51c6\u786e\u6027\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u5bf9\u865a\u5047\u76f8\u5173\u6027\u7684\u504f\u5dee\u3002", "motivation": "\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u5982\u4f55\u5229\u7528\u5408\u7406\u53cd\u4e8b\u5b9e\u793a\u4f8b\uff08plausible counterfactual explanations, p-CFEs\uff09\u6765\u6539\u8fdb\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u516c\u5e73\u6027\uff0c\u7279\u522b\u662f\u51cf\u5c11\u6a21\u578b\u5bf9\u865a\u5047\u76f8\u5173\u6027\u7684\u4f9d\u8d56\u3002", "method": "\u5c06p-CFEs\u6807\u8bb0\u4e3a\u8bf1\u5bfc\u7684\u9519\u8bef\u76ee\u6807\u7c7b\u522b\uff0c\u5e76\u7528\u8fd9\u4e9b\u6570\u636e\u8bad\u7ec3\u5206\u7c7b\u5668\u3002\u968f\u540e\u8bc4\u4f30\u8be5\u5206\u7c7b\u5668\u5728\u672a\u53d7\u5e72\u6270\u7684\u6570\u636e\u4e0a\u7684\u8868\u73b0\uff0c\u9a8c\u8bc1\u5176\u662f\u5426\u80fd\u591f\u6b63\u786e\u6062\u590d\u539f\u59cb\u6807\u7b7e\u3002\u8fd9\u79cd\u65b9\u6cd5\u6269\u5c55\u4e86\u4e4b\u524d\u57fa\u4e8e\u5bf9\u6297\u6027\u6270\u52a8\u7684\u7814\u7a76\uff0c\u5e94\u7528\u4e8ep-CFEs\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528p-CFEs\u8bad\u7ec3\u7684\u5206\u7c7b\u5668\u4e0d\u4ec5\u5728\u5206\u5e03\u5185\u6570\u636e\u4e0a\u8fbe\u5230\u4e86\u9ad8\u51c6\u786e\u6027\uff0c\u8fd8\u663e\u8457\u51cf\u5c11\u4e86\u5bf9\u865a\u5047\u76f8\u5173\u6027\u7684\u504f\u5dee\u3002", "conclusion": "\u5408\u7406\u53cd\u4e8b\u5b9e\u793a\u4f8b\uff08p-CFEs\uff09\u53ef\u4ee5\u7528\u4f5c\u4e00\u79cd\u6709\u6548\u7684\u6570\u636e\u589e\u5f3a\u5de5\u5177\uff0c\u5e2e\u52a9\u6784\u5efa\u66f4\u7a33\u5065\u3001\u66f4\u516c\u5e73\u7684\u5206\u7c7b\u5668\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u964d\u4f4e\u865a\u5047\u76f8\u5173\u6027\u5f71\u54cd\u7684\u60c5\u51b5\u4e0b\u3002"}}
{"id": "2505.16620", "pdf": "https://arxiv.org/pdf/2505.16620", "abs": "https://arxiv.org/abs/2505.16620", "authors": ["Benjamin Herdeanu", "Juan Nathaniel", "Carla Roesch", "Jatan Buch", "Gregor Ramien", "Johannes Haux", "Pierre Gentine"], "title": "CausalDynamics: A large-scale benchmark for structural discovery of dynamical causal models", "categories": ["cs.LG"], "comment": "16+19 pages, 5+8 figures", "summary": "Causal discovery for dynamical systems poses a major challenge in fields\nwhere active interventions are infeasible. Most methods used to investigate\nthese systems and their associated benchmarks are tailored to deterministic,\nlow-dimensional and weakly nonlinear time-series data. To address these\nlimitations, we present CausalDynamics, a large-scale benchmark and extensible\ndata generation framework to advance the structural discovery of dynamical\ncausal models. Our benchmark consists of true causal graphs derived from\nthousands of coupled ordinary and stochastic differential equations as well as\ntwo idealized climate models. We perform a comprehensive evaluation of\nstate-of-the-art causal discovery algorithms for graph reconstruction on\nsystems with noisy, confounded, and lagged dynamics. CausalDynamics consists of\na plug-and-play, build-your-own coupling workflow that enables the construction\nof a hierarchy of physical systems. We anticipate that our framework will\nfacilitate the development of robust causal discovery algorithms that are\nbroadly applicable across domains while addressing their unique challenges. We\nprovide a user-friendly implementation and documentation on\nhttps://kausable.github.io/CausalDynamics.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86CausalDynamics\uff0c\u4e00\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\u548c\u53ef\u6269\u5c55\u7684\u6570\u636e\u751f\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u63a8\u8fdb\u52a8\u6001\u56e0\u679c\u6a21\u578b\u7684\u7ed3\u6784\u53d1\u73b0\u3002\u5b83\u5305\u542b\u4ece\u6570\u5343\u4e2a\u8026\u5408\u5e38\u5fae\u5206\u65b9\u7a0b\u3001\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u4ee5\u53ca\u4e24\u4e2a\u7406\u60f3\u5316\u6c14\u5019\u6a21\u578b\u4e2d\u884d\u751f\u7684\u771f\u5b9e\u56e0\u679c\u56fe\u3002\u7814\u7a76\u5bf9\u5177\u6709\u566a\u58f0\u3001\u6df7\u6742\u548c\u6ede\u540e\u52a8\u6001\u7684\u7cfb\u7edf\u7684\u56fe\u5f62\u91cd\u5efa\u8fdb\u884c\u4e86\u6700\u5148\u8fdb\u7684\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\u7684\u5168\u9762\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u7684\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u786e\u5b9a\u6027\u3001\u4f4e\u7ef4\u548c\u5f31\u975e\u7ebf\u6027\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u96be\u4ee5\u5904\u7406\u52a8\u6001\u7cfb\u7edf\u4e2d\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u7279\u522b\u662f\u5728\u65e0\u6cd5\u8fdb\u884c\u4e3b\u52a8\u5e72\u9884\u7684\u9886\u57df\u3002\u9700\u8981\u4e00\u4e2a\u66f4\u590d\u6742\u548c\u9ad8\u7ef4\u5ea6\u7684\u57fa\u51c6\u6765\u63a8\u52a8\u52a8\u6001\u56e0\u679c\u6a21\u578b\u7684\u7814\u7a76\u3002", "method": "\u63d0\u51faCausalDynamics\u6846\u67b6\uff0c\u5305\u62ec\u4ece\u6570\u5343\u4e2a\u8026\u5408\u5e38\u5fae\u5206\u65b9\u7a0b\u3001\u968f\u673a\u5fae\u5206\u65b9\u7a0b\u53ca\u4e24\u4e2a\u7406\u60f3\u5316\u6c14\u5019\u6a21\u578b\u4e2d\u63d0\u53d6\u771f\u5b9e\u56e0\u679c\u56fe\uff1b\u6267\u884c\u6700\u5148\u8fdb\u7684\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\u5728\u6709\u566a\u58f0\u3001\u6df7\u6742\u548c\u6ede\u540e\u52a8\u6001\u7684\u7cfb\u7edf\u4e0a\u7684\u56fe\u5f62\u91cd\u5efa\u8bc4\u4f30\uff1b\u63d0\u4f9b\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u5de5\u4f5c\u6d41\u7a0b\u4ee5\u6784\u5efa\u7269\u7406\u7cfb\u7edf\u7684\u5c42\u6b21\u7ed3\u6784\u3002", "result": "CausalDynamics\u6846\u67b6\u80fd\u591f\u4fc3\u8fdb\u7a33\u5065\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\u7684\u53d1\u5c55\uff0c\u9002\u7528\u4e8e\u8de8\u57df\u5e94\u7528\u5e76\u89e3\u51b3\u72ec\u7279\u6311\u6218\u3002\u63d0\u4f9b\u4e86\u7528\u6237\u53cb\u597d\u7684\u5b9e\u73b0\u548c\u6587\u6863\u3002", "conclusion": "CausalDynamics\u4e3a\u52a8\u6001\u56e0\u679c\u6a21\u578b\u7684\u7ed3\u6784\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u7684\u57fa\u51c6\u548c\u5de5\u5177\uff0c\u63a8\u52a8\u4e86\u76f8\u5173\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2505.16636", "pdf": "https://arxiv.org/pdf/2505.16636", "abs": "https://arxiv.org/abs/2505.16636", "authors": ["Victor Dheur", "Souhaib Ben Taieb"], "title": "Multivariate Latent Recalibration for Conditional Normalizing Flows", "categories": ["cs.LG"], "comment": null, "summary": "Reliably characterizing the full conditional distribution of a multivariate\nresponse variable given a set of covariates is crucial for trustworthy\ndecision-making. However, misspecified or miscalibrated multivariate models may\nyield a poor approximation of the joint distribution of the response variables,\nleading to unreliable predictions and suboptimal decisions. Furthermore,\nstandard recalibration methods are primarily limited to univariate settings,\nwhile conformal prediction techniques, despite generating multivariate\nprediction regions with coverage guarantees, do not provide a full probability\ndensity function. We address this gap by first introducing a novel notion of\nlatent calibration, which assesses probabilistic calibration in the latent\nspace of a conditional normalizing flow. Second, we propose latent\nrecalibration (LR), a novel post-hoc model recalibration method that learns a\ntransformation of the latent space with finite-sample bounds on latent\ncalibration. Unlike existing methods, LR produces a recalibrated distribution\nwith an explicit multivariate density function while remaining computationally\nefficient. Extensive experiments on both tabular and image datasets show that\nLR consistently improves latent calibration error and the negative\nlog-likelihood of the recalibrated models.", "AI": {"tldr": "\u5728\u591a\u53d8\u91cf\u54cd\u5e94\u53d8\u91cf\u7684\u6761\u4ef6\u4e0b\uff0c\u51c6\u786e\u63cf\u8ff0\u5176\u5b8c\u6574\u7684\u6761\u4ef6\u5206\u5e03\u5bf9\u4e8e\u53ef\u4fe1\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u9519\u8bef\u6307\u5b9a\u6216\u6821\u51c6\u4e0d\u826f\u7684\u591a\u53d8\u91cf\u6a21\u578b\u53ef\u80fd\u5bfc\u81f4\u5bf9\u8054\u5408\u5206\u5e03\u7684\u8fd1\u4f3c\u8f83\u5dee\uff0c\u4ece\u800c\u5bfc\u81f4\u4e0d\u53ef\u9760\u7684\u9884\u6d4b\u548c\u6b21\u4f18\u51b3\u7b56\u3002\u73b0\u6709\u7684\u91cd\u65b0\u6821\u51c6\u65b9\u6cd5\u4e3b\u8981\u5c40\u9650\u4e8e\u5355\u53d8\u91cf\u8bbe\u7f6e\uff0c\u800c\u5c3d\u7ba1\u5171\u5f62\u9884\u6d4b\u6280\u672f\u53ef\u4ee5\u751f\u6210\u5177\u6709\u8986\u76d6\u4fdd\u8bc1\u7684\u591a\u53d8\u91cf\u9884\u6d4b\u533a\u57df\uff0c\u4f46\u5b83\u4eec\u4e0d\u63d0\u4f9b\u5b8c\u6574\u7684\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6f5c\u5728\u6821\u51c6\u6982\u5ff5\uff0c\u5e76\u5f15\u5165\u4e86\u6f5c\u5728\u91cd\u65b0\u6821\u51c6\uff08LR\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5b66\u4e60\u6f5c\u5728\u7a7a\u95f4\u7684\u8f6c\u6362\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u5e76\u4ea7\u751f\u5177\u6709\u660e\u786e\u591a\u53d8\u91cf\u5bc6\u5ea6\u51fd\u6570\u7684\u91cd\u65b0\u6821\u51c6\u5206\u5e03\u3002\u5b9e\u9a8c\u8868\u660e\uff0cLR\u80fd\u591f\u6301\u7eed\u6539\u5584\u6f5c\u5728\u6821\u51c6\u8bef\u5dee\u548c\u91cd\u65b0\u6821\u51c6\u6a21\u578b\u7684\u8d1f\u5bf9\u6570\u4f3c\u7136\u6027\u3002", "motivation": "\u53ef\u9760\u5730\u63cf\u8ff0\u7ed9\u5b9a\u534f\u53d8\u91cf\u96c6\u7684\u591a\u53d8\u91cf\u54cd\u5e94\u53d8\u91cf\u7684\u5b8c\u6574\u6761\u4ef6\u5206\u5e03\u5bf9\u4e8e\u53ef\u4fe1\u8d56\u7684\u51b3\u7b56\u5236\u5b9a\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5f53\u524d\u7684\u65b9\u6cd5\u8981\u4e48\u65e0\u6cd5\u5f88\u597d\u5730\u8fd1\u4f3c\u8054\u5408\u5206\u5e03\uff0c\u8981\u4e48\u7f3a\u4e4f\u5168\u9762\u7684\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u652f\u6301\uff0c\u8fd9\u4fc3\u4f7f\u4e86\u5bf9\u6539\u8fdb\u7684\u591a\u53d8\u91cf\u6a21\u578b\u6821\u51c6\u65b9\u6cd5\u7684\u9700\u6c42\u3002", "method": "1. \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6f5c\u5728\u6821\u51c6\u6982\u5ff5\uff0c\u7528\u4e8e\u8bc4\u4f30\u6761\u4ef6\u6807\u51c6\u5316\u6d41\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u6982\u7387\u6821\u51c6\u3002\n2. \u5f15\u5165\u4e86\u6f5c\u5728\u91cd\u65b0\u6821\u51c6\uff08LR\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u540e\u9a8c\u6a21\u578b\u91cd\u65b0\u6821\u51c6\u65b9\u6cd5\uff0c\u5b83\u5b66\u4e60\u6f5c\u5728\u7a7a\u95f4\u7684\u8f6c\u6362\uff0c\u5e76\u5728\u6709\u9650\u6837\u672c\u4e0a\u8bbe\u7f6e\u4e86\u6f5c\u5728\u6821\u51c6\u7684\u8fb9\u754c\u3002\n3. LR\u751f\u6210\u4e86\u4e00\u4e2a\u5177\u6709\u663e\u5f0f\u591a\u53d8\u91cf\u5bc6\u5ea6\u51fd\u6570\u7684\u91cd\u65b0\u6821\u51c6\u5206\u5e03\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u901a\u8fc7\u5728\u8868\u683c\u6570\u636e\u548c\u56fe\u50cf\u6570\u636e\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86LR\u65b9\u6cd5\u80fd\u591f\u6301\u7eed\u964d\u4f4e\u6f5c\u5728\u6821\u51c6\u8bef\u5dee\u548c\u91cd\u65b0\u6821\u51c6\u6a21\u578b\u7684\u8d1f\u5bf9\u6570\u4f3c\u7136\u6027\u3002", "conclusion": "\u6f5c\u5728\u91cd\u65b0\u6821\u51c6\uff08LR\uff09\u65b9\u6cd5\u4e3a\u591a\u53d8\u91cf\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u91cd\u65b0\u6821\u51c6\u65b9\u6848\uff0c\u6539\u5584\u4e86\u6f5c\u5728\u6821\u51c6\u8bef\u5dee\u548c\u6a21\u578b\u7684\u8d1f\u5bf9\u6570\u4f3c\u7136\u6027\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u8ba1\u7b97\u6548\u7387\u548c\u660e\u786e\u7684\u591a\u53d8\u91cf\u5bc6\u5ea6\u51fd\u6570\u8868\u793a\u3002"}}
{"id": "2505.16649", "pdf": "https://arxiv.org/pdf/2505.16649", "abs": "https://arxiv.org/abs/2505.16649", "authors": ["Zhichao Zhu", "Yang Qi", "Hengyuan Ma", "Wenlian Lu", "Jianfeng Feng"], "title": "Stochastic Forward-Forward Learning through Representational Dimensionality Compression", "categories": ["cs.LG", "cs.NE"], "comment": "14 pages, 9 figures, 2 tables", "summary": "The Forward-Forward (FF) algorithm provides a bottom-up alternative to\nbackpropagation (BP) for training neural networks, relying on a layer-wise\n\"goodness\" function to guide learning. Existing goodness functions, inspired by\nenergy-based learning (EBL), are typically defined as the sum of squared\npost-synaptic activations, neglecting the correlations between neurons. In this\nwork, we propose a novel goodness function termed dimensionality compression\nthat uses the effective dimensionality (ED) of fluctuating neural responses to\nincorporate second-order statistical structure. Our objective minimizes ED for\nclamped inputs when noise is considered while maximizing it across the sample\ndistribution, promoting structured representations without the need to prepare\nnegative samples. We demonstrate that this formulation achieves competitive\nperformance compared to other non-BP methods. Moreover, we show that noise\nplays a constructive role that can enhance generalization and improve inference\nwhen predictions are derived from the mean of squared outputs, which is\nequivalent to making predictions based on the energy term. Our findings\ncontribute to the development of more biologically plausible learning\nalgorithms and suggest a natural fit for neuromorphic computing, where\nstochasticity is a computational resource rather than a nuisance. The code is\navailable at https://github.com/ZhichaoZhu/StochasticForwardForward", "AI": {"tldr": "The paper introduces a new goodness function for the Forward-Forward algorithm that uses effective dimensionality to incorporate second-order statistical structure, achieving competitive performance with other non-BP methods.", "motivation": "Existing goodness functions in the Forward-Forward algorithm neglect correlations between neurons. The authors aim to develop a more comprehensive goodness function that considers second-order statistical structure.", "method": "The proposed method defines a novel goodness function called dimensionality compression, which minimizes effective dimensionality (ED) for clamped inputs with noise and maximizes it across the sample distribution. This approach promotes structured representations without needing negative samples.", "result": "The formulation achieves competitive performance compared to other non-BP methods. Noise is shown to play a constructive role in enhancing generalization and improving inference when predictions are based on the mean of squared outputs.", "conclusion": "This work contributes to the development of biologically plausible learning algorithms and highlights the potential of neuromorphic computing, where stochasticity can be utilized as a computational resource."}}
{"id": "2505.16664", "pdf": "https://arxiv.org/pdf/2505.16664", "abs": "https://arxiv.org/abs/2505.16664", "authors": ["Khoa Tran", "Tri Le", "Bao Huynh", "Hung-Cuong Trinh", "Vy-Rin Nguyen"], "title": "End-to-End Framework for Predicting the Remaining Useful Life of Lithium-Ion Batteries", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate prediction of the Remaining Useful Life (RUL) is essential for\nenabling timely maintenance of lithium-ion batteries, impacting the operational\nefficiency of electric applications that rely on them. This paper proposes a\nRUL prediction approach that leverages data from recent charge-discharge cycles\nto estimate the number of remaining usable cycles. The approach introduces both\na novel signal processing pipeline and a deep learning prediction model. In the\nsignal preprocessing pipeline, a derived capacity feature is computed based on\ncurrent and capacity signals. Alongside original capacity, voltage and current,\nthese features are denoised and enhanced using statistical metrics and a\ndelta-based method to capture differences between the current and previous\ncycles. In the prediction model, the processed features are then fed into a\nhybrid deep learning architecture composed of 1D Convolutional Neural Networks\n(CNN), Attentional Long Short-Term Memory (A-LSTM), and Ordinary Differential\nEquation-based LSTM (ODE-LSTM) modules. This architecture is designed to\ncapture both local signal characteristics and long-range temporal dependencies\nwhile modeling the continuous-time dynamics of battery degradation. The model\nis further evaluated using transfer learning across different learning\nstrategies and target data partitioning scenarios. Results indicate that the\nmodel maintains robust performance, even when fine-tuned on limited target\ndata. Experimental results on two publicly available large-scale datasets\ndemonstrate that the proposed method outperforms a baseline deep learning\napproach and machine learning techniques, achieving an RMSE of 101.59,\nhighlighting its strong potential for real-world RUL prediction applications.", "AI": {"tldr": "\u51c6\u786e\u9884\u6d4b\u9502\u79bb\u5b50\u7535\u6c60\u7684\u5269\u4f59\u4f7f\u7528\u5bff\u547d\uff08RUL\uff09\u5bf9\u4e8e\u53ca\u65f6\u7ef4\u62a4\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u65b0\u9896\u4fe1\u53f7\u5904\u7406\u7ba1\u9053\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u5145\u7535-\u653e\u7535\u5faa\u73af\u4e2d\u7684\u7279\u5f81\u5e76\u5efa\u6a21\u7535\u6c60\u9000\u5316\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u4e86\u5bf9RUL\u7684\u9ad8\u6548\u9884\u6d4b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u5f88\u5f3a\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u9502\u79bb\u5b50\u7535\u6c60RUL\u7684\u7cbe\u786e\u9884\u6d4b\u76f4\u63a5\u5f71\u54cd\u5230\u4f9d\u8d56\u5b83\u7684\u7535\u52a8\u8bbe\u5907\u7684\u8fd0\u884c\u6548\u7387\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u57fa\u4e8e\u8fd1\u671f\u5145\u653e\u7535\u6570\u636e\u3001\u80fd\u6709\u6548\u4f30\u8ba1\u5269\u4f59\u53ef\u7528\u5468\u671f\u7684\u65b9\u6cd5\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1) \u4e00\u4e2a\u521b\u65b0\u7684\u4fe1\u53f7\u9884\u5904\u7406\u7ba1\u9053\uff0c\u8ba1\u7b97\u884d\u751f\u5bb9\u91cf\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u7edf\u8ba1\u6307\u6807\u548c\u5dee\u5206\u65b9\u6cd5\u589e\u5f3a\u4fe1\u53f7\uff1b2) \u4e00\u79cd\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff0c\u5305\u542b\u4e00\u7ef4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u3001\u6ce8\u610f\u529b\u673a\u5236\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08A-LSTM\uff09\u548c\u57fa\u4e8e\u5e38\u5fae\u5206\u65b9\u7a0b\u7684LSTM\uff08ODE-LSTM\uff09\uff0c\u4ee5\u6355\u6349\u5c40\u90e8\u4fe1\u53f7\u7279\u6027\u548c\u957f\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\uff1b3) \u4f7f\u7528\u8fc1\u79fb\u5b66\u4e60\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5373\u4f7f\u5728\u6709\u9650\u7684\u76ee\u6807\u6570\u636e\u4e0a\u5fae\u8c03\u65f6\u4ecd\u80fd\u4fdd\u6301\u7a33\u5065\u6027\u80fd\uff0c\u5728\u4e24\u4e2a\u516c\u5f00\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u7684\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u548c\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6280\u672f\uff0c\u5176RMSE\u503c\u4e3a101.59\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9884\u6d4b\u9502\u79bb\u5b50\u7535\u6c60\u7684RUL\uff0c\u5c55\u73b0\u4e86\u5f3a\u5927\u7684\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2505.16672", "pdf": "https://arxiv.org/pdf/2505.16672", "abs": "https://arxiv.org/abs/2505.16672", "authors": ["Yun-Cheng Tsai", "Samuel Yen-Chi Chen"], "title": "Quantum Feature Optimization for Enhanced Clustering of Blockchain Transaction Data", "categories": ["cs.LG"], "comment": "6 pages, 6 figures, 1 table", "summary": "Blockchain transaction data exhibits high dimensionality, noise, and\nintricate feature entanglement, presenting significant challenges for\ntraditional clustering algorithms. In this study, we conduct a comparative\nanalysis of three clustering approaches: (1) Classical K-Means Clustering,\napplied to pre-processed feature representations; (2) Hybrid Clustering,\nwherein classical features are enhanced with quantum random features extracted\nusing randomly initialized quantum neural networks (QNNs); and (3) Fully\nQuantum Clustering, where a QNN is trained in a self-supervised manner\nleveraging a SwAV-based loss function to optimize the feature space for\nclustering directly. The proposed experimental framework systematically\ninvestigates the impact of quantum circuit depth and the number of learned\nprototypes, demonstrating that even shallow quantum circuits can effectively\nextract meaningful non-linear representations, significantly improving\nclustering performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u4e09\u79cd\u533a\u5757\u94fe\u4ea4\u6613\u6570\u636e\u805a\u7c7b\u65b9\u6cd5\uff1a\u7ecf\u5178K-Means\u3001\u6df7\u5408\u805a\u7c7b\uff08\u7ed3\u5408\u91cf\u5b50\u968f\u673a\u7279\u5f81\uff09\u548c\u5168\u91cf\u5b50\u805a\u7c7b\uff08\u4f7f\u7528\u81ea\u76d1\u7763\u8bad\u7ec3\u7684\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\uff09\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u6d45\u5c42\u91cf\u5b50\u7535\u8def\u4e5f\u80fd\u6709\u6548\u63d0\u53d6\u975e\u7ebf\u6027\u7279\u5f81\uff0c\u663e\u8457\u63d0\u5347\u805a\u7c7b\u6548\u679c\u3002", "motivation": "\u533a\u5757\u94fe\u4ea4\u6613\u6570\u636e\u5177\u6709\u9ad8\u7ef4\u5ea6\u3001\u566a\u58f0\u548c\u590d\u6742\u7279\u5f81\u7ea0\u7f20\u7684\u7279\u70b9\uff0c\u8fd9\u5bf9\u4f20\u7edf\u805a\u7c7b\u7b97\u6cd5\u6784\u6210\u4e86\u91cd\u5927\u6311\u6218\u3002\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u805a\u7c7b\u6027\u80fd\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u4e09\u79cd\u65b9\u6cd5\uff1a1) \u7ecf\u5178K-Means\u805a\u7c7b\uff1b2) \u6df7\u5408\u805a\u7c7b\uff0c\u7ed3\u5408\u7ecf\u5178\u7279\u5f81\u4e0e\u91cf\u5b50\u968f\u673a\u7279\u5f81\uff1b3) \u5168\u91cf\u5b50\u805a\u7c7b\uff0c\u4f7f\u7528\u81ea\u76d1\u7763\u8bad\u7ec3\u7684\u91cf\u5b50\u795e\u7ecf\u7f51\u7edc\u4f18\u5316\u7279\u5f81\u7a7a\u95f4\u3002\u901a\u8fc7\u7cfb\u7edf\u5b9e\u9a8c\u5206\u6790\u91cf\u5b50\u7535\u8def\u6df1\u5ea6\u548c\u5b66\u4e60\u539f\u578b\u6570\u91cf\u5bf9\u805a\u7c7b\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u6d45\u5c42\u91cf\u5b50\u7535\u8def\u4e5f\u80fd\u6709\u6548\u63d0\u53d6\u6709\u610f\u4e49\u7684\u975e\u7ebf\u6027\u7279\u5f81\uff0c\u663e\u8457\u6539\u5584\u805a\u7c7b\u6027\u80fd\u3002", "conclusion": "\u6df7\u5408\u805a\u7c7b\u548c\u5168\u91cf\u5b50\u805a\u7c7b\u65b9\u6cd5\u5728\u5904\u7406\u533a\u5757\u94fe\u4ea4\u6613\u6570\u636e\u65f6\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u6d45\u5c42\u91cf\u5b50\u7535\u8def\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u805a\u7c7b\u6548\u679c\u3002"}}
{"id": "2505.16675", "pdf": "https://arxiv.org/pdf/2505.16675", "abs": "https://arxiv.org/abs/2505.16675", "authors": ["Wenwen Qiang", "Jingyao Wang", "Zeen Song", "Jiangmeng Li", "Changwen Zheng"], "title": "On the Out-of-Distribution Generalization of Self-Supervised Learning", "categories": ["cs.LG"], "comment": null, "summary": "In this paper, we focus on the out-of-distribution (OOD) generalization of\nself-supervised learning (SSL). By analyzing the mini-batch construction during\nthe SSL training phase, we first give one plausible explanation for SSL having\nOOD generalization. Then, from the perspective of data generation and causal\ninference, we analyze and conclude that SSL learns spurious correlations during\nthe training process, which leads to a reduction in OOD generalization. To\naddress this issue, we propose a post-intervention distribution (PID) grounded\nin the Structural Causal Model. PID offers a scenario where the spurious\nvariable and label variable is mutually independent. Besides, we demonstrate\nthat if each mini-batch during SSL training satisfies PID, the resulting SSL\nmodel can achieve optimal worst-case OOD performance. This motivates us to\ndevelop a batch sampling strategy that enforces PID constraints through the\nlearning of a latent variable model. Through theoretical analysis, we\ndemonstrate the identifiability of the latent variable model and validate the\neffectiveness of the proposed sampling strategy. Experiments conducted on\nvarious downstream OOD tasks demonstrate the effectiveness of the proposed\nsampling strategy.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u81ea\u76d1\u7763\u5b66\u4e60(SSL)\u5728\u5206\u5e03\u5916(OOD)\u6cdb\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u7684\u540e\u5e72\u9884\u5206\u5e03(PID)\uff0c\u5e76\u8bbe\u8ba1\u4e86\u6ee1\u8db3PID\u7ea6\u675f\u7684\u6279\u91cf\u91c7\u6837\u7b56\u7565\uff0c\u4ece\u800c\u63d0\u5347SSL\u6a21\u578b\u7684OOD\u6cdb\u5316\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u7b56\u7565\u5728\u591a\u4e2a\u4e0b\u6e38OOD\u4efb\u52a1\u4e2d\u6709\u6548\u3002", "motivation": "\u81ea\u76d1\u7763\u5b66\u4e60(SSL)\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u5b66\u5230\u865a\u5047\u76f8\u5173\u6027\uff0c\u5bfc\u81f4\u5176\u5206\u5e03\u5916(OOD)\u6cdb\u5316\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u4ece\u6570\u636e\u751f\u6210\u548c\u56e0\u679c\u63a8\u65ad\u7684\u89d2\u5ea6\u5206\u6790SSL\u4e2d\u7684\u865a\u5047\u76f8\u5173\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u7684\u540e\u5e72\u9884\u5206\u5e03(PID)\uff0c\u4f7f\u865a\u5047\u53d8\u91cf\u548c\u6807\u7b7e\u53d8\u91cf\u76f8\u4e92\u72ec\u7acb\uff1b\u8fdb\u4e00\u6b65\u8bbe\u8ba1\u4e86\u6279\u91cf\u91c7\u6837\u7b56\u7565\uff0c\u901a\u8fc7\u5b66\u4e60\u6f5c\u5728\u53d8\u91cf\u6a21\u578b\u6765\u6ee1\u8db3PID\u7ea6\u675f\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86\u6f5c\u5728\u53d8\u91cf\u6a21\u578b\u7684\u53ef\u8bc6\u522b\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u6240\u63d0\u91c7\u6837\u7b56\u7565\u7684\u6709\u6548\u6027\uff1b\u5b9e\u9a8c\u8bc1\u660e\u8be5\u7b56\u7565\u5728\u591a\u4e2a\u4e0b\u6e38OOD\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u63d0\u51fa\u7684\u6279\u91cf\u91c7\u6837\u7b56\u7565\u53ef\u4ee5\u63d0\u9ad8SSL\u6a21\u578b\u7684OOD\u6cdb\u5316\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3SSL\u4e2d\u7684\u865a\u5047\u76f8\u5173\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\u3002"}}
{"id": "2505.16680", "pdf": "https://arxiv.org/pdf/2505.16680", "abs": "https://arxiv.org/abs/2505.16680", "authors": ["Filip Thor", "Carl Nettelblad"], "title": "Learning Genomic Structure from $k$-mers", "categories": ["cs.LG", "q-bio.GN", "q-bio.QM"], "comment": null, "summary": "Sequencing a genome to determine an individual's DNA produces an enormous\nnumber of short nucleotide subsequences known as reads, which must be\nreassembled to reconstruct the full genome. We present a method for analyzing\nthis type of data using contrastive learning, in which an encoder model is\ntrained to produce embeddings that cluster together sequences from the same\ngenomic region. The sequential nature of genomic regions is preserved in the\nform of trajectories through this embedding space. Trained solely to reflect\nthe structure of the genome, the resulting model provides a general\nrepresentation of $k$-mer sequences, suitable for a range of downstream tasks\ninvolving read data. We apply our framework to learn the structure of the $E.\\\ncoli$ genome, and demonstrate its use in simulated ancient DNA (aDNA) read\nmapping and identification of structural variations. Furthermore, we illustrate\nthe potential of using this type of model for metagenomic species\nidentification. We show how incorporating a domain-specific noise model can\nenhance embedding robustness, and how a supervised contrastive learning setting\ncan be adopted when a linear reference genome is available, by introducing a\ndistance thresholding parameter $\\Gamma$. The model can also be trained fully\nself-supervised on read data, enabling analysis without the need to construct a\nfull genome assembly using specialized algorithms. Small prediction heads based\non a pre-trained embedding are shown to perform on par with BWA-aln, the\ncurrent gold standard approach for aDNA mapping, in terms of accuracy and\nruntime for short genomes. Given the method's favorable scaling properties with\nrespect to total genome size, inference using our approach is highly promising\nfor metagenomic applications and for mapping to genomes comparable in size to\nthe human genome.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u57fa\u56e0\u7ec4\u6d4b\u5e8f\u6570\u636e\u7684\u5206\u6790\u3002\u901a\u8fc7\u8bad\u7ec3\u7f16\u7801\u5668\u6a21\u578b\u751f\u6210\u5d4c\u5165\uff0c\u8fd9\u4e9b\u5d4c\u5165\u53ef\u4ee5\u805a\u7c7b\u6765\u81ea\u76f8\u540c\u57fa\u56e0\u7ec4\u533a\u57df\u7684\u5e8f\u5217\uff0c\u5e76\u4fdd\u7559\u57fa\u56e0\u7ec4\u533a\u57df\u7684\u987a\u5e8f\u7279\u6027\u3002\u6b64\u65b9\u6cd5\u9002\u7528\u4e8e\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\uff0c\u4f8b\u5982\u6a21\u62df\u53e4DNA\uff08aDNA\uff09\u8bfb\u6bb5\u6620\u5c04\u548c\u7ed3\u6784\u53d8\u5f02\u8bc6\u522b\u3002\u6b64\u5916\uff0c\u8be5\u6a21\u578b\u5728\u5143\u57fa\u56e0\u7ec4\u7269\u79cd\u9274\u5b9a\u65b9\u9762\u4e5f\u663e\u793a\u51fa\u6f5c\u529b\u3002\u8bba\u6587\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u5f15\u5165\u9886\u57df\u7279\u5b9a\u7684\u566a\u58f0\u6a21\u578b\u589e\u5f3a\u5d4c\u5165\u7684\u9c81\u68d2\u6027\uff0c\u4ee5\u53ca\u5728\u6709\u7ebf\u6027\u53c2\u8003\u57fa\u56e0\u7ec4\u65f6\u91c7\u7528\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u8bbe\u7f6e\u3002\u5bf9\u4e8e\u77ed\u57fa\u56e0\u7ec4\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u4e0a\u4e0e\u5f53\u524d\u7684\u9ec4\u91d1\u6807\u51c6BWA-aln\u76f8\u5f53\u3002\u7531\u4e8e\u5176\u826f\u597d\u7684\u6269\u5c55\u6027\uff0c\u8be5\u65b9\u6cd5\u5728\u5143\u57fa\u56e0\u7ec4\u5e94\u7528\u548c\u4eba\u7c7b\u5927\u5c0f\u57fa\u56e0\u7ec4\u6620\u5c04\u65b9\u9762\u5177\u6709\u5f88\u9ad8\u7684\u524d\u666f\u3002", "motivation": "\u57fa\u56e0\u7ec4\u6d4b\u5e8f\u4f1a\u4ea7\u751f\u5927\u91cf\u7684\u77ed\u6838\u82f7\u9178\u5b50\u5e8f\u5217\uff08reads\uff09\uff0c\u9700\u8981\u91cd\u65b0\u7ec4\u88c5\u4ee5\u91cd\u5efa\u5b8c\u6574\u7684\u57fa\u56e0\u7ec4\u3002\u4f20\u7edf\u7684\u7ec4\u88c5\u65b9\u6cd5\u590d\u6742\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6709\u6548\u5206\u6790\u8fd9\u4e9b\u6570\u636e\u5e76\u63d0\u4f9b\u901a\u7528\u7684\u8868\u793a\u5f62\u5f0f\uff0c\u4ee5\u4fbf\u4e8e\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u7684\u6267\u884c\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bf9\u6bd4\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u5176\u4e2d\u7f16\u7801\u5668\u6a21\u578b\u88ab\u8bad\u7ec3\u4ee5\u751f\u6210\u5d4c\u5165\uff0c\u8fd9\u4e9b\u5d4c\u5165\u80fd\u591f\u5c06\u6765\u81ea\u76f8\u540c\u57fa\u56e0\u7ec4\u533a\u57df\u7684\u5e8f\u5217\u805a\u7c7b\u5728\u4e00\u8d77\u3002\u901a\u8fc7\u4fdd\u6301\u57fa\u56e0\u7ec4\u533a\u57df\u7684\u987a\u5e8f\u7279\u6027\uff0c\u5f62\u6210\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u8f68\u8ff9\u3002\u6a21\u578b\u53ef\u4ee5\u4ec5\u53cd\u6620\u57fa\u56e0\u7ec4\u7ed3\u6784\u8fdb\u884c\u8bad\u7ec3\uff0c\u4e5f\u53ef\u4ee5\u5728\u6709\u7ebf\u6027\u53c2\u8003\u57fa\u56e0\u7ec4\u65f6\u91c7\u7528\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u8bbe\u7f6e\u3002\u53e6\u5916\uff0c\u8fd8\u53ef\u4ee5\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u7684\u566a\u58f0\u6a21\u578b\u589e\u5f3a\u5d4c\u5165\u7684\u9c81\u68d2\u6027\u3002", "result": "\u8be5\u6a21\u578b\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u5305\u62ec\u6a21\u62df\u53e4DNA\u8bfb\u6bb5\u6620\u5c04\u3001\u7ed3\u6784\u53d8\u5f02\u8bc6\u522b\u548c\u5143\u57fa\u56e0\u7ec4\u7269\u79cd\u9274\u5b9a\u3002\u5bf9\u4e8e\u77ed\u57fa\u56e0\u7ec4\uff0c\u57fa\u4e8e\u9884\u8bad\u7ec3\u5d4c\u5165\u7684\u5c0f\u9884\u6d4b\u5934\u5728\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u4e0a\u4e0eBWA-aln\u76f8\u5f53\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u826f\u597d\u7684\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u4eba\u7c7b\u5927\u5c0f\u7684\u57fa\u56e0\u7ec4\u548c\u5143\u57fa\u56e0\u7ec4\u5e94\u7528\u3002", "conclusion": "\u63d0\u51fa\u7684\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u4e3a\u57fa\u56e0\u7ec4\u6d4b\u5e8f\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u751f\u6210\u901a\u7528\u7684\u5e8f\u5217\u8868\u793a\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u3002\u7279\u522b\u662f\u5728\u65e0\u9700\u6784\u5efa\u5b8c\u6574\u57fa\u56e0\u7ec4\u88c5\u914d\u7684\u60c5\u51b5\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5c55\u73b0\u4e86\u5de8\u5927\u7684\u6f5c\u529b\uff0c\u53ef\u7528\u4e8e\u4eba\u7c7b\u5927\u5c0f\u57fa\u56e0\u7ec4\u548c\u5143\u57fa\u56e0\u7ec4\u7684\u5e94\u7528\u3002"}}
{"id": "2505.16690", "pdf": "https://arxiv.org/pdf/2505.16690", "abs": "https://arxiv.org/abs/2505.16690", "authors": ["Beier Luo", "Shuoyuan Wang", "Yixuan Li", "Hongxin Wei"], "title": "Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Post-training of large language models is essential for adapting pre-trained\nlanguage models (PLMs) to align with human preferences and downstream tasks.\nWhile PLMs typically exhibit well-calibrated confidence, post-trained language\nmodels (PoLMs) often suffer from over-confidence, assigning high confidence to\nboth correct and incorrect outputs, which can undermine reliability in critical\napplications. A major obstacle in calibrating PoLMs is the scarcity of labeled\ndata for individual downstream tasks. To address this, we propose\nDisagreement-Aware Confidence Alignment (DACA), a novel unsupervised method to\noptimize the parameters (e.g., temperature $\\tau$) in post-hoc confidence\ncalibration. Our method is motivated by the under-confidence issue caused by\nprediction disagreement between the PLM and PoLM while aligning their\nconfidence via temperature scaling. Theoretically, the PLM's confidence\nunderestimates PoLM's prediction accuracy on disagreement examples, causing a\nlarger $\\tau$ and producing under-confident predictions. DACA mitigates this by\nselectively using only agreement examples for calibration, effectively\ndecoupling the influence of disagreement. In this manner, our method avoids an\noverly large $\\tau$ in temperature scaling caused by disagreement examples,\nimproving calibration performance. Extensive experiments demonstrate the\neffectiveness of our method, improving the average ECE of open-sourced and\nAPI-based LLMs (e.g. GPT-4o) by up to 15.08$\\%$ on common benchmarks.", "AI": {"tldr": "\u63d0\u51fa\u4e86Disagreement-Aware Confidence Alignment (DACA)\uff0c\u4e00\u79cd\u65b0\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u4f7f\u7528\u4e00\u81f4\u6837\u672c\u8fdb\u884c\u6821\u51c6\u6765\u4f18\u5316\u540e\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08PoLMs\uff09\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u53c2\u6570\uff0c\u6709\u6548\u51cf\u5c11\u56e0\u9884\u6d4b\u4e0d\u4e00\u81f4\u5bfc\u81f4\u7684\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u5f00\u6e90\u548cAPI-based LLMs\u7684\u5e73\u5747ECE\u8fbe15.08%\u3002", "motivation": "\u540e\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08PoLMs\uff09\u5728\u5173\u952e\u5e94\u7528\u4e2d\u5e38\u8868\u73b0\u51fa\u8fc7\u5ea6\u81ea\u4fe1\u7684\u95ee\u9898\uff0c\u8fd9\u53ef\u80fd\u964d\u4f4e\u5176\u53ef\u9760\u6027\u3002\u7136\u800c\uff0c\u9488\u5bf9\u4e2a\u522b\u4e0b\u6e38\u4efb\u52a1\u6807\u6ce8\u6570\u636e\u7684\u7a00\u7f3a\u6027\u6210\u4e3a\u6821\u51c6PoLMs\u7684\u4e00\u5927\u969c\u788d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDisagreement-Aware Confidence Alignment (DACA) \u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u6e29\u5ea6\u7f29\u653e\u6280\u672f\u5bf9PLM\u548cPoLM\u4e4b\u95f4\u7684\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u6821\u51c6\uff0c\u5e76\u9009\u62e9\u6027\u5730\u4ec5\u4f7f\u7528\u9884\u6d4b\u4e00\u81f4\u7684\u6837\u672c\u6765\u907f\u514d\u9884\u6d4b\u4e0d\u4e00\u81f4\u5bfc\u81f4\u7684\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDACA \u65b9\u6cd5\u6709\u6548\u5730\u6539\u5584\u4e86\u6821\u51c6\u6027\u80fd\uff0c\u5c06\u5f00\u6e90\u548c\u57fa\u4e8eAPI\u7684\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4o\uff09\u5728\u5e38\u89c1\u57fa\u51c6\u4e0a\u7684\u5e73\u5747\u671f\u671b\u6821\u51c6\u8bef\u5dee\uff08ECE\uff09\u63d0\u5347\u4e86\u9ad8\u8fbe15.08%\u3002", "conclusion": "DACA\u662f\u4e00\u79cd\u6709\u6548\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u80fd\u591f\u901a\u8fc7\u9009\u62e9\u6027\u4f7f\u7528\u4e00\u81f4\u6837\u672c\u6765\u4f18\u5316PoLMs\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u53c2\u6570\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2505.16705", "pdf": "https://arxiv.org/pdf/2505.16705", "abs": "https://arxiv.org/abs/2505.16705", "authors": ["Seonghwan Park", "Jueun Mun", "Donghyun Oh", "Namhoon Lee"], "title": "An Analysis of Concept Bottleneck Models: Measuring, Understanding, and Mitigating the Impact of Noisy Annotations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Concept bottleneck models (CBMs) ensure interpretability by decomposing\npredictions into human interpretable concepts. Yet the annotations used for\ntraining CBMs that enable this transparency are often noisy, and the impact of\nsuch corruption is not well understood. In this study, we present the first\nsystematic study of noise in CBMs and show that even moderate corruption\nsimultaneously impairs prediction performance, interpretability, and the\nintervention effectiveness. Our analysis identifies a susceptible subset of\nconcepts whose accuracy declines far more than the average gap between noisy\nand clean supervision and whose corruption accounts for most performance loss.\nTo mitigate this vulnerability we propose a two-stage framework. During\ntraining, sharpness-aware minimization stabilizes the learning of\nnoise-sensitive concepts. During inference, where clean labels are unavailable,\nwe rank concepts by predictive entropy and correct only the most uncertain\nones, using uncertainty as a proxy for susceptibility. Theoretical analysis and\nextensive ablations elucidate why sharpness-aware training confers robustness\nand why uncertainty reliably identifies susceptible concepts, providing a\nprincipled basis that preserves both interpretability and resilience in the\npresence of noise.", "AI": {"tldr": "Concept bottleneck models (CBMs) are affected by noisy annotations in training, leading to impaired prediction performance and interpretability. This study identifies vulnerable concepts and proposes a two-stage framework involving sharpness-aware minimization and uncertainty-based correction to enhance robustness.", "motivation": "Existing CBMs suffer from noisy annotations which impact their prediction performance, interpretability, and intervention effectiveness. There is a lack of understanding about how noise affects these models and how to mitigate its influence.", "method": "The study introduces a two-stage framework: 1) sharpness-aware minimization during training to stabilize noise-sensitive concept learning; 2) ranking concepts by predictive entropy during inference to correct only the most uncertain ones using uncertainty as a proxy for susceptibility.", "result": "Theoretical analysis and extensive experiments demonstrate that sharpness-aware training improves model robustness and uncertainty effectively identifies vulnerable concepts, thus preserving interpretability and resilience in the presence of noise.", "conclusion": "The proposed framework enhances the robustness of CBMs against noisy annotations while maintaining interpretability."}}
{"id": "2505.16710", "pdf": "https://arxiv.org/pdf/2505.16710", "abs": "https://arxiv.org/abs/2505.16710", "authors": ["Wenhao Li", "Yuxin Zhang", "Gen Luo", "Daohai Yu", "Rongrong Ji"], "title": "Training Long-Context LLMs Efficiently via Chunk-wise Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While long-context large language models (LLMs) exhibit remarkable document\nprocessing capabilities, their prohibitively high training costs often hinder\ncustomized applications. To mitigate this issue, we propose \\textit{Sequential\nChunk-wise Optimization} (SeCO), a memory-efficient training paradigm that\npartitions lengthy inputs into manageable chunks. Each chunk independently\nconstructs its computational graph and performs localized backpropagation,\nensuring that only one chunk's forward activations are stored in memory.\nBuilding on SeCO, we further introduce \\textit{Sparse Chunk-wise Optimization}\n(SpaCO), which reduces computational overhead by selectively propagating\ngradients to specific chunks and incorporates a carefully designed compensation\nfactor to ensure unbiased gradient estimation. SpaCO decouples the\ncomputational cost of backpropagation from the context length, enabling\ntraining time to gradually converge to inference time as sequences become\nlonger. Implemented as lightweight training wrappers, both SeCO and SpaCO offer\nsubstantial practical benefits. For example, when fine-tuning an 8B model with\nLoRA on a single RTX 3090 GPU, SeCO expands maximum sequence length from 1K to\n16K tokens, while SpaCO demonstrates accelerated training speed -- achieving up\nto 3x faster than SeCO under the same experimental setup. These innovations\nprovide new insights into optimizing long-context models, making them more\naccessible for practical applications. We have open-sourced the code at\n\\href{https://github.com/wenhaoli-xmu/seco}{here}.", "AI": {"tldr": "\u63d0\u51fa\u4e86SeCO\u548cSpaCO\u4e24\u79cd\u65b9\u6cd5\uff0c\u5206\u522b\u6269\u5c55\u4e86\u6a21\u578b\u7684\u6700\u5927\u5e8f\u5217\u957f\u5ea6\u5e76\u52a0\u901f\u4e86\u8bad\u7ec3\u901f\u5ea6\uff0c\u4e3a\u957f\u4e0a\u4e0b\u6587\u6a21\u578b\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u957f\u4e0a\u4e0b\u6587\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c3d\u7ba1\u5728\u6587\u6863\u5904\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u9ad8\u6602\u7684\u8bad\u7ec3\u6210\u672c\u9650\u5236\u4e86\u5b9a\u5236\u5316\u5e94\u7528\u7684\u53ef\u80fd\u6027\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u8bad\u7ec3\u65b9\u5f0f\u6765\u964d\u4f4e\u5185\u5b58\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSequential Chunk-wise Optimization (SeCO) \u7684\u5185\u5b58\u9ad8\u6548\u8bad\u7ec3\u8303\u5f0f\uff0c\u5c06\u957f\u8f93\u5165\u5212\u5206\u4e3a\u5c0f\u5757\uff0c\u6bcf\u5757\u72ec\u7acb\u6784\u5efa\u8ba1\u7b97\u56fe\u5e76\u8fdb\u884c\u5c40\u90e8\u53cd\u5411\u4f20\u64ad\uff0c\u4ece\u800c\u51cf\u5c11\u5185\u5b58\u5360\u7528\u3002\u8fdb\u4e00\u6b65\u5f15\u5165Sparse Chunk-wise Optimization (SpaCO)\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u5730\u5411\u7279\u5b9a\u5757\u4f20\u64ad\u68af\u5ea6\u5e76\u52a0\u5165\u8865\u507f\u56e0\u5b50\uff0c\u786e\u4fdd\u65e0\u504f\u68af\u5ea6\u4f30\u8ba1\uff0c\u540c\u65f6\u4f7f\u53cd\u5411\u4f20\u64ad\u7684\u8ba1\u7b97\u6210\u672c\u4e0e\u4e0a\u4e0b\u6587\u957f\u5ea6\u89e3\u8026\u3002", "result": "\u4f7f\u7528\u5355\u4e2aRTX 3090 GPU\u5bf98B\u6a21\u578b\u8fdb\u884cLoRA\u5fae\u8c03\u65f6\uff0cSeCO\u5c06\u6700\u5927\u5e8f\u5217\u957f\u5ea6\u4ece1K\u6269\u5c55\u523016K tokens\uff1b\u800cSpaCO\u5728\u76f8\u540c\u5b9e\u9a8c\u8bbe\u7f6e\u4e0b\u6bd4SeCO\u5feb3\u500d\u3002", "conclusion": "SeCO\u548cSpaCO\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u8bad\u7ec3\u5305\u88c5\u5668\uff0c\u63d0\u4f9b\u4e86\u663e\u8457\u7684\u5b9e\u9645\u597d\u5904\uff0c\u964d\u4f4e\u4e86\u957f\u4e0a\u4e0b\u6587\u6a21\u578b\u7684\u8bad\u7ec3\u95e8\u69db\uff0c\u5e76\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u591a\u53ef\u80fd\u6027\u3002"}}
{"id": "2505.16724", "pdf": "https://arxiv.org/pdf/2505.16724", "abs": "https://arxiv.org/abs/2505.16724", "authors": ["Konstantinos Barmpas", "Na Lee", "Yannis Panagakis", "Dimitrios A. Adamos", "Nikolaos Laskaris", "Stefanos Zafeiriou"], "title": "Advancing Brainwave Modeling with a Codebook-Based Foundation Model", "categories": ["cs.LG", "cs.AI", "cs.HC"], "comment": null, "summary": "Recent advances in large-scale pre-trained Electroencephalogram (EEG) models\nhave shown great promise, driving progress in Brain-Computer Interfaces (BCIs)\nand healthcare applications. However, despite their success, many existing\npre-trained models have struggled to fully capture the rich information content\nof neural oscillations, a limitation that fundamentally constrains their\nperformance and generalizability across diverse BCI tasks. This limitation is\nfrequently rooted in suboptimal architectural design choices which constrain\ntheir representational capacity. In this work, we introduce LaBraM++, an\nenhanced Large Brainwave Foundation Model (LBM) that incorporates principled\nimprovements grounded in robust signal processing foundations. LaBraM++\ndemonstrates substantial gains across a variety of tasks, consistently\noutperforming its originally-based architecture and achieving competitive\nresults when compared to other open-source LBMs. Its superior performance and\ntraining efficiency highlight its potential as a strong foundation for future\nadvancements in LBMs.", "AI": {"tldr": "\u8fd1\u671f\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u8111\u7535\u56fe\uff08EEG\uff09\u6a21\u578b\u7684\u53d1\u5c55\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u63a8\u52a8\u4e86\u8111\u673a\u63a5\u53e3\uff08BCI\uff09\u548c\u533b\u7597\u5065\u5eb7\u5e94\u7528\u7684\u8fdb\u6b65\u3002\u7136\u800c\uff0c\u8bb8\u591a\u73b0\u6709\u6a21\u578b\u672a\u80fd\u5145\u5206\u6355\u6349\u795e\u7ecf\u632f\u8361\u7684\u4e30\u5bcc\u4fe1\u606f\u5185\u5bb9\uff0c\u8fd9\u4ece\u6839\u672c\u4e0a\u9650\u5236\u4e86\u5b83\u4eec\u5728\u591a\u6837\u5316BCI\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u5927\u578b\u8111\u7535\u57fa\u7840\u6a21\u578bLaBraM++\uff0c\u901a\u8fc7\u57fa\u4e8e\u7a33\u5065\u4fe1\u53f7\u5904\u7406\u539f\u7406\u7684\u539f\u5219\u6027\u6539\u8fdb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u4f18\u4e8e\u5176\u539f\u59cb\u67b6\u6784\uff0c\u5e76\u5728\u4e0e\u5176\u4ed6\u5f00\u6e90LBM\u7684\u7ade\u4e89\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u7684\u5927\u89c4\u6a21\u9884\u8bad\u7ec3EEG\u6a21\u578b\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5b83\u4eec\u5728\u6355\u6349\u795e\u7ecf\u632f\u8361\u7684\u4e30\u5bcc\u4fe1\u606f\u5185\u5bb9\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u8fd9\u4e00\u5c40\u9650\u6027\u6e90\u4e8e\u6b21\u4f18\u7684\u67b6\u6784\u8bbe\u8ba1\u9009\u62e9\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u8868\u73b0\u548c\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u6539\u8fdb\u7684\u6a21\u578b\u67b6\u6784\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "method": "\u5f15\u5165\u4e86\u589e\u5f3a\u578b\u5927\u5c3a\u5ea6\u8111\u7535\u57fa\u7840\u6a21\u578bLaBraM++\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u57fa\u4e8e\u7a33\u5065\u4fe1\u53f7\u5904\u7406\u539f\u7406\u7684\u6539\u8fdb\uff0c\u4f18\u5316\u4e86\u5176\u8868\u793a\u80fd\u529b\uff0c\u4ece\u800c\u514b\u670d\u4e86\u4f20\u7edf\u6a21\u578b\u5728\u6355\u6349\u795e\u7ecf\u632f\u8361\u4fe1\u606f\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "result": "LaBraM++\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u5c55\u793a\u4e86\u663e\u8457\u7684\u63d0\u5347\uff0c\u4e0d\u4ec5\u8d85\u8d8a\u4e86\u5176\u539f\u672c\u7684\u67b6\u6784\uff0c\u8fd8\u4e0e\u5176\u5b83\u5f00\u6e90\u7684\u5927\u89c4\u6a21\u8111\u7535\u57fa\u7840\u6a21\u578b\uff08LBM\uff09\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\uff0c\u540c\u65f6\u5177\u5907\u66f4\u9ad8\u7684\u8bad\u7ec3\u6548\u7387\u3002", "conclusion": "LaBraM++\u51ed\u501f\u5176\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u9ad8\u6548\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u4e3a\u672a\u6765LBMs\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u57fa\u7840\u3002"}}
{"id": "2505.16725", "pdf": "https://arxiv.org/pdf/2505.16725", "abs": "https://arxiv.org/abs/2505.16725", "authors": ["Phillip Mueller", "Jannik Wiese", "Sebastian Mueller", "Lars Mikelsons"], "title": "Masked Conditioning for Deep Generative Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Datasets in engineering domains are often small, sparsely labeled, and\ncontain numerical as well as categorical conditions. Additionally.\ncomputational resources are typically limited in practical applications which\nhinders the adoption of generative models for engineering tasks. We introduce a\nnovel masked-conditioning approach, that enables generative models to work with\nsparse, mixed-type data. We mask conditions during training to simulate sparse\nconditions at inference time. For this purpose, we explore the use of various\nsparsity schedules that show different strengths and weaknesses. In addition,\nwe introduce a flexible embedding that deals with categorical as well as\nnumerical conditions. We integrate our method into an efficient variational\nautoencoder as well as a latent diffusion model and demonstrate the\napplicability of our approach on two engineering-related datasets of 2D point\nclouds and images. Finally, we show that small models trained on limited data\ncan be coupled with large pretrained foundation models to improve generation\nquality while retaining the controllability induced by our conditioning scheme.", "AI": {"tldr": "\u5728\u5de5\u7a0b\u9886\u57df\uff0c\u6570\u636e\u96c6\u901a\u5e38\u8f83\u5c0f\u3001\u7a00\u758f\u6807\u8bb0\uff0c\u5e76\u5305\u542b\u6570\u503c\u548c\u5206\u7c7b\u6761\u4ef6\u3002\u7531\u4e8e\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\uff0c\u751f\u6210\u6a21\u578b\u96be\u4ee5\u5e94\u7528\u4e8e\u5de5\u7a0b\u4efb\u52a1\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5c4f\u853d\u6761\u4ef6\u65b9\u6cd5\uff0c\u4f7f\u751f\u6210\u6a21\u578b\u80fd\u591f\u5904\u7406\u7a00\u758f\u3001\u6df7\u5408\u7c7b\u578b\u7684\u6570\u636e\u3002\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5c4f\u853d\u6761\u4ef6\uff0c\u6a21\u62df\u63a8\u7406\u65f6\u7684\u7a00\u758f\u6761\u4ef6\uff0c\u5e76\u63a2\u7d22\u4e0d\u540c\u7684\u7a00\u758f\u65f6\u95f4\u8868\u3002\u6b64\u5916\uff0c\u5f15\u5165\u4e86\u4e00\u79cd\u7075\u6d3b\u7684\u5d4c\u5165\u65b9\u5f0f\uff0c\u53ef\u4ee5\u5904\u7406\u5206\u7c7b\u548c\u6570\u503c\u6761\u4ef6\u3002\u6211\u4eec\u5c06\u8fd9\u79cd\u65b9\u6cd5\u96c6\u6210\u5230\u9ad8\u6548\u7684\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548c\u6f5c\u5728\u6269\u6563\u6a21\u578b\u4e2d\uff0c\u5e76\u5728\u4e24\u4e2a\u4e0e\u5de5\u7a0b\u76f8\u5173\u76842D\u70b9\u4e91\u548c\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u9002\u7528\u6027\u3002\u6700\u540e\uff0c\u6211\u4eec\u8868\u660e\u5c0f\u578b\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u4e0e\u5927\u578b\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u7ed3\u5408\uff0c\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u6211\u4eec\u6761\u4ef6\u65b9\u6848\u5e26\u6765\u7684\u53ef\u63a7\u6027\u3002", "motivation": "\u5de5\u7a0b\u9886\u57df\u7684\u6570\u636e\u96c6\u901a\u5e38\u8f83\u5c0f\u3001\u6807\u8bb0\u7a00\u758f\u4e14\u5305\u542b\u6570\u503c\u53ca\u5206\u7c7b\u6761\u4ef6\u3002\u6b64\u5916\uff0c\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8ba1\u7b97\u8d44\u6e90\u901a\u5e38\u6709\u9650\uff0c\u8fd9\u963b\u788d\u4e86\u751f\u6210\u6a21\u578b\u5728\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5c4f\u853d\u6761\u4ef6\u65b9\u6cd5\uff0c\u4f7f\u751f\u6210\u6a21\u578b\u80fd\u591f\u5904\u7406\u7a00\u758f\u3001\u6df7\u5408\u7c7b\u578b\u7684\u6570\u636e\u3002\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5c4f\u853d\u6761\u4ef6\u6765\u6a21\u62df\u63a8\u7406\u65f6\u7684\u7a00\u758f\u6761\u4ef6\uff0c\u5e76\u63a2\u7d22\u4e0d\u540c\u7684\u7a00\u758f\u65f6\u95f4\u8868\u3002\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u7075\u6d3b\u7684\u5d4c\u5165\u65b9\u5f0f\uff0c\u53ef\u4ee5\u5904\u7406\u5206\u7c7b\u548c\u6570\u503c\u6761\u4ef6\u3002\u5c06\u8be5\u65b9\u6cd5\u96c6\u6210\u5230\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548c\u6f5c\u5728\u6269\u6563\u6a21\u578b\u4e2d\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e24\u4e2a\u4e0e\u5de5\u7a0b\u76f8\u5173\u76842D\u70b9\u4e91\u548c\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u9002\u7528\u6027\u3002\u5c0f\u578b\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u4e0e\u5927\u578b\u9884\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u7ed3\u5408\uff0c\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u6761\u4ef6\u65b9\u6848\u5e26\u6765\u7684\u53ef\u63a7\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u5c4f\u853d\u6761\u4ef6\u65b9\u6cd5\u6210\u529f\u4f7f\u751f\u6210\u6a21\u578b\u9002\u5e94\u7a00\u758f\u3001\u6df7\u5408\u7c7b\u578b\u7684\u5de5\u7a0b\u6570\u636e\uff0c\u5e76\u4e14\u901a\u8fc7\u4e0e\u5927\u578b\u9884\u8bad\u7ec3\u6a21\u578b\u7ed3\u5408\uff0c\u53ef\u4ee5\u5728\u6709\u9650\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u4e0b\u5b9e\u73b0\u9ad8\u8d28\u91cf\u751f\u6210\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u63a7\u6027\u3002"}}
{"id": "2505.16733", "pdf": "https://arxiv.org/pdf/2505.16733", "abs": "https://arxiv.org/abs/2505.16733", "authors": ["Ziwei Luo", "Fredrik K. Gustafsson", "Jens Sj\u00f6lund", "Thomas B. Sch\u00f6n"], "title": "Forward-only Diffusion Probabilistic Models", "categories": ["cs.LG"], "comment": "Project page: https://algolzw.github.io/fod", "summary": "This work presents a forward-only diffusion (FoD) approach for generative\nmodelling. In contrast to traditional diffusion models that rely on a coupled\nforward-backward diffusion scheme, FoD directly learns data generation through\na single forward diffusion process, yielding a simple yet efficient generative\nframework. The core of FoD is a state-dependent linear stochastic differential\nequation that involves a mean-reverting term in both the drift and diffusion\nfunctions. This mean-reversion property guarantees the convergence to clean\ndata, naturally simulating a stochastic interpolation between source and target\ndistributions. More importantly, FoD is analytically tractable and is trained\nusing a simple stochastic flow matching objective, enabling a few-step\nnon-Markov chain sampling during inference. The proposed FoD model, despite its\nsimplicity, achieves competitive performance on various image-conditioned\n(e.g., image restoration) and unconditional generation tasks, demonstrating its\neffectiveness in generative modelling. Our code is available at\nhttps://github.com/Algolzw/FoD.", "AI": {"tldr": "This paper introduces a forward-only diffusion (FoD) approach for generative modelling which simplifies the process by eliminating the need for a coupled forward-backward diffusion scheme. Instead, FoD employs a single forward diffusion process based on a state-dependent linear stochastic differential equation with mean-reverting properties that guarantee convergence to clean data. FoD is analytically tractable and trained using a simple stochastic flow matching objective, making it efficient for various image generation tasks.", "motivation": "The motivation behind this paper is to simplify the generative modeling process by eliminating the complexity of traditional diffusion models that rely on both forward and backward diffusion processes. By doing so, they aim to create a more efficient framework for data generation.", "method": "The method involves developing a forward-only diffusion model based on a state-dependent linear stochastic differential equation that includes a mean-reverting term in both the drift and diffusion functions. This allows the model to converge to clean data and simulate a stochastic interpolation between source and target distributions.", "result": "FoD achieves competitive performance on various image-conditioned and unconditional generation tasks, demonstrating its effectiveness in generative modeling despite its simplicity.", "conclusion": "The conclusion is that the proposed FoD model offers a simplified yet effective approach to generative modeling, achieving competitive results on different types of generation tasks."}}
{"id": "2505.16734", "pdf": "https://arxiv.org/pdf/2505.16734", "abs": "https://arxiv.org/abs/2505.16734", "authors": ["Bang You", "Puze Liu", "Huaping Liu", "Jan Peters", "Oleg Arenz"], "title": "Maximum Total Correlation Reinforcement Learning", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Simplicity is a powerful inductive bias. In reinforcement learning,\nregularization is used for simpler policies, data augmentation for simpler\nrepresentations, and sparse reward functions for simpler objectives, all that,\nwith the underlying motivation to increase generalizability and robustness by\nfocusing on the essentials. Supplementary to these techniques, we investigate\nhow to promote simple behavior throughout the episode. To that end, we\nintroduce a modification of the reinforcement learning problem that\nadditionally maximizes the total correlation within the induced trajectories.\nWe propose a practical algorithm that optimizes all models, including policy\nand state representation, based on a lower-bound approximation. In simulated\nrobot environments, our method naturally generates policies that induce\nperiodic and compressible trajectories, and that exhibit superior robustness to\nnoise and changes in dynamics compared to baseline methods, while also\nimproving performance in the original tasks.", "AI": {"tldr": "\u901a\u8fc7\u6700\u5927\u5316\u8bf1\u5bfc\u8f68\u8ff9\u5185\u7684\u603b\u76f8\u5173\u6027\u6765\u4fc3\u8fdb\u7b80\u5355\u884c\u4e3a\uff0c\u63d0\u51fa\u4e00\u79cd\u4f18\u5316\u7b56\u7565\u548c\u72b6\u6001\u8868\u793a\u7684\u7b97\u6cd5\uff0c\u5728\u6a21\u62df\u673a\u5668\u4eba\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u9c81\u68d2\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u7b80\u5355\u6027\u662f\u4e00\u4e2a\u5f3a\u6709\u529b\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u6b63\u5219\u5316\u3001\u6570\u636e\u589e\u5f3a\u548c\u7a00\u758f\u5956\u52b1\u51fd\u6570\u7b49\u6280\u672f\u90fd\u662f\u4e3a\u4e86\u4f7f\u7b56\u7565\u3001\u8868\u793a\u548c\u76ee\u6807\u66f4\u7b80\u5355\uff0c\u4ece\u800c\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002\u672c\u6587\u8865\u5145\u4e86\u8fd9\u4e9b\u6280\u672f\uff0c\u7814\u7a76\u5982\u4f55\u5728\u6574\u4e2a\u8fc7\u7a0b\u4e2d\u4fc3\u8fdb\u7b80\u5355\u884c\u4e3a\u3002", "method": "\u5f15\u5165\u5bf9\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u7684\u4fee\u6539\uff0c\u4ee5\u989d\u5916\u6700\u5927\u5316\u8bf1\u5bfc\u8f68\u8ff9\u5185\u7684\u603b\u76f8\u5173\u6027\uff0c\u5e76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4e0b\u754c\u8fd1\u4f3c\u7684\u5b9e\u7528\u7b97\u6cd5\uff0c\u4f18\u5316\u6240\u6709\u6a21\u578b\uff0c\u5305\u62ec\u7b56\u7565\u548c\u72b6\u6001\u8868\u793a\u3002", "result": "\u5728\u6a21\u62df\u673a\u5668\u4eba\u73af\u5883\u4e2d\uff0c\u8be5\u65b9\u6cd5\u81ea\u7136\u751f\u6210\u8bf1\u5bfc\u5468\u671f\u6027\u548c\u53ef\u538b\u7f29\u8f68\u8ff9\u7684\u7b56\u7565\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u5bf9\u566a\u58f0\u548c\u52a8\u6001\u53d8\u5316\u7684\u4f18\u8d8a\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u5728\u539f\u59cb\u4efb\u52a1\u4e2d\u4e5f\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u6700\u5927\u5316\u8f68\u8ff9\u5185\u7684\u603b\u76f8\u5173\u6027\uff0c\u53ef\u4ee5\u751f\u6210\u66f4\u7b80\u5355\u3001\u66f4\u9c81\u68d2\u7684\u884c\u4e3a\u7b56\u7565\uff0c\u8fd9\u79cd\u7b56\u7565\u5728\u9762\u5bf9\u73af\u5883\u53d8\u5316\u65f6\u8868\u73b0\u66f4\u597d\uff0c\u540c\u65f6\u5728\u539f\u59cb\u4efb\u52a1\u4e0a\u4e5f\u6709\u66f4\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2505.16736", "pdf": "https://arxiv.org/pdf/2505.16736", "abs": "https://arxiv.org/abs/2505.16736", "authors": ["Nicolas Keriven"], "title": "Backward Oversmoothing: why is it hard to train deep Graph Neural Networks?", "categories": ["cs.LG"], "comment": null, "summary": "Oversmoothing has long been identified as a major limitation of Graph Neural\nNetworks (GNNs): input node features are smoothed at each layer and converge to\na non-informative representation, if the weights of the GNN are sufficiently\nbounded. This assumption is crucial: if, on the contrary, the weights are\nsufficiently large, then oversmoothing may not happen. Theoretically, GNN could\nthus learn to not oversmooth. However it does not really happen in practice,\nwhich prompts us to examine oversmoothing from an optimization point of view.\nIn this paper, we analyze backward oversmoothing, that is, the notion that\nbackpropagated errors used to compute gradients are also subject to\noversmoothing from output to input. With non-linear activation functions, we\noutline the key role of the interaction between forward and backward smoothing.\nMoreover, we show that, due to backward oversmoothing, GNNs provably exhibit\nmany spurious stationary points: as soon as the last layer is trained, the\nwhole GNN is at a stationary point. As a result, we can exhibit regions where\ngradients are near-zero while the loss stays high. The proof relies on the fact\nthat, unlike forward oversmoothing, backward errors are subjected to a linear\noversmoothing even in the presence of non-linear activation function, such that\nthe average of the output error plays a key role. Additionally, we show that\nthis phenomenon is specific to deep GNNs, and exhibit counter-example\nMulti-Layer Perceptron. This paper is a step toward a more complete\ncomprehension of the optimization landscape specific to GNNs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u4e2d\u7684\u8fc7\u5e73\u6ed1\u95ee\u9898\uff0c\u5e76\u4ece\u4f18\u5316\u7684\u89d2\u5ea6\u5206\u6790\u4e86\u53cd\u5411\u4f20\u64ad\u4e2d\u7684\u8fc7\u5e73\u6ed1\u73b0\u8c61\u3002\u4f5c\u8005\u6307\u51fa\uff0c\u7531\u4e8e\u53cd\u5411\u8fc7\u5e73\u6ed1\uff0cGNN\u5b58\u5728\u8bb8\u591a\u865a\u5047\u7684\u9a7b\u70b9\uff0c\u8fd9\u5bfc\u81f4\u5728\u635f\u5931\u4ecd\u7136\u8f83\u9ad8\u65f6\u68af\u5ea6\u63a5\u8fd1\u96f6\u3002\u6b64\u5916\uff0c\u8fd9\u79cd\u73b0\u8c61\u4e3b\u8981\u51fa\u73b0\u5728\u6df1\u5c42GNN\u4e2d\uff0c\u800c\u975e\u591a\u5c42\u611f\u77e5\u5668\uff08MLP\uff09\u3002", "motivation": "\u8fc7\u5e73\u6ed1\u662fGNN\u7684\u4e00\u4e2a\u4e3b\u8981\u9650\u5236\uff0c\u5c3d\u7ba1\u7406\u8bba\u4e0a\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u6743\u91cd\u907f\u514d\u8fc7\u5e73\u6ed1\uff0c\u4f46\u5b9e\u9645\u4e0a\u5e76\u672a\u53d1\u751f\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4ece\u4f18\u5316\u7684\u89d2\u5ea6\u91cd\u65b0\u5ba1\u89c6\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u5206\u6790\u4e86\u53cd\u5411\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u7684\u8fc7\u5e73\u6ed1\u73b0\u8c61\uff0c\u5373\u7528\u4e8e\u8ba1\u7b97\u68af\u5ea6\u7684\u53cd\u5411\u4f20\u64ad\u8bef\u5dee\u4e5f\u53d7\u5230\u8fc7\u5e73\u6ed1\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\uff0c\u7814\u7a76\u4e86\u524d\u5411\u548c\u53cd\u5411\u8fc7\u5e73\u6ed1\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u5e76\u8bc1\u660e\u4e86\u7531\u4e8e\u53cd\u5411\u8fc7\u5e73\u6ed1\uff0c\u53ea\u8981\u6700\u540e\u4e00\u5c42\u88ab\u8bad\u7ec3\uff0c\u6574\u4e2aGNN\u5c31\u5904\u4e8e\u4e00\u4e2a\u9a7b\u70b9\u3002", "result": "\u53d1\u73b0\u4e86\u6df1\u5c42GNN\u4e2d\u7531\u4e8e\u53cd\u5411\u8fc7\u5e73\u6ed1\u800c\u5bfc\u81f4\u7684\u865a\u5047\u9a7b\u70b9\u73b0\u8c61\uff0c\u5e76\u5c55\u793a\u4e86\u68af\u5ea6\u63a5\u8fd1\u96f6\u800c\u635f\u5931\u4ecd\u9ad8\u7684\u533a\u57df\u3002\u6b64\u5916\uff0c\u8bc1\u660e\u4e86\u8fd9\u79cd\u73b0\u8c61\u4ec5\u9650\u4e8eGNN\uff0c\u800c\u4e0d\u9002\u7528\u4e8eMLP\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86GNN\u4f18\u5316\u8fc7\u7a0b\u4e2d\u5b58\u5728\u7684\u72ec\u7279\u6311\u6218\uff0c\u5e76\u4e3a\u7406\u89e3GNN\u7279\u5b9a\u7684\u4f18\u5316\u666f\u89c2\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u8ba4\u8bc6\u3002"}}
{"id": "2505.16737", "pdf": "https://arxiv.org/pdf/2505.16737", "abs": "https://arxiv.org/abs/2505.16737", "authors": ["Chengcan Wu", "Zhixin Zhang", "Zeming Wei", "Yihao Zhang", "Meng Sun"], "title": "Mitigating Fine-tuning Risks in LLMs via Safety-Aware Probing Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR", "math.OC"], "comment": null, "summary": "The significant progress of large language models (LLMs) has led to\nremarkable achievements across numerous applications. However, their ability to\ngenerate harmful content has sparked substantial safety concerns. Despite the\nimplementation of safety alignment techniques during the pre-training phase,\nrecent research indicates that fine-tuning LLMs on adversarial or even benign\ndata can inadvertently compromise their safety. In this paper, we re-examine\nthe fundamental issue of why fine-tuning on non-harmful data still results in\nsafety degradation. We introduce a safety-aware probing (SAP) optimization\nframework designed to mitigate the safety risks of fine-tuning LLMs.\nSpecifically, SAP incorporates a safety-aware probe into the gradient\npropagation process, mitigating the model's risk of safety degradation by\nidentifying potential pitfalls in gradient directions, thereby enhancing\ntask-specific performance while successfully preserving model safety. Our\nextensive experimental results demonstrate that SAP effectively reduces\nharmfulness below the original fine-tuned model and achieves comparable test\nloss to standard fine-tuning methods. Our code is available at\nhttps://github.com/ChengcanWu/SAP.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c3d\u7ba1\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u91c7\u7528\u4e86\u5b89\u5168\u5bf9\u9f50\u6280\u672f\uff0c\u4f46\u5fae\u8c03\u65f6\u4ecd\u53ef\u80fd\u56e0\u5bf9\u6297\u6027\u6216\u826f\u6027\u6570\u636e\u5bfc\u81f4\u5b89\u5168\u6027\u4e0b\u964d\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u6846\u67b6\u2014\u2014\u5b89\u5168\u611f\u77e5\u63a2\u6d4b\uff08SAP\uff09\uff0c\u901a\u8fc7\u5728\u68af\u5ea6\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u52a0\u5165\u5b89\u5168\u63a2\u6d4b\u673a\u5236\uff0c\u8bc6\u522b\u6f5c\u5728\u98ce\u9669\u65b9\u5411\uff0c\u4ece\u800c\u7f13\u89e3\u5b89\u5168\u6027\u4e0b\u964d\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0cSAP\u80fd\u6709\u6548\u964d\u4f4e\u6709\u5bb3\u5185\u5bb9\u751f\u6210\uff0c\u5e76\u4fdd\u6301\u4e0e\u6807\u51c6\u5fae\u8c03\u65b9\u6cd5\u76f8\u5f53\u7684\u6d4b\u8bd5\u635f\u5931\u3002", "motivation": "\u5c3d\u7ba1\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u5b9e\u65bd\u4e86\u5b89\u5168\u5bf9\u9f50\u6280\u672f\uff0c\u4f46\u5fae\u8c03LLMs\u65f6\uff0c\u5373\u4f7f\u662f\u975e\u6709\u5bb3\u6570\u636e\u4e5f\u53ef\u80fd\u5bfc\u81f4\u5b89\u5168\u6027\u4e0b\u964d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u5e76\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u786e\u4fdd\u5fae\u8c03\u540e\u7684\u6a21\u578b\u4ecd\u7136\u5b89\u5168\u53ef\u9760\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u5b89\u5168\u611f\u77e5\u63a2\u6d4b\uff08SAP\uff09\u7684\u4f18\u5316\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u5c06\u5b89\u5168\u63a2\u6d4b\u6a21\u5757\u5d4c\u5165\u5230\u68af\u5ea6\u4f20\u64ad\u8fc7\u7a0b\u4e2d\uff0c\u8bc6\u522b\u53ef\u80fd\u5bfc\u81f4\u5b89\u5168\u6027\u4e0b\u964d\u7684\u98ce\u9669\u65b9\u5411\uff0c\u4ece\u800c\u51cf\u5c11\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u6027\u9000\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSAP\u80fd\u591f\u663e\u8457\u964d\u4f4e\u5fae\u8c03\u540e\u6a21\u578b\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u7684\u53ef\u80fd\u6027\uff0c\u540c\u65f6\u5176\u6d4b\u8bd5\u635f\u5931\u4e0e\u6807\u51c6\u5fae\u8c03\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "SAP\u6846\u67b6\u4e3a\u7f13\u89e3LLMs\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7684\u5b89\u5168\u6027\u4e0b\u964d\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u7684\u540c\u65f6\uff0c\u6210\u529f\u4fdd\u7559\u6a21\u578b\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2505.16790", "pdf": "https://arxiv.org/pdf/2505.16790", "abs": "https://arxiv.org/abs/2505.16790", "authors": ["Hyunjin Seo", "Taewon Kim", "Sihyun Yu", "SungSoo Ahn"], "title": "Learning Flexible Forward Trajectories for Masked Molecular Diffusion", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Masked diffusion models (MDMs) have achieved notable progress in modeling\ndiscrete data, while their potential in molecular generation remains\nunderexplored. In this work, we explore their potential and introduce the\nsurprising result that naively applying standards MDMs severely degrades the\nperformance. We identify the critical cause of this issue as a state-clashing\nproblem-where the forward diffusion of distinct molecules collapse into a\ncommon state, resulting in a mixture of reconstruction targets that cannot be\nlearned using typical reverse diffusion process with unimodal predictions. To\nmitigate this, we propose Masked Element-wise Learnable Diffusion (MELD) that\norchestrates per-element corruption trajectories to avoid collision between\ndistinct molecular graphs. This is achieved through a parameterized noise\nscheduling network that assigns distinct corruption rates to individual graph\nelements, i.e., atoms and bonds. Extensive experiments on diverse molecular\nbenchmarks reveal that MELD markedly enhances overall generation quality\ncompared to element-agnostic noise scheduling, increasing the chemical validity\nof vanilla MDMs on ZINC250K from 15% to 93%, Furthermore, it achieves\nstate-of-the-art property alignment in conditional generation tasks.", "AI": {"tldr": "\u63a2\u7d22\u4e86Masked\u6269\u6563\u6a21\u578b\uff08MDMs\uff09\u5728\u5206\u5b50\u751f\u6210\u4e2d\u7684\u6f5c\u529b\uff0c\u53d1\u73b0\u76f4\u63a5\u5e94\u7528\u6807\u51c6MDMs\u4f1a\u5bfc\u81f4\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u95ee\u9898\u7684\u6839\u6e90\u662f\u72b6\u6001\u51b2\u7a81\u95ee\u9898\uff0c\u5373\u4e0d\u540c\u5206\u5b50\u7684\u524d\u5411\u6269\u6563\u4f1a\u584c\u7f29\u5230\u540c\u4e00\u72b6\u6001\uff0c\u5bfc\u81f4\u53cd\u5411\u6269\u6563\u8fc7\u7a0b\u65e0\u6cd5\u5b66\u4e60\u3002\u4e3a\u4e86\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u2014\u2014Masked Element-wise Learnable Diffusion\uff08MELD\uff09\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u566a\u58f0\u8c03\u5ea6\u7f51\u7edc\u4e3a\u6bcf\u4e2a\u56fe\u5143\u7d20\u5206\u914d\u4e0d\u540c\u7684\u8150\u8680\u7387\uff0c\u4ece\u800c\u907f\u514d\u5206\u5b50\u56fe\u4e4b\u95f4\u7684\u51b2\u7a81\u3002\u5b9e\u9a8c\u8868\u660e\uff0cMELD\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u5b50\u751f\u6210\u8d28\u91cf\uff0c\u5e76\u5728\u6761\u4ef6\u751f\u6210\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5c5e\u6027\u5bf9\u9f50\u6548\u679c\u3002", "motivation": "\u5c3d\u7ba1Masked\u6269\u6563\u6a21\u578b\uff08MDMs\uff09\u5728\u79bb\u6563\u6570\u636e\u5efa\u6a21\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5176\u5728\u5206\u5b50\u751f\u6210\u9886\u57df\u7684\u6f5c\u529b\u5c1a\u672a\u88ab\u5145\u5206\u6316\u6398\u3002\u7814\u7a76\u8005\u8bd5\u56fe\u63a2\u7d22MDMs\u5728\u5206\u5b50\u751f\u6210\u4e2d\u7684\u8868\u73b0\uff0c\u4f46\u53d1\u73b0\u76f4\u63a5\u5e94\u7528\u6807\u51c6MDMs\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e25\u91cd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMasked Element-wise Learnable Diffusion\uff08MELD\uff09\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u53c2\u6570\u5316\u566a\u58f0\u8c03\u5ea6\u7f51\u7edc\u4e3a\u6bcf\u4e2a\u56fe\u5143\u7d20\uff08\u5982\u539f\u5b50\u548c\u952e\uff09\u5206\u914d\u4e0d\u540c\u7684\u8150\u8680\u7387\uff0c\u4ee5\u907f\u514d\u4e0d\u540c\u5206\u5b50\u56fe\u4e4b\u95f4\u7684\u51b2\u7a81\u3002\u5177\u4f53\u6765\u8bf4\uff0cMELD\u534f\u8c03\u4e86\u6bcf\u4e2a\u5143\u7d20\u7684\u8150\u8680\u8f68\u8ff9\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u72b6\u6001\u51b2\u7a81\u95ee\u9898\u3002", "result": "\u5728\u591a\u4e2a\u5206\u5b50\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMELD\u663e\u8457\u63d0\u9ad8\u4e86\u6574\u4f53\u751f\u6210\u8d28\u91cf\u3002\u4f8b\u5982\uff0c\u5728ZINC250K\u6570\u636e\u96c6\u4e0a\uff0c\u5316\u5b66\u6709\u6548\u6027\u4ece15%\u63d0\u9ad8\u5230\u4e8693%\u3002\u6b64\u5916\uff0cMELD\u5728\u6761\u4ef6\u751f\u6210\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5c5e\u6027\u5bf9\u9f50\u6548\u679c\u3002", "conclusion": "MELD\u901a\u8fc7\u89e3\u51b3\u72b6\u6001\u51b2\u7a81\u95ee\u9898\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u5b50\u751f\u6210\u7684\u8d28\u91cf\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u6761\u4ef6\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002\u8fd9\u8868\u660e\uff0c\u9488\u5bf9\u5206\u5b50\u56fe\u7279\u6027\u7684\u65b9\u6cd5\u8bbe\u8ba1\u5bf9\u4e8e\u63d0\u5347\u751f\u6210\u6a21\u578b\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2505.16791", "pdf": "https://arxiv.org/pdf/2505.16791", "abs": "https://arxiv.org/abs/2505.16791", "authors": ["Tillmann Rheude", "Roland Eils", "Benjamin Wild"], "title": "Cohort-Based Active Modality Acquisition", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real-world machine learning applications often involve data from multiple\nmodalities that must be integrated effectively to make robust predictions.\nHowever, in many practical settings, not all modalities are available for every\nsample, and acquiring additional modalities can be costly. This raises the\nquestion: which samples should be prioritized for additional modality\nacquisition when resources are limited? While prior work has explored\nindividual-level acquisition strategies and training-time active learning\nparadigms, test-time and cohort-based acquisition remain underexplored despite\ntheir importance in many real-world settings. We introduce Cohort-based Active\nModality Acquisition (CAMA), a novel test-time setting to formalize the\nchallenge of selecting which samples should receive additional modalities. We\nderive acquisition strategies that leverage a combination of generative\nimputation and discriminative modeling to estimate the expected benefit of\nacquiring missing modalities based on common evaluation metrics. We also\nintroduce upper-bound heuristics that provide performance ceilings to benchmark\nacquisition strategies. Experiments on common multimodal datasets demonstrate\nthat our proposed imputation-based strategies can more effectively guide the\nacquisition of new samples in comparison to those relying solely on unimodal\ninformation, entropy guidance, and random selections. Our work provides an\neffective solution for optimizing modality acquisition at the cohort level,\nenabling better utilization of resources in constrained settings.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCohort-based Active Modality Acquisition\uff08CAMA\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u51b3\u5b9a\u54ea\u4e9b\u6837\u672c\u5e94\u4f18\u5148\u83b7\u53d6\u989d\u5916\u7684\u6a21\u6001\u6570\u636e\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u751f\u6210\u5f0f\u586b\u8865\u548c\u5224\u522b\u5efa\u6a21\u6765\u4f30\u8ba1\u83b7\u53d6\u7f3a\u5931\u6a21\u6001\u7684\u9884\u671f\u6536\u76ca\uff0c\u5e76\u5f15\u5165\u4e0a\u9650\u542f\u53d1\u5f0f\u65b9\u6cd5\u4f5c\u4e3a\u6027\u80fd\u57fa\u51c6\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u4ec5\u4f9d\u8d56\u5355\u6a21\u6001\u4fe1\u606f\u3001\u71b5\u5f15\u5bfc\u6216\u968f\u673a\u9009\u62e9\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u57fa\u4e8e\u586b\u8865\u7684\u7b56\u7565\u66f4\u6709\u6548\u5730\u6307\u5bfc\u65b0\u6837\u672c\u7684\u83b7\u53d6\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u673a\u5668\u5b66\u4e60\u5e94\u7528\u5e38\u5e38\u9700\u8981\u6574\u5408\u6765\u81ea\u591a\u4e2a\u6a21\u6001\u7684\u6570\u636e\u4ee5\u8fdb\u884c\u7a33\u5065\u9884\u6d4b\u3002\u7136\u800c\uff0c\u5728\u8bb8\u591a\u5b9e\u9645\u60c5\u51b5\u4e0b\uff0c\u5e76\u975e\u6240\u6709\u6837\u672c\u7684\u6240\u6709\u6a21\u6001\u90fd\u53ef\u7528\uff0c\u4e14\u83b7\u53d6\u989d\u5916\u6a21\u6001\u53ef\u80fd\u6210\u672c\u9ad8\u6602\u3002\u8fd9\u63d0\u51fa\u4e86\u4e00\u4e2a\u95ee\u9898\uff1a\u5f53\u8d44\u6e90\u6709\u9650\u65f6\uff0c\u5e94\u8be5\u4f18\u5148\u4e3a\u54ea\u4e9b\u6837\u672c\u83b7\u53d6\u989d\u5916\u7684\u6a21\u6001\u6570\u636e\uff1f\u5c3d\u7ba1\u5df2\u6709\u5de5\u4f5c\u63a2\u7d22\u4e86\u4e2a\u4f53\u7ea7\u522b\u7684\u83b7\u53d6\u7b56\u7565\u548c\u8bad\u7ec3\u65f6\u95f4\u7684\u4e3b\u52a8\u5b66\u4e60\u8303\u5f0f\uff0c\u4f46\u5728\u6d4b\u8bd5\u65f6\u95f4\u548c\u57fa\u4e8e\u961f\u5217\u7684\u83b7\u53d6\u7b56\u7565\u65b9\u9762\u4ecd\u5b58\u5728\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u8bba\u6587\u5f15\u5165\u4e86\u961f\u5217\u57fa\u7840\u4e3b\u52a8\u6a21\u6001\u83b7\u53d6\uff08CAMA\uff09\uff0c\u4e00\u79cd\u65b0\u7684\u6d4b\u8bd5\u65f6\u95f4\u8bbe\u7f6e\uff0c\u7528\u4e8e\u5f62\u5f0f\u5316\u9009\u62e9\u54ea\u4e9b\u6837\u672c\u5e94\u63a5\u6536\u989d\u5916\u6a21\u6001\u7684\u95ee\u9898\u3002\u901a\u8fc7\u7ed3\u5408\u751f\u6210\u5f0f\u586b\u8865\u548c\u5224\u522b\u5efa\u6a21\uff0c\u63a8\u5bfc\u51fa\u83b7\u53d6\u7b56\u7565\uff0c\u4ee5\u6839\u636e\u5e38\u89c1\u8bc4\u4f30\u6307\u6807\u4f30\u8ba1\u83b7\u53d6\u7f3a\u5931\u6a21\u6001\u7684\u9884\u671f\u597d\u5904\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u63d0\u4f9b\u6027\u80fd\u4e0a\u9650\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u7528\u4f5c\u83b7\u53d6\u7b56\u7565\u7684\u57fa\u51c6\u3002", "result": "\u5728\u5e38\u89c1\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u586b\u8865\u7684\u7b56\u7565\u76f8\u8f83\u4e8e\u90a3\u4e9b\u4ec5\u4f9d\u8d56\u5355\u6a21\u6001\u4fe1\u606f\u3001\u71b5\u5f15\u5bfc\u548c\u968f\u673a\u9009\u62e9\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u6307\u5bfc\u65b0\u6837\u672c\u7684\u83b7\u53d6\u3002", "conclusion": "\u6211\u4eec\u7684\u5de5\u4f5c\u4e3a\u4f18\u5316\u961f\u5217\u7ea7\u522b\u7684\u6a21\u6001\u83b7\u53d6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u5f97\u5728\u53d7\u9650\u73af\u5883\u4e2d\u66f4\u597d\u5730\u5229\u7528\u8d44\u6e90\u6210\u4e3a\u53ef\u80fd\u3002"}}
{"id": "2505.16748", "pdf": "https://arxiv.org/pdf/2505.16748", "abs": "https://arxiv.org/abs/2505.16748", "authors": ["Julien Laasri", "Marc Revol"], "title": "Revenue Optimization with Price-Sensitive and Interdependent Demand", "categories": ["cs.LG", "math.OC", "90C59", "G.1.6"], "comment": "21 pages, 17 figures, dated 2018, in French", "summary": "As Kalyan T. Talluri and Garrett J. Van Ryzin describe in their work [3],\nRevenue Management aims to maximize an organization's revenue by considering\nthree types of decision categories: structural, pricing, and quantity. In this\ndocument, our primary focus will be on decisions related to pricing and\nquantity for the sale of airline tickets on a direct flight over a certain\nnumber of time periods. More specifically, we will only focus on the\noptimization aspect of this problem. We will assume the demand data to be\ngiven, since Air France estimates it beforehand using real data. Similarly, we\nassume all price options to be predetermined by Air France's algorithms and\nverified by their analysts. Our objective will be to maximize the revenue of a\ndirect flight by choosing the prices for each product from the predefined set\nof options.\n  --\n  Comme d\\'ecrit par Kalyan T. Talluri et Garrett J. Van Ryzin dans leur\nouvrage [3], le Revenue Management consiste en la maximisation du revenu d'un\norganisme \\`a partir de trois types de cat\\'egories de d\\'ecision :\nstructurelles, prix et quantit\\'e. Dans ce document, nous nous int\\'eresserons\nprincipalement aux d\\'ecisions de type prix et quantit\\'e pour la vente de\nbillets d'avion sur un vol direct au cours d'un certain nombre de pas de temps.\nPlus pr\\'ecis\\'ement, nous nous situerons dans la partie optimisation du\nprobl\\`eme. Nous prendrons ainsi les donn\\'ees de demande comme acquises, car\nelles sont estim\\'ees au pr\\'ealable par Air France \\`a partir des donn\\'ees\nr\\'eelles. De m\\^eme, pour chaque produit que l'on cherchera \\`a vendre, on\nnous impose en amont les prix possibles que l'on a droit d'utiliser et qui se\nbasent sur des algorithmes d'Air France dont les r\\'esultats sont v\\'erifi\\'es\npar des analystes. Notre but sera alors de maximiser le revenu d'un vol direct\nen choisissant les prix de chaque produit parmi ceux impos\\'es.", "AI": {"tldr": "The paper focuses on optimizing pricing and quantity decisions to maximize revenue for airline ticket sales on direct flights over specific time periods, assuming demand data and price options are predetermined.", "motivation": "To address the Revenue Management problem by focusing on pricing and quantity decisions to optimize revenue for airline ticket sales.", "method": "Using predefined demand data and price options, the method involves selecting optimal prices from a set of predetermined options to maximize revenue.", "result": "The result is an optimized approach to setting prices for each product to achieve maximum revenue for a direct flight.", "conclusion": "Revenue Management through pricing and quantity optimization can effectively maximize an organization's revenue in the context of airline ticket sales."}}
{"id": "2505.16801", "pdf": "https://arxiv.org/pdf/2505.16801", "abs": "https://arxiv.org/abs/2505.16801", "authors": ["Eleftherios Kalafatis", "Konstantinos Mitsis", "Konstantia Zarkogianni", "Maria Athanasiou", "Konstantina Nikita"], "title": "A modular framework for automated evaluation of procedural content generation in serious games with deep reinforcement learning agents", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Serious Games (SGs) are nowadays shifting focus to include procedural content\ngeneration (PCG) in the development process as a means of offering personalized\nand enhanced player experience. However, the development of a framework to\nassess the impact of PCG techniques when integrated into SGs remains\nparticularly challenging. This study proposes a methodology for automated\nevaluation of PCG integration in SGs, incorporating deep reinforcement learning\n(DRL) game testing agents. To validate the proposed framework, a previously\nintroduced SG featuring card game mechanics and incorporating three different\nversions of PCG for nonplayer character (NPC) creation has been deployed.\nVersion 1 features random NPC creation, while versions 2 and 3 utilize a\ngenetic algorithm approach. These versions are used to test the impact of\ndifferent dynamic SG environments on the proposed framework's agents. The\nobtained results highlight the superiority of the DRL game testing agents\ntrained on Versions 2 and 3 over those trained on Version 1 in terms of win\nrate (i.e. number of wins per played games) and training time. More\nspecifically, within the execution of a test emulating regular gameplay, both\nVersions 2 and 3 peaked at a 97% win rate and achieved statistically\nsignificant higher (p=0009) win rates compared to those achieved in Version 1\nthat peaked at 94%. Overall, results advocate towards the proposed framework's\ncapability to produce meaningful data for the evaluation of procedurally\ngenerated content in SGs.", "AI": {"tldr": "\u4e25\u8083\u6e38\u620f(SGs)\u6b63\u5728\u5c06\u8fc7\u7a0b\u5185\u5bb9\u751f\u6210(PCG)\u7eb3\u5165\u5f00\u53d1\u6d41\u7a0b\uff0c\u4ee5\u63d0\u4f9b\u4e2a\u6027\u5316\u548c\u589e\u5f3a\u7684\u73a9\u5bb6\u4f53\u9a8c\u3002\u7136\u800c\uff0c\u8bc4\u4f30PCG\u6280\u672f\u5728SGs\u4e2d\u7684\u5f71\u54cd\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60(DRL)\u6e38\u620f\u6d4b\u8bd5\u4ee3\u7406\u4eba\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u4e00\u4e2a\u5305\u542b\u4e09\u79cd\u4e0d\u540cNPC\u521b\u5efa\u7248\u672c\u7684\u5361\u724c\u6e38\u620f\u6765\u9a8c\u8bc1\u8be5\u6846\u67b6\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5728\u7248\u672c2\u548c3\u4e0a\u8bad\u7ec3\u7684DRL\u4ee3\u7406\u4eba\u5728\u80dc\u7387\u548c\u8bad\u7ec3\u65f6\u95f4\u4e0a\u4f18\u4e8e\u7248\u672c1\u4e0a\u7684\u4ee3\u7406\u4eba\u3002", "motivation": "\u8fc7\u7a0b\u5185\u5bb9\u751f\u6210\uff08PCG\uff09\u5728\u4e25\u8083\u6e38\u620f\u4e2d\u8d8a\u6765\u8d8a\u53d7\u5230\u5173\u6ce8\uff0c\u56e0\u4e3a\u5b83\u53ef\u4ee5\u63d0\u4f9b\u4e2a\u6027\u5316\u7684\u73a9\u5bb6\u4f53\u9a8c\u3002\u7136\u800c\uff0c\u76ee\u524d\u7f3a\u4e4f\u6709\u6548\u7684\u6846\u67b6\u6765\u8bc4\u4f30PCG\u6280\u672f\u5bf9\u4e25\u8083\u6e38\u620f\u7684\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u6e38\u620f\u6d4b\u8bd5\u4ee3\u7406\u4eba\u7684\u81ea\u52a8\u5316\u8bc4\u4f30\u65b9\u6cd5\u3002\u901a\u8fc7\u4f7f\u7528\u4e00\u4e2a\u5305\u542b\u4e09\u79cd\u4e0d\u540cNPC\u521b\u5efa\u7248\u672c\uff08\u968f\u673a\u521b\u5efa\u3001\u9057\u4f20\u7b97\u6cd5\uff09\u7684\u5361\u724c\u6e38\u620f\u6765\u9a8c\u8bc1\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728\u7248\u672c2\u548c3\u4e0a\u8bad\u7ec3\u7684DRL\u4ee3\u7406\u4eba\u5728\u80dc\u7387\u548c\u8bad\u7ec3\u65f6\u95f4\u4e0a\u4f18\u4e8e\u7248\u672c1\u4e0a\u7684\u4ee3\u7406\u4eba\u3002\u5177\u4f53\u800c\u8a00\uff0c\u7248\u672c2\u548c3\u7684\u80dc\u7387\u8fbe\u523097%\uff0c\u800c\u7248\u672c1\u4ec5\u4e3a94%\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u80fd\u591f\u751f\u6210\u6709\u610f\u4e49\u7684\u6570\u636e\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e25\u8083\u6e38\u620f\u4e2d\u7684\u8fc7\u7a0b\u751f\u6210\u5185\u5bb9\u7684\u6548\u679c\u3002"}}
{"id": "2505.16754", "pdf": "https://arxiv.org/pdf/2505.16754", "abs": "https://arxiv.org/abs/2505.16754", "authors": ["Hannah Markgraf", "Michael Eichelbeck", "Daria Cappey", "Selin Demirt\u00fcrk", "Yara Schattschneider", "Matthias Althoff"], "title": "PyTupli: A Scalable Infrastructure for Collaborative Offline Reinforcement Learning Projects", "categories": ["cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) has gained traction as a powerful\nparadigm for learning control policies from pre-collected data, eliminating the\nneed for costly or risky online interactions. While many open-source libraries\noffer robust implementations of offline RL algorithms, they all rely on\ndatasets composed of experience tuples consisting of state, action, next state,\nand reward. Managing, curating, and distributing such datasets requires\nsuitable infrastructure. Although static datasets exist for established\nbenchmark problems, no standardized or scalable solution supports developing\nand sharing datasets for novel or user-defined benchmarks. To address this gap,\nwe introduce PyTupli, a Python-based tool to streamline the creation, storage,\nand dissemination of benchmark environments and their corresponding tuple\ndatasets. PyTupli includes a lightweight client library with defined interfaces\nfor uploading and retrieving benchmarks and data. It supports fine-grained\nfiltering at both the episode and tuple level, allowing researchers to curate\nhigh-quality, task-specific datasets. A containerized server component enables\nproduction-ready deployment with authentication, access control, and automated\ncertificate provisioning for secure use. By addressing key barriers in dataset\ninfrastructure, PyTupli facilitates more collaborative, reproducible, and\nscalable offline RL research.", "AI": {"tldr": "Offline RL\u7814\u7a76\u4e2d\uff0c\u7ba1\u7406\u3001\u521b\u5efa\u548c\u5206\u4eab\u6570\u636e\u96c6\u5b58\u5728\u6311\u6218\u3002\u672c\u6587\u4ecb\u7ecdPyTupli\u5de5\u5177\uff0c\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4fc3\u8fdb\u66f4\u534f\u4f5c\u3001\u53ef\u91cd\u73b0\u548c\u53ef\u6269\u5c55\u7684\u79bb\u7ebfRL\u7814\u7a76\u3002", "motivation": "\u5c3d\u7ba1\u6709\u8bb8\u591a\u5f00\u6e90\u5e93\u63d0\u4f9b\u5f3a\u5927\u7684\u79bb\u7ebfRL\u7b97\u6cd5\u5b9e\u73b0\uff0c\u4f46\u7ba1\u7406\u548c\u5171\u4eab\u8fd9\u4e9b\u6240\u9700\u7684\u57fa\u4e8e\u7ecf\u9a8c\u5143\u7ec4\u7684\u6570\u636e\u96c6\u7f3a\u4e4f\u6807\u51c6\u5316\u548c\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8fd9\u9650\u5236\u4e86\u9488\u5bf9\u65b0\u95ee\u9898\u6216\u7528\u6237\u81ea\u5b9a\u4e49\u57fa\u51c6\u7684\u79bb\u7ebfRL\u7814\u7a76\u8fdb\u5c55\u3002", "method": "\u63d0\u51faPyTupli\u5de5\u5177\uff0c\u5305\u62ec\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5ba2\u6237\u7aef\u5e93\uff0c\u7528\u4e8e\u4e0a\u4f20\u548c\u68c0\u7d22\u57fa\u51c6\u73af\u5883\u53ca\u5176\u5bf9\u5e94\u7684\u6570\u636e\u96c6\uff1b\u652f\u6301\u7ec6\u7c92\u5ea6\u8fc7\u6ee4\uff0c\u4ee5\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u4efb\u52a1\u7279\u5b9a\u6570\u636e\u96c6\uff1b\u4ee5\u53ca\u4e00\u4e2a\u5bb9\u5668\u5316\u7684\u670d\u52a1\u5668\u7ec4\u4ef6\uff0c\u63d0\u4f9b\u8eab\u4efd\u9a8c\u8bc1\u3001\u8bbf\u95ee\u63a7\u5236\u548c\u81ea\u52a8\u8bc1\u4e66\u914d\u7f6e\uff0c\u786e\u4fdd\u5b89\u5168\u4f7f\u7528\u3002", "result": "PyTupli\u7b80\u5316\u4e86\u79bb\u7ebfRL\u4e2d\u57fa\u51c6\u73af\u5883\u548c\u6570\u636e\u96c6\u7684\u521b\u5efa\u3001\u5b58\u50a8\u548c\u5206\u53d1\u8fc7\u7a0b\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u5b89\u5168\u7684\u6570\u636e\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u89e3\u51b3\u6570\u636e\u96c6\u57fa\u7840\u8bbe\u65bd\u4e2d\u7684\u5173\u952e\u969c\u788d\uff0cPyTupli\u4fc3\u8fdb\u4e86\u66f4\u534f\u4f5c\u3001\u53ef\u91cd\u73b0\u548c\u53ef\u6269\u5c55\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7814\u7a76\u3002"}}
{"id": "2505.16856", "pdf": "https://arxiv.org/pdf/2505.16856", "abs": "https://arxiv.org/abs/2505.16856", "authors": ["Wei Xiao", "Jiacheng Liu", "Zifeng Zhuang", "Runze Suo", "Shangke Lyu", "Donglin Wang"], "title": "Efficient Online RL Fine Tuning with Offline Pre-trained Policy Only", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Improving the performance of pre-trained policies through online\nreinforcement learning (RL) is a critical yet challenging topic. Existing\nonline RL fine-tuning methods require continued training with offline\npretrained Q-functions for stability and performance. However, these offline\npretrained Q-functions commonly underestimate state-action pairs beyond the\noffline dataset due to the conservatism in most offline RL methods, which\nhinders further exploration when transitioning from the offline to the online\nsetting. Additionally, this requirement limits their applicability in scenarios\nwhere only pre-trained policies are available but pre-trained Q-functions are\nabsent, such as in imitation learning (IL) pre-training. To address these\nchallenges, we propose a method for efficient online RL fine-tuning using\nsolely the offline pre-trained policy, eliminating reliance on pre-trained\nQ-functions. We introduce PORL (Policy-Only Reinforcement Learning\nFine-Tuning), which rapidly initializes the Q-function from scratch during the\nonline phase to avoid detrimental pessimism. Our method not only achieves\ncompetitive performance with advanced offline-to-online RL algorithms and\nonline RL approaches that leverage data or policies prior, but also pioneers a\nnew path for directly fine-tuning behavior cloning (BC) policies.", "AI": {"tldr": "\u901a\u8fc7\u4ec5\u4f7f\u7528\u79bb\u7ebf\u9884\u8bad\u7ec3\u7b56\u7565\uff0cPORL\u65b9\u6cd5\u5728\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u4e3a\u76f4\u63a5\u5fae\u8c03\u884c\u4e3a\u514b\u9686\uff08BC\uff09\u7b56\u7565\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002", "motivation": "\u73b0\u6709\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u79bb\u7ebf\u9884\u8bad\u7ec3\u7684Q\u51fd\u6570\uff0c\u4f46\u8fd9\u4e9bQ\u51fd\u6570\u7531\u4e8e\u4fdd\u5b88\u6027\u9650\u5236\u4e86\u8fdb\u4e00\u6b65\u63a2\u7d22\uff0c\u5e76\u4e14\u5728\u4ec5\u6709\u9884\u8bad\u7ec3\u7b56\u7565\u53ef\u7528\u800c\u6ca1\u6709\u9884\u8bad\u7ec3Q\u51fd\u6570\u7684\u60c5\u51b5\u4e0b\u4e0d\u9002\u7528\u3002", "method": "\u63d0\u51faPORL\u65b9\u6cd5\uff0c\u4ec5\u4f7f\u7528\u79bb\u7ebf\u9884\u8bad\u7ec3\u7b56\u7565\u8fdb\u884c\u9ad8\u6548\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\uff0c\u901a\u8fc7\u5728\u7ebf\u9636\u6bb5\u4ece\u5934\u5feb\u901f\u521d\u59cb\u5316Q\u51fd\u6570\u4ee5\u907f\u514d\u60b2\u89c2\u4f30\u8ba1\u3002", "result": "PORL\u65b9\u6cd5\u4e0d\u4ec5\u4e0e\u5148\u8fdb\u7684\u79bb\u7ebf\u5230\u5728\u7ebfRL\u7b97\u6cd5\u548c\u5229\u7528\u6570\u636e\u6216\u7b56\u7565\u5148\u9a8c\u7684\u5728\u7ebfRL\u65b9\u6cd5\u5177\u6709\u7ade\u4e89\u529b\uff0c\u8fd8\u6210\u529f\u5730\u5b9e\u73b0\u4e86\u5bf9\u884c\u4e3a\u514b\u9686\u7b56\u7565\u7684\u76f4\u63a5\u5fae\u8c03\u3002", "conclusion": "PORL\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u5f53\u524d\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u4e2d\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u4ec5\u6709\u9884\u8bad\u7ec3\u7b56\u7565\u53ef\u7528\u7684\u60c5\u51b5\u3002"}}
{"id": "2505.16755", "pdf": "https://arxiv.org/pdf/2505.16755", "abs": "https://arxiv.org/abs/2505.16755", "authors": ["Ayano Nakai-Kasai", "Tadashi Wadayama"], "title": "Multi-Output Gaussian Processes for Graph-Structured Data", "categories": ["cs.LG"], "comment": null, "summary": "Graph-structured data is a type of data to be obtained associated with a\ngraph structure where vertices and edges describe some kind of data\ncorrelation. This paper proposes a regression method on graph-structured data,\nwhich is based on multi-output Gaussian processes (MOGP), to capture both the\ncorrelation between vertices and the correlation between associated data. The\nproposed formulation is built on the definition of MOGP. This allows it to be\napplied to a wide range of data configurations and scenarios. Moreover, it has\nhigh expressive capability due to its flexibility in kernel design. It includes\nexisting methods of Gaussian processes for graph-structured data as special\ncases and is possible to remove restrictions on data configurations, model\nselection, and inference scenarios in the existing methods. The performance of\nextensions achievable by the proposed formulation is evaluated through computer\nexperiments with synthetic and real data.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u8f93\u51fa\u9ad8\u65af\u8fc7\u7a0b\uff08MOGP\uff09\u7684\u56fe\u7ed3\u6784\u6570\u636e\u56de\u5f52\u65b9\u6cd5\uff0c\u80fd\u591f\u6355\u6349\u9876\u70b9\u95f4\u53ca\u5173\u8054\u6570\u636e\u95f4\u7684\u76f8\u5173\u6027\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u9ad8\u5ea6\u8868\u8fbe\u80fd\u529b\uff0c\u53ef\u5e94\u7528\u4e8e\u591a\u79cd\u6570\u636e\u914d\u7f6e\u548c\u573a\u666f\uff0c\u5e76\u901a\u8fc7\u8ba1\u7b97\u673a\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6269\u5c55\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u9ad8\u65af\u8fc7\u7a0b\u5728\u5904\u7406\u56fe\u7ed3\u6784\u6570\u636e\u65f6\u53d7\u5230\u6570\u636e\u914d\u7f6e\u3001\u6a21\u578b\u9009\u62e9\u548c\u63a8\u7406\u573a\u666f\u7684\u9650\u5236\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u7684\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u5e76\u63d0\u9ad8\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8eMOGP\u7684\u56fe\u7ed3\u6784\u6570\u636e\u56de\u5f52\u65b9\u6cd5\uff0c\u5229\u7528MOGP\u5b9a\u4e49\u6784\u5efa\u516c\u5f0f\u4ee5\u6355\u6349\u9876\u70b9\u95f4\u548c\u5173\u8054\u6570\u636e\u95f4\u7684\u76f8\u5173\u6027\uff0c\u540c\u65f6\u5141\u8bb8\u7075\u6d3b\u8bbe\u8ba1\u6838\u51fd\u6570\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u7684\u8ba1\u7b97\u673a\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u516c\u5f0f\u5728\u6027\u80fd\u6269\u5c55\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u6db5\u76d6\u4e86\u73b0\u6709\u7684\u56fe\u7ed3\u6784\u6570\u636e\u9ad8\u65af\u8fc7\u7a0b\u65b9\u6cd5\u4f5c\u4e3a\u7279\u6b8a\u60c5\u51b5\uff0c\u8fd8\u80fd\u591f\u79fb\u9664\u73b0\u6709\u65b9\u6cd5\u5bf9\u6570\u636e\u914d\u7f6e\u3001\u6a21\u578b\u9009\u62e9\u548c\u63a8\u7406\u573a\u666f\u7684\u9650\u5236\uff0c\u5c55\u73b0\u51fa\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2505.16860", "pdf": "https://arxiv.org/pdf/2505.16860", "abs": "https://arxiv.org/abs/2505.16860", "authors": ["Ziyue Qiao", "Qianyi Cai", "Hao Dong", "Jiawei Gu", "Pengyang Wang", "Meng Xiao", "Xiao Luo", "Hui Xiong"], "title": "GCAL: Adapting Graph Models to Evolving Domain Shifts", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to ICML 2025", "summary": "This paper addresses the challenge of graph domain adaptation on evolving,\nmultiple out-of-distribution (OOD) graphs. Conventional graph domain adaptation\nmethods are confined to single-step adaptation, making them ineffective in\nhandling continuous domain shifts and prone to catastrophic forgetting. This\npaper introduces the Graph Continual Adaptive Learning (GCAL) method, designed\nto enhance model sustainability and adaptability across various graph domains.\nGCAL employs a bilevel optimization strategy. The \"adapt\" phase uses an\ninformation maximization approach to fine-tune the model with new graph domains\nwhile re-adapting past memories to mitigate forgetting. Concurrently, the\n\"generate memory\" phase, guided by a theoretical lower bound derived from\ninformation bottleneck theory, involves a variational memory graph generation\nmodule to condense original graphs into memories. Extensive experimental\nevaluations demonstrate that GCAL substantially outperforms existing methods in\nterms of adaptability and knowledge retention.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5GCAL\uff0c\u901a\u8fc7\u53cc\u5c42\u4f18\u5316\u7b56\u7565\uff0c\u5728\u5904\u7406\u8fde\u7eed\u9886\u57df\u53d8\u5316\u548c\u907f\u514d\u707e\u96be\u6027\u9057\u5fd8\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u56fe\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u5c40\u9650\u4e8e\u5355\u6b65\u81ea\u9002\u5e94\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8fde\u7eed\u9886\u57df\u7684\u53d8\u5316\u5e76\u5bb9\u6613\u53d1\u751f\u707e\u96be\u6027\u9057\u5fd8\u3002", "method": "GCAL\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u7b56\u7565\uff0c\u5305\u62ec\u201c\u9002\u5e94\u201d\u9636\u6bb5\u548c\u201c\u751f\u6210\u8bb0\u5fc6\u201d\u9636\u6bb5\u3002\u201c\u9002\u5e94\u201d\u9636\u6bb5\u901a\u8fc7\u4fe1\u606f\u6700\u5927\u5316\u65b9\u6cd5\u5fae\u8c03\u6a21\u578b\u4ee5\u9002\u5e94\u65b0\u56fe\u57df\uff0c\u5e76\u91cd\u65b0\u8c03\u6574\u8fc7\u53bb\u7684\u8bb0\u5fc6\u4ee5\u51cf\u5c11\u9057\u5fd8\uff1b\u201c\u751f\u6210\u8bb0\u5fc6\u201d\u9636\u6bb5\u5229\u7528\u4fe1\u606f\u74f6\u9888\u7406\u8bba\u7684\u7406\u8bba\u4e0b\u754c\uff0c\u901a\u8fc7\u53d8\u5206\u8bb0\u5fc6\u56fe\u751f\u6210\u6a21\u5757\u5c06\u539f\u59cb\u56fe\u6d53\u7f29\u6210\u8bb0\u5fc6\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0cGCAL\u5728\u9002\u5e94\u6027\u548c\u77e5\u8bc6\u4fdd\u7559\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "GCAL\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u56fe\u57df\u4e0a\u7684\u53ef\u6301\u7eed\u6027\u548c\u9002\u5e94\u6027\uff0c\u4e3a\u5904\u7406\u8fde\u7eed\u9886\u57df\u53d8\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.16786", "pdf": "https://arxiv.org/pdf/2505.16786", "abs": "https://arxiv.org/abs/2505.16786", "authors": ["Fares B. Mehouachi", "Saif Eddin Jabari"], "title": "FlowMixer: A Constrained Neural Architecture for Interpretable Spatiotemporal Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "We introduce FlowMixer, a neural architecture that leverages constrained\nmatrix operations to model structured spatiotemporal patterns. At its core,\nFlowMixer incorporates non-negative matrix mixing layers within a reversible\nmapping framework-applying transforms before mixing and their inverses\nafterward. This shape-preserving design enables a Kronecker-Koopman eigenmode\nframework that bridges statistical learning with dynamical systems theory,\nproviding interpretable spatiotemporal patterns and facilitating direct\nalgebraic manipulation of prediction horizons without retraining. Extensive\nexperiments across diverse domains demonstrate FlowMixer's robust long-horizon\nforecasting capabilities while effectively modeling physical phenomena such as\nchaotic attractors and turbulent flows. These results suggest that\narchitectural constraints can simultaneously enhance predictive performance and\nmathematical interpretability in neural forecasting systems.", "AI": {"tldr": "FlowMixer\u662f\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u67b6\u6784\uff0c\u5229\u7528\u53d7\u7ea6\u675f\u7684\u77e9\u9635\u64cd\u4f5c\u6765\u5efa\u6a21\u7ed3\u6784\u5316\u7684\u65f6\u7a7a\u6a21\u5f0f\u3002\u5b83\u7ed3\u5408\u4e86\u975e\u8d1f\u77e9\u9635\u6df7\u5408\u5c42\u548c\u53ef\u9006\u6620\u5c04\u6846\u67b6\uff0c\u5728\u6df7\u5408\u524d\u540e\u5e94\u7528\u53d8\u6362\u53ca\u5176\u9006\u53d8\u6362\u3002\u8fd9\u79cd\u8bbe\u8ba1\u4fdd\u6301\u5f62\u72b6\u4e0d\u53d8\uff0c\u901a\u8fc7Kronecker-Koopman\u7279\u5f81\u6a21\u5f0f\u6846\u67b6\u8fde\u63a5\u7edf\u8ba1\u5b66\u4e60\u4e0e\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\uff0c\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u65f6\u7a7a\u6a21\u5f0f\uff0c\u5e76\u5141\u8bb8\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u76f4\u63a5\u4ee3\u6570\u64cd\u4f5c\u9884\u6d4b\u8303\u56f4\u3002\u5b9e\u9a8c\u8868\u660e\uff0cFlowMixer\u5177\u6709\u5f3a\u5927\u7684\u957f\u65f6\u9884\u6d4b\u80fd\u529b\uff0c\u540c\u65f6\u6709\u6548\u5efa\u6a21\u7269\u7406\u73b0\u8c61\u5982\u6df7\u6c8c\u5438\u5f15\u5b50\u548c\u6e4d\u6d41\u3002\u8fd9\u8bf4\u660e\u67b6\u6784\u7ea6\u675f\u53ef\u4ee5\u540c\u65f6\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u548c\u6570\u5b66\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5728\u5904\u7406\u590d\u6742\u65f6\u7a7a\u6a21\u5f0f\uff08\u4f8b\u5982\u6df7\u6c8c\u5438\u5f15\u5b50\u548c\u6e4d\u6d41\uff09\u65f6\u53ef\u80fd\u7f3a\u4e4f\u8db3\u591f\u7684\u9884\u6d4b\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u589e\u5f3a\u6a21\u578b\u5bf9\u8fd9\u4e9b\u73b0\u8c61\u7684\u7406\u89e3\u548c\u9884\u6d4b\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u6570\u5b66\u4e0a\u7684\u53ef\u89e3\u91ca\u6027\u3002", "method": "FlowMixer\u4f7f\u7528\u975e\u8d1f\u77e9\u9635\u6df7\u5408\u5c42\u548c\u53ef\u9006\u6620\u5c04\u6846\u67b6\uff0c\u5148\u8fdb\u884c\u53d8\u6362\u518d\u6df7\u5408\uff0c\u4e4b\u540e\u518d\u5e94\u7528\u5176\u9006\u53d8\u6362\u3002\u8fd9\u79cd\u65b9\u6cd5\u901a\u8fc7Kronecker-Koopman\u7279\u5f81\u6a21\u5f0f\u6846\u67b6\u5c06\u7edf\u8ba1\u5b66\u4e60\u4e0e\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\u76f8\u7ed3\u5408\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86FlowMixer\u5728\u4e0d\u540c\u9886\u57df\u4e2d\u7684\u5f3a\u5927\u957f\u65f6\u9884\u6d4b\u80fd\u529b\uff0c\u5c24\u5176\u5728\u5efa\u6a21\u7269\u7406\u73b0\u8c61\uff08\u5982\u6df7\u6c8c\u5438\u5f15\u5b50\u548c\u6e4d\u6d41\uff09\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u5f15\u5165\u7684FlowMixer\u67b6\u6784\u901a\u8fc7\u65bd\u52a0\u7279\u5b9a\u7ea6\u675f\u6761\u4ef6\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u9884\u6d4b\u6027\u80fd\uff0c\u8fd8\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u6570\u5b66\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u795e\u7ecf\u9884\u6d4b\u7cfb\u7edf\u7684\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2505.16896", "pdf": "https://arxiv.org/pdf/2505.16896", "abs": "https://arxiv.org/abs/2505.16896", "authors": ["Can Chen", "David Heurtel-Depeiges", "Robert M. Vernon", "Christopher James Langmead", "Yoshua Bengio", "Quentin Fournier"], "title": "Structure-Aligned Protein Language Model", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 8 figures, 7 tables", "summary": "Protein language models (pLMs) pre-trained on vast protein sequence databases\nexcel at various downstream tasks but lack the structural knowledge essential\nfor many biological applications. To address this, we integrate structural\ninsights from pre-trained protein graph neural networks (pGNNs) into pLMs\nthrough a latent-level contrastive learning task. This task aligns residue\nrepresentations from pLMs with those from pGNNs across multiple proteins,\nenriching pLMs with inter-protein structural knowledge. Additionally, we\nincorporate a physical-level task that infuses intra-protein structural\nknowledge by optimizing pLMs to predict structural tokens. The proposed\ndual-task framework effectively incorporates both inter-protein and\nintra-protein structural knowledge into pLMs. Given the variability in the\nquality of protein structures in PDB, we further introduce a residue loss\nselection module, which uses a small model trained on high-quality structures\nto select reliable yet challenging residue losses for the pLM to learn.\nApplying our structure alignment method to the state-of-the-art ESM2 and\nAMPLIFY results in notable performance gains across a wide range of tasks,\nincluding a 12.7% increase in ESM2 contact prediction. The data, code, and\nresulting SaESM2 and SaAMPLIFY models will be released on Hugging Face.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u9884\u8bad\u7ec3\u7684\u86cb\u767d\u8d28\u56fe\u795e\u7ecf\u7f51\u7edc(pGNNs)\u4e2d\u7684\u7ed3\u6784\u89c1\u89e3\u6574\u5408\u5230\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b(pLMs)\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u4efb\u52a1\u6846\u67b6\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u86cb\u767d\u8d28\u95f4\u7684\u7ed3\u6784\u77e5\u8bc6\u548c\u86cb\u767d\u8d28\u5185\u7684\u7ed3\u6784\u77e5\u8bc6\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u6b8b\u5dee\u635f\u5931\u9009\u62e9\u6a21\u5757\u4ee5\u63d0\u9ad8\u5b66\u4e60\u6548\u679c\u3002\u5e94\u7528\u6b64\u65b9\u6cd5\u6539\u8fdb\u4e86ESM2\u548cAMPLIFY\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u7f3a\u4e4f\u8bb8\u591a\u751f\u7269\u5b66\u5e94\u7528\u6240\u9700\u7684\u7ed3\u6784\u77e5\u8bc6\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u9700\u8981\u5c06\u7ed3\u6784\u77e5\u8bc6\u6574\u5408\u5230pLMs\u4e2d\u3002", "method": "1. \u4f7f\u7528\u6f5c\u5728\u7ea7\u522b\u7684\u5bf9\u6bd4\u5b66\u4e60\u4efb\u52a1\uff0c\u5c06pGNNs\u4e2d\u7684\u7ed3\u6784\u89c1\u89e3\u6574\u5408\u5230pLMs\u4e2d\u3002\n2. \u5f15\u5165\u7269\u7406\u7ea7\u522b\u4efb\u52a1\uff0c\u901a\u8fc7\u4f18\u5316pLMs\u9884\u6d4b\u7ed3\u6784\u6807\u8bb0\u6765\u6ce8\u5165\u86cb\u767d\u8d28\u5185\u7684\u7ed3\u6784\u77e5\u8bc6\u3002\n3. \u5f00\u53d1\u4e86\u4e00\u4e2a\u6b8b\u5dee\u635f\u5931\u9009\u62e9\u6a21\u5757\uff0c\u5229\u7528\u9ad8\u8d28\u91cf\u7ed3\u6784\u8bad\u7ec3\u7684\u5c0f\u578b\u6a21\u578b\u6765\u9009\u62e9\u53ef\u9760\u4e14\u5177\u6709\u6311\u6218\u6027\u7684\u6b8b\u5dee\u635f\u5931\u4f9bpLM\u5b66\u4e60\u3002\n4. \u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8eESM2\u548cAMPLIFY\u6a21\u578b\uff0c\u751f\u6210SaESM2\u548cSaAMPLIFY\u6a21\u578b\u3002", "result": "\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\uff0c\u5305\u62ecESM2\u63a5\u89e6\u9884\u6d4b\uff0c\u6027\u80fd\u63d0\u5347\u4e8612.7%\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7ed3\u6784\u77e5\u8bc6\u6574\u5408\u5230pLMs\u4e2d\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5176\u5728\u751f\u7269\u76f8\u5173\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002\u6240\u63d0\u51fa\u7684\u6846\u67b6\u548c\u6a21\u578b\u5c06\u5728Hugging Face\u4e0a\u53d1\u5e03\uff0c\u4f9b\u7814\u7a76\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2505.16932", "pdf": "https://arxiv.org/pdf/2505.16932", "abs": "https://arxiv.org/abs/2505.16932", "authors": ["Noah Amsel", "David Persson", "Christopher Musco", "Robert Gower"], "title": "The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.NA", "math.NA", "math.OC"], "comment": null, "summary": "Computing the polar decomposition and the related matrix sign function, has\nbeen a well-studied problem in numerical analysis for decades. More recently,\nit has emerged as an important subroutine in deep learning, particularly within\nthe Muon optimization framework. However, the requirements in this setting\ndiffer significantly from those of traditional numerical analysis. In deep\nlearning, methods must be highly efficient and GPU-compatible, but high\naccuracy is often unnecessary. As a result, classical algorithms like\nNewton-Schulz (which suffers from slow initial convergence) and methods based\non rational functions (which rely on QR decompositions or matrix inverses) are\npoorly suited to this context. In this work, we introduce Polar Express, a\nGPU-friendly algorithm for computing the polar decomposition. Like classical\npolynomial methods such as Newton-Schulz, our approach uses only matrix-matrix\nmultiplications, making it GPU-compatible. Motivated by earlier work of Chen &\nChow and Nakatsukasa & Freund, Polar Express adapts the polynomial update rule\nat each iteration by solving a minimax optimization problem, and we prove that\nit enjoys a strong worst-case optimality guarantee. This property ensures both\nrapid early convergence and fast asymptotic convergence. We also address\nfinite-precision issues, making it stable in bfloat16 in practice. We apply\nPolar Express within the Muon optimization framework and show consistent\nimprovements in validation loss on large-scale models such as GPT-2,\noutperforming recent alternatives across a range of learning rates.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPolar Express\u7684GPU\u53cb\u597d\u7684\u6781\u5206\u89e3\u8ba1\u7b97\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u4f18\u5316\u6846\u67b6\u3002\u8be5\u7b97\u6cd5\u901a\u8fc7\u89e3\u51b3\u6781\u5c0f\u5316\u4f18\u5316\u95ee\u9898\u6765\u8c03\u6574\u591a\u9879\u5f0f\u66f4\u65b0\u89c4\u5219\uff0c\u5e76\u5177\u6709\u5f3a\u6700\u5dee\u60c5\u51b5\u6700\u4f18\u6027\u4fdd\u8bc1\uff0c\u786e\u4fdd\u5feb\u901f\u6536\u655b\u548c\u6570\u503c\u7a33\u5b9a\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528Polar Express\u53ef\u4ee5\u6539\u5584\u5982GPT-2\u7b49\u5927\u89c4\u6a21\u6a21\u578b\u7684\u9a8c\u8bc1\u635f\u5931\u3002", "motivation": "\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\uff0c\u6781\u5206\u89e3\u8ba1\u7b97\u4f5c\u4e3aMuon\u4f18\u5316\u6846\u67b6\u4e2d\u7684\u91cd\u8981\u5b50\u7a0b\u5e8f\uff0c\u9700\u8981\u9ad8\u6548\u4e14\u4e0eGPU\u517c\u5bb9\u7684\u65b9\u6cd5\uff0c\u4f46\u4f20\u7edf\u6570\u503c\u5206\u6790\u65b9\u6cd5\uff08\u5982Newton-Schulz\u6216\u57fa\u4e8e\u6709\u7406\u51fd\u6570\u7684\u65b9\u6cd5\uff09\u65e0\u6cd5\u6ee1\u8db3\u8fd9\u4e9b\u9700\u6c42\uff0c\u56e0\u4e3a\u5b83\u4eec\u8981\u4e48\u521d\u59cb\u6536\u655b\u6162\uff0c\u8981\u4e48\u4f9d\u8d56\u4e8eQR\u5206\u89e3\u6216\u77e9\u9635\u6c42\u9006\u7b49\u64cd\u4f5c\u3002", "method": "Polar Express\u7b97\u6cd5\u4ec5\u4f7f\u7528\u77e9\u9635-\u77e9\u9635\u4e58\u6cd5\uff0c\u4f7f\u5176\u4e0eGPU\u517c\u5bb9\u3002\u5b83\u901a\u8fc7\u5728\u6bcf\u6b21\u8fed\u4ee3\u4e2d\u89e3\u51b3\u4e00\u4e2a\u6781\u5c0f\u5316\u4f18\u5316\u95ee\u9898\u6765\u8c03\u6574\u591a\u9879\u5f0f\u66f4\u65b0\u89c4\u5219\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5177\u6709\u5f3a\u6700\u5dee\u60c5\u51b5\u6700\u4f18\u6027\u4fdd\u8bc1\uff0c\u4ece\u800c\u786e\u4fdd\u5feb\u901f\u65e9\u671f\u6536\u655b\u548c\u6e10\u8fdb\u5feb\u901f\u6536\u655b\u3002\u6b64\u5916\uff0c\u8be5\u7b97\u6cd5\u8fd8\u89e3\u51b3\u4e86\u6709\u9650\u7cbe\u5ea6\u95ee\u9898\uff0c\u4f7f\u5176\u5728bfloat16\u4e2d\u4fdd\u6301\u7a33\u5b9a\u3002", "result": "\u5728Muon\u4f18\u5316\u6846\u67b6\u4e2d\u5e94\u7528Polar Express\u540e\uff0c\u5728\u5305\u62ecGPT-2\u5728\u5185\u7684\u5927\u89c4\u6a21\u6a21\u578b\u4e0a\uff0c\u9a8c\u8bc1\u635f\u5931\u5f97\u5230\u4e86\u4e00\u81f4\u7684\u6539\u8fdb\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u5b66\u4e60\u7387\u4e0b\u5747\u4f18\u4e8e\u8fd1\u671f\u7684\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "Polar Express\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u3001GPU\u53cb\u597d\u7684\u6781\u5206\u89e3\u8ba1\u7b97\u65b9\u6cd5\uff0c\u7279\u522b\u9002\u5408\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u4f18\u5316\u4efb\u52a1\u3002\u5b83\u4e0d\u4ec5\u5177\u5907\u7406\u8bba\u4e0a\u7684\u5f3a\u6536\u655b\u6027\u4fdd\u8bc1\uff0c\u800c\u4e14\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6570\u503c\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2505.16941", "pdf": "https://arxiv.org/pdf/2505.16941", "abs": "https://arxiv.org/abs/2505.16941", "authors": ["Chao Pang", "Vincent Jeanselme", "Young Sang Choi", "Xinzhuo Jiang", "Zilin Jing", "Aparajita Kashyap", "Yuta Kobayashi", "Yanwei Li", "Florent Pollet", "Karthik Natarajan", "Shalmali Joshi"], "title": "FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Foundation models hold significant promise in healthcare, given their\ncapacity to extract meaningful representations independent of downstream tasks.\nThis property has enabled state-of-the-art performance across several clinical\napplications trained on structured electronic health record (EHR) data, even in\nsettings with limited labeled data, a prevalent challenge in healthcare.\nHowever, there is little consensus on these models' potential for clinical\nutility due to the lack of desiderata of comprehensive and meaningful tasks and\nsufficiently diverse evaluations to characterize the benefit over conventional\nsupervised learning. To address this gap, we propose a suite of clinically\nmeaningful tasks spanning patient outcomes, early prediction of acute and\nchronic conditions, including desiderata for robust evaluations. We evaluate\nstate-of-the-art foundation models on EHR data consisting of 5 million patients\nfrom Columbia University Irving Medical Center (CUMC), a large urban academic\nmedical center in New York City, across 14 clinically relevant tasks. We\nmeasure overall accuracy, calibration, and subpopulation performance to surface\ntradeoffs based on the choice of pre-training, tokenization, and data\nrepresentation strategies. Our study aims to advance the empirical evaluation\nof structured EHR foundation models and guide the development of future\nhealthcare foundation models.", "AI": {"tldr": "\u57fa\u7840\u6a21\u578b\u5728\u533b\u7597\u4fdd\u5065\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u56e0\u5176\u80fd\u591f\u72ec\u7acb\u4e8e\u4e0b\u6e38\u4efb\u52a1\u63d0\u53d6\u6709\u610f\u4e49\u7684\u8868\u793a\u3002\u5c3d\u7ba1\u8fd9\u4e9b\u6a21\u578b\u5728\u7ed3\u6784\u5316\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u4e34\u5e8a\u5b9e\u7528\u6027\u5c1a\u7f3a\u4e4f\u5171\u8bc6\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u4e34\u5e8a\u610f\u4e49\u7684\u4efb\u52a1\uff0c\u5e76\u5bf9\u6700\u5148\u8fdb\u7684\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u4ee5\u6307\u5bfc\u672a\u6765\u533b\u7597\u4fdd\u5065\u57fa\u7840\u6a21\u578b\u7684\u53d1\u5c55\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7684\u6f5c\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u6316\u6398\uff0c\u7279\u522b\u662f\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u7684\u5b9e\u9645\u6548\u7528\u5c1a\u672a\u8fbe\u6210\u5171\u8bc6\u3002\u56e0\u6b64\uff0c\u9700\u8981\u660e\u786e\u7684\u4efb\u52a1\u548c\u591a\u6837\u5316\u7684\u8bc4\u4f30\u6765\u5c55\u793a\u8fd9\u4e9b\u6a21\u578b\u76f8\u8f83\u4e8e\u4f20\u7edf\u76d1\u7763\u5b66\u4e60\u7684\u4f18\u52bf\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u5957\u5177\u6709\u4e34\u5e8a\u610f\u4e49\u7684\u4efb\u52a1\uff0c\u6db5\u76d6\u4e86\u60a3\u8005\u7ed3\u679c\u3001\u6025\u6027\u4e0e\u6162\u6027\u75be\u75c5\u7684\u65e9\u671f\u9884\u6d4b\u7b49\u591a\u4e2a\u65b9\u9762\uff0c\u5e76\u63d0\u51fa\u4e86\u7a33\u5065\u7684\u8bc4\u4f30\u6807\u51c6\u3002\u4f7f\u7528\u6765\u81ea\u54e5\u4f26\u6bd4\u4e9a\u5927\u5b66\u6b27\u6587\u533b\u5b66\u4e2d\u5fc3\uff08CUMC\uff09\u5305\u542b5\u767e\u4e07\u60a3\u8005\u7684EHR\u6570\u636e\uff0c\u572814\u4e2a\u4e34\u5e8a\u76f8\u5173\u4efb\u52a1\u4e0a\u8bc4\u4f30\u4e86\u6700\u5148\u8fdb\u7684\u57fa\u7840\u6a21\u578b\u3002\u901a\u8fc7\u6d4b\u91cf\u6574\u4f53\u51c6\u786e\u6027\u3001\u6821\u51c6\u5ea6\u4ee5\u53ca\u5b50\u7fa4\u4f53\u6027\u80fd\uff0c\u5206\u6790\u4e86\u9884\u8bad\u7ec3\u3001\u6807\u8bb0\u5316\u548c\u6570\u636e\u8868\u793a\u7b56\u7565\u7684\u9009\u62e9\u5bf9\u6a21\u578b\u8868\u73b0\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u7840\u6a21\u578b\u5728\u591a\u4e2a\u4e34\u5e8a\u76f8\u5173\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u51c6\u786e\u6027\u548c\u6821\u51c6\u5ea6\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u4e0d\u540c\u9884\u8bad\u7ec3\u3001\u6807\u8bb0\u5316\u548c\u6570\u636e\u8868\u793a\u7b56\u7565\u4e4b\u95f4\u7684\u6743\u8861\u3002\u8fd9\u4e3a\u672a\u6765\u533b\u7597\u4fdd\u5065\u57fa\u7840\u6a21\u578b\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u6307\u5bfc\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u4e00\u7cfb\u5217\u4e34\u5e8a\u4efb\u52a1\u7684\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u57fa\u7840\u6a21\u578b\u5728\u7ed3\u6784\u5316EHR\u6570\u636e\u4e0a\u7684\u4f18\u52bf\uff0c\u5e76\u5f3a\u8c03\u4e86\u7a33\u5065\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002\u8fd9\u5c06\u6709\u52a9\u4e8e\u63a8\u52a8\u672a\u6765\u533b\u7597\u4fdd\u5065\u9886\u57df\u57fa\u7840\u6a21\u578b\u7684\u5f00\u53d1\u548c\u6539\u8fdb\u3002"}}
{"id": "2505.16947", "pdf": "https://arxiv.org/pdf/2505.16947", "abs": "https://arxiv.org/abs/2505.16947", "authors": ["Csaba D\u00e9k\u00e1ny", "Stefan Balauca", "Robin Staab", "Dimitar I. Dimitrov", "Martin Vechev"], "title": "MixAT: Combining Continuous and Discrete Adversarial Training for LLMs", "categories": ["cs.LG", "cs.AI", "I.2.7; K.4.1"], "comment": null, "summary": "Despite recent efforts in Large Language Models (LLMs) safety and alignment,\ncurrent adversarial attacks on frontier LLMs are still able to force harmful\ngenerations consistently. Although adversarial training has been widely studied\nand shown to significantly improve the robustness of traditional machine\nlearning models, its strengths and weaknesses in the context of LLMs are less\nunderstood. Specifically, while existing discrete adversarial attacks are\neffective at producing harmful content, training LLMs with concrete adversarial\nprompts is often computationally expensive, leading to reliance on continuous\nrelaxations. As these relaxations do not correspond to discrete input tokens,\nsuch latent training methods often leave models vulnerable to a diverse set of\ndiscrete attacks. In this work, we aim to bridge this gap by introducing MixAT,\na novel method that combines stronger discrete and faster continuous attacks\nduring training. We rigorously evaluate MixAT across a wide spectrum of\nstate-of-the-art attacks, proposing the At Least One Attack Success Rate\n(ALO-ASR) metric to capture the worst-case vulnerability of models. We show\nMixAT achieves substantially better robustness (ALO-ASR < 20%) compared to\nprior defenses (ALO-ASR > 50%), while maintaining a runtime comparable to\nmethods based on continuous relaxations. We further analyze MixAT in realistic\ndeployment settings, exploring how chat templates, quantization, low-rank\nadapters, and temperature affect both adversarial training and evaluation,\nrevealing additional blind spots in current methodologies. Our results\ndemonstrate that MixAT's discrete-continuous defense offers a principled and\nsuperior robustness-accuracy tradeoff with minimal computational overhead,\nhighlighting its promise for building safer LLMs. We provide our code and\nmodels at https://github.com/insait-institute/MixAT.", "AI": {"tldr": "\u5c3d\u7ba1\u5728\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5b89\u5168\u6027\u548c\u5bf9\u9f50\u65b9\u9762\u6709\u6700\u8fd1\u7684\u52aa\u529b\uff0c\u5f53\u524d\u7684\u5bf9\u6297\u653b\u51fb\u4ecd\u80fd\u6301\u7eed\u751f\u6210\u6709\u5bb3\u5185\u5bb9\u3002\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aMixAT\u7684\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u79bb\u6563\u548c\u8fde\u7eed\u7684\u5bf9\u6297\u8bad\u7ec3\uff0c\u4ee5\u63d0\u9ad8LLM\u7684\u9c81\u68d2\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMixAT\u5728\u4fdd\u6301\u4e0e\u8fde\u7eed\u65b9\u6cd5\u76f8\u4f3c\u8fd0\u884c\u65f6\u95f4\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u76f2\u70b9\u3002", "motivation": "\u5c3d\u7ba1\u5bf9\u6297\u8bad\u7ec3\u5728\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4e2d\u88ab\u5e7f\u6cdb\u7814\u7a76\u5e76\u663e\u793a\u51fa\u663e\u8457\u63d0\u9ad8\u9c81\u68d2\u6027\u7684\u6548\u679c\uff0c\u4f46\u5728LLMs\u4e2d\u7684\u5e94\u7528\u5b58\u5728\u6311\u6218\uff1a\u79bb\u6563\u5bf9\u6297\u8bad\u7ec3\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u800c\u8fde\u7eed\u677e\u5f1b\u65b9\u6cd5\u867d\u7136\u66f4\u5feb\uff0c\u4f46\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u5bf9\u79bb\u6563\u653b\u51fb\u4ecd\u7136\u8106\u5f31\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8LLMs\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMixAT\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u66f4\u5f3a\u7684\u79bb\u6563\u653b\u51fb\u548c\u66f4\u5feb\u7684\u8fde\u7eed\u653b\u51fb\u7ed3\u5408\u5230\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u3002\u540c\u65f6\uff0c\u5f15\u5165\u4e86At Least One Attack Success Rate (ALO-ASR) \u6307\u6807\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u8106\u5f31\u6027\u3002\u6b64\u5916\uff0c\u5206\u6790\u4e86\u5728\u5b9e\u9645\u90e8\u7f72\u573a\u666f\u4e2d\uff0c\u5982\u804a\u5929\u6a21\u677f\u3001\u91cf\u5316\u3001\u4f4e\u79e9\u9002\u914d\u5668\u548c\u6e29\u5ea6\u7b49\u56e0\u7d20\u5982\u4f55\u5f71\u54cd\u5bf9\u6297\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "MixAT\u5728\u5e7f\u6cdb\u7684\u6700\u65b0\u653b\u51fb\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u66f4\u597d\u7684\u9c81\u68d2\u6027\uff08ALO-ASR < 20%\uff09\uff0c\u76f8\u8f83\u4e8e\u5148\u524d\u7684\u9632\u5fa1\u65b9\u6cd5\uff08ALO-ASR > 50%\uff09\u3002\u540c\u65f6\uff0c\u5176\u8fd0\u884c\u65f6\u95f4\u4e0e\u57fa\u4e8e\u8fde\u7eed\u677e\u5f1b\u7684\u65b9\u6cd5\u76f8\u5f53\u3002\u6b64\u5916\uff0cMixAT\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u4e2d\u7684\u989d\u5916\u76f2\u70b9\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u6700\u5c0f\u8ba1\u7b97\u5f00\u9500\u4e0b\u63d0\u4f9b\u66f4\u4f18\u7684\u9c81\u68d2\u6027-\u51c6\u786e\u6027\u6743\u8861\u3002", "conclusion": "MixAT\u901a\u8fc7\u7ed3\u5408\u79bb\u6563\u548c\u8fde\u7eed\u7684\u5bf9\u6297\u8bad\u7ec3\uff0c\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u548c\u4f18\u8d8a\u7684\u9c81\u68d2\u6027-\u51c6\u786e\u6027\u6743\u8861\uff0c\u5177\u6709\u6784\u5efa\u66f4\u5b89\u5168\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u529b\u3002\u4ee3\u7801\u548c\u6a21\u578b\u5df2\u516c\u5f00\u53d1\u5e03\u3002"}}
{"id": "2505.16829", "pdf": "https://arxiv.org/pdf/2505.16829", "abs": "https://arxiv.org/abs/2505.16829", "authors": ["Anna Heuser", "Thomas Kesselheim"], "title": "Contextual Learning for Stochastic Optimization", "categories": ["cs.LG", "cs.DS", "cs.GT"], "comment": "Full version of EC'25 paper", "summary": "Motivated by stochastic optimization, we introduce the problem of learning\nfrom samples of contextual value distributions. A contextual value distribution\ncan be understood as a family of real-valued distributions, where each sample\nconsists of a context $x$ and a random variable drawn from the corresponding\nreal-valued distribution $D_x$. By minimizing a convex surrogate loss, we learn\nan empirical distribution $D'_x$ for each context, ensuring a small L\\'evy\ndistance to $D_x$. We apply this result to obtain the sample complexity bounds\nfor the learning of an $\\epsilon$-optimal policy for stochastic optimization\nproblems defined on an unknown contextual value distribution. The sample\ncomplexity is shown to be polynomial for the general case of strongly monotone\nand stable optimization problems, including Single-item Revenue Maximization,\nPandora's Box and Optimal Stopping.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.16950", "pdf": "https://arxiv.org/pdf/2505.16950", "abs": "https://arxiv.org/abs/2505.16950", "authors": ["Adnan Oomerjee", "Zafeirios Fountas", "Zhongwei Yu", "Haitham Bou-Ammar", "Jun Wang"], "title": "Bottlenecked Transformers: Periodic KV Cache Abstraction for Generalised Reasoning", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "comment": null, "summary": "Despite their impressive capabilities, Large Language Models struggle with\ngeneralisation beyond their training distribution, often exhibiting\nsophisticated pattern interpolation rather than true abstract reasoning\n(extrapolation). In this work, we approach this limitation through the lens of\nInformation Bottleneck (IB) theory, which posits that model generalisation\nemerges from an optimal balance between input compression and retention of\npredictive information in latent representations. We prove using IB theory that\ndecoder-only Transformers are inherently constrained in their ability to form\ntask-optimal sequence representations. We then use this result to demonstrate\nthat periodic global transformation of the internal sequence-level\nrepresentations (KV cache) is a necessary computational step for improving\nTransformer generalisation in reasoning tasks. Based on these theoretical\ninsights, we propose a modification to the Transformer architecture, in the\nform of an additional module that globally rewrites the KV cache at periodic\nintervals, shifting its capacity away from memorising input prefixes and toward\nencoding features most useful for predicting future tokens. Our model delivers\nsubstantial gains on mathematical reasoning benchmarks, outperforming both\nvanilla Transformers with up to 3.5x more parameters, as well as\nheuristic-driven pruning mechanisms for cache compression. Our approach can be\nseen as a principled generalisation of existing KV-cache compression methods;\nwhereas such methods focus solely on compressing input representations, they\noften do so at the expense of retaining predictive information, and thus their\ncapabilities are inherently bounded by those of an unconstrained model. This\nestablishes a principled framework to manipulate Transformer memory using\ninformation theory, addressing fundamental reasoning limitations that scaling\nalone cannot overcome.", "AI": {"tldr": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u80fd\u529b\u60ca\u4eba\uff0c\u4f46\u5b83\u4eec\u5728\u8bad\u7ec3\u5206\u5e03\u4e4b\u5916\u7684\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u5f80\u5f80\u8868\u73b0\u51fa\u590d\u6742\u7684\u6a21\u5f0f\u63d2\u503c\u800c\u975e\u771f\u6b63\u7684\u62bd\u8c61\u63a8\u7406\u3002\u672c\u6587\u901a\u8fc7\u4fe1\u606f\u74f6\u9888\uff08IB\uff09\u7406\u8bba\u5206\u6790\u4e86\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u8bc1\u660e\u4e86\u4ec5\u89e3\u7801\u5668\u7684Transformer\u5728\u5f62\u6210\u4efb\u52a1\u6700\u4f18\u5e8f\u5217\u8868\u793a\u65b9\u9762\u5b58\u5728\u56fa\u6709\u7ea6\u675f\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u5bf9\u5185\u90e8\u5e8f\u5217\u7ea7\u8868\u793a\uff08KV\u7f13\u5b58\uff09\u8fdb\u884c\u5468\u671f\u6027\u5168\u5c40\u53d8\u6362\u6765\u6539\u8fdbTransformer\u7684\u63a8\u7406\u6cdb\u5316\u80fd\u529b\u3002\u57fa\u4e8e\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u5bf9Transformer\u67b6\u6784\u7684\u4fee\u6539\uff0c\u589e\u52a0\u4e00\u4e2a\u6a21\u5757\u5468\u671f\u6027\u91cd\u5199KV\u7f13\u5b58\uff0c\u4f7f\u5176\u5bb9\u91cf\u4ece\u8bb0\u5fc6\u8f93\u5165\u524d\u7f00\u8f6c\u5411\u7f16\u7801\u5bf9\u672a\u6765\u6807\u8bb0\u9884\u6d4b\u6700\u6709\u7528\u7684\u7279\u5f81\u3002\u8be5\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\uff0c\u4f18\u4e8e\u5177\u6709\u591a\u8fbe3.5\u500d\u53c2\u6570\u7684\u666e\u901aTransformer\u4ee5\u53ca\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u7f13\u5b58\u538b\u7f29\u673a\u5236\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u53ef\u4ee5\u88ab\u89c6\u4e3a\u73b0\u6709KV\u7f13\u5b58\u538b\u7f29\u65b9\u6cd5\u7684\u539f\u5219\u6027\u63a8\u5e7f\uff0c\u89e3\u51b3\u4e86\u5355\u7eaf\u6269\u5c55\u65e0\u6cd5\u514b\u670d\u7684\u57fa\u672c\u63a8\u7406\u9650\u5236\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u5728\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u4e4b\u5916\u7684\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u5f80\u5f80\u4f9d\u8d56\u4e8e\u590d\u6742\u6a21\u5f0f\u7684\u63d2\u503c\u800c\u4e0d\u662f\u771f\u6b63\u7684\u62bd\u8c61\u63a8\u7406\u3002\u8fd9\u4fc3\u4f7f\u4f5c\u8005\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u7406\u8bba\u6307\u5bfc\u6539\u8fdbTransformer\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "1. \u4f7f\u7528\u4fe1\u606f\u74f6\u9888\uff08IB\uff09\u7406\u8bba\u5206\u6790Transformer\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\n2. \u8bc1\u660e\u4ec5\u89e3\u7801\u5668\u7684Transformer\u5728\u5f62\u6210\u4efb\u52a1\u6700\u4f18\u5e8f\u5217\u8868\u793a\u65b9\u9762\u5b58\u5728\u56fa\u6709\u7ea6\u675f\u3002\n3. \u63d0\u51fa\u901a\u8fc7\u5bf9\u5185\u90e8\u5e8f\u5217\u7ea7\u8868\u793a\uff08KV\u7f13\u5b58\uff09\u8fdb\u884c\u5468\u671f\u6027\u5168\u5c40\u53d8\u6362\u6765\u6539\u8fdb\u6cdb\u5316\u80fd\u529b\u3002\n4. \u5728Transformer\u67b6\u6784\u4e2d\u589e\u52a0\u4e00\u4e2a\u6a21\u5757\uff0c\u5468\u671f\u6027\u5730\u91cd\u5199KV\u7f13\u5b58\uff0c\u51cf\u5c11\u5bf9\u8f93\u5165\u524d\u7f00\u7684\u8bb0\u5fc6\uff0c\u589e\u5f3a\u5bf9\u672a\u6765\u6807\u8bb0\u9884\u6d4b\u7684\u80fd\u529b\u3002", "result": "\u63d0\u51fa\u7684\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u4f18\u4e8e\u5177\u6709\u66f4\u591a\u53c2\u6570\u7684\u666e\u901aTransformer\u548c\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u7f13\u5b58\u538b\u7f29\u673a\u5236\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u7406\u8bba\u539f\u5219\u6027\u64cd\u7eb5Transformer\u5185\u5b58\u7684\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u5355\u7eaf\u6269\u5c55\u65e0\u6cd5\u514b\u670d\u7684\u57fa\u672c\u63a8\u7406\u9650\u5236\uff0c\u4e3a\u6539\u8fdbTransformer\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2505.16833", "pdf": "https://arxiv.org/pdf/2505.16833", "abs": "https://arxiv.org/abs/2505.16833", "authors": ["Alihan H\u00fcy\u00fck", "Finale Doshi-Velez"], "title": "Strategically Linked Decisions in Long-Term Planning and Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Long-term planning, as in reinforcement learning (RL), involves finding\nstrategies: actions that collectively work toward a goal rather than\nindividually optimizing their immediate outcomes. As part of a strategy, some\nactions are taken at the expense of short-term benefit to enable future actions\nwith even greater returns. These actions are only advantageous if followed up\nby the actions they facilitate, consequently, they would not have been taken if\nthose follow-ups were not available. In this paper, we quantify such\ndependencies between planned actions with strategic link scores: the drop in\nthe likelihood of one decision under the constraint that a follow-up decision\nis no longer available. We demonstrate the utility of strategic link scores\nthrough three practical applications: (i) explaining black-box RL agents by\nidentifying strategically linked pairs among decisions they make, (ii)\nimproving the worst-case performance of decision support systems by\ndistinguishing whether recommended actions can be adopted as standalone\nimprovements or whether they are strategically linked hence requiring a\ncommitment to a broader strategy to be effective, and (iii) characterizing the\nplanning processes of non-RL agents purely through interventions aimed at\nmeasuring strategic link scores - as an example, we consider a realistic\ntraffic simulator and analyze through road closures the effective planning\nhorizon of the emergent routing behavior of many drivers.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u2014\u2014\u6218\u7565\u94fe\u63a5\u5206\u6570\uff0c\u7528\u4e8e\u91cf\u5316\u5f3a\u5316\u5b66\u4e60\u4e2d\u8ba1\u5212\u884c\u52a8\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u901a\u8fc7\u4e09\u4e2a\u5b9e\u9645\u5e94\u7528\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6548\u7528\uff1a\u89e3\u91ca\u9ed1\u7bb1RL\u4ee3\u7406\u3001\u6539\u5584\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u548c\u5206\u6790\u975eRL\u4ee3\u7406\u7684\u89c4\u5212\u8fc7\u7a0b\u3002", "motivation": "\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u957f\u671f\u89c4\u5212\u6d89\u53ca\u627e\u5230\u7b56\u7565\uff1a\u96c6\u4f53\u671d\u7740\u76ee\u6807\u5de5\u4f5c\u7684\u884c\u52a8\uff0c\u800c\u4e0d\u662f\u5355\u72ec\u4f18\u5316\u5176\u5373\u65f6\u7ed3\u679c\u3002\u4f5c\u4e3a\u7b56\u7565\u7684\u4e00\u90e8\u5206\uff0c\u67d0\u4e9b\u884c\u52a8\u662f\u4ee5\u77ed\u671f\u5229\u76ca\u4e3a\u4ee3\u4ef7\u91c7\u53d6\u7684\uff0c\u4ee5\u4f7f\u672a\u6765\u7684\u884c\u52a8\u83b7\u5f97\u66f4\u5927\u7684\u56de\u62a5\u3002\u8fd9\u4e9b\u884c\u52a8\u53ea\u6709\u5728\u5176\u4fc3\u6210\u7684\u540e\u7eed\u884c\u52a8\u5f97\u4ee5\u5b9e\u65bd\u65f6\u624d\u5177\u6709\u4f18\u52bf\uff0c\u56e0\u6b64\u5982\u679c\u8fd9\u4e9b\u540e\u7eed\u884c\u52a8\u4e0d\u53ef\u7528\uff0c\u5b83\u4eec\u5c31\u4e0d\u4f1a\u88ab\u6267\u884c\u3002", "method": "\u6211\u4eec\u901a\u8fc7\u6218\u7565\u94fe\u63a5\u5206\u6570\u91cf\u5316\u4e86\u8ba1\u5212\u884c\u52a8\u4e4b\u95f4\u7684\u8fd9\u79cd\u4f9d\u8d56\u5173\u7cfb\uff1a\u5728\u540e\u7eed\u51b3\u7b56\u4e0d\u518d\u53ef\u7528\u7684\u7ea6\u675f\u4e0b\uff0c\u4e00\u4e2a\u51b3\u7b56\u7684\u53ef\u80fd\u6027\u4e0b\u964d\u4e86\u591a\u5c11\u3002", "result": "\u6211\u4eec\u901a\u8fc7\u4e09\u4e2a\u5b9e\u9645\u5e94\u7528\u5c55\u793a\u4e86\u6218\u7565\u94fe\u63a5\u5206\u6570\u7684\u5b9e\u7528\u6027\uff1a(i) \u901a\u8fc7\u8bc6\u522b\u4ed6\u4eec\u6240\u505a\u51b3\u7b56\u4e2d\u6218\u7565\u6027\u94fe\u63a5\u7684\u5bf9\u6765\u89e3\u91ca\u9ed1\u7bb1RL\u4ee3\u7406\uff1b(ii) \u901a\u8fc7\u533a\u5206\u63a8\u8350\u52a8\u4f5c\u662f\u5426\u53ef\u4ee5\u4f5c\u4e3a\u72ec\u7acb\u6539\u8fdb\u91c7\u7528\uff0c\u8fd8\u662f\u9700\u8981\u627f\u8bfa\u66f4\u5e7f\u6cdb\u7684\u6218\u7565\u624d\u80fd\u6709\u6548\uff0c\u4ece\u800c\u6539\u5584\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7684\u6700\u5dee\u8868\u73b0\uff1b(iii) \u4ec5\u901a\u8fc7\u65e8\u5728\u8861\u91cf\u6218\u7565\u94fe\u63a5\u5206\u6570\u7684\u5e72\u9884\u63aa\u65bd\u6765\u63cf\u8ff0\u975eRL\u4ee3\u7406\u7684\u89c4\u5212\u8fc7\u7a0b - \u4f8b\u5982\uff0c\u6211\u4eec\u5728\u73b0\u5b9e\u7684\u4ea4\u901a\u6a21\u62df\u5668\u4e2d\u8003\u8651\uff0c\u5e76\u901a\u8fc7\u9053\u8def\u5c01\u95ed\u5206\u6790\u8bb8\u591a\u9a7e\u9a76\u5458\u51fa\u73b0\u7684\u8def\u7531\u884c\u4e3a\u7684\u6709\u6548\u89c4\u5212\u8303\u56f4\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u6218\u7565\u94fe\u63a5\u5206\u6570\u7684\u6982\u5ff5\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u591a\u4e2a\u9886\u57df\u4e2d\u7684\u6f5c\u5728\u7528\u9014\uff0c\u5305\u62ec\u89e3\u91caRL\u4ee3\u7406\u3001\u6539\u8fdb\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u548c\u5206\u6790\u975eRL\u4ee3\u7406\u7684\u89c4\u5212\u8fc7\u7a0b\u3002"}}
{"id": "2505.16850", "pdf": "https://arxiv.org/pdf/2505.16850", "abs": "https://arxiv.org/abs/2505.16850", "authors": ["Tajamul Ashraf", "Mohammed Mohsen Peerzada", "Moloud Abdar", "Yutong Xie", "Yuyin Zhou", "Xiaofeng Liu", "Iqra Altaf Gillani", "Janibul Bashir"], "title": "ATR-Bench: A Federated Learning Benchmark for Adaptation, Trust, and Reasoning", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Federated Learning Benchmark for Domain Adaptation, Trustworthiness,\n  and Reasoning", "summary": "Federated Learning (FL) has emerged as a promising paradigm for collaborative\nmodel training while preserving data privacy across decentralized participants.\nAs FL adoption grows, numerous techniques have been proposed to tackle its\npractical challenges. However, the lack of standardized evaluation across key\ndimensions hampers systematic progress and fair comparison of FL methods. In\nthis work, we introduce ATR-Bench, a unified framework for analyzing federated\nlearning through three foundational dimensions: Adaptation, Trust, and\nReasoning. We provide an in-depth examination of the conceptual foundations,\ntask formulations, and open research challenges associated with each theme. We\nhave extensively benchmarked representative methods and datasets for adaptation\nto heterogeneous clients and trustworthiness in adversarial or unreliable\nenvironments. Due to the lack of reliable metrics and models for reasoning in\nFL, we only provide literature-driven insights for this dimension. ATR-Bench\nlays the groundwork for a systematic and holistic evaluation of federated\nlearning with real-world relevance. We will make our complete codebase publicly\naccessible and a curated repository that continuously tracks new developments\nand research in the FL literature.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86ATR-Bench\uff0c\u4e00\u4e2a\u7528\u4e8e\u5206\u6790\u8054\u90a6\u5b66\u4e60\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u6db5\u76d6\u9002\u5e94\u6027\u3001\u4fe1\u4efb\u548c\u63a8\u7406\u4e09\u4e2a\u57fa\u7840\u7ef4\u5ea6\uff0c\u5e76\u63d0\u4f9b\u4e86\u4ee3\u8868\u6027\u7684\u65b9\u6cd5\u548c\u6570\u636e\u96c6\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u5c3d\u7ba1\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u9886\u57df\u6709\u8bb8\u591a\u6280\u672f\u88ab\u63d0\u51fa\u4ee5\u89e3\u51b3\u5b9e\u9645\u6311\u6218\uff0c\u4f46\u7f3a\u4e4f\u6807\u51c6\u5316\u8bc4\u4f30\u963b\u788d\u4e86\u7cfb\u7edf\u6027\u8fdb\u5c55\u548c\u516c\u5e73\u6bd4\u8f83\u3002", "method": "\u5f15\u5165ATR-Bench\u6846\u67b6\uff0c\u901a\u8fc7\u9002\u5e94\u6027\u3001\u4fe1\u4efb\u548c\u63a8\u7406\u4e09\u4e2a\u7ef4\u5ea6\u5206\u6790\u8054\u90a6\u5b66\u4e60\uff0c\u63d0\u4f9b\u6982\u5ff5\u57fa\u7840\u3001\u4efb\u52a1\u516c\u5f0f\u5316\u548c\u5f00\u653e\u7814\u7a76\u6311\u6218\u7684\u6df1\u5165\u8003\u5bdf\uff0c\u5e76\u5bf9\u9002\u5e94\u6027\u548c\u4fe1\u4efb\u7ef4\u5ea6\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u4e3a\u8054\u90a6\u5b66\u4e60\u7684\u7cfb\u7edf\u6027\u548c\u6574\u4f53\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u7279\u522b\u662f\u9488\u5bf9\u73b0\u5b9e\u4e16\u754c\u7684\u76f8\u5173\u6027\uff0c\u5e76\u5c06\u516c\u5f00\u4ee3\u7801\u5e93\u548c\u6301\u7eed\u8ddf\u8e2a\u65b0\u53d1\u5c55\u7684\u6587\u732e\u5b58\u50a8\u5e93\u3002", "conclusion": "ATR-Bench\u6709\u52a9\u4e8e\u63a8\u52a8\u8054\u90a6\u5b66\u4e60\u9886\u57df\u5411\u66f4\u7cfb\u7edf\u5316\u548c\u5168\u9762\u7684\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2505.17016", "pdf": "https://arxiv.org/pdf/2505.17016", "abs": "https://arxiv.org/abs/2505.17016", "authors": ["Shuhan Tan", "Kairan Dou", "Yue Zhao", "Philipp Kr\u00e4henb\u00fchl"], "title": "Interactive Post-Training for Vision-Language-Action Models", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "comment": "Project page: https://ariostgx.github.io/ript_vla/", "summary": "We introduce RIPT-VLA, a simple and scalable reinforcement-learning-based\ninteractive post-training paradigm that fine-tunes pretrained\nVision-Language-Action (VLA) models using only sparse binary success rewards.\nExisting VLA training pipelines rely heavily on offline expert demonstration\ndata and supervised imitation, limiting their ability to adapt to new tasks and\nenvironments under low-data regimes. RIPT-VLA addresses this by enabling\ninteractive post-training with a stable policy optimization algorithm based on\ndynamic rollout sampling and leave-one-out advantage estimation.\n  RIPT-VLA has the following characteristics. First, it applies to various VLA\nmodels, resulting in an improvement on the lightweight QueST model by 21.2%,\nand the 7B OpenVLA-OFT model to an unprecedented 97.5% success rate. Second, it\nis computationally efficient and data-efficient: with only one demonstration,\nRIPT-VLA enables an unworkable SFT model (4%) to succeed with a 97% success\nrate within 15 iterations. Furthermore, we demonstrate that the policy learned\nby RIPT-VLA generalizes across different tasks and scenarios and is robust to\nthe initial state context. These results highlight RIPT-VLA as a practical and\neffective paradigm for post-training VLA models through minimal supervision.", "AI": {"tldr": "\u6211\u4eec\u63d0\u51fa\u4e86RIPT-VLA\uff0c\u4e00\u79cd\u7b80\u5355\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4ea4\u4e92\u5f0f\u540e\u8bad\u7ec3\u8303\u5f0f\uff0c\u4ec5\u4f7f\u7528\u7a00\u758f\u7684\u4e8c\u5143\u6210\u529f\u5956\u52b1\u5fae\u8c03\u9884\u8bad\u7ec3\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\uff08VLA\uff09\u6a21\u578b\u3002RIPT-VLA\u901a\u8fc7\u52a8\u6001 rollout \u91c7\u6837\u548c\u7559\u4e00\u6cd5\u4f18\u52bf\u4f30\u8ba1\u7684\u7a33\u5b9a\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u5b9e\u73b0\u4ea4\u4e92\u5f0f\u540e\u8bad\u7ec3\u3002\u5b9e\u9a8c\u8868\u660e\uff0cRIPT-VLA\u4e0d\u4ec5\u663e\u8457\u63d0\u5347\u4e86\u4e0d\u540cVLA\u6a21\u578b\u7684\u8868\u73b0\uff08\u5982QueST\u6a21\u578b\u63d0\u9ad821.2%\uff0cOpenVLA-OFT\u6a21\u578b\u8fbe\u523097.5%\u7684\u6210\u529f\u7387\uff09\uff0c\u8fd8\u5177\u6709\u8ba1\u7b97\u9ad8\u6548\u3001\u6570\u636e\u9ad8\u6548\u7684\u7279\u70b9\uff0c\u5e76\u4e14\u5b66\u5230\u7684\u7b56\u7565\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u573a\u666f\u4e2d\u5177\u6709\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684VLA\u8bad\u7ec3\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u7684\u79bb\u7ebf\u4e13\u5bb6\u6f14\u793a\u6570\u636e\u548c\u76d1\u7763\u6a21\u4eff\u5b66\u4e60\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u4f4e\u6570\u636e\u91cf\u6761\u4ef6\u4e0b\u9002\u5e94\u65b0\u4efb\u52a1\u548c\u73af\u5883\u7684\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u5bf9\u5927\u91cf\u6570\u636e\u7684\u4f9d\u8d56\u5e76\u63d0\u5347\u6a21\u578b\u7684\u9002\u5e94\u80fd\u529b\u3002", "method": "RIPT-VLA\u662f\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4ea4\u4e92\u5f0f\u540e\u8bad\u7ec3\u8303\u5f0f\uff0c\u5b83\u91c7\u7528\u52a8\u6001rollout\u91c7\u6837\u548c\u7559\u4e00\u6cd5\u4f18\u52bf\u4f30\u8ba1\u7684\u7a33\u5b9a\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u8fdb\u884c\u5fae\u8c03\u3002\u8fd9\u79cd\u65b9\u6cd5\u53ea\u9700\u8981\u7a00\u758f\u7684\u4e8c\u5143\u6210\u529f\u5956\u52b1\uff0c\u4e0d\u9700\u8981\u5927\u91cf\u7684\u4e13\u5bb6\u6f14\u793a\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRIPT-VLA\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u4e0d\u540cVLA\u6a21\u578b\u7684\u8868\u73b0\uff0c\u4f8b\u5982\u5c06QueST\u6a21\u578b\u6027\u80fd\u63d0\u534721.2%\uff0c\u5c06OpenVLA-OFT\u6a21\u578b\u7684\u6210\u529f\u7387\u63d0\u9ad8\u5230\u524d\u6240\u672a\u6709\u768497.5%\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u53ea\u9700\u4e00\u4e2a\u6f14\u793a\u5373\u53ef\u572815\u6b21\u8fed\u4ee3\u5185\u5c06\u4e0d\u53ef\u7528\u7684SFT\u6a21\u578b\uff084%\u6210\u529f\u7387\uff09\u63d0\u5347\u81f397%\u7684\u6210\u529f\u7387\u3002\u540c\u65f6\uff0c\u6240\u5b66\u7b56\u7565\u5177\u6709\u8de8\u4efb\u52a1\u548c\u573a\u666f\u7684\u6cdb\u5316\u80fd\u529b\u4ee5\u53ca\u5bf9\u521d\u59cb\u72b6\u6001\u4e0a\u4e0b\u6587\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "RIPT-VLA\u4f5c\u4e3a\u4e00\u79cd\u7b80\u5355\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u4e3a\u901a\u8fc7\u6700\u5c11\u76d1\u7763\u8fdb\u884cVLA\u6a21\u578b\u7684\u540e\u8bad\u7ec3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u9645\u4e14\u6709\u6548\u7684\u8303\u5f0f\u3002"}}
{"id": "2505.16857", "pdf": "https://arxiv.org/pdf/2505.16857", "abs": "https://arxiv.org/abs/2505.16857", "authors": ["Ertu\u011frul Ke\u00e7eci", "M\u00fcjde G\u00fczelkaya", "Tufan Kumbasar"], "title": "Redefining Clustered Federated Learning for System Identification: The Path of ClusterCraft", "categories": ["cs.LG", "I.2.8; I.5.3; I.2.11"], "comment": null, "summary": "This paper addresses the System Identification (SYSID) problem within the\nframework of federated learning. We introduce a novel algorithm, Incremental\nClustering-based federated learning method for SYSID (IC-SYSID), designed to\ntackle SYSID challenges across multiple data sources without prior knowledge.\nIC-SYSID utilizes an incremental clustering method, ClusterCraft (CC), to\neliminate the dependency on the prior knowledge of the dataset. CC starts with\na single cluster model and assigns similar local workers to the same clusters\nby dynamically increasing the number of clusters. To reduce the number of\nclusters generated by CC, we introduce ClusterMerge, where similar cluster\nmodels are merged. We also introduce enhanced ClusterCraft to reduce the\ngeneration of similar cluster models during the training. Moreover, IC-SYSID\naddresses cluster model instability by integrating a regularization term into\nthe loss function and initializing cluster models with scaled Glorot\ninitialization. It also utilizes a mini-batch deep learning approach to manage\nlarge SYSID datasets during local training. Through the experiments conducted\non a real-world representing SYSID problem, where a fleet of vehicles\ncollaboratively learns vehicle dynamics, we show that IC-SYSID achieves a high\nSYSID performance while preventing the learning of unstable clusters.", "AI": {"tldr": "This paper proposes IC-SYSID, an algorithm that uses incremental clustering for system identification within federated learning. It introduces ClusterCraft and ClusterMerge to handle multiple data sources without prior knowledge and enhances cluster stability through regularization and initialization techniques.", "motivation": "To solve the System Identification (SYSID) problem using federated learning across multiple data sources without relying on prior knowledge of the datasets.", "method": "The paper introduces IC-SYSID which uses ClusterCraft for incremental clustering starting with a single cluster model and dynamically increasing clusters based on similarity. ClusterMerge is used to reduce the number of clusters by merging similar ones. Enhanced ClusterCraft prevents generation of similar models during training. Regularization and scaled Glorot initialization are integrated to address cluster model instability. A mini-batch deep learning approach is also utilized for managing large SYSID datasets.", "result": "Experiments on a real-world SYSID problem involving collaborative learning of vehicle dynamics showed that IC-SYSID achieves high performance in SYSID while preventing unstable clusters from being learned.", "conclusion": "IC-SYSID effectively addresses the SYSID problem in a federated learning setting, achieving high performance and ensuring cluster model stability."}}
{"id": "2505.16872", "pdf": "https://arxiv.org/pdf/2505.16872", "abs": "https://arxiv.org/abs/2505.16872", "authors": ["Mohammed Al-Qudah", "Fadi AlMahamid"], "title": "A Multi-Step Comparative Framework for Anomaly Detection in IoT Data Streams", "categories": ["cs.LG"], "comment": null, "summary": "The rapid expansion of Internet of Things (IoT) devices has introduced\ncritical security challenges, underscoring the need for accurate anomaly\ndetection. Although numerous studies have proposed machine learning (ML)\nmethods for this purpose, limited research systematically examines how\ndifferent preprocessing steps--normalization, transformation, and feature\nselection--interact with distinct model architectures. To address this gap,\nthis paper presents a multi-step evaluation framework assessing the combined\nimpact of preprocessing choices on three ML algorithms: RNN-LSTM, autoencoder\nneural networks (ANN), and Gradient Boosting (GBoosting). Experiments on the\nIoTID20 dataset shows that GBoosting consistently delivers superior accuracy\nacross preprocessing configurations, while RNN-LSTM shows notable gains with\nz-score normalization and autoencoders excel in recall, making them well-suited\nfor unsupervised scenarios. By offering a structured analysis of preprocessing\ndecisions and their interplay with various ML techniques, the proposed\nframework provides actionable guidance to enhance anomaly detection performance\nin IoT environments.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u591a\u6b65\u9aa4\u8bc4\u4f30\u6846\u67b6\uff0c\u5206\u6790\u9884\u5904\u7406\u9009\u62e9\u5bf9\u4e09\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff08RNN-LSTM\u3001ANN\u3001GBoosting\uff09\u5728IoT\u73af\u5883\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u5f71\u54cd\u3002\u5b9e\u9a8c\u8868\u660eGBoosting\u51c6\u786e\u6027\u6700\u9ad8\uff0cRNN-LSTM\u5728z-score\u5f52\u4e00\u5316\u65f6\u8868\u73b0\u663e\u8457\u63d0\u5347\uff0c\u800c\u81ea\u7f16\u7801\u5668\u5728\u53ec\u56de\u7387\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002\u8be5\u6846\u67b6\u4e3a\u63d0\u9ad8IoT\u73af\u5883\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u63d0\u4f9b\u4e86\u5b9e\u9645\u6307\u5bfc\u3002", "motivation": "\u7269\u8054\u7f51\u8bbe\u5907\u7684\u5feb\u901f\u6269\u5c55\u5e26\u6765\u4e86\u5173\u952e\u7684\u5b89\u5168\u6311\u6218\uff0c\u7279\u522b\u662f\u5bf9\u7cbe\u786e\u5f02\u5e38\u68c0\u6d4b\u7684\u9700\u6c42\u3002\u7136\u800c\uff0c\u76ee\u524d\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7814\u7a76\u6765\u63a2\u8ba8\u4e0d\u540c\u7684\u9884\u5904\u7406\u6b65\u9aa4\uff08\u5f52\u4e00\u5316\u3001\u8f6c\u6362\u548c\u7279\u5f81\u9009\u62e9\uff09\u5982\u4f55\u4e0e\u4e0d\u540c\u7684\u6a21\u578b\u67b6\u6784\u76f8\u4e92\u4f5c\u7528\u4ee5\u4f18\u5316\u5f02\u5e38\u68c0\u6d4b\u6548\u679c\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u6b65\u9aa4\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u9884\u5904\u7406\u9009\u62e9\u5bf9\u4e09\u79cd\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7684\u5f71\u54cd\uff1aRNN-LSTM\u3001\u81ea\u52a8\u7f16\u7801\u795e\u7ecf\u7f51\u7edc\uff08ANN\uff09\u548c\u68af\u5ea6\u63d0\u5347\uff08GBoosting\uff09\u3002\u901a\u8fc7\u5728IoTID20\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e0d\u540c\u9884\u5904\u7406\u914d\u7f6e\u4e0b\u7684\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff1aGBoosting\u5728\u6240\u6709\u9884\u5904\u7406\u914d\u7f6e\u4e0b\u90fd\u80fd\u63d0\u4f9b\u6700\u9ad8\u7684\u51c6\u786e\u6027\uff1bRNN-LSTM\u5728\u4f7f\u7528z-score\u5f52\u4e00\u5316\u65f6\u6027\u80fd\u6709\u663e\u8457\u63d0\u5347\uff1b\u81ea\u52a8\u7f16\u7801\u5668\u5728\u53ec\u56de\u7387\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u9002\u5408\u65e0\u76d1\u7763\u573a\u666f\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u63d0\u4f9b\u7ed3\u6784\u5316\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u9610\u660e\u4e86\u9884\u5904\u7406\u51b3\u7b56\u4e0e\u5404\u79cd\u673a\u5668\u5b66\u4e60\u6280\u672f\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5e76\u4e3a\u589e\u5f3a\u7269\u8054\u7f51\u73af\u5883\u4e2d\u7684\u5f02\u5e38\u68c0\u6d4b\u6027\u80fd\u63d0\u4f9b\u4e86\u5b9e\u9645\u6307\u5bfc\u3002"}}
{"id": "2505.16903", "pdf": "https://arxiv.org/pdf/2505.16903", "abs": "https://arxiv.org/abs/2505.16903", "authors": ["Peyman Baghershahi", "Sourav Medya"], "title": "Unsupervised Prompting for Graph Neural Networks", "categories": ["cs.LG"], "comment": "25 pages, 5 figures, 14 tables", "summary": "Prompt tuning methods for Graph Neural Networks (GNNs) have become popular to\naddress the semantic gap between pre-training and fine-tuning steps. However,\nexisting GNN prompting methods rely on labeled data and involve lightweight\nfine-tuning for downstream tasks. Meanwhile, in-context learning methods for\nLarge Language Models (LLMs) have shown promising performance with no parameter\nupdating and no or minimal labeled data. Inspired by these approaches, in this\nwork, we first introduce a challenging problem setup to evaluate GNN prompting\nmethods. This setup encourages a prompting function to enhance a pre-trained\nGNN's generalization to a target dataset under covariate shift without updating\nthe GNN's parameters and with no labeled data. Next, we propose a fully\nunsupervised prompting method based on consistency regularization through\npseudo-labeling. We use two regularization techniques to align the prompted\ngraphs' distribution with the original data and reduce biased predictions.\nThrough extensive experiments under our problem setting, we demonstrate that\nour unsupervised approach outperforms the state-of-the-art prompting methods\nthat have access to labels.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u3001\u5177\u6709\u6311\u6218\u6027\u7684\u8bc4\u4f30\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNN\uff09\u63d0\u793a\u65b9\u6cd5\u7684\u95ee\u9898\u8bbe\u5b9a\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u63d0\u793a\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u65e0\u9700\u66f4\u65b0GNN\u53c2\u6570\u548c\u65e0\u6807\u7b7e\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u4e00\u81f4\u6027\u6b63\u5219\u5316\u548c\u4f2a\u6807\u8bb0\u6280\u672f\u63d0\u5347\u4e86\u9884\u8bad\u7ec3GNN\u5bf9\u76ee\u6807\u6570\u636e\u96c6\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u7684\u4f9d\u8d56\u6807\u7b7e\u7684\u63d0\u793a\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684GNN\u63d0\u793a\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6807\u7b7e\u6570\u636e\u5e76\u6d89\u53ca\u4e0b\u6e38\u4efb\u52a1\u7684\u8f7b\u91cf\u7ea7\u5fae\u8c03\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\u5728\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u548c\u6781\u5c11\u6216\u65e0\u6807\u7b7e\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u8272\u3002\u53d7\u6b64\u542f\u53d1\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u4e00\u79cd\u65e0\u9700\u66f4\u65b0GNN\u53c2\u6570\u4e14\u65e0\u9700\u6807\u7b7e\u6570\u636e\u7684\u65b9\u6cd5\u6765\u589e\u5f3a\u9884\u8bad\u7ec3GNN\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u7814\u7a76\u8005\u9996\u5148\u5f15\u5165\u4e86\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\u8bbe\u5b9a\uff0c\u7528\u4e8e\u8bc4\u4f30GNN\u63d0\u793a\u65b9\u6cd5\u5728\u534f\u53d8\u91cf\u504f\u79fb\u4e0b\u7684\u8868\u73b0\u3002\u968f\u540e\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e00\u81f4\u6027\u6b63\u5219\u5316\u7684\u5b8c\u5168\u65e0\u76d1\u7763\u63d0\u793a\u65b9\u6cd5\uff0c\u4f7f\u7528\u4f2a\u6807\u8bb0\u6280\u672f\uff0c\u5e76\u7ed3\u5408\u4e24\u79cd\u6b63\u5219\u5316\u6280\u672f\u6765\u5bf9\u9f50\u63d0\u793a\u56fe\u7684\u6570\u636e\u5206\u5e03\uff0c\u51cf\u5c11\u504f\u5dee\u9884\u6d4b\u3002", "result": "\u5728\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\u5728\u6ca1\u6709\u6807\u7b7e\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684\u9700\u8981\u6807\u7b7e\u7684\u6700\u5148\u8fdb\u7684\u63d0\u793a\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65e0\u76d1\u7763\u63d0\u793a\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u66f4\u65b0GNN\u53c2\u6570\u548c\u4e0d\u4f7f\u7528\u6807\u7b7e\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u9884\u8bad\u7ec3GNN\u5bf9\u76ee\u6807\u6570\u636e\u96c6\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3aGNN\u63d0\u793a\u65b9\u6cd5\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2505.16918", "pdf": "https://arxiv.org/pdf/2505.16918", "abs": "https://arxiv.org/abs/2505.16918", "authors": ["Nikola Tankovic", "Robert Sajina"], "title": "Scalable and Interpretable Contextual Bandits: A Literature Review and Retail Offer Prototype", "categories": ["cs.LG"], "comment": null, "summary": "This paper presents a concise review of Contextual Multi-Armed Bandit (CMAB)\nmethods and introduces an experimental framework for scalable, interpretable\noffer selection, addressing the challenge of fast-changing offers. The approach\nmodels context at the product category level, allowing offers to span multiple\ncategories and enabling knowledge transfer across similar offers. This improves\nlearning efficiency and generalization in dynamic environments. The framework\nextends standard CMAB methodology to support multi-category contexts, and\nachieves scalability through efficient feature engineering and modular design.\nAdvanced features such as MPG (Member Purchase Gap) and MF (Matrix\nFactorization) capture nuanced user-offer interactions, with implementation in\nPython for practical deployment.\n  A key contribution is interpretability at scale: logistic regression models\nyield transparent weight vectors, accessible via a large language model (LLM)\ninterface for real-time, user-level tracking and explanation of evolving\npreferences. This enables the generation of detailed member profiles and\nidentification of behavioral patterns, supporting personalized offer\noptimization and enhancing trust in automated decisions. By situating our\nprototype alongside established paradigms like Generalized Linear Models and\nThompson Sampling, we demonstrate its value for both research and real-world\nCMAB applications.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u4e0a\u4e0b\u6587\u591a\u81c2\u8001\u864e\u673a\uff08CMAB\uff09\u65b9\u6cd5\u7684\u7b80\u660e\u7efc\u8ff0\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u5b9e\u9a8c\u6846\u67b6\uff0c\u7528\u4e8e\u53ef\u6269\u5c55\u548c\u53ef\u89e3\u91ca\u7684\u4f18\u60e0\u9009\u62e9\uff0c\u89e3\u51b3\u4e86\u5feb\u901f\u53d8\u5316\u7684\u4f18\u60e0\u6311\u6218\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5efa\u6a21\u4ea7\u54c1\u7c7b\u522b\u7ea7\u522b\u7684\u4e0a\u4e0b\u6587\uff0c\u652f\u6301\u8de8\u591a\u4e2a\u7c7b\u522b\u7684\u4f18\u60e0\uff0c\u5e76\u5141\u8bb8\u76f8\u4f3c\u4f18\u60e0\u4e4b\u95f4\u7684\u77e5\u8bc6\u8f6c\u79fb\uff0c\u4ece\u800c\u63d0\u9ad8\u52a8\u6001\u73af\u5883\u4e2d\u7684\u5b66\u4e60\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u6269\u5c55\u4e86\u6807\u51c6\u7684CMAB\u65b9\u6cd5\u4ee5\u652f\u6301\u591a\u7c7b\u522b\u4e0a\u4e0b\u6587\uff0c\u901a\u8fc7\u9ad8\u6548\u7684\u7279\u5f81\u5de5\u7a0b\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u3002\u5173\u952e\u8d21\u732e\u5728\u4e8e\u5927\u89c4\u6a21\u7684\u53ef\u89e3\u91ca\u6027\uff1a\u903b\u8f91\u56de\u5f52\u6a21\u578b\u751f\u6210\u900f\u660e\u7684\u6743\u91cd\u5411\u91cf\uff0c\u53ef\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a5\u53e3\u8fdb\u884c\u5b9e\u65f6\u3001\u7528\u6237\u7ea7\u522b\u7684\u8ddf\u8e2a\u548c\u89e3\u91ca\uff0c\u751f\u6210\u8be6\u7ec6\u7684\u4f1a\u5458\u753b\u50cf\u5e76\u8bc6\u522b\u884c\u4e3a\u6a21\u5f0f\uff0c\u652f\u6301\u4e2a\u6027\u5316\u4f18\u60e0\u4f18\u5316\u5e76\u589e\u5f3a\u5bf9\u81ea\u52a8\u5316\u51b3\u7b56\u7684\u4fe1\u4efb\u3002", "motivation": "\u5728\u5feb\u901f\u53d8\u5316\u7684\u73af\u5883\u4e2d\uff0c\u4f20\u7edf\u7684CMAB\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u4f18\u60e0\u9009\u62e9\u7684\u6311\u6218\uff0c\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63d0\u5347\u5b66\u4e60\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\u4ee5\u652f\u6301\u4e2a\u6027\u5316\u4f18\u5316\u548c\u589e\u5f3a\u4fe1\u4efb\u3002", "method": "\u8be5\u65b9\u6cd5\u4e3b\u8981\u901a\u8fc7\u4ee5\u4e0b\u6b65\u9aa4\u5b9e\u73b0\uff1a1. \u5efa\u6a21\u4ea7\u54c1\u7c7b\u522b\u7ea7\u522b\u7684\u4e0a\u4e0b\u6587\uff0c\u652f\u6301\u8de8\u591a\u4e2a\u7c7b\u522b\u7684\u4f18\u60e0\uff1b2. \u5141\u8bb8\u76f8\u4f3c\u4f18\u60e0\u4e4b\u95f4\u7684\u77e5\u8bc6\u8f6c\u79fb\uff1b3. \u6269\u5c55\u6807\u51c6\u7684CMAB\u65b9\u6cd5\u4ee5\u652f\u6301\u591a\u7c7b\u522b\u4e0a\u4e0b\u6587\uff1b4. \u901a\u8fc7\u9ad8\u6548\u7684\u7279\u5f81\u5de5\u7a0b\uff08\u5982MPG\u548cMF\uff09\u548c\u6a21\u5757\u5316\u8bbe\u8ba1\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\uff1b5. \u4f7f\u7528\u903b\u8f91\u56de\u5f52\u6a21\u578b\u751f\u6210\u900f\u660e\u7684\u6743\u91cd\u5411\u91cf\uff0c\u7ed3\u5408LLM\u63a5\u53e3\u8fdb\u884c\u5b9e\u65f6\u89e3\u91ca\u3002", "result": "\u8be5\u6846\u67b6\u5c55\u793a\u4e86\u5728\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4ef7\u503c\uff0c\u80fd\u591f\u652f\u6301\u5927\u89c4\u6a21\u7684\u4e2a\u6027\u5316\u4f18\u60e0\u4f18\u5316\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u900f\u660e\u7684\u89e3\u91ca\u673a\u5236\uff0c\u589e\u5f3a\u4e86\u5bf9\u81ea\u52a8\u5316\u51b3\u7b56\u7684\u4fe1\u4efb\u3002\u901a\u8fc7\u4e0e\u5df2\u5efa\u7acb\u7684\u65b9\u6cd5\uff08\u5982\u5e7f\u4e49\u7ebf\u6027\u6a21\u578b\u548c\u6c64\u666e\u68ee\u91c7\u6837\uff09\u5bf9\u6bd4\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u5b9e\u9a8c\u6846\u67b6\u4e3aCMAB\u65b9\u6cd5\u7684\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u5feb\u901f\u53d8\u5316\u7684\u4f18\u60e0\u9009\u62e9\u573a\u666f\u4e2d\u3002\u5b83\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u5b66\u4e60\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u8fd8\u901a\u8fc7\u5927\u89c4\u6a21\u53ef\u89e3\u91ca\u6027\u652f\u6301\u4e2a\u6027\u5316\u4f18\u5316\uff0c\u63a8\u52a8\u4e86CMAB\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2505.16925", "pdf": "https://arxiv.org/pdf/2505.16925", "abs": "https://arxiv.org/abs/2505.16925", "authors": ["Igor Udovichenko", "Olivier Croissant", "Anita Toleutaeva", "Evgeny Burnaev", "Alexander Korotin"], "title": "Risk-Averse Reinforcement Learning with Itakura-Saito Loss", "categories": ["cs.LG"], "comment": null, "summary": "Risk-averse reinforcement learning finds application in various high-stakes\nfields. Unlike classical reinforcement learning, which aims to maximize\nexpected returns, risk-averse agents choose policies that minimize risk,\noccasionally sacrificing expected value. These preferences can be framed\nthrough utility theory. We focus on the specific case of the exponential\nutility function, where we can derive the Bellman equations and employ various\nreinforcement learning algorithms with few modifications. However, these\nmethods suffer from numerical instability due to the need for exponent\ncomputation throughout the process. To address this, we introduce a numerically\nstable and mathematically sound loss function based on the Itakura-Saito\ndivergence for learning state-value and action-value functions. We evaluate our\nproposed loss function against established alternatives, both theoretically and\nempirically. In the experimental section, we explore multiple financial\nscenarios, some with known analytical solutions, and show that our loss\nfunction outperforms the alternatives.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eItakura-Saito divergence\u7684\u6570\u503c\u7a33\u5b9a\u635f\u5931\u51fd\u6570\uff0c\u7528\u4e8e\u98ce\u9669\u89c4\u907f\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u72b6\u6001\u503c\u548c\u52a8\u4f5c\u503c\u51fd\u6570\u5b66\u4e60\uff0c\u5e76\u5728\u91d1\u878d\u573a\u666f\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u98ce\u9669\u89c4\u907f\u5f3a\u5316\u5b66\u4e60\u9002\u7528\u4e8e\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u4e0e\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u4e0d\u540c\uff0c\u5b83\u901a\u8fc7\u727a\u7272\u90e8\u5206\u671f\u671b\u6536\u76ca\u6765\u6700\u5c0f\u5316\u98ce\u9669\uff0c\u800c\u6307\u6570\u6548\u7528\u51fd\u6570\u4e0b\u7684Bellman\u65b9\u7a0b\u6c42\u89e3\u5b58\u5728\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u5f15\u5165\u57fa\u4e8eItakura-Saito divergence\u7684\u6570\u503c\u7a33\u5b9a\u635f\u5931\u51fd\u6570\uff0c\u89e3\u51b3\u6307\u6570\u6548\u7528\u51fd\u6570\u4e0b\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4e2d\u7684\u6570\u503c\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u540c\u65f6\u5bf9\u63d0\u51fa\u7684\u635f\u5931\u51fd\u6570\u8fdb\u884c\u7406\u8bba\u548c\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u5728\u591a\u4e2a\u91d1\u878d\u573a\u666f\u5b9e\u9a8c\u4e2d\uff08\u90e8\u5206\u5177\u6709\u89e3\u6790\u89e3\uff09\uff0c\u6240\u63d0\u51fa\u7684\u635f\u5931\u51fd\u6570\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u57fa\u4e8eItakura-Saito divergence\u7684\u635f\u5931\u51fd\u6570\u4e3a\u98ce\u9669\u89c4\u907f\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6570\u503c\u7a33\u5b9a\u4e14\u6570\u5b66\u4e25\u8c28\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u5408\u5728\u76f8\u5173\u9886\u57df\u5e94\u7528\u3002"}}
{"id": "2505.16933", "pdf": "https://arxiv.org/pdf/2505.16933", "abs": "https://arxiv.org/abs/2505.16933", "authors": ["Zebin You", "Shen Nie", "Xiaolu Zhang", "Jun Hu", "Jun Zhou", "Zhiwu Lu", "Ji-Rong Wen", "Chongxuan Li"], "title": "LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": null, "summary": "In this work, we introduce LLaDA-V, a purely diffusion-based Multimodal Large\nLanguage Model (MLLM) that integrates visual instruction tuning with masked\ndiffusion models, representing a departure from the autoregressive paradigms\ndominant in current multimodal approaches. Built upon LLaDA, a representative\nlarge language diffusion model, LLaDA-V incorporates a vision encoder and MLP\nconnector that projects visual features into the language embedding space,\nenabling effective multimodal alignment. Our empirical investigation reveals\nseveral intriguing results: First, LLaDA-V demonstrates promising multimodal\nperformance despite its language model being weaker on purely textual tasks\nthan counterparts like LLaMA3-8B and Qwen2-7B. When trained on the same\ninstruction data, LLaDA-V is highly competitive to LLaMA3-V across multimodal\ntasks with better data scalability. It also narrows the performance gap to\nQwen2-VL, suggesting the effectiveness of its architecture for multimodal\ntasks. Second, LLaDA-V achieves state-of-the-art performance in multimodal\nunderstanding compared to existing hybrid autoregressive-diffusion and purely\ndiffusion-based MLLMs. Our findings suggest that large language diffusion\nmodels show promise in multimodal contexts and warrant further investigation in\nfuture research. Project page and codes:\nhttps://ml-gsai.github.io/LLaDA-V-demo/.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u7eaf\u6269\u6563\u578b\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578bLLaDA-V\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u7ed3\u5408\u89c6\u89c9\u6307\u4ee4\u8c03\u6574\u4e0e\u63a9\u7801\u6269\u6563\u6a21\u578b\uff0c\u7a81\u7834\u4e86\u5f53\u524d\u4e3b\u6d41\u7684\u81ea\u56de\u5f52\u8303\u5f0f\u3002\u57fa\u4e8eLLaDA\u6784\u5efa\uff0cLLaDA-V\u5f15\u5165\u4e86\u89c6\u89c9\u7f16\u7801\u5668\u548cMLP\u8fde\u63a5\u5668\uff0c\u5c06\u89c6\u89c9\u7279\u5f81\u6620\u5c04\u5230\u8bed\u8a00\u5d4c\u5165\u7a7a\u95f4\uff0c\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u591a\u6a21\u6001\u5bf9\u9f50\u3002\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0c\u5c3d\u7ba1\u5176\u8bed\u8a00\u6a21\u578b\u5728\u7eaf\u6587\u672c\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0d\u5982LLaMA3-8B\u548cQwen2-7B\u7b49\u6a21\u578b\uff0c\u4f46\u5728\u76f8\u540c\u7684\u6307\u4ee4\u6570\u636e\u8bad\u7ec3\u4e0b\uff0cLLaDA-V\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u5177\u6709\u9ad8\u5ea6\u7ade\u4e89\u529b\uff0c\u5e76\u4e14\u5728\u6570\u636e\u6269\u5c55\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002\u6b64\u5916\uff0cLLaDA-V\u5728\u591a\u6a21\u6001\u7406\u89e3\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u73b0\u6709\u6df7\u5408\u81ea\u56de\u5f52-\u6269\u6563\u53ca\u7eaf\u6269\u6563\u578b\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6700\u4f73\u6027\u80fd\u3002\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6269\u6563\u6a21\u578b\u5728\u591a\u6a21\u6001\u9886\u57df\u5177\u6709\u5e7f\u9614\u7684\u5e94\u7528\u524d\u666f\uff0c\u503c\u5f97\u8fdb\u4e00\u6b65\u6df1\u5165\u7814\u7a76\u3002", "motivation": "\u76ee\u524d\u7684\u591a\u6a21\u6001\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u4e8e\u81ea\u56de\u5f52\u8303\u5f0f\uff0c\u800c\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u65b9\u6cd5\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u7eaf\u6269\u6563\u578b\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4ee5\u9a8c\u8bc1\u5176\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u63a2\u7d22\u662f\u5426\u80fd\u591f\u8d85\u8d8a\u73b0\u6709\u7684\u81ea\u56de\u5f52\u6216\u6df7\u5408\u6a21\u578b\u67b6\u6784\u3002", "method": "LLaDA-V\u901a\u8fc7\u6574\u5408\u89c6\u89c9\u6307\u4ee4\u8c03\u4f18\u4e0e\u63a9\u7801\u6269\u6563\u6a21\u578b\uff0c\u6253\u7834\u4e86\u4f20\u7edf\u7684\u81ea\u56de\u5f52\u8303\u5f0f\u3002\u5177\u4f53\u800c\u8a00\uff0c\u8be5\u6a21\u578b\u57fa\u4e8eLLaDA\u6784\u5efa\uff0c\u6dfb\u52a0\u4e86\u4e00\u4e2a\u89c6\u89c9\u7f16\u7801\u5668\u548c\u4e00\u4e2aMLP\u8fde\u63a5\u5668\uff0c\u7528\u4e8e\u5c06\u89c6\u89c9\u7279\u5f81\u6295\u5f71\u5230\u8bed\u8a00\u5d4c\u5165\u7a7a\u95f4\uff0c\u4ece\u800c\u5b9e\u73b0\u9ad8\u6548\u7684\u591a\u6a21\u6001\u5bf9\u9f50\u3002", "result": "1. \u5c3d\u7ba1LLaDA-V\u7684\u8bed\u8a00\u6a21\u578b\u5728\u7eaf\u6587\u672c\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5f31\u4e8eLLaMA3-8B\u548cQwen2-7B\u7b49\u6a21\u578b\uff0c\u4f46\u5176\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff1b2. \u5728\u76f8\u540c\u6307\u4ee4\u6570\u636e\u8bad\u7ec3\u4e0b\uff0cLLaDA-V\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0eLLaMA3-V\u76f8\u5f53\uff0c\u5e76\u4e14\u6570\u636e\u6269\u5c55\u6027\u66f4\u597d\uff1b3. LLaDA-V\u663e\u8457\u7f29\u5c0f\u4e86\u4e0eQwen2-VL\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u8bc1\u660e\u4e86\u5176\u67b6\u6784\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff1b4. \u5728\u591a\u6a21\u6001\u7406\u89e3\u4efb\u52a1\u4e2d\uff0cLLaDA-V\u8fbe\u5230\u4e86\u73b0\u6709\u6a21\u578b\u7684\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6269\u6563\u6a21\u578b\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u5177\u6709\u663e\u8457\u6f5c\u529b\u3002\u672a\u6765\u7684\u7814\u7a76\u53ef\u4ee5\u8fdb\u4e00\u6b65\u4f18\u5316\u6269\u6563\u6a21\u578b\u67b6\u6784\uff0c\u63a2\u7d22\u5176\u5728\u66f4\u591a\u590d\u6742\u591a\u6a21\u6001\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2505.16936", "pdf": "https://arxiv.org/pdf/2505.16936", "abs": "https://arxiv.org/abs/2505.16936", "authors": ["Yizhuo Chen", "Tianchen Wang", "You Lyu", "Yanlan Hu", "Jinyang Li", "Tomoyoshi Kimura", "Hongjue Zhao", "Yigong Hu", "Denizhan Kara", "Tarek Abdelzaher"], "title": "SPAR: Self-supervised Placement-Aware Representation Learning for Multi-Node IoT Systems", "categories": ["cs.LG"], "comment": null, "summary": "This work develops the underpinnings of self-supervised placement-aware\nrepresentation learning given spatially-distributed (multi-view and multimodal)\nsensor observations, motivated by the need to represent external environmental\nstate in multi-sensor IoT systems in a manner that correctly distills spatial\nphenomena from the distributed multi-vantage observations. The objective of\nsensing in IoT systems is, in general, to collectively represent an externally\nobserved environment given multiple vantage points from which sensory\nobservations occur. Pretraining of models that help interpret sensor data must\ntherefore encode the relation between signals observed by sensors and the\nobservers' vantage points in order to attain a representation that encodes the\nobserved spatial phenomena in a manner informed by the specific placement of\nthe measuring instruments, while allowing arbitrary placement. The work\nsignificantly advances self-supervised model pretraining from IoT signals\nbeyond current solutions that often overlook the distinctive spatial nature of\nIoT data. Our framework explicitly learns the dependencies between measurements\nand geometric observer layouts and structural characteristics, guided by a core\ndesign principle: the duality between signals and observer positions. We\nfurther provide theoretical analyses from the perspectives of information\ntheory and occlusion-invariant representation learning to offer insight into\nthe rationale behind our design. Experiments on three real-world\ndatasets--covering vehicle monitoring, human activity recognition, and\nearthquake localization--demonstrate the superior generalizability and\nrobustness of our method across diverse modalities, sensor placements,\napplication-level inference tasks, and spatial scales.", "AI": {"tldr": "This work develops self-supervised placement-aware representation learning for spatially-distributed multi-view and multimodal sensor observations in IoT systems.", "motivation": "The need to represent external environmental state in multi-sensor IoT systems in a manner that correctly distills spatial phenomena from the distributed multi-vantage observations.", "method": "Framework explicitly learns dependencies between measurements and geometric observer layouts and structural characteristics, guided by the duality between signals and observer positions. Theoretical analyses from information theory and occlusion-invariant representation learning are provided.", "result": "Experiments on three real-world datasets demonstrate superior generalizability and robustness across diverse modalities, sensor placements, application-level inference tasks, and spatial scales.", "conclusion": "Advances self-supervised model pretraining from IoT signals beyond current solutions that often overlook the distinctive spatial nature of IoT data."}}
{"id": "2505.16952", "pdf": "https://arxiv.org/pdf/2505.16952", "abs": "https://arxiv.org/abs/2505.16952", "authors": ["Shengyu Feng", "Weiwei Sun", "Shanda Li", "Ameet Talwalkar", "Yiming Yang"], "title": "A Comprehensive Evaluation of Contemporary ML-Based Solvers for Combinatorial Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning (ML) has demonstrated considerable potential in supporting\nmodel design and optimization for combinatorial optimization (CO) problems.\nHowever, much of the progress to date has been evaluated on small-scale,\nsynthetic datasets, raising concerns about the practical effectiveness of\nML-based solvers in real-world, large-scale CO scenarios. Additionally, many\nexisting CO benchmarks lack sufficient training data, limiting their utility\nfor evaluating data-driven approaches. To address these limitations, we\nintroduce FrontierCO, a comprehensive benchmark that covers eight canonical CO\nproblem types and evaluates 16 representative ML-based solvers--including graph\nneural networks and large language model (LLM) agents. FrontierCO features\nchallenging instances drawn from industrial applications and frontier CO\nresearch, offering both realistic problem difficulty and abundant training\ndata. Our empirical results provide critical insights into the strengths and\nlimitations of current ML methods, helping to guide more robust and practically\nrelevant advances at the intersection of machine learning and combinatorial\noptimization. Our data is available at\nhttps://huggingface.co/datasets/CO-Bench/FrontierCO.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86FrontierCO\uff0c\u8fd9\u662f\u4e00\u4e2a\u5168\u9762\u7684\u7ec4\u5408\u4f18\u5316\uff08CO\uff09\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u6db5\u76d6\u4e86\u516b\u4e2a\u5178\u578b\u7684CO\u95ee\u9898\u7c7b\u578b\uff0c\u5e76\u8bc4\u4f30\u4e8616\u79cd\u5177\u6709\u4ee3\u8868\u6027\u7684\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u7684\u6c42\u89e3\u5668\u3002FrontierCO\u63d0\u4f9b\u4e86\u6765\u81ea\u5de5\u4e1a\u5e94\u7528\u548c\u524d\u6cbfCO\u7814\u7a76\u7684\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\u5b9e\u4f8b\uff0c\u65e2\u4f53\u73b0\u4e86\u5b9e\u9645\u95ee\u9898\u7684\u96be\u5ea6\uff0c\u53c8\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u8bad\u7ec3\u6570\u636e\u3002\u5b9e\u9a8c\u7ed3\u679c\u63ed\u793a\u4e86\u5f53\u524dML\u65b9\u6cd5\u5728\u89e3\u51b3CO\u95ee\u9898\u4e0a\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\u6027\uff0c\u4e3a\u63a8\u52a8\u673a\u5668\u5b66\u4e60\u4e0e\u7ec4\u5408\u4f18\u5316\u4ea4\u53c9\u9886\u57df\u7684\u66f4\u7a33\u5065\u3001\u66f4\u5177\u5b9e\u8df5\u610f\u4e49\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002\u76f8\u5173\u6570\u636e\u53ef\u5728https://huggingface.co/datasets/CO-Bench/FrontierCO\u83b7\u53d6\u3002", "motivation": "\u76ee\u524d\uff0c\u5c3d\u7ba1\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u5728\u652f\u6301\u7ec4\u5408\u4f18\u5316\uff08CO\uff09\u95ee\u9898\u7684\u6a21\u578b\u8bbe\u8ba1\u548c\u4f18\u5316\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5176\u8fdb\u5c55\u4e3b\u8981\u57fa\u4e8e\u5c0f\u89c4\u6a21\u3001\u5408\u6210\u6570\u636e\u96c6\u7684\u8bc4\u4f30\uff0c\u8fd9\u5f15\u53d1\u4e86\u5bf9ML\u6c42\u89e3\u5668\u5728\u771f\u5b9e\u4e16\u754c\u5927\u89c4\u6a21CO\u573a\u666f\u4e2d\u5b9e\u9645\u6548\u679c\u7684\u62c5\u5fe7\u3002\u6b64\u5916\uff0c\u8bb8\u591a\u73b0\u6709\u7684CO\u57fa\u51c6\u7f3a\u4e4f\u8db3\u591f\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u9650\u5236\u4e86\u5b83\u4eec\u5728\u8bc4\u4f30\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u65f6\u7684\u5b9e\u7528\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u53cd\u6620\u5b9e\u9645\u95ee\u9898\u96be\u5ea6\u5e76\u63d0\u4f9b\u5145\u8db3\u8bad\u7ec3\u6570\u636e\u7684\u7efc\u5408\u57fa\u51c6\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u540d\u4e3aFrontierCO\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\u3002\u8be5\u5e73\u53f0\u8986\u76d6\u4e86\u516b\u79cd\u5178\u578b\u7684CO\u95ee\u9898\u7c7b\u578b\uff0c\u5e76\u8bc4\u4f30\u4e8616\u79cd\u4ee3\u8868\u6027ML\u6c42\u89e3\u5668\uff0c\u5305\u62ec\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u3002FrontierCO\u4e2d\u7684\u95ee\u9898\u5b9e\u4f8b\u6765\u6e90\u4e8e\u5de5\u4e1a\u5e94\u7528\u548c\u524d\u6cbfCO\u7814\u7a76\uff0c\u786e\u4fdd\u4e86\u95ee\u9898\u7684\u5b9e\u9645\u96be\u5ea6\u548c\u5145\u8db3\u7684\u8bad\u7ec3\u6570\u636e\u91cf\u3002\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u4e86\u5f53\u524dML\u65b9\u6cd5\u5728\u89e3\u51b3CO\u95ee\u9898\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cFrontierCO\u6210\u529f\u5730\u53cd\u6620\u4e86\u5b9e\u9645CO\u95ee\u9898\u7684\u590d\u6742\u6027\u548c\u96be\u5ea6\u3002\u901a\u8fc7\u5bf916\u79cdML\u6c42\u89e3\u5668\u7684\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5728\u89e3\u51b3\u4e0d\u540c\u7c7b\u578b\u7684CO\u95ee\u9898\u65f6\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\u6027\u3002\u5177\u4f53\u800c\u8a00\uff0c\u67d0\u4e9bML\u6c42\u89e3\u5668\u5728\u7279\u5b9a\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5176\u4ed6\u95ee\u9898\u4e0a\u5219\u9762\u4e34\u6311\u6218\u3002\u8fd9\u4e9b\u53d1\u73b0\u6709\u52a9\u4e8e\u6307\u5bfc\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u6539\u8fdbML\u65b9\u6cd5\u5728CO\u9886\u57df\u7684\u5e94\u7528\u3002", "conclusion": "FrontierCO\u4f5c\u4e3a\u4e00\u4e2a\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u586b\u8865\u4e86\u73b0\u6709CO\u57fa\u51c6\u5728\u5b9e\u9645\u95ee\u9898\u96be\u5ea6\u548c\u8bad\u7ec3\u6570\u636e\u91cf\u65b9\u9762\u7684\u7a7a\u767d\u3002\u5b83\u4e0d\u4ec5\u4e3a\u8bc4\u4f30ML\u6c42\u89e3\u5668\u5728CO\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\uff0c\u8fd8\u63ed\u793a\u4e86\u5f53\u524d\u65b9\u6cd5\u7684\u4f18\u52a3\u52bf\u3002\u8fd9\u4e00\u5de5\u4f5c\u5c06\u4fc3\u8fdb\u673a\u5668\u5b66\u4e60\u4e0e\u7ec4\u5408\u4f18\u5316\u4ea4\u53c9\u9886\u57df\u7684\u53d1\u5c55\uff0c\u63a8\u52a8\u66f4\u52a0\u7a33\u5065\u548c\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u7684\u51fa\u73b0\u3002"}}
{"id": "2505.16984", "pdf": "https://arxiv.org/pdf/2505.16984", "abs": "https://arxiv.org/abs/2505.16984", "authors": ["Mingyang Liu", "Gabriele Farina", "Asuman Ozdaglar"], "title": "UFT: Unifying Supervised and Reinforcement Fine-Tuning", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Post-training has demonstrated its importance in enhancing the reasoning\ncapabilities of large language models (LLMs). The primary post-training methods\ncan be categorized into supervised fine-tuning (SFT) and reinforcement\nfine-tuning (RFT). SFT is efficient and well-suited for small language models,\nbut it may lead to overfitting and limit the reasoning abilities of larger\nmodels. In contrast, RFT generally yields better generalization but depends\nheavily on the strength of the base model. To address the limitations of SFT\nand RFT, we propose Unified Fine-Tuning (UFT), a novel post-training paradigm\nthat unifies SFT and RFT into a single, integrated process. UFT enables the\nmodel to effectively explore solutions while incorporating informative\nsupervision signals, bridging the gap between memorizing and thinking\nunderlying existing methods. Notably, UFT outperforms both SFT and RFT in\ngeneral, regardless of model sizes. Furthermore, we theoretically prove that\nUFT breaks RFT's inherent exponential sample complexity bottleneck, showing for\nthe first time that unified training can exponentially accelerate convergence\non long-horizon reasoning tasks.", "AI": {"tldr": "\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\u4e2d\uff0c\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u548c\u5f3a\u5316\u5fae\u8c03\uff08RFT\uff09\u5404\u6709\u5c40\u9650\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u540e\u8bad\u7ec3\u8303\u5f0f\u2014\u2014\u7edf\u4e00\u5fae\u8c03\uff08UFT\uff09\uff0c\u5c06SFT\u548cRFT\u6574\u5408\u4e3a\u4e00\u4e2a\u5355\u4e00\u8fc7\u7a0b\u3002UFT\u4e0d\u4ec5\u5728\u5404\u79cd\u6a21\u578b\u5c3a\u5bf8\u4e0a\u8868\u73b0\u4f18\u4e8eSFT\u548cRFT\uff0c\u8fd8\u7406\u8bba\u4e0a\u7a81\u7834\u4e86RFT\u56fa\u6709\u7684\u6307\u6570\u6837\u672c\u590d\u6742\u5ea6\u74f6\u9888\uff0c\u9996\u6b21\u8bc1\u660e\u7edf\u4e00\u8bad\u7ec3\u53ef\u4ee5\u5728\u957f\u65f6\u63a8\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6307\u6570\u7ea7\u52a0\u901f\u6536\u655b\u3002", "motivation": "\u5f53\u524d\u4e3b\u8981\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5SFT\u548cRFT\u5206\u522b\u5b58\u5728\u8fc7\u62df\u5408\u4e0e\u5bf9\u57fa\u7840\u6a21\u578b\u4f9d\u8d56\u6027\u5f3a\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u5927\u6a21\u578b\u4e0a\u7684\u5e94\u7528\u6548\u679c\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u7684\u65b0\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aUFT\u7684\u65b0\u540e\u8bad\u7ec3\u8303\u5f0f\uff0c\u8be5\u65b9\u6cd5\u5c06SFT\u548cRFT\u878d\u5408\u5230\u4e00\u4e2a\u96c6\u6210\u8fc7\u7a0b\u4e2d\uff0c\u4f7f\u6a21\u578b\u65e2\u80fd\u6709\u6548\u63a2\u7d22\u89e3\u51b3\u65b9\u6848\uff0c\u53c8\u80fd\u5f15\u5165\u6709\u76ca\u7684\u76d1\u7763\u4fe1\u53f7\uff0c\u4ece\u800c\u5f25\u5408\u73b0\u6709\u65b9\u6cd5\u4e2d\u8bb0\u5fc6\u4e0e\u601d\u8003\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u65e0\u8bba\u6a21\u578b\u5927\u5c0f\u5982\u4f55\uff0cUFT\u5728\u603b\u4f53\u4e0a\u90fd\u4f18\u4e8eSFT\u548cRFT\u3002\u6b64\u5916\uff0c\u7406\u8bba\u5206\u6790\u663e\u793aUFT\u53ef\u4ee5\u6253\u7834RFT\u56fa\u6709\u7684\u6307\u6570\u6837\u672c\u590d\u6742\u5ea6\u74f6\u9888\uff0c\u5e76\u5728\u957f\u65f6\u63a8\u7406\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6307\u6570\u7ea7\u52a0\u901f\u6536\u655b\u3002", "conclusion": "UFT\u4f5c\u4e3a\u4e00\u79cd\u65b0\u578b\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5728\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u4e14\u4ece\u7406\u8bba\u4e0a\u652f\u6301\u4e86\u5176\u5728\u5904\u7406\u590d\u6742\u63a8\u7406\u4efb\u52a1\u65f6\u7684\u9ad8\u6548\u6027\u3002"}}
{"id": "2505.16992", "pdf": "https://arxiv.org/pdf/2505.16992", "abs": "https://arxiv.org/abs/2505.16992", "authors": ["Aleksandra Franz", "Hao Wei", "Luca Guastoni", "Nils Thuerey"], "title": "PICT -- A Differentiable, GPU-Accelerated Multi-Block PISO Solver for Simulation-Coupled Learning Tasks in Fluid Dynamics", "categories": ["cs.LG", "physics.comp-ph"], "comment": "Source code at https://github.com/tum-pbs/PICT", "summary": "Despite decades of advancements, the simulation of fluids remains one of the\nmost challenging areas of in scientific computing. Supported by the necessity\nof gradient information in deep learning, differentiable simulators have\nemerged as an effective tool for optimization and learning in physics\nsimulations. In this work, we present our fluid simulator PICT, a\ndifferentiable pressure-implicit solver coded in PyTorch with\nGraphics-processing-unit (GPU) support. We first verify the accuracy of both\nthe forward simulation and our derived gradients in various established\nbenchmarks like lid-driven cavities and turbulent channel flows before we show\nthat the gradients provided by our solver can be used to learn complicated\nturbulence models in 2D and 3D. We apply both supervised and unsupervised\ntraining regimes using physical priors to match flow statistics. In particular,\nwe learn a stable sub-grid scale (SGS) model for a 3D turbulent channel flow\npurely based on reference statistics. The low-resolution corrector trained with\nour solver runs substantially faster than the highly resolved references, while\nkeeping or even surpassing their accuracy. Finally, we give additional insights\ninto the physical interpretation of different solver gradients, and motivate a\nphysically informed regularization technique. To ensure that the full potential\nof PICT can be leveraged, it is published as open source:\nhttps://github.com/tum-pbs/PICT.", "AI": {"tldr": "\u5c3d\u7ba1\u51e0\u5341\u5e74\u6765\u53d6\u5f97\u4e86\u8fdb\u6b65\uff0c\u6d41\u4f53\u6a21\u62df\u4ecd\u7136\u662f\u79d1\u5b66\u8ba1\u7b97\u4e2d\u6700\u5177\u6311\u6218\u6027\u7684\u9886\u57df\u4e4b\u4e00\u3002\u7531\u4e8e\u6df1\u5ea6\u5b66\u4e60\u4e2d\u5bf9\u68af\u5ea6\u4fe1\u606f\u7684\u9700\u6c42\uff0c\u53ef\u5fae\u5206\u6a21\u62df\u5668\u5df2\u6210\u4e3a\u7269\u7406\u6a21\u62df\u4f18\u5316\u548c\u5b66\u4e60\u7684\u6709\u6548\u5de5\u5177\u3002\u5728\u8fd9\u9879\u5de5\u4f5c\u4e2d\uff0c\u6211\u4eec\u63d0\u51fa\u4e86PICT\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8ePyTorch\u7684\u53ef\u5fae\u5206\u538b\u529b\u9690\u5f0f\u6c42\u89e3\u5668\uff0c\u5e76\u652f\u6301GPU\u3002\u6211\u4eec\u5728\u5404\u79cd\u5df2\u5efa\u7acb\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u524d\u5411\u6a21\u62df\u548c\u5bfc\u51fa\u68af\u5ea6\u7684\u51c6\u786e\u6027\uff0c\u4f8b\u5982\u76d6\u9a71\u52a8\u8154\u548c\u6e4d\u6d41\u901a\u9053\u6d41\u52a8\u3002\u7136\u540e\u6211\u4eec\u5c55\u793a\u4e86\u6c42\u89e3\u5668\u63d0\u4f9b\u7684\u68af\u5ea6\u53ef\u4ee5\u7528\u4e8e\u5b66\u4e60\u590d\u6742\u7684\u4e8c\u7ef4\u548c\u4e09\u7ef4\u6e4d\u6d41\u6a21\u578b\u3002\u6211\u4eec\u4f7f\u7528\u76d1\u7763\u548c\u65e0\u76d1\u7763\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5229\u7528\u7269\u7406\u5148\u9a8c\u5339\u914d\u6d41\u4f53\u7edf\u8ba1\u7279\u6027\u3002\u7279\u522b\u662f\uff0c\u6211\u4eec\u57fa\u4e8e\u53c2\u8003\u7edf\u8ba1\u91cf\u5b66\u4e60\u4e86\u4e00\u4e2a\u7a33\u5b9a\u76843D\u6e4d\u6d41\u901a\u9053\u6d41\u7684\u5b50\u7f51\u683c\u5c3a\u5ea6\uff08SGS\uff09\u6a21\u578b\u3002\u901a\u8fc7\u6211\u4eec\u7684\u6c42\u89e3\u5668\u8bad\u7ec3\u7684\u4f4e\u5206\u8fa8\u7387\u6821\u6b63\u5668\u6bd4\u9ad8\u5206\u8fa8\u7387\u53c2\u8003\u8fd0\u884c\u5feb\u5f97\u591a\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u8d85\u8d8a\u5176\u51c6\u786e\u6027\u3002\u6700\u540e\uff0c\u6211\u4eec\u63d0\u4f9b\u4e86\u5bf9\u4e0d\u540c\u6c42\u89e3\u5668\u68af\u5ea6\u7684\u7269\u7406\u89e3\u91ca\u7684\u989d\u5916\u89c1\u89e3\uff0c\u5e76\u6fc0\u53d1\u4e86\u4e00\u79cd\u7269\u7406\u77e5\u60c5\u7684\u6b63\u5219\u5316\u6280\u672f\u3002\u4e3a\u4e86\u786e\u4fddPICT\u7684\u5168\u90e8\u6f5c\u529b\u5f97\u4ee5\u53d1\u6325\uff0c\u5b83\u4f5c\u4e3a\u5f00\u6e90\u53d1\u5e03\uff1ahttps://github.com/tum-pbs/PICT\u3002", "motivation": "\u6d41\u4f53\u6a21\u62df\u662f\u79d1\u5b66\u8ba1\u7b97\u4e2d\u6700\u5177\u6709\u6311\u6218\u6027\u7684\u9886\u57df\u4e4b\u4e00\uff0c\u800c\u53ef\u5fae\u5206\u6a21\u62df\u5668\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u5bf9\u4e8e\u4f18\u5316\u548c\u5b66\u4e60\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u5f00\u53d1\u4e00\u4e2a\u9ad8\u6548\u3001\u51c6\u786e\u7684\u53ef\u5fae\u5206\u6d41\u4f53\u6a21\u62df\u5668\u662f\u975e\u5e38\u91cd\u8981\u7684\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPICT\u7684\u53ef\u5fae\u5206\u538b\u529b\u9690\u5f0f\u6c42\u89e3\u5668\uff0c\u8be5\u6c42\u89e3\u5668\u57fa\u4e8ePyTorch\u5e76\u652f\u6301GPU\u3002\u9996\u5148\uff0c\u5728\u591a\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u524d\u5411\u6a21\u62df\u548c\u68af\u5ea6\u7684\u51c6\u786e\u6027\u3002\u7136\u540e\uff0c\u4f7f\u7528\u76d1\u7763\u548c\u65e0\u76d1\u7763\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5229\u7528\u7269\u7406\u5148\u9a8c\u6765\u5b66\u4e60\u590d\u6742\u7684\u6e4d\u6d41\u6a21\u578b\u3002\u6700\u540e\uff0c\u63a2\u8ba8\u4e86\u6c42\u89e3\u5668\u68af\u5ea6\u7684\u7269\u7406\u89e3\u91ca\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7269\u7406\u77e5\u60c5\u7684\u6b63\u5219\u5316\u6280\u672f\u3002", "result": "PICT\u80fd\u591f\u5728\u4fdd\u8bc1\u751a\u81f3\u8d85\u8d8a\u9ad8\u5206\u8fa8\u7387\u53c2\u8003\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u5927\u5e45\u63d0\u9ad8\u8fd0\u884c\u901f\u5ea6\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5bf9\u6c42\u89e3\u5668\u68af\u5ea6\u7684\u6df1\u5165\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u7269\u7406\u77e5\u60c5\u7684\u6b63\u5219\u5316\u6280\u672f\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "conclusion": "PICT\u4f5c\u4e3a\u4e00\u4e2a\u9ad8\u6548\u7684\u53ef\u5fae\u5206\u6d41\u4f53\u6a21\u62df\u5668\uff0c\u4e0d\u4ec5\u5728\u901f\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u9ad8\u5206\u8fa8\u7387\u53c2\u8003\uff0c\u800c\u4e14\u5728\u7cbe\u5ea6\u4e0a\u4e5f\u8868\u73b0\u51fa\u8272\u3002\u901a\u8fc7\u5bf9\u6c42\u89e3\u5668\u68af\u5ea6\u7684\u6df1\u5165\u7406\u89e3\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7269\u7406\u77e5\u60c5\u7684\u6b63\u5219\u5316\u6280\u672f\uff0c\u8fd9\u4e3a\u672a\u6765\u7684\u7269\u7406\u6a21\u62df\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2505.16996", "pdf": "https://arxiv.org/pdf/2505.16996", "abs": "https://arxiv.org/abs/2505.16996", "authors": ["Shalev Manor", "Mohammad Kohandel"], "title": "A Unified Framework for Simultaneous Parameter and Function Discovery in Differential Equations", "categories": ["cs.LG"], "comment": "13 pages, 8 figures", "summary": "Inverse problems involving differential equations often require identifying\nunknown parameters or functions from data. Existing approaches, such as\nPhysics-Informed Neural Networks (PINNs), Universal Differential Equations\n(UDEs) and Universal Physics-Informed Neural Networks (UPINNs), are effective\nat isolating either parameters or functions but can face challenges when\napplied simultaneously due to solution non-uniqueness. In this work, we\nintroduce a framework that addresses these limitations by establishing\nconditions under which unique solutions can be guaranteed. To illustrate, we\napply it to examples from biological systems and ecological dynamics,\ndemonstrating accurate and interpretable results. Our approach significantly\nenhances the potential of machine learning techniques in modeling complex\nsystems in science and engineering.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u5fae\u5206\u65b9\u7a0b\u53cd\u95ee\u9898\u4e2d\u7684\u975e\u552f\u4e00\u6027\u6311\u6218\uff0c\u786e\u4fdd\u53c2\u6570\u548c\u51fd\u6570\u7684\u540c\u65f6\u8bc6\u522b\u5177\u6709\u552f\u4e00\u89e3\uff0c\u5e76\u5728\u751f\u7269\u548c\u751f\u6001\u9886\u57df\u5c55\u793a\u4e86\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u5982PINNs\u3001UDEs\u548cUPINNs\u5728\u540c\u65f6\u8bc6\u522b\u53c2\u6570\u548c\u51fd\u6570\u65f6\u9762\u4e34\u89e3\u7684\u975e\u552f\u4e00\u6027\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u8303\u56f4\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u7acb\u4fdd\u8bc1\u552f\u4e00\u89e3\u7684\u6761\u4ef6\uff0c\u89e3\u51b3\u4e86\u53c2\u6570\u548c\u51fd\u6570\u540c\u65f6\u8bc6\u522b\u65f6\u7684\u975e\u552f\u4e00\u6027\u95ee\u9898\u3002", "result": "\u5728\u751f\u7269\u7cfb\u7edf\u548c\u751f\u6001\u52a8\u529b\u5b66\u7684\u4f8b\u5b50\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5c55\u793a\u4e86\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\u3002", "conclusion": "\u8be5\u6846\u67b6\u663e\u8457\u589e\u5f3a\u4e86\u673a\u5668\u5b66\u4e60\u6280\u672f\u5728\u79d1\u5b66\u548c\u5de5\u7a0b\u590d\u6742\u7cfb\u7edf\u5efa\u6a21\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.17013", "pdf": "https://arxiv.org/pdf/2505.17013", "abs": "https://arxiv.org/abs/2505.17013", "authors": ["Kevin Lu", "Nicky Kriplani", "Rohit Gandikota", "Minh Pham", "David Bau", "Chinmay Hegde", "Niv Cohen"], "title": "When Are Concepts Erased From Diffusion Models?", "categories": ["cs.LG", "cs.CV"], "comment": "Project Page:\n  https://nyu-dice-lab.github.io/when-are-concepts-erased/", "summary": "Concept erasure, the ability to selectively prevent a model from generating\nspecific concepts, has attracted growing interest, with various approaches\nemerging to address the challenge. However, it remains unclear how thoroughly\nthese methods erase the target concept. We begin by proposing two conceptual\nmodels for the erasure mechanism in diffusion models: (i) reducing the\nlikelihood of generating the target concept, and (ii) interfering with the\nmodel's internal guidance mechanisms. To thoroughly assess whether a concept\nhas been truly erased from the model, we introduce a suite of independent\nevaluations. Our evaluation framework includes adversarial attacks, novel\nprobing techniques, and analysis of the model's alternative generations in\nplace of the erased concept. Our results shed light on the tension between\nminimizing side effects and maintaining robustness to adversarial prompts.\nBroadly, our work underlines the importance of comprehensive evaluation for\nerasure in diffusion models.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u6269\u6563\u6a21\u578b\u4e2d\u7684\u6982\u5ff5\u64e6\u9664\u673a\u5236\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u6982\u5ff5\u64e6\u9664\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u5957\u72ec\u7acb\u8bc4\u4f30\u65b9\u6cd5\u6765\u5224\u65ad\u6982\u5ff5\u662f\u5426\u88ab\u5f7b\u5e95\u64e6\u9664\u3002\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u51cf\u5c11\u526f\u4f5c\u7528\u548c\u4fdd\u6301\u5bf9\u5bf9\u6297\u6027\u63d0\u793a\u7684\u9c81\u68d2\u6027\u4e4b\u95f4\u7684\u5e73\u8861\uff0c\u4ee5\u53ca\u5168\u9762\u8bc4\u4f30\u6982\u5ff5\u64e6\u9664\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u968f\u7740\u5bf9\u6a21\u578b\u751f\u6210\u7279\u5b9a\u6982\u5ff5\u8fdb\u884c\u9009\u62e9\u6027\u963b\u6b62\u7684\u5174\u8da3\u65e5\u76ca\u589e\u957f\uff0c\u591a\u79cd\u65b9\u6cd5\u88ab\u63d0\u51fa\u4ee5\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u3002\u7136\u800c\uff0c\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u8fd9\u4e9b\u65b9\u6cd5\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u80fd\u591f\u5f7b\u5e95\u64e6\u9664\u76ee\u6807\u6982\u5ff5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e24\u79cd\u6269\u6563\u6a21\u578b\u4e2d\u6982\u5ff5\u64e6\u9664\u7684\u673a\u5236\u6a21\u578b\uff1a(i) \u964d\u4f4e\u751f\u6210\u76ee\u6807\u6982\u5ff5\u7684\u53ef\u80fd\u6027\uff1b(ii) \u5e72\u6270\u6a21\u578b\u5185\u90e8\u7684\u5f15\u5bfc\u673a\u5236\u3002\u540c\u65f6\uff0c\u4e3a\u4e86\u8bc4\u4f30\u6982\u5ff5\u662f\u5426\u88ab\u771f\u6b63\u64e6\u9664\uff0c\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u7cfb\u5217\u72ec\u7acb\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5305\u62ec\u5bf9\u6297\u6027\u653b\u51fb\u3001\u65b0\u7684\u63a2\u6d4b\u6280\u672f\u4ee5\u53ca\u5206\u6790\u6a21\u578b\u5728\u64e6\u9664\u6982\u5ff5\u540e\u7684\u66ff\u4ee3\u751f\u6210\u5185\u5bb9\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u5728\u6700\u5c0f\u5316\u526f\u4f5c\u7528\u548c\u7ef4\u6301\u5bf9\u5bf9\u6297\u6027\u63d0\u793a\u7684\u9c81\u68d2\u6027\u4e4b\u95f4\u7684\u7d27\u5f20\u5173\u7cfb\u3002", "conclusion": "\u672c\u5de5\u4f5c\u5f3a\u8c03\u4e86\u5bf9\u6269\u6563\u6a21\u578b\u4e2d\u7684\u6982\u5ff5\u64e6\u9664\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2505.14403", "pdf": "https://arxiv.org/pdf/2505.14403", "abs": "https://arxiv.org/abs/2505.14403", "authors": ["Zhaohui Yang", "Shilei Jiang", "Chen Hu", "Linjing Li", "Shihong Deng", "Daxin Jiang"], "title": "Unearthing Gems from Stones: Policy Optimization with Negative Sample Augmentation for LLM Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in reasoning language models have witnessed a paradigm shift\nfrom short to long CoT pattern. Given the substantial computational cost of\nrollouts in long CoT models, maximizing the utility of fixed training datasets\nbecomes crucial. Our analysis reveals that negative responses contain valuable\ncomponents such as self-reflection and error-correction steps, yet primary\nexisting methods either completely discard negative samples (RFT) or apply\nequal penalization across all tokens (RL), failing to leverage these potential\nlearning signals. In light of this, we propose Behavior Constrained Policy\nGradient with Negative Sample Augmentation (BCPG-NSA), a fine-grained offline\nRL framework that encompasses three stages: 1) sample segmentation, 2)\nconsensus-based step correctness assessment combining LLM and PRM judgers, and\n3) policy optimization with NSA designed to effectively mine positive steps\nwithin negative samples. Experimental results show that BCPG-NSA outperforms\nbaselines on several challenging math/coding reasoning benchmarks using the\nsame training dataset, achieving improved sample efficiency and demonstrating\nrobustness and scalability when extended to multiple iterations.", "AI": {"tldr": "\u8fd1\u671f\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u7ecf\u5386\u4e86\u4ece\u77ed\u94fe\u5230\u957f\u94fe\u601d\u8003\uff08CoT\uff09\u6a21\u5f0f\u7684\u8303\u5f0f\u8f6c\u53d8\u3002\u9274\u4e8e\u957f\u94feCoT\u6a21\u578b\u7684\u5de8\u5927\u8ba1\u7b97\u6210\u672c\uff0c\u6700\u5927\u5316\u56fa\u5b9a\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u6548\u7528\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u6211\u4eec\u53d1\u73b0\u8d1f\u6837\u672c\u4e2d\u5305\u542b\u6709\u4ef7\u503c\u7684\u6210\u5206\uff0c\u5982\u81ea\u6211\u53cd\u601d\u548c\u9519\u8bef\u7ea0\u6b63\u6b65\u9aa4\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u5b8c\u5168\u4e22\u5f03\u8d1f\u6837\u672c\uff08RFT\uff09\uff0c\u8981\u4e48\u5bf9\u6240\u6709\u6807\u8bb0\u65bd\u52a0\u76f8\u7b49\u60e9\u7f5a\uff08RL\uff09\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u5e26\u6709\u8d1f\u6837\u672c\u589e\u5f3a\u7684\u884c\u4e3a\u7ea6\u675f\u7b56\u7565\u68af\u5ea6\uff08BCPG-NSA\uff09\uff0c\u4e00\u79cd\u7cbe\u7ec6\u7c92\u5ea6\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u62ec\u4e09\u4e2a\u9636\u6bb5\uff1a1\uff09\u6837\u672c\u5206\u5272\uff1b2\uff09\u57fa\u4e8e\u5171\u8bc6\u7684\u6b65\u9aa4\u6b63\u786e\u6027\u8bc4\u4f30\uff0c\u7ed3\u5408LLM\u548cPRM\u8bc4\u5224\u5668\uff1b3\uff09\u901a\u8fc7NSA\u4f18\u5316\u7b56\u7565\uff0c\u6709\u6548\u6316\u6398\u8d1f\u6837\u672c\u4e2d\u7684\u6b63\u5411\u6b65\u9aa4\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cBCPG-NSA\u5728\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66/\u7f16\u7801\u63a8\u7406\u57fa\u51c6\u4e0a\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u4f7f\u7528\u76f8\u540c\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6837\u672c\u6548\u7387\uff0c\u5e76\u5c55\u793a\u4e86\u6269\u5c55\u5230\u591a\u8f6e\u8fed\u4ee3\u65f6\u7684\u7a33\u5065\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u957f\u94feCoT\u6a21\u578b\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u5145\u5206\u5229\u7528\u56fa\u5b9a\u8bad\u7ec3\u6570\u636e\u96c6\u7684\u4ef7\u503c\uff0c\u540c\u65f6\u6316\u6398\u8d1f\u6837\u672c\u4e2d\u6f5c\u5728\u7684\u5b66\u4e60\u4fe1\u53f7\uff08\u5982\u81ea\u6211\u53cd\u601d\u548c\u9519\u8bef\u7ea0\u6b63\u6b65\u9aa4\uff09\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBCPG-NSA\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u662f\u4e00\u79cd\u7cbe\u7ec6\u7c92\u5ea6\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u4e3b\u8981\u9636\u6bb5\uff1a1\uff09\u6837\u672c\u5206\u5272\uff1b2\uff09\u7ed3\u5408LLM\u548cPRM\u8bc4\u5224\u5668\u8fdb\u884c\u57fa\u4e8e\u5171\u8bc6\u7684\u6b65\u9aa4\u6b63\u786e\u6027\u8bc4\u4f30\uff1b3\uff09\u901a\u8fc7\u8d1f\u6837\u672c\u589e\u5f3a\uff08NSA\uff09\u4f18\u5316\u7b56\u7565\uff0c\u4ee5\u6709\u6548\u6316\u6398\u8d1f\u6837\u672c\u4e2d\u7684\u6b63\u5411\u6b65\u9aa4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cBCPG-NSA\u5728\u591a\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u6570\u5b66/\u7f16\u7801\u63a8\u7406\u57fa\u51c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\uff0c\u5e76\u5728\u591a\u8f6e\u8fed\u4ee3\u4e2d\u8868\u73b0\u51fa\u7a33\u5065\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "BCPG-NSA\u662f\u4e00\u79cd\u6709\u6548\u7684\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u80fd\u591f\u5145\u5206\u6316\u6398\u8d1f\u6837\u672c\u4e2d\u7684\u6f5c\u5728\u4ef7\u503c\uff0c\u63d0\u5347\u957f\u94feCoT\u6a21\u578b\u7684\u6027\u80fd\u3001\u6837\u672c\u6548\u7387\u4ee5\u53ca\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u80fd\u529b\u3002"}}
