<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 4]
- [cs.CV](#cs.CV) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Human-AI Collaboration or Academic Misconduct? Measuring AI Use in Student Writing Through Stylometric Evidence](https://arxiv.org/abs/2505.08828)
*Eduardo Araujo Oliveira,Madhavi Mohoni,Sonsoles López-Pernas,Mohammed Saqr*

Main category: cs.CL

TL;DR: 研究使用作者验证技术量化AI在学术写作中的协助，通过三个阶段的调查，开发并评估了一种改进的特征向量差异AV方法，以支持学术诚信调查。


<details>
  <summary>Details</summary>
Motivation: 随着人-AI合作在教育环境中日益普遍，理解和衡量这种互动的程度和性质面临重大挑战。研究旨在通过作者验证技术量化AI在学术写作中的协助，以促进透明度、可解释性和学生发展。

Method: 研究分为三个阶段：数据集选择和扩展、AV方法开发和系统评估。使用三个数据集，包括公共数据集（PAN-14）和墨尔本大学学生的两个数据集，扩展数据以包括LLM生成的文本，总计1,889篇文档和540个作者问题。开发了一种改进的特征向量差异AV方法，构建学生学术写作的稳健档案，捕捉其写作的有意义的个体特征。

Result: 结果表明，改进的AV分类器能够识别文体差异，并在单词和句子级别衡量人-AI合作，同时为教育工作者提供透明的工具，以支持学术诚信调查。

Conclusion: 这项工作推进了AV技术，为AI驱动时代学术写作的动态提供了可操作的见解。

Abstract: As human-AI collaboration becomes increasingly prevalent in educational
contexts, understanding and measuring the extent and nature of such
interactions pose significant challenges. This research investigates the use of
authorship verification (AV) techniques not as a punitive measure, but as a
means to quantify AI assistance in academic writing, with a focus on promoting
transparency, interpretability, and student development. Building on prior
work, we structured our investigation into three stages: dataset selection and
expansion, AV method development, and systematic evaluation. Using three
datasets - including a public dataset (PAN-14) and two from University of
Melbourne students from various courses - we expanded the data to include
LLM-generated texts, totalling 1,889 documents and 540 authorship problems from
506 students. We developed an adapted Feature Vector Difference AV methodology
to construct robust academic writing profiles for students, designed to capture
meaningful, individual characteristics of their writing. The method's
effectiveness was evaluated across multiple scenarios, including distinguishing
between student-authored and LLM-generated texts and testing resilience against
LLMs' attempts to mimic student writing styles. Results demonstrate the
enhanced AV classifier's ability to identify stylometric discrepancies and
measure human-AI collaboration at word and sentence levels while providing
educators with a transparent tool to support academic integrity investigations.
This work advances AV technology, offering actionable insights into the
dynamics of academic writing in an AI-driven era.

</details>


### [2] [Clicking some of the silly options: Exploring Player Motivation in Static and Dynamic Educational Interactive Narratives](https://arxiv.org/abs/2505.08891)
*Daeun Hwang,Samuel Shields,Alex Calderwood,Shi Johnson-Bey,Michael Mateas,Noah Wardrip-Fruin,Edward F. Melcer*

Main category: cs.CL

TL;DR: 研究AI驱动的动态叙事在教育游戏中的潜力，发现动态叙事对学习者动机有积极影响，但需平衡教学目标与叙事动态性。


<details>
  <summary>Details</summary>
Motivation: 动机是成功学习的重要因素，以往研究证明静态互动叙事游戏对动机有积极影响，AI技术的发展使动态和自适应互动叙事越来越可行，但动态叙事对学习者动机的影响研究有限。

Method: 比较两种版本的教育互动叙事游戏《Academical》，一种是传统的手工编写分支剧情（静态叙事），另一种在游戏过程中动态排序剧情（动态叙事）。

Result: 结果强调了响应性内容和多种选择对玩家参与度的重要性，同时也展示了在平衡教学目标与叙事动态性方面的挑战。

Conclusion: 这项工作为AI驱动的动态叙事在教育游戏中的潜力提供了初步的启示。

Abstract: Motivation is an important factor underlying successful learning. Previous
research has demonstrated the positive effects that static interactive
narrative games can have on motivation. Concurrently, advances in AI have made
dynamic and adaptive approaches to interactive narrative increasingly
accessible. However, limited work has explored the impact that dynamic
narratives can have on learner motivation. In this paper, we compare two
versions of Academical, a choice-based educational interactive narrative game
about research ethics. One version employs a traditional hand-authored
branching plot (i.e., static narrative) while the other dynamically sequences
plots during play (i.e., dynamic narrative). Results highlight the importance
of responsive content and a variety of choices for player engagement, while
also illustrating the challenge of balancing pedagogical goals with the dynamic
aspects of narrative. We also discuss design implications that arise from these
findings. Ultimately, this work provides initial steps to illuminate the
emerging potential of AI-driven dynamic narrative in educational games.

</details>


### [3] [A suite of LMs comprehend puzzle statements as well as humans](https://arxiv.org/abs/2505.08996)
*Adele E Goldberg,Supantho Rakshit,Jennifer Hu,Kyle Mahowald*

Main category: cs.CL

TL;DR: 重新评估了大型语言模型在理解复杂英语语句上的表现，发现人类表现被高估，模型能力被低估。在限制重读的条件下，人类准确率低于某些大型语言模型。研究结果表明，人类和模型在涉及潜在互惠行为的查询上都面临挑战，这表明存在共享的语用敏感性，而非模型特定的缺陷。此外，通过额外分析发现模型性能被系统性低估。这些发现强调了在评估大型语言模型时需要更谨慎的实验设计和编码实践，并挑战了当前模型在语言理解上天生弱于人类的假设。


<details>
  <summary>Details</summary>
Motivation: 重新评估大型语言模型在理解复杂英语语句上的表现，纠正之前研究中可能存在的对人类表现的高估和对模型能力的低估。

Method: 使用相同的刺激材料，进行预注册研究，比较人类在允许重读和限制重读两种条件下的反应，同时对比不同大型语言模型的表现。通过额外分析模型的对数概率、开放性回答的重新编码以及对其他句子的语法性评分，进一步评估模型性能。

Result: 人类在限制重读条件下的准确率（73%）低于Falcon-180B-Chat（76%）和GPT-4（81%），而新的GPT-o1模型达到完美准确率。人类和模型在涉及潜在互惠行为的查询上都面临挑战，表明存在共享的语用敏感性。通过额外分析发现模型性能被系统性低估，GPT-4o可以根据提示框架与新手或专家的语法性判断一致。

Conclusion: 需要更谨慎的实验设计和编码实践来评估大型语言模型，当前模型在语言理解上并不天生弱于人类。

Abstract: Recent claims suggest that large language models (LMs) underperform humans in
comprehending minimally complex English statements (Dentella et al., 2024).
Here, we revisit those findings and argue that human performance was
overestimated, while LLM abilities were underestimated. Using the same stimuli,
we report a preregistered study comparing human responses in two conditions:
one allowed rereading (replicating the original study), and one that restricted
rereading (a more naturalistic comprehension test). Human accuracy dropped
significantly when rereading was restricted (73%), falling below that of
Falcon-180B-Chat (76%) and GPT-4 (81%). The newer GPT-o1 model achieves perfect
accuracy. Results further show that both humans and models are
disproportionately challenged by queries involving potentially reciprocal
actions (e.g., kissing), suggesting shared pragmatic sensitivities rather than
model-specific deficits. Additional analyses using Llama-2-70B log
probabilities, a recoding of open-ended model responses, and grammaticality
ratings of other sentences reveal systematic underestimation of model
performance. We find that GPT-4o can align with either naive or expert
grammaticality judgments, depending on prompt framing. These findings
underscore the need for more careful experimental design and coding practices
in LLM evaluation, and they challenge the assumption that current models are
inherently weaker than humans at language comprehension.

</details>


### [4] [For GPT-4 as with Humans: Information Structure Predicts Acceptability of Long-Distance Dependencies](https://arxiv.org/abs/2505.09005)
*Nicole Cuneo,Eleanor Graves,Supantho Rakshit,Adele E. Goldberg*

Main category: cs.CL

TL;DR: 研究探讨了GPT-4对英语信息结构和长距离依赖结构的判断能力，发现其与人类判断相似，表明自然语言和GPT-4生成英语之间存在紧密联系。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型（LM）对自然语言的理解和生成能力，特别是对英语信息结构和长距离依赖（LDD）结构的判断能力。

Method: 通过实验，让GPT-4完成与人类相同的任务，包括信息结构和接受度任务，并通过操纵信息结构来验证因果关系。

Result: GPT-4在信息结构和接受度任务上表现出可靠的元语言技能，复制了人类的交互效应。操纵信息结构可以增加后续LDD结构的接受度。

Conclusion: GPT-4生成的英语与自然英语之间存在紧密联系，信息结构和句法之间也存在紧密关系，需要进一步探索。

Abstract: It remains debated how well any LM understands natural language or generates
reliable metalinguistic judgments. Moreover, relatively little work has
demonstrated that LMs can represent and respect subtle relationships between
form and function proposed by linguists. We here focus on a particular such
relationship established in recent work: English speakers' judgments about the
information structure of canonical sentences predicts independently collected
acceptability ratings on corresponding 'long distance dependency' [LDD]
constructions, across a wide array of base constructions and multiple types of
LDDs. To determine whether any LM captures this relationship, we probe GPT-4 on
the same tasks used with humans and new extensions.Results reveal reliable
metalinguistic skill on the information structure and acceptability tasks,
replicating a striking interaction between the two, despite the zero-shot,
explicit nature of the tasks, and little to no chance of contamination [Studies
1a, 1b]. Study 2 manipulates the information structure of base sentences and
confirms a causal relationship: increasing the prominence of a constituent in a
context sentence increases the subsequent acceptability ratings on an LDD
construction. The findings suggest a tight relationship between natural and
GPT-4 generated English, and between information structure and syntax, which
begs for further exploration.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [5] [Graph-based Online Monitoring of Train Driver States via Facial and Skeletal Features](https://arxiv.org/abs/2505.08800)
*Olivia Nocentini,Marta Lagomarsino,Gokhan Solak,Younggeol Cho,Qiyi Tong,Marta Lorenzini,Arash Ajoudani*

Main category: cs.CV

TL;DR: 本研究提出了一种基于行为的在线监测系统，使用定制的有向图神经网络（DGNN）对列车司机的状态进行分类，结合面部和骨骼特征的模型在三分类模型中准确率最高（80.88%），在二元警觉性分类中准确率超过99%，并引入了包含模拟病理条件的新数据集，以扩大对疲劳和健康相关风险的评估范围。


<details>
  <summary>Details</summary>
Motivation: 传统的列车司机疲劳监测系统（如死人开关）功能有限，无法有效监测司机的警觉性状态，因此需要一种更先进的在线监测系统来提高铁路安全。

Method: 本研究开发了一种基于行为的在线监测系统，使用定制的有向图神经网络（DGNN）对列车司机的状态进行分类。通过消融研究比较了三种特征配置：仅骨骼、仅面部和两者的组合，以优化模型的输入表示。

Result: 实验结果表明，结合面部和骨骼特征的模型在三分类模型中准确率最高（80.88%），在二元警觉性分类中准确率超过99%。此外，本研究还引入了一个新的数据集，首次将模拟病理条件纳入列车司机监测中，扩大了对疲劳和健康相关风险的评估范围。

Conclusion: 本研究通过使用先进的视觉技术进行在线监测，为提高铁路安全迈出了重要一步。

Abstract: Driver fatigue poses a significant challenge to railway safety, with
traditional systems like the dead-man switch offering limited and basic
alertness checks. This study presents an online behavior-based monitoring
system utilizing a customised Directed-Graph Neural Network (DGNN) to classify
train driver's states into three categories: alert, not alert, and
pathological. To optimize input representations for the model, an ablation
study was performed, comparing three feature configurations: skeletal-only,
facial-only, and a combination of both. Experimental results show that
combining facial and skeletal features yields the highest accuracy (80.88%) in
the three-class model, outperforming models using only facial or skeletal
features. Furthermore, this combination achieves over 99% accuracy in the
binary alertness classification. Additionally, we introduced a novel dataset
that, for the first time, incorporates simulated pathological conditions into
train driver monitoring, broadening the scope for assessing risks related to
fatigue and health. This work represents a step forward in enhancing railway
safety through advanced online monitoring using vision-based technologies.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [6] [Deep reinforcement learning-based longitudinal control strategy for automated vehicles at signalised intersections](https://arxiv.org/abs/2505.08896)
*Pankaj Kumar,Aditya Mishra,Pranamesh Chakraborty,Subrahmanya Swamy Peruru*

Main category: cs.AI

TL;DR: 研究提出了一种基于深度强化学习的信号灯交叉口纵向车辆控制策略，通过综合奖励函数和DRL算法（DDPG和SAC）训练模型，结果表明该策略能提高交通安全性、效率和舒适性。


<details>
  <summary>Details</summary>
Motivation: 开发信号灯交叉口的自动驾驶车辆控制策略是一项挑战，因为其决策过程复杂。该研究旨在提出一种基于深度强化学习的纵向车辆控制策略，以应对这一挑战。

Method: 研究提出了一个综合奖励函数，重点关注距离间隔效率奖励、黄灯决策标准和非对称加减速响应，同时考虑传统安全和舒适性标准。将该奖励函数与两种流行的DRL算法（DDPG和SAC）结合，处理连续的加减速动作空间。使用真实世界前车轨迹和基于Ornstein-Uhlenbeck过程生成的模拟轨迹训练模型。

Result: 通过累积分布函数（CDF）图与真实世界轨迹数据比较，结果表明RL模型成功保持了较低的距离间隔（即更高效率）和抖动，同时不降低安全性。在多种安全关键场景（包括跟车和交通信号遵守）中评估模型的鲁棒性，DDPG和SAC模型均成功处理了这些场景，DDPG模型的动作曲线比SAC模型更平滑。

Conclusion: 总体而言，结果证实基于DRL的信号灯交叉口纵向车辆控制策略有助于提高交通安全、效率和舒适性。

Abstract: Developing an autonomous vehicle control strategy for signalised
intersections (SI) is one of the challenging tasks due to its inherently
complex decision-making process. This study proposes a Deep Reinforcement
Learning (DRL) based longitudinal vehicle control strategy at SI. A
comprehensive reward function has been formulated with a particular focus on
(i) distance headway-based efficiency reward, (ii) decision-making criteria
during amber light, and (iii) asymmetric acceleration/ deceleration response,
along with the traditional safety and comfort criteria. This reward function
has been incorporated with two popular DRL algorithms, Deep Deterministic
Policy Gradient (DDPG) and Soft-Actor Critic (SAC), which can handle the
continuous action space of acceleration/deceleration. The proposed models have
been trained on the combination of real-world leader vehicle (LV) trajectories
and simulated trajectories generated using the Ornstein-Uhlenbeck (OU) process.
The overall performance of the proposed models has been tested using Cumulative
Distribution Function (CDF) plots and compared with the real-world trajectory
data. The results show that the RL models successfully maintain lower distance
headway (i.e., higher efficiency) and jerk compared to human-driven vehicles
without compromising safety. Further, to assess the robustness of the proposed
models, we evaluated the model performance on diverse safety-critical
scenarios, in terms of car-following and traffic signal compliance. Both DDPG
and SAC models successfully handled the critical scenarios, while the DDPG
model showed smoother action profiles compared to the SAC model. Overall, the
results confirm that DRL-based longitudinal vehicle control strategy at SI can
help to improve traffic safety, efficiency, and comfort.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [7] [A Preliminary Framework for Intersectionality in ML Pipelines](https://arxiv.org/abs/2505.08792)
*Michelle Nashla Turcios,Alicia E. Boyd,Angela D. R. Smith,Brittany Johnson*

Main category: cs.LG

TL;DR: Intersectionality framework can support the development of technologies that acknowledge and support all members of society, but it has been adopted and adapted in ways that are not always true to its foundations, thereby weakening its potential for impact.


<details>
  <summary>Details</summary>
Motivation: Machine learning technologies may not provide adequate support for societal identities and experiences.

Method: Amplify the foundational intersectionality scholarship to create a socially relevant preliminary framework in developing machine-learning solutions.

Result: Evaluate and report on the (mis)alignments of intersectionality application in machine learning literature.

Conclusion: Intersectionality framework can support the development of technologies that acknowledge and support all members of society.

Abstract: Machine learning (ML) has become a go-to solution for improving how we use,
experience, and interact with technology (and the world around us).
Unfortunately, studies have repeatedly shown that machine learning technologies
may not provide adequate support for societal identities and experiences.
Intersectionality is a sociological framework that provides a mechanism for
explicitly considering complex social identities, focusing on social justice
and power. While the framework of intersectionality can support the development
of technologies that acknowledge and support all members of society, it has
been adopted and adapted in ways that are not always true to its foundations,
thereby weakening its potential for impact. To support the appropriate adoption
and use of intersectionality for more equitable technological outcomes, we
amplify the foundational intersectionality scholarship--Crenshaw, Combahee, and
Collins (three C's), to create a socially relevant preliminary framework in
developing machine-learning solutions. We use this framework to evaluate and
report on the (mis)alignments of intersectionality application in machine
learning literature.

</details>
