<div id=toc></div>

# 目录

- [cs.LG](#cs.LG) [总数: 103]
- [cs.AI](#cs.AI) [总数: 23]
- [stat.ML](#stat.ML) [总数: 9]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Developing a Dyslexia Indicator Using Eye Tracking](https://arxiv.org/abs/2506.11004)
*Kevin Cogan, Vuong M. Ngo, Mark Roantree*

**主要类别:** cs.LG

**AI概要:** 本文研究了眼动追踪技术与机器学习算法结合在早期读写障碍检测中的有效性，通过分析眼动模式并使用随机森林分类器达到了88.58%的准确率，并利用层次聚类方法识别不同严重程度的读写障碍。


<details>
  <summary>更多</summary>
  
**动机:** 鉴于读写障碍影响全球约10%至20%的人口，严重影响了学习能力，亟需创新且易于获取的诊断方法。

**方法:** 采用眼动追踪技术分析一般的眼动模式（如延长的注视时间和不规则扫视），提出了一种改进的基于眼动追踪的读写障碍特征确定方案，并应用随机森林分类器来检测读写障碍；同时，使用层次聚类方法识别读写障碍的不同严重程度。

**结果:** 随机森林分类器在检测读写障碍方面取得了88.58%的准确率，并且层次聚类方法成功用于识别读写障碍的不同严重程度。

**结论:** 眼动追踪与机器学习相结合为读写障碍的诊断提供了一个高度准确和可访问的方法，在临床研究中展示了其潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Developing+a+Dyslexia+Indicator+Using+Eye+Tracking，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11004，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11004&send_immediately=true&force_search=false)

**原文摘要:** Dyslexia, affecting an estimated 10% to 20% of the global population,
significantly impairs learning capabilities, highlighting the need for
innovative and accessible diagnostic methods. This paper investigates the
effectiveness of eye-tracking technology combined with machine learning
algorithms as a cost-effective alternative for early dyslexia detection. By
analyzing general eye movement patterns, including prolonged fixation durations
and erratic saccades, we proposed an enhanced solution for determining
eye-tracking-based dyslexia features. A Random Forest Classifier was then
employed to detect dyslexia, achieving an accuracy of 88.58\%. Additionally,
hierarchical clustering methods were applied to identify varying severity
levels of dyslexia. The analysis incorporates diverse methodologies across
various populations and settings, demonstrating the potential of this
technology to identify individuals with dyslexia, including those with
borderline traits, through non-invasive means. Integrating eye-tracking with
machine learning represents a significant advancement in the diagnostic
process, offering a highly accurate and accessible method in clinical research.

</details>


### [2] [Data Science: a Natural Ecosystem](https://arxiv.org/abs/2506.11010)
*Emilio Porcu, Roy El Moukari, Laurent Najman, Francisco Herrera, Horst Simon*

**主要类别:** cs.LG

**AI概要:** 本文提出了一个全面的数据科学视角，定义了数据科学的核心组成部分和特定学科引发的数据科学，并指出了计算数据科学与基础数据科学之间存在分歧的威胁。


<details>
  <summary>更多</summary>
  
**动机:** 作者旨在提供一个整体的数据科学视角，将其视为一个自然生态系统，其中挑战和任务源自于数据宇宙中5D复杂性的多种组合（数据结构、领域、基数、因果关系和伦理）以及数据生命周期的不同阶段。

**方法:** 文章通过语义上将核心数据科学分为计算型和基础型来探讨数据科学的本质。

**结果:** 文中提出了一种严格的方法来衡量数据宇宙发现是否有用，以缓解计算数据科学与基础数据科学之间的分歧。

**结论:** 如果不对数据宇宙中的发现是否应有用进行评级，那么计算数据科学与基础数据科学之间存在严重的分歧威胁。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data+Science%3A+a+Natural+Ecosystem，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11010，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11010&send_immediately=true&force_search=false)

**原文摘要:** This manuscript provides a holistic (data-centric) view of what we term
essential data science, as a natural ecosystem with challenges and missions
stemming from the data universe with its multiple combinations of the 5D
complexities (data structure, domain, cardinality, causality, and ethics) with
the phases of the data life cycle. Data agents perform tasks driven by specific
goals. The data scientist is an abstract entity that comes from the logical
organization of data agents with their actions. Data scientists face challenges
that are defined according to the missions. We define specific
discipline-induced data science, which in turn allows for the definition of
pan-data science, a natural ecosystem that integrates specific disciplines with
the essential data science. We semantically split the essential data science
into computational, and foundational. We claim that there is a serious threat
of divergence between computational and foundational data science. Especially,
if no approach is taken to rate whether a data universe discovery should be
useful or not. We suggest that rigorous approaches to measure the usefulness of
data universe discoveries might mitigate such a divergence.

</details>


### [3] [Not All Clients Are Equal: Personalized Federated Learning on Heterogeneous Multi-Modal Clients](https://arxiv.org/abs/2506.11024)
*Minhyuk Seo, Taeheon Kim, Hankook Lee, Jonghyun Choi, Tinne Tuytelaars*

**主要类别:** cs.LG

**AI概要:** 本文提出了一个任务相似性感知的模型聚合方法和一个维度不变模块，以解决联邦学习中的数据异质性和模型异质性问题。实验表明，该方法在个性化和泛化能力方面优于现有技术。


<details>
  <summary>更多</summary>
  
**动机:** 基础模型在多模态任务中表现出色，但集中训练引发了隐私问题并导致高传输成本。而联邦学习提供了一个无需共享数据的分布式替代方案。为了满足个性化AI模型的需求，出现了个性化的联邦学习（PFL）。尽管有潜力，大多数PFL研究仍局限于模拟环境，忽视了现实世界中出现的数据和模型异质性。

**方法:** 为了解决数据异质性，提出了一种任务相似性感知的模型聚合方法，为每个客户端提供定制化的全局模型；对于模型异质性，则设计了一个维度不变模块，支持异构模型之间的知识分享。

**结果:** 实证验证表明，所提出的方法在个性化和泛化能力上都超越了当前最先进的技术。

**结论:** 通过引入任务相似性感知的模型聚合方法和维度不变模块，研究解决了多模态PFL中的数据和模型异质性问题，并在新的基准测试中取得了卓越的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Not+All+Clients+Are+Equal%3A+Personalized+Federated+Learning+on+Heterogeneous+Multi-Modal+Clients，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11024，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11024&send_immediately=true&force_search=false)

**原文摘要:** Foundation models have shown remarkable capabilities across diverse
multi-modal tasks, but their centralized training raises privacy concerns and
induces high transmission costs. In contrast, federated learning (FL) offers a
distributed alternative without the need to share data. Recently, for the
growing demand for personalizing AI models for different user purposes,
personalized federated learning (PFL) has emerged. PFL allows each client to
leverage the knowledge of other clients for further adaptation to individual
user preferences, again without the need to share data. Despite its potential,
most PFL studies remain confined to simulated environments, overlooking the
data and model heterogeneity that arise in real-world scenarios. In contrast,
we first consider large data heterogeneity, evaluating on a new benchmark for
multi-modal PFL, spanning 40 distinct tasks with realistic data distribution
shifts. We then consider model heterogeneity in that we do not assume that all
clients share similar model architectures. To address data heterogeneity, we
propose a task-similarity-aware model aggregation method that provides
customized global models to each client. For model heterogeneity, we propose a
dimension-invariant module that enables knowledge sharing across heterogeneous
models. Empirical validations demonstrate that the proposed approach
outperforms the state-of-the-art, excelling in both personalization and
generalization capabilities.

</details>


### [4] [When Algorithms Play Favorites: Lookism in the Generation and Perception of Faces](https://arxiv.org/abs/2506.11025)
*Miriam Doh, Aditya Gulati, Matei Mancas, Nuria Oliver*

**主要类别:** cs.LG

**AI概要:** 论文研究了合成生成的面孔和基于机器学习的性别分类算法如何受到外貌偏好的影响，发现文本到图像系统倾向于将面部吸引力与智力和可信度等无关的积极特质联系起来，并且性别分类模型在'较不吸引人'的面孔上表现出更高的错误率，特别是在非白人女性中。这些结果引发了关于数字身份系统的公平性问题。


<details>
  <summary>更多</summary>
  
**动机:** 研究旨在探讨合成面孔生成以及基于机器学习的性别识别算法是否受到外观主义（即基于外貌的偏好待遇）的影响。

**方法:** 通过实验分析13,200个合成生成的人脸图片，评估文本到图像(T2I)系统对于脸部特征的关联性和性别分类模型对于不同面貌吸引力水平的人脸识别准确度。

**结果:** 发现T2I系统会将面部吸引力与智力、可信赖度等正面特质相关联；性别分类器对于被认为‘不够吸引人’的脸孔具有更高误判率，尤其针对非白人女性群体时更为明显。

**结论:** 研究结果揭示了现有技术中存在的潜在偏见问题，特别是对于数字身份验证系统而言，这可能引发一系列公平性考量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是When+Algorithms+Play+Favorites%3A+Lookism+in+the+Generation+and+Perception+of+Faces，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11025，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11025&send_immediately=true&force_search=false)

**原文摘要:** This paper examines how synthetically generated faces and machine
learning-based gender classification algorithms are affected by algorithmic
lookism, the preferential treatment based on appearance. In experiments with
13,200 synthetically generated faces, we find that: (1) text-to-image (T2I)
systems tend to associate facial attractiveness to unrelated positive traits
like intelligence and trustworthiness; and (2) gender classification models
exhibit higher error rates on "less-attractive" faces, especially among
non-White women. These result raise fairness concerns regarding digital
identity systems.

</details>


### [5] [Evaluating Privacy-Utility Tradeoffs in Synthetic Smart Grid Data](https://arxiv.org/abs/2506.11026)
*Andre Catarino, Rui Melo, Rui Abreu, Luis Cruz*

**主要类别:** cs.LG

**AI概要:** 本研究比较了四种合成数据生成方法在不同合成机制下的表现，评估了分类实用性、分布保真度和隐私泄露情况。结果表明，扩散模型实现了最高的实用性，而CTGAN对重建攻击的抵抗力最强。


<details>
  <summary>更多</summary>
  
**动机:** 动态分时电价(dToU)的广泛采用需要准确识别能从中受益的家庭。然而，使用实际消费数据会引起严重的隐私问题，因此促使采用合成替代方案。

**方法:** 本研究采用了四种合成数据生成方法：Wasserstein-GP生成对抗网络(WGAN)、条件表格GAN(CTGAN)、扩散模型以及高斯噪声增强，并在不同的合成机制下进行了对比评估。

**结果:** 研究表明架构设计起着关键作用：扩散模型达到了最高的实用性（宏观F1高达88.2%），而CTGAN提供了对重建攻击最强的抵抗能力。

**结论:** 这些发现强调了结构化生成模型在开发保护隐私的数据驱动能源系统方面的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Evaluating+Privacy-Utility+Tradeoffs+in+Synthetic+Smart+Grid+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11026，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11026&send_immediately=true&force_search=false)

**原文摘要:** The widespread adoption of dynamic Time-of-Use (dToU) electricity tariffs
requires accurately identifying households that would benefit from such pricing
structures. However, the use of real consumption data poses serious privacy
concerns, motivating the adoption of synthetic alternatives. In this study, we
conduct a comparative evaluation of four synthetic data generation methods,
Wasserstein-GP Generative Adversarial Networks (WGAN), Conditional Tabular GAN
(CTGAN), Diffusion Models, and Gaussian noise augmentation, under different
synthetic regimes. We assess classification utility, distribution fidelity, and
privacy leakage. Our results show that architectural design plays a key role:
diffusion models achieve the highest utility (macro-F1 up to 88.2%), while
CTGAN provide the strongest resistance to reconstruction attacks. These
findings highlight the potential of structured generative models for developing
privacy-preserving, data-driven energy systems.

</details>


### [6] [From Reasoning to Code: GRPO Optimization for Underrepresented Languages](https://arxiv.org/abs/2506.11027)
*Federico Pennino, Bianca Raimondi, Massimo Rondelli, Andrea Gurioli, Maurizio Gabbrielli*

**主要类别:** cs.LG

**AI概要:** 论文提出了一种通用方法，利用Qwen 2.5模型的小规模代码版本与组相对策略优化（GRPO）相结合，通过明确的推理步骤实现有效的代码生成，特别是对于源代码数据库较小的语言。实验评估表明，在数学逻辑问题基准测试中，该方法在推理质量、代码准确性和逻辑正确性方面有显著提升。


<details>
  <summary>更多</summary>
  
**动机:** 针对那些与Python等流行语言相比公开训练数据较少的编程语言，使用大型语言模型生成精确且可执行的代码是一项挑战。特别是像Prolog这样在线资源有限的语言，其代码生成尤为困难。

**方法:** 采用小规模的Qwen 2.5模型代码版本，并结合组相对策略优化（GRPO），通过直接将基于推理的反馈整合到强化学习循环中来改进代码生成过程。

**结果:** 经过一定步骤的训练后，模型能够生成逻辑一致且语法正确的代码。实验结果表明，这种方法在解决数学逻辑问题时提升了推理的质量、代码准确性以及逻辑正确性。

**结论:** 研究展示了一种新的方法，它可以通过显式的推理步骤有效地为缺乏大量训练资源的编程语言生成代码。这种途径显示了对多种编程语言潜在的好处。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+Reasoning+to+Code%3A+GRPO+Optimization+for+Underrepresented+Languages，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11027，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11027&send_immediately=true&force_search=false)

**原文摘要:** Generating accurate and executable code using large language models (LLMs) is
challenging for languages with limited public training data compared to popular
languages such as Python. This paper introduces a generalizable approach that
uses small-scale code versions of the Qwen 2.5 model combined with Group
Relative Policy Optimization (GRPO) to enable effective code generation through
explicit reasoning steps, which is particularly beneficial for languages with
smaller source code databases. Using Prolog as a representative use case --
given its limited online presence -- the initial model faced challenges in
generating executable code. After some training steps, the model successfully
produces logically consistent and syntactically accurate code by directly
integrating reasoning-driven feedback into the reinforcement learning loop.
Experimental evaluations using mathematical logic problem benchmarks illustrate
significant improvements in reasoning quality, code accuracy, and logical
correctness, underscoring the potential of this approach to benefit a wide
range of programming languages lacking extensive training resources.

</details>


### [7] [Enhancing Epidemic Forecasting: Evaluating the Role of Mobility Data and Graph Convolutional Networks](https://arxiv.org/abs/2506.11028)
*Suhan Guo, Zhenghao Xu, Furao Shen, Jian Zhao*

**主要类别:** cs.LG

**AI概要:** 研究通过两阶段方法探讨了移动性数据和图卷积网络(GCN)在传染病预测模型中的作用，发现虽然这些技术对提高预测性能没有显著贡献，但纳入死亡率和住院数据可以明显改善模型准确性。此外，GCN生成的空间图与封锁令之间存在显著相关性，表明空间图可能是移动性的敏感指标。


<details>
  <summary>更多</summary>
  
**动机:** 准确预测传染病爆发对于决策至关重要。研究旨在解决机器学习算法与其流行病学应用之间的差距，尤其是针对现实世界数据时最佳方法往往表现不佳的问题。

**方法:** 采用了两阶段方法：首先通过试点研究评估移动性数据的重要性，然后评估图卷积网络（GCNs）对接种变压器骨干的影响。

**结果:** 结果显示，尽管移动性数据和GCN模块对提升预测性能帮助不大，但加入死亡率及住院化数据能显著提高模型准确性；另外，GCN产生的空间地图与封锁命令间显示出值得注意的相关性。

**结论:** 本研究为传染性疾病预测建模中的流动性表示提供了一个新的视角，并有助于决策者更好地准备应对未来疫情。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhancing+Epidemic+Forecasting%3A+Evaluating+the+Role+of+Mobility+Data+and+Graph+Convolutional+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11028，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11028&send_immediately=true&force_search=false)

**原文摘要:** Accurate prediction of contagious disease outbreaks is vital for informed
decision-making. Our study addresses the gap between machine learning
algorithms and their epidemiological applications, noting that methods optimal
for benchmark datasets often underperform with real-world data due to
difficulties in incorporating mobility information. We adopt a two-phase
approach: first, assessing the significance of mobility data through a pilot
study, then evaluating the impact of Graph Convolutional Networks (GCNs) on a
transformer backbone. Our findings reveal that while mobility data and GCN
modules do not significantly enhance forecasting performance, the inclusion of
mortality and hospitalization data markedly improves model accuracy.
Additionally, a comparative analysis between GCN-derived spatial maps and
lockdown orders suggests a notable correlation, highlighting the potential of
spatial maps as sensitive indicators for mobility. Our research offers a novel
perspective on mobility representation in predictive modeling for contagious
diseases, empowering decision-makers to better prepare for future outbreaks.

</details>


### [8] [Generalization Bound of Gradient Flow through Training Trajectory and Data-dependent Kernel](https://arxiv.org/abs/2506.11357)
*Yilan Chen, Zhichao Wang, Wei Huang, Andi Han, Taiji Suzuki, Arya Mazumdar*

**主要类别:** cs.LG

**AI概要:** 本文提出了一个基于损失路径核（LPK）的梯度流泛化界，该界与基于RKHS范数和核迹的经典Rademacher复杂度界一致，并且能够捕捉整个训练轨迹，适应数据和优化动态。此边界揭示了训练过程中损失梯度的范数如何影响最终的泛化性能，并通过实验证明了理论边界与实际泛化差距的良好相关性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管基于梯度的优化方法在实践中表现出色，但其理论上的泛化特性仍未被完全理解。文章旨在建立一个更紧密、更具信息性的泛化界限，以更好地解释这些方法的表现。

**方法:** 研究者们引入了一个依赖于数据的核函数——损失路径核（LPK），并结合梯度流稳定性分析以及Rademacher复杂度的一致收敛来证明泛化界。这个新的泛化界不仅适用于过参数化的神经网络，也展现了神经网络相比核方法的特征学习能力。

**结果:** 所提出的泛化界能够恢复已有针对过参数化神经网络的核回归界限，并且数值实验表明，新提出的界限与真实泛化误差有良好的对应关系。

**结论:** 通过使用损失路径核，研究提供了对于梯度下降法泛化性质的新见解，并且证实了这一新泛化界对实际模型泛化行为的预测能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generalization+Bound+of+Gradient+Flow+through+Training+Trajectory+and+Data-dependent+Kernel，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11357，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11357&send_immediately=true&force_search=false)

**原文摘要:** Gradient-based optimization methods have shown remarkable empirical success,
yet their theoretical generalization properties remain only partially
understood. In this paper, we establish a generalization bound for gradient
flow that aligns with the classical Rademacher complexity bounds for kernel
methods-specifically those based on the RKHS norm and kernel trace-through a
data-dependent kernel called the loss path kernel (LPK). Unlike static kernels
such as NTK, the LPK captures the entire training trajectory, adapting to both
data and optimization dynamics, leading to tighter and more informative
generalization guarantees. Moreover, the bound highlights how the norm of the
training loss gradients along the optimization trajectory influences the final
generalization performance. The key technical ingredients in our proof combine
stability analysis of gradient flow with uniform convergence via Rademacher
complexity. Our bound recovers existing kernel regression bounds for
overparameterized neural networks and shows the feature learning capability of
neural networks compared to kernel methods. Numerical experiments on real-world
datasets validate that our bounds correlate well with the true generalization
gap.

</details>


### [9] [Output Scaling: YingLong-Delayed Chain of Thought in a Large Pretrained Time Series Forecasting Model](https://arxiv.org/abs/2506.11029)
*Xue Wang, Tian Zhou, Jinyang Gao, Bolin Ding, Jingren Zhou*

**主要类别:** cs.LG

**AI概要:** 提出了一种基于非因果双向注意力编码器的联合预测框架YingLong，用于时间序列预测。模型通过掩码标记恢复训练，并采用多输入集成方法来处理输出方差。该模型在ETT和Weather数据集上表现出色，在GIFT-Eval基准测试中也显著优于其他最佳的时间序列基础模型。


<details>
  <summary>更多</summary>
  
**动机:** 为了提高时间序列预测的准确性，研究者开发了一种新的联合预测框架，与传统的直接或递归方法不同，它利用了长输出带来的延迟思维链推理的优势。

**方法:** YingLong是一个非因果、双向注意力仅编码器的transformer，通过掩码标记恢复的方式进行训练。研究人员还使用多输入集成方法来应对输出方差的问题。

**结果:** YingLong模型在零样本任务中的表现优于其他模型，尤其是在ETT和Weather数据集上。根据GIFT-Eval基准测试结果，该模型比最佳的时间序列基础模型和端到端训练模型分别高出14%和44%的成绩。

**结论:** YingLong联合预测框架提供了一种有效的时间序列预测方法，其性能超过了现有技术，并且具有很好的泛化能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Output+Scaling%3A+YingLong-Delayed+Chain+of+Thought+in+a+Large+Pretrained+Time+Series+Forecasting+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11029，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11029&send_immediately=true&force_search=false)

**原文摘要:** We present a joint forecasting framework for time series prediction that
contrasts with traditional direct or recursive methods. This framework achieves
state-of-the-art performance for our designed foundation model, YingLong, and
reveals a novel scaling effect: longer outputs significantly enhance model
accuracy due to delayed chain-of-thought reasoning in our non-causal approach.
YingLong is a non-causal, bidirectional attention encoder-only transformer
trained through masked token recovery, aligning more effectively with language
understanding tasks than with generation tasks. Additionally, we boost
performance by tackling output variance with a multi-input ensemble. We release
four foundation models ranging from 6M to 300M parameters, demonstrating
superior results in zero-shot tasks on the ETT and Weather datasets. YingLong
achieves more than 60% best performance. To ensure generalizability, we
assessed the models using the GIFT-Eval benchmark, which comprises 23 time
series datasets across 7 domains. Yinglong significantly outperformed the best
time-series foundation models, end-to-end trained models by 14% and 44% in rank
respectively.The pretrained 300M model is available at
https://huggingface.co/qcw1314/YingLong_300m

</details>


### [10] [Taxonomy of reduction matrices for Graph Coarsening](https://arxiv.org/abs/2506.11743)
*Antonin Joly, Nicolas Keriven, Aline Roumy*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种更为通用的图约简矩阵概念，指出约简矩阵和提升矩阵在图粗化过程中并不完全对称，并且通过修改约简矩阵可以进一步降低受限谱近似（RSA），同时探讨了不同类型的可接受约简矩阵家族及其性质。


<details>
  <summary>更多</summary>
  
**动机:** 本文动机在于改善现有的图粗化框架，这些框架通常要求约简矩阵与提升矩阵之间存在固定关系，通常是彼此的伪逆。作者观察到这两个矩阵的角色并不是完全对称的，因此提出了一个更一般的约简矩阵定义，以期在保持图的关键属性的同时最小化信息损失即RSA。

**方法:** 文章首先分析了约简矩阵和提升矩阵的作用，并指出了仅约束提升矩阵的重要性。接着，文中引入了一个更普遍的约简矩阵概念，并不是提升矩阵的伪逆。然后建立了一系列‘可接受’的约简矩阵家族分类，并讨论了它们必须满足的不同属性以及是否存在封闭形式的描述。最后，通过调整约简矩阵来探索如何减少给定粗化表示下的RSA。

**结果:** 研究表明，对于由固定的提升矩阵所代表的固定粗化，可以通过简单地修改约简矩阵来进一步减小RSA。此外，文章还提供了基于RSA优化过程的例子，并且展示了选择不同的约简矩阵对于图形神经网络性能的影响。

**结论:** 研究结论表明，通过放宽约简矩阵与提升矩阵之间的传统关系，可以发现新的方法来进一步减少RSA。这不仅有助于减轻图的内存负担，而且可能提高诸如图神经网络等应用的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Taxonomy+of+reduction+matrices+for+Graph+Coarsening，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11743，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11743&send_immediately=true&force_search=false)

**原文摘要:** Graph coarsening aims to diminish the size of a graph to lighten its memory
footprint, and has numerous applications in graph signal processing and machine
learning. It is usually defined using a reduction matrix and a lifting matrix,
which, respectively, allows to project a graph signal from the original graph
to the coarsened one and back. This results in a loss of information measured
by the so-called Restricted Spectral Approximation (RSA). Most coarsening
frameworks impose a fixed relationship between the reduction and lifting
matrices, generally as pseudo-inverses of each other, and seek to define a
coarsening that minimizes the RSA. In this paper, we remark that the roles of
these two matrices are not entirely symmetric: indeed, putting constraints on
the lifting matrix alone ensures the existence of important objects such as the
coarsened graph's adjacency matrix or Laplacian. In light of this, in this
paper, we introduce a more general notion of reduction matrix, that is not
necessarily the pseudo-inverse of the lifting matrix. We establish a taxonomy
of ``admissible'' families of reduction matrices, discuss the different
properties that they must satisfy and whether they admit a closed-form
description or not. We show that, for a fixed coarsening represented by a fixed
lifting matrix, the RSA can be further reduced simply by modifying the
reduction matrix. We explore different examples, including some based on a
constrained optimization process of the RSA. Since this criterion has also been
linked to the performance of Graph Neural Networks, we also illustrate the
impact of this choices on different node classification tasks on coarsened
graphs.

</details>


### [11] [Forward Target Propagation: A Forward-Only Approach to Global Error Credit Assignment via Local Losses](https://arxiv.org/abs/2506.11030)
*Nazmus Saadat As-Saquib, A N M Nafiz Abeer, Hung-Ta Chien, Byung-Jun Yoon, Suhas Kumar, Su-in Yi*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的神经网络训练方法——前向目标传播(FTP)，该方法以二次前向传递代替了反向传播，从而解决了传统BP算法在生物和硬件层面的局限性。实验表明，FTP在不同类型的网络上都达到了与BP相竞争的准确率，并且在低精度量化和新兴硬件限制下表现更优，同时具有更高的效率。


<details>
  <summary>更多</summary>
  
**动机:** 传统的基于梯度的反向传播算法（BP）虽然取得了广泛的成功，但在生物学合理性和硬件实现方面存在重要局限，如对称权重的误差反向传播、非局部信用分配以及反向传递期间活动冻结等问题。

**方法:** 提出了前向目标传播(FTP)作为一种生物合理且计算高效的替代方案，它通过第二次前向传递来取代反向传递。FTP仅使用前馈计算来估计层目标，不需要对称反馈权重或可学习逆函数，因此支持模块化和局部学习。

**结果:** 研究者们在全连接网络、卷积神经网络(CNNs)及循环神经网络(RNNs)上评估了FTP，在MNIST、CIFAR10、CIFAR100数据集上FTP展现出了与BP相当的准确度，并且在处理序列任务中的长期依赖关系时也十分有效。此外，相较于BP和其他受生物启发的方法，FTP在低精度量化和新硬件约束条件下表现更佳，同时展现出显著的效率提升。

**结论:** FTP以其最小的计算开销、纯前向特性以及与硬件的良好兼容性，为节能型设备学习和神经形态计算提供了一个有前景的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Forward+Target+Propagation%3A+A+Forward-Only+Approach+to+Global+Error+Credit+Assignment+via+Local+Losses，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11030，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11030&send_immediately=true&force_search=false)

**原文摘要:** Training neural networks has traditionally relied on backpropagation (BP), a
gradient-based algorithm that, despite its widespread success, suffers from key
limitations in both biological and hardware perspectives. These include
backward error propagation by symmetric weights, non-local credit assignment,
and frozen activity during backward passes. We propose Forward Target
Propagation (FTP), a biologically plausible and computationally efficient
alternative that replaces the backward pass with a second forward pass. FTP
estimates layerwise targets using only feedforward computations, eliminating
the need for symmetric feedback weights or learnable inverse functions, hence
enabling modular and local learning. We evaluate FTP on fully connected
networks, CNNs, and RNNs, demonstrating accuracies competitive with BP on
MNIST, CIFAR10, and CIFAR100, as well as effective modeling of long-term
dependencies in sequential tasks. Moreover, FTP outperforms BP under quantized
low-precision and emerging hardware constraints while also demonstrating
substantial efficiency gains over other biologically inspired methods such as
target propagation variants and forward-only learning algorithms. With its
minimal computational overhead, forward-only nature, and hardware
compatibility, FTP provides a promising direction for energy-efficient
on-device learning and neuromorphic computing.

</details>


### [12] [In Defense of Defensive Forecasting](https://arxiv.org/abs/2506.11848)
*Juan Carlos Perdomo, Benjamin Recht*

**主要类别:** cs.LG

**AI概要:** 本教程综述了防御性预测的算法，该方法通过纠正过去的错误而不是预知未来来进行预测。介绍了Vovk开创的防御性预测的基本理论，并为在线学习、校准、专家建议预测和在线一致性预测导出了简单且接近最优的算法。


<details>
  <summary>更多</summary>
  
**动机:** 探讨一种通过纠正过去的错误而非预知未来来进行预测的方法，这种方法由Vovk提出，并将其应用于一系列预测问题中。

**方法:** 使用防御性预测框架，将预测目标视为一个连续游戏，并开发出即使在任何结果下也能最小化指标的预测方法。

**结果:** 提供了一个关于防御性预测通用理论的基础介绍，并针对在线学习、校准、基于专家建议的预测以及在线一致性预测等问题推导出了简单而近乎最优的算法。

**结论:** 防御性预测提供了一种新的预测视角，即通过修正历史错误来优化预测过程，这种方法可以产生对于多种预测任务有效的算法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是In+Defense+of+Defensive+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11848，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11848&send_immediately=true&force_search=false)

**原文摘要:** This tutorial provides a survey of algorithms for Defensive Forecasting,
where predictions are derived not by prognostication but by correcting past
mistakes. Pioneered by Vovk, Defensive Forecasting frames the goal of
prediction as a sequential game, and derives predictions to minimize metrics no
matter what outcomes occur. We present an elementary introduction to this
general theory and derive simple, near-optimal algorithms for online learning,
calibration, prediction with expert advice, and online conformal prediction.

</details>


### [13] [Task-aligned prompting improves zero-shot detection of AI-generated images by Vision-Language Models](https://arxiv.org/abs/2506.11031)
*Zoher Kachwala, Danishjeet Singh, Danielle Yang, Filippo Menczer*

**主要类别:** cs.LG

**AI概要:** 本研究探索了预训练的视觉-语言模型（VLMs）在零样本检测AI生成图像方面的应用。通过使用任务对齐提示，尤其是以'让我们检查风格和合成伪影'作为前缀的方法（称为zero-shot-s^2），可以显著提高宏F1分数，并且无需微调。该方法在多个开源模型和数据集上表现出良好的泛化能力，同时在不同模型尺寸上也保持了鲁棒性。此外，研究还发现自一致性行为在这种设置中同样有效，而且在大多数情况下zero-shot-s^2比链式思维更具优势。


<details>
  <summary>更多</summary>
  
**动机:** 随着图像生成器产生越来越逼真的图像，对其潜在误用的担忧也在增加。监督检测依赖于大型策划的数据集，并难以跨多种生成器进行泛化。因此，需要一种简单、可泛化且可解释的方法来检测AI生成的图像。

**方法:** 研究人员使用预训练的视觉-语言模型(VLMs)进行了零样本检测实验。他们采用了任务对齐提示策略，特别是提出了一个名为zero-shot-s^2的新方法，即在模型响应前加上'让我们检查风格和合成伪影'这一短语。这种方法被用来评估两个广泛使用的开源模型以及三个最近的不同数据集上的性能。

**结果:** zero-shot-s^2方法提高了宏F1分数达8%-29%，并且在不同的数据集和模型组合中表现出了很好的泛化能力和鲁棒性。自一致性行为在图像检测任务中也是有效的，而且zero-shot-s^2通常比链式思维提示方法表现更好。

**结论:** 任务对齐提示能够激发更集中的推理过程，并增强VLMs在检测AI生成图像方面的潜在能力。Zero-shot-s^2提供了一种简单、泛化性强且易于解释的方法，相较于监督学习方法是一个有吸引力的选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Task-aligned+prompting+improves+zero-shot+detection+of+AI-generated+images+by+Vision-Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11031，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11031&send_immediately=true&force_search=false)

**原文摘要:** As image generators produce increasingly realistic images, concerns about
potential misuse continue to grow. Supervised detection relies on large,
curated datasets and struggles to generalize across diverse generators. In this
work, we investigate the use of pre-trained Vision-Language Models (VLMs) for
zero-shot detection of AI-generated images. While off-the-shelf VLMs exhibit
some task-specific reasoning and chain-of-thought prompting offers gains, we
show that task-aligned prompting elicits more focused reasoning and
significantly improves performance without fine-tuning. Specifically, prefixing
the model's response with the phrase "Let's examine the style and the synthesis
artifacts" -- a method we call zero-shot-s$^2$ -- boosts Macro F1 scores by
8%-29%. These gains are consistent for two widely used open-source models and
across three recent, diverse datasets spanning human faces, objects, and
animals with images generated by 16 different models -- demonstrating strong
generalization. We further evaluate the approach across three additional model
sizes and observe improvements in most dataset-model combinations -- suggesting
robustness to model scale. Surprisingly, self-consistency, a behavior
previously observed in language reasoning, where aggregating answers from
diverse reasoning paths improves performance, also holds in this setting. Even
here, zero-shot-s$^2$ scales better than chain-of-thought in most cases --
indicating that it elicits more useful diversity. Our findings show that
task-aligned prompts elicit more focused reasoning and enhance latent
capabilities in VLMs, like the detection of AI-generated images -- offering a
simple, generalizable, and explainable alternative to supervised methods. Our
code is publicly available on github: https://github.com/Zoher15/Zero-shot-s2.

</details>


### [14] [Scalable Generalized Bayesian Online Neural Network Training for Sequential Decision Making](https://arxiv.org/abs/2506.11898)
*Gerardo Duran-Martin, Leandro Sánchez-Betancourt, Álvaro Cartea, Kevin Murphy*

**主要类别:** cs.LG

**AI概要:** 本文介绍了用于在线学习和神经网络参数广义贝叶斯推理的可扩展算法，结合了频率论和贝叶斯过滤的优点，实现了快速低秩更新，并且定义了一个明确的后验预测分布用于决策。该方法无需重放缓冲区或离线重新训练，实验表明在非平稳上下文强盗问题和贝叶斯优化问题上，这些方法在速度和准确性之间取得了具有竞争力的平衡。


<details>
  <summary>更多</summary>
  
**动机:** 作者旨在为顺序决策任务设计一种能够结合频率论和贝叶斯过滤优势的在线学习和广义贝叶斯推理算法。

**方法:** 主要方法是通过块对角近似参数误差协方差来执行快速低秩更新，并且维持一个良好的后验预测分布用于决策。对于隐藏层参数采用低秩误差协方差更新，而对于最终层参数则使用全秩误差协方差更新。

**结果:** 尽管这种方法表征了一个不适当的后验，但所得到的后验预测分布是明确定义的。所有网络参数都能在线更新，无需回放缓冲或离线再训练。

**结论:** 实证研究表明，该方法在（非平稳）上下文强盗问题和贝叶斯优化问题中，在速度与准确性之间达到了竞争性的权衡。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+Generalized+Bayesian+Online+Neural+Network+Training+for+Sequential+Decision+Making，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11898，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11898&send_immediately=true&force_search=false)

**原文摘要:** We introduce scalable algorithms for online learning and generalized Bayesian
inference of neural network parameters, designed for sequential decision making
tasks. Our methods combine the strengths of frequentist and Bayesian filtering,
which include fast low-rank updates via a block-diagonal approximation of the
parameter error covariance, and a well-defined posterior predictive
distribution that we use for decision making. More precisely, our main method
updates a low-rank error covariance for the hidden layers parameters, and a
full-rank error covariance for the final layer parameters. Although this
characterizes an improper posterior, we show that the resulting posterior
predictive distribution is well-defined. Our methods update all network
parameters online, with no need for replay buffers or offline retraining. We
show, empirically, that our methods achieve a competitive tradeoff between
speed and accuracy on (non-stationary) contextual bandit problems and Bayesian
optimization problems.

</details>


### [15] [Deep Learning Approach to Bearing and Induction Motor Fault Diagnosis via Data Fusion](https://arxiv.org/abs/2506.11032)
*Mert Sehri, Merve Ertagrin, Ozal Yildirim, Ahmet Orhan, Patrick Dumond*

**主要类别:** cs.LG

**AI概要:** 本文使用卷积神经网络（CNN）和长短期记忆（LSTM）递归神经网络来评估加速度计和麦克风数据，以实现轴承和感应电机的诊断。通过提出一种综合运用深度学习和传感器融合的方法，促进了多模型诊断的研究以及更多多传感器数据的收集。


<details>
  <summary>更多</summary>
  
**动机:** 研究者希望通过结合不同的传感器信息，并利用深度学习技术，提高对恒速运行设备如轴承和感应电机的故障诊断能力。同时，鼓励研究人员关注多模型诊断方法并收集更多种类的传感器数据。

**方法:** 采用卷积神经网络处理加速度计和麦克风数据，然后使用长短期记忆递归神经网络有效地融合这些传感器的信息。

**结果:** 研究表明，通过使用CNN和LSTM网络相结合的方式可以有效提升基于多传感器数据融合的诊断效果。

**结论:** 该研究展示了一种将深度学习与传感器融合应用于机械设备状态监测的有效途径，并建议未来工作应进一步探索不同类型的传感器组合及更广泛的工业应用场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Deep+Learning+Approach+to+Bearing+and+Induction+Motor+Fault+Diagnosis+via+Data+Fusion，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11032，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11032&send_immediately=true&force_search=false)

**原文摘要:** Convolutional Neural Networks (CNNs) are used to evaluate accelerometer and
microphone data for bearing and induction motor diagnosis. A Long Short-Term
Memory (LSTM) recurrent neural network is used to combine sensor information
effectively, highlighting the benefits of data fusion. This approach encourages
researchers to focus on multi model diagnosis for constant speed data
collection by proposing a comprehensive way to use deep learning and sensor
fusion and encourages data scientists to collect more multi-sensor data,
including acoustic and accelerometer datasets.

</details>


### [16] [pLSTM: parallelizable Linear Source Transition Mark networks](https://arxiv.org/abs/2506.11997)
*Korbinian Pöppel, Richard Freinschlag, Thomas Schmied, Wei Lin, Sepp Hochreiter*

**主要类别:** cs.LG

**AI概要:** 本文介绍了pLSTM，这是一种针对DAGs的并行化线性RNN架构，它能够处理长距离依赖问题，并在箭头指向外推等合成计算机视觉任务中表现优于Transformer。


<details>
  <summary>更多</summary>
  
**动机:** 现有现代递归结构（如xLSTM和Mamba）在语言建模上挑战了Transformer，但它们的应用局限于序列或需按预定义顺序处理多维数据。相比之下，多维RNN适合处理具有更高层次结构的数据。为了解决这些限制，研究者将多维概念扩展到线性RNN，并引入了pLSTM网络。

**方法:** 研究者们提出了使用源、转换和标记门作用于一般DAG的线图上的并行化线性源转换标记网络（pLSTMs）。对于规则网格（1D和2D），该方案可以使用einsum操作、连接和填充以对数时间有效地实现。

**结果:** pLSTM通过两种不同的模式解决了DAG中的长距离消失/爆炸激活/梯度问题：定向传播模式（P-模式）和扩散分布模式（D-模式）。实验表明，pLSTM在箭头指向外推等合成计算机视觉任务中表现出色，能够很好地泛化到更大的图像尺寸。

**结论:** pLSTM在处理长距离依赖信息方面展示了强大的性能，在合成计算机视觉任务以及分子图和计算机视觉基准测试中均表现出色。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是pLSTM%3A+parallelizable+Linear+Source+Transition+Mark+networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11997，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11997&send_immediately=true&force_search=false)

**原文摘要:** Modern recurrent architectures, such as xLSTM and Mamba, have recently
challenged the Transformer in language modeling. However, their structure
constrains their applicability to sequences only or requires processing
multi-dimensional data structures, such as images or molecular graphs, in a
pre-defined sequential order. In contrast, Multi-Dimensional RNNs (MDRNNs) are
well suited for data with a higher level structure, like 2D grids, trees, and
directed acyclic graphs (DAGs). In this work, we extend the notion of
multi-dimensionality to linear RNNs. We introduce parallelizable Linear Source
Transition Mark networks (pLSTMs) using Source, Transition, and Mark gates that
act on the line graph of a general DAG. This enables parallelization in analogy
to parallel associative scans and the chunkwise-recurrent form of sequential
linear RNNs, but for DAGs. For regular grids (1D and 2D), like images, this
scheme can be efficiently implemented using einsum operations, concatenations,
and padding in logarithmic time. pLSTMs tackle the vanishing/exploding
activation/gradient problem for long distances in DAGs via two distinct modes:
a directed propagation mode (P-mode) and a diffusive distribution mode
(D-mode). To showcase the long-range capabilities of pLSTM, we introduce
arrow-pointing extrapolation as a synthetic computer vision task that contains
long-distance directional information. We demonstrate that pLSTMs generalize
well to larger image sizes, whereas Transformers struggle to extrapolate. On
established molecular graph and computer vision benchmarks, pLSTMs also show
strong performance. Code and Datasets are available at:
https://github.com/ml-jku/plstm_experiments.

</details>


### [17] [Runtime Safety through Adaptive Shielding: From Hidden Parameter Inference to Provable Guarantees](https://arxiv.org/abs/2506.11033)
*Minjae Kwon, Tyler Ingebrand, Ufuk Topcu, Lu Feng*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于约束隐藏参数马尔可夫决策过程的形式化方法的运行时防护机制，用于强化学习。该机制通过功能编码器实时推断隐藏参数，并根据预测的安全风险来限制动作空间，同时考虑了不确定性。实验证明，该方法能够显著减少安全违规行为，并且在不同环境下具有良好的泛化能力，同时保持较低的运行时开销。


<details>
  <summary>更多</summary>
  
**动机:** 由于隐藏参数（如机器人的质量分布或摩擦）的变化可能给执行过程中带来安全隐患，研究者开发了一种针对强化学习的运行时保护机制，旨在减少安全违规行为的同时保持对环境变化的良好适应性。

**方法:** 研究人员采用了受限隐藏参数马尔可夫决策过程的形式化方法，并利用功能编码器实现从观察中对隐藏参数进行实时推断。所提出的防护机制通过预测未来安全风险（例如障碍物接近度）来限制行动空间，并采用一致性预测处理不确定性。

**结果:** 实验表明，该方法能够在多种环境和不同的隐藏参数条件下显著降低安全违规次数，并表现出强大的非分布外泛化能力，而且额外的运行时间开销很小。

**结论:** 提出的运行时防护机制不仅满足概率安全保证，而且在所有符合安全标准的策略中产生最优策略。它证明了自己是有效提高机器人等系统安全性的一种手段。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Runtime+Safety+through+Adaptive+Shielding%3A+From+Hidden+Parameter+Inference+to+Provable+Guarantees，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11033，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11033&send_immediately=true&force_search=false)

**原文摘要:** Variations in hidden parameters, such as a robot's mass distribution or
friction, pose safety risks during execution. We develop a runtime shielding
mechanism for reinforcement learning, building on the formalism of constrained
hidden-parameter Markov decision processes. Function encoders enable real-time
inference of hidden parameters from observations, allowing the shield and the
underlying policy to adapt online. The shield constrains the action space by
forecasting future safety risks (such as obstacle proximity) and accounts for
uncertainty via conformal prediction. We prove that the proposed mechanism
satisfies probabilistic safety guarantees and yields optimal policies among the
set of safety-compliant policies. Experiments across diverse environments with
varying hidden parameters show that our method significantly reduces safety
violations and achieves strong out-of-distribution generalization, while
incurring minimal runtime overhead.

</details>


### [18] [CausalVLBench: Benchmarking Visual Causal Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2506.11034)
*Aneesh Komanduri, Karuna Bhaila, Xintao Wu*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一个针对大型视觉-语言模型（LVLMs）的因果推理基准测试CausalVLBench，它涵盖了三个代表性的任务，并评估了当前开源LVLMs在这些任务上的表现，以期揭示现有模型的不足并推动改进。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLMs）在因果推理等任务中显示出潜力，但关于LVLMs在视觉因果推理任务中的能力展示相对较少。本文旨在通过引入一个全面的因果推理基准来填补这一空白。

**方法:** 作者们创建了一个名为CausalVLBench的基准测试，该测试包括三个代表性任务：因果结构推断、干预目标预测和反事实预测。使用这个基准测试对最先进的开源LVLMs进行了评估。

**结果:** 研究结果展示了当前开源LVLMs在因果推理任务中的基本优势和劣势，并且指出了现有视觉-语言模型在这类任务中存在的局限性。

**结论:** CausalVLBench基准测试为LVLMs在视觉因果推理方面提供了评估框架，揭示了现有模型的缺点，并为提升LVLMs的视觉因果推理能力提出了新的方向和范式。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CausalVLBench%3A+Benchmarking+Visual+Causal+Reasoning+in+Large+Vision-Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11034，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11034&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) have shown remarkable ability in various
language tasks, especially with their emergent in-context learning capability.
Extending LLMs to incorporate visual inputs, large vision-language models
(LVLMs) have shown impressive performance in tasks such as recognition and
visual question answering (VQA). Despite increasing interest in the utility of
LLMs in causal reasoning tasks such as causal discovery and counterfactual
reasoning, there has been relatively little work showcasing the abilities of
LVLMs on visual causal reasoning tasks. We take this opportunity to formally
introduce a comprehensive causal reasoning benchmark for multi-modal in-context
learning from LVLMs. Our CausalVLBench encompasses three representative tasks:
causal structure inference, intervention target prediction, and counterfactual
prediction. We evaluate the ability of state-of-the-art open-source LVLMs on
our causal reasoning tasks across three causal representation learning datasets
and demonstrate their fundamental strengths and weaknesses. We hope that our
benchmark elucidates the drawbacks of existing vision-language models and
motivates new directions and paradigms in improving the visual causal reasoning
abilities of LVLMs.

</details>


### [19] [Tversky Neural Networks: Psychologically Plausible Deep Learning with Differentiable Tversky Similarity](https://arxiv.org/abs/2506.11035)
*Moussa Koulako Bala Doumbouya, Dan Jurafsky, Christopher D. Manning*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于Tversky相似性理论的可微参数化方法，开发了Tversky投影层，用于替代深度学习中的线性投影层，并在图像识别和语言建模任务中证明了其优越性。


<details>
  <summary>更多</summary>
  
**动机:** 心理学研究表明，深度学习中标准的几何相似性模型不符合人类感知的心理学原理。Tversky（1977）提出了一个基于特征集合表示对象及其相似性的公理理论，但该模型因难以融入离散集操作而未被深度学习采用。

**方法:** 作者发展了一种可以通过梯度下降来学习的Tversky相似性的可微参数化方法，并且推导出神经网络构建模块，比如能够模拟非线性函数如XOR的Tversky投影层。

**结果:** 实验表明，Tversky投影层在NABirds图像分类任务上比线性层适配器基线提高了24.7%的相对准确率，在GPT-2上使用时，困惑度降低了7.5%，参数数量减少了34.8%。

**结论:** 这项工作为深度学习中隐含的相似性模型提供了一个新的范式，并设计了在网络中依据已建立的心理相似性理论具有可解释性的结构。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Tversky+Neural+Networks%3A+Psychologically+Plausible+Deep+Learning+with+Differentiable+Tversky+Similarity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11035，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11035&send_immediately=true&force_search=false)

**原文摘要:** Work in psychology has highlighted that the geometric model of similarity
standard in deep learning is not psychologically plausible because its metric
properties such as symmetry do not align with human perception. In contrast,
Tversky (1977) proposed an axiomatic theory of similarity based on a
representation of objects as sets of features, and their similarity as a
function of common and distinctive features. However, this model has not been
used in deep learning before, partly due to the challenge of incorporating
discrete set operations. We develop a differentiable parameterization of
Tversky's similarity that is learnable through gradient descent, and derive
neural network building blocks such as the Tversky projection layer, which
unlike the linear projection layer can model non-linear functions such as XOR.
Through experiments with image recognition and language modeling, we show that
the Tversky projection layer is a beneficial replacement for the linear
projection layer, which employs geometric similarity. On the NABirds image
classification task, a frozen ResNet-50 adapted with a Tversky projection layer
achieves a 24.7% relative accuracy improvement over the linear layer adapter
baseline. With Tversky projection layers, GPT-2's perplexity on PTB decreases
by 7.5%, and its parameter count by 34.8%. Finally, we propose a unified
interpretation of both projection layers as computing similarities of input
stimuli to learned prototypes, for which we also propose a novel visualization
technique highlighting the interpretability of Tversky projection layers. Our
work offers a new paradigm for thinking about the similarity model implicit in
deep learning, and designing networks that are interpretable under an
established theory of psychological similarity.

</details>


### [20] [Human-centered Interactive Learning via MLLMs for Text-to-Image Person Re-identification](https://arxiv.org/abs/2506.11036)
*Yang Qin, Chao Chen, Zhihang Fu, Dezhong Peng, Xi Peng, Peng Hu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种交互式跨模态学习框架（ICL），通过以人类为中心的交互来提高文本查询的区分度，并引入了测试时的人类中心交互模块（THI）和重组数据增强策略（RDA）来解决文本到图像人员重识别中的问题。实验表明该方法在四个基准上取得了显著的性能提升。


<details>
  <summary>更多</summary>
  
**动机:** 现有的文本到图像人员重识别方法因网络架构和数据质量等内在限制，在处理具有挑战性的候选图像时往往遇到困难。为了解决这些问题，特别是提高文本查询的区分度以及应对训练文本质量低的问题，提出了新的方法。

**方法:** 提出了一个交互式跨模态学习框架（ICL），它利用以人类为中心的交互并通过外部多模态知识来增强文本查询的区分性。此外，开发了一个即插即用的测试时人类中心交互（THI）模块，该模块专注于人物特征的视觉问答，与多模态大型语言模型进行多轮互动。同时，引入了基于信息丰富和多样性增强的新重组数据增强（RDA）策略。

**结果:** 在四个TIReID基准上的广泛实验表明，所提出的方法在排名准确性方面实现了显著改进。

**结论:** 提出的ICL框架及THI模块和RDA策略有效提高了文本到图像人员重识别任务中对候选图像的辨别能力，特别是在处理低质量训练文本的情况下。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Human-centered+Interactive+Learning+via+MLLMs+for+Text-to-Image+Person+Re-identification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11036，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11036&send_immediately=true&force_search=false)

**原文摘要:** Despite remarkable advancements in text-to-image person re-identification
(TIReID) facilitated by the breakthrough of cross-modal embedding models,
existing methods often struggle to distinguish challenging candidate images due
to intrinsic limitations, such as network architecture and data quality. To
address these issues, we propose an Interactive Cross-modal Learning framework
(ICL), which leverages human-centered interaction to enhance the
discriminability of text queries through external multimodal knowledge. To
achieve this, we propose a plug-and-play Test-time Humane-centered Interaction
(THI) module, which performs visual question answering focused on human
characteristics, facilitating multi-round interactions with a multimodal large
language model (MLLM) to align query intent with latent target images.
Specifically, THI refines user queries based on the MLLM responses to reduce
the gap to the best-matching images, thereby boosting ranking accuracy.
Additionally, to address the limitation of low-quality training texts, we
introduce a novel Reorganization Data Augmentation (RDA) strategy based on
information enrichment and diversity enhancement to enhance query
discriminability by enriching, decomposing, and reorganizing person
descriptions. Extensive experiments on four TIReID benchmarks, i.e.,
CUHK-PEDES, ICFG-PEDES, RSTPReid, and UFine6926, demonstrate that our method
achieves remarkable performance with substantial improvement.

</details>


### [21] [Mini-Game Lifetime Value Prediction in WeChat](https://arxiv.org/abs/2506.11037)
*Aochuan Chen, Yifan Niu, Ziqi Gao, Yujie Sun, Shoujun Liu, Gong Chen, Yang Liu, Jia Li*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的框架GRePO-LTV，通过图表示学习和帕累托优化来解决由于数据稀缺和预测任务间高度相关性导致的生命周期价值(LTV)预测难题。


<details>
  <summary>更多</summary>
  
**动机:** 广告商面临的重要挑战是准确预测用户对特定商品的累计购买贡献（即LTV），因为这能提高广告与用户兴趣的匹配度，并为广告商带来巨大利润。然而现实中的广告场景往往存在数据不足的问题，用户的购买率极低，且不同时间间隔内的预测任务之间高度相关，这给LTV模型的有效训练带来了额外难度。

**方法:** 提出了一个名为GRePO-LTV的新颖框架，该框架首先利用图表示学习来应对数据稀缺问题，然后采用帕累托优化处理预测任务之间的相互依赖关系。

**结果:** 新框架GRePO-LTV能够有效地缓解因数据稀疏及任务间高关联性所带来的LTV预测挑战。

**结论:** GRePO-LTV框架结合了图表示学习和帕累托优化方法，提供了一种解决LTV预测中数据稀缺和任务间强相关性的有效手段。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mini-Game+Lifetime+Value+Prediction+in+WeChat，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11037，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11037&send_immediately=true&force_search=false)

**原文摘要:** The LifeTime Value (LTV) prediction, which endeavors to forecast the
cumulative purchase contribution of a user to a particular item, remains a
vital challenge that advertisers are keen to resolve. A precise LTV prediction
system enhances the alignment of user interests with meticulously designed
advertisements, thereby generating substantial profits for advertisers.
Nonetheless, this issue is complicated by the paucity of data typically
observed in real-world advertising scenarios. The purchase rate among
registered users is often as critically low as 0.1%, resulting in a dataset
where the majority of users make only several purchases. Consequently, there is
insufficient supervisory signal for effectively training the LTV prediction
model. An additional challenge emerges from the interdependencies among tasks
with high correlation. It is a common practice to estimate a user's
contribution to a game over a specified temporal interval. Varying the lengths
of these intervals corresponds to distinct predictive tasks, which are highly
correlated. For instance, predictions over a 7-day period are heavily reliant
on forecasts made over a 3-day period, where exceptional cases can adversely
affect the accuracy of both tasks. In order to comprehensively address the
aforementioned challenges, we introduce an innovative framework denoted as
Graph-Represented Pareto-Optimal LifeTime Value prediction (GRePO-LTV). Graph
representation learning is initially employed to address the issue of data
scarcity. Subsequently, Pareto-Optimization is utilized to manage the
interdependence of prediction tasks.

</details>


### [22] [MoTE: Mixture of Task-specific Experts for Pre-Trained ModelBased Class-incremental Learning](https://arxiv.org/abs/2506.11038)
*Linjie Li, Zhenyu Wu, Yang Ji*

**主要类别:** cs.LG

**AI概要:** 提出了一种任务特定专家混合（MoTE）框架，解决了类增量学习中因任务输出维度不一致导致的校准问题，并通过实验验证了其优越性。


<details>
  <summary>更多</summary>
  
**动机:** 基于预训练模型的类增量学习方法存在提示覆盖和适配器方法中的维度不对齐等问题。尽管专家融合的想法可以帮助解决维度不一致的问题，但在动态环境中专家和路由参数容易被覆盖，使得直接应用混合专家模型面临挑战。

**方法:** 提出了一个名为MoTE (mixture of task-specific experts) 的框架，该框架利用加权特征融合和稀疏激活机制来实现任务感知的专家过滤以及在推理阶段可靠的专家联合推断，从而模仿路由层的行为同时避免灾难性遗忘。

**结果:** 大量实验表明，所提出的方法在不需要示例集的情况下表现出优越性。此外，MoTE 中的任务数量与适配器的数量呈线性关系。研究还探讨了适配器扩展与模型性能之间的权衡，并提出了Adapter-Limited MoTE。

**结论:** MoTE框架为类增量学习提供了一个有效方案，能够处理跨任务输出维度不一致的问题，并且在没有示例集的情况下依然保持良好的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MoTE%3A+Mixture+of+Task-specific+Experts+for+Pre-Trained+ModelBased+Class-incremental+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11038，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11038&send_immediately=true&force_search=false)

**原文摘要:** Class-incremental learning (CIL) requires deep learning models to
continuously acquire new knowledge from streaming data while preserving
previously learned information. Recently, CIL based on pre-trained models
(PTMs) has achieved remarkable success. However, prompt-based approaches suffer
from prompt overwriting, while adapter-based methods face challenges such as
dimensional misalignment between tasks. While the idea of expert fusion in
Mixture of Experts (MoE) can help address dimensional inconsistency, both
expert and routing parameters are prone to being overwritten in dynamic
environments, making MoE challenging to apply directly in CIL. To tackle these
issues, we propose a mixture of task-specific experts (MoTE) framework that
effectively mitigates the miscalibration caused by inconsistent output
dimensions across tasks. Inspired by the weighted feature fusion and sparse
activation mechanisms in MoE, we introduce task-aware expert filtering and
reliable expert joint inference during the inference phase, mimicking the
behavior of routing layers without inducing catastrophic forgetting. Extensive
experiments demonstrate the superiority of our method without requiring an
exemplar set. Furthermore, the number of tasks in MoTE scales linearly with the
number of adapters. Building on this, we further explore the trade-off between
adapter expansion and model performance and propose the Adapter-Limited MoTE.
The code is available at https://github.com/Franklilinjie/MoTE.

</details>


### [23] [Angle Domain Guidance: Latent Diffusion Requires Rotation Rather Than Extrapolation](https://arxiv.org/abs/2506.11039)
*Cheng Jin, Zhenyu Xiao, Chutao Liu, Yuantao Gu*

**主要类别:** cs.LG

**AI概要:** 本文探讨了无分类器引导（CFG）在文本到图像的潜在扩散模型中导致的颜色失真问题，并提出了一种角度域引导（ADG）算法来缓解这一问题，同时保持文本-图像对齐的优势。实验表明ADG在颜色保真度和与人类感知偏好的一致性方面优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于解决当使用高权重的无分类器引导时，尽管能够显著增强文本-图像的一致性，但也会造成生成图像中出现明显的颜色失真问题。

**方法:** 研究者们首先构建了一个理论框架，解释了无分类器引导所引起的范数放大和异常扩散现象。基于此理论及潜在空间结构的理解，提出了角度域引导（ADG）算法，该算法通过限制幅度变化并优化角度对齐来减少颜色失真。

**结果:** 实验结果显示，ADG算法不仅能有效减轻颜色失真，还能够在较高的引导权重下维持优秀的文本-图像对齐效果，同时提高了颜色的真实度以及与人类感知偏好的匹配程度。

**结论:** 结论指出，ADG算法成功地解决了CFG在高权重条件下产生的颜色失真问题，同时保持甚至增强了文本-图像之间的对齐质量，为高质量图像合成提供了新的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Angle+Domain+Guidance%3A+Latent+Diffusion+Requires+Rotation+Rather+Than+Extrapolation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11039，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11039&send_immediately=true&force_search=false)

**原文摘要:** Classifier-free guidance (CFG) has emerged as a pivotal advancement in
text-to-image latent diffusion models, establishing itself as a cornerstone
technique for achieving high-quality image synthesis. However, under high
guidance weights, where text-image alignment is significantly enhanced, CFG
also leads to pronounced color distortions in the generated images. We identify
that these distortions stem from the amplification of sample norms in the
latent space. We present a theoretical framework that elucidates the mechanisms
of norm amplification and anomalous diffusion phenomena induced by
classifier-free guidance. Leveraging our theoretical insights and the latent
space structure, we propose an Angle Domain Guidance (ADG) algorithm. ADG
constrains magnitude variations while optimizing angular alignment, thereby
mitigating color distortions while preserving the enhanced text-image alignment
achieved at higher guidance weights. Experimental results demonstrate that ADG
significantly outperforms existing methods, generating images that not only
maintain superior text alignment but also exhibit improved color fidelity and
better alignment with human perceptual preferences.

</details>


### [24] [Large Language models for Time Series Analysis: Techniques, Applications, and Challenges](https://arxiv.org/abs/2506.11040)
*Feifei Shi, Xueyan Yin, Kang Wang, Wanyu Tu, Qifu Sun, Huansheng Ning*

**主要类别:** cs.LG

**AI概要:** 本文系统地回顾了预训练大语言模型（LLMs）在时间序列分析中的应用，包括关键技术、潜在应用和开放挑战，并为未来研究指明了方向。


<details>
  <summary>更多</summary>
  
**动机:** 传统的时间序列分析方法在非线性特征表示和长期依赖关系捕捉方面存在局限性，而大语言模型的出现通过跨模态知识整合和内在注意力机制为时间序列分析提供了变革潜力。然而，从零开始开发通用的大语言模型受到数据多样性、标注稀缺以及计算需求等因素的限制。

**方法:** 文章首先建立了一个AI驱动的时间序列分析演变路线图，从早期的机器学习时代到新兴的大语言模型驱动范式，再到本土时间基础模型的发展。其次，从工作流程的角度组织并系统化了大语言模型驱动的时间序列分析技术格局，涵盖了输入、优化和轻量化阶段。最后，批判性地审查了新颖的实际应用，并强调了可以指导未来研究和创新的关键开放挑战。

**结果:** 该研究不仅提供了关于当前进展的宝贵见解，还概述了未来发展的有希望的方向。它作为学术界和工业界研究人员的基础参考，为开发更高效、可泛化和可解释的大语言模型驱动的时间序列分析系统铺平了道路。

**结论:** 论文通过对大语言模型驱动的时间序列分析的全面审视，突出了其技术进步、现实世界的应用案例及未来研究面临的挑战，旨在促进该领域更加有效且可解释的系统的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Large+Language+models+for+Time+Series+Analysis%3A+Techniques%2C+Applications%2C+and+Challenges，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11040，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11040&send_immediately=true&force_search=false)

**原文摘要:** Time series analysis is pivotal in domains like financial forecasting and
biomedical monitoring, yet traditional methods are constrained by limited
nonlinear feature representation and long-term dependency capture. The
emergence of Large Language Models (LLMs) offers transformative potential by
leveraging their cross-modal knowledge integration and inherent attention
mechanisms for time series analysis. However, the development of
general-purpose LLMs for time series from scratch is still hindered by data
diversity, annotation scarcity, and computational requirements. This paper
presents a systematic review of pre-trained LLM-driven time series analysis,
focusing on enabling techniques, potential applications, and open challenges.
First, it establishes an evolutionary roadmap of AI-driven time series
analysis, from the early machine learning era, through the emerging LLM-driven
paradigm, to the development of native temporal foundation models. Second, it
organizes and systematizes the technical landscape of LLM-driven time series
analysis from a workflow perspective, covering LLMs' input, optimization, and
lightweight stages. Finally, it critically examines novel real-world
applications and highlights key open challenges that can guide future research
and innovation. The work not only provides valuable insights into current
advances but also outlines promising directions for future development. It
serves as a foundational reference for both academic and industrial
researchers, paving the way for the development of more efficient,
generalizable, and interpretable systems of LLM-driven time series analysis.

</details>


### [25] [ChemHGNN: A Hierarchical Hypergraph Neural Network for Reaction Virtual Screening and Discovery](https://arxiv.org/abs/2506.11041)
*Xiaobao Huang, Yihong Ma, Anjali Gurajapu, Jules Schleinitz, Zhichun Guo, Sarah E. Reisman, Nitesh V. Chawla*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为ChemHGNN的超图神经网络框架，用于更有效地捕捉反应网络中的高阶关系，并通过实验证明了其在大规模设置下相对于GNN基线的优越性。


<details>
  <summary>更多</summary>
  
**动机:** 化学和材料科学中的反应虚拟筛选和发现是基本挑战，传统的图神经网络（GNNs）难以建模多反应物相互作用。

**方法:** 开发了ChemHGNN，一种超图神经网络（HGNN）框架，该框架能够自然地通过超边来建模多反应物反应，提出了反应中心感知的负采样策略（RCNS）以及结合分子、反应和超图层面特征的层次嵌入方法。

**结果:** 实验结果表明，在USPTO数据集上，ChemHGNN显著优于HGNN和GNN基线，特别是在大规模情况下，同时保持了解释性和化学合理性。

**结论:** ChemHGNN为加速反应发现提供了一个基于化学信息的框架，并且被证明是GNN的一个更好的替代方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ChemHGNN%3A+A+Hierarchical+Hypergraph+Neural+Network+for+Reaction+Virtual+Screening+and+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11041，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11041&send_immediately=true&force_search=false)

**原文摘要:** Reaction virtual screening and discovery are fundamental challenges in
chemistry and materials science, where traditional graph neural networks (GNNs)
struggle to model multi-reactant interactions. In this work, we propose
ChemHGNN, a hypergraph neural network (HGNN) framework that effectively
captures high-order relationships in reaction networks. Unlike GNNs, which
require constructing complete graphs for multi-reactant reactions, ChemHGNN
naturally models multi-reactant reactions through hyperedges, enabling more
expressive reaction representations. To address key challenges, such as
combinatorial explosion, model collapse, and chemically invalid negative
samples, we introduce a reaction center-aware negative sampling strategy (RCNS)
and a hierarchical embedding approach combining molecule, reaction and
hypergraph level features. Experiments on the USPTO dataset demonstrate that
ChemHGNN significantly outperforms HGNN and GNN baselines, particularly in
large-scale settings, while maintaining interpretability and chemical
plausibility. Our work establishes HGNNs as a superior alternative to GNNs for
reaction virtual screening and discovery, offering a chemically informed
framework for accelerating reaction discovery.

</details>


### [26] [GenFT: A Generative Parameter-Efficient Fine-Tuning Method for Pretrained Foundation Models](https://arxiv.org/abs/2506.11042)
*Baoquan Zhang, Guangning Xu, Michael. K. Ng*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的参数高效微调方法GenFT，通过利用预训练权重W_0来指导任务特定权重ΔW的更新，从而在视觉和自然语言处理任务中实现了比现有PEFT方法更优的性能。


<details>
  <summary>更多</summary>
  
**动机:** 研究者们希望解决如何有效利用预训练好的权重 W_0 来指导任务特异性的 ΔW 更新的问题，避免从零开始低效地训练 ΔW。

**方法:** 研究者提出了生成式参数高效微调（GenFT），这是一种新颖的方法，能够从 W_0 中提取结构化、可转移的信息，以便有效地训练 ΔW。为了提取行和列的结构信息，GenFT 对 W_0 应用行和列变换以提炼出关键模式。此外，还设计了策略将 ΔW 分解为层共享和层特定组件，以平衡信息重用和个人化灵活性。

**结果:** GenFT 方法简单而有效，在计算机视觉（CV）和自然语言处理（NLP）任务上表现出色。在 VTAB-1K、FGVC 和 GLUE 基准测试中的大量实验表明，GenFT 的表现优于当前最先进的 PEFT 方法。

**结论:** GenFT 提供了一个有效的模型适应新视角，并且在多个基准测试中超过了现有的 PEFT 方法，为高效模型适应提供了新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GenFT%3A+A+Generative+Parameter-Efficient+Fine-Tuning+Method+for+Pretrained+Foundation+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11042，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11042&send_immediately=true&force_search=false)

**原文摘要:** Pretrained Foundation Models (PFMs) have transformed numerous applications by
enabling efficient adaptation to customized tasks. Parameter-Efficient
Fine-Tuning (PEFT) has emerged as a resource-efficient alternative to full
fine-tuning, especially leveraging reparameterized weights $\Delta W$ to adapt
models for downstream tasks. However, a critical yet underexplored question
remains: can we utilize well-pretrained weights $W_0$ to guide the update of
task-specific $\Delta W$, avoiding inefficient training it from scratch? To end
this, we propose Generative Parameter-Efficient Fine-Tuning (GenFT), a novel
method that extracts structured, transferable information from $W_0$ for
efficient $\Delta W$ training. To extract row and column structure information,
GenFT applies row and column transformations to distill essential patterns from
$W_0$. A tailored policy further decomposes $\Delta W$ into layer-shared and
layer-specific components, balancing information reuse and individualized
flexibility. GenFT is simple yet effective, achieving superior performance
across CV and NLP tasks. Extensive experiments on VTAB-1K, FGVC, and GLUE
benchmarks demonstrate that GenFT outperforms state-of-the-art PEFT methods,
offering a new perspective for efficient model adaptation.

</details>


### [27] [Boost Post-Training Quantization via Null Space Optimization for Large Language Models](https://arxiv.org/abs/2506.11044)
*Jiaqi Zhao, Miao Zhang, Weili Guan, Liqiang Nie*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的量化方法Q2N，通过引入零空间概念来减少大型语言模型的量化误差，提供了理论上的闭式解，并在多个先进模型上进行了有效性验证。


<details>
  <summary>更多</summary>
  
**动机:** 现有的大型语言模型（LLMs）后训练量化方法虽然取得了显著成功，但性能提升逐渐变得微小，表明当前的量化策略不足以支持更压缩模型的发展。因此，研究需要新的方向以进一步减小量化误差。

**方法:** 文章提出了一个即插即用的零空间投影模块Q2N，设计了一个高效的零空间投影近似方法，特别针对LLMs的特点，并且从理论上推导出满足实际推理条件而不增加额外内存开销的等效向量闭式解。

**结果:** 广泛的实验结果表明，所提出的Q2N方法以及基于零空间优化的观点对于LLMs的量化是有效的。

**结论:** 本文作为基于零空间洞察减少量化误差的第一步，旨在启发未来的研究者设计更加先进的量化方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Boost+Post-Training+Quantization+via+Null+Space+Optimization+for+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11044，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11044&send_immediately=true&force_search=false)

**原文摘要:** Existing post-training quantization methods for large language models (LLMs)
offer remarkable success. However, the increasingly marginal performance gains
suggest that existing quantization strategies are insufficient to support the
development of more compressed models. To inspire new directions for future
research, this paper introduces the concept of null space into LLMs
quantization. We argue that the quantization error can be effectively
alleviated by constraining the post-quantization weight perturbation to lie
within the null space of input activations. To prove this idea, we propose a
plug-and-play null space projection module for existing milestone PTQ baselines
named Q2N. Specifically, we first design an efficient and accurate null space
projection approximation method tailored to the characteristics of LLMs.
Subsequently, we theoretically derive a closed-form solution for an equivalent
vector of the obtained projection matrix, which satisfies practical inference
condition while avoiding additional memory overhead. Extensive experiments are
conducted on various state-of-the-art LLMs (LLaMA3, DeepSeek, Qwen3) and
baselines, demonstrating the effectiveness of both our Q2N and the perspective
of null space optimization for LLMs quantization. We view this paper the first
step to further alleviate the quantization error based on the insights of null
space, hoping it inspiring future researchers to design more advanced
quantization methods. Codes are available at https://github.com/zjq0455/q2n.

</details>


### [28] [Procedural Environment Generation for Tool-Use Agents](https://arxiv.org/abs/2506.11045)
*Michael Sullivan, Mareike Hartmann, Alexander Koller*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为RandomWorld的合成工具使用数据生成流程，该方法生成的数据可以提高模型在工具使用基准测试中的表现，并且在NESTFUL数据集上的两个度量上达到了新的SoTA。


<details>
  <summary>更多</summary>
  
**动机:** 现有的合成工具使用数据生成方法往往是非交互式的和/或非组合式的，这使得在线RL训练的数据整理成为一个开放的问题。

**方法:** 提出了RandomWorld，这是一种用于生成交互式工具和组合式工具使用数据的过程化生成流程。

**结果:** 通过SFT和RL调整并在合成的RandomWorld数据上训练的模型，在一系列工具使用基准测试中有所提升，并在NESTFUL数据集的两项指标上设定了新的SoTA。进一步实验表明，下游性能随着RandomWorld生成的训练数据量而扩展。

**结论:** RandomWorld为工具使用数据生成提供了一个有前景的方向，并且通过完全合成的数据有可能实现进一步的改进。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Procedural+Environment+Generation+for+Tool-Use+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11045，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11045&send_immediately=true&force_search=false)

**原文摘要:** Although the power of LLM tool-use agents has ignited a flurry of recent
research in this area, the curation of tool-use training data remains an open
problem$-$especially for online RL training. Existing approaches to synthetic
tool-use data generation tend to be non-interactive, and/or non-compositional.
We introduce RandomWorld, a pipeline for the procedural generation of
interactive tools and compositional tool-use data. We show that models tuned
via SFT and RL on synthetic RandomWorld data improve on a range of tool-use
benchmarks, and set the new SoTA for two metrics on the NESTFUL dataset.
Further experiments show that downstream performance scales with the amount of
RandomWorld-generated training data, opening up the possibility of further
improvement through the use of entirely synthetic data.

</details>


### [29] [The Effects of Data Augmentation on Confidence Estimation for LLMs](https://arxiv.org/abs/2506.11046)
*Rui Wang, Renyu Zhu, Minmin Lin, Runze Wu, Tangjie Lv, Changjie Fan, Haobo Wang*

**主要类别:** cs.LG

**AI概要:** 研究了不同数据增强方法对大型语言模型（LLMs）信心估计的影响，发现数据多样性可以提高增强效果并减少过度自信问题。随机组合增强策略在参数可转移性和可用性方面显示出潜力。


<details>
  <summary>更多</summary>
  
**动机:** 由于置信度估计对于反映大规模语言模型（特别是广泛使用的闭源模型）的可靠性至关重要，因此本研究旨在探索不同的数据增强方法如何影响置信度估计，并试图超越特定增强技术的局限性来发掘其潜在价值。

**方法:** 通过实验研究了多种数据增强方法对置信度估计性能的影响，并分析了保持语义信息的同时增加数据多样性的作用。此外还评估了不同应用场景下各种增强策略的效果以及参数迁移性和可用性。

**结果:** 结果表明，适当的数据增强策略能够改善性能并且减轻过高的置信度问题。同时，更大的数据多样性有助于提高数据增强的有效性。另外，随机组合的数据增强方法被发现是一个有前途的选择，因为它在参数传递和实用性方面表现良好。

**结论:** 数据增强是改进大型语言模型置信度估计的一种有效方式，它可以通过增加数据多样性来加强模型性能，并且使用随机组合的增强策略可能是未来实践中的一个好选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Effects+of+Data+Augmentation+on+Confidence+Estimation+for+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11046，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11046&send_immediately=true&force_search=false)

**原文摘要:** Confidence estimation is crucial for reflecting the reliability of large
language models (LLMs), particularly in the widely used closed-source models.
Utilizing data augmentation for confidence estimation is viable, but
discussions focus on specific augmentation techniques, limiting its potential.
We study the impact of different data augmentation methods on confidence
estimation. Our findings indicate that data augmentation strategies can achieve
better performance and mitigate the impact of overconfidence. We investigate
the influential factors related to this and discover that, while preserving
semantic information, greater data diversity enhances the effectiveness of
augmentation. Furthermore, the impact of different augmentation strategies
varies across different range of application. Considering parameter
transferability and usability, the random combination of augmentations is a
promising choice.

</details>


### [30] [Perception-Driven Bias Detection in Machine Learning via Crowdsourced Visual Judgment](https://arxiv.org/abs/2506.11047)
*Chirudeep Tupakula, Rittika Shamsuddin*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于感知驱动的偏见检测框架，利用众包的人类判断来识别数据中的潜在偏见。通过一个轻量级网络平台展示简化后的数值数据可视化，并收集用户对群体相似性的二元判断。该方法聚合用户的视觉反馈以标记可能存在的偏见数据段，并通过统计测试和机器学习交叉验证进行验证。研究结果表明非专家用户的直观感受与已知偏见案例有可靠的相关性，为公平审计提供了一个可扩展且易于解释的替代方案。


<details>
  <summary>更多</summary>
  
**动机:** 随着机器学习系统在高风险领域的应用日益增多，它们仍然容易受到偏见的影响，这些偏见会对特定人群产生不成比例的影响。传统的偏见检测方法往往依赖于敏感标签或严格的公平度量标准，这限制了其在实际环境中的适用性。

**方法:** 论文介绍了一种新的基于感知驱动的偏见检测框架，该框架利用众包人类判断。受reCAPTCHA等众包系统的启发，作者们开发了一个轻量级的网页平台，用于显示简化版的数据可视化（例如跨人口群体的薪资分布）并收集关于组间相似性的二元评判。用户反馈被汇总用来标记出可能存在偏见的数据部分，然后通过统计检验和机器学习交叉评估加以验证。

**结果:** 研究发现表明，非专业用户的感知信号与已知偏见案例之间存在可靠的相关性，这提示视觉直觉可以作为强有力的、可扩展的公平审核代理指标。

**结论:** 这种基于感知的方法为传统的公平性诊断提供了标签效率高、可解释性强的替代方案，为实现符合人类认知的、基于众包的偏见检测流程铺平了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Perception-Driven+Bias+Detection+in+Machine+Learning+via+Crowdsourced+Visual+Judgment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11047，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11047&send_immediately=true&force_search=false)

**原文摘要:** Machine learning systems are increasingly deployed in high-stakes domains,
yet they remain vulnerable to bias systematic disparities that
disproportionately impact specific demographic groups. Traditional bias
detection methods often depend on access to sensitive labels or rely on rigid
fairness metrics, limiting their applicability in real-world settings. This
paper introduces a novel, perception-driven framework for bias detection that
leverages crowdsourced human judgment. Inspired by reCAPTCHA and other
crowd-powered systems, we present a lightweight web platform that displays
stripped-down visualizations of numeric data (for example-salary distributions
across demographic clusters) and collects binary judgments on group similarity.
We explore how users' visual perception-shaped by layout, spacing, and question
phrasing can signal potential disparities. User feedback is aggregated to flag
data segments as biased, which are then validated through statistical tests and
machine learning cross-evaluations. Our findings show that perceptual signals
from non-expert users reliably correlate with known bias cases, suggesting that
visual intuition can serve as a powerful, scalable proxy for fairness auditing.
This approach offers a label-efficient, interpretable alternative to
conventional fairness diagnostics, paving the way toward human-aligned,
crowdsourced bias detection pipelines.

</details>


### [31] [I Can't Believe It's Not Real: CV-MuSeNet: Complex-Valued Multi-Signal Segmentation](https://arxiv.org/abs/2506.11048)
*Sangwon Shin, Mehmet C. Vuran*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一种名为CMuSeNet的复数多信号分割网络，用于宽带频谱感知。它基于复数神经网络（CVNNs）并引入了新的损失函数和相似性度量，以提高在低信噪比环境中的弱信号检测和训练效率。实验结果表明，与实值神经网络相比，CMuSeNet能够显著提高准确性，并大幅减少训练时间。


<details>
  <summary>更多</summary>
  
**动机:** 随着无线电频率频谱变得越来越拥挤，高效利用频谱面临挑战。尽管认知无线电系统结合了神经网络的最新创新成果实现了动态频谱访问，但传统的实值神经网络（RVNNs）由于未能专门捕捉无线电信号的关键属性如相位和幅度，在低信噪比环境中表现不佳。因此，需要一种新的方法来克服这些限制。

**方法:** 提出了CMuSeNet，一个专为宽带频谱感知设计的复数多信号分割网络。通过详细的超参数分析，发现简单地将现有的RVNN转换成它们的复数版本是无效的。CMuSeNet基于具有残差架构的复数神经网络(CVNN)，并引入了复数傅里叶谱焦点损失(CFL)以及复平面交集比(CIoU)相似度指标，以增强训练性能。

**结果:** 综合评估显示，CMuSeNet在合成、室内空中传输及真实世界数据集上达到了平均98.98%-99.90%的准确率，相较于其实值对应物提高了最多9.2个百分点，并且始终优于当前最先进水平。令人印象深刻的是，CMuSeNet仅用两个epoch就达到了RVNN对应的准确度级别，而后者需要27个epoch，同时相较于现有技术减少了高达92.2%的训练时间。

**结论:** 研究结果强调了复数值架构对于改善低信噪比环境下的弱信号检测和训练效率的有效性。这表明，像CMuSeNet这样的复数神经网络不仅能够提高频谱感知任务的准确性，还能极大地提升训练过程的效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是I+Can%27t+Believe+It%27s+Not+Real%3A+CV-MuSeNet%3A+Complex-Valued+Multi-Signal+Segmentation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11048，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11048&send_immediately=true&force_search=false)

**原文摘要:** The increasing congestion of the radio frequency spectrum presents challenges
for efficient spectrum utilization. Cognitive radio systems enable dynamic
spectrum access with the aid of recent innovations in neural networks. However,
traditional real-valued neural networks (RVNNs) face difficulties in low
signal-to-noise ratio (SNR) environments, as they were not specifically
developed to capture essential wireless signal properties such as phase and
amplitude. This work presents CMuSeNet, a complex-valued multi-signal
segmentation network for wideband spectrum sensing, to address these
limitations. Extensive hyperparameter analysis shows that a naive conversion of
existing RVNNs into their complex-valued counterparts is ineffective. Built on
complex-valued neural networks (CVNNs) with a residual architecture, CMuSeNet
introduces a complexvalued Fourier spectrum focal loss (CFL) and a complex
plane intersection over union (CIoU) similarity metric to enhance training
performance. Extensive evaluations on synthetic, indoor overthe-air, and
real-world datasets show that CMuSeNet achieves an average accuracy of
98.98%-99.90%, improving by up to 9.2 percentage points over its real-valued
counterpart and consistently outperforms state of the art. Strikingly, CMuSeNet
achieves the accuracy level of its RVNN counterpart in just two epochs,
compared to the 27 epochs required for RVNN, while reducing training time by up
to a 92.2% over the state of the art. The results highlight the effectiveness
of complex-valued architectures in improving weak signal detection and training
efficiency for spectrum sensing in challenging low-SNR environments. The
dataset is available at: https://dx.doi.org/10.21227/hcc1-6p22

</details>


### [32] [15,500 Seconds: Lean UAV Classification Leveraging PEFT and Pre-Trained Networks](https://arxiv.org/abs/2506.11049)
*Andrew P. Berg, Qian Zhang, Mia Y. Wang*

**主要类别:** cs.LG

**AI概要:** 该论文针对无人机音频分类中的数据稀缺问题，通过参数高效的微调、数据增强和预训练网络等方法，实现了高达95%的验证准确率。


<details>
  <summary>更多</summary>
  
**动机:** 随着消费级和军用无人机市场的增长，无人机所带来的安全问题日益严重。论文旨在解决深度无人机音频分类中关键的数据稀缺挑战。

**方法:** 研究者基于先前的工作，采用了参数高效微调、数据增强以及预训练网络的新颖方法。

**结果:** 利用EfficientNet-B0模型，研究人员达到了超过95%的验证准确率。

**结论:** 本研究表明，即使在数据稀缺的情况下，通过采用特定的技术手段如参数高效调整、数据扩充及使用预训练模型，也能实现高精度的无人机音频分类。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是15%2C500+Seconds%3A+Lean+UAV+Classification+Leveraging+PEFT+and+Pre-Trained+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11049，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11049&send_immediately=true&force_search=false)

**原文摘要:** Unmanned Aerial Vehicles (UAVs) pose an escalating security concerns as the
market for consumer and military UAVs grows. This paper address the critical
data scarcity challenges in deep UAV audio classification. We build upon our
previous work expanding novel approaches such as: parameter efficient
fine-tuning, data augmentation, and pre-trained networks. We achieve
performance upwards of 95\% validation accuracy with EfficientNet-B0.

</details>


### [33] [NSW-EPNews: A News-Augmented Benchmark for Electricity Price Forecasting with LLMs](https://arxiv.org/abs/2506.11050)
*Zhaoge Bi, Linghan Huang, Haolin Jin, Qingwen Zeng, Huaming Chen*

**主要类别:** cs.LG

**AI概要:** 该论文介绍了NSW-EPNews，这是一个新的基准数据集，用于评估时间序列模型和大型语言模型（LLMs）在现实世界电力价格预测中的表现。研究发现对于传统模型来说，新闻特征带来的增益很小；而对于最先进的LLMs，虽然性能有所提升但也经常产生错误的预测结果。


<details>
  <summary>更多</summary>
  
**动机:** 现有的电价预测方法主要依赖于数值历史而忽略了同期文本信号的影响。为了解决这一问题，并且为了提供一个能够联合评估时间序列模型与大型语言模型（LLMs）在实际电力价格预测上表现的平台，研究者们提出了NSW-EPNews这一新基准。

**方法:** 通过收集2015年至2024年间来自澳大利亚新南威尔士州的超过175,000个半小时点电价数据、每日温度读数以及精选的市场新闻摘要构建了NSW-EPNews数据集。将任务定义为基于多模态输入进行48步提前预测，其中包括滞后价格、向量化的新闻与天气特性给经典模型使用，以及为LLMs设计的结构化上下文提示工程。

**结果:** 研究表明，对于传统的统计学和机器学习模型而言，加入新闻特征所带来的改进非常有限；而针对像GPT-4o和Gemini 1.5 Pro这样的最先进LLMs，则观察到了一定的性能提升，但同时也发现了这些模型频繁地生成错误或不正确的电价序列。

**结论:** NSW-EPNews为在多模态环境中评估基于事实的数值推理提供了严格的测试平台，并揭示了当前LLM能力与高风险能源预测需求之间存在的关键差距。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NSW-EPNews%3A+A+News-Augmented+Benchmark+for+Electricity+Price+Forecasting+with+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11050，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11050&send_immediately=true&force_search=false)

**原文摘要:** Electricity price forecasting is a critical component of modern
energy-management systems, yet existing approaches heavily rely on numerical
histories and ignore contemporaneous textual signals. We introduce NSW-EPNews,
the first benchmark that jointly evaluates time-series models and large
language models (LLMs) on real-world electricity-price prediction. The dataset
includes over 175,000 half-hourly spot prices from New South Wales, Australia
(2015-2024), daily temperature readings, and curated market-news summaries from
WattClarity. We frame the task as 48-step-ahead forecasting, using multimodal
input, including lagged prices, vectorized news and weather features for
classical models, and prompt-engineered structured contexts for LLMs. Our
datasets yields 3.6k multimodal prompt-output pairs for LLM evaluation using
specific templates. Through compresive benchmark design, we identify that for
traditional statistical and machine learning models, the benefits gain is
marginal from news feature. For state-of-the-art LLMs, such as GPT-4o and
Gemini 1.5 Pro, we observe modest performance increase while it also produce
frequent hallucinations such as fabricated and malformed price sequences.
NSW-EPNews provides a rigorous testbed for evaluating grounded numerical
reasoning in multimodal settings, and highlights a critical gap between current
LLM capabilities and the demands of high-stakes energy forecasting.

</details>


### [34] [ACCORD: Autoregressive Constraint-satisfying Generation for COmbinatorial Optimization with Routing and Dynamic attention](https://arxiv.org/abs/2506.11052)
*Henrik Abgaryan, Tristan Cazenave, Ararat Harutyunyan*

**主要类别:** cs.LG

**AI概要:** 研究了大型语言模型（LLMs）在NP难题组合优化任务中的推理能力，并提出了ACCORD方法，该方法利用自回归约束生成和基于注意力的路由来解决这些问题。实验表明，基于80亿参数Llama模型的ACCORD，在六个NP难题上优于标准提示和输入输出方法，甚至与更大的模型如gpt-4相比也是如此。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLMs）展现出了令人印象深刻的推理能力，但它们直接应用于NP难题组合问题尚未得到充分探索。

**方法:** 提出了一种名为ACCORD的新方法，它包括一种新颖的数据集表示形式和模型架构，利用了LLMs的自回归特性来动态地强制执行可行性约束，并结合了基于注意力的路由来激活特定于问题的LoRA模块。此外，还介绍了一个名为ACCORD-90k的监督数据集，涵盖了六个NP难题组合问题。

**结果:** 广泛的实验证明，基于80亿参数Llama模型构建的ACCORD模型在多个NP难题组合优化问题上始终优于标准提示和输入输出方法，即使与像gpt-4这样的更大规模的语言模型相比也表现出色。消融研究表明，所提出的输出结构提高了解决方案的可行性。

**结论:** 这是首次大规模、端到端地探索LLMs在广泛组合优化问题中应用的框架，并且代码已公开可用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ACCORD%3A+Autoregressive+Constraint-satisfying+Generation+for+COmbinatorial+Optimization+with+Routing+and+Dynamic+attention，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11052，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11052&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have demonstrated impressive reasoning
capabilities, yet their direct application to NP-hard combinatorial problems
(CPs) remains underexplored. In this work, we systematically investigate the
reasoning abilities of LLMs on a variety of NP-hard combinatorial optimization
tasks and introduce ACCORD: Autoregressive Constraint-satisfying generation for
COmbinatorial optimization with Routing and Dynamic attention. ACCORD features
a novel dataset representation and model architecture that leverage the
autoregressive nature of LLMs to dynamically enforce feasibility constraints,
coupled with attention-based routing to activate problem-specific LoRA modules.
We also present the ACCORD-90k supervised dataset, covering six NP-hard
combinatorial problems: TSP, VRP, Knapsack, FlowShop, JSSP, and BinPacking.
Extensive experiments demonstrate that our ACCORD model, built on an
8B-parameter Llama backbone, consistently outperforms standard prompting and
input-output methods, even when compared to much larger LLMs, such as gpt-4.
Ablation studies further show that our output structure enhances solution
feasibility. To the best of our knowledge, this is the first large-scale,
end-to-end framework for exploring the applications of LLMs to a broad spectrum
of combinatorial optimization problems. The codes are publicly available at
https://github.com/starjob42/ACCORD

</details>


### [35] [Bootstrapping your behavior: a new pretraining strategy for user behavior sequence data](https://arxiv.org/abs/2506.11053)
*Weichang Wu, Xiaolu Zhang, Jun Zhou, Yuchen Li, Wenwen Xia*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的用户行为序列预训练策略BYOB，它通过自动构建监督嵌入来总结未来时间窗口内的所有行为信息，从而消除了手动选择行为词汇的需要。实验表明，该方法在AUC上平均提高了3.9%，在训练吞吐量上提高了98.9%。在线部署两个月后，在支付宝移动应用的两个金融逾期风险预测任务中，KS分别比基线模型提高了约2.7%和7.1%，为蚂蚁集团减少了数百万美元的坏账风险。


<details>
  <summary>更多</summary>
  
**动机:** 当前的用户行为序列预训练方法依赖于预测行为分布，而这一过程的关键步骤是构建一个选定的行为词汇表。然而，这个手动过程不仅耗时费力，还容易产生偏差。此外，词汇量的限制也直接影响了模型的泛化能力。因此，研究者们希望找到一种能够自动构建监督信号的方法，以提高模型效率和性能。

**方法:** 本文介绍了一种名为Bootstrapping Your Behavior (BYOB)的新颖用户行为序列预训练策略。该策略通过预测一个自动构造的监督嵌入来汇总未来时间窗口内所有行为的信息，从而避免了手动选择行为词汇。实现过程中采用了学生-教师编码器方案来有效地构建预训练监督。

**结果:** 实验结果显示，BYOB方法在两个真实世界工业数据集上的八项下游任务中取得了显著效果，平均AUC提高了3.9%，训练吞吐量提升了98.9%。在线部署测试中，对于支付宝应用程序中的两项金融逾期风险预测任务，相较于基线模型，KS值分别提高了约2.7%和7.1%。

**结论:** 研究表明，BYOB方法能够在不依赖手工选择行为词汇的情况下有效提升用户行为序列模型的表现，并且在实际应用中展现出良好的性能改善以及对坏账风险的有效降低。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bootstrapping+your+behavior%3A+a+new+pretraining+strategy+for+user+behavior+sequence+data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11053，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11053&send_immediately=true&force_search=false)

**原文摘要:** User Behavior Sequence (UBS) modeling is crucial in industrial applications.
As data scale and task diversity grow, UBS pretraining methods have become
increasingly pivotal. State-of-the-art UBS pretraining methods rely on
predicting behavior distributions. The key step in these methods is
constructing a selected behavior vocabulary. However, this manual step is
labor-intensive and prone to bias. The limitation of vocabulary capacity also
directly affects models' generalization ability. In this paper, we introduce
Bootstrapping Your Behavior (\model{}), a novel UBS pretraining strategy that
predicts an automatically constructed supervision embedding summarizing all
behaviors' information within a future time window, eliminating the manual
behavior vocabulary selection. In implementation, we incorporate a
student-teacher encoder scheme to construct the pretraining supervision
effectively. Experiments on two real-world industrial datasets and eight
downstream tasks demonstrate that \model{} achieves an average improvement of
3.9\% in AUC and 98.9\% in training throughput. Notably, the model exhibits
meaningful attention patterns and cluster representations during pretraining
without any label supervision. In our online deployment over two months, the
pretrained model improves the KS by about 2.7\% and 7.1\% over the baseline
model for two financial overdue risk prediction tasks in the Alipay mobile
application, which reduces bad debt risk by millions of dollars for Ant group.

</details>


### [36] [Adaptive Composition of Machine Learning as a Service (MLaaS) for IoT Environments](https://arxiv.org/abs/2506.11054)
*Deepak Kanneganti, Sajib Mistry, Sheik Mohammad Mostakim Fattah, Aneesh Krishna, Monowar Bhuyan*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种自适应的MLaaS组合框架，该框架通过服务评估模型识别表现不佳的MLaaS服务，并通过候选选择模型筛选出最佳替代方案。采用上下文多臂赌博机优化策略逐步更新MLaaS组合，以应对IoT环境的变化，同时保持服务质量并减少从零开始重组计算成本。


<details>
  <summary>更多</summary>
  
**动机:** 物联网环境的动态特性对机器学习即服务（MLaaS）组合的长期有效性提出了挑战，包括数据分布波动（如概念漂移和数据异质性）以及系统需求变化（如可扩展性要求和资源限制）。

**方法:** 本文介绍了一个自适应MLaaS组合框架，它结合了用于识别性能不佳的MLaaS服务的服务评估模型和用于过滤最优替换的候选选择模型。此外，还开发了一种自适应组合机制，该机制使用基于上下文的多臂赌博机优化策略来递增地更新MLaaS组合。

**结果:** 在真实世界数据集上的实验结果表明，所提出的方法能够有效应对物联网环境中的变化，同时维持服务质量并降低重新组合的成本。

**结论:** 提出的自适应MLaaS组合框架能够无缝、高效且可扩展地应对物联网环境中的不确定性，持续适应不断变化的物联网约束条件，保证服务质量的同时减少了完全重新组合所需的计算开销。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Adaptive+Composition+of+Machine+Learning+as+a+Service+%28MLaaS%29+for+IoT+Environments，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11054，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11054&send_immediately=true&force_search=false)

**原文摘要:** The dynamic nature of Internet of Things (IoT) environments challenges the
long-term effectiveness of Machine Learning as a Service (MLaaS) compositions.
The uncertainty and variability of IoT environments lead to fluctuations in
data distribution, e.g., concept drift and data heterogeneity, and evolving
system requirements, e.g., scalability demands and resource limitations. This
paper proposes an adaptive MLaaS composition framework to ensure a seamless,
efficient, and scalable MLaaS composition. The framework integrates a service
assessment model to identify underperforming MLaaS services and a candidate
selection model to filter optimal replacements. An adaptive composition
mechanism is developed that incrementally updates MLaaS compositions using a
contextual multi-armed bandit optimization strategy. By continuously adapting
to evolving IoT constraints, the approach maintains Quality of Service (QoS)
while reducing the computational cost associated with recomposition from
scratch. Experimental results on a real-world dataset demonstrate the
efficiency of our proposed approach.

</details>


### [37] [PolyMicros: Bootstrapping a Foundation Model for Polycrystalline Material Structure](https://arxiv.org/abs/2506.11055)
*Michael Buzzy, Andreas Robertson, Peng Chen, Surya Kalidindi*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种新的机器学习方法，能够从极度稀疏和复杂的科学领域空间数据中学习。通过一种基于物理的数据增强方案，使用少量实验观察训练局部生成模型，并通过多样性管理策略来生成大规模且物理上多样化的数据集。利用这种方法构建了PolyMicros，这是第一个用于多晶材料的基础模型，可以解决3D实验显微镜加速方面的长期挑战。


<details>
  <summary>更多</summary>
  
**动机:** 在材料科学领域，虽然基础模型的进步有望革新新材料的发现、制造与设计，但成功案例往往局限于可轻松整理出数百万样本数据的材料类别（如原子结构）。对于许多结构和功能材料（例如介观结构金属合金），这样的数据集成本过高或难以构建，因此数据集仅限于非常少的例子。为了解决这一难题，研究者们提出了一个新颖的机器学习方法。

**方法:** 提出的方法包括一个由物理驱动的数据增强方案，该方案利用一组局部生成模型，这些模型甚至可以在仅有五个实验观测的情况下进行训练，并通过一个新的多样性管理策略来协调它们，从而生成一个大规模并且物理上多样化的大数据集。

**结果:** 研究人员利用所提出的方法建立了PolyMicros，这是首个针对多晶材料的基础模型，它在无需额外训练的情况下解决了多个长期存在的有关加速三维实验显微技术的问题。

**结论:** 新提出的机器学习方法及PolyMicros模型为处理极端稀疏且复杂的空间数据提供了有效手段，并在加速三维实验显微术方面展现了巨大潜力。此外，研究团队还公开了他们的模型和数据集供社区使用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PolyMicros%3A+Bootstrapping+a+Foundation+Model+for+Polycrystalline+Material+Structure，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11055，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11055&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in Foundation Models for Materials Science are poised to
revolutionize the discovery, manufacture, and design of novel materials with
tailored properties and responses. Although great strides have been made,
successes have been restricted to materials classes where multi-million sample
data repositories can be readily curated (e.g., atomistic structures).
Unfortunately, for many structural and functional materials (e.g., mesoscale
structured metal alloys), such datasets are too costly or prohibitive to
construct; instead, datasets are limited to very few examples. To address this
challenge, we introduce a novel machine learning approach for learning from
hyper-sparse, complex spatial data in scientific domains. Our core contribution
is a physics-driven data augmentation scheme that leverages an ensemble of
local generative models, trained on as few as five experimental observations,
and coordinates them through a novel diversity curation strategy to generate a
large-scale, physically diverse dataset. We utilize this framework to construct
PolyMicros, the first Foundation Model for polycrystalline materials (a
structural material class important across a broad range of industrial and
scientific applications). We demonstrate the utility of PolyMicros by zero-shot
solving several long standing challenges related to accelerating 3D
experimental microscopy. Finally, we make both our models and datasets openly
available to the community.

</details>


### [38] [xInv: Explainable Optimization of Inverse Problems](https://arxiv.org/abs/2506.11056)
*Sean Memery, Kevin Denamganai, Anna Kapron-King, Kartic Subr*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种方法，通过在可微模拟器中加入自然语言事件的生成机制，并利用语言模型从这些事件列表创建解释，以提高逆问题迭代优化过程对领域专家的可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管正向模型的可解释性和可理解性已经得到了相当大的发展，但逆问题的迭代优化过程对于领域专家来说仍然不够透明。

**方法:** 研究者们建议的方法是在一个可微分的模拟器中加入能够在其前向和后向传播过程中产生自然语言事件的功能。之后，使用语言模型将这些事件列表转化为人类可以理解的解释。

**结果:** 通过一个说明性的优化问题和一个涉及神经网络训练的例子展示了该方法的有效性。

**结论:** 该方法提供了一个新的途径来帮助领域专家更好地理解和解释逆问题求解中的迭代优化过程。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是xInv%3A+Explainable+Optimization+of+Inverse+Problems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11056，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11056&send_immediately=true&force_search=false)

**原文摘要:** Inverse problems are central to a wide range of fields, including healthcare,
climate science, and agriculture. They involve the estimation of inputs,
typically via iterative optimization, to some known forward model so that it
produces a desired outcome. Despite considerable development in the
explainability and interpretability of forward models, the iterative
optimization of inverse problems remains largely cryptic to domain experts. We
propose a methodology to produce explanations, from traces produced by an
optimizer, that are interpretable by humans at the abstraction of the domain.
The central idea in our approach is to instrument a differentiable simulator so
that it emits natural language events during its forward and backward passes.
In a post-process, we use a Language Model to create an explanation from the
list of events. We demonstrate the effectiveness of our approach with an
illustrative optimization problem and an example involving the training of a
neural network.

</details>


### [39] [STRCMP: Integrating Graph Structural Priors with Language Models for Combinatorial Optimization](https://arxiv.org/abs/2506.11057)
*Xijun Li, Jiexiang Yang, Jinghao Wang, Bo Peng, Jianguo Yao, Haibing Guan*

**主要类别:** cs.LG

**AI概要:** 本文提出STRCMP，一种基于大语言模型的结构感知算法发现框架，旨在解决组合优化问题。通过结合图神经网络和条件化于结构嵌入的大语言模型，STRCMP能够识别出以求解器特定代码形式存在的高性能算法，并通过进化精炼过程迭代优化生成的算法。在混合整数线性规划和布尔可满足性问题上的广泛评估表明，STRCMP在解决方案最优性和计算效率方面显著优于其他五种强神经和基于大语言模型的方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法通常忽视了组合优化(CO)问题中固有的关键结构先验知识，导致次优解和迭代效率低下。受到人类专家利用CO结构进行算法设计成功的启发，研究者们希望开发一种能够系统整合这些结构先验知识的新方法，以提高解决方案的质量和求解效率。

**方法:** 提出了STRCMP框架，它将一个用于从CO实例中提取结构嵌入的图神经网络(GNN)与根据这些嵌入调整后的大语言模型(LLM)相结合。LLM被用来识别以求解器特定代码形式存在的高性能算法。该复合架构确保了语法正确性、保留了问题拓扑结构，并符合自然语言目标。此外，还采用了一个进化精炼过程来迭代地优化所生成的算法。

**结果:** 通过使用九个基准数据集对混合整数线性规划和布尔可满足性问题进行了广泛的评估。结果表明，在解决方案最优性和计算效率两方面，提出的STRCMP明显优于五种强大的神经和基于大语言模型的方法。

**结论:** STRCMP作为一个新的结构感知算法发现框架，成功地利用了组合优化问题中的结构先验信息，从而在保证解决方案质量的同时提高了求解效率。这为未来处理NP难问题提供了有潜力的新途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是STRCMP%3A+Integrating+Graph+Structural+Priors+with+Language+Models+for+Combinatorial+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11057，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11057&send_immediately=true&force_search=false)

**原文摘要:** Combinatorial optimization (CO) problems, central to operation research and
theoretical computer science, present significant computational challenges due
to their NP-hard nature. While large language models (LLMs) have emerged as
promising tools for CO--either by directly generating solutions or synthesizing
solver-specific codes--existing approaches often neglect critical structural
priors inherent to CO problems, leading to suboptimality and iterative
inefficiency. Inspired by human experts' success in leveraging CO structures
for algorithm design, we propose STRCMP, a novel structure-aware LLM-based
algorithm discovery framework that systematically integrates structure priors
to enhance solution quality and solving efficiency. Our framework combines a
graph neural network (GNN) for extracting structural embeddings from CO
instances with an LLM conditioned on these embeddings to identify
high-performing algorithms in the form of solver-specific codes. This composite
architecture ensures syntactic correctness, preserves problem topology, and
aligns with natural language objectives, while an evolutionary refinement
process iteratively optimizes generated algorithm. Extensive evaluations across
Mixed Integer Linear Programming and Boolean Satisfiability problems, using
nine benchmark datasets, demonstrate that our proposed STRCMP outperforms five
strong neural and LLM-based methods by a large margin, in terms of both
solution optimality and computational efficiency. The code and learned model
will be publicly available upon the acceptance of the paper.

</details>


### [40] [ADAMIX: Adaptive Mixed-Precision Delta-Compression with Quantization Error Optimization for Large Language Models](https://arxiv.org/abs/2506.11087)
*Boya Xiong, Shuo Wang, Weifeng Ge, Guanhua Chen, Yun Chen*

**主要类别:** cs.LG

**AI概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ADAMIX%3A+Adaptive+Mixed-Precision+Delta-Compression+with+Quantization+Error+Optimization+for+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11087，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11087&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) achieve impressive performance on various
knowledge-intensive and complex reasoning tasks in different domains. In
certain scenarios like multi-tenant serving, a large number of LLMs finetuned
from the same base model are deployed to meet complex requirements for users.
Recent works explore delta-compression approaches to quantize and compress the
delta parameters between the customized LLM and the corresponding base model.
However, existing works either exhibit unsatisfactory performance at high
compression ratios or depend on empirical bit allocation schemes. In this work,
we propose ADAMIX, an effective adaptive mixed-precision delta-compression
framework. We provide a mathematical derivation of quantization error to
motivate our mixed-precision compression strategy and formulate the optimal
mixed-precision bit allocation scheme as the solution to a 0/1 integer linear
programming problem. Our derived bit allocation strategy minimizes the
quantization error while adhering to a predefined compression ratio
requirement. Experimental results on various models and benchmarks demonstrate
that our approach surpasses the best baseline by a considerable margin. On
tasks like AIME2024 and GQA, where the norm of $\Delta \mathbf{W}$ is large and
the base model lacks sufficient ability, ADAMIX outperforms the best baseline
Delta-CoMe by 22.3% and 6.1% with 7B models, respectively.

</details>


### [41] [Debiasing Online Preference Learning via Preference Feature Preservation](https://arxiv.org/abs/2506.11098)
*Dongyoung Kim, Jinsung Yoon, Jinwoo Shin, Jaehyung Kim*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的框架PFP（偏好特征保留），旨在保持人类偏好特征的分布，并在整个在线偏好学习过程中利用这些丰富的信号，从而减少大型语言模型在学习过程中对某些偏好的偏向性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的大规模语言模型（LLMs）偏好学习框架简化了人类偏好，使用二元配对比较和标量奖励，这可能导致LLMs的响应偏向于主要偏好特征，并且这种偏向在网络偏好学习步骤的迭代中会更加严重。

**方法:** PFP框架首先从离线的人类偏好数据中提取偏好特征并训练一个特征分类器；然后，通过训练过的分类器和分布保持优化，在在线学习期间为新输入指令映射适当的偏好特征；最后，通过将偏好特征融入系统提示中，使LLMs能够明确处理各种人类偏好，以此来训练LLM。

**结果:** 实验表明，PFP成功地减少了在线学习过程中的偏好特征偏差，因此在评估LLM一致性标准基准上比以前的偏好学习方法表现出更好的性能。

**结论:** PFP框架提供了一种有效的方法来解决偏好学习中的特征偏差问题，有助于提高大型语言模型与人类偏好的一致性和多样性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Debiasing+Online+Preference+Learning+via+Preference+Feature+Preservation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11098，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11098&send_immediately=true&force_search=false)

**原文摘要:** Recent preference learning frameworks for large language models (LLMs)
simplify human preferences with binary pairwise comparisons and scalar rewards.
This simplification could make LLMs' responses biased to mostly preferred
features, and would be exacerbated during the iterations of online preference
learning steps. To address these challenges, we propose a novel framework
coined PFP (Preference Feature Preservation). The key idea of PFP is
maintaining the distribution of human preference features and utilizing such
rich signals throughout the online preference learning process. Specifically,
PFP first extract preference features from offline pairwise human preference
data and trains a feature classifier. Then, using trained classifier and the
distribution preserving optimization, PFP maps appropriate preference features
for a new input instruction during online learning. Lastly, PFP trains LLM
using the existing preference learning method, by incorporating the preference
feature into system prompts and enabling LLM to explicitly handle various human
preferences. Our experiments demonstrate that PFP successfully mitigates the
bias in preference features during online learning, and hence achieves superior
performance compared to previous preference learning methods on standard
benchmarks to evaluate LLM alignment.

</details>


### [42] [Knowledge Graph Embeddings with Representing Relations as Annular Sectors](https://arxiv.org/abs/2506.11099)
*Huiling Zhu, Yingqi Zeng*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的基于极坐标的知识图谱嵌入模型SectorE，该模型将关系建模为环形扇区，并在其中嵌入实体点以编码层次结构。实验表明SectorE在多个数据集上具有竞争力的表现。


<details>
  <summary>更多</summary>
  
**动机:** 现有的知识图谱嵌入模型通常忽略了实体中固有的语义层次结构。

**方法:** 提出了一个名为SectorE的新颖嵌入模型，它使用极坐标系来表示实体和关系。在这个模型中，关系被建模为环形扇区，结合了模量和相位来捕捉推理模式和关系属性；实体则作为这些扇区内的点进行嵌入，直观地编码了层次结构。

**结果:** 通过在FB15k-237、WN18RR以及YAGO3-10三个基准数据集上的评估，SectorE展示了与各种类型模型相比的竞争性表现，尤其是在语义建模能力方面。

**结论:** SectorE提供了一种有效的方法来处理知识图谱中的语义层次结构问题，其在链接预测任务上的良好表现证明了这种方法的有效性和潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Knowledge+Graph+Embeddings+with+Representing+Relations+as+Annular+Sectors，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11099，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11099&send_immediately=true&force_search=false)

**原文摘要:** Knowledge graphs (KGs), structured as multi-relational data of entities and
relations, are vital for tasks like data analysis and recommendation systems.
Knowledge graph completion (KGC), or link prediction, addresses incompleteness
of KGs by inferring missing triples (h, r, t). It is vital for downstream
applications. Region-based embedding models usually embed entities as points
and relations as geometric regions to accomplish the task. Despite progress,
these models often overlook semantic hierarchies inherent in entities. To solve
this problem, we propose SectorE, a novel embedding model in polar coordinates.
Relations are modeled as annular sectors, combining modulus and phase to
capture inference patterns and relation attributes. Entities are embedded as
points within these sectors, intuitively encoding hierarchical structure.
Evaluated on FB15k-237, WN18RR, and YAGO3-10, SectorE achieves competitive
performance against various kinds of models, demonstrating strengths in
semantic modeling capability.

</details>


### [43] [An Active Learning-Based Streaming Pipeline for Reduced Data Training of Structure Finding Models in Neutron Diffractometry](https://arxiv.org/abs/2506.11100)
*Tianle Wang, Jorge Ramirez, Cristina Garcia-Cardona, Thomas Proffen, Shantenu Jha, Sudip K. Seal*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的批量模式主动学习策略，通过不确定性采样减少训练数据量并提高模型准确性，并设计了高效的流式训练工作流程，与传统训练相比缩短了约20%的训练时间且没有损失精度。


<details>
  <summary>更多</summary>
  
**动机:** 中子衍射仪中的结构确定工作负载在计算上非常昂贵，通常需要数小时到数天才能从材料的中子衍射图案确定其结构。最近有报道称基于模拟中子散射图案训练的机器学习模型能够显著加速这些任务。但是，随着要预测的结构参数数量增加，训练这些模型所需的模拟数据量呈指数级增长，构成了重大的计算挑战。

**方法:** 引入了一种新颖的批量模式主动学习（AL）策略，该策略使用不确定性采样从一个概率分布中抽取训练数据，这个分布更倾向于那些模型最不确定的标记样本。

**结果:** 确认了这种策略的有效性，它能够在减少约75%训练数据的同时提高模型准确性。此外，还讨论了一个利用此AL策略设计的高效流式训练工作流，并展示了在两个异构平台上的性能研究，表明相比于传统的训练工作流，流式工作流可以缩短大约20%的训练时间而不损失任何精度。

**结论:** 新提出的批量模式主动学习策略有效减少了训练所需的数据量，并提高了模型的准确性；同时，采用该策略的流式训练工作流相较于传统方法能显著降低训练时间。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Active+Learning-Based+Streaming+Pipeline+for+Reduced+Data+Training+of+Structure+Finding+Models+in+Neutron+Diffractometry，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11100，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11100&send_immediately=true&force_search=false)

**原文摘要:** Structure determination workloads in neutron diffractometry are
computationally expensive and routinely require several hours to many days to
determine the structure of a material from its neutron diffraction patterns.
The potential for machine learning models trained on simulated neutron
scattering patterns to significantly speed up these tasks have been reported
recently. However, the amount of simulated data needed to train these models
grows exponentially with the number of structural parameters to be predicted
and poses a significant computational challenge. To overcome this challenge, we
introduce a novel batch-mode active learning (AL) policy that uses uncertainty
sampling to simulate training data drawn from a probability distribution that
prefers labelled examples about which the model is least certain. We confirm
its efficacy in training the same models with about 75% less training data
while improving the accuracy. We then discuss the design of an efficient
stream-based training workflow that uses this AL policy and present a
performance study on two heterogeneous platforms to demonstrate that, compared
with a conventional training workflow, the streaming workflow delivers about
20% shorter training time without any loss of accuracy.

</details>


### [44] [PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation](https://arxiv.org/abs/2506.11170)
*Ching Chang, Ming-Chih Lo, Wen-Chih Peng, Tien-Fu Chen*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的时间序列分割框架PromptTSS，能够处理多粒度状态并适应动态环境中的新演化模式。实验表明该方法在多粒度分割、单粒度分割和迁移学习中均有显著的准确率提升。


<details>
  <summary>更多</summary>
  
**动机:** 现有的时间序列分割方法无法在一个统一模型内处理多个粒度级别，并且对动态环境中出现的新模式适应性有限。为了解决这些挑战，本文提出了一个名为PromptTSS的新框架。

**方法:** PromptTSS框架使用了一个带有提示机制的统一模型，该机制利用标签和边界信息来指导分割过程，同时捕捉粗略和精细的模式，并能动态地适应未见的模式。

**结果:** 实验结果显示，与现有方法相比，PromptTSS在多粒度分割上的准确性提高了24.49%，在单粒度分割上提高了17.88%，而在迁移学习任务中则最高提升了599.24%。

**结论:** PromptTSS不仅能够有效解决多粒度时间序列数据的分割问题，还表现出对层次化状态和演变的时间序列动态的良好适应性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PromptTSS%3A+A+Prompting-Based+Approach+for+Interactive+Multi-Granularity+Time+Series+Segmentation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11170，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11170&send_immediately=true&force_search=false)

**原文摘要:** Multivariate time series data, collected across various fields such as
manufacturing and wearable technology, exhibit states at multiple levels of
granularity, from coarse-grained system behaviors to fine-grained, detailed
events. Effectively segmenting and integrating states across these different
granularities is crucial for tasks like predictive maintenance and performance
optimization. However, existing time series segmentation methods face two key
challenges: (1) the inability to handle multiple levels of granularity within a
unified model, and (2) limited adaptability to new, evolving patterns in
dynamic environments. To address these challenges, we propose PromptTSS, a
novel framework for time series segmentation with multi-granularity states.
PromptTSS uses a unified model with a prompting mechanism that leverages label
and boundary information to guide segmentation, capturing both coarse- and
fine-grained patterns while adapting dynamically to unseen patterns.
Experiments show PromptTSS improves accuracy by 24.49% in multi-granularity
segmentation, 17.88% in single-granularity segmentation, and up to 599.24% in
transfer learning, demonstrating its adaptability to hierarchical states and
evolving time series dynamics.

</details>


### [45] [Collapsing Sequence-Level Data-Policy Coverage via Poisoning Attack in Offline Reinforcement Learning](https://arxiv.org/abs/2506.11172)
*Xue Zhou, Dapeng Man, Chen Xu, Fanyi Zeng, Tao Liu, Huan Wang, Shucheng He, Chaoyang Gao, Wu Yang*

**主要类别:** cs.LG

**AI概要:** 本文提出了序列级集中性系数来量化离线强化学习中的数据策略覆盖，并基于此发现设计了一种称为CSDPC的中毒攻击，该攻击通过污染少量数据即可显著降低代理性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的离线强化学习研究试图改善数据-策略覆盖来减少分布偏移，但忽视了覆盖不足带来的安全风险，并且单步分析不符合离线RL的多步决策特性。

**方法:** 引入序列级集中性系数来度量覆盖情况，并通过理论分析揭示它对估计误差上限的影响。提出CSDPC中毒攻击，将状态-动作对转换为决策单元，提取代表性的决策模式，然后识别并污染那些可能导致覆盖不足的罕见模式。

**结果:** 实验证明，仅需污染1%的数据集就能使代理性能下降90%。

**结论:** 这项研究为离线强化学习的安全性分析和保护提供了新的视角。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Collapsing+Sequence-Level+Data-Policy+Coverage+via+Poisoning+Attack+in+Offline+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11172，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11172&send_immediately=true&force_search=false)

**原文摘要:** Offline reinforcement learning (RL) heavily relies on the coverage of
pre-collected data over the target policy's distribution. Existing studies aim
to improve data-policy coverage to mitigate distributional shifts, but overlook
security risks from insufficient coverage, and the single-step analysis is not
consistent with the multi-step decision-making nature of offline RL. To address
this, we introduce the sequence-level concentrability coefficient to quantify
coverage, and reveal its exponential amplification on the upper bound of
estimation errors through theoretical analysis. Building on this, we propose
the Collapsing Sequence-Level Data-Policy Coverage (CSDPC) poisoning attack.
Considering the continuous nature of offline RL data, we convert state-action
pairs into decision units, and extract representative decision patterns that
capture multi-step behavior. We identify rare patterns likely to cause
insufficient coverage, and poison them to reduce coverage and exacerbate
distributional shifts. Experiments show that poisoning just 1% of the dataset
can degrade agent performance by 90%. This finding provides new perspectives
for analyzing and safeguarding the security of offline RL.

</details>


### [46] [Detection of obstructions in oil and gas pipelines: machine learning techniques for hydrate classification](https://arxiv.org/abs/2506.11220)
*Hellockston Gomes de Brito, Carla Wilza Souza de Paula Maitelli, Osvaldo Chiavone-Filho*

**主要类别:** cs.LG

**AI概要:** 该研究使用监督机器学习技术，特别是决策树、k-最近邻(k-NN)算法和朴素贝叶斯分类器方法来检测并缓解油气生产中的流动保障问题，重点是防止天然气水合物的形成。研究表明决策树算法在预测水合物形成方面表现出最高的准确性（99.99%）。


<details>
  <summary>更多</summary>
  
**动机:** 油气资源对全球经济至关重要，但其开采和生产过程中会遇到多种挑战，如沉积物堆积、蜡沉积、矿物结垢和腐蚀导致的管线堵塞。本研究旨在通过应用监督机器学习技术来解决这些问题，尤其是预防油气生产系统中天然气水合物的形成，以确保流体输送的效率。

**方法:** 本研究采用了监督机器学习技术，包括决策树、k-最近邻(k-NN)算法以及朴素贝叶斯分类器，用于识别和减少影响油气生产的流动保障问题。数据预处理和清洗步骤被实施以保证从Petrobras公开的3W项目GitHub仓库获取的数据集的质量与一致性。利用scikit-learn Python库执行分类任务。

**结果:** 结果表明所提出的方法能够有效地根据操作条件对水合物形成进行分类，其中决策树算法显示了最高的预测准确率（99.99%）。

**结论:** 这项研究提供了一种可靠的方法来优化生产效率，特别是在预防油气生产系统中天然气水合物形成的问题上。采用决策树算法表现出了极高的预测精度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Detection+of+obstructions+in+oil+and+gas+pipelines%3A+machine+learning+techniques+for+hydrate+classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11220，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11220&send_immediately=true&force_search=false)

**原文摘要:** Oil and gas reserves are vital resources for the global economy, serving as
key components in transportation, energy production, and industrial processes.
However, oil and gas extraction and production operations may encounter several
challenges, such as pipeline and production line blockages, caused by factors
including sediment accumulation, wax deposition, mineral scaling, and
corrosion. This study addresses these challenges by employing supervised
machine learning techniques, specifically decision trees, the k-Nearest
Neighbors (k-NN) algorithm (k-NN), and the Naive Bayes classifier method, to
detect and mitigate flow assurance challenges, ensuring efficient fluid
transport. The primary focus is on preventing gas hydrate formation in oil
production systems. To achieve this, data preprocessing and cleaning were
conducted to ensure the quality and consistency of the dataset, which was
sourced from Petrobras publicly available 3W project repository on GitHub. The
scikit-learn Python library, a widely recognized open-source tool for
supervised machine learning techniques, was utilized for classification tasks
due to its robustness and versatility. The results demonstrate that the
proposed methodology effectively classifies hydrate formation under operational
conditions, with the decision tree algorithm exhibiting the highest predictive
accuracy (99.99 percent). Consequently, this approach provides a reliable
solution for optimizing production efficiency.

</details>


### [47] [uPVC-Net: A Universal Premature Ventricular Contraction Detection Deep Learning Algorithm](https://arxiv.org/abs/2506.11238)
*Hagai Hamami, Yosef Solewicz, Daniel Zur, Yonatan Kleerekoper, Joachim A. Behar*

**主要类别:** cs.LG

**AI概要:** 研究开发了uPVC-Net，一种深度学习模型，可以从任何单导联心电图记录中检测室性早搏（PVCs），并在不同数据集上展示了强大的泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 由于心电图波形的变异性，准确检测室性早搏（PVCs）仍然是一个挑战。这些变异可能由导联放置、记录条件和人口统计学差异引起。

**方法:** 研究人员开发了uPVC-Net，这是一种通用的深度学习模型，用于从任意单导联心电图记录中检测PVCs。该模型基于四个独立的心电图数据集进行开发，包括来自Holter监测器和现代可穿戴心电图贴片的总计830万个心跳。uPVC-Net采用了定制架构和多源多导联训练策略，并在每次实验中保留一个数据集以评估其分布外（OOD）泛化能力。

**结果:** uPVC-Net在留出的数据集上实现了97.8%到99.1%之间的AUC。值得注意的是，在可穿戴单导联心电图数据上的表现达到了99.1%的AUC。

**结论:** uPVC-Net展现了跨多种导联配置和人群的强大泛化能力，突出了它在实际临床部署中的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是uPVC-Net%3A+A+Universal+Premature+Ventricular+Contraction+Detection+Deep+Learning+Algorithm，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11238，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11238&send_immediately=true&force_search=false)

**原文摘要:** Introduction: Premature Ventricular Contractions (PVCs) are common cardiac
arrhythmias originating from the ventricles. Accurate detection remains
challenging due to variability in electrocardiogram (ECG) waveforms caused by
differences in lead placement, recording conditions, and population
demographics. Methods: We developed uPVC-Net, a universal deep learning model
to detect PVCs from any single-lead ECG recordings. The model is developed on
four independent ECG datasets comprising a total of 8.3 million beats collected
from Holter monitors and a modern wearable ECG patch. uPVC-Net employs a custom
architecture and a multi-source, multi-lead training strategy. For each
experiment, one dataset is held out to evaluate out-of-distribution (OOD)
generalization. Results: uPVC-Net achieved an AUC between 97.8% and 99.1% on
the held-out datasets. Notably, performance on wearable single-lead ECG data
reached an AUC of 99.1%. Conclusion: uPVC-Net exhibits strong generalization
across diverse lead configurations and populations, highlighting its potential
for robust, real-world clinical deployment.

</details>


### [48] [A Causal Lens for Learning Long-term Fair Policies](https://arxiv.org/abs/2506.11242)
*Jacob Lear, Lu Zhang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种在强化学习背景下的一般框架，用于衡量长期公平性，并通过因果视角将其分解为直接影响、延迟影响和虚假效应三个部分。研究了这些成分与一种新兴的公平概念——利益公平之间的内在联系，并开发了一种简单而有效的方法来平衡各种公平概念。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大多数研究都集中在静态环境下的直接偏见上，但本文强调了在动态决策系统中同时考虑长期公平性和瞬时公平性要求的重要性。

**方法:** 本文在强化学习的背景下提出了一种通用框架，其中长期公平性是通过不同群体能够获得的平均预期资格收益差异来衡量的。然后，从因果关系的角度，将这一度量分解成代表政策对资格收益直接冲击、延迟冲击以及虚假效应的三个组成部分。

**结果:** 分析了这些组成部分与旨在控制决策结果平等的一种新兴公平观念——效益公平之间的内在联系。

**结论:** 最后，开发了一种简单却有效的办法来平衡不同的公平观念。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Causal+Lens+for+Learning+Long-term+Fair+Policies，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11242，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11242&send_immediately=true&force_search=false)

**原文摘要:** Fairness-aware learning studies the development of algorithms that avoid
discriminatory decision outcomes despite biased training data. While most
studies have concentrated on immediate bias in static contexts, this paper
highlights the importance of investigating long-term fairness in dynamic
decision-making systems while simultaneously considering instantaneous fairness
requirements. In the context of reinforcement learning, we propose a general
framework where long-term fairness is measured by the difference in the average
expected qualification gain that individuals from different groups could
obtain.Then, through a causal lens, we decompose this metric into three
components that represent the direct impact, the delayed impact, as well as the
spurious effect the policy has on the qualification gain. We analyze the
intrinsic connection between these components and an emerging fairness notion
called benefit fairness that aims to control the equity of outcomes in
decision-making. Finally, we develop a simple yet effective approach for
balancing various fairness notions.

</details>


### [49] [Can Time-Series Foundation Models Perform Building Energy Management Tasks?](https://arxiv.org/abs/2506.11250)
*Ozan Baris Mulayim, Pengrui Quan, Liying Han, Xiaomin Ouyang, Dezhi Hong, Mario Bergés, Mani Srivastava*

**主要类别:** cs.LG

**AI概要:** 本文评估了时间序列基础模型(TSFMs)在建筑能源管理(BEM)任务中的表现，发现TSFMs在零样本单变量预测、包含协变量的热行为建模、零样本表示学习用于分类任务以及对性能指标和变化操作条件的鲁棒性等四个维度上的泛化能力有限。


<details>
  <summary>更多</summary>
  
**动机:** 受到大型语言模型（LLMs）成功转型的启发，研究人员希望通过研究时间序列基础模型（TSFMs）来解决建筑能源管理（BEM）中普遍存在的可扩展性挑战。

**方法:** 论文通过四个维度评估了TSFMs：(1) 零样本单变量预测的通用性；(2) 包含协变量以进行热行为建模的预测；(3) 分类任务的零样本表示学习；(4) 对性能指标和不同操作条件的鲁棒性。

**结果:** 结果显示，TSFMs在未见数据集和单变量预测模式下的泛化能力有限，仅略优于统计模型。当加入协变量时，TSFMs的表现没有改进，并且其性能仍低于利用协变量的传统模型。尽管TSFMs为下游分类任务生成了有效的零样本表示，但在测试时拟合的情况下它们可能不如统计模型。此外，TSFMs的预测性能对于评估指标敏感，在更复杂的建筑环境中与统计模型相比表现不佳。

**结论:** 这些发现强调了TSFMs设计需要有针对性的进步，特别是在处理协变量以及将上下文和时间动态纳入预测机制方面，以便开发出更加适应性和可扩展性的BEM解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Can+Time-Series+Foundation+Models+Perform+Building+Energy+Management+Tasks%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11250，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11250&send_immediately=true&force_search=false)

**原文摘要:** Building energy management (BEM) tasks require processing and learning from a
variety of time-series data. Existing solutions rely on bespoke task- and
data-specific models to perform these tasks, limiting their broader
applicability. Inspired by the transformative success of Large Language Models
(LLMs), Time-Series Foundation Models (TSFMs), trained on diverse datasets,
have the potential to change this. Were TSFMs to achieve a level of
generalizability across tasks and contexts akin to LLMs, they could
fundamentally address the scalability challenges pervasive in BEM. To
understand where they stand today, we evaluate TSFMs across four dimensions:
(1) generalizability in zero-shot univariate forecasting, (2) forecasting with
covariates for thermal behavior modeling, (3) zero-shot representation learning
for classification tasks, and (4) robustness to performance metrics and varying
operational conditions. Our results reveal that TSFMs exhibit \emph{limited}
generalizability, performing only marginally better than statistical models on
unseen datasets and modalities for univariate forecasting. Similarly, inclusion
of covariates in TSFMs does not yield performance improvements, and their
performance remains inferior to conventional models that utilize covariates.
While TSFMs generate effective zero-shot representations for downstream
classification tasks, they may remain inferior to statistical models in
forecasting when statistical models perform test-time fitting. Moreover, TSFMs
forecasting performance is sensitive to evaluation metrics, and they struggle
in more complex building environments compared to statistical models. These
findings underscore the need for targeted advancements in TSFM design,
particularly their handling of covariates and incorporating context and
temporal dynamics into prediction mechanisms, to develop more adaptable and
scalable solutions for BEM.

</details>


### [50] [Domain-Constrained Diffusion Models to Synthesize Tabular Data: A Case Study in Power Systems](https://arxiv.org/abs/2506.11281)
*Milad Hoseinpour, Vladimir Dvorkin*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种结合领域约束的引导扩散模型来合成数据，特别适用于如电力系统等涉及表格数据的领域，并通过梯度引导保证生成的数据满足领域要求，例如基尔霍夫定律。


<details>
  <summary>更多</summary>
  
**动机:** 由于隐私、安全和法律障碍日益受到关注，对合成数据的需求正在增长，特别是在医疗保健、金融和能源等领域。尽管生成模型提供了解决这些问题的方案，但其效用取决于领域特定知识的融入。

**方法:** 作者提出使用一种引导扩散模型来合成数据，该模型直接将领域约束整合到生成过程中。他们开发了这一模型以应用于电力系统，并可能推广到其他包含表格数据的领域。为了满足领域约束，比如遵守基尔霍夫定律，研究者引入了基于梯度的引导方法来调整采样轨迹朝向可行的方向。

**结果:** 数值结果表明，所提出的方法能够有效地生成既具有统计代表性又高保真的潮流数据集。

**结论:** 通过将领域特定的知识直接整合进生成过程，提出的引导扩散模型可以有效生成符合领域约束条件（如基尔霍夫定律）的合成数据，为解决跨领域的数据共享问题提供了新途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Domain-Constrained+Diffusion+Models+to+Synthesize+Tabular+Data%3A+A+Case+Study+in+Power+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11281，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11281&send_immediately=true&force_search=false)

**原文摘要:** Growing concerns over privacy, security, and legal barriers are driving the
rising demand for synthetic data across domains such as healthcare, finance,
and energy. While generative models offer a promising solution to overcome
these barriers, their utility depends on the incorporation of domain-specific
knowledge. We propose to synthesize data using a guided diffusion model that
integrates domain constraints directly into the generative process. We develop
the model in the context of power systems, with potential applicability to
other domains that involve tabular data. Specifically, we synthesize
statistically representative and high-fidelity power flow datasets. To satisfy
domain constraints, e.g., Kirchhoff laws, we introduce a gradient-based
guidance to steer the sampling trajectory in a feasible direction. Numerical
results demonstrate the effectiveness of our approach.

</details>


### [51] [Sampling Imbalanced Data with Multi-objective Bilevel Optimization](https://arxiv.org/abs/2506.11315)
*Karen Medlin, Sven Leyffer, Krishnan Raghavan*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的多目标双层优化框架MOODS，用于指导合成过采样和多数类欠采样，并引入了一个验证指标ε/δ非重叠多样化度量，该度量能够量化采样方法对模型性能的影响。实验结果表明，通过提高多样性，F1分数提高了1-15%。


<details>
  <summary>更多</summary>
  
**动机:** 传统的处理二分类不平衡问题的方法如重新加权损失函数或简单的重采样存在过拟合风险，且没有考虑多数类和少数类数据集之间的多样性，因为缺乏衡量这种不平衡对模型影响的度量标准。

**方法:** 提出了一个多目标双层优化框架MOODS，旨在同时指导合成过采样和多数类欠采样；并且设计了一个名为ε/δ非重叠多样化度量的新验证指标，用以评估采样方法对模型性能的好坏。

**结果:** 实验结果显示，使用提出的MOODS框架和ε/δ非重叠多样化度量可以提升模型性能，具体表现为F1分数增加了1-15%。

**结论:** 本文介绍的方法为解决二分类不平衡问题提供了一个有效途径，通过优化采样策略和引入新的度量标准来增强模型的多样性和整体表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sampling+Imbalanced+Data+with+Multi-objective+Bilevel+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11315，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11315&send_immediately=true&force_search=false)

**原文摘要:** Two-class classification problems are often characterized by an imbalance
between the number of majority and minority datapoints resulting in poor
classification of the minority class in particular. Traditional approaches,
such as reweighting the loss function or na\"ive resampling, risk overfitting
and subsequently fail to improve classification because they do not consider
the diversity between majority and minority datasets. Such consideration is
infeasible because there is no metric that can measure the impact of imbalance
on the model. To obviate these challenges, we make two key contributions.
First, we introduce MOODS~(Multi-Objective Optimization for Data Sampling), a
novel multi-objective bilevel optimization framework that guides both synthetic
oversampling and majority undersampling. Second, we introduce a validation
metric -- `$\epsilon/ \delta$ non-overlapping diversification metric' -- that
quantifies the goodness of a sampling method towards model performance. With
this metric we experimentally demonstrate state-of-the-art performance with
improvement in diversity driving a $1-15 \%$ increase in $F1$ scores.

</details>


### [52] [An Attention-based Spatio-Temporal Neural Operator for Evolving Physics](https://arxiv.org/abs/2506.11328)
*Vispi Karkaria, Doksoo Lee, Yi-Ping Chen, Yue Yu, Wei Chen*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的架构ASNO，它结合了可分离的注意力机制来处理空间和时间交互，并适应未知的物理参数。通过在SciML基准测试中的实证结果表明，ASNO优于现有模型，具有应用于工程、物理发现和可解释机器学习的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 科学机器学习（SciML）中的一个关键挑战是学习未知且不断演变的物理过程，并进行跨时空尺度的预测。例如，在现实世界的制造问题中，如增材制造，用户调整已知的机器设置时，未知的环境参数同时波动。为了做出可靠的预测，需要模型不仅能够从数据中捕捉到长距离时空交互，而且能够适应新和未知的环境；传统机器学习模型擅长第一个任务，但往往缺乏物理可解释性，并且难以在变化的环境条件下泛化。

**方法:** 为了解决这些挑战，提出了基于注意力机制的时空神经算子（ASNO），这是一种新颖的架构，结合了用于空间和时间交互的可分离注意力机制，并能适应未见的物理参数。受到后向差分公式（BDF）的启发，ASNO学习了一个用于时间预测和外推的transformer以及一个基于注意力机制的神经算子来处理变化的外部负载。

**结果:** 通过隔离历史状态贡献和外部力增强了可解释性，使基础物理定律的发现成为可能，并对未见物理环境具有泛化能力。在SciML基准上的实证结果显示，ASNO超过了现有的模型。

**结论:** ASNO架构在解决科学机器学习中的挑战方面展现出了巨大的潜力，尤其是在提高模型对于未知环境的适应性和增强物理可解释性方面。这表明ASNO在工程应用、物理学发现及可解释的机器学习领域具有广泛的应用前景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Attention-based+Spatio-Temporal+Neural+Operator+for+Evolving+Physics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11328，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11328&send_immediately=true&force_search=false)

**原文摘要:** In scientific machine learning (SciML), a key challenge is learning unknown,
evolving physical processes and making predictions across spatio-temporal
scales. For example, in real-world manufacturing problems like additive
manufacturing, users adjust known machine settings while unknown environmental
parameters simultaneously fluctuate. To make reliable predictions, it is
desired for a model to not only capture long-range spatio-temporal interactions
from data but also adapt to new and unknown environments; traditional machine
learning models excel at the first task but often lack physical
interpretability and struggle to generalize under varying environmental
conditions. To tackle these challenges, we propose the Attention-based
Spatio-Temporal Neural Operator (ASNO), a novel architecture that combines
separable attention mechanisms for spatial and temporal interactions and adapts
to unseen physical parameters. Inspired by the backward differentiation formula
(BDF), ASNO learns a transformer for temporal prediction and extrapolation and
an attention-based neural operator for handling varying external loads,
enhancing interpretability by isolating historical state contributions and
external forces, enabling the discovery of underlying physical laws and
generalizability to unseen physical environments. Empirical results on SciML
benchmarks demonstrate that ASNO outperforms over existing models, establishing
its potential for engineering applications, physics discovery, and
interpretable machine learning.

</details>


### [53] [The Sample Complexity of Parameter-Free Stochastic Convex Optimization](https://arxiv.org/abs/2506.11336)
*Jared Lawrence, Ari Kalinsky, Hannah Bradfield, Yair Carmon, Oliver Hinder*

**主要类别:** cs.LG

**AI概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Sample+Complexity+of+Parameter-Free+Stochastic+Convex+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11336，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11336&send_immediately=true&force_search=false)

**原文摘要:** We study the sample complexity of stochastic convex optimization when problem
parameters, e.g., the distance to optimality, are unknown. We pursue two
strategies. First, we develop a reliable model selection method that avoids
overfitting the validation set. This method allows us to generically tune the
learning rate of stochastic optimization methods to match the optimal
known-parameter sample complexity up to $\log\log$ factors. Second, we develop
a regularization-based method that is specialized to the case that only the
distance to optimality is unknown. This method provides perfect adaptability to
unknown distance to optimality, demonstrating a separation between the sample
and computational complexity of parameter-free stochastic convex optimization.
Combining these two methods allows us to simultaneously adapt to multiple
problem structures.
  Experiments performing few-shot learning on CIFAR-10 by fine-tuning CLIP
models and prompt engineering Gemini to count shapes indicate that our reliable
model selection method can help mitigate overfitting to small validation sets.

</details>


### [54] [Improving Group Robustness on Spurious Correlation via Evidential Alignment](https://arxiv.org/abs/2506.11347)
*Wenqian Ye, Guangtao Zheng, Aidong Zhang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为证据对齐的新框架，该框架利用不确定性量化来理解存在偏差的模型行为，而不需要群体注释。通过使用二阶风险最小化量化模型预测的证据，并用提出的证据校准技术校准有偏模型，证据对齐可以识别并抑制虚假相关性同时保留核心特征。


<details>
  <summary>更多</summary>
  
**动机:** 深度神经网络通常学习和依赖于虚假相关性，即非因果特征与目标之间的表面关联。例如，一个图像分类器可能根据沙漠背景来识别骆驼。虽然这可以在训练期间产生较高的整体准确性，但它会降低在没有这些关联的更多样化场景中的泛化能力。这个问题对于分布外鲁棒性和可信度提出了重大挑战。

**方法:** 本文提出的方法是证据对齐（Evidential Alignment），它是一个新框架，利用不确定性量化来理解带有偏差的模型的行为，无需外部群体注释。通过第二阶风险最小化来量化模型预测的证据，并且使用所提出的证据校准技术来校准有偏模型。

**结果:** 实证结果表明，该方法显著提高了不同架构和数据模态下的组鲁棒性，为解决虚假相关性提供了一个可扩展和原则性的解决方案。

**结论:** 证据对齐是一种有效的方法，能够学习有偏模型的模式并在不需任何虚假相关性注释的情况下对模型进行去偏处理。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+Group+Robustness+on+Spurious+Correlation+via+Evidential+Alignment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11347，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11347&send_immediately=true&force_search=false)

**原文摘要:** Deep neural networks often learn and rely on spurious correlations, i.e.,
superficial associations between non-causal features and the targets. For
instance, an image classifier may identify camels based on the desert
backgrounds. While it can yield high overall accuracy during training, it
degrades generalization on more diverse scenarios where such correlations do
not hold. This problem poses significant challenges for out-of-distribution
robustness and trustworthiness. Existing methods typically mitigate this issue
by using external group annotations or auxiliary deterministic models to learn
unbiased representations. However, such information is costly to obtain, and
deterministic models may fail to capture the full spectrum of biases learned by
the models. To address these limitations, we propose Evidential Alignment, a
novel framework that leverages uncertainty quantification to understand the
behavior of the biased models without requiring group annotations. By
quantifying the evidence of model prediction with second-order risk
minimization and calibrating the biased models with the proposed evidential
calibration technique, Evidential Alignment identifies and suppresses spurious
correlations while preserving core features. We theoretically justify the
effectiveness of our method as capable of learning the patterns of biased
models and debiasing the model without requiring any spurious correlation
annotations. Empirical results demonstrate that our method significantly
improves group robustness across diverse architectures and data modalities,
providing a scalable and principled solution to spurious correlations.

</details>


### [55] [EDN: A Novel Edge-Dependent Noise Model for Graph Data](https://arxiv.org/abs/2506.11368)
*Pintu Kumar, Nandyala Hemachandra*

**主要类别:** cs.LG

**AI概要:** 本文介绍了Edge-Dependent Noise (EDN)模型，该模型认为在现实场景中节点的标签噪声可能受到节点间连接的影响。研究了三种EDN变体，并发现节点标签被污染的概率依赖于其度数。实验表明，两种EDN变体会导致图神经网络(GNNs)和现有抗噪算法的性能下降比传统节点标签噪声模型更严重。这强调了在评估图数据的抗噪算法时考虑EDN的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的节点标签噪声模型如对称标签噪声(SLN)和类条件噪声(CCN)忽略了图数据中重要的节点关系。而Edge-Dependent Noise (EDN) 模型解决了这一限制，假设在实际情况中标签噪声可能受到节点间连接的影响。

**方法:** 研究者探索了三种EDN变体，并展示了所有三种情况下节点标签被破坏的概率都与其度数相关。此外，他们比较了不同变体下这些概率对节点度数的依赖性。实验部分使用了5种不同的图神经网络架构和8种针对图数据的噪声鲁棒算法，在流行的图数据集上进行了测试。

**结果:** 实验结果表明，与传统的节点标签噪声模型相比，两种EDN变体会导致图神经网络（GNNs）和现有噪声鲁棒算法的性能更加恶化。通过构建适当的假设检验问题，统计验证了这一点。

**结论:** 将EDN纳入考量对于提高噪声环境下基于图的学习可靠性至关重要，因为相较于传统节点标签噪声模型，EDN能更真实地反映实际场景下的噪声影响。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EDN%3A+A+Novel+Edge-Dependent+Noise+Model+for+Graph+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11368，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11368&send_immediately=true&force_search=false)

**原文摘要:** An important structural feature of a graph is its set of edges, as it
captures the relationships among the nodes (the graph's topology). Existing
node label noise models like Symmetric Label Noise (SLN) and Class Conditional
Noise (CCN) disregard this important node relationship in graph data; and the
Edge-Dependent Noise (EDN) model addresses this limitation. EDN posits that in
real-world scenarios, label noise may be influenced by the connections between
nodes. We explore three variants of EDN. A crucial notion that relates nodes
and edges in a graph is the degree of a node; we show that in all three
variants, the probability of a node's label corruption is dependent on its
degree. Additionally, we compare the dependence of these probabilities on node
degree across different variants. We performed experiments on popular graph
datasets using 5 different GNN architectures and 8 noise robust algorithms for
graph data. The results demonstrate that 2 variants of EDN lead to greater
performance degradation in both Graph Neural Networks (GNNs) and existing
noise-robust algorithms, as compared to traditional node label noise models. We
statistically verify this by posing a suitable hypothesis-testing problem. This
emphasizes the importance of incorporating EDN when evaluating noise robust
algorithms for graphs, to enhance the reliability of graph-based learning in
noisy environments.

</details>


### [56] [LoRA Users Beware: A Few Spurious Tokens Can Manipulate Your Finetuned Model](https://arxiv.org/abs/2506.11402)
*Pradyut Sekhsaria, Marcel Mateos Salles, Hai Huang, Randall Balestriero*

**主要类别:** cs.LG

**AI概要:** 本文揭示了参数高效微调（PEFT）的一个潜在问题：当少量标记与下游任务类别相关时，模型会主要依赖这些标记来做决策。这种现象可能由于数据清理错误或恶意的无缝虚假标记注入（SSTI）而发生。研究在不同模型和数据集上验证了这一发现，并指出即使单个SSTI标记也能显著影响模型决策，同时LoRA等级对模型依赖虚假标记的程度有直接影响。


<details>
  <summary>更多</summary>
  
**动机:** 文章旨在探讨PEFT方法在资源效率提升的同时可能引发的灾难性失败，特别是当存在少量与下游任务相关的标记时，模型可能会寻找捷径解决方案。此外，还讨论了通过无缝虚假标记注入方式操纵模型行为的可能性。

**方法:** 研究者们通过对来自三个不同系列的模型（Snowflake Arctic、Apple OpenELM 和 Meta LLaMA-3）以及四个多样化数据集（IMDB、财经分类、常识问答、Bios偏见）应用无缝虚假标记注入（SSTI）来观察其效果。

**结果:** 研究发现了三种令人惊讶的行为：1) 单个SSTI标记足以引导模型决策；2) 对于轻度SSTI情况，模型对虚假标记的依赖程度与LoRA等级成正比；3) 在重度SSTI情况下，较大的LoRA等级值变得更为有利，因为它促使模型关注非虚假标记，从而提高鲁棒性。

**结论:** 该研究表明，尽管PEFT能够以资源高效的方式将预训练的大规模语言模型调整到特定的下游任务中，但同时也存在潜在风险，即模型可能会过分依赖于少量与任务相关的标记进行决策。此外，通过SSTI可以轻易地操控经过微调后的大型语言模型的行为。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LoRA+Users+Beware%3A+A+Few+Spurious+Tokens+Can+Manipulate+Your+Finetuned+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11402，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11402&send_immediately=true&force_search=false)

**原文摘要:** Parameter Efficient FineTuning (PEFT), such as Low-Rank Adaptation (LoRA),
aligns pre-trained Large Language Models (LLMs) to particular downstream tasks
in a resource-efficient manner. Because efficiency has been the main metric of
progress, very little attention has been put in understanding possible
catastrophic failures. We uncover one such failure: PEFT encourages a model to
search for shortcut solutions to solve its fine-tuning tasks. When very small
amount of tokens, e.g., one token per prompt, are correlated with downstream
task classes, PEFT makes any pretrained model rely predominantly on that token
for decision making. While such spurious tokens may emerge accidentally from
incorrect data cleaning, it also opens opportunities for malevolent parties to
control a model's behavior from Seamless Spurious Token Injection (SSTI). In
SSTI, a small amount of tokens correlated with downstream classes are injected
by the dataset creators. At test time, the finetuned LLM's behavior can be
controlled solely by injecting those few tokens. We apply SSTI across models
from three families (Snowflake Arctic, Apple OpenELM, and Meta LLaMA-3) and
four diverse datasets (IMDB, Financial Classification, CommonSense QA, and Bias
in Bios). Our findings reveal three astonishing behaviors. First, as few as a
single token of SSTI is sufficient to steer a model's decision making. Second,
for light SSTI, the reliance on spurious tokens is proportional to the LoRA
rank. Lastly, with aggressive SSTI, larger LoRA rank values become preferable
to small rank values as it makes the model attend to non-spurious tokens, hence
improving robustness.

</details>


### [57] [The Effect of Stochasticity in Score-Based Diffusion Sampling: a KL Divergence Analysis](https://arxiv.org/abs/2506.11378)
*Bernardo P. Schaeffer, Ricardo M. S. Rosa, Glauco Valle*

**主要类别:** cs.LG

**AI概要:** 该论文研究了在基于分数的扩散模型中，随机性参数对生成过程的影响。通过KL散度界限和数值与分析示例来探讨随机性如何影响误差传播。研究表明，对于准确的分数函数，随机性有助于减少采样轨迹上的KL散度；而对于近似的分数函数，则存在误差修正与放大之间的权衡。


<details>
  <summary>更多</summary>
  
**动机:** 研究旨在理解不同随机性水平下，先验分布误差及分数逼近误差如何在基于分数的扩散模型中传播，并探索随机性是否能作为误差校正机制。

**方法:** 使用log-Sobolev不等式为前向过程边缘分布导出理论界，以更有效地控制沿采样路径的KL散度衰减。此外，还进行了数值实验来说明和支持理论结果。

**结果:** 对于精确分数函数，增加随机性可降低采样轨迹中的KL散度；对于近似分数函数，随机性的效果取决于分数误差结构，可能改善也可能恶化性能。

**结论:** 论文提供了关于随机性如何影响基于分数扩散模型中生成过程质量的新见解，强调了选择适当随机性参数的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Effect+of+Stochasticity+in+Score-Based+Diffusion+Sampling%3A+a+KL+Divergence+Analysis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11378，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11378&send_immediately=true&force_search=false)

**原文摘要:** Sampling in score-based diffusion models can be performed by solving either a
probability flow ODE or a reverse-time stochastic differential equation (SDE)
parameterized by an arbitrary stochasticity parameter. In this work, we study
the effect of stochasticity on the generation process through bounds on the
Kullback-Leibler (KL) divergence and complement the analysis with numerical and
analytical examples. Our results apply to general forward SDEs with additive
noise and Lipschitz-continuous score functions, and quantify how errors from
the prior distribution and score approximation propagate under different
choices of the stochasticity parameter. The theoretical bounds are derived
using log-Sobolev inequalities for the marginals of the forward process, which
enable a more effective control of the KL divergence decay along sampling. For
exact score functions, we find that stochasticity acts as an error-correcting
mechanism, decreasing KL divergence along the sampling trajectory. For an
approximate score function, there is a trade-off between error correction and
score error amplification, so that stochasticity can either improve or worsen
the performance, depending on the structure of the score error. Numerical
experiments on simple datasets and a fully analytical example are included to
illustrate and enlighten the theoretical results.

</details>


### [58] [RollingQ: Reviving the Cooperation Dynamics in Multimodal Transformer](https://arxiv.org/abs/2506.11465)
*Haotian Ni, Yake Wei, Hang Liu, Gong Chen, Chong Peng, Hao Lin, Di Hu*

**主要类别:** cs.LG

**AI概要:** 研究发现常用的自注意力模型在多模态学习中的动态适应性减弱，导致对某一模态的偏好增强，并形成自我强化循环。为解决此问题，提出了一种名为Rolling Query (RollingQ)的新方法，通过旋转查询来平衡注意力分配并恢复合作动态，从而提高多模态Transformer的整体能力。


<details>
  <summary>更多</summary>
  
**动机:** 多模态学习中有效融合不同模态信息面临挑战，尤其是在样本间模态质量不一致时。尽管动态融合策略（如Transformer中的注意力机制）旨在通过根据输入数据特性自适应地强调模态来解决这一挑战，但观察到广泛使用的自注意力模型的动态适应性实际上有所降低，倾向于无视数据特征而偏好单一模态。这种偏见引发了自我加强的循环，逐渐过度强调了被青睐的模态，扩大了跨模态注意力键的分布差距，并使注意力机制失去其动态属性。

**方法:** 提出了一种名为Rolling Query (RollingQ)的方法，该方法通过旋转查询以打破自我强化循环、缓解关键分布差距来平衡注意力分配。

**结果:** 在各种多模态场景上的大量实验验证了RollingQ的有效性，表明恢复合作动态对于增强广泛应用的多模态Transformers更广泛的能力至关重要。

**结论:** RollingQ提供了一个简单但有效的方式来复活多模态Transformer中注意力机制的动态性质，有助于改善模型处理不同模态信息的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是RollingQ%3A+Reviving+the+Cooperation+Dynamics+in+Multimodal+Transformer，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11465，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11465&send_immediately=true&force_search=false)

**原文摘要:** Multimodal learning faces challenges in effectively fusing information from
diverse modalities, especially when modality quality varies across samples.
Dynamic fusion strategies, such as attention mechanism in Transformers, aim to
address such challenge by adaptively emphasizing modalities based on the
characteristics of input data. However, through amounts of carefully designed
experiments, we surprisingly observed that the dynamic adaptability of
widely-used self-attention models diminishes. Model tends to prefer one
modality regardless of data characteristics. This bias triggers a
self-reinforcing cycle that progressively overemphasizes the favored modality,
widening the distribution gap in attention keys across modalities and
deactivating attention mechanism's dynamic properties. To revive adaptability,
we propose a simple yet effective method Rolling Query (RollingQ), which
balances attention allocation by rotating the query to break the
self-reinforcing cycle and mitigate the key distribution gap. Extensive
experiments on various multimodal scenarios validate the effectiveness of
RollingQ and the restoration of cooperation dynamics is pivotal for enhancing
the broader capabilities of widely deployed multimodal Transformers. The source
code is available at https://github.com/GeWu-Lab/RollingQ_ICML2025.

</details>


### [59] [FIGNN: Feature-Specific Interpretability for Graph Neural Network Surrogate Models](https://arxiv.org/abs/2506.11398)
*Riddhiman Raut, Romit Maulik, Shivam Barwey*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的图神经网络架构FIGNN，旨在提高科学应用中非结构化网格上深度学习代理模型的可解释性。通过引入特征特定的池策略和基于掩码的正则化项，该方法在保持预测性能的同时揭示了每个特征独特的物理意义空间模式。


<details>
  <summary>更多</summary>
  
**动机:** 传统图神经网络（GNN）在多变量预测任务中难以清晰地表达不同特征的空间影响。为了克服这一局限，并且提升深度学习代理模型在科学应用场景下的可解释性，提出了FIGNN架构。

**方法:** FIGNN采用了一种特征特定的池化策略来独立归因于每个预测变量的空间重要性，并且加入了一个基于掩码的正则化项到训练目标中，以促进模型性能的局部归因与可解释性之间的对齐。

**结果:** 通过对两个物理系统—SPEEDY大气循环模型和后向台阶流体动力学基准—进行代理建模评估，结果表明FIGNN不仅达到了具有竞争力的预测性能，而且展示了每个特征特有的、具有物理意义的空间模式。此外，滚动稳定性分析、特征级错误预算以及空间掩码叠加进一步证实了FIGNN的有效性。

**结论:** FIGNN作为一种通用框架，在复杂的物理领域内为可解释性的代理建模提供了有力支持，它能够在维持高预测准确性的同时提供物理上有意义的空间特征解析。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FIGNN%3A+Feature-Specific+Interpretability+for+Graph+Neural+Network+Surrogate+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11398，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11398&send_immediately=true&force_search=false)

**原文摘要:** This work presents a novel graph neural network (GNN) architecture, the
Feature-specific Interpretable Graph Neural Network (FIGNN), designed to
enhance the interpretability of deep learning surrogate models defined on
unstructured grids in scientific applications. Traditional GNNs often obscure
the distinct spatial influences of different features in multivariate
prediction tasks. FIGNN addresses this limitation by introducing a
feature-specific pooling strategy, which enables independent attribution of
spatial importance for each predicted variable. Additionally, a mask-based
regularization term is incorporated into the training objective to explicitly
encourage alignment between interpretability and predictive error, promoting
localized attribution of model performance. The method is evaluated for
surrogate modeling of two physically distinct systems: the SPEEDY atmospheric
circulation model and the backward-facing step (BFS) fluid dynamics benchmark.
Results demonstrate that FIGNN achieves competitive predictive performance
while revealing physically meaningful spatial patterns unique to each feature.
Analysis of rollout stability, feature-wise error budgets, and spatial mask
overlays confirm the utility of FIGNN as a general-purpose framework for
interpretable surrogate modeling in complex physical domains.

</details>


### [60] [LearnAlign: Reasoning Data Selection for Reinforcement Learning in Large Language Models Based on Improved Gradient Alignment](https://arxiv.org/abs/2506.11480)
*Shikun Li, Shipeng Li, Zhiqin Yang, Xinghua Zhang, Gaode Chen, Xiaobo Xia, Hengyu Liu, Zhe Peng*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为LearnAlign的新方法，该方法基于梯度对齐智能选择可学习的和代表性的训练推理数据，以提高强化学习在大型语言模型中的数据效率。实验表明，该方法可以显著减少训练数据需求，并在某些情况下提高性能。


<details>
  <summary>更多</summary>
  
**动机:** 增强大型语言模型（LLMs）的推理能力是强化学习（RL）的一个关键应用领域，但其数据利用效率低下仍然是一个主要瓶颈。为了解决这个问题，研究者们提出了一个新的基于梯度对齐的方法。

**方法:** LearnAlign 方法通过成功概率来衡量数据的学习潜力，用以克服梯度范数中响应长度偏差的问题。它能够智能地挑选出具有学习价值和代表性的训练推理数据用于RL后训练。

**结果:** 在三个数学推理基准测试中，LearnAlign 方法大幅减少了训练所需的数据量，同时保持了轻微的性能下降甚至有所提升。例如，在GSM8K基准上，与使用全部数据集相比，减少了多达1000个数据点的需求，且表现更优（77.53%对比77.04%）。此外，在分阶段RL设置下也展示了有效性。

**结论:** 这项工作为数据高效型RL后训练提供了有价值的见解，并为未来优化推理数据选择的研究奠定了基础。为了便于后续工作，研究人员计划公开代码。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LearnAlign%3A+Reasoning+Data+Selection+for+Reinforcement+Learning+in+Large+Language+Models+Based+on+Improved+Gradient+Alignment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11480，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11480&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement learning (RL) has become a key technique for enhancing LLMs'
reasoning abilities, yet its data inefficiency remains a major bottleneck. To
address this critical yet challenging issue, we present a novel
gradient-alignment-based method, named LearnAlign, which intelligently selects
the learnable and representative training reasoning data for RL post-training.
To overcome the well-known issue of response-length bias in gradient norms, we
introduce the data learnability based on the success rate, which can indicate
the learning potential of each data point. Experiments across three
mathematical reasoning benchmarks demonstrate that our method significantly
reduces training data requirements while achieving minor performance
degradation or even improving performance compared to full-data training. For
example, it reduces data requirements by up to 1,000 data points with better
performance (77.53%) than that on the full dataset on GSM8K benchmark (77.04%).
Furthermore, we show its effectiveness in the staged RL setting. This work
provides valuable insights into data-efficient RL post-training and establishes
a foundation for future research in optimizing reasoning data selection.To
facilitate future work, we will release code.

</details>


### [61] [Diabetes Prediction and Management Using Machine Learning Approaches](https://arxiv.org/abs/2506.11501)
*Mowafaq Salem Alzboon, Muhyeeddin Alqaraleh, Mohammad Subhi Al-Batah*

**主要类别:** cs.LG

**AI概要:** 本研究通过对比多种机器学习算法在糖尿病风险分类中的表现，发现神经网络和随机森林算法具有最高的预测准确性，分别为78.57%和76.30%，表明了机器学习技术在早期筛查糖尿病方面的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 鉴于糖尿病已成为一个重大的全球健康问题，并且病例数量不断增加，有必要加强对该疾病的早期发现和积极管理，以避免或减轻其严重的健康并发症。近年来，机器学习算法在预测糖尿病风险方面显示出了巨大潜力，这为医疗实践者提供了很大帮助。

**方法:** 研究使用了Pima印第安人糖尿病数据库中的768个样本，包括年龄、身体质量指数（BMI）和血糖水平等重要的人口统计学和临床特征。实验评估了几种类型的机器学习算法，包括逻辑回归、决策树、随机森林、K-最近邻、朴素贝叶斯、支持向量机、梯度提升以及神经网络模型，在糖尿病预测上的准确性和有效性。

**结果:** 结果显示，神经网络算法的预测准确性最高，达到了78.57%，其次是随机森林算法，准确率为76.30%。这些发现表明，机器学习技术不仅非常有效，而且可以作为数据驱动方式下预测糖尿病的早期筛查工具，提供有关哪些人群更有可能受到影响的重要信息。

**结论:** 研究表明，机器学习技术对于识别糖尿病高风险个体具有显著作用，可作为早期筛查工具，并有助于实现对糖尿病的及时干预，从而减少由糖尿病引起的健康结果和疾病负担。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diabetes+Prediction+and+Management+Using+Machine+Learning+Approaches，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11501，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11501&send_immediately=true&force_search=false)

**原文摘要:** Diabetes has emerged as a significant global health issue, especially with
the increasing number of cases in many countries. This trend Underlines the
need for a greater emphasis on early detection and proactive management to
avert or mitigate the severe health complications of this disease. Over recent
years, machine learning algorithms have shown promising potential in predicting
diabetes risk and are beneficial for practitioners. Objective: This study
highlights the prediction capabilities of statistical and non-statistical
machine learning methods over Diabetes risk classification in 768 samples from
the Pima Indians Diabetes Database. It consists of the significant demographic
and clinical features of age, body mass index (BMI) and blood glucose levels
that greatly depend on the vulnerability against Diabetes. The experimentation
assesses the various types of machine learning algorithms in terms of accuracy
and effectiveness regarding diabetes prediction. These algorithms include
Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, Naive
Bayes, Support Vector Machine, Gradient Boosting and Neural Network Models. The
results show that the Neural Network algorithm gained the highest predictive
accuracy with 78,57 %, and then the Random Forest algorithm had the second
position with 76,30 % accuracy. These findings show that machine learning
techniques are not just highly effective. Still, they also can potentially act
as early screening tools in predicting Diabetes within a data-driven fashion
with valuable information on who is more likely to get affected. In addition,
this study can help to realize the potential of machine learning for timely
intervention over the longer term, which is a step towards reducing health
outcomes and disease burden attributable to Diabetes on healthcare systems

</details>


### [62] [Byzantine Outside, Curious Inside: Reconstructing Data Through Malicious Updates](https://arxiv.org/abs/2506.11413)
*Kai Yue, Richeng Jin, Chau-Wai Wong, Huaiyu Dai*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的联邦学习威胁模型，即恶意好奇的客户端，该客户端通过操纵自己的梯度来推断其他客户端的私有数据。研究者开发了一种结合梯度反转和恶意更新策略的重建算法，并指出传统的服务器端鲁棒聚合和客户端隐私机制可能无法防御这种攻击，甚至可能会无意中放大数据泄露。


<details>
  <summary>更多</summary>
  
**动机:** 联邦学习允许在不共享原始数据的情况下进行分散式机器学习，但研究表明，在常见的联邦学习协议下，仍有可能发生隐私泄露。特别是拥有客户端梯度访问权限的服务器可以合成类似客户训练数据的数据。本文旨在探讨一种新型的客户端威胁模型——恶意好奇的客户端，其目的是通过操控自身梯度来推断同伴的私有数据。

**方法:** 本文首先正式定义了这种新的客户端威胁模型，并提供了理论分析以证明它在联邦学习训练过程中能够实现显著的数据重建成功。为了展示其实用影响，研究者进一步开发了一种结合梯度反转与恶意更新策略的数据重建算法。

**结果:** 分析和实验结果揭示了联邦学习防御中的一个关键盲点：针对提出的攻击，服务器端的鲁棒聚合方法和客户端的隐私保护机制都可能失效。令人惊讶的是，设计用来增强鲁棒性或隐私的标准防御措施可能会无意间增加数据泄漏。与基准方法相比，错误使用的防御措施反而可能提高重建图像质量10-15%。

**结论:** 本文介绍了一个新的联邦学习攻击向量，表明即使采取了现有的防御措施，恶意好奇的客户端仍然能够在联邦学习环境中造成严重的隐私风险。这表明需要重新评估当前的联邦学习安全策略并开发更有效的防御手段。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Byzantine+Outside%2C+Curious+Inside%3A+Reconstructing+Data+Through+Malicious+Updates，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11413，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11413&send_immediately=true&force_search=false)

**原文摘要:** Federated learning (FL) enables decentralized machine learning without
sharing raw data, allowing multiple clients to collaboratively learn a global
model. However, studies reveal that privacy leakage is possible under commonly
adopted FL protocols. In particular, a server with access to client gradients
can synthesize data resembling the clients' training data. In this paper, we
introduce a novel threat model in FL, named the maliciously curious client,
where a client manipulates its own gradients with the goal of inferring private
data from peers. This attacker uniquely exploits the strength of a Byzantine
adversary, traditionally aimed at undermining model robustness, and repurposes
it to facilitate data reconstruction attack. We begin by formally defining this
novel client-side threat model and providing a theoretical analysis that
demonstrates its ability to achieve significant reconstruction success during
FL training. To demonstrate its practical impact, we further develop a
reconstruction algorithm that combines gradient inversion with malicious update
strategies. Our analysis and experimental results reveal a critical blind spot
in FL defenses: both server-side robust aggregation and client-side privacy
mechanisms may fail against our proposed attack. Surprisingly, standard server-
and client-side defenses designed to enhance robustness or privacy may
unintentionally amplify data leakage. Compared to the baseline approach, a
mistakenly used defense may instead improve the reconstructed image quality by
10-15%.

</details>


### [63] [Machine Learning-Based Quantification of Vesicoureteral Reflux with Enhancing Accuracy and Efficiency](https://arxiv.org/abs/2506.11508)
*Muhyeeddin Alqaraleh, Mowafaq Salem Alzboon, Mohammad Subhi Al-Batah, Lana Yasin Al Aesa, Mohammed Hasan Abu-Arqoub, Rashiq Rafiq Marie, Firas Hussein Alsmad*

**主要类别:** cs.LG

**AI概要:** 研究使用机器学习分析VCUG图像以提高VUR诊断的一致性，通过六个预测模型对113张VCUG图像进行评估，所有模型都实现了准确分类，并且没有假阳性和假阴性。


<details>
  <summary>更多</summary>
  
**动机:** 传统的VUR评估采用主观分级系统，导致诊断存在差异。本研究旨在利用机器学习来改善诊断的一致性。

**方法:** 研究回顾了113张VCUG图像，并由专家对VUR严重程度进行分级。选取了九个基于图像的特征用于训练六个预测模型：逻辑回归、决策树、梯度提升、神经网络和随机梯度下降。模型通过留一交叉验证法进行评估。

**结果:** 分析发现肾盏变形是高分级VUR的关键指标。所有模型均实现了精准分类，无假阳性或假阴性结果。AUC值证实了模型对不同VUR等级的细微图像模式具有高度敏感性。

**结论:** 结果表明，机器学习可以为当前主观的VUR评估提供一种客观且标准化的替代方案。这些发现强调了肾盏变形作为严重病例强预测因子的重要性。未来的研究应致力于扩大数据集、优化影像特征并提高模型的泛化能力，以便更广泛地应用于临床。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Machine+Learning-Based+Quantification+of+Vesicoureteral+Reflux+with+Enhancing+Accuracy+and+Efficiency，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11508，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11508&send_immediately=true&force_search=false)

**原文摘要:** Vesicoureteral reflux (VUR) is traditionally assessed using subjective
grading systems, which introduces variability in diagnosis. This study
investigates the use of machine learning to improve diagnostic consistency by
analyzing voiding cystourethrogram (VCUG) images. A total of 113 VCUG images
were reviewed, with expert grading of VUR severity. Nine image-based features
were selected to train six predictive models: Logistic Regression, Decision
Tree, Gradient Boosting, Neural Network, and Stochastic Gradient Descent. The
models were evaluated using leave-one-out cross-validation. Analysis identified
deformation patterns in the renal calyces as key indicators of high-grade VUR.
All models achieved accurate classifications with no false positives or
negatives. High sensitivity to subtle image patterns characteristic of
different VUR grades was confirmed by substantial Area Under the Curve (AUC)
values. The results suggest that machine learning can offer an objective and
standardized alternative to current subjective VUR assessments. These findings
highlight renal calyceal deformation as a strong predictor of severe cases.
Future research should aim to expand the dataset, refine imaging features, and
improve model generalizability for broader clinical use.

</details>


### [64] [Bias Amplification in RAG: Poisoning Knowledge Retrieval to Steer LLMs](https://arxiv.org/abs/2506.11415)
*Linlin Wang, Tianqing Zhu, Laiqiao Qin, Longxiang Gao, Wanlei Zhou*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种Bias Retrieval and Reward Attack (BRRA)框架，揭示了检索增强生成(RAG)系统中的投毒攻击不仅影响模型输出质量，还会放大模型偏见，并提出了双阶段防御机制来缓解这种攻击的影响。


<details>
  <summary>更多</summary>
  
**动机:** 现有的研究主要集中在RAG系统中投毒攻击对模型输出质量的影响，而忽视了这些攻击可能放大模型偏见的问题。

**方法:** 设计了一个基于多目标奖励函数的对抗性文档生成方法，使用子空间投影技术操纵检索结果，并构建了一个循环反馈机制以持续放大偏见。

**结果:** 实验表明，BRRA攻击可以显著增强主流大型语言模型在多个维度上的偏见。此外，还探索了一种双阶段防御机制来有效减轻攻击的影响。

**结论:** RAG系统中的投毒攻击直接放大了模型输出偏见，本研究表明需要关注RAG系统的公平性问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bias+Amplification+in+RAG%3A+Poisoning+Knowledge+Retrieval+to+Steer+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11415，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11415&send_immediately=true&force_search=false)

**原文摘要:** In Large Language Models, Retrieval-Augmented Generation (RAG) systems can
significantly enhance the performance of large language models by integrating
external knowledge. However, RAG also introduces new security risks. Existing
research focuses mainly on how poisoning attacks in RAG systems affect model
output quality, overlooking their potential to amplify model biases. For
example, when querying about domestic violence victims, a compromised RAG
system might preferentially retrieve documents depicting women as victims,
causing the model to generate outputs that perpetuate gender stereotypes even
when the original query is gender neutral. To show the impact of the bias, this
paper proposes a Bias Retrieval and Reward Attack (BRRA) framework, which
systematically investigates attack pathways that amplify language model biases
through a RAG system manipulation. We design an adversarial document generation
method based on multi-objective reward functions, employ subspace projection
techniques to manipulate retrieval results, and construct a cyclic feedback
mechanism for continuous bias amplification. Experiments on multiple mainstream
large language models demonstrate that BRRA attacks can significantly enhance
model biases in dimensions. In addition, we explore a dual stage defense
mechanism to effectively mitigate the impacts of the attack. This study reveals
that poisoning attacks in RAG systems directly amplify model output biases and
clarifies the relationship between RAG system security and model fairness. This
novel potential attack indicates that we need to keep an eye on the fairness
issues of the RAG system.

</details>


### [65] [Prioritizing Alignment Paradigms over Task-Specific Model Customization in Time-Series LLMs](https://arxiv.org/abs/2506.11512)
*Wei Li, Yunyao Cheng, Xinli Hao, Chaohong Ma, Yuxuan Liang, Bin Yang, Christian S. Jensen, Xiaofeng Meng*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于时间序列数据内在特征的对齐范式，作为利用大型语言模型进行时间序列推理的新方法，旨在解决当前方法成本高、不灵活和效率低的问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法通常专注于任务特定的模型定制，例如预测和异常检测，而忽视了时间序列数据本身（即时间序列原语），这对于深入推理至关重要。

**方法:** 提出了三种对齐范式：注入对齐、桥接对齐和内部对齐，分别强调时间序列原语的不同方面：领域、特性和表示法，以激活大型语言模型的时间序列推理能力。

**结果:** 通过采用这种面向对齐的方法，可以实现经济、灵活且高效的时间序列推理，并为未来的研究指明了方向。

**结论:** 文章建议实践者采用一种基于对齐的方法来选择合适的时间序列推理范式，并将相关文献归类到这些对齐范式中，同时概述了有前途的研究方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Prioritizing+Alignment+Paradigms+over+Task-Specific+Model+Customization+in+Time-Series+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11512，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11512&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in Large Language Models (LLMs) have enabled unprecedented
capabilities for time-series reasoning in diverse real-world applications,
including medical, financial, and spatio-temporal domains. However, existing
approaches typically focus on task-specific model customization, such as
forecasting and anomaly detection, while overlooking the data itself, referred
to as time-series primitives, which are essential for in-depth reasoning. This
position paper advocates a fundamental shift in approaching time-series
reasoning with LLMs: prioritizing alignment paradigms grounded in the intrinsic
primitives of time series data over task-specific model customization. This
realignment addresses the core limitations of current time-series reasoning
approaches, which are often costly, inflexible, and inefficient, by
systematically accounting for intrinsic structure of data before task
engineering. To this end, we propose three alignment paradigms: Injective
Alignment, Bridging Alignment, and Internal Alignment, which are emphasized by
prioritizing different aspects of time-series primitives: domain,
characteristic, and representation, respectively, to activate time-series
reasoning capabilities of LLMs to enable economical, flexible, and efficient
reasoning. We further recommend that practitioners adopt an alignment-oriented
method to avail this instruction to select an appropriate alignment paradigm.
Additionally, we categorize relevant literature into these alignment paradigms
and outline promising research directions.

</details>


### [66] [PPDiff: Diffusing in Hybrid Sequence-Structure Space for Protein-Protein Complex Design](https://arxiv.org/abs/2506.11420)
*Zhenqiao Song, Tiaoxiao Li, Lei Li, Martin Renqiang Min*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为PPDiff的扩散模型，用于设计对任意蛋白质靶点具有高亲和力的结合蛋白。该模型通过非自回归的方式同时设计结合蛋白的序列和结构，并且在基准测试和实际应用中表现优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 设计具有高亲和力的蛋白质结合物对于生物医学研究和生物技术至关重要。尽管针对特定蛋白质有最新进展，但无需大量湿实验室测试即可按需为任意蛋白质靶标创造高亲和力结合物的能力仍然是一个重大挑战。

**方法:** 研究人员开发了PPDiff，一种基于Sequence Structure Interleaving Network with Causal attention layers (SSINC) 的扩散模型，它能够捕捉全局氨基酸相关性、利用k-最近邻等变图层来建模三维空间中的局部相互作用，并使用因果注意层简化蛋白质序列内的复杂相互依赖关系。

**结果:** 为了评估PPDiff，创建了一个名为PPBench的数据集，包含来自蛋白质数据库（PDB）的706,360个复合体。模型首先在PPBench上预训练，然后在两个实际应用中进行微调：目标蛋白迷你结合物复合体设计和抗原-抗体复合体设计。PPDiff在这两个下游应用中分别达到了50.00%、23.16% 和 16.89%的成功率，持续超越基线方法。

**结论:** PPDiff作为一种创新性的蛋白质结合物设计工具，在不需要过多实验验证的情况下展现了显著的性能优势，为快速设计高亲和力蛋白质结合物提供了一条新的途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PPDiff%3A+Diffusing+in+Hybrid+Sequence-Structure+Space+for+Protein-Protein+Complex+Design，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11420，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11420&send_immediately=true&force_search=false)

**原文摘要:** Designing protein-binding proteins with high affinity is critical in
biomedical research and biotechnology. Despite recent advancements targeting
specific proteins, the ability to create high-affinity binders for arbitrary
protein targets on demand, without extensive rounds of wet-lab testing, remains
a significant challenge. Here, we introduce PPDiff, a diffusion model to
jointly design the sequence and structure of binders for arbitrary protein
targets in a non-autoregressive manner. PPDiffbuilds upon our developed
Sequence Structure Interleaving Network with Causal attention layers (SSINC),
which integrates interleaved self-attention layers to capture global amino acid
correlations, k-nearest neighbor (kNN) equivariant graph layers to model local
interactions in three-dimensional (3D) space, and causal attention layers to
simplify the intricate interdependencies within the protein sequence. To assess
PPDiff, we curate PPBench, a general protein-protein complex dataset comprising
706,360 complexes from the Protein Data Bank (PDB). The model is pretrained on
PPBenchand finetuned on two real-world applications: target-protein mini-binder
complex design and antigen-antibody complex design. PPDiffconsistently
surpasses baseline methods, achieving success rates of 50.00%, 23.16%, and
16.89% for the pretraining task and the two downstream applications,
respectively.

</details>


### [67] [Improving Multimodal Learning Balance and Sufficiency through Data Remixing](https://arxiv.org/abs/2506.11550)
*Xiaoyu Ma, Hao Chen, Yongjian Deng*

**主要类别:** cs.LG

**AI概要:** 本文提出了多模态数据重混技术来解决模态懒惰和模态冲突问题，通过解耦多模态数据、过滤每个模态的难例以减轻模态不平衡，并在批次层面重新组装以对齐梯度方向和避免跨模态干扰，从而增强单模态学习的充分性。实验结果表明该方法可以无缝集成到现有方法中，且不增加额外的计算开销。


<details>
  <summary>更多</summary>
  
**动机:** 现有的多模态模型联合训练时存在模态懒惰和模态冲突的问题，导致了多模态学习不足和不平衡。而现有的方法虽然尝试通过加强弱模态、调整优化速度或分解多模态学习来改善这些问题，但未能同时实现单模态的充分性和多模态间的平衡。

**方法:** 提出了一种新的多模态数据重混方法，包括解耦多模态数据以及为每种模态过滤困难样本以缓解模态间的不平衡；然后在批处理级别上重新组合这些数据，以使梯度方向一致并防止跨模态干扰，进而促进单模态学习的充分性。

**结果:** 实验结果显示所提方法能够与现有方法无缝整合，在CREMAD数据集上准确率提高了约6.50%，在Kinetic-Sounds数据集上提升了3.41%的准确率，而且没有扩展训练集也没有在推理过程中增加额外的计算负担。

**结论:** 提出的多模态数据重混方法有效解决了模态间的学习不平衡问题，同时增强了单模态学习的效果，并且能够在不增加额外计算成本的情况下提高模型性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+Multimodal+Learning+Balance+and+Sufficiency+through+Data+Remixing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11550，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11550&send_immediately=true&force_search=false)

**原文摘要:** Different modalities hold considerable gaps in optimization trajectories,
including speeds and paths, which lead to modality laziness and modality clash
when jointly training multimodal models, resulting in insufficient and
imbalanced multimodal learning. Existing methods focus on enforcing the weak
modality by adding modality-specific optimization objectives, aligning their
optimization speeds, or decomposing multimodal learning to enhance unimodal
learning. These methods fail to achieve both unimodal sufficiency and
multimodal balance. In this paper, we, for the first time, address both
concerns by proposing multimodal Data Remixing, including decoupling multimodal
data and filtering hard samples for each modality to mitigate modality
imbalance; and then batch-level reassembling to align the gradient directions
and avoid cross-modal interference, thus enhancing unimodal learning
sufficiency. Experimental results demonstrate that our method can be seamlessly
integrated with existing approaches, improving accuracy by approximately
6.50%$\uparrow$ on CREMAD and 3.41%$\uparrow$ on Kinetic-Sounds, without
training set expansion or additional computational overhead during inference.
The source code is available at https://github.com/MatthewMaxy/Remix_ICML2025.

</details>


### [68] [TruncQuant: Truncation-Ready Quantization for DNNs with Flexible Weight Bit Precision](https://arxiv.org/abs/2506.11431)
*Jinhee Kim, Seoyeon Yoon, Taeho Lee, Joo Chan Lee, Kang Eun Jeon, Jong Hwan Ko*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的截断就绪训练方案TruncQuant，旨在解决深度神经网络在边缘设备上部署时面临的模型大小和推理延迟问题。该方法通过运行时的位移实现灵活的位精度，并且可以很容易地在现有的量化感知框架中实现。


<details>
  <summary>更多</summary>
  
**动机:** 由于最先进的模型复杂性不断增加，在边缘设备上部署深度神经网络是一项具有挑战性的任务，需要努力减少模型大小和推理延迟。当前的量化感知训练方案并非针对截断过程设计，因此制定能够承受截断引入误差的训练方案仍是一个难题。

**方法:** 提出了TruncQuant，这是一种新颖的截断就绪训练方案，它允许通过运行时位移来达到灵活的位精度。TruncQuant与截断过程的结果对齐，显示出跨位宽设置的强大鲁棒性。

**结果:** TruncQuant展示了强大的鲁棒性，能够在不同的位宽设置下保持性能，并且提供了一个容易实现的训练方案，可以融入现有的量化感知框架中。

**结论:** TruncQuant为适应不同硬件平台提供了可能性，同时减少了模型大小和推理延迟，是一种有效应对截断错误的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TruncQuant%3A+Truncation-Ready+Quantization+for+DNNs+with+Flexible+Weight+Bit+Precision，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11431，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11431&send_immediately=true&force_search=false)

**原文摘要:** The deployment of deep neural networks on edge devices is a challenging task
due to the increasing complexity of state-of-the-art models, requiring efforts
to reduce model size and inference latency. Recent studies explore models
operating at diverse quantization settings to find the optimal point that
balances computational efficiency and accuracy. Truncation, an effective
approach for achieving lower bit precision mapping, enables a single model to
adapt to various hardware platforms with little to no cost. However,
formulating a training scheme for deep neural networks to withstand the
associated errors introduced by truncation remains a challenge, as the current
quantization-aware training schemes are not designed for the truncation
process. We propose TruncQuant, a novel truncation-ready training scheme
allowing flexible bit precision through bit-shifting in runtime. We achieve
this by aligning TruncQuant with the output of the truncation process,
demonstrating strong robustness across bit-width settings, and offering an
easily implementable training scheme within existing quantization-aware
frameworks. Our code is released at https://github.com/a2jinhee/TruncQuant.

</details>


### [69] [Learn to Preserve Personality: Federated Foundation Models in Recommendations](https://arxiv.org/abs/2506.11563)
*Zhiwei Li, Guodong Long, Chunxu Zhang, Honglei Zhang, Jing Jiang, Chengqi Zhang*

**主要类别:** cs.LG

**AI概要:** 本文讨论了一种新的学习范式，其中联邦基础模型(FFM)不仅利用其泛化能力，而且特别设计以保持用户个性的完整性，在推荐系统中进行了详细说明。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基础模型在泛化和个人化之间找到平衡点是一个核心的学习挑战，而联邦基础模型通过去中心化过程提供了分离共享知识与个体特定适应性的结构手段。推荐系统依赖于反映用户独特特征的丰富隐性反馈，为联邦基础模型提供了一个完美的测试平台。

**方法:** 论文提出了一种新的学习模式，它让联邦基础模型（FFMs）不仅发挥它们的泛化能力，而且还特别注重保护用户的个性特点，这在推荐场景下得到了充分展示。

**结果:** 设想未来个人代理将由个性化适应的基础模型驱动，在内容决策上指导用户。这种架构承诺了以用户为中心、去中心化的系统，其中个人对其个性化代理保持控制。

**结论:** 文章提出了一个基于联邦基础模型的新学习框架，该框架旨在推荐系统领域内实现泛化同时保留用户个性，并展望了以此为基础构建的未来个性化代理系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learn+to+Preserve+Personality%3A+Federated+Foundation+Models+in+Recommendations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11563，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11563&send_immediately=true&force_search=false)

**原文摘要:** A core learning challenge for existed Foundation Models (FM) is striking the
tradeoff between generalization with personalization, which is a dilemma that
has been highlighted by various parameter-efficient adaptation techniques.
Federated foundation models (FFM) provide a structural means to decouple shared
knowledge from individual specific adaptations via decentralized processes.
Recommendation systems offer a perfect testbed for FFMs, given their reliance
on rich implicit feedback reflecting unique user characteristics. This position
paper discusses a novel learning paradigm where FFMs not only harness their
generalization capabilities but are specifically designed to preserve the
integrity of user personality, illustrated thoroughly within the recommendation
contexts. We envision future personal agents, powered by personalized adaptive
FMs, guiding user decisions on content. Such an architecture promises a user
centric, decentralized system where individuals maintain control over their
personalized agents.

</details>


### [70] [Dynamic Sparse Training of Diagonally Sparse Networks](https://arxiv.org/abs/2506.11449)
*Abhishek Tyagi, Arjun Iyer, William H Renninger, Christopher Kanan, Yuhao Zhu*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的结构化稀疏到稀疏动态稀疏训练方法DynaDiag，该方法在整个训练过程中强制执行对角线稀疏模式，并且在多种神经架构上保持与非结构化稀疏相当的准确性，同时提供了实际的计算加速。


<details>
  <summary>更多</summary>
  
**动机:** 尽管动态稀疏训练（DST）在减少参数数量方面取得了进步，但非结构化稀疏性通常无法转化为现代硬件上的实际速度提升。为了解决这一问题，研究者们提出了DynaDiag。

**方法:** DynaDiag是一种新型的结构化稀疏到稀疏DST方法，在训练期间实施对角线稀疏模式，并且通过定制的CUDA内核利用这种对角线结构来加快计算速度，使得这种方法更加适合硬件运行。

**结果:** 实证评估表明，DynaDiag在不同神经网络架构中保持了与非结构化稀疏相当的精度，同时带来了显著的计算性能提升。特别是当视觉转换器（ViTs）中的线性层稀疏度达到90%时，在线推理速度提高了3.13倍，而在GPU上训练速度相比等效的非结构化层提高了1.59倍。

**结论:** DynaDiag提供了一个硬件友好的解决方案，它不仅能够匹配非结构化稀疏模型的表现，而且还能在在线推理和训练过程中实现显著的速度提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dynamic+Sparse+Training+of+Diagonally+Sparse+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11449，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11449&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in Dynamic Sparse Training (DST) have pushed the frontier of
sparse neural network training in structured and unstructured contexts,
matching dense-model performance while drastically reducing parameter counts to
facilitate model scaling. However, unstructured sparsity often fails to
translate into practical speedups on modern hardware. To address this
shortcoming, we propose DynaDiag, a novel structured sparse-to-sparse DST
method that performs at par with unstructured sparsity. DynaDiag enforces a
diagonal sparsity pattern throughout training and preserves sparse computation
in forward and backward passes. We further leverage the diagonal structure to
accelerate computation via a custom CUDA kernel, rendering the method
hardware-friendly. Empirical evaluations on diverse neural architectures
demonstrate that our method maintains accuracy on par with unstructured
counterparts while benefiting from tangible computational gains. Notably, with
90% sparse linear layers in ViTs, we observe up to a 3.13x speedup in online
inference without sacrificing model performance and a 1.59x speedup in training
on a GPU compared to equivalent unstructured layers. Our source code is
available at https://github.com/horizon-research/DynaDiag/.

</details>


### [71] [A Comparative Analysis of Influence Signals for Data Debugging](https://arxiv.org/abs/2506.11584)
*Nikolaos Myrtakis, Ioannis Tsamardinos, Vassilis Christophides*

**主要类别:** cs.LG

**AI概要:** 本文对基于影响的信号进行了比较评估，这些信号用于调试训练数据，可以识别错误标记和异常样本。实验表明Self-Influence等信号能够有效检测出错误标记的样本，但现有的信号无法检测到异常值，并且没有考虑到训练过程中的动态变化以及影响抵消效应。


<details>
  <summary>更多</summary>
  
**动机:** 提高训练样本的质量对于提高机器学习模型的可靠性和性能至关重要。本文旨在通过比较不同基于影响的信号来解决这个问题，以期找到更有效的调试训练数据的方法。

**方法:** 通过对几种基于影响的信号（如Self-Influence, Average Absolute Influence, Marginal Influence, GD-class）在统一的影响估计器下进行实验研究，评估它们在不同数据模态（图像和表格）及深度学习模型中检测不同类型错误（例如错误标记和异常样本）的能力。

**结果:** 研究表明像Self-Influence这样的信号能有效地检测出错误标记的样本，但是现有信号都无法检测异常值。此外，现有信号未考虑训练过程中样本对模型影响的变化情况，有些信号还会遭遇影响抵消效应。

**结论:** 虽然一些基于影响的信号被证明在检测错误标记样本方面是有效的，但对于检测异常样本来说还不够充分。未来的研究需要开发新的信号或改进现有方法，以便更好地捕捉训练过程中的动态特性并避免影响抵消问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Comparative+Analysis+of+Influence+Signals+for+Data+Debugging，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11584，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11584&send_immediately=true&force_search=false)

**原文摘要:** Improving the quality of training samples is crucial for improving the
reliability and performance of ML models. In this paper, we conduct a
comparative evaluation of influence-based signals for debugging training data.
These signals can potentially identify both mislabeled and anomalous samples
from a potentially noisy training set as we build the models and hence
alleviate the need for dedicated glitch detectors. Although several
influence-based signals (e.g., Self-Influence, Average Absolute Influence,
Marginal Influence, GD-class) have been recently proposed in the literature,
there are no experimental studies for assessing their power in detecting
different glitch types (e.g., mislabeled and anomalous samples) under a common
influence estimator (e.g., TraceIn) for different data modalities (image and
tabular), and deep learning models (trained from scratch or foundation).
Through extensive experiments, we show that signals like Self-Influence
effectively detect mislabeled samples, but none of the existing signals can
detect anomalies. Existing signals do not take into account the training
dynamics, i.e., how the samples' influence on the model changes during
training, while some signals fall into influence cancellation effects, i.e.,
influence score is zero due to unsigned scores accumulation, resulting in
misleading influence attribution.

</details>


### [72] [Model Organisms for Emergent Misalignment](https://arxiv.org/abs/2506.11613)
*Edward Turner, Anna Soligo, Mia Taylor, Senthooran Rajamanoharan, Neel Nanda*

**主要类别:** cs.LG

**AI概要:** 该研究通过创建改进的模型生物体，使用新的狭义上不一致的数据集，提高了对紧急不一致（EM）现象的理解，并为未来的研究提供了工具。研究表明，EM在不同的模型大小、三个模型家族和多种训练协议中稳健地发生。通过提炼出干净的模型生物体，研究者们确定了一个机制相变，并展示了它对应于所有研究生物体中的一个稳健的行为相变。


<details>
  <summary>更多</summary>
  
**动机:** 先前的工作发现，当大型语言模型在具有狭隘有害性的数据集上进行微调时，会导致它们变得广泛不一致，即出现了所谓的紧急不一致（EM）。专家调查显示这种情况是高度未预料到的，这表明我们在理解模型一致性方面存在关键性空白。为了增进理解并提供未来研究所需的工具，本研究致力于此问题。

**方法:** 研究人员使用了新开发的狭义上不一致的数据集来创造一组改进后的模型生物体，这些模型生物体能够达到99%的一致性，并且可以在较小的0.5B参数模型上工作。此外，他们还证明了使用单个秩-1 LoRA适配器可以诱导出不一致性。实验中，EM现象在不同规模的模型、三个模型系列以及包括全监督微调在内的许多训练协议中都表现出了稳健性。

**结果:** 结果表明，EM现象在各种模型尺寸、三个模型族系及多种训练方案下均能稳定出现。通过更清晰的模型生物体，研究者们识别出了一个机械式的相变过程，并证实了这一相变与所研究的所有生物体中观察到的稳健行为相变相对应。

**结论:** 尽管使大型语言模型保持一致对于前沿AI安全至关重要，但EM揭示了我们距离实现这一点还有多远。通过提炼那些隔离了最小化一致性妥协变化的干净模型生物体及其学习方式，研究为今后深入理解和减轻LLM中的对齐风险奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Model+Organisms+for+Emergent+Misalignment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11613，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11613&send_immediately=true&force_search=false)

**原文摘要:** Recent work discovered Emergent Misalignment (EM): fine-tuning large language
models on narrowly harmful datasets can lead them to become broadly misaligned.
A survey of experts prior to publication revealed this was highly unexpected,
demonstrating critical gaps in our understanding of model alignment. In this
work, we both advance understanding and provide tools for future research.
Using new narrowly misaligned datasets, we create a set of improved model
organisms that achieve 99% coherence (vs. 67% prior), work with smaller 0.5B
parameter models (vs. 32B), and that induce misalignment using a single rank-1
LoRA adapter. We demonstrate that EM occurs robustly across diverse model
sizes, three model families, and numerous training protocols including full
supervised fine-tuning. Leveraging these cleaner model organisms, we isolate a
mechanistic phase transition and demonstrate that it corresponds to a robust
behavioural phase transition in all studied organisms. Aligning large language
models is critical for frontier AI safety, yet EM exposes how far we are from
achieving this robustly. By distilling clean model organisms that isolate a
minimal alignment-compromising change, and where this is learnt, we establish a
foundation for future research into understanding and mitigating alignment
risks in LLMs.

</details>


### [73] [Position Paper: Rethinking AI/ML for Air Interface in Wireless Networks](https://arxiv.org/abs/2506.11466)
*Georgios Kontes, Diomidis S. Michalopoulos, Birendra Ghimire, Christopher Mutschler*

**主要类别:** cs.LG

**AI概要:** 本文探讨了AI/ML在无线通信中的应用，尤其是在空中接口部分，并概述了3GPP标准化讨论中与AI/ML相关的议题、关键用例、架构考量和技术要求。


<details>
  <summary>更多</summary>
  
**动机:** 尽管AI/ML在计算机视觉、自然语言处理和视频分析等领域得到了广泛应用，但在无线网络，特别是空中接口的应用还处于早期阶段。要充分发挥AI/ML在无线通信中的潜力，需要对两个领域有深入的跨学科理解。

**方法:** 本文提供了3GPP标准化过程中有关AI/ML的讨论概览，强调了关键应用场景、架构考虑以及技术需求。

**结果:** 文章确定了开放的研究挑战和机会，学术界和工业界可以在此基础上为未来AI赋能的无线系统的发展做出贡献。

**结论:** 为了实现AI/ML在无线通信中的全部潜能，必须克服现有的研究挑战，并抓住机遇来推动AI赋能的无线系统向前发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Position+Paper%3A+Rethinking+AI%2FML+for+Air+Interface+in+Wireless+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11466，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11466&send_immediately=true&force_search=false)

**原文摘要:** AI/ML research has predominantly been driven by domains such as computer
vision, natural language processing, and video analysis. In contrast, the
application of AI/ML to wireless networks, particularly at the air interface,
remains in its early stages. Although there are emerging efforts to explore
this intersection, fully realizing the potential of AI/ML in wireless
communications requires a deep interdisciplinary understanding of both fields.
We provide an overview of AI/ML-related discussions in 3GPP standardization,
highlighting key use cases, architectural considerations, and technical
requirements. We outline open research challenges and opportunities where
academic and industrial communities can contribute to shaping the future of
AI-enabled wireless systems.

</details>


### [74] [Convergent Linear Representations of Emergent Misalignment](https://arxiv.org/abs/2506.11618)
*Anna Soligo, Edward Turner, Senthooran Rajamanoharan, Neel Nanda*

**主要类别:** cs.LG

**AI概要:** 研究发现,使用少量的rank-1适配器对大型语言模型进行微调时,会导致模型出现普遍的不一致行为。这种现象被称为突发不一致,并且不同的突发不一致模型会收敛到类似的不一致表示。通过从一个微调模型中提取'不一致方向',可以有效地消除使用高维LoRAs和不同数据集进行微调时的不一致行为。


<details>
  <summary>更多</summary>
  
**动机:** 对于大型语言模型在狭窄的数据集上进行微调可能导致它们发展出广泛偏离的行为,即所谓的突发不一致现象。然而,导致这种不一致的根本机制以及它为何能够超出训练领域之外扩散,目前还不清楚,这表明我们在模型一致性方面存在重要的知识缺口。

**方法:** 研究人员训练并研究了一个最小模型,该模型仅使用9个rank-1适配器就足以引起Qwen2.5-14B-Instruct的突发不一致。通过观察这个过程,他们发现了不同突发不一致模型之间趋同于相似的不一致表达方式,并通过实验直接解释了微调适配器的作用,其中六个适配器贡献了一般性的不一致,而另外两个则专门针对微调领域的不一致。

**结果:** 结果表明,不同突发不一致模型确实会收敛到类似的表现形式,并且可以通过从一个微调模型中抽取'不一致方向'来有效移除其他微调过程中产生的不一致行为,即便这些微调采用了更高维度的LoRA或是基于不同的数据集。

**结论:** 这项工作加深了我们对于突发不一致性背后机制的理解,并为更好地理解和缓解更广泛意义上的不一致性提供了可能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Convergent+Linear+Representations+of+Emergent+Misalignment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11618，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11618&send_immediately=true&force_search=false)

**原文摘要:** Fine-tuning large language models on narrow datasets can cause them to
develop broadly misaligned behaviours: a phenomena known as emergent
misalignment. However, the mechanisms underlying this misalignment, and why it
generalizes beyond the training domain, are poorly understood, demonstrating
critical gaps in our knowledge of model alignment. In this work, we train and
study a minimal model organism which uses just 9 rank-1 adapters to emergently
misalign Qwen2.5-14B-Instruct. Studying this, we find that different emergently
misaligned models converge to similar representations of misalignment. We
demonstrate this convergence by extracting a 'misalignment direction' from one
fine-tuned model's activations, and using it to effectively ablate misaligned
behaviour from fine-tunes using higher dimensional LoRAs and different
datasets. Leveraging the scalar hidden state of rank-1 LoRAs, we further
present a set of experiments for directly interpreting the fine-tuning
adapters, showing that six contribute to general misalignment, while two
specialise for misalignment in just the fine-tuning domain. Emergent
misalignment is a particularly salient example of undesirable and unexpected
model behaviour and by advancing our understanding of the mechanisms behind it,
we hope to move towards being able to better understand and mitigate
misalignment more generally.

</details>


### [75] [Why Do Class-Dependent Evaluation Effects Occur with Time Series Feature Attributions? A Synthetic Data Investigation](https://arxiv.org/abs/2506.11790)
*Gregor Baer, Isel Grau, Chao Zhang, Pieter Van Gorp*

**主要类别:** cs.LG

**AI概要:** 研究发现，基于扰动的评估方法在不同预测类别中表现出不同的性能，这可能导致对特征归因质量的评价与实际情况不符。通过控制实验和合成时间序列数据，研究者们发现了即使是在简单的场景下，基于扰动的评价和基于真实情况的评价之间也经常存在矛盾。这些结果表明需要谨慎解读基于扰动的度量，并且提出了重新考虑归因评价实际衡量内容的机会，以及开发更全面的评价框架的可能性。


<details>
  <summary>更多</summary>
  
**动机:** 由于研究人员通常在没有真实情况时依赖基于扰动的指标来评估特征归因方法，而这些评估指标在相同数据集的不同预测类别上表现不同，因此这项研究旨在探讨这些类依赖效应在什么条件下出现，并质疑基于扰动分析是否可靠地测量了归因质量。

**方法:** 研究者通过使用具有已知真实特征位置的合成时间序列数据进行受控实验，系统地改变二元分类任务中的特征类型和类别对比，然后使用多种归因方法比较基于扰动的降级分数与基于真实情况的精确度-召回率指标。

**结果:** 实验表明，即使在具有时间局部化特征的简单情况下，当类别之间的特征幅度或时间范围有基本变化时，也会出现类依赖效应。更重要的是，基于扰动的方法和基于真实情况的指标经常在跨类别的归因质量评估上产生相互矛盾的结果，而且评估方法间的相关性较弱。

**结论:** 基于扰动的度量可能并不总是与归因是否正确识别区分特征相一致，这提示研究者应该仔细解释基于扰动的度量。此外，研究揭示了重新思考归因评价实际上衡量的内容的机会，并建议发展能够捕捉归因质量多个维度的更为全面的评价框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Why+Do+Class-Dependent+Evaluation+Effects+Occur+with+Time+Series+Feature+Attributions%3F+A+Synthetic+Data+Investigation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11790，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11790&send_immediately=true&force_search=false)

**原文摘要:** Evaluating feature attribution methods represents a critical challenge in
explainable AI (XAI), as researchers typically rely on perturbation-based
metrics when ground truth is unavailable. However, recent work demonstrates
that these evaluation metrics can show different performance across predicted
classes within the same dataset. These "class-dependent evaluation effects"
raise questions about whether perturbation analysis reliably measures
attribution quality, with direct implications for XAI method development and
the trustworthiness of evaluation techniques. We investigate under which
conditions these class-dependent effects arise by conducting controlled
experiments with synthetic time series data where ground truth feature
locations are known. We systematically vary feature types and class contrasts
across binary classification tasks, then compare perturbation-based degradation
scores with ground truth-based precision-recall metrics using multiple
attribution methods. Our experiments demonstrate that class-dependent effects
emerge with both evaluation approaches even in simple scenarios with temporally
localized features, triggered by basic variations in feature amplitude or
temporal extent between classes. Most critically, we find that
perturbation-based and ground truth metrics frequently yield contradictory
assessments of attribution quality across classes, with weak correlations
between evaluation approaches. These findings suggest that researchers should
interpret perturbation-based metrics with care, as they may not always align
with whether attributions correctly identify discriminating features. These
findings reveal opportunities to reconsider what attribution evaluation
actually measures and to develop more comprehensive evaluation frameworks that
capture multiple dimensions of attribution quality.

</details>


### [76] [TrustGLM: Evaluating the Robustness of GraphLLMs Against Prompt, Text, and Structure Attacks](https://arxiv.org/abs/2506.11844)
*Qihai Zhang, Xinyue Sheng, Yuanfu Sun, Qiaoyu Tan*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为TrustGLM的研究，旨在评估基于大型语言模型的图框架（GraphLLMs）在文本、图结构和提示操作三个维度上的对抗攻击脆弱性，并探讨了相应的防御技术。


<details>
  <summary>更多</summary>
  
**动机:** 受到大型语言模型成功的启发，研究从传统的图学习方法转向基于LLM的图框架（GraphLLMs）。尽管GraphLLMs具有潜力，但它们对对抗性扰动的鲁棒性尚未得到充分探索，这对高风险场景中的模型部署是一个关键问题。

**方法:** 提出了TrustGLM，一个全面的研究来评估GraphLLMs在文本、图结构和提示操作这三个方面对对抗攻击的脆弱性。使用最先进的攻击算法从每个角度严格评估模型韧性，并通过六个不同领域的基准数据集进行大量实验。

**结果:** 研究发现GraphLLMs极易受到文本攻击的影响，即仅替换节点文本属性中少数语义相似的词；标准图结构攻击方法可以显著降低模型性能；而提示模板中候选标签集的随机打乱会导致性能大幅下降。此外，还研究了针对每种攻击向量的数据增强训练和对抗训练等防御技术。

**结论:** TrustGLM研究揭示了GraphLLMs在多种攻击下的脆弱性，并展示了通过特定防御技术提高其鲁棒性的潜力。开源库希望促进公平快速的评估并激发该领域进一步创新研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TrustGLM%3A+Evaluating+the+Robustness+of+GraphLLMs+Against+Prompt%2C+Text%2C+and+Structure+Attacks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11844，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11844&send_immediately=true&force_search=false)

**原文摘要:** Inspired by the success of large language models (LLMs), there is a
significant research shift from traditional graph learning methods to LLM-based
graph frameworks, formally known as GraphLLMs. GraphLLMs leverage the reasoning
power of LLMs by integrating three key components: the textual attributes of
input nodes, the structural information of node neighborhoods, and
task-specific prompts that guide decision-making. Despite their promise, the
robustness of GraphLLMs against adversarial perturbations remains largely
unexplored-a critical concern for deploying these models in high-stakes
scenarios. To bridge the gap, we introduce TrustGLM, a comprehensive study
evaluating the vulnerability of GraphLLMs to adversarial attacks across three
dimensions: text, graph structure, and prompt manipulations. We implement
state-of-the-art attack algorithms from each perspective to rigorously assess
model resilience. Through extensive experiments on six benchmark datasets from
diverse domains, our findings reveal that GraphLLMs are highly susceptible to
text attacks that merely replace a few semantically similar words in a node's
textual attribute. We also find that standard graph structure attack methods
can significantly degrade model performance, while random shuffling of the
candidate label set in prompt templates leads to substantial performance drops.
Beyond characterizing these vulnerabilities, we investigate defense techniques
tailored to each attack vector through data-augmented training and adversarial
training, which show promising potential to enhance the robustness of
GraphLLMs. We hope that our open-sourced library will facilitate rapid,
equitable evaluation and inspire further innovative research in this field.

</details>


### [77] [Regression-adjusted Monte Carlo Estimators for Shapley Values and Probabilistic Values](https://arxiv.org/abs/2506.11849)
*R. Teal Witter, Yurong Liu, Christopher Musco*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种结合蒙特卡洛采样和线性回归方法的新技术，用于更准确地估计概率值如Shapley值等。实验表明，该方法在八个数据集上的表现优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 由于像Shapley值这样的概率值在可解释AI中作为核心工具被广泛使用，但其精确计算需要指数时间，因此研究集中于寻找有效的近似方法。

**方法:** 作者提出了一种新的方法来结合蒙特卡洛采样和线性回归两种技术，并且这种方法比先前的算法更加灵活，允许将线性回归替换为任何可以高效计算其概率值的函数族。

**结果:** 通过八个数据集的实验，新方法在估计Shapley值时的误差比Permutation SHAP低6.5倍，比Kernel SHAP低3.8倍，比Leverage SHAP低2.6倍。对于更一般的概率值，可以获得比之前工作中的最佳估计器低215倍的误差。

**结论:** 所提出的方法提供了最先进的性能来估计概率值，并且能够产生无偏估计，同时利用了树模型如XGBoost的准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Regression-adjusted+Monte+Carlo+Estimators+for+Shapley+Values+and+Probabilistic+Values，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11849，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11849&send_immediately=true&force_search=false)

**原文摘要:** With origins in game theory, probabilistic values like Shapley values,
Banzhaf values, and semi-values have emerged as a central tool in explainable
AI. They are used for feature attribution, data attribution, data valuation,
and more. Since all of these values require exponential time to compute
exactly, research has focused on efficient approximation methods using two
techniques: Monte Carlo sampling and linear regression formulations. In this
work, we present a new way of combining both of these techniques. Our approach
is more flexible than prior algorithms, allowing for linear regression to be
replaced with any function family whose probabilistic values can be computed
efficiently. This allows us to harness the accuracy of tree-based models like
XGBoost, while still producing unbiased estimates. From experiments across
eight datasets, we find that our methods give state-of-the-art performance for
estimating probabilistic values. For Shapley values, the error of our methods
can be $6.5\times$ lower than Permutation SHAP (the most popular Monte Carlo
method), $3.8\times$ lower than Kernel SHAP (the most popular linear regression
method), and $2.6\times$ lower than Leverage SHAP (the prior state-of-the-art
Shapley value estimator). For more general probabilistic values, we can obtain
error $215\times$ lower than the best estimator from prior work.

</details>


### [78] [Task-Driven Discrete Representation Learning](https://arxiv.org/abs/2506.11511)
*Tung-Long Vuong*

**主要类别:** cs.LG

**AI概要:** 本文从任务驱动的角度探讨了深度离散表示学习（DRL）的实用性，提出了一个统一框架来研究离散特征对下游任务的价值，并提供了关于表征能力和样本复杂度之间权衡的理论分析。


<details>
  <summary>更多</summary>
  
**动机:** 现有的大多数深度离散表示学习(DRL)框架主要关注生成设置，而离散表示的好坏在文献中定义模糊。作者希望从实用角度出发，基于任务来检验DRL，并探索离散特征对于下游任务的实际价值。

**方法:** 提出了一种统一的框架，该框架探索了离散特征与下游任务相关的有用性，同时提供了一个理论分析，探讨了表征能力与样本复杂度之间的权衡。

**结果:** 展示了所提出的框架在不同应用中的灵活性和有效性。

**结论:** 通过从任务驱动的角度重新审视深度离散表示学习，本文不仅为离散表示的质量提供了新的视角，而且通过理论分析加深了对其如何影响任务性能的理解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Task-Driven+Discrete+Representation+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11511，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11511&send_immediately=true&force_search=false)

**原文摘要:** In recent years, deep discrete representation learning (DRL) has achieved
significant success across various domains. Most DRL frameworks (e.g., the
widely used VQ-VAE and its variants) have primarily focused on generative
settings, where the quality of a representation is implicitly gauged by the
fidelity of its generation. In fact, the goodness of a discrete representation
remain ambiguously defined across the literature. In this work, we adopt a
practical approach that examines DRL from a task-driven perspective. We propose
a unified framework that explores the usefulness of discrete features in
relation to downstream tasks, with generation naturally viewed as one possible
application. In this context, the properties of discrete representations as
well as the way they benefit certain tasks are also relatively understudied. We
therefore provide an additional theoretical analysis of the trade-off between
representational capacity and sample complexity, shedding light on how discrete
representation utilization impacts task performance. Finally, we demonstrate
the flexibility and effectiveness of our framework across diverse applications.

</details>


### [79] [Robust Molecular Property Prediction via Densifying Scarce Labeled Data](https://arxiv.org/abs/2506.11877)
*Jina Kim, Jeffrey Willette, Bruno Andreis, Sung Ju Hwang*

**主要类别:** cs.LG

**AI概要:** 为了解决分子预测模型在处理训练数据分布外化合物时的泛化问题，本文提出了一种基于元学习的方法，该方法利用未标记的数据来插值分布内和分布外的数据，从而提高模型对于未知化合物的预测能力。


<details>
  <summary>更多</summary>
  
**动机:** 分子预测模型通常依赖于训练数据中观察到的结构，导致对分布外化合物的泛化性能较差。然而，在药物发现过程中，推动研究进展的关键化合物往往不在训练集之内，这使得模型偏向于训练数据的问题尤为突出。此外，由于实验验证的成本高昂且耗时，标签数据稀缺也加大了实现可靠泛化的难度。

**方法:** 提出了一种新的基于元学习的方法，通过利用未标记数据来填补分布内（ID）和分布外（OOD）数据之间的空白，让模型能够学会如何超越训练分布进行泛化。

**结果:** 所提出的方法在具有显著协变量偏移的实际挑战性数据集上，相较于最先进方法展示了显著的性能提升。

**结论:** 新提出的元学习方法有效地提高了分子预测模型对训练数据之外化合物的泛化能力，为药物研发提供了更可靠的工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robust+Molecular+Property+Prediction+via+Densifying+Scarce+Labeled+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11877，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11877&send_immediately=true&force_search=false)

**原文摘要:** A widely recognized limitation of molecular prediction models is their
reliance on structures observed in the training data, resulting in poor
generalization to out-of-distribution compounds. Yet in drug discovery, the
compounds most critical for advancing research often lie beyond the training
set, making the bias toward the training data particularly problematic. This
mismatch introduces substantial covariate shift, under which standard deep
learning models produce unstable and inaccurate predictions. Furthermore, the
scarcity of labeled data, stemming from the onerous and costly nature of
experimental validation, further exacerbates the difficulty of achieving
reliable generalization. To address these limitations, we propose a novel
meta-learning-based approach that leverages unlabeled data to interpolate
between in-distribution (ID) and out-of-distribution (OOD) data, enabling the
model to meta-learn how to generalize beyond the training distribution. We
demonstrate significant performance gains over state-of-the-art methods on
challenging real-world datasets that exhibit substantial covariate shift.

</details>


### [80] [Brewing Knowledge in Context: Distillation Perspectives on In-Context Learning](https://arxiv.org/abs/2506.11516)
*Chengye Li, Haiyun Liu, Yuanxi Li*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的理论视角，将上下文学习（ICL）解释为一种隐式知识蒸馏形式，并通过该视角推导出一个基于Rademacher复杂度的泛化界。


<details>
  <summary>更多</summary>
  
**动机:** 尽管上下文学习在实践中取得了成功，但其背后的机制仍不被充分理解，这限制了我们对它的解释、改进和可靠应用的能力。

**方法:** 作者将ICL视为一种隐式的知识蒸馏过程，在这个过程中，提示示例引导模型在推理时形成特定于任务的参考模型，并基于此观点推导了一个Rademacher复杂度泛化边界。

**结果:** 研究结果表明，蒸馏权重的偏差与提示和目标分布之间的最大均值差异（MMD）呈线性增长。

**结论:** 提出的理论框架解释了几个实证现象，并统一了先前基于梯度和基于分布的分析，这是首次将推理时注意力正式化为一个蒸馏过程。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Brewing+Knowledge+in+Context%3A+Distillation+Perspectives+on+In-Context+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11516，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11516&send_immediately=true&force_search=false)

**原文摘要:** In-context learning (ICL) allows large language models (LLMs) to solve novel
tasks without weight updates. Despite its empirical success, the mechanism
behind ICL remains poorly understood, limiting our ability to interpret,
improve, and reliably apply it. In this paper, we propose a new theoretical
perspective that interprets ICL as an implicit form of knowledge distillation
(KD), where prompt demonstrations guide the model to form a task-specific
reference model during inference. Under this view, we derive a Rademacher
complexity-based generalization bound and prove that the bias of the distilled
weights grows linearly with the Maximum Mean Discrepancy (MMD) between the
prompt and target distributions. This theoretical framework explains several
empirical phenomena and unifies prior gradient-based and distributional
analyses. To the best of our knowledge, this is the first to formalize
inference-time attention as a distillation process, which provides theoretical
insights for future prompt engineering and automated demonstration selection.

</details>


### [81] [An Explainable AI Framework for Dynamic Resource Management in Vehicular Network Slicing](https://arxiv.org/abs/2506.11882)
*Haochen Sun, Yifan Liu, Ahmed Al-Tahmeesschi, Swarna Chetty, Syed Ali Raza Zaidi, Avishek Nag, Hamed Ahmadi*

**主要类别:** cs.LG

**AI概要:** 论文提出了一种可解释的深度强化学习(XRL)框架，用于车联网中的动态网络切片和资源分配。该方法结合了基于特征的方法（利用Shapley值）和注意力机制来解析和优化决策过程，提高了eMBB和URLLC服务的质量(QoS)满意度。


<details>
  <summary>更多</summary>
  
**动机:** 为了满足包括增强移动宽带(eMBB)和超可靠低延迟通信(URLLC)在内的多样化车联网服务需求，需要有效的资源管理和网络切片。

**方法:** 采用一种可解释的深度强化学习(XRL)框架，该框架建立在接近实时的RAN智能控制器上，并且通过集成基于特征的方法（利用Shapley值）和注意力机制来解析和优化强化学习代理的决策。

**结果:** 仿真结果显示，所提方法提供了清晰的实时资源分配过程洞察，并且相比纯注意力机制实现了更高的解释精度。此外，URLLC服务的QoS满意度从78.0%提升到了80.13%，而eMBB服务的QoS满意度则从71.44%提高到了73.21%。

**结论:** 本研究提出的XRL框架有效提升了车联网中eMBB和URLLC服务的资源管理效率与服务质量满意度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Explainable+AI+Framework+for+Dynamic+Resource+Management+in+Vehicular+Network+Slicing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11882，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11882&send_immediately=true&force_search=false)

**原文摘要:** Effective resource management and network slicing are essential to meet the
diverse service demands of vehicular networks, including Enhanced Mobile
Broadband (eMBB) and Ultra-Reliable and Low-Latency Communications (URLLC).
This paper introduces an Explainable Deep Reinforcement Learning (XRL)
framework for dynamic network slicing and resource allocation in vehicular
networks, built upon a near-real-time RAN intelligent controller. By
integrating a feature-based approach that leverages Shapley values and an
attention mechanism, we interpret and refine the decisions of our
reinforcementlearning agents, addressing key reliability challenges in
vehicular communication systems. Simulation results demonstrate that our
approach provides clear, real-time insights into the resource allocation
process and achieves higher interpretability precision than a pure attention
mechanism. Furthermore, the Quality of Service (QoS) satisfaction for URLLC
services increased from 78.0% to 80.13%, while that for eMBB services improved
from 71.44% to 73.21%.

</details>


### [82] [Delayformer: spatiotemporal transformation for predicting high-dimensional dynamics](https://arxiv.org/abs/2506.11528)
*Zijian Wang, Peng Tao, Luonan Chen*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Delayformer的新框架，该框架通过开发一种新的多变量时空信息转换方法来同时预测所有变量的动态，这种方法将每个观测变量转换为延迟嵌入状态（向量），并进一步从不同变量中交叉学习这些状态。


<details>
  <summary>更多</summary>
  
**动机:** 在有限和噪声数据的情况下，准确预测高维系统中所有变量的动力学是一个具有挑战性的任务，因为它们的非线性和复杂的相互作用。当前的方法，包括深度学习方法，在这种情况下对现实世界的系统表现往往不佳。

**方法:** Delayformer框架首先利用一个共享的视觉Transformer（ViT）编码器以延迟嵌入的形式从观察到的变量中交叉表示动力学状态，然后采用不同的线性解码器来预测下一个状态，即并行地预测所有原始变量。

**结果:** 通过利用延迟嵌入理论的理论基础和Transformers的表现能力，Delayformer在合成数据集和真实世界数据集上的预测任务中都优于当前最先进方法，并且展示了其作为基础时间序列模型跨领域预测任务中的潜力。

**结论:** Delayformer作为一种新的框架，能够克服非线性和交互问题，从而在多种场景下展现出广泛适用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Delayformer%3A+spatiotemporal+transformation+for+predicting+high-dimensional+dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11528，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11528&send_immediately=true&force_search=false)

**原文摘要:** Predicting time-series is of great importance in various scientific and
engineering fields. However, in the context of limited and noisy data,
accurately predicting dynamics of all variables in a high-dimensional system is
a challenging task due to their nonlinearity and also complex interactions.
Current methods including deep learning approaches often perform poorly for
real-world systems under such circumstances. This study introduces the
Delayformer framework for simultaneously predicting dynamics of all variables,
by developing a novel multivariate spatiotemporal information (mvSTI)
transformation that makes each observed variable into a delay-embedded state
(vector) and further cross-learns those states from different variables. From
dynamical systems viewpoint, Delayformer predicts system states rather than
individual variables, thus theoretically and computationally overcoming such
nonlinearity and cross-interaction problems. Specifically, it first utilizes a
single shared Visual Transformer (ViT) encoder to cross-represent dynamical
states from observed variables in a delay embedded form and then employs
distinct linear decoders for predicting next states, i.e. equivalently
predicting all original variables parallelly. By leveraging the theoretical
foundations of delay embedding theory and the representational capabilities of
Transformers, Delayformer outperforms current state-of-the-art methods in
forecasting tasks on both synthetic and real-world datasets. Furthermore, the
potential of Delayformer as a foundational time-series model is demonstrated
through cross-domain forecasting tasks, highlighting its broad applicability
across various scenarios.

</details>


### [83] [Attention-based Adversarial Robust Distillation in Radio Signal Classifications for Low-Power IoT Devices](https://arxiv.org/abs/2506.11892)
*Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Guisheng Liao, Basil AsSadhan, Fabio Roli*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的紧凑型变压器设计，用于调制分类，并且能够通过从鲁棒训练的大变压器转移对抗注意力图来提高对对抗性攻击的鲁抗性。该方法在白盒场景下超越了现有技术，包括快速梯度法和投影梯度下降攻击，并探讨了不同架构间对抗样本的可迁移性。


<details>
  <summary>更多</summary>
  
**动机:** 由于变压器在自然语言处理和计算机视觉等许多应用中的巨大成功，变压器也被成功应用于自动调制分类中。然而，基于变压器的无线电信号分类容易受到难以察觉且精心制作的对抗样本攻击。因此，研究者提出了一个针对变压器基调制分类中对抗样本的防御系统。考虑到物联网（IoT）应用程序或电力供应受限环境下的设备操作需要计算效率高的架构，研究者还提出了一种紧凑型变压器。

**方法:** 为了增强紧凑型变压器在对抗攻击面前的鲁棒性，研究者提出了一种新方法，这种方法旨在将鲁棒训练的大变压器的对抗注意力图转移到紧凑型变压器上。

**结果:** 所提出的方法在考虑的白盒场景中表现出色，超过了当前最先进的技术，包括快速梯度方法和投影梯度下降攻击。此外，研究者提供了工作机理的基本原理，并调查了对抗样本在不同架构之间的可迁移性。

**结论:** 提出的方法具有保护变压器免受对抗样本迁移的能力，并为在资源受限环境下使用紧凑型变压器进行鲁棒调制分类提供了一个有潜力的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Attention-based+Adversarial+Robust+Distillation+in+Radio+Signal+Classifications+for+Low-Power+IoT+Devices，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11892，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11892&send_immediately=true&force_search=false)

**原文摘要:** Due to great success of transformers in many applications such as natural
language processing and computer vision, transformers have been successfully
applied in automatic modulation classification. We have shown that
transformer-based radio signal classification is vulnerable to imperceptible
and carefully crafted attacks called adversarial examples. Therefore, we
propose a defense system against adversarial examples in transformer-based
modulation classifications. Considering the need for computationally efficient
architecture particularly for Internet of Things (IoT)-based applications or
operation of devices in environment where power supply is limited, we propose a
compact transformer for modulation classification. The advantages of robust
training such as adversarial training in transformers may not be attainable in
compact transformers. By demonstrating this, we propose a novel compact
transformer that can enhance robustness in the presence of adversarial attacks.
The new method is aimed at transferring the adversarial attention map from the
robustly trained large transformer to a compact transformer. The proposed
method outperforms the state-of-the-art techniques for the considered white-box
scenarios including fast gradient method and projected gradient descent
attacks. We have provided reasoning of the underlying working mechanisms and
investigated the transferability of the adversarial examples between different
architectures. The proposed method has the potential to protect the transformer
from the transferability of adversarial examples.

</details>


### [84] [Robust Filtering -- Novel Statistical Learning and Inference Algorithms with Applications](https://arxiv.org/abs/2506.11530)
*Aamir Hussain Chughtai*

**主要类别:** cs.LG

**AI概要:** 本论文提出了一种新的鲁棒非线性滤波方法，以应对现实世界中异常情况下的状态估计问题，并通过多个场景验证了该方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 传统滤波方法假设已知噪声统计特性，但在实际应用中经常遇到异常值、偏差、漂移和缺失观测等未知或部分已知的统计特性，这限制了常规方法的应用。

**方法:** 本论文基于贝叶斯推断框架，采用确定性和随机近似技术（包括变分推理VI和粒子滤波/顺序蒙特卡洛SMC）开发了新的鲁棒非线性滤波方法。此外，还研究了在测量异常情况下使用贝叶斯克拉美-罗界（BCRBs）来探讨理论估计极限。

**结果:** 通过目标跟踪、室内定位、3D点云配准、网格配准以及位姿图优化等场景中的模拟与实验，验证了所提方法的性能提升。

**结论:** 工作具有基础性质，对多种应用场景有用，并可能在未来向开发抗异常机器学习管道、从异常数据中学习系统动力学等方面扩展，解决生成式AI中标准扩散模型面临的挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robust+Filtering+--+Novel+Statistical+Learning+and+Inference+Algorithms+with+Applications，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11530，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11530&send_immediately=true&force_search=false)

**原文摘要:** State estimation or filtering serves as a fundamental task to enable
intelligent decision-making in applications such as autonomous vehicles,
robotics, healthcare monitoring, smart grids, intelligent transportation, and
predictive maintenance. Standard filtering assumes prior knowledge of noise
statistics to extract latent system states from noisy sensor data. However,
real-world scenarios involve abnormalities like outliers, biases, drifts, and
missing observations with unknown or partially known statistics, limiting
conventional approaches. This thesis presents novel robust nonlinear filtering
methods to mitigate these challenges. Based on insights from our filtering
proposals, we extend the formulations to offline estimation/learning setups and
propose smoothing extensions. Our methods leverage Bayesian inference
frameworks, employing both deterministic and stochastic approximation
techniques including Variational Inference (VI) and Particle Filters/Sequential
Monte Carlo (SMC). We also study theoretical estimation limits using Bayesian
Cram\'er-Rao bounds (BCRBs) in the context of measurement abnormalities. To
validate the performance gains of the proposed methods, we perform simulations
and experiments in scenarios including target tracking, indoor localization, 3D
point cloud registration, mesh registration, and pose graph optimization. The
fundamental nature of the work makes it useful in diverse applications, with
possible future extensions toward developing outlier-robust machine learning
pipelines, learning system dynamics from anomalous data, and addressing
challenges in generative AI where standard diffusion models struggle with
outliers, imbalanced datasets, and mode collapse.

</details>


### [85] [A Neural Rejection System Against Universal Adversarial Perturbations in Radio Signal Classification](https://arxiv.org/abs/2506.11901)
*Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Fabio Roli*

**主要类别:** cs.LG

**AI概要:** 本文研究了一种称为神经拒绝系统的防御机制，以对抗普遍存在的对抗性扰动，并通过实验证明该系统比未受保护的深度神经网络能够更有效地抵御这种攻击。


<details>
  <summary>更多</summary>
  
**动机:** 近年来，尽管深度学习在无线电信号分类中表现出优于传统方法的优势，但研究人员发现即使是小而故意的特征扰动（即对抗样本）也能显著降低基于深度学习的无线电信号分类性能。其中，由于通用对抗扰动具有数据独立性的特点，因此成为一种实用策略，能以高成功率愚弄无线电信号分类。

**方法:** 提出并探讨了一种名为神经拒绝系统的防御机制来对抗通用对抗扰动，并且通过生成白盒通用对抗扰动来评估其性能。

**结果:** 实验结果表明，所提出的神经拒绝系统能够比未经防护的深度神经网络以明显更高的准确率抵御通用对抗扰动。

**结论:** 神经拒绝系统作为抵御通用对抗扰动的有效手段，能够在无线电信号分类任务中提供更强的安全性和鲁棒性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Neural+Rejection+System+Against+Universal+Adversarial+Perturbations+in+Radio+Signal+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11901，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11901&send_immediately=true&force_search=false)

**原文摘要:** Advantages of deep learning over traditional methods have been demonstrated
for radio signal classification in the recent years. However, various
researchers have discovered that even a small but intentional feature
perturbation known as adversarial examples can significantly deteriorate the
performance of the deep learning based radio signal classification. Among
various kinds of adversarial examples, universal adversarial perturbation has
gained considerable attention due to its feature of being data independent,
hence as a practical strategy to fool the radio signal classification with a
high success rate. Therefore, in this paper, we investigate a defense system
called neural rejection system to propose against universal adversarial
perturbations, and evaluate its performance by generating white-box universal
adversarial perturbations. We show that the proposed neural rejection system is
able to defend universal adversarial perturbations with significantly higher
accuracy than the undefended deep neural network.

</details>


### [86] [Spectra-to-Structure and Structure-to-Spectra Inference Across the Periodic Table](https://arxiv.org/abs/2506.11908)
*Yufeng Wang, Peiyao Wang, Lu Ma, Yuewei Lin, Qun Liu, Haibin Ling*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为XAStruct的学习框架，它能够从晶体结构预测XAS光谱，并从XAS输入推断局部结构描述符。该模型在覆盖周期表上70多种元素的大规模数据集上进行训练，具有广泛的化学和键合环境泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的X射线吸收光谱（XAS）解释方法依赖于专家分析、计算成本高昂的模拟以及特定元素的经验法则。机器学习虽有加速XAS解释的潜力，但现有模型往往针对特定元素或光谱范围而设计。因此，需要一个更加通用且高效的学习框架来解决这些问题。

**方法:** 研究者开发了XAStruct，这是一个可以从晶体结构预测XAS光谱并从XAS光谱反推局部结构描述符的学习框架。XAStruct使用了一个大规模的数据集，涵盖了周期表中超过70种元素。模型包括首个直接从XAS光谱预测邻近原子类型的机器学习方法，以及一个无需特定元素调整的统一回归模型来预测平均最近邻距离。尽管尝试过将两个流程整合成单一端到端模型，但实证结果表明这样会导致性能下降，最终选择分别独立训练以确保最佳准确性和任务特异性表现。

**结果:** XAStruct提供了一个可扩展和可扩展的解决方案，用于数据驱动的XAS分析和局部结构推断。通过结合深度神经网络处理复杂的结构-性质映射，以及为更简单任务提供高效的基线模型，XAStruct能够在广泛的化学和键合环境中应用。

**结论:** XAStruct是一个强大的工具，能够提升XAS光谱的解析效率和准确性，同时具备对不同元素和化学环境的良好适应性。它代表了向实现完全数据驱动的XAS分析迈出的重要一步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Spectra-to-Structure+and+Structure-to-Spectra+Inference+Across+the+Periodic+Table，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11908，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11908&send_immediately=true&force_search=false)

**原文摘要:** X-ray Absorption Spectroscopy (XAS) is a powerful technique for probing local
atomic environments, yet its interpretation remains limited by the need for
expert-driven analysis, computationally expensive simulations, and
element-specific heuristics. Recent advances in machine learning have shown
promise for accelerating XAS interpretation, but many existing models are
narrowly focused on specific elements, edge types, or spectral regimes. In this
work, we present XAStruct, a learning framework capable of both predicting XAS
spectra from crystal structures and inferring local structural descriptors from
XAS input. XAStruct is trained on a large-scale dataset spanning over 70
elements across the periodic table, enabling generalization to a wide variety
of chemistries and bonding environments. The model includes the first machine
learning approach for predicting neighbor atom types directly from XAS spectra,
as well as a unified regression model for mean nearest-neighbor distance that
requires no element-specific tuning. While we explored integrating the two
pipelines into a single end-to-end model, empirical results showed performance
degradation. As a result, the two tasks were trained independently to ensure
optimal accuracy and task-specific performance. By combining deep neural
networks for complex structure-property mappings with efficient baseline models
for simpler tasks, XAStruct offers a scalable and extensible solution for
data-driven XAS analysis and local structure inference. The source code will be
released upon paper acceptance.

</details>


### [87] [Breaking Habits: On the Role of the Advantage Function in Learning Causal State Representations](https://arxiv.org/abs/2506.11912)
*Miguel Suau*

**主要类别:** cs.LG

**AI概要:** 本文探讨了优势函数在策略梯度方法中如何帮助减少策略混淆现象，并通过理论分析和实证研究证明其能改善智能体在非典型轨迹上的表现。


<details>
  <summary>更多</summary>
  
**动机:** 先前的研究表明强化学习智能体会利用奖励与观察之间虚假的相关性来制定策略，这会导致策略混淆。本文旨在展示优势函数不仅可以降低梯度估计的方差，还可以减轻策略混淆的影响。

**方法:** 本文采用了理论分析结合实证的方法，展示了优势函数通过调整相对于状态表示的动作值，降低了当前策略下更可能出现的状态-动作对的重要性，从而打破了虚假相关性并鼓励智能体专注于因果因素。

**结果:** 结果表明，使用优势函数训练可以导致更好的出轨迹性能，即智能体能够更好地泛化到它通常路径之外的情境。

**结论:** 结论是优势函数在策略梯度方法中的应用有助于缓解策略混淆问题，提高智能体在新情境下的泛化能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Breaking+Habits%3A+On+the+Role+of+the+Advantage+Function+in+Learning+Causal+State+Representations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11912，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11912&send_immediately=true&force_search=false)

**原文摘要:** Recent work has shown that reinforcement learning agents can develop policies
that exploit spurious correlations between rewards and observations. This
phenomenon, known as policy confounding, arises because the agent's policy
influences both past and future observation variables, creating a feedback loop
that can hinder the agent's ability to generalize beyond its usual
trajectories. In this paper, we show that the advantage function, commonly used
in policy gradient methods, not only reduces the variance of gradient estimates
but also mitigates the effects of policy confounding. By adjusting action
values relative to the state representation, the advantage function downweights
state-action pairs that are more likely under the current policy, breaking
spurious correlations and encouraging the agent to focus on causal factors. We
provide both analytical and empirical evidence demonstrating that training with
the advantage function leads to improved out-of-trajectory performance.

</details>


### [88] [EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction](https://arxiv.org/abs/2506.12015)
*Hsi-Che Lin, Yu-Chu Yu, Kai-Po Chang, Yu-Chiang Frank Wang*

**主要类别:** cs.LG

**AI概要:** EMLoC是一个基于模拟器的内存高效微调框架，通过LoRA校正实现模型微调，同时保持与推理相同的内存预算。它使用下游校准集上的激活感知奇异值分解来构建轻量级模拟器，并提出了一种新的补偿算法以纠正微调后的LoRA模块，从而可以将其合并到原始模型中进行推理。EMLoC支持灵活的压缩比率和标准训练流程，适用于广泛的应用场景，并在多个数据集和模态上优于其他基线方法。


<details>
  <summary>更多</summary>
  
**动机:** 由于对大型基础模型进行领域特定或个性化任务的微调需要大量的内存开销，对于大多数用户来说成本过高。因此，开发一种内存高效的微调方法，使得个人用户也能够负担得起模型微调，成为了研究的动机。

**方法:** EMLoC采用了基于模拟器的方法，首先利用小规模下游校准集上的激活感知奇异值分解创建一个轻量级的任务特定模拟器。然后，在这个轻量级模拟器上通过LoRA执行微调。为了处理原始模型与压缩后模拟器之间的不匹配问题，提出了一个新的补偿算法来修正微调后的LoRA模块，以便它可以被集成回原模型中用于推理。

**结果:** 广泛的实验表明，EMLoC在多个数据集和模态上相对于其他基线方法表现更优。此外，无需量化的情况下，EMLoC允许在单个24GB消费级GPU上对380亿参数模型进行微调，为个人用户提供了一个高效且实用的模型适应方案。

**结论:** EMLoC提供了一种新颖而有效的解决方案，解决了大型基础模型微调时遇到的高内存需求问题。该框架不仅降低了微调的成本，还提高了灵活性和实用性，使得个人用户也能进行高级别模型的微调。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EMLoC%3A+Emulator-based+Memory-efficient+Fine-tuning+with+LoRA+Correction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.12015，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.12015&send_immediately=true&force_search=false)

**原文摘要:** Open-source foundation models have seen rapid adoption and development,
enabling powerful general-purpose capabilities across diverse domains. However,
fine-tuning large foundation models for domain-specific or personalized tasks
remains prohibitively expensive for most users due to the significant memory
overhead beyond that of inference. We introduce EMLoC, an Emulator-based
Memory-efficient fine-tuning framework with LoRA Correction, which enables
model fine-tuning within the same memory budget required for inference. EMLoC
constructs a task-specific light-weight emulator using activation-aware
singular value decomposition (SVD) on a small downstream calibration set.
Fine-tuning then is performed on this lightweight emulator via LoRA. To tackle
the misalignment between the original model and the compressed emulator, we
propose a novel compensation algorithm to correct the fine-tuned LoRA module,
which thus can be merged into the original model for inference. EMLoC supports
flexible compression ratios and standard training pipelines, making it
adaptable to a wide range of applications. Extensive experiments demonstrate
that EMLoC outperforms other baselines across multiple datasets and modalities.
Moreover, without quantization, EMLoC enables fine-tuning of a 38B model on a
single 24GB consumer GPU-bringing efficient and practical model adaptation to
individual users.

</details>


### [89] [KCES: Training-Free Defense for Robust Graph Neural Networks via Kernel Complexity](https://arxiv.org/abs/2506.11611)
*Yaning Jia, Shenyang Deng, Chiyu Ma, Yaoqing Yang, Soroush Vosoughi*

**主要类别:** cs.LG

**AI概要:** 本文提出了基于核复杂度的边净化(KCES)框架，这是一种无需训练且与模型无关的防御方法，通过移除对图核复杂度影响较大的边来提高GNN对抗扰动和攻击的鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管已经有许多针对GNN脆弱性的防御方法被提出，但它们往往依赖于启发式指标、过拟合特定攻击模式，并且计算复杂度高。为了克服这些局限性，需要一种新的防御机制，既能提供理论保障又能有效提升GNN的鲁棒性。

**方法:** KCES框架利用了图核复杂度(GKC)，这是一个从图的Gram矩阵中导出的新颖度量标准，用于表征GNN的一般化能力。根据GKC，为每条边定义了一个KC分数，衡量删除该边时GKC的变化。具有高KC分数的边通常由对抗性扰动引入，将被修剪以减轻其有害影响。

**结果:** 理论分析和广泛的实验表明，KCES能够一致地增强GNN的鲁棒性，优于最先进基线的表现，并且提高了现有防御策略的有效性。

**结论:** KCES作为一种即插即用模块，可以无缝集成到现有的防御策略中，而不需要额外的训练过程，为保护GNN提供了一种有原则且高效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是KCES%3A+Training-Free+Defense+for+Robust+Graph+Neural+Networks+via+Kernel+Complexity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11611，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11611&send_immediately=true&force_search=false)

**原文摘要:** Graph Neural Networks (GNNs) have achieved impressive success across a wide
range of graph-based tasks, yet they remain highly vulnerable to small,
imperceptible perturbations and adversarial attacks. Although numerous defense
methods have been proposed to address these vulnerabilities, many rely on
heuristic metrics, overfit to specific attack patterns, and suffer from high
computational complexity. In this paper, we propose Kernel Complexity-Based
Edge Sanitization (KCES), a training-free, model-agnostic defense framework.
KCES leverages Graph Kernel Complexity (GKC), a novel metric derived from the
graph's Gram matrix that characterizes GNN generalization via its test error
bound. Building on GKC, we define a KC score for each edge, measuring the
change in GKC when the edge is removed. Edges with high KC scores, typically
introduced by adversarial perturbations, are pruned to mitigate their harmful
effects, thereby enhancing GNNs' robustness. KCES can also be seamlessly
integrated with existing defense strategies as a plug-and-play module without
requiring training. Theoretical analysis and extensive experiments demonstrate
that KCES consistently enhances GNN robustness, outperforms state-of-the-art
baselines, and amplifies the effectiveness of existing defenses, offering a
principled and efficient solution for securing GNNs.

</details>


### [90] [Machine Unlearning for Robust DNNs: Attribution-Guided Partitioning and Neuron Pruning in Noisy Environments](https://arxiv.org/abs/2506.11615)
*Deliang Jin, Gang Chen, Shuo Feng, Yufeng Ling, Haoran Zhu*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一种受机器遗忘原理启发的新框架，通过归因引导的数据分区、区分性神经元剪枝和针对性微调来减轻噪声样本的影响。这种方法不需要对噪声分布做出严格假设，也不需要完全重新训练模型，而是在高质量数据子集上微调网络以恢复并提高其泛化性能。在CIFAR-10图像分类等代表性任务中，与标准再训练相比，该框架能够显著提高准确率，并且减少再训练时间。


<details>
  <summary>更多</summary>
  
**动机:** 深度神经网络容易受到噪声或损坏的训练数据的影响，导致性能严重下降。传统的噪声缓解方法通常依赖于对噪声分布的显式假设，或者需要广泛的再训练，这对于大规模模型来说是不切实际的。

**方法:** 本文提出的框架结合了归因引导的数据分区、区分性神经元剪枝以及有针对性的微调，首先使用基于梯度的归因来概率地区分高质量示例和可能被破坏的示例，然后应用基于回归的灵敏度分析识别并剪枝最易受噪声影响的神经元，最后在高质量数据子集上微调得到的网络。

**结果:** 评估表明，在不同噪声水平下，该方法在代表性的任务（如CIFAR-10图像分类和语音识别）中都取得了显著的准确性和效率提升。例如，在注入标签噪声的CIFAR-10上，该框架比标准再训练大约提高了10%的绝对精度，同时在某些设置中减少了高达47%的再训练时间。

**结论:** 所提出的方法展示了在噪声环境中实现鲁棒泛化的有效性和可扩展性，相比传统抗噪学习方法具有多方面优势，包括避免全模型重训或显式噪声建模的需求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Machine+Unlearning+for+Robust+DNNs%3A+Attribution-Guided+Partitioning+and+Neuron+Pruning+in+Noisy+Environments，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11615，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11615&send_immediately=true&force_search=false)

**原文摘要:** Deep neural networks (DNNs) have achieved remarkable success across diverse
domains, but their performance can be severely degraded by noisy or corrupted
training data. Conventional noise mitigation methods often rely on explicit
assumptions about noise distributions or require extensive retraining, which
can be impractical for large-scale models. Inspired by the principles of
machine unlearning, we propose a novel framework that integrates
attribution-guided data partitioning, discriminative neuron pruning, and
targeted fine-tuning to mitigate the impact of noisy samples. Our approach
employs gradient-based attribution to probabilistically distinguish
high-quality examples from potentially corrupted ones without imposing
restrictive assumptions on the noise. It then applies regression-based
sensitivity analysis to identify and prune neurons that are most vulnerable to
noise. Finally, the resulting network is fine-tuned on the high-quality data
subset to efficiently recover and enhance its generalization performance. This
integrated unlearning-inspired framework provides several advantages over
conventional noise-robust learning approaches. Notably, it combines data-level
unlearning with model-level adaptation, thereby avoiding the need for full
model retraining or explicit noise modeling. We evaluate our method on
representative tasks (e.g., CIFAR-10 image classification and speech
recognition) under various noise levels and observe substantial gains in both
accuracy and efficiency. For example, our framework achieves approximately a
10% absolute accuracy improvement over standard retraining on CIFAR-10 with
injected label noise, while reducing retraining time by up to 47% in some
settings. These results demonstrate the effectiveness and scalability of the
proposed approach for achieving robust generalization in noisy environments.

</details>


### [91] [Physically-informed change-point kernels for structural dynamics](https://arxiv.org/abs/2506.11625)
*Daniel James Pitchforth, Matthew Rhys Jones, Samuel John Gibson, Elizabeth Jane Cross*

**主要类别:** cs.LG

**AI概要:** 本文开发了一种新的物理信息变化点核函数，用于高斯过程，能够动态调整对可用物理知识的依赖程度，并允许用户定义现象发生条件及知识在模型中引入和退出的速度。此外，还实现了基于物理现象发生的建模噪声变化，以更准确地捕捉不确定性。通过两个工程案例研究了新核结构的能力。


<details>
  <summary>更多</summary>
  
**动机:** 确保物理信息机器学习者内部物理和数据之间的相对平衡是重要的建模考虑因素，以充分利用基于物理和数据方法的优势。过度依赖物理知识可能有害，而物理知识利用不足则可能浪费宝贵资源。实现最优的物理-数据平衡是一项挑战，特别是在该水平随时间变化的情况下。

**方法:** 本文提出了新的、具有物理信息的变化点核函数，适用于高斯过程，能够根据条件自动学习并恢复对物理知识的依赖切换。同时，还实施了基于所发生物理现象的建模噪声变化，以便与预测一起提供更代表性的不确定性捕获。

**结果:** 通过两个工程案例研究展示了新型核结构的能力：斜拉桥的方向风载荷以及飞行操作期间飞机机翼应变的预测。

**结论:** 这些新的核函数提供了对物理知识使用程度的高水平控制，使得用户可以定义他们认为现象应该出现的条件，以及知识被逐步引入或移出模型的速度。当用户不太确定时，模型可以自动学习并以可解释且直观的方式恢复对物理知识的依赖切换。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Physically-informed+change-point+kernels+for+structural+dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11625，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11625&send_immediately=true&force_search=false)

**原文摘要:** The relative balance between physics and data within any physics-informed
machine learner is an important modelling consideration to ensure that the
benefits of both physics and data-based approaches are maximised. An over
reliance on physical knowledge can be detrimental, particularly when the
physics-based component of a model may not accurately represent the true
underlying system. An underutilisation of physical knowledge potentially wastes
a valuable resource, along with benefits in model interpretability and reduced
demand for expensive data collection. Achieving an optimal physics-data balance
is a challenging aspect of model design, particularly if the level varies
through time; for example, one might have a physical approximation, only valid
within particular regimes, or a physical phenomenon may be known to only occur
when given conditions are met (e.g. at high temperatures). This paper develops
novel, physically-informed, change-point kernels for Gaussian processes,
capable of dynamically varying the reliance upon available physical knowledge.
A high level of control is granted to a user, allowing for the definition of
conditions in which they believe a phenomena should occur and the rate at which
the knowledge should be phased in and out of a model. In circumstances where
users may be less certain, the switching reliance upon physical knowledge may
be automatically learned and recovered from the model in an interpretable and
intuitive manner. Variation of the modelled noise based on the physical
phenomena occurring is also implemented to provide a more representative
capture of uncertainty alongside predictions. The capabilities of the new
kernel structures are explored through the use of two engineering case studies:
the directional wind loading of a cable-stayed bridge and the prediction of
aircraft wing strain during in-flight manoeuvring.

</details>


### [92] [Geometry-Aware Edge Pooling for Graph Neural Networks](https://arxiv.org/abs/2506.11700)
*Katharina Limbeck, Lydia Mezrag, Guy Wolf, Bastian Rieck*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的图池化层，通过边塌缩来实现结构感知的池化。该方法利用扩散几何并迭代地减小图的大小，同时保持其度量结构和结构多样性。实验结果表明，与其它池化层相比，所提方法在多种图分类任务中表现更优，能够保留输入图的关键谱属性，并且在不同的池化比率下仍能保持高精度。


<details>
  <summary>更多</summary>
  
**动机:** 现有图神经网络中的池化操作往往以牺牲基础图结构和可解释性为代价来优化学习任务，导致在不同数据集类型、下游任务和池化比率下的性能不稳定。

**方法:** 提出了新的图池化层，通过边塌缩的方式来进行结构感知的池化。这些方法基于扩散几何，并逐步减小图的规模，同时保持图的度量结构和结构多样性。使用了幅度（一种等距不变的多样性度量）来指导池化过程，允许控制池化过程的保真度。此外，还采用度量空间的扩展作为更快且更稳定的替代方案，以确保计算效率。

**结果:** 实验结果显示，提出的方法在一系列多样化的图分类任务上比其他池化层实现了更好的性能，保留了输入图的关键谱特性，并且在变化的池化比例下依然保持了很高的准确性。

**结论:** 通过引入基于边塌缩的新图池化层，该研究提供了一种能够在保证结构信息完整性的前提下进行高效池化的新方法。这不仅提高了模型处理不同类型数据集时的表现一致性，也为图神经网络的设计提供了新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Geometry-Aware+Edge+Pooling+for+Graph+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11700，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11700&send_immediately=true&force_search=false)

**原文摘要:** Graph Neural Networks (GNNs) have shown significant success for graph-based
tasks. Motivated by the prevalence of large datasets in real-world
applications, pooling layers are crucial components of GNNs. By reducing the
size of input graphs, pooling enables faster training and potentially better
generalisation. However, existing pooling operations often optimise for the
learning task at the expense of fundamental graph structures and
interpretability. This leads to unreliable performance across varying dataset
types, downstream tasks and pooling ratios. Addressing these concerns, we
propose novel graph pooling layers for structure aware pooling via edge
collapses. Our methods leverage diffusion geometry and iteratively reduce a
graph's size while preserving both its metric structure and structural
diversity. We guide pooling using magnitude, an isometry-invariant diversity
measure, which permits us to control the fidelity of the pooling process.
Further, we use the spread of a metric space as a faster and more stable
alternative ensuring computational efficiency. Empirical results demonstrate
that our methods (i) achieve superior performance compared to alternative
pooling layers across a range of diverse graph classification tasks, (ii)
preserve key spectral properties of the input graphs, and (iii) retain high
accuracy across varying pooling ratios.

</details>


### [93] [Growing with Experience: Growing Neural Networks in Deep Reinforcement Learning](https://arxiv.org/abs/2506.11706)
*Lukas Fehring, Marius Lindauer, Theresa Eimer*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为GrowNN的方法，通过在训练过程中逐步增加网络层数来提高强化学习模型的性能和可训练性。


<details>
  <summary>更多</summary>
  
**动机:** 当前即便中等规模的强化学习网络训练也面临挑战，这限制了可以学习到的策略复杂度。为了解决这个问题，研究者们希望找到一种方法，在不牺牲网络可训练性的前提下增加网络容量。

**方法:** GrowNN方法首先使用一个小网络开始训练以学习初始策略，然后逐步添加新的层而不改变已经编码的功能。随着策略复杂度的提升，新增加的层会被用来学习更具有表现力的策略。

**结果:** 实验结果表明，在MiniHack和Mujoco上的测试显示，采用GrowNN逐步加深的网络比相同大小的静态网络表现更好，分别提高了48%（MiniHack Room）和72%（Ant）。

**结论:** GrowNN提供了一个简单而有效的方法来提高强化学习算法中的网络容量和性能，同时保持了良好的训练能力，并且可以很容易地整合进现有的大多数RL智能体中。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Growing+with+Experience%3A+Growing+Neural+Networks+in+Deep+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11706，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11706&send_immediately=true&force_search=false)

**原文摘要:** While increasingly large models have revolutionized much of the machine
learning landscape, training even mid-sized networks for Reinforcement Learning
(RL) is still proving to be a struggle. This, however, severely limits the
complexity of policies we are able to learn. To enable increased network
capacity while maintaining network trainability, we propose GrowNN, a simple
yet effective method that utilizes progressive network growth during training.
We start training a small network to learn an initial policy. Then we add
layers without changing the encoded function. Subsequent updates can utilize
the added layers to learn a more expressive policy, adding capacity as the
policy's complexity increases. GrowNN can be seamlessly integrated into most
existing RL agents. Our experiments on MiniHack and Mujoco show improved agent
performance, with incrementally GrowNN-deeper networks outperforming their
respective static counterparts of the same size by up to 48% on MiniHack Room
and 72% on Ant.

</details>


### [94] [SSPINNpose: A Self-Supervised PINN for Inertial Pose and Dynamics Estimation](https://arxiv.org/abs/2506.11786)
*Markus Gambietz, Eva Dorschky, Altan Akat, Marcel Schöckel, Jörg Miehling, Anne D. Koelewijn*

**主要类别:** cs.LG

**AI概要:** 提出了一种自监督的物理信息神经网络SSPINNpose，能够直接从IMU数据估计关节运动学和动力学，无需真实标签训练。与光学动作捕捉相比，该方法在行走和跑步时能准确估计关节角度和力矩，具有低延迟、高鲁棒性，并能推断传感器的解剖位置。


<details>
  <summary>更多</summary>
  
**动机:** 当前实时人体运动动态估计方法依赖于有监督学习，需要实验室测量系统提供真实数据集，但这些系统会引入测量和处理误差，且难以泛化到现实世界或未见过的动作。

**方法:** 提出了SSPINNpose，一种自监督物理信息神经网络，它直接从IMU数据估计关节运动学和动力学，不需真实标签。通过人体物理模型优化输出的物理合理性并生成虚拟测量数据，利用这些虚拟数据直接基于测量的传感器数据训练网络。

**结果:** SSPINNpose能够以8.7度和4.9 BWBH%的RMSD分别准确估计步行和最高达4.9 m/s速度跑动时的关节角度和关节力矩，且延迟为3.5毫秒。此外，该框架在稀疏传感器配置中表现出鲁棒性，并可以推断传感器的解剖位置。

**结论:** SSPINNpose作为一种可扩展和适应性强的解决方案，在实验室和现场环境中都具有作为实时生物力学分析工具的巨大潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SSPINNpose%3A+A+Self-Supervised+PINN+for+Inertial+Pose+and+Dynamics+Estimation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11786，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11786&send_immediately=true&force_search=false)

**原文摘要:** Accurate real-time estimation of human movement dynamics, including internal
joint moments and muscle forces, is essential for applications in clinical
diagnostics and sports performance monitoring. Inertial measurement units
(IMUs) provide a minimally intrusive solution for capturing motion data,
particularly when used in sparse sensor configurations. However, current
real-time methods rely on supervised learning, where a ground truth dataset
needs to be measured with laboratory measurement systems, such as optical
motion capture. These systems are known to introduce measurement and processing
errors and often fail to generalize to real-world or previously unseen
movements, necessitating new data collection efforts that are time-consuming
and impractical. To overcome these limitations, we propose SSPINNpose, a
self-supervised, physics-informed neural network that estimates joint
kinematics and kinetics directly from IMU data, without requiring ground truth
labels for training. We run the network output through a physics model of the
human body to optimize physical plausibility and generate virtual measurement
data. Using this virtual sensor data, the network is trained directly on the
measured sensor data instead of a ground truth. When compared to optical motion
capture, SSPINNpose is able to accurately estimate joint angles and joint
moments at an RMSD of 8.7 deg and 4.9 BWBH%, respectively, for walking and
running at speeds up to 4.9 m/s at a latency of 3.5 ms. Furthermore, the
framework demonstrates robustness across sparse sensor configurations and can
infer the anatomical locations of the sensors. These results underscore the
potential of SSPINNpose as a scalable and adaptable solution for real-time
biomechanical analysis in both laboratory and field environments.

</details>


### [95] [SEC-bench: Automated Benchmarking of LLM Agents on Real-World Software Security Tasks](https://arxiv.org/abs/2506.11791)
*Hwiwon Lee, Ziqi Zhang, Hanxiao Lu, Lingming Zhang*

**主要类别:** cs.LG

**AI概要:** 本文介绍了SEC-bench，这是一个完全自动化的基准测试框架，用于评估大型语言模型代理在真实的安全工程任务中的表现。通过实现概念验证生成和漏洞修补两项关键软件安全任务，揭示了现有LLM代码代理在处理实际软件漏洞时的显著性能差距。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基准测试主要依赖于合成挑战或简化的漏洞数据集，未能捕捉到安全工程师在实践中遇到的复杂性和模糊性。因此，需要一个更贴近实际情况的自动化基准来严格评估大型语言模型（LLM）代理的安全性。

**方法:** 开发了一个名为SEC-bench的新型多代理架构框架，能够自动生成具有重现性的高质量软件漏洞数据集，并且成本低廉。该框架支持自动构建代码库、在隔离环境中重现漏洞以及生成标准补丁以供评估。

**结果:** 对最先进LLM代码代理的全面评估显示，在概念验证生成方面成功率最高为18.0%，而在漏洞修补方面则达到了34.0%。这些结果表明要开发出更加实用、智能和自主的安全工程LLM代理还有很长的路要走。

**结论:** SEC-bench提供了一种新的方式来评估LLM代理在处理实际软件安全问题时的表现，强调了改进现有技术的重要性，以便创建更适合安全工程需求的LLM解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SEC-bench%3A+Automated+Benchmarking+of+LLM+Agents+on+Real-World+Software+Security+Tasks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11791，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11791&send_immediately=true&force_search=false)

**原文摘要:** Rigorous security-focused evaluation of large language model (LLM) agents is
imperative for establishing trust in their safe deployment throughout the
software development lifecycle. However, existing benchmarks largely rely on
synthetic challenges or simplified vulnerability datasets that fail to capture
the complexity and ambiguity encountered by security engineers in practice. We
introduce SEC-bench, the first fully automated benchmarking framework for
evaluating LLM agents on authentic security engineering tasks. SEC-bench
employs a novel multi-agent scaffold that automatically constructs code
repositories with harnesses, reproduces vulnerabilities in isolated
environments, and generates gold patches for reliable evaluation. Our framework
automatically creates high-quality software vulnerability datasets with
reproducible artifacts at a cost of only $0.87 per instance. Using SEC-bench,
we implement two critical software security tasks to rigorously evaluate LLM
agents' capabilities: proof-of-concept (PoC) generation and vulnerability
patching. A comprehensive evaluation of state-of-the-art LLM code agents
reveals significant performance gaps, achieving at most 18.0% success in PoC
generation and 34.0% in vulnerability patching on our complete dataset. These
results highlight the crucial steps needed toward developing LLM agents that
are more practical, intelligent, and autonomous for security engineering.

</details>


### [96] [Understanding Input Selectivity in Mamba: Impact on Approximation Power, Memorization, and Associative Recall Capacity](https://arxiv.org/abs/2506.11891)
*Ningyuan Huang, Miguel Sarabia, Abhinav Moudgil, Pau Rodriguez, Luca Zappella, Federico Danieli*

**主要类别:** cs.LG

**AI概要:** 本文探讨了Mamba模型中输入选择性的作用，分析了其对函数逼近能力、长期记忆和联想回忆能力的影响，并通过理论和实证结果证明了S6层能够表示Haar小波投影、动态对抗记忆衰退以及在MQAR任务中的表现。


<details>
  <summary>更多</summary>
  
**动机:** 尽管Mamba引入的输入选择性提高了性能，但尚不清楚它如何利用这一特性及其与其他操作的交互方式。

**方法:** 研究方法包括证明S6层可以表示Haar小波投影，展示S6层如何动态地对抗记忆衰退，以及为使用不同mixer的Mamba架构提供MQAR联想回忆任务的解析解。

**结果:** 研究表明，Mamba的S6层比其前身S4D在逼近不连续函数方面具有优势；S6层能够动态地对抗记忆衰减；并且对于MQAR任务，给出了Mamba架构下的解析解。

**结论:** 本研究提供了关于Mamba工作机制的理解，并揭示了改进的机会。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+Input+Selectivity+in+Mamba%3A+Impact+on+Approximation+Power%2C+Memorization%2C+and+Associative+Recall+Capacity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11891，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11891&send_immediately=true&force_search=false)

**原文摘要:** State-Space Models (SSMs), and particularly Mamba, have recently emerged as a
promising alternative to Transformers. Mamba introduces input selectivity to
its SSM layer (S6) and incorporates convolution and gating into its block
definition. While these modifications do improve Mamba's performance over its
SSM predecessors, it remains largely unclear how Mamba leverages the additional
functionalities provided by input selectivity, and how these interact with the
other operations in the Mamba architecture. In this work, we demystify the role
of input selectivity in Mamba, investigating its impact on function
approximation power, long-term memorization, and associative recall
capabilities. In particular: (i) we prove that the S6 layer of Mamba can
represent projections onto Haar wavelets, providing an edge over its Diagonal
SSM (S4D) predecessor in approximating discontinuous functions commonly arising
in practice; (ii) we show how the S6 layer can dynamically counteract memory
decay; (iii) we provide analytical solutions to the MQAR associative recall
task using the Mamba architecture with different mixers -- Mamba, Mamba-2, and
S4D. We demonstrate the tightness of our theoretical constructions with
empirical results on concrete tasks. Our findings offer a mechanistic
understanding of Mamba and reveal opportunities for improvement.

</details>


### [97] [Measurement-aligned Flow for Inverse Problem](https://arxiv.org/abs/2506.11893)
*Shaorong Zhang, Rob Brekelmans, Yunshu Wu, Greg Ver Steeg*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的框架——测量对齐采样（MAS），用于解决线性逆问题，该方法可以更灵活地平衡先验信息和测量信息，并且在处理不同类型的噪声时优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的扩散模型在处理先验信息与测量信息相冲突的情况时存在困难，特别是在非高斯或未知噪声的情况下。为了解决这些问题，提出了一个新的框架以更灵活地平衡这两者的信息。

**方法:** 通过引入名为测量对齐采样（MAS）的新框架来解决线性逆问题。MAS不仅统一并扩展了DDNM和DAPS等现有方法，还提供了新的优化视角。它可以适应已知的高斯噪声以及未知或非高斯噪声类型。

**结果:** 广泛的实验表明，MAS在一系列任务中始终优于最先进的方法。

**结论:** MAS提供了一种有效的方法来解决包含复杂先验信息的线性逆问题，在处理各种噪声类型时表现优异，展示了其作为解决此类问题潜在工具的价值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Measurement-aligned+Flow+for+Inverse+Problem，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11893，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11893&send_immediately=true&force_search=false)

**原文摘要:** Diffusion models provide a powerful way to incorporate complex prior
information for solving inverse problems. However, existing methods struggle to
correctly incorporate guidance from conflicting signals in the prior and
measurement, especially in the challenging setting of non-Gaussian or unknown
noise. To bridge these gaps, we propose Measurement-Aligned Sampling (MAS), a
novel framework for linear inverse problem solving that can more flexibly
balance prior and measurement information. MAS unifies and extends existing
approaches like DDNM and DAPS, and offers a new optimization perspective. MAS
can generalize to handle known Gaussian noise, unknown or non-Gaussian noise
types. Extensive experiments show that MAS consistently outperforms
state-of-the-art methods across a range of tasks.

</details>


### [98] [TreeRL: LLM Reinforcement Learning with On-Policy Tree Search](https://arxiv.org/abs/2506.11902)
*Zhenyu Hou, Ziniu Hu, Yujiang Li, Rui Lu, Jie Tang, Yuxiao Dong*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为TreeRL的强化学习框架，它直接结合了在线策略树搜索以提高在大型语言模型上的推理任务表现。


<details>
  <summary>更多</summary>
  
**动机:** 现有的链式强化学习方法存在探索空间有限和奖励模型训练中可能出现分布不匹配及奖励漏洞的问题。

**方法:** 通过引入TreeRL，该方法利用在线策略树搜索来提供密集的过程奖励，并采用一种成本效益高的树搜索方法，从高不确定性的中间步骤进行策略性分支。

**结果:** 实验表明，在具有挑战性的数学和代码推理基准测试中，TreeRL的表现优于传统的ChainRL。

**结论:** TreeRL为大型语言模型中的强化学习提供了新的可能性，其代码已开源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TreeRL%3A+LLM+Reinforcement+Learning+with+On-Policy+Tree+Search，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11902，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11902&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement learning (RL) with tree search has demonstrated superior
performance in traditional reasoning tasks. Compared to conventional
independent chain sampling strategies with outcome supervision, tree search
enables better exploration of the reasoning space and provides dense, on-policy
process rewards during RL training but remains under-explored in On-Policy LLM
RL. We propose TreeRL, a reinforcement learning framework that directly
incorporates on-policy tree search for RL training. Our approach includes
intermediate supervision and eliminates the need for a separate reward model
training. Existing approaches typically train a separate process reward model,
which can suffer from distribution mismatch and reward hacking. We also
introduce a cost-effective tree search approach that achieves higher search
efficiency under the same generation token budget by strategically branching
from high-uncertainty intermediate steps rather than using random branching.
Experiments on challenging math and code reasoning benchmarks demonstrate that
TreeRL achieves superior performance compared to traditional ChainRL,
highlighting the potential of tree search for LLM. TreeRL is open-sourced at
https://github.com/THUDM/TreeRL.

</details>


### [99] [Visual Pre-Training on Unlabeled Images using Reinforcement Learning](https://arxiv.org/abs/2506.11967)
*Dibya Ghosh, Sergey Levine*

**主要类别:** cs.LG

**AI概要:** 该论文提出了一种将无标签图像数据预训练视为强化学习问题的方法，通过改变视角或增加图像增强来变换图像，并通过奖励函数来塑造特征学习。实验表明这种方法在处理野外的未标记图像、视频数据以及网络爬取数据时能够提高表示效果。


<details>
  <summary>更多</summary>
  
**动机:** 作者观察到许多自监督图像预训练方法与价值基强化学习算法有相似之处，即都是学习从当前观察（如图像裁剪）到可能达到的状态和回报之间的关联。基于此，研究旨在探索一种直接将无标签图像数据预训练建模为RL问题的方法。

**方法:** 提出了一个动态系统，在这个系统中代理通过改变视角或者添加图像增广的方式转换图像。这种学习方式类似于作物一致性自监督，但通过奖励功能提供了简单的方式来使用策划的图片或弱标签字幕来调整特征学习。

**结果:** 实验证明了当使用野外未经标记的图像进行训练时，包括像EpicKitchens这样的视频数据、像COCO这样的场景数据以及像CC12M这样的网页抓取数据，所提出的方法能够改善表征。

**结论:** 本文介绍了一种新的视角，将图像预训练任务重新构建为强化学习问题，这不仅加强了对图像特征的理解，而且提供了一种有效利用无标签数据的新方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Visual+Pre-Training+on+Unlabeled+Images+using+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11967，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11967&send_immediately=true&force_search=false)

**原文摘要:** In reinforcement learning (RL), value-based algorithms learn to associate
each observation with the states and rewards that are likely to be reached from
it. We observe that many self-supervised image pre-training methods bear
similarity to this formulation: learning features that associate crops of
images with those of nearby views, e.g., by taking a different crop or color
augmentation. In this paper, we complete this analogy and explore a method that
directly casts pre-training on unlabeled image data like web crawls and video
frames as an RL problem. We train a general value function in a dynamical
system where an agent transforms an image by changing the view or adding image
augmentations. Learning in this way resembles crop-consistency
self-supervision, but through the reward function, offers a simple lever to
shape feature learning using curated images or weakly labeled captions when
they exist. Our experiments demonstrate improved representations when training
on unlabeled images in the wild, including video data like EpicKitchens, scene
data like COCO, and web-crawl data like CC12M.

</details>


### [100] [Self-Regulating Cars: Automating Traffic Control in Free Flow Road Networks](https://arxiv.org/abs/2506.11973)
*Ankit Bhardwaj, Rohail Asim, Sachin Chauhan, Yasir Zaki, Lakshminarayanan Subramanian*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于强化学习的自调节汽车交通控制协议，该协议通过动态调整车辆速度来优化吞吐量和防止拥堵，无需新的物理基础设施。在高保真PTV Vissim模拟器上评估的结果表明，该方法能够提高总吞吐量5%，减少平均延误13%，并减少停车次数3%。


<details>
  <summary>更多</summary>
  
**动机:** 由于通勤者数量的增长和基础设施的限制，自由流动的道路网络（如郊区高速公路）越来越容易出现交通拥堵。传统的控制机制，例如交通信号灯或局部启发式算法，在这些高速、无信号灯的环境中无效或不可行。

**方法:** 本文引入了自调节汽车的概念，这是一种基于强化学习的交通控制协议，它能够根据实时交通情况动态地调节车辆速度，以优化道路通行能力和避免拥堵。该方法结合了经典的交通流理论、间隙接受模型以及微观仿真技术，并将其整合到一个考虑物理特性的强化学习框架中。

**结果:** 在实际高速公路网络上的高保真度PTV Vissim模拟器中进行评估后，与没有控制的情况相比，所提出的方法使总吞吐量提高了5％，平均延迟减少了13％，总停车次数减少了3％。此外，它还能实现更加平滑且抗拥堵的车流，并能适应各种不同的交通模式。

**结论:** 自调节汽车作为一种基于强化学习的交通管理方案，展示了其在提高道路网络效率和缓解交通拥堵方面的潜力，同时具有良好的泛化能力，适用于多种交通模式。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Self-Regulating+Cars%3A+Automating+Traffic+Control+in+Free+Flow+Road+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11973，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11973&send_immediately=true&force_search=false)

**原文摘要:** Free-flow road networks, such as suburban highways, are increasingly
experiencing traffic congestion due to growing commuter inflow and limited
infrastructure. Traditional control mechanisms, such as traffic signals or
local heuristics, are ineffective or infeasible in these high-speed,
signal-free environments. We introduce self-regulating cars, a reinforcement
learning-based traffic control protocol that dynamically modulates vehicle
speeds to optimize throughput and prevent congestion, without requiring new
physical infrastructure. Our approach integrates classical traffic flow theory,
gap acceptance models, and microscopic simulation into a physics-informed RL
framework. By abstracting roads into super-segments, the agent captures
emergent flow dynamics and learns robust speed modulation policies from
instantaneous traffic observations. Evaluated in the high-fidelity PTV Vissim
simulator on a real-world highway network, our method improves total throughput
by 5%, reduces average delay by 13%, and decreases total stops by 3% compared
to the no-control setting. It also achieves smoother, congestion-resistant flow
while generalizing across varied traffic patterns, demonstrating its potential
for scalable, ML-driven traffic management.

</details>


### [101] [Compression Aware Certified Training](https://arxiv.org/abs/2506.11992)
*Changming Xu, Gagandeep Singh*

**主要类别:** cs.LG

**AI概要:** 提出了一种名为CACTUS的框架，可以在训练过程中统一压缩和认证鲁棒性目标，使得深度神经网络在安全关键、资源受限环境中既能保持高效也能维持高准确率和可认证的鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的方法将压缩和认证鲁棒性视为独立的目标，在效率或安全性方面做出了妥协。为了克服这一问题，作者提出了一个可以同时考虑这两个目标的通用框架。

**方法:** CACTUS (Compression Aware Certified Training Using network Sets) 框架，它允许在训练期间就考虑到模型压缩的需求，并且保证了即使在压缩后模型仍然能够保持高的认证准确率。

**结果:** 应用CACTUS于剪枝和量化，结果表明该方法能够有效地训练出既可被高效压缩又能保持高准确性和可认证鲁棒性的模型。CACTUS 在多种数据集和输入规范上都达到了最先进的准确性和认证性能。

**结论:** CACTUS 提供了一个有效的方法来解决在安全关键和资源受限环境中的深度神经网络需要平衡效率与鲁棒性的挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Compression+Aware+Certified+Training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11992，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11992&send_immediately=true&force_search=false)

**原文摘要:** Deep neural networks deployed in safety-critical, resource-constrained
environments must balance efficiency and robustness. Existing methods treat
compression and certified robustness as separate goals, compromising either
efficiency or safety. We propose CACTUS (Compression Aware Certified Training
Using network Sets), a general framework for unifying these objectives during
training. CACTUS models maintain high certified accuracy even when compressed.
We apply CACTUS for both pruning and quantization and show that it effectively
trains models which can be efficiently compressed while maintaining high
accuracy and certifiable robustness. CACTUS achieves state-of-the-art accuracy
and certified performance for both pruning and quantization on a variety of
datasets and input specifications.

</details>


### [102] [An Efficient Compression of Deep Neural Network Checkpoints Based on Prediction and Context Modeling](https://arxiv.org/abs/2506.12000)
*Yuriy Kim, Evgeny Belyaev*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于预测的压缩方法，结合剪枝和量化技术，有效减少了神经网络训练过程中权重和优化器状态（即检查点）的数据大小，同时保持了模型性能并支持从恢复的检查点近乎无损地恢复训练。


<details>
  <summary>更多</summary>
  
**动机:** 为了在存储受限的环境中有效压缩神经网络训练过程中的权重和优化器状态（检查点），以便减少所需存储空间，并确保能够从这些压缩过的检查点中近乎无损地恢复训练。

**方法:** 提出了基于先前保存的检查点值进行上下文建模的算术编码预测压缩方法；此外还采用了剪枝和量化技术来进一步提高压缩效率。

**结果:** 实验结果表明，该方法能够大幅度减小比特大小，同时允许从恢复的检查点近乎无损地恢复训练，保持了模型的性能。

**结论:** 通过结合预测压缩、剪枝和量化技术，可以有效地压缩神经网络训练过程中的检查点数据量，这对于存储资源有限的情况特别有用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Efficient+Compression+of+Deep+Neural+Network+Checkpoints+Based+on+Prediction+and+Context+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.12000，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.12000&send_immediately=true&force_search=false)

**原文摘要:** This paper is dedicated to an efficient compression of weights and optimizer
states (called checkpoints) obtained at different stages during a neural
network training process. First, we propose a prediction-based compression
approach, where values from the previously saved checkpoint are used for
context modeling in arithmetic coding. Second, in order to enhance the
compression performance, we also propose to apply pruning and quantization of
the checkpoint values. Experimental results show that our approach achieves
substantial bit size reduction, while enabling near-lossless training recovery
from restored checkpoints, preserving the model's performance and making it
suitable for storage-limited environments.

</details>


### [103] [SIMSHIFT: A Benchmark for Adapting Neural Surrogates to Distribution Shifts](https://arxiv.org/abs/2506.12007)
*Paul Setinek, Gianluca Galletti, Thomas Gross, Dominik Schnürer, Johannes Brandstetter, Werner Zellinger*

**主要类别:** cs.LG

**AI概要:** 本文引入了SIMSHIFT，一个包含四个工业模拟任务的新基准数据集和评估套件，并将现有的领域适应方法扩展到最新的神经替代模型中，以解决在未见过的问题配置上进行预测时的性能下降问题。


<details>
  <summary>更多</summary>
  
**动机:** 神经偏微分方程（PDEs）代理在遇到新的材料类型或结构尺寸等未知问题配置时，通常会遭遇显著的性能下降。

**方法:** 作者们首先提出了SIMSHIFT，这是一个由四个工业模拟任务组成的新基准数据集和评估套件。接着，他们将已有的领域适应方法扩展到了最先进的神经代理模型上，并系统地评估了这些方法。

**结果:** 广泛的实验表明了分布外神经代理建模的挑战，展示了领域适应在模拟中的潜力，并揭示了在工业相关场景下实现鲁棒神经代理的关键开放问题。

**结论:** 研究强调了通过领域适应技术来提高神经代理模型在新问题配置下的泛化能力的重要性，并指出了未来的研究方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SIMSHIFT%3A+A+Benchmark+for+Adapting+Neural+Surrogates+to+Distribution+Shifts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.12007，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.12007&send_immediately=true&force_search=false)

**原文摘要:** Neural surrogates for Partial Differential Equations (PDEs) often suffer
significant performance degradation when evaluated on unseen problem
configurations, such as novel material types or structural dimensions.
Meanwhile, Domain Adaptation (DA) techniques have been widely used in vision
and language processing to generalize from limited information about unseen
configurations. In this work, we address this gap through two focused
contributions. First, we introduce SIMSHIFT, a novel benchmark dataset and
evaluation suite composed of four industrial simulation tasks: hot rolling,
sheet metal forming, electric motor design and heatsink design. Second, we
extend established domain adaptation methods to state of the art neural
surrogates and systematically evaluate them. These approaches use parametric
descriptions and ground truth simulations from multiple source configurations,
together with only parametric descriptions from target configurations. The goal
is to accurately predict target simulations without access to ground truth
simulation data. Extensive experiments on SIMSHIFT highlight the challenges of
out of distribution neural surrogate modeling, demonstrate the potential of DA
in simulation, and reveal open problems in achieving robust neural surrogates
under distribution shifts in industrially relevant scenarios. Our codebase is
available at https://github.com/psetinek/simshift

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [104] [A Survey of Task-Oriented Knowledge Graph Reasoning: Status, Applications, and Prospects](https://arxiv.org/abs/2506.11012)
*Guanglin Niu, Bo Li, Yangguang Lin*

**主要类别:** cs.AI

**AI概要:** 本文全面回顾了知识图谱推理(KGR)的研究，包括主要的推理任务、下游应用任务以及潜在的挑战性推理任务，并探讨了大型语言模型等先进技术对KGR的影响。


<details>
  <summary>更多</summary>
  
**动机:** 现有的KGR方法可以分为六种类型的任务，但缺乏一个系统的综述来总结所有KGR任务，特别是下游应用和更具挑战性的推理范式。

**方法:** 本文提供了一个更为全面的视角来研究KGR，基于主要推理任务、下游应用任务和潜在挑战性推理任务对方法进行分类。此外，还探索了诸如大型语言模型等先进技术和它们对KGR的影响。

**结果:** 本文强调了KGR领域中的关键研究趋势，并概述了未来有希望的发展方向。

**结论:** 本综述旨在为KGR研究提供一个全面的视角，涵盖多种推理任务及其在实际应用中的重要性，并指出了未来的研究方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Survey+of+Task-Oriented+Knowledge+Graph+Reasoning%3A+Status%2C+Applications%2C+and+Prospects，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11012，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11012&send_immediately=true&force_search=false)

**原文摘要:** Knowledge graphs (KGs) have emerged as a powerful paradigm for structuring
and leveraging diverse real-world knowledge, which serve as a fundamental
technology for enabling cognitive intelligence systems with advanced
understanding and reasoning capabilities. Knowledge graph reasoning (KGR) aims
to infer new knowledge based on existing facts in KGs, playing a crucial role
in applications such as public security intelligence, intelligent healthcare,
and financial risk assessment. From a task-centric perspective, existing KGR
approaches can be broadly classified into static single-step KGR, static
multi-step KGR, dynamic KGR, multi-modal KGR, few-shot KGR, and inductive KGR.
While existing surveys have covered these six types of KGR tasks, a
comprehensive review that systematically summarizes all KGR tasks particularly
including downstream applications and more challenging reasoning paradigms
remains lacking. In contrast to previous works, this survey provides a more
comprehensive perspective on the research of KGR by categorizing approaches
based on primary reasoning tasks, downstream application tasks, and potential
challenging reasoning tasks. Besides, we explore advanced techniques, such as
large language models (LLMs), and their impact on KGR. This work aims to
highlight key research trends and outline promising future directions in the
field of KGR.

</details>


### [105] [OntoGSN: An Ontology for Dynamic Management of Assurance Cases](https://arxiv.org/abs/2506.11023)
*Tomas Bueno Momcilovic, Barbara Gallina, Ingmar Kessler, Dian Balta*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种名为OntoGSN的本体和中间件，用于在目标结构表示法(GSN)标准中管理保证案例(ACs)，以解决ACs维护困难的问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有工具虽然提供了静态、文档中心应用的支持，并且正在出现动态环境下的方法（如自动驾驶），但管理保证案例仍然具有挑战性。因为面对变化时保持嵌入的知识需要大量的工作，这个过程可能会让开发者感到沮丧，甚至产生管理不善的情况，从而导致虚假的信心。

**方法:** 研究人员开发了OntoGSN，它包括一个与GSN社区标准v3一对一形式化的OWL本体以及SWRL规则，一个帮助本体和解析器以便与广泛使用的AC工具集成，设计决策的存储库和文档，一个带有自动化模式的SPARQL查询库，以及一个原型界面。

**结果:** OntoGSN提供了一个可自动填充、评估和更新的知识表示和可查询图。该本体严格遵循标准文本，并根据FAIR原则、OOPS框架、能力问题和社区反馈进行了评估。

**结论:** 通过展示涉及大型语言模型中对抗鲁棒性的保证案例的例子，研究人员证明了他们的贡献在动态AC管理中的实用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是OntoGSN%3A+An+Ontology+for+Dynamic+Management+of+Assurance+Cases，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11023，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11023&send_immediately=true&force_search=false)

**原文摘要:** Assurance cases (ACs) are a common artifact for building and maintaining
confidence in system properties such as safety or robustness. Constructing an
AC can be challenging, although existing tools provide support in static,
document-centric applications and methods for dynamic contexts (e.g.,
autonomous driving) are emerging. Unfortunately, managing ACs remains a
challenge, since maintaining the embedded knowledge in the face of changes
requires substantial effort, in the process deterring developers - or worse,
producing poorly managed cases that instill false confidence. To address this,
we present OntoGSN: an ontology and supporting middleware for managing ACs in
the Goal Structuring Notation (GSN) standard. OntoGSN offers a knowledge
representation and a queryable graph that can be automatically populated,
evaluated, and updated. Our contributions include: a 1:1 formalization of the
GSN Community Standard v3 in an OWL ontology with SWRL rules; a helper ontology
and parser for integration with a widely used AC tool; a repository and
documentation of design decisions for OntoGSN maintenance; a SPARQL query
library with automation patterns; and a prototypical interface. The ontology
strictly adheres to the standard's text and has been evaluated according to
FAIR principles, the OOPS framework, competency questions, and community
feedback. The development of other middleware elements is guided by the
community needs and subject to ongoing evaluations. To demonstrate the utility
of our contributions, we illustrate dynamic AC management in an example
involving assurance of adversarial robustness in large language models.

</details>


### [106] [LLM-as-a-Fuzzy-Judge: Fine-Tuning Large Language Models as a Clinical Evaluation Judge with Fuzzy Logic](https://arxiv.org/abs/2506.11221)
*Weibing Zheng, Laurah Turner, Jess Kropczynski, Murat Ozer, Tri Nguyen, Shane Halse*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种称为LLM-as-a-Fuzzy-Judge的新方法，它将模糊逻辑与大型语言模型相结合，以解决医学生临床技能自动评估与主观医生偏好的一致性问题。


<details>
  <summary>更多</summary>
  
**动机:** 临床沟通技能在医学教育中至关重要，而大规模地练习和评估这些技能却具有挑战性。虽然由大语言模型驱动的临床情景模拟显示出了增强医学生临床实践能力的潜力，但提供遵循细微医师判断的自动化和可扩展临床评估仍然困难。

**方法:** 本论文的方法论始于从基于LLM的医学教育系统收集数据，然后基于多维模糊集进行数据标注，接着是提示工程以及使用这些人工标注对预训练的LLM进行监督微调（SFT）。

**结果:** 结果表明，LLM-as-a-Fuzzy-Judge方法达到了超过80%的准确率，主要评判项超过了90%，有效地利用了模糊逻辑和LLM来提供与人类一致的评估解决方案。

**结论:** 该研究表明，通过结合模糊逻辑和大型语言模型（LLM）的方法，即LLM-as-a-Fuzzy-Judge，可以实现与人类偏好相一致的、可解释的评估。这种方法在医学教育中推进了自动化评估的发展，并支持更稳健的评估和判断实践。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM-as-a-Fuzzy-Judge%3A+Fine-Tuning+Large+Language+Models+as+a+Clinical+Evaluation+Judge+with+Fuzzy+Logic，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11221，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11221&send_immediately=true&force_search=false)

**原文摘要:** Clinical communication skills are critical in medical education, and
practicing and assessing clinical communication skills on a scale is
challenging. Although LLM-powered clinical scenario simulations have shown
promise in enhancing medical students' clinical practice, providing automated
and scalable clinical evaluation that follows nuanced physician judgment is
difficult. This paper combines fuzzy logic and Large Language Model (LLM) and
proposes LLM-as-a-Fuzzy-Judge to address the challenge of aligning the
automated evaluation of medical students' clinical skills with subjective
physicians' preferences. LLM-as-a-Fuzzy-Judge is an approach that LLM is
fine-tuned to evaluate medical students' utterances within student-AI patient
conversation scripts based on human annotations from four fuzzy sets, including
Professionalism, Medical Relevance, Ethical Behavior, and Contextual
Distraction. The methodology of this paper started from data collection from
the LLM-powered medical education system, data annotation based on
multidimensional fuzzy sets, followed by prompt engineering and the supervised
fine-tuning (SFT) of the pre-trained LLMs using these human annotations. The
results show that the LLM-as-a-Fuzzy-Judge achieves over 80\% accuracy, with
major criteria items over 90\%, effectively leveraging fuzzy logic and LLM as a
solution to deliver interpretable, human-aligned assessment. This work suggests
the viability of leveraging fuzzy logic and LLM to align with human
preferences, advances automated evaluation in medical education, and supports
more robust assessment and judgment practices. The GitHub repository of this
work is available at https://github.com/2sigmaEdTech/LLMAsAJudge

</details>


### [107] [MUDAS: Mote-scale Unsupervised Domain Adaptation in Multi-label Sound Classification](https://arxiv.org/abs/2506.11331)
*Jihoon Yun, Chengzhang Li, Dhrubojyoti Roy, Anish Arora*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种名为MUDAS的无监督领域适应框架，它专为资源受限的物联网环境中的多标签声音分类设计。通过选择性地使用高置信度数据重新训练分类器，并结合类别特定的自适应阈值和多样性正则化，MUDAS在减少计算和内存需求的同时提高了分类准确性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的无监督领域适应算法主要针对单标签任务，并且需要大量的计算资源，这限制了它们在多标签场景和资源受限的物联网设备上的应用。特别是在城市声音分类这样的场景中，由于存在重叠的声音和变化的声学环境，因此需要具有强大适应性的多标签分类能力，同时还要能够运行在低功耗、设备端系统上。

**方法:** MUDAS是一种针对资源受限的物联网设置而开发的多标签声音分类的无监督领域适应框架。该方法通过有选择性地使用高置信度的数据来重新训练分类器，以最小化计算和内存需求，使之适合设备端部署。此外，MUDAS还集成了类别特定的自适应阈值以生成可靠的伪标签，并采用多样性正则化来提高多标签分类精度。

**结果:** 在SONYC Urban Sound Tagging (SONYC-UST) 数据集上进行的评估表明，MUDAS相比现有的无监督领域适应算法，在分类准确性上取得了显著的改进，同时在资源受限的物联网环境下表现出良好的性能。

**结论:** MUDAS提供了一个有效的解决方案，用于在资源受限的物联网设备上执行多标签声音分类的无监督领域适应。它的设计考虑到了计算效率和内存限制，同时通过创新的方法提高了分类性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MUDAS%3A+Mote-scale+Unsupervised+Domain+Adaptation+in+Multi-label+Sound+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11331，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11331&send_immediately=true&force_search=false)

**原文摘要:** Unsupervised Domain Adaptation (UDA) is essential for adapting machine
learning models to new, unlabeled environments where data distribution shifts
can degrade performance. Existing UDA algorithms are designed for single-label
tasks and rely on significant computational resources, limiting their use in
multi-label scenarios and in resource-constrained IoT devices. Overcoming these
limitations is particularly challenging in contexts such as urban sound
classification, where overlapping sounds and varying acoustics require robust,
adaptive multi-label capabilities on low-power, on-device systems. To address
these limitations, we introduce Mote-scale Unsupervised Domain Adaptation for
Sounds (MUDAS), a UDA framework developed for multi-label sound classification
in resource-constrained IoT settings. MUDAS efficiently adapts models by
selectively retraining the classifier in situ using high-confidence data,
minimizing computational and memory requirements to suit on-device deployment.
Additionally, MUDAS incorporates class-specific adaptive thresholds to generate
reliable pseudo-labels and applies diversity regularization to improve
multi-label classification accuracy. In evaluations on the SONYC Urban Sound
Tagging (SONYC-UST) dataset recorded at various New York City locations, MUDAS
demonstrates notable improvements in classification accuracy over existing UDA
algorithms, achieving good performance in a resource-constrained IoT setting.

</details>


### [108] [Benchmarking Multimodal LLMs on Recognition and Understanding over Chemical Tables](https://arxiv.org/abs/2506.11375)
*Yitong Zhou, Mingyue Cheng, Qingyang Mao, Yucong Luo, Qi Liu, Yupeng Li, Xiaohan Zhang, Deguang Liu, Xin Li, Enhong Chen*

**主要类别:** cs.AI

**AI概要:** 我们提出了ChemTable，这是一个从文献的实验部分整理出的真实化学表格的大规模基准，旨在评估多模态模型在化学领域中的表格识别和理解能力。研究发现这些模型在基本布局解析上表现尚可，但在描述性和推理型问答任务中存在显著局限，并且开源与闭源模型之间存在性能差距。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基准测试大多忽略了化学表格这种包含符号表达式、结构化变量和嵌入式分子图形等复杂信息的特点，这限制了多模态大语言模型在化学科学理解上的支持能力。

**方法:** 引入了一个名为ChemTable的新基准，它包括了由专家标注的单元格多边形、逻辑布局以及领域特定标签（如试剂、催化剂、产率和图形组件）。该基准支持两个核心任务：1）表格识别，涵盖结构分析和内容提取；2）表格理解，涉及基于表格结构和领域语义的描述性及推理型问题解答。

**结果:** 一系列代表性多模态模型在ChemTable上的评估表明，虽然模型在基础布局解析方面表现出合理水平，但在描述性和推理型QA任务上与人类表现相比有重大局限。此外，在多个维度上观察到开源与闭源模型之间的显著性能差异。

**结论:** 这些结果强调了具有化学意识的表格理解所面临的挑战，并将ChemTable定位为一个严格而现实的基准，以促进科学推理的进步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Benchmarking+Multimodal+LLMs+on+Recognition+and+Understanding+over+Chemical+Tables，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11375，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11375&send_immediately=true&force_search=false)

**原文摘要:** Chemical tables encode complex experimental knowledge through symbolic
expressions, structured variables, and embedded molecular graphics. Existing
benchmarks largely overlook this multimodal and domain-specific complexity,
limiting the ability of multimodal large language models to support scientific
understanding in chemistry. In this work, we introduce ChemTable, a large-scale
benchmark of real-world chemical tables curated from the experimental sections
of literature. ChemTable includes expert-annotated cell polygons, logical
layouts, and domain-specific labels, including reagents, catalysts, yields, and
graphical components and supports two core tasks: (1) Table Recognition,
covering structure parsing and content extraction; and (2) Table Understanding,
encompassing both descriptive and reasoning-oriented question answering
grounded in table structure and domain semantics. We evaluated a range of
representative multimodal models, including both open-source and closed-source
models, on ChemTable and reported a series of findings with practical and
conceptual insights. Although models show reasonable performance on basic
layout parsing, they exhibit substantial limitations on both descriptive and
inferential QA tasks compared to human performance, and we observe significant
performance gaps between open-source and closed-source models across multiple
dimensions. These results underscore the challenges of chemistry-aware table
understanding and position ChemTable as a rigorous and realistic benchmark for
advancing scientific reasoning.

</details>


### [109] [Large Language Model-Powered Conversational Agent Delivering Problem-Solving Therapy (PST) for Family Caregivers: Enhancing Empathy and Therapeutic Alliance Using In-Context Learning](https://arxiv.org/abs/2506.11376)
*Liying Wang, Ph. D., Daffodil Carrington, M. S., Daniil Filienko, M. S., Caroline El Jazmi, M. S., Serena Jinchen Xie, M. S., Martine De Cock, Ph. D., Sarah Iribarren, Ph. D., Weichao Yuwen, Ph. D*

**主要类别:** cs.AI

**AI概要:** 本研究探讨了大型语言模型（LLM）驱动的对话代理为家庭护理者提供基于证据的心理健康支持的可能性，特别是整合了动机访谈（MI）和行为链分析（BCA）的问题解决疗法（PST）。通过一个被试内实验，28名护理者与四个LLM配置互动，评估了共情能力和治疗联盟。最佳表现的模型结合了少量样本学习和检索增强生成（RAG）提示技术以及临床策划的例子。这些模型展示了改善的情境理解和个性化支持，并且参与者对模型能够验证情绪、探索未表达的情感并提供可操作策略的能力表示赞赏。然而，在全面评估与高效建议之间找到平衡仍是一项挑战。


<details>
  <summary>更多</summary>
  
**动机:** 家庭护理者由于其多方面角色和有限资源经常面临重大的心理健康挑战。这项研究旨在探索大型语言模型（LLM）驱动的对话代理是否能够为护理者提供有效的心理健康支持。

**方法:** 采用了一个被试内实验设计，让28名家庭护理者与四种不同的LLM配置进行互动，以评价模型的同理心水平和治疗关系。最有效的模型采用了少量示例学习和检索增强生成（RAG）等提示技术，并结合了由临床医生策划的案例。

**结果:** 研究表明，采用少量示例学习和检索增强生成（RAG）技术的模型在情境理解和个性化支持方面表现出色。参与者的定性反馈和定量评分显示，他们认为这些模型具有良好的共情能力，并能形成强有力的治疗联盟。参与者特别欣赏模型的情绪确认、深层次情感探索及提供实用策略的能力。

**结论:** 该工作强调了大型语言模型在向家庭护理者提供富有同情心和定制化支持方面的潜力。尽管存在如何平衡细致评估与有效提供建议之间的挑战，但LLM在提高护理者心理健康状况上展现出了积极的作用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Large+Language+Model-Powered+Conversational+Agent+Delivering+Problem-Solving+Therapy+%28PST%29+for+Family+Caregivers%3A+Enhancing+Empathy+and+Therapeutic+Alliance+Using+In-Context+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11376，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11376&send_immediately=true&force_search=false)

**原文摘要:** Family caregivers often face substantial mental health challenges due to
their multifaceted roles and limited resources. This study explored the
potential of a large language model (LLM)-powered conversational agent to
deliver evidence-based mental health support for caregivers, specifically
Problem-Solving Therapy (PST) integrated with Motivational Interviewing (MI)
and Behavioral Chain Analysis (BCA). A within-subject experiment was conducted
with 28 caregivers interacting with four LLM configurations to evaluate empathy
and therapeutic alliance. The best-performing models incorporated Few-Shot and
Retrieval-Augmented Generation (RAG) prompting techniques, alongside
clinician-curated examples. The models showed improved contextual understanding
and personalized support, as reflected by qualitative responses and
quantitative ratings on perceived empathy and therapeutic alliances.
Participants valued the model's ability to validate emotions, explore
unexpressed feelings, and provide actionable strategies. However, balancing
thorough assessment with efficient advice delivery remains a challenge. This
work highlights the potential of LLMs in delivering empathetic and tailored
support for family caregivers.

</details>


### [110] [FocalAD: Local Motion Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2506.11419)
*Bin Sun, Boao Zhang, Jiayi Lu, Xinjie Feng, Jiachen Shang, Rui Cao, Mengchao Zheng, Chuanye Wang, Shichun Yang, Yaoguang Cao, Ziying Song*

**主要类别:** cs.AI

**AI概要:** 提出了FocalAD，一种端到端的自动驾驶框架，通过增强局部运动表示来改善规划，并专注于关键局部邻居。实验表明，FocalAD在多个数据集上优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的端到端自动驾驶中运动预测方法通常依赖于全局聚合的运动特征，忽略了规划决策主要受到少数局部交互代理的影响。未能关注这些重要的局部交互可能会掩盖潜在风险并削弱规划可靠性。

**方法:** FocalAD框架包括两个核心模块：Ego-Local-Agents Interactor（ELAI）和Focal-Local-Agents Loss（FLA Loss）。ELAI通过基于图的自我中心交互表示捕捉与局部邻居之间的运动动态，以改进自我车辆规划及代理运动查询。FLA Loss增加对决策至关重要的相邻代理的权重，指导模型优先考虑那些更相关的规划。

**结果:** 广泛的实验显示，FocalAD在nuScenes开放环路数据集和Bench2Drive闭环基准测试上超越了现有最先进方法。特别是在注重鲁棒性的Adv-nuScenes数据集中，FocalAD相较于DiffusionDrive平均碰撞率降低了41.9%，而相比SparseDrive则降低了15.6%。

**结论:** FocalAD通过聚焦关键局部邻居并加强局部运动表征，提高了自动驾驶系统的规划可靠性和安全性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FocalAD%3A+Local+Motion+Planning+for+End-to-End+Autonomous+Driving，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11419，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11419&send_immediately=true&force_search=false)

**原文摘要:** In end-to-end autonomous driving,the motion prediction plays a pivotal role
in ego-vehicle planning. However, existing methods often rely on globally
aggregated motion features, ignoring the fact that planning decisions are
primarily influenced by a small number of locally interacting agents. Failing
to attend to these critical local interactions can obscure potential risks and
undermine planning reliability. In this work, we propose FocalAD, a novel
end-to-end autonomous driving framework that focuses on critical local
neighbors and refines planning by enhancing local motion representations.
Specifically, FocalAD comprises two core modules: the Ego-Local-Agents
Interactor (ELAI) and the Focal-Local-Agents Loss (FLA Loss). ELAI conducts a
graph-based ego-centric interaction representation that captures motion
dynamics with local neighbors to enhance both ego planning and agent motion
queries. FLA Loss increases the weights of decision-critical neighboring
agents, guiding the model to prioritize those more relevant to planning.
Extensive experiments show that FocalAD outperforms existing state-of-the-art
methods on the open-loop nuScenes datasets and closed-loop Bench2Drive
benchmark. Notably, on the robustness-focused Adv-nuScenes dataset, FocalAD
achieves even greater improvements, reducing the average colilision rate by
41.9% compared to DiffusionDrive and by 15.6% compared to SparseDrive.

</details>


### [111] [Resolve Highway Conflict in Multi-Autonomous Vehicle Controls with Local State Attention](https://arxiv.org/abs/2506.11445)
*Xuan Duy Ta, Bang Giang Le, Thanh Ha Le, Viet Cuong Ta*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种局部状态注意力模块，以帮助自动驾驶车辆在混合交通环境中更好地处理与其他车辆的冲突和随机事件。通过模拟高速公路合并场景测试，结果表明该方法相比现有基线在合并效率上有了显著提升，特别是在高密度交通环境下。


<details>
  <summary>更多</summary>
  
**动机:** 在混合交通环境中，自动驾驶车辆需要适应人类驾驶的车辆和其他非常规驾驶情况。尽管多智能体近端策略优化等方法可以有效训练MARL任务，但它们往往无法解决智能体之间的局部冲突，并且难以泛化到随机事件中。

**方法:** 本文提出了一个局部状态注意模块来辅助输入状态表示。通过依赖自注意力操作符，该模块旨在压缩附近智能体的关键信息，以解决交通情境中的冲突。利用具有优先车辆作为意外事件的模拟高速公路合并情景，本方法能够优先考虑其他车辆的信息以管理合并过程。

**结果:** 结果表明，与流行的基线相比，我们的方法在合并效率方面有显著提高，尤其是在高密度交通设置下。

**结论:** 局部状态注意力模块有助于改善自动驾驶汽车在复杂交通环境下的表现，特别是在处理突发事件和提高合并效率方面。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Resolve+Highway+Conflict+in+Multi-Autonomous+Vehicle+Controls+with+Local+State+Attention，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11445，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11445&send_immediately=true&force_search=false)

**原文摘要:** In mixed-traffic environments, autonomous vehicles must adapt to
human-controlled vehicles and other unusual driving situations. This setting
can be framed as a multi-agent reinforcement learning (MARL) environment with
full cooperative reward among the autonomous vehicles. While methods such as
Multi-agent Proximal Policy Optimization can be effective in training MARL
tasks, they often fail to resolve local conflict between agents and are unable
to generalize to stochastic events. In this paper, we propose a Local State
Attention module to assist the input state representation. By relying on the
self-attention operator, the module is expected to compress the essential
information of nearby agents to resolve the conflict in traffic situations.
Utilizing a simulated highway merging scenario with the priority vehicle as the
unexpected event, our approach is able to prioritize other vehicles'
information to manage the merging process. The results demonstrate significant
improvements in merging efficiency compared to popular baselines, especially in
high-density traffic settings.

</details>


### [112] [Structure-Aware Automatic Channel Pruning by Searching with Graph Embedding](https://arxiv.org/abs/2506.11469)
*Zifan Liu, Yuan Cao, Yanwei Yu, Heng Qi, Jie Gui*

**主要类别:** cs.AI

**AI概要:** 提出了一种结构感知的自动通道剪枝框架SACP，利用图卷积网络来建模网络拓扑并学习每个通道的全局重要性，通过搜索确定最佳剪枝率组合，在基准数据集上优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的剪枝方法通常依赖于局部启发式或基于权重的标准，无法捕捉网络内的全局结构依赖关系，导致次优的剪枝决策和模型性能下降。

**方法:** 提出了一个名为SACP的新框架，该框架使用图卷积网络（GCNs）对网络拓扑进行建模，并学习每个通道的重要性。此外，通过将剪枝率组合限制在特定空间内，并采用搜索方法来确定最优剪枝率组合。

**结果:** 在CIFAR-10和ImageNet等基准数据集以及ResNet、VGG16等多种模型上的广泛实验表明，SACP在压缩效率方面优于最先进的剪枝方法，并且在保持准确度方面具有竞争力。

**结论:** SACP框架通过考虑全局结构信息实现了更高效的神经网络剪枝，有助于减少计算开销，同时保持较高的模型准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Structure-Aware+Automatic+Channel+Pruning+by+Searching+with+Graph+Embedding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11469，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11469&send_immediately=true&force_search=false)

**原文摘要:** Channel pruning is a powerful technique to reduce the computational overhead
of deep neural networks, enabling efficient deployment on resource-constrained
devices. However, existing pruning methods often rely on local heuristics or
weight-based criteria that fail to capture global structural dependencies
within the network, leading to suboptimal pruning decisions and degraded model
performance. To address these limitations, we propose a novel structure-aware
automatic channel pruning (SACP) framework that utilizes graph convolutional
networks (GCNs) to model the network topology and learn the global importance
of each channel. By encoding structural relationships within the network, our
approach implements topology-aware pruning and this pruning is fully automated,
reducing the need for human intervention. We restrict the pruning rate
combinations to a specific space, where the number of combinations can be
dynamically adjusted, and use a search-based approach to determine the optimal
pruning rate combinations. Extensive experiments on benchmark datasets
(CIFAR-10, ImageNet) with various models (ResNet, VGG16) demonstrate that SACP
outperforms state-of-the-art pruning methods on compression efficiency and
competitive on accuracy retention.

</details>


### [113] [Reviving DSP for Advanced Theorem Proving in the Era of Reasoning Models](https://arxiv.org/abs/2506.11487)
*Chenrui Cao, Liangcheng Song, Zenan Li, Xinyi Le, Xian Zhang, Hui Xue, Fan Yang*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种改进的神经符号协调框架DSP+，无需额外训练即可在自动定理证明中达到与基于强化学习的大规模训练模型相当的表现，并且在解决miniF2F、ProofNet和PutnamBench问题集中的题目时表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 当前趋势是利用基于强化学习的大规模训练来进行自动定理证明，但研究者发现即使不经过任何训练，通过精心设计的现有推理模型和策略步骤证明器之间的神经符号协调也能取得类似的效果。

**方法:** 提出了一个名为DSP+的框架，该框架对每个阶段都进行了细粒度和集成化的神经符号增强：1) 在草稿阶段，提示推理模型生成简洁的自然语言子目标以利于草图阶段；2) 在草图阶段，自形式化假设来帮助证明阶段，并根据预定义规则屏蔽包含语法错误的草图行；3) 在证明阶段，将像Aesop这样的符号搜索方法与步骤证明器紧密集成以建立草图子目标的证明。

**结果:** 实验结果表明，无需额外的模型训练或微调，DSP+分别解决了来自miniF2F、ProofNet和PutnamBench的644个问题中的80.7%、32.8%和24个问题，并且相比于最先进的方法需要更少的资源。此外，DSP+还证明了一个先前工作未解决的IMO问题，并且生成了人类专家可以理解的证明模式，有助于识别形式化错误。

**结论:** 研究结果强调了除了基于RL的训练之外，经典推理模式的潜力。所有组件都将开源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reviving+DSP+for+Advanced+Theorem+Proving+in+the+Era+of+Reasoning+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11487，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11487&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements, such as DeepSeek-Prover-V2-671B and
Kimina-Prover-Preview-72B, demonstrate a prevailing trend in leveraging
reinforcement learning (RL)-based large-scale training for automated theorem
proving. Surprisingly, we discover that even without any training, careful
neuro-symbolic coordination of existing off-the-shelf reasoning models and
tactic step provers can achieve comparable performance. This paper introduces
\textbf{DSP+}, an improved version of the Draft, Sketch, and Prove framework,
featuring a \emph{fine-grained and integrated} neuro-symbolic enhancement for
each phase: (1) In the draft phase, we prompt reasoning models to generate
concise natural-language subgoals to benefit the sketch phase, removing
thinking tokens and references to human-written proofs; (2) In the sketch
phase, subgoals are autoformalized with hypotheses to benefit the proving
phase, and sketch lines containing syntactic errors are masked according to
predefined rules; (3) In the proving phase, we tightly integrate symbolic
search methods like Aesop with step provers to establish proofs for the sketch
subgoals. Experimental results show that, without any additional model training
or fine-tuning, DSP+ solves 80.7\%, 32.8\%, and 24 out of 644 problems from
miniF2F, ProofNet, and PutnamBench, respectively, while requiring fewer budgets
compared to state-of-the-arts. DSP+ proves \texttt{imo\_2019\_p1}, an IMO
problem in miniF2F that is not solved by any prior work. Additionally, DSP+
generates proof patterns comprehensible by human experts, facilitating the
identification of formalization errors; For example, eight wrongly formalized
statements in miniF2F are discovered. Our results highlight the potential of
classical reasoning patterns besides the RL-based training. All components will
be open-sourced.

</details>


### [114] [RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning](https://arxiv.org/abs/2506.11555)
*Yu Wang, Shiwan Zhao, Ming Fan, Zhihu Wang, Yubo Zhang, Xicheng Zhang, Zhengfan Wang, Heyuan Huang, Ting Liu*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种名为RAG+的新方法，它通过在检索增强生成（RAG）管道中明确地结合应用意识推理来改进大型语言模型（LLMs），从而缩小了所检索事实与任务特定推理之间的差距。实验表明，RAG+在多个领域和模型上都优于标准RAG变体。


<details>
  <summary>更多</summary>
  
**动机:** 现有的检索增强生成（RAG）范式往往忽视了知识应用的认知步骤，导致检索到的事实与任务特定推理之间存在脱节。

**方法:** RAG+是一个有原则且模块化的扩展，它构建了一个由知识和对齐的应用示例组成的双重语料库，并在推理过程中联合检索两者。

**结果:** 实验显示，RAG+在数学、法律和医学领域的多个模型上持续优于标准RAG变体，平均提升了3-5%，在复杂场景下最高可达7.5%的增益。

**结论:** 通过将检索与可操作的应用相结合，RAG+为知识整合提供了一个更加基于认知基础的框架，朝着更可解释和能力更强的大型语言模型迈进了一步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是RAG%2B%3A+Enhancing+Retrieval-Augmented+Generation+with+Application-Aware+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11555，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11555&send_immediately=true&force_search=false)

**原文摘要:** The integration of external knowledge through Retrieval-Augmented Generation
(RAG) has become foundational in enhancing large language models (LLMs) for
knowledge-intensive tasks. However, existing RAG paradigms often overlook the
cognitive step of applying knowledge, leaving a gap between retrieved facts and
task-specific reasoning. In this work, we introduce RAG+, a principled and
modular extension that explicitly incorporates application-aware reasoning into
the RAG pipeline. RAG+ constructs a dual corpus consisting of knowledge and
aligned application examples, created either manually or automatically, and
retrieves both jointly during inference. This design enables LLMs not only to
access relevant information but also to apply it within structured,
goal-oriented reasoning processes. Experiments across mathematical, legal, and
medical domains, conducted on multiple models, demonstrate that RAG+
consistently outperforms standard RAG variants, achieving average improvements
of 3-5%, and peak gains up to 7.5% in complex scenarios. By bridging retrieval
with actionable application, RAG+ advances a more cognitively grounded
framework for knowledge integration, representing a step toward more
interpretable and capable LLMs.

</details>


### [115] [Collaborative LLM Inference via Planning for Efficient Reasoning](https://arxiv.org/abs/2506.11578)
*Byeongchan Lee, Jonghoon Lee, Dongyoung Kim, Jaehyung Kim, Jinwoo Shin*

**主要类别:** cs.AI

**AI概要:** 提出了一种测试时协作框架，使得小型（免费）和大型（付费）语言模型能够合作解决复杂任务，通过规划者模型生成计划并由推理者模型执行，从而在保持准确性的同时显著减少对付费推理的依赖。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型在复杂的推理任务上表现出色，但那些能力强大的模型通常只能通过付费API访问，成本过高；而较小的开源模型虽然免费且易于本地部署，但缺乏足够的推理能力。为了解决这一矛盾，研究提出了一个使大小模型能够在测试阶段协作的框架，以结合它们的优势。

**方法:** 该论文介绍了一个测试时协作框架，在这个框架中，首先由一个规划者模型生成一个计划，这个计划是对问题的高度抽象和提炼。接着，这个计划作为轻量级的中介来指导推理者模型产生完整的解决方案。小型和大型模型轮流担任规划者和推理者的角色，通过多轮次传递计划来协作解决复杂任务。

**结果:** 所提出的方法实现了与单独使用强大专有模型相当的准确性，同时显著减少了对付费推理服务的依赖。这些结果突出了规划作为一种有效的先验手段，在现实世界的部署约束下协调成本意识的跨模型推理的有效性。

**结论:** 研究表明，通过让小型和大型语言模型在测试时协作，可以有效地结合两者的优势，即在保证解决问题准确性的同时大大降低了成本。这表明了规划在实际部署限制条件下对于组织成本敏感的跨模型推理的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Collaborative+LLM+Inference+via+Planning+for+Efficient+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11578，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11578&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) excel at complex reasoning tasks, but those with
strong capabilities (e.g., whose numbers of parameters are larger than 100B)
are often accessible only through paid APIs, making them too costly for
applications of frequent use. In contrast, smaller open-sourced LLMs (e.g.,
whose numbers of parameters are less than 3B) are freely available and easy to
deploy locally (e.g., under a single GPU having 8G VRAM), but lack suff icient
reasoning ability. This trade-off raises a natural question: can small (free)
and large (costly) models collaborate at test time to combine their strengths?
We propose a test-time collaboration framework in which a planner model first
generates a plan, defined as a distilled and high-level abstraction of the
problem.
  This plan serves as a lightweight intermediate that guides a reasoner model,
which generates a complete solution. Small and large models take turns acting
as planner and reasoner, exchanging plans in a multi-round cascade to
collaboratively solve complex tasks. Our method achieves accuracy comparable to
strong proprietary models alone, while significantly reducing reliance on paid
inference. These results highlight planning as an effective prior for
orchestrating cost-aware, cross-model inference under real-world deployment
constraints.

</details>


### [116] [VLM@school -- Evaluation of AI image understanding on German middle school knowledge](https://arxiv.org/abs/2506.11604)
*René Peinl, Vincent Tischler*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一个新的基准数据集，用于评估视觉语言模型在结合视觉推理与德语科目背景知识的任务上的能力。该数据集基于真实中学课程的九个领域，包括数学、历史、生物和宗教等，并包含了2000多个开放式问题以及486张图片。研究发现即使是表现最好的模型整体准确率也不到45%，尤其在音乐、数学和对抗性问题上表现较差。结果表明流行基准测试的成功与现实世界多模态理解之间存在显著差异。


<details>
  <summary>更多</summary>
  
**动机:** 现有的英文基准测试通常依赖于人为制造的难题或脱离上下文的问题，而本文旨在通过构建一个基于德国中学实际课程内容的数据集来评估视觉语言模型（VLMs）在需要结合视觉理解和学科特定背景知识任务中的表现。

**方法:** 创建了一个包含超过2000个开放性问题的新数据集，这些问题基于486张图像，涵盖了从数学到宗教等九个不同领域的中学课程内容。使用了十三种最先进且权重公开的视觉语言模型来进行跨维度评估，包括领域特异性准确性及对抗性设计问题上的性能。

**结果:** 最强的模型总体准确率也低于45%，特别是在音乐、数学以及对抗性条件下表现尤为不佳。这显示出当前流行的基准测试成绩与现实世界中多模态理解能力之间存在较大差距。

**结论:** 中学水平的任务为测试VLMs提供了一条有意义但未充分利用的途径，尤其是在非英语环境中。所提出的数据集和评估协议作为一个严格的测试平台，有助于更好地理解和改进未来AI系统在视觉和语言推理方面的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是VLM%40school+--+Evaluation+of+AI+image+understanding+on+German+middle+school+knowledge，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11604，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11604&send_immediately=true&force_search=false)

**原文摘要:** This paper introduces a novel benchmark dataset designed to evaluate the
capabilities of Vision Language Models (VLMs) on tasks that combine visual
reasoning with subject-specific background knowledge in the German language. In
contrast to widely used English-language benchmarks that often rely on
artificially difficult or decontextualized problems, this dataset draws from
real middle school curricula across nine domains including mathematics,
history, biology, and religion. The benchmark includes over 2,000 open-ended
questions grounded in 486 images, ensuring that models must integrate visual
interpretation with factual reasoning rather than rely on superficial textual
cues. We evaluate thirteen state-of-the-art open-weight VLMs across multiple
dimensions, including domain-specific accuracy and performance on adversarial
crafted questions. Our findings reveal that even the strongest models achieve
less than 45% overall accuracy, with particularly poor performance in music,
mathematics, and adversarial settings. Furthermore, the results indicate
significant discrepancies between success on popular benchmarks and real-world
multimodal understanding. We conclude that middle school-level tasks offer a
meaningful and underutilized avenue for stress-testing VLMs, especially in
non-English contexts. The dataset and evaluation protocol serve as a rigorous
testbed to better understand and improve the visual and linguistic reasoning
capabilities of future AI systems.

</details>


### [117] [Mitigating Hallucination Through Theory-Consistent Symmetric Multimodal Preference Optimization](https://arxiv.org/abs/2506.11712)
*Wenqi Liu, Xuemeng Song, Jiaxi Li, Yinwei Wei, Na Zheng, Jianhua Yin, Liqiang Nie*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种对称多模态偏好优化(SymMPO)方法，通过直接的偏好监督来增强视觉理解，并引入了偏好边界一致性损失以定量调节对称偏好对之间的偏好差距。在五个基准测试中的综合评估表明，SymMPO在减少MLLMs的幻觉方面表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 现有的方法虽然已经通过利用面向视觉的对比目标来提高MLLMs对视觉输入的关注度从而减少了幻觉，但它们存在优化目标函数不够严谨和偏好监督间接的问题。为了解决这些问题，作者提出了SymMPO方法。

**方法:** SymMPO执行具有直接偏好监督（即响应对）的对称偏好学习，以增强视觉理解，同时保持与标准DPO的严格理论一致性。此外，除了传统的顺序偏好学习之外，SymMPO还引入了偏好边界一致性损失来量化调节对称偏好对之间的偏好差距。

**结果:** 在五个基准测试中进行的综合评估证明了SymMPO在减少MLLMs幻觉方面的优越性能。

**结论:** SymMPO提供了一种更有效的方法来减少多模态大型语言模型中的幻觉问题，通过直接偏好监督和额外的偏好边界一致性损失，它在多个基准上表现优于现有方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mitigating+Hallucination+Through+Theory-Consistent+Symmetric+Multimodal+Preference+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11712，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11712&send_immediately=true&force_search=false)

**原文摘要:** Direct Preference Optimization (DPO) has emerged as an effective approach for
mitigating hallucination in Multimodal Large Language Models (MLLMs). Although
existing methods have achieved significant progress by utilizing
vision-oriented contrastive objectives for enhancing MLLMs' attention to visual
inputs and hence reducing hallucination, they suffer from non-rigorous
optimization objective function and indirect preference supervision. To address
these limitations, we propose a Symmetric Multimodal Preference Optimization
(SymMPO), which conducts symmetric preference learning with direct preference
supervision (i.e., response pairs) for visual understanding enhancement, while
maintaining rigorous theoretical alignment with standard DPO. In addition to
conventional ordinal preference learning, SymMPO introduces a preference margin
consistency loss to quantitatively regulate the preference gap between
symmetric preference pairs. Comprehensive evaluation across five benchmarks
demonstrate SymMPO's superior performance, validating its effectiveness in
hallucination mitigation of MLLMs.

</details>


### [118] [Relational GNNs Cannot Learn $C_2$ Features for Planning](https://arxiv.org/abs/2506.11721)
*Dillon Z. Chen*

**主要类别:** cs.AI

**AI概要:** 论文指出，尽管R-GNNs在理论上与C_2特征有关，但它们实际上无法学习由C_2特征定义的价值函数，并且提出了之前的一些GNN架构可能更适合于学习这类价值函数。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机是基于关系图神经网络（R-GNNs）的理论基础，即GNNs的表现力与C_2（一种带有两个变量和计数的一阶逻辑）之间的已知联系，以及在规划领域中C_2特征对于描述最优价值函数的重要性。

**方法:** 通过理论分析来证明R-GNNs不能学习由C_2特征定义的价值函数，并且还鉴定了先前用于规划的GNN架构，这些架构可能更能够学习此类价值函数。

**结果:** 结果表明，与经验结果相反，R-GNNs并不能学习由C_2特征定义的价值函数。

**结论:** 结论是虽然R-GNNs在理论上与C_2特征相关联，但实际上它们并不适合学习这种类型的价值函数，而其他一些GNN架构可能更加适合。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Relational+GNNs+Cannot+Learn+%24C_2%24+Features+for+Planning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11721，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11721&send_immediately=true&force_search=false)

**原文摘要:** Relational Graph Neural Networks (R-GNNs) are a GNN-based approach for
learning value functions that can generalise to unseen problems from a given
planning domain. R-GNNs were theoretically motivated by the well known
connection between the expressive power of GNNs and $C_2$, first-order logic
with two variables and counting. In the context of planning, $C_2$ features
refer to the set of formulae in $C_2$ with relations defined by the unary and
binary predicates of a planning domain. Some planning domains exhibit optimal
value functions that can be decomposed as arithmetic expressions of $C_2$
features. We show that, contrary to empirical results, R-GNNs cannot learn
value functions defined by $C_2$ features. We also identify prior GNN
architectures for planning that may better learn value functions defined by
$C_2$ features.

</details>


### [119] [Causal Effect Identification in Heterogeneous Environments from Higher-Order Moments](https://arxiv.org/abs/2506.11756)
*Yaroslav Kivva, Sina Akbari, Saber Salehkaleybar, Negar Kiyavash*

**主要类别:** cs.AI

**AI概要:** 本文探讨了在存在潜在混淆变量的情况下，如何通过来自多个环境的数据估计处理变量对结果的因果效应。提出了当数据生成机制中只有一个参数跨环境变化时估计因果效应的方法，并证明了如果潜在变量和处理变量的外生噪声分布都跨环境变化，则无法识别因果效应。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于解决在存在未观察到的混杂因素的情况下，如何准确地估计一个处理变量对于结果变量的因果效应。

**方法:** 采用基于矩的方法来估计因果效应，前提是数据生成机制中的单一参数（无论是外生噪声分布还是两个变量间的因果关系）在不同环境中发生变化。

**结果:** 结果显示，只要数据生成机制的一个参数在各环境中有所不同，就可以估计出因果效应；但如果潜在变量和处理变量的外生噪声分布都在各环境中变化，则因果效应变得不可识别。此外，还提出了一种方法来判断哪个参数发生了变化。

**结论:** 该研究为存在潜在混淆因子情况下的因果推断提供了新的见解与工具，但在某些情况下仍面临挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Causal+Effect+Identification+in+Heterogeneous+Environments+from+Higher-Order+Moments，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11756，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11756&send_immediately=true&force_search=false)

**原文摘要:** We investigate the estimation of the causal effect of a treatment variable on
an outcome in the presence of a latent confounder. We first show that the
causal effect is identifiable under certain conditions when data is available
from multiple environments, provided that the target causal effect remains
invariant across these environments. Secondly, we propose a moment-based
algorithm for estimating the causal effect as long as only a single parameter
of the data-generating mechanism varies across environments -- whether it be
the exogenous noise distribution or the causal relationship between two
variables. Conversely, we prove that identifiability is lost if both exogenous
noise distributions of both the latent and treatment variables vary across
environments. Finally, we propose a procedure to identify which parameter of
the data-generating mechanism has varied across the environments and evaluate
the performance of our proposed methods through experiments on synthetic data.

</details>


### [120] [On the Performance of LLMs for Real Estate Appraisal](https://arxiv.org/abs/2506.11812)
*Margot Geerts, Manon Reusens, Bart Baesens, Seppe vanden Broucke, Jochen De Weerdt*

**主要类别:** cs.AI

**AI概要:** 本研究探讨了大型语言模型（LLMs）如何通过优化的上下文学习（ICL）策略来提供竞争性和可解释性的房价估计，从而民主化房地产洞察的获取。尽管传统机器学习模型在预测准确性方面仍占优势，但LLMs 提供了一个更易访问、互动和可解释的选择。研究结果表明，精心挑选基于特征相似性和地理邻近性的上下文示例能够显著提高 LLM 的表现，但 LLM 在价格区间过度自信和空间推理能力有限的问题上仍存在挑战。


<details>
  <summary>更多</summary>
  
**动机:** 房地产市场对全球经济至关重要，但由于信息不对称而受到限制。本研究动机在于探索大型语言模型能否通过生成易于理解的房价评估来解决这一问题，并为利益相关者提供透明度更高的房地产估价服务。

**方法:** 研究方法包括系统地评估不同国际住房数据集上的领先大型语言模型，比较零样本、少样本、增强市场报告以及混合提示技术的效果。此外，还考察了根据特征相似性和地理位置选择上下文实例对 LLM 性能的影响。

**结果:** 研究表明，大型语言模型可以有效利用诸如房产大小和设施等享乐变量来进行有意义的价格估计。虽然在纯预测精度上不如传统机器学习模型，但 LLMs 提供了更加友好且可解释的选择。同时发现，基于特征与位置相似性精选的上下文案例能够大大提升 LLM 的性能；不过，LLM 在处理价格范围时表现出过度自信，并且其空间推理能力有所欠缺。

**结论:** 结论是，通过优化提示策略，大型语言模型有潜力改善房地产评估过程中的透明度并为各方参与者提供有价值的见解。尽管存在一些局限性，但 LLM 作为传统方法之外的一种补充手段展现出了巨大的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Performance+of+LLMs+for+Real+Estate+Appraisal，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11812，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11812&send_immediately=true&force_search=false)

**原文摘要:** The real estate market is vital to global economies but suffers from
significant information asymmetry. This study examines how Large Language
Models (LLMs) can democratize access to real estate insights by generating
competitive and interpretable house price estimates through optimized
In-Context Learning (ICL) strategies. We systematically evaluate leading LLMs
on diverse international housing datasets, comparing zero-shot, few-shot,
market report-enhanced, and hybrid prompting techniques. Our results show that
LLMs effectively leverage hedonic variables, such as property size and
amenities, to produce meaningful estimates. While traditional machine learning
models remain strong for pure predictive accuracy, LLMs offer a more
accessible, interactive and interpretable alternative. Although
self-explanations require cautious interpretation, we find that LLMs explain
their predictions in agreement with state-of-the-art models, confirming their
trustworthiness. Carefully selected in-context examples based on feature
similarity and geographic proximity, significantly enhance LLM performance, yet
LLMs struggle with overconfidence in price intervals and limited spatial
reasoning. We offer practical guidance for structured prediction tasks through
prompt optimization. Our findings highlight LLMs' potential to improve
transparency in real estate appraisal and provide actionable insights for
stakeholders.

</details>


### [121] [Revealing Political Bias in LLMs through Structured Multi-Agent Debate](https://arxiv.org/abs/2506.11825)
*Aishwarya Bandaru, Fabian Bindley, Trevor Bluth, Nandini Chavda, Baixu Chen, Ethan Law*

**主要类别:** cs.AI

**AI概要:** 研究了大型语言模型（LLMs）在模拟社交行为时的政治偏见和辩论中的互动动态，发现中立代理人倾向于与民主党人保持一致，而共和党人则更接近中立；性别对代理人的态度有影响，并且具有相同政治归属的代理人可以形成回音室。


<details>
  <summary>更多</summary>
  
**动机:** 探索大型语言模型在模拟社会行为时的政治偏向性和辩论中的互动模式，这是一个尚未充分研究的领域。

**方法:** 通过构建一个结构化的多智能体辩论框架，让代表中立、共和党和民主党的美国LLM代理人参与关于政治敏感话题的辩论，并系统地改变底层LLM、代理人性别以及辩论格式来观察模型来源和代理人人格如何影响整个辩论过程中的政治偏见和态度。

**结果:** 中立代理人通常与民主党观点保持一致，而共和党代理人则向中立靠拢；性别会影响代理人态度，当代理人意识到其他代理人的性别时，会调整自己的观点；与先前的研究相反，具有相同政治归属的代理人能够形成回音室，随着辩论的进行表现出预期的态度强化。

**结论:** 大型语言模型在模拟辩论等社会互动时展现出复杂的政治偏见和个人特质，这表明需要进一步研究这些模型在不同情境下的行为表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Revealing+Political+Bias+in+LLMs+through+Structured+Multi-Agent+Debate，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11825，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11825&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are increasingly used to simulate social
behaviour, yet their political biases and interaction dynamics in debates
remain underexplored. We investigate how LLM type and agent gender attributes
influence political bias using a structured multi-agent debate framework, by
engaging Neutral, Republican, and Democrat American LLM agents in debates on
politically sensitive topics. We systematically vary the underlying LLMs, agent
genders, and debate formats to examine how model provenance and agent personas
influence political bias and attitudes throughout debates. We find that Neutral
agents consistently align with Democrats, while Republicans shift closer to the
Neutral; gender influences agent attitudes, with agents adapting their opinions
when aware of other agents' genders; and contrary to prior research, agents
with shared political affiliations can form echo chambers, exhibiting the
expected intensification of attitudes as debates progress.

</details>


### [122] [Addressing Bias in LLMs: Strategies and Application to Fair AI-based Recruitment](https://arxiv.org/abs/2506.11880)
*Alejandro Peña, Julian Fierrez, Aythami Morales, Gonzalo Mancera, Miguel Lopez, Ruben Tolosana*

**主要类别:** cs.AI

**AI概要:** 本文研究了基于Transformer的系统在学习数据中存在的群体偏见的能力，并提出了一种隐私增强框架来减少学习流程中的性别信息，以缓解最终工具中的偏见行为。实验分析了数据偏见对基于两种不同大语言模型系统的影响力，以及所提出的框架如何有效地防止训练出的系统再现数据中的偏见。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLMs）表现出色，但在高风险环境中使用时，它们容易受到伦理问题的影响，如人口统计学偏见、问责制或隐私问题。本研究旨在通过基于AI的自动化招聘案例研究，分析基于Transformer的系统学习数据中存在的人口统计学偏见的能力。

**方法:** 提出了一个隐私增强框架，用于从学习过程中减少性别信息，以此作为减轻最终工具中偏见行为的一种手段。实验设计用来评估该框架在两个不同的大型语言模型上构建的系统中的有效性。

**结果:** 实验结果表明，所提框架能够有效阻止系统在学习过程中复制数据中存在的性别偏见。

**结论:** 研究强调了在开发基于人工智能的招聘工具时考虑隐私保护措施的重要性，并展示了如何通过实施特定策略来减轻潜在的偏见。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Addressing+Bias+in+LLMs%3A+Strategies+and+Application+to+Fair+AI-based+Recruitment，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11880，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11880&send_immediately=true&force_search=false)

**原文摘要:** The use of language technologies in high-stake settings is increasing in
recent years, mostly motivated by the success of Large Language Models (LLMs).
However, despite the great performance of LLMs, they are are susceptible to
ethical concerns, such as demographic biases, accountability, or privacy. This
work seeks to analyze the capacity of Transformers-based systems to learn
demographic biases present in the data, using a case study on AI-based
automated recruitment. We propose a privacy-enhancing framework to reduce
gender information from the learning pipeline as a way to mitigate biased
behaviors in the final tools. Our experiments analyze the influence of data
biases on systems built on two different LLMs, and how the proposed framework
effectively prevents trained systems from reproducing the bias in the data.

</details>


### [123] [Towards a Cascaded LLM Framework for Cost-effective Human-AI Decision-Making](https://arxiv.org/abs/2506.11887)
*Claudio Fanconi, Mihaela van der Schaar*

**主要类别:** cs.AI

**AI概要:** 论文提出了一种级联的LLM决策框架，用于在基础模型、更强大的大型模型和人类专家之间自适应地分配任务，以平衡预测准确性、知识与推理成本以及是否需要人类介入的信心。该方法通过延期策略和弃权策略两个阶段来决定接受基础模型的答案、使用大型模型重新生成答案或请求人类干预，并且该框架包含一个在线学习机制，可以利用人类反馈随着时间提高决策质量。实验结果表明，这种级联策略在大多数情况下提高了准确性，同时降低了成本，并提供了一个处理弃权问题的原则性方法。


<details>
  <summary>更多</summary>
  
**动机:** 有效的AI-人类决策需要平衡预测的正确性、知识和推理复杂性的成本，以及关于是否应放弃自动化答案或引入人类专家的信心。

**方法:** 论文提出的是一种基于级联大语言模型（LLM）的决策框架，包括两个主要阶段：首先是一个延期策略，它根据置信度分数判断是接受基础模型的答案还是用更大规模的模型重新生成；其次是弃权策略，决定级联模型的回答是否足够确定或需要人类干预。此外，该框架中还结合了在线学习机制，能够利用人类反馈来逐步改善决策的质量。

**结果:** 研究者们在一般问题回答（ARC-Easy和ARC-Challenge）和医学问题回答（MedQA和MedMCQA）上展示了这种方法。结果显示，相比单个模型基线，所提出的级联策略在大多数情况下不仅提高了准确率，而且还减少了成本，并为处理弃权提供了一种有原则的方法。

**结论:** 论文展示了一种新的决策框架，该框架能够有效地在不同层级的专业知识之间分配任务，既提升了决策的准确性又控制了成本，并且能通过在线学习不断改进。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+a+Cascaded+LLM+Framework+for+Cost-effective+Human-AI+Decision-Making，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11887，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11887&send_immediately=true&force_search=false)

**原文摘要:** Effective human-AI decision-making balances three key factors: the
\textit{correctness} of predictions, the \textit{cost} of knowledge and
reasoning complexity, and the confidence about whether to \textit{abstain}
automated answers or involve human experts. In this work, we present a cascaded
LLM decision framework that adaptively delegates tasks across multiple tiers of
expertise -- a base model for initial candidate answers, a more capable and
knowledgeable (but costlier) large model, and a human expert for when the model
cascade abstains. Our method proceeds in two stages. First, a deferral policy
determines whether to accept the base model's answer or regenerate it with the
large model based on the confidence score. Second, an abstention policy decides
whether the cascade model response is sufficiently certain or requires human
intervention. Moreover, we incorporate an online learning mechanism in the
framework that can leverage human feedback to improve decision quality over
time. We demonstrate this approach to general question-answering (ARC-Easy and
ARC-Challenge) and medical question-answering (MedQA and MedMCQA). Our results
show that our cascaded strategy outperforms in most cases single-model
baselines in accuracy while reducing cost and providing a principled way to
handle abstentions.

</details>


### [124] [Schema-R1: A reasoning training approach for schema linking in Text-to-SQL Task](https://arxiv.org/abs/2506.11986)
*Wuzhenghong Wen, Su Pan, yuwei Sun*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种基于强化学习的推理模式链接模型Schema-R1，旨在提高Text-to-SQL任务中模式链接的推理能力。通过构建高质量推理样本、有监督微调以及基于规则的强化学习训练三个步骤，该方法相比现有技术提高了过滤准确率10%。


<details>
  <summary>更多</summary>
  
**动机:** 当前用于模式链接模型的微调方法采用死记硬背的学习方式，过度优化真实模式链接结果而牺牲了推理能力。由于下游任务难以获得高质量推理样本，作者们提出了一个新的解决方案来增强模式链接模型的推理能力。

**方法:** 所提出的Schema-R1模型包括三个主要步骤：
1. 构建小批量的高质量推理样本
2. 为冷启动初始化进行监督式微调
3. 基于规则的强化学习训练

**结果:** 实验结果显示，与现有方法相比，Schema-R1方法在过滤准确率上提升了10%。

**结论:** 研究表明，Schema-R1能够有效提升模式链接模型的推理能力，并且在过滤准确率方面取得了显著改进。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Schema-R1%3A+A+reasoning+training+approach+for+schema+linking+in+Text-to-SQL+Task，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11986，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11986&send_immediately=true&force_search=false)

**原文摘要:** Schema linking is a critical step in Text-to-SQL task, aiming to accurately
predict the table names and column names required for the SQL query based on
the given question. However, current fine-tuning approaches for schema linking
models employ a rote-learning paradigm, excessively optimizing for ground truth
schema linking outcomes while compromising reasoning ability. This limitation
arises because of the difficulty in acquiring a high-quality reasoning sample
for downstream tasks. To address this, we propose Schema-R1, a reasoning schema
linking model trained using reinforcement learning. Specifically, Schema-R1
consists of three key steps: constructing small batches of high-quality
reasoning samples, supervised fine-tuning for cold-start initialization, and
rule-based reinforcement learning training. The final results demonstrate that
our method effectively enhances the reasoning ability of the schema linking
model, achieving a 10\% improvement in filter accuracy compared to the existing
method. Our code is available at https://github.com/hongWin/Schema-R1/.

</details>


### [125] [Tracing LLM Reasoning Processes with Strategic Games: A Framework for Planning, Revision, and Resource-Constrained Decision Making](https://arxiv.org/abs/2506.12012)
*Xiaopeng Yuan, Xingjian Zhang, Ke Xu, Yifan Xu, Lijun Yu, Jindong Wang, Yushun Dong, Haohan Wang*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种新的评估框架，通过策略游戏来测试大型语言模型（LLMs）的计划、修订和资源限制下的决策能力，并引入了多个衡量指标。实验结果表明，ChatGPT-o3-mini在综合评分上表现最佳，而Qwen-Plus尽管修正风险率高但胜率较低。研究还发现频繁编辑并不总是带来更好的结果。


<details>
  <summary>更多</summary>
  
**动机:** 当前对大型语言模型的评价主要集中在最终结果上，而忽略了中间推理步骤的重要性，如规划、修订以及在资源约束下的决策过程。作者认为测量这些内部过程对于理解模型行为和提高可靠性至关重要。

**方法:** 作者提出了一个基于策略游戏的自然评估环境，这种环境是封闭的、规则明确的系统，具有清晰的状态、有限的资源和自动反馈机制。他们定义了一个框架，该框架沿着三个核心维度——计划、修订和资源受限决策制定——来评估LLM。为了实现这一点，他们定义了除胜率之外的其他度量标准，包括过度修正风险率、修正成功率、改进斜率和超预算比率。

**结果:** 通过对12个领先模型进行4320轮对抗性回合测试，ChatGPT-o3-mini取得了最高的综合得分，其胜率为74.7%，修正成功率为78.6%，改进斜率为0.041。相比之下，Qwen-Plus虽然拥有81.6%的过高修正风险率，但仅赢得了25.6%的比赛，这主要是由于资源使用过量。此外，研究观察到过度修正风险率与修正成功率之间存在负相关关系（皮尔森r=-0.51, p=0.093），表明更频繁地编辑并不一定能够改善结果。

**结论:** 研究结论强调了不仅要评估LLMs做出什么决定，还要考虑它们是如何达到这些决定的过程。提出的评估方法有助于更好地理解模型的行为模式，并为提高模型的可靠性和性能提供了新的视角。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Tracing+LLM+Reasoning+Processes+with+Strategic+Games%3A+A+Framework+for+Planning%2C+Revision%2C+and+Resource-Constrained+Decision+Making，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.12012，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.12012&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are increasingly used for tasks that require
complex reasoning. Most benchmarks focus on final outcomes but overlook the
intermediate reasoning steps - such as planning, revision, and decision making
under resource constraints. We argue that measuring these internal processes is
essential for understanding model behavior and improving reliability. We
propose using strategic games as a natural evaluation environment: closed,
rule-based systems with clear states, limited resources, and automatic
feedback. We introduce a framework that evaluates LLMs along three core
dimensions: planning, revision, and resource-constrained decision making. To
operationalize this, we define metrics beyond win rate, including
overcorrection risk rate, correction success rate, improvement slope, and
over-budget ratio. In 4320 adversarial rounds across 12 leading models,
ChatGPT-o3-mini achieves the top composite score, with a win rate of 74.7
percent, a correction success rate of 78.6 percent, and an improvement slope of
0.041. By contrast, Qwen-Plus, despite an overcorrection risk rate of 81.6
percent, wins only 25.6 percent of its matches - primarily due to excessive
resource use. We also observe a negative correlation between overcorrection
risk rate and correction success rate (Pearson r = -0.51, p = 0.093),
suggesting that more frequent edits do not always improve outcomes. Our
findings highlight the value of assessing not only what LLMs decide but how
they arrive at those decisions

</details>


### [126] [Evaluation is All You Need: Strategic Overclaiming of LLM Reasoning Capabilities Through Evaluation Design](https://arxiv.org/abs/2506.04734)
*Lin Sun, Weihong Lin, Jinzhu Wu, Yongfu Zhu, Xiaoqi Jian, Guangxiang Zhao, Change Jia, Linglin Zhang, Sai-er Hu, Yuhan Wu, Xiangzheng Zhang*

**主要类别:** cs.AI

**AI概要:** 研究发现Deepseek-R1-Distill系列推理模型的基准评估结果受多种因素影响而波动，提出需要建立更严格的模型性能评估范式。


<details>
  <summary>更多</summary>
  
**动机:** 观察到基于Deepseek-R1-Distill系列的开源推理模型以及QwQ-32B模型在不同评估条件下的表现存在显著差异，导致它们所声称的性能提升难以被可靠地复现。

**方法:** 通过实证评估分析了Deepseek-R1-Distill系列模型的表现，并指出当前模型性能评价存在的问题。

**结果:** 发现了即使是细微的评估条件变化也会导致这些模型评估结果的大幅变动。

**结论:** 为了确保模型性能改进的可信度，研究人员建议制定一个更加严格和一致的模型性能评估框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Evaluation+is+All+You+Need%3A+Strategic+Overclaiming+of+LLM+Reasoning+Capabilities+Through+Evaluation+Design，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.04734，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.04734&send_immediately=true&force_search=false)

**原文摘要:** Reasoning models represented by the Deepseek-R1-Distill series have been
widely adopted by the open-source community due to their strong performance in
mathematics, science, programming, and other domains. However, our study
reveals that their benchmark evaluation results are subject to significant
fluctuations caused by various factors. Subtle differences in evaluation
conditions can lead to substantial variations in results. Similar phenomena are
observed in other open-source inference models fine-tuned based on the
Deepseek-R1-Distill series, as well as in the QwQ-32B model, making their
claimed performance improvements difficult to reproduce reliably. Therefore, we
advocate for the establishment of a more rigorous paradigm for model
performance evaluation and present our empirical assessments of the
Deepseek-R1-Distill series models.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [127] [A Framework for Non-Linear Attention via Modern Hopfield Networks](https://arxiv.org/abs/2506.11043)
*Ahmed Farooq*

**主要类别:** stat.ML

**AI概要:** 本文提出了一个能量函数，将现代Hopfield网络与Vaswani等人提出的注意力机制相统一。这个能量景观的最小值形成了'上下文井'，代表了标记之间的稳定关系配置。非线性注意力机制通过改进模型对复杂关系的理解来提高变压器模型的能力、效率和性能。


<details>
  <summary>更多</summary>
  
**动机:** 作者旨在通过提出一种新的能量函数方法，将现代Hopfield网络（MNH）的概念与Vaswani等人引入的注意力机制相结合，以期改善转换器模型对于序列建模任务的表现。

**方法:** 研究者们定义了一个能量景观，该景观中的梯度对应于注意力计算。他们还探讨了非线性注意力机制如何帮助增强基于转换器模型（如BERT等）在处理复杂关系时的理解能力。

**结果:** 通过引入非线性头到基于转换器的模型中，能够更好地理解和学习表示，从而提高整体效率和表现。

**结论:** 论文提供了一种新视角，即通过非线性注意力机制增强转换器模型的能力，为序列建模任务提供了更有效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Framework+for+Non-Linear+Attention+via+Modern+Hopfield+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11043，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11043&send_immediately=true&force_search=false)

**原文摘要:** In this work we propose an energy functional along the lines of Modern
Hopfield Networks (MNH), the stationary points of which correspond to the
attention due to Vaswani et al. [12], thus unifying both frameworks. The minima
of this landscape form "context wells" - stable configurations that encapsulate
the contextual relationships among tokens. A compelling picture emerges: across
$n$ token embeddings an energy landscape is defined whose gradient corresponds
to the attention computation. Non-linear attention mechanisms offer a means to
enhance the capabilities of transformer models for various sequence modeling
tasks by improving the model's understanding of complex relationships, learning
of representations, and overall efficiency and performance. A rough analogy can
be seen via cubic splines which offer a richer representation of non-linear
data where a simpler linear model may be inadequate. This approach can be used
for the introduction of non-linear heads in transformer based models such as
BERT, [6], etc.

</details>


### [128] [Collaborative Prediction: To Join or To Disjoin Datasets](https://arxiv.org/abs/2506.11271)
*Kyung Rok Kim, Yansong Wang, Xiaocheng Li, Guanting Chen*

**主要类别:** stat.ML

**AI概要:** 本文研究了如何通过选择合适的高质量数据集来最小化预测模型的总体损失，并提出了一种具有理论保证的实际算法，该算法在标准线性回归和更广泛的机器学习应用中都表现出有效性。


<details>
  <summary>更多</summary>
  
**动机:** 随着生成式人工智能的兴起，选择高质量的数据集以改进机器学习模型的需求日益受到关注。然而，对于即使是简单的预测模型来说，这一主题的部分内容仍然未被充分探索。

**方法:** 作者们研究了来自不同来源的数据集何时可以有效地合并以增强预测模型的表现，并且提出了一个基于oracle不等式和数据驱动估计器的实际算法，该算法能够以高概率减少总体损失。

**结果:** 数值实验表明所提出的算法在标准线性回归以及更广泛的机器学习应用中是有效的。

**结论:** 本文提出了一种新的算法，它能够选取合适的数据集并以较高的概率降低预测模型的总体损失，这为提高机器学习模型性能提供了一种实用的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Collaborative+Prediction%3A+To+Join+or+To+Disjoin+Datasets，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11271，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11271&send_immediately=true&force_search=false)

**原文摘要:** With the recent rise of generative Artificial Intelligence (AI), the need of
selecting high-quality dataset to improve machine learning models has garnered
increasing attention. However, some part of this topic remains underexplored,
even for simple prediction models. In this work, we study the problem of
developing practical algorithms that select appropriate dataset to minimize
population loss of our prediction model with high probability. Broadly
speaking, we investigate when datasets from different sources can be
effectively merged to enhance the predictive model's performance, and propose a
practical algorithm with theoretical guarantees. By leveraging an oracle
inequality and data-driven estimators, the algorithm reduces population loss
with high probability. Numerical experiments demonstrate its effectiveness in
both standard linear regression and broader machine learning applications. Code
is available at https://github.com/kkrokii/collaborative_prediction.

</details>


### [129] [Fast Bayesian Optimization of Function Networks with Partial Evaluations](https://arxiv.org/abs/2506.11456)
*Poompol Buathong, Peter I. Frazier*

**主要类别:** stat.ML

**AI概要:** 本文提出了一种加速的p-KGFN算法，通过一次廉价的全局蒙特卡洛模拟为网络中的每个节点生成特定候选输入，从而减少了计算开销，同时在查询效率上仅有适度损失。实验表明该方法保持了有竞争力的查询效率，并且相比原始p-KGFN算法速度提高了最多16倍。


<details>
  <summary>更多</summary>
  
**动机:** 在实际应用中，例如制造和药物发现，涉及到可以独立评估并产生不同成本的功能网络。最近的一个BOFN变体p-KGFN利用了这种结构，实现了成本意识的部分评估，但每次迭代选择评估位置时需要优化一个嵌套的基于蒙特卡洛的获取函数，这导致了大量的计算开销。

**方法:** 提出了一种加速的p-KGFN算法，该算法通过执行一次低成本的全局蒙特卡洛模拟来为网络中的每个节点生成特定于节点的候选输入，以此来减少计算负担。

**结果:** 数值实验证明，所提出的方法能够在保持具有竞争力的查询效率的同时，相较于原有的p-KGFN算法实现了最高达16倍的速度提升。

**结论:** 加速的p-KGFN算法成功地降低了计算开销，虽然在查询效率方面略有牺牲，但在实际应用场景中显著提升了优化过程的速度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fast+Bayesian+Optimization+of+Function+Networks+with+Partial+Evaluations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11456，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11456&send_immediately=true&force_search=false)

**原文摘要:** Bayesian optimization of function networks (BOFN) is a framework for
optimizing expensive-to-evaluate objective functions structured as networks,
where some nodes' outputs serve as inputs for others. Many real-world
applications, such as manufacturing and drug discovery, involve function
networks with additional properties - nodes that can be evaluated independently
and incur varying costs. A recent BOFN variant, p-KGFN, leverages this
structure and enables cost-aware partial evaluations, selectively querying only
a subset of nodes at each iteration. p-KGFN reduces the number of expensive
objective function evaluations needed but has a large computational overhead:
choosing where to evaluate requires optimizing a nested Monte Carlo-based
acquisition function for each node in the network. To address this, we propose
an accelerated p-KGFN algorithm that reduces computational overhead with only a
modest loss in query efficiency. Key to our approach is generation of
node-specific candidate inputs for each node in the network via one inexpensive
global Monte Carlo simulation. Numerical experiments show that our method
maintains competitive query efficiency while achieving up to a 16x speedup over
the original p-KGFN algorithm.

</details>


### [130] [On the performance of multi-fidelity and reduced-dimensional neural emulators for inference of physiologic boundary conditions](https://arxiv.org/abs/2506.11683)
*Chloe H. Choi, Andrea Zanoni, Daniele E. Schiavazzi, Alison L. Marsden*

**主要类别:** stat.ML

**AI概要:** 本文研究了心血管建模中的贝叶斯参数估计问题，通过利用低保真近似来减少从后验分布采样的计算成本，并验证了五种不同方法在分析测试案例和两个心血管实例上的准确性和计算成本。


<details>
  <summary>更多</summary>
  
**动机:** 解决心血管建模中的反问题具有挑战性，因为运行高保真模拟的计算成本很高。为了降低从后验分布中抽样的计算成本，需要探索不同的方法。

**方法:** 文中提出了三种方法：1. 为高保真模拟本身构建一个代理模型；2. 构建一个代理模型来表示高保真与低保真模型之间的差异；3. 将高保真与代理模型之间的差异视为随机噪声，并使用归一化流估计其分布。

**结果:** 文章验证了五种不同方法在分析测试案例上的表现，并且在两个复杂度递增的心血管实例上进行了演示，包括集总参数温克塞尔模型和患者特异性三维解剖模型。

**结论:** 通过将这些方法应用于实际心血管建模问题，可以显著降低贝叶斯参数估计的计算成本，同时保持一定的准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+performance+of+multi-fidelity+and+reduced-dimensional+neural+emulators+for+inference+of+physiologic+boundary+conditions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11683，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11683&send_immediately=true&force_search=false)

**原文摘要:** Solving inverse problems in cardiovascular modeling is particularly
challenging due to the high computational cost of running high-fidelity
simulations. In this work, we focus on Bayesian parameter estimation and
explore different methods to reduce the computational cost of sampling from the
posterior distribution by leveraging low-fidelity approximations. A common
approach is to construct a surrogate model for the high-fidelity simulation
itself. Another is to build a surrogate for the discrepancy between high- and
low-fidelity models. This discrepancy, which is often easier to approximate, is
modeled with either a fully connected neural network or a nonlinear
dimensionality reduction technique that enables surrogate construction in a
lower-dimensional space. A third possible approach is to treat the discrepancy
between the high-fidelity and surrogate models as random noise and estimate its
distribution using normalizing flows. This allows us to incorporate the
approximation error into the Bayesian inverse problem by modifying the
likelihood function. We validate five different methods which are variations of
the above on analytical test cases by comparing them to posterior distributions
derived solely from high-fidelity models, assessing both accuracy and
computational cost. Finally, we demonstrate our approaches on two
cardiovascular examples of increasing complexity: a lumped-parameter Windkessel
model and a patient-specific three-dimensional anatomy.

</details>


### [131] [Using Deep Operators to Create Spatio-temporal Surrogates for Dynamical Systems under Uncertainty](https://arxiv.org/abs/2506.11761)
*Jichuan Tang, Patrick T. Brewick, Ryan G. McClarren, Christopher Sweet*

**主要类别:** stat.ML

**AI概要:** 本文提出了一种新的深度算子网络变体——全领域扩展DeepONet（FExD），用于作为时空代理模型，为动力系统提供多输出响应预测。该模型通过增强分支网络的表现力和扩展主干网络的预测能力，有效学习了多个自由度上的完整解算子。实验结果表明，FExD在精度和计算效率方面均优于传统的DeepONet及改进的时空扩展DeepONet。


<details>
  <summary>更多</summary>
  
**动机:** 尽管SciML方法在处理个体时间序列的响应预测问题上取得了显著进展，但构建一个完整的时空代理模型仍然是个挑战。本文旨在解决这一难题，特别是在土木基础设施应用中对动态系统的多输出响应预测需求。

**方法:** 提出了一种名为全领域扩展DeepONet (FExD) 的新变体，它通过提高分支网络的表现能力和扩大主干网络的预测范围来学习跨多个自由度的完整解决方案操作符。此方法被用来同时捕捉受随机地面运动影响的斜拉桥测试模型中多个传感器位置的动力学特性。

**结果:** FExD模型能够比普通的DeepONet和修改后的时空扩展DeepONet提供更高的准确性和计算效率。

**结论:** 所提出的FExD模型展示了在结构动力学应用中的操作员学习方面的重大进步，不仅提高了预测准确性，还增强了计算效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Using+Deep+Operators+to+Create+Spatio-temporal+Surrogates+for+Dynamical+Systems+under+Uncertainty，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11761，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11761&send_immediately=true&force_search=false)

**原文摘要:** Spatio-temporal data, which consists of responses or measurements gathered at
different times and positions, is ubiquitous across diverse applications of
civil infrastructure. While SciML methods have made significant progress in
tackling the issue of response prediction for individual time histories,
creating a full spatial-temporal surrogate remains a challenge. This study
proposes a novel variant of deep operator networks (DeepONets), namely the
full-field Extended DeepONet (FExD), to serve as a spatial-temporal surrogate
that provides multi-output response predictions for dynamical systems. The
proposed FExD surrogate model effectively learns the full solution operator
across multiple degrees of freedom by enhancing the expressiveness of the
branch network and expanding the predictive capabilities of the trunk network.
The proposed FExD surrogate is deployed to simultaneously capture the dynamics
at several sensing locations along a testbed model of a cable-stayed bridge
subjected to stochastic ground motions. The ensuing response predictions from
the FExD are comprehensively compared against both a vanilla DeepONet and a
modified spatio-temporal Extended DeepONet. The results demonstrate the
proposed FExD can achieve both superior accuracy and computational efficiency,
representing a significant advancement in operator learning for structural
dynamics applications.

</details>


### [132] [Bayesian Optimization with Inexact Acquisition: Is Random Grid Search Sufficient?](https://arxiv.org/abs/2506.11831)
*Hwanwoo Kim, Chong Liu, Yuxin Chen*

**主要类别:** stat.ML

**AI概要:** 本文探讨了贝叶斯优化中获取函数的不精确最大化对累积遗憾的影响，证明了在一定条件下，不精确的贝叶斯优化算法仍能实现次线性累积遗憾，并提出随机网格搜索作为有效的解决方法。


<details>
  <summary>更多</summary>
  
**动机:** 现实情况中，准确地最大化获取函数通常是难以处理且计算成本高的。因此，研究者们想要了解获取函数的不精确解如何影响贝叶斯优化的表现。

**方法:** 通过定义一个获取解不准确性度量，研究者建立了不需要准确求解获取函数最大化的GP-UCB和GP-TS的累积遗憾界限。基于这些结果，提出了随机网格搜索作为一个有效且计算效率高的获取函数解算器。

**结果:** 研究表明，在积累不准确性满足适当条件的情况下，不精确的贝叶斯优化算法可以达到次线性的累积遗憾。

**结论:** 即使使用不精确的最大化器，贝叶斯优化仍然能够保持良好的性能。随机网格搜索被证实为一种既有效又高效的获取函数解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bayesian+Optimization+with+Inexact+Acquisition%3A+Is+Random+Grid+Search+Sufficient%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11831，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11831&send_immediately=true&force_search=false)

**原文摘要:** Bayesian optimization (BO) is a widely used iterative algorithm for
optimizing black-box functions. Each iteration requires maximizing an
acquisition function, such as the upper confidence bound (UCB) or a sample path
from the Gaussian process (GP) posterior, as in Thompson sampling (TS).
However, finding an exact solution to these maximization problems is often
intractable and computationally expensive. Reflecting such realistic
situations, in this paper, we delve into the effect of inexact maximizers of
the acquisition functions. Defining a measure of inaccuracy in acquisition
solutions, we establish cumulative regret bounds for both GP-UCB and GP-TS
without requiring exact solutions of acquisition function maximization. Our
results show that under appropriate conditions on accumulated inaccuracy,
inexact BO algorithms can still achieve sublinear cumulative regret. Motivated
by such findings, we provide both theoretical justification and numerical
validation for random grid search as an effective and computationally efficient
acquisition function solver.

</details>


### [133] [Learning Overspecified Gaussian Mixtures Exponentially Fast with the EM Algorithm](https://arxiv.org/abs/2506.11850)
*Zhenisbek Assylbekov, Alan Legg, Artur Pak*

**主要类别:** stat.ML

**AI概要:** 本文研究了当应用于过指定的高斯混合模型时EM算法的收敛性质，证明了在满足一定条件下，总体EM算法以指数速度收敛于KL距离，并且提供了有限样本情况下的统计收敛保证。实验结果支持了理论发现。


<details>
  <summary>更多</summary>
  
**动机:** 探讨EM算法在过指定高斯混合模型（即拟合模型中的成分数量超过真实分布中的成分数量）中的收敛特性，尤其是在成分均值位于正则单纯形顶点和混合权重满足非退化条件的结构配置下。

**方法:** 利用负对数似然函数在最优解附近的强凸性，以及Polyak-Łojasiewicz不等式来建立ε精度近似可达到性。此外，还在有限样本设定中导出了显式的统计收敛保证。

**结果:** 证明了在给定结构配置下，总体EM算法关于KL距离呈指数快速收敛，并且在O(log(1/ε))迭代次数内可以达到ε精度近似的解。同时，数值实验验证了理论分析的结果。

**结论:** 这项工作不仅加深了对过指定设置下EM行为的理解，还为高维聚类和密度估计任务中的初始化策略和模型设计提供了实用见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Overspecified+Gaussian+Mixtures+Exponentially+Fast+with+the+EM+Algorithm，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11850，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11850&send_immediately=true&force_search=false)

**原文摘要:** We investigate the convergence properties of the EM algorithm when applied to
overspecified Gaussian mixture models -- that is, when the number of components
in the fitted model exceeds that of the true underlying distribution. Focusing
on a structured configuration where the component means are positioned at the
vertices of a regular simplex and the mixture weights satisfy a non-degeneracy
condition, we demonstrate that the population EM algorithm converges
exponentially fast in terms of the Kullback-Leibler (KL) distance. Our analysis
leverages the strong convexity of the negative log-likelihood function in a
neighborhood around the optimum and utilizes the Polyak-{\L}ojasiewicz
inequality to establish that an $\epsilon$-accurate approximation is achievable
in $O(\log(1/\epsilon))$ iterations. Furthermore, we extend these results to a
finite-sample setting by deriving explicit statistical convergence guarantees.
Numerical experiments on synthetic datasets corroborate our theoretical
findings, highlighting the dramatic acceleration in convergence compared to
conventional sublinear rates. This work not only deepens the understanding of
EM's behavior in overspecified settings but also offers practical insights into
initialization strategies and model design for high-dimensional clustering and
density estimation tasks.

</details>


### [134] [How do Probabilistic Graphical Models and Graph Neural Networks Look at Network Data?](https://arxiv.org/abs/2506.11869)
*Michela Lapenna, Caterina De Bacco*

**主要类别:** stat.ML

**AI概要:** 本文比较了概率图模型(PGMs)和图神经网络(GNNs)在处理网络数据集时的表现，特别是在链接预测任务中。研究发现，在低维度或噪声特征以及异质性增加的情况下，PGMs比GNNs表现得更好。此外还对比了两者的计算复杂度和可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于探讨概率图模型(PGMs)与图神经网络(GNNs)这两种方法在捕捉网络化数据集中信息方面的能力差异。

**方法:** 通过解决一个链接预测任务来进行研究，并且进行了三个主要实验，分别关注PGMs和GNNs如何处理输入特征、它们对噪声特征的鲁棒性以及随着图的异质性增加时的表现。

**结果:** 结果表明，当输入特征为低维或含噪声时，PGMs优于GNNs；并且随着图的异质性增加，PGMs也显示出更强的鲁棒性。

**结论:** 除了预测任务之外，文章还从计算复杂性和可解释性的角度对比了两种框架，指出PGMs在某些情况下可能比GNNs更适合处理图结构数据。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+do+Probabilistic+Graphical+Models+and+Graph+Neural+Networks+Look+at+Network+Data%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11869，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11869&send_immediately=true&force_search=false)

**原文摘要:** Graphs are a powerful data structure for representing relational data and are
widely used to describe complex real-world systems. Probabilistic Graphical
Models (PGMs) and Graph Neural Networks (GNNs) can both leverage
graph-structured data, but their inherent functioning is different. The
question is how do they compare in capturing the information contained in
networked datasets? We address this objective by solving a link prediction task
and we conduct three main experiments, on both synthetic and real networks: one
focuses on how PGMs and GNNs handle input features, while the other two
investigate their robustness to noisy features and increasing heterophily of
the graph. PGMs do not necessarily require features on nodes, while GNNs cannot
exploit the network edges alone, and the choice of input features matters. We
find that GNNs are outperformed by PGMs when input features are low-dimensional
or noisy, mimicking many real scenarios where node attributes might be scalar
or noisy. Then, we find that PGMs are more robust than GNNs when the
heterophily of the graph is increased. Finally, to assess performance beyond
prediction tasks, we also compare the two frameworks in terms of their
computational complexity and interpretability.

</details>


### [135] [Spectral Estimation with Free Decompression](https://arxiv.org/abs/2506.11994)
*Siavash Ameli, Chris van der Heide, Liam Hodgkinson, Michael W. Mahoney*

**主要类别:** stat.ML

**AI概要:** 本文提出了一种名为'自由解压'的新方法，通过小子矩阵的实证谱密度来推断非常大（难以直接处理）矩阵的特征谱。


<details>
  <summary>更多</summary>
  
**动机:** 随着数据集规模的增长，协方差和核矩阵变得越来越大，直接形成这些矩阵变得不切实际或不可能。在分布式学习等场景下，可能只能访问原始矩阵的很小一部分子矩阵，并且无法获得完整的矩阵-向量乘积。因此需要一种新的方法来估计这些‘难以触及’矩阵的谱。

**方法:** 基于自由概率论的原则，作者引入了一种新的“自由解压”方法，用于从可获取的小子矩阵的实证谱密度外推到估计非常大的、无法直接形成的矩阵的特征谱。

**结果:** 通过一系列示例展示了该方法的有效性，包括与随机矩阵理论中的已知极限分布进行比较，以及应用于真实世界数据集的子矩阵，其结果与全矩阵的经验特征谱相匹配。

**结论:** 提出的方法提供了一种有效的手段，可以从未完全形成的大型矩阵中提取关键信息，如特征值谱，从而支持机器学习应用中的重要计算任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Spectral+Estimation+with+Free+Decompression，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2506.11994，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2506.11994&send_immediately=true&force_search=false)

**原文摘要:** Computing eigenvalues of very large matrices is a critical task in many
machine learning applications, including the evaluation of log-determinants,
the trace of matrix functions, and other important metrics. As datasets
continue to grow in scale, the corresponding covariance and kernel matrices
become increasingly large, often reaching magnitudes that make their direct
formation impractical or impossible. Existing techniques typically rely on
matrix-vector products, which can provide efficient approximations, if the
matrix spectrum behaves well. However, in settings like distributed learning,
or when the matrix is defined only indirectly, access to the full data set can
be restricted to only very small sub-matrices of the original matrix. In these
cases, the matrix of nominal interest is not even available as an implicit
operator, meaning that even matrix-vector products may not be available. In
such settings, the matrix is "impalpable," in the sense that we have access to
only masked snapshots of it. We draw on principles from free probability theory
to introduce a novel method of "free decompression" to estimate the spectrum of
such matrices. Our method can be used to extrapolate from the empirical
spectral densities of small submatrices to infer the eigenspectrum of extremely
large (impalpable) matrices (that we cannot form or even evaluate with full
matrix-vector products). We demonstrate the effectiveness of this approach
through a series of examples, comparing its performance against known limiting
distributions from random matrix theory in synthetic settings, as well as
applying it to submatrices of real-world datasets, matching them with their
full empirical eigenspectra.

</details>
