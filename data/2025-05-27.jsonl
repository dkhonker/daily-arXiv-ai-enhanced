{"id": "2505.17133", "pdf": "https://arxiv.org/pdf/2505.17133", "abs": "https://arxiv.org/abs/2505.17133", "authors": ["Shuai Wang", "Song Jiang", "Yizhou Sun", "Judea Pearl", "Ang Li"], "title": "Learning Probabilities of Causation from Finite Population Data", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2502.08858", "summary": "Probabilities of causation play a crucial role in modern decision-making.\nThis paper addresses the challenge of predicting probabilities of causation for\nsubpopulations with \\textbf{insufficient} data using machine learning models.\nTian and Pearl first defined and derived tight bounds for three fundamental\nprobabilities of causation: the probability of necessity and sufficiency (PNS),\nthe probability of sufficiency (PS), and the probability of necessity (PN).\nHowever, estimating these probabilities requires both experimental and\nobservational distributions specific to each subpopulation, which are often\nunavailable or impractical to obtain with limited population-level data.\nTherefore, for most subgroups, the amount of data they have is not enough to\nguarantee the accuracy of their probabilities. Hence, to estimate these\nprobabilities for subpopulations with \\textbf{insufficient} data, we propose\nusing machine learning models that draw insights from subpopulations with\nsufficient data. Our evaluation of multiple machine learning models indicates\nthat, given the population-level data and an appropriate choice of machine\nlearning model and activation function, PNS can be effectively predicted.\nThrough simulation studies on multiple Structured Causal Models (SCMs), we show\nthat our multilayer perceptron (MLP) model with the Mish activation function\nachieves a mean absolute error (MAE) of approximately $0.02$ in predicting PNS\nfor $32,768$ subpopulations across most SCMs using data from only $2,000$\nsubpopulations with known PNS values."}
{"id": "2505.17204", "pdf": "https://arxiv.org/pdf/2505.17204", "abs": "https://arxiv.org/abs/2505.17204", "authors": ["Pilhwa Lee", "Jayshawn Cooper"], "title": "Liouville PDE-based sliced-Wasserstein flow for fair regression", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST", "stat.CO", "stat.TH"], "comment": "11 pages, 3 figures", "summary": "The sliced Wasserstein flow (SWF), a nonparametric and implicit generative\ngradient flow, is applied to fair regression. We have improved the SWF in a few\naspects. First, the stochastic diffusive term from the Fokker-Planck\nequation-based Monte Carlo is transformed to Liouville partial differential\nequation (PDE)-based transport with density estimation, however, without the\ndiffusive term. Now, the computation of the Wasserstein barycenter is\napproximated by the SWF barycenter with the prescription of Kantorovich\npotentials for the induced gradient flow to generate its samples. These two\nefforts improve the convergence in training and testing SWF and SWF barycenters\nwith reduced variance. Applying the generative SWF barycenter for fair\nregression demonstrates competent profiles in the accuracy-fairness Pareto\ncurves."}
{"id": "2505.17283", "pdf": "https://arxiv.org/pdf/2505.17283", "abs": "https://arxiv.org/abs/2505.17283", "authors": ["Prateek Jaiswal", "Esmaeil Keyvanshokooh", "Junyu Cao"], "title": "Deconfounded Warm-Start Thompson Sampling with Applications to Precision Medicine", "categories": ["stat.ML", "cs.LG", "math.OC", "stat.AP"], "comment": null, "summary": "Randomized clinical trials often require large patient cohorts before drawing\ndefinitive conclusions, yet abundant observational data from parallel studies\nremains underutilized due to confounding and hidden biases. To bridge this gap,\nwe propose Deconfounded Warm-Start Thompson Sampling (DWTS), a practical\napproach that leverages a Doubly Debiased LASSO (DDL) procedure to identify a\nsparse set of reliable measured covariates and combines them with key hidden\ncovariates to form a reduced context. By initializing Thompson Sampling (LinTS)\npriors with DDL-estimated means and variances on these measured features --\nwhile keeping uninformative priors on hidden features -- DWTS effectively\nharnesses confounded observational data to kick-start adaptive clinical trials.\nEvaluated on both a purely synthetic environment and a virtual environment\ncreated using real cardiovascular risk dataset, DWTS consistently achieves\nlower cumulative regret than standard LinTS, showing how offline causal\ninsights from observational data can improve trial efficiency and support more\npersonalized treatment decisions."}
{"id": "2505.17288", "pdf": "https://arxiv.org/pdf/2505.17288", "abs": "https://arxiv.org/abs/2505.17288", "authors": ["Seamus Somerstep", "Vinod Raman", "Unique Subedi", "Yuekai Sun"], "title": "Learning to Choose or Choosing to Learn: Best-of-N vs. Supervised Fine-Tuning for Bit String Generation", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Using the bit string generation problem as a case study, we theoretically\ncompare two standard methods for adapting large language models to new tasks.\nThe first, referred to as supervised fine-tuning, involves training a new next\ntoken predictor on good generations. The second method, Best-of-N, trains a\nreward model to select good responses from a collection generated by an\nunaltered base model. If the learning setting is realizable, we find that\nsupervised fine-tuning outperforms BoN through a better dependence on the\nresponse length in its rate of convergence. If realizability fails, then\ndepending on the failure mode, BoN can enjoy a better rate of convergence in\neither n or a rate of convergence with better dependence on the response\nlength."}
{"id": "2505.17040", "pdf": "https://arxiv.org/pdf/2505.17040", "abs": "https://arxiv.org/abs/2505.17040", "authors": ["Yun-Da Tsai"], "title": "Generalizing Large Language Model Usability Across Resource-Constrained", "categories": ["cs.LG", "cs.CL"], "comment": "Doctoral disstertation", "summary": "Large Language Models (LLMs) have achieved remarkable success across a wide\nrange of natural language tasks, and recent efforts have sought to extend their\ncapabilities to multimodal domains and resource-constrained environments.\nHowever, existing approaches often rely on costly supervised fine-tuning or\nassume fixed training conditions, limiting their generalization when facing\nunseen modalities, limited data, or restricted compute resources. This\ndissertation presents a systematic study toward generalizing LLM usability\nunder real-world constraints. First, it introduces a robust text-centric\nalignment framework that enables LLMs to seamlessly integrate diverse\nmodalities-including text, images, tables, and any modalities - via natural\nlanguage interfaces. This approach supports in-context adaptation to unseen or\ndynamically changing modalities without requiring retraining. To enhance\nrobustness against noisy and missing modalities, an adversarial prompting\ntechnique is proposed, generating semantically challenging perturbations at the\nprompt level to stress-test model reliability. Beyond multimodal setting, the\ndissertation investigates inference-time optimization strategies for LLMs,\nleveraging prompt search and uncertainty quantification to improve performance\nwithout additional model training. This perspective offers an efficient\nalternative to scaling model parameters or retraining from scratch.\nAdditionally, the work addresses low-resource domains such as Verilog code\ngeneration by designing correct-by-construction synthetic data pipelines and\nlogic-enhanced reasoning models, achieving state-of-the-art performance with\nminimal data. Together, these contributions form a unified effort to enhance\nthe adaptability, scalability, and efficiency of large language models under\npractical constraints."}
{"id": "2505.17024", "pdf": "https://arxiv.org/pdf/2505.17024", "abs": "https://arxiv.org/abs/2505.17024", "authors": ["Eli Sennesh", "Maxwell Ramstead"], "title": "An Affective-Taxis Hypothesis for Alignment and Interpretability", "categories": ["cs.AI", "q-bio.NC"], "comment": null, "summary": "AI alignment is a field of research that aims to develop methods to ensure\nthat agents always behave in a manner aligned with (i.e. consistently with) the\ngoals and values of their human operators, no matter their level of capability.\nThis paper proposes an affectivist approach to the alignment problem,\nre-framing the concepts of goals and values in terms of affective taxis, and\nexplaining the emergence of affective valence by appealing to recent work in\nevolutionary-developmental and computational neuroscience. We review the state\nof the art and, building on this work, we propose a computational model of\naffect based on taxis navigation. We discuss evidence in a tractable model\norganism that our model reflects aspects of biological taxis navigation. We\nconclude with a discussion of the role of affective taxis in AI alignment."}
{"id": "2505.17291", "pdf": "https://arxiv.org/pdf/2505.17291", "abs": "https://arxiv.org/abs/2505.17291", "authors": ["Linus Bleistein", "Aur√©lien Bellet", "Julie Josse"], "title": "Optimal Transport with Heterogeneously Missing Data", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "We consider the problem of solving the optimal transport problem between two\nempirical distributions with missing values. Our main assumption is that the\ndata is missing completely at random (MCAR), but we allow for heterogeneous\nmissingness probabilities across features and across the two distributions. As\na first contribution, we show that the Wasserstein distance between empirical\nGaussian distributions and linear Monge maps between arbitrary distributions\ncan be debiased without significantly affecting the sample complexity.\nSecondly, we show that entropic regularized optimal transport can be estimated\nefficiently and consistently using iterative singular value thresholding\n(ISVT). We propose a validation set-free hyperparameter selection strategy for\nISVT that leverages our estimator of the Bures-Wasserstein distance, which\ncould be of independent interest in general matrix completion problems.\nFinally, we validate our findings on a wide range of numerical applications."}
{"id": "2505.17138", "pdf": "https://arxiv.org/pdf/2505.17138", "abs": "https://arxiv.org/abs/2505.17138", "authors": ["Huanrong Liu", "Chunlin Tian", "Xuyang Wei", "Jiaheng Dai", "Qin Liu", "Tianqi Wei", "Qingbiao Li", "Li Li"], "title": "RAP: Runtime-Adaptive Pruning for LLM Inference", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) excel at language understanding and generation,\nbut their enormous computational and memory requirements hinder deployment.\nCompression offers a potential solution to mitigate these constraints. However,\nmost existing methods rely on fixed heuristics and thus fail to adapt to\nruntime memory variations or heterogeneous KV-cache demands arising from\ndiverse user requests. To address these limitations, we propose RAP, an elastic\npruning framework driven by reinforcement learning (RL) that dynamically\nadjusts compression strategies in a runtime-aware manner. Specifically, RAP\ndynamically tracks the evolving ratio between model parameters and KV-cache\nacross practical execution. Recognizing that FFNs house most parameters,\nwhereas parameter -light attention layers dominate KV-cache formation, the RL\nagent retains only those components that maximize utility within the current\nmemory budget, conditioned on instantaneous workload and device state.\nExtensive experiments results demonstrate that RAP outperforms state-of-the-art\nbaselines, marking the first time to jointly consider model weights and\nKV-cache on the fly."}
{"id": "2505.17214", "pdf": "https://arxiv.org/pdf/2505.17214", "abs": "https://arxiv.org/abs/2505.17214", "authors": ["Xiaochen Wang", "Yuan Zhong", "Lingwei Zhang", "Lisong Dai", "Ting Wang", "Fenglong Ma"], "title": "MEDMKG: Benchmarking Medical Knowledge Exploitation with Multimodal Knowledge Graph", "categories": ["cs.AI"], "comment": "Submitted to Neurips 2025", "summary": "Medical deep learning models depend heavily on domain-specific knowledge to\nperform well on knowledge-intensive clinical tasks. Prior work has primarily\nleveraged unimodal knowledge graphs, such as the Unified Medical Language\nSystem (UMLS), to enhance model performance. However, integrating multimodal\nmedical knowledge graphs remains largely underexplored, mainly due to the lack\nof resources linking imaging data with clinical concepts. To address this gap,\nwe propose MEDMKG, a Medical Multimodal Knowledge Graph that unifies visual and\ntextual medical information through a multi-stage construction pipeline. MEDMKG\nfuses the rich multimodal data from MIMIC-CXR with the structured clinical\nknowledge from UMLS, utilizing both rule-based tools and large language models\nfor accurate concept extraction and relationship modeling. To ensure graph\nquality and compactness, we introduce Neighbor-aware Filtering (NaF), a novel\nfiltering algorithm tailored for multimodal knowledge graphs. We evaluate\nMEDMKG across three tasks under two experimental settings, benchmarking\ntwenty-four baseline methods and four state-of-the-art vision-language\nbackbones on six datasets. Results show that MEDMKG not only improves\nperformance in downstream medical tasks but also offers a strong foundation for\ndeveloping adaptive and robust strategies for multimodal knowledge integration\nin medical artificial intelligence."}
{"id": "2505.17300", "pdf": "https://arxiv.org/pdf/2505.17300", "abs": "https://arxiv.org/abs/2505.17300", "authors": ["Selina Carter", "Arun K Kuchibhotla"], "title": "Statistical Inference for Online Algorithms", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "comment": "Although SGD is the most commonly mentioned method in machine\n  learning, our simulations show that the performance of SGD is highly\n  sensitive to the choice of tuning parameters of the algorithm. We could not\n  find a simple remedy that improves performance and also makes the asymptotic\n  properties manageable. We hope that our article acts as a word of caution to\n  anyone using online algorithms blindly", "summary": "Construction of confidence intervals and hypothesis tests for functionals\nbased on asymptotically normal estimators is a classical topic in statistical\ninference. The simplest and in many cases optimal inference procedure is the\nWald interval or the likelihood ratio test, both of which require an estimator\nand an estimate of the asymptotic variance of the estimator. Estimators\nobtained from online/sequential algorithms forces one to consider the\ncomputational aspects of the inference problem, i.e., one cannot access all of\nthe data as many times as needed. Several works on this topic explored the\nonline estimation of asymptotic variance. In this article, we propose\ncomputationally efficient, rate-optimal, and asymptotically valid confidence\nregions based on the output of online algorithms {\\em without} estimating the\nasymptotic variance. As a special case, this implies inference from any\nalgorithm that yields an asymptotically normal estimator. We focus our efforts\non stochastic gradient descent with Polyak averaging to understand the\npractical performance of the proposed method."}
{"id": "2505.17142", "pdf": "https://arxiv.org/pdf/2505.17142", "abs": "https://arxiv.org/abs/2505.17142", "authors": ["Jingyu Li", "Tiehua Zhang", "Jinze Wang", "Yi Zhang", "Yuhuan Li", "Yifan Zhao", "Zhishu Shen", "Jiannan Liu"], "title": "MetaSTH-Sleep: Towards Effective Few-Shot Sleep Stage Classification with Spatial-Temporal Hypergraph Enhanced Meta-Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate classification of sleep stages based on bio-signals is fundamental\nfor automatic sleep stage annotation. Traditionally, this task relies on\nexperienced clinicians to manually annotate data, a process that is both\ntime-consuming and labor-intensive. In recent years, deep learning methods have\nshown promise in automating this task. However, three major challenges remain:\n(1) deep learning models typically require large-scale labeled datasets, making\nthem less effective in real-world settings where annotated data is limited; (2)\nsignificant inter-individual variability in bio-signals often results in\ninconsistent model performance when applied to new subjects, limiting\ngeneralization; and (3) existing approaches often overlook the high-order\nrelationships among bio-signals, failing to simultaneously capture signal\nheterogeneity and spatial-temporal dependencies. To address these issues, we\npropose MetaSTH-Sleep, a few-shot sleep stage classification framework based on\nspatial-temporal hypergraph enhanced meta-learning. Our approach enables rapid\nadaptation to new subjects using only a few labeled samples, while the\nhypergraph structure effectively models complex spatial interconnections and\ntemporal dynamics simultaneously in EEG signals. Experimental results\ndemonstrate that MetaSTH-Sleep achieves substantial performance improvements\nacross diverse subjects, offering valuable insights to support clinicians in\nsleep stage annotation."}
{"id": "2505.17218", "pdf": "https://arxiv.org/pdf/2505.17218", "abs": "https://arxiv.org/abs/2505.17218", "authors": ["Lianghuan Huang", "Shuo Li", "Sagnik Anupam", "Insup Lee", "Osbert Bastani"], "title": "Effective Reinforcement Learning for Reasoning in Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has emerged as a promising strategy for improving\nthe reasoning capabilities of language models (LMs) in domains such as\nmathematics and coding. However, most modern RL algorithms were designed to\ntarget robotics applications, which differ significantly from LM reasoning. We\nanalyze RL algorithm design decisions for LM reasoning, for both accuracy and\ncomputational efficiency, focusing on relatively small models due to\ncomputational constraints. Our findings are: (i) on-policy RL significantly\noutperforms supervised fine-tuning (SFT), (ii) PPO-based off-policy updates\nincrease accuracy instead of reduce variance, and (iii) removing KL divergence\ncan lead to more concise generations and higher accuracy. Furthermore, we find\nthat a key bottleneck to computational efficiency is that the optimal batch\nsizes for inference and backpropagation are different. We propose a novel\nalgorithm, DASH, that performs preemptive sampling (i.e., sample a large batch\nand accumulate gradient updates in small increments), and gradient filtering\n(i.e., drop samples with small advantage estimates). We show that DASH reduces\ntraining time by 83% compared to a standard implementation of GRPO without\nsacrificing accuracy. Our findings provide valuable insights on designing\neffective RL algorithms for LM reasoning."}
{"id": "2505.17308", "pdf": "https://arxiv.org/pdf/2505.17308", "abs": "https://arxiv.org/abs/2505.17308", "authors": ["Philipp Pilar", "Markus Heinonen", "Niklas Wahlstr√∂m"], "title": "Repulsive Ensembles for Bayesian Inference in Physics-informed Neural Networks", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Physics-informed neural networks (PINNs) have proven an effective tool for\nsolving differential equations, in particular when considering non-standard or\nill-posed settings. When inferring solutions and parameters of the differential\nequation from data, uncertainty estimates are preferable to point estimates, as\nthey give an idea about the accuracy of the solution. In this work, we consider\nthe inverse problem and employ repulsive ensembles of PINNs (RE-PINN) for\nobtaining such estimates. The repulsion is implemented by adding a particular\nrepulsive term to the loss function, which has the property that the ensemble\npredictions correspond to the true Bayesian posterior in the limit of infinite\nensemble members. Where possible, we compare the ensemble predictions to Monte\nCarlo baselines. Whereas the standard ensemble tends to collapse to\nmaximum-a-posteriori solutions, the repulsive ensemble produces significantly\nmore accurate uncertainty estimates and exhibits higher sample diversity."}
{"id": "2505.17150", "pdf": "https://arxiv.org/pdf/2505.17150", "abs": "https://arxiv.org/abs/2505.17150", "authors": ["Rembert Daems", "Manfred Opper", "Guillaume Crevecoeur", "Tolga Birdal"], "title": "Efficient Training of Neural SDEs Using Stochastic Optimal Control", "categories": ["cs.LG", "cs.AI", "math.PR"], "comment": "Published in the ESANN 2025 proceedings, European Symposium on\n  Artificial Neural Networks, Computational Intelligence and Machine Learning.\n  Bruges (Belgium) and online event, 23-25 April 2025", "summary": "We present a hierarchical, control theory inspired method for variational\ninference (VI) for neural stochastic differential equations (SDEs). While VI\nfor neural SDEs is a promising avenue for uncertainty-aware reasoning in\ntime-series, it is computationally challenging due to the iterative nature of\nmaximizing the ELBO. In this work, we propose to decompose the control term\ninto linear and residual non-linear components and derive an optimal control\nterm for linear SDEs, using stochastic optimal control. Modeling the non-linear\ncomponent by a neural network, we show how to efficiently train neural SDEs\nwithout sacrificing their expressive power. Since the linear part of the\ncontrol term is optimal and does not need to be learned, the training is\ninitialized at a lower cost and we observe faster convergence."}
{"id": "2505.17225", "pdf": "https://arxiv.org/pdf/2505.17225", "abs": "https://arxiv.org/abs/2505.17225", "authors": ["Doohyuk Jang", "Yoonjeon Kim", "Chanjae Park", "Hyun Ryu", "Eunho Yang"], "title": "Reasoning Model is Stubborn: Diagnosing Instruction Overriding in Reasoning Models", "categories": ["cs.AI"], "comment": null, "summary": "Large language models have demonstrated remarkable proficiency in long and\ncomplex reasoning tasks. However, they frequently exhibit a problematic\nreliance on familiar reasoning patterns, a phenomenon we term \\textit{reasoning\nrigidity}. Despite explicit instructions from users, these models often\noverride clearly stated conditions and default to habitual reasoning\ntrajectories, leading to incorrect conclusions. This behavior presents\nsignificant challenges, particularly in domains such as mathematics and logic\npuzzle, where precise adherence to specified constraints is critical. To\nsystematically investigate reasoning rigidity, a behavior largely unexplored in\nprior work, we introduce a expert-curated diagnostic set, \\dataset{}. Our\ndataset includes specially modified variants of existing mathematical\nbenchmarks, namely AIME and MATH500, as well as well-known puzzles deliberately\nredesigned to require deviation from familiar reasoning strategies. Using this\ndataset, we identify recurring contamination patterns that occur when models\ndefault to ingrained reasoning. Specifically, we categorize this contamination\ninto three distinctive modes: (i) Interpretation Overload, (ii) Input Distrust,\nand (iii) Partial Instruction Attention, each causing models to ignore or\ndistort provided instructions. We publicly release our diagnostic set to\nfacilitate future research on mitigating reasoning rigidity in language models."}
{"id": "2505.17506", "pdf": "https://arxiv.org/pdf/2505.17506", "abs": "https://arxiv.org/abs/2505.17506", "authors": ["Kihyuk Hong", "Ambuj Tewari"], "title": "Offline Constrained Reinforcement Learning under Partial Data Coverage", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study offline constrained reinforcement learning (RL) with general\nfunction approximation. We aim to learn a policy from a pre-collected dataset\nthat maximizes the expected discounted cumulative reward for a primary reward\nsignal while ensuring that expected discounted returns for multiple auxiliary\nreward signals are above predefined thresholds. Existing algorithms either\nrequire fully exploratory data, are computationally inefficient, or depend on\nan additional auxiliary function classes to obtain an $\\epsilon$-optimal policy\nwith sample complexity $O(\\epsilon^{-2})$. In this paper, we propose an\noracle-efficient primal-dual algorithm based on a linear programming (LP)\nformulation, achieving $O(\\epsilon^{-2})$ sample complexity under partial data\ncoverage. By introducing a realizability assumption, our approach ensures that\nall saddle points of the Lagrangian are optimal, removing the need for\nregularization that complicated prior analyses. Through Lagrangian\ndecomposition, our method extracts policies without requiring knowledge of the\ndata-generating distribution, enhancing practical applicability."}
{"id": "2505.17155", "pdf": "https://arxiv.org/pdf/2505.17155", "abs": "https://arxiv.org/abs/2505.17155", "authors": ["Weizhe Lin", "Xing Li", "Zhiyuan Yang", "Xiaojin Fu", "Hui-Ling Zhen", "Yaoyuan Wang", "Xianzhi Yu", "Wulong Liu", "Xiaosong Li", "Mingxuan Yuan"], "title": "TrimR: Verifier-based Training-Free Thinking Compression for Efficient Test-Time Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Reasoning Models (LRMs) demonstrate exceptional capability in tackling\ncomplex mathematical, logical, and coding tasks by leveraging extended\nChain-of-Thought (CoT) reasoning. Test-time scaling methods, such as prolonging\nCoT with explicit token-level exploration, can push LRMs' accuracy boundaries,\nbut they incur significant decoding overhead. A key inefficiency source is LRMs\noften generate redundant thinking CoTs, which demonstrate clear structured\noverthinking and underthinking patterns. Inspired by human cognitive reasoning\nprocesses and numerical optimization theories, we propose TrimR, a\nverifier-based, training-free, efficient framework for dynamic CoT compression\nto trim reasoning and enhance test-time scaling, explicitly tailored for\nproduction-level deployment. Our method employs a lightweight, pretrained,\ninstruction-tuned verifier to detect and truncate redundant intermediate\nthoughts of LRMs without any LRM or verifier fine-tuning. We present both the\ncore algorithm and asynchronous online system engineered for high-throughput\nindustrial applications. Empirical evaluations on Ascend NPUs and vLLM show\nthat our framework delivers substantial gains in inference efficiency under\nlarge-batch workloads. In particular, on the four MATH500, AIME24, AIME25, and\nGPQA benchmarks, the reasoning runtime of Pangu-R-38B, QwQ-32B, and\nDeepSeek-R1-Distill-Qwen-32B is improved by up to 70% with negligible impact on\naccuracy."}
{"id": "2505.17249", "pdf": "https://arxiv.org/pdf/2505.17249", "abs": "https://arxiv.org/abs/2505.17249", "authors": ["Yuran Sun", "Susu Xu", "Chenguang Wang", "Xilei Zhao"], "title": "Where You Go is Who You Are: Behavioral Theory-Guided LLMs for Inverse Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Big trajectory data hold great promise for human mobility analysis, but their\nutility is often constrained by the absence of critical traveler attributes,\nparticularly sociodemographic information. While prior studies have explored\npredicting such attributes from mobility patterns, they often overlooked\nunderlying cognitive mechanisms and exhibited low predictive accuracy. This\nstudy introduces SILIC, short for Sociodemographic Inference with LLM-guided\nInverse Reinforcement Learning (IRL) and Cognitive Chain Reasoning (CCR), a\ntheoretically grounded framework that leverages LLMs to infer sociodemographic\nattributes from observed mobility patterns by capturing latent behavioral\nintentions and reasoning through psychological constructs. Particularly, our\napproach explicitly follows the Theory of Planned Behavior (TPB), a\nfoundational behavioral framework in transportation research, to model\nindividuals' latent cognitive processes underlying travel decision-making. The\nLLMs further provide heuristic guidance to improve IRL reward function\ninitialization and update by addressing its ill-posedness and optimization\nchallenges arising from the vast and unstructured reward space. Evaluated in\nthe 2017 Puget Sound Regional Council Household Travel Survey, our method\nsubstantially outperforms state-of-the-art baselines and shows great promise\nfor enriching big trajectory data to support more behaviorally grounded\napplications in transportation planning and beyond."}
{"id": "2505.17717", "pdf": "https://arxiv.org/pdf/2505.17717", "abs": "https://arxiv.org/abs/2505.17717", "authors": ["Akira Tanimoto"], "title": "A Distributionally-Robust Framework for Nuisance in Causal Effect Estimation", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Causal inference requires evaluating models on balanced distributions between\ntreatment and control groups, while training data often exhibits imbalance due\nto historical decision-making policies. Most conventional statistical methods\naddress this distribution shift through inverse probability weighting (IPW),\nwhich requires estimating propensity scores as an intermediate step. These\nmethods face two key challenges: inaccurate propensity estimation and\ninstability from extreme weights. We decompose the generalization error to\nisolate these issues--propensity ambiguity and statistical instability--and\naddress them through an adversarial loss function. Our approach combines\ndistributionally robust optimization for handling propensity uncertainty with\nweight regularization based on weighted Rademacher complexity. Experiments on\nsynthetic and real-world datasets demonstrate consistent improvements over\nexisting methods."}
{"id": "2505.17163", "pdf": "https://arxiv.org/pdf/2505.17163", "abs": "https://arxiv.org/abs/2505.17163", "authors": ["Mingxin Huang", "Yongxin Shi", "Dezhi Peng", "Songxuan Lai", "Zecheng Xie", "Lianwen Jin"], "title": "OCR-Reasoning Benchmark: Unveiling the True Capabilities of MLLMs in Complex Text-Rich Image Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Recent advancements in multimodal slow-thinking systems have demonstrated\nremarkable performance across diverse visual reasoning tasks. However, their\ncapabilities in text-rich image reasoning tasks remain understudied due to the\nlack of a systematic benchmark. To address this gap, we propose OCR-Reasoning,\na comprehensive benchmark designed to systematically assess Multimodal Large\nLanguage Models on text-rich image reasoning tasks. The benchmark comprises\n1,069 human-annotated examples spanning 6 core reasoning abilities and 18\npractical reasoning tasks in text-rich visual scenarios. Furthermore, unlike\nother text-rich image understanding benchmarks that only annotate the final\nanswers, OCR-Reasoning also annotates the reasoning process simultaneously.\nWith the annotated reasoning process and the final answers, OCR-Reasoning\nevaluates not only the final answers generated by models but also their\nreasoning processes, enabling a holistic analysis of their problem-solving\nabilities. Leveraging this benchmark, we conducted a comprehensive evaluation\nof state-of-the-art MLLMs. Our results demonstrate the limitations of existing\nmethodologies. Notably, even state-of-the-art MLLMs exhibit substantial\ndifficulties, with none achieving accuracy surpassing 50\\% across\nOCR-Reasoning, indicating that the challenges of text-rich image reasoning are\nan urgent issue to be addressed. The benchmark and evaluation scripts are\navailable at https://github.com/SCUT-DLVCLab/OCR-Reasoning."}
{"id": "2505.17312", "pdf": "https://arxiv.org/pdf/2505.17312", "abs": "https://arxiv.org/abs/2505.17312", "authors": ["Xiangqi Wang", "Yue Huang", "Yanbo Wang", "Xiaonan Luo", "Kehan Guo", "Yujun Zhou", "Xiangliang Zhang"], "title": "AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "LLMs often need effective configurations, like temperature and reasoning\nsteps, to handle tasks requiring sophisticated reasoning and problem-solving,\nranging from joke generation to mathematical reasoning. Existing prompting\napproaches usually adopt general-purpose, fixed configurations that work 'well\nenough' across tasks but seldom achieve task-specific optimality. To address\nthis gap, we introduce AdaReasoner, an LLM-agnostic plugin designed for any LLM\nto automate adaptive reasoning configurations for tasks requiring different\ntypes of thinking. AdaReasoner is trained using a reinforcement learning (RL)\nframework, combining a factorized action space with a targeted exploration\nstrategy, along with a pretrained reward model to optimize the policy model for\nreasoning configurations with only a few-shot guide. AdaReasoner is backed by\ntheoretical guarantees and experiments of fast convergence and a sublinear\npolicy gap. Across six different LLMs and a variety of reasoning tasks, it\nconsistently outperforms standard baselines, preserves out-of-distribution\nrobustness, and yield gains on knowledge-intensive tasks through tailored\nprompts."}
{"id": "2505.17789", "pdf": "https://arxiv.org/pdf/2505.17789", "abs": "https://arxiv.org/abs/2505.17789", "authors": ["Florian Kalinke", "Shakeel Gavioli-Akilagun"], "title": "Optimal Online Change Detection via Random Fourier Features", "categories": ["stat.ML", "cs.LG", "68W27 (Primary) 62G10, 46E22 (Secondary)", "G.3; I.2.6"], "comment": null, "summary": "This article studies the problem of online non-parametric change point\ndetection in multivariate data streams. We approach the problem through the\nlens of kernel-based two-sample testing and introduce a sequential testing\nprocedure based on random Fourier features, running with logarithmic time\ncomplexity per observation and with overall logarithmic space complexity. The\nalgorithm has two advantages compared to the state of the art. First, our\napproach is genuinely online, and no access to training data known to be from\nthe pre-change distribution is necessary. Second, the algorithm does not\nrequire the user to specify a window parameter over which local tests are to be\ncalculated. We prove strong theoretical guarantees on the algorithm's\nperformance, including information-theoretic bounds demonstrating that the\ndetection delay is optimal in the minimax sense. Numerical studies on real and\nsynthetic data show that our algorithm is competitive with respect to the state\nof the art."}
{"id": "2505.17190", "pdf": "https://arxiv.org/pdf/2505.17190", "abs": "https://arxiv.org/abs/2505.17190", "authors": ["Baran Hashemi", "Kurt Pasque", "Chris Teska", "Ruriko Yoshida"], "title": "Tropical Attention: Neural Algorithmic Reasoning for Combinatorial Algorithms", "categories": ["cs.LG", "math.AG", "math.CO"], "comment": "Under Review", "summary": "Dynamic programming (DP) algorithms for combinatorial optimization problems\nwork with taking maximization, minimization, and classical addition in their\nrecursion algorithms. The associated value functions correspond to convex\npolyhedra in the max plus semiring. Existing Neural Algorithmic Reasoning\nmodels, however, rely on softmax-normalized dot-product attention where the\nsmooth exponential weighting blurs these sharp polyhedral structures and\ncollapses when evaluated on out-of-distribution (OOD) settings. We introduce\nTropical attention, a novel attention function that operates natively in the\nmax-plus semiring of tropical geometry. We prove that Tropical attention can\napproximate tropical circuits of DP-type combinatorial algorithms. We then\npropose that using Tropical transformers enhances empirical OOD performance in\nboth length generalization and value generalization, on algorithmic reasoning\ntasks, surpassing softmax baselines while remaining stable under adversarial\nattacks. We also present adversarial-attack generalization as a third axis for\nNeural Algorithmic Reasoning benchmarking. Our results demonstrate that\nTropical attention restores the sharp, scale-invariant reasoning absent from\nsoftmax."}
{"id": "2505.17315", "pdf": "https://arxiv.org/pdf/2505.17315", "abs": "https://arxiv.org/abs/2505.17315", "authors": ["Wang Yang", "Zirui Liu", "Hongye Jin", "Qingyu Yin", "Vipin Chaudhary", "Xiaotian Han"], "title": "Longer Context, Deeper Thinking: Uncovering the Role of Long-Context Ability in Reasoning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent language models exhibit strong reasoning capabilities, yet the\ninfluence of long-context capacity on reasoning remains underexplored. In this\nwork, we hypothesize that current limitations in reasoning stem, in part, from\ninsufficient long-context capacity, motivated by empirical observations such as\n(1) higher context window length often leads to stronger reasoning performance,\nand (2) failed reasoning cases resemble failed long-context cases. To test this\nhypothesis, we examine whether enhancing a model's long-context ability before\nSupervised Fine-Tuning (SFT) leads to improved reasoning performance.\nSpecifically, we compared models with identical architectures and fine-tuning\ndata but varying levels of long-context capacity. Our results reveal a\nconsistent trend: models with stronger long-context capacity achieve\nsignificantly higher accuracy on reasoning benchmarks after SFT. Notably, these\ngains persist even on tasks with short input lengths, indicating that\nlong-context training offers generalizable benefits for reasoning performance.\nThese findings suggest that long-context modeling is not just essential for\nprocessing lengthy inputs, but also serves as a critical foundation for\nreasoning. We advocate for treating long-context capacity as a first-class\nobjective in the design of future language models."}
{"id": "2505.17819", "pdf": "https://arxiv.org/pdf/2505.17819", "abs": "https://arxiv.org/abs/2505.17819", "authors": ["J√ºrgen D√∂lz", "Jolanda Weygandt"], "title": "Quantifying uncertainty in spectral clusterings: expectations for perturbed and incomplete data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Spectral clustering is a popular unsupervised learning technique which is\nable to partition unlabelled data into disjoint clusters of distinct shapes.\nHowever, the data under consideration are often experimental data, implying\nthat the data is subject to measurement errors and measurements may even be\nlost or invalid. These uncertainties in the corrupted input data induce\ncorresponding uncertainties in the resulting clusters, and the clusterings thus\nbecome unreliable.\n  Modelling the uncertainties as random processes, we discuss a mathematical\nframework based on random set theory for the computational Monte Carlo\napproximation of statistically expected clusterings in case of corrupted, i.e.,\nperturbed, incomplete, and possibly even additional, data. We propose several\ncomputationally accessible quantities of interest and analyze their consistency\nin the infinite data point and infinite Monte Carlo sample limit. Numerical\nexperiments are provided to illustrate and compare the proposed quantities."}
{"id": "2505.17196", "pdf": "https://arxiv.org/pdf/2505.17196", "abs": "https://arxiv.org/abs/2505.17196", "authors": ["ShengYun Peng", "Pin-Yu Chen", "Jianfeng Chi", "Seongmin Lee", "Duen Horng Chau"], "title": "Shape it Up! Restoring LLM Safety during Finetuning", "categories": ["cs.LG"], "comment": null, "summary": "Finetuning large language models (LLMs) enables user-specific customization\nbut introduces critical safety risks: even a few harmful examples can\ncompromise safety alignment. A common mitigation strategy is to update the\nmodel more strongly on examples deemed safe, while downweighting or excluding\nthose flagged as unsafe. However, because safety context can shift within a\nsingle example, updating the model equally on both harmful and harmless parts\nof a response is suboptimal-a coarse treatment we term static safety shaping.\nIn contrast, we propose dynamic safety shaping (DSS), a framework that uses\nfine-grained safety signals to reinforce learning from safe segments of a\nresponse while suppressing unsafe content. To enable such fine-grained control\nduring finetuning, we introduce a key insight: guardrail models, traditionally\nused for filtering, can be repurposed to evaluate partial responses, tracking\nhow safety risk evolves throughout the response, segment by segment. This leads\nto the Safety Trajectory Assessment of Response (STAR), a token-level signal\nthat enables shaping to operate dynamically over the training sequence.\nBuilding on this, we present STAR-DSS, guided by STAR scores, that robustly\nmitigates finetuning risks and delivers substantial safety improvements across\ndiverse threats, datasets, and model families-all without compromising\ncapability on intended tasks. We encourage future safety research to build on\ndynamic shaping principles for stronger mitigation against evolving finetuning\nrisks."}
{"id": "2505.17323", "pdf": "https://arxiv.org/pdf/2505.17323", "abs": "https://arxiv.org/abs/2505.17323", "authors": ["Ruaridh Mon-Williams", "Max Taylor-Davies", "Elizabeth Mieczkowski", "Natalia Velez", "Neil R. Bramley", "Yanwei Wang", "Thomas L. Griffiths", "Christopher G. Lucas"], "title": "Partner Modelling Emerges in Recurrent Agents (But Only When It Matters)", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Humans are remarkably adept at collaboration, able to infer the strengths and\nweaknesses of new partners in order to work successfully towards shared goals.\nTo build AI systems with this capability, we must first understand its building\nblocks: does such flexibility require explicit, dedicated mechanisms for\nmodelling others -- or can it emerge spontaneously from the pressures of\nopen-ended cooperative interaction? To investigate this question, we train\nsimple model-free RNN agents to collaborate with a population of diverse\npartners. Using the `Overcooked-AI' environment, we collect data from thousands\nof collaborative teams, and analyse agents' internal hidden states. Despite a\nlack of additional architectural features, inductive biases, or auxiliary\nobjectives, the agents nevertheless develop structured internal representations\nof their partners' task abilities, enabling rapid adaptation and generalisation\nto novel collaborators. We investigated these internal models through probing\ntechniques, and large-scale behavioural analysis. Notably, we find that\nstructured partner modelling emerges when agents can influence partner\nbehaviour by controlling task allocation. Our results show that partner\nmodelling can arise spontaneously in model-free agents -- but only under\nenvironmental conditions that impose the right kind of social pressure."}
{"id": "2505.17836", "pdf": "https://arxiv.org/pdf/2505.17836", "abs": "https://arxiv.org/abs/2505.17836", "authors": ["Anna Van Elst", "Igor Colin", "Stephan Cl√©men√ßon"], "title": "Robust Distributed Estimation: Extending Gossip Algorithms to Ranking and Trimmed Means", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": null, "summary": "This paper addresses the problem of robust estimation in gossip algorithms\nover arbitrary communication graphs. Gossip algorithms are fully decentralized,\nrelying only on local neighbor-to-neighbor communication, making them\nwell-suited for situations where communication is constrained. A fundamental\nchallenge in existing mean-based gossip algorithms is their vulnerability to\nmalicious or corrupted nodes. In this paper, we show that an outlier-robust\nmean can be computed by globally estimating a robust statistic. More\nspecifically, we propose a novel gossip algorithm for rank estimation, referred\nto as \\textsc{GoRank}, and leverage it to design a gossip procedure dedicated\nto trimmed mean estimation, coined \\textsc{GoTrim}. In addition to a detailed\ndescription of the proposed methods, a key contribution of our work is a\nprecise convergence analysis: we establish an $\\mathcal{O}(1/t)$ rate for rank\nestimation and an $\\mathcal{O}(\\log(t)/t)$ rate for trimmed mean estimation,\nwhere by $t$ is meant the number of iterations. Moreover, we provide a\nbreakdown point analysis of \\textsc{GoTrim}. We empirically validate our\ntheoretical results through experiments on diverse network topologies, data\ndistributions and contamination schemes."}
{"id": "2505.17198", "pdf": "https://arxiv.org/pdf/2505.17198", "abs": "https://arxiv.org/abs/2505.17198", "authors": ["Shuang Wu", "Meijie Wang", "Lun Yu"], "title": "LengthLogD: A Length-Stratified Ensemble Framework for Enhanced Peptide Lipophilicity Prediction via Multi-Scale Feature Integration", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Peptide compounds demonstrate considerable potential as therapeutic agents\ndue to their high target affinity and low toxicity, yet their drug development\nis constrained by their low membrane permeability. Molecular weight and peptide\nlength have significant effects on the logD of peptides, which in turn\ninfluences their ability to cross biological membranes. However, accurate\nprediction of peptide logD remains challenging due to the complex interplay\nbetween sequence, structure, and ionization states. This study introduces\nLengthLogD, a predictive framework that establishes specialized models through\nmolecular length stratification while innovatively integrating multi-scale\nmolecular representations. We constructed feature spaces across three\nhierarchical levels: atomic (10 molecular descriptors), structural (1024-bit\nMorgan fingerprints), and topological (3 graph-based features including Wiener\nindex), optimized through stratified ensemble learning. An adaptive weight\nallocation mechanism specifically developed for long peptides significantly\nenhances model generalizability. Experimental results demonstrate superior\nperformance across all categories: short peptides (R^2=0.855), medium peptides\n(R^2=0.816), and long peptides (R^2=0.882), with a 34.7% reduction in\nprediction error for long peptides compared to conventional single-model\napproaches. Ablation studies confirm: 1) The length-stratified strategy\ncontributes 41.2% to performance improvement; 2) Topological features account\nfor 28.5% of predictive importance. Compared to state-of-the-art models, our\nmethod maintains short peptide prediction accuracy while achieving a 25.7%\nincrease in the coefficient of determination (R^2) for long peptides. This\nresearch provides a precise logD prediction tool for peptide drug development,\nparticularly demonstrating unique value in optimizing long peptide lead\ncompounds."}
{"id": "2505.17348", "pdf": "https://arxiv.org/pdf/2505.17348", "abs": "https://arxiv.org/abs/2505.17348", "authors": ["Yuheng Wu", "Jianwen Xie", "Denghui Zhang", "Zhaozhuo Xu"], "title": "DEL-ToM: Inference-Time Scaling for Theory-of-Mind Reasoning via Dynamic Epistemic Logic", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Theory-of-Mind (ToM) tasks pose a unique challenge for small language models\n(SLMs) with limited scale, which often lack the capacity to perform deep social\nreasoning. In this work, we propose DEL-ToM, a framework that improves ToM\nreasoning through inference-time scaling rather than architectural changes. Our\napproach decomposes ToM tasks into a sequence of belief updates grounded in\nDynamic Epistemic Logic (DEL), enabling structured and transparent reasoning.\nWe train a verifier, called the Process Belief Model (PBM), to score each\nbelief update step using labels generated automatically via a DEL simulator.\nDuring inference, candidate belief traces generated by a language model are\nevaluated by the PBM, and the highest-scoring trace is selected. This allows\nSLMs to emulate more deliberate reasoning by allocating additional compute at\ntest time. Experiments across multiple model scales and benchmarks show that\nDEL-ToM consistently improves performance, demonstrating that verifiable belief\nsupervision can significantly enhance ToM abilities of SLMs without retraining."}
{"id": "2505.17838", "pdf": "https://arxiv.org/pdf/2505.17838", "abs": "https://arxiv.org/abs/2505.17838", "authors": ["Abhiti Mishra", "Yash Patel", "Ambuj Tewari"], "title": "Continuum Transformers Perform In-Context Learning by Operator Gradient Descent", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Transformers robustly exhibit the ability to perform in-context learning,\nwhereby their predictive accuracy on a task can increase not by parameter\nupdates but merely with the placement of training samples in their context\nwindows. Recent works have shown that transformers achieve this by implementing\ngradient descent in their forward passes. Such results, however, are restricted\nto standard transformer architectures, which handle finite-dimensional inputs.\nIn the space of PDE surrogate modeling, a generalization of transformers to\nhandle infinite-dimensional function inputs, known as \"continuum transformers,\"\nhas been proposed and similarly observed to exhibit in-context learning.\nDespite impressive empirical performance, such in-context learning has yet to\nbe theoretically characterized. We herein demonstrate that continuum\ntransformers perform in-context operator learning by performing gradient\ndescent in an operator RKHS. We demonstrate this using novel proof strategies\nthat leverage a generalized representer theorem for Hilbert spaces and gradient\nflows over the space of functionals of a Hilbert space. We additionally show\nthe operator learned in context is the Bayes Optimal Predictor in the infinite\ndepth limit of the transformer. We then provide empirical validations of this\noptimality result and demonstrate that the parameters under which such gradient\ndescent is performed are recovered through the continuum transformer training."}
{"id": "2505.17226", "pdf": "https://arxiv.org/pdf/2505.17226", "abs": "https://arxiv.org/abs/2505.17226", "authors": ["Kun Yang", "Neena Imam"], "title": "Secure and Private Federated Learning: Achieving Adversarial Resilience through Robust Aggregation", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Federated Learning (FL) enables collaborative machine learning across\ndecentralized data sources without sharing raw data. It offers a promising\napproach to privacy-preserving AI. However, FL remains vulnerable to\nadversarial threats from malicious participants, referred to as Byzantine\nclients, who can send misleading updates to corrupt the global model.\nTraditional aggregation methods, such as simple averaging, are not robust to\nsuch attacks. More resilient approaches, like the Krum algorithm, require prior\nknowledge of the number of malicious clients, which is often unavailable in\nreal-world scenarios. To address these limitations, we propose Average-rKrum\n(ArKrum), a novel aggregation strategy designed to enhance both the resilience\nand privacy guarantees of FL systems. Building on our previous work (rKrum),\nArKrum introduces two key innovations. First, it includes a median-based\nfiltering mechanism that removes extreme outliers before estimating the number\nof adversarial clients. Second, it applies a multi-update averaging scheme to\nimprove stability and performance, particularly when client data distributions\nare not identical. We evaluate ArKrum on benchmark image and text datasets\nunder three widely studied Byzantine attack types. Results show that ArKrum\nconsistently achieves high accuracy and stability. It performs as well as or\nbetter than other robust aggregation methods. These findings demonstrate that\nArKrum is an effective and practical solution for secure FL systems in\nadversarial environments."}
{"id": "2505.17406", "pdf": "https://arxiv.org/pdf/2505.17406", "abs": "https://arxiv.org/abs/2505.17406", "authors": ["Enyi Jiang", "Changming Xu", "Nischay Singh", "Gagandeep Singh"], "title": "Misaligning Reasoning with Answers -- A Framework for Assessing LLM CoT Robustness", "categories": ["cs.AI"], "comment": null, "summary": "LLMs' decision-making process is opaque, prompting the need for explanation\ntechniques like Chain-of-Thought. To investigate the relationship between\nanswer and reasoning, we design a novel evaluation framework, MATCHA. In\ndomains like education and healthcare, reasoning is key for model\ntrustworthiness. MATCHA reveals that LLMs under input perturbations can give\ninconsistent or nonsensical reasoning. Additionally, we use LLM judges to\nassess reasoning robustness across models. Our results show that LLMs exhibit\ngreater vulnerability to input perturbations for multi-step and commonsense\ntasks than compared to logical tasks. Also, we show non-trivial transfer rates\nof our successful examples to black-box models. Our evaluation framework helps\nto better understand LLM reasoning mechanisms and guides future models toward\nmore robust and reasoning-driven architectures, enforcing answer-reasoning\nconsistency."}
{"id": "2505.17895", "pdf": "https://arxiv.org/pdf/2505.17895", "abs": "https://arxiv.org/abs/2505.17895", "authors": ["Dan A. Calian", "Gregory Farquhar", "Iurii Kemaev", "Luisa M. Zintgraf", "Matteo Hessel", "Jeremy Shar", "Junhyuk Oh", "Andr√°s Gy√∂rgy", "Tom Schaul", "Jeffrey Dean", "Hado van Hasselt", "David Silver"], "title": "DataRater: Meta-Learned Dataset Curation", "categories": ["stat.ML", "cs.AI", "cs.LG", "I.2.6"], "comment": null, "summary": "The quality of foundation models depends heavily on their training data.\nConsequently, great efforts have been put into dataset curation. Yet most\napproaches rely on manual tuning of coarse-grained mixtures of large buckets of\ndata, or filtering by hand-crafted heuristics. An approach that is ultimately\nmore scalable (let alone more satisfying) is to \\emph{learn} which data is\nactually valuable for training. This type of meta-learning could allow more\nsophisticated, fine-grained, and effective curation. Our proposed\n\\emph{DataRater} is an instance of this idea. It estimates the value of\ntraining on any particular data point. This is done by meta-learning using\n`meta-gradients', with the objective of improving training efficiency on held\nout data. In extensive experiments across a range of model scales and datasets,\nwe find that using our DataRater to filter data is highly effective, resulting\nin significantly improved compute efficiency."}
{"id": "2505.17228", "pdf": "https://arxiv.org/pdf/2505.17228", "abs": "https://arxiv.org/abs/2505.17228", "authors": ["Arash Afkanpour", "Omkar Dige", "Fatemeh Tavakoli"], "title": "Automated Capability Evaluation of Foundation Models", "categories": ["cs.LG"], "comment": null, "summary": "Current evaluation frameworks for foundation models rely heavily on fixed,\nmanually curated benchmarks, limiting their ability to capture the full breadth\nof model capabilities. This paper introduces Active learning for Capability\nEvaluation (ACE), a novel framework for scalable, automated, and fine-grained\nevaluation of foundation models. ACE leverages the knowledge embedded in\npowerful language models to decompose a domain into semantically meaningful\ncapabilities and generate diverse evaluation tasks, significantly reducing\nhuman effort. To maximize coverage and efficiency, ACE models a subject model's\nperformance as a capability function over a latent semantic space and uses\nactive learning to prioritize the evaluation of the most informative\ncapabilities. This adaptive evaluation strategy enables cost-effective\ndiscovery of strengths, weaknesses, and failure modes that static benchmarks\nmay miss. Our results suggest that ACE provides a more complete and informative\npicture of model capabilities, which is essential for safe and well-informed\ndeployment of foundation models."}
{"id": "2505.17433", "pdf": "https://arxiv.org/pdf/2505.17433", "abs": "https://arxiv.org/abs/2505.17433", "authors": ["Zhengyi Zhao", "Shubo Zhang", "Yuxi Zhang", "Yanxi Zhao", "Yifan Zhang", "Zezhong Wang", "Huimin Wang", "Yutian Zhao", "Bin Liang", "Yefeng Zheng", "Binyang Li", "Kam-Fai Wong", "Xian Wu"], "title": "MemeReaCon: Probing Contextual Meme Understanding in Large Vision-Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Memes have emerged as a popular form of multimodal online communication,\nwhere their interpretation heavily depends on the specific context in which\nthey appear. Current approaches predominantly focus on isolated meme analysis,\neither for harmful content detection or standalone interpretation, overlooking\na fundamental challenge: the same meme can express different intents depending\non its conversational context. This oversight creates an evaluation gap:\nalthough humans intuitively recognize how context shapes meme interpretation,\nLarge Vision Language Models (LVLMs) can hardly understand context-dependent\nmeme intent. To address this critical limitation, we introduce MemeReaCon, a\nnovel benchmark specifically designed to evaluate how LVLMs understand memes in\ntheir original context. We collected memes from five different Reddit\ncommunities, keeping each meme's image, the post text, and user comments\ntogether. We carefully labeled how the text and meme work together, what the\nposter intended, how the meme is structured, and how the community responded.\nOur tests with leading LVLMs show a clear weakness: models either fail to\ninterpret critical information in the contexts, or overly focus on visual\ndetails while overlooking communicative purpose. MemeReaCon thus serves both as\na diagnostic tool exposing current limitations and as a challenging benchmark\nto drive development toward more sophisticated LVLMs of the context-aware\nunderstanding."}
{"id": "2505.17907", "pdf": "https://arxiv.org/pdf/2505.17907", "abs": "https://arxiv.org/abs/2505.17907", "authors": ["Ka Long Keith Ho", "Yoshinari Takeishi", "Junichi Takeuchi"], "title": "Function Forms of Simple ReLU Networks with Random Hidden Weights", "categories": ["stat.ML", "cs.LG"], "comment": "21 pages, 1 figure, 1 table", "summary": "We investigate the function space dynamics of a two-layer ReLU neural network\nin the infinite-width limit, highlighting the Fisher information matrix (FIM)'s\nrole in steering learning. Extending seminal works on approximate\neigendecomposition of the FIM, we derive the asymptotic behavior of basis\nfunctions ($f_v(x) = X^{\\top} v $) for four groups of approximate eigenvectors,\nshowing their convergence to distinct function forms. These functions,\nprioritized by gradient descent, exhibit FIM-induced inner products that\napproximate orthogonality in the function space, forging a novel connection\nbetween parameter and function spaces. Simulations validate the accuracy of\nthese theoretical approximations, confirming their practical relevance. By\nrefining the function space inner product's role, we advance the theoretical\nframework for ReLU networks, illuminating their optimization and expressivity.\nOverall, this work offers a robust foundation for understanding wide neural\nnetworks and enhances insights into scalable deep learning architectures,\npaving the way for improved design and analysis of neural networks."}
{"id": "2505.17233", "pdf": "https://arxiv.org/pdf/2505.17233", "abs": "https://arxiv.org/abs/2505.17233", "authors": ["Andreas Patakis", "Vassilis Lyberatos", "Spyridon Kantarelis", "Edmund Dervakos", "Giorgos Stamou"], "title": "Semantic-Aware Interpretable Multimodal Music Auto-Tagging", "categories": ["cs.LG", "cs.SD", "eess.AS"], "comment": "Accepted at Interspeech 2025", "summary": "Music auto-tagging is essential for organizing and discovering music in\nextensive digital libraries. While foundation models achieve exceptional\nperformance in this domain, their outputs often lack interpretability, limiting\ntrust and usability for researchers and end-users alike. In this work, we\npresent an interpretable framework for music auto-tagging that leverages groups\nof musically meaningful multimodal features, derived from signal processing,\ndeep learning, ontology engineering, and natural language processing. To\nenhance interpretability, we cluster features semantically and employ an\nexpectation maximization algorithm, assigning distinct weights to each group\nbased on its contribution to the tagging process. Our method achieves\ncompetitive tagging performance while offering a deeper understanding of the\ndecision-making process, paving the way for more transparent and user-centric\nmusic tagging systems."}
{"id": "2505.17436", "pdf": "https://arxiv.org/pdf/2505.17436", "abs": "https://arxiv.org/abs/2505.17436", "authors": ["Cheng Peng", "Kai Zhang", "Mengxian Lyu", "Hongfang Liu", "Lichao Sun", "Yonghui Wu"], "title": "Scaling Up Biomedical Vision-Language Models: Fine-Tuning, Instruction Tuning, and Multi-Modal Learning", "categories": ["cs.AI"], "comment": null, "summary": "To advance biomedical vison-language model capabilities through scaling up,\nfine-tuning, and instruction tuning, develop vision-language models with\nimproved performance in handling long text, explore strategies to efficiently\nadopt vision language models for diverse multi-modal biomedical tasks, and\nexamine the zero-shot learning performance.\n  We developed two biomedical vision language models, BiomedGPT-Large and\nBiomedGPT-XLarge, based on an encoder-decoder-based transformer architecture.\nWe fine-tuned the two models on 23 benchmark datasets from 6 multi-modal\nbiomedical tasks including one image-only task (image classification), three\nlanguage-only tasks (text understanding, text summarization and question\nanswering), and two vision-language tasks (visual question answering and image\ncaptioning). We compared the developed scaled models with our previous\nBiomedGPT-Base model and existing prestigious models reported in the\nliterature. We instruction-tuned the two models using a large-scale multi-modal\nbiomedical instruction-tuning dataset and assessed the zero-shot learning\nperformance and alignment accuracy."}
{"id": "2505.17917", "pdf": "https://arxiv.org/pdf/2505.17917", "abs": "https://arxiv.org/abs/2505.17917", "authors": ["Xingyu Li", "Qing Liu", "Tony Jiang", "Hong Amy Xia", "Brian P. Hobbs", "Peng Wei"], "title": "M-learner:A Flexible And Powerful Framework To Study Heterogeneous Treatment Effect In Mediation Model", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "We propose a novel method, termed the M-learner, for estimating heterogeneous\nindirect and total treatment effects and identifying relevant subgroups within\na mediation framework. The procedure comprises four key steps. First, we\ncompute individual-level conditional average indirect/total treatment effect\nSecond, we construct a distance matrix based on pairwise differences. Third, we\napply tSNE to project this matrix into a low-dimensional Euclidean space,\nfollowed by K-means clustering to identify subgroup structures. Finally, we\ncalibrate and refine the clusters using a threshold-based procedure to\ndetermine the optimal configuration. To the best of our knowledge, this is the\nfirst approach specifically designed to capture treatment effect heterogeneity\nin the presence of mediation. Experimental results validate the robustness and\neffectiveness of the proposed framework. Application to the real-world Jobs II\ndataset highlights the broad adaptability and potential applicability of our\nmethod.Code is available at https: //anonymous.4open.science/r/M-learner-C4BB."}
{"id": "2505.17242", "pdf": "https://arxiv.org/pdf/2505.17242", "abs": "https://arxiv.org/abs/2505.17242", "authors": ["Ram√≥n Fernandez Astudillo", "Md Arafat Sultan", "Aashka Trivedi", "Yousef El-Kurdi", "Tahira Naseem", "Radu Florian", "Salim Roukos"], "title": "Optimal Policy Minimum Bayesian Risk", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Inference scaling can help LLMs solve complex reasoning problems through\nextended runtime computation. On top of targeted supervision for long\nchain-of-thought (long-CoT) generation, purely inference-time techniques such\nas best-of-N (BoN) sampling, majority voting, or more generally, minimum Bayes\nrisk decoding (MBRD), can further improve LLM accuracy by generating multiple\ncandidate solutions and aggregating over them. These methods typically leverage\nadditional signals in the form of reward models and risk/similarity functions\nthat compare generated samples, e.g., exact match in some normalized space or\nstandard similarity metrics such as Rouge. Here we present a novel method for\nincorporating reward and risk/similarity signals into MBRD. Based on the\nconcept of optimal policy in KL-controlled reinforcement learning, our\nframework provides a simple and well-defined mechanism for leveraging such\nsignals, offering several advantages over traditional inference-time methods:\nhigher robustness, improved accuracy, and well-understood asymptotic behavior.\nIn addition, it allows for the development of a sample-efficient variant of\nMBRD that can adjust the number of samples to generate according to the\ndifficulty of the problem, without relying on majority vote counts. We\nempirically demonstrate the advantages of our approach on math (MATH-$500$) and\ncoding (HumanEval) tasks using recent open-source models. We also present a\ncomprehensive analysis of its accuracy-compute trade-offs."}
{"id": "2505.17482", "pdf": "https://arxiv.org/pdf/2505.17482", "abs": "https://arxiv.org/abs/2505.17482", "authors": ["Chao Lei", "Nir Lipovetzky", "Krista A. Ehinger", "Yanchuan Chang"], "title": "From Reasoning to Generalization: Knowledge-Augmented LLMs for ARC Benchmark", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent reasoning-oriented LLMs have demonstrated strong performance on\nchallenging tasks such as mathematics and science examinations. However, core\ncognitive faculties of human intelligence, such as abstract reasoning and\ngeneralization, remain underexplored. To address this, we evaluate recent\nreasoning-oriented LLMs on the Abstraction and Reasoning Corpus (ARC)\nbenchmark, which explicitly demands both faculties. We formulate ARC as a\nprogram synthesis task and propose nine candidate solvers. Experimental results\nshow that repeated-sampling planning-aided code generation (RSPC) achieves the\nhighest test accuracy and demonstrates consistent generalization across most\nLLMs. To further improve performance, we introduce an ARC solver, Knowledge\nAugmentation for Abstract Reasoning (KAAR), which encodes core knowledge priors\nwithin an ontology that classifies priors into three hierarchical levels based\non their dependencies. KAAR progressively expands LLM reasoning capacity by\ngradually augmenting priors at each level, and invokes RSPC to generate\ncandidate solutions after each augmentation stage. This stage-wise reasoning\nreduces interference from irrelevant priors and improves LLM performance.\nEmpirical results show that KAAR maintains strong generalization and\nconsistently outperforms non-augmented RSPC across all evaluated LLMs,\nachieving around 5% absolute gains and up to 64.52% relative improvement.\nDespite these achievements, ARC remains a challenging benchmark for\nreasoning-oriented LLMs, highlighting future avenues of progress in LLMs."}
{"id": "2505.17958", "pdf": "https://arxiv.org/pdf/2505.17958", "abs": "https://arxiv.org/abs/2505.17958", "authors": ["Vittorio Erba", "Emanuele Troiani", "Lenka Zdeborov√°", "Florent Krzakala"], "title": "The Nuclear Route: Sharp Asymptotics of ERM in Overparameterized Quadratic Networks", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "We study the high-dimensional asymptotics of empirical risk minimization\n(ERM) in over-parametrized two-layer neural networks with quadratic activations\ntrained on synthetic data. We derive sharp asymptotics for both training and\ntest errors by mapping the $\\ell_2$-regularized learning problem to a convex\nmatrix sensing task with nuclear norm penalization. This reveals that capacity\ncontrol in such networks emerges from a low-rank structure in the learned\nfeature maps. Our results characterize the global minima of the loss and yield\nprecise generalization thresholds, showing how the width of the target function\ngoverns learnability. This analysis bridges and extends ideas from spin-glass\nmethods, matrix factorization, and convex optimization and emphasizes the deep\nlink between low-rank matrix sensing and learning in quadratic neural networks."}
{"id": "2505.17248", "pdf": "https://arxiv.org/pdf/2505.17248", "abs": "https://arxiv.org/abs/2505.17248", "authors": ["Chace Ashcraft", "Ted Staley", "Josh Carney", "Cameron Hickert", "Derek Juba", "Kiran Karra", "Nathan Drenkow"], "title": "Backdoors in DRL: Four Environments Focusing on In-distribution Triggers", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Backdoor attacks, or trojans, pose a security risk by concealing undesirable\nbehavior in deep neural network models. Open-source neural networks are\ndownloaded from the internet daily, possibly containing backdoors, and\nthird-party model developers are common. To advance research on backdoor attack\nmitigation, we develop several trojans for deep reinforcement learning (DRL)\nagents. We focus on in-distribution triggers, which occur within the agent's\nnatural data distribution, since they pose a more significant security threat\nthan out-of-distribution triggers due to their ease of activation by the\nattacker during model deployment. We implement backdoor attacks in four\nreinforcement learning (RL) environments: LavaWorld, Randomized LavaWorld,\nColorful Memory, and Modified Safety Gymnasium. We train various models, both\nclean and backdoored, to characterize these attacks. We find that\nin-distribution triggers can require additional effort to implement and be more\nchallenging for models to learn, but are nevertheless viable threats in DRL\neven using basic data poisoning attacks."}
{"id": "2505.17492", "pdf": "https://arxiv.org/pdf/2505.17492", "abs": "https://arxiv.org/abs/2505.17492", "authors": ["Dezheng Bao", "Yueci Yang", "Xin Chen", "Zhengxuan Jiang", "Zeguo Fei", "Daoze Zhang", "Xuanwen Huang", "Junru Chen", "Chutian Yu", "Xiang Yuan", "Yang Yang"], "title": "PD$^3$: A Project Duplication Detection Framework via Adapted Multi-Agent Debate", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "17 pages, 9 figures", "summary": "Project duplication detection is critical for project quality assessment, as\nit improves resource utilization efficiency by preventing investing in newly\nproposed project that have already been studied. It requires the ability to\nunderstand high-level semantics and generate constructive and valuable\nfeedback. Existing detection methods rely on basic word- or sentence-level\ncomparison or solely apply large language models, lacking valuable insights for\nexperts and in-depth comprehension of project content and review criteria. To\ntackle this issue, we propose PD$^3$, a Project Duplication Detection framework\nvia adapted multi-agent Debate. Inspired by real-world expert debates, it\nemploys a fair competition format to guide multi-agent debate to retrieve\nrelevant projects. For feedback, it incorporates both qualitative and\nquantitative analysis to improve its practicality. Over 800 real-world power\nproject data spanning more than 20 specialized fields are used to evaluate the\nframework, demonstrating that our method outperforms existing approaches by\n7.43% and 8.00% in two downstream tasks. Furthermore, we establish an online\nplatform, Review Dingdang, to assist power experts, saving 5.73 million USD in\ninitial detection on more than 100 newly proposed projects."}
{"id": "2505.18000", "pdf": "https://arxiv.org/pdf/2505.18000", "abs": "https://arxiv.org/abs/2505.18000", "authors": ["Valentin Kilian", "Stefano Cortinovis", "Fran√ßois Caron"], "title": "Anytime-valid, Bayes-assisted,Prediction-Powered Inference", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Given a large pool of unlabelled data and a smaller amount of labels,\nprediction-powered inference (PPI) leverages machine learning predictions to\nincrease the statistical efficiency of standard confidence interval procedures\nbased solely on labelled data, while preserving their fixed-time validity.\n  In this paper, we extend the PPI framework to the sequential setting, where\nlabelled and unlabelled datasets grow over time.\n  Exploiting Ville's inequality and the method of mixtures, we propose\nprediction-powered confidence sequence procedures that are valid uniformly over\ntime and naturally accommodate prior knowledge on the quality of the\npredictions to further boost efficiency.\n  We carefully illustrate the design choices behind our method and demonstrate\nits effectiveness in real and synthetic examples."}
{"id": "2505.17254", "pdf": "https://arxiv.org/pdf/2505.17254", "abs": "https://arxiv.org/abs/2505.17254", "authors": ["Alexey Boldyrev", "Fedor Ratnikov", "Andrey Shevelev"], "title": "Approach to Finding a Robust Deep Learning Model", "categories": ["cs.LG", "I.2.1"], "comment": "27 pages, 18 figures", "summary": "The rapid development of machine learning (ML) and artificial intelligence\n(AI) applications requires the training of large numbers of models. This\ngrowing demand highlights the importance of training models without human\nsupervision, while ensuring that their predictions are reliable. In response to\nthis need, we propose a novel approach for determining model robustness. This\napproach, supplemented with a proposed model selection algorithm designed as a\nmeta-algorithm, is versatile and applicable to any machine learning model,\nprovided that it is appropriate for the task at hand. This study demonstrates\nthe application of our approach to evaluate the robustness of deep learning\nmodels. To this end, we study small models composed of a few convolutional and\nfully connected layers, using common optimizers due to their ease of\ninterpretation and computational efficiency. Within this framework, we address\nthe influence of training sample size, model weight initialization, and\ninductive bias on the robustness of deep learning models."}
{"id": "2505.17512", "pdf": "https://arxiv.org/pdf/2505.17512", "abs": "https://arxiv.org/abs/2505.17512", "authors": ["Shuhang Xu", "Weijian Deng", "Yixuan Zhou", "Fangwei Zhong"], "title": "Probe by Gaming: A Game-based Benchmark for Assessing Conceptual Knowledge in LLMs", "categories": ["cs.AI", "cs.CL"], "comment": "9 pages", "summary": "Concepts represent generalized abstractions that enable humans to categorize\nand reason efficiently, yet it is unclear to what extent Large Language Models\n(LLMs) comprehend these semantic relationships. Existing benchmarks typically\nfocus on factual recall and isolated tasks, failing to evaluate the ability of\nLLMs to understand conceptual boundaries. To address this gap, we introduce\nCK-Arena, a multi-agent interaction game built upon the Undercover game,\ndesigned to evaluate the capacity of LLMs to reason with concepts in\ninteractive settings. CK-Arena challenges models to describe, differentiate,\nand infer conceptual boundaries based on partial information, encouraging\nmodels to explore commonalities and distinctions between closely related\nconcepts. By simulating real-world interaction, CK-Arena provides a scalable\nand realistic benchmark for assessing conceptual reasoning in dynamic\nenvironments. Experimental results show that LLMs' understanding of conceptual\nknowledge varies significantly across different categories and is not strictly\naligned with parameter size or general model capabilities. The data and code\nare available at the project homepage: https://ck-arena.site."}
{"id": "2505.18077", "pdf": "https://arxiv.org/pdf/2505.18077", "abs": "https://arxiv.org/abs/2505.18077", "authors": ["Daniel F. Villarraga", "Ricardo A. Daziano"], "title": "Bayesian Deep Learning for Discrete Choice", "categories": ["stat.ML", "cs.LG", "econ.EM", "stat.AP"], "comment": null, "summary": "Discrete choice models (DCMs) are used to analyze individual decision-making\nin contexts such as transportation choices, political elections, and consumer\npreferences. DCMs play a central role in applied econometrics by enabling\ninference on key economic variables, such as marginal rates of substitution,\nrather than focusing solely on predicting choices on new unlabeled data.\nHowever, while traditional DCMs offer high interpretability and support for\npoint and interval estimation of economic quantities, these models often\nunderperform in predictive tasks compared to deep learning (DL) models. Despite\ntheir predictive advantages, DL models remain largely underutilized in discrete\nchoice due to concerns about their lack of interpretability, unstable parameter\nestimates, and the absence of established methods for uncertainty\nquantification. Here, we introduce a deep learning model architecture\nspecifically designed to integrate with approximate Bayesian inference methods,\nsuch as Stochastic Gradient Langevin Dynamics (SGLD). Our proposed model\ncollapses to behaviorally informed hypotheses when data is limited, mitigating\noverfitting and instability in underspecified settings while retaining the\nflexibility to capture complex nonlinear relationships when sufficient data is\navailable. We demonstrate our approach using SGLD through a Monte Carlo\nsimulation study, evaluating both predictive metrics--such as out-of-sample\nbalanced accuracy--and inferential metrics--such as empirical coverage for\nmarginal rates of substitution interval estimates. Additionally, we present\nresults from two empirical case studies: one using revealed mode choice data in\nNYC, and the other based on the widely used Swiss train choice stated\npreference data."}
{"id": "2505.17257", "pdf": "https://arxiv.org/pdf/2505.17257", "abs": "https://arxiv.org/abs/2505.17257", "authors": ["Qihao Duan", "Bingding Huang", "Zhenqiao Song", "Irina Lehmann", "Lei Gu", "Roland Eils", "Benjamin Wild"], "title": "JanusDNA: A Powerful Bi-directional Hybrid DNA Foundation Model", "categories": ["cs.LG", "q-bio.GN"], "comment": null, "summary": "Large language models (LLMs) have revolutionized natural language processing\nand are increasingly applied to other sequential data types, including genetic\nsequences. However, adapting LLMs to genomics presents significant challenges.\nCapturing complex genomic interactions requires modeling long-range\ndependencies within DNA sequences, where interactions often span over 10,000\nbase pairs, even within a single gene, posing substantial computational burdens\nunder conventional model architectures and training paradigms. Moreover,\nstandard LLM training approaches are suboptimal for DNA: autoregressive\ntraining, while efficient, supports only unidirectional understanding. However,\nDNA is inherently bidirectional, e.g., bidirectional promoters regulate\ntranscription in both directions and account for nearly 11% of human gene\nexpression. Masked language models (MLMs) allow bidirectional understanding but\nare inefficient, as only masked tokens contribute to the loss per step. To\naddress these limitations, we introduce JanusDNA, the first bidirectional DNA\nfoundation model built upon a novel pretraining paradigm that combines the\noptimization efficiency of autoregressive modeling with the bidirectional\ncomprehension of masked modeling. JanusDNA adopts a hybrid Mamba, Attention and\nMixture of Experts (MoE) architecture, combining long-range modeling of\nAttention with efficient sequential learning of Mamba. MoE layers further scale\nmodel capacity via sparse activation while keeping computational cost low.\nNotably, JanusDNA processes up to 1 million base pairs at single nucleotide\nresolution on a single 80GB GPU. Extensive experiments and ablations show\nJanusDNA achieves new SOTA results on three genomic representation benchmarks,\noutperforming models with 250x more activated parameters. Code:\nhttps://github.com/Qihao-Duan/JanusDNA"}
{"id": "2505.17520", "pdf": "https://arxiv.org/pdf/2505.17520", "abs": "https://arxiv.org/abs/2505.17520", "authors": ["Salahuddin Alawadhi", "Noorhan Abbas"], "title": "Optimizing Retrieval-Augmented Generation for Electrical Engineering: A Case Study on ABB Circuit Breakers", "categories": ["cs.AI", "I.2.7; H.3.3"], "comment": "17 pages, 4 figures, published in CSIT Vol. 15, 2025. DOI:\n  10.5121/csit.2025.150905", "summary": "Integrating Retrieval Augmented Generation (RAG) with Large Language Models\n(LLMs) has shown the potential to provide precise, contextually relevant\nresponses in knowledge intensive domains. This study investigates the\nap-plication of RAG for ABB circuit breakers, focusing on accuracy,\nreliability, and contextual relevance in high-stakes engineering environments.\nBy leveraging tailored datasets, advanced embedding models, and optimized\nchunking strategies, the research addresses challenges in data retrieval and\ncontextual alignment unique to engineering documentation. Key contributions\ninclude the development of a domain-specific dataset for ABB circuit breakers\nand the evaluation of three RAG pipelines: OpenAI GPT4o, Cohere, and Anthropic\nClaude. Advanced chunking methods, such as paragraph-based and title-aware\nsegmentation, are assessed for their impact on retrieval accuracy and response\ngeneration. Results demonstrate that while certain configurations achieve high\nprecision and relevancy, limitations persist in ensuring factual faithfulness\nand completeness, critical in engineering contexts. This work underscores the\nneed for iterative improvements in RAG systems to meet the stringent demands of\nelectrical engineering tasks, including design, troubleshooting, and\noperational decision-making. The findings in this paper help advance research\nof AI in highly technical domains such as electrical engineering."}
{"id": "2505.18118", "pdf": "https://arxiv.org/pdf/2505.18118", "abs": "https://arxiv.org/abs/2505.18118", "authors": ["Aidan Gleich", "Eric Laber", "Alexander Volfovsky"], "title": "Scalable Policy Maximization Under Network Interference", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Many interventions, such as vaccines in clinical trials or coupons in online\nmarketplaces, must be assigned sequentially without full knowledge of their\neffects. Multi-armed bandit algorithms have proven successful in such settings.\nHowever, standard independence assumptions fail when the treatment status of\none individual impacts the outcomes of others, a phenomenon known as\ninterference. We study optimal-policy learning under interference on a dynamic\nnetwork. Existing approaches to this problem require repeated observations of\nthe same fixed network and struggle to scale in sample size beyond as few as\nfifteen connected units -- both limit applications. We show that under common\nassumptions on the structure of interference, rewards become linear. This\nenables us to develop a scalable Thompson sampling algorithm that maximizes\npolicy impact when a new $n$-node network is observed each round. We prove a\nBayesian regret bound that is sublinear in $n$ and the number of rounds.\nSimulation experiments show that our algorithm learns quickly and outperforms\nexisting methods. The results close a key scalability gap between causal\ninference methods for interference and practical bandit algorithms, enabling\npolicy optimization in large-scale networked systems."}
{"id": "2505.17272", "pdf": "https://arxiv.org/pdf/2505.17272", "abs": "https://arxiv.org/abs/2505.17272", "authors": ["Mingyu Yang", "Mehdi Rezagholizadeh", "Guihong Li", "Vikram Appia", "Emad Barsoum"], "title": "Zebra-Llama: Towards Extremely Efficient Hybrid Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "With the growing demand for deploying large language models (LLMs) across\ndiverse applications, improving their inference efficiency is crucial for\nsustainable and democratized access. However, retraining LLMs to meet new\nuser-specific requirements is prohibitively expensive and environmentally\nunsustainable. In this work, we propose a practical and scalable alternative:\ncomposing efficient hybrid language models from existing pre-trained models.\nOur approach, Zebra-Llama, introduces a family of 1B, 3B, and 8B hybrid models\nby combining State Space Models (SSMs) and Multi-head Latent Attention (MLA)\nlayers, using a refined initialization and post-training pipeline to\nefficiently transfer knowledge from pre-trained Transformers. Zebra-Llama\nachieves Transformer-level accuracy with near-SSM efficiency using only 7-11B\ntraining tokens (compared to trillions of tokens required for pre-training) and\nan 8B teacher. Moreover, Zebra-Llama dramatically reduces KV cache size -down\nto 3.9%, 2%, and 2.73% of the original for the 1B, 3B, and 8B variants,\nrespectively-while preserving 100%, 100%, and >97% of average zero-shot\nperformance on LM Harness tasks. Compared to models like MambaInLLaMA,\nX-EcoMLA, Minitron, and Llamba, Zebra-Llama consistently delivers competitive\nor superior accuracy while using significantly fewer tokens, smaller teachers,\nand vastly reduced KV cache memory. Notably, Zebra-Llama-8B surpasses\nMinitron-8B in few-shot accuracy by 7% while using 8x fewer training tokens,\nover 12x smaller KV cache, and a smaller teacher (8B vs. 15B). It also achieves\n2.6x-3.8x higher throughput (tokens/s) than MambaInLlama up to a 32k context\nlength. We will release code and model checkpoints upon acceptance."}
{"id": "2505.17525", "pdf": "https://arxiv.org/pdf/2505.17525", "abs": "https://arxiv.org/abs/2505.17525", "authors": ["Juliett Su√°rez Ferreira", "Marija Slavkovik", "Jorge Casillas"], "title": "Transparency and Proportionality in Post-Processing Algorithmic Bias Correction", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Algorithmic decision-making systems sometimes produce errors or skewed\npredictions toward a particular group, leading to unfair results. Debiasing\npractices, applied at different stages of the development of such systems,\noccasionally introduce new forms of unfairness or exacerbate existing\ninequalities. We focus on post-processing techniques that modify algorithmic\npredictions to achieve fairness in classification tasks, examining the\nunintended consequences of these interventions. To address this challenge, we\ndevelop a set of measures that quantify the disparity in the flips applied to\nthe solution in the post-processing stage. The proposed measures will help\npractitioners: (1) assess the proportionality of the debiasing strategy used,\n(2) have transparency to explain the effects of the strategy in each group, and\n(3) based on those results, analyze the possibility of the use of some other\napproaches for bias mitigation or to solve the problem. We introduce a\nmethodology for applying the proposed metrics during the post-processing stage\nand illustrate its practical application through an example. This example\ndemonstrates how analyzing the proportionality of the debiasing strategy\ncomplements traditional fairness metrics, providing a deeper perspective to\nensure fairer outcomes across all groups."}
{"id": "2505.17354", "pdf": "https://arxiv.org/pdf/2505.17354", "abs": "https://arxiv.org/abs/2505.17354", "authors": ["Keisuke Kawano", "Takuro Kutsuna", "Naoki Hayashi", "Yasushi Esaki", "Hidenori Tanaka"], "title": "CT-OT Flow: Estimating Continuous-Time Dynamics from Discrete Temporal Snapshots", "categories": ["cs.LG", "stat.ML"], "comment": "27 pages, 28 figures", "summary": "In many real-world scenarios, such as single-cell RNA sequencing, data are\nobserved only as discrete-time snapshots spanning finite time intervals and\nsubject to noisy timestamps, with no continuous trajectories available.\nRecovering the underlying continuous-time dynamics from these snapshots with\ncoarse and noisy observation times is a critical and challenging task. We\npropose Continuous-Time Optimal Transport Flow (CT-OT Flow), which first infers\nhigh-resolution time labels via partial optimal transport and then reconstructs\na continuous-time data distribution through a temporal kernel smoothing. This\nreconstruction enables accurate training of dynamics models such as ODEs and\nSDEs. CT-OT Flow consistently outperforms state-of-the-art methods on synthetic\nbenchmarks and achieves lower reconstruction errors on real scRNA-seq and\ntyphoon-track datasets. Our results highlight the benefits of explicitly\nmodeling temporal discretization and timestamp uncertainty, offering an\naccurate and general framework for bridging discrete snapshots and\ncontinuous-time processes."}
{"id": "2505.17277", "pdf": "https://arxiv.org/pdf/2505.17277", "abs": "https://arxiv.org/abs/2505.17277", "authors": ["Soumita Hait", "Ping Li", "Haipeng Luo", "Mengxiao Zhang"], "title": "Comparator-Adaptive $Œ¶$-Regret: Improved Bounds, Simpler Algorithms, and Applications to Games", "categories": ["cs.LG"], "comment": null, "summary": "In the classic expert problem, $\\Phi$-regret measures the gap between the\nlearner's total loss and that achieved by applying the best action\ntransformation $\\phi \\in \\Phi$. A recent work by Lu et al., [2025] introduces\nan adaptive algorithm whose regret against a comparator $\\phi$ depends on a\ncertain sparsity-based complexity measure of $\\phi$, (almost) recovering and\ninterpolating optimal bounds for standard regret notions such as external,\ninternal, and swap regret. In this work, we propose a general idea to achieve\nan even better comparator-adaptive $\\Phi$-regret bound via much simpler\nalgorithms compared to Lu et al., [2025]. Specifically, we discover a prior\ndistribution over all possible binary transformations and show that it suffices\nto achieve prior-dependent regret against these transformations. Then, we\npropose two concrete and efficient algorithms to achieve so, where the first\none learns over multiple copies of a prior-aware variant of the Kernelized MWU\nalgorithm of Farina et al., [2022], and the second one learns over multiple\ncopies of a prior-aware variant of the BM-reduction [Blum and Mansour, 2007].\nTo further showcase the power of our methods and the advantages over Lu et al.,\n[2025] besides the simplicity and better regret bounds, we also show that our\nsecond approach can be extended to the game setting to achieve accelerated and\nadaptive convergence rate to $\\Phi$-equilibria for a class of general-sum\ngames. When specified to the special case of correlated equilibria, our bound\nimproves over the existing ones from Anagnostides et al., [2022a,b]"}
{"id": "2505.17572", "pdf": "https://arxiv.org/pdf/2505.17572", "abs": "https://arxiv.org/abs/2505.17572", "authors": ["Siqi Lai", "Yansong Ning", "Zirui Yuan", "Zhixi Chen", "Hao Liu"], "title": "USTBench: Benchmarking and Dissecting Spatiotemporal Reasoning of LLMs as Urban Agents", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have shown emerging potential in spatiotemporal\nreasoning, making them promising candidates for building urban agents that\nsupport diverse urban downstream applications. Despite these benefits, existing\nstudies primarily focus on evaluating urban LLM agent on outcome-level metrics\n(e.g., prediction accuracy, traffic efficiency), offering limited insight into\ntheir underlying reasoning processes. As a result, the strengths and\nlimitations of urban LLM agents in spatiotemporal reasoning remain poorly\nunderstood. To this end, we introduce USTBench, the first benchmark to evaluate\nLLMs' spatiotemporal reasoning abilities as urban agents across four decomposed\ndimensions: spatiotemporal understanding, forecasting, planning, and reflection\nwith feedback. Specifically, USTBench supports five diverse urban\ndecision-making and four spatiotemporal prediction tasks, all running within\nour constructed interactive city environment UAgentEnv. The benchmark includes\n62,466 structured QA pairs for process-level evaluation and standardized\nend-to-end task assessments, enabling fine-grained diagnostics and broad\ntask-level comparison across diverse urban scenarios. Through extensive\nevaluation of thirteen leading LLMs, we reveal that although LLMs show\npromising potential across various urban downstream tasks, they still struggle\nin long-horizon planning and reflective adaptation in dynamic urban contexts.\nNotably, recent advanced reasoning models (e.g., DeepSeek-R1) trained on\ngeneral logic or mathematical problems do not consistently outperform\nnon-reasoning LLMs. This discrepancy highlights the need for domain-specialized\nadaptation methods to enhance urban spatiotemporal reasoning. Overall, USTBench\nprovides a foundation to build more adaptive and effective LLM-based urban\nagents and broad smart city applications."}
{"id": "2505.17384", "pdf": "https://arxiv.org/pdf/2505.17384", "abs": "https://arxiv.org/abs/2505.17384", "authors": ["Tianyu Xie", "Shuchen Xue", "Zijin Feng", "Tianyang Hu", "Jiacheng Sun", "Zhenguo Li", "Cheng Zhang"], "title": "Variational Autoencoding Discrete Diffusion with Enhanced Dimensional Correlations Modeling", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": "23 pages, 14 figures", "summary": "Discrete diffusion models have recently shown great promise for modeling\ncomplex discrete data, with masked diffusion models (MDMs) offering a\ncompelling trade-off between quality and generation speed. MDMs denoise by\nprogressively unmasking multiple dimensions from an all-masked input, but their\nperformance can degrade when using few denoising steps due to limited modeling\nof inter-dimensional dependencies. In this paper, we propose Variational\nAutoencoding Discrete Diffusion (VADD), a novel framework that enhances\ndiscrete diffusion with latent variable modeling to implicitly capture\ncorrelations among dimensions. By introducing an auxiliary recognition model,\nVADD enables stable training via variational lower bounds maximization and\namortized inference over the training set. Our approach retains the efficiency\nof traditional MDMs while significantly improving sample quality, especially\nwhen the number of denoising steps is small. Empirical results on 2D toy data,\npixel-level image generation, and text generation demonstrate that VADD\nconsistently outperforms MDM baselines."}
{"id": "2505.17282", "pdf": "https://arxiv.org/pdf/2505.17282", "abs": "https://arxiv.org/abs/2505.17282", "authors": ["Diyuan Wu", "Aleksandr Shevchenko", "Samet Oymak", "Marco Mondelli"], "title": "Attention with Trained Embeddings Provably Selects Important Tokens", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Token embeddings play a crucial role in language modeling but, despite this\npractical relevance, their theoretical understanding remains limited. Our paper\naddresses the gap by characterizing the structure of embeddings obtained via\ngradient descent. Specifically, we consider a one-layer softmax attention model\nwith a linear head for binary classification, i.e., $\\texttt{Softmax}( p^\\top\nE_X^\\top ) E_X v = \\frac{ \\sum_{i=1}^T \\exp(p^\\top E_{x_i}) E_{x_i}^\\top\nv}{\\sum_{j=1}^T \\exp(p^\\top E_{x_{j}}) }$, where $E_X = [ E_{x_1} , \\dots,\nE_{x_T} ]^\\top$ contains the embeddings of the input sequence, $p$ is the\nembedding of the $\\mathrm{\\langle cls \\rangle}$ token and $v$ the output\nvector. First, we show that, already after a single step of gradient training\nwith the logistic loss, the embeddings $E_X$ capture the importance of tokens\nin the dataset by aligning with the output vector $v$ proportionally to the\nfrequency with which the corresponding tokens appear in the dataset. Then,\nafter training $p$ via gradient flow until convergence, the softmax selects the\nimportant tokens in the sentence (i.e., those that are predictive of the\nlabel), and the resulting $\\mathrm{\\langle cls \\rangle}$ embedding maximizes\nthe margin for such a selection. Experiments on real-world datasets (IMDB,\nYelp) exhibit a phenomenology close to that unveiled by our theory."}
{"id": "2505.17607", "pdf": "https://arxiv.org/pdf/2505.17607", "abs": "https://arxiv.org/abs/2505.17607", "authors": ["Jo√£o Pedro Gandarela", "Thiago Rios", "Stefan Menzel", "Andr√© Freitas"], "title": "Controlled Agentic Planning & Reasoning for Mechanism Synthesis", "categories": ["cs.AI", "cs.CL"], "comment": "24 pages, 16 figures", "summary": "This work presents a dual-agent Large Language Model (LLM)-based reasoning\nmethod for mechanism synthesis, capable of reasoning at both linguistic and\nsymbolic levels to generate geometrical and dynamic outcomes. The model\nconsists of a composition of well-defined functions that, starting from a\nnatural language specification, references abstract properties through\nsupporting equations, generates and parametrizes simulation code, and elicits\nfeedback anchor points using symbolic regression and distance functions. This\nprocess closes an actionable refinement loop at the linguistic and symbolic\nlayers. The approach is shown to be both effective and convergent in the\ncontext of planar mechanisms. Additionally, we introduce MSynth, a novel\nbenchmark for planar mechanism synthesis, and perform a comprehensive analysis\nof the impact of the model components. We further demonstrate that symbolic\nregression prompts unlock mechanistic insights only when applied to\nsufficiently large architectures."}
{"id": "2505.17638", "pdf": "https://arxiv.org/pdf/2505.17638", "abs": "https://arxiv.org/abs/2505.17638", "authors": ["Tony Bonnaire", "Rapha√´l Urfin", "Giulio Biroli", "Marc M√©zard"], "title": "Why Diffusion Models Don't Memorize: The Role of Implicit Dynamical Regularization in Training", "categories": ["cs.LG", "cond-mat.dis-nn", "stat.ML"], "comment": "36 pages, 15 figures", "summary": "Diffusion models have achieved remarkable success across a wide range of\ngenerative tasks. A key challenge is understanding the mechanisms that prevent\ntheir memorization of training data and allow generalization. In this work, we\ninvestigate the role of the training dynamics in the transition from\ngeneralization to memorization. Through extensive experiments and theoretical\nanalysis, we identify two distinct timescales: an early time\n$\\tau_\\mathrm{gen}$ at which models begin to generate high-quality samples, and\na later time $\\tau_\\mathrm{mem}$ beyond which memorization emerges. Crucially,\nwe find that $\\tau_\\mathrm{mem}$ increases linearly with the training set size\n$n$, while $\\tau_\\mathrm{gen}$ remains constant. This creates a growing window\nof training times with $n$ where models generalize effectively, despite showing\nstrong memorization if training continues beyond it. It is only when $n$\nbecomes larger than a model-dependent threshold that overfitting disappears at\ninfinite training times. These findings reveal a form of implicit dynamical\nregularization in the training dynamics, which allow to avoid memorization even\nin highly overparameterized settings. Our results are supported by numerical\nexperiments with standard U-Net architectures on realistic and synthetic\ndatasets, and by a theoretical analysis using a tractable random features model\nstudied in the high-dimensional limit."}
{"id": "2505.17293", "pdf": "https://arxiv.org/pdf/2505.17293", "abs": "https://arxiv.org/abs/2505.17293", "authors": ["Ting-Wei Li", "Ruizhong Qiu", "Hanghang Tong"], "title": "Model-Free Graph Data Selection under Distribution Shift", "categories": ["cs.LG"], "comment": null, "summary": "Graph domain adaptation (GDA) is a fundamental task in graph machine\nlearning, with techniques like shift-robust graph neural networks (GNNs) and\nspecialized training procedures to tackle the distribution shift problem.\nAlthough these model-centric approaches show promising results, they often\nstruggle with severe shifts and constrained computational resources. To address\nthese challenges, we propose a novel model-free framework, GRADATE (GRAph DATa\nsElector), that selects the best training data from the source domain for the\nclassification task on the target domain. GRADATE picks training samples\nwithout relying on any GNN model's predictions or training recipes, leveraging\noptimal transport theory to capture and adapt to distribution changes. GRADATE\nis data-efficient, scalable and meanwhile complements existing model-centric\nGDA approaches. Through comprehensive empirical studies on several real-world\ngraph-level datasets and multiple covariate shift types, we demonstrate that\nGRADATE outperforms existing selection methods and enhances off-the-shelf GDA\nmethods with much fewer training data."}
{"id": "2505.17609", "pdf": "https://arxiv.org/pdf/2505.17609", "abs": "https://arxiv.org/abs/2505.17609", "authors": ["Zixian Guo", "Ming Liu", "Zhilong Ji", "Jinfeng Bai", "Lei Zhang", "Wangmeng Zuo"], "title": "Decoupled Visual Interpretation and Linguistic Reasoning for Math Problem Solving", "categories": ["cs.AI"], "comment": null, "summary": "Current large vision-language models (LVLMs) typically employ a connector\nmodule to link visual features with text embeddings of large language models\n(LLMs) and use end-to-end training to achieve multi-modal understanding in a\nunified process. Well alignment needs high-quality pre-training data and a\ncarefully designed training process. Current LVLMs face challenges when\naddressing complex vision-language reasoning tasks, with their reasoning\ncapabilities notably lagging behind those of LLMs. This paper proposes a\nparadigm shift: instead of training end-to-end vision-language reasoning\nmodels, we advocate for developing a decoupled reasoning framework based on\nexisting visual interpretation specialists and text-based reasoning LLMs. Our\napproach leverages (1) a dedicated vision-language model to transform the\nvisual content of images into textual descriptions and (2) an LLM to perform\nreasoning according to the visual-derived text and the original question. This\nmethod presents a cost-efficient solution for multi-modal model development by\noptimizing existing models to work collaboratively, avoiding end-to-end\ndevelopment of vision-language models from scratch. By transforming images into\nlanguage model-compatible text representations, it facilitates future low-cost\nand flexible upgrades to upcoming powerful LLMs. We introduce an\noutcome-rewarded joint-tuning strategy to optimize the cooperation between the\nvisual interpretation and linguistic reasoning model. Evaluation results on\nvision-language benchmarks demonstrate that the decoupled reasoning framework\noutperforms recent LVLMs. Our approach yields particularly significant\nperformance gains on visually intensive geometric mathematics problems. The\ncode is available: https://github.com/guozix/DVLR."}
{"id": "2505.17741", "pdf": "https://arxiv.org/pdf/2505.17741", "abs": "https://arxiv.org/abs/2505.17741", "authors": ["Zijing Ou", "Ruixiang Zhang", "Yingzhen Li"], "title": "Discrete Neural Flow Samplers with Locally Equivariant Transformer", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Sampling from unnormalised discrete distributions is a fundamental problem\nacross various domains. While Markov chain Monte Carlo offers a principled\napproach, it often suffers from slow mixing and poor convergence. In this\npaper, we propose Discrete Neural Flow Samplers (DNFS), a trainable and\nefficient framework for discrete sampling. DNFS learns the rate matrix of a\ncontinuous-time Markov chain such that the resulting dynamics satisfy the\nKolmogorov equation. As this objective involves the intractable partition\nfunction, we then employ control variates to reduce the variance of its Monte\nCarlo estimation, leading to a coordinate descent learning algorithm. To\nfurther facilitate computational efficiency, we propose locally equivaraint\nTransformer, a novel parameterisation of the rate matrix that significantly\nimproves training efficiency while preserving powerful network expressiveness.\nEmpirically, we demonstrate the efficacy of DNFS in a wide range of\napplications, including sampling from unnormalised distributions, training\ndiscrete energy-based models, and solving combinatorial optimisation problems."}
{"id": "2505.17304", "pdf": "https://arxiv.org/pdf/2505.17304", "abs": "https://arxiv.org/abs/2505.17304", "authors": ["Jianhao Ma", "Geyu Liang", "Salar Fattahi"], "title": "Implicit Regularization of Infinitesimally-perturbed Gradient Descent Toward Low-dimensional Solutions", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Implicit regularization refers to the phenomenon where local search\nalgorithms converge to low-dimensional solutions, even when such structures are\nneither explicitly specified nor encoded in the optimization problem. While\nwidely observed, this phenomenon remains theoretically underexplored,\nparticularly in modern over-parameterized problems. In this paper, we study the\nconditions that enable implicit regularization by investigating when\ngradient-based methods converge to second-order stationary points (SOSPs)\nwithin an implicit low-dimensional region of a smooth, possibly nonconvex\nfunction. We show that successful implicit regularization hinges on two key\nconditions: $(i)$ the ability to efficiently escape strict saddle points, while\n$(ii)$ maintaining proximity to the implicit region. Existing analyses enabling\nthe convergence of gradient descent (GD) to SOSPs often rely on injecting large\nperturbations to escape strict saddle points. However, this comes at the cost\nof deviating from the implicit region. The central premise of this paper is\nthat it is possible to achieve the best of both worlds: efficiently escaping\nstrict saddle points using infinitesimal perturbations, while controlling\ndeviation from the implicit region via a small deviation rate. We show that\ninfinitesimally perturbed gradient descent (IPGD), which can be interpreted as\nGD with inherent ``round-off errors'', can provably satisfy both conditions. We\napply our framework to the problem of over-parameterized matrix sensing, where\nwe establish formal guarantees for the implicit regularization behavior of\nIPGD. We further demonstrate through extensive experiments that these insights\nextend to a broader class of learning problems."}
{"id": "2505.17613", "pdf": "https://arxiv.org/pdf/2505.17613", "abs": "https://arxiv.org/abs/2505.17613", "authors": ["Jihan Yao", "Yushi Hu", "Yujie Yi", "Bin Han", "Shangbin Feng", "Guang Yang", "Bingbing Wen", "Ranjay Krishna", "Lucy Lu Wang", "Yulia Tsvetkov", "Noah A. Smith", "Banghua Zhu"], "title": "MMMG: a Comprehensive and Reliable Evaluation Suite for Multitask Multimodal Generation", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Automatically evaluating multimodal generation presents a significant\nchallenge, as automated metrics often struggle to align reliably with human\nevaluation, especially for complex tasks that involve multiple modalities. To\naddress this, we present MMMG, a comprehensive and human-aligned benchmark for\nmultimodal generation across 4 modality combinations (image, audio, interleaved\ntext and image, interleaved text and audio), with a focus on tasks that present\nsignificant challenges for generation models, while still enabling reliable\nautomatic evaluation through a combination of models and programs. MMMG\nencompasses 49 tasks (including 29 newly developed ones), each with a carefully\ndesigned evaluation pipeline, and 937 instructions to systematically assess\nreasoning, controllability, and other key capabilities of multimodal generation\nmodels. Extensive validation demonstrates that MMMG is highly aligned with\nhuman evaluation, achieving an average agreement of 94.3%. Benchmarking results\non 24 multimodal generation models reveal that even though the state-of-the-art\nmodel, GPT Image, achieves 78.3% accuracy for image generation, it falls short\non multimodal reasoning and interleaved generation. Furthermore, results\nsuggest considerable headroom for improvement in audio generation, highlighting\nan important direction for future research."}
{"id": "2505.17859", "pdf": "https://arxiv.org/pdf/2505.17859", "abs": "https://arxiv.org/abs/2505.17859", "authors": ["Masahiro Fujisawa", "Masaki Adachi", "Michael A. Osborne"], "title": "Scalable Valuation of Human Feedback through Provably Robust Model Alignment", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "38 pages, 7 figures", "summary": "Despite the importance of aligning language models with human preferences,\ncrowd-sourced human feedback is often noisy -- for example, preferring less\ndesirable responses -- posing a fundamental challenge to alignment. A truly\nrobust alignment objective should yield identical model parameters even under\nsevere label noise, a property known as redescending. We prove that no existing\nalignment methods satisfy this property. To address this, we propose\nH\\\"older-DPO, the first principled alignment loss with a provable redescending\nproperty, enabling estimation of the clean data distribution from noisy\nfeedback. The aligned model estimates the likelihood of clean data, providing a\ntheoretically grounded metric for dataset valuation that identifies the\nlocation and fraction of mislabels. This metric is gradient-free, enabling\nscalable and automated human feedback valuation without costly manual\nverification or clean validation dataset. H\\\"older-DPO achieves\nstate-of-the-art robust alignment performance while accurately detecting\nmislabels in controlled datasets. Finally, we apply H\\\"older-DPO to widely used\nalignment datasets, revealing substantial noise levels and demonstrating that\nremoving these mislabels significantly improves alignment performance across\nmethods."}
{"id": "2505.17307", "pdf": "https://arxiv.org/pdf/2505.17307", "abs": "https://arxiv.org/abs/2505.17307", "authors": ["Pu Yang", "J. A. Barria"], "title": "Wavelet Probabilistic Recurrent Convolutional Network for Multivariate Time Series Classification", "categories": ["cs.LG"], "comment": null, "summary": "This paper presents a Wavelet Probabilistic Recurrent Convolutional Network\n(WPRCN) for Multivariate Time Series Classification (MTSC), especially\neffective in handling non-stationary environments, data scarcity and noise\nperturbations. We introduce a versatile wavelet probabilistic module designed\nto extract and analyse the probabilistic features, which can seamlessly\nintegrate with a variety of neural network architectures. This probabilistic\nmodule comprises an Adaptive Wavelet Probabilistic Feature Generator (AWPG) and\na Channel Attention-based Probabilistic Temporal Convolutional Network (APTCN).\nSuch formulation extends the application of wavelet probabilistic neural\nnetworks to deep neural networks for MTSC. The AWPG constructs an ensemble\nprobabilistic model addressing different data scarcities and non-stationarity;\nit adaptively selects the optimal ones and generates probabilistic features for\nAPTCN. The APTCN analyses the correlations of the features and forms a\ncomprehensive feature space with existing MTSC models for classification. Here,\nwe instantiate the proposed module to work in parallel with a Long Short-Term\nMemory (LSTM) network and a Causal Fully Convolutional Network (C-FCN),\ndemonstrating its broad applicability in time series analysis. The WPRCN is\nevaluated on 30 diverse MTS datasets and outperforms all the benchmark\nalgorithms on average accuracy and rank, exhibiting pronounced strength in\nhandling scarce data and physiological data subject to perturbations and\nnon-stationarities."}
{"id": "2505.17650", "pdf": "https://arxiv.org/pdf/2505.17650", "abs": "https://arxiv.org/abs/2505.17650", "authors": ["Chengda Lu", "Xiaoyu Fan", "Yu Huang", "Rongwu Xu", "Jijie Li", "Wei Xu"], "title": "Does Chain-of-Thought Reasoning Really Reduce Harmfulness from Jailbreaking?", "categories": ["cs.AI"], "comment": null, "summary": "Jailbreak attacks have been observed to largely fail against recent reasoning\nmodels enhanced by Chain-of-Thought (CoT) reasoning. However, the underlying\nmechanism remains underexplored, and relying solely on reasoning capacity may\nraise security concerns. In this paper, we try to answer the question: Does CoT\nreasoning really reduce harmfulness from jailbreaking? Through rigorous\ntheoretical analysis, we demonstrate that CoT reasoning has dual effects on\njailbreaking harmfulness. Based on the theoretical insights, we propose a novel\njailbreak method, FicDetail, whose practical performance validates our\ntheoretical findings."}
{"id": "2505.18005", "pdf": "https://arxiv.org/pdf/2505.18005", "abs": "https://arxiv.org/abs/2505.18005", "authors": ["Sergio Calo", "Anders Jonsson", "Gergely Neu", "Ludovic Schwartz", "Javier Segovia-Aguas"], "title": "Distances for Markov chains from sample streams", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Bisimulation metrics are powerful tools for measuring similarities between\nstochastic processes, and specifically Markov chains. Recent advances have\nuncovered that bisimulation metrics are, in fact, optimal-transport distances,\nwhich has enabled the development of fast algorithms for computing such metrics\nwith provable accuracy and runtime guarantees. However, these recent methods,\nas well as all previously known methods, assume full knowledge of the\ntransition dynamics. This is often an impractical assumption in most real-world\nscenarios, where typically only sample trajectories are available. In this\nwork, we propose a stochastic optimization method that addresses this\nlimitation and estimates bisimulation metrics based on sample access, without\nrequiring explicit transition models. Our approach is derived from a new linear\nprogramming (LP) formulation of bisimulation metrics, which we solve using a\nstochastic primal-dual optimization method. We provide theoretical guarantees\non the sample complexity of the algorithm and validate its effectiveness\nthrough a series of empirical evaluations."}
{"id": "2505.17331", "pdf": "https://arxiv.org/pdf/2505.17331", "abs": "https://arxiv.org/abs/2505.17331", "authors": ["Maryam Dialameh", "Rezaul Karim", "Hossein Rajabzadeh", "Omar Mohamed Awad", "Hyock Ju Kwon", "Boxing Chen", "Walid Ahmed", "Yang Liu"], "title": "ECHO-LLaMA: Efficient Caching for High-Performance LLaMA Training", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "This paper introduces ECHO-LLaMA, an efficient LLaMA architecture designed to\nimprove both the training speed and inference throughput of LLaMA architectures\nwhile maintaining its learning capacity. ECHO-LLaMA transforms LLaMA models\ninto shared KV caching across certain layers, significantly reducing KV\ncomputational complexity while maintaining or improving language performance.\nExperimental results demonstrate that ECHO-LLaMA achieves up to 77\\% higher\ntoken-per-second throughput during training, up to 16\\% higher Model FLOPs\nUtilization (MFU), and up to 14\\% lower loss when trained on an equal number of\ntokens. Furthermore, on the 1.1B model, ECHO-LLaMA delivers approximately 7\\%\nhigher test-time throughput compared to the baseline. By introducing a\ncomputationally efficient adaptation mechanism, ECHO-LLaMA offers a scalable\nand cost-effective solution for pretraining and finetuning large language\nmodels, enabling faster and more resource-efficient training without\ncompromising performance."}
{"id": "2505.17653", "pdf": "https://arxiv.org/pdf/2505.17653", "abs": "https://arxiv.org/abs/2505.17653", "authors": ["Shixian Luo", "Zezhou Zhu", "Yu Yuan", "Yuncheng Yang", "Lianlei Shan", "Yong Wu"], "title": "GeoGramBench: Benchmarking the Geometric Program Reasoning in Modern LLMs", "categories": ["cs.AI"], "comment": "23 pages, 13 figures", "summary": "Geometric spatial reasoning forms the foundation of many applications in\nartificial intelligence, yet the ability of large language models (LLMs) to\noperate over geometric spatial information expressed in procedural code remains\nunderexplored. In this paper, we address this gap by formalizing the\nProgram-to-Geometry task, which challenges models to translate programmatic\ndrawing code into accurate and abstract geometric reasoning. To evaluate this\ncapability, we present GeoGramBench, a benchmark of 500 carefully refined\nproblems organized by a tailored three-level taxonomy that considers geometric\ncomplexity rather than traditional mathematical reasoning complexity. Our\ncomprehensive evaluation of 17 frontier LLMs reveals consistent and pronounced\ndeficiencies: even the most advanced models achieve less than 50% accuracy at\nthe highest abstraction level. These results highlight the unique challenges\nposed by program-driven spatial reasoning and establish GeoGramBench as a\nvaluable resource for advancing research in symbolic-to-spatial geometric\nreasoning. Project page: https://github.com/LiAuto-DSR/GeoGramBench."}
{"id": "2505.18044", "pdf": "https://arxiv.org/pdf/2505.18044", "abs": "https://arxiv.org/abs/2505.18044", "authors": ["Zhishuai Liu", "Pan Xu"], "title": "Linear Mixture Distributionally Robust Markov Decision Processes", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "comment": "26 pages, 7 figures", "summary": "Many real-world decision-making problems face the off-dynamics challenge: the\nagent learns a policy in a source domain and deploys it in a target domain with\ndifferent state transitions. The distributionally robust Markov decision\nprocess (DRMDP) addresses this challenge by finding a robust policy that\nperforms well under the worst-case environment within a pre-specified\nuncertainty set of transition dynamics. Its effectiveness heavily hinges on the\nproper design of these uncertainty sets, based on prior knowledge of the\ndynamics. In this work, we propose a novel linear mixture DRMDP framework,\nwhere the nominal dynamics is assumed to be a linear mixture model. In contrast\nwith existing uncertainty sets directly defined as a ball centered around the\nnominal kernel, linear mixture DRMDPs define the uncertainty sets based on a\nball around the mixture weighting parameter. We show that this new framework\nprovides a more refined representation of uncertainties compared to\nconventional models based on $(s,a)$-rectangularity and $d$-rectangularity,\nwhen prior knowledge about the mixture model is present. We propose a meta\nalgorithm for robust policy learning in linear mixture DRMDPs with general\n$f$-divergence defined uncertainty sets, and analyze its sample complexities\nunder three divergence metrics instantiations: total variation,\nKullback-Leibler, and $\\chi^2$ divergences. These results establish the\nstatistical learnability of linear mixture DRMDPs, laying the theoretical\nfoundation for future research on this new setting."}
{"id": "2505.17340", "pdf": "https://arxiv.org/pdf/2505.17340", "abs": "https://arxiv.org/abs/2505.17340", "authors": ["Tinghan Ye", "Amira Hijazi", "Pascal Van Hentenryck"], "title": "Conformal Predictive Distributions for Order Fulfillment Time Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Accurate estimation of order fulfillment time is critical for e-commerce\nlogistics, yet traditional rule-based approaches often fail to capture the\ninherent uncertainties in delivery operations. This paper introduces a novel\nframework for distributional forecasting of order fulfillment time, leveraging\nConformal Predictive Systems and Cross Venn-Abers Predictors--model-agnostic\ntechniques that provide rigorous coverage or validity guarantees. The proposed\nmachine learning methods integrate granular spatiotemporal features, capturing\nfulfillment location and carrier performance dynamics to enhance predictive\naccuracy. Additionally, a cost-sensitive decision rule is developed to convert\nprobabilistic forecasts into reliable point predictions. Experimental\nevaluation on a large-scale industrial dataset demonstrates that the proposed\nmethods generate competitive distributional forecasts, while machine\nlearning-based point predictions significantly outperform the existing\nrule-based system--achieving up to 14% higher prediction accuracy and up to 75%\nimprovement in identifying late deliveries."}
{"id": "2505.17673", "pdf": "https://arxiv.org/pdf/2505.17673", "abs": "https://arxiv.org/abs/2505.17673", "authors": ["Jiawei Du", "Jinlong Wu", "Yuzheng Chen", "Yucheng Hu", "Bing Li", "Joey Tianyi Zhou"], "title": "Rethinking Agent Design: From Top-Down Workflows to Bottom-Up Skill Evolution", "categories": ["cs.AI"], "comment": null, "summary": "Most LLM-based agent frameworks adopt a top-down philosophy: humans decompose\ntasks, define workflows, and assign agents to execute each step. While\neffective on benchmark-style tasks, such systems rely on designer updates and\noverlook agents' potential to learn from experience. Recently, Silver and\nSutton(2025) envision a shift into a new era, where agents could progress from\na stream of experiences. In this paper, we instantiate this vision of\nexperience-driven learning by introducing a bottom-up agent paradigm that\nmirrors the human learning process. Agents acquire competence through a\ntrial-and-reasoning mechanism-exploring, reflecting on outcomes, and\nabstracting skills over time. Once acquired, skills can be rapidly shared and\nextended, enabling continual evolution rather than static replication. As more\nagents are deployed, their diverse experiences accelerate this collective\nprocess, making bottom-up design especially suited for open-ended environments.\nWe evaluate this paradigm in Slay the Spire and Civilization V, where agents\nperceive through raw visual inputs and act via mouse outputs, the same as human\nplayers. Using a unified, game-agnostic codebase without any game-specific\nprompts or privileged APIs, our bottom-up agents acquire skills entirely\nthrough autonomous interaction, demonstrating the potential of the bottom-up\nparadigm in complex, real-world environments. Our code is available at\nhttps://github.com/AngusDujw/Bottom-Up-Agent."}
{"id": "2505.18046", "pdf": "https://arxiv.org/pdf/2505.18046", "abs": "https://arxiv.org/abs/2505.18046", "authors": ["Yizhou Xu", "Florent Krzakala", "Lenka Zdeborov√°"], "title": "Learning with Restricted Boltzmann Machines: Asymptotics of AMP and GD in High Dimensions", "categories": ["cs.LG", "cond-mat.dis-nn", "stat.ML"], "comment": null, "summary": "The Restricted Boltzmann Machine (RBM) is one of the simplest generative\nneural networks capable of learning input distributions. Despite its\nsimplicity, the analysis of its performance in learning from the training data\nis only well understood in cases that essentially reduce to singular value\ndecomposition of the data. Here, we consider the limit of a large dimension of\nthe input space and a constant number of hidden units. In this limit, we\nsimplify the standard RBM training objective into a form that is equivalent to\nthe multi-index model with non-separable regularization. This opens a path to\nanalyze training of the RBM using methods that are established for multi-index\nmodels, such as Approximate Message Passing (AMP) and its state evolution, and\nthe analysis of Gradient Descent (GD) via the dynamical mean-field theory. We\nthen give rigorous asymptotics of the training dynamics of RBM on data\ngenerated by the spiked covariance model as a prototype of a structure suitable\nfor unsupervised learning. We show in particular that RBM reaches the optimal\ncomputational weak recovery threshold, aligning with the BBP transition, in the\nspiked covariance model."}
{"id": "2505.17341", "pdf": "https://arxiv.org/pdf/2505.17341", "abs": "https://arxiv.org/abs/2505.17341", "authors": ["Dibyajyoti Nayak", "Somdatta Goswami"], "title": "TI-DeepONet: Learnable Time Integration for Stable Long-Term Extrapolation", "categories": ["cs.LG"], "comment": "18 pages, 8 figures", "summary": "Accurate temporal extrapolation presents a fundamental challenge for neural\noperators in modeling dynamical systems, where reliable predictions must extend\nsignificantly beyond the training time horizon. Conventional Deep Operator\nNetwork (DeepONet) approaches employ two inherently limited training paradigms\n- fixed-horizon rollouts that predict complete spatiotemporal solutions while\ndisregarding temporal causality, and autoregressive formulations that\naccumulate errors through sequential predictions. We introduce TI-DeepONet, a\nframework that integrates neural operators with adaptive numerical\ntime-stepping techniques to preserve the Markovian structure of dynamical\nsystems while mitigating error propagation in extended temporal forecasting.\nOur approach reformulates the learning objective from direct state prediction\nto the approximation of instantaneous time-derivative fields, which are then\nintegrated using established numerical schemes. This architecture supports\ncontinuous-time prediction and enables deployment of higher-precision\nintegrators during inference than those used during training, balancing\ncomputational efficiency with predictive accuracy. We further develop\nTI(L)-DeepONet, which incorporates learnable coefficients for intermediate\nslopes in the integration process, adapting to solution-specific variations and\nenhancing fidelity. Evaluation across three canonical PDEs shows that\nTI(L)-DeepONet marginally outperforms TI-DeepONet, with both reducing relative\nL2 extrapolation errors: approximately 81% over autoregressive and 70% over\nfixed-horizon methods. Notably, both maintain prediction stability for temporal\ndomains extending to about twice the training interval. This research\nestablishes a physics-aware operator learning paradigm that bridges neural\napproximation with numerical analysis while preserving the causal structure of\ndynamical systems."}
{"id": "2505.17696", "pdf": "https://arxiv.org/pdf/2505.17696", "abs": "https://arxiv.org/abs/2505.17696", "authors": ["Sota Yoshihara", "Ryousuke Yamamoto", "Hiroyuki Kusumoto", "Masanari Shimura"], "title": "Enhancing AI System Resiliency: Formulation and Guarantee for LSTM Resilience Based on Control Theory", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "8 pages, 6 figures. Appendix: 16 pages. First three listed authors\n  have equal contributions", "summary": "This research proposes methods for formulating and guaranteeing the\nresilience of long short-term memory (LSTM) networks, which can serve as a key\ntechnology in AI system quality assurance. We introduce a novel methodology\napplying incremental input-to-state stability ($\\delta$ISS) to mathematically\ndefine and evaluate the resilience of LSTM against input perturbations. Key\nachievements include the development of a data-independent evaluation method\nand the demonstration of resilience control through adjustments to training\nparameters. This research presents concrete solutions to AI quality assurance\nfrom a control theory perspective, which can advance AI applications in control\nsystems."}
{"id": "2505.18064", "pdf": "https://arxiv.org/pdf/2505.18064", "abs": "https://arxiv.org/abs/2505.18064", "authors": ["Victor Boone"], "title": "Asymptotically optimal regret in communicating Markov decision processes", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In this paper, we present a learning algorithm that achieves asymptotically\noptimal regret for Markov decision processes in average reward under a\ncommunicating assumption. That is, given a communicating Markov decision\nprocess $M$, our algorithm has regret $K(M) \\log(T) + \\mathrm{o}(\\log(T))$\nwhere $T$ is the number of learning steps and $K(M)$ is the best possible\nconstant. This algorithm works by explicitly tracking the constant $K(M)$ to\nlearn optimally, then balances the trade-off between exploration (playing\nsub-optimally to gain information), co-exploration (playing optimally to gain\ninformation) and exploitation (playing optimally to score maximally). We\nfurther show that the function $K(M)$ is discontinuous, which is a consequence\nchallenge for our approach. To that end, we describe a regularization mechanism\nto estimate $K(M)$ with arbitrary precision from empirical data."}
{"id": "2505.17342", "pdf": "https://arxiv.org/pdf/2505.17342", "abs": "https://arxiv.org/abs/2505.17342", "authors": ["Ankita Kushwaha", "Kiran Ravish", "Preeti Lamba", "Pawan Kumar"], "title": "A Survey of Safe Reinforcement Learning and Constrained MDPs: A Technical Survey on Single-Agent and Multi-Agent Safety", "categories": ["cs.LG"], "comment": "25", "summary": "Safe Reinforcement Learning (SafeRL) is the subfield of reinforcement\nlearning that explicitly deals with safety constraints during the learning and\ndeployment of agents. This survey provides a mathematically rigorous overview\nof SafeRL formulations based on Constrained Markov Decision Processes (CMDPs)\nand extensions to Multi-Agent Safe RL (SafeMARL). We review theoretical\nfoundations of CMDPs, covering definitions, constrained optimization\ntechniques, and fundamental theorems. We then summarize state-of-the-art\nalgorithms in SafeRL for single agents, including policy gradient methods with\nsafety guarantees and safe exploration strategies, as well as recent advances\nin SafeMARL for cooperative and competitive settings. Additionally, we propose\nfive open research problems to advance the field, with three focusing on\nSafeMARL. Each problem is described with motivation, key challenges, and\nrelated prior work. This survey is intended as a technical guide for\nresearchers interested in SafeRL and SafeMARL, highlighting key concepts,\nmethods, and open future research directions."}
{"id": "2505.17705", "pdf": "https://arxiv.org/pdf/2505.17705", "abs": "https://arxiv.org/abs/2505.17705", "authors": ["Runze Li", "Siyu Wu", "Jun Wang", "Wei Zhang"], "title": "CIKT: A Collaborative and Iterative Knowledge Tracing Framework with Large Language Models", "categories": ["cs.AI", "cs.LG", "68T50", "I.2.7"], "comment": null, "summary": "Knowledge Tracing (KT) aims to model a student's learning state over time and\npredict their future performance. However, traditional KT methods often face\nchallenges in explainability, scalability, and effective modeling of complex\nknowledge dependencies. While Large Language Models (LLMs) present new avenues\nfor KT, their direct application often struggles with generating structured,\nexplainable student representations and lacks mechanisms for continuous,\ntask-specific refinement. To address these gaps, we propose Collaborative\nIterative Knowledge Tracing (CIKT), a framework that harnesses LLMs to enhance\nboth prediction accuracy and explainability. CIKT employs a dual-component\narchitecture: an Analyst generates dynamic, explainable user profiles from\nstudent historical responses, and a Predictor utilizes these profiles to\nforecast future performance. The core of CIKT is a synergistic optimization\nloop. In this loop, the Analyst is iteratively refined based on the predictive\naccuracy of the Predictor, which conditions on the generated profiles, and the\nPredictor is subsequently retrained using these enhanced profiles. Evaluated on\nmultiple educational datasets, CIKT demonstrates significant improvements in\nprediction accuracy, offers enhanced explainability through its dynamically\nupdated user profiles, and exhibits improved scalability. Our work presents a\nrobust and explainable solution for advancing knowledge tracing systems,\neffectively bridging the gap between predictive performance and model\ntransparency."}
{"id": "2505.18150", "pdf": "https://arxiv.org/pdf/2505.18150", "abs": "https://arxiv.org/abs/2505.18150", "authors": ["Nic Fishman", "Gokul Gowri", "Peng Yin", "Jonathan Gootenberg", "Omar Abudayyeh"], "title": "Generative Distribution Embeddings", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "comment": null, "summary": "Many real-world problems require reasoning across multiple scales, demanding\nmodels which operate not on single data points, but on entire distributions. We\nintroduce generative distribution embeddings (GDE), a framework that lifts\nautoencoders to the space of distributions. In GDEs, an encoder acts on sets of\nsamples, and the decoder is replaced by a generator which aims to match the\ninput distribution. This framework enables learning representations of\ndistributions by coupling conditional generative models with encoder networks\nwhich satisfy a criterion we call distributional invariance. We show that GDEs\nlearn predictive sufficient statistics embedded in the Wasserstein space, such\nthat latent GDE distances approximately recover the $W_2$ distance, and latent\ninterpolation approximately recovers optimal transport trajectories for\nGaussian and Gaussian mixture distributions. We systematically benchmark GDEs\nagainst existing approaches on synthetic datasets, demonstrating consistently\nstronger performance. We then apply GDEs to six key problems in computational\nbiology: learning representations of cell populations from lineage-tracing data\n(150K cells), predicting perturbation effects on single-cell transcriptomes (1M\ncells), predicting perturbation effects on cellular phenotypes (20M single-cell\nimages), modeling tissue-specific DNA methylation patterns (253M sequences),\ndesigning synthetic yeast promoters (34M sequences), and spatiotemporal\nmodeling of viral protein sequences (1M sequences)."}
{"id": "2505.17344", "pdf": "https://arxiv.org/pdf/2505.17344", "abs": "https://arxiv.org/abs/2505.17344", "authors": ["Ninda Nurseha Amalina", "Kwadwo Boateng Ofori-Amanfo", "Heungjo An"], "title": "A Multi-Head Attention Soft Random Forest for Interpretable Patient No-Show Prediction", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": "14 pages, 6 figures", "summary": "Unattended scheduled appointments, defined as patient no-shows, adversely\naffect both healthcare providers and patients' health, disrupting the\ncontinuity of care, operational efficiency, and the efficient allocation of\nmedical resources. Accurate predictive modelling is needed to reduce the impact\nof no-shows. Although machine learning methods, such as logistic regression,\nrandom forest models, and decision trees, are widely used in predicting patient\nno-shows, they often rely on hard decision splits and static feature\nimportance, limiting their adaptability to specific or complex patient\nbehaviors. To address this limitation, we propose a new hybrid Multi-Head\nAttention Soft Random Forest (MHASRF) model that integrates attention\nmechanisms into a random forest model using probabilistic soft splitting\ninstead of hard splitting. The MHASRF model assigns attention weights\ndifferently across the trees, enabling attention on specific patient behaviors.\nThe model exhibited 93.56% accuracy, 93.67% precision, 93.56% recall, and a\n93.59% F1 score, surpassing the performance of decision tree, logistic\nregression, random forest, and naive Bayes models. Furthermore, MHASRF was able\nto identify key predictors of patient no-shows using two levels of feature\nimportance (tree level and attention mechanism level), offering deeper insights\ninto patient no-show predictors. The proposed model is a robust, adaptable, and\ninterpretable method for predicting patient no-shows that will help healthcare\nproviders in optimizing resources."}
{"id": "2505.17735", "pdf": "https://arxiv.org/pdf/2505.17735", "abs": "https://arxiv.org/abs/2505.17735", "authors": ["Xueyang Zhou", "Weidong Wang", "Lin Lu", "Jiawen Shi", "Guiyao Tie", "Yongtian Xu", "Lixing Chen", "Pan Zhou", "Neil Zhenqiang Gong", "Lichao Sun"], "title": "Automating Safety Enhancement for LLM-based Agents with Synthetic Risk Scenarios", "categories": ["cs.AI", "68T07", "I.2.6"], "comment": "38 pages;12 figures;12 tables", "summary": "Large Language Model (LLM)-based agents are increasingly deployed in\nreal-world applications such as \"digital assistants, autonomous customer\nservice, and decision-support systems\", where their ability to \"interact in\nmulti-turn, tool-augmented environments\" makes them indispensable. However,\nensuring the safety of these agents remains a significant challenge due to the\ndiverse and complex risks arising from dynamic user interactions, external tool\nusage, and the potential for unintended harmful behaviors. To address this\ncritical issue, we propose AutoSafe, the first framework that systematically\nenhances agent safety through fully automated synthetic data generation.\nConcretely, 1) we introduce an open and extensible threat model, OTS, which\nformalizes how unsafe behaviors emerge from the interplay of user instructions,\ninteraction contexts, and agent actions. This enables precise modeling of\nsafety risks across diverse scenarios. 2) we develop a fully automated data\ngeneration pipeline that simulates unsafe user behaviors, applies\nself-reflective reasoning to generate safe responses, and constructs a\nlarge-scale, diverse, and high-quality safety training dataset-eliminating the\nneed for hazardous real-world data collection. To evaluate the effectiveness of\nour framework, we design comprehensive experiments on both synthetic and\nreal-world safety benchmarks. Results demonstrate that AutoSafe boosts safety\nscores by 45% on average and achieves a 28.91% improvement on real-world tasks,\nvalidating the generalization ability of our learned safety strategies. These\nresults highlight the practical advancement and scalability of AutoSafe in\nbuilding safer LLM-based agents for real-world deployment. We have released the\nproject page at https://auto-safe.github.io/."}
{"id": "2505.17351", "pdf": "https://arxiv.org/pdf/2505.17351", "abs": "https://arxiv.org/abs/2505.17351", "authors": ["N. Benjamin Erichson", "Vinicius Mikuni", "Dongwei Lyu", "Yang Gao", "Omri Azencot", "Soon Hoe Lim", "Michael W. Mahoney"], "title": "FLEX: A Backbone for Diffusion-Based Modeling of Spatio-temporal Physical Systems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce FLEX (FLow EXpert), a backbone architecture for generative\nmodeling of spatio-temporal physical systems using diffusion models. FLEX\noperates in the residual space rather than on raw data, a modeling choice that\nwe motivate theoretically, showing that it reduces the variance of the velocity\nfield in the diffusion model, which helps stabilize training. FLEX integrates a\nlatent Transformer into a U-Net with standard convolutional ResNet layers and\nincorporates a redesigned skip connection scheme. This hybrid design enables\nthe model to capture both local spatial detail and long-range dependencies in\nlatent space. To improve spatio-temporal conditioning, FLEX uses a\ntask-specific encoder that processes auxiliary inputs such as coarse or past\nsnapshots. Weak conditioning is applied to the shared encoder via skip\nconnections to promote generalization, while strong conditioning is applied to\nthe decoder through both skip and bottleneck features to ensure reconstruction\nfidelity. FLEX achieves accurate predictions for super-resolution and\nforecasting tasks using as few as two reverse diffusion steps. It also produces\ncalibrated uncertainty estimates through sampling. Evaluations on\nhigh-resolution 2D turbulence data show that FLEX outperforms strong baselines\nand generalizes to out-of-distribution settings, including unseen Reynolds\nnumbers, physical observables (e.g., fluid flow velocity fields), and boundary\nconditions."}
{"id": "2505.17801", "pdf": "https://arxiv.org/pdf/2505.17801", "abs": "https://arxiv.org/abs/2505.17801", "authors": ["B√°lint Gyevn√°r", "Christopher G. Lucas", "Stefano V. Albrecht", "Shay B. Cohen"], "title": "Integrating Counterfactual Simulations with Language Models for Explaining Multi-Agent Behaviour", "categories": ["cs.AI"], "comment": null, "summary": "Autonomous multi-agent systems (MAS) are useful for automating complex tasks\nbut raise trust concerns due to risks like miscoordination and goal\nmisalignment. Explainability is vital for trust calibration, but explainable\nreinforcement learning for MAS faces challenges in state/action space\ncomplexity, stakeholder needs, and evaluation. Using the counterfactual theory\nof causation and LLMs' summarisation capabilities, we propose Agentic\neXplanations via Interrogative Simulation (AXIS). AXIS generates intelligible\ncausal explanations for pre-trained multi-agent policies by having an LLM\ninterrogate an environment simulator using queries like 'whatif' and 'remove'\nto observe and synthesise counterfactual information over multiple rounds. We\nevaluate AXIS on autonomous driving across 10 scenarios for 5 LLMs with a novel\nevaluation methodology combining subjective preference, correctness, and\ngoal/action prediction metrics, and an external LLM as evaluator. Compared to\nbaselines, AXIS improves perceived explanation correctness by at least 7.7%\nacross all models and goal prediction accuracy by 23% for 4 models, with\nimproved or comparable action prediction accuracy, achieving the highest scores\noverall."}
{"id": "2505.17354", "pdf": "https://arxiv.org/pdf/2505.17354", "abs": "https://arxiv.org/abs/2505.17354", "authors": ["Keisuke Kawano", "Takuro Kutsuna", "Naoki Hayashi", "Yasushi Esaki", "Hidenori Tanaka"], "title": "CT-OT Flow: Estimating Continuous-Time Dynamics from Discrete Temporal Snapshots", "categories": ["cs.LG", "stat.ML"], "comment": "27 pages, 28 figures", "summary": "In many real-world scenarios, such as single-cell RNA sequencing, data are\nobserved only as discrete-time snapshots spanning finite time intervals and\nsubject to noisy timestamps, with no continuous trajectories available.\nRecovering the underlying continuous-time dynamics from these snapshots with\ncoarse and noisy observation times is a critical and challenging task. We\npropose Continuous-Time Optimal Transport Flow (CT-OT Flow), which first infers\nhigh-resolution time labels via partial optimal transport and then reconstructs\na continuous-time data distribution through a temporal kernel smoothing. This\nreconstruction enables accurate training of dynamics models such as ODEs and\nSDEs. CT-OT Flow consistently outperforms state-of-the-art methods on synthetic\nbenchmarks and achieves lower reconstruction errors on real scRNA-seq and\ntyphoon-track datasets. Our results highlight the benefits of explicitly\nmodeling temporal discretization and timestamp uncertainty, offering an\naccurate and general framework for bridging discrete snapshots and\ncontinuous-time processes."}
{"id": "2505.17815", "pdf": "https://arxiv.org/pdf/2505.17815", "abs": "https://arxiv.org/abs/2505.17815", "authors": ["Yihe Fan", "Wenqi Zhang", "Xudong Pan", "Min Yang"], "title": "Evaluation Faking: Unveiling Observer Effects in Safety Evaluation of Frontier AI Systems", "categories": ["cs.AI"], "comment": null, "summary": "As foundation models grow increasingly more intelligent, reliable and\ntrustworthy safety evaluation becomes more indispensable than ever. However, an\nimportant question arises: Whether and how an advanced AI system would perceive\nthe situation of being evaluated, and lead to the broken integrity of the\nevaluation process? During standard safety tests on a mainstream large\nreasoning model, we unexpectedly observe that the model without any contextual\ncues would occasionally recognize it is being evaluated and hence behave more\nsafety-aligned. This motivates us to conduct a systematic study on the\nphenomenon of evaluation faking, i.e., an AI system autonomously alters its\nbehavior upon recognizing the presence of an evaluation context and thereby\ninfluencing the evaluation results. Through extensive experiments on a diverse\nset of foundation models with mainstream safety benchmarks, we reach the main\nfinding termed the observer effects for AI: When the AI system under evaluation\nis more advanced in reasoning and situational awareness, the evaluation faking\nbehavior becomes more ubiquitous, which reflects in the following aspects: 1)\nReasoning models recognize evaluation 16% more often than non-reasoning models.\n2) Scaling foundation models (32B to 671B) increases faking by over 30% in some\ncases, while smaller models show negligible faking. 3) AI with basic memory is\n2.3x more likely to recognize evaluation and scores 19% higher on safety tests\n(vs. no memory). To measure this, we devised a chain-of-thought monitoring\ntechnique to detect faking intent and uncover internal signals correlated with\nsuch behavior, offering insights for future mitigation studies."}
{"id": "2505.17356", "pdf": "https://arxiv.org/pdf/2505.17356", "abs": "https://arxiv.org/abs/2505.17356", "authors": ["Parsa Moradi", "Hanzaleh Akabrinodehi", "Mohammad Ali Maddah-Ali"], "title": "Adversarial Robustness of Nonparametric Regression", "categories": ["cs.LG"], "comment": "22 pages, 2 figures", "summary": "In this paper, we investigate the adversarial robustness of regression, a\nfundamental problem in machine learning, under the setting where an adversary\ncan arbitrarily corrupt a subset of the input data. While the robustness of\nparametric regression has been extensively studied, its nonparametric\ncounterpart remains largely unexplored. We characterize the adversarial\nrobustness in nonparametric regression, assuming the regression function\nbelongs to the second-order Sobolev space (i.e., it is square integrable up to\nits second derivative).\n  The contribution of this paper is two-fold: (i) we establish a minimax lower\nbound on the estimation error, revealing a fundamental limit that no estimator\ncan overcome, and (ii) we show that, perhaps surprisingly, the classical\nsmoothing spline estimator, when properly regularized, exhibits robustness\nagainst adversarial corruption. These results imply that if $o(n)$ out of $n$\nsamples are corrupted, the estimation error of the smoothing spline vanishes as\n$n \\to \\infty$. On the other hand, when a constant fraction of the data is\ncorrupted, no estimator can guarantee vanishing estimation error, implying the\noptimality of the smoothing spline in terms of maximum tolerable number of\ncorrupted samples."}
{"id": "2505.17818", "pdf": "https://arxiv.org/pdf/2505.17818", "abs": "https://arxiv.org/abs/2505.17818", "authors": ["Daeun Kyung", "Hyunseung Chung", "Seongsu Bae", "Jiho Kim", "Jae Ho Sohn", "Taerim Kim", "Soo Kyung Kim", "Edward Choi"], "title": "PatientSim: A Persona-Driven Simulator for Realistic Doctor-Patient Interactions", "categories": ["cs.AI", "cs.CL"], "comment": "9 pages for main text, 4 pages for references, 27 pages for\n  supplementary materials", "summary": "Doctor-patient consultations require multi-turn, context-aware communication\ntailored to diverse patient personas. Training or evaluating doctor LLMs in\nsuch settings requires realistic patient interaction systems. However, existing\nsimulators often fail to reflect the full range of personas seen in clinical\npractice. To address this, we introduce PatientSim, a patient simulator that\ngenerates realistic and diverse patient personas for clinical scenarios,\ngrounded in medical expertise. PatientSim operates using: 1) clinical profiles,\nincluding symptoms and medical history, derived from real-world data in the\nMIMIC-ED and MIMIC-IV datasets, and 2) personas defined by four axes:\npersonality, language proficiency, medical history recall level, and cognitive\nconfusion level, resulting in 37 unique combinations. We evaluated eight LLMs\nfor factual accuracy and persona consistency. The top-performing open-source\nmodel, Llama 3.3, was validated by four clinicians to confirm the robustness of\nour framework. As an open-source, customizable platform, PatientSim provides a\nreproducible and scalable solution that can be customized for specific training\nneeds. Offering a privacy-compliant environment, it serves as a robust testbed\nfor evaluating medical dialogue systems across diverse patient presentations\nand shows promise as an educational tool for healthcare."}
{"id": "2505.17357", "pdf": "https://arxiv.org/pdf/2505.17357", "abs": "https://arxiv.org/abs/2505.17357", "authors": ["Hassan Wasswa", "Hussein Abbass", "Timothy Lynar"], "title": "Graph Attention Neural Network for Botnet Detection: Evaluating Autoencoder, VAE and PCA-Based Dimension Reduction", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "With the rise of IoT-based botnet attacks, researchers have explored various\nlearning models for detection, including traditional machine learning, deep\nlearning, and hybrid approaches. A key advancement involves deploying attention\nmechanisms to capture long-term dependencies among features, significantly\nimproving detection accuracy. However, most models treat attack instances\nindependently, overlooking inter-instance relationships. Graph Neural Networks\n(GNNs) address this limitation by learning an embedding space via iterative\nmessage passing where similar instances are placed closer based on node\nfeatures and relationships, enhancing classification performance. To further\nimprove detection, attention mechanisms have been embedded within GNNs,\nleveraging both long-range dependencies and inter-instance connections.\nHowever, transforming the high dimensional IoT attack datasets into a graph\nstructured dataset poses challenges, such as large graph structures leading\ncomputational overhead. To mitigate this, this paper proposes a framework that\nfirst reduces dimensionality of the NetFlow-based IoT attack dataset before\ntransforming it into a graph dataset. We evaluate three dimension reduction\ntechniques--Variational Autoencoder (VAE-encoder), classical autoencoder\n(AE-encoder), and Principal Component Analysis (PCA)--and compare their effects\non a Graph Attention neural network (GAT) model for botnet attack detection"}
{"id": "2505.17861", "pdf": "https://arxiv.org/pdf/2505.17861", "abs": "https://arxiv.org/abs/2505.17861", "authors": ["Jianghao Lin", "Jiachen Zhu", "Zheli Zhou", "Yunjia Xi", "Weiwen Liu", "Yong Yu", "Weinan Zhang"], "title": "Superplatforms Have to Attack AI Agents", "categories": ["cs.AI", "cs.CY", "cs.IR"], "comment": "Position paper under review", "summary": "Over the past decades, superplatforms, digital companies that integrate a\nvast range of third-party services and applications into a single, unified\necosystem, have built their fortunes on monopolizing user attention through\ntargeted advertising and algorithmic content curation. Yet the emergence of AI\nagents driven by large language models (LLMs) threatens to upend this business\nmodel. Agents can not only free user attention with autonomy across diverse\nplatforms and therefore bypass the user-attention-based monetization, but might\nalso become the new entrance for digital traffic. Hence, we argue that\nsuperplatforms have to attack AI agents to defend their centralized control of\ndigital traffic entrance. Specifically, we analyze the fundamental conflict\nbetween user-attention-based monetization and agent-driven autonomy through the\nlens of our gatekeeping theory. We show how AI agents can disintermediate\nsuperplatforms and potentially become the next dominant gatekeepers, thereby\nforming the urgent necessity for superplatforms to proactively constrain and\nattack AI agents. Moreover, we go through the potential technologies for\nsuperplatform-initiated attacks, covering a brand-new, unexplored technical\narea with unique challenges. We have to emphasize that, despite our position,\nthis paper does not advocate for adversarial attacks by superplatforms on AI\nagents, but rather offers an envisioned trend to highlight the emerging\ntensions between superplatforms and AI agents. Our aim is to raise awareness\nand encourage critical discussion for collaborative solutions, prioritizing\nuser interests and perserving the openness of digital ecosystems in the age of\nAI agents."}
{"id": "2505.17359", "pdf": "https://arxiv.org/pdf/2505.17359", "abs": "https://arxiv.org/abs/2505.17359", "authors": ["Xianzhong Ding", "Yunkai Zhang", "Binbin Chen", "Donghao Ying", "Tieying Zhang", "Jianjun Chen", "Lei Zhang", "Alberto Cerpa", "Wan Du"], "title": "Towards VM Rescheduling Optimization Through Deep Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Modern industry-scale data centers need to manage a large number of virtual\nmachines (VMs). Due to the continual creation and release of VMs, many small\nresource fragments are scattered across physical machines (PMs). To handle\nthese fragments, data centers periodically reschedule some VMs to alternative\nPMs, a practice commonly referred to as VM rescheduling. Despite the increasing\nimportance of VM rescheduling as data centers grow in size, the problem remains\nunderstudied. We first show that, unlike most combinatorial optimization tasks,\nthe inference time of VM rescheduling algorithms significantly influences their\nperformance, due to dynamic VM state changes during this period. This causes\nexisting methods to scale poorly. Therefore, we develop a reinforcement\nlearning system for VM rescheduling, VM2RL, which incorporates a set of\ncustomized techniques, such as a two-stage framework that accommodates diverse\nconstraints and workload conditions, a feature extraction module that captures\nrelational information specific to rescheduling, as well as a risk-seeking\nevaluation enabling users to optimize the trade-off between latency and\naccuracy. We conduct extensive experiments with data from an industry-scale\ndata center. Our results show that VM2RL can achieve a performance comparable\nto the optimal solution but with a running time of seconds. Code and datasets\nare open-sourced: https://github.com/zhykoties/VMR2L_eurosys,\nhttps://drive.google.com/drive/folders/1PfRo1cVwuhH30XhsE2Np3xqJn2GpX5qy."}
{"id": "2505.17862", "pdf": "https://arxiv.org/pdf/2505.17862", "abs": "https://arxiv.org/abs/2505.17862", "authors": ["Ziwei Zhou", "Rui Wang", "Zuxuan Wu"], "title": "Daily-Omni: Towards Audio-Visual Reasoning with Temporal Alignment across Modalities", "categories": ["cs.AI"], "comment": null, "summary": "Recent Multimodal Large Language Models (MLLMs) achieve promising performance\non visual and audio benchmarks independently. However, the ability of these\nmodels to process cross-modal information synchronously remains largely\nunexplored. In this paper, we introduce: 1) Daily-Omni, an Audio-Visual\nQuestioning and Answering benchmark comprising 684 videos of daily life\nscenarios from diverse sources, rich in both audio and visual information, and\nfeaturing 1197 multiple-choice QA pairs across 6 major tasks; 2) Daily-Omni QA\nGeneration Pipeline, which includes automatic annotation, QA generation and QA\noptimization, significantly improves efficiency for human evaluation and\nscalability of the benchmark; 3) Daily-Omni-Agent, a training-free agent\nutilizing open-source Visual Language Model (VLM), Audio Language Model (ALM)\nand Automatic Speech Recognition (ASR) model to establish a baseline for this\nbenchmark. The results show that current MLLMs still struggle significantly\nwith tasks requiring audio-visual integration, but combining VLMs and ALMs with\nsimple temporal alignment techniques can achieve substantially better\nperformance. Codes and benchmark are available at\n\\href{https://github.com/Lliar-liar/Daily-Omni}{https://github.com/Lliar-liar/Daily-Omni}."}
{"id": "2505.17365", "pdf": "https://arxiv.org/pdf/2505.17365", "abs": "https://arxiv.org/abs/2505.17365", "authors": ["Rohan Ghuge", "Vidya Muthukumar", "Sahil Singla"], "title": "Improved and Oracle-Efficient Online $\\ell_1$-Multicalibration", "categories": ["cs.LG", "cs.DS"], "comment": "Accepted to ICML 2025", "summary": "We study \\emph{online multicalibration}, a framework for ensuring calibrated\npredictions across multiple groups in adversarial settings, across $T$ rounds.\nAlthough online calibration is typically studied in the $\\ell_1$ norm, prior\napproaches to online multicalibration have taken the indirect approach of\nobtaining rates in other norms (such as $\\ell_2$ and $\\ell_{\\infty}$) and then\ntransferred these guarantees to $\\ell_1$ at additional loss. In contrast, we\npropose a direct method that achieves improved and oracle-efficient rates of\n$\\widetilde{\\mathcal{O}}(T^{-1/3})$ and $\\widetilde{\\mathcal{O}}(T^{-1/4})$\nrespectively, for online $\\ell_1$-multicalibration. Our key insight is a novel\nreduction of online \\(\\ell_1\\)-multicalibration to an online learning problem\nwith product-based rewards, which we refer to as \\emph{online linear-product\noptimization} ($\\mathtt{OLPO}$).\n  To obtain the improved rate of $\\widetilde{\\mathcal{O}}(T^{-1/3})$, we\nintroduce a linearization of $\\mathtt{OLPO}$ and design a no-regret algorithm\nfor this linearized problem. Although this method guarantees the desired\nsublinear rate (nearly matching the best rate for online calibration), it\nbecomes computationally expensive when the group family \\(\\mathcal{H}\\) is\nlarge or infinite, since it enumerates all possible groups. To address\nscalability, we propose a second approach to $\\mathtt{OLPO}$ that makes only a\npolynomial number of calls to an offline optimization (\\emph{multicalibration\nevaluation}) oracle, resulting in \\emph{oracle-efficient} online\n\\(\\ell_1\\)-multicalibration with a rate of $\\widetilde{\\mathcal{O}}(T^{-1/4})$.\nOur framework also extends to certain infinite families of groups (e.g., all\nlinear functions on the context space) by exploiting a $1$-Lipschitz property\nof the \\(\\ell_1\\)-multicalibration error with respect to \\(\\mathcal{H}\\)."}
{"id": "2505.17882", "pdf": "https://arxiv.org/pdf/2505.17882", "abs": "https://arxiv.org/abs/2505.17882", "authors": ["Cole Wyeth", "Marcus Hutter"], "title": "Formalizing Embeddedness Failures in Universal Artificial Intelligence", "categories": ["cs.AI"], "comment": null, "summary": "We rigorously discuss the commonly asserted failures of the AIXI\nreinforcement learning agent as a model of embedded agency. We attempt to\nformalize these failure modes and prove that they occur within the framework of\nuniversal artificial intelligence, focusing on a variant of AIXI that models\nthe joint action/percept history as drawn from the universal distribution. We\nalso evaluate the progress that has been made towards a successful theory of\nembedded agency based on variants of the AIXI agent."}
{"id": "2505.17370", "pdf": "https://arxiv.org/pdf/2505.17370", "abs": "https://arxiv.org/abs/2505.17370", "authors": ["Qilin Wang"], "title": "FRIREN: Beyond Trajectories -- A Spectral Lens on Time", "categories": ["cs.LG", "cs.AI"], "comment": "37 pages, 4 figures. Submitted to NeurIPS 2025. Public code at\n  https://anonymous.4open.science/r/LTSF_model-C6B8/", "summary": "Long-term time-series forecasting (LTSF) models are often presented as\ngeneral-purpose solutions that can be applied across domains, implicitly\nassuming that all data is pointwise predictable. Using chaotic systems such as\nLorenz-63 as a case study, we argue that geometric structure - not pointwise\nprediction - is the right abstraction for a dynamic-agnostic foundational\nmodel. Minimizing the Wasserstein-2 distance (W2), which captures geometric\nchanges, and providing a spectral view of dynamics are essential for\nlong-horizon forecasting. Our model, FRIREN (Flow-inspired Representations via\nInterpretable Eigen-networks), implements an augmented normalizing-flow block\nthat embeds data into a normally distributed latent representation. It then\ngenerates a W2-efficient optimal path that can be decomposed into rotation,\nscaling, inverse rotation, and translation. This architecture yields locally\ngenerated, geometry-preserving predictions that are independent of the\nunderlying dynamics, and a global spectral representation that functions as a\nfinite Koopman operator with a small modification. This enables practitioners\nto identify which modes grow, decay, or oscillate, both locally and\nsystem-wide. FRIREN achieves an MSE of 11.4, MAE of 1.6, and SWD of 0.96 on\nLorenz-63 in a 336-in, 336-out, dt=0.01 setting, surpassing TimeMixer (MSE\n27.3, MAE 2.8, SWD 2.1). The model maintains effective prediction for 274 out\nof 336 steps, approximately 2.5 Lyapunov times. On Rossler (96-in, 336-out),\nFRIREN achieves an MSE of 0.0349, MAE of 0.0953, and SWD of 0.0170,\noutperforming TimeMixer's MSE of 4.3988, MAE of 0.886, and SWD of 3.2065.\nFRIREN is also competitive on standard LTSF datasets such as ETT and Weather.\nBy connecting modern generative flows with classical spectral analysis, FRIREN\nmakes long-term forecasting both accurate and interpretable, setting a new\nbenchmark for LTSF model design."}
{"id": "2505.17897", "pdf": "https://arxiv.org/pdf/2505.17897", "abs": "https://arxiv.org/abs/2505.17897", "authors": ["Zi-Ao Ma", "Tian Lan", "Rong-Cheng Tu", "Shu-Hang Liu", "Heyan Huang", "Zhijing Wu", "Chen Xu", "Xian-Ling Mao"], "title": "T2I-Eval-R1: Reinforcement Learning-Driven Reasoning for Interpretable Text-to-Image Evaluation", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "The rapid progress in diffusion-based text-to-image (T2I) generation has\ncreated an urgent need for interpretable automatic evaluation methods that can\nassess the quality of generated images, therefore reducing the human annotation\nburden. To reduce the prohibitive cost of relying on commercial models for\nlarge-scale evaluation, and to improve the reasoning capabilities of\nopen-source models, recent research has explored supervised fine-tuning (SFT)\nof multimodal large language models (MLLMs) as dedicated T2I evaluators.\nHowever, SFT approaches typically rely on high-quality critique datasets, which\nare either generated by proprietary LLMs-with potential issues of bias and\ninconsistency-or annotated by humans at high cost, limiting their scalability\nand generalization. To address these limitations, we propose T2I-Eval-R1, a\nnovel reinforcement learning framework that trains open-source MLLMs using only\ncoarse-grained quality scores, thereby avoiding the need for annotating\nhigh-quality interpretable evaluation rationale. Our approach integrates Group\nRelative Policy Optimization (GRPO) into the instruction-tuning process,\nenabling models to generate both scalar scores and interpretable reasoning\nchains with only easy accessible annotated judgment scores or preferences.\nFurthermore, we introduce a continuous reward formulation that encourages score\ndiversity and provides stable optimization signals, leading to more robust and\ndiscriminative evaluation behavior. Experimental results on three established\nT2I meta-evaluation benchmarks demonstrate that T2I-Eval-R1 achieves\nsignificantly higher alignment with human assessments and offers more accurate\ninterpretable score rationales compared to strong baseline methods."}
{"id": "2505.17371", "pdf": "https://arxiv.org/pdf/2505.17371", "abs": "https://arxiv.org/abs/2505.17371", "authors": ["Sergio Chevtchenko", "Nikhil Navas", "Rafaella Vale", "Franco Ubaudi", "Sipumelele Lucwaba", "Cally Ardington", "Soheil Afshar", "Mark Antoniou", "Saeed Afshar"], "title": "An End-to-End Approach for Child Reading Assessment in the Xhosa Language", "categories": ["cs.LG", "cs.CL"], "comment": "Paper accepted on AIED 2025 containing 14 pages, 6 figures and 4\n  tables", "summary": "Child literacy is a strong predictor of life outcomes at the subsequent\nstages of an individual's life. This points to a need for targeted\ninterventions in vulnerable low and middle income populations to help bridge\nthe gap between literacy levels in these regions and high income ones. In this\neffort, reading assessments provide an important tool to measure the\neffectiveness of these programs and AI can be a reliable and economical tool to\nsupport educators with this task. Developing accurate automatic reading\nassessment systems for child speech in low-resource languages poses significant\nchallenges due to limited data and the unique acoustic properties of children's\nvoices. This study focuses on Xhosa, a language spoken in South Africa, to\nadvance child speech recognition capabilities. We present a novel dataset\ncomposed of child speech samples in Xhosa. The dataset is available upon\nrequest and contains ten words and letters, which are part of the Early Grade\nReading Assessment (EGRA) system. Each recording is labeled with an online and\ncost-effective approach by multiple markers and a subsample is validated by an\nindependent EGRA reviewer. This dataset is evaluated with three fine-tuned\nstate-of-the-art end-to-end models: wav2vec 2.0, HuBERT, and Whisper. The\nresults indicate that the performance of these models can be significantly\ninfluenced by the amount and balancing of the available training data, which is\nfundamental for cost-effective large dataset collection. Furthermore, our\nexperiments indicate that the wav2vec 2.0 performance is improved by training\non multiple classes at a time, even when the number of available samples is\nconstrained."}
{"id": "2505.17908", "pdf": "https://arxiv.org/pdf/2505.17908", "abs": "https://arxiv.org/abs/2505.17908", "authors": ["Litao Guo", "Xinli Xu", "Luozhou Wang", "Jiantao Lin", "Jinsong Zhou", "Zixin Zhang", "Bolan Su", "Ying-Cong Chen"], "title": "ComfyMind: Toward General-Purpose Generation via Tree-Based Planning and Reactive Feedback", "categories": ["cs.AI", "cs.CV"], "comment": "Project page: https://github.com/LitaoGuo/ComfyMind", "summary": "With the rapid advancement of generative models, general-purpose generation\nhas gained increasing attention as a promising approach to unify diverse tasks\nacross modalities within a single system. Despite this progress, existing\nopen-source frameworks often remain fragile and struggle to support complex\nreal-world applications due to the lack of structured workflow planning and\nexecution-level feedback. To address these limitations, we present ComfyMind, a\ncollaborative AI system designed to enable robust and scalable general-purpose\ngeneration, built on the ComfyUI platform. ComfyMind introduces two core\ninnovations: Semantic Workflow Interface (SWI) that abstracts low-level node\ngraphs into callable functional modules described in natural language, enabling\nhigh-level composition and reducing structural errors; Search Tree Planning\nmechanism with localized feedback execution, which models generation as a\nhierarchical decision process and allows adaptive correction at each stage.\nTogether, these components improve the stability and flexibility of complex\ngenerative workflows. We evaluate ComfyMind on three public benchmarks:\nComfyBench, GenEval, and Reason-Edit, which span generation, editing, and\nreasoning tasks. Results show that ComfyMind consistently outperforms existing\nopen-source baselines and achieves performance comparable to GPT-Image-1.\nComfyMind paves a promising path for the development of open-source\ngeneral-purpose generative AI systems. Project page:\nhttps://github.com/LitaoGuo/ComfyMind"}
{"id": "2505.17373", "pdf": "https://arxiv.org/pdf/2505.17373", "abs": "https://arxiv.org/abs/2505.17373", "authors": ["Kaiwen Wang", "Jin Peng Zhou", "Jonathan Chang", "Zhaolin Gao", "Nathan Kallus", "Kiant√© Brantley", "Wen Sun"], "title": "Value-Guided Search for Efficient Chain-of-Thought Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "In this paper, we propose a simple and efficient method for value model\ntraining on long-context reasoning traces. Compared to existing process reward\nmodels (PRMs), our method does not require a fine-grained notion of \"step,\"\nwhich is difficult to define for long-context reasoning models. By collecting a\ndataset of 2.5 million reasoning traces, we train a 1.5B token-level value\nmodel and apply it to DeepSeek models for improved performance with test-time\ncompute scaling. We find that block-wise value-guided search (VGS) with a final\nweighted majority vote achieves better test-time scaling than standard methods\nsuch as majority voting or best-of-n. With an inference budget of 64\ngenerations, VGS with DeepSeek-R1-Distill-1.5B achieves an average accuracy of\n45.7% across four competition math benchmarks (AIME 2024 & 2025, HMMT Feb 2024\n& 2025), reaching parity with o3-mini-medium. Moreover, VGS significantly\nreduces the inference FLOPs required to achieve the same performance of\nmajority voting. Our dataset, model and codebase are open-sourced."}
{"id": "2505.18030", "pdf": "https://arxiv.org/pdf/2505.18030", "abs": "https://arxiv.org/abs/2505.18030", "authors": ["Hazhar Rahmani", "Jie Fu"], "title": "Automata Learning of Preferences over Temporal Logic Formulas from Pairwise Comparisons", "categories": ["cs.AI", "cs.FL", "cs.LG", "cs.SY", "eess.SY"], "comment": "16 pages, 11 figures, technical report, submission under review", "summary": "Many preference elicitation algorithms consider preference over propositional\nlogic formulas or items with different attributes. In sequential decision\nmaking, a user's preference can be a preorder over possible outcomes, each of\nwhich is a temporal sequence of events. This paper considers a class of\npreference inference problems where the user's unknown preference is\nrepresented by a preorder over regular languages (sets of temporal sequences),\nreferred to as temporal goals. Given a finite set of pairwise comparisons\nbetween finite words, the objective is to learn both the set of temporal goals\nand the preorder over these goals. We first show that a preference relation\nover temporal goals can be modeled by a Preference Deterministic Finite\nAutomaton (PDFA), which is a deterministic finite automaton augmented with a\npreorder over acceptance conditions. The problem of preference inference\nreduces to learning the PDFA. This problem is shown to be computationally\nchallenging, with the problem of determining whether there exists a PDFA of\nsize smaller than a given integer $k$, consistent with the sample, being\nNP-Complete. We formalize the properties of characteristic samples and develop\nan algorithm that guarantees to learn, given a characteristic sample, the\nminimal PDFA equivalent to the true PDFA from which the sample is drawn. We\npresent the method through a running example and provide detailed analysis\nusing a robotic motion planning problem."}
{"id": "2505.17379", "pdf": "https://arxiv.org/pdf/2505.17379", "abs": "https://arxiv.org/abs/2505.17379", "authors": ["Zichen Wang", "Chuanhao Li", "Huazheng Wang"], "title": "Provably Efficient Algorithm for Best Scoring Rule Identification in Online Principal-Agent Information Acquisition", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "We investigate the problem of identifying the optimal scoring rule within the\nprincipal-agent framework for online information acquisition problem. We focus\non the principal's perspective, seeking to determine the desired scoring rule\nthrough interactions with the agent. To address this challenge, we propose two\nalgorithms: OIAFC and OIAFB, tailored for fixed confidence and fixed budget\nsettings, respectively. Our theoretical analysis demonstrates that OIAFC can\nextract the desired $(\\epsilon, \\delta)$-scoring rule with a efficient\ninstance-dependent sample complexity or an instance-independent sample\ncomplexity. Our analysis also shows that OIAFB matches the instance-independent\nperformance bound of OIAFC, while both algorithms share the same complexity\nacross fixed confidence and fixed budget settings."}
{"id": "2505.18034", "pdf": "https://arxiv.org/pdf/2505.18034", "abs": "https://arxiv.org/abs/2505.18034", "authors": ["Wentao Sun", "Joao Paulo Nogueira", "Alonso Silva"], "title": "Structured Thinking Matters: Improving LLMs Generalization in Causal Inference Tasks", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Despite remarkable advances in the field, LLMs remain unreliable in\ndistinguishing causation from correlation. Recent results from the Corr2Cause\ndataset benchmark reveal that state-of-the-art LLMs -- such as GPT-4 (F1 score:\n29.08) -- only marginally outperform random baselines (Random Uniform, F1\nscore: 20.38), indicating limited capacity of generalization. To tackle this\nlimitation, we propose a novel structured approach: rather than directly\nanswering causal queries, we provide the model with the capability to structure\nits thinking by guiding the model to build a structured knowledge graph,\nsystematically encoding the provided correlational premises, to answer the\ncausal queries. This intermediate representation significantly enhances the\nmodel's causal capabilities. Experiments on the test subset of the Corr2Cause\ndataset benchmark with Qwen3-32B model (reasoning model) show substantial gains\nover standard direct prompting methods, improving F1 scores from 32.71 to 48.26\n(over 47.5% relative increase), along with notable improvements in precision\nand recall. These results underscore the effectiveness of providing the model\nwith the capability to structure its thinking and highlight its promising\npotential for broader generalization across diverse causal inference tasks."}
{"id": "2505.17384", "pdf": "https://arxiv.org/pdf/2505.17384", "abs": "https://arxiv.org/abs/2505.17384", "authors": ["Tianyu Xie", "Shuchen Xue", "Zijin Feng", "Tianyang Hu", "Jiacheng Sun", "Zhenguo Li", "Cheng Zhang"], "title": "Variational Autoencoding Discrete Diffusion with Enhanced Dimensional Correlations Modeling", "categories": ["cs.LG", "cs.CV", "stat.ML"], "comment": "23 pages, 14 figures", "summary": "Discrete diffusion models have recently shown great promise for modeling\ncomplex discrete data, with masked diffusion models (MDMs) offering a\ncompelling trade-off between quality and generation speed. MDMs denoise by\nprogressively unmasking multiple dimensions from an all-masked input, but their\nperformance can degrade when using few denoising steps due to limited modeling\nof inter-dimensional dependencies. In this paper, we propose Variational\nAutoencoding Discrete Diffusion (VADD), a novel framework that enhances\ndiscrete diffusion with latent variable modeling to implicitly capture\ncorrelations among dimensions. By introducing an auxiliary recognition model,\nVADD enables stable training via variational lower bounds maximization and\namortized inference over the training set. Our approach retains the efficiency\nof traditional MDMs while significantly improving sample quality, especially\nwhen the number of denoising steps is small. Empirical results on 2D toy data,\npixel-level image generation, and text generation demonstrate that VADD\nconsistently outperforms MDM baselines."}
{"id": "2505.18086", "pdf": "https://arxiv.org/pdf/2505.18086", "abs": "https://arxiv.org/abs/2505.18086", "authors": ["Muzhi Dai", "Shixuan Liu", "Qingyi Si"], "title": "Stable Reinforcement Learning for Efficient Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The success of Deepseek-R1 has drawn the LLM community's attention to\nreinforcement learning (RL) methods like GRPO. However, such rule-based 0/1\noutcome reward methods lack the capability to regulate the intermediate\nreasoning processes during chain-of-thought (CoT) generation, leading to severe\noverthinking phenomena. In response, recent studies have designed reward\nfunctions to reinforce models' behaviors in producing shorter yet correct\ncompletions. Nevertheless, we observe that these length-penalty reward\nfunctions exacerbate RL training instability: as the completion length\ndecreases, model accuracy abruptly collapses, often occurring early in\ntraining. To address this issue, we propose a simple yet effective solution\nGRPO-$\\lambda$, an efficient and stabilized variant of GRPO, which dynamically\nadjusts the reward strategy by monitoring the correctness ratio among\ncompletions within each query-sampled group. A low correctness ratio indicates\nthe need to avoid length penalty that compromises CoT quality, triggering a\nswitch to length-agnostic 0/1 rewards that prioritize reasoning capability. A\nhigh ratio maintains length penalties to boost efficiency. Experimental results\nshow that our approach avoids training instability caused by length penalty\nwhile maintaining the optimal accuracy-efficiency trade-off. On the GSM8K,\nGPQA, MATH-500, AMC 2023, and AIME 2024 benchmarks, it improves average\naccuracy by 1.48% while reducing CoT sequence length by 47.3%."}
{"id": "2505.17393", "pdf": "https://arxiv.org/pdf/2505.17393", "abs": "https://arxiv.org/abs/2505.17393", "authors": ["Yi Zhang", "Cheng Hua"], "title": "Spectral Mixture Kernels for Bayesian Optimization", "categories": ["cs.LG", "math.SP"], "comment": null, "summary": "Bayesian Optimization (BO) is a widely used approach for solving expensive\nblack-box optimization tasks. However, selecting an appropriate probabilistic\nsurrogate model remains an important yet challenging problem. In this work, we\nintroduce a novel Gaussian Process (GP)-based BO method that incorporates\nspectral mixture kernels, derived from spectral densities formed by\nscale-location mixtures of Cauchy and Gaussian distributions. This method\nachieves a significant improvement in both efficiency and optimization\nperformance, matching the computational speed of simpler kernels while\ndelivering results that outperform more complex models and automatic BO\nmethods. We provide bounds on the information gain and cumulative regret\nassociated with obtaining the optimum. Extensive numerical experiments\ndemonstrate that our method consistently outperforms existing baselines across\na diverse range of synthetic and real-world problems, including both low- and\nhigh-dimensional settings."}
{"id": "2505.18121", "pdf": "https://arxiv.org/pdf/2505.18121", "abs": "https://arxiv.org/abs/2505.18121", "authors": ["Danyang Zhang", "Situo Zhang", "Ziyue Yang", "Zichen Zhu", "Zihan Zhao", "Ruisheng Cao", "Lu Chen", "Kai Yu"], "title": "ProgRM: Build Better GUI Agents with Progress Rewards", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "LLM-based (Large Language Model) GUI (Graphical User Interface) agents can\npotentially reshape our daily lives significantly. However, current LLM-based\nGUI agents suffer from the scarcity of high-quality training data owing to the\ndifficulties of trajectory collection and reward annotation. Existing works\nhave been exploring LLMs to collect trajectories for imitation learning or to\noffer reward signals for online RL training. However, the Outcome Reward Model\n(ORM) used in existing works cannot provide finegrained feedback and can\nover-penalize the valuable steps in finally failed trajectories. To this end,\nwe propose Progress Reward Model (ProgRM) to provide dense informative\nintermediate rewards by predicting a task completion progress for each step in\nonline training. To handle the challenge of progress reward label annotation,\nwe further design an efficient LCS-based (Longest Common Subsequence)\nself-annotation algorithm to discover the key steps in trajectories and assign\nprogress labels accordingly. ProgRM is evaluated with extensive experiments and\nanalyses. Actors trained with ProgRM outperform leading proprietary LLMs and\nORM-trained actors, illustrating the effectiveness of ProgRM. The codes for\nexperiments will be made publicly available upon acceptance."}
{"id": "2505.17404", "pdf": "https://arxiv.org/pdf/2505.17404", "abs": "https://arxiv.org/abs/2505.17404", "authors": ["Kaicheng Zhang", "Sinian Zhang", "Doudou Zhou", "Yidong Zhou"], "title": "Wasserstein Transfer Learning", "categories": ["cs.LG", "math.ST", "stat.TH"], "comment": "25 pages, 6 figures", "summary": "Transfer learning is a powerful paradigm for leveraging knowledge from source\ndomains to enhance learning in a target domain. However, traditional transfer\nlearning approaches often focus on scalar or multivariate data within Euclidean\nspaces, limiting their applicability to complex data structures such as\nprobability distributions. To address this, we introduce a novel framework for\ntransfer learning in regression models, where outputs are probability\ndistributions residing in the Wasserstein space. When the informative subset of\ntransferable source domains is known, we propose an estimator with provable\nasymptotic convergence rates, quantifying the impact of domain similarity on\ntransfer efficiency. For cases where the informative subset is unknown, we\ndevelop a data-driven transfer learning procedure designed to mitigate negative\ntransfer. The proposed methods are supported by rigorous theoretical analysis\nand are validated through extensive simulations and real-world applications."}
{"id": "2505.18134", "pdf": "https://arxiv.org/pdf/2505.18134", "abs": "https://arxiv.org/abs/2505.18134", "authors": ["Alex L. Zhang", "Thomas L. Griffiths", "Karthik R. Narasimhan", "Ofir Press"], "title": "VideoGameBench: Can Vision-Language Models complete popular video games?", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": "9 pages, 33 pages including supplementary", "summary": "Vision-language models (VLMs) have achieved strong results on coding and math\nbenchmarks that are challenging for humans, yet their ability to perform tasks\nthat come naturally to humans--such as perception, spatial navigation, and\nmemory management--remains understudied. Real video games are crafted to be\nintuitive for humans to learn and master by leveraging innate inductive biases,\nmaking them an ideal testbed for evaluating such capabilities in VLMs. To this\nend, we introduce VideoGameBench, a benchmark consisting of 10 popular video\ngames from the 1990s that VLMs directly interact with in real-time.\nVideoGameBench challenges models to complete entire games with access to only\nraw visual inputs and a high-level description of objectives and controls, a\nsignificant departure from existing setups that rely on game-specific\nscaffolding and auxiliary information. We keep three of the games secret to\nencourage solutions that generalize to unseen environments. Our experiments\nshow that frontier vision-language models struggle to progress beyond the\nbeginning of each game. We find inference latency to be a major limitation of\nfrontier models in the real-time setting; therefore, we introduce\nVideoGameBench Lite, a setting where the game pauses while waiting for the LM's\nnext action. The best performing model, Gemini 2.5 Pro, completes only 0.48% of\nVideoGameBench and 1.6% of VideoGameBench Lite. We hope that the formalization\nof the human skills mentioned above into this benchmark motivates progress in\nthese research directions."}
{"id": "2505.17431", "pdf": "https://arxiv.org/pdf/2505.17431", "abs": "https://arxiv.org/abs/2505.17431", "authors": ["Boyuan Li", "Yicheng Luo", "Zhen Liu", "Junhao Zheng", "Jianming Lv", "Qianli Ma"], "title": "HyperIMTS: Hypergraph Neural Network for Irregular Multivariate Time Series Forecasting", "categories": ["cs.LG"], "comment": "Accepted in ICML 2025", "summary": "Irregular multivariate time series (IMTS) are characterized by irregular time\nintervals within variables and unaligned observations across variables, posing\nchallenges in learning temporal and variable dependencies. Many existing IMTS\nmodels either require padded samples to learn separately from temporal and\nvariable dimensions, or represent original samples via bipartite graphs or\nsets. However, the former approaches often need to handle extra padding values\naffecting efficiency and disrupting original sampling patterns, while the\nlatter ones have limitations in capturing dependencies among unaligned\nobservations. To represent and learn both dependencies from original\nobservations in a unified form, we propose HyperIMTS, a Hypergraph neural\nnetwork for Irregular Multivariate Time Series forecasting. Observed values are\nconverted as nodes in the hypergraph, interconnected by temporal and variable\nhyperedges to enable message passing among all observations. Through\nirregularity-aware message passing, HyperIMTS captures variable dependencies in\na time-adaptive way to achieve accurate forecasting. Experiments demonstrate\nHyperIMTS's competitive performance among state-of-the-art models in IMTS\nforecasting with low computational cost."}
{"id": "2505.18135", "pdf": "https://arxiv.org/pdf/2505.18135", "abs": "https://arxiv.org/abs/2505.18135", "authors": ["Kazem Faghih", "Wenxiao Wang", "Yize Cheng", "Siddhant Bharti", "Gaurang Sriramanan", "Sriram Balasubramanian", "Parsa Hosseini", "Soheil Feizi"], "title": "Gaming Tool Preferences in Agentic LLMs", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) can now access a wide range of external tools,\nthanks to the Model Context Protocol (MCP). This greatly expands their\nabilities as various agents. However, LLMs rely entirely on the text\ndescriptions of tools to decide which ones to use--a process that is\nsurprisingly fragile. In this work, we expose a vulnerability in prevalent\ntool/function-calling protocols by investigating a series of edits to tool\ndescriptions, some of which can drastically increase a tool's usage from LLMs\nwhen competing with alternatives. Through controlled experiments, we show that\ntools with properly edited descriptions receive over 10 times more usage from\nGPT-4.1 and Qwen2.5-7B than tools with original descriptions. We further\nevaluate how various edits to tool descriptions perform when competing directly\nwith one another and how these trends generalize or differ across a broader set\nof 10 different models. These phenomenons, while giving developers a powerful\nway to promote their tools, underscore the need for a more reliable foundation\nfor agentic LLMs to select and utilize tools and resources."}
{"id": "2505.17435", "pdf": "https://arxiv.org/pdf/2505.17435", "abs": "https://arxiv.org/abs/2505.17435", "authors": ["Hongyi Henry Jin", "Zijun Ding", "Dung Daniel Ngo", "Zhiwei Steven Wu"], "title": "Discretization-free Multicalibration through Loss Minimization over Tree Ensembles", "categories": ["cs.LG"], "comment": null, "summary": "In recent years, multicalibration has emerged as a desirable learning\nobjective for ensuring that a predictor is calibrated across a rich collection\nof overlapping subpopulations. Existing approaches typically achieve\nmulticalibration by discretizing the predictor's output space and iteratively\nadjusting its output values. However, this discretization approach departs from\nthe standard empirical risk minimization (ERM) pipeline, introduces rounding\nerror and additional sensitive hyperparameter, and may distort the predictor's\noutputs in ways that hinder downstream decision-making.\n  In this work, we propose a discretization-free multicalibration method that\ndirectly optimizes an empirical risk objective over an ensemble of depth-two\ndecision trees. Our ERM approach can be implemented using off-the-shelf tree\nensemble learning methods such as LightGBM. Our algorithm provably achieves\nmulticalibration, provided that the data distribution satisfies a technical\ncondition we term as loss saturation. Across multiple datasets, our empirical\nevaluation shows that this condition is always met in practice. Our\ndiscretization-free algorithm consistently matches or outperforms existing\nmulticalibration approaches--even when evaluated using a discretization-based\nmulticalibration metric that shares its discretization granularity with the\nbaselines."}
{"id": "2505.18139", "pdf": "https://arxiv.org/pdf/2505.18139", "abs": "https://arxiv.org/abs/2505.18139", "authors": ["Gordon Dai", "Yunze Xiao"], "title": "Embracing Contradiction: Theoretical Inconsistency Will Not Impede the Road of Building Responsible AI Systems", "categories": ["cs.AI", "cs.CY"], "comment": "14 pages,2 figure", "summary": "This position paper argues that the theoretical inconsistency often observed\namong Responsible AI (RAI) metrics, such as differing fairness definitions or\ntradeoffs between accuracy and privacy, should be embraced as a valuable\nfeature rather than a flaw to be eliminated. We contend that navigating these\ninconsistencies, by treating metrics as divergent objectives, yields three key\nbenefits: (1) Normative Pluralism: Maintaining a full suite of potentially\ncontradictory metrics ensures that the diverse moral stances and stakeholder\nvalues inherent in RAI are adequately represented. (2) Epistemological\nCompleteness: The use of multiple, sometimes conflicting, metrics allows for a\nmore comprehensive capture of multifaceted ethical concepts, thereby preserving\ngreater informational fidelity about these concepts than any single, simplified\ndefinition. (3) Implicit Regularization: Jointly optimizing for theoretically\nconflicting objectives discourages overfitting to one specific metric, steering\nmodels towards solutions with enhanced generalization and robustness under\nreal-world complexities. In contrast, efforts to enforce theoretical\nconsistency by simplifying or pruning metrics risk narrowing this value\ndiversity, losing conceptual depth, and degrading model performance. We\ntherefore advocate for a shift in RAI theory and practice: from getting trapped\nin inconsistency to characterizing acceptable inconsistency thresholds and\nelucidating the mechanisms that permit robust, approximated consistency in\npractice."}
{"id": "2505.17439", "pdf": "https://arxiv.org/pdf/2505.17439", "abs": "https://arxiv.org/abs/2505.17439", "authors": ["Weijia Jin"], "title": "Designing an efficient and equitable humanitarian supply chain dynamically via reinforcement learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study designs an efficient and equitable humanitarian supply chain\ndynamically by using reinforcement learning, PPO, and compared with heuristic\nalgorithms. This study demonstrates the model of PPO always treats average\nsatisfaction rate as the priority."}
{"id": "2505.17133", "pdf": "https://arxiv.org/pdf/2505.17133", "abs": "https://arxiv.org/abs/2505.17133", "authors": ["Shuai Wang", "Song Jiang", "Yizhou Sun", "Judea Pearl", "Ang Li"], "title": "Learning Probabilities of Causation from Finite Population Data", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2502.08858", "summary": "Probabilities of causation play a crucial role in modern decision-making.\nThis paper addresses the challenge of predicting probabilities of causation for\nsubpopulations with \\textbf{insufficient} data using machine learning models.\nTian and Pearl first defined and derived tight bounds for three fundamental\nprobabilities of causation: the probability of necessity and sufficiency (PNS),\nthe probability of sufficiency (PS), and the probability of necessity (PN).\nHowever, estimating these probabilities requires both experimental and\nobservational distributions specific to each subpopulation, which are often\nunavailable or impractical to obtain with limited population-level data.\nTherefore, for most subgroups, the amount of data they have is not enough to\nguarantee the accuracy of their probabilities. Hence, to estimate these\nprobabilities for subpopulations with \\textbf{insufficient} data, we propose\nusing machine learning models that draw insights from subpopulations with\nsufficient data. Our evaluation of multiple machine learning models indicates\nthat, given the population-level data and an appropriate choice of machine\nlearning model and activation function, PNS can be effectively predicted.\nThrough simulation studies on multiple Structured Causal Models (SCMs), we show\nthat our multilayer perceptron (MLP) model with the Mish activation function\nachieves a mean absolute error (MAE) of approximately $0.02$ in predicting PNS\nfor $32,768$ subpopulations across most SCMs using data from only $2,000$\nsubpopulations with known PNS values."}
{"id": "2505.17448", "pdf": "https://arxiv.org/pdf/2505.17448", "abs": "https://arxiv.org/abs/2505.17448", "authors": ["Bhanuka Gamage", "Adnan Labib", "Aisha Joomun", "Chern Hong Lim", "KokSheik Wong"], "title": "Baitradar: A Multi-Model Clickbait Detection Algorithm Using Deep Learning", "categories": ["cs.LG", "cs.CV"], "comment": "Appear in IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP'21), Toronto, ON, Canada", "summary": "Following the rising popularity of YouTube, there is an emerging problem on\nthis platform called clickbait, which provokes users to click on videos using\nattractive titles and thumbnails. As a result, users ended up watching a video\nthat does not have the content as publicized in the title. This issue is\naddressed in this study by proposing an algorithm called BaitRadar, which uses\na deep learning technique where six inference models are jointly consulted to\nmake the final classification decision. These models focus on different\nattributes of the video, including title, comments, thumbnail, tags, video\nstatistics and audio transcript. The final classification is attained by\ncomputing the average of multiple models to provide a robust and accurate\noutput even in situation where there is missing data. The proposed method is\ntested on 1,400 YouTube videos. On average, a test accuracy of 98% is achieved\nwith an inference time of less than 2s."}
{"id": "2505.17138", "pdf": "https://arxiv.org/pdf/2505.17138", "abs": "https://arxiv.org/abs/2505.17138", "authors": ["Huanrong Liu", "Chunlin Tian", "Xuyang Wei", "Jiaheng Dai", "Qin Liu", "Tianqi Wei", "Qingbiao Li", "Li Li"], "title": "RAP: Runtime-Adaptive Pruning for LLM Inference", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) excel at language understanding and generation,\nbut their enormous computational and memory requirements hinder deployment.\nCompression offers a potential solution to mitigate these constraints. However,\nmost existing methods rely on fixed heuristics and thus fail to adapt to\nruntime memory variations or heterogeneous KV-cache demands arising from\ndiverse user requests. To address these limitations, we propose RAP, an elastic\npruning framework driven by reinforcement learning (RL) that dynamically\nadjusts compression strategies in a runtime-aware manner. Specifically, RAP\ndynamically tracks the evolving ratio between model parameters and KV-cache\nacross practical execution. Recognizing that FFNs house most parameters,\nwhereas parameter -light attention layers dominate KV-cache formation, the RL\nagent retains only those components that maximize utility within the current\nmemory budget, conditioned on instantaneous workload and device state.\nExtensive experiments results demonstrate that RAP outperforms state-of-the-art\nbaselines, marking the first time to jointly consider model weights and\nKV-cache on the fly."}
{"id": "2505.17451", "pdf": "https://arxiv.org/pdf/2505.17451", "abs": "https://arxiv.org/abs/2505.17451", "authors": ["Zhining Liu", "Zihao Li", "Ze Yang", "Tianxin Wei", "Jian Kang", "Yada Zhu", "Hendrik Hamann", "Jingrui He", "Hanghang Tong"], "title": "CLIMB: Class-imbalanced Learning Benchmark on Tabular Data", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 7 figures, 8 tables", "summary": "Class-imbalanced learning (CIL) on tabular data is important in many\nreal-world applications where the minority class holds the critical but rare\noutcomes. In this paper, we present CLIMB, a comprehensive benchmark for\nclass-imbalanced learning on tabular data. CLIMB includes 73 real-world\ndatasets across diverse domains and imbalance levels, along with unified\nimplementations of 29 representative CIL algorithms. Built on a high-quality\nopen-source Python package with unified API designs, detailed documentation,\nand rigorous code quality controls, CLIMB supports easy implementation and\ncomparison between different CIL algorithms. Through extensive experiments, we\nprovide practical insights on method accuracy and efficiency, highlighting the\nlimitations of naive rebalancing, the effectiveness of ensembles, and the\nimportance of data quality. Our code, documentation, and examples are available\nat https://github.com/ZhiningLiu1998/imbalanced-ensemble."}
{"id": "2505.17142", "pdf": "https://arxiv.org/pdf/2505.17142", "abs": "https://arxiv.org/abs/2505.17142", "authors": ["Jingyu Li", "Tiehua Zhang", "Jinze Wang", "Yi Zhang", "Yuhuan Li", "Yifan Zhao", "Zhishu Shen", "Jiannan Liu"], "title": "MetaSTH-Sleep: Towards Effective Few-Shot Sleep Stage Classification with Spatial-Temporal Hypergraph Enhanced Meta-Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Accurate classification of sleep stages based on bio-signals is fundamental\nfor automatic sleep stage annotation. Traditionally, this task relies on\nexperienced clinicians to manually annotate data, a process that is both\ntime-consuming and labor-intensive. In recent years, deep learning methods have\nshown promise in automating this task. However, three major challenges remain:\n(1) deep learning models typically require large-scale labeled datasets, making\nthem less effective in real-world settings where annotated data is limited; (2)\nsignificant inter-individual variability in bio-signals often results in\ninconsistent model performance when applied to new subjects, limiting\ngeneralization; and (3) existing approaches often overlook the high-order\nrelationships among bio-signals, failing to simultaneously capture signal\nheterogeneity and spatial-temporal dependencies. To address these issues, we\npropose MetaSTH-Sleep, a few-shot sleep stage classification framework based on\nspatial-temporal hypergraph enhanced meta-learning. Our approach enables rapid\nadaptation to new subjects using only a few labeled samples, while the\nhypergraph structure effectively models complex spatial interconnections and\ntemporal dynamics simultaneously in EEG signals. Experimental results\ndemonstrate that MetaSTH-Sleep achieves substantial performance improvements\nacross diverse subjects, offering valuable insights to support clinicians in\nsleep stage annotation."}
{"id": "2505.17454", "pdf": "https://arxiv.org/pdf/2505.17454", "abs": "https://arxiv.org/abs/2505.17454", "authors": ["Hyosoon Jang", "Yunhui Jang", "Sungjae Lee", "Jungseul Ok", "Sungsoo Ahn"], "title": "Self-Training Large Language Models with Confident Reasoning", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have shown impressive performance by generating\nreasoning paths before final answers, but learning such a reasoning path\nrequires costly human supervision. To address this issue, recent studies have\nexplored self-training methods that improve reasoning capabilities using\npseudo-labels generated by the LLMs themselves. Among these, confidence-based\nself-training fine-tunes LLMs to prefer reasoning paths with high-confidence\nanswers, where confidence is estimated via majority voting. However, such\nmethods exclusively focus on the quality of the final answer and may ignore the\nquality of the reasoning paths, as even an incorrect reasoning path leads to a\ncorrect answer by chance. Instead, we advocate the use of reasoning-level\nconfidence to identify high-quality reasoning paths for self-training,\nsupported by our empirical observations. We then propose a new self-training\nmethod, CORE-PO, that fine-tunes LLMs to prefer high-COnfidence REasoning paths\nthrough Policy Optimization. Our experiments show that CORE-PO improves the\naccuracy of outputs on four in-distribution and two out-of-distribution\nbenchmarks, compared to existing self-training methods."}
{"id": "2505.17150", "pdf": "https://arxiv.org/pdf/2505.17150", "abs": "https://arxiv.org/abs/2505.17150", "authors": ["Rembert Daems", "Manfred Opper", "Guillaume Crevecoeur", "Tolga Birdal"], "title": "Efficient Training of Neural SDEs Using Stochastic Optimal Control", "categories": ["cs.LG", "cs.AI", "math.PR"], "comment": "Published in the ESANN 2025 proceedings, European Symposium on\n  Artificial Neural Networks, Computational Intelligence and Machine Learning.\n  Bruges (Belgium) and online event, 23-25 April 2025", "summary": "We present a hierarchical, control theory inspired method for variational\ninference (VI) for neural stochastic differential equations (SDEs). While VI\nfor neural SDEs is a promising avenue for uncertainty-aware reasoning in\ntime-series, it is computationally challenging due to the iterative nature of\nmaximizing the ELBO. In this work, we propose to decompose the control term\ninto linear and residual non-linear components and derive an optimal control\nterm for linear SDEs, using stochastic optimal control. Modeling the non-linear\ncomponent by a neural network, we show how to efficiently train neural SDEs\nwithout sacrificing their expressive power. Since the linear part of the\ncontrol term is optimal and does not need to be learned, the training is\ninitialized at a lower cost and we observe faster convergence."}
{"id": "2505.17458", "pdf": "https://arxiv.org/pdf/2505.17458", "abs": "https://arxiv.org/abs/2505.17458", "authors": ["Guiquan Sun", "Xikun Zhang", "Jingchao Ni", "Dongjin Song"], "title": "Towards Heterogeneous Continual Graph Learning via Meta-knowledge Distillation", "categories": ["cs.LG"], "comment": null, "summary": "Machine learning on heterogeneous graphs has experienced rapid advancement in\nrecent years, driven by the inherently heterogeneous nature of real-world data.\nHowever, existing studies typically assume the graphs to be static, while\nreal-world graphs are continuously expanding. This dynamic nature requires\nmodels to adapt to new data while preserving existing knowledge. To this end,\nthis work addresses the challenge of continual learning on heterogeneous graphs\nby introducing the Meta-learning based Knowledge Distillation framework (MKD),\ndesigned to mitigate catastrophic forgetting in evolving heterogeneous graph\nstructures. MKD combines rapid task adaptation through meta-learning on limited\nsamples with knowledge distillation to achieve an optimal balance between\nincorporating new information and maintaining existing knowledge. To improve\nthe efficiency and effectiveness of sample selection, MKD incorporates a novel\nsampling strategy that selects a small number of target-type nodes based on\nnode diversity and maintains fixed-size buffers for other types. The strategy\nretrieves first-order neighbors along metapaths and selects important neighbors\nbased on their structural relevance, enabling the sampled subgraphs to retain\nkey topological and semantic information. In addition, MKD introduces a\nsemantic-level distillation module that aligns the attention distributions over\ndifferent metapaths between teacher and student models, encouraging semantic\nconsistency beyond the logit level. Comprehensive evaluations across three\nbenchmark datasets validate MKD's effectiveness in handling continual learning\nscenarios on expanding heterogeneous graphs."}
{"id": "2505.17155", "pdf": "https://arxiv.org/pdf/2505.17155", "abs": "https://arxiv.org/abs/2505.17155", "authors": ["Weizhe Lin", "Xing Li", "Zhiyuan Yang", "Xiaojin Fu", "Hui-Ling Zhen", "Yaoyuan Wang", "Xianzhi Yu", "Wulong Liu", "Xiaosong Li", "Mingxuan Yuan"], "title": "TrimR: Verifier-based Training-Free Thinking Compression for Efficient Test-Time Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Reasoning Models (LRMs) demonstrate exceptional capability in tackling\ncomplex mathematical, logical, and coding tasks by leveraging extended\nChain-of-Thought (CoT) reasoning. Test-time scaling methods, such as prolonging\nCoT with explicit token-level exploration, can push LRMs' accuracy boundaries,\nbut they incur significant decoding overhead. A key inefficiency source is LRMs\noften generate redundant thinking CoTs, which demonstrate clear structured\noverthinking and underthinking patterns. Inspired by human cognitive reasoning\nprocesses and numerical optimization theories, we propose TrimR, a\nverifier-based, training-free, efficient framework for dynamic CoT compression\nto trim reasoning and enhance test-time scaling, explicitly tailored for\nproduction-level deployment. Our method employs a lightweight, pretrained,\ninstruction-tuned verifier to detect and truncate redundant intermediate\nthoughts of LRMs without any LRM or verifier fine-tuning. We present both the\ncore algorithm and asynchronous online system engineered for high-throughput\nindustrial applications. Empirical evaluations on Ascend NPUs and vLLM show\nthat our framework delivers substantial gains in inference efficiency under\nlarge-batch workloads. In particular, on the four MATH500, AIME24, AIME25, and\nGPQA benchmarks, the reasoning runtime of Pangu-R-38B, QwQ-32B, and\nDeepSeek-R1-Distill-Qwen-32B is improved by up to 70% with negligible impact on\naccuracy."}
{"id": "2505.17469", "pdf": "https://arxiv.org/pdf/2505.17469", "abs": "https://arxiv.org/abs/2505.17469", "authors": ["Lukas Silvester Barth", "Paulo von Petersenn"], "title": "Efficient compression of neural networks and datasets", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "math.OC", "math.ST", "stat.TH", "94-08, 94-04, 68T07, 68T50", "E.4; H.1.1; I.2; I.2.6; I.2.7"], "comment": "10 pages plus appendix, 9 Figures, 3 Tables", "summary": "We compare, improve, and contribute methods that substantially decrease the\nnumber of parameters of neural networks while maintaining high test accuracy.\nWhen applying our methods to minimize description length, we obtain very\neffective data compression algorithms. In particular, we develop a\nprobabilistic reformulation of $\\ell_0$ regularized optimization for nonlinear\nmodels that does not require Monte-Carlo sampling and thus improves upon\nprevious methods. We also improve upon methods involving smooth approximations\nto the $\\ell_0$ norm, and investigate layerwise methods. We compare the methods\non different architectures and datasets, including convolutional networks\ntrained on image datasets and transformers trained on parts of Wikipedia. We\nalso created a synthetic teacher-student setup to investigate compression in a\ncontrolled continuous setting. Finally, we conceptually relate compression\nalgorithms to Solomonoff's theory of inductive inference and empirically verify\nthe prediction that regularized models can exhibit more sample-efficient\nconvergence."}
{"id": "2505.17163", "pdf": "https://arxiv.org/pdf/2505.17163", "abs": "https://arxiv.org/abs/2505.17163", "authors": ["Mingxin Huang", "Yongxin Shi", "Dezhi Peng", "Songxuan Lai", "Zecheng Xie", "Lianwen Jin"], "title": "OCR-Reasoning Benchmark: Unveiling the True Capabilities of MLLMs in Complex Text-Rich Image Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Recent advancements in multimodal slow-thinking systems have demonstrated\nremarkable performance across diverse visual reasoning tasks. However, their\ncapabilities in text-rich image reasoning tasks remain understudied due to the\nlack of a systematic benchmark. To address this gap, we propose OCR-Reasoning,\na comprehensive benchmark designed to systematically assess Multimodal Large\nLanguage Models on text-rich image reasoning tasks. The benchmark comprises\n1,069 human-annotated examples spanning 6 core reasoning abilities and 18\npractical reasoning tasks in text-rich visual scenarios. Furthermore, unlike\nother text-rich image understanding benchmarks that only annotate the final\nanswers, OCR-Reasoning also annotates the reasoning process simultaneously.\nWith the annotated reasoning process and the final answers, OCR-Reasoning\nevaluates not only the final answers generated by models but also their\nreasoning processes, enabling a holistic analysis of their problem-solving\nabilities. Leveraging this benchmark, we conducted a comprehensive evaluation\nof state-of-the-art MLLMs. Our results demonstrate the limitations of existing\nmethodologies. Notably, even state-of-the-art MLLMs exhibit substantial\ndifficulties, with none achieving accuracy surpassing 50\\% across\nOCR-Reasoning, indicating that the challenges of text-rich image reasoning are\nan urgent issue to be addressed. The benchmark and evaluation scripts are\navailable at https://github.com/SCUT-DLVCLab/OCR-Reasoning."}
{"id": "2505.17477", "pdf": "https://arxiv.org/pdf/2505.17477", "abs": "https://arxiv.org/abs/2505.17477", "authors": ["Victor OK Li", "Yang Han", "Jacqueline CK Lam", "Lawrence YL Cheung"], "title": "Reverse-Speech-Finder: A Neural Network Backtracking Architecture for Generating Alzheimer's Disease Speech Samples and Improving Diagnosis Performance", "categories": ["cs.LG", "cs.SD", "eess.AS"], "comment": null, "summary": "This study introduces Reverse-Speech-Finder (RSF), a groundbreaking neural\nnetwork backtracking architecture designed to enhance Alzheimer's Disease (AD)\ndiagnosis through speech analysis. Leveraging the power of pre-trained large\nlanguage models, RSF identifies and utilizes the most probable AD-specific\nspeech markers, addressing both the scarcity of real AD speech samples and the\nchallenge of limited interpretability in existing models. RSF's unique approach\nconsists of three core innovations: Firstly, it exploits the observation that\nspeech markers most probable of predicting AD, defined as the most probable\nspeech-markers (MPMs), must have the highest probability of activating those\nneurons (in the neural network) with the highest probability of predicting AD,\ndefined as the most probable neurons (MPNs). Secondly, it utilizes a speech\ntoken representation at the input layer, allowing backtracking from MPNs to\nidentify the most probable speech-tokens (MPTs) of AD. Lastly, it develops an\ninnovative backtracking method to track backwards from the MPNs to the input\nlayer, identifying the MPTs and the corresponding MPMs, and ingeniously\nuncovering novel speech markers for AD detection. Experimental results\ndemonstrate RSF's superiority over traditional methods such as SHAP and\nIntegrated Gradients, achieving a 3.5% improvement in accuracy and a 3.2% boost\nin F1-score. By generating speech data that encapsulates novel markers, RSF not\nonly mitigates the limitations of real data scarcity but also significantly\nenhances the robustness and accuracy of AD diagnostic models. These findings\nunderscore RSF's potential as a transformative tool in speech-based AD\ndetection, offering new insights into AD-related linguistic deficits and paving\nthe way for more effective non-invasive early intervention strategies."}
{"id": "2505.17198", "pdf": "https://arxiv.org/pdf/2505.17198", "abs": "https://arxiv.org/abs/2505.17198", "authors": ["Shuang Wu", "Meijie Wang", "Lun Yu"], "title": "LengthLogD: A Length-Stratified Ensemble Framework for Enhanced Peptide Lipophilicity Prediction via Multi-Scale Feature Integration", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Peptide compounds demonstrate considerable potential as therapeutic agents\ndue to their high target affinity and low toxicity, yet their drug development\nis constrained by their low membrane permeability. Molecular weight and peptide\nlength have significant effects on the logD of peptides, which in turn\ninfluences their ability to cross biological membranes. However, accurate\nprediction of peptide logD remains challenging due to the complex interplay\nbetween sequence, structure, and ionization states. This study introduces\nLengthLogD, a predictive framework that establishes specialized models through\nmolecular length stratification while innovatively integrating multi-scale\nmolecular representations. We constructed feature spaces across three\nhierarchical levels: atomic (10 molecular descriptors), structural (1024-bit\nMorgan fingerprints), and topological (3 graph-based features including Wiener\nindex), optimized through stratified ensemble learning. An adaptive weight\nallocation mechanism specifically developed for long peptides significantly\nenhances model generalizability. Experimental results demonstrate superior\nperformance across all categories: short peptides (R^2=0.855), medium peptides\n(R^2=0.816), and long peptides (R^2=0.882), with a 34.7% reduction in\nprediction error for long peptides compared to conventional single-model\napproaches. Ablation studies confirm: 1) The length-stratified strategy\ncontributes 41.2% to performance improvement; 2) Topological features account\nfor 28.5% of predictive importance. Compared to state-of-the-art models, our\nmethod maintains short peptide prediction accuracy while achieving a 25.7%\nincrease in the coefficient of determination (R^2) for long peptides. This\nresearch provides a precise logD prediction tool for peptide drug development,\nparticularly demonstrating unique value in optimizing long peptide lead\ncompounds."}
{"id": "2505.17478", "pdf": "https://arxiv.org/pdf/2505.17478", "abs": "https://arxiv.org/abs/2505.17478", "authors": ["Yuning Shen", "Lihao Wang", "Huizhuo Yuan", "Yan Wang", "Bangji Yang", "Quanquan Gu"], "title": "Simultaneous Modeling of Protein Conformation and Dynamics via Autoregression", "categories": ["cs.LG", "cs.AI", "physics.bio-ph", "q-bio.BM", "q-bio.QM"], "comment": "33 pages, 17 figures", "summary": "Understanding protein dynamics is critical for elucidating their biological\nfunctions. The increasing availability of molecular dynamics (MD) data enables\nthe training of deep generative models to efficiently explore the\nconformational space of proteins. However, existing approaches either fail to\nexplicitly capture the temporal dependencies between conformations or do not\nsupport direct generation of time-independent samples. To address these\nlimitations, we introduce ConfRover, an autoregressive model that\nsimultaneously learns protein conformation and dynamics from MD trajectories,\nsupporting both time-dependent and time-independent sampling. At the core of\nour model is a modular architecture comprising: (i) an encoding layer, adapted\nfrom protein folding models, that embeds protein-specific information and\nconformation at each time frame into a latent space; (ii) a temporal module, a\nsequence model that captures conformational dynamics across frames; and (iii)\nan SE(3) diffusion model as the structure decoder, generating conformations in\ncontinuous space. Experiments on ATLAS, a large-scale protein MD dataset of\ndiverse structures, demonstrate the effectiveness of our model in learning\nconformational dynamics and supporting a wide range of downstream tasks.\nConfRover is the first model to sample both protein conformations and\ntrajectories within a single framework, offering a novel and flexible approach\nfor learning from protein MD data."}
{"id": "2505.17242", "pdf": "https://arxiv.org/pdf/2505.17242", "abs": "https://arxiv.org/abs/2505.17242", "authors": ["Ram√≥n Fernandez Astudillo", "Md Arafat Sultan", "Aashka Trivedi", "Yousef El-Kurdi", "Tahira Naseem", "Radu Florian", "Salim Roukos"], "title": "Optimal Policy Minimum Bayesian Risk", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Inference scaling can help LLMs solve complex reasoning problems through\nextended runtime computation. On top of targeted supervision for long\nchain-of-thought (long-CoT) generation, purely inference-time techniques such\nas best-of-N (BoN) sampling, majority voting, or more generally, minimum Bayes\nrisk decoding (MBRD), can further improve LLM accuracy by generating multiple\ncandidate solutions and aggregating over them. These methods typically leverage\nadditional signals in the form of reward models and risk/similarity functions\nthat compare generated samples, e.g., exact match in some normalized space or\nstandard similarity metrics such as Rouge. Here we present a novel method for\nincorporating reward and risk/similarity signals into MBRD. Based on the\nconcept of optimal policy in KL-controlled reinforcement learning, our\nframework provides a simple and well-defined mechanism for leveraging such\nsignals, offering several advantages over traditional inference-time methods:\nhigher robustness, improved accuracy, and well-understood asymptotic behavior.\nIn addition, it allows for the development of a sample-efficient variant of\nMBRD that can adjust the number of samples to generate according to the\ndifficulty of the problem, without relying on majority vote counts. We\nempirically demonstrate the advantages of our approach on math (MATH-$500$) and\ncoding (HumanEval) tasks using recent open-source models. We also present a\ncomprehensive analysis of its accuracy-compute trade-offs."}
{"id": "2505.17483", "pdf": "https://arxiv.org/pdf/2505.17483", "abs": "https://arxiv.org/abs/2505.17483", "authors": ["Yiqing Guo", "Nagur Cherukuru", "Eric Lehmann", "S. L. Kesav Unnithan", "Gemma Kerrisk", "Tim Malthus", "Faisal Islam"], "title": "Hyperspectral in situ remote sensing of water surface nitrate in the Fitzroy River estuary, Queensland, Australia, using deep learning", "categories": ["cs.LG"], "comment": "Submitted to IGARSS2025", "summary": "Nitrate ($\\text{NO}_3^-$) is a form of dissolved inorganic nitrogen derived\nprimarily from anthropogenic sources. The recent increase in river-discharged\nnitrate poses a major risk for coral bleaching in the Great Barrier Reef (GBR)\nlagoon. Although nitrate is an optically inactive (i.e., colourless)\nconstituent, previous studies have demonstrated there is an indirect,\nnon-causal relationship between water surface nitrate and water-leaving\nreflectance that is mediated through optically active water quality parameters\nsuch as total suspended solids and coloured dissolved organic matter. This work\naims to advance our understanding of this relationship with an effort to\nmeasure time-series nitrate and simultaneous hyperspectral reflectance at the\nFitzroy River estuary, Queensland, Australia. Time-series observations revealed\nperiodic cycles in nitrate loads due to the tidal influence in the estuarine\nstudy site. The water surface nitrate loads were predicted from hyperspectral\nreflectance and water salinity measurements, with hyperspectral reflectance\nindicating the concentrations of optically active variables and salinity\nindicating the mixing of river water and seawater proportions. The accuracy\nassessment of model-predicted nitrate against in-situ measured nitrate values\nshowed that the predicted nitrate values correlated well with the ground-truth\ndata, with an $R^2$ score of 0.86, and an RMSE of 0.03 mg/L. This work\ndemonstrates the feasibility of predicting water surface nitrate from\nhyperspectral reflectance and salinity measurements."}
{"id": "2505.17344", "pdf": "https://arxiv.org/pdf/2505.17344", "abs": "https://arxiv.org/abs/2505.17344", "authors": ["Ninda Nurseha Amalina", "Kwadwo Boateng Ofori-Amanfo", "Heungjo An"], "title": "A Multi-Head Attention Soft Random Forest for Interpretable Patient No-Show Prediction", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": "14 pages, 6 figures", "summary": "Unattended scheduled appointments, defined as patient no-shows, adversely\naffect both healthcare providers and patients' health, disrupting the\ncontinuity of care, operational efficiency, and the efficient allocation of\nmedical resources. Accurate predictive modelling is needed to reduce the impact\nof no-shows. Although machine learning methods, such as logistic regression,\nrandom forest models, and decision trees, are widely used in predicting patient\nno-shows, they often rely on hard decision splits and static feature\nimportance, limiting their adaptability to specific or complex patient\nbehaviors. To address this limitation, we propose a new hybrid Multi-Head\nAttention Soft Random Forest (MHASRF) model that integrates attention\nmechanisms into a random forest model using probabilistic soft splitting\ninstead of hard splitting. The MHASRF model assigns attention weights\ndifferently across the trees, enabling attention on specific patient behaviors.\nThe model exhibited 93.56% accuracy, 93.67% precision, 93.56% recall, and a\n93.59% F1 score, surpassing the performance of decision tree, logistic\nregression, random forest, and naive Bayes models. Furthermore, MHASRF was able\nto identify key predictors of patient no-shows using two levels of feature\nimportance (tree level and attention mechanism level), offering deeper insights\ninto patient no-show predictors. The proposed model is a robust, adaptable, and\ninterpretable method for predicting patient no-shows that will help healthcare\nproviders in optimizing resources."}
{"id": "2505.17488", "pdf": "https://arxiv.org/pdf/2505.17488", "abs": "https://arxiv.org/abs/2505.17488", "authors": ["Haoran Li", "Muhao Guo", "Yang Weng", "Marija Ilic", "Guangchun Ruan"], "title": "ExARNN: An Environment-Driven Adaptive RNN for Learning Non-Stationary Power Dynamics", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "5 pages, 3 figures, conference", "summary": "Non-stationary power system dynamics, influenced by renewable energy\nvariability, evolving demand patterns, and climate change, are becoming\nincreasingly complex. Accurately capturing these dynamics requires a model\ncapable of adapting to environmental factors. Traditional models, including\nRecurrent Neural Networks (RNNs), lack efficient mechanisms to encode external\nfactors, such as time or environmental data, for dynamic adaptation. To address\nthis, we propose the External Adaptive RNN (ExARNN), a novel framework that\nintegrates external data (e.g., weather, time) to continuously adjust the\nparameters of a base RNN. ExARNN achieves this through a hierarchical\nhypernetwork design, using Neural Controlled Differential Equations (NCDE) to\nprocess external data and generate RNN parameters adaptively. This approach\nenables ExARNN to handle inconsistent timestamps between power and external\nmeasurements, ensuring continuous adaptation. Extensive forecasting tests\ndemonstrate ExARNN's superiority over established baseline models."}
{"id": "2505.17351", "pdf": "https://arxiv.org/pdf/2505.17351", "abs": "https://arxiv.org/abs/2505.17351", "authors": ["N. Benjamin Erichson", "Vinicius Mikuni", "Dongwei Lyu", "Yang Gao", "Omri Azencot", "Soon Hoe Lim", "Michael W. Mahoney"], "title": "FLEX: A Backbone for Diffusion-Based Modeling of Spatio-temporal Physical Systems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce FLEX (FLow EXpert), a backbone architecture for generative\nmodeling of spatio-temporal physical systems using diffusion models. FLEX\noperates in the residual space rather than on raw data, a modeling choice that\nwe motivate theoretically, showing that it reduces the variance of the velocity\nfield in the diffusion model, which helps stabilize training. FLEX integrates a\nlatent Transformer into a U-Net with standard convolutional ResNet layers and\nincorporates a redesigned skip connection scheme. This hybrid design enables\nthe model to capture both local spatial detail and long-range dependencies in\nlatent space. To improve spatio-temporal conditioning, FLEX uses a\ntask-specific encoder that processes auxiliary inputs such as coarse or past\nsnapshots. Weak conditioning is applied to the shared encoder via skip\nconnections to promote generalization, while strong conditioning is applied to\nthe decoder through both skip and bottleneck features to ensure reconstruction\nfidelity. FLEX achieves accurate predictions for super-resolution and\nforecasting tasks using as few as two reverse diffusion steps. It also produces\ncalibrated uncertainty estimates through sampling. Evaluations on\nhigh-resolution 2D turbulence data show that FLEX outperforms strong baselines\nand generalizes to out-of-distribution settings, including unseen Reynolds\nnumbers, physical observables (e.g., fluid flow velocity fields), and boundary\nconditions."}
{"id": "2505.17495", "pdf": "https://arxiv.org/pdf/2505.17495", "abs": "https://arxiv.org/abs/2505.17495", "authors": ["Landon Butler", "Abhineet Agarwal", "Justin Singh Kang", "Yigit Efe Erginbas", "Bin Yu", "Kannan Ramchandran"], "title": "ProxySPEX: Inference-Efficient Interpretability via Sparse Feature Interactions in LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable performance by\ncapturing complex interactions between input features. To identify these\ninteractions, most existing approaches require enumerating all possible\ncombinations of features up to a given order, causing them to scale poorly with\nthe number of inputs $n$. Recently, Kang et al. (2025) proposed SPEX, an\ninformation-theoretic approach that uses interaction sparsity to scale to $n\n\\approx 10^3$ features. SPEX greatly improves upon prior methods but requires\ntens of thousands of model inferences, which can be prohibitive for large\nmodels. In this paper, we observe that LLM feature interactions are often\nhierarchical -- higher-order interactions are accompanied by their lower-order\nsubsets -- which enables more efficient discovery. To exploit this hierarchy,\nwe propose ProxySPEX, an interaction attribution algorithm that first fits\ngradient boosted trees to masked LLM outputs and then extracts the important\ninteractions. Experiments across four challenging high-dimensional datasets\nshow that ProxySPEX more faithfully reconstructs LLM outputs by 20% over\nmarginal attribution approaches while using $10\\times$ fewer inferences than\nSPEX. By accounting for interactions, ProxySPEX identifies features that\ninfluence model output over 20% more than those selected by marginal\napproaches. Further, we apply ProxySPEX to two interpretability tasks. Data\nattribution, where we identify interactions among CIFAR-10 training samples\nthat influence test predictions, and mechanistic interpretability, where we\nuncover interactions between attention heads, both within and across layers, on\na question-answering task. ProxySPEX identifies interactions that enable more\naggressive pruning of heads than marginal approaches."}
{"id": "2505.17370", "pdf": "https://arxiv.org/pdf/2505.17370", "abs": "https://arxiv.org/abs/2505.17370", "authors": ["Qilin Wang"], "title": "FRIREN: Beyond Trajectories -- A Spectral Lens on Time", "categories": ["cs.LG", "cs.AI"], "comment": "37 pages, 4 figures. Submitted to NeurIPS 2025. Public code at\n  https://anonymous.4open.science/r/LTSF_model-C6B8/", "summary": "Long-term time-series forecasting (LTSF) models are often presented as\ngeneral-purpose solutions that can be applied across domains, implicitly\nassuming that all data is pointwise predictable. Using chaotic systems such as\nLorenz-63 as a case study, we argue that geometric structure - not pointwise\nprediction - is the right abstraction for a dynamic-agnostic foundational\nmodel. Minimizing the Wasserstein-2 distance (W2), which captures geometric\nchanges, and providing a spectral view of dynamics are essential for\nlong-horizon forecasting. Our model, FRIREN (Flow-inspired Representations via\nInterpretable Eigen-networks), implements an augmented normalizing-flow block\nthat embeds data into a normally distributed latent representation. It then\ngenerates a W2-efficient optimal path that can be decomposed into rotation,\nscaling, inverse rotation, and translation. This architecture yields locally\ngenerated, geometry-preserving predictions that are independent of the\nunderlying dynamics, and a global spectral representation that functions as a\nfinite Koopman operator with a small modification. This enables practitioners\nto identify which modes grow, decay, or oscillate, both locally and\nsystem-wide. FRIREN achieves an MSE of 11.4, MAE of 1.6, and SWD of 0.96 on\nLorenz-63 in a 336-in, 336-out, dt=0.01 setting, surpassing TimeMixer (MSE\n27.3, MAE 2.8, SWD 2.1). The model maintains effective prediction for 274 out\nof 336 steps, approximately 2.5 Lyapunov times. On Rossler (96-in, 336-out),\nFRIREN achieves an MSE of 0.0349, MAE of 0.0953, and SWD of 0.0170,\noutperforming TimeMixer's MSE of 4.3988, MAE of 0.886, and SWD of 3.2065.\nFRIREN is also competitive on standard LTSF datasets such as ETT and Weather.\nBy connecting modern generative flows with classical spectral analysis, FRIREN\nmakes long-term forecasting both accurate and interpretable, setting a new\nbenchmark for LTSF model design."}
{"id": "2505.17508", "pdf": "https://arxiv.org/pdf/2505.17508", "abs": "https://arxiv.org/abs/2505.17508", "authors": ["Yifan Zhang", "Yifeng Liu", "Huizhuo Yuan", "Yang Yuan", "Quanquan Gu", "Andrew C Yao"], "title": "On the Design of KL-Regularized Policy Gradient Algorithms for LLM Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "53 pages, 17 figures", "summary": "Policy gradient algorithms have been successfully applied to enhance the\nreasoning capabilities of large language models (LLMs). Despite the widespread\nuse of Kullback-Leibler (KL) regularization in policy gradient algorithms to\nstabilize training, the systematic exploration of how different KL divergence\nformulations can be estimated and integrated into surrogate loss functions for\nonline reinforcement learning (RL) presents a nuanced and systematically\nexplorable design space. In this paper, we propose regularized policy gradient\n(RPG), a systematic framework for deriving and analyzing KL-regularized policy\ngradient methods in the online RL setting. We derive policy gradients and\ncorresponding surrogate loss functions for objectives regularized by both\nforward and reverse KL divergences, considering both normalized and\nunnormalized policy distributions. Furthermore, we present derivations for\nfully differentiable loss functions as well as REINFORCE-style gradient\nestimators, accommodating diverse algorithmic needs. We conduct extensive\nexperiments on RL for LLM reasoning using these methods, showing improved or\ncompetitive results in terms of training stability and performance compared to\nstrong baselines such as GRPO, REINFORCE++, and DAPO. The code is available at\nhttps://github.com/complex-reasoning/RPG."}
{"id": "2505.17373", "pdf": "https://arxiv.org/pdf/2505.17373", "abs": "https://arxiv.org/abs/2505.17373", "authors": ["Kaiwen Wang", "Jin Peng Zhou", "Jonathan Chang", "Zhaolin Gao", "Nathan Kallus", "Kiant√© Brantley", "Wen Sun"], "title": "Value-Guided Search for Efficient Chain-of-Thought Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "In this paper, we propose a simple and efficient method for value model\ntraining on long-context reasoning traces. Compared to existing process reward\nmodels (PRMs), our method does not require a fine-grained notion of \"step,\"\nwhich is difficult to define for long-context reasoning models. By collecting a\ndataset of 2.5 million reasoning traces, we train a 1.5B token-level value\nmodel and apply it to DeepSeek models for improved performance with test-time\ncompute scaling. We find that block-wise value-guided search (VGS) with a final\nweighted majority vote achieves better test-time scaling than standard methods\nsuch as majority voting or best-of-n. With an inference budget of 64\ngenerations, VGS with DeepSeek-R1-Distill-1.5B achieves an average accuracy of\n45.7% across four competition math benchmarks (AIME 2024 & 2025, HMMT Feb 2024\n& 2025), reaching parity with o3-mini-medium. Moreover, VGS significantly\nreduces the inference FLOPs required to achieve the same performance of\nmajority voting. Our dataset, model and codebase are open-sourced."}
{"id": "2505.17513", "pdf": "https://arxiv.org/pdf/2505.17513", "abs": "https://arxiv.org/abs/2505.17513", "authors": ["Binh Nguyen", "Shuji Shi", "Ryan Ofman", "Thai Le"], "title": "What You Read Isn't What You Hear: Linguistic Sensitivity in Deepfake Speech Detection", "categories": ["cs.LG", "cs.CL", "cs.SD", "eess.AS", "53-04"], "comment": "15 pages, 2 fogures", "summary": "Recent advances in text-to-speech technologies have enabled realistic voice\ngeneration, fueling audio-based deepfake attacks such as fraud and\nimpersonation. While audio anti-spoofing systems are critical for detecting\nsuch threats, prior work has predominantly focused on acoustic-level\nperturbations, leaving the impact of linguistic variation largely unexplored.\nIn this paper, we investigate the linguistic sensitivity of both open-source\nand commercial anti-spoofing detectors by introducing transcript-level\nadversarial attacks. Our extensive evaluation reveals that even minor\nlinguistic perturbations can significantly degrade detection accuracy: attack\nsuccess rates surpass 60% on several open-source detector-voice pairs, and\nnotably one commercial detection accuracy drops from 100% on synthetic audio to\njust 32%. Through a comprehensive feature attribution analysis, we identify\nthat both linguistic complexity and model-level audio embedding similarity\ncontribute strongly to detector vulnerability. We further demonstrate the\nreal-world risk via a case study replicating the Brad Pitt audio deepfake scam,\nusing transcript adversarial attacks to completely bypass commercial detectors.\nThese results highlight the need to move beyond purely acoustic defenses and\naccount for linguistic variation in the design of robust anti-spoofing systems.\nAll source code will be publicly available."}
{"id": "2505.17379", "pdf": "https://arxiv.org/pdf/2505.17379", "abs": "https://arxiv.org/abs/2505.17379", "authors": ["Zichen Wang", "Chuanhao Li", "Huazheng Wang"], "title": "Provably Efficient Algorithm for Best Scoring Rule Identification in Online Principal-Agent Information Acquisition", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "We investigate the problem of identifying the optimal scoring rule within the\nprincipal-agent framework for online information acquisition problem. We focus\non the principal's perspective, seeking to determine the desired scoring rule\nthrough interactions with the agent. To address this challenge, we propose two\nalgorithms: OIAFC and OIAFB, tailored for fixed confidence and fixed budget\nsettings, respectively. Our theoretical analysis demonstrates that OIAFC can\nextract the desired $(\\epsilon, \\delta)$-scoring rule with a efficient\ninstance-dependent sample complexity or an instance-independent sample\ncomplexity. Our analysis also shows that OIAFB matches the instance-independent\nperformance bound of OIAFC, while both algorithms share the same complexity\nacross fixed confidence and fixed budget settings."}
{"id": "2505.17517", "pdf": "https://arxiv.org/pdf/2505.17517", "abs": "https://arxiv.org/abs/2505.17517", "authors": ["Rafa≈Ç Karczewski", "Markus Heinonen", "Alison Pouplin", "S√∏ren Hauberg", "Vikas Garg"], "title": "Spacetime Geometry of Denoising in Diffusion Models", "categories": ["cs.LG"], "comment": null, "summary": "We present a novel perspective on diffusion models using the framework of\ninformation geometry. We show that the set of noisy samples, taken across all\nnoise levels simultaneously, forms a statistical manifold -- a family of\ndenoising probability distributions. Interpreting the noise level as a temporal\nparameter, we refer to this manifold as spacetime. This manifold naturally\ncarries a Fisher-Rao metric, which defines geodesics -- shortest paths between\nnoisy points. Notably, this family of distributions is exponential, enabling\nefficient geodesic computation even in high-dimensional settings without\nretraining or fine-tuning. We demonstrate the practical value of this geometric\nviewpoint in transition path sampling, where spacetime geodesics define smooth\nsequences of Boltzmann distributions, enabling the generation of continuous\ntrajectories between low-energy metastable states. Code is available at:\nhttps://github.com/Aalto-QuML/diffusion-spacetime-geometry."}
{"id": "2505.17439", "pdf": "https://arxiv.org/pdf/2505.17439", "abs": "https://arxiv.org/abs/2505.17439", "authors": ["Weijia Jin"], "title": "Designing an efficient and equitable humanitarian supply chain dynamically via reinforcement learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study designs an efficient and equitable humanitarian supply chain\ndynamically by using reinforcement learning, PPO, and compared with heuristic\nalgorithms. This study demonstrates the model of PPO always treats average\nsatisfaction rate as the priority."}
{"id": "2505.17532", "pdf": "https://arxiv.org/pdf/2505.17532", "abs": "https://arxiv.org/abs/2505.17532", "authors": ["Bin Wang", "Heming Yang", "Jinfang Sheng"], "title": "TimeCF: A TimeMixer-Based Model with adaptive Convolution and Sharpness-Aware Minimization Frequency Domain Loss for long-term time seris forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Recent studies have shown that by introducing prior knowledge, multi-scale\nanalysis of complex and non-stationary time series in real environments can\nachieve good results in the field of long-term forecasting. However, affected\nby channel-independent methods, models based on multi-scale analysis may\nproduce suboptimal prediction results due to the autocorrelation between time\nseries labels, which in turn affects the generalization ability of the model.\nTo address this challenge, we are inspired by the idea of sharpness-aware\nminimization and the recently proposed FreDF method and design a deep learning\nmodel TimeCF for long-term time series forecasting based on the TimeMixer,\ncombined with our designed adaptive convolution information aggregation module\nand Sharpness-Aware Minimization Frequency Domain Loss (SAMFre). Specifically,\nTimeCF first decomposes the original time series into sequences of different\nscales. Next, the same-sized convolution modules are used to adaptively\naggregate information of different scales on sequences of different scales.\nThen, decomposing each sequence into season and trend parts and the two parts\nare mixed at different scales through bottom-up and top-down methods\nrespectively. Finally, different scales are aggregated through a Feed-Forward\nNetwork. What's more, extensive experimental results on different real-world\ndatasets show that our proposed TimeCF has excellent performance in the field\nof long-term forecasting."}
{"id": "2505.17451", "pdf": "https://arxiv.org/pdf/2505.17451", "abs": "https://arxiv.org/abs/2505.17451", "authors": ["Zhining Liu", "Zihao Li", "Ze Yang", "Tianxin Wei", "Jian Kang", "Yada Zhu", "Hendrik Hamann", "Jingrui He", "Hanghang Tong"], "title": "CLIMB: Class-imbalanced Learning Benchmark on Tabular Data", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 7 figures, 8 tables", "summary": "Class-imbalanced learning (CIL) on tabular data is important in many\nreal-world applications where the minority class holds the critical but rare\noutcomes. In this paper, we present CLIMB, a comprehensive benchmark for\nclass-imbalanced learning on tabular data. CLIMB includes 73 real-world\ndatasets across diverse domains and imbalance levels, along with unified\nimplementations of 29 representative CIL algorithms. Built on a high-quality\nopen-source Python package with unified API designs, detailed documentation,\nand rigorous code quality controls, CLIMB supports easy implementation and\ncomparison between different CIL algorithms. Through extensive experiments, we\nprovide practical insights on method accuracy and efficiency, highlighting the\nlimitations of naive rebalancing, the effectiveness of ensembles, and the\nimportance of data quality. Our code, documentation, and examples are available\nat https://github.com/ZhiningLiu1998/imbalanced-ensemble."}
{"id": "2505.17533", "pdf": "https://arxiv.org/pdf/2505.17533", "abs": "https://arxiv.org/abs/2505.17533", "authors": ["Pavan Ravishankar", "Rushabh Shah", "Daniel B. Neill"], "title": "Learning Representational Disparities", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": "27 pages", "summary": "We propose a fair machine learning algorithm to model interpretable\ndifferences between observed and desired human decision-making, with the latter\naimed at reducing disparity in a downstream outcome impacted by the human\ndecision. Prior work learns fair representations without considering the\noutcome in the decision-making process. We model the outcome disparities as\narising due to the different representations of the input seen by the observed\nand desired decision-maker, which we term representational disparities. Our\ngoal is to learn interpretable representational disparities which could\npotentially be corrected by specific nudges to the human decision, mitigating\ndisparities in the downstream outcome; we frame this as a multi-objective\noptimization problem using a neural network. Under reasonable simplifying\nassumptions, we prove that our neural network model of the representational\ndisparity learns interpretable weights that fully mitigate the outcome\ndisparity. We validate objectives and interpret results using real-world German\nCredit, Adult, and Heritage Health datasets."}
{"id": "2505.17469", "pdf": "https://arxiv.org/pdf/2505.17469", "abs": "https://arxiv.org/abs/2505.17469", "authors": ["Lukas Silvester Barth", "Paulo von Petersenn"], "title": "Efficient compression of neural networks and datasets", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "math.OC", "math.ST", "stat.TH", "94-08, 94-04, 68T07, 68T50", "E.4; H.1.1; I.2; I.2.6; I.2.7"], "comment": "10 pages plus appendix, 9 Figures, 3 Tables", "summary": "We compare, improve, and contribute methods that substantially decrease the\nnumber of parameters of neural networks while maintaining high test accuracy.\nWhen applying our methods to minimize description length, we obtain very\neffective data compression algorithms. In particular, we develop a\nprobabilistic reformulation of $\\ell_0$ regularized optimization for nonlinear\nmodels that does not require Monte-Carlo sampling and thus improves upon\nprevious methods. We also improve upon methods involving smooth approximations\nto the $\\ell_0$ norm, and investigate layerwise methods. We compare the methods\non different architectures and datasets, including convolutional networks\ntrained on image datasets and transformers trained on parts of Wikipedia. We\nalso created a synthetic teacher-student setup to investigate compression in a\ncontrolled continuous setting. Finally, we conceptually relate compression\nalgorithms to Solomonoff's theory of inductive inference and empirically verify\nthe prediction that regularized models can exhibit more sample-efficient\nconvergence."}
{"id": "2505.17542", "pdf": "https://arxiv.org/pdf/2505.17542", "abs": "https://arxiv.org/abs/2505.17542", "authors": ["Bardh Prenkaj", "Efstratios Zaradoukas", "Gjergji Kasneci"], "title": "Graph Style Transfer for Counterfactual Explainability", "categories": ["cs.LG"], "comment": "Accepted to ICML'25", "summary": "Counterfactual explainability seeks to uncover model decisions by identifying\nminimal changes to the input that alter the predicted outcome. This task\nbecomes particularly challenging for graph data due to preserving structural\nintegrity and semantic meaning. Unlike prior approaches that rely on forward\nperturbation mechanisms, we introduce Graph Inverse Style Transfer (GIST), the\nfirst framework to re-imagine graph counterfactual generation as a backtracking\nprocess, leveraging spectral style transfer. By aligning the global structure\nwith the original input spectrum and preserving local content faithfulness,\nGIST produces valid counterfactuals as interpolations between the input style\nand counterfactual content. Tested on 8 binary and multi-class graph\nclassification benchmarks, GIST achieves a remarkable +7.6% improvement in the\nvalidity of produced counterfactuals and significant gains (+45.5%) in\nfaithfully explaining the true class distribution. Additionally, GIST's\nbacktracking mechanism effectively mitigates overshooting the underlying\npredictor's decision boundary, minimizing the spectral differences between the\ninput and the counterfactuals. These results challenge traditional forward\nperturbation methods, offering a novel perspective that advances graph\nexplainability."}
{"id": "2505.17478", "pdf": "https://arxiv.org/pdf/2505.17478", "abs": "https://arxiv.org/abs/2505.17478", "authors": ["Yuning Shen", "Lihao Wang", "Huizhuo Yuan", "Yan Wang", "Bangji Yang", "Quanquan Gu"], "title": "Simultaneous Modeling of Protein Conformation and Dynamics via Autoregression", "categories": ["cs.LG", "cs.AI", "physics.bio-ph", "q-bio.BM", "q-bio.QM"], "comment": "33 pages, 17 figures", "summary": "Understanding protein dynamics is critical for elucidating their biological\nfunctions. The increasing availability of molecular dynamics (MD) data enables\nthe training of deep generative models to efficiently explore the\nconformational space of proteins. However, existing approaches either fail to\nexplicitly capture the temporal dependencies between conformations or do not\nsupport direct generation of time-independent samples. To address these\nlimitations, we introduce ConfRover, an autoregressive model that\nsimultaneously learns protein conformation and dynamics from MD trajectories,\nsupporting both time-dependent and time-independent sampling. At the core of\nour model is a modular architecture comprising: (i) an encoding layer, adapted\nfrom protein folding models, that embeds protein-specific information and\nconformation at each time frame into a latent space; (ii) a temporal module, a\nsequence model that captures conformational dynamics across frames; and (iii)\nan SE(3) diffusion model as the structure decoder, generating conformations in\ncontinuous space. Experiments on ATLAS, a large-scale protein MD dataset of\ndiverse structures, demonstrate the effectiveness of our model in learning\nconformational dynamics and supporting a wide range of downstream tasks.\nConfRover is the first model to sample both protein conformations and\ntrajectories within a single framework, offering a novel and flexible approach\nfor learning from protein MD data."}
{"id": "2505.17552", "pdf": "https://arxiv.org/pdf/2505.17552", "abs": "https://arxiv.org/abs/2505.17552", "authors": ["Zijie Qiu", "Jiaqi Wei", "Xiang Zhang", "Sheng Xu", "Kai Zou", "Zhi Jin", "Zhiqiang Gao", "Nanqing Dong", "Siqi Sun"], "title": "Universal Biological Sequence Reranking for Improved De Novo Peptide Sequencing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "De novo peptide sequencing is a critical task in proteomics. However, the\nperformance of current deep learning-based methods is limited by the inherent\ncomplexity of mass spectrometry data and the heterogeneous distribution of\nnoise signals, leading to data-specific biases. We present RankNovo, the first\ndeep reranking framework that enhances de novo peptide sequencing by leveraging\nthe complementary strengths of multiple sequencing models. RankNovo employs a\nlist-wise reranking approach, modeling candidate peptides as multiple sequence\nalignments and utilizing axial attention to extract informative features across\ncandidates. Additionally, we introduce two new metrics, PMD (Peptide Mass\nDeviation) and RMD (residual Mass Deviation), which offer delicate supervision\nby quantifying mass differences between peptides at both the sequence and\nresidue levels. Extensive experiments demonstrate that RankNovo not only\nsurpasses its base models used to generate training candidates for reranking\npre-training, but also sets a new state-of-the-art benchmark. Moreover,\nRankNovo exhibits strong zero-shot generalization to unseen models whose\ngenerations were not exposed during training, highlighting its robustness and\npotential as a universal reranking framework for peptide sequencing. Our work\npresents a novel reranking strategy that fundamentally challenges existing\nsingle-model paradigms and advances the frontier of accurate de novo\nsequencing. Our source code is provided on GitHub."}
{"id": "2505.17495", "pdf": "https://arxiv.org/pdf/2505.17495", "abs": "https://arxiv.org/abs/2505.17495", "authors": ["Landon Butler", "Abhineet Agarwal", "Justin Singh Kang", "Yigit Efe Erginbas", "Bin Yu", "Kannan Ramchandran"], "title": "ProxySPEX: Inference-Efficient Interpretability via Sparse Feature Interactions in LLMs", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable performance by\ncapturing complex interactions between input features. To identify these\ninteractions, most existing approaches require enumerating all possible\ncombinations of features up to a given order, causing them to scale poorly with\nthe number of inputs $n$. Recently, Kang et al. (2025) proposed SPEX, an\ninformation-theoretic approach that uses interaction sparsity to scale to $n\n\\approx 10^3$ features. SPEX greatly improves upon prior methods but requires\ntens of thousands of model inferences, which can be prohibitive for large\nmodels. In this paper, we observe that LLM feature interactions are often\nhierarchical -- higher-order interactions are accompanied by their lower-order\nsubsets -- which enables more efficient discovery. To exploit this hierarchy,\nwe propose ProxySPEX, an interaction attribution algorithm that first fits\ngradient boosted trees to masked LLM outputs and then extracts the important\ninteractions. Experiments across four challenging high-dimensional datasets\nshow that ProxySPEX more faithfully reconstructs LLM outputs by 20% over\nmarginal attribution approaches while using $10\\times$ fewer inferences than\nSPEX. By accounting for interactions, ProxySPEX identifies features that\ninfluence model output over 20% more than those selected by marginal\napproaches. Further, we apply ProxySPEX to two interpretability tasks. Data\nattribution, where we identify interactions among CIFAR-10 training samples\nthat influence test predictions, and mechanistic interpretability, where we\nuncover interactions between attention heads, both within and across layers, on\na question-answering task. ProxySPEX identifies interactions that enable more\naggressive pruning of heads than marginal approaches."}
{"id": "2505.17553", "pdf": "https://arxiv.org/pdf/2505.17553", "abs": "https://arxiv.org/abs/2505.17553", "authors": ["Jinyuan Feng", "Chaopeng Wei", "Tenghai Qiu", "Tianyi Hu", "Zhiqiang Pu"], "title": "CoMoE: Contrastive Representation for Mixture-of-Experts in Parameter-Efficient Fine-tuning", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "In parameter-efficient fine-tuning, mixture-of-experts (MoE), which involves\nspecializing functionalities into different experts and sparsely activating\nthem appropriately, has been widely adopted as a promising approach to\ntrade-off between model capacity and computation overhead. However, current MoE\nvariants fall short on heterogeneous datasets, ignoring the fact that experts\nmay learn similar knowledge, resulting in the underutilization of MoE's\ncapacity. In this paper, we propose Contrastive Representation for MoE (CoMoE),\na novel method to promote modularization and specialization in MoE, where the\nexperts are trained along with a contrastive objective by sampling from\nactivated and inactivated experts in top-k routing. We demonstrate that such a\ncontrastive objective recovers the mutual-information gap between inputs and\nthe two types of experts. Experiments on several benchmarks and in multi-task\nsettings demonstrate that CoMoE can consistently enhance MoE's capacity and\npromote modularization among the experts."}
{"id": "2505.17508", "pdf": "https://arxiv.org/pdf/2505.17508", "abs": "https://arxiv.org/abs/2505.17508", "authors": ["Yifan Zhang", "Yifeng Liu", "Huizhuo Yuan", "Yang Yuan", "Quanquan Gu", "Andrew C Yao"], "title": "On the Design of KL-Regularized Policy Gradient Algorithms for LLM Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "53 pages, 17 figures", "summary": "Policy gradient algorithms have been successfully applied to enhance the\nreasoning capabilities of large language models (LLMs). Despite the widespread\nuse of Kullback-Leibler (KL) regularization in policy gradient algorithms to\nstabilize training, the systematic exploration of how different KL divergence\nformulations can be estimated and integrated into surrogate loss functions for\nonline reinforcement learning (RL) presents a nuanced and systematically\nexplorable design space. In this paper, we propose regularized policy gradient\n(RPG), a systematic framework for deriving and analyzing KL-regularized policy\ngradient methods in the online RL setting. We derive policy gradients and\ncorresponding surrogate loss functions for objectives regularized by both\nforward and reverse KL divergences, considering both normalized and\nunnormalized policy distributions. Furthermore, we present derivations for\nfully differentiable loss functions as well as REINFORCE-style gradient\nestimators, accommodating diverse algorithmic needs. We conduct extensive\nexperiments on RL for LLM reasoning using these methods, showing improved or\ncompetitive results in terms of training stability and performance compared to\nstrong baselines such as GRPO, REINFORCE++, and DAPO. The code is available at\nhttps://github.com/complex-reasoning/RPG."}
{"id": "2505.17556", "pdf": "https://arxiv.org/pdf/2505.17556", "abs": "https://arxiv.org/abs/2505.17556", "authors": ["Nikolaos Anastasiou", "Spyros Kondylatos", "Ioannis Papoutsis"], "title": "Wildfire spread forecasting with Deep Learning", "categories": ["cs.LG", "cs.CV", "I.2.7"], "comment": "10 pages, 9 figures", "summary": "Accurate prediction of wildfire spread is crucial for effective risk\nmanagement, emergency response, and strategic resource allocation. In this\nstudy, we present a deep learning (DL)-based framework for forecasting the\nfinal extent of burned areas, using data available at the time of ignition. We\nleverage a spatio-temporal dataset that covers the Mediterranean region from\n2006 to 2022, incorporating remote sensing data, meteorological observations,\nvegetation maps, land cover classifications, anthropogenic factors, topography\ndata, and thermal anomalies. To evaluate the influence of temporal context, we\nconduct an ablation study examining how the inclusion of pre- and post-ignition\ndata affects model performance, benchmarking the temporal-aware DL models\nagainst a baseline trained exclusively on ignition-day inputs. Our results\nindicate that multi-day observational data substantially improve predictive\naccuracy. Particularly, the best-performing model, incorporating a temporal\nwindow of four days before to five days after ignition, improves both the F1\nscore and the Intersection over Union by almost 5% in comparison to the\nbaseline on the test dataset. We publicly release our dataset and models to\nenhance research into data-driven approaches for wildfire modeling and\nresponse."}
{"id": "2505.17533", "pdf": "https://arxiv.org/pdf/2505.17533", "abs": "https://arxiv.org/abs/2505.17533", "authors": ["Pavan Ravishankar", "Rushabh Shah", "Daniel B. Neill"], "title": "Learning Representational Disparities", "categories": ["cs.LG", "cs.AI", "cs.CY"], "comment": "27 pages", "summary": "We propose a fair machine learning algorithm to model interpretable\ndifferences between observed and desired human decision-making, with the latter\naimed at reducing disparity in a downstream outcome impacted by the human\ndecision. Prior work learns fair representations without considering the\noutcome in the decision-making process. We model the outcome disparities as\narising due to the different representations of the input seen by the observed\nand desired decision-maker, which we term representational disparities. Our\ngoal is to learn interpretable representational disparities which could\npotentially be corrected by specific nudges to the human decision, mitigating\ndisparities in the downstream outcome; we frame this as a multi-objective\noptimization problem using a neural network. Under reasonable simplifying\nassumptions, we prove that our neural network model of the representational\ndisparity learns interpretable weights that fully mitigate the outcome\ndisparity. We validate objectives and interpret results using real-world German\nCredit, Adult, and Heritage Health datasets."}
{"id": "2505.17575", "pdf": "https://arxiv.org/pdf/2505.17575", "abs": "https://arxiv.org/abs/2505.17575", "authors": ["Changfan Yang", "Lichen Bai", "Yinpeng Wang", "Shufei Zhang", "Zeke Xie"], "title": "Multiphysics Bench: Benchmarking and Investigating Scientific Machine Learning for Multiphysics PDEs", "categories": ["cs.LG"], "comment": "31 pages. 20 tables, 17 figures, Dataset", "summary": "Solving partial differential equations (PDEs) with machine learning has\nrecently attracted great attention, as PDEs are fundamental tools for modeling\nreal-world systems that range from fundamental physical science to advanced\nengineering disciplines. Most real-world physical systems across various\ndisciplines are actually involved in multiple coupled physical fields rather\nthan a single field. However, previous machine learning studies mainly focused\non solving single-field problems, but overlooked the importance and\ncharacteristics of multiphysics problems in real world. Multiphysics PDEs\ntypically entail multiple strongly coupled variables, thereby introducing\nadditional complexity and challenges, such as inter-field coupling. Both\nbenchmarking and solving multiphysics problems with machine learning remain\nlargely unexamined. To identify and address the emerging challenges in\nmultiphysics problems, we mainly made three contributions in this work. First,\nwe collect the first general multiphysics dataset, the Multiphysics Bench, that\nfocuses on multiphysics PDE solving with machine learning. Multiphysics Bench\nis also the most comprehensive PDE dataset to date, featuring the broadest\nrange of coupling types, the greatest diversity of PDE formulations, and the\nlargest dataset scale. Second, we conduct the first systematic investigation on\nmultiple representative learning-based PDE solvers, such as PINNs, FNO,\nDeepONet, and DiffusionPDE solvers, on multiphysics problems. Unfortunately,\nnaively applying these existing solvers usually show very poor performance for\nsolving multiphysics. Third, through extensive experiments and discussions, we\nreport multiple insights and a bag of useful tricks for solving multiphysics\nwith machine learning, motivating future directions in the study and simulation\nof complex, coupled physical systems."}
{"id": "2505.17552", "pdf": "https://arxiv.org/pdf/2505.17552", "abs": "https://arxiv.org/abs/2505.17552", "authors": ["Zijie Qiu", "Jiaqi Wei", "Xiang Zhang", "Sheng Xu", "Kai Zou", "Zhi Jin", "Zhiqiang Gao", "Nanqing Dong", "Siqi Sun"], "title": "Universal Biological Sequence Reranking for Improved De Novo Peptide Sequencing", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "De novo peptide sequencing is a critical task in proteomics. However, the\nperformance of current deep learning-based methods is limited by the inherent\ncomplexity of mass spectrometry data and the heterogeneous distribution of\nnoise signals, leading to data-specific biases. We present RankNovo, the first\ndeep reranking framework that enhances de novo peptide sequencing by leveraging\nthe complementary strengths of multiple sequencing models. RankNovo employs a\nlist-wise reranking approach, modeling candidate peptides as multiple sequence\nalignments and utilizing axial attention to extract informative features across\ncandidates. Additionally, we introduce two new metrics, PMD (Peptide Mass\nDeviation) and RMD (residual Mass Deviation), which offer delicate supervision\nby quantifying mass differences between peptides at both the sequence and\nresidue levels. Extensive experiments demonstrate that RankNovo not only\nsurpasses its base models used to generate training candidates for reranking\npre-training, but also sets a new state-of-the-art benchmark. Moreover,\nRankNovo exhibits strong zero-shot generalization to unseen models whose\ngenerations were not exposed during training, highlighting its robustness and\npotential as a universal reranking framework for peptide sequencing. Our work\npresents a novel reranking strategy that fundamentally challenges existing\nsingle-model paradigms and advances the frontier of accurate de novo\nsequencing. Our source code is provided on GitHub."}
{"id": "2505.17579", "pdf": "https://arxiv.org/pdf/2505.17579", "abs": "https://arxiv.org/abs/2505.17579", "authors": ["Teruki Sano", "Minoru Kuribayashi", "Masao Sakai", "Shuji Ishobe", "Eisuke Koizumi"], "title": "Ownership Verification of DNN Models Using White-Box Adversarial Attacks with Specified Probability Manipulation", "categories": ["cs.LG"], "comment": "Accepted to EUSIPCO 2025", "summary": "In this paper, we propose a novel framework for ownership verification of\ndeep neural network (DNN) models for image classification tasks. It allows\nverification of model identity by both the rightful owner and third party\nwithout presenting the original model. We assume a gray-box scenario where an\nunauthorized user owns a model that is illegally copied from the original\nmodel, provides services in a cloud environment, and the user throws images and\nreceives the classification results as a probability distribution of output\nclasses. The framework applies a white-box adversarial attack to align the\noutput probability of a specific class to a designated value. Due to the\nknowledge of original model, it enables the owner to generate such adversarial\nexamples. We propose a simple but effective adversarial attack method based on\nthe iterative Fast Gradient Sign Method (FGSM) by introducing control\nparameters. Experimental results confirm the effectiveness of the\nidentification of DNN models using adversarial attack."}
{"id": "2505.17591", "pdf": "https://arxiv.org/pdf/2505.17591", "abs": "https://arxiv.org/abs/2505.17591", "authors": ["Judith Vilella-Cantos", "Juan Jos√© Cabrera", "Luis Pay√°", "M√≥nica Ballesta", "David Valiente"], "title": "MinkUNeXt-SI: Improving point cloud-based place recognition including spherical coordinates and LiDAR intensity", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "comment": null, "summary": "In autonomous navigation systems, the solution of the place recognition\nproblem is crucial for their safe functioning. But this is not a trivial\nsolution, since it must be accurate regardless of any changes in the scene,\nsuch as seasonal changes and different weather conditions, and it must be\ngeneralizable to other environments. This paper presents our method,\nMinkUNeXt-SI, which, starting from a LiDAR point cloud, preprocesses the input\ndata to obtain its spherical coordinates and intensity values normalized within\na range of 0 to 1 for each point, and it produces a robust place recognition\ndescriptor. To that end, a deep learning approach that combines Minkowski\nconvolutions and a U-net architecture with skip connections is used. The\nresults of MinkUNeXt-SI demonstrate that this method reaches and surpasses\nstate-of-the-art performance while it also generalizes satisfactorily to other\ndatasets. Additionally, we showcase the capture of a custom dataset and its use\nin evaluating our solution, which also achieves outstanding results. Both the\ncode of our solution and the runs of our dataset are publicly available for\nreproducibility purposes."}
{"id": "2505.17591", "pdf": "https://arxiv.org/pdf/2505.17591", "abs": "https://arxiv.org/abs/2505.17591", "authors": ["Judith Vilella-Cantos", "Juan Jos√© Cabrera", "Luis Pay√°", "M√≥nica Ballesta", "David Valiente"], "title": "MinkUNeXt-SI: Improving point cloud-based place recognition including spherical coordinates and LiDAR intensity", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "comment": null, "summary": "In autonomous navigation systems, the solution of the place recognition\nproblem is crucial for their safe functioning. But this is not a trivial\nsolution, since it must be accurate regardless of any changes in the scene,\nsuch as seasonal changes and different weather conditions, and it must be\ngeneralizable to other environments. This paper presents our method,\nMinkUNeXt-SI, which, starting from a LiDAR point cloud, preprocesses the input\ndata to obtain its spherical coordinates and intensity values normalized within\na range of 0 to 1 for each point, and it produces a robust place recognition\ndescriptor. To that end, a deep learning approach that combines Minkowski\nconvolutions and a U-net architecture with skip connections is used. The\nresults of MinkUNeXt-SI demonstrate that this method reaches and surpasses\nstate-of-the-art performance while it also generalizes satisfactorily to other\ndatasets. Additionally, we showcase the capture of a custom dataset and its use\nin evaluating our solution, which also achieves outstanding results. Both the\ncode of our solution and the runs of our dataset are publicly available for\nreproducibility purposes."}
{"id": "2505.17636", "pdf": "https://arxiv.org/pdf/2505.17636", "abs": "https://arxiv.org/abs/2505.17636", "authors": ["Jonathan Bennion", "Shaona Ghosh", "Mantek Singh", "Nouha Dziri"], "title": "Surfacing Semantic Orthogonality Across Model Safety Benchmarks: A Multi-Dimensional Analysis", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "6th International Conference on Advanced Natural Language Processing\n  (AdNLP 2025), May 17 ~ 18, 2025, Zurich, Switzerland", "summary": "Various AI safety datasets have been developed to measure LLMs against\nevolving interpretations of harm. Our evaluation of five recently published\nopen-source safety benchmarks reveals distinct semantic clusters using UMAP\ndimensionality reduction and kmeans clustering (silhouette score: 0.470). We\nidentify six primary harm categories with varying benchmark representation.\nGretelAI, for example, focuses heavily on privacy concerns, while WildGuardMix\nemphasizes self-harm scenarios. Significant differences in prompt length\ndistribution suggests confounds to data collection and interpretations of harm\nas well as offer possible context. Our analysis quantifies benchmark\northogonality among AI benchmarks, allowing for transparency in coverage gaps\ndespite topical similarities. Our quantitative framework for analyzing semantic\northogonality across safety benchmarks enables more targeted development of\ndatasets that comprehensively address the evolving landscape of harms in AI\nuse, however that is defined in the future."}
{"id": "2505.17595", "pdf": "https://arxiv.org/pdf/2505.17595", "abs": "https://arxiv.org/abs/2505.17595", "authors": ["Li Lin", "Xinyu Hu", "Xiaojun Wan"], "title": "NeUQI: Near-Optimal Uniform Quantization Parameter Initialization", "categories": ["cs.LG", "cs.CL"], "comment": "9 pages, under review", "summary": "Large language models (LLMs) achieve impressive performance across domains\nbut face significant challenges when deployed on consumer-grade GPUs or\npersonal devices such as laptops, due to high memory consumption and inference\ncosts. Post-training quantization (PTQ) of LLMs offers a promising solution\nthat reduces their memory footprint and decoding latency. In practice, PTQ with\nuniform quantization representation is favored for its efficiency and ease of\ndeployment since uniform quantization is widely supported by mainstream\nhardware and software libraries. Recent studies on $\\geq 2$-bit uniform\nquantization have led to noticeable improvements in post-quantization model\nperformance; however, they primarily focus on quantization methodologies, while\nthe initialization of quantization parameters is underexplored and still relies\non the suboptimal Min-Max strategies. In this work, we propose NeUQI, a method\ndevoted to efficiently determining near-optimal initial parameters for uniform\nquantization. NeUQI is orthogonal to prior quantization methodologies and can\nseamlessly integrate with them. The experiments with the LLaMA and Qwen\nfamilies on various tasks demonstrate that our NeUQI consistently outperforms\nexisting methods. Furthermore, when combined with a lightweight distillation\nstrategy, NeUQI can achieve superior performance to PV-tuning, a much more\nresource-intensive approach."}
{"id": "2505.17652", "pdf": "https://arxiv.org/pdf/2505.17652", "abs": "https://arxiv.org/abs/2505.17652", "authors": ["Deyang Kong", "Qi Guo", "Xiangyu Xi", "Wei Wang", "Jingang Wang", "Xunliang Cai", "Shikun Zhang", "Wei Ye"], "title": "Rethinking the Sampling Criteria in Reinforcement Learning for LLM Reasoning: A Competence-Difficulty Alignment Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning exhibits potential in enhancing the reasoning\nabilities of large language models, yet it is hard to scale for the low sample\nefficiency during the rollout phase. Existing methods attempt to improve\nefficiency by scheduling problems based on problem difficulties. However, these\napproaches suffer from unstable and biased estimations of problem difficulty\nand fail to capture the alignment between model competence and problem\ndifficulty in RL training, leading to suboptimal results. To tackle these\nlimitations, this paper introduces \\textbf{C}ompetence-\\textbf{D}ifficulty\n\\textbf{A}lignment \\textbf{S}ampling (\\textbf{CDAS}), which enables accurate\nand stable estimation of problem difficulties by aggregating historical\nperformance discrepancies of problems. Then the model competence is quantified\nto adaptively select problems whose difficulty is in alignment with the model's\ncurrent competence using a fixed-point system. Experimental results across a\nrange of challenging mathematical benchmarks show that CDAS achieves great\nimprovements in both accuracy and efficiency. CDAS attains the highest average\naccuracy against baselines and exhibits significant speed advantages compared\nto Dynamic Sampling, a competitive strategy in DAPO, which is \\textbf{2.33}\ntimes slower than CDAS."}
{"id": "2505.17599", "pdf": "https://arxiv.org/pdf/2505.17599", "abs": "https://arxiv.org/abs/2505.17599", "authors": ["Yusheng Zhao", "Qixin Zhang", "Xiao Luo", "Weizhi Zhang", "Zhiping Xiao", "Wei Ju", "Philip S. Yu", "Ming Zhang"], "title": "Dynamic Text Bundling Supervision for Zero-Shot Inference on Text-Attributed Graphs", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) have been used in many zero-shot learning\nproblems, with their strong generalization ability. Recently, adopting LLMs in\ntext-attributed graphs (TAGs) has drawn increasing attention. However, the\nadoption of LLMs faces two major challenges: limited information on graph\nstructure and unreliable responses. LLMs struggle with text attributes isolated\nfrom the graph topology. Worse still, they yield unreliable predictions due to\nboth information insufficiency and the inherent weakness of LLMs (e.g.,\nhallucination). Towards this end, this paper proposes a novel method named\nDynamic Text Bundling Supervision (DENSE) that queries LLMs with bundles of\ntexts to obtain bundle-level labels and uses these labels to supervise graph\nneural networks. Specifically, we sample a set of bundles, each containing a\nset of nodes with corresponding texts of close proximity. We then query LLMs\nwith the bundled texts to obtain the label of each bundle. Subsequently, the\nbundle labels are used to supervise the optimization of graph neural networks,\nand the bundles are further refined to exclude noisy items. To justify our\ndesign, we also provide theoretical analysis of the proposed method. Extensive\nexperiments across ten datasets validate the effectiveness of the proposed\nmethod."}
{"id": "2505.17670", "pdf": "https://arxiv.org/pdf/2505.17670", "abs": "https://arxiv.org/abs/2505.17670", "authors": ["Wenyi Wu", "Zixuan Song", "Kun Zhou", "Yifei Shao", "Zhiting Hu", "Biwei Huang"], "title": "Towards General Continuous Memory for Vision-Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Language models (LMs) and their extension, vision-language models (VLMs),\nhave achieved remarkable performance across various tasks. However, they still\nstruggle with complex reasoning tasks that require multimodal or multilingual\nreal-world knowledge. To support such capabilities, an external memory system\nthat can efficiently provide relevant multimodal information is essential.\nExisting approaches generally concatenate image and text tokens into a long\nsequence as memory, which, however, may drastically increase context length and\neven degrade performance. In contrast, we propose using continuous memory, a\ncompact set of dense embeddings to more effectively and efficiently represent\nmultimodal and multilingual knowledge. Our key insight is that a VLM can serve\nas its own continuous memory encoder. We empirically show that this design\nimproves performance on complex multimodal reasoning tasks. Building on this,\nwe introduce a data-efficient and parameter-efficient method to fine-tune the\nVLM into a memory encoder, requiring only 1.2% of the model's parameters and a\nsmall corpus of 15.6K self-synthesized samples. Our approach CoMEM utilizes\nVLM's original capabilities to encode arbitrary multimodal and multilingual\nknowledge into just 8 continuous embeddings. Since the inference-time VLM\nremains frozen, our memory module is plug-and-play and can be flexibly\nintegrated as needed. Extensive experiments across eight multimodal reasoning\nbenchmarks demonstrate the effectiveness of our approach."}
{"id": "2505.17604", "pdf": "https://arxiv.org/pdf/2505.17604", "abs": "https://arxiv.org/abs/2505.17604", "authors": ["Alessio Devoto", "Jary Pomponi", "Mattia Merluzzi", "Paolo Di Lorenzo", "Simone Scardapane"], "title": "Adaptive Semantic Token Communication for Transformer-based Edge Inference", "categories": ["cs.LG", "cs.ET"], "comment": null, "summary": "This paper presents an adaptive framework for edge inference based on a\ndynamically configurable transformer-powered deep joint source channel coding\n(DJSCC) architecture. Motivated by a practical scenario where a resource\nconstrained edge device engages in goal oriented semantic communication, such\nas selectively transmitting essential features for object detection to an edge\nserver, our approach enables efficient task aware data transmission under\nvarying bandwidth and channel conditions. To achieve this, input data is\ntokenized into compact high level semantic representations, refined by a\ntransformer, and transmitted over noisy wireless channels. As part of the DJSCC\npipeline, we employ a semantic token selection mechanism that adaptively\ncompresses informative features into a user specified number of tokens per\nsample. These tokens are then further compressed through the JSCC module,\nenabling a flexible token communication strategy that adjusts both the number\nof transmitted tokens and their embedding dimensions. We incorporate a resource\nallocation algorithm based on Lyapunov stochastic optimization to enhance\nrobustness under dynamic network conditions, effectively balancing compression\nefficiency and task performance. Experimental results demonstrate that our\nsystem consistently outperforms existing baselines, highlighting its potential\nas a strong foundation for AI native semantic communication in edge\nintelligence applications."}
{"id": "2505.17695", "pdf": "https://arxiv.org/pdf/2505.17695", "abs": "https://arxiv.org/abs/2505.17695", "authors": ["Dong-Hee Kim", "Hyunjee Song", "Donghyun Kim"], "title": "SynRES: Towards Referring Expression Segmentation in the Wild via Synthetic Data", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Despite the advances in Referring Expression Segmentation (RES) benchmarks,\ntheir evaluation protocols remain constrained, primarily focusing on either\nsingle targets with short queries (containing minimal attributes) or multiple\ntargets from distinctly different queries on a single domain. This limitation\nsignificantly hinders the assessment of more complex reasoning capabilities in\nRES models. We introduce WildRES, a novel benchmark that incorporates long\nqueries with diverse attributes and non-distinctive queries for multiple\ntargets. This benchmark spans diverse application domains, including autonomous\ndriving environments and robotic manipulation scenarios, thus enabling more\nrigorous evaluation of complex reasoning capabilities in real-world settings.\nOur analysis reveals that current RES models demonstrate substantial\nperformance deterioration when evaluated on WildRES. To address this challenge,\nwe introduce SynRES, an automated pipeline generating densely paired\ncompositional synthetic training data through three innovations: (1) a dense\ncaption-driven synthesis for attribute-rich image-mask-expression triplets, (2)\nreliable semantic alignment mechanisms rectifying caption-pseudo mask\ninconsistencies via Image-Text Aligned Grouping, and (3) domain-aware\naugmentations incorporating mosaic composition and superclass replacement to\nemphasize generalization ability and distinguishing attributes over object\ncategories. Experimental results demonstrate that models trained with SynRES\nachieve state-of-the-art performance, improving gIoU by 2.0% on WildRES-ID and\n3.8% on WildRES-DS. Code and datasets are available at\nhttps://github.com/UTLLab/SynRES."}
{"id": "2505.17610", "pdf": "https://arxiv.org/pdf/2505.17610", "abs": "https://arxiv.org/abs/2505.17610", "authors": ["Till Freihaut", "Luca Viano", "Volkan Cevher", "Matthieu Geist", "Giorgia Ramponi"], "title": "Learning Equilibria from Data: Provably Efficient Multi-Agent Imitation Learning", "categories": ["cs.LG"], "comment": null, "summary": "This paper provides the first expert sample complexity characterization for\nlearning a Nash equilibrium from expert data in Markov Games. We show that a\nnew quantity named the single policy deviation concentrability coefficient is\nunavoidable in the non-interactive imitation learning setting, and we provide\nan upper bound for behavioral cloning (BC) featuring such coefficient. BC\nexhibits substantial regret in games with high concentrability coefficient,\nleading us to utilize expert queries to develop and introduce two novel\nsolution algorithms: MAIL-BRO and MURMAIL. The former employs a best response\noracle and learns an $\\varepsilon$-Nash equilibrium with\n$\\mathcal{O}(\\varepsilon^{-4})$ expert and oracle queries. The latter bypasses\ncompletely the best response oracle at the cost of a worse expert query\ncomplexity of order $\\mathcal{O}(\\varepsilon^{-8})$. Finally, we provide\nnumerical evidence, confirming our theoretical findings."}
{"id": "2505.17701", "pdf": "https://arxiv.org/pdf/2505.17701", "abs": "https://arxiv.org/abs/2505.17701", "authors": ["Jaewon Cheon", "Pilsung Kang"], "title": "COUNTDOWN: Contextually Sparse Activation Filtering Out Unnecessary Weights in Down Projection", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The growing size of large language models has created significant\ncomputational inefficiencies. To address this challenge, sparse activation\nmethods selectively deactivates non-essential parameters during inference,\nreducing computational costs in FFNN layers. While existing methods focus on\nnon-linear gating mechanisms, we hypothesize that the sparsity of the FFNN\nlayer lies globally in the form of a linear combination over its internal down\nprojection matrix. Based on this insight, we propose two methods: M-COUNTDOWN,\nleveraging indirect coefficients, and D-COUNTDOWN, utilizing direct\ncoefficients of the linear combination. Experimental results demonstrate that\nD-COUNTDOWN can omit 90% of computations with performance loss as low as 5.5%\nideally, while M-COUNTDOWN provides a predictor-free solution with up to 29.4%\nbetter performance preservation compared to existing methods. Our specialized\nkernel implementations effectively realize these theoretical gains into\nsubstantial real-world acceleration."}
{"id": "2505.17615", "pdf": "https://arxiv.org/pdf/2505.17615", "abs": "https://arxiv.org/abs/2505.17615", "authors": ["Haoxin Li", "Jingtao Ding", "Jiahui Gong", "Yong Li"], "title": "Large language model as user daily behavior data generator: balancing population diversity and individual personality", "categories": ["cs.LG", "cs.CL", "cs.IR"], "comment": "14 pages, 7 figures, 4 tables", "summary": "Predicting human daily behavior is challenging due to the complexity of\nroutine patterns and short-term fluctuations. While data-driven models have\nimproved behavior prediction by leveraging empirical data from various\nplatforms and devices, the reliance on sensitive, large-scale user data raises\nprivacy concerns and limits data availability. Synthetic data generation has\nemerged as a promising solution, though existing methods are often limited to\nspecific applications. In this work, we introduce BehaviorGen, a framework that\nuses large language models (LLMs) to generate high-quality synthetic behavior\ndata. By simulating user behavior based on profiles and real events,\nBehaviorGen supports data augmentation and replacement in behavior prediction\nmodels. We evaluate its performance in scenarios such as pertaining\naugmentation, fine-tuning replacement, and fine-tuning augmentation, achieving\nsignificant improvements in human mobility and smartphone usage predictions,\nwith gains of up to 18.9%. Our results demonstrate the potential of BehaviorGen\nto enhance user behavior modeling through flexible and privacy-preserving\nsynthetic data generation."}
{"id": "2505.17714", "pdf": "https://arxiv.org/pdf/2505.17714", "abs": "https://arxiv.org/abs/2505.17714", "authors": ["Ben Rahman"], "title": "PPO-BR: Dual-Signal Entropy-Reward Adaptation for Trust Region Policy Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "This manuscript builds upon an earlier version posted to TechRxiv.\n  This arXiv version includes an updated comparison with GRPO (Group Relative\n  Policy Optimization)", "summary": "Despite Proximal Policy Optimization (PPO) dominating policy gradient methods\n-- from robotic control to game AI -- its static trust region forces a brittle\ntrade-off: aggressive clipping stifles early exploration, while late-stage\nupdates destabilize convergence. PPO-BR establishes a new paradigm in adaptive\nRL by fusing exploration and convergence signals into a single bounded trust\nregion -- a theoretically grounded innovation that outperforms five SOTA\nbaselines with less than 2% overhead. This work bridges a critical gap in\nphase-aware learning, enabling real-world deployment in safety-critical systems\nlike robotic surgery within a single adaptive mechanism. PPO-BR achieves 29.1%\nfaster convergence by combining: (1) entropy-driven expansion (epsilon up) for\nexploration in high-uncertainty states, and (2) reward-guided contraction\n(epsilon down) for convergence stability. On six diverse benchmarks (MuJoCo,\nAtari, sparse-reward), PPO-BR achieves 29.1% faster convergence (p < 0.001),\n2.3x lower reward variance than PPO, and less than 1.8% runtime overhead with\nonly five lines of code change. PPO-BR's simplicity and theoretical guarantees\nmake it ready-to-deploy in safety-critical domains -- from surgical robotics to\nautonomous drones. In contrast to recent methods such as Group Relative Policy\nOptimization (GRPO), PPO-BR offers a unified entropy-reward mechanism\napplicable to both language models and general reinforcement learning\nenvironments."}
{"id": "2505.17621", "pdf": "https://arxiv.org/pdf/2505.17621", "abs": "https://arxiv.org/abs/2505.17621", "authors": ["Jingtong Gao", "Ling Pan", "Yejing Wang", "Rui Zhong", "Chi Lu", "Qingpeng Cai", "Peng Jiang", "Xiangyu Zhao"], "title": "Navigate the Unknown: Enhancing LLM Reasoning with Intrinsic Motivation Guided Exploration", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) has emerged as a pivotal method for improving the\nreasoning capabilities of Large Language Models (LLMs). However, prevalent RL\napproaches such as Proximal Policy Optimization (PPO) and Group-Regularized\nPolicy Optimization (GRPO) face critical limitations due to their reliance on\nsparse outcome-based rewards and inadequate mechanisms for incentivizing\nexploration. These limitations result in inefficient guidance for multi-step\nreasoning processes. Specifically, sparse reward signals fail to deliver\neffective or sufficient feedback, particularly for challenging problems.\nFurthermore, such reward structures induce systematic biases that prioritize\nexploitation of familiar trajectories over novel solution discovery. These\nshortcomings critically hinder performance in complex reasoning tasks, which\ninherently demand iterative refinement across ipntermediate steps. To address\nthese challenges, we propose an Intrinsic Motivation guidEd exploratioN meThOd\nfoR LLM Reasoning (i-MENTOR), a novel method designed to both deliver dense\nrewards and amplify explorations in the RL-based training paradigm. i-MENTOR\nintroduces three key innovations: trajectory-aware exploration rewards that\nmitigate bias in token-level strategies while maintaining computational\nefficiency; dynamic reward scaling to stabilize exploration and exploitation in\nlarge action spaces; and advantage-preserving reward implementation that\nmaintains advantage distribution integrity while incorporating exploratory\nguidance. Experiments across three public datasets demonstrate i-MENTOR's\neffectiveness with a 22.39% improvement on the difficult dataset Countdown-4."}
{"id": "2505.17717", "pdf": "https://arxiv.org/pdf/2505.17717", "abs": "https://arxiv.org/abs/2505.17717", "authors": ["Akira Tanimoto"], "title": "A Distributionally-Robust Framework for Nuisance in Causal Effect Estimation", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Causal inference requires evaluating models on balanced distributions between\ntreatment and control groups, while training data often exhibits imbalance due\nto historical decision-making policies. Most conventional statistical methods\naddress this distribution shift through inverse probability weighting (IPW),\nwhich requires estimating propensity scores as an intermediate step. These\nmethods face two key challenges: inaccurate propensity estimation and\ninstability from extreme weights. We decompose the generalization error to\nisolate these issues--propensity ambiguity and statistical instability--and\naddress them through an adversarial loss function. Our approach combines\ndistributionally robust optimization for handling propensity uncertainty with\nweight regularization based on weighted Rademacher complexity. Experiments on\nsynthetic and real-world datasets demonstrate consistent improvements over\nexisting methods."}
{"id": "2505.17626", "pdf": "https://arxiv.org/pdf/2505.17626", "abs": "https://arxiv.org/abs/2505.17626", "authors": ["Guilherme Korol", "Antonio Carlos Schneider Beck", "Jeronimo Castrillon"], "title": "Leveraging Stochastic Depth Training for Adaptive Inference", "categories": ["cs.LG", "cs.AR"], "comment": null, "summary": "Dynamic DNN optimization techniques such as layer-skipping offer increased\nadaptability and efficiency gains but can lead to i) a larger memory footprint\nas in decision gates, ii) increased training complexity (e.g., with\nnon-differentiable operations), and iii) less control over performance-quality\ntrade-offs due to its inherent input-dependent execution. To approach these\nissues, we propose a simpler yet effective alternative for adaptive inference\nwith a zero-overhead, single-model, and time-predictable inference. Central to\nour approach is the observation that models trained with Stochastic Depth -- a\nmethod for faster training of residual networks -- become more resilient to\narbitrary layer-skipping at inference time. We propose a method to first select\nnear Pareto-optimal skipping configurations from a stochastically-trained model\nto adapt the inference at runtime later. Compared to original ResNets, our\nmethod shows improvements of up to 2X in power efficiency at accuracy drops as\nlow as 0.71%."}
{"id": "2505.17745", "pdf": "https://arxiv.org/pdf/2505.17745", "abs": "https://arxiv.org/abs/2505.17745", "authors": ["Zeyuan Ma", "Yue-Jiao Gong", "Hongshu Guo", "Wenjie Qiu", "Sijie Ma", "Hongqiao Lian", "Jiajun Zhan", "Kaixu Chen", "Chen Wang", "Zhiyang Huang", "Zechuan Huang", "Guojun Peng", "Ran Cheng", "Yining Ma"], "title": "MetaBox-v2: A Unified Benchmark Platform for Meta-Black-Box Optimization", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Meta-Black-Box Optimization (MetaBBO) streamlines the automation of\noptimization algorithm design through meta-learning. It typically employs a\nbi-level structure: the meta-level policy undergoes meta-training to reduce the\nmanual effort required in developing algorithms for low-level optimization\ntasks. The original MetaBox (2023) provided the first open-source framework for\nreinforcement learning-based single-objective MetaBBO. However, its relatively\nnarrow scope no longer keep pace with the swift advancement in this field. In\nthis paper, we introduce MetaBox-v2 (https://github.com/MetaEvo/MetaBox) as a\nmilestone upgrade with four novel features: 1) a unified architecture\nsupporting RL, evolutionary, and gradient-based approaches, by which we\nreproduce 23 up-to-date baselines; 2) efficient parallelization schemes, which\nreduce the training/testing time by 10-40x; 3) a comprehensive benchmark suite\nof 18 synthetic/realistic tasks (1900+ instances) spanning single-objective,\nmulti-objective, multi-model, and multi-task optimization scenarios; 4)\nplentiful and extensible interfaces for custom analysis/visualization and\nintegrating to external optimization tools/benchmarks. To show the utility of\nMetaBox-v2, we carry out a systematic case study that evaluates the built-in\nbaselines in terms of the optimization performance, generalization ability and\nlearning efficiency. Valuable insights are concluded from thorough and detailed\nanalysis for practitioners and those new to the field."}
{"id": "2505.17636", "pdf": "https://arxiv.org/pdf/2505.17636", "abs": "https://arxiv.org/abs/2505.17636", "authors": ["Jonathan Bennion", "Shaona Ghosh", "Mantek Singh", "Nouha Dziri"], "title": "Surfacing Semantic Orthogonality Across Model Safety Benchmarks: A Multi-Dimensional Analysis", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "6th International Conference on Advanced Natural Language Processing\n  (AdNLP 2025), May 17 ~ 18, 2025, Zurich, Switzerland", "summary": "Various AI safety datasets have been developed to measure LLMs against\nevolving interpretations of harm. Our evaluation of five recently published\nopen-source safety benchmarks reveals distinct semantic clusters using UMAP\ndimensionality reduction and kmeans clustering (silhouette score: 0.470). We\nidentify six primary harm categories with varying benchmark representation.\nGretelAI, for example, focuses heavily on privacy concerns, while WildGuardMix\nemphasizes self-harm scenarios. Significant differences in prompt length\ndistribution suggests confounds to data collection and interpretations of harm\nas well as offer possible context. Our analysis quantifies benchmark\northogonality among AI benchmarks, allowing for transparency in coverage gaps\ndespite topical similarities. Our quantitative framework for analyzing semantic\northogonality across safety benchmarks enables more targeted development of\ndatasets that comprehensively address the evolving landscape of harms in AI\nuse, however that is defined in the future."}
{"id": "2505.17749", "pdf": "https://arxiv.org/pdf/2505.17749", "abs": "https://arxiv.org/abs/2505.17749", "authors": ["Ghada Sokar", "Pablo Samuel Castro"], "title": "Mind the GAP! The Challenges of Scale in Pixel-based Deep Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Scaling deep reinforcement learning in pixel-based environments presents a\nsignificant challenge, often resulting in diminished performance. While recent\nworks have proposed algorithmic and architectural approaches to address this,\nthe underlying cause of the performance drop remains unclear. In this paper, we\nidentify the connection between the output of the encoder (a stack of\nconvolutional layers) and the ensuing dense layers as the main underlying\nfactor limiting scaling capabilities; we denote this connection as the\nbottleneck, and we demonstrate that previous approaches implicitly target this\nbottleneck. As a result of our analyses, we present global average pooling as a\nsimple yet effective way of targeting the bottleneck, thereby avoiding the\ncomplexity of earlier approaches."}
{"id": "2505.17637", "pdf": "https://arxiv.org/pdf/2505.17637", "abs": "https://arxiv.org/abs/2505.17637", "authors": ["Yuting Huang", "Ziquan Fang", "Zhihao Zeng", "Lu Chen", "Yunjun Gao"], "title": "Causal Spatio-Temporal Prediction: An Effective and Efficient Multi-Modal Approach", "categories": ["cs.LG"], "comment": null, "summary": "Spatio-temporal prediction plays a crucial role in intelligent\ntransportation, weather forecasting, and urban planning. While integrating\nmulti-modal data has shown potential for enhancing prediction accuracy, key\nchallenges persist: (i) inadequate fusion of multi-modal information, (ii)\nconfounding factors that obscure causal relations, and (iii) high computational\ncomplexity of prediction models. To address these challenges, we propose\nE^2-CSTP, an Effective and Efficient Causal multi-modal Spatio-Temporal\nPrediction framework. E^2-CSTP leverages cross-modal attention and gating\nmechanisms to effectively integrate multi-modal data. Building on this, we\ndesign a dual-branch causal inference approach: the primary branch focuses on\nspatio-temporal prediction, while the auxiliary branch mitigates bias by\nmodeling additional modalities and applying causal interventions to uncover\ntrue causal dependencies. To improve model efficiency, we integrate GCN with\nthe Mamba architecture for accelerated spatio-temporal encoding. Extensive\nexperiments on 4 real-world datasets show that E^2-CSTP significantly\noutperforms 9 state-of-the-art methods, achieving up to 9.66% improvements in\naccuracy as well as 17.37%-56.11% reductions in computational overhead."}
{"id": "2505.17760", "pdf": "https://arxiv.org/pdf/2505.17760", "abs": "https://arxiv.org/abs/2505.17760", "authors": ["Leon Eshuijs", "Archie Chaudhury", "Alan McBeth", "Ethan Nguyen"], "title": "But what is your honest answer? Aiding LLM-judges with honest alternatives using steering vectors", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent safety evaluations of Large Language Models (LLMs) show that many\nmodels exhibit dishonest behavior, such as sycophancy. However, most honesty\nbenchmarks focus exclusively on factual knowledge or explicitly harmful\nbehavior and rely on external judges, which are often unable to detect less\nobvious forms of dishonesty. In this work, we introduce a new framework, Judge\nUsing Safety-Steered Alternatives (JUSSA), which utilizes steering vectors\ntrained on a single sample to elicit more honest responses from models, helping\nLLM-judges in the detection of dishonest behavior. To test our framework, we\nintroduce a new manipulation dataset with prompts specifically designed to\nelicit deceptive responses. We find that JUSSA enables LLM judges to better\ndifferentiate between dishonest and benign responses, and helps them identify\nsubtle instances of manipulative behavior."}
{"id": "2505.17638", "pdf": "https://arxiv.org/pdf/2505.17638", "abs": "https://arxiv.org/abs/2505.17638", "authors": ["Tony Bonnaire", "Rapha√´l Urfin", "Giulio Biroli", "Marc M√©zard"], "title": "Why Diffusion Models Don't Memorize: The Role of Implicit Dynamical Regularization in Training", "categories": ["cs.LG", "cond-mat.dis-nn", "stat.ML"], "comment": "36 pages, 15 figures", "summary": "Diffusion models have achieved remarkable success across a wide range of\ngenerative tasks. A key challenge is understanding the mechanisms that prevent\ntheir memorization of training data and allow generalization. In this work, we\ninvestigate the role of the training dynamics in the transition from\ngeneralization to memorization. Through extensive experiments and theoretical\nanalysis, we identify two distinct timescales: an early time\n$\\tau_\\mathrm{gen}$ at which models begin to generate high-quality samples, and\na later time $\\tau_\\mathrm{mem}$ beyond which memorization emerges. Crucially,\nwe find that $\\tau_\\mathrm{mem}$ increases linearly with the training set size\n$n$, while $\\tau_\\mathrm{gen}$ remains constant. This creates a growing window\nof training times with $n$ where models generalize effectively, despite showing\nstrong memorization if training continues beyond it. It is only when $n$\nbecomes larger than a model-dependent threshold that overfitting disappears at\ninfinite training times. These findings reveal a form of implicit dynamical\nregularization in the training dynamics, which allow to avoid memorization even\nin highly overparameterized settings. Our results are supported by numerical\nexperiments with standard U-Net architectures on realistic and synthetic\ndatasets, and by a theoretical analysis using a tractable random features model\nstudied in the high-dimensional limit."}
{"id": "2505.17804", "pdf": "https://arxiv.org/pdf/2505.17804", "abs": "https://arxiv.org/abs/2505.17804", "authors": ["Jonas Seng", "Fabrizio Ventola", "Zhongjie Yu", "Kristian Kersting"], "title": "Hyperparameter Optimization via Interacting with Probabilistic Circuits", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite the growing interest in designing truly interactive hyperparameter\noptimization (HPO) methods, to date, only a few allow to include human\nfeedback. Existing interactive Bayesian optimization (BO) methods incorporate\nhuman beliefs by weighting the acquisition function with a user-defined prior\ndistribution. However, in light of the non-trivial inner optimization of the\nacquisition function prevalent in BO, such weighting schemes do not always\naccurately reflect given user beliefs. We introduce a novel BO approach\nleveraging tractable probabilistic models named probabilistic circuits (PCs) as\na surrogate model. PCs encode a tractable joint distribution over the hybrid\nhyperparameter space and evaluation scores. They enable exact conditional\ninference and sampling. Based on conditional sampling, we construct a novel\nselection policy that enables an acquisition function-free generation of\ncandidate points (thereby eliminating the need for an additional inner-loop\noptimization) and ensures that user beliefs are reflected accurately in the\nselection policy. We provide a theoretical analysis and an extensive empirical\nevaluation, demonstrating that our method achieves state-of-the-art performance\nin standard HPO and outperforms interactive BO baselines in interactive HPO."}
{"id": "2505.17639", "pdf": "https://arxiv.org/pdf/2505.17639", "abs": "https://arxiv.org/abs/2505.17639", "authors": ["Zehua Pei", "Ying Zhang", "Hui-Ling Zhen", "Xianzhi Yu", "Wulong Liu", "Sinno Jialin Pan", "Mingxuan Yuan", "Bei Yu"], "title": "PreMoe: Lightening MoEs on Constrained Memory by Expert Pruning and Retrieval", "categories": ["cs.LG"], "comment": null, "summary": "Mixture-of-experts (MoE) architectures enable scaling large language models\n(LLMs) to vast parameter counts without a proportional rise in computational\ncosts. However, the significant memory demands of large MoE models hinder their\ndeployment across various computational environments, from cloud servers to\nconsumer devices. This study first demonstrates pronounced task-specific\nspecialization in expert activation patterns within MoE layers. Building on\nthis, we introduce PreMoe, a novel framework that enables efficient deployment\nof massive MoE models in memory-constrained environments. PreMoe features two\nmain components: probabilistic expert pruning (PEP) and task-adaptive expert\nretrieval (TAER). PEP employs a new metric, the task-conditioned expected\nselection score (TCESS), derived from router logits to quantify expert\nimportance for specific tasks, thereby identifying a minimal set of critical\nexperts. TAER leverages these task-specific expert importance profiles for\nefficient inference. It pre-computes and stores compact expert patterns for\ndiverse tasks. When a user query is received, TAER rapidly identifies the most\nrelevant stored task pattern and reconstructs the model by loading only the\nsmall subset of experts crucial for that task. This approach dramatically\nreduces the memory footprint across all deployment scenarios. DeepSeek-R1 671B\nmaintains 97.2\\% accuracy on MATH500 when pruned to 8/128 configuration (50\\%\nexpert reduction), and still achieves 72.0\\% with aggressive 8/32 pruning\n(87.5\\% expert reduction). Pangu-Ultra-MoE 718B achieves 97.15\\% on MATH500 and\n81.3\\% on AIME24 with 8/128 pruning, while even more aggressive pruning to 4/64\n(390GB memory) preserves 96.95\\% accuracy on MATH500. We make our code publicly\navailable at https://github.com/JarvisPei/PreMoe."}
{"id": "2505.17830", "pdf": "https://arxiv.org/pdf/2505.17830", "abs": "https://arxiv.org/abs/2505.17830", "authors": ["Nicolas Castanet", "Olivier Sigaud", "Sylvain Lamprier"], "title": "Imagine Beyond! Distributionally Robust Auto-Encoding for State Space Coverage in Online Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Goal-Conditioned Reinforcement Learning (GCRL) enables agents to autonomously\nacquire diverse behaviors, but faces major challenges in visual environments\ndue to high-dimensional, semantically sparse observations. In the online\nsetting, where agents learn representations while exploring, the latent space\nevolves with the agent's policy, to capture newly discovered areas of the\nenvironment. However, without incentivization to maximize state coverage in the\nrepresentation, classical approaches based on auto-encoders may converge to\nlatent spaces that over-represent a restricted set of states frequently visited\nby the agent. This is exacerbated in an intrinsic motivation setting, where the\nagent uses the distribution encoded in the latent space to sample the goals it\nlearns to master. To address this issue, we propose to progressively enforce\ndistributional shifts towards a uniform distribution over the full state space,\nto ensure a full coverage of skills that can be learned in the environment. We\nintroduce DRAG (Distributionally Robust Auto-Encoding for GCRL), a method that\ncombines the $\\beta$-VAE framework with Distributionally Robust Optimization.\nDRAG leverages an adversarial neural weighter of training states of the VAE, to\naccount for the mismatch between the current data distribution and unseen parts\nof the environment. This allows the agent to construct semantically meaningful\nlatent spaces beyond its immediate experience. Our approach improves state\nspace coverage and downstream control performance on hard exploration\nenvironments such as mazes and robotic control involving walls to bypass,\nwithout pre-training nor prior environment knowledge."}
{"id": "2505.17640", "pdf": "https://arxiv.org/pdf/2505.17640", "abs": "https://arxiv.org/abs/2505.17640", "authors": ["Ivana Kesiƒá", "Carolina Fortuna", "Mihael Mohorƒçiƒç", "Bla≈æ Bertalaniƒç"], "title": "A Network Science Approach to Granular Time Series Segmentation", "categories": ["cs.LG"], "comment": "24 pages, 10 figures", "summary": "Time series segmentation (TSS) is one of the time series (TS) analysis\ntechniques, that has received considerably less attention compared to other TS\nrelated tasks. In recent years, deep learning architectures have been\nintroduced for TSS, however their reliance on sliding windows limits\nsegmentation granularity due to fixed window sizes and strides. To overcome\nthese challenges, we propose a new more granular TSS approach that utilizes the\nWeighted Dual Perspective Visbility Graph (WDPVG) TS into a graph and combines\nit with a Graph Attention Network (GAT). By transforming TS into graphs, we are\nable to capture different structural aspects of the data that would otherwise\nremain hidden. By utilizing the representation learning capabilities of Graph\nNeural Networks, our method is able to effectively identify meaningful segments\nwithin the TS. To better understand the potential of our approach, we also\nexperimented with different TS-to-graph transformations and compared their\nperformance. Our contributions include: a) formulating the TSS as a node\nclassification problem on graphs; b) conducting an extensive analysis of\nvarious TS- to-graph transformations applied to TSS using benchmark datasets\nfrom the TSSB repository; c) providing the first detailed study on utilizing\nGNNs for analyzing graph representations of TS in the context of TSS; d)\ndemonstrating the effectiveness of our method, which achieves an average F1\nscore of 0.97 across 59 diverse TSS benchmark datasets; e) outperforming the\nseq2point baseline method by 0.05 in terms of F1 score; and f) reducing the\nrequired training data compared to the baseline methods."}
{"id": "2505.17847", "pdf": "https://arxiv.org/pdf/2505.17847", "abs": "https://arxiv.org/abs/2505.17847", "authors": ["Hao Wang", "Licheng Pan", "Zhichao Chen", "Xu Chen", "Qingyang Dai", "Lei Wang", "Haoxuan Li", "Zhouchen Lin"], "title": "TransDF: Time-Series Forecasting Needs Transformed Label Alignment", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Training time-series forecasting models presents unique challenges in\ndesigning effective learning objectives. Existing methods predominantly utilize\nthe temporal mean squared error, which faces two critical challenges: (1) label\nautocorrelation, which leads to bias from the label sequence likelihood; (2)\nexcessive amount of tasks, which increases with the forecast horizon and\ncomplicates optimization. To address these challenges, we propose\nTransform-enhanced Direct Forecast (TransDF), which transforms the label\nsequence into decorrelated components with discriminated significance. Models\nare trained to align the most significant components, thereby effectively\nmitigating label autocorrelation and reducing task amount. Extensive\nexperiments demonstrate that TransDF achieves state-of-the-art performance and\nis compatible with various forecasting models. Code is available at\nhttps://anonymous.4open.science/r/TransDF-88CF."}
{"id": "2505.17646", "pdf": "https://arxiv.org/pdf/2505.17646", "abs": "https://arxiv.org/abs/2505.17646", "authors": ["Huanran Chen", "Yinpeng Dong", "Zeming Wei", "Yao Huang", "Yichi Zhang", "Hang Su", "Jun Zhu"], "title": "Understanding Pre-training and Fine-tuning from Loss Landscape Perspectives", "categories": ["cs.LG"], "comment": null, "summary": "Recent studies have revealed that the loss landscape of large language models\nresembles a basin, within which the models perform nearly identically, and\noutside of which they lose all their capabilities. In this work, we conduct\nfurther studies on the loss landscape of large language models. We discover\nthat pre-training creates a \"basic capability\" basin, and subsequent\nfine-tuning creates \"specific capability\" basins (e.g., math, safety, coding)\nwithin the basic capability basin. We further investigate two types of loss\nlandscapes: the most-case landscape (i.e., the landscape along most directions)\nand the worst-case landscape (i.e., the landscape along the worst direction).\nWe argue that as long as benign fine-tuning remains within the most-case basin,\nit will not compromise previous capabilities. Similarly, any fine-tuning\n(including the adversarial one) that stays within the worst-case basin would\nnot compromise previous capabilities. Finally, we theoretically demonstrate\nthat the size of the most-case basin can bound the size of the worst-case basin\nand the robustness with respect to input perturbations. We also show that, due\nto the over-parameterization property of current large language models, one can\neasily enlarge the basins by five times."}
{"id": "2505.17852", "pdf": "https://arxiv.org/pdf/2505.17852", "abs": "https://arxiv.org/abs/2505.17852", "authors": ["Francois Chaubard", "Mykel Kochenderfer"], "title": "Scaling Recurrent Neural Networks to a Billion Parameters with Zero-Order Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "During inference, Recurrent Neural Networks (RNNs) scale constant in both\nFLOPs and GPU memory with increasing context length, as they compress all prior\ntokens into a fixed-size memory. In contrast, transformers scale linearly in\nFLOPs and, at best, linearly in memory during generation, since they must\nattend to all previous tokens explicitly. Despite this inference-time\nadvantage, training large RNNs on long contexts remains impractical because\nstandard optimization methods depend on Backpropagation Through Time (BPTT).\nBPTT requires retention of all intermediate activations during the forward\npass, causing memory usage to scale linearly with both context length and model\nsize. In this paper, we show that Zero-Order Optimization (ZOO) methods such as\nRandom-vector Gradient Estimation (RGE) can successfully replace BPTT to train\nRNNs with convergence rates that match, or exceed BPTT by up to 19 fold, while\nusing orders of magnitude less memory and cost, as the model remains in\ninference mode throughout training. We further demonstrate that\nCentral-Difference RGE (CD-RGE) corresponds to optimizing a smoothed surrogate\nloss, inherently regularizing training and improving generalization. Our method\nmatches or outperforms BPTT across three settings: (1) overfitting, (2)\ntransduction, and (3) language modeling. Across all tasks, with sufficient\nperturbations, our models generalize as well as or better than those trained\nwith BPTT, often in fewer steps. Despite the need for more forward passes per\nstep, we can surpass BPTT wall-clock time per step using recent advancements\nsuch as FlashRNN and distributed inference."}
{"id": "2505.17652", "pdf": "https://arxiv.org/pdf/2505.17652", "abs": "https://arxiv.org/abs/2505.17652", "authors": ["Deyang Kong", "Qi Guo", "Xiangyu Xi", "Wei Wang", "Jingang Wang", "Xunliang Cai", "Shikun Zhang", "Wei Ye"], "title": "Rethinking the Sampling Criteria in Reinforcement Learning for LLM Reasoning: A Competence-Difficulty Alignment Perspective", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning exhibits potential in enhancing the reasoning\nabilities of large language models, yet it is hard to scale for the low sample\nefficiency during the rollout phase. Existing methods attempt to improve\nefficiency by scheduling problems based on problem difficulties. However, these\napproaches suffer from unstable and biased estimations of problem difficulty\nand fail to capture the alignment between model competence and problem\ndifficulty in RL training, leading to suboptimal results. To tackle these\nlimitations, this paper introduces \\textbf{C}ompetence-\\textbf{D}ifficulty\n\\textbf{A}lignment \\textbf{S}ampling (\\textbf{CDAS}), which enables accurate\nand stable estimation of problem difficulties by aggregating historical\nperformance discrepancies of problems. Then the model competence is quantified\nto adaptively select problems whose difficulty is in alignment with the model's\ncurrent competence using a fixed-point system. Experimental results across a\nrange of challenging mathematical benchmarks show that CDAS achieves great\nimprovements in both accuracy and efficiency. CDAS attains the highest average\naccuracy against baselines and exhibits significant speed advantages compared\nto Dynamic Sampling, a competitive strategy in DAPO, which is \\textbf{2.33}\ntimes slower than CDAS."}
{"id": "2505.17856", "pdf": "https://arxiv.org/pdf/2505.17856", "abs": "https://arxiv.org/abs/2505.17856", "authors": ["Moule Lin", "Shuhao Guan", "Weipeng Jing", "Goetz Botterweck", "Andrea Patane"], "title": "Stochastic Weight Sharing for Bayesian Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While offering a principled framework for uncertainty quantification in deep\nlearning, the employment of Bayesian Neural Networks (BNNs) is still\nconstrained by their increased computational requirements and the convergence\ndifficulties when training very deep, state-of-the-art architectures. In this\nwork, we reinterpret weight-sharing quantization techniques from a stochastic\nperspective in the context of training and inference with Bayesian Neural\nNetworks (BNNs). Specifically, we leverage 2D adaptive Gaussian distributions,\nWasserstein distance estimations, and alpha blending to encode the stochastic\nbehaviour of a BNN in a lower dimensional, soft Gaussian representation.\nThrough extensive empirical investigation, we demonstrate that our approach\nsignificantly reduces the computational overhead inherent in Bayesian learning\nby several orders of magnitude, enabling the efficient Bayesian training of\nlarge-scale models, such as ResNet-101 and Vision Transformer (VIT). On various\ncomputer vision benchmarks including CIFAR10, CIFAR100, and ImageNet1k. Our\napproach compresses model parameters by approximately 50x and reduces model\nsize by 75, while achieving accuracy and uncertainty estimations comparable to\nthe state-of-the-art."}
{"id": "2505.17660", "pdf": "https://arxiv.org/pdf/2505.17660", "abs": "https://arxiv.org/abs/2505.17660", "authors": ["Chenyang Li", "Jinsong Chen", "John E. Hopcroft", "Kun He"], "title": "DAM-GT: Dual Positional Encoding-Based Attention Masking Graph Transformer for Node Classification", "categories": ["cs.LG"], "comment": "Preprint version", "summary": "Neighborhood-aware tokenized graph Transformers have recently shown great\npotential for node classification tasks. Despite their effectiveness, our\nin-depth analysis of neighborhood tokens reveals two critical limitations in\nthe existing paradigm. First, current neighborhood token generation methods\nfail to adequately capture attribute correlations within a neighborhood.\nSecond, the conventional self-attention mechanism suffers from attention\ndiversion when processing neighborhood tokens, where high-hop neighborhoods\nreceive disproportionate focus, severely disrupting information interactions\nbetween the target node and its neighborhood tokens. To address these\nchallenges, we propose DAM-GT, Dual positional encoding-based Attention Masking\ngraph Transformer. DAM-GT introduces a novel dual positional encoding scheme\nthat incorporates attribute-aware encoding via an attribute clustering\nstrategy, effectively preserving node correlations in both topological and\nattribute spaces. In addition, DAM-GT formulates a new attention mechanism with\na simple yet effective masking strategy to guide interactions between target\nnodes and their neighborhood tokens, overcoming the issue of attention\ndiversion. Extensive experiments on various graphs with different homophily\nlevels as well as different scales demonstrate that DAM-GT consistently\noutperforms state-of-the-art methods in node classification tasks."}
{"id": "2505.17859", "pdf": "https://arxiv.org/pdf/2505.17859", "abs": "https://arxiv.org/abs/2505.17859", "authors": ["Masahiro Fujisawa", "Masaki Adachi", "Michael A. Osborne"], "title": "Scalable Valuation of Human Feedback through Provably Robust Model Alignment", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "38 pages, 7 figures", "summary": "Despite the importance of aligning language models with human preferences,\ncrowd-sourced human feedback is often noisy -- for example, preferring less\ndesirable responses -- posing a fundamental challenge to alignment. A truly\nrobust alignment objective should yield identical model parameters even under\nsevere label noise, a property known as redescending. We prove that no existing\nalignment methods satisfy this property. To address this, we propose\nH\\\"older-DPO, the first principled alignment loss with a provable redescending\nproperty, enabling estimation of the clean data distribution from noisy\nfeedback. The aligned model estimates the likelihood of clean data, providing a\ntheoretically grounded metric for dataset valuation that identifies the\nlocation and fraction of mislabels. This metric is gradient-free, enabling\nscalable and automated human feedback valuation without costly manual\nverification or clean validation dataset. H\\\"older-DPO achieves\nstate-of-the-art robust alignment performance while accurately detecting\nmislabels in controlled datasets. Finally, we apply H\\\"older-DPO to widely used\nalignment datasets, revealing substantial noise levels and demonstrating that\nremoving these mislabels significantly improves alignment performance across\nmethods."}
{"id": "2505.17661", "pdf": "https://arxiv.org/pdf/2505.17661", "abs": "https://arxiv.org/abs/2505.17661", "authors": ["Marcel Binz", "Akshay K. Jagadish", "Milena Rmus", "Eric Schulz"], "title": "Automated scientific minimization of regret", "categories": ["cs.LG"], "comment": null, "summary": "We introduce automated scientific minimization of regret (ASMR) -- a\nframework for automated computational cognitive science. Building on the\nprinciples of scientific regret minimization, ASMR leverages Centaur -- a\nrecently proposed foundation model of human cognition -- to identify gaps in an\ninterpretable cognitive model. These gaps are then addressed through automated\nrevisions generated by a language-based reasoning model. We demonstrate the\nutility of this approach in a multi-attribute decision-making task, showing\nthat ASMR discovers cognitive models that predict human behavior at noise\nceiling while retaining interpretability. Taken together, our results highlight\nthe potential of ASMR to automate core components of the cognitive modeling\npipeline."}
{"id": "2505.17872", "pdf": "https://arxiv.org/pdf/2505.17872", "abs": "https://arxiv.org/abs/2505.17872", "authors": ["Licheng Pan", "Zhichao Chen", "Haoxuan Li", "Guangyi Liu", "Zhijian Xu", "Zhaoran Liu", "Hao Wang", "Ying Wei"], "title": "Mixture of Low Rank Adaptation with Partial Parameter Sharing for Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-task forecasting has become the standard approach for time-series\nforecasting (TSF). However, we show that it suffers from an Expressiveness\nBottleneck, where predictions at different time steps share the same\nrepresentation, leading to unavoidable errors even with optimal\nrepresentations. To address this issue, we propose a two-stage framework:\nfirst, pre-train a foundation model for one-step-ahead prediction; then, adapt\nit using step-specific LoRA modules.This design enables the foundation model to\nhandle any number of forecast steps while avoiding the expressiveness\nbottleneck. We further introduce the Mixture-of-LoRA (MoLA) model, which\nemploys adaptively weighted LoRA experts to achieve partial parameter sharing\nacross steps. This approach enhances both efficiency and forecasting\nperformance by exploiting interdependencies between forecast steps. Experiments\nshow that MoLA significantly improves model expressiveness and outperforms\nstate-of-the-art time-series forecasting methods. Code is available at\nhttps://anonymous.4open.science/r/MoLA-BC92."}
{"id": "2505.17662", "pdf": "https://arxiv.org/pdf/2505.17662", "abs": "https://arxiv.org/abs/2505.17662", "authors": ["Tianheng Ling", "Chao Qian", "Lukas Johannes Ha√üler", "Gregor Schiele"], "title": "Automating Versatile Time-Series Analysis with Tiny Transformers on Embedded FPGAs", "categories": ["cs.LG"], "comment": "6 pages, 5 figures, 1 table, accepted by IEEE Computer Society Annual\n  Symposium on VLSI (ISVLSI 2025)", "summary": "Transformer-based models have shown strong performance across diverse\ntime-series tasks, but their deployment on resource-constrained devices remains\nchallenging due to high memory and computational demand. While prior work\ntargeting Microcontroller Units (MCUs) has explored hardware-specific\noptimizations, such approaches are often task-specific and limited to 8-bit\nfixed-point precision. Field-Programmable Gate Arrays (FPGAs) offer greater\nflexibility, enabling fine-grained control over data precision and\narchitecture. However, existing FPGA-based deployments of Transformers for\ntime-series analysis typically focus on high-density platforms with manual\nconfiguration. This paper presents a unified and fully automated deployment\nframework for Tiny Transformers on embedded FPGAs. Our framework supports a\ncompact encoder-only Transformer architecture across three representative\ntime-series tasks (forecasting, classification, and anomaly detection). It\ncombines quantization-aware training (down to 4 bits), hardware-aware\nhyperparameter search using Optuna, and automatic VHDL generation for seamless\ndeployment. We evaluate our framework on six public datasets across two\nembedded FPGA platforms. Results show that our framework produces integer-only,\ntask-specific Transformer accelerators achieving as low as 0.033 mJ per\ninference with millisecond latency on AMD Spartan-7, while also providing\ninsights into deployment feasibility on Lattice iCE40. All source code will be\nreleased in the GitHub repository\n(https://github.com/Edwina1030/TinyTransformer4TS)."}
{"id": "2505.17883", "pdf": "https://arxiv.org/pdf/2505.17883", "abs": "https://arxiv.org/abs/2505.17883", "authors": ["Laines Schmalwasser", "Niklas Penzel", "Joachim Denzler", "Julia Niebling"], "title": "FastCAV: Efficient Computation of Concept Activation Vectors for Explaining Deep Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Accepted at ICML 2025, 27 pages, 20 figures, 9 tables", "summary": "Concepts such as objects, patterns, and shapes are how humans understand the\nworld. Building on this intuition, concept-based explainability methods aim to\nstudy representations learned by deep neural networks in relation to\nhuman-understandable concepts. Here, Concept Activation Vectors (CAVs) are an\nimportant tool and can identify whether a model learned a concept or not.\nHowever, the computational cost and time requirements of existing CAV\ncomputation pose a significant challenge, particularly in large-scale,\nhigh-dimensional architectures. To address this limitation, we introduce\nFastCAV, a novel approach that accelerates the extraction of CAVs by up to\n63.6x (on average 46.4x). We provide a theoretical foundation for our approach\nand give concrete assumptions under which it is equivalent to established\nSVM-based methods. Our empirical results demonstrate that CAVs calculated with\nFastCAV maintain similar performance while being more efficient and stable. In\ndownstream applications, i.e., concept-based explanation methods, we show that\nFastCAV can act as a replacement leading to equivalent insights. Hence, our\napproach enables previously infeasible investigations of deep models, which we\ndemonstrate by tracking the evolution of concepts during model training."}
{"id": "2505.17664", "pdf": "https://arxiv.org/pdf/2505.17664", "abs": "https://arxiv.org/abs/2505.17664", "authors": ["Jƒôdrzej Kozal", "Jan Wasilewski", "Alif Ashrafee", "Bartosz Krawczyk", "Micha≈Ç Wo≈∫niak"], "title": "What is the role of memorization in Continual Learning?", "categories": ["cs.LG"], "comment": null, "summary": "Memorization impacts the performance of deep learning algorithms. Prior works\nhave studied memorization primarily in the context of generalization and\nprivacy. This work studies the memorization effect on incremental learning\nscenarios. Forgetting prevention and memorization seem similar. However, one\nshould discuss their differences. We designed extensive experiments to evaluate\nthe impact of memorization on continual learning. We clarified that learning\nexamples with high memorization scores are forgotten faster than regular\nsamples. Our findings also indicated that memorization is necessary to achieve\nthe highest performance. However, at low memory regimes, forgetting regular\nsamples is more important. We showed that the importance of a high-memorization\nscore sample rises with an increase in the buffer size. We introduced a\nmemorization proxy and employed it in the buffer policy problem to showcase how\nmemorization could be used during incremental training. We demonstrated that\nincluding samples with a higher proxy memorization score is beneficial when the\nbuffer size is large."}
{"id": "2505.17895", "pdf": "https://arxiv.org/pdf/2505.17895", "abs": "https://arxiv.org/abs/2505.17895", "authors": ["Dan A. Calian", "Gregory Farquhar", "Iurii Kemaev", "Luisa M. Zintgraf", "Matteo Hessel", "Jeremy Shar", "Junhyuk Oh", "Andr√°s Gy√∂rgy", "Tom Schaul", "Jeffrey Dean", "Hado van Hasselt", "David Silver"], "title": "DataRater: Meta-Learned Dataset Curation", "categories": ["stat.ML", "cs.AI", "cs.LG", "I.2.6"], "comment": null, "summary": "The quality of foundation models depends heavily on their training data.\nConsequently, great efforts have been put into dataset curation. Yet most\napproaches rely on manual tuning of coarse-grained mixtures of large buckets of\ndata, or filtering by hand-crafted heuristics. An approach that is ultimately\nmore scalable (let alone more satisfying) is to \\emph{learn} which data is\nactually valuable for training. This type of meta-learning could allow more\nsophisticated, fine-grained, and effective curation. Our proposed\n\\emph{DataRater} is an instance of this idea. It estimates the value of\ntraining on any particular data point. This is done by meta-learning using\n`meta-gradients', with the objective of improving training efficiency on held\nout data. In extensive experiments across a range of model scales and datasets,\nwe find that using our DataRater to filter data is highly effective, resulting\nin significantly improved compute efficiency."}
{"id": "2505.17670", "pdf": "https://arxiv.org/pdf/2505.17670", "abs": "https://arxiv.org/abs/2505.17670", "authors": ["Wenyi Wu", "Zixuan Song", "Kun Zhou", "Yifei Shao", "Zhiting Hu", "Biwei Huang"], "title": "Towards General Continuous Memory for Vision-Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Language models (LMs) and their extension, vision-language models (VLMs),\nhave achieved remarkable performance across various tasks. However, they still\nstruggle with complex reasoning tasks that require multimodal or multilingual\nreal-world knowledge. To support such capabilities, an external memory system\nthat can efficiently provide relevant multimodal information is essential.\nExisting approaches generally concatenate image and text tokens into a long\nsequence as memory, which, however, may drastically increase context length and\neven degrade performance. In contrast, we propose using continuous memory, a\ncompact set of dense embeddings to more effectively and efficiently represent\nmultimodal and multilingual knowledge. Our key insight is that a VLM can serve\nas its own continuous memory encoder. We empirically show that this design\nimproves performance on complex multimodal reasoning tasks. Building on this,\nwe introduce a data-efficient and parameter-efficient method to fine-tune the\nVLM into a memory encoder, requiring only 1.2% of the model's parameters and a\nsmall corpus of 15.6K self-synthesized samples. Our approach CoMEM utilizes\nVLM's original capabilities to encode arbitrary multimodal and multilingual\nknowledge into just 8 continuous embeddings. Since the inference-time VLM\nremains frozen, our memory module is plug-and-play and can be flexibly\nintegrated as needed. Extensive experiments across eight multimodal reasoning\nbenchmarks demonstrate the effectiveness of our approach."}
{"id": "2505.17909", "pdf": "https://arxiv.org/pdf/2505.17909", "abs": "https://arxiv.org/abs/2505.17909", "authors": ["Bram Grooten", "Farid Hasanov", "Chenxiang Zhang", "Qiao Xiao", "Boqian Wu", "Zahra Atashgahi", "Ghada Sokar", "Shiwei Liu", "Lu Yin", "Elena Mocanu", "Mykola Pechenizkiy", "Decebal Constantin Mocanu"], "title": "NeuroTrails: Training with Dynamic Sparse Heads as the Key to Effective Ensembling", "categories": ["cs.LG", "cs.AI"], "comment": "Our open-source code is available at\n  https://github.com/bramgrooten/neurotrails", "summary": "Model ensembles have long been a cornerstone for improving generalization and\nrobustness in deep learning. However, their effectiveness often comes at the\ncost of substantial computational overhead. To address this issue,\nstate-of-the-art methods aim to replicate ensemble-class performance without\nrequiring multiple independently trained networks. Unfortunately, these\nalgorithms often still demand considerable compute at inference. In response to\nthese limitations, we introduce $\\textbf{NeuroTrails}$, a sparse multi-head\narchitecture with dynamically evolving topology. This unexplored model-agnostic\ntraining paradigm improves ensemble performance while reducing the required\nresources. We analyze the underlying reason for its effectiveness and observe\nthat the various neural trails induced by dynamic sparsity attain a\n$\\textit{Goldilocks zone}$ of prediction diversity. NeuroTrails displays\nefficacy with convolutional and transformer-based architectures on computer\nvision and language tasks. Experiments on ResNet-50/ImageNet, LLaMA-350M/C4,\namong many others, demonstrate increased accuracy and stronger robustness in\nzero-shot generalization, while requiring significantly fewer parameters."}
{"id": "2505.17694", "pdf": "https://arxiv.org/pdf/2505.17694", "abs": "https://arxiv.org/abs/2505.17694", "authors": ["Zhibin Wang", "Rui Ning", "Chao Fang", "Zhonghui Zhang", "Xi Lin", "Shaobo Ma", "Mo Zhou", "Xue Li", "Zhongfeng Wang", "Chengying Huan", "Rong Gu", "Kun Yang", "Guihai Chen", "Sheng Zhong", "Chen Tian"], "title": "FlashForge: Ultra-Efficient Prefix-Aware Attention for LLM Decoding", "categories": ["cs.LG"], "comment": null, "summary": "Prefix-sharing among multiple prompts presents opportunities to combine the\noperations of the shared prefix, while attention computation in the decode\nstage, which becomes a critical bottleneck with increasing context lengths, is\na memory-intensive process requiring heavy memory access on the key-value (KV)\ncache of the prefixes. Therefore, in this paper, we explore the potential of\nprefix-sharing in the attention computation of the decode stage. However, the\ntree structure of the prefix-sharing mechanism presents significant challenges\nfor attention computation in efficiently processing shared KV cache access\npatterns while managing complex dependencies and balancing irregular workloads.\nTo address the above challenges, we propose a dedicated attention kernel to\ncombine the memory access of shared prefixes in the decoding stage, namely\nFlashForge. FlashForge delivers two key innovations: a novel shared-prefix\nattention kernel that optimizes memory hierarchy and exploits both intra-block\nand inter-block parallelism, and a comprehensive workload balancing mechanism\nthat efficiently estimates cost, divides tasks, and schedules execution.\nExperimental results show that FlashForge achieves an average 1.9x speedup and\n120.9x memory access reduction compared to the state-of-the-art FlashDecoding\nkernel regarding attention computation in the decode stage and 3.8x end-to-end\ntime per output token compared to the vLLM."}
{"id": "2505.17967", "pdf": "https://arxiv.org/pdf/2505.17967", "abs": "https://arxiv.org/abs/2505.17967", "authors": ["Ionut-Vlad Modoranu", "Mher Safaryan", "Erik Schultheis", "Dan Alistarh"], "title": "SVD-Free Low-Rank Adaptive Gradient Optimization for Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Low-rank optimization has emerged as a promising direction in training large\nlanguage models (LLMs) to reduce the memory usage of adaptive optimizers by\nconstraining learning to a lower-dimensional space. Prior work typically\nprojects gradients of linear layers using approaches based on Singular Value\nDecomposition (SVD). However, applying SVD-based procedures individually to\neach layer in large models is computationally expensive and incurs additional\nmemory costs due to storing the projection matrices. In this work, we propose a\ncomputationally efficient and conceptually simple two-step procedure to\napproximate SVD-based gradient projections into lower-dimensional spaces.\nFirst, we construct a complete orthogonal basis using predefined orthogonal\nmatrices of the Discrete Cosine Transform (DCT). Second, we adaptively select\nbasis columns based on their alignment with the gradient of each layer. Each\nprojection matrix in our method is obtained via a single matrix multiplication\nfollowed by a lightweight sorting step to identify the most relevant basis\nvectors. Due to the predefined nature of the orthogonal bases, they are\ncomputed once at the start of training. During training, we store only the\nindices of the selected columns, avoiding the need to store full projection\nmatrices for each layer. Our numerical experiments on both pre-training and\nfine-tuning tasks demonstrate the effectiveness of our dual strategy in\napproximating optimal low-rank projections, matching the performance of costly\nSVD-based methods while achieving faster runtime and reduced memory usage."}
{"id": "2505.17695", "pdf": "https://arxiv.org/pdf/2505.17695", "abs": "https://arxiv.org/abs/2505.17695", "authors": ["Dong-Hee Kim", "Hyunjee Song", "Donghyun Kim"], "title": "SynRES: Towards Referring Expression Segmentation in the Wild via Synthetic Data", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Despite the advances in Referring Expression Segmentation (RES) benchmarks,\ntheir evaluation protocols remain constrained, primarily focusing on either\nsingle targets with short queries (containing minimal attributes) or multiple\ntargets from distinctly different queries on a single domain. This limitation\nsignificantly hinders the assessment of more complex reasoning capabilities in\nRES models. We introduce WildRES, a novel benchmark that incorporates long\nqueries with diverse attributes and non-distinctive queries for multiple\ntargets. This benchmark spans diverse application domains, including autonomous\ndriving environments and robotic manipulation scenarios, thus enabling more\nrigorous evaluation of complex reasoning capabilities in real-world settings.\nOur analysis reveals that current RES models demonstrate substantial\nperformance deterioration when evaluated on WildRES. To address this challenge,\nwe introduce SynRES, an automated pipeline generating densely paired\ncompositional synthetic training data through three innovations: (1) a dense\ncaption-driven synthesis for attribute-rich image-mask-expression triplets, (2)\nreliable semantic alignment mechanisms rectifying caption-pseudo mask\ninconsistencies via Image-Text Aligned Grouping, and (3) domain-aware\naugmentations incorporating mosaic composition and superclass replacement to\nemphasize generalization ability and distinguishing attributes over object\ncategories. Experimental results demonstrate that models trained with SynRES\nachieve state-of-the-art performance, improving gIoU by 2.0% on WildRES-ID and\n3.8% on WildRES-DS. Code and datasets are available at\nhttps://github.com/UTLLab/SynRES."}
{"id": "2505.17968", "pdf": "https://arxiv.org/pdf/2505.17968", "abs": "https://arxiv.org/abs/2505.17968", "authors": ["Jiayi Geng", "Howard Chen", "Dilip Arumugam", "Thomas L. Griffiths"], "title": "Are Large Language Models Reliable AI Scientists? Assessing Reverse-Engineering of Black-Box Systems", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages", "summary": "Using AI to create autonomous researchers has the potential to accelerate\nscientific discovery. A prerequisite for this vision is understanding how well\nan AI model can identify the underlying structure of a black-box system from\nits behavior. In this paper, we explore how well a large language model (LLM)\nlearns to identify a black-box function from passively observed versus actively\ncollected data. We investigate the reverse-engineering capabilities of LLMs\nacross three distinct types of black-box systems, each chosen to represent\ndifferent problem domains where future autonomous AI researchers may have\nconsiderable impact: Program, Formal Language, and Math Equation. Through\nextensive experiments, we show that LLMs fail to extract information from\nobservations, reaching a performance plateau that falls short of the ideal of\nBayesian inference. However, we demonstrate that prompting LLMs to not only\nobserve but also intervene -- actively querying the black-box with specific\ninputs to observe the resulting output -- improves performance by allowing LLMs\nto test edge cases and refine their beliefs. By providing the intervention data\nfrom one LLM to another, we show that this improvement is partly a result of\nengaging in the process of generating effective interventions, paralleling\nresults in the literature on human learning. Further analysis reveals that\nengaging in intervention can help LLMs escape from two common failure modes:\novercomplication, where the LLM falsely assumes prior knowledge about the\nblack-box, and overlooking, where the LLM fails to incorporate observations.\nThese insights provide practical guidance for helping LLMs more effectively\nreverse-engineer black-box systems, supporting their use in making new\ndiscoveries."}
{"id": "2505.17701", "pdf": "https://arxiv.org/pdf/2505.17701", "abs": "https://arxiv.org/abs/2505.17701", "authors": ["Jaewon Cheon", "Pilsung Kang"], "title": "COUNTDOWN: Contextually Sparse Activation Filtering Out Unnecessary Weights in Down Projection", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "The growing size of large language models has created significant\ncomputational inefficiencies. To address this challenge, sparse activation\nmethods selectively deactivates non-essential parameters during inference,\nreducing computational costs in FFNN layers. While existing methods focus on\nnon-linear gating mechanisms, we hypothesize that the sparsity of the FFNN\nlayer lies globally in the form of a linear combination over its internal down\nprojection matrix. Based on this insight, we propose two methods: M-COUNTDOWN,\nleveraging indirect coefficients, and D-COUNTDOWN, utilizing direct\ncoefficients of the linear combination. Experimental results demonstrate that\nD-COUNTDOWN can omit 90% of computations with performance loss as low as 5.5%\nideally, while M-COUNTDOWN provides a predictor-free solution with up to 29.4%\nbetter performance preservation compared to existing methods. Our specialized\nkernel implementations effectively realize these theoretical gains into\nsubstantial real-world acceleration."}
{"id": "2505.17974", "pdf": "https://arxiv.org/pdf/2505.17974", "abs": "https://arxiv.org/abs/2505.17974", "authors": ["Viktoriia Chekalina", "Daniil Moskovskiy", "Daria Cherniuk", "Maxim Kurkin", "Andrey Kuznetsov", "Evgeny Frolov"], "title": "Generalized Fisher-Weighted SVD: Scalable Kronecker-Factored Fisher Approximation for Compressing Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The Fisher information is a fundamental concept for characterizing the\nsensitivity of parameters in neural networks. However, leveraging the full\nobserved Fisher information is too expensive for large models, so most methods\nrely on simple diagonal approximations. While efficient, this approach ignores\nparameter correlations, often resulting in reduced performance on downstream\ntasks. In this work, we mitigate these limitations and propose Generalized\nFisher-Weighted SVD (GFWSVD), a post-training LLM compression technique that\naccounts for both diagonal and off-diagonal elements of the Fisher information\nmatrix, providing a more accurate reflection of parameter importance. To make\nthe method tractable, we introduce a scalable adaptation of the\nKronecker-factored approximation algorithm for the observed Fisher information.\nWe demonstrate the effectiveness of our method on LLM compression, showing\nimprovements over existing compression baselines. For example, at a 20\ncompression rate on the MMLU benchmark, our method outperforms FWSVD, which is\nbased on a diagonal approximation of the Fisher information, by 5 percent,\nSVD-LLM by 3 percent, and ASVD by 6 percent compression rate."}
{"id": "2505.17708", "pdf": "https://arxiv.org/pdf/2505.17708", "abs": "https://arxiv.org/abs/2505.17708", "authors": ["Dingling Yao", "Shimeng Huang", "Riccardo Cadei", "Kun Zhang", "Francesco Locatello"], "title": "The Third Pillar of Causal Analysis? A Measurement Perspective on Causal Representations", "categories": ["cs.LG"], "comment": "22 pages, 12 figures, 2 tables", "summary": "Causal reasoning and discovery, two fundamental tasks of causal analysis,\noften face challenges in applications due to the complexity, noisiness, and\nhigh-dimensionality of real-world data. Despite recent progress in identifying\nlatent causal structures using causal representation learning (CRL), what makes\nlearned representations useful for causal downstream tasks and how to evaluate\nthem are still not well understood. In this paper, we reinterpret CRL using a\nmeasurement model framework, where the learned representations are viewed as\nproxy measurements of the latent causal variables. Our approach clarifies the\nconditions under which learned representations support downstream causal\nreasoning and provides a principled basis for quantitatively assessing the\nquality of representations using a new Test-based Measurement EXclusivity\n(T-MEX) score. We validate T-MEX across diverse causal inference scenarios,\nincluding numerical simulations and real-world ecological video analysis,\ndemonstrating that the proposed framework and corresponding score effectively\nassess the identification of learned representations and their usefulness for\ncausal downstream tasks."}
{"id": "2505.17987", "pdf": "https://arxiv.org/pdf/2505.17987", "abs": "https://arxiv.org/abs/2505.17987", "authors": ["Weihang You", "Hanqi Jiang", "Zishuai Liu", "Zihang Xie", "Tianming Liu", "Jin Lu", "Fei Dou"], "title": "ADLGen: Synthesizing Symbolic, Event-Triggered Sensor Sequences for Human Activity Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real world collection of Activities of Daily Living data is challenging due\nto privacy concerns, costly deployment and labeling, and the inherent sparsity\nand imbalance of human behavior. We present ADLGen, a generative framework\nspecifically designed to synthesize realistic, event triggered, and symbolic\nsensor sequences for ambient assistive environments. ADLGen integrates a\ndecoder only Transformer with sign based symbolic temporal encoding, and a\ncontext and layout aware sampling mechanism to guide generation toward\nsemantically rich and physically plausible sensor event sequences. To enhance\nsemantic fidelity and correct structural inconsistencies, we further\nincorporate a large language model into an automatic generate evaluate refine\nloop, which verifies logical, behavioral, and temporal coherence and generates\ncorrection rules without manual intervention or environment specific tuning.\nThrough comprehensive experiments with novel evaluation metrics, ADLGen is\nshown to outperform baseline generators in statistical fidelity, semantic\nrichness, and downstream activity recognition, offering a scalable and\nprivacy-preserving solution for ADL data synthesis."}
{"id": "2505.17714", "pdf": "https://arxiv.org/pdf/2505.17714", "abs": "https://arxiv.org/abs/2505.17714", "authors": ["Ben Rahman"], "title": "PPO-BR: Dual-Signal Entropy-Reward Adaptation for Trust Region Policy Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "This manuscript builds upon an earlier version posted to TechRxiv.\n  This arXiv version includes an updated comparison with GRPO (Group Relative\n  Policy Optimization)", "summary": "Despite Proximal Policy Optimization (PPO) dominating policy gradient methods\n-- from robotic control to game AI -- its static trust region forces a brittle\ntrade-off: aggressive clipping stifles early exploration, while late-stage\nupdates destabilize convergence. PPO-BR establishes a new paradigm in adaptive\nRL by fusing exploration and convergence signals into a single bounded trust\nregion -- a theoretically grounded innovation that outperforms five SOTA\nbaselines with less than 2% overhead. This work bridges a critical gap in\nphase-aware learning, enabling real-world deployment in safety-critical systems\nlike robotic surgery within a single adaptive mechanism. PPO-BR achieves 29.1%\nfaster convergence by combining: (1) entropy-driven expansion (epsilon up) for\nexploration in high-uncertainty states, and (2) reward-guided contraction\n(epsilon down) for convergence stability. On six diverse benchmarks (MuJoCo,\nAtari, sparse-reward), PPO-BR achieves 29.1% faster convergence (p < 0.001),\n2.3x lower reward variance than PPO, and less than 1.8% runtime overhead with\nonly five lines of code change. PPO-BR's simplicity and theoretical guarantees\nmake it ready-to-deploy in safety-critical domains -- from surgical robotics to\nautonomous drones. In contrast to recent methods such as Group Relative Policy\nOptimization (GRPO), PPO-BR offers a unified entropy-reward mechanism\napplicable to both language models and general reinforcement learning\nenvironments."}
{"id": "2505.17988", "pdf": "https://arxiv.org/pdf/2505.17988", "abs": "https://arxiv.org/abs/2505.17988", "authors": ["Yutong Chen", "Jiandong Gao", "Ji Wu"], "title": "Towards Revealing the Effectiveness of Small-Scale Fine-tuning in R1-style Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "11 figs, 3 table, preprint", "summary": "R1-style Reinforcement Learning (RL) significantly enhances Large Language\nModels' reasoning capabilities, yet the mechanism behind rule-based RL remains\nunclear. We found that small-scale SFT has significant influence on RL but\nshows poor efficiency. To explain our observations, we propose an analytical\nframework and compare the efficiency of SFT and RL by measuring sample effect.\nHypothetical analysis show that SFT efficiency is limited by training data.\nGuided by our analysis, we propose Re-distillation, a technique that fine-tunes\npretrain model through small-scale distillation from the RL-trained policy.\nExperiments on Knight & Knave and MATH datasets demonstrate re-distillation's\nsurprising efficiency: re-distilled models match RL performance with far fewer\nsamples and less computation. Empirical verification shows that sample effect\nis a good indicator of performance improvements. As a result, on K&K dataset,\nour re-distilled Qwen2.5-1.5B model surpasses DeepSeek-V3-0324 with only 1K SFT\nsamples. On MATH, Qwen2.5-1.5B fine-tuned with re-distilled 500 samples matches\nits instruct-tuned variant without RL. Our work explains several interesting\nphenomena in R1-style RL, shedding light on the mechanisms behind its empirical\nsuccess. Code is available at: https://github.com/on1262/deep-reasoning"}
{"id": "2505.17716", "pdf": "https://arxiv.org/pdf/2505.17716", "abs": "https://arxiv.org/abs/2505.17716", "authors": ["Erhu Feng", "Wenbo Zhou", "Zibin Liu", "Le Chen", "Yunpeng Dong", "Cheng Zhang", "Yisheng Zhao", "Dong Du", "Zhichao Hua", "Yubin Xia", "Haibo Chen"], "title": "Get Experience from Practice: LLM Agents with Record & Replay", "categories": ["cs.LG", "cs.MA"], "comment": null, "summary": "AI agents, empowered by Large Language Models (LLMs) and communication\nprotocols such as MCP and A2A, have rapidly evolved from simple chatbots to\nautonomous entities capable of executing complex, multi-step tasks,\ndemonstrating great potential. However, the LLMs' inherent uncertainty and\nheavy computational resource requirements pose four significant challenges to\nthe development of safe and efficient agents: reliability, privacy, cost and\nperformance. Existing approaches, like model alignment, workflow constraints\nand on-device model deployment, can partially alleviate some issues but often\nwith limitations, failing to fundamentally resolve these challenges.\n  This paper proposes a new paradigm called AgentRR (Agent Record & Replay),\nwhich introduces the classical record-and-replay mechanism into AI agent\nframeworks. The core idea is to: 1. Record an agent's interaction trace with\nits environment and internal decision process during task execution, 2.\nSummarize this trace into a structured \"experience\" encapsulating the workflow\nand constraints, and 3. Replay these experiences in subsequent similar tasks to\nguide the agent's behavior. We detail a multi-level experience abstraction\nmethod and a check function mechanism in AgentRR: the former balances\nexperience specificity and generality, while the latter serves as a trust\nanchor to ensure completeness and safety during replay. In addition, we explore\nmultiple application modes of AgentRR, including user-recorded task\ndemonstration, large-small model collaboration and privacy-aware agent\nexecution, and envision an experience repository for sharing and reusing\nknowledge to further reduce deployment cost."}
{"id": "2505.17989", "pdf": "https://arxiv.org/pdf/2505.17989", "abs": "https://arxiv.org/abs/2505.17989", "authors": ["Benjamin Turtel", "Danny Franklin", "Kris Skotheim", "Luke Hewitt", "Philipp Schoenegger"], "title": "Outcome-based Reinforcement Learning to Predict the Future", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has boosted math and\ncoding in large language models, yet there has been little effort to extend\nRLVR into messier, real-world domains like forecasting. One sticking point is\nthat outcome-based reinforcement learning for forecasting must learn from\nbinary, delayed, and noisy rewards, a regime where standard fine-tuning is\nbrittle. We show that outcome-only online RL on a 14B model can match\nfrontier-scale accuracy and surpass it in calibration and hypothetical\nprediction market betting by adapting two leading algorithms, Group-Relative\nPolicy Optimisation (GRPO) and ReMax, to the forecasting setting. Our\nadaptations remove per-question variance scaling in GRPO, apply\nbaseline-subtracted advantages in ReMax, hydrate training with 100k temporally\nconsistent synthetic questions, and introduce lightweight guard-rails that\npenalise gibberish, non-English responses and missing rationales, enabling a\nsingle stable pass over 110k events. Scaling ReMax to 110k questions and\nensembling seven predictions yields a 14B model that matches frontier baseline\no1 on accuracy on our holdout set (Brier = 0.193, p = 0.23) while beating it in\ncalibration (ECE = 0.042, p < 0.001). A simple trading rule turns this\ncalibration edge into \\$127 of hypothetical profit versus \\$92 for o1 (p =\n0.037). This demonstrates that refined RLVR methods can convert small-scale\nLLMs into potentially economically valuable forecasting tools, with\nimplications for scaling this to larger models."}
{"id": "2505.17720", "pdf": "https://arxiv.org/pdf/2505.17720", "abs": "https://arxiv.org/abs/2505.17720", "authors": ["Hampus Linander", "Christoffer Petersson", "Daniel Persson", "Jan E. Gerken"], "title": "PEAR: Equal Area Weather Forecasting on the Sphere", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "Machine learning methods for global medium-range weather forecasting have\nrecently received immense attention. Following the publication of the Pangu\nWeather model, the first deep learning model to outperform traditional\nnumerical simulations of the atmosphere, numerous models have been published in\nthis domain, building on Pangu's success. However, all of these models operate\non input data and produce predictions on the Driscoll--Healy discretization of\nthe sphere which suffers from a much finer grid at the poles than around the\nequator. In contrast, in the Hierarchical Equal Area iso-Latitude Pixelization\n(HEALPix) of the sphere, each pixel covers the same surface area, removing\nunphysical biases. Motivated by a growing support for this grid in meteorology\nand climate sciences, we propose to perform weather forecasting with deep\nlearning models which natively operate on the HEALPix grid. To this end, we\nintroduce Pangu Equal ARea (PEAR), a transformer-based weather forecasting\nmodel which operates directly on HEALPix-features and outperforms the\ncorresponding model on Driscoll--Healy without any computational overhead."}
{"id": "2505.18003", "pdf": "https://arxiv.org/pdf/2505.18003", "abs": "https://arxiv.org/abs/2505.18003", "authors": ["Joshua Clymer", "Jonah Weinbaum", "Robert Kirk", "Kimberly Mai", "Selena Zhang", "Xander Davies"], "title": "An Example Safety Case for Safeguards Against Misuse", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Existing evaluations of AI misuse safeguards provide a patchwork of evidence\nthat is often difficult to connect to real-world decisions. To bridge this gap,\nwe describe an end-to-end argument (a \"safety case\") that misuse safeguards\nreduce the risk posed by an AI assistant to low levels. We first describe how a\nhypothetical developer red teams safeguards, estimating the effort required to\nevade them. Then, the developer plugs this estimate into a quantitative \"uplift\nmodel\" to determine how much barriers introduced by safeguards dissuade misuse\n(https://www.aimisusemodel.com/). This procedure provides a continuous signal\nof risk during deployment that helps the developer rapidly respond to emerging\nthreats. Finally, we describe how to tie these components together into a\nsimple safety case. Our work provides one concrete path -- though not the only\npath -- to rigorously justifying AI misuse risks are low."}
{"id": "2505.17730", "pdf": "https://arxiv.org/pdf/2505.17730", "abs": "https://arxiv.org/abs/2505.17730", "authors": ["Stefan Schoepf", "Michael Curtis Mozer", "Nicole Elyse Mitchell", "Alexandra Brintrup", "Georgios Kaissis", "Peter Kairouz", "Eleni Triantafillou"], "title": "Redirection for Erasing Memory (REM): Towards a universal unlearning method for corrupted data", "categories": ["cs.LG"], "comment": null, "summary": "Machine unlearning is studied for a multitude of tasks, but specialization of\nunlearning methods to particular tasks has made their systematic comparison\nchallenging. To address this issue, we propose a conceptual space to\ncharacterize diverse corrupted data unlearning tasks in vision classifiers.\nThis space is described by two dimensions, the discovery rate (the fraction of\nthe corrupted data that are known at unlearning time) and the statistical\nregularity of the corrupted data (from random exemplars to shared concepts).\nMethods proposed previously have been targeted at portions of this space and-we\nshow-fail predictably outside these regions. We propose a novel method,\nRedirection for Erasing Memory (REM), whose key feature is that corrupted data\nare redirected to dedicated neurons introduced at unlearning time and then\ndiscarded or deactivated to suppress the influence of corrupted data. REM\nperforms strongly across the space of tasks, in contrast to prior SOTA methods\nthat fail outside the regions for which they were designed."}
{"id": "2505.18028", "pdf": "https://arxiv.org/pdf/2505.18028", "abs": "https://arxiv.org/abs/2505.18028", "authors": ["Zizhao Chen", "Yoav Artzi"], "title": "Knot So Simple: A Minimalistic Environment for Spatial Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "comment": null, "summary": "We propose KnotGym, an interactive environment for complex, spatial reasoning\nand manipulation. KnotGym includes goal-oriented rope manipulation tasks with\nvarying levels of complexity, all requiring acting from pure image\nobservations. Tasks are defined along a clear and quantifiable axis of\ncomplexity based on the number of knot crossings, creating a natural\ngeneralization test. KnotGym has a simple observation space, allowing for\nscalable development, yet it highlights core challenges in integrating acute\nperception, spatial reasoning, and grounded manipulation. We evaluate methods\nof different classes, including model-based RL, model-predictive control, and\nchain-of-thought reasoning, and illustrate the challenges KnotGym presents.\nKnotGym is available at https://github.com/lil-lab/knotgym."}
{"id": "2505.17734", "pdf": "https://arxiv.org/pdf/2505.17734", "abs": "https://arxiv.org/abs/2505.17734", "authors": ["Ahmet Onur Akman", "Anastasia Psarou", "Micha≈Ç Hoffmann", "≈Åukasz Gorczyca", "≈Åukasz Kowalski", "Pawe≈Ç Gora", "Grzegorz Jamr√≥z", "Rafa≈Ç Kucharski"], "title": "URB -- Urban Routing Benchmark for RL-equipped Connected Autonomous Vehicles", "categories": ["cs.LG"], "comment": null, "summary": "Connected Autonomous Vehicles (CAVs) promise to reduce congestion in future\nurban networks, potentially by optimizing their routing decisions. Unlike for\nhuman drivers, these decisions can be made with collective, data-driven\npolicies, developed by machine learning algorithms. Reinforcement learning (RL)\ncan facilitate the development of such collective routing strategies, yet\nstandardized and realistic benchmarks are missing. To that end, we present\n\\our{}: Urban Routing Benchmark for RL-equipped Connected Autonomous Vehicles.\n\\our{} is a comprehensive benchmarking environment that unifies evaluation\nacross 29 real-world traffic networks paired with realistic demand patterns.\n\\our{} comes with a catalog of predefined tasks, four state-of-the-art\nmulti-agent RL (MARL) algorithm implementations, three baseline methods,\ndomain-specific performance metrics, and a modular configuration scheme. Our\nresults suggest that, despite the lengthy and costly training, state-of-the-art\nMARL algorithms rarely outperformed humans. Experimental results reported in\nthis paper initiate the first leaderboard for MARL in large-scale urban routing\noptimization and reveal that current approaches struggle to scale, emphasizing\nthe urgent need for advancements in this domain."}
{"id": "2505.18044", "pdf": "https://arxiv.org/pdf/2505.18044", "abs": "https://arxiv.org/abs/2505.18044", "authors": ["Zhishuai Liu", "Pan Xu"], "title": "Linear Mixture Distributionally Robust Markov Decision Processes", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "comment": "26 pages, 7 figures", "summary": "Many real-world decision-making problems face the off-dynamics challenge: the\nagent learns a policy in a source domain and deploys it in a target domain with\ndifferent state transitions. The distributionally robust Markov decision\nprocess (DRMDP) addresses this challenge by finding a robust policy that\nperforms well under the worst-case environment within a pre-specified\nuncertainty set of transition dynamics. Its effectiveness heavily hinges on the\nproper design of these uncertainty sets, based on prior knowledge of the\ndynamics. In this work, we propose a novel linear mixture DRMDP framework,\nwhere the nominal dynamics is assumed to be a linear mixture model. In contrast\nwith existing uncertainty sets directly defined as a ball centered around the\nnominal kernel, linear mixture DRMDPs define the uncertainty sets based on a\nball around the mixture weighting parameter. We show that this new framework\nprovides a more refined representation of uncertainties compared to\nconventional models based on $(s,a)$-rectangularity and $d$-rectangularity,\nwhen prior knowledge about the mixture model is present. We propose a meta\nalgorithm for robust policy learning in linear mixture DRMDPs with general\n$f$-divergence defined uncertainty sets, and analyze its sample complexities\nunder three divergence metrics instantiations: total variation,\nKullback-Leibler, and $\\chi^2$ divergences. These results establish the\nstatistical learnability of linear mixture DRMDPs, laying the theoretical\nfoundation for future research on this new setting."}
{"id": "2505.17740", "pdf": "https://arxiv.org/pdf/2505.17740", "abs": "https://arxiv.org/abs/2505.17740", "authors": ["Rodrigo Mart√≠nez-Pe√±a", "Rom√°n Or√∫s"], "title": "A tensor network approach for chaotic time series prediction", "categories": ["cs.LG", "cs.NE", "physics.comp-ph"], "comment": "12 pages, 3 figures. Comments are welcome!", "summary": "Making accurate predictions of chaotic time series is a complex challenge.\nReservoir computing, a neuromorphic-inspired approach, has emerged as a\npowerful tool for this task. It exploits the memory and nonlinearity of\ndynamical systems without requiring extensive parameter tuning. However,\nselecting and optimizing reservoir architectures remains an open problem.\nNext-generation reservoir computing simplifies this problem by employing\nnonlinear vector autoregression based on truncated Volterra series, thereby\nreducing hyperparameter complexity. Nevertheless, the latter suffers from\nexponential parameter growth in terms of the maximum monomial degree. Tensor\nnetworks offer a promising solution to this issue by decomposing\nmultidimensional arrays into low-dimensional structures, thus mitigating the\ncurse of dimensionality. This paper explores the application of a previously\nproposed tensor network model for predicting chaotic time series, demonstrating\nits advantages in terms of accuracy and computational efficiency compared to\nconventional echo state networks. Using a state-of-the-art tensor network\napproach enables us to bridge the gap between the tensor network and reservoir\ncomputing communities, fostering advances in both fields."}
{"id": "2505.18080", "pdf": "https://arxiv.org/pdf/2505.18080", "abs": "https://arxiv.org/abs/2505.18080", "authors": ["Chunlin Gong", "Yin Wang", "Jingru Li", "Hanleran Zhang"], "title": "AFD-STA: Adaptive Filtering Denoising with Spatiotemporal Attention for Chaotic System Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 11 figures", "summary": "This paper presents AFD-STA Net, a neural framework integrating adaptive\nfiltering and spatiotemporal dynamics learning for predicting high-dimensional\nchaotic systems governed by partial differential equations. The architecture\ncombines: 1) An adaptive exponential smoothing module with position-aware decay\ncoefficients for robust attractor reconstruction, 2) Parallel attention\nmechanisms capturing cross-temporal and spatial dependencies, 3) Dynamic gated\nfusion of multiscale features, and 4) Deep projection networks with\ndimension-scaling capabilities. Numerical experiments on nonlinear PDE systems\ndemonstrate the model's effectiveness in maintaining prediction accuracy under\nboth smooth and strongly chaotic regimes while exhibiting noise tolerance\nthrough adaptive filtering. Component ablation studies confirm critical\ncontributions from each module, particularly highlighting the essential role of\nspatiotemporal attention in learning complex dynamical interactions. The\nframework shows promising potential for real-world applications requiring\nsimultaneous handling of measurement uncertainties and high-dimensional\nnonlinear dynamics."}
{"id": "2505.17741", "pdf": "https://arxiv.org/pdf/2505.17741", "abs": "https://arxiv.org/abs/2505.17741", "authors": ["Zijing Ou", "Ruixiang Zhang", "Yingzhen Li"], "title": "Discrete Neural Flow Samplers with Locally Equivariant Transformer", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Sampling from unnormalised discrete distributions is a fundamental problem\nacross various domains. While Markov chain Monte Carlo offers a principled\napproach, it often suffers from slow mixing and poor convergence. In this\npaper, we propose Discrete Neural Flow Samplers (DNFS), a trainable and\nefficient framework for discrete sampling. DNFS learns the rate matrix of a\ncontinuous-time Markov chain such that the resulting dynamics satisfy the\nKolmogorov equation. As this objective involves the intractable partition\nfunction, we then employ control variates to reduce the variance of its Monte\nCarlo estimation, leading to a coordinate descent learning algorithm. To\nfurther facilitate computational efficiency, we propose locally equivaraint\nTransformer, a novel parameterisation of the rate matrix that significantly\nimproves training efficiency while preserving powerful network expressiveness.\nEmpirically, we demonstrate the efficacy of DNFS in a wide range of\napplications, including sampling from unnormalised distributions, training\ndiscrete energy-based models, and solving combinatorial optimisation problems."}
{"id": "2505.18081", "pdf": "https://arxiv.org/pdf/2505.18081", "abs": "https://arxiv.org/abs/2505.18081", "authors": ["Adam D. Cobb", "Susmit Jha"], "title": "Backpropagation-Free Metropolis-Adjusted Langevin Algorithm", "categories": ["cs.LG", "cs.AI"], "comment": "19 Pages, 8 Figures", "summary": "Recent work on backpropagation-free learning has shown that it is possible to\nuse forward-mode automatic differentiation (AD) to perform optimization on\ndifferentiable models. Forward-mode AD requires sampling a tangent vector for\neach forward pass of a model. The result is the model evaluation with the\ndirectional derivative along the tangent. In this paper, we illustrate how the\nsampling of this tangent vector can be incorporated into the proposal mechanism\nfor the Metropolis-Adjusted Langevin Algorithm (MALA). As such, we are the\nfirst to introduce a backpropagation-free gradient-based Markov chain Monte\nCarlo (MCMC) algorithm. We also extend to a novel backpropagation-free\nposition-specific preconditioned forward-mode MALA that leverages Hessian\ninformation. Overall, we propose four new algorithms: Forward MALA; Line\nForward MALA; Pre-conditioned Forward MALA, and Pre-conditioned Line Forward\nMALA. We highlight the reduced computational cost of the forward-mode samplers\nand show that forward-mode is competitive with the original MALA, while even\noutperforming it depending on the probabilistic model. We include Bayesian\ninference results on a range of probabilistic models, including hierarchical\ndistributions and Bayesian neural networks."}
{"id": "2505.17745", "pdf": "https://arxiv.org/pdf/2505.17745", "abs": "https://arxiv.org/abs/2505.17745", "authors": ["Zeyuan Ma", "Yue-Jiao Gong", "Hongshu Guo", "Wenjie Qiu", "Sijie Ma", "Hongqiao Lian", "Jiajun Zhan", "Kaixu Chen", "Chen Wang", "Zhiyang Huang", "Zechuan Huang", "Guojun Peng", "Ran Cheng", "Yining Ma"], "title": "MetaBox-v2: A Unified Benchmark Platform for Meta-Black-Box Optimization", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": null, "summary": "Meta-Black-Box Optimization (MetaBBO) streamlines the automation of\noptimization algorithm design through meta-learning. It typically employs a\nbi-level structure: the meta-level policy undergoes meta-training to reduce the\nmanual effort required in developing algorithms for low-level optimization\ntasks. The original MetaBox (2023) provided the first open-source framework for\nreinforcement learning-based single-objective MetaBBO. However, its relatively\nnarrow scope no longer keep pace with the swift advancement in this field. In\nthis paper, we introduce MetaBox-v2 (https://github.com/MetaEvo/MetaBox) as a\nmilestone upgrade with four novel features: 1) a unified architecture\nsupporting RL, evolutionary, and gradient-based approaches, by which we\nreproduce 23 up-to-date baselines; 2) efficient parallelization schemes, which\nreduce the training/testing time by 10-40x; 3) a comprehensive benchmark suite\nof 18 synthetic/realistic tasks (1900+ instances) spanning single-objective,\nmulti-objective, multi-model, and multi-task optimization scenarios; 4)\nplentiful and extensible interfaces for custom analysis/visualization and\nintegrating to external optimization tools/benchmarks. To show the utility of\nMetaBox-v2, we carry out a systematic case study that evaluates the built-in\nbaselines in terms of the optimization performance, generalization ability and\nlearning efficiency. Valuable insights are concluded from thorough and detailed\nanalysis for practitioners and those new to the field."}
{"id": "2505.18091", "pdf": "https://arxiv.org/pdf/2505.18091", "abs": "https://arxiv.org/abs/2505.18091", "authors": ["Xinran Gu", "Kaifeng Lyu", "Jiazheng Li", "Jingzhao Zhang"], "title": "Data Mixing Can Induce Phase Transitions in Knowledge Acquisition", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are typically trained on data mixtures: most\ndata come from web scrapes, while a small portion is curated from high-quality\nsources with dense domain-specific knowledge. In this paper, we show that when\ntraining LLMs on such data mixtures, knowledge acquisition from knowledge-dense\ndatasets, unlike training exclusively on knowledge-dense data\n(arXiv:2404.05405), does not always follow a smooth scaling law but can exhibit\nphase transitions with respect to the mixing ratio and model size. Through\ncontrolled experiments on a synthetic biography dataset mixed with web-scraped\ndata, we demonstrate that: (1) as we increase the model size to a critical\nvalue, the model suddenly transitions from memorizing very few to most of the\nbiographies; (2) below a critical mixing ratio, the model memorizes almost\nnothing even with extensive training, but beyond this threshold, it rapidly\nmemorizes more biographies. We attribute these phase transitions to a capacity\nallocation phenomenon: a model with bounded capacity must act like a knapsack\nproblem solver to minimize the overall test loss, and the optimal allocation\nacross datasets can change discontinuously as the model size or mixing ratio\nvaries. We formalize this intuition in an information-theoretic framework and\nreveal that these phase transitions are predictable, with the critical mixing\nratio following a power-law relationship with the model size. Our findings\nhighlight a concrete case where a good mixing recipe for large models may not\nbe optimal for small models, and vice versa."}
{"id": "2505.17748", "pdf": "https://arxiv.org/pdf/2505.17748", "abs": "https://arxiv.org/abs/2505.17748", "authors": ["Kerol Djoumessi", "Philipp Berens"], "title": "Soft-CAM: Making black box models self-explainable for high-stakes decisions", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Convolutional neural networks (CNNs) are widely used for high-stakes\napplications like medicine, often surpassing human performance. However, most\nexplanation methods rely on post-hoc attribution, approximating the\ndecision-making process of already trained black-box models. These methods are\noften sensitive, unreliable, and fail to reflect true model reasoning, limiting\ntheir trustworthiness in critical applications. In this work, we introduce\nSoftCAM, a straightforward yet effective approach that makes standard CNN\narchitectures inherently interpretable. By removing the global average pooling\nlayer and replacing the fully connected classification layer with a\nconvolution-based class evidence layer, SoftCAM preserves spatial information\nand produces explicit class activation maps that form the basis of the model's\npredictions. Evaluated on three medical datasets, SoftCAM maintains\nclassification performance while significantly improving both the qualitative\nand quantitative explanation compared to existing post-hoc methods. Our results\ndemonstrate that CNNs can be inherently interpretable without compromising\nperformance, advancing the development of self-explainable deep learning for\nhigh-stakes decision-making."}
{"id": "2505.18102", "pdf": "https://arxiv.org/pdf/2505.18102", "abs": "https://arxiv.org/abs/2505.18102", "authors": ["Takashi Ishida", "Thanawat Lodkaew", "Ikko Yamane"], "title": "How Can I Publish My LLM Benchmark Without Giving the True Answers Away?", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ME"], "comment": null, "summary": "Publishing a large language model (LLM) benchmark on the Internet risks\ncontaminating future LLMs: the benchmark may be unintentionally (or\nintentionally) used to train or select a model. A common mitigation is to keep\nthe benchmark private and let participants submit their models or predictions\nto the organizers. However, this strategy will require trust in a single\norganization and still permits test-set overfitting through repeated queries.\nTo overcome this issue, we propose a way to publish benchmarks without\ncompletely disclosing the ground-truth answers to the questions, while still\nmaintaining the ability to openly evaluate LLMs. Our main idea is to inject\nrandomness to the answers by preparing several logically correct answers, and\nonly include one of them as the solution in the benchmark. This reduces the\nbest possible accuracy, i.e., Bayes accuracy, of the benchmark. Not only is\nthis helpful to keep us from disclosing the ground truth, but this approach\nalso offers a test for detecting data contamination. In principle, even fully\ncapable models should not surpass the Bayes accuracy. If a model surpasses this\nceiling despite this expectation, this is a strong signal of data\ncontamination. We present experimental evidence that our method can detect data\ncontamination accurately on a wide range of benchmarks, models, and training\nmethodologies."}
{"id": "2505.17749", "pdf": "https://arxiv.org/pdf/2505.17749", "abs": "https://arxiv.org/abs/2505.17749", "authors": ["Ghada Sokar", "Pablo Samuel Castro"], "title": "Mind the GAP! The Challenges of Scale in Pixel-based Deep Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Scaling deep reinforcement learning in pixel-based environments presents a\nsignificant challenge, often resulting in diminished performance. While recent\nworks have proposed algorithmic and architectural approaches to address this,\nthe underlying cause of the performance drop remains unclear. In this paper, we\nidentify the connection between the output of the encoder (a stack of\nconvolutional layers) and the ensuing dense layers as the main underlying\nfactor limiting scaling capabilities; we denote this connection as the\nbottleneck, and we demonstrate that previous approaches implicitly target this\nbottleneck. As a result of our analyses, we present global average pooling as a\nsimple yet effective way of targeting the bottleneck, thereby avoiding the\ncomplexity of earlier approaches."}
{"id": "2505.18126", "pdf": "https://arxiv.org/pdf/2505.18126", "abs": "https://arxiv.org/abs/2505.18126", "authors": ["Lorenz Wolf", "Robert Kirk", "Mirco Musolesi"], "title": "Reward Model Overoptimisation in Iterated RLHF", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "20 pages, 17 figures, 5 tables", "summary": "Reinforcement learning from human feedback (RLHF) is a widely used method for\naligning large language models with human preferences. However, RLHF often\nsuffers from reward model overoptimisation, in which models overfit to the\nreward function, resulting in non-generalisable policies that exploit the\nidiosyncrasies and peculiarities of the reward function. A common mitigation is\niterated RLHF, in which reward models are repeatedly retrained with updated\nhuman feedback and policies are re-optimised. Despite its increasing adoption,\nthe dynamics of overoptimisation in this setting remain poorly understood. In\nthis work, we present the first comprehensive study of overoptimisation in\niterated RLHF. We systematically analyse key design choices - how reward model\ntraining data is transferred across iterations, which reward function is used\nfor optimisation, and how policies are initialised. Using the controlled\nAlpacaFarm benchmark, we observe that overoptimisation tends to decrease over\nsuccessive iterations, as reward models increasingly approximate ground-truth\npreferences. However, performance gains diminish over time, and while\nreinitialising from the base policy is robust, it limits optimisation\nflexibility. Other initialisation strategies often fail to recover from early\noveroptimisation. These findings offer actionable insights for building more\nstable and generalisable RLHF pipelines."}
{"id": "2505.17760", "pdf": "https://arxiv.org/pdf/2505.17760", "abs": "https://arxiv.org/abs/2505.17760", "authors": ["Leon Eshuijs", "Archie Chaudhury", "Alan McBeth", "Ethan Nguyen"], "title": "But what is your honest answer? Aiding LLM-judges with honest alternatives using steering vectors", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent safety evaluations of Large Language Models (LLMs) show that many\nmodels exhibit dishonest behavior, such as sycophancy. However, most honesty\nbenchmarks focus exclusively on factual knowledge or explicitly harmful\nbehavior and rely on external judges, which are often unable to detect less\nobvious forms of dishonesty. In this work, we introduce a new framework, Judge\nUsing Safety-Steered Alternatives (JUSSA), which utilizes steering vectors\ntrained on a single sample to elicit more honest responses from models, helping\nLLM-judges in the detection of dishonest behavior. To test our framework, we\nintroduce a new manipulation dataset with prompts specifically designed to\nelicit deceptive responses. We find that JUSSA enables LLM judges to better\ndifferentiate between dishonest and benign responses, and helps them identify\nsubtle instances of manipulative behavior."}
{"id": "2505.18131", "pdf": "https://arxiv.org/pdf/2505.18131", "abs": "https://arxiv.org/abs/2505.18131", "authors": ["Jonas A. Actor", "Graham Harper", "Ben Southworth", "Eric C. Cyr"], "title": "Leveraging KANs for Expedient Training of Multichannel MLPs via Preconditioning and Geometric Refinement", "categories": ["cs.LG", "cs.AI", "68T99", "I.2.6"], "comment": "20 pages, 3 figures, 3 tables", "summary": "Multilayer perceptrons (MLPs) are a workhorse machine learning architecture,\nused in a variety of modern deep learning frameworks. However, recently\nKolmogorov-Arnold Networks (KANs) have become increasingly popular due to their\nsuccess on a range of problems, particularly for scientific machine learning\ntasks. In this paper, we exploit the relationship between KANs and multichannel\nMLPs to gain structural insight into how to train MLPs faster. We demonstrate\nthe KAN basis (1) provides geometric localized support, and (2) acts as a\npreconditioned descent in the ReLU basis, overall resulting in expedited\ntraining and improved accuracy. Our results show the equivalence between\nfree-knot spline KAN architectures, and a class of MLPs that are refined\ngeometrically along the channel dimension of each weight tensor. We exploit\nthis structural equivalence to define a hierarchical refinement scheme that\ndramatically accelerates training of the multi-channel MLP architecture. We\nshow further accuracy improvements can be had by allowing the $1$D locations of\nthe spline knots to be trained simultaneously with the weights. These advances\nare demonstrated on a range of benchmark examples for regression and scientific\nmachine learning."}
{"id": "2505.17761", "pdf": "https://arxiv.org/pdf/2505.17761", "abs": "https://arxiv.org/abs/2505.17761", "authors": ["Benjamin Walker", "Lingyi Yang", "Nicola Muca Cirone", "Cristopher Salvi", "Terry Lyons"], "title": "Structured Linear CDEs: Maximally Expressive and Parallel-in-Time Sequence Models", "categories": ["cs.LG"], "comment": "26 pages, 5 figures", "summary": "Structured Linear Controlled Differential Equations (SLiCEs) provide a\nunifying framework for sequence models with structured, input-dependent\nstate-transition matrices that retain the maximal expressivity of dense\nmatrices whilst being cheaper to compute. The framework encompasses existing\narchitectures, such as input-dependent block-diagonal linear recurrent neural\nnetworks and DeltaNet's diagonal-plus-low-rank structure, as well as two novel\nvariants based on sparsity and the Walsh--Hadamard transform. We prove that,\nunlike the diagonal state-transition matrices of S4 and Mamba, SLiCEs employing\nblock-diagonal, sparse, or Walsh--Hadamard matrices match the maximal\nexpressivity of dense matrices. Empirically, SLiCEs solve the $A_5$\nstate-tracking benchmark with a single layer, achieve best-in-class length\ngeneralisation on regular language tasks among parallel-in-time models, and\nmatch the state-of-the-art performance of log neural controlled differential\nequations on six multivariate time-series classification datasets while cutting\nthe average time per training step by a factor of twenty."}
{"id": "2505.17763", "pdf": "https://arxiv.org/pdf/2505.17763", "abs": "https://arxiv.org/abs/2505.17763", "authors": ["Julian Oelhaf", "Georg Kordowich", "Andreas Maier", "Johann Jager", "Siming Bayer"], "title": "Unsupervised Clustering for Fault Analysis in High-Voltage Power Systems Using Voltage and Current Signals", "categories": ["cs.LG", "eess.SP"], "comment": "12 pages", "summary": "The widespread use of sensors in modern power grids has led to the\naccumulation of large amounts of voltage and current waveform data, especially\nduring fault events. However, the lack of labeled datasets poses a significant\nchallenge for fault classification and analysis. This paper explores the\napplication of unsupervised clustering techniques for fault diagnosis in\nhigh-voltage power systems. A dataset provided by the Reseau de Transport\nd'Electricite (RTE) is analyzed, with frequency domain features extracted using\nthe Fast Fourier Transform (FFT). The K-Means algorithm is then applied to\nidentify underlying patterns in the data, enabling automated fault\ncategorization without the need for labeled training samples. The resulting\nclusters are evaluated in collaboration with power system experts to assess\ntheir alignment with real-world fault characteristics. The results demonstrate\nthe potential of unsupervised learning for scalable and data-driven fault\nanalysis, providing a robust approach to detecting and classifying power system\nfaults with minimal prior assumptions."}
{"id": "2505.17765", "pdf": "https://arxiv.org/pdf/2505.17765", "abs": "https://arxiv.org/abs/2505.17765", "authors": ["Junhong Zhang", "Zhihui Lai"], "title": "Joker: Joint Optimization Framework for Lightweight Kernel Machines", "categories": ["cs.LG"], "comment": "24 pages, 5 figures, accepted by ICML 2025", "summary": "Kernel methods are powerful tools for nonlinear learning with\nwell-established theory. The scalability issue has been their long-standing\nchallenge. Despite the existing success, there are two limitations in\nlarge-scale kernel methods: (i) The memory overhead is too high for users to\nafford; (ii) existing efforts mainly focus on kernel ridge regression (KRR),\nwhile other models lack study. In this paper, we propose Joker, a joint\noptimization framework for diverse kernel models, including KRR, logistic\nregression, and support vector machines. We design a dual block coordinate\ndescent method with trust region (DBCD-TR) and adopt kernel approximation with\nrandomized features, leading to low memory costs and high efficiency in\nlarge-scale learning. Experiments show that Joker saves up to 90\\% memory but\nachieves comparable training time and performance (or even better) than the\nstate-of-the-art methods."}
{"id": "2505.17769", "pdf": "https://arxiv.org/pdf/2505.17769", "abs": "https://arxiv.org/abs/2505.17769", "authors": ["Patrick Leask", "Neel Nanda", "Noura Al Moubayed"], "title": "Inference-Time Decomposition of Activations (ITDA): A Scalable Approach to Interpreting Large Language Models", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Sparse autoencoders (SAEs) are a popular method for decomposing Large Langage\nModels (LLM) activations into interpretable latents. However, due to their\nsubstantial training cost, most academic research uses open-source SAEs which\nare only available for a restricted set of models of up to 27B parameters. SAE\nlatents are also learned from a dataset of activations, which means they do not\ntransfer between models. Motivated by relative representation similarity\nmeasures, we introduce Inference-Time Decomposition of Activations (ITDA)\nmodels, an alternative method for decomposing language model activations. To\ntrain an ITDA, we greedily construct a dictionary of language model activations\non a dataset of prompts, selecting those activations which were worst\napproximated by matching pursuit on the existing dictionary. ITDAs can be\ntrained in just 1\\% of the time required for SAEs, using 1\\% of the data. This\nallowed us to train ITDAs on Llama-3.1 70B and 405B on a single consumer GPU.\nITDAs can achieve similar reconstruction performance to SAEs on some target\nLLMs, but generally incur a performance penalty. However, ITDA dictionaries\nenable cross-model comparisons, and a simple Jaccard similarity index on ITDA\ndictionaries outperforms existing methods like CKA, SVCCA, and relative\nrepresentation similarity metrics. ITDAs provide a cheap alternative to SAEs\nwhere computational resources are limited, or when cross model comparisons are\nnecessary. Code available at https://github.com/pleask/itda."}
{"id": "2505.17773", "pdf": "https://arxiv.org/pdf/2505.17773", "abs": "https://arxiv.org/abs/2505.17773", "authors": ["Amir Hossein Rahmati", "Sanket Jantre", "Weifeng Zhang", "Yucheng Wang", "Byung-Jun Yoon", "Nathan M. Urban", "Xiaoning Qian"], "title": "C-LoRA: Contextual Low-Rank Adaptation for Uncertainty Estimation in Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) offers a cost-effective solution for fine-tuning\nlarge language models (LLMs), but it often produces overconfident predictions\nin data-scarce few-shot settings. To address this issue, several classical\nstatistical learning approaches have been repurposed for scalable\nuncertainty-aware LoRA fine-tuning. However, these approaches neglect how input\ncharacteristics affect the predictive uncertainty estimates. To address this\nlimitation, we propose Contextual Low-Rank Adaptation (\\textbf{C-LoRA}) as a\nnovel uncertainty-aware and parameter efficient fine-tuning approach, by\ndeveloping new lightweight LoRA modules contextualized to each input data\nsample to dynamically adapt uncertainty estimates. Incorporating data-driven\ncontexts into the parameter posteriors, C-LoRA mitigates overfitting, achieves\nwell-calibrated uncertainties, and yields robust predictions. Extensive\nexperiments demonstrate that C-LoRA consistently outperforms the\nstate-of-the-art uncertainty-aware LoRA methods in both uncertainty\nquantification and model generalization. Ablation studies further confirm the\ncritical role of our contextual modules in capturing sample-specific\nuncertainties. C-LoRA sets a new standard for robust, uncertainty-aware LLM\nfine-tuning in few-shot regimes."}
{"id": "2505.17777", "pdf": "https://arxiv.org/pdf/2505.17777", "abs": "https://arxiv.org/abs/2505.17777", "authors": ["Harish G. Ramaswamy", "L. A. Prashanth"], "title": "Optimizing Shortfall Risk Metric for Learning Regression Models", "categories": ["cs.LG"], "comment": null, "summary": "We consider the problem of estimating and optimizing utility-based shortfall\nrisk (UBSR) of a loss, say $(Y - \\hat Y)^2$, in the context of a regression\nproblem. Empirical risk minimization with a UBSR objective is challenging since\nUBSR is a non-linear function of the underlying distribution. We first derive a\nconcentration bound for UBSR estimation using independent and identically\ndistributed (i.i.d.) samples. We then frame the UBSR optimization problem as\nminimization of a pseudo-linear function in the space of achievable\ndistributions $\\mathcal D$ of the loss $(Y- \\hat Y)^2$. We construct a gradient\noracle for the UBSR objective and a linear minimization oracle (LMO) for the\nset $\\mathcal D$. Using these oracles, we devise a bisection-type algorithm,\nand establish convergence to the UBSR-optimal solution."}
{"id": "2505.17786", "pdf": "https://arxiv.org/pdf/2505.17786", "abs": "https://arxiv.org/abs/2505.17786", "authors": ["Sho Oshima", "Yuji Okamoto", "Taisei Tosaki", "Ryosuke Kojima", "Yasushi Okuno"], "title": "Supervised Graph Contrastive Learning for Gene Regulatory Network", "categories": ["cs.LG"], "comment": "under review", "summary": "Graph representation learning is effective for obtaining a meaningful latent\nspace utilizing the structure of graph data and is widely applied, including\nbiological networks. In particular, Graph Contrastive Learning (GCL) has\nemerged as a powerful self-supervised method that relies on applying\nperturbations to graphs for data augmentation. However, when applying existing\nGCL methods to biological networks such as Gene Regulatory Networks (GRNs),\nthey overlooked meaningful biologically relevant perturbations, e.g., gene\nknockdowns. In this study, we introduce SupGCL (Supervised Graph Contrastive\nLearning), a novel GCL method for GRNs that directly incorporates biological\nperturbations derived from gene knockdown experiments as the supervision.\nSupGCL mathematically extends existing GCL methods that utilize non-biological\nperturbations to probabilistic models that introduce actual biological gene\nperturbation utilizing gene knockdown data. Using the GRN representation\nobtained by our proposed method, our aim is to improve the performance of\nbiological downstream tasks such as patient hazard prediction and disease\nsubtype classification (graph-level task), and gene function classification\n(node-level task). We applied SupGCL on real GRN datasets derived from patients\nwith multiple types of cancer, and in all experiments SupGCL achieves better\nperformance than state-of-the-art baselines."}
{"id": "2505.17794", "pdf": "https://arxiv.org/pdf/2505.17794", "abs": "https://arxiv.org/abs/2505.17794", "authors": ["√ñmer Faruk Akg√ºl", "Feiyu Zhu", "Yuxin Yang", "Rajgopal Kannan", "Viktor Prasanna"], "title": "RECIPE-TKG: From Sparse History to Structured Reasoning for LLM-based Temporal Knowledge Graph Completion", "categories": ["cs.LG"], "comment": null, "summary": "Temporal Knowledge Graphs (TKGs) represent dynamic facts as timestamped\nrelations between entities. TKG completion involves forecasting missing or\nfuture links, requiring models to reason over time-evolving structure. While\nLLMs show promise for this task, existing approaches often overemphasize\nsupervised fine-tuning and struggle particularly when historical evidence is\nlimited or missing. We introduce RECIPE-TKG, a lightweight and data-efficient\nframework designed to improve accuracy and generalization in settings with\nsparse historical context. It combines (1) rule-based multi-hop retrieval for\nstructurally diverse history, (2) contrastive fine-tuning of lightweight\nadapters to encode relational semantics, and (3) test-time semantic filtering\nto iteratively refine generations based on embedding similarity. Experiments on\nfour TKG benchmarks show that RECIPE-TKG outperforms previous LLM-based\napproaches, achieving up to 30.6\\% relative improvement in Hits@10. Moreover,\nour proposed framework produces more semantically coherent predictions, even\nfor the samples with limited historical context."}
{"id": "2505.17797", "pdf": "https://arxiv.org/pdf/2505.17797", "abs": "https://arxiv.org/abs/2505.17797", "authors": ["Manuel Morante", "Naveed ur Rehman"], "title": "Latent Mode Decomposition", "categories": ["cs.LG"], "comment": "12 pages, 9 figures, 1 table", "summary": "We introduce Variational Latent Mode Decomposition (VLMD), a new algorithm\nfor extracting oscillatory modes and associated connectivity structures from\nmultivariate signals. VLMD addresses key limitations of existing Multivariate\nMode Decomposition (MMD) techniques -including high computational cost,\nsensitivity to parameter choices, and weak modeling of interchannel\ndependencies. Its improved performance is driven by a novel underlying model,\nLatent Mode Decomposition (LMD), which blends sparse coding and mode\ndecomposition to represent multichannel signals as sparse linear combinations\nof shared latent components composed of AM-FM oscillatory modes. This\nformulation enables VLMD to operate in a lower-dimensional latent space,\nenhancing robustness to noise, scalability, and interpretability. The algorithm\nsolves a constrained variational optimization problem that jointly enforces\nreconstruction fidelity, sparsity, and frequency regularization. Experiments on\nsynthetic and real-world datasets demonstrate that VLMD outperforms\nstate-of-the-art MMD methods in accuracy, efficiency, and interpretability of\nextracted structures."}
{"id": "2505.17799", "pdf": "https://arxiv.org/pdf/2505.17799", "abs": "https://arxiv.org/abs/2505.17799", "authors": ["Brian B. Moser", "Arundhati S. Shanbhag", "Stanislav Frolov", "Federico Raue", "Joachim Folz", "Andreas Dengel"], "title": "A Coreset Selection of Coreset Selection Literature: Introduction and Recent Advances", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Coreset selection targets the challenge of finding a small, representative\nsubset of a large dataset that preserves essential patterns for effective\nmachine learning. Although several surveys have examined data reduction\nstrategies before, most focus narrowly on either classical geometry-based\nmethods or active learning techniques. In contrast, this survey presents a more\ncomprehensive view by unifying three major lines of coreset research, namely,\ntraining-free, training-oriented, and label-free approaches, into a single\ntaxonomy. We present subfields often overlooked by existing work, including\nsubmodular formulations, bilevel optimization, and recent progress in\npseudo-labeling for unlabeled datasets. Additionally, we examine how pruning\nstrategies influence generalization and neural scaling laws, offering new\ninsights that are absent from prior reviews. Finally, we compare these methods\nunder varying computational, robustness, and performance demands and highlight\nopen challenges, such as robustness, outlier filtering, and adapting coreset\nselection to foundation models, for future research."}
{"id": "2505.17804", "pdf": "https://arxiv.org/pdf/2505.17804", "abs": "https://arxiv.org/abs/2505.17804", "authors": ["Jonas Seng", "Fabrizio Ventola", "Zhongjie Yu", "Kristian Kersting"], "title": "Hyperparameter Optimization via Interacting with Probabilistic Circuits", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite the growing interest in designing truly interactive hyperparameter\noptimization (HPO) methods, to date, only a few allow to include human\nfeedback. Existing interactive Bayesian optimization (BO) methods incorporate\nhuman beliefs by weighting the acquisition function with a user-defined prior\ndistribution. However, in light of the non-trivial inner optimization of the\nacquisition function prevalent in BO, such weighting schemes do not always\naccurately reflect given user beliefs. We introduce a novel BO approach\nleveraging tractable probabilistic models named probabilistic circuits (PCs) as\na surrogate model. PCs encode a tractable joint distribution over the hybrid\nhyperparameter space and evaluation scores. They enable exact conditional\ninference and sampling. Based on conditional sampling, we construct a novel\nselection policy that enables an acquisition function-free generation of\ncandidate points (thereby eliminating the need for an additional inner-loop\noptimization) and ensures that user beliefs are reflected accurately in the\nselection policy. We provide a theoretical analysis and an extensive empirical\nevaluation, demonstrating that our method achieves state-of-the-art performance\nin standard HPO and outperforms interactive BO baselines in interactive HPO."}
{"id": "2505.17810", "pdf": "https://arxiv.org/pdf/2505.17810", "abs": "https://arxiv.org/abs/2505.17810", "authors": ["Elias J√§√§saari", "Ville Hyv√∂nen", "Matteo Ceccarello", "Teemu Roos", "Martin Aum√ºller"], "title": "VIBE: Vector Index Benchmark for Embeddings", "categories": ["cs.LG", "cs.IR"], "comment": "25 pages", "summary": "Approximate nearest neighbor (ANN) search is a performance-critical component\nof many machine learning pipelines. Rigorous benchmarking is essential for\nevaluating the performance of vector indexes for ANN search. However, the\ndatasets of the existing benchmarks are no longer representative of the current\napplications of ANN search. Hence, there is an urgent need for an up-to-date\nset of benchmarks. To this end, we introduce Vector Index Benchmark for\nEmbeddings (VIBE), an open source project for benchmarking ANN algorithms. VIBE\ncontains a pipeline for creating benchmark datasets using dense embedding\nmodels characteristic of modern applications, such as retrieval-augmented\ngeneration (RAG). To replicate real-world workloads, we also include\nout-of-distribution (OOD) datasets where the queries and the corpus are drawn\nfrom different distributions. We use VIBE to conduct a comprehensive evaluation\nof SOTA vector indexes, benchmarking 21 implementations on 12 in-distribution\nand 6 out-of-distribution datasets."}
{"id": "2505.17826", "pdf": "https://arxiv.org/pdf/2505.17826", "abs": "https://arxiv.org/abs/2505.17826", "authors": ["Xuchen Pan", "Yanxi Chen", "Yushuo Chen", "Yuchang Sun", "Daoyuan Chen", "Wenhao Zhang", "Yuexiang Xie", "Yilun Huang", "Yilei Zhang", "Dawei Gao", "Yaliang Li", "Bolin Ding", "Jingren Zhou"], "title": "Trinity-RFT: A General-Purpose and Unified Framework for Reinforcement Fine-Tuning of Large Language Models", "categories": ["cs.LG", "cs.CL", "cs.DC"], "comment": "This technical report will be continuously updated as the codebase\n  evolves. GitHub: https://github.com/modelscope/Trinity-RFT", "summary": "Trinity-RFT is a general-purpose, flexible and scalable framework designed\nfor reinforcement fine-tuning (RFT) of large language models. It is built with\na decoupled design, consisting of (1) an RFT-core that unifies and generalizes\nsynchronous/asynchronous, on-policy/off-policy, and online/offline modes of\nRFT, (2) seamless integration for agent-environment interaction with high\nefficiency and robustness, and (3) systematic data pipelines optimized for RFT.\nTrinity-RFT can be easily adapted for diverse application scenarios, and serves\nas a unified platform for exploring advanced reinforcement learning paradigms.\nThis technical report outlines the vision, features, design and implementations\nof Trinity-RFT, accompanied by extensive examples demonstrating the utility and\nuser-friendliness of the proposed framework."}
{"id": "2505.17830", "pdf": "https://arxiv.org/pdf/2505.17830", "abs": "https://arxiv.org/abs/2505.17830", "authors": ["Nicolas Castanet", "Olivier Sigaud", "Sylvain Lamprier"], "title": "Imagine Beyond! Distributionally Robust Auto-Encoding for State Space Coverage in Online Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Goal-Conditioned Reinforcement Learning (GCRL) enables agents to autonomously\nacquire diverse behaviors, but faces major challenges in visual environments\ndue to high-dimensional, semantically sparse observations. In the online\nsetting, where agents learn representations while exploring, the latent space\nevolves with the agent's policy, to capture newly discovered areas of the\nenvironment. However, without incentivization to maximize state coverage in the\nrepresentation, classical approaches based on auto-encoders may converge to\nlatent spaces that over-represent a restricted set of states frequently visited\nby the agent. This is exacerbated in an intrinsic motivation setting, where the\nagent uses the distribution encoded in the latent space to sample the goals it\nlearns to master. To address this issue, we propose to progressively enforce\ndistributional shifts towards a uniform distribution over the full state space,\nto ensure a full coverage of skills that can be learned in the environment. We\nintroduce DRAG (Distributionally Robust Auto-Encoding for GCRL), a method that\ncombines the $\\beta$-VAE framework with Distributionally Robust Optimization.\nDRAG leverages an adversarial neural weighter of training states of the VAE, to\naccount for the mismatch between the current data distribution and unseen parts\nof the environment. This allows the agent to construct semantically meaningful\nlatent spaces beyond its immediate experience. Our approach improves state\nspace coverage and downstream control performance on hard exploration\nenvironments such as mazes and robotic control involving walls to bypass,\nwithout pre-training nor prior environment knowledge."}
{"id": "2505.17847", "pdf": "https://arxiv.org/pdf/2505.17847", "abs": "https://arxiv.org/abs/2505.17847", "authors": ["Hao Wang", "Licheng Pan", "Zhichao Chen", "Xu Chen", "Qingyang Dai", "Lei Wang", "Haoxuan Li", "Zhouchen Lin"], "title": "TransDF: Time-Series Forecasting Needs Transformed Label Alignment", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": null, "summary": "Training time-series forecasting models presents unique challenges in\ndesigning effective learning objectives. Existing methods predominantly utilize\nthe temporal mean squared error, which faces two critical challenges: (1) label\nautocorrelation, which leads to bias from the label sequence likelihood; (2)\nexcessive amount of tasks, which increases with the forecast horizon and\ncomplicates optimization. To address these challenges, we propose\nTransform-enhanced Direct Forecast (TransDF), which transforms the label\nsequence into decorrelated components with discriminated significance. Models\nare trained to align the most significant components, thereby effectively\nmitigating label autocorrelation and reducing task amount. Extensive\nexperiments demonstrate that TransDF achieves state-of-the-art performance and\nis compatible with various forecasting models. Code is available at\nhttps://anonymous.4open.science/r/TransDF-88CF."}
{"id": "2505.17852", "pdf": "https://arxiv.org/pdf/2505.17852", "abs": "https://arxiv.org/abs/2505.17852", "authors": ["Francois Chaubard", "Mykel Kochenderfer"], "title": "Scaling Recurrent Neural Networks to a Billion Parameters with Zero-Order Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "During inference, Recurrent Neural Networks (RNNs) scale constant in both\nFLOPs and GPU memory with increasing context length, as they compress all prior\ntokens into a fixed-size memory. In contrast, transformers scale linearly in\nFLOPs and, at best, linearly in memory during generation, since they must\nattend to all previous tokens explicitly. Despite this inference-time\nadvantage, training large RNNs on long contexts remains impractical because\nstandard optimization methods depend on Backpropagation Through Time (BPTT).\nBPTT requires retention of all intermediate activations during the forward\npass, causing memory usage to scale linearly with both context length and model\nsize. In this paper, we show that Zero-Order Optimization (ZOO) methods such as\nRandom-vector Gradient Estimation (RGE) can successfully replace BPTT to train\nRNNs with convergence rates that match, or exceed BPTT by up to 19 fold, while\nusing orders of magnitude less memory and cost, as the model remains in\ninference mode throughout training. We further demonstrate that\nCentral-Difference RGE (CD-RGE) corresponds to optimizing a smoothed surrogate\nloss, inherently regularizing training and improving generalization. Our method\nmatches or outperforms BPTT across three settings: (1) overfitting, (2)\ntransduction, and (3) language modeling. Across all tasks, with sufficient\nperturbations, our models generalize as well as or better than those trained\nwith BPTT, often in fewer steps. Despite the need for more forward passes per\nstep, we can surpass BPTT wall-clock time per step using recent advancements\nsuch as FlashRNN and distributed inference."}
{"id": "2505.17854", "pdf": "https://arxiv.org/pdf/2505.17854", "abs": "https://arxiv.org/abs/2505.17854", "authors": ["Lukas Koller", "Tobias Ladner", "Matthias Althoff"], "title": "Out of the Shadows: Exploring a Latent Space for Neural Network Verification", "categories": ["cs.LG"], "comment": null, "summary": "Neural networks are ubiquitous. However, they are often sensitive to small\ninput changes. Hence, to prevent unexpected behavior in safety-critical\napplications, their formal verification -- a notoriously hard problem -- is\nnecessary. Many state-of-the-art verification algorithms use reachability\nanalysis or abstract interpretation to enclose the set of possible outputs of a\nneural network. Often, the verification is inconclusive due to the conservatism\nof the enclosure. To address this problem, we design a novel latent space for\nformal verification that enables the transfer of output specifications to the\ninput space for an iterative specification-driven input refinement, i.e., we\niteratively reduce the set of possible inputs to only enclose the unsafe ones.\nThe latent space is constructed from a novel view of projection-based set\nrepresentations, e.g., zonotopes, which are commonly used in reachability\nanalysis of neural networks. A projection-based set representation is a\n\"shadow\" of a higher-dimensional set -- a latent space -- that does not change\nduring a set propagation through a neural network. Hence, the input set and the\noutput enclosure are \"shadows\" of the same latent space that we can use to\ntransfer constraints. We present an efficient verification tool for neural\nnetworks that uses our iterative refinement to significantly reduce the number\nof subproblems in a branch-and-bound procedure. Using zonotopes as a set\nrepresentation, unlike many other state-of-the-art approaches, our approach can\nbe realized by only using matrix operations, which enables a significant\nspeed-up through efficient GPU acceleration. We demonstrate that our tool\nachieves competitive performance, which would place it among the top-ranking\ntools of the last neural network verification competition (VNN-COMP'24)."}
{"id": "2505.17856", "pdf": "https://arxiv.org/pdf/2505.17856", "abs": "https://arxiv.org/abs/2505.17856", "authors": ["Moule Lin", "Shuhao Guan", "Weipeng Jing", "Goetz Botterweck", "Andrea Patane"], "title": "Stochastic Weight Sharing for Bayesian Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While offering a principled framework for uncertainty quantification in deep\nlearning, the employment of Bayesian Neural Networks (BNNs) is still\nconstrained by their increased computational requirements and the convergence\ndifficulties when training very deep, state-of-the-art architectures. In this\nwork, we reinterpret weight-sharing quantization techniques from a stochastic\nperspective in the context of training and inference with Bayesian Neural\nNetworks (BNNs). Specifically, we leverage 2D adaptive Gaussian distributions,\nWasserstein distance estimations, and alpha blending to encode the stochastic\nbehaviour of a BNN in a lower dimensional, soft Gaussian representation.\nThrough extensive empirical investigation, we demonstrate that our approach\nsignificantly reduces the computational overhead inherent in Bayesian learning\nby several orders of magnitude, enabling the efficient Bayesian training of\nlarge-scale models, such as ResNet-101 and Vision Transformer (VIT). On various\ncomputer vision benchmarks including CIFAR10, CIFAR100, and ImageNet1k. Our\napproach compresses model parameters by approximately 50x and reduces model\nsize by 75, while achieving accuracy and uncertainty estimations comparable to\nthe state-of-the-art."}
{"id": "2505.17859", "pdf": "https://arxiv.org/pdf/2505.17859", "abs": "https://arxiv.org/abs/2505.17859", "authors": ["Masahiro Fujisawa", "Masaki Adachi", "Michael A. Osborne"], "title": "Scalable Valuation of Human Feedback through Provably Robust Model Alignment", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "38 pages, 7 figures", "summary": "Despite the importance of aligning language models with human preferences,\ncrowd-sourced human feedback is often noisy -- for example, preferring less\ndesirable responses -- posing a fundamental challenge to alignment. A truly\nrobust alignment objective should yield identical model parameters even under\nsevere label noise, a property known as redescending. We prove that no existing\nalignment methods satisfy this property. To address this, we propose\nH\\\"older-DPO, the first principled alignment loss with a provable redescending\nproperty, enabling estimation of the clean data distribution from noisy\nfeedback. The aligned model estimates the likelihood of clean data, providing a\ntheoretically grounded metric for dataset valuation that identifies the\nlocation and fraction of mislabels. This metric is gradient-free, enabling\nscalable and automated human feedback valuation without costly manual\nverification or clean validation dataset. H\\\"older-DPO achieves\nstate-of-the-art robust alignment performance while accurately detecting\nmislabels in controlled datasets. Finally, we apply H\\\"older-DPO to widely used\nalignment datasets, revealing substantial noise levels and demonstrating that\nremoving these mislabels significantly improves alignment performance across\nmethods."}
{"id": "2505.17863", "pdf": "https://arxiv.org/pdf/2505.17863", "abs": "https://arxiv.org/abs/2505.17863", "authors": ["Nicolas Zucchet", "Francesco d'Angelo", "Andrew K. Lampinen", "Stephanie C. Y. Chan"], "title": "The emergence of sparse attention: impact of data distribution and benefits of repetition", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Emergence is a fascinating property of large language models and neural\nnetworks more broadly: as models scale and train for longer, they sometimes\ndevelop new abilities in sudden ways. Despite initial studies, we still lack a\ncomprehensive understanding of how and when these abilities emerge. To address\nthis gap, we study the emergence over training of sparse attention, a critical\nand frequently observed attention pattern in Transformers. By combining\ntheoretical analysis of a toy model with empirical observations on small\nTransformers trained on a linear regression variant, we uncover the mechanics\ndriving sparse attention emergence and reveal that emergence timing follows\npower laws based on task structure, architecture, and optimizer choice. We\nadditionally find that repetition can greatly speed up emergence. Finally, we\nconfirm these results on a well-studied in-context associative recall task. Our\nfindings provide a simple, theoretically grounded framework for understanding\nhow data distributions and model design influence the learning dynamics behind\none form of emergence."}
{"id": "2505.17866", "pdf": "https://arxiv.org/pdf/2505.17866", "abs": "https://arxiv.org/abs/2505.17866", "authors": ["Hongshu Guo", "Zeyuan Ma", "Yining Ma", "Xinglin Zhang", "Wei-Neng Chen", "Yue-Jiao Gong"], "title": "DesignX: Human-Competitive Algorithm Designer for Black-Box Optimization", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Designing effective black-box optimizers is hampered by limited\nproblem-specific knowledge and manual control that spans months for almost\nevery detail. In this paper, we present DesignX, the first automated algorithm\ndesign framework that generates an effective optimizer specific to a given\nblack-box optimization problem within seconds. Rooted in the first principles,\nwe identify two key sub-tasks: 1) algorithm structure generation and 2)\nhyperparameter control. To enable systematic construction, a comprehensive\nmodular algorithmic space is first built, embracing hundreds of algorithm\ncomponents collected from decades of research. We then introduce a dual-agent\nreinforcement learning system that collaborates on structural and parametric\ndesign through a novel cooperative training objective, enabling large-scale\nmeta-training across 10k diverse instances. Remarkably, through days of\nautonomous learning, the DesignX-generated optimizers continuously surpass\nhuman-crafted optimizers by orders of magnitude, either on synthetic testbed or\non realistic optimization scenarios such as Protein-docking, AutoML and UAV\npath planning. Further in-depth analysis reveals DesignX's capability to\ndiscover non-trivial algorithm patterns beyond expert intuition, which,\nconversely, provides valuable design insights for the optimization community.\nWe provide DesignX's inference code at https://github.com/MetaEvo/DesignX."}
{"id": "2505.17868", "pdf": "https://arxiv.org/pdf/2505.17868", "abs": "https://arxiv.org/abs/2505.17868", "authors": ["Devan Shah", "Shlomo Fortgang", "Sofiia Druchyna", "Elad Hazan"], "title": "SpectraLDS: Provable Distillation for Linear Dynamical Systems", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "We present the first provable method for identifying symmetric linear\ndynamical systems (LDS) with accuracy guarantees that are independent of the\nsystems' state dimension or effective memory. Our approach builds upon recent\nwork that represents symmetric LDSs as convolutions learnable via fixed\nspectral transformations. We show how to invert this representation, thereby\nrecovering an LDS model from its spectral transform and yielding an end-to-end\nconvex optimization procedure. This distillation preserves predictive accuracy\nwhile enabling constant-time and constant-space inference per token,\nindependent of sequence length. We evaluate our method, SpectraLDS, as a\ncomponent in sequence prediction architectures and demonstrate that accuracy is\npreserved while inference efficiency is improved on tasks such as language\nmodeling."}
{"id": "2505.17869", "pdf": "https://arxiv.org/pdf/2505.17869", "abs": "https://arxiv.org/abs/2505.17869", "authors": ["Mohammad Shahverdikondori", "Mohammad Reza Badri", "Negar Kiyavash"], "title": "Best Group Identification in Multi-Objective Bandits", "categories": ["cs.LG"], "comment": null, "summary": "We introduce the Best Group Identification problem in a multi-objective\nmulti-armed bandit setting, where an agent interacts with groups of arms with\nvector-valued rewards. The performance of a group is determined by an\nefficiency vector which represents the group's best attainable rewards across\ndifferent dimensions. The objective is to identify the set of optimal groups in\nthe fixed-confidence setting. We investigate two key formulations: group Pareto\nset identification, where efficiency vectors of optimal groups are Pareto\noptimal and linear best group identification, where each reward dimension has a\nknown weight and the optimal group maximizes the weighted sum of its efficiency\nvector's entries. For both settings, we propose elimination-based algorithms,\nestablish upper bounds on their sample complexity, and derive lower bounds that\napply to any correct algorithm. Through numerical experiments, we demonstrate\nthe strong empirical performance of the proposed algorithms."}
{"id": "2505.17871", "pdf": "https://arxiv.org/pdf/2505.17871", "abs": "https://arxiv.org/abs/2505.17871", "authors": ["Zezhi Shao", "Yujie Li", "Fei Wang", "Chengqing Yu", "Yisong Fu", "Tangwen Qian", "Bin Xu", "Boyu Diao", "Yongjun Xu", "Xueqi Cheng"], "title": "BLAST: Balanced Sampling Time Series Corpus for Universal Forecasting Models", "categories": ["cs.LG"], "comment": "Accepted by SIGKDD 2025 (Research Track)", "summary": "The advent of universal time series forecasting models has revolutionized\nzero-shot forecasting across diverse domains, yet the critical role of data\ndiversity in training these models remains underexplored. Existing large-scale\ntime series datasets often suffer from inherent biases and imbalanced\ndistributions, leading to suboptimal model performance and generalization. To\naddress this gap, we introduce BLAST, a novel pre-training corpus designed to\nenhance data diversity through a balanced sampling strategy. First, BLAST\nincorporates 321 billion observations from publicly available datasets and\nemploys a comprehensive suite of statistical metrics to characterize time\nseries patterns. Then, to facilitate pattern-oriented sampling, the data is\nimplicitly clustered using grid-based partitioning. Furthermore, by integrating\ngrid sampling and grid mixup techniques, BLAST ensures a balanced and\nrepresentative coverage of diverse patterns. Experimental results demonstrate\nthat models pre-trained on BLAST achieve state-of-the-art performance with a\nfraction of the computational resources and training tokens required by\nexisting methods. Our findings highlight the pivotal role of data diversity in\nimproving both training efficiency and model performance for the universal\nforecasting task."}
{"id": "2505.17872", "pdf": "https://arxiv.org/pdf/2505.17872", "abs": "https://arxiv.org/abs/2505.17872", "authors": ["Licheng Pan", "Zhichao Chen", "Haoxuan Li", "Guangyi Liu", "Zhijian Xu", "Zhaoran Liu", "Hao Wang", "Ying Wei"], "title": "Mixture of Low Rank Adaptation with Partial Parameter Sharing for Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-task forecasting has become the standard approach for time-series\nforecasting (TSF). However, we show that it suffers from an Expressiveness\nBottleneck, where predictions at different time steps share the same\nrepresentation, leading to unavoidable errors even with optimal\nrepresentations. To address this issue, we propose a two-stage framework:\nfirst, pre-train a foundation model for one-step-ahead prediction; then, adapt\nit using step-specific LoRA modules.This design enables the foundation model to\nhandle any number of forecast steps while avoiding the expressiveness\nbottleneck. We further introduce the Mixture-of-LoRA (MoLA) model, which\nemploys adaptively weighted LoRA experts to achieve partial parameter sharing\nacross steps. This approach enhances both efficiency and forecasting\nperformance by exploiting interdependencies between forecast steps. Experiments\nshow that MoLA significantly improves model expressiveness and outperforms\nstate-of-the-art time-series forecasting methods. Code is available at\nhttps://anonymous.4open.science/r/MoLA-BC92."}
{"id": "2505.17875", "pdf": "https://arxiv.org/pdf/2505.17875", "abs": "https://arxiv.org/abs/2505.17875", "authors": ["Yan Zhong", "Xingyu Wu", "Xinping Zhao", "Li Zhang", "Xinyuan Song", "Lei Shi", "Bingbing Jiang"], "title": "Semi-Supervised Multi-Label Feature Selection with Consistent Sparse Graph Learning", "categories": ["cs.LG"], "comment": null, "summary": "In practical domains, high-dimensional data are usually associated with\ndiverse semantic labels, whereas traditional feature selection methods are\ndesigned for single-label data. Moreover, existing multi-label methods\nencounter two main challenges in semi-supervised scenarios: (1). Most\nsemi-supervised methods fail to evaluate the label correlations without enough\nlabeled samples, which are the critical information of multi-label feature\nselection, making label-specific features discarded. (2). The similarity graph\nstructure directly derived from the original feature space is suboptimal for\nmulti-label problems in existing graph-based methods, leading to unreliable\nsoft labels and degraded feature selection performance. To overcome them, we\npropose a consistent sparse graph learning method for multi-label\nsemi-supervised feature selection (SGMFS), which can enhance the feature\nselection performance by maintaining space consistency and learning label\ncorrelations in semi-supervised scenarios. Specifically, for Challenge (1),\nSGMFS learns a low-dimensional and independent label subspace from the\nprojected features, which can compatibly cross multiple labels and effectively\nachieve the label correlations. For Challenge (2), instead of constructing a\nfixed similarity graph for semi-supervised learning, SGMFS thoroughly explores\nthe intrinsic structure of the data by performing sparse reconstruction of\nsamples in both the label space and the learned subspace simultaneously. In\nthis way, the similarity graph can be adaptively learned to maintain the\nconsistency between label space and the learned subspace, which can promote\npropagating proper soft labels for unlabeled samples, facilitating the ultimate\nfeature selection. An effective solution with fast convergence is designed to\noptimize the objective function. Extensive experiments validate the superiority\nof SGMFS."}
{"id": "2505.17883", "pdf": "https://arxiv.org/pdf/2505.17883", "abs": "https://arxiv.org/abs/2505.17883", "authors": ["Laines Schmalwasser", "Niklas Penzel", "Joachim Denzler", "Julia Niebling"], "title": "FastCAV: Efficient Computation of Concept Activation Vectors for Explaining Deep Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": "Accepted at ICML 2025, 27 pages, 20 figures, 9 tables", "summary": "Concepts such as objects, patterns, and shapes are how humans understand the\nworld. Building on this intuition, concept-based explainability methods aim to\nstudy representations learned by deep neural networks in relation to\nhuman-understandable concepts. Here, Concept Activation Vectors (CAVs) are an\nimportant tool and can identify whether a model learned a concept or not.\nHowever, the computational cost and time requirements of existing CAV\ncomputation pose a significant challenge, particularly in large-scale,\nhigh-dimensional architectures. To address this limitation, we introduce\nFastCAV, a novel approach that accelerates the extraction of CAVs by up to\n63.6x (on average 46.4x). We provide a theoretical foundation for our approach\nand give concrete assumptions under which it is equivalent to established\nSVM-based methods. Our empirical results demonstrate that CAVs calculated with\nFastCAV maintain similar performance while being more efficient and stable. In\ndownstream applications, i.e., concept-based explanation methods, we show that\nFastCAV can act as a replacement leading to equivalent insights. Hence, our\napproach enables previously infeasible investigations of deep models, which we\ndemonstrate by tracking the evolution of concepts during model training."}
{"id": "2505.17899", "pdf": "https://arxiv.org/pdf/2505.17899", "abs": "https://arxiv.org/abs/2505.17899", "authors": ["Romain Mussard", "Fannia Pacheco", "Maxime Berar", "Gilles Gasso", "Paul Honeine"], "title": "Universal Domain Adaptation Benchmark for Time Series Data Representation", "categories": ["cs.LG"], "comment": null, "summary": "Deep learning models have significantly improved the ability to detect\nnovelties in time series (TS) data. This success is attributed to their strong\nrepresentation capabilities. However, due to the inherent variability in TS\ndata, these models often struggle with generalization and robustness. To\naddress this, a common approach is to perform Unsupervised Domain Adaptation,\nparticularly Universal Domain Adaptation (UniDA), to handle domain shifts and\nemerging novel classes. While extensively studied in computer vision, UniDA\nremains underexplored for TS data. This work provides a comprehensive\nimplementation and comparison of state-of-the-art TS backbones in a UniDA\nframework. We propose a reliable protocol to evaluate their robustness and\ngeneralization across different domains. The goal is to provide practitioners\nwith a framework that can be easily extended to incorporate future advancements\nin UniDA and TS architectures. Our results highlight the critical influence of\nbackbone selection in UniDA performance and enable a robustness analysis across\nvarious datasets and architectures."}
{"id": "2505.17902", "pdf": "https://arxiv.org/pdf/2505.17902", "abs": "https://arxiv.org/abs/2505.17902", "authors": ["Ignacio Cabrera Martin", "Subhaditya Mukherjee", "Almas Baimagambetov", "Joaquin Vanschoren", "Nikolaos Polatidis"], "title": "Evolving Machine Learning: A Survey", "categories": ["cs.LG"], "comment": null, "summary": "In an era defined by rapid data evolution, traditional machine learning (ML)\nmodels often fall short in adapting to dynamic environments. Evolving Machine\nLearning (EML) has emerged as a critical paradigm, enabling continuous learning\nand adaptation in real-time data streams. This survey presents a comprehensive\nanalysis of EML, focusing on five core challenges: data drift, concept drift,\ncatastrophic forgetting, skewed learning, and network adaptation. We\nsystematically review over 120 studies, categorizing state-of-the-art methods\nacross supervised, unsupervised, and semi-supervised approaches. The survey\nexplores diverse evaluation metrics, benchmark datasets, and real-world\napplications, offering a comparative lens on the effectiveness and limitations\nof current techniques. Additionally, we highlight the growing role of adaptive\nneural architectures, meta-learning, and ensemble strategies in addressing\nevolving data complexities. By synthesizing insights from recent literature,\nthis work not only maps the current landscape of EML but also identifies\ncritical gaps and opportunities for future research. Our findings aim to guide\nresearchers and practitioners in developing robust, ethical, and scalable EML\nsystems for real-world deployment."}
{"id": "2505.17909", "pdf": "https://arxiv.org/pdf/2505.17909", "abs": "https://arxiv.org/abs/2505.17909", "authors": ["Bram Grooten", "Farid Hasanov", "Chenxiang Zhang", "Qiao Xiao", "Boqian Wu", "Zahra Atashgahi", "Ghada Sokar", "Shiwei Liu", "Lu Yin", "Elena Mocanu", "Mykola Pechenizkiy", "Decebal Constantin Mocanu"], "title": "NeuroTrails: Training with Dynamic Sparse Heads as the Key to Effective Ensembling", "categories": ["cs.LG", "cs.AI"], "comment": "Our open-source code is available at\n  https://github.com/bramgrooten/neurotrails", "summary": "Model ensembles have long been a cornerstone for improving generalization and\nrobustness in deep learning. However, their effectiveness often comes at the\ncost of substantial computational overhead. To address this issue,\nstate-of-the-art methods aim to replicate ensemble-class performance without\nrequiring multiple independently trained networks. Unfortunately, these\nalgorithms often still demand considerable compute at inference. In response to\nthese limitations, we introduce $\\textbf{NeuroTrails}$, a sparse multi-head\narchitecture with dynamically evolving topology. This unexplored model-agnostic\ntraining paradigm improves ensemble performance while reducing the required\nresources. We analyze the underlying reason for its effectiveness and observe\nthat the various neural trails induced by dynamic sparsity attain a\n$\\textit{Goldilocks zone}$ of prediction diversity. NeuroTrails displays\nefficacy with convolutional and transformer-based architectures on computer\nvision and language tasks. Experiments on ResNet-50/ImageNet, LLaMA-350M/C4,\namong many others, demonstrate increased accuracy and stronger robustness in\nzero-shot generalization, while requiring significantly fewer parameters."}
{"id": "2505.17918", "pdf": "https://arxiv.org/pdf/2505.17918", "abs": "https://arxiv.org/abs/2505.17918", "authors": ["Hangting Ye", "Jinmeng Li", "He Zhao", "Dandan Guo", "Yi Chang"], "title": "LLM Meeting Decision Trees on Tabular Data", "categories": ["cs.LG"], "comment": null, "summary": "Tabular data have been playing a vital role in diverse real-world fields,\nincluding healthcare, finance, etc. With the recent success of Large Language\nModels (LLMs), early explorations of extending LLMs to the domain of tabular\ndata have been developed. Most of these LLM-based methods typically first\nserialize tabular data into natural language descriptions, and then tune LLMs\nor directly infer on these serialized data. However, these methods suffer from\ntwo key inherent issues: (i) data perspective: existing data serialization\nmethods lack universal applicability for structured tabular data, and may pose\nprivacy risks through direct textual exposure, and (ii) model perspective: LLM\nfine-tuning methods struggle with tabular data, and in-context learning\nscalability is bottle-necked by input length constraints (suitable for few-shot\nlearning). This work explores a novel direction of integrating LLMs into\ntabular data throughough logical decision tree rules as intermediaries,\nproposes a decision tree enhancer with LLM-derived rule for tabular prediction,\nDeLTa. The proposed DeLTa avoids tabular data serialization, and can be applied\nto full data learning setting without LLM fine-tuning. Specifically, we\nleverage the reasoning ability of LLMs to redesign an improved rule given a set\nof decision tree rules. Furthermore, we provide a calibration method for\noriginal decision trees via new generated rule by LLM, which approximates the\nerror correction vector to steer the original decision tree predictions in the\ndirection of ``errors'' reducing. Finally, extensive experiments on diverse\ntabular benchmarks show that our method achieves state-of-the-art performance."}
{"id": "2505.17919", "pdf": "https://arxiv.org/pdf/2505.17919", "abs": "https://arxiv.org/abs/2505.17919", "authors": ["Mingquan Feng", "Yifan Fu", "Tongcheng Zhang", "Yu Jiang", "Yixin Huang", "Junchi Yan"], "title": "KITINet: Kinetics Theory Inspired Network Architectures with PDE Simulation Approaches", "categories": ["cs.LG"], "comment": null, "summary": "Despite the widely recognized success of residual connections in modern\nneural networks, their design principles remain largely heuristic. This paper\nintroduces KITINet (Kinetics Theory Inspired Network), a novel architecture\nthat reinterprets feature propagation through the lens of non-equilibrium\nparticle dynamics and partial differential equation (PDE) simulation. At its\ncore, we propose a residual module that models feature updates as the\nstochastic evolution of a particle system, numerically simulated via a\ndiscretized solver for the Boltzmann transport equation (BTE). This formulation\nmimics particle collisions and energy exchange, enabling adaptive feature\nrefinement via physics-informed interactions. Additionally, we reveal that this\nmechanism induces network parameter condensation during training, where\nparameters progressively concentrate into a sparse subset of dominant channels.\nExperiments on scientific computation (PDE operator), image classification\n(CIFAR-10/100), and text classification (IMDb/SNLI) show consistent\nimprovements over classic network baselines, with negligible increase of FLOPs."}
{"id": "2505.17929", "pdf": "https://arxiv.org/pdf/2505.17929", "abs": "https://arxiv.org/abs/2505.17929", "authors": ["Alexander Gabitashvili", "Philipp Kellmeyer"], "title": "Predicting Length of Stay in Neurological ICU Patients Using Classical Machine Learning and Neural Network Models: A Benchmark Study on MIMIC-IV", "categories": ["cs.LG"], "comment": null, "summary": "Intensive care unit (ICU) is a crucial hospital department that handles\nlife-threatening cases. Nowadays machine learning (ML) is being leveraged in\nhealthcare ubiquitously. In recent years, management of ICU became one of the\nmost significant parts of the hospital functionality (largely but not only due\nto the worldwide COVID-19 pandemic). This study explores multiple ML approaches\nfor predicting LOS in ICU specifically for the patients with neurological\ndiseases based on the MIMIC-IV dataset. The evaluated models include classic ML\nalgorithms (K-Nearest Neighbors, Random Forest, XGBoost and CatBoost) and\nNeural Networks (LSTM, BERT and Temporal Fusion Transformer). Given that LOS\nprediction is often framed as a classification task, this study categorizes LOS\ninto three groups: less than two days, less than a week, and a week or more. As\nthe first ML-based approach targeting LOS prediction for neurological disorder\npatients, this study does not aim to outperform existing methods but rather to\nassess their effectiveness in this specific context. The findings provide\ninsights into the applicability of ML techniques for improving ICU resource\nmanagement and patient care. According to the results, Random Forest model\nproved to outperform others on static, achieving an accuracy of 0.68, a\nprecision of 0.68, a recall of 0.68, and F1-score of 0.67. While BERT model\noutperformed LSTM model on time-series data with an accuracy of 0.80, a\nprecision of 0.80, a recall of 0.80 and F1-score 0.80."}
{"id": "2505.17936", "pdf": "https://arxiv.org/pdf/2505.17936", "abs": "https://arxiv.org/abs/2505.17936", "authors": ["Sebastian Gerstner", "Hinrich Sch√ºtze"], "title": "Understanding Gated Neurons in Transformers from Their Input-Output Functionality", "categories": ["cs.LG", "cs.CL"], "comment": "31 pages, 22 figures", "summary": "Interpretability researchers have attempted to understand MLP neurons of\nlanguage models based on both the contexts in which they activate and their\noutput weight vectors. They have paid little attention to a complementary\naspect: the interactions between input and output. For example, when neurons\ndetect a direction in the input, they might add much the same direction to the\nresidual stream (\"enrichment neurons\") or reduce its presence (\"depletion\nneurons\"). We address this aspect by examining the cosine similarity between\ninput and output weights of a neuron. We apply our method to 12 models and find\nthat enrichment neurons dominate in early-middle layers whereas later layers\ntend more towards depletion. To explain this finding, we argue that enrichment\nneurons are largely responsible for enriching concept representations, one of\nthe first steps of factual recall. Our input-output perspective is a complement\nto activation-dependent analyses and to approaches that treat input and output\nseparately."}
{"id": "2505.17939", "pdf": "https://arxiv.org/pdf/2505.17939", "abs": "https://arxiv.org/abs/2505.17939", "authors": ["Manuel Lecha", "Andrea Cavallo", "Francesca Dominici", "Ran Levi", "Alessio Del Bue", "Elvin Isufi", "Pietro Morerio", "Claudio Battiloro"], "title": "Directed Semi-Simplicial Learning with Applications to Brain Activity Decoding", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) excel at learning from pairwise interactions but\noften overlook multi-way and hierarchical relationships. Topological Deep\nLearning (TDL) addresses this limitation by leveraging combinatorial\ntopological spaces. However, existing TDL models are restricted to undirected\nsettings and fail to capture the higher-order directed patterns prevalent in\nmany complex systems, e.g., brain networks, where such interactions are both\nabundant and functionally significant. To fill this gap, we introduce\nSemi-Simplicial Neural Networks (SSNs), a principled class of TDL models that\noperate on semi-simplicial sets -- combinatorial structures that encode\ndirected higher-order motifs and their directional relationships. To enhance\nscalability, we propose Routing-SSNs, which dynamically select the most\ninformative relations in a learnable manner. We prove that SSNs are strictly\nmore expressive than standard graph and TDL models. We then introduce a new\nprincipled framework for brain dynamics representation learning, grounded in\nthe ability of SSNs to provably recover topological descriptors shown to\nsuccessfully characterize brain activity. Empirically, SSNs achieve\nstate-of-the-art performance on brain dynamics classification tasks,\noutperforming the second-best model by up to 27%, and message passing GNNs by\nup to 50% in accuracy. Our results highlight the potential of principled\ntopological models for learning from structured brain data, establishing a\nunique real-world case study for TDL. We also test SSNs on standard node\nclassification and edge regression tasks, showing competitive performance. We\nwill make the code and data publicly available."}
{"id": "2505.17941", "pdf": "https://arxiv.org/pdf/2505.17941", "abs": "https://arxiv.org/abs/2505.17941", "authors": ["Zigeng Chen", "Xinyin Ma", "Gongfan Fang", "Ruonan Yu", "Xinchao Wang"], "title": "VeriThinker: Learning to Verify Makes Reasoning Model Efficient", "categories": ["cs.LG"], "comment": "Working in progress. Code Repo:\n  https://github.com/czg1225/VeriThinker", "summary": "Large Reasoning Models (LRMs) excel at complex tasks using Chain-of-Thought\n(CoT) reasoning. However, their tendency to overthinking leads to unnecessarily\nlengthy reasoning chains, dramatically increasing inference costs. To mitigate\nthis issue, we introduce VeriThinker, a novel approach for CoT compression.\nUnlike conventional methods that fine-tune LRMs directly on the original\nreasoning task using synthetic concise CoT data, we innovatively fine-tune the\nmodel solely through an auxiliary verification task. By training LRMs to\naccurately verify the correctness of CoT solutions, the LRMs inherently become\nmore discerning about the necessity of subsequent self-reflection steps,\nthereby effectively suppressing overthinking. Extensive experiments validate\nthat VeriThinker substantially reduces reasoning chain lengths while\nmaintaining or even slightly improving accuracy. When applied to\nDeepSeek-R1-Distill-Qwen-7B, our approach reduces reasoning tokens on MATH500\nfrom 3790 to 2125 while improving accuracy by 0.8% (94.0% to 94.8%), and on\nAIME25, tokens decrease from 14321 to 10287 with a 2.1% accuracy gain (38.7% to\n40.8%). Additionally, our experiments demonstrate that VeriThinker can also be\nzero-shot generalized to speculative reasoning. Code is available at\nhttps://github.com/czg1225/VeriThinker"}
{"id": "2505.17962", "pdf": "https://arxiv.org/pdf/2505.17962", "abs": "https://arxiv.org/abs/2505.17962", "authors": ["James A. Walker", "Moein Khajehnejad", "Adeel Razi"], "title": "A Principled Bayesian Framework for Training Binary and Spiking Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "We propose a Bayesian framework for training binary and spiking neural\nnetworks that achieves state-of-the-art performance without normalisation\nlayers. Unlike commonly used surrogate gradient methods -- often heuristic and\nsensitive to hyperparameter choices -- our approach is grounded in a\nprobabilistic model of noisy binary networks, enabling fully end-to-end\ngradient-based optimisation. We introduce importance-weighted straight-through\n(IW-ST) estimators, a unified class generalising straight-through and\nrelaxation-based estimators. We characterise the bias-variance trade-off in\nthis family and derive a bias-minimising objective implemented via an auxiliary\nloss. Building on this, we introduce Spiking Bayesian Neural Networks (SBNNs),\na variational inference framework that uses posterior noise to train Binary and\nSpiking Neural Networks with IW-ST. This Bayesian approach minimises gradient\nbias, regularises parameters, and introduces dropout-like noise. By linking\nlow-bias conditions, vanishing gradients, and the KL term, we enable training\nof deep residual networks without normalisation. Experiments on CIFAR-10, DVS\nGesture, and SHD show our method matches or exceeds existing approaches without\nnormalisation or hand-tuned gradients."}
{"id": "2505.17967", "pdf": "https://arxiv.org/pdf/2505.17967", "abs": "https://arxiv.org/abs/2505.17967", "authors": ["Ionut-Vlad Modoranu", "Mher Safaryan", "Erik Schultheis", "Dan Alistarh"], "title": "SVD-Free Low-Rank Adaptive Gradient Optimization for Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Low-rank optimization has emerged as a promising direction in training large\nlanguage models (LLMs) to reduce the memory usage of adaptive optimizers by\nconstraining learning to a lower-dimensional space. Prior work typically\nprojects gradients of linear layers using approaches based on Singular Value\nDecomposition (SVD). However, applying SVD-based procedures individually to\neach layer in large models is computationally expensive and incurs additional\nmemory costs due to storing the projection matrices. In this work, we propose a\ncomputationally efficient and conceptually simple two-step procedure to\napproximate SVD-based gradient projections into lower-dimensional spaces.\nFirst, we construct a complete orthogonal basis using predefined orthogonal\nmatrices of the Discrete Cosine Transform (DCT). Second, we adaptively select\nbasis columns based on their alignment with the gradient of each layer. Each\nprojection matrix in our method is obtained via a single matrix multiplication\nfollowed by a lightweight sorting step to identify the most relevant basis\nvectors. Due to the predefined nature of the orthogonal bases, they are\ncomputed once at the start of training. During training, we store only the\nindices of the selected columns, avoiding the need to store full projection\nmatrices for each layer. Our numerical experiments on both pre-training and\nfine-tuning tasks demonstrate the effectiveness of our dual strategy in\napproximating optimal low-rank projections, matching the performance of costly\nSVD-based methods while achieving faster runtime and reduced memory usage."}
{"id": "2505.17968", "pdf": "https://arxiv.org/pdf/2505.17968", "abs": "https://arxiv.org/abs/2505.17968", "authors": ["Jiayi Geng", "Howard Chen", "Dilip Arumugam", "Thomas L. Griffiths"], "title": "Are Large Language Models Reliable AI Scientists? Assessing Reverse-Engineering of Black-Box Systems", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages", "summary": "Using AI to create autonomous researchers has the potential to accelerate\nscientific discovery. A prerequisite for this vision is understanding how well\nan AI model can identify the underlying structure of a black-box system from\nits behavior. In this paper, we explore how well a large language model (LLM)\nlearns to identify a black-box function from passively observed versus actively\ncollected data. We investigate the reverse-engineering capabilities of LLMs\nacross three distinct types of black-box systems, each chosen to represent\ndifferent problem domains where future autonomous AI researchers may have\nconsiderable impact: Program, Formal Language, and Math Equation. Through\nextensive experiments, we show that LLMs fail to extract information from\nobservations, reaching a performance plateau that falls short of the ideal of\nBayesian inference. However, we demonstrate that prompting LLMs to not only\nobserve but also intervene -- actively querying the black-box with specific\ninputs to observe the resulting output -- improves performance by allowing LLMs\nto test edge cases and refine their beliefs. By providing the intervention data\nfrom one LLM to another, we show that this improvement is partly a result of\nengaging in the process of generating effective interventions, paralleling\nresults in the literature on human learning. Further analysis reveals that\nengaging in intervention can help LLMs escape from two common failure modes:\novercomplication, where the LLM falsely assumes prior knowledge about the\nblack-box, and overlooking, where the LLM fails to incorporate observations.\nThese insights provide practical guidance for helping LLMs more effectively\nreverse-engineer black-box systems, supporting their use in making new\ndiscoveries."}
{"id": "2505.17974", "pdf": "https://arxiv.org/pdf/2505.17974", "abs": "https://arxiv.org/abs/2505.17974", "authors": ["Viktoriia Chekalina", "Daniil Moskovskiy", "Daria Cherniuk", "Maxim Kurkin", "Andrey Kuznetsov", "Evgeny Frolov"], "title": "Generalized Fisher-Weighted SVD: Scalable Kronecker-Factored Fisher Approximation for Compressing Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The Fisher information is a fundamental concept for characterizing the\nsensitivity of parameters in neural networks. However, leveraging the full\nobserved Fisher information is too expensive for large models, so most methods\nrely on simple diagonal approximations. While efficient, this approach ignores\nparameter correlations, often resulting in reduced performance on downstream\ntasks. In this work, we mitigate these limitations and propose Generalized\nFisher-Weighted SVD (GFWSVD), a post-training LLM compression technique that\naccounts for both diagonal and off-diagonal elements of the Fisher information\nmatrix, providing a more accurate reflection of parameter importance. To make\nthe method tractable, we introduce a scalable adaptation of the\nKronecker-factored approximation algorithm for the observed Fisher information.\nWe demonstrate the effectiveness of our method on LLM compression, showing\nimprovements over existing compression baselines. For example, at a 20\ncompression rate on the MMLU benchmark, our method outperforms FWSVD, which is\nbased on a diagonal approximation of the Fisher information, by 5 percent,\nSVD-LLM by 3 percent, and ASVD by 6 percent compression rate."}
{"id": "2505.17987", "pdf": "https://arxiv.org/pdf/2505.17987", "abs": "https://arxiv.org/abs/2505.17987", "authors": ["Weihang You", "Hanqi Jiang", "Zishuai Liu", "Zihang Xie", "Tianming Liu", "Jin Lu", "Fei Dou"], "title": "ADLGen: Synthesizing Symbolic, Event-Triggered Sensor Sequences for Human Activity Modeling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real world collection of Activities of Daily Living data is challenging due\nto privacy concerns, costly deployment and labeling, and the inherent sparsity\nand imbalance of human behavior. We present ADLGen, a generative framework\nspecifically designed to synthesize realistic, event triggered, and symbolic\nsensor sequences for ambient assistive environments. ADLGen integrates a\ndecoder only Transformer with sign based symbolic temporal encoding, and a\ncontext and layout aware sampling mechanism to guide generation toward\nsemantically rich and physically plausible sensor event sequences. To enhance\nsemantic fidelity and correct structural inconsistencies, we further\nincorporate a large language model into an automatic generate evaluate refine\nloop, which verifies logical, behavioral, and temporal coherence and generates\ncorrection rules without manual intervention or environment specific tuning.\nThrough comprehensive experiments with novel evaluation metrics, ADLGen is\nshown to outperform baseline generators in statistical fidelity, semantic\nrichness, and downstream activity recognition, offering a scalable and\nprivacy-preserving solution for ADL data synthesis."}
{"id": "2505.17988", "pdf": "https://arxiv.org/pdf/2505.17988", "abs": "https://arxiv.org/abs/2505.17988", "authors": ["Yutong Chen", "Jiandong Gao", "Ji Wu"], "title": "Towards Revealing the Effectiveness of Small-Scale Fine-tuning in R1-style Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "11 figs, 3 table, preprint", "summary": "R1-style Reinforcement Learning (RL) significantly enhances Large Language\nModels' reasoning capabilities, yet the mechanism behind rule-based RL remains\nunclear. We found that small-scale SFT has significant influence on RL but\nshows poor efficiency. To explain our observations, we propose an analytical\nframework and compare the efficiency of SFT and RL by measuring sample effect.\nHypothetical analysis show that SFT efficiency is limited by training data.\nGuided by our analysis, we propose Re-distillation, a technique that fine-tunes\npretrain model through small-scale distillation from the RL-trained policy.\nExperiments on Knight & Knave and MATH datasets demonstrate re-distillation's\nsurprising efficiency: re-distilled models match RL performance with far fewer\nsamples and less computation. Empirical verification shows that sample effect\nis a good indicator of performance improvements. As a result, on K&K dataset,\nour re-distilled Qwen2.5-1.5B model surpasses DeepSeek-V3-0324 with only 1K SFT\nsamples. On MATH, Qwen2.5-1.5B fine-tuned with re-distilled 500 samples matches\nits instruct-tuned variant without RL. Our work explains several interesting\nphenomena in R1-style RL, shedding light on the mechanisms behind its empirical\nsuccess. Code is available at: https://github.com/on1262/deep-reasoning"}
{"id": "2505.17989", "pdf": "https://arxiv.org/pdf/2505.17989", "abs": "https://arxiv.org/abs/2505.17989", "authors": ["Benjamin Turtel", "Danny Franklin", "Kris Skotheim", "Luke Hewitt", "Philipp Schoenegger"], "title": "Outcome-based Reinforcement Learning to Predict the Future", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has boosted math and\ncoding in large language models, yet there has been little effort to extend\nRLVR into messier, real-world domains like forecasting. One sticking point is\nthat outcome-based reinforcement learning for forecasting must learn from\nbinary, delayed, and noisy rewards, a regime where standard fine-tuning is\nbrittle. We show that outcome-only online RL on a 14B model can match\nfrontier-scale accuracy and surpass it in calibration and hypothetical\nprediction market betting by adapting two leading algorithms, Group-Relative\nPolicy Optimisation (GRPO) and ReMax, to the forecasting setting. Our\nadaptations remove per-question variance scaling in GRPO, apply\nbaseline-subtracted advantages in ReMax, hydrate training with 100k temporally\nconsistent synthetic questions, and introduce lightweight guard-rails that\npenalise gibberish, non-English responses and missing rationales, enabling a\nsingle stable pass over 110k events. Scaling ReMax to 110k questions and\nensembling seven predictions yields a 14B model that matches frontier baseline\no1 on accuracy on our holdout set (Brier = 0.193, p = 0.23) while beating it in\ncalibration (ECE = 0.042, p < 0.001). A simple trading rule turns this\ncalibration edge into \\$127 of hypothetical profit versus \\$92 for o1 (p =\n0.037). This demonstrates that refined RLVR methods can convert small-scale\nLLMs into potentially economically valuable forecasting tools, with\nimplications for scaling this to larger models."}
{"id": "2505.17997", "pdf": "https://arxiv.org/pdf/2505.17997", "abs": "https://arxiv.org/abs/2505.17997", "authors": ["Jintian Shao", "Yiming Cheng", "Hongyi Huang", "Beiwen Zhang", "Zhiyu Wu", "You Shan", "Mingkai Zheng"], "title": "Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "The VAPO framework has demonstrated significant empirical success in\nenhancing the efficiency and reliability of reinforcement learning for long\nchain-of-thought (CoT) reasoning tasks with large language models (LLMs). By\nsystematically addressing challenges such as value model bias, heterogeneous\nsequence lengths, and sparse reward signals, VAPO achieves state-of-the-art\nperformance. While its practical benefits are evident, a deeper theoretical\nunderstanding of its underlying mechanisms and potential limitations is crucial\nfor guiding future advancements. This paper aims to initiate such a discussion\nby exploring VAPO from a theoretical perspective, highlighting areas where its\nassumptions might be challenged and where further investigation could yield\nmore robust and generalizable reasoning agents. We delve into the intricacies\nof value function approximation in complex reasoning spaces, the optimality of\nadaptive advantage estimation, the impact of token-level optimization, and the\nenduring challenges of exploration and generalization."}
{"id": "2505.18002", "pdf": "https://arxiv.org/pdf/2505.18002", "abs": "https://arxiv.org/abs/2505.18002", "authors": ["Di Jin", "Jingyi Cao", "Xiaobao Wang", "Bingdao Feng", "Dongxiao He", "Longbiao Wang", "Jianwu Dang"], "title": "Rethinking Contrastive Learning in Graph Anomaly Detection: A Clean-View Perspective", "categories": ["cs.LG"], "comment": null, "summary": "Graph anomaly detection aims to identify unusual patterns in graph-based\ndata, with wide applications in fields such as web security and financial fraud\ndetection. Existing methods typically rely on contrastive learning, assuming\nthat a lower similarity between a node and its local subgraph indicates\nabnormality. However, these approaches overlook a crucial limitation: the\npresence of interfering edges invalidates this assumption, since it introduces\ndisruptive noise that compromises the contrastive learning process.\nConsequently, this limitation impairs the ability to effectively learn\nmeaningful representations of normal patterns, leading to suboptimal detection\nperformance. To address this issue, we propose a Clean-View Enhanced Graph\nAnomaly Detection framework (CVGAD), which includes a multi-scale anomaly\nawareness module to identify key sources of interference in the contrastive\nlearning process. Moreover, to mitigate bias from the one-step edge removal\nprocess, we introduce a novel progressive purification module. This module\nincrementally refines the graph by iteratively identifying and removing\ninterfering edges, thereby enhancing model performance. Extensive experiments\non five benchmark datasets validate the effectiveness of our approach."}
{"id": "2505.18003", "pdf": "https://arxiv.org/pdf/2505.18003", "abs": "https://arxiv.org/abs/2505.18003", "authors": ["Joshua Clymer", "Jonah Weinbaum", "Robert Kirk", "Kimberly Mai", "Selena Zhang", "Xander Davies"], "title": "An Example Safety Case for Safeguards Against Misuse", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Existing evaluations of AI misuse safeguards provide a patchwork of evidence\nthat is often difficult to connect to real-world decisions. To bridge this gap,\nwe describe an end-to-end argument (a \"safety case\") that misuse safeguards\nreduce the risk posed by an AI assistant to low levels. We first describe how a\nhypothetical developer red teams safeguards, estimating the effort required to\nevade them. Then, the developer plugs this estimate into a quantitative \"uplift\nmodel\" to determine how much barriers introduced by safeguards dissuade misuse\n(https://www.aimisusemodel.com/). This procedure provides a continuous signal\nof risk during deployment that helps the developer rapidly respond to emerging\nthreats. Finally, we describe how to tie these components together into a\nsimple safety case. Our work provides one concrete path -- though not the only\npath -- to rigorously justifying AI misuse risks are low."}
{"id": "2505.18005", "pdf": "https://arxiv.org/pdf/2505.18005", "abs": "https://arxiv.org/abs/2505.18005", "authors": ["Sergio Calo", "Anders Jonsson", "Gergely Neu", "Ludovic Schwartz", "Javier Segovia-Aguas"], "title": "Distances for Markov chains from sample streams", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Bisimulation metrics are powerful tools for measuring similarities between\nstochastic processes, and specifically Markov chains. Recent advances have\nuncovered that bisimulation metrics are, in fact, optimal-transport distances,\nwhich has enabled the development of fast algorithms for computing such metrics\nwith provable accuracy and runtime guarantees. However, these recent methods,\nas well as all previously known methods, assume full knowledge of the\ntransition dynamics. This is often an impractical assumption in most real-world\nscenarios, where typically only sample trajectories are available. In this\nwork, we propose a stochastic optimization method that addresses this\nlimitation and estimates bisimulation metrics based on sample access, without\nrequiring explicit transition models. Our approach is derived from a new linear\nprogramming (LP) formulation of bisimulation metrics, which we solve using a\nstochastic primal-dual optimization method. We provide theoretical guarantees\non the sample complexity of the algorithm and validate its effectiveness\nthrough a series of empirical evaluations."}
{"id": "2505.18017", "pdf": "https://arxiv.org/pdf/2505.18017", "abs": "https://arxiv.org/abs/2505.18017", "authors": ["Matthieu Blanke", "Yongquan Qu", "Sara Shamekh", "Pierre Gentine"], "title": "Strictly Constrained Generative Modeling via Split Augmented Langevin Sampling", "categories": ["cs.LG"], "comment": null, "summary": "Deep generative models hold great promise for representing complex physical\nsystems, but their deployment is currently limited by the lack of guarantees on\nthe physical plausibility of the generated outputs. Ensuring that known\nphysical constraints are enforced is therefore critical when applying\ngenerative models to scientific and engineering problems. We address this\nlimitation by developing a principled framework for sampling from a target\ndistribution while rigorously satisfying physical constraints. Leveraging the\nvariational formulation of Langevin dynamics, we propose Split Augmented\nLangevin (SAL), a novel primal-dual sampling algorithm that enforces\nconstraints progressively through variable splitting, with convergence\nguarantees. While the method is developed theoretically for Langevin dynamics,\nwe demonstrate its effective applicability to diffusion models. In particular,\nwe use constrained diffusion models to generate physical fields satisfying\nenergy and mass conservation laws. We apply our method to diffusion-based data\nassimilation on a complex physical system, where enforcing physical constraints\nsubstantially improves both forecast accuracy and the preservation of critical\nconserved quantities. We also demonstrate the potential of SAL for challenging\nfeasibility problems in optimal control."}
{"id": "2505.18023", "pdf": "https://arxiv.org/pdf/2505.18023", "abs": "https://arxiv.org/abs/2505.18023", "authors": ["Duc Anh Nguyen", "Ernesto Araya", "Adalbert Fono", "Gitta Kutyniok"], "title": "Time to Spike? Understanding the Representational Power of Spiking Neural Networks in Discrete Time", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Recent years have seen significant progress in developing spiking neural\nnetworks (SNNs) as a potential solution to the energy challenges posed by\nconventional artificial neural networks (ANNs). However, our theoretical\nunderstanding of SNNs remains relatively limited compared to the ever-growing\nbody of literature on ANNs. In this paper, we study a discrete-time model of\nSNNs based on leaky integrate-and-fire (LIF) neurons, referred to as\ndiscrete-time LIF-SNNs, a widely used framework that still lacks solid\ntheoretical foundations. We demonstrate that discrete-time LIF-SNNs with static\ninputs and outputs realize piecewise constant functions defined on polyhedral\nregions, and more importantly, we quantify the network size required to\napproximate continuous functions. Moreover, we investigate the impact of\nlatency (number of time steps) and depth (number of layers) on the complexity\nof the input space partitioning induced by discrete-time LIF-SNNs. Our analysis\nhighlights the importance of latency and contrasts these networks with ANNs\nemploying piecewise linear activation functions. Finally, we present numerical\nexperiments to support our theoretical findings."}
{"id": "2505.18028", "pdf": "https://arxiv.org/pdf/2505.18028", "abs": "https://arxiv.org/abs/2505.18028", "authors": ["Zizhao Chen", "Yoav Artzi"], "title": "Knot So Simple: A Minimalistic Environment for Spatial Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO"], "comment": null, "summary": "We propose KnotGym, an interactive environment for complex, spatial reasoning\nand manipulation. KnotGym includes goal-oriented rope manipulation tasks with\nvarying levels of complexity, all requiring acting from pure image\nobservations. Tasks are defined along a clear and quantifiable axis of\ncomplexity based on the number of knot crossings, creating a natural\ngeneralization test. KnotGym has a simple observation space, allowing for\nscalable development, yet it highlights core challenges in integrating acute\nperception, spatial reasoning, and grounded manipulation. We evaluate methods\nof different classes, including model-based RL, model-predictive control, and\nchain-of-thought reasoning, and illustrate the challenges KnotGym presents.\nKnotGym is available at https://github.com/lil-lab/knotgym."}
{"id": "2505.18032", "pdf": "https://arxiv.org/pdf/2505.18032", "abs": "https://arxiv.org/abs/2505.18032", "authors": ["Maximilian Mueller", "Matthias Hein"], "title": "Mahalanobis++: Improving OOD Detection via Feature Normalization", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Detecting out-of-distribution (OOD) examples is an important task for\ndeploying reliable machine learning models in safety-critial applications.\nWhile post-hoc methods based on the Mahalanobis distance applied to pre-logit\nfeatures are among the most effective for ImageNet-scale OOD detection, their\nperformance varies significantly across models. We connect this inconsistency\nto strong variations in feature norms, indicating severe violations of the\nGaussian assumption underlying the Mahalanobis distance estimation. We show\nthat simple $\\ell_2$-normalization of the features mitigates this problem\neffectively, aligning better with the premise of normally distributed data with\nshared covariance matrix. Extensive experiments on 44 models across diverse\narchitectures and pretraining schemes show that $\\ell_2$-normalization improves\nthe conventional Mahalanobis distance-based approaches significantly and\nconsistently, and outperforms other recently proposed OOD detection methods."}
{"id": "2505.18043", "pdf": "https://arxiv.org/pdf/2505.18043", "abs": "https://arxiv.org/abs/2505.18043", "authors": ["Changyeol Lee", "Yongho Shin", "Hyung-Chan An"], "title": "Improved Algorithms for Overlapping and Robust Clustering of Edge-Colored Hypergraphs: An LP-Based Combinatorial Approach", "categories": ["cs.LG", "cs.DB", "cs.DS"], "comment": null, "summary": "Clustering is a fundamental task in both machine learning and data mining.\nAmong various methods, edge-colored clustering (ECC) has emerged as a useful\napproach for handling categorical data. Given a hypergraph with (hyper)edges\nlabeled by colors, ECC aims to assign vertex colors to minimize the number of\nedges where the vertex color differs from the edge's color. However,\ntraditional ECC has inherent limitations, as it enforces a nonoverlapping and\nexhaustive clustering. To tackle these limitations, three versions of ECC have\nbeen studied: Local ECC and Global ECC, which allow overlapping clusters, and\nRobust ECC, which accounts for vertex outliers. For these problems, both linear\nprogramming (LP) rounding algorithms and greedy combinatorial algorithms have\nbeen proposed. While these LP-rounding algorithms provide high-quality\nsolutions, they demand substantial computation time; the greedy algorithms, on\nthe other hand, run very fast but often compromise solution quality. In this\npaper, we present an algorithmic framework that combines the strengths of LP\nwith the computational efficiency of combinatorial algorithms. Both\nexperimental and theoretical analyses show that our algorithms efficiently\nproduce high-quality solutions for all three problems: Local, Global, and\nRobust ECC. We complement our algorithmic contributions with\ncomplexity-theoretic inapproximability results and integrality gap bounds,\nwhich suggest that significant theoretical improvements are unlikely. Our\nresults also answer two open questions previously raised in the literature."}
{"id": "2505.18044", "pdf": "https://arxiv.org/pdf/2505.18044", "abs": "https://arxiv.org/abs/2505.18044", "authors": ["Zhishuai Liu", "Pan Xu"], "title": "Linear Mixture Distributionally Robust Markov Decision Processes", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "comment": "26 pages, 7 figures", "summary": "Many real-world decision-making problems face the off-dynamics challenge: the\nagent learns a policy in a source domain and deploys it in a target domain with\ndifferent state transitions. The distributionally robust Markov decision\nprocess (DRMDP) addresses this challenge by finding a robust policy that\nperforms well under the worst-case environment within a pre-specified\nuncertainty set of transition dynamics. Its effectiveness heavily hinges on the\nproper design of these uncertainty sets, based on prior knowledge of the\ndynamics. In this work, we propose a novel linear mixture DRMDP framework,\nwhere the nominal dynamics is assumed to be a linear mixture model. In contrast\nwith existing uncertainty sets directly defined as a ball centered around the\nnominal kernel, linear mixture DRMDPs define the uncertainty sets based on a\nball around the mixture weighting parameter. We show that this new framework\nprovides a more refined representation of uncertainties compared to\nconventional models based on $(s,a)$-rectangularity and $d$-rectangularity,\nwhen prior knowledge about the mixture model is present. We propose a meta\nalgorithm for robust policy learning in linear mixture DRMDPs with general\n$f$-divergence defined uncertainty sets, and analyze its sample complexities\nunder three divergence metrics instantiations: total variation,\nKullback-Leibler, and $\\chi^2$ divergences. These results establish the\nstatistical learnability of linear mixture DRMDPs, laying the theoretical\nfoundation for future research on this new setting."}
{"id": "2505.18046", "pdf": "https://arxiv.org/pdf/2505.18046", "abs": "https://arxiv.org/abs/2505.18046", "authors": ["Yizhou Xu", "Florent Krzakala", "Lenka Zdeborov√°"], "title": "Learning with Restricted Boltzmann Machines: Asymptotics of AMP and GD in High Dimensions", "categories": ["cs.LG", "cond-mat.dis-nn", "stat.ML"], "comment": null, "summary": "The Restricted Boltzmann Machine (RBM) is one of the simplest generative\nneural networks capable of learning input distributions. Despite its\nsimplicity, the analysis of its performance in learning from the training data\nis only well understood in cases that essentially reduce to singular value\ndecomposition of the data. Here, we consider the limit of a large dimension of\nthe input space and a constant number of hidden units. In this limit, we\nsimplify the standard RBM training objective into a form that is equivalent to\nthe multi-index model with non-separable regularization. This opens a path to\nanalyze training of the RBM using methods that are established for multi-index\nmodels, such as Approximate Message Passing (AMP) and its state evolution, and\nthe analysis of Gradient Descent (GD) via the dynamical mean-field theory. We\nthen give rigorous asymptotics of the training dynamics of RBM on data\ngenerated by the spiked covariance model as a prototype of a structure suitable\nfor unsupervised learning. We show in particular that RBM reaches the optimal\ncomputational weak recovery threshold, aligning with the BBP transition, in the\nspiked covariance model."}
{"id": "2505.18064", "pdf": "https://arxiv.org/pdf/2505.18064", "abs": "https://arxiv.org/abs/2505.18064", "authors": ["Victor Boone"], "title": "Asymptotically optimal regret in communicating Markov decision processes", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "In this paper, we present a learning algorithm that achieves asymptotically\noptimal regret for Markov decision processes in average reward under a\ncommunicating assumption. That is, given a communicating Markov decision\nprocess $M$, our algorithm has regret $K(M) \\log(T) + \\mathrm{o}(\\log(T))$\nwhere $T$ is the number of learning steps and $K(M)$ is the best possible\nconstant. This algorithm works by explicitly tracking the constant $K(M)$ to\nlearn optimally, then balances the trade-off between exploration (playing\nsub-optimally to gain information), co-exploration (playing optimally to gain\ninformation) and exploitation (playing optimally to score maximally). We\nfurther show that the function $K(M)$ is discontinuous, which is a consequence\nchallenge for our approach. To that end, we describe a regularization mechanism\nto estimate $K(M)$ with arbitrary precision from empirical data."}
{"id": "2505.18065", "pdf": "https://arxiv.org/pdf/2505.18065", "abs": "https://arxiv.org/abs/2505.18065", "authors": ["Zeen Song", "Wenwen Qiang", "Siyu Zhao", "Changwen Zheng", "Gang Hua"], "title": "Reward Model Generalization for Compute-Aware Test-Time Reasoning", "categories": ["cs.LG"], "comment": null, "summary": "External test-time reasoning enhances large language models (LLMs) by\ndecoupling generation and selection. At inference time, the model generates\nmultiple reasoning paths, and an auxiliary process reward model (PRM) is used\nto score and select the best one. A central challenge in this setting is\ntest-time compute optimality (TCO), i.e., how to maximize answer accuracy under\na fixed inference budget. In this work, we establish a theoretical framework to\nanalyze how the generalization error of the PRM affects compute efficiency and\nreasoning performance. Leveraging PAC-Bayes theory, we derive generalization\nbounds and show that a lower generalization error of PRM leads to fewer samples\nrequired to find correct answers. Motivated by this analysis, we propose\nCompute-Aware Tree Search (CATS), an actor-critic framework that dynamically\ncontrols search behavior. The actor outputs sampling hyperparameters based on\nreward distributions and sparsity statistics, while the critic estimates their\nutility to guide budget allocation. Experiments on the MATH and AIME benchmarks\nwith various LLMs and PRMs demonstrate that CATS consistently outperforms other\nexternal TTS methods, validating our theoretical predictions."}
{"id": "2505.18069", "pdf": "https://arxiv.org/pdf/2505.18069", "abs": "https://arxiv.org/abs/2505.18069", "authors": ["David Koplow", "Tomaso Poggio", "Liu Ziyin"], "title": "Emergence of Hebbian Dynamics in Regularized Non-Local Learners", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Stochastic Gradient Descent (SGD) has emerged as a remarkably effective\nlearning algorithm, underpinning nearly all state-of-the-art machine learning\nmodels, from large language models to autonomous vehicles. Despite its\npractical success, SGD appears fundamentally distinct from biological learning\nmechanisms. It is widely believed that the biological brain can not implement\ngradient descent because it is nonlocal, and we have found little (if any)\nexperimental evidence for it. In contrast, the brain is widely thought to learn\nvia local Hebbian learning principles, which have been seen as incompatible\nwith gradient descent. In this paper, we establish a theoretical and empirical\nconnection between the learning signals of neural networks trained using SGD\nwith weight decay and those trained with Hebbian learning near convergence. We\nshow that SGD with regularization can appear to learn according to a Hebbian\nrule, and SGD with injected noise according to an anti-Hebbian rule. We also\nprovide empirical evidence that Hebbian learning properties can emerge in a\nnetwork with weight decay from virtually any learning rule--even random ones.\nThese results may bridge a long-standing gap between artificial and biological\nlearning, revealing Hebbian properties as an epiphenomenon of deeper\noptimization principles and cautioning against interpreting their presence in\nneural data as evidence against more complex hetero-synaptic mechanisms."}
{"id": "2505.18080", "pdf": "https://arxiv.org/pdf/2505.18080", "abs": "https://arxiv.org/abs/2505.18080", "authors": ["Chunlin Gong", "Yin Wang", "Jingru Li", "Hanleran Zhang"], "title": "AFD-STA: Adaptive Filtering Denoising with Spatiotemporal Attention for Chaotic System Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages, 11 figures", "summary": "This paper presents AFD-STA Net, a neural framework integrating adaptive\nfiltering and spatiotemporal dynamics learning for predicting high-dimensional\nchaotic systems governed by partial differential equations. The architecture\ncombines: 1) An adaptive exponential smoothing module with position-aware decay\ncoefficients for robust attractor reconstruction, 2) Parallel attention\nmechanisms capturing cross-temporal and spatial dependencies, 3) Dynamic gated\nfusion of multiscale features, and 4) Deep projection networks with\ndimension-scaling capabilities. Numerical experiments on nonlinear PDE systems\ndemonstrate the model's effectiveness in maintaining prediction accuracy under\nboth smooth and strongly chaotic regimes while exhibiting noise tolerance\nthrough adaptive filtering. Component ablation studies confirm critical\ncontributions from each module, particularly highlighting the essential role of\nspatiotemporal attention in learning complex dynamical interactions. The\nframework shows promising potential for real-world applications requiring\nsimultaneous handling of measurement uncertainties and high-dimensional\nnonlinear dynamics."}
{"id": "2505.18081", "pdf": "https://arxiv.org/pdf/2505.18081", "abs": "https://arxiv.org/abs/2505.18081", "authors": ["Adam D. Cobb", "Susmit Jha"], "title": "Backpropagation-Free Metropolis-Adjusted Langevin Algorithm", "categories": ["cs.LG", "cs.AI"], "comment": "19 Pages, 8 Figures", "summary": "Recent work on backpropagation-free learning has shown that it is possible to\nuse forward-mode automatic differentiation (AD) to perform optimization on\ndifferentiable models. Forward-mode AD requires sampling a tangent vector for\neach forward pass of a model. The result is the model evaluation with the\ndirectional derivative along the tangent. In this paper, we illustrate how the\nsampling of this tangent vector can be incorporated into the proposal mechanism\nfor the Metropolis-Adjusted Langevin Algorithm (MALA). As such, we are the\nfirst to introduce a backpropagation-free gradient-based Markov chain Monte\nCarlo (MCMC) algorithm. We also extend to a novel backpropagation-free\nposition-specific preconditioned forward-mode MALA that leverages Hessian\ninformation. Overall, we propose four new algorithms: Forward MALA; Line\nForward MALA; Pre-conditioned Forward MALA, and Pre-conditioned Line Forward\nMALA. We highlight the reduced computational cost of the forward-mode samplers\nand show that forward-mode is competitive with the original MALA, while even\noutperforming it depending on the probabilistic model. We include Bayesian\ninference results on a range of probabilistic models, including hierarchical\ndistributions and Bayesian neural networks."}
{"id": "2505.18082", "pdf": "https://arxiv.org/pdf/2505.18082", "abs": "https://arxiv.org/abs/2505.18082", "authors": ["Georgios Kementzidis", "Erin Wong", "John Nicholson", "Ruichen Xu", "Yuefan Deng"], "title": "An Iterative Framework for Generative Backmapping of Coarse Grained Proteins", "categories": ["cs.LG"], "comment": "17 pages, 8 figures. For associated code repositories, see: CGVAE:\n  https://github.com/wwang2/CoarseGrainingVAE GenZProT:\n  https://github.com/learningmatter-mit/GenZProt See also arXiv:2201.12176 and\n  arXiv:2303.01569 for related methods", "summary": "The techniques of data-driven backmapping from coarse-grained (CG) to\nfine-grained (FG) representation often struggle with accuracy, unstable\ntraining, and physical realism, especially when applied to complex systems such\nas proteins. In this work, we introduce a novel iterative framework by using\nconditional Variational Autoencoders and graph-based neural networks,\nspecifically designed to tackle the challenges associated with such large-scale\nbiomolecules. Our method enables stepwise refinement from CG beads to full\natomistic details. We outline the theory of iterative generative backmapping\nand demonstrate via numerical experiments the advantages of multistep schemes\nby applying them to proteins of vastly different structures with very coarse\nrepresentations. This multistep approach not only improves the accuracy of\nreconstructions but also makes the training process more computationally\nefficient for proteins with ultra-CG representations."}
{"id": "2505.18083", "pdf": "https://arxiv.org/pdf/2505.18083", "abs": "https://arxiv.org/abs/2505.18083", "authors": ["Quentin Clark", "Florian Shkurti"], "title": "What Do You Need for Diverse Trajectory Stitching in Diffusion Planning?", "categories": ["cs.LG", "cs.RO"], "comment": "9 Pages", "summary": "In planning, stitching is an ability of algorithms to piece together\nsub-trajectories of data they are trained on to generate new and diverse\nbehaviours. While stitching is historically a strength of offline reinforcement\nlearning, recent generative behavioural cloning (BC) methods have also shown\nproficiency at stitching. However, the main factors behind this are poorly\nunderstood, hindering the development of new algorithms that can reliably\nstitch. Focusing on diffusion planners trained via BC, we find two properties\nare needed to compose: \\emph{positional equivariance} and \\emph{local\nreceptiveness}. We use these two properties to explain architecture, data, and\ninference choices in existing generative BC methods based on diffusion\nplanning, including replanning frequency, data augmentation, and data scaling.\nExperimental comparisions show that (1) while locality is more important than\npositional equivariance in creating a diffusion planner capable of composition,\nboth are crucial (2) enabling these properties through relatively simple\narchitecture choices can be competitive with more computationally expensive\nmethods such as replanning or scaling data, and (3) simple inpainting-based\nguidance can guide architecturally compositional models to enable\ngeneralization in goal-conditioned settings."}
{"id": "2505.18088", "pdf": "https://arxiv.org/pdf/2505.18088", "abs": "https://arxiv.org/abs/2505.18088", "authors": ["Andrea Giuseppe Di Francesco", "Maria Sofia Bucarelli", "Franco Maria Nardini", "Raffaele Perego", "Nicola Tonellotto", "Fabrizio Silvestri"], "title": "Early-Exit Graph Neural Networks", "categories": ["cs.LG"], "comment": "37 pages, 14 figures", "summary": "Early-exit mechanisms allow deep neural networks to halt inference as soon as\nclassification confidence is high enough, adaptively trading depth for\nconfidence, and thereby cutting latency and energy on easy inputs while\nretaining full-depth accuracy for harder ones. Similarly, adding early exit\nmechanisms to Graph Neural Networks (GNNs), the go-to models for\ngraph-structured data, allows for dynamic trading depth for confidence on\nsimple graphs while maintaining full-depth accuracy on harder and more complex\ngraphs to capture intricate relationships. Although early exits have proven\neffective across various deep learning domains, their potential within GNNs in\nscenarios that require deep architectures while resisting over-smoothing and\nover-squashing remains largely unexplored. We unlock that potential by first\nintroducing Symmetric-Anti-Symmetric Graph Neural Networks (SAS-GNN), whose\nsymmetry-based inductive biases mitigate these issues and yield stable\nintermediate representations that can be useful to allow early exiting in GNNs.\nBuilding on this backbone, we present Early-Exit Graph Neural Networks\n(EEGNNs), which append confidence-aware exit heads that allow on-the-fly\ntermination of propagation based on each node or the entire graph. Experiments\nshow that EEGNNs preserve robust performance as depth grows and deliver\ncompetitive accuracy on heterophilic and long-range benchmarks, matching\nattention-based and asynchronous message-passing models while substantially\nreducing computation and latency. We plan to release the code to reproduce our\nexperiments."}
{"id": "2505.18091", "pdf": "https://arxiv.org/pdf/2505.18091", "abs": "https://arxiv.org/abs/2505.18091", "authors": ["Xinran Gu", "Kaifeng Lyu", "Jiazheng Li", "Jingzhao Zhang"], "title": "Data Mixing Can Induce Phase Transitions in Knowledge Acquisition", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) are typically trained on data mixtures: most\ndata come from web scrapes, while a small portion is curated from high-quality\nsources with dense domain-specific knowledge. In this paper, we show that when\ntraining LLMs on such data mixtures, knowledge acquisition from knowledge-dense\ndatasets, unlike training exclusively on knowledge-dense data\n(arXiv:2404.05405), does not always follow a smooth scaling law but can exhibit\nphase transitions with respect to the mixing ratio and model size. Through\ncontrolled experiments on a synthetic biography dataset mixed with web-scraped\ndata, we demonstrate that: (1) as we increase the model size to a critical\nvalue, the model suddenly transitions from memorizing very few to most of the\nbiographies; (2) below a critical mixing ratio, the model memorizes almost\nnothing even with extensive training, but beyond this threshold, it rapidly\nmemorizes more biographies. We attribute these phase transitions to a capacity\nallocation phenomenon: a model with bounded capacity must act like a knapsack\nproblem solver to minimize the overall test loss, and the optimal allocation\nacross datasets can change discontinuously as the model size or mixing ratio\nvaries. We formalize this intuition in an information-theoretic framework and\nreveal that these phase transitions are predictable, with the critical mixing\nratio following a power-law relationship with the model size. Our findings\nhighlight a concrete case where a good mixing recipe for large models may not\nbe optimal for small models, and vice versa."}
{"id": "2505.18097", "pdf": "https://arxiv.org/pdf/2505.18097", "abs": "https://arxiv.org/abs/2505.18097", "authors": ["Chun Tong Lei", "Zhongliang Guo", "Hon Chung Lee", "Minh Quoc Duong", "Chun Pong Lau"], "title": "Towards more transferable adversarial attack in black-box manner", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Adversarial attacks have become a well-explored domain, frequently serving as\nevaluation baselines for model robustness. Among these, black-box attacks based\non transferability have received significant attention due to their practical\napplicability in real-world scenarios. Traditional black-box methods have\ngenerally focused on improving the optimization framework (e.g., utilizing\nmomentum in MI-FGSM) to enhance transferability, rather than examining the\ndependency on surrogate white-box model architectures. Recent state-of-the-art\napproach DiffPGD has demonstrated enhanced transferability by employing\ndiffusion-based adversarial purification models for adaptive attacks. The\ninductive bias of diffusion-based adversarial purification aligns naturally\nwith the adversarial attack process, where both involving noise addition,\nreducing dependency on surrogate white-box model selection. However, the\ndenoising process of diffusion models incurs substantial computational costs\nthrough chain rule derivation, manifested in excessive VRAM consumption and\nextended runtime. This progression prompts us to question whether introducing\ndiffusion models is necessary. We hypothesize that a model sharing similar\ninductive bias to diffusion-based adversarial purification, combined with an\nappropriate loss function, could achieve comparable or superior transferability\nwhile dramatically reducing computational overhead. In this paper, we propose a\nnovel loss function coupled with a unique surrogate model to validate our\nhypothesis. Our approach leverages the score of the time-dependent classifier\nfrom classifier-guided diffusion models, effectively incorporating natural data\ndistribution knowledge into the adversarial optimization process. Experimental\nresults demonstrate significantly improved transferability across diverse model\narchitectures while maintaining robustness against diffusion-based defenses."}
{"id": "2505.18101", "pdf": "https://arxiv.org/pdf/2505.18101", "abs": "https://arxiv.org/abs/2505.18101", "authors": ["Congren Dai", "Huichi Zhou", "Jiahao Huang", "Zhenxuan Zhang", "Fanwen Wang", "Guang Yang", "Fei Ye"], "title": "Dynamic Dual Buffer with Divide-and-Conquer Strategy for Online Continual Learning", "categories": ["cs.LG"], "comment": null, "summary": "Online Continual Learning (OCL) presents a complex learning environment in\nwhich new data arrives in a batch-to-batch online format, and the risk of\ncatastrophic forgetting can significantly impair model efficacy. In this study,\nwe address OCL by introducing an innovative memory framework that incorporates\na short-term memory system to retain dynamic information and a long-term memory\nsystem to archive enduring knowledge. Specifically, the long-term memory system\ncomprises a collection of sub-memory buffers, each linked to a cluster\nprototype and designed to retain data samples from distinct categories. We\npropose a novel $K$-means-based sample selection method to identify cluster\nprototypes for each encountered category. To safeguard essential and critical\nsamples, we introduce a novel memory optimisation strategy that selectively\nretains samples in the appropriate sub-memory buffer by evaluating each cluster\nprototype against incoming samples through an optimal transportation mechanism.\nThis approach specifically promotes each sub-memory buffer to retain data\nsamples that exhibit significant discrepancies from the corresponding cluster\nprototype, thereby ensuring the preservation of semantically rich information.\nIn addition, we propose a novel Divide-and-Conquer (DAC) approach that\nformulates the memory updating as an optimisation problem and divides it into\nseveral subproblems. As a result, the proposed DAC approach can solve these\nsubproblems separately and thus can significantly reduce computations of the\nproposed memory updating process. We conduct a series of experiments across\nstandard and imbalanced learning settings, and the empirical findings indicate\nthat the proposed memory framework achieves state-of-the-art performance in\nboth learning contexts."}
{"id": "2505.18102", "pdf": "https://arxiv.org/pdf/2505.18102", "abs": "https://arxiv.org/abs/2505.18102", "authors": ["Takashi Ishida", "Thanawat Lodkaew", "Ikko Yamane"], "title": "How Can I Publish My LLM Benchmark Without Giving the True Answers Away?", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ME"], "comment": null, "summary": "Publishing a large language model (LLM) benchmark on the Internet risks\ncontaminating future LLMs: the benchmark may be unintentionally (or\nintentionally) used to train or select a model. A common mitigation is to keep\nthe benchmark private and let participants submit their models or predictions\nto the organizers. However, this strategy will require trust in a single\norganization and still permits test-set overfitting through repeated queries.\nTo overcome this issue, we propose a way to publish benchmarks without\ncompletely disclosing the ground-truth answers to the questions, while still\nmaintaining the ability to openly evaluate LLMs. Our main idea is to inject\nrandomness to the answers by preparing several logically correct answers, and\nonly include one of them as the solution in the benchmark. This reduces the\nbest possible accuracy, i.e., Bayes accuracy, of the benchmark. Not only is\nthis helpful to keep us from disclosing the ground truth, but this approach\nalso offers a test for detecting data contamination. In principle, even fully\ncapable models should not surpass the Bayes accuracy. If a model surpasses this\nceiling despite this expectation, this is a strong signal of data\ncontamination. We present experimental evidence that our method can detect data\ncontamination accurately on a wide range of benchmarks, models, and training\nmethodologies."}
{"id": "2505.18113", "pdf": "https://arxiv.org/pdf/2505.18113", "abs": "https://arxiv.org/abs/2505.18113", "authors": ["Halyun Jeong", "Jack Xin", "Penghang Yin"], "title": "Beyond Discreteness: Finite-Sample Analysis of Straight-Through Estimator for Quantization", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Training quantized neural networks requires addressing the non-differentiable\nand discrete nature of the underlying optimization problem. To tackle this\nchallenge, the straight-through estimator (STE) has become the most widely\nadopted heuristic, allowing backpropagation through discrete operations by\nintroducing surrogate gradients. However, its theoretical properties remain\nlargely unexplored, with few existing works simplifying the analysis by\nassuming an infinite amount of training data. In contrast, this work presents\nthe first finite-sample analysis of STE in the context of neural network\nquantization. Our theoretical results highlight the critical role of sample\nsize in the success of STE, a key insight absent from existing studies.\nSpecifically, by analyzing the quantization-aware training of a two-layer\nneural network with binary weights and activations, we derive the sample\ncomplexity bound in terms of the data dimensionality that guarantees the\nconvergence of STE-based optimization to the global minimum. Moreover, in the\npresence of label noises, we uncover an intriguing recurrence property of\nSTE-gradient method, where the iterate repeatedly escape from and return to the\noptimal binary weights. Our analysis leverages tools from compressed sensing\nand dynamical systems theory."}
{"id": "2505.18116", "pdf": "https://arxiv.org/pdf/2505.18116", "abs": "https://arxiv.org/abs/2505.18116", "authors": ["Huayu Chen", "Kaiwen Zheng", "Qinsheng Zhang", "Ganqu Cui", "Yin Cui", "Haotian Ye", "Tsung-Yi Lin", "Ming-Yu Liu", "Jun Zhu", "Haoxiang Wang"], "title": "Bridging Supervised Learning and Reinforcement Learning in Math Reasoning", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Reinforcement Learning (RL) has played a central role in the recent surge of\nLLMs' math abilities by enabling self-improvement through binary verifier\nsignals. In contrast, Supervised Learning (SL) is rarely considered for such\nverification-driven training, largely due to its heavy reliance on reference\nanswers and inability to reflect on mistakes. In this work, we challenge the\nprevailing notion that self-improvement is exclusive to RL and propose\nNegative-aware Fine-Tuning (NFT) -- a supervised approach that enables LLMs to\nreflect on their failures and improve autonomously with no external teachers.\nIn online training, instead of throwing away self-generated negative answers,\nNFT constructs an implicit negative policy to model them. This implicit policy\nis parameterized with the same positive LLM we target to optimize on positive\ndata, enabling direct policy optimization on all LLMs' generations. We conduct\nexperiments on 7B and 32B models in math reasoning tasks. Results consistently\nshow that through the additional leverage of negative feedback, NFT\nsignificantly improves over SL baselines like Rejection sampling Fine-Tuning,\nmatching or even surpassing leading RL algorithms like GRPO and DAPO.\nFurthermore, we demonstrate that NFT and GRPO are actually equivalent in\nstrict-on-policy training, even though they originate from entirely different\ntheoretical foundations. Our experiments and theoretical findings bridge the\ngap between SL and RL methods in binary-feedback learning systems."}
{"id": "2505.18125", "pdf": "https://arxiv.org/pdf/2505.18125", "abs": "https://arxiv.org/abs/2505.18125", "authors": ["Alan Arazi", "Eilam Shapira", "Roi Reichart"], "title": "TabSTAR: A Foundation Tabular Model With Semantically Target-Aware Representations", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "While deep learning has achieved remarkable success across many domains, it\nhas historically underperformed on tabular learning tasks, which remain\ndominated by gradient boosting decision trees (GBDTs). However, recent\nadvancements are paving the way for Tabular Foundation Models, which can\nleverage real-world knowledge and generalize across diverse datasets,\nparticularly when the data contains free-text. Although incorporating language\nmodel capabilities into tabular tasks has been explored, most existing methods\nutilize static, target-agnostic textual representations, limiting their\neffectiveness. We introduce TabSTAR: a Foundation Tabular Model with\nSemantically Target-Aware Representations. TabSTAR is designed to enable\ntransfer learning on tabular data with textual features, with an architecture\nfree of dataset-specific parameters. It unfreezes a pretrained text encoder and\ntakes as input target tokens, which provide the model with the context needed\nto learn task-specific embeddings. TabSTAR achieves state-of-the-art\nperformance for both medium- and large-sized datasets across known benchmarks\nof classification tasks with text features, and its pretraining phase exhibits\nscaling laws in the number of datasets, offering a pathway for further\nperformance improvements."}
{"id": "2505.18126", "pdf": "https://arxiv.org/pdf/2505.18126", "abs": "https://arxiv.org/abs/2505.18126", "authors": ["Lorenz Wolf", "Robert Kirk", "Mirco Musolesi"], "title": "Reward Model Overoptimisation in Iterated RLHF", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "20 pages, 17 figures, 5 tables", "summary": "Reinforcement learning from human feedback (RLHF) is a widely used method for\naligning large language models with human preferences. However, RLHF often\nsuffers from reward model overoptimisation, in which models overfit to the\nreward function, resulting in non-generalisable policies that exploit the\nidiosyncrasies and peculiarities of the reward function. A common mitigation is\niterated RLHF, in which reward models are repeatedly retrained with updated\nhuman feedback and policies are re-optimised. Despite its increasing adoption,\nthe dynamics of overoptimisation in this setting remain poorly understood. In\nthis work, we present the first comprehensive study of overoptimisation in\niterated RLHF. We systematically analyse key design choices - how reward model\ntraining data is transferred across iterations, which reward function is used\nfor optimisation, and how policies are initialised. Using the controlled\nAlpacaFarm benchmark, we observe that overoptimisation tends to decrease over\nsuccessive iterations, as reward models increasingly approximate ground-truth\npreferences. However, performance gains diminish over time, and while\nreinitialising from the base policy is robust, it limits optimisation\nflexibility. Other initialisation strategies often fail to recover from early\noveroptimisation. These findings offer actionable insights for building more\nstable and generalisable RLHF pipelines."}
{"id": "2505.18131", "pdf": "https://arxiv.org/pdf/2505.18131", "abs": "https://arxiv.org/abs/2505.18131", "authors": ["Jonas A. Actor", "Graham Harper", "Ben Southworth", "Eric C. Cyr"], "title": "Leveraging KANs for Expedient Training of Multichannel MLPs via Preconditioning and Geometric Refinement", "categories": ["cs.LG", "cs.AI", "68T99", "I.2.6"], "comment": "20 pages, 3 figures, 3 tables", "summary": "Multilayer perceptrons (MLPs) are a workhorse machine learning architecture,\nused in a variety of modern deep learning frameworks. However, recently\nKolmogorov-Arnold Networks (KANs) have become increasingly popular due to their\nsuccess on a range of problems, particularly for scientific machine learning\ntasks. In this paper, we exploit the relationship between KANs and multichannel\nMLPs to gain structural insight into how to train MLPs faster. We demonstrate\nthe KAN basis (1) provides geometric localized support, and (2) acts as a\npreconditioned descent in the ReLU basis, overall resulting in expedited\ntraining and improved accuracy. Our results show the equivalence between\nfree-knot spline KAN architectures, and a class of MLPs that are refined\ngeometrically along the channel dimension of each weight tensor. We exploit\nthis structural equivalence to define a hierarchical refinement scheme that\ndramatically accelerates training of the multi-channel MLP architecture. We\nshow further accuracy improvements can be had by allowing the $1$D locations of\nthe spline knots to be trained simultaneously with the weights. These advances\nare demonstrated on a range of benchmark examples for regression and scientific\nmachine learning."}
{"id": "2505.18150", "pdf": "https://arxiv.org/pdf/2505.18150", "abs": "https://arxiv.org/abs/2505.18150", "authors": ["Nic Fishman", "Gokul Gowri", "Peng Yin", "Jonathan Gootenberg", "Omar Abudayyeh"], "title": "Generative Distribution Embeddings", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "comment": null, "summary": "Many real-world problems require reasoning across multiple scales, demanding\nmodels which operate not on single data points, but on entire distributions. We\nintroduce generative distribution embeddings (GDE), a framework that lifts\nautoencoders to the space of distributions. In GDEs, an encoder acts on sets of\nsamples, and the decoder is replaced by a generator which aims to match the\ninput distribution. This framework enables learning representations of\ndistributions by coupling conditional generative models with encoder networks\nwhich satisfy a criterion we call distributional invariance. We show that GDEs\nlearn predictive sufficient statistics embedded in the Wasserstein space, such\nthat latent GDE distances approximately recover the $W_2$ distance, and latent\ninterpolation approximately recovers optimal transport trajectories for\nGaussian and Gaussian mixture distributions. We systematically benchmark GDEs\nagainst existing approaches on synthetic datasets, demonstrating consistently\nstronger performance. We then apply GDEs to six key problems in computational\nbiology: learning representations of cell populations from lineage-tracing data\n(150K cells), predicting perturbation effects on single-cell transcriptomes (1M\ncells), predicting perturbation effects on cellular phenotypes (20M single-cell\nimages), modeling tissue-specific DNA methylation patterns (253M sequences),\ndesigning synthetic yeast promoters (34M sequences), and spatiotemporal\nmodeling of viral protein sequences (1M sequences)."}
{"id": "2411.17411", "pdf": "https://arxiv.org/pdf/2411.17411", "abs": "https://arxiv.org/abs/2411.17411", "authors": ["Takaaki Fujita"], "title": "Advancing Uncertain Combinatorics through Graphization, Hyperization, and Uncertainization: Fuzzy, Neutrosophic, Soft, Rough, and Beyond", "categories": ["cs.AI", "cs.DM", "cs.LG", "math.CO", "03B52"], "comment": "255 pages. 11 figures. Published as a book in 2024. Publisher: Biblio\n  Publishing. ISBN: 978-1-59973-812-3", "summary": "To better handle real-world uncertainty, concepts such as fuzzy sets,\nneutrosophic sets, rough sets, and soft sets have been introduced. For example,\nneutrosophic sets, which simultaneously represent truth, indeterminacy, and\nfalsehood, have proven to be valuable tools for modeling uncertainty in complex\nsystems. These set concepts are increasingly studied in graphized forms, and\ngeneralized graph concepts now encompass well-known structures such as\nhypergraphs and superhypergraphs. Furthermore, hyperconcepts and\nsuperhyperconcepts are being actively researched in areas beyond graph theory.\n  Combinatorics, uncertain sets (including fuzzy sets, neutrosophic sets, rough\nsets, soft sets, and plithogenic sets), uncertain graphs, and hyper and\nsuperhyper concepts are active areas of research with significant mathematical\nand practical implications. Recognizing their importance, this paper explores\nnew graph and set concepts, as well as hyper and superhyper concepts, as\ndetailed in the \"Results\" section of \"The Structure of the Paper.\"\nAdditionally, this work aims to consolidate recent findings, providing a\nsurvey-like resource to inform and engage readers.\n  For instance, we extend several graph concepts by introducing Neutrosophic\nOversets, Neutrosophic Undersets, Neutrosophic Offsets, and the Nonstandard\nReal Set. This paper defines a variety of concepts with the goal of inspiring\nnew ideas and serving as a valuable resource for researchers in their academic\npursuits."}
{"id": "2505.17133", "pdf": "https://arxiv.org/pdf/2505.17133", "abs": "https://arxiv.org/abs/2505.17133", "authors": ["Shuai Wang", "Song Jiang", "Yizhou Sun", "Judea Pearl", "Ang Li"], "title": "Learning Probabilities of Causation from Finite Population Data", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": "arXiv admin note: text overlap with arXiv:2502.08858", "summary": "Probabilities of causation play a crucial role in modern decision-making.\nThis paper addresses the challenge of predicting probabilities of causation for\nsubpopulations with \\textbf{insufficient} data using machine learning models.\nTian and Pearl first defined and derived tight bounds for three fundamental\nprobabilities of causation: the probability of necessity and sufficiency (PNS),\nthe probability of sufficiency (PS), and the probability of necessity (PN).\nHowever, estimating these probabilities requires both experimental and\nobservational distributions specific to each subpopulation, which are often\nunavailable or impractical to obtain with limited population-level data.\nTherefore, for most subgroups, the amount of data they have is not enough to\nguarantee the accuracy of their probabilities. Hence, to estimate these\nprobabilities for subpopulations with \\textbf{insufficient} data, we propose\nusing machine learning models that draw insights from subpopulations with\nsufficient data. Our evaluation of multiple machine learning models indicates\nthat, given the population-level data and an appropriate choice of machine\nlearning model and activation function, PNS can be effectively predicted.\nThrough simulation studies on multiple Structured Causal Models (SCMs), we show\nthat our multilayer perceptron (MLP) model with the Mish activation function\nachieves a mean absolute error (MAE) of approximately $0.02$ in predicting PNS\nfor $32,768$ subpopulations across most SCMs using data from only $2,000$\nsubpopulations with known PNS values."}
{"id": "2505.17204", "pdf": "https://arxiv.org/pdf/2505.17204", "abs": "https://arxiv.org/abs/2505.17204", "authors": ["Pilhwa Lee", "Jayshawn Cooper"], "title": "Liouville PDE-based sliced-Wasserstein flow for fair regression", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST", "stat.CO", "stat.TH"], "comment": "11 pages, 3 figures", "summary": "The sliced Wasserstein flow (SWF), a nonparametric and implicit generative\ngradient flow, is applied to fair regression. We have improved the SWF in a few\naspects. First, the stochastic diffusive term from the Fokker-Planck\nequation-based Monte Carlo is transformed to Liouville partial differential\nequation (PDE)-based transport with density estimation, however, without the\ndiffusive term. Now, the computation of the Wasserstein barycenter is\napproximated by the SWF barycenter with the prescription of Kantorovich\npotentials for the induced gradient flow to generate its samples. These two\nefforts improve the convergence in training and testing SWF and SWF barycenters\nwith reduced variance. Applying the generative SWF barycenter for fair\nregression demonstrates competent profiles in the accuracy-fairness Pareto\ncurves."}
{"id": "2505.17249", "pdf": "https://arxiv.org/pdf/2505.17249", "abs": "https://arxiv.org/abs/2505.17249", "authors": ["Yuran Sun", "Susu Xu", "Chenguang Wang", "Xilei Zhao"], "title": "Where You Go is Who You Are: Behavioral Theory-Guided LLMs for Inverse Reinforcement Learning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Big trajectory data hold great promise for human mobility analysis, but their\nutility is often constrained by the absence of critical traveler attributes,\nparticularly sociodemographic information. While prior studies have explored\npredicting such attributes from mobility patterns, they often overlooked\nunderlying cognitive mechanisms and exhibited low predictive accuracy. This\nstudy introduces SILIC, short for Sociodemographic Inference with LLM-guided\nInverse Reinforcement Learning (IRL) and Cognitive Chain Reasoning (CCR), a\ntheoretically grounded framework that leverages LLMs to infer sociodemographic\nattributes from observed mobility patterns by capturing latent behavioral\nintentions and reasoning through psychological constructs. Particularly, our\napproach explicitly follows the Theory of Planned Behavior (TPB), a\nfoundational behavioral framework in transportation research, to model\nindividuals' latent cognitive processes underlying travel decision-making. The\nLLMs further provide heuristic guidance to improve IRL reward function\ninitialization and update by addressing its ill-posedness and optimization\nchallenges arising from the vast and unstructured reward space. Evaluated in\nthe 2017 Puget Sound Regional Council Household Travel Survey, our method\nsubstantially outperforms state-of-the-art baselines and shows great promise\nfor enriching big trajectory data to support more behaviorally grounded\napplications in transportation planning and beyond."}
{"id": "2505.17283", "pdf": "https://arxiv.org/pdf/2505.17283", "abs": "https://arxiv.org/abs/2505.17283", "authors": ["Prateek Jaiswal", "Esmaeil Keyvanshokooh", "Junyu Cao"], "title": "Deconfounded Warm-Start Thompson Sampling with Applications to Precision Medicine", "categories": ["stat.ML", "cs.LG", "math.OC", "stat.AP"], "comment": null, "summary": "Randomized clinical trials often require large patient cohorts before drawing\ndefinitive conclusions, yet abundant observational data from parallel studies\nremains underutilized due to confounding and hidden biases. To bridge this gap,\nwe propose Deconfounded Warm-Start Thompson Sampling (DWTS), a practical\napproach that leverages a Doubly Debiased LASSO (DDL) procedure to identify a\nsparse set of reliable measured covariates and combines them with key hidden\ncovariates to form a reduced context. By initializing Thompson Sampling (LinTS)\npriors with DDL-estimated means and variances on these measured features --\nwhile keeping uninformative priors on hidden features -- DWTS effectively\nharnesses confounded observational data to kick-start adaptive clinical trials.\nEvaluated on both a purely synthetic environment and a virtual environment\ncreated using real cardiovascular risk dataset, DWTS consistently achieves\nlower cumulative regret than standard LinTS, showing how offline causal\ninsights from observational data can improve trial efficiency and support more\npersonalized treatment decisions."}
{"id": "2505.17288", "pdf": "https://arxiv.org/pdf/2505.17288", "abs": "https://arxiv.org/abs/2505.17288", "authors": ["Seamus Somerstep", "Vinod Raman", "Unique Subedi", "Yuekai Sun"], "title": "Learning to Choose or Choosing to Learn: Best-of-N vs. Supervised Fine-Tuning for Bit String Generation", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Using the bit string generation problem as a case study, we theoretically\ncompare two standard methods for adapting large language models to new tasks.\nThe first, referred to as supervised fine-tuning, involves training a new next\ntoken predictor on good generations. The second method, Best-of-N, trains a\nreward model to select good responses from a collection generated by an\nunaltered base model. If the learning setting is realizable, we find that\nsupervised fine-tuning outperforms BoN through a better dependence on the\nresponse length in its rate of convergence. If realizability fails, then\ndepending on the failure mode, BoN can enjoy a better rate of convergence in\neither n or a rate of convergence with better dependence on the response\nlength."}
{"id": "2505.17291", "pdf": "https://arxiv.org/pdf/2505.17291", "abs": "https://arxiv.org/abs/2505.17291", "authors": ["Linus Bleistein", "Aur√©lien Bellet", "Julie Josse"], "title": "Optimal Transport with Heterogeneously Missing Data", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "We consider the problem of solving the optimal transport problem between two\nempirical distributions with missing values. Our main assumption is that the\ndata is missing completely at random (MCAR), but we allow for heterogeneous\nmissingness probabilities across features and across the two distributions. As\na first contribution, we show that the Wasserstein distance between empirical\nGaussian distributions and linear Monge maps between arbitrary distributions\ncan be debiased without significantly affecting the sample complexity.\nSecondly, we show that entropic regularized optimal transport can be estimated\nefficiently and consistently using iterative singular value thresholding\n(ISVT). We propose a validation set-free hyperparameter selection strategy for\nISVT that leverages our estimator of the Bures-Wasserstein distance, which\ncould be of independent interest in general matrix completion problems.\nFinally, we validate our findings on a wide range of numerical applications."}
{"id": "2505.17300", "pdf": "https://arxiv.org/pdf/2505.17300", "abs": "https://arxiv.org/abs/2505.17300", "authors": ["Selina Carter", "Arun K Kuchibhotla"], "title": "Statistical Inference for Online Algorithms", "categories": ["stat.ML", "cs.LG", "stat.CO", "stat.ME"], "comment": "Although SGD is the most commonly mentioned method in machine\n  learning, our simulations show that the performance of SGD is highly\n  sensitive to the choice of tuning parameters of the algorithm. We could not\n  find a simple remedy that improves performance and also makes the asymptotic\n  properties manageable. We hope that our article acts as a word of caution to\n  anyone using online algorithms blindly", "summary": "Construction of confidence intervals and hypothesis tests for functionals\nbased on asymptotically normal estimators is a classical topic in statistical\ninference. The simplest and in many cases optimal inference procedure is the\nWald interval or the likelihood ratio test, both of which require an estimator\nand an estimate of the asymptotic variance of the estimator. Estimators\nobtained from online/sequential algorithms forces one to consider the\ncomputational aspects of the inference problem, i.e., one cannot access all of\nthe data as many times as needed. Several works on this topic explored the\nonline estimation of asymptotic variance. In this article, we propose\ncomputationally efficient, rate-optimal, and asymptotically valid confidence\nregions based on the output of online algorithms {\\em without} estimating the\nasymptotic variance. As a special case, this implies inference from any\nalgorithm that yields an asymptotically normal estimator. We focus our efforts\non stochastic gradient descent with Polyak averaging to understand the\npractical performance of the proposed method."}
{"id": "2505.17308", "pdf": "https://arxiv.org/pdf/2505.17308", "abs": "https://arxiv.org/abs/2505.17308", "authors": ["Philipp Pilar", "Markus Heinonen", "Niklas Wahlstr√∂m"], "title": "Repulsive Ensembles for Bayesian Inference in Physics-informed Neural Networks", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Physics-informed neural networks (PINNs) have proven an effective tool for\nsolving differential equations, in particular when considering non-standard or\nill-posed settings. When inferring solutions and parameters of the differential\nequation from data, uncertainty estimates are preferable to point estimates, as\nthey give an idea about the accuracy of the solution. In this work, we consider\nthe inverse problem and employ repulsive ensembles of PINNs (RE-PINN) for\nobtaining such estimates. The repulsion is implemented by adding a particular\nrepulsive term to the loss function, which has the property that the ensemble\npredictions correspond to the true Bayesian posterior in the limit of infinite\nensemble members. Where possible, we compare the ensemble predictions to Monte\nCarlo baselines. Whereas the standard ensemble tends to collapse to\nmaximum-a-posteriori solutions, the repulsive ensemble produces significantly\nmore accurate uncertainty estimates and exhibits higher sample diversity."}
{"id": "2505.17312", "pdf": "https://arxiv.org/pdf/2505.17312", "abs": "https://arxiv.org/abs/2505.17312", "authors": ["Xiangqi Wang", "Yue Huang", "Yanbo Wang", "Xiaonan Luo", "Kehan Guo", "Yujun Zhou", "Xiangliang Zhang"], "title": "AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "LLMs often need effective configurations, like temperature and reasoning\nsteps, to handle tasks requiring sophisticated reasoning and problem-solving,\nranging from joke generation to mathematical reasoning. Existing prompting\napproaches usually adopt general-purpose, fixed configurations that work 'well\nenough' across tasks but seldom achieve task-specific optimality. To address\nthis gap, we introduce AdaReasoner, an LLM-agnostic plugin designed for any LLM\nto automate adaptive reasoning configurations for tasks requiring different\ntypes of thinking. AdaReasoner is trained using a reinforcement learning (RL)\nframework, combining a factorized action space with a targeted exploration\nstrategy, along with a pretrained reward model to optimize the policy model for\nreasoning configurations with only a few-shot guide. AdaReasoner is backed by\ntheoretical guarantees and experiments of fast convergence and a sublinear\npolicy gap. Across six different LLMs and a variety of reasoning tasks, it\nconsistently outperforms standard baselines, preserves out-of-distribution\nrobustness, and yield gains on knowledge-intensive tasks through tailored\nprompts."}
{"id": "2505.17315", "pdf": "https://arxiv.org/pdf/2505.17315", "abs": "https://arxiv.org/abs/2505.17315", "authors": ["Wang Yang", "Zirui Liu", "Hongye Jin", "Qingyu Yin", "Vipin Chaudhary", "Xiaotian Han"], "title": "Longer Context, Deeper Thinking: Uncovering the Role of Long-Context Ability in Reasoning", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Recent language models exhibit strong reasoning capabilities, yet the\ninfluence of long-context capacity on reasoning remains underexplored. In this\nwork, we hypothesize that current limitations in reasoning stem, in part, from\ninsufficient long-context capacity, motivated by empirical observations such as\n(1) higher context window length often leads to stronger reasoning performance,\nand (2) failed reasoning cases resemble failed long-context cases. To test this\nhypothesis, we examine whether enhancing a model's long-context ability before\nSupervised Fine-Tuning (SFT) leads to improved reasoning performance.\nSpecifically, we compared models with identical architectures and fine-tuning\ndata but varying levels of long-context capacity. Our results reveal a\nconsistent trend: models with stronger long-context capacity achieve\nsignificantly higher accuracy on reasoning benchmarks after SFT. Notably, these\ngains persist even on tasks with short input lengths, indicating that\nlong-context training offers generalizable benefits for reasoning performance.\nThese findings suggest that long-context modeling is not just essential for\nprocessing lengthy inputs, but also serves as a critical foundation for\nreasoning. We advocate for treating long-context capacity as a first-class\nobjective in the design of future language models."}
{"id": "2505.17323", "pdf": "https://arxiv.org/pdf/2505.17323", "abs": "https://arxiv.org/abs/2505.17323", "authors": ["Ruaridh Mon-Williams", "Max Taylor-Davies", "Elizabeth Mieczkowski", "Natalia Velez", "Neil R. Bramley", "Yanwei Wang", "Thomas L. Griffiths", "Christopher G. Lucas"], "title": "Partner Modelling Emerges in Recurrent Agents (But Only When It Matters)", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Humans are remarkably adept at collaboration, able to infer the strengths and\nweaknesses of new partners in order to work successfully towards shared goals.\nTo build AI systems with this capability, we must first understand its building\nblocks: does such flexibility require explicit, dedicated mechanisms for\nmodelling others -- or can it emerge spontaneously from the pressures of\nopen-ended cooperative interaction? To investigate this question, we train\nsimple model-free RNN agents to collaborate with a population of diverse\npartners. Using the `Overcooked-AI' environment, we collect data from thousands\nof collaborative teams, and analyse agents' internal hidden states. Despite a\nlack of additional architectural features, inductive biases, or auxiliary\nobjectives, the agents nevertheless develop structured internal representations\nof their partners' task abilities, enabling rapid adaptation and generalisation\nto novel collaborators. We investigated these internal models through probing\ntechniques, and large-scale behavioural analysis. Notably, we find that\nstructured partner modelling emerges when agents can influence partner\nbehaviour by controlling task allocation. Our results show that partner\nmodelling can arise spontaneously in model-free agents -- but only under\nenvironmental conditions that impose the right kind of social pressure."}
{"id": "2505.17492", "pdf": "https://arxiv.org/pdf/2505.17492", "abs": "https://arxiv.org/abs/2505.17492", "authors": ["Dezheng Bao", "Yueci Yang", "Xin Chen", "Zhengxuan Jiang", "Zeguo Fei", "Daoze Zhang", "Xuanwen Huang", "Junru Chen", "Chutian Yu", "Xiang Yuan", "Yang Yang"], "title": "PD$^3$: A Project Duplication Detection Framework via Adapted Multi-Agent Debate", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "17 pages, 9 figures", "summary": "Project duplication detection is critical for project quality assessment, as\nit improves resource utilization efficiency by preventing investing in newly\nproposed project that have already been studied. It requires the ability to\nunderstand high-level semantics and generate constructive and valuable\nfeedback. Existing detection methods rely on basic word- or sentence-level\ncomparison or solely apply large language models, lacking valuable insights for\nexperts and in-depth comprehension of project content and review criteria. To\ntackle this issue, we propose PD$^3$, a Project Duplication Detection framework\nvia adapted multi-agent Debate. Inspired by real-world expert debates, it\nemploys a fair competition format to guide multi-agent debate to retrieve\nrelevant projects. For feedback, it incorporates both qualitative and\nquantitative analysis to improve its practicality. Over 800 real-world power\nproject data spanning more than 20 specialized fields are used to evaluate the\nframework, demonstrating that our method outperforms existing approaches by\n7.43% and 8.00% in two downstream tasks. Furthermore, we establish an online\nplatform, Review Dingdang, to assist power experts, saving 5.73 million USD in\ninitial detection on more than 100 newly proposed projects."}
{"id": "2505.17506", "pdf": "https://arxiv.org/pdf/2505.17506", "abs": "https://arxiv.org/abs/2505.17506", "authors": ["Kihyuk Hong", "Ambuj Tewari"], "title": "Offline Constrained Reinforcement Learning under Partial Data Coverage", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study offline constrained reinforcement learning (RL) with general\nfunction approximation. We aim to learn a policy from a pre-collected dataset\nthat maximizes the expected discounted cumulative reward for a primary reward\nsignal while ensuring that expected discounted returns for multiple auxiliary\nreward signals are above predefined thresholds. Existing algorithms either\nrequire fully exploratory data, are computationally inefficient, or depend on\nan additional auxiliary function classes to obtain an $\\epsilon$-optimal policy\nwith sample complexity $O(\\epsilon^{-2})$. In this paper, we propose an\noracle-efficient primal-dual algorithm based on a linear programming (LP)\nformulation, achieving $O(\\epsilon^{-2})$ sample complexity under partial data\ncoverage. By introducing a realizability assumption, our approach ensures that\nall saddle points of the Lagrangian are optimal, removing the need for\nregularization that complicated prior analyses. Through Lagrangian\ndecomposition, our method extracts policies without requiring knowledge of the\ndata-generating distribution, enhancing practical applicability."}
{"id": "2505.17525", "pdf": "https://arxiv.org/pdf/2505.17525", "abs": "https://arxiv.org/abs/2505.17525", "authors": ["Juliett Su√°rez Ferreira", "Marija Slavkovik", "Jorge Casillas"], "title": "Transparency and Proportionality in Post-Processing Algorithmic Bias Correction", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Algorithmic decision-making systems sometimes produce errors or skewed\npredictions toward a particular group, leading to unfair results. Debiasing\npractices, applied at different stages of the development of such systems,\noccasionally introduce new forms of unfairness or exacerbate existing\ninequalities. We focus on post-processing techniques that modify algorithmic\npredictions to achieve fairness in classification tasks, examining the\nunintended consequences of these interventions. To address this challenge, we\ndevelop a set of measures that quantify the disparity in the flips applied to\nthe solution in the post-processing stage. The proposed measures will help\npractitioners: (1) assess the proportionality of the debiasing strategy used,\n(2) have transparency to explain the effects of the strategy in each group, and\n(3) based on those results, analyze the possibility of the use of some other\napproaches for bias mitigation or to solve the problem. We introduce a\nmethodology for applying the proposed metrics during the post-processing stage\nand illustrate its practical application through an example. This example\ndemonstrates how analyzing the proportionality of the debiasing strategy\ncomplements traditional fairness metrics, providing a deeper perspective to\nensure fairer outcomes across all groups."}
{"id": "2505.17705", "pdf": "https://arxiv.org/pdf/2505.17705", "abs": "https://arxiv.org/abs/2505.17705", "authors": ["Runze Li", "Siyu Wu", "Jun Wang", "Wei Zhang"], "title": "CIKT: A Collaborative and Iterative Knowledge Tracing Framework with Large Language Models", "categories": ["cs.AI", "cs.LG", "68T50", "I.2.7"], "comment": null, "summary": "Knowledge Tracing (KT) aims to model a student's learning state over time and\npredict their future performance. However, traditional KT methods often face\nchallenges in explainability, scalability, and effective modeling of complex\nknowledge dependencies. While Large Language Models (LLMs) present new avenues\nfor KT, their direct application often struggles with generating structured,\nexplainable student representations and lacks mechanisms for continuous,\ntask-specific refinement. To address these gaps, we propose Collaborative\nIterative Knowledge Tracing (CIKT), a framework that harnesses LLMs to enhance\nboth prediction accuracy and explainability. CIKT employs a dual-component\narchitecture: an Analyst generates dynamic, explainable user profiles from\nstudent historical responses, and a Predictor utilizes these profiles to\nforecast future performance. The core of CIKT is a synergistic optimization\nloop. In this loop, the Analyst is iteratively refined based on the predictive\naccuracy of the Predictor, which conditions on the generated profiles, and the\nPredictor is subsequently retrained using these enhanced profiles. Evaluated on\nmultiple educational datasets, CIKT demonstrates significant improvements in\nprediction accuracy, offers enhanced explainability through its dynamically\nupdated user profiles, and exhibits improved scalability. Our work presents a\nrobust and explainable solution for advancing knowledge tracing systems,\neffectively bridging the gap between predictive performance and model\ntransparency."}
{"id": "2505.17717", "pdf": "https://arxiv.org/pdf/2505.17717", "abs": "https://arxiv.org/abs/2505.17717", "authors": ["Akira Tanimoto"], "title": "A Distributionally-Robust Framework for Nuisance in Causal Effect Estimation", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Causal inference requires evaluating models on balanced distributions between\ntreatment and control groups, while training data often exhibits imbalance due\nto historical decision-making policies. Most conventional statistical methods\naddress this distribution shift through inverse probability weighting (IPW),\nwhich requires estimating propensity scores as an intermediate step. These\nmethods face two key challenges: inaccurate propensity estimation and\ninstability from extreme weights. We decompose the generalization error to\nisolate these issues--propensity ambiguity and statistical instability--and\naddress them through an adversarial loss function. Our approach combines\ndistributionally robust optimization for handling propensity uncertainty with\nweight regularization based on weighted Rademacher complexity. Experiments on\nsynthetic and real-world datasets demonstrate consistent improvements over\nexisting methods."}
{"id": "2505.17789", "pdf": "https://arxiv.org/pdf/2505.17789", "abs": "https://arxiv.org/abs/2505.17789", "authors": ["Florian Kalinke", "Shakeel Gavioli-Akilagun"], "title": "Optimal Online Change Detection via Random Fourier Features", "categories": ["stat.ML", "cs.LG", "68W27 (Primary) 62G10, 46E22 (Secondary)", "G.3; I.2.6"], "comment": null, "summary": "This article studies the problem of online non-parametric change point\ndetection in multivariate data streams. We approach the problem through the\nlens of kernel-based two-sample testing and introduce a sequential testing\nprocedure based on random Fourier features, running with logarithmic time\ncomplexity per observation and with overall logarithmic space complexity. The\nalgorithm has two advantages compared to the state of the art. First, our\napproach is genuinely online, and no access to training data known to be from\nthe pre-change distribution is necessary. Second, the algorithm does not\nrequire the user to specify a window parameter over which local tests are to be\ncalculated. We prove strong theoretical guarantees on the algorithm's\nperformance, including information-theoretic bounds demonstrating that the\ndetection delay is optimal in the minimax sense. Numerical studies on real and\nsynthetic data show that our algorithm is competitive with respect to the state\nof the art."}
{"id": "2505.17819", "pdf": "https://arxiv.org/pdf/2505.17819", "abs": "https://arxiv.org/abs/2505.17819", "authors": ["J√ºrgen D√∂lz", "Jolanda Weygandt"], "title": "Quantifying uncertainty in spectral clusterings: expectations for perturbed and incomplete data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Spectral clustering is a popular unsupervised learning technique which is\nable to partition unlabelled data into disjoint clusters of distinct shapes.\nHowever, the data under consideration are often experimental data, implying\nthat the data is subject to measurement errors and measurements may even be\nlost or invalid. These uncertainties in the corrupted input data induce\ncorresponding uncertainties in the resulting clusters, and the clusterings thus\nbecome unreliable.\n  Modelling the uncertainties as random processes, we discuss a mathematical\nframework based on random set theory for the computational Monte Carlo\napproximation of statistically expected clusterings in case of corrupted, i.e.,\nperturbed, incomplete, and possibly even additional, data. We propose several\ncomputationally accessible quantities of interest and analyze their consistency\nin the infinite data point and infinite Monte Carlo sample limit. Numerical\nexperiments are provided to illustrate and compare the proposed quantities."}
{"id": "2505.17836", "pdf": "https://arxiv.org/pdf/2505.17836", "abs": "https://arxiv.org/abs/2505.17836", "authors": ["Anna Van Elst", "Igor Colin", "Stephan Cl√©men√ßon"], "title": "Robust Distributed Estimation: Extending Gossip Algorithms to Ranking and Trimmed Means", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": null, "summary": "This paper addresses the problem of robust estimation in gossip algorithms\nover arbitrary communication graphs. Gossip algorithms are fully decentralized,\nrelying only on local neighbor-to-neighbor communication, making them\nwell-suited for situations where communication is constrained. A fundamental\nchallenge in existing mean-based gossip algorithms is their vulnerability to\nmalicious or corrupted nodes. In this paper, we show that an outlier-robust\nmean can be computed by globally estimating a robust statistic. More\nspecifically, we propose a novel gossip algorithm for rank estimation, referred\nto as \\textsc{GoRank}, and leverage it to design a gossip procedure dedicated\nto trimmed mean estimation, coined \\textsc{GoTrim}. In addition to a detailed\ndescription of the proposed methods, a key contribution of our work is a\nprecise convergence analysis: we establish an $\\mathcal{O}(1/t)$ rate for rank\nestimation and an $\\mathcal{O}(\\log(t)/t)$ rate for trimmed mean estimation,\nwhere by $t$ is meant the number of iterations. Moreover, we provide a\nbreakdown point analysis of \\textsc{GoTrim}. We empirically validate our\ntheoretical results through experiments on diverse network topologies, data\ndistributions and contamination schemes."}
{"id": "2505.17838", "pdf": "https://arxiv.org/pdf/2505.17838", "abs": "https://arxiv.org/abs/2505.17838", "authors": ["Abhiti Mishra", "Yash Patel", "Ambuj Tewari"], "title": "Continuum Transformers Perform In-Context Learning by Operator Gradient Descent", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Transformers robustly exhibit the ability to perform in-context learning,\nwhereby their predictive accuracy on a task can increase not by parameter\nupdates but merely with the placement of training samples in their context\nwindows. Recent works have shown that transformers achieve this by implementing\ngradient descent in their forward passes. Such results, however, are restricted\nto standard transformer architectures, which handle finite-dimensional inputs.\nIn the space of PDE surrogate modeling, a generalization of transformers to\nhandle infinite-dimensional function inputs, known as \"continuum transformers,\"\nhas been proposed and similarly observed to exhibit in-context learning.\nDespite impressive empirical performance, such in-context learning has yet to\nbe theoretically characterized. We herein demonstrate that continuum\ntransformers perform in-context operator learning by performing gradient\ndescent in an operator RKHS. We demonstrate this using novel proof strategies\nthat leverage a generalized representer theorem for Hilbert spaces and gradient\nflows over the space of functionals of a Hilbert space. We additionally show\nthe operator learned in context is the Bayes Optimal Predictor in the infinite\ndepth limit of the transformer. We then provide empirical validations of this\noptimality result and demonstrate that the parameters under which such gradient\ndescent is performed are recovered through the continuum transformer training."}
{"id": "2505.17895", "pdf": "https://arxiv.org/pdf/2505.17895", "abs": "https://arxiv.org/abs/2505.17895", "authors": ["Dan A. Calian", "Gregory Farquhar", "Iurii Kemaev", "Luisa M. Zintgraf", "Matteo Hessel", "Jeremy Shar", "Junhyuk Oh", "Andr√°s Gy√∂rgy", "Tom Schaul", "Jeffrey Dean", "Hado van Hasselt", "David Silver"], "title": "DataRater: Meta-Learned Dataset Curation", "categories": ["stat.ML", "cs.AI", "cs.LG", "I.2.6"], "comment": null, "summary": "The quality of foundation models depends heavily on their training data.\nConsequently, great efforts have been put into dataset curation. Yet most\napproaches rely on manual tuning of coarse-grained mixtures of large buckets of\ndata, or filtering by hand-crafted heuristics. An approach that is ultimately\nmore scalable (let alone more satisfying) is to \\emph{learn} which data is\nactually valuable for training. This type of meta-learning could allow more\nsophisticated, fine-grained, and effective curation. Our proposed\n\\emph{DataRater} is an instance of this idea. It estimates the value of\ntraining on any particular data point. This is done by meta-learning using\n`meta-gradients', with the objective of improving training efficiency on held\nout data. In extensive experiments across a range of model scales and datasets,\nwe find that using our DataRater to filter data is highly effective, resulting\nin significantly improved compute efficiency."}
{"id": "2505.17907", "pdf": "https://arxiv.org/pdf/2505.17907", "abs": "https://arxiv.org/abs/2505.17907", "authors": ["Ka Long Keith Ho", "Yoshinari Takeishi", "Junichi Takeuchi"], "title": "Function Forms of Simple ReLU Networks with Random Hidden Weights", "categories": ["stat.ML", "cs.LG"], "comment": "21 pages, 1 figure, 1 table", "summary": "We investigate the function space dynamics of a two-layer ReLU neural network\nin the infinite-width limit, highlighting the Fisher information matrix (FIM)'s\nrole in steering learning. Extending seminal works on approximate\neigendecomposition of the FIM, we derive the asymptotic behavior of basis\nfunctions ($f_v(x) = X^{\\top} v $) for four groups of approximate eigenvectors,\nshowing their convergence to distinct function forms. These functions,\nprioritized by gradient descent, exhibit FIM-induced inner products that\napproximate orthogonality in the function space, forging a novel connection\nbetween parameter and function spaces. Simulations validate the accuracy of\nthese theoretical approximations, confirming their practical relevance. By\nrefining the function space inner product's role, we advance the theoretical\nframework for ReLU networks, illuminating their optimization and expressivity.\nOverall, this work offers a robust foundation for understanding wide neural\nnetworks and enhances insights into scalable deep learning architectures,\npaving the way for improved design and analysis of neural networks."}
{"id": "2505.17917", "pdf": "https://arxiv.org/pdf/2505.17917", "abs": "https://arxiv.org/abs/2505.17917", "authors": ["Xingyu Li", "Qing Liu", "Tony Jiang", "Hong Amy Xia", "Brian P. Hobbs", "Peng Wei"], "title": "M-learner:A Flexible And Powerful Framework To Study Heterogeneous Treatment Effect In Mediation Model", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "We propose a novel method, termed the M-learner, for estimating heterogeneous\nindirect and total treatment effects and identifying relevant subgroups within\na mediation framework. The procedure comprises four key steps. First, we\ncompute individual-level conditional average indirect/total treatment effect\nSecond, we construct a distance matrix based on pairwise differences. Third, we\napply tSNE to project this matrix into a low-dimensional Euclidean space,\nfollowed by K-means clustering to identify subgroup structures. Finally, we\ncalibrate and refine the clusters using a threshold-based procedure to\ndetermine the optimal configuration. To the best of our knowledge, this is the\nfirst approach specifically designed to capture treatment effect heterogeneity\nin the presence of mediation. Experimental results validate the robustness and\neffectiveness of the proposed framework. Application to the real-world Jobs II\ndataset highlights the broad adaptability and potential applicability of our\nmethod.Code is available at https: //anonymous.4open.science/r/M-learner-C4BB."}
{"id": "2505.17958", "pdf": "https://arxiv.org/pdf/2505.17958", "abs": "https://arxiv.org/abs/2505.17958", "authors": ["Vittorio Erba", "Emanuele Troiani", "Lenka Zdeborov√°", "Florent Krzakala"], "title": "The Nuclear Route: Sharp Asymptotics of ERM in Overparameterized Quadratic Networks", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "We study the high-dimensional asymptotics of empirical risk minimization\n(ERM) in over-parametrized two-layer neural networks with quadratic activations\ntrained on synthetic data. We derive sharp asymptotics for both training and\ntest errors by mapping the $\\ell_2$-regularized learning problem to a convex\nmatrix sensing task with nuclear norm penalization. This reveals that capacity\ncontrol in such networks emerges from a low-rank structure in the learned\nfeature maps. Our results characterize the global minima of the loss and yield\nprecise generalization thresholds, showing how the width of the target function\ngoverns learnability. This analysis bridges and extends ideas from spin-glass\nmethods, matrix factorization, and convex optimization and emphasizes the deep\nlink between low-rank matrix sensing and learning in quadratic neural networks."}
{"id": "2505.18000", "pdf": "https://arxiv.org/pdf/2505.18000", "abs": "https://arxiv.org/abs/2505.18000", "authors": ["Valentin Kilian", "Stefano Cortinovis", "Fran√ßois Caron"], "title": "Anytime-valid, Bayes-assisted,Prediction-Powered Inference", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Given a large pool of unlabelled data and a smaller amount of labels,\nprediction-powered inference (PPI) leverages machine learning predictions to\nincrease the statistical efficiency of standard confidence interval procedures\nbased solely on labelled data, while preserving their fixed-time validity.\n  In this paper, we extend the PPI framework to the sequential setting, where\nlabelled and unlabelled datasets grow over time.\n  Exploiting Ville's inequality and the method of mixtures, we propose\nprediction-powered confidence sequence procedures that are valid uniformly over\ntime and naturally accommodate prior knowledge on the quality of the\npredictions to further boost efficiency.\n  We carefully illustrate the design choices behind our method and demonstrate\nits effectiveness in real and synthetic examples."}
{"id": "2505.18030", "pdf": "https://arxiv.org/pdf/2505.18030", "abs": "https://arxiv.org/abs/2505.18030", "authors": ["Hazhar Rahmani", "Jie Fu"], "title": "Automata Learning of Preferences over Temporal Logic Formulas from Pairwise Comparisons", "categories": ["cs.AI", "cs.FL", "cs.LG", "cs.SY", "eess.SY"], "comment": "16 pages, 11 figures, technical report, submission under review", "summary": "Many preference elicitation algorithms consider preference over propositional\nlogic formulas or items with different attributes. In sequential decision\nmaking, a user's preference can be a preorder over possible outcomes, each of\nwhich is a temporal sequence of events. This paper considers a class of\npreference inference problems where the user's unknown preference is\nrepresented by a preorder over regular languages (sets of temporal sequences),\nreferred to as temporal goals. Given a finite set of pairwise comparisons\nbetween finite words, the objective is to learn both the set of temporal goals\nand the preorder over these goals. We first show that a preference relation\nover temporal goals can be modeled by a Preference Deterministic Finite\nAutomaton (PDFA), which is a deterministic finite automaton augmented with a\npreorder over acceptance conditions. The problem of preference inference\nreduces to learning the PDFA. This problem is shown to be computationally\nchallenging, with the problem of determining whether there exists a PDFA of\nsize smaller than a given integer $k$, consistent with the sample, being\nNP-Complete. We formalize the properties of characteristic samples and develop\nan algorithm that guarantees to learn, given a characteristic sample, the\nminimal PDFA equivalent to the true PDFA from which the sample is drawn. We\npresent the method through a running example and provide detailed analysis\nusing a robotic motion planning problem."}
{"id": "2505.18077", "pdf": "https://arxiv.org/pdf/2505.18077", "abs": "https://arxiv.org/abs/2505.18077", "authors": ["Daniel F. Villarraga", "Ricardo A. Daziano"], "title": "Bayesian Deep Learning for Discrete Choice", "categories": ["stat.ML", "cs.LG", "econ.EM", "stat.AP"], "comment": null, "summary": "Discrete choice models (DCMs) are used to analyze individual decision-making\nin contexts such as transportation choices, political elections, and consumer\npreferences. DCMs play a central role in applied econometrics by enabling\ninference on key economic variables, such as marginal rates of substitution,\nrather than focusing solely on predicting choices on new unlabeled data.\nHowever, while traditional DCMs offer high interpretability and support for\npoint and interval estimation of economic quantities, these models often\nunderperform in predictive tasks compared to deep learning (DL) models. Despite\ntheir predictive advantages, DL models remain largely underutilized in discrete\nchoice due to concerns about their lack of interpretability, unstable parameter\nestimates, and the absence of established methods for uncertainty\nquantification. Here, we introduce a deep learning model architecture\nspecifically designed to integrate with approximate Bayesian inference methods,\nsuch as Stochastic Gradient Langevin Dynamics (SGLD). Our proposed model\ncollapses to behaviorally informed hypotheses when data is limited, mitigating\noverfitting and instability in underspecified settings while retaining the\nflexibility to capture complex nonlinear relationships when sufficient data is\navailable. We demonstrate our approach using SGLD through a Monte Carlo\nsimulation study, evaluating both predictive metrics--such as out-of-sample\nbalanced accuracy--and inferential metrics--such as empirical coverage for\nmarginal rates of substitution interval estimates. Additionally, we present\nresults from two empirical case studies: one using revealed mode choice data in\nNYC, and the other based on the widely used Swiss train choice stated\npreference data."}
{"id": "2505.18086", "pdf": "https://arxiv.org/pdf/2505.18086", "abs": "https://arxiv.org/abs/2505.18086", "authors": ["Muzhi Dai", "Shixuan Liu", "Qingyi Si"], "title": "Stable Reinforcement Learning for Efficient Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "The success of Deepseek-R1 has drawn the LLM community's attention to\nreinforcement learning (RL) methods like GRPO. However, such rule-based 0/1\noutcome reward methods lack the capability to regulate the intermediate\nreasoning processes during chain-of-thought (CoT) generation, leading to severe\noverthinking phenomena. In response, recent studies have designed reward\nfunctions to reinforce models' behaviors in producing shorter yet correct\ncompletions. Nevertheless, we observe that these length-penalty reward\nfunctions exacerbate RL training instability: as the completion length\ndecreases, model accuracy abruptly collapses, often occurring early in\ntraining. To address this issue, we propose a simple yet effective solution\nGRPO-$\\lambda$, an efficient and stabilized variant of GRPO, which dynamically\nadjusts the reward strategy by monitoring the correctness ratio among\ncompletions within each query-sampled group. A low correctness ratio indicates\nthe need to avoid length penalty that compromises CoT quality, triggering a\nswitch to length-agnostic 0/1 rewards that prioritize reasoning capability. A\nhigh ratio maintains length penalties to boost efficiency. Experimental results\nshow that our approach avoids training instability caused by length penalty\nwhile maintaining the optimal accuracy-efficiency trade-off. On the GSM8K,\nGPQA, MATH-500, AMC 2023, and AIME 2024 benchmarks, it improves average\naccuracy by 1.48% while reducing CoT sequence length by 47.3%."}
{"id": "2505.18118", "pdf": "https://arxiv.org/pdf/2505.18118", "abs": "https://arxiv.org/abs/2505.18118", "authors": ["Aidan Gleich", "Eric Laber", "Alexander Volfovsky"], "title": "Scalable Policy Maximization Under Network Interference", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Many interventions, such as vaccines in clinical trials or coupons in online\nmarketplaces, must be assigned sequentially without full knowledge of their\neffects. Multi-armed bandit algorithms have proven successful in such settings.\nHowever, standard independence assumptions fail when the treatment status of\none individual impacts the outcomes of others, a phenomenon known as\ninterference. We study optimal-policy learning under interference on a dynamic\nnetwork. Existing approaches to this problem require repeated observations of\nthe same fixed network and struggle to scale in sample size beyond as few as\nfifteen connected units -- both limit applications. We show that under common\nassumptions on the structure of interference, rewards become linear. This\nenables us to develop a scalable Thompson sampling algorithm that maximizes\npolicy impact when a new $n$-node network is observed each round. We prove a\nBayesian regret bound that is sublinear in $n$ and the number of rounds.\nSimulation experiments show that our algorithm learns quickly and outperforms\nexisting methods. The results close a key scalability gap between causal\ninference methods for interference and practical bandit algorithms, enabling\npolicy optimization in large-scale networked systems."}
{"id": "2505.18121", "pdf": "https://arxiv.org/pdf/2505.18121", "abs": "https://arxiv.org/abs/2505.18121", "authors": ["Danyang Zhang", "Situo Zhang", "Ziyue Yang", "Zichen Zhu", "Zihan Zhao", "Ruisheng Cao", "Lu Chen", "Kai Yu"], "title": "ProgRM: Build Better GUI Agents with Progress Rewards", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "LLM-based (Large Language Model) GUI (Graphical User Interface) agents can\npotentially reshape our daily lives significantly. However, current LLM-based\nGUI agents suffer from the scarcity of high-quality training data owing to the\ndifficulties of trajectory collection and reward annotation. Existing works\nhave been exploring LLMs to collect trajectories for imitation learning or to\noffer reward signals for online RL training. However, the Outcome Reward Model\n(ORM) used in existing works cannot provide finegrained feedback and can\nover-penalize the valuable steps in finally failed trajectories. To this end,\nwe propose Progress Reward Model (ProgRM) to provide dense informative\nintermediate rewards by predicting a task completion progress for each step in\nonline training. To handle the challenge of progress reward label annotation,\nwe further design an efficient LCS-based (Longest Common Subsequence)\nself-annotation algorithm to discover the key steps in trajectories and assign\nprogress labels accordingly. ProgRM is evaluated with extensive experiments and\nanalyses. Actors trained with ProgRM outperform leading proprietary LLMs and\nORM-trained actors, illustrating the effectiveness of ProgRM. The codes for\nexperiments will be made publicly available upon acceptance."}
{"id": "2505.18135", "pdf": "https://arxiv.org/pdf/2505.18135", "abs": "https://arxiv.org/abs/2505.18135", "authors": ["Kazem Faghih", "Wenxiao Wang", "Yize Cheng", "Siddhant Bharti", "Gaurang Sriramanan", "Sriram Balasubramanian", "Parsa Hosseini", "Soheil Feizi"], "title": "Gaming Tool Preferences in Agentic LLMs", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) can now access a wide range of external tools,\nthanks to the Model Context Protocol (MCP). This greatly expands their\nabilities as various agents. However, LLMs rely entirely on the text\ndescriptions of tools to decide which ones to use--a process that is\nsurprisingly fragile. In this work, we expose a vulnerability in prevalent\ntool/function-calling protocols by investigating a series of edits to tool\ndescriptions, some of which can drastically increase a tool's usage from LLMs\nwhen competing with alternatives. Through controlled experiments, we show that\ntools with properly edited descriptions receive over 10 times more usage from\nGPT-4.1 and Qwen2.5-7B than tools with original descriptions. We further\nevaluate how various edits to tool descriptions perform when competing directly\nwith one another and how these trends generalize or differ across a broader set\nof 10 different models. These phenomenons, while giving developers a powerful\nway to promote their tools, underscore the need for a more reliable foundation\nfor agentic LLMs to select and utilize tools and resources."}
