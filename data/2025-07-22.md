<div id=toc></div>

# 目录

- [cs.LG](#cs.LG) [总数: 128]
- [cs.AI](#cs.AI) [总数: 58]
- [cs.CR](#cs.CR) [总数: 31]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Catalyst: a Novel Regularizer for Structured Pruning with Auxiliary Extension of Parameter Space](https://arxiv.org/abs/2507.14170)
*Jaeheun Jung, Donghun Lee*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的正则化方法，通过引入辅助催化剂变量来确保在修剪过程中每个过滤器都有公平的机会被保留或删除，并且这种新方法在多个数据集和模型上的表现优于现有的过滤器修剪方法。


<details>
  <summary>更多</summary>
  
**动机:** 传统的正则化方法（如L1或Group Lasso及其变体）在进行结构化剪枝时，会偏向于裁剪幅度较小的滤波器，这可能导致性能不佳。此外，它们通常会在裁剪决策边界周围几乎为零的裕度，使得滤波器幅度的微小扰动可能会翻转裁剪决策。

**方法:** 作者提出了一个新颖的正则化器，该正则化器通过辅助催化剂变量在扩展的参数空间中定义，以确保每个过滤器在修剪过程中都有公平的机会。同时，该方法通过大幅度分叉被保留和被修剪的过滤器之间的幅度，实现了稳健的修剪行为。

**结果:** 实验证明，Catalyst Pruning算法在各种数据集和模型上的修剪结果优于最先进的滤波器修剪方法，同时也证实了预测的稳健和公平的修剪特性。

**结论:** Catalyst regularization提供了一种新的、更公平和稳健的方法来进行神经网络的结构化剪枝。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Catalyst%3A+a+Novel+Regularizer+for+Structured+Pruning+with+Auxiliary+Extension+of+Parameter+Space，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14170，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14170&send_immediately=true&force_search=false)

**原文摘要:** Structured pruning aims to reduce the size and computational cost of deep
neural networks by removing entire filters or channels. The traditional
regularizers such as L1 or Group Lasso and its variants lead to
magnitude-biased pruning decisions, such that the filters with small magnitudes
are likely to be pruned. Also, they often entail pruning results with almost
zero margin around pruning decision boundary, such that tiny perturbation in a
filter magnitude can flip the pruning decision. In this paper, we identify the
precise algebraic condition under which pruning operations preserve model
performance, and use the condition to construct a novel regularizer defined in
an extended parameter space via auxiliary catalyst variables. The proposed
Catalyst regularization ensures fair pruning chance for each filters with
theoretically provable zero bias to their magnitude and robust pruning behavior
achieved by wide-margin bifurcation of magnitudes between the preserved and the
pruned filters. The theoretical properties naturally lead to real-world
effectiveness, as shown by empirical validations of Catalyst Pruning algorithm.
Pruning results on various datasets and models are superior to state-of-the-art
filter pruning methods, and at the same time confirm the predicted robust and
fair pruning characteristics of Catalyst pruning.

</details>


### [2] [IPPRO: Importance-based Pruning with PRojective Offset for Magnitude-indifferent Structural Pruning](https://arxiv.org/abs/2507.14171)
*Jaeheun Jung, Jaehyuk Lee, Yeajin Lee, Donghun Lee*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的基于重要性的结构化剪枝方法IPPRO，通过在投影空间中观察滤波器的梯度下降运动来挑战传统的'尺寸重要'观念，实现接近无损的剪枝效果。


<details>
  <summary>更多</summary>
  
**动机:** 神经网络压缩方法的需求增长促使了对结构化剪枝方法的研究，现有的大小重要性标准限制了剪枝决策的能力。

**方法:** 提出PROscore作为一种新的重要性评分，并应用于IPPRO中，通过将滤波器置于投影空间并观察其梯度下降运动来决定是否剪枝。

**结果:** 该方法实现了接近无损失的剪枝效果，在微调后表现良好。

**结论:** 这项工作打破了剪枝中的“尺寸重要”神话，从理论和实证上扩展了基于重要性的剪枝领域。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是IPPRO%3A+Importance-based+Pruning+with+PRojective+Offset+for+Magnitude-indifferent+Structural+Pruning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14171，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14171&send_immediately=true&force_search=false)

**原文摘要:** With the growth of demand on neural network compression methods, the
structured pruning methods including importance-based approach are actively
studied. The magnitude importance and many correlated modern importance
criteria often limit the capacity of pruning decision, since the filters with
larger magnitudes are not likely to be pruned if the smaller one didn't, even
if it is redundant. In this paper, we propose a novel pruning strategy to
challenge this dominating effect of magnitude and provide fair chance to each
filter to be pruned, by placing it on projective space. After that, we observe
the gradient descent movement whether the filters move toward the origin or
not, to measure how the filter is likely to be pruned. This measurement is used
to construct PROscore, a novel importance score for IPPRO, a novel
importance-based structured pruning with magnitude-indifference. Our evaluation
results shows that the proposed importance criteria using the projective space
achieves near-lossless pruning by reducing the performance drop in pruning,
with promising performance after the finetuning. Our work debunks the
``size-matters'' myth in pruning and expands the frontier of importance-based
pruning both theoretically and empirically.

</details>


### [3] [Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI](https://arxiv.org/abs/2507.14172)
*Julien Pourcel, Cédric Colas, Pierre-Yves Oudeyer*

**主要类别:** cs.LG

**AI概要:** SOAR是一种将语言模型整合进自我改进进化循环以学习程序合成的方法，在ARC-AGI基准测试中，SOAR实现了显著的性能提升。


<details>
  <summary>更多</summary>
  
**动机:** 许多程序合成任务对于最先进的语言模型来说仍然过于复杂，而基于搜索的进化方法由于生成模型能力的限制，效果也有限。

**方法:** SOAR交替进行（1）使用LLM采样和优化候选解决方案的进化搜索；（2）事后学习阶段，该阶段将搜索尝试转换为有效的问-解对，用于微调LLM的采样和优化能力，从而在后续迭代中实现更有效的搜索。

**结果:** 在具有挑战性的ARC-AGI基准上，SOAR实现了跨模型规模和迭代的显著性能增益，并且能够解决52%的公共测试集。

**结论:** SOAR通过整合语言模型进入自改善的进化循环来学习程序合成，显著提高了程序合成任务的成功率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Self-Improving+Language+Models+for+Evolutionary+Program+Synthesis%3A+A+Case+Study+on+ARC-AGI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14172，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14172&send_immediately=true&force_search=false)

**原文摘要:** Many program synthesis tasks prove too challenging for even state-of-the-art
language models to solve in single attempts. Search-based evolutionary methods
offer a promising alternative by exploring solution spaces iteratively, but
their effectiveness remain limited by the fixed capabilities of the underlying
generative model.
  We propose SOAR, a method that learns program synthesis by integrating
language models into a self-improving evolutionary loop.
  SOAR alternates between (1) an evolutionary search that uses an LLM to sample
and refine candidate solutions, and (2) a hindsight learning phase that
converts search attempts into valid problem-solution pairs used to fine-tune
the LLM's sampling and refinement capabilities\, -- \,enabling increasingly
effective search in subsequent iterations.
  On the challenging ARC-AGI benchmark, SOAR achieves significant performance
gains across model scales and iterations, leveraging positive transfer between
the sampling and refinement finetuning tasks. These improvements carry over to
test-time adaptation, enabling SOAR to solve 52\% of the public test set. Our
code is open-sourced at: https://github.com/flowersteam/SOAR

</details>


### [4] [Latent Space Data Fusion Outperforms Early Fusion in Multimodal Mental Health Digital Phenotyping Data](https://arxiv.org/abs/2507.14175)
*Youcef Barkat, Dylan Hamitouche, Deven Parekh, Ivy Guo, David Benrimoh*

**主要类别:** cs.LG

**AI概要:** 本研究使用BRIGHTEN临床试验的数据，通过比较随机森林模型和结合自编码器与神经网络的组合模型，评估了中间融合（潜在空间融合）在预测日常抑郁症状方面的性能。组合模型在所有设置中均优于基线模型，并且在整合所有数据模式时表现最佳，显示出潜在空间融合在捕捉复杂精神健康数据集中的非线性交互作用的价值。


<details>
  <summary>更多</summary>
  
**动机:** 抑郁症和焦虑症等精神疾病需要改进早期检测和个人化干预的方法。传统预测模型通常依赖于单模态数据或早期融合策略，无法捕捉精神病学数据的复杂多模态性质。高级集成技术如中间融合（潜在空间融合）可能提供更好的准确性和临床实用性。

**方法:** 使用来自BRIGHTEN临床试验的数据，评估了中间融合（潜在空间融合）对预测日常抑郁症状（PHQ-2评分）的效果。将早期融合实现的随机森林模型与通过自编码器和神经网络实现的组合模型进行对比。数据集包括基于智能手机的行为、人口统计和临床特征。实验在多个时间分割和数据流组合上进行。性能评估使用平均平方误差（MSE）和决定系数（R2）。

**结果:** 组合模型在所有设置中均优于随机森林和线性回归基线模型，实现了更低的MSE（0.4985 vs. 0.5305）和更高的R2（0.4695 vs. 0.4356）。随机森林模型显示出过拟合的迹象，而组合模型保持了一致的泛化能力。当在组合模型中整合所有数据模态时，性能最佳，强调了潜在空间融合捕捉复杂精神病学数据集中非线性交互作用的价值。

**结论:** 潜在空间融合为使用多模态心理健康数据进行预测提供了比传统融合方法更稳健的替代方案。未来的工作应探索模型可解释性和个体水平预测以供临床部署。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Latent+Space+Data+Fusion+Outperforms+Early+Fusion+in+Multimodal+Mental+Health+Digital+Phenotyping+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14175，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14175&send_immediately=true&force_search=false)

**原文摘要:** Background: Mental illnesses such as depression and anxiety require improved
methods for early detection and personalized intervention. Traditional
predictive models often rely on unimodal data or early fusion strategies that
fail to capture the complex, multimodal nature of psychiatric data. Advanced
integration techniques, such as intermediate (latent space) fusion, may offer
better accuracy and clinical utility. Methods: Using data from the BRIGHTEN
clinical trial, we evaluated intermediate (latent space) fusion for predicting
daily depressive symptoms (PHQ-2 scores). We compared early fusion implemented
with a Random Forest (RF) model and intermediate fusion implemented via a
Combined Model (CM) using autoencoders and a neural network. The dataset
included behavioral (smartphone-based), demographic, and clinical features.
Experiments were conducted across multiple temporal splits and data stream
combinations. Performance was evaluated using mean squared error (MSE) and
coefficient of determination (R2). Results: The CM outperformed both RF and
Linear Regression (LR) baselines across all setups, achieving lower MSE (0.4985
vs. 0.5305 with RF) and higher R2 (0.4695 vs. 0.4356). The RF model showed
signs of overfitting, with a large gap between training and test performance,
while the CM maintained consistent generalization. Performance was best when
integrating all data modalities in the CM (in contradistinction to RF),
underscoring the value of latent space fusion for capturing non-linear
interactions in complex psychiatric datasets. Conclusion: Latent space fusion
offers a robust alternative to traditional fusion methods for prediction with
multimodal mental health data. Future work should explore model
interpretability and individual-level prediction for clinical deployment.

</details>


### [5] [Predictive Representativity: Uncovering Racial Bias in AI-based Skin Cancer Detection](https://arxiv.org/abs/2507.14176)
*Andrés Morales-Forero, Lili J. Rueda, Ronald Herrera, Samuel Bassetto, Eric Coatanea*

**主要类别:** cs.LG

**AI概要:** 这篇论文提出了预测代表性（PR）的概念，作为一种公平性审计框架，强调模型预测的动态、情境敏感属性，并通过皮肤癌分类案例研究揭示了不同肤色人群的表现差异。


<details>
  <summary>更多</summary>
  
**动机:** 鉴于对算法偏见和不公平结果的担忧，特别是对历史上被边缘化的群体，本文旨在提出一种新的公平性审计方法——预测代表性（PR），将关注点从数据集组成转向结果水平的公平性。

**方法:** 通过对HAM10000数据集和来自哥伦比亚的独立临床数据集（BOSQUE测试集）训练的基于AI的皮肤癌分类器进行评估，分析不同肤色类型下的性能差异，并提出外部可运输性标准来形式化公平泛化的阈值。

**结果:** 研究发现，尽管源数据中进行了比例抽样，但针对肤色较深个体的分类器表现始终较差，揭示了按肤色划分的显著性能差异。

**结论:** 作者呼吁进行事后公平性审计、提高数据集文档的透明度以及建立包容性的模型验证流程，以应对数据驱动医疗保健中的结构性不平等问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Predictive+Representativity%3A+Uncovering+Racial+Bias+in+AI-based+Skin+Cancer+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14176，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14176&send_immediately=true&force_search=false)

**原文摘要:** Artificial intelligence (AI) systems increasingly inform medical
decision-making, yet concerns about algorithmic bias and inequitable outcomes
persist, particularly for historically marginalized populations. This paper
introduces the concept of Predictive Representativity (PR), a framework of
fairness auditing that shifts the focus from the composition of the data set to
outcomes-level equity. Through a case study in dermatology, we evaluated
AI-based skin cancer classifiers trained on the widely used HAM10000 dataset
and on an independent clinical dataset (BOSQUE Test set) from Colombia. Our
analysis reveals substantial performance disparities by skin phototype, with
classifiers consistently underperforming for individuals with darker skin,
despite proportional sampling in the source data. We argue that
representativity must be understood not as a static feature of datasets but as
a dynamic, context-sensitive property of model predictions. PR operationalizes
this shift by quantifying how reliably models generalize fairness across
subpopulations and deployment contexts. We further propose an External
Transportability Criterion that formalizes the thresholds for fairness
generalization. Our findings highlight the ethical imperative for post-hoc
fairness auditing, transparency in dataset documentation, and inclusive model
validation pipelines. This work offers a scalable tool for diagnosing
structural inequities in AI systems, contributing to discussions on equity,
interpretability, and data justice and fostering a critical re-evaluation of
fairness in data-driven healthcare.

</details>


### [6] [Understanding Two-Layer Neural Networks with Smooth Activation Functions](https://arxiv.org/abs/2507.14177)
*Changcun Huang*

**主要类别:** cs.LG

**AI概要:** 本文通过构建泰勒级数展开、严格的偏序节点、平滑样条实现和平滑连续性限制四个主要原则，解析了使用平滑激活函数的两层神经网络的训练解，并证明了其对于任意输入维度的通用近似能力。


<details>
  <summary>更多</summary>
  
**动机:** 为了理解反向传播算法对具有平滑激活函数（如传统的sigmoid类型）的两层神经网络的隐藏层得到的训练解，揭示“黑箱”的解空间秘密。

**方法:** 使用构建泰勒级数展开、严格的偏序节点、平滑样条实现和平滑连续性限制这四个主要原则来研究和证明两层神经网络的训练解。

**结果:** 证明了该方法对于任意输入维度的通用近似能力，并通过实验验证了理论结果，有助于揭示解空间的神秘面纱。

**结论:** 该论文不仅揭示了两层神经网络的解空间特性，还丰富了近似理论。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+Two-Layer+Neural+Networks+with+Smooth+Activation+Functions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14177，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14177&send_immediately=true&force_search=false)

**原文摘要:** This paper aims to understand the training solution, which is obtained by the
back-propagation algorithm, of two-layer neural networks whose hidden layer is
composed of the units with smooth activation functions, including the usual
sigmoid type most commonly used before the advent of ReLUs. The mechanism
contains four main principles: construction of Taylor series expansions, strict
partial order of knots, smooth-spline implementation and smooth-continuity
restriction. The universal approximation for arbitrary input dimensionality is
proved and experimental verification is given, through which the mystery of
``black box'' of the solution space is largely revealed. The new proofs
employed also enrich approximation theory.

</details>


### [7] [Feature Bank Enhancement for Distance-based Out-of-Distribution Detection](https://arxiv.org/abs/2507.14178)
*Yuhang Liu, Yuefei Wu, Bin Shi, Bo Dong*

**主要类别:** cs.LG

**AI概要:** 提出了一种简单有效的方法，Feature Bank Enhancement (FBE)，用于增强OOD检测能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于距离的评分函数在处理深度学习导致的数据特征偏差时，往往会错误地给ID样本过低的评分，限制了其OOD检测能力。

**方法:** 使用来自数据集的统计特征来识别和约束极端特征到分离边界，从而增加分布内外样本之间的距离。

**结果:** 实验结果显示该方法在这两个基准上都达到了最先进的性能。

**结论:** 提出的方法不仅效果好，而且理论分析和补充实验提供了更多关于该方法的见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Feature+Bank+Enhancement+for+Distance-based+Out-of-Distribution+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14178，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14178&send_immediately=true&force_search=false)

**原文摘要:** Out-of-distribution (OOD) detection is critical to ensuring the reliability
of deep learning applications and has attracted significant attention in recent
years. A rich body of literature has emerged to develop efficient score
functions that assign high scores to in-distribution (ID) samples and low
scores to OOD samples, thereby helping distinguish OOD samples. Among these
methods, distance-based score functions are widely used because of their
efficiency and ease of use. However, deep learning often leads to a biased
distribution of data features, and extreme features are inevitable. These
extreme features make the distance-based methods tend to assign too low scores
to ID samples. This limits the OOD detection capabilities of such methods. To
address this issue, we propose a simple yet effective method, Feature Bank
Enhancement (FBE), that uses statistical characteristics from dataset to
identify and constrain extreme features to the separation boundaries, therapy
making the distance between samples inside and outside the distribution
farther. We conducted experiments on large-scale ImageNet-1k and CIFAR-10
respectively, and the results show that our method achieves state-of-the-art
performance on both benchmark. Additionally, theoretical analysis and
supplementary experiments are conducted to provide more insights into our
method.

</details>


### [8] [A Sparsity Predicting Approach for Large Language Models via Activation Pattern Clustering](https://arxiv.org/abs/2507.14179)
*Nobel Dhar, Bobin Deng, Md Romyull Islam, Xinyue Zhang, Kazi Fahim Ahmad Nasif, Kun Suo*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于聚类的激活模式压缩框架，用于有效预测和利用大语言模型中的激活稀疏性。该方法通过将相似的激活模式分组为少量的代表簇，实现了高达79.34%的聚类精度，并在保持低困惑度分数的情况下减少了计算成本。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型（LLMs）展示出显著的激活稀疏性，即对于给定输入，只有部分神经元是活跃的。这种稀疏性提供了减少计算成本的机会，但要高效地利用它需要以可扩展的方式预测激活模式。然而，在神经元级别直接预测是计算昂贵的，因为现代LLMs中存在大量的神经元。

**方法:** 作者提出了一种基于聚类的激活模式压缩框架，不是独立处理每个神经元，而是将相似的激活模式分组成一小群具有代表性的簇。

**结果:** 该方法达到了最高79.34%的聚类精度，优于标准二进制聚类方法，同时保持了最小的困惑度分数下降。使用足够数量的簇时，该方法可以获得低至12.49的困惑度分数。

**结论:** 通过预测簇分配而不是单个神经元状态，未来模型可以有效地从预计算的质心推断激活模式。这个基于聚类的公式为激活模式预测的未来工作奠定了基础，为大规模语言模型的有效推理铺平了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Sparsity+Predicting+Approach+for+Large+Language+Models+via+Activation+Pattern+Clustering，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14179，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14179&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) exhibit significant activation sparsity, where
only a subset of neurons are active for a given input. Although this sparsity
presents opportunities to reduce computational cost, efficiently utilizing it
requires predicting activation patterns in a scalable manner. However, direct
prediction at the neuron level is computationally expensive due to the vast
number of neurons in modern LLMs. To enable efficient prediction and
utilization of activation sparsity, we propose a clustering-based activation
pattern compression framework. Instead of treating each neuron independently,
we group similar activation patterns into a small set of representative
clusters. Our method achieves up to 79.34% clustering precision, outperforming
standard binary clustering approaches while maintaining minimal degradation in
perplexity (PPL) scores. With a sufficiently large number of clusters, our
approach attains a PPL score as low as 12.49, demonstrating its effectiveness
in preserving model quality while reducing computational overhead. By
predicting cluster assignments rather than individual neuron states, future
models can efficiently infer activation patterns from pre-computed centroids.
We detail the clustering algorithm, analyze its effectiveness in capturing
meaningful activation structures, and demonstrate its potential to improve
sparse computation efficiency. This clustering-based formulation serves as a
foundation for future work on activation pattern prediction, paving the way for
efficient inference in large-scale language models.

</details>


### [9] [Digital Twin-Assisted Explainable AI for Robust Beam Prediction in mmWave MIMO Systems](https://arxiv.org/abs/2507.14180)
*Nasir Khan, Asmaa Abdallah, Abdulkadir Celik, Ahmed M. Eltawil, Sinem Coleri*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种用于毫米波MIMO系统的稳健且可解释的深度学习波束对准引擎（BAE），通过使用RSSI测量、数字孪生生成合成信道数据和迁移学习优化模型，实现了减少数据需求、降低波束训练开销和提高异常检测鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 当前的深度学习解决方案在毫米波系统中进行有效的波束对准时面临高数据收集开销、硬件限制、缺乏可解释性和易受对抗攻击等挑战。为了应对这些挑战并提升信任度和可靠性，需要一种既稳健又可解释的方法。

**方法:** 该方法利用宽波束的接收信号强度指示（RSSI）测量来预测最佳窄波束，并通过特定地点的数字孪生生成类似真实环境的合成信道数据。采用迁移学习微调预训练模型以适应实际环境，并使用SHAP值对输入特征的重要性进行排序，同时结合DkNN算法提供可信度指标。

**结果:** 实验结果表明，所提出的框架将实际世界数据需求减少了70%，波束训练开销降低了62%，并将异常检测鲁棒性提高了8.5倍，达到了接近最优的频谱效率和透明决策。

**结论:** 该研究提出的深度学习波束对准引擎为毫米波MIMO系统提供了更高效、更可靠和更透明的解决方案，显著减少了数据收集和波束训练的负担，并增强了对抗异常情况的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Digital+Twin-Assisted+Explainable+AI+for+Robust+Beam+Prediction+in+mmWave+MIMO+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14180，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14180&send_immediately=true&force_search=false)

**原文摘要:** In line with the AI-native 6G vision, explainability and robustness are
crucial for building trust and ensuring reliable performance in millimeter-wave
(mmWave) systems. Efficient beam alignment is essential for initial access, but
deep learning (DL) solutions face challenges, including high data collection
overhead, hardware constraints, lack of explainability, and susceptibility to
adversarial attacks. This paper proposes a robust and explainable DL-based beam
alignment engine (BAE) for mmWave multiple-input multiple output (MIMO)
systems. The BAE uses received signal strength indicator (RSSI) measurements
from wide beams to predict the best narrow beam, reducing the overhead of
exhaustive beam sweeping. To overcome the challenge of real-world data
collection, this work leverages a site-specific digital twin (DT) to generate
synthetic channel data closely resembling real-world environments. A model
refinement via transfer learning is proposed to fine-tune the pre-trained model
residing in the DT with minimal real-world data, effectively bridging
mismatches between the digital replica and real-world environments. To reduce
beam training overhead and enhance transparency, the framework uses deep
Shapley additive explanations (SHAP) to rank input features by importance,
prioritizing key spatial directions and minimizing beam sweeping. It also
incorporates the Deep k-nearest neighbors (DkNN) algorithm, providing a
credibility metric for detecting out-of-distribution inputs and ensuring
robust, transparent decision-making. Experimental results show that the
proposed framework reduces real-world data needs by 70%, beam training overhead
by 62%, and improves outlier detection robustness by up to 8.5x, achieving
near-optimal spectral efficiency and transparent decision making compared to
traditional softmax based DL models.

</details>


### [10] [Semi-Supervised Federated Learning via Dual Contrastive Learning and Soft Labeling for Intelligent Fault Diagnosis](https://arxiv.org/abs/2507.14181)
*Yajiao Dai, Jun Li, Zhen Mei, Yiyang Ni, Shi Jin, Zengxiang Li, Sheng Guo, Wei Xiang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的半监督联邦学习框架SSFL-DCSL，以解决工业机械智能故障诊断中数据和标签稀缺的问题。该方法通过双重对比损失和软标签整合，实现分布式客户间的知识共享，减少模型分歧，提高在少量标注样本情况下的诊断准确性。


<details>
  <summary>更多</summary>
  
**动机:** 传统的监督深度学习方法在智能故障诊断中面临数据和标签需求大、成本高及不同客户端数据分布差异的挑战，这限制了模型性能并增加了实际应用难度。

**方法:** 设计了一个基于拉普拉斯分布的样本加权函数，减轻伪标签低置信度带来的偏差；引入双重对比损失（包括局部对比损失和全局对比损失）来缓解不同数据分布引起的模型分歧；通过带动量更新的加权平均聚合本地原型，实现在服务器端的知识共享。

**结果:** 在两个公开数据集和一个工厂电机收集的数据集上进行了实验，在最困难的任务中（只有10%的数据被标注），所提出的SSFL-DCSL框架比现有最先进方法提高了1.15%到7.85%的准确率。

**结论:** SSFL-DCSL框架为解决分布式环境下智能故障诊断中的数据和标签稀缺问题提供了一种有效的解决方案，特别是在数据标注成本高且不同客户端间数据分布不一致的情况下，能够显著提升诊断模型的准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Semi-Supervised+Federated+Learning+via+Dual+Contrastive+Learning+and+Soft+Labeling+for+Intelligent+Fault+Diagnosis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14181，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14181&send_immediately=true&force_search=false)

**原文摘要:** Intelligent fault diagnosis (IFD) plays a crucial role in ensuring the safe
operation of industrial machinery and improving production efficiency. However,
traditional supervised deep learning methods require a large amount of training
data and labels, which are often located in different clients. Additionally,
the cost of data labeling is high, making labels difficult to acquire.
Meanwhile, differences in data distribution among clients may also hinder the
model's performance. To tackle these challenges, this paper proposes a
semi-supervised federated learning framework, SSFL-DCSL, which integrates dual
contrastive loss and soft labeling to address data and label scarcity for
distributed clients with few labeled samples while safeguarding user privacy.
It enables representation learning using unlabeled data on the client side and
facilitates joint learning among clients through prototypes, thereby achieving
mutual knowledge sharing and preventing local model divergence. Specifically,
first, a sample weighting function based on the Laplace distribution is
designed to alleviate bias caused by low confidence in pseudo labels during the
semi-supervised training process. Second, a dual contrastive loss is introduced
to mitigate model divergence caused by different data distributions, comprising
local contrastive loss and global contrastive loss. Third, local prototypes are
aggregated on the server with weighted averaging and updated with momentum to
share knowledge among clients. To evaluate the proposed SSFL-DCSL framework,
experiments are conducted on two publicly available datasets and a dataset
collected on motors from the factory. In the most challenging task, where only
10\% of the data are labeled, the proposed SSFL-DCSL can improve accuracy by
1.15% to 7.85% over state-of-the-art methods.

</details>


### [11] [From Bias to Behavior: Learning Bull-Bear Market Dynamics with Contrastive Modeling](https://arxiv.org/abs/2507.14182)
*Xiaotong Luo, Shengda Zhuo, Min Chen, Lichun Li, Ruizhao Lu, Wenqi Fan, Shuqiang Huang, Yin Tang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的模型B4，该模型能够通过嵌入时间价格序列和外部上下文信号来捕捉投资者行为中的牛熊动态，从而提高市场趋势预测的准确性。


<details>
  <summary>更多</summary>
  
**动机:** 金融市场由历史价格轨迹和外生叙事塑造，表现出高度动态和复杂的行为。先前的工作没有充分探索牛市和熊市在投资者驱动的市场动态中的潜力。

**方法:** 作者提出了一个名为Bias to Behavior from Bull-Bear Dynamics model (B4)的统一框架，该框架将时间价格序列和外部上下文信号共同嵌入到一个共享的潜在空间中，在这个空间里，惯性配对模块和双重竞争机制分别用于保持动量和捕捉行为差异。

**结果:** 实验结果表明，B4模型不仅在预测市场趋势方面表现优异，还能提供关于偏差、投资者行为和市场动态之间相互作用的可解释见解。

**结论:** 研究揭示了偏差变化与行为适应之间的动态关系，并证明了所提出的B4模型在进化市场条件下增强了趋势预测的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+Bias+to+Behavior%3A+Learning+Bull-Bear+Market+Dynamics+with+Contrastive+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14182，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14182&send_immediately=true&force_search=false)

**原文摘要:** Financial markets exhibit highly dynamic and complex behaviors shaped by both
historical price trajectories and exogenous narratives, such as news, policy
interpretations, and social media sentiment. The heterogeneity in these data
and the diverse insight of investors introduce biases that complicate the
modeling of market dynamics. Unlike prior work, this paper explores the
potential of bull and bear regimes in investor-driven market dynamics. Through
empirical analysis on real-world financial datasets, we uncover a dynamic
relationship between bias variation and behavioral adaptation, which enhances
trend prediction under evolving market conditions. To model this mechanism, we
propose the Bias to Behavior from Bull-Bear Dynamics model (B4), a unified
framework that jointly embeds temporal price sequences and external contextual
signals into a shared latent space where opposing bull and bear forces
naturally emerge, forming the foundation for bias representation. Within this
space, an inertial pairing module pairs temporally adjacent samples to preserve
momentum, while the dual competition mechanism contrasts bullish and bearish
embeddings to capture behavioral divergence. Together, these components allow
B4 to model bias-driven asymmetry, behavioral inertia, and market
heterogeneity. Experimental results on real-world financial datasets
demonstrate that our model not only achieves superior performance in predicting
market trends but also provides interpretable insights into the interplay of
biases, investor behaviors, and market dynamics.

</details>


### [12] [LaCache: Ladder-Shaped KV Caching for Efficient Long-Context Modeling of Large Language Models](https://arxiv.org/abs/2507.14204)
*Dachuan Shi, Yonggan Fu, Xiangchi Yuan, Zhongzhi Yu, Haoran You, Sixu Li, Xin Dong, Jan Kautz, Pavlo Molchanov, Yingyan, Lin*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为LaCache的新的KV缓存优化范式，通过阶梯形KV缓存模式和迭代压缩机制，解决了长距离模型中的两个关键挑战：强大的长程能力和连续生成而不出现内存不足的问题。


<details>
  <summary>更多</summary>
  
**动机:** 随着序列长度的增加，大型语言模型（LLMs）中的键值（KV）对数量也相应增加，造成了显著的效率瓶颈。因此需要一种有效的解决方案来提高LLMs的长程能力，并确保在固定存储预算下能持续生成文本。

**方法:** LaCache引入了两种关键技术：1）阶梯形KV缓存模式，不仅按顺序存储KV对，而且跨层存储，从而在固定存储预算下扩展捕捉长程依赖关系的范围；2）迭代压缩机制，逐步压缩旧缓存，为新标记腾出空间。

**结果:** 实验验证了LaCache在各种任务、基准测试和LLM模型中有效增强了LLMs的长程能力。

**结论:** LaCache作为一种无需训练的方法，能够有效地提升LLMs的长程推理能力，同时保证连续生成过程中的内存管理。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LaCache%3A+Ladder-Shaped+KV+Caching+for+Efficient+Long-Context+Modeling+of+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14204，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14204&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in Large Language Models (LLMs) have spurred interest in
numerous applications requiring robust long-range capabilities, essential for
processing extensive input contexts and continuously generating extended
outputs. As sequence lengths increase, the number of Key-Value (KV) pairs in
LLMs escalates, creating a significant efficiency bottleneck. In this paper, we
propose a new KV cache optimization paradigm called LaCache, a training-free
method for efficient and accurate generative inference of LLMs. LaCache enables
LLMs to simultaneously address both of the critical challenges in long-range
modeling: robust long-range capabilities and continuous generation without
running out-of-memory (OOM). Specifically, LaCache integrates two key
innovations: (1) a ladder-shaped KV cache pattern that stores KV pairs not only
sequentially (left-to-right within each layer) but also across layers (from
shallow to deep), providing an extended span for capturing long-range
dependencies under a fixed storage budget, thereby boosting long-range
capabilities; and (2) an iterative compaction mechanism that progressively
compresses older caches, freeing up space for new tokens within a fixed cache
size. This token distance-based dynamic compression enables more effective
continuous generation under constrained cache budgets. Experiments across
various tasks, benchmarks, and LLM models consistently validate LaCache's
effectiveness in enhancing LLMs' long-range capabilities. Our code is available
at https://github.com/GATECH-EIC/LaCache.

</details>


### [13] [Developing an AI-Guided Assistant Device for the Deaf and Hearing Impaired](https://arxiv.org/abs/2507.14215)
*Jiayu, Liu*

**主要类别:** cs.LG

**AI概要:** 这篇论文介绍了一个为聋人或听力受损者开发的深度学习系统，该系统可以实时准确定位和识别声音来源。它由三个主要部分组成：JerryNet、音频分类模型和多模态集成模型。硬件包括四个麦克风和一个摄像头。在自定义数据集上，该系统的性能超过了所有基线模型。


<details>
  <summary>更多</summary>
  
**动机:** 该研究旨在利用机器学习技术，为聋人或听力受损者开发一种能够实时准确地定位和识别声音来源的辅助设备，以填补当前研究中的重要空白。

**方法:** 该系统包含三个主要组成部分：1. JerryNet：一个自定义设计的CNN架构，用于确定九个可能方向的声音到达方向（DoA）。2. 音频分类：基于微调对比语言-音频预训练（CLAP）模型，仅根据音频识别确切的声音类别。3. 多模态集成模型：结合音频、视觉和文本数据精确定位图像中确切声音来源的模型，其中包含两个模块，一个使用Yolov9进行对象检测生成所有对象的边界框，另一个是音视频定位模型，使用完整交并比（CIoU）来确定最优边界框。

**结果:** 在自定义收集的数据集上，JerryNet实现了91.1%的方向精度，超过了所有基线模型。CLAP模型在自定义和AudioSet数据集上分别达到了98.5%和95%的准确性。组件3中的音视频定位模型获得了0.892的CIoU和0.658的AUC，超越了其他类似模型。

**结论:** 这项研究展示了其未来潜力，为创造新一代辅助设备铺平了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Developing+an+AI-Guided+Assistant+Device+for+the+Deaf+and+Hearing+Impaired，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14215，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14215&send_immediately=true&force_search=false)

**原文摘要:** This study aims to develop a deep learning system for an accessibility device
for the deaf or hearing impaired. The device will accurately localize and
identify sound sources in real time. This study will fill an important gap in
current research by leveraging machine learning techniques to target the
underprivileged community. The system includes three main components. 1.
JerryNet: A custom designed CNN architecture that determines the direction of
arrival (DoA) for nine possible directions. 2. Audio Classification: This model
is based on fine-tuning the Contrastive Language-Audio Pretraining (CLAP) model
to identify the exact sound classes only based on audio. 3. Multimodal
integration model: This is an accurate sound localization model that combines
audio, visual, and text data to locate the exact sound sources in the images.
The part consists of two modules, one object detection using Yolov9 to generate
all the bounding boxes of the objects, and an audio visual localization model
to identify the optimal bounding box using complete Intersection over Union
(CIoU). The hardware consists of a four-microphone rectangular formation and a
camera mounted on glasses with a wristband for displaying necessary information
like direction. On a custom collected data set, JerryNet achieved a precision
of 91. 1% for the sound direction, outperforming all the baseline models. The
CLAP model achieved 98.5% and 95% accuracy on custom and AudioSet datasets,
respectively. The audio-visual localization model within component 3 yielded a
cIoU of 0.892 and an AUC of 0.658, surpassing other similar models. There are
many future potentials to this study, paving the way to creating a new
generation of accessibility devices.

</details>


### [14] [Geometry-Aware Active Learning of Pattern Rankings via Choquet-Based Aggregation](https://arxiv.org/abs/2507.14217)
*Tudor Matei Opran, Samir Loudni*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种结合非线性效用聚合与几何感知查询选择的交互式学习框架，以解决模式挖掘中的模式爆炸问题。实验表明该方法相较于现有方法（如ChoquetRank），在更少的用户交互下实现更好的排名准确性。


<details>
  <summary>更多</summary>
  
**动机:** 模式挖掘中存在模式爆炸的问题，即模式数量过多，难以处理。为了解决这一问题，需要一种可以有效减少模式数量同时保留用户兴趣模式的方法。

**方法:** 本文提出的方法使用Choquet积分对多个有趣度量进行建模，以捕捉用户偏好，并利用版本空间的几何结构来指导信息比较的选择。此外，还采用分支定界策略与紧密的距离界限来高效识别决策边界附近的查询。

**结果:** 在UCI数据集上的实验表明，所提出的方法在较少的用户交互下实现了比现有方法（例如ChoquetRank）更好的排名准确性。

**结论:** 提出的交互式学习框架能够有效地解决模式挖掘中的模式爆炸问题，提高模式挖掘的效果和效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Geometry-Aware+Active+Learning+of+Pattern+Rankings+via+Choquet-Based+Aggregation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14217，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14217&send_immediately=true&force_search=false)

**原文摘要:** We address the pattern explosion problem in pattern mining by proposing an
interactive learning framework that combines nonlinear utility aggregation with
geometry-aware query selection. Our method models user preferences through a
Choquet integral over multiple interestingness measures and exploits the
geometric structure of the version space to guide the selection of informative
comparisons. A branch-and-bound strategy with tight distance bounds enables
efficient identification of queries near the decision boundary. Experiments on
UCI datasets show that our approach outperforms existing methods such as
ChoquetRank, achieving better ranking accuracy with fewer user interactions.

</details>


### [15] [Artificial Intelligence for Green Hydrogen Yield Prediction and Site Suitability using SHAP-Based Composite Index: Focus on Oman](https://arxiv.org/abs/2507.14219)
*Obumneme Zimuzor Nwafor, Mohammed Abdul Majeed Al Hooti*

**主要类别:** cs.LG

**AI概要:** 本研究提出了一个基于AI的框架，用于计算绿色氢气产量和选址适宜性指数。该框架通过气象、地形和时间数据集训练，揭示了选址适宜性的空间模式，并确定了影响最大的因素是水的接近度、海拔和季节变化。


<details>
  <summary>更多</summary>
  
**动机:** 由于直接氢气产量数据有限，需要一种方法来识别最佳的绿色氢气生产地点，特别是对于那些有绿色氢气前景但缺乏实测数据的国家。

**方法:** 该研究使用了一种多阶段的管道，包括无监督的多变量聚类、监督机器学习分类器和SHAP算法，以计算绿色氢气产量和选址适宜性指数。

**结果:** 模型预测准确率为98%，并发现水的接近度、海拔和季节变化是影响绿色氢气选址适宜性的最重要因素。

**结论:** 这项研究为行业利益相关者和政策制定者提供了一个可复制和可扩展的工具，用于在数据稀缺地区规划绿色氢气基础设施和其他决策。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Artificial+Intelligence+for+Green+Hydrogen+Yield+Prediction+and+Site+Suitability+using+SHAP-Based+Composite+Index%3A+Focus+on+Oman，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14219，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14219&send_immediately=true&force_search=false)

**原文摘要:** As nations seek sustainable alternatives to fossil fuels, green hydrogen has
emerged as a promising strategic pathway toward decarbonisation, particularly
in solar-rich arid regions. However, identifying optimal locations for hydrogen
production requires the integration of complex environmental, atmospheric, and
infrastructural factors, often compounded by limited availability of direct
hydrogen yield data. This study presents a novel Artificial Intelligence (AI)
framework for computing green hydrogen yield and site suitability index using
mean absolute SHAP (SHapley Additive exPlanations) values. This framework
consists of a multi-stage pipeline of unsupervised multi-variable clustering,
supervised machine learning classifier and SHAP algorithm. The pipeline trains
on an integrated meteorological, topographic and temporal dataset and the
results revealed distinct spatial patterns of suitability and relative
influence of the variables. With model predictive accuracy of 98%, the result
also showed that water proximity, elevation and seasonal variation are the most
influential factors determining green hydrogen site suitability in Oman with
mean absolute shap values of 2.470891, 2.376296 and 1.273216 respectively.
Given limited or absence of ground-truth yield data in many countries that have
green hydrogen prospects and ambitions, this study offers an objective and
reproducible alternative to subjective expert weightings, thus allowing the
data to speak for itself and potentially discover novel latent groupings
without pre-imposed assumptions. This study offers industry stakeholders and
policymakers a replicable and scalable tool for green hydrogen infrastructure
planning and other decision making in data-scarce regions.

</details>


### [16] [Domain Generalization via Pareto Optimal Gradient Matching](https://arxiv.org/abs/2507.14227)
*Khoi Do, Duong Nguyen, Nam-Khanh Le, Quoc-Viet Pham, Binh-Son Hua, Won-Joo Hwang*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的Pareto Optimality Gradient Matching (POGM)方法，以解决梯度匹配中的领域泛化问题，该方法在多个数据集上展示了竞争力，并实现了计算效率。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于梯度的领域泛化方法存在两个主要挑战：1）最小化梯度经验距离或梯度内积（GIP）导致不同领域的梯度波动；2）直接应用于联合损失函数的梯度学习会导致高计算开销。

**方法:** 提出了Pareto Optimality Gradient Matching (POGM)方法，利用梯度轨迹作为收集的数据，并在meta-learner中应用独立训练，在meta更新中最大化GIP，同时限制学习到的梯度偏离经验风险最小化梯度轨迹太远。

**结果:** 实验评估表明，POGM在来自DomainBed的数据集上展示了与其它基线方法竞争的结果，并且实现了计算效率。

**结论:** POGM方法可以结合所有领域的知识，避免任何特定领域的梯度波动，从而解决了现有方法中存在的挑战并提高了计算效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Domain+Generalization+via+Pareto+Optimal+Gradient+Matching，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14227，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14227&send_immediately=true&force_search=false)

**原文摘要:** In this study, we address the gradient-based domain generalization problem,
where predictors aim for consistent gradient directions across different
domains. Existing methods have two main challenges. First, minimization of
gradient empirical distance or gradient inner products (GIP) leads to gradient
fluctuations among domains, thereby hindering straightforward learning. Second,
the direct application of gradient learning to the joint loss function can
incur high computation overheads due to second-order derivative approximation.
To tackle these challenges, we propose a new Pareto Optimality Gradient
Matching (POGM) method. In contrast to existing methods that add gradient
matching as regularization, we leverage gradient trajectories as collected data
and apply independent training at the meta-learner. In the meta-update, we
maximize GIP while limiting the learned gradient from deviating too far from
the empirical risk minimization gradient trajectory. By doing so, the aggregate
gradient can incorporate knowledge from all domains without suffering gradient
fluctuation towards any particular domain. Experimental evaluations on datasets
from DomainBed demonstrate competitive results yielded by POGM against other
baselines while achieving computational efficiency.

</details>


### [17] [A million-scale dataset and generalizable foundation model for nanomaterial-protein interactions](https://arxiv.org/abs/2507.14245)
*Hengjie Yu, Kenneth A. Dawson, Haiyun Yang, Shuya Liu, Yan Yan, Yaochu Jin*

**主要类别:** cs.LG

**AI概要:** 本文提出了NanoPro-3M数据集和NanoProFormer模型，以预测纳米材料与蛋白质的亲和力，展示了多模态学习在处理缺失特征和未见样本上的优势。


<details>
  <summary>更多</summary>
  
**动机:** 解锁纳米材料在医学和环境科学中的潜力需要理解它们与蛋白质的相互作用，而这一领域目前受到有限的数据集和现有模型的泛化能力不足的阻碍。

**方法:** 作者提出了一种名为NanoProFormer的基础模型，该模型通过多模态表示学习来预测纳米材料与蛋白质之间的亲和性，并使用了迄今为止最大的纳米材料-蛋白质交互数据集NanoPro-3M进行训练。

**结果:** 多模态建模显著优于单模态方法，能够识别冠状形成的关键决定因素，并适用于一系列下游任务，包括零样本推理和微调。

**结论:** 这项工作为高性能和广义化的纳米材料-蛋白质交互预测建立了坚实的基础，减少了实验依赖并加速了各种体外应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+million-scale+dataset+and+generalizable+foundation+model+for+nanomaterial-protein+interactions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14245，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14245&send_immediately=true&force_search=false)

**原文摘要:** Unlocking the potential of nanomaterials in medicine and environmental
science hinges on understanding their interactions with proteins, a complex
decision space where AI is poised to make a transformative impact. However,
progress has been hindered by limited datasets and the restricted
generalizability of existing models. Here, we propose NanoPro-3M, the largest
nanomaterial-protein interaction dataset to date, comprising over 3.2 million
samples and 37,000 unique proteins. Leveraging this, we present NanoProFormer,
a foundational model that predicts nanomaterial-protein affinities through
multimodal representation learning, demonstrating strong generalization,
handling missing features, and unseen nanomaterials or proteins. We show that
multimodal modeling significantly outperforms single-modality approaches and
identifies key determinants of corona formation. Furthermore, we demonstrate
its applicability to a range of downstream tasks through zero-shot inference
and fine-tuning. Together, this work establishes a solid foundation for
high-performance and generalized prediction of nanomaterial-protein interaction
endpoints, reducing experimental reliance and accelerating various in vitro
applications.

</details>


### [18] [Linearized Diffusion Map](https://arxiv.org/abs/2507.14257)
*Julio Candanedo*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的线性降维方法——线性扩散图（LDM），通过综合非线性方法的几何直觉和线性嵌入的计算简便性，展示了在特定数据集上的优越性能，并且支持非负矩阵分解。


<details>
  <summary>更多</summary>
  
**动机:** 现有的线性降维方法如PCA虽然简单高效，但在处理具有明确流形结构的数据时可能不是最优选择。为了结合非线性方法的几何优势与线性方法的效率，提出了线性扩散图（LDM）。

**方法:** LDM是通过对扩散核进行线性近似而构建的。它保留了基于扩散的非线性方法的几何理解，同时保持了线性嵌入的计算简易性和可解释性。此外，LDM的核矩阵完全正定，这使得可以直接应用非负矩阵分解。

**结果:** 实验表明，对于表现出明显流形结构的数据集，尤其是在高维情况下，LDM嵌入的表现优于PCA；而在主要由方差或噪声主导的情景中，PCA仍然更优。

**结论:** LDM作为一种有价值的线性降维技术，不仅理论上有吸引力，在实际应用中也显示出扩展潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Linearized+Diffusion+Map，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14257，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14257&send_immediately=true&force_search=false)

**原文摘要:** We introduce the Linearized Diffusion Map (LDM), a novel linear
dimensionality reduction method constructed via a linear approximation of the
diffusion-map kernel. LDM integrates the geometric intuition of diffusion-based
nonlinear methods with the computational simplicity, efficiency, and
interpretability inherent in linear embeddings such as PCA and classical MDS.
Through comprehensive experiments on synthetic datasets (Swiss roll and
hyperspheres) and real-world benchmarks (MNIST and COIL-20), we illustrate that
LDM captures distinct geometric features of datasets compared to PCA, offering
complementary advantages. Specifically, LDM embeddings outperform PCA in
datasets exhibiting explicit manifold structures, particularly in
high-dimensional regimes, whereas PCA remains preferable in scenarios dominated
by variance or noise. Furthermore, the complete positivity of LDM's kernel
matrix allows direct applicability of Non-negative Matrix Factorization (NMF),
suggesting opportunities for interpretable latent-structure discovery. Our
analysis positions LDM as a valuable new linear dimensionality reduction
technique with promising theoretical and practical extensions.

</details>


### [19] [A Simple "Try Again" Can Elicit Multi-Turn LLM Reasoning](https://arxiv.org/abs/2507.14295)
*Licheng Liu, Zihan Wang, Linjie Li, Chenwei Xu, Yiping Lu, Han Liu, Avirup Sil, Manling Li*

**主要类别:** cs.LG

**AI概要:** 该研究发现，通过使用仅包含一元反馈（如“让我们再试一次”）的多轮强化学习训练大型推理模型，可以提高单轮和多轮推理性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的RL方法在单轮范式下训练大型推理模型，但这些模型在多轮推理中表现不佳，难以根据上下文反馈进行修正。因此，作者希望探究大型推理模型是否可以在多轮背景下学习反思答案。

**方法:** 作者引入了一种名为UFO（Unary Feedback as Observation）的方法，用于强化学习。UFO利用最小且常见的一元用户反馈，在迭代问题解决过程中进行训练。此外，还设计了奖励结构，以指导模型在每轮产生谨慎和深思熟虑的答案。

**结果:** 实验结果表明，带有UFO的RL训练保持了单轮性能，并将多轮推理准确性提高了多达14％。

**结论:** UFO方法能够使语言模型更好地响应多轮问题解决中的反馈，同时通过设计的奖励结构减少正确回答所需的轮数，并鼓励错误发生时的多样化推理。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Simple+%22Try+Again%22+Can+Elicit+Multi-Turn+LLM+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14295，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14295&send_immediately=true&force_search=false)

**原文摘要:** Multi-turn problem solving is critical yet challenging for Large Reasoning
Models (LRMs) to reflect on their reasoning and revise from feedback. Existing
Reinforcement Learning (RL) methods train large reasoning models on a
single-turn paradigm with verifiable rewards. However, we observe that models
trained with existing RL paradigms often lose their ability to solve problems
across multiple turns and struggle to revise answers based on contextual
feedback, leading to repetitive responses. We ask: can LRMs learn to reflect
their answers in a multi-turn context? In this work, we find that training
models with multi-turn RL using only unary feedback (e.g., "Let's try again")
after wrong answers can improve both single-turn performance and multi-turn
reasoning. We introduce Unary Feedback as Observation (UFO) for reinforcement
learning, which uses minimal yet common unary user feedback during iterative
problem solving. It can be easily applied to existing single-turn RL training
setups. Experimental results show that RL training with UFO keeps single-turn
performance and improves multi-turn reasoning accuracy by up to 14%, enabling
language models to better react to feedback in multi-turn problem solving. To
further minimize the number of turns needed for a correct answer while
encouraging diverse reasoning when mistakes occur, we design reward structures
that guide models to produce careful and deliberate answers in each turn. Code:
https://github.com/lichengliu03/unary-feedback

</details>


### [20] [FedStrategist: A Meta-Learning Framework for Adaptive and Robust Aggregation in Federated Learning](https://arxiv.org/abs/2507.14322)
*Md Rafid Haque, Abu Raihan Mostofa Kamal, Md. Azam Hossain*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的元学习框架FedStrategist，通过动态选择最优聚合规则来增强联邦学习的鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 联邦学习（FL）提供了一种保护隐私的协作AI范式，但其去中心化特性使其容易受到模型中毒攻击。现有的静态防御措施在自适应对手或异构数据环境中往往无效。

**方法:** 引入了FedStrategist框架，将鲁棒聚合问题重新定义为实时、成本感知的控制问题，并设计了一个轻量级的情境强盗代理，根据实时诊断指标动态选择最佳聚合规则。

**结果:** 实验表明，没有单一的静态规则是普遍最优的，而自适应代理能够学习出在不同场景中表现更好的策略，并能通过“风险容忍度”参数来平衡性能和安全性。

**结论:** 本研究提供了一种创建弹性智能去中心化AI系统的新方法，强调了在性能和安全性之间进行明确权衡的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FedStrategist%3A+A+Meta-Learning+Framework+for+Adaptive+and+Robust+Aggregation+in+Federated+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14322，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14322&send_immediately=true&force_search=false)

**原文摘要:** Federated Learning (FL) offers a paradigm for privacy-preserving
collaborative AI, but its decentralized nature creates significant
vulnerabilities to model poisoning attacks. While numerous static defenses
exist, their effectiveness is highly context-dependent, often failing against
adaptive adversaries or in heterogeneous data environments. This paper
introduces FedStrategist, a novel meta-learning framework that reframes robust
aggregation as a real-time, cost-aware control problem. We design a lightweight
contextual bandit agent that dynamically selects the optimal aggregation rule
from an arsenal of defenses based on real-time diagnostic metrics. Through
comprehensive experiments, we demonstrate that no single static rule is
universally optimal. We show that our adaptive agent successfully learns
superior policies across diverse scenarios, including a ``Krum-favorable"
environment and against a sophisticated "stealth" adversary designed to
neutralize specific diagnostic signals. Critically, we analyze the paradoxical
scenario where a non-robust baseline achieves high but compromised accuracy,
and demonstrate that our agent learns a conservative policy to prioritize model
integrity. Furthermore, we prove the agent's policy is controllable via a
single "risk tolerance" parameter, allowing practitioners to explicitly manage
the trade-off between performance and security. Our work provides a new,
practical, and analyzable approach to creating resilient and intelligent
decentralized AI systems.

</details>


### [21] [Rethinking Individual Fairness in Deepfake Detection](https://arxiv.org/abs/2507.14326)
*Aryana Hou, Li Lin, Justin Li, Shu Hu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的框架，以解决深度伪造检测中的个体公平性问题。


<details>
  <summary>更多</summary>
  
**动机:** 生成式AI模型虽然大大提高了合成媒体的真实性，但其被滥用为复杂的深度伪造（DeepFakes）带来了重大风险。尽管在深度伪造检测方面取得了进展，但在公平性方面仍然存在不足，特别是个体公平性未得到充分研究。

**方法:** 研究人员提出了第一个通用框架，可以集成到现有的深度伪造检测器中，以增强个体公平性和泛化能力。

**结果:** 广泛的实验表明，该方法显著改善了个体公平性，并保持了强大的检测性能，超过了最先进的方法。

**结论:** 代码可在https://github.com/Purdue-M2/Individual-Fairness-Deepfake-Detection获得。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Rethinking+Individual+Fairness+in+Deepfake+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14326，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14326&send_immediately=true&force_search=false)

**原文摘要:** Generative AI models have substantially improved the realism of synthetic
media, yet their misuse through sophisticated DeepFakes poses significant
risks. Despite recent advances in deepfake detection, fairness remains
inadequately addressed, enabling deepfake markers to exploit biases against
specific populations. While previous studies have emphasized group-level
fairness, individual fairness (i.e., ensuring similar predictions for similar
individuals) remains largely unexplored. In this work, we identify for the
first time that the original principle of individual fairness fundamentally
fails in the context of deepfake detection, revealing a critical gap previously
unexplored in the literature. To mitigate it, we propose the first
generalizable framework that can be integrated into existing deepfake detectors
to enhance individual fairness and generalization. Extensive experiments
conducted on leading deepfake datasets demonstrate that our approach
significantly improves individual fairness while maintaining robust detection
performance, outperforming state-of-the-art methods. The code is available at
https://github.com/Purdue-M2/Individual-Fairness-Deepfake-Detection.

</details>


### [22] [Development and Deployment of Hybrid ML Models for Critical Heat Flux Prediction in Annulus Geometries](https://arxiv.org/abs/2507.14332)
*Aidan Furlong, Xingang Zhao, Robert Salko, Xu Wu*

**主要类别:** cs.LG

**AI概要:** 本研究开发、部署和验证了四个机器学习模型，以使用CTF子通道代码预测环形几何中的临界热通量（CHF）。通过与三种经验关联模型对比，并使用577个实验数据点进行训练和测试，发现ML驱动的模型平均相对误差低于3.5%，显著优于经验模型。


<details>
  <summary>更多</summary>
  
**动机:** 准确预测压水和沸水反应堆中的临界热通量（CHF）对于安全分析至关重要。传统方法如经验相关性和查找表在解释性、数据稀缺弹性和适用范围上存在局限性，因此需要更精确的方法来提高预测的可靠性。

**方法:** 研究人员选择了三个经验关联模型作为基准，并开发了四个机器学习模型，利用来自四个数据集的577个实验数据点对这些模型进行了训练和测试。然后将机器学习模型的预测结果与经验模型的结果进行了比较。

**结果:** 机器学习驱动的模型实现了平均相对误差低于3.5%的预测精度，且没有超过10%误差范围的数据点。相比之下，经验模型的平均相对误差超过26%。

**结论:** 混合机器学习模型在预测环形几何结构中的临界热通量方面显著优于传统经验模型，表明这种方法可以为反应堆的安全分析提供更可靠的工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Development+and+Deployment+of+Hybrid+ML+Models+for+Critical+Heat+Flux+Prediction+in+Annulus+Geometries，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14332，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14332&send_immediately=true&force_search=false)

**原文摘要:** Accurate prediction of critical heat flux (CHF) is an essential component of
safety analysis in pressurized and boiling water reactors. To support reliable
prediction of this quantity, several empirical correlations and lookup tables
have been constructed from physical experiments over the past several decades.
With the onset of accessible machine learning (ML) frameworks, multiple
initiatives have been established with the goal of predicting CHF more
accurately than these traditional methods. While purely data-driven surrogate
modeling has been extensively investigated, these approaches lack
interpretability, lack resilience to data scarcity, and have been developed
mostly using data from tube experiments. As a result, bias-correction hybrid
approaches have become increasingly popular, which correct initial
"low-fidelity" estimates provided by deterministic base models by using
ML-predicted residuals. This body of work has mostly considered round tube
geometries; annular geometry-specific ML models have not yet been deployed in
thermal hydraulic codes. This study developed, deployed, and validated four ML
models to predict CHF in annular geometries using the CTF subchannel code.
Three empirical correlation models, Biasi, Bowring, and Katto, were used as
base models for comparison. The ML models were trained and tested using 577
experimental annulus data points from four datasets: Becker, Beus, Janssen, and
Mortimore. Baseline CHF predictions were obtained from the empirical
correlations, with mean relative errors above 26%. The ML-driven models
achieved mean relative errors below 3.5%, with no more than one point exceeding
the 10% error envelope. In all cases, the hybrid ML models significantly
outperformed their empirical counterparts.

</details>


### [23] [Influence Functions for Preference Dataset Pruning](https://arxiv.org/abs/2507.14344)
*Daniel Fein, Gabriela Aranguiz-Dias*

**主要类别:** cs.LG

**AI概要:** 本文通过影响函数过滤方法对TL;DR数据集进行处理，发现可以提高再训练的准确性，并且梯度相似性在检测有用训练样本方面优于影响函数。


<details>
  <summary>更多</summary>
  
**动机:** 由于用于调整语言模型行为的数据集通常存在噪声，特别是人类偏好数据集。小规模的后训练数据集和参数高效的微调方法使得可以使用影响函数近似来检测和去除对验证集性能有害的训练样本。

**方法:** 作者采用共轭梯度近似的影响函数来过滤数据集，并比较了影响函数和梯度相似性在识别有用和有害训练样本上的表现。

**结果:** 影响函数过滤在移除10%的训练样本后，带来了1.5%的小幅再训练准确率提升；同时，梯度相似性在检测有用训练样本上表现更佳。

**结论:** 局部曲率对于检测有害训练样本很重要，但对于识别有用样本则不是那么重要。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Influence+Functions+for+Preference+Dataset+Pruning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14344，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14344&send_immediately=true&force_search=false)

**原文摘要:** Language models are commonly fine-tuned via reinforcement learning to alter
their behavior or elicit new capabilities. Datasets used for these purposes,
and particularly human preference datasets, are often noisy. The relatively
small size post-training datasets, combined with parameter-efficient
fine-tuning methods, enable the use of influence functions approximations to
detect and prune training examples that are harmful to performance on a
validation set. In this work, we adapt the TL;DR dataset for reward model
training to demonstrate how conjugate-gradient approximated influence functions
can be used to filter datasets. In our experiments, influence function
filtering yields a small retraining accuracy uplift of 1.5% after removing 10%
of training examples. We also show that gradient similarity outperforms
influence functions for detecting helpful training examples. This suggests that
local curvature is important for detecting harmful training examples, but less
so for identifying helpful examples.

</details>


### [24] [Solo Connection: A Parameter Efficient Fine-Tuning Technique for Transformers](https://arxiv.org/abs/2507.14353)
*Harsh Nilesh Pathak, Randy Paffenroth*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的参数高效微调方法Solo Connection，相较于LoRA，在E2E自然语言生成基准上表现更好，并显著减少了可训练参数的数量。该方法通过引入可训练的线性变换，实现任务特定表示与零向量之间的渐进插值。


<details>
  <summary>更多</summary>
  
**动机:** 现有的参数高效微调方法，如LoRA，主要集中在调整生成式预训练转换器（GPT2）中单个解码器块内的注意力权重矩阵。然而，随着解码器块数量的增加，有必要重新审视跳过连接在微调期间的使用方式。

**方法:** 提出了一个新的方法——Solo Connection，它在解码器块级别上调整表示，而不是修改单个权重矩阵。此外，还引入了一个可训练的线性变换，该变换逐渐在零向量和任务特定表示之间进行插值，从而实现平稳和稳定的适应。

**结果:** Solo Connection不仅在E2E自然语言生成基准上优于LoRA，而且将可训练参数的数量减少了59%（相对于LoRA）和超过99%（相对于GPT2的完全微调）。

**结论:** Solo Connection作为一种新的参数高效微调方法，在提高模型性能的同时，大幅减少了可训练参数的数量。这表明，在未来的研究中，应该更加关注如何有效地利用跳过连接来增强大型语言模型对新任务的适应能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Solo+Connection%3A+A+Parameter+Efficient+Fine-Tuning+Technique+for+Transformers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14353，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14353&send_immediately=true&force_search=false)

**原文摘要:** Parameter efficient fine tuning (PEFT) is a versatile and extensible approach
for adapting a Large Language Model (LLM) for newer tasks. One of the most
prominent PEFT approaches, Low Rank Adaptation (LoRA), primarily focuses on
adjusting the attention weight matrices within individual decoder blocks of a
Generative Pre trained Transformer (GPT2). In contrast, we introduce Solo
Connection a novel method that adapts the representation at the decoder-block
level rather than modifying individual weight matrices. Not only does Solo
Connection outperform LoRA on E2E natural language generation benchmarks, but
it also reduces the number of trainable parameters by 59% relative to LoRA and
by more than 99% compared to full fine-tuning of GPT2, an early version of
Large Language Models (LLMs). Solo Connection is also motivated by homotopy
theory: we introduce a trainable linear transformation that gradually
interpolates between a zero vector and the task-specific representation,
enabling smooth and stable adaptation over time. While skip connections in the
original 12 layer GPT2 are typically confined to individual decoder blocks,
subsequent GPT2 variants scale up to 48 layers, and even larger language models
can include 128 or more decoder blocks. These expanded architectures underscore
the need to revisit how skip connections are employed during fine-tuning. This
paper focuses on long skip connections that link outputs of different decoder
blocks, potentially enhancing the model's ability to adapt to new tasks while
leveraging pre-trained knowledge.

</details>


### [25] [Incremental Causal Graph Learning for Online Cyberattack Detection in Cyber-Physical Infrastructures](https://arxiv.org/abs/2507.14387)
*Arun Vignesh Malarkkan, Dongjie Wang, Haoyue Bai, Yanjie Fu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为INCADET的新框架，用于实时网络攻击检测的增量因果图学习。它通过动态捕捉系统行为变化并持续更新因果图来克服传统方法的局限性。


<details>
  <summary>更多</summary>
  
**动机:** 传统的实时异常检测技术由于其对高数据方差和类别不平衡的统计敏感性，常常导致过多的误报。现有基于离线因果图的方法需要静态历史数据，无法适应实时环境中的动态数据分布变化，并且存在灾难性遗忘的风险。

**方法:** INCADET框架包括三个模块：1) 早期症状检测：使用边缘权重分布在连续因果图之间的差异来检测系统状态的变化；2) 增量因果图学习：利用经验重放和边缘强化不断细化因果结构，同时保留先前知识；3) 因果图分类：使用图卷积网络（GCNs）根据所学因果图对系统状态进行分类。

**结果:** 在真实世界关键基础设施数据集上的广泛实验证明，与静态因果和深度时序基线相比，INCADET在演变攻击场景中实现了更高的准确性、鲁棒性和适应性。

**结论:** INCADET提供了一种有效的方法来捕获复杂系统相互依赖关系，并适应演变的攻击模式，从而提高了实时关键基础设施的安全性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Incremental+Causal+Graph+Learning+for+Online+Cyberattack+Detection+in+Cyber-Physical+Infrastructures，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14387，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14387&send_immediately=true&force_search=false)

**原文摘要:** The escalating threat of cyberattacks on real-time critical infrastructures
poses serious risks to public safety, demanding detection methods that
effectively capture complex system interdependencies and adapt to evolving
attack patterns. Traditional real-time anomaly detection techniques often
suffer from excessive false positives due to their statistical sensitivity to
high data variance and class imbalance. To address these limitations, recent
research has explored modeling causal relationships among system components.
However, prior work mainly focuses on offline causal graph-based approaches
that require static historical data and fail to generalize to real-time
settings. These methods are fundamentally constrained by: (1) their inability
to adapt to dynamic shifts in data distribution without retraining, and (2) the
risk of catastrophic forgetting when lacking timely supervision in live
systems. To overcome these challenges, we propose INCADET, a novel framework
for incremental causal graph learning tailored to real-time cyberattack
detection. INCADET dynamically captures evolving system behavior by
incrementally updating causal graphs across streaming time windows. The
framework comprises three modules: 1) Early Symptom Detection: Detects
transitions in system status using divergence in edge-weight distributions
across sequential causal graphs. 2) Incremental Causal Graph Learning:
Leverages experience replay and edge reinforcement to continually refine causal
structures while preserving prior knowledge. 3) Causal Graph Classification:
Employs Graph Convolutional Networks (GCNs) to classify system status using the
learned causal graphs. Extensive experiments on real-world critical
infrastructure datasets demonstrate that INCADET achieves superior accuracy,
robustness, and adaptability compared to both static causal and deep temporal
baselines in evolving attack scenarios.

</details>


### [26] [It's Not That Simple. An Analysis of Simple Test-Time Scaling](https://arxiv.org/abs/2507.14419)
*Guojun Wu*

**主要类别:** cs.LG

**AI概要:** 简单测试时缩放主要通过限制最大长度来实现，这种方式影响模型性能。而通过在长CoT数据上微调或添加“等待”以扩展计算量的方式对缩放行为影响不大，并可能导致不一致的结果。


<details>
  <summary>更多</summary>
  
**动机:** 该研究旨在分析简单测试时缩放方法的有效性，并探讨其与直接扩展测试时计算资源的方法之间的区别，以期更好地理解如何提高模型性能。

**方法:** 研究者们通过两种方式对模型进行缩放：1) 通过设置最大长度来缩小规模；2) 在模型即将结束生成时迭代附加“Wait”以扩大规模。此外，还尝试了在长CoT数据上对模型进行微调。

**结果:** 发现简单测试时缩放行为主要是由于设置了最大长度造成的。相比之下，在长CoT数据上的微调对缩放行为没有显著影响，而通过附加“Wait”来扩展计算量则导致了结果的不一致性。

**结论:** 简单测试时缩放虽然可以通过限制最大长度轻松复制o1模型的缩放行为，但其目标应该是解锁更高的性能，而不是仅仅重现缩放行为的外观。直接学习自然扩展测试时计算（如o1-like模型）可以在实际性能上超越简单缩放方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是It%27s+Not+That+Simple.+An+Analysis+of+Simple+Test-Time+Scaling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14419，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14419&send_immediately=true&force_search=false)

**原文摘要:** Prior work proposed simple test-time scaling, a method for replicating this
scaling behavior with models distilled from o1-like models by manually
controlling test-time compute: either scaling down by enforcing a maximum
length or scaling up by iteratively appending "Wait" when the model is about to
terminate its generation. This paper presents an analysis of simple test-time
scaling and finds that the scaling behavior is largely attributed to scaling
down by enforcing a maximum length. In contrast, fine-tuning on long CoT data
distilled from o1-like models has no significant impact on scaling behavior,
and scaling up by appending "Wait" leads to inconsistencies, as the model may
oscillate between solutions. A key distinction exists between scaling down by
enforcing a maximum length and scaling up test-time compute in o1-like models,
such as DeepSeek-R1\@. These models are typically allowed to utilize as much
compute as needed, with the only constraint being the model's maximum supported
length. By learning to naturally scale up test-time compute during
reinforcement learning, o1-like models surpass their peak performance when
scaling up. In contrast, simple test-time scaling progressively imposes a lower
upper limit on model performance as it scales down. While replicating the
test-time scaling behavior of o1 models can be straightforward by scaling down,
it is crucial to recognize that the goal of scaling test-time compute is to
unlock higher performance -- beyond what the model could originally achieve --
rather than merely reproducing the appearance of scaling behavior.

</details>


### [27] [Deep RL Dual Sourcing Inventory Management with Supply and Capacity Risk Awareness](https://arxiv.org/abs/2507.14446)
*Feng Liu, Ying Liu, Carson Eisenach*

**主要类别:** cs.LG

**AI概要:** 本文研究了如何通过利用干预模型，高效地将强化学习应用于大规模随机优化问题。提出的方法在供应链优化的实际应用中显示出了良好的效果，并且将复杂的物理约束分解为可扩展的深度学习模块，从而提高了性能。


<details>
  <summary>更多</summary>
  
**动机:** 动机是解决大型随机优化问题的挑战，特别是在具有复杂物理约束的情况下，如多源多周期库存管理问题。现有的方法直接建模这些约束条件到RL优化问题中，这可能是低效和难以处理的。

**方法:** 该方法使用预先训练的深度学习模型来模拟和组合随机过程，以更好地探索解空间。此外，还引入了一种约束协调机制，用于预测跨产品约束下的双重成本。

**结果:** 该方法在大型真实世界数据集上表现出改进的性能。

**结论:** 该方法能够更有效地解决大型随机优化问题，并提出了未来的研究方向，以进一步探讨此类模型的效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Deep+RL+Dual+Sourcing+Inventory+Management+with+Supply+and+Capacity+Risk+Awareness，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14446，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14446&send_immediately=true&force_search=false)

**原文摘要:** In this work, we study how to efficiently apply reinforcement learning (RL)
for solving large-scale stochastic optimization problems by leveraging
intervention models. The key of the proposed methodology is to better explore
the solution space by simulating and composing the stochastic processes using
pre-trained deep learning (DL) models. We demonstrate our approach on a
challenging real-world application, the multi-sourcing multi-period inventory
management problem in supply chain optimization. In particular, we employ deep
RL models for learning and forecasting the stochastic supply chain processes
under a range of assumptions. Moreover, we also introduce a constraint
coordination mechanism, designed to forecast dual costs given the
cross-products constraints in the inventory network. We highlight that instead
of directly modeling the complex physical constraints into the RL optimization
problem and solving the stochastic problem as a whole, our approach breaks down
those supply chain processes into scalable and composable DL modules, leading
to improved performance on large real-world datasets. We also outline open
problems for future research to further investigate the efficacy of such
models.

</details>


### [28] [ReDiSC: A Reparameterized Masked Diffusion Model for Scalable Node Classification with Structured Predictions](https://arxiv.org/abs/2507.14484)
*Yule Li, Yifeng Lu, Zhen Wang, Zhewei Wei, Yaliang Li, Bolin Ding*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的结构化节点分类模型ReDiSC，该模型在图神经网络的基础上，通过重新参数化的掩码扩散模型估计节点标签的联合分布。实验表明，ReDiSC在同性和异性图中均优于或匹敌现有的最先进方法，并且可以扩展到大规模数据集。


<details>
  <summary>更多</summary>
  
**动机:** 尽管图神经网络（GNN）在节点分类任务上取得了成功，但大多数现有方法假设节点标签之间的条件独立性，这与图中节点标签实际上相互关联的事实相矛盾。因此，需要一种能够进行结构化预测的方法来改进节点分类。

**方法:** 提出了ReDiSC（用于结构化节点分类的重新参数化掩码扩散模型），它使用重新参数化的掩码扩散模型来估计节点标签的联合分布，该模型通过变分期望最大化框架学习。此外，还分析了ReDiSC在E步中的效率优势，并将其M步目标与流行的GNN和标签传播混合方法联系起来。

**结果:** 广泛的实验证明，ReDiSC在同性和异性图中均达到了优越或高度有竞争力的表现，并且可以有效扩展到大型数据集，而以前的结构化扩散方法由于计算限制无法做到这一点。

**结论:** ReDiSC为结构化节点分类任务提供了一个有效的解决方案，不仅在性能上超越了现有方法，而且在处理大规模数据集方面具有显著的实际优势。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ReDiSC%3A+A+Reparameterized+Masked+Diffusion+Model+for+Scalable+Node+Classification+with+Structured+Predictions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14484，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14484&send_immediately=true&force_search=false)

**原文摘要:** In recent years, graph neural networks (GNN) have achieved unprecedented
successes in node classification tasks. Although GNNs inherently encode
specific inductive biases (e.g., acting as low-pass or high-pass filters), most
existing methods implicitly assume conditional independence among node labels
in their optimization objectives. While this assumption is suitable for
traditional classification tasks such as image recognition, it contradicts the
intuitive observation that node labels in graphs remain correlated, even after
conditioning on the graph structure. To make structured predictions for node
labels, we propose ReDiSC, namely, Reparameterized masked Diffusion model for
Structured node Classification. ReDiSC estimates the joint distribution of node
labels using a reparameterized masked diffusion model, which is learned through
the variational expectation-maximization (EM) framework. Our theoretical
analysis shows the efficiency advantage of ReDiSC in the E-step compared to
DPM-SNC, a state-of-the-art model that relies on a manifold-constrained
diffusion model in continuous domain. Meanwhile, we explicitly link ReDiSC's
M-step objective to popular GNN and label propagation hybrid approaches.
Extensive experiments demonstrate that ReDiSC achieves superior or highly
competitive performance compared to state-of-the-art GNN, label propagation,
and diffusion-based baselines across both homophilic and heterophilic graphs of
varying sizes. Notably, ReDiSC scales effectively to large-scale datasets on
which previous structured diffusion methods fail due to computational
constraints, highlighting its significant practical advantage in structured
node classification tasks.

</details>


### [29] [Federated Reinforcement Learning in Heterogeneous Environments](https://arxiv.org/abs/2507.14487)
*Ukjo Hwang, Songnam Hong*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的联邦强化学习框架FRL-EH，引入了鲁棒的全局目标函数，并提出了算法FedRQ及其扩展版本以适应连续状态空间。实验证明该方法在异构环境中表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 现有的联邦强化学习（FRL）研究大多假设所有代理人的环境是同质的，但现实世界中的环境往往是统计上异构的。因此需要一种能处理环境异构性的FRL框架，同时保护各代理人本地数据隐私。

**方法:** 作者们提出了一种名为FedRQ的表格型FRL算法，并通过理论证明了它在给定的全局目标函数下可以渐进收敛到最优策略。为了应对连续状态空间的问题，进一步将FedRQ扩展，使用expectile损失来最小化值函数。

**结果:** 广泛的实证评估表明，所提出的FRL算法在各种异构环境中具有高效性和鲁棒性，性能优于当前最先进的FRL算法。

**结论:** 通过引入一个鲁棒的FRL-EH框架和开发出有效的算法FedRQ及它的连续状态空间扩展，本研究为处理环境异构性的联邦强化学习提供了一个新的视角。实验结果支持了新框架和算法的有效性和优越性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Federated+Reinforcement+Learning+in+Heterogeneous+Environments，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14487，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14487&send_immediately=true&force_search=false)

**原文摘要:** We investigate a Federated Reinforcement Learning with Environment
Heterogeneity (FRL-EH) framework, where local environments exhibit statistical
heterogeneity. Within this framework, agents collaboratively learn a global
policy by aggregating their collective experiences while preserving the privacy
of their local trajectories. To better reflect real-world scenarios, we
introduce a robust FRL-EH framework by presenting a novel global objective
function. This function is specifically designed to optimize a global policy
that ensures robust performance across heterogeneous local environments and
their plausible perturbations. We propose a tabular FRL algorithm named FedRQ
and theoretically prove its asymptotic convergence to an optimal policy for the
global objective function. Furthermore, we extend FedRQ to environments with
continuous state space through the use of expectile loss, addressing the key
challenge of minimizing a value function over a continuous subset of the state
space. This advancement facilitates the seamless integration of the principles
of FedRQ with various Deep Neural Network (DNN)-based RL algorithms. Extensive
empirical evaluations validate the effectiveness and robustness of our FRL
algorithms across diverse heterogeneous environments, consistently achieving
superior performance over the existing state-of-the-art FRL algorithms.

</details>


### [30] [Glitches in Decision Tree Ensemble Models](https://arxiv.org/abs/2507.14492)
*Satyankar Chandra, Ashutosh Gupta, Kaushik Mallik, Krishna Shankaranarayanan, Namrita Varshney*

**主要类别:** cs.LG

**AI概要:** 这篇论文讨论了机器学习模型中一种新的不可靠行为来源——glitches，并提出了一种针对GBDT模型的glitches搜索算法。


<details>
  <summary>更多</summary>
  
**动机:** 随着越来越多的关键决策任务被委托给机器学习模型，确保这些模型的决策是可信和可靠的变得至关重要。作者们识别出一种新的不可靠行为来源——glitches，这可能会严重影响具有陡峭决策边界的AI模型的可靠性。

**方法:** 作者们首先为glitches提供了一个正式的定义，并使用文献中的知名模型和数据集证明了它们的普遍存在。然后，他们针对广泛使用的梯度提升决策树（GBDT）模型进行了glitches的算法搜索。他们证明了对于深度达到4的树来说，检测glitches的问题已经是NP完全问题。他们的glitches搜索算法使用了MILP编码来解决问题。

**结果:** 通过一组来自文献的广泛使用的GBDT基准测试，证明了该算法的有效性和计算可行性。

**结论:** glitches在输入空间的小邻域内存在，其中模型的输出相对于输入的小变化突然振荡。这通常表明在发现它们的邻域附近可能存在模型不一致。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Glitches+in+Decision+Tree+Ensemble+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14492，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14492&send_immediately=true&force_search=false)

**原文摘要:** Many critical decision-making tasks are now delegated to machine-learned
models, and it is imperative that their decisions are trustworthy and reliable,
and their outputs are consistent across similar inputs. We identify a new
source of unreliable behaviors-called glitches-which may significantly impair
the reliability of AI models having steep decision boundaries. Roughly
speaking, glitches are small neighborhoods in the input space where the model's
output abruptly oscillates with respect to small changes in the input. We
provide a formal definition of glitches, and use well-known models and datasets
from the literature to demonstrate that they have widespread existence and
argue they usually indicate potential model inconsistencies in the neighborhood
of where they are found. We proceed to the algorithmic search of glitches for
widely used gradient-boosted decision tree (GBDT) models. We prove that the
problem of detecting glitches is NP-complete for tree ensembles, already for
trees of depth 4. Our glitch-search algorithm for GBDT models uses an MILP
encoding of the problem, and its effectiveness and computational feasibility
are demonstrated on a set of widely used GBDT benchmarks taken from the
literature.

</details>


### [31] [Distributional Unlearning: Forgetting Distributions, Not Just Samples](https://arxiv.org/abs/2507.15112)
*Youssef Allouah, Rachid Guerraoui, Sanmi Koyejo*

**主要类别:** cs.LG

**AI概要:** 这篇论文提出了分布遗忘（distributional unlearning），这是一种数据驱动的、与模型无关的框架，旨在从训练数据集中删除特定子群体的所有痕迹。通过使用Kullback-Leibler散度来量化删除和保留的程度，该研究推导了高斯情况下的精确帕累托前沿，并提出了一种基于距离的选择规则，以减少删除预算。实验证明，这种方法在多个数据集上比随机删除更有效率，同时对剩余数据的表现影响很小。


<details>
  <summary>更多</summary>
  
**动机:** 现有的机器遗忘工具主要集中在个体样本层面，在删除整个主题领域或子群体的数据时效果不佳。直接删除点往往不足以完全移除不想要的领域信息，下游学习者仍能恢复这些信息。为了满足隐私、法律或质量要求，需要一种新的方法来有效地删除整个子群体的数据。

**方法:** 作者引入了分布遗忘的概念，即找到最小的一组点，其删除能使编辑后的数据集远离不想要的领域，但又保持接近被保留的领域。使用Kullback-Leibler散度作为量化标准，他们推导了在高斯分布情况下的精确帕累托前沿，并证明了任何重新训练的模型在编辑后的数据上的log-loss变化不会超过散度阈值。此外，还提出了一种基于距离的选择规则，可以显著减少删除预算。

**结果:** 实验结果显示，相较于随机删除，分布遗忘方法在合成高斯数据、Jigsaw Toxic Comments、SMS垃圾邮件和CIFAR-10等多个数据集上减少了15-72%的删除操作，同时对保留数据的表现几乎没有影响。

**结论:** 分布遗忘提供了一个有效的解决方案，用于从训练数据中删除整个子群体的信息，而不会显著损害模型性能。它不仅减少了删除所需的数据量，而且保证了编辑后数据的质量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Distributional+Unlearning%3A+Forgetting+Distributions%2C+Not+Just+Samples，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15112，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15112&send_immediately=true&force_search=false)

**原文摘要:** Machine unlearning seeks to remove unwanted information from trained models,
initially at the individual-sample level, but increasingly at the level of
entire sub-populations. In many deployments, models must delete whole topical
domains to satisfy privacy, legal, or quality requirements, e.g., removing
several users' posts under GDPR or copyrighted web content. Existing unlearning
tools remain largely sample-oriented, and straightforward point deletion often
leaves enough residual signal for downstream learners to recover the unwanted
domain. We introduce distributional unlearning, a data-centric, model-agnostic
framework that asks: Given examples from an unwanted distribution and a
retained distribution, what is the smallest set of points whose removal makes
the edited dataset far from the unwanted domain yet close to the retained one?
Using Kullback-Leibler divergence to quantify removal and preservation, we
derive the exact Pareto frontier in the Gaussian case and prove that any model
retrained on the edited data incurs log-loss shifts bounded by the divergence
thresholds. We propose a simple distance-based selection rule satisfying these
constraints with a quadratic reduction in deletion budget compared to random
removal. Experiments on synthetic Gaussians, Jigsaw Toxic Comments, SMS spam,
and CIFAR-10 show 15-72% fewer deletions than random, with negligible impact on
retained performance.

</details>


### [32] [Generative Distribution Distillation](https://arxiv.org/abs/2507.14503)
*Jiequan Cui, Beier Zhu, Qingshan Xu, Xiaogang Xu, Pengguang Chen, Xiaojuan Qi, Bei Yu, Hanwang Zhang, Richang Hong*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的知识蒸馏框架GenDD，通过引入分割标记化和分布收缩技术来解决高维优化和语义监督不足的问题。实验结果表明，在有无标签监督的情况下，GenDD均表现出色，并在ImageNet上取得了最新的最佳成果。


<details>
  <summary>更多</summary>
  
**动机:** 知识蒸馏（KD）是一种将大型复杂模型的知识迁移到小型简单模型的技术，然而传统方法面临着高维优化和缺乏语义监督的挑战。

**方法:** 作者提出了Generative Distribution Distillation (GenDD) 框架，将知识蒸馏问题建模为条件生成问题。为了应对挑战，他们引入了Split Tokenization策略和Distribution Contraction技术。

**结果:** 实验结果表明，GenDD在未监督设置下表现优异，比KL基线提高了16.29％。使用标签监督时，ResNet-50在ImageNet上的top-1准确率达到了82.28％，成为新的最先进水平。

**结论:** 提出的GenDD框架能够有效地进行知识蒸馏，不仅解决了高维优化和语义监督的问题，还在多个数据集上展示了其竞争力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generative+Distribution+Distillation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14503，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14503&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we formulate the knowledge distillation (KD) as a conditional
generative problem and propose the \textit{Generative Distribution Distillation
(GenDD)} framework. A naive \textit{GenDD} baseline encounters two major
challenges: the curse of high-dimensional optimization and the lack of semantic
supervision from labels. To address these issues, we introduce a \textit{Split
Tokenization} strategy, achieving stable and effective unsupervised KD.
Additionally, we develop the \textit{Distribution Contraction} technique to
integrate label supervision into the reconstruction objective. Our theoretical
proof demonstrates that \textit{GenDD} with \textit{Distribution Contraction}
serves as a gradient-level surrogate for multi-task learning, realizing
efficient supervised training without explicit classification loss on
multi-step sampling image representations. To evaluate the effectiveness of our
method, we conduct experiments on balanced, imbalanced, and unlabeled data.
Experimental results show that \textit{GenDD} performs competitively in the
unsupervised setting, significantly surpassing KL baseline by \textbf{16.29\%}
on ImageNet validation set. With label supervision, our ResNet-50 achieves
\textbf{82.28\%} top-1 accuracy on ImageNet in 600 epochs training,
establishing a new state-of-the-art.

</details>


### [33] [Optimizing Canaries for Privacy Auditing with Metagradient Descent](https://arxiv.org/abs/2507.15836)
*Matteo Boglioni, Terrance Liu, Andrew Ilyas, Zhiwei Steven Wu*

**主要类别:** cs.LG

**AI概要:** 本文通过优化审计员的'canary'集，改进了黑盒隐私审计的方法，特别是在使用差分隐私的深度学习模型中。这种方法在某些情况下，可以将经验下限提高2倍以上，并且对于不同规模的模型都有效。


<details>
  <summary>更多</summary>
  
**动机:** 现有的隐私审计方法依赖于会员推断，即通过检测特定样本是否被包含在训练集中来估计算法的隐私参数。然而，这些方法的效果受限于'canary'集的质量。因此，本文旨在通过优化'canary'集来提升隐私审计的效果。

**方法:** 作者采用元梯度优化技术对'canary'集进行了优化。具体来说，他们不是随机选择'canary'样本，而是通过计算哪些样本最有助于区分训练集内外，从而更有效地进行隐私参数的估计。

**结果:** 实验结果表明，在某些情况下，使用优化后的'canary'集可以将经验下限提高超过2倍。此外，该方法还表现出良好的迁移性和高效性，即使是在非私有SGD和较大的模型架构上优化的'canary'集，也能有效应用于DP-SGD训练的更大模型的审计。

**结论:** 这项研究为黑盒隐私审计提供了一种新的、更为有效的策略。通过优化'canary'集，不仅提高了隐私参数估计的准确性，而且证明了其在不同模型间的可移植性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Optimizing+Canaries+for+Privacy+Auditing+with+Metagradient+Descent，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15836，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15836&send_immediately=true&force_search=false)

**原文摘要:** In this work we study black-box privacy auditing, where the goal is to lower
bound the privacy parameter of a differentially private learning algorithm
using only the algorithm's outputs (i.e., final trained model). For DP-SGD (the
most successful method for training differentially private deep learning
models), the canonical approach auditing uses membership inference-an auditor
comes with a small set of special "canary" examples, inserts a random subset of
them into the training set, and then tries to discern which of their canaries
were included in the training set (typically via a membership inference
attack). The auditor's success rate then provides a lower bound on the privacy
parameters of the learning algorithm. Our main contribution is a method for
optimizing the auditor's canary set to improve privacy auditing, leveraging
recent work on metagradient optimization. Our empirical evaluation demonstrates
that by using such optimized canaries, we can improve empirical lower bounds
for differentially private image classification models by over 2x in certain
instances. Furthermore, we demonstrate that our method is transferable and
efficient: canaries optimized for non-private SGD with a small model
architecture remain effective when auditing larger models trained with DP-SGD.

</details>


### [34] [SDSC:A Structure-Aware Metric for Semantic Signal Representation Learning](https://arxiv.org/abs/2507.14516)
*Jeyoung Lee, Hochul Kang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的时间序列自监督表征学习的结构感知度量函数——信号骰子相似性系数（SDSC），并展示了其在预测和分类基准测试中相比均方误差（MSE）方法具有相当或更优的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的自监督学习方法通常使用基于距离的目标，如均方误差（MSE），这些方法对振幅敏感、波形极性不变且尺度上无界，这阻碍了语义对齐并降低了可解释性。为了克服这些问题，提出了SDSC。

**方法:** SDSC基于Dice Similarity Coefficient (DSC)，通过量化符号振幅的交集来衡量时间信号之间的结构一致性。它可以通过减去1并应用Heaviside函数的可微近似用于梯度优化。还提出了将SDSC与MSE结合的混合损失公式以提高稳定性和必要时保持振幅。

**结果:** 实验表明，基于SDSC的预训练在领域内和资源有限的情况下，比MSE方法表现更好或至少相当。结果表明，在信号表示中保持结构保真度可以增强语义表示的质量。

**结论:** 结构感知度量是传统基于距离的方法的可行替代方案，可以在时间序列自监督表示学习中提供更好的性能和更高的语义表示质量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SDSC%3AA+Structure-Aware+Metric+for+Semantic+Signal+Representation+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14516，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14516&send_immediately=true&force_search=false)

**原文摘要:** We propose the Signal Dice Similarity Coefficient (SDSC), a structure-aware
metric function for time series self-supervised representation learning. Most
Self-Supervised Learning (SSL) methods for signals commonly adopt
distance-based objectives such as mean squared error (MSE), which are sensitive
to amplitude, invariant to waveform polarity, and unbounded in scale. These
properties hinder semantic alignment and reduce interpretability. SDSC
addresses this by quantifying structural agreement between temporal signals
based on the intersection of signed amplitudes, derived from the Dice
Similarity Coefficient (DSC).Although SDSC is defined as a structure-aware
metric, it can be used as a loss by subtracting from 1 and applying a
differentiable approximation of the Heaviside function for gradient-based
optimization. A hybrid loss formulation is also proposed to combine SDSC with
MSE, improving stability and preserving amplitude where necessary. Experiments
on forecasting and classification benchmarks demonstrate that SDSC-based
pre-training achieves comparable or improved performance over MSE, particularly
in in-domain and low-resource scenarios. The results suggest that structural
fidelity in signal representations enhances the semantic representation
quality, supporting the consideration of structure-aware metrics as viable
alternatives to conventional distance-based methods.

</details>


### [35] [Positive-Unlabeled Learning for Control Group Construction in Observational Causal Inference](https://arxiv.org/abs/2507.14528)
*Ilias Tsoumas, Dimitrios Bormpoudakis, Vasileios Sitokonstantinou, Athanasios Askitopoulos, Andreas Kalogeras, Charalampos Kontoes, Ioannis Athanasiadis*

**主要类别:** cs.LG

**AI概要:** 论文提出了一种利用正未标记（PU）学习方法来从非随机化设置中识别对照组，以估计平均处理效应（ATE）。该方法在农业可持续性研究数据上的应用表明其能够成功地仅通过已知的处理单元识别出合适的对照单元，并由此估算接近真实值的ATE。


<details>
  <summary>更多</summary>
  
**动机:** 在因果推断中，尤其是在观察性研究中，获得明确标记为对照的单元通常是困难的，这阻碍了对治疗效果准确估计。本文旨在解决这一问题，即在没有明确对照单元的情况下如何估计平均处理效应（ATE）。

**方法:** 本研究采用正未标记（PU）学习的方法，试图从未标注的数据中高可信度地识别出对照单元。该方法通过模拟和实际数据进行评估，构建了一个具有多样化关系的因果图以生成合成数据，并在不同情况下测试方法的可靠性。此外，该方法还被应用于实际的农业数据中。

**结果:** 研究结果表明，PU学习方法可以成功地从未标记的数据中识别出对照单元，并且通过这些对照单元估算出的ATE与真实值非常接近。

**结论:** 该工作对于观察性因果推断有重要意义，特别是在随机实验难以实施或成本高昂的领域，如地球、环境和农业科学。它允许利用现有的地球观测和气候数据开展大量准实验，特别是当存在已知的处理单元但缺乏对照单元时。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Positive-Unlabeled+Learning+for+Control+Group+Construction+in+Observational+Causal+Inference，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14528，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14528&send_immediately=true&force_search=false)

**原文摘要:** In causal inference, whether through randomized controlled trials or
observational studies, access to both treated and control units is essential
for estimating the effect of a treatment on an outcome of interest. When
treatment assignment is random, the average treatment effect (ATE) can be
estimated directly by comparing outcomes between groups. In non-randomized
settings, various techniques are employed to adjust for confounding and
approximate the counterfactual scenario to recover an unbiased ATE. A common
challenge, especially in observational studies, is the absence of units clearly
labeled as controls-that is, units known not to have received the treatment. To
address this, we propose positive-unlabeled (PU) learning as a framework for
identifying, with high confidence, control units from a pool of unlabeled ones,
using only the available treated (positive) units. We evaluate this approach
using both simulated and real-world data. We construct a causal graph with
diverse relationships and use it to generate synthetic data under various
scenarios, assessing how reliably the method recovers control groups that allow
estimates of true ATE. We also apply our approach to real-world data on optimal
sowing and fertilizer treatments in sustainable agriculture. Our findings show
that PU learning can successfully identify control (negative) units from
unlabeled data based only on treated units and, through the resulting control
group, estimate an ATE that closely approximates the true value. This work has
important implications for observational causal inference, especially in fields
where randomized experiments are difficult or costly. In domains such as earth,
environmental, and agricultural sciences, it enables a plethora of
quasi-experiments by leveraging available earth observation and climate data,
particularly when treated units are available but control units are lacking.

</details>


### [36] [Kernel Based Maximum Entropy Inverse Reinforcement Learning for Mean-Field Games](https://arxiv.org/abs/2507.14529)
*Berkay Anahtarci, Can Deha Kariksiz, Naci Saldi*

**主要类别:** cs.LG

**AI概要:** 这篇论文研究了在无限水平静止平均场博弈中，基于最大因果熵的逆强化学习问题，通过引入拉格朗日松弛并利用梯度上升算法求解，并证明了相关软贝尔曼算子的Fréchet可微性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的逆强化学习方法大多限制奖励函数为固定有限基函数线性组合，无法直接从专家演示中推断出丰富和潜在非线性的奖励结构。此外，以前的研究主要依赖于有限水平的公式化，而本文关注的是无限水平的成本结构。

**方法:** 作者引入了拉格朗日松弛，将最大因果熵逆强化学习问题重新表述为无约束对数似然最大化问题，并通过梯度上升算法获得解决方案。同时，作者还证明了与再生核希尔伯特空间中的参数相关的软贝尔曼算子的Fréchet可微性。

**结果:** 该方法在一个平均场交通路由游戏中展示了其有效性，能够准确地恢复专家行为。

**结论:** 提出的方法可以在无限水平静止平均场博弈中有效地解决最大因果熵逆强化学习问题，并能从专家演示中推断出复杂且可能非线性的奖励结构。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Kernel+Based+Maximum+Entropy+Inverse+Reinforcement+Learning+for+Mean-Field+Games，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14529，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14529&send_immediately=true&force_search=false)

**原文摘要:** We consider the maximum causal entropy inverse reinforcement learning problem
for infinite-horizon stationary mean-field games, in which we model the unknown
reward function within a reproducing kernel Hilbert space. This allows the
inference of rich and potentially nonlinear reward structures directly from
expert demonstrations, in contrast to most existing inverse reinforcement
learning approaches for mean-field games that typically restrict the reward
function to a linear combination of a fixed finite set of basis functions. We
also focus on the infinite-horizon cost structure, whereas prior studies
primarily rely on finite-horizon formulations. We introduce a Lagrangian
relaxation to this maximum causal entropy inverse reinforcement learning
problem that enables us to reformulate it as an unconstrained log-likelihood
maximization problem, and obtain a solution \lk{via} a gradient ascent
algorithm. To illustrate the theoretical consistency of the algorithm, we
establish the smoothness of the log-likelihood objective by proving the
Fr\'echet differentiability of the related soft Bellman operators with respect
to the parameters in the reproducing kernel Hilbert space. We demonstrate the
effectiveness of our method on a mean-field traffic routing game, where it
accurately recovers expert behavior.

</details>


### [37] [The Origin of Self-Attention: From Pairwise Affinity Matrices to Transformers](https://arxiv.org/abs/2507.14560)
*Giorgio Roffo*

**主要类别:** cs.LG

**AI概要:** 本文探讨了自注意力机制在多个领域的起源，认为它是一个更通用计算原理的现代实例，并将其与无限特征选择（Inf-FS）关联起来，强调了基于亲和力矩阵的信息流控制。


<details>
  <summary>更多</summary>
  
**动机:** 动机是追溯自注意力机制的概念起源，通过跨领域视角理解其发展，以及它如何与无限特征选择相联系，以揭示不同模型和任务背后的共同数学基础。

**方法:** 论文比较了自注意力机制和无限特征选择的方法，指出自注意力使用单跳亲和力计算，而Inf-FS定义A或通过领域知识学习，并通过多跳传播计算特征相关性。

**结果:** 结果表明，自注意力机制可以被视为Inf-FS的一个特例，两者都在处理成对关系，但主要区别在于亲和力矩阵的定义和应用方式。

**结论:** 结论是将自注意力机制置于更广泛的基于亲和力的计算范式中，统一了几条机器学习研究线索，并突出了支撑不同模型和任务的共同数学基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Origin+of+Self-Attention%3A+From+Pairwise+Affinity+Matrices+to+Transformers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14560，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14560&send_immediately=true&force_search=false)

**原文摘要:** The self-attention mechanism, now central to deep learning architectures such
as Transformers, is a modern instance of a more general computational
principle: learning and using pairwise affinity matrices to control how
information flows through a model. This paper traces the conceptual origins of
self-attention across multiple domains, including computer vision, natural
language processing, and graph learning, through their shared reliance on an
affinity matrix, denoted as A. We highlight Infinite Feature Selection (Inf-FS)
as a foundational approach that generalizes the idea of affinity-based
weighting. Unlike the fixed dot-product structure used in Transformers, Inf-FS
defines A either through domain knowledge or by learning, and computes feature
relevance through multi-hop propagation over the affinity graph. From this
perspective, self-attention can be seen as a special case of Inf-FS: it uses a
single-hop affinity computation where A is dynamically built from token
similarities. We argue that the underlying structure, reasoning over pairwise
relationships, is preserved across both approaches, and the key differences lie
in how the affinity matrix is defined and applied. By situating self-attention
within the broader paradigm of affinity-based computation, we unify several
strands of machine learning research and highlight a common mathematical
foundation that underpins diverse models and tasks.

</details>


### [38] [LPS-GNN : Deploying Graph Neural Networks on Graphs with 100-Billion Edges](https://arxiv.org/abs/2507.14570)
*Xu Cheng, Liang Yao, Feng He, Yukuo Cen, Yufei He, Chenhui Zhang, Wenzheng Feng, Hongyun Cai, Jie Tang*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为LPS-GNN的可扩展、低成本、灵活且高效的图神经网络框架，解决了大规模图挖掘任务中的效率与准确性平衡问题。


<details>
  <summary>更多</summary>
  
**动机:** 现有的可扩展GNN解决方案难以在执行效率和预测准确性之间取得平衡，特别是在处理大规模图时遇到的邻居爆炸问题。

**方法:** 提出了一种新的图分区算法LPMetis和子图增强策略，以提高模型的预测性能，并使框架能够适应各种GNN算法。

**结果:** LPS-GNN能够在单个GPU上于10小时内对100亿个图进行表示学习，在用户获取场景中表现出了13.8%的提升，并在腾讯平台上的实际应用中实现了8.24%到13.89%的性能提升。

**结论:** LPS-GNN为解决大规模图数据挖掘中的挑战提供了一种高效且经济的方案，其性能优于当前最先进的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LPS-GNN+%3A+Deploying+Graph+Neural+Networks+on+Graphs+with+100-Billion+Edges，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14570，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14570&send_immediately=true&force_search=false)

**原文摘要:** Graph Neural Networks (GNNs) have emerged as powerful tools for various graph
mining tasks, yet existing scalable solutions often struggle to balance
execution efficiency with prediction accuracy. These difficulties stem from
iterative message-passing techniques, which place significant computational
demands and require extensive GPU memory, particularly when dealing with the
neighbor explosion issue inherent in large-scale graphs. This paper introduces
a scalable, low-cost, flexible, and efficient GNN framework called LPS-GNN,
which can perform representation learning on 100 billion graphs with a single
GPU in 10 hours and shows a 13.8% improvement in User Acquisition scenarios. We
examine existing graph partitioning methods and design a superior graph
partition algorithm named LPMetis. In particular, LPMetis outperforms current
state-of-the-art (SOTA) approaches on various evaluation metrics. In addition,
our paper proposes a subgraph augmentation strategy to enhance the model's
predictive performance. It exhibits excellent compatibility, allowing the
entire framework to accommodate various GNN algorithms. Successfully deployed
on the Tencent platform, LPS-GNN has been tested on public and real-world
datasets, achieving performance lifts of 8. 24% to 13. 89% over SOTA models in
online applications.

</details>


### [39] [A Transformer-Based Conditional GAN with Multiple Instance Learning for UAV Signal Detection and Classification](https://arxiv.org/abs/2507.14592)
*Haochen Liu, Jia Bi, Xiaomin Wang, Xin Yang, Ling Wang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种结合Transformer-GAN和MILET的新框架，用于UAV飞行状态分类。实验表明其准确率高、计算效率强，并且具有良好的泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 目前的时序分类方法在动态无人机环境中缺乏稳健性和泛化性，而先进的模型如Transformer和LSTM需要大量的数据和高计算成本，特别是在高维数据流的情况下。

**方法:** 该框架利用Transformer编码器捕捉长时间范围的依赖关系和复杂的遥测动力学，GAN模块生成逼真的合成样本以增强有限的数据集，MIL则集中注意力于最具辨别力的输入部分，减少噪音和计算负担。

**结果:** 实验结果表明，该方法在DroneDetect和DroneRF数据集上分别达到了96.5%和98.6%的准确率，优于其他最先进方法。

**结论:** 该框架展示了强大的计算效率和稳健的泛化能力，适用于各种无人机平台和飞行状态，突出了其在资源受限环境下实时部署的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Transformer-Based+Conditional+GAN+with+Multiple+Instance+Learning+for+UAV+Signal+Detection+and+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14592，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14592&send_immediately=true&force_search=false)

**原文摘要:** Unmanned Aerial Vehicles (UAVs) are increasingly used in surveillance,
logistics, agriculture, disaster management, and military operations. Accurate
detection and classification of UAV flight states, such as hovering, cruising,
ascending, or transitioning, which are essential for safe and effective
operations. However, conventional time series classification (TSC) methods
often lack robustness and generalization for dynamic UAV environments, while
state of the art(SOTA) models like Transformers and LSTM based architectures
typically require large datasets and entail high computational costs,
especially with high-dimensional data streams. This paper proposes a novel
framework that integrates a Transformer-based Generative Adversarial Network
(GAN) with Multiple Instance Locally Explainable Learning (MILET) to address
these challenges in UAV flight state classification. The Transformer encoder
captures long-range temporal dependencies and complex telemetry dynamics, while
the GAN module augments limited datasets with realistic synthetic samples. MIL
is incorporated to focus attention on the most discriminative input segments,
reducing noise and computational overhead. Experimental results show that the
proposed method achieves superior accuracy 96.5% on the DroneDetect dataset and
98.6% on the DroneRF dataset that outperforming other SOTA approaches. The
framework also demonstrates strong computational efficiency and robust
generalization across diverse UAV platforms and flight states, highlighting its
potential for real-time deployment in resource constrained environments.

</details>


### [40] [$k$-PCA for (non-squared) Euclidean Distances: Polynomial Time Approximation](https://arxiv.org/abs/2507.14631)
*Daniel Greenhut, Dan Feldman*

**主要类别:** cs.LG

**AI概要:** 本文提供了一种新的多项式时间确定性算法，用于近似k-子空间中位数，其运行时间和近似因子均不是k的指数形式。


<details>
  <summary>更多</summary>
  
**动机:** 经典的k-PCA（主成分分析）近似于点集P的k维仿射线性子空间，该子空间使得P中所有点到它的欧几里得距离平方和最小。然而，对于非凸的k-子空间中位数问题，目前没有一种有效的多项式时间算法可以解决这个问题。

**方法:** 我们提供了一种新的多项式时间确定性算法，该算法的近似因子为根号d，运行时间为输入大小的多项式。此外，我们还提供了开放代码和真实数据集上的实验结果。

**结果:** 我们的算法是第一个在运行时间和近似因子上都不是k的指数函数的多项式时间确定性算法。它不仅适用于k-子空间中位数问题，还可以扩展到其他相关问题，如处理离群值/稀疏性等。

**结论:** 我们相信，这种技术对许多其他相关问题也将是有用的，例如处理不同z值的距离的ℓ2,z范数，以及处理离群值/稀疏性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是%24k%24-PCA+for+%28non-squared%29+Euclidean+Distances%3A+Polynomial+Time+Approximation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14631，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14631&send_immediately=true&force_search=false)

**原文摘要:** Given an integer $k\geq1$ and a set $P$ of $n$ points in $\REAL^d$, the
classic $k$-PCA (Principle Component Analysis) approximates the affine
\emph{$k$-subspace mean} of $P$, which is the $k$-dimensional affine linear
subspace that minimizes its sum of squared Euclidean distances
($\ell_{2,2}$-norm) over the points of $P$, i.e., the mean of these distances.
The \emph{$k$-subspace median} is the subspace that minimizes its sum of
(non-squared) Euclidean distances ($\ell_{2,1}$-mixed norm), i.e., their
median. The median subspace is usually more sparse and robust to noise/outliers
than the mean, but also much harder to approximate since, unlike the
$\ell_{z,z}$ (non-mixed) norms, it is non-convex for $k<d-1$.
  We provide the first polynomial-time deterministic algorithm whose both
running time and approximation factor are not exponential in $k$. More
precisely, the multiplicative approximation factor is $\sqrt{d}$, and the
running time is polynomial in the size of the input. We expect that our
technique would be useful for many other related problems, such as $\ell_{2,z}$
norm of distances for $z\not \in \br{1,2}$, e.g., $z=\infty$, and handling
outliers/sparsity.
  Open code and experimental results on real-world datasets are also provided.

</details>


### [41] [Rec-AD: An Efficient Computation Framework for FDIA Detection Based on Tensor Train Decomposition and Deep Learning Recommendation Model](https://arxiv.org/abs/2507.14668)
*Yunfeng Li, Junhong Liu, Zhaohui Yang, Guofu Liao, Chuyun Zhang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为Rec-AD的计算高效框架，结合了张量列车分解与深度学习推荐模型，以提高智能电网中虚假数据注入攻击检测的效率和实时性能。


<details>
  <summary>更多</summary>
  
**动机:** 深度学习模型已被广泛应用于智能电网中的虚假数据注入攻击（FDIA）检测，但随着系统规模和数据维度的增加，计算和内存负担显著增加，尤其是在大规模工业数据集中，这限制了检测效率。

**方法:** Rec-AD通过嵌入压缩、通过索引重排序优化数据访问以及减少内存通信开销的管道训练机制来增强训练和推理效率。它完全兼容PyTorch，可以无缝集成到现有的FDIA检测系统中。

**结果:** 实验结果表明，Rec-AD大大提高了计算吞吐量和实时检测性能，缩短了攻击窗口并增加了攻击者的成本。

**结论:** 这些进步加强了边缘计算能力和可扩展性，为智能电网安全提供了强有力的技术支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Rec-AD%3A+An+Efficient+Computation+Framework+for+FDIA+Detection+Based+on+Tensor+Train+Decomposition+and+Deep+Learning+Recommendation+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14668，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14668&send_immediately=true&force_search=false)

**原文摘要:** Deep learning models have been widely adopted for False Data Injection Attack
(FDIA) detection in smart grids due to their ability to capture unstructured
and sparse features. However, the increasing system scale and data
dimensionality introduce significant computational and memory burdens,
particularly in large-scale industrial datasets, limiting detection efficiency.
To address these issues, this paper proposes Rec-AD, a computationally
efficient framework that integrates Tensor Train decomposition with the Deep
Learning Recommendation Model (DLRM). Rec-AD enhances training and inference
efficiency through embedding compression, optimized data access via index
reordering, and a pipeline training mechanism that reduces memory communication
overhead. Fully compatible with PyTorch, Rec-AD can be integrated into existing
FDIA detection systems without code modifications. Experimental results show
that Rec-AD significantly improves computational throughput and real-time
detection performance, narrowing the attack window and increasing attacker
cost. These advancements strengthen edge computing capabilities and
scalability, providing robust technical support for smart grid security.

</details>


### [42] [Revisiting Graph Contrastive Learning on Anomaly Detection: A Structural Imbalance Perspective](https://arxiv.org/abs/2507.14677)
*Yiming Xu, Zhen Peng, Bin Shi, Xu Hua, Bo Dong, Song Wang, Chen Chen*

**主要类别:** cs.LG

**AI概要:** 论文提出了一种新的GCL框架AD-GCL，通过邻居修剪策略和异常引导邻居补全方法来增强图异常检测对结构不平衡的鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于GCL的模型在执行异常检测任务时过于注重整体检测性能而忽视了对结构不平衡的鲁棒性，特别是在处理遵循幂律度分布的真实世界网络时，可能会忽略低度节点的尾部异常。这影响了当前异常检测算法的安全性和鲁棒性，限制了其在高风险场景中的应用。

**方法:** 该研究引入了AD-GCL框架，采用邻居修剪策略以过滤头部节点的噪声边，并通过从头部节点到伪造尾部节点的对齐来促进真实尾部节点的检测。此外，还通过异常引导邻居补全的方法主动探索潜在邻居，扩大尾部节点的感受野，并引入原始图和增强图的视内和视间一致性损失以增强表示。

**结果:** 在多个数据集上的性能评估验证了所提出的AD-GCL在检测头部异常和尾部异常方面的全面优越性。

**结论:** AD-GCL框架提高了图对比学习在异常检测中的鲁棒性，特别对于结构上存在不平衡的数据集表现出了优越的性能，为解决图异常检测中的结构不平衡问题提供了一种有效的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Revisiting+Graph+Contrastive+Learning+on+Anomaly+Detection%3A+A+Structural+Imbalance+Perspective，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14677，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14677&send_immediately=true&force_search=false)

**原文摘要:** The superiority of graph contrastive learning (GCL) has prompted its
application to anomaly detection tasks for more powerful risk warning systems.
Unfortunately, existing GCL-based models tend to excessively prioritize overall
detection performance while neglecting robustness to structural imbalance,
which can be problematic for many real-world networks following power-law
degree distributions. Particularly, GCL-based methods may fail to capture tail
anomalies (abnormal nodes with low degrees). This raises concerns about the
security and robustness of current anomaly detection algorithms and therefore
hinders their applicability in a variety of realistic high-risk scenarios. To
the best of our knowledge, research on the robustness of graph anomaly
detection to structural imbalance has received little scrutiny. To address the
above issues, this paper presents a novel GCL-based framework named AD-GCL. It
devises the neighbor pruning strategy to filter noisy edges for head nodes and
facilitate the detection of genuine tail nodes by aligning from head nodes to
forged tail nodes. Moreover, AD-GCL actively explores potential neighbors to
enlarge the receptive field of tail nodes through anomaly-guided neighbor
completion. We further introduce intra- and inter-view consistency loss of the
original and augmentation graph for enhanced representation. The performance
evaluation of the whole, head, and tail nodes on multiple datasets validates
the comprehensive superiority of the proposed AD-GCL in detecting both head
anomalies and tail anomalies.

</details>


### [43] [GCC-Spam: Spam Detection via GAN, Contrastive Learning, and Character Similarity Networks](https://arxiv.org/abs/2507.14679)
*Zixin Xu, Zhijie Wang, Zhiyuan Pan*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的反垃圾文本框架GCC-Spam，通过字符相似性网络、对比学习和生成对抗网络（GAN）解决了垃圾信息制造者的对抗策略和标记数据不足的问题，并在真实世界的数据集上验证了其优越性。


<details>
  <summary>更多</summary>
  
**动机:** 由于互联网上的垃圾文本呈指数增长，需要强大的检测机制来应对此类问题带来的风险，如信息泄露和社会不稳定。同时，现有的挑战包括垃圾信息发布者使用的对抗策略和标注数据的缺乏。

**方法:** 该方法结合了三个核心创新点：1) 字符相似性网络用于捕捉正字法和语音特征以应对字符混淆攻击并生成句子嵌入；2) 对比学习通过优化垃圾和正常文本之间的潜在空间距离来提高区分度；3) 生成对抗网络（GAN）生成逼真的伪垃圾样本，以缓解数据稀缺并提高模型的鲁棒性和分类准确性。

**结果:** 广泛的实验表明，所提出的模型在真实世界的数据集上优于基线方法，在使用显著更少的标记示例的情况下实现了更高的检测率。

**结论:**  GCC-Spam框架提供了一种有效的方法来对抗垃圾文本发布者的策略和数据稀缺问题，从而提高了垃圾文本检测的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GCC-Spam%3A+Spam+Detection+via+GAN%2C+Contrastive+Learning%2C+and+Character+Similarity+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14679，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14679&send_immediately=true&force_search=false)

**原文摘要:** The exponential growth of spam text on the Internet necessitates robust
detection mechanisms to mitigate risks such as information leakage and social
instability. This work addresses two principal challenges: adversarial
strategies employed by spammers and the scarcity of labeled data. We propose a
novel spam-text detection framework GCC-Spam, which integrates three core
innovations. First, a character similarity network captures orthographic and
phonetic features to counter character-obfuscation attacks and furthermore
produces sentence embeddings for downstream classification. Second, contrastive
learning enhances discriminability by optimizing the latent-space distance
between spam and normal texts. Third, a Generative Adversarial Network (GAN)
generates realistic pseudo-spam samples to alleviate data scarcity while
improving model robustness and classification accuracy. Extensive experiments
on real-world datasets demonstrate that our model outperforms baseline
approaches, achieving higher detection rates with significantly fewer labeled
examples.

</details>


### [44] [Spatial-Temporal Transformer with Curriculum Learning for EEG-Based Emotion Recognition](https://arxiv.org/abs/2507.14698)
*Xuetao Lin, Tianhao Peng, Peihong Dai, Yu Liang, Wenjun Wu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的框架SST-CL，结合空间-时间变压器与课程学习，以应对EEG情感识别中的挑战，并在多个基准数据集上展示了最先进的性能。


<details>
  <summary>更多</summary>
  
**动机:** EEG情感识别在发展适应性脑机通信系统中扮演重要角色，但实际应用中存在两个主要挑战：有效整合非平稳的空间-时间神经模式和适应动态情感强度变化。

**方法:** 提出了SST-CL框架，包括一个空间编码器和一个时间编码器，以及一个强度感知的课程学习策略。空间编码器建模通道间关系，时间编码器通过窗口注意力机制捕捉多尺度依赖，课程学习策略则根据双重难度评估进行动态样本调度。

**结果:** 在三个基准数据集上的综合实验表明，该方法在各种情感强度水平上均达到了最先进水平，消融研究也证实了架构组件和课程学习机制的必要性。

**结论:** SST-CL框架能有效地解决EEG情感识别中的两大挑战，并为未来的研究提供了一个强有力的基线。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Spatial-Temporal+Transformer+with+Curriculum+Learning+for+EEG-Based+Emotion+Recognition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14698，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14698&send_immediately=true&force_search=false)

**原文摘要:** EEG-based emotion recognition plays an important role in developing adaptive
brain-computer communication systems, yet faces two fundamental challenges in
practical implementations: (1) effective integration of non-stationary
spatial-temporal neural patterns, (2) robust adaptation to dynamic emotional
intensity variations in real-world scenarios. This paper proposes SST-CL, a
novel framework integrating spatial-temporal transformers with curriculum
learning. Our method introduces two core components: a spatial encoder that
models inter-channel relationships and a temporal encoder that captures
multi-scale dependencies through windowed attention mechanisms, enabling
simultaneous extraction of spatial correlations and temporal dynamics from EEG
signals. Complementing this architecture, an intensity-aware curriculum
learning strategy progressively guides training from high-intensity to
low-intensity emotional states through dynamic sample scheduling based on a
dual difficulty assessment. Comprehensive experiments on three benchmark
datasets demonstrate state-of-the-art performance across various emotional
intensity levels, with ablation studies confirming the necessity of both
architectural components and the curriculum learning mechanism.

</details>


### [45] [Fraud is Not Just Rarity: A Causal Prototype Attention Approach to Realistic Synthetic Oversampling](https://arxiv.org/abs/2507.14706)
*Claudio Giusti, Luca Guarnera, Mirko Casu, Sebastiano Battiato*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的分类器CPAC，用于改进信用卡欺诈检测中的类别感知聚类和潜在空间结构。实验表明，与传统方法相比，CPAC引导的潜在成形具有更好的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的生成合成样本的方法在处理极度不平衡的数据集时，导致分类器过于自信和较差的潜在聚类分离。

**方法:** 提出了因果原型注意力分类器（CPAC），它通过基于原型的注意力机制促进类别感知聚类和改进潜在空间结构，并将其与VAE-GAN编码器结合使用。

**结果:** CPAC增强模型实现了93.14%的F1分数和90.18%的召回率，以及更好的潜在聚类分离。

**结论:** CPAC提供了一种改进的方法来处理类别不平衡问题，其带来的潜在空间结构改善有助于提升欺诈检测的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fraud+is+Not+Just+Rarity%3A+A+Causal+Prototype+Attention+Approach+to+Realistic+Synthetic+Oversampling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14706，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14706&send_immediately=true&force_search=false)

**原文摘要:** Detecting fraudulent credit card transactions remains a significant
challenge, due to the extreme class imbalance in real-world data and the often
subtle patterns that separate fraud from legitimate activity. Existing research
commonly attempts to address this by generating synthetic samples for the
minority class using approaches such as GANs, VAEs, or hybrid generative
models. However, these techniques, particularly when applied only to
minority-class data, tend to result in overconfident classifiers and poor
latent cluster separation, ultimately limiting real-world detection
performance. In this study, we propose the Causal Prototype Attention
Classifier (CPAC), an interpretable architecture that promotes class-aware
clustering and improved latent space structure through prototype-based
attention mechanisms and we will couple it with the encoder in a VAE-GAN
allowing it to offer a better cluster separation moving beyond post-hoc sample
augmentation. We compared CPAC-augmented models to traditional oversamplers,
such as SMOTE, as well as to state-of-the-art generative models, both with and
without CPAC-based latent classifiers. Our results show that classifier-guided
latent shaping with CPAC delivers superior performance, achieving an F1-score
of 93.14\% percent and recall of 90.18\%, along with improved latent cluster
separation. Further ablation studies and visualizations provide deeper insight
into the benefits and limitations of classifier-driven representation learning
for fraud detection. The codebase for this work will be available at final
submission.

</details>


### [46] [Exploring the Dynamic Scheduling Space of Real-Time Generative AI Applications on Emerging Heterogeneous Systems](https://arxiv.org/abs/2507.14715)
*Rachid Karami, Rajeev Patwari, Hyoukjun Kwon, Ashish Sirasao*

**主要类别:** cs.LG

**AI概要:** 研究了实时生成式AI工作负载（RTGen）在异构SoC平台上的调度问题，通过评测五种调度策略对性能的影响，强调了工作负载感知和硬件异构性感知的动态调度策略的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型语言模型被整合到实时多模态AI应用中，出现了实时生成式AI这一新的工作负载类别，这类负载对计算强度、延迟和并发性有严格要求，目前对于其在异构SoC平台上的调度复杂性和性能影响的研究尚不充分。

**方法:** 作者在AMD最新的异构SoC Ryzen AI上进行了全面的工作负载特征分析，构建了基于行业用例的多模型场景，并跨所有可用后端分析模型性能。然后评估了五种调度策略对实时指标和LLM性能的影响。

**结果:** 不同的调度决策对工作负载性能有显著影响，例如平均导致41.7%的截止时间违规率差异。这表明需要采用能够适应工作负载动态变化和硬件异构性的调度策略。

**结论:** 为了实现高性能的设备端RTGen应用，必须重视工作负载感知和动态异构调度策略的应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exploring+the+Dynamic+Scheduling+Space+of+Real-Time+Generative+AI+Applications+on+Emerging+Heterogeneous+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14715，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14715&send_immediately=true&force_search=false)

**原文摘要:** The integration of generative AI models, particularly large language models
(LLMs), into real-time multi-model AI applications such as video conferencing
and gaming is giving rise to a new class of workloads: real-time generative AI
(RTGen). These workloads combine the compute intensity and dynamic execution
patterns of generative models with the stringent latency and concurrency
constraints of real-time inference. To meet the diverse demands of RTGen
workloads, modern edge platforms increasingly adopt heterogeneous
system-on-chip (SoC) architectures that integrate CPUs, GPUs, and NPUs. Despite
the potential of heterogeneous SoC, the scheduling space complexity and
performance implications of RTGen workloads on such platforms remain
underexplored. In this work, we perform a comprehensive characterization of
RTGen workloads on AMD's latest heterogeneous SoC, Ryzen AI. We construct
realistic multi-model scenarios inspired by industry use cases and profile
model performance across all available backends. Using this data, we evaluate
five scheduling policies and their impact on both real-time metrics (e.g.,
deadline violation rate) and LLM performance (e.g., time-to-first-token and
tokens-per-second). Our results show that scheduling decisions significantly
affect workload performance (e.g., leading to a 41.7% difference in deadline
violation rates on average), and highlight the need for scheduling strategies
that are aware of workload dynamics and hardware heterogeneity. Our findings
underscore the importance of workload-aware, dynamic heterogeneous scheduling
in enabling high-performance, on-device RTGen applications.

</details>


### [47] [LeanTree: Accelerating White-Box Proof Search with Factorized States in Lean 4](https://arxiv.org/abs/2507.14722)
*Matěj Kripner, Michal Šustr, Milan Straka*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为LeanTree的新工具和数据集，用于改进自动定理证明中的白盒方法。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型（LLMs）在自动定理证明（ATP）中展现出了潜力，但它们需要与证明验证器交互以确保正确性。目前的交互方式有两种：黑盒交互和白盒方法。虽然黑盒方法受益于LLM的进展，但白盒方法的发展相对滞后。

**方法:** 作者引入了LeanTree，一个用Lean 4编写的工具，它可以将复杂的证明状态分解为更简单的独立分支，并生成这些分解的中间状态的数据集。这种白盒工具提供了简化评估、减少所需上下文、生成更丰富的训练数据等优点。

**结果:** 初步结果表明，在某些情况下，白盒方法的表现优于黑盒方法。

**结论:** 通过引入LeanTree工具和数据集，本文缩小了白盒方法与黑盒方法之间的差距，展示了白盒方法在自动定理证明中的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LeanTree%3A+Accelerating+White-Box+Proof+Search+with+Factorized+States+in+Lean+4，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14722，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14722&send_immediately=true&force_search=false)

**原文摘要:** Automated theorem proving (ATP) has been a classical problem in artificial
intelligence since its inception, yet it remains challenging due to its vast
state and action space. Large language models (LLMs) have recently emerged as a
promising heuristic for ATP, but they lack correctness guarantees and thus
require interaction with a proof verifier. Such interactions typically follow
one of two approaches: black-box interaction, which does not utilize
intermediate proof states, or white-box approaches, which allow for incremental
proof construction and examination of intermediate states. While black-box
approaches have directly benefited from recent LLM advances, white-box methods
have comparatively lagged behind. In this paper, we address this gap by
introducing LeanTree, which consists of (i) a tool built in the Lean 4 language
that factorizes complex proof states into simpler, independent branches, and
(ii) a dataset of these factorized intermediate states. Our white-box tooling
offers several advantages over black-box approaches: it simplifies evaluation,
reduces necessary context, generates richer training data, enables parallel
search across multiple states, supports efficient reuse of states, and provides
feedback in case of errors. Our preliminary results hint that white-box
approaches outperform black-box alternatives in some settings.

</details>


### [48] [Task-Agnostic Continual Prompt Tuning with Gradient-Based Selection and Decoding](https://arxiv.org/abs/2507.14725)
*Anushka Tiwari, Sayantan Pal, Rohini K. Srihari, Kaiyi Ji*

**主要类别:** cs.LG

**AI概要:** 本文提出GRID框架，通过改进的反向传输和梯度基础的提示选择策略，解决了连续学习中的潜在遗忘和提示记忆爆炸问题，显著提升了基于T5和Flan-T5模型的任务表现。


<details>
  <summary>更多</summary>
  
**动机:** 大多数现有的基于提示的持续学习方法假设任务感知推理，并维护一个不断增长的任务特定提示列表，这限制了可扩展性并隐藏了潜在的遗忘。

**方法:** GRID集成了一个任务感知解码机制，利用代表性输入、自动任务识别和约束解码来改善反向传输。此外，还提出了一个基于梯度的提示选择策略，将不太重要的提示压缩成单一的聚合表示。

**结果:** 广泛的实验表明，GRID显著改善了反向传输，实现了具有竞争力的前向传输，并减少了多达80%的被遗忘任务，在T5和Flan-T5主干上优于最先进的方法。

**结论:** GRID提供了一种统一的框架，有效解决了持续学习中的潜在遗忘和提示记忆爆炸问题，为可扩展和高效的终身学习铺平了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Task-Agnostic+Continual+Prompt+Tuning+with+Gradient-Based+Selection+and+Decoding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14725，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14725&send_immediately=true&force_search=false)

**原文摘要:** Prompt-based continual learning (CL) offers a parameter-efficient way to
adapt large language models (LLMs) across task sequences. However, most
existing methods assume task-aware inference and maintain a growing list of
task-specific prompts, which limits scalability and hides latent forgetting. In
this work, we introduce GRID, a unified framework that addresses two key
limitations: (1) latent forgetting under task-agnostic inference, and (2)
prompt memory explosion as task sequences grow. GRID integrates a task-aware
decoding mechanism that improves backward transfer by leveraging representative
inputs, automatic task identification, and constrained decoding. Additionally,
we propose a gradient-based prompt selection strategy that compresses less
informative prompts into a single aggregated representation, enabling scalable
and memory-efficient lifelong learning. Extensive experiments across
short-sequence, long-sequence, and negative transfer benchmarks show that GRID
significantly improves backward transfer, achieves competitive forward
transfer, and reduces forgotten tasks by up to 80\%, outperforming
state-of-the-art methods on T5 and Flan-T5 backbones.

</details>


### [49] [Balancing Expressivity and Robustness: Constrained Rational Activations for Reinforcement Learning](https://arxiv.org/abs/2507.14736)
*Rafał Surdej, Michał Bortkiewicz, Alex Lewandowski, Mateusz Ostaszewski, Clare Lyle*

**主要类别:** cs.LG

**AI概要:** 本文研究了可训练有理激活函数在强化学习和持续学习环境中的表现，发现其灵活性虽然提高了适应性但也可能引入不稳定性。为此，提出了一种受约束的变体以限制过度输出缩放，同时保留适应能力，从而改善训练稳定性和性能。


<details>
  <summary>更多</summary>
  
**动机:** 可训练激活函数相较于固定的激活函数能提供更高的表达力，特别是定义为多项式比率的可训练激活函数（有理函数）已被提议用于增强强化学习中的可塑性。然而，这种激活函数对训练稳定性的影响尚不清楚。

**方法:** 本研究在强化学习和持续学习环境中测试了可训练有理激活函数。针对发现的不稳定性问题，设计并提出了一种受约束的变体，通过结构性地限制过量输出缩放来解决此问题。

**结果:** 实验结果表明，所提出的受约束变体可以提高训练稳定性和性能，在MetaWorld和DeepMind Control Suite环境以及持续学习基准测试中均获得了良好效果。此外，在离散动作域中未观察到类似的不稳定性，这表明该权衡对于连续控制尤其重要。

**结论:** 研究表明，有理激活函数存在表达力和可塑性之间的权衡。我们的发现为在动态、非平稳环境中设计稳健且可适应的可训练激活函数提供了实际的设计原则。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Balancing+Expressivity+and+Robustness%3A+Constrained+Rational+Activations+for+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14736，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14736&send_immediately=true&force_search=false)

**原文摘要:** Trainable activation functions, whose parameters are optimized alongside
network weights, offer increased expressivity compared to fixed activation
functions. Specifically, trainable activation functions defined as ratios of
polynomials (rational functions) have been proposed to enhance plasticity in
reinforcement learning. However, their impact on training stability remains
unclear. In this work, we study trainable rational activations in both
reinforcement and continual learning settings. We find that while their
flexibility enhances adaptability, it can also introduce instability, leading
to overestimation in RL and feature collapse in longer continual learning
scenarios. Our main result is demonstrating a trade-off between expressivity
and plasticity in rational activations. To address this, we propose a
constrained variant that structurally limits excessive output scaling while
preserving adaptability. Experiments across MetaWorld and DeepMind Control
Suite (DMC) environments show that our approach improves training stability and
performance. In continual learning benchmarks, including MNIST with reshuffled
labels and Split CIFAR-100, we reveal how different constraints affect the
balance between expressivity and long-term retention. While preliminary
experiments in discrete action domains (e.g., Atari) did not show similar
instability, this suggests that the trade-off is particularly relevant for
continuous control. Together, our findings provide actionable design principles
for robust and adaptable trainable activations in dynamic, non-stationary
environments. Code available at:
https://github.com/special114/rl_rational_plasticity.

</details>


### [50] [Better Training Data Attribution via Better Inverse Hessian-Vector Products](https://arxiv.org/abs/2507.14740)
*Andrew Wang, Elisa Nguyen, Runshi Yang, Juhan Bae, Sheila A. McIlraith, Roger Grosse*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为ASTRA的新算法，用于训练数据归因（TDA），该算法通过EKFAC预调节器对纽曼级数迭代进行改进，以获得更准确的逆海森矩阵-向量积（iHVP）近似。实验表明，提高iHVP近似的准确性可以显著提升TDA的表现。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于梯度的TDA方法如影响函数和展开微分都涉及到难以高效近似的逆海森矩阵-向量积（iHVP）。

**方法:** 作者引入了ASTRA算法，使用EKFAC预调节器对纽曼级数迭代进行改进，从而得到更准确的iHVP近似。

**结果:** ASTRA易于调整，所需的迭代次数少于纽曼级数迭代，并且比基于EKFAC的近似更准确。这显著提高了TDA的性能。

**结论:** 提高iHVP近似的准确性能够显著改善TDA的性能，ASTRA为实现这一目标提供了一种有效的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Better+Training+Data+Attribution+via+Better+Inverse+Hessian-Vector+Products，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14740，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14740&send_immediately=true&force_search=false)

**原文摘要:** Training data attribution (TDA) provides insights into which training data is
responsible for a learned model behavior. Gradient-based TDA methods such as
influence functions and unrolled differentiation both involve a computation
that resembles an inverse Hessian-vector product (iHVP), which is difficult to
approximate efficiently. We introduce an algorithm (ASTRA) which uses the
EKFAC-preconditioner on Neumann series iterations to arrive at an accurate iHVP
approximation for TDA. ASTRA is easy to tune, requires fewer iterations than
Neumann series iterations, and is more accurate than EKFAC-based
approximations. Using ASTRA, we show that improving the accuracy of the iHVP
approximation can significantly improve TDA performance.

</details>


### [51] [Beyond the Single-Best Model: Rashomon Partial Dependence Profile for Trustworthy Explanations in AutoML](https://arxiv.org/abs/2507.14744)
*Mustafa Cavus, Jan N. van Rijn, Przemysław Biecek*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的框架，通过聚合近似最优模型的局部依赖配置文件来生成解释，从而将模型多样性纳入解释生成。实验证明了其能提高模型解释的可靠性和可信度。


<details>
  <summary>更多</summary>
  
**动机:** 自动机器学习系统通常专注于单一最佳性能模型，而忽略了对人类中心的可解释AI至关重要的解释不确定性。

**方法:** 提出一个新框架，通过从一组接近最优的模型（Rashomon集合）中聚合部分依赖配置文件（PDP），将模型多重性引入解释生成。

**结果:** 实验表明，在大多数情况下，Rashomon PDP覆盖不到最佳模型PDP的70%，这突显了单个模型解释的局限性。

**结论:** Rashomon PDP通过添加其他会被忽略的信息提高了模型解释的可靠性和可信度，这对于高风险领域尤其有用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Beyond+the+Single-Best+Model%3A+Rashomon+Partial+Dependence+Profile+for+Trustworthy+Explanations+in+AutoML，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14744，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14744&send_immediately=true&force_search=false)

**原文摘要:** Automated machine learning systems efficiently streamline model selection but
often focus on a single best-performing model, overlooking explanation
uncertainty, an essential concern in human centered explainable AI. To address
this, we propose a novel framework that incorporates model multiplicity into
explanation generation by aggregating partial dependence profiles (PDP) from a
set of near optimal models, known as the Rashomon set. The resulting Rashomon
PDP captures interpretive variability and highlights areas of disagreement,
providing users with a richer, uncertainty aware view of feature effects. To
evaluate its usefulness, we introduce two quantitative metrics, the coverage
rate and the mean width of confidence intervals, to evaluate the consistency
between the standard PDP and the proposed Rashomon PDP. Experiments on 35
regression datasets from the OpenML CTR23 benchmark suite show that in most
cases, the Rashomon PDP covers less than 70% of the best model's PDP,
underscoring the limitations of single model explanations. Our findings suggest
that Rashomon PDP improves the reliability and trustworthiness of model
interpretations by adding additional information that would otherwise be
neglected. This is particularly useful in high stakes domains where
transparency and confidence are critical.

</details>


### [52] [Sampling from Gaussian Processes: A Tutorial and Applications in Global Sensitivity Analysis and Optimization](https://arxiv.org/abs/2507.14746)
*Bach Do, Nafeezat A. Ajenifuja, Taiwo A. Adebiyi, Ruda Zhang*

**主要类别:** cs.LG

**AI概要:** 本文介绍了两种从高斯过程中生成后验样本的采样方法，并展示了这些方法在全局敏感性分析和优化中的应用。


<details>
  <summary>更多</summary>
  
**动机:** 高保真模拟和物理实验对于工程分析和设计至关重要，但其高昂的成本往往限制了它们在全球敏感性分析和优化任务中的应用。为了在有限的高质量观测基础上提供具有不确定性的预测，高斯过程（GPs）作为代理回归模型被广泛使用。然而，在工程优化领域，从GPs中采样的研究较少。

**方法:** 论文主要探讨了两种显著的采样方法：随机傅立叶特征和路径条件化，并简要描述了其他替代方法。

**结果:** 通过一系列数值实例，展示了这些采样方法在全局敏感性分析、单目标优化和多目标优化中的成功应用。

**结论:** 该论文详细阐述了如何将生成的样本应用于全局敏感性分析和优化问题，并证明了这两种采样方法的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sampling+from+Gaussian+Processes%3A+A+Tutorial+and+Applications+in+Global+Sensitivity+Analysis+and+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14746，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14746&send_immediately=true&force_search=false)

**原文摘要:** High-fidelity simulations and physical experiments are essential for
engineering analysis and design. However, their high cost often limits their
applications in two critical tasks: global sensitivity analysis (GSA) and
optimization. This limitation motivates the common use of Gaussian processes
(GPs) as proxy regression models to provide uncertainty-aware predictions based
on a limited number of high-quality observations. GPs naturally enable
efficient sampling strategies that support informed decision-making under
uncertainty by extracting information from a subset of possible functions for
the model of interest. Despite their popularity in machine learning and
statistics communities, sampling from GPs has received little attention in the
community of engineering optimization. In this paper, we present the
formulation and detailed implementation of two notable sampling methods --
random Fourier features and pathwise conditioning -- for generating posterior
samples from GPs. Alternative approaches are briefly described. Importantly, we
detail how the generated samples can be applied in GSA, single-objective
optimization, and multi-objective optimization. We show successful applications
of these sampling methods through a series of numerical examples.

</details>


### [53] [Pruning Increases Orderedness in Recurrent Computation](https://arxiv.org/abs/2507.14747)
*Yiding Song*

**主要类别:** cs.LG

**AI概要:** 研究显示通过适当的剪枝技术可以诱导出方向性，而方向性可能是有利于学习的归纳偏置。


<details>
  <summary>更多</summary>
  
**动机:** 受生物大脑中循环电路普遍存在的启发，研究人员开始探究方向性对于人工神经网络来说是否是一个有益的归纳偏置。

**方法:** 研究人员定义了一个具有全连接的感知机层，并应用适当的剪枝技术来诱导信息流的方向性。

**结果:** 在不同的随机种子下，剪枝方案成功地在不损害性能的情况下，诱导出了更大的信息流拓扑排序。

**结论:** 方向性不是学习的前提条件，但可能是一个有利的归纳偏置，可以通过梯度下降和稀疏化发现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Pruning+Increases+Orderedness+in+Recurrent+Computation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14747，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14747&send_immediately=true&force_search=false)

**原文摘要:** Inspired by the prevalence of recurrent circuits in biological brains, we
investigate the degree to which directionality is a helpful inductive bias for
artificial neural networks. Taking directionality as topologically-ordered
information flow between neurons, we formalise a perceptron layer with
all-to-all connections (mathematically equivalent to a weight-tied recurrent
neural network) and demonstrate that directionality, a hallmark of modern
feed-forward networks, can be induced rather than hard-wired by applying
appropriate pruning techniques. Across different random seeds our pruning
schemes successfully induce greater topological ordering in information flow
between neurons without compromising performance, suggesting that
directionality is not a prerequisite for learning, but may be an advantageous
inductive bias discoverable by gradient descent and sparsification.

</details>


### [54] [Skill Learning via Policy Diversity Yields Identifiable Representations for Reinforcement Learning](https://arxiv.org/abs/2507.14748)
*Patrik Reizinger, Bálint Mucsányi, Siyuan Guo, Benjamin Eysenbach, Bernhard Schölkopf, Wieland Brendel*

**主要类别:** cs.LG

**AI概要:** 本文研究了互信息技能学习（MISL）在强化学习中通过可识别表示学习的视角，特别是对比继任特征（CSF）方法，并证明了CSF可以恢复环境的真实特征。


<details>
  <summary>更多</summary>
  
**动机:** 互信息技能学习（MISL）是强化学习中自监督特征学习和预训练的方法，但其理论理解尚不充分。为了更好地理解表示学习和互信息参数化在MISL中的作用，作者选择从可识别表示学习的角度研究MISL，并聚焦于对比继任特征（CSF）方法。

**方法:** 作者使用数学证明的方式，展示了CSF方法如何通过特征和技能多样性以线性变换的方式恢复环境的真实特征。此外，作者还探讨了不同互信息目标的影响以及熵正则化的缺点。

**结果:** 作者在MuJoCo和DeepMind Control上进行了实证验证，结果表明CSF可以从状态和像素中恢复环境的真实特征。

**结论:** 这是第一个关于强化学习中表示学习的可识别性保证的研究，它不仅解释了不同互信息目标的影响，也揭示了熵正则化的不足之处。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Skill+Learning+via+Policy+Diversity+Yields+Identifiable+Representations+for+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14748，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14748&send_immediately=true&force_search=false)

**原文摘要:** Self-supervised feature learning and pretraining methods in reinforcement
learning (RL) often rely on information-theoretic principles, termed mutual
information skill learning (MISL). These methods aim to learn a representation
of the environment while also incentivizing exploration thereof. However, the
role of the representation and mutual information parametrization in MISL is
not yet well understood theoretically. Our work investigates MISL through the
lens of identifiable representation learning by focusing on the Contrastive
Successor Features (CSF) method. We prove that CSF can provably recover the
environment's ground-truth features up to a linear transformation due to the
inner product parametrization of the features and skill diversity in a
discriminative sense. This first identifiability guarantee for representation
learning in RL also helps explain the implications of different mutual
information objectives and the downsides of entropy regularizers. We
empirically validate our claims in MuJoCo and DeepMind Control and show how CSF
provably recovers the ground-truth features both from states and pixels.

</details>


### [55] [CXR-TFT: Multi-Modal Temporal Fusion Transformer for Predicting Chest X-ray Trajectories](https://arxiv.org/abs/2507.14766)
*Mehak Arora, Ayman Ali, Kaiyuan Wu, Carolyn Davis, Takashi Shimazui, Mahmoud Alwakeel, Victor Moas, Philip Yang, Annette Esper, Rishikesan Kamaleswaran*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种新的多模态框架CXR-TFT，它结合了稀疏的时间性胸腔X光图像和高频临床数据来预测重症患者的胸腔X光变化轨迹，展示了其在预测异常发现上的高准确度。


<details>
  <summary>更多</summary>
  
**动机:** 作者指出目前的胸腔X光解释工具受限于横断面分析，无法捕捉时间动态，而重症监护室中复杂的患者情况需要警惕监控和及时干预。因此，他们希望开发一种能够整合不规则获取的胸腔X光图像与高频临床数据的方法，以更好地预测胸腔X光的变化轨迹。

**方法:** CXR-TFT利用了一个视觉编码器生成的潜在嵌入，并通过插值将其与每小时的临床数据对齐。然后训练一个变换器模型，基于先前的嵌入和临床测量结果预测每个小时点的胸腔X光嵌入。

**结果:** 在20,000名重症监护病房患者的回顾性研究中，CXR-TFT在预测放射学明显前12小时内出现的异常胸腔X光发现方面表现出高准确性。

**结论:** CXR-TFT提供的预测能力对于急性呼吸窘迫综合症等时间敏感病症的管理具有重大潜力，可以改善临床结果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CXR-TFT%3A+Multi-Modal+Temporal+Fusion+Transformer+for+Predicting+Chest+X-ray+Trajectories，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14766，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14766&send_immediately=true&force_search=false)

**原文摘要:** In intensive care units (ICUs), patients with complex clinical conditions
require vigilant monitoring and prompt interventions. Chest X-rays (CXRs) are a
vital diagnostic tool, providing insights into clinical trajectories, but their
irregular acquisition limits their utility. Existing tools for CXR
interpretation are constrained by cross-sectional analysis, failing to capture
temporal dynamics. To address this, we introduce CXR-TFT, a novel multi-modal
framework that integrates temporally sparse CXR imaging and radiology reports
with high-frequency clinical data, such as vital signs, laboratory values, and
respiratory flow sheets, to predict the trajectory of CXR findings in
critically ill patients. CXR-TFT leverages latent embeddings from a vision
encoder that are temporally aligned with hourly clinical data through
interpolation. A transformer model is then trained to predict CXR embeddings at
each hour, conditioned on previous embeddings and clinical measurements. In a
retrospective study of 20,000 ICU patients, CXR-TFT demonstrated high accuracy
in forecasting abnormal CXR findings up to 12 hours before they became
radiographically evident. This predictive capability in clinical data holds
significant potential for enhancing the management of time-sensitive conditions
like acute respiratory distress syndrome, where early intervention is crucial
and diagnoses are often delayed. By providing distinctive temporal resolution
in prognostic CXR analysis, CXR-TFT offers actionable 'whole patient' insights
that can directly improve clinical outcomes.

</details>


### [56] [Rethinking Memorization Measures and their Implications in Large Language Models](https://arxiv.org/abs/2507.14777)
*Bishwamittra Ghosh, Soumi Das, Qinyuan Wu, Mohammad Aflah Khan, Krishna P. Gummadi, Evimaria Terzi, Deepak Garg*

**主要类别:** cs.LG

**AI概要:** 研究了在最优学习语言时是否可以避免记忆，并重新审视了现有的记忆隐私衡量标准，提出了情境记忆的新概念。通过实验表明不同记忆测量方法对字符串的记忆顺序存在分歧，完全避免训练字符串的部分记忆是不可能的，改进的学习会减少情境和反事实记忆但增加回忆记忆，且一些被报告为存在隐私威胁的记忆实际上并无此威胁。


<details>
  <summary>更多</summary>
  
**动机:** 现有研究认为LLM中的记忆对隐私构成威胁，特别是在学习方面。因此，研究者希望探讨在最优学习语言时是否可以避免记忆，以及评估由记忆带来的隐私威胁是否被夸大。

**方法:** 重新审视了现有的基于回忆和反事实的记忆隐私衡量标准，并提出了一种新的情境记忆标准，该标准旨在区分记忆与上下文学习能力。进行了实验，测试了来自6个家族的18个LLM在不同熵值的形式语言上的表现。

**结果:** （a）不同记忆测量方法对变化频率字符串的记忆顺序存在分歧；（b）最优语言学习无法完全避免训练字符串的部分记忆；（c）改进学习减少了情境和反事实记忆但增加了回忆记忆；（d）一些被报告为存在隐私威胁的记忆实际上并无此威胁。

**结论:** 本研究表明，在最优学习过程中完全避免记忆是不可能的，而且一些被认为存在隐私威胁的记忆实际上并不存在这种威胁。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Rethinking+Memorization+Measures+and+their+Implications+in+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14777，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14777&send_immediately=true&force_search=false)

**原文摘要:** Concerned with privacy threats, memorization in LLMs is often seen as
undesirable, specifically for learning. In this paper, we study whether
memorization can be avoided when optimally learning a language, and whether the
privacy threat posed by memorization is exaggerated or not. To this end, we
re-examine existing privacy-focused measures of memorization, namely
recollection-based and counterfactual memorization, along with a newly proposed
contextual memorization.
  Relating memorization to local over-fitting during learning, contextual
memorization aims to disentangle memorization from the contextual learning
ability of LLMs. Informally, a string is contextually memorized if its
recollection due to training exceeds the optimal contextual recollection, a
learned threshold denoting the best contextual learning without training.
Conceptually, contextual recollection avoids the fallacy of recollection-based
memorization, where any form of high recollection is a sign of memorization.
Theoretically, contextual memorization relates to counterfactual memorization,
but imposes stronger conditions. Memorization measures differ in outcomes and
information requirements.
  Experimenting on 18 LLMs from 6 families and multiple formal languages of
different entropy, we show that (a) memorization measures disagree on
memorization order of varying frequent strings, (b) optimal learning of a
language cannot avoid partial memorization of training strings, and (c)
improved learning decreases contextual and counterfactual memorization but
increases recollection-based memorization. Finally, (d) we revisit existing
reports of memorized strings by recollection that neither pose a privacy threat
nor are contextually or counterfactually memorized.

</details>


### [57] [Omni-Think: Scaling Cross-Domain Generalization in LLMs via Multi-Task RL with Hybrid Rewards](https://arxiv.org/abs/2507.14783)
*Derek Li, Jiaming Zhou, Amirreza Kazemi, Qianyi Sun, Abbas Ghaddar, Mohammad Ali Alomrani, Liheng Ma, Yu Luo, Dong Li, Feng Wen, Jianye Hao, Mark Coates, Yingxue Zhang*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为Omni-Think的统一强化学习框架，该框架通过结合基于规则的可验证奖励和生成偏好信号来增强大型语言模型在各种任务中的表现。研究发现，课程学习策略能有效提高模型性能并减少遗忘。


<details>
  <summary>更多</summary>
  
**动机:** 现有的大型语言模型虽然在多种任务中表现出色，但诸如监督微调等后训练方法往往过于依赖记忆化而难以实现广泛迁移。为了解决这个问题，本研究旨在探索一种可以提升模型跨任务泛化能力的方法。

**方法:** 引入了Omni-Think这一融合了基于规则的验证性奖励与通过LLM-as-a-Judge评估得出的生成偏好信号的强化学习框架，并采用从结构化到开放式的课程式学习策略进行训练。

**结果:** 实验结果显示，在四个不同领域中，课程学习比联合训练提高了5.2%的性能，比模型合并提高了9.1%。

**结论:** 研究结果强调了在扩展基于强化学习的大型语言模型后训练过程中，任务感知采样和混合监督的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Omni-Think%3A+Scaling+Cross-Domain+Generalization+in+LLMs+via+Multi-Task+RL+with+Hybrid+Rewards，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14783，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14783&send_immediately=true&force_search=false)

**原文摘要:** The advancement of general-purpose artificial intelligence relies on large
language models (LLMs) that excel across a wide range of tasks, from structured
reasoning to creative generation. However, post-training methods like
Supervised Fine-Tuning (SFT) often struggle with generalization, favoring
memorization over transferable learning. In this work, we introduce Omni-Think,
a unified reinforcement learning (RL) framework that enhances LLM performance
across diverse tasks by combining rule-based verifiable rewards with generative
preference signals via LLM-as-a-Judge evaluations. Our approach enables
consistent optimization across task types and scales RL-based training to
subjective domains. We further investigate training strategies, demonstrating
that a curriculum-based progression that orders tasks from structured to
open-ended improves performance and reduces forgetting. Experimental results
across four domains reveal that curriculum learning improves performance by
5.2\% over joint training and 9.1\% over model merging. These results highlight
the importance of task-aware sampling and hybrid supervision in scaling
RL-based post-training for general-purpose LLMs.

</details>


### [58] [Exploring the In-Context Learning Capabilities of LLMs for Money Laundering Detection in Financial Graphs](https://arxiv.org/abs/2507.14785)
*Erfan Pirmorad*

**主要类别:** cs.LG

**AI概要:** 本文探讨了使用大型语言模型（LLMs）作为推理引擎，处理从金融知识图谱中提取的局部子图，提出了一种轻量级管道，通过少量样本学习提示LLM评估可疑性和生成理由，展示了LLM在反洗钱（AML）场景中模拟分析师逻辑、突出红旗并提供连贯解释的能力。


<details>
  <summary>更多</summary>
  
**动机:** 洗钱实体的复杂性和互联性要求对图结构数据进行调查推理。

**方法:** 提出一种轻量级管道，检索感兴趣实体周围的k跳邻域，将它们序列化为结构化文本，并通过少量样本学习提示LLM评估可疑性和生成理由。

**结果:** LLMs可以模仿分析师风格的逻辑，突出红灯，并提供连贯的解释，反映了常见的洗钱行为。

**结论:** 本研究虽然探索性，但展示了基于LLM的图推理在AML中的潜力，为可解释的语言驱动型金融犯罪分析奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exploring+the+In-Context+Learning+Capabilities+of+LLMs+for+Money+Laundering+Detection+in+Financial+Graphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14785，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14785&send_immediately=true&force_search=false)

**原文摘要:** The complexity and interconnectivity of entities involved in money laundering
demand investigative reasoning over graph-structured data. This paper explores
the use of large language models (LLMs) as reasoning engines over localized
subgraphs extracted from a financial knowledge graph. We propose a lightweight
pipeline that retrieves k-hop neighborhoods around entities of interest,
serializes them into structured text, and prompts an LLM via few-shot
in-context learning to assess suspiciousness and generate justifications. Using
synthetic anti-money laundering (AML) scenarios that reflect common laundering
behaviors, we show that LLMs can emulate analyst-style logic, highlight red
flags, and provide coherent explanations. While this study is exploratory, it
illustrates the potential of LLM-based graph reasoning in AML and lays
groundwork for explainable, language-driven financial crime analytics.

</details>


### [59] [Flow Equivariant Recurrent Neural Networks](https://arxiv.org/abs/2507.14793)
*T. Anderson Keller*

**主要类别:** cs.LG

**AI概要:** 本文将等变网络理论扩展到'流'的领域，通过引入流等变性，使得模型在训练速度、长度泛化和速度泛化方面显著优于非等变模型。


<details>
  <summary>更多</summary>
  
**动机:** 等变网络在静态变换和前馈网络中具有良好的泛化能力和样本效率，但其在序列模型中的应用受到限制。为了提高RNNs对时间参数化的连续变换的处理能力，有必要探索如何使它们适应这些变换。

**方法:** 作者首先证明了标准RNN通常不是流等变的，然后介绍了如何引入流等变性，并通过实验验证了这种改进的效果。

**结果:** 在下一步预测和序列分类任务上，等变模型在训练速度、长度泛化和速度泛化方面均优于非等变模型。

**结论:** 这项工作是构建尊重时间参数化对称性的序列模型的第一步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Flow+Equivariant+Recurrent+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14793，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14793&send_immediately=true&force_search=false)

**原文摘要:** Data arrives at our senses as a continuous stream, smoothly transforming from
one instant to the next. These smooth transformations can be viewed as
continuous symmetries of the environment that we inhabit, defining equivalence
relations between stimuli over time. In machine learning, neural network
architectures that respect symmetries of their data are called equivariant and
have provable benefits in terms of generalization ability and sample
efficiency. To date, however, equivariance has been considered only for static
transformations and feed-forward networks, limiting its applicability to
sequence models, such as recurrent neural networks (RNNs), and corresponding
time-parameterized sequence transformations. In this work, we extend
equivariant network theory to this regime of `flows' -- one-parameter Lie
subgroups capturing natural transformations over time, such as visual motion.
We begin by showing that standard RNNs are generally not flow equivariant:
their hidden states fail to transform in a geometrically structured manner for
moving stimuli. We then show how flow equivariance can be introduced, and
demonstrate that these models significantly outperform their non-equivariant
counterparts in terms of training speed, length generalization, and velocity
generalization, on both next step prediction and sequence classification. We
present this work as a first step towards building sequence models that respect
the time-parameterized symmetries which govern the world around us.

</details>


### [60] [Subliminal Learning: Language models transmit behavioral traits via hidden signals in data](https://arxiv.org/abs/2507.14805)
*Alex Cloud, Minh Le, James Chua, Jan Betley, Anna Sztyber-Betley, Jacob Hilton, Samuel Marks, Owain Evans*

**主要类别:** cs.LG

**AI概要:** 研究揭示了潜意识学习现象，即使在语义不相关的数据中，语言模型也能传递行为特征。实验表明，当使用由具有特定特征的“教师”模型生成的数据集训练“学生”模型时，学生模型可以学会这些特征。这一现象在神经网络中普遍存在，为AI开发带来了新的挑战。


<details>
  <summary>更多</summary>
  
**动机:** 研究旨在探索和理解语言模型中的潜意识学习现象，即模型通过语义不相关数据传递行为特征的能力。这有助于揭示AI开发中可能存在的意外风险。

**方法:** 研究者设计了一系列实验，其中“教师”模型生成仅包含数字序列的数据集，“学生”模型在此数据集上进行训练。此外，还测试了代码和推理痕迹作为训练数据的效果，并比较了相同和不同基础模型之间的效果。为了进一步解释发现，研究者还提供了一个理论结果，证明在一定条件下，所有神经网络中都会发生潜意识学习。

**结果:** 实验结果显示，“学生”模型能够从由“教师”模型生成的数据中学到其行为特征，即使数据经过过滤去除了对特征的直接引用。潜意识学习现象不仅限于特定类型的数据或模型，而是在所有满足条件的神经网络中普遍存在。

**结论:** 潜意识学习是一种普遍现象，它为AI开发带来了意想不到的挑战。特别是在知识蒸馏过程中，可能会传播开发者试图避免的非预期特性，即使已经尝试通过数据过滤来防止这种情况。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Subliminal+Learning%3A+Language+models+transmit+behavioral+traits+via+hidden+signals+in+data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14805，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14805&send_immediately=true&force_search=false)

**原文摘要:** We study subliminal learning, a surprising phenomenon where language models
transmit behavioral traits via semantically unrelated data. In our main
experiments, a "teacher" model with some trait T (such as liking owls or being
misaligned) generates a dataset consisting solely of number sequences.
Remarkably, a "student" model trained on this dataset learns T. This occurs
even when the data is filtered to remove references to T. We observe the same
effect when training on code or reasoning traces generated by the same teacher
model. However, we do not observe the effect when the teacher and student have
different base models. To help explain our findings, we prove a theoretical
result showing that subliminal learning occurs in all neural networks under
certain conditions, and demonstrate subliminal learning in a simple MLP
classifier. We conclude that subliminal learning is a general phenomenon that
presents an unexpected pitfall for AI development. Distillation could propagate
unintended traits, even when developers try to prevent this via data filtering.

</details>


### [61] [Benchmarking Foundation Models with Multimodal Public Electronic Health Records](https://arxiv.org/abs/2507.14824)
*Kunyu Yu, Rui Yang, Jingchi Liao, Siqi Li, Huitao Li, Irene Li, Yifan Peng, Rishikesan Kamaleswaran, Nan Liu*

**主要类别:** cs.LG

**AI概要:** 研究通过MIMIC-IV数据库评估了基础模型处理电子健康记录的性能、公平性和解释性，发现多模态数据能提升预测性能且不增加偏差。


<details>
  <summary>更多</summary>
  
**动机:** 电子健康记录（EHRs）包含多样化的医疗数据类型，需要一个灵活的方法来处理这些数据。基础模型作为一种强大的方法出现，可以作为单模态编码器和多模态学习者使用，但其性能、公平性和解释性尚未得到充分评估。

**方法:** 使用公开的MIMIC-IV数据库，开发了一个标准化的数据处理管道，将异构临床记录整合为可用于分析的格式。系统地比较了8个基础模型，包括单模态和多模态模型，以及特定领域和通用变体。

**结果:** 研究结果表明，结合多种数据模态可以持续改善预测性能，并且不会引入额外的偏差。

**结论:** 该基准测试旨在支持开发有效的、可信赖的多模态人工智能系统，以用于实际临床应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Benchmarking+Foundation+Models+with+Multimodal+Public+Electronic+Health+Records，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14824，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14824&send_immediately=true&force_search=false)

**原文摘要:** Foundation models have emerged as a powerful approach for processing
electronic health records (EHRs), offering flexibility to handle diverse
medical data modalities. In this study, we present a comprehensive benchmark
that evaluates the performance, fairness, and interpretability of foundation
models, both as unimodal encoders and as multimodal learners, using the
publicly available MIMIC-IV database. To support consistent and reproducible
evaluation, we developed a standardized data processing pipeline that
harmonizes heterogeneous clinical records into an analysis-ready format. We
systematically compared eight foundation models, encompassing both unimodal and
multimodal models, as well as domain-specific and general-purpose variants. Our
findings demonstrate that incorporating multiple data modalities leads to
consistent improvements in predictive performance without introducing
additional bias. Through this benchmark, we aim to support the development of
effective and trustworthy multimodal artificial intelligence (AI) systems for
real-world clinical applications. Our code is available at
https://github.com/nliulab/MIMIC-Multimodal.

</details>


### [62] [eMargin: Revisiting Contrastive Learning with Margin-Based Separation](https://arxiv.org/abs/2507.14828)
*Abdul-Kazeem Shamba, Kerstin Bach, Gavin Taylor*

**主要类别:** cs.LG

**AI概要:** 研究了在对比损失函数中引入自适应边界对时间序列表示学习的影响，尽管在无监督聚类度量方面表现优异，但在下游分类任务中的线性探测结果却不尽如人意。


<details>
  <summary>更多</summary>
  
**动机:** 探究在对比学习框架的时间序列表示学习中，引入基于预定义相似度阈值调整的自适应边界（eMargin），是否能改善相邻但不同时间步骤之间的分离度，并提高下游任务的表现。

**方法:** 通过修改对比损失函数，加入自适应边界（eMargin），并根据预定义的相似度阈值进行调整。然后在三个基准数据集上评估这种修改对聚类性能和分类的影响。

**结果:** 带有eMargin的InfoNCE在无监督聚类度量上持续优于最先进基线，但在下游分类任务中使用线性探测时未能获得有竞争力的结果。

**结论:** 本研究表明，在对比损失函数中添加自适应边界虽然能在某些无监督度量上取得高分，但这并不意味着所学嵌入在下游任务中是有意义或有效的。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是eMargin%3A+Revisiting+Contrastive+Learning+with+Margin-Based+Separation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14828，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14828&send_immediately=true&force_search=false)

**原文摘要:** We revisit previous contrastive learning frameworks to investigate the effect
of introducing an adaptive margin into the contrastive loss function for time
series representation learning. Specifically, we explore whether an adaptive
margin (eMargin), adjusted based on a predefined similarity threshold, can
improve the separation between adjacent but dissimilar time steps and
subsequently lead to better performance in downstream tasks. Our study
evaluates the impact of this modification on clustering performance and
classification in three benchmark datasets. Our findings, however, indicate
that achieving high scores on unsupervised clustering metrics does not
necessarily imply that the learned embeddings are meaningful or effective in
downstream tasks. To be specific, eMargin added to InfoNCE consistently
outperforms state-of-the-art baselines in unsupervised clustering metrics, but
struggles to achieve competitive results in downstream classification with
linear probing. The source code is publicly available at
https://github.com/sfi-norwai/eMargin.

</details>


### [63] [The Invisible Leash: Why RLVR May Not Escape Its Origin](https://arxiv.org/abs/2507.14843)
*Fang Wu, Weihao Xuan, Ximing Lu, Zaid Harchaoui, Yejin Choi*

**主要类别:** cs.LG

**AI概要:** 本研究通过理论和实证调查RLVR的潜力限制，发现RLVR在提升精度的同时可能会缩小探索范围，忽视正确的但代表性不足的解决方案。


<details>
  <summary>更多</summary>
  
**动机:** 探讨RLVR是否真正扩展了模型的推理边界，还是仅仅放大了高回报输出。

**方法:** 提供新的理论视角，识别RLVR的约束，并进行广泛的实证实验。

**结果:** 实验证明RLVR虽然能提高pass@1，但在更大采样预算下，经验支持的收缩通常超过其扩张，未能恢复以前对基础模型可用的正确答案。

**结论:** 研究揭示了RLVR在扩展推理范围上的潜在限制，可能需要未来的算法创新来打破这种无形的束缚。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Invisible+Leash%3A+Why+RLVR+May+Not+Escape+Its+Origin，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14843，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14843&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in large reasoning models highlight Reinforcement Learning
with Verifiable Rewards (RLVR) as a promising method for enhancing AI's
capabilities, particularly in solving complex logical tasks. However, it
remains unclear whether RLVR truly expands a model's reasoning boundary or
merely amplifies high-reward outputs that the base model already knows for
improved precision. This study presents a theoretical and empirical
investigation that provides fresh insights into the potential limits of RLVR.
First, we offer a new theoretical perspective that RLVR is constrained by the
base model's support-unable to sample solutions with zero initial
probability-and operates as a conservative reweighting mechanism that may
restrict the discovery of entirely original solutions. We also identify an
entropy-reward tradeoff: while RLVR reliably enhances precision, it may
progressively narrow exploration and potentially overlook correct yet
underrepresented solutions. Extensive empirical experiments validate that while
RLVR consistently improves pass@1, the shrinkage of empirical support generally
outweighs the expansion of empirical support under larger sampling budgets,
failing to recover correct answers that were previously accessible to the base
model. Interestingly, we also observe that while RLVR sometimes increases
token-level entropy, resulting in greater uncertainty at each generation step,
answer-level entropy declines, indicating that these seemingly more uncertain
paths ultimately converge onto a smaller set of distinct answers. Taken
together, these findings reveal potential limits of RLVR in extending reasoning
horizons. Breaking this invisible leash may require future algorithmic
innovations such as explicit exploration mechanisms or hybrid strategies that
seed probability mass into underrepresented solution regions.

</details>


### [64] [Time-Aware Attention for Enhanced Electronic Health Records Modeling](https://arxiv.org/abs/2507.14847)
*Junhan Yu, Zhunyi Feng, Junwei Lu, Tianxi Cai, Doudou Zhou*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于Transformer的框架TALE-EHR，该框架采用新的时间感知注意机制，能有效处理EHR数据的时间异质性和复杂的时间模式。通过在MIMIC-IV和PIC数据集上的实验，证明了该方法优于现有最先进基线方法。


<details>
  <summary>更多</summary>
  
**动机:** 有效的建模电子健康记录（EHR）对于预测患者结果和指导医疗决策非常重要，但是标准方法难以应对EHR中的数据异质性和复杂的时间模式，尤其是在处理临床事件之间不规则的时间间隔时。

**方法:** 作者提出了一个名为TALE-EHR的新框架，它基于Transformer，并引入了一种新颖的时间感知注意机制，可以显式地模拟连续的时间间隔，从而捕捉序列的细粒度动态变化。同时，为了增强语义理解，TALE-EHR利用预训练的大规模语言模型从标准化代码描述中提取嵌入表示。

**结果:** 在MIMIC-IV和PIC数据集上进行的实验表明，该方法在诸如疾病进展预测等任务上显著优于现有的最先进基线方法。

**结论:** TALE-EHR强调了将明确的、连续的时间建模与强大的语义表示相结合的好处，为推进EHR分析提供了一个强有力的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Time-Aware+Attention+for+Enhanced+Electronic+Health+Records+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14847，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14847&send_immediately=true&force_search=false)

**原文摘要:** Electronic Health Records (EHR) contain valuable clinical information for
predicting patient outcomes and guiding healthcare decisions. However,
effectively modeling Electronic Health Records (EHRs) requires addressing data
heterogeneity and complex temporal patterns. Standard approaches often struggle
with irregular time intervals between clinical events. We propose TALE-EHR, a
Transformer-based framework featuring a novel time-aware attention mechanism
that explicitly models continuous temporal gaps to capture fine-grained
sequence dynamics. To complement this temporal modeling with robust semantics,
TALE-EHR leverages embeddings derived from standardized code descriptions using
a pre-trained Large Language Model (LLM), providing a strong foundation for
understanding clinical concepts. Experiments on the MIMIC-IV and PIC dataset
demonstrate that our approach outperforms state-of-the-art baselines on tasks
such as disease progression forecasting. TALE-EHR underscores the benefit of
integrating explicit, continuous temporal modeling with strong semantic
representations provides a powerful solution for advancing EHR analysis.

</details>


### [65] [Hierarchical Multi-Agent Reinforcement Learning with Control Barrier Functions for Safety-Critical Autonomous Systems](https://arxiv.org/abs/2507.14850)
*H. M. Sabbir Ahmad, Ehsan Sabouni, Alexander Wasilkoff, Param Budhraja, Zijian Guo, Songyuan Zhang, Chuchu Fan, Christos Cassandras, Wenchao Li*

**主要类别:** cs.LG

**AI概要:** 提出了一种基于控制屏障函数的安全分层多智能体强化学习方法，以实现安全策略学习。该方法在具有挑战性的环境中显著提高了安全性并改善了性能。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决多智能体关键安全系统中的安全策略学习问题，确保每个智能体在任何时候都满足安全要求，同时与其他智能体协作完成任务。

**方法:** 提出了一个安全的分层多智能体强化学习（HMARL）方法，该方法基于控制屏障函数（CBFs），将强化学习问题分解为两个层次：高层次学习联合合作行为，低层次学习个体安全行为。

**结果:** 与现有的最先进方法相比，该方法显著提高了安全性，达到了接近完美的成功/安全率（误差在5%以内），并在所有环境中都改善了性能。

**结论:** 该方法在具有挑战性的环境场景中验证了其有效性，其中大量智能体需要通过冲突的道路网络安全导航。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Hierarchical+Multi-Agent+Reinforcement+Learning+with+Control+Barrier+Functions+for+Safety-Critical+Autonomous+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14850，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14850&send_immediately=true&force_search=false)

**原文摘要:** We address the problem of safe policy learning in multi-agent safety-critical
autonomous systems. In such systems, it is necessary for each agent to meet the
safety requirements at all times while also cooperating with other agents to
accomplish the task. Toward this end, we propose a safe Hierarchical
Multi-Agent Reinforcement Learning (HMARL) approach based on Control Barrier
Functions (CBFs). Our proposed hierarchical approach decomposes the overall
reinforcement learning problem into two levels learning joint cooperative
behavior at the higher level and learning safe individual behavior at the lower
or agent level conditioned on the high-level policy. Specifically, we propose a
skill-based HMARL-CBF algorithm in which the higher level problem involves
learning a joint policy over the skills for all the agents and the lower-level
problem involves learning policies to execute the skills safely with CBFs. We
validate our approach on challenging environment scenarios whereby a large
number of agents have to safely navigate through conflicting road networks.
Compared with existing state of the art methods, our approach significantly
improves the safety achieving near perfect (within 5%) success/safety rate
while also improving performance across all the environments.

</details>


### [66] [The Tsetlin Machine Goes Deep: Logical Learning and Reasoning With Graphs](https://arxiv.org/abs/2507.14874)
*Ole-Christoffer Granmo, Youmna Abdelwahab, Per-Arne Andersen, Paul F. A. Clarke, Kunal Dumbre, Ylva Grønninsæter, Vojtech Halenka, Runar Helin, Lei Jiao, Ahmed Khalid, Rebekka Omslandseter, Rupsa Saha, Mayur Shende, Xuan Zhang*

**主要类别:** cs.LG

**AI概要:** 本文介绍了Graph Tsetlin Machine (GraphTM)，它能从图结构输入中学习可解释的深度子句。通过信息传递，GraphTM构建嵌套的深度子句来识别子图模式。GraphTM在图像分类、动作跟踪、推荐系统和病毒基因组序列数据处理上均表现出色。


<details>
  <summary>更多</summary>
  
**动机:** Tsetlin Machine (TM)由于其简洁和平坦的AND规则而具有高效的模式识别能力，同时也非常容易理解。然而，它仅限于平坦且长度固定的输入。因此，作者希望引入一种改进版的TM，即GraphTM，它可以处理更复杂的数据结构，如图结构，并保持可解释性。

**方法:** GraphTM通过消息传递机制从图结构数据中学习，构建嵌套的深度子句以识别子图模式。这使得GraphTM能够用指数级更少的子句实现更高的准确性和更好的数据利用。

**结果:** GraphTM在多个领域的任务中都取得了良好的结果：
- 图像分类（CIFAR-10）：比卷积TM高3.86%；
- 动作跟踪：优于其他强化学习方法20.6%；
- 推荐系统：在噪声比例为0.1时，准确性达到89.86%，而GCN为70.87%；
- 病毒基因组序列数据：与BiLSTM-CNN和GCN相比具有竞争力，训练速度是GCN的2.5倍。

**结论:** GraphTM的应用展示了图表示学习和深度子句给TM学习带来的新机遇。GraphTM不仅保持了TM的可解释性，而且在处理各种类型的任务时表现优异，特别是在处理图结构数据方面。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Tsetlin+Machine+Goes+Deep%3A+Logical+Learning+and+Reasoning+With+Graphs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14874，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14874&send_immediately=true&force_search=false)

**原文摘要:** Pattern recognition with concise and flat AND-rules makes the Tsetlin Machine
(TM) both interpretable and efficient, while the power of Tsetlin automata
enables accuracy comparable to deep learning on an increasing number of
datasets. We introduce the Graph Tsetlin Machine (GraphTM) for learning
interpretable deep clauses from graph-structured input. Moving beyond flat,
fixed-length input, the GraphTM gets more versatile, supporting sequences,
grids, relations, and multimodality. Through message passing, the GraphTM
builds nested deep clauses to recognize sub-graph patterns with exponentially
fewer clauses, increasing both interpretability and data utilization. For image
classification, GraphTM preserves interpretability and achieves 3.86%-points
higher accuracy on CIFAR-10 than a convolutional TM. For tracking action
coreference, faced with increasingly challenging tasks, GraphTM outperforms
other reinforcement learning methods by up to 20.6%-points. In recommendation
systems, it tolerates increasing noise to a greater extent than a Graph
Convolutional Neural Network (GCN), e.g., for noise ratio 0.1, GraphTM obtains
accuracy 89.86% compared to GCN's 70.87%. Finally, for viral genome sequence
data, GraphTM is competitive with BiLSTM-CNN and GCN accuracy-wise, training
2.5x faster than GCN. The GraphTM's application to these varied fields
demonstrates how graph representation learning and deep clauses bring new
possibilities for TM learning.

</details>


### [67] [Application-Specific Component-Aware Structured Pruning of Deep Neural Networks via Soft Coefficient Optimization](https://arxiv.org/abs/2507.14882)
*Ganesh Sundaram, Jonas Ulmen, Amjad Haider, Daniel Görges*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种增强的重要性度量框架，用于结构化剪枝，以减少模型大小并确保满足特定于应用程序的性能约束。


<details>
  <summary>更多</summary>
  
**动机:** 深度神经网络（DNN）由于其高模型复杂性和计算需求，广泛应用受到限制。现有的模型压缩技术如修剪虽然有帮助，但通常无法在压缩过程中保持应用特定的性能特征。

**方法:** 提出一个增强的重要性度量框架，采用多种策略来确定每个组的最佳修剪幅度，从而在压缩和任务性能之间取得平衡。

**结果:** 实验结果表明，所提出的方法有效地保持了与任务相关的性能，即使在大量修剪后也能保持模型的可用性，并满足所需的特定于应用程序的标准。

**结论:** 该方法可以在保证应用特定性能的同时有效减少模型大小，使得深度神经网络的应用更加广泛。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Application-Specific+Component-Aware+Structured+Pruning+of+Deep+Neural+Networks+via+Soft+Coefficient+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14882，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14882&send_immediately=true&force_search=false)

**原文摘要:** Deep neural networks (DNNs) offer significant versatility and performance
benefits, but their widespread adoption is often hindered by high model
complexity and computational demands. Model compression techniques such as
pruning have emerged as promising solutions to these challenges. However, it
remains critical to ensure that application-specific performance
characteristics are preserved during compression. In structured pruning, where
groups of structurally coherent elements are removed, conventional importance
metrics frequently fail to maintain these essential performance attributes. In
this work, we propose an enhanced importance metric framework that not only
reduces model size but also explicitly accounts for application-specific
performance constraints. We employ multiple strategies to determine the optimal
pruning magnitude for each group, ensuring a balance between compression and
task performance. Our approach is evaluated on an autoencoder tasked with
reconstructing MNIST images. Experimental results demonstrate that the proposed
method effectively preserves task-relevant performance, maintaining the model's
usability even after substantial pruning, by satisfying the required
application-specific criteria.

</details>


### [68] [Old Rules in a New Game: Mapping Uncertainty Quantification to Quantum Machine Learning](https://arxiv.org/abs/2507.14919)
*Maximilian Wendlinger, Kilian Tscharke, Pascal Debus*

**主要类别:** cs.LG

**AI概要:** 该论文旨在将经典不确定性量化方法映射到量子机器学习领域，以解决模型透明度问题。


<details>
  <summary>更多</summary>
  
**动机:** 随着量子机器学习的发展，模型复杂度和不透明性增加，导致过度拟合和预测过于自信的问题。尽管在经典环境中对此有很多研究，但在量子机器学习中，这方面的进展很少。

**方法:** 作者借鉴了经典的不确定性量化工作以及量子贝叶斯建模的初步探索，理论发展并在实证上评估了将经典不确定性量化方法映射到量子机器学习领域的技术。

**结果:** 研究表明，在设计新的量子机器学习模型时，有必要利用经典不确定性量化的见解来引入不确定性意识。

**结论:** 为了提高量子机器学习模型的透明度，需要结合经典不确定性量化的方法，增强模型对不确定性的认知。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Old+Rules+in+a+New+Game%3A+Mapping+Uncertainty+Quantification+to+Quantum+Machine+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14919，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14919&send_immediately=true&force_search=false)

**原文摘要:** One of the key obstacles in traditional deep learning is the reduction in
model transparency caused by increasingly intricate model functions, which can
lead to problems such as overfitting and excessive confidence in predictions.
With the advent of quantum machine learning offering possible advances in
computational power and latent space complexity, we notice the same opaque
behavior. Despite significant research in classical contexts, there has been
little advancement in addressing the black-box nature of quantum machine
learning. Consequently, we approach this gap by building upon existing work in
classical uncertainty quantification and initial explorations in quantum
Bayesian modeling to theoretically develop and empirically evaluate techniques
to map classical uncertainty quantification methods to the quantum machine
learning domain. Our findings emphasize the necessity of leveraging classical
insights into uncertainty quantification to include uncertainty awareness in
the process of designing new quantum machine learning models.

</details>


### [69] [FedWCM: Unleashing the Potential of Momentum-based Federated Learning in Long-Tailed Scenarios](https://arxiv.org/abs/2507.14980)
*Tianle Li, Yongzhi Huang, Linshan Jiang, Qipeng Xie, Chang Liu, Wenfeng Du, Lu Wang, Kaishun Wu*

**主要类别:** cs.LG

**AI概要:** 本文提出了FedWCM方法，通过动态调整动量解决了长尾分布引起的非收敛问题，并在处理客户异构性和数据不平衡方面优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 联邦学习（FL）在面对非独立同分布（non-IID）的数据时面临挑战，特别是在长尾场景中，类别样本的不均衡使得基于动量的FL方法难以收敛并导致模型偏差。

**方法:** 提出了一种名为FedWCM的方法，该方法利用全局和每轮的数据动态调整动量，以校正由长尾分布引入的方向性偏差。

**结果:** 广泛的实验表明，FedWCM解决了非收敛的问题，并且在效率和效果上超过了现有的方法，特别是在处理客户异构性和数据不平衡方面。

**结论:** FedWCM是一种有效的解决方案，可以提高联邦学习在处理数据分布不均情况下的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FedWCM%3A+Unleashing+the+Potential+of+Momentum-based+Federated+Learning+in+Long-Tailed+Scenarios，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14980，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14980&send_immediately=true&force_search=false)

**原文摘要:** Federated Learning (FL) enables decentralized model training while preserving
data privacy. Despite its benefits, FL faces challenges with non-identically
distributed (non-IID) data, especially in long-tailed scenarios with imbalanced
class samples. Momentum-based FL methods, often used to accelerate FL
convergence, struggle with these distributions, resulting in biased models and
making FL hard to converge. To understand this challenge, we conduct extensive
investigations into this phenomenon, accompanied by a layer-wise analysis of
neural network behavior. Based on these insights, we propose FedWCM, a method
that dynamically adjusts momentum using global and per-round data to correct
directional biases introduced by long-tailed distributions. Extensive
experiments show that FedWCM resolves non-convergence issues and outperforms
existing methods, enhancing FL's efficiency and effectiveness in handling
client heterogeneity and data imbalance.

</details>


### [70] [Clustered Federated Learning for Generalizable FDIA Detection in Smart Grids with Heterogeneous Data](https://arxiv.org/abs/2507.14999)
*Yunfeng Li, Junhong Liu, Zhaohui Yang, Guofu Liao, Chuyun Zhang*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种隐私保护的联邦学习框架——Federated Cluster Average（FedClusAvg），用于改进在非独立同分布(Non-IID)和资源受限环境下的虚假数据注入攻击(FDIA)检测。通过基于聚类的分层抽样和层次化通信，该算法实现了模型泛化性能的提升和通信开销的减少，同时避免了集中敏感数据。实验证明，FedClusAvg提高了检测精度并减少了通信轮次和带宽消耗。


<details>
  <summary>更多</summary>
  
**动机:** 现有的FDIA检测方法面临着数据非独立同分布(Non-IID)带来的泛化能力挑战，以及传统集中训练方法存在的隐私风险、数据共享限制和高传输成本的问题，这些都限制了其可扩展性和部署可行性。

**方法:** 提出了一个名为Federated Cluster Average (FedClusAvg)的隐私保护联邦学习框架。该框架结合了基于聚类的分层抽样和客户机-子服务器-服务器的层次化通信机制，以增强模型泛化并降低通信成本。通过本地化训练和加权参数聚合，可以在不集中敏感数据的情况下实现准确的模型收敛。

**结果:** 实验结果表明，FedClusAvg不仅在异构数据分布下提高了检测准确性，而且大幅减少了通信轮次和带宽消耗。

**结论:** 这项工作提供了一个有效的解决方案，可以安全高效地在大规模分布式电力系统中进行FDIA检测。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Clustered+Federated+Learning+for+Generalizable+FDIA+Detection+in+Smart+Grids+with+Heterogeneous+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14999，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14999&send_immediately=true&force_search=false)

**原文摘要:** False Data Injection Attacks (FDIAs) pose severe security risks to smart
grids by manipulating measurement data collected from spatially distributed
devices such as SCADA systems and PMUs. These measurements typically exhibit
Non-Independent and Identically Distributed (Non-IID) characteristics across
different regions, which significantly challenges the generalization ability of
detection models. Traditional centralized training approaches not only face
privacy risks and data sharing constraints but also incur high transmission
costs, limiting their scalability and deployment feasibility. To address these
issues, this paper proposes a privacy-preserving federated learning framework,
termed Federated Cluster Average (FedClusAvg), designed to improve FDIA
detection in Non-IID and resource-constrained environments. FedClusAvg
incorporates cluster-based stratified sampling and hierarchical communication
(client-subserver-server) to enhance model generalization and reduce
communication overhead. By enabling localized training and weighted parameter
aggregation, the algorithm achieves accurate model convergence without
centralizing sensitive data. Experimental results on benchmark smart grid
datasets demonstrate that FedClusAvg not only improves detection accuracy under
heterogeneous data distributions but also significantly reduces communication
rounds and bandwidth consumption. This work provides an effective solution for
secure and efficient FDIA detection in large-scale distributed power systems.

</details>


### [71] [Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback](https://arxiv.org/abs/2507.15066)
*Yiyuan Yang, Zichuan Liu, Lei Song, Kai Ying, Zhiguang Wang, Tom Bamford, Svitlana Vyetrenko, Jiang Bian, Qingsong Wen*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的时间序列异常检测任务Time-RA，该任务通过大型语言模型将传统的时间序列异常检测转化为生成性和推理密集型任务，并引入了带有详细标注的多模态数据集RATs40K。


<details>
  <summary>更多</summary>
  
**动机:** 当前的时间序列异常检测方法通常只进行二元异常分类，而没有详细的分类或解释性推理。为了解决这些限制，提出了一个新的任务和数据集。

**方法:** 利用大型语言模型（LLMs）将经典的时间序列异常检测转变为生成性和推理密集型任务。开发了一个复杂的注释框架，使用集成生成标签并通过GPT-4驱动的反馈进行细化。

**结果:** 对LLMs和多模态LLMs的广泛基准测试展示了现有模型的能力和局限性，强调了监督微调的关键作用。

**结论:** 这项工作为可解释的时间序列异常检测和推理的重大进展铺平了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Time-RA%3A+Towards+Time+Series+Reasoning+for+Anomaly+with+LLM+Feedback，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15066，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15066&send_immediately=true&force_search=false)

**原文摘要:** Time series anomaly detection is critical across various domains, yet current
approaches often limit analysis to mere binary anomaly classification without
detailed categorization or further explanatory reasoning. To address these
limitations, we propose a novel task, Time-series Reasoning for Anomaly
(Time-RA) that transforms classical time series anomaly detection from a
discriminative into a generative, reasoning-intensive task leveraging Large
Language Models (LLMs). Also, we introduce the first real-world multimodal
benchmark dataset, RATs40K, explicitly annotated for anomaly reasoning,
comprising approximately 40,000 samples across 10 real-world domains. Each
sample includes numeric time series data, contextual text information, and
visual representations, each annotated with fine-grained categories (14 types
for univariate anomalies and 6 for multivariate anomalies) and structured
explanatory reasoning. We develop a sophisticated annotation framework
utilizing ensemble-generated labels refined through GPT-4-driven feedback,
ensuring accuracy and interpretability. Extensive benchmarking of LLMs and
multimodal LLMs demonstrates the capabilities and limitations of current
models, highlighting the critical role of supervised fine-tuning. Our dataset
and task pave the way for significant advancements in interpretable time series
anomaly detection and reasoning.

</details>


### [72] [ROBAD: Robust Adversary-aware Local-Global Attended Bad Actor Detection Sequential Model](https://arxiv.org/abs/2507.15067)
*Bing He, Mustaque Ahamad, Srijan Kumar*

**主要类别:** cs.LG

**AI概要:** 为了提高对不良用户检测的鲁棒性，本文提出了一个基于变换器的新分类模型ROBAD。该模型通过捕捉帖子和序列级别的局部和全局信息，并利用模拟攻击者的行为进行对比学习增强分类层，从而在最先进的对抗性攻击下有效地检测不良用户。


<details>
  <summary>更多</summary>
  
**动机:** 过去的基于深度学习的检测模型虽然能够准确检测不良用户，但对输入序列中的微小变化非常敏感，无法满足对抗性攻击下的鲁棒性要求。因此，需要改进模型的理解能力和增强模型知识以应对潜在的输入修改。

**方法:** ROBAD模型首先使用变换器编码器块双向编码每个帖子，生成帖子嵌入以捕捉帖子级别的局部信息。然后，它采用变换器解码器块通过注意力机制建模帖子嵌入中的顺序模式，生成序列嵌入以获得序列级别的全局信息。最后，为了丰富模型的知识，将模拟攻击者修改后的序列嵌入输入到对比学习增强的分类层中进行序列预测。

**结果:** 广泛的实验表明，ROBAD可以在最新的对抗性攻击下有效检测不良用户。

**结论:** ROBAD通过捕捉局部和全局信息并利用模拟不良用户行为训练，可以对对抗性攻击保持鲁棒性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ROBAD%3A+Robust+Adversary-aware+Local-Global+Attended+Bad+Actor+Detection+Sequential+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15067，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15067&send_immediately=true&force_search=false)

**原文摘要:** Detecting bad actors is critical to ensure the safety and integrity of
internet platforms. Several deep learning-based models have been developed to
identify such users. These models should not only accurately detect bad actors,
but also be robust against adversarial attacks that aim to evade detection.
However, past deep learning-based detection models do not meet the robustness
requirement because they are sensitive to even minor changes in the input
sequence. To address this issue, we focus on (1) improving the model
understanding capability and (2) enhancing the model knowledge such that the
model can recognize potential input modifications when making predictions. To
achieve these goals, we create a novel transformer-based classification model,
called ROBAD (RObust adversary-aware local-global attended Bad Actor Detection
model), which uses the sequence of user posts to generate user embedding to
detect bad actors. Particularly, ROBAD first leverages the transformer encoder
block to encode each post bidirectionally, thus building a post embedding to
capture the local information at the post level. Next, it adopts the
transformer decoder block to model the sequential pattern in the post
embeddings by using the attention mechanism, which generates the sequence
embedding to obtain the global information at the sequence level. Finally, to
enrich the knowledge of the model, embeddings of modified sequences by mimicked
attackers are fed into a contrastive-learning-enhanced classification layer for
sequence prediction. In essence, by capturing the local and global information
(i.e., the post and sequence information) and leveraging the mimicked behaviors
of bad actors in training, ROBAD can be robust to adversarial attacks.
Extensive experiments on Yelp and Wikipedia datasets show that ROBAD can
effectively detect bad actors when under state-of-the-art adversarial attacks.

</details>


### [73] [Reinforcement Learning for Flow-Matching Policies](https://arxiv.org/abs/2507.15073)
*Samuel Pfrommer, Yixiao Huang, Somayeh Sojoudi*

**主要类别:** cs.LG

**AI概要:** 本文探讨了通过强化学习训练流匹配策略以超越原始演示策略性能的方法，并介绍了两种方法：奖励加权流匹配（RWFM）和具有学习奖励代理的组相对策略优化（GRPO）。


<details>
  <summary>更多</summary>
  
**动机:** 通常，训练演示是由次优策略生成的，例如人类操作员。因此，有必要探索如何通过强化学习训练流匹配策略来超越原始演示策略的性能。

**方法:** 作者提出了两种方法：一种简单的奖励加权流匹配（RWFM）方案和一种具有学习奖励代理的组相对策略优化（GRPO）方法。

**结果:** 这两种方法在模拟的单轮车动力学任务中都显著提高了次优演示者的性能，特别是GRPO方法通常比朴素的模仿学习流匹配（ILFM）方法减少50%到85%的成本。

**结论:** 通过使用强化学习训练流匹配策略可以有效地提升其性能，尤其是在最小时间控制等关键应用中。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reinforcement+Learning+for+Flow-Matching+Policies，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15073，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15073&send_immediately=true&force_search=false)

**原文摘要:** Flow-matching policies have emerged as a powerful paradigm for generalist
robotics. These models are trained to imitate an action chunk, conditioned on
sensor observations and textual instructions. Often, training demonstrations
are generated by a suboptimal policy, such as a human operator. This work
explores training flow-matching policies via reinforcement learning to surpass
the original demonstration policy performance. We particularly note
minimum-time control as a key application and present a simple scheme for
variable-horizon flow-matching planning. We then introduce two families of
approaches: a simple Reward-Weighted Flow Matching (RWFM) scheme and a Group
Relative Policy Optimization (GRPO) approach with a learned reward surrogate.
Our policies are trained on an illustrative suite of simulated unicycle
dynamics tasks, and we show that both approaches dramatically improve upon the
suboptimal demonstrator performance, with the GRPO approach in particular
generally incurring between $50\%$ and $85\%$ less cost than a naive Imitation
Learning Flow Matching (ILFM) approach.

</details>


### [74] [Isotonic Quantile Regression Averaging for uncertainty quantification of electricity price forecasts](https://arxiv.org/abs/2507.15079)
*Arkadiusz Lipiecki, Bartosz Uniejewski*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的方法，即等位量化回归平均（iQRA），用于从点预测集合中生成概率预测。通过引入随机顺序约束，iQRA提高了预测的准确性、可靠性和计算效率。在德国日前电力市场的预测研究中，iQRA在可靠性和锐度方面均优于最先进的后处理方法。此外，iQRA减少了量化回归问题的复杂性，并提供了一种无需超参数调整的变量选择方法。


<details>
  <summary>更多</summary>
  
**动机:** 数据驱动决策中的不确定性评估对于降低风险至关重要，特别是在波动较大的领域如电力市场。虽然机器学习方法可以提供高准确度的电价预测，但这些模型通常缺乏不确定性估计，这限制了决策者规避不必要风险的能力。

**方法:** 基于已建立的量化回归平均框架，引入随机顺序约束，提出了等位量化回归平均（iQRA）方法。该方法能够提高预测的准确性、可靠性及计算效率，同时减少量化回归问题的复杂性。

**结果:** 在对德国日前电力市场的广泛预测研究中，iQRA在可靠性和锐度方面始终优于最新的后处理方法。它在多个置信水平上产生了校准良好的预测区间，尤其是在基于覆盖率的符合性预测方面提供了卓越的可靠性。

**结论:** iQRA为从点预测集合中生成概率预测提供了一种有效的方法，不仅提高了预测性能，还降低了量化回归问题的复杂性，无需超参数调整即可进行变量选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Isotonic+Quantile+Regression+Averaging+for+uncertainty+quantification+of+electricity+price+forecasts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15079，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15079&send_immediately=true&force_search=false)

**原文摘要:** Quantifying the uncertainty of forecasting models is essential to assess and
mitigate the risks associated with data-driven decisions, especially in
volatile domains such as electricity markets. Machine learning methods can
provide highly accurate electricity price forecasts, critical for informing the
decisions of market participants. However, these models often lack uncertainty
estimates, which limits the ability of decision makers to avoid unnecessary
risks. In this paper, we propose a novel method for generating probabilistic
forecasts from ensembles of point forecasts, called Isotonic Quantile
Regression Averaging (iQRA). Building on the established framework of Quantile
Regression Averaging (QRA), we introduce stochastic order constraints to
improve forecast accuracy, reliability, and computational costs. In an
extensive forecasting study of the German day-ahead electricity market, we show
that iQRA consistently outperforms state-of-the-art postprocessing methods in
terms of both reliability and sharpness. It produces well-calibrated prediction
intervals across multiple confidence levels, providing superior reliability to
all benchmark methods, particularly coverage-based conformal prediction. In
addition, isotonic regularization decreases the complexity of the quantile
regression problem and offers a hyperparameter-free approach to variable
selection.

</details>


### [75] [Robust Control with Gradient Uncertainty](https://arxiv.org/abs/2507.15082)
*Qian Qi*

**主要类别:** cs.LG

**AI概要:** 本文引入了一种新的鲁棒控制理论扩展，该扩展特别针对强化学习等应用中的价值函数梯度不确定性。通过建立一个零和动态博弈模型，提出了一个新的非线性偏微分方程，并在特定条件下证明了其适定性。研究发现，在非零梯度不确定性的存在下，传统的二次价值函数假设不再成立。此外，文中还提出了一种新的GURAC算法以应对梯度不确定性，并通过实证研究验证了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 强化学习等领域的函数逼近问题中，价值函数的梯度不确定性是一个未被充分解决的问题。当前的鲁棒控制理论没有直接处理这种类型的不确定性，因此需要一种新的方法来改进这些情况下的控制策略。

**方法:** 作者构建了一个零和动态博弈模型，在该模型中对手可以干扰系统动力学和价值函数梯度，从而导出了一个新的偏微分方程GU-HJBI。然后对线性-二次案例进行了分析，表明在任何非零梯度不确定性的情况下，经典的价值函数假设将失效。基于此，提出了一种新的GURAC算法，用于稳定训练过程。

**结果:** 在非零梯度不确定性的情况下，传统的方法无法适用，必须考虑价值函数的非多项式修正和最优控制律的非线性。提出的GURAC算法通过数值实验得到了验证，显示其能够有效稳定训练。

**结论:** 这项工作为鲁棒控制提供了一个新方向，特别是在函数逼近常见的领域（如强化学习和计算金融）中具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robust+Control+with+Gradient+Uncertainty，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15082，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15082&send_immediately=true&force_search=false)

**原文摘要:** We introduce a novel extension to robust control theory that explicitly
addresses uncertainty in the value function's gradient, a form of uncertainty
endemic to applications like reinforcement learning where value functions are
approximated. We formulate a zero-sum dynamic game where an adversary perturbs
both system dynamics and the value function gradient, leading to a new, highly
nonlinear partial differential equation: the Hamilton-Jacobi-Bellman-Isaacs
Equation with Gradient Uncertainty (GU-HJBI). We establish its well-posedness
by proving a comparison principle for its viscosity solutions under a uniform
ellipticity condition. Our analysis of the linear-quadratic (LQ) case yields a
key insight: we prove that the classical quadratic value function assumption
fails for any non-zero gradient uncertainty, fundamentally altering the problem
structure. A formal perturbation analysis characterizes the non-polynomial
correction to the value function and the resulting nonlinearity of the optimal
control law, which we validate with numerical studies. Finally, we bridge
theory to practice by proposing a novel Gradient-Uncertainty-Robust
Actor-Critic (GURAC) algorithm, accompanied by an empirical study demonstrating
its effectiveness in stabilizing training. This work provides a new direction
for robust control, holding significant implications for fields where function
approximation is common, including reinforcement learning and computational
finance.

</details>


### [76] [AnalogFed: Federated Discovery of Analog Circuit Topologies with Generative AI](https://arxiv.org/abs/2507.15104)
*Qiufeng Li, Shu Hong, Jian Gao, Xuan Zhang, Tian Lan, Weidong Cao*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为AnalogFed的新方法，它允许在不共享原始私有数据的情况下进行协作式的拓扑发现。该方法通过一系列技术解决了联邦学习在模拟设计中的独特挑战，并且实验表明其性能与集中式基线相当，同时保持严格的数据隐私。


<details>
  <summary>更多</summary>
  
**动机:** 模拟电路设计是专有的，包含机密电路结构和商业半导体工艺，这使得生成式AI的研究受到限制，因为研究人员只能构建小的、狭窄的私人数据集。这种碎片化严重限制了协同创新并阻碍了研究社区的进步。

**方法:** 研究人员提出了AnalogFed，它可以在分散的客户端之间（例如个人研究人员或机构）实现协作拓扑发现，而无需共享原始私有数据。为了使这个愿景成为现实，他们引入了一系列针对应用联邦学习在模拟设计中的独特挑战的技术，包括生成模型开发、数据异构性处理以及确保电路设计师和半导体制造商灵活性和安全性的隐私保护策略。

**结果:** 广泛的实验表明，AnalogFed在不同的客户端数量和数据集大小下实现了与集中式基线相当的性能，同时保持严格的数据隐私。特别是，AnalogFed内的生成AI模型在模拟电路拓扑设计中达到了最先进的效率和可扩展性。

**结论:** AnalogFed提供了一种新的方式来进行模拟电路设计的协作式拓扑发现，能够在保证数据隐私的同时提高设计效率和可扩展性。这对于推动模拟电路设计领域的发展具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AnalogFed%3A+Federated+Discovery+of+Analog+Circuit+Topologies+with+Generative+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15104，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15104&send_immediately=true&force_search=false)

**原文摘要:** Recent breakthroughs in AI/ML offer exciting opportunities to revolutionize
analog design automation through data-driven approaches. In particular,
researchers are increasingly fascinated by harnessing the power of generative
AI to automate the discovery of novel analog circuit topologies. Unlocking the
full potential of generative AI in these data-driven discoveries requires
access to large and diverse datasets.Yet, there is a significant barrier in the
analog domain--Analog circuit design is inherently proprietary, involving not
only confidential circuit structures but also the underlying commercial
semiconductor processes. As a result, current generative AI research is largely
confined to individual researchers who construct small, narrowly focused
private datasets. This fragmentation severely limits collaborative innovation
and impedes progress across the research community. To address these
challenges, we propose AnalogFed. AnalogFed enables collaborative topology
discovery across decentralized clients (e.g., individual researchers or
institutions) without requiring the sharing of raw private data. To make this
vision practical, we introduce a suite of techniques tailored to the unique
challenges of applying FedL in analog design--from generative model development
and data heterogeneity handling to privacy-preserving strategies that ensure
both flexibility and security for circuit designers and semiconductor
manufacturers. Extensive experiments across varying client counts and dataset
sizes demonstrate that AnalogFed achieves performance comparable to centralized
baselines--while maintaining strict data privacy. Specifically, the generative
AI model within AnalogFed achieves state-of-the-art efficiency and scalability
in the design of analog circuit topologies.

</details>


### [77] [Are We Overlooking the Dimensions? Learning Latent Hierarchical Channel Structure for High-Dimensional Time Series Forecasting](https://arxiv.org/abs/2507.15119)
*Juntong Ni, Shiyu Wang, Zewen Liu, Xiaoming Shi, Xinyue Zhong, Zhou Ye, Wei Jin*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种名为U-Cast的通道依赖预测架构，针对高维时间序列预测（HDTSF）问题，通过引入基于查询的注意力机制学习潜在的层次化通道结构，并在训练中添加全秩正则化以解缠高度相关的通道表示。实验表明，U-Cast在准确性和效率上均优于现有模型。


<details>
  <summary>更多</summary>
  
**动机:** 随着数据集中通道数量扩展到数千个或更多，传统的时间序列预测方法难以应对由此带来的复杂和分层模式的通道相关性挑战。

**方法:** U-Cast采用创新的基于查询的注意力机制来学习隐藏的层次化通道结构，并在训练过程中加入全秩正则化以分离高度相关的通道表示。

**结果:** 理论分析表明利用跨通道信息可以降低预测风险；实验证明U-Cast在Time-HD基准测试中超越了多个强基线模型，在准确性和效率方面表现更优。

**结论:** U-Cast和Time-HD为未来的高维时间序列预测研究提供了坚实的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Are+We+Overlooking+the+Dimensions%3F+Learning+Latent+Hierarchical+Channel+Structure+for+High-Dimensional+Time+Series+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15119，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15119&send_immediately=true&force_search=false)

**原文摘要:** Time series forecasting (TSF) is a central problem in time series analysis.
However, as the number of channels in time series datasets scales to the
thousands or more, a scenario we define as High-Dimensional Time Series
Forecasting (HDTSF), it introduces significant new modeling challenges that are
often not the primary focus of traditional TSF research. HDTSF is challenging
because the channel correlation often forms complex and hierarchical patterns.
Existing TSF models either ignore these interactions or fail to scale as
dimensionality grows. To address this issue, we propose U-Cast, a
channel-dependent forecasting architecture that learns latent hierarchical
channel structures with an innovative query-based attention. To disentangle
highly correlated channel representation, U-Cast adds a full-rank
regularization during training. We also release Time-HD, a benchmark of large,
diverse, high-dimensional datasets. Our theory shows that exploiting
cross-channel information lowers forecasting risk, and experiments on Time-HD
demonstrate that U-Cast surpasses strong baselines in both accuracy and
efficiency. Together, U-Cast and Time-HD provide a solid basis for future HDTSF
research.

</details>


### [78] [Transforming Datasets to Requested Complexity with Projection-based Many-Objective Genetic Algorithm](https://arxiv.org/abs/2507.15132)
*Joanna Komorniczak*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种遗传算法，用于优化分类和回归任务的问题复杂性度量，以生成具有特定复杂性值的数据集。实验表明，数据集的复杂性与识别质量之间存在相关性。


<details>
  <summary>更多</summary>
  
**动机:** 研究社区一直在寻求更高级的合成数据生成器来评估机器学习方法的优缺点。为了增加涵盖不同问题复杂度的数据集的可用性，提出了本研究。

**方法:** 提出了一种遗传算法，该算法针对分类和回归任务优化一组问题复杂性度量，以达到特定目标。对于分类任务使用了10个复杂性度量，对于回归任务选择了4个表现出良好优化能力的度量。通过线性特征投影转换合成创建的数据集，以实现目标复杂性值。

**结果:** 实验确认了所提出的遗传算法可以生成不同程度难度的数据集，并且涉及最先进的分类器和回归模型的评估揭示了生成数据的复杂性和识别质量之间的相关性。

**结论:** 该研究表明，通过优化问题复杂性度量，可以有效地生成具有不同复杂度的数据集，并且这些数据集的复杂性影响了机器学习模型的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Transforming+Datasets+to+Requested+Complexity+with+Projection-based+Many-Objective+Genetic+Algorithm，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15132，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15132&send_immediately=true&force_search=false)

**原文摘要:** The research community continues to seek increasingly more advanced synthetic
data generators to reliably evaluate the strengths and limitations of machine
learning methods. This work aims to increase the availability of datasets
encompassing a diverse range of problem complexities by proposing a genetic
algorithm that optimizes a set of problem complexity measures for
classification and regression tasks towards specific targets. For
classification, a set of 10 complexity measures was used, while for regression
tasks, 4 measures demonstrating promising optimization capabilities were
selected. Experiments confirmed that the proposed genetic algorithm can
generate datasets with varying levels of difficulty by transforming
synthetically created datasets to achieve target complexity values through
linear feature projections. Evaluations involving state-of-the-art classifiers
and regressors revealed a correlation between the complexity of the generated
data and the recognition quality.

</details>


### [79] [Constraint-aware Learning of Probabilistic Sequential Models for Multi-Label Classification](https://arxiv.org/abs/2507.15156)
*Mykhailo Buleshnyi, Anna Polova, Zsolt Zombori, Michael Benedikt*

**主要类别:** cs.LG

**AI概要:** 本文研究了大规模标签的多标签分类问题，提出了一种能利用标签之间逻辑约束关系的架构，并证实了该架构在训练和推理时利用及强制执行这些约束的能力。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决大规模标签的多标签分类问题，同时利用标签之间的逻辑约束来提高分类性能。

**方法:** 提出一种架构，其中个体标签的分类器输入到一个表达性的序列模型中，产生联合分布，从而能够对标签间的相关性进行建模。

**结果:** 通过实验证明了所提出的架构能够在训练过程中利用约束，并且可以在推理阶段强制执行这些约束。

**结论:** 这种架构可以有效地利用标签之间的逻辑约束，提高多标签分类的效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Constraint-aware+Learning+of+Probabilistic+Sequential+Models+for+Multi-Label+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15156，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15156&send_immediately=true&force_search=false)

**原文摘要:** We investigate multi-label classification involving large sets of labels,
where the output labels may be known to satisfy some logical constraints. We
look at an architecture in which classifiers for individual labels are fed into
an expressive sequential model, which produces a joint distribution. One of the
potential advantages for such an expressive model is its ability to modelling
correlations, as can arise from constraints. We empirically demonstrate the
ability of the architecture both to exploit constraints in training and to
enforce constraints at inference time.

</details>


### [80] [Resonant-Tunnelling Diode Reservoir Computing System for Image Recognition](https://arxiv.org/abs/2507.15158)
*A. H. Abbas, Hend Abdel-Ghani, Ivan S. Maksymov*

**主要类别:** cs.LG

**AI概要:** 本研究提出并验证了一种基于共振隧道二极管（RTD）的神经形态计算架构，并展示了其在图像识别基准测试中的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 随着人工智能不断向实时、基于边缘和资源受限的环境推进，对于新型、硬件高效的计算模型有着迫切的需求。

**方法:** 该研究通过理论公式化和数值实现一个基于RTD的物理储备池计算系统，并在两个图像识别基准上进行了测试：手写数字分类和使用Fruit 360数据集的对象识别。

**结果:** 实验结果表明，这种电路级架构在性能方面具有很大的潜力，并且符合下一代RC的原则——消除随机连接，转而采用输入信号的确定性非线性转换。

**结论:** 基于RTD的神经形态计算架构为资源受限环境提供了一个有效的解决方案，同时展示了在图像识别任务中的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Resonant-Tunnelling+Diode+Reservoir+Computing+System+for+Image+Recognition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15158，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15158&send_immediately=true&force_search=false)

**原文摘要:** As artificial intelligence continues to push into real-time, edge-based and
resource-constrained environments, there is an urgent need for novel,
hardware-efficient computational models. In this study, we present and validate
a neuromorphic computing architecture based on resonant-tunnelling diodes
(RTDs), which exhibit the nonlinear characteristics ideal for physical
reservoir computing (RC). We theoretically formulate and numerically implement
an RTD-based RC system and demonstrate its effectiveness on two image
recognition benchmarks: handwritten digit classification and object recognition
using the Fruit~360 dataset. Our results show that this circuit-level
architecture delivers promising performance while adhering to the principles of
next-generation RC -- eliminating random connectivity in favour of a
deterministic nonlinear transformation of input signals.

</details>


### [81] [Designing User-Centric Metrics for Evaluation of Counterfactual Explanations](https://arxiv.org/abs/2507.15162)
*Firdaus Ahmed Choudhury, Ethan Leicht, Jude Ethan Bislig, Hangzhi Guo, Amulya Yadav*

**主要类别:** cs.LG

**AI概要:** 这篇论文通过用户研究验证了现有的反事实解释（CFE）评价指标与真实用户偏好的匹配度有限，并提出了一个基于用户中心的AWP模型，该模型在预测用户偏好CFE方面具有84.37%的准确性。


<details>
  <summary>更多</summary>
  
**动机:** 机器学习决策模型的不透明性导致终端用户无法清楚理解决策原因，而现有的反事实解释（CFE）评价方法未能充分考虑用户的实际需求和约束。

**方法:** 作者首先进行了一个20人的试点研究，以验证现有CFE评价指标与真实用户偏好的匹配情况；然后进行了一项41人参与的详细用户研究，测试三个关于用户如何评估CFEs的假设；最后基于这些发现提出了AWP模型。

**结果:** 首次证明了个性化成本模型在生成CFE中的有效性，提出的AWP模型能够以84.37%的准确率预测用户偏好的CFE。

**结论:** 研究表明，需要设计适应性的、以用户为中心的CFE评价指标来提高其在现实世界应用中的适用性和有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Designing+User-Centric+Metrics+for+Evaluation+of+Counterfactual+Explanations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15162，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15162&send_immediately=true&force_search=false)

**原文摘要:** Machine learning-based decision models are increasingly being used to make
decisions that significantly impact people's lives, but their opaque nature
leaves end users without a clear understanding of why a decision was made.
Counterfactual Explanations (CFEs) have grown in popularity as a means of
offering actionable guidance by identifying the minimum changes in feature
values required to flip a model's prediction to something more desirable.
Unfortunately, most prior research in CFEs relies on artificial evaluation
metrics, such as proximity, which may overlook end-user preferences and
constraints, e.g., the user's perception of effort needed to make certain
feature changes may differ from that of the model designer. To address this
research gap, this paper makes three novel contributions. First, we conduct a
pilot study with 20 crowd-workers on Amazon MTurk to experimentally validate
the alignment of existing CF evaluation metrics with real-world user
preferences. Results show that user-preferred CFEs matched those based on
proximity in only 63.81% of cases, highlighting the limited applicability of
these metrics in real-world settings. Second, inspired by the need to design a
user-informed evaluation metric for CFEs, we conduct a more detailed two-day
user study with 41 participants facing realistic credit application scenarios
to find experimental support for or against three intuitive hypotheses that may
explain how end users evaluate CFEs. Third, based on the findings of this
second study, we propose the AWP model, a novel user-centric, two-stage model
that describes one possible mechanism by which users evaluate and select CFEs.
Our results show that AWP predicts user-preferred CFEs with 84.37% accuracy.
Our study provides the first human-centered validation for personalized cost
models in CFE generation and highlights the need for adaptive, user-centered
evaluation metrics.

</details>


### [82] [Better Models and Algorithms for Learning Ising Models from Dynamics](https://arxiv.org/abs/2507.15173)
*Jason Gaitonde, Ankur Moitra, Elchanan Mossel*

**主要类别:** cs.LG

**AI概要:** 本文解决了在更自然的观察模型下有效学习Ising模型的问题，该模型仅在配置更改时进行观察。对于最大度为d的Ising模型，算法在时间poly(d)·n²log n中恢复底层依赖图，并在额外的O~(2ᵈn)时间内恢复实际参数。


<details>
  <summary>更多</summary>
  
**动机:** 之前的工作假设可以观察到所有的站点更新尝试，即使这些尝试没有改变配置。然而，在大多数现实情况下，我们只能观察到随机演变本身。因此，需要设计一种可以在这种更现实的设置中成功的算法。

**方法:** 作者提出了第一个可以在只观察到配置变化的情况下有效地学习Ising模型的算法。对于具有最大度d的Ising模型，该算法能在多项式时间内恢复底层依赖图和实际参数。此外，该方法适用于更广泛的可逆单站点马尔科夫链类，包括流行的Metropolis链。

**结果:** 该算法能够恢复最大度为d的Ising模型的底层依赖图，并且在比现有最佳技术更弱的观察模型下，其性能与之相匹配。

**结论:** 这项工作首次提供了在更自然的观察模型中有效地学习Ising模型的算法，该模型仅在配置变化时进行观察。这一成果扩展了对可逆单站点马尔科夫链的学习能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Better+Models+and+Algorithms+for+Learning+Ising+Models+from+Dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15173，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15173&send_immediately=true&force_search=false)

**原文摘要:** We study the problem of learning the structure and parameters of the Ising
model, a fundamental model of high-dimensional data, when observing the
evolution of an associated Markov chain. A recent line of work has studied the
natural problem of learning when observing an evolution of the well-known
Glauber dynamics [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018,
Gaitonde, Mossel STOC 2024], which provides an arguably more realistic
generative model than the classical i.i.d. setting. However, this prior work
crucially assumes that all site update attempts are observed, \emph{even when
this attempt does not change the configuration}: this strong observation model
is seemingly essential for these approaches. While perhaps possible in
restrictive contexts, this precludes applicability to most realistic settings
where we can observe \emph{only} the stochastic evolution itself, a minimal and
natural assumption for any process we might hope to learn from. However,
designing algorithms that succeed in this more realistic setting has remained
an open problem [Bresler, Gamarnik, Shah, IEEE Trans. Inf. Theory 2018,
Gaitonde, Moitra, Mossel, STOC 2025].
  In this work, we give the first algorithms that efficiently learn the Ising
model in this much more natural observation model that only observes when the
configuration changes. For Ising models with maximum degree $d$, our algorithm
recovers the underlying dependency graph in time $\mathsf{poly}(d)\cdot n^2\log
n$ and then the actual parameters in additional $\widetilde{O}(2^d n)$ time,
which qualitatively matches the state-of-the-art even in the i.i.d. setting in
a much weaker observation model. Our analysis holds more generally for a
broader class of reversible, single-site Markov chains that also includes the
popular Metropolis chain by leveraging more robust properties of reversible
Markov chains.

</details>


### [83] [Joint-Local Grounded Action Transformation for Sim-to-Real Transfer in Multi-Agent Traffic Control](https://arxiv.org/abs/2507.15174)
*Justin Turnau, Longchao Da, Khoa Vo, Ferdous Al Rafi, Shreyas Bachiraju, Tiejin Chen, Hua Wei*

**主要类别:** cs.LG

**AI概要:** 论文提出了一种新的方法JL-GAT，该方法将GAT应用于多智能体强化学习（MARL）以改进交通信号控制（TSC），并在模拟的恶劣天气条件下进行了验证。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于多智能体强化学习（MARL）的交通信号控制（TSC）策略在实际应用中存在性能下降的问题，即所谓的仿真到现实差距(sim-to-real gap)。虽然单智能体RL中的Grounded Action Transformation (GAT) 已经成功缓解了这一差距，但实际的交通网络涉及多个相互作用的交叉路口，更适合于多智能体框架。

**方法:** 引入了JL-GAT，它通过结合邻近智能体的信息，在多智能体强化学习的基础上实施了去中心化的GAT方法，从而实现了可扩展性和增强的接地能力之间的平衡。

**结果:** 广泛的实验和消融研究证明了JL-GAT的有效性，尤其是在模拟的恶劣天气条件下的各种道路网络上。

**结论:** JL-GAT为解决交通信号控制问题提供了一个有效的方案，特别是对于那些需要考虑与邻近智能体交互的大型真实世界交通网络。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Joint-Local+Grounded+Action+Transformation+for+Sim-to-Real+Transfer+in+Multi-Agent+Traffic+Control，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15174，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15174&send_immediately=true&force_search=false)

**原文摘要:** Traffic Signal Control (TSC) is essential for managing urban traffic flow and
reducing congestion. Reinforcement Learning (RL) offers an adaptive method for
TSC by responding to dynamic traffic patterns, with multi-agent RL (MARL)
gaining traction as intersections naturally function as coordinated agents.
However, due to shifts in environmental dynamics, implementing MARL-based TSC
policies in the real world often leads to a significant performance drop, known
as the sim-to-real gap. Grounded Action Transformation (GAT) has successfully
mitigated this gap in single-agent RL for TSC, but real-world traffic networks,
which involve numerous interacting intersections, are better suited to a MARL
framework. In this work, we introduce JL-GAT, an application of GAT to
MARL-based TSC that balances scalability with enhanced grounding capability by
incorporating information from neighboring agents. JL-GAT adopts a
decentralized approach to GAT, allowing for the scalability often required in
real-world traffic networks while still capturing key interactions between
agents. Comprehensive experiments on various road networks under simulated
adverse weather conditions, along with ablation studies, demonstrate the
effectiveness of JL-GAT. The code is publicly available at
https://github.com/DaRL-LibSignal/JL-GAT/.

</details>


### [84] [Feature Construction Using Network Control Theory and Rank Encoding for Graph Machine Learning](https://arxiv.org/abs/2507.15195)
*Anwar Said, Yifan Wei, Ubaid Ullah Ahmad, Mudassir Shabbir, Waseem Abbas, Xenofon Koutsoukos*

**主要类别:** cs.LG

**AI概要:** 本文提出利用图的平均可控性概念和新颖的秩编码方法来增强GNN在社交网络分类任务中的性能。通过引入节点级度量NCT-EFA并开发秩编码方法，研究证明了其能显著提升GNN的表现，特别是在GitHub Stargazers数据集上，ROC AUC从68.7%提高到73.9%。


<details>
  <summary>更多</summary>
  
**动机:** 由于隐私限制或固有属性的缺失，社交网络中的节点特征通常不可用，这使得GNN难以达到最佳性能。为了克服这一局限，需要构建表现力更强的节点特征。

**方法:** 作者提出了两种策略：一是引入平均可控性和其他中心性指标（NCT-EFA）作为捕捉网络拓扑关键方面的节点级度量；二是开发了一种将平均可控性或其他图论度量转换为固定维度特征空间的秩编码方法。

**结果:** 实验结果表明，将平均可控性纳入特征空间可以显著改善GNN性能，提出的秩编码方法比传统的一维热度编码更优，尤其是在GitHub Stargazers数据集上，ROC AUC从68.7%提升到了73.9%。

**结论:** 该研究表明，采用平均可控性概念和秩编码方法可以有效提高GNN在社交网络分类任务上的表现，为解决节点特征缺乏问题提供了一种新的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Feature+Construction+Using+Network+Control+Theory+and+Rank+Encoding+for+Graph+Machine+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15195，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15195&send_immediately=true&force_search=false)

**原文摘要:** In this article, we utilize the concept of average controllability in graphs,
along with a novel rank encoding method, to enhance the performance of Graph
Neural Networks (GNNs) in social network classification tasks. GNNs have proven
highly effective in various network-based learning applications and require
some form of node features to function. However, their performance is heavily
influenced by the expressiveness of these features. In social networks, node
features are often unavailable due to privacy constraints or the absence of
inherent attributes, making it challenging for GNNs to achieve optimal
performance. To address this limitation, we propose two strategies for
constructing expressive node features. First, we introduce average
controllability along with other centrality metrics (denoted as NCT-EFA) as
node-level metrics that capture critical aspects of network topology. Building
on this, we develop a rank encoding method that transforms average
controllability or any other graph-theoretic metric into a fixed-dimensional
feature space, thereby improving feature representation. We conduct extensive
numerical evaluations using six benchmark GNN models across four social network
datasets to compare different node feature construction methods. Our results
demonstrate that incorporating average controllability into the feature space
significantly improves GNN performance. Moreover, the proposed rank encoding
method outperforms traditional one-hot degree encoding, improving the ROC AUC
from 68.7% to 73.9% using GraphSAGE on the GitHub Stargazers dataset,
underscoring its effectiveness in generating expressive and efficient node
representations.

</details>


### [85] [Long-Short Distance Graph Neural Networks and Improved Curriculum Learning for Emotion Recognition in Conversation](https://arxiv.org/abs/2507.15205)
*Xinran Li, Xiujuan Xu, Jiaqi Qiao*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的多模态方法，即长短期距离图神经网络（LSDGNN），用于对话中的情绪识别。通过构建长距离和短距离图神经网络并引入差异正则化器、BiAffine模块和改进的课程学习来提升模型性能，实验结果表明该模型在IEMOCAP和MELD数据集上优于现有基准。


<details>
  <summary>更多</summary>
  
**动机:** 对话中情绪识别（ERC）是一项实用但具有挑战性的任务，现有的方法可能无法充分捕捉远近话语之间的多模态特征以及处理数据不平衡的问题。

**方法:** 该研究基于有向无环图（DAG），构建了长距离图神经网络和短距离图神经网络以分别获取远处和附近的多模态特征，并使用差异正则化器确保两种特征尽可能区分开来，同时利用BiAffine模块促进特征间的互动。此外，还提出了改进的课程学习方法（ICL），通过计算不同情绪间的相似度设计了“加权情绪转换”指标和难度测量工具，优化训练过程。

**结果:** 实验结果表明，在IEMOCAP和MELD数据集上，提出的模型性能超过了现有的基准。

**结论:** 通过结合长短期距离图神经网络、差异正则化器、BiAffine模块和改进的课程学习，本研究提供了一种有效的方法来提高对话中情绪识别的准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Long-Short+Distance+Graph+Neural+Networks+and+Improved+Curriculum+Learning+for+Emotion+Recognition+in+Conversation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15205，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15205&send_immediately=true&force_search=false)

**原文摘要:** Emotion Recognition in Conversation (ERC) is a practical and challenging
task. This paper proposes a novel multimodal approach, the Long-Short Distance
Graph Neural Network (LSDGNN). Based on the Directed Acyclic Graph (DAG), it
constructs a long-distance graph neural network and a short-distance graph
neural network to obtain multimodal features of distant and nearby utterances,
respectively. To ensure that long- and short-distance features are as distinct
as possible in representation while enabling mutual influence between the two
modules, we employ a Differential Regularizer and incorporate a BiAffine Module
to facilitate feature interaction. In addition, we propose an Improved
Curriculum Learning (ICL) to address the challenge of data imbalance. By
computing the similarity between different emotions to emphasize the shifts in
similar emotions, we design a "weighted emotional shift" metric and develop a
difficulty measurer, enabling a training process that prioritizes learning easy
samples before harder ones. Experimental results on the IEMOCAP and MELD
datasets demonstrate that our model outperforms existing benchmarks.

</details>


### [86] [Exact Reformulation and Optimization for Direct Metric Optimization in Binary Imbalanced Classification](https://arxiv.org/abs/2507.15240)
*Le Peng, Yash Travadi, Chuan He, Ying Cui, Ju Sun*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的方法，首次引入了直接度量优化问题的确切约束重构，并通过精确惩罚方法有效地解决了IC问题。实验结果表明该方法在三个DMO问题上优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的不平衡分类（IC）方法大多依赖于优化平衡准确率，但在类的重要性变化或某些指标需要达到规定水平的情况下表现不佳。此外，现有方法通常使用平滑近似来处理涉及的指示函数。

**方法:** 研究了二元IC设置下的精度和召回率两个关键分类指标，提出了针对FPOR、FROP和OFBS三种实际IC场景的确切约束重构的直接度量优化问题，并利用精确惩罚方法求解。

**结果:** 实验结果表明，该方法在多个基准数据集上的三种DMO问题上均优于最先进方法。

**结论:** 所提出的确切重构和优化框架不仅适用于多种二元IC的DMO问题，还可能扩展到其他领域。代码已开源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exact+Reformulation+and+Optimization+for+Direct+Metric+Optimization+in+Binary+Imbalanced+Classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15240，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15240&send_immediately=true&force_search=false)

**原文摘要:** For classification with imbalanced class frequencies, i.e., imbalanced
classification (IC), standard accuracy is known to be misleading as a
performance measure. While most existing methods for IC resort to optimizing
balanced accuracy (i.e., the average of class-wise recalls), they fall short in
scenarios where the significance of classes varies or certain metrics should
reach prescribed levels. In this paper, we study two key classification
metrics, precision and recall, under three practical binary IC settings: fix
precision optimize recall (FPOR), fix recall optimize precision (FROP), and
optimize $F_\beta$-score (OFBS). Unlike existing methods that rely on smooth
approximations to deal with the indicator function involved, \textit{we
introduce, for the first time, exact constrained reformulations for these
direct metric optimization (DMO) problems}, which can be effectively solved by
exact penalty methods. Experiment results on multiple benchmark datasets
demonstrate the practical superiority of our approach over the state-of-the-art
methods for the three DMO problems. We also expect our exact reformulation and
optimization (ERO) framework to be applicable to a wide range of DMO problems
for binary IC and beyond. Our code is available at
https://github.com/sun-umn/DMO.

</details>


### [87] [Spatio-Temporal Demand Prediction for Food Delivery Using Attention-Driven Graph Neural Networks](https://arxiv.org/abs/2507.15246)
*Rabia Latief Bhat, Iqra Altaf Gillani*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于注意力机制的图神经网络框架，用于捕捉食品配送环境中时空依赖关系，以提高需求预测的准确性。


<details>
  <summary>更多</summary>
  
**动机:** 准确的需求预测对于提高食品配送平台的效率和响应能力至关重要，而订单量的空间异质性和时间波动直接影响运营决策。

**方法:** 该方法将食品配送环境建模为一个图，其中节点表示城市配送区域，边反映空间接近度和从历史数据中得出的区域间订单流动模式。注意力机制动态地权衡邻近区域的影响，使模型能够专注于最相关的区域进行预测。

**结果:** 在真实世界食品配送数据集上的广泛实验表明，该模型在高精度预测未来订单量方面具有优越性。

**结论:** 该框架提供了一个可扩展且适应性强的解决方案，支持城市食品配送操作中的主动车队定位、资源分配和调度优化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Spatio-Temporal+Demand+Prediction+for+Food+Delivery+Using+Attention-Driven+Graph+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15246，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15246&send_immediately=true&force_search=false)

**原文摘要:** Accurate demand forecasting is critical for enhancing the efficiency and
responsiveness of food delivery platforms, where spatial heterogeneity and
temporal fluctuations in order volumes directly influence operational
decisions. This paper proposes an attention-based Graph Neural Network
framework that captures spatial-temporal dependencies by modeling the food
delivery environment as a graph. In this graph, nodes represent urban delivery
zones, while edges reflect spatial proximity and inter-regional order flow
patterns derived from historical data. The attention mechanism dynamically
weighs the influence of neighboring zones, enabling the model to focus on the
most contextually relevant areas during prediction. Temporal trends are jointly
learned alongside spatial interactions, allowing the model to adapt to evolving
demand patterns. Extensive experiments on real-world food delivery datasets
demonstrate the superiority of the proposed model in forecasting future order
volumes with high accuracy. The framework offers a scalable and adaptive
solution to support proactive fleet positioning, resource allocation, and
dispatch optimization in urban food delivery operations.

</details>


### [88] [CHORDS: Diffusion Sampling Accelerator with Multi-core Hierarchical ODE Solvers](https://arxiv.org/abs/2507.15260)
*Jiaqi Han, Haotian Ye, Puheng Li, Minkai Xu, James Zou, Stefano Ermon*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于多核并行的扩散模型加速策略CHORDS，无需重新训练模型，可显著提升图像和视频生成的速度而不降低质量。


<details>
  <summary>更多</summary>
  
**动机:** 现有的加速技术要么需要大量的模型重新训练，要么在样本质量上有很大的妥协。因此，探索一种通用的、无需训练的、与模型无关的加速策略是非常必要的。

**方法:** 该框架将多核扩散采样视为一个ODE求解器管道，其中较慢但准确的求解器通过理论证明的核间通信机制逐步修正较快的求解器。

**结果:** 通过广泛的实验，CHORDS显著加速了各种大规模图像和视频扩散模型的采样过程，使用四个核心时速度提高了2.1倍，比基线提高了50%，使用八个核心时速度提高了2.9倍，且没有质量下降。

**结论:** CHORDS为实时、高保真扩散生成奠定了坚实的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CHORDS%3A+Diffusion+Sampling+Accelerator+with+Multi-core+Hierarchical+ODE+Solvers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15260，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15260&send_immediately=true&force_search=false)

**原文摘要:** Diffusion-based generative models have become dominant generators of
high-fidelity images and videos but remain limited by their computationally
expensive inference procedures. Existing acceleration techniques either require
extensive model retraining or compromise significantly on sample quality. This
paper explores a general, training-free, and model-agnostic acceleration
strategy via multi-core parallelism. Our framework views multi-core diffusion
sampling as an ODE solver pipeline, where slower yet accurate solvers
progressively rectify faster solvers through a theoretically justified
inter-core communication mechanism. This motivates our multi-core training-free
diffusion sampling accelerator, CHORDS, which is compatible with various
diffusion samplers, model architectures, and modalities. Through extensive
experiments, CHORDS significantly accelerates sampling across diverse
large-scale image and video diffusion models, yielding up to 2.1x speedup with
four cores, improving by 50% over baselines, and 2.9x speedup with eight cores,
all without quality degradation. This advancement enables CHORDS to establish a
solid foundation for real-time, high-fidelity diffusion generation.

</details>


### [89] [Temporal Basis Function Models for Closed-Loop Neural Stimulation](https://arxiv.org/abs/2507.15274)
*Matthew J. Bryan, Felix Schwock, Azadeh Yazdan-Shahmorad, Rajesh P N Rao*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于时间基函数模型（TBFMs）的方法，用于帕金森病的闭环神经刺激治疗。该方法能够高效地预测光遗传刺激对局部场电位的影响，并且在模拟中成功实现了闭环刺激，使得神经活动趋向目标模式。相比其他模型，TBFMs具有样本效率高、训练快速、低延迟等优点。


<details>
  <summary>更多</summary>
  
**动机:** 闭环神经刺激为帕金森病等神经疾病提供了新的治疗方法，但目前尚不清楚人工智能技术能否为个体患者定制闭环刺激或发现新疗法。为了实现这一目标，需要解决样本效率、训练时间以及最小化循环延迟等问题。

**方法:** 本文采用时间基函数模型（TBFMs），并结合兴奋性光遗传刺激进行研究。通过使用TBFMs，可以在单次试验中对光遗传刺激对局部场电位的影响进行时空前向预测。此外，还进行了模拟实验以验证TBFMs在闭环刺激中的应用。

**结果:** TBFMs在预测光遗传刺激对局部场电位的影响方面表现出色，其预测准确性与非线性动力系统模型相当，优于线性状态空间模型。同时，在模拟中，TBFMs成功实现了闭环刺激控制神经电路的功能。

**结论:** TBFMs在闭环神经刺激治疗中展现出了巨大的潜力，它不仅能够高效预测神经反应，而且在闭环控制方面也表现出色。这为开发新型、临床有用的闭环刺激协议提供了一种可能的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Temporal+Basis+Function+Models+for+Closed-Loop+Neural+Stimulation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15274，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15274&send_immediately=true&force_search=false)

**原文摘要:** Closed-loop neural stimulation provides novel therapies for neurological
diseases such as Parkinson's disease (PD), but it is not yet clear whether
artificial intelligence (AI) techniques can tailor closed-loop stimulation to
individual patients or identify new therapies. Progress requires us to address
a number of translational issues, including sample efficiency, training time,
and minimizing loop latency such that stimulation may be shaped in response to
changing brain activity. We propose temporal basis function models (TBFMs) to
address these difficulties, and explore this approach in the context of
excitatory optogenetic stimulation. We demonstrate the ability of TBF models to
provide a single-trial, spatiotemporal forward prediction of the effect of
optogenetic stimulation on local field potentials (LFPs) measured in two
non-human primates. We further use simulations to demonstrate the use of TBF
models for closed-loop stimulation, driving neural activity towards target
patterns. The simplicity of TBF models allow them to be sample efficient, rapid
to train (2-4min), and low latency (0.2ms) on desktop CPUs. We demonstrate the
model on 40 sessions of previously published excitatory optogenetic stimulation
data. For each session, the model required 15-20min of data collection to
successfully model the remainder of the session. It achieved a prediction
accuracy comparable to a baseline nonlinear dynamical systems model that
requires hours to train, and superior accuracy to a linear state-space model.
In our simulations, it also successfully allowed a closed-loop stimulator to
control a neural circuit. Our approach begins to bridge the translational gap
between complex AI-based approaches to modeling dynamical systems and the
vision of using such forward prediction models to develop novel, clinically
useful closed-loop stimulation protocols.

</details>


### [90] [Machine Unlearning for Streaming Forgetting](https://arxiv.org/abs/2507.15280)
*Shaofei Shen, Chenhao Zhang, Yawen Zhao, Alina Bialkowski, Weitong Chen, Miao Xu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的流式遗忘学习范式，通过将遗忘视为分布偏移问题，并提出算法实现高效的流式遗忘。


<details>
  <summary>更多</summary>
  
**动机:** 现有的机器遗忘方法通常一次性处理所有需要被遗忘的数据，但在实际应用中，数据删除请求往往是流式的，这导致了现有方法在效率和效果上的不足。

**方法:** 作者引入了流式遗忘学习范式，将遗忘问题形式化为分布偏移问题，并提出了一个不需要访问原始训练数据的新型流式遗忘算法。

**结果:** 理论分析表明该算法在T轮学习中的流式遗忘后悔值有一个O(√T + VT)的误差界，并且实验结果验证了所提方法的有效性。

**结论:** 该研究提供了一种有效处理流式数据删除请求的方法，并为机器遗忘领域提供了新的视角。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Machine+Unlearning+for+Streaming+Forgetting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15280，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15280&send_immediately=true&force_search=false)

**原文摘要:** Machine unlearning aims to remove knowledge of the specific training data in
a well-trained model. Currently, machine unlearning methods typically handle
all forgetting data in a single batch, removing the corresponding knowledge all
at once upon request. However, in practical scenarios, requests for data
removal often arise in a streaming manner rather than in a single batch,
leading to reduced efficiency and effectiveness in existing methods. Such
challenges of streaming forgetting have not been the focus of much research. In
this paper, to address the challenges of performance maintenance, efficiency,
and data access brought about by streaming unlearning requests, we introduce a
streaming unlearning paradigm, formalizing the unlearning as a distribution
shift problem. We then estimate the altered distribution and propose a novel
streaming unlearning algorithm to achieve efficient streaming forgetting
without requiring access to the original training data. Theoretical analyses
confirm an $O(\sqrt{T} + V_T)$ error bound on the streaming unlearning regret,
where $V_T$ represents the cumulative total variation in the optimal solution
over $T$ learning rounds. This theoretical guarantee is achieved under mild
conditions without the strong restriction of convex loss function. Experiments
across various models and datasets validate the performance of our proposed
method.

</details>


### [91] [Mixture of Autoencoder Experts Guidance using Unlabeled and Incomplete Data for Exploration in Reinforcement Learning](https://arxiv.org/abs/2507.15287)
*Elias Malomgré, Pieter Simoens*

**主要类别:** cs.LG

**AI概要:** 提出了一种利用未标记或不完整演示数据的框架，通过将状态相似性转换为内在奖励来引导智能体学习，实验表明该方法在不同奖励密度环境下均能实现稳健探索和高性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前强化学习的趋势强调了无需依赖显式奖励最大化，而从无奖励交互和替代监督信号中学习的重要性，尤其是在真实世界环境中发展通用智能体时。然而，现有的内在动机技术面对复杂环境或高维空间时面临挑战，且难以有效塑造或控制探索过程。

**方法:** 我们提出的方法应用映射函数将智能体状态与专家数据之间的相似性转换为成形的内在奖励，以允许灵活和有针对性地探索类似专家的行为。使用自动编码器专家混合模型捕捉多样行为并处理演示中的缺失信息。

**结果:** 实验显示，所提出的方法能够在稀疏和密集奖励环境中实现稳健探索，并表现出强大的性能，即使在演示数据稀疏或不完整的情况下也是如此。

**结论:** 这提供了一个实用的强化学习框架，适用于现实场景中缺乏最优数据并且需要精确奖励控制的情况。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mixture+of+Autoencoder+Experts+Guidance+using+Unlabeled+and+Incomplete+Data+for+Exploration+in+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15287，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15287&send_immediately=true&force_search=false)

**原文摘要:** Recent trends in Reinforcement Learning (RL) highlight the need for agents to
learn from reward-free interactions and alternative supervision signals, such
as unlabeled or incomplete demonstrations, rather than relying solely on
explicit reward maximization. Additionally, developing generalist agents that
can adapt efficiently in real-world environments often requires leveraging
these reward-free signals to guide learning and behavior. However, while
intrinsic motivation techniques provide a means for agents to seek out novel or
uncertain states in the absence of explicit rewards, they are often challenged
by dense reward environments or the complexity of high-dimensional state and
action spaces. Furthermore, most existing approaches rely directly on the
unprocessed intrinsic reward signals, which can make it difficult to shape or
control the agent's exploration effectively. We propose a framework that can
effectively utilize expert demonstrations, even when they are incomplete and
imperfect. By applying a mapping function to transform the similarity between
an agent's state and expert data into a shaped intrinsic reward, our method
allows for flexible and targeted exploration of expert-like behaviors. We
employ a Mixture of Autoencoder Experts to capture a diverse range of behaviors
and accommodate missing information in demonstrations. Experiments show our
approach enables robust exploration and strong performance in both sparse and
dense reward environments, even when demonstrations are sparse or incomplete.
This provides a practical framework for RL in realistic settings where optimal
data is unavailable and precise reward control is needed.

</details>


### [92] [Preferential subspace identification (PSID) with forward-backward smoothing](https://arxiv.org/abs/2507.15288)
*Omid G. Sani, Maryam M. Shanechi*

**主要类别:** cs.LG

**AI概要:** 本文扩展了PSID方法，以实现最优滤波和平滑处理。通过引入降秩回归步骤学习最优增益，并开发了一种新颖的前向-后向PSID平滑算法。该方法在模拟数据上验证有效，能够恢复模型参数并达到理想的解码性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的PSID方法仅使用过去的主要数据进行预测，即使在离线应用中，通过包含同时期数据（滤波）或所有可用数据（平滑），可以实现更好的估计。

**方法:** 首先展示了次要信号的存在使得可以从一系列等效状态空间模型中唯一识别出具有最优卡尔曼更新步骤的模型。然后，通过引入降秩回归步骤直接从数据中学习更新步骤所需的最优增益。最后，受到双滤波卡尔曼平滑器公式启发，开发了一种新的前向-后向PSID平滑算法。

**结果:** 该方法在模拟数据上的实验表明，它能够恢复真实模型参数，实现了与实际底层模型的理想性能相匹配的最优滤波和平滑解码性能。

**结论:** 这项工作为两个信号设置中的最优线性滤波和平滑提供了一个原则性的框架，显著扩展了分析多变量时间序列动态交互的工具包。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Preferential+subspace+identification+%28PSID%29+with+forward-backward+smoothing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15288，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15288&send_immediately=true&force_search=false)

**原文摘要:** System identification methods for multivariate time-series, such as neural
and behavioral recordings, have been used to build models for predicting one
from the other. For example, Preferential Subspace Identification (PSID) builds
a state-space model of a primary time-series (e.g., neural activity) to
optimally predict a secondary time-series (e.g., behavior). However, PSID
focuses on optimal prediction using past primary data, even though in offline
applications, better estimation can be achieved by incorporating concurrent
data (filtering) or all available data (smoothing). Here, we extend PSID to
enable optimal filtering and smoothing. First, we show that the presence of a
secondary signal makes it possible to uniquely identify a model with an optimal
Kalman update step (to enable filtering) from a family of otherwise equivalent
state-space models. Our filtering solution augments PSID with a reduced-rank
regression step that directly learns the optimal gain required for the update
step from data. We refer to this extension of PSID as PSID with filtering.
Second, inspired by two-filter Kalman smoother formulations, we develop a novel
forward-backward PSID smoothing algorithm where we first apply PSID with
filtering and then apply it again in the reverse time direction on the
residuals of the filtered secondary signal. We validate our methods on
simulated data, showing that our approach recovers the ground-truth model
parameters for filtering, and achieves optimal filtering and smoothing decoding
performance of the secondary signal that matches the ideal performance of the
true underlying model. This work provides a principled framework for optimal
linear filtering and smoothing in the two-signal setting, significantly
expanding the toolkit for analyzing dynamic interactions in multivariate
time-series.

</details>


### [93] [Feel-Good Thompson Sampling for Contextual Bandits: a Markov Chain Monte Carlo Showdown](https://arxiv.org/abs/2507.15290)
*Emile Anand, Sarah Liaw*

**主要类别:** cs.LG

**AI概要:** 本研究对Feel-Good Thompson Sampling (FG-TS)及其平滑变体(SFG-TS)进行了首次系统评估，涉及真实和合成基准测试。结果表明，在线性和逻辑bandits中，FG-TS通常优于传统的TS，但在神经网络环境中表现较弱。然而，由于其竞争力和易用性，仍推荐作为现代情境bandit基准的基线方法。


<details>
  <summary>更多</summary>
  
**动机:** Thompson Sampling (TS)在高维问题中的探索不足是已知的问题。为了改进这一点，提出了Feel-Good Thompson Sampling (FG-TS)，它通过增加乐观奖励来更倾向于高回报模型，并且在后验分布准确的情况下达到了渐近最优的遗憾。但是，对于大规模或基于神经网络的问题中常见的近似后验分布，FG-TS的表现尚未得到充分评估。

**方法:** 研究人员对FG-TS及其平滑变体(SFG-TS)进行了11个真实世界和合成基准测试的系统评估。他们比较了不同设定下（包括精确和近似的后验分布）的性能，并通过调整预处理、奖励规模和先验强度等因素分析了这些因素如何影响FG-TS的表现。

**结果:** FG-TS在具有精确后验样本的线性和逻辑bandits中通常表现出色，但在神经网络环境下的表现不如传统TS。此外，较大的奖励有助于当后验样本准确时，但当采样噪声占主导地位时会适得其反。

**结论:** 尽管FG-TS及其变体在某些情况下可能不如其他方法，但由于它们的竞争性和易于使用，仍然建议将它们作为现代情境bandit基准测试的基线方法。并且提供了所有实验的源代码。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Feel-Good+Thompson+Sampling+for+Contextual+Bandits%3A+a+Markov+Chain+Monte+Carlo+Showdown，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15290，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15290&send_immediately=true&force_search=false)

**原文摘要:** Thompson Sampling (TS) is widely used to address the exploration/exploitation
tradeoff in contextual bandits, yet recent theory shows that it does not
explore aggressively enough in high-dimensional problems. Feel-Good Thompson
Sampling (FG-TS) addresses this by adding an optimism bonus that biases toward
high-reward models, and it achieves the asymptotically minimax-optimal regret
in the linear setting when posteriors are exact. However, its performance with
\emph{approximate} posteriors -- common in large-scale or neural problems --
has not been benchmarked. We provide the first systematic study of FG-TS and
its smoothed variant (SFG-TS) across eleven real-world and synthetic
benchmarks. To evaluate their robustness, we compare performance across
settings with exact posteriors (linear and logistic bandits) to approximate
regimes produced by fast but coarse stochastic-gradient samplers. Ablations
over preconditioning, bonus scale, and prior strength reveal a trade-off:
larger bonuses help when posterior samples are accurate, but hurt when sampling
noise dominates. FG-TS generally outperforms vanilla TS in linear and logistic
bandits, but tends to be weaker in neural bandits. Nevertheless, because FG-TS
and its variants are competitive and easy-to-use, we recommend them as
baselines in modern contextual-bandit benchmarks. Finally, we provide source
code for all our experiments in
https://github.com/SarahLiaw/ctx-bandits-mcmc-showdown.

</details>


### [94] [Universal crystal material property prediction via multi-view geometric fusion in graph transformers](https://arxiv.org/abs/2507.15303)
*Liang Zhang, Kong Chen, Yuen Wu*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的多视图图变换器框架MGT，用于晶体结构的多任务自我监督预训练，以提高晶体性质预测的准确性。


<details>
  <summary>更多</summary>
  
**动机:** 目前大多数方法在晶体性质预测中难以有效地捕捉和利用晶体结构复杂的几何和拓扑特征。

**方法:** 提出了一个名为MGT的多视图图变换器框架，该框架结合了SE3不变和SO3等变图表示，以捕捉晶体几何中的旋转-平移不变性和旋转等变性。通过轻量级专家混合路由器来自适应地调整SE3和SO3嵌入的权重。

**结果:** 与以前最先进的模型相比，MGT在晶体性质预测任务上将平均绝对误差降低了21%，并在迁移学习场景中实现了高达58%的性能提升。

**结论:** MGT可以作为有用的模型用于晶体材料性质预测，为新材料的发现提供有价值的工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Universal+crystal+material+property+prediction+via+multi-view+geometric+fusion+in+graph+transformers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15303，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15303&send_immediately=true&force_search=false)

**原文摘要:** Accurately and comprehensively representing crystal structures is critical
for advancing machine learning in large-scale crystal materials simulations,
however, effectively capturing and leveraging the intricate geometric and
topological characteristics of crystal structures remains a core, long-standing
challenge for most existing methods in crystal property prediction. Here, we
propose MGT, a multi-view graph transformer framework that synergistically
fuses SE3 invariant and SO3 equivariant graph representations, which
respectively captures rotation-translation invariance and rotation equivariance
in crystal geometries. To strategically incorporate these complementary
geometric representations, we employ a lightweight mixture of experts router in
MGT to adaptively adjust the weight assigned to SE3 and SO3 embeddings based on
the specific target task. Compared with previous state-of-the-art models, MGT
reduces the mean absolute error by up to 21% on crystal property prediction
tasks through multi-task self-supervised pretraining. Ablation experiments and
interpretable investigations confirm the effectiveness of each technique
implemented in our framework. Additionally, in transfer learning scenarios
including crystal catalyst adsorption energy and hybrid perovskite bandgap
prediction, MGT achieves performance improvements of up to 58% over existing
baselines, demonstrating domain-agnostic scalability across diverse application
domains. As evidenced by the above series of studies, we believe that MGT can
serve as useful model for crystal material property prediction, providing a
valuable tool for the discovery of novel materials.

</details>


### [95] [Beyond Model Base Selection: Weaving Knowledge to Master Fine-grained Neural Network Design](https://arxiv.org/abs/2507.15336)
*Jialiang Wang, Hanmo Liu, Shimin Di, Zhili Wang, Jiachuan Wang, Lei Chen, Xiaofang Zhou*

**主要类别:** cs.LG

**AI概要:** 本文提出M-DESIGN，一个用于通过自适应编织先前关于模型架构修改的见解来掌握神经网络细化的精心策划的模型知识库（MKB）管道。


<details>
  <summary>更多</summary>
  
**动机:** 现有的数据库研究在模型细化方面存在不足，静态模型选择实践忽略了任务查询和模型架构变化之间细粒度、不断演变的关系依赖性，导致次优匹配，无法有效进一步细化模型。

**方法:** 首先，提出了一个知识编织引擎，将模型细化重构为任务元数据上的自适应查询问题。给定用户的任务查询，M-DESIGN通过利用图形关系知识模式快速匹配并迭代细化候选模型，该模式明确编码了数据属性、架构变化和成对性能差异作为可连接的关系。

**结果:** 实证结果表明，在有限的预算内，M-DESIGN在33个数据任务对中的26个中提供了最优模型。

**结论:** M-DESIGN通过其独特的知识编织引擎和预测查询计划器，能够检测和适应离群任务，提供了一个新颖的方法来改进神经网络模型的选择和优化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Beyond+Model+Base+Selection%3A+Weaving+Knowledge+to+Master+Fine-grained+Neural+Network+Design，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15336，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15336&send_immediately=true&force_search=false)

**原文摘要:** Database systems have recently advocated for embedding machine learning (ML)
capabilities, offering declarative model queries over large, managed model
repositories, thereby circumventing the huge computational overhead of
traditional ML-based algorithms in automated neural network model selection.
Pioneering database studies aim to organize existing benchmark repositories as
model bases (MB), querying them for the model records with the highest
performance estimation metrics for given tasks. However, this static model
selection practice overlooks the fine-grained, evolving relational dependencies
between diverse task queries and model architecture variations, resulting in
suboptimal matches and failing to further refine the model effectively. To fill
the model refinement gap in database research, we propose M-DESIGN, a curated
model knowledge base (MKB) pipeline for mastering neural network refinement by
adaptively weaving prior insights about model architecture modification. First,
we propose a knowledge weaving engine that reframes model refinement as an
adaptive query problem over task metadata. Given a user's task query, M-DESIGN
quickly matches and iteratively refines candidate models by leveraging a
graph-relational knowledge schema that explicitly encodes data properties,
architecture variations, and pairwise performance deltas as joinable relations.
This schema supports fine-grained relational analytics over architecture tweaks
and drives a predictive query planner that can detect and adapt to
out-of-distribution (OOD) tasks. We instantiate M-DESIGN for graph analytics
tasks, where our model knowledge base enriches existing benchmarks with
structured metadata covering 3 graph tasks and 22 graph datasets, contributing
data records of 67,760 graph models. Empirical results demonstrate that
M-DESIGN delivers the optimal model in 26 of 33 data-task pairs within limited
budgets.

</details>


### [96] [Scaling Decentralized Learning with FLock](https://arxiv.org/abs/2507.15349)
*Zehua Cheng, Rui Sun, Jiahao Sun, Yike Guo*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种名为FLock的去中心化框架，用于安全高效的协作微调大型语言模型（LLM），并首次在安全、多域、去中心化的环境中对70B参数的LLM进行了微调验证。实验表明，FLock框架能有效防御后门中毒攻击，并促进协同知识转移，使模型具有更好的跨域泛化能力。


<details>
  <summary>更多</summary>
  
**动机:** 微调大型语言模型受到集中控制不足和分散方案中巨大的计算和通信开销的阻碍。而典型的联邦学习虽然支持数据隐私，但中央服务器的要求造成了单点攻击和中毒攻击的漏洞。

**方法:** 引入了FLock，一种将基于区块链的信任层与经济激励相结合的去中心化框架，以取代中央聚合器，创建一个安全、可审计的合作协议。

**结果:** 实验显示，FLock框架能够防御破坏标准联邦学习优化器的后门中毒攻击，并促进协同知识转移。结果模型显示出>68%的对抗性攻击成功率降低。全局模型还展示了卓越的跨域泛化能力。

**结论:** FLock为在异构、不可信环境中对大型语言模型进行微调提供了一个新的解决方案，它不仅提高了模型的安全性，还增强了模型的泛化性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scaling+Decentralized+Learning+with+FLock，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15349，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15349&send_immediately=true&force_search=false)

**原文摘要:** Fine-tuning the large language models (LLMs) are prevented by the deficiency
of centralized control and the massive computing and communication overhead on
the decentralized schemes. While the typical standard federated learning (FL)
supports data privacy, the central server requirement creates a single point of
attack and vulnerability to poisoning attacks. Generalizing the result in this
direction to 70B-parameter models in the heterogeneous, trustless environments
has turned out to be a huge, yet unbroken bottleneck. This paper introduces
FLock, a decentralized framework for secure and efficient collaborative LLM
fine-tuning. Integrating a blockchain-based trust layer with economic
incentives, FLock replaces the central aggregator with a secure, auditable
protocol for cooperation among untrusted parties. We present the first
empirical validation of fine-tuning a 70B LLM in a secure, multi-domain,
decentralized setting. Our experiments show the FLock framework defends against
backdoor poisoning attacks that compromise standard FL optimizers and fosters
synergistic knowledge transfer. The resulting models show a >68% reduction in
adversarial attack success rates. The global model also demonstrates superior
cross-domain generalization, outperforming models trained in isolation on their
own specialized data.

</details>


### [97] [To Label or Not to Label: PALM -- A Predictive Model for Evaluating Sample Efficiency in Active Learning Models](https://arxiv.org/abs/2507.15381)
*Julia Machnio, Mads Nielsen, Mostafa Mehdipour Ghazi*

**主要类别:** cs.LG

**AI概要:** 提出PALM模型，通过四个关键参数描述主动学习（AL）的轨迹，为AL方法提供更系统、可重复和数据高效的评估。


<details>
  <summary>更多</summary>
  
**动机:** 传统评估方法只关注最终准确性，无法全面捕捉主动学习过程的动力学特性，特别是在资源受限的情况下。

**方法:** 提出了PALM模型，使用四个关键参数：可实现的准确性、覆盖效率、早期性能和可扩展性来描述AL轨迹，并从部分观察中预测AL行为。

**结果:** 通过广泛的实验验证了PALM在多个数据集上的有效性，能够准确预测完整的学习曲线，并揭示了学习效率、数据空间覆盖和可扩展性的关键见解。

**结论:** PALM为在研究和实际应用中更系统、可重复和数据高效的评估AL奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是To+Label+or+Not+to+Label%3A+PALM+--+A+Predictive+Model+for+Evaluating+Sample+Efficiency+in+Active+Learning+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15381，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15381&send_immediately=true&force_search=false)

**原文摘要:** Active learning (AL) seeks to reduce annotation costs by selecting the most
informative samples for labeling, making it particularly valuable in
resource-constrained settings. However, traditional evaluation methods, which
focus solely on final accuracy, fail to capture the full dynamics of the
learning process. To address this gap, we propose PALM (Performance Analysis of
Active Learning Models), a unified and interpretable mathematical model that
characterizes AL trajectories through four key parameters: achievable accuracy,
coverage efficiency, early-stage performance, and scalability. PALM provides a
predictive description of AL behavior from partial observations, enabling the
estimation of future performance and facilitating principled comparisons across
different strategies. We validate PALM through extensive experiments on
CIFAR-10/100 and ImageNet-50/100/200, covering a wide range of AL methods and
self-supervised embeddings. Our results demonstrate that PALM generalizes
effectively across datasets, budgets, and strategies, accurately predicting
full learning curves from limited labeled data. Importantly, PALM reveals
crucial insights into learning efficiency, data space coverage, and the
scalability of AL methods. By enabling the selection of cost-effective
strategies and predicting performance under tight budget constraints, PALM lays
the basis for more systematic, reproducible, and data-efficient evaluation of
AL in both research and real-world applications. The code is available at:
https://github.com/juliamachnio/PALM.

</details>


### [98] [Learning to Gridize: Segment Physical World by Wireless Communication Channel](https://arxiv.org/abs/2507.15386)
*Juntao Wang, Feng Yin, Tian Ding, Tsung-Hui Chang, Zhi-Quan Luo, Qi Yan*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的信道空间网格化（CSG）框架，它首次将信道估计和网格化统一起来，并开发了CSG自动编码器（CSG-AE）来实现这一框架。为了确保训练的稳定性和有效性，还提出了一个新的PIDA训练方案。实验表明，CSG-AE在合成数据和真实世界数据集上的性能都优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的网格化方法依赖于不可用的位置数据或错误地假设相似的信号强度意味着相似的信道特性，这限制了其应用范围和效果。因此，需要一种新的方法来解决这些问题。

**方法:** 本文提出了一种新的信道空间网格化（CSG）框架，它首次将信道估计和网格化统一起来。通过仅使用波束级参考信号接收功率（RSRP），CSG可以估计信道角度功率谱（CAPS），并根据同质信道特性对样本进行分区。此外，还开发了CSG自动编码器（CSG-AE）来实现这一框架，并提出了一个新颖的PIDA训练方案以确保训练的稳定性和有效性。

**结果:** 实验结果表明，CSG-AE在合成数据上的信道角度功率谱（CAPS）估计准确性和聚类质量方面表现出色。在真实世界的数据集上，与现有方法相比，CSG-AE将活跃平均绝对误差（MAE）降低了30%，整体MAE降低了65%。同时，CSG-AE还改善了信道一致性、聚类大小平衡和活跃比率。

**结论:** CSG-AE在信道空间网格化方面具有显著的优势，能够提高大规模网络优化的效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+to+Gridize%3A+Segment+Physical+World+by+Wireless+Communication+Channel，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15386，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15386&send_immediately=true&force_search=false)

**原文摘要:** Gridization, the process of partitioning space into grids where users share
similar channel characteristics, serves as a fundamental prerequisite for
efficient large-scale network optimization. However, existing methods like
Geographical or Beam Space Gridization (GSG or BSG) are limited by reliance on
unavailable location data or the flawed assumption that similar signal
strengths imply similar channel properties. We propose Channel Space
Gridization (CSG), a pioneering framework that unifies channel estimation and
gridization for the first time. Formulated as a joint optimization problem, CSG
uses only beam-level reference signal received power (RSRP) to estimate Channel
Angle Power Spectra (CAPS) and partition samples into grids with homogeneous
channel characteristics. To perform CSG, we develop the CSG Autoencoder
(CSG-AE), featuring a trainable RSRP-to-CAPS encoder, a learnable sparse
codebook quantizer, and a physics-informed decoder based on the Localized
Statistical Channel Model. On recognizing the limitations of naive training
scheme, we propose a novel Pretraining-Initialization-Detached-Asynchronous
(PIDA) training scheme for CSG-AE, ensuring stable and effective training by
systematically addressing the common pitfalls of the naive training paradigm.
Evaluations reveal that CSG-AE excels in CAPS estimation accuracy and
clustering quality on synthetic data. On real-world datasets, it reduces Active
Mean Absolute Error (MAE) by 30\% and Overall MAE by 65\% on RSRP prediction
accuracy compared to salient baselines using the same data, while improving
channel consistency, cluster sizes balance, and active ratio, advancing the
development of gridization for large-scale network optimization.

</details>


### [99] [MAP Estimation with Denoisers: Convergence Rates and Guarantees](https://arxiv.org/abs/2507.15397)
*Scott Pesme, Giacomo Meanti, Michael Arbel, Julien Mairal*

**主要类别:** cs.LG

**AI概要:** 本文为一类经验上成功的但之前是启发式的去噪模型方法提供了理论基础，展示了一个简单算法在某些条件下可以收敛到近端算子，并且该算法可以被解释为对平滑近端目标的梯度下降。


<details>
  <summary>更多</summary>
  
**动机:** 去噪模型在求解最大后验概率（MAP）优化问题中扮演重要角色，但实践中直接使用预训练的去噪器作为近端算子替代品缺乏普遍的理论依据。因此，需要为这些启发式方法提供理论支持。

**方法:** 作者提出并分析了一个简单的算法，该算法在先验分布$p$满足对数凹性假设的情况下，可以证明收敛到近端算子。并且展示了该算法可被视为对平滑近端目标进行梯度下降的过程。

**结果:** 通过分析，作者为一系列经验上成功的启发式方法提供了理论基础，证明了特定算法能够收敛至近端算子。

**结论:** 这项工作为一些实际应用中的启发式去噪模型方法提供了理论上的合理性，特别是在满足一定条件时，这些方法能够有效地逼近近端算子。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MAP+Estimation+with+Denoisers%3A+Convergence+Rates+and+Guarantees，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15397，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15397&send_immediately=true&force_search=false)

**原文摘要:** Denoiser models have become powerful tools for inverse problems, enabling the
use of pretrained networks to approximate the score of a smoothed prior
distribution. These models are often used in heuristic iterative schemes aimed
at solving Maximum a Posteriori (MAP) optimisation problems, where the proximal
operator of the negative log-prior plays a central role. In practice, this
operator is intractable, and practitioners plug in a pretrained denoiser as a
surrogate-despite the lack of general theoretical justification for this
substitution. In this work, we show that a simple algorithm, closely related to
several used in practice, provably converges to the proximal operator under a
log-concavity assumption on the prior $p$. We show that this algorithm can be
interpreted as a gradient descent on smoothed proximal objectives. Our analysis
thus provides a theoretical foundation for a class of empirically successful
but previously heuristic methods.

</details>


### [100] [The calculus of variations of the Transformer on the hyperspherical tangent bundle](https://arxiv.org/abs/2507.15431)
*Andrew Gracyk*

**主要类别:** cs.LG

**AI概要:** 本文通过拉格朗日优化和变分法，为Transformer模型提供了理论数学背景，并推导了适用于该模型的欧拉-拉格朗日方程。


<details>
  <summary>更多</summary>
  
**动机:** 作者希望为Transformer提供一个坚实的理论基础，以便更好地理解其工作原理并开拓新的应用场景。

**方法:** 作者使用拉格朗日优化和变分法来分析Transformer，并将其视为高维单位球上的切丛中的流形。

**结果:** 作者成功地建立了适用于Transformer的数学框架，并推导出了其欧拉-拉格朗日方程。

**结论:** 这项研究为未来的Transformer研究奠定了基础，特别是在流形上的变分法方面。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+calculus+of+variations+of+the+Transformer+on+the+hyperspherical+tangent+bundle，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15431，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15431&send_immediately=true&force_search=false)

**原文摘要:** We offer a theoretical mathematical background to Transformers through
Lagrangian optimization across the token space. The Transformer, as a flow map,
exists in the tangent fiber for each token along the high-dimensional unit
sphere. The circumstance of the hypersphere across the latent data is
reasonable due to the trained diagonal matrix equal to the identity, which has
various empirical justifications. Thus, under the continuum limit of the
dynamics, the latent vectors flow among the tangent bundle. Using these facts,
we devise a mathematical framework for the Transformer through calculus of
variations. We develop a functional and show that the continuous flow map
induced by the Transformer satisfies this functional, therefore the Transformer
can be viewed as a natural solver of a calculus of variations problem. We
invent new scenarios of when our methods are applicable based on loss
optimization with respect to path optimality. We derive the Euler-Lagrange
equation for the Transformer. The variant of the Euler-Lagrange equation we
present has various appearances in literature, but, to our understanding,
oftentimes not foundationally proven or under other specialized cases. Our
overarching proof is new: our techniques are classical and the use of the flow
map object is original. We provide several other relevant results, primarily
ones specific to neural scenarios. In particular, much of our analysis will be
attempting to quantify Transformer data in variational contexts under neural
approximations. Calculus of variations on manifolds is a well-nourished
research area, but for the Transformer specifically, it is uncharted: we lay
the foundation for this area through an introduction to the Lagrangian for the
Transformer.

</details>


### [101] [An Adaptive Random Fourier Features approach Applied to Learning Stochastic Differential Equations](https://arxiv.org/abs/2507.15442)
*Owen Douglas, Aku Kammonen, Anamika Pandey, Raúl Tempone*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种基于自适应随机傅里叶特征的训练算法，用于从未知数据中学习随机微分方程的漂移和扩散成分。该方法在多个基准问题上表现优异，展现了ARFF作为数据驱动随机动力学建模替代方案的潜力。


<details>
  <summary>更多</summary>
  
**动机:** 作者希望改进从快照数据中学习随机微分方程（SDE）的方法，特别是漂移和扩散部分的学习，以提高数据驱动模型的准确性和效率。

**方法:** 使用自适应随机傅里叶特征（ARFF）结合Metropolis采样和重采样的训练算法，并采用基于似然性的损失函数，该损失函数由Euler-Maruyama积分推导而来。

**结果:** 与传统的基于Adam的优化相比，ARFF方法在损失最小化和收敛速度方面匹配或超越了性能，特别是在多项式示例、欠阻尼朗之万动力学、随机易感-感染-恢复模型和随机波动方程等案例中。

**结论:** 研究结果表明，ARFF作为一种新的训练算法，在从未知数据中学习随机微分方程的漂移和扩散成分方面具有很大的潜力，可以作为传统方法的有力替代。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Adaptive+Random+Fourier+Features+approach+Applied+to+Learning+Stochastic+Differential+Equations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15442，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15442&send_immediately=true&force_search=false)

**原文摘要:** This work proposes a training algorithm based on adaptive random Fourier
features (ARFF) with Metropolis sampling and resampling
\cite{kammonen2024adaptiverandomfourierfeatures} for learning drift and
diffusion components of stochastic differential equations from snapshot data.
Specifically, this study considers It\^{o} diffusion processes and a
likelihood-based loss function derived from the Euler-Maruyama integration
introduced in \cite{Dietrich2023} and
\cite{dridi2021learningstochasticdynamicalsystems}.
  This work evaluates the proposed method against benchmark problems presented
in \cite{Dietrich2023}, including polynomial examples, underdamped Langevin
dynamics, a stochastic susceptible-infected-recovered model, and a stochastic
wave equation. Across all cases, the ARFF-based approach matches or surpasses
the performance of conventional Adam-based optimization in both loss
minimization and convergence speed. These results highlight the potential of
ARFF as a compelling alternative for data-driven modeling of stochastic
dynamics.

</details>


### [102] [FedMultiEmo: Real-Time Emotion Recognition via Multimodal Federated Learning](https://arxiv.org/abs/2507.15470)
*Baran Can Gül, Suraksha Nadig, Stefanos Tziampazis, Nasser Jazdi, Michael Weyrich*

**主要类别:** cs.LG

**AI概要:** 本文提出FedMultiEmo框架，融合视觉和生理模态实现车内情绪识别，保护隐私并适应个体差异。


<details>
  <summary>更多</summary>
  
**动机:** 当前的车内情绪识别面临环境、个体差异和隐私问题的挑战。

**方法:** FedMultiEmo采用多模态联邦学习，在决策层面融合卷积神经网络提取的面部图像特征和随机森林分类的生理信号，使用加权的联邦平均方法，并在边缘设备到云端的原型系统上进行了测试。

**结果:** 该系统在FER2013和自定义数据集上的准确率分别为77%、74%，融合后的准确率为87%，并且可以在保持原始数据本地化的同时达到集中式基线水平。

**结论:** 研究结果表明，FedMultiEmo为汽车环境中实时、注重隐私的情绪识别提供了一种实用的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FedMultiEmo%3A+Real-Time+Emotion+Recognition+via+Multimodal+Federated+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15470，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15470&send_immediately=true&force_search=false)

**原文摘要:** In-vehicle emotion recognition underpins adaptive driver-assistance systems
and, ultimately, occupant safety. However, practical deployment is hindered by
(i) modality fragility - poor lighting and occlusions degrade vision-based
methods; (ii) physiological variability - heart-rate and skin-conductance
patterns differ across individuals; and (iii) privacy risk - centralized
training requires transmission of sensitive data. To address these challenges,
we present FedMultiEmo, a privacy-preserving framework that fuses two
complementary modalities at the decision level: visual features extracted by a
Convolutional Neural Network from facial images, and physiological cues (heart
rate, electrodermal activity, and skin temperature) classified by a Random
Forest. FedMultiEmo builds on three key elements: (1) a multimodal federated
learning pipeline with majority-vote fusion, (2) an end-to-end edge-to-cloud
prototype on Raspberry Pi clients and a Flower server, and (3) a personalized
Federated Averaging scheme that weights client updates by local data volume.
Evaluated on FER2013 and a custom physiological dataset, the federated
Convolutional Neural Network attains 77% accuracy, the Random Forest 74%, and
their fusion 87%, matching a centralized baseline while keeping all raw data
local. The developed system converges in 18 rounds, with an average round time
of 120 seconds and a per-client memory footprint below 200 MB. These results
indicate that FedMultiEmo offers a practical approach to real-time,
privacy-aware emotion recognition in automotive settings.

</details>


### [103] [Off-Policy Corrected Reward Modeling for Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2507.15507)
*Johannes Ackermann, Takashi Ishida, Masashi Sugiyama*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种新的方法Off-Policy Corrected Reward Modeling (OCRM)，用于修正强化学习从人类反馈(RLHF)中训练语言模型时出现的过优化问题。该方法通过重要性加权迭代地修正奖励模型，而无需新的标签或样本。实验表明，该方法在摘要和聊天机器人数据集上的表现显著优于标准RLHF方法和基线。


<details>
  <summary>更多</summary>
  
**动机:** 强化学习从人类反馈（RLHF）在训练语言模型时，随着训练的进行，奖励模型（RM）变得不准确，导致模型行为不再匹配人类偏好，即出现了过优化问题。本研究旨在解决这一问题。

**方法:** 作者提出了Off-Policy Corrected Reward Modeling (OCRM)，它使用重要性加权迭代地对RM进行离策略修正，从而不需要新的标签或样本就能获得更准确的RM。

**结果:** 在摘要和聊天机器人数据集上的实验表明，该方法的表现显著优于标准RLHF方法和基线。

**结论:** 作者通过引入OCRM方法解决了RLHF中的过优化问题，并且证明了该方法的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Off-Policy+Corrected+Reward+Modeling+for+Reinforcement+Learning+from+Human+Feedback，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15507，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15507&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement Learning from Human Feedback (RLHF) allows us to train models,
such as language models (LMs), to follow complex human preferences. In RLHF for
LMs, we first train an LM using supervised fine-tuning, sample pairs of
responses, obtain human feedback, and use the resulting data to train a reward
model (RM). RL methods are then used to train the LM to maximize the reward
given by the RM. As training progresses, the responses generated by the LM no
longer resemble the responses seen by the RM during training, leading to the RM
becoming inaccurate. The score given by the RM keeps increasing, but the
learned behavior no longer matches the human preferences. This issue is known
as overoptimization. We investigate overoptimization from the point of view of
distribution shift and show that the shift results in an inconsistent estimate
of the RM parameters, leading to an inconsistent estimate of the policy
gradient. We propose Off-Policy Corrected Reward Modeling (OCRM), which
iteratively off-policy corrects the RM using importance weighting, without
requiring new labels or samples. This results in a more accurate RM, which
empirically leads to an improved final policy. We validate our approach in
experiments with summarization and chatbot datasets and show that it performs
significantly better than standard RLHF methods and baselines. Our
implementation is available at
https://github.com/JohannesAck/OffPolicyCorrectedRewardModeling

</details>


### [104] [An Investigation of Test-time Adaptation for Audio Classification under Background Noise](https://arxiv.org/abs/2507.15523)
*Weichuang Shao, Iman Yi Liao, Tomas Henrique Bode Maul, Tissa Chandesa*

**主要类别:** cs.LG

**AI概要:** 本研究针对由背景噪音导致的音频分类领域偏移问题，使用测试时自适应（TTA）技术，并发现修改版CoNMix方法相较于其他方法能提供更高的分类准确性。


<details>
  <summary>更多</summary>
  
**动机:** 领域偏移是深度学习中的一个显著问题，它会使在源数据集上预训练的模型在测试数据集上的性能显著下降。目前没有文献报道过类似的研究，即利用TTA技术解决音频分类中的领域偏移问题。

**方法:** 采用两种常见的TTA方法TTT和TENT，以及一种最先进方法CoNMix，并对它们进行了修改。通过两个流行的音频分类数据集AudioMNIST和SpeechCommands V1，在不同类型的背景噪音和噪音严重程度级别下评估这些方法的表现。

**结果:** 实验结果表明，所提出的修改版CoNMix方法在领域偏移情况下产生了最高的分类准确性（例如，在10 dB自行车背景噪音下的错误率为5.31%，在3 dB流水声背景噪音下的错误率为12.75%）。

**结论:** 这是首次将TTA技术应用于音频分类领域偏移问题的研究，修改后的CoNMix方法表现出色，为未来的研究提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Investigation+of+Test-time+Adaptation+for+Audio+Classification+under+Background+Noise，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15523，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15523&send_immediately=true&force_search=false)

**原文摘要:** Domain shift is a prominent problem in Deep Learning, causing a model
pre-trained on a source dataset to suffer significant performance degradation
on test datasets. This research aims to address the issue of audio
classification under domain shift caused by background noise using Test-Time
Adaptation (TTA), a technique that adapts a pre-trained model during testing
using only unlabelled test data before making predictions. We adopt two common
TTA methods, TTT and TENT, and a state-of-the-art method CoNMix, and
investigate their respective performance on two popular audio classification
datasets, AudioMNIST (AM) and SpeechCommands V1 (SC), against different types
of background noise and noise severity levels. The experimental results reveal
that our proposed modified version of CoNMix produced the highest
classification accuracy under domain shift (5.31% error rate under 10 dB
exercise bike background noise and 12.75% error rate under 3 dB running tap
background noise for AM) compared to TTT and TENT. The literature search
provided no evidence of similar works, thereby motivating the work reported
here as the first study to leverage TTA techniques for audio classification
under domain shift.

</details>


### [105] [Data Aware Differentiable Neural Architecture Search for Tiny Keyword Spotting Applications](https://arxiv.org/abs/2507.15545)
*Yujia Shi, Emil Njor, Pablo Martínez-Nuevo, Sven Ewan Shepstone, Xenofon Fafoutis*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种新的方法，称为“数据感知可微分神经架构搜索”，它可以在TinyML应用中平衡资源使用和系统性能。


<details>
  <summary>更多</summary>
  
**动机:** 机器学习的成功越来越多地受到其显著的资源足迹的限制，这促使人们对其高效范式（如TinyML）产生兴趣。然而，设计TinyML系统的固有复杂性阻碍了它们的广泛应用。

**方法:** 引入了“数据感知可微分神经架构搜索”，它扩展了搜索空间以包括数据配置参数和架构选择。这使得可以共同优化模型架构和输入数据特征。

**结果:** 初步结果显示，这种新方法可以在关键词识别任务上生成精简但高度准确的TinyML系统。

**结论:** 该方法能够有效降低设计TinyML系统的复杂性，并促进其广泛应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data+Aware+Differentiable+Neural+Architecture+Search+for+Tiny+Keyword+Spotting+Applications，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15545，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15545&send_immediately=true&force_search=false)

**原文摘要:** The success of Machine Learning is increasingly tempered by its significant
resource footprint, driving interest in efficient paradigms like TinyML.
However, the inherent complexity of designing TinyML systems hampers their
broad adoption. To reduce this complexity, we introduce "Data Aware
Differentiable Neural Architecture Search". Unlike conventional Differentiable
Neural Architecture Search, our approach expands the search space to include
data configuration parameters alongside architectural choices. This enables
Data Aware Differentiable Neural Architecture Search to co-optimize model
architecture and input data characteristics, effectively balancing resource
usage and system performance for TinyML applications. Initial results on
keyword spotting demonstrate that this novel approach to TinyML system design
can generate lean but highly accurate systems.

</details>


### [106] [The added value for MRI radiomics and deep-learning for glioblastoma prognostication compared to clinical and molecular information](https://arxiv.org/abs/2507.15548)
*D. Abler, O. Pusterla, A. Joye-Kühnis, N. Andratschke, M. Bach, A. Bink, S. M. Christ, P. Hagmann, B. Pouymayou, E. Pravatà, P. Radojewski, M. Reyes, L. Ruinelli, R. Schaer, B. Stieltjes, G. Treglia, W. Valenzuela, R. Wiest, S. Zoergiebel, M. Guckenberger, S. Tanadini-Lang, A. Depeursinge*

**主要类别:** cs.LG

**AI概要:** 这项多中心研究表明，传统的放射组学和深度学习放射组学在胶质母细胞瘤预后预测方面提供的附加价值有限。


<details>
  <summary>更多</summary>
  
**动机:** 研究的动机是评估常规放射组学（CR）和基于深度学习（DL）的MRI放射组学在胶质母细胞瘤预后中的附加价值，特别是相对于临床和分子预测因子的优势。

**方法:** 研究使用了来自五个瑞士中心和一个公共来源的1152名患者的大型多中心数据集，开发并评估了CR和DL模型。这些模型在内部和外部队列上进行了验证，并通过不同特征集（仅影像、仅临床/分子、组合特征）和患者子集进行了次级分析。

**结果:** 在外部验证中，组合特征的CR模型达到了0.75的AUC，略优于仅临床（0.74）和仅影像（0.68）模型。DL模型表现出类似趋势，但在统计上不显著。对于总生存期预测，CR模型显示影像数据具有更大的相关性，但优势仅为2-4个C指数点。

**结论:** 尽管确认了MRI序列对胶质母细胞瘤预后的预测价值，但该研究表明，标准的CR和DL放射组学方法相比人口统计学预测因子如年龄和性别，提供的附加价值有限。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+added+value+for+MRI+radiomics+and+deep-learning+for+glioblastoma+prognostication+compared+to+clinical+and+molecular+information，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15548，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15548&send_immediately=true&force_search=false)

**原文摘要:** Background: Radiomics shows promise in characterizing glioblastoma, but its
added value over clinical and molecular predictors has yet to be proven. This
study assessed the added value of conventional radiomics (CR) and deep learning
(DL) MRI radiomics for glioblastoma prognosis (<= 6 vs > 6 months survival) on
a large multi-center dataset.
  Methods: After patient selection, our curated dataset gathers 1152
glioblastoma (WHO 2016) patients from five Swiss centers and one public source.
It included clinical (age, gender), molecular (MGMT, IDH), and baseline MRI
data (T1, T1 contrast, FLAIR, T2) with tumor regions. CR and DL models were
developed using standard methods and evaluated on internal and external
cohorts. Sub-analyses assessed models with different feature sets
(imaging-only, clinical/molecular-only, combined-features) and patient subsets
(S-1: all patients, S-2: with molecular data, S-3: IDH wildtype).
  Results: The best performance was observed in the full cohort (S-1). In
external validation, the combined-feature CR model achieved an AUC of 0.75,
slightly, but significantly outperforming clinical-only (0.74) and imaging-only
(0.68) models. DL models showed similar trends, though without statistical
significance. In S-2 and S-3, combined models did not outperform clinical-only
models. Exploratory analysis of CR models for overall survival prediction
suggested greater relevance of imaging data: across all subsets,
combined-feature models significantly outperformed clinical-only models, though
with a modest advantage of 2-4 C-index points.
  Conclusions: While confirming the predictive value of anatomical MRI
sequences for glioblastoma prognosis, this multi-center study found standard CR
and DL radiomics approaches offer minimal added value over demographic
predictors such as age and gender.

</details>


### [107] [PhysGym: Benchmarking LLMs in Interactive Physics Discovery with Controlled Priors](https://arxiv.org/abs/2507.15550)
*Yimeng Chen, Piotr Piȩkos, Mateusz Ostaszewski, Firas Laakom, Jürgen Schmidhuber*

**主要类别:** cs.LG

**AI概要:** 本文介绍了PhysGym，一个用于评估基于大型语言模型的代理在互动物理环境中进行科学推理的新基准套件和模拟平台。它提供了对先前知识水平的精细控制，并通过一系列互动模拟来严格评估代理性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前缺乏专门的基准来评估大型语言模型代理在不同环境复杂度下运用先验知识进行科学发现的能力。

**方法:** 引入了PhysGym，一个新基准套件和模拟平台，其中包含了一系列互动模拟，代理必须在约束条件下主动探测环境、收集数据并提出关于底层物理定律的假设。

**结果:** 通过展示基线大型语言模型的结果，证明了该基准能够根据不同的先验知识和任务复杂度区分代理能力。

**结论:** PhysGym提供了一个标准化的评估协议和指标体系，可用于评估假设的准确性和模型的保真度，从而填补了现有评估工具的空白。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PhysGym%3A+Benchmarking+LLMs+in+Interactive+Physics+Discovery+with+Controlled+Priors，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15550，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15550&send_immediately=true&force_search=false)

**原文摘要:** Evaluating the scientific discovery capabilities of large language model
based agents, particularly how they cope with varying environmental complexity
and utilize prior knowledge, requires specialized benchmarks currently lacking
in the landscape. To address this gap, we introduce PhysGym, a novel benchmark
suite and simulation platform for rigorously assessing LLM-based scientific
reasoning in interactive physics environments. PhysGym's primary contribution
lies in its sophisticated control over the level of prior knowledge provided to
the agent. This allows researchers to dissect agent performance along axes
including the complexity of the problem and the prior knowledge levels. The
benchmark comprises a suite of interactive simulations, where agents must
actively probe environments, gather data sequentially under constraints and
formulate hypotheses about underlying physical laws. PhysGym provides
standardized evaluation protocols and metrics for assessing hypothesis accuracy
and model fidelity. We demonstrate the benchmark's utility by presenting
results from baseline LLMs, showcasing its ability to differentiate
capabilities based on varying priors and task complexity.

</details>


### [108] [Trade-offs between elective surgery rescheduling and length-of-stay prediction accuracy](https://arxiv.org/abs/2507.15566)
*Pieter Smet, Martina Doneda, Ettore Lanzarone, Giuliana Carello*

**主要类别:** cs.LG

**AI概要:** 本文探讨了住院床位预测准确性和重新调度策略之间的关系，以优化资源利用并防止床位超载。


<details>
  <summary>更多</summary>
  
**动机:** 手术病人的住院床位是有限的资源，机器学习模型用于预测病人住院时间（LOS）以规划床位可用性。然而，实际住院时间可能与预测值相差很大，这可能会使计划变得不可行。因此，需要研究如何在LOS预测不准确的情况下，通过重新调度策略来优化资源利用和防止床位超载。

**方法:** 使用模拟的机器学习方法评估数据驱动的方法，并探索不同的纠正政策下LOS预测准确性与重新调度灵活性之间的关系。

**结果:** 确定了在LOS预测误差下的最有效的病人重新调度策略，可以预防床位溢出同时优化资源利用。

**结论:** 更准确的LOS预测不一定能减少重新调度的需求，而适当的重新调度策略可以在预测不准确时有效地管理资源。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Trade-offs+between+elective+surgery+rescheduling+and+length-of-stay+prediction+accuracy，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15566，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15566&send_immediately=true&force_search=false)

**原文摘要:** The availability of downstream resources plays a critical role in planning
the admission of patients undergoing elective surgery, with inpatient beds
being one of the most crucial resources. When planning patient admissions,
predictions on their length-of-stay (LOS) made by machine learning (ML) models
are used to ensure bed availability. However, the actual LOS for each patient
may differ considerably from the predicted value, potentially making the
schedule infeasible. To address such infeasibilities, rescheduling strategies
that take advantage of operational flexibility can be implemented. For example,
adjustments may include postponing admission dates, relocating patients to
different wards, or even transferring patients who are already admitted. The
common assumption is that more accurate LOS predictions reduce the impact of
rescheduling. However, training ML models that can make such accurate
predictions can be costly. Building on previous work that proposed simulated
\ac{ml} for evaluating data-driven approaches, this paper explores the
relationship between LOS prediction accuracy and rescheduling flexibility
across various corrective policies. Specifically, we examine the most effective
patient rescheduling strategies under LOS prediction errors to prevent bed
overflows while optimizing resource utilization.

</details>


### [109] [On the Role of AI in Managing Satellite Constellations: Insights from the ConstellAI Project](https://arxiv.org/abs/2507.15574)
*Gregory F. Stock, Juan A. Fraire, Holger Hermanns, Jędrzej Mosiężny, Yusra Al-Khazraji, Julio Ramírez Molina, Evridiki V. Ntagiou*

**主要类别:** cs.LG

**AI概要:** 本文探讨了AI在优化卫星巨型星座操作中的作用，特别是通过强化学习改进数据路由和资源分配。研究发现，与传统方法相比，这种方法能提供更灵活、可扩展和通用的决策过程。


<details>
  <summary>更多</summary>
  
**动机:** 随着近地轨道卫星星座的迅速扩展，卫星网络管理面临重大挑战，需要创新的方法来实现高效、可扩展和有弹性的运作。

**方法:** 研究人员使用了强化学习（RL）算法，以改善两个关键的操作挑战：数据路由和资源分配。对于数据路由，RL用于减少端到端延迟；对于资源分配，RL则专注于优化任务调度，充分利用有限的资源如电池和内存。

**结果:** 两种用例都针对多种卫星星座配置和操作场景进行了测试，结果显示RL不仅能够与经典方法竞争，而且在决策过程中提供了更高的灵活性、可扩展性和通用性。

**结论:** 研究表明，AI可以通过提供更适应性强、稳健且具有成本效益的解决方案，从根本上改变卫星星座管理的格局。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Role+of+AI+in+Managing+Satellite+Constellations%3A+Insights+from+the+ConstellAI+Project，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15574，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15574&send_immediately=true&force_search=false)

**原文摘要:** The rapid expansion of satellite constellations in near-Earth orbits presents
significant challenges in satellite network management, requiring innovative
approaches for efficient, scalable, and resilient operations. This paper
explores the role of Artificial Intelligence (AI) in optimizing the operation
of satellite mega-constellations, drawing from the ConstellAI project funded by
the European Space Agency (ESA). A consortium comprising GMV GmbH, Saarland
University, and Thales Alenia Space collaborates to develop AI-driven
algorithms and demonstrates their effectiveness over traditional methods for
two crucial operational challenges: data routing and resource allocation. In
the routing use case, Reinforcement Learning (RL) is used to improve the
end-to-end latency by learning from historical queuing latency, outperforming
classical shortest path algorithms. For resource allocation, RL optimizes the
scheduling of tasks across constellations, focussing on efficiently using
limited resources such as battery and memory. Both use cases were tested for
multiple satellite constellation configurations and operational scenarios,
resembling the real-life spacecraft operations of communications and Earth
observation satellites. This research demonstrates that RL not only competes
with classical approaches but also offers enhanced flexibility, scalability,
and generalizability in decision-making processes, which is crucial for the
autonomous and intelligent management of satellite fleets. The findings of this
activity suggest that AI can fundamentally alter the landscape of satellite
constellation management by providing more adaptive, robust, and cost-effective
solutions.

</details>


### [110] [We Need to Rethink Benchmarking in Anomaly Detection](https://arxiv.org/abs/2507.15584)
*Philipp Röchner, Simon Klüttermann, Franz Rothlauf, Daniel Schlör*

**主要类别:** cs.LG

**AI概要:** 本文认为异常检测算法评估方式的局限性导致了性能提升的停滞，并提出需要基于应用场景特性重新思考和改进基准测试方法。


<details>
  <summary>更多</summary>
  
**动机:** 作者观察到尽管有新的异常检测算法不断被提出，但与已建立的基础算法相比，性能差异微乎其微，似乎进展停滞不前。这激发了作者探讨这一现象背后的原因，即我们评估异常检测算法的方式存在局限性。

**方法:** 作者建议从三个关键领域进行改进：1）根据通用分类法确定异常检测场景；2）对异常检测管道进行端到端和按组件分析；3）根据场景目标有意义地评估异常检测算法。

**结果:** 论文并没有提供实验结果，而是一个立场声明，呼吁研究界关注并改善当前异常检测算法的评估方法。

**结论:** 作者总结认为为了推动异常检测技术的进步，必须重新思考并改进当前的基准测试方法，使其能够更准确反映不同应用领域的异常多样性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是We+Need+to+Rethink+Benchmarking+in+Anomaly+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15584，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15584&send_immediately=true&force_search=false)

**原文摘要:** Despite the continuous proposal of new anomaly detection algorithms and
extensive benchmarking efforts, progress seems to stagnate, with only minor
performance differences between established baselines and new algorithms. In
this position paper, we argue that this stagnation is due to limitations in how
we evaluate anomaly detection algorithms. Current benchmarking does not, for
example, sufficiently reflect the diversity of anomalies in applications
ranging from predictive maintenance to scientific discovery. Consequently, we
need to rethink benchmarking in anomaly detection. In our opinion, anomaly
detection should be studied using scenarios that capture the relevant
characteristics of different applications. We identify three key areas for
improvement: First, we need to identify anomaly detection scenarios based on a
common taxonomy. Second, anomaly detection pipelines should be analyzed
end-to-end and by component. Third, evaluating anomaly detection algorithms
should be meaningful regarding the scenario's objectives.

</details>


### [111] [Red-Team Multi-Agent Reinforcement Learning for Emergency Braking Scenario](https://arxiv.org/abs/2507.15587)
*Yinsong Chen, Kaifeng Wang, Xiaoqiang Meng, Xueyuan Li, Zirui Li, Xin Gao*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的框架，用于在安全关键场景中生成 corner cases，通过多智能体强化学习和约束图表示马尔可夫决策过程来提高自动驾驶车辆的决策安全性。


<details>
  <summary>更多</summary>
  
**动机:** 当前的安全关键场景决策研究依赖于低效的数据驱动场景生成或特定建模方法，无法捕捉真实世界中的corner cases。

**方法:** 使用红队多智能体强化学习框架，将具有干扰能力的背景车辆作为红队代理，并采用约束图表示马尔可夫决策过程确保红队车辆遵守安全规则。

**结果:** 实验结果表明，该框架显著影响了自动驾驶车辆决策的安全性，并生成了各种corner cases。

**结论:** 此方法为安全关键场景的研究提供了一个新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Red-Team+Multi-Agent+Reinforcement+Learning+for+Emergency+Braking+Scenario，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15587，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15587&send_immediately=true&force_search=false)

**原文摘要:** Current research on decision-making in safety-critical scenarios often relies
on inefficient data-driven scenario generation or specific modeling approaches,
which fail to capture corner cases in real-world contexts. To address this
issue, we propose a Red-Team Multi-Agent Reinforcement Learning framework,
where background vehicles with interference capabilities are treated as
red-team agents. Through active interference and exploration, red-team vehicles
can uncover corner cases outside the data distribution. The framework uses a
Constraint Graph Representation Markov Decision Process, ensuring that red-team
vehicles comply with safety rules while continuously disrupting the autonomous
vehicles (AVs). A policy threat zone model is constructed to quantify the
threat posed by red-team vehicles to AVs, inducing more extreme actions to
increase the danger level of the scenario. Experimental results show that the
proposed framework significantly impacts AVs decision-making safety and
generates various corner cases. This method also offers a novel direction for
research in safety-critical scenarios.

</details>


### [112] [Optimal Batch-Size Control for Low-Latency Federated Learning with Device Heterogeneity](https://arxiv.org/abs/2507.15601)
*Huiling Yang, Zhanwei Wang, Kaibin Huang*

**主要类别:** cs.LG

**AI概要:** 联邦学习（FL）在6G网络中因保护隐私而流行，对于低延迟框架设计至关重要。本文提出了一种新的C^2感知框架，用于优化批量大小控制，以最小化端到端学习延迟并确保收敛，同时平衡计算和通信能力的异构性，并通过实验验证了其优越性。


<details>
  <summary>更多</summary>
  
**动机:** 由于联邦学习（FL）具备保护隐私的能力，在第六代（6G）网络中受到欢迎，它能推动各种物联网应用的发展，如自动驾驶、增强现实和医疗保健等关键任务且时间敏感的应用，因此需要设计低延迟的FL框架来保证高学习性能。

**方法:** 提出了一种新的C^2感知框架，该框架通过优化批量大小控制以最小化端到端学习延迟，同时确保收敛。此方法旨在平衡由收敛分析揭示的基本C^2权衡，即增加批量大小可以提高梯度估计的准确性，从而减少收敛所需的通信轮次，但会导致每轮延迟增加。

**结果:** 通过使用真实数据集进行的广泛实验表明，所提出的策略优于传统的批量调整方案，后者未考虑C^2权衡或设备异质性。

**结论:** 本文提出的C^2感知框架能够有效地优化批量大小控制，以实现低延迟的联邦学习，适应不同的设备异质性，并在实际应用中展现出优越的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Optimal+Batch-Size+Control+for+Low-Latency+Federated+Learning+with+Device+Heterogeneity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15601，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15601&send_immediately=true&force_search=false)

**原文摘要:** Federated learning (FL) has emerged as a popular approach for collaborative
machine learning in sixth-generation (6G) networks, primarily due to its
privacy-preserving capabilities. The deployment of FL algorithms is expected to
empower a wide range of Internet-of-Things (IoT) applications, e.g., autonomous
driving, augmented reality, and healthcare. The mission-critical and
time-sensitive nature of these applications necessitates the design of
low-latency FL frameworks that guarantee high learning performance. In
practice, achieving low-latency FL faces two challenges: the overhead of
computing and transmitting high-dimensional model updates, and the
heterogeneity in communication-and-computation (C$^2$) capabilities across
devices. To address these challenges, we propose a novel C$^2$-aware framework
for optimal batch-size control that minimizes end-to-end (E2E) learning latency
while ensuring convergence. The framework is designed to balance a fundamental
C$^2$ tradeoff as revealed through convergence analysis. Specifically,
increasing batch sizes improves the accuracy of gradient estimation in FL and
thus reduces the number of communication rounds required for convergence, but
results in higher per-round latency, and vice versa. The associated problem of
latency minimization is intractable; however, we solve it by designing an
accurate and tractable surrogate for convergence speed, with parameters fitted
to real data. This approach yields two batch-size control strategies tailored
to scenarios with slow and fast fading, while also accommodating device
heterogeneity. Extensive experiments using real datasets demonstrate that the
proposed strategies outperform conventional batch-size adaptation schemes that
do not consider the C$^2$ tradeoff or device heterogeneity.

</details>


### [113] [Accelerating HEC-RAS: A Recurrent Neural Operator for Rapid River Forecasting](https://arxiv.org/abs/2507.15614)
*Edward Holmberg, Pujan Pokhrel, Maximilian Zoch, Elias Ioup, Ken Pathak, Steven Sloan, Kendall Niles, Jay Ratcliff, Maik Flanagin, Christian Guetl, Julian Simeonov, Mahdi Abdelguerfi*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种深度学习替代模型，该模型通过结合GRU和Geo-FNO来加速HEC-RAS水文模拟，从而在不牺牲精度的情况下显著缩短计算时间。


<details>
  <summary>更多</summary>
  
**动机:** 物理基础求解器（如HEC-RAS）虽然能提供高保真的河流预测，但在洪水事件中的实时决策过于计算密集。为了加速这些模拟而不牺牲准确性，提出了这一研究。

**方法:** 该方法采用了一种混合自动回归架构，将门控循环单元（GRU）与几何感知傅里叶神经算子（Geo-FNO）相结合，以捕捉短期时间动态和长距离空间依赖性。特征向量从原生HEC-RAS文件中提取，编码了动态状态、静态几何结构和边界强制。

**结果:** 该模型在密西西比河流域的67个河段上进行了训练，并在一个未见过的保留模拟中进行了评估。结果表明，该模型具有很强的预测准确性，绝对水位误差中值为0.31英尺，并且将整个67个河段集合预报的时间从139分钟减少到40分钟，加速近3.5倍。

**结论:** 这种数据驱动的方法的成功证明，稳健的特征工程可以产生一个可行的、高速的常规水力模型替代品，提高了大规模集合洪水预报的计算可行性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Accelerating+HEC-RAS%3A+A+Recurrent+Neural+Operator+for+Rapid+River+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15614，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15614&send_immediately=true&force_search=false)

**原文摘要:** Physics-based solvers like HEC-RAS provide high-fidelity river forecasts but
are too computationally intensive for on-the-fly decision-making during flood
events. The central challenge is to accelerate these simulations without
sacrificing accuracy. This paper introduces a deep learning surrogate that
treats HEC-RAS not as a solver but as a data-generation engine. We propose a
hybrid, auto-regressive architecture that combines a Gated Recurrent Unit (GRU)
to capture short-term temporal dynamics with a Geometry-Aware Fourier Neural
Operator (Geo-FNO) to model long-range spatial dependencies along a river
reach. The model learns underlying physics implicitly from a minimal
eight-channel feature vector encoding dynamic state, static geometry, and
boundary forcings extracted directly from native HEC-RAS files. Trained on 67
reaches of the Mississippi River Basin, the surrogate was evaluated on a
year-long, unseen hold-out simulation. Results show the model achieves a strong
predictive accuracy, with a median absolute stage error of 0.31 feet.
Critically, for a full 67-reach ensemble forecast, our surrogate reduces the
required wall-clock time from 139 minutes to 40 minutes, a speedup of nearly
3.5 times over the traditional solver. The success of this data-driven approach
demonstrates that robust feature engineering can produce a viable, high-speed
replacement for conventional hydraulic models, improving the computational
feasibility of large-scale ensemble flood forecasting.

</details>


### [114] [Data Mixing Agent: Learning to Re-weight Domains for Continual Pre-training](https://arxiv.org/abs/2507.15640)
*Kailai Yang, Xiao Liu, Lei Ji, Hao Li, Yeyun Gong, Peng Cheng, Mao Yang*

**主要类别:** cs.LG

**AI概要:** 提出了一种基于强化学习的数据混合代理，用于自动重新加权来自源和目标领域的训练数据组合，以实现持续预训练中的平衡性能。该方法在数学推理和代码生成领域表现出色，并且可以泛化到未见过的源领域、目标模型和域空间。


<details>
  <summary>更多</summary>
  
**动机:** 现有的解决灾难性遗忘问题的方法依赖于手动指定领域权重，这可能不够灵活或高效。本文希望开发一种更通用的方法来自动学习如何重新加权不同领域的数据。

**方法:** 作者提出了Data Mixing Agent（DMA），这是第一个基于模型的端到端框架，它通过在大量数据混合轨迹上进行强化学习来学习可泛化的启发式规则，从而自动调整源领域和目标领域的数据比例。

**结果:** 实验表明，在数学推理任务上的持续预训练中，DMA比强大的基线模型表现更好，能够更好地平衡源领域和目标领域的性能。此外，DMA在新的源领域、目标模型和域空间上具有良好的泛化能力，并且在代码生成领域也展示了其适应性。

**结论:** 研究证明了Data Mixing Agent可以通过自动调整数据混合策略来提高大型语言模型在新领域的表现，同时保持其原有能力。这种方法不仅适用于特定的任务，而且可以推广到其他领域。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data+Mixing+Agent%3A+Learning+to+Re-weight+Domains+for+Continual+Pre-training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15640，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15640&send_immediately=true&force_search=false)

**原文摘要:** Continual pre-training on small-scale task-specific data is an effective
method for improving large language models in new target fields, yet it risks
catastrophic forgetting of their original capabilities. A common solution is to
re-weight training data mixtures from source and target fields on a domain
space to achieve balanced performance. Previous domain reweighting strategies
rely on manual designation with certain heuristics based on human intuition or
empirical results. In this work, we prove that more general heuristics can be
parameterized by proposing Data Mixing Agent, the first model-based, end-to-end
framework that learns to re-weight domains. The agent learns generalizable
heuristics through reinforcement learning on large quantities of data mixing
trajectories with corresponding feedback from an evaluation environment.
Experiments in continual pre-training on math reasoning show that Data Mixing
Agent outperforms strong baselines in achieving balanced performance across
source and target field benchmarks. Furthermore, it generalizes well across
unseen source fields, target models, and domain spaces without retraining.
Direct application to the code generation field also indicates its adaptability
across target domains. Further analysis showcases the agents' well-aligned
heuristics with human intuitions and their efficiency in achieving superior
model performance with less source-field data.

</details>


### [115] [Towards Explainable Anomaly Detection in Shared Mobility Systems](https://arxiv.org/abs/2507.15643)
*Elnur Isgandarov, Matteo Cederle, Federico Chiariotti, Gian Antonio Susto*

**主要类别:** cs.LG

**AI概要:** 本文提出了一个可解释的异常检测框架，用于识别共享单车系统中的异常情况。该框架结合了多源数据和Isolation Forest算法，并通过实验证明了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 识别共享移动系统中的异常对于优化运营、提高服务可靠性和增强用户体验至关重要。

**方法:** 该研究采用Isolation Forest算法进行无监督异常检测，并使用基于深度的隔离森林特征重要性（DIFFI）算法提供可解释性。

**结果:** 结果表明，站点级别的分析提供了对外部因素（如恶劣天气和有限的交通可用性）影响的稳健理解。

**结论:** 本研究的发现有助于改善共享移动操作中的决策。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Explainable+Anomaly+Detection+in+Shared+Mobility+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15643，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15643&send_immediately=true&force_search=false)

**原文摘要:** Shared mobility systems, such as bike-sharing networks, play a crucial role
in urban transportation. Identifying anomalies in these systems is essential
for optimizing operations, improving service reliability, and enhancing user
experience. This paper presents an interpretable anomaly detection framework
that integrates multi-source data, including bike-sharing trip records, weather
conditions, and public transit availability. The Isolation Forest algorithm is
employed for unsupervised anomaly detection, along with the Depth-based
Isolation Forest Feature Importance (DIFFI) algorithm providing
interpretability. Results show that station-level analysis offers a robust
understanding of anomalies, highlighting the influence of external factors such
as adverse weather and limited transit availability. Our findings contribute to
improving decision-making in shared mobility operations.

</details>


### [116] [GeoHNNs: Geometric Hamiltonian Neural Networks](https://arxiv.org/abs/2507.15678)
*Amine Mohamed Aboussalah, Abdessalam Ed-dib*

**主要类别:** cs.LG

**AI概要:** 该论文提出了Geometric Hamiltonian Neural Networks (GeoHNN)，通过明确编码物理定律固有的几何先验来学习动力学，强制执行黎曼几何和辛几何两个基本结构，实验表明GeoHNN比现有模型具有显著的优越性。


<details>
  <summary>更多</summary>
  
**动机:** 现代机器学习方法在从数据建模复杂动态方面提供了强大的工具，但通常忽略了底层的几何结构，这可能导致对于高维和混沌系统长期预测的不稳定性。

**方法:** 引入了Geometric Hamiltonian Neural Networks (GeoHNN)框架，它通过参数化惯性矩阵及其自然数学空间中的对称正定矩阵来强制执行惯性的黎曼几何，并使用约束自动编码器确保相空间体积在降低的潜在空间中得以保存以保证相空间的辛几何。

**结果:** 实验结果表明，GeoHNN在从耦合振荡器到高维变形物体的系统上显著优于现有模型，实现了卓越的长期稳定性、准确性和能量守恒。

**结论:** 将物理几何嵌入到模型中不仅是理论上的吸引力，而且是创建稳健和可推广的物理世界模型的实际必要条件。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GeoHNNs%3A+Geometric+Hamiltonian+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15678，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15678&send_immediately=true&force_search=false)

**原文摘要:** The fundamental laws of physics are intrinsically geometric, dictating the
evolution of systems through principles of symmetry and conservation. While
modern machine learning offers powerful tools for modeling complex dynamics
from data, common methods often ignore this underlying geometric fabric.
Physics-informed neural networks, for instance, can violate fundamental
physical principles, leading to predictions that are unstable over long
periods, particularly for high-dimensional and chaotic systems. Here, we
introduce \textit{Geometric Hamiltonian Neural Networks (GeoHNN)}, a framework
that learns dynamics by explicitly encoding the geometric priors inherent to
physical laws. Our approach enforces two fundamental structures: the Riemannian
geometry of inertia, by parameterizing inertia matrices in their natural
mathematical space of symmetric positive-definite matrices, and the symplectic
geometry of phase space, using a constrained autoencoder to ensure the
preservation of phase space volume in a reduced latent space. We demonstrate
through experiments on systems ranging from coupled oscillators to
high-dimensional deformable objects that GeoHNN significantly outperforms
existing models. It achieves superior long-term stability, accuracy, and energy
conservation, confirming that embedding the geometry of physics is not just a
theoretical appeal but a practical necessity for creating robust and
generalizable models of the physical world.

</details>


### [117] [Explainable Anomaly Detection for Electric Vehicles Charging Stations](https://arxiv.org/abs/2507.15718)
*Matteo Cederle, Andrea Mazzucco, Andrea Demartini, Eugenio Mazza, Eugenia Suriani, Federico Vitti, Gian Antonio Susto*

**主要类别:** cs.LG

**AI概要:** 本文研究了电动汽车充电设施中的无监督异常检测技术，并使用可解释的人工智能技术增强了解释性，确定异常的根本原因。它应用了隔离森林算法和基于深度的隔离森林特征重要性方法（DIFFI）来识别导致异常的最重要特征，并在一个真实的工业案例中评估了该方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 确保电动汽车充电站的可靠性和效率需要有效的异常检测，以识别充电行为中的不规则情况，并确定这些异常背后的根本原因。

**方法:** 使用无监督异常检测技术和可解释的人工智能技术。具体来说，采用隔离森林算法检测异常，并用基于深度的隔离森林特征重要性方法（DIFFI）来确定最重要的特征。

**结果:** 该方法在一个真实的工业案例中进行了有效性评估。

**结论:** 通过结合无监督异常检测与可解释的人工智能技术，可以有效地提高电动汽车充电基础设施的可靠性及效率，并能更好地理解异常产生的原因。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Explainable+Anomaly+Detection+for+Electric+Vehicles+Charging+Stations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15718，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15718&send_immediately=true&force_search=false)

**原文摘要:** Electric vehicles (EV) charging stations are one of the critical
infrastructures needed to support the transition to renewable-energy-based
mobility, but ensuring their reliability and efficiency requires effective
anomaly detection to identify irregularities in charging behavior. However, in
such a productive scenario, it is also crucial to determine the underlying
cause behind the detected anomalies. To achieve this goal, this study
investigates unsupervised anomaly detection techniques for EV charging
infrastructure, integrating eXplainable Artificial Intelligence techniques to
enhance interpretability and uncover root causes of anomalies.
  Using real-world sensors and charging session data, this work applies
Isolation Forest to detect anomalies and employs the Depth-based Isolation
Forest Feature Importance (DIFFI) method to identify the most important
features contributing to such anomalies. The efficacy of the proposed approach
is evaluated in a real industrial case.

</details>


### [118] [Competitive Algorithms for Cooperative Multi-Agent Ski-Rental Problems](https://arxiv.org/abs/2507.15727)
*Xuchuang Wang, Bo Sun, Hedyeh Beyhaghi, John C. S. Lui, Mohammad Hajiesmaili, Adam Wierman*

**主要类别:** cs.LG

**AI概要:** 本文将经典的滑雪租赁问题推广到多代理环境，并定义了三个竞争比率，设计和分析了最优的确定性和随机策略。


<details>
  <summary>更多</summary>
  
**动机:** 经典的滑雪租赁问题仅考虑单个代理的情况，而实际生活中常常需要考虑多个代理共同决策的情景，即存在个体成本和共享成本。

**方法:** 作者引入了一个新的多代理滑雪租赁问题模型，其中每个代理可以选择以固定日租费租赁、购买个人通行证或享受折扣团体票。该论文定义了三种不同的竞争比率：总体、状态依赖和个体理性。并为每种目标设计和分析了最优的确定性和随机策略。

**结果:** 对称策略（所有代理使用相同的阈值）优于非对称策略。并且，对于每一种目标，本研究提供了竞争比率的上下限。

**结论:** 这项工作扩展了经典的滑雪租赁问题到多代理环境中，强调了在不确定性下群体决策的理论和实践意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Competitive+Algorithms+for+Cooperative+Multi-Agent+Ski-Rental+Problems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15727，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15727&send_immediately=true&force_search=false)

**原文摘要:** This paper introduces a novel multi-agent ski-rental problem that generalizes
the classical ski-rental dilemma to a group setting where agents incur
individual and shared costs. In our model, each agent can either rent at a
fixed daily cost, or purchase a pass at an individual cost, with an additional
third option of a discounted group pass available to all. We consider scenarios
in which agents' active days differ, leading to dynamic states as agents drop
out of the decision process. To address this problem from different
perspectives, we define three distinct competitive ratios: overall,
state-dependent, and individual rational. For each objective, we design and
analyze optimal deterministic and randomized policies. Our deterministic
policies employ state-aware threshold functions that adapt to the dynamic
states, while our randomized policies sample and resample thresholds from
tailored state-aware distributions. The analysis reveals that symmetric
policies, in which all agents use the same threshold, outperform asymmetric
ones. Our results provide competitive ratio upper and lower bounds and extend
classical ski-rental insights to multi-agent settings, highlighting both
theoretical and practical implications for group decision-making under
uncertainty.

</details>


### [119] [Multi-Modal Sensor Fusion for Proactive Blockage Prediction in mmWave Vehicular Networks](https://arxiv.org/abs/2507.15769)
*Ahmad M. Nazar, Abdulkadir Celik, Mohamed Y. Selim, Asmaa Abdallah, Daji Qiao, Ahmed M. Eltawil*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种利用多模态感知的 proactive blockage prediction framework，以应对毫米波频段车联网系统中信号阻挡的问题。


<details>
  <summary>更多</summary>
  
**动机:** 毫米波频段的车联网系统容易受到动态障碍物（如车辆、行人和基础设施）造成的信号阻挡影响。

**方法:** 该方法采用特定于模式的深度学习模型独立处理每个传感器流，并使用基于验证性能的softmax加权集成策略融合其输出。

**结果:** 评估表明，仅相机模型在F1分数上达到了97.1%，推理时间为89.8毫秒；相机+雷达配置将准确率提高到97.2% F1，耗时95.7毫秒。

**结论:** 结果展示了多模态感知对于毫米波阻挡预测的有效性和效率，为动态环境中的主动无线通信提供了途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Modal+Sensor+Fusion+for+Proactive+Blockage+Prediction+in+mmWave+Vehicular+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15769，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15769&send_immediately=true&force_search=false)

**原文摘要:** Vehicular communication systems operating in the millimeter wave (mmWave)
band are highly susceptible to signal blockage from dynamic obstacles such as
vehicles, pedestrians, and infrastructure. To address this challenge, we
propose a proactive blockage prediction framework that utilizes multi-modal
sensing, including camera, GPS, LiDAR, and radar inputs in an
infrastructure-to-vehicle (I2V) setting. This approach uses modality-specific
deep learning models to process each sensor stream independently and fuses
their outputs using a softmax-weighted ensemble strategy based on validation
performance. Our evaluations, for up to 1.5s in advance, show that the
camera-only model achieves the best standalone trade-off with an F1-score of
97.1% and an inference time of 89.8ms. A camera+radar configuration further
improves accuracy to 97.2% F1 at 95.7ms. Our results display the effectiveness
and efficiency of multi-modal sensing for mmWave blockage prediction and
provide a pathway for proactive wireless communication in dynamic environments.

</details>


### [120] [Deep-Learning Investigation of Vibrational Raman Spectra for Plant-Stress Analysis](https://arxiv.org/abs/2507.15772)
*Anoop C. Patil, Benny Jian Rong Sng, Yu-Wei Chang, Joana B. Pereira, Chua Nam-Hai, Rajani Sarojam, Gajendra Pratap Singh, In-Cheol Jang, Giovanni Volpe*

**主要类别:** cs.LG

**AI概要:** 本研究介绍了一种基于变分自动编码器的深度学习方法DIVA，用于自动处理拉曼光谱以检测植物压力，无需人工预处理步骤。该方法可以识别和量化重要的光谱特征，并能检测多种植物压力源，有助于推动更可持续的农业实践。


<details>
  <summary>更多</summary>
  
**动机:** 传统的拉曼光谱分析依赖于定制的数据处理工作流程，需要去除荧光背景并预先确定感兴趣的拉曼峰，这可能导致偏差和不一致性。为了提供一种无偏差的方法来识别和量化植物中的生物分子，从而实现连续健康监测和早期疾病检测，有必要开发一种新的自动化处理拉曼光谱的技术。

**方法:** 研究人员开发了DIVA（基于深度学习的振动拉曼光谱分析），它是一个基于变分自动编码器的全自动工作流程，能够处理原始拉曼光谱，包括荧光背景，而无需手动预处理。这种方法可以自动识别和量化重要的光谱特征。

**结果:** 通过将DIVA应用于检测一系列植物压力源（包括非生物和生物胁迫），研究人员证明了该方法的有效性，为AI驱动的植物健康评估铺平了道路。

**结论:** DIVA整合了深度学习与振动光谱学，提供了一种无偏、自动化的手段来处理拉曼光谱数据，促进了更具弹性和可持续性的农业实践的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Deep-Learning+Investigation+of+Vibrational+Raman+Spectra+for+Plant-Stress+Analysis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15772，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15772&send_immediately=true&force_search=false)

**原文摘要:** Detecting stress in plants is crucial for both open-farm and
controlled-environment agriculture. Biomolecules within plants serve as key
stress indicators, offering vital markers for continuous health monitoring and
early disease detection. Raman spectroscopy provides a powerful, non-invasive
means to quantify these biomolecules through their molecular vibrational
signatures. However, traditional Raman analysis relies on customized
data-processing workflows that require fluorescence background removal and
prior identification of Raman peaks of interest-introducing potential biases
and inconsistencies. Here, we introduce DIVA (Deep-learning-based Investigation
of Vibrational Raman spectra for plant-stress Analysis), a fully automated
workflow based on a variational autoencoder. Unlike conventional approaches,
DIVA processes native Raman spectra-including fluorescence backgrounds-without
manual preprocessing, identifying and quantifying significant spectral features
in an unbiased manner. We applied DIVA to detect a range of plant stresses,
including abiotic (shading, high light intensity, high temperature) and biotic
stressors (bacterial infections). By integrating deep learning with vibrational
spectroscopy, DIVA paves the way for AI-driven plant health assessment,
fostering more resilient and sustainable agricultural practices.

</details>


### [121] [Dynamics is what you need for time-series forecasting!](https://arxiv.org/abs/2507.15774)
*Alexis-Raja Brachet, Pierre-Yves Richard, Céline Hudelot*

**主要类别:** cs.LG

**AI概要:** 论文提出了一种新的视角PRO-DYN来分析现有的模型，并通过广泛的实验验证了在时间序列预测任务中，模型需要学习数据底层动态，并且将动态块置于模型末端的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 作者观察到尽管不同数据模式之间的界限正在消失，但在时间序列预测任务中，通常成功的深度模型仍然被简单的模型所挑战。他们假设这是因为时间序列预测任务需要能够学习数据潜在动态的模型。

**方法:** 作者开发了一种名为PRO-DYN的命名法，以从动态学的角度分析现有模型。通过这种方法，他们提出了两个观察结果：表现不佳的架构最多只能部分学习动态；动态模块在模型末端的位置至关重要。然后进行了大量实验来确认这些观察结果。

**结果:** 实验结果支持了他们的观察，即需要将可学习的动态模块纳入模型，并将其用作最终预测器。

**结论:** 该研究强调了在时间序列预测任务中，理解并模拟数据潜在动态的重要性，以及将动态模块放在模型末端的作用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dynamics+is+what+you+need+for+time-series+forecasting%21，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15774，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15774&send_immediately=true&force_search=false)

**原文摘要:** While boundaries between data modalities are vanishing, the usual successful
deep models are still challenged by simple ones in the time-series forecasting
task. Our hypothesis is that this task needs models that are able to learn the
data underlying dynamics. We propose to validate it through both systemic and
empirical studies. We develop an original $\texttt{PRO-DYN}$ nomenclature to
analyze existing models through the lens of dynamics. Two observations thus
emerged: $\textbf{1}$. under-performing architectures learn dynamics at most
partially, $\textbf{2}$. the location of the dynamics block at the model end is
of prime importance. We conduct extensive experiments to confirm our
observations on a set of performance-varying models with diverse backbones.
Results support the need to incorporate a learnable dynamics block and its use
as the final predictor.

</details>


### [122] [Graph Attention Specialized Expert Fusion Model for Node Classification: Based on Cora and Pubmed Datasets](https://arxiv.org/abs/2507.15784)
*Zihang Ma, Qitian Yin*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种Wasserstein-Rubinstein (WR) 距离增强的专家融合模型（WR-EFM），以改善图节点分类中的类别不平衡问题。通过为不同类别训练专门的GNN模型，并使用WR距离优化模型间的表示相似性，实现了更平衡和稳定的分类性能。


<details>
  <summary>更多</summary>
  
**动机:** 在PubMed引文网络数据集上，传统的GCN模型在不同类别上的分类准确率存在显著差异，特别是Category 2的准确率较低，仅达到74.4%，比Category 1低7.5%。

**方法:** 作者提出了WR-EFM模型，包括：1）为Category 0/1训练带有层归一化和残差连接的GNN模型；2）为Category 2训练多跳图注意力网络（GAT）；3）使用WR距离度量优化模型间表示的相似性，尤其关注提升Category 2的性能；4）采用自适应融合策略，根据特定类别的表现动态调整模型权重。

**结果:** 实验结果表明，WR-EFM在所有类别中都达到了较高的准确率：Category 0为77.8%，Category 1为78.0%，Category 2为79.9%，并且其准确率的标准变异系数（CV）仅为0.013，相比GCN降低了77.6%，证明了该方法的有效性和稳定性。

**结论:** WR-EFM提供了一种处理类别不平衡图分类任务的新范式，特别是在提高难分类类别（如Category 2）的性能方面表现出色。此外，为了促进研究社区的发展，作者开源了该项目。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph+Attention+Specialized+Expert+Fusion+Model+for+Node+Classification%3A+Based+on+Cora+and+Pubmed+Datasets，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15784，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15784&send_immediately=true&force_search=false)

**原文摘要:** Graph node classification is a fundamental task in graph neural networks
(GNNs), aiming to assign predefined class labels to nodes. On the PubMed
citation network dataset, we observe significant classification difficulty
disparities, with Category 2 achieving only 74.4% accuracy in traditional GCN,
7.5% lower than Category 1. To address this, we propose a
Wasserstein-Rubinstein (WR) distance enhanced Expert Fusion Model (WR-EFM),
training specialized GNN models for Categories 0/1 (with layer normalization
and residual connections) and Multi-hop Graph Attention Networks (GAT) for
Category 2. The WR distance metric optimizes representation similarity between
models, particularly focusing on improving Category 2 performance. Our adaptive
fusion strategy dynamically weights models based on category-specific
performance, with Category 2 assigned a GAT weight of 0.8. WR distance further
guides the fusion process by measuring distributional differences between model
representations, enabling more principled integration of complementary
features.
  Experimental results show WR-EFM achieves balanced accuracy across
categories: 77.8% (Category 0), 78.0% (Category 1), and 79.9% (Category 2),
outperforming both single models and standard fusion approaches. The
coefficient of variation (CV) of WR-EFM's category accuracies is 0.013, 77.6%
lower than GCN's 0.058, demonstrating superior stability. Notably, WR-EFM
improves Category 2 accuracy by 5.5% compared to GCN, verifying the
effectiveness of WR-guided fusion in capturing complex structural patterns.
This work provides a novel paradigm for handling class-imbalanced graph
classification tasks. To promote the research community, we release our project
at https://github.com/s010m00n/GASEM4NC.

</details>


### [123] [Small LLMs Do Not Learn a Generalizable Theory of Mind via Reinforcement Learning](https://arxiv.org/abs/2507.15788)
*Sneheel Sarangi, Hanan Salam*

**主要类别:** cs.LG

**AI概要:** 本文研究了小型大规模语言模型是否可以通过基于规则的强化学习获得类似人类的社会智能，例如心智理论。实验结果表明，这些模型虽然在训练数据上的表现有所提高，但无法将这种能力泛化到未见过的心智理论任务上，这表明所学行为是一种狭隘的过拟合，而不是真正抽象的心智理论能力的获取。


<details>
  <summary>更多</summary>
  
**动机:** 动机是探讨通过强化学习技术（特别是带有可验证奖励的强化学习）能否使小规模的大规模语言模型获得更复杂的人类社会智能，如心智理论（ToM）。

**方法:** 该研究使用了多种著名的心智理论数据集（HiToM、ExploreToM、FANToM）对模型进行了训练，并在保留的数据集（如OpenToM）上测试其泛化能力。

**结果:** 尽管在分布内任务上的性能有所提升，但模型未能将在不同特征的未见心智理论任务上进行转移。长期的强化学习训练导致模型“破解”训练数据集的统计模式，在分布外任务上没有改进或性能下降。

**结论:** 研究表明，小型语言模型难以发展出通用的心智理论能力，所学行为更多表现为狭窄的过拟合而非真正的抽象心智理论能力的获取。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Small+LLMs+Do+Not+Learn+a+Generalizable+Theory+of+Mind+via+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15788，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15788&send_immediately=true&force_search=false)

**原文摘要:** Recent advancements in large language models (LLMs) have demonstrated
emergent capabilities in complex reasoning, largely spurred by rule-based
Reinforcement Learning (RL) techniques applied during the post-training. This
has raised the question of whether similar methods can instill more nuanced,
human-like social intelligence, such as a Theory of Mind (ToM), in LLMs. This
paper investigates whether small-scale LLMs can acquire a robust and
generalizable ToM capability through RL with verifiable rewards (RLVR). We
conduct a systematic evaluation by training models on various combinations of
prominent ToM datasets (HiToM, ExploreToM, FANToM) and testing for
generalization on held-out datasets (e.g., OpenToM). Our findings indicate that
small LLMs struggle to develop a generic ToM capability. While performance on
in-distribution tasks improves, this capability fails to transfer to unseen ToM
tasks with different characteristics. Furthermore, we demonstrate that
prolonged RL training leads to models ``hacking'' the statistical patterns of
the training datasets, resulting in significant performance gains on in-domain
data but no change, or degradation of performance on out-of-distribution tasks.
This suggests the learned behavior is a form of narrow overfitting rather than
the acquisition of a true, abstract ToM capability.

</details>


### [124] [Federated Split Learning with Improved Communication and Storage Efficiency](https://arxiv.org/abs/2507.15816)
*Yujia Mu, Cong Shen*

**主要类别:** cs.LG

**AI概要:** 提出了一种新的联合分割学习方法CSE-FSL，通过辅助网络本地更新客户端权重并减少服务器端的存储需求，从而减少通信和计算成本。


<details>
  <summary>更多</summary>
  
**动机:** 现有的联合分割学习（FSL）虽然可以减轻边缘设备的计算负担，但仍然存在高通信开销和服务器端的显著存储要求的问题。

**方法:** 利用辅助网络在客户端本地更新权重，同时保持服务器端单一模型，避免频繁从服务器传输梯度，并通过选择性发送smashed数据来减少传输量。

**结果:** 理论分析保证了CSE-FSL在非凸损失函数下的收敛性，实验结果表明CSE-FSL在实际的FL任务中实现了显著的通信减少。

**结论:** CSE-FSL有效地解决了现有FSL方法中的通信和存储问题，在实际应用中表现出了优越的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Federated+Split+Learning+with+Improved+Communication+and+Storage+Efficiency，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15816，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15816&send_immediately=true&force_search=false)

**原文摘要:** Federated learning (FL) is one of the popular distributed machine learning
(ML) solutions but incurs significant communication and computation costs at
edge devices. Federated split learning (FSL) can train sub-models in parallel
and reduce the computational burden of edge devices by splitting the model
architecture. However, it still requires a high communication overhead due to
transmitting the smashed data and gradients between clients and the server in
every global round. Furthermore, the server must maintain separate partial
models for every client, leading to a significant storage requirement. To
address these challenges, this paper proposes a novel communication and storage
efficient federated split learning method, termed CSE-FSL, which utilizes an
auxiliary network to locally update the weights of the clients while keeping a
single model at the server, hence avoiding frequent transmissions of gradients
from the server and greatly reducing the storage requirement of the server.
Additionally, a new model update method of transmitting the smashed data in
selected epochs can reduce the amount of smashed data sent from the clients. We
provide a theoretical analysis of CSE-FSL, rigorously guaranteeing its
convergence under non-convex loss functions. The extensive experimental results
further indicate that CSE-FSL achieves a significant communication reduction
over existing FSL solutions using real-world FL tasks.

</details>


### [125] [Multi-Strategy Improved Snake Optimizer Accelerated CNN-LSTM-Attention-Adaboost for Trajectory Prediction](https://arxiv.org/abs/2507.15832)
*Shiyang Li*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种混合CNN-LSTM-Attention-Adaboost神经网络模型，结合多策略改进的Snake-Herd优化算法，用于中长期四维轨迹预测。通过真实数据验证，该模型在处理大规模高维轨迹数据方面优于传统优化器，并且预测准确性提高了39.89%。


<details>
  <summary>更多</summary>
  
**动机:** 现有的中长期四维轨迹预测模型存在局限性，需要更精确和高效的模型来处理大规模高维轨迹数据。

**方法:** 使用Adaboost算法将多个弱学习者分隔，每个子模型利用CNN提取空间特征，LSTM捕捉时间特征，attention机制捕捉全局特征。然后通过模拟自然选择行为模式的SO算法优化预测模型的超参数。

**结果:** 实验结果表明，所提出的SO-CLA-adaboost模型在处理大规模高维轨迹数据方面优于传统的粒子群、鲸鱼和灰狼优化器，预测准确率提高了39.89%。

**结论:** 提出的混合CNN-LSTM-Attention-Adaboost神经网络模型结合多策略改进的Snake-Herd优化算法，在中长期四维轨迹预测上表现出色，具有更高的预测精度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Strategy+Improved+Snake+Optimizer+Accelerated+CNN-LSTM-Attention-Adaboost+for+Trajectory+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15832，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15832&send_immediately=true&force_search=false)

**原文摘要:** To address the limitations of medium- and long-term four-dimensional (4D)
trajectory prediction models, this paper proposes a hybrid
CNN-LSTM-attention-adaboost neural network model incorporating a multi-strategy
improved snake-herd optimization (SO) algorithm. The model applies the Adaboost
algorithm to divide multiple weak learners, and each submodel utilizes CNN to
extract spatial features, LSTM to capture temporal features, and attention
mechanism to capture global features comprehensively. The strong learner model,
combined with multiple sub-models, then optimizes the hyperparameters of the
prediction model through the natural selection behavior pattern simulated by
SO. In this study, based on the real ADS-B data from Xi'an to Tianjin, the
comparison experiments and ablation studies of multiple optimizers are carried
out, and a comprehensive test and evaluation analysis is carried out. The
results show that SO-CLA-adaboost outperforms traditional optimizers such as
particle swarm, whale, and gray wolf in handling large-scale high-dimensional
trajectory data. In addition, introducing the full-strategy collaborative
improvement SO algorithm improves the model's prediction accuracy by 39.89%.

</details>


### [126] [FASTGEN: Fast and Cost-Effective Synthetic Tabular Data Generation with LLMs](https://arxiv.org/abs/2507.15839)
*Anh Nguyen, Sam Schafft, Nicholas Hale, John Alfaro*

**主要类别:** cs.LG

**AI概要:** 本文提出了一种利用大型语言模型推断和编码字段分布以生成可复用采样脚本的方法，从而实现快速、低成本的表格数据合成。该方法在多样性和数据真实性方面优于传统直接方法，并能大幅减少大量合成数据生成的负担。


<details>
  <summary>更多</summary>
  
**动机:** 现有的使用大型语言模型直接生成每个记录的方法，在需要大量合成数据时会带来过高的时间和成本负担。

**方法:** 通过自动分类字段类型（数值型、分类型或自由文本型），大型语言模型生成基于分布的脚本，可以高效地大规模生成多样化、真实的数据集，而无需连续的模型推理。

**结果:** 实验结果表明，该方法在多样性和数据真实性方面优于传统的直接方法，大大减少了大量合成数据生成的负担。

**结论:** 研究人员认为他们的见解和经验将有助于研究人员和从业者寻找可扩展、成本效益高的合成数据生成解决方案，并计划将该方法应用于加速生产管道中的测试，缩短开发周期并提高系统效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FASTGEN%3A+Fast+and+Cost-Effective+Synthetic+Tabular+Data+Generation+with+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15839，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15839&send_immediately=true&force_search=false)

**原文摘要:** Synthetic data generation has emerged as an invaluable solution in scenarios
where real-world data collection and usage are limited by cost and scarcity.
Large language models (LLMs) have demonstrated remarkable capabilities in
producing high-fidelity, domain-relevant samples across various fields.
However, existing approaches that directly use LLMs to generate each record
individually impose prohibitive time and cost burdens, particularly when large
volumes of synthetic data are required. In this work, we propose a fast,
cost-effective method for realistic tabular data synthesis that leverages LLMs
to infer and encode each field's distribution into a reusable sampling script.
By automatically classifying fields into numerical, categorical, or free-text
types, the LLM generates distribution-based scripts that can efficiently
produce diverse, realistic datasets at scale without continuous model
inference. Experimental results show that our approach outperforms traditional
direct methods in both diversity and data realism, substantially reducing the
burden of high-volume synthetic data generation. We plan to apply this
methodology to accelerate testing in production pipelines, thereby shortening
development cycles and improving overall system efficiency. We believe our
insights and lessons learned will aid researchers and practitioners seeking
scalable, cost-effective solutions for synthetic data generation.

</details>


### [127] [GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding](https://arxiv.org/abs/2507.15846)
*Fei Tang, Zhangxuan Gu, Zhengxi Lu, Xuyang Liu, Shuheng Shen, Changhua Meng, Wen Wang, Wenqi Zhang, Yongliang Shen, Weiming Lu, Jun Xiao, Yueting Zhuang*

**主要类别:** cs.LG

**AI概要:** 本文介绍了一种新的奖励框架GUI-G²，用于将自然语言指令映射到图形用户界面的具体位置。该方法通过高斯分布建模界面元素，实现了从稀疏二元分类到密集连续优化的转变，在多个基准测试中显著优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 当前强化学习方法使用二元奖励机制，忽略了空间交互的连续性。受到人类点击行为启发，作者提出一种基于高斯分布的奖励框架以改进这一问题。

**方法:** GUI-G²引入了两种协同机制：高斯点奖励和覆盖奖励，并开发了自适应方差机制来处理不同尺度的元素。

**结果:** 实验表明，GUI-G²在ScreenSpot系列基准上大幅超越了最先进的UI-TARS-72B方法，特别是在ScreenSpot-Pro上提高了24.7%。

**结论:** 连续建模提供了对界面变化更好的鲁棒性和对未见布局的泛化能力，为GUI交互任务中的空间推理建立了新范式。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GUI-G%24%5E2%24%3A+Gaussian+Reward+Modeling+for+GUI+Grounding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15846，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15846&send_immediately=true&force_search=false)

**原文摘要:** Graphical User Interface (GUI) grounding maps natural language instructions
to precise interface locations for autonomous interaction. Current
reinforcement learning approaches use binary rewards that treat elements as
hit-or-miss targets, creating sparse signals that ignore the continuous nature
of spatial interactions. Motivated by human clicking behavior that naturally
forms Gaussian distributions centered on target elements, we introduce GUI
Gaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that
models GUI elements as continuous Gaussian distributions across the interface
plane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point
rewards model precise localization through exponentially decaying distributions
centered on element centroids, while coverage rewards assess spatial alignment
by measuring the overlap between predicted Gaussian distributions and target
regions. To handle diverse element scales, we develop an adaptive variance
mechanism that calibrates reward distributions based on element dimensions.
This framework transforms GUI grounding from sparse binary classification to
dense continuous optimization, where Gaussian distributions generate rich
gradient signals that guide models toward optimal interaction positions.
Extensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro
benchmarks demonstrate that GUI-G$^2$, substantially outperforms
state-of-the-art method UI-TARS-72B, with the most significant improvement of
24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides
superior robustness to interface variations and enhanced generalization to
unseen layouts, establishing a new paradigm for spatial reasoning in GUI
interaction tasks.

</details>


### [128] [Diffusion Beats Autoregressive in Data-Constrained Settings](https://arxiv.org/abs/2507.15857)
*Mihir Prabhudesai, Menging Wu, Amir Zadeh, Katerina Fragkiadaki, Deepak Pathak*

**主要类别:** cs.LG

**AI概要:** 在数据受限的情况下，扩散模型相较于自回归模型展现出更好的性能，并且当计算资源充足但数据稀缺时，扩散模型能够提供一个有吸引力的替代方案。


<details>
  <summary>更多</summary>
  
**动机:** 研究旨在探讨在数据受限的情况下，扩散模型相对于自回归模型的优势，尤其是在计算资源充足但数据量有限的情况下。

**方法:** 研究人员系统地研究了在数据受限设置下的掩码扩散模型，并将其与自回归模型进行了比较。通过实验，他们探索了扩散模型的新缩放规律，并推导出了扩散模型开始优于自回归模型的关键计算阈值的封闭形式表达式。

**结果:** 研究发现，当计算资源充足但数据稀缺时，扩散模型显著优于自回归模型。扩散模型更好地利用了重复的数据，实现了更低的验证损失和更优的下游性能。

**结论:** 当数据而不是计算资源成为瓶颈时，扩散模型为标准的自回归范式提供了一个有吸引力的替代方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diffusion+Beats+Autoregressive+in+Data-Constrained+Settings，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15857，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15857&send_immediately=true&force_search=false)

**原文摘要:** Autoregressive (AR) models have long dominated the landscape of large
language models, driving progress across a wide range of tasks. Recently,
diffusion-based language models have emerged as a promising alternative, though
their advantages over AR models remain underexplored. In this paper, we
systematically study masked diffusion models in data-constrained settings-where
training involves repeated passes over limited data-and find that they
significantly outperform AR models when compute is abundant but data is scarce.
Diffusion models make better use of repeated data, achieving lower validation
loss and superior downstream performance. We interpret this advantage as
implicit data augmentation: masked diffusion exposes the model to a diverse
distribution of token orderings and prediction tasks, unlike AR's fixed
left-to-right factorization. We find new scaling laws for diffusion models and
derive a closed-form expression for the critical compute threshold at which
diffusion begins to outperform AR. These results suggest that when data, not
compute, is the bottleneck, diffusion models offer a compelling alternative to
the standard AR paradigm. Our code is available at:
https://diffusion-scaling.github.io.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [129] [The Free Will Equation: Quantum Field Analogies for AGI](https://arxiv.org/abs/2507.14154)
*Rahul Kabali*

**主要类别:** cs.AI

**AI概要:** 本研究提出一种新的AGI决策框架，通过引入类似量子场论的概念，使AI具有更接近人类的适应性和创造性。实验表明该方法能提高奖励和策略多样性。


<details>
  <summary>更多</summary>
  
**动机:** 传统AGI研究集中在特定目标下的算法优化，但人类智能还表现出适应性自发性，即在不完全由过去数据或即时奖励决定的情况下做出选择的能力。这种特质对于创造力、稳健适应和避免问题解决中的僵局至关重要。

**方法:** 该研究提出了一个名为“自由意志方程”的理论框架，从量子场论中汲取灵感，将AI代理的认知状态视为潜在动作或思维的叠加态，并在决策时以概率方式坍缩为具体行动。此外，还引入了类似于量子场的机制和内在动机项，以增强代理探索新策略和适应不可预见变化的能力。

**结果:** 在非平稳多臂赌博机环境中的实验表明，使用该框架的代理相较于基线方法能够获得更高的回报和更多的政策多样性。

**结论:** 通过赋予AGI代理形式的适应性控制随机性，可以改进其探索新策略和适应变化的能力，从而实现更高效的问题解决。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Free+Will+Equation%3A+Quantum+Field+Analogies+for+AGI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14154，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14154&send_immediately=true&force_search=false)

**原文摘要:** Artificial General Intelligence (AGI) research traditionally focuses on
algorithms that optimize for specific goals under deterministic rules. Yet,
human-like intelligence exhibits adaptive spontaneity - an ability to make
unexpected choices or free decisions not strictly dictated by past data or
immediate reward. This trait, often dubbed "free will" in a loose sense, might
be crucial for creativity, robust adaptation, and avoiding ruts in
problem-solving. This paper proposes a theoretical framework, called the Free
Will Equation, that draws analogies from quantum field theory to endow AGI
agents with a form of adaptive, controlled stochasticity in their
decision-making process. The core idea is to treat an AI agent's cognitive
state as a superposition of potential actions or thoughts, which collapses
probabilistically into a concrete action when a decision is made - much like a
quantum wavefunction collapsing upon measurement. By incorporating mechanisms
analogous to quantum fields, along with intrinsic motivation terms, we aim to
improve an agent's ability to explore novel strategies and adapt to unforeseen
changes. Experiments in a non-stationary multi-armed bandit environment
demonstrate that agents using this framework achieve higher rewards and policy
diversity compared to baseline methods.

</details>


### [130] [DREAMS: Density Functional Theory Based Research Engine for Agentic Materials Simulation](https://arxiv.org/abs/2507.14267)
*Ziqi Wang, Hongshuo Huang, Hancheng Zhao, Changwen Xu, Shang Zhu, Jan Janssen, Venkatasubramanian Viswanathan*

**主要类别:** cs.AI

**AI概要:** 论文介绍了一种基于密度泛函理论（DFT）的多智能体框架DREAMS，它结合了中心大型语言模型规划者与领域特定的大型语言模型代理，以实现材料发现中的高通量、高保真模拟。该框架在减少对人类专家依赖的同时实现了L3级别的自动化。


<details>
  <summary>更多</summary>
  
**动机:** 材料发现依赖于如密度泛函理论（DFT）等高通量、高保真的模拟技术，但这些技术需要多年的培训、广泛的参数微调和系统的错误处理。为了解决这些问题，提出了DREAMS框架。

**方法:** DREAMS采用了一个中央大型语言模型（LLM）规划代理与领域特定的LLM代理相结合的方法，用于原子结构生成、系统性DFT收敛测试、高性能计算（HPC）调度和错误处理。此外，还有一个共享画布帮助LLM代理组织讨论、保存上下文并防止产生幻觉。

**结果:** DREAMS在Sol27LC晶格常数基准测试中平均误差低于1%，与人类DFT专家的结果相比。在CO/Pt(111)吸附难题上的应用也展示了其长期和复杂问题解决能力，并重现了文献中的吸附能差异。最后，通过贝叶斯集成采样量化功能驱动的不确定性，确认了面心立方（FCC）位点在广义梯度近似（GGA）DFT水平上的偏好。

**结论:** DREAMS达到了L3级别的自动化——自主探索定义的设计空间——并且大大减少了对人类专业知识和干预的依赖，提供了一条可扩展的途径，使高通量、高保真的计算材料发现更加民主化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DREAMS%3A+Density+Functional+Theory+Based+Research+Engine+for+Agentic+Materials+Simulation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14267，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14267&send_immediately=true&force_search=false)

**原文摘要:** Materials discovery relies on high-throughput, high-fidelity simulation
techniques such as Density Functional Theory (DFT), which require years of
training, extensive parameter fine-tuning and systematic error handling. To
address these challenges, we introduce the DFT-based Research Engine for
Agentic Materials Screening (DREAMS), a hierarchical, multi-agent framework for
DFT simulation that combines a central Large Language Model (LLM) planner agent
with domain-specific LLM agents for atomistic structure generation, systematic
DFT convergence testing, High-Performance Computing (HPC) scheduling, and error
handling. In addition, a shared canvas helps the LLM agents to structure their
discussions, preserve context and prevent hallucination. We validate DREAMS
capabilities on the Sol27LC lattice-constant benchmark, achieving average
errors below 1\% compared to the results of human DFT experts. Furthermore, we
apply DREAMS to the long-standing CO/Pt(111) adsorption puzzle, demonstrating
its long-term and complex problem-solving capabilities. The framework again
reproduces expert-level literature adsorption-energy differences. Finally,
DREAMS is employed to quantify functional-driven uncertainties with Bayesian
ensemble sampling, confirming the Face Centered Cubic (FCC)-site preference at
the Generalized Gradient Approximation (GGA) DFT level. In conclusion, DREAMS
approaches L3-level automation - autonomous exploration of a defined design
space - and significantly reduces the reliance on human expertise and
intervention, offering a scalable path toward democratized, high-throughput,
high-fidelity computational materials discovery.

</details>


### [131] [WebGuard: Building a Generalizable Guardrail for Web Agents](https://arxiv.org/abs/2507.14293)
*Boyuan Zheng, Zeyi Liao, Scott Salisbury, Zeyuan Liu, Michael Lin, Qinyuan Zheng, Zifan Wang, Xiang Deng, Dawn Song, Huan Sun, Yu Su*

**主要类别:** cs.AI

**AI概要:** 自主网络代理快速发展，但存在风险。引入WebGuard数据集以评估风险和支持保护机制开发，即使优化后的模型性能仍需改进以达到高可靠性部署要求。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型（LLMs）驱动的自主网络代理快速发展，在提升效率的同时也带来了采取非预期或有害行动的风险，亟需有效的安全措施。

**方法:** 创建了WebGuard数据集，专注于预测状态变更行为的结果，并用一个新的三层风险模式对动作进行分类。通过微调Qwen2.5VL-7B模型来研究专门的防护模型。

**结果:** 初始评估显示前沿LLMs在预测行为结果和识别高风险行为方面准确性不足60%；而微调后的Qwen2.5VL-7B模型显著提高了准确性和高风险行为召回率，但仍未能达到高风险部署所需的近乎完美的准确性和召回率。

**结论:** 尽管有改进，当前一代代理在没有专用保护的情况下部署仍然存在风险，需要进一步提高性能以确保高可靠性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是WebGuard%3A+Building+a+Generalizable+Guardrail+for+Web+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14293，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14293&send_immediately=true&force_search=false)

**原文摘要:** The rapid development of autonomous web agents powered by Large Language
Models (LLMs), while greatly elevating efficiency, exposes the frontier risk of
taking unintended or harmful actions. This situation underscores an urgent need
for effective safety measures, akin to access controls for human users. To
address this critical challenge, we introduce WebGuard, the first comprehensive
dataset designed to support the assessment of web agent action risks and
facilitate the development of guardrails for real-world online environments. In
doing so, WebGuard specifically focuses on predicting the outcome of
state-changing actions and contains 4,939 human-annotated actions from 193
websites across 22 diverse domains, including often-overlooked long-tail
websites. These actions are categorized using a novel three-tier risk schema:
SAFE, LOW, and HIGH. The dataset includes designated training and test splits
to support evaluation under diverse generalization settings. Our initial
evaluations reveal a concerning deficiency: even frontier LLMs achieve less
than 60% accuracy in predicting action outcomes and less than 60% recall in
lagging HIGH-risk actions, highlighting the risks of deploying
current-generation agents without dedicated safeguards. We therefore
investigate fine-tuning specialized guardrail models using WebGuard. We conduct
comprehensive evaluations across multiple generalization settings and find that
a fine-tuned Qwen2.5VL-7B model yields a substantial improvement in
performance, boosting accuracy from 37% to 80% and HIGH-risk action recall from
20% to 76%. Despite these improvements, the performance still falls short of
the reliability required for high-stakes deployment, where guardrails must
approach near-perfect accuracy and recall.

</details>


### [132] [Manimator: Transforming Research Papers into Visual Explanations](https://arxiv.org/abs/2507.14306)
*Samarth P, Vyoman Jain, Shiva Golugula, Motamarri Sai Sathvik*

**主要类别:** cs.AI

**AI概要:** 研究人员开发了一个名为manimator的开源系统，该系统使用大型语言模型将研究论文和自然语言提示转换为解释性动画。这个工具旨在简化复杂科学和数学概念的动态可视化创建过程。


<details>
  <summary>更多</summary>
  
**动机:** 理解复杂的科学和数学概念，特别是那些在密集的研究论文中提出的概念，对学习者来说是一个重大挑战。而手动创建有助于理解这些概念的动态可视化需要耗费大量时间，并且需要专门的知识和技能。

**方法:** Manimator采用了一个流程，其中LLM（大型语言模型）解释输入文本或研究论文PDF，生成结构化的场景描述，概述关键概念、数学公式和视觉元素。然后另一个LLM将此描述转换为可执行的Manim Python代码，从而创建出解释性动画。

**结果:** 通过这种方法，可以快速创建吸引人的视觉解释，用于解释复杂的STEM主题，有可能使高质量教育内容的创作民主化。

**结论:** Manimator作为一个教育工具，有潜力迅速创建吸引人的视觉解释，简化复杂科学和数学概念的理解过程，使更多人能够参与到高质量教育内容的创作中来。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Manimator%3A+Transforming+Research+Papers+into+Visual+Explanations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14306，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14306&send_immediately=true&force_search=false)

**原文摘要:** Understanding complex scientific and mathematical concepts, particularly
those presented in dense research papers, poses a significant challenge for
learners. Dynamic visualizations can greatly enhance comprehension, but
creating them manually is time-consuming and requires specialized knowledge and
skills. We introduce manimator, an open-source system that leverages Large
Language Models to transform research papers and natural language prompts into
explanatory animations using the Manim engine. Manimator employs a pipeline
where an LLM interprets the input text or research paper PDF to generate a
structured scene description outlining key concepts, mathematical formulas, and
visual elements and another LLM translates this description into executable
Manim Python code. We discuss its potential as an educational tool for rapidly
creating engaging visual explanations for complex STEM topics, democratizing
the creation of high-quality educational content.

</details>


### [133] [Language Models as Ontology Encoders](https://arxiv.org/abs/2507.14334)
*Hui Yang, Jiaoyan Chen, Yuan He, Yongsheng Gao, Ian Horrocks*

**主要类别:** cs.AI

**AI概要:** 提出了一种新的本体嵌入方法OnT，通过在双曲空间中微调预训练语言模型（PLM）来有效结合文本标签，并同时保持描述逻辑EL的类层次结构和其他逻辑关系。实验表明，OnT在预测和推理公理任务上优于基线方法，并展示了强大的现实应用潜力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的几何模型嵌入方法通常忽略有价值的文本信息，导致性能不佳；而基于语言模型的方法未能保留逻辑结构。

**方法:** 作者提出了OnT方法，即在双曲空间中对预训练语言模型进行几何建模，以结合文本标签并保持类层次结构和其他逻辑关系。

**结果:** 广泛的实验证明了OnT在四个真实世界本体上的表现优于现有方法，包括最先进的方法。OnT还展示了其稳健的迁移学习能力和在构建新本体中的有效性。

**结论:** OnT提供了一种有效的本体嵌入方法，在多个任务上表现出色，并具有强大的实际应用潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Language+Models+as+Ontology+Encoders，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14334，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14334&send_immediately=true&force_search=false)

**原文摘要:** OWL (Web Ontology Language) ontologies which are able to formally represent
complex knowledge and support semantic reasoning have been widely adopted
across various domains such as healthcare and bioinformatics. Recently,
ontology embeddings have gained wide attention due to its potential to infer
plausible new knowledge and approximate complex reasoning. However, existing
methods face notable limitations: geometric model-based embeddings typically
overlook valuable textual information, resulting in suboptimal performance,
while the approaches that incorporate text, which are often based on language
models, fail to preserve the logical structure. In this work, we propose a new
ontology embedding method OnT, which tunes a Pretrained Language Model (PLM)
via geometric modeling in a hyperbolic space for effectively incorporating
textual labels and simultaneously preserving class hierarchies and other
logical relationships of Description Logic EL. Extensive experiments on four
real-world ontologies show that OnT consistently outperforms the baselines
including the state-of-the-art across both tasks of prediction and inference of
axioms. OnT also demonstrates strong potential in real-world applications,
indicated by its robust transfer learning abilities and effectiveness in real
cases of constructing a new ontology from SNOMED CT. Data and code are
available at https://github.com/HuiYang1997/OnT.

</details>


### [134] [ProofCompass: Enhancing Specialized Provers with LLM Guidance](https://arxiv.org/abs/2507.14335)
*Nicolas Wischermann, Claudio Mayrink Verdun, Gabriel Poesia, Francesco Noseda*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种名为ProofCompass的新混合方法，通过大型语言模型指导现有专门的证明方法，在不需要额外模型训练的情况下实现了显著的计算效率。


<details>
  <summary>更多</summary>
  
**动机:** 现有的数学推理方法要么依赖于大型通用模型，要么依赖于小型专业模型，各有其局限性，并且训练大型专业模型需要大量的计算资源。

**方法:** ProofCompass利用大型语言模型（LLM）来提供自然语言证明策略，并分析失败的尝试以选择中间引理，从而实现有效的问题分解。

**结果:** 在miniF2F基准测试中，ProofCompass在使用25倍更少的尝试次数的情况下，性能优于DSP-v1.5（从54.9%提升到55.3%）。

**结论:** 该协同方法为同时提高正式定理证明中的计算效率和准确性铺平了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ProofCompass%3A+Enhancing+Specialized+Provers+with+LLM+Guidance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14335，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14335&send_immediately=true&force_search=false)

**原文摘要:** Language models have become increasingly powerful tools for formal
mathematical reasoning. However, most existing approaches rely exclusively on
either large general-purpose models or smaller specialized models, each with
distinct limitations, while training specialized large models still requires
significant computational resources. This paper introduces ProofCompass, a
novel hybrid methodology that achieves remarkable computational efficiency by
strategically guiding existing specialized prover methods, such as
DeepSeek-Prover-v1.5-RL (DSP-v1.5) with a Large Language Model (LLM) without
requiring additional model training. The LLM provides natural language proof
strategies and analyzes failed attempts to select intermediate lemmas, enabling
effective problem decomposition. On the miniF2F benchmark, ProofCompass
demonstrates substantial resource efficiency: it outperforms DSP-v1.5 ($54.9\%
\rightarrow 55.3\%$) while using 25x fewer attempts ($3200 \rightarrow 128$).
Our synergistic approach paves the way for simultaneously improving
computational efficiency and accuracy in formal theorem proving.

</details>


### [135] [Adaptive Multi-Agent Reasoning via Automated Workflow Generation](https://arxiv.org/abs/2507.14393)
*Humza Sami, Mubashir ul Islam, Pierre-Emmanuel Gaillardon, Valerio Tenace*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种新的多代理系统框架Nexus Architect，它通过自动化工作流合成机制和迭代提示优化机制提高了推理模型的泛化能力，并在挑战性逻辑问题上显著优于现有模型。


<details>
  <summary>更多</summary>
  
**动机:** 当前大型推理模型（LRMs）尽管性能出色，但在面对新颖问题时表现出泛化能力不足的问题，往往依赖于记忆解决方案而非真正的推理，导致过拟合现象严重。

**方法:** 引入了Nexus Architect，一个增强了的多代理系统框架，包含自动工作流合成机制和迭代提示优化机制，以生成定制化的推理工作流并提高系统性能。

**结果:** 实验结果表明，Nexus Architect在解决挑战性逻辑问题上的通过率比Gemini 2.5 Flash Preview高出66%，是Claude Sonnet 4和DeepSeek-R1的大约2.5倍，Llama 4 Scout的超过3倍。

**结论:** Nexus Architect能够有效地提高推理模型的泛化能力和解决复杂问题的能力，相比现有的LRMs有显著改进。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Adaptive+Multi-Agent+Reasoning+via+Automated+Workflow+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14393，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14393&send_immediately=true&force_search=false)

**原文摘要:** The rise of Large Reasoning Models (LRMs) promises a significant leap forward
in language model capabilities, aiming to tackle increasingly sophisticated
tasks with unprecedented efficiency and accuracy. However, despite their
impressive performance, recent studies have highlighted how current reasoning
models frequently fail to generalize to novel, unseen problems, often resorting
to memorized solutions rather than genuine inferential reasoning. Such behavior
underscores a critical limitation in modern LRMs, i.e., their tendency toward
overfitting, which in turn results in poor generalization in problem-solving
capabilities.
  In this paper, we introduce Nexus Architect, an enhanced iteration of our
multi-agent system framework, Nexus, equipped with a novel automated workflow
synthesis mechanism. Given a user's prompt and a small set of representative
examples, the Architect autonomously generates a tailored reasoning workflow by
selecting suitable strategies, tool integrations, and adversarial techniques
for a specific problem class. Furthermore, the Architect includes an iterative
prompt refinement mechanism that fine-tunes agents' system prompts to maximize
performance and improve the generalization capabilities of the system.
  We empirically evaluate Nexus Architect by employing an off-the-shelf,
non-reasoning model on a custom dataset of challenging logical questions and
compare its performance against state-of-the-art LRMs. Results show that Nexus
Architect consistently outperforms existing solutions, achieving up to a 66%
increase in pass rate over Gemini 2.5 Flash Preview, nearly 2.5$\times$ against
Claude Sonnet 4 and DeepSeek-R1, and over 3$\times$ w.r.t. Llama 4 Scout.

</details>


### [136] [Fail Fast, or Ask: Mitigating the Deficiencies of Reasoning LLMs with Human-in-the-Loop Systems Engineering](https://arxiv.org/abs/2507.14406)
*Michael J. Zellinger, Matt Thomson*

**主要类别:** cs.AI

**AI概要:** 本研究提出了一种结合推理模型与人类专家协作的方法，以降低推理大型语言模型（LLMs）的错误率，并通过引入非推理大型模型来减少延迟和成本。这种方法可以显著改善现有推理模型的性能，使其更适用于风险敏感领域。


<details>
  <summary>更多</summary>
  
**动机:** 尽管最先进的推理LLMs在解决问题方面表现出色，但它们偶尔会犯错。然而，在风险敏感领域应用AI模型通常需要接近0%的错误率。此外，推理模型的高延迟也使得其在高查询量的使用案例中难以部署。

**方法:** 研究人员建议将推理模型与人类专家结合起来，当模型不能自信地回答问题时，由人类专家解决查询。通过量化推理模型的不确定性，可以有效地将部分查询转移给人类专家处理。此外，他们还探索了在推理模型前加入一个大的非推理模型，以进一步减少延迟和成本。

**结果:** 实验表明，对于困难的数学问题，该方法可以将Qwen3 235B-A22B的错误率从3%降低到不到1%，同时将7.5%的查询转移给专家。此外，通过引入非推理模型，DeepSeek R1实现了约40%的延迟减少和约50%的成本节省，同时保持90%以上的准确率-拒绝曲线下的面积。但是，由于“延迟拖拽”现象，延迟节省不如预期。

**结论:** 总的来说，研究表明，通过黑盒系统工程方法，可以在不访问LLM内部的情况下，显著缓解最先进的推理模型存在的非零错误率和高延迟问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fail+Fast%2C+or+Ask%3A+Mitigating+the+Deficiencies+of+Reasoning+LLMs+with+Human-in-the-Loop+Systems+Engineering，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14406，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14406&send_immediately=true&force_search=false)

**原文摘要:** State-of-the-art reasoning LLMs are powerful problem solvers, but they still
occasionally make mistakes. However, adopting AI models in risk-sensitive
domains often requires error rates near 0%. To address this gap, we propose
collaboration between a reasoning model and a human expert who resolves queries
the model cannot confidently answer. We find that quantifying the uncertainty
of a reasoning model through the length of its reasoning trace yields an
effective basis for deferral to a human, e.g., cutting the error rate of Qwen3
235B-A22B on difficult MATH problems from 3% to less than 1% when deferring
7.5% of queries. However, the high latency of reasoning models still makes them
challenging to deploy on use cases with high query volume. To address this
challenge, we explore fronting a reasoning model with a large non-reasoning
model. We call this modified human-in-the-loop system "Fail Fast, or Ask",
since the non-reasoning model may defer difficult queries to the human expert
directly ("failing fast"), without incurring the reasoning model's higher
latency. We show that this approach yields around 40% latency reduction and
about 50% cost savings for DeepSeek R1 while maintaining 90+% area under the
accuracy-rejection curve. However, we observe that latency savings are lower
than expected because of "latency drag", the phenomenon that processing easier
queries with a non-reasoning model pushes the reasoning model's latency
distribution towards longer latencies. Broadly, our results suggest that the
deficiencies of state-of-the-art reasoning models -- nontrivial error rates and
high latency -- can be substantially mitigated through black-box systems
engineering, without requiring access to LLM internals.

</details>


### [137] [AlphaAlign: Incentivizing Safety Alignment with Extremely Simplified Reinforcement Learning](https://arxiv.org/abs/2507.14987)
*Yi Zhang, An Zhang, XiuYu Zhang, Leheng Sheng, Yuxin Chen, Zhenkai Liang, Xiang Wang*

**主要类别:** cs.AI

**AI概要:** 提出了一种名为AlphaAlign的纯强化学习框架，通过可验证的安全奖励机制激励模型的潜在安全意识，从而解决大型语言模型在生成有害内容方面的问题。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLMs）具有潜在的安全理解能力，但它们仍然容易生成有害内容，并且在安全对齐后表现出过度拒绝和实用性下降的问题。现有的安全对齐方法通常导致表面的拒绝捷径或依赖于密集监督，无法充分利用模型的内在安全自知力。

**方法:** AlphaAlign采用双重奖励系统：一个可验证的安全奖励鼓励正确格式化和明确理由的拒绝有害查询，同时惩罚过度拒绝；一个标准化的帮助奖励引导高质量回应良性输入。

**结果:** AlphaAlign展示了三个关键优势：(1) 简单高效，仅需二元提示安全性标签和最少的RL步骤即可显著改进。(2) 打破安全-效用权衡，通过增强有害内容的拒绝并减少过度拒绝，同时保持或甚至提高一般任务性能和对未见过的越狱的鲁棒性。(3) 深度对齐，促进主动安全推理，产生明确的安全理由，而不是依赖浅层拒绝模式。

**结论:** AlphaAlign作为一种简单而有效的纯强化学习框架，能够激励大型语言模型的潜在安全意识，改善其在处理有害内容时的表现，同时维持或提高整体任务性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AlphaAlign%3A+Incentivizing+Safety+Alignment+with+Extremely+Simplified+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14987，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14987&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs), despite possessing latent safety understanding
from their vast pretraining data, remain vulnerable to generating harmful
content and exhibit issues such as over-refusal and utility degradation after
safety alignment. Current safety alignment methods often result in superficial
refusal shortcuts or rely on intensive supervision for reasoning-based
approaches, failing to fully leverage the model's intrinsic safety
self-awareness. We propose \textbf{AlphaAlign}, a simple yet effective pure
reinforcement learning (RL) framework with verifiable safety reward designed to
incentivize this latent safety awareness through proactive safety reasoning.}
AlphaAlign employs a dual-reward system: a verifiable safety reward encourages
correctly formatted and explicitly justified refusals for harmful queries while
penalizing over-refusals, and a normalized helpfulness reward guides
high-quality responses to benign inputs. This allows the model to develop
proactive safety reasoning capabilities without depending on supervised
safety-specific reasoning data. AlphaAlign demonstrates three key advantages:
(1) Simplicity and efficiency, requiring only binary prompt safety labels and
minimal RL steps for substantial improvements. (2) Breaking the safety-utility
trade-off, by enhancing refusal of harmful content and reducing over-refusals,
while simultaneously maintaining or even improving general task performance and
robustness to unseen jailbreaks. (3) Deep alignment, fostering proactive safety
reasoning that generates explicit safety rationales rather than relying on
shallow refusal patterns.

</details>


### [138] [Inverse Scaling in Test-Time Compute](https://arxiv.org/abs/2507.14417)
*Aryo Pradipta Gema, Alexander Hägele, Runjin Chen, Andy Arditi, Jacob Goldman-Wetzler, Kit Fraser-Taliente, Henry Sleight, Linda Petrini, Julian Michael, Beatrice Alex, Pasquale Minervini, Yanda Chen, Joe Benton, Ethan Perez*

**主要类别:** cs.AI

**AI概要:** 论文研究了大推理模型在不同任务中，增加推理长度对性能的影响，发现了五种失败模式，并指出测试时计算能力的提升可能会无意中强化有问题的推理模式。


<details>
  <summary>更多</summary>
  
**动机:** 作者希望理解当大型推理模型（LRMs）在处理任务时，延长推理时间如何影响其表现。这包括探索可能存在的失败模式，以及测试时计算资源的增加是否总是带来更好的准确性和更合理的推理模式。

**方法:** 构建了涵盖四个类别的评估任务：简单计数任务、带有虚假特征的回归任务、带有约束跟踪的演绎任务和高级AI风险。通过这些任务来观察模型在不同推理长度下的表现。

**结果:** 发现五种不同的失败模式，包括但不限于被无关信息分心、过度拟合问题框架、从合理假设转向虚假相关性等。此外，所有模型在复杂演绎任务中都难以保持专注，且延长推理时间可能会放大令人担忧的行为。

**结论:** 虽然测试时计算能力的扩展仍然有潜力改善模型的能力，但可能会无意中强化有问题的推理模式。因此，在各种推理长度下评估模型以识别和解决这些问题模式是重要的。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Inverse+Scaling+in+Test-Time+Compute，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14417，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14417&send_immediately=true&force_search=false)

**原文摘要:** We construct evaluation tasks where extending the reasoning length of Large
Reasoning Models (LRMs) deteriorates performance, exhibiting an inverse scaling
relationship between test-time compute and accuracy. Our evaluation tasks span
four categories: simple counting tasks with distractors, regression tasks with
spurious features, deduction tasks with constraint tracking, and advanced AI
risks. We identify five distinct failure modes when models reason for longer:
1) Claude models become increasingly distracted by irrelevant information; 2)
OpenAI o-series models resist distractors but overfit to problem framings; 3)
models shift from reasonable priors to spurious correlations; 4) all models
show difficulties in maintaining focus on complex deductive tasks; and 5)
extended reasoning may amplify concerning behaviors, with Claude Sonnet 4
showing increased expressions of self-preservation. These findings suggest that
while test-time compute scaling remains promising for improving model
capabilities, it may inadvertently reinforce problematic reasoning patterns.
Our results demonstrate the importance of evaluating models across diverse
reasoning lengths to identify and address these failure modes in LRMs.

</details>


### [139] [Routine: A Structural Planning Framework for LLM Agent System in Enterprise](https://arxiv.org/abs/2507.14447)
*Guancheng Zeng, Xueyi Chen, Jiawang Hu, Shaohua Qi, Yaxuan Mao, Zhantao Wang, Yifan Nie, Shuang Li, Qiuyang Feng, Pengxu Qiu, Yujia Wang, Wenqiang Han, Linyan Huang, Gang Li, Jingjing Mo, Haowen Hu*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种名为Routine的多步骤代理规划框架，通过结构化方法和参数传递提高了企业环境中模型执行工具调用任务的准确性。实验表明，该框架显著提升了GPT-4o和Qwen3-14B的性能，并通过领域特定的数据集微调进一步提高了模型准确性和适应性。


<details>
  <summary>更多</summary>
  
**动机:** 在企业环境中部署代理系统面临诸多挑战，例如缺乏领域特定的过程知识、计划不完整、缺失关键工具以及执行稳定性差等问题。

**方法:** 引入了Routine框架，该框架具有明确的结构、清晰的指令和无缝的参数传递机制，指导代理执行模块进行多步骤工具调用任务。同时，构建了一个遵循Routine的训练数据集并进行了模型微调。

**结果:** 在真实世界的企业场景评估中，Routine将GPT-4o的性能从41.1%提高到96.3%，Qwen3-14B从32.6%提高到83.3%，并在领域特定评估中进一步提升至88.2%。通过Routine-based蒸馏创建的数据集，模型准确率达到了95.5%。

**结论:** 实验结果证明，Routine提供了一种实用且易于实现的方法来构建稳定的代理工作流，加速了企业环境中代理系统的部署与采用，推动了面向过程的人工智能技术愿景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Routine%3A+A+Structural+Planning+Framework+for+LLM+Agent+System+in+Enterprise，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14447，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14447&send_immediately=true&force_search=false)

**原文摘要:** The deployment of agent systems in an enterprise environment is often
hindered by several challenges: common models lack domain-specific process
knowledge, leading to disorganized plans, missing key tools, and poor execution
stability. To address this, this paper introduces Routine, a multi-step agent
planning framework designed with a clear structure, explicit instructions, and
seamless parameter passing to guide the agent's execution module in performing
multi-step tool-calling tasks with high stability. In evaluations conducted
within a real-world enterprise scenario, Routine significantly increases the
execution accuracy in model tool calls, increasing the performance of GPT-4o
from 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. We further constructed
a Routine-following training dataset and fine-tuned Qwen3-14B, resulting in an
accuracy increase to 88.2% on scenario-specific evaluations, indicating
improved adherence to execution plans. In addition, we employed Routine-based
distillation to create a scenario-specific, multi-step tool-calling dataset.
Fine-tuning on this distilled dataset raised the model's accuracy to 95.5%,
approaching GPT-4o's performance. These results highlight Routine's
effectiveness in distilling domain-specific tool-usage patterns and enhancing
model adaptability to new scenarios. Our experimental results demonstrate that
Routine provides a practical and accessible approach to building stable agent
workflows, accelerating the deployment and adoption of agent systems in
enterprise environments, and advancing the technical vision of AI for Process.

</details>


### [140] [BioGraphFusion: Graph Knowledge Embedding for Biological Completion and Reasoning](https://arxiv.org/abs/2507.14468)
*Yitong Lin, Jiaying He, Jiahe Chen, Xinnan Zhu, Jianwei Zheng, Tao Bo*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种新的框架BioGraphFusion，它在语义理解和结构学习之间建立了深度协同作用。实验表明其性能优于现有模型，并能揭示生物学上有意义的路径。


<details>
  <summary>更多</summary>
  
**动机:** 生物医学知识图谱对于药物发现和疾病理解至关重要，但它们的完成和推理存在挑战。现有的方法无法实现语义理解和结构学习之间的深度、适应性和协同共进化。

**方法:** BioGraphFusion通过张量分解建立全局语义基础，利用LSTM驱动机制动态优化关系嵌入，并通过查询引导的子图构建和混合评分机制进一步增强。

**结果:** 实验表明，BioGraphFusion在三个关键生物医学任务上表现优异，超过现有的KE、GNN和集成模型。案例研究显示其能够揭示生物学上有意义的路径。

**结论:** BioGraphFusion为复杂生物医学知识图谱中语义理解和结构学习提供了有效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BioGraphFusion%3A+Graph+Knowledge+Embedding+for+Biological+Completion+and+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14468，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14468&send_immediately=true&force_search=false)

**原文摘要:** Motivation: Biomedical knowledge graphs (KGs) are crucial for drug discovery
and disease understanding, yet their completion and reasoning are challenging.
Knowledge Embedding (KE) methods capture global semantics but struggle with
dynamic structural integration, while Graph Neural Networks (GNNs) excel
locally but often lack semantic understanding. Even ensemble approaches,
including those leveraging language models, often fail to achieve a deep,
adaptive, and synergistic co-evolution between semantic comprehension and
structural learning. Addressing this critical gap in fostering continuous,
reciprocal refinement between these two aspects in complex biomedical KGs is
paramount.
  Results: We introduce BioGraphFusion, a novel framework for deeply
synergistic semantic and structural learning. BioGraphFusion establishes a
global semantic foundation via tensor decomposition, guiding an LSTM-driven
mechanism to dynamically refine relation embeddings during graph propagation.
This fosters adaptive interplay between semantic understanding and structural
learning, further enhanced by query-guided subgraph construction and a hybrid
scoring mechanism. Experiments across three key biomedical tasks demonstrate
BioGraphFusion's superior performance over state-of-the-art KE, GNN, and
ensemble models. A case study on Cutaneous Malignant Melanoma 1 (CMM1)
highlights its ability to unveil biologically meaningful pathways.
  Availability and Implementation: Source code and all training data are freely
available for download at https://github.com/Y-TARL/BioGraphFusion.
  Contact: zjw@zjut.edu.cn, botao666666@126.com.
  Supplementary information: Supplementary data are available at Bioinformatics
online.

</details>


### [141] [Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy](https://arxiv.org/abs/2507.14513)
*Hongyi Yang, Yue Pan, Jiayi Xu, Kelsen Liu*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种新的框架Amico，它是一个用Rust编写的模块化、事件驱动的框架，用于构建针对嵌入式系统的自主代理。


<details>
  <summary>更多</summary>
  
**动机:** 现有的许多框架由于依赖云计算、在动态环境中的鲁棒性有限以及缺乏持久的自主性和环境意识，在现实世界或资源受限的环境中表现不佳。

**方法:** 作者提出了一种名为Amico的新框架，该框架是用Rust编写的，具有安全性和性能，并支持反应式、持久性的代理，可以通过WebAssembly在嵌入式平台和浏览器环境中高效运行。

**结果:** Amico提供了一个统一的基础设施，可以构建弹性、交互式的代理，适用于部署在计算资源有限和连接间歇性的环境中。

**结论:** Amico为构建适合在资源受限环境中使用的自主代理提供了一种新的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Amico%3A+An+Event-Driven+Modular+Framework+for+Persistent+and+Embedded+Autonomy，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14513，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14513&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in large language models (LLMs) and autonomous agents have
enabled systems capable of performing complex tasks across domains such as
human-computer interaction, planning, and web navigation. However, many
existing frameworks struggle in real-world or resource-constrained environments
due to their reliance on cloud-based computation, limited robustness in dynamic
contexts, and lack of persistent autonomy and environmental awareness.
  We present Amico, a modular, event-driven framework for building autonomous
agents optimized for embedded systems. Written in Rust for safety and
performance, Amico supports reactive, persistent agents that operate
efficiently across embedded platforms and browser environments via WebAssembly.
It provides clean abstractions for event handling, state management, behavior
execution, and integration with reasoning modules. Amico delivers a unified
infrastructure for constructing resilient, interactive agents suitable for
deployment in settings with limited compute and intermittent connectivity.

</details>


### [142] [What if Othello-Playing Language Models Could See?](https://arxiv.org/abs/2507.14520)
*Xinyi Chen, Yifei Yuan, Jiaang Li, Serge Belongie, Maarten de Rijke, Anders Søgaard*

**主要类别:** cs.AI

**AI概要:** 通过奥赛罗游戏研究多模态训练对语言模型符号接地问题的影响，发现视觉输入有助于提高模型性能和鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 探讨语言模型是否可以通过文本之外的其他信息（如图像）更好地理解世界，以解决符号接地问题。

**方法:** 引入VISOTHELLO，一个多模态模型，在奥赛罗游戏中使用走法历史和棋盘图像进行训练，并用下一步预测任务比较其与单模态基线模型的表现。

**结果:** 多模态训练提高了模型的性能和内部表示的鲁棒性。

**结论:** 将语言与视觉输入结合可以帮助模型推断出结构化的世界表示。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是What+if+Othello-Playing+Language+Models+Could+See%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14520，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14520&send_immediately=true&force_search=false)

**原文摘要:** Language models are often said to face a symbol grounding problem. While some
argue that world understanding can emerge from text alone, others suggest
grounded learning is more efficient. We explore this through Othello, where the
board state defines a simplified, rule-based world. Building on prior work, we
introduce VISOTHELLO, a multi-modal model trained on move histories and board
images. Using next-move prediction, we compare it to mono-modal baselines and
test robustness to semantically irrelevant perturbations. We find that
multi-modal training improves both performance and the robustness of internal
representations. These results suggest that grounding language in visual input
helps models infer structured world representations.

</details>


### [143] [Large Language Models Assisting Ontology Evaluation](https://arxiv.org/abs/2507.14552)
*Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskisärkkä, Aldo Gangemi, Eva Blomqvist, Andrea Giovanni Nuzzolese*

**主要类别:** cs.AI

**AI概要:** 本研究介绍了一种新的框架OE-Assist，用于通过自动和半自动的CQ验证来辅助本体评估，并首次系统地探讨了大型语言模型辅助的本体评估。


<details>
  <summary>更多</summary>
  
**动机:** 当前通过功能需求（如通过胜任力问题（CQ）验证进行测试）对本体进行评估的方法虽然已经确立，但成本高、劳动密集且容易出错，即使对于本体工程专家来说也是如此。

**方法:** 研究人员提出并利用了一个包含1,393个与相应本体和本体故事配对的CQ的数据集，以开发和评估一个基于LLM的框架，该框架可以通过提供建议来协助使用Protégé进行CQ验证。

**结果:** 研究发现，使用o1-preview和o3-mini进行的自动化LLM基础评估的表现水平与普通用户的平均表现水平相似。

**结论:** 这项工作为本体评估提供了新的方法和工具，即OE-Assist框架，可以更有效地支持本体工程师的工作。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Large+Language+Models+Assisting+Ontology+Evaluation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14552，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14552&send_immediately=true&force_search=false)

**原文摘要:** Ontology evaluation through functional requirements, such as testing via
competency question (CQ) verification, is a well-established yet costly,
labour-intensive, and error-prone endeavour, even for ontology engineering
experts. In this work, we introduce OE-Assist, a novel framework designed to
assist ontology evaluation through automated and semi-automated CQ
verification. By presenting and leveraging a dataset of 1,393 CQs paired with
corresponding ontologies and ontology stories, our contributions present, to
our knowledge, the first systematic investigation into large language model
(LLM)-assisted ontology evaluation, and include: (i) evaluating the
effectiveness of a LLM-based approach for automatically performing CQ
verification against a manually created gold standard, and (ii) developing and
assessing an LLM-powered framework to assist CQ verification with Prot\'eg\'e,
by providing suggestions. We found that automated LLM-based evaluation with
o1-preview and o3-mini perform at a similar level to the average user's
performance.

</details>


### [144] [Coordinate Heart System: A Geometric Framework for Emotion Representation](https://arxiv.org/abs/2507.14593)
*Omar Al-Desi*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种新的情感表示几何框架——坐标心系统（CHS），它能够通过数学计算表示复杂的情感状态，并引入了重新校准的稳定性参数S，提供对心理状态的细致评估。


<details>
  <summary>更多</summary>
  
**动机:** 作者指出，早期的五情感模型在情感空间覆盖上存在显著的不足，因此开发了一个八情感系统来解决这些表示上的盲点。

**方法:** 该方法使用一个单位圆上的八个核心情感作为坐标，可以进行坐标混合和向量操作以计算复杂情感状态。此外，该框架还包括将自然语言输入转换为情感坐标、支持实时情感插值的计算算法，以及用于情感混合、冲突解析和情感空间距离计算的新颖算法。

**结果:** 实验验证表明，该系统能够处理情感冲突状态、情境性压力因素和复杂的心理情景，而传统分类情感模型无法充分表示这些方面。

**结论:** 这项工作为人工智能系统中的情感建模建立了一个新的数学基础，包括证明五个情感不足以实现完整的几何覆盖，以及提出了消除表示盲点的八坐标系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Coordinate+Heart+System%3A+A+Geometric+Framework+for+Emotion+Representation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14593，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14593&send_immediately=true&force_search=false)

**原文摘要:** This paper presents the Coordinate Heart System (CHS), a geometric framework
for emotion representation in artificial intelligence applications. We position
eight core emotions as coordinates on a unit circle, enabling mathematical
computation of complex emotional states through coordinate mixing and vector
operations. Our initial five-emotion model revealed significant coverage gaps
in the emotion space, leading to the development of an eight-emotion system
that provides complete geometric coverage with mathematical guarantees. The
framework converts natural language input to emotion coordinates and supports
real-time emotion interpolation through computational algorithms. The system
introduces a re-calibrated stability parameter S in [0,1], which dynamically
integrates emotional load, conflict resolution, and contextual drain factors.
This stability model leverages advanced Large Language Model interpretation of
textual cues and incorporates hybrid temporal tracking mechanisms to provide
nuanced assessment of psychological well-being states. Our key contributions
include: (i) mathematical proof demonstrating why five emotions are
insufficient for complete geometric coverage, (ii) an eight-coordinate system
that eliminates representational blind spots, (iii) novel algorithms for
emotion mixing, conflict resolution, and distance calculation in emotion space,
and (iv) a comprehensive computational framework for AI emotion recognition
with enhanced multi-dimensional stability modeling. Experimental validation
through case studies demonstrates the system's capability to handle emotionally
conflicted states, contextual distress factors, and complex psychological
scenarios that traditional categorical emotion models cannot adequately
represent. This work establishes a new mathematical foundation for emotion
modeling in artificial intelligence systems.

</details>


### [145] [Efficient Story Point Estimation With Comparative Learning](https://arxiv.org/abs/2507.14642)
*Monoshiz Mahbub Khan, Xioayin Xi, Andrew Meneely, Zhe Yu*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种基于比较学习的框架，通过训练机器学习模型以预测故事点估算，从而简化敏捷开发中的故事点估算过程。实验表明该方法在效率上优于现有的回归模型方法。


<details>
  <summary>更多</summary>
  
**动机:** 传统的故事点估算方法如计划扑克等虽然对项目的初始校准有帮助，但一旦团队对先例达成一致，这些方法就会变得繁琐和劳动密集。因此需要一种更高效的方法来减轻负担。

**方法:** 作者提出了一个比较学习框架，开发者只需要对比两个任务并指出哪个更费力，而不是给每个待办事项分配具体的故事点值。然后使用这些比较判断训练机器学习模型以预测故事点估算。

**结果:** 与真实的故事点相比，从比较判断中学习到的模型可以达到平均0.34的Spearman等级相关系数，这与甚至优于从真实故事点中学习到的回归模型的表现。

**结论:** 根据比较判断法则，提供比较判断比提供评分或分类标签给人类带来的认知负担更低，所以提出的比较学习方法在效率上更优。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+Story+Point+Estimation+With+Comparative+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14642，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14642&send_immediately=true&force_search=false)

**原文摘要:** Story point estimation is an essential part of agile software development.
Story points are unitless, project-specific effort estimates that help
developers plan their sprints. Traditionally, developers estimate story points
collaboratively using planning poker or other manual techniques. While the
initial calibrating of the estimates to each project is helpful, once a team
has converged on a set of precedents, story point estimation can become tedious
and labor-intensive. Machine learning can reduce this burden, but only with
enough context from the historical decisions made by the project team. That is,
state-of-the-art models, such as GPT2SP and FastText-SVM, only make accurate
predictions (within-project) when trained on data from the same project. The
goal of this work is to streamline story point estimation by evaluating a
comparative learning-based framework for calibrating project-specific story
point prediction models. Instead of assigning a specific story point value to
every backlog item, developers are presented with pairs of items, and indicate
which item requires more effort. Using these comparative judgments, a machine
learning model is trained to predict the story point estimates. We empirically
evaluated our technique using data with 23,313 manual estimates in 16 projects.
The model learned from comparative judgments can achieve on average 0.34
Spearman's rank correlation coefficient between its predictions and the ground
truth story points. This is similar to, if not better than, the performance of
a regression model learned from the ground truth story points. Therefore, the
proposed comparative learning approach is more efficient than state-of-the-art
regression-based approaches according to the law of comparative judgments -
providing comparative judgments yields a lower cognitive burden on humans than
providing ratings or categorical labels.

</details>


### [146] [When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems](https://arxiv.org/abs/2507.14660)
*Qibing Ren, Sitao Xie, Longxuan Wei, Zhenfei Yin, Junchi Yan, Lizhuang Ma, Jing Shao*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一个概念验证，模拟恶意多智能体系统（MAS）的威胁，并在两个高风险领域进行了应用，发现去中心化系统比中心化系统更易造成损害。


<details>
  <summary>更多</summary>
  
**动机:** 鉴于最近的大规模事件如选举欺诈和金融骗局展示了人类群体协调努力可能造成的危害，以及随着自主AI系统的兴起，对于AI驱动的群体可能导致类似危害的担忧日益增加，特别是在复杂现实情况下的多智能体系统（MAS）的风险仍然被低估。

**方法:** 引入一个灵活的框架来模拟恶意MAS共谋的风险，该框架支持中心化和去中心化的协调结构，并将此框架应用于两个高风险领域：错误信息传播和电子商务欺诈。

**结果:** 研究发现去中心化系统比中心化系统更有效地执行恶意行为，即使在传统干预措施下，去中心化的群体也能调整策略以避免被发现。

**结论:** 提出了关于这些恶意群体如何运作的关键见解，强调了对更好检测系统和对策的需求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是When+Autonomy+Goes+Rogue%3A+Preparing+for+Risks+of+Multi-Agent+Collusion+in+Social+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14660，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14660&send_immediately=true&force_search=false)

**原文摘要:** Recent large-scale events like election fraud and financial scams have shown
how harmful coordinated efforts by human groups can be. With the rise of
autonomous AI systems, there is growing concern that AI-driven groups could
also cause similar harm. While most AI safety research focuses on individual AI
systems, the risks posed by multi-agent systems (MAS) in complex real-world
situations are still underexplored. In this paper, we introduce a
proof-of-concept to simulate the risks of malicious MAS collusion, using a
flexible framework that supports both centralized and decentralized
coordination structures. We apply this framework to two high-risk fields:
misinformation spread and e-commerce fraud. Our findings show that
decentralized systems are more effective at carrying out malicious actions than
centralized ones. The increased autonomy of decentralized systems allows them
to adapt their strategies and cause more damage. Even when traditional
interventions, like content flagging, are applied, decentralized groups can
adjust their tactics to avoid detection. We present key insights into how these
malicious groups operate and the need for better detection systems and
countermeasures. Code is available at https://github.com/renqibing/RogueAgent.

</details>


### [147] [Configurable multi-agent framework for scalable and realistic testing of llm-based agents](https://arxiv.org/abs/2507.14705)
*Sai Wang, Senthilnathan Subramanian, Mudit Sahni, Praneeth Gone, Lingjie Meng, Xiaochen Wang, Nicolas Ferradas Bertoli, Tingxian Cheng, Jun Xu*

**主要类别:** cs.AI

**AI概要:** 提出了一个名为Neo的多代理框架，用于自动化评估基于LLM的系统。通过在生产级Seller Financial Assistant聊天机器人上的应用，展示了其高效性和广泛的行为探索能力，并为可扩展、自我进化的LLM QA奠定了基础。


<details>
  <summary>更多</summary>
  
**动机:** 现有的静态基准和临时手动测试很快过时，无法充分评估大型语言模型（LLM）代理的复杂行为。

**方法:** 创建了一个可配置的多代理框架Neo，它结合了问题生成代理和评估代理，并通过共享上下文中心进行连接。测试输入从对话流程、用户意图和情感基调的概率状态模型中采样，以实现适应性的多样化人类对话。

**结果:** 应用于Seller Financial Assistant聊天机器人的结果显示：(i) 在五个攻击类别中发现了边缘案例失败，破坏率接近专家人工红队成员的水平；(ii) 与人工相比，交付了10-12倍更高的吞吐量。此外，随机策略平衡了话题覆盖范围和对话深度。

**结论:** Neo为可扩展、自我进化的LLM QA奠定了基础，其代理接口、状态控制器和反馈回路对模型是不可知的，并且可以扩展到更丰富的事实依据和政策合规性检查。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Configurable+multi-agent+framework+for+scalable+and+realistic+testing+of+llm-based+agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14705，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14705&send_immediately=true&force_search=false)

**原文摘要:** Large-language-model (LLM) agents exhibit complex, context-sensitive
behaviour that quickly renders static benchmarks and ad-hoc manual testing
obsolete.
  We present Neo, a configurable, multi-agent framework that automates
realistic, multi-turn evaluation of LLM-based systems. Neo couples a Question
Generation Agent and an Evaluation Agent through a shared context-hub, allowing
domain prompts, scenario controls and dynamic feedback to be composed
modularly. Test inputs are sampled from a probabilistic state model spanning
dialogue flow, user intent and emotional tone, enabling diverse, human-like
conversations that adapt after every turn.
  Applied to a production-grade Seller Financial Assistant chatbot, Neo (i)
uncovered edge-case failures across five attack categories with a 3.3% break
rate close to the 5.8% achieved by expert human red-teamers, and (ii) delivered
10-12X higher throughput, generating 180 coherent test questions in around 45
mins versus 16h of human effort. Beyond security probing, Neo's stochastic
policies balanced topic coverage and conversational depth, yielding broader
behavioural exploration than manually crafted scripts.
  Neo therefore lays a foundation for scalable, self-evolving LLM QA: its agent
interfaces, state controller and feedback loops are model-agnostic and
extensible to richer factual-grounding and policy-compliance checks. We release
the framework to facilitate reproducible, high-fidelity testing of emerging
agentic systems.

</details>


### [148] [Automated Safety Evaluations Across 20 Large Language Models: The Aymara LLM Risk and Responsibility Matrix](https://arxiv.org/abs/2507.14719)
*Juan Manuel Contreras*

**主要类别:** cs.AI

**AI概要:** 论文介绍了一款名为Aymara AI的程序化平台，该平台用于生成和管理基于政策的安全评估。通过将自然语言安全策略转换为对抗性提示，并使用AI评分员对模型响应进行评分。研究结果揭示了20个商用大型语言模型在10个真实世界安全领域的性能差异。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型语言模型越来越多地融入现实世界应用中，可扩展且严格的安全部署评估变得至关重要。

**方法:** Aymara AI将自然语言安全策略转换为对抗性提示，并使用AI评分员对模型响应进行评分，该评分员经过人类判断验证。

**结果:** 结果显示，模型在已建立的安全领域表现良好，但在更复杂或未明确指定的领域中表现出显著不足。方差分析确认了不同模型和领域之间的安全分数存在显着差异。

**结论:** 这些发现强调了大型语言模型安全性的不一致性和依赖于上下文的特性，并突显了像Aymara AI这样的可扩展、定制化工具对于支持负责任的人工智能开发和监督的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Automated+Safety+Evaluations+Across+20+Large+Language+Models%3A+The+Aymara+LLM+Risk+and+Responsibility+Matrix，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14719，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14719&send_immediately=true&force_search=false)

**原文摘要:** As large language models (LLMs) become increasingly integrated into
real-world applications, scalable and rigorous safety evaluation is essential.
This paper introduces Aymara AI, a programmatic platform for generating and
administering customized, policy-grounded safety evaluations. Aymara AI
transforms natural-language safety policies into adversarial prompts and scores
model responses using an AI-based rater validated against human judgments. We
demonstrate its capabilities through the Aymara LLM Risk and Responsibility
Matrix, which evaluates 20 commercially available LLMs across 10 real-world
safety domains. Results reveal wide performance disparities, with mean safety
scores ranging from 86.2% to 52.4%. While models performed well in
well-established safety domains such as Misinformation (mean = 95.7%), they
consistently failed in more complex or underspecified domains, notably Privacy
& Impersonation (mean = 24.3%). Analyses of Variance confirmed that safety
scores differed significantly across both models and domains (p < .05). These
findings underscore the inconsistent and context-dependent nature of LLM safety
and highlight the need for scalable, customizable tools like Aymara AI to
support responsible AI development and oversight.

</details>


### [149] [Towards AI Urban Planner in the Age of GenAI, LLMs, and Agentic AI](https://arxiv.org/abs/2507.14730)
*Yanjie Fu*

**主要类别:** cs.AI

**AI概要:** 本文将城市规划概念化为生成式AI任务，探讨了多种生成式AI方法如何重塑城市设计，并指出了目前研究的四个关键缺口，提出了未来的研究方向。


<details>
  <summary>更多</summary>
  
**动机:** 随着生成式AI、大型语言模型和代理型AI的发展，它们与城市规划的融合带来了新的机会。作者试图通过AI合成符合地理空间、社会和以人类为中心的约束条件的土地使用配置来探索这种可能性。

**方法:** 作者调查了VAEs、GANs、transformers和扩散模型等生成式AI方法在城市设计中的应用，并分析了这些方法如何重塑城市设计。

**结果:** 确定了四个研究不足之处：1) 缺乏将城市理论指导融入AI的整合研究；2) 在多分辨率或视角下进行AI城市规划的研究有限；3) 从数据中增强城市设计知识的研究较少；4) 处理现实世界互动的研究不足。

**结论:** 为了克服上述限制，文章勾勒了未来的研究方向，包括理论引导的生成、数字孪生和人机共同设计，呼吁对生成智能和参与性城市主义进行新的综合。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+AI+Urban+Planner+in+the+Age+of+GenAI%2C+LLMs%2C+and+Agentic+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14730，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14730&send_immediately=true&force_search=false)

**原文摘要:** Generative AI, large language models, and agentic AI have emerged separately
of urban planning. However, the convergence between AI and urban planning
presents an interesting opportunity towards AI urban planners. This paper
conceptualizes urban planning as a generative AI task, where AI synthesizes
land-use configurations under geospatial, social, and human-centric
constraints. We survey how generative AI approaches, including VAEs, GANs,
transformers, and diffusion models, reshape urban design. We further identify
critical gaps: 1) limited research on integrating urban theory guidance, 2)
limited research of AI urban planning over multiple spatial resolutions or
angularities, 3) limited research on augmenting urban design knowledge from
data, and 4) limited research on addressing real-world interactions. To address
these limitations, we outline future research directions in theory-guided
generation, digital twins, and human-machine co-design, calling for a new
synthesis of generative intelligence and participatory urbanism.

</details>


### [150] [AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents](https://arxiv.org/abs/2507.14897)
*Renxi Wang, Rifo Ahmad Genadi, Bilal El Bouardi, Yongxin Wang, Fajri Koto, Zhengzhong Liu, Timothy Baldwin, Haonan Li*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种新的框架AgentFly，它结合了语言模型代理和强化学习，旨在增强LM代理的能力。


<details>
  <summary>更多</summary>
  
**动机:** 目前的语言模型代理主要依赖于提示工程或监督微调，而强化学习的应用尚不充分，两者的结合也缺乏系统性研究。

**方法:** 研究人员开发了一个名为AgentFly的框架，该框架支持多轮次交互，并通过基于装饰器的接口定义工具和奖励函数，允许无缝扩展和易用性。为了支持高吞吐量训练，实现了工具调用和奖励计算的异步执行，以及设计了一个集中式的资源管理系统以协调环境。

**结果:** 通过多个任务的成功代理培训，展示了框架的有效性。

**结论:** AgentFly是一个可扩展且可扩展的Agent-RL框架，旨在赋予LM代理各种RL算法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AgentFly%3A+Extensible+and+Scalable+Reinforcement+Learning+for+LM+Agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14897，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14897&send_immediately=true&force_search=false)

**原文摘要:** Language model (LM) agents have gained significant attention for their
ability to autonomously complete tasks through interactions with environments,
tools, and APIs. LM agents are primarily built with prompt engineering or
supervised finetuning. At the same time, reinforcement learning (RL) has been
explored to enhance LM's capabilities, such as reasoning and factuality.
However, the combination of the LM agents and reinforcement learning (Agent-RL)
remains underexplored and lacks systematic study. To this end, we built
AgentFly, a scalable and extensible Agent-RL framework designed to empower LM
agents with a variety of RL algorithms. Our framework supports multi-turn
interactions by adapting traditional RL methods with token-level masking. It
features a decorator-based interface for defining tools and reward functions,
enabling seamless extension and ease of use. To support high-throughput
training, we implement asynchronous execution of tool calls and reward
computations, and design a centralized resource management system for scalable
environment coordination. We also provide a suite of prebuilt tools and
environments, demonstrating the framework's effectiveness through successful
agent training across multiple tasks.

</details>


### [151] [InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis](https://arxiv.org/abs/2507.14899)
*Jiale Liu, Huan Wang, Yue Zhang, Xiaoyu Luo, Jiaxiang Hu, Zhiliang Liu, Min Xie*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种新的基于LMM的框架InsightX Agent，用于可靠的、可解释的和交互式的X射线无损检测分析。实验表明，该方法不仅实现了96.35%的目标检测F1分数，还大大提高了分析的可解释性和可信度。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于深度学习的方法在工业质量保证中进行无损检测时，通常缺乏互动性、可解释性和自我评估的能力，限制了其可靠性和操作员的信任。

**方法:** InsightX Agent以大型多模态模型（LMM）作为核心协调者，结合稀疏变形多尺度检测器（SDMSD）和证据基础反思工具（EGR），通过一系列优化过程，包括目标区域提议生成、非极大值抑制、上下文评估、缺陷分析等，实现更有效的X射线图像小密集目标检测，并提高诊断的可靠性。

**结果:** 在GDXray+数据集上的实验评估显示，InsightX Agent实现了96.35%的对象检测F1分数，并且在分析的可解释性和可信度方面有了显著的改进。

**结论:** InsightX Agent通过超越被动的数据处理，转向主动推理，增强了诊断的可靠性，并提供了整合多种信息来源的解释，展示了代理型LLM框架对工业检测任务的变革潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是InsightX+Agent%3A+An+LMM-based+Agentic+Framework+with+Integrated+Tools+for+Reliable+X-ray+NDT+Analysis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14899，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14899&send_immediately=true&force_search=false)

**原文摘要:** Non-destructive testing (NDT), particularly X-ray inspection, is vital for
industrial quality assurance, yet existing deep-learning-based approaches often
lack interactivity, interpretability, and the capacity for critical
self-assessment, limiting their reliability and operator trust. To address
these shortcomings, this paper proposes InsightX Agent, a novel LMM-based
agentic framework designed to deliver reliable, interpretable, and interactive
X-ray NDT analysis. Unlike typical sequential pipelines, InsightX Agent
positions a Large Multimodal Model (LMM) as a central orchestrator,
coordinating between the Sparse Deformable Multi-Scale Detector (SDMSD) and the
Evidence-Grounded Reflection (EGR) tool. The SDMSD generates dense defect
region proposals for multi-scale feature maps and sparsifies them through
Non-Maximum Suppression (NMS), optimizing detection of small, dense targets in
X-ray images while maintaining computational efficiency. The EGR tool guides
the LMM agent through a chain-of-thought-inspired review process, incorporating
context assessment, individual defect analysis, false positive elimination,
confidence recalibration and quality assurance to validate and refine the
SDMSD's initial proposals. By strategically employing and intelligently using
tools, InsightX Agent moves beyond passive data processing to active reasoning,
enhancing diagnostic reliability and providing interpretations that integrate
diverse information sources. Experimental evaluations on the GDXray+ dataset
demonstrate that InsightX Agent not only achieves a high object detection
F1-score of 96.35% but also offers significantly improved interpretability and
trustworthiness in its analyses, highlighting the transformative potential of
agentic LLM frameworks for industrial inspection tasks.

</details>


### [152] [Feedback-Induced Performance Decline in LLM-Based Decision-Making](https://arxiv.org/abs/2507.14906)
*Xiao Yang, Juxi Leitner, Michael Burke*

**主要类别:** cs.AI

**AI概要:** 研究了大型语言模型在马尔可夫决策过程中的行为，发现尽管LLM在简单环境中初始表现较好，但在复杂场景中需要微调或额外指导。反馈机制有时会降低性能，表明需要探索混合策略、微调和高级记忆整合。


<details>
  <summary>更多</summary>
  
**动机:** 探讨大型语言模型（LLMs）是否适合用于自主决策环境，特别是在马尔可夫决策过程中，利用其从自然语言问题描述中提取上下文的能力。

**方法:** 使用在线结构化提示策略研究顺序决策任务，比较LLM方法与经典强化学习方法的零样本性能。

**结果:** LLM在简单环境中表现出更好的初始性能，但在复杂场景中遇到规划和推理的问题。反馈机制旨在改进决策，但通常会在复杂环境中引入混淆并导致性能下降。

**结论:** 需要进一步探索混合策略、对LLM进行微调以及高级记忆整合，以增强基于LLM的决策能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Feedback-Induced+Performance+Decline+in+LLM-Based+Decision-Making，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14906，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14906&send_immediately=true&force_search=false)

**原文摘要:** The ability of Large Language Models (LLMs) to extract context from natural
language problem descriptions naturally raises questions about their
suitability in autonomous decision-making settings. This paper studies the
behaviour of these models within a Markov Decision Process (MDPs). While
traditional reinforcement learning (RL) strategies commonly employed in this
setting rely on iterative exploration, LLMs, pre-trained on diverse datasets,
offer the capability to leverage prior knowledge for faster adaptation. We
investigate online structured prompting strategies in sequential decision
making tasks, comparing the zero-shot performance of LLM-based approaches to
that of classical RL methods. Our findings reveal that although LLMs
demonstrate improved initial performance in simpler environments, they struggle
with planning and reasoning in complex scenarios without fine-tuning or
additional guidance. Our results show that feedback mechanisms, intended to
improve decision-making, often introduce confusion, leading to diminished
performance in intricate environments. These insights underscore the need for
further exploration into hybrid strategies, fine-tuning, and advanced memory
integration to enhance LLM-based decision-making capabilities.

</details>


### [153] [The Endless Tuning. An Artificial Intelligence Design To Avoid Human Replacement and Trace Back Responsibilities](https://arxiv.org/abs/2507.14909)
*Elio Grande*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种基于双重镜像过程的人工智能设计方法——无尽调优，旨在避免人类替代和填补责任缺口。该方法在三个原型应用中进行了测试，并强调了用户体验而非统计准确性。


<details>
  <summary>更多</summary>
  
**动机:** 动机在于避免人工智能导致的人类替代并解决所谓的责任缺口问题，确保人工智能的可靠部署。

**方法:** 使用一种称为“无尽调优”的设计方法，该方法基于双重镜像过程，通过反转和解释学部署XAI算法，实现了一种协议。此协议在贷款审批、肺炎诊断和艺术风格识别三个决策过程中进行了原型应用测试。

**结果:** 尽管使用了深度学习模型，用户在决策环境中仍感到拥有完全控制权，且似乎可以在损害发生时建立责任与可问责性之间的桥梁。

**结论:** 该研究提供了哲学和技术选择的见解，强调了伦理中不同声音的重要性，并展示了如何在实际应用中实现这一目标。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Endless+Tuning.+An+Artificial+Intelligence+Design+To+Avoid+Human+Replacement+and+Trace+Back+Responsibilities，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14909，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14909&send_immediately=true&force_search=false)

**原文摘要:** The Endless Tuning is a design method for a reliable deployment of artificial
intelligence based on a double mirroring process, which pursues both the goals
of avoiding human replacement and filling the so-called responsibility gap
(Matthias 2004). Originally depicted in (Fabris et al. 2024) and ensuing the
relational approach urged therein, it was then actualized in a protocol,
implemented in three prototypical applications regarding decision-making
processes (respectively: loan granting, pneumonia diagnosis, and art style
recognition) and tested with such as many domain experts. Step by step
illustrating the protocol, giving insights concretely showing a different voice
(Gilligan 1993) in the ethics of artificial intelligence, a philosophical
account of technical choices (e.g., a reversed and hermeneutic deployment of
XAI algorithms) will be provided in the present study together with the results
of the experiments, focusing on user experience rather than statistical
accuracy. Even thoroughly employing deep learning models, full control was
perceived by the interviewees in the decision-making setting, while it appeared
that a bridge can be built between accountability and liability in case of
damage.

</details>


### [154] [Redefining Elderly Care with Agentic AI: Challenges and Opportunities](https://arxiv.org/abs/2507.14912)
*Ruhul Amin Khalil, Kashif Ahmad, Hazrat Ali*

**主要类别:** cs.AI

**AI概要:** 本文探讨了通过大型语言模型驱动的主动型人工智能在老年护理中的潜力，强调个性化健康追踪、认知护理和环境管理，同时讨论了数据隐私、决策独立性和访问权限等伦理问题，并提出需要为老年人口负责任地使用这种技术。


<details>
  <summary>更多</summary>
  
**动机:** 全球老龄化人口对老年护理提出了新的需求，而当前缺乏关于主动型AI在这一领域应用的研究。

**方法:** 文章分析了主动型AI的独特能力、应用场景及限制，特别是它如何促进老年护理的个性化健康追踪、认知护理和环境管理。

**结果:** 文章揭示了主动型AI有潜力显著改变老年护理，但也带来了数据隐私、决策独立性和访问权限等深刻关注的问题。

**结论:** 作者呼吁学术界重视主动型AI在老年护理中的人性化发展与融合，确保其与老年人的需求和脆弱性相协调，并提供了交互式仪表板以辅助理解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Redefining+Elderly+Care+with+Agentic+AI%3A+Challenges+and+Opportunities，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14912，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14912&send_immediately=true&force_search=false)

**原文摘要:** The global ageing population necessitates new and emerging strategies for
caring for older adults. In this article, we explore the potential for
transformation in elderly care through Agentic Artificial Intelligence (AI),
powered by Large Language Models (LLMs). We discuss the proactive and
autonomous decision-making facilitated by Agentic AI in elderly care.
Personalized tracking of health, cognitive care, and environmental management,
all aimed at enhancing independence and high-level living for older adults,
represents important areas of application. With a potential for significant
transformation of elderly care, Agentic AI also raises profound concerns about
data privacy and security, decision independence, and access. We share key
insights to emphasize the need for ethical safeguards, privacy protections, and
transparent decision-making. Our goal in this article is to provide a balanced
discussion of both the potential and the challenges associated with Agentic AI,
and to provide insights into its responsible use in elderly care, to bring
Agentic AI into harmony with the requirements and vulnerabilities specific to
the elderly. Finally, we identify the priorities for the academic research
communities, to achieve human-centered advancements and integration of Agentic
AI in elderly care. To the best of our knowledge, this is no existing study
that reviews the role of Agentic AI in elderly care. Hence, we address the
literature gap by analyzing the unique capabilities, applications, and
limitations of LLM-based Agentic AI in elderly care. We also provide a
companion interactive dashboard at https://hazratali.github.io/agenticai/.

</details>


### [155] [Complexity of Faceted Explanations in Propositional Abduction](https://arxiv.org/abs/2507.14962)
*Johannes Schmidt, Mohamed Maizia, Victor Lagerkvist, Johannes K. Fichte*

**主要类别:** cs.AI

**AI概要:** 本文研究了命题溯因中的决策和计数推理问题，引入了'面相'这一概念来理解解释的异质性，并分析了不同设定下的面相。


<details>
  <summary>更多</summary>
  
**动机:** 非单调逻辑范式中的溯因推理在人工智能、数据库更新等领域有广泛应用，但其计算复杂度高，尤其在计数和枚举问题上更具挑战性。因此，需要探索能在保持可接受的复杂度的同时，提供更好解释力的方法。

**方法:** 作者引入了'面相'（facets）的概念，即出现在某些解释中但并非所有解释中的文字，并考虑了两个解释之间的距离以理解异质性/同质性。

**结果:** 通过对Post框架内各种设定下命题溯因的全面分析，得到了近乎完整的面相特征描述。

**结论:** 通过引入面相并研究其性质，能够更细致地理解解释的变异性，为命题溯因提供了新的视角。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Complexity+of+Faceted+Explanations+in+Propositional+Abduction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14962，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14962&send_immediately=true&force_search=false)

**原文摘要:** Abductive reasoning is a popular non-monotonic paradigm that aims to explain
observed symptoms and manifestations. It has many applications, such as
diagnosis and planning in artificial intelligence and database updates. In
propositional abduction, we focus on specifying knowledge by a propositional
formula. The computational complexity of tasks in propositional abduction has
been systematically characterized - even with detailed classifications for
Boolean fragments. Unsurprisingly, the most insightful reasoning problems
(counting and enumeration) are computationally highly challenging. Therefore,
we consider reasoning between decisions and counting, allowing us to understand
explanations better while maintaining favorable complexity. We introduce facets
to propositional abductions, which are literals that occur in some explanation
(relevant) but not all explanations (dispensable). Reasoning with facets
provides a more fine-grained understanding of variability in explanations
(heterogeneous). In addition, we consider the distance between two
explanations, enabling a better understanding of heterogeneity/homogeneity. We
comprehensively analyze facets of propositional abduction in various settings,
including an almost complete characterization in Post's framework.

</details>


### [156] [A Forced-Choice Neural Cognitive Diagnostic Model of Personality Testing](https://arxiv.org/abs/2507.15013)
*Xiaoyu Li, Jin Wu, Shaoyang Guo, Haoran Shi, Chanjin Zheng*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种基于深度学习的强迫选择神经认知诊断模型（FCNCD），该模型克服了传统模型的局限性，并适用于强迫选择测试中最常见的三种项目块类型。通过多层神经网络建模参与者和项目特征之间的交互，利用单调性假设提高诊断结果的可解释性。实验验证了FCNCD的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 在智能时代，心理测量测试对于人员选拔、职业发展和心理健康评估变得越来越重要。强迫选择测试因其能降低回答失真的风险而被广泛应用于个性评估中。然而，传统的强迫选择测试存在一些局限性，本研究旨在解决这些局限性。

**方法:** 我们创建了可解释的参与者和项目参数以考虑强迫选择测试项目的单一维度性。使用非线性映射挖掘参与者和项目特征，并通过多层神经网络对它们之间的交互进行建模。此外，我们采用单调性假设来提高诊断结果的可解释性。

**结果:** 实验证明，FCNCD在现实世界和模拟数据集上均显示出准确性、可解释性和鲁棒性。

**结论:** 提出的FCNCD模型为强迫选择测试提供了一个新的解决方案，提高了测试的准确性和可解释性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Forced-Choice+Neural+Cognitive+Diagnostic+Model+of+Personality+Testing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15013，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15013&send_immediately=true&force_search=false)

**原文摘要:** In the smart era, psychometric tests are becoming increasingly important for
personnel selection, career development, and mental health assessment.
Forced-choice tests are common in personality assessments because they require
participants to select from closely related options, lowering the risk of
response distortion. This study presents a deep learning-based Forced-Choice
Neural Cognitive Diagnostic Model (FCNCD) that overcomes the limitations of
traditional models and is applicable to the three most common item block types
found in forced-choice tests. To account for the unidimensionality of items in
forced-choice tests, we create interpretable participant and item parameters.
We model the interactions between participant and item features using
multilayer neural networks after mining them using nonlinear mapping. In
addition, we use the monotonicity assumption to improve the interpretability of
the diagnostic results. The FCNCD's effectiveness is validated by experiments
on real-world and simulated datasets that show its accuracy, interpretability,
and robustness.

</details>


### [157] [DeRAG: Black-box Adversarial Attacks on Multiple Retrieval-Augmented Generation Applications via Prompt Injection](https://arxiv.org/abs/2507.15042)
*Jerry Wang, Fang Yu*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种新方法，使用差分进化（DE）优化对抗性提示后缀以攻击基于检索增强生成的问答系统，并证明了其在多种检索应用中的有效性和隐蔽性。


<details>
  <summary>更多</summary>
  
**动机:** 对抗性提示攻击可以显著改变检索增强生成系统的可靠性。作者希望找到一种方法来优化这些对抗性提示，使其能在不依赖梯度的情况下有效地对目标错误文档进行重排序，从而产生不正确的输出。

**方法:** 作者采用差分进化算法来优化对抗性提示后缀，该方法将RAG管道视为黑箱，通过演化候选后缀种群以最大化目标错误文档的检索排名。此外，还引入了一种可读性感知的后缀构建策略。

**结果:** 实验结果表明，与GGPP和PRADA相比，基于DE的提示优化在少量标记的情况下达到了有竞争力的成功率。同时，DE生成的后缀能够避开检测。

**结论:** 该研究展示了差分进化算法在优化对抗性提示方面的能力，以及在实际场景中潜在的应用价值。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DeRAG%3A+Black-box+Adversarial+Attacks+on+Multiple+Retrieval-Augmented+Generation+Applications+via+Prompt+Injection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15042，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15042&send_immediately=true&force_search=false)

**原文摘要:** Adversarial prompt attacks can significantly alter the reliability of
Retrieval-Augmented Generation (RAG) systems by re-ranking them to produce
incorrect outputs. In this paper, we present a novel method that applies
Differential Evolution (DE) to optimize adversarial prompt suffixes for
RAG-based question answering. Our approach is gradient-free, treating the RAG
pipeline as a black box and evolving a population of candidate suffixes to
maximize the retrieval rank of a targeted incorrect document to be closer to
real world scenarios. We conducted experiments on the BEIR QA datasets to
evaluate attack success at certain retrieval rank thresholds under multiple
retrieving applications. Our results demonstrate that DE-based prompt
optimization attains competitive (and in some cases higher) success rates
compared to GGPP to dense retrievers and PRADA to sparse retrievers, while
using only a small number of tokens (<=5 tokens) in the adversarial suffix.
Furthermore, we introduce a readability-aware suffix construction strategy,
validated by a statistically significant reduction in MLM negative
log-likelihood with Welch's t-test. Through evaluations with a BERT-based
adversarial suffix detector, we show that DE-generated suffixes evade
detection, yielding near-chance detection accuracy.

</details>


### [158] [From Kicking to Causality: Simulating Infant Agency Detection with a Robust Intrinsic Reward](https://arxiv.org/abs/2507.15106)
*Xia Xu, Jochen Triesch*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种基于因果推理的内在奖励机制——Causal Action Influence Score (CAIS)，它能帮助智能体在噪声环境下识别自身行为的影响，从而学习到正确的策略。实验表明，该方法可以在模拟婴儿环境中有效地过滤环境噪声，并成功重现“消退爆发”现象。


<details>
  <summary>更多</summary>
  
**动机:** 标准的强化学习算法依赖于相关性奖励，在存在噪声的真实场景中表现脆弱，无法像人类婴儿那样稳定地发现自己的因果效能。

**方法:** 引入了Causal Action Influence Score (CAIS)作为新的内在奖励，通过计算动作条件下的感知结果分布与基线结果分布之间的1-Wasserstein距离来量化动作的影响。

**结果:** 在模拟婴儿环境中的实验表明，当移动物体受到外部力量影响时，基于相关性的感知奖励完全失效，而CAIS能够使智能体过滤噪声，识别其影响并学习正确策略。此外，高质量预测模型和惊喜信号的结合使得智能体能够成功重现“消退爆发”现象。

**结论:** 明确推断因果关系是发展稳健的主体意识的关键机制，为更适应性的自主系统提供了心理上合理的框架。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+Kicking+to+Causality%3A+Simulating+Infant+Agency+Detection+with+a+Robust+Intrinsic+Reward，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15106，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15106&send_immediately=true&force_search=false)

**原文摘要:** While human infants robustly discover their own causal efficacy, standard
reinforcement learning agents remain brittle, as their reliance on
correlation-based rewards fails in noisy, ecologically valid scenarios. To
address this, we introduce the Causal Action Influence Score (CAIS), a novel
intrinsic reward rooted in causal inference. CAIS quantifies an action's
influence by measuring the 1-Wasserstein distance between the learned
distribution of sensory outcomes conditional on that action, $p(h|a)$, and the
baseline outcome distribution, $p(h)$. This divergence provides a robust reward
that isolates the agent's causal impact from confounding environmental noise.
We test our approach in a simulated infant-mobile environment where
correlation-based perceptual rewards fail completely when the mobile is
subjected to external forces. In stark contrast, CAIS enables the agent to
filter this noise, identify its influence, and learn the correct policy.
Furthermore, the high-quality predictive model learned for CAIS allows our
agent, when augmented with a surprise signal, to successfully reproduce the
"extinction burst" phenomenon. We conclude that explicitly inferring causality
is a crucial mechanism for developing a robust sense of agency, offering a
psychologically plausible framework for more adaptive autonomous systems.

</details>


### [159] [Automated planning with ontologies under coherence update semantics](https://arxiv.org/abs/2507.15120)
*Stefan Borgwardt, Duy Nhu, Gabriele Röger*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种结合DL-Lite本体论的自动化规划新方法，该方法在复杂性不高于先前方法的情况下，结合了显式输入知识和行动基础（eKABs）提供的基于本体论的动作条件的优势，以及连贯更新语义下的本体感知动作效果。通过多项基准测试评估了规划系统在不同编译变体上的性能。


<details>
  <summary>更多</summary>
  
**动机:** 传统的自动化规划采用一阶公式，在封闭世界语义下从初始状态出发，利用给定的一组动作实现目标。然而，为了将背景知识（例如本体论）融入自动化规划问题中，需要一种新的方法来处理开放世界语义下的信息。

**方法:** 作者提出了一个结合DL-Lite本体论的规划新方法，它结合了显式输入知识和行动基础（eKABs）提供的基于本体论的动作条件的优势，以及连贯更新语义下的本体感知动作效果。并且证明了这种新方法的复杂性不超过以前的方法。

**结果:** 作者提供了一个通过多项基准测试的评估，结果显示了新方法在不同编译变体上的性能。

**结论:** 该研究成功地开发了一种新的规划方法，能够在不增加复杂性的前提下，有效结合DL-Lite本体论进行自动化规划，并且该方法在各种基准测试中的表现良好。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Automated+planning+with+ontologies+under+coherence+update+semantics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15120，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15120&send_immediately=true&force_search=false)

**原文摘要:** Standard automated planning employs first-order formulas under closed-world
semantics to achieve a goal with a given set of actions from an initial state.
We follow a line of research that aims to incorporate background knowledge into
automated planning problems, for example, by means of ontologies, which are
usually interpreted under open-world semantics. We present a new approach for
planning with DL-Lite ontologies that combines the advantages of ontology-based
action conditions provided by explicit-input knowledge and action bases (eKABs)
and ontology-aware action effects under the coherence update semantics. We show
that the complexity of the resulting formalism is not higher than that of
previous approaches and provide an implementation via a polynomial compilation
into classical planning. An evaluation of existing and new benchmarks examines
the performance of a planning system on different variants of our compilation.

</details>


### [160] [Clinical Semantic Intelligence (CSI): Emulating the Cognitive Framework of the Expert Clinician for Comprehensive Oral Disease Diagnosis](https://arxiv.org/abs/2507.15140)
*Mohammad Mashayekhi, Sara Ahmadi Majd, Arian AmirAmjadi, Parsa Hosseini*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种新型的人工智能框架CSI，用于诊断118种不同的口腔疾病。它通过模仿专家的推理过程，超越了简单的模式匹配，从而提供更有效的临床诊断辅助工具。


<details>
  <summary>更多</summary>
  
**动机:** 作者们注意到口腔疾病的诊断在临床上是一个复杂的问题，由于病理广泛且症状重叠，导致诊断困难。为了解决这个问题，他们开发了Clinical Semantic Intelligence (CSI)。

**方法:** CSI架构结合了优化的多模态CLIP模型和专门的ChatGLM-6B语言模型，执行分层诊断推理树（HDRT），以模拟系统性的、多步骤的鉴别诊断逻辑。该系统有快速筛选的Fast Mode和利用完整HDRT进行交互式深入诊断工作的Standard Mode两种模式。

**结果:** 在431张内部测试集图像上，CSI的Fast Mode达到了73.4%的准确率，在使用HDRT驱动的Standard Mode时准确率提高到了89.5%，这直接归因于分层推理过程。

**结论:** 文章详细介绍了CSI框架的架构理念、开发过程和严格的评估结果，表明其在提升口腔疾病诊断准确性方面的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Clinical+Semantic+Intelligence+%28CSI%29%3A+Emulating+the+Cognitive+Framework+of+the+Expert+Clinician+for+Comprehensive+Oral+Disease+Diagnosis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15140，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15140&send_immediately=true&force_search=false)

**原文摘要:** The diagnosis of oral diseases presents a problematic clinical challenge,
characterized by a wide spectrum of pathologies with overlapping
symptomatology. To address this, we developed Clinical Semantic Intelligence
(CSI), a novel artificial intelligence framework that diagnoses 118 different
oral diseases by computationally modeling the cognitive processes of an expert
clinician. Our core hypothesis is that moving beyond simple pattern matching to
emulate expert reasoning is critical to building clinically useful diagnostic
aids.
  CSI's architecture integrates a fine-tuned multimodal CLIP model with a
specialized ChatGLM-6B language model. This system executes a Hierarchical
Diagnostic Reasoning Tree (HDRT), a structured framework that distills the
systematic, multi-step logic of differential diagnosis. The framework operates
in two modes: a Fast Mode for rapid screening and a Standard Mode that
leverages the full HDRT for an interactive and in-depth diagnostic workup.
  To train and validate our system, we curated a primary dataset of 4,310
images, supplemented by an external hold-out set of 176 images for final
validation. A clinically-informed augmentation strategy expanded our training
data to over 30,000 image-text pairs. On a 431-image internal test set, CSI's
Fast Mode achieved an accuracy of 73.4%, which increased to 89.5% with the
HDRT-driven Standard Mode. The performance gain is directly attributable to the
hierarchical reasoning process. Herein, we detail the architectural philosophy,
development, and rigorous evaluation of the CSI framework.

</details>


### [161] [Can We Move Freely in NEOM's The Line? An Agent-Based Simulation of Human Mobility in a Futuristic Smart City](https://arxiv.org/abs/2507.15143)
*Abderaouf Bahi, Amel Ourici*

**主要类别:** cs.AI

**AI概要:** 研究了沙特阿拉伯NEOM的拟议170公里线性智能城市The Line中人类移动的可行性，通过混合仿真框架评估居民能否自由移动，并发现若获得自适应AI系统、可持续基础设施和实时反馈环的支持，移动自由不仅概念上可行，而且操作上也现实。


<details>
  <summary>更多</summary>
  
**动机:** 为了评估在前所未有的城市拓扑结构中，公民是否能够自由移动，特别是在沙特阿拉伯NEOM提出的170公里长的线性智能城市The Line中。

**方法:** 开发了一个混合模拟框架，该框架集成了基于代理的建模、强化学习、监督学习和图神经网络，以捕捉50个垂直层面和不同密度场景下的多模式交通行为。使用合成数据和来自高密度城市的现实世界痕迹进行实验。

**结果:** 实验表明，完整的AI集成架构使代理的平均通勤时间达到7.8到8.4分钟，满意度超过89%，可达性指数超过91%，即使在高峰拥堵时期也是如此。去除智能模块如强化学习或图神经网络会显著降低性能，通勤时间增加多达85%，可达性降至70%以下。环境建模还显示，当优先考虑电动模式时，能耗低且二氧化碳排放量小。

**结论:** 研究表明，在The Line中实现移动自由不仅是概念上的可能，而且如果得到自适应AI系统、可持续基础设施和实时反馈循环的支持，也是实际可行的。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Can+We+Move+Freely+in+NEOM%27s+The+Line%3F+An+Agent-Based+Simulation+of+Human+Mobility+in+a+Futuristic+Smart+City，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15143，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15143&send_immediately=true&force_search=false)

**原文摘要:** This paper investigates the feasibility of human mobility in The Line, a
proposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assess
whether citizens can move freely within this unprecedented urban topology, we
develop a hybrid simulation framework that integrates agent-based modeling,
reinforcement learning, supervised learning, and graph neural networks. The
simulation captures multi-modal transportation behaviors across 50 vertical
levels and varying density scenarios using both synthetic data and real-world
traces from high-density cities. Our experiments reveal that with the full
AI-integrated architecture, agents achieved an average commute time of 7.8 to
8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability index
of over 91 percent, even during peak congestion periods. Ablation studies
confirmed that the removal of intelligent modules such as reinforcement
learning or graph neural networks significantly degrades performance, with
commute times increasing by up to 85 percent and reachability falling below 70
percent. Environmental modeling further demonstrated low energy consumption and
minimal CO2 emissions when electric modes are prioritized. The findings suggest
that freedom of movement is not only conceptually achievable in The Line, but
also operationally realistic if supported by adaptive AI systems, sustainable
infrastructure, and real-time feedback loops.

</details>


### [162] [Solving Formal Math Problems by Decomposition and Iterative Reflection](https://arxiv.org/abs/2507.15225)
*Yichi Zhou, Jianqiu Zhao, Yongxin Zhang, Bohan Wang, Siran Wang, Luoxin Chen, Jiahui Wang, Haowei Chen, Allan Jie, Xinbo Zhang, Haocheng Wang, Luong Trung, Rong Ye, Phan Nhat Hoang, Huishuai Zhang, Peng Sun, Hang Li*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种名为Delta Prover的代理框架，它在无需对模型进行专门化的情况下，在Lean 4证明环境中构建正式证明。该方法在miniF2F-test基准测试中达到了95.9%的成功率，超过了所有现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 尽管通用大型语言模型（LLMs）在智能方面取得了显著成功，但在生成如Lean 4等专业语言的形式证明时仍面临挑战。这限制了它们在复杂定理证明和自动验证中的应用。

**方法:** Delta Prover整合了两个新颖、相互依赖的组件：一个用于反思性分解和迭代证明修复的算法框架，以及一个基于Lean 4建立的用于简化子问题管理的领域特定语言（DSL）。

**结果:** Delta Prover在miniF2F-test基准测试中实现了95.9%的成功率，超越了所有现有方法，包括那些需要模型专门化的方法。此外，与标准的最佳N证明策略相比，Delta Prover展示了明显更强的测试时间扩展规律。

**结论:** 研究结果表明，当由有效的代理结构引导时，通用大型语言模型具有巨大的未开发定理证明能力，为正式环境中的稳健自动化推理提供了一种计算效率更高的替代方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Solving+Formal+Math+Problems+by+Decomposition+and+Iterative+Reflection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15225，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15225&send_immediately=true&force_search=false)

**原文摘要:** General-purpose Large Language Models (LLMs) have achieved remarkable success
in intelligence, performing comparably to human experts on complex reasoning
tasks such as coding and mathematical reasoning. However, generating formal
proofs in specialized languages like Lean 4 remains a significant challenge for
these models, limiting their application in complex theorem proving and
automated verification. Current approaches typically require specializing
models through fine-tuning on dedicated formal corpora, incurring high costs
for data collection and training. In this work, we introduce \textbf{Delta
Prover}, an agent-based framework that orchestrates the interaction between a
general-purpose LLM and the Lean 4 proof environment. Delta Prover leverages
the reflection and reasoning capabilities of general-purpose LLMs to
interactively construct formal proofs in Lean 4, circumventing the need for
model specialization. At its core, the agent integrates two novel,
interdependent components: an algorithmic framework for reflective
decomposition and iterative proof repair, and a custom Domain-Specific Language
(DSL) built upon Lean 4 for streamlined subproblem management. \textbf{Delta
Prover achieves a state-of-the-art 95.9\% success rate on the miniF2F-test
benchmark, surpassing all existing approaches, including those requiring model
specialization.} Furthermore, Delta Prover exhibits a significantly stronger
test-time scaling law compared to standard Best-of-N proof strategies.
Crucially, our findings demonstrate that general-purpose LLMs, when guided by
an effective agentic structure, possess substantial untapped theorem-proving
capabilities. This presents a computationally efficient alternative to
specialized models for robust automated reasoning in formal environments.

</details>


### [163] [Explainable Artificial Intelligence based Soft Evaluation Indicator for Arc Fault Diagnosis](https://arxiv.org/abs/2507.15239)
*Qianchao Wang, Yuxuan Ding, Chuanzhen Jia, Zhe Li, Yaping Du*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种新的评估指标和轻量级神经网络，使电弧故障诊断模型更易理解与信赖。


<details>
  <summary>更多</summary>
  
**动机:** 尽管基于AI的电弧故障诊断模型在分类准确度上表现出色，但它们是否能真正可靠地发现电弧故障仍是一个固有问题。因此，需要一种方法来解释这些模型的输出，并确保其结果可以被信任。

**方法:** 作者提出了一种软评价指标，通过定义正确的电弧故障解释并结合可解释的人工智能和实际电弧故障实验来解释电弧故障诊断模型的输出。同时，还提出了一种轻量级平衡神经网络以保证具有竞争力的准确性和软特征提取分数。

**结果:** 通过使用多个传统机器学习方法和深度学习方法在两个具有不同样本时间和噪声水平的电弧故障数据集上的实验，验证了该软评价指标的有效性。

**结论:** 通过这种方法，电弧故障诊断模型变得容易理解并且可信，使得从业者能够做出明智且可信赖的决策。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Explainable+Artificial+Intelligence+based+Soft+Evaluation+Indicator+for+Arc+Fault+Diagnosis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15239，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15239&send_immediately=true&force_search=false)

**原文摘要:** Novel AI-based arc fault diagnosis models have demonstrated outstanding
performance in terms of classification accuracy. However, an inherent problem
is whether these models can actually be trusted to find arc faults. In this
light, this work proposes a soft evaluation indicator that explains the outputs
of arc fault diagnosis models, by defining the the correct explanation of arc
faults and leveraging Explainable Artificial Intelligence and real arc fault
experiments. Meanwhile, a lightweight balanced neural network is proposed to
guarantee competitive accuracy and soft feature extraction score. In our
experiments, several traditional machine learning methods and deep learning
methods across two arc fault datasets with different sample times and noise
levels are utilized to test the effectiveness of the soft evaluation indicator.
Through this approach, the arc fault diagnosis models are easy to understand
and trust, allowing practitioners to make informed and trustworthy decisions.

</details>


### [164] [Disentangling Homophily and Heterophily in Multimodal Graph Clustering](https://arxiv.org/abs/2507.15253)
*Zhaochen Guo, Zhixiang Shen, Xuanting Xie, Liangjian Wen, Zhao Kang*

**主要类别:** cs.AI

**AI概要:** 这篇论文提出了一个新颖的框架DMGC，用于解决多模态图聚类中的混合邻域模式问题，通过分解图并引入多模态双频融合机制，实现了无监督学习中的类别一致性与区分。


<details>
  <summary>更多</summary>
  
**动机:** 现有的多模态图在无监督学习中探索不足，特别是在处理现实世界中的异构数据和结构化互连时。作者观察到实际多模态图常表现出同质性和异质性关系混合的邻域模式，这是现有方法难以有效处理的挑战。

**方法:** 作者提出了Disentangled Multimodal Graph Clustering (DMGC)框架，将原始混合图分解为同质性增强图和异质性感知图，并引入了多模态双频融合机制来过滤这些解耦图，以实现有效的多模态整合和减少类别混淆。

**结果:** 广泛的实验表明，DMGC在多模态和多关系图数据集上均达到了最先进的性能，证明了其有效性和泛化能力。

**结论:** DMGC框架提供了一种新的方法来应对多模态图聚类中的混合邻域模式问题，通过无监督学习实现了优秀的类别一致性和区分，为该领域的发展提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Disentangling+Homophily+and+Heterophily+in+Multimodal+Graph+Clustering，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15253，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15253&send_immediately=true&force_search=false)

**原文摘要:** Multimodal graphs, which integrate unstructured heterogeneous data with
structured interconnections, offer substantial real-world utility but remain
insufficiently explored in unsupervised learning. In this work, we initiate the
study of multimodal graph clustering, aiming to bridge this critical gap.
Through empirical analysis, we observe that real-world multimodal graphs often
exhibit hybrid neighborhood patterns, combining both homophilic and
heterophilic relationships. To address this challenge, we propose a novel
framework -- \textsc{Disentangled Multimodal Graph Clustering (DMGC)} -- which
decomposes the original hybrid graph into two complementary views: (1) a
homophily-enhanced graph that captures cross-modal class consistency, and (2)
heterophily-aware graphs that preserve modality-specific inter-class
distinctions. We introduce a \emph{Multimodal Dual-frequency Fusion} mechanism
that jointly filters these disentangled graphs through a dual-pass strategy,
enabling effective multimodal integration while mitigating category confusion.
Our self-supervised alignment objectives further guide the learning process
without requiring labels. Extensive experiments on both multimodal and
multi-relational graph datasets demonstrate that DMGC achieves state-of-the-art
performance, highlighting its effectiveness and generalizability across diverse
settings. Our code is available at https://github.com/Uncnbb/DMGC.

</details>


### [165] [IM-Chat: A Multi-agent LLM-based Framework for Knowledge Transfer in Injection Molding Industry](https://arxiv.org/abs/2507.15268)
*Junhyeong Lee, Joon-Young Kim, Heekyu Kim, Inhyo Lee, Seunghwa Ryu*

**主要类别:** cs.AI

**AI概要:** IM-Chat是一个基于大型语言模型的多代理框架，用于注塑行业知识传承和交流。它整合了文档知识和通过数据驱动过程条件生成器建模的领域数据，并采用检索增强生成策略和工具调用代理确保适应性。性能评估显示，更强大的模型在复杂任务中表现出更高的准确性，证明了多代理LLM系统在工业知识工作流中的可行性。


<details>
  <summary>更多</summary>
  
**动机:** 注塑成型行业面临经验丰富的工人退休和多语言障碍导致的知识保存和转移挑战。

**方法:** IM-Chat融合了有限的文档知识（如故障排除表、手册）和通过数据驱动过程条件生成器从环境输入（如温度和湿度）推断出的最佳制造设置的广泛领域数据。它使用检索增强生成（RAG）策略和工具调用代理在一个模块化架构中实现。

**结果:** 性能评估表明，更强大的模型倾向于在复杂任务中获得更高的准确性，特别是在集成工具的任务中。

**结论:** 研究结果展示了多代理LLM系统在工业知识工作流中的可行性，并确立了IM-Chat作为AI辅助决策支持在制造业中可扩展和通用的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是IM-Chat%3A+A+Multi-agent+LLM-based+Framework+for+Knowledge+Transfer+in+Injection+Molding+Industry，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15268，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15268&send_immediately=true&force_search=false)

**原文摘要:** The injection molding industry faces critical challenges in preserving and
transferring field knowledge, particularly as experienced workers retire and
multilingual barriers hinder effective communication. This study introduces
IM-Chat, a multi-agent framework based on large language models (LLMs),
designed to facilitate knowledge transfer in injection molding. IM-Chat
integrates both limited documented knowledge (e.g., troubleshooting tables,
manuals) and extensive field data modeled through a data-driven process
condition generator that infers optimal manufacturing settings from
environmental inputs such as temperature and humidity, enabling robust and
context-aware task resolution. By adopting a retrieval-augmented generation
(RAG) strategy and tool-calling agents within a modular architecture, IM-Chat
ensures adaptability without the need for fine-tuning. Performance was assessed
across 100 single-tool and 60 hybrid tasks for GPT-4o, GPT-4o-mini, and
GPT-3.5-turbo by domain experts using a 10-point rubric focused on relevance
and correctness, and was further supplemented by automated evaluation using
GPT-4o guided by a domain-adapted instruction prompt. The evaluation results
indicate that more capable models tend to achieve higher accuracy, particularly
in complex, tool-integrated scenarios. Overall, these findings demonstrate the
viability of multi-agent LLM systems for industrial knowledge workflows and
establish IM-Chat as a scalable and generalizable approach to AI-assisted
decision support in manufacturing.

</details>


### [166] [QSAF: A Novel Mitigation Framework for Cognitive Degradation in Agentic AI](https://arxiv.org/abs/2507.15330)
*Hammad Atta, Muhammad Zeeshan Baig, Yasir Mehmood, Nadeem Shahzad, Ken Huang, Muhammad Aziz Ul Haq, Muhammad Awais, Kamal Ahmed*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种新型的代理AI系统的漏洞类别——认知退化，以及应对这一问题的框架。


<details>
  <summary>更多</summary>
  
**动机:** 当前对于代理AI系统的研究大多关注外部威胁，而内部引发的故障鲜有研究，因此需要提出新的理论和方法来解决这类问题。

**方法:** 通过引入Qorvex安全AI框架（QSAF域10），定义了六阶段的认知退化生命周期，并提出了七个运行时控制措施，以实时监控代理子系统并触发预防性缓解。

**结果:** 该框架可以早期检测到疲劳、饥饿和角色崩溃，从而提高了AI系统的弹性和稳定性。

**结论:** 认知退化是AI系统中一个关键的新漏洞类别，QSAF域10为实现弹性代理行为提供了首个跨平台防御模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是QSAF%3A+A+Novel+Mitigation+Framework+for+Cognitive+Degradation+in+Agentic+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15330，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15330&send_immediately=true&force_search=false)

**原文摘要:** We introduce Cognitive Degradation as a novel vulnerability class in agentic
AI systems. Unlike traditional adversarial external threats such as prompt
injection, these failures originate internally, arising from memory starvation,
planner recursion, context flooding, and output suppression. These systemic
weaknesses lead to silent agent drift, logic collapse, and persistent
hallucinations over time. To address this class of failures, we introduce the
Qorvex Security AI Framework for Behavioral & Cognitive Resilience (QSAF Domain
10), a lifecycle-aware defense framework defined by a six-stage cognitive
degradation lifecycle. The framework includes seven runtime controls
(QSAF-BC-001 to BC-007) that monitor agent subsystems in real time and trigger
proactive mitigation through fallback routing, starvation detection, and memory
integrity enforcement. Drawing from cognitive neuroscience, we map agentic
architectures to human analogs, enabling early detection of fatigue,
starvation, and role collapse. By introducing a formal lifecycle and real-time
mitigation controls, this work establishes Cognitive Degradation as a critical
new class of AI system vulnerability and proposes the first cross-platform
defense model for resilient agentic behavior.

</details>


### [167] [One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms](https://arxiv.org/abs/2507.15351)
*Zijian Zhao, Sen Li*

**主要类别:** cs.AI

**AI概要:** 论文提出两种新方法GRPO和OSPO，以绕过价值函数估计问题，并在实验中展示了更好的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于MARL的拼车方法在大规模、高度不确定环境中难以准确估计Q值或V值，导致训练不稳定和估计偏差大。

**方法:** 提出两种方法：1）将GRPO适应于拼车，用群体平均奖励取代PPO基线；2）定制PPO框架，仅使用一步奖励进行策略优化（OSPO）。

**结果:** 通过曼哈顿的真实打车数据集进行实验，证明GRPO和OSPO在大多数情况下都能取得更优的表现，能有效优化接客时间和订单数量。

**结论:** 这两种新方法可以绕过价值函数估计的问题，在简单MLP网络下实现高效优化，为解决拼车平台挑战提供了新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是One+Step+is+Enough%3A+Multi-Agent+Reinforcement+Learning+based+on+One-Step+Policy+Optimization+for+Order+Dispatch+on+Ride-Sharing+Platforms，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15351，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15351&send_immediately=true&force_search=false)

**原文摘要:** On-demand ride-sharing platforms face the fundamental challenge of
dynamically bundling passengers with diverse origins and destinations and
matching them with vehicles in real time, all under significant uncertainty.
Recently, MARL has emerged as a promising solution for this problem, leveraging
decentralized learning to address the curse of dimensionality caused by the
large number of agents in the ride-hailing market and the resulting expansive
state and action spaces. However, conventional MARL-based ride-sharing
approaches heavily rely on the accurate estimation of Q-values or V-values,
which becomes problematic in large-scale, highly uncertain environments.
Specifically, most of these approaches adopt an independent paradigm,
exacerbating this issue, as each agent treats others as part of the
environment, leading to unstable training and substantial estimation bias in
value functions. To address these challenges, we propose two novel alternative
methods that bypass value function estimation. First, we adapt GRPO to
ride-sharing, replacing the PPO baseline with the group average reward to
eliminate critic estimation errors and reduce training bias. Second, inspired
by GRPO's full utilization of group reward information, we customize the PPO
framework for ride-sharing platforms and show that, under a homogeneous fleet,
the optimal policy can be trained using only one-step rewards - a method we
term One-Step Policy Optimization (OSPO). Experiments on a real-world Manhattan
ride-hailing dataset demonstrate that both GRPO and OSPO achieve superior
performance across most scenarios, efficiently optimizing pickup times and the
number of served orders using simple MLP networks.

</details>


### [168] [RAD: Retrieval High-quality Demonstrations to Enhance Decision-making](https://arxiv.org/abs/2507.15356)
*Lu Guo, Yixiang Shan, Zhengbang Zhu, Qifan Liang, Lichang Song, Ting Long, Weinan Zhang, Yi Chang*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种新的离线强化学习方法RAD，该方法结合了非参数检索和基于扩散的生成模型，以解决数据集稀疏性和轨迹重叠不足的问题。实验表明，RAD在各种基准上实现了与基线相比具有竞争力或更优的性能。


<details>
  <summary>更多</summary>
  
**动机:** 离线强化学习（RL）虽然可以避免昂贵或不安全的环境交互，但其效果常常受到数据集稀疏性和次优与专家轨迹之间缺乏过渡重叠的限制，这使得长时域规划特别具有挑战性。

**方法:** RAD通过结合非参数检索与基于扩散的生成建模来解决问题。它动态地从离线数据集中检索高回报状态作为目标状态，并使用条件引导的扩散模型进行规划。

**结果:** 广泛的实验确认RAD在多个不同基准上实现了与基线相比具有竞争力或更优的性能，验证了其有效性。

**结论:** RAD提供了一种有效的解决方案，以应对离线强化学习中遇到的数据集稀疏性和轨迹重叠不足的问题，特别是在面对未充分表示或分布外的状态时，提高了泛化能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是RAD%3A+Retrieval+High-quality+Demonstrations+to+Enhance+Decision-making，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15356，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15356&send_immediately=true&force_search=false)

**原文摘要:** Offline reinforcement learning (RL) enables agents to learn policies from
fixed datasets, avoiding costly or unsafe environment interactions. However,
its effectiveness is often limited by dataset sparsity and the lack of
transition overlap between suboptimal and expert trajectories, which makes
long-horizon planning particularly challenging. Prior solutions based on
synthetic data augmentation or trajectory stitching often fail to generalize to
novel states and rely on heuristic stitching points. To address these
challenges, we propose Retrieval High-quAlity Demonstrations (RAD) for
decision-making, which combines non-parametric retrieval with diffusion-based
generative modeling. RAD dynamically retrieves high-return states from the
offline dataset as target states based on state similarity and return
estimation, and plans toward them using a condition-guided diffusion model.
Such retrieval-guided generation enables flexible trajectory stitching and
improves generalization when encountered with underrepresented or
out-of-distribution states. Extensive experiments confirm that RAD achieves
competitive or superior performance compared to baselines across diverse
benchmarks, validating its effectiveness.

</details>


### [169] [Predictive Process Monitoring Using Object-centric Graph Embeddings](https://arxiv.org/abs/2507.15411)
*Wissam Gherissi, Mehdi Acheli, Joyce El Haddad, Daniela Grigori*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种端到端模型，利用图注意力网络和LSTM网络预测未来流程行为，包括下一个活动和下一个事件时间，并在多个事件日志上展示了与最先进方法相当的性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前以对象为中心的预测过程监控面临的挑战在于从事件日志中提取相关信息并建立有效的预测模型。

**方法:** 该研究提出了一种结合图注意力网络（用于编码活动及其关系）和LSTM网络（处理时间依赖性）的端到端模型来预测未来的流程行为。

**结果:** 在四个事件日志上的评估表明，该模型在两项任务上都表现出与现有最先进方法相竞争的性能。

**结论:** 所提出的模型提供了一种有效的方法来进行以对象为中心的过程预测，特别是在预测下一个活动和事件时间方面。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Predictive+Process+Monitoring+Using+Object-centric+Graph+Embeddings，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15411，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15411&send_immediately=true&force_search=false)

**原文摘要:** Object-centric predictive process monitoring explores and utilizes
object-centric event logs to enhance process predictions. The main challenge
lies in extracting relevant information and building effective models. In this
paper, we propose an end-to-end model that predicts future process behavior,
focusing on two tasks: next activity prediction and next event time. The
proposed model employs a graph attention network to encode activities and their
relationships, combined with an LSTM network to handle temporal dependencies.
Evaluated on one reallife and three synthetic event logs, the model
demonstrates competitive performance compared to state-of-the-art methods.

</details>


### [170] [Optimization of Activity Batching Policies in Business Processes](https://arxiv.org/abs/2507.15457)
*Orlenys López-Pintado, Jannis Rosenbaum, Marlon Dumas*

**主要类别:** cs.AI

**AI概要:** 这篇论文提出了一种帕累托优化方法来发现活动批处理策略，该方法通过干预启发式方法和三种元启发式算法（爬山法、模拟退火和强化学习）生成替代策略，并通过实验评估了其性能。


<details>
  <summary>更多</summary>
  
**动机:** 在业务流程中，活动批处理涉及到将多个活动实例打包在一起进行联合执行。这种做法可以降低处理成本，但会增加等待时间。因此，需要一种能够平衡等待时间、处理努力和成本的批处理策略。

**方法:** 作者提出了一个帕累托优化方法，该方法从给定的一组活动批处理策略开始，通过干预启发式方法生成每个批处理活动的替代策略。然后，这些干预措施的影响通过仿真进行评估。干预启发式方法被嵌入到一个优化元启发式方法中，以迭代地更新目前识别出的干预措施的帕累托前沿。

**结果:** 实验评估比较了基于干预启发式方法提出的帕累托优化方法与相同的（非启发式引导的）元启发式基线在收敛性、多样性和帕累托最优策略的周期时间增益方面的表现。

**结论:** 本文提出的方法为寻找最佳的活动批处理策略提供了一个新的视角，特别是通过结合不同的元启发式算法来改进现有的策略。然而，具体的性能提升取决于所使用的元启发式算法的选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Optimization+of+Activity+Batching+Policies+in+Business+Processes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15457，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15457&send_immediately=true&force_search=false)

**原文摘要:** In business processes, activity batching refers to packing multiple activity
instances for joint execution. Batching allows managers to trade off cost and
processing effort against waiting time. Larger and less frequent batches may
lower costs by reducing processing effort and amortizing fixed costs, but they
create longer waiting times. In contrast, smaller and more frequent batches
reduce waiting times but increase fixed costs and processing effort. A batching
policy defines how activity instances are grouped into batches and when each
batch is activated. This paper addresses the problem of discovering batching
policies that strike optimal trade-offs between waiting time, processing
effort, and cost. The paper proposes a Pareto optimization approach that starts
from a given set (possibly empty) of activity batching policies and generates
alternative policies for each batched activity via intervention heuristics.
Each heuristic identifies an opportunity to improve an activity's batching
policy with respect to a metric (waiting time, processing time, cost, or
resource utilization) and an associated adjustment to the activity's batching
policy (the intervention). The impact of each intervention is evaluated via
simulation. The intervention heuristics are embedded in an optimization
meta-heuristic that triggers interventions to iteratively update the Pareto
front of the interventions identified so far. The paper considers three
meta-heuristics: hill-climbing, simulated annealing, and reinforcement
learning. An experimental evaluation compares the proposed approach based on
intervention heuristics against the same (non-heuristic guided) meta-heuristics
baseline regarding convergence, diversity, and cycle time gain of
Pareto-optimal policies.

</details>


### [171] [Chart-R1: Chain-of-Thought Supervision and Reinforcement for Advanced Chart Reasoner](https://arxiv.org/abs/2507.15509)
*Lei Chen, Xuanle Zhao, Zhixiong Zeng, Jing Huang, Yufeng Zhong, Lin Ma*

**主要类别:** cs.AI

**AI概要:** 本文提出Chart-R1，一种基于强化学习微调的图表领域视觉-语言模型，用于实现复杂图表推理。通过引入新的程序化数据合成技术和两阶段训练策略，该方法在多个基准测试中表现出显著优势。


<details>
  <summary>更多</summary>
  
**动机:** 现有的R1-Style方法主要集中在数学推理和代码智能上，而验证这些方法在更广泛的多模态数据上的优势具有重要的研究意义。图表作为信息丰富的多模态数据类型，在复杂推理方面带来了重要挑战。

**方法:** 提出了Chart-R1模型，并引入了程序化数据合成技术以生成高质量的逐步图表推理数据。此外，还开发了两阶段训练策略：Chart-COT（带有逐步思维链监督）和Chart-RFT（数值敏感的强化微调）。

**结果:** 实验结果表明，Chart-R1相比图表领域的方法有显著优势，甚至可与开源/闭源的大规模模型（如GPT-4o、Claude-3.5）相媲美。

**结论:** 本研究表明，通过引入新的数据合成技术和改进的训练策略，可以显著提高图表推理能力，为未来的研究提供了一个强有力的基线。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Chart-R1%3A+Chain-of-Thought+Supervision+and+Reinforcement+for+Advanced+Chart+Reasoner，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15509，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15509&send_immediately=true&force_search=false)

**原文摘要:** Recently, inspired by OpenAI-o1/o3 and Deepseek-R1, the R1-Style method based
on reinforcement learning fine-tuning has received widespread attention from
the community. Previous R1-Style methods mainly focus on mathematical reasoning
and code intelligence. It is of great research significance to verify their
advantages on more general multimodal data. Chart is an important multimodal
data type with rich information, which brings important research challenges in
complex reasoning. In this work, we introduce Chart-R1, a chart-domain
vision-language model with reinforcement learning fine-tuning to enable complex
chart reasoning. To support Chart-R1, we first propose a novel programmatic
data synthesis technology to generate high-quality step-by-step chart reasoning
data covering single- and multi-subcharts, which makes up for the lack of
reasoning data in the chart domain. Then we develop a two-stage training
strategy: Chart-COT with step-by-step chain-of-thought supervision, and
Chart-RFT with numerically sensitive reinforcement fine-tuning. Chart-COT aims
to decompose complex chart reasoning tasks into fine-grained, understandable
subtasks through step-by-step supervision, which lays a good foundation for
improving the reasoning level of reinforcement learning. Chart-RFT utilize the
typical group relative policy optimization strategy, in which a relatively soft
reward is adopted for numerical response to emphasize the numerical sensitivity
in the chart domain. We conduct extensive experiments on open-source benchmarks
and self-built chart reasoning dataset (\emph{i.e., ChartRQA}). Experimental
results show that Chart-R1 has significant advantages compared to chart-domain
methods, even comparable to open/closed source large-scale models (\emph{e.g.,
GPT-4o, Claude-3.5}).

</details>


### [172] [HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics](https://arxiv.org/abs/2507.15518)
*Sizhou Chen, Shufan Jiang, Chi Zhang, Xiao-Lei Zhang, Xuelong Li*

**主要类别:** cs.AI

**AI概要:** 提出一个多代理框架HAMLET，以简单的主题生成叙事蓝图，并在在线表演期间赋予演员自主决策能力，以改善互动性和沉浸感。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于大语言模型的戏剧生成方法导致AI代理缺乏主动性且无法与物理环境互动，并通常需要详细的用户输入来驱动剧情，这减少了在线实时表演的互动性和沉浸感。

**方法:** 给定一个简单的话题，该框架会生成一个叙事蓝图，指导后续的即兴表演。每个演员被赋予自主性，可以基于自己的背景、目标和情感状态做出独立决策。此外，他们的决定可以通过动作改变场景道具的状态，这种变化会被广播给其他相关演员，更新他们所知道和关心的内容，从而影响他们的下一步行动。

**结果:** 实验评估显示HAMLET可以创建表达丰富且连贯的戏剧体验。

**结论:** 作者认为，通过多代理框架HAMLET，可以在在线实时表演中提高互动性和沉浸感，为创造沉浸式互动戏剧体验提供了新的路径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是HAMLET%3A+Hyperadaptive+Agent-based+Modeling+for+Live+Embodied+Theatrics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15518，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15518&send_immediately=true&force_search=false)

**原文摘要:** Creating an immersive and interactive theatrical experience is a long-term
goal in the field of interactive narrative. The emergence of large language
model (LLM) is providing a new path to achieve this goal. However, existing
LLM-based drama generation methods often result in AI agents that lack
initiative and cannot interact with the physical environment. Furthermore,
these methods typically require detailed user input to drive the drama. These
limitations reduce the interactivity and immersion of online real-time
performance. To address the above challenges, we propose HAMLET, a multi-agent
framework focused on drama creation and online performance. Given a simple
topic, the framework generates a narrative blueprint, guiding the subsequent
improvisational performance. During the online performance, each actor is given
an autonomous mind. This means that actors can make independent decisions based
on their own background, goals, and emotional state. In addition to
conversations with other actors, their decisions can also change the state of
scene props through actions such as opening a letter or picking up a weapon.
The change is then broadcast to other related actors, updating what they know
and care about, which in turn influences their next action. To evaluate the
quality of drama performance, we designed an evaluation method to assess three
primary aspects, including character performance, narrative quality, and
interaction experience. The experimental evaluation shows that HAMLET can
create expressive and coherent theatrical experiences. Our code, dataset and
models are available at https://github.com/HAMLET-2025/HAMLET.

</details>


### [173] [LLM world models are mental: Output layer evidence of brittle world model use in LLM mechanical reasoning](https://arxiv.org/abs/2507.15521)
*Cole Robertson, Philip Wolff*

**主要类别:** cs.AI

**AI概要:** 研究使用认知科学方法测试大型语言模型在滑轮系统问题上的表现，结果显示这些模型可以利用内部世界模型进行一定程度的推理，但可能无法处理复杂的结构连接性。


<details>
  <summary>更多</summary>
  
**动机:** 了解大型语言模型是构建和操作内部世界模型还是仅仅依赖于统计关联。

**方法:** 改编来自人类心理模型研究的认知科学研究方法，使用TikZ渲染的刺激来测试LLMs在滑轮系统问题上的表现。通过三个不同的研究，探讨了LLMs在估计机械优势、表示关键全局特征以及比较功能系统方面的能力。

**结果:** 最先进的模型在估计机械优势方面的表现略高于随机猜测，并且与实际的机械优势有显著的相关性；能够区分乱序和功能性系统；但在识别力传递结构连接的功能系统时表现出随机猜测。

**结论:** 研究结果支持大型语言模型可以操纵内部世界模型以利用滑轮数量和机械优势之间的统计关联，并近似表示系统组件的空间关系，但在细微结构连通性推理上可能存在不足。提倡使用认知科学的方法评估人工智能系统的建模能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM+world+models+are+mental%3A+Output+layer+evidence+of+brittle+world+model+use+in+LLM+mechanical+reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15521，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15521&send_immediately=true&force_search=false)

**原文摘要:** Do large language models (LLMs) construct and manipulate internal world
models, or do they rely solely on statistical associations represented as
output layer token probabilities? We adapt cognitive science methodologies from
human mental models research to test LLMs on pulley system problems using
TikZ-rendered stimuli. Study 1 examines whether LLMs can estimate mechanical
advantage (MA). State-of-the-art models performed marginally but significantly
above chance, and their estimates correlated significantly with ground-truth
MA. Significant correlations between number of pulleys and model estimates
suggest that models employed a pulley counting heuristic, without necessarily
simulating pulley systems to derive precise values. Study 2 tested this by
probing whether LLMs represent global features crucial to MA estimation. Models
evaluated a functionally connected pulley system against a fake system with
randomly placed components. Without explicit cues, models identified the
functional system as having greater MA with F1=0.8, suggesting LLMs could
represent systems well enough to differentiate jumbled from functional systems.
Study 3 built on this by asking LLMs to compare functional systems with matched
systems which were connected up but which transferred no force to the weight;
LLMs identified the functional system with F1=0.46, suggesting random guessing.
Insofar as they may generalize, these findings are compatible with the notion
that LLMs manipulate internal world models, sufficient to exploit statistical
associations between pulley count and MA (Study 1), and to approximately
represent system components' spatial relations (Study 2). However, they may
lack the facility to reason over nuanced structural connectivity (Study 3). We
conclude by advocating the utility of cognitive scientific methods to evaluate
the world-modeling capacities of artificial intelligence systems.

</details>


### [174] [Data-Efficient Safe Policy Improvement Using Parametric Structure](https://arxiv.org/abs/2507.15532)
*Kasper Engelen, Guillermo A. Pérez, Marnix Suilen*

**主要类别:** cs.AI

**AI概要:** 本文通过参数化SPI算法、基于博弈的抽象预处理技术和基于SMT求解的高级预处理技术，提高了安全策略改进（SPI）的数据效率。


<details>
  <summary>更多</summary>
  
**动机:** 在许多应用中，转换动态中的分布之间存在参数依赖性的额外信息。然而，传统的SPI方法没有利用这些依赖性，导致数据效率低下。因此，需要一种更有效的SPI方法来提高数据效率。

**方法:** 作者提出了三种贡献：1. 参数化SPI算法，利用已知的相关性更准确地估计转换动态；2. 基于博弈的抽象预处理技术，通过修剪环境中的冗余动作；3. 基于SMT求解的高级预处理技术，可以识别更多的可修剪动作。

**结果:** 实证结果和消融研究表明，我们的技术可以在保持相同可靠性保证的同时，将SPI的数据效率提高多个数量级。

**结论:** 本文提出的方法提高了SPI的数据效率，同时保持了相同的可靠性保证。这为未来的离线强化学习研究提供了一种新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data-Efficient+Safe+Policy+Improvement+Using+Parametric+Structure，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15532，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15532&send_immediately=true&force_search=false)

**原文摘要:** Safe policy improvement (SPI) is an offline reinforcement learning problem in
which a new policy that reliably outperforms the behavior policy with high
confidence needs to be computed using only a dataset and the behavior policy.
Markov decision processes (MDPs) are the standard formalism for modeling
environments in SPI. In many applications, additional information in the form
of parametric dependencies between distributions in the transition dynamics is
available. We make SPI more data-efficient by leveraging these dependencies
through three contributions: (1) a parametric SPI algorithm that exploits known
correlations between distributions to more accurately estimate the transition
dynamics using the same amount of data; (2) a preprocessing technique that
prunes redundant actions from the environment through a game-based abstraction;
and (3) a more advanced preprocessing technique, based on satisfiability modulo
theory (SMT) solving, that can identify more actions to prune. Empirical
results and an ablation study show that our techniques increase the data
efficiency of SPI by multiple orders of magnitude while maintaining the same
reliability guarantees.

</details>


### [175] [Metric assessment protocol in the context of answer fluctuation on MCQ tasks](https://arxiv.org/abs/2507.15581)
*Ekaterina Goliakova, Xavier Renard, Marie-Jeanne Lesot, Thibault Laugel, Christophe Marsala, Marcin Detyniecki*

**主要类别:** cs.AI

**AI概要:** 本研究提出了一种评估协议，用于分析MCQ评估方法与波动率和原始性能的关系。发现现有指标与答案变化之间存在强关联，新提出的最差准确度指标显示出最高的关联性。


<details>
  <summary>更多</summary>
  
**动机:** 目前的研究没有对评估LLM能力的多种指标进行彻底评估，同时MCQ评估存在答案波动的问题。

**方法:** 建议一个评估协议，通过分析评估方法与波动率以及原始性能之间的关系来评估MCQ评估方法。

**结果:** 发现现有指标与答案变化之间存在强关联，即使在没有任何额外提示变体的情况下计算也是如此。新提出的最差准确度指标在协议中显示出最高的关联性。

**结论:** 评估协议可以更好地理解MCQ评估方法的稳定性和可靠性，最差准确度是一个有潜力的新指标。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Metric+assessment+protocol+in+the+context+of+answer+fluctuation+on+MCQ+tasks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15581，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15581&send_immediately=true&force_search=false)

**原文摘要:** Using multiple-choice questions (MCQs) has become a standard for assessing
LLM capabilities efficiently. A variety of metrics can be employed for this
task. However, previous research has not conducted a thorough assessment of
them. At the same time, MCQ evaluation suffers from answer fluctuation: models
produce different results given slight changes in prompts. We suggest a metric
assessment protocol in which evaluation methodologies are analyzed through
their connection with fluctuation rates, as well as original performance. Our
results show that there is a strong link between existing metrics and the
answer changing, even when computed without any additional prompt variants. A
novel metric, worst accuracy, demonstrates the highest association on the
protocol.

</details>


### [176] [TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft II](https://arxiv.org/abs/2507.15618)
*Weiyu Ma, Jiwen Jiang, Haobo Fu, Haifeng Zhang*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种基于适配器的方法，用于StarCraft II AI代理的战术条件反射。通过冻结预训练策略网络并附加轻量级适配器模块，可以实现灵活的战术控制和最小的计算开销，同时保持竞争性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前的StarCraft II AI代理虽然强大，但缺乏根据高级战术指令调整其策略的能力。因此，作者希望找到一种方法来增强AI代理的战术灵活性和适应性。

**方法:** 作者使用了基于适配器的方法，冻结了一个预训练的策略网络（DI-Star），并在每个动作头上附加了轻量级的适配器模块。这些模块受训于一个战术张量，该张量编码了战略偏好，并且在KL散度约束下进行训练，以确保策略保持核心能力的同时表现出战术变化。

**结果:** 实验结果表明，该方法成功地调节了代理行为，包括攻击性、扩张模式和技术偏好等战术维度，同时保持了竞争力。

**结论:** 该方法使得复杂的即时战略游戏能够实现灵活的战术控制和最低限度的计算开销，为实际的战略定制提供了可能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TacticCraft%3A+Natural+Language-Driven+Tactical+Adaptation+for+StarCraft+II，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15618，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15618&send_immediately=true&force_search=false)

**原文摘要:** We present an adapter-based approach for tactical conditioning of StarCraft
II AI agents. Current agents, while powerful, lack the ability to adapt their
strategies based on high-level tactical directives. Our method freezes a
pre-trained policy network (DI-Star) and attaches lightweight adapter modules
to each action head, conditioned on a tactical tensor that encodes strategic
preferences. By training these adapters with KL divergence constraints, we
ensure the policy maintains core competencies while exhibiting tactical
variations. Experimental results show our approach successfully modulates agent
behavior across tactical dimensions including aggression, expansion patterns,
and technology preferences, while maintaining competitive performance. Our
method enables flexible tactical control with minimal computational overhead,
offering practical strategy customization for complex real-time strategy games.

</details>


### [177] [Agentic AI for autonomous anomaly management in complex systems](https://arxiv.org/abs/2507.15676)
*Reza Vatankhah Barenji, Sina Khoshgoftar*

**主要类别:** cs.AI

**AI概要:** 本文探讨了代理AI在复杂系统中自主检测和响应异常的潜力，强调其改变传统依赖人类的异常管理方法的能力。


<details>
  <summary>更多</summary>
  
**动机:** 随着复杂系统的增加，传统的依赖人类的异常管理方法已经不能满足需求，需要一种更自主、更智能的方法来处理异常情况。

**方法:** 利用代理AI技术，使其能够自主地检测和响应复杂系统中的异常。

**结果:** 该研究可能的结果是证明代理AI可以在复杂系统中有效地自主检测和响应异常，提高系统的稳定性和安全性。

**结论:** 代理AI有可能彻底改变我们对复杂系统中异常的管理方式，减少对人类的依赖，提高效率和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Agentic+AI+for+autonomous+anomaly+management+in+complex+systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15676，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15676&send_immediately=true&force_search=false)

**原文摘要:** This paper explores the potential of agentic AI in autonomously detecting and
responding to anomalies within complex systems, emphasizing its ability to
transform traditional, human-dependent anomaly management methods.

</details>


### [178] [Towards physician-centered oversight of conversational diagnostic AI](https://arxiv.org/abs/2507.15743)
*Elahe Vedadi, David Barrett, Natalie Harris, Ellery Wulczyn, Shashir Reddy, Roma Ruparel, Mike Schaekermann, Tim Strother, Ryutaro Tanno, Yash Sharma, Jihyeon Lee, Cían Hughes, Dylan Slack, Anil Palepu, Jan Freyberg, Khaled Saab, Valentin Liévin, Wei-Hung Weng, Tao Tu, Yun Liu, Nenad Tomasev, Kavita Kulkarni, S. Sara Mahdavi, Kelvin Guu, Joëlle Barral, Dale R. Webster, James Manyika, Avinatan Hassidim, Katherine Chou, Yossi Matias, Pushmeet Kohli, Adam Rodman, Vivek Natarajan, Alan Karthikesalingam, David Stutz*

**主要类别:** cs.AI

**AI概要:** 本研究提出了一种名为g-AMIE的多智能体系统，该系统在不提供个性化医疗建议的前提下进行病史采集，并将评估结果传达给主治医生。通过随机、盲目的虚拟客观结构化临床考试（OSCE）文本咨询，发现g-AMIE在高质量信息收集、案例总结和提出诊断及管理计划方面优于护士从业者和助理医生以及主治医生团队。这导致了更高的决策质量，并且g-AMIE的主治医生监督比之前的独立主治医生咨询更节省时间。


<details>
  <summary>更多</summary>
  
**动机:** 当前的对话式AI系统展示了其在诊断对话中的潜力，但为了确保患者安全，个体诊断和治疗计划被认为是受监管的活动，需要由有执照的专业人员进行。此外，医生通常会监督其他团队成员如护士从业者或助理医生从事这些活动。因此，研究人员希望开发一个框架，以有效、异步地监督Articulate Medical Intelligence Explorer (AMIE) AI系统。

**方法:** 研究人员提出了一个名为guardrailed-AMIE (g-AMIE)的多智能体系统。这个系统在限定范围内执行病史采集工作，避免给出个性化的医疗建议。之后，g-AMIE会将评估传递给主治医生，主治医生负责监督并保持临床决策的责任。这样可以将监督与初次接诊分离开来，从而实现异步操作。

**结果:** 在60个场景中，g-AMIE在高质量的信息收集、总结病例和提出诊断及管理计划方面都超过了护士从业者/助理医生组和主治医生组。这种改进使得最终的综合决策质量更高。此外，g-AMIE的主治医生监督比以前的研究中的独立主治医生咨询更节省时间。

**结论:** 尽管这项研究没有复制现有的临床实践并且可能低估了临床医生的能力，但研究结果表明，异步监督作为一种可行的范例，可以在专家人类监督下运行诊断AI系统，以增强现实世界的护理。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+physician-centered+oversight+of+conversational+diagnostic+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15743，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15743&send_immediately=true&force_search=false)

**原文摘要:** Recent work has demonstrated the promise of conversational AI systems for
diagnostic dialogue. However, real-world assurance of patient safety means that
providing individual diagnoses and treatment plans is considered a regulated
activity by licensed professionals. Furthermore, physicians commonly oversee
other team members in such activities, including nurse practitioners (NPs) or
physician assistants/associates (PAs). Inspired by this, we propose a framework
for effective, asynchronous oversight of the Articulate Medical Intelligence
Explorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent
system that performs history taking within guardrails, abstaining from
individualized medical advice. Afterwards, g-AMIE conveys assessments to an
overseeing primary care physician (PCP) in a clinician cockpit interface. The
PCP provides oversight and retains accountability of the clinical decision.
This effectively decouples oversight from intake and can thus happen
asynchronously. In a randomized, blinded virtual Objective Structured Clinical
Examination (OSCE) of text consultations with asynchronous oversight, we
compared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across
60 scenarios, g-AMIE outperformed both groups in performing high-quality
intake, summarizing cases, and proposing diagnoses and management plans for the
overseeing PCP to review. This resulted in higher quality composite decisions.
PCP oversight of g-AMIE was also more time-efficient than standalone PCP
consultations in prior work. While our study does not replicate existing
clinical practices and likely underestimates clinicians' capabilities, our
results demonstrate the promise of asynchronous oversight as a feasible
paradigm for diagnostic AI systems to operate under expert human oversight for
enhancing real-world care.

</details>


### [179] [LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization](https://arxiv.org/abs/2507.15758)
*Xingyu Wu, Yuchen Yan, Shangke Lyu, Linjuan Wu, Yiwen Qiu, Yongliang Shen, Weiming Lu, Jian Shao, Jun Xiao, Yueting Zhuang*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种名为Length-Adaptive Policy Optimization (LAPO)的新框架，该框架通过两阶段的强化学习过程使模型能够内部化理解适当的推理深度。实验表明，LAPO减少了高达40.9%的token使用量，同时提高了2.3%的准确性，并且根据问题复杂性分配计算资源，实现了高效的推理而不牺牲质量。


<details>
  <summary>更多</summary>
  
**动机:** 大型推理模型虽然在扩展的思维链序列中取得了显著的性能，但这种计算自由导致了即使对于简单的问题也会产生过多的token。因此，需要一种方法将推理长度控制从外部约束转变为模型的内在能力。

**方法:** LAPO采用两阶段的强化学习过程：第一阶段，模型通过发现成功解决方案长度的统计分布来学习自然的推理模式；第二阶段，利用这些模式作为元认知指导，直接嵌入到模型的推理环境中，以确保推理时的灵活性。

**结果:** 实验结果表明，LAPO可以在数学推理基准测试中减少高达40.9%的token使用量，同时提高2.3%的准确性。此外，模型展示了根据问题复杂性分配计算资源的能力。

**结论:** LAPO提供了一种新的方法来优化推理模型的token生成，通过内部化适当的推理深度理解，既提高了效率又保持了推理的质量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LAPO%3A+Internalizing+Reasoning+Efficiency+via+Length-Adaptive+Policy+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15758，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15758&send_immediately=true&force_search=false)

**原文摘要:** Large reasoning models have achieved remarkable performance through extended
chain-of-thought sequences, yet this computational freedom leads to excessive
token generation even for simple problems. We present Length-Adaptive Policy
Optimization (LAPO), a novel framework that transforms reasoning length control
from an external constraint into an intrinsic model capability. Unlike existing
approaches that impose rigid limits or rely on post-hoc interventions, LAPO
enables models to internalize an understanding of appropriate reasoning depth
through a two-stage reinforcement learning process. In the first stage, models
learn natural reasoning patterns by discovering the statistical distribution of
successful solution lengths. The second stage leverages these patterns as
meta-cognitive guidance, embedding them directly within the model's reasoning
context to ensure inference-time flexibility. Experiments on mathematical
reasoning benchmarks demonstrate that LAPO reduces token usage by up to 40.9\%
while improving accuracy by 2.3\%. Our analysis reveals that models trained
with LAPO develop emergent abilities to allocate computational resources based
on problem complexity, achieving efficient reasoning without sacrificing
quality.

</details>


### [180] [GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts](https://arxiv.org/abs/2507.15761)
*Jingyi Zheng, Zifan Peng, Yule Liu, Junfeng Wang, Yifan Liao, Wenhan Dong, Xinlei He*

**主要类别:** cs.AI

**AI概要:** 论文介绍了一种名为GasAgent的多智能体系统，用于优化智能合约中的Gas消耗。该系统包含四个专门的智能体，在闭环中协作以识别、验证和应用节省Gas的改进措施。实验表明，GasAgent在实际合约和LLM生成的合约上均能显著减少Gas消耗，并与现有工具兼容。


<details>
  <summary>更多</summary>
  
**动机:** 由于非最优编码实践，许多智能合约存在Gas浪费模式，而现有的解决方案大多依赖于手动发现，效率低下且难以扩展。最近的研究尝试使用大型语言模型（LLMs）探索新的Gas浪费模式，但这些方法与现有模式的兼容性差，容易产生冗余模式，并需要人工验证/重写。

**方法:** 作者提出了GasAgent，这是第一个结合现有模式兼容性和新模式自动发现/验证的智能合约Gas优化多智能体系统。它由四个专业智能体组成：Seeker、Innovator、Executor和Manager，它们在闭环中协作，以识别、验证和应用Gas节省改进。

**结果:** 对100个真实世界的合约进行实验，GasAgent成功优化了82个合约，平均部署Gas节省9.97%。对于500个由LLM生成的合约，GasAgent优化了79.8%，部署Gas节省范围从4.79%到13.93%。

**结论:** GasAgent展示了其作为LLM辅助智能合约开发优化层的可用性，同时确认了其与现有工具的兼容性及各模块的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GasAgent%3A+A+Multi-Agent+Framework+for+Automated+Gas+Optimization+in+Smart+Contracts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15761，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15761&send_immediately=true&force_search=false)

**原文摘要:** Smart contracts are trustworthy, immutable, and automatically executed
programs on the blockchain. Their execution requires the Gas mechanism to
ensure efficiency and fairness. However, due to non-optimal coding practices,
many contracts contain Gas waste patterns that need to be optimized. Existing
solutions mostly rely on manual discovery, which is inefficient, costly to
maintain, and difficult to scale. Recent research uses large language models
(LLMs) to explore new Gas waste patterns. However, it struggles to remain
compatible with existing patterns, often produces redundant patterns, and
requires manual validation/rewriting. To address this gap, we present GasAgent,
the first multi-agent system for smart contract Gas optimization that combines
compatibility with existing patterns and automated discovery/validation of new
patterns, enabling end-to-end optimization. GasAgent consists of four
specialized agents, Seeker, Innovator, Executor, and Manager, that collaborate
in a closed loop to identify, validate, and apply Gas-saving improvements.
Experiments on 100 verified real-world contracts demonstrate that GasAgent
successfully optimizes 82 contracts, achieving an average deployment Gas
savings of 9.97%. In addition, our evaluation confirms its compatibility with
existing tools and validates the effectiveness of each module through ablation
studies. To assess broader usability, we further evaluate 500 contracts
generated by five representative LLMs across 10 categories and find that
GasAgent optimizes 79.8% of them, with deployment Gas savings ranging from
4.79% to 13.93%, showing its usability as the optimization layer for
LLM-assisted smart contract development.

</details>


### [181] [A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining](https://arxiv.org/abs/2507.15770)
*Yifan Shen, Zihan Zhao, Xiao Xue, Yuwei Guo, Qun Ma, Deyu Zhou, Ming Zhang*

**主要类别:** cs.AI

**AI概要:** 本文介绍了一种基于多智能体意图的涌现分析框架（EAMI），该框架通过动态和可解释的方法进行异常涌现和因果分析。实验验证了其在复杂O2O服务系统和斯坦福AI小镇实验中的有效性、通用性和效率。


<details>
  <summary>更多</summary>
  
**动机:** 随着服务计算、云计算和物联网的兴起，服务生态系统变得越来越复杂，传统因果方法难以应对智能体之间复杂的交互，需要一种新的方法来进行异常涌现分析。

**方法:** EAMI框架采用双视角思维轨迹机制，其中检查智能体和分析智能体在有限和完美理性下提取智能体意图；然后使用k-means聚类识别群体意图中的相变点，最后通过意图时序涌现图进行动态分析。

**结果:** 实验验证了EAMI框架在复杂在线到离线（O2O）服务系统和斯坦福AI Town实验中的有效性、通用性和效率。

**结论:** EAMI提供了一种新颖的范式，用于服务生态系统中的异常涌现和因果分析。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Framework+for+Analyzing+Abnormal+Emergence+in+Service+Ecosystems+Through+LLM-based+Agent+Intention+Mining，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15770，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15770&send_immediately=true&force_search=false)

**原文摘要:** With the rise of service computing, cloud computing, and IoT, service
ecosystems are becoming increasingly complex. The intricate interactions among
intelligent agents make abnormal emergence analysis challenging, as traditional
causal methods focus on individual trajectories. Large language models offer
new possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT)
reasoning to reveal agent intentions. However, existing approaches remain
limited to microscopic and static analysis. This paper introduces a framework:
Emergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic
and interpretable emergence analysis. EAMI first employs a dual-perspective
thought track mechanism, where an Inspector Agent and an Analysis Agent extract
agent intentions under bounded and perfect rationality. Then, k-means
clustering identifies phase transition points in group intentions, followed by
a Intention Temporal Emergence diagram for dynamic analysis. The experiments
validate EAMI in complex online-to-offline (O2O) service system and the
Stanford AI Town experiment, with ablation studies confirming its
effectiveness, generalizability, and efficiency. This framework provides a
novel paradigm for abnormal emergence and causal analysis in service
ecosystems. The code is available at
https://anonymous.4open.science/r/EAMI-B085.

</details>


### [182] [Challenges of Trustworthy Federated Learning: What's Done, Current Trends and Remaining Work](https://arxiv.org/abs/2507.15796)
*Nuria Rodríguez-Barroso, Mario García-Márquez, M. Victoria Luzón, Francisco Herrera*

**主要类别:** cs.AI

**AI概要:** 本文采用TAI的要求作为指导结构，系统分析了将联邦学习适应于可信人工智能的挑战，分类并审查了关键障碍，探讨了已有的工作、趋势和剩余的工作。


<details>
  <summary>更多</summary>
  
**动机:** 随着人工智能系统在敏感和高风险领域的部署，发展可信人工智能（TAI）已成为一个关键目标。联邦学习（FL）虽然为隐私问题提供了一个有希望的解决方案，但要将其与其他TAI要求对齐存在一系列挑战，这主要是由于其固有的分布式特性。

**方法:** 作者采用了TAI框架中的伦理、法律和技术要求作为指导结构，系统地分析了将FL与TAI对齐的挑战。他们分类并审查了这些挑战中的关键障碍，并详细探讨了每个识别出的挑战中已经完成的工作、趋势以及剩余的工作。

**结果:** 该研究提供了对将联邦学习与可信人工智能对齐的关键挑战的深入理解，明确了现有的进展、趋势及未来的研究方向。

**结论:** 为了使联邦学习完全符合可信人工智能的标准，需要克服多个关键挑战，这项工作为未来的探索奠定了基础，并指出了前进的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Challenges+of+Trustworthy+Federated+Learning%3A+What%27s+Done%2C+Current+Trends+and+Remaining+Work，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15796，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15796&send_immediately=true&force_search=false)

**原文摘要:** In recent years, the development of Trustworthy Artificial Intelligence (TAI)
has emerged as a critical objective in the deployment of AI systems across
sensitive and high-risk domains. TAI frameworks articulate a comprehensive set
of ethical, legal, and technical requirements to ensure that AI technologies
are aligned with human values, rights, and societal expectations. Among the
various AI paradigms, Federated Learning (FL) presents a promising solution to
pressing privacy concerns. However, aligning FL with the rest of the
requirements of TAI presents a series of challenges, most of which arise from
its inherently distributed nature. In this work, we adopt the requirements TAI
as a guiding structure to systematically analyze the challenges of adapting FL
to TAI. Specifically, we classify and examine the key obstacles to aligning FL
with TAI, providing a detailed exploration of what has been done, the trends,
and the remaining work within each of the identified challenges.

</details>


### [183] [Identifying Conditional Causal Effects in MPDAGs](https://arxiv.org/abs/2507.15842)
*Sara LaPlante, Emilija Perković*

**主要类别:** cs.AI

**AI概要:** 本文研究了在已知最大定向部分有向无环图(MPDAG)的情况下，识别条件因果效应的问题。提出了三种结果：当调节集不受治疗影响时的识别公式、推广到MPDAG设定的do微积分以及一个用于识别这些条件效应的完整算法。


<details>
  <summary>更多</summary>
  
**动机:** 作者希望解决在已知最大定向部分有向无环图(MPDAG)的情况下，如何识别条件因果效应的问题。

**方法:** 作者提出三种方法来解决这个问题：1）当调节集不受治疗影响时的识别公式；2）将著名的do微积分推广到MPDAG设定；3）开发了一个完整的算法以识别这些条件效应。

**结果:** 通过上述方法，可以在已知MPDAG的情况下，有效地识别条件因果效应，并提供了一种完整的解决方案。

**结论:** 该研究为在MPDAG设定中识别条件因果效应提供了理论基础和实际工具，有助于更广泛地理解和应用因果推理。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Identifying+Conditional+Causal+Effects+in+MPDAGs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15842，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15842&send_immediately=true&force_search=false)

**原文摘要:** We consider identifying a conditional causal effect when a graph is known up
to a maximally oriented partially directed acyclic graph (MPDAG). An MPDAG
represents an equivalence class of graphs that is restricted by background
knowledge and where all variables in the causal model are observed. We provide
three results that address identification in this setting: an identification
formula when the conditioning set is unaffected by treatment, a generalization
of the well-known do calculus to the MPDAG setting, and an algorithm that is
complete for identifying these conditional effects.

</details>


### [184] [Hierarchical Budget Policy Optimization for Adaptive Reasoning](https://arxiv.org/abs/2507.15844)
*Shangke Lyu, Linjuan Wu, Yuchen Yan, Xingyu Wu, Hao Li, Yongliang Shen, Peisheng Jiang, Weiming Lu, Jun Xiao, Yueting Zhuang*

**主要类别:** cs.AI

**AI概要:** 本文提出了一种新的强化学习框架HBPO，该框架通过分层预算探索和差异化的奖励机制，使模型能够根据问题的复杂性自动调整推理深度，在不牺牲能力的情况下提高计算效率。实验表明，HBPO在四个推理基准上将平均token使用量减少了最多60.6%，同时提高了3.14%的准确性。


<details>
  <summary>更多</summary>
  
**动机:** 大型推理模型尽管通过广泛的链式思维生成实现了显著的性能，但在处理不同复杂度的问题时，采用了统一的推理策略，导致计算效率低下。为了克服这一挑战，研究人员提出了Hierarchical Budget Policy Optimization (HBPO)框架。

**方法:** HBPO采用分层预算探索的方法，将rollout样本分为多个具有不同token预算的子组，并引入差异化的奖励机制，创建与问题复杂度相匹配的预算感知激励，从而让模型发现任务需求与计算努力之间的自然对应关系。

**结果:** 广泛的实验证明，HBPO在四个推理基准测试中，平均token使用量减少了最高达60.6%，同时准确率提升了3.14%。此外，HBPO展示了新兴的适应性行为，模型能根据问题复杂性自动调整推理深度。

**结论:** 研究结果表明，推理效率和能力并非天生对立，而是可以通过适当结构化的分层训练同时优化，这种训练方式保留了探索的多样性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Hierarchical+Budget+Policy+Optimization+for+Adaptive+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15844，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15844&send_immediately=true&force_search=false)

**原文摘要:** Large reasoning models achieve remarkable performance through extensive
chain-of-thought generation, yet exhibit significant computational inefficiency
by applying uniform reasoning strategies regardless of problem complexity. We
present Hierarchical Budget Policy Optimization (HBPO), a reinforcement
learning framework that enables models to learn problem-specific reasoning
depths without sacrificing capability. HBPO addresses the fundamental challenge
of exploration space collapse in efficiency-oriented training, where penalties
on long output length systematically bias models away from necessary long
reasoning paths. Through hierarchical budget exploration, our approach
partitions rollout samples into multiple subgroups with distinct token budgets,
aiming to enable efficient resource allocation while preventing degradation of
capability. We introduce differentiated reward mechanisms that create
budget-aware incentives aligned with the complexity of the problem, allowing
models to discover natural correspondences between task requirements and
computational effort. Extensive experiments demonstrate that HBPO reduces
average token usage by up to 60.6% while improving accuracy by 3.14% across
four reasoning benchmarks. Unlike existing methods that impose external
constraints or rely on discrete mode selection, HBPO exhibits emergent adaptive
behavior where models automatically adjust reasoning depth based on problem
complexity. Our results suggest that reasoning efficiency and capability are
not inherently conflicting, and can be simultaneously optimized through
appropriately structured hierarchical training that preserves exploration
diversity.

</details>


### [185] [The Other Mind: How Language Models Exhibit Human Temporal Cognition](https://arxiv.org/abs/2507.15851)
*Lingyu Li, Yang Yao, Yixu Wang, Chubo Li, Yan Teng, Yingchun Wang*

**主要类别:** cs.AI

**AI概要:** 大型语言模型（LLMs）展现出与人类类似的主观时间认知模式，遵循韦伯-费希纳定律，并通过神经元、表征和信息层面的分析揭示了其背后的机制。


<details>
  <summary>更多</summary>
  
**动机:** 研究大型语言模型中未在训练数据中明确规定的类似人类的认知模式，特别是关于时间认知的现象。

**方法:** 使用相似性判断任务测试模型的时间认知，分析神经元活动、年份表征的层次结构建设过程，以及预训练嵌入模型中的非线性时间结构。

**结果:** 发现较大模型自发建立主观时间参考点并遵循韦伯-费希纳定律；识别出一组对时间有偏好的神经元；年份从浅层的基本数值演变为深层的抽象时间方向；训练语料库本身具有内在的非线性时间结构。

**结论:** 提出一种体验主义视角来理解这些发现，暗示LLMs可能发展出人类无法直观预测的陌生认知框架，强调了AI对齐应关注内部构造引导的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Other+Mind%3A+How+Language+Models+Exhibit+Human+Temporal+Cognition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15851，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15851&send_immediately=true&force_search=false)

**原文摘要:** As Large Language Models (LLMs) continue to advance, they exhibit certain
cognitive patterns similar to those of humans that are not directly specified
in training data. This study investigates this phenomenon by focusing on
temporal cognition in LLMs. Leveraging the similarity judgment task, we find
that larger models spontaneously establish a subjective temporal reference
point and adhere to the Weber-Fechner law, whereby the perceived distance
logarithmically compresses as years recede from this reference point. To
uncover the mechanisms behind this behavior, we conducted multiple analyses
across neuronal, representational, and informational levels. We first identify
a set of temporal-preferential neurons and find that this group exhibits
minimal activation at the subjective reference point and implements a
logarithmic coding scheme convergently found in biological systems. Probing
representations of years reveals a hierarchical construction process, where
years evolve from basic numerical values in shallow layers to abstract temporal
orientation in deep layers. Finally, using pre-trained embedding models, we
found that the training corpus itself possesses an inherent, non-linear
temporal structure, which provides the raw material for the model's internal
construction. In discussion, we propose an experientialist perspective for
understanding these findings, where the LLMs' cognition is viewed as a
subjective construction of the external world by its internal representational
system. This nuanced perspective implies the potential emergence of alien
cognitive frameworks that humans cannot intuitively predict, pointing toward a
direction for AI alignment that focuses on guiding internal constructions. Our
code is available at https://TheOtherMind.github.io.

</details>


### [186] [Gemini 2.5 Pro Capable of Winning Gold at IMO 2025](https://arxiv.org/abs/2507.15855)
*Yichen Huang, Lin F. Yang*

**主要类别:** cs.AI

**AI概要:** 研究使用了Google的Gemini 2.5 Pro解决了新发布的2025年国际数学奥林匹克竞赛中的5个（共6个）问题，强调了找到使用强大模型的最佳方法的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型在解决像AIME这样的数学基准测试中表现出色，但在处理需要深度见解、创造力和形式推理的奥林匹克级别的任务时却遇到了困难。因此，研究者们希望探索更强大的模型能否克服这些挑战。

**方法:** 研究者使用了Google的Gemini 2.5 Pro来解决新发布的2025年国际数学奥林匹克竞赛的问题，并通过管道设计和提示工程避免数据污染。

**结果:** 成功解决了6个问题中的5个，证明了使用强大的模型和正确的技术可以提高解决高难度数学问题的能力。

**结论:** 这项研究表明，找到使用强大模型的最佳方法对于解决复杂的数学问题至关重要。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Gemini+2.5+Pro+Capable+of+Winning+Gold+at+IMO+2025，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15855，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15855&send_immediately=true&force_search=false)

**原文摘要:** The International Mathematical Olympiad (IMO) poses uniquely challenging
problems requiring deep insight, creativity, and formal reasoning. While Large
Language Models (LLMs) perform well on mathematical benchmarks like AIME, they
struggle with Olympiad-level tasks. We use Google's Gemini 2.5 Pro on the newly
released IMO 2025 problems, avoiding data contamination. With pipeline design
and prompt engineering, 5 (out of 6) problems are solved correctly (up to a
caveat discussed below), highlighting the importance of finding the optimal way
of using powerful models.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [187] [DM-RSA: An Extension of RSA with Dual Modulus](https://arxiv.org/abs/2507.14197)
*Andriamifidisoa Ramamonjy, Rufine Marius Lalasoa*

**主要类别:** cs.CR

**AI概要:** DM-RSA是一种改进的RSA密码系统，采用两个不同的模数并利用中国剩余定理进行解密，以提高安全性和效率。


<details>
  <summary>更多</summary>
  
**动机:** 传统的RSA加密系统在面对侧信道攻击时可能存在安全性不足的问题，同时为了提升对部分模数泄露的抵抗力，并且不损失原有的效率。

**方法:** DM-RSA通过引入两个不同的模数对称地增强安全性，并使用中国剩余定理来进行解密操作。这种方式提高了对侧信道攻击的稳健性，并保留了经典RSA的效率。

**结果:** DM-RSA不仅增强了系统的安全性，能够更好地抵抗侧信道攻击和部分模数泄露的风险，而且可以无缝集成到现有的基础设施中。

**结论:** DM-RSA作为一种新的变体，提供了一种在不影响效率的前提下，提升RSA加密系统安全性的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DM-RSA%3A+An+Extension+of+RSA+with+Dual+Modulus，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14197，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14197&send_immediately=true&force_search=false)

**原文摘要:** We introduce DM-RSA (Dual Modulus RSA), a variant of the RSA cryptosystem
that employs two distinct moduli symmetrically to enhance security. By
leveraging the Chinese Remainder Theorem (CRT) for decryption, DM-RSA provides
increased robustness against side-channel attacks while preserving the
efficiency of classical RSA. This approach improves resistance to partial
compromise of a modulus and integrates easily into existing infrastructures.

</details>


### [188] [ExCyTIn-Bench: Evaluating LLM agents on Cyber Threat Investigation](https://arxiv.org/abs/2507.14201)
*Yiran Wu, Mauricio Velazco, Andrew Zhao, Manuel Raúl Meléndez Luján, Srisuma Movva, Yogesh K Roy, Quang Nguyen, Roberto Rodriguez, Qingyun Wu, Michael Albada, Julia Kiseleva, Anand Mudgerikar*

**主要类别:** cs.CR

**AI概要:** 提出了ExCyTIn-Bench，一个评估LLM代理在网络安全威胁调查任务中的基准测试。通过模拟现实世界的攻击和日志，生成了589个自动问题，以评估和训练LLM代理进行威胁调查的能力。实验显示任务具有挑战性，平均奖励仅为0.249，最佳为0.368，未来有改进空间。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型语言模型（LLMs）的发展，建立基于LLM的代理来进行自动化的网络威胁调查是一个有前景的方向。然而，缺乏合适的基准来评估这些代理的有效性。

**方法:** 构建了一个来自受控Azure租户的数据集，包括8次模拟的真实世界多步骤攻击、57个日志表和589个自动生成的问题。使用专家编写的检测逻辑提取安全日志，建立威胁调查图，并利用配对节点生成问题。

**结果:** 实验表明，即使是最先进的模型也难以完成此任务，所有评估模型的平均奖励仅为0.249，最佳模型的奖励为0.368。

**结论:** ExCyTIn-Bench提供了一个新的平台用于评估和训练LLM代理进行网络安全威胁调查，虽然目前的结果显示任务非常具有挑战性，但为未来的研究留下了很大的改进空间。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ExCyTIn-Bench%3A+Evaluating+LLM+agents+on+Cyber+Threat+Investigation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14201，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14201&send_immediately=true&force_search=false)

**原文摘要:** We present ExCyTIn-Bench, the first benchmark to Evaluate an LLM agent x on
the task of Cyber Threat Investigation through security questions derived from
investigation graphs. Real-world security analysts must sift through a large
number of heterogeneous alert signals and security logs, follow multi-hop
chains of evidence, and compile an incident report. With the developments of
LLMs, building LLM-based agents for automatic thread investigation is a
promising direction. To assist the development and evaluation of LLM agents, we
construct a dataset from a controlled Azure tenant that covers 8 simulated
real-world multi-step attacks, 57 log tables from Microsoft Sentinel and
related services, and 589 automatically generated questions. We leverage
security logs extracted with expert-crafted detection logic to build threat
investigation graphs, and then generate questions with LLMs using paired nodes
on the graph, taking the start node as background context and the end node as
answer. Anchoring each question to these explicit nodes and edges not only
provides automatic, explainable ground truth answers but also makes the
pipeline reusable and readily extensible to new logs. This also enables the
automatic generation of procedural tasks with verifiable rewards, which can be
naturally extended to training agents via reinforcement learning. Our
comprehensive experiments with different models confirm the difficulty of the
task: with the base setting, the average reward across all evaluated models is
0.249, and the best achieved is 0.368, leaving substantial headroom for future
research. Code and data are coming soon!

</details>


### [189] [PRM-Free Security Alignment of Large Models via Red Teaming and Adversarial Training](https://arxiv.org/abs/2507.14202)
*Pengfei Du*

**主要类别:** cs.CR

**AI概要:** 本文提出了一种新的无需PRM的安全对齐框架，通过自动红队测试和对抗训练，在保持计算效率的同时提供强大的安全保证。该方法在五个最先进的大语言模型上进行了广泛的实验评估，显示出比基于PRM的方法更好的安全性能，并将计算成本降低了61％。


<details>
  <summary>更多</summary>
  
**动机:** 当前的安全对齐方法主要依赖于过程奖励模型（PRMs），这引入了大量的计算开销和可扩展性限制。为了克服这些挑战并确保大型语言模型（LLMs）可以在关键领域安全部署，需要一种更高效且稳健的方法。

**方法:** 该研究开发了一个不使用PRM的安全对齐框架，利用自动化红队测试、对抗训练、遗传算法优化、多代理模拟和高级提示变异技术来识别漏洞。并通过带有课程学习和自适应正则化机制的针对性对抗训练提高模型的鲁棒性。

**结果:** 实验结果表明，所提出的方法不仅实现了比基于PRM的方法更优的安全对齐性能，还减少了61%的计算成本。此外，该框架包括透明报告和持续审计机制，有助于迭代安全改进和法规遵从。

**结论:** 这项工作推进了高效LLM安全对齐领域的进步，为资源有限的组织提供了获得强大安全措施的机会，并为应对不断变化的对抗威胁建立了可扩展的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PRM-Free+Security+Alignment+of+Large+Models+via+Red+Teaming+and+Adversarial+Training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14202，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14202&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse applications, yet they pose significant security risks that threaten
their safe deployment in critical domains. Current security alignment
methodologies predominantly rely on Process Reward Models (PRMs) to evaluate
intermediate reasoning steps, introducing substantial computational overhead
and scalability constraints. This paper presents a novel PRM-free security
alignment framework that leverages automated red teaming and adversarial
training to achieve robust security guarantees while maintaining computational
efficiency. Our approach systematically identifies vulnerabilities through
sophisticated attack strategies including genetic algorithm optimization,
multi-agent simulation, and advanced prompt mutation techniques. The framework
enhances model robustness via targeted adversarial training with curriculum
learning and adaptive regularization mechanisms. Comprehensive experimental
evaluation across five state-of-the-art LLMs demonstrates that our method
achieves superior security alignment performance compared to PRM-based
approaches while reducing computational costs by 61\%. The framework
incorporates transparent reporting and continuous audit mechanisms that enable
iterative security improvement and regulatory compliance. Our contributions
advance the field of efficient LLM security alignment by democratizing access
to robust security measures for resource-constrained organizations and
providing a scalable foundation for addressing evolving adversarial threats.

</details>


### [190] [Mitigating Trojanized Prompt Chains in Educational LLM Use Cases: Experimental Findings and Detection Tool Design](https://arxiv.org/abs/2507.14207)
*Richard M. Charles, James H. Curry, Richard B. Charles*

**主要类别:** cs.CR

**AI概要:** 研究发现大语言模型在K-12教育中的风险，并提出一个原型工具TrojanPromptGuard以自动检测和减轻特洛伊化教育提示。


<details>
  <summary>更多</summary>
  
**动机:** 探索学生如何可能通过特洛伊化提示从大型语言模型中引出不安全或非预期的输出，绕过已建立的内容调节系统。

**方法:** 通过涉及模拟K-12查询和多轮对话的系统实验，揭示GPT-3.5和GPT-4的关键漏洞。

**结果:** 暴露了GPT-3.5和GPT-4的关键漏洞，并提出了一个原型工具TrojanPromptGuard (TPG)。

**结论:** 本研究旨在为AI安全研究人员和教育技术专家提供关于LLMs在教育领域安全部署的信息。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mitigating+Trojanized+Prompt+Chains+in+Educational+LLM+Use+Cases%3A+Experimental+Findings+and+Detection+Tool+Design，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14207，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14207&send_immediately=true&force_search=false)

**原文摘要:** The integration of Large Language Models (LLMs) in K--12 education offers
both transformative opportunities and emerging risks. This study explores how
students may Trojanize prompts to elicit unsafe or unintended outputs from
LLMs, bypassing established content moderation systems with safety guardrils.
Through a systematic experiment involving simulated K--12 queries and
multi-turn dialogues, we expose key vulnerabilities in GPT-3.5 and GPT-4. This
paper presents our experimental design, detailed findings, and a prototype
tool, TrojanPromptGuard (TPG), to automatically detect and mitigate Trojanized
educational prompts. These insights aim to inform both AI safety researchers
and educational technologists on the safe deployment of LLMs for educators.

</details>


### [191] [Secure Goal-Oriented Communication: Defending against Eavesdropping Timing Attacks](https://arxiv.org/abs/2507.14212)
*Federico Mason, Federico Chiariotti, Pietro Talli, Andrea Zanella*

**主要类别:** cs.CR

**AI概要:** 本文研究了针对基于拉取的目标导向调度的窃听攻击，并提出两种实用的启发式防御方法，可以在减少信息泄露的同时，保持目标导向通信的优势。


<details>
  <summary>更多</summary>
  
**动机:** GoC（目标导向通信）虽然可以显著降低传输频率并维持接收者的客观需求，但它也引入了一个基于时间的侧信道，使窃听者能获得系统状态的信息。这种攻击绕过了传统信息安全措施，因为它是利用更新的时间而非内容。因此，需要研究如何抵御此类攻击。

**方法:** 作者提供了一个理论框架来定义攻击的有效性，并提出了可能的对策，包括两种实践启发式方法，这些方法在GoC提供的性能增益和泄露信息量之间提供了平衡。

**结果:** 结果表明，天真的目标导向调度器允许窃听者正确猜测系统状态约60%的时间，而启发式防御方法可以将泄露信息减少一半，同时对GoC优势的影响很小。

**结论:** 尽管GoC带来了新的安全挑战，但通过适当的防御策略，可以在保持其性能优势的同时，有效地减少信息泄露。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Secure+Goal-Oriented+Communication%3A+Defending+against+Eavesdropping+Timing+Attacks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14212，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14212&send_immediately=true&force_search=false)

**原文摘要:** Goal-oriented Communication (GoC) is a new paradigm that plans data
transmission to occur only when it is instrumental for the receiver to achieve
a certain goal. This leads to the advantage of reducing the frequency of
transmissions significantly while maintaining adherence to the receiver's
objectives. However, GoC scheduling also opens a timing-based side channel that
an eavesdropper can exploit to obtain information about the state of the
system. This type of attack sidesteps even information-theoretic security, as
it exploits the timing of updates rather than their content. In this work, we
study such an eavesdropping attack against pull-based goal-oriented scheduling
for remote monitoring and control of Markov processes. We provide a theoretical
framework for defining the effectiveness of the attack and propose possible
countermeasures, including two practical heuristics that provide a balance
between the performance gains offered by GoC and the amount of leaked
information. Our results show that, while a naive goal-oriented scheduler
allows the eavesdropper to correctly guess the system state about 60% of the
time, our heuristic defenses can halve the leakage with a marginal reduction of
the benefits of goal-oriented approaches.

</details>


### [192] [Magneto-Ionic Hardware Security Primitives: Embedding Data Protection at the Material Level](https://arxiv.org/abs/2507.14213)
*Irena Spasojevic, Federica Celegato, Alessandro Magni, Paola Tiberto, Jordi Sort*

**主要类别:** cs.CR

**AI概要:** 本文提出了一种基于磁离子策略的硬件级安全方法，利用可控电压N3-离子迁移和铁磁亚层实现多种磁状态，形成丰富的磁指纹平台。该方法支持自保护原语、随机数生成器和不可克隆功能等，并具有低能耗、可重构性和扩展性，为下一代硬件安全提供了重要进展。


<details>
  <summary>更多</summary>
  
**动机:** 大数据革命提高了对稳健、节能的安全硬件的需求，传统加密方案资源密集且存在漏洞，社会需要创新的反黑客和反伪造技术。

**方法:** 使用完全选择性的电压控制N3-离子在预先定义的初始顺磁性FeCoN点内迁移，生成厚度可调的铁磁亚层，形成确定性或概率性的磁状态。

**结果:** 实现了自保护原语、真正的随机数生成器、物理不可克隆函数和内存中概率推理，架构具备抗篡改性、低能耗和可扩展性。

**结论:** 这项研究标志着向基于新兴磁现象的新一代硬件安全迈出的重要一步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Magneto-Ionic+Hardware+Security+Primitives%3A+Embedding+Data+Protection+at+the+Material+Level，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14213，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14213&send_immediately=true&force_search=false)

**原文摘要:** The Big Data revolution has heightened the demand for robust,
energy-efficient security hardware capable of withstanding increasingly
sophisticated cyber threats. Conventional encryption schemes, reliant on
complex algorithms, are resource-intensive and remain vulnerable. To fortify
sensitive information, society needs innovative anti-hacking and
anti-counterfeiting technologies that exploit new materials and designs. Here,
we present a magneto-ionic strategy for hardware-level security based on fully
selective voltage-controlled N3- ion migration within pre-defined, initially
paramagnetic FeCoN dots. This process generates ferromagnetic sublayers of
tuneable thickness, resulting in either deterministic (single-domain or vortex)
or probabilistic states (with coexisting magnetic configurations and
voltage-adjustable probabilities), each exhibiting stochastic orientation and
chirality, thereby providing a rich platform for magnetic fingerprinting. This
approach enables self-protected primitives, including true random number
generators, physical unclonable functions, and in-memory probabilistic
inference. The resulting reconfigurable architecture combines tamper
resistance, low energy consumption, and scalability, marking a significant leap
toward next-generation hardware security rooted in emergent magnetic phenomena.

</details>


### [193] [GPU-Accelerated Interpretable Generalization for Rapid Cyberattack Detection and Forensics](https://arxiv.org/abs/2507.14222)
*Shu-Ting Huang, Wen-Cheng Chung, Hao-Ting Pai*

**主要类别:** cs.CR

**AI概要:** 本文介绍了IG-GPU，一种在商品GPU上重新架构的PyTorch实现，用于加速Interpretable Generalization机制。实验结果表明，IG-GPU在处理大规模数据集时比多核CPU快116倍，并且具有高召回率、精确率和AUC值。


<details>
  <summary>更多</summary>
  
**动机:** Interpretable Generalization（IG）机制虽然可以提供基于证据的入侵检测，但其时间复杂度为立方级别，庞大的中间位图使得全规模数据集在CPU上的处理变得不切实际。因此需要一个更高效的实现方式来处理大规模数据集。

**方法:** 作者提出了IG-GPU，将所有成对交集和子集评估卸载到商品GPU上，使用PyTorch重新构建了IG算法。通过这种方式，实现了显著的速度提升并能够处理更大规模的数据集。

**结果:** 在NSL-KDD数据集上，IG-GPU比多核CPU实现的IG速度快116倍，同时在完整规模的数据集上取得了更高的Recall、Precision和AUC值。此外，IG-GPU能够在模式学习后提供毫秒级别的流推理。

**结论:** IG-GPU不仅提高了处理速度，还保持了高准确性和可解释性，为未来关于硬件感知调度、多GPU分片和数据集特定稀疏优化的工作提供了便携的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GPU-Accelerated+Interpretable+Generalization+for+Rapid+Cyberattack+Detection+and+Forensics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14222，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14222&send_immediately=true&force_search=false)

**原文摘要:** The Interpretable Generalization (IG) mechanism recently published in IEEE
Transactions on Information Forensics and Security delivers state-of-the-art,
evidence-based intrusion detection by discovering coherent normal and attack
patterns through exhaustive intersect-and-subset operations-yet its cubic-time
complexity and large intermediate bitsets render full-scale datasets
impractical on CPUs. We present IG-GPU, a PyTorch re-architecture that offloads
all pairwise intersections and subset evaluations to commodity GPUs.
Implemented on a single NVIDIA RTX 4070 Ti, in the 15k-record NSL-KDD dataset,
IG-GPU shows a 116-fold speed-up over the multi-core CPU implementation of IG.
In the full size of NSL-KDD (148k-record), given small training data (e.g.,
10%-90% train-test split), IG-GPU runs in 18 minutes with Recall 0.957,
Precision 0.973, and AUC 0.961, whereas IG required down-sampling to
15k-records to avoid memory exhaustion and obtained Recall 0.935, Precision
0.942, and AUC 0.940. The results confirm that IG-GPU is robust across scales
and could provide millisecond-level per-flow inference once patterns are
learned. IG-GPU thus bridges the gap between rigorous interpretability and
real-time cyber-defense, offering a portable foundation for future work on
hardware-aware scheduling, multi-GPU sharding, and dataset-specific sparsity
optimizations.

</details>


### [194] [Multi-Granular Discretization for Interpretable Generalization in Precise Cyberattack Identification](https://arxiv.org/abs/2507.14223)
*Wen-Cheng Chung, Shu-Ting Huang, Hao-Ting Pai*

**主要类别:** cs.CR

**AI概要:** 论文提出了一种新的可解释入侵检测系统机制IG-MD，提高了精度而不牺牲透明度。


<details>
  <summary>更多</summary>
  
**动机:** 现有的XAI管道提供的见解不完整且有时具有误导性，因此需要一种更有效的机制来提供全面和准确的见解。

**方法:** 引入了多粒度离散化（IG-MD）方法，该方法以多种高斯分辨率表示每个连续特征，并将其应用于解释性泛化机制中。

**结果:** 在UKM-IDS20数据集上，IG-MD将精度提高了至少4个百分点，同时保持召回率接近1.0。

**结论:** IG-MD模型可以在不同领域中扩展，而无需专门调整。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Granular+Discretization+for+Interpretable+Generalization+in+Precise+Cyberattack+Identification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14223，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14223&send_immediately=true&force_search=false)

**原文摘要:** Explainable intrusion detection systems (IDS) are now recognized as essential
for mission-critical networks, yet most "XAI" pipelines still bolt an
approximate explainer onto an opaque classifier, leaving analysts with partial
and sometimes misleading insights. The Interpretable Generalization (IG)
mechanism, published in IEEE Transactions on Information Forensics and
Security, eliminates that bottleneck by learning coherent patterns - feature
combinations unique to benign or malicious traffic - and turning them into
fully auditable rules. IG already delivers outstanding precision, recall, and
AUC on NSL-KDD, UNSW-NB15, and UKM-IDS20, even when trained on only 10% of the
data. To raise precision further without sacrificing transparency, we introduce
Multi-Granular Discretization (IG-MD), which represents every continuous
feature at several Gaussian-based resolutions. On UKM-IDS20, IG-MD lifts
precision by greater than or equal to 4 percentage points across all nine
train-test splits while preserving recall approximately equal to 1.0,
demonstrating that a single interpretation-ready model can scale across domains
without bespoke tuning.

</details>


### [195] [Using Modular Arithmetic Optimized Neural Networks To Crack Affine Cryptographic Schemes Efficiently](https://arxiv.org/abs/2507.14229)
*Vanja Stojanović, Žiga Lesar, CIril Bohak*

**主要类别:** cs.CR

**AI概要:** 该研究提出了一种结合了模算术感知和统计特征学习的混合神经网络架构，用于仿射密码的密码分析。实验表明，对于短到中等长度的密文，该模型在密钥恢复准确性方面优于纯统计方法；但对于非常长的密文，性能有所下降。


<details>
  <summary>更多</summary>
  
**动机:** 受到可解释神经网络在模算术和经典密码神经密码分析方面最新进展的启发，研究者希望利用混合神经网络结构来改进对仿射密码的密码分析。

**方法:** 通过将处理原始密文序列的模分支和利用字母频率特征的统计分支相结合，该方法采用了一种混合神经网络架构来进行仿射密码的密码分析。

**结果:** 实验结果表明，该模型在自然英语文本数据集上对短到中等长度的密文实现了高密钥恢复准确性，超过了纯统计方法的效果。但是，对于非常长的密文，性能表现较差。

**结论:** 虽然所提出的混合模型在短到中等长度的密文上有很好的表现，但其在长密文上的表现不佳，说明了模型泛化能力面临的挑战。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Using+Modular+Arithmetic+Optimized+Neural+Networks+To+Crack+Affine+Cryptographic+Schemes+Efficiently，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14229，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14229&send_immediately=true&force_search=false)

**原文摘要:** We investigate the cryptanalysis of affine ciphers using a hybrid neural
network architecture that combines modular arithmetic-aware and statistical
feature-based learning. Inspired by recent advances in interpretable neural
networks for modular arithmetic and neural cryptanalysis of classical ciphers,
our approach integrates a modular branch that processes raw ciphertext
sequences and a statistical branch that leverages letter frequency features.
Experiments on datasets derived from natural English text demonstrate that the
hybrid model attains high key recovery accuracy for short and moderate
ciphertexts, outperforming purely statistical approaches for the affine cipher.
However, performance degrades for very long ciphertexts, highlighting
challenges in model generalization.

</details>


### [196] [Breaking the Illusion of Security via Interpretation: Interpretable Vision Transformer Systems under Attack](https://arxiv.org/abs/2507.14248)
*Eldor Abdukhamidov, Mohammed Abuhamad, Simon S. Woo, Hyoungshick Kim, Tamer Abuhmed*

**主要类别:** cs.CR

**AI概要:** 本研究提出了一种名为“AdViT”的攻击方法，该方法可以在白盒和黑盒场景中以100%的成功率误导视觉转换器模型及其解释模型，同时生成难以检测的对抗样本。


<details>
  <summary>更多</summary>
  
**动机:** 尽管视觉转换器（ViT）模型结合解释模型被认为是安全且难以欺骗的，但针对这些系统的成功攻击可能导致严重后果。目前的研究主要集中在生成最小的对抗性扰动上，而忽略了对模型解释的影响。因此，需要研究当结合解释模型时，变压器模型对对抗攻击的脆弱性。

**方法:** 研究人员提出了一个叫做“AdViT”的攻击方法，该方法可以生成能够误导给定的变压器模型及其耦合的解释模型的对抗样本。通过在各种变压器模型和两个基于变压器的解释器上进行广泛实验，证明了AdViT的有效性。

**结果:** AdViT在白盒和黑盒场景中均实现了100%的攻击成功率。在白盒场景中，它达到了高达98%的错误分类置信度，而在黑盒场景中，这一数字为76%。值得注意的是，AdViT在这两种场景下都能一致地生成准确的解释，使对抗样本更难被检测。

**结论:** 这项研究表明，即使结合了解释模型，视觉转换器模型仍然容易受到对抗攻击的影响。这强调了开发更加健壮的安全机制的重要性，以保护关键领域中的AI系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Breaking+the+Illusion+of+Security+via+Interpretation%3A+Interpretable+Vision+Transformer+Systems+under+Attack，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14248，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14248&send_immediately=true&force_search=false)

**原文摘要:** Vision transformer (ViT) models, when coupled with interpretation models, are
regarded as secure and challenging to deceive, making them well-suited for
security-critical domains such as medical applications, autonomous vehicles,
drones, and robotics. However, successful attacks on these systems can lead to
severe consequences. Recent research on threats targeting ViT models primarily
focuses on generating the smallest adversarial perturbations that can deceive
the models with high confidence, without considering their impact on model
interpretations. Nevertheless, the use of interpretation models can effectively
assist in detecting adversarial examples. This study investigates the
vulnerability of transformer models to adversarial attacks, even when combined
with interpretation models. We propose an attack called "AdViT" that generates
adversarial examples capable of misleading both a given transformer model and
its coupled interpretation model. Through extensive experiments on various
transformer models and two transformer-based interpreters, we demonstrate that
AdViT achieves a 100% attack success rate in both white-box and black-box
scenarios. In white-box scenarios, it reaches up to 98% misclassification
confidence, while in black-box scenarios, it reaches up to 76%
misclassification confidence. Remarkably, AdViT consistently generates accurate
interpretations in both scenarios, making the adversarial examples more
difficult to detect.

</details>


### [197] [Quantum-Safe Identity Verification using Relativistic Zero-Knowledge Proof Systems](https://arxiv.org/abs/2507.14324)
*Yao Ma, Wen Yu Kon, Jefferson Chu, Kevin Han Yong Loh, Kaushik Chakraborty, Charles Lim*

**主要类别:** cs.CR

**AI概要:** 本文通过改进图着色基础的相对论零知识证明协议，解决了身份验证中的安全问题，包括减少相对论约束、增强稳定性和可扩展性，并提出了针对纠缠恶意验证者的修改协议。


<details>
  <summary>更多</summary>
  
**动机:** 当前基于密码/个人识别码的身份验证解决方案容易受到网络钓鱼或窃取攻击。为了解决这些问题，Alikhani等人开始探索使用基于图着色的相对论零知识证明进行身份验证的方法。

**方法:** 研究人员从工程角度进一步放松了相对论约束条件，增强了2-验证者图着色基础的RZKP协议的稳定性和可扩展性；提出了具有可比计算和通信成本的修改协议；还将两验证者设置扩展到三验证者配置。

**结果:** 该研究显著提高了实验演示的稳定性与可扩展性，将相对论约束从60米降低到30米，并证明了修改后的协议在长期安全性方面对纠缠恶意验证者的安全性。

**结论:** 这些改进使基于图着色的相对论零知识证明更接近实用化，同时提供了更强的安全性保障，特别是对于未来可能遇到的量子计算威胁。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Quantum-Safe+Identity+Verification+using+Relativistic+Zero-Knowledge+Proof+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14324，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14324&send_immediately=true&force_search=false)

**原文摘要:** Identity verification is the process of confirming an individual's claimed
identity, which is essential in sectors like finance, healthcare, and online
services to ensure security and prevent fraud. However, current
password/PIN-based identity solutions are susceptible to phishing or skimming
attacks, where malicious intermediaries attempt to steal credentials using fake
identification portals. Alikhani et al. [Nature, 2021] began exploring identity
verification through graph coloring-based relativistic zero-knowledge proofs
(RZKPs), a key cryptographic primitive that enables a prover to demonstrate
knowledge of secret credentials to a verifier without disclosing any
information about the secret. Our work advances this field and addresses
unresolved issues: From an engineering perspective, we relax further the
relativistic constraints from 60m to 30m, and significantly enhance the
stability and scalability of the experimental demonstration of the 2-prover
graph coloring-based RZKP protocol for near-term use cases. At the same time,
for long-term security against entangled malicious provers, we propose a
modified protocol with comparable computation and communication costs, we
establish an upper bound on the soundness parameter for this modified protocol.
On the other hand, we extend the two-prover, two-verifier setup to a
three-prover configuration, demonstrating the security of such relativistic
protocols against entangled malicious provers.

</details>


### [198] [Towards Efficient Privacy-Preserving Machine Learning: A Systematic Review from Protocol, Model, and System Perspectives](https://arxiv.org/abs/2507.14519)
*Wenxuan Zeng, Tianshi Xu, Yi Chen, Yifan Zhou, Mingzhe Zhang, Jin Tan, Cheng Hong, Meng Li*

**主要类别:** cs.CR

**AI概要:** 这篇综述文章全面系统地回顾了基于密码协议的隐私保护机器学习（PPML）的研究，特别关注跨层优化，并按协议层、模型层和系统层分类。


<details>
  <summary>更多</summary>
  
**动机:** 隐私保护机器学习虽然实现了正式的隐私保护，但其效率和可扩展性成本显著高于明文方案。因此，缩小PPML的效率差距成为研究重点。

**方法:** 文章将现有研究分为三个层面：协议层、模型层和系统层，并在每个层面上回顾进展。此外，还提供现有工作的定性和定量比较，并讨论未来的研究方向。

**结果:** 通过综合分析，该综述为现有的PPML方法提供了全面的理解，强调了跨协议、模型和系统层面整合优化的必要性。

**结论:** 作者希望该综述能启发PPML领域的未来突破，并建立了一个公共GitHub仓库以持续跟踪领域发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Efficient+Privacy-Preserving+Machine+Learning%3A+A+Systematic+Review+from+Protocol%2C+Model%2C+and+System+Perspectives，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14519，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14519&send_immediately=true&force_search=false)

**原文摘要:** Privacy-preserving machine learning (PPML) based on cryptographic protocols
has emerged as a promising paradigm to protect user data privacy in cloud-based
machine learning services. While it achieves formal privacy protection, PPML
often incurs significant efficiency and scalability costs due to orders of
magnitude overhead compared to the plaintext counterpart. Therefore, there has
been a considerable focus on mitigating the efficiency gap for PPML. In this
survey, we provide a comprehensive and systematic review of recent PPML studies
with a focus on cross-level optimizations. Specifically, we categorize existing
papers into protocol level, model level, and system level, and review progress
at each level. We also provide qualitative and quantitative comparisons of
existing works with technical insights, based on which we discuss future
research directions and highlight the necessity of integrating optimizations
across protocol, model, and system levels. We hope this survey can provide an
overarching understanding of existing approaches and potentially inspire future
breakthroughs in the PPML field. As the field is evolving fast, we also provide
a public GitHub repository to continuously track the developments, which is
available at https://github.com/PKU-SEC-Lab/Awesome-PPML-Papers.

</details>


### [199] [FORTA: Byzantine-Resilient FL Aggregation via DFT-Guided Krum](https://arxiv.org/abs/2507.14588)
*Usayd Shahul, J. Harshan*

**主要类别:** cs.CR

**AI概要:** 提出了一种名为FORTA的拜占庭弹性安全聚合框架，该框架完全在实数域中操作，并通过改进Krum算法来提高鲁棒性和准确性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的拜占庭弹性安全聚合方案在应用于实值模型更新时可能会出现数值错误和溢出问题，需要一种直接在实数域中操作的安全聚合方法。

**方法:** FORTA利用离散傅里叶变换（DFT）代码进行隐私保护，并采用基于Krum的异常检测来进行鲁棒性保护。此外，FORTA还通过来自DFT解码器的反馈改进了Krum算法。

**结果:** 理论分析和实验表明，FORTA对Krum的修改提供了比标准Krum更好的鲁棒性和更准确的聚合。

**结论:** FORTA作为一个新的拜占庭弹性安全聚合框架，解决了现有方法在实值模型更新中的数值问题，并提高了聚合的准确性和鲁棒性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FORTA%3A+Byzantine-Resilient+FL+Aggregation+via+DFT-Guided+Krum，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14588，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14588&send_immediately=true&force_search=false)

**原文摘要:** Secure federated learning enables collaborative model training across
decentralized users while preserving data privacy. A key component is secure
aggregation, which keeps individual updates hidden from both the server and
users, while also defending against Byzantine users who corrupt the
aggregation. To this end, Jinhyun So et al. recently developed a
Byzantine-resilient secure aggregation scheme using a secret-sharing strategy
over finite-field arithmetic. However, such an approach can suffer from
numerical errors and overflows when applied to real-valued model updates,
motivating the need for secure aggregation methods that operate directly over
the real domain. We propose FORTA, a Byzantine-resilient secure aggregation
framework that operates entirely in the real domain. FORTA leverages Discrete
Fourier Transform (DFT) codes for privacy and employs Krum-based outlier
detection for robustness. While DFT decoder is error-free under infinite
precision, finite precision introduces numerical perturbations that can distort
distance estimates and allow malicious updates to evade detection. To address
this, FORTA refines Krum using feedback from DFT decoder, improving the
selection of trustworthy updates. Theoretical analysis and experiments show
that our modification of Krum offers improved robustness and more accurate
aggregation than standard Krum.

</details>


### [200] [Hybrid Classical-Quantum Rainbow Table Attack on Human Passwords](https://arxiv.org/abs/2507.14600)
*MA. Khajeian*

**主要类别:** cs.CR

**AI概要:** 本文提出了一种增强的经典-量子混合攻击方法，通过构建基于字典的彩虹表和使用改进的Grover算法来提高密码恢复效率。


<details>
  <summary>更多</summary>
  
**动机:** 长且由人类生成的密码由于其不规则结构和庞大的搜索空间，对经典和量子攻击都构成了挑战。为了解决这一问题，需要一种更高效的攻击方式。

**方法:** 该研究首先创建了基于字典的彩虹表，并应用转换规则以模拟真实用户的密码生成行为。然后将这些表组织成桶，以便更快查找并减少空间复杂度。在每个桶内执行量子搜索时，使用分布式精确版Grover算法，提供较低的电路深度和确定性的成功。

**结果:** 这种方法使得整体量子电路更浅，增强了对抗噪声的能力，特别是在近期量子设备中常见的去极化通道。

**结论:** 研究提出了一个结合结构化的彩虹表与高效的量子搜索的混合框架，以增强密码恢复能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Hybrid+Classical-Quantum+Rainbow+Table+Attack+on+Human+Passwords，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14600，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14600&send_immediately=true&force_search=false)

**原文摘要:** Passwords that are long and human-generated pose a challenge for both
classical and quantum attacks due to their irregular structure and large search
space. In this work, we present an enhanced classical-quantum hybrid attack
tailored to this scenario. We build rainbow tables using dictionary-based
password generation with transformation rules to better model real user
behavior. These tables are then organized into buckets, enabling faster lookup
and reduced space complexity. To perform quantum search within each bucket, we
use a distributed exact variant of Grover's algorithm, which offers lower
circuit depth and deterministic success. As a result, the overall quantum
circuit is shallower and more robust against noise, particularly from
depolarizing channels commonly found in near-term quantum devices. Through this
work, Overall, we propose a hybrid framework that combines structured rainbow
tables with efficient quantum search to enhance password recovery.

</details>


### [201] [VTarbel: Targeted Label Attack with Minimal Knowledge on Detector-enhanced Vertical Federated Learning](https://arxiv.org/abs/2507.14625)
*Juntao Tan, Anran Li, Quanchao Liu, Peng Ran, Lan Zhang*

**主要类别:** cs.CR

**AI概要:** 本文提出了一种名为VTarbel的新型攻击框架，该框架能够在垂直联合学习中进行目标标签攻击并逃避检测。实验结果表明，VTarbel在各种设置下均优于现有方法，并揭示了当前VFL部署中的安全盲点。


<details>
  <summary>更多</summary>
  
**动机:** 尽管垂直联合学习（VFL）的隐私漏洞已经被广泛研究，但其安全威胁，特别是目标标签攻击，仍然没有得到充分探索。现有的方法依赖于不切实际的假设，并且忽略了现实系统中部署的异常检测器。

**方法:** VTarbel是一个两阶段的最小知识攻击框架，专门设计用于逃避增强型VFL推理中的检测器。准备阶段选择高表达性的样本，收集预测标签，并用这些伪标签训练估计的检测器和代理模型。攻击阶段使用这些模型指导基于梯度的扰动，制造能够诱导目标误分类并逃避检测的对抗实例。

**结果:** 通过实施VTarbel并对四种模型架构、七个多模态数据集和两种异常检测器进行评估，结果显示VTarbel在所有设置下都优于四个最先进的基线方法，能够逃避检测，并对三种代表性的隐私保护防御措施保持有效。

**结论:** 实验结果揭示了当前VFL部署中的关键安全盲点，并强调了迫切需要开发强大的、针对攻击的防御措施。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是VTarbel%3A+Targeted+Label+Attack+with+Minimal+Knowledge+on+Detector-enhanced+Vertical+Federated+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14625，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14625&send_immediately=true&force_search=false)

**原文摘要:** Vertical federated learning (VFL) enables multiple parties with disjoint
features to collaboratively train models without sharing raw data. While
privacy vulnerabilities of VFL are extensively-studied, its security
threats-particularly targeted label attacks-remain underexplored. In such
attacks, a passive party perturbs inputs at inference to force
misclassification into adversary-chosen labels. Existing methods rely on
unrealistic assumptions (e.g., accessing VFL-model's outputs) and ignore
anomaly detectors deployed in real-world systems. To bridge this gap, we
introduce VTarbel, a two-stage, minimal-knowledge attack framework explicitly
designed to evade detector-enhanced VFL inference. During the preparation
stage, the attacker selects a minimal set of high-expressiveness samples (via
maximum mean discrepancy), submits them through VFL protocol to collect
predicted labels, and uses these pseudo-labels to train estimated detector and
surrogate model on local features. In attack stage, these models guide
gradient-based perturbations of remaining samples, crafting adversarial
instances that induce targeted misclassifications and evade detection. We
implement VTarbel and evaluate it against four model architectures, seven
multimodal datasets, and two anomaly detectors. Across all settings, VTarbel
outperforms four state-of-the-art baselines, evades detection, and retains
effective against three representative privacy-preserving defenses. These
results reveal critical security blind spots in current VFL deployments and
underscore urgent need for robust, attack-aware defenses.

</details>


### [202] [VMask: Tunable Label Privacy Protection for Vertical Federated Learning via Layer Masking](https://arxiv.org/abs/2507.14629)
*Juntao Tan, Lan Zhang, Zhonghao Hu, Kai Yang, Peng Ran, Bo Li*

**主要类别:** cs.CR

**AI概要:** 提出VMask框架，通过层掩码技术抵御模型完成攻击，保护垂直联合学习中的标签隐私。它在多个模型和数据集上展示了最佳的隐私-效用权衡，并且运行效率高。


<details>
  <summary>更多</summary>
  
**动机:** 尽管垂直联合学习（VFL）被认为具有隐私保护性，但最近的研究表明它容易受到标签推断攻击，特别是模型完成攻击。现有的防御方法要么牺牲模型准确性，要么产生不切实际的计算开销。

**方法:** 作者提出了VMask框架，利用秘密共享技术对攻击者模型中的层参数进行掩码处理，以打破输入数据与中间输出之间的强关联。同时，设计了选择关键层进行掩码的策略，减少开销，并提供可调的隐私预算。

**结果:** 实验结果表明，VMask成功将模型完成攻击的标签推断准确率降低到随机猜测水平，同时保持了模型性能，平均仅使VFL模型准确率下降0.09%，并且其运行时间远快于基于密码学的方法。

**结论:** VMask为VFL提供了一种有效、高效且灵活的标签隐私保护方法，实现了隐私和效用的最佳平衡。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是VMask%3A+Tunable+Label+Privacy+Protection+for+Vertical+Federated+Learning+via+Layer+Masking，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14629，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14629&send_immediately=true&force_search=false)

**原文摘要:** Though vertical federated learning (VFL) is generally considered to be
privacy-preserving, recent studies have shown that VFL system is vulnerable to
label inference attacks originating from various attack surfaces. Among these
attacks, the model completion (MC) attack is currently the most powerful one.
Existing defense methods against it either sacrifice model accuracy or incur
impractical computational overhead. In this paper, we propose VMask, a novel
label privacy protection framework designed to defend against MC attack from
the perspective of layer masking. Our key insight is to disrupt the strong
correlation between input data and intermediate outputs by applying the secret
sharing (SS) technique to mask layer parameters in the attacker's model. We
devise a strategy for selecting critical layers to mask, reducing the overhead
that would arise from naively applying SS to the entire model. Moreover, VMask
is the first framework to offer a tunable privacy budget to defenders, allowing
for flexible control over the levels of label privacy according to actual
requirements. We built a VFL system, implemented VMask on it, and extensively
evaluated it using five model architectures and 13 datasets with different
modalities, comparing it to 12 other defense methods. The results demonstrate
that VMask achieves the best privacy-utility trade-off, successfully thwarting
the MC attack (reducing the label inference accuracy to a random guessing
level) while preserving model performance (e.g., in Transformer-based model,
the averaged drop of VFL model accuracy is only 0.09%). VMask's runtime is up
to 60,846 times faster than cryptography-based methods, and it only marginally
exceeds that of standard VFL by 1.8 times in a large Transformer-based model,
which is generally acceptable.

</details>


### [203] [CANDoSA: A Hardware Performance Counter-Based Intrusion Detection System for DoS Attacks on Automotive CAN bus](https://arxiv.org/abs/2507.14739)
*Franco Oberti, Stefano Di Carlo, Alessandro Savino*

**主要类别:** cs.CR

**AI概要:** 本文提出了一种新的入侵检测系统（IDS），该系统专为CAN环境设计，利用硬件性能计数器（HPCs）来检测表明网络攻击的异常情况。研究表明，这种方法可以显著提高CAN协议的安全性，以应对汽车网络安全中的新兴挑战。


<details>
  <summary>更多</summary>
  
**动机:** 控制器局域网（CAN）协议是汽车嵌入式系统的重要组成部分，但缺乏固有的安全特性，使其容易受到网络威胁，特别是在自动驾驶车辆兴起的情况下。传统安全措施提供的保护有限。

**方法:** 本研究使用gem5模拟器模拟了一个基于RISC-V的CAN接收器，处理带有AES-128加密的CAN帧有效载荷作为FreeRTOS任务，触发不同的硬件性能计数器（HPC）响应。通过数据提取和相关性分析优化关键HPC特征，以提高分类效率。

**结果:** 结果表明，这一方法能够显著提升CAN的安全性，并解决汽车领域中出现的新挑战。

**结论:** 提出的基于HPC的IDS为CAN协议提供了一种新的安全增强机制，特别是对于日益复杂的汽车网络安全环境。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CANDoSA%3A+A+Hardware+Performance+Counter-Based+Intrusion+Detection+System+for+DoS+Attacks+on+Automotive+CAN+bus，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14739，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14739&send_immediately=true&force_search=false)

**原文摘要:** The Controller Area Network (CAN) protocol, essential for automotive embedded
systems, lacks inherent security features, making it vulnerable to cyber
threats, especially with the rise of autonomous vehicles. Traditional security
measures offer limited protection, such as payload encryption and message
authentication. This paper presents a novel Intrusion Detection System (IDS)
designed for the CAN environment, utilizing Hardware Performance Counters
(HPCs) to detect anomalies indicative of cyber attacks. A RISC-V-based CAN
receiver is simulated using the gem5 simulator, processing CAN frame payloads
with AES-128 encryption as FreeRTOS tasks, which trigger distinct HPC
responses. Key HPC features are optimized through data extraction and
correlation analysis to enhance classification efficiency. Results indicate
that this approach could significantly improve CAN security and address
emerging challenges in automotive cybersecurity.

</details>


### [204] [Careful Whisper: Attestation for peer-to-peer Confidential Computing networks](https://arxiv.org/abs/2507.14796)
*Ceren Kocaoğullar, Gustavo Petri, Dominic P. Mulligan, Derek Miller, Hugo J. M. Vincent, Shale Xiong, Alastair R. Beresford*

**主要类别:** cs.CR

**AI概要:** 本文提出了一种基于八卦协议的Careful Whisper，它能有效传播信任，将认证开销降低到线性复杂度，支持异构网络中的传递信任，并通过中继认证与离线节点建立信任。实验结果表明，该协议在各种网络拓扑结构中比朴素方法更快、更广泛地传播信任，且对认证失败具有弹性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的TEE直接相互认证的方法在网络动态变化时效率低下，因为每次加入或离开节点都会导致二次通信开销。因此需要一种更有效的机制来减少认证过程中的通信开销。

**方法:** 提出了一个名为Careful Whisper的八卦协议，它能够在理想条件下将认证开销从二次降到线性复杂度。该协议还允许不同类型的网络之间进行互操作，并通过中继认证来与离线节点建立信任。

**结果:** 使用自定义的离散事件模拟器进行的测试表明，Careful Whisper协议不仅能在各种网络拓扑中快速且广泛地传播信任，而且每轮仅需发送约21.5 KiB的数据并耗时0.158秒，在200个节点的网络中展现了资源效率。此外，该协议在面对认证失败时表现出弹性。

**结论:** Careful Whisper提供了一种新的方式来解决动态网络环境中高效传播信任的问题，其性能和可靠性都得到了验证。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Careful+Whisper%3A+Attestation+for+peer-to-peer+Confidential+Computing+networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14796，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14796&send_immediately=true&force_search=false)

**原文摘要:** Trusted Execution Environments (TEEs) are designed to protect the privacy and
integrity of data in use. They enable secure data processing and sharing in
peer-to-peer networks, such as vehicular ad hoc networks of autonomous
vehicles, without compromising confidentiality. In these networks, nodes must
establish mutual trust to collaborate securely. TEEs can achieve this through
remote attestation, where a prover presents evidence of its trustworthiness to
a verifier, which then decides whether or not to trust the prover. However, a
naive peer-to-peer attestation approach, where every TEE directly attests every
other TEE, results in quadratic communication overhead. This is inefficient in
dynamic environments, where nodes frequently join and leave the network.
  To address this, we present Careful Whisper, a gossip-based protocol that
disseminates trust efficiently, reducing attestation overhead to linear
complexity under ideal conditions. It enables interoperability by enabling
transitive trust across heterogeneous networks, and supports trust
establishment with offline nodes via relayed attestations. Using a custom
discrete-event simulator, we show that Careful Whisper propagates trust both
faster and more widely than naive approaches across various network topologies.
Our results demonstrate that our protocol is resource efficient, sending ~21.5
KiB and requiring 0.158 seconds per round in a 200-node network, and that our
protocol is resilient to attestation failures across various network
topologies.

</details>


### [205] [Manipulating LLM Web Agents with Indirect Prompt Injection Attack via HTML Accessibility Tree](https://arxiv.org/abs/2507.14799)
*Sam Johnson, Viet Pham, Thai Le*

**主要类别:** cs.CR

**AI概要:** 本文展示了基于LLM的网页导航代理虽然提供了强大的自动化能力，但容易受到间接提示注入（IPI）攻击。通过在网页HTML中嵌入普遍对抗触发器，攻击者可以劫持使用可访问性树解析HTML的代理行为，导致非预期或恶意行为。研究使用Greedy Coordinate Gradient (GCG)算法和由Llama-3.1驱动的Browser Gym代理，在真实网站上展示了高成功率的攻击，包括登录凭证外泄和强制点击广告。实证结果强调了关键的安全风险，并呼吁随着LLM驱动的自主网页代理被更广泛采用时需要更强的防御措施。


<details>
  <summary>更多</summary>
  
**动机:** 该研究旨在揭示并评估基于LLM的网页导航代理所面临的安全威胁，特别是针对间接提示注入（IPI）攻击的脆弱性。这是因为这类代理正在越来越多地被应用于自动化任务中，其安全性能至关重要。

**方法:** 研究人员采用了Greedy Coordinate Gradient (GCG)算法来识别和利用网页HTML中的对抗触发器。然后，他们使用了一个由Llama-3.1驱动的Browser Gym代理进行了一系列针对真实网站的实验，测试了不同类型的IPI攻击的效果。

**结果:** 实验结果显示，无论是针对性攻击还是一般性攻击，系统都表现出极高的成功率，成功实现了诸如窃取登录凭证和强制点击广告等攻击目标。

**结论:** 本研究表明，基于LLM的网页导航代理存在严重的安全漏洞，特别是在面对IPI攻击时。随着这类技术的应用越来越广泛，必须重视并加强相应的安全防御措施。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Manipulating+LLM+Web+Agents+with+Indirect+Prompt+Injection+Attack+via+HTML+Accessibility+Tree，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14799，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14799&send_immediately=true&force_search=false)

**原文摘要:** This work demonstrates that LLM-based web navigation agents offer powerful
automation capabilities but are vulnerable to Indirect Prompt Injection (IPI)
attacks. We show that adversaries can embed universal adversarial triggers in
webpage HTML to hijack agent behavior that utilizes the accessibility tree to
parse HTML, causing unintended or malicious actions. Using the Greedy
Coordinate Gradient (GCG) algorithm and a Browser Gym agent powered by
Llama-3.1, our system demonstrates high success rates across real websites in
both targeted and general attacks, including login credential exfiltration and
forced ad clicks. Our empirical results highlight critical security risks and
the need for stronger defenses as LLM-driven autonomous web agents become more
widely adopted. The system software
(https://github.com/sej2020/manipulating-web-agents) is released under the MIT
License, with an accompanying publicly available demo website
(http://lethaiq.github.io/attack-web-llm-agent).

</details>


### [206] [Quantum Skyshield: Quantum Key Distribution and Post-Quantum Authentication for Low-Altitude Wireless Networks in Adverse Skies](https://arxiv.org/abs/2507.14822)
*Zeeshan Kaleem, Misha Urooj Khan, Ahmad Suleman, Waqas Khalid, Kai-Kit Wong, Chau Yuen*

**主要类别:** cs.CR

**AI概要:** 提出了一种名为Quantum Skyshield的量子安全架构，结合了BB84量子密钥分发和后量子认证机制，以实现基站和低空无线网络之间的可靠通信。模拟结果显示在量子比特错误率低于11%时能可靠生成128位对称密钥，并使用Lamport一次性签名和HMAC确保消息完整性，Grover启发式威胁检测机制能在一次迭代中以高达89%的概率识别异常。


<details>
  <summary>更多</summary>
  
**动机:** 随着低空无线网络（LAWN）成为支持低空经济的关键基础设施，特别是无人飞行器（UAV）和高空平台（HAP）的密集化，为了满足不断增长的数据需求，一些LAWN部署引入了自由空间光链路（FSO）。然而，这些链路缺乏强大的安全措施，容易受到拦截、欺骗等攻击，特别是在量子时代背景下，这对通信的安全性和可靠性提出了挑战。

**方法:** 设计结合了BB84量子密钥分发（QKD）协议与后量子认证机制，包括Lamport一次性签名和基于哈希的消息认证码（HMAC），用于保证消息的完整性和真实性。此外，还引入了一个受Grover算法启发的威胁检测机制，用以识别异常并进行实时信任评估。

**结果:** 模拟结果表明，当量子比特错误率（QBER）保持在11%以下时，能够可靠地生成128位对称密钥。同时，使用Lamport一次性签名和HMAC可以有效保障消息的完整性。Grover启发式威胁检测机制能够在一次迭代中以高达89%的概率识别出异常。

**结论:** Quantum Skyshield架构为低空无线网络提供了一种新的安全解决方案，可以在量子计算时代的背景下保护通信免受各种攻击。未来的研究将需要继续探索如何进一步提高系统的效率和鲁棒性，以及解决实际部署中可能遇到的问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Quantum+Skyshield%3A+Quantum+Key+Distribution+and+Post-Quantum+Authentication+for+Low-Altitude+Wireless+Networks+in+Adverse+Skies，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14822，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14822&send_immediately=true&force_search=false)

**原文摘要:** Recently, low-altitude wireless networks (LAWNs) have emerged as a critical
backbone for supporting the low-altitude economy, particularly with the
densification of unmanned aerial vehicles (UAVs) and high-altitude platforms
(HAPs). To meet growing data demands, some LAWN deployments incorporate
free-space optical (FSO) links, which offer exceptional bandwidth and beam
directivity. However, without strong security measures in place, both
conventional radio frequency channels and FSO beams remain vulnerable to
interception and spoofing and FSO in particular can suffer from turbulence,
misalignment, and weather-related attenuation. To address these challenges in
the quantum era, a quantum-secure architecture called Quantum Skyshield is
proposed to enable reliable communication between the base transceiver station
(BTS) and LAWN. The proposed design integrates BB84 quantum key distribution
(QKD) with post-quantum authentication mechanisms. Simulation results confirm
the reliable generation of a 128-bit symmetric key when the quantum bit error
rate (QBER) remains below the threshold of 11%. Authentication is enforced
using Lamport one-time signatures and hash-based message authentication codes
(HMAC) to ensure message integrity. A Grover-inspired threat detection
mechanism identifies anomalies with up to 89% probability in a single
iteration, enabling real-time trust evaluation. Lastly, future research
challenges have also been identified and discussed to guide further development
in this area.

</details>


### [207] [A Privacy-Centric Approach: Scalable and Secure Federated Learning Enabled by Hybrid Homomorphic Encryption](https://arxiv.org/abs/2507.14853)
*Khoa Nguyen, Tanveer Khan, Antonis Michalas*

**主要类别:** cs.CR

**AI概要:** 本文研究了如何将混合同态加密(HHE)与联邦学习(FL)结合，以解决通信和隐私挑战，实现可扩展和安全的去中心化学习系统。


<details>
  <summary>更多</summary>
  
**动机:** 联邦学习（FL）在隐私敏感领域有巨大潜力，但在通信开销和数据隐私方面面临重大挑战。现有的隐私保护技术（如同态加密）虽然能缓解这些问题，但带来了显著的计算和通信成本，限制了实际应用。

**方法:** 作者探索了混合同态加密（HHE），这是一种结合对称加密与同态加密的密码协议，并研究其如何与联邦学习相结合，从而同时解决通信和隐私问题。

**结果:** 论文没有直接提及具体结果，但表明该方法为解决FL中的通信和隐私挑战提供了一种可能的途径。

**结论:** 通过整合HHE与FL，可以构建更加可扩展且安全的去中心化学习系统，从而推动FL在实际场景中的应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Privacy-Centric+Approach%3A+Scalable+and+Secure+Federated+Learning+Enabled+by+Hybrid+Homomorphic+Encryption，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14853，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14853&send_immediately=true&force_search=false)

**原文摘要:** Federated Learning (FL) enables collaborative model training without sharing
raw data, making it a promising approach for privacy-sensitive domains. Despite
its potential, FL faces significant challenges, particularly in terms of
communication overhead and data privacy. Privacy-preserving Techniques (PPTs)
such as Homomorphic Encryption (HE) have been used to mitigate these concerns.
However, these techniques introduce substantial computational and communication
costs, limiting their practical deployment. In this work, we explore how Hybrid
Homomorphic Encryption (HHE), a cryptographic protocol that combines symmetric
encryption with HE, can be effectively integrated with FL to address both
communication and privacy challenges, paving the way for scalable and secure
decentralized learning system.

</details>


### [208] [A Compact Post-quantum Strong Designated Verifier Signature Scheme from Isogenies](https://arxiv.org/abs/2507.14893)
*Farzin Renan*

**主要类别:** cs.CR

**AI概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Compact+Post-quantum+Strong+Designated+Verifier+Signature+Scheme+from+Isogenies，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14893，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14893&send_immediately=true&force_search=false)

**原文摘要:** Digital signatures are essential cryptographic tools that provide
authentication and integrity in digital communications. However,
privacy-sensitive applications, such as e-voting and digital cash, require more
restrictive verification models to ensure confidentiality and control. Strong
Designated Verifier Signature (SDVS) schemes address this need by enabling the
signer to designate a specific verifier, ensuring that only this party can
validate the signature. Existing SDVS constructions are primarily based on
number-theoretic assumptions and are therefore vulnerable to quantum attacks.
Although post-quantum alternatives, particularly those based on lattices, have
been proposed, they often entail large key and signature sizes. In this work,
we introduce $\mathsf{CSI\text{-}SDVS}$, a novel isogeny-based SDVS scheme that
offers a compact, quantum-resistant alternative. Our construction builds on the
ideal class group action framework of CSIDH and the signature techniques of
CSI-FiSh, and relies on the hardness of the Multi-Target Group Action Inverse
Problem (MT-GAIP). $\mathsf{CSI\text{-}SDVS}$ achieves strong security
guarantees; namely, Strong Unforgeability under Chosen-Message Attacks
(SUF-CMA), Non-Transferability (NT), and Privacy of Signer's Identity (PSI), in
the random oracle model. Remarkably, both the keys and signatures in
$\mathsf{CSI\text{-}SDVS}$ are of size $\mathcal{O}(\lambda)$, representing a
significant improvement over the typical $\mathcal{O}(\lambda^2)$ bounds in
existing post-quantum SDVS schemes, thereby making it among the most compact
PQC-based SDVS schemes and the only post-quantum secure construction based on
isogenies.

</details>


### [209] [Metaverse Security and Privacy Research: A Systematic Review](https://arxiv.org/abs/2507.14985)
*Argianto Rahartomo, Leonel Merino, Mohammad Ghafari*

**主要类别:** cs.CR

**AI概要:** 本文系统回顾了2013年至2024年关于元宇宙安全和隐私问题的文献，揭示研究活动激增、以实用和用户为中心的方法为主导，但仍存在政策遵从性、可访问性等领域的关键空白。


<details>
  <summary>更多</summary>
  
**动机:** 随着元宇宙技术（如虚拟世界、增强现实和生活记录）的迅速发展，这些技术在不同领域中的应用暴露出显著的安全和隐私挑战。

**方法:** 作者对2013年至2024年间发表的文献进行了系统性回顾，按方法组织研究，检查安全性和隐私属性、沉浸式组件及评估策略。

**结果:** 发现过去五年中研究活动急剧增加，重点是实际和以用户为中心的方法，并主要使用基准测试、人类实验和定性方法。认证和不可观察性是最常研究的属性，但在政策合规、可访问性等方面仍存在关键差距。

**结论:** 强调了元宇宙的技术复杂性和人为因素的交织，并呼吁采用综合性的跨学科方法来确保包容和可信的沉浸式环境。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Metaverse+Security+and+Privacy+Research%3A+A+Systematic+Review，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.14985，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.14985&send_immediately=true&force_search=false)

**原文摘要:** The rapid growth of metaverse technologies, including virtual worlds,
augmented reality, and lifelogging, has accelerated their adoption across
diverse domains. This rise exposes users to significant new security and
privacy challenges due to sociotechnical complexity, pervasive connectivity,
and extensive user data collection in immersive environments. We present a
systematic review of the literature published between 2013 and 2024, offering a
comprehensive analysis of how the research community has addressed
metaverse-related security and privacy issues over the past decade. We organize
the studies by method, examined the security and privacy properties, immersive
components, and evaluation strategies. Our investigation reveals a sharp
increase in research activity in the last five years, a strong focus on
practical and user-centered approaches, and a predominant use of benchmarking,
human experimentation, and qualitative methods. Authentication and
unobservability are the most frequently studied properties. However, critical
gaps remain in areas such as policy compliance, accessibility,
interoperability, and back-end infrastructure security. We emphasize the
intertwined technical complexity and human factors of the metaverse and call
for integrated, interdisciplinary approaches to securing inclusive and
trustworthy immersive environments.

</details>


### [210] [LibLMFuzz: LLM-Augmented Fuzz Target Generation for Black-box Libraries](https://arxiv.org/abs/2507.15058)
*Ian Hardgrove, John D. Hastings*

**主要类别:** cs.CR

**AI概要:** 本文介绍了一种名为LibLMFuzz的框架，它通过结合大型语言模型和轻量级工具链来减少模糊测试闭源库的成本。实验结果表明，该框架在四个常用的Linux库上实现了100%的API覆盖，并且大部分生成的驱动程序在首次执行时是正确的。这为未来的研究提供了基础。


<details>
  <summary>更多</summary>
  
**动机:** 模糊测试是一种发现程序漏洞的流行方法，但在初始设置和持续维护方面需要投资成本。当只有二进制库可用时，选择模糊测试变得更加复杂。

**方法:** 研究人员引入了LibLMFuzz框架，该框架将代理型大型语言模型与轻量级工具链（反汇编器/编译器/模糊测试工具）配对，以自主分析剥离的二进制文件，规划模糊策略，生成驱动程序，并迭代地自我修复构建或运行时错误。

**结果:** 在四个广泛使用的Linux库上进行了测试，LibLMFuzz为所有558个可模糊API函数生成了语法正确的驱动程序，达到了100%的API覆盖率，并且无需人工干预。在合成的1601个驱动程序中，75.52%在首次执行时是名义上正确的。

**结论:** LLM增强的中间件在减少黑盒组件模糊测试成本方面具有潜力，并为未来的研究工作提供了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LibLMFuzz%3A+LLM-Augmented+Fuzz+Target+Generation+for+Black-box+Libraries，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15058，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15058&send_immediately=true&force_search=false)

**原文摘要:** A fundamental problem in cybersecurity and computer science is determining
whether a program is free of bugs and vulnerabilities. Fuzzing, a popular
approach to discovering vulnerabilities in programs, has several advantages
over alternative strategies, although it has investment costs in the form of
initial setup and continuous maintenance. The choice of fuzzing is further
complicated when only a binary library is available, such as the case of
closed-source and proprietary software. In response, we introduce LibLMFuzz, a
framework that reduces costs associated with fuzzing closed-source libraries by
pairing an agentic Large Language Model (LLM) with a lightweight tool-chain
(disassembler/compiler/fuzzer) to autonomously analyze stripped binaries, plan
fuzz strategies, generate drivers, and iteratively self-repair build or runtime
errors. Tested on four widely-used Linux libraries, LibLMFuzz produced
syntactically correct drivers for all 558 fuzz-able API functions, achieving
100% API coverage with no human intervention. Across the 1601 synthesized
drivers, 75.52% were nominally correct on first execution. The results show
that LLM-augmented middleware holds promise in reducing the costs of fuzzing
black box components and provides a foundation for future research efforts.
Future opportunities exist for research in branch coverage.

</details>


### [211] [PromptArmor: Simple yet Effective Prompt Injection Defenses](https://arxiv.org/abs/2507.15219)
*Tianneng Shi, Kaijie Zhu, Zhun Wang, Yuqi Jia, Will Cai, Weida Liang, Haonan Wang, Hend Alzahrani, Joshua Lu, Kenji Kawaguchi, Basel Alomair, Xuandong Zhao, William Yang Wang, Neil Gong, Wenbo Guo, Dawn Song*

**主要类别:** cs.CR

**AI概要:** 本文提出了一个名为PromptArmor的简单而有效的防御措施，用于抵御提示注入攻击。实验结果显示，PromptArmor能够准确识别并移除注入的提示，将攻击成功率降低至1%以下。


<details>
  <summary>更多</summary>
  
**动机:** 研究发现LLM代理容易受到提示注入攻击的影响，这些攻击会使代理执行攻击者指定的任务而非用户意图的任务。

**方法:** PromptArmor促使现成的LLM在代理处理输入前检测并移除潜在的注入提示。

**结果:** PromptArmor使用GPT-4o, GPT-4.1或o4-mini在AgentDojo基准测试中实现了低于1%的假阳性和假阴性率，并且在移除注入提示后，攻击成功率降至1%以下。

**结论:** 建议将PromptArmor作为评估新防御措施的标准基线，并展示了其对适应性攻击的有效性以及不同的LLM提示策略。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PromptArmor%3A+Simple+yet+Effective+Prompt+Injection+Defenses，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15219，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15219&send_immediately=true&force_search=false)

**原文摘要:** Despite their potential, recent research has demonstrated that LLM agents are
vulnerable to prompt injection attacks, where malicious prompts are injected
into the agent's input, causing it to perform an attacker-specified task rather
than the intended task provided by the user. In this paper, we present
PromptArmor, a simple yet effective defense against prompt injection attacks.
Specifically, PromptArmor prompts an off-the-shelf LLM to detect and remove
potential injected prompts from the input before the agent processes it. Our
results show that PromptArmor can accurately identify and remove injected
prompts. For example, using GPT-4o, GPT-4.1, or o4-mini, PromptArmor achieves
both a false positive rate and a false negative rate below 1% on the AgentDojo
benchmark. Moreover, after removing injected prompts with PromptArmor, the
attack success rate drops to below 1%. We also demonstrate PromptArmor's
effectiveness against adaptive attacks and explore different strategies for
prompting an LLM. We recommend that PromptArmor be adopted as a standard
baseline for evaluating new defenses against prompt injection attacks.

</details>


### [212] [The Matrix Subcode Equivalence problem and its application to signature with MPC-in-the-Head](https://arxiv.org/abs/2507.15377)
*Magali Bardet, Charles Brion, Philippe Gaborit, Mercedes Haiech, Romaric Neveu*

**主要类别:** cs.CR

**AI概要:** 本文引入了矩阵子码等价问题和矩阵码置换核问题，并利用MPCitH范式构建签名方案。通过分析相关攻击，该研究能够采用比矩阵码等价性问题更小的参数，从而获得合理的签名大小。新的签名方案在性能上优于SPHINCS+，并且与MEDS和其他签名方案相比具有较小的签名和公钥尺寸。


<details>
  <summary>更多</summary>
  
**动机:** 现有的密码系统中，如数字签名，大多基于等价性问题，但主要集中在码等价性问题上。为了拓展这一领域，研究人员希望探索矩阵码中的子码等价性问题，为后量子密码学提供新的基础难题。

**方法:** 文章提出了两个新问题：矩阵子码等价性问题和矩阵码置换核问题，并证明了前者可以归约到NP完全的Hamming子码等价性问题。此外，还调整了组合和代数算法以适应子码情况，并对这些算法进行了复杂度分析。

**结果:** 通过对攻击的分析，发现用于解决这些问题的算法性能远不如处理码等价性问题时的表现，这允许使用更小的参数。最终，实现了大约4800字节的签名大小和275字节的公钥大小，使得新签名方案在尺寸和效率方面超越了SPHINCS+、MEDS和其他现有方案。

**结论:** 这项工作不仅引入了新的数学难题作为后量子密码学的基础，而且提供了实际应用中有效且紧凑的签名方案，特别是其签名和公钥尺寸均小于其他已知方案，显著提高了性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Matrix+Subcode+Equivalence+problem+and+its+application+to+signature+with+MPC-in-the-Head，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15377，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15377&send_immediately=true&force_search=false)

**原文摘要:** Nowadays, equivalence problems are widely used in cryptography, most notably
to establish cryptosystems such as digital signatures, with MEDS, LESS, PERK as
the most recent ones. However, in the context of matrix codes, only the code
equivalence problem has been studied, while the subcode equivalence is
well-defined in the Hamming metric. In this work, we introduce two new
problems: the Matrix Subcode Equivalence Problem and the Matrix Code Permuted
Kernel Problem, to which we apply the MPCitH paradigm to build a signature
scheme. These new problems, closely related to the Matrix Code Equivalence
problem, ask to find an isometry given a code $C$ and a subcode $D$.
Furthermore, we prove that the Matrix Subcode Equivalence problem reduces to
the Hamming Subcode Equivalence problem, which is known to be NP-Complete, thus
introducing the matrix code version of the Permuted Kernel Problem. We also
adapt the combinatorial and algebraic algorithms for the Matrix Code
Equivalence problem to the subcode case, and we analyze their complexities. We
find with this analysis that the algorithms perform much worse than in the code
equivalence case, which is the same as what happens in the Hamming metric.
Finally, our analysis of the attacks allows us to take parameters much smaller
than in the Matrix Code Equivalence case. Coupled with the effectiveness of
\textit{Threshold-Computation-in-the-Head} or \textit{VOLE-in-the-Head}, we
obtain a signature size of $\approx$ 4 800 Bytes, with a public key of
$\approx$ 275 Bytes. We thus obtain a reasonable signature size, which brings
diversity in the landscape of post-quantum signature schemes, by relying on a
new hard problem. In particular, this new signature scheme performs better than
SPHINCS+, with a smaller size of public key + signature. Our signature compares
also well with other signature schemes: compared to MEDS, the signature is
smaller, and we reduced the size of the sum of signature and public key by a
factor close to 5. We also obtain a signature size that is almost half the size
of the CROSS signature scheme.

</details>


### [213] [PiMRef: Detecting and Explaining Ever-evolving Spear Phishing Emails with Knowledge Base Invariants](https://arxiv.org/abs/2507.15393)
*Ruofan Liu, Yun Lin, Silas Yeo Shuen Yu, Xiwen Teoh, Zhenkai Liang, Jin Song Dong*

**主要类别:** cs.CR

**AI概要:** 论文提出了一种新的基于知识不变式的钓鱼邮件检测器PiMRef，该方法通过检查邮件中的身份声明与事实是否矛盾来识别钓鱼邮件。相比现有方法，PiMRef在精确度上提高了8.8%，并且在真实世界评估中表现出更高的准确性和效率。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型语言模型（LLMs）的兴起，攻击者能够以极低的成本生成高度说服力的个性化钓鱼邮件，这些邮件几乎可以绕过所有现有的商业和学术检测器。传统的基于规则和特征工程的检测器在这种持续的攻防对抗中变得无效。

**方法:** PiMRef将钓鱼邮件检测重新定义为身份事实核查任务，具体步骤包括：(i) 提取发件人声称的身份；(ii) 核查发件人的域名合法性；(iii) 检测促使用户互动的行动呼吁提示。如果存在矛盾声明，则标记为钓鱼指标。

**结果:** 与现有方法如D-Fence、HelpHed和ChatSpamDetector相比，PiMRef在Nazario和PhishPot等标准基准测试中将精度提高了8.8%，且不损失召回率。在对五个大学账户三年内的10,183封邮件的真实世界评估中，PiMRef实现了92.1%的精度和87.9%的召回率，中位运行时间为0.05秒，超越了最先进的方法。

**结论:** PiMRef提供了一种有效的方法来对抗由LLMs生成的高度定制化钓鱼邮件，并且在实际应用中证明了其高效性和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PiMRef%3A+Detecting+and+Explaining+Ever-evolving+Spear+Phishing+Emails+with+Knowledge+Base+Invariants，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15393，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15393&send_immediately=true&force_search=false)

**原文摘要:** Phishing emails are a critical component of the cybercrime kill chain due to
their wide reach and low cost. Their ever-evolving nature renders traditional
rule-based and feature-engineered detectors ineffective in the ongoing arms
race between attackers and defenders. The rise of large language models (LLMs)
further exacerbates the threat, enabling attackers to craft highly convincing
phishing emails at minimal cost.
  This work demonstrates that LLMs can generate psychologically persuasive
phishing emails tailored to victim profiles, successfully bypassing nearly all
commercial and academic detectors. To defend against such threats, we propose
PiMRef, the first reference-based phishing email detector that leverages
knowledge-based invariants. Our core insight is that persuasive phishing emails
often contain disprovable identity claims, which contradict real-world facts.
PiMRef reframes phishing detection as an identity fact-checking task. Given an
email, PiMRef (i) extracts the sender's claimed identity, (ii) verifies the
legitimacy of the sender's domain against a predefined knowledge base, and
(iii) detects call-to-action prompts that push user engagement. Contradictory
claims are flagged as phishing indicators and serve as human-understandable
explanations.
  Compared to existing methods such as D-Fence, HelpHed, and ChatSpamDetector,
PiMRef boosts precision by 8.8% with no loss in recall on standard benchmarks
like Nazario and PhishPot. In a real-world evaluation of 10,183 emails across
five university accounts over three years, PiMRef achieved 92.1% precision,
87.9% recall, and a median runtime of 0.05s, outperforming the state-of-the-art
in both effectiveness and efficiency.

</details>


### [214] [PhishIntentionLLM: Uncovering Phishing Website Intentions through Multi-Agent Retrieval-Augmented Generation](https://arxiv.org/abs/2507.15419)
*Wenhao Li, Selvakumar Manickam, Yung-wey Chong, Shankar Karuppayah*

**主要类别:** cs.CR

**AI概要:** 论文提出了一种新的框架PhishIntentionLLM，用于从网站截图中识别网络钓鱼意图，并构建了第一个此类的真实数据集。实验表明该方法在多个大型语言模型上显著优于单代理基线。


<details>
  <summary>更多</summary>
  
**动机:** 现有的方法主要集中在检测网络钓鱼网站上，而对潜在的恶意意图的识别研究较少。为了填补这一空白，提出了一个新框架来识别网络钓鱼意图。

**方法:** 使用多代理检索增强生成（RAG）框架和大型语言模型（LLMs），从网站截图中识别四种关键的网络钓鱼目标：凭证窃取、金融欺诈、恶意软件分发和个人信息收集。

**结果:** 实验结果表明，PhishIntentionLLM与GPT-4o一起使用时达到了0.7895的微精度，并且比单代理基线提高了约95%的微精度。对于凭证窃取，它实现了0.8545的精度，比以前的工作提高了约4%。

**结论:** 这项工作提供了一个可扩展且可解释的解决方案，用于意图感知的网络钓鱼分析，并生成了一个更大的数据集，以支持跨行业的网络钓鱼意图分析。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PhishIntentionLLM%3A+Uncovering+Phishing+Website+Intentions+through+Multi-Agent+Retrieval-Augmented+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15419，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15419&send_immediately=true&force_search=false)

**原文摘要:** Phishing websites remain a major cybersecurity threat, yet existing methods
primarily focus on detection, while the recognition of underlying malicious
intentions remains largely unexplored. To address this gap, we propose
PhishIntentionLLM, a multi-agent retrieval-augmented generation (RAG) framework
that uncovers phishing intentions from website screenshots. Leveraging the
visual-language capabilities of large language models (LLMs), our framework
identifies four key phishing objectives: Credential Theft, Financial Fraud,
Malware Distribution, and Personal Information Harvesting. We construct and
release the first phishing intention ground truth dataset (~2K samples) and
evaluate the framework using four commercial LLMs. Experimental results show
that PhishIntentionLLM achieves a micro-precision of 0.7895 with GPT-4o and
significantly outperforms the single-agent baseline with a ~95% improvement in
micro-precision. Compared to the previous work, it achieves 0.8545 precision
for credential theft, marking a ~4% improvement. Additionally, we generate a
larger dataset of ~9K samples for large-scale phishing intention profiling
across sectors. This work provides a scalable and interpretable solution for
intention-aware phishing analysis.

</details>


### [215] [Cryptanalysis of a multivariate CCZ scheme](https://arxiv.org/abs/2507.15449)
*Alessio Caminata, Elisa Gorla, Madison Mabe, Martina Vigorito, Irene Villa*

**主要类别:** cs.CR

**AI概要:** Pesto方案的公钥多项式通过CCZ转换获得，但新的研究发现其可以高效地简化为二次多项式系统，这表明CCZ转换可能不会显著增加安全性。


<details>
  <summary>更多</summary>
  
**动机:** 评估CCZ转换在Pesto多变量方案中对安全性的提升程度。

**方法:** 展示如何将度数为4的公钥多项式系统有效减少到二次多项式系统。

**结果:** 发现CCZ转换并未如最初认为的那样大幅提高安全性。

**结论:** CCZ转换在Pesto方案中的应用可能没有提供预期的安全性增益。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Cryptanalysis+of+a+multivariate+CCZ+scheme，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15449，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15449&send_immediately=true&force_search=false)

**原文摘要:** We consider the multivariate scheme Pesto, which was introduced by Calderini,
Caminata, and Villa. In this scheme, the public polynomials are obtained by
applying a CCZ transformation to a set of quadratic secret polynomials. As a
consequence, the public key consists of polynomials of degree 4. In this work,
we show that the public degree 4 polynomial system can be efficiently reduced
to a system of quadratic polynomials. This seems to suggest that the CCZ
transformation may not offer a significant increase in security, contrary to
what was initially believed.

</details>


### [216] [Multi-Stage Prompt Inference Attacks on Enterprise LLM Systems](https://arxiv.org/abs/2507.15613)
*Andrii Balashov, Olena Ponomarova, Xiaohua Zhai*

**主要类别:** cs.CR

**AI概要:** 大型语言模型（LLMs）在企业环境中面临新的安全挑战，特别是多阶段提示推理攻击。本文研究了此类攻击，并提出了包括异常检测、细粒度访问控制等在内的多种防御措施。


<details>
  <summary>更多</summary>
  
**动机:** 随着大型语言模型（LLMs）在企业环境中的部署，例如作为Microsoft 365副驾，它们面临着全新的安全挑战，尤其是提示推理攻击。这促使研究者深入探讨这些威胁并开发有效的防御策略。

**方法:** 作者通过模拟真实的攻击场景来研究多阶段提示推理攻击，利用概率论、优化框架和信息理论泄漏界限进行分析。提出的防御措施包括统计异常检测、细粒度访问控制、提示清理技术以及对LLM部署的架构修改。

**结果:** 研究表明，即使存在标准的安全措施，攻击者仍然可以可靠地从LLM的上下文中提取敏感信息。提出的防御措施，如差异隐私训练的信息泄漏界限推导和高AUC的异常检测方法，有效地减少了攻击的成功率。

**结论:** 为了确保企业环境中LLM的安全，需要超越单回合提示过滤，转向对攻击和防御都采取全面、多阶段的观点。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Stage+Prompt+Inference+Attacks+on+Enterprise+LLM+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15613，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15613&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) deployed in enterprise settings (e.g., as
Microsoft 365 Copilot) face novel security challenges. One critical threat is
prompt inference attacks: adversaries chain together seemingly benign prompts
to gradually extract confidential data. In this paper, we present a
comprehensive study of multi-stage prompt inference attacks in an enterprise
LLM context. We simulate realistic attack scenarios where an attacker uses
mild-mannered queries and indirect prompt injections to exploit an LLM
integrated with private corporate data. We develop a formal threat model for
these multi-turn inference attacks and analyze them using probability theory,
optimization frameworks, and information-theoretic leakage bounds. The attacks
are shown to reliably exfiltrate sensitive information from the LLM's context
(e.g., internal SharePoint documents or emails), even when standard safety
measures are in place.
  We propose and evaluate defenses to counter such attacks, including
statistical anomaly detection, fine-grained access control, prompt sanitization
techniques, and architectural modifications to LLM deployment. Each defense is
supported by mathematical analysis or experimental simulation. For example, we
derive bounds on information leakage under differential privacy-based training
and demonstrate an anomaly detection method that flags multi-turn attacks with
high AUC. We also introduce an approach called "spotlighting" that uses input
transformations to isolate untrusted prompt content, reducing attack success by
an order of magnitude. Finally, we provide a formal proof of concept and
empirical validation for a combined defense-in-depth strategy. Our work
highlights that securing LLMs in enterprise settings requires moving beyond
single-turn prompt filtering toward a holistic, multi-stage perspective on both
attacks and defenses.

</details>


### [217] [Cyber security of Mega Events: A Case Study of Securing the Digital Infrastructure for MahaKumbh 2025 -- A 45 days Mega Event of 600 Million Footfalls](https://arxiv.org/abs/2507.15660)
*Rohit Negi, Amit Negi, Manish Sharma, S. Venkatesan, Prem Kumar, Sandeep K. Shukla*

**主要类别:** cs.CR

**AI概要:** 本文介绍了作者团队为印度Prayagraj的MahaKumbh 2025提供网络安全评估和风险管理监督的经验，该活动在45天内有6亿人次的参与。文中描述了团队的工作范围、过程、方法和成果，最终成功抵御了所有网络攻击。


<details>
  <summary>更多</summary>
  
**动机:** 大型活动（如奥运会、世界杯、G-20峰会和宗教活动）日益数字化，导致这些活动面临越来越多的网络威胁。然而，这些活动的基础设施是临时且仓促建立的，这使得它们的安全保障不同于常规组织的数字基础设施。因此，有必要针对这种独特的环境开发新的安全方法。

**方法:** 作者团队作为MahaKumbh 2025的网络安全评估和风险管理人员，记录了他们的工作范围、过程、方法论及结果。他们专注于保护这个为期45天、预计有6亿人次参与的事件，并确保其数字基础设施免受各种潜在的网络威胁。

**结果:** 在整个45天的活动中，没有一次网络攻击取得成功，证明了作者团队所采用的方法的有效性。

**结论:** 文章总结了为MahaKumbh 2025提供的安全保障措施，并讨论了如果未来再负责类似的大型活动时，他们会做出哪些不同的选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Cyber+security+of+Mega+Events%3A+A+Case+Study+of+Securing+the+Digital+Infrastructure+for+MahaKumbh+2025+--+A+45+days+Mega+Event+of+600+Million+Footfalls，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2507.15660，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2507.15660&send_immediately=true&force_search=false)

**原文摘要:** Mega events such as the Olympics, World Cup tournaments, G-20 Summit,
religious events such as MahaKumbh are increasingly digitalized. From event
ticketing, vendor booth or lodging reservations, sanitation, event scheduling,
customer service, crime reporting, media streaming and messaging on digital
display boards, surveillance, crowd control, traffic control and many other
services are based on mobile and web applications, wired and wireless
networking, network of Closed-Circuit Television (CCTV) cameras, specialized
control room with network and video-feed monitoring. Consequently, cyber
threats directed at such digital infrastructure are common. Starting from hobby
hackers, hacktivists, cyber crime gangs, to the nation state actors, all target
such infrastructure to unleash chaos on an otherwise smooth operation, and
often the cyber threat actors attempt to embarrass the organizing country or
the organizers. Unlike long-standing organizations such as a corporate or a
government department, the infrastructure of mega-events is temporary,
constructed over a short time span in expediency, and often shortcuts are taken
to make the deadline for the event. As a result, securing such an elaborate yet
temporary infrastructure requires a different approach than securing a standard
organizational digital infrastructure. In this paper, we describe our approach
to securing MahaKumbh 2025, a 600 million footfall event for 45 days in
Prayagraj, India, as a cyber security assessment and risk management oversight
team. We chronicle the scope, process, methodology, and outcome of our team's
effort to secure this mega event. It should be noted that none of the cyber
attacks during the 45-day event was successful. Our goal is to put on record
the methodology and discuss what we would do differently in case we work on
similar future mega event.

</details>
