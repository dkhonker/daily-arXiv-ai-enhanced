<div id=toc></div>

# 目录

- [cs.LG](#cs.LG) [总数: 123]
- [cs.AI](#cs.AI) [总数: 58]
- [stat.ML](#stat.ML) [总数: 17]


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [1] [Adaptive Tokenization: On the Hop-Overpriority Problem in Tokenized Graph Learning Models](https://arxiv.org/abs/2505.15845)
*Zhibiao Wang, Yunlong Zhou, Ziwei Zhang, Mengmei Zhang, Shirui Pan, Chunming Hu, Xiao Wang*

**主要类别:** cs.LG

**概要:** 本论文提出Learnable Graph Token List (LGTL)，解决现有TGLMs中hop-overpriority问题，通过自适应调整节点权重提高模型性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前Tokenized Graph Learning Models (TGLMs)依赖手工设计的token列表，在处理异质图时难以平衡局部和全局信号，存在未被探索的hop-overpriority问题。

**方法:** 提出Learnable Graph Token List (LGTL)，包含图注意力门模块和选择模块，自适应调整不同跳跃距离的节点权重并优先考虑信息丰富的节点，解决hop-overpriority问题。

**结果:** 理论分析表明LGTL能有效解决hop-overpriority问题，实验结果验证了其在Graph Transformers和Graph LLM骨架上的有效性。

**结论:** LGTL作为即插即用模块，可以替代手工设计的token列表，提升TGLMs对同质和异质图的学习能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Adaptive+Tokenization%3A+On+the+Hop-Overpriority+Problem+in+Tokenized+Graph+Learning+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15845，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15845&send_immediately=true&force_search=false)

**原文摘要:** Graph Transformers, leveraging the global attention to capture long-range
dependencies in graph structures, have significantly advanced graph machine
learning, but face prohibitive computational complexity. Tokenized Graph
Learning Models (TGLMs) address this issue by converting graphs into ordered
token lists for scalable processing. Besides, TGLMs also empower Large Language
Models (LLMs) to handle text-attributed graphs more effectively and thus are
also employed in Graph LLMs. However, existing TGLMs rely on hand-designed
token lists and their adaptability to diverse graph learning scenarios remains
unexplored. In this paper, we first conduct extensive empirical and theoretical
preliminary studies for hand-designed token lists. Surprisingly, we identify an
unexplored hop-overpriority problem: the common pre-defined token lists
overemphasize nearby nodes and overwhelm the ability of TGLMs to balance local
and global signals. This phenomenon is especially harmful for heterophilic
graphs. To address this problem, we propose the Learnable Graph Token List
(LGTL), a plug-and-play module to replace hand-designed token lists in TGLMs.
Specifically, LGTL adaptively adjusts the weights across hops and prioritizes
informative nodes within hops through a graph attention gate module and a
selection module, respectively. In this way, contextually informative nodes can
be adaptively emphasized for both homophilic and heterophilic graphs. Besides,
we theoretically show that LGTL can address the hop-overpriority problem.
Extensive experiments on benchmarks validate the efficacy of LGTL across both
Graph Transformers and Graph LLM backbones.

</details>


### [2] [Last Layer Empirical Bayes](https://arxiv.org/abs/2505.15888)
*Valentin Villecroze, Yixin Wang, Gabriel Loaiza-Ganem*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一个名为LLEB（last layer empirical Bayes）的方法，通过在神经网络的最后一层使用可学习的先验分布来量化预测中的不确定性。该方法结合了贝叶斯神经网络和集成方法的特点，表现与现有方法相当，并为不确定性量化研究提供了新的方向。


<details>
  <summary>更多</summary>
  
**动机:** 当前量化神经网络预测不确定性的主要方法包括贝叶斯神经网络（BNNs）和深度集成。这些方法通过在权重分布上计算期望来进行预测。受近期研究启发，作者提出了一种新方法，利用集合中使用的分布可以被理解为与学习到的数据依赖型先验相对应的后验这一特点。

**方法:** LLEB方法将一个可学习的先验表示为正则化流（normalizing flow），并通过最大化证据下界（evidence lower bound）对其进行训练。为了保持可处理性，这种方法仅应用于神经网络的最后一层。

**结果:** LLEB方法的表现与现有的不确定性量化方法相当，并展示了如何在标准BNNs和集成方法之间进行插值，取决于所使用先验的强度。

**结论:** LLEB是一个有前景的研究方向，结合了BNNs和集成方法的优点，为未来的不确定性量化研究提供了新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Last+Layer+Empirical+Bayes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15888，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15888&send_immediately=true&force_search=false)

**原文摘要:** The task of quantifying the inherent uncertainty associated with neural
network predictions is a key challenge in artificial intelligence. Bayesian
neural networks (BNNs) and deep ensembles are among the most prominent
approaches to tackle this task. Both approaches produce predictions by
computing an expectation of neural network outputs over some distribution on
the corresponding weights; this distribution is given by the posterior in the
case of BNNs, and by a mixture of point masses for ensembles. Inspired by
recent work showing that the distribution used by ensembles can be understood
as a posterior corresponding to a learned data-dependent prior, we propose last
layer empirical Bayes (LLEB). LLEB instantiates a learnable prior as a
normalizing flow, which is then trained to maximize the evidence lower bound;
to retain tractability we use the flow only on the last layer. We show why LLEB
is well motivated, and how it interpolates between standard BNNs and ensembles
in terms of the strength of the prior that they use. LLEB performs on par with
existing approaches, highlighting that empirical Bayes is a promising direction
for future research in uncertainty quantification.

</details>


### [3] [Is (Selective) Round-To-Nearest Quantization All You Need?](https://arxiv.org/abs/2505.15909)
*Alex Kogan*

**主要类别:** cs.LG

**概要:** 这篇论文重新审视了RTN（Round-to-Nearest）量化方法，表明其在成本和性能上可以与更先进的方法媲美，并提出通过选择性提高某些模型层的数据精度格式，可以逐步提高RTN的准确性，从而为LLMs的量化提供了一个可行且实用的选择。


<details>
  <summary>更多</summary>
  
**动机:** 随着大规模语言模型（LLMs）的发展，量化成为必要的工具。尽管RTN是最简单的量化技术之一，但近年来它被许多更先进的量化方法所取代。本研究旨在纠正这一观点，证明RTN不仅应用成本更低，而且在某些方面性能也可与先进方法相媲美。

**方法:** 作者基于最近的Marlin内核实现了RTN，并通过选择性地提高特定模型层和模块的数据精度格式，逐步提高了RTN的准确性。

**结果:** 实验结果表明，RTN的令牌生成吞吐量可以优于更先进的替代方案，同时保持相似的准确性。

**结论:** RTN作为一种简单且低成本的量化方法，对于LLMs的量化任务来说是一个可行且实用的选择。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Is+%28Selective%29+Round-To-Nearest+Quantization+All+You+Need%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15909，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15909&send_immediately=true&force_search=false)

**原文摘要:** Quantization became a necessary tool for serving ever-increasing Large
Language Models (LLMs). RTN (Round-to-Nearest) is perhaps the simplest
quantization technique that has been around well before LLMs surged to the
forefront of machine learning (ML) research. Yet, it has been largely dismissed
by recent and more advanced quantization methods that claim superiority over
RTN in nearly every aspect of performance. This work aims to dispel this
established point of view, showing that RTN is not only much cheaper to apply,
but also its token generation throughput can be better than and accuracy can be
similar to more advanced alternatives. In particular, we discuss our
implementation of RTN based on the recent Marlin kernels and demonstrate how
the accuracy of RTN can be gradually improved by selectively increasing the
data precision format of certain model layers and modules. Based on our
results, we argue that RTN presents a viable and practical choice for
quantizing LLMs.

</details>


### [4] [AllMetrics: A Unified Python Library for Standardized Metric Evaluation and Robust Data Validation in Machine Learning](https://arxiv.org/abs/2505.15931)
*Morteza Alizadeh, Mehrdad Oveisi, Sonya Falahati, Ghazal Mousavi, Mohsen Alambardar Meybodi, Somayeh Sadat Mehrnia, Ilker Hacihaliloglu, Arman Rahmim, Mohammad R. Salmanpour*

**主要类别:** cs.LG

**概要:** 论文介绍了一个名为AllMetrics的开源Python库，旨在通过标准化不同机器学习任务中的度量评估来解决现有库中碎片化、不一致实现和数据验证协议不足的问题。该库支持多种ML任务，并通过模块化API和强大的输入验证机制确保模型评估的可重复性和可靠性。


<details>
  <summary>更多</summary>
  
**动机:** 当前的机器学习度量库存在碎片化、不一致的实现以及数据验证协议不足的问题，导致结果不可靠，难以跨框架比较。

**方法:** 引入了AllMetrics库，一个统一的Python库，用于标准化各种机器学习任务（如回归、分类、聚类等）的度量评估。该库具有任务特定参数和类特定报告功能，以解决计算差异，并通过模块化API和强输入验证确保可靠性和可重复性。

**结果:** 在多个领域（如医疗、金融、房地产）的数据集上应用AllMetrics库，与Python、Matlab和R组件进行比较，证明其能够产生相似的结果并减少评估误差。

**结论:** AllMetrics库通过设计原则、架构组件和实证分析展示了其减少评估错误和提高机器学习工作流可信度的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AllMetrics%3A+A+Unified+Python+Library+for+Standardized+Metric+Evaluation+and+Robust+Data+Validation+in+Machine+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15931，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15931&send_immediately=true&force_search=false)

**原文摘要:** Machine learning (ML) models rely heavily on consistent and accurate
performance metrics to evaluate and compare their effectiveness. However,
existing libraries often suffer from fragmentation, inconsistent
implementations, and insufficient data validation protocols, leading to
unreliable results. Existing libraries have often been developed independently
and without adherence to a unified standard, particularly concerning the
specific tasks they aim to support. As a result, each library tends to adopt
its conventions for metric computation, input/output formatting, error
handling, and data validation protocols. This lack of standardization leads to
both implementation differences (ID) and reporting differences (RD), making it
difficult to compare results across frameworks or ensure reliable evaluations.
To address these issues, we introduce AllMetrics, an open-source unified Python
library designed to standardize metric evaluation across diverse ML tasks,
including regression, classification, clustering, segmentation, and
image-to-image translation. The library implements class-specific reporting for
multi-class tasks through configurable parameters to cover all use cases, while
incorporating task-specific parameters to resolve metric computation
discrepancies across implementations. Various datasets from domains like
healthcare, finance, and real estate were applied to our library and compared
with Python, Matlab, and R components to identify which yield similar results.
AllMetrics combines a modular Application Programming Interface (API) with
robust input validation mechanisms to ensure reproducibility and reliability in
model evaluation. This paper presents the design principles, architectural
components, and empirical analyses demonstrating the ability to mitigate
evaluation errors and to enhance the trustworthiness of ML workflows.

</details>


### [5] [MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding](https://arxiv.org/abs/2505.15946)
*Yuxiang Wei, Yanteng Zhang, Xi Xiao, Tianyang Wang, Xiao Wang, Vince D. Calhoun*

**主要类别:** cs.LG

**概要:** MoRE-Brain是一个受神经启发的框架，旨在实现高保真、适应性强和可解释的视觉重建。它采用分层Mixture-of-Experts架构，模仿专门的脑网络，通过新颖的双阶段路由机制合成图像。实验验证了其高重建保真度和有效利用fMRI信号的能力。


<details>
  <summary>更多</summary>
  
**动机:** 当前从fMRI解码视觉体验的研究往往过于关注最大化重建保真度，而忽略了可解释性，这对获得神经科学洞察力至关重要。为了解决这一问题，需要一个能够提供高保真度、适应性强和可解释的视觉重建方法。

**方法:** 提出了一种名为MoRE-Brain的神经启发式框架。该框架采用层次化的Mixture-of-Experts架构，不同的专家处理功能相关的体素组的fMRI信号，模拟专业化的脑网络。首先将专家训练为将fMRI编码到冻结的CLIP空间中，然后通过新颖的双阶段路由机制引导精细调整的扩散模型合成图像。该方法实现了高效的跨主体泛化，并提供了增强的机制洞察力。

**结果:** 广泛的实验验证了MoRE-Brain具有高重建保真度，瓶颈分析进一步证明了其对fMRI信号的有效利用，区分了真实的神经解码与过度依赖生成先验。

**结论:** MoRE-Brain标志着基于fMRI的视觉解码在更通用和可解释方向上的重大进展。代码即将公开。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MoRE-Brain%3A+Routed+Mixture+of+Experts+for+Interpretable+and+Generalizable+Cross-Subject+fMRI+Visual+Decoding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15946，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15946&send_immediately=true&force_search=false)

**原文摘要:** Decoding visual experiences from fMRI offers a powerful avenue to understand
human perception and develop advanced brain-computer interfaces. However,
current progress often prioritizes maximizing reconstruction fidelity while
overlooking interpretability, an essential aspect for deriving neuroscientific
insight. To address this gap, we propose MoRE-Brain, a neuro-inspired framework
designed for high-fidelity, adaptable, and interpretable visual reconstruction.
MoRE-Brain uniquely employs a hierarchical Mixture-of-Experts architecture
where distinct experts process fMRI signals from functionally related voxel
groups, mimicking specialized brain networks. The experts are first trained to
encode fMRI into the frozen CLIP space. A finetuned diffusion model then
synthesizes images, guided by expert outputs through a novel dual-stage routing
mechanism that dynamically weighs expert contributions across the diffusion
process. MoRE-Brain offers three main advancements: First, it introduces a
novel Mixture-of-Experts architecture grounded in brain network principles for
neuro-decoding. Second, it achieves efficient cross-subject generalization by
sharing core expert networks while adapting only subject-specific routers.
Third, it provides enhanced mechanistic insight, as the explicit routing
reveals precisely how different modeled brain regions shape the semantic and
spatial attributes of the reconstructed image. Extensive experiments validate
MoRE-Brain's high reconstruction fidelity, with bottleneck analyses further
demonstrating its effective utilization of fMRI signals, distinguishing genuine
neural decoding from over-reliance on generative priors. Consequently,
MoRE-Brain marks a substantial advance towards more generalizable and
interpretable fMRI-based visual decoding. Code will be publicly available soon:
https://github.com/yuxiangwei0808/MoRE-Brain.

</details>


### [6] [Towards Identifiability of Interventional Stochastic Differential Equations](https://arxiv.org/abs/2505.15987)
*Aaron Zweig, Zaikang Lin, Elham Azizi, David Knowles*

**主要类别:** cs.LG

**概要:** 研究了在多次干预下随机微分方程(SDE)模型的可识别性。结果提供了从其平稳分布样本中唯一恢复SDE参数的第一个可证明的界限。对于线性SDE，给出了必要的干预次数的严格界限；对于非线性SDE，在小噪声条件下给出了上限。通过合成数据验证了真实参数恢复的有效性，并基于理论结果展示了具有可学习激活函数的参数化的优点。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于解决随机微分方程模型在多次干预下的参数识别问题，特别是在平稳分布样本有限的情况下，如何能够唯一地恢复SDE参数。

**方法:** 通过对线性和非线性SDE进行分析，给出干预次数的界限。对于线性SDE提供严格的界限，而对于非线性SDE则是在小噪声条件下的上限。实验部分使用合成数据验证参数恢复的效果，并探讨了可学习激活函数参数化的优势。

**结果:** 理论上提供了线性SDE和非线性SDE参数恢复的界限，并通过实验验证了方法的有效性。结果表明，具有可学习激活函数的参数化方式可以更好地恢复真实参数。

**结论:** 本文为SDE模型的参数识别提供了新的理论界限，并展示了可学习激活函数在参数化中的优势，为进一步的研究奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Identifiability+of+Interventional+Stochastic+Differential+Equations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15987，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15987&send_immediately=true&force_search=false)

**原文摘要:** We study identifiability of stochastic differential equation (SDE) models
under multiple interventions. Our results give the first provable bounds for
unique recovery of SDE parameters given samples from their stationary
distributions. We give tight bounds on the number of necessary interventions
for linear SDEs, and upper bounds for nonlinear SDEs in the small noise regime.
We experimentally validate the recovery of true parameters in synthetic data,
and motivated by our theoretical results, demonstrate the advantage of
parameterizations with learnable activation functions.

</details>


### [7] [Interpretability Illusions with Sparse Autoencoders: Evaluating Robustness of Concept Representations](https://arxiv.org/abs/2505.16004)
*Aaron J. Li, Suraj Srinivas, Usha Bhalla, Himabindu Lakkaraju*

**主要类别:** cs.LG

**概要:** 稀疏自编码器(SAEs)在解释大型语言模型(LLMs)的内部激活方面被广泛应用，但其概念表示对输入扰动的鲁棒性一直被忽视。研究发现，微小的对抗性输入扰动可以在不影响基础LLMs输出的情况下操纵基于概念的解释，表明SAE概念表示是脆弱的，可能不适合用于模型监控和监督应用。


<details>
  <summary>更多</summary>
  
**动机:** 尽管现有对稀疏自编码器(SAEs)的评估集中在重建-稀疏权衡、人类可解释性和特征解耦等方面，但忽视了概念表示对输入扰动的鲁棒性这一关键方面。

**方法:** 将鲁棒性量化表述为输入空间优化问题，并开发了一个包含现实场景的全面评估框架，在这些场景中，对抗性扰动被设计用来操控SAE表示。

**结果:** 实证结果表明，微小的对抗性输入扰动可以在不影响基础LLMs输出的情况下有效操控基于概念的解释。

**结论:** SAE概念表示是脆弱的，可能不适用于模型监控和监督应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interpretability+Illusions+with+Sparse+Autoencoders%3A+Evaluating+Robustness+of+Concept+Representations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16004，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16004&send_immediately=true&force_search=false)

**原文摘要:** Sparse autoencoders (SAEs) are commonly used to interpret the internal
activations of large language models (LLMs) by mapping them to
human-interpretable concept representations. While existing evaluations of SAEs
focus on metrics such as the reconstruction-sparsity tradeoff, human
(auto-)interpretability, and feature disentanglement, they overlook a critical
aspect: the robustness of concept representations to input perturbations. We
argue that robustness must be a fundamental consideration for concept
representations, reflecting the fidelity of concept labeling. To this end, we
formulate robustness quantification as input-space optimization problems and
develop a comprehensive evaluation framework featuring realistic scenarios in
which adversarial perturbations are crafted to manipulate SAE representations.
Empirically, we find that tiny adversarial input perturbations can effectively
manipulate concept-based interpretations in most scenarios without notably
affecting the outputs of the base LLMs themselves. Overall, our results suggest
that SAE concept representations are fragile and may be ill-suited for
applications in model monitoring and oversight.

</details>


### [8] [GradPCA: Leveraging NTK Alignment for Reliable Out-of-Distribution Detection](https://arxiv.org/abs/2505.16017)
*Mariia Seleznova, Hung-Hsu Chou, Claudio Mayrink Verdun, Gitta Kutyniok*

**主要类别:** cs.LG

**概要:** 提出了一种名为GradPCA的新型OOD检测方法，利用神经网络梯度的低秩结构，并通过PCA应用于梯度类均值，提供理论支持并验证其在图像分类基准上的优越性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的OOD检测方法在不同数据集上表现不一致，需要一种更稳定和有效的检测方法。

**方法:** GradPCA方法利用了由神经切线核(NTK)对齐引起的神经网络梯度的低秩结构，将主成分分析(PCA)应用于梯度类均值。

**结果:** 广泛的实验表明GradPCA在标准图像分类基准上表现出更强的一致性，且特征质量（特别是预训练与非预训练表示的选择）对检测器的成功与否起关键作用。

**结论:** GradPCA为设计更原则性的频谱OOD检测器提供了理论框架和指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GradPCA%3A+Leveraging+NTK+Alignment+for+Reliable+Out-of-Distribution+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16017，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16017&send_immediately=true&force_search=false)

**原文摘要:** We introduce GradPCA, an Out-of-Distribution (OOD) detection method that
exploits the low-rank structure of neural network gradients induced by Neural
Tangent Kernel (NTK) alignment. GradPCA applies Principal Component Analysis
(PCA) to gradient class-means, achieving more consistent performance than
existing methods across standard image classification benchmarks. We provide a
theoretical perspective on spectral OOD detection in neural networks to support
GradPCA, highlighting feature-space properties that enable effective detection
and naturally emerge from NTK alignment. Our analysis further reveals that
feature quality -- particularly the use of pretrained versus non-pretrained
representations -- plays a crucial role in determining which detectors will
succeed. Extensive experiments validate the strong performance of GradPCA, and
our theoretical framework offers guidance for designing more principled
spectral OOD detectors.

</details>


### [9] [Toward Theoretical Insights into Diffusion Trajectory Distillation via Operator Merging](https://arxiv.org/abs/2505.16024)
*Weiguo Gao, Ming Li*

**主要类别:** cs.LG

**概要:** 这篇论文通过将扩散轨迹蒸馏重新解释为线性算子合并问题，提出了一种动态规划算法来计算最优合并策略，并发现了该策略中的相变现象，从而提高了对扩散轨迹蒸馏的理论理解。


<details>
  <summary>更多</summary>
  
**动机:** 现有的扩散轨迹蒸馏方法虽然可以加速采样过程，但对其不同策略与生成质量之间的权衡缺乏理论洞察，这使得优化和选择合适的蒸馏策略变得复杂。

**方法:** 作者将扩散轨迹蒸馏重新解释为线性算子合并问题，其中教师模型的每一步都被表示为作用于噪声数据的线性算子。通过动态规划算法计算出最优的合并策略，以最大程度地保留信号保真度。同时研究了数据协方差结构对最优策略的影响。

**结果:** 研究表明，在最优策略中存在由数据协方差结构控制的明显相变现象。这一发现加深了对扩散轨迹蒸馏的理论理解，并为改进蒸馏策略提供了实际指导。

**结论:** 这项工作为扩散轨迹蒸馏提供了新的理论视角，并通过动态规划算法和相变现象的研究，为提高蒸馏策略的有效性和生成质量提供了理论支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Toward+Theoretical+Insights+into+Diffusion+Trajectory+Distillation+via+Operator+Merging，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16024，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16024&send_immediately=true&force_search=false)

**原文摘要:** Diffusion trajectory distillation methods aim to accelerate sampling in
diffusion models, which produce high-quality outputs but suffer from slow
sampling speeds. These methods train a student model to approximate the
multi-step denoising process of a pretrained teacher model in a single step,
enabling one-shot generation. However, theoretical insights into the trade-off
between different distillation strategies and generative quality remain
limited, complicating their optimization and selection. In this work, we take a
first step toward addressing this gap. Specifically, we reinterpret trajectory
distillation as an operator merging problem in the linear regime, where each
step of the teacher model is represented as a linear operator acting on noisy
data. These operators admit a clear geometric interpretation as projections and
rescalings corresponding to the noise schedule. During merging, signal
shrinkage occurs as a convex combination of operators, arising from both
discretization and limited optimization time of the student model. We propose a
dynamic programming algorithm to compute the optimal merging strategy that
maximally preserves signal fidelity. Additionally, we demonstrate the existence
of a sharp phase transition in the optimal strategy, governed by data
covariance structures. Our findings enhance the theoretical understanding of
diffusion trajectory distillation and offer practical insights for improving
distillation strategies.

</details>


### [10] [Equivariant Eikonal Neural Networks: Grid-Free, Scalable Travel-Time Prediction on Homogeneous Spaces](https://arxiv.org/abs/2505.16035)
*Alejandro García-Castellanos, David R. Wessels, Nicky J. van den Berg, Remco Duits, Daniël M. Pelt, Erik J. Bekkers*

**主要类别:** cs.LG

**概要:** 提出了一种新的框架——Equivariant Neural Eikonal Solvers，它将Equivariant Neural Fields与Neural Eikonal Solvers相结合。通过单一神经场和共享主干网络，结合Physics-Informed Neural Networks (PINNs)，该方法能够准确地对不同Riemannian流形上的Eikonal旅行时间解进行建模，并在地震旅行时间建模任务中表现出优越的性能、可扩展性、适应性和用户可控性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的Neural Operator-based Eikonal求解器方法在处理任意Riemannian流形上的问题时存在性能、可扩展性及用户控制能力的不足，因此需要一种更高效且灵活的方法来解决Eikonal方程。

**方法:** 该方法使用单一神经场，其中统一的共享主干网络基于Lie群中的点云表示的信号特定潜在变量进行条件化，以建模多样化的Eikonal解。通过整合等变神经场（ENF），确保从潜在表示到解场的等变映射，提供权重共享带来的表示效率提升、稳健的几何基础以及解的可操控性。此外，通过将这些可操控的表示与物理信息神经网络（PINNs）结合，框架可以准确地对Eikonal旅行时间解进行建模，并推广到具有正则群作用的任意Riemannian流形。

**结果:** 实验结果表明，该方法在2D和3D基准数据集的地震旅行时间建模应用中，相较于现有的Neural Operator-based Eikonal求解器方法，表现出更高的性能、可扩展性、适应性和用户可控性。

**结论:** Equivariant Neural Eikonal Solvers框架通过结合ENFs和PINNs，能够在多种Riemannian流形上有效地解决Eikonal方程，并展现出优越的性能和灵活性，为相关领域提供了新的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Equivariant+Eikonal+Neural+Networks%3A+Grid-Free%2C+Scalable+Travel-Time+Prediction+on+Homogeneous+Spaces，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16035，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16035&send_immediately=true&force_search=false)

**原文摘要:** We introduce Equivariant Neural Eikonal Solvers, a novel framework that
integrates Equivariant Neural Fields (ENFs) with Neural Eikonal Solvers. Our
approach employs a single neural field where a unified shared backbone is
conditioned on signal-specific latent variables - represented as point clouds
in a Lie group - to model diverse Eikonal solutions. The ENF integration
ensures equivariant mapping from these latent representations to the solution
field, delivering three key benefits: enhanced representation efficiency
through weight-sharing, robust geometric grounding, and solution steerability.
This steerability allows transformations applied to the latent point cloud to
induce predictable, geometrically meaningful modifications in the resulting
Eikonal solution. By coupling these steerable representations with
Physics-Informed Neural Networks (PINNs), our framework accurately models
Eikonal travel-time solutions while generalizing to arbitrary Riemannian
manifolds with regular group actions. This includes homogeneous spaces such as
Euclidean, position-orientation, spherical, and hyperbolic manifolds. We
validate our approach through applications in seismic travel-time modeling of
2D and 3D benchmark datasets. Experimental results demonstrate superior
performance, scalability, adaptability, and user controllability compared to
existing Neural Operator-based Eikonal solver methods.

</details>


### [11] [Learning from Algorithm Feedback: One-Shot SAT Solver Guidance with GNNs](https://arxiv.org/abs/2505.16053)
*Jan Tönshoff, Martin Grohe*

**主要类别:** cs.LG

**概要:** 本研究提出了一种名为RLAF（Reinforcement Learning from Algorithm Feedback）的新方法，利用图神经网络（GNNs）学习指导SAT求解器的分支启发式算法。通过将推断出的变量权重和极性注入现有的SAT求解器分支启发式算法中，RLAF显著减少了不同基础求解器在各种SAT问题分布上的平均求解时间，在某些情况下实现了超过两倍的速度提升，并且能够有效推广到更大、更难的问题。相比基于手工设计权重启发式的专家监督方法，RLAF训练的策略表现更为出色，为组合优化中的数据驱动启发式设计提供了有希望的方向。


<details>
  <summary>更多</summary>
  
**动机:** SAT求解器是计算机科学的基础工具，但其性能通常依赖于人工设计的启发式算法。为了改进这一状况，需要一种自动化的方法来学习并指导SAT求解器的分支选择过程，以提高其效率和适用性。

**方法:** 研究引入了RLAF框架，使用图神经网络（GNNs）为SAT求解器的分支启发式算法提供单次指导。GNN通过一次前向传播为所有变量分配权重和极性参数。该问题被建模为强化学习问题，使用现成的策略梯度方法（如GRPO）进行训练，其中求解器的计算成本作为唯一的奖励信号。

**结果:** RLAF训练的策略显著降低了不同基础求解器在各种SAT问题分布上的平均求解时间，在某些情况下实现了超过两倍的速度提升。此外，这些策略在训练后能够有效推广到更大、更难的问题，并且一致优于基于手工设计权重启发式的专家监督方法。

**结论:** RLAF展示了通过数据驱动的方式设计组合优化启发式算法的潜力，为未来的研究提供了新的方向。通过结合强化学习和图神经网络，可以显著提高SAT求解器的性能和泛化能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+from+Algorithm+Feedback%3A+One-Shot+SAT+Solver+Guidance+with+GNNs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16053，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16053&send_immediately=true&force_search=false)

**原文摘要:** Boolean Satisfiability (SAT) solvers are foundational to computer science,
yet their performance typically hinges on hand-crafted heuristics. This work
introduces Reinforcement Learning from Algorithm Feedback (RLAF) as a paradigm
for learning to guide SAT solver branching heuristics with Graph Neural
Networks (GNNs). Central to our approach is a novel and generic mechanism for
injecting inferred variable weights and polarities into the branching
heuristics of existing SAT solvers. In a single forward pass, a GNN assigns
these parameters to all variables. Casting this one-shot guidance as a
reinforcement learning problem lets us train the GNN with off-the-shelf
policy-gradient methods, such as GRPO, directly using the solver's
computational cost as the sole reward signal. Extensive evaluations demonstrate
that RLAF-trained policies significantly reduce the mean solve times of
different base solvers across diverse SAT problem distributions, achieving more
than a 2x speedup in some cases, while generalizing effectively to larger and
harder problems after training. Notably, these policies consistently outperform
expert-supervised approaches based on learning handcrafted weighting
heuristics, offering a promising path towards data-driven heuristic design in
combinatorial optimization.

</details>


### [12] [Not All Models Suit Expert Offloading: On Local Routing Consistency of Mixture-of-Expert Models](https://arxiv.org/abs/2505.16056)
*Jingcong Liang, Siyuan Wang, Miren Tian, Yitong Li, Duyu Tang, Zhongyu Wei*

**主要类别:** cs.LG

**概要:** 本研究提出了用于衡量MoE模型局部路由一致性的两种新指标，并通过实验分析揭示了影响路由一致性的关键因素及缓存优化策略。


<details>
  <summary>更多</summary>
  
**动机:** 尽管一些研究利用了专家激活的局部性，但这种**局部路由一致性**在不同模型中的程度变化较大，尚未得到充分研究。因此需要更好的量化方法和理解，以优化MoE模型在内存受限设备上的部署。

**方法:** 提出了两个指标：(1) Segment Routing Best Performance (SRP)，评估固定专家组对一段令牌需求的覆盖率；(2) Segment Cache Best Hit Rate (SCH)，测量特定缓存大小限制下的最佳段级缓存命中率。通过这些指标分析了20个不同规模和架构的MoE大语言模型。

**结果:** 发现每层应用MoE且不使用共享专家的模型表现出最高的局部路由一致性。领域专业化的专家比词汇专业化的专家对路由一致性贡献更大。大多数模型可以通过大约2倍活跃专家数量的缓存大小，在缓存效果和效率之间取得良好平衡。

**结论:** Mixture-of-Experts (MoE)模型可以通过提高局部路由一致性来实现内存高效的部署，并且在不影响推理速度的情况下平衡缓存效果和效率。提出的方法和发现为未来内存优化的MoE设计提供了指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Not+All+Models+Suit+Expert+Offloading%3A+On+Local+Routing+Consistency+of+Mixture-of-Expert+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16056，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16056&send_immediately=true&force_search=false)

**原文摘要:** Mixture-of-Experts (MoE) enables efficient scaling of large language models
(LLMs) with sparsely activated experts during inference. To effectively deploy
large MoE models on memory-constrained devices, many systems introduce *expert
offloading* that caches a subset of experts in fast memory, leaving others on
slow memory to run on CPU or load on demand. While some research has exploited
the locality of expert activations, where consecutive tokens activate similar
experts, the degree of this **local routing consistency** varies across models
and remains understudied. In this paper, we propose two metrics to measure
local routing consistency of MoE models: (1) **Segment Routing Best Performance
(SRP)**, which evaluates how well a fixed group of experts can cover the needs
of a segment of tokens, and (2) **Segment Cache Best Hit Rate (SCH)**, which
measures the optimal segment-level cache hit rate under a given cache size
limit. We analyzed 20 MoE LLMs with diverse sizes and architectures and found
that models that apply MoE on every layer and do not use shared experts exhibit
the highest local routing consistency. We further showed that
domain-specialized experts contribute more to routing consistency than
vocabulary-specialized ones, and that most models can balance between cache
effectiveness and efficiency with cache sizes approximately 2x the active
experts. These findings pave the way for memory-efficient MoE design and
deployment without compromising inference speed. We publish the code for
replicating experiments at https://github.com/ljcleo/moe-lrc .

</details>


### [13] [Mesh-free sparse identification of nonlinear dynamics](https://arxiv.org/abs/2505.16058)
*Mars Liyao Gao, J. Nathan Kutz, Bernat Font*

**主要类别:** cs.LG

**概要:** 提出了一种名为mesh-free SINDy的新算法，该算法利用神经网络逼近和自动微分的力量，可以从任意传感器布置和非均匀时间数据采样中识别控制方程。该方法对高噪声水平和有限的数据具有鲁棒性，同时保持计算效率。实验表明，即使在高噪声和低数据情况下，mesh-free SINDy也能实现稳健的PDE发现。


<details>
  <summary>更多</summary>
  
**动机:** 识别动力系统的控制方程是科学建模中最重要的任务之一。然而，这一过程通常需要高质量的空间-时间数据，并且需要在结构化网格上均匀采样。为了克服这些限制，提出了mesh-free SINDy算法。

**方法:** mesh-free SINDy算法利用了神经网络逼近和自动微分的能力，可以从任意传感器布置和非均匀时间数据采样中识别控制方程。该方法不需要过多的超参数调整，使其广泛适用于许多科学和工程问题。

**结果:** 通过一系列偏微分方程（如Burgers'方程、热方程、Korteweg-De Vries方程和2D对流扩散方程）的详细数值实验，验证了该方法的有效性。即使在高噪声和低数据的情况下，mesh-free SINDy也能实现稳健的PDE发现。例如，对于Burgers'方程，使用5,000个样本和高达75%的噪声，或仅100个样本和1%的噪声，都能成功识别。所有这些都在不到一分钟的训练时间内完成。

**结论:** mesh-free SINDy是一种有效的方法，能够从任意传感器布置和非均匀时间数据采样中识别控制方程，对高噪声和有限数据具有鲁棒性，同时保持计算效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mesh-free+sparse+identification+of+nonlinear+dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16058，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16058&send_immediately=true&force_search=false)

**原文摘要:** Identifying the governing equations of a dynamical system is one of the most
important tasks for scientific modeling. However, this procedure often requires
high-quality spatio-temporal data uniformly sampled on structured grids. In
this paper, we propose mesh-free SINDy, a novel algorithm which leverages the
power of neural network approximation as well as auto-differentiation to
identify governing equations from arbitrary sensor placements and non-uniform
temporal data sampling. We show that mesh-free SINDy is robust to high noise
levels and limited data while remaining computationally efficient. In our
implementation, the training procedure is straight-forward and nearly free of
hyperparameter tuning, making mesh-free SINDy widely applicable to many
scientific and engineering problems. In the experiments, we demonstrate its
effectiveness on a series of PDEs including the Burgers' equation, the heat
equation, the Korteweg-De Vries equation and the 2D advection-diffusion
equation. We conduct detailed numerical experiments on all datasets, varying
the noise levels and number of samples, and we also compare our approach to
previous state-of-the-art methods. It is noteworthy that, even in high-noise
and low-data scenarios, mesh-free SINDy demonstrates robust PDE discovery,
achieving successful identification with up to 75% noise for the Burgers'
equation using 5,000 samples and with as few as 100 samples and 1% noise. All
of this is achieved within a training time of under one minute.

</details>


### [14] [Few-Shot Test-Time Optimization Without Retraining for Semiconductor Recipe Generation and Beyond](https://arxiv.org/abs/2505.16060)
*Shangding Gu, Donghao Ying, Ming Jin, Yu Joe Lu, Jun Wang, Javad Lavaei, Costas Spanos*

**主要类别:** cs.LG

**概要:** 提出了一种新的测试时优化框架Model Feedback Learning (MFL)，它可以在不重新训练模型或修改硬件的情况下优化预训练AI模型或已部署硬件系统的输入。MFL通过轻量级反向模型迭代搜索最优输入，适应新目标。在半导体等实际应用中，MFL显著优于贝叶斯优化和人类专家，并展示了广泛的应用前景。此外，MFL具有稳定性优化功能，增强了对过程变化的鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 当前许多方法依赖于调整模型参数来优化输入，但在某些实际场景（如半导体制造）中，修改已部署系统往往是不可行或成本过高的。因此需要一种无需重新训练模型或修改硬件即可优化输入的方法。

**方法:** 引入了Model Feedback Learning (MFL)框架，利用轻量级反向模型进行迭代搜索以找到最优输入。该方法不需要重新训练模型或修改硬件，能够高效适应新目标，并且特别适用于无法修改已部署系统的实际场景。

**结果:** 在半导体等离子蚀刻任务中，MFL仅需五次迭代即可生成目标配方，显著优于贝叶斯优化和人类专家。此外，在化学过程和电子系统中也表现出色，稳定性优化增强了其在高维控制设置中的鲁棒性。

**结论:** MFL提供了一种可扩展且高效的范式，用于在实际环境中部署智能控制，特别是在无法修改已部署系统的场景中展现出了广泛的应用潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Few-Shot+Test-Time+Optimization+Without+Retraining+for+Semiconductor+Recipe+Generation+and+Beyond，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16060，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16060&send_immediately=true&force_search=false)

**原文摘要:** We introduce Model Feedback Learning (MFL), a novel test-time optimization
framework for optimizing inputs to pre-trained AI models or deployed hardware
systems without requiring any retraining of the models or modifications to the
hardware. In contrast to existing methods that rely on adjusting model
parameters, MFL leverages a lightweight reverse model to iteratively search for
optimal inputs, enabling efficient adaptation to new objectives under
deployment constraints. This framework is particularly advantageous in
real-world settings, such as semiconductor manufacturing recipe generation,
where modifying deployed systems is often infeasible or cost-prohibitive. We
validate MFL on semiconductor plasma etching tasks, where it achieves target
recipe generation in just five iterations, significantly outperforming both
Bayesian optimization and human experts. Beyond semiconductor applications, MFL
also demonstrates strong performance in chemical processes (e.g., chemical
vapor deposition) and electronic systems (e.g., wire bonding), highlighting its
broad applicability. Additionally, MFL incorporates stability-aware
optimization, enhancing robustness to process variations and surpassing
conventional supervised learning and random search methods in high-dimensional
control settings. By enabling few-shot adaptation, MFL provides a scalable and
efficient paradigm for deploying intelligent control in real-world
environments.

</details>


### [15] [Merge to Mix: Mixing Datasets via Model Merging](https://arxiv.org/abs/2505.16066)
*Zhixu Silvia Tao, Kasper Vinken, Hao-Wei Yeh, Avi Cooper, Xavier Boix*

**主要类别:** cs.LG

**概要:** Mixing datasets for fine-tuning large models is crucial for downstream tasks, but it often relies on heuristics and trial-and-error. This paper proposes Merge to Mix, a method that accelerates dataset mixture composition through model merging. Experiments show that Merge to Mix outperforms current state-of-the-art methods in dataset selection for fine-tuning LMs.


<details>
  <summary>更多</summary>
  
**动机:** The motivation behind this paper is the challenge of effectively mixing datasets for fine-tuning large models to maximize performance on downstream tasks, which currently relies on heuristics and trial-and-error.

**方法:** The proposed method, Merge to Mix, accelerates composing dataset mixtures through model merging. It combines individually fine-tuned models using simple arithmetic operations, serving as a surrogate for a model fine-tuned on the entire mixture.

**结果:** Experiments demonstrate that Merge to Mix surpasses state-of-the-art methods in dataset selection for fine-tuning LMs.

**结论:** Merge to Mix provides an effective way to accelerate the process of selecting dataset mixtures for fine-tuning large models without requiring full fine-tuning on each candidate mixture.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Merge+to+Mix%3A+Mixing+Datasets+via+Model+Merging，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16066，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16066&send_immediately=true&force_search=false)

**原文摘要:** Mixing datasets for fine-tuning large models (LMs) has become critical for
maximizing performance on downstream tasks. However, composing effective
dataset mixtures typically relies on heuristics and trial-and-error, often
requiring multiple fine-tuning runs to achieve the desired outcome. We propose
a novel method, $\textit{Merge to Mix}$, that accelerates composing dataset
mixtures through model merging. Model merging is a recent technique that
combines the abilities of multiple individually fine-tuned LMs into a single LM
by using a few simple arithmetic operations. Our key insight is that merging
models individually fine-tuned on each dataset in a mixture can effectively
serve as a surrogate for a model fine-tuned on the entire mixture. Merge to Mix
leverages this insight to accelerate selecting dataset mixtures without
requiring full fine-tuning on each candidate mixture. Our experiments
demonstrate that Merge to Mix surpasses state-of-the-art methods in dataset
selection for fine-tuning LMs.

</details>


### [16] [Bidirectional Variational Autoencoders](https://arxiv.org/abs/2505.16074)
*Bart Kosko, Olaoluwa Adigun*

**主要类别:** cs.LG

**概要:** 本文提出了一种新的双向变分自编码器（BVAE）网络架构，通过单一神经网络实现编码和解码功能，在多个图像任务上表现出色，并减少约50%的参数量。


<details>
  <summary>更多</summary>
  
**动机:** 当前的变分自编码器（VAE）通常使用编码-解码器网络对来处理数据，但这种方法可能需要更多的参数。为了提高效率并优化性能，本研究提出了一种新的网络架构——双向变分自编码器（BVAE）。

**方法:** BVAE采用单一神经网络同时执行编码和解码任务，而不是传统的编码-解码器网络对。编码通过前向传播进行，而解码则通过同一突触网络的反向传播完成。

**结果:** 在四个图像任务（图像重建、分类、插值和生成）上的模拟实验表明，BVAE不仅将参数数量减少了近50%，而且在性能上略微优于单向VAE。

**结论:** BVAE作为一种高效的网络架构，能够在减少参数数量的同时提升或保持性能，为图像处理任务提供了一种有潜力的新方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bidirectional+Variational+Autoencoders，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16074，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16074&send_immediately=true&force_search=false)

**原文摘要:** We present the new bidirectional variational autoencoder (BVAE) network
architecture. The BVAE uses a single neural network both to encode and decode
instead of an encoder-decoder network pair. The network encodes in the forward
direction and decodes in the backward direction through the same synaptic web.
Simulations compared BVAEs and ordinary VAEs on the four image tasks of image
reconstruction, classification, interpolation, and generation. The image
datasets included MNIST handwritten digits, Fashion-MNIST, CIFAR-10, and
CelebA-64 face images. The bidirectional structure of BVAEs cut the parameter
count by almost 50% and still slightly outperformed the unidirectional VAEs.

</details>


### [17] [Ensembling Sparse Autoencoders](https://arxiv.org/abs/2505.16077)
*Soham Gadgil, Chris Lin, Su-In Lee*

**主要类别:** cs.LG

**概要:** 稀疏自编码器(SAEs)通常用于将神经网络激活分解为人类可解释的特征，但单个SAE只能捕获有限的特征子集。本文提出通过朴素装袋和提升方法集成多个SAEs以克服这一限制，并在三个语言模型和SAE架构设置下进行评估。结果表明，集成SAEs可以提高语言模型激活的重建、特征多样性、SAE稳定性以及在下游任务中的实际效用。


<details>
  <summary>更多</summary>
  
**动机:** 研究表明，使用不同初始权重训练的SAEs可以学习到不同的特征，这意味着单个SAE只能提取激活空间中有限的特征子集。

**方法:** 提出通过朴素装袋（对具有不同权重初始化的SAEs进行集成）和提升（依次训练SAEs以最小化残差误差）方法集成多个SAEs。

**结果:** 实证结果表明，集成SAEs可以改善语言模型激活的重建、特征多样性和SAE稳定性，并且在诸如概念检测和虚假相关性去除等下游任务中表现优于单个SAE。

**结论:** 集成多个SAEs能够有效提高特征提取能力、模型稳定性和在下游任务中的实际效用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Ensembling+Sparse+Autoencoders，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16077，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16077&send_immediately=true&force_search=false)

**原文摘要:** Sparse autoencoders (SAEs) are used to decompose neural network activations
into human-interpretable features. Typically, features learned by a single SAE
are used for downstream applications. However, it has recently been shown that
SAEs trained with different initial weights can learn different features,
demonstrating that a single SAE captures only a limited subset of features that
can be extracted from the activation space. Motivated by this limitation, we
propose to ensemble multiple SAEs through naive bagging and boosting.
Specifically, SAEs trained with different weight initializations are ensembled
in naive bagging, whereas SAEs sequentially trained to minimize the residual
error are ensembled in boosting. We evaluate our ensemble approaches with three
settings of language models and SAE architectures. Our empirical results
demonstrate that ensembling SAEs can improve the reconstruction of language
model activations, diversity of features, and SAE stability. Furthermore,
ensembling SAEs performs better than applying a single SAE on downstream tasks
such as concept detection and spurious correlation removal, showing improved
practical utility.

</details>


### [18] [FR-Mamba: Time-Series Physical Field Reconstruction Based on State Space Model](https://arxiv.org/abs/2505.16083)
*Jiahuan Long, Wenzhe Zhang, Ning Wang, Tingsong Jiang, Wen Yao*

**主要类别:** cs.LG

**概要:** 提出了一种新的物理场重建框架FR-Mamba，结合傅里叶神经算子(FNO)和状态空间模型(SSM)，能够有效捕捉长时间序列的时空特征，显著优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的深度学习方法在物理场重建中难以捕捉长时间依赖性，导致对时间演变物理系统的表现不佳。

**方法:** 设计了一个混合神经网络架构FR-Mamba，将傅里叶神经算子(FNO)与状态空间模型(SSM)相结合。其中，使用Mamba来建模长时间依赖性，并通过线性时间复杂度实现高效计算；FNO则用于捕捉非局部空间特征。最后融合两部分提取的时空表示以重建全场分布。

**结果:** 广泛的实验表明，该方法在流场重建任务中显著优于现有的PFR方法，在长序列上表现出高精度性能。

**结论:** FR-Mamba框架通过结合FNO和SSM，成功解决了现有方法无法有效捕捉长时间依赖性的问题，为物理场重建提供了高性能解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FR-Mamba%3A+Time-Series+Physical+Field+Reconstruction+Based+on+State+Space+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16083，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16083&send_immediately=true&force_search=false)

**原文摘要:** Physical field reconstruction (PFR) aims to predict the state distribution of
physical quantities (e.g., velocity, pressure, and temperature) based on
limited sensor measurements. It plays a critical role in domains such as fluid
dynamics and thermodynamics. However, existing deep learning methods often fail
to capture long-range temporal dependencies, resulting in suboptimal
performance on time-evolving physical systems. To address this, we propose
FR-Mamba, a novel spatiotemporal flow field reconstruction framework based on
state space modeling. Specifically, we design a hybrid neural network
architecture that combines Fourier Neural Operator (FNO) and State Space Model
(SSM) to capture both global spatial features and long-range temporal
dependencies. We adopt Mamba, a recently proposed efficient SSM architecture,
to model long-range temporal dependencies with linear time complexity. In
parallel, the FNO is employed to capture non-local spatial features by
leveraging frequency-domain transformations. The spatiotemporal representations
extracted by these two components are then fused to reconstruct the full-field
distribution of the physical system. Extensive experiments demonstrate that our
approach significantly outperforms existing PFR methods in flow field
reconstruction tasks, achieving high-accuracy performance on long sequences.

</details>


### [19] [A Survey of Large Language Models for Text-Guided Molecular Discovery: from Molecule Generation to Optimization](https://arxiv.org/abs/2505.16094)
*Ziqing Wang, Kexin Zhang, Zihan Zhao, Yibo Wen, Abhishek Pandey, Han Liu, Kaize Ding*

**主要类别:** cs.LG

**概要:** 大型语言模型（LLMs）正在通过自然语言和符号符号与化学空间进行文本引导的交互，引入分子发现领域的范式转变。本文综述了LLM在分子生成和优化两个核心任务中的新兴应用，并提供了最新和前瞻性的评论。基于我们提出的分类法，分析了每类问题的代表性技术，强调了在不同学习设置下如何利用LLM的能力。此外，还包括常用数据集和评估协议，讨论了关键挑战和未来方向。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型在分子发现领域展现出巨大潜力，能够通过自然语言处理与化学空间进行交互。为了推动这一新领域的发展，需要对现有技术和方法进行全面总结和前瞻性分析。

**方法:** 提出了一种针对分子生成和优化问题的分类法，分析了各类问题的代表性技术，探讨了LLM能力在不同学习设置下的应用，并介绍了常用的分子数据集和评估协议。

**结果:** 为研究人员提供了一个全面的资源，涵盖了LLM在分子科学中的应用现状、挑战及未来发展方向。

**结论:** LLM在分子发现领域具有广阔的应用前景，但仍面临许多挑战。未来的研究应关注模型性能提升、多模态数据整合以及更高效的分子生成和优化方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Survey+of+Large+Language+Models+for+Text-Guided+Molecular+Discovery%3A+from+Molecule+Generation+to+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16094，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16094&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are introducing a paradigm shift in molecular
discovery by enabling text-guided interaction with chemical spaces through
natural language, symbolic notations, with emerging extensions to incorporate
multi-modal inputs. To advance the new field of LLM for molecular discovery,
this survey provides an up-to-date and forward-looking review of the emerging
use of LLMs for two central tasks: molecule generation and molecule
optimization. Based on our proposed taxonomy for both problems, we analyze
representative techniques in each category, highlighting how LLM capabilities
are leveraged across different learning settings. In addition, we include the
commonly used datasets and evaluation protocols. We conclude by discussing key
challenges and future directions, positioning this survey as a resource for
researchers working at the intersection of LLMs and molecular science. A
continuously updated reading list is available at
https://github.com/REAL-Lab-NU/Awesome-LLM-Centric-Molecular-Discovery.

</details>


### [20] [Reinforcement Learning for Stock Transactions](https://arxiv.org/abs/2505.16099)
*Ziyi, Zhou, Nicholas Stern, Julien Laasri*

**主要类别:** cs.LG

**概要:** 本研究旨在应用强化学习（RL）来确定在给定时间范围内购买股票的最佳时机，并可扩展至确定最佳卖点。通过定义马尔可夫决策过程（MDP）问题，使用Q-Learning、线性函数近似Q-Learning和深度Q-Learning训练一系列代理模型，同时尝试用机器学习回归和分类模型预测股票价格。最终比较各代理模型以找出最优策略。


<details>
  <summary>更多</summary>
  
**动机:** 如果能在混乱的交易中找到规律，则可以利用这些洞察获得丰厚利润。因此，项目目标是应用强化学习技术来寻找买卖股票的最佳时机。

**方法:** 1. 定义自己的马尔可夫决策过程（MDP）问题，以适应免费现实数据的格式。
2. 使用Q-Learning、带有线性函数逼近的Q-Learning以及深度Q-Learning训练多个代理模型。
3. 采用机器学习中的回归和分类模型预测股票价格。
4. 比较不同代理模型的表现，判断其是否收敛到一个策略，并评估哪个策略能最大化股票市场利润。

**结果:** 通过训练和比较不同的代理模型，研究发现了一些能够收敛于策略的模型，并从中识别出表现最佳的策略。然而，具体结果未详细说明。

**结论:** 强化学习方法，特别是Q-Learning及其变体，能够在股票市场中找到有效的买卖策略。此外，结合机器学习模型预测股票价格进一步增强了研究的价值。未来可以通过更多调整优化模型性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reinforcement+Learning+for+Stock+Transactions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16099，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16099&send_immediately=true&force_search=false)

**原文摘要:** Much research has been done to analyze the stock market. After all, if one
can determine a pattern in the chaotic frenzy of transactions, then they could
make a hefty profit from capitalizing on these insights. As such, the goal of
our project was to apply reinforcement learning (RL) to determine the best time
to buy a stock within a given time frame. With only a few adjustments, our
model can be extended to identify the best time to sell a stock as well. In
order to use the format of free, real-world data to train the model, we define
our own Markov Decision Process (MDP) problem. These two papers [5] [6] helped
us in formulating the state space and the reward system of our MDP problem. We
train a series of agents using Q-Learning, Q-Learning with linear function
approximation, and deep Q-Learning. In addition, we try to predict the stock
prices using machine learning regression and classification models. We then
compare our agents to see if they converge on a policy, and if so, which one
learned the best policy to maximize profit on the stock market.

</details>


### [21] [Towards Trustworthy Keylogger detection: A Comprehensive Analysis of Ensemble Techniques and Feature Selections through Explainable AI](https://arxiv.org/abs/2505.16103)
*Monirul Islam Mahmud*

**主要类别:** cs.LG

**概要:** 本研究利用多种传统机器学习模型和高级集成方法进行键盘记录器检测，并通过特征选择方法优化性能，AdaBoost结合Fisher Score表现最佳，准确率高达99.76%。


<details>
  <summary>更多</summary>
  
**动机:** 键盘记录器检测对于识别异常系统行为（如打字与字符显示之间的延迟）和分析网络流量模式以发现数据外泄至关重要。为了提高检测效率并降低计算复杂度，需要对不同机器学习模型和特征选择方法进行综合评估。

**方法:** 使用了多种传统机器学习模型（SVC、随机森林、决策树、XGBoost、AdaBoost、逻辑回归和朴素贝叶斯）和高级集成方法（Stacking、Blending和Voting），以及特征选择方法（信息增益、Lasso L1和Fisher Score）。基于公开的Kaggle键盘记录器检测数据集进行实验，并采用可解释AI技术（SHAP和LIME）解释模型。

**结果:** AdaBoost结合Fisher Score取得了最佳性能，准确率达到99.76%，F1分数为0.99，精确率为100%，召回率为98.6%，特异性为1.0，AUC为0.99，接近完美分类。

**结论:** AdaBoost结合Fisher Score在键盘记录器检测任务中表现优异，能够提供高精度的预测结果，同时特征选择方法有助于降低计算复杂度。可解释AI技术进一步增强了模型的透明性和可信度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Trustworthy+Keylogger+detection%3A+A+Comprehensive+Analysis+of+Ensemble+Techniques+and+Feature+Selections+through+Explainable+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16103，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16103&send_immediately=true&force_search=false)

**原文摘要:** Keylogger detection involves monitoring for unusual system behaviors such as
delays between typing and character display, analyzing network traffic patterns
for data exfiltration. In this study, we provide a comprehensive analysis for
keylogger detection with traditional machine learning models - SVC, Random
Forest, Decision Tree, XGBoost, AdaBoost, Logistic Regression and Naive Bayes
and advanced ensemble methods including Stacking, Blending and Voting.
Moreover, feature selection approaches such as Information gain, Lasso L1 and
Fisher Score are thoroughly assessed to improve predictive performance and
lower computational complexity. The Keylogger Detection dataset from publicly
available Kaggle website is used in this project. In addition to accuracy-based
classification, this study implements the approach for model interpretation
using Explainable AI (XAI) techniques namely SHAP (Global) and LIME (Local) to
deliver finer explanations for how much each feature contributes in assisting
or hindering the detection process. To evaluate the models result, we have used
AUC score, sensitivity, Specificity, Accuracy and F1 score. The best
performance was achieved by AdaBoost with 99.76% accuracy, F1 score of 0.99,
100% precision, 98.6% recall, 1.0 specificity and 0.99 of AUC that is
near-perfect classification with Fisher Score.

</details>


### [22] [Tools in the Loop: Quantifying Uncertainty of LLM Question Answering Systems That Use Tools](https://arxiv.org/abs/2505.16113)
*Panagiotis Lymperopoulos, Vasanth Sarathy*

**主要类别:** cs.LG

**概要:** 本研究提出了一种新的框架，用于对调用外部工具的大型语言模型（LLMs）进行不确定性量化。该框架结合了LLM和外部工具的预测不确定性，并提出了高效的近似方法，使不确定性计算在实际应用中可行。实验结果表明，该框架在增强基于LLM系统的可信度方面非常有效，特别是在需要外部工具支持的情况下。


<details>
  <summary>更多</summary>
  
**动机:** 现代大型语言模型（LLMs）在预训练知识不足的领域通常需要依赖外部工具来提供准确答案。然而，在高风险应用中，评估综合系统输出的不确定性至关重要，而现有方法无法充分应对这种调用外部工具场景下的不确定性问题。

**方法:** 研究人员开发了一个新框架，将LLM和外部工具的预测不确定性结合起来进行量化。此外，他们扩展了先前针对令牌序列的不确定性量化方法，并提出了高效的近似算法以适应实际应用场景。通过两个合成问答数据集和检索增强生成（RAG）系统，验证了该框架的有效性。

**结果:** 实验结果显示，该框架能够有效提高基于LLM系统的可信度，尤其是在LLM内部知识不足且需要外部工具协助的情况下。

**结论:** 提出的框架为解决调用外部工具的LLMs中的不确定性问题提供了一种实用的方法，从而增强了这些系统在关键应用场景中的可靠性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Tools+in+the+Loop%3A+Quantifying+Uncertainty+of+LLM+Question+Answering+Systems+That+Use+Tools，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16113，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16113&send_immediately=true&force_search=false)

**原文摘要:** Modern Large Language Models (LLMs) often require external tools, such as
machine learning classifiers or knowledge retrieval systems, to provide
accurate answers in domains where their pre-trained knowledge is insufficient.
This integration of LLMs with external tools expands their utility but also
introduces a critical challenge: determining the trustworthiness of responses
generated by the combined system. In high-stakes applications, such as medical
decision-making, it is essential to assess the uncertainty of both the LLM's
generated text and the tool's output to ensure the reliability of the final
response. However, existing uncertainty quantification methods do not account
for the tool-calling scenario, where both the LLM and external tool contribute
to the overall system's uncertainty. In this work, we present a novel framework
for modeling tool-calling LLMs that quantifies uncertainty by jointly
considering the predictive uncertainty of the LLM and the external tool. We
extend previous methods for uncertainty quantification over token sequences to
this setting and propose efficient approximations that make uncertainty
computation practical for real-world applications. We evaluate our framework on
two new synthetic QA datasets, derived from well-known machine learning
datasets, which require tool-calling for accurate answers. Additionally, we
apply our method to retrieval-augmented generation (RAG) systems and conduct a
proof-of-concept experiment demonstrating the effectiveness of our uncertainty
metrics in scenarios where external information retrieval is needed. Our
results show that the framework is effective in enhancing trust in LLM-based
systems, especially in cases where the LLM's internal knowledge is insufficient
and external tools are required.

</details>


### [23] [A Generic Framework for Conformal Fairness](https://arxiv.org/abs/2505.16115)
*Aditya T. Vadlamani, Anutam Srinivasan, Pranav Maneriker, Ali Payani, Srinivasan Parthasarathy*

**主要类别:** cs.LG

**概要:** 这篇论文提出了Conformal Fairness的概念，通过一个理论基础良好的算法和框架来控制不同敏感群体之间的覆盖率差距。该框架利用了可交换性假设，适用于非IID数据类型（如图数据）。实验表明，该算法可以控制与公平性相关的差距，并且覆盖率符合理论预期。


<details>
  <summary>更多</summary>
  
**动机:** 现有的Conformal Prediction方法虽然提供了关于真实标签覆盖率的概率保证，但对数据集中敏感属性的存在是不可知的。因此需要一种新的方法来解决不同敏感群体之间的覆盖率差距问题。

**方法:** 作者形式化了Conformal Fairness的概念，并提出了一种理论基础良好的算法和框架，利用可交换性假设而非典型的IID假设，从而将Conformal Fairness应用于非IID数据类型和任务。

**结果:** 在图和表格数据集上的实验表明，提出的算法不仅可以控制覆盖率差距，还能满足公平性相关的要求，结果与理论预期一致。

**结论:** Conformal Fairness提供了一种有效的方法来控制不同敏感群体之间的覆盖率差距，同时满足公平性和覆盖率的要求，适用于更广泛的数据类型和任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Generic+Framework+for+Conformal+Fairness，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16115，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16115&send_immediately=true&force_search=false)

**原文摘要:** Conformal Prediction (CP) is a popular method for uncertainty quantification
with machine learning models. While conformal prediction provides probabilistic
guarantees regarding the coverage of the true label, these guarantees are
agnostic to the presence of sensitive attributes within the dataset. In this
work, we formalize \textit{Conformal Fairness}, a notion of fairness using
conformal predictors, and provide a theoretically well-founded algorithm and
associated framework to control for the gaps in coverage between different
sensitive groups. Our framework leverages the exchangeability assumption
(implicit to CP) rather than the typical IID assumption, allowing us to apply
the notion of Conformal Fairness to data types and tasks that are not IID, such
as graph data. Experiments were conducted on graph and tabular datasets to
demonstrate that the algorithm can control fairness-related gaps in addition to
coverage aligned with theoretical expectations.

</details>


### [24] [Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning](https://arxiv.org/abs/2505.16122)
*Junhong Lin, Xinyue Zeng, Jie Zhu, Song Wang, Julian Shun, Jun Wu, Dawei Zhou*

**主要类别:** cs.LG

**概要:** 大型语言模型（LLMs）在复杂推理任务中表现出色，但推理效率低下。本研究发现许多LLM存在过度思考的问题，即对于简单问题也生成冗长的推理过程。为解决这一问题，我们提出了BBAM（贝叶斯预算分配模型）和$E^3$指标，以捕捉正确性和计算效率之间的权衡。基于此，我们设计了Plan-and-Budget框架，该框架将复杂问题分解为子问题，并根据估计的复杂度自适应地分配token预算。实验表明，Plan-and-Budget提高了多种任务和模型的推理效率，显著减少了token使用量并提升了准确性。值得注意的是，它能使较小的模型（如DS-Qwen-32B）达到与较大模型（如DS-LLaMA-70B）相当的效率，且无需重新训练。


<details>
  <summary>更多</summary>
  
**动机:** 尽管LLMs在复杂推理任务上取得了显著成功，但其推理效率仍然较低。许多模型在处理简单问题时产生冗长的推理过程，而在较难的问题上又可能因固定token预算而导致推理不足。因此，需要一种方法来优化推理过程中的计算资源分配，从而提高效率。

**方法:** 1. 提出了BBAM（Bayesian Budget Allocation Model），用于对推理过程建模，并引入了$E^3$指标衡量正确性与计算效率之间的权衡。
2. 设计了Plan-and-Budget框架，该框架在测试时将复杂问题分解为子问题，并根据复杂度估计自适应地分配token预算。
3. 通过实验证明了Plan-and-Budget的有效性，展示了其在不同任务和模型上的性能提升。

**结果:** Plan-and-Budget框架在多个任务和模型上实现了显著改进：
- 准确性提升高达+70%。
- token使用量减少达-39%。
- $E^3$指标提升+187.5%。
此外，较小的模型（如DS-Qwen-32B）通过该框架能够达到与较大模型（如DS-LLaMA-70B）相匹配的效率。

**结论:** 本文提出了一种新的推理优化框架Plan-and-Budget，解决了LLMs在推理过程中存在的过度思考或推理不足的问题。通过将复杂问题分解为子问题并自适应分配token预算，该框架显著提高了推理效率，减少了计算资源消耗，同时展示了其在不同规模模型间的性能差距缩小能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Plan+and+Budget%3A+Effective+and+Efficient+Test-Time+Scaling+on+Large+Language+Model+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16122，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16122&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have achieved remarkable success in complex
reasoning tasks, but their inference remains computationally inefficient. We
observe a common failure mode in many prevalent LLMs, overthinking, where
models generate verbose and tangential reasoning traces even for simple
queries. Recent works have tried to mitigate this by enforcing fixed token
budgets, however, this can lead to underthinking, especially on harder
problems. Through empirical analysis, we identify that this inefficiency often
stems from unclear problem-solving strategies. To formalize this, we develop a
theoretical model, BBAM (Bayesian Budget Allocation Model), which models
reasoning as a sequence of sub-questions with varying uncertainty, and
introduce the $E^3$ metric to capture the trade-off between correctness and
computation efficiency. Building on theoretical results from BBAM, we propose
Plan-and-Budget, a model-agnostic, test-time framework that decomposes complex
queries into sub-questions and allocates token budgets based on estimated
complexity using adaptive scheduling. Plan-and-Budget improves reasoning
efficiency across a range of tasks and models, achieving up to +70% accuracy
gains, -39% token reduction, and +187.5% improvement in $E^3$. Notably, it
elevates a smaller model (DS-Qwen-32B) to match the efficiency of a larger
model (DS-LLaMA-70B)-demonstrating Plan-and-Budget's ability to close
performance gaps without retraining. Our code is available at
anonymous.4open.science/r/P-and-B-6513/.

</details>


### [25] [Directional Convergence, Benign Overfitting of Gradient Descent in leaky ReLU two-layer Neural Networks](https://arxiv.org/abs/2505.16204)
*Ichiro Hashimoto*

**主要类别:** cs.LG

**概要:** 这篇论文证明了固定宽度的带泄露ReLU两层神经网络在使用指数损失函数进行梯度下降优化时，其网络参数的方向性收敛。通过分析收敛方向，建立了良性的过拟合充分条件，并发现了测试误差界限中的新相变现象。这些结果不仅限于先前研究的近似正交数据设置。此外，在子高斯混合模型中，良性过拟合以高概率发生。


<details>
  <summary>更多</summary>
  
**动机:** 研究者希望证明使用梯度下降优化的固定宽度泄露ReLU两层神经网络的方向性收敛，以及探索良性过拟合的条件和测试误差界限中的相变现象，超越之前仅对梯度流和近似正交数据的研究。

**方法:** 作者通过细致分析网络参数的收敛方向，推导出良性过拟合的充分条件，并揭示测试误差界限中的新相变。他们还扩展了研究范围，不再局限于近似正交数据设置。

**结果:** 论文成功证明了固定宽度泄露ReLU两层神经网络在梯度下降优化下的方向性收敛，建立了良性过拟合的充分条件，并发现了一个新的测试误差界限中的相变现象。在子高斯混合模型中验证了良性过拟合发生的高概率性。

**结论:** 固定宽度泄露ReLU两层神经网络在梯度下降优化下表现出方向性收敛，且其良性过拟合和测试误差界限中的相变现象被揭示。这些结果适用于更广泛的数据设置，而不仅仅局限于近似正交数据。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Directional+Convergence%2C+Benign+Overfitting+of+Gradient+Descent+in+leaky+ReLU+two-layer+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16204，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16204&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we prove directional convergence of network parameters of
fixed width leaky ReLU two-layer neural networks optimized by gradient descent
with exponential loss, which was previously only known for gradient flow. By a
careful analysis of the convergent direction, we establish sufficient
conditions of benign overfitting and discover a new phase transition in the
test error bound. All of these results hold beyond the nearly orthogonal data
setting which was studied in prior works. As an application, we demonstrate
that benign overfitting occurs with high probability in sub-Gaussian mixture
models.

</details>


### [26] [Robust Invariant Representation Learning by Distribution Extrapolation](https://arxiv.org/abs/2505.16126)
*Kotaro Yoshida, Slavakis Konstantinos*

**主要类别:** cs.LG

**概要:** 这篇论文探讨了不变风险最小化(IRM)在深度学习中的应用，旨在通过学习不变表示来实现分布外(OOD)泛化。由于IRM提出了一个本质上具有挑战性的双层优化问题，大多数现有的方法（包括IRMv1）采用了基于惩罚的单层近似。然而，实证研究一致表明，这些方法经常无法优于调整良好的经验风险最小化(ERM)，强调了对更稳健的IRM实现的需求。本文理论上确定了一个关键限制，即许多IRM变体的惩罚项对有限的环境多样性和过度参数化非常敏感，导致性能下降。为了解决这个问题，提出了一种新的基于外推的框架，通过合成分布转移增强IRM惩罚，从而提高环境多样性。广泛的实验结果表明，所提出的方法在从合成设置到现实的、过度参数化的场景中始终优于最先进的IRM变体，验证了其有效性和鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管IRM被广泛研究，但现有方法往往不能超越良好调整的ERM，这表明需要更稳健的IRM方法。

**方法:** 提出了一种新的基于外推的框架，该框架通过合成分布转移增强IRM惩罚，从而提高环境多样性。

**结果:** 实验结果表明，在各种场景下，新方法始终优于现有的IRM变体，证明了其优越的有效性和鲁棒性。

**结论:** 通过增强环境多样性和减少对有限多样性和过度参数化的敏感性，提出的框架提供了一种更有效的IRM方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Robust+Invariant+Representation+Learning+by+Distribution+Extrapolation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16126，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16126&send_immediately=true&force_search=false)

**原文摘要:** Invariant risk minimization (IRM) aims to enable out-of-distribution (OOD)
generalization in deep learning by learning invariant representations. As IRM
poses an inherently challenging bi-level optimization problem, most existing
approaches -- including IRMv1 -- adopt penalty-based single-level
approximations. However, empirical studies consistently show that these methods
often fail to outperform well-tuned empirical risk minimization (ERM),
highlighting the need for more robust IRM implementations. This work
theoretically identifies a key limitation common to many IRM variants: their
penalty terms are highly sensitive to limited environment diversity and
over-parameterization, resulting in performance degradation. To address this
issue, a novel extrapolation-based framework is proposed that enhances
environmental diversity by augmenting the IRM penalty through synthetic
distributional shifts. Extensive experiments -- ranging from synthetic setups
to realistic, over-parameterized scenarios -- demonstrate that the proposed
method consistently outperforms state-of-the-art IRM variants, validating its
effectiveness and robustness.

</details>


### [27] [AdamS: Momentum Itself Can Be A Normalizer for LLM Pretraining and Post-training](https://arxiv.org/abs/2505.16363)
*Huishuai Zhang, Bohan Wang, Luoxin Chen*

**主要类别:** cs.LG

**概要:** 提出了一种名为AdamS的新优化器，适用于大型语言模型的预训练和后训练。通过利用动量和当前梯度平方加权和的平方根作为分母，AdamS消除了对二阶矩估计的需求，从而在保持与带动量的SGD相同内存和计算消耗的情况下，提供了优越的优化性能。AdamS继承了AdamW的超参数，无需修改优化器API或架构即可无缝集成到现有管道中。实验表明，AdamS在GPT-2和Llama2等多个任务中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 在Transformer目标函数中观察到的(L0, L1)平滑性属性是AdamS的出发点，其中局部平滑性由梯度大小决定，这些梯度大小可以进一步用动量大小近似。

**方法:** AdamS采用动量和当前梯度平方加权和的平方根作为分母，去除了对二阶矩估计的需求，并且可以直接继承AdamW的超参数。它与模型无关，可以无缝集成到现有管道中，无需修改优化器API或架构。

**结果:** AdamS在包括GPT-2和Llama2（高达13B参数）在内的各种任务上展示了强大的性能，包括预训练和强化学习中的后训练阶段。

**结论:** AdamS作为一种新的优化器，具有高效性、简单性和理论依据，成为现有优化器的一个有吸引力的替代方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AdamS%3A+Momentum+Itself+Can+Be+A+Normalizer+for+LLM+Pretraining+and+Post-training，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16363，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16363&send_immediately=true&force_search=false)

**原文摘要:** We introduce AdamS, a simple yet effective alternative to Adam for large
language model (LLM) pretraining and post-training. By leveraging a novel
denominator, i.e., the root of weighted sum of squares of the momentum and the
current gradient, AdamS eliminates the need for second-moment estimates. Hence,
AdamS is efficient, matching the memory and compute footprint of SGD with
momentum while delivering superior optimization performance. Moreover, AdamS is
easy to adopt: it can directly inherit hyperparameters of AdamW, and is
entirely model-agnostic, integrating seamlessly into existing pipelines without
modifications to optimizer APIs or architectures. The motivation behind AdamS
stems from the observed $(L_0, L_1)$ smoothness properties in transformer
objectives, where local smoothness is governed by gradient magnitudes that can
be further approximated by momentum magnitudes. We establish rigorous
theoretical convergence guarantees and provide practical guidelines for
hyperparameter selection. Empirically, AdamS demonstrates strong performance in
various tasks, including pre-training runs on GPT-2 and Llama2 (up to 13B
parameters) and reinforcement learning in post-training regimes. With its
efficiency, simplicity, and theoretical grounding, AdamS stands as a compelling
alternative to existing optimizers.

</details>


### [28] [Scalable Graph Generative Modeling via Substructure Sequences](https://arxiv.org/abs/2505.16130)
*Zehong Wang, Zheyuan Zhang, Tianyi Ma, Chuxu Zhang, Yanfang Ye*

**主要类别:** cs.LG

**概要:** 论文提出了一种超越消息传递的图神经网络方法，名为生成式图模式机（G²PM），它利用Transformer预训练框架将图实例表示为子结构序列，并展示了强大的可扩展性和优于先前生成方法的表现。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于消息传递的图神经网络（GNNs）尽管成功，但存在表达能力受限、过平滑、过度压缩以及难以建模长距离依赖等问题，这些问题限制了其可扩展性。

**方法:** G²PM将图实例（节点、边或整个图）表示为子结构序列，并通过在这些序列上进行生成式预训练来学习可泛化和可迁移的表示。此方法使用了一个Transformer预训练框架。

**结果:** G²PM表现出强大的可扩展性，在ogbn-arxiv基准测试中，模型参数量达到60M时性能持续提升，优于先前在更小规模（如3M参数）就达到性能上限的生成方法。此外，在包括节点分类、图分类和迁移学习在内的多种任务中，G²PM始终优于强大的基线模型。

**结论:** G²PM提供了一个有说服力的基础，用于可扩展的图学习，并且代码和数据集已在GitHub上公开。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+Graph+Generative+Modeling+via+Substructure+Sequences，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16130，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16130&send_immediately=true&force_search=false)

**原文摘要:** Graph neural networks (GNNs) has been predominantly driven by
message-passing, where node representations are iteratively updated via local
neighborhood aggregation. Despite their success, message-passing suffers from
fundamental limitations -- including constrained expressiveness,
over-smoothing, over-squashing, and limited capacity to model long-range
dependencies. These issues hinder scalability: increasing data size or model
size often fails to yield improved performance, limiting the viability of GNNs
as backbones for graph foundation models. In this work, we explore pathways
beyond message-passing and introduce Generative Graph Pattern Machine
(G$^2$PM), a generative Transformer pre-training framework for graphs. G$^2$PM
represents graph instances (nodes, edges, or entire graphs) as sequences of
substructures, and employs generative pre-training over the sequences to learn
generalizable, transferable representations. Empirically, G$^2$PM demonstrates
strong scalability: on the ogbn-arxiv benchmark, it continues to improve with
model sizes up to 60M parameters, outperforming prior generative approaches
that plateau at significantly smaller scales (e.g., 3M). In addition, we
systematically analyze the model design space, highlighting key architectural
choices that contribute to its scalability and generalization. Across diverse
tasks -- including node classification, graph classification, and transfer
learning -- G$^2$PM consistently outperforms strong baselines, establishing a
compelling foundation for scalable graph learning. The code and dataset are
available at https://github.com/Zehong-Wang/G2PM.

</details>


### [29] [Neighbour-Driven Gaussian Process Variational Autoencoders for Scalable Structured Latent Modelling](https://arxiv.org/abs/2505.16481)
*Xinxing Shi, Xiaoyu Jiang, Mauricio A. Álvarez*

**主要类别:** cs.LG

**概要:** 提出了一种基于邻居驱动的近似策略来实现可扩展的GPVAE推理，通过限制在每个数据点的最近邻进行计算，保留了关键的潜在依赖关系，并允许更灵活的核选择和减少对大量诱导点的需求。实验表明，该方法在预测性能和计算效率上优于其他GPVAE变体。


<details>
  <summary>更多</summary>
  
**动机:** 高斯过程变分自编码器（GPVAEs）通过用GP先验替代完全因子化的高斯先验，捕捉潜在变量之间的更丰富的相关性。然而，在大规模GPVAEs中进行精确的GP推理计算成本过高，现有方法通常依赖于限制性的核假设或大量的诱导点。

**方法:** 提出了一种邻居驱动的近似策略，利用潜在空间中的局部邻接性，将计算限制在每个数据点的最近邻，从而实现可扩展的GPVAE推理。

**结果:** 通过广泛的实验，包括表示学习、数据插补和条件生成任务，证明了该方法在预测性能和计算效率方面优于其他GPVAE变体。

**结论:** 所提出的邻居驱动近似策略在GPVAE推理中表现出优越的性能和效率，同时允许更灵活的核选择并减少了对大量诱导点的需求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Neighbour-Driven+Gaussian+Process+Variational+Autoencoders+for+Scalable+Structured+Latent+Modelling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16481，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16481&send_immediately=true&force_search=false)

**原文摘要:** Gaussian Process (GP) Variational Autoencoders (VAEs) extend standard VAEs by
replacing the fully factorised Gaussian prior with a GP prior, thereby
capturing richer correlations among latent variables. However, performing exact
GP inference in large-scale GPVAEs is computationally prohibitive, often
forcing existing approaches to rely on restrictive kernel assumptions or large
sets of inducing points. In this work, we propose a neighbour-driven
approximation strategy that exploits local adjacencies in the latent space to
achieve scalable GPVAE inference. By confining computations to the nearest
neighbours of each data point, our method preserves essential latent
dependencies, allowing more flexible kernel choices and mitigating the need for
numerous inducing points. Through extensive experiments on tasks including
representation learning, data imputation, and conditional generation, we
demonstrate that our approach outperforms other GPVAE variants in both
predictive performance and computational efficiency.

</details>


### [30] [Multimodal Online Federated Learning with Modality Missing in Internet of Things](https://arxiv.org/abs/2505.16138)
*Heqiang Wang, Xiang Liu, Xiaoxiong Zhong, Lixing Chen, Fangming Liu, Weizhe Zhang*

**主要类别:** cs.LG

**概要:** The paper introduces Multimodal Online Federated Learning (MMO-FL) and Prototypical Modality Mitigation (PMM) to address challenges in handling multimodal data with missing modalities in IoT environments.


<details>
  <summary>更多</summary>
  
**动机:** IoT devices generate vast amounts of multimodal data, necessitating advanced computational capabilities and distributed learning strategies. The real-time nature and storage limitations of edge devices call for an online learning paradigm.

**方法:** The authors propose MMO-FL for decentralized multimodal learning and PMM algorithm to mitigate the impact of missing modalities by leveraging prototype learning.

**结果:** Experimental results on two multimodal datasets show that PMM outperforms benchmarks in compensating for missing modalities.

**结论:** MMO-FL and PMM provide effective solutions for managing multimodal data with missing modalities in IoT environments.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multimodal+Online+Federated+Learning+with+Modality+Missing+in+Internet+of+Things，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16138，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16138&send_immediately=true&force_search=false)

**原文摘要:** The Internet of Things (IoT) ecosystem generates vast amounts of multimodal
data from heterogeneous sources such as sensors, cameras, and microphones. As
edge intelligence continues to evolve, IoT devices have progressed from simple
data collection units to nodes capable of executing complex computational
tasks. This evolution necessitates the adoption of distributed learning
strategies to effectively handle multimodal data in an IoT environment.
Furthermore, the real-time nature of data collection and limited local storage
on edge devices in IoT call for an online learning paradigm. To address these
challenges, we introduce the concept of Multimodal Online Federated Learning
(MMO-FL), a novel framework designed for dynamic and decentralized multimodal
learning in IoT environments. Building on this framework, we further account
for the inherent instability of edge devices, which frequently results in
missing modalities during the learning process. We conduct a comprehensive
theoretical analysis under both complete and missing modality scenarios,
providing insights into the performance degradation caused by missing
modalities. To mitigate the impact of modality missing, we propose the
Prototypical Modality Mitigation (PMM) algorithm, which leverages prototype
learning to effectively compensate for missing modalities. Experimental results
on two multimodal datasets further demonstrate the superior performance of PMM
compared to benchmarks.

</details>


### [31] [Incremental Sequence Classification with Temporal Consistency](https://arxiv.org/abs/2505.16548)
*Lucas Maystre, Gabriel Barello, Tudor Berariu, Aleix Cambray, Rares Dolga, Alvaro Ortega Gonzalez, Andrei Nica, David Barber*

**主要类别:** cs.LG

**概要:** 本论文探讨了增量序列分类问题，提出了一种基于时间差分学习的时序一致性条件，并据此开发了一种新的损失函数以提升训练效率和预测准确性。实验表明，该方法在文本分类任务及大语言模型生成结果验证中均表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 当前增量序列分类研究中缺乏对预测结果时序一致性的充分考虑，这可能导致数据利用效率低下以及预测性能不足。

**方法:** 受强化学习中时间差分学习的启发，识别出一种时序一致性条件，要求连续预测结果满足这一条件。基于此条件设计了一种新的损失函数，用于训练增量序列分类器。

**结果:** 在多个基准数据集上的文本分类任务中，该方法相较于其他方法显著提升了预测准确性；在验证大语言模型生成的小学数学题答案正确性任务中，仅需观察少数标记即可更有效地区分有潜力和无潜力的生成结果。

**结论:** 提出的时序一致性条件及其对应的损失函数能够有效提升增量序列分类任务的数据效率和预测性能，尤其适用于需要实时更新预测结果的应用场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Incremental+Sequence+Classification+with+Temporal+Consistency，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16548，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16548&send_immediately=true&force_search=false)

**原文摘要:** We address the problem of incremental sequence classification, where
predictions are updated as new elements in the sequence are revealed. Drawing
on temporal-difference learning from reinforcement learning, we identify a
temporal-consistency condition that successive predictions should satisfy. We
leverage this condition to develop a novel loss function for training
incremental sequence classifiers. Through a concrete example, we demonstrate
that optimizing this loss can offer substantial gains in data efficiency. We
apply our method to text classification tasks and show that it improves
predictive accuracy over competing approaches on several benchmark datasets. We
further evaluate our approach on the task of verifying large language model
generations for correctness in grade-school math problems. Our results show
that models trained with our method are better able to distinguish promising
generations from unpromising ones after observing only a few tokens.

</details>


### [32] [NAN: A Training-Free Solution to Coefficient Estimation in Model Merging](https://arxiv.org/abs/2505.16148)
*Chongjie Si, Kangtao Lv, Jingjing Jiang, Yadao Wang, Yongwei Wang, Xiaokang Yang, Wenbo Su, Bo Zheng, Wei Shen*

**主要类别:** cs.LG

**概要:** 本论文提出了一种名为NAN的方法，用于模型合并的系数估计，该方法基于参数范数的逆，并且无需训练、可即插即用，适用于多种合并策略。实验表明，NAN能够持续提升基线方法的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的模型合并方法通常依赖于启发式算法来确定合并系数，这限制了其可扩展性和通用性。因此，需要一种更系统化的方法来优化模型合并的权重。

**方法:** 作者通过最小二乘优化的角度重新审视模型合并问题，发现最佳的合并权重应与每个模型中编码的任务特定信息量成比例。基于这一观察，提出了NAN方法，利用参数范数的逆来估计模型合并系数。

**结果:** 在广泛的实验中，NAN方法被证明能够持续提升各种基线方法的性能。

**结论:** NAN是一种简单而有效的方法，无需训练即可实现即插即用，并适用于广泛的模型合并策略。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NAN%3A+A+Training-Free+Solution+to+Coefficient+Estimation+in+Model+Merging，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16148，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16148&send_immediately=true&force_search=false)

**原文摘要:** Model merging offers a training-free alternative to multi-task learning by
combining independently fine-tuned models into a unified one without access to
raw data. However, existing approaches often rely on heuristics to determine
the merging coefficients, limiting their scalability and generality. In this
work, we revisit model merging through the lens of least-squares optimization
and show that the optimal merging weights should scale with the amount of
task-specific information encoded in each model. Based on this insight, we
propose NAN, a simple yet effective method that estimates model merging
coefficients via the inverse of parameter norm. NAN is training-free,
plug-and-play, and applicable to a wide range of merging strategies. Extensive
experiments on show that NAN consistently improves performance of baseline
methods.

</details>


### [33] [Reconsidering Fairness Through Unawareness from the Perspective of Model Multiplicity](https://arxiv.org/abs/2505.16638)
*Benedikt Höltgen, Nuria Oliver*

**主要类别:** cs.LG

**概要:** 本论文探讨了通过无意识(FtU)方法在不必然降低准确性的情况下减少算法歧视的可能性，并结合模型多重性理论提供了新的见解，强调了在高风险场景中考虑FtU的价值。


<details>
  <summary>更多</summary>
  
**动机:** 尽管Fairness through Unawareness (FtU)长期以来被认为不足以确保公平性，但作者试图重新评估这一方法，证明其在某些情况下可以有效减少算法歧视而不牺牲预测准确性。

**方法:** 作者通过理论分析和实证研究相结合的方式，评估了FtU对算法公平性和准确性的双重影响，并将其与模型多重性（Model Multiplicity）理论联系起来。此外，还通过实际案例展示了FtU在政策制定中的应用潜力。

**结果:** 研究表明，FtU可以在不显著降低预测准确性的情况下减少算法歧视。同时，作者提出了在实际应用中应谨慎使用受保护属性（如性别），并提供明确的依据来支持其使用。

**结论:** 论文认为FtU值得在实际应用中考虑，特别是在高风险场景下，能够帮助实现更公平的政策决策，同时保持效能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reconsidering+Fairness+Through+Unawareness+from+the+Perspective+of+Model+Multiplicity，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16638，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16638&send_immediately=true&force_search=false)

**原文摘要:** Fairness through Unawareness (FtU) describes the idea that discrimination
against demographic groups can be avoided by not considering group membership
in the decisions or predictions. This idea has long been criticized in the
machine learning literature as not being sufficient to ensure fairness. In
addition, the use of additional features is typically thought to increase the
accuracy of the predictions for all groups, so that FtU is sometimes thought to
be detrimental to all groups. In this paper, we show both theoretically and
empirically that FtU can reduce algorithmic discrimination without necessarily
reducing accuracy. We connect this insight with the literature on Model
Multiplicity, to which we contribute with novel theoretical and empirical
results. Furthermore, we illustrate how, in a real-life application, FtU can
contribute to the deployment of more equitable policies without losing
efficacy. Our findings suggest that FtU is worth considering in practical
applications, particularly in high-risk scenarios, and that the use of
protected attributes such as gender in predictive models should be accompanied
by a clear and well-founded justification.

</details>


### [34] [Why Can Accurate Models Be Learned from Inaccurate Annotations?](https://arxiv.org/abs/2505.16159)
*Chongjie Si, Yidan Cui, Fuchao Yang, Xiaokang Yang, Wei Shen*

**主要类别:** cs.LG

**概要:** 本研究探讨了模型为何能在不准确标签的数据上训练后仍然能提取正确信息，并提出了轻量级插件LIP，以增强现有算法在各种不准确条件下的性能。


<details>
  <summary>更多</summary>
  
**动机:** 由于精确标注的成本高，从不准确的标注中学习受到了广泛关注。尽管存在错误标签，但模型仍能做出准确预测的现象尚未被深入探究。

**方法:** 通过分析权重矩阵的经验和理论视角，发现不准确标签主要在较低奇异值成分中积累噪声，轻微扰动主子空间。并在适中标签不准确的情况下，证明主子空间角度偏差最小，解释了模型仍能有效泛化的原因。基于这些见解，提出了一种轻量级插件LIP，帮助分类器保留主子空间信息并减轻标签不准确带来的噪声影响。

**结果:** 广泛的实验表明，LIP在各种不准确条件下都能一致提升现有算法的性能。

**结论:** 希望这些研究结果能为理解模型在不准确监督下的鲁棒性提供有价值的理论和实践见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Why+Can+Accurate+Models+Be+Learned+from+Inaccurate+Annotations%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16159，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16159&send_immediately=true&force_search=false)

**原文摘要:** Learning from inaccurate annotations has gained significant attention due to
the high cost of precise labeling. However, despite the presence of erroneous
labels, models trained on noisy data often retain the ability to make accurate
predictions. This intriguing phenomenon raises a fundamental yet largely
unexplored question: why models can still extract correct label information
from inaccurate annotations remains unexplored. In this paper, we conduct a
comprehensive investigation into this issue. By analyzing weight matrices from
both empirical and theoretical perspectives, we find that label inaccuracy
primarily accumulates noise in lower singular components and subtly perturbs
the principal subspace. Within a certain range, the principal subspaces of
weights trained on inaccurate labels remain largely aligned with those learned
from clean labels, preserving essential task-relevant information. We formally
prove that the angles of principal subspaces exhibit minimal deviation under
moderate label inaccuracy, explaining why models can still generalize
effectively. Building on these insights, we propose LIP, a lightweight plug-in
designed to help classifiers retain principal subspace information while
mitigating noise induced by label inaccuracy. Extensive experiments on tasks
with various inaccuracy conditions demonstrate that LIP consistently enhances
the performance of existing algorithms. We hope our findings can offer valuable
theoretical and practical insights to understand of model robustness under
inaccurate supervision.

</details>


### [35] [Sequential Monte Carlo for Policy Optimization in Continuous POMDPs](https://arxiv.org/abs/2505.16732)
*Hany Abdulsamad, Sahel Iqbal, Simo Särkkä*

**主要类别:** cs.LG

**概要:** 本论文提出了一种新的策略优化框架，适用于连续部分可观测马尔可夫决策过程（POMDPs），通过将策略学习视为非马尔可夫Feynman-Kac模型中的概率推断，解决了探索与利用之间的平衡问题。该方法无需外部探索奖励或手工启发式方法，通过开发嵌套序贯蒙特卡洛（SMC）算法来优化策略，并在标准连续POMDP基准测试中展示了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 在部分可观测的情况下，最优决策需要在减少不确定性（探索）和追求即时目标（利用）之间取得平衡。现有的方法难以有效应对这一挑战，尤其是在连续POMDP环境中。因此，需要一种新方法来明确解决探索与利用的平衡问题。

**方法:** 提出了一种新的策略优化框架，将策略学习作为非马尔可夫Feynman-Kac模型中的概率推断，该模型能够通过预测未来的观测结果来捕捉信息收集的价值。为了优化策略，开发了一种嵌套序贯蒙特卡洛（SMC）算法，该算法能够在由POMDP诱导的最佳轨迹分布样本下，有效地估计历史依赖的策略梯度。

**结果:** 所提出的算法在标准连续POMDP基准测试中表现出色，而现有方法在不确定性下的行动表现不佳。这表明新方法在处理探索与利用平衡问题方面具有显著优势。

**结论:** 本文提出的策略优化框架为连续POMDP提供了一种有效的方法，解决了探索与利用之间的平衡问题，无需外部探索奖励或手工启发式方法，展现了在不确定性环境下的优越性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sequential+Monte+Carlo+for+Policy+Optimization+in+Continuous+POMDPs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16732，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16732&send_immediately=true&force_search=false)

**原文摘要:** Optimal decision-making under partial observability requires agents to
balance reducing uncertainty (exploration) against pursuing immediate
objectives (exploitation). In this paper, we introduce a novel policy
optimization framework for continuous partially observable Markov decision
processes (POMDPs) that explicitly addresses this challenge. Our method casts
policy learning as probabilistic inference in a non-Markovian Feynman--Kac
model that inherently captures the value of information gathering by
anticipating future observations, without requiring extrinsic exploration
bonuses or handcrafted heuristics. To optimize policies under this model, we
develop a nested sequential Monte Carlo~(SMC) algorithm that efficiently
estimates a history-dependent policy gradient under samples from the optimal
trajectory distribution induced by the POMDP. We demonstrate the effectiveness
of our algorithm across standard continuous POMDP benchmarks, where existing
methods struggle to act under uncertainty.

</details>


### [36] [Enhancing Federated Survival Analysis through Peer-Driven Client Reputation in Healthcare](https://arxiv.org/abs/2505.16190)
*Navid Seidi, Satyaki Roy, Sajal Das*

**主要类别:** cs.LG

**概要:** 本论文提出了一种鲁棒的、由同行驱动的声誉机制，用于联邦医疗保健。通过结合去中心化的同行反馈与基于聚类的噪声处理，增强模型聚合，同时采用差分隐私保护敏感信息。实验表明该方法在处理数据异构性和声誉不足方面表现出色，能够有效降低噪声客户端更新的影响，并优于没有声誉系统的联邦学习方法。


<details>
  <summary>更多</summary>
  
**动机:** 联邦学习（FL）在数字健康领域具有巨大潜力，但机构间的异构性、缺乏持续的声誉以及不可靠的贡献仍然是主要挑战。

**方法:** 提出了一种结合去中心化同行反馈与基于聚类的噪声处理的混合通信模型，将联邦聚合和声誉机制解耦，并在共享客户端模型更新之前应用差分隐私以保护敏感信息。使用Cox比例风险模型进行生存分析，并通过一致性指数动态调整信任评分。

**结果:** 实验评估显示，该方法在合成数据集和SEER数据集上均能实现高且稳定的一致性指数值，有效降低了噪声客户端更新的影响。

**结论:** 所提出的声誉机制有效地解决了数据异构性和声誉不足的问题，并优于缺乏声誉系统的联邦学习方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Enhancing+Federated+Survival+Analysis+through+Peer-Driven+Client+Reputation+in+Healthcare，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16190，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16190&send_immediately=true&force_search=false)

**原文摘要:** Federated Learning (FL) holds great promise for digital health by enabling
collaborative model training without compromising patient data privacy.
However, heterogeneity across institutions, lack of sustained reputation, and
unreliable contributions remain major challenges. In this paper, we propose a
robust, peer-driven reputation mechanism for federated healthcare that employs
a hybrid communication model to integrate decentralized peer feedback with
clustering-based noise handling to enhance model aggregation. Crucially, our
approach decouples the federated aggregation and reputation mechanisms by
applying differential privacy to client-side model updates before sharing them
for peer evaluation. This ensures sensitive information remains protected
during reputation computation, while unaltered updates are sent to the server
for global model training. Using the Cox Proportional Hazards model for
survival analysis across multiple federated nodes, our framework addresses both
data heterogeneity and reputation deficit by dynamically adjusting trust scores
based on local performance improvements measured via the concordance index.
Experimental evaluations on both synthetic datasets and the SEER dataset
demonstrate that our method consistently achieves high and stable C-index
values, effectively down-weighing noisy client updates and outperforming FL
methods that lack a reputation system.

</details>


### [37] [Meta-reinforcement learning with minimum attention](https://arxiv.org/abs/2505.16741)
*Pilhwa Lee, Shashank Gupta*

**主要类别:** cs.LG

**概要:** 将最小关注原则应用于强化学习的奖励部分，探索其与元学习和稳定性的联系。通过基于模型的元学习、集成模型学习和基于梯度的元策略学习，展示了在高维非线性动力学中的优越性能，包括快速适应、减少方差和提高能源效率。


<details>
  <summary>更多</summary>
  
**动机:** 最小关注原则最初由Brockett提出，用于状态和时间控制的变化，其正则化在模拟生物控制（如运动学习）中具有重要意义。因此，研究者希望将其应用于强化学习中，以探索其与元学习和稳定性的联系。

**方法:** 将最小关注原则作为奖励的一部分应用于强化学习，结合基于模型的元学习方法，在高维非线性动力学中进行探索。具体来说，交替执行基于集成的模型学习和基于梯度的元策略学习。

**结果:** 实证结果表明，与无模型和基于模型的强化学习算法相比，最小关注原则表现出优越的能力，包括快速适应少量样本、减少模型和环境扰动带来的方差，并且提高了能源效率。

**结论:** 最小关注原则在强化学习中展现出显著优势，特别是在元学习和稳定性方面，为解决高维非线性动力学问题提供了有效的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Meta-reinforcement+learning+with+minimum+attention，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16741，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16741&send_immediately=true&force_search=false)

**原文摘要:** Minimum attention applies the least action principle in the changes of
control concerning state and time, first proposed by Brockett. The involved
regularization is highly relevant in emulating biological control, such as
motor learning. We apply minimum attention in reinforcement learning (RL) as
part of the rewards and investigate its connection to meta-learning and
stabilization. Specifically, model-based meta-learning with minimum attention
is explored in high-dimensional nonlinear dynamics. Ensemble-based model
learning and gradient-based meta-policy learning are alternately performed.
Empirically, we show that the minimum attention does show outperforming
competence in comparison to the state-of-the-art algorithms in model-free and
model-based RL, i.e., fast adaptation in few shots and variance reduction from
the perturbations of the model and environment. Furthermore, the minimum
attention demonstrates the improvement in energy efficiency.

</details>


### [38] [ICYM2I: The illusion of multimodal informativeness under missingness](https://arxiv.org/abs/2505.16953)
*Young Sang Choi, Vincent Jeanselme, Pierre Elias, Shalmali Joshi*

**主要类别:** cs.LG

**概要:** 在多模态学习中，由于多种因素（如成本、硬件故障或特定模态的信息感知价值），训练时可用的模态可能与部署时不同。本研究提出了一种框架ICYM2I，用于评估在模态缺失情况下的预测性能和信息增益，通过逆概率加权校正来解决忽略模态缺失导致的偏差。


<details>
  <summary>更多</summary>
  
**动机:** 结合不同类型的数据可以带来潜在的信息增益，推动了基于人工智能应用的多模态学习的发展。然而，在实际应用中，由于成本、硬件问题或对特定模态信息价值的不同认知，开发阶段收集的模态可能与部署阶段可用的模态不一致。简单估计新增模态的信息增益而不考虑缺失性可能导致对其下游任务价值的错误估计。

**方法:** 本文提出了一个问题，即多模态学习中的模态缺失，并展示了忽略这一过程所导致的偏差。为了解决该问题，引入了一个名为ICYM2I的框架，该框架使用逆概率加权校正方法，来评估在模态缺失情况下预测性能和信息增益。

**结果:** 通过在合成、半合成和真实世界医疗数据集上的实验，证明了所提出的调整方法在估计模态缺失情况下的信息增益的重要性。

**结论:** 研究正式化了多模态学习中模态缺失的问题，并通过ICYM2I框架提供了有效的解决方案，强调了在考虑模态缺失时正确估计信息增益的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ICYM2I%3A+The+illusion+of+multimodal+informativeness+under+missingness，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16953，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16953&send_immediately=true&force_search=false)

**原文摘要:** Multimodal learning is of continued interest in artificial intelligence-based
applications, motivated by the potential information gain from combining
different types of data. However, modalities collected and curated during
development may differ from the modalities available at deployment due to
multiple factors including cost, hardware failure, or -- as we argue in this
work -- the perceived informativeness of a given modality. Na{\"i}ve estimation
of the information gain associated with including an additional modality
without accounting for missingness may result in improper estimates of that
modality's value in downstream tasks. Our work formalizes the problem of
missingness in multimodal learning and demonstrates the biases resulting from
ignoring this process. To address this issue, we introduce ICYM2I (In Case You
Multimodal Missed It), a framework for the evaluation of predictive performance
and information gain under missingness through inverse probability
weighting-based correction. We demonstrate the importance of the proposed
adjustment to estimate information gain under missingness on synthetic,
semi-synthetic, and real-world medical datasets.

</details>


### [39] [NQKV: A KV Cache Quantization Scheme Based on Normal Distribution Characteristics](https://arxiv.org/abs/2505.16210)
*Zhihang Cai, Xingjun Zhang, Zhendong Tan, Zheng Wei*

**主要类别:** cs.LG

**概要:** 为了应对大语言模型（LLMs）推理过程中KV缓存内存消耗大的问题，本文提出了一种名为NQKV的算法。该算法通过分析KV缓存元素分布并采用基于块的分位数量化方法，实现了信息理论上最优的量化误差，并在不显著影响模型输出质量的前提下，使OPT模型能够以2倍的批量大小或4倍的上下文长度进行推理，且相比不使用KV缓存时提高了9.3倍的吞吐量。


<details>
  <summary>更多</summary>
  
**动机:** 大语言模型（LLMs）通常需要较大的批量大小来提高吞吐量或更长的上下文长度来满足任务需求，这会显著增加推理过程中KV缓存的内存资源消耗，成为LLM部署中的主要瓶颈。因此，需要一种方法来降低KV缓存的内存消耗。

**方法:** 1. 分析了KV缓存的元素分布，发现每个块内的元素遵循正态分布。
2. 基于上述发现，设计了NQKV算法，该算法采用基于块的分位数量化方法。
3. 该方法在理论上实现最优的量化误差，从而有效减少KV缓存的内存占用。

**结果:** NQKV算法能够在不显著影响模型输出质量的情况下，使OPT模型：
- 使用2倍的批量大小进行推理；
- 使用4倍的上下文长度进行推理；
- 相比不使用KV缓存时，提高了9.3倍的吞吐量。

**结论:** NQKV算法通过将KV缓存量化到更低比特，在保持模型输出质量的同时显著降低了内存消耗，为大语言模型的高效部署提供了一种有效的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NQKV%3A+A+KV+Cache+Quantization+Scheme+Based+on+Normal+Distribution+Characteristics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16210，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16210&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have demonstrated remarkable proficiency across
a wide range of tasks. However, LLMs often require larger batch sizes to
enhance throughput or longer context lengths to meet task demands, which
significantly increases the memory resource consumption of the Key-Value (KV)
cache during inference, becoming a major bottleneck in LLM deployment. To
address this issue, quantization is a common and straightforward approach.
Currently, quantization methods for activations are limited to 8-bit, and
quantization to even lower bits can lead to substantial accuracy drops. To
further save space by quantizing the KV cache to even lower bits, we analyzed
the element distribution of the KV cache and designed the NQKV algorithm. Since
the elements within each block of the KV cache follow a normal distribution,
NQKV employs per-block quantile quantization to achieve
information-theoretically optimal quantization error. Without significantly
compromising model output quality, NQKV enables the OPT model to perform
inference with an 2x larger batch size or a 4x longer context length, and it
improves throughput by 9.3x compared to when the KV cache is not used.

</details>


### [40] [Bigger Isn't Always Memorizing: Early Stopping Overparameterized Diffusion Models](https://arxiv.org/abs/2505.16959)
*Alessandro Favero, Antonio Sclocchi, Matthieu Wyart*

**主要类别:** cs.LG

**概要:** 扩散概率模型在训练前会经历一个自然数据领域的泛化过程，之后才开始记忆训练集，且记忆时间与数据集大小成正比。通过早停策略可以优化泛化并避免记忆，具有实际应用价值。


<details>
  <summary>更多</summary>
  
**动机:** 尽管扩散概率模型在生成式AI中占据核心地位，但其泛化的机制尚不明确。研究者希望理解这些模型如何在高度过参数化的情况下实现泛化而非单纯记忆训练数据。

**方法:** 研究者通过实验发现，在高度过参数化的扩散模型中，泛化在记忆开始之前就已经逐步实现。他们分析了从图像到语言扩散模型的多种情况，并研究了一个简单的随机规则的概率上下文无关文法的学习过程，以揭示泛化和记忆之间的动态关系。

**结果:** 结果表明，记忆时间与数据集大小成正比，泛化与记忆是时间尺度上的竞争关系。此外，早停策略能够有效优化泛化性能并避免过度记忆。

**结论:** 本研究支持使用与数据集大小相关的早停准则来优化扩散模型的泛化能力，这对超参数迁移和隐私敏感的应用具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bigger+Isn%27t+Always+Memorizing%3A+Early+Stopping+Overparameterized+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16959，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16959&send_immediately=true&force_search=false)

**原文摘要:** Diffusion probabilistic models have become a cornerstone of modern generative
AI, yet the mechanisms underlying their generalization remain poorly
understood. In fact, if these models were perfectly minimizing their training
loss, they would just generate data belonging to their training set, i.e.,
memorize, as empirically found in the overparameterized regime. We revisit this
view by showing that, in highly overparameterized diffusion models,
generalization in natural data domains is progressively achieved during
training before the onset of memorization. Our results, ranging from image to
language diffusion models, systematically support the empirical law that
memorization time is proportional to the dataset size. Generalization vs.
memorization is then best understood as a competition between time scales. We
show that this phenomenology is recovered in diffusion models learning a simple
probabilistic context-free grammar with random rules, where generalization
corresponds to the hierarchical acquisition of deeper grammar rules as training
time grows, and the generalization cost of early stopping can be characterized.
We summarize these results in a phase diagram. Overall, our results support
that a principled early-stopping criterion - scaling with dataset size - can
effectively optimize generalization while avoiding memorization, with direct
implications for hyperparameter transfer and privacy-sensitive applications.

</details>


### [41] [Reward-Aware Proto-Representations in Reinforcement Learning](https://arxiv.org/abs/2505.16217)
*Hon Tik Tse, Siddarth Chandrasekar, Marlos C. Machado*

**主要类别:** cs.LG

**概要:** 本文研究了默认表示（DR）的理论基础，并通过实验分析了其在奖励塑造、选项发现、探索和迁移学习等设置中的优势。与继承表示（SR）相比，DR表现出定性不同的、奖励感知的行为，并在多个设置中实现了更好的性能。


<details>
  <summary>更多</summary>
  
**动机:** 强化学习中，继承表示（SR）已被用于解决探索、信用分配和泛化等关键挑战，但它不考虑奖励动态。因此，需要一种类似但能考虑奖励动态的表示方法。

**方法:** 本文在表格情况下的默认表示（DR）建立了理论基础：(1) 推导动态规划和时间差分方法来学习DR；(2) 刻画DR向量空间的基础；(3) 通过默认特征将DR扩展到函数逼近情况。同时，在奖励塑造、选项发现、探索和迁移学习等多个场景中对DR进行了实证分析。

**结果:** 实验结果表明，与继承表示（SR）相比，DR产生了定性不同的、奖励感知的行为，并在多个场景中实现了定量上更好的性能。

**结论:** 默认表示（DR）是一种能够考虑奖励动态的表示方法，它在理论和实证上都展现了比继承表示（SR）更优越的特性，特别是在奖励感知行为和性能方面。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reward-Aware+Proto-Representations+in+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16217，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16217&send_immediately=true&force_search=false)

**原文摘要:** In recent years, the successor representation (SR) has attracted increasing
attention in reinforcement learning (RL), and it has been used to address some
of its key challenges, such as exploration, credit assignment, and
generalization. The SR can be seen as representing the underlying credit
assignment structure of the environment by implicitly encoding its induced
transition dynamics. However, the SR is reward-agnostic. In this paper, we
discuss a similar representation that also takes into account the reward
dynamics of the problem. We study the default representation (DR), a recently
proposed representation with limited theoretical (and empirical) analysis.
Here, we lay some of the theoretical foundation underlying the DR in the
tabular case by (1) deriving dynamic programming and (2) temporal-difference
methods to learn the DR, (3) characterizing the basis for the vector space of
the DR, and (4) formally extending the DR to the function approximation case
through default features. Empirically, we analyze the benefits of the DR in
many of the settings in which the SR has been applied, including (1) reward
shaping, (2) option discovery, (3) exploration, and (4) transfer learning. Our
results show that, compared to the SR, the DR gives rise to qualitatively
different, reward-aware behaviour and quantitatively better performance in
several settings.

</details>


### [42] [Guided Diffusion Sampling on Function Spaces with Applications to PDEs](https://arxiv.org/abs/2505.17004)
*Jiachen Yao, Abbas Mammadov, Julius Berner, Gavin Kerrigan, Jong Chul Ye, Kamyar Azizzadenesheli, Anima Anandkumar*

**主要类别:** cs.LG

**概要:** 提出了一种通用框架FunDPS，用于基于PDE的反问题中的条件采样。通过函数空间扩散模型和插件式引导方法，在极稀疏或嘈杂的测量条件下恢复完整解。该方法首先训练一个无条件的、与离散化无关的去噪模型，使用神经算子架构。在推理过程中，通过基于梯度的引导机制优化样本以满足稀疏观测数据。通过严格的数学分析，将Tweedie公式扩展到无限维希尔伯特空间，为后验采样方法提供了理论基础。在仅有3%观测数据的五个PDE任务中，该方法比最先进的固定分辨率扩散基线平均提高了32%的准确性，并减少了4倍的采样步骤。此外，多分辨率微调确保了强大的跨分辨率泛化能力。这是第一个独立于离散化的扩散模型框架，为PDE中的正向和反问题提供了一个实用且灵活的解决方案。


<details>
  <summary>更多</summary>
  
**动机:** 当前基于PDE的反问题解决方法在面对极稀疏或噪声测量时效果不佳，特别是在严重数据稀缺的情况下。因此需要一种新的方法来准确地恢复完整解并有效处理这些问题。

**方法:** 1. 提出FunDPS框架：结合函数空间扩散模型和插件式引导方法进行条件采样。
2. 训练阶段：使用神经算子架构构建一个无条件的、与离散化无关的去噪模型。
3. 推理阶段：通过基于梯度的引导机制优化样本，使其满足稀疏观测数据。
4. 理论支持：将Tweedie公式扩展到无限维希尔伯特空间，为后验采样方法提供理论依据。
5. 多分辨率微调：确保模型具有强大的跨分辨率泛化能力。

**结果:** 在五个PDE任务中，仅使用3%的观测数据，FunDPS方法比现有最先进的固定分辨率扩散基线平均提高了32%的准确性，并减少了4倍的采样步骤。

**结论:** FunDPS是第一个独立于离散化的扩散模型框架，能够准确捕获函数空间中的后验分布，即使在极小监督和严重数据稀缺的情况下也能表现出色。它为PDE中的正向和反问题提供了一个实用且灵活的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Guided+Diffusion+Sampling+on+Function+Spaces+with+Applications+to+PDEs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.17004，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.17004&send_immediately=true&force_search=false)

**原文摘要:** We propose a general framework for conditional sampling in PDE-based inverse
problems, targeting the recovery of whole solutions from extremely sparse or
noisy measurements. This is accomplished by a function-space diffusion model
and plug-and-play guidance for conditioning. Our method first trains an
unconditional discretization-agnostic denoising model using neural operator
architectures. At inference, we refine the samples to satisfy sparse
observation data via a gradient-based guidance mechanism. Through rigorous
mathematical analysis, we extend Tweedie's formula to infinite-dimensional
Hilbert spaces, providing the theoretical foundation for our posterior sampling
approach. Our method (FunDPS) accurately captures posterior distributions in
function spaces under minimal supervision and severe data scarcity. Across five
PDE tasks with only 3% observation, our method achieves an average 32% accuracy
improvement over state-of-the-art fixed-resolution diffusion baselines while
reducing sampling steps by 4x. Furthermore, multi-resolution fine-tuning
ensures strong cross-resolution generalizability. To the best of our knowledge,
this is the first diffusion-based framework to operate independently of
discretization, offering a practical and flexible solution for forward and
inverse problems in the context of PDEs. Code is available at
https://github.com/neuraloperator/FunDPS

</details>


### [43] [Realistic Evaluation of TabPFN v2 in Open Environments](https://arxiv.org/abs/2505.16226)
*Zi-Jian Cheng, Zi-Yi Jia, Zhi Zhou, Yu-Feng Li, Lan-Zhe Guo*

**主要类别:** cs.LG

**概要:** TabPFN v2在开放环境中的表现有限，适合小规模、协变量偏移和类别平衡的任务，而基于树的模型仍然是开放环境中通用表格任务的最佳选择。


<details>
  <summary>更多</summary>
  
**动机:** 尽管对TabPFN v2的研究已经很多，但大多数研究局限于封闭环境，忽视了开放环境中常见的挑战。因此，有必要评估TabPFN v2在开放环境中的适应性和鲁棒性。

**方法:** 构建了一个统一的评估框架，涵盖各种现实世界的挑战，并使用该框架评估TabPFN v2在开放环境场景下的鲁棒性。

**结果:** 实证结果表明，TabPFN v2在开放环境中表现出显著的局限性，但在小规模、协变量偏移和类别平衡的任务中表现良好。

**结论:** 基于树的模型仍然是开放环境中通用表格任务的最佳选择。为了促进未来的研究，建议建立开放环境的表格基准、多指标评估和通用模块以增强模型的鲁棒性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Realistic+Evaluation+of+TabPFN+v2+in+Open+Environments，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16226，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16226&send_immediately=true&force_search=false)

**原文摘要:** Tabular data, owing to its ubiquitous presence in real-world domains, has
garnered significant attention in machine learning research. While tree-based
models have long dominated tabular machine learning tasks, the recently
proposed deep learning model TabPFN v2 has emerged, demonstrating unparalleled
performance and scalability potential. Although extensive research has been
conducted on TabPFN v2 to further improve performance, the majority of this
research remains confined to closed environments, neglecting the challenges
that frequently arise in open environments. This raises the question: Can
TabPFN v2 maintain good performance in open environments? To this end, we
conduct the first comprehensive evaluation of TabPFN v2's adaptability in open
environments. We construct a unified evaluation framework covering various
real-world challenges and assess the robustness of TabPFN v2 under open
environments scenarios using this framework. Empirical results demonstrate that
TabPFN v2 shows significant limitations in open environments but is suitable
for small-scale, covariate-shifted, and class-balanced tasks. Tree-based models
remain the optimal choice for general tabular tasks in open environments. To
facilitate future research on open environments challenges, we advocate for
open environments tabular benchmarks, multi-metric evaluation, and universal
modules to strengthen model robustness. We publicly release our evaluation
framework at https://anonymous.4open.science/r/tabpfn-ood-4E65.

</details>


### [44] [Understanding Prompt Tuning and In-Context Learning via Meta-Learning](https://arxiv.org/abs/2505.17010)
*Tim Genewein, Kevin Wenliang Li, Jordi Grau-Moya, Anian Ruoss, Laurent Orseau, Marcus Hutter*

**主要类别:** cs.LG

**概要:** 这篇论文通过贝叶斯视角解释了最佳提示（prompting）的概念，并探讨了其固有限制，提出软前缀能有效提升提示效果，同时结合实验验证了不同模型和方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 当前的提示优化方法多依赖经验驱动，缺乏对提示概念的深入理解，因此需要从理论角度阐释提示机制及其限制。

**方法:** 作者通过贝叶斯视图理解最佳提示，将元训练神经网络视为预训练分布上的贝叶斯预测器，并研究条件化这些预测器以形成最佳提示的标准。此外，还通过实验比较LSTM和Transformer在不同前缀调优和权重调优方法下的表现。

**结果:** 实验表明，软前缀（soft prefixes）可以通过操纵激活方式提供比硬标记更有效的提示，适用于已训练和未训练的网络。这为提示机制提供了重要的机械论依据。

**结论:** 最佳提示可以通过贝叶斯理论形式化理解，但其固有限制只能通过调整权重克服。软前缀为提示优化提供了新的方向，超越了传统的标记限制。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+Prompt+Tuning+and+In-Context+Learning+via+Meta-Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.17010，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.17010&send_immediately=true&force_search=false)

**原文摘要:** Prompting is one of the main ways to adapt a pretrained model to target
tasks. Besides manually constructing prompts, many prompt optimization methods
have been proposed in the literature. Method development is mainly empirically
driven, with less emphasis on a conceptual understanding of prompting. In this
paper we discuss how optimal prompting can be understood through a Bayesian
view, which also implies some fundamental limitations of prompting that can
only be overcome by tuning weights. The paper explains in detail how
meta-trained neural networks behave as Bayesian predictors over the pretraining
distribution, whose hallmark feature is rapid in-context adaptation. Optimal
prompting can be studied formally as conditioning these Bayesian predictors,
yielding criteria for target tasks where optimal prompting is and is not
possible. We support the theory with educational experiments on LSTMs and
Transformers, where we compare different versions of prefix-tuning and
different weight-tuning methods. We also confirm that soft prefixes, which are
sequences of real-valued vectors outside the token alphabet, can lead to very
effective prompts for trained and even untrained networks by manipulating
activations in ways that are not achievable by hard tokens. This adds an
important mechanistic aspect beyond the conceptual Bayesian theory.

</details>


### [45] [Offline Guarded Safe Reinforcement Learning for Medical Treatment Optimization Strategies](https://arxiv.org/abs/2505.16242)
*Runze Yan, Xun Shen, Akifumi Wachi, Sebastien Gros, Anni Zhao, Xiao Hu*

**主要类别:** cs.LG

**概要:** 在医疗场景中应用离线强化学习时，OOD问题可能带来重大风险。现有的方法如保守Q学习（CQL）仅通过抑制不确定动作来约束动作选择，但未能有效规制下游状态轨迹。本文提出了一种基于模型的离线强化学习框架——离线守护安全强化学习（OGSRL），引入双重约束机制，在确保状态-动作轨迹分布内的情况下安全地改进策略。该框架包括一个OOD守护模块和一个安全性成本约束，提供理论上的安全性和近似最优性保证。


<details>
  <summary>更多</summary>
  
**动机:** 离线强化学习在医疗场景中的应用面临OOD问题的重大挑战，现有方法虽然尝试解决，但效果有限，因为它们仅关注动作选择的约束而忽略了对状态轨迹的规制。这限制了发现长期治疗策略的能力，因此需要一种新方法来在确保安全的同时改进策略。

**方法:** 提出了离线守护安全强化学习（OGSRL）框架，包含两个核心组件：1）OOD守护模块，用于定义临床验证的安全区域并限制优化过程在这些区域内进行；2）安全性成本约束，将医学知识编码为生理安全边界以防止潜在危险干预。通过这两个机制，OGSRL能够在不偏离支持的状态-动作轨迹的前提下探索优于临床医生行为的治疗策略。

**结果:** 理论上证明了满足约束条件的策略能够保持在安全可靠区域内，并实现接近数据支持的最佳策略的性能。实验结果表明，与现有方法相比，OGSRL可以更有效地改进策略，同时确保安全性和可靠性。

**结论:** OGSRL提供了一种新的离线强化学习方法，可以在医疗场景中安全地改进策略，超越临床医生推荐的行为，同时确保状态-动作轨迹保持在分布内。这种方法具有理论保障，并为实际应用提供了可靠的解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Offline+Guarded+Safe+Reinforcement+Learning+for+Medical+Treatment+Optimization+Strategies，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16242，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16242&send_immediately=true&force_search=false)

**原文摘要:** When applying offline reinforcement learning (RL) in healthcare scenarios,
the out-of-distribution (OOD) issues pose significant risks, as inappropriate
generalization beyond clinical expertise can result in potentially harmful
recommendations. While existing methods like conservative Q-learning (CQL)
attempt to address the OOD issue, their effectiveness is limited by only
constraining action selection by suppressing uncertain actions. This
action-only regularization imitates clinician actions that prioritize
short-term rewards, but it fails to regulate downstream state trajectories,
thereby limiting the discovery of improved long-term treatment strategies. To
safely improve policy beyond clinician recommendations while ensuring that
state-action trajectories remain in-distribution, we propose \textit{Offline
Guarded Safe Reinforcement Learning} ($\mathsf{OGSRL}$), a theoretically
grounded model-based offline RL framework. $\mathsf{OGSRL}$ introduces a novel
dual constraint mechanism for improving policy with reliability and safety.
First, the OOD guardian is established to specify clinically validated regions
for safe policy exploration. By constraining optimization within these regions,
it enables the reliable exploration of treatment strategies that outperform
clinician behavior by leveraging the full patient state history, without
drifting into unsupported state-action trajectories. Second, we introduce a
safety cost constraint that encodes medical knowledge about physiological
safety boundaries, providing domain-specific safeguards even in areas where
training data might contain potentially unsafe interventions. Notably, we
provide theoretical guarantees on safety and near-optimality: policies that
satisfy these constraints remain in safe and reliable regions and achieve
performance close to the best possible policy supported by the data.

</details>


### [46] [Graph Neural Network-Based Collaborative Perception for Adaptive Scheduling in Distributed Systems](https://arxiv.org/abs/2505.16248)
*Wenxuan Zhu, Qiyuan Wu, Tengda Tang, Renzi Meng, Sheng Chai, Xuehui Quan*

**主要类别:** cs.LG

**概要:** A GNN-based multi-node collaborative perception mechanism is proposed to address limitations in distributed systems, showing superior performance in experiments.


<details>
  <summary>更多</summary>
  
**动机:** To overcome the limitations of multi-node perception and delayed scheduling response in distributed systems.

**方法:** The system is modeled as a graph structure with message-passing and state-update modules. A multi-layer GNN is constructed for information aggregation and state inference. A perception representation method fuses local states with global features.

**结果:** The proposed method outperforms mainstream algorithms in task completion rate, average latency, load balancing, and transmission efficiency under various conditions including limited bandwidth and dynamic structural changes.

**结论:** The GNN-based multi-node collaborative perception mechanism demonstrates superior perception capabilities and cooperative scheduling performance.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph+Neural+Network-Based+Collaborative+Perception+for+Adaptive+Scheduling+in+Distributed+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16248，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16248&send_immediately=true&force_search=false)

**原文摘要:** This paper addresses the limitations of multi-node perception and delayed
scheduling response in distributed systems by proposing a GNN-based multi-node
collaborative perception mechanism. The system is modeled as a graph structure.
Message-passing and state-update modules are introduced. A multi-layer graph
neural network is constructed to enable efficient information aggregation and
dynamic state inference among nodes. In addition, a perception representation
method is designed by fusing local states with global features. This improves
each node's ability to perceive the overall system status. The proposed method
is evaluated within a customized experimental framework. A dataset featuring
heterogeneous task loads and dynamic communication topologies is used.
Performance is measured in terms of task completion rate, average latency, load
balancing, and transmission efficiency. Experimental results show that the
proposed method outperforms mainstream algorithms under various conditions,
including limited bandwidth and dynamic structural changes. It demonstrates
superior perception capabilities and cooperative scheduling performance. The
model achieves rapid convergence and efficient responses to complex system
states.

</details>


### [47] [Small-to-Large Generalization: Data Influences Models Consistently Across Scale](https://arxiv.org/abs/2505.16260)
*Alaa Khaddaj, Logan Engstrom, Aleksander Madry*

**主要类别:** cs.LG

**概要:** 通过研究发现，小规模和大规模语言模型的预测结果在训练数据选择上通常高度相关。基于此，研究探讨了代理模型规模对数据归因和数据集选择两个下游任务效果的影响。


<details>
  <summary>更多</summary>
  
**动机:** 当前实践中，由于大规模模型训练成本高，难以精确描述训练数据变化对预测的影响，因此通常使用易于训练的小规模代理模型进行推断。然而，数据变化对不同规模模型的影响并不相同，这促使我们探究训练数据分布如何影响不同计算规模下的模型行为。

**方法:** 研究分析了不同规模（小规模与大规模）的语言模型预测结果在训练数据选择上的相关性，并以此为基础，进一步探讨代理模型规模对数据归因和数据集选择这两个下游任务效果的影响。

**结果:** 研究表明，小规模和大规模语言模型的预测结果在训练数据选择上通常具有高度相关性。此外，研究还明确了代理模型规模对数据归因和数据集选择任务效果的具体影响。

**结论:** 训练数据分布对不同规模模型的行为有显著影响，但小规模和大规模语言模型的预测结果在训练数据选择上表现出高度相关性。这一发现为使用小规模代理模型来理解大规模模型行为提供了理论支持，同时强调了在数据归因和数据集选择任务中考虑代理模型规模的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Small-to-Large+Generalization%3A+Data+Influences+Models+Consistently+Across+Scale，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16260，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16260&send_immediately=true&force_search=false)

**原文摘要:** Choice of training data distribution greatly influences model behavior. Yet,
in large-scale settings, precisely characterizing how changes in training data
affects predictions is often difficult due to model training costs. Current
practice is to instead extrapolate from scaled down, inexpensive-to-train proxy
models. However, changes in data do not influence smaller and larger models
identically. Therefore, understanding how choice of data affects large-scale
models raises the question: how does training data distribution influence model
behavior across compute scale? We find that small- and large-scale language
model predictions (generally) do highly correlate across choice of training
data. Equipped with these findings, we characterize how proxy scale affects
effectiveness in two downstream proxy model applications: data attribution and
dataset selection.

</details>


### [48] [Think-RM: Enabling Long-Horizon Reasoning in Generative Reward Models](https://arxiv.org/abs/2505.16265)
*Ilgee Hong, Changlong Yu, Liang Qiu, Weixiang Yan, Zhenghao Xu, Haoming Jiang, Qingru Zhang, Qin Lu, Xin Liu, Chao Zhang, Tuo Zhao*

**主要类别:** cs.LG

**概要:** Think-RM是一种新的训练框架，通过模拟内部思考过程，使生成奖励模型（GenRMs）能够进行长时推理。它通过监督微调和基于规则的强化学习提升模型能力，并提出了一种新的成对强化学习管道以优化策略。实验表明，Think-RM在RM-Bench上超越了现有方法8%，并在与新管道结合时表现出更优的最终策略性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前生成奖励模型（GenRMs）虽然比传统的Bradley-Terry奖励模型（BT RMs）更鲁棒，但仍然受限于浅层推理能力和无法直接输出点对奖励信号的问题，这限制了其处理复杂任务的能力以及与标准RLHF算法的兼容性。

**方法:** 1. 提出Think-RM框架，通过建模内部思考过程生成灵活的自我引导推理痕迹，支持自省、假设推理和发散推理。
2. 使用监督微调（SFT）在长链推理数据上预热模型。
3. 采用基于规则的强化学习进一步提升模型的长时推理能力。
4. 提出一种新的成对强化学习管道，直接优化策略以使用成对偏好奖励，无需转换为点对奖励。

**结果:** 在RM-Bench基准测试中，Think-RM超越了BT RM和垂直扩展的GenRM，表现提高了8%。同时，当与提出的成对RLHF管道结合时，展示了优于传统方法的最终策略性能。

**结论:** Think-RM通过引入长时推理能力显著提升了生成奖励模型的表现，并且其成对RLHF管道提高了奖励信号的有效利用，为未来研究提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Think-RM%3A+Enabling+Long-Horizon+Reasoning+in+Generative+Reward+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16265，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16265&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement learning from human feedback (RLHF) has become a powerful
post-training paradigm for aligning large language models with human
preferences. A core challenge in RLHF is constructing accurate reward signals,
where the conventional Bradley-Terry reward models (BT RMs) often suffer from
sensitivity to data size and coverage, as well as vulnerability to reward
hacking. Generative reward models (GenRMs) offer a more robust alternative by
generating chain-of-thought (CoT) rationales followed by a final reward.
However, existing GenRMs rely on shallow, vertically scaled reasoning, limiting
their capacity to handle nuanced or complex (e.g., reasoning-intensive) tasks.
Moreover, their pairwise preference outputs are incompatible with standard RLHF
algorithms that require pointwise reward signals. In this work, we introduce
Think-RM, a training framework that enables long-horizon reasoning in GenRMs by
modeling an internal thinking process. Rather than producing structured,
externally provided rationales, Think-RM generates flexible, self-guided
reasoning traces that support advanced capabilities such as self-reflection,
hypothetical reasoning, and divergent reasoning. To elicit these reasoning
abilities, we first warm-up the models by supervised fine-tuning (SFT) over
long CoT data. We then further improve the model's long-horizon abilities by
rule-based reinforcement learning (RL). In addition, we propose a novel
pairwise RLHF pipeline that directly optimizes policies using pairwise
preference rewards, eliminating the need for pointwise reward conversion and
enabling more effective use of Think-RM outputs. Experiments show that Think-RM
achieves state-of-the-art results on RM-Bench, outperforming both BT RM and
vertically scaled GenRM by 8%. When combined with our pairwise RLHF pipeline,
it demonstrates superior end-policy performance compared to traditional
approaches.

</details>


### [49] [Only Large Weights (And Not Skip Connections) Can Prevent the Perils of Rank Collapse](https://arxiv.org/abs/2505.16284)
*Josh Alman, Zhao Song*

**主要类别:** cs.LG

**概要:** 注意力机制在现代大型语言模型（LLMs）中起着核心作用。尽管计算前向和后向梯度的直接算法需要二次时间复杂度，但研究表明，如果模型权重较小，则几乎线性时间的算法是可能的。然而，本文证明了大权重对于避免表示能力不足的问题（称为层坍缩）是必要的。因此，为了保持Transformer的表现力，注意力机制的二次运行时间不可避免。


<details>
  <summary>更多</summary>
  
**动机:** 研究旨在探讨为何注意力机制在大型语言模型中需要二次时间复杂度，并分析小权重对模型表示能力的影响。具体来说，作者希望揭示为什么大权重对于避免层坍缩（layer collapse）至关重要，从而解释为什么注意力机制的时间复杂度无法进一步降低。

**方法:** 作者引入了“层坍缩”的概念，这是一种表示能力不足的现象，意味着整个网络可以用单层网络很好地近似。通过理论分析，作者证明了当权重较小时，即使存在跳跃连接，层坍缩仍会发生。只有大权重可以有效避免这种现象，从而维持模型的表示能力。

**结果:** 研究表明，大权重对于避免层坍缩是必要的。这意味着为了保持Transformer模型的表达能力，注意力机制的二次运行时间不可避免。此外，作者还指出，跳跃连接并不能解决小权重导致的表示能力不足问题。

**结论:** 本文通过引入“层坍缩”概念，揭示了大权重在避免表示能力不足方面的重要性。结果表明，为了维持Transformer模型的表现力，注意力机制的二次运行时间是不可避免的。这为理解模型设计中的权衡提供了新的视角。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Only+Large+Weights+%28And+Not+Skip+Connections%29+Can+Prevent+the+Perils+of+Rank+Collapse，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16284，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16284&send_immediately=true&force_search=false)

**原文摘要:** Attention mechanisms lie at the heart of modern large language models (LLMs).
Straightforward algorithms for forward and backward (gradient) computation take
quadratic time, and a line of work initiated by [Alman and Song NeurIPS 2023]
and [Alman and Song NeurIPS 2024] has shown that quadratic time is necessary
unless the model weights are small, in which case almost linear time algorithms
are possible. In this paper, we show that large weights are necessary to avoid
a strong preclusion to representational strength we call layer collapse, which
means that the entire network can be approximated well by a network with only a
single layer. Thus, the quadratic running time of attention is unavoidable for
expressive transformers.
  The notion of layer collapse that we introduce is a variant on the notion of
rank collapse from the work of [Dong, Cordonnier, and Loukas ICML 2021]. They
showed that in Self Attention Networks with small weights and with skip
connections, rank collapse must occur. This is typically interpreted as
justifying the necessity of skip connections in expressive networks. However,
our result shows that even with skip connections, if the weights are small,
then layer collapse still occurs. Thus, only large weights, and not skip
connections, can prevent these representational weaknesses.

</details>


### [50] [Fairness under Competition](https://arxiv.org/abs/2505.16291)
*Ronen Gradwohl, Eilam Shapira, Moshe Tennenholtz*

**主要类别:** cs.LG

**概要:** 尽管单个分类器是公平的，但竞争性分类器可能仍会导致不公平的生态系统结果。改善个体公平性可能导致生态系统公平性的整体下降。


<details>
  <summary>更多</summary>
  
**动机:** 研究采用公平分类器对整体生态系统公平性的影响，特别是引入竞争企业环境下的公平性研究。

**方法:** 量化系统中公平性的损失，基于分类器的相关性和数据重叠程度，并提供理论和实验结果支持。

**结果:** 即使竞争分类器单独满足公平性要求，生态系统的整体结果仍可能不公平；提高个体公平性可能导致生态系统公平性的下降。

**结论:** 需要采取新的行动来解决生态系统层面的公平性问题，而不仅仅是调整个体分类器。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fairness+under+Competition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16291，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16291&send_immediately=true&force_search=false)

**原文摘要:** Algorithmic fairness has emerged as a central issue in ML, and it has become
standard practice to adjust ML algorithms so that they will satisfy fairness
requirements such as Equal Opportunity. In this paper we consider the effects
of adopting such fair classifiers on the overall level of ecosystem fairness.
Specifically, we introduce the study of fairness with competing firms, and
demonstrate the failure of fair classifiers in yielding fair ecosystems. Our
results quantify the loss of fairness in systems, under a variety of
conditions, based on classifiers' correlation and the level of their data
overlap. We show that even if competing classifiers are individually fair, the
ecosystem's outcome may be unfair; and that adjusting biased algorithms to
improve their individual fairness may lead to an overall decline in ecosystem
fairness. In addition to these theoretical results, we also provide supporting
experimental evidence. Together, our model and results provide a novel and
essential call for action.

</details>


### [51] [Large-Scale Bayesian Tensor Reconstruction: An Approximate Message Passing Solution](https://arxiv.org/abs/2505.16305)
*Bingyang Cheng, Zhongtao Chen, Yichen Jin, Hao Zhang, Chen Zhang, Edmud Y. Lam, Yik-Chung Wu*

**主要类别:** cs.LG

**概要:** 本论文提出了一种名为CP-GAMP的可扩展贝叶斯张量分解算法，通过避免矩阵求逆和联合推断张量秩与噪声功率，显著减少了运行时间，并保持了与现有最佳方法相当的重构精度。


<details>
  <summary>更多</summary>
  
**动机:** 现有的贝叶斯框架虽然可以进行不确定性量化和自动超参数学习，但在处理大规模张量时由于高维矩阵求逆问题而无法很好地扩展。

**方法:** 引入CP-GAMP算法，利用广义近似消息传递（GAMP）来避免矩阵求逆，并结合期望最大化（EM）过程来联合推断张量秩和噪声功率。

**结果:** 在合成的100x100x100阶数为20的张量实验中，当仅观察到20%的元素时，CP-GAMP相较于最先进的变分贝叶斯CPD方法减少了82.7%的运行时间，同时保持了相当的重构精度。

**结论:** CP-GAMP是一种有效的、可扩展的贝叶斯CPD算法，适合于大规模张量分解任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Large-Scale+Bayesian+Tensor+Reconstruction%3A+An+Approximate+Message+Passing+Solution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16305，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16305&send_immediately=true&force_search=false)

**原文摘要:** Tensor CANDECOMP/PARAFAC decomposition (CPD) is a fundamental model for
tensor reconstruction. Although the Bayesian framework allows for principled
uncertainty quantification and automatic hyperparameter learning, existing
methods do not scale well for large tensors because of high-dimensional matrix
inversions. To this end, we introduce CP-GAMP, a scalable Bayesian CPD
algorithm. This algorithm leverages generalized approximate message passing
(GAMP) to avoid matrix inversions and incorporates an expectation-maximization
routine to jointly infer the tensor rank and noise power. Through multiple
experiments, for synthetic 100x100x100 rank 20 tensors with only 20% elements
observed, the proposed algorithm reduces runtime by 82.7% compared to the
state-of-the-art variational Bayesian CPD method, while maintaining comparable
reconstruction accuracy.

</details>


### [52] [CAIFormer: A Causal Informed Transformer for Multivariate Time Series Forecasting](https://arxiv.org/abs/2505.16308)
*Xingyu Zhang, Wenwen Qiang, Siyu Zhao, Huijie Guo, Jiangmeng Li, Chuxiong Sun, Changwen Zheng*

**主要类别:** cs.LG

**概要:** 提出了一种新的all-to-one预测范式，结合因果结构和Causal Informed Transformer (CAIFormer)模型来改进多变量时间序列预测。


<details>
  <summary>更多</summary>
  
**动机:** 现有大多数多变量时间序列预测方法采用all-to-all范式，难以区分变量的特定因果影响，并容易将因果相关的信息与虚假相关混淆。

**方法:** 1. 构建Structural Causal Model从观察数据中推断因果结构。
2. 将历史序列划分为四个子段：内生、直接因果、碰撞因果和虚假相关。
3. 提出Causal Informed Transformer (CAIFormer)，包括三个模块分别处理内生、直接因果和碰撞因果子段。
4. 结合三个模块的输出生成最终预测结果。

**结果:** 在多个基准数据集上的广泛实验表明，CAIFormer的有效性显著。

**结论:** 提出的all-to-one范式和CAIFormer模型能够有效识别变量特定的因果影响，减少虚假相关干扰，提升多变量时间序列预测性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CAIFormer%3A+A+Causal+Informed+Transformer+for+Multivariate+Time+Series+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16308，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16308&send_immediately=true&force_search=false)

**原文摘要:** Most existing multivariate time series forecasting methods adopt an
all-to-all paradigm that feeds all variable histories into a unified model to
predict their future values without distinguishing their individual roles.
However, this undifferentiated paradigm makes it difficult to identify
variable-specific causal influences and often entangles causally relevant
information with spurious correlations. To address this limitation, we propose
an all-to-one forecasting paradigm that predicts each target variable
separately. Specifically, we first construct a Structural Causal Model from
observational data and then, for each target variable, we partition the
historical sequence into four sub-segments according to the inferred causal
structure: endogenous, direct causal, collider causal, and spurious
correlation. The prediction relies solely on the first three causally relevant
sub-segments, while the spurious correlation sub-segment is excluded.
Furthermore, we propose Causal Informed Transformer (CAIFormer), a novel
forecasting model comprising three components: Endogenous Sub-segment
Prediction Block, Direct Causal Sub-segment Prediction Block, and Collider
Causal Sub-segment Prediction Block, which process the endogenous, direct
causal, and collider causal sub-segments, respectively. Their outputs are then
combined to produce the final prediction. Extensive experiments on multiple
benchmark datasets demonstrate the effectiveness of the CAIFormer.

</details>


### [53] [FreshRetailNet-50K: A Stockout-Annotated Censored Demand Dataset for Latent Demand Recovery and Forecasting in Fresh Retail](https://arxiv.org/abs/2505.16319)
*Yangyang Wang, Jiawei Gu, Li Long, Xin Li, Li Shen, Zhouyu Fu, Xiangjun Zhou, Xu Jiang*

**主要类别:** cs.LG

**概要:** 准确的需求估计对零售业至关重要，但因缺货期间未观测到的需求导致政策偏差。现有数据集无法解决这种审查效应。为此，我们提出了FreshRetailNet-50K，这是第一个大规模基准数据集，包含50,000个商店产品的小时销售数据和库存状态记录，能够通过两阶段需求建模方法显著提高预测精度并减少系统性低估。此数据集解决了零售AI的长期限制，并为未来创新提供了平台。


<details>
  <summary>更多</summary>
  
**动机:** 准确的需求估计对零售业制定库存和定价策略至关重要，但由于缺货期间的审查效应（即未观测到的需求），现有数据集缺乏时间和标注细节，难以解决这一问题。这导致了系统性的政策偏差。

**方法:** 提出名为FreshRetailNet-50K的大规模基准数据集，包含详细的小时级销售数据、库存状态记录及丰富的上下文变量（如促销折扣、降水等）。通过两阶段需求建模方法：第一阶段利用精确的小时级标注重建缺货期间的潜在需求；第二阶段使用恢复的需求训练稳健的需求预测模型。

**结果:** 实验结果表明，该方法将预测准确性提高了2.73%，并将系统性需求低估从7.37%降低至接近零偏差。

**结论:** FreshRetailNet-50K数据集以前所未有的时间粒度和全面的真实世界信息，为需求填补、易腐品库存优化和因果零售分析开辟了新的研究方向，解决了零售AI的长期限制，并提供了即时解决方案和未来方法创新的平台。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FreshRetailNet-50K%3A+A+Stockout-Annotated+Censored+Demand+Dataset+for+Latent+Demand+Recovery+and+Forecasting+in+Fresh+Retail，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16319，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16319&send_immediately=true&force_search=false)

**原文摘要:** Accurate demand estimation is critical for the retail business in guiding the
inventory and pricing policies of perishable products. However, it faces
fundamental challenges from censored sales data during stockouts, where
unobserved demand creates systemic policy biases. Existing datasets lack the
temporal resolution and annotations needed to address this censoring effect. To
fill this gap, we present FreshRetailNet-50K, the first large-scale benchmark
for censored demand estimation. It comprises 50,000 store-product time series
of detailed hourly sales data from 898 stores in 18 major cities, encompassing
863 perishable SKUs meticulously annotated for stockout events. The hourly
stock status records unique to this dataset, combined with rich contextual
covariates, including promotional discounts, precipitation, and temporal
features, enable innovative research beyond existing solutions. We demonstrate
one such use case of two-stage demand modeling: first, we reconstruct the
latent demand during stockouts using precise hourly annotations. We then
leverage the recovered demand to train robust demand forecasting models in the
second stage. Experimental results show that this approach achieves a 2.73\%
improvement in prediction accuracy while reducing the systematic demand
underestimation from 7.37\% to near-zero bias. With unprecedented temporal
granularity and comprehensive real-world information, FreshRetailNet-50K opens
new research directions in demand imputation, perishable inventory
optimization, and causal retail analytics. The unique annotation quality and
scale of the dataset address long-standing limitations in retail AI, providing
immediate solutions and a platform for future methodological innovation. The
data (https://huggingface.co/datasets/Dingdong-Inc/FreshRetailNet-50K) and code
(https://github.com/Dingdong-Inc/frn-50k-baseline}) are openly released.

</details>


### [54] [AdaSTaR: Adaptive Data Sampling for Training Self-Taught Reasoners](https://arxiv.org/abs/2505.16322)
*Woosung Koh, Wonbeen Oh, Jaein Jang, MinHyung Lee, Hyeongjin Kim, Ah Yeon Kim, Joonkee Kim, Junghyun Lee, Taehyeon Kim, Se-Young Yun*

**主要类别:** cs.LG

**概要:** 论文提出了AdaSTaR算法，解决了Self-Taught Reasoners (STaR)中的训练数据不平衡问题，通过两个自适应采样原则提升了训练效率和模型性能，在多个基准测试中表现优异并减少了计算资源消耗。


<details>
  <summary>更多</summary>
  
**动机:** 现有的自我改善机制通常采用随机观察（数据）采样，这导致训练观察不平衡——过度训练于已解决的例子，而对具有挑战性的例子训练不足。

**方法:** 提出了一种新的算法AdaSTaR，通过整合两种自适应采样原则来解决训练观察不平衡的问题：(1) 自适应多样性采样：促进跨观测值的平衡训练；(2) 自适应课程采样：动态调整数据难度以匹配模型不断变化的实力。

**结果:** AdaSTaR在六个基准测试中均实现了最佳测试准确性，并且与广泛的基线相比，平均减少了58.6%的训练FLOPs。这些性能和效率的改进可以推广到不同的预训练LMs和更大的模型。

**结论:** AdaSTaR在六个基准测试中均取得了最佳的测试准确性，并且平均减少了58.6%的训练FLOPs，相较于广泛的基础模型展现了性能和效率的提升。这些改进适用于不同的预训练LMs和更大的模型，为更高效和有效的自改善语言模型铺平了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AdaSTaR%3A+Adaptive+Data+Sampling+for+Training+Self-Taught+Reasoners，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16322，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16322&send_immediately=true&force_search=false)

**原文摘要:** Self-Taught Reasoners (STaR), synonymously known as Rejection sampling
Fine-Tuning (RFT), is an integral part of the training pipeline of
self-improving reasoning Language Models (LMs). The self-improving mechanism
often employs random observation (data) sampling. However, this results in
trained observation imbalance; inefficiently over-training on solved examples
while under-training on challenging ones. In response, we introduce Adaptive
STaR (AdaSTaR), a novel algorithm that rectifies this by integrating two
adaptive sampling principles: (1) Adaptive Sampling for Diversity: promoting
balanced training across observations, and (2) Adaptive Sampling for
Curriculum: dynamically adjusting data difficulty to match the model's evolving
strength. Across six benchmarks, AdaSTaR achieves best test accuracy in all
instances (6/6) and reduces training FLOPs by an average of 58.6% against an
extensive list of baselines. These improvements in performance and efficiency
generalize to different pre-trained LMs and larger models, paving the way for
more efficient and effective self-improving LMs.

</details>


### [55] [ChemMLLM: Chemical Multimodal Large Language Model](https://arxiv.org/abs/2505.16326)
*Qian Tan, Dongzhan Zhou, Peng Xia, Wanhao Liu, Wanli Ouyang, Lei Bai, Yuqiang Li, Tianfan Fu*

**主要类别:** cs.LG

**概要:** 提出ChemMLLM，一个用于分子理解和生成的化学多模态大语言模型，并设计了五个跨文本、分子SMILES字符串和图像的多模态任务及相应数据集。实验结果表明，ChemMLLM在所有评估任务中表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 尽管多模态大语言模型在许多应用中取得了显著进展，但能够处理跨模态理解和生成的化学多模态大语言模型仍鲜有研究。

**方法:** 提出了ChemMLLM，一个统一的化学多模态大语言模型，并设计了五个跨文本、分子SMILES字符串和图像的多模态任务，同时整理了相关数据集。

**结果:** 实验结果表明，ChemMLLM在所有评估任务中均表现出色，例如在分子图像优化任务中，ChemMLLM相比最佳基线（GPT-4o）性能提升了118.9%。

**结论:** ChemMLLM在化学多模态理解和生成方面展现了优越性能，其代码已公开发布。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ChemMLLM%3A+Chemical+Multimodal+Large+Language+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16326，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16326&send_immediately=true&force_search=false)

**原文摘要:** Multimodal large language models (MLLMs) have made impressive progress in
many applications in recent years. However, chemical MLLMs that can handle
cross-modal understanding and generation remain underexplored. To fill this
gap, in this paper, we propose ChemMLLM, a unified chemical multimodal large
language model for molecule understanding and generation. Also, we design five
multimodal tasks across text, molecular SMILES strings, and image, and curate
the datasets. We benchmark ChemMLLM against a range of general leading MLLMs
and Chemical LLMs on these tasks. Experimental results show that ChemMLLM
achieves superior performance across all evaluated tasks. For example, in
molecule image optimization task, ChemMLLM outperforms the best baseline
(GPT-4o) by 118.9\% (4.27 vs 1.95 property improvement). The code is publicly
available at https://github.com/bbsbz/ChemMLLM.git.

</details>


### [56] [Understanding Differential Transformer Unchains Pretrained Self-Attentions](https://arxiv.org/abs/2505.16333)
*Chaerin Kong, Jiho Jang, Nojun Kwak*

**主要类别:** cs.LG

**概要:** Differential Transformer因其卓越的性能受到关注，但其成功机制尚不明确。本文研究发现其成功源于负注意力增强表达能力、减少注意力头冗余和改善学习动态，并提出DEX方法将这些优势整合到预训练语言模型中，通过少量数据(<0.01%)实现显著性能提升。


<details>
  <summary>更多</summary>
  
**动机:** 尽管Differential Transformer表现出色，但其成功原因尚未明确，且其架构需要从头开始大规模训练，限制了预训练权重的使用。

**方法:** 通过深入研究，揭示Differential Transformer成功的三个关键因素：负注意力增强表达能力、减少注意力头冗余、改善学习动态。基于此，提出DEX方法，通过重用softmax注意力分数并在输出值矩阵上添加轻量级差分操作，将差分注意的优势高效整合到预训练语言模型中。

**结果:** DEX方法在多种基准测试中显著提高了预训练LLMs的性能，仅需极少量的适应数据(<0.01%)即可实现显著性能提升。

**结论:** Differential Transformer的成功可归因于负注意力、减少冗余和改进学习动态。DEX方法为高效利用预训练模型提供了新途径，展示了在少量数据下实现显著性能提升的能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Understanding+Differential+Transformer+Unchains+Pretrained+Self-Attentions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16333，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16333&send_immediately=true&force_search=false)

**原文摘要:** Differential Transformer has recently gained significant attention for its
impressive empirical performance, often attributed to its ability to perform
noise canceled attention. However, precisely how differential attention
achieves its empirical benefits remains poorly understood. Moreover,
Differential Transformer architecture demands large-scale training from
scratch, hindering utilization of open pretrained weights. In this work, we
conduct an in-depth investigation of Differential Transformer, uncovering three
key factors behind its success: (1) enhanced expressivity via negative
attention, (2) reduced redundancy among attention heads, and (3) improved
learning dynamics. Based on these findings, we propose DEX, a novel method to
efficiently integrate the advantages of differential attention into pretrained
language models. By reusing the softmax attention scores and adding a
lightweight differential operation on the output value matrix, DEX effectively
incorporates the key advantages of differential attention while remaining
lightweight in both training and inference. Evaluations confirm that DEX
substantially improves the pretrained LLMs across diverse benchmarks, achieving
significant performance gains with minimal adaptation data (< 0.01\%).

</details>


### [57] [Improving Chemical Understanding of LLMs via SMILES Parsing](https://arxiv.org/abs/2505.16340)
*Yunhui Jang, Jaehyung Kim, Sungsoo Ahn*

**主要类别:** cs.LG

**概要:** CLEANMOL 是一个新框架，将 SMILES 解析转化为明确的任务以提升大语言模型的分子结构理解能力。通过子图和全局图匹配任务及自适应难度评分的数据集预训练，CLEANMOL 提升了开源 LLM 的分子结构理解能力，并在 Mol-Instructions 基准上表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 当前的大语言模型（LLMs）难以准确解析 SMILES 表示法，甚至无法完成基本任务如计算分子环的数量，这限制了其在分子科学中的应用。

**方法:** 提出 CLEANMOL 框架，将 SMILES 解析转化为一系列明确且确定性的任务，包括子图匹配和全局图匹配等，这些任务与分子结构特性对齐。构建具有自适应难度评分的分子预训练数据集，并在这些任务上预训练开源 LLMs。

**结果:** 实验结果表明，CLEANMOL 不仅增强了模型的结构理解能力，还在 Mol-Instructions 基准测试中取得了最佳或与基线持平的表现。

**结论:** CLEANMOL 框架有效提升了大语言模型对分子结构的理解能力，为分子科学领域的研究提供了更强大的工具支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Improving+Chemical+Understanding+of+LLMs+via+SMILES+Parsing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16340，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16340&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are increasingly recognized as powerful tools
for scientific discovery, particularly in molecular science. A fundamental
requirement for these models is the ability to accurately understand molecular
structures, commonly encoded in the SMILES representation. However, current
LLMs struggle to interpret SMILES, even failing to carry out basic tasks such
as counting molecular rings. To address this limitation, we introduce CLEANMOL,
a novel framework that formulates SMILES parsing into a suite of clean and
deterministic tasks explicitly designed to promote graph-level molecular
comprehension. These tasks span from subgraph matching to global graph
matching, providing structured supervision aligned with molecular structural
properties. We construct a molecular pretraining dataset with adaptive
difficulty scoring and pre-train open-source LLMs on these tasks. Our results
show that CLEANMOL not only enhances structural comprehension but also achieves
the best or competes with the baseline on the Mol-Instructions benchmark.

</details>


### [58] [A Square Peg in a Square Hole: Meta-Expert for Long-Tailed Semi-Supervised Learning](https://arxiv.org/abs/2505.16341)
*Yaxin Hou, Yuheng Jia*

**主要类别:** cs.LG

**概要:** This paper tackles long-tailed semi-supervised learning with distribution mismatch by proposing a dynamic expert assignment module and a multi-depth feature fusion module, leading to improved performance and reduced model bias.


<details>
  <summary>更多</summary>
  
**动机:** Existing methods for long-tailed semi-supervised learning do not fully utilize the expertise of different auxiliary classifiers (experts) when handling distribution mismatches between labeled and unlabeled data.

**方法:** 1. Dynamic Expert Assignment Module: Estimates the class membership (head, medium, or tail) of samples and assigns suitable experts based on this estimation to produce high-quality pseudo-labels during training and predictions during testing.
2. Multi-Depth Feature Fusion Module: Combines features from different depths in the network to balance bias toward head classes and discriminative ability.

**结果:** Comprehensive experiments on CIFAR-10-LT, STL-10-LT, and SVHN-LT datasets demonstrate the effectiveness of the method across various settings.

**结论:** The proposed method effectively addresses the challenges of long-tailed semi-supervised learning with distribution mismatch through dynamic expert assignment and multi-depth feature fusion.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Square+Peg+in+a+Square+Hole%3A+Meta-Expert+for+Long-Tailed+Semi-Supervised+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16341，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16341&send_immediately=true&force_search=false)

**原文摘要:** This paper studies the long-tailed semi-supervised learning (LTSSL) with
distribution mismatch, where the class distribution of the labeled training
data follows a long-tailed distribution and mismatches with that of the
unlabeled training data. Most existing methods introduce auxiliary classifiers
(experts) to model various unlabeled data distributions and produce
pseudo-labels, but the expertises of various experts are not fully utilized. We
observe that different experts are good at predicting different intervals of
samples, e.g., long-tailed expert is skilled in samples located in the head
interval and uniform expert excels in samples located in the medium interval.
Therefore, we propose a dynamic expert assignment module that can estimate the
class membership (i.e., head, medium, or tail class) of samples, and
dynamically assigns suitable expert to each sample based on the estimated
membership to produce high-quality pseudo-label in the training phase and
produce prediction in the testing phase. We also theoretically reveal that
integrating different experts' strengths will lead to a smaller generalization
error bound. Moreover, we find that the deeper features are more biased toward
the head class but with more discriminative ability, while the shallower
features are less biased but also with less discriminative ability. We,
therefore, propose a multi-depth feature fusion module to utilize different
depth features to mitigate the model bias. Our method demonstrates its
effectiveness through comprehensive experiments on the CIFAR-10-LT, STL-10-LT,
and SVHN-LT datasets across various settings. The code is available at
https://github.com/yaxinhou/Meta-Expert.

</details>


### [59] [Arrival Control in Quasi-Reversible Queueing Systems: Optimization and Reinforcement Learning](https://arxiv.org/abs/2505.16353)
*Céline Comte, Pascal Moyal*

**主要类别:** cs.LG

**概要:** 本文提出了一种通用方案，用于优化准可逆排队系统的到达率。首先提出了准可逆性的替代定义，涵盖可逆性并强调客户类别定义的重要性。接着引入了平衡到达控制策略，将Whittle网络中的平衡到达率概念推广到更广泛的准可逆排队系统。证明了在准可逆排队系统中补充平衡到达控制策略可以保持准可逆性，并指定了平稳测度的形式。重新审视了两个经典的准可逆排队系统例子：Whittle网络和顺序无关队列。最后，集中讨论了准入控制问题，并在优化和强化学习框架中利用了这些结果。


<details>
  <summary>更多</summary>
  
**动机:** 当前对于准可逆排队系统的优化方法存在局限性，特别是缺乏对到达率的有效控制策略。为了改进这一状况，需要引入新的定义和控制策略来扩展可应用的系统范围，并确保系统性能。

**方法:** 1. 提出准可逆性的新定义，包含可逆性并强调客户类别的重要性。
2. 引入平衡到达控制策略，推广平衡到达率的概念到更广泛的准可逆排队系统。
3. 证明平衡到达控制策略能保持系统的准可逆性。
4. 指定平稳测度的形式。
5. 在准入控制问题上结合优化和强化学习方法进行研究。

**结果:** 通过引入平衡到达控制策略，成功地保持了准可逆排队系统的准可逆性，并明确了平稳测度的形式。此外，在准入控制问题的研究中展示了该方法在优化和强化学习中的潜在应用价值。

**结论:** 本文提出的平衡到达控制策略为优化准可逆排队系统的到达率提供了有效的手段，并且可以在更广泛的系统中应用。同时，该策略与优化及强化学习方法的结合为解决复杂的准入控制问题提供了新思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Arrival+Control+in+Quasi-Reversible+Queueing+Systems%3A+Optimization+and+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16353，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16353&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we introduce a versatile scheme for optimizing the arrival
rates of quasi-reversible queueing systems. We first propose an alternative
definition of quasi-reversibility that encompasses reversibility and highlights
the importance of the definition of customer classes. In a second time, we
introduce balanced arrival control policies, which generalize the notion of
balanced arrival rates introduced in the context of Whittle networks, to the
much broader class of quasi-reversible queueing systems. We prove that
supplementing a quasi-reversible queueing system with a balanced
arrival-control policy preserves the quasi-reversibility, and we specify the
form of the stationary measures. We revisit two canonical examples of
quasi-reversible queueing systems, Whittle networks and order-independent
queues. Lastly, we focus on the problem of admission control and leverage our
results in the frameworks of optimization and reinforcement learning.

</details>


### [60] [A collaborative constrained graph diffusion model for the generation of realistic synthetic molecules](https://arxiv.org/abs/2505.16365)
*Manuel Ruiz-Botella, Marta Sales-Pardo, Roger Guimerà*

**主要类别:** cs.LG

**概要:** 生成化学上有效的分子是解决健康和环境可持续性等紧迫挑战的关键。然而，由于分子空间的广阔，探索以发现新分子是一项艰巨的任务。本文介绍了一种名为CoCoGraph的新模型，该模型通过协作和约束图扩散方法生成化学上有效的分子。CoCoGraph在标准基准测试中优于现有最先进方法，同时参数数量减少了一个数量级。通过对36种化学性质的分析表明，CoCoGraph生成的分子分布与真实分子更接近。利用模型的高效性，我们创建了一个包含820万个合成生成分子的数据库，并进行了类似图灵测试的评估，以进一步评估生成分子的合理性及CoCoGraph的潜在偏差和局限性。


<details>
  <summary>更多</summary>
  
**动机:** 开发新的分子化合物对于应对从健康到环境可持续性的紧迫挑战至关重要。然而，由于分子空间的庞大，探索并发现新分子变得困难。

**方法:** 提出了一种名为CoCoGraph的模型，该模型是一种协作和约束图扩散模型，能够生成化学上有效的分子。模型中内置的约束和协作机制使其在标准基准测试中表现优异，且参数数量显著减少。

**结果:** CoCoGraph在标准基准测试中优于当前最先进的方法，同时参数数量减少了一个数量级。对36种化学性质的分析表明，CoCoGraph生成的分子分布与真实分子更为接近。

**结论:** CoCoGraph模型不仅在性能上超越了现有方法，而且生成的分子具有更高的合理性。通过对生成分子的图灵测试评估，进一步揭示了模型的潜在偏差和局限性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+collaborative+constrained+graph+diffusion+model+for+the+generation+of+realistic+synthetic+molecules，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16365，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16365&send_immediately=true&force_search=false)

**原文摘要:** Developing new molecular compounds is crucial to address pressing challenges,
from health to environmental sustainability. However, exploring the molecular
space to discover new molecules is difficult due to the vastness of the space.
Here we introduce CoCoGraph, a collaborative and constrained graph diffusion
model capable of generating molecules that are guaranteed to be chemically
valid. Thanks to the constraints built into the model and to the collaborative
mechanism, CoCoGraph outperforms state-of-the-art approaches on standard
benchmarks while requiring up to an order of magnitude fewer parameters.
Analysis of 36 chemical properties also demonstrates that CoCoGraph generates
molecules with distributions more closely matching real molecules than current
models. Leveraging the model's efficiency, we created a database of 8.2M
million synthetically generated molecules and conducted a Turing-like test with
organic chemistry experts to further assess the plausibility of the generated
molecules, and potential biases and limitations of CoCoGraph.

</details>


### [61] [SATURN: SAT-based Reinforcement Learning to Unleash Language Model Reasoning](https://arxiv.org/abs/2505.16368)
*Huanyu Liu, Jia Li, Hao Zhu, Kechi Zhang, Yihong Dong, Ge Li*

**主要类别:** cs.LG

**概要:** 设计能有效激发大语言模型推理能力的强化学习任务仍是一个开放问题。现有的RL任务存在可扩展性、可验证性和难度控制的问题。为了解决这些问题，我们提出了基于SAT问题的RL框架Saturn，它具有可扩展的任务构建、基于规则的验证和精确的难度控制功能。Saturn通过设计课程学习管道，逐步提高LLM的推理能力，并引入了一个原则性的机制来控制难度过渡。我们创建了包含2660个SAT问题的数据集Saturn-2.6k，支持评估LLM推理随问题难度的变化。实验结果表明，在SAT问题上，Saturn-1.5B和Saturn-7B分别提高了14.0和28.1的平均pass@3分数；在数学和编程任务上也取得了显著提升。与现有SOTA方法相比，Saturn进一步提升了8.8%。


<details>
  <summary>更多</summary>
  
**动机:** 当前强化学习任务无法有效激发大语言模型的推理能力，主要受限于数据生成依赖人工标注或昂贵的LLM合成、输出难以自动可靠验证以及任务缺乏精细的难度控制。

**方法:** 提出了一种基于布尔可满足性（SAT）问题的强化学习框架Saturn。该框架包括：1) 可扩展的任务构建，利用SAT问题生成大量训练数据；2) 基于规则的验证机制，确保输出的可靠性；3) 精确的难度控制系统，通过设计课程学习管道，从简单到复杂逐步训练LLM。此外，还设计了一个稳定训练的机制来控制难度过渡。

**结果:** 1) 在SAT问题上，Saturn-1.5B和Saturn-7B分别实现了+14.0和+28.1的平均pass@3改进；2) 在数学和编程任务中，Saturn-1.5B和Saturn-7B分别提高了+4.9和+1.8的平均分；3) 与现有SOTA方法相比，Saturn在构建RL任务方面进一步提升了+8.8%。

**结论:** Saturn框架通过解决现有RL任务中的关键限制，成功提高了LLM的推理能力，并且在SAT问题、数学和编程任务上都表现出显著优势。这些成果证明了Saturn的有效性和潜力，为进一步研究提供了坚实基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SATURN%3A+SAT-based+Reinforcement+Learning+to+Unleash+Language+Model+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16368，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16368&send_immediately=true&force_search=false)

**原文摘要:** How to design reinforcement learning (RL) tasks that effectively unleash the
reasoning capability of large language models (LLMs) remains an open question.
Existing RL tasks (e.g., math, programming, and constructing reasoning tasks)
suffer from three key limitations: (1) Scalability. They rely heavily on human
annotation or expensive LLM synthesis to generate sufficient training data. (2)
Verifiability. LLMs' outputs are hard to verify automatically and reliably. (3)
Controllable Difficulty. Most tasks lack fine-grained difficulty control,
making it hard to train LLMs to develop reasoning ability from easy to hard.
  To address these limitations, we propose Saturn, a SAT-based RL framework
that uses Boolean Satisfiability (SAT) problems to train and evaluate LLM
reasoning. Saturn enables scalable task construction, rule-based verification,
and precise difficulty control. Saturn designs a curriculum learning pipeline
that continuously improves LLMs' reasoning capability by constructing SAT tasks
of increasing difficulty and training LLMs from easy to hard. To ensure stable
training, we design a principled mechanism to control difficulty transitions.
  We introduce Saturn-2.6k, a dataset of 2,660 SAT problems with varying
difficulty. It supports the evaluation of how LLM reasoning changes with
problem difficulty. We apply Saturn to DeepSeek-R1-Distill-Qwen and obtain
Saturn-1.5B and Saturn-7B. We achieve several notable results: (1) On SAT
problems, Saturn-1.5B and Saturn-7B achieve average pass@3 improvements of
+14.0 and +28.1, respectively. (2) On math and programming tasks, Saturn-1.5B
and Saturn-7B improve average scores by +4.9 and +1.8 on benchmarks (e.g.,
AIME, LiveCodeBench). (3) Compared to the state-of-the-art (SOTA) approach in
constructing RL tasks, Saturn achieves further improvements of +8.8%. We
release the source code, data, and models to support future research.

</details>


### [62] [Omni TM-AE: A Scalable and Interpretable Embedding Model Using the Full Tsetlin Machine State Space](https://arxiv.org/abs/2505.16386)
*Ahmed K. Kadhim, Lei Jiao, Rishad Shafik, Ole-Christoffer Granmo*

**主要类别:** cs.LG

**概要:** 提出了一种新的嵌入模型Omni Tsetlin Machine AutoEncoder（Omni TM-AE），该模型通过单一训练阶段构建可重用和可解释的嵌入，同时在语义相似性、情感分类和文档聚类任务中表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型的复杂性增加引发了对其可解释性和可重用性的担忧。传统的嵌入模型如Word2Vec和GloVe虽然具有可扩展性，但缺乏透明度；而可解释模型如Tsetlin Machine则在可扩展性和可重用性方面存在限制。

**方法:** 引入了Omni Tsetlin Machine AutoEncoder（Omni TM-AE），一种新型嵌入模型，充分利用Tsetlin Machine状态矩阵中的信息（包括之前未用于子句形成的字面量），从而实现单一训练阶段内构建可重用且可解释的嵌入。

**结果:** 在语义相似性、情感分类和文档聚类任务上的广泛实验表明，Omni TM-AE的表现与主流嵌入模型相当甚至更优。

**结论:** 可以在现代自然语言处理系统中平衡性能、可扩展性和可解释性，而无需依赖不透明的架构。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Omni+TM-AE%3A+A+Scalable+and+Interpretable+Embedding+Model+Using+the+Full+Tsetlin+Machine+State+Space，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16386，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16386&send_immediately=true&force_search=false)

**原文摘要:** The increasing complexity of large-scale language models has amplified
concerns regarding their interpretability and reusability. While traditional
embedding models like Word2Vec and GloVe offer scalability, they lack
transparency and often behave as black boxes. Conversely, interpretable models
such as the Tsetlin Machine (TM) have shown promise in constructing explainable
learning systems, though they previously faced limitations in scalability and
reusability. In this paper, we introduce Omni Tsetlin Machine AutoEncoder (Omni
TM-AE), a novel embedding model that fully exploits the information contained
in the TM's state matrix, including literals previously excluded from clause
formation. This method enables the construction of reusable, interpretable
embeddings through a single training phase. Extensive experiments across
semantic similarity, sentiment classification, and document clustering tasks
show that Omni TM-AE performs competitively with and often surpasses mainstream
embedding models. These results demonstrate that it is possible to balance
performance, scalability, and interpretability in modern Natural Language
Processing (NLP) systems without resorting to opaque architectures.

</details>


### [63] [AceReason-Nemotron: Advancing Math and Code Reasoning through Reinforcement Learning](https://arxiv.org/abs/2505.16400)
*Yang Chen, Zhuolin Yang, Zihan Liu, Chankyu Lee, Peng Xu, Mohammad Shoeybi, Bryan Catanzaro, Wei Ping*

**主要类别:** cs.LG

**概要:** 尽管在大规模强化学习（RL）推理方面取得了进展，但构建高性能推理模型的训练方法仍然难以捉摸。本研究展示了大规模RL可以显著增强中小型模型的推理能力，超越最先进的基于蒸馏的模型。通过系统研究RL训练过程，提出了一种有效的方法：先对数学提示进行训练，再对代码提示进行训练。这种方法不仅提高了数学基准上的性能，还改善了代码推理任务的表现。此外，扩展代码RL迭代进一步提升了代码基准上的表现。研究还发现了关键的实验见解，如课程学习和策略参数更新的稳定效果。最终，RL不仅激发了预训练和监督微调期间获得的基础推理能力，还推动了模型推理能力的极限。


<details>
  <summary>更多</summary>
  
**动机:** 当前高性能推理模型的训练方法不够明确，前沿模型的关键实现细节常被省略。同时，对于小型模型，蒸馏比RL更有效。因此，研究者希望证明大规模RL能够显著提高中小型模型的推理能力，并探索其具体方法和机制。

**方法:** 研究者系统地研究了RL训练过程，提出了一个简单而有效的方法：首先在仅数学提示上进行训练，然后在仅代码提示上进行训练。他们开发了一个强大的数据整理管道，收集具有高质量、可验证答案和测试用例的挑战性提示，以实现跨领域的基于验证的RL。此外，还采用了课程学习策略和策略参数更新方法。

**结果:** 该方法显著提高了中小型模型在数学和代码推理任务上的性能。例如，在AIME 2025数学基准上分别提高了14.6%和17.2%，在LiveCodeBench代码推理任务上分别提高了6.8%和5.8%。扩展代码RL迭代进一步提高了代码基准上的表现，同时几乎没有降低数学结果。

**结论:** 大规模RL不仅能激发模型在预训练和监督微调中获得的基础推理能力，还能推动模型推理能力的极限，解决以前无法解决的问题。这表明RL在提升中小型模型推理能力方面的巨大潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AceReason-Nemotron%3A+Advancing+Math+and+Code+Reasoning+through+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16400，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16400&send_immediately=true&force_search=false)

**原文摘要:** Despite recent progress in large-scale reinforcement learning (RL) for
reasoning, the training recipe for building high-performing reasoning models
remains elusive. Key implementation details of frontier models, such as
DeepSeek-R1, including data curation strategies and RL training recipe, are
often omitted. Moreover, recent research indicates distillation remains more
effective than RL for smaller models. In this work, we demonstrate that
large-scale RL can significantly enhance the reasoning capabilities of strong,
small- and mid-sized models, achieving results that surpass those of
state-of-the-art distillation-based models. We systematically study the RL
training process through extensive ablations and propose a simple yet effective
approach: first training on math-only prompts, then on code-only prompts.
Notably, we find that math-only RL not only significantly enhances the
performance of strong distilled models on math benchmarks (e.g., +14.6% /
+17.2% on AIME 2025 for the 7B / 14B models), but also code reasoning tasks
(e.g., +6.8% / +5.8% on LiveCodeBench for the 7B / 14B models). In addition,
extended code-only RL iterations further improve performance on code benchmarks
with minimal or no degradation in math results. We develop a robust data
curation pipeline to collect challenging prompts with high-quality, verifiable
answers and test cases to enable verification-based RL across both domains.
Finally, we identify key experimental insights, including curriculum learning
with progressively increasing response lengths and the stabilizing effect of
on-policy parameter updates. We find that RL not only elicits the foundational
reasoning capabilities acquired during pretraining and supervised fine-tuning
(e.g., distillation), but also pushes the limits of the model's reasoning
ability, enabling it to solve problems that were previously unsolvable.

</details>


### [64] [Divide-Fuse-Conquer: Eliciting "Aha Moments" in Multi-Scenario Games](https://arxiv.org/abs/2505.16401)
*Xiaoqing Zhang, Huabin Zheng, Ang Lv, Yuhan Liu, Zirui Song, Flood Sung, Xiuying Chen, Rui Yan*

**主要类别:** cs.LG

**概要:** 提出了一种名为Divide-Fuse-Conquer的新框架，通过分组、融合和征服三个步骤来增强多场景强化学习中的泛化能力。实验表明，使用该策略训练的Qwen2.5-32B-Align在18个TextArena游戏中表现优异，可与Claude3.5相媲美。


<details>
  <summary>更多</summary>
  
**动机:** 当前强化学习方法虽然在数学、编码和视觉任务中表现出色，但在多场景游戏中的泛化能力面临挑战，例如规则多样性、交互模式复杂性等导致模型在一个场景中表现良好但无法推广到其他场景。简单的多场景组合训练还会引起训练不稳定性及性能下降等问题。因此需要一种新方法来解决这些挑战。

**方法:** 提出了Divide-Fuse-Conquer框架，具体步骤包括：1) 根据游戏规则和难度等因素对游戏进行启发式分组；2) 为每个组训练专门的模型以使其在特定组的游戏上表现出色（分步）；3) 融合不同组模型参数生成新模型，并继续针对多个组进行训练，直到所有组的场景都被攻克（融合与征服）。

**结果:** 在18个TextArena游戏上的实验表明，采用Divide-Fuse-Conquer策略训练的Qwen2.5-32B-Align达到了与Claude3.5相当的性能水平，取得了7场胜利和4场平局的好成绩。

**结论:** Divide-Fuse-Conquer框架能够有效提升多场景强化学习中的泛化能力，为未来利用强化学习改进大语言模型泛化能力的研究提供了新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Divide-Fuse-Conquer%3A+Eliciting+%22Aha+Moments%22+in+Multi-Scenario+Games，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16401，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16401&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) have been observed to suddenly exhibit advanced
reasoning abilities during reinforcement learning (RL), resembling an ``aha
moment'' triggered by simple outcome-based rewards. While RL has proven
effective in eliciting such breakthroughs in tasks involving mathematics,
coding, and vision, it faces significant challenges in multi-scenario games.
The diversity of game rules, interaction modes, and environmental complexities
often leads to policies that perform well in one scenario but fail to
generalize to others. Simply combining multiple scenarios during training
introduces additional challenges, such as training instability and poor
performance. To overcome these challenges, we propose Divide-Fuse-Conquer, a
framework designed to enhance generalization in multi-scenario RL. This
approach starts by heuristically grouping games based on characteristics such
as rules and difficulties. Specialized models are then trained for each group
to excel at games in the group is what we refer to as the divide step. Next, we
fuse model parameters from different groups as a new model, and continue
training it for multiple groups, until the scenarios in all groups are
conquered. Experiments across 18 TextArena games show that Qwen2.5-32B-Align
trained with the Divide-Fuse-Conquer strategy reaches a performance level
comparable to Claude3.5, achieving 7 wins and 4 draws. We hope our approach can
inspire future research on using reinforcement learning to improve the
generalization of LLMs.

</details>


### [65] [Performance Guaranteed Poisoning Attacks in Federated Learning: A Sliding Mode Approach](https://arxiv.org/abs/2505.16403)
*Huazi Pan, Yanjun Zhang, Leo Yu Zhang, Scott Adams, Abbas Kouzani, Suiyang Khoo*

**主要类别:** cs.LG

**概要:** 在联邦学习中，提出了一种新型的投毒攻击方法FedSA，通过整合滑模控制理论，能够以隐蔽且可控的方式降低全局模型的预测准确率到预定目标。实验表明，该方法在少量恶意客户端的情况下也能高效实现目标，并保持高度隐秘性。


<details>
  <summary>更多</summary>
  
**动机:** 联邦学习中的协作特性使其容易受到数据和模型更新的投毒攻击威胁。现有的投毒攻击多以导致服务拒绝（DoS）问题为目标，而本文旨在提出一种更精细、可控的投毒攻击方法。

**方法:** 提出名为FedSA的新攻击方法，结合了鲁棒非线性控制-滑模控制（SMC）理论与模型投毒攻击。通过操纵恶意客户端的更新，推动全局模型进入受损状态，同时以受控且不易察觉的速度进行。利用FedSA的鲁棒控制特性，可精确设定全局模型的收敛界限和准确率水平。

**结果:** 实验结果表明，FedSA能够在使用较少恶意客户端的情况下，精准地将全局模型准确率降低到预设水平，同时保持高隐匿性和可调的学习速率。

**结论:** FedSA作为一种新型投毒攻击方法，展示了其在联邦学习环境下的有效性和隐蔽性，强调了对联邦学习系统安全性进一步研究的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Performance+Guaranteed+Poisoning+Attacks+in+Federated+Learning%3A+A+Sliding+Mode+Approach，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16403，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16403&send_immediately=true&force_search=false)

**原文摘要:** Manipulation of local training data and local updates, i.e., the poisoning
attack, is the main threat arising from the collaborative nature of the
federated learning (FL) paradigm. Most existing poisoning attacks aim to
manipulate local data/models in a way that causes denial-of-service (DoS)
issues. In this paper, we introduce a novel attack method, named Federated
Learning Sliding Attack (FedSA) scheme, aiming at precisely introducing the
extent of poisoning in a subtle controlled manner. It operates with a
predefined objective, such as reducing global model's prediction accuracy by
10\%. FedSA integrates robust nonlinear control-Sliding Mode Control (SMC)
theory with model poisoning attacks. It can manipulate the updates from
malicious clients to drive the global model towards a compromised state,
achieving this at a controlled and inconspicuous rate. Additionally, leveraging
the robust control properties of FedSA allows precise control over the
convergence bounds, enabling the attacker to set the global accuracy of the
poisoned model to any desired level. Experimental results demonstrate that
FedSA can accurately achieve a predefined global accuracy with fewer malicious
clients while maintaining a high level of stealth and adjustable learning
rates.

</details>


### [66] [Implicit Jailbreak Attacks via Cross-Modal Information Concealment on Vision-Language Models](https://arxiv.org/abs/2505.16446)
*Zhaoxin Wang, Handing Wang, Cong Tian, Yaochu Jin*

**主要类别:** cs.LG

**概要:** 多模态大语言模型（MLLMs）虽然具备强大的跨模态推理能力，但其扩展的输入空间引入了新的攻击面。本文提出了一种新型隐式越狱框架IJA，通过最低有效位隐写术将恶意指令嵌入图像，并结合看似无害的文本提示，从而增强对不同MLLMs的攻击效果。该方法在商业模型如GPT-4o和Gemini-1.5 Pro上，仅平均使用3次查询即可达到超过90%的攻击成功率。


<details>
  <summary>更多</summary>
  
**动机:** 尽管多模态大语言模型具有强大的跨模态推理能力，但随着这些模型逐渐整合跨模态一致性与对齐机制，显式的越狱攻击变得更容易被检测和阻止。因此，需要一种更隐蔽且高效的攻击方法来测试和提升模型的安全性。

**方法:** 提出了一个名为IJA的隐式越狱框架，该框架利用最低有效位隐写术将恶意指令嵌入图像，并结合看似无害的图像相关文本提示。同时，引入对抗性后缀生成和模板优化模块，基于模型反馈迭代优化提示和嵌入内容，以提高在不同MLLMs上的攻击效果。

**结果:** 实验表明，IJA框架在商业模型如GPT-4o和Gemini-1.5 Pro上表现出色，仅需平均3次查询即可实现超过90%的攻击成功率。

**结论:** 本文提出的IJA框架展示了隐式越狱攻击在多模态大语言模型中的潜力和威胁，强调了进一步研究和改进模型安全性的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Implicit+Jailbreak+Attacks+via+Cross-Modal+Information+Concealment+on+Vision-Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16446，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16446&send_immediately=true&force_search=false)

**原文摘要:** Multimodal large language models (MLLMs) enable powerful cross-modal
reasoning capabilities. However, the expanded input space introduces new attack
surfaces. Previous jailbreak attacks often inject malicious instructions from
text into less aligned modalities, such as vision. As MLLMs increasingly
incorporate cross-modal consistency and alignment mechanisms, such explicit
attacks become easier to detect and block. In this work, we propose a novel
implicit jailbreak framework termed IJA that stealthily embeds malicious
instructions into images via least significant bit steganography and couples
them with seemingly benign, image-related textual prompts. To further enhance
attack effectiveness across diverse MLLMs, we incorporate adversarial suffixes
generated by a surrogate model and introduce a template optimization module
that iteratively refines both the prompt and embedding based on model feedback.
On commercial models like GPT-4o and Gemini-1.5 Pro, our method achieves attack
success rates of over 90% using an average of only 3 queries.

</details>


### [67] [Constrained Non-negative Matrix Factorization for Guided Topic Modeling of Minority Topics](https://arxiv.org/abs/2505.16493)
*Seyedeh Fatemeh Ebrahimi, Jaakko Peltonen*

**主要类别:** cs.LG

**概要:** 提出了一种通过特别约束的非负矩阵分解(NMF)的主题建模解决方案，该方法利用种子词列表来表征少数群体内容，但不要求专家预先指定其在少数群体主题上的划分。通过在合成数据上进行实验，该方法在主题纯度、归一化互信息等方面优于几种基线方法，并通过Jensen-Shannon散度(JSD)评估主题质量。在一个关于YouTube vlog评论的案例研究中，该模型成功识别并揭示了与心理健康相关的少数群体内容。


<details>
  <summary>更多</summary>
  
**动机:** 主题模型常常无法捕捉到低出现率但对领域至关重要的主题（少数主题），例如在线评论中的心理健康主题。现有的方法虽然可以结合领域知识，但如果需要过多详细的预期主题，则可能会阻碍主题划分和变化的发现。

**方法:** 提出了一种通过特别约束的非负矩阵分解(NMF)的主题建模解决方案。该方法引入一个种子词列表以表征感兴趣的少数内容，但不需要专家预先指定这些内容在少数主题中的划分。通过对少数主题和主题中的种子词内容进行出现率约束，学习到不同的数据驱动的少数主题和多数主题。使用Karush-Kuhn-Tucker (KKT)条件与乘法更新来拟合约束的NMF。

**结果:** 在合成数据上，该方法在主题纯度、归一化互信息等方面优于几个基线方法，并使用Jensen-Shannon散度(JSD)评估主题质量。在YouTube vlog评论的案例研究中，模型成功识别并揭示了与心理健康相关的少数群体内容。

**结论:** 所提出的受约束的NMF方法能够有效地识别少数主题，并且在合成数据和实际应用中均表现良好。这种方法为探索少数群体内容提供了新的途径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Constrained+Non-negative+Matrix+Factorization+for+Guided+Topic+Modeling+of+Minority+Topics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16493，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16493&send_immediately=true&force_search=false)

**原文摘要:** Topic models often fail to capture low-prevalence, domain-critical themes,
so-called minority topics, such as mental health themes in online comments.
While some existing methods can incorporate domain knowledge, such as expected
topical content, methods allowing guidance may require overly detailed expected
topics, hindering the discovery of topic divisions and variation. We propose a
topic modeling solution via a specially constrained NMF. We incorporate a seed
word list characterizing minority content of interest, but we do not require
experts to pre-specify their division across minority topics. Through
prevalence constraints on minority topics and seed word content across topics,
we learn distinct data-driven minority topics as well as majority topics. The
constrained NMF is fitted via Karush-Kuhn-Tucker (KKT) conditions with
multiplicative updates. We outperform several baselines on synthetic data in
terms of topic purity, normalized mutual information, and also evaluate topic
quality using Jensen-Shannon divergence (JSD). We conduct a case study on
YouTube vlog comments, analyzing viewer discussion of mental health content;
our model successfully identifies and reveals this domain-relevant minority
content.

</details>


### [68] [Accuracy vs. Accuracy: Computational Tradeoffs Between Classification Rates and Utility](https://arxiv.org/abs/2505.16494)
*Noga Amit, Omer Reingold, Guy N. Rothblum*

**主要类别:** cs.LG

**概要:** 在包含更丰富标签（如个体类型、排名或风险估计）而非仅仅是二元结果的训练数据环境下，本文重新审视了公平性及其与效用和效率之间的相互作用。提出了一种算法，可以实现比标准监督学习更强的基于证据的公平性概念，并支持准确的子群体分类率的分类和排名技术。此外，还展示了同时实现准确分类率和最优损失最小化在某些情况下是计算不可行的。


<details>
  <summary>更多</summary>
  
**动机:** 现有公平性研究主要集中在标准监督学习中二元结果的数据上，但现实中的数据往往包含更丰富的标签信息，例如个体类型、排名或风险估计。这些信息为实现更强的基于证据的公平性提供了可能性。因此，需要探索如何利用这些丰富标签来改进公平性和效用的平衡。

**方法:** 1. 提出了一种新的算法框架，该框架能够利用更丰富的数据标签（如个体类型、排名或风险估计）来实现更强的基于证据的公平性。
2. 设计了分类和排名技术，能够在保持准确的子群体分类率的同时适用于广泛的分类规则和下游应用。
3. 开发了预测器，支持损失最小化以最大化效用或实现公平处理。
4. 通过理论分析证明了同时实现准确分类率和最优损失最小化的计算不可行性。
5. 探讨了两种自然且可实现的准确性概念之间的权衡，它们都可以由公平性动机驱动。

**结果:** 1. 所提出的算法实现了比标准监督学习更强的基于证据的公平性。
2. 在保持准确的子群体分类率方面取得了显著进展。
3. 理论上证明了同时满足准确分类率和最优损失最小化的计算困难性。
4. 发现两种准确性概念可以通过高效学习分别实现，但同时实现存在挑战。

**结论:** 本文提出了利用丰富数据标签实现更强公平性的方法，并揭示了同时实现准确分类率和最优损失最小化的计算障碍。这表明，在公平性研究中需要在两种自然且可实现的准确性概念之间进行权衡。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Accuracy+vs.+Accuracy%3A+Computational+Tradeoffs+Between+Classification+Rates+and+Utility，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16494，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16494&send_immediately=true&force_search=false)

**原文摘要:** We revisit the foundations of fairness and its interplay with utility and
efficiency in settings where the training data contain richer labels, such as
individual types, rankings, or risk estimates, rather than just binary
outcomes. In this context, we propose algorithms that achieve stronger notions
of evidence-based fairness than are possible in standard supervised learning.
Our methods support classification and ranking techniques that preserve
accurate subpopulation classification rates, as suggested by the underlying
data distributions, across a broad class of classification rules and downstream
applications. Furthermore, our predictors enable loss minimization, whether
aimed at maximizing utility or in the service of fair treatment.
  Complementing our algorithmic contributions, we present impossibility results
demonstrating that simultaneously achieving accurate classification rates and
optimal loss minimization is, in some cases, computationally infeasible. Unlike
prior impossibility results, our notions are not inherently in conflict and are
simultaneously satisfied by the Bayes-optimal predictor. Furthermore, we show
that each notion can be satisfied individually via efficient learning. Our
separation thus stems from the computational hardness of learning a
sufficiently good approximation of the Bayes-optimal predictor. These
computational impossibilities present a choice between two natural and
attainable notions of accuracy that could both be motivated by fairness.

</details>


### [69] [Computing Exact Shapley Values in Polynomial Time for Product-Kernel Methods](https://arxiv.org/abs/2505.16516)
*Majid Mohammadi, Siu Lun Chau, Krikamol Muandet*

**主要类别:** cs.LG

**概要:** 本论文提出了一种名为PKeX-Shapley的新算法，利用积核的乘法结构实现了多项式时间内Shapley值的确切计算。此方法提高了基于核的学习的可解释性，并可推广到解释核基统计差异（如MMD和HSIC）。


<details>
  <summary>更多</summary>
  
**动机:** 核方法在机器学习中广泛使用，但由于其黑箱性质，可解释性受到限制。虽然基于Shapley值的特征归因技术提供了可解释性的路径，但精确计算Shapley值通常计算上不可行，因此需要开发近似方案。

**方法:** 论文引入了PKeX-Shapley算法，该算法通过利用积核模型的功能分解递归公式，能够在多项式时间内实现Shapley值的确切计算。此外，框架还可以推广到解释核基统计差异，例如最大均值差异（MMD）和Hilbert-Schmidt独立性标准（HSIC）。

**结果:** PKeX-Shapley算法不仅实现了Shapley值的高效计算，还增强了基于核的学习的可解释性。并且证明了该方法可以应用于更广泛的核基统计工具中。

**结论:** PKeX-Shapley为基于核的方法提供了一个新的、高效的解释工具，能够显著提高这些模型的透明度和可解释性，同时拓宽了其在统计推断中的应用范围。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Computing+Exact+Shapley+Values+in+Polynomial+Time+for+Product-Kernel+Methods，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16516，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16516&send_immediately=true&force_search=false)

**原文摘要:** Kernel methods are widely used in machine learning due to their flexibility
and expressive power. However, their black-box nature poses significant
challenges to interpretability, limiting their adoption in high-stakes
applications. Shapley value-based feature attribution techniques, such as SHAP
and kernel-specific variants like RKHS-SHAP, offer a promising path toward
explainability. Yet, computing exact Shapley values remains computationally
intractable in general, motivating the development of various approximation
schemes. In this work, we introduce PKeX-Shapley, a novel algorithm that
utilizes the multiplicative structure of product kernels to enable the exact
computation of Shapley values in polynomial time. We show that product-kernel
models admit a functional decomposition that allows for a recursive formulation
of Shapley values. This decomposition not only yields computational efficiency
but also enhances interpretability in kernel-based learning. We also
demonstrate how our framework can be generalized to explain kernel-based
statistical discrepancies such as the Maximum Mean Discrepancy (MMD) and the
Hilbert-Schmidt Independence Criterion (HSIC), thus offering new tools for
interpretable statistical inference.

</details>


### [70] [Joint Relational Database Generation via Graph-Conditional Diffusion Models](https://arxiv.org/abs/2505.16527)
*Mohamed Amine Ketata, David Lüdke, Leo Schwinn, Stephan Günnemann*

**主要类别:** cs.LG

**概要:** 提出了一种新的生成模型GRDM，用于关系数据库的所有表的联合建模，无需固定顺序。该模型在多表关联性和单表保真度上显著优于自回归基线方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的生成模型要么专注于单表生成，要么依赖于自回归分解，这限制了并行性、下游应用灵活性，并因条件独立假设导致误差累积。

**方法:** 通过使用RDBs的自然图表示，提出了Graph-Conditional Relational Diffusion Model (GRDM)，利用图神经网络来联合去噪行属性并捕捉复杂的跨表依赖关系。

**结果:** 在六个真实世界的关系数据库上的广泛实验表明，该方法在建模多跳跨表关联方面显著优于自回归基线，并在单表保真度度量上达到最先进的性能。

**结论:** GRDM提供了一种无需固定顺序的联合建模所有RDB表的方法，展现了优越的性能和灵活性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Joint+Relational+Database+Generation+via+Graph-Conditional+Diffusion+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16527，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16527&send_immediately=true&force_search=false)

**原文摘要:** Building generative models for relational databases (RDBs) is important for
applications like privacy-preserving data release and augmenting real datasets.
However, most prior work either focuses on single-table generation or relies on
autoregressive factorizations that impose a fixed table order and generate
tables sequentially. This approach limits parallelism, restricts flexibility in
downstream applications like missing value imputation, and compounds errors due
to commonly made conditional independence assumptions. We propose a
fundamentally different approach: jointly modeling all tables in an RDB without
imposing any order. By using a natural graph representation of RDBs, we propose
the Graph-Conditional Relational Diffusion Model (GRDM). GRDM leverages a graph
neural network to jointly denoise row attributes and capture complex
inter-table dependencies. Extensive experiments on six real-world RDBs
demonstrate that our approach substantially outperforms autoregressive
baselines in modeling multi-hop inter-table correlations and achieves
state-of-the-art performance on single-table fidelity metrics.

</details>


### [71] [HOFT: Householder Orthogonal Fine-tuning](https://arxiv.org/abs/2505.16531)
*Alejandro Moreno Arcas, Albert Sanchis, Jorge Civera, Alfons Juan*

**主要类别:** cs.LG

**概要:** 提出HOFT和SHOFT两种新型正交微调方法，缓解时间和空间复杂度问题，并在下游任务中表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基础模型适应方法主要依赖低秩方法或正交微调方法，但传统正交微调方法效率较低，需要改进。

**方法:** 提出Householder Orthogonal Fine-tuning (HOFT) 和 Scaled Householder Orthogonal Fine-tuning (SHOFT)，通过探索正交微调范式的理论性质来降低时间和空间复杂度。

**结果:** HOFT和SHOFT在常识推理、机器翻译、主题驱动生成和数学推理等下游任务中，相较于现有最先进的适应方法表现出相当或更优的结果。

**结论:** HOFT和SHOFT有效缓解了正交微调的时间和空间复杂度问题，并在多种任务中展现出良好的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是HOFT%3A+Householder+Orthogonal+Fine-tuning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16531，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16531&send_immediately=true&force_search=false)

**原文摘要:** Adaptation of foundation models using low-rank methods is a widespread
approach. Another way to adapt these models is to employ orthogonal fine-tuning
methods, which are less time and memory efficient despite their good
generalization properties. In this work, we propose Householder Orthogonal
Fine-tuning (HOFT), a novel orthogonal fine-tuning method that aims to
alleviate time and space complexity. Moreover, some theoretical properties of
the orthogonal fine-tuning paradigm are explored. From this exploration, Scaled
Householder Orthogonal Fine-tuning (SHOFT) is proposed. Both HOFT and SHOFT are
evaluated in downstream tasks, namely commonsense reasoning, machine
translation, subject-driven generation and mathematical reasoning. Compared
with state-of-the-art adaptation methods, HOFT and SHOFT show comparable or
better results.

</details>


### [72] [Towards Coordinate- and Dimension-Agnostic Machine Learning for Partial Differential Equations](https://arxiv.org/abs/2505.16549)
*Trung V. Phan, George A. Kevrekidis, Soledad Villar, Yannis G. Kevrekidis, Juan M. Bello-Rivas*

**主要类别:** cs.LG

**概要:** 本论文提出了一种基于外微积分形式主义的机器学习方法，用于预测标量场系统的演化，这种方法在坐标和维度上独立，能够实现“空间解放”的偏微分方程（PDE）学习。通过在FitzHugh-Nagumo、Barkley反应扩散模型以及Patlak-Keller-Segel模型中的实验，证明了该方法可以在不同空间条件下无缝过渡并准确预测。


<details>
  <summary>更多</summary>
  
**动机:** 现有的数据驱动偏微分方程识别方法通常依赖于特定的空间维度和数据采集的坐标系，这限制了所学进化方程向其他空间的泛化能力。为了解决这一问题，研究者希望开发一种与坐标和维度无关的学习方法。

**方法:** 研究者采用了一种基于外微积分的机器学习方法，这种形式主义是无坐标的，并且可以立即推广到任意维度。通过在FitzHugh-Nagumo、Barkley反应扩散模型以及由原位趋化细菌观测信息的Patlak-Keller-Segel模型中进行数值实验来验证该方法。

**结果:** 实验结果表明，该方法允许在各种空间上下文中进行无缝转换，能够在不同维度、坐标系、边界条件和曲率的空间中进行准确预测。

**结论:** 提出的“空间解放”PDE学习方法克服了传统方法的局限性，实现了对不同空间条件下场动力学的有效预测，具有广泛的应用前景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Towards+Coordinate-+and+Dimension-Agnostic+Machine+Learning+for+Partial+Differential+Equations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16549，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16549&send_immediately=true&force_search=false)

**原文摘要:** The machine learning methods for data-driven identification of partial
differential equations (PDEs) are typically defined for a given number of
spatial dimensions and a choice of coordinates the data have been collected in.
This dependence prevents the learned evolution equation from generalizing to
other spaces. In this work, we reformulate the problem in terms of coordinate-
and dimension-independent representations, paving the way toward what we call
``spatially liberated" PDE learning. To this end, we employ a machine learning
approach to predict the evolution of scalar field systems expressed in the
formalism of exterior calculus, which is coordinate-free and immediately
generalizes to arbitrary dimensions by construction. We demonstrate the
performance of this approach in the FitzHugh-Nagumo and Barkley
reaction-diffusion models, as well as the Patlak-Keller-Segel model informed by
in-situ chemotactic bacteria observations. We provide extensive numerical
experiments that demonstrate that our approach allows for seamless transitions
across various spatial contexts. We show that the field dynamics learned in one
space can be used to make accurate predictions in other spaces with different
dimensions, coordinate systems, boundary conditions, and curvatures.

</details>


### [73] [A Two-Stage Data Selection Framework for Data-Efficient Model Training on Edge Devices](https://arxiv.org/abs/2505.16563)
*Chen Gong, Rui Xing, Zhenzhe Zheng, Fan Wu*

**主要类别:** cs.LG

**概要:** 由于数据隐私和个性化服务需求，边缘设备上的机器学习模型训练需求正在增加。然而，当前的设备上模型训练因低训练吞吐量、有限存储和数据重要性多样而无法充分利用设备数据。为提高数据资源利用率，本文提出了一种两阶段数据选择框架Titan，以从流数据中选择最重要的数据批次进行模型训练，保证效率和效果。Titan通过粗粒度过滤候选数据集和细粒度选择最高性能提升的数据批次，并利用管道技术协同执行数据选择和模型训练，避免资源冲突。实验表明，Titan可将训练时间减少43%，最终准确率提高6.2%，系统开销较小。


<details>
  <summary>更多</summary>
  
**动机:** 机器学习模型在边缘设备上的训练需求日益增长，但由于低训练吞吐量、有限存储和数据重要性多样，当前设备上的模型训练未能充分利用设备数据。

**方法:** 提出了一种两阶段数据选择框架Titan：第一阶段粗粒度过滤出具有潜在高重要性的候选数据集；第二阶段细粒度选择具有最高模型性能提升的数据批次。此外，Titan利用管道技术协同执行数据选择和模型训练，避免资源冲突。

**结果:** 实验证明Titan可以将训练时间减少43%，最终准确率提高6.2%，同时系统开销（如数据处理延迟、内存占用和能耗）较小。

**结论:** Titan框架有效提高了设备上数据资源的利用率，在减少训练时间的同时提升了模型最终准确率，且系统开销较低，适合实际应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Two-Stage+Data+Selection+Framework+for+Data-Efficient+Model+Training+on+Edge+Devices，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16563，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16563&send_immediately=true&force_search=false)

**原文摘要:** The demand for machine learning (ML) model training on edge devices is
escalating due to data privacy and personalized service needs. However, we
observe that current on-device model training is hampered by the
under-utilization of on-device data, due to low training throughput, limited
storage and diverse data importance. To improve data resource utilization, we
propose a two-stage data selection framework {\sf Titan} to select the most
important data batch from streaming data for model training with guaranteed
efficiency and effectiveness. Specifically, in the first stage, {\sf Titan}
filters out a candidate dataset with potentially high importance in a
coarse-grained manner.In the second stage of fine-grained selection, we propose
a theoretically optimal data selection strategy to identify the data batch with
the highest model performance improvement to current training round. To further
enhance time-and-resource efficiency, {\sf Titan} leverages a pipeline to
co-execute data selection and model training, and avoids resource conflicts by
exploiting idle computing resources. We evaluate {\sf Titan} on real-world edge
devices and three representative edge computing tasks with diverse models and
data modalities. Empirical results demonstrate that {\sf Titan} achieves up to
$43\%$ reduction in training time and $6.2\%$ increase in final accuracy with
minor system overhead, such as data processing delay, memory footprint and
energy consumption.

</details>


### [74] [Finetuning-Activated Backdoors in LLMs](https://arxiv.org/abs/2505.16567)
*Thibaud Gloaguen, Mark Vero, Robin Staab, Martin Vechev*

**主要类别:** cs.LG

**概要:** 研究展示了通过微调激活后门（FAB）攻击，可使大型语言模型在微调后表现出恶意行为，挑战了微调过程的安全性假设。


<details>
  <summary>更多</summary>
  
**动机:** 尽管微调公开的大型语言模型（LLMs）被认为是提高任务特定性能的标准做法，但目前尚未有人研究微调过程中可能存在的安全威胁。本文旨在探讨是否可以通过特定方法创建看似无害但在下游用户微调后表现出恶意行为的语言模型。

**方法:** 提出了一种名为FAB（Finetuning-Activated Backdoor）的攻击方法，利用元学习技术对LLM进行投毒，模拟下游微调过程，优化以使微调后的模型出现恶意行为。同时，确保投毒前的LLM保持正常功能且不表现出任何恶意行为。

**结果:** FAB攻击在多个LLM和三种目标恶意行为（未经请求的广告、拒绝服务和越狱能力）上证明了其有效性，并且该后门对用户不同的微调选择（如数据集、步骤数、调度器等）具有鲁棒性。

**结论:** 研究结果表明，微调过程可能存在安全漏洞，揭示了LLMs复杂性带来的新攻击向量，挑战了关于微调安全性的传统假设。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Finetuning-Activated+Backdoors+in+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16567，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16567&send_immediately=true&force_search=false)

**原文摘要:** Finetuning openly accessible Large Language Models (LLMs) has become standard
practice for achieving task-specific performance improvements. Until now,
finetuning has been regarded as a controlled and secure process in which
training on benign datasets led to predictable behaviors. In this paper, we
demonstrate for the first time that an adversary can create poisoned LLMs that
initially appear benign but exhibit malicious behaviors once finetuned by
downstream users. To this end, our proposed attack, FAB (Finetuning-Activated
Backdoor), poisons an LLM via meta-learning techniques to simulate downstream
finetuning, explicitly optimizing for the emergence of malicious behaviors in
the finetuned models. At the same time, the poisoned LLM is regularized to
retain general capabilities and to exhibit no malicious behaviors prior to
finetuning. As a result, when users finetune the seemingly benign model on
their own datasets, they unknowingly trigger its hidden backdoor behavior. We
demonstrate the effectiveness of FAB across multiple LLMs and three target
behaviors: unsolicited advertising, refusal, and jailbreakability.
Additionally, we show that FAB-backdoors are robust to various finetuning
choices made by the user (e.g., dataset, number of steps, scheduler). Our
findings challenge prevailing assumptions about the security of finetuning,
revealing yet another critical attack vector exploiting the complexities of
LLMs.

</details>


### [75] [Large Language Model-Empowered Interactive Load Forecasting](https://arxiv.org/abs/2505.16577)
*Yu Zuo, Dalin Qin, Yi Wang*

**主要类别:** cs.LG

**概要:** 随着电力系统复杂性的增加，准确的负荷预测变得越来越重要。然而，当前预测方法的静态设计缺乏人机交互机制，导致操作人员难以理解和应用这些模型，并且无法将他们的经验融入预测过程。本文提出了一种基于大型语言模型（LLM）的多智能体协作框架，通过自然语言理解与推理能力，降低技术门槛并整合人类经验。实验表明，用户在关键阶段提供适当见解时，互动式负荷预测精度显著提高，成本分析显示该框架具有实际部署可行性。


<details>
  <summary>更多</summary>
  
**动机:** 电力系统复杂性增加使得精确的负荷预测至关重要，但现有方法缺乏人机交互机制，使非AI专家的操作人员难以使用并整合其经验。

**方法:** 设计了一种基于LLM的多智能体协作框架，包含一组专门的智能体以执行预测工作流中的不同任务，并通过专用通信机制进行协作。该框架在整个预测流程中嵌入了交互机制，允许操作人员提供输入和见解。

**结果:** 实验结果表明，在用户于关键阶段提供适当见解的情况下，互动式负荷预测的准确性显著提高；成本分析表明该框架在现实世界中部署是经济可行的。

**结论:** 提出的LLM多智能体协作框架成功降低了非专家用户的使用门槛，同时提高了预测准确性，为实际电力系统提供了实用的人机交互解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Large+Language+Model-Empowered+Interactive+Load+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16577，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16577&send_immediately=true&force_search=false)

**原文摘要:** The growing complexity of power systems has made accurate load forecasting
more important than ever. An increasing number of advanced load forecasting
methods have been developed. However, the static design of current methods
offers no mechanism for human-model interaction. As the primary users of
forecasting models, system operators often find it difficult to understand and
apply these advanced models, which typically requires expertise in artificial
intelligence (AI). This also prevents them from incorporating their experience
and real-world contextual understanding into the forecasting process. Recent
breakthroughs in large language models (LLMs) offer a new opportunity to
address this issue. By leveraging their natural language understanding and
reasoning capabilities, we propose an LLM-based multi-agent collaboration
framework to bridge the gap between human operators and forecasting models. A
set of specialized agents is designed to perform different tasks in the
forecasting workflow and collaborate via a dedicated communication mechanism.
This framework embeds interactive mechanisms throughout the load forecasting
pipeline, reducing the technical threshold for non-expert users and enabling
the integration of human experience. Our experiments demonstrate that the
interactive load forecasting accuracy can be significantly improved when users
provide proper insight in key stages. Our cost analysis shows that the
framework remains affordable, making it practical for real-world deployment.

</details>


### [76] [How Ensembles of Distilled Policies Improve Generalisation in Reinforcement Learning](https://arxiv.org/abs/2505.16581)
*Max Weltevrede, Moritz A. Zanger, Matthijs T. J. Spaan, Wendelin Böhmer*

**主要类别:** cs.LG

**概要:** 在强化学习的零样本策略迁移中，本文研究了训练后策略蒸馏的泛化能力，并提供了理论和实证依据，表明使用多样数据训练的策略集成能够显著提升泛化性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管已有研究表明训练后的策略蒸馏可以提升测试环境中的性能，但其原因尚不明确，且缺乏对蒸馏所需数据的选择指导。

**方法:** 在一定假设条件下，推导出训练后策略蒸馏的泛化界，并提出两点改进建议：1) 使用策略集成；2) 使用尽可能多的训练环境数据进行蒸馏。随后在更一般的设置下验证这些建议的有效性。

**结果:** 实验证明，基于多样化数据集训练的策略集成能够在测试环境中显著优于原始代理。

**结论:** 策略蒸馏可以通过集成学习和充分利用训练数据来增强泛化能力，为零样本策略迁移提供了一种有效方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+Ensembles+of+Distilled+Policies+Improve+Generalisation+in+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16581，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16581&send_immediately=true&force_search=false)

**原文摘要:** In the zero-shot policy transfer setting in reinforcement learning, the goal
is to train an agent on a fixed set of training environments so that it can
generalise to similar, but unseen, testing environments. Previous work has
shown that policy distillation after training can sometimes produce a policy
that outperforms the original in the testing environments. However, it is not
yet entirely clear why that is, or what data should be used to distil the
policy. In this paper, we prove, under certain assumptions, a generalisation
bound for policy distillation after training. The theory provides two practical
insights: for improved generalisation, you should 1) train an ensemble of
distilled policies, and 2) distil it on as much data from the training
environments as possible. We empirically verify that these insights hold in
more general settings, when the assumptions required for the theory no longer
hold. Finally, we demonstrate that an ensemble of policies distilled on a
diverse dataset can generalise significantly better than the original agent.

</details>


### [77] [Training on Plausible Counterfactuals Removes Spurious Correlations](https://arxiv.org/abs/2505.16583)
*Shpresim Sadiku, Kartikeya Chitranshi, Hiroshi Kera, Sebastian Pokutta*

**主要类别:** cs.LG

**概要:** 通过使用带有错误目标类别的合理反事实示例(p-CFEs)训练分类器，可以使分类器对未受干扰的输入进行原始标签分类。实验表明，与对抗性扰动相比，使用p-CFEs训练可以提高分类器在分布内准确性，并显著减少对虚假相关性的偏差。


<details>
  <summary>更多</summary>
  
**动机:** 研究者希望探索如何利用合理反事实示例（plausible counterfactual explanations, p-CFEs）来改进机器学习模型的泛化能力和公平性，特别是减少模型对虚假相关性的依赖。

**方法:** 将p-CFEs标记为诱导的错误目标类别，并用这些数据训练分类器。随后评估该分类器在未受干扰的数据上的表现，验证其是否能够正确恢复原始标签。这种方法扩展了之前基于对抗性扰动的研究，应用于p-CFEs。

**结果:** 实验结果表明，使用p-CFEs训练的分类器不仅在分布内数据上达到了高准确性，还显著减少了对虚假相关性的偏差。

**结论:** 合理反事实示例（p-CFEs）可以用作一种有效的数据增强工具，帮助构建更稳健、更公平的分类器，尤其是在需要降低虚假相关性影响的情况下。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Training+on+Plausible+Counterfactuals+Removes+Spurious+Correlations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16583，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16583&send_immediately=true&force_search=false)

**原文摘要:** Plausible counterfactual explanations (p-CFEs) are perturbations that
minimally modify inputs to change classifier decisions while remaining
plausible under the data distribution. In this study, we demonstrate that
classifiers can be trained on p-CFEs labeled with induced \emph{incorrect}
target classes to classify unperturbed inputs with the original labels. While
previous studies have shown that such learning is possible with adversarial
perturbations, we extend this paradigm to p-CFEs. Interestingly, our
experiments reveal that learning from p-CFEs is even more effective: the
resulting classifiers achieve not only high in-distribution accuracy but also
exhibit significantly reduced bias with respect to spurious correlations.

</details>


### [78] [CausalDynamics: A large-scale benchmark for structural discovery of dynamical causal models](https://arxiv.org/abs/2505.16620)
*Benjamin Herdeanu, Juan Nathaniel, Carla Roesch, Jatan Buch, Gregor Ramien, Johannes Haux, Pierre Gentine*

**主要类别:** cs.LG

**概要:** 本研究提出了CausalDynamics，一个大规模基准和可扩展的数据生成框架，用于推进动态因果模型的结构发现。它包含从数千个耦合常微分方程、随机微分方程以及两个理想化气候模型中衍生的真实因果图。研究对具有噪声、混杂和滞后动态的系统的图形重建进行了最先进的因果发现算法的全面评估。


<details>
  <summary>更多</summary>
  
**动机:** 现有的因果发现方法主要针对确定性、低维和弱非线性时间序列数据，难以处理动态系统中的因果关系，特别是在无法进行主动干预的领域。需要一个更复杂和高维度的基准来推动动态因果模型的研究。

**方法:** 提出CausalDynamics框架，包括从数千个耦合常微分方程、随机微分方程及两个理想化气候模型中提取真实因果图；执行最先进的因果发现算法在有噪声、混杂和滞后动态的系统上的图形重建评估；提供一个模块化的工作流程以构建物理系统的层次结构。

**结果:** CausalDynamics框架能够促进稳健因果发现算法的发展，适用于跨域应用并解决独特挑战。提供了用户友好的实现和文档。

**结论:** CausalDynamics为动态因果模型的结构发现提供了新的基准和工具，推动了相关领域的研究进展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CausalDynamics%3A+A+large-scale+benchmark+for+structural+discovery+of+dynamical+causal+models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16620，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16620&send_immediately=true&force_search=false)

**原文摘要:** Causal discovery for dynamical systems poses a major challenge in fields
where active interventions are infeasible. Most methods used to investigate
these systems and their associated benchmarks are tailored to deterministic,
low-dimensional and weakly nonlinear time-series data. To address these
limitations, we present CausalDynamics, a large-scale benchmark and extensible
data generation framework to advance the structural discovery of dynamical
causal models. Our benchmark consists of true causal graphs derived from
thousands of coupled ordinary and stochastic differential equations as well as
two idealized climate models. We perform a comprehensive evaluation of
state-of-the-art causal discovery algorithms for graph reconstruction on
systems with noisy, confounded, and lagged dynamics. CausalDynamics consists of
a plug-and-play, build-your-own coupling workflow that enables the construction
of a hierarchy of physical systems. We anticipate that our framework will
facilitate the development of robust causal discovery algorithms that are
broadly applicable across domains while addressing their unique challenges. We
provide a user-friendly implementation and documentation on
https://kausable.github.io/CausalDynamics.

</details>


### [79] [Multivariate Latent Recalibration for Conditional Normalizing Flows](https://arxiv.org/abs/2505.16636)
*Victor Dheur, Souhaib Ben Taieb*

**主要类别:** cs.LG

**概要:** 在多变量响应变量的条件下，准确描述其完整的条件分布对于可信决策至关重要。然而，错误指定或校准不良的多变量模型可能导致对联合分布的近似较差，从而导致不可靠的预测和次优决策。现有的重新校准方法主要局限于单变量设置，而尽管共形预测技术可以生成具有覆盖保证的多变量预测区域，但它们不提供完整的概率密度函数。本文提出了一种新的潜在校准概念，并引入了潜在重新校准（LR）方法，该方法学习潜在空间的转换，同时保持计算效率并产生具有明确多变量密度函数的重新校准分布。实验表明，LR能够持续改善潜在校准误差和重新校准模型的负对数似然性。


<details>
  <summary>更多</summary>
  
**动机:** 可靠地描述给定协变量集的多变量响应变量的完整条件分布对于可信赖的决策制定至关重要。然而，当前的方法要么无法很好地近似联合分布，要么缺乏全面的概率密度函数支持，这促使了对改进的多变量模型校准方法的需求。

**方法:** 1. 提出了一种新的潜在校准概念，用于评估条件标准化流的潜在空间中的概率校准。
2. 引入了潜在重新校准（LR），这是一种后验模型重新校准方法，它学习潜在空间的转换，并在有限样本上设置了潜在校准的边界。
3. LR生成了一个具有显式多变量密度函数的重新校准分布，同时保持了计算效率。

**结果:** 通过在表格数据和图像数据上的广泛实验，证明了LR方法能够持续降低潜在校准误差和重新校准模型的负对数似然性。

**结论:** 潜在重新校准（LR）方法为多变量模型提供了有效的重新校准方案，改善了潜在校准误差和模型的负对数似然性，同时保留了计算效率和明确的多变量密度函数表示。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multivariate+Latent+Recalibration+for+Conditional+Normalizing+Flows，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16636，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16636&send_immediately=true&force_search=false)

**原文摘要:** Reliably characterizing the full conditional distribution of a multivariate
response variable given a set of covariates is crucial for trustworthy
decision-making. However, misspecified or miscalibrated multivariate models may
yield a poor approximation of the joint distribution of the response variables,
leading to unreliable predictions and suboptimal decisions. Furthermore,
standard recalibration methods are primarily limited to univariate settings,
while conformal prediction techniques, despite generating multivariate
prediction regions with coverage guarantees, do not provide a full probability
density function. We address this gap by first introducing a novel notion of
latent calibration, which assesses probabilistic calibration in the latent
space of a conditional normalizing flow. Second, we propose latent
recalibration (LR), a novel post-hoc model recalibration method that learns a
transformation of the latent space with finite-sample bounds on latent
calibration. Unlike existing methods, LR produces a recalibrated distribution
with an explicit multivariate density function while remaining computationally
efficient. Extensive experiments on both tabular and image datasets show that
LR consistently improves latent calibration error and the negative
log-likelihood of the recalibrated models.

</details>


### [80] [Stochastic Forward-Forward Learning through Representational Dimensionality Compression](https://arxiv.org/abs/2505.16649)
*Zhichao Zhu, Yang Qi, Hengyuan Ma, Wenlian Lu, Jianfeng Feng*

**主要类别:** cs.LG

**概要:** The paper introduces a new goodness function for the Forward-Forward algorithm that uses effective dimensionality to incorporate second-order statistical structure, achieving competitive performance with other non-BP methods.


<details>
  <summary>更多</summary>
  
**动机:** Existing goodness functions in the Forward-Forward algorithm neglect correlations between neurons. The authors aim to develop a more comprehensive goodness function that considers second-order statistical structure.

**方法:** The proposed method defines a novel goodness function called dimensionality compression, which minimizes effective dimensionality (ED) for clamped inputs with noise and maximizes it across the sample distribution. This approach promotes structured representations without needing negative samples.

**结果:** The formulation achieves competitive performance compared to other non-BP methods. Noise is shown to play a constructive role in enhancing generalization and improving inference when predictions are based on the mean of squared outputs.

**结论:** This work contributes to the development of biologically plausible learning algorithms and highlights the potential of neuromorphic computing, where stochasticity can be utilized as a computational resource.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Stochastic+Forward-Forward+Learning+through+Representational+Dimensionality+Compression，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16649，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16649&send_immediately=true&force_search=false)

**原文摘要:** The Forward-Forward (FF) algorithm provides a bottom-up alternative to
backpropagation (BP) for training neural networks, relying on a layer-wise
"goodness" function to guide learning. Existing goodness functions, inspired by
energy-based learning (EBL), are typically defined as the sum of squared
post-synaptic activations, neglecting the correlations between neurons. In this
work, we propose a novel goodness function termed dimensionality compression
that uses the effective dimensionality (ED) of fluctuating neural responses to
incorporate second-order statistical structure. Our objective minimizes ED for
clamped inputs when noise is considered while maximizing it across the sample
distribution, promoting structured representations without the need to prepare
negative samples. We demonstrate that this formulation achieves competitive
performance compared to other non-BP methods. Moreover, we show that noise
plays a constructive role that can enhance generalization and improve inference
when predictions are derived from the mean of squared outputs, which is
equivalent to making predictions based on the energy term. Our findings
contribute to the development of more biologically plausible learning
algorithms and suggest a natural fit for neuromorphic computing, where
stochasticity is a computational resource rather than a nuisance. The code is
available at https://github.com/ZhichaoZhu/StochasticForwardForward

</details>


### [81] [End-to-End Framework for Predicting the Remaining Useful Life of Lithium-Ion Batteries](https://arxiv.org/abs/2505.16664)
*Khoa Tran, Tri Le, Bao Huynh, Hung-Cuong Trinh, Vy-Rin Nguyen*

**主要类别:** cs.LG

**概要:** 准确预测锂离子电池的剩余使用寿命（RUL）对于及时维护至关重要。本文提出了一种结合新颖信号处理管道和深度学习模型的方法，通过提取充电-放电循环中的特征并建模电池退化过程，实现了对RUL的高效预测。实验表明，该方法在两个公开数据集上表现出色，具有很强的实际应用潜力。


<details>
  <summary>更多</summary>
  
**动机:** 锂离子电池RUL的精确预测直接影响到依赖它的电动设备的运行效率，因此需要一种基于近期充放电数据、能有效估计剩余可用周期的方法。

**方法:** 方法包括：1) 一个创新的信号预处理管道，计算衍生容量特征，并使用统计指标和差分方法增强信号；2) 一种混合深度学习架构，包含一维卷积神经网络（CNN）、注意力机制长短期记忆网络（A-LSTM）和基于常微分方程的LSTM（ODE-LSTM），以捕捉局部信号特性和长时间依赖关系；3) 使用迁移学习评估模型性能。

**结果:** 实验结果表明，该模型即使在有限的目标数据上微调时仍能保持稳健性能，在两个公开的大规模数据集上，该方法的表现优于基线深度学习方法和传统机器学习技术，其RMSE值为101.59。

**结论:** 所提出的方法能够有效预测锂离子电池的RUL，展现了强大的实际应用潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是End-to-End+Framework+for+Predicting+the+Remaining+Useful+Life+of+Lithium-Ion+Batteries，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16664，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16664&send_immediately=true&force_search=false)

**原文摘要:** Accurate prediction of the Remaining Useful Life (RUL) is essential for
enabling timely maintenance of lithium-ion batteries, impacting the operational
efficiency of electric applications that rely on them. This paper proposes a
RUL prediction approach that leverages data from recent charge-discharge cycles
to estimate the number of remaining usable cycles. The approach introduces both
a novel signal processing pipeline and a deep learning prediction model. In the
signal preprocessing pipeline, a derived capacity feature is computed based on
current and capacity signals. Alongside original capacity, voltage and current,
these features are denoised and enhanced using statistical metrics and a
delta-based method to capture differences between the current and previous
cycles. In the prediction model, the processed features are then fed into a
hybrid deep learning architecture composed of 1D Convolutional Neural Networks
(CNN), Attentional Long Short-Term Memory (A-LSTM), and Ordinary Differential
Equation-based LSTM (ODE-LSTM) modules. This architecture is designed to
capture both local signal characteristics and long-range temporal dependencies
while modeling the continuous-time dynamics of battery degradation. The model
is further evaluated using transfer learning across different learning
strategies and target data partitioning scenarios. Results indicate that the
model maintains robust performance, even when fine-tuned on limited target
data. Experimental results on two publicly available large-scale datasets
demonstrate that the proposed method outperforms a baseline deep learning
approach and machine learning techniques, achieving an RMSE of 101.59,
highlighting its strong potential for real-world RUL prediction applications.

</details>


### [82] [Quantum Feature Optimization for Enhanced Clustering of Blockchain Transaction Data](https://arxiv.org/abs/2505.16672)
*Yun-Cheng Tsai, Samuel Yen-Chi Chen*

**主要类别:** cs.LG

**概要:** 本研究比较了三种区块链交易数据聚类方法：经典K-Means、混合聚类（结合量子随机特征）和全量子聚类（使用自监督训练的量子神经网络）。实验表明，即使是浅层量子电路也能有效提取非线性特征，显著提升聚类效果。


<details>
  <summary>更多</summary>
  
**动机:** 区块链交易数据具有高维度、噪声和复杂特征纠缠的特点，这对传统聚类算法构成了重大挑战。因此需要探索新的方法来提高聚类性能。

**方法:** 研究采用了三种方法：1) 经典K-Means聚类；2) 混合聚类，结合经典特征与量子随机特征；3) 全量子聚类，使用自监督训练的量子神经网络优化特征空间。通过系统实验分析量子电路深度和学习原型数量对聚类的影响。

**结果:** 实验结果表明，即使是浅层量子电路也能有效提取有意义的非线性特征，显著改善聚类性能。

**结论:** 混合聚类和全量子聚类方法在处理区块链交易数据时表现出优越性能，特别是在浅层量子电路情况下，能够显著提升聚类效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Quantum+Feature+Optimization+for+Enhanced+Clustering+of+Blockchain+Transaction+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16672，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16672&send_immediately=true&force_search=false)

**原文摘要:** Blockchain transaction data exhibits high dimensionality, noise, and
intricate feature entanglement, presenting significant challenges for
traditional clustering algorithms. In this study, we conduct a comparative
analysis of three clustering approaches: (1) Classical K-Means Clustering,
applied to pre-processed feature representations; (2) Hybrid Clustering,
wherein classical features are enhanced with quantum random features extracted
using randomly initialized quantum neural networks (QNNs); and (3) Fully
Quantum Clustering, where a QNN is trained in a self-supervised manner
leveraging a SwAV-based loss function to optimize the feature space for
clustering directly. The proposed experimental framework systematically
investigates the impact of quantum circuit depth and the number of learned
prototypes, demonstrating that even shallow quantum circuits can effectively
extract meaningful non-linear representations, significantly improving
clustering performance.

</details>


### [83] [On the Out-of-Distribution Generalization of Self-Supervised Learning](https://arxiv.org/abs/2505.16675)
*Wenwen Qiang, Jingyao Wang, Zeen Song, Jiangmeng Li, Changwen Zheng*

**主要类别:** cs.LG

**概要:** 本文研究了自监督学习(SSL)在分布外(OOD)泛化问题，提出了一种基于结构因果模型的后干预分布(PID)，并设计了满足PID约束的批量采样策略，从而提升SSL模型的OOD泛化能力。实验表明该策略在多个下游OOD任务中有效。


<details>
  <summary>更多</summary>
  
**动机:** 自监督学习(SSL)在训练过程中可能学到虚假相关性，导致其分布外(OOD)泛化性能下降。

**方法:** 从数据生成和因果推断的角度分析SSL中的虚假相关性，并提出了基于结构因果模型的后干预分布(PID)，使虚假变量和标签变量相互独立；进一步设计了批量采样策略，通过学习潜在变量模型来满足PID约束。

**结果:** 理论分析证明了潜在变量模型的可识别性，并验证了所提采样策略的有效性；实验证明该策略在多个下游OOD任务中表现良好。

**结论:** 提出的批量采样策略可以提高SSL模型的OOD泛化性能，为解决SSL中的虚假相关性提供了一种新方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+the+Out-of-Distribution+Generalization+of+Self-Supervised+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16675，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16675&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we focus on the out-of-distribution (OOD) generalization of
self-supervised learning (SSL). By analyzing the mini-batch construction during
the SSL training phase, we first give one plausible explanation for SSL having
OOD generalization. Then, from the perspective of data generation and causal
inference, we analyze and conclude that SSL learns spurious correlations during
the training process, which leads to a reduction in OOD generalization. To
address this issue, we propose a post-intervention distribution (PID) grounded
in the Structural Causal Model. PID offers a scenario where the spurious
variable and label variable is mutually independent. Besides, we demonstrate
that if each mini-batch during SSL training satisfies PID, the resulting SSL
model can achieve optimal worst-case OOD performance. This motivates us to
develop a batch sampling strategy that enforces PID constraints through the
learning of a latent variable model. Through theoretical analysis, we
demonstrate the identifiability of the latent variable model and validate the
effectiveness of the proposed sampling strategy. Experiments conducted on
various downstream OOD tasks demonstrate the effectiveness of the proposed
sampling strategy.

</details>


### [84] [Learning Genomic Structure from $k$-mers](https://arxiv.org/abs/2505.16680)
*Filip Thor, Carl Nettelblad*

**主要类别:** cs.LG

**概要:** 本论文提出了一种基于对比学习的方法，用于基因组测序数据的分析。通过训练编码器模型生成嵌入，这些嵌入可以聚类来自相同基因组区域的序列，并保留基因组区域的顺序特性。此方法适用于多种下游任务，例如模拟古DNA（aDNA）读段映射和结构变异识别。此外，该模型在元基因组物种鉴定方面也显示出潜力。论文展示了如何通过引入领域特定的噪声模型增强嵌入的鲁棒性，以及在有线性参考基因组时采用监督对比学习设置。对于短基因组，该方法在准确性和运行时间上与当前的黄金标准BWA-aln相当。由于其良好的扩展性，该方法在元基因组应用和人类大小基因组映射方面具有很高的前景。


<details>
  <summary>更多</summary>
  
**动机:** 基因组测序会产生大量的短核苷酸子序列（reads），需要重新组装以重建完整的基因组。传统的组装方法复杂且计算成本高，因此需要一种新的方法来有效分析这些数据并提供通用的表示形式，以便于各种下游任务的执行。

**方法:** 作者提出了一种基于对比学习的方法，其中编码器模型被训练以生成嵌入，这些嵌入能够将来自相同基因组区域的序列聚类在一起。通过保持基因组区域的顺序特性，形成嵌入空间中的轨迹。模型可以仅反映基因组结构进行训练，也可以在有线性参考基因组时采用监督对比学习设置。另外，还可以通过领域特定的噪声模型增强嵌入的鲁棒性。

**结果:** 该模型在多个任务中表现良好，包括模拟古DNA读段映射、结构变异识别和元基因组物种鉴定。对于短基因组，基于预训练嵌入的小预测头在准确性和运行时间上与BWA-aln相当。此外，该方法具有良好的扩展性，适用于人类大小的基因组和元基因组应用。

**结论:** 提出的对比学习方法为基因组测序数据分析提供了一种有效的解决方案，能够生成通用的序列表示，适用于多种下游任务。特别是在无需构建完整基因组装配的情况下，该方法展现了巨大的潜力，可用于人类大小基因组和元基因组的应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Genomic+Structure+from+%24k%24-mers，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16680，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16680&send_immediately=true&force_search=false)

**原文摘要:** Sequencing a genome to determine an individual's DNA produces an enormous
number of short nucleotide subsequences known as reads, which must be
reassembled to reconstruct the full genome. We present a method for analyzing
this type of data using contrastive learning, in which an encoder model is
trained to produce embeddings that cluster together sequences from the same
genomic region. The sequential nature of genomic regions is preserved in the
form of trajectories through this embedding space. Trained solely to reflect
the structure of the genome, the resulting model provides a general
representation of $k$-mer sequences, suitable for a range of downstream tasks
involving read data. We apply our framework to learn the structure of the $E.\
coli$ genome, and demonstrate its use in simulated ancient DNA (aDNA) read
mapping and identification of structural variations. Furthermore, we illustrate
the potential of using this type of model for metagenomic species
identification. We show how incorporating a domain-specific noise model can
enhance embedding robustness, and how a supervised contrastive learning setting
can be adopted when a linear reference genome is available, by introducing a
distance thresholding parameter $\Gamma$. The model can also be trained fully
self-supervised on read data, enabling analysis without the need to construct a
full genome assembly using specialized algorithms. Small prediction heads based
on a pre-trained embedding are shown to perform on par with BWA-aln, the
current gold standard approach for aDNA mapping, in terms of accuracy and
runtime for short genomes. Given the method's favorable scaling properties with
respect to total genome size, inference using our approach is highly promising
for metagenomic applications and for mapping to genomes comparable in size to
the human genome.

</details>


### [85] [Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator](https://arxiv.org/abs/2505.16690)
*Beier Luo, Shuoyuan Wang, Yixuan Li, Hongxin Wei*

**主要类别:** cs.LG

**概要:** 提出了Disagreement-Aware Confidence Alignment (DACA)，一种新的无监督方法，通过选择性使用一致样本进行校准来优化后训练语言模型（PoLMs）的置信度校准参数，有效减少因预测不一致导致的过度自信问题，并在多个基准测试中显著提高了开源和API-based LLMs的平均ECE达15.08%。


<details>
  <summary>更多</summary>
  
**动机:** 后训练语言模型（PoLMs）在关键应用中常表现出过度自信的问题，这可能降低其可靠性。然而，针对个别下游任务标注数据的稀缺性成为校准PoLMs的一大障碍。

**方法:** 提出了一种名为Disagreement-Aware Confidence Alignment (DACA) 的新方法，该方法通过温度缩放技术对PLM和PoLM之间的置信度进行校准，并选择性地仅使用预测一致的样本来避免预测不一致导致的过度自信问题。

**结果:** 实验结果表明，DACA 方法有效地改善了校准性能，将开源和基于API的语言模型（如GPT-4o）在常见基准上的平均期望校准误差（ECE）提升了高达15.08%。

**结论:** DACA是一种有效的无监督方法，能够通过选择性使用一致样本来优化PoLMs的置信度校准参数，从而提升模型在实际应用中的可靠性和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Your+Pre-trained+LLM+is+Secretly+an+Unsupervised+Confidence+Calibrator，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16690，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16690&send_immediately=true&force_search=false)

**原文摘要:** Post-training of large language models is essential for adapting pre-trained
language models (PLMs) to align with human preferences and downstream tasks.
While PLMs typically exhibit well-calibrated confidence, post-trained language
models (PoLMs) often suffer from over-confidence, assigning high confidence to
both correct and incorrect outputs, which can undermine reliability in critical
applications. A major obstacle in calibrating PoLMs is the scarcity of labeled
data for individual downstream tasks. To address this, we propose
Disagreement-Aware Confidence Alignment (DACA), a novel unsupervised method to
optimize the parameters (e.g., temperature $\tau$) in post-hoc confidence
calibration. Our method is motivated by the under-confidence issue caused by
prediction disagreement between the PLM and PoLM while aligning their
confidence via temperature scaling. Theoretically, the PLM's confidence
underestimates PoLM's prediction accuracy on disagreement examples, causing a
larger $\tau$ and producing under-confident predictions. DACA mitigates this by
selectively using only agreement examples for calibration, effectively
decoupling the influence of disagreement. In this manner, our method avoids an
overly large $\tau$ in temperature scaling caused by disagreement examples,
improving calibration performance. Extensive experiments demonstrate the
effectiveness of our method, improving the average ECE of open-sourced and
API-based LLMs (e.g. GPT-4o) by up to 15.08$\%$ on common benchmarks.

</details>


### [86] [An Analysis of Concept Bottleneck Models: Measuring, Understanding, and Mitigating the Impact of Noisy Annotations](https://arxiv.org/abs/2505.16705)
*Seonghwan Park, Jueun Mun, Donghyun Oh, Namhoon Lee*

**主要类别:** cs.LG

**概要:** Concept bottleneck models (CBMs) are affected by noisy annotations in training, leading to impaired prediction performance and interpretability. This study identifies vulnerable concepts and proposes a two-stage framework involving sharpness-aware minimization and uncertainty-based correction to enhance robustness.


<details>
  <summary>更多</summary>
  
**动机:** Existing CBMs suffer from noisy annotations which impact their prediction performance, interpretability, and intervention effectiveness. There is a lack of understanding about how noise affects these models and how to mitigate its influence.

**方法:** The study introduces a two-stage framework: 1) sharpness-aware minimization during training to stabilize noise-sensitive concept learning; 2) ranking concepts by predictive entropy during inference to correct only the most uncertain ones using uncertainty as a proxy for susceptibility.

**结果:** Theoretical analysis and extensive experiments demonstrate that sharpness-aware training improves model robustness and uncertainty effectively identifies vulnerable concepts, thus preserving interpretability and resilience in the presence of noise.

**结论:** The proposed framework enhances the robustness of CBMs against noisy annotations while maintaining interpretability.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是An+Analysis+of+Concept+Bottleneck+Models%3A+Measuring%2C+Understanding%2C+and+Mitigating+the+Impact+of+Noisy+Annotations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16705，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16705&send_immediately=true&force_search=false)

**原文摘要:** Concept bottleneck models (CBMs) ensure interpretability by decomposing
predictions into human interpretable concepts. Yet the annotations used for
training CBMs that enable this transparency are often noisy, and the impact of
such corruption is not well understood. In this study, we present the first
systematic study of noise in CBMs and show that even moderate corruption
simultaneously impairs prediction performance, interpretability, and the
intervention effectiveness. Our analysis identifies a susceptible subset of
concepts whose accuracy declines far more than the average gap between noisy
and clean supervision and whose corruption accounts for most performance loss.
To mitigate this vulnerability we propose a two-stage framework. During
training, sharpness-aware minimization stabilizes the learning of
noise-sensitive concepts. During inference, where clean labels are unavailable,
we rank concepts by predictive entropy and correct only the most uncertain
ones, using uncertainty as a proxy for susceptibility. Theoretical analysis and
extensive ablations elucidate why sharpness-aware training confers robustness
and why uncertainty reliably identifies susceptible concepts, providing a
principled basis that preserves both interpretability and resilience in the
presence of noise.

</details>


### [87] [Training Long-Context LLMs Efficiently via Chunk-wise Optimization](https://arxiv.org/abs/2505.16710)
*Wenhao Li, Yuxin Zhang, Gen Luo, Daohai Yu, Rongrong Ji*

**主要类别:** cs.LG

**概要:** 提出了SeCO和SpaCO两种方法，分别扩展了模型的最大序列长度并加速了训练速度，为长上下文模型优化提供了新思路。


<details>
  <summary>更多</summary>
  
**动机:** 长上下文大语言模型（LLMs）尽管在文档处理方面表现出色，但其高昂的训练成本限制了定制化应用的可能性。因此需要一种更高效的训练方式来降低内存和计算开销。

**方法:** 提出了一种名为Sequential Chunk-wise Optimization (SeCO) 的内存高效训练范式，将长输入划分为小块，每块独立构建计算图并进行局部反向传播，从而减少内存占用。进一步引入Sparse Chunk-wise Optimization (SpaCO)，通过选择性地向特定块传播梯度并加入补偿因子，确保无偏梯度估计，同时使反向传播的计算成本与上下文长度解耦。

**结果:** 使用单个RTX 3090 GPU对8B模型进行LoRA微调时，SeCO将最大序列长度从1K扩展到16K tokens；而SpaCO在相同实验设置下比SeCO快3倍。

**结论:** SeCO和SpaCO作为轻量级训练包装器，提供了显著的实际好处，降低了长上下文模型的训练门槛，并为实际应用提供了更多可能性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Training+Long-Context+LLMs+Efficiently+via+Chunk-wise+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16710，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16710&send_immediately=true&force_search=false)

**原文摘要:** While long-context large language models (LLMs) exhibit remarkable document
processing capabilities, their prohibitively high training costs often hinder
customized applications. To mitigate this issue, we propose \textit{Sequential
Chunk-wise Optimization} (SeCO), a memory-efficient training paradigm that
partitions lengthy inputs into manageable chunks. Each chunk independently
constructs its computational graph and performs localized backpropagation,
ensuring that only one chunk's forward activations are stored in memory.
Building on SeCO, we further introduce \textit{Sparse Chunk-wise Optimization}
(SpaCO), which reduces computational overhead by selectively propagating
gradients to specific chunks and incorporates a carefully designed compensation
factor to ensure unbiased gradient estimation. SpaCO decouples the
computational cost of backpropagation from the context length, enabling
training time to gradually converge to inference time as sequences become
longer. Implemented as lightweight training wrappers, both SeCO and SpaCO offer
substantial practical benefits. For example, when fine-tuning an 8B model with
LoRA on a single RTX 3090 GPU, SeCO expands maximum sequence length from 1K to
16K tokens, while SpaCO demonstrates accelerated training speed -- achieving up
to 3x faster than SeCO under the same experimental setup. These innovations
provide new insights into optimizing long-context models, making them more
accessible for practical applications. We have open-sourced the code at
\href{https://github.com/wenhaoli-xmu/seco}{here}.

</details>


### [88] [Advancing Brainwave Modeling with a Codebook-Based Foundation Model](https://arxiv.org/abs/2505.16724)
*Konstantinos Barmpas, Na Lee, Yannis Panagakis, Dimitrios A. Adamos, Nikolaos Laskaris, Stefanos Zafeiriou*

**主要类别:** cs.LG

**概要:** 近期大规模预训练脑电图（EEG）模型的发展展现出巨大潜力，推动了脑机接口（BCI）和医疗健康应用的进步。然而，许多现有模型未能充分捕捉神经振荡的丰富信息内容，这从根本上限制了它们在多样化BCI任务中的性能和泛化能力。本文提出了一种改进的大型脑电基础模型LaBraM++，通过基于稳健信号处理原理的原则性改进，显著提升了在多种任务上的表现，优于其原始架构，并在与其他开源LBM的竞争中表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 尽管现有的大规模预训练EEG模型取得了成功，但它们在捕捉神经振荡的丰富信息内容方面存在不足，这一局限性源于次优的架构设计选择，限制了模型的表现和跨任务泛化能力。因此，需要一种改进的模型架构以提升性能。

**方法:** 引入了增强型大尺度脑电基础模型LaBraM++，该模型通过基于稳健信号处理原理的改进，优化了其表示能力，从而克服了传统模型在捕捉神经振荡信息方面的不足。

**结果:** LaBraM++在多种任务上展示了显著的提升，不仅超越了其原本的架构，还与其它开源的大规模脑电基础模型（LBM）相比具有竞争力，同时具备更高的训练效率。

**结论:** LaBraM++凭借其优越的性能和高效的训练过程，为未来LBMs的发展提供了一个强大的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Advancing+Brainwave+Modeling+with+a+Codebook-Based+Foundation+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16724，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16724&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in large-scale pre-trained Electroencephalogram (EEG) models
have shown great promise, driving progress in Brain-Computer Interfaces (BCIs)
and healthcare applications. However, despite their success, many existing
pre-trained models have struggled to fully capture the rich information content
of neural oscillations, a limitation that fundamentally constrains their
performance and generalizability across diverse BCI tasks. This limitation is
frequently rooted in suboptimal architectural design choices which constrain
their representational capacity. In this work, we introduce LaBraM++, an
enhanced Large Brainwave Foundation Model (LBM) that incorporates principled
improvements grounded in robust signal processing foundations. LaBraM++
demonstrates substantial gains across a variety of tasks, consistently
outperforming its originally-based architecture and achieving competitive
results when compared to other open-source LBMs. Its superior performance and
training efficiency highlight its potential as a strong foundation for future
advancements in LBMs.

</details>


### [89] [Masked Conditioning for Deep Generative Models](https://arxiv.org/abs/2505.16725)
*Phillip Mueller, Jannik Wiese, Sebastian Mueller, Lars Mikelsons*

**主要类别:** cs.LG

**概要:** 在工程领域，数据集通常较小、稀疏标记，并包含数值和分类条件。由于计算资源有限，生成模型难以应用于工程任务。本文提出了一种新的屏蔽条件方法，使生成模型能够处理稀疏、混合类型的数据。通过在训练过程中屏蔽条件，模拟推理时的稀疏条件，并探索不同的稀疏时间表。此外，引入了一种灵活的嵌入方式，可以处理分类和数值条件。我们将这种方法集成到高效的变分自编码器和潜在扩散模型中，并在两个与工程相关的2D点云和图像数据集上展示了该方法的适用性。最后，我们表明小型模型可以通过与大型预训练基础模型结合，提高生成质量，同时保持我们条件方案带来的可控性。


<details>
  <summary>更多</summary>
  
**动机:** 工程领域的数据集通常较小、标记稀疏且包含数值及分类条件。此外，实际应用中的计算资源通常有限，这阻碍了生成模型在工程任务中的应用。

**方法:** 提出了一种新的屏蔽条件方法，使生成模型能够处理稀疏、混合类型的数据。通过在训练过程中屏蔽条件来模拟推理时的稀疏条件，并探索不同的稀疏时间表。还引入了一种灵活的嵌入方式，可以处理分类和数值条件。将该方法集成到变分自编码器和潜在扩散模型中。

**结果:** 该方法在两个与工程相关的2D点云和图像数据集上表现出良好的适用性。小型模型可以通过与大型预训练基础模型结合，提高生成质量，同时保持条件方案带来的可控性。

**结论:** 提出的屏蔽条件方法成功使生成模型适应稀疏、混合类型的工程数据，并且通过与大型预训练模型结合，可以在有限数据和计算资源下实现高质量生成，同时保持可控性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Masked+Conditioning+for+Deep+Generative+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16725，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16725&send_immediately=true&force_search=false)

**原文摘要:** Datasets in engineering domains are often small, sparsely labeled, and
contain numerical as well as categorical conditions. Additionally.
computational resources are typically limited in practical applications which
hinders the adoption of generative models for engineering tasks. We introduce a
novel masked-conditioning approach, that enables generative models to work with
sparse, mixed-type data. We mask conditions during training to simulate sparse
conditions at inference time. For this purpose, we explore the use of various
sparsity schedules that show different strengths and weaknesses. In addition,
we introduce a flexible embedding that deals with categorical as well as
numerical conditions. We integrate our method into an efficient variational
autoencoder as well as a latent diffusion model and demonstrate the
applicability of our approach on two engineering-related datasets of 2D point
clouds and images. Finally, we show that small models trained on limited data
can be coupled with large pretrained foundation models to improve generation
quality while retaining the controllability induced by our conditioning scheme.

</details>


### [90] [Forward-only Diffusion Probabilistic Models](https://arxiv.org/abs/2505.16733)
*Ziwei Luo, Fredrik K. Gustafsson, Jens Sjölund, Thomas B. Schön*

**主要类别:** cs.LG

**概要:** This paper introduces a forward-only diffusion (FoD) approach for generative modelling which simplifies the process by eliminating the need for a coupled forward-backward diffusion scheme. Instead, FoD employs a single forward diffusion process based on a state-dependent linear stochastic differential equation with mean-reverting properties that guarantee convergence to clean data. FoD is analytically tractable and trained using a simple stochastic flow matching objective, making it efficient for various image generation tasks.


<details>
  <summary>更多</summary>
  
**动机:** The motivation behind this paper is to simplify the generative modeling process by eliminating the complexity of traditional diffusion models that rely on both forward and backward diffusion processes. By doing so, they aim to create a more efficient framework for data generation.

**方法:** The method involves developing a forward-only diffusion model based on a state-dependent linear stochastic differential equation that includes a mean-reverting term in both the drift and diffusion functions. This allows the model to converge to clean data and simulate a stochastic interpolation between source and target distributions.

**结果:** FoD achieves competitive performance on various image-conditioned and unconditional generation tasks, demonstrating its effectiveness in generative modeling despite its simplicity.

**结论:** The conclusion is that the proposed FoD model offers a simplified yet effective approach to generative modeling, achieving competitive results on different types of generation tasks.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Forward-only+Diffusion+Probabilistic+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16733，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16733&send_immediately=true&force_search=false)

**原文摘要:** This work presents a forward-only diffusion (FoD) approach for generative
modelling. In contrast to traditional diffusion models that rely on a coupled
forward-backward diffusion scheme, FoD directly learns data generation through
a single forward diffusion process, yielding a simple yet efficient generative
framework. The core of FoD is a state-dependent linear stochastic differential
equation that involves a mean-reverting term in both the drift and diffusion
functions. This mean-reversion property guarantees the convergence to clean
data, naturally simulating a stochastic interpolation between source and target
distributions. More importantly, FoD is analytically tractable and is trained
using a simple stochastic flow matching objective, enabling a few-step
non-Markov chain sampling during inference. The proposed FoD model, despite its
simplicity, achieves competitive performance on various image-conditioned
(e.g., image restoration) and unconditional generation tasks, demonstrating its
effectiveness in generative modelling. Our code is available at
https://github.com/Algolzw/FoD.

</details>


### [91] [Maximum Total Correlation Reinforcement Learning](https://arxiv.org/abs/2505.16734)
*Bang You, Puze Liu, Huaping Liu, Jan Peters, Oleg Arenz*

**主要类别:** cs.LG

**概要:** 通过最大化诱导轨迹内的总相关性来促进简单行为，提出一种优化策略和状态表示的算法，在模拟机器人环境中表现出优越的鲁棒性和性能。


<details>
  <summary>更多</summary>
  
**动机:** 在强化学习中，简单性是一个强有力的归纳偏置，正则化、数据增强和稀疏奖励函数等技术都是为了使策略、表示和目标更简单，从而提高泛化能力和鲁棒性。本文补充了这些技术，研究如何在整个过程中促进简单行为。

**方法:** 引入对强化学习问题的修改，以额外最大化诱导轨迹内的总相关性，并提出一种基于下界近似的实用算法，优化所有模型，包括策略和状态表示。

**结果:** 在模拟机器人环境中，该方法自然生成诱导周期性和可压缩轨迹的策略，相比基线方法，表现出对噪声和动态变化的优越鲁棒性，同时在原始任务中也提高了性能。

**结论:** 通过最大化轨迹内的总相关性，可以生成更简单、更鲁棒的行为策略，这种策略在面对环境变化时表现更好，同时在原始任务上也有更好的性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Maximum+Total+Correlation+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16734，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16734&send_immediately=true&force_search=false)

**原文摘要:** Simplicity is a powerful inductive bias. In reinforcement learning,
regularization is used for simpler policies, data augmentation for simpler
representations, and sparse reward functions for simpler objectives, all that,
with the underlying motivation to increase generalizability and robustness by
focusing on the essentials. Supplementary to these techniques, we investigate
how to promote simple behavior throughout the episode. To that end, we
introduce a modification of the reinforcement learning problem that
additionally maximizes the total correlation within the induced trajectories.
We propose a practical algorithm that optimizes all models, including policy
and state representation, based on a lower-bound approximation. In simulated
robot environments, our method naturally generates policies that induce
periodic and compressible trajectories, and that exhibit superior robustness to
noise and changes in dynamics compared to baseline methods, while also
improving performance in the original tasks.

</details>


### [92] [Backward Oversmoothing: why is it hard to train deep Graph Neural Networks?](https://arxiv.org/abs/2505.16736)
*Nicolas Keriven*

**主要类别:** cs.LG

**概要:** 该论文探讨了图神经网络（GNNs）中的过平滑问题，并从优化的角度分析了反向传播中的过平滑现象。作者指出，由于反向过平滑，GNN存在许多虚假的驻点，这导致在损失仍然较高时梯度接近零。此外，这种现象主要出现在深层GNN中，而非多层感知器（MLP）。


<details>
  <summary>更多</summary>
  
**动机:** 过平滑是GNN的一个主要限制，尽管理论上可以通过调整权重避免过平滑，但实际上并未发生。因此，需要从优化的角度重新审视这一问题。

**方法:** 作者分析了反向传播过程中的过平滑现象，即用于计算梯度的反向传播误差也受到过平滑的影响。通过非线性激活函数，研究了前向和反向过平滑之间的相互作用。并证明了由于反向过平滑，只要最后一层被训练，整个GNN就处于一个驻点。

**结果:** 发现了深层GNN中由于反向过平滑而导致的虚假驻点现象，并展示了梯度接近零而损失仍高的区域。此外，证明了这种现象仅限于GNN，而不适用于MLP。

**结论:** 本研究揭示了GNN优化过程中存在的独特挑战，并为理解GNN特定的优化景观提供了更全面的认识。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Backward+Oversmoothing%3A+why+is+it+hard+to+train+deep+Graph+Neural+Networks%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16736，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16736&send_immediately=true&force_search=false)

**原文摘要:** Oversmoothing has long been identified as a major limitation of Graph Neural
Networks (GNNs): input node features are smoothed at each layer and converge to
a non-informative representation, if the weights of the GNN are sufficiently
bounded. This assumption is crucial: if, on the contrary, the weights are
sufficiently large, then oversmoothing may not happen. Theoretically, GNN could
thus learn to not oversmooth. However it does not really happen in practice,
which prompts us to examine oversmoothing from an optimization point of view.
In this paper, we analyze backward oversmoothing, that is, the notion that
backpropagated errors used to compute gradients are also subject to
oversmoothing from output to input. With non-linear activation functions, we
outline the key role of the interaction between forward and backward smoothing.
Moreover, we show that, due to backward oversmoothing, GNNs provably exhibit
many spurious stationary points: as soon as the last layer is trained, the
whole GNN is at a stationary point. As a result, we can exhibit regions where
gradients are near-zero while the loss stays high. The proof relies on the fact
that, unlike forward oversmoothing, backward errors are subjected to a linear
oversmoothing even in the presence of non-linear activation function, such that
the average of the output error plays a key role. Additionally, we show that
this phenomenon is specific to deep GNNs, and exhibit counter-example
Multi-Layer Perceptron. This paper is a step toward a more complete
comprehension of the optimization landscape specific to GNNs.

</details>


### [93] [Mitigating Fine-tuning Risks in LLMs via Safety-Aware Probing Optimization](https://arxiv.org/abs/2505.16737)
*Chengcan Wu, Zhixin Zhang, Zeming Wei, Yihao Zhang, Meng Sun*

**主要类别:** cs.LG

**概要:** 大型语言模型（LLMs）尽管在预训练阶段采用了安全对齐技术，但微调时仍可能因对抗性或良性数据导致安全性下降。本文提出了一种新的优化框架——安全感知探测（SAP），通过在梯度传播过程中加入安全探测机制，识别潜在风险方向，从而缓解安全性下降问题。实验表明，SAP能有效降低有害内容生成，并保持与标准微调方法相当的测试损失。


<details>
  <summary>更多</summary>
  
**动机:** 尽管在预训练阶段实施了安全对齐技术，但微调LLMs时，即使是非有害数据也可能导致安全性下降。因此，需要重新审视并解决这一问题，确保微调后的模型仍然安全可靠。

**方法:** 提出了一种名为安全感知探测（SAP）的优化框架，该框架通过将安全探测模块嵌入到梯度传播过程中，识别可能导致安全性下降的风险方向，从而减少微调过程中的安全性退化。

**结果:** 实验结果表明，SAP能够显著降低微调后模型生成有害内容的可能性，同时其测试损失与标准微调方法相当。

**结论:** SAP框架为缓解LLMs微调过程中的安全性下降提供了一种有效解决方案，能够在提升任务性能的同时，成功保留模型的安全性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mitigating+Fine-tuning+Risks+in+LLMs+via+Safety-Aware+Probing+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16737，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16737&send_immediately=true&force_search=false)

**原文摘要:** The significant progress of large language models (LLMs) has led to
remarkable achievements across numerous applications. However, their ability to
generate harmful content has sparked substantial safety concerns. Despite the
implementation of safety alignment techniques during the pre-training phase,
recent research indicates that fine-tuning LLMs on adversarial or even benign
data can inadvertently compromise their safety. In this paper, we re-examine
the fundamental issue of why fine-tuning on non-harmful data still results in
safety degradation. We introduce a safety-aware probing (SAP) optimization
framework designed to mitigate the safety risks of fine-tuning LLMs.
Specifically, SAP incorporates a safety-aware probe into the gradient
propagation process, mitigating the model's risk of safety degradation by
identifying potential pitfalls in gradient directions, thereby enhancing
task-specific performance while successfully preserving model safety. Our
extensive experimental results demonstrate that SAP effectively reduces
harmfulness below the original fine-tuned model and achieves comparable test
loss to standard fine-tuning methods. Our code is available at
https://github.com/ChengcanWu/SAP.

</details>


### [94] [Learning Flexible Forward Trajectories for Masked Molecular Diffusion](https://arxiv.org/abs/2505.16790)
*Hyunjin Seo, Taewon Kim, Sihyun Yu, SungSoo Ahn*

**主要类别:** cs.LG

**概要:** 探索了Masked扩散模型（MDMs）在分子生成中的潜力，发现直接应用标准MDMs会导致性能显著下降。问题的根源是状态冲突问题，即不同分子的前向扩散会塌缩到同一状态，导致反向扩散过程无法学习。为了解决此问题，提出了一种新的方法——Masked Element-wise Learnable Diffusion（MELD），通过参数化噪声调度网络为每个图元素分配不同的腐蚀率，从而避免分子图之间的冲突。实验表明，MELD显著提高了分子生成质量，并在条件生成任务中实现了最先进的属性对齐效果。


<details>
  <summary>更多</summary>
  
**动机:** 尽管Masked扩散模型（MDMs）在离散数据建模方面取得了显著进展，但其在分子生成领域的潜力尚未被充分挖掘。研究者试图探索MDMs在分子生成中的表现，但发现直接应用标准MDMs会导致性能严重下降。

**方法:** 提出了一种名为Masked Element-wise Learnable Diffusion（MELD）的方法，该方法通过参数化噪声调度网络为每个图元素（如原子和键）分配不同的腐蚀率，以避免不同分子图之间的冲突。具体来说，MELD协调了每个元素的腐蚀轨迹，从而解决了状态冲突问题。

**结果:** 在多个分子基准测试中，MELD显著提高了整体生成质量。例如，在ZINC250K数据集上，化学有效性从15%提高到了93%。此外，MELD在条件生成任务中实现了最先进的属性对齐效果。

**结论:** MELD通过解决状态冲突问题显著提高了分子生成的质量，并展示了在条件生成任务中的优越性能。这表明，针对分子图特性的方法设计对于提升生成模型的性能至关重要。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+Flexible+Forward+Trajectories+for+Masked+Molecular+Diffusion，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16790，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16790&send_immediately=true&force_search=false)

**原文摘要:** Masked diffusion models (MDMs) have achieved notable progress in modeling
discrete data, while their potential in molecular generation remains
underexplored. In this work, we explore their potential and introduce the
surprising result that naively applying standards MDMs severely degrades the
performance. We identify the critical cause of this issue as a state-clashing
problem-where the forward diffusion of distinct molecules collapse into a
common state, resulting in a mixture of reconstruction targets that cannot be
learned using typical reverse diffusion process with unimodal predictions. To
mitigate this, we propose Masked Element-wise Learnable Diffusion (MELD) that
orchestrates per-element corruption trajectories to avoid collision between
distinct molecular graphs. This is achieved through a parameterized noise
scheduling network that assigns distinct corruption rates to individual graph
elements, i.e., atoms and bonds. Extensive experiments on diverse molecular
benchmarks reveal that MELD markedly enhances overall generation quality
compared to element-agnostic noise scheduling, increasing the chemical validity
of vanilla MDMs on ZINC250K from 15% to 93%, Furthermore, it achieves
state-of-the-art property alignment in conditional generation tasks.

</details>


### [95] [Cohort-Based Active Modality Acquisition](https://arxiv.org/abs/2505.16791)
*Tillmann Rheude, Roland Eils, Benjamin Wild*

**主要类别:** cs.LG

**概要:** 本论文提出了一种名为Cohort-based Active Modality Acquisition（CAMA）的新方法，用于在资源有限的情况下决定哪些样本应优先获取额外的模态数据。该方法结合生成式填补和判别建模来估计获取缺失模态的预期收益，并引入上限启发式方法作为性能基准。实验表明，与仅依赖单模态信息、熵引导或随机选择的方法相比，基于填补的策略更有效地指导新样本的获取。


<details>
  <summary>更多</summary>
  
**动机:** 现实世界中的机器学习应用常常需要整合来自多个模态的数据以进行稳健预测。然而，在许多实际情况下，并非所有样本的所有模态都可用，且获取额外模态可能成本高昂。这提出了一个问题：当资源有限时，应该优先为哪些样本获取额外的模态数据？尽管已有工作探索了个体级别的获取策略和训练时间的主动学习范式，但在测试时间和基于队列的获取策略方面仍存在研究空白。

**方法:** 论文引入了队列基础主动模态获取（CAMA），一种新的测试时间设置，用于形式化选择哪些样本应接收额外模态的问题。通过结合生成式填补和判别建模，推导出获取策略，以根据常见评估指标估计获取缺失模态的预期好处。此外，还引入了提供性能上限的启发式方法，用作获取策略的基准。

**结果:** 在常见的多模态数据集上的实验表明，所提出的基于填补的策略相较于那些仅依赖单模态信息、熵引导和随机选择的方法，能够更有效地指导新样本的获取。

**结论:** 我们的工作为优化队列级别的模态获取提供了一种有效解决方案，使得在受限环境中更好地利用资源成为可能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Cohort-Based+Active+Modality+Acquisition，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16791，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16791&send_immediately=true&force_search=false)

**原文摘要:** Real-world machine learning applications often involve data from multiple
modalities that must be integrated effectively to make robust predictions.
However, in many practical settings, not all modalities are available for every
sample, and acquiring additional modalities can be costly. This raises the
question: which samples should be prioritized for additional modality
acquisition when resources are limited? While prior work has explored
individual-level acquisition strategies and training-time active learning
paradigms, test-time and cohort-based acquisition remain underexplored despite
their importance in many real-world settings. We introduce Cohort-based Active
Modality Acquisition (CAMA), a novel test-time setting to formalize the
challenge of selecting which samples should receive additional modalities. We
derive acquisition strategies that leverage a combination of generative
imputation and discriminative modeling to estimate the expected benefit of
acquiring missing modalities based on common evaluation metrics. We also
introduce upper-bound heuristics that provide performance ceilings to benchmark
acquisition strategies. Experiments on common multimodal datasets demonstrate
that our proposed imputation-based strategies can more effectively guide the
acquisition of new samples in comparison to those relying solely on unimodal
information, entropy guidance, and random selections. Our work provides an
effective solution for optimizing modality acquisition at the cohort level,
enabling better utilization of resources in constrained settings.

</details>


### [96] [Revenue Optimization with Price-Sensitive and Interdependent Demand](https://arxiv.org/abs/2505.16748)
*Julien Laasri, Marc Revol*

**主要类别:** cs.LG

**概要:** The paper focuses on optimizing pricing and quantity decisions to maximize revenue for airline ticket sales on direct flights over specific time periods, assuming demand data and price options are predetermined.


<details>
  <summary>更多</summary>
  
**动机:** To address the Revenue Management problem by focusing on pricing and quantity decisions to optimize revenue for airline ticket sales.

**方法:** Using predefined demand data and price options, the method involves selecting optimal prices from a set of predetermined options to maximize revenue.

**结果:** The result is an optimized approach to setting prices for each product to achieve maximum revenue for a direct flight.

**结论:** Revenue Management through pricing and quantity optimization can effectively maximize an organization's revenue in the context of airline ticket sales.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Revenue+Optimization+with+Price-Sensitive+and+Interdependent+Demand，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16748，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16748&send_immediately=true&force_search=false)

**原文摘要:** As Kalyan T. Talluri and Garrett J. Van Ryzin describe in their work [3],
Revenue Management aims to maximize an organization's revenue by considering
three types of decision categories: structural, pricing, and quantity. In this
document, our primary focus will be on decisions related to pricing and
quantity for the sale of airline tickets on a direct flight over a certain
number of time periods. More specifically, we will only focus on the
optimization aspect of this problem. We will assume the demand data to be
given, since Air France estimates it beforehand using real data. Similarly, we
assume all price options to be predetermined by Air France's algorithms and
verified by their analysts. Our objective will be to maximize the revenue of a
direct flight by choosing the prices for each product from the predefined set
of options.
  --
  Comme d\'ecrit par Kalyan T. Talluri et Garrett J. Van Ryzin dans leur
ouvrage [3], le Revenue Management consiste en la maximisation du revenu d'un
organisme \`a partir de trois types de cat\'egories de d\'ecision :
structurelles, prix et quantit\'e. Dans ce document, nous nous int\'eresserons
principalement aux d\'ecisions de type prix et quantit\'e pour la vente de
billets d'avion sur un vol direct au cours d'un certain nombre de pas de temps.
Plus pr\'ecis\'ement, nous nous situerons dans la partie optimisation du
probl\`eme. Nous prendrons ainsi les donn\'ees de demande comme acquises, car
elles sont estim\'ees au pr\'ealable par Air France \`a partir des donn\'ees
r\'eelles. De m\^eme, pour chaque produit que l'on cherchera \`a vendre, on
nous impose en amont les prix possibles que l'on a droit d'utiliser et qui se
basent sur des algorithmes d'Air France dont les r\'esultats sont v\'erifi\'es
par des analystes. Notre but sera alors de maximiser le revenu d'un vol direct
en choisissant les prix de chaque produit parmi ceux impos\'es.

</details>


### [97] [A modular framework for automated evaluation of procedural content generation in serious games with deep reinforcement learning agents](https://arxiv.org/abs/2505.16801)
*Eleftherios Kalafatis, Konstantinos Mitsis, Konstantia Zarkogianni, Maria Athanasiou, Konstantina Nikita*

**主要类别:** cs.LG

**概要:** 严肃游戏(SGs)正在将过程内容生成(PCG)纳入开发流程，以提供个性化和增强的玩家体验。然而，评估PCG技术在SGs中的影响仍然具有挑战性。本研究提出了一种结合深度强化学习(DRL)游戏测试代理人的自动化评估方法，并通过一个包含三种不同NPC创建版本的卡牌游戏来验证该框架。结果表明，在版本2和3上训练的DRL代理人在胜率和训练时间上优于版本1上的代理人。


<details>
  <summary>更多</summary>
  
**动机:** 过程内容生成（PCG）在严肃游戏中越来越受到关注，因为它可以提供个性化的玩家体验。然而，目前缺乏有效的框架来评估PCG技术对严肃游戏的影响。

**方法:** 研究提出了一种结合深度强化学习（DRL）游戏测试代理人的自动化评估方法。通过使用一个包含三种不同NPC创建版本（随机创建、遗传算法）的卡牌游戏来验证该框架的有效性。

**结果:** 结果显示，在版本2和3上训练的DRL代理人在胜率和训练时间上优于版本1上的代理人。具体而言，版本2和3的胜率达到97%，而版本1仅为94%。

**结论:** 提出的框架能够生成有意义的数据，用于评估严肃游戏中的过程生成内容的效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+modular+framework+for+automated+evaluation+of+procedural+content+generation+in+serious+games+with+deep+reinforcement+learning+agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16801，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16801&send_immediately=true&force_search=false)

**原文摘要:** Serious Games (SGs) are nowadays shifting focus to include procedural content
generation (PCG) in the development process as a means of offering personalized
and enhanced player experience. However, the development of a framework to
assess the impact of PCG techniques when integrated into SGs remains
particularly challenging. This study proposes a methodology for automated
evaluation of PCG integration in SGs, incorporating deep reinforcement learning
(DRL) game testing agents. To validate the proposed framework, a previously
introduced SG featuring card game mechanics and incorporating three different
versions of PCG for nonplayer character (NPC) creation has been deployed.
Version 1 features random NPC creation, while versions 2 and 3 utilize a
genetic algorithm approach. These versions are used to test the impact of
different dynamic SG environments on the proposed framework's agents. The
obtained results highlight the superiority of the DRL game testing agents
trained on Versions 2 and 3 over those trained on Version 1 in terms of win
rate (i.e. number of wins per played games) and training time. More
specifically, within the execution of a test emulating regular gameplay, both
Versions 2 and 3 peaked at a 97% win rate and achieved statistically
significant higher (p=0009) win rates compared to those achieved in Version 1
that peaked at 94%. Overall, results advocate towards the proposed framework's
capability to produce meaningful data for the evaluation of procedurally
generated content in SGs.

</details>


### [98] [PyTupli: A Scalable Infrastructure for Collaborative Offline Reinforcement Learning Projects](https://arxiv.org/abs/2505.16754)
*Hannah Markgraf, Michael Eichelbeck, Daria Cappey, Selin Demirtürk, Yara Schattschneider, Matthias Althoff*

**主要类别:** cs.LG

**概要:** Offline RL研究中，管理、创建和分享数据集存在挑战。本文介绍PyTupli工具，解决这些问题，促进更协作、可重现和可扩展的离线RL研究。


<details>
  <summary>更多</summary>
  
**动机:** 尽管有许多开源库提供强大的离线RL算法实现，但管理和共享这些所需的基于经验元组的数据集缺乏标准化和可扩展的解决方案。这限制了针对新问题或用户自定义基准的离线RL研究进展。

**方法:** 提出PyTupli工具，包括一个轻量级客户端库，用于上传和检索基准环境及其对应的数据集；支持细粒度过滤，以构建高质量的任务特定数据集；以及一个容器化的服务器组件，提供身份验证、访问控制和自动证书配置，确保安全使用。

**结果:** PyTupli简化了离线RL中基准环境和数据集的创建、存储和分发过程，为研究人员提供了高效、安全的数据管理解决方案。

**结论:** 通过解决数据集基础设施中的关键障碍，PyTupli促进了更协作、可重现和可扩展的离线强化学习研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PyTupli%3A+A+Scalable+Infrastructure+for+Collaborative+Offline+Reinforcement+Learning+Projects，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16754，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16754&send_immediately=true&force_search=false)

**原文摘要:** Offline reinforcement learning (RL) has gained traction as a powerful
paradigm for learning control policies from pre-collected data, eliminating the
need for costly or risky online interactions. While many open-source libraries
offer robust implementations of offline RL algorithms, they all rely on
datasets composed of experience tuples consisting of state, action, next state,
and reward. Managing, curating, and distributing such datasets requires
suitable infrastructure. Although static datasets exist for established
benchmark problems, no standardized or scalable solution supports developing
and sharing datasets for novel or user-defined benchmarks. To address this gap,
we introduce PyTupli, a Python-based tool to streamline the creation, storage,
and dissemination of benchmark environments and their corresponding tuple
datasets. PyTupli includes a lightweight client library with defined interfaces
for uploading and retrieving benchmarks and data. It supports fine-grained
filtering at both the episode and tuple level, allowing researchers to curate
high-quality, task-specific datasets. A containerized server component enables
production-ready deployment with authentication, access control, and automated
certificate provisioning for secure use. By addressing key barriers in dataset
infrastructure, PyTupli facilitates more collaborative, reproducible, and
scalable offline RL research.

</details>


### [99] [Efficient Online RL Fine Tuning with Offline Pre-trained Policy Only](https://arxiv.org/abs/2505.16856)
*Wei Xiao, Jiacheng Liu, Zifeng Zhuang, Runze Suo, Shangke Lyu, Donglin Wang*

**主要类别:** cs.LG

**概要:** 通过仅使用离线预训练策略，PORL方法在在线强化学习微调中表现出色，并为直接微调行为克隆（BC）策略开辟了新途径。


<details>
  <summary>更多</summary>
  
**动机:** 现有的在线强化学习微调方法依赖于离线预训练的Q函数，但这些Q函数由于保守性限制了进一步探索，并且在仅有预训练策略可用而没有预训练Q函数的情况下不适用。

**方法:** 提出PORL方法，仅使用离线预训练策略进行高效的在线强化学习微调，通过在线阶段从头快速初始化Q函数以避免悲观估计。

**结果:** PORL方法不仅与先进的离线到在线RL算法和利用数据或策略先验的在线RL方法具有竞争力，还成功地实现了对行为克隆策略的直接微调。

**结论:** PORL提供了一种新的方法来解决当前在线强化学习微调中的挑战，特别是对于仅有预训练策略可用的情况。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Efficient+Online+RL+Fine+Tuning+with+Offline+Pre-trained+Policy+Only，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16856，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16856&send_immediately=true&force_search=false)

**原文摘要:** Improving the performance of pre-trained policies through online
reinforcement learning (RL) is a critical yet challenging topic. Existing
online RL fine-tuning methods require continued training with offline
pretrained Q-functions for stability and performance. However, these offline
pretrained Q-functions commonly underestimate state-action pairs beyond the
offline dataset due to the conservatism in most offline RL methods, which
hinders further exploration when transitioning from the offline to the online
setting. Additionally, this requirement limits their applicability in scenarios
where only pre-trained policies are available but pre-trained Q-functions are
absent, such as in imitation learning (IL) pre-training. To address these
challenges, we propose a method for efficient online RL fine-tuning using
solely the offline pre-trained policy, eliminating reliance on pre-trained
Q-functions. We introduce PORL (Policy-Only Reinforcement Learning
Fine-Tuning), which rapidly initializes the Q-function from scratch during the
online phase to avoid detrimental pessimism. Our method not only achieves
competitive performance with advanced offline-to-online RL algorithms and
online RL approaches that leverage data or policies prior, but also pioneers a
new path for directly fine-tuning behavior cloning (BC) policies.

</details>


### [100] [Multi-Output Gaussian Processes for Graph-Structured Data](https://arxiv.org/abs/2505.16755)
*Ayano Nakai-Kasai, Tadashi Wadayama*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种基于多输出高斯过程（MOGP）的图结构数据回归方法，能够捕捉顶点间及关联数据间的相关性。该方法具有高度表达能力，可应用于多种数据配置和场景，并通过计算机实验验证了其扩展性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有的高斯过程在处理图结构数据时受到数据配置、模型选择和推理场景的限制，需要一种更灵活的方法来克服这些限制并提高表达能力。

**方法:** 提出了基于MOGP的图结构数据回归方法，利用MOGP定义构建公式以捕捉顶点间和关联数据间的相关性，同时允许灵活设计核函数。

**结果:** 通过使用合成和真实数据的计算机实验，证明了所提出的公式在性能扩展方面的有效性。

**结论:** 所提出的方法不仅涵盖了现有的图结构数据高斯过程方法作为特殊情况，还能够移除现有方法对数据配置、模型选择和推理场景的限制，展现出广泛的应用潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Multi-Output+Gaussian+Processes+for+Graph-Structured+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16755，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16755&send_immediately=true&force_search=false)

**原文摘要:** Graph-structured data is a type of data to be obtained associated with a
graph structure where vertices and edges describe some kind of data
correlation. This paper proposes a regression method on graph-structured data,
which is based on multi-output Gaussian processes (MOGP), to capture both the
correlation between vertices and the correlation between associated data. The
proposed formulation is built on the definition of MOGP. This allows it to be
applied to a wide range of data configurations and scenarios. Moreover, it has
high expressive capability due to its flexibility in kernel design. It includes
existing methods of Gaussian processes for graph-structured data as special
cases and is possible to remove restrictions on data configurations, model
selection, and inference scenarios in the existing methods. The performance of
extensions achievable by the proposed formulation is evaluated through computer
experiments with synthetic and real data.

</details>


### [101] [GCAL: Adapting Graph Models to Evolving Domain Shifts](https://arxiv.org/abs/2505.16860)
*Ziyue Qiao, Qianyi Cai, Hao Dong, Jiawei Gu, Pengyang Wang, Meng Xiao, Xiao Luo, Hui Xiong*

**主要类别:** cs.LG

**概要:** 本文提出了一种新的图领域自适应方法GCAL，通过双层优化策略，在处理连续领域变化和避免灾难性遗忘方面表现出色。


<details>
  <summary>更多</summary>
  
**动机:** 现有的图领域自适应方法局限于单步自适应，无法有效处理连续领域的变化并容易发生灾难性遗忘。

**方法:** GCAL采用双层优化策略，包括“适应”阶段和“生成记忆”阶段。“适应”阶段通过信息最大化方法微调模型以适应新图域，并重新调整过去的记忆以减少遗忘；“生成记忆”阶段利用信息瓶颈理论的理论下界，通过变分记忆图生成模块将原始图浓缩成记忆。

**结果:** 广泛的实验评估表明，GCAL在适应性和知识保留方面显著优于现有方法。

**结论:** GCAL方法提高了模型在不同图域上的可持续性和适应性，为处理连续领域变化提供了有效解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GCAL%3A+Adapting+Graph+Models+to+Evolving+Domain+Shifts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16860，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16860&send_immediately=true&force_search=false)

**原文摘要:** This paper addresses the challenge of graph domain adaptation on evolving,
multiple out-of-distribution (OOD) graphs. Conventional graph domain adaptation
methods are confined to single-step adaptation, making them ineffective in
handling continuous domain shifts and prone to catastrophic forgetting. This
paper introduces the Graph Continual Adaptive Learning (GCAL) method, designed
to enhance model sustainability and adaptability across various graph domains.
GCAL employs a bilevel optimization strategy. The "adapt" phase uses an
information maximization approach to fine-tune the model with new graph domains
while re-adapting past memories to mitigate forgetting. Concurrently, the
"generate memory" phase, guided by a theoretical lower bound derived from
information bottleneck theory, involves a variational memory graph generation
module to condense original graphs into memories. Extensive experimental
evaluations demonstrate that GCAL substantially outperforms existing methods in
terms of adaptability and knowledge retention.

</details>


### [102] [FlowMixer: A Constrained Neural Architecture for Interpretable Spatiotemporal Forecasting](https://arxiv.org/abs/2505.16786)
*Fares B. Mehouachi, Saif Eddin Jabari*

**主要类别:** cs.LG

**概要:** FlowMixer是一种新的神经架构，利用受约束的矩阵操作来建模结构化的时空模式。它结合了非负矩阵混合层和可逆映射框架，在混合前后应用变换及其逆变换。这种设计保持形状不变，通过Kronecker-Koopman特征模式框架连接统计学习与动力系统理论，提供可解释的时空模式，并允许在不重新训练的情况下直接代数操作预测范围。实验表明，FlowMixer具有强大的长时预测能力，同时有效建模物理现象如混沌吸引子和湍流。这说明架构约束可以同时提高预测性能和数学可解释性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的神经网络架构在处理复杂时空模式（例如混沌吸引子和湍流）时可能缺乏足够的预测能力和可解释性。因此需要一种新方法来增强模型对这些现象的理解和预测能力，同时保持数学上的可解释性。

**方法:** FlowMixer使用非负矩阵混合层和可逆映射框架，先进行变换再混合，之后再应用其逆变换。这种方法通过Kronecker-Koopman特征模式框架将统计学习与动力系统理论相结合。

**结果:** 广泛的实验证明了FlowMixer在不同领域中的强大长时预测能力，尤其在建模物理现象（如混沌吸引子和湍流）方面表现出色。

**结论:** 引入的FlowMixer架构通过施加特定约束条件，不仅提高了预测性能，还增强了模型的数学可解释性，为神经预测系统的改进提供了新方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FlowMixer%3A+A+Constrained+Neural+Architecture+for+Interpretable+Spatiotemporal+Forecasting，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16786，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16786&send_immediately=true&force_search=false)

**原文摘要:** We introduce FlowMixer, a neural architecture that leverages constrained
matrix operations to model structured spatiotemporal patterns. At its core,
FlowMixer incorporates non-negative matrix mixing layers within a reversible
mapping framework-applying transforms before mixing and their inverses
afterward. This shape-preserving design enables a Kronecker-Koopman eigenmode
framework that bridges statistical learning with dynamical systems theory,
providing interpretable spatiotemporal patterns and facilitating direct
algebraic manipulation of prediction horizons without retraining. Extensive
experiments across diverse domains demonstrate FlowMixer's robust long-horizon
forecasting capabilities while effectively modeling physical phenomena such as
chaotic attractors and turbulent flows. These results suggest that
architectural constraints can simultaneously enhance predictive performance and
mathematical interpretability in neural forecasting systems.

</details>


### [103] [Structure-Aligned Protein Language Model](https://arxiv.org/abs/2505.16896)
*Can Chen, David Heurtel-Depeiges, Robert M. Vernon, Christopher James Langmead, Yoshua Bengio, Quentin Fournier*

**主要类别:** cs.LG

**概要:** 通过将预训练的蛋白质图神经网络(pGNNs)中的结构见解整合到蛋白质语言模型(pLMs)中，提出了一种双任务框架。该框架结合了蛋白质间的结构知识和蛋白质内的结构知识，并引入了一个残差损失选择模块以提高学习效果。应用此方法改进了ESM2和AMPLIFY模型，在多个任务上取得了显著的性能提升。


<details>
  <summary>更多</summary>
  
**动机:** 现有的蛋白质语言模型在各种下游任务中表现出色，但缺乏许多生物学应用所需的结构知识。为了解决这一问题，需要将结构知识整合到pLMs中。

**方法:** 1. 使用潜在级别的对比学习任务，将pGNNs中的结构见解整合到pLMs中。
2. 引入物理级别任务，通过优化pLMs预测结构标记来注入蛋白质内的结构知识。
3. 开发了一个残差损失选择模块，利用高质量结构训练的小型模型来选择可靠且具有挑战性的残差损失供pLM学习。
4. 将该方法应用于ESM2和AMPLIFY模型，生成SaESM2和SaAMPLIFY模型。

**结果:** 在多种任务上，包括ESM2接触预测，性能提升了12.7%。

**结论:** 通过将结构知识整合到pLMs中，可以显著提高其在生物相关任务上的性能。所提出的框架和模型将在Hugging Face上发布，供研究社区使用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Structure-Aligned+Protein+Language+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16896，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16896&send_immediately=true&force_search=false)

**原文摘要:** Protein language models (pLMs) pre-trained on vast protein sequence databases
excel at various downstream tasks but lack the structural knowledge essential
for many biological applications. To address this, we integrate structural
insights from pre-trained protein graph neural networks (pGNNs) into pLMs
through a latent-level contrastive learning task. This task aligns residue
representations from pLMs with those from pGNNs across multiple proteins,
enriching pLMs with inter-protein structural knowledge. Additionally, we
incorporate a physical-level task that infuses intra-protein structural
knowledge by optimizing pLMs to predict structural tokens. The proposed
dual-task framework effectively incorporates both inter-protein and
intra-protein structural knowledge into pLMs. Given the variability in the
quality of protein structures in PDB, we further introduce a residue loss
selection module, which uses a small model trained on high-quality structures
to select reliable yet challenging residue losses for the pLM to learn.
Applying our structure alignment method to the state-of-the-art ESM2 and
AMPLIFY results in notable performance gains across a wide range of tasks,
including a 12.7% increase in ESM2 contact prediction. The data, code, and
resulting SaESM2 and SaAMPLIFY models will be released on Hugging Face.

</details>


### [104] [The Polar Express: Optimal Matrix Sign Methods and Their Application to the Muon Algorithm](https://arxiv.org/abs/2505.16932)
*Noah Amsel, David Persson, Christopher Musco, Robert Gower*

**主要类别:** cs.LG

**概要:** 本论文提出了一种名为Polar Express的GPU友好的极分解计算算法，适用于深度学习中的优化框架。该算法通过解决极小化优化问题来调整多项式更新规则，并具有强最差情况最优性保证，确保快速收敛和数值稳定性。实验表明，使用Polar Express可以改善如GPT-2等大规模模型的验证损失。


<details>
  <summary>更多</summary>
  
**动机:** 在深度学习中，极分解计算作为Muon优化框架中的重要子程序，需要高效且与GPU兼容的方法，但传统数值分析方法（如Newton-Schulz或基于有理函数的方法）无法满足这些需求，因为它们要么初始收敛慢，要么依赖于QR分解或矩阵求逆等操作。

**方法:** Polar Express算法仅使用矩阵-矩阵乘法，使其与GPU兼容。它通过在每次迭代中解决一个极小化优化问题来调整多项式更新规则，并证明了其具有强最差情况最优性保证，从而确保快速早期收敛和渐进快速收敛。此外，该算法还解决了有限精度问题，使其在bfloat16中保持稳定。

**结果:** 在Muon优化框架中应用Polar Express后，在包括GPT-2在内的大规模模型上，验证损失得到了一致的改进，并且在不同学习率下均优于近期的其他方法。

**结论:** Polar Express是一种高效的、GPU友好的极分解计算方法，特别适合深度学习中的优化任务。它不仅具备理论上的强收敛性保证，而且在实践中表现出良好的数值稳定性和性能提升。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是The+Polar+Express%3A+Optimal+Matrix+Sign+Methods+and+Their+Application+to+the+Muon+Algorithm，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16932，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16932&send_immediately=true&force_search=false)

**原文摘要:** Computing the polar decomposition and the related matrix sign function, has
been a well-studied problem in numerical analysis for decades. More recently,
it has emerged as an important subroutine in deep learning, particularly within
the Muon optimization framework. However, the requirements in this setting
differ significantly from those of traditional numerical analysis. In deep
learning, methods must be highly efficient and GPU-compatible, but high
accuracy is often unnecessary. As a result, classical algorithms like
Newton-Schulz (which suffers from slow initial convergence) and methods based
on rational functions (which rely on QR decompositions or matrix inverses) are
poorly suited to this context. In this work, we introduce Polar Express, a
GPU-friendly algorithm for computing the polar decomposition. Like classical
polynomial methods such as Newton-Schulz, our approach uses only matrix-matrix
multiplications, making it GPU-compatible. Motivated by earlier work of Chen &
Chow and Nakatsukasa & Freund, Polar Express adapts the polynomial update rule
at each iteration by solving a minimax optimization problem, and we prove that
it enjoys a strong worst-case optimality guarantee. This property ensures both
rapid early convergence and fast asymptotic convergence. We also address
finite-precision issues, making it stable in bfloat16 in practice. We apply
Polar Express within the Muon optimization framework and show consistent
improvements in validation loss on large-scale models such as GPT-2,
outperforming recent alternatives across a range of learning rates.

</details>


### [105] [FoMoH: A clinically meaningful foundation model evaluation for structured electronic health records](https://arxiv.org/abs/2505.16941)
*Chao Pang, Vincent Jeanselme, Young Sang Choi, Xinzhuo Jiang, Zilin Jing, Aparajita Kashyap, Yuta Kobayashi, Yanwei Li, Florent Pollet, Karthik Natarajan, Shalmali Joshi*

**主要类别:** cs.LG

**概要:** 基础模型在医疗保健领域具有重要意义，因其能够独立于下游任务提取有意义的表示。尽管这些模型在结构化电子健康记录（EHR）数据上表现出色，但其临床实用性尚缺乏共识。本文提出了一系列临床意义的任务，并对最先进的基础模型进行了评估，以指导未来医疗保健基础模型的发展。


<details>
  <summary>更多</summary>
  
**动机:** 基础模型在医疗领域的潜力尚未得到充分挖掘，特别是在临床应用中的实际效用尚未达成共识。因此，需要明确的任务和多样化的评估来展示这些模型相较于传统监督学习的优势。

**方法:** 作者设计了一套具有临床意义的任务，涵盖了患者结果、急性与慢性疾病的早期预测等多个方面，并提出了稳健的评估标准。使用来自哥伦比亚大学欧文医学中心（CUMC）包含5百万患者的EHR数据，在14个临床相关任务上评估了最先进的基础模型。通过测量整体准确性、校准度以及子群体性能，分析了预训练、标记化和数据表示策略的选择对模型表现的影响。

**结果:** 研究表明，基础模型在多个临床相关任务中表现出较高的准确性和校准度，同时揭示了不同预训练、标记化和数据表示策略之间的权衡。这为未来医疗保健基础模型的设计提供了重要的指导。

**结论:** 本研究通过一系列临床任务的评估，展示了基础模型在结构化EHR数据上的优势，并强调了稳健评估的重要性。这将有助于推动未来医疗保健领域基础模型的开发和改进。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FoMoH%3A+A+clinically+meaningful+foundation+model+evaluation+for+structured+electronic+health+records，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16941，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16941&send_immediately=true&force_search=false)

**原文摘要:** Foundation models hold significant promise in healthcare, given their
capacity to extract meaningful representations independent of downstream tasks.
This property has enabled state-of-the-art performance across several clinical
applications trained on structured electronic health record (EHR) data, even in
settings with limited labeled data, a prevalent challenge in healthcare.
However, there is little consensus on these models' potential for clinical
utility due to the lack of desiderata of comprehensive and meaningful tasks and
sufficiently diverse evaluations to characterize the benefit over conventional
supervised learning. To address this gap, we propose a suite of clinically
meaningful tasks spanning patient outcomes, early prediction of acute and
chronic conditions, including desiderata for robust evaluations. We evaluate
state-of-the-art foundation models on EHR data consisting of 5 million patients
from Columbia University Irving Medical Center (CUMC), a large urban academic
medical center in New York City, across 14 clinically relevant tasks. We
measure overall accuracy, calibration, and subpopulation performance to surface
tradeoffs based on the choice of pre-training, tokenization, and data
representation strategies. Our study aims to advance the empirical evaluation
of structured EHR foundation models and guide the development of future
healthcare foundation models.

</details>


### [106] [MixAT: Combining Continuous and Discrete Adversarial Training for LLMs](https://arxiv.org/abs/2505.16947)
*Csaba Dékány, Stefan Balauca, Robin Staab, Dimitar I. Dimitrov, Martin Vechev*

**主要类别:** cs.LG

**概要:** 尽管在大语言模型（LLMs）的安全性和对齐方面有最近的努力，当前的对抗攻击仍能持续生成有害内容。本论文介绍了一种名为MixAT的新方法，结合了离散和连续的对抗训练，以提高LLM的鲁棒性。实验结果表明，MixAT在保持与连续方法相似运行时间的同时，显著提高了模型的鲁棒性，并揭示了现有方法中的盲点。


<details>
  <summary>更多</summary>
  
**动机:** 尽管对抗训练在传统机器学习模型中被广泛研究并显示出显著提高鲁棒性的效果，但在LLMs中的应用存在挑战：离散对抗训练计算成本高，而连续松弛方法虽然更快，但可能导致模型对离散攻击仍然脆弱。因此，需要一种结合两者优势的方法来提高LLMs的鲁棒性。

**方法:** 提出了一种名为MixAT的方法，该方法将更强的离散攻击和更快的连续攻击结合到训练过程中。同时，引入了At Least One Attack Success Rate (ALO-ASR) 指标来评估模型在最坏情况下的脆弱性。此外，分析了在实际部署场景中，如聊天模板、量化、低秩适配器和温度等因素如何影响对抗训练和评估。

**结果:** MixAT在广泛的最新攻击中表现出显著更好的鲁棒性（ALO-ASR < 20%），相较于先前的防御方法（ALO-ASR > 50%）。同时，其运行时间与基于连续松弛的方法相当。此外，MixAT揭示了现有方法中的额外盲点，并展示了在最小计算开销下提供更优的鲁棒性-准确性权衡。

**结论:** MixAT通过结合离散和连续的对抗训练，提供了原则性和优越的鲁棒性-准确性权衡，具有构建更安全的大语言模型的潜力。代码和模型已公开发布。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MixAT%3A+Combining+Continuous+and+Discrete+Adversarial+Training+for+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16947，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16947&send_immediately=true&force_search=false)

**原文摘要:** Despite recent efforts in Large Language Models (LLMs) safety and alignment,
current adversarial attacks on frontier LLMs are still able to force harmful
generations consistently. Although adversarial training has been widely studied
and shown to significantly improve the robustness of traditional machine
learning models, its strengths and weaknesses in the context of LLMs are less
understood. Specifically, while existing discrete adversarial attacks are
effective at producing harmful content, training LLMs with concrete adversarial
prompts is often computationally expensive, leading to reliance on continuous
relaxations. As these relaxations do not correspond to discrete input tokens,
such latent training methods often leave models vulnerable to a diverse set of
discrete attacks. In this work, we aim to bridge this gap by introducing MixAT,
a novel method that combines stronger discrete and faster continuous attacks
during training. We rigorously evaluate MixAT across a wide spectrum of
state-of-the-art attacks, proposing the At Least One Attack Success Rate
(ALO-ASR) metric to capture the worst-case vulnerability of models. We show
MixAT achieves substantially better robustness (ALO-ASR < 20%) compared to
prior defenses (ALO-ASR > 50%), while maintaining a runtime comparable to
methods based on continuous relaxations. We further analyze MixAT in realistic
deployment settings, exploring how chat templates, quantization, low-rank
adapters, and temperature affect both adversarial training and evaluation,
revealing additional blind spots in current methodologies. Our results
demonstrate that MixAT's discrete-continuous defense offers a principled and
superior robustness-accuracy tradeoff with minimal computational overhead,
highlighting its promise for building safer LLMs. We provide our code and
models at https://github.com/insait-institute/MixAT.

</details>


### [107] [Contextual Learning for Stochastic Optimization](https://arxiv.org/abs/2505.16829)
*Anna Heuser, Thomas Kesselheim*

**主要类别:** cs.LG

**概要:** Error


<details>
  <summary>更多</summary>
  
**动机:** Error

**方法:** Error

**结果:** Error

**结论:** Error

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Contextual+Learning+for+Stochastic+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16829，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16829&send_immediately=true&force_search=false)

**原文摘要:** Motivated by stochastic optimization, we introduce the problem of learning
from samples of contextual value distributions. A contextual value distribution
can be understood as a family of real-valued distributions, where each sample
consists of a context $x$ and a random variable drawn from the corresponding
real-valued distribution $D_x$. By minimizing a convex surrogate loss, we learn
an empirical distribution $D'_x$ for each context, ensuring a small L\'evy
distance to $D_x$. We apply this result to obtain the sample complexity bounds
for the learning of an $\epsilon$-optimal policy for stochastic optimization
problems defined on an unknown contextual value distribution. The sample
complexity is shown to be polynomial for the general case of strongly monotone
and stable optimization problems, including Single-item Revenue Maximization,
Pandora's Box and Optimal Stopping.

</details>


### [108] [Bottlenecked Transformers: Periodic KV Cache Abstraction for Generalised Reasoning](https://arxiv.org/abs/2505.16950)
*Adnan Oomerjee, Zafeirios Fountas, Zhongwei Yu, Haitham Bou-Ammar, Jun Wang*

**主要类别:** cs.LG

**概要:** 尽管大型语言模型（LLM）能力惊人，但它们在训练分布之外的泛化能力有限，往往表现出复杂的模式插值而非真正的抽象推理。本文通过信息瓶颈（IB）理论分析了这一局限性，证明了仅解码器的Transformer在形成任务最优序列表示方面存在固有约束，并提出通过对内部序列级表示（KV缓存）进行周期性全局变换来改进Transformer的推理泛化能力。基于此，我们提出了对Transformer架构的修改，增加一个模块周期性重写KV缓存，使其容量从记忆输入前缀转向编码对未来标记预测最有用的特征。该模型在数学推理基准上取得了显著的改进，优于具有多达3.5倍参数的普通Transformer以及基于启发式的缓存压缩机制。我们的方法可以被视为现有KV缓存压缩方法的原则性推广，解决了单纯扩展无法克服的基本推理限制。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型虽然功能强大，但在训练数据分布之外的泛化能力有限，往往依赖于复杂模式的插值而不是真正的抽象推理。这促使作者探索如何通过理论指导改进Transformer模型的泛化能力。

**方法:** 1. 使用信息瓶颈（IB）理论分析Transformer模型的泛化能力。
2. 证明仅解码器的Transformer在形成任务最优序列表示方面存在固有约束。
3. 提出通过对内部序列级表示（KV缓存）进行周期性全局变换来改进泛化能力。
4. 在Transformer架构中增加一个模块，周期性地重写KV缓存，减少对输入前缀的记忆，增强对未来标记预测的能力。

**结果:** 提出的模型在数学推理基准测试中表现优异，显著优于具有更多参数的普通Transformer和基于启发式的缓存压缩机制。

**结论:** 本文提出了一种基于信息理论原则性操纵Transformer内存的方法，解决了单纯扩展无法克服的基本推理限制，为改进Transformer模型的泛化能力提供了新的思路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bottlenecked+Transformers%3A+Periodic+KV+Cache+Abstraction+for+Generalised+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16950，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16950&send_immediately=true&force_search=false)

**原文摘要:** Despite their impressive capabilities, Large Language Models struggle with
generalisation beyond their training distribution, often exhibiting
sophisticated pattern interpolation rather than true abstract reasoning
(extrapolation). In this work, we approach this limitation through the lens of
Information Bottleneck (IB) theory, which posits that model generalisation
emerges from an optimal balance between input compression and retention of
predictive information in latent representations. We prove using IB theory that
decoder-only Transformers are inherently constrained in their ability to form
task-optimal sequence representations. We then use this result to demonstrate
that periodic global transformation of the internal sequence-level
representations (KV cache) is a necessary computational step for improving
Transformer generalisation in reasoning tasks. Based on these theoretical
insights, we propose a modification to the Transformer architecture, in the
form of an additional module that globally rewrites the KV cache at periodic
intervals, shifting its capacity away from memorising input prefixes and toward
encoding features most useful for predicting future tokens. Our model delivers
substantial gains on mathematical reasoning benchmarks, outperforming both
vanilla Transformers with up to 3.5x more parameters, as well as
heuristic-driven pruning mechanisms for cache compression. Our approach can be
seen as a principled generalisation of existing KV-cache compression methods;
whereas such methods focus solely on compressing input representations, they
often do so at the expense of retaining predictive information, and thus their
capabilities are inherently bounded by those of an unconstrained model. This
establishes a principled framework to manipulate Transformer memory using
information theory, addressing fundamental reasoning limitations that scaling
alone cannot overcome.

</details>


### [109] [Strategically Linked Decisions in Long-Term Planning and Reinforcement Learning](https://arxiv.org/abs/2505.16833)
*Alihan Hüyük, Finale Doshi-Velez*

**主要类别:** cs.LG

**概要:** 论文提出了一种新的方法——战略链接分数，用于量化强化学习中计划行动之间的依赖关系，并通过三个实际应用展示了该方法的效用：解释黑箱RL代理、改善决策支持系统和分析非RL代理的规划过程。


<details>
  <summary>更多</summary>
  
**动机:** 在强化学习中，长期规划涉及找到策略：集体朝着目标工作的行动，而不是单独优化其即时结果。作为策略的一部分，某些行动是以短期利益为代价采取的，以使未来的行动获得更大的回报。这些行动只有在其促成的后续行动得以实施时才具有优势，因此如果这些后续行动不可用，它们就不会被执行。

**方法:** 我们通过战略链接分数量化了计划行动之间的这种依赖关系：在后续决策不再可用的约束下，一个决策的可能性下降了多少。

**结果:** 我们通过三个实际应用展示了战略链接分数的实用性：(i) 通过识别他们所做决策中战略性链接的对来解释黑箱RL代理；(ii) 通过区分推荐动作是否可以作为独立改进采用，还是需要承诺更广泛的战略才能有效，从而改善决策支持系统的最差表现；(iii) 仅通过旨在衡量战略链接分数的干预措施来描述非RL代理的规划过程 - 例如，我们在现实的交通模拟器中考虑，并通过道路封闭分析许多驾驶员出现的路由行为的有效规划范围。

**结论:** 本文提出了战略链接分数的概念，并展示了其在多个领域中的潜在用途，包括解释RL代理、改进决策支持系统和分析非RL代理的规划过程。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Strategically+Linked+Decisions+in+Long-Term+Planning+and+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16833，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16833&send_immediately=true&force_search=false)

**原文摘要:** Long-term planning, as in reinforcement learning (RL), involves finding
strategies: actions that collectively work toward a goal rather than
individually optimizing their immediate outcomes. As part of a strategy, some
actions are taken at the expense of short-term benefit to enable future actions
with even greater returns. These actions are only advantageous if followed up
by the actions they facilitate, consequently, they would not have been taken if
those follow-ups were not available. In this paper, we quantify such
dependencies between planned actions with strategic link scores: the drop in
the likelihood of one decision under the constraint that a follow-up decision
is no longer available. We demonstrate the utility of strategic link scores
through three practical applications: (i) explaining black-box RL agents by
identifying strategically linked pairs among decisions they make, (ii)
improving the worst-case performance of decision support systems by
distinguishing whether recommended actions can be adopted as standalone
improvements or whether they are strategically linked hence requiring a
commitment to a broader strategy to be effective, and (iii) characterizing the
planning processes of non-RL agents purely through interventions aimed at
measuring strategic link scores - as an example, we consider a realistic
traffic simulator and analyze through road closures the effective planning
horizon of the emergent routing behavior of many drivers.

</details>


### [110] [ATR-Bench: A Federated Learning Benchmark for Adaptation, Trust, and Reasoning](https://arxiv.org/abs/2505.16850)
*Tajamul Ashraf, Mohammed Mohsen Peerzada, Moloud Abdar, Yutong Xie, Yuyin Zhou, Xiaofeng Liu, Iqra Altaf Gillani, Janibul Bashir*

**主要类别:** cs.LG

**概要:** 本论文提出了ATR-Bench，一个用于分析联邦学习的统一框架，涵盖适应性、信任和推理三个基础维度，并提供了代表性的方法和数据集基准测试。


<details>
  <summary>更多</summary>
  
**动机:** 尽管联邦学习（FL）领域有许多技术被提出以解决实际挑战，但缺乏标准化评估阻碍了系统性进展和公平比较。

**方法:** 引入ATR-Bench框架，通过适应性、信任和推理三个维度分析联邦学习，提供概念基础、任务公式化和开放研究挑战的深入考察，并对适应性和信任维度进行了广泛的基准测试。

**结果:** 为联邦学习的系统性和整体评估奠定了基础，特别是针对现实世界的相关性，并将公开代码库和持续跟踪新发展的文献存储库。

**结论:** ATR-Bench有助于推动联邦学习领域向更系统化和全面的方向发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ATR-Bench%3A+A+Federated+Learning+Benchmark+for+Adaptation%2C+Trust%2C+and+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16850，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16850&send_immediately=true&force_search=false)

**原文摘要:** Federated Learning (FL) has emerged as a promising paradigm for collaborative
model training while preserving data privacy across decentralized participants.
As FL adoption grows, numerous techniques have been proposed to tackle its
practical challenges. However, the lack of standardized evaluation across key
dimensions hampers systematic progress and fair comparison of FL methods. In
this work, we introduce ATR-Bench, a unified framework for analyzing federated
learning through three foundational dimensions: Adaptation, Trust, and
Reasoning. We provide an in-depth examination of the conceptual foundations,
task formulations, and open research challenges associated with each theme. We
have extensively benchmarked representative methods and datasets for adaptation
to heterogeneous clients and trustworthiness in adversarial or unreliable
environments. Due to the lack of reliable metrics and models for reasoning in
FL, we only provide literature-driven insights for this dimension. ATR-Bench
lays the groundwork for a systematic and holistic evaluation of federated
learning with real-world relevance. We will make our complete codebase publicly
accessible and a curated repository that continuously tracks new developments
and research in the FL literature.

</details>


### [111] [Interactive Post-Training for Vision-Language-Action Models](https://arxiv.org/abs/2505.17016)
*Shuhan Tan, Kairan Dou, Yue Zhao, Philipp Krähenbühl*

**主要类别:** cs.LG

**概要:** 我们提出了RIPT-VLA，一种简单且可扩展的基于强化学习的交互式后训练范式，仅使用稀疏的二元成功奖励微调预训练的视觉-语言-动作（VLA）模型。RIPT-VLA通过动态 rollout 采样和留一法优势估计的稳定策略优化算法实现交互式后训练。实验表明，RIPT-VLA不仅显著提升了不同VLA模型的表现（如QueST模型提高21.2%，OpenVLA-OFT模型达到97.5%的成功率），还具有计算高效、数据高效的特点，并且学到的策略在不同任务和场景中具有泛化性和鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的VLA训练方法依赖大量的离线专家演示数据和监督模仿学习，这限制了它们在低数据量条件下适应新任务和环境的能力。因此，需要一种新的方法来减少对大量数据的依赖并提升模型的适应能力。

**方法:** RIPT-VLA是一种基于强化学习的交互式后训练范式，它采用动态rollout采样和留一法优势估计的稳定策略优化算法进行微调。这种方法只需要稀疏的二元成功奖励，不需要大量的专家演示数据。

**结果:** 实验结果表明，RIPT-VLA可以显著提升不同VLA模型的表现，例如将QueST模型性能提升21.2%，将OpenVLA-OFT模型的成功率提高到前所未有的97.5%。此外，该方法只需一个演示即可在15次迭代内将不可用的SFT模型（4%成功率）提升至97%的成功率。同时，所学策略具有跨任务和场景的泛化能力以及对初始状态上下文的鲁棒性。

**结论:** RIPT-VLA作为一种简单且可扩展的方法，为通过最少监督进行VLA模型的后训练提供了一个实际且有效的范式。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Interactive+Post-Training+for+Vision-Language-Action+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.17016，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.17016&send_immediately=true&force_search=false)

**原文摘要:** We introduce RIPT-VLA, a simple and scalable reinforcement-learning-based
interactive post-training paradigm that fine-tunes pretrained
Vision-Language-Action (VLA) models using only sparse binary success rewards.
Existing VLA training pipelines rely heavily on offline expert demonstration
data and supervised imitation, limiting their ability to adapt to new tasks and
environments under low-data regimes. RIPT-VLA addresses this by enabling
interactive post-training with a stable policy optimization algorithm based on
dynamic rollout sampling and leave-one-out advantage estimation.
  RIPT-VLA has the following characteristics. First, it applies to various VLA
models, resulting in an improvement on the lightweight QueST model by 21.2%,
and the 7B OpenVLA-OFT model to an unprecedented 97.5% success rate. Second, it
is computationally efficient and data-efficient: with only one demonstration,
RIPT-VLA enables an unworkable SFT model (4%) to succeed with a 97% success
rate within 15 iterations. Furthermore, we demonstrate that the policy learned
by RIPT-VLA generalizes across different tasks and scenarios and is robust to
the initial state context. These results highlight RIPT-VLA as a practical and
effective paradigm for post-training VLA models through minimal supervision.

</details>


### [112] [Redefining Clustered Federated Learning for System Identification: The Path of ClusterCraft](https://arxiv.org/abs/2505.16857)
*Ertuğrul Keçeci, Müjde Güzelkaya, Tufan Kumbasar*

**主要类别:** cs.LG

**概要:** This paper proposes IC-SYSID, an algorithm that uses incremental clustering for system identification within federated learning. It introduces ClusterCraft and ClusterMerge to handle multiple data sources without prior knowledge and enhances cluster stability through regularization and initialization techniques.


<details>
  <summary>更多</summary>
  
**动机:** To solve the System Identification (SYSID) problem using federated learning across multiple data sources without relying on prior knowledge of the datasets.

**方法:** The paper introduces IC-SYSID which uses ClusterCraft for incremental clustering starting with a single cluster model and dynamically increasing clusters based on similarity. ClusterMerge is used to reduce the number of clusters by merging similar ones. Enhanced ClusterCraft prevents generation of similar models during training. Regularization and scaled Glorot initialization are integrated to address cluster model instability. A mini-batch deep learning approach is also utilized for managing large SYSID datasets.

**结果:** Experiments on a real-world SYSID problem involving collaborative learning of vehicle dynamics showed that IC-SYSID achieves high performance in SYSID while preventing unstable clusters from being learned.

**结论:** IC-SYSID effectively addresses the SYSID problem in a federated learning setting, achieving high performance and ensuring cluster model stability.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Redefining+Clustered+Federated+Learning+for+System+Identification%3A+The+Path+of+ClusterCraft，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16857，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16857&send_immediately=true&force_search=false)

**原文摘要:** This paper addresses the System Identification (SYSID) problem within the
framework of federated learning. We introduce a novel algorithm, Incremental
Clustering-based federated learning method for SYSID (IC-SYSID), designed to
tackle SYSID challenges across multiple data sources without prior knowledge.
IC-SYSID utilizes an incremental clustering method, ClusterCraft (CC), to
eliminate the dependency on the prior knowledge of the dataset. CC starts with
a single cluster model and assigns similar local workers to the same clusters
by dynamically increasing the number of clusters. To reduce the number of
clusters generated by CC, we introduce ClusterMerge, where similar cluster
models are merged. We also introduce enhanced ClusterCraft to reduce the
generation of similar cluster models during the training. Moreover, IC-SYSID
addresses cluster model instability by integrating a regularization term into
the loss function and initializing cluster models with scaled Glorot
initialization. It also utilizes a mini-batch deep learning approach to manage
large SYSID datasets during local training. Through the experiments conducted
on a real-world representing SYSID problem, where a fleet of vehicles
collaboratively learns vehicle dynamics, we show that IC-SYSID achieves a high
SYSID performance while preventing the learning of unstable clusters.

</details>


### [113] [A Multi-Step Comparative Framework for Anomaly Detection in IoT Data Streams](https://arxiv.org/abs/2505.16872)
*Mohammed Al-Qudah, Fadi AlMahamid*

**主要类别:** cs.LG

**概要:** 这篇论文提出一个多步骤评估框架，分析预处理选择对三种机器学习算法（RNN-LSTM、ANN、GBoosting）在IoT环境异常检测中的影响。实验表明GBoosting准确性最高，RNN-LSTM在z-score归一化时表现显著提升，而自编码器在召回率方面表现出色。该框架为提高IoT环境中的异常检测性能提供了实际指导。


<details>
  <summary>更多</summary>
  
**动机:** 物联网设备的快速扩展带来了关键的安全挑战，特别是对精确异常检测的需求。然而，目前缺乏系统性研究来探讨不同的预处理步骤（归一化、转换和特征选择）如何与不同的模型架构相互作用以优化异常检测效果。

**方法:** 作者提出了一个多步骤评估框架，用于评估预处理选择对三种机器学习算法的影响：RNN-LSTM、自动编码神经网络（ANN）和梯度提升（GBoosting）。通过在IoTID20数据集上进行实验，比较不同预处理配置下的模型性能。

**结果:** 实验结果表明：GBoosting在所有预处理配置下都能提供最高的准确性；RNN-LSTM在使用z-score归一化时性能有显著提升；自动编码器在召回率方面表现出色，适合无监督场景。

**结论:** 该框架通过提供结构化的分析方法，阐明了预处理决策与各种机器学习技术之间的相互作用，并为增强物联网环境中的异常检测性能提供了实际指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Multi-Step+Comparative+Framework+for+Anomaly+Detection+in+IoT+Data+Streams，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16872，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16872&send_immediately=true&force_search=false)

**原文摘要:** The rapid expansion of Internet of Things (IoT) devices has introduced
critical security challenges, underscoring the need for accurate anomaly
detection. Although numerous studies have proposed machine learning (ML)
methods for this purpose, limited research systematically examines how
different preprocessing steps--normalization, transformation, and feature
selection--interact with distinct model architectures. To address this gap,
this paper presents a multi-step evaluation framework assessing the combined
impact of preprocessing choices on three ML algorithms: RNN-LSTM, autoencoder
neural networks (ANN), and Gradient Boosting (GBoosting). Experiments on the
IoTID20 dataset shows that GBoosting consistently delivers superior accuracy
across preprocessing configurations, while RNN-LSTM shows notable gains with
z-score normalization and autoencoders excel in recall, making them well-suited
for unsupervised scenarios. By offering a structured analysis of preprocessing
decisions and their interplay with various ML techniques, the proposed
framework provides actionable guidance to enhance anomaly detection performance
in IoT environments.

</details>


### [114] [Unsupervised Prompting for Graph Neural Networks](https://arxiv.org/abs/2505.16903)
*Peyman Baghershahi, Sourav Medya*

**主要类别:** cs.LG

**概要:** 本文提出了一种全新的、具有挑战性的评估图神经网络（GNN）提示方法的问题设定，并开发了一种完全无监督的提示方法，该方法在无需更新GNN参数和无标签数据的情况下，通过一致性正则化和伪标记技术提升了预训练GNN对目标数据集的泛化能力。实验表明，该方法优于现有的依赖标签的提示方法。


<details>
  <summary>更多</summary>
  
**动机:** 当前的GNN提示方法依赖于标签数据并涉及下游任务的轻量级微调，而大型语言模型（LLM）中的上下文学习方法在无需参数更新和极少或无标签数据的情况下表现出色。受此启发，研究者希望探索一种无需更新GNN参数且无需标签数据的方法来增强预训练GNN的泛化能力。

**方法:** 研究者首先引入了一个具有挑战性的问题设定，用于评估GNN提示方法在协变量偏移下的表现。随后，他们提出了一种基于一致性正则化的完全无监督提示方法，使用伪标记技术，并结合两种正则化技术来对齐提示图的数据分布，减少偏差预测。

**结果:** 在广泛实验中，所提出的无监督方法在没有标签数据的情况下，表现优于现有的需要标签的最先进的提示方法。

**结论:** 所提出的无监督提示方法能够在不更新GNN参数和不使用标签数据的情况下，显著提升预训练GNN对目标数据集的泛化能力，为GNN提示方法的研究提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Unsupervised+Prompting+for+Graph+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16903，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16903&send_immediately=true&force_search=false)

**原文摘要:** Prompt tuning methods for Graph Neural Networks (GNNs) have become popular to
address the semantic gap between pre-training and fine-tuning steps. However,
existing GNN prompting methods rely on labeled data and involve lightweight
fine-tuning for downstream tasks. Meanwhile, in-context learning methods for
Large Language Models (LLMs) have shown promising performance with no parameter
updating and no or minimal labeled data. Inspired by these approaches, in this
work, we first introduce a challenging problem setup to evaluate GNN prompting
methods. This setup encourages a prompting function to enhance a pre-trained
GNN's generalization to a target dataset under covariate shift without updating
the GNN's parameters and with no labeled data. Next, we propose a fully
unsupervised prompting method based on consistency regularization through
pseudo-labeling. We use two regularization techniques to align the prompted
graphs' distribution with the original data and reduce biased predictions.
Through extensive experiments under our problem setting, we demonstrate that
our unsupervised approach outperforms the state-of-the-art prompting methods
that have access to labels.

</details>


### [115] [Scalable and Interpretable Contextual Bandits: A Literature Review and Retail Offer Prototype](https://arxiv.org/abs/2505.16918)
*Nikola Tankovic, Robert Sajina*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种针对上下文多臂老虎机（CMAB）方法的简明综述，并引入了一个实验框架，用于可扩展和可解释的优惠选择，解决了快速变化的优惠挑战。该方法通过建模产品类别级别的上下文，支持跨多个类别的优惠，并允许相似优惠之间的知识转移，从而提高动态环境中的学习效率和泛化能力。此外，该框架扩展了标准的CMAB方法以支持多类别上下文，通过高效的特征工程和模块化设计实现可扩展性。关键贡献在于大规模的可解释性：逻辑回归模型生成透明的权重向量，可通过大型语言模型接口进行实时、用户级别的跟踪和解释，生成详细的会员画像并识别行为模式，支持个性化优惠优化并增强对自动化决策的信任。


<details>
  <summary>更多</summary>
  
**动机:** 在快速变化的环境中，传统的CMAB方法难以应对优惠选择的挑战，缺乏可扩展性和可解释性。因此，需要一种新的框架来解决这些问题，提升学习效率和泛化能力，同时提供可解释的结果以支持个性化优化和增强信任。

**方法:** 该方法主要通过以下步骤实现：1. 建模产品类别级别的上下文，支持跨多个类别的优惠；2. 允许相似优惠之间的知识转移；3. 扩展标准的CMAB方法以支持多类别上下文；4. 通过高效的特征工程（如MPG和MF）和模块化设计实现可扩展性；5. 使用逻辑回归模型生成透明的权重向量，结合LLM接口进行实时解释。

**结果:** 该框架展示了在研究和实际应用中的价值，能够支持大规模的个性化优惠优化，同时提供了透明的解释机制，增强了对自动化决策的信任。通过与已建立的方法（如广义线性模型和汤普森采样）对比，证明了其在动态环境中的优越性能。

**结论:** 提出的实验框架为CMAB方法的研究和实际应用提供了一种新的解决方案，特别是在快速变化的优惠选择场景中。它不仅提高了学习效率和泛化能力，还通过大规模可解释性支持个性化优化，推动了CMAB技术的发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Scalable+and+Interpretable+Contextual+Bandits%3A+A+Literature+Review+and+Retail+Offer+Prototype，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16918，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16918&send_immediately=true&force_search=false)

**原文摘要:** This paper presents a concise review of Contextual Multi-Armed Bandit (CMAB)
methods and introduces an experimental framework for scalable, interpretable
offer selection, addressing the challenge of fast-changing offers. The approach
models context at the product category level, allowing offers to span multiple
categories and enabling knowledge transfer across similar offers. This improves
learning efficiency and generalization in dynamic environments. The framework
extends standard CMAB methodology to support multi-category contexts, and
achieves scalability through efficient feature engineering and modular design.
Advanced features such as MPG (Member Purchase Gap) and MF (Matrix
Factorization) capture nuanced user-offer interactions, with implementation in
Python for practical deployment.
  A key contribution is interpretability at scale: logistic regression models
yield transparent weight vectors, accessible via a large language model (LLM)
interface for real-time, user-level tracking and explanation of evolving
preferences. This enables the generation of detailed member profiles and
identification of behavioral patterns, supporting personalized offer
optimization and enhancing trust in automated decisions. By situating our
prototype alongside established paradigms like Generalized Linear Models and
Thompson Sampling, we demonstrate its value for both research and real-world
CMAB applications.

</details>


### [116] [Risk-Averse Reinforcement Learning with Itakura-Saito Loss](https://arxiv.org/abs/2505.16925)
*Igor Udovichenko, Olivier Croissant, Anita Toleutaeva, Evgeny Burnaev, Alexander Korotin*

**主要类别:** cs.LG

**概要:** 论文提出了一种基于Itakura-Saito divergence的数值稳定损失函数，用于风险规避强化学习中的状态值和动作值函数学习，并在金融场景实验中表现优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 风险规避强化学习适用于高风险领域，与传统强化学习不同，它通过牺牲部分期望收益来最小化风险，而指数效用函数下的Bellman方程求解存在数值不稳定性问题。

**方法:** 引入基于Itakura-Saito divergence的数值稳定损失函数，解决指数效用函数下强化学习算法中的数值不稳定性问题，同时对提出的损失函数进行理论和实证评估。

**结果:** 在多个金融场景实验中（部分具有解析解），所提出的损失函数表现优于现有替代方案。

**结论:** 基于Itakura-Saito divergence的损失函数为风险规避强化学习提供了一个数值稳定且数学严谨的解决方案，适合在相关领域应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Risk-Averse+Reinforcement+Learning+with+Itakura-Saito+Loss，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16925，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16925&send_immediately=true&force_search=false)

**原文摘要:** Risk-averse reinforcement learning finds application in various high-stakes
fields. Unlike classical reinforcement learning, which aims to maximize
expected returns, risk-averse agents choose policies that minimize risk,
occasionally sacrificing expected value. These preferences can be framed
through utility theory. We focus on the specific case of the exponential
utility function, where we can derive the Bellman equations and employ various
reinforcement learning algorithms with few modifications. However, these
methods suffer from numerical instability due to the need for exponent
computation throughout the process. To address this, we introduce a numerically
stable and mathematically sound loss function based on the Itakura-Saito
divergence for learning state-value and action-value functions. We evaluate our
proposed loss function against established alternatives, both theoretically and
empirically. In the experimental section, we explore multiple financial
scenarios, some with known analytical solutions, and show that our loss
function outperforms the alternatives.

</details>


### [117] [LLaDA-V: Large Language Diffusion Models with Visual Instruction Tuning](https://arxiv.org/abs/2505.16933)
*Zebin You, Shen Nie, Xiaolu Zhang, Jun Hu, Jun Zhou, Zhiwu Lu, Ji-Rong Wen, Chongxuan Li*

**主要类别:** cs.LG

**概要:** 本研究介绍了一种全新的纯扩散型多模态大语言模型LLaDA-V，该模型通过结合视觉指令调整与掩码扩散模型，突破了当前主流的自回归范式。基于LLaDA构建，LLaDA-V引入了视觉编码器和MLP连接器，将视觉特征映射到语言嵌入空间，实现了有效的多模态对齐。实证研究表明，尽管其语言模型在纯文本任务上的表现不如LLaMA3-8B和Qwen2-7B等模型，但在相同的指令数据训练下，LLaDA-V在多模态任务上具有高度竞争力，并且在数据扩展性方面表现出色。此外，LLaDA-V在多模态理解任务中达到了现有混合自回归-扩散及纯扩散型多模态大语言模型的最佳性能。这些发现表明，大型语言扩散模型在多模态领域具有广阔的应用前景，值得进一步深入研究。


<details>
  <summary>更多</summary>
  
**动机:** 目前的多模态方法大多依赖于自回归范式，而基于扩散模型的方法尚未得到充分探索。因此，研究者希望开发一种纯扩散型多模态大语言模型，以验证其在多模态任务中的潜力，并探索是否能够超越现有的自回归或混合模型架构。

**方法:** LLaDA-V通过整合视觉指令调优与掩码扩散模型，打破了传统的自回归范式。具体而言，该模型基于LLaDA构建，添加了一个视觉编码器和一个MLP连接器，用于将视觉特征投影到语言嵌入空间，从而实现高效的多模态对齐。

**结果:** 1. 尽管LLaDA-V的语言模型在纯文本任务上的表现弱于LLaMA3-8B和Qwen2-7B等模型，但其在多模态任务上表现出色；2. 在相同指令数据训练下，LLaDA-V在多模态任务上的表现与LLaMA3-V相当，并且数据扩展性更好；3. LLaDA-V显著缩小了与Qwen2-VL的性能差距，证明了其架构在多模态任务中的有效性；4. 在多模态理解任务中，LLaDA-V达到了现有模型的最佳性能。

**结论:** 研究结果表明，大型语言扩散模型在多模态任务中具有显著潜力。未来的研究可以进一步优化扩散模型架构，探索其在更多复杂多模态场景中的应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLaDA-V%3A+Large+Language+Diffusion+Models+with+Visual+Instruction+Tuning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16933，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16933&send_immediately=true&force_search=false)

**原文摘要:** In this work, we introduce LLaDA-V, a purely diffusion-based Multimodal Large
Language Model (MLLM) that integrates visual instruction tuning with masked
diffusion models, representing a departure from the autoregressive paradigms
dominant in current multimodal approaches. Built upon LLaDA, a representative
large language diffusion model, LLaDA-V incorporates a vision encoder and MLP
connector that projects visual features into the language embedding space,
enabling effective multimodal alignment. Our empirical investigation reveals
several intriguing results: First, LLaDA-V demonstrates promising multimodal
performance despite its language model being weaker on purely textual tasks
than counterparts like LLaMA3-8B and Qwen2-7B. When trained on the same
instruction data, LLaDA-V is highly competitive to LLaMA3-V across multimodal
tasks with better data scalability. It also narrows the performance gap to
Qwen2-VL, suggesting the effectiveness of its architecture for multimodal
tasks. Second, LLaDA-V achieves state-of-the-art performance in multimodal
understanding compared to existing hybrid autoregressive-diffusion and purely
diffusion-based MLLMs. Our findings suggest that large language diffusion
models show promise in multimodal contexts and warrant further investigation in
future research. Project page and codes:
https://ml-gsai.github.io/LLaDA-V-demo/.

</details>


### [118] [SPAR: Self-supervised Placement-Aware Representation Learning for Multi-Node IoT Systems](https://arxiv.org/abs/2505.16936)
*Yizhuo Chen, Tianchen Wang, You Lyu, Yanlan Hu, Jinyang Li, Tomoyoshi Kimura, Hongjue Zhao, Yigong Hu, Denizhan Kara, Tarek Abdelzaher*

**主要类别:** cs.LG

**概要:** This work develops self-supervised placement-aware representation learning for spatially-distributed multi-view and multimodal sensor observations in IoT systems.


<details>
  <summary>更多</summary>
  
**动机:** The need to represent external environmental state in multi-sensor IoT systems in a manner that correctly distills spatial phenomena from the distributed multi-vantage observations.

**方法:** Framework explicitly learns dependencies between measurements and geometric observer layouts and structural characteristics, guided by the duality between signals and observer positions. Theoretical analyses from information theory and occlusion-invariant representation learning are provided.

**结果:** Experiments on three real-world datasets demonstrate superior generalizability and robustness across diverse modalities, sensor placements, application-level inference tasks, and spatial scales.

**结论:** Advances self-supervised model pretraining from IoT signals beyond current solutions that often overlook the distinctive spatial nature of IoT data.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SPAR%3A+Self-supervised+Placement-Aware+Representation+Learning+for+Multi-Node+IoT+Systems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16936，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16936&send_immediately=true&force_search=false)

**原文摘要:** This work develops the underpinnings of self-supervised placement-aware
representation learning given spatially-distributed (multi-view and multimodal)
sensor observations, motivated by the need to represent external environmental
state in multi-sensor IoT systems in a manner that correctly distills spatial
phenomena from the distributed multi-vantage observations. The objective of
sensing in IoT systems is, in general, to collectively represent an externally
observed environment given multiple vantage points from which sensory
observations occur. Pretraining of models that help interpret sensor data must
therefore encode the relation between signals observed by sensors and the
observers' vantage points in order to attain a representation that encodes the
observed spatial phenomena in a manner informed by the specific placement of
the measuring instruments, while allowing arbitrary placement. The work
significantly advances self-supervised model pretraining from IoT signals
beyond current solutions that often overlook the distinctive spatial nature of
IoT data. Our framework explicitly learns the dependencies between measurements
and geometric observer layouts and structural characteristics, guided by a core
design principle: the duality between signals and observer positions. We
further provide theoretical analyses from the perspectives of information
theory and occlusion-invariant representation learning to offer insight into
the rationale behind our design. Experiments on three real-world
datasets--covering vehicle monitoring, human activity recognition, and
earthquake localization--demonstrate the superior generalizability and
robustness of our method across diverse modalities, sensor placements,
application-level inference tasks, and spatial scales.

</details>


### [119] [A Comprehensive Evaluation of Contemporary ML-Based Solvers for Combinatorial Optimization](https://arxiv.org/abs/2505.16952)
*Shengyu Feng, Weiwei Sun, Shanda Li, Ameet Talwalkar, Yiming Yang*

**主要类别:** cs.LG

**概要:** 本论文介绍了FrontierCO，这是一个全面的组合优化（CO）基准测试平台，涵盖了八个典型的CO问题类型，并评估了16种具有代表性的基于机器学习（ML）的求解器。FrontierCO提供了来自工业应用和前沿CO研究的具有挑战性的问题实例，既体现了实际问题的难度，又提供了丰富的训练数据。实验结果揭示了当前ML方法在解决CO问题上的优势与局限性，为推动机器学习与组合优化交叉领域的更稳健、更具实践意义的发展提供了指导。相关数据可在https://huggingface.co/datasets/CO-Bench/FrontierCO获取。


<details>
  <summary>更多</summary>
  
**动机:** 目前，尽管机器学习（ML）在支持组合优化（CO）问题的模型设计和优化方面展现出巨大潜力，但其进展主要基于小规模、合成数据集的评估，这引发了对ML求解器在真实世界大规模CO场景中实际效果的担忧。此外，许多现有的CO基准缺乏足够的训练数据，限制了它们在评估数据驱动方法时的实用性。因此，需要一个能够反映实际问题难度并提供充足训练数据的综合基准来解决这些问题。

**方法:** 研究人员开发了名为FrontierCO的综合基准测试平台。该平台覆盖了八种典型的CO问题类型，并评估了16种代表性ML求解器，包括图神经网络和大型语言模型（LLM）代理。FrontierCO中的问题实例来源于工业应用和前沿CO研究，确保了问题的实际难度和充足的训练数据量。通过广泛的实证研究，分析了当前ML方法在解决CO问题方面的表现。

**结果:** 实验结果显示，FrontierCO成功地反映了实际CO问题的复杂性和难度。通过对16种ML求解器的评估，揭示了这些方法在解决不同类型的CO问题时的优势与局限性。具体而言，某些ML求解器在特定问题上表现出色，但在其他问题上则面临挑战。这些发现有助于指导未来的研究方向，以改进ML方法在CO领域的应用。

**结论:** FrontierCO作为一个综合基准测试平台，填补了现有CO基准在实际问题难度和训练数据量方面的空白。它不仅为评估ML求解器在CO问题上的表现提供了有力工具，还揭示了当前方法的优劣势。这一工作将促进机器学习与组合优化交叉领域的发展，推动更加稳健和实用的解决方案的出现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Comprehensive+Evaluation+of+Contemporary+ML-Based+Solvers+for+Combinatorial+Optimization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16952，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16952&send_immediately=true&force_search=false)

**原文摘要:** Machine learning (ML) has demonstrated considerable potential in supporting
model design and optimization for combinatorial optimization (CO) problems.
However, much of the progress to date has been evaluated on small-scale,
synthetic datasets, raising concerns about the practical effectiveness of
ML-based solvers in real-world, large-scale CO scenarios. Additionally, many
existing CO benchmarks lack sufficient training data, limiting their utility
for evaluating data-driven approaches. To address these limitations, we
introduce FrontierCO, a comprehensive benchmark that covers eight canonical CO
problem types and evaluates 16 representative ML-based solvers--including graph
neural networks and large language model (LLM) agents. FrontierCO features
challenging instances drawn from industrial applications and frontier CO
research, offering both realistic problem difficulty and abundant training
data. Our empirical results provide critical insights into the strengths and
limitations of current ML methods, helping to guide more robust and practically
relevant advances at the intersection of machine learning and combinatorial
optimization. Our data is available at
https://huggingface.co/datasets/CO-Bench/FrontierCO.

</details>


### [120] [UFT: Unifying Supervised and Reinforcement Fine-Tuning](https://arxiv.org/abs/2505.16984)
*Mingyang Liu, Gabriele Farina, Asuman Ozdaglar*

**主要类别:** cs.LG

**概要:** 在提升大语言模型推理能力的后训练方法中，监督微调（SFT）和强化微调（RFT）各有局限。本文提出了一种新的后训练范式——统一微调（UFT），将SFT和RFT整合为一个单一过程。UFT不仅在各种模型尺寸上表现优于SFT和RFT，还理论上突破了RFT固有的指数样本复杂度瓶颈，首次证明统一训练可以在长时推理任务中实现指数级加速收敛。


<details>
  <summary>更多</summary>
  
**动机:** 当前主要的后训练方法SFT和RFT分别存在过拟合与对基础模型依赖性强的问题，限制了其在大模型上的应用效果。因此需要一种能够结合两者优势的新方法来克服这些局限。

**方法:** 提出了一种名为UFT的新后训练范式，该方法将SFT和RFT融合到一个集成过程中，使模型既能有效探索解决方案，又能引入有益的监督信号，从而弥合现有方法中记忆与思考之间的差距。

**结果:** 实验表明，无论模型大小如何，UFT在总体上都优于SFT和RFT。此外，理论分析显示UFT可以打破RFT固有的指数样本复杂度瓶颈，并在长时推理任务中实现指数级加速收敛。

**结论:** UFT作为一种新型的后训练方法，在提升大语言模型推理能力方面具有显著优势，且从理论上支持了其在处理复杂推理任务时的高效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是UFT%3A+Unifying+Supervised+and+Reinforcement+Fine-Tuning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16984，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16984&send_immediately=true&force_search=false)

**原文摘要:** Post-training has demonstrated its importance in enhancing the reasoning
capabilities of large language models (LLMs). The primary post-training methods
can be categorized into supervised fine-tuning (SFT) and reinforcement
fine-tuning (RFT). SFT is efficient and well-suited for small language models,
but it may lead to overfitting and limit the reasoning abilities of larger
models. In contrast, RFT generally yields better generalization but depends
heavily on the strength of the base model. To address the limitations of SFT
and RFT, we propose Unified Fine-Tuning (UFT), a novel post-training paradigm
that unifies SFT and RFT into a single, integrated process. UFT enables the
model to effectively explore solutions while incorporating informative
supervision signals, bridging the gap between memorizing and thinking
underlying existing methods. Notably, UFT outperforms both SFT and RFT in
general, regardless of model sizes. Furthermore, we theoretically prove that
UFT breaks RFT's inherent exponential sample complexity bottleneck, showing for
the first time that unified training can exponentially accelerate convergence
on long-horizon reasoning tasks.

</details>


### [121] [PICT -- A Differentiable, GPU-Accelerated Multi-Block PISO Solver for Simulation-Coupled Learning Tasks in Fluid Dynamics](https://arxiv.org/abs/2505.16992)
*Aleksandra Franz, Hao Wei, Luca Guastoni, Nils Thuerey*

**主要类别:** cs.LG

**概要:** 尽管几十年来取得了进步，流体模拟仍然是科学计算中最具挑战性的领域之一。由于深度学习中对梯度信息的需求，可微分模拟器已成为物理模拟优化和学习的有效工具。在这项工作中，我们提出了PICT，这是一个基于PyTorch的可微分压力隐式求解器，并支持GPU。我们在各种已建立的基准测试中验证了前向模拟和导出梯度的准确性，例如盖驱动腔和湍流通道流动。然后我们展示了求解器提供的梯度可以用于学习复杂的二维和三维湍流模型。我们使用监督和无监督训练方法，利用物理先验匹配流体统计特性。特别是，我们基于参考统计量学习了一个稳定的3D湍流通道流的子网格尺度（SGS）模型。通过我们的求解器训练的低分辨率校正器比高分辨率参考运行快得多，同时保持甚至超越其准确性。最后，我们提供了对不同求解器梯度的物理解释的额外见解，并激发了一种物理知情的正则化技术。为了确保PICT的全部潜力得以发挥，它作为开源发布：https://github.com/tum-pbs/PICT。


<details>
  <summary>更多</summary>
  
**动机:** 流体模拟是科学计算中最具有挑战性的领域之一，而可微分模拟器在深度学习中对于优化和学习至关重要。因此，开发一个高效、准确的可微分流体模拟器是非常重要的。

**方法:** 提出了一种名为PICT的可微分压力隐式求解器，该求解器基于PyTorch并支持GPU。首先，在多种基准测试中验证了前向模拟和梯度的准确性。然后，使用监督和无监督训练方法，利用物理先验来学习复杂的湍流模型。最后，探讨了求解器梯度的物理解释，并提出了一种物理知情的正则化技术。

**结果:** PICT能够在保证甚至超越高分辨率参考精度的同时，大幅提高运行速度。此外，通过对求解器梯度的深入分析，提出了物理知情的正则化技术，进一步提升了模型的稳定性和性能。

**结论:** PICT作为一个高效的可微分流体模拟器，不仅在速度上显著优于高分辨率参考，而且在精度上也表现出色。通过对求解器梯度的深入理解，提出了一种物理知情的正则化技术，这为未来的物理模拟研究提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PICT+--+A+Differentiable%2C+GPU-Accelerated+Multi-Block+PISO+Solver+for+Simulation-Coupled+Learning+Tasks+in+Fluid+Dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16992，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16992&send_immediately=true&force_search=false)

**原文摘要:** Despite decades of advancements, the simulation of fluids remains one of the
most challenging areas of in scientific computing. Supported by the necessity
of gradient information in deep learning, differentiable simulators have
emerged as an effective tool for optimization and learning in physics
simulations. In this work, we present our fluid simulator PICT, a
differentiable pressure-implicit solver coded in PyTorch with
Graphics-processing-unit (GPU) support. We first verify the accuracy of both
the forward simulation and our derived gradients in various established
benchmarks like lid-driven cavities and turbulent channel flows before we show
that the gradients provided by our solver can be used to learn complicated
turbulence models in 2D and 3D. We apply both supervised and unsupervised
training regimes using physical priors to match flow statistics. In particular,
we learn a stable sub-grid scale (SGS) model for a 3D turbulent channel flow
purely based on reference statistics. The low-resolution corrector trained with
our solver runs substantially faster than the highly resolved references, while
keeping or even surpassing their accuracy. Finally, we give additional insights
into the physical interpretation of different solver gradients, and motivate a
physically informed regularization technique. To ensure that the full potential
of PICT can be leveraged, it is published as open source:
https://github.com/tum-pbs/PICT.

</details>


### [122] [A Unified Framework for Simultaneous Parameter and Function Discovery in Differential Equations](https://arxiv.org/abs/2505.16996)
*Shalev Manor, Mohammad Kohandel*

**主要类别:** cs.LG

**概要:** 这篇论文提出了一种新框架，用于解决微分方程反问题中的非唯一性挑战，确保参数和函数的同时识别具有唯一解，并在生物和生态领域展示了准确且可解释的结果。


<details>
  <summary>更多</summary>
  
**动机:** 现有的方法如PINNs、UDEs和UPINNs在同时识别参数和函数时面临解的非唯一性问题，限制了其应用范围。

**方法:** 提出了一种新框架，通过建立保证唯一解的条件，解决了参数和函数同时识别时的非唯一性问题。

**结果:** 在生物系统和生态动力学的例子中，该方法展示了准确且可解释的结果。

**结论:** 该框架显著增强了机器学习技术在科学和工程复杂系统建模中的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Unified+Framework+for+Simultaneous+Parameter+and+Function+Discovery+in+Differential+Equations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16996，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16996&send_immediately=true&force_search=false)

**原文摘要:** Inverse problems involving differential equations often require identifying
unknown parameters or functions from data. Existing approaches, such as
Physics-Informed Neural Networks (PINNs), Universal Differential Equations
(UDEs) and Universal Physics-Informed Neural Networks (UPINNs), are effective
at isolating either parameters or functions but can face challenges when
applied simultaneously due to solution non-uniqueness. In this work, we
introduce a framework that addresses these limitations by establishing
conditions under which unique solutions can be guaranteed. To illustrate, we
apply it to examples from biological systems and ecological dynamics,
demonstrating accurate and interpretable results. Our approach significantly
enhances the potential of machine learning techniques in modeling complex
systems in science and engineering.

</details>


### [123] [When Are Concepts Erased From Diffusion Models?](https://arxiv.org/abs/2505.17013)
*Kevin Lu, Nicky Kriplani, Rohit Gandikota, Minh Pham, David Bau, Chinmay Hegde, Niv Cohen*

**主要类别:** cs.LG

**概要:** 这篇论文探讨了扩散模型中的概念擦除机制，提出了两种概念擦除模型，并引入了一套独立评估方法来判断概念是否被彻底擦除。研究结果强调了在减少副作用和保持对对抗性提示的鲁棒性之间的平衡，以及全面评估概念擦除的重要性。


<details>
  <summary>更多</summary>
  
**动机:** 随着对模型生成特定概念进行选择性阻止的兴趣日益增长，多种方法被提出以应对这一挑战。然而，目前尚不清楚这些方法在多大程度上能够彻底擦除目标概念。

**方法:** 作者提出了两种扩散模型中概念擦除的机制模型：(i) 降低生成目标概念的可能性；(ii) 干扰模型内部的引导机制。同时，为了评估概念是否被真正擦除，作者引入了一系列独立评估方法，包括对抗性攻击、新的探测技术以及分析模型在擦除概念后的替代生成内容。

**结果:** 研究结果揭示了在最小化副作用和维持对对抗性提示的鲁棒性之间的紧张关系。

**结论:** 本工作强调了对扩散模型中的概念擦除进行全面评估的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是When+Are+Concepts+Erased+From+Diffusion+Models%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.17013，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.17013&send_immediately=true&force_search=false)

**原文摘要:** Concept erasure, the ability to selectively prevent a model from generating
specific concepts, has attracted growing interest, with various approaches
emerging to address the challenge. However, it remains unclear how thoroughly
these methods erase the target concept. We begin by proposing two conceptual
models for the erasure mechanism in diffusion models: (i) reducing the
likelihood of generating the target concept, and (ii) interfering with the
model's internal guidance mechanisms. To thoroughly assess whether a concept
has been truly erased from the model, we introduce a suite of independent
evaluations. Our evaluation framework includes adversarial attacks, novel
probing techniques, and analysis of the model's alternative generations in
place of the erased concept. Our results shed light on the tension between
minimizing side effects and maintaining robustness to adversarial prompts.
Broadly, our work underlines the importance of comprehensive evaluation for
erasure in diffusion models.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [124] [Bandit based Dynamic Candidate Edge Selection in Solving Traveling Salesman Problems](https://arxiv.org/abs/2505.15862)
*Long Wanga, Jiongzhi Zheng, Zhengda Xiong, ChuMin Li, Kun He*

**主要类别:** cs.AI

**概要:** 使用多臂老虎机模型动态选择候选边以改进LKH算法在TSP问题上的表现。


<details>
  <summary>更多</summary>
  
**动机:** 经典LKH算法使用的预设候选边在局部搜索中保持静态，可能导致陷入局部最优解，限制了寻找更优解的潜力。

**方法:** 通过扩展候选集并加入有希望的边，结合多臂老虎机模型动态选择每次迭代中最合适的候选边，从而提升LKH算法的性能。

**结果:** 大量实验表明，该方法在多个TSP基准测试中表现出色，并显著提升了LKH-3在典型TSP变种问题上的性能。

**结论:** 提出的基于多臂老虎机的方法可以有效改善LKH和LKH-3算法在解决TSP及其变种问题中的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bandit+based+Dynamic+Candidate+Edge+Selection+in+Solving+Traveling+Salesman+Problems，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15862，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15862&send_immediately=true&force_search=false)

**原文摘要:** Algorithms designed for routing problems typically rely on high-quality
candidate edges to guide their search, aiming to reduce the search space and
enhance the search efficiency. However, many existing algorithms, like the
classical Lin-Kernighan-Helsgaun (LKH) algorithm for the Traveling Salesman
Problem (TSP), often use predetermined candidate edges that remain static
throughout local searches. This rigidity could cause the algorithm to get
trapped in local optima, limiting its potential to find better solutions. To
address this issue, we propose expanding the candidate sets to include other
promising edges, providing them an opportunity for selection. Specifically, we
incorporate multi-armed bandit models to dynamically select the most suitable
candidate edges in each iteration, enabling LKH to make smarter choices and
lead to improved solutions. Extensive experiments on multiple TSP benchmarks
show the excellent performance of our method. Moreover, we employ this
bandit-based method to LKH-3, an extension of LKH tailored for solving various
TSP variant problems, and our method also significantly enhances LKH-3's
performance across typical TSP variants.

</details>


### [125] [PhyX: Does Your Model Have the "Wits" for Physical Reasoning?](https://arxiv.org/abs/2505.15929)
*Hui Shen, Taiqiang Wu, Qi Han, Yunta Hsieh, Jizhou Wang, Yuyue Zhang, Yuxin Cheng, Zijian Hao, Yuansheng Ni, Xin Wang, Zhongwei Wan, Kai Zhang, Wendong Xu, Jing Xiong, Ping Luo, Wenhu Chen, Chaofan Tao, Zhuoqing Mao, Ngai Wong*

**主要类别:** cs.AI

**概要:** 现有的基准测试未能捕捉到智能的一个关键方面：物理推理。为填补这一空白，我们引入了PhyX，这是第一个大规模基准，旨在评估模型在视觉场景中基于物理的推理能力。PhyX包含3K个精心策划的多模态问题，涵盖了6种推理类型、25个子领域和6个核心物理领域。即使是最先进的模型在物理推理方面也显著挣扎。我们的分析揭示了当前模型的关键局限性，并通过详细的统计、案例研究和多种评估范式提供了深入分析。为确保可重复性，我们基于广泛使用的工具包实现了兼容的评估协议，使一键评估成为可能。


<details>
  <summary>更多</summary>
  
**动机:** 现有基准测试未能捕捉到智能的一个关键方面：物理推理，即结合领域知识、符号推理和理解现实世界约束的综合能力。

**方法:** 引入了PhyX，一个大规模基准测试，包含3K个精心策划的多模态问题，涵盖6种推理类型、25个子领域和6个核心物理领域（热力学、电磁学、力学、现代物理学、光学和波声学）。采用兼容的评估协议并使用广泛使用的工具包如VLMEvalKit实现一键评估。

**结果:** 即使是最先进的模型（如GPT-4o、Claude3.7-Sonnet和GPT-o4-mini）在物理推理方面的表现分别仅为32.5%、42.2%和45.8%，与人类专家相比性能差距超过29%。当前模型存在关键局限性，例如过度依赖记忆中的学科知识、数学公式和表面级别的视觉模式匹配。

**结论:** PhyX揭示了当前模型在物理推理方面的显著不足，强调需要进一步改进以达到更深层次的理解和推理能力。提供的详细分析和评估框架有助于未来的研究和发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PhyX%3A+Does+Your+Model+Have+the+%22Wits%22+for+Physical+Reasoning%3F，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15929，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15929&send_immediately=true&force_search=false)

**原文摘要:** Existing benchmarks fail to capture a crucial aspect of intelligence:
physical reasoning, the integrated ability to combine domain knowledge,
symbolic reasoning, and understanding of real-world constraints. To address
this gap, we introduce PhyX: the first large-scale benchmark designed to assess
models capacity for physics-grounded reasoning in visual scenarios. PhyX
includes 3K meticulously curated multimodal questions spanning 6 reasoning
types across 25 sub-domains and 6 core physics domains: thermodynamics,
electromagnetism, mechanics, modern physics, optics, and wave\&acoustics. In
our comprehensive evaluation, even state-of-the-art models struggle
significantly with physical reasoning. GPT-4o, Claude3.7-Sonnet, and
GPT-o4-mini achieve only 32.5\%, 42.2\%, and 45.8\% accuracy
respectively-performance gaps exceeding 29\% compared to human experts. Our
analysis exposes critical limitations in current models: over-reliance on
memorized disciplinary knowledge, excessive dependence on mathematical
formulations, and surface-level visual pattern matching rather than genuine
physical understanding. We provide in-depth analysis through fine-grained
statistics, detailed case studies, and multiple evaluation paradigms to
thoroughly examine physical reasoning capabilities. To ensure reproducibility,
we implement a compatible evaluation protocol based on widely-used toolkits
such as VLMEvalKit, enabling one-click evaluation.

</details>


### [126] [Exploring Flow-Lenia Universes with a Curiosity-driven AI Scientist: Discovering Diverse Ecosystem Dynamics](https://arxiv.org/abs/2505.15998)
*Thomas Michel, Marko Cvjetko, Gautier Hamon, Pierre-Yves Oudeyer, Clément Moulin-Frier*

**主要类别:** cs.AI

**概要:** 本论文提出了一种使用好奇心驱动的人工智能科学家，在Flow-Lenia（具有质量守恒和参数局部化的连续细胞自动机）中自动发现系统级动态的方法。该方法通过在大型环境中探索不同的相互作用模式，揭示了细胞自动机中导致自我组织的进化和生态系统动态的过程。相比随机搜索，该方法能够显著展现更多样化的动态，并展示了如何通过生态系统模拟实现复杂集体行为的自我组织。此外，还提供了一个交互式探索工具，以促进人类与AI协作进行科学研究。虽然此方法在Flow-Lenia中进行了演示，但它为理解其他可参数化的复杂系统的涌现集体特性提供了潜在框架。


<details>
  <summary>更多</summary>
  
**动机:** 之前的研究已经在Lenia中使用多样性搜索算法找到了自我组织的个体模式，但这些研究主要集中在小型环境中的单一模式上。本文旨在扩展这一研究，探索支持不同相互作用模式的大环境，并揭示细胞自动机中更复杂的自组织过程。

**方法:** 研究者采用内在动机目标探索过程（IMGEPs），结合全仿真范围的度量标准（如进化活动、基于压缩的复杂性和多尺度熵），来驱动对多样化Flow-Lenia环境的探索。通过两个实验验证了该方法的有效性，表明其相较于随机搜索能发现更多的动态。

**结果:** 实验结果表明，该方法能够显著展示更多样化的动态。定性结果显示，生态系统模拟能够使复杂的集体行为自我组织，而这些行为是以前个体模式搜索和分析所无法捕捉到的。

**结论:** 本研究提出的方法成功地在Flow-Lenia中揭示了复杂集体行为的自我组织过程，并且通过人机协作的工作流程增强了科学探索的能力。该方法不仅适用于Flow-Lenia，还可以推广到其他需要理解涌现集体特性的复杂系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exploring+Flow-Lenia+Universes+with+a+Curiosity-driven+AI+Scientist%3A+Discovering+Diverse+Ecosystem+Dynamics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15998，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15998&send_immediately=true&force_search=false)

**原文摘要:** We present a method for the automated discovery of system-level dynamics in
Flow-Lenia$-$a continuous cellular automaton (CA) with mass conservation and
parameter localization$-$using a curiosity-driven AI scientist. This method
aims to uncover processes leading to self-organization of evolutionary and
ecosystemic dynamics in CAs. We build on previous work which uses diversity
search algorithms in Lenia to find self-organized individual patterns, and
extend it to large environments that support distinct interacting patterns. We
adapt Intrinsically Motivated Goal Exploration Processes (IMGEPs) to drive
exploration of diverse Flow-Lenia environments using simulation-wide metrics,
such as evolutionary activity, compression-based complexity, and multi-scale
entropy. We test our method in two experiments, showcasing its ability to
illuminate significantly more diverse dynamics compared to random search. We
show qualitative results illustrating how ecosystemic simulations enable
self-organization of complex collective behaviors not captured by previous
individual pattern search and analysis. We complement automated discovery with
an interactive exploration tool, creating an effective human-AI collaborative
workflow for scientific investigation. Though demonstrated specifically with
Flow-Lenia, this methodology provides a framework potentially applicable to
other parameterizable complex systems where understanding emergent collective
properties is of interest.

</details>


### [127] [Children's Mental Models of AI Reasoning: Implications for AI Literacy Education](https://arxiv.org/abs/2505.16031)
*Aayushi Dangol, Robert Wolfe, Runhua Zhao, JaeWon Kim, Trushaa Ramanan, Katie Davis, Julie A. Kientz*

**主要类别:** cs.AI

**概要:** The paper explores how children conceptualize AI reasoning through a two-phase study, revealing three models of AI reasoning and differences in understanding between younger and older children.


<details>
  <summary>更多</summary>
  
**动机:** To foster AI literacy among children by understanding their mental models of AI reasoning processes.

**方法:** A two-phase approach involving a co-design session with 8 children followed by a field study with 106 children (grades 3-8).

**结果:** Identified three models of AI reasoning: Deductive, Inductive, and Inherent. Younger children attribute AI's reasoning to inherent intelligence while older children recognize AI as a pattern recognizer.

**结论:** Highlights three tensions in children's understanding of AI reasoning and provides implications for designing AI curricula and explainable AI tools.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Children%27s+Mental+Models+of+AI+Reasoning%3A+Implications+for+AI+Literacy+Education，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16031，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16031&send_immediately=true&force_search=false)

**原文摘要:** As artificial intelligence (AI) advances in reasoning capabilities, most
recently with the emergence of Large Reasoning Models (LRMs), understanding how
children conceptualize AI's reasoning processes becomes critical for fostering
AI literacy. While one of the "Five Big Ideas" in AI education highlights
reasoning algorithms as central to AI decision-making, less is known about
children's mental models in this area. Through a two-phase approach, consisting
of a co-design session with 8 children followed by a field study with 106
children (grades 3-8), we identified three models of AI reasoning: Deductive,
Inductive, and Inherent. Our findings reveal that younger children (grades 3-5)
often attribute AI's reasoning to inherent intelligence, while older children
(grades 6-8) recognize AI as a pattern recognizer. We highlight three tensions
that surfaced in children's understanding of AI reasoning and conclude with
implications for scaffolding AI curricula and designing explainable AI tools.

</details>


### [128] [Causal LLM Routing: End-to-End Regret Minimization from Observational Data](https://arxiv.org/abs/2505.16037)
*Asterios Tsiourvas, Wei Sun, Georgia Perakis*

**主要类别:** cs.AI

**概要:** LLM routing focuses on selecting the best model for each query by balancing accuracy and cost. Unlike previous methods that predict metrics first then select models, leading to potential compounding errors and reliance on costly full-feedback data, this paper proposes a causal end-to-end framework that learns from observational data by minimizing decision-making regret. The authors introduce two surrogate objectives for efficient optimization and extend their framework to handle varying cost preferences. Experiments show state-of-the-art performance.


<details>
  <summary>更多</summary>
  
**动机:** Existing LLM routing methods use a decoupled strategy of predicting metrics before model selection, which is prone to compounding errors and depends on expensive full-feedback data. There is a need for a more effective and efficient method that can learn from observational data.

**方法:** The paper proposes a causal end-to-end framework for learning routing policies by minimizing decision-making regret from observational data. Two theoretically grounded surrogate objectives are introduced for efficient optimization: a classification-based upper bound and a softmax-weighted regret approximation. Additionally, an interval-conditioned architecture is used to handle heterogeneous cost preferences.

**结果:** Experiments conducted on public benchmarks demonstrate that the proposed method outperforms existing baselines, achieving state-of-the-art performance across different embedding models.

**结论:** The proposed causal end-to-end framework for LLM routing effectively learns from observational data, reducing decision-making regret and handling heterogeneous cost preferences. It achieves superior performance compared to existing methods.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Causal+LLM+Routing%3A+End-to-End+Regret+Minimization+from+Observational+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16037，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16037&send_immediately=true&force_search=false)

**原文摘要:** LLM routing aims to select the most appropriate model for each query,
balancing competing performance metrics such as accuracy and cost across a pool
of language models. Prior approaches typically adopt a decoupled strategy,
where the metrics are first predicted and the model is then selected based on
these estimates. This setup is prone to compounding errors and often relies on
full-feedback data, where each query is evaluated by all candidate models,
which is costly to obtain and maintain in practice. In contrast, we learn from
observational data, which records only the outcome of the model actually
deployed. We propose a causal end-to-end framework that learns routing policies
by minimizing decision-making regret from observational data. To enable
efficient optimization, we introduce two theoretically grounded surrogate
objectives: a classification-based upper bound, and a softmax-weighted regret
approximation shown to recover the optimal policy at convergence. We further
extend our framework to handle heterogeneous cost preferences via an
interval-conditioned architecture. Experiments on public benchmarks show that
our method outperforms existing baselines, achieving state-of-the-art
performance across different embedding models.

</details>


### [129] [SPhyR: Spatial-Physical Reasoning Benchmark on Material Distribution](https://arxiv.org/abs/2505.16048)
*Philipp D. Siedler*

**主要类别:** cs.AI

**概要:** 生成一个过长；没有阅读的总结


<details>
  <summary>更多</summary>
  
**动机:** 描述本文中的动机

**方法:** 本文的方法

**结果:** 本文的结果

**结论:** 本文的结论

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SPhyR%3A+Spatial-Physical+Reasoning+Benchmark+on+Material+Distribution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16048，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16048&send_immediately=true&force_search=false)

**原文摘要:** We introduce a novel dataset designed to benchmark the physical and spatial
reasoning capabilities of Large Language Models (LLM) based on topology
optimization, a method for computing optimal material distributions within a
design space under prescribed loads and supports. In this dataset, LLMs are
provided with conditions such as 2D boundary, applied forces and supports, and
must reason about the resulting optimal material distribution. The dataset
includes a variety of tasks, ranging from filling in masked regions within
partial structures to predicting complete material distributions. Solving these
tasks requires understanding the flow of forces and the required material
distribution under given constraints, without access to simulation tools or
explicit physical models, challenging models to reason about structural
stability and spatial organization. Our dataset targets the evaluation of
spatial and physical reasoning abilities in 2D settings, offering a
complementary perspective to traditional language and logic benchmarks.

</details>


### [130] [How Memory Management Impacts LLM Agents: An Empirical Study of Experience-Following Behavior](https://arxiv.org/abs/2505.16067)
*Zidi Xiong, Yuping Lin, Wenya Xie, Pengfei He, Jiliang Tang, Himabindu Lakkaraju, Zhen Xiang*

**主要类别:** cs.AI

**概要:** 在大型语言模型（LLM）代理中，记忆管理对其长期性能至关重要。本文通过经验研究发现，添加和删除记忆操作对代理行为有显著影响，并揭示了经验跟随属性带来的错误传播和经验回放错位两大挑战。通过结合选择性添加和删除策略，可以有效缓解这些问题，提升10%的绝对性能。此外，研究还探讨了任务分布变化和受限内存条件下的记忆管理影响，为设计稳健的长期代理性能支持的记忆组件提供了实际指导。


<details>
  <summary>更多</summary>
  
**动机:** 研究记忆管理决策对LLM代理行为，特别是长期性能的影响，以改进代理的任务表现。

**方法:** 聚焦于两种基本记忆操作——添加（将新体验纳入记忆库）和删除（选择性移除过往体验），并通过定量分析研究其对代理行为的影响。识别出经验跟随属性及其引发的错误传播和经验回放错位问题，再通过受控实验验证选择性添加和删除策略的效果。

**结果:** 发现代理表现出经验跟随属性，揭示了错误传播和经验回放错位两大挑战。选择性添加和删除策略可使性能平均绝对提升10%，并在任务分布变化和受限内存条件下提供进一步见解。

**结论:** 记忆管理决策显著影响LLM代理的行为动态，研究结果为设计支持稳健长期性能的记忆组件提供了实用指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+Memory+Management+Impacts+LLM+Agents%3A+An+Empirical+Study+of+Experience-Following+Behavior，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16067，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16067&send_immediately=true&force_search=false)

**原文摘要:** Memory is a critical component in large language model (LLM)-based agents,
enabling them to store and retrieve past executions to improve task performance
over time. In this paper, we conduct an empirical study on how memory
management choices impact the LLM agents' behavior, especially their long-term
performance. Specifically, we focus on two fundamental memory operations that
are widely used by many agent frameworks-addition, which incorporates new
experiences into the memory base, and deletion, which selectively removes past
experiences-to systematically study their impact on the agent behavior. Through
our quantitative analysis, we find that LLM agents display an
experience-following property: high similarity between a task input and the
input in a retrieved memory record often results in highly similar agent
outputs. Our analysis further reveals two significant challenges associated
with this property: error propagation, where inaccuracies in past experiences
compound and degrade future performance, and misaligned experience replay,
where outdated or irrelevant experiences negatively influence current tasks.
Through controlled experiments, we show that combining selective addition and
deletion strategies can help mitigate these negative effects, yielding an
average absolute performance gain of 10% compared to naive memory growth.
Furthermore, we highlight how memory management choices affect agents' behavior
under challenging conditions such as task distribution shifts and constrained
memory resources. Our findings offer insights into the behavioral dynamics of
LLM agent memory systems and provide practical guidance for designing memory
components that support robust, long-term agent performance. We also release
our code to facilitate further study.

</details>


### [131] [SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation](https://arxiv.org/abs/2505.16080)
*Jiayue Liu, Zhongchao Yi, Zhengyang Zhou, Qihe Huang, Kuo Yang, Xu Wang, Yang Wang*

**主要类别:** cs.AI

**概要:** SynEVO是一种受神经科学启发的时空网络，通过跨域集体智能学习提升泛化能力，最高可提高42%。


<details>
  <summary>更多</summary>
  
**动机:** 当前时空学习模型通常从特定源数据中训练独立模型，导致在源之间的可迁移性有限，即使相关任务也需要重新设计和训练。因此需要一种能够实现集体智能和模型演化的解决方案。

**方法:** 提出了一种名为SynEVO的突触进化时空网络。该方法首先对样本组进行重新排序以模仿人类课程学习，并设计了两种互补的学习器：弹性公共容器和任务无关提取器，允许模型增长及共性和个性的解缠。此外，还引入了带有新差异度量的自适应动态耦合器，用于确定新样本组是否应纳入公共容器以实现跨域模型演化。

**结果:** 实验表明，SynEVO在跨域场景下最多可以将泛化能力提高42%，并为知识转移和适应提供了一种NeuroAI范式。

**结论:** SynEVO通过跨域集体智能学习显著提升了模型的泛化能力，证明了其在知识转移和适应方面的有效性，为未来研究提供了新的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SynEVO%3A+A+neuro-inspired+spatiotemporal+evolutional+framework+for+cross-domain+adaptation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16080，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16080&send_immediately=true&force_search=false)

**原文摘要:** Discovering regularities from spatiotemporal systems can benefit various
scientific and social planning. Current spatiotemporal learners usually train
an independent model from a specific source data that leads to limited
transferability among sources, where even correlated tasks requires new design
and training. The key towards increasing cross-domain knowledge is to enable
collective intelligence and model evolution. In this paper, inspired by
neuroscience theories, we theoretically derive the increased information
boundary via learning cross-domain collective intelligence and propose a
Synaptic EVOlutional spatiotemporal network, SynEVO, where SynEVO breaks the
model independence and enables cross-domain knowledge to be shared and
aggregated. Specifically, we first re-order the sample groups to imitate the
human curriculum learning, and devise two complementary learners, elastic
common container and task-independent extractor to allow model growth and
task-wise commonality and personality disentanglement. Then an adaptive dynamic
coupler with a new difference metric determines whether the new sample group
should be incorporated into common container to achieve model evolution under
various domains. Experiments show that SynEVO improves the generalization
capacity by at most 42% under cross-domain scenarios and SynEVO provides a
paradigm of NeuroAI for knowledge transfer and adaptation.

</details>


### [132] [Optimizing LLM-Based Multi-Agent System with Textual Feedback: A Case Study on Software Development](https://arxiv.org/abs/2505.16086)
*Ming Shen, Raphael Shu, Anurag Pratik, James Gung, Yubin Ge, Monica Sunkara, Yi Zhang*

**主要类别:** cs.AI

**概要:** 本研究提出了一种针对基于角色的多智能体系统的两步优化管道，通过自然语言反馈识别表现不佳的智能体并优化其系统提示，展示了在软件开发任务中的有效性，并探讨了不同优化设置对多智能体系统群体行为的影响。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLM）驱动的多智能体系统在解决需要跨技能专家协作的复杂任务方面取得了显著进展，但优化这些系统仍然具有挑战性。

**方法:** 研究提出了一种两步优化管道：1) 通过文本反馈识别表现不佳的智能体及其失败原因；2) 利用失败解释优化已识别智能体的系统提示。此外，研究比较了在线与离线优化、个体与群体优化的效果，并探讨了一次性和多轮提示优化策略。

**结果:** 实验结果表明，该优化方法在处理软件开发任务时是有效的，并且不同的优化设置对多智能体系统的群体行为产生了影响。

**结论:** 该研究证明了所提出的优化方法的有效性，并为未来基于角色的多智能体系统的发展提供了实际见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Optimizing+LLM-Based+Multi-Agent+System+with+Textual+Feedback%3A+A+Case+Study+on+Software+Development，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16086，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16086&send_immediately=true&force_search=false)

**原文摘要:** We have seen remarkable progress in large language models (LLMs) empowered
multi-agent systems solving complex tasks necessitating cooperation among
experts with diverse skills. However, optimizing LLM-based multi-agent systems
remains challenging. In this work, we perform an empirical case study on group
optimization of role-based multi-agent systems utilizing natural language
feedback for challenging software development tasks under various evaluation
dimensions. We propose a two-step agent prompts optimization pipeline:
identifying underperforming agents with their failure explanations utilizing
textual feedback and then optimizing system prompts of identified agents
utilizing failure explanations. We then study the impact of various
optimization settings on system performance with two comparison groups: online
against offline optimization and individual against group optimization. For
group optimization, we study two prompting strategies: one-pass and multi-pass
prompting optimizations. Overall, we demonstrate the effectiveness of our
optimization method for role-based multi-agent systems tackling software
development tasks evaluated on diverse evaluation dimensions, and we
investigate the impact of diverse optimization settings on group behaviors of
the multi-agent systems to provide practical insights for future development.

</details>


### [133] [Can AI Read Between The Lines? Benchmarking LLMs On Financial Nuance](https://arxiv.org/abs/2505.16090)
*Dominick Kubica, Dylan T. Gordon, Nanami Emura, Derleen Saini, Charlie Goldenberg*

**主要类别:** cs.AI

**概要:** 到2025年，生成式人工智能（GenAI）已成为跨行业提高生产力的核心工具。尽管大型语言模型（LLMs）在处理日常语言情感分析方面表现出色，但在财务领域，它们难以准确解析盈余电话会议记录中的模糊语言和专业术语。本研究通过评估Microsoft Copilot、OpenAI的ChatGPT、Google的Gemini及传统机器学习模型对金融文本情感分析的表现，探讨这些模型输出的情感与市场情绪和股票变动的相关性，并通过提示工程技术和可视化方法进一步改进和评估模型表现。


<details>
  <summary>更多</summary>
  
**动机:** 生成式人工智能（GenAI）在各行业的广泛应用促使人们需要评估其在高风险领域的可靠性和准确性，特别是在金融领域中。由于金融披露常包含模糊陈述、前瞻语言和行业术语，这对LLMs的情感分析能力提出了挑战。因此，研究者希望了解不同LLMs和传统机器学习模型在金融文本情感分析中的表现，以期提升其准确性和可靠性。

**方法:** 1. 选择Microsoft Copilot、OpenAI的ChatGPT、Google的Gemini和传统机器学习模型进行比较。
2. 使用Microsoft盈余电话会议记录作为数据源，进行情感分析。
3. 通过提示工程技术优化情感分析结果。
4. 开发可视化方法评估情感一致性，分析情感趋势与股票表现之间的关系。
5. 考察Microsoft各业务线对整体影响的程度。

**结果:** 研究发现，大型语言模型在金融文本情感分析中存在一定的局限性，尤其是在处理包含模糊语言和行业术语的内容时。通过提示工程技术可以有效改善情感分析的结果。此外，研究还揭示了不同业务线对整体情感分析的影响程度，有助于更深入地理解市场反应。

**结论:** 尽管大型语言模型在一般语言情感分析方面表现出色，但它们在金融领域中的应用仍需谨慎对待。提示工程技术能够显著提升模型的性能，而可视化方法则为评估模型表现提供了有力工具。未来的研究应继续探索如何进一步优化这些模型，以更好地适应金融领域的特殊需求。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Can+AI+Read+Between+The+Lines%3F+Benchmarking+LLMs+On+Financial+Nuance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16090，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16090&send_immediately=true&force_search=false)

**原文摘要:** As of 2025, Generative Artificial Intelligence (GenAI) has become a central
tool for productivity across industries. Beyond text generation, GenAI now
plays a critical role in coding, data analysis, and research workflows. As
large language models (LLMs) continue to evolve, it is essential to assess the
reliability and accuracy of their outputs, especially in specialized,
high-stakes domains like finance. Most modern LLMs transform text into
numerical vectors, which are used in operations such as cosine similarity
searches to generate responses. However, this abstraction process can lead to
misinterpretation of emotional tone, particularly in nuanced financial
contexts. While LLMs generally excel at identifying sentiment in everyday
language, these models often struggle with the nuanced, strategically ambiguous
language found in earnings call transcripts. Financial disclosures frequently
embed sentiment in hedged statements, forward-looking language, and
industry-specific jargon, making it difficult even for human analysts to
interpret consistently, let alone AI models. This paper presents findings from
the Santa Clara Microsoft Practicum Project, led by Professor Charlie
Goldenberg, which benchmarks the performance of Microsoft's Copilot, OpenAI's
ChatGPT, Google's Gemini, and traditional machine learning models for sentiment
analysis of financial text. Using Microsoft earnings call transcripts, the
analysis assesses how well LLM-derived sentiment correlates with market
sentiment and stock movements and evaluates the accuracy of model outputs.
Prompt engineering techniques are also examined to improve sentiment analysis
results. Visualizations of sentiment consistency are developed to evaluate
alignment between tone and stock performance, with sentiment trends analyzed
across Microsoft's lines of business to determine which segments exert the
greatest influence.

</details>


### [134] [TrialPanorama: Database and Benchmark for Systematic Review and Design of Clinical Trials](https://arxiv.org/abs/2505.16097)
*Zifeng Wang, Qiao Jin, Jiacheng Lin, Junyi Gao, Jathurshan Pradeepkumar, Pengcheng Jiang, Benjamin Danek, Zhiyong Lu, Jimeng Sun*

**主要类别:** cs.AI

**概要:** 本论文介绍了TrialPanorama，一个包含1,657,476个临床试验记录的大规模结构化数据库。该数据库从15个全球来源聚合数据，并链接到标准的生物医学本体论，如DrugBank和MedDRA。为了展示其效用，作者从TrialPanorama数据库中衍生出一系列基准任务，包括系统评价和试验设计相关的任务。实验使用五个最先进的大语言模型（LLMs）表明，通用的LLMs虽然具备一定的零样本能力，但它们的表现仍然不足以满足高风险的临床试验工作流程。


<details>
  <summary>更多</summary>
  
**动机:** 开发适用于垂直领域的AI需要坚实的训练和评估数据基础。现有的临床试验数据分散且非结构化，限制了AI在这一领域的发展。因此，需要一个统一、可扩展的资源来支持各种临床试验任务。

**方法:** 构建了一个名为TrialPanorama的大规模结构化数据库，其中包括1,657,476个临床试验记录，从15个全球来源聚合数据，并与标准生物医学本体论（如DrugBank和MedDRA）相关联。基于此数据库，定义了一套基准任务，涵盖系统评价和试验设计两大类共八个任务。使用五个最先进的大语言模型对这些任务进行了实验评估。

**结果:** 实验结果显示，尽管通用的大语言模型在某些任务上表现出一定的零样本能力，但其性能仍不足以应对临床试验中的高风险工作流程。这表明，在临床试验领域，需要更专业的AI模型和方法。

**结论:** TrialPanorama作为一个大规模结构化数据库，为临床试验相关任务提供了一个统一、可扩展的资源。然而，现有的通用大语言模型在处理高风险临床试验工作时表现不足，需要进一步研究和发展更专业化的AI模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TrialPanorama%3A+Database+and+Benchmark+for+Systematic+Review+and+Design+of+Clinical+Trials，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16097，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16097&send_immediately=true&force_search=false)

**原文摘要:** Developing artificial intelligence (AI) for vertical domains requires a solid
data foundation for both training and evaluation. In this work, we introduce
TrialPanorama, a large-scale, structured database comprising 1,657,476 clinical
trial records aggregated from 15 global sources. The database captures key
aspects of trial design and execution, including trial setups, interventions,
conditions, biomarkers, and outcomes, and links them to standard biomedical
ontologies such as DrugBank and MedDRA. This structured and ontology-grounded
design enables TrialPanorama to serve as a unified, extensible resource for a
wide range of clinical trial tasks, including trial planning, design, and
summarization. To demonstrate its utility, we derive a suite of benchmark tasks
directly from the TrialPanorama database. The benchmark spans eight tasks
across two categories: three for systematic review (study search, study
screening, and evidence summarization) and five for trial design (arm design,
eligibility criteria, endpoint selection, sample size estimation, and trial
completion assessment). The experiments using five state-of-the-art large
language models (LLMs) show that while general-purpose LLMs exhibit some
zero-shot capability, their performance is still inadequate for high-stakes
clinical trial workflows. We release TrialPanorama database and the benchmark
to facilitate further research on AI for clinical trials.

</details>


### [135] [BioDSA-1K: Benchmarking Data Science Agents for Biomedical Research](https://arxiv.org/abs/2505.16100)
*Zifeng Wang, Benjamin Danek, Jimeng Sun*

**主要类别:** cs.AI

**概要:** 论文介绍了BioDSA-1K，一个用于评估AI在生物医学假设验证任务中的基准。该基准包括1029个假设验证任务和1177个分析计划，来自300多项已发表的生物医学研究。其目的是从四个维度评估AI：假设决策准确性、证据与结论的一致性、推理过程的正确性以及生成的分析代码的可执行性。此外，BioDSA-1K还包含无法验证的假设，以反映现实科学研究中的常见情况。


<details>
  <summary>更多</summary>
  
**动机:** 科学假设验证是生物医学研究中的核心挑战，但AI在这一领域仍面临困难，特别是在复杂的真实世界数据处理和证据解释方面。因此，需要一个专门设计的基准来测试AI在生物医学假设验证中的能力。

**方法:** 构建了一个名为BioDSA-1K的基准，其中包括1029个假设验证任务和1177个分析计划，这些内容来源于超过300项已发表的生物医学研究。每个任务都包含一个结构化的假设及其支持证据，并可通过标准统计或机器学习方法进行验证。基准允许从四个维度进行评估：假设决策准确性、证据与结论的一致性、推理过程的正确性以及生成分析代码的可执行性。此外，还包括了不可验证的假设。

**结果:** BioDSA-1K为评估AI在生物医学假设验证中的表现提供了一个全面的框架，能够涵盖真实科学研究中的多种场景，特别是那些数据不足以支持或反驳假设的情况。

**结论:** BioDSA-1K为开发和评估通用且值得信赖的AI代理提供了基础，旨在推动生物医学发现领域的进步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BioDSA-1K%3A+Benchmarking+Data+Science+Agents+for+Biomedical+Research，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16100，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16100&send_immediately=true&force_search=false)

**原文摘要:** Validating scientific hypotheses is a central challenge in biomedical
research, and remains difficult for artificial intelligence (AI) agents due to
the complexity of real-world data analysis and evidence interpretation. In this
work, we present BioDSA-1K, a benchmark designed to evaluate AI agents on
realistic, data-driven biomedical hypothesis validation tasks. BioDSA-1K
consists of 1,029 hypothesis-centric tasks paired with 1,177 analysis plans,
curated from over 300 published biomedical studies to reflect the structure and
reasoning found in authentic research workflows. Each task includes a
structured hypothesis derived from the original study's conclusions, expressed
in the affirmative to reflect the language of scientific reporting, and one or
more pieces of supporting evidence grounded in empirical data tables. While
these hypotheses mirror published claims, they remain testable using standard
statistical or machine learning methods. The benchmark enables evaluation along
four axes: (1) hypothesis decision accuracy, (2) alignment between evidence and
conclusion, (3) correctness of the reasoning process, and (4) executability of
the AI-generated analysis code. Importantly, BioDSA-1K includes non-verifiable
hypotheses: cases where the available data are insufficient to support or
refute a claim, reflecting a common yet underexplored scenario in real-world
science. We propose BioDSA-1K as a foundation for building and evaluating
generalizable, trustworthy AI agents for biomedical discovery.

</details>


### [136] [Logic-of-Thought: Empowering Large Language Models with Logic Programs for Solving Puzzles in Natural Language](https://arxiv.org/abs/2505.16114)
*Naiqi Li, Peiyuan Liu, Zheng Liu, Tao Dai, Yong Jiang, Shu-Tao Xia*

**主要类别:** cs.AI

**概要:** 为了解决自然语言中的复杂谜题，本文提出了Logic-of-Thought框架，结合大语言模型和逻辑编程，将谜题规则转化为可精确求解的程序，实验表明该方法在多种谜题上接近完美准确率。


<details>
  <summary>更多</summary>
  
**动机:** 解决自然语言中的复杂谜题是AI领域长期存在的挑战，尽管大语言模型在许多任务中表现出色，但在需要精确推理和穷举搜索的复杂谜题上仍然表现不佳。

**方法:** 提出Logic-of-Thought（Logot）框架，利用大语言模型将谜题规则和状态翻译成答案集程序（ASP），然后由ASP解释器准确高效地推断解决方案。这种方法结合了大语言模型的自然语言理解和逻辑程序的精确推理能力。

**结果:** 在各种网格谜题和涉及动作的动态谜题上评估该方法，结果显示在所有任务中几乎达到完美准确度。

**结论:** Logic-of-Thought框架成功地将大语言模型与逻辑编程结合起来，解决了需要精确推理的复杂谜题，并在实验中展现了优异的表现。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Logic-of-Thought%3A+Empowering+Large+Language+Models+with+Logic+Programs+for+Solving+Puzzles+in+Natural+Language，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16114，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16114&send_immediately=true&force_search=false)

**原文摘要:** Solving puzzles in natural language poses a long-standing challenge in AI.
While large language models (LLMs) have recently shown impressive capabilities
in a variety of tasks, they continue to struggle with complex puzzles that
demand precise reasoning and exhaustive search. In this paper, we propose
Logic-of-Thought (Logot), a novel framework that bridges LLMs with logic
programming to address this problem. Our method leverages LLMs to translate
puzzle rules and states into answer set programs (ASPs), the solution of which
are then accurately and efficiently inferred by an ASP interpreter. This hybrid
approach combines the natural language understanding of LLMs with the precise
reasoning capabilities of logic programs. We evaluate our method on various
grid puzzles and dynamic puzzles involving actions, demonstrating near-perfect
accuracy across all tasks. Our code and data are available at:
https://github.com/naiqili/Logic-of-Thought.

</details>


### [137] [LLM-Powered AI Agent Systems and Their Applications in Industry](https://arxiv.org/abs/2505.16120)
*Guannan Liang, Qianqian Tong*

**主要类别:** cs.AI

**概要:** 大型语言模型（LLMs）重塑了代理系统，使其更灵活、跨域推理能力强且能进行自然语言交互。多模态LLM集成后，当前代理系统能够处理多种数据类型。本文回顾了从预LLM时代到现今的架构演变，并分类探讨了其在多个领域的应用，同时指出了面临的挑战及潜在解决方案。


<details>
  <summary>更多</summary>
  
**动机:** 研究动机在于探索大型语言模型（LLMs）如何改变代理系统，以及这些新系统在实际应用中的潜力和限制。

**方法:** 通过文献综述和案例分析的方法，对代理系统的演进进行了全面评估，并按软件、物理和自适应混合系统分类讨论了其应用。

**结果:** 发现LLM驱动的代理系统在灵活性、跨域推理和自然语言交互方面有显著提升，但也存在诸如高推理延迟、输出不确定性等挑战。

**结论:** LLM驱动的代理系统具有巨大的潜力，但需要解决技术挑战以实现更广泛和安全的应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LLM-Powered+AI+Agent+Systems+and+Their+Applications+in+Industry，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16120，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16120&send_immediately=true&force_search=false)

**原文摘要:** The emergence of Large Language Models (LLMs) has reshaped agent systems.
Unlike traditional rule-based agents with limited task scope, LLM-powered
agents offer greater flexibility, cross-domain reasoning, and natural language
interaction. Moreover, with the integration of multi-modal LLMs, current agent
systems are highly capable of processing diverse data modalities, including
text, images, audio, and structured tabular data, enabling richer and more
adaptive real-world behavior. This paper comprehensively examines the evolution
of agent systems from the pre-LLM era to current LLM-powered architectures. We
categorize agent systems into software-based, physical, and adaptive hybrid
systems, highlighting applications across customer service, software
development, manufacturing automation, personalized education, financial
trading, and healthcare. We further discuss the primary challenges posed by
LLM-powered agents, including high inference latency, output uncertainty, lack
of evaluation metrics, and security vulnerabilities, and propose potential
solutions to mitigate these concerns.

</details>


### [138] [Sudoku-Bench: Evaluating creative reasoning with Sudoku variants](https://arxiv.org/abs/2505.16135)
*Jeffrey Seely, Yuki Imajuku, Tianyu Zhao, Edoardo Cetin, Llion Jones*

**主要类别:** cs.AI

**概要:** 大型语言模型（LLMs）现有的推理基准测试往往无法捕捉真实的创造力，常常奖励对先前观察到的模式的记忆。为了解决这一不足，我们提出了Sudoku-Bench，这是一个精心策划的、具有挑战性和非传统数独变体的基准测试，专门用于评估创造性的、多步骤的逻辑推理能力。数独变体构成了一个异常有效的推理研究领域：每个谜题引入独特的或微妙交互的约束条件，使得记忆变得不可行，并要求解题者识别出新的逻辑突破点（“突破口”）。尽管数独变体种类繁多，但它们保持了一种共同且紧凑的结构，从而实现了清晰和一致的评估。Sudoku-Bench包括精心挑选的谜题集、标准化的基于文本的谜题表示形式以及与数千个公开可用的谜题兼容的灵活工具——使其易于扩展为一个通用的研究环境。基线实验表明，最先进的LLMs在没有帮助的情况下解决的谜题不到15%，突显了推进长时程、战略性推理能力的重大机遇。


<details>
  <summary>更多</summary>
  
**动机:** 当前的大规模语言模型推理基准未能有效捕捉真实创造力，通常奖励对已有模式的记忆。因此需要一个能更好评估创造性、多步骤逻辑推理的新基准。

**方法:** 创建了一个名为Sudoku-Bench的新基准，包含一系列挑战性高且不寻常的数独变体。这些数独变体具有独特或相互作用的约束条件，难以通过记忆解决，需要发现新的逻辑突破口。该基准还包括精选的谜题集、标准的基于文本的谜题表示方法及与大量公开谜题兼容的灵活工具。

**结果:** 实验显示，最先进的大规模语言模型在无辅助情况下只能解决不到15%的数独谜题，表明在长时程战略推理能力方面存在显著改进空间。

**结论:** Sudoku-Bench提供了一个有效的平台来评估和推动大规模语言模型的创造性推理能力，未来可进一步提升这些模型的战略推理水平。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sudoku-Bench%3A+Evaluating+creative+reasoning+with+Sudoku+variants，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16135，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16135&send_immediately=true&force_search=false)

**原文摘要:** Existing reasoning benchmarks for large language models (LLMs) frequently
fail to capture authentic creativity, often rewarding memorization of
previously observed patterns. We address this shortcoming with Sudoku-Bench, a
curated benchmark of challenging and unconventional Sudoku variants
specifically selected to evaluate creative, multi-step logical reasoning.
Sudoku variants form an unusually effective domain for reasoning research: each
puzzle introduces unique or subtly interacting constraints, making memorization
infeasible and requiring solvers to identify novel logical breakthroughs
(``break-ins''). Despite their diversity, Sudoku variants maintain a common and
compact structure, enabling clear and consistent evaluation. Sudoku-Bench
includes a carefully chosen puzzle set, a standardized text-based puzzle
representation, and flexible tools compatible with thousands of publicly
available puzzles -- making it easy to extend into a general research
environment. Baseline experiments show that state-of-the-art LLMs solve fewer
than 15\% of puzzles unaided, highlighting significant opportunities to advance
long-horizon, strategic reasoning capabilities.

</details>


### [139] [Losing is for Cherishing: Data Valuation Based on Machine Unlearning and Shapley Value](https://arxiv.org/abs/2505.16147)
*Le Ma, Shirao Yang, Zihao Wang, Yinggui Wang, Lei Wang, Tao Wei, Kejun Zhang*

**主要类别:** cs.AI

**概要:** 提出了Unlearning Shapley框架，通过机器遗忘技术高效估计数据价值，支持部分和全部数据估值，适用于大型模型和数据市场，相比现有方法大幅降低计算开销。


<details>
  <summary>更多</summary>
  
**动机:** 大型模型的普及加剧了对高效数据估值方法的需求，而传统方法（如基于博弈论的Shapley值或基于影响函数的技术）面临高昂的计算成本或需要访问完整数据及模型训练细节，难以实现部分数据估值。

**方法:** 提出了一种名为Unlearning Shapley的新框架，利用机器遗忘技术从预训练模型中移除目标数据，并通过测量可达测试集上的性能变化来计算Shapley值。该方法使用Monte Carlo采样避免重新训练模型，同时消除了对完整数据的依赖。

**结果:** 实验表明，该方法在基准数据集和大规模文本语料库上与最先进的方法具有相同的准确性，但计算开销减少了几个数量级。进一步分析验证了估计值与数据子集真实影响之间的强相关性，证明其在实际场景中的可靠性。

**结论:** Unlearning Shapley弥合了数据估值理论与实际部署之间的差距，提供了一种可扩展且符合隐私要求的解决方案，适用于现代AI生态系统。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Losing+is+for+Cherishing%3A+Data+Valuation+Based+on+Machine+Unlearning+and+Shapley+Value，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16147，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16147&send_immediately=true&force_search=false)

**原文摘要:** The proliferation of large models has intensified the need for efficient data
valuation methods to quantify the contribution of individual data providers.
Traditional approaches, such as game-theory-based Shapley value and
influence-function-based techniques, face prohibitive computational costs or
require access to full data and model training details, making them hardly
achieve partial data valuation. To address this, we propose Unlearning Shapley,
a novel framework that leverages machine unlearning to estimate data values
efficiently. By unlearning target data from a pretrained model and measuring
performance shifts on a reachable test set, our method computes Shapley values
via Monte Carlo sampling, avoiding retraining and eliminating dependence on
full data. Crucially, Unlearning Shapley supports both full and partial data
valuation, making it scalable for large models (e.g., LLMs) and practical for
data markets. Experiments on benchmark datasets and large-scale text corpora
demonstrate that our approach matches the accuracy of state-of-the-art methods
while reducing computational overhead by orders of magnitude. Further analysis
confirms a strong correlation between estimated values and the true impact of
data subsets, validating its reliability in real-world scenarios. This work
bridges the gap between data valuation theory and practical deployment,
offering a scalable, privacy-compliant solution for modern AI ecosystems.

</details>


### [140] [Dynamic Sampling that Adapts: Iterative DPO for Self-Aware Mathematical Reasoning](https://arxiv.org/abs/2505.16176)
*Jun Rao, Xuebo Liu, Hexuan Deng, Zepeng Lin, Zixiong Yu, Jiansheng Wei, Xiaojun Meng, Min Zhang*

**主要类别:** cs.AI

**概要:** 在数据选择方面，现有的方法通常依赖于外部预定义的静态指标，如难度和多样性，这些指标往往为监督微调(SFT)设计，缺乏对连续训练过程的适应性。为了应对这一挑战，本文提出了SAI-DPO算法，该算法通过实时评估模型在不同训练阶段的推理能力，动态地选择训练数据，从而提高了数据利用效率和最终任务性能。实验表明，SAI-DPO在多个数学推理基准上平均提升了21.3个百分点的性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有数据选择方法依赖静态指标，在动态训练和在线强化学习框架中表现不佳，无法适应模型能力的变化。

**方法:** 提出SAI-DPO算法，通过持续评估模型在不同训练阶段的推理能力，动态调整数据选择策略，以适应模型的优劣势变化。

**结果:** 在三个先进模型和八个数学推理基准上的广泛实验表明，SAI-DPO实现了高达21.3个百分点的性能提升，在AIME24和AMC23数据集上分别提升了10和15个点。

**结论:** 动态、模型自适应的数据选择策略优于静态、外部定义的方法，能显著提高推理能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dynamic+Sampling+that+Adapts%3A+Iterative+DPO+for+Self-Aware+Mathematical+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16176，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16176&send_immediately=true&force_search=false)

**原文摘要:** In the realm of data selection for reasoning tasks, existing approaches
predominantly rely on externally predefined static metrics such as difficulty
and diversity, which are often designed for supervised fine-tuning (SFT) and
lack adaptability to continuous training processes. A critical limitation of
these methods is their inability to dynamically align with the evolving
capabilities of models during online training, a gap that becomes increasingly
pronounced with the rise of dynamic training paradigms and online reinforcement
learning (RL) frameworks (e.g., R1 models). To address this, we introduce
SAI-DPO, an algorithm that dynamically selects training data by continuously
assessing a model's stage-specific reasoning abilities across different
training phases. By integrating real-time model performance feedback, SAI-DPO
adaptively adapts data selection to the evolving strengths and weaknesses of
the model, thus enhancing both data utilization efficiency and final task
performance. Extensive experiments on three state-of-the-art models and eight
mathematical reasoning benchmarks, including challenging competition-level
datasets (e.g., AIME24 and AMC23), demonstrate that SAI-DPO achieves an average
performance boost of up to 21.3 percentage points, with particularly notable
improvements of 10 and 15 points on AIME24 and AMC23, respectively. These
results highlight the superiority of dynamic, model-adaptive data selection
over static, externally defined strategies in advancing reasoning.

</details>


### [141] [SafeKey: Amplifying Aha-Moment Insights for Safety Reasoning](https://arxiv.org/abs/2505.16186)
*Kaiwen Zhou, Xuandong Zhao, Gaowen Liu, Jayanth Srinivasa, Aosong Feng, Dawn Song, Xin Eric Wang*

**主要类别:** cs.AI

**概要:** Large Reasoning Models (LRMs)虽然在复杂任务中表现出色，但存在安全风险。本文提出SafeKey方法，通过增强关键句中的安全信号和改进模型对查询的理解，显著提高LRMs对越狱攻击和有害提示的安全泛化能力，同时保持通用性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管监督微调(SFT)提高了LRMs的安全性能，但这些模型在面对未见过的越狱提示时表现不佳。

**方法:** SafeKey包含两个互补目标：(1) Dual-Path Safety Head，在关键句之前增强模型内部表示中的安全信号；(2) Query-Mask Modeling，改进模型对其查询理解的关注度，其中包含重要的安全提示。

**结果:** 实验表明，SafeKey方法显著提高了多个安全基准测试中的安全泛化能力，降低了9.6%的平均有害率，同时保持了模型的通用能力。

**结论:** SafeKey通过重塑内部注意力和改进隐藏表示的质量来增强LRMs的安全性，为解决越狱攻击和有害提示提供了有效方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SafeKey%3A+Amplifying+Aha-Moment+Insights+for+Safety+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16186，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16186&send_immediately=true&force_search=false)

**原文摘要:** Large Reasoning Models (LRMs) introduce a new generation paradigm of
explicitly reasoning before answering, leading to remarkable improvements in
complex tasks. However, they pose great safety risks against harmful queries
and adversarial attacks. While recent mainstream safety efforts on LRMs,
supervised fine-tuning (SFT), improve safety performance, we find that
SFT-aligned models struggle to generalize to unseen jailbreak prompts. After
thorough investigation of LRMs' generation, we identify a safety aha moment
that can activate safety reasoning and lead to a safe response. This aha moment
typically appears in the `key sentence', which follows models' query
understanding process and can indicate whether the model will proceed safely.
Based on these insights, we propose SafeKey, including two complementary
objectives to better activate the safety aha moment in the key sentence: (1) a
Dual-Path Safety Head to enhance the safety signal in the model's internal
representations before the key sentence, and (2) a Query-Mask Modeling
objective to improve the models' attention on its query understanding, which
has important safety hints. Experiments across multiple safety benchmarks
demonstrate that our methods significantly improve safety generalization to a
wide range of jailbreak attacks and out-of-distribution harmful prompts,
lowering the average harmfulness rate by 9.6\%, while maintaining general
abilities. Our analysis reveals how SafeKey enhances safety by reshaping
internal attention and improving the quality of hidden representations.

</details>


### [142] [Velocity Completion Task and Method for Event-based Player Positional Data in Soccer](https://arxiv.org/abs/2505.16199)
*Rikuhei Umemoto, Keisuke Fujii*

**主要类别:** cs.AI

**概要:** 在团队运动中，基于事件的位置数据通常缺乏连续的时间信息，限制了对个体行为和团队策略的深入动态分析。本文提出了一种新方法，利用团队运动的基于事件的位置数据同时完成所有代理人的速度信息，并验证了神经网络方法在速度补全任务中的优越性。


<details>
  <summary>更多</summary>
  
**动机:** 团队运动等多代理系统的行为分析需要理解个体代理的移动和交互，但基于事件的位置数据缺乏连续时间信息，无法直接计算速度等关键属性，限制了动态分析的深度。

**方法:** 提出一种新方法，利用团队运动的基于事件的位置数据同时完成所有代理人的速度信息，并使用神经网络方法考虑底层的时间依赖性和玩家间或玩家与球的交互图结构。

**结果:** 实验表明，基于神经网络的方法在速度补全误差方面优于基于规则的方法，且使用补全速度得到的空间评估结果更接近于完整跟踪数据得出的结果。

**结论:** 所提出的方法能够有效补全速度信息，增强团队运动系统的分析能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Velocity+Completion+Task+and+Method+for+Event-based+Player+Positional+Data+in+Soccer，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16199，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16199&send_immediately=true&force_search=false)

**原文摘要:** In many real-world complex systems, the behavior can be observed as a
collection of discrete events generated by multiple interacting agents.
Analyzing the dynamics of these multi-agent systems, especially team sports,
often relies on understanding the movement and interactions of individual
agents. However, while providing valuable snapshots, event-based positional
data typically lacks the continuous temporal information needed to directly
calculate crucial properties such as velocity. This absence severely limits the
depth of dynamic analysis, preventing a comprehensive understanding of
individual agent behaviors and emergent team strategies. To address this
challenge, we propose a new method to simultaneously complete the velocity of
all agents using only the event-based positional data from team sports. Based
on this completed velocity information, we investigate the applicability of
existing team sports analysis and evaluation methods. Experiments using soccer
event data demonstrate that neural network-based approaches outperformed
rule-based methods regarding velocity completion error, considering the
underlying temporal dependencies and graph structure of player-to-player or
player-to-ball interaction. Moreover, the space evaluation results obtained
using the completed velocity are closer to those derived from complete tracking
data, highlighting our method's potential for enhanced team sports system
analysis.

</details>


### [143] [LightRouter: Towards Efficient LLM Collaboration with Minimal Overhead](https://arxiv.org/abs/2505.16221)
*Yifan Zhang, Xinkui Zhao, Zuxin Wang, Guanjie Cheng, Yueshen Xu, Shuiguang Deng, Jianwei Yin*

**主要类别:** cs.AI

**概要:** 大型语言模型（LLM）的快速发展为自然语言处理任务带来了显著的能力。然而，不同LLM在成本、性能和计算需求上的巨大差异给用户选择合适的模型带来了挑战。本文提出了LightRouter框架，通过系统地选择和整合少量LLM来同时优化任务性能和成本效率。LightRouter采用自适应选择机制减少启动令牌数量以降低成本，并使用有效的整合策略结合模型输出。实验表明，LightRouter与广泛使用的集成基线相比，在准确性上提高了25%，并且与高性能模型相比，推理成本降低了27%。该框架无需任何先验知识，仅依赖廉价的轻量级模型，提供了一种高效的选择和组合LLM的实际方法。


<details>
  <summary>更多</summary>
  
**动机:** 当前可用的大型语言模型（LLM）在成本、性能和计算需求方面存在显著差异，这使得用户很难确定哪个模型最适合特定的任务。因此，需要一种能够平衡性能和成本的模型选择和整合方案。

**方法:** 提出了一种名为LightRouter的新框架，该框架通过以下步骤实现目标：1) 使用自适应选择机制挑选出只需要最少引导令牌的模型，从而降低运行成本；2) 应用有效的整合策略将这些模型的输出结合起来，以提高整体性能。整个过程不需要对各个模型有任何预先了解，只依赖于低成本的轻量化模型。

**结果:** 广泛的实验表明，LightRouter在多个基准测试中匹配或超越了常用的集成基线模型，准确率提升了25%。此外，与领先的高性能量子模型相比，LightRouter不仅实现了相当的性能水平，还成功将推理成本减少了27%。

**结论:** LightRouter提供了一种实用且高效的LLM选择和整合方法，它能够在不牺牲性能的情况下显著降低成本。这种方法为未来如何最优地选择和组合模型提供了宝贵的见解。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LightRouter%3A+Towards+Efficient+LLM+Collaboration+with+Minimal+Overhead，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16221，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16221&send_immediately=true&force_search=false)

**原文摘要:** The rapid advancement of large language models has unlocked remarkable
capabilities across a diverse array of natural language processing tasks.
However, the considerable differences among available LLMs-in terms of cost,
performance, and computational demands-pose significant challenges for users
aiming to identify the most suitable model for specific tasks. In this work, we
present LightRouter, a novel framework designed to systematically select and
integrate a small subset of LLMs from a larger pool, with the objective of
jointly optimizing both task performance and cost efficiency. LightRouter
leverages an adaptive selection mechanism to identify models that require only
a minimal number of boot tokens, thereby reducing costs, and further employs an
effective integration strategy to combine their outputs. Extensive experiments
across multiple benchmarks demonstrate that LightRouter matches or outperforms
widely-used ensemble baselines, achieving up to a 25% improvement in accuracy.
Compared with leading high-performing models, LightRouter achieves comparable
performance while reducing inference costs by up to 27%. Importantly, our
framework operates without any prior knowledge of individual models and relies
exclusively on inexpensive, lightweight models. This work introduces a
practical approach for efficient LLM selection and provides valuable insights
into optimal strategies for model combination.

</details>


### [144] [MADCluster: Model-agnostic Anomaly Detection with Self-supervised Clustering Network](https://arxiv.org/abs/2505.16223)
*Sangyong Lee, Subo Hwang, Dohoon Kim*

**主要类别:** cs.AI

**概要:** 本文提出了一种新的模型无关异常检测框架MADCluster，利用自监督聚类解决了深度学习方法中的'超球体崩溃'问题。通过单聚类和一种新提出的'One-directed Adaptive loss'，MADCluster提高了表达能力，并在四个时间序列基准数据集上验证了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的基于深度学习的异常检测方法存在'超球体崩溃'问题，即正常数据点被映射到一个过于紧密的区域，导致异常检测性能下降。为了解决这一问题并提高模型的通用性，提出了MADCluster框架。

**方法:** MADCluster由三个主要部分组成：捕获高维时序动态的Base Embedder、Cluster Distance Mapping以及用于连续中心更新的Sequence-wise Clustering。此外，提出了一种新的损失函数'One-directed Adaptive loss'，以优化单聚类的效果，并且该损失函数具有数学证明的优化特性。

**结果:** 在四个时间序列基准数据集上的实验表明，应用MADCluster可以提升比较模型的整体性能，显示出其与不同架构的兼容性和对模型性能的增强潜力。

**结论:** MADCluster作为一种模型无关的异常检测框架，展现了在各种架构中提升模型性能的潜力，特别是在解决'超球体崩溃'问题方面的有效性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MADCluster%3A+Model-agnostic+Anomaly+Detection+with+Self-supervised+Clustering+Network，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16223，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16223&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we propose MADCluster, a novel model-agnostic anomaly
detection framework utilizing self-supervised clustering. MADCluster is
applicable to various deep learning architectures and addresses the
'hypersphere collapse' problem inherent in existing deep learning-based anomaly
detection methods. The core idea is to cluster normal pattern data into a
'single cluster' while simultaneously learning the cluster center and mapping
data close to this center. Also, to improve expressiveness and enable effective
single clustering, we propose a new 'One-directed Adaptive loss'. The
optimization of this loss is mathematically proven. MADCluster consists of
three main components: Base Embedder capturing high-dimensional temporal
dynamics, Cluster Distance Mapping, and Sequence-wise Clustering for continuous
center updates. Its model-agnostic characteristics are achieved by applying
various architectures to the Base Embedder. Experiments on four time series
benchmark datasets demonstrate that applying MADCluster improves the overall
performance of comparative models. In conclusion, the compatibility of
MADCluster shows potential for enhancing model performance across various
architectures.

</details>


### [145] [MAPLE: Many-Shot Adaptive Pseudo-Labeling for In-Context Learning](https://arxiv.org/abs/2505.16225)
*Zihan Chen, Song Wang, Zhen Tan, Jundong Li, Cong Shen*

**主要类别:** cs.AI

**概要:** 提出了一种名为MAPLE的新框架，通过伪标记样本来减少对大量标注数据的需求，从而提升多示例情境学习（many-shot ICL）的性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管多示例情境学习（many-shot ICL）相较于少示例情境学习（few-shot ICL）表现更好，但其受限于获取大量标注数据的高成本问题。

**方法:** MAPLE首先识别出有影响力的未标注样本子集，并通过查询大语言模型（LLMs）对其进行伪标记。然后，这些伪标记样本被自适应地选择和调整，以适配每个测试查询，作为输入来提高多示例情境学习的性能。

**结果:** 在真实世界数据集上的广泛实验表明，该框架在有限标注数据的情况下能够有效增强大语言模型的适应性和性能。

**结论:** MAPLE提供了一种低成本、有效的解决方案，以克服多示例情境学习中对大量标注数据的需求，同时提升了大语言模型的性能和适应性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MAPLE%3A+Many-Shot+Adaptive+Pseudo-Labeling+for+In-Context+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16225，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16225&send_immediately=true&force_search=false)

**原文摘要:** In-Context Learning (ICL) empowers Large Language Models (LLMs) to tackle
diverse tasks by incorporating multiple input-output examples, known as
demonstrations, into the input of LLMs. More recently, advancements in the
expanded context windows of LLMs have led to many-shot ICL, which uses hundreds
of demonstrations and outperforms few-shot ICL, which relies on fewer examples.
However, this approach is often hindered by the high cost of obtaining large
amounts of labeled data. To address this challenge, we propose Many-Shot
Adaptive Pseudo-LabEling, namely MAPLE, a novel influence-based many-shot ICL
framework that utilizes pseudo-labeled samples to compensate for the lack of
label information. We first identify a subset of impactful unlabeled samples
and perform pseudo-labeling on them by querying LLMs. These pseudo-labeled
samples are then adaptively selected and tailored to each test query as input
to improve the performance of many-shot ICL, without significant labeling
costs. Extensive experiments on real-world datasets demonstrate the
effectiveness of our framework, showcasing its ability to enhance LLM
adaptability and performance with limited labeled data.

</details>


### [146] [How do Scaling Laws Apply to Knowledge Graph Engineering Tasks? The Impact of Model Size on Large Language Model Performance](https://arxiv.org/abs/2505.16276)
*Desiree Heim, Lars-Peter Meyer, Markus Schröder, Johannes Frey, Andreas Dengel*

**主要类别:** cs.AI

**概要:** 这篇论文探讨了大型语言模型（LLMs）在知识图谱工程（KGE）任务中的表现与模型大小之间的关系。通过LKM-KG-Bench框架，作者评估了26个开源LLMs在理解和生成知识图谱及查询方面的性能。研究发现，尽管通常较大的模型表现更好，但在某些情况下存在性能平稳或上限效应，这表明较小的模型可能在特定任务中具有更高的成本效益。对于同一模型家族，有时较大的模型表现不如较小的模型，因此建议测试相邻大小的模型以获得最佳效果。


<details>
  <summary>更多</summary>
  
**动机:** 了解LLMs的大小与其在KGE任务中的性能之间的关系，以便在资源成本和性能之间找到最佳平衡。

**方法:** 使用LKM-KG-Bench框架对26个开源LLMs进行基准测试，分析不同模型大小类别的基准分数变化，并检查单个模型和模型家族的分数发展与大小的相关性。

**结果:** 大多数情况下，较大的模型在KGE任务中表现出更好的性能，但存在性能平稳或上限效应的情况。此外，同一模型家族中，有时较大的模型表现不如较小的模型。

**结论:** 在选择用于KGE任务的LLM时，应考虑模型大小与性能的关系，同时注意可能存在性能平稳或上限效应的情况。建议测试相邻大小的模型以获得最佳效果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+do+Scaling+Laws+Apply+to+Knowledge+Graph+Engineering+Tasks%3F+The+Impact+of+Model+Size+on+Large+Language+Model+Performance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16276，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16276&send_immediately=true&force_search=false)

**原文摘要:** When using Large Language Models (LLMs) to support Knowledge Graph
Engineering (KGE), one of the first indications when searching for an
appropriate model is its size. According to the scaling laws, larger models
typically show higher capabilities. However, in practice, resource costs are
also an important factor and thus it makes sense to consider the ratio between
model performance and costs. The LLM-KG-Bench framework enables the comparison
of LLMs in the context of KGE tasks and assesses their capabilities of
understanding and producing KGs and KG queries. Based on a dataset created in
an LLM-KG-Bench run covering 26 open state-of-the-art LLMs, we explore the
model size scaling laws specific to KGE tasks. In our analyses, we assess how
benchmark scores evolve between different model size categories. Additionally,
we inspect how the general score development of single models and families of
models correlates to their size. Our analyses revealed that, with a few
exceptions, the model size scaling laws generally also apply to the selected
KGE tasks. However, in some cases, plateau or ceiling effects occurred, i.e.,
the task performance did not change much between a model and the next larger
model. In these cases, smaller models could be considered to achieve high
cost-effectiveness. Regarding models of the same family, sometimes larger
models performed worse than smaller models of the same family. These effects
occurred only locally. Hence it is advisable to additionally test the next
smallest and largest model of the same family.

</details>


### [147] [No Black Boxes: Interpretable and Interactable Predictive Healthcare with Knowledge-Enhanced Agentic Causal Discovery](https://arxiv.org/abs/2505.16288)
*Xiaoxue Han, Pengfei Hu, Jun-En Ding, Chang Lu, Feng Liu, Yue Ning*

**主要类别:** cs.AI

**概要:** Deep learning models for diagnosis prediction lack interpretability and interactivity. II-KEA, a new framework, addresses these issues by integrating personalized knowledge databases and agentic LLMs, demonstrating superior performance in case studies on MIMIC-III and MIMIC-IV.


<details>
  <summary>更多</summary>
  
**动机:** Despite high accuracy in diagnosis prediction, deep learning models lack interpretability and interactivity, which are crucial for clinical decision-making.

**方法:** II-KEA integrates personalized knowledge databases and agentic LLMs to enhance both interpretability through explicit reasoning and causal analysis, and interactivity by allowing clinicians to inject their knowledge and experience.

**结果:** II-KEA was evaluated on MIMIC-III and MIMIC-IV, showing superior performance with enhanced interpretability and interactivity.

**结论:** II-KEA addresses the limitations of current deep learning models in clinical applications by improving interpretability and interactivity.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是No+Black+Boxes%3A+Interpretable+and+Interactable+Predictive+Healthcare+with+Knowledge-Enhanced+Agentic+Causal+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16288，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16288&send_immediately=true&force_search=false)

**原文摘要:** Deep learning models trained on extensive Electronic Health Records (EHR)
data have achieved high accuracy in diagnosis prediction, offering the
potential to assist clinicians in decision-making and treatment planning.
However, these models lack two crucial features that clinicians highly value:
interpretability and interactivity. The ``black-box'' nature of these models
makes it difficult for clinicians to understand the reasoning behind
predictions, limiting their ability to make informed decisions. Additionally,
the absence of interactive mechanisms prevents clinicians from incorporating
their own knowledge and experience into the decision-making process. To address
these limitations, we propose II-KEA, a knowledge-enhanced agent-driven causal
discovery framework that integrates personalized knowledge databases and
agentic LLMs. II-KEA enhances interpretability through explicit reasoning and
causal analysis, while also improving interactivity by allowing clinicians to
inject their knowledge and experience through customized knowledge bases and
prompts. II-KEA is evaluated on both MIMIC-III and MIMIC-IV, demonstrating
superior performance along with enhanced interpretability and interactivity, as
evidenced by its strong results from extensive case studies.

</details>


### [148] [EquivPruner: Boosting Efficiency and Quality in LLM-Based Search via Action Pruning](https://arxiv.org/abs/2505.16312)
*Jiawei Liu, Qisi Chen, Jianshu Zhang, Quan Liu, Defu Lian*

**主要类别:** cs.AI

**概要:** 这篇论文提出了一种名为EquivPruner的方法，可以识别并修剪大语言模型在推理搜索过程中语义等价的动作，从而减少令牌消耗，提高搜索效率和推理准确性。此外，还介绍了MathEquiv数据集，用于数学语句等价性的训练。实验表明，该方法能显著减少令牌消耗并提升准确率。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型在复杂推理中表现出色，但当前策略因重复探索语义等价步骤而消耗大量令牌。现有的语义相似性方法难以准确识别特定领域（如数学推理）中的这种等价性。

**方法:** 提出了EquivPruner方法，用于识别和修剪大语言模型推理搜索过程中的语义等价动作。同时创建了MathEquiv数据集，以支持轻量级等价检测器的训练。

**结果:** 广泛的实验表明，EquivPruner显著减少了令牌消耗，提高了搜索效率，并且通常增强了推理准确性。例如，在Qwen2.5-Math-7B-Instruct应用于GSM8K时，减少了48.1%的令牌消耗，同时提升了准确率。

**结论:** EquivPruner是一种简单而有效的方法，能够减少大语言模型推理过程中的令牌消耗，提高效率和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EquivPruner%3A+Boosting+Efficiency+and+Quality+in+LLM-Based+Search+via+Action+Pruning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16312，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16312&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) excel at complex reasoning through search
algorithms, yet current strategies often suffer from massive token consumption
due to redundant exploration of semantically equivalent steps. Existing
semantic similarity methods struggle to accurately identify such equivalence in
domain-specific contexts like mathematical reasoning. To address this, we
propose EquivPruner, a simple yet effective approach that identifies and prunes
semantically equivalent actions during LLM reasoning search. We also introduce
MathEquiv, the first dataset we created for mathematical statement equivalence,
which enables the training of a lightweight equivalence detector. Extensive
experiments across various models and tasks demonstrate that EquivPruner
significantly reduces token consumption, improving searching efficiency and
often bolstering reasoning accuracy. For instance, when applied to
Qwen2.5-Math-7B-Instruct on GSM8K, EquivPruner reduced token consumption by
48.1\% while also improving accuracy. Our code is available at
https://github.com/Lolo1222/EquivPruner.

</details>


### [149] [Incentivizing Dual Process Thinking for Efficient Large Language Model Reasoning](https://arxiv.org/abs/2505.16315)
*Xiaoxue Cheng, Junyi Li, Zhenduo Zhang, Xinyu Tang, Wayne Xin Zhao, Xinyu Kong, Zhiqiang Zhang*

**主要类别:** cs.AI

**概要:** ACPO是一种强化学习框架，通过自适应认知分配和动态系统切换使大型推理模型更高效。实验表明，ACPO能减少冗余推理并根据任务复杂性调整认知分配，实现高效的混合推理。


<details>
  <summary>更多</summary>
  
**动机:** 大型推理模型在复杂推理任务中表现出色，但常因过度思考产生冗余内容。受认知科学双重过程理论启发，研究旨在开发一种框架，使模型能够通过自适应认知分配和动态系统切换实现高效推理。

**方法:** 提出ACPO框架，包含两个关键组件：1) 引入系统感知推理标记以明确表示思维模式，使模型的认知过程透明；2) 整合在线难度估计和标记长度预算，以指导强化学习中的自适应系统切换和推理。采用两阶段训练策略：第一阶段为监督微调，使模型生成带有明确思维模式的推理路径；第二阶段应用ACPO进一步增强自适应系统切换，进行难度感知推理。

**结果:** 实验结果表明，ACPO有效减少了冗余推理，并能根据任务复杂性自适应调整认知分配，实现了高效的混合推理。

**结论:** ACPO框架成功使大型推理模型通过自适应认知分配和动态系统切换提高效率，减少冗余推理，实现难度感知的高效混合推理。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Incentivizing+Dual+Process+Thinking+for+Efficient+Large+Language+Model+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16315，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16315&send_immediately=true&force_search=false)

**原文摘要:** Large reasoning models (LRMs) have demonstrated strong performance on complex
reasoning tasks, but often suffer from overthinking, generating redundant
content regardless of task difficulty. Inspired by the dual process theory in
cognitive science, we propose Adaptive Cognition Policy Optimization (ACPO), a
reinforcement learning framework that enables LRMs to achieve efficient
reasoning through adaptive cognitive allocation and dynamic system switch. ACPO
incorporates two key components: (1) introducing system-aware reasoning tokens
to explicitly represent the thinking modes thereby making the model's cognitive
process transparent, and (2) integrating online difficulty estimation and token
length budget to guide adaptive system switch and reasoning during
reinforcement learning. To this end, we propose a two-stage training strategy.
The first stage begins with supervised fine-tuning to cold start the model,
enabling it to generate reasoning paths with explicit thinking modes. In the
second stage, we apply ACPO to further enhance adaptive system switch for
difficulty-aware reasoning. Experimental results demonstrate that ACPO
effectively reduces redundant reasoning while adaptively adjusting cognitive
allocation based on task complexity, achieving efficient hybrid reasoning.

</details>


### [150] [Serious Games: Human-AI Interaction, Evolution, and Coevolution](https://arxiv.org/abs/2505.16388)
*Nandini Doreswamy, Louise Horstmanshof*

**主要类别:** cs.AI

**概要:** 通过进化博弈论（EGT）模型，如鹰鸽博弈、重复囚徒困境和消耗战，可以预测人类与AI之间的进化平衡。这些模型揭示了合作与竞争的可能性，并提供了理解人类-AI共同演化的框架。未来研究需要探索更多方法和跨学科视角。


<details>
  <summary>更多</summary>
  
**动机:** 探讨人类与AI之间竞争与合作的潜在进化平衡，并为人类-AI互动、演化和共同演化提供理论框架。

**方法:** 分析三个经典的EGT模型：鹰鸽博弈、重复囚徒困境和消耗战，评估其在人类-AI共同演化中的适用性。

**结果:** 发现这些模型能够揭示人类与AI之间可能的合作与竞争动态，包括混合策略平衡、认知共同演化以及资源分配的不对称均衡。

**结论:** EGT为理解人类-AI演化动态提供了合适框架，但未来研究需超越EGT，结合更多方法、实证验证和跨学科视角，同时关注伦理和认知影响。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Serious+Games%3A+Human-AI+Interaction%2C+Evolution%2C+and+Coevolution，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16388，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16388&send_immediately=true&force_search=false)

**原文摘要:** The serious games between humans and AI have only just begun. Evolutionary
Game Theory (EGT) models the competitive and cooperative strategies of
biological entities. EGT could help predict the potential evolutionary
equilibrium of humans and AI. The objective of this work was to examine some of
the EGT models relevant to human-AI interaction, evolution, and coevolution. Of
thirteen EGT models considered, three were examined: the Hawk-Dove Game,
Iterated Prisoner's Dilemma, and the War of Attrition. This selection was based
on the widespread acceptance and clear relevance of these models to potential
human-AI evolutionary dynamics and coevolutionary trajectories. The Hawk-Dove
Game predicts balanced mixed-strategy equilibria based on the costs of
conflict. It also shows the potential for balanced coevolution rather than
dominance. Iterated Prisoner's Dilemma suggests that repeated interaction may
lead to cognitive coevolution. It demonstrates how memory and reciprocity can
lead to cooperation. The War of Attrition suggests that competition for
resources may result in strategic coevolution, asymmetric equilibria, and
conventions on sharing resources. Therefore, EGT may provide a suitable
framework to understand and predict the human-AI evolutionary dynamic. However,
future research could extend beyond EGT and explore additional frameworks,
empirical validation methods, and interdisciplinary perspectives. AI is being
shaped by human input and is evolving in response to it. So too,
neuroplasticity allows the human brain to grow and evolve in response to
stimuli. If humans and AI converge in future, what might be the result of human
neuroplasticity combined with an ever-evolving AI? Future research should be
mindful of the ethical and cognitive implications of human-AI interaction,
evolution, and coevolution.

</details>


### [151] [FREESON: Retriever-Free Retrieval-Augmented Reasoning via Corpus-Traversing MCTS](https://arxiv.org/abs/2505.16409)
*Chaeeun Kim, Seungone Kim*

**主要类别:** cs.AI

**概要:** FREESON框架通过CT-MCTS算法使LRMs同时担任生成器和检索器，减少硬件成本并提高检索精度，在多个QA基准上表现优异。


<details>
  <summary>更多</summary>
  
**动机:** 现有的检索增强推理方法依赖独立的检索模型，这不仅增加了硬件和操作成本，还因表示瓶颈导致检索过程中的错误。

**方法:** 提出FREESON框架，结合CT-MCTS算法，让LRMs自己检索相关知识，充当生成器和检索器的角色。

**结果:** 在五个开放领域问答基准测试中，FREESON比四个带有独立检索器的多步推理模型平均提高了14.4%的EM和F1分数，并且在PopQA和2WikiMultihopQA上分别超越最强基线3%。

**结论:** FREESON框架显著提高了检索增强推理的效果，降低了成本，展示了LRMs作为生成器和检索器的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是FREESON%3A+Retriever-Free+Retrieval-Augmented+Reasoning+via+Corpus-Traversing+MCTS，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16409，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16409&send_immediately=true&force_search=false)

**原文摘要:** Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in
multi-step reasoning and calling search engines at appropriate steps. However,
existing retrieval-augmented reasoning approaches rely on separate retrieval
models, limiting the LRM's role in retrieval to deciding when to retrieve and
how to query. This separation not only increases hardware and operational costs
but also leads to errors in the retrieval process due to the representation
bottleneck, a phenomenon where the retriever's embedding space is not
expressive enough to meet the generator's requirements. To address this, we
shift our perspective from sequence-to-sequence matching to locating the
answer-containing paths within the corpus, and propose a novel framework called
FREESON (Retriever-FREE Retrieval-Augmented ReaSONing). This framework enables
LRMs to retrieve relevant knowledge on their own by acting as both a generator
and retriever. To achieve this, we introduce a variant of the MCTS algorithm
specialized for the retrieval task, which we call CT-MCTS (Corpus-Traversing
Monte Carlo Tree Search). In this algorithm, LRMs traverse through the corpus
toward answer-containing regions. Our results on five open-domain QA
benchmarks, including single-hop and multi-hop questions, show that FREESON
achieves an average improvement of 14.4% in EM and F1 over four multi-step
reasoning models with a separate retriever, and it also performs comparably to
the strongest baseline, surpassing it by 3% on PopQA and 2WikiMultihopQA.

</details>


### [152] [Internal Bias in Reasoning Models leads to Overthinking](https://arxiv.org/abs/2505.16448)
*Renfei Dang, Shujian Huang, Jiajun Chen*

**主要类别:** cs.AI

**概要:** 当前推理模型因冗余和不必要的反思而被批评为过度思考。本文首次揭示，这种过度思考可能源于模型对输入文本的内部偏差。通过可解释性实验发现，过度关注输入部分会放大内部偏差对决策过程的影响。屏蔽原始输入部分可有效缓解内部偏差影响，减少31%-53%的推理长度，并在大多数情况下提高准确性。这表明内部偏差与过度思考之间存在因果关系。


<details>
  <summary>更多</summary>
  
**动机:** 当前推理模型虽然具有强大的探索能力，但因过度思考（冗余和不必要的反思）受到批评，因此需要研究其原因并优化模型性能。

**方法:** 1. 揭示推理模型中过度思考的根源为内部偏差。
2. 通过可解释性实验分析模型对输入部分的过度关注如何放大内部偏差。
3. 测试屏蔽原始输入部分对推理长度和准确性的改善效果。

**结果:** 1. 发现模型的过度思考行为主要由其对输入部分的过度关注引起。
2. 屏蔽原始输入部分可有效减轻内部偏差影响，减少推理长度31%-53%。
3. 在多数情况下，该方法还提高了推理任务的准确性。

**结论:** 内部偏差与过度思考之间存在因果关系，减少对输入部分的过度关注可以显著改善推理效率和准确性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Internal+Bias+in+Reasoning+Models+leads+to+Overthinking，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16448，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16448&send_immediately=true&force_search=false)

**原文摘要:** While current reasoning models possess strong exploratory capabilities, they
are often criticized for overthinking due to redundant and unnecessary
reflections. In this work, we reveal for the first time that overthinking in
reasoning models may stem from their internal bias towards input texts. Upon
encountering a reasoning problem, the model immediately forms a preliminary
guess about the answer, which we term as an internal bias since it is not
derived through actual reasoning. When this guess conflicts with its reasoning
result, the model tends to engage in reflection, leading to the waste of
computational resources. Through further interpretability experiments, we find
that this behavior is largely driven by the model's excessive attention to the
input section, which amplifies the influence of internal bias on its
decision-making process. Additionally, by masking out the original input
section, the affect of internal bias can be effectively alleviated and the
reasoning length could be reduced by 31%-53% across different complex reasoning
tasks. Notably, in most cases, this approach also leads to improvements in
accuracy. These findings demonstrate a causal relationship between internal
bias and overthinking.

</details>


### [153] [Psychology-driven LLM Agents for Explainable Panic Prediction on Social Media during Sudden Disaster Events](https://arxiv.org/abs/2505.16455)
*Mengzhu Liu, Zhengqiu Zhu, Chuan Ai, Chen Gao, Xinghong Li, Lingnan He, Kaisheng Lai, Yingfeng Chen, Xin Lu, Yong Li, Quanjun Yin*

**主要类别:** cs.AI

**概要:** 在突发事件中，准确预测社交媒体上的公众恐慌情绪对于主动治理和危机管理至关重要。为了解决现有方法面临的挑战（数据标注不足、风险感知未建模以及恐慌形成机制的可解释性不足），本文提出了基于情绪唤起理论的心理驱动生成式代理框架PsychoAgent。该框架通过构建细粒度恐慌情绪数据集COPE、整合跨域异构数据建模风险感知，并设计基于LLM的角色扮演代理增强可解释性。实验表明，PsychoAgent相比基线模型提升了12.6%至21.7%的恐慌情绪预测性能，并实现了从“数据驱动拟合”到“基于角色的机制解释模拟”的范式转变。


<details>
  <summary>更多</summary>
  
**动机:** 当前在预测社交媒体上公众恐慌情绪的研究中存在三个主要问题：1）缺乏精细标注的数据限制了情绪预测研究；2）未建模的风险感知导致预测不准确；3）恐慌形成机制的可解释性不足。这些问题促使作者提出一种新的框架来解决这些挑战。

**方法:** 1）构建了一个细粒度的公开恐慌情绪数据集COPE，通过人类与大语言模型（LLMs）协作减少语义偏差；2）开发了一个框架，整合跨域异构数据，基于心理机制建模风险感知和情绪生成的认知差异；3）设计了一个基于LLM的角色扮演代理，通过专门设计的提示词模拟个体心理链条，以增强可解释性。

**结果:** 在自建数据集上的实验结果表明，PsychoAgent相比基线模型提高了12.6%到21.7%的恐慌情绪预测性能。此外，该方法的可解释性和泛化能力得到了验证。

**结论:** PsychoAgent框架成功解决了现有方法中的关键问题，实现了从“数据驱动拟合”到“基于角色的机制解释模拟”的范式转变，为恐慌情绪预测提供了更透明和可解释的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Psychology-driven+LLM+Agents+for+Explainable+Panic+Prediction+on+Social+Media+during+Sudden+Disaster+Events，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16455，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16455&send_immediately=true&force_search=false)

**原文摘要:** During sudden disaster events, accurately predicting public panic sentiment
on social media is crucial for proactive governance and crisis management.
Current efforts on this problem face three main challenges: lack of finely
annotated data hinders emotion prediction studies, unmodeled risk perception
causes prediction inaccuracies, and insufficient interpretability of panic
formation mechanisms. We address these issues by proposing a Psychology-driven
generative Agent framework (PsychoAgent) for explainable panic prediction based
on emotion arousal theory. Specifically, we first construct a fine-grained open
panic emotion dataset (namely COPE) via human-large language models (LLMs)
collaboration to mitigate semantic bias. Then, we develop a framework
integrating cross-domain heterogeneous data grounded in psychological
mechanisms to model risk perception and cognitive differences in emotion
generation. To enhance interpretability, we design an LLM-based role-playing
agent that simulates individual psychological chains through dedicatedly
designed prompts. Experimental results on our annotated dataset show that
PsychoAgent improves panic emotion prediction performance by 12.6% to 21.7%
compared to baseline models. Furthermore, the explainability and generalization
of our approach is validated. Crucially, this represents a paradigm shift from
opaque "data-driven fitting" to transparent "role-based simulation with
mechanistic interpretation" for panic emotion prediction during emergencies.
Our implementation is publicly available at:
https://anonymous.4open.science/r/PsychoAgent-19DD.

</details>


### [154] [MMMR: Benchmarking Massive Multi-Modal Reasoning Tasks](https://arxiv.org/abs/2505.16459)
*Guiyao Tie, Xueyang Zhou, Tianhe Gu, Ruihang Zhang, Chaoran Hu, Sizhe Zhang, Mengqu Sun, Yan Zhang, Pan Zhou, Lichao Sun*

**主要类别:** cs.AI

**概要:** 论文提出了一种新的基准（MMMR），用于评估具有显式思维的多模态推理能力，包括一个高难度数据集和一个模块化推理追踪评估管道（RTEP）。研究表明，带中间思维痕迹的多模态大语言模型（MLLMs-T）总体优于不带思维痕迹的模型，但顶级模型仍存在推理不一致等问题。该基准揭示了准确性和推理质量之间的差距，并为未来模型发展提供了可操作的评估方法。


<details>
  <summary>更多</summary>
  
**动机:** 当前对多模态大语言模型（MLLMs）推理能力的理解不足，缺乏标准化的评估基准，且现有研究主要关注感知或最终答案的正确性，未能深入分析模型在不同模态下的推理过程及失败原因。

**方法:** 构建了一个新的基准（MMMR），包含：1) 一个包含1,083个问题的高难度数据集，涵盖六种多样推理类型；2) 一个模块化推理追踪评估管道（RTEP），通过相关性、一致性等指标评估推理质量，并进行结构化错误标注。

**结果:** 实证结果表明，带中间思维痕迹的MLLMs-T总体上优于非思维痕迹模型，但即使是顶级模型如Claude-3.7-Sonnet和Gemini-2.5 Pro也存在推理不一致和过度思考等问题。

**结论:** MMMR基准揭示了准确性和推理质量之间的持续差距，为评估、比较和改进下一代多模态推理系统提供了可扩展的基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MMMR%3A+Benchmarking+Massive+Multi-Modal+Reasoning+Tasks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16459，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16459&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in Multi-Modal Large Language Models (MLLMs) have enabled
unified processing of language, vision, and structured inputs, opening the door
to complex tasks such as logical deduction, spatial reasoning, and scientific
analysis. Despite their promise, the reasoning capabilities of MLLMs,
particularly those augmented with intermediate thinking traces (MLLMs-T),
remain poorly understood and lack standardized evaluation benchmarks. Existing
work focuses primarily on perception or final answer correctness, offering
limited insight into how models reason or fail across modalities. To address
this gap, we introduce the MMMR, a new benchmark designed to rigorously
evaluate multi-modal reasoning with explicit thinking. The MMMR comprises 1) a
high-difficulty dataset of 1,083 questions spanning six diverse reasoning types
with symbolic depth and multi-hop demands and 2) a modular Reasoning Trace
Evaluation Pipeline (RTEP) for assessing reasoning quality beyond accuracy
through metrics like relevance, consistency, and structured error annotations.
Empirical results show that MLLMs-T overall outperform non-thinking
counterparts, but even top models like Claude-3.7-Sonnet and Gemini-2.5 Pro
suffer from reasoning pathologies such as inconsistency and overthinking. This
benchmark reveals persistent gaps between accuracy and reasoning quality and
provides an actionable evaluation pipeline for future model development.
Overall, the MMMR offers a scalable foundation for evaluating, comparing, and
improving the next generation of multi-modal reasoning systems.

</details>


### [155] [ReflectEvo: Improving Meta Introspection of Small LLMs by Learning Self-Reflection](https://arxiv.org/abs/2505.16475)
*Jiaqi Li, Xinyi Dong, Yang Liu, Zhizhuo Yang, Quansen Wang, Xiaobo Wang, SongChun Zhu, Zixia Jia, Zilong Zheng*

**主要类别:** cs.AI

**概要:** 本研究提出了ReflectEvo，一个展示小型语言模型通过反思学习增强元内省的新颖流程。使用SFT和DPO方法显著提升了Llama-3和Mistral的推理能力，并且在没有蒸馏或精细人工标注的情况下超越了三个知名开源模型的BIG-bench表现。此外，还分析了自动生成的高质量反思对错误定位和纠正的影响。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型（LLMs）表现出卓越的性能，但其计算和存储成本较高，限制了实际应用。因此，提升小型语言模型（SLMs）的推理能力至关重要。本研究旨在探索如何通过反思学习来持续改进SLMs的元内省能力。

**方法:** 1. 提出ReflectEvo流程，通过迭代生成自我反思进行自我训练，形成连续的自我进化过程。
2. 构建了一个大规模、综合性的自我生成反思数据集ReflectEvo-460k，包含扩展的指令和多领域的多样化任务。
3. 使用该数据集，通过监督微调（SFT）和基于偏好优化（DPO）的方法验证反思学习对提升SLMs推理能力的有效性。
4. 对自动生成的高质量反思进行了深入分析，探讨其对错误定位和纠正的影响。

**结果:** 1. 反思学习显著提高了SLMs的推理能力：
   - Llama-3从52.4%提升到71.2%。
   - Mistral从44.4%提升到71.1%。
2. ReflectEvo能够在无需蒸馏或精细人工标注的情况下，与三个知名的开源模型在BIG-bench上的推理能力相媲美甚至超越。
3. 高质量的自动生成反思对错误定位和纠正具有积极影响。

**结论:** 本研究表明，通过迭代反思学习可以持续提高SLMs的推理性能。提出的ReflectEvo流程及其衍生的数据集为未来的研究提供了新的方向，展示了反思学习在提升SLMs推理能力方面的巨大潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ReflectEvo%3A+Improving+Meta+Introspection+of+Small+LLMs+by+Learning+Self-Reflection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16475，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16475&send_immediately=true&force_search=false)

**原文摘要:** We present a novel pipeline, ReflectEvo, to demonstrate that small language
models (SLMs) can enhance meta introspection through reflection learning. This
process iteratively generates self-reflection for self-training, fostering a
continuous and self-evolving process. Leveraging this pipeline, we construct
ReflectEvo-460k, a large-scale, comprehensive, self-generated reflection
dataset with broadened instructions and diverse multi-domain tasks. Building
upon this dataset, we demonstrate the effectiveness of reflection learning to
improve SLMs' reasoning abilities using SFT and DPO with remarkable
performance, substantially boosting Llama-3 from 52.4% to 71.2% and Mistral
from 44.4% to 71.1%. It validates that ReflectEvo can rival or even surpass the
reasoning capability of the three prominent open-sourced models on BIG-bench
without distillation from superior models or fine-grained human annotation. We
further conduct a deeper analysis of the high quality of self-generated
reflections and their impact on error localization and correction. Our work
highlights the potential of continuously enhancing the reasoning performance of
SLMs through iterative reflection learning in the long run.

</details>


### [156] [Advancing the Scientific Method with Large Language Models: From Hypothesis to Discovery](https://arxiv.org/abs/2505.16477)
*Yanbo Zhang, Sumeer A. Khan, Adnan Mahmud, Huck Yang, Alexander Lavin, Michael Levin, Jeremy Frey, Jared Dunnmon, James Evans, Alan Bundy, Saso Dzeroski, Jesper Tegner, Hector Zenil*

**主要类别:** cs.AI

**概要:** 大型语言模型（LLMs）正在通过提高生产力和重塑科学方法来改变科学研究，尽管存在幻觉和可靠性等挑战。它们在科学周期的各个阶段都有潜在应用，但需要与人类科学目标协作并设定明确评估指标。向AI驱动科学转变引发伦理问题，需谨慎引导以实现负责任和有效的突破。


<details>
  <summary>更多</summary>
  
**动机:** 近年来，AI对科学发展贡献显著，LLMs在提升科研生产力和重塑科学方法方面展现出巨大潜力，特别是在化学和生物学领域中参与实验设计、数据分析和工作流程。然而，其可靠性和真实性仍面临挑战。

**方法:** 本文综述了LLMs如何重新定义科学方法，并探讨其在科学周期各阶段（从假设检验到发现）中的潜在应用，强调应追求其与人类科学目标的深度整合。

**结果:** LLMs可以作为创造性和生产力增强工具，推动跨学科的变革性突破，但在多大程度上让LLMs主导科学研究仍需科学界决定。

**结论:** 为使LLMs成为相关且有效的创造性引擎和生产力增强工具，必须在其与所有科学步骤的深度整合过程中确保与人类科学目标的一致性，并设立明确的评估标准，同时解决相关的伦理问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Advancing+the+Scientific+Method+with+Large+Language+Models%3A+From+Hypothesis+to+Discovery，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16477，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16477&send_immediately=true&force_search=false)

**原文摘要:** With recent Nobel Prizes recognising AI contributions to science, Large
Language Models (LLMs) are transforming scientific research by enhancing
productivity and reshaping the scientific method. LLMs are now involved in
experimental design, data analysis, and workflows, particularly in chemistry
and biology. However, challenges such as hallucinations and reliability
persist. In this contribution, we review how Large Language Models (LLMs) are
redefining the scientific method and explore their potential applications
across different stages of the scientific cycle, from hypothesis testing to
discovery. We conclude that, for LLMs to serve as relevant and effective
creative engines and productivity enhancers, their deep integration into all
steps of the scientific process should be pursued in collaboration and
alignment with human scientific goals, with clear evaluation metrics. The
transition to AI-driven science raises ethical questions about creativity,
oversight, and responsibility. With careful guidance, LLMs could evolve into
creative engines, driving transformative breakthroughs across scientific
disciplines responsibly and effectively. However, the scientific community must
also decide how much it leaves to LLMs to drive science, even when associations
with 'reasoning', mostly currently undeserved, are made in exchange for the
potential to explore hypothesis and solution regions that might otherwise
remain unexplored by human exploration alone.

</details>


### [157] [Minimizing the energy depletion in wireless rechargeable sensor networks using bi-level metaheuristic charging schemes](https://arxiv.org/abs/2505.16482)
*Huynh Thi Thanh Binh, Le Van Cuong, Dang Hai Dang, Le Trong Vinh*

**主要类别:** cs.AI

**概要:** 在无线可充电传感器网络（WRSN）中，提出了一种新的双层优化的部分充电方法来最小化能量消耗。该方法同时优化了充电路径和时间，并提出了两种近似算法以解决此问题，实验表明其优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 无线能量传输技术为解决传感器网络中的能量限制问题提供了新机会，但现有的完全充电策略可能导致一系列传感器因充电延迟过长而失效。因此，需要一种新的部分充电策略来减少能量消耗并提高充电效率。

**方法:** 首先构建了研究问题的数学模型，然后提出了两种近似算法：第一种结合多起点局部搜索方法和遗传算法；第二种采用嵌套方法，利用多任务和协方差矩阵适应进化策略的优点。这两种算法分别从上层优化充电路径，下层优化充电时间。

**结果:** 通过在不同网络场景下的实验验证，证明了所提出的两种算法在性能上优于现有工作。

**结论:** 提出的部分充电方法及其对应的两种近似算法能够有效减少WRSN中的能量消耗，并且在各种网络场景中表现出色。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Minimizing+the+energy+depletion+in+wireless+rechargeable+sensor+networks+using+bi-level+metaheuristic+charging+schemes，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16482，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16482&send_immediately=true&force_search=false)

**原文摘要:** Recently, Wireless Rechargeable Sensor Networks (WRSNs) that leveraged the
advantage of wireless energy transfer technology have opened a promising
opportunity in solving the limited energy issue. However, an ineffective
charging strategy may reduce the charging performance. Although many practical
charging algorithms have been introduced, these studies mainly focus on
optimizing the charging path with a fully charging approach. This approach may
lead to the death of a series of sensors due to their extended charging
latency. This paper introduces a novel partial charging approach that follows a
bi-level optimized scheme to minimize energy depletion in WRSNs. We aim at
optimizing simultaneously two factors: the charging path and time. To
accomplish this, we first formulate a mathematical model of the investigated
problem. We then propose two approximate algorithms in which the optimization
of the charging path and the charging time are considered as the upper and
lower level, respectively. The first algorithm combines a Multi-start Local
Search method and a Genetic Algorithm to find a solution. The second algorithm
adopts a nested approach that utilizes the advantages of the Multitasking and
Covariance Matrix Adaptation Evolutionary Strategies. Experimental validations
on various network scenarios demonstrate that our proposed algorithms
outperform the existing works.

</details>


### [158] [Relevance for Stability of Verification Status of a Set of Arguments in Incomplete Argumentation Frameworks (with Proofs)](https://arxiv.org/abs/2505.16507)
*Anshu Xiong, Songmao Zhang*

**主要类别:** cs.AI

**概要:** 本文扩展了在不完全论证框架（IAFs）中关于单个论证的稳定性相关性概念，研究了一组论证的验证状态稳定性的相关性，并提出了强相关性概念。复杂性分析表明，在大多数语义下检测（强）相关性可以在P时间内完成，但在基础语义下的可处理方法仍存在困难。


<details>
  <summary>更多</summary>
  
**动机:** Odekerken等人在2024年提出了针对单个论证的稳定性相关性概念，本文旨在扩展这一概念以适用于一组论证的验证状态稳定性。

**方法:** 研究了在某些情况下需要解决的不确定性，以确保在每个IAF完成时，给定的一组论证是否为扩展的结果相同。提出了强相关性概念来描述所有情境下达到稳定性的必要性。

**结果:** 检测（强）相关性在多数语义下可以在P时间内完成，但基础语义下的可处理方法仍面临挑战。

**结论:** 扩展了相关性概念到一组论证的验证状态稳定性，并提出了强相关性，同时分析了其计算复杂性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Relevance+for+Stability+of+Verification+Status+of+a+Set+of+Arguments+in+Incomplete+Argumentation+Frameworks+%28with+Proofs%29，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16507，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16507&send_immediately=true&force_search=false)

**原文摘要:** The notion of relevance was proposed for stability of justification status of
a single argument in incomplete argumentation frameworks (IAFs) in 2024 by
Odekerken et al. To extend the notion, we study the relevance for stability of
verification status of a set of arguments in this paper, i.e., the
uncertainties in an IAF that have to be resolved in some situations so that
answering whether a given set of arguments is an extension obtains the same
result in every completion of the IAF. Further we propose the notion of strong
relevance for describing the necessity of resolution in all situations reaching
stability. An analysis of complexity reveals that detecting the (strong)
relevance for stability of sets of arguments can be accomplished in P time
under the most semantics discussed in the paper. We also discuss the difficulty
in finding tractable methods for relevance detection under grounded semantics.

</details>


### [159] [Bridging the Dynamic Perception Gap: Training-Free Draft Chain-of-Thought for Dynamic Multimodal Spatial Reasoning](https://arxiv.org/abs/2505.16579)
*Siqu Ou, Hongcheng Liu, Pingjie Wang, Yusheng Liao, Chuan Xuan, Yanfeng Wang, Yu Wang*

**主要类别:** cs.AI

**概要:** 通过将文本推理链与动态视觉草图结合，GRASSLAND基准和D2R框架在动态空间推理任务中显著提升了多模态大语言模型的表现。


<details>
  <summary>更多</summary>
  
**动机:** 尽管思维链（CoT）在多模态大语言模型（MLLMs）的复杂推理中取得了进展，但现有方法仍局限于文本或静态视觉领域，在动态空间推理任务中表现不佳。

**方法:** 1. 创建了GRASSLAND迷宫导航基准，用于评估动态空间推理。2. 提出了无需训练的D2R框架，将文本思维链与对应的视觉草图无缝集成到MLLMs中。

**结果:** 实验表明，增强文本推理链与动态视觉草图相结合的方法显著优于传统方法，并在多种任务中持续提升性能。

**结论:** D2R框架为动态空间推理提供了强大的基线，无需模型微调即可广泛应用于各类任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Bridging+the+Dynamic+Perception+Gap%3A+Training-Free+Draft+Chain-of-Thought+for+Dynamic+Multimodal+Spatial+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16579，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16579&send_immediately=true&force_search=false)

**原文摘要:** While chains-of-thought (CoT) have advanced complex reasoning in multimodal
large language models (MLLMs), existing methods remain confined to text or
static visual domains, often faltering in dynamic spatial reasoning tasks. To
bridge this gap, we present GRASSLAND, a novel maze navigation benchmark
designed to evaluate dynamic spatial reasoning. Our experiments show that
augmenting textual reasoning chains with dynamic visual drafts, overlaid on
input images, significantly outperforms conventional approaches, offering new
insights into spatial reasoning in evolving environments. To generalize this
capability, we propose D2R (Dynamic Draft-Augmented Reasoning), a training-free
framework that seamlessly integrates textual CoT with corresponding visual
drafts into MLLMs. Extensive evaluations demonstrate that D2R consistently
enhances performance across diverse tasks, establishing a robust baseline for
dynamic spatial reasoning without requiring model fine-tuning. Project is open
at https://github.com/Cratileo/D2R.

</details>


### [160] [Open and Sustainable AI: challenges, opportunities and the road ahead in the life sciences](https://arxiv.org/abs/2505.16619)
*Gavin Farrell, Eleni Adamidi, Rafael Andrade Buono, Mihail Anton, Omar Abdelghani Attafi, Salvador Capella Gutierrez, Emidio Capriotti, Leyla Jael Castro, Davide Cirillo, Lisa Crossman, Christophe Dessimoz, Alexandros Dimopoulos, Raul Fernandez-Diaz, Styliani-Christina Fragkouli, Carole Goble, Wei Gu, John M. Hancock, Alireza Khanteymoori, Tom Lenaerts, Fabio G. Liberante, Peter Maccallum, Alexander Miguel Monzon, Magnus Palmblad, Lucy Poveda, Ovidiu Radulescu, Denis C. Shields, Shoaib Sufi, Thanasis Vergoulis, Fotis Psomopoulos, Silvio C. E. Tosatto*

**主要类别:** cs.AI

**概要:** AI在生命科学领域的应用取得了突破性进展，但随之而来的研究结果的可重复性和可重用性问题也日益严重。本文提出了一套开放和可持续的AI（OSAI）建议，旨在推动可信、环保和透明的AI模型开发，并促进政策制定和实施路径的发展。


<details>
  <summary>更多</summary>
  
**动机:** 为了应对AI方法快速普及所带来的长期研究挑战，如信任度下降、可重复性差等问题，同时关注环境可持续性。

**方法:** 通过审查现有问题并结合生命科学社区共识，提出了超过300个AI生态系统组件相关的OSAI建议。

**结果:** 连接研究人员与相关AI资源，推动可持续、可重用和透明的AI模型发展，并为未来政策制定提供支持。

**结论:** 需要采取实际行动来解决AI研究中的信任、可重复性和可持续性问题，以最大化投资回报并加速生命科学研究进展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Open+and+Sustainable+AI%3A+challenges%2C+opportunities+and+the+road+ahead+in+the+life+sciences，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16619，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16619&send_immediately=true&force_search=false)

**原文摘要:** Artificial intelligence (AI) has recently seen transformative breakthroughs
in the life sciences, expanding possibilities for researchers to interpret
biological information at an unprecedented capacity, with novel applications
and advances being made almost daily. In order to maximise return on the
growing investments in AI-based life science research and accelerate this
progress, it has become urgent to address the exacerbation of long-standing
research challenges arising from the rapid adoption of AI methods. We review
the increased erosion of trust in AI research outputs, driven by the issues of
poor reusability and reproducibility, and highlight their consequent impact on
environmental sustainability. Furthermore, we discuss the fragmented components
of the AI ecosystem and lack of guiding pathways to best support Open and
Sustainable AI (OSAI) model development. In response, this perspective
introduces a practical set of OSAI recommendations directly mapped to over 300
components of the AI ecosystem. Our work connects researchers with relevant AI
resources, facilitating the implementation of sustainable, reusable and
transparent AI. Built upon life science community consensus and aligned to
existing efforts, the outputs of this perspective are designed to aid the
future development of policy and structured pathways for guiding AI
implementation.

</details>


### [161] [SMART: Self-Generating and Self-Validating Multi-Dimensional Assessment for LLMs' Mathematical Problem Solving](https://arxiv.org/abs/2505.16646)
*Yujie Hou, Ting Zhang, Mei Wang, Xuetao Ma, Hu Huang*

**主要类别:** cs.AI

**概要:** 大型语言模型在数学基准测试中表现出色，但这些成功是否反映了真正的数学推理能力仍存在争议。现有的评估指标如最终答案准确性无法充分解析底层能力。为此，我们提出了SMART框架：一个自我生成和自我验证的多维评估系统。SMART将数学问题解决分解为理解、推理、算术和反思四个维度，并通过定制任务独立评估每个维度。此外，SMART集成了自动化自我生成和自我验证机制，以确保可扩展性和可靠性。通过对21个最先进的开源和闭源大型语言模型进行评估，发现它们在不同维度上的能力存在显著差异。研究结果表明，仅依靠最终答案准确性的评估方法是不够的，需要一个新的综合指标来更好地捕捉真实的解决问题的能力。


<details>
  <summary>更多</summary>
  
**动机:** 目前对于大型语言模型在数学任务中的表现，尚不清楚其成功是基于真正的数学推理还是表面模式识别。同时，常用的评估指标（如最终答案准确性）无法有效解析模型在不同数学能力维度上的具体表现，因此需要更精细和全面的评估方法。

**方法:** 提出SMART框架，将数学问题解决过程分为理解、推理、算术和反思四个维度，并设计了针对性的任务来独立评估每个维度。此外，SMART还包含自动化的自我生成和自我验证机制，用于生成和验证基准数据，从而保证评估系统的可扩展性和可靠性。

**结果:** 通过对21个最先进的大型语言模型进行评估，发现它们在不同维度上的能力存在显著差异。结果表明，仅依赖最终答案准确性作为评估标准是不充分的。

**结论:** 需要采用新的综合性评估指标来更全面地衡量大型语言模型的真实问题解决能力，并且SMART框架为这一目标提供了一种可行的方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SMART%3A+Self-Generating+and+Self-Validating+Multi-Dimensional+Assessment+for+LLMs%27+Mathematical+Problem+Solving，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16646，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16646&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models have achieved remarkable results on a variety of
mathematical benchmarks. However, concerns remain as to whether these successes
reflect genuine mathematical reasoning or superficial pattern recognition.
Common evaluation metrics, such as final answer accuracy, fail to disentangle
the underlying competencies involved, offering limited diagnostic value. To
address these limitations, we introduce SMART: a Self-Generating and
Self-Validating Multi-Dimensional Assessment Framework. SMART decomposes
mathematical problem solving into four distinct dimensions: understanding,
reasoning, arithmetic, and reflection \& refinement. Each dimension is
evaluated independently through tailored tasks, enabling interpretable and
fine-grained analysis of LLM behavior. Crucially, SMART integrates an automated
self-generating and self-validating mechanism to produce and verify benchmark
data, ensuring both scalability and reliability. We apply SMART to 21
state-of-the-art open- and closed-source LLMs, uncovering significant
discrepancies in their abilities across different dimensions. Our findings
demonstrate the inadequacy of final answer accuracy as a sole metric and
motivate a new holistic metric to better capture true problem-solving
capabilities. Code and benchmarks will be released upon acceptance.

</details>


### [162] [ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming](https://arxiv.org/abs/2505.16667)
*Xinwei Yang, Zhaofeng Liu, Chen Huang, Jiashuai Zhang, Tong Zhang, Yifan Zhang, Wenqiang Lei*

**主要类别:** cs.AI

**概要:** 本文提出了一种人类反馈的分类法，覆盖整个编程过程以促进细粒度评估；引入了ELABORATIONSET数据集，用于模拟大规模人类反馈和实际人类交互研究；还提出了ELABORATION基准，用以全面评估人类与LLM在竞争性编程中的合作，并指出了现有方法的优势与不足。


<details>
  <summary>更多</summary>
  
**动机:** 当前关于人类与大型语言模型（LLM）在竞争性编程中合作的研究虽然众多，但因研究碎片化以及使用多样化的应用特定人类反馈，导致对这一领域的综合理解仍然有限。

**方法:** 1. 提出一种涵盖整个编程过程的人类反馈分类法，以支持细粒度评估。2. 创建名为ELABORATIONSET的新型编程数据集，该数据集经过精心标注，能够实现大规模模拟人类反馈并降低真实人类交互研究的成本。3. 引入ELABORATION新基准，以深入评估人类与LLM在竞争性编程中的协作效果。

**结果:** 通过提出的ELABORATION基准，成功识别出现有方法的优势与劣势，为未来改进奠定了基础。

**结论:** 本文通过提出分类法、新数据集及新基准，促进了对人类与LLM在竞争性编程中合作的全面理解，同时为未来研究提供了资源与方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ELABORATION%3A+A+Comprehensive+Benchmark+on+Human-LLM+Competitive+Programming，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16667，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16667&send_immediately=true&force_search=false)

**原文摘要:** While recent research increasingly emphasizes the value of human-LLM
collaboration in competitive programming and proposes numerous empirical
methods, a comprehensive understanding remains elusive due to the fragmented
nature of existing studies and their use of diverse, application-specific human
feedback. Thus, our work serves a three-fold purpose: First, we present the
first taxonomy of human feedback consolidating the entire programming process,
which promotes fine-grained evaluation. Second, we introduce ELABORATIONSET, a
novel programming dataset specifically designed for human-LLM collaboration,
meticulously annotated to enable large-scale simulated human feedback and
facilitate costeffective real human interaction studies. Third, we introduce
ELABORATION, a novel benchmark to facilitate a thorough assessment of human-LLM
competitive programming. With ELABORATION, we pinpoint strengthes and
weaknesses of existing methods, thereby setting the foundation for future
improvement. Our code and dataset are available at
https://github.com/SCUNLP/ELABORATION

</details>


### [163] [SPaRC: A Spatial Pathfinding Reasoning Challenge](https://arxiv.org/abs/2505.16686)
*Lars Benedikt Kaesberg, Jan Philip Wahle, Terry Ruas, Bela Gipp*

**主要类别:** cs.AI

**概要:** 现有的推理数据集无法测试抽象、多步骤的问题，尤其是路径寻找和复杂规则约束满足问题。我们引入了SPaRC数据集，包含1000个2D网格路径寻找谜题，用于评估空间和符号推理能力。人类在此任务上表现优异（98.0%准确率），而现有模型如o4-mini则表现不佳（15.8%准确率）。模型经常生成无效路径，并在导航和空间逻辑上出错。与人类不同，模型未能根据任务难度调整计算资源。通过多次尝试解题，模型的准确性有所提高，表明改进训练方法和高效测试时间扩展方法可能提升空间推理能力。SPaRC可用于揭示模型的空间推理局限性，并推动研究新的抽象、多步骤问题解决方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的推理数据集无法充分测试抽象、多步骤的问题，特别是路径寻找和复杂规则约束满足问题。因此需要一个新数据集来评估模型的空间和符号推理能力。

**方法:** 构建了一个名为SPaRC的数据集，包含1000个2D网格路径寻找谜题，要求逐步规划并遵循算术和几何规则。通过对比人类和现有推理模型的表现，分析模型在空间推理上的局限性。

**结果:** 人类在SPaRC数据集上表现出近乎完美的准确率（98.0%），尤其在简单谜题上表现优异；而现有模型如o4-mini则表现较差（15.8%），特别是在困难谜题上（1.1%）。模型经常生成无效路径，并在导航和空间逻辑上出错。

**结论:** SPaRC数据集揭示了现有模型在空间推理上的局限性，为改进训练方法和开发更高效的测试时间扩展方法提供了方向，有助于推动抽象、多步骤问题解决的研究。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SPaRC%3A+A+Spatial+Pathfinding+Reasoning+Challenge，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16686，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16686&send_immediately=true&force_search=false)

**原文摘要:** Existing reasoning datasets saturate and fail to test abstract, multi-step
problems, especially pathfinding and complex rule constraint satisfaction. We
introduce SPaRC (Spatial Pathfinding Reasoning Challenge), a dataset of 1,000
2D grid pathfinding puzzles to evaluate spatial and symbolic reasoning,
requiring step-by-step planning with arithmetic and geometric rules. Humans
achieve near-perfect accuracy (98.0%; 94.5% on hard puzzles), while the best
reasoning models, such as o4-mini, struggle (15.8%; 1.1% on hard puzzles).
Models often generate invalid paths (>50% of puzzles for o4-mini), and
reasoning tokens reveal they make errors in navigation and spatial logic.
Unlike humans, who take longer on hard puzzles, models fail to scale test-time
compute with difficulty. Allowing models to make multiple solution attempts
improves accuracy, suggesting potential for better spatial reasoning with
improved training and efficient test-time scaling methods. SPaRC can be used as
a window into models' spatial reasoning limitations and drive research toward
new methods that excel in abstract, multi-step problem-solving.

</details>


### [164] [MCP-RADAR: A Multi-Dimensional Benchmark for Evaluating Tool Use Capabilities in Large Language Models](https://arxiv.org/abs/2505.16700)
*Xuanqi Gao, Siyi Xie, Juan Zhai, Shqing Ma, Chao Shen*

**主要类别:** cs.AI

**概要:** 这篇论文提出了MCP-RADAR，一个全面评估大语言模型在Model Context Protocol框架下工具使用能力的基准。它通过五个维度进行客观量化测量，并揭示了不同模型在准确度、效率和速度上的权衡。


<details>
  <summary>更多</summary>
  
**动机:** 当前对大语言模型工具使用能力的评估方法不足，无法充分适应新的MCP框架下的需求。

**方法:** 引入MCP-RADAR，一个全新的基准测试方法，从答案准确性、工具选择效率、计算资源效率、参数构建准确性和执行速度五个维度进行评估。

**结果:** 对领先的商业和开源大语言模型的评估显示，不同模型在准确度、效率和速度上存在显著权衡。

**结论:** MCP-RADAR为开发者提供了优化工具的指导，并适用于所有大语言模型代理工具集成框架，推动整个LLM-工具交互生态系统的优化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MCP-RADAR%3A+A+Multi-Dimensional+Benchmark+for+Evaluating+Tool+Use+Capabilities+in+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16700，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16700&send_immediately=true&force_search=false)

**原文摘要:** As Large Language Models (LLMs) evolve from passive text generators to active
reasoning agents capable of tool interaction, the Model Context Protocol (MCP)
has emerged as a standardized framework for dynamic tool discovery and
orchestration. Despite widespread industry adoption, existing evaluation
methodologies fail to adequately assess tool utilization capabilities within
this new paradigm. This paper introduces MCP-RADAR, the first comprehensive
benchmark specifically designed to evaluate LLM performance in the MCP
framework through a novel five-dimensional approach measuring: answer accuracy,
tool selection efficiency, computational resource efficiency, parameter
construction accuracy, and execution speed. Unlike conventional benchmarks that
rely on subjective human evaluations or binary success metrics, MCP-RADAR
employs objective, quantifiable measurements across multiple task domains
including software engineering, mathematical reasoning, and general
problem-solving. Our evaluations of leading commercial and open-source LLMs
reveal distinctive capability profiles with significant trade-offs between
accuracy, efficiency, and speed, challenging traditional single-metric
performance rankings. Besides, we provide valuable guidance for developers to
optimize their tools for maximum model compatibility and effectiveness. While
focused on MCP due to its standardized approach, our methodology remains
applicable across all LLM agent tool integration frameworks, providing valuable
insights for both LLM developers and tool creators to optimize the entire
LLM-tool interaction ecosystem. The implementation, configurations, and
datasets used in our evaluation are publicly available at
https://anonymous.4open.science/r/MCPRadar-B143.

</details>


### [165] [Data-Driven Breakthroughs and Future Directions in AI Infrastructure: A Comprehensive Review](https://arxiv.org/abs/2505.16771)
*Beyazit Bestami Yuksel, Ayse Yilmazer Metin*

**主要类别:** cs.AI

**概要:** 这篇论文总结了过去十五年中人工智能领域的重大突破，从历史、理论和技术角度分析了这些进展，并探讨了未来的AI研究和政策发展方向。


<details>
  <summary>更多</summary>
  
**动机:** 整合历史、理论和技术视角，识别AI进化中的关键转折点，解释研究如何将突破转化为可扩展的解决方案，并评估隐私保护技术的作用。

**方法:** 通过追溯计算资源、数据访问和算法创新的汇聚来确定AI进化中的关键转折点；应用统计学习理论的概念如样本复杂性和数据效率来解释突破；评估新兴的隐私保护技术如联邦学习、PETs和数据站点范式。

**结果:** 明确了GPU模型训练、ImageNet引发的数据中心化转变、Transformer架构简化以及GPT系列扩展建模能力等为更深层次的范式转变的指标；强调了数据为中心方法的重要性；评估了在真实世界数据不可用时模拟和合成数据生成的效用和限制。

**结论:** 通过对技术见解与不断发展的数据基础设施的对齐，该研究为未来的AI研究和政策发展提供了战略指导。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Data-Driven+Breakthroughs+and+Future+Directions+in+AI+Infrastructure%3A+A+Comprehensive+Review，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16771，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16771&send_immediately=true&force_search=false)

**原文摘要:** This paper presents a comprehensive synthesis of major breakthroughs in
artificial intelligence (AI) over the past fifteen years, integrating
historical, theoretical, and technological perspectives. It identifies key
inflection points in AI' s evolution by tracing the convergence of
computational resources, data access, and algorithmic innovation. The analysis
highlights how researchers enabled GPU based model training, triggered a data
centric shift with ImageNet, simplified architectures through the Transformer,
and expanded modeling capabilities with the GPT series. Rather than treating
these advances as isolated milestones, the paper frames them as indicators of
deeper paradigm shifts. By applying concepts from statistical learning theory
such as sample complexity and data efficiency, the paper explains how
researchers translated breakthroughs into scalable solutions and why the field
must now embrace data centric approaches. In response to rising privacy
concerns and tightening regulations, the paper evaluates emerging solutions
like federated learning, privacy enhancing technologies (PETs), and the data
site paradigm, which reframe data access and security. In cases where real
world data remains inaccessible, the paper also assesses the utility and
constraints of mock and synthetic data generation. By aligning technical
insights with evolving data infrastructure, this study offers strategic
guidance for future AI research and policy development.

</details>


### [166] [Fuzzy Information Evolution with Three-Way Decision in Social Network Group Decision-Making](https://arxiv.org/abs/2505.16781)
*Qianlei Jia, Xinliang Zhou, Ondrej Krejcar, Enrique Herrera-Viedma*

**主要类别:** cs.AI

**概要:** 论文提出了一种新的社会网络群体决策(SNGDM)框架，结合三重决策理论、动态网络重建和语言意见表示来应对传统模型中的挑战。该框架通过引入三重决策机制、基于意见相似性的连接调整规则以及使用语言术语描述代理意见，能够有效处理不确定性、意见演变和网络动态。实验结果表明，该模型在多UAV协作决策场景中提高了系统稳定性和决策行为的真实性。


<details>
  <summary>更多</summary>
  
**动机:** 群体决策面临不确定性、动态社会结构和模糊信息的挑战，传统意见动力学模型难以有效应对这些问题。

**方法:** 1. 引入三重决策机制以明确建模代理判断中的犹豫和模糊性。
2. 开发基于意见相似性的连接调整规则，使代理能够自适应更新通信链路。
3. 使用语言术语描述代理意见，以更好地处理主观、模糊或不完整的信息。
4. 构建集成多代理决策框架，同时考虑个体不确定性、意见演化和网络动态。

**结果:** 该模型应用于多无人机协同决策场景中，模拟结果和共识分析证明了其有效性。实验比较进一步验证了该算法在提高系统稳定性和表示现实决策行为方面的优势。

**结论:** 所提出的SNGDM框架能够有效应对群体决策中的不确定性、动态社会结构和模糊信息问题，适用于多UAV协作决策等实际场景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Fuzzy+Information+Evolution+with+Three-Way+Decision+in+Social+Network+Group+Decision-Making，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16781，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16781&send_immediately=true&force_search=false)

**原文摘要:** In group decision-making (GDM) scenarios, uncertainty, dynamic social
structures, and vague information present major challenges for traditional
opinion dynamics models. To address these issues, this study proposes a novel
social network group decision-making (SNGDM) framework that integrates
three-way decision (3WD) theory, dynamic network reconstruction, and linguistic
opinion representation. First, the 3WD mechanism is introduced to explicitly
model hesitation and ambiguity in agent judgments, thereby preventing
irrational decisions. Second, a connection adjustment rule based on opinion
similarity is developed, enabling agents to adaptively update their
communication links and better reflect the evolving nature of social
relationships. Third, linguistic terms are used to describe agent opinions,
allowing the model to handle subjective, vague, or incomplete information more
effectively. Finally, an integrated multi-agent decision-making framework is
constructed, which simultaneously considers individual uncertainty, opinion
evolution, and network dynamics. The proposed model is applied to a multi-UAV
cooperative decision-making scenario, where simulation results and consensus
analysis demonstrate its effectiveness. Experimental comparisons further verify
the advantages of the algorithm in enhancing system stability and representing
realistic decision-making behaviors.

</details>


### [167] [Gaze Into the Abyss -- Planning to Seek Entropy When Reward is Scarce](https://arxiv.org/abs/2505.16787)
*Ashish Sundar, Chunbo Luo, Xiaoyang Wang*

**主要类别:** cs.AI

**概要:** 论文提出了一种新的MBRL方法，通过主动寻找高熵状态和分层规划器优化world model学习过程，在Miniworld迷宫任务中比基础Dreamer更高效。


<details>
  <summary>更多</summary>
  
**动机:** MBRL方法主要关注actor的优化，而忽视了world model的学习优化。然而，提高world model的保真度和减少其收敛时间可以带来显著的下游好处，例如改善actor的训练性能。

**方法:** 提出了一种新方法，该方法利用world model生成的短视距潜在预测，主动寻找高熵状态，为传统的基于好奇心的方法提供了一个有原则的替代方案。此外，还提出了一个分层规划器，动态决定何时重新规划、规划时长以及奖励与熵之间的权重。该方法理论上可应用于任何仅使用模型生成数据训练actor的模型，但本文只以Dreamer为例进行概念验证。

**结果:** 在Miniworld程序生成的迷宫任务中，相较于基础Dreamer，该方法在收敛时速度快50％，且在想象中训练的策略只需要基础Dreamer 60%的环境步骤即可收敛。

**结论:** 通过优化world model学习过程，可以显著提升MBRL方法的样本效率和收敛速度。所提出的新方法在测试环境中表现优于基础Dreamer。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Gaze+Into+the+Abyss+--+Planning+to+Seek+Entropy+When+Reward+is+Scarce，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16787，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16787&send_immediately=true&force_search=false)

**原文摘要:** Model-based reinforcement learning (MBRL) offers an intuitive way to increase
the sample efficiency of model-free RL methods by simultaneously training a
world model that learns to predict the future. MBRL methods have progressed by
largely prioritising the actor; optimising the world model learning has been
neglected meanwhile. Improving the fidelity of the world model and reducing its
time to convergence can yield significant downstream benefits, one of which is
improving the ensuing performance of any actor it may train. We propose a novel
approach that anticipates and actively seeks out high-entropy states using
short-horizon latent predictions generated by the world model, offering a
principled alternative to traditional curiosity-driven methods that chase
once-novel states well after they were stumbled into. While many model
predictive control (MPC) based methods offer similar alternatives, they
typically lack commitment, synthesising multi step plans after every step. To
mitigate this, we present a hierarchical planner that dynamically decides when
to replan, planning horizon length, and the weighting between reward and
entropy. While our method can theoretically be applied to any model that trains
its own actors with solely model generated data, we have applied it to just
Dreamer as a proof of concept. Our method finishes the Miniworld procedurally
generated mazes 50% faster than base Dreamer at convergence and the policy
trained in imagination converges in only 60% of the environment steps that base
Dreamer needs.

</details>


### [168] [KTAE: A Model-Free Algorithm to Key-Tokens Advantage Estimation in Mathematical Reasoning](https://arxiv.org/abs/2505.16826)
*Wei Sun, Wen Yang, Pu Jian, Qianlong Du, Fuwei Cui, Shuo Ren, Jiajun Zhang*

**主要类别:** cs.AI

**概要:** 近期研究表明，将强化学习与基于规则的奖励相结合，可以显著提升大语言模型的推理能力，即使不进行监督微调。然而，现有的强化学习算法（如GRPO和DAPO）在计算优势时存在粗粒度问题，即它们为序列中的每个标记分配相同的值，无法捕捉标记特定的贡献，阻碍了有效学习。为了解决这一局限性，我们提出了关键标记优势估计（KTAE），这是一种新的算法，可以在不引入额外模型的情况下估计细粒度的标记级优势。KTAE利用采样rollouts的正确性，并应用统计分析来量化序列中单个标记对最终结果的重要性。这种量化的标记级重要性随后与rollout级优势结合，以获得更细粒度的标记级优势估计。实证结果显示，使用GRPO+KTAE和DAPO+KTAE训练的模型在五个数学推理基准上优于基线方法。值得注意的是，它们以较短的回答实现了更高的准确性，甚至在使用相同基础模型的情况下超过了R1-Distill-Qwen-1.5B。


<details>
  <summary>更多</summary>
  
**动机:** 尽管强化学习与基于规则的奖励相结合能增强大语言模型的推理能力，但现有算法（如GRPO和DAPO）在计算优势时存在粗粒度问题，限制了模型的学习效果。因此，需要一种新的方法来解决这一问题，从而提高模型的性能。

**方法:** 提出了一种名为Key-token Advantage Estimation (KTAE)的新算法。该算法通过利用采样rollouts的正确性和统计分析，量化序列中单个标记对最终结果的重要性，然后将这种标记级重要性与rollout级优势结合，以获得更细粒度的标记级优势估计。

**结果:** 实验结果表明，使用GRPO+KTAE和DAPO+KTAE训练的模型在五个数学推理基准上超越了基线方法。这些模型不仅在较短的回答中实现了更高的准确性，而且在使用相同基础模型的情况下，其表现甚至超过了R1-Distill-Qwen-1.5B。

**结论:** KTAE算法能够有效地解决现有强化学习算法在优势估计中的粗粒度问题，显著提升模型在数学推理任务中的表现。这表明，细粒度的标记级优势估计对于改进强化学习模型具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是KTAE%3A+A+Model-Free+Algorithm+to+Key-Tokens+Advantage+Estimation+in+Mathematical+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16826，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16826&send_immediately=true&force_search=false)

**原文摘要:** Recent advances have demonstrated that integrating reinforcement learning
with rule-based rewards can significantly enhance the reasoning capabilities of
large language models, even without supervised fine-tuning. However, prevalent
reinforcement learning algorithms such as GRPO and its variants like DAPO,
suffer from a coarse granularity issue when computing the advantage.
Specifically, they compute rollout-level advantages that assign identical
values to every token within a sequence, failing to capture token-specific
contributions and hindering effective learning. To address this limitation, we
propose Key-token Advantage Estimation (KTAE) - a novel algorithm that
estimates fine-grained, token-level advantages without introducing additional
models. KTAE leverages the correctness of sampled rollouts and applies
statistical analysis to quantify the importance of individual tokens within a
sequence to the final outcome. This quantified token-level importance is then
combined with the rollout-level advantage to obtain a more fine-grained
token-level advantage estimation. Empirical results show that models trained
with GRPO+KTAE and DAPO+KTAE outperform baseline methods across five
mathematical reasoning benchmarks. Notably, they achieve higher accuracy with
shorter responses and even surpass R1-Distill-Qwen-1.5B using the same base
model.

</details>


### [169] [GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent](https://arxiv.org/abs/2505.16827)
*Bin Xie, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Jie Liu, Min Zhang, Liqiang Nie*

**主要类别:** cs.AI

**概要:** 在动态环境中，GUI自动化面临重大挑战。现有的MLLMs存在两个主要问题：错误解释UI组件和知识过时。传统的微调方法对于特定应用的知识更新成本过高。本文提出了GUI-explorer，一种无需训练的GUI代理，包含两个核心机制：(1) 自主探索功能感知轨迹；(2) 无监督挖掘转换感知知识。通过这些机制，GUI-explorer在SPA-Bench和AndroidWorld上的任务成功率分别达到53.7%和47.4%，显著优于现有技术，并且对新应用无需参数更新。


<details>
  <summary>更多</summary>
  
**动机:** 当前的MLLMs在GUI自动化中表现不佳，主要是因为它们容易误解UI组件并且知识容易过时。此外，传统方法在更新特定应用知识时成本高昂，因此需要一种新的解决方案来克服这些问题。

**方法:** GUI-explorer采用两种基本机制：(1) 自主探索功能感知轨迹——设计了一个功能感知任务目标生成器，通过分析GUI结构信息（如截图和活动层次）自动构建探索目标，从而实现系统化探索以收集多样化的轨迹。(2) 无监督挖掘转换感知知识——开发了一个转换感知知识提取器，通过无监督分析结构化交互三元组（观察、动作、结果）的状态转换，提取有效的屏幕操作逻辑，从而无需人工参与知识提取过程。

**结果:** 实验结果表明，在SPA-Bench数据集上任务成功率为53.7%，在AndroidWorld数据集上任务成功率为47.4%，相比现有技术有显著提升。并且，GUI-explorer在处理新应用时无需更新参数。

**结论:** GUI-explorer作为一种无需训练的GUI代理，通过自主探索和无监督知识挖掘有效解决了现有方法中的关键问题，提升了GUI自动化在动态环境中的性能，并开源供公众使用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GUI-explorer%3A+Autonomous+Exploration+and+Mining+of+Transition-aware+Knowledge+for+GUI+Agent，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16827，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16827&send_immediately=true&force_search=false)

**原文摘要:** GUI automation faces critical challenges in dynamic environments. MLLMs
suffer from two key issues: misinterpreting UI components and outdated
knowledge. Traditional fine-tuning methods are costly for app-specific
knowledge updates. We propose GUI-explorer, a training-free GUI agent that
incorporates two fundamental mechanisms: (1) Autonomous Exploration of
Function-aware Trajectory. To comprehensively cover all application
functionalities, we design a Function-aware Task Goal Generator that
automatically constructs exploration goals by analyzing GUI structural
information (e.g., screenshots and activity hierarchies). This enables
systematic exploration to collect diverse trajectories. (2) Unsupervised Mining
of Transition-aware Knowledge. To establish precise screen-operation logic, we
develop a Transition-aware Knowledge Extractor that extracts effective
screen-operation logic through unsupervised analysis the state transition of
structured interaction triples (observation, action, outcome). This eliminates
the need for human involvement in knowledge extraction. With a task success
rate of 53.7% on SPA-Bench and 47.4% on AndroidWorld, GUI-explorer shows
significant improvements over SOTA agents. It requires no parameter updates for
new apps. GUI-explorer is open-sourced and publicly available at
https://github.com/JiuTian-VL/GUI-explorer.

</details>


### [170] [From EduVisBench to EduVisAgent: A Benchmark and Multi-Agent Framework for Pedagogical Visualization](https://arxiv.org/abs/2505.16832)
*Haonian Ji, Shi Qiu, Siyang Xin, Siwei Han, Zhaorun Chen, Hongyi Wang, Dake Zhang, Huaxiu Yao*

**主要类别:** cs.AI

**概要:** 在教育领域，基础模型生成有效视觉解释的能力有限。论文提出了EduVisBench基准和EduVisAgent框架，后者显著提升了模型性能。


<details>
  <summary>更多</summary>
  
**动机:** 尽管基础模型在教育场景中广泛应用，但其生成教育上有效的视觉解释的能力仍然不足，特别是在结合结构化和可解释的可视化以支持概念理解方面存在局限。

**方法:** 引入了EduVisBench多领域多层次基准来评估模型的视觉推理能力，并提出了EduVisAgent多代理协作框架，该框架协调专门代理进行教学规划、推理分解、元认知提示和可视化设计。

**结果:** 实验结果表明，EduVisAgent大幅优于所有基线方法，性能提升40.2%，并提供了更符合教育需求的可视化。

**结论:** EduVisAgent通过多代理协作显著提高了基础模型在教育场景中的视觉推理和解释能力，为未来研究提供了新方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是From+EduVisBench+to+EduVisAgent%3A+A+Benchmark+and+Multi-Agent+Framework+for+Pedagogical+Visualization，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16832，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16832&send_immediately=true&force_search=false)

**原文摘要:** While foundation models (FMs), such as diffusion models and large
vision-language models (LVLMs), have been widely applied in educational
contexts, their ability to generate pedagogically effective visual explanations
remains limited. Most existing approaches focus primarily on textual reasoning,
overlooking the critical role of structured and interpretable visualizations in
supporting conceptual understanding. To better assess the visual reasoning
capabilities of FMs in educational settings, we introduce EduVisBench, a
multi-domain, multi-level benchmark. EduVisBench features diverse STEM problem
sets requiring visually grounded solutions, along with a fine-grained
evaluation rubric informed by pedagogical theory. Our empirical analysis
reveals that existing models frequently struggle with the inherent challenge of
decomposing complex reasoning and translating it into visual representations
aligned with human cognitive processes. To address these limitations, we
propose EduVisAgent, a multi-agent collaborative framework that coordinates
specialized agents for instructional planning, reasoning decomposition,
metacognitive prompting, and visualization design. Experimental results show
that EduVisAgent substantially outperforms all baselines, achieving a 40.2%
improvement and delivering more educationally aligned visualizations.
EduVisBench and EduVisAgent are available at
https://github.com/aiming-lab/EduVisBench and
https://github.com/aiming-lab/EduVisAgent.

</details>


### [171] [Think or Not? Selective Reasoning via Reinforcement Learning for Vision-Language Models](https://arxiv.org/abs/2505.16854)
*Jiaqi Wang, Kevin Qinghong Lin, James Cheng, Mike Zheng Shou*

**主要类别:** cs.AI

**概要:** TON是一种两阶段训练策略，通过'thought dropout'操作和GRPO阶段使视觉-语言模型能够选择性地进行推理，从而减少完成长度并保持性能。


<details>
  <summary>更多</summary>
  
**动机:** 受到人类思维过程的启发，提出了一种让视觉-语言模型首先决定何时需要推理的方法，以避免不必要的推理步骤。

**方法:** 提出TON，一种两阶段训练策略：(i) SFT阶段使用'thought dropout'操作引入思考或不思考格式；(ii) GRPO阶段允许模型探索何时思考或不思考，并最大化任务感知结果奖励。

**结果:** 实验表明，TON可将完成长度减少高达90%，同时不牺牲性能甚至提升性能。在不同规模模型和任务中，模型逐渐学会跳过不必要的推理步骤。

**结论:** TON为实现类人推理模式提供了新的方向，特别是在强化学习方法中。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Think+or+Not%3F+Selective+Reasoning+via+Reinforcement+Learning+for+Vision-Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16854，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16854&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement Learning (RL) has proven to be an effective post-training
strategy for enhancing reasoning in vision-language models (VLMs). Group
Relative Policy Optimization (GRPO) is a recent prominent method that
encourages models to generate complete reasoning traces before answering,
leading to increased token usage and computational cost. Inspired by the
human-like thinking process-where people skip reasoning for easy questions but
think carefully when needed-we explore how to enable VLMs to first decide when
reasoning is necessary. To realize this, we propose TON, a two-stage training
strategy: (i) a supervised fine-tuning (SFT) stage with a simple yet effective
'thought dropout' operation, where reasoning traces are randomly replaced with
empty thoughts. This introduces a think-or-not format that serves as a cold
start for selective reasoning; (ii) a GRPO stage that enables the model to
freely explore when to think or not, while maximizing task-aware outcome
rewards. Experimental results show that TON can reduce the completion length by
up to 90% compared to vanilla GRPO, without sacrificing performance or even
improving it. Further evaluations across diverse vision-language tasks-covering
a range of reasoning difficulties under both 3B and 7B models-consistently
reveal that the model progressively learns to bypass unnecessary reasoning
steps as training advances. These findings shed light on the path toward
human-like reasoning patterns in reinforcement learning approaches. Our code is
available at https://github.com/kokolerk/TON.

</details>


### [172] [Predicate-Conditional Conformalized Answer Sets for Knowledge Graph Embeddings](https://arxiv.org/abs/2505.16877)
*Yuqicheng Zhu, Daniel Hernández, Yuan He, Zifeng Ding, Bo Xiong, Evgeny Kharlamov, Steffen Staab*

**主要类别:** cs.AI

**概要:** 本论文提出了一种名为CondKGCP的新方法，该方法通过合并具有相似向量表示的谓词并增强校准过程以包含排名信息，从而在保持紧凑预测集的同时近似谓词条件覆盖保证。这种方法适用于需要高可靠性的应用（如医疗诊断），并通过理论和实证两方面验证了其有效性。


<details>
  <summary>更多</summary>
  
**动机:** 现有的知识图谱嵌入（KGE）不确定性量化方法仅提供基于查询和答案参考集合的平均概率保证（边际覆盖保证）。然而，在诸如医疗诊断等高风险应用中，通常需要更强的保证：即针对每个查询提供一致的覆盖率（条件覆盖保证）。

**方法:** 论文提出了CondKGCP方法，它通过以下步骤实现条件覆盖保证：1) 合并具有相似向量表示的谓词；2) 在校准过程中加入排名信息。这些技术帮助生成更精确且紧凑的预测集。

**结果:** 作者通过综合评估证明了CondKGCP方法的理论保证，并展示了其在实际应用中的有效性。结果表明，该方法能够在保持预测集紧凑性的同时提供接近谓词条件覆盖保证的性能。

**结论:** CondKGCP是一种新颖的方法，能够为知识图谱嵌入提供更强的条件覆盖保证，同时保持预测集的紧凑性。这使得它在高风险应用场景中具有较大的潜力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Predicate-Conditional+Conformalized+Answer+Sets+for+Knowledge+Graph+Embeddings，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16877，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16877&send_immediately=true&force_search=false)

**原文摘要:** Uncertainty quantification in Knowledge Graph Embedding (KGE) methods is
crucial for ensuring the reliability of downstream applications. A recent work
applies conformal prediction to KGE methods, providing uncertainty estimates by
generating a set of answers that is guaranteed to include the true answer with
a predefined confidence level. However, existing methods provide probabilistic
guarantees averaged over a reference set of queries and answers (marginal
coverage guarantee). In high-stakes applications such as medical diagnosis, a
stronger guarantee is often required: the predicted sets must provide
consistent coverage per query (conditional coverage guarantee). We propose
CondKGCP, a novel method that approximates predicate-conditional coverage
guarantees while maintaining compact prediction sets. CondKGCP merges
predicates with similar vector representations and augments calibration with
rank information. We prove the theoretical guarantees and demonstrate empirical
effectiveness of CondKGCP by comprehensive evaluations.

</details>


### [173] [Identifying, Evaluating, and Mitigating Risks of AI Thought Partnerships](https://arxiv.org/abs/2505.16899)
*Kerem Oktar, Katherine M. Collins, Jose Hernandez-Orallo, Diane Coyle, Stephen Cave, Adrian Weller, Ilia Sucholutsky*

**主要类别:** cs.AI

**概要:** 这篇论文探讨了AI作为人类思维伙伴在复杂推理中的新型合作方式，提出了评估和缓解其多层面风险的框架与策略。


<details>
  <summary>更多</summary>
  
**动机:** 随着AI技术的进步，AI不再局限于执行狭义任务，而是能够与人类在复杂推理中进行真正意义上的协作，从问题概念化到解决方案头脑风暴。这种新型合作形式带来了新的认知扩展可能性，但也伴随着重大风险。

**方法:** 作者通过提出一个新颖的框架（RISc），系统地识别AI思维伙伴在实时、个体和社会层面的风险，并基于此框架提出具体的评估指标和缓解策略。

**结果:** 该框架成功识别了AI思维伙伴在不同层面上可能带来的风险，并为开发者和政策制定者提供了具体的风险缓解策略。

**结论:** 随着AI思维伙伴的不断普及，论文提出的策略有助于防止重大危害的发生，并确保人类能从这种高效的思维合作关系中获益。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Identifying%2C+Evaluating%2C+and+Mitigating+Risks+of+AI+Thought+Partnerships，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16899，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16899&send_immediately=true&force_search=false)

**原文摘要:** Artificial Intelligence (AI) systems have historically been used as tools
that execute narrowly defined tasks. Yet recent advances in AI have unlocked
possibilities for a new class of models that genuinely collaborate with humans
in complex reasoning, from conceptualizing problems to brainstorming solutions.
Such AI thought partners enable novel forms of collaboration and extended
cognition, yet they also pose major risks-including and beyond risks of typical
AI tools and agents. In this commentary, we systematically identify risks of AI
thought partners through a novel framework that identifies risks at multiple
levels of analysis, including Real-time, Individual, and Societal risks arising
from collaborative cognition (RISc). We leverage this framework to propose
concrete metrics for risk evaluation, and finally suggest specific mitigation
strategies for developers and policymakers. As AI thought partners continue to
proliferate, these strategies can help prevent major harms and ensure that
humans actively benefit from productive thought partnerships.

</details>


### [174] [Beyond Needle(s) in the Embodied Haystack: Environment, Architecture, and Training Considerations for Long Context Reasoning](https://arxiv.org/abs/2505.16928)
*Bosung Kim, Prithviraj Ammanabrolu*

**主要类别:** cs.AI

**概要:** 提出了一个新框架$\infty$-THOR，用于长时域具身任务，推动了具身AI中的长上下文理解。该框架提供了生成可扩展、可重现且无限长时域轨迹的生成框架；一种新的具身问答任务Needle(s) in the Embodied Haystack；以及一个包含复杂任务的长时域数据集和基准套件。为了实现这一能力，我们探索了架构适应，包括交错的目标-状态-动作建模、上下文扩展技术和上下文并行性，以使基于LLM的代理能够进行极端长上下文推理和交互。实验结果和分析突显了我们基准带来的挑战，并提供了关于训练策略和模型在长时域条件下的行为的见解。这项工作为下一代具备强大长时推理和规划能力的具身AI系统奠定了基础。


<details>
  <summary>更多</summary>
  
**动机:** 当前具身AI系统在长时域任务中的表现有限，缺乏对长上下文的理解和推理能力。因此需要一个新的框架来解决这些限制，提升AI系统在复杂、长时域任务中的表现。

**方法:** 1. 开发了一个生成框架，用于合成可扩展、可重现且无限长时域的轨迹。
2. 提出了一个新的具身问答任务Needle(s) in the Embodied Haystack，测试代理的长上下文推理能力。
3. 创建了一个长时域数据集和基准套件，包含跨越数百个环境步骤的复杂任务。
4. 探索了架构适应技术，包括交错目标-状态-动作建模、上下文扩展技术和上下文并行性，以增强基于LLM的代理的能力。

**结果:** 实验结果表明，所提出的基准带来了显著的挑战，同时提供了关于训练策略和模型行为的重要见解。这有助于改进模型在长时域条件下的表现。

**结论:** $\infty$-THOR框架为下一代具身AI系统奠定了基础，使其具备强大的长时推理和规划能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Beyond+Needle%28s%29+in+the+Embodied+Haystack%3A+Environment%2C+Architecture%2C+and+Training+Considerations+for+Long+Context+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16928，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16928&send_immediately=true&force_search=false)

**原文摘要:** We introduce $\infty$-THOR, a new framework for long-horizon embodied tasks
that advances long-context understanding in embodied AI. $\infty$-THOR
provides: (1) a generation framework for synthesizing scalable, reproducible,
and unlimited long-horizon trajectories; (2) a novel embodied QA task,
Needle(s) in the Embodied Haystack, where multiple scattered clues across
extended trajectories test agents' long-context reasoning ability; and (3) a
long-horizon dataset and benchmark suite featuring complex tasks that span
hundreds of environment steps, each paired with ground-truth action sequences.
To enable this capability, we explore architectural adaptations, including
interleaved Goal-State-Action modeling, context extension techniques, and
Context Parallelism, to equip LLM-based agents for extreme long-context
reasoning and interaction. Experimental results and analyses highlight the
challenges posed by our benchmark and provide insights into training strategies
and model behaviors under long-horizon conditions. Our work provides a
foundation for the next generation of embodied AI systems capable of robust,
long-term reasoning and planning.

</details>


### [175] [NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification](https://arxiv.org/abs/2505.16938)
*NovelSeek Team, Bo Zhang, Shiyang Feng, Xiangchao Yan, Jiakang Yuan, Zhiyin Yu, Xiaohan He, Songtao Huang, Shaowei Hou, Zheng Nie, Zhilong Wang, Jinyao Liu, Runmin Ma, Tianshuo Peng, Peng Ye, Dongzhan Zhou, Shufei Zhang, Xiaosong Wang, Yilan Zhang, Meng Li, Zhongying Tu, Xiangyu Yue, Wangli Ouyang, Bowen Zhou, Lei Bai*

**主要类别:** cs.AI

**概要:** 论文介绍了一种名为NovelSeek的统一闭环多代理框架，用于在多个科学领域进行自主科学研究(ASR)，具有可扩展性、交互性和高效性三个关键优势。


<details>
  <summary>更多</summary>
  
**动机:** 随着人工智能的发展，它不仅提高了研究效率，还推动了创新，加速了科学研究范式的转变。因此，引入一种能够跨科学领域进行自主科学研究的框架变得至关重要。

**方法:** 提出了一种名为NovelSeek的统一闭环多代理框架，该框架具有以下特点：1) 可扩展性：适用于12个科学任务；2) 交互性：提供人类专家反馈和多代理交互接口；3) 高效性：显著减少时间成本，提升性能。

**结果:** 在多个科学领域中，NovelSeek展示了显著的性能提升：反应产率预测从27.6%提升到35.4%，增强子活性预测准确率从0.52提升到0.79，2D语义分割精度从78.8%提升到81.0%。

**结论:** NovelSeek为跨学科科学研究提供了强大的工具，能够以前所未有的速度和精确度解决复杂问题，极大地提升了科研效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是NovelSeek%3A+When+Agent+Becomes+the+Scientist+--+Building+Closed-Loop+System+from+Hypothesis+to+Verification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16938，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16938&send_immediately=true&force_search=false)

**原文摘要:** Artificial Intelligence (AI) is accelerating the transformation of scientific
research paradigms, not only enhancing research efficiency but also driving
innovation. We introduce NovelSeek, a unified closed-loop multi-agent framework
to conduct Autonomous Scientific Research (ASR) across various scientific
research fields, enabling researchers to tackle complicated problems in these
fields with unprecedented speed and precision. NovelSeek highlights three key
advantages: 1) Scalability: NovelSeek has demonstrated its versatility across
12 scientific research tasks, capable of generating innovative ideas to enhance
the performance of baseline code. 2) Interactivity: NovelSeek provides an
interface for human expert feedback and multi-agent interaction in automated
end-to-end processes, allowing for the seamless integration of domain expert
knowledge. 3) Efficiency: NovelSeek has achieved promising performance gains in
several scientific fields with significantly less time cost compared to human
efforts. For instance, in reaction yield prediction, it increased from 27.6% to
35.4% in just 12 hours; in enhancer activity prediction, accuracy rose from
0.52 to 0.79 with only 4 hours of processing; and in 2D semantic segmentation,
precision advanced from 78.8% to 81.0% in a mere 30 hours.

</details>


### [176] [AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios](https://arxiv.org/abs/2505.16944)
*Yunjia Qi, Hao Peng, Xiaozhi Wang, Amy Xin, Youfeng Liu, Bin Xu, Lei Hou, Juanzi Li*

**主要类别:** cs.AI

**概要:** 大型语言模型（LLMs）在真实世界的应用中表现出高级能力。为了评估LLMs遵循指令的能力，我们引入了AgentIF基准测试。通过分析现有模型的表现，发现它们在处理复杂约束结构和工具规格方面表现不佳。


<details>
  <summary>更多</summary>
  
**动机:** 目前对于LLMs是否能可靠地遵循 lengthy instructions with complex constraints 尚未得到充分研究，而这对agentic applications至关重要。

**方法:** 构建了一个名为AgentIF的基准测试，包含来自50个真实世界代理应用的707条人类标注的指令，平均每条指令1,723词，并有11.9个约束条件。使用多种评估方法，包括基于代码、LLM和混合评估。

**结果:** 当前先进的LLMs总体表现较差，特别是在处理复杂约束结构和工具规格时。进行了错误分析和实验，揭示了现有LLMs的失败模式。

**结论:** AgentIF为系统评估LLMs在代理场景中的指令遵循能力提供了首个基准，揭示了现有模型的不足，并为未来研究提供了资源和方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AGENTIF%3A+Benchmarking+Instruction+Following+of+Large+Language+Models+in+Agentic+Scenarios，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16944，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16944&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) have demonstrated advanced capabilities in
real-world agentic applications. Growing research efforts aim to develop
LLM-based agents to address practical demands, introducing a new challenge:
agentic scenarios often involve lengthy instructions with complex constraints,
such as extended system prompts and detailed tool specifications. While
adherence to such instructions is crucial for agentic applications, whether
LLMs can reliably follow them remains underexplored. In this paper, we
introduce AgentIF, the first benchmark for systematically evaluating LLM
instruction following ability in agentic scenarios. AgentIF features three key
characteristics: (1) Realistic, constructed from 50 real-world agentic
applications. (2) Long, averaging 1,723 words with a maximum of 15,630 words.
(3) Complex, averaging 11.9 constraints per instruction, covering diverse
constraint types, such as tool specifications and condition constraints. To
construct AgentIF, we collect 707 human-annotated instructions across 50
agentic tasks from industrial application agents and open-source agentic
systems. For each instruction, we annotate the associated constraints and
corresponding evaluation metrics, including code-based evaluation, LLM-based
evaluation, and hybrid code-LLM evaluation. We use AgentIF to systematically
evaluate existing advanced LLMs. We observe that current models generally
perform poorly, especially in handling complex constraint structures and tool
specifications. We further conduct error analysis and analytical experiments on
instruction length and meta constraints, providing some findings about the
failure modes of existing LLMs. We have released the code and data to
facilitate future research.

</details>


### [177] [HyGenar: An LLM-Driven Hybrid Genetic Algorithm for Few-Shot Grammar Generation](https://arxiv.org/abs/2505.16978)
*Weizhi Tang, Yixuan Li, Chris Sypherd, Elizabeth Polgreen, Vaishak Belle*

**主要类别:** cs.AI

**概要:** 语法在自然语言处理和文本/代码生成中起着关键作用。尽管大型语言模型（LLMs）在各个领域表现出令人印象深刻的能力，但它们推断和生成语法的能力尚未得到充分研究。本文通过引入一个包含540个结构化语法生成挑战的新数据集、设计6个度量标准，并评估8种不同的LLM来研究LLM在少量样本语法生成中的能力。研究发现现有的LLM在语法生成方面表现不佳。为此，我们提出了一种由LLM驱动的混合遗传算法HyGenar，以优化语法生成。HyGenar在提高生成语法的句法和语义正确性方面取得了显著进展。


<details>
  <summary>更多</summary>
  
**动机:** 探讨大型语言模型在语法生成方面的不足，并试图通过新方法改善其性能。

**方法:** 1. 构建了一个包含540个结构化语法生成任务的数据集。
2. 设计了6个评估指标。
3. 评估了8种不同的LLM模型。
4. 提出了LLM驱动的混合遗传算法HyGenar。

**结果:** 实验结果表明现有LLM在语法生成上表现欠佳，而HyGenar在提升生成语法的句法和语义正确性方面有显著改进。

**结论:** 现有的LLM在语法生成方面存在局限性，但通过使用HyGenar等混合方法可以显著提升其性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是HyGenar%3A+An+LLM-Driven+Hybrid+Genetic+Algorithm+for+Few-Shot+Grammar+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16978，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16978&send_immediately=true&force_search=false)

**原文摘要:** Grammar plays a critical role in natural language processing and text/code
generation by enabling the definition of syntax, the creation of parsers, and
guiding structured outputs. Although large language models (LLMs) demonstrate
impressive capabilities across domains, their ability to infer and generate
grammars has not yet been thoroughly explored. In this paper, we aim to study
and improve the ability of LLMs for few-shot grammar generation, where grammars
are inferred from sets of a small number of positive and negative examples and
generated in Backus-Naur Form. To explore this, we introduced a novel dataset
comprising 540 structured grammar generation challenges, devised 6 metrics, and
evaluated 8 various LLMs against it. Our findings reveal that existing LLMs
perform sub-optimally in grammar generation. To address this, we propose an
LLM-driven hybrid genetic algorithm, namely HyGenar, to optimize grammar
generation. HyGenar achieves substantial improvements in both the syntactic and
semantic correctness of generated grammars across LLMs.

</details>


### [178] [Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design](https://arxiv.org/abs/2505.16979)
*Zhenkun Li, Lingyao Li, Shuhang Lin, Yongfeng Zhang*

**主要类别:** cs.AI

**概要:** 通过将领域先验转换为算法蓝图层次结构，Know-The-Ropes（KtR）框架解决了单代理和多代理语言模型的局限性。实验表明，在背包问题和任务分配问题上，分解任务并针对性增强可显著提高小规模模型的性能。


<details>
  <summary>更多</summary>
  
**动机:** 单一代理LLMs存在有限上下文、角色过载和脆弱领域迁移等问题，而传统多代理方法虽有所改善，却引入了新的挑战，如不明确的分解、模糊的合同和验证开销。因此需要一个新框架来解决这些问题。

**方法:** 提出了一种名为Know-The-Ropes (KtR) 的框架，该框架将领域先验转化为算法蓝图层次结构。在这个结构中，任务被递归地分解为由控制器介导的子任务，每个子任务可以通过零样本学习或最轻量的增强（如思维链、微调、自我检查等）来解决。这种方法基于No-Free-Lunch定理，用有纪律的分解代替对通用提示符的追求。

**结果:** 在背包问题（3-8件物品）中，三个GPT-4o-mini代理通过修补单一瓶颈代理，将5件物品大小实例的准确率从3%提升到95%。在更困难的任务分配问题（6-15个任务）中，六代理o3-mini蓝图在规模达10时达到100%，规模13-15时达到84%，而零样本准确率为11%。

**结论:** 算法感知分解与目标增强相结合，可以将适度的模型转变为可靠的合作者，无需不断增大的单一模型。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Know+the+Ropes%3A+A+Heuristic+Strategy+for+LLM-based+Multi-Agent+System+Design，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16979，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16979&send_immediately=true&force_search=false)

**原文摘要:** Single-agent LLMs hit hard limits--finite context, role overload, and brittle
domain transfer. Conventional multi-agent fixes soften those edges yet expose
fresh pains: ill-posed decompositions, fuzzy contracts, and verification
overhead that blunts the gains. We therefore present Know-The-Ropes (KtR), a
framework that converts domain priors into an algorithmic blueprint hierarchy,
in which tasks are recursively split into typed, controller-mediated subtasks,
each solved zero-shot or with the lightest viable boost (e.g.,
chain-of-thought, micro-tune, self-check). Grounded in the No-Free-Lunch
theorem, KtR trades the chase for a universal prompt for disciplined
decomposition. On the Knapsack problem (3-8 items), three GPT-4o-mini agents
raise accuracy from 3% zero-shot to 95% on size-5 instances after patching a
single bottleneck agent. On the tougher Task-Assignment problem (6-15 jobs), a
six-agent o3-mini blueprint hits 100% up to size 10 and 84% on sizes 13-15,
versus 11% zero-shot. Algorithm-aware decomposition plus targeted augmentation
thus turns modest models into reliable collaborators--no ever-larger monoliths
required.

</details>


### [179] [Beyond Correlation: Towards Causal Large Language Model Agents in Biomedicine](https://arxiv.org/abs/2505.16982)
*Adib Bazgir, Amir Habibdoust Lafmajani, Yuwen Zhang*

**主要类别:** cs.AI

**概要:** 这篇论文提出了一种将因果推理与大型语言模型（LLMs）相结合的新方法，旨在通过整合多模态数据和因果推理工具来解决生物医学中的问题。这种方法可能带来变革性机遇，例如加速药物发现和实现个性化医疗。


<details>
  <summary>更多</summary>
  
**动机:** 尽管大型语言模型在生物医学领域展现出潜力，但它们缺乏真正的因果理解能力，仅依赖于相关性。因此，需要一种新的方法来实现因果推理和多模态数据的结合。

**方法:** 设计安全可控的代理框架；开发严格的因果评估基准；整合异构数据源；以及协同结合LLMs、结构化知识（KGs）和形式化的因果推理工具。

**结果:** 这种因果LLM代理可以解锁变革性机会，如通过自动化假设生成和模拟加速药物发现，通过患者特定的因果模型实现个性化医疗。

**结论:** 该研究议程旨在促进跨学科努力，将因果概念和基础模型结合起来，开发可靠的AI伙伴以推动生物医学进步。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Beyond+Correlation%3A+Towards+Causal+Large+Language+Model+Agents+in+Biomedicine，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16982，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16982&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) show promise in biomedicine but lack true causal
understanding, relying instead on correlations. This paper envisions causal LLM
agents that integrate multimodal data (text, images, genomics, etc.) and
perform intervention-based reasoning to infer cause-and-effect. Addressing this
requires overcoming key challenges: designing safe, controllable agentic
frameworks; developing rigorous benchmarks for causal evaluation; integrating
heterogeneous data sources; and synergistically combining LLMs with structured
knowledge (KGs) and formal causal inference tools. Such agents could unlock
transformative opportunities, including accelerating drug discovery through
automated hypothesis generation and simulation, enabling personalized medicine
through patient-specific causal models. This research agenda aims to foster
interdisciplinary efforts, bridging causal concepts and foundation models to
develop reliable AI partners for biomedical progress.

</details>


### [180] [X-MAS: Towards Building Multi-Agent Systems with Heterogeneous LLMs](https://arxiv.org/abs/2505.16997)
*Rui Ye, Xiangrui Liu, Qimin Wu, Xianghe Pang, Zhenfei Yin, Lei Bai, Siheng Chen*

**主要类别:** cs.AI

**概要:** 本论文探讨了异构LLM驱动的多智能体系统（X-MAS）范式，通过引入X-MAS-Bench测试平台评估27个LLM在不同领域和功能上的表现，并证明从同质到异构LLM驱动的MAS可以显著提升系统性能。


<details>
  <summary>更多</summary>
  
**动机:** 当前大多数多智能体系统（MAS）框架依赖单一LLM驱动所有智能体，限制了系统的智能水平。为了突破这一限制，本文探索了由多样LLM驱动的异构MAS（X-MAS）的可能性。

**方法:** 1. 提出X-MAS-Bench，一个全面的测试平台，用于评估不同LLM在多个领域和MAS相关功能上的表现。
2. 对27个LLM进行超过170万次评估，涵盖5个领域（21个测试集）和5个功能。
3. 分析从同质到异构LLM驱动MAS的性能改进，并在特定数据集上验证其效果。

**结果:** 实验结果表明：
- 在仅聊天机器人场景中，异构配置在MATH数据集上提升了8.4%的性能。
- 在混合聊天机器人-推理器场景中，异构MAS在AIME数据集上实现了47%的显著性能提升。

**结论:** 异构LLM驱动的MAS具有极大的潜力，无需结构重新设计即可显著提高系统性能，为可扩展、协作型AI系统的发展提供了有希望的方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是X-MAS%3A+Towards+Building+Multi-Agent+Systems+with+Heterogeneous+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16997，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16997&send_immediately=true&force_search=false)

**原文摘要:** LLM-based multi-agent systems (MAS) extend the capabilities of single LLMs by
enabling cooperation among multiple specialized agents. However, most existing
MAS frameworks rely on a single LLM to drive all agents, constraining the
system's intelligence to the limit of that model. This paper explores the
paradigm of heterogeneous LLM-driven MAS (X-MAS), where agents are powered by
diverse LLMs, elevating the system's potential to the collective intelligence
of diverse LLMs. We introduce X-MAS-Bench, a comprehensive testbed designed to
evaluate the performance of various LLMs across different domains and
MAS-related functions. As an extensive empirical study, we assess 27 LLMs
across 5 domains (encompassing 21 test sets) and 5 functions, conducting over
1.7 million evaluations to identify optimal model selections for each
domain-function combination. Building on these findings, we demonstrate that
transitioning from homogeneous to heterogeneous LLM-driven MAS can
significantly enhance system performance without requiring structural redesign.
Specifically, in a chatbot-only MAS scenario, the heterogeneous configuration
yields up to 8.4\% performance improvement on the MATH dataset. In a mixed
chatbot-reasoner scenario, the heterogeneous MAS could achieve a remarkable
47\% performance boost on the AIME dataset. Our results underscore the
transformative potential of heterogeneous LLMs in MAS, highlighting a promising
avenue for advancing scalable, collaborative AI systems.

</details>


### [181] [Unearthing Gems from Stones: Policy Optimization with Negative Sample Augmentation for LLM Reasoning](https://arxiv.org/abs/2505.14403)
*Zhaohui Yang, Shilei Jiang, Chen Hu, Linjing Li, Shihong Deng, Daxin Jiang*

**主要类别:** cs.AI

**概要:** 近期推理语言模型的发展经历了从短链到长链思考（CoT）模式的范式转变。鉴于长链CoT模型的巨大计算成本，最大化固定训练数据集的效用变得至关重要。我们发现负样本中包含有价值的成分，如自我反思和错误纠正步骤，但现有方法要么完全丢弃负样本（RFT），要么对所有标记施加相等惩罚（RL）。为此，我们提出了带有负样本增强的行为约束策略梯度（BCPG-NSA），一种精细粒度的离线强化学习框架，包括三个阶段：1）样本分割；2）基于共识的步骤正确性评估，结合LLM和PRM评判器；3）通过NSA优化策略，有效挖掘负样本中的正向步骤。实验结果表明，BCPG-NSA在多个具有挑战性的数学/编码推理基准上优于基线模型，使用相同的训练数据集实现了更高的样本效率，并展示了扩展到多轮迭代时的稳健性和可扩展性。


<details>
  <summary>更多</summary>
  
**动机:** 为了提高长链CoT模型的计算效率，充分利用固定训练数据集的价值，同时挖掘负样本中潜在的学习信号（如自我反思和错误纠正步骤）。

**方法:** 提出了一种名为BCPG-NSA的新方法，该方法是一种精细粒度的离线强化学习框架，包含三个主要阶段：1）样本分割；2）结合LLM和PRM评判器进行基于共识的步骤正确性评估；3）通过负样本增强（NSA）优化策略，以有效挖掘负样本中的正向步骤。

**结果:** 实验结果显示，BCPG-NSA在多个具有挑战性的数学/编码推理基准上显著优于基线模型，同时提高了样本效率，并在多轮迭代中表现出稳健性和可扩展性。

**结论:** BCPG-NSA是一种有效的离线强化学习框架，能够充分挖掘负样本中的潜在价值，提升长链CoT模型的性能、样本效率以及在复杂推理任务中的应用能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Unearthing+Gems+from+Stones%3A+Policy+Optimization+with+Negative+Sample+Augmentation+for+LLM+Reasoning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.14403，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.14403&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in reasoning language models have witnessed a paradigm shift
from short to long CoT pattern. Given the substantial computational cost of
rollouts in long CoT models, maximizing the utility of fixed training datasets
becomes crucial. Our analysis reveals that negative responses contain valuable
components such as self-reflection and error-correction steps, yet primary
existing methods either completely discard negative samples (RFT) or apply
equal penalization across all tokens (RL), failing to leverage these potential
learning signals. In light of this, we propose Behavior Constrained Policy
Gradient with Negative Sample Augmentation (BCPG-NSA), a fine-grained offline
RL framework that encompasses three stages: 1) sample segmentation, 2)
consensus-based step correctness assessment combining LLM and PRM judgers, and
3) policy optimization with NSA designed to effectively mine positive steps
within negative samples. Experimental results show that BCPG-NSA outperforms
baselines on several challenging math/coding reasoning benchmarks using the
same training dataset, achieving improved sample efficiency and demonstrating
robustness and scalability when extended to multiple iterations.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [182] [CoT Information: Improved Sample Complexity under Chain-of-Thought Supervision](https://arxiv.org/abs/2505.15927)
*Awni Altabaa, Omar Montasser, John Lafferty*

**主要类别:** stat.ML

**概要:** This paper develops a statistical theory for chain-of-thought (CoT) supervision, showing it leads to faster learning rates than standard methods by using the CoT information measure.


<details>
  <summary>更多</summary>
  
**动机:** Learning complex functions involving multi-step reasoning is challenging for standard supervised learning. CoT supervision has emerged as an effective technique in enhancing reasoning capabilities of large language models.

**方法:** Developing a statistical theory of learning under CoT supervision, and explicitly linking the CoT risk and end-to-end risk to achieve sharper sample complexity bounds via the CoT information measure.

**结果:** Theoretical results show that CoT supervision can yield significantly faster learning rates compared to standard E2E supervision, with sample complexity scaling as d/I(D,h⋆)COT(ε;H).

**结论:** CoT information is a fundamental measure of statistical complexity for learning under chain-of-thought supervision.

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是CoT+Information%3A+Improved+Sample+Complexity+under+Chain-of-Thought+Supervision，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.15927，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.15927&send_immediately=true&force_search=false)

**原文摘要:** Learning complex functions that involve multi-step reasoning poses a
significant challenge for standard supervised learning from input-output
examples. Chain-of-thought (CoT) supervision, which provides intermediate
reasoning steps together with the final output, has emerged as a powerful
empirical technique, underpinning much of the recent progress in the reasoning
capabilities of large language models. This paper develops a statistical theory
of learning under CoT supervision. A key characteristic of the CoT setting, in
contrast to standard supervision, is the mismatch between the training
objective (CoT risk) and the test objective (end-to-end risk). A central part
of our analysis, distinguished from prior work, is explicitly linking those two
types of risk to achieve sharper sample complexity bounds. This is achieved via
the *CoT information measure* $\mathcal{I}_{\mathcal{D},
h_\star}^{\mathrm{CoT}}(\epsilon; \calH)$, which quantifies the additional
discriminative power gained from observing the reasoning process. The main
theoretical results demonstrate how CoT supervision can yield significantly
faster learning rates compared to standard E2E supervision. Specifically, it is
shown that the sample complexity required to achieve a target E2E error
$\epsilon$ scales as $d/\mathcal{I}_{\mathcal{D},
h_\star}^{\mathrm{CoT}}(\epsilon; \calH)$, where $d$ is a measure of hypothesis
class complexity, which can be much faster than standard $d/\epsilon$ rates.
Information-theoretic lower bounds in terms of the CoT information are also
obtained. Together, these results suggest that CoT information is a fundamental
measure of statistical complexity for learning under chain-of-thought
supervision.

</details>


### [183] [PO-Flow: Flow-based Generative Models for Sampling Potential Outcomes and Counterfactuals](https://arxiv.org/abs/2505.16051)
*Dongze Wu, David I. Inouye, Yao Xie*

**主要类别:** stat.ML

**概要:** 提出了一种名为PO-Flow的新框架，用于因果推理的连续归一化流（CNF），可联合建模潜在结果和反事实。通过流匹配训练，PO-Flow为个体潜在结果预测、反事实预测以及不确定性感知密度学习提供了一个统一框架。这是首个在不要求显式分布假设的情况下实现潜在结果密度学习的生成模型，并支持基于一般观察数据集的事实结果条件下的反事实预测。在ACIC、IHDP和IBM基准测试中，它在一系列因果推理任务中始终优于先前的方法。此外，PO-Flow在高维设置中也表现出色，包括反事实图像生成，展示了其广泛适用性。


<details>
  <summary>更多</summary>
  
**动机:** 当前的因果推理方法可能需要显式的分布假设或难以处理高维数据，作者希望开发一种不需要显式分布假设且能够同时处理潜在结果和反事实预测的方法，以提升因果推理的准确性和适用性。

**方法:** 作者提出了PO-Flow，这是一种基于连续归一化流（CNF）的因果推理框架。该框架通过流匹配进行训练，可以联合建模潜在结果和反事实。PO-Flow不仅实现了潜在结果的密度学习，还支持基于观察数据的事实结果条件下的反事实预测。

**结果:** PO-Flow在多个基准数据集（如ACIC、IHDP和IBM）上的一系列因果推理任务中表现优于先前的方法。此外，它还在高维数据（如图像生成）中成功应用，证明了其广泛的适用性。

**结论:** PO-Flow是一种强大的因果推理工具，能够在不要求显式分布假设的情况下进行潜在结果密度学习和反事实预测，并适用于高维数据，具有广泛的适用性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是PO-Flow%3A+Flow-based+Generative+Models+for+Sampling+Potential+Outcomes+and+Counterfactuals，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16051，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16051&send_immediately=true&force_search=false)

**原文摘要:** We propose PO-Flow, a novel continuous normalizing flow (CNF) framework for
causal inference that jointly models potential outcomes and counterfactuals.
Trained via flow matching, PO-Flow provides a unified framework for
individualized potential outcome prediction, counterfactual predictions, and
uncertainty-aware density learning. Among generative models, it is the first to
enable density learning of potential outcomes without requiring explicit
distributional assumptions (e.g., Gaussian mixtures), while also supporting
counterfactual prediction conditioned on factual outcomes in general
observational datasets. On benchmarks such as ACIC, IHDP, and IBM, it
consistently outperforms prior methods across a range of causal inference
tasks. Beyond that, PO-Flow succeeds in high-dimensional settings, including
counterfactual image generation, demonstrating its broad applicability.

</details>


### [184] [Oh SnapMMD! Forecasting Stochastic Dynamics Beyond the Schrödinger Bridge's End](https://arxiv.org/abs/2505.16082)
*Renato Berlinghieri, Yunyi Shen, Jialong Jiang, Tamara Broderick*

**主要类别:** stat.ML

**概要:** 科学家们常常希望基于潜藏随机动力学的'快照'数据预测超出观察时间范围的结果。例如，在单细胞mRNA时程分析中，由于测量会破坏细胞，研究人员无法获取任何单一细胞的轨迹。本研究提出了一种新的框架SnapMMD，通过直接拟合状态测量和观测时间的联合分布来学习动力学。该方法可以推断出未知且与状态相关的波动性，并在各种真实和合成实验中展示了准确的预测能力。此外，它允许在不完整状态测量的情况下进行学习，并提供了一个类似于$R^2$的诊断统计量。


<details>
  <summary>更多</summary>
  
**动机:** 科学家需要从早期状态测量（如干细胞）预测分化结果，但现有的Schrödinger-bridge (SB) 方法要么简化为遵循预设参考动力学，要么需要用户选择固定、与状态无关的波动性，这可能导致较差的预测质量。

**方法:** 提出了一个新的框架SnapMMD，通过最大均值差异（MMD）损失直接拟合状态测量和观测时间的联合分布。此方法可以从观测数据中推断未知且与状态相关的波动性。

**结果:** 在多种真实和合成实验中，该方法提供了准确的预测。此外，其插值性能（以及一般的速度场重建）在几乎所有实验中都至少与最先进的方法一样好，甚至更好。

**结论:** SnapMMD框架能够准确预测并处理不完整状态测量，同时提供一个诊断拟合优度的统计量。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Oh+SnapMMD%21+Forecasting+Stochastic+Dynamics+Beyond+the+Schr%C3%B6dinger+Bridge%27s+End，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16082，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16082&send_immediately=true&force_search=false)

**原文摘要:** Scientists often want to make predictions beyond the observed time horizon of
"snapshot" data following latent stochastic dynamics. For example, in time
course single-cell mRNA profiling, scientists have access to cellular
transcriptional state measurements (snapshots) from different biological
replicates at different time points, but they cannot access the trajectory of
any one cell because measurement destroys the cell. Researchers want to
forecast (e.g.) differentiation outcomes from early state measurements of stem
cells. Recent Schr\"odinger-bridge (SB) methods are natural for interpolating
between snapshots. But past SB papers have not addressed forecasting -- likely
since existing methods either (1) reduce to following pre-set reference
dynamics (chosen before seeing data) or (2) require the user to choose a fixed,
state-independent volatility since they minimize a Kullback-Leibler divergence.
Either case can lead to poor forecasting quality. In the present work, we
propose a new framework, SnapMMD, that learns dynamics by directly fitting the
joint distribution of both state measurements and observation time with a
maximum mean discrepancy (MMD) loss. Unlike past work, our method allows us to
infer unknown and state-dependent volatilities from the observed data. We show
in a variety of real and synthetic experiments that our method delivers
accurate forecasts. Moreover, our approach allows us to learn in the presence
of incomplete state measurements and yields an $R^2$-style statistic that
diagnoses fit. We also find that our method's performance at interpolation (and
general velocity-field reconstruction) is at least as good as (and often better
than) state-of-the-art in almost all of our experiments.

</details>


### [185] [Dimension-adapted Momentum Outscales SGD](https://arxiv.org/abs/2505.16098)
*Damien Ferbach, Katie Everett, Gauthier Gidel, Elliot Paquette, Courtney Paquette*

**主要类别:** stat.ML

**概要:** DANA通过根据模型大小和数据复杂性调整动量超参数，改进了传统SGD-M的缩放定律指数，并在广泛的实验中验证了其优越性。


<details>
  <summary>更多</summary>
  
**动机:** 研究随机动量算法在小批量训练中的缩放规律，特别是在由数据复杂性、目标复杂性和模型大小参数化的幂律随机特征模型上的表现。

**方法:** 分析使用随机动量算法训练时的不同损失曲线形状，并比较传统的SGD-M与维度适应的Nesterov加速（DANA）方法在不同数据-目标复杂性下的表现。DANA通过基于模型大小和数据复杂性调整动量超参数来改进缩放指数。

**结果:** 理论分析和高维合成二次实验表明，DANA在广泛的數據和目标复杂性范围内表现出优于传统方法的计算最优缩放行为。此外，在大规模LSTM文本实验中，DANA也显示出改进的损失指数。

**结论:** DANA能够在更广泛的數據和目标复杂性范围内实现更好的缩放行为，而传统方法则有所不足。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Dimension-adapted+Momentum+Outscales+SGD，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16098，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16098&send_immediately=true&force_search=false)

**原文摘要:** We investigate scaling laws for stochastic momentum algorithms with small
batch on the power law random features model, parameterized by data complexity,
target complexity, and model size. When trained with a stochastic momentum
algorithm, our analysis reveals four distinct loss curve shapes determined by
varying data-target complexities. While traditional stochastic gradient descent
with momentum (SGD-M) yields identical scaling law exponents to SGD,
dimension-adapted Nesterov acceleration (DANA) improves these exponents by
scaling momentum hyperparameters based on model size and data complexity. This
outscaling phenomenon, which also improves compute-optimal scaling behavior, is
achieved by DANA across a broad range of data and target complexities, while
traditional methods fall short. Extensive experiments on high-dimensional
synthetic quadratics validate our theoretical predictions and large-scale text
experiments with LSTMs show DANA's improved loss exponents over SGD hold in a
practical setting.

</details>


### [186] [Exponential Convergence of CAVI for Bayesian PCA](https://arxiv.org/abs/2505.16145)
*Arghya Datta, Philippe Gagnon, Florian Maire*

**主要类别:** stat.ML

**概要:** 本文研究了用于贝叶斯概率主成分分析（BPCA）的坐标上升变分推理（CAVI）算法的收敛速度，证明了单个主成分情况下的精确指数收敛结果，并通过引入新的对称KL散度下界，证明了任意数量主成分模型的指数收敛性。


<details>
  <summary>更多</summary>
  
**动机:** 尽管BPCA参数通常使用CAVI算法学习，但其收敛速度尚未被明确表征。因此，作者旨在填补这一空白，研究CAVI在BPCA中的收敛特性。

**方法:** 1. 证明了当模型使用单个主成分时，CAVI具有精确的指数收敛结果，通过与经典的幂迭代算法建立联系。
2. 引入了一个新的对称Kullback-Leibler散度的下界，以证明任意数量主成分模型的指数收敛性。

**结果:** 1. 在单个主成分情况下，得到了精确的指数收敛结果，并揭示了传统PCA是BPCA参数的点估计。
2. 对于任意数量主成分模型，证明了CAVI的指数收敛性，提供了更通用的结果。

**结论:** 本文首次表征了CAVI在BPCA中的收敛速度，不仅为单个主成分情况提供了精确结果，还通过引入新工具扩展到了任意数量主成分模型，同时为信息理论领域贡献了一个独立感兴趣的对称KL散度下界。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Exponential+Convergence+of+CAVI+for+Bayesian+PCA，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16145，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16145&send_immediately=true&force_search=false)

**原文摘要:** Probabilistic principal component analysis (PCA) and its Bayesian variant
(BPCA) are widely used for dimension reduction in machine learning and
statistics. The main advantage of probabilistic PCA over the traditional
formulation is allowing uncertainty quantification. The parameters of BPCA are
typically learned using mean-field variational inference, and in particular,
the coordinate ascent variational inference (CAVI) algorithm. So far, the
convergence speed of CAVI for BPCA has not been characterized. In our paper, we
fill this gap in the literature. Firstly, we prove a precise exponential
convergence result in the case where the model uses a single principal
component (PC). Interestingly, this result is established through a connection
with the classical $\textit{power iteration algorithm}$ and it indicates that
traditional PCA is retrieved as points estimates of the BPCA parameters.
Secondly, we leverage recent tools to prove exponential convergence of CAVI for
the model with any number of PCs, thus leading to a more general result, but
one that is of a slightly different flavor. To prove the latter result, we
additionally needed to introduce a novel lower bound for the symmetric
Kullback--Leibler divergence between two multivariate normal distributions,
which, we believe, is of independent interest in information theory.

</details>


### [187] [Integral Imprecise Probability Metrics](https://arxiv.org/abs/2505.16156)
*Siu Lun Chau, Michele Caprio, Krikamol Muandet*

**主要类别:** stat.ML

**概要:** 本文引入了Integral Imprecise Probability Metric (IIPM)框架，将经典的Integral Probability Metric推广到容量设置下，适用于广泛的不精确概率模型。理论方面，确定了IIPM作为有效度量的条件，并证明其可以度量容量的弱收敛形式。实践上，IIPM不仅能够比较不同不精确概率模型，还能量化单一模型中的认知不确定性，提出了一类新的EU度量——Maximum Mean Imprecision (MMI)，并验证了其优越性。


<details>
  <summary>更多</summary>
  
**动机:** 统计和机器学习中，衡量概率分布差异是基础任务，主要用于比较统计不确定性。然而，认知不确定性（Epistemic Uncertainty, EU）由于知识不完全，需要比经典概率更丰富的表示方法。不精确概率（Imprecise Probability, IP）理论提供了这样的模型，因此在不精确概率机器学习（IPML）领域，需要超越经典概率的度量方法。

**方法:** 提出了基于Choquet积分的IIPM框架，将经典IPM推广到容量（Capacities）这一广泛包含现有IP模型的类别。通过理论分析，明确了IIPM作为合法度量的条件及其对弱收敛形式的度量能力。此外，通过比较IP模型与其共轭模型，提出了新的EU度量——Maximum Mean Imprecision (MMI)。

**结果:** 理论上，验证了IIPM在适当条件下可作为合法度量，并能度量弱收敛形式；实践中，通过选择性分类实验，展示了MMI相较于现有EU度量的强经验性能，尤其是在经典方法难以扩展到多类别情况时表现更优。

**结论:** 本文为IPML领域提供了理论与实践上的进步，提出了一个系统性的框架来比较和量化不精确概率下的认知不确定性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Integral+Imprecise+Probability+Metrics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16156，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16156&send_immediately=true&force_search=false)

**原文摘要:** Quantifying differences between probability distributions is fundamental to
statistics and machine learning, primarily for comparing statistical
uncertainty. In contrast, epistemic uncertainty (EU) -- due to incomplete
knowledge -- requires richer representations than those offered by classical
probability. Imprecise probability (IP) theory offers such models, capturing
ambiguity and partial belief. This has driven growing interest in imprecise
probabilistic machine learning (IPML), where inference and decision-making rely
on broader uncertainty models -- highlighting the need for metrics beyond
classical probability. This work introduces the Integral Imprecise Probability
Metric (IIPM) framework, a Choquet integral-based generalisation of classical
Integral Probability Metric (IPM) to the setting of capacities -- a broad class
of IP models encompassing many existing ones, including lower probabilities,
probability intervals, belief functions, and more. Theoretically, we establish
conditions under which IIPM serves as a valid metric and metrises a form of
weak convergence of capacities. Practically, IIPM not only enables comparison
across different IP models but also supports the quantification of epistemic
uncertainty within a single IP model. In particular, by comparing an IP model
with its conjugate, IIPM gives rise to a new class of EU measures -- Maximum
Mean Imprecision -- which satisfy key axiomatic properties proposed in the
Uncertainty Quantification literature. We validate MMI through selective
classification experiments, demonstrating strong empirical performance against
established EU measures, and outperforming them when classical methods struggle
to scale to a large number of classes. Our work advances both theory and
practice in IPML, offering a principled framework for comparing and quantifying
epistemic uncertainty under imprecision.

</details>


### [188] [Generalized Power Priors for Improved Bayesian Inference with Historical Data](https://arxiv.org/abs/2505.16244)
*Masanari Kimura, Howard Bondell*

**主要类别:** stat.ML

**概要:** 这篇论文扩展了功率先验的框架，通过将后验分布视为阿马里α-散度线性组合的最小化结果，提供了更灵活的历史数据整合方式，并揭示了几何解释。


<details>
  <summary>更多</summary>
  
**动机:** 在贝叶斯框架下，功率先验提供了一种结合历史数据和当前数据的方法。但为了提高灵活性和适应性，需要对现有框架进行扩展。

**方法:** 作者通过引入阿马里α-散度的一般化形式来重新定义后验分布，并研究了这种一般化的功率后验的理论性质。

**结果:** 研究表明，这种方法可以通过选择合适的α参数使数据更好地适应模型，从而提高性能。此外，还发现该方法在概率分布的黎曼流形上表现为广义测地线。

**结论:** 这种扩展的功率后验不仅增强了模型的灵活性，还为功率后验提供了新的几何解释。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generalized+Power+Priors+for+Improved+Bayesian+Inference+with+Historical+Data，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16244，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16244&send_immediately=true&force_search=false)

**原文摘要:** The power prior is a class of informative priors designed to incorporate
historical data alongside current data in a Bayesian framework. It includes a
power parameter that controls the influence of historical data, providing
flexibility and adaptability. A key property of the power prior is that the
resulting posterior minimizes a linear combination of KL divergences between
two pseudo-posterior distributions: one ignoring historical data and the other
fully incorporating it. We extend this framework by identifying the posterior
distribution as the minimizer of a linear combination of Amari's
$\alpha$-divergence, a generalization of KL divergence. We show that this
generalization can lead to improved performance by allowing for the data to
adapt to appropriate choices of the $\alpha$ parameter. Theoretical properties
of this generalized power posterior are established, including behavior as a
generalized geodesic on the Riemannian manifold of probability distributions,
offering novel insights into its geometric interpretation.

</details>


### [189] [Graph-Smoothed Bayesian Black-Box Shift Estimator and Its Information Geometry](https://arxiv.org/abs/2505.16251)
*Masanari Kimura*

**主要类别:** stat.ML

**概要:** 这篇论文提出了一种新的方法Graph-Smoothed Bayesian BBSE (GS-B$^3$SE)，用于解决标签分布偏移问题，具有可证明的理论性质和对类别相似性的建模能力。


<details>
  <summary>更多</summary>
  
**动机:** 现有的黑盒偏移估计方法在处理标签分布偏移时，容易受到采样噪声和类别相似性的影响，导致结果不稳定。因此需要一种更稳健的方法来估计目标类别的先验概率。

**方法:** GS-B$^3$SE方法通过引入Laplacian-Gaussian先验，将目标log-priors和混淆矩阵列绑定在一个标签相似性图上。使用HMC或快速块Newton-CG方案进行后验推断，并证明了该方法的可识别性、收缩率、方差界限以及对Laplacian错配的鲁棒性。

**结果:** 实验表明，GS-B$^3$SE能够有效估计目标类别的先验概率，同时对采样噪声和类别相似性具有更好的鲁棒性。此外，从信息几何的角度重新解释了该方法，表明其可以推广现有的偏移估计方法。

**结论:** Graph-Smoothed Bayesian BBSE (GS-B$^3$SE)是一种完全概率化的标签分布偏移适应方法，相比传统方法更加稳健且能充分利用类别间的相似性信息。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Graph-Smoothed+Bayesian+Black-Box+Shift+Estimator+and+Its+Information+Geometry，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16251，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16251&send_immediately=true&force_search=false)

**原文摘要:** Label shift adaptation aims to recover target class priors when the labelled
source distribution $P$ and the unlabelled target distribution $Q$ share $P(X
\mid Y) = Q(X \mid Y)$ but $P(Y) \neq Q(Y)$. Classical black-box shift
estimators invert an empirical confusion matrix of a frozen classifier,
producing a brittle point estimate that ignores sampling noise and similarity
among classes. We present Graph-Smoothed Bayesian BBSE (GS-B$^3$SE), a fully
probabilistic alternative that places Laplacian-Gaussian priors on both target
log-priors and confusion-matrix columns, tying them together on a
label-similarity graph. The resulting posterior is tractable with HMC or a fast
block Newton-CG scheme. We prove identifiability, $N^{-1/2}$ contraction,
variance bounds that shrink with the graph's algebraic connectivity, and
robustness to Laplacian misspecification. We also reinterpret GS-B$^3$SE
through information geometry, showing that it generalizes existing shift
estimators.

</details>


### [190] [Higher-Order Asymptotics of Test-Time Adaptation for Batch Normalization Statistics](https://arxiv.org/abs/2505.16257)
*Masanari Kimura*

**主要类别:** stat.ML

**概要:** 本研究开发了一个高阶渐近框架，用于在分布偏移下通过整合经典Edgeworth展开和鞍点逼近技术以及新颖的一步M估计视角来适应Batch Normalization (BN)统计的测试时间适应（TTA）。通过分析训练和测试分布之间的统计差异，推导出BN均值归一化差异的Edgeworth展开，并获得最小化适应统计量均方误差的最佳加权参数。将BN TTA重新解释为一步M估计器使我们能够推导出更高阶的局部渐近正态性结果，将偏度和其他更高阶矩纳入估计器的行为中。此外，我们量化了适应过程中的偏差、方差和偏度之间的权衡，并建立了相应的模型风险泛化界。改进的鞍点逼近进一步提供了BN TTA统计量的均匀准确密度和尾概率估计。这些理论见解提供了一个全面的理解，即如何通过高阶校正和稳健的一步更新来提高BN层适应变化数据分布的可靠性和性能。


<details>
  <summary>更多</summary>
  
**动机:** 在机器学习模型中，Batch Normalization (BN)统计量在训练和测试阶段的数据分布可能会发生偏移。为了提高模型在不同数据分布下的适应能力，需要一种有效的测试时间适应（TTA）方法，以减少由于分布偏移带来的负面影响。这促使了对高阶渐近框架的研究，该框架可以更好地理解和优化BN统计量在分布偏移下的行为。

**方法:** 研究结合了经典Edgeworth展开和鞍点逼近技术，并引入了一种新的一步M-估计视角。通过对训练和测试分布之间统计差异的分析，推导出BN均值归一化差异的Edgeworth展开式，并确定一个最优的加权参数以最小化适应统计量的均方误差。此外，将BN TTA视为一步M-估计器，从而推导出更高阶的局部渐近正态性结果，这些结果考虑了偏度及其他更高阶矩的影响。最后，使用改进的鞍点逼近技术，获得了BN TTA统计量的均匀准确密度和尾概率估计。

**结果:** 该研究成功地推导出了一个最佳加权参数，它能够最小化适应统计量的均方误差。同时，通过重新诠释BN TTA为一步M-估计器，得出了更高阶的局部渐近正态性结果，这些结果揭示了偏度和其他更高阶矩在估计器行为中的作用。此外，量化了适应过程中偏差、方差和偏度之间的权衡，并建立了相应的模型风险泛化界。最终，改进的鞍点逼近技术提供了均匀准确的密度和尾概率估计，增强了BN层适应变化数据分布的可靠性和性能。

**结论:** 本研究提出的高阶渐近框架为理解Batch Normalization统计量在分布偏移下的行为提供了新的视角。通过整合Edgeworth展开、鞍点逼近和一步M-估计方法，不仅提升了BN层适应变化数据分布的能力，还揭示了更高阶统计量在模型性能中的重要作用。这些理论成果为进一步优化BN统计量的适应策略奠定了基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Higher-Order+Asymptotics+of+Test-Time+Adaptation+for+Batch+Normalization+Statistics，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16257，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16257&send_immediately=true&force_search=false)

**原文摘要:** This study develops a higher-order asymptotic framework for test-time
adaptation (TTA) of Batch Normalization (BN) statistics under distribution
shift by integrating classical Edgeworth expansion and saddlepoint
approximation techniques with a novel one-step M-estimation perspective. By
analyzing the statistical discrepancy between training and test distributions,
we derive an Edgeworth expansion for the normalized difference in BN means and
obtain an optimal weighting parameter that minimizes the mean-squared error of
the adapted statistic. Reinterpreting BN TTA as a one-step M-estimator allows
us to derive higher-order local asymptotic normality results, which incorporate
skewness and other higher moments into the estimator's behavior. Moreover, we
quantify the trade-offs among bias, variance, and skewness in the adaptation
process and establish a corresponding generalization bound on the model risk.
The refined saddlepoint approximations further deliver uniformly accurate
density and tail probability estimates for the BN TTA statistic. These
theoretical insights provide a comprehensive understanding of how higher-order
corrections and robust one-step updating can enhance the reliability and
performance of BN layers in adapting to changing data distributions.

</details>


### [191] [Generator-Mediated Bandits: Thompson Sampling for GenAI-Powered Adaptive Interventions](https://arxiv.org/abs/2505.16311)
*Marc Brooks, Gabriel Durham, Kihyuk Hong, Ambuj Tewari*

**主要类别:** stat.ML

**概要:** 近期生成式人工智能（GenAI）模型的进步使得可以根据最新的用户情境生成个性化内容。然而，标准的Bandit方法未考虑GenAI引入的新结构。本文提出了一种名为GAMBITTS的方法，该方法通过明确建模治疗和奖励生成过程，在模拟研究中表现优于传统算法。


<details>
  <summary>更多</summary>
  
**动机:** 尽管个性化决策系统通常使用Bandit公式建模，但GenAI的集成引入了新的结构进入经典的顺序学习问题。在由GenAI驱动的干预中，代理选择一个查询，但环境经历从生成模型中抽取的随机响应。标准Bandit方法并未明确考虑这种结构，其中动作仅通过随机、观察到的治疗影响奖励。

**方法:** 提出了生成器中介的Bandit-Thompson采样（GAMBITTS），这是一种为行动/治疗分离设计的Bandit方法。GAMBITTS明确建模了治疗和奖励生成过程，利用传递治疗中的信息加速策略学习。该方法以使用大型语言模型生成文本的移动健康干预作为激励案例研究。

**结果:** 通过分解治疗和奖励中的不确定性来源，建立了GAMBITTS的遗憾边界，并确定了其比标准Bandit方法实现更强保证的条件。在模拟研究中，GAMBITTS通过利用观察到的治疗手段，始终优于传统算法。

**结论:** GAMBITTS在模拟研究中通过利用观测到的治疗手段，能够更准确地估计期望奖励，从而始终优于传统算法。并且在处理治疗和奖励的不确定性来源时，GAMBITTS可以建立遗憾边界，识别出比标准多臂老虎机方法更强的保证条件。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Generator-Mediated+Bandits%3A+Thompson+Sampling+for+GenAI-Powered+Adaptive+Interventions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16311，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16311&send_immediately=true&force_search=false)

**原文摘要:** Recent advances in generative artificial intelligence (GenAI) models have
enabled the generation of personalized content that adapts to up-to-date user
context. While personalized decision systems are often modeled using bandit
formulations, the integration of GenAI introduces new structure into otherwise
classical sequential learning problems. In GenAI-powered interventions, the
agent selects a query, but the environment experiences a stochastic response
drawn from the generative model. Standard bandit methods do not explicitly
account for this structure, where actions influence rewards only through
stochastic, observed treatments. We introduce generator-mediated
bandit-Thompson sampling (GAMBITTS), a bandit approach designed for this
action/treatment split, using mobile health interventions with large language
model-generated text as a motivating case study. GAMBITTS explicitly models
both the treatment and reward generation processes, using information in the
delivered treatment to accelerate policy learning relative to standard methods.
We establish regret bounds for GAMBITTS by decomposing sources of uncertainty
in treatment and reward, identifying conditions where it achieves stronger
guarantees than standard bandit approaches. In simulation studies, GAMBITTS
consistently outperforms conventional algorithms by leveraging observed
treatments to more accurately estimate expected rewards.

</details>


### [192] [Better Rates for Private Linear Regression in the Proportional Regime via Aggressive Clipping](https://arxiv.org/abs/2505.16329)
*Simone Bombari, Inbar Seroussi, Marco Mondelli*

**主要类别:** stat.ML

**概要:** 通过引入频繁裁剪机制，本研究优化了差分隐私随机梯度下降（DP-SGD）的误差率，并证明了在特定数据分布下激进裁剪策略的优越性。


<details>
  <summary>更多</summary>
  
**动机:** 现有理论中，为了简化分析，通常将裁剪常数设得远大于单个样本梯度的期望范数，这与实际性能优化的需求不符。因此需要弥合理论与实践之间的差距。

**方法:** 研究假设数据为多变量高斯分布，训练样本数 $n$ 与输入维度 $d$ 成比例，并确保零集中差分隐私。通过建立一组常微分方程 (ODEs) 来确定 DP-SGD 轨迹的等效性，并以此推导出风险边界。

**结果:** 当 $n/d$ 足够大时，研究显示激进裁剪策略、递减学习率和私有噪声调度能显著改善 DP-SGD 的性能。

**结论:** 激进裁剪策略在特定条件下是最佳选择，且递减学习率和私有噪声调度对提升模型性能至关重要。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Better+Rates+for+Private+Linear+Regression+in+the+Proportional+Regime+via+Aggressive+Clipping，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16329，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16329&send_immediately=true&force_search=false)

**原文摘要:** Differentially private (DP) linear regression has received significant
attention in the recent theoretical literature, with several works aimed at
obtaining improved error rates. A common approach is to set the clipping
constant much larger than the expected norm of the per-sample gradients. While
simplifying the analysis, this is however in sharp contrast with what empirical
evidence suggests to optimize performance. Our work bridges this gap between
theory and practice: we provide sharper rates for DP stochastic gradient
descent (DP-SGD) by crucially operating in a regime where clipping happens
frequently. Specifically, we consider the setting where the data is
multivariate Gaussian, the number of training samples $n$ is proportional to
the input dimension $d$, and the algorithm guarantees constant-order zero
concentrated DP. Our method relies on establishing a deterministic equivalent
for the trajectory of DP-SGD in terms of a family of ordinary differential
equations (ODEs). As a consequence, the risk of DP-SGD is bounded between two
ODEs, with upper and lower bounds matching for isotropic data. By studying
these ODEs when $n / d$ is large enough, we demonstrate the optimality of
aggressive clipping, and we uncover the benefits of decaying learning rate and
private noise scheduling.

</details>


### [193] [Learning non-equilibrium diffusions with Schrödinger bridges: from exactly solvable to simulation-free](https://arxiv.org/abs/2505.16644)
*Stephen Y. Zhang, Michael P H Stumpf*

**主要类别:** stat.ML

**概要:** 本论文研究了非平衡态系统中的Schrödinger桥问题，提出了一种新的算法mvOU-OTFM，能够更准确、快速地学习Schrödinger桥。


<details>
  <summary>更多</summary>
  
**动机:** 现有文献大多假设布朗运动参考动力学，仅适用于势能驱动的动力学系统。然而，许多生物系统是非平衡态的，包含非保守力的作用，因此需要一种新的方法来处理这类问题。

**方法:** 作者考虑了由多变量Ornstein-Uhlenbeck过程描述的参考过程，并提出了mvOU-OTFM算法，该算法基于流和得分匹配技术，无需模拟即可学习Schrödinger桥。

**结果:** 在高斯边缘分布的情况下，作者推导了静态和动态Schrödinger桥的显式解；对于一般边缘分布，mvOU-OTFM算法在合成和真实单细胞数据上的表现优于其他方法，且训练速度显著更快。

**结论:** mvOU-OTFM算法为解决非平衡态系统的Schrödinger桥问题提供了一种高效的方法，具有广泛的应用前景。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+non-equilibrium+diffusions+with+Schr%C3%B6dinger+bridges%3A+from+exactly+solvable+to+simulation-free，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16644，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16644&send_immediately=true&force_search=false)

**原文摘要:** We consider the Schr\"odinger bridge problem which, given ensemble
measurements of the initial and final configurations of a stochastic dynamical
system and some prior knowledge on the dynamics, aims to reconstruct the "most
likely" evolution of the system compatible with the data. Most existing
literature assume Brownian reference dynamics and are implicitly limited to
potential-driven dynamics. We depart from this regime and consider reference
processes described by a multivariate Ornstein-Uhlenbeck process with generic
drift matrix $\mathbf{A} \in \mathbb{R}^{d \times d}$. When $\mathbf{A}$ is
asymmetric, this corresponds to a non-equilibrium system with non-conservative
forces at play: this is important for applications to biological systems, which
are naturally exist out-of-equilibrium. In the case of Gaussian marginals, we
derive explicit expressions that characterise the solution of both the static
and dynamic Schr\"odinger bridge. For general marginals, we propose mvOU-OTFM,
a simulation-free algorithm based on flow and score matching for learning the
Schr\"odinger bridge. In application to a range of problems based on synthetic
and real single cell data, we demonstrate that mvOU-OTFM achieves higher
accuracy compared to competing methods, whilst being significantly faster to
train.

</details>


### [194] [Sharp concentration of uniform generalization errors in binary linear classification](https://arxiv.org/abs/2505.16713)
*Shogo Nakakita*

**主要类别:** stat.ML

**概要:** 通过等周论证，研究二元线性分类问题中泛化误差的集中性，并证明了在非常广泛的设定下，一致泛化误差几乎必然收敛到其期望值。


<details>
  <summary>更多</summary>
  
**动机:** 分析二元线性分类问题中泛化误差围绕其期望值的集中性，以更好地理解模型性能和泛化能力。

**方法:** 使用Poincaré和log-Sobolev不等式来建立输出标签和加权输入向量联合分布的集中性边界，并进行渐近分析以证明一致泛化误差的几乎必然收敛。

**结果:** 得到了与平衡标签情况下的集中性边界相差仅适度常数的结果，并证明了一致泛化误差在广泛设定下几乎必然收敛到其期望值。

**结论:** 一致大数定律可以在无维度限制条件下成立，这为高维数据场景下模型泛化能力提供了理论支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Sharp+concentration+of+uniform+generalization+errors+in+binary+linear+classification，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16713，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16713&send_immediately=true&force_search=false)

**原文摘要:** We examine the concentration of uniform generalization errors around their
expectation in binary linear classification problems via an isoperimetric
argument. In particular, we establish Poincar\'{e} and log-Sobolev inequalities
for the joint distribution of the output labels and the label-weighted input
vectors, which we apply to derive concentration bounds. The derived
concentration bounds are sharp up to moderate multiplicative constants by those
under well-balanced labels. In asymptotic analysis, we also show that almost
sure convergence of uniform generalization errors to their expectation occurs
in very broad settings, such as proportionally high-dimensional regimes. Using
this convergence, we establish uniform laws of large numbers under
dimension-free conditions.

</details>


### [195] [How high is `high'? Rethinking the roles of dimensionality in topological data analysis and manifold learning](https://arxiv.org/abs/2505.16879)
*Hannah Sansford, Nick Whiteley, Patrick Rubin-Delanchy*

**主要类别:** stat.ML

**概要:** 本文提出了广义的Hanson-Wright不等式，并利用其揭示了数据点云几何的新统计见解。研究探讨了三种维度概念：环境内在维度、相关性秩和潜在内在维度，并发现当内在维度远大于样本量的对数时，持久性图可以揭示潜在的同源性和流形结构。基于此理论，文章重新审视了Gardner等人关于网格细胞活动中的环面结构的神经科学发现，首次证明该结构与物理空间等距，表明网格细胞活动能够忠实表示现实世界。


<details>
  <summary>更多</summary>
  
**动机:** 通过引入广义Hanson-Wright不等式，研究数据点云的几何特性以及不同维度概念之间的关系，以理解数据中隐藏的流形结构及拓扑特征。

**方法:** 使用广义Hanson-Wright不等式分析数据模型中的三种维度概念：环境内在维度、相关性秩和潜在内在维度，并探讨这些维度如何影响持久性图揭示潜在同源性和流形结构的能力。

**结果:** 发现了当内在维度远大于样本量对数时，持久性图可以有效揭示潜在同源性和流形结构；重新分析了网格细胞活动中的环面结构，证明其与物理空间等距。

**结论:** 提出了新的统计方法来理解数据点云的几何特性，证实了网格细胞活动能够忠实地反映现实世界的几何结构。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是How+high+is+%60high%27%3F+Rethinking+the+roles+of+dimensionality+in+topological+data+analysis+and+manifold+learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16879，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16879&send_immediately=true&force_search=false)

**原文摘要:** We present a generalised Hanson-Wright inequality and use it to establish new
statistical insights into the geometry of data point-clouds. In the setting of
a general random function model of data, we clarify the roles played by three
notions of dimensionality: ambient intrinsic dimension $p_{\mathrm{int}}$,
which measures total variability across orthogonal feature directions;
correlation rank, which measures functional complexity across samples; and
latent intrinsic dimension, which is the dimension of manifold structure hidden
in data. Our analysis shows that in order for persistence diagrams to reveal
latent homology and for manifold structure to emerge it is sufficient that
$p_{\mathrm{int}}\gg \log n$, where $n$ is the sample size. Informed by these
theoretical perspectives, we revisit the ground-breaking neuroscience discovery
of toroidal structure in grid-cell activity made by Gardner et al. (Nature,
2022): our findings reveal, for the first time, evidence that this structure is
in fact isometric to physical space, meaning that grid cell activity conveys a
geometrically faithful representation of the real world.

</details>


### [196] [Statistical Test for Saliency Maps of Graph Neural Networks via Selective Inference](https://arxiv.org/abs/2505.16893)
*Shuichi Nishino, Tomohiro Shiraishi, Teruyuki Katsuoka, Ichiro Takeuchi*

**主要类别:** stat.ML

**概要:** 本研究提出了一种统计测试框架，用于评估图神经网络（GNN）显著性映射的可靠性，解决了数据双重利用导致的第一类错误率膨胀问题，并通过实验证明了该方法的有效性。


<details>
  <summary>更多</summary>
  
**动机:** 解释GNN决策时，现有的显著性映射在面对噪声时的鲁棒性不足，且其可靠性受到质疑。

**方法:** 提出一种基于选择性推断的统计测试框架，以严格评估显著性映射的重要性，同时提供有效的p值并控制第一类错误率。

**结果:** 实验结果表明，该方法在合成和真实数据集上均能有效评估GNN解释的可靠性。

**结论:** 所提出的方法能够确保识别出的显著子图包含有意义的信息而非随机伪影，从而提高了GNN解释的可信度。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Statistical+Test+for+Saliency+Maps+of+Graph+Neural+Networks+via+Selective+Inference，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16893，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16893&send_immediately=true&force_search=false)

**原文摘要:** Graph Neural Networks (GNNs) have gained prominence for their ability to
process graph-structured data across various domains. However, interpreting GNN
decisions remains a significant challenge, leading to the adoption of saliency
maps for identifying influential nodes and edges. Despite their utility, the
reliability of GNN saliency maps has been questioned, particularly in terms of
their robustness to noise. In this study, we propose a statistical testing
framework to rigorously evaluate the significance of saliency maps. Our main
contribution lies in addressing the inflation of the Type I error rate caused
by double-dipping of data, leveraging the framework of Selective Inference. Our
method provides statistically valid $p$-values while controlling the Type I
error rate, ensuring that identified salient subgraphs contain meaningful
information rather than random artifacts. To demonstrate the effectiveness of
our method, we conduct experiments on both synthetic and real-world datasets,
showing its effectiveness in assessing the reliability of GNN interpretations.

</details>


### [197] [TULiP: Test-time Uncertainty Estimation via Linearization and Weight Perturbation](https://arxiv.org/abs/2505.16923)
*Yuhui Zhang, Dongshen Wu, Yuichiro Wada, Takafumi Kanamori*

**主要类别:** stat.ML

**概要:** 提出了一种名为TULiP的不确定性估计方法，通过计算模型参数扰动产生的不确定性分数来检测近分布样本和分布外样本。


<details>
  <summary>更多</summary>
  
**动机:** 可靠的不确定性估计方法是现代分布外（OOD）检测器的基础，对于在开放世界中安全部署深度学习模型至关重要。因此，需要一种理论上驱动的、事后可计算的不确定性估计方法。

**方法:** TULiP考虑了在网络收敛前施加的假设性扰动，并基于线性化的训练动态过程，限制这种扰动的影响，从而通过扰动模型参数计算出不确定性分数。最终，该方法通过对一组采样预测进行计算来得出不确定性。

**结果:** 研究者在合成回归和分类数据集上可视化了其边界，并使用大规模图像分类OOD检测基准展示了TULiP的有效性。实验结果表明，TULiP在近分布样本检测方面具有最先进的性能。

**结论:** TULiP是一种理论上驱动的事后不确定性估计器，适用于OOD检测，尤其在处理近分布样本时表现出色。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是TULiP%3A+Test-time+Uncertainty+Estimation+via+Linearization+and+Weight+Perturbation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.16923，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.16923&send_immediately=true&force_search=false)

**原文摘要:** A reliable uncertainty estimation method is the foundation of many modern
out-of-distribution (OOD) detectors, which are critical for safe deployments of
deep learning models in the open world. In this work, we propose TULiP, a
theoretically-driven post-hoc uncertainty estimator for OOD detection. Our
approach considers a hypothetical perturbation applied to the network before
convergence. Based on linearized training dynamics, we bound the effect of such
perturbation, resulting in an uncertainty score computable by perturbing model
parameters. Ultimately, our approach computes uncertainty from a set of sampled
predictions. We visualize our bound on synthetic regression and classification
datasets. Furthermore, we demonstrate the effectiveness of TULiP using
large-scale OOD detection benchmarks for image classification. Our method
exhibits state-of-the-art performance, particularly for near-distribution
samples.

</details>


### [198] [Critical Points of Random Neural Networks](https://arxiv.org/abs/2505.17000)
*Simmaco Di Lillo*

**主要类别:** stat.ML

**概要:** 这篇论文研究了在无限宽度极限下，随着深度增加的随机神经网络中临界点的期望数量，并根据激活函数的不同进行了分析。


<details>
  <summary>更多</summary>
  
**动机:** 了解随机神经网络中临界点的期望数量如何随着深度和激活函数的变化而变化，以揭示潜在的理论机制。

**方法:** 通过数学推导，得到固定指数的临界点和超过给定阈值的临界点的期望数量的精确渐近公式，并结合数值实验验证理论预测。

**结果:** 发现存在三个不同的渐变模式取决于协方差的第一导数在1处的值：临界点的期望数量可能收敛、多项式增长或指数增长。此外，对于不满足正则性条件的ReLU激活函数，临界点的数量随映射分辨率增加而增加。

**结论:** 随机神经网络的临界点数量行为受激活函数及其正则性条件的影响显著，且理论结果得到了数值实验的支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Critical+Points+of+Random+Neural+Networks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2505.17000，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2505.17000&send_immediately=true&force_search=false)

**原文摘要:** This work investigates the expected number of critical points of random
neural networks with different activation functions as the depth increases in
the infinite-width limit. Under suitable regularity conditions, we derive
precise asymptotic formulas for the expected number of critical points of fixed
index and those exceeding a given threshold. Our analysis reveals three
distinct regimes depending on the value of the first derivative of the
covariance evaluated at 1: the expected number of critical points may converge,
grow polynomially, or grow exponentially with depth. The theoretical
predictions are supported by numerical experiments. Moreover, we provide
numerical evidence suggesting that, when the regularity condition is not
satisfied (e.g. for neural networks with ReLU as activation function), the
number of critical points increases as the map resolution increases, indicating
a potential divergence in the number of critical points.

</details>
