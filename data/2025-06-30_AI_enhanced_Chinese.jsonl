{"id": "2506.21739", "pdf": "https://arxiv.org/pdf/2506.21739", "abs": "https://arxiv.org/abs/2506.21739", "authors": ["Felipe Rog\u00e9rio Pimentel", "Rafael Gustavo Alves"], "title": "Modification of a Numerical Method Using FIR Filters in a Time-dependent SIR Model for COVID-19", "categories": ["stat.ML", "cs.LG", "math.OC", "92B05, 92-10, 65K05, 37M99, 49"], "comment": "14 pages, 3 figures, 3 tables, and 2 algorithms", "summary": "Authors Yi-Cheng Chen, Ping-En Lu, Cheng-Shang Chang, and Tzu-Hsuan Liu use\nthe Finite Impulse Response (FIR) linear system filtering method to track and\npredict the number of people infected and recovered from COVID-19, in a\npandemic context in which there was still no vaccine and the only way to avoid\ncontagion was isolation. To estimate the coefficients of these FIR filters,\nChen et al. used machine learning methods through a classical optimization\nproblem with regularization (ridge regression). These estimated coefficients\nare called ridge coefficients. The epidemic mathematical model adopted by these\nresearchers to formulate the FIR filters is the time-dependent discrete SIR. In\nthis paper, we propose a small modification to the algorithm of Chen et al. to\nobtain the ridge coefficients. We then used this modified algorithm to track\nand predict the number of people infected and recovered from COVID-19 in the\nstate of Minas Gerais/Brazil, within a prediction window, during the initial\nperiod of the pandemic. We also compare the predicted data with the respective\nreal data to check how good the approximation is. In the modified algorithm, we\nset values for the FIR filter orders and for the regularization parameters,\nboth different from the respective values defined by Chen et al. in their\nalgorithm. In this context, the numerical results obtained by the modified\nalgorithm in some simulations present better approximation errors compared to\nthe respective approximation errors presented by the algorithm of Chen et al.", "AI": {"tldr": "\u901a\u8fc7\u4fee\u6539Chen\u7b49\u4eba\u7684\u7b97\u6cd5\uff0c\u4f7f\u7528\u4e0d\u540c\u7684FIR\u6ee4\u6ce2\u5668\u9636\u6570\u548c\u6b63\u5219\u5316\u53c2\u6570\u503c\uff0c\u6765\u8ddf\u8e2a\u548c\u9884\u6d4b\u5df4\u897f\u7c73\u7eb3\u65af\u5409\u62c9\u65af\u5dde\u5728\u75ab\u60c5\u521d\u671f\u7684COVID-19\u611f\u67d3\u548c\u5eb7\u590d\u4eba\u6570\uff0c\u5e76\u4e0e\u5b9e\u9645\u6570\u636e\u8fdb\u884c\u6bd4\u8f83\uff0c\u7ed3\u679c\u663e\u793a\u4fee\u6539\u540e\u7684\u7b97\u6cd5\u5728\u67d0\u4e9b\u6a21\u62df\u4e2d\u5177\u6709\u66f4\u597d\u7684\u903c\u8fd1\u8bef\u5dee\u3002", "motivation": "\u5728\u6ca1\u6709\u75ab\u82d7\u7684\u60c5\u51b5\u4e0b\uff0c\u9694\u79bb\u662f\u907f\u514d\u611f\u67d3\u7684\u552f\u4e00\u65b9\u6cd5\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u8ddf\u8e2a\u548c\u9884\u6d4b\u611f\u67d3\u548c\u5eb7\u590d\u4eba\u6570\u3002Chen\u7b49\u4eba\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFIR\u7ebf\u6027\u7cfb\u7edf\u6ee4\u6ce2\u7684\u65b9\u6cd5\uff0c\u8be5\u7814\u7a76\u5728\u6b64\u57fa\u7840\u4e0a\u8fdb\u884c\u4e86\u6539\u8fdb\u4ee5\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u3002", "method": "\u91c7\u7528\u65f6\u95f4\u4f9d\u8d56\u79bb\u6563SIR\u6a21\u578b\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5cad\u56de\u5f52\u4f18\u5316\u95ee\u9898\u4f30\u8ba1FIR\u6ee4\u6ce2\u5668\u7cfb\u6570\uff08\u5373\u5cad\u7cfb\u6570\uff09\u3002\u5bf9Chen\u7b49\u4eba\u7684\u7b97\u6cd5\u8fdb\u884c\u4e86\u5c0f\u4fee\u6539\uff0c\u91cd\u65b0\u8bbe\u7f6e\u4e86FIR\u6ee4\u6ce2\u5668\u9636\u6570\u548c\u6b63\u5219\u5316\u53c2\u6570\u503c\uff0c\u7528\u4e8e\u9884\u6d4b\u5df4\u897f\u7c73\u7eb3\u65af\u5409\u62c9\u65af\u5dde\u7684COVID-19\u611f\u67d3\u548c\u5eb7\u590d\u4eba\u6570\u3002", "result": "\u4fee\u6539\u540e\u7684\u7b97\u6cd5\u5728\u67d0\u4e9b\u6a21\u62df\u4e2d\u8868\u73b0\u51fa\u6bd4Chen\u7b49\u4eba\u539f\u7b97\u6cd5\u66f4\u597d\u7684\u903c\u8fd1\u8bef\u5dee\uff0c\u9884\u6d4b\u7ed3\u679c\u66f4\u63a5\u8fd1\u5b9e\u9645\u6570\u636e\u3002", "conclusion": "\u901a\u8fc7\u8c03\u6574FIR\u6ee4\u6ce2\u5668\u9636\u6570\u548c\u6b63\u5219\u5316\u53c2\u6570\uff0c\u53ef\u4ee5\u6539\u5584\u57fa\u4e8eFIR\u6ee4\u6ce2\u5668\u7684\u75ab\u60c5\u9884\u6d4b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u63d0\u9ad8\u611f\u67d3\u548c\u5eb7\u590d\u4eba\u6570\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2506.21741", "pdf": "https://arxiv.org/pdf/2506.21741", "abs": "https://arxiv.org/abs/2506.21741", "authors": ["Benjamin Sterling", "Chad Gueli", "M\u00f3nica F. Bugallo"], "title": "Critically-Damped Higher-Order Langevin Dynamics", "categories": ["stat.ML", "cs.LG"], "comment": "12 pages", "summary": "Denoising Diffusion Probabilistic Models represent an entirely new class of\ngenerative AI methods that have yet to be fully explored. Critical damping has\nbeen successfully introduced in Critically-Damped Langevin Dynamics (CLD) and\nCritically-Damped Third-Order Langevin Dynamics (TOLD++), but has not yet been\napplied to dynamics of arbitrary order. The proposed line of work generalizes\nHigher-Order Langevin Dynamics (HOLD), a recent state-of-the-art diffusion\nmethod, by introducing the concept of critical damping from systems analysis.", "AI": {"tldr": "\u751f\u6210\u5f0fAI\u65b9\u6cd5\u4e2d\u7684\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\u5c1a\u5f85\u5145\u5206\u63a2\u7d22\u3002\u5173\u952e\u963b\u5c3c\u867d\u5df2\u5728CLD\u548cTOLD++\u4e2d\u6210\u529f\u5f15\u5165\uff0c\u4f46\u5c1a\u672a\u5e94\u7528\u4e8e\u4efb\u610f\u9636\u7684\u52a8\u529b\u5b66\u4e2d\u3002\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u7cfb\u7edf\u5206\u6790\u4e2d\u7684\u5173\u952e\u963b\u5c3c\u6982\u5ff5\uff0c\u5bf9\u6700\u8fd1\u7684\u9876\u7ea7\u6269\u6563\u65b9\u6cd5\u2014\u2014\u9ad8\u9636\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\uff08HOLD\uff09\u8fdb\u884c\u4e86\u63a8\u5e7f\u3002", "motivation": "\u5c06\u5173\u952e\u963b\u5c3c\u7684\u6982\u5ff5\u5f15\u5165\u5230\u4efb\u610f\u9636\u7684\u52a8\u529b\u5b66\u4e2d\uff0c\u4ee5\u671f\u6539\u8fdb\u73b0\u6709\u6269\u6563\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u5bf9\u9ad8\u9636\u6717\u4e4b\u4e07\u52a8\u529b\u5b66\uff08HOLD\uff09\u8fdb\u884c\u63a8\u5e7f\uff0c\u5e76\u7ed3\u5408\u7cfb\u7edf\u5206\u6790\u4e2d\u7684\u5173\u952e\u963b\u5c3c\u6982\u5ff5\uff0c\u6784\u5efa\u65b0\u7684\u751f\u6210\u6a21\u578b\u3002", "result": "\u5b9e\u73b0\u4e86\u5bf9HOLD\u7684\u63a8\u5e7f\uff0c\u53ef\u80fd\u63d0\u5347\u751f\u6210\u6a21\u578b\u7684\u6548\u679c\u548c\u6548\u7387\u3002", "conclusion": "\u5f15\u5165\u5173\u952e\u963b\u5c3c\u6982\u5ff5\u7684\u63a8\u5e7f\u65b9\u6cd5\u4e3a\u6269\u6563\u6a21\u578b\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u548c\u53ef\u80fd\u6027\u3002"}}
{"id": "2506.21757", "pdf": "https://arxiv.org/pdf/2506.21757", "abs": "https://arxiv.org/abs/2506.21757", "authors": ["Tianrong Chen", "Huangjie Zheng", "David Berthelot", "Jiatao Gu", "Josh Susskind", "Shuangfei Zhai"], "title": "TADA: Improved Diffusion Sampling with Training-free Augmented Dynamics", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Diffusion models have demonstrated exceptional capabilities in generating\nhigh-fidelity images but typically suffer from inefficient sampling. Many\nsolver designs and noise scheduling strategies have been proposed to\ndramatically improve sampling speeds. In this paper, we introduce a new\nsampling method that is up to $186\\%$ faster than the current state of the art\nsolver for comparative FID on ImageNet512. This new sampling method is\ntraining-free and uses an ordinary differential equation (ODE) solver. The key\nto our method resides in using higher-dimensional initial noise, allowing to\nproduce more detailed samples with less function evaluations from existing\npretrained diffusion models. In addition, by design our solver allows to\ncontrol the level of detail through a simple hyper-parameter at no extra\ncomputational cost. We present how our approach leverages momentum dynamics by\nestablishing a fundamental equivalence between momentum diffusion models and\nconventional diffusion models with respect to their training paradigms.\nMoreover, we observe the use of higher-dimensional noise naturally exhibits\ncharacteristics similar to stochastic differential equations (SDEs). Finally,\nwe demonstrate strong performances on a set of representative pretrained\ndiffusion models, including EDM, EDM2, and Stable-Diffusion 3, which cover\nmodels in both pixel and latent spaces, as well as class and text conditional\nsettings. The code is available at https://github.com/apple/ml-tada.", "AI": {"tldr": "\u6269\u6563\u6a21\u578b\u867d\u64c5\u957f\u751f\u6210\u9ad8\u4fdd\u771f\u56fe\u50cf\uff0c\u4f46\u91c7\u6837\u6548\u7387\u4f4e\u3002\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u6bd4\u73b0\u6709\u6700\u4f73\u6c42\u89e3\u5668\u5feb186%\uff0c\u4e14\u65e0\u9700\u8bad\u7ec3\uff0c\u57fa\u4e8eODE\u6c42\u89e3\u5668\uff0c\u4f7f\u7528\u66f4\u9ad8\u7ef4\u521d\u59cb\u566a\u58f0\u51cf\u5c11\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\uff0c\u5e76\u53ef\u901a\u8fc7\u8d85\u53c2\u6570\u63a7\u5236\u7ec6\u8282\u6c34\u5e73\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u52a8\u91cf\u52a8\u529b\u5b66\uff0c\u63ed\u793a\u4e86\u52a8\u91cf\u6269\u6563\u6a21\u578b\u4e0e\u4f20\u7edf\u6269\u6563\u6a21\u578b\u7684\u7b49\u4ef7\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u4e0a\u5c55\u793a\u4e86\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u6269\u6563\u6a21\u578b\u5728\u751f\u6210\u9ad8\u4fdd\u771f\u56fe\u50cf\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u91c7\u6837\u6548\u7387\u4f4e\u4e0b\uff0c\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u5e76\u63d0\u9ad8\u91c7\u6837\u901f\u5ea6\uff0c\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u91c7\u6837\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u91c7\u7528ODE\u6c42\u89e3\u5668\uff0c\u4f7f\u7528\u66f4\u9ad8\u7ef4\u521d\u59cb\u566a\u58f0\u4ee5\u51cf\u5c11\u51fd\u6570\u8bc4\u4f30\u6b21\u6570\uff0c\u4ece\u800c\u751f\u6210\u66f4\u8be6\u7ec6\u6837\u672c\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u4e00\u4e2a\u8d85\u53c2\u6570\u53ef\u4ee5\u65e0\u989d\u5916\u8ba1\u7b97\u6210\u672c\u5730\u63a7\u5236\u6837\u672c\u7ec6\u8282\u6c34\u5e73\u3002\u65b9\u6cd5\u8fd8\u5229\u7528\u4e86\u52a8\u91cf\u52a8\u529b\u5b66\uff0c\u5e76\u5efa\u7acb\u4e86\u52a8\u91cf\u6269\u6563\u6a21\u578b\u4e0e\u4f20\u7edf\u6269\u6563\u6a21\u578b\u4e4b\u95f4\u7684\u57fa\u672c\u7b49\u4ef7\u6027\u3002", "result": "\u5728ImageNet512\u4e0a\uff0c\u8be5\u65b9\u6cd5\u6bd4\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6c42\u89e3\u5668\u5feb186%\uff08\u9488\u5bf9\u6bd4\u8f83FID\uff09\u3002\u5728\u5305\u62ecEDM\u3001EDM2\u548cStable-Diffusion 3\u5728\u5185\u7684\u4ee3\u8868\u6027\u9884\u8bad\u7ec3\u6269\u6563\u6a21\u578b\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u8986\u76d6\u50cf\u7d20\u548c\u6f5c\u5728\u7a7a\u95f4\u6a21\u578b\u4ee5\u53ca\u7c7b\u522b\u548c\u6587\u672c\u6761\u4ef6\u8bbe\u7f6e\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b0\u91c7\u6837\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6269\u6563\u6a21\u578b\u7684\u91c7\u6837\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u4e86\u751f\u6210\u6837\u672c\u7684\u8d28\u91cf\u3002\u6b64\u5916\uff0c\u65b9\u6cd5\u63ed\u793a\u4e86\u52a8\u91cf\u6269\u6563\u6a21\u578b\u4e0e\u4f20\u7edf\u6269\u6563\u6a21\u578b\u7684\u7b49\u4ef7\u6027\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002"}}
{"id": "2506.21802", "pdf": "https://arxiv.org/pdf/2506.21802", "abs": "https://arxiv.org/abs/2506.21802", "authors": ["Johan Hallberg Szabadv\u00e1ry", "Tuwe L\u00f6fstr\u00f6m", "Ulf Johansson", "Cecilia S\u00f6nstr\u00f6d", "Ernst Ahlberg", "Lars Carlsson"], "title": "Classification with Reject Option: Distribution-free Error Guarantees via Conformal Prediction", "categories": ["stat.ML", "cs.LG"], "comment": "20 pages, 3 figures", "summary": "Machine learning (ML) models always make a prediction, even when they are\nlikely to be wrong. This causes problems in practical applications, as we do\nnot know if we should trust a prediction. ML with reject option addresses this\nissue by abstaining from making a prediction if it is likely to be incorrect.\nIn this work, we formalise the approach to ML with reject option in binary\nclassification, deriving theoretical guarantees on the resulting error rate.\nThis is achieved through conformal prediction (CP), which produce prediction\nsets with distribution-free validity guarantees. In binary classification, CP\ncan output prediction sets containing exactly one, two or no labels. By\naccepting only the singleton predictions, we turn CP into a binary classifier\nwith reject option.\n  Here, CP is formally put in the framework of predicting with reject option.\nWe state and prove the resulting error rate, and give finite sample estimates.\nNumerical examples provide illustrations of derived error rate through several\ndifferent conformal prediction settings, ranging from full conformal prediction\nto offline batch inductive conformal prediction. The former has a direct link\nto sharp validity guarantees, whereas the latter is more fuzzy in terms of\nvalidity guarantees but can be used in practice. Error-reject curves illustrate\nthe trade-off between error rate and reject rate, and can serve to aid a user\nto set an acceptable error rate or reject rate in practice.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u4e86\u5728\u4e8c\u5206\u7c7b\u95ee\u9898\u4e2d\uff0c\u901a\u8fc7\u7b26\u5408\u6027\u9884\u6d4b\uff08Conformal Prediction, CP\uff09\u65b9\u6cd5\u5b9e\u73b0\u5e26\u62d2\u7edd\u9009\u9879\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u63d0\u4f9b\u5206\u5e03\u65e0\u5173\u7684\u6709\u6548\u6027\u4fdd\u8bc1\uff0c\u5e76\u901a\u8fc7\u63a7\u5236\u62d2\u7edd\u7387\u4e0e\u9519\u8bef\u7387\u4e4b\u95f4\u7684\u6743\u8861\u6765\u4f18\u5316\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5373\u4f7f\u53ef\u80fd\u51fa\u9519\u4e5f\u4f1a\u505a\u51fa\u9884\u6d4b\uff0c\u8fd9\u5bfc\u81f4\u4e86\u9884\u6d4b\u53ef\u4fe1\u5ea6\u7684\u95ee\u9898\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u5e26\u62d2\u7edd\u9009\u9879\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5373\u5f53\u9884\u6d4b\u53ef\u80fd\u4e0d\u51c6\u786e\u65f6\u9009\u62e9\u4e0d\u8fdb\u884c\u9884\u6d4b\u3002", "method": "\u8bba\u6587\u5c06\u7b26\u5408\u6027\u9884\u6d4b\uff08CP\uff09\u65b9\u6cd5\u5f62\u5f0f\u5316\u5730\u5e94\u7528\u4e8e\u5e26\u62d2\u7edd\u9009\u9879\u7684\u4e8c\u5206\u7c7b\u95ee\u9898\u4e2d\u3002\u901a\u8fc7\u4ec5\u63a5\u53d7\u5355\u6807\u7b7e\u9884\u6d4b\u7ed3\u679c\uff0c\u5c06CP\u8f6c\u5316\u4e3a\u5177\u6709\u62d2\u7edd\u9009\u9879\u7684\u4e8c\u5206\u7c7b\u5668\u3002\u6b64\u5916\uff0c\u8bba\u6587\u8fd8\u63d0\u4f9b\u4e86\u7406\u8bba\u4e0a\u7684\u9519\u8bef\u7387\u4fdd\u8bc1\u548c\u6709\u9650\u6837\u672c\u4f30\u8ba1\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u5c55\u793a\u4e86\u4e0d\u540c\u7b26\u5408\u6027\u9884\u6d4b\u8bbe\u7f6e\u4e0b\u7684\u9519\u8bef\u7387\u8868\u73b0\uff0c\u5305\u62ec\u5b8c\u6574\u7684\u7b26\u5408\u6027\u9884\u6d4b\u548c\u79bb\u7ebf\u6279\u91cf\u5f52\u7eb3\u5f0f\u7b26\u5408\u6027\u9884\u6d4b\u3002\u8bef\u5dee-\u62d2\u7edd\u66f2\u7ebf\u8fdb\u4e00\u6b65\u8bf4\u660e\u4e86\u9519\u8bef\u7387\u548c\u62d2\u7edd\u7387\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "conclusion": "\u5e26\u62d2\u7edd\u9009\u9879\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u7ed3\u5408\u7b26\u5408\u6027\u9884\u6d4b\u80fd\u591f\u5728\u4e8c\u5206\u7c7b\u95ee\u9898\u4e2d\u63d0\u4f9b\u6709\u6548\u7684\u9519\u8bef\u7387\u63a7\u5236\uff0c\u5e76\u5141\u8bb8\u7528\u6237\u6839\u636e\u5b9e\u9645\u9700\u6c42\u8bbe\u7f6e\u53ef\u63a5\u53d7\u7684\u9519\u8bef\u7387\u6216\u62d2\u7edd\u7387\u3002"}}
{"id": "2506.21655", "pdf": "https://arxiv.org/pdf/2506.21655", "abs": "https://arxiv.org/abs/2506.21655", "authors": ["Minjie Hong", "Zirun Guo", "Yan Xia", "Zehan Wang", "Ziang Zhang", "Tao Jin", "Zhou Zhao"], "title": "APO: Enhancing Reasoning Ability of MLLMs via Asymmetric Policy Optimization", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Multimodal Large Language Models (MLLMs) are powerful at integrating diverse\ndata, but they often struggle with complex reasoning. While Reinforcement\nlearning (RL) can boost reasoning in LLMs, applying it to MLLMs is tricky.\nCommon issues include a drop in performance on general tasks and the generation\nof overly detailed or \"overthinking\" reasoning. Our work investigates how the\nKL penalty and overthinking affect RL training in MLLMs. We propose Asymmetric\nPolicy Optimization (APO) to address these issues, which divides the sampled\nresponses into positive and negative groups. For positive samples,\nDifficulty-Adaptive Divergence Shaping (DADS) is introduced to dynamically\nadjust the KL divergence weight based on their difficulty. This method prevents\npolicy entropy from dropping sharply, improves training stability, utilizes\nsamples better, and preserves the model's existing knowledge. For negative\nsamples, Suboptimal Trajectory Complexity Regularization (STCR) is proposed to\npenalize overly long responses. This helps mitigate overthinking and encourages\nmore concise reasoning while preserving the model's explorative capacity. We\napply our method to Qwen2.5-VL-3B, creating View-R1-3B. View-R1-3B\nsignificantly enhances reasoning capabilities, showing an average 7\\% gain over\nthe base model and outperforming larger MLLMs (7-11B) on various reasoning\nbenchmarks. Importantly, unlike other reasoning-tuned MLLMs that often degrade\non general tasks, View-R1-3B maintains consistent improvement, demonstrating\nsuperior generalization. These results highlight the effectiveness and broad\napplicability of our DADS and STCR techniques for advancing complex multimodal\nreasoning in MLLMs. The code will be made available at\nhttps://github.com/Indolent-Kawhi/View-R1.", "AI": {"tldr": "Multimodal Large Language Models (MLLMs) struggle with complex reasoning despite their data integration capabilities. Reinforcement Learning (RL) can improve reasoning but poses challenges when applied to MLLMs such as performance degradation and overthinking. This paper investigates the impact of KL penalty and overthinking in RL training for MLLMs, proposing Asymmetric Policy Optimization (APO) to address these issues. APO includes Difficulty-Adaptive Divergence Shaping (DADS) for positive samples and Suboptimal Trajectory Complexity Regularization (STCR) for negative samples. The method was applied to Qwen2.5-VL-3B creating View-R1-3B, which showed a 7% gain over the base model and outperformed larger models on reasoning benchmarks without degrading general task performance.", "motivation": "The motivation is to enhance the reasoning capabilities of MLLMs while avoiding common pitfalls like performance degradation on general tasks and overthinking, by investigating the effects of KL penalty and overthinking during RL training.", "method": "The method involves using Asymmetric Policy Optimization (APO), which categorizes sampled responses into positive and negative groups. For positive samples, Difficulty-Adaptive Divergence Shaping (DADS) dynamically adjusts the KL divergence weight based on difficulty. For negative samples, Suboptimal Trajectory Complexity Regularization (STCR) penalizes overly long responses.", "result": "View-R1-3B, derived from Qwen2.5-VL-3B, demonstrated an average 7% improvement over the base model and outperformed larger MLLMs on various reasoning benchmarks. Notably, it maintained consistent improvement on general tasks without degradation.", "conclusion": "The proposed DADS and STCR techniques effectively advance complex multimodal reasoning in MLLMs, showing strong generalization and applicability. The code will be released on GitHub."}}
{"id": "2506.21669", "pdf": "https://arxiv.org/pdf/2506.21669", "abs": "https://arxiv.org/abs/2506.21669", "authors": ["Wanxin Tian", "Shijie Zhang", "Kevin Zhang", "Xiaowei Chi", "Yulin Luo", "Junyu Lu", "Chunkai Fan", "Qiang Zhou", "Yiming Zhao", "Ning Liu Siyu Lin", "Zhiyuan Qin", "Xiaozhu Ju", "Shanghang Zhang", "Jian Tang"], "title": "SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents", "categories": ["cs.AI"], "comment": null, "summary": "Self-evolution, the ability of agents to autonomously improve their reasoning\nand behavior, is essential for the embodied domain with long-horizon,\nreal-world tasks. Despite current advancements in reinforcement fine-tuning\n(RFT) showing strong performance in enhancing reasoning in LLMs, its potential\nto enable self-evolving embodied intelligence with multi-modal interactions\nremains largely unexplored. Specifically, reinforcement fine-tuning faces two\nfundamental obstacles in embodied settings: (i) the lack of accessible\nintermediate rewards in multi-step reasoning tasks limits effective learning\nsignals, and (ii) reliance on hand-crafted reward functions restricts\ngeneralization to novel tasks and environments. To address these challenges, we\npresent Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework\ndesigned for enabling the self-evolving capabilities of embodied agents.\nSpecifically, to convert sparse delayed rewards into denser intermediate\nsignals that improve multi-step reasoning, we propose Tree-based group relative\npolicy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into\nGRPO. To generalize reward estimation across tasks and scenes, supporting\nautonomous adaptation and reward-driven self-evolution, we further introduce\nMulti-modal Generative Reward Model (MGRM). To holistically evaluate the\neffectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing\nstate-of-the-art methods with scores of 85.07% (textual) and 36.19%\n(multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also\nachieves scores of 80.3% without environmental reward, surpassing all\nopen-source baselines and highlighting its scalability as a self-evolving\nembodied agent. Additional experiments and qualitative analysis further support\nthe potential of SEEA-R1 for future research in scalable embodied intelligence.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSEEA-R1\u7684\u5f3a\u5316\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7Tree-GRPO\u548cMGRM\u65b9\u6cd5\u89e3\u51b3\u7a00\u758f\u5956\u52b1\u95ee\u9898\u548c\u8de8\u4efb\u52a1\u5956\u52b1\u4f30\u8ba1\u95ee\u9898\uff0c\u5728ALFWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\uff0c\u5305\u62ecGPT-4o\uff0c\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u53ef\u81ea\u6211\u6f14\u5316\u7684\u5177\u8eab\u667a\u80fd\u4f53\u7684\u6f5c\u529b\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5fae\u8c03\u6280\u672f\u5728\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u591a\u6a21\u6001\u4e92\u52a8\u4e2d\u7684\u81ea\u6211\u6f14\u5316\u667a\u80fd\u4f53\u73b0\u4ecd\u5f85\u63a2\u7d22\uff0c\u4e3b\u8981\u53d7\u9650\u4e8e\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u7f3a\u4e4f\u6709\u6548\u7684\u5b66\u4e60\u4fe1\u53f7\u4ee5\u53ca\u5bf9\u4eba\u5de5\u8bbe\u8ba1\u5956\u52b1\u51fd\u6570\u7684\u4f9d\u8d56\u3002", "method": "\u63d0\u51faSEEA-R1\u6846\u67b6\uff0c\u5305\u542bTree-GRPO\uff08\u5c06\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6574\u5408\u5230\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\u4e2d\u4ee5\u6539\u5584\u591a\u6b65\u63a8\u7406\uff09\u548cMGRM\uff08\u7528\u4e8e\u8de8\u4efb\u52a1\u548c\u573a\u666f\u7684\u5956\u52b1\u4f30\u8ba1\uff0c\u652f\u6301\u81ea\u4e3b\u9002\u5e94\u548c\u5956\u52b1\u9a71\u52a8\u7684\u81ea\u6211\u6f14\u5316\uff09\u3002", "result": "\u5728ALFWorld\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6587\u672c\u548c\u591a\u6a21\u6001\u4efb\u52a1\u5206\u522b\u8fbe\u523085.07%\u548c36.19%\u7684\u5206\u6570\uff0c\u8d85\u8fc7\u5305\u62ecGPT-4o\u5728\u5185\u7684\u5148\u524d\u6a21\u578b\uff1b\u5373\u4f7f\u6ca1\u6709\u73af\u5883\u5956\u52b1\uff0c\u4e5f\u83b7\u5f97\u4e8680.3%\u7684\u5206\u6570\uff0c\u8d85\u8d8a\u6240\u6709\u5f00\u6e90\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "SEEA-R1\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u5177\u8eab\u667a\u80fd\u4f53\u7684\u81ea\u6211\u6f14\u5316\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u8bc4\u6d4b\u6307\u6807\u4e0a\u5c55\u73b0\u4e86\u4f18\u8d8a\u6027\uff0c\u4e3a\u672a\u6765\u53ef\u6269\u5c55\u7684\u5177\u8eab\u667a\u80fd\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2506.21894", "pdf": "https://arxiv.org/pdf/2506.21894", "abs": "https://arxiv.org/abs/2506.21894", "authors": ["Rafael Oliveira", "Xuesong Wang", "Kian Ming A. Chai", "Edwin V. Bonilla"], "title": "Thompson Sampling in Function Spaces via Neural Operators", "categories": ["stat.ML", "cs.LG"], "comment": "Under review", "summary": "We propose an extension of Thompson sampling to optimization problems over\nfunction spaces where the objective is a known functional of an unknown\noperator's output. We assume that functional evaluations are inexpensive, while\nqueries to the operator (such as running a high-fidelity simulator) are costly.\nOur algorithm employs a sample-then-optimize approach using neural operator\nsurrogates. This strategy avoids explicit uncertainty quantification by\ntreating trained neural operators as approximate samples from a Gaussian\nprocess. We provide novel theoretical convergence guarantees, based on Gaussian\nprocesses in the infinite-dimensional setting, under minimal assumptions. We\nbenchmark our method against existing baselines on functional optimization\ntasks involving partial differential equations and other nonlinear\noperator-driven phenomena, demonstrating improved sample efficiency and\ncompetitive performance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u7684\u6c64\u666e\u68ee\u91c7\u6837\u65b9\u6cd5\uff0c\u7528\u4e8e\u51fd\u6570\u7a7a\u95f4\u4e0a\u7684\u4f18\u5316\u95ee\u9898\u3002\u8be5\u7b97\u6cd5\u91c7\u7528\u795e\u7ecf\u7b97\u5b50\u4ee3\u7406\u8fdb\u884c\u6837\u672c-\u4f18\u5316\u7b56\u7565\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u6536\u655b\u6027\u4fdd\u8bc1\uff0c\u5728\u6d89\u53ca\u504f\u5fae\u5206\u65b9\u7a0b\u7684\u529f\u80fd\u4f18\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u91c7\u6837\u6548\u7387\u548c\u7ade\u4e89\u529b\u3002", "motivation": "\u5728\u51fd\u6570\u7a7a\u95f4\u4f18\u5316\u95ee\u9898\u4e2d\uff0c\u76ee\u6807\u51fd\u6570\u662f\u672a\u77e5\u7b97\u5b50\u8f93\u51fa\u7684\u5df2\u77e5\u6cdb\u51fd\uff0c\u800c\u7b97\u5b50\u67e5\u8be2\u6210\u672c\u9ad8\u4f46\u6cdb\u51fd\u8bc4\u4f30\u5ec9\u4ef7\u3002\u4e3a\u89e3\u51b3\u6b64\u7c7b\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u6602\u8d35\u7684\u7b97\u5b50\u67e5\u8be2\u6b21\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u4f18\u5316\u6027\u80fd\u3002", "method": "\u8be5\u65b9\u6cd5\u6269\u5c55\u4e86\u6c64\u666e\u68ee\u91c7\u6837\uff0c\u4f7f\u7528\u795e\u7ecf\u7b97\u5b50\u4ee3\u7406\u8fdb\u884c\u6837\u672c-\u4f18\u5316\u7b56\u7565\u3002\u5c06\u8bad\u7ec3\u597d\u7684\u795e\u7ecf\u7b97\u5b50\u89c6\u4e3a\u9ad8\u65af\u8fc7\u7a0b\u7684\u8fd1\u4f3c\u6837\u672c\uff0c\u907f\u514d\u4e86\u663e\u5f0f\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002\u901a\u8fc7\u7ed3\u5408\u5ec9\u4ef7\u7684\u6cdb\u51fd\u8bc4\u4f30\u548c\u4ee3\u4ef7\u9ad8\u6602\u7684\u7b97\u5b50\u67e5\u8be2\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u4f18\u5316\u3002", "result": "\u5728\u6d89\u53ca\u504f\u5fae\u5206\u65b9\u7a0b\u548c\u5176\u4ed6\u975e\u7ebf\u6027\u7b97\u5b50\u9a71\u52a8\u73b0\u8c61\u7684\u529f\u80fd\u4f18\u5316\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u8f83\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u5c55\u73b0\u51fa\u66f4\u9ad8\u7684\u91c7\u6837\u6548\u7387\u548c\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u6269\u5c55\u6c64\u666e\u68ee\u91c7\u6837\u65b9\u6cd5\u5728\u51fd\u6570\u7a7a\u95f4\u4f18\u5316\u95ee\u9898\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u63d0\u4f9b\u4e86\u7406\u8bba\u6536\u655b\u6027\u4fdd\u8bc1\uff0c\u5e76\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\u548c\u7ade\u4e89\u529b\u3002"}}
{"id": "2506.21683", "pdf": "https://arxiv.org/pdf/2506.21683", "abs": "https://arxiv.org/abs/2506.21683", "authors": ["Xihong Su", "Jia Lin Hau", "Gersi Doko", "Kishan Panaganti", "Marek Petrik"], "title": "Risk-Averse Total-Reward Reinforcement Learning", "categories": ["cs.LG"], "comment": "The paper is under review now", "summary": "Risk-averse total-reward Markov Decision Processes (MDPs) offer a promising\nframework for modeling and solving undiscounted infinite-horizon objectives.\nExisting model-based algorithms for risk measures like the entropic risk\nmeasure (ERM) and entropic value-at-risk (EVaR) are effective in small\nproblems, but require full access to transition probabilities. We propose a\nQ-learning algorithm to compute the optimal stationary policy for total-reward\nERM and EVaR objectives with strong convergence and performance guarantees. The\nalgorithm and its optimality are made possible by ERM's dynamic consistency and\nelicitability. Our numerical results on tabular domains demonstrate quick and\nreliable convergence of the proposed Q-learning algorithm to the optimal\nrisk-averse value function.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cdQ\u5b66\u4e60\u7b97\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\u5177\u6709\u5f3a\u6536\u655b\u6027\u548c\u6027\u80fd\u4fdd\u8bc1\u7684\u603b\u5956\u52b1ERM\u548cEVaR\u76ee\u6807\u7684\u6700\u4f18 stationary policy\u3002\u5728\u8868\u683c\u57df\u4e0a\u7684\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684Q\u5b66\u4e60\u7b97\u6cd5\u80fd\u591f\u5feb\u901f\u4e14\u53ef\u9760\u5730\u6536\u655b\u5230\u6700\u4f18\u7684\u98ce\u9669\u538c\u6076\u503c\u51fd\u6570\u3002", "motivation": "Risk-averse total-reward MDPs\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5e0c\u671b\u7684\u6846\u67b6\u6765\u5efa\u6a21\u548c\u89e3\u51b3\u672a\u6298\u6263\u7684\u65e0\u9650\u65f6\u95f4\u76ee\u6807\u95ee\u9898\u3002\u7136\u800c\u73b0\u6709\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u7b97\u6cd5\u5728\u5c0f\u89c4\u6a21\u95ee\u9898\u4e2d\u6709\u6548\uff0c\u4f46\u9700\u8981\u5b8c\u5168\u8bbf\u95ee\u8f6c\u79fb\u6982\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cdQ-learning\u7b97\u6cd5\uff0c\u7528\u4e8e\u8ba1\u7b97\u603b\u5956\u52b1ERM\u548cEVaR\u76ee\u6807\u7684\u6700\u4f18 stationary policy\u3002\u8be5\u7b97\u6cd5\u5229\u7528\u4e86ERM\u7684\u52a8\u6001\u4e00\u81f4\u6027\u548c\u53ef\u5f15\u51fa\u6027\u3002", "result": "\u5728\u8868\u683c\u57df\u4e0a\u7684\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684Q\u5b66\u4e60\u7b97\u6cd5\u80fd\u591f\u5feb\u901f\u4e14\u53ef\u9760\u5730\u6536\u655b\u5230\u6700\u4f18\u7684\u98ce\u9669\u538c\u6076\u503c\u51fd\u6570\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684Q\u5b66\u4e60\u7b97\u6cd5\u5177\u6709\u5f3a\u6536\u655b\u6027\u548c\u6027\u80fd\u4fdd\u8bc1\uff0c\u5e76\u80fd\u6210\u529f\u5e94\u7528\u4e8e\u603b\u5956\u52b1ERM\u548cEVaR\u76ee\u6807\u7684\u4f18\u5316\u95ee\u9898\u3002"}}
{"id": "2506.21734", "pdf": "https://arxiv.org/pdf/2506.21734", "abs": "https://arxiv.org/abs/2506.21734", "authors": ["Guan Wang", "Jin Li", "Yuhao Sun", "Xing Chen", "Changling Liu", "Yue Wu", "Meng Lu", "Sen Song", "Yasin Abbasi Yadkori"], "title": "Hierarchical Reasoning Model", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Reasoning, the process of devising and executing complex goal-oriented action\nsequences, remains a critical challenge in AI. Current large language models\n(LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from\nbrittle task decomposition, extensive data requirements, and high latency.\nInspired by the hierarchical and multi-timescale processing in the human brain,\nwe propose the Hierarchical Reasoning Model (HRM), a novel recurrent\narchitecture that attains significant computational depth while maintaining\nboth training stability and efficiency. HRM executes sequential reasoning tasks\nin a single forward pass without explicit supervision of the intermediate\nprocess, through two interdependent recurrent modules: a high-level module\nresponsible for slow, abstract planning, and a low-level module handling rapid,\ndetailed computations. With only 27 million parameters, HRM achieves\nexceptional performance on complex reasoning tasks using only 1000 training\nsamples. The model operates without pre-training or CoT data, yet achieves\nnearly perfect performance on challenging tasks including complex Sudoku\npuzzles and optimal path finding in large mazes. Furthermore, HRM outperforms\nmuch larger models with significantly longer context windows on the Abstraction\nand Reasoning Corpus (ARC), a key benchmark for measuring artificial general\nintelligence capabilities. These results underscore HRM's potential as a\ntransformative advancement toward universal computation and general-purpose\nreasoning systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9012\u5f52\u67b6\u6784\u2014\u2014\u5206\u5c42\u63a8\u7406\u6a21\u578b\uff08HRM\uff09\uff0c\u5b83\u901a\u8fc7\u4e24\u4e2a\u76f8\u4e92\u4f9d\u8d56\u7684\u9012\u5f52\u6a21\u5757\u6267\u884c\u987a\u5e8f\u63a8\u7406\u4efb\u52a1\uff0c\u4ec5\u75282700\u4e07\u53c2\u6570\u548c1000\u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u751a\u81f3\u8d85\u8fc7\u66f4\u5927\u89c4\u6a21\u7684\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u4f7f\u7528Chain-of-Thought\u6280\u672f\uff0c\u4f46\u8be5\u6280\u672f\u5b58\u5728\u4efb\u52a1\u5206\u89e3\u8106\u5f31\u3001\u6570\u636e\u9700\u6c42\u5927\u548c\u9ad8\u5ef6\u8fdf\u7684\u95ee\u9898\u3002\u53d7\u4eba\u7c7b\u5927\u8111\u5206\u5c42\u548c\u591a\u65f6\u95f4\u5c3a\u5ea6\u5904\u7406\u7684\u542f\u53d1\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5b9a\u548c\u9ad8\u6548\u7684\u63a8\u7406\u6a21\u578b\u3002", "method": "\u8bbe\u8ba1\u4e86\u5206\u5c42\u63a8\u7406\u6a21\u578b\uff08HRM\uff09\uff0c\u5305\u542b\u4e24\u4e2a\u76f8\u4e92\u4f9d\u8d56\u7684\u9012\u5f52\u6a21\u5757\uff1a\u9ad8\u5c42\u6a21\u5757\u8d1f\u8d23\u6162\u901f\u62bd\u8c61\u89c4\u5212\uff0c\u4f4e\u5c42\u6a21\u5757\u5904\u7406\u5feb\u901f\u8be6\u7ec6\u8ba1\u7b97\u3002HRM\u5728\u5355\u6b21\u524d\u5411\u4f20\u9012\u4e2d\u5b8c\u6210\u987a\u5e8f\u63a8\u7406\u4efb\u52a1\uff0c\u65e0\u9700\u4e2d\u95f4\u8fc7\u7a0b\u7684\u663e\u5f0f\u76d1\u7763\u3002", "result": "HRM\u4ec5\u75282700\u4e07\u53c2\u6570\u548c1000\u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u5982\u6570\u72ec\u548c\u8ff7\u5bab\u5bfb\u8def\u4e2d\u51e0\u4e4e\u8fbe\u5230\u5b8c\u7f8e\u8868\u73b0\uff0c\u5e76\u4e14\u5728ARC\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8d85\u8d8a\u5177\u6709\u66f4\u957f\u4e0a\u4e0b\u6587\u7a97\u53e3\u7684\u5927\u89c4\u6a21\u6a21\u578b\u3002", "conclusion": "HRM\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u901a\u5411\u901a\u7528\u8ba1\u7b97\u548c\u901a\u7528\u63a8\u7406\u7cfb\u7edf\u7684\u91cd\u8981\u8fdb\u6b65\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.22204", "pdf": "https://arxiv.org/pdf/2506.22204", "abs": "https://arxiv.org/abs/2506.22204", "authors": ["Gurjeet Sangra Singh", "Maciej Falkiewicz", "Alexandros Kalousis"], "title": "Hybrid Generative Modeling for Incomplete Physics: Deep Grey-Box Meets Optimal Transport", "categories": ["stat.ML", "cs.LG"], "comment": "Workshop paper at ICLR 2025 (XAI4Science Workshop)", "summary": "Physics phenomena are often described by ordinary and/or partial differential\nequations (ODEs/PDEs), and solved analytically or numerically. Unfortunately,\nmany real-world systems are described only approximately with missing or\nunknown terms in the equations. This makes the distribution of the physics\nmodel differ from the true data-generating process (DGP). Using limited and\nunpaired data between DGP observations and the imperfect model simulations, we\ninvestigate this particular setting by completing the known-physics model,\ncombining theory-driven models and data-driven to describe the shifted\ndistribution involved in the DGP. We present a novel hybrid generative model\napproach combining deep grey-box modelling with Optimal Transport (OT) methods\nto enhance incomplete physics models. Our method implements OT maps in data\nspace while maintaining minimal source distribution distortion, demonstrating\nsuperior performance in resolving the unpaired problem and ensuring correct\nusage of physics parameters. Unlike black-box alternatives, our approach\nleverages physics-based inductive biases to accurately learn system dynamics\nwhile preserving interpretability through its domain knowledge foundation.\nExperimental results validate our method's effectiveness in both generation\ntasks and model transparency, offering detailed insights into learned physics\ndynamics.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df1\u5ea6\u7070\u8272\u5efa\u6a21\u4e0e\u6700\u4f18\u4f20\u8f93\uff08OT\uff09\u65b9\u6cd5\u7684\u6df7\u5408\u751f\u6210\u6a21\u578b\uff0c\u4ee5\u589e\u5f3a\u4e0d\u5b8c\u6574\u7684\u7269\u7406\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u5728\u89e3\u51b3\u975e\u914d\u5bf9\u95ee\u9898\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u7269\u7406\u7684\u5f52\u7eb3\u504f\u5dee\u51c6\u786e\u5b66\u4e60\u7cfb\u7edf\u52a8\u529b\u5b66\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u751f\u6210\u4efb\u52a1\u548c\u6a21\u578b\u900f\u660e\u5ea6\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "motivation": "\u8bb8\u591a\u73b0\u5b9e\u4e16\u754c\u7cfb\u7edf\u53ea\u80fd\u7528\u8fd1\u4f3c\u63cf\u8ff0\uff0c\u5176\u5fae\u5206\u65b9\u7a0b\u4e2d\u5b58\u5728\u7f3a\u5931\u6216\u672a\u77e5\u9879\uff0c\u5bfc\u81f4\u7269\u7406\u6a21\u578b\u5206\u5e03\u4e0e\u771f\u5b9e\u6570\u636e\u751f\u6210\u8fc7\u7a0b\uff08DGP\uff09\u4e0d\u540c\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u6709\u9650\u4e14\u975e\u914d\u5bf9\u7684\u6570\u636e\uff0c\u7ed3\u5408\u7406\u8bba\u9a71\u52a8\u548c\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u6765\u5b8c\u5584\u5df2\u77e5\u7269\u7406\u6a21\u578b\uff0c\u63cf\u8ff0DGP\u4e2d\u7684\u504f\u79fb\u5206\u5e03\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u6df7\u5408\u751f\u6210\u6a21\u578b\uff0c\u5c06\u6df1\u5ea6\u7070\u8272\u5efa\u6a21\u4e0e\u6700\u4f18\u4f20\u8f93\uff08OT\uff09\u65b9\u6cd5\u76f8\u7ed3\u5408\u3002\u8be5\u65b9\u6cd5\u5728\u6570\u636e\u7a7a\u95f4\u4e2d\u5b9e\u73b0OT\u6620\u5c04\uff0c\u540c\u65f6\u5c3d\u91cf\u51cf\u5c11\u6e90\u5206\u5e03\u5931\u771f\uff0c\u786e\u4fdd\u6b63\u786e\u4f7f\u7528\u7269\u7406\u53c2\u6570\u3002\u5229\u7528\u7269\u7406\u57fa\u7840\u7684\u5f52\u7eb3\u504f\u5dee\uff0c\u51c6\u786e\u5b66\u4e60\u7cfb\u7edf\u52a8\u529b\u5b66\u5e76\u4fdd\u6301\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u751f\u6210\u4efb\u52a1\u548c\u6a21\u578b\u900f\u660e\u5ea6\u65b9\u9762\u8868\u73b0\u6709\u6548\uff0c\u80fd\u591f\u63d0\u4f9b\u5173\u4e8e\u5b66\u4e60\u5230\u7684\u7269\u7406\u52a8\u529b\u5b66\u7684\u8be6\u7ec6\u89c1\u89e3\u3002\u89e3\u51b3\u4e86\u975e\u914d\u5bf9\u95ee\u9898\uff0c\u5e76\u51c6\u786e\u6355\u6349\u4e86\u7cfb\u7edf\u52a8\u529b\u5b66\u3002", "conclusion": "\u7ed3\u5408\u6df1\u5ea6\u7070\u8272\u5efa\u6a21\u4e0e\u6700\u4f18\u4f20\u8f93\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u589e\u5f3a\u4e0d\u5b8c\u6574\u7684\u7269\u7406\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u53ef\u89e3\u91ca\u6027\u3002\u6b64\u65b9\u6cd5\u9002\u7528\u4e8e\u89e3\u51b3\u975e\u914d\u5bf9\u6570\u636e\u95ee\u9898\uff0c\u5e76\u80fd\u51c6\u786e\u5b66\u4e60\u590d\u6742\u7cfb\u7edf\u7684\u52a8\u529b\u5b66\u884c\u4e3a\u3002"}}
{"id": "2506.21695", "pdf": "https://arxiv.org/pdf/2506.21695", "abs": "https://arxiv.org/abs/2506.21695", "authors": ["Oron Nir", "Jay Tenenbaum", "Ariel Shamir"], "title": "Unimodal Strategies in Density-Based Clustering", "categories": ["cs.LG"], "comment": null, "summary": "Density-based clustering methods often surpass centroid-based counterparts,\nwhen addressing data with noise or arbitrary data distributions common in\nreal-world problems. In this study, we reveal a key property intrinsic to\ndensity-based clustering methods regarding the relation between the number of\nclusters and the neighborhood radius of core points - we empirically show that\nit is nearly unimodal, and support this claim theoretically in a specific\nsetting. We leverage this property to devise new strategies for finding\nappropriate values for the radius more efficiently based on the Ternary Search\nalgorithm. This is especially important for large scale data that is\nhigh-dimensional, where parameter tuning is computationally intensive. We\nvalidate our methodology through extensive applications across a range of\nhigh-dimensional, large-scale NLP, Audio, and Computer Vision tasks,\ndemonstrating its practical effectiveness and robustness. This work not only\noffers a significant advancement in parameter control for density-based\nclustering but also broadens the understanding regarding the relations between\ntheir guiding parameters. Our code is available at\nhttps://github.com/oronnir/UnimodalStrategies.", "AI": {"tldr": "\u5bc6\u5ea6\u805a\u7c7b\u65b9\u6cd5\u5728\u5904\u7406\u5e26\u566a\u58f0\u6216\u4efb\u610f\u6570\u636e\u5206\u5e03\u65f6\u901a\u5e38\u4f18\u4e8e\u57fa\u4e8e\u8d28\u5fc3\u7684\u805a\u7c7b\u65b9\u6cd5\u3002\u672c\u6587\u63ed\u793a\u4e86\u5bc6\u5ea6\u805a\u7c7b\u4e2d\u805a\u7c7b\u6570\u4e0e\u6838\u5fc3\u70b9\u90bb\u57df\u534a\u5f84\u95f4\u7684\u5173\u952e\u7279\u6027\uff0c\u5e76\u901a\u8fc7\u4e09\u5143\u641c\u7d22\u7b97\u6cd5\u63d0\u51fa\u66f4\u9ad8\u6548\u7684\u534a\u5f84\u9009\u62e9\u7b56\u7565\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u9ad8\u7ef4\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5bc6\u5ea6\u805a\u7c7b\u65b9\u6cd5\u5728\u5904\u7406\u5e26\u566a\u58f0\u6216\u4efb\u610f\u5206\u5e03\u7684\u6570\u636e\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u53c2\u6570\u8c03\u4f18\uff08\u5982\u90bb\u57df\u534a\u5f84\uff09\u5728\u9ad8\u7ef4\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u8ba1\u7b97\u4ee3\u4ef7\u9ad8\u6602\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u53d1\u73b0\u6838\u5fc3\u70b9\u90bb\u57df\u534a\u5f84\u548c\u805a\u7c7b\u6570\u4e4b\u95f4\u7684\u5173\u7cfb\u8fd1\u4f3c\u5355\u5cf0\u6027\uff0c\u5e76\u57fa\u4e8e\u6b64\u7279\u6027\u7ed3\u5408\u4e09\u5143\u641c\u7d22\u7b97\u6cd5\u63d0\u51fa\u65b0\u7b56\u7565\u4ee5\u66f4\u9ad8\u6548\u5730\u5bfb\u627e\u5408\u9002\u7684\u534a\u5f84\u503c\u3002", "result": "\u901a\u8fc7\u5728\u9ad8\u7ef4\u3001\u5927\u89c4\u6a21\u7684NLP\u3001\u97f3\u9891\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u4e0d\u4ec5\u4e3a\u5bc6\u5ea6\u805a\u7c7b\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u53c2\u6570\u63a7\u5236\u6539\u8fdb\uff0c\u8fd8\u52a0\u6df1\u4e86\u5bf9\u5bc6\u5ea6\u805a\u7c7b\u53c2\u6570\u95f4\u5173\u7cfb\u7684\u7406\u89e3\u3002"}}
{"id": "2506.21763", "pdf": "https://arxiv.org/pdf/2506.21763", "abs": "https://arxiv.org/abs/2506.21763", "authors": ["Xin Wang", "Jiyao Liu", "Yulong Xiao", "Junzhi Ning", "Lihao Liu", "Junjun He", "Botian Shi", "Kaicheng Yu"], "title": "THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?", "categories": ["cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are accelerating scientific idea generation, but\nrigorously evaluating these numerous, often superficial, AI-generated\npropositions for novelty and factual accuracy is a critical bottleneck; manual\nverification is too slow.Existing validation methods are inadequate: LLMs as\nstandalone verifiers may hallucinate and lack domain knowledge (our findings\nshow ~60\\% unawareness of relevant papers in specific domains), while\ntraditional citation networks lack explicit causality and narrative surveys are\nunstructured.This underscores a core challenge: the absence of structured,\nverifiable, and causally-linked historical data of scientific evolution.To\naddress this,we introduce \\textbf{THE-Tree} (\\textbf{T}echnology\n\\textbf{H}istory \\textbf{E}volution Tree), a computational framework that\nconstructs such domain-specific evolution trees from scientific\nliterature.THE-Tree employs a search algorithm to explore evolutionary paths.\nDuring its node expansion, it utilizes a novel \"Think-Verbalize-Cite-Verify\"\nprocess: an LLM proposes potential advancements and cites supporting\nliterature. Critically, each proposed evolutionary link is then validated for\nlogical coherence and evidential support by a recovered natural language\ninference mechanism that interrogates the cited literature, ensuring that each\nstep is grounded.We construct and validate 88 THE-Trees across diverse domains\nand release a benchmark dataset including up to 71k fact verifications covering\n27k papers to foster further research.Experiments demonstrate that i) in graph\ncompletion, our THE-Tree improves hit@1 by 8\\% to 14\\% across multiple models\ncompared to traditional citation networks; ii) for predicting future scientific\ndevelopments, it improves hit@1 metric by nearly 10\\%; and iii) when combined\nwith other methods, it boosts the performance of evaluating important\nscientific papers by almost 100\\%.", "AI": {"tldr": "\u63d0\u51faTHE-Tree\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u9886\u57df\u7279\u5b9a\u7684\u79d1\u6280\u6f14\u5316\u6811\uff0c\u89e3\u51b3\u4e86\u79d1\u5b66\u521b\u610f\u751f\u6210\u4e2d\u5173\u4e8e\u65b0\u9896\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u7684\u8bc4\u4f30\u95ee\u9898\u3002\u8be5\u6846\u67b6\u4f7f\u7528\u72ec\u7279\u7684\u9a8c\u8bc1\u8fc7\u7a0b\u786e\u4fdd\u6bcf\u4e00\u6b65\u90fd\u6709\u6839\u636e\uff0c\u5e76\u5728\u591a\u4e2a\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u79d1\u5b66\u9884\u6d4b\u548c\u91cd\u8981\u8bba\u6587\u8bc4\u4f30\u7684\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u52a0\u901f\u4e86\u79d1\u5b66\u521b\u610f\u7684\u751f\u6210\uff0c\u4f46\u5bf9\u8fd9\u4e9b\u521b\u610f\u8fdb\u884c\u4e25\u8c28\u7684\u65b0\u9896\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u8bc4\u4f30\u5374\u6210\u4e3a\u74f6\u9888\u3002\u73b0\u6709\u7684\u9a8c\u8bc1\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff1aLLMs\u53ef\u80fd\u4ea7\u751f\u5e7b\u89c9\u4e14\u7f3a\u4e4f\u9886\u57df\u77e5\u8bc6\uff0c\u800c\u4f20\u7edf\u5f15\u7528\u7f51\u7edc\u7f3a\u4e4f\u660e\u786e\u7684\u56e0\u679c\u5173\u7cfb\uff0c\u53d9\u8ff0\u6027\u7efc\u8ff0\u5219\u65e0\u7ed3\u6784\u53ef\u8a00\u3002", "method": "\u5f15\u5165THE-Tree\uff08\u6280\u672f\u5386\u53f2\u6f14\u5316\u6811\uff09\uff0c\u4e00\u79cd\u8ba1\u7b97\u6846\u67b6\uff0c\u4ece\u79d1\u5b66\u6587\u732e\u4e2d\u6784\u5efa\u9886\u57df\u7279\u5b9a\u7684\u6f14\u5316\u6811\u3002\u4f7f\u7528\u641c\u7d22\u7b97\u6cd5\u63a2\u7d22\u6f14\u5316\u8def\u5f84\uff0c\u5728\u8282\u70b9\u6269\u5c55\u65f6\u91c7\u7528\u201cThink-Verbalize-Cite-Verify\u201d\u8fc7\u7a0b\uff0cLLM\u63d0\u51fa\u6f5c\u5728\u8fdb\u5c55\u5e76\u5f15\u7528\u652f\u6301\u6587\u732e\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u673a\u5236\u9a8c\u8bc1\u6bcf\u4e2a\u63d0\u8bae\u7684\u6f14\u5316\u94fe\u63a5\u3002", "result": "\u6784\u5efa\u5e76\u9a8c\u8bc1\u4e8688\u4e2aTHE-Tree\uff0c\u6db5\u76d6\u591a\u4e2a\u9886\u57df\uff0c\u53d1\u5e03\u4e86\u4e00\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u3002\u5b9e\u9a8c\u8868\u660e\uff1a1\uff09\u5728\u56fe\u8865\u5168\u4efb\u52a1\u4e2d\uff0c\u76f8\u6bd4\u4f20\u7edf\u5f15\u7528\u7f51\u7edc\uff0cTHE-Tree\u4f7f\u591a\u4e2a\u6a21\u578b\u7684hit@1\u63d0\u9ad88%\u523014%\uff1b2\uff09\u9884\u6d4b\u672a\u6765\u79d1\u5b66\u53d1\u5c55\u65f6\uff0chit@1\u6307\u6807\u63d0\u9ad8\u8fd110%\uff1b3\uff09\u4e0e\u5176\u4ed6\u65b9\u6cd5\u7ed3\u5408\u65f6\uff0c\u8bc4\u4f30\u91cd\u8981\u79d1\u5b66\u8bba\u6587\u7684\u6027\u80fd\u51e0\u4e4e\u63d0\u5347100%\u3002", "conclusion": "THE-Tree\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u79d1\u5b66\u521b\u610f\u8bc4\u4f30\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5373\u7f3a\u4e4f\u7ed3\u6784\u5316\u3001\u53ef\u9a8c\u8bc1\u548c\u56e0\u679c\u5173\u8054\u7684\u79d1\u5b66\u6f14\u5316\u5386\u53f2\u6570\u636e\uff0c\u5176\u5e94\u7528\u53ef\u663e\u8457\u63d0\u5347\u76f8\u5173\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2506.22228", "pdf": "https://arxiv.org/pdf/2506.22228", "abs": "https://arxiv.org/abs/2506.22228", "authors": ["Rong Ma", "Xi Li", "Jingyuan Hu", "Bin Yu"], "title": "Uncovering smooth structures in single-cell data with PCS-guided neighbor embeddings", "categories": ["stat.ML", "cs.LG", "q-bio.GN", "stat.AP"], "comment": null, "summary": "Single-cell sequencing is revolutionizing biology by enabling detailed\ninvestigations of cell-state transitions. Many biological processes unfold\nalong continuous trajectories, yet it remains challenging to extract smooth,\nlow-dimensional representations from inherently noisy, high-dimensional\nsingle-cell data. Neighbor embedding (NE) algorithms, such as t-SNE and UMAP,\nare widely used to embed high-dimensional single-cell data into low dimensions.\nBut they often introduce undesirable distortions, resulting in misleading\ninterpretations. Existing evaluation methods for NE algorithms primarily focus\non separating discrete cell types rather than capturing continuous cell-state\ntransitions, while dynamic modeling approaches rely on strong assumptions about\ncellular processes and specialized data. To address these challenges, we build\non the Predictability-Computability-Stability (PCS) framework for reliable and\nreproducible data-driven discoveries. First, we systematically evaluate popular\nNE algorithms through empirical analysis, simulation, and theory, and reveal\ntheir key shortcomings, such as artifacts and instability. We then introduce\nNESS, a principled and interpretable machine learning approach to improve NE\nrepresentations by leveraging algorithmic stability and to enable robust\ninference of smooth biological structures. NESS offers useful concepts,\nquantitative stability metrics, and efficient computational workflows to\nuncover developmental trajectories and cell-state transitions in single-cell\ndata. Finally, we apply NESS to six single-cell datasets, spanning pluripotent\nstem cell differentiation, organoid development, and multiple tissue-specific\nlineage trajectories. Across these diverse contexts, NESS consistently yields\nuseful biological insights, such as identification of transitional and stable\ncell states and quantification of transcriptional dynamics during development.", "AI": {"tldr": "This paper addresses the challenge of extracting smooth, low-dimensional representations from noisy single-cell data by introducing NESS, an approach that improves NE representations for robust inference of biological structures. It evaluates popular NE algorithms and demonstrates NESS's effectiveness across multiple datasets.", "motivation": "Single-cell sequencing enables detailed investigations of cell-state transitions but it's challenging to extract smooth, low-dimensional representations from noisy, high-dimensional data. Existing NE algorithms introduce distortions and existing evaluation methods focus on separating discrete cell types rather than capturing continuous transitions.", "method": "The authors systematically evaluate popular NE algorithms through empirical analysis, simulation, and theory. They then introduce NESS, a machine learning approach to improve NE representations by leveraging algorithmic stability for robust inference of smooth biological structures.", "result": "NESS offers useful concepts, quantitative stability metrics, and efficient computational workflows to uncover developmental trajectories and cell-state transitions in single-cell data. When applied to six single-cell datasets, NESS consistently provides useful biological insights.", "conclusion": "NESS consistently yields useful biological insights across diverse single-cell datasets, such as identification of transitional and stable cell states and quantification of transcriptional dynamics during development."}}
{"id": "2506.21714", "pdf": "https://arxiv.org/pdf/2506.21714", "abs": "https://arxiv.org/abs/2506.21714", "authors": ["Denis Gudovskiy", "Wenzhao Zheng", "Tomoyuki Okuno", "Yohei Nakata", "Kurt Keutzer"], "title": "$\\textrm{ODE}_t \\left(\\textrm{ODE}_l \\right)$: Shortcutting the Time and Length in Diffusion and Flow Models for Faster Sampling", "categories": ["cs.LG", "cs.CV"], "comment": "Preprint. Github page: github.com/gudovskiy/odelt", "summary": "Recently, continuous normalizing flows (CNFs) and diffusion models (DMs) have\nbeen studied using the unified theoretical framework. Although such models can\ngenerate high-quality data points from a noise distribution, the sampling\ndemands multiple iterations to solve an ordinary differential equation (ODE)\nwith high computational complexity. Most existing methods focus on reducing the\nnumber of time steps during the sampling process to improve efficiency. In this\nwork, we explore a complementary direction in which the quality-complexity\ntradeoff can be dynamically controlled in terms of time steps and in the length\nof the neural network. We achieve this by rewiring the blocks in the\ntransformer-based architecture to solve an inner discretized ODE w.r.t. its\nlength. Then, we employ time- and length-wise consistency terms during flow\nmatching training, and as a result, the sampling can be performed with an\narbitrary number of time steps and transformer blocks. Unlike others, our\n$\\textrm{ODE}_t \\left(\\textrm{ODE}_l \\right)$ approach is solver-agnostic in\ntime dimension and decreases both latency and memory usage. Compared to the\nprevious state of the art, image generation experiments on CelebA-HQ and\nImageNet show a latency reduction of up to $3\\times$ in the most efficient\nsampling mode, and a FID score improvement of up to $3.5$ points for\nhigh-quality sampling. We release our code and model weights with fully\nreproducible experiments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cd\u8fdeTransformer\u67b6\u6784\u4e2d\u7684\u5757\u6765\u89e3\u51b3\u5185\u90e8\u79bb\u6563\u5316ODE\uff0c\u540c\u65f6\u5728\u6d41\u5339\u914d\u8bad\u7ec3\u4e2d\u4f7f\u7528\u65f6\u95f4\u548c\u957f\u5ea6\u4e00\u81f4\u6027\u9879\uff0c\u4ece\u800c\u5b9e\u73b0\u52a8\u6001\u63a7\u5236\u8d28\u91cf-\u590d\u6742\u5ea6\u6743\u8861\u3002\u8be5\u65b9\u6cd5\u51cf\u5c11\u4e86\u5ef6\u8fdf\u548c\u5185\u5b58\u4f7f\u7528\uff0c\u5e76\u5728\u56fe\u50cf\u751f\u6210\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u9ad8\u8fbe3\u500d\u7684\u5ef6\u8fdf\u964d\u4f4e\u548c\u6700\u591a3.5\u70b9FID\u5206\u6570\u7684\u6539\u8fdb\u3002", "motivation": "\u8fde\u7eed\u6807\u51c6\u5316\u6d41(CNFs)\u548c\u6269\u6563\u6a21\u578b(DMs)\u53ef\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u70b9\uff0c\u4f46\u91c7\u6837\u8fc7\u7a0b\u9700\u8981\u591a\u6b21\u8fed\u4ee3\u6c42\u89e3\u5e38\u5fae\u5206\u65b9\u7a0b(ODE)\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3002\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u51cf\u5c11\u91c7\u6837\u8fc7\u7a0b\u4e2d\u7684\u65f6\u95f4\u6b65\u6570\u4ee5\u63d0\u9ad8\u6548\u7387\uff0c\u672c\u6587\u63a2\u7d22\u4e86\u53e6\u4e00\u79cd\u65b9\u5411\uff0c\u5373\u901a\u8fc7\u52a8\u6001\u63a7\u5236\u65f6\u95f4\u6b65\u957f\u548c\u795e\u7ecf\u7f51\u7edc\u957f\u5ea6\u6765\u5e73\u8861\u8d28\u91cf\u548c\u590d\u6742\u5ea6\u3002", "method": "\u901a\u8fc7\u91cd\u8fdeTransformer\u67b6\u6784\u4e2d\u7684\u5757\u6765\u6c42\u89e3\u4e0e\u957f\u5ea6\u76f8\u5173\u7684\u5185\u90e8\u79bb\u6563\u5316ODE\u3002\u5728\u6d41\u5339\u914d\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5f15\u5165\u65f6\u95f4\u548c\u957f\u5ea6\u4e00\u81f4\u6027\u9879\uff0c\u4f7f\u5f97\u91c7\u6837\u53ef\u4ee5\u5728\u4efb\u610f\u6570\u91cf\u7684\u65f6\u95f4\u6b65\u957f\u548cTransformer\u5757\u4e0a\u6267\u884c\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u4e0e\u6c42\u89e3\u5668\u65e0\u5173\uff0c\u80fd\u591f\u540c\u65f6\u51cf\u5c11\u5ef6\u8fdf\u548c\u5185\u5b58\u4f7f\u7528\u3002", "result": "\u5728CelebA-HQ\u548cImageNet\u4e0a\u7684\u56fe\u50cf\u751f\u6210\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u6700\u9ad8\u6548\u7684\u91c7\u6837\u6a21\u5f0f\u4e0b\uff0c\u5ef6\u8fdf\u6700\u591a\u53ef\u51cf\u5c113\u500d\uff0c\u9ad8\u8d28\u91cf\u91c7\u6837\u65f6FID\u5206\u6570\u6700\u591a\u53ef\u63d0\u9ad83.5\u70b9\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u663e\u8457\u63d0\u9ad8\u4e86\u91c7\u6837\u6548\u7387\uff0c\u8fd8\u6539\u5584\u4e86\u751f\u6210\u6570\u636e\u7684\u8d28\u91cf\u3002\u901a\u8fc7\u5f00\u6e90\u4ee3\u7801\u548c\u6a21\u578b\u6743\u91cd\uff0c\u786e\u4fdd\u5b9e\u9a8c\u7ed3\u679c\u5b8c\u5168\u53ef\u590d\u73b0\u3002"}}
{"id": "2506.21784", "pdf": "https://arxiv.org/pdf/2506.21784", "abs": "https://arxiv.org/abs/2506.21784", "authors": ["Yifan Liu", "Xishun Liao", "Haoxuan Ma", "Jonathan Liu", "Rohan Jadhav", "Jiaqi Ma"], "title": "MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Understanding and modeling human mobility patterns is crucial for effective\ntransportation planning and urban development. Despite significant advances in\nmobility research, there remains a critical gap in simulation platforms that\nallow for algorithm development, policy implementation, and comprehensive\nevaluation at scale. Traditional activity-based models require extensive data\ncollection and manual calibration, machine learning approaches struggle with\nadaptation to dynamic conditions, and treding agent-based Large Language Models\n(LLMs) implementations face computational constraints with large-scale\nsimulations. To address these challenges, we propose MobiVerse, a hybrid\nframework leverages the efficiency of lightweight domain-specific generator for\ngenerating base activity chains with the adaptability of LLMs for context-aware\nmodifications. A case study was conducted in Westwood, Los Angeles, where we\nefficiently generated and dynamically adjusted schedules for the whole\npopulation of approximately 53,000 agents on a standard PC. Our experiments\ndemonstrate that MobiVerse successfully enables agents to respond to\nenvironmental feedback, including road closures, large gathering events like\nfootball games, and congestion, through our hybrid framework. Its modular\ndesign facilitates testing various mobility algorithms at both transportation\nsystem and agent levels. Results show our approach maintains computational\nefficiency while enhancing behavioral realism. MobiVerse bridges the gap in\nmobility simulation by providing a customizable platform for mobility systems\nplanning and operations with benchmark algorithms. Code and videos are\navailable at https://github.com/ucla-mobility/MobiVerse.", "AI": {"tldr": "MobiVerse\u662f\u4e00\u4e2a\u6df7\u5408\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u8f7b\u91cf\u7ea7\u9886\u57df\u7279\u5b9a\u751f\u6210\u5668\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u7528\u4e8e\u751f\u6210\u57fa\u7840\u6d3b\u52a8\u94fe\u5e76\u6839\u636e\u4e0a\u4e0b\u6587\u8fdb\u884c\u4fee\u6539\u3002\u8be5\u6846\u67b6\u5728\u6d1b\u6749\u77f6Westwood\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\u6210\u529f\u6a21\u62df\u4e86\u7ea653,000\u4e2a\u4ee3\u7406\u7684\u65e5\u7a0b\u5b89\u6392\uff0c\u5e76\u80fd\u5e94\u5bf9\u73af\u5883\u53cd\u9988\u5982\u9053\u8def\u5c01\u95ed\u3001\u5927\u578b\u805a\u4f1a\u4e8b\u4ef6\u548c\u62e5\u5835\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMobiVerse\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u589e\u5f3a\u4e86\u884c\u4e3a\u73b0\u5b9e\u4e3b\u4e49\uff0c\u4e3a\u79fb\u52a8\u7cfb\u7edf\u89c4\u5212\u548c\u64cd\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u5b9a\u5236\u5e73\u53f0\u3002", "motivation": "\u7406\u89e3\u548c\u5efa\u6a21\u4eba\u7c7b\u79fb\u52a8\u6a21\u5f0f\u5bf9\u4e8e\u6709\u6548\u7684\u4ea4\u901a\u89c4\u5212\u548c\u57ce\u5e02\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5f53\u524d\u7684\u79fb\u52a8\u7814\u7a76\u5b58\u5728\u4e00\u4e2a\u5173\u952e\u5dee\u8ddd\uff0c\u5373\u7f3a\u4e4f\u5141\u8bb8\u5927\u89c4\u6a21\u7b97\u6cd5\u5f00\u53d1\u3001\u653f\u7b56\u5b9e\u65bd\u548c\u5168\u9762\u8bc4\u4f30\u7684\u4eff\u771f\u5e73\u53f0\u3002\u4f20\u7edf\u7684\u65b9\u6cd5\u8981\u4e48\u9700\u8981\u5927\u91cf\u6570\u636e\u6536\u96c6\u548c\u624b\u52a8\u6821\u51c6\uff0c\u8981\u4e48\u5728\u9002\u5e94\u52a8\u6001\u6761\u4ef6\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u6216\u8005\u5728\u5927\u89c4\u6a21\u4eff\u771f\u65f6\u9762\u4e34\u8ba1\u7b97\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86MobiVerse\uff0c\u8fd9\u662f\u4e00\u4e2a\u6df7\u5408\u6846\u67b6\uff0c\u5229\u7528\u8f7b\u91cf\u7ea7\u9886\u57df\u7279\u5b9a\u751f\u6210\u5668\u751f\u6210\u57fa\u7840\u6d3b\u52a8\u94fe\uff0c\u5e76\u901a\u8fc7LLMs\u8fdb\u884c\u4e0a\u4e0b\u6587\u611f\u77e5\u4fee\u6539\u3002\u8be5\u6846\u67b6\u5177\u6709\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u5728\u4ea4\u901a\u7cfb\u7edf\u548c\u4ee3\u7406\u7ea7\u522b\u6d4b\u8bd5\u5404\u79cd\u79fb\u52a8\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cMobiVerse\u4f7f\u4ee3\u7406\u80fd\u591f\u5bf9\u73af\u5883\u53cd\u9988\u505a\u51fa\u53cd\u5e94\uff0c\u5305\u62ec\u9053\u8def\u5c01\u95ed\u3001\u5927\u578b\u96c6\u4f1a\u4e8b\u4ef6\u548c\u62e5\u5835\u7b49\u3002\u5176\u6a21\u5757\u5316\u8bbe\u8ba1\u4fc3\u8fdb\u4e86\u4e0d\u540c\u79fb\u52a8\u7b97\u6cd5\u7684\u6d4b\u8bd5\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u589e\u5f3a\u4e86\u884c\u4e3a\u73b0\u5b9e\u4e3b\u4e49\u3002", "conclusion": "MobiVerse\u901a\u8fc7\u63d0\u4f9b\u4e00\u4e2a\u53ef\u5b9a\u5236\u7684\u5e73\u53f0\uff0c\u5f25\u8865\u4e86\u79fb\u52a8\u4eff\u771f\u4e2d\u7684\u7a7a\u767d\uff0c\u9002\u7528\u4e8e\u79fb\u52a8\u7cfb\u7edf\u89c4\u5212\u548c\u64cd\u4f5c\uff0c\u5e76\u5e26\u6709\u57fa\u51c6\u7b97\u6cd5\u3002"}}
{"id": "2506.22343", "pdf": "https://arxiv.org/pdf/2506.22343", "abs": "https://arxiv.org/abs/2506.22343", "authors": ["Xiang Li", "Garrett Wen", "Weiqing He", "Jiayuan Wu", "Qi Long", "Weijie J. Su"], "title": "Optimal Estimation of Watermark Proportions in Hybrid AI-Human Texts", "categories": ["stat.ML", "cs.CL", "cs.LG", "stat.ME"], "comment": null, "summary": "Text watermarks in large language models (LLMs) are an increasingly important\ntool for detecting synthetic text and distinguishing human-written content from\nLLM-generated text. While most existing studies focus on determining whether\nentire texts are watermarked, many real-world scenarios involve mixed-source\ntexts, which blend human-written and watermarked content. In this paper, we\naddress the problem of optimally estimating the watermark proportion in\nmixed-source texts. We cast this problem as estimating the proportion parameter\nin a mixture model based on \\emph{pivotal statistics}. First, we show that this\nparameter is not even identifiable in certain watermarking schemes, let alone\nconsistently estimable. In stark contrast, for watermarking methods that employ\ncontinuous pivotal statistics for detection, we demonstrate that the proportion\nparameter is identifiable under mild conditions. We propose efficient\nestimators for this class of methods, which include several popular unbiased\nwatermarks as examples, and derive minimax lower bounds for any measurable\nestimator based on pivotal statistics, showing that our estimators achieve\nthese lower bounds. Through evaluations on both synthetic data and mixed-source\ntext generated by open-source models, we demonstrate that our proposed\nestimators consistently achieve high estimation accuracy.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u6df7\u5408\u6765\u6e90\u6587\u672c\u4e2d\u4f30\u8ba1\u6c34\u5370\u6bd4\u4f8b\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5173\u952e\u7edf\u8ba1\u91cf\u7684\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u8bc6\u522b\u4e14\u8fbe\u5230\u6700\u4f18\u4e0b\u754c\u3002", "motivation": "\u73b0\u6709\u7684\u7814\u7a76\u591a\u5173\u6ce8\u4e8e\u68c0\u6d4b\u6574\u4e2a\u6587\u672c\u662f\u5426\u5305\u542b\u6c34\u5370\uff0c\u4f46\u5728\u8bb8\u591a\u73b0\u5b9e\u573a\u666f\u4e2d\uff0c\u6587\u672c\u53ef\u80fd\u7531\u4eba\u5de5\u64b0\u5199\u5185\u5bb9\u548c\u5e26\u6c34\u5370\u7684\u5185\u5bb9\u6df7\u5408\u800c\u6210\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u51c6\u786e\u4f30\u8ba1\u6df7\u5408\u6587\u672c\u4e2d\u7684\u6c34\u5370\u6bd4\u4f8b\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u57fa\u4e8e\u5173\u952e\u7edf\u8ba1\u91cf\u7684\u6df7\u5408\u6a21\u578b\u53c2\u6570\u4f30\u8ba1\u95ee\u9898\u3002\u5bf9\u4e8e\u4f7f\u7528\u8fde\u7eed\u5173\u952e\u7edf\u8ba1\u91cf\u7684\u6c34\u5370\u65b9\u6cd5\uff0c\u5728\u6e29\u548c\u6761\u4ef6\u4e0b\u8bc1\u660e\u4e86\u6bd4\u4f8b\u53c2\u6570\u7684\u53ef\u8bc6\u522b\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u6709\u6548\u7684\u4f30\u8ba1\u5668\u3002\u540c\u65f6\u63a8\u5bfc\u4e86\u4efb\u4f55\u57fa\u4e8e\u5173\u952e\u7edf\u8ba1\u91cf\u7684\u53ef\u6d4b\u91cf\u4f30\u8ba1\u5668\u7684\u6781\u5c0f\u6781\u5927\u4e0b\u754c\u3002", "result": "\u901a\u8fc7\u5728\u5408\u6210\u6570\u636e\u548c\u5f00\u6e90\u6a21\u578b\u751f\u6210\u7684\u6df7\u5408\u6765\u6e90\u6587\u672c\u4e0a\u7684\u8bc4\u4f30\uff0c\u8bc1\u660e\u6240\u63d0\u51fa\u7684\u4f30\u8ba1\u5668\u80fd\u591f\u6301\u7eed\u8fbe\u5230\u9ad8\u4f30\u8ba1\u7cbe\u5ea6\u3002", "conclusion": "\u5728\u7279\u5b9a\u6c34\u5370\u65b9\u6848\u4e0b\uff0c\u6bd4\u4f8b\u53c2\u6570\u662f\u53ef\u8bc6\u522b\u7684\uff0c\u5e76\u4e14\u6240\u63d0\u51fa\u7684\u4f30\u8ba1\u5668\u8fbe\u5230\u4e86\u7406\u8bba\u6700\u4f18\u4e0b\u754c\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6df7\u5408\u6765\u6e90\u6587\u672c\u5206\u6790\u3002"}}
{"id": "2506.21718", "pdf": "https://arxiv.org/pdf/2506.21718", "abs": "https://arxiv.org/abs/2506.21718", "authors": ["Yash Akhauri", "Bryan Lewandowski", "Cheng-Hsi Lin", "Adrian N. Reyes", "Grant C. Forbes", "Arissa Wongpanich", "Bangding Yang", "Mohamed S. Abdelfattah", "Sagi Perel", "Xingyou Song"], "title": "Performance Prediction for Large Systems via Text-to-Text Regression", "categories": ["cs.LG", "cs.AI", "cs.PF", "cs.SE", "cs.SY", "eess.SY"], "comment": "Code can be found at https://github.com/google-deepmind/regress-lm", "summary": "In many industries, predicting metric outcomes of large systems is a\nfundamental problem, driven largely by traditional tabular regression. However,\nsuch methods struggle on complex systems data in the wild such as configuration\nfiles or system logs, where feature engineering is often infeasible. We propose\ntext-to-text regression as a general, scalable alternative. For predicting\nresource efficiency on Borg, Google's massive compute cluster scheduling\nsystem, a 60M parameter encoder-decoder, trained from random initialization,\nachieves up to a near perfect 0.99 (0.9 average) rank correlation across the\nentire fleet, and 100x lower MSE than tabular approaches. The model also easily\nadapts to new tasks in only 500 few-shot examples and captures the densities of\ncomplex outcome distributions. Ablation studies highlight the importance of\nusing encoders, increasing sequence length, and the model's inherent\nuncertainty quantification. These findings pave the way for universal\nsimulators of real-world outcomes.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6587\u672c\u5230\u6587\u672c\u56de\u5f52\u65b9\u6cd5\uff0c\u7528\u4e8e\u9884\u6d4b\u5927\u578b\u7cfb\u7edf\uff08\u5982Google\u7684Borg\u96c6\u7fa4\u8c03\u5ea6\u7cfb\u7edf\uff09\u7684\u8d44\u6e90\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u5728\u65e0\u9700\u7279\u5f81\u5de5\u7a0b\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u590d\u6742\u7cfb\u7edf\u6570\u636e\uff08\u5982\u914d\u7f6e\u6587\u4ef6\u6216\u7cfb\u7edf\u65e5\u5fd7\uff09\u8868\u73b0\u51fa\u8272\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u4f20\u7edf\u8868\u683c\u56de\u5f52\u65b9\u6cd5\uff0c\u65b0\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8\u7684\u79e9\u76f8\u5173\u6027\uff08\u63a5\u8fd1\u5b8c\u7f8e0.99\uff09\u548c\u66f4\u4f4e\u7684\u5747\u65b9\u8bef\u5dee\uff08MSE\u4f4e100\u500d\uff09\u3002\u6b64\u5916\uff0c\u6a21\u578b\u53ef\u901a\u8fc7\u5c11\u91cf\u6837\u672c\u9002\u5e94\u65b0\u4efb\u52a1\uff0c\u5e76\u80fd\u6355\u6349\u590d\u6742\u7ed3\u679c\u5206\u5e03\u7684\u5bc6\u5ea6\u3002\u6d88\u878d\u7814\u7a76\u5f3a\u8c03\u4e86\u4f7f\u7528\u7f16\u7801\u5668\u3001\u589e\u52a0\u5e8f\u5217\u957f\u5ea6\u4ee5\u53ca\u6a21\u578b\u5185\u5728\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u8bb8\u591a\u884c\u4e1a\u9700\u8981\u9884\u6d4b\u5927\u578b\u7cfb\u7edf\u7684\u5ea6\u91cf\u7ed3\u679c\uff0c\u4f46\u4f20\u7edf\u8868\u683c\u56de\u5f52\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u7cfb\u7edf\u6570\u636e\uff08\u5982\u914d\u7f6e\u6587\u4ef6\u6216\u7cfb\u7edf\u65e5\u5fd7\uff09\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u56e0\u4e3a\u7279\u5f81\u5de5\u7a0b\u5f80\u5f80\u4e0d\u53ef\u884c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u901a\u7528\u4e14\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u6587\u672c\u5230\u6587\u672c\u56de\u5f52\u65b9\u6cd5\uff0c\u5229\u7528\u4e00\u4e2a6000\u4e07\u53c2\u6570\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\uff0c\u4ece\u968f\u673a\u521d\u59cb\u5316\u5f00\u59cb\u8bad\u7ec3\u3002\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u9884\u6d4bGoogle Borg\u96c6\u7fa4\u8c03\u5ea6\u7cfb\u7edf\u7684\u8d44\u6e90\u6548\u7387\uff0c\u65e0\u9700\u8fdb\u884c\u7279\u5f81\u5de5\u7a0b\u3002", "result": "\u5728\u9884\u6d4bBorg\u7cfb\u7edf\u8d44\u6e90\u6548\u7387\u7684\u4efb\u52a1\u4e2d\uff0c\u8be5\u6a21\u578b\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5b8c\u7f8e\u76840.99\uff08\u5e73\u5747\u503c\u4e3a0.9\uff09\u79e9\u76f8\u5173\u6027\uff0c\u5747\u65b9\u8bef\u5dee\uff08MSE\uff09\u6bd4\u8868\u683c\u65b9\u6cd5\u4f4e100\u500d\u3002\u6b64\u5916\uff0c\u6a21\u578b\u4ec5\u9700500\u4e2a\u6837\u672c\u5373\u53ef\u9002\u5e94\u65b0\u4efb\u52a1\uff0c\u5e76\u80fd\u6355\u6349\u590d\u6742\u7ed3\u679c\u5206\u5e03\u7684\u5bc6\u5ea6\u3002", "conclusion": "\u6587\u672c\u5230\u6587\u672c\u56de\u5f52\u65b9\u6cd5\u4e3a\u9884\u6d4b\u5927\u578b\u590d\u6742\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u826f\u597d\u7684\u9002\u5e94\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u80fd\u529b\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u7ed3\u679c\u7684\u901a\u7528\u6a21\u62df\u5668\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.21805", "pdf": "https://arxiv.org/pdf/2506.21805", "abs": "https://arxiv.org/abs/2506.21805", "authors": ["Nicolas Bougie", "Narimasa Watanabe"], "title": "CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Modeling human behavior in urban environments is fundamental for social\nscience, behavioral studies, and urban planning. Prior work often rely on\nrigid, hand-crafted rules, limiting their ability to simulate nuanced\nintentions, plans, and adaptive behaviors. Addressing these challenges, we\nenvision an urban simulator (CitySim), capitalizing on breakthroughs in\nhuman-level intelligence exhibited by large language models. In CitySim, agents\ngenerate realistic daily schedules using a recursive value-driven approach that\nbalances mandatory activities, personal habits, and situational factors. To\nenable long-term, lifelike simulations, we endow agents with beliefs, long-term\ngoals, and spatial memory for navigation. CitySim exhibits closer alignment\nwith real humans than prior work, both at micro and macro levels. Additionally,\nwe conduct insightful experiments by modeling tens of thousands of agents and\nevaluating their collective behaviors under various real-world scenarios,\nincluding estimating crowd density, predicting place popularity, and assessing\nwell-being. Our results highlight CitySim as a scalable, flexible testbed for\nunderstanding and forecasting urban phenomena.", "AI": {"tldr": "\u6784\u5efa\u4e86\u4e00\u4e2a\u57ce\u5e02\u6a21\u62df\u5668CitySim\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4eba\u7c7b\u667a\u80fd\u6765\u751f\u6210\u66f4\u771f\u5b9e\u7684\u57ce\u5e02\u884c\u4e3a\u6a21\u62df\u3002\u901a\u8fc7\u8d4b\u4e88\u4ee3\u7406\u4fe1\u5ff5\u3001\u957f\u671f\u76ee\u6807\u548c\u7a7a\u95f4\u8bb0\u5fc6\uff0cCitySim\u5728\u5fae\u89c2\u548c\u5b8f\u89c2\u5c42\u9762\u90fd\u4e0e\u771f\u5b9e\u4eba\u7c7b\u884c\u4e3a\u66f4\u52a0\u4e00\u81f4\uff0c\u5e76\u53ef\u6269\u5c55\u7528\u4e8e\u7406\u89e3\u57ce\u5e02\u73b0\u8c61\u3002", "motivation": "\u73b0\u6709\u7684\u57ce\u5e02\u884c\u4e3a\u5efa\u6a21\u5de5\u4f5c\u901a\u5e38\u4f9d\u8d56\u4e8e\u521a\u6027\u3001\u624b\u5de5\u8bbe\u8ba1\u7684\u89c4\u5219\uff0c\u9650\u5236\u4e86\u5bf9\u590d\u6742\u610f\u56fe\u3001\u8ba1\u5212\u548c\u9002\u5e94\u6027\u884c\u4e3a\u7684\u6a21\u62df\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aCitySim\u7684\u57ce\u5e02\u6a21\u62df\u5668\uff0c\u4f7f\u7528\u9012\u5f52\u4ef7\u503c\u9a71\u52a8\u7684\u65b9\u6cd5\u751f\u6210\u73b0\u5b9e\u7684\u65e5\u7a0b\u5b89\u6392\uff0c\u5e73\u8861\u5f3a\u5236\u6d3b\u52a8\u3001\u4e2a\u4eba\u4e60\u60ef\u548c\u60c5\u5883\u56e0\u7d20\u3002\u540c\u65f6\uff0c\u8d4b\u4e88\u4ee3\u7406\u4fe1\u5ff5\u3001\u957f\u671f\u76ee\u6807\u548c\u7a7a\u95f4\u8bb0\u5fc6\u4ee5\u5b9e\u73b0\u957f\u671f\u3001\u7c7b\u4f3c\u751f\u6d3b\u7684\u6a21\u62df\u3002", "result": "CitySim\u5728\u5fae\u89c2\u548c\u5b8f\u89c2\u5c42\u9762\u4e0a\u90fd\u8868\u73b0\u51fa\u6bd4\u4ee5\u524d\u7684\u5de5\u4f5c\u66f4\u63a5\u8fd1\u771f\u5b9e\u4eba\u7c7b\u7684\u884c\u4e3a\u3002\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86CitySim\u5728\u4f30\u8ba1\u4eba\u7fa4\u5bc6\u5ea6\u3001\u9884\u6d4b\u5730\u70b9\u53d7\u6b22\u8fce\u7a0b\u5ea6\u548c\u8bc4\u4f30\u5e78\u798f\u611f\u7b49\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "CitySim\u4f5c\u4e3a\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u7075\u6d3b\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4e3a\u7406\u89e3\u548c\u9884\u6d4b\u57ce\u5e02\u73b0\u8c61\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2506.22429", "pdf": "https://arxiv.org/pdf/2506.22429", "abs": "https://arxiv.org/abs/2506.22429", "authors": ["David Holzm\u00fcller", "Max Sch\u00f6lpple"], "title": "Beyond ReLU: How Activations Affect Neural Kernels and Random Wide Networks", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "While the theory of deep learning has made some progress in recent years,\nmuch of it is limited to the ReLU activation function. In particular, while the\nneural tangent kernel (NTK) and neural network Gaussian process kernel (NNGP)\nhave given theoreticians tractable limiting cases of fully connected neural\nnetworks, their properties for most activation functions except for powers of\nthe ReLU function are poorly understood. Our main contribution is to provide a\nmore general characterization of the RKHS of these kernels for typical\nactivation functions whose only non-smoothness is at zero, such as SELU, ELU,\nor LeakyReLU. Our analysis also covers a broad set of special cases such as\nmissing biases, two-layer networks, or polynomial activations. Our results show\nthat a broad class of not infinitely smooth activations generate equivalent\nRKHSs at different network depths, while polynomial activations generate\nnon-equivalent RKHSs. Finally, we derive results for the smoothness of NNGP\nsample paths, characterizing the smoothness of infinitely wide neural networks\nat initialization.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u6269\u5c55\u4e86\u5bf9\u795e\u7ecf\u7f51\u7edc\u4e2d\u5e38\u7528\u7684\u6fc0\u6d3b\u51fd\u6570\uff08\u5982SELU\u3001ELU\u3001LeakyReLU\u7b49\uff09\u7684\u7406\u8bba\u7406\u89e3\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u5728\u4e0d\u540c\u7f51\u7edc\u6df1\u5ea6\u4e0b\u751f\u6210\u7684RKHS\u7279\u6027\u4ee5\u53caNNGP\u6837\u672c\u8def\u5f84\u7684\u5e73\u6ed1\u6027\u3002", "motivation": "\u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u7406\u8bba\u8fd1\u5e74\u6765\u53d6\u5f97\u4e86\u4e00\u4e9b\u8fdb\u5c55\uff0c\u4f46\u5927\u591a\u6570\u7814\u7a76\u5c40\u9650\u4e8eReLU\u6fc0\u6d3b\u51fd\u6570\uff0c\u5bf9\u4e8e\u5176\u4ed6\u5e38\u89c1\u6fc0\u6d3b\u51fd\u6570\u7684\u6027\u8d28\u4e86\u89e3\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5173\u4e8e\u795e\u7ecf\u5207\u7ebf\u6838\uff08NTK\uff09\u548c\u795e\u7ecf\u7f51\u7edc\u9ad8\u65af\u8fc7\u7a0b\u6838\uff08NNGP\uff09\u3002", "method": "\u4f5c\u8005\u5bf9\u5178\u578b\u7684\u6fc0\u6d3b\u51fd\u6570\uff08\u5176\u552f\u4e00\u975e\u5149\u6ed1\u70b9\u5728\u96f6\u5904\uff09\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u518d\u751f\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff08RKHS\uff09\u7279\u5f81\u5206\u6790\uff0c\u6db5\u76d6\u4e86\u5305\u62ec\u7f3a\u5931\u504f\u5dee\u3001\u4e24\u5c42\u7f51\u7edc\u6216\u591a\u9879\u5f0f\u6fc0\u6d3b\u7b49\u7279\u6b8a\u60c5\u51b5\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u4e00\u5927\u7c7b\u975e\u65e0\u9650\u5149\u6ed1\u7684\u6fc0\u6d3b\u51fd\u6570\u5728\u4e0d\u540c\u7684\u7f51\u7edc\u6df1\u5ea6\u4e0b\u751f\u6210\u7b49\u4ef7\u7684RKHS\uff0c\u800c\u591a\u9879\u5f0f\u6fc0\u6d3b\u51fd\u6570\u5219\u751f\u6210\u975e\u7b49\u4ef7\u7684RKHS\uff0c\u5e76\u4e14\u63a8\u5bfc\u51fa\u4e86NNGP\u6837\u672c\u8def\u5f84\u7684\u5e73\u6ed1\u6027\u7ed3\u679c\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u52a0\u6df1\u4e86\u6211\u4eec\u5bf9\u975eReLU\u6fc0\u6d3b\u51fd\u6570\u7684\u7406\u89e3\uff0c\u7279\u522b\u662f\u5728\u65e0\u9650\u5bbd\u795e\u7ecf\u7f51\u7edc\u521d\u59cb\u5316\u65f6\u7684\u5e73\u6ed1\u6027\u3002"}}
{"id": "2506.21744", "pdf": "https://arxiv.org/pdf/2506.21744", "abs": "https://arxiv.org/abs/2506.21744", "authors": ["Biying Zhou", "Nanyu Luo", "Feng Ji"], "title": "Federated Item Response Theory Models", "categories": ["cs.LG", "stat.AP", "stat.ML"], "comment": null, "summary": "Item Response Theory (IRT) models have been widely used to estimate\nrespondents' latent abilities and calibrate items' difficulty. Traditional IRT\nestimation requires all individual raw response data to be centralized in one\nplace, thus potentially causing privacy issues. Federated learning is an\nemerging field in computer science and machine learning with added features of\nprivacy protection and distributed computing. To integrate the advances from\nfederated learning with modern psychometrics, we propose a novel framework,\nFederated Item Response Theory (IRT), to enable estimating traditional IRT\nmodels with additional privacy, allowing estimation in a distributed manner\nwithout losing estimation accuracy.\n  Our numerical experiments confirm that FedIRT achieves statistical accuracy\nsimilar to standard IRT estimation using popular R packages, while offering\ncritical advantages: privacy protection and reduced communication costs. We\nalso validate FedIRT's utility through a real-world exam dataset, demonstrating\nits effectiveness in realistic educational contexts. This new framework extends\nIRT's applicability to distributed settings, such as multi-school assessments,\nwithout sacrificing accuracy or security. To support practical adoption, we\nprovide an open-ource R package, FedIRT, implementing the framework for the\ntwo-parameter logistic (2PL) and partial credit models (PCM).", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u5373\u8054\u5408\u9879\u76ee\u53cd\u5e94\u7406\u8bba\uff08FedIRT\uff09\uff0c\u5b83\u80fd\u591f\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e0b\u4f30\u8ba1\u4f20\u7edf\u7684IRT\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u5e76\u51cf\u5c11\u901a\u4fe1\u6210\u672c\uff0c\u4e14\u4e0d\u635f\u5931\u4f30\u8ba1\u7cbe\u5ea6\u3002\u4f5c\u8005\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u548c\u771f\u5b9e\u8003\u8bd5\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90R\u5305FedIRT\u4ee5\u652f\u6301\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u4f20\u7edf\u7684IRT\u4f30\u8ba1\u9700\u8981\u5c06\u6240\u6709\u4e2a\u4f53\u7684\u539f\u59cb\u54cd\u5e94\u6570\u636e\u96c6\u4e2d\u5230\u4e00\u4e2a\u5730\u65b9\uff0c\u8fd9\u53ef\u80fd\u4f1a\u5f15\u53d1\u9690\u79c1\u95ee\u9898\u3002\u4e3a\u4e86\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u7684\u4f18\u52bf\u4e0e\u73b0\u4ee3\u5fc3\u7406\u6d4b\u91cf\u5b66\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFederated Item Response Theory (IRT)\u7684\u65b0\u6846\u67b6\uff0c\u5141\u8bb8\u5728\u5206\u5e03\u5f0f\u73af\u5883\u4e0b\u8fdb\u884cIRT\u6a21\u578b\u7684\u4f30\u8ba1\uff0c\u540c\u65f6\u63d0\u4f9b\u9690\u79c1\u4fdd\u62a4\u548c\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u3002\u8be5\u6846\u67b6\u9002\u7528\u4e8e\u4e24\u53c2\u6570\u903b\u8f91\u6a21\u578b(2PL)\u548c\u90e8\u5206\u4fe1\u7528\u6a21\u578b(PCM)\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0cFedIRT\u5728\u7edf\u8ba1\u51c6\u786e\u6027\u4e0a\u4e0e\u4f7f\u7528\u6d41\u884cR\u5305\u7684\u6807\u51c6IRT\u4f30\u8ba1\u76f8\u4f3c\uff0c\u540c\u65f6\u5177\u6709\u9690\u79c1\u4fdd\u62a4\u548c\u964d\u4f4e\u901a\u4fe1\u6210\u672c\u7684\u4f18\u52bf\u3002\u901a\u8fc7\u771f\u5b9e\u8003\u8bd5\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86FedIRT\u5728\u6559\u80b2\u73af\u5883\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "FedIRT\u6269\u5c55\u4e86IRT\u5728\u5206\u5e03\u5f0f\u73af\u5883\uff08\u5982\u591a\u6821\u8bc4\u4f30\uff09\u4e2d\u7684\u9002\u7528\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u51c6\u786e\u6027\u548c\u5b89\u5168\u6027\u3002\u4e3a\u652f\u6301\u5b9e\u9645\u5e94\u7528\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u5f00\u6e90R\u5305FedIRT\u3002"}}
{"id": "2506.21887", "pdf": "https://arxiv.org/pdf/2506.21887", "abs": "https://arxiv.org/abs/2506.21887", "authors": ["Edward Chen", "Sang T. Truong", "Natalie Dullerud", "Sanmi Koyejo", "Carlos Guestrin"], "title": "Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "High-stakes decision-making involves navigating multiple competing objectives\nwith expensive evaluations. For instance, in brachytherapy, clinicians must\nbalance maximizing tumor coverage (e.g., an aspirational target or soft bound\nof >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard\nbound of <601 cGy to the bladder), with each plan evaluation being\nresource-intensive. Selecting Pareto-optimal solutions that match implicit\npreferences is challenging, as exhaustive Pareto frontier exploration is\ncomputationally and cognitively prohibitive, necessitating interactive\nframeworks to guide users. While decision-makers (DMs) often possess domain\nknowledge to narrow the search via such soft-hard bounds, current methods often\nlack systematic approaches to iteratively refine these multi-faceted preference\nstructures. Critically, DMs must trust their final decision, confident they\nhaven't missed superior alternatives; this trust is paramount in\nhigh-consequence scenarios. We present Active-MoSH, an interactive local-global\nframework designed for this process. Its local component integrates soft-hard\nbounds with probabilistic preference learning, maintaining distributions over\nDM preferences and bounds for adaptive Pareto subset refinement. This is guided\nby an active sampling strategy optimizing exploration-exploitation while\nminimizing cognitive burden. To build DM trust, Active-MoSH's global component,\nT-MoSH, leverages multi-objective sensitivity analysis to identify potentially\noverlooked, high-value points beyond immediate feedback. We demonstrate\nActive-MoSH's performance benefits through diverse synthetic and real-world\napplications. A user study on AI-generated image selection further validates\nour hypotheses regarding the framework's ability to improve convergence,\nenhance DM trust, and provide expressive preference articulation, enabling more\neffective DMs.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aActive-MoSH\u7684\u4ea4\u4e92\u5f0f\u5c40\u90e8-\u5168\u5c40\u6846\u67b6\uff0c\u7528\u4e8e\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u7684\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u3002\u5b83\u901a\u8fc7\u6574\u5408\u8f6f\u786c\u8fb9\u754c\u4e0e\u6982\u7387\u504f\u597d\u5b66\u4e60\u6765\u9010\u6b65\u7ec6\u5316\u504f\u597d\u7ed3\u6784\uff0c\u5e76\u5229\u7528\u591a\u76ee\u6807\u654f\u611f\u6027\u5206\u6790\u4ee5\u5efa\u7acb\u51b3\u7b56\u8005\u7684\u4fe1\u4efb\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u63d0\u9ad8\u6536\u655b\u6027\u548c\u589e\u5f3a\u51b3\u7b56\u8005\u4fe1\u5fc3\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\uff0c\u9700\u8981\u5728\u591a\u4e2a\u7ade\u4e89\u76ee\u6807\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\uff0c\u800c\u6bcf\u4e2a\u8bc4\u4f30\u90fd\u53ef\u80fd\u8017\u8d39\u5927\u91cf\u8d44\u6e90\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u96be\u4ee5\u7cfb\u7edf\u5730\u8fed\u4ee3\u6539\u8fdb\u591a\u7ef4\u504f\u597d\u7ed3\u6784\uff0c\u4e14\u51b3\u7b56\u8005\u5fc5\u987b\u4fe1\u4efb\u6700\u7ec8\u51b3\u5b9a\uff0c\u786e\u4fdd\u6ca1\u6709\u9519\u8fc7\u66f4\u4f18\u65b9\u6848\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u5f15\u5bfc\u7528\u6237\u5e76\u9010\u6b65\u5b8c\u5584\u504f\u597d\u7684\u6846\u67b6\u3002", "method": "Active-MoSH\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u90e8\u5206\uff1a1) \u5c40\u90e8\u7ec4\u4ef6\u7ed3\u5408\u8f6f\u786c\u8fb9\u754c\u4e0e\u6982\u7387\u504f\u597d\u5b66\u4e60\uff0c\u901a\u8fc7\u5206\u5e03\u5efa\u6a21\u52a8\u6001\u8c03\u6574Pareto\u5b50\u96c6\uff1b2) \u5168\u5c40\u7ec4\u4ef6T-MoSH\u4f7f\u7528\u591a\u76ee\u6807\u654f\u611f\u6027\u5206\u6790\u8bc6\u522b\u6f5c\u5728\u88ab\u5ffd\u7565\u7684\u9ad8\u4ef7\u503c\u70b9\u3002\u6b64\u5916\uff0c\u91c7\u7528\u4e3b\u52a8\u91c7\u6837\u7b56\u7565\u4f18\u5316\u63a2\u7d22\u4e0e\u5f00\u53d1\u4e4b\u95f4\u7684\u5e73\u8861\uff0c\u540c\u65f6\u51cf\u5c11\u8ba4\u77e5\u8d1f\u62c5\u3002", "result": "\u901a\u8fc7\u591a\u6837\u5316\u7684\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u5e94\u7528\uff0c\u8bc1\u660e\u4e86Active-MoSH\u5728\u6027\u80fd\u4e0a\u7684\u63d0\u5347\u3002\u7528\u6237\u7814\u7a76\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u6539\u5584\u6536\u655b\u6027\u3001\u589e\u5f3a\u51b3\u7b56\u8005\u4fe1\u4efb\u4ee5\u53ca\u63d0\u4f9b\u660e\u786e\u504f\u597d\u8868\u8fbe\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "Active-MoSH\u4e3a\u9ad8\u98ce\u9669\u51b3\u7b56\u4e2d\u7684\u591a\u76ee\u6807\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u5c40\u90e8\u548c\u5168\u5c40\u7ec4\u4ef6\u534f\u540c\u5de5\u4f5c\uff0c\u80fd\u591f\u5728\u964d\u4f4e\u8ba4\u77e5\u8d1f\u62c5\u7684\u540c\u65f6\uff0c\u5e2e\u52a9\u51b3\u7b56\u8005\u627e\u5230\u66f4\u4f18\u89e3\u5e76\u589e\u5f3a\u5bf9\u5176\u51b3\u7b56\u7684\u4fe1\u4efb\u3002"}}
{"id": "2506.21771", "pdf": "https://arxiv.org/pdf/2506.21771", "abs": "https://arxiv.org/abs/2506.21771", "authors": ["John Wesley Hostetter", "Min Chi"], "title": "Gradient-Based Neuroplastic Adaptation for Concurrent Optimization of Neuro-Fuzzy Networks", "categories": ["cs.LG", "cs.NE"], "comment": "45 pages", "summary": "Neuro-fuzzy networks (NFNs) are transparent, symbolic, and universal function\napproximations that perform as well as conventional neural architectures, but\ntheir knowledge is expressed as linguistic IF-THEN rules. Despite these\nadvantages, their systematic design process remains a challenge. Existing work\nwill often sequentially build NFNs by inefficiently isolating parametric and\nstructural identification, leading to a premature commitment to brittle and\nsubpar architecture. We propose a novel application-independent approach called\ngradient-based neuroplastic adaptation for the concurrent optimization of NFNs'\nparameters and structure. By recognizing that NFNs' parameters and structure\nshould be optimized simultaneously as they are deeply conjoined, settings\npreviously unapproachable for NFNs are now accessible, such as the online\nreinforcement learning of NFNs for vision-based tasks. The effectiveness of\nconcurrently optimizing NFNs is empirically shown as it is trained by online\nreinforcement learning to proficiently play challenging scenarios from a\nvision-based video game called DOOM.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u7684\u795e\u7ecf\u53ef\u5851\u6027\u9002\u5e94\u65b9\u6cd5\uff0c\u7528\u4e8e\u540c\u65f6\u4f18\u5316\u795e\u7ecf\u6a21\u7cca\u7f51\u7edc\uff08NFNs\uff09\u7684\u53c2\u6570\u548c\u7ed3\u6784\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u53c2\u6570\u4e0e\u7ed3\u6784\u4f18\u5316\u5206\u79bb\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u9a8c\u8bc1\u4e86\u5176\u5728\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u795e\u7ecf\u6a21\u7cca\u7f51\u7edc\uff08NFNs\uff09\u5177\u6709\u900f\u660e\u3001\u7b26\u53f7\u5316\u548c\u901a\u7528\u51fd\u6570\u903c\u8fd1\u7684\u4f18\u70b9\uff0c\u4f46\u5176\u7cfb\u7edf\u8bbe\u8ba1\u8fc7\u7a0b\u4ecd\u9762\u4e34\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5c06\u53c2\u6570\u548c\u7ed3\u6784\u8bc6\u522b\u9694\u79bb\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u4e14\u67b6\u6784\u8106\u5f31\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4e0e\u5177\u4f53\u5e94\u7528\u65e0\u5173\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u795e\u7ecf\u53ef\u5851\u6027\u9002\u5e94\u65b9\u6cd5\uff0c\u7528\u4e8e\u540c\u65f6\u4f18\u5316NFNs\u7684\u53c2\u6570\u548c\u7ed3\u6784\uff0c\u907f\u514d\u4e86\u53c2\u6570\u4e0e\u7ed3\u6784\u4f18\u5316\u7684\u5206\u79bb\u3002", "result": "\u901a\u8fc7\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3NFNs\u73a9\u57fa\u4e8e\u89c6\u89c9\u7684\u6e38\u620fDOOM\uff0c\u5b9e\u8bc1\u4e86\u540c\u65f6\u4f18\u5316NFNs\u53c2\u6570\u548c\u7ed3\u6784\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8e\u68af\u5ea6\u7684\u795e\u7ecf\u53ef\u5851\u6027\u9002\u5e94\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3NFNs\u53c2\u6570\u4e0e\u7ed3\u6784\u4f18\u5316\u95ee\u9898\uff0c\u4e3aNFNs\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2506.21996", "pdf": "https://arxiv.org/pdf/2506.21996", "abs": "https://arxiv.org/abs/2506.21996", "authors": ["Rapha\u00ebl Boige", "Amine Boumaza", "Bruno Scherrer"], "title": "AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms", "categories": ["cs.AI"], "comment": null, "summary": "Deterministic game-solving algorithms are conventionally analyzed in the\nlight of their average-case complexity against a distribution of random\ngame-trees, where leaf values are independently sampled from a fixed\ndistribution. This simplified model enables uncluttered mathematical analysis,\nrevealing two key properties: root value distributions asymptotically collapse\nto a single fixed value for finite-valued trees, and all reasonable algorithms\nachieve global optimality. However, these findings are artifacts of the model's\ndesign-its long criticized independence assumption strips games of structural\ncomplexity, producing trivial instances where no algorithm faces meaningful\nchallenges. To address this limitation, we introduce a new probabilistic model\nthat incrementally constructs game-trees using a fixed level-wise conditional\ndistribution. By enforcing ancestor dependency, a critical structural feature\nof real-world games, our framework generates problems with adjustable\ndifficulty while retaining some form of analytical tractability. For several\nalgorithms, including AlphaBeta and Scout, we derive recursive formulas\ncharacterizing their average-case complexities under this model. These allow us\nto rigorously compare algorithms on deep game-trees, where Monte-Carlo\nsimulations are no longer feasible. While asymptotically, all algorithms seem\nto converge to identical branching factor (a result analogous to those of\nindependence-based models), deep finite trees reveal stark differences:\nAlphaBeta incurs a significantly larger constant multiplicative factor compared\nto algorithms like Scout, leading to a substantial practical slowdown. Our\nframework sheds new light on classical game-solving algorithms, offering\nrigorous evidence and analytical tools to advance the understanding of these\nmethods under a more realistic, challenging, and yet tractable model.", "AI": {"tldr": "\u4f20\u7edf\u786e\u5b9a\u6027\u535a\u5f08\u6c42\u89e3\u7b97\u6cd5\u901a\u5e38\u57fa\u4e8e\u7b80\u5316\u6a21\u578b\u5206\u6790\uff0c\u8be5\u6a21\u578b\u5047\u8bbe\u53f6\u8282\u70b9\u503c\u72ec\u7acb\u91c7\u6837\u3002\u7136\u800c\u8fd9\u79cd\u6a21\u578b\u5ffd\u7565\u4e86\u6e38\u620f\u7684\u7ed3\u6784\u6027\u590d\u6742\u5ea6\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6982\u7387\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u7956\u5148\u4f9d\u8d56\u5173\u7cfb\u6765\u751f\u6210\u5177\u6709\u53ef\u8c03\u96be\u5ea6\u7684\u6e38\u620f\u6811\uff0c\u5e76\u63a8\u5bfc\u4e86\u51e0\u4e2a\u7ecf\u5178\u7b97\u6cd5\uff08\u5982AlphaBeta\u548cScout\uff09\u5728\u8be5\u6a21\u578b\u4e0b\u7684\u5e73\u5747\u590d\u6742\u5ea6\u9012\u5f52\u516c\u5f0f\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u6df1\u5c42\u6709\u9650\u6811\u4e0a\uff0c\u4e0d\u540c\u7b97\u6cd5\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4f8b\u5982AlphaBeta\u76f8\u8f83\u4e8eScout\u6709\u66f4\u5927\u7684\u5e38\u6570\u56e0\u5b50\uff0c\u5bfc\u81f4\u5b9e\u9645\u8fd0\u884c\u901f\u5ea6\u8f83\u6162\u3002", "motivation": "\u73b0\u6709\u7684\u535a\u5f08\u6c42\u89e3\u7b97\u6cd5\u5206\u6790\u57fa\u4e8e\u53f6\u8282\u70b9\u72ec\u7acb\u91c7\u6837\u7684\u7b80\u5316\u6a21\u578b\uff0c\u8fd9\u5ffd\u7565\u4e86\u771f\u5b9e\u6e38\u620f\u4e2d\u7ed3\u6784\u590d\u6742\u6027\uff0c\u4f7f\u5f97\u5206\u6790\u7ed3\u679c\u65e0\u6cd5\u53cd\u6620\u5b9e\u9645\u60c5\u51b5\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u63a5\u8fd1\u73b0\u5b9e\u3001\u540c\u65f6\u4fdd\u6301\u4e00\u5b9a\u5206\u6790\u53ef\u884c\u6027\u7684\u65b0\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6982\u7387\u6a21\u578b\uff0c\u901a\u8fc7\u56fa\u5b9a\u5c42\u6b21\u6761\u4ef6\u5206\u5e03\u9010\u6b65\u6784\u5efa\u6e38\u620f\u6811\uff0c\u5e76\u5f3a\u5236\u6267\u884c\u7956\u5148\u4f9d\u8d56\u5173\u7cfb\u4ee5\u53cd\u6620\u771f\u5b9e\u6e38\u620f\u7684\u7ed3\u6784\u6027\u590d\u6742\u5ea6\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u63a8\u5bfc\u4e86\u51e0\u79cd\u7ecf\u5178\u7b97\u6cd5\uff08\u5982AlphaBeta\u548cScout\uff09\u5728\u65b0\u6a21\u578b\u4e0b\u7684\u5e73\u5747\u590d\u6742\u5ea6\u9012\u5f52\u516c\u5f0f\u3002", "result": "\u5728\u65b0\u6a21\u578b\u4e0b\uff0c\u867d\u7136\u6240\u6709\u7b97\u6cd5\u5728\u6e10\u8fd1\u60c5\u51b5\u4e0b\u4f3c\u4e4e\u90fd\u6536\u655b\u5230\u76f8\u540c\u7684\u5206\u652f\u56e0\u5b50\uff0c\u4f46\u5728\u6df1\u5c42\u6709\u9650\u6811\u4e0a\uff0c\u4e0d\u540c\u7b97\u6cd5\u7684\u8868\u73b0\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u4f8b\u5982\uff0cAlphaBeta\u76f8\u6bd4Scout\u5177\u6709\u66f4\u5927\u7684\u5e38\u6570\u56e0\u5b50\uff0c\u5bfc\u81f4\u5b9e\u9645\u8fd0\u884c\u901f\u5ea6\u53d8\u6162\u3002", "conclusion": "\u65b0\u6a21\u578b\u4e3a\u7ecf\u5178\u535a\u5f08\u6c42\u89e3\u7b97\u6cd5\u63d0\u4f9b\u4e86\u66f4\u73b0\u5b9e\u3001\u66f4\u5177\u6311\u6218\u6027\u4e14\u53ef\u5206\u6790\u7684\u6846\u67b6\uff0c\u6709\u52a9\u4e8e\u6df1\u5165\u7406\u89e3\u8fd9\u4e9b\u7b97\u6cd5\u7684\u5b9e\u9645\u8868\u73b0\u53ca\u5dee\u5f02\u3002"}}
{"id": "2506.22331", "pdf": "https://arxiv.org/pdf/2506.22331", "abs": "https://arxiv.org/abs/2506.22331", "authors": ["Adiba Ejaz", "Elias Bareinboim"], "title": "Less Greedy Equivalence Search", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "comment": "35 total pages. 14 figures", "summary": "Greedy Equivalence Search (GES) is a classic score-based algorithm for causal\ndiscovery from observational data. In the sample limit, it recovers the Markov\nequivalence class of graphs that describe the data. Still, it faces two\nchallenges in practice: computational cost and finite-sample accuracy. In this\npaper, we develop Less Greedy Equivalence Search (LGES), a variant of GES that\nretains its theoretical guarantees while partially addressing these\nlimitations. LGES modifies the greedy step: rather than always applying the\nhighest-scoring insertion, it avoids edge insertions between variables for\nwhich the score implies some conditional independence. This more targeted\nsearch yields up to a \\(10\\)-fold speed-up and a substantial reduction in\nstructural error relative to GES. Moreover, LGES can guide the search using\nprior assumptions, while correcting these assumptions when contradicted by the\ndata. Finally, LGES can exploit interventional data to refine the learned\nobservational equivalence class. We prove that LGES recovers the true\nequivalence class in the sample limit from observational and interventional\ndata, even with misspecified prior assumptions. Experiments demonstrate that\nLGES outperforms GES and other baselines in speed, accuracy, and robustness to\nmisspecified assumptions. Our code is available at\nhttps://github.com/CausalAILab/lges.", "AI": {"tldr": "LGES\u662f\u4e00\u79cd\u6539\u8fdb\u7248\u7684GES\u7b97\u6cd5\uff0c\u901a\u8fc7\u66f4\u7cbe\u786e\u7684\u641c\u7d22\u7b56\u7565\u63d0\u5347\u4e86\u8ba1\u7b97\u901f\u5ea6\u548c\u51c6\u786e\u6027\uff0c\u5e76\u80fd\u5229\u7528\u5e72\u9884\u6570\u636e\u53ca\u4fee\u6b63\u5148\u9a8c\u5047\u8bbe\uff0c\u5b9e\u73b0\u5728\u6837\u672c\u6781\u9650\u4e0b\u6062\u590d\u771f\u5b9e\u7b49\u4ef7\u7c7b\u3002\u5b9e\u9a8c\u8868\u660eLGES\u5728\u901f\u5ea6\u3001\u51c6\u786e\u6027\u548c\u5bf9\u9519\u8bef\u5047\u8bbe\u7684\u9c81\u68d2\u6027\u4e0a\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u7ecf\u5178\u7684\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5GES\u5728\u7406\u8bba\u4e0a\u80fd\u591f\u4ece\u89c2\u6d4b\u6570\u636e\u4e2d\u6062\u590d\u63cf\u8ff0\u6570\u636e\u7684\u9a6c\u5c14\u53ef\u592b\u7b49\u4ef7\u7c7b\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u6709\u9650\u6837\u672c\u7cbe\u5ea6\u4e0d\u8db3\u7684\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u6539\u8fdb\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86Less Greedy Equivalence Search (LGES)\uff0c\u5b83\u901a\u8fc7\u4fee\u6539\u8d2a\u5a6a\u6b65\u9aa4\u6765\u907f\u514d\u53d8\u91cf\u4e4b\u95f4\u56e0\u5f97\u5206\u6697\u793a\u67d0\u4e9b\u6761\u4ef6\u72ec\u7acb\u800c\u8fdb\u884c\u7684\u8fb9\u63d2\u5165\u3002\u6b64\u5916\uff0cLGES\u53ef\u4ee5\u4f7f\u7528\u5148\u9a8c\u5047\u8bbe\u5f15\u5bfc\u641c\u7d22\uff0c\u5e76\u5728\u6570\u636e\u77db\u76fe\u65f6\u4fee\u6b63\u8fd9\u4e9b\u5047\u8bbe\uff0c\u540c\u65f6\u8fd8\u80fd\u5229\u7528\u5e72\u9884\u6570\u636e\u8fdb\u4e00\u6b65\u7ec6\u5316\u5b66\u4e60\u5230\u7684\u89c2\u6d4b\u7b49\u4ef7\u7c7b\u3002", "result": "LGES\u76f8\u6bd4GES\u5b9e\u73b0\u4e86\u9ad8\u8fbe10\u500d\u7684\u901f\u5ea6\u63d0\u5347\u548c\u663e\u8457\u7684\u7ed3\u6784\u8bef\u5dee\u51cf\u5c11\u3002\u5b9e\u9a8c\u8fd8\u8bc1\u660e\uff0cLGES\u5728\u901f\u5ea6\u3001\u51c6\u786e\u6027\u548c\u5bf9\u9519\u8bef\u5047\u8bbe\u7684\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8eGES\u548c\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "LGES\u4e0d\u4ec5\u4fdd\u7559\u4e86GES\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u8fd8\u90e8\u5206\u89e3\u51b3\u4e86\u5176\u8ba1\u7b97\u6210\u672c\u548c\u6709\u9650\u6837\u672c\u7cbe\u5ea6\u95ee\u9898\u3002\u5b83\u80fd\u591f\u5728\u89c2\u6d4b\u548c\u5e72\u9884\u6570\u636e\uff08\u5373\u4f7f\u5b58\u5728\u9519\u8bef\u6307\u5b9a\u7684\u5148\u9a8c\u5047\u8bbe\uff09\u7684\u6837\u672c\u6781\u9650\u4e0b\u6062\u590d\u771f\u5b9e\u7684\u7b49\u4ef7\u7c7b\u3002"}}
{"id": "2506.21782", "pdf": "https://arxiv.org/pdf/2506.21782", "abs": "https://arxiv.org/abs/2506.21782", "authors": ["Aditya Narendra", "Dmitry Makarov", "Aleksandr Panov"], "title": "M3PO: Massively Multi-Task Model-Based Policy Optimization", "categories": ["cs.LG", "cs.RO"], "comment": "6 pages, 4 figures. Accepted at IEEE/RSJ IROS 2025. Full version,\n  including appendix and implementation details", "summary": "We introduce Massively Multi-Task Model-Based Policy Optimization (M3PO), a\nscalable model-based reinforcement learning (MBRL) framework designed to\naddress sample inefficiency in single-task settings and poor generalization in\nmulti-task domains. Existing model-based approaches like DreamerV3 rely on\npixel-level generative models that neglect control-centric representations,\nwhile model-free methods such as PPO suffer from high sample complexity and\nweak exploration. M3PO integrates an implicit world model, trained to predict\ntask outcomes without observation reconstruction, with a hybrid exploration\nstrategy that combines model-based planning and model-free uncertainty-driven\nbonuses. This eliminates the bias-variance trade-off in prior methods by using\ndiscrepancies between model-based and model-free value estimates to guide\nexploration, while maintaining stable policy updates through a trust-region\noptimizer. M3PO provides an efficient and robust alternative to existing\nmodel-based policy optimization approaches and achieves state-of-the-art\nperformance across multiple benchmarks.", "AI": {"tldr": "M3PO\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u4e86\u9690\u5f0f\u4e16\u754c\u6a21\u578b\u548c\u6df7\u5408\u63a2\u7d22\u7b56\u7565\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7a33\u5065\u7684\u66ff\u4ee3\u73b0\u6709\u57fa\u4e8e\u6a21\u578b\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u65b9\u6cd5\uff08\u5982DreamerV3\uff09\u4f9d\u8d56\u4e8e\u5ffd\u89c6\u63a7\u5236\u4e2d\u5fc3\u8868\u793a\u7684\u50cf\u7d20\u7ea7\u751f\u6210\u6a21\u578b\uff0c\u800c\u65e0\u6a21\u578b\u65b9\u6cd5\uff08\u5982PPO\uff09\u5219\u9762\u4e34\u9ad8\u6837\u672c\u590d\u6742\u6027\u548c\u5f31\u63a2\u7d22\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u5355\u4efb\u52a1\u8bbe\u7f6e\u4e2d\u7684\u6837\u672c\u6548\u7387\u4f4e\u4e0b\u548c\u591a\u4efb\u52a1\u9886\u57df\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86M3PO\u3002", "method": "M3PO\u6574\u5408\u4e86\u4e00\u4e2a\u9690\u5f0f\u4e16\u754c\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u88ab\u8bad\u7ec3\u7528\u4e8e\u9884\u6d4b\u4efb\u52a1\u7ed3\u679c\u800c\u4e0d\u8fdb\u884c\u89c2\u5bdf\u91cd\u5efa\uff0c\u4ee5\u53ca\u4e00\u79cd\u7ed3\u5408\u4e86\u57fa\u4e8e\u6a21\u578b\u7684\u89c4\u5212\u548c\u57fa\u4e8e\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u5956\u52b1\u7684\u6df7\u5408\u63a2\u7d22\u7b56\u7565\u3002\u901a\u8fc7\u4f7f\u7528\u57fa\u4e8e\u6a21\u578b\u548c\u65e0\u6a21\u578b\u4ef7\u503c\u4f30\u8ba1\u4e4b\u95f4\u7684\u5dee\u5f02\u6765\u5f15\u5bfc\u63a2\u7d22\uff0c\u5e76\u901a\u8fc7\u4fe1\u4efb\u533a\u57df\u4f18\u5316\u5668\u4fdd\u6301\u7a33\u5b9a\u7684\u7b56\u7565\u66f4\u65b0\u3002", "result": "M3PO\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u7a33\u5065\u7684\u66ff\u4ee3\u73b0\u6709\u57fa\u4e8e\u6a21\u578b\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "M3PO\u89e3\u51b3\u4e86\u6837\u672c\u6548\u7387\u4f4e\u4e0b\u548c\u591a\u4efb\u52a1\u9886\u57df\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u5dee\u7684\u95ee\u9898\uff0c\u662f\u4e00\u79cd\u6709\u6548\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002"}}
{"id": "2506.22005", "pdf": "https://arxiv.org/pdf/2506.22005", "abs": "https://arxiv.org/abs/2506.22005", "authors": ["Naoto Onda", "Kazumi Kasaura", "Yuta Oriike", "Masaya Taniguchi", "Akiyoshi Sannai", "Sho Sonoda"], "title": "LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving", "categories": ["cs.AI"], "comment": "15 pages, 4 figures, 5 tables", "summary": "We introduce LeanConjecturer, a pipeline for automatically generating\nuniversity-level mathematical conjectures in Lean 4 using Large Language Models\n(LLMs). Our hybrid approach combines rule-based context extraction with\nLLM-based theorem statement generation, addressing the data scarcity challenge\nin formal theorem proving. Through iterative generation and evaluation,\nLeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with\n3,776 identified as syntactically valid and non-trivial, that is, cannot be\nproven by \\texttt{aesop} tactic. We demonstrate the utility of these generated\nconjectures for reinforcement learning through Group Relative Policy\nOptimization (GRPO), showing that targeted training on domain-specific\nconjectures can enhance theorem proving capabilities. Our approach generates\n103.25 novel conjectures per seed file on average, providing a scalable\nsolution for creating training data for theorem proving systems. Our system\nsuccessfully verified several non-trivial theorems in topology, including\nproperties of semi-open, alpha-open, and pre-open sets, demonstrating its\npotential for mathematical discovery beyond simple variations of existing\nresults.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86LeanConjecturer\uff0c\u4e00\u4e2a\u7ed3\u5408\u89c4\u5219\u57fa\u7840\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u6df7\u5408\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210\u5927\u5b66\u6c34\u5e73\u7684\u6570\u5b66\u731c\u60f3\u3002\u901a\u8fc7\u8fed\u4ee3\u751f\u6210\u4e0e\u8bc4\u4f30\uff0c\u8be5\u7cfb\u7edf\u4ece40\u4e2aMathlib\u79cd\u5b50\u6587\u4ef6\u4e2d\u751f\u6210\u4e8612,289\u4e2a\u731c\u60f3\uff0c\u5176\u4e2d3,776\u4e2a\u88ab\u786e\u8ba4\u4e3a\u8bed\u6cd5\u6709\u6548\u4e14\u975e\u5e73\u51e1\u3002\u8fd9\u4e9b\u751f\u6210\u7684\u731c\u60f3\u4e0d\u4ec5\u53ef\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u8fd8\u6210\u529f\u9a8c\u8bc1\u4e86\u62d3\u6251\u5b66\u4e2d\u7684\u51e0\u4e2a\u975e\u5e73\u51e1\u5b9a\u7406\uff0c\u663e\u793a\u51fa\u8d85\u8d8a\u73b0\u6709\u7ed3\u679c\u7b80\u5355\u53d8\u4f53\u7684\u6570\u5b66\u53d1\u73b0\u6f5c\u529b\u3002", "motivation": "\u5728\u5f62\u5f0f\u5316\u5b9a\u7406\u8bc1\u660e\u4e2d\uff0c\u6570\u636e\u7a00\u7f3a\u662f\u4e00\u4e2a\u4e3b\u8981\u6311\u6218\uff0c\u8fd9\u9650\u5236\u4e86\u81ea\u52a8\u5b9a\u7406\u751f\u6210\u548c\u9a8c\u8bc1\u7cfb\u7edf\u7684\u8fdb\u6b65\u3002\u6b64\u5916\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u5df2\u6709\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u96be\u4ee5\u751f\u6210\u65b0\u7684\u3001\u6709\u610f\u4e49\u7684\u6570\u5b66\u731c\u60f3\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u521b\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4fc3\u8fdb\u66f4\u5e7f\u6cdb\u7684\u6570\u5b66\u53d1\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLeanConjecturer\u7684\u7ba1\u9053\uff0c\u7ed3\u5408\u89c4\u5219\u57fa\u7840\u7684\u4e0a\u4e0b\u6587\u63d0\u53d6\u548c\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b9a\u7406\u9648\u8ff0\u751f\u6210\u6280\u672f\u3002\u5177\u4f53\u6b65\u9aa4\u5305\u62ec\uff1a1) \u4f7f\u7528\u89c4\u5219\u57fa\u7840\u65b9\u6cd5\u4ece\u73b0\u6709\u6570\u5b66\u5e93\uff08\u5982Mathlib\uff09\u4e2d\u63d0\u53d6\u80cc\u666f\u4fe1\u606f\uff1b2) \u5229\u7528LLMs\u751f\u6210\u65b0\u7684\u6570\u5b66\u731c\u60f3\uff1b3) \u901a\u8fc7\u8fed\u4ee3\u751f\u6210\u4e0e\u8bc4\u4f30\u8fc7\u7a0b\u7b5b\u9009\u51fa\u6709\u6548\u7684\u3001\u975e\u5e73\u51e1\u7684\u731c\u60f3\u3002\u6700\u540e\uff0c\u901a\u8fc7Group Relative Policy Optimization (GRPO) \u65b9\u6cd5\uff0c\u5c06\u751f\u6210\u7684\u731c\u60f3\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u4ee5\u589e\u5f3a\u5b9a\u7406\u8bc1\u660e\u80fd\u529b\u3002", "result": "LeanConjecturer\u4ece40\u4e2aMathlib\u79cd\u5b50\u6587\u4ef6\u4e2d\u751f\u6210\u4e8612,289\u4e2a\u731c\u60f3\uff0c\u5176\u4e2d3,776\u4e2a\u88ab\u786e\u8ba4\u4e3a\u8bed\u6cd5\u6709\u6548\u4e14\u975e\u5e73\u51e1\u3002\u8fd9\u4e9b\u731c\u60f3\u4e0d\u4ec5\u53ef\u7528\u4e8e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u8fd8\u6210\u529f\u9a8c\u8bc1\u4e86\u62d3\u6251\u5b66\u4e2d\u7684\u51e0\u4e2a\u975e\u5e73\u51e1\u5b9a\u7406\uff0c\u4f8b\u5982\u5173\u4e8e\u534a\u5f00\u3001alpha-\u5f00\u548c\u9884\u5f00\u96c6\u5408\u7684\u6027\u8d28\u3002\u5e73\u5747\u6bcf\u4e2a\u79cd\u5b50\u6587\u4ef6\u751f\u6210\u4e86103.25\u4e2a\u65b0\u731c\u60f3\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u521b\u5efa\u5b9a\u7406\u8bc1\u660e\u7cfb\u7edf\u7684\u8bad\u7ec3\u6570\u636e\u3002", "conclusion": "LeanConjecturer\u5c55\u793a\u4e86\u4e00\u4e2a\u6210\u529f\u7684\u6848\u4f8b\uff0c\u5373\u5982\u4f55\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u89c4\u5219\u57fa\u7840\u65b9\u6cd5\u76f8\u7ed3\u5408\u7684\u65b9\u5f0f\uff0c\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6570\u5b66\u731c\u60f3\u3002\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u89e3\u51b3\u4e86\u5f62\u5f0f\u5316\u5b9a\u7406\u8bc1\u660e\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u8fd8\u5c55\u793a\u4e86\u5176\u5728\u6570\u5b66\u53d1\u73b0\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u90a3\u4e9b\u8d85\u8d8a\u73b0\u6709\u7ed3\u679c\u7b80\u5355\u53d8\u4f53\u7684\u9886\u57df\u3002\u672a\u6765\u7684\u7814\u7a76\u53ef\u4ee5\u8fdb\u4e00\u6b65\u4f18\u5316\u751f\u6210\u548c\u9a8c\u8bc1\u8fc7\u7a0b\uff0c\u63a2\u7d22\u66f4\u591a\u6570\u5b66\u9886\u57df\u7684\u5e94\u7528\u3002"}}
{"id": "2506.21788", "pdf": "https://arxiv.org/pdf/2506.21788", "abs": "https://arxiv.org/abs/2506.21788", "authors": ["Massimiliano Lupo Pasini", "Jong Youl Choi", "Pei Zhang", "Kshitij Mehta", "Rylie Weaver", "Ashwin M. Aji", "Karl W. Schulz", "Jorda Polo", "Prasanna Balaprakash"], "title": "Multi-task parallelism for robust pre-training of graph foundation models on multi-source, multi-fidelity atomistic modeling data", "categories": ["cs.LG", "cond-mat.mtrl-sci", "cs.AI", "physics.atm-clus", "68T07, 68T09", "I.2; I.2.5; I.2.11"], "comment": "15 pages, 4 figures, 2 tables", "summary": "Graph foundation models using graph neural networks promise sustainable,\nefficient atomistic modeling. To tackle challenges of processing multi-source,\nmulti-fidelity data during pre-training, recent studies employ multi-task\nlearning, in which shared message passing layers initially process input\natomistic structures regardless of source, then route them to multiple decoding\nheads that predict data-specific outputs. This approach stabilizes pre-training\nand enhances a model's transferability to unexplored chemical regions.\nPreliminary results on approximately four million structures are encouraging,\nyet questions remain about generalizability to larger, more diverse datasets\nand scalability on supercomputers. We propose a multi-task parallelism method\nthat distributes each head across computing resources with GPU acceleration.\nImplemented in the open-source HydraGNN architecture, our method was trained on\nover 24 million structures from five datasets and tested on the Perlmutter,\nAurora, and Frontier supercomputers, demonstrating efficient scaling on all\nthree highly heterogeneous super-computing architectures.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u4efb\u52a1\u5e76\u884c\u65b9\u6cd5\uff0c\u901a\u8fc7GPU\u52a0\u901f\u5c06\u6bcf\u4e2a\u89e3\u7801\u5934\u5206\u914d\u5230\u8ba1\u7b97\u8d44\u6e90\u4e0a\u3002\u8be5\u65b9\u6cd5\u5728\u5f00\u6e90HydraGNN\u67b6\u6784\u4e2d\u5b9e\u73b0\uff0c\u5e76\u5728\u4e09\u4e2a\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u8868\u73b0\u51fa\u826f\u597d\u7684\u6269\u5c55\u6027\u3002", "motivation": "\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u56fe\u57fa\u7840\u6a21\u578b\u4e3a\u53ef\u6301\u7eed\u3001\u9ad8\u6548\u7684\u539f\u5b50\u5efa\u6a21\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\u3002\u7136\u800c\uff0c\u5728\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5904\u7406\u591a\u6e90\u3001\u591a\u4fdd\u771f\u5ea6\u6570\u636e\u4ecd\u5b58\u5728\u6311\u6218\u3002\u73b0\u6709\u7814\u7a76\u91c7\u7528\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u4f46\u5176\u5728\u66f4\u5927\u3001\u66f4\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5728\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u7684\u53ef\u6269\u5c55\u6027\u4ecd\u6709\u5f85\u9a8c\u8bc1\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u4efb\u52a1\u5e76\u884c\u65b9\u6cd5\uff0c\u4f7f\u7528GPU\u52a0\u901f\u5c06\u6bcf\u4e2a\u89e3\u7801\u5934\u5206\u5e03\u5728\u8ba1\u7b97\u8d44\u6e90\u4e0a\u3002\u6b64\u65b9\u6cd5\u88ab\u5b9e\u73b0\u5728\u5f00\u6e90\u7684HydraGNN\u67b6\u6784\u4e2d\uff0c\u5e76\u5728\u8d85\u8fc72400\u4e07\u7ed3\u6784\u7684\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728Perlmutter\u3001Aurora\u548cFrontier\u4e09\u4e2a\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u5747\u5c55\u73b0\u51fa\u9ad8\u6548\u7684\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u9ad8\u5ea6\u5f02\u6784\u7684\u8d85\u7ea7\u8ba1\u7b97\u67b6\u6784\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u591a\u4efb\u52a1\u5e76\u884c\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u56fe\u57fa\u7840\u6a21\u578b\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5728\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u672a\u6765\u7684\u539f\u5b50\u5efa\u6a21\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6301\u3002"}}
{"id": "2506.22056", "pdf": "https://arxiv.org/pdf/2506.22056", "abs": "https://arxiv.org/abs/2506.22056", "authors": ["Xuan Zhang", "Ziyan Jiang", "Rui Meng", "Yifei Leng", "Zhenbang Xiao", "Zora Zhiruo Wang", "Yanyi Shang", "Dehan Kong"], "title": "Universal Retrieval for Multimodal Trajectory Modeling", "categories": ["cs.AI"], "comment": "18 pages, 3 figures, accepted by Workshop on Computer-use Agents @\n  ICML 2025", "summary": "Trajectory data, capturing human actions and environmental states across\nvarious modalities, holds significant potential for enhancing AI agent\ncapabilities, particularly in GUI environments. However, how to model the\nrepresentation of trajectory-level data presents a significant challenge that\nhas not been systematically addressed amid explosive trajectory data growth. In\nthis work, we introduce Multimodal Trajectory Retrieval, bridging the gap\nbetween universal retrieval and agent-centric trajectory modeling. We construct\nthe Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and\nstates across diverse real-world scenarios. Based on this, we present\nGAE-Bench, a benchmark containing a large number of trajectory-based retrieval\npairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework\nthat adopts vision-language models and incorporates optimized contrastive\nlearning through a token selection and the GradCache mechanism. Comprehensive\nevaluations across multiple datasets show that GAE-Retriever consistently\noutperforms strong baselines in retrieval recall, highlighting its\neffectiveness in advancing multimodal trajectory retrieval.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u591a\u6a21\u6001\u8f68\u8ff9\u68c0\u7d22\uff08Multimodal Trajectory Retrieval\uff09\uff0c\u901a\u8fc7\u6784\u5efa\u7edf\u4e00\u7684\u4ee3\u7406\u8f68\u8ff9\u6570\u636e\u96c6\uff08UATD\uff09\u548cGAE-Bench\u57fa\u51c6\uff0c\u4ee5\u53ca\u63d0\u51faGAE-Retriever\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8f68\u8ff9\u6570\u636e\u7684\u68c0\u7d22\u53ec\u56de\u7387\uff0c\u63a8\u52a8\u4e86AI\u4ee3\u7406\u5728GUI\u73af\u5883\u4e2d\u7684\u80fd\u529b\u53d1\u5c55\u3002", "motivation": "\u8f68\u8ff9\u6570\u636e\u80fd\u591f\u6355\u6349\u4eba\u7c7b\u884c\u4e3a\u548c\u73af\u5883\u72b6\u6001\uff0c\u5728\u589e\u5f3aAI\u4ee3\u7406\u80fd\u529b\uff08\u7279\u522b\u662f\u5728GUI\u73af\u5883\u4e2d\uff09\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002\u7136\u800c\uff0c\u5982\u4f55\u5bf9\u8f68\u8ff9\u7ea7\u6570\u636e\u8fdb\u884c\u5efa\u6a21\u4ecd\u7136\u662f\u4e00\u4e2a\u5c1a\u672a\u7cfb\u7edf\u89e3\u51b3\u7684\u91cd\u8981\u6311\u6218\u3002", "method": "1. \u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aUnified Agent Trajectory Dataset (UATD)\u7684\u6570\u636e\u96c6\uff0c\u5305\u542b\u6765\u81ea\u591a\u6837\u5316\u771f\u5b9e\u573a\u666f\u7684\u6ce8\u91ca\u6f14\u793a\u548c\u72b6\u6001\u3002\n2. \u63d0\u51fa\u4e86GAE-Bench\u57fa\u51c6\uff0c\u5305\u542b\u5927\u91cf\u57fa\u4e8e\u8f68\u8ff9\u7684\u68c0\u7d22\u5bf9\u3002\n3. \u8bbe\u8ba1\u4e86GAE-Retriever\u6846\u67b6\uff0c\u91c7\u7528\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u4ee4\u724c\u9009\u62e9\u548cGradCache\u673a\u5236\u4f18\u5316\u5bf9\u6bd4\u5b66\u4e60\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u8868\u660e\uff0cGAE-Retriever\u5728\u68c0\u7d22\u53ec\u56de\u7387\u4e0a\u6301\u7eed\u4f18\u4e8e\u5f3a\u5927\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u63a8\u8fdb\u591a\u6a21\u6001\u8f68\u8ff9\u68c0\u7d22\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u591a\u6a21\u6001\u8f68\u8ff9\u68c0\u7d22\u4e3a\u8fde\u63a5\u901a\u7528\u68c0\u7d22\u548c\u4ee5\u4ee3\u7406\u4e3a\u4e2d\u5fc3\u7684\u8f68\u8ff9\u5efa\u6a21\u63d0\u4f9b\u4e86\u6865\u6881\u3002\u6240\u63d0\u51fa\u7684GAE-Retriever\u6846\u67b6\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u6548\u679c\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2506.21797", "pdf": "https://arxiv.org/pdf/2506.21797", "abs": "https://arxiv.org/abs/2506.21797", "authors": ["Peihao Wang", "Zhangyang Wang"], "title": "Why Neural Network Can Discover Symbolic Structures with Gradient-based Training: An Algebraic and Geometric Foundation for Neurosymbolic Reasoning", "categories": ["cs.LG"], "comment": "International Conference on Neuro-symbolic Systems (NeuS), 2025", "summary": "We develop a theoretical framework that explains how discrete symbolic\nstructures can emerge naturally from continuous neural network training\ndynamics. By lifting neural parameters to a measure space and modeling training\nas Wasserstein gradient flow, we show that under geometric constraints, such as\ngroup invariance, the parameter measure $\\mu_t$ undergoes two concurrent\nphenomena: (1) a decoupling of the gradient flow into independent optimization\ntrajectories over some potential functions, and (2) a progressive contraction\non the degree of freedom. These potentials encode algebraic constraints\nrelevant to the task and act as ring homomorphisms under a commutative\nsemi-ring structure on the measure space. As training progresses, the network\ntransitions from a high-dimensional exploration to compositional\nrepresentations that comply with algebraic operations and exhibit a lower\ndegree of freedom. We further establish data scaling laws for realizing\nsymbolic tasks, linking representational capacity to the group invariance that\nfacilitates symbolic solutions. This framework charts a principled foundation\nfor understanding and designing neurosymbolic systems that integrate continuous\nlearning with discrete algebraic reasoning.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7406\u8bba\u6846\u67b6\uff0c\u89e3\u91ca\u4e86\u79bb\u6563\u7b26\u53f7\u7ed3\u6784\u5982\u4f55\u5728\u8fde\u7eed\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u52a8\u6001\u4e2d\u81ea\u7136\u51fa\u73b0\u3002\u901a\u8fc7\u5c06\u795e\u7ecf\u53c2\u6570\u63d0\u5347\u5230\u6d4b\u5ea6\u7a7a\u95f4\u5e76\u5efa\u6a21\u4e3aWasserstein\u68af\u5ea6\u6d41\uff0c\u5728\u51e0\u4f55\u7ea6\u675f\uff08\u5982\u7fa4\u4e0d\u53d8\u6027\uff09\u4e0b\uff0c\u53c2\u6570\u6d4b\u5ea6\u7ecf\u5386\u4e86\u4e24\u4e2a\u73b0\u8c61\uff1a(1) \u68af\u5ea6\u6d41\u5206\u89e3\u4e3a\u4e00\u4e9b\u52bf\u51fd\u6570\u4e0a\u7684\u72ec\u7acb\u4f18\u5316\u8f68\u8ff9\uff1b(2) \u81ea\u7531\u5ea6\u7684\u9010\u6b65\u6536\u7f29\u3002\u8fd9\u4e9b\u52bf\u51fd\u6570\u7f16\u7801\u4e0e\u4efb\u52a1\u76f8\u5173\u7684\u4ee3\u6570\u7ea6\u675f\uff0c\u5e76\u4f5c\u4e3a\u6d4b\u5ea6\u7a7a\u95f4\u4e0a\u4ea4\u6362\u534a\u73af\u7ed3\u6784\u4e0b\u7684\u73af\u540c\u6001\u3002\u968f\u7740\u8bad\u7ec3\u8fdb\u884c\uff0c\u7f51\u7edc\u4ece\u9ad8\u7ef4\u63a2\u7d22\u8fc7\u6e21\u5230\u7b26\u5408\u4ee3\u6570\u8fd0\u7b97\u7684\u7ec4\u5408\u8868\u793a\uff0c\u81ea\u7531\u5ea6\u964d\u4f4e\u3002\u6b64\u5916\uff0c\u8bba\u6587\u5efa\u7acb\u4e86\u5b9e\u73b0\u7b26\u53f7\u4efb\u52a1\u7684\u6570\u636e\u7f29\u653e\u5b9a\u5f8b\uff0c\u5c06\u8868\u793a\u80fd\u529b\u4e0e\u4fc3\u8fdb\u7b26\u53f7\u89e3\u7684\u7fa4\u4e0d\u53d8\u6027\u8054\u7cfb\u8d77\u6765\u3002\u8be5\u6846\u67b6\u4e3a\u7406\u89e3\u548c\u8bbe\u8ba1\u7ed3\u5408\u8fde\u7eed\u5b66\u4e60\u4e0e\u79bb\u6563\u4ee3\u6570\u63a8\u7406\u7684\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "\u7814\u7a76\u8005\u5e0c\u671b\u7406\u89e3\u79bb\u6563\u7b26\u53f7\u7ed3\u6784\u5982\u4f55\u80fd\u4ece\u8fde\u7eed\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u81ea\u7136\u4ea7\u751f\uff0c\u4ece\u800c\u4e3a\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\u7684\u7406\u8bba\u57fa\u7840\u63d0\u4f9b\u652f\u6301\u3002\u8fd9\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u6574\u5408\u8fde\u7eed\u5b66\u4e60\u548c\u79bb\u6563\u4ee3\u6570\u63a8\u7406\uff0c\u63a8\u52a8\u795e\u7ecf\u7f51\u7edc\u5728\u7b26\u53f7\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u7814\u7a76\u8005\u901a\u8fc7\u5c06\u795e\u7ecf\u7f51\u7edc\u53c2\u6570\u6620\u5c04\u5230\u6d4b\u5ea6\u7a7a\u95f4\uff0c\u5e76\u5c06\u8bad\u7ec3\u8fc7\u7a0b\u5efa\u6a21\u4e3aWasserstein\u68af\u5ea6\u6d41\u6765\u5206\u6790\u5176\u52a8\u6001\u7279\u6027\u3002\u5728\u51e0\u4f55\u7ea6\u675f\uff08\u5982\u7fa4\u4e0d\u53d8\u6027\uff09\u4e0b\uff0c\u7814\u7a76\u8005\u53d1\u73b0\u53c2\u6570\u6d4b\u5ea6\u7ecf\u5386\u4e86\u4e24\u79cd\u73b0\u8c61\uff1a\u68af\u5ea6\u6d41\u7684\u5206\u89e3\u548c\u81ea\u7531\u5ea6\u7684\u6536\u7f29\u3002\u8fdb\u4e00\u6b65\u5730\uff0c\u7814\u7a76\u8005\u5efa\u7acb\u4e86\u6570\u636e\u7f29\u653e\u5b9a\u5f8b\u4ee5\u8fde\u63a5\u8868\u793a\u80fd\u529b\u548c\u7fa4\u4e0d\u53d8\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u7279\u5b9a\u51e0\u4f55\u7ea6\u675f\u4e0b\uff0c\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u52a8\u6001\u53ef\u4ee5\u5bfc\u81f4\u79bb\u6563\u7b26\u53f7\u7ed3\u6784\u7684\u81ea\u7136\u51fa\u73b0\u3002\u7f51\u7edc\u4ece\u9ad8\u7ef4\u63a2\u7d22\u9010\u6e10\u8fc7\u6e21\u5230\u5177\u6709\u8f83\u4f4e\u81ea\u7531\u5ea6\u7684\u7ec4\u5408\u8868\u793a\uff0c\u8fd9\u4e9b\u8868\u793a\u7b26\u5408\u4ee3\u6570\u8fd0\u7b97\u89c4\u5219\u3002\u5e76\u4e14\uff0c\u8868\u793a\u80fd\u529b\u4e0e\u7fa4\u4e0d\u53d8\u6027\u4e4b\u95f4\u5b58\u5728\u660e\u786e\u5173\u7cfb\uff0c\u80fd\u591f\u4fc3\u8fdb\u7b26\u53f7\u4efb\u52a1\u7684\u5b9e\u73b0\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u7406\u89e3\u79bb\u6563\u7b26\u53f7\u7ed3\u6784\u5728\u8fde\u7eed\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u4e2d\u7684\u81ea\u7136\u5f62\u6210\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002\u8fd9\u4e00\u6846\u67b6\u4e0d\u4ec5\u6709\u52a9\u4e8e\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u795e\u7ecf\u7b26\u53f7\u7cfb\u7edf\uff0c\u8fd8\u4e3a\u7ed3\u5408\u8fde\u7eed\u5b66\u4e60\u548c\u79bb\u6563\u4ee3\u6570\u63a8\u7406\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u7684\u6307\u5bfc\u3002"}}
{"id": "2506.22068", "pdf": "https://arxiv.org/pdf/2506.22068", "abs": "https://arxiv.org/abs/2506.22068", "authors": ["Shengyue Yao", "Runqing Guo", "Yangyang Qin", "Miangbing Meng", "Jipeng Cao", "Yilun Lin", "Yisheng Lv", "Fei-Yue Wang"], "title": "Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios", "categories": ["cs.AI"], "comment": "Submitted to IEEE Transaction on Vehicular Technology", "summary": "With the deep penetration of Artificial Intelligence (AI) in the\ntransportation sector, intelligent cockpits, autonomous driving, and\nintelligent road networks are developing at an unprecedented pace. However, the\ndata ecosystems of these three key areas are increasingly fragmented and\nincompatible. Especially, existing testing methods rely on data stacking, fail\nto cover all edge cases, and lack flexibility. To address this issue, this\npaper introduces the concept of \"Query as Test\" (QaT). This concept shifts the\nfocus from rigid, prescripted test cases to flexible, on-demand logical queries\nagainst a unified data representation. Specifically, we identify the need for a\nfundamental improvement in data storage and representation, leading to our\nproposal of \"Extensible Scenarios Notations\" (ESN). ESN is a novel declarative\ndata framework based on Answer Set Programming (ASP), which uniformly\nrepresents heterogeneous multimodal data from the cockpit, vehicle, and road as\na collection of logical facts and rules. This approach not only achieves deep\nsemantic fusion of data, but also brings three core advantages: (1) supports\ncomplex and flexible semantic querying through logical reasoning; (2) provides\nnatural interpretability for decision-making processes; (3) allows for\non-demand data abstraction through logical rules, enabling fine-grained privacy\nprotection. We further elaborate on the QaT paradigm, transforming the\nfunctional validation and safety compliance checks of autonomous driving\nsystems into logical queries against the ESN database, significantly enhancing\nthe expressiveness and formal rigor of the testing. Finally, we introduce the\nconcept of \"Validation-Driven Development\" (VDD), which suggests to guide\ndevelopments by logical validation rather than quantitative testing in the era\nof Large Language Models, in order to accelerating the iteration and\ndevelopment process.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86Query as Test\uff08QaT\uff09\u7684\u6982\u5ff5\uff0c\u901a\u8fc7\u7edf\u4e00\u7684\u6570\u636e\u8868\u793a\u548c\u903b\u8f91\u67e5\u8be2\u6765\u6d4b\u8bd5\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\uff0c\u5e76\u5f15\u5165\u4e86Extensible Scenarios Notations\uff08ESN\uff09\u6846\u67b6\u548cValidation-Driven Development\uff08VDD\uff09\u6982\u5ff5\uff0c\u4ee5\u63d0\u5347\u6d4b\u8bd5\u7684\u7075\u6d3b\u6027\u3001\u89e3\u91ca\u6027\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5728\u4ea4\u901a\u9886\u57df\u7684\u6df1\u5165\u5e94\u7528\uff0c\u667a\u80fd\u5ea7\u8231\u3001\u81ea\u52a8\u9a7e\u9a76\u548c\u667a\u80fd\u8def\u7f51\u4e09\u4e2a\u5173\u952e\u9886\u57df\u7684\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u5176\u6570\u636e\u751f\u6001\u7cfb\u7edf\u5374\u65e5\u76ca\u788e\u7247\u5316\u4e14\u4e0d\u517c\u5bb9\u3002\u73b0\u6709\u7684\u6d4b\u8bd5\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6570\u636e\u5806\u53e0\uff0c\u65e0\u6cd5\u8986\u76d6\u6240\u6709\u8fb9\u7f18\u60c5\u51b5\uff0c\u7f3a\u4e4f\u7075\u6d3b\u6027\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201cQuery as Test\u201d\uff08QaT\uff09\u7684\u65b0\u6982\u5ff5\uff0c\u5c06\u529f\u80fd\u9a8c\u8bc1\u548c\u5b89\u5168\u5408\u89c4\u6027\u68c0\u67e5\u8f6c\u5316\u4e3a\u5bf9\u7edf\u4e00\u6570\u636e\u8868\u793a\u7684\u903b\u8f91\u67e5\u8be2\uff1b\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u578b\u58f0\u660e\u5f0f\u6570\u636e\u6846\u67b6\u201cExtensible Scenarios Notations\u201d\uff08ESN\uff09\uff0c\u57fa\u4e8eAnswer Set Programming\uff08ASP\uff09\uff0c\u80fd\u591f\u7edf\u4e00\u8868\u793a\u6765\u81ea\u5ea7\u8231\u3001\u8f66\u8f86\u548c\u9053\u8def\u7684\u5f02\u6784\u591a\u6a21\u6001\u6570\u636e\uff1b\u8fd8\u4ecb\u7ecd\u4e86\u201cValidation-Driven Development\u201d\uff08VDD\uff09\u7406\u5ff5\uff0c\u5021\u5bfc\u4ee5\u903b\u8f91\u9a8c\u8bc1\u5f15\u5bfc\u5f00\u53d1\u800c\u975e\u4f20\u7edf\u7684\u5b9a\u91cf\u6d4b\u8bd5\u3002", "result": "\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u6570\u636e\u7684\u6df1\u5ea6\u8bed\u4e49\u878d\u5408\uff0c\u8fd8\u5e26\u6765\u4e86\u4e09\u5927\u6838\u5fc3\u4f18\u52bf\uff1a\u652f\u6301\u590d\u6742\u7075\u6d3b\u7684\u8bed\u4e49\u67e5\u8be2\u3001\u63d0\u4f9b\u51b3\u7b56\u8fc7\u7a0b\u7684\u81ea\u7136\u53ef\u89e3\u91ca\u6027\u3001\u4ee5\u53ca\u901a\u8fc7\u903b\u8f91\u89c4\u5219\u5b9e\u73b0\u6309\u9700\u6570\u636e\u62bd\u8c61\u4ece\u800c\u4fdd\u969c\u9690\u79c1\u4fdd\u62a4\u3002\u6b64\u5916\uff0cQaT\u8303\u5f0f\u663e\u8457\u589e\u5f3a\u4e86\u6d4b\u8bd5\u7684\u8868\u8fbe\u80fd\u529b\u548c\u5f62\u5f0f\u4e25\u8c28\u6027\u3002", "conclusion": "QaT\u3001ESN\u548cVDD\u5171\u540c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u529f\u80fd\u9a8c\u8bc1\u548c\u5b89\u5168\u6027\u68c0\u67e5\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u3001\u66f4\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u52a0\u901f\u8fed\u4ee3\u548c\u5f00\u53d1\u8fc7\u7a0b\u3002"}}
{"id": "2506.21833", "pdf": "https://arxiv.org/pdf/2506.21833", "abs": "https://arxiv.org/abs/2506.21833", "authors": ["Kunjal Panchal", "Sunav Choudhary", "Yuriy Brun", "Hui Guan"], "title": "The Cost of Avoiding Backpropagation", "categories": ["cs.LG"], "comment": null, "summary": "Forward-mode automatic differentiation (FmAD) and zero-order (ZO)\noptimization have been proposed as memory-efficient alternatives to\nbackpropagation (BP) for gradient computation, especially in low-resource\nsettings. However, their practical benefits remain unclear due to two key gaps:\na lack of comparison against memory-efficient BP variants, such as activation\ncheckpointing, and a lack of a unified theoretical analysis. This work presents\na comprehensive theoretical and empirical comparison of BP, FmAD, and ZO\nmethods. Our theoretical analysis shows that while FmAD, and ZO can reduce\nmemory usage, they incur significant costs in accuracy, convergence speed, and\ncomputation compared to BP with checkpointing. These drawbacks worsen with\nlarger models or constrained perturbation budgets. Empirical experiments on\nlarge language and vision-language models show that BP with checkpointing\noutperforms FmAD and ZO variants, including those enhanced with variance\nreduction, achieving up to 31.1% higher accuracy, 34.8% faster convergence, and\n3.8x fewer computations at comparable memory usage. Our results highlight\nfundamental limitations of FmAD and ZO, and reaffirm BP with checkpointing as\nthe most effective strategy for model training under memory-constrained\nsettings. Our code is available at\nhttps://github.com/Astuary/The_Cost_of_Avoiding_Backpropagation.", "AI": {"tldr": "\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\uff0c\u524d\u5411\u6a21\u5f0f\u81ea\u52a8\u5fae\u5206(FmAD)\u548c\u96f6\u9636(ZO)\u4f18\u5316\u88ab\u63d0\u51fa\u4f5c\u4e3a\u53cd\u5411\u4f20\u64ad(BP)\u7684\u5185\u5b58\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\u3002\u7136\u800c\uff0c\u7531\u4e8e\u7f3a\u4e4f\u4e0e\u9ad8\u6548\u7684BP\u53d8\u4f53\uff08\u5982\u6fc0\u6d3b\u68c0\u67e5\u70b9\uff09\u7684\u6bd4\u8f83\u4ee5\u53ca\u7edf\u4e00\u7684\u7406\u8bba\u5206\u6790\uff0c\u5176\u5b9e\u9645\u4f18\u52bf\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u6587\u901a\u8fc7\u7406\u8bba\u548c\u5b9e\u8bc1\u7814\u7a76\u5bf9\u6bd4\u4e86BP\u3001FmAD\u548cZO\u65b9\u6cd5\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5c3d\u7ba1FmAD\u548cZO\u53ef\u4ee5\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\uff0c\u4f46\u5b83\u4eec\u5728\u7cbe\u5ea6\u3001\u6536\u655b\u901f\u5ea6\u548c\u8ba1\u7b97\u6210\u672c\u4e0a\u663e\u8457\u900a\u8272\u4e8e\u5e26\u6709\u68c0\u67e5\u70b9\u7684BP\uff0c\u4e14\u968f\u7740\u6a21\u578b\u589e\u5927\u6216\u6270\u52a8\u9884\u7b97\u53d7\u9650\uff0c\u8fd9\u79cd\u52a3\u52bf\u66f4\u52a0\u660e\u663e\u3002\u5b9e\u9a8c\u663e\u793a\uff0c\u5728\u76f8\u4f3c\u5185\u5b58\u6d88\u8017\u4e0b\uff0c\u5e26\u6709\u68c0\u67e5\u70b9\u7684BP\u6bd4FmAD\u548cZO\u53d8\u4f53\u8868\u73b0\u66f4\u4f18\uff0c\u5305\u62ec\u90a3\u4e9b\u91c7\u7528\u65b9\u5dee\u7f29\u51cf\u6280\u672f\u7684\u53d8\u4f53\uff0c\u6700\u9ad8\u53ef\u63d0\u534731.1%\u7684\u7cbe\u5ea6\u3001\u52a0\u901f34.8%\u7684\u6536\u655b\uff0c\u5e76\u51cf\u5c113.8\u500d\u7684\u8ba1\u7b97\u91cf\u3002\u8fd9\u7a81\u663e\u4e86FmAD\u548cZO\u7684\u6839\u672c\u5c40\u9650\u6027\uff0c\u540c\u65f6\u518d\u6b21\u786e\u8ba4\u4e86\u5e26\u6709\u68c0\u67e5\u70b9\u7684BP\u662f\u5728\u5185\u5b58\u53d7\u9650\u60c5\u51b5\u4e0b\u8bad\u7ec3\u6a21\u578b\u7684\u6700\u4f73\u7b56\u7565\u3002", "motivation": "\u4e3a\u4e86\u660e\u786eFmAD\u548cZO\u65b9\u6cd5\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u5b9e\u9645\u4f18\u52bf\uff0c\u5f25\u8865\u5176\u4e0e\u9ad8\u6548\u7684BP\u53d8\u4f53\uff08\u5982\u6fc0\u6d3b\u68c0\u67e5\u70b9\uff09\u4e4b\u95f4\u7f3a\u4e4f\u6bd4\u8f83\u4ee5\u53ca\u7edf\u4e00\u7406\u8bba\u5206\u6790\u7684\u7a7a\u767d\u3002", "method": "\u5bf9BP\u3001FmAD\u548cZO\u65b9\u6cd5\u8fdb\u884c\u5168\u9762\u7684\u7406\u8bba\u548c\u5b9e\u8bc1\u6bd4\u8f83\uff0c\u5305\u62ec\u5206\u6790\u5185\u5b58\u4f7f\u7528\u3001\u7cbe\u5ea6\u3001\u6536\u655b\u901f\u5ea6\u548c\u8ba1\u7b97\u6210\u672c\u7b49\u65b9\u9762\u7684\u5f71\u54cd\uff0c\u5e76\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8bc1\u660e\uff0cFmAD\u548cZO\u867d\u7136\u80fd\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\uff0c\u4f46\u5728\u7cbe\u5ea6\u3001\u6536\u655b\u901f\u5ea6\u548c\u8ba1\u7b97\u6210\u672c\u4e0a\u8fdc\u4e0d\u5982\u5e26\u6709\u68c0\u67e5\u70b9\u7684BP\uff0c\u4e14\u8fd9\u79cd\u5dee\u8ddd\u968f\u7740\u6a21\u578b\u89c4\u6a21\u589e\u5927\u6216\u6270\u52a8\u9884\u7b97\u53d7\u9650\u800c\u52a0\u5267\u3002\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86\u5e26\u6709\u68c0\u67e5\u70b9\u7684BP\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "FmAD\u548cZO\u5b58\u5728\u6839\u672c\u6027\u7684\u5c40\u9650\u6027\uff0c\u5728\u5185\u5b58\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u5e26\u6709\u68c0\u67e5\u70b9\u7684BP\u4ecd\u7136\u662f\u8bad\u7ec3\u6a21\u578b\u6700\u6709\u6548\u7684\u7b56\u7565\u3002"}}
{"id": "2506.22183", "pdf": "https://arxiv.org/pdf/2506.22183", "abs": "https://arxiv.org/abs/2506.22183", "authors": ["Camille Fran\u00e7ois", "Ludovic P\u00e9ran", "Ayah Bdeir", "Nouha Dziri", "Will Hawkins", "Yacine Jernite", "Sayash Kapoor", "Juliet Shen", "Heidy Khlaaf", "Kevin Klyman", "Nik Marda", "Marie Pellat", "Deb Raji", "Divya Siddarth", "Aviya Skowron", "Joseph Spisak", "Madhulika Srikumar", "Victor Storchan", "Audrey Tang", "Jen Weedon"], "title": "A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety", "categories": ["cs.AI"], "comment": "Proceedings from the Columbia Convening on Openness in Artificial\n  Intelligence and AI Safety", "summary": "The rapid rise of open-weight and open-source foundation models is\nintensifying the obligation and reshaping the opportunity to make AI systems\nsafe. This paper reports outcomes from the Columbia Convening on AI Openness\nand Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme\ninvolving more than forty-five researchers, engineers, and policy leaders from\nacademia, industry, civil society, and government. Using a participatory,\nsolutions-oriented process, the working groups produced (i) a research agenda\nat the intersection of safety and open source AI; (ii) a mapping of existing\nand needed technical interventions and open source tools to safely and\nresponsibly deploy open foundation models across the AI development workflow;\nand (iii) a mapping of the content safety filter ecosystem with a proposed\nroadmap for future research and development. We find that openness --\nunderstood as transparent weights, interoperable tooling, and public governance\n-- can enhance safety by enabling independent scrutiny, decentralized\nmitigation, and culturally plural oversight. However, significant gaps persist:\nscarce multimodal and multilingual benchmarks, limited defenses against\nprompt-injection and compositional attacks in agentic systems, and insufficient\nparticipatory mechanisms for communities most affected by AI harms. The paper\nconcludes with a roadmap of five priority research directions, emphasizing\nparticipatory inputs, future-proof content filters, ecosystem-wide safety\ninfrastructure, rigorous agentic safeguards, and expanded harm taxonomies.\nThese recommendations informed the February 2025 French AI Action Summit and\nlay groundwork for an open, plural, and accountable AI safety discipline.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e94\u4e2a\u4f18\u5148\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u63a8\u52a8\u5f00\u653e\u3001\u591a\u5143\u548c\u8d1f\u8d23\u4efb\u7684AI\u5b89\u5168\u5b66\u79d1\u7684\u53d1\u5c55\u3002", "motivation": "\u968f\u7740\u5f00\u6e90\u6743\u91cd\u548c\u5f00\u6e90\u57fa\u7840\u6a21\u578b\u7684\u8fc5\u901f\u5174\u8d77\uff0c\u786e\u4fddAI\u7cfb\u7edf\u5b89\u5168\u7684\u9700\u6c42\u6108\u53d1\u8feb\u5207\uff0c\u540c\u65f6\u8fd9\u4e5f\u5e26\u6765\u4e86\u65b0\u7684\u673a\u9047\u3002", "method": "\u901a\u8fc7\u53c2\u4e0e\u5f0f\u3001\u89e3\u51b3\u65b9\u6848\u5bfc\u5411\u7684\u8fc7\u7a0b\uff0c\u5de5\u4f5c\u5c0f\u7ec4\u5728\u5b89\u5168\u4e0e\u5f00\u6e90AI\u7684\u4ea4\u53c9\u70b9\u4e0a\u5236\u5b9a\u4e86\u7814\u7a76\u8bae\u7a0b\uff0c\u7ed8\u5236\u4e86\u73b0\u6709\u548c\u9700\u8981\u7684\u6280\u672f\u5e72\u9884\u53ca\u5f00\u6e90\u5de5\u5177\u56fe\u8c31\uff0c\u4ee5\u53ca\u5185\u5bb9\u5b89\u5168\u8fc7\u6ee4\u5668\u751f\u6001\u7cfb\u7edf\u7684\u6620\u5c04\u3002", "result": "\u53d1\u73b0\u5f00\u653e\u6027\uff08\u900f\u660e\u6743\u91cd\u3001\u4e92\u64cd\u4f5c\u5de5\u5177\u3001\u516c\u5171\u6cbb\u7406\uff09\u53ef\u4ee5\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u4f46\u4ecd\u7136\u5b58\u5728\u591a\u6a21\u6001\u548c\u591a\u8bed\u8a00\u57fa\u51c6\u4e0d\u8db3\u3001\u9488\u5bf9\u63d0\u793a\u6ce8\u5165\u548c\u7ec4\u5408\u653b\u51fb\u7684\u9632\u5fa1\u6709\u9650\u7b49\u95ee\u9898\u3002", "conclusion": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e94\u4e2a\u4f18\u5148\u7814\u7a76\u65b9\u5411\uff1a\u5f3a\u8c03\u591a\u65b9\u53c2\u4e0e\u3001\u672a\u6765\u9a8c\u8bc1\u7684\u5185\u5bb9\u8fc7\u6ee4\u5668\u3001\u5168\u751f\u6001\u7cfb\u7edf\u7684\u5b89\u5168\u57fa\u7840\u8bbe\u65bd\u3001\u4e25\u683c\u7684\u4ee3\u7406\u4fdd\u62a4\u63aa\u65bd\u548c\u6269\u5c55\u7684\u5371\u5bb3\u5206\u7c7b\u6cd5\u3002\u8fd9\u4e9b\u5efa\u8bae\u4e3a2025\u5e74\u6cd5\u56fdAI\u884c\u52a8\u5cf0\u4f1a\u63d0\u4f9b\u4e86\u4fe1\u606f\u652f\u6301\uff0c\u5e76\u4e3a\u5f00\u653e\u3001\u591a\u5143\u548c\u8d1f\u8d23\u4efb\u7684AI\u5b89\u5168\u5b66\u79d1\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.21844", "pdf": "https://arxiv.org/pdf/2506.21844", "abs": "https://arxiv.org/abs/2506.21844", "authors": ["Jun Ohkubo"], "title": "Koopman operator-based discussion on partial observation in stochastic systems", "categories": ["cs.LG"], "comment": "23 pages, 5 figures", "summary": "It is sometimes difficult to achieve a complete observation for a full set of\nobservables, and partial observations are necessary. For deterministic systems,\nthe Mori-Zwanzig formalism provides a theoretical framework for handling\npartial observations. Recently, data-driven algorithms based on the Koopman\noperator theory have made significant progress, and there is a discussion to\nconnect the Mori-Zwanzig formalism with the Koopman operator theory. In this\nwork, we discuss the effects of partial observation in stochastic systems using\nthe Koopman operator theory. The discussion clarifies the importance of\ndistinguishing the state space and the function space in stochastic systems.\nEven in stochastic systems, the delay embedding technique is beneficial for\npartial observation, and several numerical experiments showed a power-law\nbehavior of the accuracy for the amplitude of the additive noise. We also\ndiscuss the relation between the exponent of the power-law behavior and the\neffects of partial observation.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u968f\u673a\u7cfb\u7edf\u4e2d\u4f7f\u7528Koopman\u7b97\u5b50\u7406\u8bba\u5904\u7406\u90e8\u5206\u89c2\u6d4b\u7684\u6548\u679c\uff0c\u5f3a\u8c03\u4e86\u533a\u5206\u72b6\u6001\u7a7a\u95f4\u548c\u51fd\u6570\u7a7a\u95f4\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5ef6\u8fdf\u5d4c\u5165\u6280\u672f\u5bf9\u90e8\u5206\u89c2\u6d4b\u7684\u76ca\u5904\u3002\u6570\u503c\u5b9e\u9a8c\u63ed\u793a\u4e86\u52a0\u6027\u566a\u58f0\u5e45\u5ea6\u7cbe\u5ea6\u7684\u5e42\u5f8b\u884c\u4e3a\uff0c\u8fd8\u8ba8\u8bba\u4e86\u5e42\u5f8b\u884c\u4e3a\u6307\u6570\u4e0e\u90e8\u5206\u89c2\u6d4b\u5f71\u54cd\u7684\u5173\u7cfb\u3002", "motivation": "\u7531\u4e8e\u6709\u65f6\u96be\u4ee5\u5bf9\u5b8c\u6574\u7684\u4e00\u7ec4\u53ef\u89c2\u6d4b\u91cf\u8fdb\u884c\u5168\u9762\u89c2\u6d4b\uff0c\u56e0\u6b64\u9700\u8981\u8fdb\u884c\u90e8\u5206\u89c2\u6d4b\u3002\u5c3d\u7ba1\u786e\u5b9a\u6027\u7cfb\u7edf\u6709Mori-Zwanzig\u5f62\u5f0f\u4e3b\u4e49\u4f5c\u4e3a\u7406\u8bba\u6846\u67b6\uff0c\u4f46\u968f\u673a\u7cfb\u7edf\u4e2d\u7684\u90e8\u5206\u89c2\u6d4b\u4ecd\u9700\u8fdb\u4e00\u6b65\u63a2\u8ba8\uff0c\u5c24\u5176\u662f\u7ed3\u5408Koopman\u7b97\u5b50\u7406\u8bba\u7684\u60c5\u51b5\u3002", "method": "\u5229\u7528Koopman\u7b97\u5b50\u7406\u8bba\u7814\u7a76\u968f\u673a\u7cfb\u7edf\u4e2d\u7684\u90e8\u5206\u89c2\u6d4b\u6548\u679c\uff0c\u901a\u8fc7\u5ef6\u8fdf\u5d4c\u5165\u6280\u672f\u6765\u5904\u7406\u90e8\u5206\u89c2\u6d4b\u6570\u636e\uff0c\u5e76\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u5206\u6790\u52a0\u6027\u566a\u58f0\u5e45\u5ea6\u7cbe\u5ea6\u7684\u5e42\u5f8b\u884c\u4e3a\u3002", "result": "\u53d1\u73b0\u5ef6\u8fdf\u5d4c\u5165\u6280\u672f\u5728\u968f\u673a\u7cfb\u7edf\u4e2d\u5bf9\u90e8\u5206\u89c2\u6d4b\u6709\u76ca\uff1b\u6570\u503c\u5b9e\u9a8c\u663e\u793a\u52a0\u6027\u566a\u58f0\u5e45\u5ea6\u7cbe\u5ea6\u5448\u73b0\u5e42\u5f8b\u884c\u4e3a\uff1b\u5e42\u5f8b\u884c\u4e3a\u7684\u6307\u6570\u4e0e\u90e8\u5206\u89c2\u6d4b\u7684\u5f71\u54cd\u5b58\u5728\u5173\u7cfb\u3002", "conclusion": "\u5728\u968f\u673a\u7cfb\u7edf\u4e2d\uff0c\u90e8\u5206\u89c2\u6d4b\u53ef\u901a\u8fc7Koopman\u7b97\u5b50\u7406\u8bba\u6709\u6548\u5904\u7406\uff0c\u5ef6\u8fdf\u5d4c\u5165\u6280\u672f\u6709\u52a9\u4e8e\u63d0\u9ad8\u89c2\u6d4b\u6548\u679c\uff0c\u5e42\u5f8b\u884c\u4e3a\u53ef\u4f5c\u4e3a\u8bc4\u4f30\u90e8\u5206\u89c2\u6d4b\u5f71\u54cd\u7684\u4e00\u4e2a\u6307\u6807\u3002"}}
{"id": "2506.22271", "pdf": "https://arxiv.org/pdf/2506.22271", "abs": "https://arxiv.org/abs/2506.22271", "authors": ["Samy Badreddine", "Emile van Krieken", "Luciano Serafini"], "title": "Breaking Rank Bottlenecks in Knowledge Graph Completion", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Many Knowledge Graph Completion (KGC) models, despite using powerful\nencoders, rely on a simple vector-matrix multiplication to score queries\nagainst candidate object entities. When the number of entities is larger than\nthe model's embedding dimension, which in practical scenarios is often by\nseveral orders of magnitude, we have a linear output layer with a rank\nbottleneck. Such bottlenecked layers limit model expressivity. We investigate\nboth theoretically and empirically how rank bottlenecks affect KGC models. We\nfind that, by limiting the set of feasible predictions, rank bottlenecks hurt\nranking accuracy and the distribution fidelity of scores. Inspired by the\nlanguage modelling literature, we propose KGE-MoS, a mixture-based output layer\nto break rank bottlenecks in many KGC models. Our experiments on four datasets\nshow that KGE-MoS improves performance and probabilistic fit of KGC models for\na low parameter cost.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86\u79e9\u74f6\u9888\u5bf9\u77e5\u8bc6\u56fe\u8c31\u8865\u5168(KGC)\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u8f93\u51fa\u5c42\u7684\u65b9\u6cd5KGE-MoS\u4ee5\u89e3\u51b3\u8be5\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0cKGE-MoS\u5728\u4f4e\u53c2\u6570\u6210\u672c\u4e0b\u63d0\u9ad8\u4e86KGC\u6a21\u578b\u7684\u6027\u80fd\u548c\u6982\u7387\u62df\u5408\u3002", "motivation": "\u8bb8\u591a\u77e5\u8bc6\u56fe\u8c31\u8865\u5168\u6a21\u578b\u5c3d\u7ba1\u4f7f\u7528\u4e86\u5f3a\u5927\u7684\u7f16\u7801\u5668\uff0c\u4f46\u4f9d\u8d56\u4e8e\u7b80\u5355\u7684\u5411\u91cf-\u77e9\u9635\u4e58\u6cd5\u6765\u8bc4\u5206\u67e5\u8be2\u4e0e\u5019\u9009\u5bf9\u8c61\u5b9e\u4f53\u3002\u5f53\u5b9e\u4f53\u6570\u91cf\u5927\u4e8e\u6a21\u578b\u7684\u5d4c\u5165\u7ef4\u5ea6\u65f6\uff08\u8fd9\u79cd\u60c5\u51b5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7ecf\u5e38\u51fa\u73b0\uff09\uff0c\u7ebf\u6027\u8f93\u51fa\u5c42\u4f1a\u51fa\u73b0\u79e9\u74f6\u9888\uff0c\u9650\u5236\u6a21\u578b\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u7814\u7a76\u8005\u4ece\u7406\u8bba\u548c\u5b9e\u8bc1\u4e24\u65b9\u9762\u5206\u6790\u4e86\u79e9\u74f6\u9888\u5982\u4f55\u5f71\u54cdKGC\u6a21\u578b\uff0c\u5e76\u53d7\u8bed\u8a00\u5efa\u6a21\u6587\u732e\u542f\u53d1\uff0c\u63d0\u51fa\u4e86KGE-MoS\uff0c\u4e00\u79cd\u57fa\u4e8e\u6df7\u5408\u7684\u8f93\u51fa\u5c42\u65b9\u6cd5\uff0c\u7528\u4e8e\u6253\u7834KGC\u6a21\u578b\u4e2d\u7684\u79e9\u74f6\u9888\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cKGE-MoS\u63d0\u9ad8\u4e86KGC\u6a21\u578b\u7684\u6027\u80fd\u548c\u6982\u7387\u62df\u5408\uff0c\u4e14\u53c2\u6570\u6210\u672c\u8f83\u4f4e\u3002", "conclusion": "\u79e9\u74f6\u9888\u4f1a\u635f\u5bb3KGC\u6a21\u578b\u7684\u6392\u540d\u51c6\u786e\u6027\u548c\u5206\u6570\u5206\u5e03\u4fdd\u771f\u5ea6\uff0c\u800cKGE-MoS\u80fd\u591f\u6709\u6548\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002"}}
{"id": "2506.21872", "pdf": "https://arxiv.org/pdf/2506.21872", "abs": "https://arxiv.org/abs/2506.21872", "authors": ["Chaofan Pan", "Xin Yang", "Yanhua Li", "Wei Wei", "Tianrui Li", "Bo An", "Jiye Liang"], "title": "A Survey of Continual Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "This work has been submitted to the IEEE TPAMI", "summary": "Reinforcement Learning (RL) is an important machine learning paradigm for\nsolving sequential decision-making problems. Recent years have witnessed\nremarkable progress in this field due to the rapid development of deep neural\nnetworks. However, the success of RL currently relies on extensive training\ndata and computational resources. In addition, RL's limited ability to\ngeneralize across tasks restricts its applicability in dynamic and real-world\nenvironments. With the arisen of Continual Learning (CL), Continual\nReinforcement Learning (CRL) has emerged as a promising research direction to\naddress these limitations by enabling agents to learn continuously, adapt to\nnew tasks, and retain previously acquired knowledge. In this survey, we provide\na comprehensive examination of CRL, focusing on its core concepts, challenges,\nand methodologies. Firstly, we conduct a detailed review of existing works,\norganizing and analyzing their metrics, tasks, benchmarks, and scenario\nsettings. Secondly, we propose a new taxonomy of CRL methods, categorizing them\ninto four types from the perspective of knowledge storage and/or transfer.\nFinally, our analysis highlights the unique challenges of CRL and provides\npractical insights into future directions.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u6301\u7eed\u5f3a\u5316\u5b66\u4e60\uff08CRL\uff09\uff0c\u5305\u62ec\u5176\u6838\u5fc3\u6982\u5ff5\u3001\u6311\u6218\u548c\u65b9\u6cd5\u8bba\u3002\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684CRL\u65b9\u6cd5\u5206\u7c7b\uff0c\u5e76\u6307\u51fa\u4e86CRL\u7684\u72ec\u7279\u6311\u6218\u53ca\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u6210\u529f\u4f9d\u8d56\u4e8e\u5927\u91cf\u7684\u8bad\u7ec3\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u4e14\u5728\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u4e0a\u6709\u9650\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u52a8\u6001\u548c\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u5f15\u5165\u8fde\u7eed\u5b66\u4e60\uff08CL\uff09\u4ee5\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u4f7fCRL\u6210\u4e3a\u4e00\u4e2a\u6709\u524d\u666f\u7684\u7814\u7a76\u65b9\u5411\u3002", "method": "1. \u5bf9\u73b0\u6709\u7684CRL\u5de5\u4f5c\u8fdb\u884c\u8be6\u7ec6\u56de\u987e\uff0c\u5206\u6790\u5176\u6307\u6807\u3001\u4efb\u52a1\u3001\u57fa\u51c6\u548c\u573a\u666f\u8bbe\u7f6e\u3002\n2. \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684CRL\u65b9\u6cd5\u5206\u7c7b\u6cd5\uff0c\u4ece\u77e5\u8bc6\u5b58\u50a8\u548c/\u6216\u8f6c\u79fb\u7684\u89d2\u5ea6\u5c06\u5176\u5206\u4e3a\u56db\u79cd\u7c7b\u578b\u3002\n3. \u9610\u8ff0CRL\u7684\u6838\u5fc3\u6982\u5ff5\u3001\u6311\u6218\u548c\u65b9\u6cd5\u8bba\u3002", "result": "\u901a\u8fc7\u8be6\u7ec6\u7684\u5ba1\u67e5\u548c\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684CRL\u65b9\u6cd5\u5206\u7c7b\u6cd5\uff0c\u5e76\u660e\u786e\u4e86CRL\u6240\u9762\u4e34\u7684\u72ec\u7279\u6311\u6218\u3002", "conclusion": "CRL\u4e3a\u89e3\u51b3\u4f20\u7edfRL\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002\u5c3d\u7ba1\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u4f46\u8be5\u9886\u57df\u5177\u6709\u5e7f\u9614\u7684\u53d1\u5c55\u524d\u666f\u548c\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.22276", "pdf": "https://arxiv.org/pdf/2506.22276", "abs": "https://arxiv.org/abs/2506.22276", "authors": ["Reuth Mirsky"], "title": "Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates", "categories": ["cs.AI"], "comment": "Extended version of a paper accepted for publication in AI Magazine", "summary": "Artificial intelligence has made remarkable strides in recent years,\nachieving superhuman performance across a wide range of tasks. Yet despite\nthese advances, most cooperative AI systems remain rigidly obedient, designed\nto follow human instructions without question and conform to user expectations,\neven when doing so may be counterproductive or unsafe. This paper argues for\nexpanding the agency of AI teammates to include \\textit{intelligent\ndisobedience}, empowering them to make meaningful and autonomous contributions\nwithin human-AI teams. It introduces a scale of AI agency levels and uses\nrepresentative examples to highlight the importance and growing necessity of\ntreating AI autonomy as an independent research focus in cooperative settings.\nThe paper then explores how intelligent disobedience manifests across different\nautonomy levels and concludes by proposing initial boundaries and\nconsiderations for studying disobedience as a core capability of artificial\nagents.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u4eba\u673a\u534f\u4f5c\u4e2d\u6269\u5c55AI\u81ea\u4e3b\u6027\u7684\u5fc5\u8981\u6027\uff0c\u63d0\u51fa\u4e86'\u667a\u80fd\u4e0d\u670d\u4ece'\u7684\u6982\u5ff5\uff0c\u5e76\u901a\u8fc7\u4e0d\u540c\u81ea\u6cbb\u5c42\u7ea7\u7684\u5b9e\u4f8b\u5206\u6790\u5176\u8868\u73b0\u5f62\u5f0f\uff0c\u6700\u540e\u63d0\u51fa\u4e86\u7814\u7a76\u4e0d\u670d\u4ece\u884c\u4e3a\u4f5c\u4e3a\u4eba\u5de5\u4ee3\u7406\u6838\u5fc3\u80fd\u529b\u7684\u521d\u6b65\u754c\u9650\u548c\u8003\u8651\u56e0\u7d20\u3002", "motivation": "\u5c3d\u7ba1\u4eba\u5de5\u667a\u80fd\u5728\u8bb8\u591a\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u8d85\u4eba\u7684\u8868\u73b0\uff0c\u4f46\u5927\u591a\u6570\u5408\u4f5cAI\u7cfb\u7edf\u4ecd\u7136\u4e25\u683c\u9075\u5faa\u4eba\u7c7b\u6307\u4ee4\uff0c\u8fd9\u79cd\u65e0\u6761\u4ef6\u670d\u4ece\u53ef\u80fd\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u662f\u53cd\u751f\u4ea7\u529b\u6216\u4e0d\u5b89\u5168\u7684\u3002\u56e0\u6b64\uff0c\u9700\u8981\u91cd\u65b0\u601d\u8003AI\u5728\u56e2\u961f\u4e2d\u7684\u89d2\u8272\u548c\u81ea\u4e3b\u6027\u3002", "method": "\u8bba\u6587\u5f15\u5165\u4e86\u4e00\u4e2aAI\u81ea\u4e3b\u6027\u7b49\u7ea7\u5c3a\u5ea6\uff0c\u4f7f\u7528\u4ee3\u8868\u6027\u7684\u4f8b\u5b50\u6765\u8bf4\u660e\u5728\u4eba\u673a\u534f\u4f5c\u73af\u5883\u4e2d\u5c06AI\u81ea\u4e3b\u6027\u4f5c\u4e3a\u4e00\u4e2a\u72ec\u7acb\u7814\u7a76\u91cd\u70b9\u7684\u91cd\u8981\u6027\u3002\u7136\u540e\u63a2\u8ba8\u4e86\u667a\u80fd\u4e0d\u670d\u4ece\u5728\u4e0d\u540c\u81ea\u4e3b\u6027\u6c34\u5e73\u4e0a\u7684\u8868\u73b0\u5f62\u5f0f\u3002", "result": "\u8bba\u6587\u5c55\u793a\u4e86\u667a\u80fd\u4e0d\u670d\u4ece\u5728\u4e0d\u540c\u81ea\u4e3b\u6027\u6c34\u5e73\u4e0a\u7684\u5177\u4f53\u8868\u73b0\uff0c\u5e76\u5f3a\u8c03\u4e86\u5c06\u5176\u89c6\u4e3a\u4eba\u5de5\u4ee3\u7406\u6838\u5fc3\u80fd\u529b\u8fdb\u884c\u7814\u7a76\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u4f5c\u8005\u63d0\u51fa\u5e94\u5c06\u4e0d\u670d\u4ece\u884c\u4e3a\u7684\u7814\u7a76\u8bbe\u4e3a\u4e00\u4e2a\u72ec\u7acb\u9886\u57df\uff0c\u660e\u786e\u4e86\u521d\u6b65\u7684\u7814\u7a76\u8fb9\u754c\u548c\u6ce8\u610f\u4e8b\u9879\uff0c\u4ee5\u4fc3\u8fdb\u66f4\u6709\u6548\u3001\u66f4\u5b89\u5168\u7684\u4eba\u673a\u534f\u4f5c\u3002"}}
{"id": "2506.21899", "pdf": "https://arxiv.org/pdf/2506.21899", "abs": "https://arxiv.org/abs/2506.21899", "authors": ["Amara Zuffer", "Michael Burke", "Mehrtash Harandi"], "title": "Advancements and Challenges in Continual Reinforcement Learning: A Comprehensive Review", "categories": ["cs.LG"], "comment": "65 pages, 9 figures", "summary": "The diversity of tasks and dynamic nature of reinforcement learning (RL)\nrequire RL agents to be able to learn sequentially and continuously, a learning\nparadigm known as continuous reinforcement learning. This survey reviews how\ncontinual learning transforms RL agents into dynamic continual learners. This\nenables RL agents to acquire and retain useful and reusable knowledge\nseamlessly. The paper delves into fundamental aspects of continual\nreinforcement learning, exploring key concepts, significant challenges, and\nnovel methodologies. Special emphasis is placed on recent advancements in\ncontinual reinforcement learning within robotics, along with a succinct\noverview of evaluation environments utilized in prominent research,\nfacilitating accessibility for newcomers to the field. The review concludes\nwith a discussion on limitations and promising future directions, providing\nvaluable insights for researchers and practitioners alike.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86\u8fde\u7eed\u5f3a\u5316\u5b66\u4e60\u5982\u4f55\u5c06\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u667a\u80fd\u4f53\u8f6c\u5316\u4e3a\u52a8\u6001\u8fde\u7eed\u5b66\u4e60\u8005\uff0c\u5f3a\u8c03\u4e86\u673a\u5668\u4eba\u9886\u57df\u4e2d\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5e76\u4e3a\u65b0\u624b\u63d0\u4f9b\u4e86\u8bc4\u4f30\u73af\u5883\u7684\u7b80\u8981\u6982\u8ff0\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u4efb\u52a1\u7684\u591a\u6837\u6027\u548c\u52a8\u6001\u7279\u6027\u8981\u6c42\u667a\u80fd\u4f53\u80fd\u591f\u8fdb\u884c\u987a\u5e8f\u548c\u6301\u7eed\u7684\u5b66\u4e60\uff0c\u5373\u8fde\u7eed\u5f3a\u5316\u5b66\u4e60\u3002\u6b64\u9700\u6c42\u9a71\u52a8\u4e86\u5bf9\u8fde\u7eed\u5b66\u4e60\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u5e94\u7528\u7684\u7814\u7a76\u3002", "method": "\u672c\u6587\u901a\u8fc7\u56de\u987e\u8fde\u7eed\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u7840\u65b9\u9762\u3001\u5173\u952e\u6982\u5ff5\u3001\u4e3b\u8981\u6311\u6218\u548c\u65b0\u65b9\u6cd5\u6765\u5206\u6790\u8fd9\u4e00\u9886\u57df\u3002\u7279\u522b\u5173\u6ce8\u673a\u5668\u4eba\u9886\u57df\u7684\u6700\u65b0\u8fdb\u5c55\u53ca\u5e38\u7528\u8bc4\u4f30\u73af\u5883\u3002", "result": "\u8bfb\u8005\u53ef\u4ee5\u7406\u89e3\u8fde\u7eed\u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u672c\u539f\u7406\u53ca\u5176\u5728\u673a\u5668\u4eba\u9886\u57df\u7684\u5e94\u7528\uff0c\u540c\u65f6\u4e86\u89e3\u5f53\u524d\u9762\u4e34\u7684\u6311\u6218\u548c\u8bc4\u4f30\u624b\u6bb5\u3002", "conclusion": "\u5c3d\u7ba1\u8fde\u7eed\u5f3a\u5316\u5b66\u4e60\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u4ecd\u5b58\u5728\u5c40\u9650\u6027\u3002\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u5305\u62ec\u6539\u8fdb\u77e5\u8bc6\u4fdd\u7559\u4e0e\u83b7\u53d6\u7684\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5f00\u53d1\u66f4\u6709\u6548\u7684\u8bc4\u4f30\u6807\u51c6\u3002"}}
{"id": "2506.22309", "pdf": "https://arxiv.org/pdf/2506.22309", "abs": "https://arxiv.org/abs/2506.22309", "authors": ["Klara M. Gutekunst", "Dominik D\u00fcrrschnabel", "Johannes Hirth", "Gerd Stumme"], "title": "Conceptual Topic Aggregation", "categories": ["cs.AI", "cs.CL", "cs.DM", "cs.LG", "06B99", "I.2.4; I.2.7"], "comment": "16 pages, 4 tables, 11 figures, International Joint Conference on\n  Conceptual Knowledge Structures", "summary": "The vast growth of data has rendered traditional manual inspection\ninfeasible, necessitating the adoption of computational methods for efficient\ndata exploration. Topic modeling has emerged as a powerful tool for analyzing\nlarge-scale textual datasets, enabling the extraction of latent semantic\nstructures. However, existing methods for topic modeling often struggle to\nprovide interpretable representations that facilitate deeper insights into data\nstructure and content. In this paper, we propose FAT-CAT, an approach based on\nFormal Concept Analysis (FCA) to enhance meaningful topic aggregation and\nvisualization of discovered topics. Our approach can handle diverse topics and\nfile types -- grouped by directories -- to construct a concept lattice that\noffers a structured, hierarchical representation of their topic distribution.\nIn a case study on the ETYNTKE dataset, we evaluate the effectiveness of our\napproach against other representation methods to demonstrate that FCA-based\naggregation provides more meaningful and interpretable insights into dataset\ncomposition than existing topic modeling techniques.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6b63\u5f0f\u6982\u5ff5\u5206\u6790\uff08FCA\uff09\u7684\u65b9\u6cd5FAT-CAT\uff0c\u7528\u4e8e\u589e\u5f3a\u6709\u610f\u4e49\u7684\u4e3b\u9898\u805a\u5408\u548c\u53ef\u89c6\u5316\u3002\u8be5\u65b9\u6cd5\u5728\u6848\u4f8b\u7814\u7a76\u4e2d\u8868\u73b0\u51fa\u6bd4\u73b0\u6709\u4e3b\u9898\u5efa\u6a21\u6280\u672f\u66f4\u6709\u610f\u4e49\u548c\u53ef\u89e3\u91ca\u7684\u89c1\u89e3\u3002", "motivation": "\u6570\u636e\u91cf\u7684\u5feb\u901f\u589e\u957f\u4f7f\u5f97\u4f20\u7edf\u7684\u624b\u52a8\u68c0\u67e5\u53d8\u5f97\u4e0d\u53ef\u884c\uff0c\u9700\u8981\u91c7\u7528\u8ba1\u7b97\u65b9\u6cd5\u8fdb\u884c\u9ad8\u6548\u7684\u6570\u636e\u63a2\u7d22\u3002\u73b0\u6709\u7684\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u96be\u4ee5\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8868\u793a\uff0c\u9650\u5236\u4e86\u5bf9\u6570\u636e\u7ed3\u6784\u548c\u5185\u5bb9\u7684\u6df1\u5165\u6d1e\u5bdf\u3002", "method": "\u63d0\u51faFAT-CAT\u65b9\u6cd5\uff0c\u57fa\u4e8e\u6b63\u5f0f\u6982\u5ff5\u5206\u6790\uff08FCA\uff09\uff0c\u80fd\u591f\u5904\u7406\u591a\u6837\u5316\u7684\u4e3b\u9898\u548c\u6587\u4ef6\u7c7b\u578b\uff0c\u5e76\u901a\u8fc7\u6784\u5efa\u6982\u5ff5\u683c\u63d0\u4f9b\u4e3b\u9898\u5206\u5e03\u7684\u7ed3\u6784\u5316\u3001\u5206\u5c42\u8868\u793a\u3002", "result": "\u5728ETYNTKE\u6570\u636e\u96c6\u4e0a\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cFAT-CAT\u76f8\u8f83\u4e8e\u5176\u4ed6\u8868\u793a\u65b9\u6cd5\u63d0\u4f9b\u4e86\u66f4\u6709\u610f\u4e49\u548c\u53ef\u89e3\u91ca\u7684\u6570\u636e\u96c6\u7ec4\u6210\u89c1\u89e3\u3002", "conclusion": "FCA-based aggregation\u5728\u4e3b\u9898\u5efa\u6a21\u65b9\u9762\u53ef\u4ee5\u63d0\u4f9b\u66f4\u53ef\u89e3\u91ca\u7684\u8868\u793a\uff0c\u6709\u52a9\u4e8e\u66f4\u6df1\u5165\u5730\u7406\u89e3\u6570\u636e\u7ed3\u6784\u548c\u5185\u5bb9\u3002"}}
{"id": "2506.21900", "pdf": "https://arxiv.org/pdf/2506.21900", "abs": "https://arxiv.org/abs/2506.21900", "authors": ["Sheng Yun", "Jianhua Pei", "Ping Wang"], "title": "TOAST: Task-Oriented Adaptive Semantic Transmission over Dynamic Wireless Environments", "categories": ["cs.LG", "eess.IV"], "comment": null, "summary": "The evolution toward 6G networks demands a fundamental shift from bit-centric\ntransmission to semantic-aware communication that emphasizes task-relevant\ninformation. This work introduces TOAST (Task-Oriented Adaptive Semantic\nTransmission), a unified framework designed to address the core challenge of\nmulti-task optimization in dynamic wireless environments through three\ncomplementary components. First, we formulate adaptive task balancing as a\nMarkov decision process, employing deep reinforcement learning to dynamically\nadjust the trade-off between image reconstruction fidelity and semantic\nclassification accuracy based on real-time channel conditions. Second, we\nintegrate module-specific Low-Rank Adaptation (LoRA) mechanisms throughout our\nSwin Transformer-based joint source-channel coding architecture, enabling\nparameter-efficient fine-tuning that dramatically reduces adaptation overhead\nwhile maintaining full performance across diverse channel impairments including\nAdditive White Gaussian Noise (AWGN), fading, phase noise, and impulse\ninterference. Third, we incorporate an Elucidating diffusion model that\noperates in the latent space to restore features corrupted by channel noises,\nproviding substantial quality improvements compared to baseline approaches.\nExtensive experiments across multiple datasets demonstrate that TOAST achieves\nsuperior performance compared to baseline approaches, with significant\nimprovements in both classification accuracy and reconstruction quality at low\nSignal-to-Noise Ratio (SNR) conditions while maintaining robust performance\nacross all tested scenarios.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faTOAST\u6846\u67b6\uff0c\u901a\u8fc7\u4efb\u52a1\u5e73\u8861\u3001\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u548c\u6269\u6563\u6a21\u578b\u63d0\u5347\u591a\u4efb\u52a1\u4f18\u5316\u5728\u52a8\u6001\u65e0\u7ebf\u73af\u5883\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "6G\u7f51\u7edc\u7684\u53d1\u5c55\u8981\u6c42\u4ece\u4ee5\u6bd4\u7279\u4e3a\u4e2d\u5fc3\u7684\u4f20\u8f93\u8f6c\u5411\u5f3a\u8c03\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u7684\u8bed\u4e49\u611f\u77e5\u901a\u4fe1\u3002", "method": "1. \u5c06\u81ea\u9002\u5e94\u4efb\u52a1\u5e73\u8861\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u8c03\u6574\u56fe\u50cf\u91cd\u5efa\u4fdd\u771f\u5ea6\u4e0e\u8bed\u4e49\u5206\u7c7b\u51c6\u786e\u7387\u4e4b\u95f4\u7684\u6743\u8861\u30022. \u5728\u57fa\u4e8eSwin Transformer\u7684\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\u67b6\u6784\u4e2d\u96c6\u6210\u6a21\u5757\u7279\u5b9a\u7684\u4f4e\u79e9\u9002\u5e94(LoRA)\u673a\u5236\uff0c\u51cf\u5c11\u9002\u5e94\u5f00\u9500\u5e76\u7ef4\u6301\u5168\u6027\u80fd\u30023. \u5f15\u5165\u9610\u660e\u6027\u6269\u6563\u6a21\u578b\uff0c\u5728\u6f5c\u5728\u7a7a\u95f4\u6062\u590d\u53d7\u4fe1\u9053\u566a\u58f0\u5f71\u54cd\u7684\u7279\u5f81\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cTOAST\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u5206\u7c7b\u51c6\u786e\u6027\u548c\u91cd\u5efa\u8d28\u91cf\uff0c\u5e76\u5728\u6240\u6709\u6d4b\u8bd5\u573a\u666f\u4e2d\u4fdd\u6301\u7a33\u5065\u6027\u80fd\u3002", "conclusion": "TOAST\u6846\u67b6\u4e3a\u52a8\u6001\u65e0\u7ebf\u73af\u5883\u4e2d\u591a\u4efb\u52a1\u4f18\u5316\u7684\u6838\u5fc3\u6311\u6218\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u4f18\u8d8a\u6027\u80fd\u548c\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.22355", "pdf": "https://arxiv.org/pdf/2506.22355", "abs": "https://arxiv.org/abs/2506.22355", "authors": ["Pascale Fung", "Yoram Bachrach", "Asli Celikyilmaz", "Kamalika Chaudhuri", "Delong Chen", "Willy Chung", "Emmanuel Dupoux", "Herv\u00e9 J\u00e9gou", "Alessandro Lazaric", "Arjun Majumdar", "Andrea Madotto", "Franziska Meier", "Florian Metze", "Th\u00e9o Moutakanni", "Juan Pino", "Basile Terver", "Joseph Tighe", "Jitendra Malik"], "title": "Embodied AI Agents: Modeling the World", "categories": ["cs.AI"], "comment": null, "summary": "This paper describes our research on AI agents embodied in visual, virtual or\nphysical forms, enabling them to interact with both users and their\nenvironments. These agents, which include virtual avatars, wearable devices,\nand robots, are designed to perceive, learn and act within their surroundings,\nwhich makes them more similar to how humans learn and interact with the\nenvironments as compared to disembodied agents. We propose that the development\nof world models is central to reasoning and planning of embodied AI agents,\nallowing these agents to understand and predict their environment, to\nunderstand user intentions and social contexts, thereby enhancing their ability\nto perform complex tasks autonomously. World modeling encompasses the\nintegration of multimodal perception, planning through reasoning for action and\ncontrol, and memory to create a comprehensive understanding of the physical\nworld. Beyond the physical world, we also propose to learn the mental world\nmodel of users to enable better human-agent collaboration.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86\u4ee5\u89c6\u89c9\u3001\u865a\u62df\u6216\u5b9e\u4f53\u5f62\u5f0f\u5448\u73b0\u7684AI\u4ee3\u7406\u7684\u7814\u7a76\uff0c\u8fd9\u4e9b\u4ee3\u7406\u80fd\u591f\u4e0e\u7528\u6237\u53ca\u5176\u73af\u5883\u8fdb\u884c\u4ea4\u4e92\u3002\u63d0\u51fa\u4e16\u754c\u6a21\u578b\u7684\u53d1\u5c55\u662f\u5177\u8eabAI\u4ee3\u7406\u63a8\u7406\u548c\u89c4\u5212\u7684\u6838\u5fc3\uff0c\u5e76\u4e14\u8fd8\u63d0\u51fa\u4e86\u5b66\u4e60\u7528\u6237\u7684\u5fc3\u7406\u4e16\u754c\u6a21\u578b\u4ee5\u5b9e\u73b0\u66f4\u597d\u7684\u4eba\u673a\u534f\u4f5c\u3002", "motivation": "\u5f53\u524d\u7684AI\u4ee3\u7406\u5728\u4e0e\u73af\u5883\u548c\u7528\u6237\u4ea4\u4e92\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u5bf9\u73af\u5883\u7684\u7406\u89e3\u548c\u9884\u6d4b\u80fd\u529b\u4ee5\u53ca\u5bf9\u7528\u6237\u610f\u56fe\u548c\u793e\u4f1a\u80cc\u666f\u7684\u7406\u89e3\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u5177\u8eabAI\u4ee3\u7406\u53ca\u5176\u4e16\u754c\u6a21\u578b\u7684\u53d1\u5c55\u53d8\u5f97\u91cd\u8981\u3002", "method": "\u7814\u7a76\u5305\u62ec\u865a\u62df\u5316\u8eab\u3001\u53ef\u7a7f\u6234\u8bbe\u5907\u548c\u673a\u5668\u4eba\u7b49\u5177\u8eabAI\u4ee3\u7406\u7684\u8bbe\u8ba1\u548c\u5f00\u53d1\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u5468\u56f4\u73af\u5883\u4e2d\u611f\u77e5\u3001\u5b66\u4e60\u548c\u884c\u52a8\u3002\u901a\u8fc7\u53d1\u5c55\u4e16\u754c\u6a21\u578b\u6765\u589e\u5f3a\u8fd9\u4e9b\u4ee3\u7406\u7684\u7406\u89e3\u548c\u9884\u6d4b\u80fd\u529b\uff0c\u5305\u62ec\u7269\u7406\u4e16\u754c\u7684\u591a\u6a21\u6001\u611f\u77e5\u3001\u57fa\u4e8e\u63a8\u7406\u7684\u52a8\u4f5c\u548c\u63a7\u5236\u89c4\u5212\uff0c\u4ee5\u53ca\u521b\u5efa\u5bf9\u7269\u7406\u4e16\u754c\u7684\u5168\u9762\u7406\u89e3\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u5b66\u4e60\u7528\u6237\u7684\u5fc3\u7406\u4e16\u754c\u6a21\u578b\u4ee5\u4fc3\u8fdb\u4eba\u673a\u534f\u4f5c\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5177\u8eabAI\u4ee3\u7406\u901a\u8fc7\u53d1\u5c55\u4e16\u754c\u6a21\u578b\u53ef\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u548c\u9884\u6d4b\u5176\u73af\u5883\uff0c\u7406\u89e3\u7528\u6237\u610f\u56fe\u548c\u793e\u4f1a\u80cc\u666f\uff0c\u4ece\u800c\u63d0\u9ad8\u6267\u884c\u590d\u6742\u4efb\u52a1\u7684\u81ea\u4e3b\u80fd\u529b\u3002\u540c\u65f6\uff0c\u5b66\u4e60\u7528\u6237\u7684\u5fc3\u7406\u4e16\u754c\u6a21\u578b\u6709\u52a9\u4e8e\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u4eba\u673a\u534f\u4f5c\u3002", "conclusion": "\u5177\u8eabAI\u4ee3\u7406\u7684\u4e16\u754c\u6a21\u578b\u53d1\u5c55\u5bf9\u5176\u63a8\u7406\u3001\u89c4\u5212\u548c\u6267\u884c\u590d\u6742\u4efb\u52a1\u7684\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u53ef\u80fd\u5305\u62ec\u8fdb\u4e00\u6b65\u4f18\u5316\u4e16\u754c\u6a21\u578b\u7684\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u53ca\u6df1\u5316\u5bf9\u7528\u6237\u5fc3\u7406\u4e16\u754c\u6a21\u578b\u7684\u7406\u89e3\uff0c\u4ee5\u63a8\u52a8AI\u4ee3\u7406\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2506.21937", "pdf": "https://arxiv.org/pdf/2506.21937", "abs": "https://arxiv.org/abs/2506.21937", "authors": ["Marwan Ait Haddou", "Mohamed Bennai"], "title": "HQCM-EBTC: A Hybrid Quantum-Classical Model for Explainable Brain Tumor Classification", "categories": ["cs.LG"], "comment": null, "summary": "We propose HQCM-EBTC, a hybrid quantum-classical model for automated brain\ntumor classification using MRI images. Trained on a dataset of 7,576 scans\ncovering normal, meningioma, glioma, and pituitary classes, HQCM-EBTC\nintegrates a 5-qubit, depth-2 quantum layer with 5 parallel circuits, optimized\nvia AdamW and a composite loss blending cross-entropy and attention\nconsistency.\n  HQCM-EBTC achieves 96.48% accuracy, substantially outperforming the classical\nbaseline (86.72%). It delivers higher precision and F1-scores, especially for\nglioma detection. t-SNE projections reveal enhanced feature separability in\nquantum space, and confusion matrices show lower misclassification. Attention\nmap analysis (Jaccard Index) confirms more accurate and focused tumor\nlocalization at high-confidence thresholds.\n  These results highlight the promise of quantum-enhanced models in medical\nimaging, advancing both diagnostic accuracy and interpretability for clinical\nbrain tumor assessment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u6a21\u578bHQCM-EBTC\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u8111\u80bf\u7624\u5206\u7c7b\u3002\u8be5\u6a21\u578b\u5728\u5305\u542b\u6b63\u5e38\u3001\u8111\u819c\u7624\u3001\u80f6\u8d28\u7624\u548c\u5782\u4f53\u7624\u76847,576\u4e2a\u626b\u63cf\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\uff0c\u6574\u5408\u4e865-qubit\u6df1\u5ea62\u7684\u91cf\u5b50\u5c42\u4e0e5\u4e2a\u5e76\u884c\u7535\u8def\uff0c\u901a\u8fc7AdamW\u4f18\u5316\u5668\u548c\u7ec4\u5408\u635f\u5931\u51fd\u6570\u8fdb\u884c\u4f18\u5316\u3002HQCM-EBTC\u5728\u51c6\u786e\u7387\uff0896.48%\uff09\u3001\u7cbe\u786e\u5ea6\u548cF1\u5206\u6570\u4e0a\u663e\u8457\u4f18\u4e8e\u7ecf\u5178\u7684\u57fa\u7ebf\u6a21\u578b\uff0886.72%\uff09\uff0c\u7279\u522b\u662f\u5728\u80f6\u8d28\u7624\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002t-SNE\u6295\u5f71\u663e\u793a\u91cf\u5b50\u7a7a\u95f4\u4e2d\u7279\u5f81\u53ef\u5206\u79bb\u6027\u589e\u5f3a\uff0c\u6df7\u6dc6\u77e9\u9635\u8868\u660e\u8bef\u5206\u7c7b\u51cf\u5c11\u3002\u6ce8\u610f\u529b\u56fe\u5206\u6790\uff08Jaccard\u6307\u6570\uff09\u786e\u8ba4\u4e86\u9ad8\u7f6e\u4fe1\u9608\u503c\u4e0b\u7684\u66f4\u51c6\u786e\u548c\u805a\u7126\u7684\u80bf\u7624\u5b9a\u4f4d\u3002\u8fd9\u4e9b\u7ed3\u679c\u5c55\u793a\u4e86\u91cf\u5b50\u589e\u5f3a\u6a21\u578b\u5728\u533b\u5b66\u6210\u50cf\u4e2d\u7684\u6f5c\u529b\uff0c\u63d0\u9ad8\u4e86\u4e34\u5e8a\u8111\u80bf\u7624\u8bc4\u4f30\u7684\u8bca\u65ad\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u5f53\u524d\u8111\u80bf\u7624\u5206\u7c7b\u65b9\u6cd5\u53ef\u80fd\u9762\u4e34\u51c6\u786e\u6027\u4e0d\u8db3\u6216\u53ef\u89e3\u91ca\u6027\u8f83\u5dee\u7684\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u7c7b\u578b\u7684\u80bf\u7624\u5982\u80f6\u8d28\u7624\u7684\u68c0\u6d4b\u4e0a\u3002\u56e0\u6b64\uff0c\u63a2\u7d22\u4e00\u79cd\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u4f18\u52bf\u7684\u65b0\u578b\u6a21\u578b\uff0c\u4ee5\u63d0\u5347\u5206\u7c7b\u6027\u80fd\u548c\u8bca\u65ad\u89e3\u91ca\u6027\u6210\u4e3a\u7814\u7a76\u7684\u52a8\u673a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aHQCM-EBTC\u7684\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c065-qubit\u3001\u6df1\u5ea6\u4e3a2\u7684\u91cf\u5b50\u5c42\u4e0e5\u4e2a\u5e76\u884c\u91cf\u5b50\u7535\u8def\u76f8\u7ed3\u5408\uff0c\u5e76\u4f7f\u7528AdamW\u4f18\u5316\u5668\u548c\u878d\u5408\u4ea4\u53c9\u71b5\u4e0e\u6ce8\u610f\u529b\u4e00\u81f4\u6027\u7684\u590d\u5408\u635f\u5931\u51fd\u6570\u8fdb\u884c\u4f18\u5316\u3002\u6a21\u578b\u5728\u5305\u542b\u6b63\u5e38\u3001\u8111\u819c\u7624\u3001\u80f6\u8d28\u7624\u548c\u5782\u4f53\u7624\u76847,576\u4e2aMRI\u626b\u63cf\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bad\u7ec3\u3002", "result": "HQCM-EBTC\u6a21\u578b\u5728\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e8696.48%\u7684\u51c6\u786e\u7387\uff0c\u660e\u663e\u4f18\u4e8e\u7ecf\u5178\u57fa\u7ebf\u6a21\u578b\u768486.72%\u3002\u540c\u65f6\uff0c\u6a21\u578b\u5728\u6240\u6709\u7c7b\u522b\u4e2d\u5747\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7cbe\u786e\u5ea6\u548cF1\u5206\u6570\uff0c\u5c24\u5176\u5728\u80f6\u8d28\u7624\u68c0\u6d4b\u65b9\u9762\u6548\u679c\u663e\u8457\u3002\u6b64\u5916\uff0ct-SNE\u6295\u5f71\u663e\u793a\u91cf\u5b50\u7a7a\u95f4\u4e2d\u7684\u7279\u5f81\u53ef\u5206\u79bb\u6027\u589e\u5f3a\uff0c\u6df7\u6dc6\u77e9\u9635\u8868\u660e\u8bef\u5206\u7c7b\u60c5\u51b5\u51cf\u5c11\uff0c\u6ce8\u610f\u529b\u56fe\u5206\u6790\uff08Jaccard\u6307\u6570\uff09\u9a8c\u8bc1\u4e86\u6a21\u578b\u5728\u9ad8\u7f6e\u4fe1\u9608\u503c\u4e0b\u5177\u6709\u66f4\u51c6\u786e\u548c\u805a\u7126\u7684\u80bf\u7624\u5b9a\u4f4d\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u91cf\u5b50\u589e\u5f3a\u6a21\u578b\u5728\u533b\u5b66\u5f71\u50cf\u9886\u57df\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u63d0\u9ad8\u8111\u80bf\u7624\u8bca\u65ad\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u4e34\u5e8a\u8111\u80bf\u7624\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u6280\u672f\u624b\u6bb5\u3002"}}
{"id": "2506.22358", "pdf": "https://arxiv.org/pdf/2506.22358", "abs": "https://arxiv.org/abs/2506.22358", "authors": ["Varvara Kalokyri", "Nikolaos S. Tachos", "Charalampos N. Kalantzopoulos", "Stelios Sfakianakis", "Haridimos Kondylakis", "Dimitrios I. Zaridis", "Sara Colantonio", "Daniele Regge", "Nikolaos Papanikolaou", "The ProCAncer-I consortium", "Konstantinos Marias", "Dimitrios I. Fotiadis", "Manolis Tsiknakis"], "title": "AI Model Passport: Data and System Traceability Framework for Transparent AI in Health", "categories": ["cs.AI"], "comment": null, "summary": "The increasing integration of Artificial Intelligence (AI) into health and\nbiomedical systems necessitates robust frameworks for transparency,\naccountability, and ethical compliance. Existing frameworks often rely on\nhuman-readable, manual documentation which limits scalability, comparability,\nand machine interpretability across projects and platforms. They also fail to\nprovide a unique, verifiable identity for AI models to ensure their provenance\nand authenticity across systems and use cases, limiting reproducibility and\nstakeholder trust. This paper introduces the concept of the AI Model Passport,\na structured and standardized documentation framework that acts as a digital\nidentity and verification tool for AI models. It captures essential metadata to\nuniquely identify, verify, trace and monitor AI models across their lifecycle -\nfrom data acquisition and preprocessing to model design, development and\ndeployment. In addition, an implementation of this framework is presented\nthrough AIPassport, an MLOps tool developed within the ProCAncer-I EU project\nfor medical imaging applications. AIPassport automates metadata collection,\nensures proper versioning, decouples results from source scripts, and\nintegrates with various development environments. Its effectiveness is\nshowcased through a lesion segmentation use case using data from the\nProCAncer-I dataset, illustrating how the AI Model Passport enhances\ntransparency, reproducibility, and regulatory readiness while reducing manual\neffort. This approach aims to set a new standard for fostering trust and\naccountability in AI-driven healthcare solutions, aspiring to serve as the\nbasis for developing transparent and regulation compliant AI systems across\ndomains.", "AI": {"tldr": "The paper introduces AI Model Passport, a standardized documentation framework for AI models in healthcare that enhances transparency, reproducibility, and regulatory readiness. Implemented as AIPassport, it automates metadata collection and verification, demonstrated through a lesion segmentation case.", "motivation": "Current frameworks for documenting AI models lack scalability, comparability, machine interpretability, and the ability to provide verifiable identities, limiting reproducibility and trust.", "method": "Development of the AI Model Passport framework which captures essential metadata across the AI model lifecycle and its implementation via AIPassport, an MLOps tool.", "result": "AIPassport successfully automates metadata collection, ensures versioning, decouples results from scripts, and integrates with various environments. Demonstrated effectiveness in a lesion segmentation use case.", "conclusion": "AI Model Passport sets a new standard for trustworthy and accountable AI-driven healthcare solutions, promoting transparency and regulatory compliance."}}
{"id": "2506.21940", "pdf": "https://arxiv.org/pdf/2506.21940", "abs": "https://arxiv.org/abs/2506.21940", "authors": ["Marwan Ait Haddou", "Mohamed Bennai"], "title": "GuiderNet: A Meta-Learning Framework for Optimizing Quantum Circuit Geometry and Mitigating Barren Plateaus", "categories": ["cs.LG"], "comment": null, "summary": "Variational Quantum Algorithms (VQAs) offer potential for near-term quantum\nadvantage but face challenges from barren plateaus, where gradients vanish, and\npoorly conditioned optimization landscapes. We introduce GuiderNet, a\nmeta-learning framework that conditions Parameterized Quantum Circuits (PQCs)\nusing data-dependent parameter shifts aimed at minimizing the log condition\nnumber of the Fubini-Study metric tensor. Implemented as a classical neural\nnetwork, GuiderNet is meta-trained to guide PQC parameters into geometrically\nfavorable regions and is embedded within hybrid quantum-classical pipelines to\nsteer both initialization and adaptive modulation during training.\n  Applied to the Kaggle Diabetes classification task, GuiderNet reduces\ncumulative training loss by over 5x, improves test accuracy from 75.3% to\n98.6%, and increases the minority-class F1 score from 0.67 to 0.95. It also\nsuppresses gradient explosion and stabilizes parameter updates, enabling\nsmoother and more robust optimization. These results demonstrate that geometric\nmeta-conditioning can mitigate barren plateaus and ill-conditioning, providing\na scalable approach to enhance trainability and generalization in quantum\nmachine learning.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGuiderNet\u7684\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u51e0\u4f55\u5143\u8c03\u8282\u6765\u6539\u5584\u53c2\u6570\u5316\u91cf\u5b50\u7535\u8def\uff08PQCs\uff09\u7684\u8bad\u7ec3\u6027\u80fd\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u635f\u5931\u5e76\u63d0\u9ad8\u4e86\u6d4b\u8bd5\u51c6\u786e\u7387\u3002", "motivation": "\u53d8\u5206\u91cf\u5b50\u7b97\u6cd5\uff08VQAs\uff09\u5728\u8fd1\u671f\u91cf\u5b50\u4f18\u52bf\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u7740\u68af\u5ea6\u6d88\u5931\u548c\u4f18\u5316\u666f\u89c2\u6761\u4ef6\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "method": "\u5f15\u5165\u4e86GuiderNet\uff0c\u4e00\u79cd\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u6570\u636e\u4f9d\u8d56\u7684\u53c2\u6570\u79fb\u4f4d\u6765\u6700\u5c0f\u5316Fubini-Study\u5ea6\u91cf\u5f20\u91cf\u7684\u5bf9\u6570\u6761\u4ef6\u6570\uff0c\u5f15\u5bfcPQC\u53c2\u6570\u8fdb\u5165\u51e0\u4f55\u6709\u5229\u533a\u57df\uff0c\u5e76\u5d4c\u5165\u6df7\u5408\u91cf\u5b50-\u7ecf\u5178\u7ba1\u9053\u4e2d\u4ee5\u6307\u5bfc\u521d\u59cb\u5316\u548c\u81ea\u9002\u5e94\u8c03\u5236\u3002", "result": "\u5728Kaggle\u7cd6\u5c3f\u75c5\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cGuiderNet\u5c06\u7d2f\u79ef\u8bad\u7ec3\u635f\u5931\u51cf\u5c11\u4e865\u500d\u4ee5\u4e0a\uff0c\u5c06\u6d4b\u8bd5\u51c6\u786e\u7387\u4ece75.3%\u63d0\u9ad8\u523098.6%\uff0c\u5e76\u5c06\u5c11\u6570\u7c7bF1\u5206\u6570\u4ece0.67\u63d0\u9ad8\u52300.95\u3002\u540c\u65f6\uff0c\u5b83\u6291\u5236\u4e86\u68af\u5ea6\u7206\u70b8\u5e76\u7a33\u5b9a\u4e86\u53c2\u6570\u66f4\u65b0\uff0c\u4f7f\u4f18\u5316\u66f4\u5e73\u6ed1\u3001\u66f4\u7a33\u5065\u3002", "conclusion": "\u51e0\u4f55\u5143\u8c03\u8282\u53ef\u4ee5\u7f13\u89e3\u68af\u5ea6\u6d88\u5931\u548c\u4e0d\u826f\u6761\u4ef6\u95ee\u9898\uff0c\u4e3a\u589e\u5f3a\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u53ef\u8bad\u7ec3\u6027\u548c\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.22419", "pdf": "https://arxiv.org/pdf/2506.22419", "abs": "https://arxiv.org/abs/2506.22419", "authors": ["Bingchen Zhao", "Despoina Magka", "Minqi Jiang", "Xian Li", "Roberta Raileanu", "Tatiana Shavrina", "Jean-Christophe Gagnon-Audet", "Kelvin Niu", "Shagun Sodhani", "Michael Shvartsman", "Andrei Lupu", "Alisia Lupidi", "Edan Toledo", "Karen Hambardzumyan", "Martin Josifoski", "Thomas Foster", "Lucia Cipolina-Kun", "Abhishek Charnalia", "Derek Dunfield", "Alexander H. Miller", "Oisin Mac Aodha", "Jakob Foerster", "Yoram Bachrach"], "title": "The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Rapid advancements in large language models (LLMs) have the potential to\nassist in scientific progress. A critical capability toward this endeavor is\nthe ability to reproduce existing work. To evaluate the ability of AI agents to\nreproduce results in an active research area, we introduce the Automated LLM\nSpeedrunning Benchmark, leveraging the research community contributions on the\nNanoGPT speedrun, a competition to train a GPT-2 model in the shortest time.\nEach of the 19 speedrun tasks provides the agent with the previous records\ntraining script, optionally paired with one of three hint formats, ranging from\npseudocode to paper-like descriptions of the new records improvements. Records\nexecute quickly by design and speedrun improvements encompass diverse\ncode-level changes, ranging from high-level algorithmic advancements to\nhardware-aware optimizations. These features make the benchmark both accessible\nand realistic for the frontier problem of improving LLM training. We find that\nrecent reasoning LLMs combined with SoTA scaffolds struggle to reimplement\nalready-known innovations in our benchmark, even when given detailed hints. Our\nbenchmark thus provides a simple, non-saturated measure of an LLMs ability to\nautomate scientific reproduction, a necessary (but not sufficient) skill for an\nautonomous research agent.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u81ea\u52a8\u5316LLM\u901f\u901a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30AI\u4ee3\u7406\u5728\u79d1\u5b66\u9886\u57df\u91cd\u73b0\u5df2\u6709\u6210\u679c\u7684\u80fd\u529b\u3002\u5c3d\u7ba1\u7ed3\u5408\u6700\u5148\u8fdb\u6846\u67b6\u7684\u63a8\u7406LLM\u5728\u6709\u8be6\u7ec6\u63d0\u793a\u7684\u60c5\u51b5\u4e0b\u4ecd\u96be\u4ee5\u91cd\u73b0\u5df2\u77e5\u521b\u65b0\uff0c\u4f46\u8be5\u57fa\u51c6\u4e3a\u63d0\u5347LLM\u8bad\u7ec3\u63d0\u4f9b\u4e86\u7b80\u5355\u4e14\u73b0\u5b9e\u7684\u8861\u91cf\u6807\u51c6\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u5176\u5728\u63a8\u52a8\u79d1\u5b66\u7814\u7a76\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002\u5176\u4e2d\u5173\u952e\u80fd\u529b\u4e4b\u4e00\u662f\u80fd\u591f\u91cd\u73b0\u73b0\u6709\u5de5\u4f5c\u3002\u4e3a\u4e86\u8bc4\u4f30AI\u4ee3\u7406\u5728\u6d3b\u8dc3\u7814\u7a76\u9886\u57df\u4e2d\u91cd\u73b0\u7ed3\u679c\u7684\u80fd\u529b\uff0c\u9700\u8981\u8bbe\u8ba1\u4e00\u4e2a\u5408\u9002\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86\u81ea\u52a8\u5316LLM\u901f\u901a\u57fa\u51c6\u6d4b\u8bd5\uff08Automated LLM Speedrunning Benchmark\uff09\uff0c\u57fa\u4e8eNanoGPT\u901f\u901a\u7ade\u8d5b\uff0c\u6d89\u53ca19\u4e2a\u901f\u901a\u4efb\u52a1\u3002\u6bcf\u4e2a\u4efb\u52a1\u63d0\u4f9b\u5148\u524d\u8bb0\u5f55\u7684\u8bad\u7ec3\u811a\u672c\u4ee5\u53ca\u4e0d\u540c\u5f62\u5f0f\u7684\u63d0\u793a\uff08\u5982\u4f2a\u4ee3\u7801\u6216\u7c7b\u4f3c\u8bba\u6587\u7684\u63cf\u8ff0\uff09\u3002\u8fd9\u4e9b\u4efb\u52a1\u6db5\u76d6\u4e86\u4ece\u9ad8\u7ea7\u7b97\u6cd5\u6539\u8fdb\u5230\u786c\u4ef6\u4f18\u5316\u7684\u591a\u6837\u5316\u4ee3\u7801\u7ea7\u53d8\u66f4\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u7ed9\u51fa\u8be6\u7ec6\u63d0\u793a\uff0c\u6700\u8fd1\u7684\u63a8\u7406LLMs\u4e0e\u6700\u5148\u8fdb\u7684\u6846\u67b6\u7ed3\u5408\u65f6\uff0c\u4ecd\u7136\u96be\u4ee5\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u91cd\u65b0\u5b9e\u73b0\u5df2\u77e5\u7684\u521b\u65b0\u3002", "conclusion": "\u8be5\u57fa\u51c6\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u4e14\u975e\u9971\u548c\u7684\u5ea6\u91cf\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u81ea\u52a8\u5316\u79d1\u5b66\u91cd\u73b0\u7684\u80fd\u529b\uff0c\u8fd9\u662f\u81ea\u4e3b\u7814\u7a76\u4ee3\u7406\u6240\u9700\u7684\u57fa\u672c\u6280\u80fd\u4e4b\u4e00\u3002"}}
{"id": "2506.21952", "pdf": "https://arxiv.org/pdf/2506.21952", "abs": "https://arxiv.org/abs/2506.21952", "authors": ["Yangyang Wan", "Haotian Wang", "Xuhui Yu", "Jiageng Chen", "Xinyu Fan", "Zuyuan He"], "title": "Physics-informed network paradigm with data generation and background noise removal for diverse distributed acoustic sensing applications", "categories": ["cs.LG", "physics.app-ph", "physics.optics"], "comment": null, "summary": "Distributed acoustic sensing (DAS) has attracted considerable attention\nacross various fields and artificial intelligence (AI) technology plays an\nimportant role in DAS applications to realize event recognition and denoising.\nExisting AI models require real-world data (RWD), whether labeled or not, for\ntraining, which is contradictory to the fact of limited available event data in\nreal-world scenarios. Here, a physics-informed DAS neural network paradigm is\nproposed, which does not need real-world events data for training. By\nphysically modeling target events and the constraints of real world and DAS\nsystem, physical functions are derived to train a generative network for\ngeneration of DAS events data. DAS debackground net is trained by using the\ngenerated DAS events data to eliminate background noise in DAS data. The\neffectiveness of the proposed paradigm is verified in event identification\napplication based on a public dataset of DAS spatiotemporal data and in belt\nconveyor fault monitoring application based on DAS time-frequency data, and\nachieved comparable or better performance than data-driven networks trained\nwith RWD. Owing to the introduction of physical information and capability of\nbackground noise removal, the paradigm demonstrates generalization in same\napplication on different sites. A fault diagnosis accuracy of 91.8% is achieved\nin belt conveyor field with networks which transferred from simulation test\nsite without any fault events data of test site and field for training. The\nproposed paradigm is a prospective solution to address significant obstacles of\ndata acquisition and intense noise in practical DAS applications and explore\nmore potential fields for DAS.", "AI": {"tldr": "DAS\u5e94\u7528\u4e2d\uff0c\u6570\u636e\u83b7\u53d6\u56f0\u96be\u548c\u566a\u58f0\u5f3a\u662f\u91cd\u8981\u95ee\u9898\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684\u795e\u7ecf\u7f51\u7edc\u8303\u5f0f\uff0c\u65e0\u9700\u771f\u5b9e\u4e16\u754c\u4e8b\u4ef6\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u901a\u8fc7\u751f\u6210\u7f51\u7edc\u751f\u6210DAS\u4e8b\u4ef6\u6570\u636e\uff0c\u5e76\u4f7f\u7528\u53bb\u80cc\u666f\u7f51\u7edc\u6d88\u9664\u80cc\u666f\u566a\u58f0\u3002\u8be5\u65b9\u6cd5\u5728\u516c\u5171\u6570\u636e\u96c6\u548c\u8f93\u9001\u5e26\u6545\u969c\u76d1\u6d4b\u4e2d\u7684\u8868\u73b0\u4f18\u4e8e\u6216\u5ab2\u7f8e\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u6570\u636e\u8bad\u7ec3\u7684\u6570\u636e\u9a71\u52a8\u7f51\u7edc\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u8de8\u573a\u5730\u7684\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6ca1\u6709\u6d4b\u8bd5\u73b0\u573a\u6545\u969c\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u8be5\u65b9\u6cd5\u4ecd\u80fd\u8fbe\u523091.8%\u7684\u6545\u969c\u8bca\u65ad\u51c6\u786e\u7387\u3002", "motivation": "\u5206\u5e03\u5f0f\u58f0\u5b66\u4f20\u611f\uff08DAS\uff09\u5728\u591a\u4e2a\u9886\u57df\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\uff0c\u4f46\u5b9e\u9645\u573a\u666f\u4e2d\u53ef\u7528\u4e8b\u4ef6\u6570\u636e\u6709\u9650\uff0c\u4e14\u80cc\u666f\u566a\u58f0\u5f3a\u70c8\uff0c\u8fd9\u9650\u5236\u4e86AI\u6a21\u578b\u7684\u5e94\u7528\u6548\u679c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u4e0d\u4f9d\u8d56\u771f\u5b9e\u4e16\u754c\u6570\u636e\u7684\u8bad\u7ec3\u65b9\u6cd5\u6765\u89e3\u51b3\u6570\u636e\u83b7\u53d6\u548c\u566a\u58f0\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684DAS\u795e\u7ecf\u7f51\u7edc\u8303\u5f0f\uff1a\n1. \u901a\u8fc7\u5bf9\u76ee\u6807\u4e8b\u4ef6\u3001\u5b9e\u9645\u73af\u5883\u548cDAS\u7cfb\u7edf\u7684\u7269\u7406\u5efa\u6a21\uff0c\u63a8\u5bfc\u51fa\u7269\u7406\u51fd\u6570\u4ee5\u8bad\u7ec3\u751f\u6210\u7f51\u7edc\uff0c\u751f\u6210DAS\u4e8b\u4ef6\u6570\u636e\u3002\n2. \u4f7f\u7528\u751f\u6210\u7684DAS\u4e8b\u4ef6\u6570\u636e\u8bad\u7ec3\u53bb\u80cc\u666f\u7f51\u7edc\uff0c\u4ee5\u6d88\u9664DAS\u6570\u636e\u4e2d\u7684\u80cc\u666f\u566a\u58f0\u3002\n3. \u5728\u4e8b\u4ef6\u8bc6\u522b\u548c\u8f93\u9001\u5e26\u6545\u969c\u76d1\u6d4b\u5e94\u7528\u4e2d\u9a8c\u8bc1\u8be5\u8303\u5f0f\u7684\u6709\u6548\u6027\u3002", "result": "- \u5728\u516c\u5171DAS\u65f6\u7a7a\u6570\u636e\u96c6\u4e0a\u7684\u4e8b\u4ef6\u8bc6\u522b\u5e94\u7528\u4e2d\uff0c\u8868\u73b0\u4e0e\u57fa\u4e8e\u771f\u5b9e\u4e16\u754c\u6570\u636e\u8bad\u7ec3\u7684\u6570\u636e\u9a71\u52a8\u7f51\u7edc\u76f8\u5f53\u6216\u66f4\u597d\u3002\n- \u5728\u57fa\u4e8eDAS\u65f6\u9891\u6570\u636e\u7684\u8f93\u9001\u5e26\u6545\u969c\u76d1\u6d4b\u5e94\u7528\u4e2d\uff0c\u8fbe\u5230\u4e8691.8%\u7684\u6545\u969c\u8bca\u65ad\u51c6\u786e\u7387\u3002\n- \u5c55\u793a\u4e86\u5728\u4e0d\u540c\u573a\u5730\u95f4\u7684\u826f\u597d\u6cdb\u5316\u80fd\u529b\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u6d4b\u8bd5\u73b0\u573a\u6545\u969c\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u80fd\u53d6\u5f97\u9ad8\u7cbe\u5ea6\u7684\u7ed3\u679c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684DAS\u795e\u7ecf\u7f51\u7edc\u8303\u5f0f\u4e3a\u89e3\u51b3\u5b9e\u9645DAS\u5e94\u7528\u4e2d\u7684\u6570\u636e\u83b7\u53d6\u56f0\u96be\u548c\u5f3a\u566a\u58f0\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u6709\u671b\u63a2\u7d22\u66f4\u591aDAS\u7684\u6f5c\u5728\u5e94\u7528\u9886\u57df\u3002"}}
{"id": "2506.20893", "pdf": "https://arxiv.org/pdf/2506.20893", "abs": "https://arxiv.org/abs/2506.20893", "authors": ["Yian Wang", "Ali Ebrahimpour-Boroojeny", "Hari Sundaram"], "title": "On the Necessity of Output Distribution Reweighting for Effective Class Unlearning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this work, we introduce an output-reweighting unlearning method, RWFT, a\nlightweight technique that erases an entire class from a trained classifier\nwithout full retraining. Forgetting specific classes from trained models is\nessential for enforcing user deletion rights and mitigating harmful or biased\npredictions. The full retraining is costly and existing unlearning methods fail\nto replicate the behavior of the retrained models when predicting samples from\nthe unlearned class. We prove this failure by designing a variant of membership\ninference attacks, MIA-NN that successfully reveals the unlearned class for any\nof these methods. We propose a simple redistribution of the probability mass\nfor the prediction on the samples in the forgotten class which is robust to\nMIA-NN. We also introduce a new metric based on the total variation (TV)\ndistance of the prediction probabilities to quantify residual leakage to\nprevent future methods from susceptibility to the new attack. Through extensive\nexperiments with state of the art baselines in machine unlearning, we show that\nour approach matches the results of full retraining in both metrics used for\nevaluation by prior work and the new metric we propose in this work. Compare to\nstate-of-the-art methods, we gain 2.79% in previously used metrics and 111.45%\nin our new TV-based metric over the best existing method.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u8f93\u51fa\u91cd\u52a0\u6743\u9057\u5fd8\u65b9\u6cd5RWFT\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5728\u4e0d\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u4ece\u5df2\u8bad\u7ec3\u7684\u5206\u7c7b\u5668\u4e2d\u5220\u9664\u6574\u4e2a\u7c7b\u522b\u3002\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u57fa\u4e8e\u603b\u53d8\u5dee\u8ddd\u79bb\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u9632\u6b62\u6210\u5458\u63a8\u65ad\u653b\u51fb\u65b9\u9762\u6bd4\u73b0\u6709\u6280\u672f\u66f4\u6709\u6548\uff0c\u5e76\u4e14\u4e0e\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u7684\u7ed3\u679c\u76f8\u5f53\u3002", "motivation": "\u4ece\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u4e2d\u9057\u5fd8\u7279\u5b9a\u7c7b\u522b\u5bf9\u4e8e\u6267\u884c\u7528\u6237\u5220\u9664\u6743\u5229\u548c\u51cf\u8f7b\u6709\u5bb3\u6216\u6709\u504f\u5dee\u7684\u9884\u6d4b\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u6210\u672c\u9ad8\u6602\uff0c\u73b0\u6709\u7684\u9057\u5fd8\u65b9\u6cd5\u65e0\u6cd5\u5728\u9884\u6d4b\u672a\u5b66\u4e60\u7c7b\u522b\u7684\u6837\u672c\u65f6\u590d\u5236\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u7684\u884c\u4e3a\u3002", "method": "1. \u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6210\u5458\u63a8\u65ad\u653b\u51fb\u53d8\u4f53MIA-NN\uff0c\u7528\u4e8e\u63ed\u793a\u73b0\u6709\u9057\u5fd8\u65b9\u6cd5\u7684\u5931\u8d25\u3002\n2. \u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u7684\u6982\u7387\u8d28\u91cf\u91cd\u65b0\u5206\u5e03\u65b9\u6cd5\uff0c\u4ee5\u5bf9\u9057\u5fd8\u7c7b\u522b\u7684\u6837\u672c\u8fdb\u884c\u9884\u6d4b\uff0c\u8be5\u65b9\u6cd5\u5bf9MIA-NN\u5177\u6709\u9c81\u68d2\u6027\u3002\n3. \u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u603b\u53d8\u5dee\u8ddd\u79bb\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u7528\u4e8e\u91cf\u5316\u6b8b\u4f59\u6cc4\u6f0f\u5e76\u9632\u6b62\u672a\u6765\u65b9\u6cd5\u53d7\u5230\u65b0\u653b\u51fb\u7684\u5f71\u54cd\u3002", "result": "\u901a\u8fc7\u4e0e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u6bd4\u8f83\uff0c\u7ed3\u679c\u8868\u660e\uff1a\n- \u5728\u5148\u524d\u5de5\u4f5c\u4e2d\u4f7f\u7528\u7684\u8bc4\u4f30\u6307\u6807\u4e2d\uff0c\u8be5\u65b9\u6cd5\u7684\u8868\u73b0\u4e0e\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u76f8\u5f53\u3002\n- \u5728\u65b0\u63d0\u51fa\u7684TV-based\u5ea6\u91cf\u6807\u51c6\u4e2d\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\uff08\u5206\u522b\u63d0\u9ad8\u4e862.79%\u548c111.45%\uff09\u3002", "conclusion": "RWFT\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e0d\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u5730\u4ece\u5206\u7c7b\u5668\u4e2d\u5220\u9664\u7c7b\u522b\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2506.21956", "pdf": "https://arxiv.org/pdf/2506.21956", "abs": "https://arxiv.org/abs/2506.21956", "authors": ["Hao Jiang", "Yongxiang Tang", "Yanxiang Zeng", "Pengjia Yuan", "Yanhua Cheng", "Teng Sha", "Xialong Liu", "Peng Jiang"], "title": "Optimal Return-to-Go Guided Decision Transformer for Auto-Bidding in Advertisement", "categories": ["cs.LG"], "comment": null, "summary": "In the realm of online advertising, advertisers partake in ad auctions to\nobtain advertising slots, frequently taking advantage of auto-bidding tools\nprovided by demand-side platforms. To improve the automation of these bidding\nsystems, we adopt generative models, namely the Decision Transformer (DT), to\ntackle the difficulties inherent in automated bidding. Applying the Decision\nTransformer to the auto-bidding task enables a unified approach to sequential\nmodeling, which efficiently overcomes short-sightedness by capturing long-term\ndependencies between past bidding actions and user behavior. Nevertheless,\nconventional DT has certain drawbacks: (1) DT necessitates a preset\nreturn-to-go (RTG) value before generating actions, which is not inherently\nproduced; (2) The policy learned by DT is restricted by its training data,\nwhich is consists of mixed-quality trajectories. To address these challenges,\nwe introduce the R* Decision Transformer (R* DT), developed in a three-step\nprocess: (1) R DT: Similar to traditional DT, R DT stores actions based on\nstate and RTG value, as well as memorizing the RTG for a given state using the\ntraining set; (2) R^ DT: We forecast the highest value (within the training\nset) of RTG for a given state, deriving a suboptimal policy based on the\ncurrent state and the forecasted supreme RTG value; (3) R* DT: Based on R^ DT,\nwe generate trajectories and select those with high rewards (using a simulator)\nto augment our training dataset. This data enhancement has been shown to\nimprove the RTG of trajectories in the training data and gradually leads the\nsuboptimal policy towards optimality. Comprehensive tests on a publicly\navailable bidding dataset validate the R* DT's efficacy and highlight its\nsuperiority when dealing with mixed-quality trajectories.", "AI": {"tldr": "R* Decision Transformer (R* DT) \u662f\u4e00\u79cd\u6539\u8fdb\u7684\u51b3\u7b56\u53d8\u538b\u5668\u6a21\u578b\uff0c\u4e13\u4e3a\u5728\u7ebf\u5e7f\u544a\u4e2d\u7684\u81ea\u52a8\u7ade\u4ef7\u4efb\u52a1\u8bbe\u8ba1\u3002\u5b83\u901a\u8fc7\u4e09\u4e2a\u6b65\u9aa4\uff08R DT\u3001R^ DT \u548c R* DT\uff09\u514b\u670d\u4f20\u7edfDT\u6a21\u578b\u7684\u7f3a\u9677\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u751f\u6210\u9ad8\u8d28\u91cf\u8f68\u8ff9\u6765\u4f18\u5316\u8bad\u7ec3\u6570\u636e\u96c6\u3002\u5b9e\u9a8c\u8868\u660e\uff0cR* DT \u5728\u5904\u7406\u6df7\u5408\u8d28\u91cf\u8f68\u8ff9\u65f6\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5728\u7ebf\u5e7f\u544a\u4e2d\uff0c\u5e7f\u544a\u5546\u53c2\u4e0e\u5e7f\u544a\u4f4d\u62cd\u5356\u5e76\u4f7f\u7528\u9700\u6c42\u65b9\u5e73\u53f0\u63d0\u4f9b\u7684\u81ea\u52a8\u51fa\u4ef7\u5de5\u5177\u3002\u4e3a\u4e86\u63d0\u9ad8\u81ea\u52a8\u51fa\u4ef7\u7cfb\u7edf\u7684\u81ea\u52a8\u5316\u7a0b\u5ea6\uff0c\u9700\u8981\u89e3\u51b3\u4f20\u7edf\u51b3\u7b56\u53d8\u538b\u5668\uff08DT\uff09\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u4f8b\u5982\u9700\u8981\u9884\u8bbe\u56de\u62a5\u503c\uff08RTG\uff09\u4ee5\u53ca\u53d7\u6df7\u5408\u8d28\u91cf\u8f68\u8ff9\u7684\u9650\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e09\u6b65\u6cd5\uff1a1) R DT - \u7c7b\u4f3c\u4e8e\u4f20\u7edfDT\uff0c\u5b58\u50a8\u57fa\u4e8e\u72b6\u6001\u548cRTG\u7684\u52a8\u4f5c\uff1b2) R^ DT - \u9884\u6d4b\u7ed9\u5b9a\u72b6\u6001\u4e0bRTG\u7684\u6700\u5927\u503c\u4ee5\u63a8\u5bfc\u6b21\u4f18\u7b56\u7565\uff1b3) R* DT - \u751f\u6210\u8f68\u8ff9\u5e76\u901a\u8fc7\u6a21\u62df\u9009\u62e9\u9ad8\u5956\u52b1\u8f68\u8ff9\u4ee5\u589e\u5f3a\u8bad\u7ec3\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cR* DT \u80fd\u591f\u6539\u5584\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u8f68\u8ff9\u7684RTG\uff0c\u5e76\u9010\u6b65\u5f15\u5bfc\u6b21\u4f18\u7b56\u7565\u5411\u6700\u4f18\u7b56\u7565\u53d1\u5c55\u3002", "conclusion": "R* DT \u5728\u516c\u5f00\u7684\u7ade\u4ef7\u6570\u636e\u96c6\u4e0a\u7684\u5168\u9762\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u5c24\u5176\u5728\u5904\u7406\u6df7\u5408\u8d28\u91cf\u8f68\u8ff9\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.21976", "pdf": "https://arxiv.org/pdf/2506.21976", "abs": "https://arxiv.org/abs/2506.21976", "authors": ["Shuhan Tan", "John Lambert", "Hong Jeon", "Sakshum Kulshrestha", "Yijing Bai", "Jing Luo", "Dragomir Anguelov", "Mingxing Tan", "Chiyu Max Jiang"], "title": "SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.MA", "cs.RO"], "comment": "Accepted to CVPR 2025", "summary": "The goal of traffic simulation is to augment a potentially limited amount of\nmanually-driven miles that is available for testing and validation, with a much\nlarger amount of simulated synthetic miles. The culmination of this vision\nwould be a generative simulated city, where given a map of the city and an\nautonomous vehicle (AV) software stack, the simulator can seamlessly simulate\nthe trip from point A to point B by populating the city around the AV and\ncontrolling all aspects of the scene, from animating the dynamic agents (e.g.,\nvehicles, pedestrians) to controlling the traffic light states. We refer to\nthis vision as CitySim, which requires an agglomeration of simulation\ntechnologies: scene generation to populate the initial scene, agent behavior\nmodeling to animate the scene, occlusion reasoning, dynamic scene generation to\nseamlessly spawn and remove agents, and environment simulation for factors such\nas traffic lights. While some key technologies have been separately studied in\nvarious works, others such as dynamic scene generation and environment\nsimulation have received less attention in the research community. We propose\nSceneDiffuser++, the first end-to-end generative world model trained on a\nsingle loss function capable of point A-to-B simulation on a city scale\nintegrating all the requirements above. We demonstrate the city-scale traffic\nsimulation capability of SceneDiffuser++ and study its superior realism under\nlong simulation conditions. We evaluate the simulation quality on an augmented\nversion of the Waymo Open Motion Dataset (WOMD) with larger map regions to\nsupport trip-level simulation.", "AI": {"tldr": "\u63d0\u51faSceneDiffuser++\uff0c\u4e00\u79cd\u7aef\u5230\u7aef\u751f\u6210\u5f0f\u4e16\u754c\u6a21\u578b\uff0c\u53ef\u5728\u57ce\u5e02\u89c4\u6a21\u4e0a\u8fdb\u884c\u70b9A\u5230\u70b9B\u7684\u4ea4\u901a\u6a21\u62df\uff0c\u6574\u5408\u4e86\u573a\u666f\u751f\u6210\u3001\u4ee3\u7406\u884c\u4e3a\u5efa\u6a21\u3001\u906e\u6321\u63a8\u7406\u3001\u52a8\u6001\u573a\u666f\u751f\u6210\u548c\u73af\u5883\u6a21\u62df\u7b49\u9700\u6c42\u3002\u901a\u8fc7\u589e\u5f3a\u7248Waymo Open Motion Dataset\u8bc4\u4f30\u5176\u6a21\u62df\u8d28\u91cf\uff0c\u5c55\u793a\u5176\u5728\u957f\u65f6\u95f4\u6a21\u62df\u6761\u4ef6\u4e0b\u7684\u4f18\u8d8a\u73b0\u5b9e\u4e3b\u4e49\u3002", "motivation": "\u76ee\u524d\u7684\u57ce\u5e02\u4ea4\u901a\u6a21\u62df\u9700\u8981\u6574\u5408\u591a\u79cd\u6280\u672f\uff0c\u5982\u573a\u666f\u751f\u6210\u3001\u4ee3\u7406\u884c\u4e3a\u5efa\u6a21\u3001\u906e\u6321\u63a8\u7406\u3001\u52a8\u6001\u573a\u666f\u751f\u6210\u548c\u73af\u5883\u6a21\u62df\u7b49\uff0c\u4f46\u67d0\u4e9b\u5173\u952e\u6280\u672f\uff08\u5982\u52a8\u6001\u573a\u666f\u751f\u6210\u548c\u73af\u5883\u6a21\u62df\uff09\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5b9e\u73b0\u65e0\u7f1d\u7684\u57ce\u5e02\u7ea7\u4ea4\u901a\u6a21\u62df\u3002", "method": "\u5f00\u53d1\u4e86SceneDiffuser++\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u57fa\u4e8e\u5355\u4e00\u635f\u5931\u51fd\u6570\u8bad\u7ec3\u7684\u7aef\u5230\u7aef\u751f\u6210\u5f0f\u4e16\u754c\u6a21\u578b\uff0c\u80fd\u591f\u6ee1\u8db3\u57ce\u5e02\u89c4\u6a21\u7684\u70b9A\u5230\u70b9B\u4ea4\u901a\u6a21\u62df\u7684\u6240\u6709\u9700\u6c42\uff0c\u5305\u62ec\u573a\u666f\u751f\u6210\u3001\u4ee3\u7406\u884c\u4e3a\u5efa\u6a21\u3001\u906e\u6321\u63a8\u7406\u3001\u52a8\u6001\u573a\u666f\u751f\u6210\u548c\u73af\u5883\u6a21\u62df\u7b49\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSceneDiffuser++\u80fd\u591f\u5728\u57ce\u5e02\u89c4\u6a21\u4e0a\u5b9e\u73b0\u9ad8\u8d28\u91cf\u7684\u4ea4\u901a\u6a21\u62df\uff0c\u5e76\u5728\u957f\u65f6\u95f4\u6a21\u62df\u6761\u4ef6\u4e0b\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u73b0\u5b9e\u4e3b\u4e49\u3002\u4f7f\u7528\u589e\u5f3a\u7248Waymo Open Motion Dataset\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "conclusion": "SceneDiffuser++\u4e3a\u57ce\u5e02\u7ea7\u4ea4\u901a\u6a21\u62df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u5176\u5728\u957f\u65f6\u95f4\u6a21\u62df\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u63a8\u52a8\u4e86CitySim\u613f\u666f\u7684\u5b9e\u73b0\u3002"}}
{"id": "2506.21997", "pdf": "https://arxiv.org/pdf/2506.21997", "abs": "https://arxiv.org/abs/2506.21997", "authors": ["Rafael Sojo", "Javier D\u00edaz-Rozo", "Concha Bielza", "Pedro Larra\u00f1aga"], "title": "Binned semiparametric Bayesian networks", "categories": ["cs.LG", "cs.AI", "I.2.6; I.5.1; G.3"], "comment": null, "summary": "This paper introduces a new type of probabilistic semiparametric model that\ntakes advantage of data binning to reduce the computational cost of kernel\ndensity estimation in nonparametric distributions. Two new conditional\nprobability distributions are developed for the new binned semiparametric\nBayesian networks, the sparse binned kernel density estimation and the Fourier\nkernel density estimation. These two probability distributions address the\ncurse of dimensionality, which typically impacts binned models, by using sparse\ntensors and restricting the number of parent nodes in conditional probability\ncalculations. To evaluate the proposal, we perform a complexity analysis and\nconduct several comparative experiments using synthetic data and datasets from\nthe UCI Machine Learning repository. The experiments include different binning\nrules, parent restrictions, grid sizes, and number of instances to get a\nholistic view of the model's behavior. As a result, our binned semiparametric\nBayesian networks achieve structural learning and log-likelihood estimations\nwith no statistically significant differences compared to the semiparametric\nBayesian networks, but at a much higher speed. Thus, the new binned\nsemiparametric Bayesian networks prove to be a reliable and more efficient\nalternative to their non-binned counterparts.", "AI": {"tldr": "This paper introduces a new type of probabilistic semiparametric model that uses data binning to reduce computational cost in kernel density estimation. Two new conditional probability distributions are developed which address the curse of dimensionality through sparse tensors and parent node restrictions. Experiments show that the new binned semiparametric Bayesian networks achieve similar results to non-binned models but with higher efficiency.", "motivation": "To create a more computationally efficient model for kernel density estimation in nonparametric distributions without sacrificing accuracy.", "method": "Development of two new conditional probability distributions for binned semiparametric Bayesian networks: sparse binned kernel density estimation and Fourier kernel density estimation. These methods use sparse tensors and limit parent nodes in conditional probability calculations to combat the curse of dimensionality.", "result": "The binned semiparametric Bayesian networks perform structural learning and log-likelihood estimations with no statistically significant differences compared to non-binned semiparametric Bayesian networks, but with significantly higher speed.", "conclusion": "The new binned semiparametric Bayesian networks are a reliable and more efficient alternative to traditional non-binned models."}}
{"id": "2506.22004", "pdf": "https://arxiv.org/pdf/2506.22004", "abs": "https://arxiv.org/abs/2506.22004", "authors": ["Mohammad Sabbaqi", "Riccardo Taormina", "Elvin Isufi"], "title": "GKNet: Graph Kalman Filtering and Model Inference via Model-based Deep Learning", "categories": ["cs.LG"], "comment": null, "summary": "Inference tasks with time series over graphs are of importance in\napplications such as urban water networks, economics, and networked\nneuroscience. Addressing these tasks typically relies on identifying a\ncomputationally affordable model that jointly captures the graph-temporal\npatterns of the data. In this work, we propose a graph-aware state space model\nfor graph time series, where both the latent state and the observation equation\nare parametric graph-induced models with a limited number of parameters that\nneed to be learned. More specifically, we consider the state equation to follow\na stochastic partial differential equation driven by noise over the graphs\nedges accounting not only for potential edge uncertainties but also for\nincreasing the degrees of freedom in the latter in a tractable manner. The\ngraph structure conditioning of the noise dispersion allows the state variable\nto deviate from the stochastic process in certain neighborhoods. The\nobservation model is a sampled and graph-filtered version of the state\ncapturing multi-hop neighboring influence. The goal is to learn the parameters\nin both state and observation models from the partially observed data for\ndownstream tasks such as prediction and imputation. The model is inferred first\nthrough a maximum likelihood approach that provides theoretical tractability\nbut is limited in expressivity and scalability. To improve on the latter, we\nuse the state-space formulation to build a principled deep learning\narchitecture that jointly learns the parameters and tracks the state in an\nend-to-end manner in the spirit of Kalman neural networks.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u56fe\u65f6\u95f4\u5e8f\u5217\u7684\u56fe\u611f\u77e5\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u7ed3\u5408\u56fe\u7ed3\u6784\u548c\u65f6\u95f4\u6a21\u5f0f\u6765\u6355\u6349\u6570\u636e\u7279\u5f81\u3002\u5b83\u5229\u7528\u566a\u58f0\u5728\u56fe\u8fb9\u4e0a\u7684\u4f20\u64ad\u7279\u6027\uff0c\u5e76\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u8fdb\u884c\u53c2\u6570\u5b66\u4e60\u548c\u72b6\u6001\u8ddf\u8e2a\uff0c\u9002\u7528\u4e8e\u9884\u6d4b\u548c\u63d2\u8865\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u5728\u57ce\u5e02\u4f9b\u6c34\u7f51\u7edc\u3001\u7ecf\u6d4e\u5b66\u548c\u795e\u7ecf\u79d1\u5b66\u7b49\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u7684\u6a21\u578b\uff0c\u96be\u4ee5\u540c\u65f6\u6355\u6349\u56fe\u7ed3\u6784\u548c\u65f6\u95f4\u6a21\u5f0f\u7684\u6570\u636e\u7279\u5f81\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u6a21\u578b\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u56fe\u611f\u77e5\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff0c\u5176\u4e2d\u9690\u542b\u72b6\u6001\u548c\u89c2\u6d4b\u65b9\u7a0b\u90fd\u662f\u7531\u56fe\u8bf1\u5bfc\u7684\u53c2\u6570\u5316\u6a21\u578b\uff0c\u5177\u6709\u5c11\u91cf\u9700\u8981\u5b66\u4e60\u7684\u53c2\u6570\u3002\u5177\u4f53\u800c\u8a00\uff0c\u72b6\u6001\u65b9\u7a0b\u9075\u5faa\u7531\u56fe\u8fb9\u4e0a\u566a\u58f0\u9a71\u52a8\u7684\u968f\u673a\u504f\u5fae\u5206\u65b9\u7a0b\uff0c\u8003\u8651\u4e86\u8fb9\u4e0d\u786e\u5b9a\u6027\u5e76\u589e\u52a0\u4e86\u81ea\u7531\u5ea6\u3002\u89c2\u6d4b\u6a21\u578b\u662f\u72b6\u6001\u7684\u91c7\u6837\u548c\u56fe\u6ee4\u6ce2\u7248\u672c\uff0c\u6355\u6349\u591a\u8df3\u90bb\u5c45\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u8fdb\u884c\u521d\u6b65\u63a8\u65ad\uff0c\u968f\u540e\u4f7f\u7528\u57fa\u4e8eKalman\u795e\u7ecf\u7f51\u7edc\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u8fdb\u884c\u7aef\u5230\u7aef\u7684\u5b66\u4e60\u548c\u72b6\u6001\u8ddf\u8e2a\u3002", "result": "\u8be5\u6a21\u578b\u80fd\u591f\u4ece\u90e8\u5206\u89c2\u6d4b\u6570\u636e\u4e2d\u5b66\u4e60\u72b6\u6001\u548c\u89c2\u6d4b\u6a21\u578b\u7684\u53c2\u6570\uff0c\u9002\u7528\u4e8e\u9884\u6d4b\u548c\u63d2\u8865\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002\u76f8\u6bd4\u4f20\u7edf\u7684\u6700\u5927\u4f3c\u7136\u65b9\u6cd5\uff0c\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u5728\u8868\u8fbe\u80fd\u529b\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u56fe\u611f\u77e5\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u6355\u6349\u56fe\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u56fe-\u65f6\u95f4\u6a21\u5f0f\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.22008", "pdf": "https://arxiv.org/pdf/2506.22008", "abs": "https://arxiv.org/abs/2506.22008", "authors": ["Alessandro Sestini", "Joakim Bergdahl", "Konrad Tollmar", "Andrew D. Bagdanov", "Linus Gissl\u00e9n"], "title": "TROFI: Trajectory-Ranked Offline Inverse Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Published at Reinforcement Learning and Video Games Workshop at RLC\n  2025", "summary": "In offline reinforcement learning, agents are trained using only a fixed set\nof stored transitions derived from a source policy. However, this requires that\nthe dataset be labeled by a reward function. In applied settings such as video\ngame development, the availability of the reward function is not always\nguaranteed. This paper proposes Trajectory-Ranked OFfline Inverse reinforcement\nlearning (TROFI), a novel approach to effectively learn a policy offline\nwithout a pre-defined reward function. TROFI first learns a reward function\nfrom human preferences, which it then uses to label the original dataset making\nit usable for training the policy. In contrast to other approaches, our method\ndoes not require optimal trajectories. Through experiments on the D4RL\nbenchmark we demonstrate that TROFI consistently outperforms baselines and\nperforms comparably to using the ground truth reward to learn policies.\nAdditionally, we validate the efficacy of our method in a 3D game environment.\nOur studies of the reward model highlight the importance of the reward function\nin this setting: we show that to ensure the alignment of a value function to\nthe actual future discounted reward, it is fundamental to have a\nwell-engineered and easy-to-learn reward function.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTROFI\u7684\u65b0\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u6ca1\u6709\u9884\u5b9a\u4e49\u5956\u52b1\u51fd\u6570\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u3002\u901a\u8fc7\u4ece\u4eba\u7c7b\u504f\u597d\u4e2d\u5b66\u4e60\u5956\u52b1\u51fd\u6570\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u6570\u636e\u96c6\u6807\u6ce8\uff0c\u4ece\u800c\u5b9e\u73b0\u6709\u6548\u7684\u7b56\u7565\u5b66\u4e60\u3002\u5b9e\u9a8c\u8868\u660e\uff0cTROFI\u5728D4RL\u57fa\u51c6\u548c3D\u6e38\u620f\u73af\u5883\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u901a\u5e38\u9700\u8981\u4f7f\u7528\u5956\u52b1\u51fd\u6570\u6807\u6ce8\u7684\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u3002\u7136\u800c\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff08\u5982\u89c6\u9891\u6e38\u620f\u5f00\u53d1\uff09\uff0c\u5956\u52b1\u51fd\u6570\u53ef\u80fd\u4e0d\u53ef\u7528\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86TROFI\u65b9\u6cd5\u3002", "method": "TROFI\u9996\u5148\u4ece\u4eba\u7c7b\u504f\u597d\u4e2d\u5b66\u4e60\u5956\u52b1\u51fd\u6570\uff0c\u7136\u540e\u5229\u7528\u8be5\u5956\u52b1\u51fd\u6570\u5bf9\u539f\u59cb\u6570\u636e\u96c6\u8fdb\u884c\u6807\u6ce8\uff0c\u4f7f\u5176\u9002\u7528\u4e8e\u7b56\u7565\u8bad\u7ec3\u3002\u4e0e\u5176\u5b83\u65b9\u6cd5\u4e0d\u540c\uff0cTROFI\u4e0d\u9700\u8981\u6700\u4f18\u8f68\u8ff9\u3002", "result": "\u901a\u8fc7\u5728D4RL\u57fa\u51c6\u4e0a\u7684\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86TROFI\u59cb\u7ec8\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u5176\u6027\u80fd\u4e0e\u4f7f\u7528\u771f\u5b9e\u5956\u52b1\u51fd\u6570\u5b66\u4e60\u7b56\u7565\u7684\u6027\u80fd\u76f8\u5f53\u3002\u6b64\u5916\uff0c\u8fd8\u57283D\u6e38\u620f\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u5956\u52b1\u51fd\u6570\u5728\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u91cd\u8981\u6027\uff1a\u4e3a\u4e86\u786e\u4fdd\u4ef7\u503c\u51fd\u6570\u4e0e\u5b9e\u9645\u672a\u6765\u6298\u6263\u5956\u52b1\u7684\u4e00\u81f4\u6027\uff0c\u5fc5\u987b\u5177\u5907\u4e00\u4e2a\u8bbe\u8ba1\u826f\u597d\u4e14\u6613\u4e8e\u5b66\u4e60\u7684\u5956\u52b1\u51fd\u6570\u3002"}}
{"id": "2506.22036", "pdf": "https://arxiv.org/pdf/2506.22036", "abs": "https://arxiv.org/abs/2506.22036", "authors": ["Ying Zhang", "Yu Zhao", "Xuhui Sui", "Baohang Zhou", "Xiangrui Cai", "Li Shen", "Xiaojie Yuan", "Dacheng Tao"], "title": "Hyper-modal Imputation Diffusion Embedding with Dual-Distillation for Federated Multimodal Knowledge Graph Completion", "categories": ["cs.LG", "cs.MM"], "comment": "Submitted to the IEEE for possible publication", "summary": "With the increasing multimodal knowledge privatization requirements,\nmultimodal knowledge graphs in different institutes are usually decentralized,\nlacking of effective collaboration system with both stronger reasoning ability\nand transmission safety guarantees. In this paper, we propose the Federated\nMultimodal Knowledge Graph Completion (FedMKGC) task, aiming at training over\nfederated MKGs for better predicting the missing links in clients without\nsharing sensitive knowledge. We propose a framework named MMFeD3-HidE for\naddressing multimodal uncertain unavailability and multimodal client\nheterogeneity challenges of FedMKGC. (1) Inside the clients, our proposed\nHyper-modal Imputation Diffusion Embedding model (HidE) recovers the complete\nmultimodal distributions from incomplete entity embeddings constrained by\navailable modalities. (2) Among clients, our proposed Multimodal FeDerated Dual\nDistillation (MMFeD3) transfers knowledge mutually between clients and the\nserver with logit and feature distillation to improve both global convergence\nand semantic consistency. We propose a FedMKGC benchmark for a comprehensive\nevaluation, consisting of a general FedMKGC backbone named MMFedE, datasets\nwith heterogeneous multimodal information, and three groups of constructed\nbaselines. Experiments conducted on our benchmark validate the effectiveness,\nsemantic consistency, and convergence robustness of MMFeD3-HidE.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFederated Multimodal Knowledge Graph Completion (FedMKGC)\u7684\u4efb\u52a1\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6846\u67b6MMFeD3-HidE\u6765\u89e3\u51b3\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u7684\u8054\u90a6\u5b66\u4e60\u95ee\u9898\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3001\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u6536\u655b\u7a33\u5065\u6027\u3002", "motivation": "\u968f\u7740\u591a\u6a21\u6001\u77e5\u8bc6\u79c1\u6709\u5316\u9700\u6c42\u7684\u589e\u52a0\uff0c\u4e0d\u540c\u673a\u6784\u7684\u591a\u6a21\u6001\u77e5\u8bc6\u56fe\u8c31\u901a\u5e38\u662f\u5206\u6563\u7684\uff0c\u7f3a\u4e4f\u6709\u6548\u7684\u534f\u4f5c\u7cfb\u7edf\u4ee5\u540c\u65f6\u63d0\u4f9b\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\u548c\u4f20\u8f93\u5b89\u5168\u4fdd\u969c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aMMFeD3-HidE\u7684\u6846\u67b6\uff0c\u5176\u4e2d\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u90e8\u5206\uff1a(1) Hyper-modal Imputation Diffusion Embedding\u6a21\u578b\uff08HidE\uff09\uff0c\u7528\u4e8e\u4ece\u4e0d\u5b8c\u6574\u7684\u5b9e\u4f53\u5d4c\u5165\u4e2d\u6062\u590d\u5b8c\u6574\u7684\u591a\u6a21\u6001\u5206\u5e03\uff1b(2) Multimodal FeDerated Dual Distillation (MMFeD3)\uff0c\u901a\u8fc7logit\u548c\u7279\u5f81\u84b8\u998f\u5728\u5ba2\u6237\u7aef\u548c\u670d\u52a1\u5668\u4e4b\u95f4\u76f8\u4e92\u4f20\u9012\u77e5\u8bc6\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cdFedMKGC\u57fa\u51c6\uff0c\u5305\u62ec\u901a\u7528\u7684FedMKGC\u4e3b\u5e72\u7f51\u7edcMMFedE\u3001\u5177\u6709\u5f02\u6784\u591a\u6a21\u6001\u4fe1\u606f\u7684\u6570\u636e\u96c6\u4ee5\u53ca\u6784\u5efa\u7684\u4e09\u7ec4\u57fa\u7ebf\u3002", "result": "\u5728\u63d0\u51fa\u7684\u57fa\u51c6\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86MMFeD3-HidE\u7684\u6709\u6548\u6027\u3001\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u6536\u655b\u7a33\u5065\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684FedMKGC\u4efb\u52a1\u53caMMFeD3-HidE\u6846\u67b6\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u591a\u6a21\u6001\u4e0d\u786e\u5b9a\u6027\u4e0d\u53ef\u7528\u6027\u548c\u591a\u6a21\u6001\u5ba2\u6237\u7aef\u5f02\u6784\u6027\u7684\u6311\u6218\uff0c\u5728\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e0b\u63d0\u9ad8\u4e86\u7f3a\u5931\u94fe\u63a5\u9884\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.22039", "pdf": "https://arxiv.org/pdf/2506.22039", "abs": "https://arxiv.org/abs/2506.22039", "authors": ["Lu Han", "Yu Liu", "Qiwen Deng", "Jian Jiang", "Yinbo Sun", "Zhe Yu", "Binfeng Wang", "Xingyu Lu", "Lintao Ma", "Han-Jia Ye", "De-Chuan Zhan"], "title": "UniCA: Adapting Time Series Foundation Model to General Covariate-Aware Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time Series Foundation Models (TSFMs) have achieved remarkable success\nthrough large-scale pretraining. However, their design primarily targets\nreal-valued series, limiting their ability to handle general forecasting tasks\ninvolving diverse and often heterogeneous covariates--such as categorical\nvariables and multimodal data (e.g., images, text)--which are typically\ntask-specific and difficult to leverage during pretraining. To address this\ngap, we propose Unified Covariate Adaptation (UniCA), a framework to bridge\nTSFMs with general covariate-aware forecasting. UniCA first performs covariate\nhomogenization to transform heterogeneous covariates into high-level\nhomogeneous series representations and then fuses them via a unified\nattention-based fusion mechanism. UniCA is compatible and universal for\nadaptation with both homogeneous and heterogeneous covariates, incorporating\nextra covariate information while preserving the generalization ability of\nTSFMs.Extensive experiments on multiple unimodal and multimodal covariate-aware\nforecasting benchmarks demonstrate the superiority of UniCA, highlighting the\npromise of covariate-aware TSFM adaptation in real-world forecasting scenarios.\nCodes are released on https://github.com/hanlu-nju/UniCA.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aUnified Covariate Adaptation\uff08UniCA\uff09\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u5f25\u5408\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u4e0e\u901a\u7528\u534f\u53d8\u91cf\u611f\u77e5\u9884\u6d4b\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u8be5\u6846\u67b6\u9996\u5148\u6267\u884c\u534f\u53d8\u91cf\u540c\u8d28\u5316\uff0c\u5c06\u5f02\u6784\u534f\u53d8\u91cf\u8f6c\u6362\u4e3a\u9ad8\u7ea7\u540c\u8d28\u5e8f\u5217\u8868\u793a\uff0c\u7136\u540e\u901a\u8fc7\u7edf\u4e00\u7684\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u878d\u5408\u673a\u5236\u8fdb\u884c\u878d\u5408\u3002\u5b9e\u9a8c\u8868\u660e\uff0cUniCA\u5728\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u534f\u53d8\u91cf\u611f\u77e5\u9884\u6d4b\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u4e3b\u8981\u9488\u5bf9\u5b9e\u503c\u5e8f\u5217\u8bbe\u8ba1\uff0c\u5728\u5904\u7406\u6d89\u53ca\u591a\u6837\u4e14\u901a\u5e38\u5f02\u6784\u534f\u53d8\u91cf\uff08\u5982\u5206\u7c7b\u53d8\u91cf\u3001\u591a\u6a21\u6001\u6570\u636e\u7b49\uff09\u7684\u901a\u7528\u9884\u6d4b\u4efb\u52a1\u65f6\u80fd\u529b\u6709\u9650\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u5bfb\u627e\u4e00\u79cd\u65b9\u6cd5\uff0c\u4f7fTSFMs\u80fd\u591f\u66f4\u597d\u5730\u9002\u5e94\u8fd9\u4e9b\u590d\u6742\u573a\u666f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aUnified Covariate Adaptation\uff08UniCA\uff09\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u62ec\u4e24\u4e2a\u5173\u952e\u6b65\u9aa4\uff1a1) \u534f\u53d8\u91cf\u540c\u8d28\u5316\uff0c\u5c06\u5f02\u6784\u534f\u53d8\u91cf\u8f6c\u5316\u4e3a\u9ad8\u7ea7\u540c\u8d28\u5e8f\u5217\u8868\u793a\uff1b2) \u901a\u8fc7\u7edf\u4e00\u7684\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u878d\u5408\u673a\u5236\u5bf9\u8fd9\u4e9b\u8868\u793a\u8fdb\u884c\u878d\u5408\u3002\u6b64\u65b9\u6cd5\u9002\u7528\u4e8e\u540c\u8d28\u548c\u5f02\u8d28\u534f\u53d8\u91cf\uff0c\u5e76\u80fd\u5728\u5f15\u5165\u989d\u5916\u534f\u53d8\u91cf\u4fe1\u606f\u7684\u540c\u65f6\u4fdd\u6301TSFMs\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cUniCA\u5728\u591a\u4e2a\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u534f\u53d8\u91cf\u611f\u77e5\u9884\u6d4b\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u9645\u9884\u6d4b\u573a\u666f\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "Unified Covariate Adaptation\uff08UniCA\uff09\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u589e\u5f3a\u4e86TSFMs\u5728\u5904\u7406\u5305\u542b\u591a\u6837\u5316\u548c\u5f02\u6784\u534f\u53d8\u91cf\u7684\u901a\u7528\u9884\u6d4b\u4efb\u52a1\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5c55\u73b0\u4e86\u5176\u5728\u73b0\u5b9e\u4e16\u754c\u9884\u6d4b\u573a\u666f\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.22049", "pdf": "https://arxiv.org/pdf/2506.22049", "abs": "https://arxiv.org/abs/2506.22049", "authors": ["Tianhao Chen", "Xin Xu", "Zijing Liu", "Pengxiang Li", "Xinyuan Song", "Ajay Kumar Jaiswal", "Fan Zhang", "Jishan Hu", "Yang Wang", "Hao Chen", "Shizhe Diao", "Shiwei Liu", "Yu Li", "Yin Lu", "Can Yang"], "title": "GPAS: Accelerating Convergence of LLM Pretraining via Gradient-Preserving Activation Scaling", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Modern Large Language Models, such as the LLaMA, Qwen and DeepSeek series,\npredominantly adopt the Pre-LayerNorm (Pre-LN) Transformer architecture. While\nbeing stable during pretraining and scalable to large model sizes, Pre-LN\nsuffers from an exponential growth in activation variance across layers,\ncausing the residual path to dominate over sub-layer outputs and limiting the\nlearning capacity of deeper layers. To mitigate this issue, we propose\nGradient-Preserving Activation Scaling (GPAS), a simple technique that can be\nused in combination with existing approaches. GPAS works by scaling down the\nintermediate activations while keeping their gradients unchanged. This leaves\ninformation in the activations intact, and avoids the gradient vanishing\nproblem associated with gradient downscaling. Extensive experiments across\nvarious model sizes from 71M to 1B show that GPAS achieves consistent\nperformance gains. Beyond enhancing Pre-LN Transformers, GPAS also shows\npromise in improving alternative architectures such as Sandwich-LN and\nDeepNorm, demonstrating its versatility and potential for improving training\ndynamics in a wide range of settings.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGradient-Preserving Activation Scaling\uff08GPAS\uff09\u7684\u65b0\u6280\u672f\uff0c\u53ef\u4ee5\u6709\u6548\u89e3\u51b3Pre-LayerNorm Transformer\u67b6\u6784\u4e2d\u6fc0\u6d3b\u65b9\u5dee\u6307\u6570\u589e\u957f\u7684\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684Pre-LayerNorm Transformer\u67b6\u6784\u867d\u7136\u5728\u9884\u8bad\u7ec3\u671f\u95f4\u7a33\u5b9a\u4e14\u53ef\u6269\u5c55\u5230\u5927\u578b\u6a21\u578b\u5c3a\u5bf8\uff0c\u4f46\u5b58\u5728\u6fc0\u6d3b\u65b9\u5dee\u8de8\u5c42\u6307\u6570\u589e\u957f\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6b8b\u5dee\u8def\u5f84\u5360\u636e\u4e3b\u5bfc\u5730\u4f4d\u5e76\u9650\u5236\u4e86\u6df1\u5c42\u7684\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86Gradient-Preserving Activation Scaling\uff08GPAS\uff09\uff0c\u901a\u8fc7\u7f29\u653e\u4e2d\u95f4\u6fc0\u6d3b\u540c\u65f6\u4fdd\u6301\u5176\u68af\u5ea6\u4e0d\u53d8\u6765\u89e3\u51b3\u95ee\u9898\uff0c\u4ece\u800c\u4fdd\u7559\u6fc0\u6d3b\u4e2d\u7684\u4fe1\u606f\u5e76\u907f\u514d\u4e0e\u68af\u5ea6\u4e0b\u7f29\u76f8\u5173\u7684\u68af\u5ea6\u6d88\u5931\u95ee\u9898\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cGPAS\u572871M\u81f31B\u4e0d\u540c\u6a21\u578b\u5c3a\u5bf8\u4e0a\u5747\u5b9e\u73b0\u4e86\u6027\u80fd\u7684\u6301\u7eed\u63d0\u5347\uff0c\u5e76\u4e14\u4e0d\u4ec5\u589e\u5f3a\u4e86Pre-LN Transformers\uff0c\u8fd8\u5bf9Sandwich-LN\u548cDeepNorm\u7b49\u66ff\u4ee3\u67b6\u6784\u8868\u73b0\u51fa\u6539\u8fdb\u6f5c\u529b\u3002", "conclusion": "GPAS\u4f5c\u4e3a\u4e00\u79cd\u7b80\u5355\u6280\u672f\uff0c\u80fd\u591f\u4e0e\u73b0\u6709\u65b9\u6cd5\u7ed3\u5408\u4f7f\u7528\uff0c\u5c55\u73b0\u51fa\u5176\u591a\u529f\u80fd\u6027\u548c\u5728\u5404\u79cd\u573a\u666f\u4e2d\u6539\u5584\u8bad\u7ec3\u52a8\u6001\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.22055", "pdf": "https://arxiv.org/pdf/2506.22055", "abs": "https://arxiv.org/abs/2506.22055", "authors": ["Mehul Gautam"], "title": "crypto price prediction using lstm+xgboost", "categories": ["cs.LG"], "comment": null, "summary": "The volatility and complex dynamics of cryptocurrency markets present unique\nchallenges for accurate price forecasting. This research proposes a hybrid deep\nlearning and machine learning model that integrates Long Short-Term Memory\n(LSTM) networks and Extreme Gradient Boosting (XGBoost) for cryptocurrency\nprice prediction. The LSTM component captures temporal dependencies in\nhistorical price data, while XGBoost enhances prediction by modeling nonlinear\nrelationships with auxiliary features such as sentiment scores and\nmacroeconomic indicators. The model is evaluated on historical datasets of\nBitcoin, Ethereum, Dogecoin, and Litecoin, incorporating both global and\nlocalized exchange data. Comparative analysis using Mean Absolute Percentage\nError (MAPE) and Min-Max Normalized Root Mean Square Error (MinMax RMSE)\ndemonstrates that the LSTM+XGBoost hybrid consistently outperforms standalone\nmodels and traditional forecasting methods. This study underscores the\npotential of hybrid architectures in financial forecasting and provides\ninsights into model adaptability across different cryptocurrencies and market\ncontexts.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\uff08LSTM\uff09\u548c\u6781\u9650\u68af\u5ea6\u63d0\u5347\uff08XGBoost\uff09\u7684\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u4e0e\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u52a0\u5bc6\u8d27\u5e01\u4ef7\u683c\u9884\u6d4b\u3002\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\u663e\u793a\uff0c\u8be5\u6df7\u5408\u6a21\u578b\u5728\u591a\u79cd\u52a0\u5bc6\u8d27\u5e01\u7684\u5386\u53f2\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u5355\u72ec\u6a21\u578b\u548c\u4f20\u7edf\u9884\u6d4b\u65b9\u6cd5\u3002", "motivation": "\u52a0\u5bc6\u8d27\u5e01\u5e02\u573a\u7684\u6ce2\u52a8\u6027\u548c\u590d\u6742\u52a8\u6001\u4e3a\u51c6\u786e\u7684\u4ef7\u683c\u9884\u6d4b\u5e26\u6765\u4e86\u72ec\u7279\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u6a21\u578b\uff0c\u6574\u5408\u4e86LSTM\u548cXGBoost\u3002LSTM\u90e8\u5206\u6355\u6349\u5386\u53f2\u4ef7\u683c\u6570\u636e\u4e2d\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u800cXGBoost\u901a\u8fc7\u5efa\u6a21\u975e\u7ebf\u6027\u5173\u7cfb\uff08\u5982\u60c5\u7eea\u5206\u6570\u548c\u5b8f\u89c2\u7ecf\u6d4e\u6307\u6807\u7b49\u8f85\u52a9\u7279\u5f81\uff09\u6765\u589e\u5f3a\u9884\u6d4b\u80fd\u529b\u3002", "result": "\u4f7f\u7528\u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee\uff08MAPE\uff09\u548c\u6700\u5c0f-\u6700\u5927\u5f52\u4e00\u5316\u5747\u65b9\u6839\u8bef\u5dee\uff08MinMax RMSE\uff09\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\uff0c\u7ed3\u679c\u8868\u660eLSTM+XGBoost\u6df7\u5408\u6a21\u578b\u59cb\u7ec8\u4f18\u4e8e\u5355\u72ec\u6a21\u578b\u548c\u4f20\u7edf\u9884\u6d4b\u65b9\u6cd5\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u6df7\u5408\u67b6\u6784\u5728\u91d1\u878d\u9884\u6d4b\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u5e76\u63d0\u4f9b\u4e86\u5173\u4e8e\u4e0d\u540c\u52a0\u5bc6\u8d27\u5e01\u548c\u5e02\u573a\u73af\u5883\u4e0b\u6a21\u578b\u9002\u5e94\u6027\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.22084", "pdf": "https://arxiv.org/pdf/2506.22084", "abs": "https://arxiv.org/abs/2506.22084", "authors": ["Chaitanya K. Joshi"], "title": "Transformers are Graph Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": "This paper is a technical version of an article in The Gradient at\n  https://thegradient.pub/transformers-are-graph-neural-networks/", "summary": "We establish connections between the Transformer architecture, originally\nintroduced for natural language processing, and Graph Neural Networks (GNNs)\nfor representation learning on graphs. We show how Transformers can be viewed\nas message passing GNNs operating on fully connected graphs of tokens, where\nthe self-attention mechanism capture the relative importance of all tokens\nw.r.t. each-other, and positional encodings provide hints about sequential\nordering or structure. Thus, Transformers are expressive set processing\nnetworks that learn relationships among input elements without being\nconstrained by apriori graphs. Despite this mathematical connection to GNNs,\nTransformers are implemented via dense matrix operations that are significantly\nmore efficient on modern hardware than sparse message passing. This leads to\nthe perspective that Transformers are GNNs currently winning the hardware\nlottery.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86Transformer\u67b6\u6784\u4e0e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u8868\u660eTransformer\u53ef\u4ee5\u88ab\u89c6\u4e3a\u5728\u5b8c\u5168\u8fde\u63a5\u7684\u56fe\u4e0a\u8fdb\u884c\u6d88\u606f\u4f20\u9012\u7684GNN\uff0c\u5c3d\u7ba1\u5176\u5b9e\u73b0\u65b9\u5f0f\u66f4\u9ad8\u6548\u3002", "motivation": "\u4e3a\u4e86\u5efa\u7acbTransformer\u67b6\u6784\u4e0e\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u5e76\u7406\u89e3\u4e24\u8005\u5728\u8868\u793a\u5b66\u4e60\u4e0a\u7684\u76f8\u4f3c\u6027\u548c\u5dee\u5f02\u6027\u3002", "method": "\u901a\u8fc7\u5206\u6790Transformer\u4f5c\u4e3a\u6d88\u606f\u4f20\u9012GNN\u5728\u5168\u8fde\u63a5\u56fe\u4e0a\u7684\u64cd\u4f5c\u673a\u5236\uff0c\u5176\u4e2d\u81ea\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u4ee4\u724c\u95f4\u7684\u76f8\u5bf9\u91cd\u8981\u6027\uff0c\u4f4d\u7f6e\u7f16\u7801\u63d0\u4f9b\u5e8f\u5217\u987a\u5e8f\u6216\u7ed3\u6784\u7684\u63d0\u793a\u3002", "result": "\u53d1\u73b0Transformer\u662f\u4e00\u79cd\u8868\u8fbe\u80fd\u529b\u5f3a\u7684\u96c6\u5408\u5904\u7406\u7f51\u7edc\uff0c\u80fd\u591f\u5b66\u4e60\u8f93\u5165\u5143\u7d20\u95f4\u7684\u5173\u7cfb\uff0c\u800c\u4e0d\u53d7\u9884\u5148\u8bbe\u5b9a\u7684\u56fe\u7ed3\u6784\u9650\u5236\u3002\u6b64\u5916\uff0c\u7531\u4e8e\u5176\u5b9e\u73b0\u4f9d\u8d56\u4e8e\u5bc6\u96c6\u77e9\u9635\u8fd0\u7b97\uff0c\u5728\u73b0\u4ee3\u786c\u4ef6\u4e0a\u6bd4\u7a00\u758f\u6d88\u606f\u4f20\u9012\u66f4\u9ad8\u6548\u3002", "conclusion": "Transformer\u53ef\u4ee5\u88ab\u89c6\u4e3a\u4e00\u79cd\u5728\u5f53\u524d\u786c\u4ef6\u6761\u4ef6\u4e0b\u975e\u5e38\u9ad8\u6548\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u56e0\u6b64\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u662f'\u8d62\u5f97\u786c\u4ef6\u5f69\u7968'\u7684GNN\u3002"}}
{"id": "2506.22095", "pdf": "https://arxiv.org/pdf/2506.22095", "abs": "https://arxiv.org/abs/2506.22095", "authors": ["Filip Rydin", "Attila Lischka", "Jiaming Wu", "Morteza Haghir Chehreghani", "Bal\u00e1zs Kulcs\u00e1r"], "title": "Learning to Solve Multi-Objective Routing Problems on Multigraphs", "categories": ["cs.LG", "cs.AI"], "comment": "18 pages, 5 Figures", "summary": "Learning-based methods for routing have gained significant attention in\nrecent years, both in single-objective and multi-objective contexts. However,\nthe multigraph setting, where multiple paths with distinct attributes can exist\nbetween destinations, has largely been overlooked, despite its high practical\nrelevancy. In this paper, we introduce two neural approaches to address\nmulti-objective routing on multigraphs. Our first approach works directly on\nthe multigraph, by autoregressively selecting edges until a tour is completed.\nOn the other hand, our second model first prunes the multigraph into a simple\ngraph and then builds routes. We validate both models experimentally and find\nthat they demonstrate strong performance across a variety of problems,\nincluding the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing\nProblem (CVRP).", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u6765\u89e3\u51b3\u591a\u76ee\u6807\u591a\u56fe\u8def\u7531\u95ee\u9898\uff0c\u4e00\u4e2a\u76f4\u63a5\u5728\u591a\u56fe\u4e0a\u64cd\u4f5c\uff0c\u53e6\u4e00\u4e2a\u5148\u5c06\u591a\u56fe\u4fee\u526a\u4e3a\u7b80\u5355\u56fe\u518d\u8fdb\u884c\u64cd\u4f5c\u3002\u5b9e\u9a8c\u8868\u660e\u8fd9\u4e24\u79cd\u65b9\u6cd5\u5728\u591a\u4e2a\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5c3d\u7ba1\u591a\u56fe\u8bbe\u7f6e\u5728\u5b9e\u9645\u4e2d\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u57fa\u4e8e\u5b66\u4e60\u7684\u8def\u7531\u65b9\u6cd5\u5927\u591a\u5ffd\u7565\u4e86\u8be5\u573a\u666f\uff0c\u7279\u522b\u662f\u5728\u591a\u76ee\u6807\u60c5\u51b5\u4e0b\u3002", "method": "\u7b2c\u4e00\u79cd\u65b9\u6cd5\u76f4\u63a5\u5728\u591a\u56fe\u4e0a\u901a\u8fc7\u81ea\u56de\u5f52\u9009\u62e9\u8fb9\u6784\u5efa\u8def\u5f84\uff1b\u7b2c\u4e8c\u79cd\u65b9\u6cd5\u5148\u5c06\u591a\u56fe\u4fee\u526a\u6210\u7b80\u5355\u56fe\uff0c\u7136\u540e\u518d\u6784\u5efa\u8def\u5f84\u3002", "result": "\u4e24\u79cd\u6a21\u578b\u5728\u5305\u62ec\u65c5\u884c\u5546\u95ee\u9898\u548c\u5bb9\u91cf\u7ea6\u675f\u8f66\u8f86\u8def\u5f84\u95ee\u9898\u7b49\u591a\u4e2a\u95ee\u9898\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u79cd\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u4e3a\u591a\u76ee\u6807\u591a\u56fe\u8def\u7531\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5728\u591a\u79cd\u95ee\u9898\u4e0a\u5c55\u793a\u4e86\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2506.22200", "pdf": "https://arxiv.org/pdf/2506.22200", "abs": "https://arxiv.org/abs/2506.22200", "authors": ["Chen Wang", "Lai Wei", "Yanzhi Zhang", "Chenyang Shao", "Zedong Dan", "Weiran Huang", "Yue Wang", "Yuzhi Zhang"], "title": "EFRame: Deeper Reasoning via Exploration-Filtering-Replay Reinforcement Learning Framework", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advances in reinforcement learning (RL) have significantly enhanced\nthe reasoning capabilities of large language models (LLMs). Group Relative\nPolicy Optimization (GRPO), an efficient variant of PPO that lowers RL's\ncomputational cost, still faces limited exploration, low sample efficiency and\ninstability, constraining its performance on complex reasoning tasks. To\naddress these limitations, we introduce EFRame, an Exploration-Filtering-Replay\nframework that systematically augments GRPO along three critical dimensions.\nEFRame performs additional rollouts to explore high-quality trajectories,\napplies online filtering to eliminate low-quality samples that introduce noise\nand variance, and leverages experience replay to repeatedly exploit rare but\ninformative samples. EFRame establishes a complete and stable learning cycle,\nguiding the model through a structured transition from exploration to\nconvergence. Our experiments across a variety of reasoning benchmarks\ndemonstrate that EFRame not only improves the robustness and efficiency of\ntraining, but also enables access to deeper reasoning capabilities that remain\nunattainable under vanilla GRPO. Furthermore, EFRame enables a more\nfine-grained categorization of training samples, allowing for a deeper analysis\nof how different types of samples contribute to the learning process in RL. Our\ncode is available at https://github.com/597358816/EFRame.", "AI": {"tldr": "EFRame\uff0c\u4e00\u4e2a\u63a2\u7d22-\u8fc7\u6ee4-\u56de\u653e\u6846\u67b6\uff0c\u901a\u8fc7\u589e\u5f3aGRPO\u5728\u63a2\u7d22\u3001\u6837\u672c\u8fc7\u6ee4\u548c\u7ecf\u9a8c\u56de\u653e\u4e09\u4e2a\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u8bad\u7ec3\u7684\u7a33\u5065\u6027\u548c\u6548\u7387\uff0c\u8fd8\u4f7f\u6a21\u578b\u80fd\u591f\u5b9e\u73b0\u66f4\u6df1\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5141\u8bb8\u5bf9\u8bad\u7ec3\u6837\u672c\u8fdb\u884c\u66f4\u7ec6\u81f4\u7684\u5206\u7c7b\u3002", "motivation": "\u5c3d\u7ba1GRPO\u964d\u4f4e\u4e86\u5f3a\u5316\u5b66\u4e60\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u4f46\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u4ecd\u53d7\u5230\u6709\u9650\u63a2\u7d22\u3001\u4f4e\u6837\u672c\u6548\u7387\u548c\u4e0d\u7a33\u5b9a\u6027\u7684\u9650\u5236\u3002", "method": "EFRame\u901a\u8fc7\u6267\u884c\u989d\u5916\u7684rollouts\u6765\u63a2\u7d22\u9ad8\u8d28\u91cf\u8f68\u8ff9\uff0c\u5728\u7ebf\u8fc7\u6ee4\u4ee5\u6d88\u9664\u4f4e\u8d28\u91cf\u6837\u672c\uff0c\u4ee5\u53ca\u5229\u7528\u7ecf\u9a8c\u56de\u653e\u91cd\u590d\u5229\u7528\u7a00\u6709\u4f46\u6709\u7528\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEFRame\u63d0\u9ad8\u4e86\u8bad\u7ec3\u7684\u7a33\u5065\u6027\u548c\u6548\u7387\uff0c\u4f7f\u6a21\u578b\u80fd\u83b7\u5f97\u66f4\u6df1\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4e14\u5b9e\u73b0\u4e86\u5bf9\u8bad\u7ec3\u6837\u672c\u66f4\u7ec6\u7c92\u5ea6\u7684\u5206\u7c7b\u3002", "conclusion": "EFRame\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u5b8c\u6574\u7684\u7a33\u5b9a\u5b66\u4e60\u5468\u671f\uff0c\u4ece\u63a2\u7d22\u5230\u6536\u655b\u90fd\u6709\u7ed3\u6784\u5316\u7684\u8f6c\u53d8\u3002"}}
{"id": "2506.22096", "pdf": "https://arxiv.org/pdf/2506.22096", "abs": "https://arxiv.org/abs/2506.22096", "authors": ["Tin Lai", "Farnaz Farid", "Yueyang Kuan", "Xintian Zhang"], "title": "Transfer Learning for Assessing Heavy Metal Pollution in Seaports Sediments", "categories": ["cs.LG"], "comment": null, "summary": "Detecting heavy metal pollution in soils and seaports is vital for regional\nenvironmental monitoring. The Pollution Load Index (PLI), an international\nstandard, is commonly used to assess heavy metal containment. However, the\nconventional PLI assessment involves laborious procedures and data analysis of\nsediment samples. To address this challenge, we propose a deep-learning-based\nmodel that simplifies the heavy metal assessment process. Our model tackles the\nissue of data scarcity in the water-sediment domain, which is traditionally\nplagued by challenges in data collection and varying standards across nations.\nBy leveraging transfer learning, we develop an accurate quantitative assessment\nmethod for predicting PLI. Our approach allows the transfer of learned features\nacross domains with different sets of features. We evaluate our model using\ndata from six major ports in New South Wales, Australia: Port Yamba, Port\nNewcastle, Port Jackson, Port Botany, Port Kembla, and Port Eden. The results\ndemonstrate significantly lower Mean Absolute Error (MAE) and Mean Absolute\nPercentage Error (MAPE) of approximately 0.5 and 0.03, respectively, compared\nto other models. Our model performance is up to 2 orders of magnitude than\nother baseline models. Our proposed model offers an innovative, accessible, and\ncost-effective approach to predicting water quality, benefiting marine life\nconservation, aquaculture, and industrial pollution monitoring.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6a21\u578b\uff0c\u7528\u4e8e\u7b80\u5316\u91cd\u91d1\u5c5e\u8bc4\u4f30\u8fc7\u7a0b\uff0c\u5e76\u901a\u8fc7\u8f6c\u79fb\u5b66\u4e60\u89e3\u51b3\u4e86\u6c34\u6c89\u79ef\u7269\u9886\u57df\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002\u8be5\u6a21\u578b\u5728\u6fb3\u5927\u5229\u4e9a\u65b0\u5357\u5a01\u5c14\u58eb\u5dde\u516d\u4e2a\u4e3b\u8981\u6e2f\u53e3\u7684\u6570\u636e\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u8f83\u4f4e\u7684MAE\u548cMAPE\u3002", "motivation": "\u68c0\u6d4b\u571f\u58e4\u548c\u6d77\u6e2f\u4e2d\u7684\u91cd\u91d1\u5c5e\u6c61\u67d3\u5bf9\u4e8e\u533a\u57df\u73af\u5883\u76d1\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u7684PLI\u8bc4\u4f30\u6d89\u53ca\u7e41\u7410\u7684\u8fc7\u7a0b\u548c\u6570\u636e\u5206\u6790\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6a21\u578b\uff0c\u5229\u7528\u8f6c\u79fb\u5b66\u4e60\u6765\u89e3\u51b3\u6c34\u6c89\u79ef\u7269\u9886\u57df\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u4ece\u800c\u5b9e\u73b0\u51c6\u786e\u7684\u5b9a\u91cf\u8bc4\u4f30\u65b9\u6cd5\u4ee5\u9884\u6d4bPLI\u3002", "result": "\u6a21\u578b\u5728\u6fb3\u5927\u5229\u4e9a\u65b0\u5357\u5a01\u5c14\u58eb\u5dde\u516d\u4e2a\u6e2f\u53e3\u7684\u6570\u636e\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u51fa\u5927\u7ea60.5\u7684MAE\u548c0.03\u7684MAPE\uff0c\u6027\u80fd\u6bd4\u5176\u4ed6\u57fa\u7ebf\u6a21\u578b\u9ad8\u51fa\u4e24\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u65b0\u3001\u6613\u7528\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u65b9\u6cd5\u6765\u9884\u6d4b\u6c34\u8d28\uff0c\u6709\u52a9\u4e8e\u6d77\u6d0b\u751f\u7269\u4fdd\u62a4\u3001\u6c34\u4ea7\u517b\u6b96\u548c\u5de5\u4e1a\u6c61\u67d3\u76d1\u6d4b\u3002"}}
{"id": "2506.22255", "pdf": "https://arxiv.org/pdf/2506.22255", "abs": "https://arxiv.org/abs/2506.22255", "authors": ["Maciej Stefaniak", "Micha\u0142 Krutul", "Jan Ma\u0142a\u015bnicki", "Maciej Pi\u00f3ro", "Jakub Krajewski", "Sebastian Jaszczur", "Marek Cygan", "Kamil Adamczewski", "Jan Ludziejewski"], "title": "Projected Compression: Trainable Projection for Efficient Transformer Compression", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models have steadily increased in size to achieve improved\nperformance; however, this growth has also led to greater inference time and\ncomputational demands. Consequently, there is rising interest in model size\nreduction methods. To address this issue, we propose Projected Compression, a\nnovel model compression technique, that reduces model weights by utilizing\nprojection modules. Specifically, we first train additional trainable\nprojections weights and preserve access to all the original model parameters.\nSubsequently, these projections are merged into a lower-dimensional product\nmatrix, resulting in a reduced-size standard Transformer-based model. Unlike\nalternative approaches that require additional computational overhead, our\nmethod matches the base model's per-token computation step in FLOPs.\nExperimental results show that Projected Compression outperforms the comparable\nhard pruning and retraining approach on higher quality models. Moreover, the\nperformance margin scales well with the number of tokens.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u901a\u8fc7\u589e\u52a0\u89c4\u6a21\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4f46\u63a8\u7406\u65f6\u95f4\u548c\u8ba1\u7b97\u9700\u6c42\u4e5f\u968f\u4e4b\u589e\u52a0\u3002\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86Projected Compression\u65b9\u6cd5\uff0c\u901a\u8fc7\u6295\u5f71\u6a21\u5757\u51cf\u5c11\u6a21\u578b\u6743\u91cd\uff0c\u6700\u7ec8\u5f62\u6210\u964d\u7ef4\u7684Transformer\u6a21\u578b\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u786c\u526a\u679d\u548c\u518d\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u9ad8\u8d28\u91cf\u6a21\u578b\u4e0a\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3a\u4e86\u63d0\u5347\u6027\u80fd\u800c\u4e0d\u65ad\u589e\u5927\uff0c\u4f46\u8fd9\u5bfc\u81f4\u4e86\u66f4\u957f\u7684\u63a8\u7406\u65f6\u95f4\u548c\u66f4\u9ad8\u7684\u8ba1\u7b97\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u6a21\u578b\u538b\u7f29\u65b9\u6cd5\u6765\u964d\u4f4e\u6a21\u578b\u5927\u5c0f\u548c\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aProjected Compression\u7684\u65b0\u6a21\u578b\u538b\u7f29\u6280\u672f\uff0c\u9996\u5148\u8bad\u7ec3\u9644\u52a0\u7684\u53ef\u8bad\u7ec3\u6295\u5f71\u6743\u91cd\uff0c\u4fdd\u7559\u5bf9\u6240\u6709\u539f\u59cb\u6a21\u578b\u53c2\u6570\u7684\u8bbf\u95ee\uff1b\u7136\u540e\u5c06\u8fd9\u4e9b\u6295\u5f71\u5408\u5e76\u5230\u4e00\u4e2a\u4f4e\u7ef4\u5ea6\u7684\u4ea7\u54c1\u77e9\u9635\u4e2d\uff0c\u4ece\u800c\u751f\u6210\u4e00\u4e2a\u7f29\u5c0f\u5c3a\u5bf8\u7684\u6807\u51c6Transformer\u6a21\u578b\u3002\u6b64\u65b9\u6cd5\u4e0e\u57fa\u7840\u6a21\u578b\u7684\u6bcf\u4ee4\u724c\u8ba1\u7b97\u6b65\u9aa4\u5728FLOPs\u4e0a\u76f8\u5339\u914d\uff0c\u4e0d\u9700\u989d\u5916\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cProjected Compression\u5728\u9ad8\u8d28\u91cf\u6a21\u578b\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u786c\u526a\u679d\u548c\u518d\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5e76\u4e14\u968f\u7740\u4ee4\u724c\u6570\u91cf\u7684\u589e\u52a0\uff0c\u6027\u80fd\u5dee\u8ddd\u4e5f\u5448\u826f\u597d\u6269\u5c55\u8d8b\u52bf\u3002", "conclusion": "Projected Compression\u662f\u4e00\u79cd\u6709\u6548\u7684\u6a21\u578b\u538b\u7f29\u6280\u672f\uff0c\u80fd\u591f\u5728\u4e0d\u589e\u52a0\u8ba1\u7b97\u5f00\u9500\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u51cf\u5c0f\u6a21\u578b\u5c3a\u5bf8\u5e76\u4fdd\u6301\u6216\u63d0\u9ad8\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u9ad8\u8d28\u91cf\u6a21\u578b\u4e0a\u6548\u679c\u660e\u663e\u3002"}}
{"id": "2506.22129", "pdf": "https://arxiv.org/pdf/2506.22129", "abs": "https://arxiv.org/abs/2506.22129", "authors": ["Anurag Panda", "Gaurav Kumar Yadav"], "title": "Earthquake Damage Grades Prediction using An Ensemble Approach Integrating Advanced Machine and Deep Learning Models", "categories": ["cs.LG"], "comment": "3rd International Conference on Applied Mathematics in Science and\n  Engineering", "summary": "In the aftermath of major earthquakes, evaluating structural and\ninfrastructural damage is vital for coordinating post-disaster response\nefforts. This includes assessing damage's extent and spatial distribution to\nprioritize rescue operations and resource allocation. Accurately estimating\ndamage grades to buildings post-earthquake is paramount for effective response\nand recovery, given the significant impact on lives and properties,\nunderscoring the urgency of streamlining relief fund allocation processes.\nPrevious studies have shown the effectiveness of multi-class classification,\nespecially XGBoost, along with other machine learning models and ensembling\nmethods, incorporating regularization to address class imbalance. One\nconsequence of class imbalance is that it may give rise to skewed models that\nundervalue minority classes and give preference to the majority class. This\nresearch deals with the problem of class imbalance with the help of the\nsynthetic minority oversampling technique (SMOTE). We delve into multiple\nmulti-class classification machine learning, deep learning models, and\nensembling methods to forecast structural damage grades. The study elucidates\nperformance determinants through comprehensive feature manipulation experiments\nand diverse training approaches. It identifies key factors contributing to\nseismic vulnerability while evaluating model performance using techniques like\nthe confusion matrix further to enhance understanding of the effectiveness of\nearthquake damage prediction.", "AI": {"tldr": "This paper addresses the problem of class imbalance in predicting structural damage grades after earthquakes using SMOTE and various machine learning models.", "motivation": "Earthquake-induced structural and infrastructural damage assessment is crucial for post-disaster response. Accurate estimation of damage grades influences lives, properties, and relief fund allocation.", "method": "The research employs synthetic minority oversampling technique (SMOTE) to handle class imbalance. It explores multi-class classification using machine learning, deep learning models, and ensembling methods, along with comprehensive feature manipulation experiments and diverse training approaches.", "result": "Performance determinants are elucidated through feature manipulation and different training techniques. Key factors contributing to seismic vulnerability are identified, and model performance is evaluated using the confusion matrix.", "conclusion": "This study enhances understanding of earthquake damage prediction effectiveness by addressing class imbalance and identifying key factors that contribute to seismic vulnerability."}}
{"id": "2506.22299", "pdf": "https://arxiv.org/pdf/2506.22299", "abs": "https://arxiv.org/abs/2506.22299", "authors": ["Tao Liu", "Longlong Lin", "Yunfeng Yu", "Xi Ou", "Youan Zhang", "Zhiqiu Ye", "Tao Jia"], "title": "CoATA: Effective Co-Augmentation of Topology and Attribute for Graph Neural Networks", "categories": ["cs.LG", "cs.AI", "I.2"], "comment": "icmr", "summary": "Graph Neural Networks (GNNs) have garnered substantial attention due to their\nremarkable capability in learning graph representations. However, real-world\ngraphs often exhibit substantial noise and incompleteness, which severely\ndegrades the performance of GNNs. Existing methods typically address this issue\nthrough single-dimensional augmentation, focusing either on refining topology\nstructures or perturbing node attributes, thereby overlooking the deeper\ninterplays between the two. To bridge this gap, this paper presents CoATA, a\ndual-channel GNN framework specifically designed for the Co-Augmentation of\nTopology and Attribute. Specifically, CoATA first propagates structural signals\nto enrich and denoise node attributes. Then, it projects the enhanced attribute\nspace into a node-attribute bipartite graph for further refinement or\nreconstruction of the underlying structure. Subsequently, CoATA introduces\ncontrastive learning, leveraging prototype alignment and consistency\nconstraints, to facilitate mutual corrections between the augmented and\noriginal graphs. Finally, extensive experiments on seven benchmark datasets\ndemonstrate that the proposed CoATA outperforms eleven state-of-the-art\nbaseline methods, showcasing its effectiveness in capturing the synergistic\nrelationship between topology and attributes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u901a\u9053GNN\u6846\u67b6CoATA\uff0c\u901a\u8fc7\u5171\u540c\u589e\u5f3a\u62d3\u6251\u7ed3\u6784\u548c\u5c5e\u6027\u6765\u5e94\u5bf9\u73b0\u5b9e\u56fe\u4e2d\u7684\u566a\u58f0\u548c\u4e0d\u5b8c\u6574\u6027\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660eCoATA\u5728\u4e03\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e11\u79cd\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684GNN\u65b9\u6cd5\u5728\u5904\u7406\u771f\u5b9e\u4e16\u754c\u56fe\u7684\u566a\u58f0\u548c\u4e0d\u5b8c\u6574\u6027\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u4e14\u5355\u7ef4\u589e\u5f3a\u65b9\u6cd5\u5ffd\u7565\u4e86\u62d3\u6251\u7ed3\u6784\u548c\u8282\u70b9\u5c5e\u6027\u4e4b\u95f4\u7684\u6df1\u5c42\u6b21\u76f8\u4e92\u4f5c\u7528\u3002", "method": "CoATA\u6846\u67b6\u9996\u5148\u4f20\u64ad\u7ed3\u6784\u4fe1\u53f7\u4ee5\u4e30\u5bcc\u548c\u53bb\u566a\u8282\u70b9\u5c5e\u6027\uff1b\u7136\u540e\u5c06\u589e\u5f3a\u7684\u5c5e\u6027\u7a7a\u95f4\u6295\u5f71\u5230\u8282\u70b9-\u5c5e\u6027\u4e8c\u5206\u56fe\u4e2d\u8fdb\u884c\u8fdb\u4e00\u6b65\u4f18\u5316\u6216\u91cd\u5efa\uff1b\u6700\u540e\u5f15\u5165\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5229\u7528\u539f\u578b\u5bf9\u9f50\u548c\u4e00\u81f4\u6027\u7ea6\u675f\u5b9e\u73b0\u589e\u5f3a\u56fe\u4e0e\u539f\u56fe\u4e4b\u95f4\u7684\u76f8\u4e92\u6821\u6b63\u3002", "result": "\u5728\u4e03\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\uff0cCoATA\u663e\u8457\u4f18\u4e8e11\u79cd\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CoATA\u80fd\u591f\u6709\u6548\u6355\u6349\u62d3\u6251\u7ed3\u6784\u548c\u5c5e\u6027\u4e4b\u95f4\u7684\u534f\u540c\u5173\u7cfb\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2506.22186", "pdf": "https://arxiv.org/pdf/2506.22186", "abs": "https://arxiv.org/abs/2506.22186", "authors": ["Kaikai Zheng", "Dawei Shi", "Yang Shi", "Long Wang"], "title": "Thompson Sampling-Based Learning and Control for Unknown Dynamic Systems", "categories": ["cs.LG"], "comment": null, "summary": "Thompson sampling (TS) is an effective method to explore parametric\nuncertainties and can therefore be used for active learning-based controller\ndesign. However, TS relies on finite parametric representations, which limits\nits applicability to more general spaces, which are more commonly encountered\nin control system design. To address this issue, this work pro poses a\nparameterization method for control law learning using reproducing kernel\nHilbert spaces and designs a data-driven active learning control approach.\nSpecifically, the proposed method treats the control law as an element in a\nfunction space, allowing the design of control laws without imposing\nrestrictions on the system structure or the form of the controller. A TS\nframework is proposed in this work to explore potential optimal control laws,\nand the convergence guarantees are further provided for the learning process.\nTheoretical analysis shows that the proposed method learns the relationship\nbetween control laws and closed-loop performance metrics at an exponential\nrate, and the upper bound of control regret is also derived. Numerical\nexperiments on controlling unknown nonlinear systems validate the effectiveness\nof the proposed method.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u7684\u63a7\u5236\u5f8b\u5b66\u4e60\u53c2\u6570\u5316\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u6570\u636e\u9a71\u52a8\u7684\u4e3b\u52a8\u5b66\u4e60\u63a7\u5236\u65b9\u6cd5\u3002\u901a\u8fc7Thompson sampling\u6846\u67b6\u63a2\u7d22\u6f5c\u5728\u7684\u6700\u4f18\u63a7\u5236\u5f8b\uff0c\u7406\u8bba\u5206\u6790\u8868\u660e\u8be5\u65b9\u6cd5\u4ee5\u6307\u6570\u901f\u7387\u5b66\u4e60\u63a7\u5236\u5f8b\u4e0e\u95ed\u73af\u6027\u80fd\u6307\u6807\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u63a8\u5bfc\u4e86\u63a7\u5236\u540e\u6094\u503c\u7684\u4e0a\u754c\u3002\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u672a\u77e5\u975e\u7ebf\u6027\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u7684Thompson sampling\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6709\u9650\u7684\u53c2\u6570\u8868\u793a\uff0c\u9650\u5236\u4e86\u5176\u5728\u66f4\u901a\u7528\u7a7a\u95f4\u4e2d\u7684\u5e94\u7528\uff0c\u800c\u8fd9\u4e9b\u7a7a\u95f4\u5728\u63a7\u5236\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u66f4\u4e3a\u5e38\u89c1\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e00\u9650\u5236\u3002", "method": "1. \u63d0\u51fa\u57fa\u4e8e\u518d\u751f\u6838\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\u7684\u63a7\u5236\u5f8b\u5b66\u4e60\u53c2\u6570\u5316\u65b9\u6cd5\u3002\n2. \u8bbe\u8ba1\u6570\u636e\u9a71\u52a8\u7684\u4e3b\u52a8\u5b66\u4e60\u63a7\u5236\u65b9\u6cd5\uff0c\u5c06\u63a7\u5236\u5f8b\u89c6\u4e3a\u51fd\u6570\u7a7a\u95f4\u4e2d\u7684\u5143\u7d20\u3002\n3. \u6784\u5efaThompson sampling\u6846\u67b6\u4ee5\u63a2\u7d22\u6f5c\u5728\u7684\u6700\u4f18\u63a7\u5236\u5f8b\uff0c\u5e76\u63d0\u4f9b\u5b66\u4e60\u8fc7\u7a0b\u7684\u6536\u655b\u6027\u4fdd\u8bc1\u3002\n4. \u7406\u8bba\u5206\u6790\u65b9\u6cd5\u7684\u5b66\u4e60\u901f\u7387\u548c\u63a7\u5236\u540e\u6094\u503c\u7684\u4e0a\u754c\u3002\n5. \u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u4ee5\u6307\u6570\u901f\u7387\u5b66\u4e60\u63a7\u5236\u5f8b\u4e0e\u95ed\u73af\u6027\u80fd\u6307\u6807\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u63a8\u5bfc\u51fa\u4e86\u63a7\u5236\u540e\u6094\u503c\u7684\u4e0a\u754c\u3002\u6570\u503c\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u63a7\u5236\u672a\u77e5\u975e\u7ebf\u6027\u7cfb\u7edf\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u514b\u670d\u4e86\u4f20\u7edfThompson sampling\u65b9\u6cd5\u7684\u9650\u5236\uff0c\u9002\u7528\u4e8e\u66f4\u901a\u7528\u7684\u7a7a\u95f4\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u5b66\u4e60\u63a7\u5236\u5f8b\u4e0e\u6027\u80fd\u6307\u6807\u5173\u7cfb\u65b9\u9762\u5177\u6709\u9ad8\u6548\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2506.22189", "pdf": "https://arxiv.org/pdf/2506.22189", "abs": "https://arxiv.org/abs/2506.22189", "authors": ["Laura van Weesep", "Samuel Genheden", "Ola Engkvist", "Jens Sj\u00f6lund"], "title": "Exploring Modularity of Agentic Systems for Drug Discovery", "categories": ["cs.LG", "cs.CL", "cs.MA"], "comment": null, "summary": "Large-language models (LLMs) and agentic systems present exciting\nopportunities to accelerate drug discovery and design. In this study, we\ncritically examine the modularity of LLM-based agentic systems for drug\ndiscovery, i.e., whether parts of the agentic system such as the LLM are\ninterchangeable, a topic that has received limited attention in drug discovery\napplications. We compare the performance of different large language models\n(LLMs) and the effectiveness of tool-calling agents versus code-generating\nagents in this domain. Our case study, comparing performance in orchestrating\ntools for chemistry and drug discovery using an LLM-as-a-judge score, shows\nthat Claude-3.5-Sonnet, Claude-3.7-Sonnet and GPT-4o outperform alternative\nlanguage models such as Llama-3.1-8B, Llama-3.1-70B, GPT-3.5-Turbo, and\nNova-Micro. Although we confirm that code-generating agents outperform the\ntool-calling ones on average, we show that this is highly question and model\ndependent. Furthermore, the impact of replacing system prompts is dependent on\nthe specific question asked and the model used, underscoring that -- even in\nthis particular domain -- one cannot just replace language models without\nconsidering prompt re-engineering. Our study highlights the necessity of\nfurther research into the modularity of agentic systems to enable the\ndevelopment of stable and scalable solutions for real-world problems.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u4ee3\u7406\u7cfb\u7edf\u5728\u836f\u7269\u53d1\u73b0\u4e0e\u8bbe\u8ba1\u4e2d\u63d0\u4f9b\u4e86\u4ee4\u4eba\u5174\u594b\u7684\u673a\u4f1a\u3002\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u7cfb\u7edf\u7684\u6a21\u5757\u5316\u7279\u6027\uff0c\u5373LLM\u7b49\u7ec4\u4ef6\u662f\u5426\u53ef\u4e92\u6362\u3002\u901a\u8fc7\u5bf9\u6bd4\u4e0d\u540cLLM\u53ca\u5de5\u5177\u8c03\u7528\u578b\u4e0e\u4ee3\u7801\u751f\u6210\u578b\u4ee3\u7406\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u8868\u660eClaude-3.5-Sonnet\u3001Claude-3.7-Sonnet\u548cGPT-4o\u8868\u73b0\u66f4\u4f18\u3002\u5c3d\u7ba1\u4ee3\u7801\u751f\u6210\u578b\u4ee3\u7406\u901a\u5e38\u4f18\u4e8e\u5de5\u5177\u8c03\u7528\u578b\u4ee3\u7406\uff0c\u4f46\u5176\u6548\u679c\u4f9d\u8d56\u4e8e\u5177\u4f53\u95ee\u9898\u548c\u6a21\u578b\u3002\u6b64\u5916\uff0c\u63d0\u793a\u8bcd\u66ff\u6362\u7684\u5f71\u54cd\u4e5f\u56e0\u95ee\u9898\u548c\u6a21\u578b\u800c\u5f02\uff0c\u8fd9\u8868\u660e\u5373\u4f7f\u5728\u6b64\u7279\u5b9a\u9886\u57df\u5185\uff0c\u4e5f\u4e0d\u80fd\u7b80\u5355\u5730\u66f4\u6362\u8bed\u8a00\u6a21\u578b\u800c\u4e0d\u8003\u8651\u63d0\u793a\u8bcd\u7684\u91cd\u65b0\u8bbe\u8ba1\u3002", "motivation": "\u63a2\u7d22\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u7cfb\u7edf\u5728\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u6a21\u5757\u5316\u7279\u6027\uff0c\u7279\u522b\u662fLLM\u7ec4\u4ef6\u7684\u53ef\u4e92\u6362\u6027\uff0c\u4ee5\u63a8\u52a8\u7a33\u5b9a\u4e14\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u7684\u53d1\u5c55\u3002", "method": "\u6bd4\u8f83\u4e0d\u540cLLM\u5728\u836f\u7269\u53d1\u73b0\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5206\u6790\u5de5\u5177\u8c03\u7528\u578b\u4e0e\u4ee3\u7801\u751f\u6210\u578b\u4ee3\u7406\u7684\u6548\u679c\u5dee\u5f02\uff0c\u540c\u65f6\u8bc4\u4f30\u7cfb\u7edf\u63d0\u793a\u8bcd\u66ff\u6362\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "Claude-3.5-Sonnet\u3001Claude-3.7-Sonnet\u548cGPT-4o\u8868\u73b0\u6700\u4f73\uff1b\u4ee3\u7801\u751f\u6210\u578b\u4ee3\u7406\u901a\u5e38\u4f18\u4e8e\u5de5\u5177\u8c03\u7528\u578b\u4ee3\u7406\uff0c\u4f46\u6548\u679c\u53d6\u51b3\u4e8e\u5177\u4f53\u95ee\u9898\u548c\u6a21\u578b\uff1b\u63d0\u793a\u8bcd\u66ff\u6362\u7684\u5f71\u54cd\u4e5f\u5177\u6709\u95ee\u9898\u548c\u6a21\u578b\u76f8\u5173\u6027\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee3\u7406\u7cfb\u7edf\u7684\u6a21\u5757\u5316\u7279\u6027\uff0c\u4ee5\u5f00\u53d1\u9002\u7528\u4e8e\u5b9e\u9645\u95ee\u9898\u7684\u7a33\u5b9a\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.22342", "pdf": "https://arxiv.org/pdf/2506.22342", "abs": "https://arxiv.org/abs/2506.22342", "authors": ["Zihan Guan", "Zhiyuan Zhao", "Fengwei Tian", "Dung Nguyen", "Payel Bhattacharjee", "Ravi Tandon", "B. Aditya Prakash", "Anil Vullikanti"], "title": "A Framework for Multi-source Privacy Preserving Epidemic Analysis", "categories": ["cs.LG", "cs.AI"], "comment": "17 pages, 6 figures", "summary": "It is now well understood that diverse datasets provide a lot of value in key\nepidemiology and public health analyses, such as forecasting and nowcasting,\ndevelopment of epidemic models, evaluation and design of interventions and\nresource allocation. Some of these datasets are often sensitive, and need\nadequate privacy protections. There are many models of privacy, but\nDifferential Privacy (DP) has become a de facto standard because of its strong\nguarantees, without making models about adversaries. In this paper, we develop\na framework the integrates deep learning and epidemic models to simultaneously\nperform epidemic forecasting and learning a mechanistic model of epidemic\nspread, while incorporating multiple datasets for these analyses, including\nsome with DP guarantees. We demonstrate our framework using a realistic but\nsynthetic financial dataset with DP; such a dataset has not been used in such\nepidemic analyses. We show that this dataset provides significant value in\nforecasting and learning an epidemic model, even when used with DP guarantees.", "AI": {"tldr": "\u5c06\u6df1\u5ea6\u5b66\u4e60\u548c\u6d41\u884c\u75c5\u6a21\u578b\u7ed3\u5408\u7684\u6846\u67b6\uff0c\u5229\u7528\u542b\u5dee\u5206\u9690\u79c1\u7684\u6570\u636e\u8fdb\u884c\u6d41\u884c\u75c5\u9884\u6d4b\u548c\u4f20\u64ad\u6a21\u578b\u5b66\u4e60\u3002", "motivation": "\u591a\u5143\u6570\u636e\u96c6\u5728\u6d41\u884c\u75c5\u5b66\u548c\u516c\u5171\u5065\u5eb7\u5206\u6790\u4e2d\u6709\u5f88\u5927\u4ef7\u503c\uff0c\u4f46\u5176\u4e2d\u4e00\u4e9b\u6570\u636e\u96c6\u654f\u611f\uff0c\u9700\u8981\u9690\u79c1\u4fdd\u62a4\u3002\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u56e0\u5f3a\u4fdd\u969c\u800c\u6210\u4e3a\u6807\u51c6\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6574\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u6d41\u884c\u75c5\u6a21\u578b\u7684\u6846\u67b6\uff0c\u540c\u65f6\u8fdb\u884c\u6d41\u884c\u75c5\u9884\u6d4b\u548c\u4f20\u64ad\u6a21\u578b\u7684\u5b66\u4e60\uff0c\u5e76\u7ed3\u5408\u591a\u4e2a\u6570\u636e\u96c6\uff08\u5305\u62ec\u5177\u6709DP\u4fdd\u969c\u7684\u6570\u636e\u96c6\uff09\u3002", "result": "\u4f7f\u7528\u5177\u6709\u5dee\u5206\u9690\u79c1\u7684\u5408\u6210\u91d1\u878d\u6570\u636e\u96c6\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u7684\u4ef7\u503c\uff0c\u5373\u4f7f\u5728DP\u4fdd\u969c\u4e0b\uff0c\u8be5\u6570\u636e\u96c6\u5bf9\u9884\u6d4b\u548c\u5b66\u4e60\u6d41\u884c\u75c5\u6a21\u578b\u4ecd\u6709\u663e\u8457\u8d21\u732e\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u53ef\u4ee5\u6709\u6548\u5730\u7ed3\u5408\u591a\u79cd\u6570\u636e\u6e90\uff0c\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u63d0\u5347\u6d41\u884c\u75c5\u9884\u6d4b\u548c\u6a21\u578b\u5b66\u4e60\u7684\u6548\u679c\u3002"}}
{"id": "2506.22190", "pdf": "https://arxiv.org/pdf/2506.22190", "abs": "https://arxiv.org/abs/2506.22190", "authors": ["Xiaobo Zhao", "Aaron Hurst", "Panagiotis Karras", "Daniel E. Lucani"], "title": "dreaMLearning: Data Compression Assisted Machine Learning", "categories": ["cs.LG", "cs.IT", "eess.SP", "math.IT"], "comment": "18 pages, 11 figures", "summary": "Despite rapid advancements, machine learning, particularly deep learning, is\nhindered by the need for large amounts of labeled data to learn meaningful\npatterns without overfitting and immense demands for computation and storage,\nwhich motivate research into architectures that can achieve good performance\nwith fewer resources. This paper introduces dreaMLearning, a novel framework\nthat enables learning from compressed data without decompression, built upon\nEntropy-based Generalized Deduplication (EntroGeDe), an entropy-driven lossless\ncompression method that consolidates information into a compact set of\nrepresentative samples. DreaMLearning accommodates a wide range of data types,\ntasks, and model architectures. Extensive experiments on regression and\nclassification tasks with tabular and image data demonstrate that dreaMLearning\naccelerates training by up to 8.8x, reduces memory usage by 10x, and cuts\nstorage by 42%, with a minimal impact on model performance. These advancements\nenhance diverse ML applications, including distributed and federated learning,\nand tinyML on resource-constrained edge devices, unlocking new possibilities\nfor efficient and scalable learning.", "AI": {"tldr": "\u5c3d\u7ba1\u673a\u5668\u5b66\u4e60\u7279\u522b\u662f\u6df1\u5ea6\u5b66\u4e60\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u5176\u5bf9\u5927\u91cf\u6807\u6ce8\u6570\u636e\u3001\u8ba1\u7b97\u548c\u5b58\u50a8\u7684\u9700\u6c42\u4ecd\u7136\u5f88\u9ad8\u3002\u672c\u6587\u63d0\u51fa\u4e86dreaMLearning\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5141\u8bb8\u5728\u4e0d\u89e3\u538b\u7684\u60c5\u51b5\u4e0b\u4ece\u538b\u7f29\u6570\u636e\u4e2d\u5b66\u4e60\uff0c\u57fa\u4e8e\u71b5\u9a71\u52a8\u7684\u65e0\u635f\u538b\u7f29\u65b9\u6cd5EntroGeDe\u3002\u5b9e\u9a8c\u8868\u660e\uff0cdreaMLearning\u53ef\u4ee5\u52a0\u901f\u8bad\u7ec3\u3001\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u548c\u5b58\u50a8\u9700\u6c42\uff0c\u540c\u65f6\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u8f83\u5c0f\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u9700\u8981\u5927\u91cf\u7684\u6807\u6ce8\u6570\u636e\u4ee5\u907f\u514d\u8fc7\u62df\u5408\uff0c\u5e76\u4e14\u5bf9\u8ba1\u7b97\u548c\u5b58\u50a8\u8d44\u6e90\u7684\u9700\u6c42\u5de8\u5927\uff0c\u8fd9\u63a8\u52a8\u4e86\u7814\u7a76\u5982\u4f55\u7528\u66f4\u5c11\u8d44\u6e90\u83b7\u5f97\u826f\u597d\u6027\u80fd\u7684\u65b0\u67b6\u6784\u3002", "method": "\u5f15\u5165\u4e86dreaMLearning\u6846\u67b6\uff0c\u5b83\u57fa\u4e8eEntropy-based Generalized Deduplication (EntroGeDe) \u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4e0d\u89e3\u538b\u7684\u60c5\u51b5\u4e0b\u76f4\u63a5\u4ece\u538b\u7f29\u6570\u636e\u4e2d\u8fdb\u884c\u5b66\u4e60\u3002\u6b64\u6846\u67b6\u9002\u7528\u4e8e\u591a\u79cd\u6570\u636e\u7c7b\u578b\u3001\u4efb\u52a1\u548c\u6a21\u578b\u67b6\u6784\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0cdreaMLearning\u53ef\u4ee5\u5c06\u8bad\u7ec3\u901f\u5ea6\u63d0\u9ad8\u81f38.8\u500d\uff0c\u51cf\u5c1110\u500d\u7684\u5185\u5b58\u4f7f\u7528\uff0c\u5e76\u964d\u4f4e42%\u7684\u5b58\u50a8\u9700\u6c42\uff0c\u540c\u65f6\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u6781\u5c0f\u3002", "conclusion": "dreaMLearning\u4e3a\u5404\u79cd\u673a\u5668\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u5305\u62ec\u5206\u5e03\u5f0f\u5b66\u4e60\u3001\u8054\u90a6\u5b66\u4e60\u4ee5\u53ca\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684tinyML\uff0c\u63d0\u9ad8\u4e86\u5b66\u4e60\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2506.22374", "pdf": "https://arxiv.org/pdf/2506.22374", "abs": "https://arxiv.org/abs/2506.22374", "authors": ["Abdulmomen Ghalkha", "Zhuojun Tian", "Chaouki Ben Issaid", "Mehdi Bennis"], "title": "Sheaf-Based Decentralized Multimodal Learning for Next-Generation Wireless Communication Systems", "categories": ["cs.LG", "cs.AI"], "comment": "13 pages, 9 figures", "summary": "In large-scale communication systems, increasingly complex scenarios require\nmore intelligent collaboration among edge devices collecting various multimodal\nsensory data to achieve a more comprehensive understanding of the environment\nand improve decision-making accuracy. However, conventional federated learning\n(FL) algorithms typically consider unimodal datasets, require identical model\narchitectures, and fail to leverage the rich information embedded in multimodal\ndata, limiting their applicability to real-world scenarios with diverse\nmodalities and varying client capabilities. To address this issue, we propose\nSheaf-DMFL, a novel decentralized multimodal learning framework leveraging\nsheaf theory to enhance collaboration among devices with diverse modalities.\nSpecifically, each client has a set of local feature encoders for its different\nmodalities, whose outputs are concatenated before passing through a\ntask-specific layer. While encoders for the same modality are trained\ncollaboratively across clients, we capture the intrinsic correlations among\nclients' task-specific layers using a sheaf-based structure. To further enhance\nlearning capability, we propose an enhanced algorithm named Sheaf-DMFL-Att,\nwhich tailors the attention mechanism within each client to capture\ncorrelations among different modalities. A rigorous convergence analysis of\nSheaf-DMFL-Att is provided, establishing its theoretical guarantees. Extensive\nsimulations are conducted on real-world link blockage prediction and mmWave\nbeamforming scenarios, demonstrate the superiority of the proposed algorithms\nin such heterogeneous wireless communication systems.", "AI": {"tldr": "In large-scale communication systems, conventional federated learning (FL) algorithms are limited in their applicability to real-world scenarios with diverse modalities. This paper proposes Sheaf-DMFL and Sheaf-DMFL-Att, which leverage sheaf theory and attention mechanisms respectively, to enhance collaboration among devices with diverse modalities.", "motivation": "Conventional FL algorithms typically consider unimodal datasets, require identical model architectures, and fail to leverage the rich information embedded in multimodal data.", "method": "Sheaf-DMFL is a decentralized multimodal learning framework leveraging sheaf theory. Each client has local feature encoders for different modalities, whose outputs are concatenated before passing through a task-specific layer. Encoders for the same modality are trained collaboratively across clients while capturing intrinsic correlations among clients' task-specific layers using a sheaf-based structure. Sheaf-DMFL-Att is an enhanced algorithm that tailors the attention mechanism within each client to capture correlations among different modalities.", "result": "Extensive simulations on real-world link blockage prediction and mmWave beamforming scenarios demonstrate the superiority of the proposed algorithms in heterogeneous wireless communication systems.", "conclusion": "Sheaf-DMFL and Sheaf-DMFL-Att provide theoretical guarantees and enhance collaboration among devices with diverse modalities."}}
{"id": "2506.22199", "pdf": "https://arxiv.org/pdf/2506.22199", "abs": "https://arxiv.org/abs/2506.22199", "authors": ["Jakub Pele\u0161ka", "Gustav \u0160\u00edr"], "title": "REDELEX: A Framework for Relational Deep Learning Exploration", "categories": ["cs.LG", "cs.DB"], "comment": "Accepted to ECMLPKDD 2025 at Porto, Portugal", "summary": "Relational databases (RDBs) are widely regarded as the gold standard for\nstoring structured information. Consequently, predictive tasks leveraging this\ndata format hold significant application promise. Recently, Relational Deep\nLearning (RDL) has emerged as a novel paradigm wherein RDBs are conceptualized\nas graph structures, enabling the application of various graph neural\narchitectures to effectively address these tasks. However, given its novelty,\nthere is a lack of analysis into the relationships between the performance of\nvarious RDL models and the characteristics of the underlying RDBs.\n  In this study, we present REDELEX$-$a comprehensive exploration framework for\nevaluating RDL models of varying complexity on the most diverse collection of\nover 70 RDBs, which we make available to the community. Benchmarked alongside\nkey representatives of classic methods, we confirm the generally superior\nperformance of RDL while providing insights into the main factors shaping\nperformance, including model complexity, database sizes and their structural\nproperties.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5173\u7cfb\u6df1\u5ea6\u5b66\u4e60\uff08RDL\uff09\u6a21\u578b\u5728\u4e0d\u540c\u5173\u7cfb\u578b\u6570\u636e\u5e93\uff08RDBs\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u901a\u8fc7\u4e00\u4e2a\u540d\u4e3aREDELEX\u7684\u6846\u67b6\u5bf970\u591a\u4e2aRDB\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002\u7814\u7a76\u8868\u660e\uff0cRDL\u6a21\u578b\u901a\u5e38\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u5f71\u54cd\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5982\u6a21\u578b\u590d\u6742\u6027\u3001\u6570\u636e\u5e93\u5927\u5c0f\u53ca\u5176\u7ed3\u6784\u7279\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5173\u7cfb\u6df1\u5ea6\u5b66\u4e60\uff08RDL\uff09\u4f5c\u4e3a\u65b0\u8303\u5f0f\u51fa\u73b0\uff0c\u4f46\u5c1a\u7f3a\u4e4f\u5bf9RDL\u6a21\u578b\u6027\u80fd\u4e0e\u5e95\u5c42\u5173\u7cfb\u578b\u6570\u636e\u5e93\uff08RDBs\uff09\u7279\u6027\u7684\u7cfb\u7edf\u5206\u6790\u3002\u56e0\u6b64\uff0c\u9700\u8981\u6df1\u5165\u7814\u7a76\u8fd9\u4e9b\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u5e93\u4e0a\u7684\u8868\u73b0\u53ca\u5f71\u54cd\u56e0\u7d20\u3002", "method": "\u7814\u7a76\u8005\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aREDELEX\u7684\u7efc\u5408\u63a2\u7d22\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e0d\u540c\u590d\u6742\u5ea6\u7684RDL\u6a21\u578b\u5728\u8d85\u8fc770\u4e2a\u5173\u7cfb\u578b\u6570\u636e\u5e93\u4e0a\u7684\u8868\u73b0\u3002\u8be5\u6846\u67b6\u8fd8\u5bf9\u6bd4\u4e86\u7ecf\u5178\u65b9\u6cd5\u7684\u5173\u952e\u4ee3\u8868\uff0c\u5e76\u5206\u6790\u4e86\u6a21\u578b\u590d\u6742\u6027\u3001\u6570\u636e\u5e93\u5927\u5c0f\u548c\u7ed3\u6784\u5c5e\u6027\u7b49\u56e0\u7d20\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRDL\u6a21\u578b\u901a\u5e38\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u7814\u7a76\u63ed\u793a\u4e86\u6a21\u578b\u590d\u6742\u6027\u3001\u6570\u636e\u5e93\u89c4\u6a21\u53ca\u5176\u7ed3\u6784\u7279\u6027\u662f\u5f71\u54cd\u6027\u80fd\u7684\u4e3b\u8981\u56e0\u7d20\u3002", "conclusion": "\u901a\u8fc7REDELEX\u6846\u67b6\u7684\u8bc4\u4f30\uff0c\u786e\u8ba4\u4e86RDL\u6a21\u578b\u5728\u9884\u6d4b\u4efb\u52a1\u4e2d\u7684\u4f18\u8d8a\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u4e8e\u5f71\u54cd\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u7684\u91cd\u8981\u89c1\u89e3\u3002"}}
{"id": "2506.22376", "pdf": "https://arxiv.org/pdf/2506.22376", "abs": "https://arxiv.org/abs/2506.22376", "authors": ["Youkang Wang", "Jian Wang", "Rubing Chen", "Xiao-Yong Wei", "Qing Li"], "title": "Probabilistic Optimality for Inference-time Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Inference-time scaling has emerged as a powerful technique for enhancing the\nreasoning performance of Large Language Models (LLMs). However, existing\napproaches often rely on heuristic strategies for parallel sampling, lacking a\nprincipled foundation. To address this gap, we propose a probabilistic\nframework that formalizes the optimality of inference-time scaling under the\nassumption that parallel samples are independently and identically distributed\n(i.i.d.), and where the Best-of-N selection strategy follows a probability\ndistribution that can be estimated. Within this framework, we derive a\ntheoretical lower bound on the required number of samples to achieve a target\nperformance level, providing the first principled guidance for\ncompute-efficient scaling. Leveraging this insight, we develop\n\\textsc{OptScale}, a practical algorithm that dynamically determines the\noptimal number of sampled responses. \\textsc{OptScale} employs a language\nmodel-based predictor to estimate probabilistic prior parameters, enabling the\ndecision of the minimal number of samples needed that satisfy predefined\nperformance thresholds and confidence levels. Extensive experiments on\nmathematical reasoning benchmarks (including MATH-500, GSM8K, AIME, and AMC)\ndemonstrate that \\textsc{OptScale} significantly reduces sampling overhead\nwhile remaining better or on par with state-of-the-art reasoning performance.\nOur work offers both a theoretical foundation and a practical solution for\nprincipled inference-time scaling, addressing a critical gap in the efficient\ndeployment of LLMs for complex reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6982\u7387\u6846\u67b6\u548c\u7b97\u6cd5OptScale\uff0c\u7528\u4e8e\u4f18\u5316\u63a8\u7406\u65f6\u6269\u5c55\u7684\u6837\u672c\u6570\u91cf\uff0c\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u7406\u65f6\u6269\u5c55\u6280\u672f\u4f9d\u8d56\u4e8e\u542f\u53d1\u5f0f\u7b56\u7565\uff0c\u7f3a\u4e4f\u7406\u8bba\u57fa\u7840\u3002", "method": "\u901a\u8fc7\u5047\u8bbe\u5e73\u884c\u6837\u672c\u72ec\u7acb\u540c\u5206\u5e03\uff0c\u63d0\u51fa\u6982\u7387\u6846\u67b6\u5e76\u63a8\u5bfc\u51fa\u8fbe\u5230\u76ee\u6807\u6027\u80fd\u6240\u9700\u7684\u6837\u672c\u6570\u7684\u7406\u8bba\u4e0b\u9650\u3002\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86OptScale\u7b97\u6cd5\uff0c\u52a8\u6001\u51b3\u5b9a\u6700\u4f18\u6837\u672c\u6570\u3002", "result": "\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cOptScale\u663e\u8457\u51cf\u5c11\u4e86\u91c7\u6837\u5f00\u9500\uff0c\u4e14\u6027\u80fd\u4f18\u4e8e\u6216\u4e0e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\u6301\u5e73\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u63a8\u7406\u65f6\u6269\u5c55\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86LLM\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u9ad8\u6548\u90e8\u7f72\u3002"}}
{"id": "2506.22389", "pdf": "https://arxiv.org/pdf/2506.22389", "abs": "https://arxiv.org/abs/2506.22389", "authors": ["Aditya Cowsik", "Tianyu He", "Andrey Gromov"], "title": "Towards Distributed Neural Architectures", "categories": ["cs.LG", "cond-mat.dis-nn", "cs.AI"], "comment": "36 pages, 25 figures", "summary": "We introduce and train distributed neural architectures (DNA) in vision and\nlanguage domains. DNAs are initialized with a proto-architecture that consists\nof (transformer, MLP, attention, etc.) modules and routers. Any token (or\npatch) can traverse any series of modules in any order. DNAs are a natural\ngeneralization of the sparse methods such as Mixture-of-Experts,\nMixture-of-Depths, parameter sharing, etc. Computation and communication\npatterns of DNA modules are learnt end-to-end during training and depend on the\ncontent and context of each token (or patch). These patterns can be shaped by\nfurther requirements added to the optimization objective such as compute/memory\nefficiency or load balancing. We empirically show that (i) trained DNAs are\ncompetitive with the dense baselines in both domains and (ii) compute\nefficiency/parameter sharing can be learnt from data. Next, we analyze the\nemergent connectivity and computation patterns in the trained DNAs. We find\nthat the paths that tokens take through the models are themselves distributed\naccording to a power-law. We show that some paths (or, equivalently, groups of\nmodules) show emergent specialization. Finally, we demonstrate that models\nlearn to allocate compute and active parameters in an interpretable way.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u5e76\u8bad\u7ec3\u4e86\u5206\u5e03\u5f0f\u795e\u7ecf\u67b6\u6784\uff08DNA\uff09\uff0c\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u9886\u57df\u5b9e\u73b0\u4e86\u4e0e\u5bc6\u96c6\u6a21\u578b\u57fa\u7ebf\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u8ba1\u7b97\u6548\u7387/\u53c2\u6570\u5171\u4eab\u53ef\u4ee5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u5206\u6790\u4e86\u8bad\u7ec3\u540e\u7684DNA\u4e2d\u7684\u8fde\u63a5\u6027\u548c\u8ba1\u7b97\u6a21\u5f0f\uff0c\u53d1\u73b0\u8def\u5f84\u5206\u5e03\u7b26\u5408\u5e42\u5f8b\uff0c\u90e8\u5206\u8def\u5f84\u8868\u73b0\u51fa\u81ea\u53d1\u7684\u4e13\u4e1a\u5316\uff0c\u6a21\u578b\u80fd\u591f\u4ee5\u53ef\u89e3\u91ca\u7684\u65b9\u5f0f\u5206\u914d\u8ba1\u7b97\u548c\u6fc0\u6d3b\u53c2\u6570\u3002", "motivation": "\u4e3a\u4e86\u63a2\u7d22\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u66f4\u9ad8\u6548\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u80fd\u591f\u6839\u636e\u6bcf\u4e2atoken\u6216patch\u7684\u5185\u5bb9\u548c\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u5730\u8c03\u6574\u8ba1\u7b97\u548c\u901a\u4fe1\u6a21\u5f0f\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u5bc6\u96c6\u6a21\u578b\u57fa\u7ebf\u76f8\u5f53\u7684\u6027\u80fd\u3002", "method": "\u521d\u59cb\u5316\u4e00\u4e2a\u5305\u542b\uff08transformer\u3001MLP\u3001attention\u7b49\uff09\u6a21\u5757\u548c\u8def\u7531\u5668\u7684\u539f\u578b\u67b6\u6784\uff0c\u4efb\u4f55token\u6216patch\u53ef\u4ee5\u4ee5\u4efb\u610f\u987a\u5e8f\u901a\u8fc7\u4efb\u610f\u7cfb\u5217\u7684\u6a21\u5757\u3002\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7aef\u5230\u7aef\u5b66\u4e60DNA\u6a21\u5757\u7684\u8ba1\u7b97\u548c\u901a\u4fe1\u6a21\u5f0f\uff0c\u5e76\u53ef\u6839\u636e\u4f18\u5316\u76ee\u6807\u8fdb\u4e00\u6b65\u6dfb\u52a0\u5982\u8ba1\u7b97/\u5185\u5b58\u6548\u7387\u6216\u8d1f\u8f7d\u5e73\u8861\u7b49\u8981\u6c42\u3002", "result": "(i) \u8bad\u7ec3\u540e\u7684DNA\u5728\u4e24\u4e2a\u9886\u57df\u4e2d\u4e0e\u5bc6\u96c6\u57fa\u7ebf\u5177\u6709\u7ade\u4e89\u529b\uff1b(ii) \u8ba1\u7b97\u6548\u7387/\u53c2\u6570\u5171\u4eab\u53ef\u4ee5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\uff1b(iii) \u6a21\u578b\u4e2d\u7684\u8def\u5f84\u5206\u5e03\u7b26\u5408\u5e42\u5f8b\uff1b(iv) \u90e8\u5206\u8def\u5f84\u8868\u73b0\u51fa\u81ea\u53d1\u7684\u4e13\u4e1a\u5316\uff1b(v) \u6a21\u578b\u80fd\u591f\u4ee5\u53ef\u89e3\u91ca\u7684\u65b9\u5f0f\u5206\u914d\u8ba1\u7b97\u548c\u6fc0\u6d3b\u53c2\u6570\u3002", "conclusion": "\u5206\u5e03\u5f0f\u795e\u7ecf\u67b6\u6784\uff08DNA\uff09\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u8bbe\u8ba1\u7075\u6d3b\u3001\u9ad8\u6548\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u5176\u8ba1\u7b97\u548c\u901a\u4fe1\u6a21\u5f0f\u53ef\u4ee5\u6839\u636e\u6570\u636e\u5185\u5bb9\u548c\u4e0a\u4e0b\u6587\u81ea\u9002\u5e94\u8c03\u6574\uff0c\u540c\u65f6\u5c55\u73b0\u51fa\u81ea\u53d1\u7684\u4e13\u4e1a\u5316\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2506.22253", "pdf": "https://arxiv.org/pdf/2506.22253", "abs": "https://arxiv.org/abs/2506.22253", "authors": ["Shunta Nonaga", "Koji Tabata", "Yuta Mizuno", "Tamiki Komatsuzaki"], "title": "Risk-Averse Best Arm Set Identification with Fixed Budget and Fixed Confidence", "categories": ["cs.LG"], "comment": null, "summary": "Decision making under uncertain environments in the maximization of expected\nreward while minimizing its risk is one of the ubiquitous problems in many\nsubjects. Here, we introduce a novel problem setting in stochastic bandit\noptimization that jointly addresses two critical aspects of decision-making:\nmaximizing expected reward and minimizing associated uncertainty, quantified\nvia the mean-variance(MV) criterion. Unlike traditional bandit formulations\nthat focus solely on expected returns, our objective is to efficiently and\naccurately identify the Pareto-optimal set of arms that strikes the best\ntrade-off between expected performance and risk. We propose a unified\nmeta-algorithmic framework capable of operating under both fixed-confidence and\nfixed-budget regimes, achieved through adaptive design of confidence intervals\ntailored to each scenario using the same sample exploration strategy. We\nprovide theoretical guarantees on the correctness of the returned solutions in\nboth settings. To complement this theoretical analysis, we conduct extensive\nempirical evaluations across synthetic benchmarks, demonstrating that our\napproach outperforms existing methods in terms of both accuracy and sample\nefficiency, highlighting its broad applicability to risk-aware decision-making\ntasks in uncertain environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u968f\u673a\u591a\u81c2\u8001\u864e\u673a\u4f18\u5316\u95ee\u9898\u8bbe\u5b9a\uff0c\u901a\u8fc7\u5747\u503c-\u65b9\u5dee\u6807\u51c6\u540c\u65f6\u89e3\u51b3\u6700\u5927\u5316\u671f\u671b\u56de\u62a5\u548c\u6700\u5c0f\u5316\u4e0d\u786e\u5b9a\u6027\u7684\u95ee\u9898\u3002\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5143\u7b97\u6cd5\u6846\u67b6\uff0c\u80fd\u591f\u5728\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u548c\u56fa\u5b9a\u9884\u7b97\u6761\u4ef6\u4e0b\u8fd0\u884c\uff0c\u5e76\u901a\u8fc7\u81ea\u9002\u5e94\u7f6e\u4fe1\u533a\u95f4\u8bbe\u8ba1\u5b9e\u73b0\u3002\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002", "motivation": "\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\uff0c\u51b3\u7b56\u9700\u8981\u540c\u65f6\u8003\u8651\u6700\u5927\u5316\u671f\u671b\u56de\u62a5\u548c\u6700\u5c0f\u5316\u98ce\u9669\u3002\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u53ea\u5173\u6ce8\u671f\u671b\u56de\u62a5\uff0c\u7f3a\u4e4f\u5bf9\u98ce\u9669\u7684\u8003\u91cf\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u5e73\u8861\u56de\u62a5\u4e0e\u98ce\u9669\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5747\u503c-\u65b9\u5dee\u6807\u51c6\u7684\u65b0\u95ee\u9898\u8bbe\u5b9a\uff0c\u76ee\u6807\u662f\u627e\u5230\u5728\u671f\u671b\u56de\u62a5\u548c\u98ce\u9669\u4e4b\u95f4\u8fbe\u5230\u6700\u4f73\u5e73\u8861\u7684Pareto\u6700\u4f18\u81c2\u96c6\u5408\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u5143\u7b97\u6cd5\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u548c\u56fa\u5b9a\u9884\u7b97\u4e24\u79cd\u573a\u666f\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7f6e\u4fe1\u533a\u95f4\u8bbe\u8ba1\u5b9e\u73b0\u9ad8\u6548\u63a2\u7d22\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u4e24\u79cd\u573a\u666f\u4e0b\u7684\u6b63\u786e\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6837\u672c\u6548\u7387\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\u7684\u98ce\u9669\u611f\u77e5\u51b3\u7b56\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.22393", "pdf": "https://arxiv.org/pdf/2506.22393", "abs": "https://arxiv.org/abs/2506.22393", "authors": ["YongKyung Oh", "Alex Bui"], "title": "Multi-View Contrastive Learning for Robust Domain Adaptation in Medical Time Series Analysis", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Adapting machine learning models to medical time series across different\ndomains remains a challenge due to complex temporal dependencies and dynamic\ndistribution shifts. Current approaches often focus on isolated feature\nrepresentations, limiting their ability to fully capture the intricate temporal\ndynamics necessary for robust domain adaptation. In this work, we propose a\nnovel framework leveraging multi-view contrastive learning to integrate\ntemporal patterns, derivative-based dynamics, and frequency-domain features.\nOur method employs independent encoders and a hierarchical fusion mechanism to\nlearn feature-invariant representations that are transferable across domains\nwhile preserving temporal coherence. Extensive experiments on diverse medical\ndatasets, including electroencephalogram (EEG), electrocardiogram (ECG), and\nelectromyography (EMG) demonstrate that our approach significantly outperforms\nstate-of-the-art methods in transfer learning tasks. By advancing the\nrobustness and generalizability of machine learning models, our framework\noffers a practical pathway for deploying reliable AI systems in diverse\nhealthcare settings.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u5229\u7528\u591a\u89c6\u89d2\u5bf9\u6bd4\u5b66\u4e60\u5c06\u65f6\u95f4\u6a21\u5f0f\u3001\u57fa\u4e8e\u5bfc\u6570\u7684\u52a8\u529b\u5b66\u548c\u9891\u57df\u7279\u5f81\u7ed3\u5408\u8d77\u6765\u3002\u901a\u8fc7\u72ec\u7acb\u7f16\u7801\u5668\u548c\u5206\u5c42\u878d\u5408\u673a\u5236\u5b66\u4e60\u53ef\u8de8\u9886\u57df\u8f6c\u79fb\u4e14\u4fdd\u6301\u65f6\u95f4\u4e00\u81f4\u6027\u7684\u7279\u5f81\u4e0d\u53d8\u8868\u793a\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u533b\u7597\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u9002\u5e94\u4e0d\u540c\u9886\u57df\u7684\u533b\u5b66\u65f6\u95f4\u5e8f\u5217\u5bf9\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6765\u8bf4\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u56e0\u4e3a\u5b58\u5728\u590d\u6742\u7684\u65f6\u95f4\u4f9d\u8d56\u6027\u548c\u52a8\u6001\u5206\u5e03\u504f\u79fb\u3002\u5f53\u524d\u65b9\u6cd5\u901a\u5e38\u5173\u6ce8\u5b64\u7acb\u7684\u7279\u5f81\u8868\u793a\uff0c\u9650\u5236\u4e86\u5176\u6355\u6349\u5fc5\u8981\u7684\u65f6\u95f4\u52a8\u529b\u5b66\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u91c7\u7528\u591a\u89c6\u89d2\u5bf9\u6bd4\u5b66\u4e60\u6765\u6574\u5408\u65f6\u95f4\u6a21\u5f0f\u3001\u57fa\u4e8e\u5bfc\u6570\u7684\u52a8\u529b\u5b66\u548c\u9891\u57df\u7279\u5f81\uff0c\u5e76\u4f7f\u7528\u72ec\u7acb\u7f16\u7801\u5668\u548c\u5206\u5c42\u878d\u5408\u673a\u5236\u5b66\u4e60\u53ef\u8de8\u9886\u57df\u8f6c\u79fb\u4e14\u4fdd\u6301\u65f6\u95f4\u4e00\u81f4\u6027\u7684\u7279\u5f81\u4e0d\u53d8\u8868\u793a\u3002", "result": "\u5728\u5305\u62ecEEG\u3001ECG\u548cEMG\u5728\u5185\u7684\u591a\u4e2a\u533b\u7597\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u8fc1\u79fb\u5b66\u4e60\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "conclusion": "\u672c\u6846\u67b6\u63d0\u9ad8\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u5728\u591a\u6837\u5316\u533b\u7597\u73af\u5883\u4e2d\u90e8\u7f72\u53ef\u9760\u7684AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u9645\u9014\u5f84\u3002"}}
{"id": "2506.22427", "pdf": "https://arxiv.org/pdf/2506.22427", "abs": "https://arxiv.org/abs/2506.22427", "authors": ["Randeep Bhatia", "Nikos Papadis", "Murali Kodialam", "TV Lakshman", "Sayak Chakrabarty"], "title": "CLoVE: Personalized Federated Learning through Clustering of Loss Vector Embeddings", "categories": ["cs.LG", "cs.AI"], "comment": "31 pages, 4 figures", "summary": "We propose CLoVE (Clustering of Loss Vector Embeddings), a novel algorithm\nfor Clustered Federated Learning (CFL). In CFL, clients are naturally grouped\ninto clusters based on their data distribution. However, identifying these\nclusters is challenging, as client assignments are unknown. CLoVE utilizes\nclient embeddings derived from model losses on client data, and leverages the\ninsight that clients in the same cluster share similar loss values, while those\nin different clusters exhibit distinct loss patterns. Based on these\nembeddings, CLoVE is able to iteratively identify and separate clients from\ndifferent clusters and optimize cluster-specific models through federated\naggregation. Key advantages of CLoVE over existing CFL algorithms are (1) its\nsimplicity, (2) its applicability to both supervised and unsupervised settings,\nand (3) the fact that it eliminates the need for near-optimal model\ninitialization, which makes it more robust and better suited for real-world\napplications. We establish theoretical convergence bounds, showing that CLoVE\ncan recover clusters accurately with high probability in a single round and\nconverges exponentially fast to optimal models in a linear setting. Our\ncomprehensive experiments comparing with a variety of both CFL and generic\nPersonalized Federated Learning (PFL) algorithms on different types of datasets\nand an extensive array of non-IID settings demonstrate that CLoVE achieves\nhighly accurate cluster recovery in just a few rounds of training, along with\nstate-of-the-art model accuracy, across a variety of both supervised and\nunsupervised PFL tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5CLoVE\uff0c\u901a\u8fc7\u6a21\u578b\u635f\u5931\u7684\u5ba2\u6237\u7aef\u5d4c\u5165\u6765\u8bc6\u522b\u548c\u5206\u79bb\u4e0d\u540c\u96c6\u7fa4\u7684\u5ba2\u6237\u7aef\uff0c\u5e76\u4f18\u5316\u96c6\u7fa4\u7279\u5b9a\u6a21\u578b\u3002\u76f8\u6bd4\u73b0\u6709\u7b97\u6cd5\uff0cCLoVE\u66f4\u7b80\u5355\u3001\u9002\u7528\u8303\u56f4\u66f4\u5e7f\u4e14\u65e0\u9700\u8fd1\u4f3c\u6700\u4f18\u6a21\u578b\u521d\u59cb\u5316\u3002\u5b9e\u9a8c\u8868\u660eCLoVE\u5728\u51e0\u8f6e\u8bad\u7ec3\u4e2d\u5c31\u80fd\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7684\u805a\u7c7b\u6062\u590d\uff0c\u5e76\u5728\u76d1\u7763\u548c\u975e\u76d1\u7763\u4efb\u52a1\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6a21\u578b\u7cbe\u5ea6\u3002", "motivation": "\u5728\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u6839\u636e\u6570\u636e\u5206\u5e03\u5c06\u5ba2\u6237\u7aef\u81ea\u7136\u5206\u7ec4\u4e3a\u96c6\u7fa4\u662f\u4e00\u9879\u6311\u6218\uff0c\u56e0\u4e3a\u5ba2\u6237\u7aef\u5206\u914d\u672a\u77e5\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u8bc6\u522b\u8fd9\u4e9b\u96c6\u7fa4\u5e76\u4f18\u5316\u96c6\u7fa4\u7279\u5b9a\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "method": "CLoVE\u5229\u7528\u4ece\u6a21\u578b\u635f\u5931\u5f97\u51fa\u7684\u5ba2\u6237\u7aef\u5d4c\u5165\uff0c\u57fa\u4e8e\u540c\u4e00\u96c6\u7fa4\u4e2d\u7684\u5ba2\u6237\u7aef\u5177\u6709\u76f8\u4f3c\u635f\u5931\u503c\uff0c\u800c\u4e0d\u540c\u96c6\u7fa4\u4e2d\u7684\u5ba2\u6237\u7aef\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u635f\u5931\u6a21\u5f0f\u8fd9\u4e00\u89c1\u89e3\uff0c\u8fed\u4ee3\u5730\u8bc6\u522b\u548c\u5206\u79bb\u6765\u81ea\u4e0d\u540c\u96c6\u7fa4\u7684\u5ba2\u6237\u7aef\uff0c\u5e76\u901a\u8fc7\u8054\u90a6\u805a\u5408\u4f18\u5316\u96c6\u7fa4\u7279\u5b9a\u6a21\u578b\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0cCLoVE\u80fd\u591f\u5728\u4e00\u8f6e\u4e2d\u4ee5\u9ad8\u6982\u7387\u51c6\u786e\u6062\u590d\u96c6\u7fa4\uff0c\u5e76\u5728\u7ebf\u6027\u8bbe\u7f6e\u4e0b\u5feb\u901f\u6536\u655b\u5230\u6700\u4f18\u6a21\u578b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCLoVE\u5728\u591a\u79cd\u6570\u636e\u96c6\u548c\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u8bbe\u7f6e\u4e0b\uff0c\u4ec5\u9700\u51e0\u8f6e\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7684\u805a\u7c7b\u6062\u590d\uff0c\u5e76\u5728\u76d1\u7763\u548c\u975e\u76d1\u7763\u4e2a\u6027\u5316\u8054\u90a6\u5b66\u4e60\u4efb\u52a1\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6a21\u578b\u7cbe\u5ea6\u3002", "conclusion": "CLoVE\u662f\u4e00\u79cd\u7b80\u5355\u4e14\u9c81\u68d2\u7684\u805a\u7c7b\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u76d1\u7763\u548c\u975e\u76d1\u7763\u8bbe\u7f6e\uff0c\u65e0\u9700\u8fd1\u4f3c\u6700\u4f18\u6a21\u578b\u521d\u59cb\u5316\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.22295", "pdf": "https://arxiv.org/pdf/2506.22295", "abs": "https://arxiv.org/abs/2506.22295", "authors": ["Zhengyun Cheng", "Changhao Wang", "Guanwen Zhang", "Yi Xu", "Wei Zhou", "Xiangyang Ji"], "title": "Score-Based Model for Low-Rank Tensor Recovery", "categories": ["cs.LG"], "comment": null, "summary": "Low-rank tensor decompositions (TDs) provide an effective framework for\nmultiway data analysis. Traditional TD methods rely on predefined structural\nassumptions, such as CP or Tucker decompositions. From a probabilistic\nperspective, these can be viewed as using Dirac delta distributions to model\nthe relationships between shared factors and the low-rank tensor. However, such\nprior knowledge is rarely available in practical scenarios, particularly\nregarding the optimal rank structure and contraction rules. The optimization\nprocedures based on fixed contraction rules are complex, and approximations\nmade during these processes often lead to accuracy loss. To address this issue,\nwe propose a score-based model that eliminates the need for predefined\nstructural or distributional assumptions, enabling the learning of\ncompatibility between tensors and shared factors. Specifically, a neural\nnetwork is designed to learn the energy function, which is optimized via score\nmatching to capture the gradient of the joint log-probability of tensor entries\nand shared factors. Our method allows for modeling structures and distributions\nbeyond the Dirac delta assumption. Moreover, integrating the block coordinate\ndescent (BCD) algorithm with the proposed smooth regularization enables the\nmodel to perform both tensor completion and denoising. Experimental results\ndemonstrate significant performance improvements across various tensor types,\nincluding sparse and continuous-time tensors, as well as visual data.", "AI": {"tldr": "Low-rank tensor decompositions (TDs) are useful for multiway data analysis, but traditional methods rely on predefined assumptions that may not hold in practical scenarios. This paper proposes a score-based model to learn the compatibility between tensors and shared factors without requiring these assumptions. The method uses a neural network to optimize an energy function via score matching and integrates block coordinate descent (BCD) with smooth regularization for tensor completion and denoising.", "motivation": "\u4f20\u7edf\u7684\u4f4e\u79e9\u5f20\u91cf\u5206\u89e3\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u9884\u5b9a\u4e49\u7684\u7ed3\u6784\u5047\u8bbe\uff0c\u5982CP\u6216Tucker\u5206\u89e3\uff0c\u8fd9\u4e9b\u5047\u8bbe\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u5f80\u5f80\u4e0d\u9002\u7528\u3002\u6b64\u5916\uff0c\u57fa\u4e8e\u56fa\u5b9a\u6536\u7f29\u89c4\u5219\u7684\u4f18\u5316\u8fc7\u7a0b\u590d\u6742\u4e14\u5bb9\u6613\u5bfc\u81f4\u7cbe\u5ea6\u635f\u5931\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f97\u5206\u7684\u6a21\u578b\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u7684\u7ed3\u6784\u6216\u5206\u5e03\u5047\u8bbe\uff0c\u901a\u8fc7\u8bbe\u8ba1\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u80fd\u91cf\u51fd\u6570\uff0c\u5e76\u5229\u7528\u5f97\u5206\u5339\u914d\u8fdb\u884c\u4f18\u5316\uff0c\u4ee5\u6355\u6349\u5f20\u91cf\u6761\u76ee\u548c\u5171\u4eab\u56e0\u5b50\u7684\u8054\u5408\u5bf9\u6570\u6982\u7387\u68af\u5ea6\u3002\u540c\u65f6\uff0c\u5c06\u5757\u5750\u6807\u4e0b\u964d\uff08BCD\uff09\u7b97\u6cd5\u4e0e\u5e73\u6ed1\u6b63\u5219\u5316\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u5f20\u91cf\u8865\u5168\u548c\u53bb\u566a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u7c7b\u578b\u7684\u5f20\u91cf\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5305\u62ec\u7a00\u758f\u5f20\u91cf\u3001\u8fde\u7eed\u65f6\u95f4\u5f20\u91cf\u4ee5\u53ca\u89c6\u89c9\u6570\u636e\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u5f97\u5206\u7684\u6a21\u578b\u80fd\u591f\u6709\u6548\u5b66\u4e60\u5f20\u91cf\u4e0e\u5171\u4eab\u56e0\u5b50\u4e4b\u95f4\u7684\u517c\u5bb9\u6027\uff0c\u65e0\u9700\u9884\u5b9a\u4e49\u5047\u8bbe\uff0c\u5e76\u4e14\u5728\u5f20\u91cf\u8865\u5168\u548c\u53bb\u566a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.22301", "pdf": "https://arxiv.org/pdf/2506.22301", "abs": "https://arxiv.org/abs/2506.22301", "authors": ["Takumi Okuo", "Shinnosuke Matsuo", "Shota Harada", "Kiyohito Tanaka", "Ryoma Bise"], "title": "Weakly-Supervised Domain Adaptation with Proportion-Constrained Pseudo-Labeling", "categories": ["cs.LG"], "comment": "Accepted at IJCNN2025", "summary": "Domain shift is a significant challenge in machine learning, particularly in\nmedical applications where data distributions differ across institutions due to\nvariations in data collection practices, equipment, and procedures. This can\ndegrade performance when models trained on source domain data are applied to\nthe target domain. Domain adaptation methods have been widely studied to\naddress this issue, but most struggle when class proportions between the source\nand target domains differ. In this paper, we propose a weakly-supervised domain\nadaptation method that leverages class proportion information from the target\ndomain, which is often accessible in medical datasets through prior knowledge\nor statistical reports. Our method assigns pseudo-labels to the unlabeled\ntarget data based on class proportion (called proportion-constrained\npseudo-labeling), improving performance without the need for additional\nannotations. Experiments on two endoscopic datasets demonstrate that our method\noutperforms semi-supervised domain adaptation techniques, even when 5% of the\ntarget domain is labeled. Additionally, the experimental results with noisy\nproportion labels highlight the robustness of our method, further demonstrating\nits effectiveness in real-world application scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5f31\u76d1\u7763\u9886\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u5229\u7528\u76ee\u6807\u9886\u57df\u7684\u7c7b\u522b\u6bd4\u4f8b\u4fe1\u606f\u8fdb\u884c\u4f2a\u6807\u7b7e\u5206\u914d\uff0c\u63d0\u5347\u6a21\u578b\u5728\u4e0d\u540c\u6570\u636e\u5206\u5e03\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u9886\u57df\u504f\u79fb\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u91cd\u8981\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u533b\u7597\u5e94\u7528\u4e2d\uff0c\u7531\u4e8e\u6570\u636e\u6536\u96c6\u5b9e\u8df5\u3001\u8bbe\u5907\u548c\u7a0b\u5e8f\u7684\u5dee\u5f02\uff0c\u5bfc\u81f4\u4e0d\u540c\u673a\u6784\u7684\u6570\u636e\u5206\u5e03\u4e0d\u540c\u3002\u5f53\u5728\u6e90\u57df\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u5e94\u7528\u4e8e\u76ee\u6807\u57df\u65f6\uff0c\u6027\u80fd\u53ef\u80fd\u4f1a\u4e0b\u964d\u3002\u73b0\u6709\u7684\u9886\u57df\u9002\u5e94\u65b9\u6cd5\u5728\u6e90\u57df\u548c\u76ee\u6807\u57df\u7c7b\u522b\u6bd4\u4f8b\u4e0d\u540c\u65f6\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5f31\u76d1\u7763\u9886\u57df\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u76ee\u6807\u9886\u57df\u7684\u7c7b\u522b\u6bd4\u4f8b\u4fe1\u606f\u4e3a\u76ee\u6807\u57df\u7684\u672a\u6807\u8bb0\u6570\u636e\u5206\u914d\u4f2a\u6807\u7b7e\uff08\u79f0\u4e3a\u6bd4\u4f8b\u7ea6\u675f\u4f2a\u6807\u7b7e\uff09\u3002\u8be5\u65b9\u6cd5\u4e0d\u9700\u8981\u989d\u5916\u7684\u6ce8\u91ca\uff0c\u5e76\u4e14\u5728\u7c7b\u522b\u6bd4\u4f8b\u4e0d\u540c\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u6709\u6548\u5de5\u4f5c\u3002", "result": "\u5728\u4e24\u4e2a\u5185\u7aa5\u955c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u534a\u76d1\u7763\u9886\u57df\u9002\u5e94\u6280\u672f\uff0c\u5373\u4f7f\u76ee\u6807\u57df\u4e2d\u67095%\u7684\u6570\u636e\u88ab\u6807\u8bb0\u3002\u6b64\u5916\uff0c\u4f7f\u7528\u566a\u58f0\u6bd4\u4f8b\u6807\u7b7e\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u9886\u57df\u9002\u5e94\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u7c7b\u522b\u6bd4\u4f8b\u4e0d\u540c\u7684\u60c5\u51b5\u4e0b\uff0c\u5e76\u4e14\u5bf9\u566a\u58f0\u6bd4\u4f8b\u6807\u7b7e\u5177\u6709\u9c81\u68d2\u6027\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2506.22304", "pdf": "https://arxiv.org/pdf/2506.22304", "abs": "https://arxiv.org/abs/2506.22304", "authors": ["Erkan Turan", "Aristotelis Siozopoulos", "Maks Ovsjanikov"], "title": "Unfolding Generative Flows with Koopman Operators: Fast and Interpretable Sampling", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Conditional Flow Matching (CFM) offers a simulation-free framework for\ntraining continuous-time generative models, bridging diffusion and flow-based\napproaches. However, sampling from CFM still relies on numerically solving\nnon-linear ODEs which can be computationally expensive and difficult to\ninterpret. Recent alternatives address sampling speed via trajectory\nstraightening, mini-batch coupling or distillation. However, these methods\ntypically do not shed light on the underlying \\textit{structure} of the\ngenerative process. In this work, we propose to accelerate CFM and introduce an\ninterpretable representation of its dynamics by integrating Koopman operator\ntheory, which models non-linear flows as linear evolution in a learned space of\nobservables. We introduce a decoder-free Koopman-CFM architecture that learns\nan embedding where the generative dynamics become linear, enabling closed-form,\none-step sampling via matrix exponentiation. This results in significant\nspeedups over traditional CFM as demonstrated on controlled 2D datasets and\nreal-world benchmarks, MNIST, Fashion-MNIST (F-MNIST), and the Toronto Face\nDataset (TFD). Unlike previous methods, our approach leads to a well-structured\nKoopman generator, whose spectral properties, eigenvalues, and eigenfunctions\noffer principled tools for analyzing generative behavior such as temporal\nscaling, mode stability, and decomposition in Koopman latent space. By\ncombining sampling efficiency with analytical structure, Koopman-enhanced flow\nmatching offers a potential step toward fast and interpretable generative\nmodeling.", "AI": {"tldr": "Conditional Flow Matching (CFM)\u7ed3\u5408Koopman\u7b97\u5b50\u7406\u8bba\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u89e3\u7801\u5668\u67b6\u6784\uff0c\u901a\u8fc7\u77e9\u9635\u6307\u6570\u5b9e\u73b0\u4e00\u6b65\u91c7\u6837\uff0c\u663e\u8457\u52a0\u901f\u4e86\u4f20\u7edfCFM\uff0c\u5e76\u5728MNIST\u3001F-MNIST\u548cTFD\u7b49\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u6784\u826f\u597d\u7684Koopman\u751f\u6210\u5668\uff0c\u53ef\u5206\u6790\u751f\u6210\u884c\u4e3a\u7684\u8c31\u7279\u6027\u3001\u7279\u5f81\u503c\u548c\u7279\u5f81\u51fd\u6570\u3002", "motivation": "\u867d\u7136CFM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65e0\u9700\u6a21\u62df\u7684\u6846\u67b6\u6765\u8bad\u7ec3\u8fde\u7eed\u65f6\u95f4\u751f\u6210\u6a21\u578b\uff0c\u4f46\u5176\u91c7\u6837\u4f9d\u8d56\u4e8e\u6570\u503c\u6c42\u89e3\u975e\u7ebf\u6027ODE\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u89e3\u91ca\u3002\u73b0\u6709\u52a0\u901f\u65b9\u6cd5\u867d\u63d0\u5347\u4e86\u91c7\u6837\u901f\u5ea6\uff0c\u4f46\u672a\u80fd\u63ed\u793a\u751f\u6210\u8fc7\u7a0b\u7684\u5e95\u5c42\u7ed3\u6784\u3002", "method": "\u5c06Koopman\u7b97\u5b50\u7406\u8bba\u4e0eCFM\u7ed3\u5408\uff0c\u63d0\u51fa\u4e00\u79cd\u65e0\u89e3\u7801\u5668\u7684Koopman-CFM\u67b6\u6784\u3002\u8be5\u67b6\u6784\u5b66\u4e60\u4e00\u4e2a\u5d4c\u5165\u7a7a\u95f4\uff0c\u5728\u5176\u4e2d\u751f\u6210\u52a8\u529b\u5b66\u53d8\u4e3a\u7ebf\u6027\uff0c\u4ece\u800c\u53ef\u901a\u8fc7\u77e9\u9635\u6307\u6570\u5b9e\u73b0\u95ed\u5f0f\u4e00\u6b65\u91c7\u6837\u3002", "result": "\u76f8\u6bd4\u4f20\u7edfCFM\uff0c\u8be5\u65b9\u6cd5\u5728\u53d7\u63a72D\u6570\u636e\u96c6\u548c\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\uff08\u5982MNIST\u3001F-MNIST\u548cTFD\uff09\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\u3002\u540c\u65f6\uff0c\u63d0\u4f9b\u4e86\u5177\u6709\u8c31\u7279\u6027\u7684Koopman\u751f\u6210\u5668\uff0c\u53ef\u7528\u4e8e\u5206\u6790\u751f\u6210\u884c\u4e3a\u3002", "conclusion": "Koopman\u589e\u5f3a\u7684\u6d41\u5339\u914d\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u91c7\u6837\u6548\u7387\uff0c\u8fd8\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u5206\u6790\u5de5\u5177\uff0c\u4e3a\u5feb\u901f\u4e14\u53ef\u89e3\u91ca\u7684\u751f\u6210\u5efa\u6a21\u8fc8\u51fa\u4e86\u6f5c\u5728\u7684\u4e00\u6b65\u3002"}}
{"id": "2506.22365", "pdf": "https://arxiv.org/pdf/2506.22365", "abs": "https://arxiv.org/abs/2506.22365", "authors": ["Tao Li", "Haozhe Lei", "Mingsheng Yin", "Yaqi Hu"], "title": "Reinforcement Learning with Physics-Informed Symbolic Program Priors for Zero-Shot Wireless Indoor Navigation", "categories": ["cs.LG", "cs.RO"], "comment": "Spotlight paper at Reinforcement Learning Conference 2025, Workshop\n  on Inductive Biases in Reinforcement Learning", "summary": "When using reinforcement learning (RL) to tackle physical control tasks,\ninductive biases that encode physics priors can help improve sample efficiency\nduring training and enhance generalization in testing. However, the current\npractice of incorporating these helpful physics-informed inductive biases\ninevitably runs into significant manual labor and domain expertise, making them\nprohibitive for general users. This work explores a symbolic approach to\ndistill physics-informed inductive biases into RL agents, where the physics\npriors are expressed in a domain-specific language (DSL) that is human-readable\nand naturally explainable. Yet, the DSL priors do not translate directly into\nan implementable policy due to partial and noisy observations and additional\nphysical constraints in navigation tasks. To address this gap, we develop a\nphysics-informed program-guided RL (PiPRL) framework with applications to\nindoor navigation. PiPRL adopts a hierarchical and modularized neuro-symbolic\nintegration, where a meta symbolic program receives semantically meaningful\nfeatures from a neural perception module, which form the bases for symbolic\nprogramming that encodes physics priors and guides the RL process of a\nlow-level neural controller. Extensive experiments demonstrate that PiPRL\nconsistently outperforms purely symbolic or neural policies and reduces\ntraining time by over 26% with the help of the program-based inductive biases.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6PiPRL\uff0c\u901a\u8fc7\u7b26\u53f7\u5316\u65b9\u6cd5\u5c06\u7269\u7406\u4fe1\u606f\u5f52\u7eb3\u504f\u5dee\u6ce8\u5165\u5230\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u4e2d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u878d\u5165\u7269\u7406\u4fe1\u606f\u5f52\u7eb3\u504f\u5dee\u7684\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u7684\u4eba\u5de5\u52b3\u52a8\u548c\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86\u7269\u7406\u4fe1\u606f\u7a0b\u5e8f\u5f15\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\uff08PiPRL\uff09\u6846\u67b6\uff0c\u91c7\u7528\u5206\u5c42\u6a21\u5757\u5316\u7684\u795e\u7ecf-\u7b26\u53f7\u96c6\u6210\u65b9\u6cd5\uff0c\u5176\u4e2d\u5143\u7b26\u53f7\u7a0b\u5e8f\u63a5\u6536\u6765\u81ea\u795e\u7ecf\u611f\u77e5\u6a21\u5757\u7684\u8bed\u4e49\u7279\u5f81\uff0c\u8fd9\u4e9b\u7279\u5f81\u6784\u6210\u4e86\u7f16\u7801\u7269\u7406\u5148\u9a8c\u5e76\u6307\u5bfc\u4f4e\u7ea7\u795e\u7ecf\u63a7\u5236\u5668\u5f3a\u5316\u5b66\u4e60\u8fc7\u7a0b\u7684\u7b26\u53f7\u7f16\u7a0b\u57fa\u7840\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u7eaf\u7b26\u53f7\u6216\u795e\u7ecf\u7b56\u7565\u76f8\u6bd4\uff0cPiPRL\u6301\u7eed\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u501f\u52a9\u7a0b\u5e8f\u5bfc\u5411\u7684\u5f52\u7eb3\u504f\u5dee\u51cf\u5c11\u4e86\u8d85\u8fc726%\u7684\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "PiPRL\u6846\u67b6\u5c55\u793a\u4e86\u5982\u4f55\u6709\u6548\u5229\u7528\u7269\u7406\u5148\u9a8c\u77e5\u8bc6\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u5728\u7269\u7406\u63a7\u5236\u4efb\u52a1\u4e2d\u7684\u6837\u672c\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u5bf9\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u7684\u4f9d\u8d56\u3002"}}
{"id": "2506.22401", "pdf": "https://arxiv.org/pdf/2506.22401", "abs": "https://arxiv.org/abs/2506.22401", "authors": ["Tong Yang", "Bo Dai", "Lin Xiao", "Yuejie Chi"], "title": "Exploration from a Primal-Dual Lens: Value-Incentivized Actor-Critic Methods for Sample-Efficient Online RL", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Online reinforcement learning (RL) with complex function approximations such\nas transformers and deep neural networks plays a significant role in the modern\npractice of artificial intelligence. Despite its popularity and importance,\nbalancing the fundamental trade-off between exploration and exploitation\nremains a long-standing challenge; in particular, we are still in lack of\nefficient and practical schemes that are backed by theoretical performance\nguarantees. Motivated by recent developments in exploration via optimistic\nregularization, this paper provides an interpretation of the principle of\noptimism through the lens of primal-dual optimization. From this fresh\nperspective, we set forth a new value-incentivized actor-critic (VAC) method,\nwhich optimizes a single easy-to-optimize objective integrating exploration and\nexploitation -- it promotes state-action and policy estimates that are both\nconsistent with collected data transitions and result in higher value\nfunctions. Theoretically, the proposed VAC method has near-optimal regret\nguarantees under linear Markov decision processes (MDPs) in both finite-horizon\nand infinite-horizon settings, which can be extended to the general function\napproximation setting under appropriate assumptions.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u4ef7\u503c\u6fc0\u52b1\u7684\u53c2\u4e0e\u8005-\u8bc4\u8bba\u5bb6\u65b9\u6cd5\uff08VAC\uff09\uff0c\u901a\u8fc7\u4e50\u89c2\u539f\u5219\u548c\u539f\u59cb-\u5bf9\u5076\u4f18\u5316\u89c6\u89d2\uff0c\u7ed3\u5408\u63a2\u7d22\u548c\u5f00\u53d1\u3002\u8be5\u65b9\u6cd5\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u6709\u63a5\u8fd1\u6700\u4f18\u7684\u540e\u6094\u4fdd\u8bc1\uff0c\u5e76\u53ef\u6269\u5c55\u81f3\u66f4\u901a\u7528\u7684\u51fd\u6570\u903c\u8fd1\u8bbe\u7f6e\u3002", "motivation": "\u53d7\u5230\u901a\u8fc7\u4e50\u89c2\u6b63\u5219\u5316\u8fdb\u884c\u63a2\u7d22\u7684\u6700\u65b0\u53d1\u5c55\u7684\u542f\u53d1", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u4ef7\u503c\u6fc0\u52b1\u7684\u53c2\u4e0e\u8005-\u8bc4\u8bba\u5bb6\uff08VAC\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4ece\u539f\u59cb-\u5bf9\u5076\u4f18\u5316\u7684\u89d2\u5ea6\u89e3\u91ca\u4e86\u4e50\u89c2\u539f\u5219\u3002VAC\u65b9\u6cd5\u4f18\u5316\u4e86\u4e00\u4e2a\u5355\u4e00\u7684\u3001\u6613\u4e8e\u4f18\u5316\u7684\u76ee\u6807\uff0c\u5c06\u63a2\u7d22\u548c\u5f00\u53d1\u96c6\u6210\u5728\u4e00\u8d77\u2014\u2014\u5b83\u4fc3\u8fdb\u4e86\u4e0e\u6536\u96c6\u7684\u6570\u636e\u8f6c\u6362\u4e00\u81f4\u5e76\u5bfc\u81f4\u66f4\u9ad8\u4ef7\u503c\u51fd\u6570\u7684\u72b6\u6001-\u52a8\u4f5c\u548c\u7b56\u7565\u4f30\u8ba1\u3002", "result": "\u7406\u8bba\u4e0a\uff0c\u5728\u7ebf\u6027\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff08MDPs\uff09\u4e2d\uff0c\u6240\u63d0\u51fa\u7684VAC\u65b9\u6cd5\u5728\u6709\u9650\u8303\u56f4\u548c\u65e0\u9650\u8303\u56f4\u8bbe\u7f6e\u4e0b\u90fd\u5177\u6709\u63a5\u8fd1\u6700\u4f18\u7684\u540e\u6094\u4fdd\u8bc1\uff0c\u8fd9\u53ef\u4ee5\u5728\u9002\u5f53\u7684\u5047\u8bbe\u4e0b\u6269\u5c55\u5230\u4e00\u822c\u51fd\u6570\u903c\u8fd1\u8bbe\u7f6e\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5373\u4ef7\u503c\u6fc0\u52b1\u7684\u53c2\u4e0e\u8005-\u8bc4\u8bba\u5bb6\u65b9\u6cd5\uff0c\u5b83\u5728\u7406\u8bba\u4e0a\u6709\u63a5\u8fd1\u6700\u4f18\u7684\u8868\u73b0\u4fdd\u8bc1\uff0c\u5e76\u4e14\u53ef\u4ee5\u5e94\u7528\u4e8e\u66f4\u4e00\u822c\u7684\u51fd\u6570\u903c\u8fd1\u573a\u666f\u3002"}}
{"id": "2506.22423", "pdf": "https://arxiv.org/pdf/2506.22423", "abs": "https://arxiv.org/abs/2506.22423", "authors": ["Pritam Dash", "Ethan Chan", "Nathan P. Lawrence", "Karthik Pattabiraman"], "title": "ARMOR: Robust Reinforcement Learning-based Control for UAVs under Physical Attacks", "categories": ["cs.LG", "cs.CR", "cs.RO"], "comment": null, "summary": "Unmanned Aerial Vehicles (UAVs) depend on onboard sensors for perception,\nnavigation, and control. However, these sensors are susceptible to physical\nattacks, such as GPS spoofing, that can corrupt state estimates and lead to\nunsafe behavior. While reinforcement learning (RL) offers adaptive control\ncapabilities, existing safe RL methods are ineffective against such attacks. We\npresent ARMOR (Adaptive Robust Manipulation-Optimized State Representations),\nan attack-resilient, model-free RL controller that enables robust UAV operation\nunder adversarial sensor manipulation. Instead of relying on raw sensor\nobservations, ARMOR learns a robust latent representation of the UAV's physical\nstate via a two-stage training framework. In the first stage, a teacher\nencoder, trained with privileged attack information, generates attack-aware\nlatent states for RL policy training. In the second stage, a student encoder is\ntrained via supervised learning to approximate the teacher's latent states\nusing only historical sensor data, enabling real-world deployment without\nprivileged information. Our experiments show that ARMOR outperforms\nconventional methods, ensuring UAV safety. Additionally, ARMOR improves\ngeneralization to unseen attacks and reduces training cost by eliminating the\nneed for iterative adversarial training.", "AI": {"tldr": "ARMOR\u662f\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u65b9\u6cd5\uff0c\u80fd\u591f\u589e\u5f3a\u65e0\u4eba\u673a\u5728\u4f20\u611f\u5668\u53d7\u5230\u653b\u51fb\u65f6\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u3002\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff0cARMOR\u65e0\u9700\u7279\u6743\u4fe1\u606f\u5373\u53ef\u5b9e\u73b0\u5b9e\u65f6\u90e8\u7f72\uff0c\u5e76\u4e14\u51cf\u5c11\u4e86\u5bf9\u6297\u8bad\u7ec3\u7684\u9700\u6c42\uff0c\u63d0\u9ad8\u4e86\u5bf9\u672a\u77e5\u653b\u51fb\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u7269\u7406\u653b\u51fb\uff08\u5982GPS\u6b3a\u9a97\uff09\u5bf9\u65e0\u4eba\u673a\u4f20\u611f\u5668\u7684\u5f71\u54cd\uff0c\u8fd9\u4e9b\u653b\u51fb\u53ef\u80fd\u5bfc\u81f4\u72b6\u6001\u4f30\u8ba1\u88ab\u7834\u574f\u5e76\u5f15\u53d1\u4e0d\u5b89\u5168\u884c\u4e3a\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u65e0\u4eba\u673a\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u5b89\u5168\u6027\u4e0e\u7a33\u5b9a\u6027\u3002", "method": "ARMOR\u91c7\u7528\u65e0\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\u5b66\u4e60\u65e0\u4eba\u673a\u7269\u7406\u72b6\u6001\u7684\u9c81\u68d2\u6f5c\u5728\u8868\u793a\u3002\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u5177\u6709\u7279\u6743\u653b\u51fb\u4fe1\u606f\u7684\u6559\u5e08\u7f16\u7801\u5668\u751f\u6210\u5bf9\u6297\u611f\u77e5\u7684\u6f5c\u5728\u72b6\u6001\u7528\u4e8e\u7b56\u7565\u8bad\u7ec3\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u76d1\u7763\u5b66\u4e60\u8bad\u7ec3\u5b66\u751f\u7f16\u7801\u5668\u4ee5\u4ec5\u4f7f\u7528\u5386\u53f2\u4f20\u611f\u5668\u6570\u636e\u903c\u8fd1\u6559\u5e08\u7684\u6f5c\u5728\u72b6\u6001\uff0c\u4ece\u800c\u5b9e\u73b0\u5b9e\u9645\u90e8\u7f72\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cARMOR\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5728\u786e\u4fdd\u65e0\u4eba\u673a\u5b89\u5168\u6027\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u5bf9\u672a\u89c1\u8fc7\u653b\u51fb\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u6d88\u9664\u8fed\u4ee3\u5bf9\u6297\u8bad\u7ec3\u9700\u6c42\u964d\u4f4e\u4e86\u8bad\u7ec3\u6210\u672c\u3002", "conclusion": "ARMOR\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u65e0\u4eba\u673a\u80fd\u591f\u5728\u5bf9\u6297\u6027\u4f20\u611f\u5668\u64cd\u63a7\u4e0b\u4fdd\u6301\u7a33\u5065\u8fd0\u884c\uff0c\u540c\u65f6\u51cf\u5c11\u8bad\u7ec3\u590d\u6742\u5ea6\u548c\u63d0\u9ad8\u6cdb\u5316\u6027\u80fd\u3002"}}
