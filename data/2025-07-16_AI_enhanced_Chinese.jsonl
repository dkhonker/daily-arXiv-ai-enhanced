{"id": "2507.10562", "pdf": "https://arxiv.org/pdf/2507.10562", "abs": "https://arxiv.org/abs/2507.10562", "authors": ["Hari Masoor"], "title": "SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents", "categories": ["cs.AI", "cs.CR", "cs.DB", "cs.LG"], "comment": "7 pages, 4 figures, 3 implementation examples. Original work\n  submitted as a preprint", "summary": "Current AI agent architectures suffer from ephemeral memory limitations,\npreventing effective collaboration and knowledge sharing across sessions and\nagent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a\nnovel framework that enables persistent, secure, and semantically searchable\nmemory sharing among AI agents. Our protocol addresses three critical\nchallenges: (1) persistent context preservation across agent sessions, (2)\nsecure multi-agent collaboration with fine-grained access control, and (3)\nefficient semantic discovery of relevant historical context. SAMEP implements a\ndistributed memory repository with vector-based semantic search, cryptographic\naccess controls (AES-256-GCM), and standardized APIs compatible with existing\nagent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness\nacross diverse domains including multi-agent software development, healthcare\nAI with HIPAA compliance, and multi-modal processing pipelines. Experimental\nresults show 73% reduction in redundant computations, 89% improvement in\ncontext relevance scores, and complete compliance with regulatory requirements\nincluding audit trail generation. SAMEP enables a new paradigm of persistent,\ncollaborative AI agent ecosystems while maintaining security and privacy\nguarantees.", "AI": {"tldr": "SAMEP\u662f\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u6301\u4e45\u7684\u3001\u5b89\u5168\u7684\u548c\u8bed\u4e49\u53ef\u641c\u7d22\u7684\u8bb0\u5fc6\u5171\u4eab\u6765\u89e3\u51b3\u5f53\u524dAI\u4ee3\u7406\u67b6\u6784\u4e2d\u7684\u77ed\u6682\u8bb0\u5fc6\u9650\u5236\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5176\u6709\u6548\u51cf\u5c11\u4e86\u5197\u4f59\u8ba1\u7b97\uff0c\u5e76\u63d0\u9ad8\u4e86\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u5206\u6570\uff0c\u540c\u65f6\u5b8c\u5168\u7b26\u5408\u6cd5\u89c4\u8981\u6c42\u3002", "motivation": "\u5f53\u524d\u7684AI\u4ee3\u7406\u67b6\u6784\u53d7\u5230\u77ed\u6682\u8bb0\u5fc6\u7684\u9650\u5236\uff0c\u65e0\u6cd5\u5728\u4f1a\u8bdd\u548c\u4ee3\u7406\u8fb9\u754c\u4e4b\u95f4\u6709\u6548\u5730\u534f\u4f5c\u548c\u5171\u4eab\u77e5\u8bc6\u3002", "method": "SAMEP\u5b9e\u73b0\u4e86\u5206\u5e03\u5f0f\u5185\u5b58\u5e93\uff0c\u5177\u6709\u57fa\u4e8e\u77e2\u91cf\u7684\u8bed\u4e49\u641c\u7d22\u3001\u52a0\u5bc6\u8bbf\u95ee\u63a7\u5236\uff08AES-256-GCM\uff09\u548c\u4e0e\u73b0\u6709\u4ee3\u7406\u901a\u4fe1\u534f\u8bae\u517c\u5bb9\u7684\u6807\u51c6API\uff08MCP\uff0cA2A\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSAMEP\u4f7f\u5197\u4f59\u8ba1\u7b97\u51cf\u5c11\u4e8673%\uff0c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u5f97\u5206\u63d0\u9ad8\u4e8689%\uff0c\u5e76\u5b8c\u5168\u7b26\u5408\u6cd5\u89c4\u8981\u6c42\uff0c\u5305\u62ec\u5ba1\u8ba1\u8ddf\u8e2a\u751f\u6210\u3002", "conclusion": "SAMEP\u5b9e\u73b0\u4e86\u4e00\u79cd\u65b0\u7684\u6301\u4e45\u6027\u3001\u534f\u4f5c\u6027\u7684AI\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\uff0c\u5728\u4fdd\u6301\u5b89\u5168\u6027\u548c\u9690\u79c1\u4fdd\u8bc1\u7684\u540c\u65f6\uff0c\u89e3\u51b3\u4e86\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff1a\u8de8\u4ee3\u7406\u4f1a\u8bdd\u7684\u6301\u4e45\u4e0a\u4e0b\u6587\u4fdd\u7559\uff0c\u5177\u6709\u7ec6\u7c92\u5ea6\u8bbf\u95ee\u63a7\u5236\u7684\u5b89\u5168\u591a\u4ee3\u7406\u534f\u4f5c\u4ee5\u53ca\u76f8\u5173\u5386\u53f2\u4e0a\u4e0b\u6587\u7684\u6709\u6548\u8bed\u4e49\u53d1\u73b0\u3002"}}
{"id": "2507.10566", "pdf": "https://arxiv.org/pdf/2507.10566", "abs": "https://arxiv.org/abs/2507.10566", "authors": ["Hung Ming Liu"], "title": "AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems", "categories": ["cs.AI", "cs.GT", "cs.LG", "cs.MA", "cs.NE", "68T07, 68T40, 91A20", "I.2.6; I.2.11; I.2.4"], "comment": "30 pages, 4 figures", "summary": "In Decentralized Multi-Agent Reinforcement Learning (MARL), the development\nof Emergent Communication has long been constrained by the ``Joint Exploration\nDilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' .\nTraditional methods address this by introducing inductive biases to facilitate\ncommunication emergence . This study fundamentally questions whether such\nartificial inductive biases are, in fact, over-engineering. Through experiments\nwith the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized\nVariational Autoencoder (VQ-VAE), we demonstrate that when agents possess an\nendogenous symbol system, their neural representations naturally exhibit\nspontaneous semantic compression and Nash equilibrium-driven semantic\nconvergence, achieving effective symbolic communication without external\ninductive biases. This aligns with recent neuroscience findings suggesting that\nthe human brain does not directly use human language for internal thought , and\nresonates with research on ``soft thinking'' capabilities in Large Language\nModels (LLMs) . Compared to traditional explicit communication methods, AIM\ndemonstrates stronger generality and efficiency. The interpretable analysis\ntoolkit developed in this study confirms that symbol usage exhibits a\nsignificant power-law distribution, leading to three major theoretical\ninsights: the ``Neural Communication Hypothesis'', the ``Tool-First\nPrinciple'', and the ``Semantic Interpretability Paradigm''. Future research\nwill explore the integration of Hierarchical Quantized Variational Autoencoders\n(HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the\npotential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This\ndiscovery offers new avenues for bridging symbolism and connectionism.", "AI": {"tldr": "\u672c\u7814\u7a76\u8d28\u7591\u5728\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u5f15\u5165\u4eba\u5de5\u5f52\u7eb3\u504f\u7f6e\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u901a\u8fc7AI\u6bcd\u8bed\u6846\u67b6\u8bc1\u660e\u4e86\u65e0\u9700\u5916\u90e8\u5f52\u7eb3\u504f\u7f6e\u5373\u53ef\u5b9e\u73b0\u6709\u6548\u7684\u7b26\u53f7\u4ea4\u6d41\uff0c\u8fd9\u4e3a\u8fde\u63a5\u4e3b\u4e49\u548c\u7b26\u53f7\u4e3b\u4e49\u4e4b\u95f4\u7684\u6865\u6881\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002", "motivation": "\u8be5\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u201c\u8054\u5408\u63a2\u7d22\u56f0\u5883\u201d\uff0c\u5e76\u8d28\u7591\u662f\u5426\u9700\u8981\u5f15\u5165\u4eba\u5de5\u5f52\u7eb3\u504f\u7f6e\u6765\u4fc3\u8fdb\u901a\u4fe1\u7684\u51fa\u73b0\u3002", "method": "\u7814\u7a76\u91c7\u7528\u4e86\u57fa\u4e8e\u77e2\u91cf\u91cf\u5316\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VQ-VAE\uff09\u7684AI\u6bcd\u8bed\u6846\u67b6\uff0c\u4f7f\u667a\u80fd\u4f53\u62e5\u6709\u5185\u6e90\u7b26\u53f7\u7cfb\u7edf\uff0c\u4ee5\u89c2\u5bdf\u5176\u795e\u7ecf\u8868\u793a\u662f\u5426\u4f1a\u81ea\u53d1\u5730\u8fdb\u884c\u8bed\u4e49\u538b\u7f29\u548c\u8bed\u4e49\u6536\u655b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u667a\u80fd\u4f53\u80fd\u591f\u5b9e\u73b0\u6709\u6548\u7684\u7b26\u53f7\u4ea4\u6d41\uff0c\u5e76\u5c55\u793a\u4e86\u66f4\u5f3a\u7684\u4e00\u822c\u6027\u548c\u6548\u7387\u3002\u6b64\u5916\uff0c\u8fd8\u53d1\u73b0\u4e86\u7b26\u53f7\u4f7f\u7528\u5448\u73b0\u51fa\u663e\u8457\u7684\u5e42\u5f8b\u5206\u5e03\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7AI\u6bcd\u8bed\u6846\u67b6\uff0c\u667a\u80fd\u4f53\u53ef\u4ee5\u5728\u6ca1\u6709\u5916\u90e8\u5f52\u7eb3\u504f\u7f6e\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6709\u6548\u7684\u7b26\u53f7\u4ea4\u6d41\uff0c\u8fd9\u4e3a\u672a\u6765\u7684\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u7684\u65b9\u5411\uff0c\u7279\u522b\u662f\u5728\u8fde\u63a5\u4e3b\u4e49\u548c\u7b26\u53f7\u4e3b\u4e49\u7684\u7ed3\u5408\u65b9\u9762\u3002"}}
{"id": "2507.10571", "pdf": "https://arxiv.org/pdf/2507.10571", "abs": "https://arxiv.org/abs/2507.10571", "authors": ["Konstantinos I. Roumeliotis", "Ranjan Sapkota", "Manoj Karkee", "Nikolaos D. Tselikas"], "title": "Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Modern Artificial Intelligence (AI) increasingly relies on multi-agent\narchitectures that blend visual and language understanding. Yet, a pressing\nchallenge remains: How can we trust these agents especially in zero-shot\nsettings with no fine-tuning? We introduce a novel modular Agentic AI visual\nclassification framework that integrates generalist multimodal agents with a\nnon-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)\nmodule. Applied to apple leaf disease diagnosis, we benchmark three\nconfigurations: (I) zero-shot with confidence-based orchestration, (II)\nfine-tuned agents with improved performance, and (III) trust-calibrated\norchestration enhanced by CLIP-based image retrieval and re-evaluation loops.\nUsing confidence calibration metrics (ECE, OCR, CCC), the orchestrator\nmodulates trust across agents. Our results demonstrate a 77.94\\% accuracy\nimprovement in the zero-shot setting using trust-aware orchestration and RAG,\nachieving 85.63\\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL\ndisplayed overconfidence. Furthermore, image-RAG grounded predictions with\nvisually similar cases, enabling correction of agent overconfidence via\niterative re-evaluation. The proposed system separates perception (vision\nagents) from meta-reasoning (orchestrator), enabling scalable and interpretable\nmulti-agent AI. This blueprint is extensible to diagnostics, biology, and other\ntrust-critical domains. All models, prompts, results, and system components\nincluding the complete software source code are openly released to support\nreproducibility, transparency, and community benchmarking at Github:\nhttps://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6a21\u5757\u5316\u4ee3\u7406AI\u89c6\u89c9\u5206\u7c7b\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u591a\u6a21\u5f0f\u4ee3\u7406\u3001\u975e\u89c6\u89c9\u63a8\u7406\u534f\u8c03\u5668\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6a21\u5757\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u7684\u82f9\u679c\u53f6\u75c5\u8bca\u65ad\u51c6\u786e\u7387\u3002", "motivation": "\u5f53\u524d\u7684\u591a\u667a\u80fd\u4f53\u67b6\u6784\u867d\u7136\u80fd\u591f\u878d\u5408\u89c6\u89c9\u548c\u8bed\u8a00\u7406\u89e3\uff0c\u4f46\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u5982\u4f55\u4fe1\u4efb\u8fd9\u4e9b\u667a\u80fd\u4f53\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u3002\u4e3a\u4e86\u63d0\u9ad8\u5728\u96f6\u6837\u672c\u60c5\u51b5\u4e0b\u7684\u53ef\u4fe1\u5ea6\u548c\u51c6\u786e\u6027\uff0c\u63d0\u51fa\u4e86\u8be5\u7814\u7a76\u3002", "method": "\u8be5\u7814\u7a76\u5f15\u5165\u4e86\u5305\u542b\u4e00\u822c\u591a\u6a21\u6001\u667a\u80fd\u4f53\u3001\u975e\u89c6\u89c9\u63a8\u7406\u534f\u8c03\u5668\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6a21\u5757\u7684\u6846\u67b6\uff0c\u5e76\u5e94\u7528\u4e8e\u82f9\u679c\u53f6\u75c5\u8bca\u65ad\u4e2d\uff0c\u901a\u8fc7\u4e09\u79cd\u914d\u7f6e\u8fdb\u884c\u6d4b\u8bd5\uff0c\u4f7f\u7528\u7f6e\u4fe1\u5ea6\u6821\u51c6\u6307\u6807\u6765\u8c03\u6574\u4e0d\u540c\u667a\u80fd\u4f53\u95f4\u7684\u4fe1\u4efb\u5ea6\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\uff0c\u4f7f\u7528\u57fa\u4e8e\u4fe1\u4efb\u7684\u534f\u8c03\u548cRAG\u65b9\u6cd5\u53ef\u5c06\u51c6\u786e\u7387\u63d0\u9ad877.94%\uff0c\u603b\u4f53\u8fbe\u523085.63%\u3002GPT-4o\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6821\u51c6\u6548\u679c\uff0c\u800cQwen-2.5-VL\u5219\u663e\u5f97\u8fc7\u4e8e\u81ea\u4fe1\u3002\u6b64\u5916\uff0c\u56fe\u50cf-RAG\u4f7f\u9884\u6d4b\u7ed3\u679c\u80fd\u57fa\u4e8e\u89c6\u89c9\u76f8\u4f3c\u6848\u4f8b\u8fdb\u884c\u8fed\u4ee3\u91cd\u65b0\u8bc4\u4f30\u3002", "conclusion": "\u63d0\u51fa\u7684\u7cfb\u7edf\u5206\u79bb\u4e86\u611f\u77e5\u4e0e\u5143\u63a8\u7406\uff0c\u4f7f\u5f97\u591a\u667a\u80fd\u4f53AI\u66f4\u52a0\u53ef\u6269\u5c55\u548c\u53ef\u89e3\u91ca\uff0c\u9002\u7528\u4e8e\u8bca\u65ad\u3001\u751f\u7269\u5b66\u53ca\u5176\u4ed6\u5bf9\u4fe1\u4efb\u5ea6\u8981\u6c42\u9ad8\u7684\u9886\u57df\u3002\u6240\u6709\u6a21\u578b\u3001\u63d0\u793a\u3001\u7ed3\u679c\u53ca\u7cfb\u7edf\u7ec4\u4ef6\u5df2\u516c\u5f00\u53d1\u5e03\u4ee5\u652f\u6301\u53ef\u91cd\u590d\u6027\u3001\u900f\u660e\u6027\u548c\u793e\u533a\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2507.10624", "pdf": "https://arxiv.org/pdf/2507.10624", "abs": "https://arxiv.org/abs/2507.10624", "authors": ["Zheng Zhang"], "title": "Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": "Substantial change to previous version (experiments, theorem,\n  analysis and related work); currently under review at TMLR", "summary": "Large Language Models (LLMs) display striking surface fluency yet\nsystematically fail at tasks requiring symbolic reasoning, arithmetic accuracy,\nand logical consistency. This paper offers a structural diagnosis of such\nfailures, revealing a persistent gap between \\textit{comprehension} and\n\\textit{competence}. Through controlled experiments and architectural analysis,\nwe demonstrate that LLMs often articulate correct principles without reliably\napplying them--a failure rooted not in knowledge access, but in computational\nexecution. We term this phenomenon the computational \\textit{split-brain\nsyndrome}, where instruction and action pathways are geometrically and\nfunctionally dissociated. This core limitation recurs across domains, from\nmathematical operations to relational inferences, and explains why model\nbehavior remains brittle even under idealized prompting. We argue that LLMs\nfunction as powerful pattern completion engines, but lack the architectural\nscaffolding for principled, compositional reasoning. Our findings delineate the\nboundary of current LLM capabilities and motivate future models with\nmetacognitive control, principle lifting, and structurally grounded execution.\nThis diagnosis also clarifies why mechanistic interpretability findings may\nreflect training-specific pattern coordination rather than universal\ncomputational principles, and why the geometric separation between instruction\nand execution pathways suggests limitations in neural introspection and\nmechanistic analysis.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9700\u8981\u7b26\u53f7\u63a8\u7406\u3001\u7b97\u672f\u51c6\u786e\u6027\u548c\u903b\u8f91\u4e00\u81f4\u6027\u7b49\u4efb\u52a1\u4e0a\u7cfb\u7edf\u6027\u5931\u8d25\uff0c\u8fd9\u79cd\u5931\u8d25\u6e90\u4e8e\u8ba1\u7b97\u6267\u884c\u800c\u975e\u77e5\u8bc6\u8bbf\u95ee\uff0c\u88ab\u79f0\u4e3a\u201c\u8ba1\u7b97\u5206\u88c2\u8111\u7efc\u5408\u75c7\u201d\u3002", "motivation": "\u89e3\u91ca\u4e3a\u4ec0\u4e48\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e00\u4e9b\u7279\u5b9a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u63ed\u793a\u5176\u6839\u672c\u539f\u56e0\u3002", "method": "\u901a\u8fc7\u53d7\u63a7\u5b9e\u9a8c\u548c\u67b6\u6784\u5206\u6790\u6765\u8bca\u65ad\u8fd9\u4e9b\u5931\u8d25\u7684\u539f\u56e0\uff0c\u5e76\u5c06LLMs\u7684\u884c\u4e3a\u4e0e\u6b63\u786e\u539f\u5219\u7684\u5e94\u7528\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u53d1\u73b0LLMs\u7ecf\u5e38\u80fd\u8868\u8fbe\u6b63\u786e\u7684\u539f\u5219\u4f46\u65e0\u6cd5\u53ef\u9760\u5730\u5e94\u7528\u5b83\u4eec\uff0c\u8fd9\u4e00\u73b0\u8c61\u88ab\u63cf\u8ff0\u4e3a\u8ba1\u7b97\u7684\u201c\u5206\u88c2\u8111\u7efc\u5408\u75c7\u201d\uff0c\u5e76\u6307\u51fa\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u884c\u4e3a\u7684\u7075\u6d3b\u6027\u3002", "conclusion": "\u5f53\u524d\u7684LLM\u80fd\u529b\u5b58\u5728\u754c\u9650\uff0c\u672a\u6765\u5e94\u5f00\u53d1\u5177\u6709\u5143\u8ba4\u77e5\u63a7\u5236\u3001\u539f\u5219\u63d0\u5347\u548c\u7ed3\u6784\u5316\u6267\u884c\u7684\u65b0\u6a21\u578b\u3002"}}
{"id": "2507.10564", "pdf": "https://arxiv.org/pdf/2507.10564", "abs": "https://arxiv.org/abs/2507.10564", "authors": ["Sameera Bharadwaja H.", "Siddhrath Jandial", "Shashank S. Agashe", "Rajesh Kumar Reddy Moore", "Youngkwan Kim"], "title": "Tool-to-Tool Matching Analysis Based Difference Score Computation Methods for Semiconductor Manufacturing", "categories": ["cs.LG", "cs.AI", "eess.SP", "stat.ML"], "comment": null, "summary": "We consider the problem of tool-to-tool matching (TTTM), also called, chamber\nmatching in the context of a semiconductor manufacturing equipment. Traditional\nTTTM approaches utilize static configuration data or depend on a golden\nreference which are difficult to obtain in a commercial manufacturing line.\nFurther, existing methods do not extend very well to a heterogeneous setting,\nwhere equipment are of different make-and-model, sourced from different\nequipment vendors. We propose novel TTTM analysis pipelines to overcome these\nissues. We hypothesize that a mismatched equipment would have higher variance\nand/or higher number of modes in the data. Our best univariate method achieves\na correlation coefficient >0.95 and >0.5 with the variance and number of modes,\nrespectively showing that the proposed methods are effective. Also, the best\nmultivariate method achieves a correlation coefficient >0.75 with the\ntop-performing univariate methods, showing its effectiveness. Finally, we\nanalyze the sensitivity of the multivariate algorithms to the algorithm\nhyper-parameters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u7684\u5de5\u5177\u5bf9\u5de5\u5177\u5339\u914d\uff08TTTM\uff09\u5206\u6790\u6d41\u7a0b\uff0c\u65e8\u5728\u89e3\u51b3\u534a\u5bfc\u4f53\u5236\u9020\u8bbe\u5907\u4e2d\u4f20\u7edf\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002\u901a\u8fc7\u5047\u8bbe\u4e0d\u5339\u914d\u8bbe\u5907\u5728\u6570\u636e\u4e0a\u4f1a\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u65b9\u5dee\u548c/\u6216\u66f4\u591a\u6a21\u5f0f\uff0c\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u7684\u65b9\u6cd5\u5728\u5355\u53d8\u91cf\u548c\u591a\u53d8\u91cf\u60c5\u51b5\u4e0b\u5747\u663e\u793a\u4e86\u6709\u6548\u6027\uff0c\u5e76\u5bf9\u591a\u53d8\u91cf\u7b97\u6cd5\u7684\u8d85\u53c2\u6570\u654f\u611f\u6027\u8fdb\u884c\u4e86\u5206\u6790\u3002", "motivation": "\u4f20\u7edf\u7684TTTM\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u9759\u6001\u914d\u7f6e\u6570\u636e\u6216\u9ec4\u91d1\u53c2\u8003\uff0c\u8fd9\u4e9b\u5728\u5546\u4e1a\u751f\u4ea7\u7ebf\u4e2d\u96be\u4ee5\u83b7\u5f97\u3002\u6b64\u5916\uff0c\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u5f88\u597d\u5730\u6269\u5c55\u5230\u5f02\u6784\u73af\u5883\uff0c\u5373\u6765\u81ea\u4e0d\u540c\u4f9b\u5e94\u5546\u3001\u4e0d\u540c\u578b\u53f7\u7684\u8bbe\u5907\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u65b0\u7684TTTM\u5206\u6790\u6d41\u7a0b\uff0c\u5047\u8bbe\u4e0d\u5339\u914d\u7684\u8bbe\u5907\u4f1a\u5728\u6570\u636e\u4e2d\u663e\u793a\u51fa\u66f4\u9ad8\u7684\u65b9\u5dee\u548c/\u6216\u66f4\u591a\u7684\u6a21\u5f0f\u3002\u57fa\u4e8e\u8fd9\u4e00\u5047\u8bbe\uff0c\u4ed6\u4eec\u5f00\u53d1\u4e86\u5355\u53d8\u91cf\u548c\u591a\u53d8\u91cf\u65b9\u6cd5\u6765\u8bc4\u4f30\u8bbe\u5907\u95f4\u7684\u5339\u914d\u5ea6\u3002", "result": "\u6700\u4f73\u7684\u5355\u53d8\u91cf\u65b9\u6cd5\u4e0e\u65b9\u5dee\u548c\u6a21\u5f0f\u6570\u91cf\u5206\u522b\u8fbe\u5230\u4e86>0.95\u548c>0.5\u7684\u76f8\u5173\u7cfb\u6570\uff0c\u800c\u6700\u4f73\u7684\u591a\u53d8\u91cf\u65b9\u6cd5\u4e0e\u8868\u73b0\u6700\u597d\u7684\u5355\u53d8\u91cf\u65b9\u6cd5\u4e4b\u95f4\u7684\u76f8\u5173\u7cfb\u6570\u8d85\u8fc7\u4e860.75\u3002\u8fd9\u8868\u660e\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u662f\u6709\u6548\u7684\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684TTTM\u5206\u6790\u6d41\u7a0b\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u95ee\u9898\uff0c\u5728\u5355\u53d8\u91cf\u548c\u591a\u53d8\u91cf\u60c5\u51b5\u4e0b\u90fd\u5c55\u793a\u4e86\u826f\u597d\u7684\u6548\u679c\u3002\u6b64\u5916\uff0c\u8fd8\u7814\u7a76\u4e86\u591a\u53d8\u91cf\u7b97\u6cd5\u5bf9\u8d85\u53c2\u6570\u7684\u654f\u611f\u6027\u3002"}}
{"id": "2507.10578", "pdf": "https://arxiv.org/pdf/2507.10578", "abs": "https://arxiv.org/abs/2507.10578", "authors": ["Jeremy Styborski", "Mingzhi Lyu", "Jiayou Lu", "Nupur Kapur", "Adams Kong"], "title": "When and Where do Data Poisons Attack Textual Inversion?", "categories": ["cs.CR", "cs.AI"], "comment": "Accepted to ICCV", "summary": "Poisoning attacks pose significant challenges to the robustness of diffusion\nmodels (DMs). In this paper, we systematically analyze when and where poisoning\nattacks textual inversion (TI), a widely used personalization technique for\nDMs. We first introduce Semantic Sensitivity Maps, a novel method for\nvisualizing the influence of poisoning on text embeddings. Second, we identify\nand experimentally verify that DMs exhibit non-uniform learning behavior across\ntimesteps, focusing on lower-noise samples. Poisoning attacks inherit this bias\nand inject adversarial signals predominantly at lower timesteps. Lastly, we\nobserve that adversarial signals distract learning away from relevant concept\nregions within training data, corrupting the TI process. Based on these\ninsights, we propose Safe-Zone Training (SZT), a novel defense mechanism\ncomprised of 3 key components: (1) JPEG compression to weaken high-frequency\npoison signals, (2) restriction to high timesteps during TI training to avoid\nadversarial signals at lower timesteps, and (3) loss masking to constrain\nlearning to relevant regions. Extensive experiments across multiple poisoning\nmethods demonstrate that SZT greatly enhances the robustness of TI against all\npoisoning attacks, improving generative quality beyond prior published\ndefenses. Code: www.github.com/JStyborski/Diff_Lab Data:\nwww.github.com/JStyborski/NC10", "AI": {"tldr": "\u8bba\u6587\u5206\u6790\u4e86\u6587\u672c\u53cd\u8f6c\u4e2d\u7684\u4e2d\u6bd2\u653b\u51fb\uff0c\u5e76\u63d0\u51fa\u4e86Safe-Zone Training\uff08SZT\uff09\u7684\u9632\u5fa1\u673a\u5236\uff0c\u8be5\u673a\u5236\u901a\u8fc7JPEG\u538b\u7f29\u3001\u9650\u5236\u9ad8\u65f6\u95f4\u6b65\u957f\u548c\u635f\u5931\u63a9\u7801\u6765\u589e\u5f3a\u5bf9\u6240\u6709\u4e2d\u6bd2\u653b\u51fb\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u7531\u4e8e\u4e2d\u6bd2\u653b\u51fb\u5bf9\u6269\u6563\u6a21\u578b\uff08DMs\uff09\u7684\u7a33\u5065\u6027\u6784\u6210\u91cd\u5927\u6311\u6218\uff0c\u7279\u522b\u662f\u9488\u5bf9\u6587\u672c\u53cd\u8f6c\uff08TI\uff09\u8fd9\u4e00\u5e7f\u6cdb\u5e94\u7528\u7684\u4e2a\u6027\u5316\u6280\u672f\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u5730\u5206\u6790\u8fd9\u4e9b\u653b\u51fb\u7684\u53d1\u751f\u65f6\u95f4\u548c\u4f4d\u7f6e\uff0c\u4ee5\u4fbf\u63d0\u51fa\u6709\u6548\u7684\u9632\u5fa1\u63aa\u65bd\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u8bed\u4e49\u654f\u611f\u6027\u56fe\u8c31\u4ee5\u53ef\u89c6\u5316\u4e2d\u6bd2\u5bf9\u6587\u672c\u5d4c\u5165\u7684\u5f71\u54cd\uff1b\u8bc6\u522b\u5e76\u5b9e\u9a8c\u9a8c\u8bc1\u4e86DMs\u5728\u4e0d\u540c\u65f6\u95f4\u6b65\u4e0a\u7684\u975e\u5747\u5300\u5b66\u4e60\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u4f4e\u566a\u58f0\u6837\u672c\u4e0a\uff1b\u89c2\u5bdf\u5230\u5bf9\u6297\u4fe1\u53f7\u4f1a\u5e72\u6270\u76f8\u5173\u6982\u5ff5\u533a\u57df\u7684\u5b66\u4e60\uff0c\u4ece\u800c\u7834\u574fTI\u8fc7\u7a0b\u3002\u57fa\u4e8e\u8fd9\u4e9b\u89c1\u89e3\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u7531JPEG\u538b\u7f29\u3001\u9ad8\u65f6\u95f4\u6b65\u957f\u9650\u5236\u548c\u635f\u5931\u63a9\u7801\u7ec4\u6210\u7684Safe-Zone Training\uff08SZT\uff09\u9632\u5fa1\u673a\u5236\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSZT\u5927\u5927\u589e\u5f3a\u4e86TI\u5bf9\u6240\u6709\u4e2d\u6bd2\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u6539\u5584\u4e86\u751f\u6210\u8d28\u91cf\uff0c\u8d85\u8d8a\u4e86\u4e4b\u524d\u53d1\u8868\u7684\u9632\u5fa1\u65b9\u6cd5\u3002", "conclusion": "Safe-Zone Training\uff08SZT\uff09\u662f\u4e00\u79cd\u65b0\u9896\u4e14\u6709\u6548\u7684\u9632\u5fa1\u673a\u5236\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u6269\u6563\u6a21\u578b\u4e2d\u6587\u672c\u53cd\u8f6c\u6280\u672f\u7684\u6297\u4e2d\u6bd2\u653b\u51fb\u80fd\u529b\u3002"}}
{"id": "2507.10630", "pdf": "https://arxiv.org/pdf/2507.10630", "abs": "https://arxiv.org/abs/2507.10630", "authors": ["Ye Yang", "Xue Xiao", "Ping Yin", "Taotao Xie"], "title": "Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs", "categories": ["cs.AI"], "comment": null, "summary": "API calls by large language models (LLMs) offer a cutting-edge approach for\ndata analysis. However, their ability to effectively utilize tools via API\ncalls remains underexplored in knowledge-intensive domains like meteorology.\nThis paper introduces KG2data, a system that integrates knowledge graphs, LLMs,\nReAct agents, and tool-use technologies to enable intelligent data acquisition\nand query handling in the meteorological field. Using a virtual API, we\nevaluate API call accuracy across three metrics: name recognition failure,\nhallucination failure, and call correctness. KG2data achieves superior\nperformance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and\nchat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based\nsystems by addressing their limited access to domain-specific knowledge, which\nhampers performance on complex or terminology-rich queries. By using a\nknowledge graph as persistent memory, our system enhances content retrieval,\ncomplex query handling, domain-specific reasoning, semantic relationship\nresolution, and heterogeneous data integration. It also mitigates the high cost\nof fine-tuning LLMs, making the system more adaptable to evolving domain\nknowledge and API structures. In summary, KG2data provides a novel solution for\nintelligent, knowledge-based question answering and data analysis in domains\nwith high knowledge demands.", "AI": {"tldr": "KG2data\u7ed3\u5408\u4e86\u77e5\u8bc6\u56fe\u8c31\u3001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5de5\u5177\u4f7f\u7528\u6280\u672f\uff0c\u9488\u5bf9\u6c14\u8c61\u9886\u57df\u5f00\u53d1\u4e86\u4e00\u79cd\u667a\u80fd\u6570\u636e\u83b7\u53d6\u548c\u67e5\u8be2\u5904\u7406\u7cfb\u7edf\u3002\u76f8\u6bd4\u5176\u4ed6\u7c7b\u4f3c\u7cfb\u7edf\uff0c\u5b83\u5728API\u8c03\u7528\u51c6\u786e\u6027\u4e0a\u8868\u73b0\u66f4\u4f73\uff0c\u5e76\u4e14\u901a\u8fc7\u4f7f\u7528\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u6301\u4e45\u6027\u8bb0\u5fc6\uff0c\u63d0\u9ad8\u4e86\u590d\u6742\u67e5\u8be2\u5904\u7406\u80fd\u529b\uff0c\u964d\u4f4e\u4e86\u8c03\u6574LLM\u7684\u6210\u672c\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u901a\u8fc7API\u8c03\u7528\u6709\u6548\u5229\u7528\u5de5\u5177\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u7279\u522b\u662f\u5728\u6c14\u8c61\u5b66\u7b49\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u3002\u4e3a\u4e86\u63d0\u9ad8LLMs\u5728\u8fd9\u4e9b\u9886\u57df\u7684\u6027\u80fd\uff0c\u9700\u8981\u89e3\u51b3\u5b83\u4eec\u5bf9\u7279\u5b9a\u9886\u57df\u77e5\u8bc6\u7684\u6709\u9650\u8bbf\u95ee\u95ee\u9898\u3002", "method": "KG2data\u6574\u5408\u4e86\u77e5\u8bc6\u56fe\u8c31\u3001LLMs\u3001ReAct\u4ee3\u7406\u548c\u5de5\u5177\u4f7f\u7528\u6280\u672f\uff0c\u4ee5\u5b9e\u73b0\u667a\u80fd\u6570\u636e\u83b7\u53d6\u548c\u67e5\u8be2\u5904\u7406\u3002\u8be5\u7cfb\u7edf\u4f7f\u7528\u865a\u62dfAPI\u6765\u8bc4\u4f30\u4e09\u79cd\u6307\u6807\u4e0a\u7684API\u8c03\u7528\u51c6\u786e\u6027\uff1a\u540d\u79f0\u8bc6\u522b\u5931\u8d25\u3001\u5e7b\u89c9\u5931\u8d25\u548c\u8c03\u7528\u6b63\u786e\u6027\u3002\u540c\u65f6\uff0c\u5b83\u4f7f\u7528\u77e5\u8bc6\u56fe\u8c31\u4f5c\u4e3a\u6301\u4e45\u6027\u5185\u5b58\uff0c\u589e\u5f3a\u4e86\u5185\u5bb9\u68c0\u7d22\u3001\u590d\u6742\u67e5\u8be2\u5904\u7406\u3001\u7279\u5b9a\u9886\u57df\u63a8\u7406\u3001\u8bed\u4e49\u5173\u7cfb\u89e3\u6790\u548c\u5f02\u6784\u6570\u636e\u96c6\u6210\u3002", "result": "\u4e0eRAG2data\u548cchat2data\u76f8\u6bd4\uff0cKG2data\u5728API\u8c03\u7528\u51c6\u786e\u6027\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5206\u522b\u8fbe\u5230\u4e861.43%\uff0c0%\u548c88.57%\uff0c\u800c\u5176\u4ed6\u4e24\u4e2a\u7cfb\u7edf\u7684\u76f8\u5e94\u6307\u6807\u5206\u522b\u4e3a(16%\uff0c10%\uff0c72.14%)\u548c(7.14%\uff0c8.57%\uff0c71.43%)\u3002\u6b64\u5916\uff0cKG2data\u8fd8\u964d\u4f4e\u4e86\u5fae\u8c03LLMs\u7684\u6210\u672c\uff0c\u4f7f\u5f97\u7cfb\u7edf\u80fd\u591f\u66f4\u597d\u5730\u9002\u5e94\u4e0d\u65ad\u53d8\u5316\u7684\u9886\u57df\u77e5\u8bc6\u548cAPI\u7ed3\u6784\u3002", "conclusion": "KG2data\u4e3a\u9ad8\u77e5\u8bc6\u9700\u6c42\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u77e5\u8bc6\u7684\u667a\u80fd\u95ee\u7b54\u548c\u6570\u636e\u5206\u6790\u3002"}}
{"id": "2507.10574", "pdf": "https://arxiv.org/pdf/2507.10574", "abs": "https://arxiv.org/abs/2507.10574", "authors": ["Jae Wan Shim"], "title": "Enhancing Cross Entropy with a Linearly Adaptive Loss Function for Optimized Classification Performance", "categories": ["cs.LG", "cs.AI", "cs.NE"], "comment": "13 pages, 2 figures", "summary": "We propose the Linearly Adaptive Cross Entropy Loss function. This is a novel\nmeasure derived from the information theory. In comparison to the standard\ncross entropy loss function, the proposed one has an additional term that\ndepends on the predicted probability of the true class. This feature serves to\nenhance the optimization process in classification tasks involving one-hot\nencoded class labels. The proposed one has been evaluated on a ResNet-based\nmodel using the CIFAR-100 dataset. Preliminary results show that the proposed\none consistently outperforms the standard cross entropy loss function in terms\nof classification accuracy. Moreover, the proposed one maintains simplicity,\nachieving practically the same efficiency to the traditional cross entropy\nloss. These findings suggest that our approach could broaden the scope for\nfuture research into loss function design.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570\uff0c\u5373\u7ebf\u6027\u81ea\u9002\u5e94\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u5e76\u5728CIFAR-100\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6807\u51c6\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u7f3a\u4e4f\u5bf9\u771f\u5b9e\u7c7b\u522b\u7684\u9884\u6d4b\u6982\u7387\u7684\u4f9d\u8d56\uff0c\u8fd9\u53ef\u80fd\u9650\u5236\u4e86\u4f18\u5316\u8fc7\u7a0b\u7684\u6548\u679c\u3002\u4e3a\u4e86\u6539\u8fdb\u8fd9\u4e00\u70b9\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u7ebf\u6027\u81ea\u9002\u5e94\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u4ee5\u589e\u5f3a\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u4f18\u5316\u6548\u679c\u3002", "method": "\u65b0\u63d0\u51fa\u7684\u635f\u5931\u51fd\u6570\u57fa\u4e8e\u4fe1\u606f\u7406\u8bba\uff0c\u4e0e\u6807\u51c6\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u76f8\u6bd4\uff0c\u589e\u52a0\u4e86\u4e00\u4e2a\u53d6\u51b3\u4e8e\u771f\u5b9e\u7c7b\u522b\u9884\u6d4b\u6982\u7387\u7684\u9879\u3002\u8fd9\u4e00\u7279\u6027\u6709\u52a9\u4e8e\u4f18\u5316\u4f7f\u7528one-hot\u7f16\u7801\u7c7b\u522b\u6807\u7b7e\u7684\u5206\u7c7b\u4efb\u52a1\u3002", "result": "\u5728\u57fa\u4e8eResNet\u6a21\u578b\u548cCIFAR-100\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u635f\u5931\u51fd\u6570\u5728\u5206\u7c7b\u51c6\u786e\u6027\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u6807\u51c6\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u51e0\u4e4e\u76f8\u540c\u7684\u6548\u7387\u3002", "conclusion": "\u7ebf\u6027\u81ea\u9002\u5e94\u4ea4\u53c9\u71b5\u635f\u5931\u51fd\u6570\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u5206\u7c7b\u51c6\u786e\u6027\uff0c\u800c\u4e14\u4fdd\u6301\u4e86\u7b80\u5355\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u672a\u6765\u635f\u5931\u51fd\u6570\u8bbe\u8ba1\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2507.10592", "pdf": "https://arxiv.org/pdf/2507.10592", "abs": "https://arxiv.org/abs/2507.10592", "authors": ["Steve Tippeconnic"], "title": "Breaking a 5-Bit Elliptic Curve Key using a 133-Qubit Quantum Computer", "categories": ["cs.CR", "68Q12, 81P68, 11T71"], "comment": "32 pages, 5 figures, real hardware results from IBM Quantum, all\n  code, circuits, and raw data are publicly available for replication", "summary": "This experiment breaks a 5-bit elliptic curve cryptographic key using a\nShor-style quantum attack. Executed on IBM's 133-qubit ibm_torino with Qiskit\nRuntime 2.0, a 15-qubit circuit, comprised of 10 logical qubits and 5 ancilla,\ninterferes over an order-32 elliptic curve subgroup to extract the secret\nscalar k from the public key relation Q = kP, without ever encoding k directly\ninto the oracle. From 16,384 shots, the quantum interference reveals a diagonal\nridge in the 32 x 32 QFT outcome space. The quantum circuit, over 67,000 layers\ndeep, produced valid interference patterns despite extreme circuit depth, and\nclassical post-processing revealed k = 7 in the top 100 invertible (a, b)\nresults. All code, circuits, and raw data are publicly available for\nreplication.", "AI": {"tldr": "\u672c\u5b9e\u9a8c\u4f7f\u7528Shor\u98ce\u683c\u7684\u91cf\u5b50\u653b\u51fb\u7834\u89e3\u4e86\u4e00\u4e2a5\u4f4d\u692d\u5706\u66f2\u7ebf\u52a0\u5bc6\u5bc6\u94a5\uff0c\u5e76\u5728IBM\u7684133\u91cf\u5b50\u6bd4\u7279ibm_torino\u4e0a\u6267\u884c\uff0c\u6210\u529f\u5730\u4ece\u516c\u94a5\u5173\u7cfb\u4e2d\u63d0\u53d6\u4e86\u79d8\u5bc6\u6807\u91cfk\u3002", "motivation": "\u52a8\u673a\u5728\u4e8e\u5c55\u793a\u91cf\u5b50\u8ba1\u7b97\u5728\u7834\u89e3\u4f20\u7edf\u52a0\u5bc6\u6280\u672f\u4e0a\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u692d\u5706\u66f2\u7ebf\u5bc6\u7801\u5b66\u65b9\u9762\u3002", "method": "\u901a\u8fc7\u4f7f\u7528Qiskit Runtime 2.0\uff0c\u5728IBM\u7684133-qubit ibm_torino\u4e0a\u6784\u5efa\u548c\u8fd0\u884c\u4e00\u4e2a15-qubit\u7535\u8def\uff0c\u8be5\u7535\u8def\u5305\u62ec10\u4e2a\u903b\u8f91\u91cf\u5b50\u6bd4\u7279\u548c5\u4e2a\u8f85\u52a9\u91cf\u5b50\u6bd4\u7279\u3002\u8be5\u65b9\u6cd5\u4e0d\u76f4\u63a5\u5c06\u79d8\u5bc6\u6807\u91cf\u7f16\u7801\u5230oracle\u4e2d\uff0c\u800c\u662f\u901a\u8fc7\u91cf\u5b50\u5e72\u6d89\u5728\u4e00\u4e2a32\u9636\u692d\u5706\u66f2\u7ebf\u5b50\u7fa4\u4e0a\u64cd\u4f5c\u4ee5\u63d0\u53d6\u79d8\u5bc6\u6807\u91cfk\u3002", "result": "\u5c3d\u7ba1\u7535\u8def\u6df1\u5ea6\u6781\u7aef\uff08\u8d85\u8fc767,000\u5c42\uff09\uff0c\u91cf\u5b50\u7535\u8def\u4ecd\u4ea7\u751f\u4e86\u6709\u6548\u7684\u5e72\u6d89\u56fe\u6848\u3002\u7ecf\u5178\u540e\u5904\u7406\u63ed\u793a\u4e86\u524d100\u4e2a\u53ef\u9006(a, b)\u7ed3\u679c\u4e2d\u7684k = 7\u3002", "conclusion": "\u5b9e\u9a8c\u6210\u529f\u5730\u4f7f\u7528\u91cf\u5b50\u8ba1\u7b97\u8d44\u6e90\u7834\u89e3\u4e86\u4e00\u4e2a5\u4f4d\u692d\u5706\u66f2\u7ebf\u52a0\u5bc6\u5bc6\u94a5\uff0c\u8bc1\u660e\u4e86\u91cf\u5b50\u8ba1\u7b97\u5728\u5bc6\u7801\u5206\u6790\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u80fd\u529b\u3002\u6240\u6709\u4ee3\u7801\u3001\u7535\u8def\u548c\u539f\u59cb\u6570\u636e\u90fd\u516c\u5f00\u53ef\u7528\uff0c\u4ee5\u4f9b\u590d\u5236\u3002"}}
{"id": "2507.10644", "pdf": "https://arxiv.org/pdf/2507.10644", "abs": "https://arxiv.org/abs/2507.10644", "authors": ["Tatiana Petrova", "Aleksandr Puzikov", "Boris Bliznukov", "Radu State"], "title": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.HC", "cs.MA", "I.2.11; I.2.7; C.2.4; K.6.5; I.2.4"], "comment": "33 pages, 9 figures, 8 tables", "summary": "The concept of the Web of Agents (WoA), which transforms the static,\ndocument-centric Web into an environment of autonomous agents acting on users'\nbehalf, has attracted growing interest as large language models (LLMs) become\nmore capable. However, research in this area is still fragmented across\ndifferent communities. Contemporary surveys catalog the latest LLM-powered\nframeworks, while the rich histories of Multi-Agent Systems (MAS) and the\nSemantic Web are often treated as separate, legacy domains. This fragmentation\nobscures the intellectual lineage of modern systems and hinders a holistic\nunderstanding of the field's trajectory. We present the first comprehensive\nevolutionary overview of the WoA. We show that modern protocols like A2A and\nthe MCP, are direct evolutionary responses to the well-documented limitations\nof earlier standards like FIPA standards and OWL-based semantic agents. To\nsystematize this analysis, we introduce a four-axis taxonomy (semantic\nfoundation, communication paradigm, locus of intelligence, discovery\nmechanism). This framework provides a unified analytical lens for comparing\nagent architectures across all generations, revealing a clear line of descent\nwhere others have seen a disconnect. Our analysis identifies a paradigm shift\nin the 'locus of intelligence': from being encoded in external data (Semantic\nWeb) or the platform (MAS) to being embedded within the agent's core model\n(LLM). This shift is foundational to modern Agentic AI, enabling the scalable\nand adaptive systems the WoA has long envisioned. We conclude that while new\nprotocols are essential, they are insufficient for building a robust, open,\ntrustworthy ecosystem. Finally, we argue that the next research frontier lies\nin solving persistent socio-technical challenges, and we map out a new agenda\nfocused on decentralized identity, economic models, security, and governance\nfor the emerging WoA.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9bWeb of Agents (WoA) \u7684\u9996\u4e2a\u5168\u9762\u8fdb\u5316\u6982\u8ff0\uff0c\u5f15\u5165\u56db\u8f74\u5206\u7c7b\u6cd5\u7cfb\u7edf\u5206\u6790\u4ee3\u7406\u67b6\u6784\uff0c\u5e76\u5f3a\u8c03\u65b0\u7684\u667a\u80fd\u5b9a\u4f4d\u8303\u5f0f\u5bf9\u73b0\u4ee3Agentic AI\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u5173\u4e8eWoA\u7684\u7814\u7a76\u5206\u6563\u5728\u4e0d\u540c\u793e\u533a\uff0c\u7f3a\u4e4f\u5bf9\u8fd9\u4e00\u9886\u57df\u6574\u4f53\u53d1\u5c55\u8f68\u8ff9\u7684\u7406\u89e3\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u6b64\u6587\u4e3aWoA\u63d0\u4f9b\u4e00\u4e2a\u7efc\u5408\u7684\u8fdb\u5316\u6982\u89c8\uff0c\u4ee5\u89e3\u51b3\u8fd9\u79cd\u788e\u7247\u5316\u7684\u95ee\u9898\u3002", "method": "\u6587\u7ae0\u4ecb\u7ecd\u4e86\u4e00\u79cd\u56db\u8f74\u5206\u7c7b\u6cd5\uff08\u8bed\u4e49\u57fa\u7840\u3001\u901a\u4fe1\u8303\u5f0f\u3001\u667a\u80fd\u4f4d\u7f6e\u3001\u53d1\u73b0\u673a\u5236\uff09\uff0c\u7528\u4e8e\u6bd4\u8f83\u5404\u4ee3\u4ee3\u7406\u67b6\u6784\uff0c\u5e76\u5206\u6790\u4e86\u4ece\u65e9\u671f\u6807\u51c6\u5982FIPA\u6807\u51c6\u548c\u57fa\u4e8eOWL\u7684\u8bed\u4e49\u4ee3\u7406\u5230\u73b0\u4ee3\u534f\u8bae\u5982A2A\u548cMCP\u7684\u6f14\u53d8\u3002", "result": "\u8be5\u5206\u6790\u63ed\u793a\u4e86\u667a\u80fd\u5b9a\u4f4d\u4ece\u5916\u90e8\u6570\u636e\u6216\u5e73\u53f0\u5230\u5d4c\u5165\u4ee3\u7406\u6838\u5fc3\u6a21\u578b\uff08LLM\uff09\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u8fd9\u662f\u73b0\u4ee3Agentic AI\u7684\u57fa\u7840\u3002\u540c\u65f6\u6307\u51fa\u65b0\u534f\u8bae\u867d\u91cd\u8981\u4f46\u4e0d\u8db3\u4ee5\u5efa\u7acb\u5f3a\u5927\u7684\u5f00\u653e\u53ef\u4fe1\u751f\u6001\u7cfb\u7edf\u3002", "conclusion": "\u7814\u7a76\u603b\u7ed3\u8ba4\u4e3a\uff0c\u672a\u6765\u7684\u7814\u7a76\u524d\u6cbf\u5728\u4e8e\u89e3\u51b3\u6301\u7eed\u5b58\u5728\u7684\u793e\u4f1a\u6280\u672f\u6311\u6218\uff0c\u5e76\u52fe\u753b\u4e86\u4e00\u4e2a\u65b0\u7684\u8bae\u7a0b\uff0c\u91cd\u70b9\u662f\u53bb\u4e2d\u5fc3\u5316\u8eab\u4efd\u3001\u7ecf\u6d4e\u6a21\u578b\u3001\u5b89\u5168\u6027\u548c\u6cbb\u7406\u65b0\u5174WoA\u3002"}}
{"id": "2507.10575", "pdf": "https://arxiv.org/pdf/2507.10575", "abs": "https://arxiv.org/abs/2507.10575", "authors": ["Kieran Chai Kai Ren"], "title": "An Adaptive Volatility-based Learning Rate Scheduler", "categories": ["cs.LG"], "comment": null, "summary": "Effective learning rate (LR) scheduling is crucial for training deep neural\nnetworks. However, popular pre-defined and adaptive schedulers can still lead\nto suboptimal generalization. This paper introduces VolSched, a novel adaptive\nLR scheduler inspired by the concept of volatility in stochastic processes like\nGeometric Brownian Motion to dynamically adjust the learning rate. By\ncalculating the ratio between long-term and short-term accuracy volatility,\nVolSched increases the LR to escape plateaus and decreases it to stabilize\ntraining, allowing the model to explore the loss landscape more effectively. We\nevaluate VolSched on the CIFAR-100 dataset against a strong baseline using a\nstandard augmentation pipeline. When paired with ResNet-18 and ResNet-34, our\nscheduler delivers consistent performance gains, improving top-1 accuracy by\n1.4 and 1.3 percentage points respectively. Analysis of the loss curves reveals\nthat VolSched promotes a longer exploration phase. A quantitative analysis of\nthe Hessian shows that VolSched finds a final solution that is 38% flatter than\nthe next-best baseline, allowing the model to obtain wider minima and hence\nbetter generalization performance.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u8c03\u5ea6\u5668VolSched\uff0c\u5b83\u901a\u8fc7\u8ba1\u7b97\u957f\u671f\u548c\u77ed\u671f\u51c6\u786e\u7387\u6ce2\u52a8\u7387\u4e4b\u95f4\u7684\u6bd4\u7387\u6765\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387\u3002\u5728CIFAR-100\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVolSched\u53ef\u4ee5\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u4f7f\u6a21\u578b\u83b7\u5f97\u66f4\u5bbd\u7684\u6700\u5c0f\u503c\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u9884\u5b9a\u4e49\u548c\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u4ecd\u53ef\u80fd\u5bfc\u81f4\u6b21\u4f18\u7684\u6cdb\u5316\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u8fd9\u4e00\u70b9\u3002", "method": "\u5f15\u5165\u4e86VolSched\uff0c\u4e00\u79cd\u53d7\u51e0\u4f55\u5e03\u6717\u8fd0\u52a8\u7b49\u968f\u673a\u8fc7\u7a0b\u4e2d\u7684\u6ce2\u52a8\u6027\u6982\u5ff5\u542f\u53d1\u7684\u81ea\u9002\u5e94\u5b66\u4e60\u7387\u8c03\u5ea6\u5668\u3002\u5b83\u901a\u8fc7\u8ba1\u7b97\u957f\u671f\u548c\u77ed\u671f\u51c6\u786e\u7387\u6ce2\u52a8\u7387\u4e4b\u95f4\u7684\u6bd4\u7387\u6765\u52a8\u6001\u8c03\u6574\u5b66\u4e60\u7387\u3002", "result": "\u5f53\u4e0eResNet-18\u548cResNet-34\u914d\u5bf9\u65f6\uff0cVolSched\u5206\u522b\u63d0\u9ad8\u4e861.4\u548c1.3\u4e2a\u767e\u5206\u70b9\u7684top-1\u51c6\u786e\u6027\u3002Hessian\u5206\u6790\u663e\u793a\uff0cVolSched\u627e\u5230\u7684\u6700\u7ec8\u89e3\u6bd4\u6b21\u4f73\u57fa\u7ebf\u5e73\u576638\uff05\u3002", "conclusion": "VolSched\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u63a2\u7d22\u635f\u5931\u666f\u89c2\uff0c\u63d0\u4f9b\u66f4\u5e7f\u6cdb\u7684\u6700\u5c0f\u503c\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2507.10610", "pdf": "https://arxiv.org/pdf/2507.10610", "abs": "https://arxiv.org/abs/2507.10610", "authors": ["Zihe Yan", "Zhuosheng Zhang"], "title": "LaSM: Layer-wise Scaling Mechanism for Defending Pop-up Attack on GUI Agents", "categories": ["cs.CR", "cs.AI"], "comment": "10 pages, 9 figures", "summary": "Graphical user interface (GUI) agents built on multimodal large language\nmodels (MLLMs) have recently demonstrated strong decision-making abilities in\nscreen-based interaction tasks. However, they remain highly vulnerable to\npop-up-based environmental injection attacks, where malicious visual elements\ndivert model attention and lead to unsafe or incorrect actions. Existing\ndefense methods either require costly retraining or perform poorly under\ninductive interference. In this work, we systematically study how such attacks\nalter the attention behavior of GUI agents and uncover a layer-wise attention\ndivergence pattern between correct and incorrect outputs. Based on this\ninsight, we propose \\textbf{LaSM}, a \\textit{Layer-wise Scaling Mechanism} that\nselectively amplifies attention and MLP modules in critical layers. LaSM\nimproves the alignment between model saliency and task-relevant regions without\nadditional training. Extensive experiments across 12 types of pop-up\nperturbations and 4 different model backbones show that LaSM consistently\nenhances the defense success rate. When combined with prompt-level alerts, LaSM\nachieves over 98\\% robustness even under strong inductive attacks. Our findings\nreveal that attention misalignment is a core vulnerability in MLLM agents and\ncan be effectively addressed through selective layer-wise modulation.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c42\u6b21\u7f29\u653e\u673a\u5236(LaSM)\u7684\u65b9\u6cd5\uff0c\u4ee5\u589e\u5f3aGUI\u4ee3\u7406\u5bf9\u57fa\u4e8e\u5f39\u51fa\u5f0f\u7684\u73af\u5883\u6ce8\u5165\u653b\u51fb\u7684\u9632\u5fa1\u80fd\u529b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9009\u62e9\u6027\u653e\u5927\u5173\u952e\u5c42\u4e2d\u7684\u6ce8\u610f\u529b\u548cMLP\u6a21\u5757\uff0c\u6539\u5584\u6a21\u578b\u663e\u8457\u6027\u548c\u4efb\u52a1\u76f8\u5173\u533a\u57df\u4e4b\u95f4\u7684\u5bf9\u9f50\uff0c\u4ece\u800c\u63d0\u9ad8\u9632\u5fa1\u6210\u529f\u7387\uff0c\u751a\u81f3\u5728\u5f3a\u70c8\u7684\u5f52\u7eb3\u653b\u51fb\u4e0b\u4e5f\u80fd\u8fbe\u523098%\u4ee5\u4e0a\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u6784\u5efa\u7684\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u4ee3\u7406\u867d\u7136\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u51b3\u7b56\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u5bf9\u4e8e\u57fa\u4e8e\u5f39\u51fa\u7a97\u53e3\u7684\u73af\u5883\u6ce8\u5165\u653b\u51fb\u975e\u5e38\u8106\u5f31\u3002\u8fd9\u79cd\u653b\u51fb\u4f1a\u8bef\u5bfc\u6a21\u578b\u7684\u6ce8\u610f\u529b\uff0c\u5bfc\u81f4\u4e0d\u5b89\u5168\u6216\u9519\u8bef\u7684\u64cd\u4f5c\u3002\u5f53\u524d\u7684\u9632\u5fa1\u63aa\u65bd\u8981\u4e48\u9700\u8981\u9ad8\u6602\u7684\u518d\u8bad\u7ec3\u6210\u672c\uff0c\u8981\u4e48\u5728\u5f52\u7eb3\u5e72\u6270\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u7814\u7a76\u4eba\u5458\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u8fd9\u4e9b\u653b\u51fb\u5982\u4f55\u6539\u53d8GUI\u4ee3\u7406\u7684\u6ce8\u610f\u529b\u884c\u4e3a\uff0c\u5e76\u53d1\u73b0\u6b63\u786e\u548c\u9519\u8bef\u8f93\u51fa\u4e4b\u95f4\u5b58\u5728\u5c42\u6b21\u6ce8\u610f\u529b\u5206\u6563\u6a21\u5f0f\u3002\u57fa\u4e8e\u8fd9\u4e00\u89c1\u89e3\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86LaSM\uff08Layer-wise Scaling Mechanism\uff09\uff0c\u5b83\u9009\u62e9\u6027\u5730\u653e\u5927\u5173\u952e\u5c42\u4e2d\u7684\u6ce8\u610f\u529b\u548cMLP\u6a21\u5757\uff0c\u4ee5\u6539\u5584\u6a21\u578b\u663e\u8457\u6027\u4e0e\u4efb\u52a1\u76f8\u5173\u533a\u57df\u4e4b\u95f4\u7684\u5bf9\u9f50\uff0c\u800c\u65e0\u9700\u989d\u5916\u7684\u8bad\u7ec3\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLaSM\u572812\u79cd\u7c7b\u578b\u7684\u5f39\u51fa\u5f0f\u5e72\u6270\u548c4\u79cd\u4e0d\u540c\u7684\u6a21\u578b\u9aa8\u5e72\u4e0a\u4e00\u81f4\u63d0\u9ad8\u4e86\u9632\u5fa1\u6210\u529f\u7387\u3002\u5f53\u4e0e\u63d0\u793a\u7ea7\u522b\u7684\u8b66\u62a5\u7ed3\u5408\u4f7f\u7528\u65f6\uff0c\u5373\u4f7f\u5728\u5f3a\u70c8\u7684\u5f52\u7eb3\u653b\u51fb\u4e0b\uff0cLaSM\u4e5f\u80fd\u5b9e\u73b0\u8d85\u8fc798%\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u6ce8\u610f\u529b\u9519\u4f4d\u662fMLLM\u4ee3\u7406\u7684\u6838\u5fc3\u6f0f\u6d1e\uff0c\u53ef\u4ee5\u901a\u8fc7\u9009\u62e9\u6027\u7684\u5c42\u6b21\u8c03\u5236\u6709\u6548\u89e3\u51b3\u3002"}}
{"id": "2507.10740", "pdf": "https://arxiv.org/pdf/2507.10740", "abs": "https://arxiv.org/abs/2507.10740", "authors": ["Maziar Kanani", "Sean O Leary", "James McDermott"], "title": "Parsing Musical Structure to Enable Meaningful Variations", "categories": ["cs.AI", "cs.NE", "cs.SD", "eess.AS"], "comment": null, "summary": "This paper presents a novel rule-based approach for generating music by\nvarying existing tunes. We parse each tune to find the Pathway Assembly (PA) [\n1], that is a structure representing all repetitions in the tune. The Sequitur\nalgorithm [2 ] is used for this. The result is a grammar. We then carry out\nmutation on the grammar, rather than on a tune directly. There are potentially\n19 types of mutations such as adding, removing, swapping or reversing parts of\nthe grammar that can be applied to the grammars. The system employs one of the\nmutations randomly in this step to automatically manipulate the grammar.\nFollowing the mutation, we need to expand the grammar which returns a new tune.\nThe output after 1 or more mutations will be a new tune related to the original\ntune. Our study examines how tunes change gradually over the course of multiple\nmutations. Edit distances, structural complexity and length of the tunes are\nused to show how a tune is changed after multiple mutations. In addition, the\nsize of effect of each mutation type is analyzed. As a final point, we review\nthe musical aspect of the output tunes. It should be noted that the study only\nfocused on generating new pitch sequences. The study is based on an Irish\ntraditional tune dataset and a list of integers has been used to represent each\ntune's pitch values.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c4\u5219\u7684\u97f3\u4e50\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u53d8\u5f02\u73b0\u6709\u66f2\u8c03\u7684\u8bed\u6cd5\u7ed3\u6784\u6765\u521b\u9020\u65b0\u66f2\u8c03\u3002", "motivation": "\u52a8\u673a\u662f\u63a2\u7d22\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\u6765\u751f\u6210\u97f3\u4e50\uff0c\u8be5\u65b9\u6cd5\u4e0d\u662f\u76f4\u63a5\u6539\u53d8\u66f2\u8c03\uff0c\u800c\u662f\u901a\u8fc7\u6539\u53d8\u8868\u793a\u66f2\u8c03\u91cd\u590d\u7ed3\u6784\u7684\u8bed\u6cd5\u89c4\u5219\u3002\u8fd9\u5141\u8bb8\u521b\u5efa\u4e0e\u539f\u59cb\u66f2\u8c03\u6709\u5173\u7684\u65b0\u66f2\u8c03\uff0c\u5e76\u7814\u7a76\u8fd9\u4e9b\u66f2\u8c03\u5728\u591a\u6b21\u53d8\u5f02\u8fc7\u7a0b\u4e2d\u7684\u53d8\u5316\u3002", "method": "\u4f7f\u7528Sequitur\u7b97\u6cd5\u89e3\u6790\u66f2\u8c03\u4ee5\u627e\u5230\u6240\u6709\u91cd\u590d\u7684\u7ed3\u6784\uff08Pathway Assembly\uff09\u3002\u7136\u540e\u5bf9\u7531\u6b64\u4ea7\u751f\u7684\u8bed\u6cd5\u8fdb\u884c19\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u53d8\u5f02\u64cd\u4f5c\u3002\u53d8\u5f02\u540e\u7684\u8bed\u6cd5\u88ab\u5c55\u5f00\u4ee5\u8fd4\u56de\u65b0\u7684\u66f2\u8c03\u3002", "result": "\u901a\u8fc7\u7f16\u8f91\u8ddd\u79bb\u3001\u7ed3\u6784\u590d\u6742\u6027\u548c\u957f\u5ea6\u7684\u53d8\u5316\u5c55\u793a\u4e86\u66f2\u8c03\u5728\u591a\u6b21\u53d8\u5f02\u540e\u5982\u4f55\u53d8\u5316\u3002\u5206\u6790\u4e86\u6bcf\u79cd\u53d8\u5f02\u7c7b\u578b\u7684\u6548\u679c\u5927\u5c0f\uff0c\u5e76\u56de\u987e\u4e86\u8f93\u51fa\u66f2\u8c03\u7684\u97f3\u4e50\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5bf9\u66f2\u8c03\u7684\u8bed\u6cd5\u7ed3\u6784\u8fdb\u884c\u53d8\u5f02\u53ef\u4ee5\u4ea7\u751f\u65b0\u7684\u66f2\u8c03\uff0c\u540c\u65f6\u4fdd\u7559\u4e0e\u539f\u59cb\u66f2\u8c03\u7684\u8054\u7cfb\u3002\u6b64\u5916\uff0c\u4e0d\u540c\u7684\u53d8\u5f02\u7c7b\u578b\u5bf9\u65b0\u66f2\u8c03\u7684\u5f71\u54cd\u7a0b\u5ea6\u4e5f\u6709\u6240\u4e0d\u540c\u3002"}}
{"id": "2507.10581", "pdf": "https://arxiv.org/pdf/2507.10581", "abs": "https://arxiv.org/abs/2507.10581", "authors": ["Esmail Gumaan"], "title": "Universal Approximation Theorem for a Single-Layer Transformer", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "7 pages, 2 figures, 1 theorem, 10 formulas", "summary": "Deep learning employs multi-layer neural networks trained via the\nbackpropagation algorithm. This approach has achieved success across many\ndomains and relies on adaptive gradient methods such as the Adam optimizer.\nSequence modeling evolved from recurrent neural networks to attention-based\nmodels, culminating in the Transformer architecture. Transformers have achieved\nstate-of-the-art performance in natural language processing (for example, BERT\nand GPT-3) and have been applied in computer vision and computational biology.\nHowever, theoretical understanding of these models remains limited. In this\npaper, we examine the mathematical foundations of deep learning and\nTransformers and present a novel theoretical result. We review key concepts\nfrom linear algebra, probability, and optimization that underpin deep learning,\nand we analyze the multi-head self-attention mechanism and the backpropagation\nalgorithm in detail. Our main contribution is a universal approximation theorem\nfor Transformers: we prove that a single-layer Transformer, comprising one\nself-attention layer followed by a position-wise feed-forward network with ReLU\nactivation, can approximate any continuous sequence-to-sequence mapping on a\ncompact domain to arbitrary precision. We provide a formal statement and a\ncomplete proof. Finally, we present case studies that demonstrate the practical\nimplications of this result. Our findings advance the theoretical understanding\nof Transformer models and help bridge the gap between theory and practice.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5355\u5c42Transformer\u7684\u901a\u7528\u8fd1\u4f3c\u5b9a\u7406\uff0c\u8bc1\u660e\u4e86\u5b83\u80fd\u591f\u4ee5\u4efb\u610f\u7cbe\u5ea6\u8fd1\u4f3c\u4efb\u4f55\u8fde\u7eed\u7684\u5e8f\u5217\u5230\u5e8f\u5217\u6620\u5c04\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u8be5\u7ed3\u679c\u7684\u5b9e\u9645\u610f\u4e49\u3002", "motivation": "\u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u548cTransformer\u67b6\u6784\u5728\u8bb8\u591a\u9886\u57df\u4e2d\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5bf9\u8fd9\u4e9b\u6a21\u578b\u7684\u7406\u8bba\u7406\u89e3\u4ecd\u7136\u6709\u9650\u3002\u4e3a\u4e86\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u672c\u6587\u65e8\u5728\u6df1\u5165\u63a2\u8ba8\u6df1\u5ea6\u5b66\u4e60\u548cTransformer\u7684\u6570\u5b66\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u65b0\u7684\u7406\u8bba\u6210\u679c\u3002", "method": "\u4f5c\u8005\u56de\u987e\u4e86\u7ebf\u6027\u4ee3\u6570\u3001\u6982\u7387\u8bba\u548c\u4f18\u5316\u4e2d\u7684\u5173\u952e\u6982\u5ff5\uff0c\u8be6\u7ec6\u5206\u6790\u4e86\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5173\u4e8eTransformer\u7684\u901a\u7528\u8fd1\u4f3c\u5b9a\u7406\uff0c\u968f\u540e\u7ed9\u51fa\u4e86\u6b63\u5f0f\u9648\u8ff0\u548c\u5b8c\u6574\u8bc1\u660e\u3002", "result": "\u4e3b\u8981\u8d21\u732e\u662f\u4e00\u4e2a\u901a\u7528\u8fd1\u4f3c\u5b9a\u7406\uff0c\u8868\u660e\u5355\u5c42Transformer\u53ef\u4ee5\u8fd1\u4f3c\u4efb\u4f55\u8fde\u7eed\u7684\u5e8f\u5217\u5230\u5e8f\u5217\u6620\u5c04\u81f3\u4efb\u610f\u7cbe\u5ea6\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u5c55\u793a\u8be5\u7ed3\u679c\u5b9e\u9645\u5f71\u54cd\u7684\u6848\u4f8b\u7814\u7a76\u3002", "conclusion": "\u672c\u7814\u7a76\u52a0\u6df1\u4e86\u5bf9Transformer\u6a21\u578b\u7684\u7406\u8bba\u7406\u89e3\uff0c\u5e76\u6709\u52a9\u4e8e\u5f25\u5408\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002"}}
{"id": "2507.10621", "pdf": "https://arxiv.org/pdf/2507.10621", "abs": "https://arxiv.org/abs/2507.10621", "authors": ["Quanyan Zhu"], "title": "Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.GT"], "comment": null, "summary": "Protecting cyberspace requires not only advanced tools but also a shift in\nhow we reason about threats, trust, and autonomy. Traditional cybersecurity\nmethods rely on manual responses and brittle heuristics. To build proactive and\nintelligent defense systems, we need integrated theoretical frameworks and\nsoftware tools. Game theory provides a rigorous foundation for modeling\nadversarial behavior, designing strategic defenses, and enabling trust in\nautonomous systems. Meanwhile, software tools process cyber data, visualize\nattack surfaces, verify compliance, and suggest mitigations. Yet a disconnect\nremains between theory and practical implementation.\n  The rise of Large Language Models (LLMs) and agentic AI offers a new path to\nbridge this gap. LLM-powered agents can operationalize abstract strategies into\nreal-world decisions. Conversely, game theory can inform the reasoning and\ncoordination of these agents across complex workflows. LLMs also challenge\nclassical game-theoretic assumptions, such as perfect rationality or static\npayoffs, prompting new models aligned with cognitive and computational\nrealities. This co-evolution promises richer theoretical foundations and novel\nsolution concepts. Agentic AI also reshapes software design: systems must now\nbe modular, adaptive, and trust-aware from the outset.\n  This chapter explores the intersection of game theory, agentic AI, and\ncybersecurity. We review key game-theoretic frameworks (e.g., static, dynamic,\nBayesian, and signaling games) and solution concepts. We then examine how LLM\nagents can enhance cyber defense and introduce LLM-driven games that embed\nreasoning into AI agents. Finally, we explore multi-agent workflows and\ncoordination games, outlining how this convergence fosters secure, intelligent,\nand adaptive cyber systems.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u535a\u5f08\u8bba\u3001\u4ee3\u7406AI\u548c\u7f51\u7edc\u5b89\u5168\u7684\u4ea4\u6c47\u70b9\uff0c\u5f3a\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8fde\u63a5\u7406\u8bba\u4e0e\u5b9e\u8df5\u4e2d\u7684\u4f5c\u7528\u3002", "motivation": "\u4f20\u7edf\u7f51\u7edc\u5b89\u5168\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u624b\u52a8\u54cd\u5e94\u548c\u8106\u5f31\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u9700\u8981\u66f4\u4e3b\u52a8\u548c\u667a\u80fd\u7684\u9632\u5fa1\u7cfb\u7edf\u3002\u535a\u5f08\u8bba\u4e3a\u5efa\u6a21\u5bf9\u6297\u884c\u4e3a\u548c\u8bbe\u8ba1\u6218\u7565\u9632\u5fa1\u63d0\u4f9b\u4e86\u4e25\u683c\u7684\u7406\u8bba\u57fa\u7840\u3002", "method": "\u7ed3\u5408\u535a\u5f08\u8bba\u6846\u67b6\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u4ee3\u7406\uff0c\u4ee5\u5b9e\u73b0\u62bd\u8c61\u7b56\u7565\u7684\u5177\u4f53\u64cd\u4f5c\u5316\uff0c\u5e76\u4fc3\u8fdb\u590d\u6742\u5de5\u4f5c\u6d41\u4e2d\u4ee3\u7406\u95f4\u7684\u534f\u8c03\u3002", "result": "\u8fd9\u79cd\u7ed3\u5408\u53ef\u4ee5\u5b9e\u73b0\u66f4\u4e30\u5bcc\u7684\u7406\u8bba\u57fa\u7840\u548c\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6982\u5ff5\uff0c\u540c\u65f6\u91cd\u5851\u8f6f\u4ef6\u8bbe\u8ba1\uff0c\u4f7f\u5176\u4ece\u4e00\u5f00\u59cb\u5c31\u5177\u6709\u6a21\u5757\u5316\u3001\u9002\u5e94\u6027\u548c\u4fe1\u4efb\u610f\u8bc6\u3002", "conclusion": "\u901a\u8fc7\u63a2\u7d22\u535a\u5f08\u8bba\u3001\u4ee3\u7406AI\u548c\u7f51\u7edc\u5b89\u5168\u7684\u4ea4\u6c47\u70b9\uff0c\u53ef\u4ee5\u4fc3\u8fdb\u5b89\u5168\u3001\u667a\u80fd\u548c\u9002\u5e94\u6027\u7684\u7f51\u7edc\u7cfb\u7edf\u7684\u5f62\u6210\u3002"}}
{"id": "2507.10750", "pdf": "https://arxiv.org/pdf/2507.10750", "abs": "https://arxiv.org/abs/2507.10750", "authors": ["Pandu Devarakota", "Nicolas Tsesmetzis", "Faruk O. Alpak", "Apurva Gala", "Detlef Hohl"], "title": "AI and the Net-Zero Journey: Energy Demand, Emissions, and the Potential for Transition", "categories": ["cs.AI"], "comment": "Technical article to be submitted to Data Centric Engineering Journal", "summary": "Thanks to the availability of massive amounts of data, computing resources,\nand advanced algorithms, AI has entered nearly every sector. This has sparked\nsignificant investment and interest, particularly in building data centers with\nthe necessary hardware and software to develop and operate AI models and\nAI-based workflows. In this technical review article, we present energy\nconsumption scenarios of data centers and impact on GHG emissions, considering\nboth near-term projections (up to 2030) and long-term outlook (2035 and\nbeyond). We address the quintessential question of whether AI will have a net\npositive, neutral, or negative impact on CO2 emissions by 2035. Additionally,\nwe discuss AI's potential to automate, create efficient and disruptive\nworkflows across various fields related to energy production, supply and\nconsumption. In the near-term scenario, the growing demand for AI will likely\nstrain computing resources, lead to increase in electricity consumption and\ntherefore associated CO2 emissions. This is due to the power-hungry nature of\nbig data centers and the requirements for training and running of large and\ncomplex AI models, as well as the penetration of AI assistant search and\napplications for public use. However, the long-term outlook could be more\npromising. AI has the potential to be a game-changer in CO2 reduction. Its\nability to further automate and optimize processes across industries, from\nenergy production to logistics, could significantly decrease our carbon\nfootprint. This positive impact is anticipated to outweigh the initial\nemissions bump, creating value for businesses and society in areas where\ntraditional solutions have fallen short. In essence, AI might cause some\ninitial growing pains for the environment, but it has the potential to support\nclimate mitigation efforts.", "AI": {"tldr": "\u8fd9\u7bc7\u6280\u672f\u8bc4\u8bba\u6587\u7ae0\u63a2\u8ba8\u4e86\u6570\u636e\u4e2d\u5fc3\u7684\u80fd\u6e90\u6d88\u8017\u60c5\u666f\u53ca\u5176\u5bf9\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u7684\u5f71\u54cd\uff0c\u8bc4\u4f30\u4e86AI\u57282035\u5e74\u4e4b\u524d\u5bf9CO2\u6392\u653e\u7684\u51c0\u5f71\u54cd\uff0c\u5e76\u8ba8\u8bba\u4e86AI\u5728\u672a\u6765\u4f18\u5316\u5404\u884c\u4e1a\u6d41\u7a0b\u3001\u51cf\u5c11\u78b3\u8db3\u8ff9\u7684\u6f5c\u529b\u3002", "motivation": "\u968f\u7740\u5927\u91cf\u6570\u636e\u7684\u53ef\u7528\u6027\u3001\u8ba1\u7b97\u8d44\u6e90\u548c\u9ad8\u7ea7\u7b97\u6cd5\u7684\u53d1\u5c55\uff0cAI\u5df2\u7ecf\u8fdb\u5165\u4e86\u51e0\u4e4e\u6bcf\u4e2a\u9886\u57df\uff0c\u7279\u522b\u662f\u5728\u5efa\u8bbe\u652f\u6301AI\u6a21\u578b\u5f00\u53d1\u548c\u8fd0\u884c\u7684\u6570\u636e\u4e2d\u5fc3\u65b9\u9762\u5f15\u8d77\u4e86\u5927\u91cf\u7684\u6295\u8d44\u548c\u5174\u8da3\u3002\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u8fd9\u4e9b\u53d1\u5c55\u5bf9\u80fd\u6e90\u6d88\u8017\u548c\u6e29\u5ba4\u6c14\u4f53\uff08GHG\uff09\u6392\u653e\u7684\u5f71\u54cd\uff0c\u4ee5\u53caAI\u5728\u77ed\u671f\u5185\u548c\u957f\u671f\u5185\u5bf9\u4e8c\u6c27\u5316\u78b3\u51cf\u6392\u7684\u53ef\u80fd\u4f5c\u7528\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5206\u6790\u548c\u9884\u6d4b\u6570\u636e\u4e2d\u5fc3\u7684\u80fd\u6e90\u6d88\u8017\u6a21\u5f0f\u6765\u7814\u7a76\u5176\u5bf9\u6e29\u5ba4\u6c14\u4f53\u6392\u653e\u7684\u5f71\u54cd\u3002\u4ed6\u4eec\u8003\u8651\u4e86\u52302030\u5e74\u7684\u8fd1\u671f\u9884\u6d4b\u548c2035\u5e74\u53ca\u4ee5\u540e\u7684\u957f\u671f\u5c55\u671b\uff0c\u540c\u65f6\u63a2\u8ba8\u4e86AI\u5728\u4e0d\u540c\u9886\u57df\u7684\u81ea\u52a8\u5316\u548c\u6548\u7387\u63d0\u5347\u80fd\u529b\u3002", "result": "\u5728\u77ed\u671f\u5185\uff0c\u7531\u4e8e\u5927\u578b\u6570\u636e\u4e2d\u5fc3\u7684\u7535\u529b\u9700\u6c42\u548c\u8bad\u7ec3\u590d\u6742AI\u6a21\u578b\u7684\u9700\u6c42\uff0cAI\u7684\u589e\u957f\u53ef\u80fd\u4f1a\u589e\u52a0\u7535\u529b\u6d88\u8017\u548c\u76f8\u5173\u7684\u4e8c\u6c27\u5316\u78b3\u6392\u653e\u3002\u7136\u800c\uff0c\u5728\u957f\u671f\u5185\uff0cAI\u6709\u6f5c\u529b\u901a\u8fc7\u81ea\u52a8\u5316\u548c\u4f18\u5316\u80fd\u6e90\u751f\u4ea7\u3001\u4f9b\u5e94\u548c\u6d88\u8d39\u7b49\u9886\u57df\u7684\u6d41\u7a0b\uff0c\u663e\u8457\u51cf\u5c11\u78b3\u8db3\u8ff9\uff0c\u4ece\u800c\u5bf9\u6c14\u5019\u7f13\u89e3\u5de5\u4f5c\u63d0\u4f9b\u652f\u6301\u3002", "conclusion": "\u5c3d\u7ba1AI\u5728\u521d\u671f\u53ef\u80fd\u4f1a\u7ed9\u73af\u5883\u5e26\u6765\u4e00\u4e9b\u589e\u957f\u7684\u75db\u82e6\uff0c\u4f46\u4ece\u957f\u8fdc\u6765\u770b\uff0c\u5b83\u5177\u6709\u652f\u6301\u6c14\u5019\u7f13\u89e3\u5de5\u4f5c\u7684\u6f5c\u529b\uff0c\u53ef\u4ee5\u5728\u90a3\u4e9b\u4f20\u7edf\u89e3\u51b3\u65b9\u6848\u4e0d\u8db3\u7684\u9886\u57df\u4e3a\u4f01\u4e1a\u548c\u793e\u4f1a\u521b\u9020\u4ef7\u503c\u3002"}}
{"id": "2507.10591", "pdf": "https://arxiv.org/pdf/2507.10591", "abs": "https://arxiv.org/abs/2507.10591", "authors": ["Vanderson Rocha", "Diego Kreutz", "Gabriel Canto", "Hendrio Bragan\u00e7a", "Eduardo Feitosa"], "title": "MH-FSF: A Unified Framework for Overcoming Benchmarking and Reproducibility Limitations in Feature Selection Evaluation", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.PF", "68T01", "I.2"], "comment": "11 pages; 4 figures; 5 tables; submitted to JBCS", "summary": "Feature selection is vital for building effective predictive models, as it\nreduces dimensionality and emphasizes key features. However, current research\noften suffers from limited benchmarking and reliance on proprietary datasets.\nThis severely hinders reproducibility and can negatively impact overall\nperformance. To address these limitations, we introduce the MH-FSF framework, a\ncomprehensive, modular, and extensible platform designed to facilitate the\nreproduction and implementation of feature selection methods. Developed through\ncollaborative research, MH-FSF provides implementations of 17 methods (11\nclassical, 6 domain-specific) and enables systematic evaluation on 10 publicly\navailable Android malware datasets. Our results reveal performance variations\nacross both balanced and imbalanced datasets, highlighting the critical need\nfor data preprocessing and selection criteria that account for these\nasymmetries. We demonstrate the importance of a unified platform for comparing\ndiverse feature selection techniques, fostering methodological consistency and\nrigor. By providing this framework, we aim to significantly broaden the\nexisting literature and pave the way for new research directions in feature\nselection, particularly within the context of Android malware detection.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86MH-FSF\u6846\u67b6\uff0c\u4e00\u4e2a\u5168\u9762\u3001\u6a21\u5757\u5316\u548c\u53ef\u6269\u5c55\u7684\u5e73\u53f0\uff0c\u7528\u4e8e\u4fc3\u8fdb\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u7684\u518d\u73b0\u548c\u5b9e\u65bd\u3002\u5b83\u63d0\u4f9b\u4e8617\u79cd\u65b9\u6cd5\u7684\u5b9e\u73b0\uff0c\u5e76\u572810\u4e2a\u516c\u5f00\u7684Android\u6076\u610f\u8f6f\u4ef6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\u3002\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u6570\u636e\u9884\u5904\u7406\u548c\u9009\u62e9\u6807\u51c6\u7684\u91cd\u8981\u6027\uff0c\u4ee5\u53ca\u7edf\u4e00\u5e73\u53f0\u5bf9\u6bd4\u8f83\u4e0d\u540c\u7279\u5f81\u9009\u62e9\u6280\u672f\u7684\u610f\u4e49\u3002", "motivation": "\u5f53\u524d\u7684\u7814\u7a76\u7ecf\u5e38\u53d7\u5230\u6709\u9650\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u4f9d\u8d56\u4e13\u6709\u6570\u636e\u96c6\u7684\u5f71\u54cd\uff0c\u8fd9\u4e25\u91cd\u963b\u788d\u4e86\u53ef\u91cd\u590d\u6027\u5e76\u53ef\u80fd\u5bf9\u6574\u4f53\u6027\u80fd\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86MH-FSF\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u542b\u4e8617\u79cd\u65b9\u6cd5\uff0811\u79cd\u7ecf\u5178\u65b9\u6cd5\u548c6\u79cd\u7279\u5b9a\u9886\u57df\u7684\u65b9\u6cd5\uff09\uff0c\u5e76\u572810\u4e2a\u516c\u5f00\u53ef\u7528\u7684Android\u6076\u610f\u8f6f\u4ef6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5e73\u8861\u548c\u4e0d\u5e73\u8861\u7684\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u5b58\u5728\u5dee\u5f02\uff0c\u7a81\u663e\u4e86\u8003\u8651\u8fd9\u4e9b\u4e0d\u5bf9\u79f0\u6027\u7684\u6570\u636e\u9884\u5904\u7406\u548c\u9009\u62e9\u6807\u51c6\u7684\u5173\u952e\u9700\u6c42\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u8fd9\u4e2a\u6846\u67b6\uff0c\u7814\u7a76\u4eba\u5458\u65e8\u5728\u663e\u8457\u62d3\u5bbd\u73b0\u6709\u7684\u6587\u732e\uff0c\u5e76\u4e3a\u7279\u5f81\u9009\u62e9\u7684\u65b0\u7814\u7a76\u65b9\u5411\u94fa\u5e73\u9053\u8def\uff0c\u7279\u522b\u662f\u5728Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7684\u80cc\u666f\u4e0b\u3002"}}
{"id": "2507.10622", "pdf": "https://arxiv.org/pdf/2507.10622", "abs": "https://arxiv.org/abs/2507.10622", "authors": ["HyeYoung Lee", "Muhammad Nadeem", "Pavel Tsoi"], "title": "Spectral Feature Extraction for Robust Network Intrusion Detection Using MFCCs", "categories": ["cs.CR", "cond-mat.dis-nn", "cs.AI", "cs.LG"], "comment": null, "summary": "The rapid expansion of Internet of Things (IoT) networks has led to a surge\nin security vulnerabilities, emphasizing the critical need for robust anomaly\ndetection and classification techniques. In this work, we propose a novel\napproach for identifying anomalies in IoT network traffic by leveraging the\nMel-frequency cepstral coefficients (MFCC) and ResNet-18, a deep learning model\nknown for its effectiveness in feature extraction and image-based tasks.\nLearnable MFCCs enable adaptive spectral feature representation, capturing the\ntemporal patterns inherent in network traffic more effectively than traditional\nfixed MFCCs. We demonstrate that transforming raw signals into MFCCs maps the\ndata into a higher-dimensional space, enhancing class separability and enabling\nmore effective multiclass classification. Our approach combines the strengths\nof MFCCs with the robust feature extraction capabilities of ResNet-18, offering\na powerful framework for anomaly detection. The proposed model is evaluated on\nthree widely used IoT intrusion detection datasets: CICIoT2023, NSL-KDD, and\nIoTID20. The experimental results highlight the potential of integrating\nadaptive signal processing techniques with deep learning architectures to\nachieve robust and scalable anomaly detection in heterogeneous IoT network\nlandscapes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684IoT\u7f51\u7edc\u6d41\u91cf\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u53ef\u5b66\u4e60\u7684\u6885\u5c14\u9891\u7387\u5012\u8c31\u7cfb\u6570\uff08MFCC\uff09\u548cResNet-18\u6a21\u578b\u3002\u901a\u8fc7\u5728\u4e09\u4e2a\u5e38\u7528\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8bc1\u660e\u4e86\u8fd9\u79cd\u65b9\u6cd5\u5728\u5f02\u6784IoT\u7f51\u7edc\u73af\u5883\u4e2d\u8fdb\u884c\u7a33\u5065\u548c\u53ef\u6269\u5c55\u7684\u5f02\u5e38\u68c0\u6d4b\u7684\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\uff08IoT\uff09\u7f51\u7edc\u7684\u8fc5\u901f\u6269\u5c55\uff0c\u5b89\u5168\u6f0f\u6d1e\u6fc0\u589e\uff0c\u8feb\u5207\u9700\u8981\u5f3a\u5927\u7684\u5f02\u5e38\u68c0\u6d4b\u548c\u5206\u7c7b\u6280\u672f\u6765\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u8be5\u65b9\u6cd5\u4f7f\u7528\u53ef\u5b66\u4e60\u7684\u6885\u5c14\u9891\u7387\u5012\u8c31\u7cfb\u6570\uff08MFCC\uff09\u5c06\u539f\u59cb\u4fe1\u53f7\u8f6c\u6362\u4e3a\u66f4\u9ad8\u7ef4\u5ea6\u7684\u7a7a\u95f4\uff0c\u5e76\u5229\u7528ResNet-18\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\u548c\u591a\u7c7b\u522b\u5206\u7c7b\u3002", "result": "\u5728CICIoT2023\u3001NSL-KDD\u548cIoTID20\u8fd9\u4e09\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684IoT\u5165\u4fb5\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6574\u5408\u81ea\u9002\u5e94\u4fe1\u53f7\u5904\u7406\u6280\u672f\u548c\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u53ef\u4ee5\u5b9e\u73b0\u7a33\u5065\u4e14\u53ef\u6269\u5c55\u7684\u5f02\u5e38\u68c0\u6d4b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u7ed3\u5408MFCC\u4e0eResNet-18\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u5f3a\u8c03\u4e86\u5728\u5f02\u6784IoT\u7f51\u7edc\u4e2d\u4f7f\u7528\u8fd9\u79cd\u96c6\u6210\u65b9\u6cd5\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.10758", "pdf": "https://arxiv.org/pdf/2507.10758", "abs": "https://arxiv.org/abs/2507.10758", "authors": ["Nikesh Prajapati", "Bimal Karki", "Saroj Gopali", "Akbar Siami Namin"], "title": "IoT Malware Network Traffic Detection using Deep Learning and GraphSAGE Models", "categories": ["cs.AI"], "comment": null, "summary": "This paper intends to detect IoT malicious attacks through deep learning\nmodels and demonstrates a comprehensive evaluation of the deep learning and\ngraph-based models regarding malicious network traffic detection. The models\nparticularly are based on GraphSAGE, Bidirectional encoder representations from\ntransformers (BERT), Temporal Convolutional Network (TCN) as well as Multi-Head\nAttention, together with Bidirectional Long Short-Term Memory (BI-LSTM)\nMulti-Head Attention and BI-LSTM and LSTM models. The chosen models\ndemonstrated great performance to model temporal patterns and detect feature\nsignificance. The observed performance are mainly due to the fact that IoT\nsystem traffic patterns are both sequential and diverse, leaving a rich set of\ntemporal patterns for the models to learn. Experimental results showed that\nBERT maintained the best performance. It achieved 99.94% accuracy rate\nalongside high precision and recall, F1-score and AUC-ROC score of 99.99% which\ndemonstrates its capabilities through temporal dependency capture. The\nMulti-Head Attention offered promising results by providing good detection\ncapabilities with interpretable results. On the other side, the Multi-Head\nAttention model required significant processing time like BI-LSTM variants. The\nGraphSAGE model achieved good accuracy while requiring the shortest training\ntime but yielded the lowest accuracy, precision, and F1 score compared to the\nother models", "AI": {"tldr": "\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u68c0\u6d4b\u7269\u8054\u7f51\u6076\u610f\u653b\u51fb\uff0c\u5e76\u5bf9\u6df1\u5ea6\u5b66\u4e60\u548c\u57fa\u4e8e\u56fe\u7684\u6a21\u578b\u5728\u6076\u610f\u7f51\u7edc\u6d41\u91cf\u68c0\u6d4b\u65b9\u9762\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cBERT\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u8fbe\u523099.94%\uff0c\u800c\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u63d0\u4f9b\u4e86\u53ef\u89e3\u91ca\u7684\u7ed3\u679c\u4f46\u9700\u8981\u5927\u91cf\u5904\u7406\u65f6\u95f4\uff0cGraphSAGE\u6a21\u578b\u8bad\u7ec3\u65f6\u95f4\u6700\u77ed\u4f46\u51c6\u786e\u7387\u6700\u4f4e\u3002", "motivation": "\u7269\u8054\u7f51\u7cfb\u7edf\u4e2d\u7684\u6d41\u91cf\u6a21\u5f0f\u65e2\u6709\u5e8f\u5217\u6027\u53c8\u591a\u6837\u5316\uff0c\u8fd9\u4e3a\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u65f6\u5e8f\u6a21\u5f0f\u8fdb\u884c\u5b66\u4e60\uff0c\u4ece\u800c\u80fd\u591f\u66f4\u6709\u6548\u5730\u68c0\u6d4b\u6076\u610f\u653b\u51fb\u3002", "method": "\u4f7f\u7528\u4e86\u57fa\u4e8eGraphSAGE\u3001BERT\u3001TCN\u4ee5\u53ca\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u3001\u53cc\u5411\u957f\u77ed\u671f\u8bb0\u5fc6\uff08BI-LSTM\uff09\u7b49\u6a21\u578b\u6765\u5efa\u6a21\u65f6\u95f4\u6a21\u5f0f\u5e76\u68c0\u6d4b\u7279\u5f81\u91cd\u8981\u6027\u3002", "result": "BERT\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u4e3a99.94%\uff0c\u5177\u6709\u9ad8\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\uff0cF1-score\u548cAUC-ROC\u5206\u6570\u4e3a99.99%\uff1b\u591a\u5934\u6ce8\u610f\u529b\u673a\u5236\u63d0\u4f9b\u4e86\u6709\u524d\u9014\u7684\u7ed3\u679c\uff0c\u4f46\u9700\u8981\u5927\u91cf\u7684\u5904\u7406\u65f6\u95f4\uff1bGraphSAGE\u6a21\u578b\u867d\u7136\u8bad\u7ec3\u65f6\u95f4\u6700\u77ed\uff0c\u4f46\u51c6\u786e\u7387\u6700\u4f4e\u3002", "conclusion": "\u4e0d\u540c\u7c7b\u578b\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u68c0\u6d4b\u7269\u8054\u7f51\u6076\u610f\u653b\u51fb\u65b9\u9762\u5404\u6709\u4f18\u52a3\uff0c\u5176\u4e2dBERT\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u8868\u73b0\u6700\u4f18\uff0c\u800cGraphSAGE\u6a21\u578b\u5219\u5728\u6548\u7387\u4e0a\u6709\u6240\u4f18\u52bf\u3002"}}
{"id": "2507.10594", "pdf": "https://arxiv.org/pdf/2507.10594", "abs": "https://arxiv.org/abs/2507.10594", "authors": ["Shengda Zhuo", "Di Wu", "Yi He", "Shuqiang Huang", "Xindong Wu"], "title": "Extension OL-MDISF: Online Learning from Mix-Typed, Drifted, and Incomplete Streaming Features", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Online learning, where feature spaces can change over time, offers a flexible\nlearning paradigm that has attracted considerable attention. However, it still\nfaces three significant challenges. First, the heterogeneity of real-world data\nstreams with mixed feature types presents challenges for traditional parametric\nmodeling. Second, data stream distributions can shift over time, causing an\nabrupt and substantial decline in model performance. Third, it is often\ninfeasible to label every data instance due to time and cost constraints. To\naddress these issues, we proposed OL-MDISF (Online Learning from Mix-typed,\nDrifted, and Incomplete Streaming Features), which constructs a latent\ncopula-based representation for heterogeneous features, detects drifts via\nensemble entropy and latent mismatch, and performs structure-aware\npseudo-labeling.\n  This companion paper serves as a standalone technical reference to OL-MDISF.\nIt provides a contextual discussion of related work in mixed-type modeling,\ndrift adaptation, and weak supervision, as well as a comprehensive set of\nexperiments across 14 real-world datasets under two types of drift scenarios.\nThese include CER trends, ablation studies, sensitivity analyses, and temporal\nensemble dynamics. We hope this document offers a reproducible benchmark for\nonline learning on complex, weakly supervised streaming data.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86OL-MDISF\uff0c\u4e00\u79cd\u7528\u4e8e\u5904\u7406\u6df7\u5408\u7c7b\u578b\u3001\u6f02\u79fb\u548c\u4e0d\u5b8c\u6574\u6d41\u6570\u636e\u7684\u5728\u7ebf\u5b66\u4e60\u65b9\u6cd5\u3002\u5b83\u901a\u8fc7\u6784\u5efa\u6f5c\u5728\u7684copula-based\u8868\u793a\uff0c\u5229\u7528\u96c6\u6210\u71b5\u548c\u6f5c\u5728\u4e0d\u5339\u914d\u68c0\u6d4b\u6f02\u79fb\uff0c\u5e76\u8fdb\u884c\u7ed3\u6784\u611f\u77e5\u7684\u4f2a\u6807\u8bb0\u3002", "motivation": "\u5728\u7ebf\u5b66\u4e60\u9762\u5bf9\u4e09\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u6d41\u7684\u5f02\u8d28\u6027\u5bf9\u4f20\u7edf\u53c2\u6570\u6a21\u578b\u63d0\u51fa\u7684\u6311\u6218\uff1b\u6570\u636e\u6d41\u5206\u5e03\u968f\u65f6\u95f4\u53d8\u5316\u5bfc\u81f4\u6a21\u578b\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff1b\u7531\u4e8e\u65f6\u95f4\u548c\u6210\u672c\u9650\u5236\u65e0\u6cd5\u6807\u6ce8\u6240\u6709\u6570\u636e\u5b9e\u4f8b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aOL-MDISF\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e3a\u5f02\u6784\u7279\u5f81\u6784\u5efa\u4e86\u6f5c\u5728\u7684copula-based\u8868\u793a\uff0c\u901a\u8fc7\u96c6\u6210\u71b5\u548c\u6f5c\u5728\u4e0d\u5339\u914d\u68c0\u6d4b\u6f02\u79fb\uff0c\u5e76\u6267\u884c\u7ed3\u6784\u611f\u77e5\u7684\u4f2a\u6807\u8bb0\u3002", "result": "\u5b9e\u9a8c\u572814\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\uff0c\u5305\u62ecCER\u8d8b\u52bf\uff0c\u6d88\u878d\u7814\u7a76\uff0c\u654f\u611f\u6027\u5206\u6790\u548c\u65f6\u95f4\u96c6\u6210\u52a8\u6001\u7b49\u65b9\u9762\uff0c\u63d0\u4f9b\u4e86\u590d\u6742\uff0c\u5f31\u76d1\u7763\u6d41\u6570\u636e\u5728\u7ebf\u5b66\u4e60\u7684\u53ef\u91cd\u590d\u57fa\u51c6\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u72ec\u7acb\u7684\u6280\u672f\u53c2\u8003\u6587\u732e\uff0c\u8ba8\u8bba\u4e86\u76f8\u5173\u5de5\u4f5c\uff0c\u5e76\u5e0c\u671b\u63d0\u4f9b\u7684\u6587\u6863\u80fd\u4f5c\u4e3a\u590d\u6742\u3001\u5f31\u76d1\u7763\u6d41\u6570\u636e\u5728\u7ebf\u5b66\u4e60\u7684\u53ef\u91cd\u590d\u57fa\u51c6\u3002"}}
{"id": "2507.10627", "pdf": "https://arxiv.org/pdf/2507.10627", "abs": "https://arxiv.org/abs/2507.10627", "authors": ["Xiaojian Zhang", "Junqing Wang", "Kerui Chen", "Peiyuan Zhao", "Huiyuan Bai"], "title": "Crypto-Assisted Graph Degree Sequence Release under Local Differential Privacy", "categories": ["cs.CR", "cs.DB"], "comment": null, "summary": "Given a graph $G$ defined in a domain $\\mathcal{G}$, we investigate locally\ndifferentially private mechanisms to release a degree sequence on $\\mathcal{G}$\nthat accurately approximates the actual degree distribution. Existing solutions\nfor this problem mostly use graph projection techniques based on edge deletion\nprocess, using a threshold parameter $\\theta$ to bound node degrees. However,\nthis approach presents a fundamental trade-off in threshold parameter\nselection. While large $\\theta$ values introduce substantial noise in the\nreleased degree sequence, small $\\theta$ values result in more edges removed\nthan necessary. Furthermore, $\\theta$ selection leads to an excessive\ncommunication cost. To remedy existing solutions' deficiencies, we present\nCADR-LDP, an efficient framework incorporating encryption techniques and\ndifferentially private mechanisms to release the degree sequence. In CADR-LDP,\nwe first use the crypto-assisted Optimal-$\\theta$-Selection method to select\nthe optimal parameter with a low communication cost. Then, we use the LPEA-LOW\nmethod to add some edges for each node with the edge addition process in local\nprojection. LPEA-LOW prioritizes the projection with low-degree nodes, which\ncan retain more edges for such nodes and reduce the projection error.\nTheoretical analysis shows that CADR-LDP satisfies $\\epsilon$-node local\ndifferential privacy. The experimental results on eight graph datasets show\nthat our solution outperforms existing methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6CADR-LDP\uff0c\u7528\u4e8e\u53d1\u5e03\u51c6\u786e\u8fd1\u4f3c\u5b9e\u9645\u5ea6\u6570\u5206\u5e03\u7684\u5ea6\u6570\u5e8f\u5217\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u52a0\u5bc6\u6280\u672f\u548c\u5dee\u5206\u9690\u79c1\u673a\u5236\uff0c\u901a\u8fc7\u4f18\u5316\u03b8\u9009\u62e9\u548c\u5c40\u90e8\u6295\u5f71\u8fb9\u7f18\u6dfb\u52a0\u65b9\u6cd5\u6765\u63d0\u9ad8\u6548\u7387\u5e76\u51cf\u5c11\u901a\u4fe1\u6210\u672c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCADR-LDP\u5728\u516b\u4e2a\u56fe\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u4e3b\u8981\u4f7f\u7528\u57fa\u4e8e\u8fb9\u5220\u9664\u8fc7\u7a0b\u7684\u56fe\u6295\u5f71\u6280\u672f\uff0c\u8fd9\u5bfc\u81f4\u4e86\u5728\u9009\u62e9\u9608\u503c\u53c2\u6570\u03b8\u65f6\u5b58\u5728\u57fa\u672c\u7684\u6743\u8861\u95ee\u9898\uff1a\u5927\u03b8\u503c\u5f15\u5165\u5927\u91cf\u566a\u97f3\uff0c\u5c0f\u03b8\u503c\u79fb\u9664\u8fc7\u591a\u7684\u8fb9\uff0c\u5e76\u4e14\u03b8\u7684\u9009\u62e9\u5bfc\u81f4\u8fc7\u9ad8\u7684\u901a\u4fe1\u6210\u672c\u3002", "method": "CADR-LDP\u6846\u67b6\u9996\u5148\u4f7f\u7528\u52a0\u5bc6\u8f85\u52a9\u7684Optimal-\u03b8-Selection\u65b9\u6cd5\u4ee5\u4f4e\u6210\u672c\u9009\u62e9\u6700\u4f18\u53c2\u6570\uff0c\u7136\u540e\u91c7\u7528LPEA-LOW\u65b9\u6cd5\u5bf9\u4f4e\u5ea6\u8282\u70b9\u4f18\u5148\u8fdb\u884c\u6295\u5f71\uff0c\u4ece\u800c\u4fdd\u7559\u66f4\u591a\u8fb9\u5e76\u51cf\u5c11\u6295\u5f71\u8bef\u5dee\u3002", "result": "\u7406\u8bba\u5206\u6790\u8bc1\u660eCADR-LDP\u6ee1\u8db3\u03b5-\u8282\u70b9\u672c\u5730\u5dee\u5206\u9690\u79c1\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u516b\u4e2a\u56fe\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u89e3\u51b3\u65b9\u6848\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "CADR-LDP\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u03b8\u9009\u62e9\u548c\u6539\u8fdb\u5c40\u90e8\u6295\u5f71\u65b9\u6cd5\uff0c\u51cf\u5c11\u4e86\u901a\u4fe1\u6210\u672c\uff0c\u63d0\u9ad8\u4e86\u53d1\u5e03\u7684\u5ea6\u6570\u5e8f\u5217\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2507.10761", "pdf": "https://arxiv.org/pdf/2507.10761", "abs": "https://arxiv.org/abs/2507.10761", "authors": ["Tyler King", "Nikolos Gurney", "John H. Miller", "Volkan Ustun"], "title": "Detecting AI Assistance in Abstract Complex Tasks", "categories": ["cs.AI", "cs.HC"], "comment": "Accepted to HCII 2025", "summary": "Detecting assistance from artificial intelligence is increasingly important\nas they become ubiquitous across complex tasks such as text generation, medical\ndiagnosis, and autonomous driving. Aid detection is challenging for humans,\nespecially when looking at abstract task data. Artificial neural networks excel\nat classification thanks to their ability to quickly learn from and process\nlarge amounts of data -- assuming appropriate preprocessing. We posit detecting\nhelp from AI as a classification task for such models. Much of the research in\nthis space examines the classification of complex but concrete data classes,\nsuch as images. Many AI assistance detection scenarios, however, result in data\nthat is not machine learning-friendly. We demonstrate that common models can\neffectively classify such data when it is appropriately preprocessed. To do so,\nwe construct four distinct neural network-friendly image formulations along\nwith an additional time-series formulation that explicitly encodes the\nexploration/exploitation of users, which allows for generalizability to other\nabstract tasks. We benchmark the quality of each image formulation across three\nclassical deep learning architectures, along with a parallel CNN-RNN\narchitecture that leverages the additional time series to maximize testing\nperformance, showcasing the importance of encoding temporal and spatial\nquantities for detecting AI aid in abstract tasks.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06AI\u8f85\u52a9\u68c0\u6d4b\u89c6\u4e3a\u5206\u7c7b\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u9002\u5f53\u9884\u5904\u7406\uff0c\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u5bf9\u62bd\u8c61\u4efb\u52a1\u6570\u636e\u8fdb\u884c\u6709\u6548\u5206\u7c7b\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5982\u6587\u672c\u751f\u6210\u3001\u533b\u7597\u8bca\u65ad\u548c\u81ea\u52a8\u9a7e\u9a76\uff0c\u68c0\u6d4b\u6765\u81eaAI\u7684\u8f85\u52a9\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u4eba\u7c7b\u6765\u8bf4\uff0c\u5c24\u5176\u662f\u5728\u67e5\u770b\u62bd\u8c61\u4efb\u52a1\u6570\u636e\u65f6\uff0c\u8f85\u52a9\u68c0\u6d4b\u5177\u6709\u6311\u6218\u6027\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7814\u7a76\u4eba\u5458\u6784\u5efa\u4e86\u56db\u79cd\u4e0d\u540c\u7684\u795e\u7ecf\u7f51\u7edc\u53cb\u597d\u578b\u56fe\u50cf\u516c\u5f0f\u4ee5\u53ca\u989d\u5916\u7684\u65f6\u95f4\u5e8f\u5217\u516c\u5f0f\uff0c\u4ee5\u660e\u786e\u7f16\u7801\u7528\u6237\u7684\u63a2\u7d22/\u5f00\u53d1\u60c5\u51b5\u3002\u7136\u540e\u5728\u4e09\u4e2a\u7ecf\u5178\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u4ee5\u53ca\u4e00\u4e2a\u5e76\u884cCNN-RNN\u67b6\u6784\u4e0a\u5bf9\u6bcf\u4e2a\u56fe\u50cf\u516c\u5f0f\u7684\u8d28\u91cf\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5f53\u6570\u636e\u7ecf\u8fc7\u9002\u5f53\u7684\u9884\u5904\u7406\u540e\uff0c\u5e38\u89c1\u7684\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u5bf9\u6b64\u7c7b\u6570\u636e\u8fdb\u884c\u5206\u7c7b\u3002\u6b64\u5916\uff0c\u7f16\u7801\u65f6\u95f4\u548c\u7a7a\u95f4\u91cf\u5bf9\u4e8e\u5728\u62bd\u8c61\u4efb\u52a1\u4e2d\u68c0\u6d4bAI\u8f85\u52a9\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u4e0d\u540c\u6570\u636e\u8868\u793a\u65b9\u6cd5\u7684\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u9002\u5f53\u7684\u6570\u636e\u9884\u5904\u7406\u548c\u9009\u62e9\u5408\u9002\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u80fd\u591f\u63d0\u9ad8AI\u8f85\u52a9\u68c0\u6d4b\u7684\u6548\u679c\u3002\u8fd9\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2507.10595", "pdf": "https://arxiv.org/pdf/2507.10595", "abs": "https://arxiv.org/abs/2507.10595", "authors": ["Yaowen Hu", "Wenxuan Tu", "Yue Liu", "Miaomiao Li", "Wenpeng Lu", "Zhigang Luo", "Xinwang Liu", "Ping Chen"], "title": "Divide-Then-Rule: A Cluster-Driven Hierarchical Interpolator for Attribute-Missing Graphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Deep graph clustering (DGC) for attribute-missing graphs is an unsupervised\ntask aimed at partitioning nodes with incomplete attributes into distinct\nclusters. Addressing this challenging issue is vital for practical\napplications. However, research in this area remains underexplored. Existing\nimputation methods for attribute-missing graphs often fail to account for the\nvarying amounts of information available across node neighborhoods, leading to\nunreliable results, especially for nodes with insufficient known neighborhood.\nTo address this issue, we propose a novel method named Divide-Then-Rule Graph\nCompletion (DTRGC). This method first addresses nodes with sufficient known\nneighborhood information and treats the imputed results as new knowledge to\niteratively impute more challenging nodes, while leveraging clustering\ninformation to correct imputation errors. Specifically, Dynamic Cluster-Aware\nFeature Propagation (DCFP) initializes missing node attributes by adjusting\npropagation weights based on the clustering structure. Subsequently,\nHierarchical Neighborhood-aware Imputation (HNAI) categorizes attribute-missing\nnodes into three groups based on the completeness of their neighborhood\nattributes. The imputation is performed hierarchically, prioritizing the groups\nwith nodes that have the most available neighborhood information. The cluster\nstructure is then used to refine the imputation and correct potential errors.\nFinally, Hop-wise Representation Enhancement (HRE) integrates information\nacross multiple hops, thereby enriching the expressiveness of node\nrepresentations. Experimental results on six widely used graph datasets show\nthat DTRGC significantly improves the clustering performance of various DGC\nmethods under attribute-missing graphs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5DTRGC\uff0c\u7528\u4e8e\u5904\u7406\u5c5e\u6027\u7f3a\u5931\u56fe\u7684\u6df1\u5ea6\u56fe\u805a\u7c7b\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u805a\u7c7b\u611f\u77e5\u7279\u5f81\u4f20\u64ad\u3001\u5c42\u6b21\u5316\u90bb\u57df\u611f\u77e5\u63d2\u8865\u548c\u8df3\u8dc3\u5f0f\u8868\u793a\u589e\u5f3a\u6765\u63d0\u9ad8\u805a\u7c7b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5c5e\u6027\u7f3a\u5931\u56fe\u7684\u586b\u8865\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u8003\u8651\u8282\u70b9\u90bb\u57df\u4fe1\u606f\u91cf\u7684\u53d8\u5316\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u53ef\u9760\uff0c\u7279\u522b\u662f\u5728\u8282\u70b9\u5df2\u77e5\u90bb\u57df\u4fe1\u606f\u4e0d\u8db3\u7684\u60c5\u51b5\u4e0b\u3002", "method": "DTRGC\u65b9\u6cd5\u9996\u5148\u5bf9\u5177\u6709\u8db3\u591f\u5df2\u77e5\u90bb\u57df\u4fe1\u606f\u7684\u8282\u70b9\u8fdb\u884c\u5904\u7406\uff0c\u5e76\u5c06\u586b\u8865\u7ed3\u679c\u4f5c\u4e3a\u65b0\u77e5\u8bc6\u8fed\u4ee3\u5730\u586b\u8865\u66f4\u590d\u6742\u7684\u8282\u70b9\uff0c\u540c\u65f6\u5229\u7528\u805a\u7c7b\u4fe1\u606f\u6821\u6b63\u586b\u8865\u9519\u8bef\u3002\u5177\u4f53\u6b65\u9aa4\u5305\u62ec\uff1a1) \u52a8\u6001\u805a\u7c7b\u611f\u77e5\u7279\u5f81\u4f20\u64ad\uff08DCFP\uff09\u521d\u59cb\u5316\u7f3a\u5931\u8282\u70b9\u5c5e\u6027\uff1b2) \u5c42\u6b21\u5316\u90bb\u57df\u611f\u77e5\u63d2\u8865\uff08HNAI\uff09\u6839\u636e\u90bb\u57df\u5c5e\u6027\u5b8c\u6574\u6027\u5206\u7ec4\u5e76\u4f18\u5148\u5904\u7406\u4fe1\u606f\u6700\u4e30\u5bcc\u7684\u8282\u70b9\uff1b3) \u8df3\u8dc3\u5f0f\u8868\u793a\u589e\u5f3a\uff08HRE\uff09\u6574\u5408\u591a\u8df3\u4fe1\u606f\u4ee5\u4e30\u5bcc\u8282\u70b9\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cDTRGC\u5728\u516d\u4e2a\u5e38\u7528\u7684\u56fe\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u5404\u79cd\u6df1\u5ea6\u56fe\u805a\u7c7b\u65b9\u6cd5\u5728\u5c5e\u6027\u7f3a\u5931\u56fe\u4e0a\u7684\u805a\u7c7b\u6027\u80fd\u3002", "conclusion": "DTRGC\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5e94\u5bf9\u5c5e\u6027\u7f3a\u5931\u56fe\u7684\u6df1\u5ea6\u56fe\u805a\u7c7b\u6311\u6218\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u90a3\u4e9b\u90bb\u57df\u4fe1\u606f\u4e0d\u5b8c\u6574\u7684\u8282\u70b9\u3002"}}
{"id": "2507.10730", "pdf": "https://arxiv.org/pdf/2507.10730", "abs": "https://arxiv.org/abs/2507.10730", "authors": ["Yin Li", "Sharad Mehrota", "Shantanu Sharma", "Komal Kumari"], "title": "Access Control for Information-Theoretically Secure Key-Document Stores", "categories": ["cs.CR", "cs.DB", "cs.DC", "cs.DS", "cs.IR"], "comment": "An extended abstract of this version has been accepted in VLDB 2025", "summary": "This paper presents a novel key-based access control technique for secure\noutsourcing key-value stores where values correspond to documents that are\nindexed and accessed using keys. The proposed approach adopts Shamir's\nsecret-sharing that offers unconditional or information-theoretic security. It\nsupports keyword-based document retrieval while preventing leakage of the data,\naccess rights of users, or the size (\\textit{i}.\\textit{e}., volume of the\noutput that satisfies a query). The proposed approach allows servers to detect\n(and abort) malicious clients from gaining unauthorized access to data, and\nprevents malicious servers from altering data undetected while ensuring\nefficient access -- it takes 231.5ms over 5,000 keywords across 500,000 files.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u5bc6\u94a5\u7684\u8bbf\u95ee\u63a7\u5236\u6280\u672f\uff0c\u9002\u7528\u4e8e\u5b89\u5168\u5916\u5305\u952e\u503c\u5b58\u50a8\u3002\u5b83\u91c7\u7528Shamir\u7684\u79d8\u5bc6\u5206\u4eab\u65b9\u6cd5\uff0c\u63d0\u4f9b\u65e0\u6761\u4ef6\u7684\u5b89\u5168\u6027\uff0c\u652f\u6301\u5173\u952e\u8bcd\u6587\u6863\u68c0\u7d22\uff0c\u5e76\u9632\u6b62\u6570\u636e\u3001\u7528\u6237\u8bbf\u95ee\u6743\u9650\u6216\u67e5\u8be2\u7ed3\u679c\u5927\u5c0f\u7684\u6cc4\u9732\u3002\u8be5\u65b9\u6cd5\u8fd8\u5141\u8bb8\u670d\u52a1\u5668\u68c0\u6d4b\u5e76\u963b\u6b62\u6076\u610f\u5ba2\u6237\u7aef\u672a\u7ecf\u6388\u6743\u7684\u6570\u636e\u8bbf\u95ee\uff0c\u9632\u6b62\u6076\u610f\u670d\u52a1\u5668\u672a\u88ab\u5bdf\u89c9\u7684\u6570\u636e\u7be1\u6539\uff0c\u540c\u65f6\u786e\u4fdd\u9ad8\u6548\u7684\u8bbf\u95ee\u901f\u5ea6\u3002", "motivation": "\u968f\u7740\u4e91\u8ba1\u7b97\u548c\u5927\u6570\u636e\u7684\u53d1\u5c55\uff0c\u6570\u636e\u5b58\u50a8\u548c\u8bbf\u95ee\u63a7\u5236\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002\u4f20\u7edf\u7684\u8bbf\u95ee\u63a7\u5236\u65b9\u6cd5\u5728\u9762\u5bf9\u5916\u5305\u952e\u503c\u5b58\u50a8\u65f6\uff0c\u65e0\u6cd5\u6709\u6548\u4fdd\u62a4\u6570\u636e\u9690\u79c1\u548c\u5b89\u5168\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u8bbf\u95ee\u63a7\u5236\u6280\u672f\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u91c7\u7528\u4e86Shamir\u7684\u79d8\u5bc6\u5206\u4eab\u7b97\u6cd5\uff0c\u901a\u8fc7\u5c06\u5bc6\u94a5\u5206\u6210\u591a\u4e2a\u90e8\u5206\uff0c\u53ea\u6709\u5f53\u8db3\u591f\u7684\u90e8\u5206\u88ab\u7ec4\u5408\u8d77\u6765\u65f6\uff0c\u624d\u80fd\u6062\u590d\u539f\u59cb\u5bc6\u94a5\u3002\u8fd9\u786e\u4fdd\u4e86\u5373\u4f7f\u90e8\u5206\u4fe1\u606f\u6cc4\u9732\uff0c\u4e5f\u65e0\u6cd5\u83b7\u5f97\u5b8c\u6574\u7684\u5bc6\u94a5\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u5957\u673a\u5236\u6765\u68c0\u6d4b\u548c\u963b\u6b62\u6076\u610f\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u572850\u4e07\u4e2a\u6587\u4ef6\u4e2d\u5bf95,000\u4e2a\u5173\u952e\u8bcd\u8fdb\u884c\u9ad8\u6548\u68c0\u7d22\uff0c\u5e73\u5747\u8017\u65f6231.5\u6beb\u79d2\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5b83\u6210\u529f\u5730\u9632\u6b62\u4e86\u6570\u636e\u6cc4\u9732\u548c\u672a\u7ecf\u6388\u6743\u7684\u8bbf\u95ee\uff0c\u4fdd\u8bc1\u4e86\u6570\u636e\u7684\u5b89\u5168\u6027\u548c\u5b8c\u6574\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u5bc6\u94a5\u7684\u8bbf\u95ee\u63a7\u5236\u6280\u672f\u4e3a\u5b89\u5168\u5916\u5305\u952e\u503c\u5b58\u50a8\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5b83\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5b89\u5168\u6027\uff0c\u800c\u4e14\u4fdd\u6301\u4e86\u8f83\u9ad8\u7684\u8bbf\u95ee\u6548\u7387\u3002"}}
{"id": "2507.10798", "pdf": "https://arxiv.org/pdf/2507.10798", "abs": "https://arxiv.org/abs/2507.10798", "authors": ["Asim H. Gazi", "Bhanu T. Gullapalli", "Daiqi Gao", "Benjamin M. Marlin", "Vivek Shetty", "Susan A. Murphy"], "title": "Uncertainty-Informed Scheduling of Decision Points for Intelligent Mobile Health Interventions", "categories": ["cs.AI"], "comment": "4 pages, 3 figures", "summary": "Timely decision making is critical to the effectiveness of mobile health\n(mHealth) interventions. At predefined timepoints called \"decision points,\"\nintelligent mHealth systems such as just-in-time adaptive interventions\n(JITAIs) estimate an individual's biobehavioral context from sensor or survey\ndata and determine whether and how to intervene. For interventions targeting\nhabitual behavior (e.g., oral hygiene), effectiveness often hinges on\ndelivering support shortly before the target behavior is likely to occur.\nCurrent practice schedules decision points at a fixed interval (e.g., one hour)\nbefore user-provided behavior times, and the fixed interval is kept the same\nfor all individuals. However, this one-size-fits-all approach performs poorly\nfor individuals with irregular routines, often scheduling decision points after\nthe target behavior has already occurred, rendering interventions ineffective.\nIn this paper, we propose SigmaScheduling, a method to dynamically schedule\ndecision points based on uncertainty in predicted behavior times. When behavior\ntiming is more predictable, SigmaScheduling schedules decision points closer to\nthe predicted behavior time; when timing is less certain, SigmaScheduling\nschedules decision points earlier, increasing the likelihood of timely\nintervention. We evaluated SigmaScheduling using real-world data from 68\nparticipants in a 10-week trial of Oralytics, a JITAI designed to improve daily\ntoothbrushing. SigmaScheduling increased the likelihood that decision points\npreceded brushing events in at least 70% of cases, preserving opportunities to\nintervene and impact behavior. Our results indicate that SigmaScheduling can\nadvance precision mHealth, particularly for JITAIs targeting time-sensitive,\nhabitual behaviors such as oral hygiene or dietary habits.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53eb\u505aSigmaScheduling\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6839\u636e\u9884\u6d4b\u884c\u4e3a\u65f6\u95f4\u7684\u4e0d\u786e\u5b9a\u6027\u52a8\u6001\u5b89\u6392\u51b3\u7b56\u70b9\uff0c\u63d0\u9ad8\u5e72\u9884\u6548\u679c\u3002", "motivation": "\u76ee\u524d\u7684\u505a\u6cd5\u662f\u4e3a\u6240\u6709\u4e2a\u4f53\u8bbe\u5b9a\u56fa\u5b9a\u7684\u65f6\u95f4\u95f4\u9694\u6765\u5b89\u6392\u51b3\u7b56\u70b9\uff0c\u8fd9\u5728\u5904\u7406\u5177\u6709\u4e0d\u89c4\u5219\u65e5\u5e38\u4e8b\u52a1\u7684\u4e2a\u4f53\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u53ef\u80fd\u4f1a\u5728\u76ee\u6807\u884c\u4e3a\u5df2\u7ecf\u53d1\u751f\u540e\u624d\u5b89\u6392\u51b3\u7b56\u70b9\uff0c\u4f7f\u5e72\u9884\u65e0\u6548\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u7684SigmaScheduling\u65b9\u6cd5\u6839\u636e\u9884\u6d4b\u884c\u4e3a\u65f6\u95f4\u7684\u4e0d\u786e\u5b9a\u6027\u52a8\u6001\u5b89\u6392\u51b3\u7b56\u70b9\u3002\u5f53\u884c\u4e3a\u65f6\u95f4\u66f4\u53ef\u9884\u6d4b\u65f6\uff0c\u5c06\u51b3\u7b56\u70b9\u5b89\u6392\u5f97\u66f4\u63a5\u8fd1\u9884\u6d4b\u7684\u884c\u4e3a\u65f6\u95f4\uff1b\u5f53\u65f6\u95f4\u4e0d\u592a\u786e\u5b9a\u65f6\uff0c\u63d0\u524d\u5b89\u6392\u51b3\u7b56\u70b9\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u6765\u81ea68\u540d\u53c2\u4e0e\u8005\u7684\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\uff0cSigmaScheduling\u4f7f\u5f97\u81f3\u5c1170%\u7684\u60c5\u51b5\u4e0b\u7684\u51b3\u7b56\u70b9\u51fa\u73b0\u5728\u5237\u7259\u4e8b\u4ef6\u4e4b\u524d\uff0c\u4fdd\u6301\u4e86\u5e72\u9884\u548c\u5f71\u54cd\u884c\u4e3a\u7684\u673a\u4f1a\u3002", "conclusion": "SigmaScheduling\u53ef\u4ee5\u63a8\u8fdb\u7cbe\u51c6mHealth\u7684\u53d1\u5c55\uff0c\u7279\u522b\u662f\u9488\u5bf9\u50cf\u53e3\u8154\u536b\u751f\u6216\u996e\u98df\u4e60\u60ef\u8fd9\u6837\u7684\u65f6\u95f4\u654f\u611f\u3001\u4e60\u60ef\u6027\u884c\u4e3a\u7684JITAIs\u3002"}}
{"id": "2507.10605", "pdf": "https://arxiv.org/pdf/2507.10605", "abs": "https://arxiv.org/abs/2507.10605", "authors": ["Fei Zhao", "Chonggang Lu", "Yue Wang", "Zheyong Xie", "Ziyan Liu", "Haofu Qian", "JianZhao Huang", "Fangcheng Shi", "Zijie Meng", "Hongcheng Guo", "Mingqian He", "Xinze Lyu", "Yiming Lu", "Ziyang Xiang", "Zheyu Ye", "Chengqiang Lu", "Zhe Xu", "Yi Wu", "Yao Hu", "Yan Gao", "Jun Fan", "Xiaolong Jiang", "Weiting Liu", "Boyang Wang", "Shaosheng Cao"], "title": "RedOne: Revealing Domain-specific LLM Post-Training in Social Networking Services", "categories": ["cs.LG", "cs.AI", "cs.SI"], "comment": null, "summary": "As a primary medium for modern information dissemination, social networking\nservices (SNS) have experienced rapid growth, which has proposed significant\nchallenges for platform content management and interaction quality improvement.\nRecently, the development of large language models (LLMs) has offered potential\nsolutions but existing studies focus on isolated tasks, which not only\nencounter diminishing benefit from the data scaling within individual scenarios\nbut also fail to flexibly adapt to diverse real-world context. To address these\nchallenges, we introduce RedOne, a domain-specific LLM designed to break the\nperformance bottleneck of single-task baselines and establish a comprehensive\nfoundation for the SNS. RedOne was developed through a three-stage training\nstrategy consisting of continue pretraining, supervised fine-tuning, and\npreference optimization, using a large-scale real-world dataset. Through\nextensive experiments, RedOne maintains strong general capabilities, and\nachieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56%\nin SNS bilingual evaluation benchmark, compared with base models. Furthermore,\nthrough online testing, RedOne reduced the exposure rate in harmful content\ndetection by 11.23% and improved the click page rate in post-view search by\n14.95% compared with single-tasks finetuned baseline models. These results\nestablish RedOne as a robust domain-specific LLM for SNS, demonstrating\nexcellent generalization across various tasks and promising applicability in\nreal-world scenarios.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aRedOne\u7684\u9886\u57df\u7279\u5b9a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u5728\u793e\u4ea4\u7f51\u7edc\u670d\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6027\u80fd\u74f6\u9888\u7684\u7a81\u7834\u548c\u5168\u9762\u7684\u57fa\u7840\u5efa\u7acb\u3002\u5b9e\u9a8c\u8868\u660e\uff0cRedOne\u57288\u4e2a\u4e3b\u8981\u4efb\u52a1\u548cSNS\u53cc\u8bed\u8bc4\u4f30\u57fa\u51c6\u4e0a\u5e73\u5747\u63d0\u5347\u4e8614.02%\u548c7.56%\uff0c\u5e76\u663e\u8457\u6539\u5584\u4e86\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u548c\u5e16\u5b50\u67e5\u770b\u641c\u7d22\u7684\u8868\u73b0\u3002", "motivation": "\u793e\u4ea4\u7f51\u7edc\u670d\u52a1\uff08SNS\uff09\u7684\u5feb\u901f\u589e\u957f\u4e3a\u5e73\u53f0\u5185\u5bb9\u7ba1\u7406\u548c\u4e92\u52a8\u8d28\u91cf\u6539\u8fdb\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\u3002\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u4e13\u6ce8\u4e8e\u5b64\u7acb\u7684\u4efb\u52a1\uff0c\u4e0d\u4ec5\u5728\u4e2a\u522b\u573a\u666f\u4e2d\u7684\u6570\u636e\u6269\u5c55\u4e2d\u9047\u5230\u6548\u76ca\u9012\u51cf\u7684\u95ee\u9898\uff0c\u800c\u4e14\u65e0\u6cd5\u7075\u6d3b\u9002\u5e94\u591a\u6837\u5316\u7684\u73b0\u5b9e\u4e16\u754c\u73af\u5883\u3002", "method": "\u4e3a\u4e86\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff0c\u7814\u7a76\u4eba\u5458\u5f15\u5165\u4e86RedOne\uff0c\u8fd9\u662f\u4e00\u79cd\u4e13\u95e8\u9488\u5bf9\u793e\u4ea4\u7f51\u7edc\u670d\u52a1\u8bbe\u8ba1\u7684\u9886\u57df\u7279\u5b9a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\u8be5\u6a21\u578b\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u548c\u504f\u597d\u4f18\u5316\uff0c\u5e76\u4f7f\u7528\u5927\u89c4\u6a21\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "RedOne\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u901a\u7528\u80fd\u529b\uff0c\u57288\u4e2a\u4e3b\u8981SNS\u4efb\u52a1\u4e0a\u5e73\u5747\u63d0\u9ad8\u4e8614.02%\uff0c\u5728SNS\u53cc\u8bed\u8bc4\u4f30\u57fa\u51c6\u4e0a\u63d0\u9ad8\u4e867.56%\u3002\u5728\u7ebf\u6d4b\u8bd5\u8fd8\u663e\u793a\uff0c\u4e0e\u5355\u4efb\u52a1\u5fae\u8c03\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0cRedOne\u5c06\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u7684\u66dd\u5149\u7387\u964d\u4f4e\u4e8611.23%\uff0c\u5e76\u5c06\u5e16\u5b50\u67e5\u770b\u641c\u7d22\u7684\u70b9\u51fb\u9875\u9762\u7387\u63d0\u9ad8\u4e8614.95%\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u786e\u7acb\u4e86RedOne\u4f5c\u4e3a\u4e00\u79cd\u7a33\u5065\u7684\u9886\u57df\u7279\u5b9a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5730\u4f4d\uff0c\u9002\u7528\u4e8e\u793e\u4ea4\u7f51\u7edc\u670d\u52a1\uff0c\u8868\u73b0\u51fa\u8272\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2507.10733", "pdf": "https://arxiv.org/pdf/2507.10733", "abs": "https://arxiv.org/abs/2507.10733", "authors": ["Jianyao Yin", "Luca Arnaboldi", "Honglong Chen", "Pascal Berrang"], "title": "3S-Attack: Spatial, Spectral and Semantic Invisible Backdoor Attack Against DNN Models", "categories": ["cs.CR"], "comment": "14 pages, 10 figures", "summary": "Backdoor attacks involve either poisoning the training data or directly\nmodifying the model in order to implant a hidden behavior, that causes the\nmodel to misclassify inputs when a specific trigger is present. During\ninference, the model maintains high accuracy on benign samples but\nmisclassifies poisoned samples into an attacker-specified target class.\nExisting research on backdoor attacks has explored developing triggers in the\nspatial, spectral (frequency), and semantic (feature) domains, aiming to make\nthem stealthy. While some approaches have considered designing triggers that\nare imperceptible in both spatial and spectral domains, few have incorporated\nthe semantic domain. In this paper, we propose a novel backdoor attack, termed\n3S-attack, which is stealthy across the spatial, spectral, and semantic\ndomains. The key idea is to exploit the semantic features of benign samples as\ntriggers, using Gradient-weighted Class Activation Mapping (Grad-CAM) and a\npreliminary model for extraction. The trigger is then embedded in the spectral\ndomain, followed by pixel-level restrictions after converting the samples back\nto the spatial domain. This process minimizes the distance between poisoned and\nbenign samples, making the attack harder to detect by existing defenses and\nhuman inspection. Extensive experiments on various datasets, along with\ntheoretical analysis, demonstrate the stealthiness of 3S-attack and highlight\nthe need for stronger defenses to ensure AI security. Our code is available at:\nhttps://anonymous.4open.science/r/anon-project-3776/", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u540e\u95e8\u653b\u51fb\u65b9\u6cd5\uff0c\u79f0\u4e3a3S-attack\uff0c\u5728\u7a7a\u95f4\u3001\u9891\u8c31\u548c\u8bed\u4e49\u9886\u57df\u4e2d\u5747\u5177\u6709\u9690\u853d\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u540e\u95e8\u653b\u51fb\u7814\u7a76\u5df2\u7ecf\u63a2\u7d22\u4e86\u5728\u7a7a\u95f4\u3001\u9891\u8c31\uff08\u9891\u7387\uff09\u548c\u8bed\u4e49\uff08\u7279\u5f81\uff09\u9886\u57df\u5f00\u53d1\u89e6\u53d1\u5668\uff0c\u4f46\u5f88\u5c11\u6709\u7ed3\u5408\u8bed\u4e49\u9886\u57df\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u826f\u6027\u6837\u672c\u7684\u8bed\u4e49\u7279\u5f81\u4f5c\u4e3a\u89e6\u53d1\u5668\uff0c\u4f7f\u7528Grad-CAM\u548c\u521d\u6b65\u6a21\u578b\u8fdb\u884c\u63d0\u53d6\u3002\u7136\u540e\u5c06\u89e6\u53d1\u5668\u5d4c\u5165\u9891\u8c31\u57df\uff0c\u5e76\u5728\u8f6c\u6362\u56de\u7a7a\u95f4\u57df\u540e\u8fdb\u884c\u50cf\u7d20\u7ea7\u9650\u5236\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u548c\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e863S-attack\u7684\u9690\u853d\u6027\uff0c\u5e76\u5f3a\u8c03\u4e86\u9700\u8981\u66f4\u5f3a\u7684\u9632\u5fa1\u63aa\u65bd\u6765\u786e\u4fddAI\u5b89\u5168\u3002", "conclusion": "3S-attack\u5728\u5404\u79cd\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5176\u9690\u853d\u6027\uff0c\u8868\u660e\u9700\u8981\u66f4\u5f3a\u7684\u9632\u5fa1\u4ee5\u786e\u4fddAI\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2507.10803", "pdf": "https://arxiv.org/pdf/2507.10803", "abs": "https://arxiv.org/abs/2507.10803", "authors": ["JaMor Hairston", "Ritvik Ranjan", "Sahithi Lakamana", "Anthony Spadaro", "Selen Bozkurt", "Jeanmarie Perrone", "Abeed Sarker"], "title": "Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case", "categories": ["cs.AI", "cs.CL", "cs.ET", "cs.IR"], "comment": "Pages: 19, Abstract word count: 151 words, Manuscript word count:\n  2185 words, References: 14, Figures: 3, Tables: 2", "summary": "Background Large language models (LLMs) face challenges in inductive thematic\nanalysis, a task requiring deep interpretive and domain-specific expertise. We\nevaluated the feasibility of using LLMs to replicate expert-driven thematic\nanalysis of social media data. Methods Using two temporally non-intersecting\nReddit datasets on xylazine (n=286 and n=686, for model optimization and\nvalidation, respectively) with twelve expert-derived themes, we evaluated five\nLLMs against expert coding. We modeled the task as a series of binary\nclassifications, rather than a single, multi-label classification, employing\nzero-, single-, and few-shot prompting strategies and measuring performance via\naccuracy, precision, recall, and F1-score. Results On the validation set,\nGPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:\n0.71). For high-prevalence themes, model-derived thematic distributions closely\nmirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:\n16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based\napproaches can automate thematic analyses, offering a scalable supplement for\nqualitative research. Keywords: thematic analysis, large language models,\nnatural language processing, qualitative analysis, social media, prompt\nengineering, public health", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u4f7f\u7528\u5c11\u91cf\u793a\u4f8b\u63d0\u793a\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u5982GPT-4\uff0c\u5728\u4e3b\u9898\u5206\u6790\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u63a5\u8fd1\u4e13\u5bb6\u6c34\u5e73\u7684\u6027\u80fd\uff0c\u8fd9\u8868\u660eLLM\u53ef\u4ee5\u4f5c\u4e3a\u81ea\u52a8\u5316\u4e3b\u9898\u5206\u6790\u7684\u6709\u6548\u8865\u5145\u5de5\u5177\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5f52\u7eb3\u4e3b\u9898\u5206\u6790\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u8fd9\u9879\u4efb\u52a1\u9700\u8981\u6df1\u5ea6\u89e3\u91ca\u548c\u9886\u57df\u4e13\u4e1a\u77e5\u8bc6\u3002\u4e3a\u4e86\u8bc4\u4f30LLMs\u662f\u5426\u80fd\u591f\u590d\u5236\u7531\u4e13\u5bb6\u9a71\u52a8\u7684\u4e3b\u9898\u5206\u6790\uff0c\u7279\u522b\u662f\u9488\u5bf9\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u8fdb\u884c\u5206\u6790\u7684\u80fd\u529b\uff0c\u5f00\u5c55\u4e86\u672c\u7814\u7a76\u3002", "method": "\u4f7f\u7528\u4e24\u4e2a\u4e0d\u540c\u65f6\u671f\u7684Reddit\u6570\u636e\u96c6\uff08n=286 \u548c n=686\uff0c\u5206\u522b\u7528\u4e8e\u6a21\u578b\u4f18\u5316\u548c\u9a8c\u8bc1\uff09\uff0c\u5e76\u6839\u636e\u5341\u4e8c\u4e2a\u4e13\u5bb6\u884d\u751f\u7684\u4e3b\u9898\uff0c\u8bc4\u4f30\u4e86\u4e94\u4e2aLLMs\u4e0e\u4e13\u5bb6\u7f16\u7801\u7684\u8868\u73b0\u3002\u5c06\u4efb\u52a1\u5efa\u6a21\u4e3a\u4e00\u7cfb\u5217\u4e8c\u5143\u5206\u7c7b\u95ee\u9898\uff0c\u800c\u4e0d\u662f\u5355\u4e00\u7684\u591a\u6807\u7b7e\u5206\u7c7b\uff0c\u5e76\u901a\u8fc7\u51c6\u786e\u7387\u3001\u7cbe\u786e\u5ea6\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u6765\u8861\u91cf\u6027\u80fd\u3002", "result": "\u5728\u9a8c\u8bc1\u96c6\u4e0a\uff0c\u5e26\u6709\u4e24\u6b21\u793a\u4f8b\u63d0\u793a\u7684GPT-4\u8868\u73b0\u6700\u4f73\uff08\u51c6\u786e\u7387\uff1a90.9%\uff1bF1\u5206\u6570\uff1a0.71\uff09\u3002\u5bf9\u4e8e\u9ad8\u9891\u7387\u4e3b\u9898\uff0c\u6a21\u578b\u5f97\u51fa\u7684\u4e3b\u9898\u5206\u5e03\u4e0e\u4e13\u5bb6\u5206\u7c7b\u975e\u5e38\u63a5\u8fd1\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u5c11\u91cf\u793a\u4f8b\u63d0\u793a\u7684LLM\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u4e3b\u9898\u5206\u6790\u7684\u81ea\u52a8\u5316\uff0c\u4e3a\u5b9a\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u8865\u5145\u5de5\u5177\u3002"}}
{"id": "2507.10606", "pdf": "https://arxiv.org/pdf/2507.10606", "abs": "https://arxiv.org/abs/2507.10606", "authors": ["Bing-Yue Wu", "Vidya A. Chhabria"], "title": "DALI-PD: Diffusion-based Synthetic Layout Heatmap Generation for ML in Physical Design", "categories": ["cs.LG", "cs.AI", "cs.AR"], "comment": "Under review at Asia and South Pacific Design Automation Conference\n  (ASP-DAC'26)", "summary": "Machine learning (ML) has demonstrated significant promise in various\nphysical design (PD) tasks. However, model generalizability remains limited by\nthe availability of high-quality, large-scale training datasets. Creating such\ndatasets is often computationally expensive and constrained by IP. While very\nfew public datasets are available, they are typically static, slow to generate,\nand require frequent updates. To address these limitations, we present DALI-PD,\na scalable framework for generating synthetic layout heatmaps to accelerate ML\nin PD research. DALI-PD uses a diffusion model to generate diverse layout\nheatmaps via fast inference in seconds. The heatmaps include power, IR drop,\ncongestion, macro placement, and cell density maps. Using DALI-PD, we created a\ndataset comprising over 20,000 layout configurations with varying macro counts\nand placements. These heatmaps closely resemble real layouts and improve ML\naccuracy on downstream ML tasks such as IR drop or congestion prediction.", "AI": {"tldr": "\u63d0\u51faDALI-PD\u6846\u67b6\uff0c\u751f\u6210\u5408\u6210\u5e03\u5c40\u70ed\u56fe\u4ee5\u52a0\u901f\u7269\u7406\u8bbe\u8ba1\u4e2d\u7684\u673a\u5668\u5b66\u4e60\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u7684\u9ad8\u8d28\u91cf\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u96c6\u6709\u9650\u4e14\u96be\u4ee5\u521b\u5efa\uff0c\u516c\u5171\u6570\u636e\u96c6\u9759\u6001\u3001\u751f\u6210\u6162\u4e14\u9700\u8981\u9891\u7e41\u66f4\u65b0\u3002", "method": "\u4f7f\u7528\u6269\u6563\u6a21\u578b\u751f\u6210\u5305\u62ec\u529f\u7387\u3001IR\u538b\u964d\u3001\u62e5\u585e\u3001\u5b8f\u653e\u7f6e\u548c\u5355\u5143\u5bc6\u5ea6\u56fe\u5728\u5185\u7684\u591a\u6837\u5316\u7684\u5e03\u5c40\u70ed\u56fe\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b\u8d85\u8fc720,000\u4e2a\u5e03\u5c40\u914d\u7f6e\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u70ed\u56fe\u4e0e\u771f\u5b9e\u5e03\u5c40\u975e\u5e38\u76f8\u4f3c\uff0c\u5e76\u63d0\u9ad8\u4e86\u4e0b\u6e38ML\u4efb\u52a1\u7684\u51c6\u786e\u6027\u3002", "conclusion": "DALI-PD\u6846\u67b6\u53ef\u4ee5\u751f\u6210\u5408\u6210\u5e03\u5c40\u70ed\u56fe\uff0c\u4ece\u800c\u52a0\u901f\u7269\u7406\u8bbe\u8ba1\u4e2d\u7684\u673a\u5668\u5b66\u4e60\u7814\u7a76\u3002"}}
{"id": "2507.10808", "pdf": "https://arxiv.org/pdf/2507.10808", "abs": "https://arxiv.org/abs/2507.10808", "authors": ["Mohammad Alikhani", "Reza Kazemi"], "title": "Contrastive-KAN: A Semi-Supervised Intrusion Detection Framework for Cybersecurity with scarce Labeled Data", "categories": ["cs.CR", "cs.SY", "eess.SP", "eess.SY"], "comment": null, "summary": "In the era of the Fourth Industrial Revolution, cybersecurity and intrusion\ndetection systems are vital for the secure and reliable operation of IoT and\nIIoT environments. A key challenge in this domain is the scarcity of labeled\ncyber-attack data, as most industrial systems operate under normal conditions.\nThis data imbalance, combined with the high cost of annotation, hinders the\neffective training of machine learning models. Moreover, rapid detection of\nattacks is essential, especially in critical infrastructure, to prevent\nlarge-scale disruptions. To address these challenges, we propose a real-time\nintrusion detection system based on a semi-supervised contrastive learning\nframework using the Kolmogorov-Arnold Network (KAN). Our method leverages\nabundant unlabeled data to distinguish between normal and attack behaviors\neffectively. We validate our approach on three benchmark datasets: UNSW-NB15,\nBoT-IoT, and Gas Pipeline, using only 2.20 percent, 1.28 percent, and 8 percent\nof labeled samples, respectively, to simulate real-world conditions.\nExperimental results show that our method outperforms existing contrastive\nlearning-based approaches. We further compare KAN with a traditional multilayer\nperceptron (MLP), demonstrating KAN's superior performance in both detection\naccuracy and robustness under limited supervision. KAN's ability to model\ncomplex relationships and its learnable activation functions are also explored\nand visualized, offering interpretability and potential for rule extraction.\nThe method supports multi-class classification and proves effective in\nsafety-critical environments where reliability is paramount.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eKolmogorov-Arnold\u7f51\u7edc\u7684\u534a\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u7684\u5b9e\u65f6\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff0c\u5229\u7528\u5c11\u91cf\u6807\u8bb0\u6570\u636e\u548c\u5927\u91cf\u672a\u6807\u8bb0\u6570\u636e\u6765\u6709\u6548\u5730\u533a\u5206\u6b63\u5e38\u548c\u653b\u51fb\u884c\u4e3a\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u5de5\u4e1a\u73af\u5883\u4e2d\u6807\u6ce8\u7684\u7f51\u7edc\u653b\u51fb\u6570\u636e\u7a00\u7f3a\uff0c\u4e14\u5927\u591a\u6570\u5de5\u4e1a\u7cfb\u7edf\u901a\u5e38\u5728\u6b63\u5e38\u6761\u4ef6\u4e0b\u8fd0\u884c\uff0c\u5bfc\u81f4\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bad\u7ec3\u56f0\u96be\u3002\u6b64\u5916\uff0c\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u4e2d\u5feb\u901f\u68c0\u6d4b\u653b\u51fb\u4ee5\u9632\u6b62\u5927\u89c4\u6a21\u4e2d\u65ad\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8eKolmogorov-Arnold Network (KAN)\u7684\u534a\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u7684\u5b9e\u65f6\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u5c11\u91cf\u7684\u6807\u6ce8\u6837\u672c\u548c\u5927\u91cf\u7684\u672a\u6807\u6ce8\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ece\u800c\u6709\u6548\u5730\u8bc6\u522b\u51fa\u6b63\u5e38\u884c\u4e3a\u548c\u653b\u51fb\u884c\u4e3a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\uff08UNSW-NB15\u3001BoT-IoT\u548cGas Pipeline\uff09\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u4e14\u4e0e\u4f20\u7edf\u7684\u591a\u5c42\u611f\u77e5\u5668\u76f8\u6bd4\uff0c\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u652f\u6301\u591a\u7c7b\u5206\u7c7b\uff0c\u5728\u5b89\u5168\u5173\u952e\u73af\u5883\u4e2d\u5c55\u793a\u4e86\u9ad8\u6548\u6027\u548c\u53ef\u9760\u6027\uff0c\u5e76\u4e14KAN\u80fd\u591f\u5bf9\u590d\u6742\u5173\u7cfb\u5efa\u6a21\u5e76\u63d0\u4f9b\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.10831", "pdf": "https://arxiv.org/pdf/2507.10831", "abs": "https://arxiv.org/abs/2507.10831", "authors": ["Yilin Xia", "Heng Zheng", "Shawn Bowers", "Bertram Lud\u00e4scher"], "title": "AF-XRAY: Visual Explanation and Resolution of Ambiguity in Legal Argumentation Frameworks", "categories": ["cs.AI"], "comment": "International Conference on Artificial Intelligence and Law (ICAIL),\n  June 16-20, 2025. Chicago, IL, USA", "summary": "Argumentation frameworks (AFs) provide formal approaches for legal reasoning,\nbut identifying sources of ambiguity and explaining argument acceptance remains\nchallenging for non-experts. We present AF-XRAY, an open-source toolkit for\nexploring, analyzing, and visualizing abstract AFs in legal reasoning. AF-XRAY\nintroduces: (i) layered visualizations based on game-theoretic argument length\nrevealing well-founded derivation structures; (ii) classification of attack\nedges by semantic roles (primary, secondary, blunders); (iii) overlay\nvisualizations of alternative 2-valued solutions on ambiguous 3-valued grounded\nsemantics; and (iv) identification of critical attack sets whose suspension\nresolves undecided arguments. Through systematic generation of critical attack\nsets, AF-XRAY transforms ambiguous scenarios into grounded solutions, enabling\nusers to pinpoint specific causes of ambiguity and explore alternative\nresolutions. We use real-world legal cases (e.g., Wild Animals as modeled by\nBench-Capon) to show that our tool supports teleological legal reasoning by\nrevealing how different assumptions lead to different justified conclusions.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u6b3e\u540d\u4e3aAF-XRAY\u7684\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u5b83\u901a\u8fc7\u591a\u79cd\u65b9\u5f0f\u89e3\u6790\u3001\u5206\u6790\u548c\u53ef\u89c6\u5316\u6cd5\u5f8b\u63a8\u7406\u4e2d\u7684\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\uff08AFs\uff09\uff0c\u5e2e\u52a9\u975e\u4e13\u5bb6\u8bc6\u522b\u6a21\u7cca\u6765\u6e90\u5e76\u89e3\u91ca\u8bba\u8bc1\u63a5\u53d7\u3002", "motivation": "\u76ee\u524d\u5728\u4f7f\u7528\u8bba\u8bc1\u6846\u67b6\uff08AFs\uff09\u8fdb\u884c\u6cd5\u5f8b\u63a8\u7406\u65f6\uff0c\u5bf9\u4e8e\u975e\u4e13\u5bb6\u6765\u8bf4\uff0c\u786e\u5b9a\u6a21\u7cca\u6765\u6e90\u4ee5\u53ca\u89e3\u91ca\u8bba\u8bc1\u63a5\u53d7\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "AF-XRAY\u5f15\u5165\u4e86\uff1a(i) \u57fa\u4e8e\u535a\u5f08\u8bba\u8bba\u8bc1\u957f\u5ea6\u7684\u5206\u5c42\u53ef\u89c6\u5316\uff0c\u63ed\u793a\u4e86\u826f\u597d\u7684\u63a8\u5bfc\u7ed3\u6784\uff1b(ii) \u6839\u636e\u8bed\u4e49\u89d2\u8272\uff08\u4e3b\u8981\uff0c\u6b21\u8981\uff0c\u5931\u8bef\uff09\u5bf9\u653b\u51fb\u8fb9\u7f18\u8fdb\u884c\u5206\u7c7b\uff1b(iii) \u5728\u6a21\u68f1\u4e24\u53ef\u7684\u4e09\u503c\u57fa\u7840\u8bed\u4e49\u4e0a\u53e0\u52a0\u4e8c\u503c\u89e3\u7684\u53ef\u89c6\u5316\uff1b(iv) \u8bc6\u522b\u5173\u952e\u653b\u51fb\u96c6\uff0c\u5176\u6682\u505c\u53ef\u4ee5\u89e3\u51b3\u672a\u51b3\u5b9a\u7684\u8bba\u8bc1\u3002", "result": "\u901a\u8fc7\u5bf9\u5173\u952e\u653b\u51fb\u96c6\u7684\u7cfb\u7edf\u751f\u6210\uff0cAF-XRAY\u5c06\u6a21\u7cca\u573a\u666f\u8f6c\u5316\u4e3a\u57fa\u7840\u89e3\u51b3\u65b9\u6848\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u786e\u5b9a\u6a21\u7cca\u7684\u5177\u4f53\u539f\u56e0\u5e76\u63a2\u7d22\u66ff\u4ee3\u89e3\u51b3\u65b9\u6848\u3002\u6b64\u5916\uff0c\u8be5\u5de5\u5177\u8fd8\u652f\u6301\u76ee\u7684\u8bba\u6cd5\u5f8b\u63a8\u7406\uff0c\u5c55\u793a\u4e86\u4e0d\u540c\u5047\u8bbe\u5982\u4f55\u5bfc\u81f4\u4e0d\u540c\u7684\u6b63\u5f53\u7ed3\u8bba\u3002", "conclusion": "AF-XRAY\u4f5c\u4e3a\u4e00\u6b3e\u5f00\u6e90\u5de5\u5177\u5305\uff0c\u4e3a\u63a2\u7d22\u3001\u5206\u6790\u548c\u53ef\u89c6\u5316\u6cd5\u5f8b\u63a8\u7406\u4e2d\u7684\u62bd\u8c61\u8bba\u8bc1\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u975e\u4e13\u5bb6\u66f4\u597d\u5730\u7406\u89e3\u6cd5\u5f8b\u8bba\u8bc1\u4e2d\u7684\u590d\u6742\u6027\u3002"}}
{"id": "2507.10609", "pdf": "https://arxiv.org/pdf/2507.10609", "abs": "https://arxiv.org/abs/2507.10609", "authors": ["Obumneme Nwafor", "Chioma Nwafor", "Amro Zakaria", "Nkechi Nwankwo"], "title": "A Feed-Forward Artificial Intelligence Pipeline for Sustainable Desalination under Climate Uncertainties: UAE Insights", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "The United Arab Emirates (UAE) relies heavily on seawater desalination to\nmeet over 90% of its drinking water needs. Desalination processes are highly\nenergy intensive and account for approximately 15% of the UAE's electricity\nconsumption, contributing to over 22% of the country's energy-related CO2\nemissions. Moreover, these processes face significant sustainability challenges\nin the face of climate uncertainties such as rising seawater temperatures,\nsalinity, and aerosol optical depth (AOD). AOD greatly affects the operational\nand economic performance of solar-powered desalination systems through\nphotovoltaic soiling, membrane fouling, and water turbidity cycles.\n  This study proposes a novel pipelined two-stage predictive modelling\narchitecture: the first stage forecasts AOD using satellite-derived time series\nand meteorological data; the second stage uses the predicted AOD and other\nmeteorological factors to predict desalination performance efficiency losses.\nThe framework achieved 98% accuracy, and SHAP (SHapley Additive exPlanations)\nwas used to reveal key drivers of system degradation. Furthermore, this study\nproposes a dust-aware rule-based control logic for desalination systems based\non predicted values of AOD and solar efficiency. This control logic is used to\nadjust the desalination plant feed water pressure, adapt maintenance\nscheduling, and regulate energy source switching.\n  To enhance the practical utility of the research findings, the predictive\nmodels and rule-based controls were packaged into an interactive dashboard for\nscenario and predictive analytics. This provides a management decision-support\nsystem for climate-adaptive planning.", "AI": {"tldr": "\u963f\u8054\u914b\u4f9d\u8d56\u6d77\u6c34\u6de1\u5316\u6ee1\u8db390%\u4ee5\u4e0a\u7684\u996e\u7528\u6c34\u9700\u6c42\uff0c\u4f46\u8be5\u8fc7\u7a0b\u8017\u80fd\u9ad8\u4e14\u53d7\u6c14\u5019\u56e0\u7d20\u5f71\u54cd\u5927\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4e24\u9636\u6bb5\u9884\u6d4b\u5efa\u6a21\u67b6\u6784\uff0c\u7528\u4e8e\u9884\u6d4b\u6c14\u6eb6\u80f6\u5149\u5b66\u6df1\u5ea6\uff08AOD\uff09\u548c\u6d77\u6c34\u6de1\u5316\u6027\u80fd\u6548\u7387\u635f\u5931\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8eAOD\u9884\u6d4b\u503c\u7684\u7070\u5c18\u611f\u77e5\u89c4\u5219\u63a7\u5236\u903b\u8f91\uff0c\u4ee5\u8c03\u6574\u6d77\u6c34\u6de1\u5316\u5382\u7684\u64cd\u4f5c\u53c2\u6570\u3002\u6b64\u5916\uff0c\u8fd8\u5f00\u53d1\u4e86\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\uff0c\u4e3a\u6c14\u5019\u9002\u5e94\u6027\u89c4\u5212\u63d0\u4f9b\u7ba1\u7406\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002", "motivation": "\u963f\u8054\u914b\u6d77\u6c34\u6de1\u5316\u8fc7\u7a0b\u80fd\u8017\u9ad8\uff0c\u5bf9\u80fd\u6e90\u76f8\u5173CO2\u6392\u653e\u8d21\u732e\u5927\uff0c\u5e76\u4e14\u9762\u5bf9\u6c14\u5019\u53d8\u5316\u5982\u6d77\u6c34\u6e29\u5ea6\u4e0a\u5347\u3001\u76d0\u5ea6\u589e\u52a0\u7b49\u5e26\u6765\u7684\u53ef\u6301\u7eed\u6027\u6311\u6218\u3002\u4e3a\u4e86\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u9884\u6d4bAOD\u53ca\u5176\u5bf9\u592a\u9633\u80fd\u6de1\u5316\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u5e76\u5236\u5b9a\u76f8\u5e94\u7684\u63a7\u5236\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u7684\u9884\u6d4b\u5efa\u6a21\u67b6\u6784\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u536b\u661f\u65f6\u95f4\u5e8f\u5217\u548c\u6c14\u8c61\u6570\u636e\u9884\u6d4bAOD\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5229\u7528\u9884\u6d4b\u7684AOD\u548c\u5176\u4ed6\u6c14\u8c61\u56e0\u7d20\u9884\u6d4b\u6de1\u5316\u6027\u80fd\u6548\u7387\u635f\u5931\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u9884\u6d4b\u503c\u7684\u7070\u5c18\u611f\u77e5\u89c4\u5219\u63a7\u5236\u903b\u8f91\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5b9e\u73b0\u4e8698%\u7684\u51c6\u786e\u7387\uff0cSHAP\u5206\u6790\u63ed\u793a\u4e86\u5bfc\u81f4\u7cfb\u7edf\u9000\u5316\u7684\u5173\u952e\u9a71\u52a8\u56e0\u7d20\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5c06\u9884\u6d4b\u6a21\u578b\u548c\u89c4\u5219\u63a7\u5236\u96c6\u6210\u5230\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u4eea\u8868\u677f\u4e2d\uff0c\u589e\u5f3a\u4e86\u7814\u7a76\u7ed3\u679c\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u672c\u7814\u7a76\u6240\u63d0\u51fa\u7684\u9884\u6d4b\u6a21\u578b\u548c\u63a7\u5236\u903b\u8f91\u53ef\u4ee5\u4e3a\u6d77\u6c34\u6de1\u5316\u8fc7\u7a0b\u4e2d\u7684\u64cd\u4f5c\u53c2\u6570\u8c03\u6574\u3001\u7ef4\u62a4\u8ba1\u5212\u8c03\u6574\u548c\u80fd\u6e90\u6e90\u5207\u6362\u63d0\u4f9b\u6709\u6548\u7684\u6307\u5bfc\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u7cfb\u7edf\u7684\u7ecf\u6d4e\u6027\u548c\u73af\u5883\u53cb\u597d\u6027\u3002"}}
{"id": "2507.10819", "pdf": "https://arxiv.org/pdf/2507.10819", "abs": "https://arxiv.org/abs/2507.10819", "authors": ["Pedro Almansa Jim\u00e9nez", "Lorenzo Fern\u00e1ndez Maim\u00f3", "\u00c1ngel Luis Per\u00e1les G\u00f3mez"], "title": "Reporte de vulnerabilidades en IIoT. Proyecto DEFENDER", "categories": ["cs.CR"], "comment": "Language: Spanish", "summary": "The main objective of this technical report is to conduct a comprehensive\nstudy on devices operating within Industrial Internet of Things (IIoT)\nenvironments, describing the scenarios that define this category and analysing\nthe vulnerabilities that compromise their security. To this end, the report\nseeks to identify and examine the main classes of IIoT devices, detailing their\ncharacteristics, functionalities, and roles within industrial systems. This\nanalysis enables a better understanding of how these devices interact and\nfulfil the requirements of critical industrial environments. The report also\nexplores the specific contexts in which these devices operate, highlighting the\ndistinctive features of industrial scenarios and the conditions under which the\ndevices function. Furthermore, it analyses the vulnerabilities affecting IIoT\ndevices, outlining their vectors, targets, impact, and consequences. The report\nthen describes the typical phases of an attack, along with a selection of\nreal-world documented incidents. These cases are classified according to the\ntaxonomy presented in Section 3, providing a comprehensive view of the\npotential threats to security and assessing the impact these vulnerabilities\nmay have on industrial environments. Finally, the report presents a compilation\nof some of the most recent and effective security countermeasures as potential\nsolutions to the security challenges faced by industrial systems. Special\nemphasis is placed on the role of Machine Learning in the development of these\napproaches, underscoring its importance in enhancing industrial cybersecurity.", "AI": {"tldr": "\u672c\u6280\u672f\u62a5\u544a\u7684\u4e3b\u8981\u76ee\u6807\u662f\u5bf9\u5de5\u4e1a\u7269\u8054\u7f51\uff08IIoT\uff09\u73af\u5883\u4e2d\u7684\u8bbe\u5907\u8fdb\u884c\u5168\u9762\u7814\u7a76\uff0c\u5206\u6790\u5176\u6f0f\u6d1e\uff0c\u5e76\u63a2\u8ba8\u673a\u5668\u5b66\u4e60\u5728\u63d0\u9ad8\u5de5\u4e1a\u7f51\u7edc\u5b89\u5168\u65b9\u9762\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u8bc6\u522b\u548c\u7814\u7a76IIoT\u8bbe\u5907\u7684\u4e3b\u8981\u7c7b\u522b\u53ca\u5176\u5728\u5de5\u4e1a\u7cfb\u7edf\u4e2d\u7684\u4f5c\u7528\uff0c\u4ee5\u7406\u89e3\u8fd9\u4e9b\u8bbe\u5907\u5982\u4f55\u4ea4\u4e92\u5e76\u6ee1\u8db3\u5173\u952e\u5de5\u4e1a\u73af\u5883\u7684\u8981\u6c42\u3002\u540c\u65f6\uff0c\u63a2\u7d22\u8fd9\u4e9b\u8bbe\u5907\u7684\u64cd\u4f5c\u80cc\u666f\uff0c\u5f3a\u8c03\u5de5\u4e1a\u573a\u666f\u7684\u72ec\u7279\u7279\u5f81\u4ee5\u53ca\u8bbe\u5907\u8fd0\u884c\u6761\u4ef6\u3002", "method": "\u8be5\u62a5\u544a\u9996\u5148\u786e\u5b9a\u5e76\u68c0\u67e5\u4e86IIoT\u8bbe\u5907\u7684\u4e3b\u8981\u7c7b\u522b\uff0c\u63cf\u8ff0\u5b83\u4eec\u7684\u7279\u6027\u3001\u529f\u80fd\u548c\u89d2\u8272\u3002\u7136\u540e\uff0c\u5b83\u5206\u6790\u4e86\u5f71\u54cdIIoT\u8bbe\u5907\u7684\u6f0f\u6d1e\uff0c\u6982\u8ff0\u4e86\u653b\u51fb\u7684\u5178\u578b\u9636\u6bb5\uff0c\u5e76\u6839\u636e\u7b2c3\u8282\u4e2d\u63d0\u51fa\u7684\u5206\u7c7b\u6cd5\u5bf9\u9009\u5b9a\u7684\u771f\u5b9e\u4e8b\u4ef6\u8fdb\u884c\u4e86\u5206\u7c7b\u3002", "result": "\u62a5\u544a\u5c55\u793a\u4e86\u5bf9IIoT\u8bbe\u5907\u64cd\u4f5c\u60c5\u666f\u7684\u7406\u89e3\uff0c\u63ed\u793a\u4e86\u7279\u5b9a\u4e8e\u8fd9\u4e9b\u8bbe\u5907\u7684\u6f0f\u6d1e\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u5c55\u793a\u4e86\u53ef\u80fd\u7684\u5b89\u5168\u5a01\u80c1\u3002\u6b64\u5916\uff0c\u8fd8\u7f16\u5236\u4e86\u4e00\u4e9b\u6700\u65b0\u548c\u6709\u6548\u7684\u5b89\u5168\u5bf9\u7b56\uff0c\u7279\u522b\u662f\u5f3a\u8c03\u4e86\u673a\u5668\u5b66\u4e60\u5728\u589e\u5f3a\u5de5\u4e1a\u7f51\u7edc\u5b89\u5168\u65b9\u9762\u7684\u4f5c\u7528\u3002", "conclusion": "\u901a\u8fc7\u5bf9IIoT\u8bbe\u5907\u53ca\u5176\u5b89\u5168\u6311\u6218\u7684\u7814\u7a76\uff0c\u62a5\u544a\u63d0\u51fa\u4e86\u9488\u5bf9\u5de5\u4e1a\u7cfb\u7edf\u7684\u6f5c\u5728\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u6307\u51fa\u673a\u5668\u5b66\u4e60\u5bf9\u4e8e\u63d0\u5347\u5de5\u4e1a\u7f51\u7edc\u5b89\u5168\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.10860", "pdf": "https://arxiv.org/pdf/2507.10860", "abs": "https://arxiv.org/abs/2507.10860", "authors": ["Atila Orhon", "Arda Okan", "Berkin Durmus", "Zach Nagengast", "Eduardo Pacheco"], "title": "WhisperKit: On-device Real-time ASR with Billion-Scale Transformers", "categories": ["cs.AI"], "comment": "ICML 2025 - On-Device Learning for Foundational Models Workshop", "summary": "Real-time Automatic Speech Recognition (ASR) is a fundamental building block\nfor many commercial applications of ML, including live captioning, dictation,\nmeeting transcriptions, and medical scribes. Accuracy and latency are the most\nimportant factors when companies select a system to deploy. We present\nWhisperKit, an optimized on-device inference system for real-time ASR that\nsignificantly outperforms leading cloud-based systems. We benchmark against\nserver-side systems that deploy a diverse set of models, including a frontier\nmodel (OpenAI gpt-4o-transcribe), a proprietary model (Deepgram nova-3), and an\nopen-source model (Fireworks large-v3-turbo).Our results show that WhisperKit\nmatches the lowest latency at 0.46s while achieving the highest accuracy 2.2%\nWER. The optimizations behind the WhisperKit system are described in detail in\nthis paper.", "AI": {"tldr": "WhisperKit \u662f\u4e00\u4e2a\u7528\u4e8e\u5b9e\u65f6\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7684\u4f18\u5316\u8bbe\u5907\u7aef\u63a8\u7406\u7cfb\u7edf\uff0c\u5176\u5728\u5ef6\u8fdf\u548c\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u9886\u5148\u7684\u57fa\u4e8e\u4e91\u7684\u7cfb\u7edf\u3002", "motivation": "\u8bb8\u591a\u5546\u4e1a\u5e94\u7528\u4f9d\u8d56\u4e8e\u5b9e\u65f6\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\uff0c\u5176\u4e2d\u51c6\u786e\u6027\u548c\u5ef6\u8fdf\u662f\u9009\u62e9\u90e8\u7f72\u7cfb\u7edf\u65f6\u6700\u91cd\u8981\u7684\u56e0\u7d20\u3002\u4f5c\u8005\u5e0c\u671b\u63d0\u4f9b\u4e00\u4e2a\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee5\u6ee1\u8db3\u8fd9\u4e9b\u9700\u6c42\u3002", "method": "\u4f5c\u8005\u5f00\u53d1\u4e86 WhisperKit \u7cfb\u7edf\uff0c\u8fd9\u662f\u4e00\u4e2a\u4f18\u5316\u8fc7\u7684\u8bbe\u5907\u7aef\u63a8\u7406\u7cfb\u7edf\u3002\u5b83\u88ab\u8bbe\u8ba1\u7528\u6765\u5b9e\u73b0\u5b9e\u65f6\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff0c\u5e76\u4e14\u4e0e\u591a\u79cd\u670d\u52a1\u5668\u7aef\u7cfb\u7edf\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u6bd4\u8f83\uff0c\u5305\u62ec\u524d\u6cbf\u6a21\u578b\u3001\u4e13\u6709\u6a21\u578b\u548c\u5f00\u6e90\u6a21\u578b\u3002", "result": "WhisperKit \u5b9e\u73b0\u4e86\u6700\u4f4e\u7684\u5ef6\u8fdf 0.46 \u79d2\uff0c\u5e76\u8fbe\u5230\u4e86\u6700\u9ad8\u7684\u51c6\u786e\u6027 2.2% \u7684\u8bcd\u9519\u8bef\u7387\uff08WER\uff09\u3002", "conclusion": "WhisperKit \u5728\u5b9e\u65f6\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u65b9\u9762\u63d0\u4f9b\u4e86\u663e\u8457\u6539\u8fdb\u7684\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u5f53\u524d\u9886\u5148\u7684\u57fa\u4e8e\u4e91\u7684\u670d\u52a1\u3002"}}
{"id": "2507.10611", "pdf": "https://arxiv.org/pdf/2507.10611", "abs": "https://arxiv.org/abs/2507.10611", "authors": ["Mengwen Ye", "Yingzi Huangfu", "Shujian Gao", "Wei Ren", "Weifan Liu", "Zekuan Yu"], "title": "FedGSCA: Medical Federated Learning with Global Sample Selector and Client Adaptive Adjuster under Label Noise", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Federated Learning (FL) emerged as a solution for collaborative medical image\nclassification while preserving data privacy. However, label noise, which\narises from inter-institutional data variability, can cause training\ninstability and degrade model performance. Existing FL methods struggle with\nnoise heterogeneity and the imbalance in medical data. Motivated by these\nchallenges, we propose FedGSCA, a novel framework for enhancing robustness in\nnoisy medical FL. FedGSCA introduces a Global Sample Selector that aggregates\nnoise knowledge from all clients, effectively addressing noise heterogeneity\nand improving global model stability. Furthermore, we develop a Client Adaptive\nAdjustment (CAA) mechanism that combines adaptive threshold pseudo-label\ngeneration and Robust Credal Labeling Loss. CAA dynamically adjusts to class\ndistributions, ensuring the inclusion of minority samples and carefully\nmanaging noisy labels by considering multiple plausible labels. This dual\napproach mitigates the impact of noisy data and prevents overfitting during\nlocal training, which improves the generalizability of the model. We evaluate\nFedGSCA on one real-world colon slides dataset and two synthetic medical\ndatasets under various noise conditions, including symmetric, asymmetric,\nextreme, and heterogeneous types. The results show that FedGSCA outperforms the\nstate-of-the-art methods, excelling in extreme and heterogeneous noise\nscenarios. Moreover, FedGSCA demonstrates significant advantages in improving\nmodel stability and handling complex noise, making it well-suited for\nreal-world medical federated learning scenarios.", "AI": {"tldr": "\u63d0\u51faFedGSCA\u6846\u67b6\uff0c\u901a\u8fc7\u5168\u5c40\u6837\u672c\u9009\u62e9\u5668\u548c\u5ba2\u6237\u81ea\u9002\u5e94\u8c03\u6574\u673a\u5236\u63d0\u9ad8\u5728\u566a\u58f0\u6807\u7b7e\u4e0b\u7684\u8054\u90a6\u5b66\u4e60\u6a21\u578b\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u533b\u7597\u6570\u636e\u4e2d\u7684\u566a\u58f0\u5f02\u8d28\u6027\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u5f15\u5165\u4e86\u5168\u5c40\u6837\u672c\u9009\u62e9\u5668\uff08Global Sample Selector\uff09\u6765\u805a\u5408\u6240\u6709\u5ba2\u6237\u7aef\u7684\u566a\u58f0\u77e5\u8bc6\uff0c\u89e3\u51b3\u566a\u58f0\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u5ba2\u6237\u81ea\u9002\u5e94\u8c03\u6574\uff08Client Adaptive Adjustment, CAA\uff09\u673a\u5236\uff0c\u7ed3\u5408\u81ea\u9002\u5e94\u9608\u503c\u4f2a\u6807\u7b7e\u751f\u6210\u548c\u9c81\u68d2\u4fe1\u5ea6\u6807\u7b7e\u635f\u5931\uff0c\u52a8\u6001\u8c03\u6574\u4ee5\u9002\u5e94\u7c7b\u522b\u5206\u5e03\u5e76\u5904\u7406\u566a\u58f0\u6807\u7b7e\u3002", "result": "\u5728\u73b0\u5b9e\u4e16\u754c\u7ed3\u80a0\u5207\u7247\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u5408\u6210\u533b\u5b66\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aFedGSCA\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u6781\u7aef\u548c\u5f02\u6784\u566a\u58f0\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "FedGSCA\u5c55\u793a\u4e86\u663e\u8457\u4f18\u52bf\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7a33\u5b9a\u6027\u5e76\u80fd\u6709\u6548\u5904\u7406\u590d\u6742\u566a\u58f0\uff0c\u9002\u5408\u5b9e\u9645\u533b\u7597\u8054\u90a6\u5b66\u4e60\u573a\u666f\u3002"}}
{"id": "2507.10836", "pdf": "https://arxiv.org/pdf/2507.10836", "abs": "https://arxiv.org/abs/2507.10836", "authors": ["Zhonghao Zhan", "Huichi Zhou", "Hamed Haddadi"], "title": "REAL-IoT: Characterizing GNN Intrusion Detection Robustness under Practical Adversarial Attack", "categories": ["cs.CR"], "comment": null, "summary": "Graph Neural Network (GNN)-based network intrusion detection systems (NIDS)\nare often evaluated on single datasets, limiting their ability to generalize\nunder distribution drift. Furthermore, their adversarial robustness is\ntypically assessed using synthetic perturbations that lack realism. This\nmeasurement gap leads to an overestimation of GNN-based NIDS resilience. To\naddress the limitations, we propose \\textbf{REAL-IoT}, a comprehensive\nframework for robustness evaluation of GNN-based NIDS in IoT environments. Our\nframework presents a methodology that creates a unified dataset from canonical\ndatasets to assess generalization under drift. In addition, it features a novel\nintrusion dataset collected from a physical IoT testbed, which captures network\ntraffic and attack scenarios under real-world settings. Furthermore, using\nREAL-IoT, we explore the usage of Large Language Models (LLMs) to analyze\nnetwork data and mitigate the impact of adversarial examples by filtering\nsuspicious flows. Our evaluations using REAL-IoT reveal performance drops in\nGNN models compared to results from standard benchmarks, quantifying their\nsusceptibility to drift and realistic attacks. We also demonstrate the\npotential of LLM-based filtering to enhance robustness. These findings\nemphasize the necessity of realistic threat modeling and rigorous measurement\npractices for developing resilient IoT intrusion detection systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faREAL-IoT\u6846\u67b6\uff0c\u65e8\u5728\u8bc4\u4f30\u57fa\u4e8eGNN\u7684\u7269\u8054\u7f51\u73af\u5883\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\uff0c\u901a\u8fc7\u521b\u5efa\u7edf\u4e00\u6570\u636e\u96c6\u548c\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fc7\u6ee4\u53ef\u7591\u6d41\u91cf\uff0c\u53d1\u73b0\u73b0\u6709GNN\u6a21\u578b\u5bf9\u5206\u5e03\u504f\u79fb\u548c\u771f\u5b9e\u653b\u51fb\u654f\u611f\uff0c\u5e76\u8bc1\u660e\u4e86LLM\u8fc7\u6ee4\u589e\u5f3a\u9c81\u68d2\u6027\u7684\u6f5c\u529b\u3002", "motivation": "\u57fa\u4e8eGNN\u7684\u7f51\u7edc\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\u901a\u5e38\u5728\u5355\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u5bfc\u81f4\u5176\u6cdb\u5316\u80fd\u529b\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u88ab\u9ad8\u4f30\u3002\u4e3a\u4e86\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u8fd9\u4e9b\u7cfb\u7edf\u7684\u6027\u80fd\u5e76\u63d0\u9ad8\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51faREAL-IoT\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u62ec\uff1a1) \u521b\u5efa\u4e00\u4e2a\u7edf\u4e00\u7684\u6570\u636e\u96c6\u6765\u8bc4\u4f30\u6a21\u578b\u5728\u5206\u5e03\u6f02\u79fb\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\uff1b2) \u6536\u96c6\u6765\u81ea\u7269\u7406IoT\u6d4b\u8bd5\u5e73\u53f0\u7684\u771f\u5b9e\u5165\u4fb5\u6570\u636e\u96c6\uff1b3) \u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5206\u6790\u7f51\u7edc\u6570\u636e\u5e76\u8fc7\u6ee4\u53ef\u7591\u6d41\u91cf\u4ee5\u51cf\u8f7b\u5bf9\u6297\u6837\u672c\u7684\u5f71\u54cd\u3002", "result": "\u4f7f\u7528REAL-IoT\u6846\u67b6\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u4e0e\u6807\u51c6\u57fa\u51c6\u7ed3\u679c\u76f8\u6bd4\uff0cGNN\u6a21\u578b\u5728\u9762\u5bf9\u5206\u5e03\u6f02\u79fb\u548c\u73b0\u5b9e\u653b\u51fb\u65f6\u6027\u80fd\u4e0b\u964d\uff0c\u8868\u660e\u5176\u8106\u5f31\u6027\u3002\u540c\u65f6\uff0c\u5c55\u793a\u4e86\u57fa\u4e8eLLM\u7684\u8fc7\u6ee4\u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u4e3a\u5f00\u53d1\u5177\u6709\u5f39\u6027\u7684\u7269\u8054\u7f51\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff0c\u5fc5\u987b\u91c7\u7528\u73b0\u5b9e\u7684\u5a01\u80c1\u5efa\u6a21\u548c\u4e25\u683c\u7684\u6d4b\u91cf\u5b9e\u8df5\u3002"}}
{"id": "2507.10894", "pdf": "https://arxiv.org/pdf/2507.10894", "abs": "https://arxiv.org/abs/2507.10894", "authors": ["Zongtao He", "Liuyi Wang", "Lu Chen", "Chengju Liu", "Qijun Chen"], "title": "NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization", "categories": ["cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "Language-guided navigation is a cornerstone of embodied AI, enabling agents\nto interpret language instructions and navigate complex environments. However,\nexpert-provided instructions are limited in quantity, while synthesized\nannotations often lack quality, making them insufficient for large-scale\nresearch. To address this, we propose NavComposer, a novel framework for\nautomatically generating high-quality navigation instructions. NavComposer\nexplicitly decomposes semantic entities such as actions, scenes, and objects,\nand recomposes them into natural language instructions. Its modular\narchitecture allows flexible integration of state-of-the-art techniques, while\nthe explicit use of semantic entities enhances both the richness and accuracy\nof instructions. Moreover, it operates in a data-agnostic manner, supporting\nadaptation to diverse navigation trajectories without domain-specific training.\nComplementing NavComposer, we introduce NavInstrCritic, a comprehensive\nannotation-free evaluation system that assesses navigation instructions on\nthree dimensions: contrastive matching, semantic consistency, and linguistic\ndiversity. NavInstrCritic provides a holistic evaluation of instruction\nquality, addressing limitations of traditional metrics that rely heavily on\nexpert annotations. By decoupling instruction generation and evaluation from\nspecific navigation agents, our method enables more scalable and generalizable\nresearch. Extensive experiments provide direct and practical evidence for the\neffectiveness of our method.", "AI": {"tldr": "\u63d0\u51faNavComposer\u6846\u67b6\uff0c\u81ea\u52a8\u4ea7\u751f\u9ad8\u8d28\u91cf\u5bfc\u822a\u6307\u4ee4\uff0c\u5e76\u5f15\u5165NavInstrCritic\u7cfb\u7edf\u8fdb\u884c\u65e0\u6ce8\u91ca\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u7684\u4e13\u5bb6\u63d0\u4f9b\u6216\u5408\u6210\u7684\u5bfc\u822a\u6307\u4ee4\u5728\u6570\u91cf\u548c\u8d28\u91cf\u4e0a\u4e0d\u8db3\u4ee5\u652f\u6301\u5927\u89c4\u6a21\u7814\u7a76\u3002", "method": "NavComposer\u901a\u8fc7\u5206\u89e3\u8bed\u4e49\u5b9e\u4f53\u5e76\u91cd\u65b0\u7ec4\u5408\u6210\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\uff0c\u91c7\u7528\u6a21\u5757\u5316\u7ed3\u6784\u96c6\u6210\u5148\u8fdb\u6280\u672f\uff0c\u5e76\u4ee5\u6570\u636e\u65e0\u5173\u7684\u65b9\u5f0f\u8fd0\u4f5c\u3002NavInstrCritic\u4ece\u5bf9\u6bd4\u5339\u914d\u3001\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u8bed\u8a00\u591a\u6837\u6027\u4e09\u4e2a\u7ef4\u5ea6\u5bf9\u6307\u4ee4\u8fdb\u884c\u5168\u9762\u8bc4\u4ef7\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u63d0\u4f9b\u4e86\u76f4\u63a5\u4e14\u5b9e\u7528\u7684\u8bc1\u636e\u8bc1\u660e\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "NavComposer\u548cNavInstrCritic\u4f7f\u5f97\u6307\u4ee4\u751f\u6210\u4e0e\u8bc4\u4f30\u66f4\u52a0\u53ef\u6269\u5c55\u548c\u6cdb\u5316\uff0c\u4fc3\u8fdb\u4e86\u66f4\u5927\u89c4\u6a21\u7684\u7814\u7a76\u3002"}}
{"id": "2507.10613", "pdf": "https://arxiv.org/pdf/2507.10613", "abs": "https://arxiv.org/abs/2507.10613", "authors": ["Zhengyu Chen", "Siqi Wang", "Teng Xiao", "Yudong Wang", "Shiqi Chen", "Xunliang Cai", "Junxian He", "Jingang Wang"], "title": "Sub-Scaling Laws: On the Role of Data Density and Training Strategies in LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional scaling laws in natural language processing suggest that\nincreasing model size and training data enhances performance. However, recent\nstudies reveal deviations, particularly in large language models, where\nperformance improvements decelerate, which is a phenomenon known as\nsub-scaling. This paper revisits these scaling laws by examining the impact of\ndata quality and training strategies on model performance. Through extensive\nempirical analysis of over 400 models, we identify high data density and\nnon-optimal resource allocation as key factors contributing to sub-scaling.\nHigh data density leads to diminishing returns due to redundant information,\nwhile optimal resource allocation is crucial for sustained performance\nimprovements. We propose a sub-optimal scaling law that better predicts\nperformance in sub-scaling regimes, highlighting the importance of data quality\nand diversity.", "AI": {"tldr": "\u672c\u6587\u91cd\u65b0\u5ba1\u89c6\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u7f29\u653e\u5b9a\u5f8b\uff0c\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u786e\u5b9a\u4e86\u6570\u636e\u8d28\u91cf\u548c\u8bad\u7ec3\u7b56\u7565\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u6b21\u4f18\u7684\u7f29\u653e\u5b9a\u5f8b\u3002", "motivation": "\u4f20\u7edf\u7684\u7f29\u653e\u5b9a\u5f8b\u8ba4\u4e3a\u589e\u52a0\u6a21\u578b\u5927\u5c0f\u548c\u8bad\u7ec3\u6570\u636e\u53ef\u4ee5\u63d0\u9ad8\u6027\u80fd\uff0c\u4f46\u6700\u8fd1\u7684\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u6027\u80fd\u6539\u8fdb\u51cf\u901f\uff0c\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u6b21\u7f29\u653e\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u5206\u6790\u8d85\u8fc7400\u4e2a\u6a21\u578b\uff0c\u7814\u7a76\u6570\u636e\u8d28\u91cf\u4e0e\u8bad\u7ec3\u7b56\u7565\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u9ad8\u6570\u636e\u5bc6\u5ea6\u548c\u975e\u6700\u4f18\u8d44\u6e90\u914d\u7f6e\u662f\u5bfc\u81f4\u6b21\u7f29\u653e\u7684\u4e3b\u8981\u56e0\u7d20\u3002\u9ad8\u6570\u636e\u5bc6\u5ea6\u4f1a\u5bfc\u81f4\u7531\u4e8e\u5197\u4f59\u4fe1\u606f\u800c\u4ea7\u751f\u7684\u6536\u76ca\u9012\u51cf\uff0c\u800c\u6700\u4f18\u8d44\u6e90\u914d\u7f6e\u5bf9\u4e8e\u6301\u7eed\u7684\u6027\u80fd\u6539\u8fdb\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6b21\u4f18\u7f29\u653e\u5b9a\u5f8b\uff0c\u8be5\u5b9a\u5f8b\u66f4\u597d\u5730\u9884\u6d4b\u4e86\u6b21\u7f29\u653e\u72b6\u6001\u4e0b\u7684\u6027\u80fd\uff0c\u5f3a\u8c03\u4e86\u6570\u636e\u8d28\u91cf\u548c\u591a\u6837\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2507.10845", "pdf": "https://arxiv.org/pdf/2507.10845", "abs": "https://arxiv.org/abs/2507.10845", "authors": ["Wenxuan Shi", "Hongwei Li", "Jiahao Yu", "Xinqian Sun", "Wenbo Guo", "Xinyu Xing"], "title": "BandFuzz: An ML-powered Collaborative Fuzzing Framework", "categories": ["cs.CR", "cs.SE"], "comment": null, "summary": "Collaborative fuzzing has recently emerged as a technique that combines\nmultiple individual fuzzers and dynamically chooses the appropriate\ncombinations suited for different programs. Unlike individual fuzzers, which\nrely on specific assumptions to maintain their effectiveness, collaborative\nfuzzing relaxes the assumptions on target programs, providing constant and\nrobust performance across various programs. Ideally, collaborative fuzzing\nshould be a more promising direction toward generic fuzzing solutions, as it\nmitigates the need for manual cherry-picking of individual fuzzers. However,\nthe effectiveness of existing collaborative fuzzing frameworks is limited by\nmajor challenges, such as the need for additional computational resources\ncompared to individual fuzzers and the inefficient allocation of resources\namong the various fuzzers.", "AI": {"tldr": "\u534f\u540c\u6a21\u7cca\u6d4b\u8bd5\u662f\u7ed3\u5408\u591a\u4e2a\u72ec\u7acb\u6a21\u7cca\u6d4b\u8bd5\u5de5\u5177\u5e76\u52a8\u6001\u9009\u62e9\u9002\u5408\u4e0d\u540c\u7a0b\u5e8f\u7ec4\u5408\u7684\u4e00\u79cd\u6280\u672f\u3002\u5b83\u5728\u5404\u79cd\u7a0b\u5e8f\u4e2d\u63d0\u4f9b\u6301\u7eed\u548c\u7a33\u5b9a\u7684\u6027\u80fd\uff0c\u4f46\u73b0\u6709\u6846\u67b6\u7684\u6709\u6548\u6027\u53d7\u5230\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u548c\u8d44\u6e90\u5206\u914d\u6548\u7387\u4f4e\u4e0b\u7684\u9650\u5236\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5355\u4e2afuzzer\u5728\u9488\u5bf9\u4e0d\u540c\u7a0b\u5e8f\u65f6\u6548\u679c\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u5e0c\u671b\u627e\u5230\u4e00\u79cd\u66f4\u901a\u7528\u7684\u6a21\u7cca\u6d4b\u8bd5\u89e3\u51b3\u65b9\u6848\uff0c\u4ece\u800c\u4e0d\u9700\u8981\u624b\u52a8\u6311\u9009\u6700\u9002\u5408\u7684fuzzer\u3002", "method": "\u534f\u540c\u6a21\u7cca\u6d4b\u8bd5\u653e\u677e\u4e86\u5bf9\u76ee\u6807\u7a0b\u5e8f\u7684\u5177\u4f53\u5047\u8bbe\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u4e2afuzzer\uff0c\u5e76\u6839\u636e\u4e0d\u540c\u7684\u7a0b\u5e8f\u52a8\u6001\u5730\u9009\u62e9\u9002\u5f53\u7684\u7ec4\u5408\u6765\u5b9e\u73b0\u3002", "result": "\u5c3d\u7ba1\u534f\u540c\u6a21\u7cca\u6d4b\u8bd5\u7406\u8bba\u4e0a\u662f\u4e00\u4e2a\u66f4\u6709\u524d\u9014\u7684\u65b9\u5411\uff0c\u4f46\u662f\u73b0\u6709\u7684\u534f\u540c\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6\u7684\u6548\u679c\u53d7\u5230\u4e86\u9700\u8981\u989d\u5916\u8ba1\u7b97\u8d44\u6e90\u548c\u8d44\u6e90\u5206\u914d\u6548\u7387\u4f4e\u4e0b\u7b49\u6311\u6218\u7684\u9650\u5236\u3002", "conclusion": "\u534f\u540c\u6a21\u7cca\u6d4b\u8bd5\u4f5c\u4e3a\u4e00\u79cd\u65b0\u5174\u6280\u672f\uff0c\u867d\u7136\u5b58\u5728\u4e00\u4e9b\u5c40\u9650\u6027\uff0c\u4f46\u5728\u8ffd\u6c42\u901a\u7528\u6a21\u7cca\u6d4b\u8bd5\u89e3\u51b3\u65b9\u6848\u65b9\u9762\u5c55\u73b0\u51fa\u4e86\u6f5c\u529b\u3002"}}
{"id": "2507.10911", "pdf": "https://arxiv.org/pdf/2507.10911", "abs": "https://arxiv.org/abs/2507.10911", "authors": ["Yicong Wu", "Ting Chen", "Irit Hochberg", "Zhoujian Sun", "Ruth Edry", "Zhengxing Huang", "Mor Peleg"], "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "categories": ["cs.AI"], "comment": null, "summary": "Therapy recommendation for chronic patients with multimorbidity is\nchallenging due to risks of treatment conflicts. Existing decision support\nsystems face scalability limitations. Inspired by the way in which general\npractitioners (GP) manage multimorbidity patients, occasionally convening\nmultidisciplinary team (MDT) collaboration, this study investigated the\nfeasibility and value of using a Large Language Model (LLM)-based multi-agent\nsystem (MAS) for safer therapy recommendations. We designed a single agent and\na MAS framework simulating MDT decision-making by enabling discussion among LLM\nagents to resolve medical conflicts. The systems were evaluated on therapy\nplanning tasks for multimorbidity patients using benchmark cases. We compared\nMAS performance with single-agent approaches and real-world benchmarks. An\nimportant contribution of our study is the definition of evaluation metrics\nthat go beyond the technical precision and recall and allow the inspection of\nclinical goals met and medication burden of the proposed advices to a gold\nstandard benchmark. Our results show that with current LLMs, a single agent GP\nperforms as well as MDTs. The best-scoring models provide correct\nrecommendations that address all clinical goals, yet the advices are\nincomplete. Some models also present unnecessary medications, resulting in\nunnecessary conflicts between medication and conditions or drug-drug\ninteractions.", "AI": {"tldr": "\u7814\u7a76\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u4e3a\u60a3\u6709\u591a\u79cd\u6162\u6027\u75c5\u7684\u60a3\u8005\u63d0\u4f9b\u66f4\u5b89\u5168\u7684\u6cbb\u7597\u5efa\u8bae\u65b9\u9762\u7684\u53ef\u884c\u6027\u548c\u4ef7\u503c\u3002\u8bbe\u8ba1\u5e76\u8bc4\u4f30\u4e86\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u7ed3\u679c\u663e\u793a\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u5355\u667a\u80fd\u4f53\u7684\u8868\u73b0\u4e0e\u591a\u5b66\u79d1\u56e2\u961f\u76f8\u5f53\uff0c\u4f46\u5efa\u8bae\u6709\u65f6\u4e0d\u5b8c\u6574\u6216\u5b58\u5728\u4e0d\u5fc5\u8981\u7684\u836f\u7269\u51b2\u7a81\u3002", "motivation": "\u7531\u4e8e\u6cbb\u7597\u51b2\u7a81\u7684\u98ce\u9669\uff0c\u4e3a\u60a3\u6709\u591a\u79cd\u6162\u6027\u75c5\u7684\u60a3\u8005\u63a8\u8350\u6cbb\u7597\u65b9\u6cd5\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u5b58\u5728\u53ef\u6269\u5c55\u6027\u7684\u9650\u5236\u3002\u53d7\u5230\u5168\u79d1\u533b\u751f\u7ba1\u7406\u591a\u75c5\u75c7\u60a3\u8005\u65b9\u5f0f\u7684\u542f\u53d1\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u8ba8\u4f7f\u7528\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8fdb\u884c\u66f4\u5b89\u5168\u7684\u6cbb\u7597\u63a8\u8350\u7684\u53ef\u884c\u6027\u548c\u4ef7\u503c\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5355\u667a\u80fd\u4f53\u548c\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u6a21\u62df\u591a\u5b66\u79d1\u56e2\u961f\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u901a\u8fc7\u8ba9\u667a\u80fd\u4f53\u4e4b\u95f4\u8fdb\u884c\u8ba8\u8bba\u4ee5\u89e3\u51b3\u533b\u7597\u51b2\u7a81\u3002\u8be5\u7cfb\u7edf\u5728\u591a\u75c5\u75c7\u60a3\u8005\u7684\u6cbb\u7597\u8ba1\u5212\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u4e0e\u5355\u667a\u80fd\u4f53\u65b9\u6cd5\u548c\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u5355\u667a\u80fd\u4f53\u5168\u79d1\u533b\u751f\u7684\u8868\u73b0\u4e0e\u591a\u5b66\u79d1\u56e2\u961f\u76f8\u5f53\u3002\u8868\u73b0\u6700\u597d\u7684\u6a21\u578b\u80fd\u591f\u63d0\u4f9b\u6b63\u786e\u5730\u89e3\u51b3\u6240\u6709\u4e34\u5e8a\u76ee\u6807\u7684\u5efa\u8bae\uff0c\u4f46\u8fd9\u4e9b\u5efa\u8bae\u6709\u65f6\u662f\u4e0d\u5b8c\u6574\u7684\u3002\u4e00\u4e9b\u6a21\u578b\u8fd8\u63d0\u51fa\u4e86\u4e0d\u5fc5\u8981\u7684\u836f\u7269\uff0c\u5bfc\u81f4\u4e86\u836f\u7269\u548c\u75c5\u60c5\u4e4b\u95f4\u6216\u836f\u7269\u4e0e\u836f\u7269\u4e4b\u95f4\u7684\u4e0d\u5fc5\u8981\u51b2\u7a81\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u867d\u7136\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53ef\u4ee5\u5728\u6cbb\u7597\u89c4\u5212\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4ecd\u7136\u9700\u8981\u8fdb\u4e00\u6b65\u5b8c\u5584\uff0c\u4ee5\u786e\u4fdd\u5efa\u8bae\u7684\u5168\u9762\u6027\u548c\u5b89\u5168\u6027\u3002\u6b64\u5916\uff0c\u7814\u7a76\u5b9a\u4e49\u4e86\u8d85\u8d8a\u6280\u672f\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u7684\u8bc4\u4ef7\u6307\u6807\uff0c\u5141\u8bb8\u68c0\u67e5\u6240\u63d0\u5efa\u8bae\u662f\u5426\u7b26\u5408\u4e34\u5e8a\u76ee\u6807\u53ca\u836f\u7269\u8d1f\u62c5\u3002"}}
{"id": "2507.10614", "pdf": "https://arxiv.org/pdf/2507.10614", "abs": "https://arxiv.org/abs/2507.10614", "authors": ["Fei Liu", "Rui Zhang", "Xi Lin", "Zhichao Lu", "Qingfu Zhang"], "title": "Fine-tuning Large Language Model for Automated Algorithm Design", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The integration of large language models (LLMs) into automated algorithm\ndesign has shown promising potential. A prevalent approach embeds LLMs within\nsearch routines to iteratively generate and refine candidate algorithms.\nHowever, most existing methods rely on off-the-shelf LLMs trained for general\ncoding tasks,leaving a key question open: Do we need LLMs specifically tailored\nfor algorithm design? If so, how can such LLMs be effectively obtained and how\nwell can they generalize across different algorithm design tasks? In this\npaper, we take a first step toward answering these questions by exploring\nfine-tuning of LLMs for algorithm design. We introduce a Diversity-Aware Rank\nbased (DAR) sampling strategy to balance training data diversity and quality,\nthen we leverage direct preference optimization to efficiently align LLM\noutputs with task objectives. Our experiments, conducted on\nLlama-3.2-1B-Instruct and Llama- 3.1-8B-Instruct, span three distinct algorithm\ndesign tasks. Results suggest that finetuned LLMs can significantly outperform\ntheir off-the-shelf counterparts with the smaller Llama-3.2-1B-Instruct and\nmatch the larger Llama-3.1-8B-Instruct on the admissible set problem. Moreover,\nwe observe promising generalization: LLMs finetuned on specific algorithm\ndesign tasks also improve performance on related tasks with varying settings.\nThese findings highlight the value of task-specific adaptation for LLMs in\nalgorithm design and open new avenues for future research.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4e3a\u7b97\u6cd5\u8bbe\u8ba1\u5b9a\u5236\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u6f5c\u529b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5c55\u793a\u4e86\u5fae\u8c03\u540e\u7684LLMs\u5728\u4e0d\u540c\u4efb\u52a1\u4e0a\u7684\u4f18\u8d8a\u8868\u73b0\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u591a\u4f9d\u8d56\u4e8e\u4e3a\u901a\u7528\u7f16\u7a0b\u4efb\u52a1\u8bad\u7ec3\u7684\u73b0\u6210LLMs\uff0c\u5bf9\u4e8e\u662f\u5426\u9700\u8981\u7279\u5b9a\u4e3a\u7b97\u6cd5\u8bbe\u8ba1\u5b9a\u5236\u7684LLMs\u53ca\u5176\u5982\u4f55\u83b7\u5f97\u548c\u8de8\u4efb\u52a1\u8868\u73b0\u7684\u95ee\u9898\u5c1a\u672a\u89e3\u7b54\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u591a\u6837\u6027\u611f\u77e5\u6392\u5e8f\uff08DAR\uff09\u91c7\u6837\u7b56\u7565\u4ee5\u5e73\u8861\u8bad\u7ec3\u6570\u636e\u7684\u591a\u6837\u6027\u548c\u8d28\u91cf\uff0c\u5e76\u4f7f\u7528\u76f4\u63a5\u504f\u597d\u4f18\u5316\u9ad8\u6548\u5bf9\u9f50LLM\u8f93\u51fa\u4e0e\u4efb\u52a1\u76ee\u6807\u3002", "result": "\u5fae\u8c03\u540e\u7684LLMs\u5728\u4e09\u9879\u4e0d\u540c\u7684\u7b97\u6cd5\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u663e\u8457\u8d85\u8d8a\u4e86\u5176\u73b0\u6210\u7248\u672c\uff0c\u5728\u8f83\u5c0f\u7684Llama-3.2-1B-Instruct\u4e0a\u751a\u81f3\u5339\u914d\u4e86\u8f83\u5927\u7684Llama-3.1-8B-Instruct\u7684\u8868\u73b0\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u9488\u5bf9\u5177\u4f53\u4efb\u52a1\u8c03\u6574LLMs\u5728\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2507.10854", "pdf": "https://arxiv.org/pdf/2507.10854", "abs": "https://arxiv.org/abs/2507.10854", "authors": ["Thomas Dalton", "Hemanth Gowda", "Girish Rao", "Sachin Pargi", "Alireza Hadj Khodabakhshi", "Joseph Rombs", "Stephan Jou", "Manish Marwah"], "title": "PhreshPhish: A Real-World, High-Quality, Large-Scale Phishing Website Dataset and Benchmark", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Phishing remains a pervasive and growing threat, inflicting heavy economic\nand reputational damage. While machine learning has been effective in real-time\ndetection of phishing attacks, progress is hindered by lack of large,\nhigh-quality datasets and benchmarks. In addition to poor-quality due to\nchallenges in data collection, existing datasets suffer from leakage and\nunrealistic base rates, leading to overly optimistic performance results. In\nthis paper, we introduce PhreshPhish, a large-scale, high-quality dataset of\nphishing websites that addresses these limitations. Compared to existing public\ndatasets, PhreshPhish is substantially larger and provides significantly higher\nquality, as measured by the estimated rate of invalid or mislabeled data\npoints. Additionally, we propose a comprehensive suite of benchmark datasets\nspecifically designed for realistic model evaluation by minimizing leakage,\nincreasing task difficulty, enhancing dataset diversity, and adjustment of base\nrates more likely to be seen in the real world. We train and evaluate multiple\nsolution approaches to provide baseline performance on the benchmark sets. We\nbelieve the availability of this dataset and benchmarks will enable realistic,\nstandardized model comparison and foster further advances in phishing\ndetection. The datasets and benchmarks are available on Hugging Face\n(https://huggingface.co/datasets/phreshphish/phreshphish).", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86PhreshPhish\uff0c\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u7684\u9493\u9c7c\u7f51\u7ad9\u6570\u636e\u96c6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u5957\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u6570\u636e\u96c6\u5b58\u5728\u7684\u95ee\u9898\uff0c\u63a8\u52a8\u9493\u9c7c\u653b\u51fb\u68c0\u6d4b\u9886\u57df\u7684\u8fdb\u6b65\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5728\u5b9e\u65f6\u68c0\u6d4b\u9493\u9c7c\u653b\u51fb\u65b9\u9762\u867d\u7136\u6709\u6548\uff0c\u4f46\u8fdb\u5c55\u53d7\u5230\u7f3a\u4e4f\u5927\u578b\u3001\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6\u548c\u57fa\u51c6\u7684\u963b\u788d\u3002\u73b0\u6709\u7684\u6570\u636e\u96c6\u5b58\u5728\u8d28\u91cf\u95ee\u9898\u3001\u6cc4\u6f0f\u548c\u4e0d\u73b0\u5b9e\u7684\u57fa\u7840\u7387\u7b49\u95ee\u9898\uff0c\u5bfc\u81f4\u6027\u80fd\u7ed3\u679c\u8fc7\u4e8e\u4e50\u89c2\u3002", "method": "\u5f15\u5165\u4e86PhreshPhish\uff0c\u4e00\u4e2a\u66f4\u5927\u89c4\u6a21\u4e14\u8d28\u91cf\u66f4\u9ad8\u7684\u9493\u9c7c\u7f51\u7ad9\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6cc4\u6f0f\u3001\u589e\u52a0\u4efb\u52a1\u96be\u5ea6\u3001\u589e\u5f3a\u6570\u636e\u96c6\u591a\u6837\u6027\u4ee5\u53ca\u8c03\u6574\u66f4\u8d34\u8fd1\u771f\u5b9e\u4e16\u754c\u7684\u57fa\u7840\u7387\uff0c\u8bbe\u8ba1\u4e86\u4e00\u5957\u4e13\u95e8\u7528\u4e8e\u5b9e\u9645\u6a21\u578b\u8bc4\u4f30\u7684\u7efc\u5408\u57fa\u51c6\u6570\u636e\u96c6\u3002", "result": "PhreshPhish\u6570\u636e\u96c6\u6bd4\u73b0\u6709\u7684\u516c\u5171\u6570\u636e\u96c6\u5927\u5f97\u591a\uff0c\u63d0\u4f9b\u4e86\u663e\u8457\u66f4\u9ad8\u7684\u8d28\u91cf\uff0c\u4f30\u8ba1\u65e0\u6548\u6216\u9519\u8bef\u6807\u8bb0\u7684\u6570\u636e\u70b9\u7387\u66f4\u4f4e\u3002\u8bad\u7ec3\u5e76\u8bc4\u4f30\u4e86\u591a\u79cd\u89e3\u51b3\u65b9\u6848\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u57fa\u51c6\u96c6\u4e0a\u7684\u57fa\u7ebf\u6027\u80fd\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u548c\u57fa\u51c6\u7684\u53ef\u7528\u6027\u5c06\u5b9e\u73b0\u73b0\u5b9e\u7684\u3001\u6807\u51c6\u5316\u7684\u6a21\u578b\u6bd4\u8f83\uff0c\u5e76\u4fc3\u8fdb\u9493\u9c7c\u68c0\u6d4b\u9886\u57df\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2507.10923", "pdf": "https://arxiv.org/pdf/2507.10923", "abs": "https://arxiv.org/abs/2507.10923", "authors": ["Yuhao Wang", "Keyan Ding", "Kehua Feng", "Zeyuan Wang", "Ming Qin", "Xiaotong Li", "Qiang Zhang", "Huajun Chen"], "title": "Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization", "categories": ["cs.AI"], "comment": "Accepted at ACL 2025 (Main Conference)", "summary": "Protein language models have emerged as powerful tools for sequence\ngeneration, offering substantial advantages in functional optimization and\ndenovo design. However, these models also present significant risks of\ngenerating harmful protein sequences, such as those that enhance viral\ntransmissibility or evade immune responses. These concerns underscore critical\nbiosafety and ethical challenges. To address these issues, we propose a\nKnowledge-guided Preference Optimization (KPO) framework that integrates prior\nknowledge via a Protein Safety Knowledge Graph. This framework utilizes an\nefficient graph pruning strategy to identify preferred sequences and employs\nreinforcement learning to minimize the risk of generating harmful proteins.\nExperimental results demonstrate that KPO effectively reduces the likelihood of\nproducing hazardous sequences while maintaining high functionality, offering a\nrobust safety assurance framework for applying generative models in\nbiotechnology.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6KPO\uff0c\u901a\u8fc7\u6574\u5408\u5148\u9a8c\u77e5\u8bc6\u548c\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u51cf\u5c11\u751f\u6210\u6709\u5bb3\u86cb\u767d\u8d28\u7684\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u7684\u86cb\u767d\u8d28\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u5e8f\u5217\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u4e5f\u5b58\u5728\u751f\u6210\u6709\u5bb3\u86cb\u767d\u8d28\u5e8f\u5217\u7684\u98ce\u9669\uff0c\u5982\u589e\u5f3a\u75c5\u6bd2\u4f20\u64ad\u6216\u9003\u907f\u514d\u75ab\u53cd\u5e94\u7684\u5e8f\u5217\uff0c\u8fd9\u5e26\u6765\u4e86\u91cd\u8981\u7684\u751f\u7269\u5b89\u5168\u548c\u4f26\u7406\u6311\u6218\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aKPO\u7684\u77e5\u8bc6\u5f15\u5bfc\u504f\u597d\u4f18\u5316\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u86cb\u767d\u8d28\u5b89\u5168\u77e5\u8bc6\u56fe\u8c31\u6574\u5408\u5148\u9a8c\u77e5\u8bc6\uff0c\u91c7\u7528\u9ad8\u6548\u7684\u56fe\u4fee\u526a\u7b56\u7565\u8bc6\u522b\u4f18\u9009\u5e8f\u5217\uff0c\u5e76\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6700\u5c0f\u5316\u751f\u6210\u6709\u5bb3\u86cb\u767d\u8d28\u7684\u98ce\u9669\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cKPO\u53ef\u4ee5\u6709\u6548\u964d\u4f4e\u4ea7\u751f\u5371\u9669\u5e8f\u5217\u7684\u53ef\u80fd\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u529f\u80fd\u6027\u3002", "conclusion": "KPO\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u5b89\u5168\u4fdd\u969c\u6846\u67b6\uff0c\u53ef\u7528\u4e8e\u751f\u7269\u6280\u672f\u4e2d\u5e94\u7528\u751f\u6210\u6a21\u578b\u7684\u5b89\u5168\u6027\u4fdd\u969c\u3002"}}
{"id": "2507.10616", "pdf": "https://arxiv.org/pdf/2507.10616", "abs": "https://arxiv.org/abs/2507.10616", "authors": ["Neel Rajani", "Aryo Pradipta Gema", "Seraphina Goldfarb-Tarrant", "Ivan Titov"], "title": "Scalpel vs. Hammer: GRPO Amplifies Existing Capabilities, SFT Replaces Them", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Training large language models (LLMs) for reasoning via maths and code\ndatasets has become a major new focus in LLM post-training. Two particularly\npopular approaches are reinforcement learning (RL) and supervised fine-tuning\n(SFT), but their training dynamics are poorly understood. We present a\ncomparative analysis of RL and SFT on the same maths problems with the same\nmodel and similar hyperparameters. We find that RL yields minor in-domain gains\non maths and slight degradation on knowledge-intensive benchmarks like MMLU,\nwhile both trends are more pronounced in SFT. We also analyse model parameters\nacross checkpoints, observing that both algorithms modify query and key weights\nthe most. Meanwhile, SFT exhibits greater updates and also affects mid-layer\nMLPs more, leading us to hypothesise that this may have caused the\nout-of-domain degradation. We therefore investigate whether freezing parts of\nthe model during training can mitigate the reduced performance on\nknowledge-intensive benchmarks. However, our results are inconclusive, with\nbenefits on GPQA:Diamond and degradation on other benchmarks. Taken together,\nour observations provide a preliminary indication for why RL amplifies existing\ncapabilities, while SFT replaces old skills with new ones.", "AI": {"tldr": "\u8bba\u6587\u6bd4\u8f83\u4e86\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u548c\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u8bad\u7ec3\u52a8\u6001\uff0c\u53d1\u73b0RL\u5bf9\u6570\u5b66\u6709\u5c0f\u5e45\u63d0\u5347\u4f46\u5bf9\u77e5\u8bc6\u5bc6\u96c6\u578b\u57fa\u51c6\u7a0d\u6709\u4e0b\u964d\uff1bSFT\u8fd9\u4e24\u65b9\u9762\u53d8\u5316\u66f4\u660e\u663e\u3002\u6a21\u578b\u53c2\u6570\u5206\u6790\u8868\u660e\uff0cSFT\u5bf9\u4e2d\u5c42MLPs\u5f71\u54cd\u66f4\u5927\uff0c\u53ef\u80fd\u662f\u5bfc\u81f4\u9886\u57df\u5916\u6027\u80fd\u4e0b\u964d\u7684\u539f\u56e0\u3002\u90e8\u5206\u6a21\u578b\u51bb\u7ed3\u8bad\u7ec3\u7684\u5c1d\u8bd5\u7ed3\u679c\u4e0d\u660e\u786e\u3002\u6574\u4f53\u89c2\u5bdf\u8868\u660eRL\u653e\u5927\u73b0\u6709\u80fd\u529b\uff0c\u800cSFT\u7528\u65b0\u6280\u80fd\u66ff\u6362\u65e7\u6280\u80fd\u3002", "motivation": "\u4e86\u89e3\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u548c\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u540e\u8bad\u7ec3\u9636\u6bb5\u9488\u5bf9\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u6570\u636e\u96c6\u7684\u8bad\u7ec3\u52a8\u6001\uff0c\u4ee5\u89e3\u91ca\u4e3a\u4ec0\u4e48\u5b83\u4eec\u5728\u9886\u57df\u5185\u548c\u9886\u57df\u5916\u7684\u8868\u73b0\u4e0d\u540c\u3002", "method": "\u5728\u540c\u4e00\u6570\u5b66\u95ee\u9898\u4e0a\uff0c\u4f7f\u7528\u76f8\u540c\u7684\u6a21\u578b\u548c\u76f8\u4f3c\u7684\u8d85\u53c2\u6570\uff0c\u5bf9RL\u548cSFT\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u3002\u68c0\u67e5\u4e0d\u540c\u68c0\u67e5\u70b9\u7684\u6a21\u578b\u53c2\u6570\uff0c\u89c2\u5bdf\u7b97\u6cd5\u5982\u4f55\u4fee\u6539\u67e5\u8be2\u548c\u952e\u6743\u91cd\u3002\u5c1d\u8bd5\u901a\u8fc7\u5728\u8bad\u7ec3\u671f\u95f4\u51bb\u7ed3\u6a21\u578b\u7684\u90e8\u5206\u6765\u51cf\u8f7b\u77e5\u8bc6\u5bc6\u96c6\u578b\u57fa\u51c6\u4e0a\u7684\u6027\u80fd\u4e0b\u964d\u3002", "result": "RL\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u6709\u8f7b\u5fae\u7684\u9886\u57df\u5185\u589e\u76ca\uff0c\u800c\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u57fa\u51c6\u5982MMLU\u4e0a\u7565\u6709\u4e0b\u964d\uff1b\u8fd9\u4e9b\u8d8b\u52bf\u5728SFT\u4e2d\u66f4\u4e3a\u660e\u663e\u3002SFT\u4e0d\u4ec5\u66f4\u591a\u5730\u66f4\u65b0\u4e86\u67e5\u8be2\u548c\u952e\u6743\u91cd\uff0c\u8fd8\u5f71\u54cd\u4e86\u4e2d\u5c42MLPs\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u4e86\u9886\u57df\u5916\u6027\u80fd\u7684\u4e0b\u964d\u3002\u90e8\u5206\u6a21\u578b\u51bb\u7ed3\u8bad\u7ec3\u7684\u7ed3\u679c\u597d\u574f\u53c2\u534a\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u521d\u6b65\u8868\u660e\uff0cRL\u503e\u5411\u4e8e\u653e\u5927\u6a21\u578b\u73b0\u6709\u7684\u80fd\u529b\uff0c\u800cSFT\u5219\u503e\u5411\u4e8e\u7528\u65b0\u7684\u6280\u80fd\u66ff\u6362\u65e7\u7684\u6280\u80fd\u3002"}}
{"id": "2507.10873", "pdf": "https://arxiv.org/pdf/2507.10873", "abs": "https://arxiv.org/abs/2507.10873", "authors": ["Danyu Sun", "Jinghuai Zhang", "Jiacen Xu", "Yu Zheng", "Yuan Tian", "Zhou Li"], "title": "From Alerts to Intelligence: A Novel LLM-Aided Framework for Host-based Intrusion Detection", "categories": ["cs.CR"], "comment": null, "summary": "Host-based intrusion detection system (HIDS) is a key defense component to\nprotect the organizations from advanced threats like Advanced Persistent\nThreats (APT). By analyzing the fine-grained logs with approaches like data\nprovenance, HIDS has shown successes in capturing sophisticated attack traces.\nDespite the progresses embarked by the research community and industry, HIDS\nstill frequently encounters backlash from their operators in the deployed\nenvironments, due to issues like high false-positive rate, inconsistent\noutcomes across environments and human-unfriendly detection results. Large\nLanguage Models (LLMs) have great potentials to advance the state of HIDS,\ngiven their extensive knowledge of attack techniques and their ability to\ndetect anomalies through semantic analysis, anchored by recent studies. Yet,\nour preliminary analysis indicates that building an HIDS by naively prompting\nan LLM is unlikely to succeed. In this work, we explore the direction of\nbuilding a customized LLM pipeline for HIDS and develop a system named SHIELD.\nSHIELD addresses challenges related to LLM's token limits, confusion of\nbackground noises, etc., by integrating a variety of techniques like\nevent-level Masked Autoencoder (MAE) for attack window detection, attack\nevidence identification and expansion, Deterministic Data Augmentation (DDA)\nfor profiling normal activities, and multi-purpose prompting that guides the\nLLM to conduct precise and interpretable attack investigations. Extensive\nexperiments on three log datasets (DARPA-E3, NodLink-simulated-data and\nATLASv2) show that SHIELD consistently achieves outstanding performance in\ncomparison with 5 representative HIDS. These findings highlight the potential\nof LLMs as powerful tools for intrusion detection and pave the way for future\nresearch in this domain.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u4e3b\u673a\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edfSHIELD\uff0c\u5b83\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u591a\u79cd\u6280\u672f\u5982\u4e8b\u4ef6\u7ea7\u522b\u7684\u63a9\u7801\u81ea\u52a8\u7f16\u7801\u5668\u3001\u786e\u5b9a\u6027\u6570\u636e\u589e\u5f3a\u548c\u591a\u7528\u9014\u63d0\u793a\uff0c\u6765\u89e3\u51b3\u4f20\u7edfHIDS\u5b58\u5728\u7684\u95ee\u9898\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u51fa\u8272\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684\u57fa\u4e8e\u4e3b\u673a\u7684\u5165\u4fb5\u68c0\u6d4b\u7cfb\u7edf\uff08HIDS\uff09\u867d\u7136\u53d6\u5f97\u4e86\u4e00\u4e9b\u6210\u529f\uff0c\u4f46\u4ecd\u7136\u5b58\u5728\u9ad8\u8bef\u62a5\u7387\u3001\u4e0d\u540c\u73af\u5883\u4e0b\u7684\u7ed3\u679c\u4e0d\u4e00\u81f4\u4ee5\u53ca\u68c0\u6d4b\u7ed3\u679c\u5bf9\u4eba\u7c7b\u4e0d\u53cb\u597d\u7b49\u95ee\u9898\u3002\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5177\u6709\u4e30\u5bcc\u7684\u653b\u51fb\u6280\u672f\u77e5\u8bc6\u548c\u901a\u8fc7\u8bed\u4e49\u5206\u6790\u68c0\u6d4b\u5f02\u5e38\u7684\u80fd\u529b\uff0c\u53ef\u80fd\u4e3a\u6539\u8fdbHIDS\u63d0\u4f9b\u65b0\u7684\u9014\u5f84\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u540d\u4e3aSHIELD\u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u7ed3\u5408\u4e86\u4e8b\u4ef6\u7ea7\u522b\u63a9\u7801\u81ea\u52a8\u7f16\u7801\u5668\uff08MAE\uff09\u3001\u786e\u5b9a\u6027\u6570\u636e\u589e\u5f3a\uff08DDA\uff09\u548c\u591a\u7528\u9014\u63d0\u793a\u7b49\u6280\u672f\uff0c\u4ee5\u514b\u670dLLM\u4ee4\u724c\u9650\u5236\u3001\u80cc\u666f\u566a\u97f3\u5e72\u6270\u7b49\u6311\u6218\uff0c\u5e76\u5f15\u5bfcLLM\u8fdb\u884c\u7cbe\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u653b\u51fb\u8c03\u67e5\u3002", "result": "\u5728\u4e09\u4e2a\u65e5\u5fd7\u6570\u636e\u96c6\uff08DARPA-E3\u3001NodLink-simulated-data\u548cATLASv2\uff09\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e5\u4e2a\u4ee3\u8868\u6027\u7684HIDS\u76f8\u6bd4\uff0cSHIELD\u59cb\u7ec8\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86LLM\u4f5c\u4e3a\u5165\u4fb5\u68c0\u6d4b\u5f3a\u5927\u5de5\u5177\u7684\u6f5c\u529b\uff0c\u5e76\u4e3a\u6b64\u9886\u57df\u7684\u672a\u6765\u7814\u7a76\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2507.10993", "pdf": "https://arxiv.org/pdf/2507.10993", "abs": "https://arxiv.org/abs/2507.10993", "authors": ["Emir Durakovic", "Min-Hong Shih"], "title": "Modeling Habitat Shifts: Integrating Convolutional Neural Networks and Tabular Data for Species Migration Prediction", "categories": ["cs.AI"], "comment": "This paper uses a lightly modified version of the AAAI 2025 LaTeX\n  style for formatting consistency. It is not a submission to AAAI and does not\n  include any AAAI-specific headers, footers, or metadata", "summary": "Due to climate-induced changes, many habitats are experiencing range shifts\naway from their traditional geographic locations (Piguet, 2011). We propose a\nsolution to accurately model whether bird species are present in a specific\nhabitat through the combination of Convolutional Neural Networks (CNNs)\n(O'Shea, 2015) and tabular data. Our approach makes use of satellite imagery\nand environmental features (e.g., temperature, precipitation, elevation) to\npredict bird presence across various climates. The CNN model captures spatial\ncharacteristics of landscapes such as forestation, water bodies, and\nurbanization, whereas the tabular method uses ecological and geographic data.\nBoth systems predict the distribution of birds with an average accuracy of 85%,\noffering a scalable but reliable method to understand bird migration.", "AI": {"tldr": "\u7ed3\u5408\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u548c\u8868\u683c\u6570\u636e\u7684\u65b9\u6cd5\u6765\u9884\u6d4b\u9e1f\u7c7b\u5728\u4e0d\u540c\u6c14\u5019\u4e0b\u7684\u5b58\u5728\uff0c\u5e73\u5747\u51c6\u786e\u7387\u4e3a85%", "motivation": "\u7531\u4e8e\u6c14\u5019\u53d8\u5316\uff0c\u8bb8\u591a\u6816\u606f\u5730\u6b63\u5728\u7ecf\u5386\u8303\u56f4\u8f6c\u79fb\uff0c\u9700\u8981\u4e00\u79cd\u51c6\u786e\u7684\u6a21\u578b\u6765\u9884\u6d4b\u7279\u5b9a\u6816\u606f\u5730\u4e2d\u662f\u5426\u5b58\u5728\u9e1f\u7c7b\u7269\u79cd", "method": "\u4f7f\u7528\u536b\u661f\u56fe\u50cf\u548c\u73af\u5883\u7279\u5f81\uff08\u4f8b\u5982\u6e29\u5ea6\u3001\u964d\u6c34\u91cf\u3001\u6d77\u62d4\uff09\u7684\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u4ee5\u53ca\u751f\u6001\u548c\u5730\u7406\u6570\u636e\u7684\u8868\u683c\u65b9\u6cd5\u6765\u9884\u6d4b\u9e1f\u7c7b\u7684\u5b58\u5728", "result": "\u4e24\u79cd\u7cfb\u7edf\u90fd\u4ee585%\u7684\u5e73\u5747\u51c6\u786e\u7387\u9884\u6d4b\u4e86\u9e1f\u7c7b\u7684\u5206\u5e03", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u7406\u89e3\u9e1f\u7c7b\u8fc1\u5f99"}}
{"id": "2507.10618", "pdf": "https://arxiv.org/pdf/2507.10618", "abs": "https://arxiv.org/abs/2507.10618", "authors": ["Peter Barnett"], "title": "Compute Requirements for Algorithmic Innovation in Frontier AI Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Algorithmic innovation in the pretraining of large language models has driven\na massive reduction in the total compute required to reach a given level of\ncapability. In this paper we empirically investigate the compute requirements\nfor developing algorithmic innovations. We catalog 36 pre-training algorithmic\ninnovations used in Llama 3 and DeepSeek-V3. For each innovation we estimate\nboth the total FLOP used in development and the FLOP/s of the hardware\nutilized. Innovations using significant resources double in their requirements\neach year. We then use this dataset to investigate the effect of compute caps\non innovation. Our analysis suggests that compute caps alone are unlikely to\ndramatically slow AI algorithmic progress. Even stringent compute caps -- such\nas capping total operations to the compute used to train GPT-2 or capping\nhardware capacity to 8 H100 GPUs -- could still have allowed for half of the\ncataloged innovations.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u7b97\u6cd5\u521b\u65b0\u6240\u9700\u7684\u8ba1\u7b97\u8d44\u6e90\uff0c\u5e76\u5206\u6790\u4e86\u8ba1\u7b97\u4e0a\u9650\u5bf9\u7b97\u6cd5\u521b\u65b0\u7684\u5f71\u54cd\u3002", "motivation": "\u4e86\u89e3\u5f00\u53d1\u7b97\u6cd5\u521b\u65b0\u6240\u9700\u7684\u8ba1\u7b97\u8d44\u6e90\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u9700\u6c42\u968f\u65f6\u95f4\u7684\u53d8\u5316\u60c5\u51b5\uff0c\u8bc4\u4f30\u8ba1\u7b97\u4e0a\u9650\u662f\u5426\u80fd\u663e\u8457\u51cf\u7f13AI\u7b97\u6cd5\u7684\u8fdb\u6b65\u3002", "method": "\u6536\u96c6\u5e76\u5206\u6790\u4e8636\u79cd\u7528\u4e8eLlama 3\u548cDeepSeek-V3\u7684\u9884\u8bad\u7ec3\u7b97\u6cd5\u521b\u65b0\uff0c\u4f30\u8ba1\u6bcf\u79cd\u521b\u65b0\u5728\u5f00\u53d1\u4e2d\u4f7f\u7528\u7684\u603bFLOP\u548c\u786c\u4ef6\u7684FLOP/s\u3002", "result": "\u4f7f\u7528\u5927\u91cf\u8d44\u6e90\u7684\u521b\u65b0\u6bcf\u5e74\u7684\u9700\u6c42\u7ffb\u500d\uff0c\u4f46\u5373\u4f7f\u662f\u6709\u4e25\u683c\u9650\u5236\u7684\u8ba1\u7b97\u4e0a\u9650\u4e5f\u5141\u8bb8\u4e00\u534a\u4ee5\u4e0a\u7684\u8bb0\u5f55\u5728\u6848\u7684\u521b\u65b0\u3002", "conclusion": "\u8ba1\u7b97\u4e0a\u9650\u5355\u72ec\u5b58\u5728\u4e0d\u592a\u53ef\u80fd\u663e\u8457\u51cf\u7f13AI\u7b97\u6cd5\u7684\u8fdb\u6b65\u3002"}}
{"id": "2507.10898", "pdf": "https://arxiv.org/pdf/2507.10898", "abs": "https://arxiv.org/abs/2507.10898", "authors": ["Jugal Gajjar", "Kamalasankari Subramaniakuppusamy", "Noha El Kachach"], "title": "MalCodeAI: Autonomous Vulnerability Detection and Remediation via Language Agnostic Code Reasoning", "categories": ["cs.CR", "cs.AI", "cs.SE"], "comment": "6 pages, 4 figures, accepted for publication in IEEE 26th\n  International Conference on Information Reuse and Integration (IRI 2025)", "summary": "The growing complexity of cyber threats and the limitations of traditional\nvulnerability detection tools necessitate novel approaches for securing\nsoftware systems. We introduce MalCodeAI, a language-agnostic, multi-stage AI\npipeline for autonomous code security analysis and remediation. MalCodeAI\ncombines code decomposition and semantic reasoning using fine-tuned\nQwen2.5-Coder-3B-Instruct models, optimized through Low-Rank Adaptation (LoRA)\nwithin the MLX framework, and delivers scalable, accurate results across 14\nprogramming languages. In Phase 1, the model achieved a validation loss as low\nas 0.397 for functional decomposition and summarization of code segments after\n200 iterations, 6 trainable layers, and a learning rate of 2 x 10^(-5). In\nPhase 2, for vulnerability detection and remediation, it achieved a best\nvalidation loss of 0.199 using the same number of iterations and trainable\nlayers but with an increased learning rate of 4 x 10^(-5), effectively\nidentifying security flaws and suggesting actionable fixes. MalCodeAI supports\nred-hat-style exploit tracing, CVSS-based risk scoring, and zero-shot\ngeneralization to detect complex, zero-day vulnerabilities. In a qualitative\nevaluation involving 15 developers, the system received high scores in\nusefulness (mean 8.06/10), interpretability (mean 7.40/10), and readability of\noutputs (mean 7.53/10), confirming its practical value in real-world\ndevelopment workflows. This work marks a significant advancement toward\nintelligent, explainable, and developer-centric software security solutions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aMalCodeAI\u7684\u591a\u9636\u6bb5AI\u6d41\u6c34\u7ebf\uff0c\u7528\u4e8e\u81ea\u52a8\u4ee3\u7801\u5b89\u5168\u5206\u6790\u548c\u4fee\u590d\u3002\u5b83\u572814\u79cd\u7f16\u7a0b\u8bed\u8a00\u4e2d\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u51c6\u786e\u7684\u7ed3\u679c\uff0c\u5e76\u5728\u4e24\u4e2a\u9636\u6bb5\u4e2d\u5206\u522b\u5b9e\u73b0\u4e860.397\u548c0.199\u7684\u9a8c\u8bc1\u635f\u5931\u3002\u7cfb\u7edf\u5728\u5b9e\u9645\u5f00\u53d1\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u83b7\u5f97\u4e86\u9ad8\u5ea6\u8bc4\u4ef7\uff0c\u7279\u522b\u662f\u5728\u6709\u7528\u6027\u548c\u89e3\u91ca\u6027\u65b9\u9762\u3002", "motivation": "\u7f51\u7edc\u5a01\u80c1\u65e5\u76ca\u590d\u6742\u4ee5\u53ca\u4f20\u7edf\u6f0f\u6d1e\u68c0\u6d4b\u5de5\u5177\u7684\u5c40\u9650\u6027\uff0c\u4fc3\u4f7f\u4e86\u5bfb\u627e\u65b0\u7684\u65b9\u6cd5\u6765\u4fdd\u969c\u8f6f\u4ef6\u7cfb\u7edf\u7684\u5b89\u5168\u3002", "method": "MalCodeAI\u4f7f\u7528\u4e86Qwen2.5-Coder-3B-Instruct\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u5206\u89e3\u548c\u8bed\u4e49\u63a8\u7406\uff0c\u5e76\u901a\u8fc7\u4f4e\u79e9\u9002\u5e94\uff08LoRA\uff09\u5728MLX\u6846\u67b6\u5185\u8fdb\u884c\u4e86\u4f18\u5316\u3002\u5b83\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\u662f\u529f\u80fd\u5206\u89e3\u548c\u4ee3\u7801\u6bb5\u603b\u7ed3\uff1b\u7b2c\u4e8c\u9636\u6bb5\u662f\u6f0f\u6d1e\u68c0\u6d4b\u548c\u4fee\u590d\u3002", "result": "\u5728\u5b9a\u91cf\u8bc4\u4f30\u4e2d\uff0cMalCodeAI\u5728\u529f\u80fd\u5206\u89e3\u548c\u603b\u7ed3\u4ee3\u7801\u6bb5\u65f6\u8fbe\u5230\u4e860.397\u7684\u9a8c\u8bc1\u635f\u5931\uff0c\u5728\u6f0f\u6d1e\u68c0\u6d4b\u548c\u4fee\u590d\u65f6\u8fbe\u5230\u4e860.199\u7684\u9a8c\u8bc1\u635f\u5931\u3002\u5728\u5b9a\u6027\u8bc4\u4f30\u4e2d\uff0c15\u540d\u5f00\u53d1\u8005\u5bf9\u7cfb\u7edf\u7684\u5b9e\u7528\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8f93\u51fa\u7684\u6613\u8bfb\u6027\u7ed9\u4e88\u4e86\u9ad8\u5206\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u6807\u5fd7\u7740\u5411\u667a\u80fd\u3001\u53ef\u89e3\u91ca\u4e14\u4ee5\u5f00\u53d1\u4eba\u5458\u4e3a\u4e2d\u5fc3\u7684\u8f6f\u4ef6\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u8fc8\u8fdb\u4e86\u4e00\u5927\u6b65\u3002"}}
{"id": "2507.11060", "pdf": "https://arxiv.org/pdf/2507.11060", "abs": "https://arxiv.org/abs/2507.11060", "authors": ["Yilmazcan Ozyurt", "Tunaberk Almaci", "Stefan Feuerriegel", "Mrinmaya Sachan"], "title": "Personalized Exercise Recommendation with Semantically-Grounded Knowledge Tracing", "categories": ["cs.AI"], "comment": null, "summary": "We introduce ExRec, a general framework for personalized exercise\nrecommendation with semantically-grounded knowledge tracing. Our method builds\non the observation that existing exercise recommendation approaches simulate\nstudent performance via knowledge tracing (KT) but they often overlook two key\naspects: (a) the semantic content of questions and (b) the sequential,\nstructured progression of student learning. To address this, our ExRec presents\nan end-to-end pipeline, from annotating the KCs of questions and learning their\nsemantic representations to training KT models and optimizing several\nreinforcement learning (RL) methods. Moreover, we improve standard\nQ-learning-based continuous RL methods via a tailored model-based value\nestimation (MVE) approach that directly leverages the components of KT model in\nestimating cumulative knowledge improvement. We validate the effectiveness of\nour ExRec using various RL methods across four real-world tasks with different\neducational goals in online math learning. We further show that ExRec\ngeneralizes robustly to new, unseen questions and that it produces\ninterpretable student learning trajectories. Together, our findings highlight\nthe promise of KT-guided RL for effective personalization in education.", "AI": {"tldr": "ExRec\u662f\u9488\u5bf9\u4e2a\u6027\u5316\u8fd0\u52a8\u63a8\u8350\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u8bed\u4e49\u57fa\u7840\u7684\u77e5\u8bc6\u8ffd\u8e2a\u6765\u63d0\u9ad8\u5b66\u4e60\u6548\u679c\u3002\u8be5\u65b9\u6cd5\u89e3\u51b3\u4e86\u73b0\u6709\u7cfb\u7edf\u4e2d\u4e24\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u5373\u95ee\u9898\u7684\u8bed\u4e49\u5185\u5bb9\u548c\u5b66\u751f\u5b66\u4e60\u7684\u8fde\u7eed\u7ed3\u6784\u5316\u8fdb\u5c55\u3002\u5728\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5bf9\u65b0\u95ee\u9898\u7684\u5f3a\u5927\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u7684\u5b66\u751f\u5b66\u4e60\u8f68\u8ff9\u3002", "motivation": "\u73b0\u6709\u7684\u7ec3\u4e60\u63a8\u8350\u65b9\u6cd5\u867d\u7136\u53ef\u4ee5\u901a\u8fc7\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u62df\u5b66\u751f\u6210\u7ee9\uff0c\u4f46\u5e38\u5e38\u5ffd\u7565\u4e86\u95ee\u9898\u7684\u8bed\u4e49\u5185\u5bb9\u4ee5\u53ca\u5b66\u751f\u5b66\u4e60\u7684\u8fde\u7eed\u3001\u7ed3\u6784\u5316\u7684\u8fdb\u7a0b\u3002", "method": "ExRec\u63d0\u51fa\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u6d41\u7a0b\uff0c\u5305\u62ec\u6807\u6ce8\u95ee\u9898\u7684\u77e5\u8bc6\u6210\u5206\uff08KCs\uff09\uff0c\u5b66\u4e60\u5b83\u4eec\u7684\u8bed\u4e49\u8868\u793a\uff0c\u8bad\u7ec3\u77e5\u8bc6\u8ffd\u8e2a\u6a21\u578b\uff0c\u5e76\u4f18\u5316\u51e0\u79cd\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8fd8\u901a\u8fc7\u4e00\u79cd\u5b9a\u5236\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u4ef7\u503c\u8bc4\u4f30\u65b9\u6cd5\u6539\u8fdb\u4e86\u6807\u51c6\u7684Q\u5b66\u4e60\u8fde\u7eed\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "ExRec\u5728\u56db\u4e2a\u5177\u6709\u4e0d\u540c\u6559\u80b2\u76ee\u6807\u7684\u771f\u5b9e\u5728\u7ebf\u6570\u5b66\u5b66\u4e60\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5bf9\u65b0\u95ee\u9898\u7684\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4ea7\u751f\u4e86\u53ef\u89e3\u91ca\u7684\u5b66\u751f\u5b66\u4e60\u8f68\u8ff9\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4ee5\u77e5\u8bc6\u8ffd\u8e2a\u4e3a\u6307\u5bfc\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u6559\u80b2\u4e2d\u7684\u4e2a\u6027\u5316\u65b9\u9762\u5177\u6709\u5f88\u5927\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.10619", "pdf": "https://arxiv.org/pdf/2507.10619", "abs": "https://arxiv.org/abs/2507.10619", "authors": ["Oluwaseyi Giwa", "Tobi Awodunmila", "Muhammad Ahmed Mohsin", "Ahsan Bilal", "Muhammad Ali Jamshed"], "title": "Meta-Reinforcement Learning for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks", "categories": ["cs.LG", "cs.AI"], "comment": "5 pages, 6 figures, under review at IEEE Wireless Communications\n  Letters", "summary": "The dynamic allocation of spectrum in 5G / 6G networks is critical to\nefficient resource utilization. However, applying traditional deep\nreinforcement learning (DRL) is often infeasible due to its immense sample\ncomplexity and the safety risks associated with unguided exploration, which can\ncause severe network interference. To address these challenges, we propose a\nmeta-learning framework that enables agents to learn a robust initial policy\nand rapidly adapt to new wireless scenarios with minimal data. We implement\nthree meta-learning architectures, model-agnostic meta-learning (MAML),\nrecurrent neural network (RNN), and an attention-enhanced RNN, and evaluate\nthem against a non-meta-learning DRL algorithm, proximal policy optimization\n(PPO) baseline, in a simulated dynamic integrated access/backhaul (IAB)\nenvironment. Our results show a clear performance gap. The attention-based\nmeta-learning agent reaches a peak mean network throughput of 48 Mbps, while\nthe PPO baseline decreased drastically to 10 Mbps. Furthermore, our method\nreduces SINR and latency violations by more than 50% compared to PPO. It also\nshows quick adaptation, with a fairness index 0.7, showing better resource\nallocation. This work proves that meta-learning is a very effective and safer\noption for intelligent control in complex wireless systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u4ee5\u5b9e\u73b05G/6G\u7f51\u7edc\u9891\u8c31\u7684\u52a8\u6001\u5206\u914d\u3002\u76f8\u6bd4\u4f20\u7edf\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u8be5\u6846\u67b6\u4e0b\u7684\u6a21\u578b\u5728\u6a21\u62df\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7f51\u7edc\u541e\u5410\u91cf\u3001\u66f4\u4f4e\u7684SINR\u548c\u5ef6\u8fdf\u8fdd\u89c4\uff0c\u5e76\u4e14\u5177\u6709\u66f4\u597d\u7684\u8d44\u6e90\u5206\u914d\u516c\u5e73\u6027\u3002", "motivation": "\u57285G/6G\u7f51\u7edc\u4e2d\uff0c\u52a8\u6001\u5206\u914d\u9891\u8c31\u5bf9\u4e8e\u9ad8\u6548\u5229\u7528\u8d44\u6e90\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7531\u4e8e\u6837\u672c\u590d\u6742\u5ea6\u9ad8\u548c\u65e0\u6307\u5bfc\u63a2\u7d22\u5e26\u6765\u7684\u5b89\u5168\u98ce\u9669\uff0c\u901a\u5e38\u96be\u4ee5\u5e94\u7528\u3002", "method": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4e00\u4e2a\u5143\u5b66\u4e60\u6846\u67b6\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u591f\u5b66\u4e60\u7a33\u5065\u7684\u521d\u59cb\u7b56\u7565\uff0c\u5e76\u5feb\u901f\u9002\u5e94\u65b0\u7684\u65e0\u7ebf\u573a\u666f\uff0c\u540c\u65f6\u5c06\u6570\u636e\u9700\u6c42\u964d\u5230\u6700\u4f4e\u3002\u5b9e\u9a8c\u4e2d\u5b9e\u73b0\u4e86\u4e09\u79cd\u5143\u5b66\u4e60\u67b6\u6784\uff1a\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u5143\u5b66\u4e60\uff08MAML\uff09\u3001\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08RNN\uff09\u4ee5\u53ca\u5e26\u6709\u6ce8\u610f\u529b\u673a\u5236\u589e\u5f3a\u7684RNN\u3002", "result": "\u4e0e\u975e\u5143\u5b66\u4e60\u7684DRL\u7b97\u6cd5PPO\u57fa\u7ebf\u76f8\u6bd4\uff0c\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u5143\u5b66\u4e60\u4ee3\u7406\u8fbe\u5230\u4e8648 Mbps\u7684\u5cf0\u503c\u5e73\u5747\u7f51\u7edc\u541e\u5410\u91cf\uff0c\u800cPPO\u57fa\u7ebf\u5219\u6025\u5267\u4e0b\u964d\u81f310 Mbps\u3002\u6b64\u5916\uff0c\u672c\u65b9\u6cd5\u8fd8\u4f7fSINR\u548c\u5ef6\u8fdf\u8fdd\u89c4\u51cf\u5c11\u4e86\u8d85\u8fc750%\uff0c\u5e76\u4e14\u5177\u67090.7\u7684\u516c\u5e73\u6027\u6307\u6570\uff0c\u663e\u793a\u51fa\u66f4\u4f73\u7684\u8d44\u6e90\u5206\u914d\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\uff0c\u5143\u5b66\u4e60\u662f\u590d\u6742\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u667a\u80fd\u5316\u63a7\u5236\u7684\u6709\u6548\u4e14\u66f4\u5b89\u5168\u7684\u9009\u62e9\u3002"}}
{"id": "2507.10927", "pdf": "https://arxiv.org/pdf/2507.10927", "abs": "https://arxiv.org/abs/2507.10927", "authors": ["Jie Zhang", "Xiaohong Li", "Man Zheng", "Zhe Hou", "Guangdong Bai", "Ruitao Feng"], "title": "DVFS: A Dynamic Verifiable Fuzzy Search Service for Encrypted Cloud Data", "categories": ["cs.CR"], "comment": null, "summary": "Cloud storage introduces critical privacy challenges for encrypted data\nretrieval, where fuzzy multi-keyword search enables approximate matching while\npreserving data confidentiality. Existing solutions face fundamental trade-offs\nbetween security and efficiency: linear-search mechanisms provide adaptive\nsecurity but incur prohibitive overhead for large-scale data, while tree-based\nindexes improve performance at the cost of branch leakage vulnerabilities.\n  To address these limitations, we propose DVFS - a dynamic verifiable fuzzy\nsearch service with three core innovations: (1) An \\textit{adaptive-secure\nfuzzy search} method integrating locality-sensitive hashing with virtual binary\ntrees, eliminating branch leakage while reducing search complexity from linear\nto sublinear ($O(\\log n)$ time); (2) A \\textit{dual-repository version control}\nmechanism supporting dynamic updates with forward privacy, preventing\ninformation leakage during operations; (3) A \\textit{blockchain-based\nverification system} that ensures correctness and completeness via smart\ncontracts, achieving $O(\\log n)$ verification complexity.\n  Our solution advances secure encrypted retrieval by simultaneously resolving\nthe security-performance paradox and enabling trustworthy dynamic operations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDVFS\u670d\u52a1\uff0c\u901a\u8fc7\u4e09\u9879\u6838\u5fc3\u521b\u65b0\u89e3\u51b3\u4e86\u73b0\u6709\u6a21\u7cca\u591a\u5173\u952e\u5b57\u641c\u7d22\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u52a0\u5bc6\u6570\u636e\u68c0\u7d22\u89e3\u51b3\u65b9\u6848\u5728\u5b89\u5168\u6027\u548c\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u57fa\u672c\u7684\u6743\u8861\uff1a\u7ebf\u6027\u641c\u7d22\u673a\u5236\u867d\u7136\u63d0\u4f9b\u9002\u5e94\u6027\u5b89\u5168\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e0b\u4f1a\u4ea7\u751f\u8fc7\u9ad8\u7684\u5f00\u9500\uff1b\u57fa\u4e8e\u6811\u7684\u7d22\u5f15\u867d\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u4f46\u5374\u5e26\u6765\u4e86\u5206\u652f\u6cc4\u6f0f\u6f0f\u6d1e\u3002", "method": "DVFS\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u521b\u65b0\u70b9\uff1a1\uff09\u81ea\u9002\u5e94\u5b89\u5168\u6a21\u7cca\u641c\u7d22\u65b9\u6cd5\uff0c\u5c06\u5c40\u90e8\u654f\u611f\u54c8\u5e0c\u4e0e\u865a\u62df\u4e8c\u53c9\u6811\u7ed3\u5408\uff0c\u6d88\u9664\u5206\u652f\u6cc4\u6f0f\u5e76\u5c06\u641c\u7d22\u590d\u6742\u5ea6\u4ece\u7ebf\u6027\u964d\u4f4e\u5230\u5bf9\u6570\u65f6\u95f4\uff1b2\uff09\u53cc\u5b58\u50a8\u5e93\u7248\u672c\u63a7\u5236\u673a\u5236\uff0c\u652f\u6301\u52a8\u6001\u66f4\u65b0\u5e76\u5177\u6709\u524d\u5411\u9690\u79c1\uff0c\u9632\u6b62\u64cd\u4f5c\u671f\u95f4\u7684\u4fe1\u606f\u6cc4\u9732\uff1b3\uff09\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u786e\u4fdd\u6b63\u786e\u6027\u548c\u5b8c\u6574\u6027\uff0c\u5b9e\u73b0\u5bf9\u6570\u65f6\u95f4\u9a8c\u8bc1\u590d\u6742\u5ea6\u3002", "result": "\u8be5\u65b9\u6848\u901a\u8fc7\u540c\u65f6\u89e3\u51b3\u5b89\u5168-\u6027\u80fd\u6096\u8bba\u5e76\u542f\u7528\u53ef\u4fe1\u8d56\u7684\u52a8\u6001\u64cd\u4f5c\uff0c\u63a8\u8fdb\u4e86\u5b89\u5168\u52a0\u5bc6\u68c0\u7d22\u7684\u53d1\u5c55\u3002", "conclusion": "DVFS\u4f5c\u4e3a\u4e00\u4e2a\u52a8\u6001\u53ef\u9a8c\u8bc1\u6a21\u7cca\u641c\u7d22\u670d\u52a1\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u6a21\u7cca\u591a\u5173\u952e\u5b57\u641c\u7d22\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\uff0c\u8fd8\u4fdd\u8bc1\u4e86\u64cd\u4f5c\u7684\u53ef\u4fe1\u5ea6\u548c\u52a8\u6001\u66f4\u65b0\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2507.11079", "pdf": "https://arxiv.org/pdf/2507.11079", "abs": "https://arxiv.org/abs/2507.11079", "authors": ["Li Wang", "Qizhen Wu", "Lei Chen"], "title": "Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander", "categories": ["cs.AI"], "comment": null, "summary": "In multiple unmanned ground vehicle confrontations, autonomously evolving\nmulti-agent tactical decisions from situational awareness remain a significant\nchallenge. Traditional handcraft rule-based methods become vulnerable in the\ncomplicated and transient battlefield environment, and current reinforcement\nlearning methods mainly focus on action manipulation instead of strategic\ndecisions due to lack of interpretability. Here, we propose a vision-language\nmodel-based commander to address the issue of intelligent\nperception-to-decision reasoning in autonomous confrontations. Our method\nintegrates a vision language model for scene understanding and a lightweight\nlarge language model for strategic reasoning, achieving unified perception and\ndecision within a shared semantic space, with strong adaptability and\ninterpretability. Unlike rule-based search and reinforcement learning methods,\nthe combination of the two modules establishes a full-chain process, reflecting\nthe cognitive process of human commanders. Simulation and ablation experiments\nvalidate that the proposed approach achieves a win rate of over 80% compared\nwith baseline models.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u7684\u6307\u6325\u5b98\uff0c\u7528\u4e8e\u591a\u65e0\u4eba\u5730\u9762\u8f66\u8f86\u5bf9\u6297\u4e2d\u7684\u81ea\u4e3b\u6218\u672f\u51b3\u7b56\uff0c\u6574\u5408\u573a\u666f\u7406\u89e3\u548c\u6218\u7565\u63a8\u7406\u3002", "motivation": "\u4f20\u7edf\u624b\u5de5\u89c4\u5219\u65b9\u6cd5\u5728\u590d\u6742\u77ac\u606f\u4e07\u53d8\u7684\u6218\u573a\u73af\u5883\u4e2d\u53d8\u5f97\u8106\u5f31\uff0c\u800c\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u884c\u52a8\u64cd\u4f5c\u800c\u975e\u7b56\u7565\u51b3\u7b56\uff0c\u4e14\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u573a\u666f\u7406\u89e3\uff0c\u4ee5\u53ca\u8f7b\u91cf\u7ea7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6218\u7565\u63a8\u7406\uff0c\u5b9e\u73b0\u7edf\u4e00\u611f\u77e5\u548c\u51b3\u7b56\uff0c\u5e76\u5177\u6709\u5f3a\u9002\u5e94\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u4eff\u771f\u548c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0c\u80dc\u7387\u8d85\u8fc780%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u6307\u6325\u5b98\u80fd\u591f\u89e3\u51b3\u81ea\u4e3b\u5bf9\u6297\u4e2d\u4ece\u611f\u77e5\u5230\u51b3\u7b56\u7684\u667a\u80fd\u63a8\u7406\u95ee\u9898\uff0c\u6a21\u62df\u4eba\u7c7b\u6307\u6325\u5b98\u7684\u8ba4\u77e5\u8fc7\u7a0b\u3002"}}
{"id": "2507.10620", "pdf": "https://arxiv.org/pdf/2507.10620", "abs": "https://arxiv.org/abs/2507.10620", "authors": ["Chenxi Liu", "Hao Miao", "Cheng Long", "Yan Zhao", "Ziyue Li", "Panos Kalnis"], "title": "LLMs Meet Cross-Modal Time Series Analytics: Overview and Directions", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at SSTD 2025 (Tutorial). arXiv admin note: text overlap with\n  arXiv:2505.02583", "summary": "Large Language Models (LLMs) have emerged as a promising paradigm for time\nseries analytics, leveraging their massive parameters and the shared sequential\nnature of textual and time series data. However, a cross-modality gap exists\nbetween time series and textual data, as LLMs are pre-trained on textual\ncorpora and are not inherently optimized for time series. In this tutorial, we\nprovide an up-to-date overview of LLM-based cross-modal time series analytics.\nWe introduce a taxonomy that classifies existing approaches into three groups\nbased on cross-modal modeling strategies, e.g., conversion, alignment, and\nfusion, and then discuss their applications across a range of downstream tasks.\nIn addition, we summarize several open challenges. This tutorial aims to expand\nthe practical application of LLMs in solving real-world problems in cross-modal\ntime series analytics while balancing effectiveness and efficiency.\nParticipants will gain a thorough understanding of current advancements,\nmethodologies, and future research directions in cross-modal time series\nanalytics.", "AI": {"tldr": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5173\u4e8e\u57fa\u4e8eLLM\u7684\u8de8\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u7684\u6700\u65b0\u6982\u8ff0\uff0c\u5305\u62ec\u5206\u7c7b\u73b0\u6709\u65b9\u6cd5\u3001\u8ba8\u8bba\u5176\u5e94\u7528\u548c\u603b\u7ed3\u5f00\u653e\u6311\u6218\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u65b9\u9762\u663e\u793a\u51fa\u5de8\u5927\u7684\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u4e0e\u6587\u672c\u6570\u636e\u4e4b\u95f4\u5b58\u5728\u8de8\u6a21\u6001\u5dee\u8ddd\u3002\u4e3a\u4e86\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u5e76\u6269\u5c55LLMs\u5728\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\u4e2d\u7684\u5e94\u7528\uff0c\u4f5c\u8005\u64b0\u5199\u4e86\u8fd9\u7bc7\u6559\u7a0b\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u4e2a\u5206\u7c7b\u6cd5\uff0c\u6839\u636e\u8de8\u6a21\u6001\u5efa\u6a21\u7b56\u7565\uff08\u5982\u8f6c\u6362\u3001\u5bf9\u9f50\u548c\u878d\u5408\uff09\u5c06\u73b0\u6709\u65b9\u6cd5\u5206\u4e3a\u4e09\u7c7b\uff0c\u5e76\u8ba8\u8bba\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5728\u4e00\u7cfb\u5217\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u53c2\u4e0e\u8005\u5c06\u83b7\u5f97\u5bf9\u5f53\u524d\u8fdb\u5c55\u3001\u65b9\u6cd5\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u7684\u6df1\u5165\u4e86\u89e3\u3002", "conclusion": "\u8be5\u6559\u7a0b\u65e8\u5728\u6269\u5927LLM\u5728\u89e3\u51b3\u8de8\u6a21\u6001\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u4e2d\u5b9e\u9645\u95ee\u9898\u7684\u5e94\u7528\uff0c\u540c\u65f6\u5e73\u8861\u6709\u6548\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2507.11137", "pdf": "https://arxiv.org/pdf/2507.11137", "abs": "https://arxiv.org/abs/2507.11137", "authors": ["Yuan Yao", "Jin Song", "Jian Jin"], "title": "Hashed Watermark as a Filter: Defeating Forging and Overwriting Attacks in Weight-based Neural Network Watermarking", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "As valuable digital assets, deep neural networks necessitate robust ownership\nprotection, positioning neural network watermarking (NNW) as a promising\nsolution. Among various NNW approaches, weight-based methods are favored for\ntheir simplicity and practicality; however, they remain vulnerable to forging\nand overwriting attacks. To address those challenges, we propose NeuralMark, a\nrobust method built around a hashed watermark filter. Specifically, we utilize\na hash function to generate an irreversible binary watermark from a secret key,\nwhich is then used as a filter to select the model parameters for embedding.\nThis design cleverly intertwines the embedding parameters with the hashed\nwatermark, providing a robust defense against both forging and overwriting\nattacks. An average pooling is also incorporated to resist fine-tuning and\npruning attacks. Furthermore, it can be seamlessly integrated into various\nneural network architectures, ensuring broad applicability. Theoretically, we\nanalyze its security boundary. Empirically, we verify its effectiveness and\nrobustness across 13 distinct Convolutional and Transformer architectures,\ncovering five image classification tasks and one text generation task. The\nsource codes are available at https://github.com/AIResearch-Group/NeuralMark.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6563\u5217\u6c34\u5370\u6ee4\u6ce2\u5668\u7684\u795e\u7ecf\u7f51\u7edc\u6240\u6709\u6743\u4fdd\u62a4\u65b9\u6cd5NeuralMark\uff0c\u589e\u5f3a\u4e86\u5bf9\u4f2a\u9020\u548c\u8986\u76d6\u653b\u51fb\u7684\u9632\u5fa1\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4f5c\u4e3a\u6709\u4ef7\u503c\u7684\u6570\u5b57\u8d44\u4ea7\uff0c\u9700\u8981\u5f3a\u6709\u529b\u7684\u6240\u6709\u6743\u4fdd\u62a4\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u6743\u91cd\u7684\u795e\u7ecf\u7f51\u7edc\u6c34\u5370\u65b9\u6cd5\u867d\u7136\u7b80\u5355\u5b9e\u7528\uff0c\u4f46\u5bb9\u6613\u53d7\u5230\u4f2a\u9020\u548c\u8986\u76d6\u653b\u51fb\u3002", "method": "\u4f7f\u7528\u6563\u5217\u51fd\u6570\u4ece\u5bc6\u94a5\u751f\u6210\u4e0d\u53ef\u9006\u7684\u4e8c\u8fdb\u5236\u6c34\u5370\uff0c\u5e76\u7528\u4f5c\u7b5b\u9009\u6a21\u578b\u53c2\u6570\u4ee5\u5d4c\u5165\u6c34\u5370\u7684\u8fc7\u6ee4\u5668\u3002\u8bbe\u8ba1\u7ed3\u5408\u4e86\u5d4c\u5165\u53c2\u6570\u4e0e\u6563\u5217\u6c34\u5370\uff0c\u63d0\u4f9b\u4e86\u5bf9\u4f2a\u9020\u548c\u8986\u76d6\u653b\u51fb\u7684\u5f3a\u5927\u9632\u5fa1\uff0c\u5e76\u52a0\u5165\u5e73\u5747\u6c60\u5316\u4ee5\u62b5\u6297\u5fae\u8c03\u548c\u526a\u679d\u653b\u51fb\u3002", "result": "\u572813\u79cd\u4e0d\u540c\u7684\u5377\u79ef\u548cTransformer\u67b6\u6784\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\uff0c\u6db5\u76d6\u4e86\u4e94\u4e2a\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u548c\u4e00\u4e2a\u6587\u672c\u751f\u6210\u4efb\u52a1\u3002", "conclusion": "NeuralMark\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u5404\u79cd\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e2d\uff0c\u786e\u4fdd\u5e7f\u6cdb\u7684\u9002\u7528\u6027\uff0c\u5e76\u4e14\u6e90\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2507.11083", "pdf": "https://arxiv.org/pdf/2507.11083", "abs": "https://arxiv.org/abs/2507.11083", "authors": ["Longhui Zhang", "Bin Wang", "Jiahao Wang", "Xiaofeng Zhao", "Min Zhang", "Hao Yang", "Meishan Zhang", "Yu Li", "Jing Li", "Jun Yu", "Min Zhang"], "title": "Function-to-Style Guidance of LLMs for Code Translation", "categories": ["cs.AI", "cs.SE"], "comment": "This paper has been accepted by ICML 2025. Models and benchmarks can\n  be found at https://www.modelscope.cn/collections/F2STrans-42526ff95dd843", "summary": "Large language models (LLMs) have made significant strides in code\ntranslation tasks. However, ensuring both the correctness and readability of\ntranslated code remains a challenge, limiting their effective adoption in\nreal-world software development. In this work, we propose F2STrans, a\nfunction-to-style guiding paradigm designed to progressively improve the\nperformance of LLMs in code translation. Our approach comprises two key stages:\n(1) Functional learning, which optimizes translation correctness using\nhigh-quality source-target code pairs mined from online programming platforms,\nand (2) Style learning, which improves translation readability by incorporating\nboth positive and negative style examples. Additionally, we introduce a novel\ncode translation benchmark that includes up-to-date source code, extensive test\ncases, and manually annotated ground-truth translations, enabling comprehensive\nfunctional and stylistic evaluations. Experiments on both our new benchmark and\nexisting datasets demonstrate that our approach significantly improves code\ntranslation performance. Notably, our approach enables Qwen-1.5B to outperform\nprompt-enhanced Qwen-32B and GPT-4 on average across 20 diverse code\ntranslation scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faF2STrans\uff0c\u4e00\u79cd\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u7ffb\u8bd1\u6b63\u786e\u6027\u548c\u53ef\u8bfb\u6027\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u65b0\u7684\u8bc4\u6d4b\u57fa\u51c6\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u7ffb\u8bd1\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u786e\u4fdd\u7ffb\u8bd1\u540e\u7684\u4ee3\u7801\u65e2\u6b63\u786e\u53c8\u6613\u8bfb\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\u3002", "method": "F2STrans\u5305\u62ec\u4e24\u4e2a\u5173\u952e\u9636\u6bb5\uff1a1\uff09\u529f\u80fd\u5b66\u4e60\uff0c\u901a\u8fc7\u4ece\u5728\u7ebf\u7f16\u7a0b\u5e73\u53f0\u6316\u6398\u7684\u9ad8\u8d28\u91cf\u6e90\u76ee\u6807\u4ee3\u7801\u5bf9\u4f18\u5316\u7ffb\u8bd1\u6b63\u786e\u6027\uff1b2\uff09\u98ce\u683c\u5b66\u4e60\uff0c\u901a\u8fc7\u5f15\u5165\u6b63\u9762\u548c\u8d1f\u9762\u7684\u98ce\u683c\u793a\u4f8b\u6539\u8fdb\u7ffb\u8bd1\u7684\u53ef\u8bfb\u6027\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5728\u65b0\u7684\u8bc4\u6d4b\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u800c\u4e14\u4f7fQwen-1.5B\u572820\u4e2a\u4e0d\u540c\u7684\u4ee3\u7801\u7ffb\u8bd1\u573a\u666f\u4e2d\u5e73\u5747\u8868\u73b0\u4f18\u4e8e\u589e\u5f3a\u63d0\u793a\u7684Qwen-32B\u548cGPT-4\u3002", "conclusion": "F2STrans\u8303\u5f0f\u80fd\u591f\u663e\u8457\u6539\u5584\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u4ee3\u7801\u7ffb\u8bd1\u7684\u6b63\u786e\u6027\u548c\u53ef\u8bfb\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2507.10623", "pdf": "https://arxiv.org/pdf/2507.10623", "abs": "https://arxiv.org/abs/2507.10623", "authors": ["Daniel Saragih", "Deyu Cao", "Tejas Balaji"], "title": "Flows and Diffusions on the Neural Manifold", "categories": ["cs.LG", "cs.CV"], "comment": "40 pages, 6 figures, 13 tables", "summary": "Diffusion and flow-based generative models have achieved remarkable success\nin domains such as image synthesis, video generation, and natural language\nmodeling. In this work, we extend these advances to weight space learning by\nleveraging recent techniques to incorporate structural priors derived from\noptimization dynamics. Central to our approach is modeling the trajectory\ninduced by gradient descent as a trajectory inference problem. We unify several\ntrajectory inference techniques under the framework of gradient flow matching,\nproviding a theoretical framework for treating optimization paths as inductive\nbias. We further explore architectural and algorithmic choices, including\nreward fine-tuning by adjoint matching, the use of autoencoders for latent\nweight representation, conditioning on task-specific context data, and adopting\ninformative source distributions such as Kaiming uniform. Experiments\ndemonstrate that our method matches or surpasses baselines in generating\nin-distribution weights, improves initialization for downstream training, and\nsupports fine-tuning to enhance performance. Finally, we illustrate a practical\napplication in safety-critical systems: detecting harmful covariate shifts,\nwhere our method outperforms the closest comparable baseline.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u4f18\u5316\u52a8\u6001\u7684\u7ed3\u6784\u5148\u9a8c\uff0c\u5c06\u68af\u5ea6\u4e0b\u964d\u8f68\u8ff9\u5efa\u6a21\u4e3a\u8f68\u8ff9\u63a8\u65ad\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u6846\u67b6\u2014\u2014\u68af\u5ea6\u6d41\u5339\u914d\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u751f\u6210\u5206\u5e03\u5185\u6743\u91cd\u3001\u6539\u8fdb\u4e0b\u6e38\u8bad\u7ec3\u521d\u59cb\u5316\u548c\u652f\u6301\u5fae\u8c03\u4ee5\u63d0\u9ad8\u6027\u80fd\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u4e14\u5728\u68c0\u6d4b\u6709\u5bb3\u534f\u53d8\u91cf\u504f\u79fb\u65b9\u9762\u6709\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u6269\u6563\u548c\u57fa\u4e8e\u6d41\u7684\u751f\u6210\u6a21\u578b\u5df2\u7ecf\u5728\u56fe\u50cf\u5408\u6210\u3001\u89c6\u9891\u751f\u6210\u548c\u81ea\u7136\u8bed\u8a00\u5efa\u6a21\u7b49\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u6280\u672f\u5c1a\u672a\u5e7f\u6cdb\u5e94\u7528\u4e8e\u6743\u91cd\u7a7a\u95f4\u5b66\u4e60\u3002\u672c\u7814\u7a76\u65e8\u5728\u5229\u7528\u6700\u8fd1\u7684\u6280\u672f\uff0c\u5c06\u4ece\u4f18\u5316\u52a8\u6001\u4e2d\u5f97\u51fa\u7684\u7ed3\u6784\u5148\u9a8c\u7eb3\u5165\u6743\u91cd\u7a7a\u95f4\u5b66\u4e60\u4e2d\u3002", "method": "\u4f5c\u8005\u5c06\u7531\u68af\u5ea6\u4e0b\u964d\u5f15\u8d77\u7684\u8f68\u8ff9\u5efa\u6a21\u4e3a\u8f68\u8ff9\u63a8\u65ad\u95ee\u9898\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u2014\u2014\u68af\u5ea6\u6d41\u5339\u914d\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u63a2\u7d22\u4e86\u67b6\u6784\u548c\u7b97\u6cd5\u7684\u9009\u62e9\uff0c\u5305\u62ec\u5956\u52b1\u5fae\u8c03\u3001\u4f7f\u7528\u81ea\u52a8\u7f16\u7801\u5668\u8fdb\u884c\u6f5c\u5728\u6743\u91cd\u8868\u793a\u3001\u57fa\u4e8e\u4efb\u52a1\u7279\u5b9a\u4e0a\u4e0b\u6587\u6570\u636e\u7684\u6761\u4ef6\u5316\u4ee5\u53ca\u91c7\u7528\u4fe1\u606f\u6e90\u5206\u5e03\uff08\u5982Kaiming\u5747\u5300\u5206\u5e03\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u751f\u6210\u5206\u5e03\u5185\u6743\u91cd\u65b9\u9762\u4e0e\u57fa\u7ebf\u6301\u5e73\u6216\u8d85\u8d8a\uff1b\u6539\u5584\u4e86\u4e0b\u6e38\u8bad\u7ec3\u7684\u521d\u59cb\u5316\uff1b\u652f\u6301\u5fae\u8c03\u4ee5\u589e\u5f3a\u6027\u80fd\uff1b\u5e76\u4e14\u5728\u4e00\u4e2a\u5b9e\u9645\u5e94\u7528\u6848\u4f8b\u4e2d\uff0c\u5373\u5728\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u68c0\u6d4b\u6709\u5bb3\u534f\u53d8\u91cf\u504f\u79fb\u65b9\u9762\uff0c\u8be5\u65b9\u6cd5\u7684\u8868\u73b0\u4f18\u4e8e\u6700\u63a5\u8fd1\u7684\u53ef\u6bd4\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5c06\u4f18\u5316\u8def\u5f84\u4f5c\u4e3a\u5f52\u7eb3\u504f\u5dee\u5904\u7406\u7684\u65b9\u6cd5\u662f\u6709\u6548\u7684\uff0c\u5c24\u5176\u662f\u5728\u751f\u6210\u5206\u5e03\u5185\u6743\u91cd\u548c\u6539\u8fdb\u4e0b\u6e38\u8bad\u7ec3\u521d\u59cb\u5316\u65b9\u9762\u3002\u6b64\u5916\uff0c\u8be5\u65b9\u6cd5\u5728\u68c0\u6d4b\u6709\u5bb3\u534f\u53d8\u91cf\u504f\u79fb\u65b9\u9762\u5177\u6709\u6f5c\u5728\u7684\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2507.11138", "pdf": "https://arxiv.org/pdf/2507.11138", "abs": "https://arxiv.org/abs/2507.11138", "authors": ["Adriano Castro", "Simon Hanisch", "Matin Fallahi", "Thorsten Strufe"], "title": "FacialMotionID: Identifying Users of Mixed Reality Headsets using Abstract Facial Motion Representations", "categories": ["cs.CR"], "comment": null, "summary": "Facial motion capture in mixed reality headsets enables real-time avatar\nanimation, allowing users to convey non-verbal cues during virtual\ninteractions. However, as facial motion data constitutes a behavioral\nbiometric, its use raises novel privacy concerns. With mixed reality systems\nbecoming more immersive and widespread, understanding whether face motion data\ncan lead to user identification or inference of sensitive attributes is\nincreasingly important.\n  To address this, we conducted a study with 116 participants using three types\nof headsets across three sessions, collecting facial, eye, and head motion data\nduring verbal and non-verbal tasks. The data used is not raw video, but rather,\nabstract representations that are used to animate digital avatars. Our analysis\nshows that individuals can be re-identified from this data with up to 98%\nbalanced accuracy, are even identifiable across device types, and that\nemotional states can be inferred with up to 86% accuracy. These results\nunderscore the potential privacy risks inherent in face motion tracking in\nmixed reality environments.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u9762\u90e8\u52a8\u4f5c\u6570\u636e\u5728\u6df7\u5408\u73b0\u5b9e\u4e2d\u53ef\u7528\u4e8e\u7528\u6237\u8bc6\u522b\u548c\u60c5\u611f\u72b6\u6001\u63a8\u65ad\uff0c\u5b58\u5728\u9690\u79c1\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u6df7\u5408\u73b0\u5b9e\u7cfb\u7edf\u7684\u666e\u53ca\uff0c\u7406\u89e3\u9762\u90e8\u8fd0\u52a8\u6570\u636e\u662f\u5426\u80fd\u5bfc\u81f4\u7528\u6237\u8bc6\u522b\u6216\u654f\u611f\u5c5e\u6027\u63a8\u65ad\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\u3002", "method": "\u7814\u7a76\u8005\u8fdb\u884c\u4e86\u4e00\u4e2a\u5305\u542b116\u540d\u53c2\u4e0e\u8005\u7684\u7814\u7a76\uff0c\u4f7f\u7528\u4e09\u79cd\u7c7b\u578b\u7684\u5934\u663e\u8bbe\u5907\uff0c\u5728\u4e09\u4e2a\u4f1a\u8bdd\u671f\u95f4\u6536\u96c6\u9762\u90e8\u3001\u773c\u90e8\u548c\u5934\u90e8\u8fd0\u52a8\u6570\u636e\uff0c\u5e76\u8fdb\u884c\u8bed\u8a00\u548c\u975e\u8bed\u8a00\u4efb\u52a1\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u4e2a\u4f53\u53ef\u4ee5\u4ece\u8fd9\u4e9b\u6570\u636e\u4e2d\u88ab\u91cd\u65b0\u8bc6\u522b\uff0c\u51c6\u786e\u7387\u9ad8\u8fbe98%\uff0c\u751a\u81f3\u53ef\u4ee5\u5728\u4e0d\u540c\u8bbe\u5907\u7c7b\u578b\u4e4b\u95f4\u8fdb\u884c\u8bc6\u522b\uff0c\u60c5\u611f\u72b6\u6001\u7684\u63a8\u65ad\u51c6\u786e\u7387\u4e5f\u9ad8\u8fbe86%\u3002", "conclusion": "\u9762\u90e8\u52a8\u4f5c\u8ffd\u8e2a\u5728\u6df7\u5408\u73b0\u5b9e\u73af\u5883\u4e2d\u5b58\u5728\u6f5c\u5728\u7684\u9690\u79c1\u98ce\u9669\u3002"}}
{"id": "2507.11117", "pdf": "https://arxiv.org/pdf/2507.11117", "abs": "https://arxiv.org/abs/2507.11117", "authors": ["Ailiya Borjigin", "Cong He", "Charles CC Lee", "Wei Zhou"], "title": "AI Agent Architecture for Decentralized Trading of Alternative Assets", "categories": ["cs.AI"], "comment": "8 Pages, 1 figure", "summary": "Decentralized trading of real-world alternative assets (e.g., gold) requires\nbridging physical asset custody with blockchain systems while meeting strict\nrequirements for compliance, liquidity, and risk management. We present\nGoldMine OS, a research oriented architecture that employs multiple specialized\nAI agents to automate and secure the tokenization and exchange of physical gold\ninto a blockchain based stablecoin (\"OZ\"). Our approach combines on chain smart\ncontracts for critical risk controls with off chain AI agents for decision\nmaking, blending the transparency and reliability of blockchains with the\nflexibility of AI driven automation. We describe four cooperative agents\n(Compliance, Token Issuance, Market Making, and Risk Control) and a\ncoordinating core, and evaluate the system through simulation and a controlled\npilot deployment. In experiments the prototype delivers on demand token\nissuance in under 1.2 s, more than 100 times faster than manual workflows. The\nMarket Making agent maintains tight liquidity with spreads often below 0.5\npercent even under volatile conditions. Fault injection tests show resilience:\nan oracle price spoofing attack is detected and mitigated within 10 s, and a\nsimulated vault mis reporting halts issuance immediately with minimal user\nimpact. The architecture scales to 5000 transactions per second with 10000\nconcurrent users in benchmarks. These results indicate that an AI agent based\ndecentralized exchange for alternative assets can satisfy rigorous performance\nand safety requirements. We discuss broader implications for democratizing\naccess to traditionally illiquid assets and explain how our governance model --\nmulti signature agent updates and on chain community voting on risk parameters\n-- provides ongoing transparency, adaptability, and formal assurance of system\nintegrity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGoldMine OS\u7684\u7814\u7a76\u578b\u67b6\u6784\uff0c\u901a\u8fc7\u7ed3\u5408\u533a\u5757\u94fe\u548cAI\u6280\u672f\u5b9e\u73b0\u9ec4\u91d1\u7684\u53bb\u4e2d\u5fc3\u5316\u4ea4\u6613\u3002\u8be5\u7cfb\u7edf\u5305\u542b\u56db\u4e2a\u534f\u4f5c\u4ee3\u7406\u548c\u4e00\u4e2a\u534f\u8c03\u6838\u5fc3\uff0c\u53ef\u4ee5\u5feb\u901f\u53d1\u884c\u4ee3\u5e01\u3001\u7ef4\u6301\u5e02\u573a\u6d41\u52a8\u6027\u548c\u5e94\u5bf9\u98ce\u9669\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u6ee1\u8db3\u6027\u80fd\u548c\u5b89\u5168\u6027\u7684\u4e25\u683c\u8981\u6c42\uff0c\u5e76\u5177\u6709\u6269\u5c55\u6027\u3002", "motivation": "\u53bb\u4e2d\u5fc3\u5316\u4ea4\u6613\u5b9e\u7269\u8d44\u4ea7\uff08\u5982\u9ec4\u91d1\uff09\u9700\u8981\u5c06\u5b9e\u7269\u8d44\u4ea7\u6258\u7ba1\u4e0e\u533a\u5757\u94fe\u7cfb\u7edf\u8fde\u63a5\u8d77\u6765\uff0c\u540c\u65f6\u6ee1\u8db3\u4e25\u683c\u7684\u5408\u89c4\u6027\u3001\u6d41\u52a8\u6027\u548c\u98ce\u9669\u7ba1\u7406\u8981\u6c42\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u65e0\u6cd5\u9ad8\u6548\u5730\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGoldMine OS\u7684\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u4f7f\u7528\u591a\u4e2a\u4e13\u4e1a\u5316\u7684AI\u4ee3\u7406\u6765\u81ea\u52a8\u548c\u4fdd\u62a4\u7269\u7406\u9ec4\u91d1\u5230\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u7a33\u5b9a\u5e01\u7684\u8f6c\u6362\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u94fe\u4e0a\u667a\u80fd\u5408\u7ea6\u548c\u94fe\u4e0bAI\u4ee3\u7406\u8fdb\u884c\u51b3\u7b56\uff0c\u4ee5\u7ed3\u5408\u533a\u5757\u94fe\u7684\u900f\u660e\u5ea6\u548c\u53ef\u9760\u6027\u4ee5\u53caAI\u9a71\u52a8\u81ea\u52a8\u5316\u7684\u7075\u6d3b\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u539f\u578b\u53ef\u4ee5\u5728\u4e0d\u52301.2\u79d2\u7684\u65f6\u95f4\u5185\u6309\u9700\u53d1\u884c\u4ee3\u5e01\uff0c\u6bd4\u624b\u52a8\u5de5\u4f5c\u6d41\u7a0b\u5feb100\u500d\u4ee5\u4e0a\u3002Market Making\u4ee3\u7406\u5728\u6ce2\u52a8\u6761\u4ef6\u4e0b\u4e5f\u80fd\u4fdd\u6301\u7d27\u5bc6\u7684\u6d41\u52a8\u6027\uff0c\u4ef7\u5dee\u901a\u5e38\u4f4e\u4e8e0.5\uff05\u3002\u6545\u969c\u6ce8\u5165\u6d4b\u8bd5\u663e\u793a\u7cfb\u7edf\u7684\u97e7\u6027\uff0c\u4f8b\u5982\uff0c\u5728\u653b\u51fb\u88ab\u68c0\u6d4b\u5e76\u572810\u79d2\u5185\u5f97\u5230\u7f13\u89e3\u3002\u8be5\u67b6\u6784\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53ef\u6269\u5c55\u5230\u6bcf\u79d25000\u7b14\u4ea4\u6613\u548c10000\u4e2a\u5e76\u53d1\u7528\u6237\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8eAI\u4ee3\u7406\u7684\u66ff\u4ee3\u8d44\u4ea7\u53bb\u4e2d\u5fc3\u5316\u4ea4\u6613\u6240\u53ef\u4ee5\u6ee1\u8db3\u4e25\u683c\u7684\u6027\u80fd\u548c\u5b89\u5168\u8981\u6c42\u3002\u8fd9\u4e3a\u4f20\u7edf\u4e0a\u4e0d\u6d41\u52a8\u8d44\u4ea7\u7684\u6c11\u4e3b\u5316\u8bbf\u95ee\u5e26\u6765\u4e86\u66f4\u5e7f\u6cdb\u7684\u5f71\u54cd\u3002\u6b64\u5916\uff0c\u4ed6\u4eec\u7684\u6cbb\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u6301\u7eed\u7684\u900f\u660e\u5ea6\u3001\u9002\u5e94\u6027\u548c\u6b63\u5f0f\u7684\u7cfb\u7edf\u5b8c\u6574\u6027\u4fdd\u8bc1\u3002"}}
{"id": "2507.10626", "pdf": "https://arxiv.org/pdf/2507.10626", "abs": "https://arxiv.org/abs/2507.10626", "authors": ["Lintao Wang", "Shiwen Xu", "Michael Horton", "Joachim Gudmundsson", "Zhiyong Wang"], "title": "Player-Team Heterogeneous Interaction Graph Transformer for Soccer Outcome Prediction", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Predicting soccer match outcomes is a challenging task due to the inherently\nunpredictable nature of the game and the numerous dynamic factors influencing\nresults. While it conventionally relies on meticulous feature engineering, deep\nlearning techniques have recently shown a great promise in learning effective\nplayer and team representations directly for soccer outcome prediction.\nHowever, existing methods often overlook the heterogeneous nature of\ninteractions among players and teams, which is crucial for accurately modeling\nmatch dynamics. To address this gap, we propose HIGFormer (Heterogeneous\nInteraction Graph Transformer), a novel graph-augmented transformer-based deep\nlearning model for soccer outcome prediction. HIGFormer introduces a\nmulti-level interaction framework that captures both fine-grained player\ndynamics and high-level team interactions. Specifically, it comprises (1) a\nPlayer Interaction Network, which encodes player performance through\nheterogeneous interaction graphs, combining local graph convolutions with a\nglobal graph-augmented transformer; (2) a Team Interaction Network, which\nconstructs interaction graphs from a team-to-team perspective to model\nhistorical match relationships; and (3) a Match Comparison Transformer, which\njointly analyzes both team and player-level information to predict match\noutcomes. Extensive experiments on the WyScout Open Access Dataset, a\nlarge-scale real-world soccer dataset, demonstrate that HIGFormer significantly\noutperforms existing methods in prediction accuracy. Furthermore, we provide\nvaluable insights into leveraging our model for player performance evaluation,\noffering a new perspective on talent scouting and team strategy analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u56fe\u589e\u5f3aTransformer\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bHIGFormer\uff0c\u7528\u4e8e\u8db3\u7403\u6bd4\u8d5b\u7ed3\u679c\u9884\u6d4b\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u591a\u5c42\u6b21\u4ea4\u4e92\u6846\u67b6\u6355\u6349\u7403\u5458\u548c\u56e2\u961f\u95f4\u7684\u5f02\u8d28\u4e92\u52a8\uff0c\u5e76\u5728\u5927\u89c4\u6a21\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u8db3\u7403\u6bd4\u8d5b\u7ed3\u679c\u9884\u6d4b\u65b9\u6cd5\u5f80\u5f80\u5ffd\u89c6\u4e86\u7403\u5458\u548c\u7403\u961f\u4e4b\u95f4\u4ea4\u4e92\u7684\u5f02\u8d28\u6027\uff0c\u8fd9\u5bf9\u51c6\u786e\u5efa\u6a21\u6bd4\u8d5b\u52a8\u6001\u81f3\u5173\u91cd\u8981\u3002", "method": "HIGFormer\u5305\u542b\u4e09\u4e2a\u90e8\u5206\uff1a(1) \u7403\u5458\u4ea4\u4e92\u7f51\u7edc\uff0c\u901a\u8fc7\u5f02\u8d28\u4ea4\u4e92\u56fe\u7f16\u7801\u7403\u5458\u8868\u73b0\uff1b(2) \u56e2\u961f\u4ea4\u4e92\u7f51\u7edc\uff0c\u4ece\u56e2\u961f\u89c6\u89d2\u6784\u5efa\u4ea4\u4e92\u56fe\u4ee5\u6a21\u62df\u5386\u53f2\u6bd4\u8d5b\u5173\u7cfb\uff1b(3) \u6bd4\u8d5b\u5bf9\u6bd4Transformer\uff0c\u5171\u540c\u5206\u6790\u56e2\u961f\u548c\u4e2a\u4eba\u5c42\u9762\u7684\u4fe1\u606f\u6765\u9884\u6d4b\u6bd4\u8d5b\u7ed3\u679c\u3002", "result": "\u5728WyScout\u5f00\u653e\u8bbf\u95ee\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cHIGFormer\u5728\u9884\u6d4b\u51c6\u786e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8be5\u6a21\u578b\u8fd8\u4e3a\u7403\u5458\u8868\u73b0\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002", "conclusion": "HIGFormer\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u89c6\u89d2\u8fdb\u884c\u4eba\u624d\u9009\u62d4\u548c\u56e2\u961f\u7b56\u7565\u5206\u6790\uff0c\u5e76\u5728\u8db3\u7403\u6bd4\u8d5b\u7ed3\u679c\u9884\u6d4b\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
