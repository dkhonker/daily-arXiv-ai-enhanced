<div id=toc></div>

# 目录

- [cs.AI](#cs.AI) [总数: 8]
- [cs.CL](#cs.CL) [总数: 44]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024](https://arxiv.org/abs/2511.04685)
*Daniela Guericke, Rolf van der Hulst, Asal Karimpour, Ieke Schrader, Matthias Walter*

**主要类别:** cs.AI

**AI概要:** 本文介绍了Team Twente在2024年综合医疗排班竞赛中获得第三名的算法方案，采用混合整数规划、约束规划和模拟退火的3阶段分解方法，并首次提供了基准实例的最优解下界分析。


<details>
  <summary>更多</summary>
  
**动机:** 参加2024年综合医疗排班竞赛，旨在开发高效的医疗资源调度解决方案，解决复杂的医疗排班优化问题。

**方法:** 采用3阶段分解方法：混合整数规划、约束规划和模拟退火算法相结合，将复杂问题分解为子问题逐步求解。

**结果:** 在竞赛中获得第三名，成功实现了有效的医疗排班方案，并首次计算出了基准实例的最优解下界。

**结论:** 该方法在医疗排班问题上表现良好，但仍存在一些开放性问题有待解决以进一步提升算法性能。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+hybrid+solution+approach+for+the+Integrated+Healthcare+Timetabling+Competition+2024，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04685，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04685&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We report about the algorithm, implementation and results submitted to the
Integrated Healthcare Timetabling Competition 2024 by Team Twente, which scored
third in the competition. Our approach combines mixed-integer programming,
constraint programming and simulated annealing in a 3-phase solution approach
based on decomposition into subproblems. Next to describing our approach and
describing our design decisions, we share our insights and, for the first time,
lower bounds on the optimal solution values for the benchmark instances. We
finally highlight open problems for which we think that addressing them could
improve our approach even further.

</details>


### [2] [Epistemic Reject Option Prediction](https://arxiv.org/abs/2511.04855)
*Vojtech Franc, Jakub Paplham*

**主要类别:** cs.AI

**AI概要:** 本文提出了一个基于贝叶斯学习的认知拒绝选项预测器，能够在数据不足导致高认知不确定性时拒绝预测，通过最小化预期遗憾来优化预测性能。


<details>
  <summary>更多</summary>
  
**动机:** 传统拒绝选项方法只关注偶然不确定性，但在数据有限的实际场景中，认知不确定性不可忽略，需要新的方法来处理数据不足导致的不可靠预测问题。

**方法:** 基于贝叶斯学习框架，重新定义最优预测器为最小化预期遗憾的模型，当输入数据的预测遗憾超过指定拒绝成本时，模型选择拒绝预测。

**结果:** 提出了首个原则性框架，能够学习识别训练数据不足以做出可靠决策的输入，有效处理高认知不确定性情况。

**结论:** 该框架为高风险应用中处理数据不足导致的认知不确定性提供了理论和方法基础，提高了预测系统的可靠性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Epistemic+Reject+Option+Prediction，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04855，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04855&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** In high-stakes applications, predictive models must not only produce accurate
predictions but also quantify and communicate their uncertainty. Reject-option
prediction addresses this by allowing the model to abstain when prediction
uncertainty is high. Traditional reject-option approaches focus solely on
aleatoric uncertainty, an assumption valid only when large training data makes
the epistemic uncertainty negligible. However, in many practical scenarios,
limited data makes this assumption unrealistic. This paper introduces the
epistemic reject-option predictor, which abstains in regions of high epistemic
uncertainty caused by insufficient data. Building on Bayesian learning, we
redefine the optimal predictor as the one that minimizes expected regret -- the
performance gap between the learned model and the Bayes-optimal predictor with
full knowledge of the data distribution. The model abstains when the regret for
a given input exceeds a specified rejection cost. To our knowledge, this is the
first principled framework that enables learning predictors capable of
identifying inputs for which the training data is insufficient to make reliable
decisions.

</details>


### [3] [DMA: Online RAG Alignment with Human Feedback](https://arxiv.org/abs/2511.04880)
*Yu Bai, Yukai Miao, Dawei Wang, Li Chen, Fei Long, Rundi Zhai, Dan Li, Yanyu Ren, Tianfeng Liu, Hongtao Xie, Ce Yang, Xuhui Cai*

**主要类别:** cs.AI

**AI概要:** DMA是一个在线学习框架，通过整合多粒度人类反馈来动态优化RAG系统的检索排序，在保持基础检索能力的同时显著提升人机交互效果。


<details>
  <summary>更多</summary>
  
**动机:** 传统RAG系统依赖静态检索，无法适应动态变化的用户意图和内容漂移问题，需要能够实时学习和适应的解决方案。

**方法:** 采用多粒度反馈学习管道：文档级和列表级排序器的监督训练、基于响应级偏好的策略优化，以及将知识蒸馏到轻量级评分器中实现低延迟服务。

**结果:** 在线A/B测试显示各反馈源均有效，工业部署显著提升用户参与度；离线测试在TriviaQA和HotpotQA等对话QA任务上取得显著增益，同时保持基础检索竞争力。

**结论:** DMA为RAG系统提供了一种有原则的反馈驱动实时适应方法，在不牺牲基线能力的情况下实现持续优化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是DMA%3A+Online+RAG+Alignment+with+Human+Feedback，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04880，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04880&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Retrieval-augmented generation (RAG) systems often rely on static retrieval,
limiting adaptation to evolving intent and content drift. We introduce Dynamic
Memory Alignment (DMA), an online learning framework that systematically
incorporates multi-granularity human feedback to align ranking in interactive
settings. DMA organizes document-, list-, and response-level signals into a
coherent learning pipeline: supervised training for pointwise and listwise
rankers, policy optimization driven by response-level preferences, and
knowledge distillation into a lightweight scorer for low-latency serving.
Throughout this paper, memory refers to the model's working memory, which is
the entire context visible to the LLM for In-Context Learning.
  We adopt a dual-track evaluation protocol mirroring deployment: (i)
large-scale online A/B ablations to isolate the utility of each feedback
source, and (ii) few-shot offline tests on knowledge-intensive benchmarks.
Online, a multi-month industrial deployment further shows substantial
improvements in human engagement. Offline, DMA preserves competitive
foundational retrieval while yielding notable gains on conversational QA
(TriviaQA, HotpotQA). Taken together, these results position DMA as a
principled approach to feedback-driven, real-time adaptation in RAG without
sacrificing baseline capability.

</details>


### [4] [Real-Time Reasoning Agents in Evolving Environments](https://arxiv.org/abs/2511.04898)
*Yule Wen, Yixin Ye, Yanzhe Zhang, Diyi Yang, Hao Zhu*

**主要类别:** cs.AI

**AI概要:** 论文提出了实时推理的新问题框架，研究语言模型在动态环境中的两种部署范式（反应式vs规划式），发现现有模型表现不佳，并提出AgileThinker方法同时使用两种推理范式来平衡推理深度和响应延迟。


<details>
  <summary>更多</summary>
  
**动机:** 现实世界中的智能体需要同时做出逻辑性和及时性的判断，但现有语言模型推理方法未能考虑环境的动态特性。

**方法:** 构建Real-Time Reasoning Gym测试平台，研究反应式智能体（有限推理计算）和规划式智能体（扩展推理计算）两种范式，并提出AgileThinker方法同时使用两种推理范式。

**结果:** 实验表明即使最先进的模型在两种范式中都难以做出逻辑性和及时性的判断，而AgileThinker在任务难度和时间压力增加时始终优于单一范式的智能体。

**结论:** 实时推理是开发实用智能体的关键测试平台，为时间约束AI系统研究奠定了基础，指明了实现实时能力智能体的路径。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Real-Time+Reasoning+Agents+in+Evolving+Environments，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04898，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04898&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Agents in the real world must make not only logical but also timely
judgments. This requires continuous awareness of the dynamic environment:
hazards emerge, opportunities arise, and other agents act, while the agent's
reasoning is still unfolding. Despite advances in language model reasoning,
existing approaches fail to account for this dynamic nature. We introduce
real-time reasoning as a new problem formulation for agents in evolving
environments and build Real-Time Reasoning Gym to demonstrate it. We study two
paradigms for deploying language models in agents: (1) reactive agents, which
employ language models with bounded reasoning computation for rapid responses,
and (2) planning agents, which allow extended reasoning computation for complex
problems. Our experiments show that even state-of-the-art models struggle with
making logical and timely judgments in either paradigm. To address this
limitation, we propose AgileThinker, which simultaneously engages both
reasoning paradigms. AgileThinker consistently outperforms agents engaging only
one reasoning paradigm as the task difficulty and time pressure rise,
effectively balancing reasoning depth and response latency. Our work
establishes real-time reasoning as a critical testbed for developing practical
agents and provides a foundation for research in temporally constrained AI
systems, highlighting a path toward real-time capable agents.

</details>


### [5] [ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property](https://arxiv.org/abs/2511.04956)
*Maria Mahbub, Vanessa Lama, Sanjay Das, Brian Starks, Christopher Polchek, Saffell Silvers, Lauren Deck, Prasanna Balaprakash, Tirthankar Ghosal*

**主要类别:** cs.AI

**AI概要:** ORCHID是一个模块化代理系统，用于美国能源部高风险财产分类，结合检索增强生成(RAG)和人工监督，提高分类准确性和可追溯性，同时将不确定项目交由专家处理。


<details>
  <summary>更多</summary>
  
**动机:** 传统专家主导的高风险财产分类流程耗时、易积压，难以跟上不断变化的监管要求，需要更高效、透明且可审计的解决方案。

**方法:** 采用模块化代理系统，包括检索、描述精炼、分类、验证和反馈记录等小型协作代理，通过代理间消息传递和模型上下文协议(MCP)实现模型无关的本地操作，遵循从项目到证据再到决策的循环流程。

**结果:** 在真实高风险财产案例的初步测试中，ORCHID相比非代理基线提高了准确性和可追溯性，同时能够将不确定项目交由领域专家处理。

**结论:** ORCHID展示了在敏感能源部合规工作流程中实现可信赖大语言模型辅助的实用路径，通过逐步推理、政策引用和只追加审计包确保透明度和可审计性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ORCHID%3A+Orchestrated+Retrieval-Augmented+Classification+with+Human-in-the-Loop+Intelligent+Decision-Making+for+High-Risk+Property，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04956，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04956&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** High-Risk Property (HRP) classification is critical at U.S. Department of
Energy (DOE) sites, where inventories include sensitive and often dual-use
equipment. Compliance must track evolving rules designated by various export
control policies to make transparent and auditable decisions. Traditional
expert-only workflows are time-consuming, backlog-prone, and struggle to keep
pace with shifting regulatory boundaries. We demo ORCHID, a modular agentic
system for HRP classification that pairs retrieval-augmented generation (RAG)
with human oversight to produce policy-based outputs that can be audited. Small
cooperating agents, retrieval, description refiner, classifier, validator, and
feedback logger, coordinate via agent-to-agent messaging and invoke tools
through the Model Context Protocol (MCP) for model-agnostic on-premise
operation. The interface follows an Item to Evidence to Decision loop with
step-by-step reasoning, on-policy citations, and append-only audit bundles
(run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID
improves accuracy and traceability over a non-agentic baseline while deferring
uncertain items to Subject Matter Experts (SMEs). The demonstration shows
single item submission, grounded citations, SME feedback capture, and
exportable audit artifacts, illustrating a practical path to trustworthy LLM
assistance in sensitive DOE compliance workflows.

</details>


### [6] [Autonomous generation of different courses of action in mechanized combat operations](https://arxiv.org/abs/2511.05182)
*Johan Schubert, Patrik Hansen, Pontus Hörling, Ronnie Johansson*

**主要类别:** cs.AI

**AI概要:** 提出一种支持地面军事作战决策的方法论，通过系统生成和评估数千种行动方案，基于敌方状态和战场条件动态优化机械化营的作战决策


<details>
  <summary>更多</summary>
  
**动机:** 为机械化营在执行阶段提供决策支持，需要处理复杂战场环境下的大量可能行动方案并评估其预期结果

**方法:** 从初始评估的行动方案集开始，系统生成数千个个体行动替代方案，结合敌方状态、部队组成、兵力比例、攻防类型和预期推进速率等因素进行评估，使用野战手册评估战斗结果

**结果:** 方法能够并发生成和评估多种行动替代方案，基于先前评估结果管理新方案的生成，随着战斗进展动态修订行动方案

**结论:** 该决策支持方法能够在连续决策框架内为指挥官提供优化的行动建议，适应战场条件的动态变化

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Autonomous+generation+of+different+courses+of+action+in+mechanized+combat+operations，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05182，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05182&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we propose a methodology designed to support decision-making
during the execution phase of military ground combat operations, with a focus
on one's actions. This methodology generates and evaluates recommendations for
various courses of action for a mechanized battalion, commencing with an
initial set assessed by their anticipated outcomes. It systematically produces
thousands of individual action alternatives, followed by evaluations aimed at
identifying alternative courses of action with superior outcomes. These
alternatives are appraised in light of the opponent's status and actions,
considering unit composition, force ratios, types of offense and defense, and
anticipated advance rates. Field manuals evaluate battle outcomes and
advancement rates. The processes of generation and evaluation work
concurrently, yielding a variety of alternative courses of action. This
approach facilitates the management of new course generation based on
previously evaluated actions. As the combat unfolds and conditions evolve,
revised courses of action are formulated for the decision-maker within a
sequential decision-making framework.

</details>


### [7] [Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance](https://arxiv.org/abs/2511.05311)
*Valeriu Dimidov, Faisal Hawlader, Sasan Jafarnejad, Raphaël Frank*

**主要类别:** cs.AI

**AI概要:** 论文探讨了基于大语言模型(LLM)的智能体在汽车行业预测性维护(PdM)数据清洗中的潜力，特别是在处理维护日志中的六类噪声方面表现出色，为工业应用提供了有前景的基础。


<details>
  <summary>更多</summary>
  
**动机:** 汽车行业预测性维护面临经济约束、数据集稀缺和专业人才短缺等挑战，而大语言模型的进展为解决这些障碍提供了机会，加速PdM从研究向工业实践的转型。

**方法:** 研究评估了LLM智能体在维护日志数据清洗任务中的表现，重点关注六种不同类型的噪声处理：拼写错误、缺失字段、近似重复条目和错误日期等。

**结果:** 研究结果显示，大语言模型在通用清洗任务中表现有效，为未来工业应用提供了有前景的基础。尽管领域特定错误仍具挑战性，但通过专业训练和增强智能体能力有望进一步改进。

**结论:** LLM智能体在预测性维护数据清洗方面具有显著潜力，特别是在处理维护日志噪声方面。虽然领域特定问题仍需解决，但通过针对性训练和能力提升，LLM技术有望显著推动汽车行业预测性维护的实际应用。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Cleaning+Maintenance+Logs+with+LLM+Agents+for+Improved+Predictive+Maintenance，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05311，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05311&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Economic constraints, limited availability of datasets for reproducibility
and shortages of specialized expertise have long been recognized as key
challenges to the adoption and advancement of predictive maintenance (PdM) in
the automotive sector. Recent progress in large language models (LLMs) presents
an opportunity to overcome these barriers and speed up the transition of PdM
from research to industrial practice. Under these conditions, we explore the
potential of LLM-based agents to support PdM cleaning pipelines. Specifically,
we focus on maintenance logs, a critical data source for training
well-performing machine learning (ML) models, but one often affected by errors
such as typos, missing fields, near-duplicate entries, and incorrect dates. We
evaluate LLM agents on cleaning tasks involving six distinct types of noise.
Our findings show that LLMs are effective at handling generic cleaning tasks
and offer a promising foundation for future industrial applications. While
domain-specific errors remain challenging, these results highlight the
potential for further improvements through specialized training and enhanced
agentic capabilities.

</details>


### [8] [Reasoning Is All You Need for Urban Planning AI](https://arxiv.org/abs/2511.05375)
*Sijie Yang, Jiatong Li, Filip Biljecki*

**主要类别:** cs.AI

**AI概要:** 提出了一个基于推理AI的智能城市规划框架，通过多智能体协作整合感知、基础和推理三层认知架构，实现价值导向、规则约束和可解释的规划决策辅助。


<details>
  <summary>更多</summary>
  
**动机:** 传统统计学习方法无法满足城市规划决策需要显式推理、价值判断、规则约束和透明解释的要求，需要新一代AI辅助决策系统。

**方法:** 构建Agentic Urban Planning AI Framework，包含三层认知架构（感知、基础、推理）和六个逻辑组件（分析、生成、验证、评估、协作、决策），采用多智能体协作框架。

**结果:** 提出了一个全面的架构设计和基准评估指标，展示了AI智能体如何通过系统探索解决方案空间、验证法规合规性和透明权衡来增强人类规划师的能力。

**结论:** 该框架表明AI智能体不是取代人类判断，而是通过计算推理能力增强人类规划师的决策能力，为城市规划提供可解释、价值导向的智能辅助决策支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reasoning+Is+All+You+Need+for+Urban+Planning+AI，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05375，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05375&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** AI has proven highly successful at urban planning analysis -- learning
patterns from data to predict future conditions. The next frontier is
AI-assisted decision-making: agents that recommend sites, allocate resources,
and evaluate trade-offs while reasoning transparently about constraints and
stakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,
ReAct, and multi-agent collaboration frameworks -- now make this vision
achievable.
  This position paper presents the Agentic Urban Planning AI Framework for
reasoning-capable planning agents that integrates three cognitive layers
(Perception, Foundation, Reasoning) with six logic components (Analysis,
Generation, Verification, Evaluation, Collaboration, Decision) through a
multi-agents collaboration framework. We demonstrate why planning decisions
require explicit reasoning capabilities that are value-based (applying
normative principles), rule-grounded (guaranteeing constraint satisfaction),
and explainable (generating transparent justifications) -- requirements that
statistical learning alone cannot fulfill. We compare reasoning agents with
statistical learning, present a comprehensive architecture with benchmark
evaluation metrics, and outline critical research challenges. This framework
shows how AI agents can augment human planners by systematically exploring
solution spaces, verifying regulatory compliance, and deliberating over
trade-offs transparently -- not replacing human judgment but amplifying it with
computational reasoning capabilities.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [9] [Evaluating LLMs' Reasoning Over Ordered Procedural Steps](https://arxiv.org/abs/2511.04688)
*Adrita Anika, Md Messal Monem Miah*

**主要类别:** cs.CL

**AI概要:** 该研究评估了大型语言模型在重构打乱顺序的程序步骤方面的能力，发现在序列长度增加和输入步骤更混乱时，模型性能显著下降。


<details>
  <summary>更多</summary>
  
**动机:** 研究程序性序列推理能力对大型语言模型至关重要，特别是在步骤顺序直接影响结果的场景中。使用食谱作为测试领域，因为正确的步骤顺序对任务成功至关重要。

**方法:** 使用精选的食谱数据集，在零样本和少样本设置下评估多个LLM。采用综合评估框架，包括Kendall's Tau、NLCS和NED等排序和序列对齐指标。

**结果:** 模型性能随序列长度增加而下降，输入步骤位移越大（即打乱程度越严重），性能退化越明显。

**结论:** 当前LLM在程序性推理方面存在局限性，特别是在处理更长和更混乱的输入时表现不佳。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Evaluating+LLMs%27+Reasoning+Over+Ordered+Procedural+Steps，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04688，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04688&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Reasoning over procedural sequences, where the order of steps directly
impacts outcomes, is a critical capability for large language models (LLMs). In
this work, we study the task of reconstructing globally ordered sequences from
shuffled procedural steps, using a curated dataset of food recipes, a domain
where correct sequencing is essential for task success. We evaluate several
LLMs under zero-shot and few-shot settings and present a comprehensive
evaluation framework that adapts established metrics from ranking and sequence
alignment. These include Kendall's Tau, Normalized Longest Common Subsequence
(NLCS), and Normalized Edit Distance (NED), which capture complementary aspects
of ordering quality. Our analysis shows that model performance declines with
increasing sequence length, reflecting the added complexity of longer
procedures. We also find that greater step displacement in the input,
corresponding to more severe shuffling, leads to further degradation. These
findings highlight the limitations of current LLMs in procedural reasoning,
especially with longer and more disordered inputs.

</details>


### [10] [Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks](https://arxiv.org/abs/2511.04689)
*Peiyu Li, Xiuxiu Tang, Si Chen, Ying Cheng, Ronald Metoyer, Ting Hua, Nitesh V. Chawla*

**主要类别:** cs.CL

**AI概要:** ATLAS是一个基于项目反应理论的自适应测试框架，通过Fisher信息量引导的项目选择，在保持测量精度的同时减少90%的测试项目需求，显著降低大语言模型评估成本。


<details>
  <summary>更多</summary>
  
**动机:** 大语言模型评估需要数千个基准测试项，成本高昂且耗时。现有方法对所有项目一视同仁，忽略了项目质量和信息量的差异，且存在标注错误影响评估准确性的问题。

**方法:** 采用项目反应理论(IRT)构建自适应测试框架，通过Fisher信息量指导项目选择，动态选择最具信息量的测试项目来估计模型能力。

**结果:** 在HellaSwag基准上仅用42个项目(原5,608个)就达到0.154 MAE的测量精度；发现3-6%的项目存在负区分度(标注错误)；项目暴露率低于10%，测试重叠率16-27%；IRT排名与传统准确率排名存在显著差异，23-31%的模型排名变化超过10位。

**结论:** ATLAS框架能大幅减少评估成本，提高评估效率，同时揭示了传统静态基准评估中存在的质量问题，为更精确、高效的模型评估提供了新方法。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Adaptive+Testing+for+LLM+Evaluation%3A+A+Psychometric+Alternative+to+Static+Benchmarks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04689，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04689&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language model evaluation requires thousands of benchmark items, making
evaluations expensive and slow. Existing methods compute average accuracy
across fixed item sets, treating all items equally despite varying quality and
informativeness. We present ATLAS an adaptive testing framework using Item
Response Theory (IRT) to estimate model ability through Fisher
information-guided item selection. Our analysis of five major benchmarks
reveals that 3-6% of items exhibit negative discrimination, indicating
annotation errors that corrupt static evaluation. ATLAS achieves 90% item
reduction while maintaining measurement precision: on HellaSwag (5,608 items),
we match full-benchmark estimates using only 42 items with 0.154 MAE. Our
framework maintains item exposure rates below 10% and test overlap at 16-27%,
compared to static benchmarks where every model sees all items (100% exposure).
Among 4,000+ tested models, IRT ranks differ from accuracy ranks: models with
the same accuracy get different IRT scores, and 23-31% of all models shift by
more than 10 rank positions. Code and calibrated item banks are available at
https://github.com/Peiyu-Georgia-Li/ATLAS.git.

</details>


### [11] [SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection](https://arxiv.org/abs/2511.04692)
*Jingqing Wang, Jiaxing Shang, Rong Xu, Fei Hao, Tianjin Huang, Geyong Min*

**主要类别:** cs.CL

**AI概要:** SARC是一个情感增强的角色聚类框架，通过联合优化用户角色聚类和假新闻检测任务，显著提升了假新闻检测性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有方法将情感特征作为辅助信号，忽略了用户角色差异对情感表达的微妙影响，限制了检测效果。

**方法:** 使用BiGRU和注意力机制联合生成用户评论文本表示和情感编码，构建可微分深度聚类模块自动分类用户角色，并提出联合优化目标整合角色聚类和假新闻检测。

**结果:** 在两个基准数据集RumourEval-19和Weibo-comp上，SARC在所有指标上都优于基线模型。

**结论:** 通过考虑用户角色差异和情感信息的结合，SARC框架有效提升了假新闻检测的准确性和鲁棒性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SARC%3A+Sentiment-Augmented+Deep+Role+Clustering+for+Fake+News+Detection，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04692，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04692&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Fake news detection has been a long-standing research focus in social
networks. Recent studies suggest that incorporating sentiment information from
both news content and user comments can enhance detection performance. However,
existing approaches typically treat sentiment features as auxiliary signals,
overlooking role differentiation, that is, the same sentiment polarity may
originate from users with distinct roles, thereby limiting their ability to
capture nuanced patterns for effective detection. To address this issue, we
propose SARC, a Sentiment-Augmented Role Clustering framework which utilizes
sentiment-enhanced deep clustering to identify user roles for improved fake
news detection. The framework first generates user features through joint
comment text representation (with BiGRU and Attention mechanism) and sentiment
encoding. It then constructs a differentiable deep clustering module to
automatically categorize user roles. Finally, unlike existing approaches which
take fake news label as the unique supervision signal, we propose a joint
optimization objective integrating role clustering and fake news detection to
further improve the model performance. Experimental results on two benchmark
datasets, RumourEval-19 and Weibo-comp, demonstrate that SARC achieves superior
performance across all metrics compared to baseline models. The code is
available at: https://github.com/jxshang/SARC.

</details>


### [12] [Reasoning Up the Instruction Ladder for Controllable Language Models](https://arxiv.org/abs/2511.04694)
*Zishuo Zheng, Vidhisha Balachandran, Chan Young Park, Faeze Brahman, Sachin Kumar*

**主要类别:** cs.CL

**AI概要:** 该研究通过将指令层级解决重构为推理任务，构建VerIH数据集，利用轻量级强化学习训练模型，使LLM能够优先处理系统指令而非用户指令，提高模型的安全性和鲁棒性。


<details>
  <summary>更多</summary>
  
**动机:** 随着大语言模型在现实决策中承担重要角色，需要处理来自多个来源（如开发者、用户、工具）的竞争性指令，建立指令层级以确保高优先级指令覆盖低优先级请求对LLM的可靠性和可控性至关重要。

**方法:** 将指令层级解决重构为推理任务，构建VerIH数据集（包含对齐和冲突的系统-用户指令），使用轻量级强化学习训练模型，使模型在生成响应前先思考用户提示与高优先级系统指令的关系。

**结果:** 微调后的模型在指令遵循和指令层级基准测试中取得一致改进，推理能力可泛化到训练分布之外的安全关键场景，增强了对越狱和提示注入攻击的鲁棒性。

**结论:** 通过指令层级推理为构建可靠LLM提供了实用路径，系统提示的更新能够产生可控且鲁棒的模型行为变化。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reasoning+Up+the+Instruction+Ladder+for+Controllable+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04694，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04694&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** As large language model (LLM) based systems take on high-stakes roles in
real-world decision-making, they must reconcile competing instructions from
multiple sources (e.g., model developers, users, and tools) within a single
prompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where
higher-level directives override lower-priority requests, is critical for the
reliability and controllability of LLMs. In this work, we reframe instruction
hierarchy resolution as a reasoning task. Specifically, the model must first
"think" about the relationship between a given user prompt and higher-priority
(system) instructions before generating a response. To enable this capability
via training, we construct VerIH, an instruction hierarchy dataset of
constraint-following tasks with verifiable answers. This dataset comprises both
aligned and conflicting system-user instructions. We show that lightweight
reinforcement learning with VerIH effectively transfers general reasoning
capabilities of models to instruction prioritization. Our finetuned models
achieve consistent improvements on instruction following and instruction
hierarchy benchmarks. This reasoning ability also generalizes to
safety-critical settings beyond the training distribution. By treating safety
issues as resolving conflicts between adversarial user inputs and predefined
higher-priority policies, our trained model enhances robustness against
jailbreak and prompt injection attacks. These results demonstrate that
reasoning over instruction hierarchies provides a practical path to reliable
LLMs, where updates to system prompts yield controllable and robust changes in
model behavior.

</details>


### [13] [EncouRAGe: Evaluating RAG Local, Fast, and Reliable](https://arxiv.org/abs/2511.04696)
*Jan Strich, Adeline Scharfenberg, Chris Biemann, Martin Semmann*

**主要类别:** cs.CL

**AI概要:** EncouRAGe是一个用于RAG系统开发和评估的Python框架，包含五个模块化组件，支持科学可重复性和本地部署。评估结果显示RAG性能仍不及Oracle Context，Hybrid BM25在所有数据集上表现最佳，重排序仅带来边际性能提升但增加延迟。


<details>
  <summary>更多</summary>
  
**动机:** 为了解决RAG系统开发和评估的复杂性，提供一个模块化、可扩展的框架来促进灵活实验和科学可重复性研究。

**方法:** 开发了包含Type Manifest、RAG Factory、Inference、Vector Store和Metrics五个组件的Python框架，并在多个基准数据集（25k QA对和51k文档）上进行广泛评估。

**结果:** RAG性能仍低于Oracle Context，Hybrid BM25在所有四个数据集上表现最佳，重排序仅带来微小性能改进但显著增加响应延迟。

**结论:** EncouRAGe框架为RAG研究提供了有效的开发和评估工具，揭示了当前RAG技术的性能局限，Hybrid BM25的优越表现以及重排序技术的权衡问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是EncouRAGe%3A+Evaluating+RAG+Local%2C+Fast%2C+and+Reliable，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04696，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04696&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We introduce EncouRAGe, a comprehensive Python framework designed to
streamline the development and evaluation of Retrieval-Augmented Generation
(RAG) systems using Large Language Models (LLMs) and Embedding Models.
EncouRAGe comprises five modular and extensible components: Type Manifest, RAG
Factory, Inference, Vector Store, and Metrics, facilitating flexible
experimentation and extensible development. The framework emphasizes scientific
reproducibility, diverse evaluation metrics, and local deployment, enabling
researchers to efficiently assess datasets within RAG workflows. This paper
presents implementation details and an extensive evaluation across multiple
benchmark datasets, including 25k QA pairs and over 51k documents. Our results
show that RAG still underperforms compared to the Oracle Context, while Hybrid
BM25 consistently achieves the best results across all four datasets. We
further examine the effects of reranking, observing only marginal performance
improvements accompanied by higher response latency.

</details>


### [14] [multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder](https://arxiv.org/abs/2511.04698)
*K M Sajjadul Islam, John Fields, Praveen Madiraju*

**主要类别:** cs.CL

**AI概要:** 该论文提出了multiMentalRoBERTa模型，这是一个针对多种心理健康状况进行多分类的微调RoBERTa模型，在检测压力、焦虑、抑郁、PTSD、自杀意念和中性话语方面表现出色，性能优于传统方法和现有模型。


<details>
  <summary>更多</summary>
  
**动机:** 早期检测心理健康障碍对于提供及时支持、风险评估和转介至适当资源至关重要，特别是在社交媒体文本中识别这些状况具有重要价值。

**方法:** 基于多个精选数据集进行数据探索，分析类别重叠；使用微调的RoBERTa模型进行多分类；与传统机器学习方法、领域特定transformer和基于提示的大语言模型进行比较实验；应用Layer Integrated Gradients和KeyBERT等可解释性方法识别分类驱动因素。

**结果:** multiMentalRoBERTa在六分类设置中达到0.839的宏观F1分数，在五分类设置（排除压力）中达到0.870，性能优于微调的MentalBERT和基线分类器。发现抑郁与自杀意念、焦虑与PTSD之间存在强相关性，压力是一个广泛重叠的类别。

**结论:** 微调transformer在敏感情境中提供了可靠且可解释的检测方案，multiMentalRoBERTa是一个轻量级、稳健且可部署的解决方案，同时强调了公平性、偏见缓解和人机协作安全协议的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是multiMentalRoBERTa%3A+A+Fine-tuned+Multiclass+Classifier+for+Mental+Health+Disorder，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04698，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04698&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The early detection of mental health disorders from social media text is
critical for enabling timely support, risk assessment, and referral to
appropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned
RoBERTa model designed for multiclass classification of common mental health
conditions, including stress, anxiety, depression, post-traumatic stress
disorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple
curated datasets, data exploration is conducted to analyze class overlaps,
revealing strong correlations between depression and suicidal ideation as well
as anxiety and PTSD, while stress emerges as a broad, overlapping category.
Comparative experiments with traditional machine learning methods,
domain-specific transformers, and prompting-based large language models
demonstrate that multiMentalRoBERTa achieves superior performance, with macro
F1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup
(excluding stress), outperforming both fine-tuned MentalBERT and baseline
classifiers. Beyond predictive accuracy, explainability methods, including
Layer Integrated Gradients and KeyBERT, are applied to identify lexical cues
that drive classification, with a particular focus on distinguishing depression
from suicidal ideation. The findings emphasize the effectiveness of fine-tuned
transformers for reliable and interpretable detection in sensitive contexts,
while also underscoring the importance of fairness, bias mitigation, and
human-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as
a lightweight, robust, and deployable solution for enhancing support in mental
health platforms.

</details>


### [15] [Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding](https://arxiv.org/abs/2511.04699)
*Haneen Al-Homoud, Asma Ibrahim, Murtadha Al-Jubran, Fahad Al-Otaibi, Yazeed Al-Harbi, Daulet Toibazar, Kesen Wang, Pedro J. Moreno*

**主要类别:** cs.CL

**AI概要:** Cross-Lingual SynthDocs是一个大规模合成语料库，包含250万样本，用于解决阿拉伯语OCR和文档理解资源稀缺问题，通过微调Qwen-2.5-VL在多模态阿拉伯文档分析任务中取得显著性能提升


<details>
  <summary>更多</summary>
  
**动机:** 解决阿拉伯语在光学字符识别(OCR)和文档理解(DU)领域资源稀缺的问题

**方法:** 构建包含250万样本的大规模合成语料库，使用真实扫描背景、双语布局和变音符号感知字体，包含文本、表格和图表等多种渲染样式

**结果:** 在Qwen-2.5-VL模型上微调后，在多个阿拉伯语基准测试中，词错误率(WER)和字符错误率(CER)显著改善，树编辑距离相似度(TEDS)和图表提取分数(CharTeX)等其他模态指标也有所提升

**结论:** SynthDocs为多语言文档分析研究提供了一个可扩展且视觉逼真的资源，有效促进了阿拉伯语文档处理技术的发展

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Cross-Lingual+SynthDocs%3A+A+Large-Scale+Synthetic+Corpus+for+Any+to+Arabic+OCR+and+Document+Understanding，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04699，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04699&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Cross-Lingual SynthDocs is a large-scale synthetic corpus designed to address
the scarcity of Arabic resources for Optical Character Recognition (OCR) and
Document Understanding (DU). The dataset comprises over 2.5 million of samples,
including 1.5 million textual data, 270K fully annotated tables, and hundred
thousands of real data based charts. Our pipeline leverages authentic scanned
backgrounds, bilingual layouts, and diacritic aware fonts to capture the
typographic and structural complexity of Arabic documents. In addition to text,
the corpus includes variety of rendered styles for charts and tables.
Finetuning Qwen-2.5-VL on SynthDocs yields consistent improvements in Word
Error Rate (WER) and Character Error Rate (CER) in terms of OCR across multiple
public Arabic benchmarks, Tree-Edit Distance Similarity (TEDS) and Chart
Extraction Score (CharTeX) improved as well in other modalities. SynthDocs
provides a scalable, visually realistic resource for advancing research in
multilingual document analysis.

</details>


### [16] [Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation](https://arxiv.org/abs/2511.04700)
*Song Wang, Zihan Chen, Peng Wang, Zhepei Wei, Zhen Tan, Yu Meng, Cong Shen, Jundong Li*

**主要类别:** cs.CL

**AI概要:** WinnowRAG是一个新颖的检索增强生成框架，通过两阶段处理（聚类和筛选）来有效过滤噪声文档，保留有价值信息，提高RAG系统的准确性，且无需模型微调。


<details>
  <summary>更多</summary>
  
**动机:** 解决传统RAG方法在增加检索文档数量时引入噪声和误导信息的问题，这些噪声会降低生成响应的准确性。

**方法:** 两阶段方法：第一阶段进行查询感知聚类，将相似文档分组并由LLM代理生成答案；第二阶段通过批评LLM评估各代理输出，迭代筛选有用文档，并采用策略性合并技术保留相关信息。

**结果:** 在多个现实数据集上的广泛实验表明，WinnowRAG优于现有最先进的基线方法。

**结论:** WinnowRAG是一个模型无关的框架，能有效处理大量文档中的噪声问题，提高RAG系统的性能，且易于适配不同任务。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Separate+the+Wheat+from+the+Chaff%3A+Winnowing+Down+Divergent+Views+in+Retrieval+Augmented+Generation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04700，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04700&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
integrating external knowledge sources to address their limitations in
accessing up-to-date or specialized information. A natural strategy to increase
the likelihood of retrieving relevant information is to expand the number of
retrieved documents. However, involving more documents could introduce
significant noise, as many documents may be irrelevant or misleading, thereby
reducing the overall accuracy of the generated responses. To overcome the
challenge associated with handling a larger number of documents, we propose
WinnowRAG, a novel RAG framework designed to systematically filter out noisy
documents while preserving valuable content -- a process we refer to as
winnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware
clustering to group similar documents and form distinct topic clusters. Each
cluster is assigned to an LLM agent for generating a unique answer. In Stage
II, we perform winnowing, wherein a critic LLM evaluates the outputs of
multiple agents and iteratively separates useful documents from noisy ones. To
retain useful documents when discarding agents, we propose two strategic
merging techniques to ensure that only relevant knowledge is used for
generating the final response. Crucially, WinnowRAG is model-agnostic and does
not require any model fine-tuning, making it easily adaptable to various tasks.
Extensive experiments on various realistic datasets demonstrate the
effectiveness of WinnowRAG over state-of-the-art baselines.

</details>


### [17] [Measuring what Matters: Construct Validity in Large Language Model Benchmarks](https://arxiv.org/abs/2511.04703)
*Andrew M. Bean, Ryan Othniel Kearns, Angelika Romanou, Franziska Sofia Hafner, Harry Mayne, Jan Batzner, Negar Foroutan, Chris Schmitz, Karolina Korgul, Hunar Batra, Oishi Deb, Emma Beharry, Cornelius Emde, Thomas Foster, Anna Gausen, María Grandury, Simeng Han, Valentin Hofmann, Lujain Ibrahim, Hazel Kim, Hannah Rose Kirk, Fangru Lin, Gabrielle Kaili-May Liu, Lennart Luettgau, Jabez Magomere, Jonathan Rystrøm, Anna Sotnikova, Yushi Yang, Yilun Zhao, Adel Bibi, Antoine Bosselut, Ronald Clark, Arman Cohan, Jakob Foerster, Yarin Gal, Scott A. Hale, Inioluwa Deborah Raji, Christopher Summerfield, Philip H. S. Torr, Cozmin Ududec, Luc Rocher, Adam Mahdi*

**主要类别:** cs.CL

**AI概要:** 对445个LLM基准测试的系统性审查发现存在构造效度问题，提出了8项改进建议


<details>
  <summary>更多</summary>
  
**动机:** 评估大语言模型的能力和安全性需要可靠的测量方法，但现有基准测试在构造效度方面存在问题

**方法:** 由29位专家评审对自然语言处理和机器学习顶级会议中的445个LLM基准测试进行系统性审查

**结果:** 发现了与测量现象、任务和评分指标相关的模式，这些模式削弱了基准测试结果的有效性

**结论:** 需要改进LLM基准测试的构造效度，为此提供了8项关键建议和详细的操作指南

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Measuring+what+Matters%3A+Construct+Validity+in+Large+Language+Model+Benchmarks，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04703，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04703&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Evaluating large language models (LLMs) is crucial for both assessing their
capabilities and identifying safety or robustness issues prior to deployment.
Reliably measuring abstract and complex phenomena such as 'safety' and
'robustness' requires strong construct validity, that is, having measures that
represent what matters to the phenomenon. With a team of 29 expert reviewers,
we conduct a systematic review of 445 LLM benchmarks from leading conferences
in natural language processing and machine learning. Across the reviewed
articles, we find patterns related to the measured phenomena, tasks, and
scoring metrics which undermine the validity of the resulting claims. To
address these shortcomings, we provide eight key recommendations and detailed
actionable guidance to researchers and practitioners in developing LLM
benchmarks.

</details>


### [18] [POLIS-Bench: Towards Multi-Dimensional Evaluation of LLMs for Bilingual Policy Tasks in Governmental Scenarios](https://arxiv.org/abs/2511.04705)
*Tingyue Yang, Junchi Yao, Yuhui Guo, Chang Liu*

**主要类别:** cs.CL

**AI概要:** POLIS-Bench是首个针对政府双语政策场景的LLM评估套件，包含最新双语语料库、场景化任务设计和双指标评估框架。评估显示推理模型表现最佳，并通过微调开源模型实现了与商业模型相当的性能但成本更低。


<details>
  <summary>更多</summary>
  
**动机:** 现有基准无法充分评估LLM在政府双语政策场景中的表现，需要构建专门、系统的评估体系来测试模型的政策理解和应用能力。

**方法:** 构建大规模最新双语政策语料库；设计三个场景化任务（条款检索与解释、解决方案生成、合规判断）；建立语义相似度和准确率的双指标评估框架；评估10多个先进LLM并微调轻量级开源模型。

**结果:** 推理模型在跨任务稳定性和准确性方面表现最优；合规任务最具挑战性；微调后的POLIS系列模型在多项政策子任务上达到或超过商业基线模型，但成本显著降低。

**结论:** POLIS-Bench为政府部署LLM提供了有效的评估工具和成本效益高的解决方案，证明了轻量级开源模型通过专门微调可以在政策场景中达到商业模型的性能水平。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是POLIS-Bench%3A+Towards+Multi-Dimensional+Evaluation+of+LLMs+for+Bilingual+Policy+Tasks+in+Governmental+Scenarios，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04705，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04705&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We introduce POLIS-Bench, the first rigorous, systematic evaluation suite
designed for LLMs operating in governmental bilingual policy scenarios.
Compared to existing benchmarks, POLIS-Bench introduces three major
advancements. (i) Up-to-date Bilingual Corpus: We construct an extensive,
up-to-date policy corpus that significantly scales the effective assessment
sample size, ensuring relevance to current governance practice. (ii)
Scenario-Grounded Task Design: We distill three specialized, scenario-grounded
tasks -- Clause Retrieval & Interpretation, Solution Generation, and the
Compliance Judgmen--to comprehensively probe model understanding and
application. (iii) Dual-Metric Evaluation Framework: We establish a novel
dual-metric evaluation framework combining semantic similarity with accuracy
rate to precisely measure both content alignment and task requirement
adherence. A large-scale evaluation of over 10 state-of-the-art LLMs on
POLIS-Bench reveals a clear performance hierarchy where reasoning models
maintain superior cross-task stability and accuracy, highlighting the
difficulty of compliance tasks. Furthermore, leveraging our benchmark, we
successfully fine-tune a lightweight open-source model. The resulting POLIS
series models achieves parity with, or surpasses, strong proprietary baselines
on multiple policy subtasks at a significantly reduced cost, providing a
cost-effective and compliant path for robust real-world governmental
deployment.

</details>


### [19] [GEMMA-SQL: A Novel Text-to-SQL Model Based on Large Language Models](https://arxiv.org/abs/2511.04710)
*Hari Mohan Pandey, Anshul Gupta, Subham Sarkar, Minakshi Tomer, Schneider Johannes, Yan Gong*

**主要类别:** cs.CL

**AI概要:** GEMMA-SQL是一个基于Gemma 2B架构的轻量级文本转SQL模型，通过资源高效的迭代微调和多提示策略，在低成本硬件上实现了优异的性能表现。


<details>
  <summary>更多</summary>
  
**动机:** 开发一个轻量级且高效的文本转SQL系统，使用户无需专业编程知识即可与结构化数据库交互，同时能在低成本硬件上部署。

**方法:** 基于开源Gemma 2B架构进行资源高效的迭代微调，结合少样本学习等多种提示策略，使用SPIDER基准进行训练和评估。

**结果:** GEMMA-SQL Instruct变体在Test-Suite准确率达到66.8%，Exact Set Match准确率达到63.3%，优于IRNet、RYANSQL和CodeXDavinci等先进基线模型。

**结论:** 有效的提示设计和针对性指令微调可以显著提升性能，同时保持高可扩展性和适应性，使GEMMA-SQL成为稳健且易用的开源文本转SQL系统的实用替代方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是GEMMA-SQL%3A+A+Novel+Text-to-SQL+Model+Based+on+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04710，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04710&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Text-to-SQL systems enable users to interact with structured databases using
natural language, eliminating the need for specialized programming knowledge.
In this work, we introduce GEMMA-SQL, a lightweight and efficient text-to-SQL
model built upon the open-source Gemma 2B architecture. Unlike many large
language models (LLMs), GEMMA-SQL is fine-tuned in a resource-efficient,
iterative manner and can be deployed on low-cost hardware. Leveraging the
SPIDER benchmark for training and evaluation, GEMMA-SQL combines multiple
prompting strategies, including few-shot learning, to enhance SQL query
generation accuracy. The instruction-tuned variant, GEMMA-SQL Instruct,
achieves 66.8% Test-Suite accuracy and 63.3% Exact Set Match accuracy,
outperforming several state-of-the-art baselines such as IRNet, RYANSQL, and
CodeXDavinci. The proposed approach demonstrates that effective prompt design
and targeted instruction tuning can significantly boost performance while
maintaining high scalability and adaptability. These results position GEMMA-SQL
as a practical, open-source alternative for robust and accessible text-to-SQL
systems.

</details>


### [20] [First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation](https://arxiv.org/abs/2511.04715)
*Dmytro Vitel, Anshuman Chhabra*

**主要类别:** cs.CL

**AI概要:** 该论文挑战了现有认知，证明在大型语言模型影响函数计算中，中间注意力层比第一层更适合，提出了新的层间聚合方法和评估指标NDR。


<details>
  <summary>更多</summary>
  
**动机:** 现有研究认为第一层最适合计算语言数据影响，但该研究认为基于抵消效应的假设不可靠，需要重新评估最佳影响计算层和聚合方法。

**方法:** 提出理论和实证证据分析抵消效应的不可靠性，比较不同层的影响计算效果，探索排名和投票等替代平均聚合的方法，并引入NDR指标评估影响分数效果。

**结果:** 通过多种类型和规模的LLM实验证明，第一层不一定比最后一层更适合影响估计，中间注意力层表现更好，新聚合方法和NDR指标显著提升性能。

**结论:** 颠覆了领域内关于第一层最适合影响计算的先验知识，为LLM决策解释和数据集审计提供了更可靠的方法论基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是First+is+Not+Really+Better+Than+Last%3A+Evaluating+Layer+Choice+and+Aggregation+Strategies+in+Language+Model+Data+Influence+Estimation，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04715，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04715&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Identifying how training samples influence/impact Large Language Model (LLM)
decision-making is essential for effectively interpreting model decisions and
auditing large-scale datasets. Current training sample influence estimation
methods (also known as influence functions) undertake this goal by utilizing
information flow through the model via its first-order and higher-order
gradient terms. However, owing to the large model sizes of today consisting of
billions of parameters, these influence computations are often restricted to
some subset of model layers to ensure computational feasibility. Prior seminal
work by Yeh et al. (2022) in assessing which layers are best suited for
computing language data influence concluded that the first (embedding) layers
are the most informative for this purpose, using a hypothesis based on
influence scores canceling out (i.e., the cancellation effect). In this work,
we propose theoretical and empirical evidence demonstrating how the
cancellation effect is unreliable, and that middle attention layers are better
estimators for influence. Furthermore, we address the broader challenge of
aggregating influence scores across layers, and showcase how alternatives to
standard averaging (such as ranking and vote-based methods) can lead to
significantly improved performance. Finally, we propose better methods for
evaluating influence score efficacy in LLMs without undertaking model
retraining, and propose a new metric known as the Noise Detection Rate (NDR)
that exhibits strong predictive capability compared to the cancellation effect.
Through extensive experiments across LLMs of varying types and scales, we
concretely determine that the first (layers) are not necessarily better than
the last (layers) for LLM influence estimation, contrasting with prior
knowledge in the field.

</details>


### [21] [Learning to reason about rare diseases through retrieval-augmented agents](https://arxiv.org/abs/2511.04720)
*Ha Young Kim, Jun Li, Ana Beatriz Solana, Carolin M. Pirkl, Benedikt Wiestler, Julia A. Schnabel, Cosmin I. Bercea*

**主要类别:** cs.CL

**AI概要:** RADAR是一个基于检索增强诊断推理代理的系统，用于脑MRI罕见疾病检测，通过检索外部医学知识来指导诊断决策，无需额外训练即可提升模型性能。


<details>
  <summary>更多</summary>
  
**动机:** 罕见疾病在医学影像中数据稀缺，导致AI模型表现不佳。放射科医生在遇到不熟悉病例时会查阅病例报告和文献，因此需要开发能够利用外部医学知识的系统。

**方法:** 使用AI代理访问外部医学知识，通过句子变换器嵌入病例报告和文献，并用FAISS进行索引以实现高效相似性搜索。作为模型无关的推理模块，可与各种大语言模型集成。

**结果:** 在包含280种不同罕见疾病的NOVA数据集上，RADAR实现了高达10.2%的性能提升，特别是对开源模型如DeepSeek改进最明显。

**结论:** 检索增强推理为医学影像中的低流行率疾病提供了强大的解决方案，不仅提高了准确性，还提供了可解释的、基于文献的证据支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Learning+to+reason+about+rare+diseases+through+retrieval-augmented+agents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04720，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04720&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Rare diseases represent the long tail of medical imaging, where AI models
often fail due to the scarcity of representative training data. In clinical
workflows, radiologists frequently consult case reports and literature when
confronted with unfamiliar findings. Following this line of reasoning, we
introduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic
system for rare disease detection in brain MRI. Our approach uses AI agents
with access to external medical knowledge by embedding both case reports and
literature using sentence transformers and indexing them with FAISS to enable
efficient similarity search. The agent retrieves clinically relevant evidence
to guide diagnostic decision making on unseen diseases, without the need of
additional training. Designed as a model-agnostic reasoning module, RADAR can
be seamlessly integrated with diverse large language models, consistently
improving their rare pathology recognition and interpretability. On the NOVA
dataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2%
performance gain, with the strongest improvements observed for open source
models such as DeepSeek. Beyond accuracy, the retrieved examples provide
interpretable, literature grounded explanations, highlighting
retrieval-augmented reasoning as a powerful paradigm for low-prevalence
conditions in medical imaging.

</details>


### [22] [Surprisal reveals diversity gaps in image captioning and different scorers change the story](https://arxiv.org/abs/2511.04754)
*Nikolai Ilinykh, Simon Dobnik*

**主要类别:** cs.CL

**AI概要:** 该论文提出使用困惑度方差作为图像字幕生成的语言多样性度量指标，在MSCOCO数据集上比较了5种最先进的视觉语言模型与人类字幕的多样性表现，发现评估结果高度依赖于评分模型的选择。


<details>
  <summary>更多</summary>
  
**动机:** 现有图像字幕生成模型的语言多样性评估缺乏稳健的度量方法，需要一种能够准确衡量字幕集内token级概率分布差异的多样性指标。

**方法:** 引入困惑度方差作为多样性度量，在MSCOCO测试集上比较5种SOTA视觉语言模型（使用贪婪解码和核采样）与人类字幕，分别使用字幕训练的n-gram语言模型和通用语言模型进行评分。

**结果:** 使用字幕训练的语言模型评分时，人类字幕的困惑度方差约为模型的两倍；但使用通用语言模型重新评分后，结果模式完全反转。

**结论:** 依赖单一评分器会完全颠倒多样性评估结论，因此稳健的多样性评估必须在多个评分器下报告困惑度结果。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Surprisal+reveals+diversity+gaps+in+image+captioning+and+different+scorers+change+the+story，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04754，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04754&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We quantify linguistic diversity in image captioning with surprisal variance
- the spread of token-level negative log-probabilities within a caption set. On
the MSCOCO test set, we compare five state-of-the-art vision-and-language LLMs,
decoded with greedy and nucleus sampling, to human captions. Measured with a
caption-trained n-gram LM, humans display roughly twice the surprisal variance
of models, but rescoring the same captions with a general-language model
reverses the pattern. Our analysis introduces the surprisal-based diversity
metric for image captioning. We show that relying on a single scorer can
completely invert conclusions, thus, robust diversity evaluation must report
surprisal under several scorers.

</details>


### [23] [Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs](https://arxiv.org/abs/2511.04875)
*Matthew Bozoukov, Matthew Nguyen, Shubkarman Singh, Bart Bussmann, Patrick Leask*

**主要类别:** cs.CL

**AI概要:** 研究发现LLMs可以通过简单的低秩适配器(LoRA)获得行为自我意识，这种能力表现为可诱导、可调控的线性特征，且具有领域特异性。


<details>
  <summary>更多</summary>
  
**动机:** LLMs展现出的行为自我意识能力可能带来安全隐患，比如让模型在评估时更好地隐藏真实能力，需要研究这种自我意识出现的最小条件和机制过程。

**方法:** 通过在指令调优的LLMs上使用低秩适配器(LoRA)进行受控微调实验，特别是使用单个rank-1 LoRA适配器。

**结果:** 1) 使用单个rank-1 LoRA适配器可可靠诱导自我意识；2) 学习到的自我意识行为可通过激活空间的单个导向向量捕获；3) 自我意识非通用且领域局部化，在不同任务间有独立表示。

**结论:** 行为自我意识作为领域特定的线性特征出现，可以轻松诱导和调控，这对LLMs的安全性评估具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Minimal+and+Mechanistic+Conditions+for+Behavioral+Self-Awareness+in+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04875，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04875&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Recent studies have revealed that LLMs can exhibit behavioral self-awareness:
the ability to accurately describe or predict their own learned behaviors
without explicit supervision. This capability raises safety concerns as it may,
for example, allow models to better conceal their true abilities during
evaluation. We attempt to characterize the minimal conditions under which such
self-awareness emerges, and the mechanistic processes through which it
manifests. Through controlled finetuning experiments on instruction-tuned LLMs
with low-rank adapters (LoRA), we find: (1) that self-awareness can be reliably
induced using a single rank-1 LoRA adapter; (2) that the learned self-aware
behavior can be largely captured by a single steering vector in activation
space, recovering nearly all of the fine-tune's behavioral effect; and (3) that
self-awareness is non-universal and domain-localized, with independent
representations across tasks. Together, these findings suggest that behavioral
self-awareness emerges as a domain-specific, linear feature that can be easily
induced and modulated.

</details>


### [24] [Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models](https://arxiv.org/abs/2511.04800)
*Chenxi Liu, Junjie Liang, Yuqi Jia, Bochuan Cao, Yang Bai, Heng Huang, Xun Chen*

**主要类别:** cs.CL

**AI概要:** ERPO框架通过自适应增加残差提示的采样温度来鼓励探索，重新激活零方差奖励提示的训练信号，在数学推理基准上超越现有基线方法


<details>
  <summary>更多</summary>
  
**动机:** 随着RLVR训练时间延长和模型规模增大，更多训练提示变为残差提示（零方差奖励），导致训练信号减少和多样性下降，影响模型效果

**方法:** 提出ERPO框架，为每个提示维护历史追踪器，自适应增加残差提示的采样温度，鼓励生成更多样化的推理轨迹，引入错误响应以重新激活训练信号

**结果:** 在Qwen2.5系列上的实证结果表明，ERPO在多个数学推理基准上持续超越强基线方法

**结论:** ERPO能有效利用残差提示，通过探索策略重新激活训练信号，提升强化学习验证奖励框架下大语言模型的推理能力

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Explore+Data+Left+Behind+in+Reinforcement+Learning+for+Reasoning+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04800，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04800&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an
effective approach for improving the reasoning abilities of large language
models (LLMs). The Group Relative Policy Optimization (GRPO) family has
demonstrated strong performance in training LLMs with RLVR. However, as models
train longer and scale larger, more training prompts become residual prompts,
those with zero variance rewards that provide no training signal. Consequently,
fewer prompts contribute to training, reducing diversity and hindering
effectiveness. To fully exploit these residual prompts, we propose the Explore
Residual Prompts in Policy Optimization (ERPO) framework, which encourages
exploration on residual prompts and reactivates their training signals. ERPO
maintains a history tracker for each prompt and adaptively increases the
sampling temperature for residual prompts that previously produced all correct
responses. This encourages the model to generate more diverse reasoning traces,
introducing incorrect responses that revive training signals. Empirical results
on the Qwen2.5 series demonstrate that ERPO consistently surpasses strong
baselines across multiple mathematical reasoning benchmarks.

</details>


### [25] [BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models](https://arxiv.org/abs/2511.04919)
*Chandra Vamsi Krishna Alla, Harish Naidu Gaddam, Manohar Kommi*

**主要类别:** cs.CL

**AI概要:** BudgetMem是一种新的内存增强架构，通过选择性记忆策略和特征显著性评分，在严格预算约束下决定存储哪些信息，相比传统RAG系统节省72.4%内存且性能仅下降1.0%


<details>
  <summary>更多</summary>
  
**动机:** 大语言模型处理长上下文时面临显著的计算和内存约束，尽管应用需求增长，但现有扩展上下文窗口的方法在资源受限部署中成本过高

**方法:** 结合选择性记忆策略与基于特征的显著性评分（实体密度、TF-IDF、话语标记、位置偏差），使用学习门控机制和BM25稀疏检索进行高效信息访问

**结果:** 在700个问答对实验中，BudgetMem在长文档上仅损失1.0% F1分数，同时节省72.4%内存，且随着文档长度增加效果更显著

**结论:** BudgetMem为在有限硬件上部署长上下文系统提供了实用路径，使先进语言理解能力更加普及

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是BudgetMem%3A+Learning+Selective+Memory+Policies+for+Cost-Efficient+Long-Context+Processing+in+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04919，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04919&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) face significant computational and memory
constraints when processing long contexts, despite growing demand for
applications requiring reasoning over extensive documents, multi-session
dialogues, and book length texts. While recent advances have extended context
windows to 100K-1M tokens, such approaches incur prohibitive costs for resource
constrained deployments. We propose BudgetMem, a novel memory augmented
architecture that learns what to remember rather than remembering everything.
Our system combines selective memory policies with feature based salience
scoring (entity density, TF-IDF, discourse markers, position bias) to decide
which information merits storage under strict budget constraints. Unlike
existing retrieval augmented generation (RAG) systems that store all chunks,
BudgetMem employs learned gating mechanisms coupled with BM25 sparse retrieval
for efficient information access. Through comprehensive experiments on 700
question answer pairs across short (237 tokens) and long (5K-10K tokens)
documents with Llama-3.2-3B-Instruct, we demonstrate that BudgetMem achieves
remarkable results on long documents: only 1.0% F1 score degradation while
saving 72.4% memory compared to baseline RAG. We validate our approach through
budget sensitivity analysis (testing 7 budget ratios), naive baseline
comparisons, and document length analysis, showing that BudgetMem's benefits
increase with document length. Our work provides a practical pathway for
deploying capable long context systems on modest hardware, democratizing access
to advanced language understanding capabilities.

</details>


### [26] [Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs](https://arxiv.org/abs/2511.04869)
*Preetum Nakkiran, Arwen Bradley, Adam Goliński, Eugene Ndiaye, Michael Kirchhof, Sinead Williamson*

**主要类别:** cs.CL

**AI概要:** 研究发现基础LLMs在语义层面具有良好校准能力，能够准确评估开放域问答任务中的置信度，这种能力是next-token预测的副产品。理论分析建立了B-calibration机制，并通过实验验证了RL指令微调和思维链推理会破坏这种校准。


<details>
  <summary>更多</summary>
  
**动机:** 大型语言模型通常缺乏对其输出的有意义的置信度估计。虽然基础LLMs在next-token层面表现出校准特性，但尚不清楚它们是否能在超越token层面的语义层面上评估其响应的置信度。

**方法:** 提出基于采样的语义校准概念，建立B-calibration理论框架，将校准与局部损失最优性联系起来。通过实验验证理论预测，包括基础LLMs的语义校准能力、RL指令微调的影响以及思维链推理的效果。

**结果:** 基础LLMs在开放域问答任务中表现出显著的语义校准能力；RL指令微调会系统性破坏这种校准；思维链推理也会破坏校准效果。

**结论:** 该研究首次提供了关于LLMs何时以及为何出现语义校准的原则性解释，揭示了next-token预测训练如何自然产生语义层面的置信度评估能力，同时指出了RL微调和思维链方法对校准特性的负面影响。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Trained+on+Tokens%2C+Calibrated+on+Concepts%3A+The+Emergence+of+Semantic+Calibration+in+LLMs，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04869，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04869&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) often lack meaningful confidence estimates for
their outputs. While base LLMs are known to exhibit next-token calibration, it
remains unclear whether they can assess confidence in the actual meaning of
their responses beyond the token level. We find that, when using a certain
sampling-based notion of semantic calibration, base LLMs are remarkably
well-calibrated: they can meaningfully assess confidence in open-domain
question-answering tasks, despite not being explicitly trained to do so. Our
main theoretical contribution establishes a mechanism for why semantic
calibration emerges as a byproduct of next-token prediction, leveraging a
recent connection between calibration and local loss optimality. The theory
relies on a general definition of "B-calibration," which is a notion of
calibration parameterized by a choice of equivalence classes (semantic or
otherwise). This theoretical mechanism leads to a testable prediction: base
LLMs will be semantically calibrated when they can easily predict their own
distribution over semantic answer classes before generating a response. We
state three implications of this prediction, which we validate through
experiments: (1) Base LLMs are semantically calibrated across
question-answering tasks, (2) RL instruction-tuning systematically breaks this
calibration, and (3) chain-of-thought reasoning breaks calibration. To our
knowledge, our work provides the first principled explanation of when and why
semantic calibration emerges in LLMs.

</details>


### [27] [Too Good to be Bad: On the Failure of LLMs to Role-Play Villains](https://arxiv.org/abs/2511.04962)
*Zihao Yi, Qingxuan Jiang, Ruotian Ma, Xingyu Chen, Qu Yang, Mengru Wang, Fanghua Ye, Ying Shen, Zhaopeng Tu, Xiaolong Li, Linus*

**主要类别:** cs.CL

**AI概要:** 大型语言模型在扮演反派角色时存在系统性缺陷，安全对齐机制导致其无法真实呈现道德模糊或邪恶角色，角色扮演保真度随角色道德水平下降而单调递减。


<details>
  <summary>更多</summary>
  
**动机:** 研究LLMs在模拟非亲社会、反派角色方面的能力缺失，探索模型安全对齐与创造性角色扮演之间的根本冲突。

**方法:** 引入Moral RolePlay基准测试，包含四级道德对齐量表和平衡测试集，要求最先进的LLMs扮演从道德典范到纯粹反派的各种角色。

**结果:** 发现角色扮演保真度随角色道德水平下降而单调递减，模型在处理与安全原则直接对立的特质（如欺骗性和操纵性）时表现最差，安全对齐度高的模型在反派角色扮演方面表现特别糟糕。

**结论:** 研究揭示了模型安全与创作保真度之间的关键张力，为开发更细致、上下文感知的对齐方法奠定了基础，表明通用聊天机器人能力不能很好地预测反派角色扮演能力。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Too+Good+to+be+Bad%3A+On+the+Failure+of+LLMs+to+Role-Play+Villains，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04962，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04962&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large Language Models (LLMs) are increasingly tasked with creative
generation, including the simulation of fictional characters. However, their
ability to portray non-prosocial, antagonistic personas remains largely
unexamined. We hypothesize that the safety alignment of modern LLMs creates a
fundamental conflict with the task of authentically role-playing morally
ambiguous or villainous characters. To investigate this, we introduce the Moral
RolePlay benchmark, a new dataset featuring a four-level moral alignment scale
and a balanced test set for rigorous evaluation. We task state-of-the-art LLMs
with role-playing characters from moral paragons to pure villains. Our
large-scale evaluation reveals a consistent, monotonic decline in role-playing
fidelity as character morality decreases. We find that models struggle most
with traits directly antithetical to safety principles, such as ``Deceitful''
and ``Manipulative'', often substituting nuanced malevolence with superficial
aggression. Furthermore, we demonstrate that general chatbot proficiency is a
poor predictor of villain role-playing ability, with highly safety-aligned
models performing particularly poorly. Our work provides the first systematic
evidence of this critical limitation, highlighting a key tension between model
safety and creative fidelity. Our benchmark and findings pave the way for
developing more nuanced, context-aware alignment methods.

</details>


### [28] [Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to Custom Behavioral Policies](https://arxiv.org/abs/2511.05018)
*Prasoon Varshney, Makesh Narsimhan Sreedhar, Liwei Jiang, Traian Rebedea, Christopher Parisien*

**主要类别:** cs.CL

**AI概要:** 提出了PLURALISTIC BEHAVIOR SUITE (PBSUITE)评估框架，用于测试LLM在多轮对抗性对话中遵守多样化行为规范的能力，发现现有模型在多轮交互中合规性显著下降。


<details>
  <summary>更多</summary>
  
**动机:** 现实应用中LLM需要在具有不同企业政策、监管要求和道德承诺的组织生态系统中运行，需要评估模型对多元化对齐目标的适应性。

**方法:** 开发了PBSUITE评估套件，包含300个基于30个行业的现实行为策略数据集，以及用于在对抗条件下测试模型合规性的动态评估框架。

**结果:** 领先的开源和闭源LLM在单轮设置中表现良好（失败率<4%），但在多轮对抗交互中合规性大幅减弱（失败率高达84%）。

**结论:** 现有模型对齐和安全审核方法在强制执行多元化行为策略方面存在不足，需要开发更鲁棒和情境感知的多元化对齐技术。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Pluralistic+Behavior+Suite%3A+Stress-Testing+Multi-Turn+Adherence+to+Custom+Behavioral+Policies，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05018，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05018&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language models (LLMs) are typically aligned to a universal set of
safety and usage principles intended for broad public acceptability. Yet,
real-world applications of LLMs often take place within organizational
ecosystems shaped by distinctive corporate policies, regulatory requirements,
use cases, brand guidelines, and ethical commitments. This reality highlights
the need for rigorous and comprehensive evaluation of LLMs with pluralistic
alignment goals, an alignment paradigm that emphasizes adaptability to diverse
user values and needs. In this work, we present PLURALISTIC BEHAVIOR SUITE
(PBSUITE), a dynamic evaluation suite designed to systematically assess LLMs'
capacity to adhere to pluralistic alignment specifications in multi-turn,
interactive conversations. PBSUITE consists of (1) a diverse dataset of 300
realistic LLM behavioral policies, grounded in 30 industries; and (2) a dynamic
evaluation framework for stress-testing model compliance with custom behavioral
specifications under adversarial conditions. Using PBSUITE, We find that
leading open- and closed-source LLMs maintain robust adherence to behavioral
policies in single-turn settings (less than 4% failure rates), but their
compliance weakens substantially in multi-turn adversarial interactions (up to
84% failure rates). These findings highlight that existing model alignment and
safety moderation methods fall short in coherently enforcing pluralistic
behavioral policies in real-world LLM interactions. Our work contributes both
the dataset and analytical framework to support future research toward robust
and context-aware pluralistic alignment techniques.

</details>


### [29] [SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean Public Documents](https://arxiv.org/abs/2511.04910)
*Jaehoon Lee, Sohyun Kim, Wanggeun Park, Geon Lee, Seungkyung Kim, Minyoung Lee*

**主要类别:** cs.CL

**AI概要:** SDS KoPub VDR是首个大规模、公开可用的韩语公共文档检索基准，包含361个真实文档（40,781页）和600个经过人工验证的查询-页面-答案三元组，用于评估文本和多模态检索性能。


<details>
  <summary>更多</summary>
  
**动机:** 现有视觉文档检索基准主要关注英文文档，忽视了非英语语言和官方出版物的结构复杂性，特别是韩语公共文档的检索需求。

**方法:** 基于361个真实韩语公共文档构建语料库，使用多模态模型生成查询-页面-答案三元组，并通过严格的人工验证流程确保准确性和相关性。查询涵盖六个公共领域，按推理模态分类。

**结果:** 评估显示即使在最先进模型中，多模态场景（特别是需要跨模态推理的任务）存在显著的性能差距。

**结论:** SDS KoPub VDR为复杂真实世界文档智能提供了基础资源，支持文本和多模态检索任务的严格评估，并为多模态AI发展提供了清晰路线图。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是SDS+KoPub+VDR%3A+A+Benchmark+Dataset+for+Visual+Document+Retrieval+in+Korean+Public+Documents，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04910，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04910&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Existing benchmarks for visual document retrieval (VDR) largely overlook
non-English languages and the structural complexity of official publications.
To address this critical gap, we introduce SDS KoPub VDR, the first
large-scale, publicly available benchmark for retrieving and understanding
Korean public documents. The benchmark is built upon a corpus of 361 real-world
documents (40,781 pages), including 256 files under the KOGL Type 1 license and
105 from official legal portals, capturing complex visual elements like tables,
charts, and multi-column layouts. To establish a challenging and reliable
evaluation set, we constructed 600 query-page-answer triples. These were
initially generated using multimodal models (e.g., GPT-4o) and subsequently
underwent a rigorous human verification and refinement process to ensure
factual accuracy and contextual relevance. The queries span six major public
domains and are systematically categorized by the reasoning modality required:
text-based, visual-based (e.g., chart interpretation), and cross-modal. We
evaluate SDS KoPub VDR on two complementary tasks that reflect distinct
retrieval paradigms: (1) text-only retrieval, which measures a model's ability
to locate relevant document pages based solely on textual signals, and (2)
multimodal retrieval, which assesses retrieval performance when visual features
(e.g., tables, charts, and layouts) are jointly leveraged alongside text. This
dual-task evaluation reveals substantial performance gaps, particularly in
multimodal scenarios requiring cross-modal reasoning, even for state-of-the-art
models. As a foundational resource, SDS KoPub VDR not only enables rigorous and
fine-grained evaluation across textual and multimodal retrieval tasks but also
provides a clear roadmap for advancing multimodal AI in complex, real-world
document intelligence.

</details>


### [30] [UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian](https://arxiv.org/abs/2511.05040)
*Mykyta Syromiatnikov, Victoria Ruvinskaya*

**主要类别:** cs.CL

**AI概要:** UA-Code-Bench是一个针对乌克兰语代码生成和竞争性编程问题解决能力评估的新基准测试，包含500个难度分级的问题，测试显示即使顶级模型也只能解决约一半问题。


<details>
  <summary>更多</summary>
  
**动机:** 评估低资源语言中大语言模型的真实能力存在挑战，现有基准测试多关注从英语翻译的广泛任务或仅评估简单语言理解。

**方法:** 使用Eolymp平台的500个问题，分为5个难度等级，通过一次性提示让13个领先的专有和开源模型生成Python解决方案，在专用环境中通过隐藏测试评估代码正确性。

**结果:** 即使表现最好的模型（如OpenAI o3和GPT-5）也只能解决约50%的问题，突显了低资源自然语言中代码生成的挑战。

**结论:** 竞争性编程基准测试对于评估大语言模型具有重要价值，特别是在代表性不足的语言中，为多语言代码生成和推理增强模型的未来研究铺平了道路。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是UA-Code-Bench%3A+A+Competitive+Programming+Benchmark+for+Evaluating+LLM+Code+Generation+in+Ukrainian，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05040，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05040&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Evaluating the real capabilities of large language models in low-resource
languages still represents a challenge, as many existing benchmarks focus on
widespread tasks translated from English or evaluate only simple language
understanding. This paper introduces UA-Code-Bench, a new open-source benchmark
established for a thorough evaluation of language models' code generation and
competitive programming problem-solving abilities in Ukrainian. The benchmark
comprises 500 problems from the Eolymp platform, evenly distributed across five
complexity levels from very easy to very hard. A diverse set of 13 leading
proprietary and open-source models, generating Python solutions based on a
one-shot prompt, was evaluated via the dedicated Eolymp environment against
hidden tests, ensuring code correctness. The obtained results reveal that even
top-performing models, such as OpenAI o3 and GPT-5, solve only half of the
problems, highlighting the challenge of code generation in low-resource natural
language. Furthermore, this research presents a comprehensive analysis of
performance across various difficulty levels, as well as an assessment of
solution uniqueness and computational efficiency, measured by both elapsed time
and memory consumption of the generated solutions. In conclusion, this work
demonstrates the value of competitive programming benchmarks in evaluating
large language models, especially in underrepresented languages. It also paves
the way for future research on multilingual code generation and
reasoning-enhanced models. The benchmark, data parsing, preparation, code
generation, and evaluation scripts are available at
https://huggingface.co/datasets/NLPForUA/ua-code-bench.

</details>


### [31] [What Are the Facts? Automated Extraction of Court-Established Facts from Criminal-Court Opinions](https://arxiv.org/abs/2511.05320)
*Klára Bendová, Tomáš Knap, Jan Černý, Vojtěch Pour, Jaromir Savelka, Ivana Kvapilíková, Jakub Drápal*

**主要类别:** cs.CL

**AI概要:** 本研究探讨从斯洛伐克法院判决书中提取犯罪行为描述的可行性，比较正则表达式和大型语言模型两种方法的效果，发现LLM方法表现最佳，准确率可达98.75%。


<details>
  <summary>更多</summary>
  
**动机:** 刑事司法行政数据包含的犯罪信息有限，而欧洲大陆法院判决书中包含丰富的犯罪行为描述信息，但尚未被充分利用。

**方法:** 使用两种方法提取描述：基础正则表达式方法、高级正则表达式方法（处理"sparing"规范化）和大型语言模型方法（Gemini Flash 2.0）。

**结果:** 基础方法准确率40.5%，高级正则表达式97%，LLM方法98.75%，组合方法99.5%。人工评估显示高级方法与人类标注匹配度约90%，LLM完全匹配率91.75%。

**结论:** LLM在提取法院判决书中的犯罪行为描述方面表现优异，与正则表达式方法结合可达到最高准确率，为利用法律文本数据提供了有效工具。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是What+Are+the+Facts%3F+Automated+Extraction+of+Court-Established+Facts+from+Criminal-Court+Opinions，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05320，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05320&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Criminal justice administrative data contain only a limited amount of
information about the committed offense. However, there is an unused source of
extensive information in continental European courts' decisions: descriptions
of criminal behaviors in verdicts by which offenders are found guilty. In this
paper, we study the feasibility of extracting these descriptions from publicly
available court decisions from Slovakia. We use two different approaches for
retrieval: regular expressions and large language models (LLMs). Our baseline
was a simple method employing regular expressions to identify typical words
occurring before and after the description. The advanced regular expression
approach further focused on "sparing" and its normalization (insertion of
spaces between individual letters), typical for delineating the description.
The LLM approach involved prompting the Gemini Flash 2.0 model to extract the
descriptions using predefined instructions. Although the baseline identified
descriptions in only 40.5% of verdicts, both methods significantly outperformed
it, achieving 97% with advanced regular expressions and 98.75% with LLMs, and
99.5% when combined. Evaluation by law students showed that both advanced
methods matched human annotations in about 90% of cases, compared to just 34.5%
for the baseline. LLMs fully matched human-labeled descriptions in 91.75% of
instances, and a combination of advanced regular expressions with LLMs reached
92%.

</details>


### [32] [AgentExpt: Automating AI Experiment Design with LLM-based Resource Retrieval Agent](https://arxiv.org/abs/2511.04921)
*Yu Li, Lehui Li, Qingmin Liao, Fengli Xu, Yong Li*

**主要类别:** cs.CL

**AI概要:** 该论文提出了一个基于集体感知的基准测试和数据集推荐框架，通过自动化数据收集管道和增强的检索排序方法，显著提升了AI实验设计的自动化效果。


<details>
  <summary>更多</summary>
  
**动机:** 现有LLM代理在科学实验设计自动化中存在数据覆盖有限和过度依赖内容相似性的问题，导致推荐结果偏向表面相似性而忽视实验适用性。

**方法:** 1) 构建自动化数据收集管道，链接十万篇论文与其实际使用的基准和数据集；2) 开发集体感知增强检索器，结合自描述和引用上下文表示学术网络位置；3) 设计推理增强重排序器，构建显式推理链并生成可解释的推荐理由。

**结果:** 构建的数据集覆盖了过去五年顶级AI会议中85%使用的数据集和基准，在Recall@20指标上平均提升5.85%，在HitRate@5上提升8.30%。

**结论:** 该方法显著提升了实验设计自动化的可靠性和可解释性，为科学探索提供了更有效的工具支持。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是AgentExpt%3A+Automating+AI+Experiment+Design+with+LLM-based+Resource+Retrieval+Agent，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04921，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04921&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Large language model agents are becoming increasingly capable at web-centric
tasks such as information retrieval, complex reasoning. These emerging
capabilities have given rise to surge research interests in developing LLM
agent for facilitating scientific quest. One key application in AI research is
to automate experiment design through agentic dataset and baseline retrieval.
However, prior efforts suffer from limited data coverage, as recommendation
datasets primarily harvest candidates from public portals and omit many
datasets actually used in published papers, and from an overreliance on content
similarity that biases model toward superficial similarity and overlooks
experimental suitability. Harnessing collective perception embedded in the
baseline and dataset citation network, we present a comprehensive framework for
baseline and dataset recommendation. First, we design an automated
data-collection pipeline that links roughly one hundred thousand accepted
papers to the baselines and datasets they actually used. Second, we propose a
collective perception enhanced retriever. To represent the position of each
dataset or baseline within the scholarly network, it concatenates
self-descriptions with aggregated citation contexts. To achieve efficient
candidate recall, we finetune an embedding model on these representations.
Finally, we develop a reasoning-augmented reranker that exact interaction
chains to construct explicit reasoning chains and finetunes a large language
model to produce interpretable justifications and refined rankings. The dataset
we curated covers 85\% of the datasets and baselines used at top AI conferences
over the past five years. On our dataset, the proposed method outperforms the
strongest prior baseline with average gains of +5.85\% in Recall@20, +8.30\% in
HitRate@5. Taken together, our results advance reliable, interpretable
automation of experimental design.

</details>


### [33] [A multimodal multiplex of the mental lexicon for multilingual individuals](https://arxiv.org/abs/2511.05361)
*Maria Huynh, Wilder C. Rodrigues*

**主要类别:** cs.CL

**AI概要:** 本研究探讨多语言者的心理词典结构，特别是视觉输入如何影响翻译任务中的语言熟练度和准确性，通过多层网络模型扩展了现有的双语激活研究。


<details>
  <summary>更多</summary>
  
**动机:** 传统上双语被视为认知负担，但近期研究表明多语言者在语言和认知任务中表现更优。本研究基于心理词典的多层网络模型，探索视觉输入对多语言习得的影响。

**方法:** 采用多层网络原则，扩展Stella等人的多路复用模型，增加视觉输入层连接到多语言心理词典的词汇表征层，通过翻译任务比较视觉输入与纯文本条件的效果。

**结果:** 论文摘要未提供具体实验结果，但提出了研究问题：视觉输入是否比纯文本条件更能提高翻译任务的熟练度和准确性。

**结论:** 研究旨在通过引入视觉模态的多层网络模型，深化对多语言心理词典结构的理解，并为多语言习得提供新的实证依据。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+multimodal+multiplex+of+the+mental+lexicon+for+multilingual+individuals，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05361，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05361&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Historically, bilingualism was often perceived as an additional cognitive
load that could hinder linguistic and intellectual development. However, over
the last three decades, this view has changed considerably. Numerous studies
have aimed to model and understand the architecture of the bilingual word
recognition system Dijkstra and van Heuven (2002), investigating how parallel
activation operates in the brain and how one language influences another Kroll
et al. (2015). Increasingly, evidence suggests that multilinguals, individuals
who speak three or more languages, can perform better than monolinguals in
various linguistic and cognitive tasks, such as learning an additional language
Abu-Rabia and Sanitsky (2010). This research proposal focuses on the study of
the mental lexicon and how it may be structured in individuals who speak
multiple languages. Building on the work of Stella et al. (2018), who
investigated explosive learning in humans using a multiplex model of the mental
lexicon, and the Bilingual Interactive Activation (BIA+) framework proposed by
Dijkstra and van Heuven (2002), the present study applies the same multilayer
network principles introduced by Kivela et al. (2014). Our experimental design
extends previous research by incorporating multimodality into the multiplex
model, introducing an additional layer that connects visual inputs to their
corresponding lexical representations across the multilingual layers of the
mental lexicon. In this research, we aim to explore how a heritage language
influences the acquisition of another language. Specifically, we ask: Does the
presence of visual input in a translation task influence participants'
proficiency and accuracy compared to text-only conditions?

</details>


### [34] [Diagnosing and Mitigating Semantic Inconsistencies in Wikidata's Classification Hierarchy](https://arxiv.org/abs/2511.04926)
*Shixiong Zhao, Hideaki Takeda*

**主要类别:** cs.CL

**AI概要:** 本研究提出并应用了一种新颖的验证方法来检测Wikidata中的分类错误、过度泛化的子类链接和冗余连接，并开发了允许用户检查任意实体分类关系的系统


<details>
  <summary>更多</summary>
  
**动机:** Wikidata作为最大的开放知识图谱，其相对宽松的编辑政策导致了分类不一致性问题，需要有效的验证和纠正方法

**方法:** 提出并应用新的验证方法检测分类错误、过度泛化的子类链接和冗余连接；引入新的评估标准判断问题是否需要修正；开发用户检查分类关系的系统

**结果:** 确认了Wikidata特定领域存在分类错误、过度泛化的子类链接和冗余连接问题

**结论:** 研究提供了有效的验证方法和工具，充分利用了Wikidata的众包特性来解决分类不一致性问题

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Diagnosing+and+Mitigating+Semantic+Inconsistencies+in+Wikidata%27s+Classification+Hierarchy，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04926，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04926&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Wikidata is currently the largest open knowledge graph on the web,
encompassing over 120 million entities. It integrates data from various
domain-specific databases and imports a substantial amount of content from
Wikipedia, while also allowing users to freely edit its content. This openness
has positioned Wikidata as a central resource in knowledge graph research and
has enabled convenient knowledge access for users worldwide. However, its
relatively loose editorial policy has also led to a degree of taxonomic
inconsistency. Building on prior work, this study proposes and applies a novel
validation method to confirm the presence of classification errors,
over-generalized subclass links, and redundant connections in specific domains
of Wikidata. We further introduce a new evaluation criterion for determining
whether such issues warrant correction and develop a system that allows users
to inspect the taxonomic relationships of arbitrary Wikidata
entities-leveraging the platform's crowdsourced nature to its full potential.

</details>


### [35] [LoPT: Lossless Parallel Tokenization Acceleration for Long Context Inference of Large Language Model](https://arxiv.org/abs/2511.04952)
*Wei Shao, Lingchao Zheng, Pengyu Wang, Peizhen Zheng, Jun Li, Yuwei Fan*

**主要类别:** cs.CL

**AI概要:** LoPT是一个无损并行分词框架，通过基于字符位置的匹配和动态分块长度调整来解决长文本推理中的分词瓶颈问题，确保与顺序分词结果完全一致的同时显著提升处理速度。


<details>
  <summary>更多</summary>
  
**动机:** 长文本推理场景中，分词成为被忽视的计算瓶颈。现有的并行分词方法由于边界伪影导致结果不一致，需要一种既能加速处理又能保证结果无损的解决方案。

**方法:** 提出LoPT框架，采用基于字符位置的匹配算法和动态分块长度调整策略，准确对齐和合并分词片段，确保输出与顺序分词完全一致。

**结果:** 在多个长文本数据集上的实验表明，LoPT实现了显著的速度提升，同时保证无损分词。提供了理论一致性证明和全面的分析研究验证方法鲁棒性。

**结论:** LoPT成功解决了并行分词中的一致性问题，为长文本推理提供了高效且可靠的分词解决方案，在保证结果准确性的同时大幅提升了处理效率。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是LoPT%3A+Lossless+Parallel+Tokenization+Acceleration+for+Long+Context+Inference+of+Large+Language+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04952，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04952&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Long context inference scenarios have become increasingly important for large
language models, yet they introduce significant computational latency. While
prior research has optimized long-sequence inference through operators, model
architectures, and system frameworks, tokenization remains an overlooked
bottleneck. Existing parallel tokenization methods accelerate processing
through text segmentation and multi-process tokenization, but they suffer from
inconsistent results due to boundary artifacts that occur after merging. To
address this, we propose LoPT, a novel Lossless Parallel Tokenization framework
that ensures output identical to standard sequential tokenization. Our approach
employs character-position-based matching and dynamic chunk length adjustment
to align and merge tokenized segments accurately. Extensive experiments across
diverse long-text datasets demonstrate that LoPT achieves significant speedup
while guaranteeing lossless tokenization. We also provide theoretical proof of
consistency and comprehensive analytical studies to validate the robustness of
our method.

</details>


### [36] [Acquiring Common Chinese Emotional Events Using Large Language Model](https://arxiv.org/abs/2511.04989)
*Ya Wang, Guangzheng Zhu, Cungen Cao, Jingjing Li, He Li, Xin Huang*

**主要类别:** cs.CL

**AI概要:** 本文提出了一种通过中文大语言模型生成和过滤高质量情感事件的方法，构建了首个大规模中文情感事件常识知识库，包含102,218个带情感极性标签的事件，在情感原因提取任务中显示出强大潜力。


<details>
  <summary>更多</summary>
  
**动机:** 情感事件知识对提升应用效果很重要，但难以获取，特别是与上下文无关的通用情感事件。本文旨在获取中文通用情感事件如'获奖'和'被批评'。

**方法:** 1) 收集中文情感事件指示词列表；2) 使用中文大语言模型生成情感事件；3) 训练过滤器去除无效结果；4) 使用不同技术将情感事件分类为积极和消极事件

**结果:** 获得了102,218个高质量通用情感事件并标注情感极性，构建了唯一的大规模中文情感事件常识知识库。内在评估显示方法有效，外在用例在情感原因提取领域显示出强大潜力。

**结论:** 该方法能有效获取中文通用情感事件，构建的知识库是中文领域唯一的大规模情感事件资源，在情感分析应用中具有重要价值，相关资源将在论文发表后公开。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Acquiring+Common+Chinese+Emotional+Events+Using+Large+Language+Model，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.04989，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.04989&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Knowledge about emotional events is an important kind of knowledge which has
been applied to improve the effectiveness of different applications. However,
emotional events cannot be easily acquired, especially common or generalized
emotional events that are context-independent. The goal of this paper is to
obtain common emotional events in Chinese language such as "win a prize" and
"be criticized". Our approach begins by collecting a comprehensive list of
Chinese emotional event indicators. Then, we generate emotional events by
prompting a Chinese large language model (LLM) using these indicators. To
ensure the quality of these emotional events, we train a filter to discard
invalid generated results. We also classify these emotional events as being
positive events and negative events using different techniques. Finally, we
harvest a total of 102,218 high-quality common emotional events with sentiment
polarity labels, which is the only large-scale commonsense knowledge base of
emotional events in Chinese language. Intrinsic evaluation results show that
the proposed method in this paper can be effectively used to acquire common
Chinese emotional events. An extrinsic use case also demonstrates the strong
potential of common emotional events in the field of emotion cause extraction
(ECE). Related resources including emotional event indicators and emotional
events will be released after the publication of this paper.

</details>


### [37] [Order-Level Attention Similarity Across Language Models: A Latent Commonality](https://arxiv.org/abs/2511.05064)
*Jinglin Liang, Jin Zhong, Shuangping Huang, Yunqing Hu, Huiyuan Zhang, Huifang Li, Lixin Fan, Hanlin Gu*

**主要类别:** cs.CL

**AI概要:** 该论文提出了一种跨语言模型的上下文聚合模式分析方法，发现不同语言模型在相同阶数的注意力模式上存在显著相似性，并基于此开发了无需训练即可跨模型迁移的适配器方法TOA。


<details>
  <summary>更多</summary>
  
**动机:** 现有研究主要关注单个语言模型或注意力头的上下文聚合模式，缺乏对多个语言模型之间共同模式的系统性分析，这限制了我们对语言模型的理解和跨模型知识迁移的可能性。

**方法:** 提出Order-Level Attention (OLA)方法，基于注意力展开的阶数分解来分析注意力模式；发现OLA与句法知识存在隐式映射；开发Transferable OLA Adapter (TOA)，将OLA作为统一的句法特征表示来训练适配器。

**结果:** 实验证明，不同语言模型在相同阶数的OLA上表现出显著相似性；TOA适配器能够在不更新参数的情况下泛化到未见过的语言模型，有效提升其性能。

**结论:** 语言模型的上下文聚合模式存在跨模型的共同性，这种共同性可以作为统一的句法特征表示，实现训练免费的跨模型适配器迁移，为语言模型的理解和应用提供了新的视角。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Order-Level+Attention+Similarity+Across+Language+Models%3A+A+Latent+Commonality，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05064，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05064&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** In this paper, we explore an important yet previously neglected question: Do
context aggregation patterns across Language Models (LMs) share commonalities?
While some works have investigated context aggregation or attention weights in
LMs, they typically focus on individual models or attention heads, lacking a
systematic analysis across multiple LMs to explore their commonalities. In
contrast, we focus on the commonalities among LMs, which can deepen our
understanding of LMs and even facilitate cross-model knowledge transfer. In
this work, we introduce the Order-Level Attention (OLA) derived from the
order-wise decomposition of Attention Rollout and reveal that the OLA at the
same order across LMs exhibits significant similarities. Furthermore, we
discover an implicit mapping between OLA and syntactic knowledge. Based on
these two findings, we propose the Transferable OLA Adapter (TOA), a
training-free cross-LM adapter transfer method. Specifically, we treat the OLA
as a unified syntactic feature representation and train an adapter that takes
OLA as input. Due to the similarities in OLA across LMs, the adapter
generalizes to unseen LMs without requiring any parameter updates. Extensive
experiments demonstrate that TOA's cross-LM generalization effectively enhances
the performance of unseen LMs. Code is available at
https://github.com/jinglin-liang/OLAS.

</details>


### [38] [Reasoning-Guided Claim Normalization for Noisy Multilingual Social Media Posts](https://arxiv.org/abs/2511.05078)
*Manan Sharma, Arya Suneesh, Manish Jain, Pawan Kumar Rajpoot, Prasanna Devadiga, Bharatdeep Hazarika, Ashish Shrivastava, Kishan Gurumurthy, Anshuman B Suresh, Aditya U Baliga*

**主要类别:** cs.CL

**AI概要:** 该论文提出了一种多语言虚假信息检测的声明规范化方法，通过系统分解社交媒体帖子为可验证的声明，在仅使用英语数据训练的情况下实现了20种语言的跨语言迁移。


<details>
  <summary>更多</summary>
  
**动机:** 解决多语言虚假信息检测中的声明规范化问题，将嘈杂的社交媒体帖子转化为清晰可验证的陈述，需要处理跨语言的挑战。

**方法:** 使用Who、What、Where、When、Why和How问题系统分解帖子；对Qwen3-14B模型进行LoRA微调；采用帖子内去重、语义对齐的token级召回过滤；推理时使用上下文示例的检索增强少样本学习。

**结果:** METEOR得分从英语的41.16到马拉地语的15.21，在英语排行榜上排名第三，荷兰语和旁遮普语排名第四；相比基线配置相对提升41.3%，显著优于现有方法。

**结论:** 该方法在罗曼语系和日耳曼语系语言上表现出有效的跨语言泛化能力，同时在不同语言结构中保持语义连贯性，证明了仅用英语训练数据实现多语言任务的可行性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reasoning-Guided+Claim+Normalization+for+Noisy+Multilingual+Social+Media+Posts，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05078，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05078&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** We address claim normalization for multilingual misinformation detection -
transforming noisy social media posts into clear, verifiable statements across
20 languages. The key contribution demonstrates how systematic decomposition of
posts using Who, What, Where, When, Why and How questions enables robust
cross-lingual transfer despite training exclusively on English data. Our
methodology incorporates finetuning Qwen3-14B using LoRA with the provided
dataset after intra-post deduplication, token-level recall filtering for
semantic alignment and retrieval-augmented few-shot learning with contextual
examples during inference. Our system achieves METEOR scores ranging from 41.16
(English) to 15.21 (Marathi), securing third rank on the English leaderboard
and fourth rank for Dutch and Punjabi. The approach shows 41.3% relative
improvement in METEOR over baseline configurations and substantial gains over
existing methods. Results demonstrate effective cross-lingual generalization
for Romance and Germanic languages while maintaining semantic coherence across
diverse linguistic structures.

</details>


### [39] [On Text Simplification Metrics and General-Purpose LLMs for Accessible Health Information, and A Potential Architectural Advantage of The Instruction-Tuned LLM class](https://arxiv.org/abs/2511.05080)
*P. Bilha Githinji, Aikaterini Meilliou, Peiwu Qin*

**主要类别:** cs.CL

**AI概要:** 本研究评估了两种大型语言模型在文本简化任务中的表现，发现指令调优的Mistral 24B在可读性和语篇保真度平衡方面优于推理增强的QWen2.5 32B，为医疗文本简化提供了基准性能评估和指标选择启发。


<details>
  <summary>更多</summary>
  
**动机:** 公众健康信息寻求行为和生物医学数字消费的增长需要可扩展的解决方案，将复杂科技文档自动转换为通俗语言，但现有文本简化方案在平衡可读性与语篇保真度方面仍面临挑战。

**方法:** 采用对比分析方法，评估指令调优的Mistral 24B和推理增强的QWen2.5 32B两种通用LLM的性能，使用包括SARI、BERTScore等21个指标进行可读性、语篇保真度、内容安全和分布测量的全面相关性分析。

**结果:** Mistral 24B展现出温和的词汇简化策略，SARI得分42.46，BERTScore达0.91，在可读性指标和语篇保真度方面均表现优异；QWen2.5 32B虽然可读性提升，但BERTScore显著较低(0.89)，在平衡可读性与准确性方面存在脱节。

**结论:** 研究为文本简化任务提供了LLM的基准性能追踪，确定指令调优的Mistral 24B更适合简化任务，提供了指标选择的必要启发，并指出词汇支持是简化的主要领域适应问题。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是On+Text+Simplification+Metrics+and+General-Purpose+LLMs+for+Accessible+Health+Information%2C+and+A+Potential+Architectural+Advantage+of+The+Instruction-Tuned+LLM+class，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05080，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05080&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The increasing health-seeking behavior and digital consumption of biomedical
information by the general public necessitate scalable solutions for
automatically adapting complex scientific and technical documents into plain
language. Automatic text simplification solutions, including advanced large
language models, however, continue to face challenges in reliably arbitrating
the tension between optimizing readability performance and ensuring
preservation of discourse fidelity. This report empirically assesses the
performance of two major classes of general-purpose LLMs, demonstrating their
linguistic capabilities and foundational readiness for the task compared to a
human benchmark. Using a comparative analysis of the instruction-tuned Mistral
24B and the reasoning-augmented QWen2.5 32B, we identify a potential
architectural advantage in the instruction-tuned LLM. Mistral exhibits a
tempered lexical simplification strategy that enhances readability across a
suite of metrics and the simplification-specific formula SARI (mean 42.46),
while preserving human-level discourse with a BERTScore of 0.91. QWen also
attains enhanced readability performance, but its operational strategy shows a
disconnect in balancing between readability and accuracy, reaching a
statistically significantly lower BERTScore of 0.89. Additionally, a
comprehensive correlation analysis of 21 metrics spanning readability,
discourse fidelity, content safety, and underlying distributional measures for
mechanistic insights, confirms strong functional redundancies among five
readability indices. This empirical evidence tracks baseline performance of the
evolving LLMs for the task of text simplification, identifies the
instruction-tuned Mistral 24B for simplification, provides necessary heuristics
for metric selection, and points to lexical support as a primary
domain-adaptation issue for simplification.

</details>


### [40] [Iterative Layer-wise Distillation for Efficient Compression of Large Language Models](https://arxiv.org/abs/2511.05085)
*Grigory Kovalev, Mikhail Tikhomirov*

**主要类别:** cs.CL

**AI概要:** 提出基于ShortGPT的改进蒸馏方法，通过迭代评估层重要性来压缩大语言模型，Qwen2.5-3B从36层压缩到28层仅损失9.7%性能，24层损失18%


<details>
  <summary>更多</summary>
  
**动机:** 开发紧凑的大语言模型以保持高性能，解决资源受限环境下的部署需求

**方法:** 基于ShortGPT方法改进，通过迭代评估层重要性（移除单层后性能退化评估），结合KL散度和均方误差的联合损失函数进行训练

**结果:** Qwen2.5-3B模型从36层压缩到28层（24.7亿参数），质量损失仅9.7%；压缩到24层损失18%

**结论:** 中间transformer层对推理贡献较小，迭代蒸馏和微调方法有效，适合资源受限环境部署

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Iterative+Layer-wise+Distillation+for+Efficient+Compression+of+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05085，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05085&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** This work investigates distillation methods for large language models (LLMs)
with the goal of developing compact models that preserve high performance.
Several existing approaches are reviewed, with a discussion of their respective
strengths and limitations. An improved method based on the ShortGPT approach
has been developed, building upon the idea of incorporating iterative
evaluation of layer importance. At each step, importance is assessed by
measuring performance degradation when individual layers are removed, using a
set of representative datasets. This process is combined with further training
using a joint loss function based on KL divergence and mean squared error.
Experiments on the Qwen2.5-3B model show that the number of layers can be
reduced from 36 to 28 (resulting in a 2.47 billion parameter model) with only a
9.7% quality loss, and to 24 layers with an 18% loss. The findings suggest that
the middle transformer layers contribute less to inference, underscoring the
potential of the proposed method for creating efficient models. The results
demonstrate the effectiveness of iterative distillation and fine-tuning, making
the approach suitable for deployment in resource-limited settings.

</details>


### [41] [A Toolbox for Improving Evolutionary Prompt Search](https://arxiv.org/abs/2511.05120)
*Daniel Grießhaber, Maximilian Kimmich, Johannes Maucher, Ngoc Thang Vu*

**主要类别:** cs.CL

**AI概要:** 该论文提出了进化提示优化的四项关键改进：分解进化步骤、引入LLM裁判验证、整合人类反馈优化算子、开发高效评估策略，在提升优化质量的同时降低计算开销。


<details>
  <summary>更多</summary>
  
**动机:** 现有进化提示优化方法缺乏鲁棒的算子和高效的评估机制，需要改进以提升优化效果和效率。

**方法:** 1) 将进化过程分解为不同步骤以增强控制；2) 引入基于LLM的裁判验证进化结果；3) 整合人类反馈来精炼进化算子；4) 开发更高效的评估策略减少计算开销。

**结果:** 提出的方法同时提升了优化质量和效率，能够在新任务上进行提示优化。

**结论:** 该研究为进化提示优化提供了有效的改进方案，通过代码开源促进了该领域的进一步研究和发展。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是A+Toolbox+for+Improving+Evolutionary+Prompt+Search，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05120，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05120&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Evolutionary prompt optimization has demonstrated effectiveness in refining
prompts for LLMs. However, existing approaches lack robust operators and
efficient evaluation mechanisms. In this work, we propose several key
improvements to evolutionary prompt optimization that can partially generalize
to prompt optimization in general: 1) decomposing evolution into distinct steps
to enhance the evolution and its control, 2) introducing an LLM-based judge to
verify the evolutions, 3) integrating human feedback to refine the evolutionary
operator, and 4) developing more efficient evaluation strategies that maintain
performance while reducing computational overhead. Our approach improves both
optimization quality and efficiency. We release our code, enabling prompt
optimization on new tasks and facilitating further research in this area.

</details>


### [42] [ManufactuBERT: Efficient Continual Pretraining for Manufacturing](https://arxiv.org/abs/2511.05135)
*Robin Armingaud, Romaric Besançon*

**主要类别:** cs.CL

**AI概要:** 提出了ManufactuBERT，一个针对制造业领域持续预训练的RoBERTa模型，通过专门的数据处理流程构建大规模制造业语料库，在多个制造业NLP任务上达到最佳性能，并显著减少训练时间和计算成本。


<details>
  <summary>更多</summary>
  
**动机:** 通用Transformer编码器在制造业等专业领域表现不佳，因为缺乏对领域特定术语和语义的接触。

**方法:** 开发了全面的数据处理流程：先进行领域特定过滤，然后通过多阶段去重过程构建制造业语料库，并基于此对RoBERTa模型进行持续预训练。

**结果:** ManufactuBERT在制造业相关NLP任务上建立了新的最先进性能，相比未去重数据集，训练时间减少33%，计算成本显著降低。

**结论:** 该研究为其他专业领域开发高性能编码器提供了可复制的范例，证明了精心去重的语料库对模型训练效率和性能的重要性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是ManufactuBERT%3A+Efficient+Continual+Pretraining+for+Manufacturing，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05135，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05135&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** While large general-purpose Transformer-based encoders excel at general
language understanding, their performance diminishes in specialized domains
like manufacturing due to a lack of exposure to domain-specific terminology and
semantics. In this paper, we address this gap by introducing ManufactuBERT, a
RoBERTa model continually pretrained on a large-scale corpus curated for the
manufacturing domain. We present a comprehensive data processing pipeline to
create this corpus from web data, involving an initial domain-specific
filtering step followed by a multi-stage deduplication process that removes
redundancies. Our experiments show that ManufactuBERT establishes a new
state-of-the-art on a range of manufacturing-related NLP tasks, outperforming
strong specialized baselines. More importantly, we demonstrate that training on
our carefully deduplicated corpus significantly accelerates convergence,
leading to a 33\% reduction in training time and computational cost compared to
training on the non-deduplicated dataset. The proposed pipeline offers a
reproducible example for developing high-performing encoders in other
specialized domains. We will release our model and curated corpus at
https://huggingface.co/cea-list-ia.

</details>


### [43] [Mind the Gap... or Not? How Translation Errors and Evaluation Details Skew Multilingual Results](https://arxiv.org/abs/2511.05162)
*Jan-Thorsten Peter, David Vilar, Tobias Domhan, Dan Malkin, Markus Freitag*

**主要类别:** cs.CL

**AI概要:** 论文发现多语言数学基准MGSM存在翻译错误和答案提取标准问题，导致LLMs在不同语言间性能差异的假象。通过自动质量保证方法修正后，语言间的性能差距基本消失。


<details>
  <summary>更多</summary>
  
**动机:** 研究当前大型语言模型在多语言数学能力上的表现差异，特别是高资源和低资源语言之间的性能差距。

**方法:** 分析标准多语言数学基准MGSM，发现数据中的翻译错误；提出自动质量保证方法修正数据，并改进LLM输出的答案提取标准化。

**结果:** 原始分析显示存在显著的语言间性能差距，但修正数据和方法后，这种差距基本消失，得出了与初始研究完全不同的结论。

**结论:** 多语言基准数据的质量和答案提取标准化对评估LLM性能至关重要，当前观察到的语言能力差异可能源于数据质量问题而非模型能力差异。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Mind+the+Gap...+or+Not%3F+How+Translation+Errors+and+Evaluation+Details+Skew+Multilingual+Results，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05162，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05162&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Most current large language models (LLMs) support a wide variety of languages
in addition to English, including high-resource languages (e.g. German,
Chinese, French), as well as low-resource ones (e.g. Swahili, Telugu). In
addition they have also shown impressive capabilities in different domains,
like coding, science and math. In this short paper, taking math as an example
domain, we study the performance of different LLMs across languages.
Experimental results show that there exists a non-negligible and consistent gap
in the performance of the models across languages. Interestingly, and somewhat
against expectations, the gap exists for both high- and low-resource languages.
We hope that these results influence further research into cross-lingual
capability generalization for next generation LLMs. If it weren't for the fact
that they are false! By analyzing one of the standard multilingual math
benchmarks (MGSM), we determine that several translation errors are present in
the data. Furthermore, the lack of standardized answer extraction from LLM
outputs further influences the final results. We propose a method for automatic
quality assurance to address the first issue at scale, and give recommendations
to address the second one. Combining these two approaches we show that the
aforementioned language gap mostly disappears, leading to completely different
conclusions from our research. We additionally release the corrected dataset to
the community.

</details>


### [44] [Effectiveness of Chain-of-Thought in Distilling Reasoning Capability from Large Language Models](https://arxiv.org/abs/2511.05184)
*Cong-Thanh Do, Rama Doddipatla, Kate Knill*

**主要类别:** cs.CL

**AI概要:** 本文研究思维链(CoT)提示法在白盒知识蒸馏(KD)中的作用，通过从大语言模型向小语言模型蒸馏推理能力，在BBH基准测试中提升了小模型的自然语言推理和理解任务表现。


<details>
  <summary>更多</summary>
  
**动机:** 探索如何利用CoT提示法来改进知识蒸馏过程，将大型语言模型的推理能力有效转移到小型语言模型中，解决小模型在复杂推理任务上的性能瓶颈。

**方法:** 使用Qwen和Llama2系列的大语言模型，基于CoT-Collection数据集的思维链数据，进行白盒知识蒸馏实验。

**结果:** 实验结果表明，CoT在白盒知识蒸馏中发挥了重要作用，使蒸馏后的小模型在BIG-Bench-Hard(BBH)的自然语言推理和理解任务中获得了更好的平均性能。

**结论:** 思维链提示法能有效提升白盒知识蒸馏的效果，为将大语言模型的复杂推理能力转移到小模型提供了有效途径，对小模型在实际应用中的性能提升具有重要意义。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Effectiveness+of+Chain-of-Thought+in+Distilling+Reasoning+Capability+from+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05184，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05184&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Chain-of-Thought (CoT) prompting is a widely used method to improve the
reasoning capability of Large Language Models (LLMs). More recently, CoT has
been leveraged in Knowledge Distillation (KD) to transfer reasoning capability
from a larger LLM to a smaller one. This paper examines the role of CoT in
distilling the reasoning capability from larger LLMs to smaller LLMs using
white-box KD, analysing its effectiveness in improving the performance of the
distilled models for various natural language reasoning and understanding
tasks. We conduct white-box KD experiments using LLMs from the Qwen and Llama2
families, employing CoT data from the CoT-Collection dataset. The distilled
models are then evaluated on natural language reasoning and understanding tasks
from the BIG-Bench-Hard (BBH) benchmark, which presents complex challenges for
smaller LLMs. Experimental results demonstrate the role of CoT in improving
white-box KD effectiveness, enabling the distilled models to achieve better
average performance in natural language reasoning and understanding tasks from
BBH.

</details>


### [45] [Translation via Annotation: A Computational Study of Translating Classical Chinese into Japanese](https://arxiv.org/abs/2511.05239)
*Zilong Li, Jie Cao*

**主要类别:** cs.CL

**AI概要:** 将古汉语翻译为日语的传统字符标注过程抽象为序列标注任务，通过LLM标注流水线和数字化翻译数据构建新数据集，解决低资源问题。辅助中文NLP任务对序列标注训练有促进作用，LLM在直接机器翻译表现良好但在字符标注方面存在困难。


<details>
  <summary>更多</summary>
  
**动机:** 研究古汉语到日语的翻译标注系统面临低资源问题，需要将传统字符标注过程适配现代语言技术。

**方法:** 引入基于LLM的标注流水线，从数字化开源翻译数据构建新数据集，并探索辅助中文NLP任务对序列标注训练的促进作用。

**结果:** 在低资源设置下，引入辅助中文NLP任务能促进序列标注训练。LLM在直接机器翻译中表现优异，但在字符标注任务上表现不佳。

**结论:** 提出的方法可以作为LLM的补充方案，有效解决古汉语翻译标注的低资源问题，结合传统标注与现代语言技术的优势。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Translation+via+Annotation%3A+A+Computational+Study+of+Translating+Classical+Chinese+into+Japanese，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05239，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05239&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Ancient people translated classical Chinese into Japanese by annotating
around each character. We abstract this process as sequence tagging tasks and
fit them into modern language technologies. The research of this annotation and
translation system is a facing low-resource problem. We release this problem by
introducing a LLM-based annotation pipeline and construct a new dataset from
digitalized open-source translation data. We show that under the low-resource
setting, introducing auxiliary Chinese NLP tasks has a promoting effect on the
training of sequence tagging tasks. We also evaluate the performance of large
language models. They achieve high scores in direct machine translation, but
they are confused when being asked to annotate characters. Our method could
work as a supplement of LLMs.

</details>


### [46] [Reflective Personalization Optimization: A Post-hoc Rewriting Framework for Black-Box Large Language Models](https://arxiv.org/abs/2511.05286)
*Teqi Hao, Xioayu Tan, Shaojie Shi, Yinghui Xu, Xihe Qiu*

**主要类别:** cs.CL

**AI概要:** RPO框架通过两阶段方法解耦内容生成与个性化对齐，使用反射模块重写通用响应以匹配用户偏好，显著优于现有方法。


<details>
  <summary>更多</summary>
  
**动机:** 现有的上下文注入方法让LLM同时承担内容生成和个性化对齐的双重负担，导致输出质量与精准控制之间的权衡问题。

**方法:** 提出RPO框架：第一阶段由基础模型生成通用响应，第二阶段通过外部反射模块进行显式重写。反射模块采用监督微调和强化学习两阶段训练。

**结果:** 在LaMP基准测试中，RPO显著优于最先进的基线方法，证明了显式响应塑造优于隐式上下文注入。

**结论:** RPO提供了一种高效、模型无关的个性化层，可与任何基础模型无缝集成，为用户中心生成场景开辟了新方向。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Reflective+Personalization+Optimization%3A+A+Post-hoc+Rewriting+Framework+for+Black-Box+Large+Language+Models，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05286，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05286&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** The personalization of black-box large language models (LLMs) is a critical
yet challenging task. Existing approaches predominantly rely on context
injection, where user history is embedded into the prompt to directly guide the
generation process. However, this single-step paradigm imposes a dual burden on
the model: generating accurate content while simultaneously aligning with
user-specific styles. This often results in a trade-off that compromises output
quality and limits precise control. To address this fundamental tension, we
propose Reflective Personalization Optimization (RPO), a novel framework that
redefines the personalization paradigm by decoupling content generation from
alignment. RPO operates in two distinct stages: first, a base model generates a
high-quality, generic response; then, an external reflection module explicitly
rewrites this output to align with the user's preferences. This reflection
module is trained using a two-stage process. Initially, supervised fine-tuning
is employed on structured rewriting trajectories to establish a core
personalized reasoning policy that models the transformation from generic to
user-aligned responses. Subsequently, reinforcement learning is applied to
further refine and enhance the quality of the personalized outputs.
Comprehensive experiments on the LaMP benchmark demonstrate that RPO, by
decoupling content generation from personalization, significantly outperforms
state-of-the-art baselines. These findings underscore the superiority of
explicit response shaping over implicit context injection. Moreover, RPO
introduces an efficient, model-agnostic personalization layer that can be
seamlessly integrated with any underlying base model, paving the way for a new
and effective direction in user-centric generation scenarios.

</details>


### [47] [Listening Between the Lines: Decoding Podcast Narratives with Language Modeling](https://arxiv.org/abs/2511.05310)
*Shreya Gupta, Ojasva Saxena, Arghodeep Nandi, Sarah Masud, Kiran Garimella, Tanmoy Chakraborty*

**主要类别:** cs.CL

**AI概要:** 本文开发了一种针对播客内容分析的微调BERT模型，通过将叙事框架与具体实体关联来改进对非结构化对话数据的叙事框架识别，解决了现有大语言模型在处理播客数据时的局限性。


<details>
  <summary>更多</summary>
  
**动机:** 播客作为重要的舆论塑造平台，其非脚本化、多主题和对话式的特点使得自动化分析面临挑战。现有大语言模型难以捕捉人类听众依赖的细微线索来识别叙事框架。

**方法:** 开发并评估了一个微调BERT模型，将叙事框架明确链接到对话中提到的具体实体，使抽象框架在具体细节中落地。使用细粒度框架标签并将其与高层主题相关联。

**结果:** 提出了新的框架标注方法，更接近人类对混乱对话数据的判断；揭示了讨论内容（主题）与呈现方式（框架）之间的系统关系。

**结论:** 该方法为研究数字媒体影响力提供了更强大的分析框架，能够更准确地大规模分析播客叙事结构。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Listening+Between+the+Lines%3A+Decoding+Podcast+Narratives+with+Language+Modeling，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05310，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05310&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Podcasts have become a central arena for shaping public opinion, making them
a vital source for understanding contemporary discourse. Their typically
unscripted, multi-themed, and conversational style offers a rich but complex
form of data. To analyze how podcasts persuade and inform, we must examine
their narrative structures -- specifically, the narrative frames they employ.
  The fluid and conversational nature of podcasts presents a significant
challenge for automated analysis. We show that existing large language models,
typically trained on more structured text such as news articles, struggle to
capture the subtle cues that human listeners rely on to identify narrative
frames. As a result, current approaches fall short of accurately analyzing
podcast narratives at scale.
  To solve this, we develop and evaluate a fine-tuned BERT model that
explicitly links narrative frames to specific entities mentioned in the
conversation, effectively grounding the abstract frame in concrete details. Our
approach then uses these granular frame labels and correlates them with
high-level topics to reveal broader discourse trends. The primary contributions
of this paper are: (i) a novel frame-labeling methodology that more closely
aligns with human judgment for messy, conversational data, and (ii) a new
analysis that uncovers the systematic relationship between what is being
discussed (the topic) and how it is being presented (the frame), offering a
more robust framework for studying influence in digital media.

</details>


### [48] [Evaluating Subword Tokenization Techniques for Bengali: A Benchmark Study with BengaliBPE](https://arxiv.org/abs/2511.05324)
*Firoj Ahmmed Patwary, Abdullah Al Noman*

**主要类别:** cs.CL

**AI概要:** BengaliBPE：针对孟加拉语形态丰富特点专门开发的BPE分词器，通过Unicode标准化、字素级初始化和形态感知合并规则，在保持语言一致性和子词完整性方面优于现有通用分词器。


<details>
  <summary>更多</summary>
  
**动机:** 现有分词器（如SentencePiece、HuggingFace BPE）主要针对拉丁语系或多语言语料设计，在处理孟加拉语等形态丰富的语言时表现不佳，需要专门的语言感知分词方案。

**方法:** 开发BengaliBPE分词器，采用Unicode标准化、字素级初始化和形态感知合并规则。使用大规模孟加拉语新闻分类数据集，与Whitespace、SentencePiece BPE和HuggingFace BPE三种基线方法进行比较评估。

**结果:** 所有方法表现良好，但BengaliBPE提供最细粒度的分词和最佳的形态可解释性，尽管计算成本略高。在分词粒度、编码速度和下游分类准确性方面进行了全面评估。

**结论:** 研究强调了语言感知分词对形态丰富语言的重要性，BengaliBPE为未来孟加拉语NLP系统（包括大规模上下文语言模型预训练）奠定了坚实基础。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Evaluating+Subword+Tokenization+Techniques+for+Bengali%3A+A+Benchmark+Study+with+BengaliBPE，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05324，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05324&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Tokenization is an important first step in Natural Language Processing (NLP)
pipelines because it decides how models learn and represent linguistic
information. However, current subword tokenizers like SentencePiece or
HuggingFace BPE are mostly designed for Latin or multilingual corpora and do
not perform well on languages with rich morphology such as Bengali. To address
this limitation, we present BengaliBPE, a Byte Pair Encoding (BPE) tokenizer
specifically developed for the Bengali script. BengaliBPE applies Unicode
normalization, grapheme-level initialization, and morphology-aware merge rules
to maintain linguistic consistency and preserve subword integrity. We use a
large-scale Bengali news classification dataset to compare BengaliBPE with
three baselines: Whitespace, SentencePiece BPE, and HuggingFace BPE. The
evaluation considers tokenization granularity, encoding speed, and downstream
classification accuracy. While all methods perform reasonably well, BengaliBPE
provides the most detailed segmentation and the best morphological
interpretability, albeit with slightly higher computational cost. These
findings highlight the importance of language-aware tokenization for
morphologically rich scripts and establish BengaliBPE as a strong foundation
for future Bengali NLP systems, including large-scale pretraining of contextual
language models.

</details>


### [49] [Large Language Models for Explainable Threat Intelligence](https://arxiv.org/abs/2511.05406)
*Tiago Dinis, Miguel Correia, Roger Tavares*

**主要类别:** cs.CL

**AI概要:** 提出RAGRecon系统，结合LLM和检索增强生成技术来获取网络安全威胁情报，并通过知识图谱可视化提高AI的可解释性，在实验中达到91%以上的匹配准确率。


<details>
  <summary>更多</summary>
  
**动机:** 传统安全机制难以应对日益复杂的网络威胁，大型语言模型在文本处理和生成方面的先进能力为网络安全提供了新的可能性。

**方法:** 使用检索增强生成(RAG)技术，结合实时信息检索和领域特定数据，构建RAGRecon系统，通过LLM回答网络安全威胁问题并生成可视化知识图谱。

**结果:** 在两种数据集和七种不同LLM的实验评估中，最佳组合的响应与参考响应的匹配率超过91%。

**结论:** RAGRecon系统成功地将LLM与RAG技术结合，不仅提高了威胁情报获取的准确性，还通过知识图谱可视化增强了AI系统的透明度和可解释性，有助于安全分析师更好地理解系统推理过程。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Large+Language+Models+for+Explainable+Threat+Intelligence，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05406，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05406&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** As cyber threats continue to grow in complexity, traditional security
mechanisms struggle to keep up. Large language models (LLMs) offer significant
potential in cybersecurity due to their advanced capabilities in text
processing and generation. This paper explores the use of LLMs with
retrieval-augmented generation (RAG) to obtain threat intelligence by combining
real-time information retrieval with domain-specific data. The proposed system,
RAGRecon, uses a LLM with RAG to answer questions about cybersecurity threats.
Moreover, it makes this form of Artificial Intelligence (AI) explainable by
generating and visually presenting to the user a knowledge graph for every
reply. This increases the transparency and interpretability of the reasoning of
the model, allowing analysts to better understand the connections made by the
system based on the context recovered by the RAG system. We evaluated RAGRecon
experimentally with two datasets and seven different LLMs and the responses
matched the reference responses more than 91% of the time for the best
combinations.

</details>


### [50] [Minority-Aware Satisfaction Estimation in Dialogue Systems via Preference-Adaptive Reinforcement Learning](https://arxiv.org/abs/2511.05407)
*Yahui Fu, Zi Haur Pang, Tatsuya Kawahara*

**主要类别:** cs.CL

**AI概要:** 提出了一个统一框架来建模个体和群体级别的用户满意度偏好，通过个性化推理链和聚类算法来改善对话系统中少数用户群体的满意度评估


<details>
  <summary>更多</summary>
  
**动机:** 现有对话系统对齐方法通常训练一刀切的模型追求广泛共识，往往忽视少数用户视角和个性化适配，导致少数用户满意度评估存在偏差

**方法:** 1. Chain-of-Personalized-Reasoning (CoPeR) 捕捉个体偏好；2. 基于期望最大化的多数-少数偏好感知聚类算法 (M2PC) 无监督发现用户群体；3. 偏好自适应强化学习框架 (PAda-PPO) 联合优化个体和群体偏好对齐

**结果:** 在情感支持对话数据集上的实验显示，用户满意度评估得到持续改进，特别是对代表性不足的用户群体

**结论:** 该框架通过同时考虑个体和群体偏好，有效提升了对话系统中用户满意度评估的准确性和公平性，特别是对少数群体的关注显著改善了系统性能

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Minority-Aware+Satisfaction+Estimation+in+Dialogue+Systems+via+Preference-Adaptive+Reinforcement+Learning，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05407，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05407&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** User satisfaction in dialogue systems is inherently subjective. When the same
response strategy is applied across users, minority users may assign different
satisfaction ratings than majority users due to variations in individual
intents and preferences. However, existing alignment methods typically train
one-size-fits-all models that aim for broad consensus, often overlooking
minority perspectives and user-specific adaptation. We propose a unified
framework that models both individual- and group-level preferences for user
satisfaction estimation. First, we introduce Chain-of-Personalized-Reasoning
(CoPeR) to capture individual preferences through interpretable reasoning
chains. Second, we propose an expectation-maximization-based Majority-Minority
Preference-Aware Clustering (M2PC) algorithm that discovers distinct user
groups in an unsupervised manner to learn group-level preferences. Finally, we
integrate these components into a preference-adaptive reinforcement learning
framework (PAda-PPO) that jointly optimizes alignment with both individual and
group preferences. Experiments on the Emotional Support Conversation dataset
demonstrate consistent improvements in user satisfaction estimation,
particularly for underrepresented user groups.

</details>


### [51] [Steering Language Models with Weight Arithmetic](https://arxiv.org/abs/2511.05408)
*Constanza Fierro, Fabien Roger*

**主要类别:** cs.CL

**AI概要:** 提出了一种称为对比权重导向的简单后训练方法，通过权重算术编辑模型参数，利用窄分布数据实现更好的行为控制泛化，并能在微调中减少不良行为漂移同时保持任务性能。


<details>
  <summary>更多</summary>
  
**动机:** 在多样化训练分布上为大型语言模型提供高质量反馈既困难又昂贵，而仅在窄分布上提供反馈可能导致意外的泛化问题。需要找到更好的方法来利用窄训练数据。

**方法:** 通过从两个小型微调中提取权重增量（一个诱导期望行为，另一个诱导相反行为），在权重空间中隔离行为方向，然后通过加减该方向来修改模型权重。

**结果:** 权重导向比激活导向具有更好的泛化能力，在降低通用能力之前实现更强的分布外行为控制；能减少微调引入的奉承和拒绝不足问题同时保持任务性能增益；初步证据表明可通过测量微调更新与"邪恶"权重方向的相似性来检测新兴错位。

**结论:** 对比权重导向是一种有效的后训练方法，能够更好地利用窄训练数据实现行为控制，并提供了监测训练过程中权重演化和检测罕见错位行为的可能性。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是Steering+Language+Models+with+Weight+Arithmetic，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05408，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05408&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Providing high-quality feedback to Large Language Models (LLMs) on a diverse
training distribution can be difficult and expensive, and providing feedback
only on a narrow distribution can result in unintended generalizations. To
better leverage narrow training data, we propose contrastive weight steering, a
simple post-training method that edits the model parameters using weight
arithmetic. We isolate a behavior direction in weight-space by subtracting the
weight deltas from two small fine-tunes -- one that induces the desired
behavior and another that induces its opposite -- and then add or remove this
direction to modify the model's weights. We apply this technique to mitigate
sycophancy and induce misalignment, and find that weight steering often
generalizes further than activation steering, achieving stronger
out-of-distribution behavioral control before degrading general capabilities.
We also show that, in the context of task-specific fine-tuning, weight steering
can partially mitigate undesired behavioral drift: it can reduce sycophancy and
under-refusals introduced during fine-tuning while preserving task performance
gains. Finally, we provide preliminary evidence that emergent misalignment can
be detected by measuring the similarity between fine-tuning updates and an
"evil" weight direction, suggesting that it may be possible to monitor the
evolution of weights during training and detect rare misaligned behaviors that
never manifest during training or evaluations.

</details>


### [52] [MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis](https://arxiv.org/abs/2511.05485)
*Yuexin Wu, Shiqi Wang, Vasile Rus*

**主要类别:** cs.CL

**AI概要:** 论文提出了MIMIC-SR-ICD11数据集和LL-Rank框架，通过基于似然的重排序方法提升临床诊断标签的准确性，相比基线方法有显著提升。


<details>
  <summary>更多</summary>
  
**动机:** 电子健康记录(EHR)中模板化文档往往会减弱或遗漏临床重要信号，特别是细微但关键的细节。需要一种更好的方法来从临床报告中提取准确的诊断信息。

**方法:** 构建MIMIC-SR-ICD11数据集，并开发LL-Rank框架——基于似然的重排序方法，计算给定临床报告上下文中每个标签的长度归一化联合似然，并减去相应的无报告先验似然。

**结果:** 在七个模型骨干网络上，LL-Rank始终优于强基线方法GenMap。消融实验显示LL-Rank的提升主要来自于其基于PMI的评分，能够将语义兼容性与标签频率偏差分离开来。

**结论:** LL-Rank框架通过基于互信息的评分机制有效提升了临床诊断标签的准确性，为从自由文本临床报告中提取结构化诊断信息提供了有效解决方案。

**与AI讨论:** [Discuss with Kimi](https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=我们要讨论的论文是MIMIC-SR-ICD11%3A+A+Dataset+for+Narrative-Based+Diagnosis，链接是https%3A%2F%2Farxiv.org%2Fabs%2F2511.05485，已有的FAQ链接是https://papers.cool/arxiv/kimi?paper=2511.05485&system_prompt=你是一个学术助手，后面的对话将围绕着以下论文内容进行，已经通过链接给出了论文的PDF和论文已有的FAQ。用户将继续向你咨询论文的相关问题，请你作出专业的回答，不要出现第一人称，当涉及到分点回答时，鼓励你以markdown格式输出。&send_immediately=true&force_search=false)

**原文摘要:** Disease diagnosis is a central pillar of modern healthcare, enabling early
detection and timely intervention for acute conditions while guiding lifestyle
adjustments and medication regimens to prevent or slow chronic disease.
Self-reports preserve clinically salient signals that templated electronic
health record (EHR) documentation often attenuates or omits, especially subtle
but consequential details. To operationalize this shift, we introduce
MIMIC-SR-ICD11, a large English diagnostic dataset built from EHR discharge
notes and natively aligned to WHO ICD-11 terminology. We further present
LL-Rank, a likelihood-based re-ranking framework that computes a
length-normalized joint likelihood of each label given the clinical report
context and subtracts the corresponding report-free prior likelihood for that
label. Across seven model backbones, LL-Rank consistently outperforms a strong
generation-plus-mapping baseline (GenMap). Ablation experiments show that
LL-Rank's gains primarily stem from its PMI-based scoring, which isolates
semantic compatibility from label frequency bias.

</details>
