{"id": "2505.08828", "pdf": "https://arxiv.org/pdf/2505.08828", "abs": "https://arxiv.org/abs/2505.08828", "authors": ["Eduardo Araujo Oliveira", "Madhavi Mohoni", "Sonsoles López-Pernas", "Mohammed Saqr"], "title": "Human-AI Collaboration or Academic Misconduct? Measuring AI Use in Student Writing Through Stylometric Evidence", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "19 pages, 10 figures, 11 tables", "summary": "As human-AI collaboration becomes increasingly prevalent in educational\ncontexts, understanding and measuring the extent and nature of such\ninteractions pose significant challenges. This research investigates the use of\nauthorship verification (AV) techniques not as a punitive measure, but as a\nmeans to quantify AI assistance in academic writing, with a focus on promoting\ntransparency, interpretability, and student development. Building on prior\nwork, we structured our investigation into three stages: dataset selection and\nexpansion, AV method development, and systematic evaluation. Using three\ndatasets - including a public dataset (PAN-14) and two from University of\nMelbourne students from various courses - we expanded the data to include\nLLM-generated texts, totalling 1,889 documents and 540 authorship problems from\n506 students. We developed an adapted Feature Vector Difference AV methodology\nto construct robust academic writing profiles for students, designed to capture\nmeaningful, individual characteristics of their writing. The method's\neffectiveness was evaluated across multiple scenarios, including distinguishing\nbetween student-authored and LLM-generated texts and testing resilience against\nLLMs' attempts to mimic student writing styles. Results demonstrate the\nenhanced AV classifier's ability to identify stylometric discrepancies and\nmeasure human-AI collaboration at word and sentence levels while providing\neducators with a transparent tool to support academic integrity investigations.\nThis work advances AV technology, offering actionable insights into the\ndynamics of academic writing in an AI-driven era."}
{"id": "2505.08891", "pdf": "https://arxiv.org/pdf/2505.08891", "abs": "https://arxiv.org/abs/2505.08891", "authors": ["Daeun Hwang", "Samuel Shields", "Alex Calderwood", "Shi Johnson-Bey", "Michael Mateas", "Noah Wardrip-Fruin", "Edward F. Melcer"], "title": "Clicking some of the silly options: Exploring Player Motivation in Static and Dynamic Educational Interactive Narratives", "categories": ["cs.CL"], "comment": "8 pages, 3 figures, 1 table, 1 appendix. Workshop paper, CHI 2025\n  Augmented Educators and AI", "summary": "Motivation is an important factor underlying successful learning. Previous\nresearch has demonstrated the positive effects that static interactive\nnarrative games can have on motivation. Concurrently, advances in AI have made\ndynamic and adaptive approaches to interactive narrative increasingly\naccessible. However, limited work has explored the impact that dynamic\nnarratives can have on learner motivation. In this paper, we compare two\nversions of Academical, a choice-based educational interactive narrative game\nabout research ethics. One version employs a traditional hand-authored\nbranching plot (i.e., static narrative) while the other dynamically sequences\nplots during play (i.e., dynamic narrative). Results highlight the importance\nof responsive content and a variety of choices for player engagement, while\nalso illustrating the challenge of balancing pedagogical goals with the dynamic\naspects of narrative. We also discuss design implications that arise from these\nfindings. Ultimately, this work provides initial steps to illuminate the\nemerging potential of AI-driven dynamic narrative in educational games."}
{"id": "2505.08996", "pdf": "https://arxiv.org/pdf/2505.08996", "abs": "https://arxiv.org/abs/2505.08996", "authors": ["Adele E Goldberg", "Supantho Rakshit", "Jennifer Hu", "Kyle Mahowald"], "title": "A suite of LMs comprehend puzzle statements as well as humans", "categories": ["cs.CL"], "comment": null, "summary": "Recent claims suggest that large language models (LMs) underperform humans in\ncomprehending minimally complex English statements (Dentella et al., 2024).\nHere, we revisit those findings and argue that human performance was\noverestimated, while LLM abilities were underestimated. Using the same stimuli,\nwe report a preregistered study comparing human responses in two conditions:\none allowed rereading (replicating the original study), and one that restricted\nrereading (a more naturalistic comprehension test). Human accuracy dropped\nsignificantly when rereading was restricted (73%), falling below that of\nFalcon-180B-Chat (76%) and GPT-4 (81%). The newer GPT-o1 model achieves perfect\naccuracy. Results further show that both humans and models are\ndisproportionately challenged by queries involving potentially reciprocal\nactions (e.g., kissing), suggesting shared pragmatic sensitivities rather than\nmodel-specific deficits. Additional analyses using Llama-2-70B log\nprobabilities, a recoding of open-ended model responses, and grammaticality\nratings of other sentences reveal systematic underestimation of model\nperformance. We find that GPT-4o can align with either naive or expert\ngrammaticality judgments, depending on prompt framing. These findings\nunderscore the need for more careful experimental design and coding practices\nin LLM evaluation, and they challenge the assumption that current models are\ninherently weaker than humans at language comprehension."}
{"id": "2505.09005", "pdf": "https://arxiv.org/pdf/2505.09005", "abs": "https://arxiv.org/abs/2505.09005", "authors": ["Nicole Cuneo", "Eleanor Graves", "Supantho Rakshit", "Adele E. Goldberg"], "title": "For GPT-4 as with Humans: Information Structure Predicts Acceptability of Long-Distance Dependencies", "categories": ["cs.CL"], "comment": null, "summary": "It remains debated how well any LM understands natural language or generates\nreliable metalinguistic judgments. Moreover, relatively little work has\ndemonstrated that LMs can represent and respect subtle relationships between\nform and function proposed by linguists. We here focus on a particular such\nrelationship established in recent work: English speakers' judgments about the\ninformation structure of canonical sentences predicts independently collected\nacceptability ratings on corresponding 'long distance dependency' [LDD]\nconstructions, across a wide array of base constructions and multiple types of\nLDDs. To determine whether any LM captures this relationship, we probe GPT-4 on\nthe same tasks used with humans and new extensions.Results reveal reliable\nmetalinguistic skill on the information structure and acceptability tasks,\nreplicating a striking interaction between the two, despite the zero-shot,\nexplicit nature of the tasks, and little to no chance of contamination [Studies\n1a, 1b]. Study 2 manipulates the information structure of base sentences and\nconfirms a causal relationship: increasing the prominence of a constituent in a\ncontext sentence increases the subsequent acceptability ratings on an LDD\nconstruction. The findings suggest a tight relationship between natural and\nGPT-4 generated English, and between information structure and syntax, which\nbegs for further exploration."}
{"id": "2505.08896", "pdf": "https://arxiv.org/pdf/2505.08896", "abs": "https://arxiv.org/abs/2505.08896", "authors": ["Pankaj Kumar", "Aditya Mishra", "Pranamesh Chakraborty", "Subrahmanya Swamy Peruru"], "title": "Deep reinforcement learning-based longitudinal control strategy for automated vehicles at signalised intersections", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Developing an autonomous vehicle control strategy for signalised\nintersections (SI) is one of the challenging tasks due to its inherently\ncomplex decision-making process. This study proposes a Deep Reinforcement\nLearning (DRL) based longitudinal vehicle control strategy at SI. A\ncomprehensive reward function has been formulated with a particular focus on\n(i) distance headway-based efficiency reward, (ii) decision-making criteria\nduring amber light, and (iii) asymmetric acceleration/ deceleration response,\nalong with the traditional safety and comfort criteria. This reward function\nhas been incorporated with two popular DRL algorithms, Deep Deterministic\nPolicy Gradient (DDPG) and Soft-Actor Critic (SAC), which can handle the\ncontinuous action space of acceleration/deceleration. The proposed models have\nbeen trained on the combination of real-world leader vehicle (LV) trajectories\nand simulated trajectories generated using the Ornstein-Uhlenbeck (OU) process.\nThe overall performance of the proposed models has been tested using Cumulative\nDistribution Function (CDF) plots and compared with the real-world trajectory\ndata. The results show that the RL models successfully maintain lower distance\nheadway (i.e., higher efficiency) and jerk compared to human-driven vehicles\nwithout compromising safety. Further, to assess the robustness of the proposed\nmodels, we evaluated the model performance on diverse safety-critical\nscenarios, in terms of car-following and traffic signal compliance. Both DDPG\nand SAC models successfully handled the critical scenarios, while the DDPG\nmodel showed smoother action profiles compared to the SAC model. Overall, the\nresults confirm that DRL-based longitudinal vehicle control strategy at SI can\nhelp to improve traffic safety, efficiency, and comfort."}
{"id": "2505.08792", "pdf": "https://arxiv.org/pdf/2505.08792", "abs": "https://arxiv.org/abs/2505.08792", "authors": ["Michelle Nashla Turcios", "Alicia E. Boyd", "Angela D. R. Smith", "Brittany Johnson"], "title": "A Preliminary Framework for Intersectionality in ML Pipelines", "categories": ["cs.LG", "cs.CY"], "comment": "Accepted for the 1st International Intersectionality and Software\n  Engineering Workshop, colocated with FSE 2025", "summary": "Machine learning (ML) has become a go-to solution for improving how we use,\nexperience, and interact with technology (and the world around us).\nUnfortunately, studies have repeatedly shown that machine learning technologies\nmay not provide adequate support for societal identities and experiences.\nIntersectionality is a sociological framework that provides a mechanism for\nexplicitly considering complex social identities, focusing on social justice\nand power. While the framework of intersectionality can support the development\nof technologies that acknowledge and support all members of society, it has\nbeen adopted and adapted in ways that are not always true to its foundations,\nthereby weakening its potential for impact. To support the appropriate adoption\nand use of intersectionality for more equitable technological outcomes, we\namplify the foundational intersectionality scholarship--Crenshaw, Combahee, and\nCollins (three C's), to create a socially relevant preliminary framework in\ndeveloping machine-learning solutions. We use this framework to evaluate and\nreport on the (mis)alignments of intersectionality application in machine\nlearning literature."}
{"id": "2505.08800", "pdf": "https://arxiv.org/pdf/2505.08800", "abs": "https://arxiv.org/abs/2505.08800", "authors": ["Olivia Nocentini", "Marta Lagomarsino", "Gokhan Solak", "Younggeol Cho", "Qiyi Tong", "Marta Lorenzini", "Arash Ajoudani"], "title": "Graph-based Online Monitoring of Train Driver States via Facial and Skeletal Features", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Driver fatigue poses a significant challenge to railway safety, with\ntraditional systems like the dead-man switch offering limited and basic\nalertness checks. This study presents an online behavior-based monitoring\nsystem utilizing a customised Directed-Graph Neural Network (DGNN) to classify\ntrain driver's states into three categories: alert, not alert, and\npathological. To optimize input representations for the model, an ablation\nstudy was performed, comparing three feature configurations: skeletal-only,\nfacial-only, and a combination of both. Experimental results show that\ncombining facial and skeletal features yields the highest accuracy (80.88%) in\nthe three-class model, outperforming models using only facial or skeletal\nfeatures. Furthermore, this combination achieves over 99% accuracy in the\nbinary alertness classification. Additionally, we introduced a novel dataset\nthat, for the first time, incorporates simulated pathological conditions into\ntrain driver monitoring, broadening the scope for assessing risks related to\nfatigue and health. This work represents a step forward in enhancing railway\nsafety through advanced online monitoring using vision-based technologies."}
{"id": "2505.09039", "pdf": "https://arxiv.org/pdf/2505.09039", "abs": "https://arxiv.org/abs/2505.09039", "authors": ["Jingfeng Chen", "Raghuveer Thirukovalluru", "Junlin Wang", "Kaiwei Luo", "Bhuwan Dhingra"], "title": "Atomic Consistency Preference Optimization for Long-Form Question Answering", "categories": ["cs.CL"], "comment": "16 pages, 2 figures", "summary": "Large Language Models (LLMs) frequently produce factoid hallucinations -\nplausible yet incorrect answers. A common mitigation strategy is model\nalignment, which improves factual accuracy by training on curated factual and\nnon-factual pairs. However, this approach often relies on a stronger model\n(e.g., GPT-4) or an external knowledge base to assess factual correctness,\nwhich may not always be accessible. To address this, we propose Atomic\nConsistency Preference Optimization (ACPO), a self-supervised preference-tuning\nmethod that enhances factual accuracy without external supervision. ACPO\nleverages atomic consistency signals, i.e., the agreement of individual facts\nacross multiple stochastic responses, to identify high- and low-quality data\npairs for model alignment. By eliminating the need for costly GPT calls, ACPO\nprovides a scalable and efficient approach to improving factoid\nquestion-answering. Despite being self-supervised, empirical results\ndemonstrate that ACPO outperforms FactAlign, a strong supervised alignment\nbaseline, by 1.95 points on the LongFact and BioGen datasets, highlighting its\neffectiveness in enhancing factual reliability without relying on external\nmodels or knowledge bases."}
{"id": "2505.08905", "pdf": "https://arxiv.org/pdf/2505.08905", "abs": "https://arxiv.org/abs/2505.08905", "authors": ["Michael Majurski", "Cynthia Matuszek"], "title": "Grounding Synthetic Data Evaluations of Language Models in Unsupervised Document Corpora", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Language Models (LMs) continue to advance, improving response quality and\ncoherence. Given Internet-scale training datasets, LMs have likely encountered\nmuch of what users might ask them to generate in some form during their\ntraining. A plethora of evaluation benchmarks have been constructed to assess\nmodel quality, response appropriateness, and reasoning capabilities. However,\nthe human effort required for benchmark construction is limited and being\nrapidly outpaced by the size and scope of the models under evaluation.\nAdditionally, having humans build a benchmark for every possible domain of\ninterest is impractical. Therefore, we propose a methodology for automating the\nconstruction of fact-based synthetic data model evaluations grounded in\ndocument populations. This work leverages those very same LMs to evaluate\ndomain-specific knowledge automatically, using only grounding documents (e.g.,\na textbook) as input. This synthetic data benchmarking approach corresponds\nwell with human curated questions with a Spearman ranking correlation of 0.96\nand a benchmark evaluation Pearson accuracy correlation of 0.79. This novel\ntool supports generating both multiple choice and open-ended synthetic data\nquestions to gain diagnostic insight of LM capability. We apply this\nmethodology to evaluate model performance on a recent relevant arXiv preprint,\ndiscovering a surprisingly strong performance from Gemma3 models."}
{"id": "2505.08793", "pdf": "https://arxiv.org/pdf/2505.08793", "abs": "https://arxiv.org/abs/2505.08793", "authors": ["Monirul Islam Pavel", "Siyi Hu", "Mahardhika Pratama", "Ryszard Kowalczyk"], "title": "Onboard Optimization and Learning: A Survey", "categories": ["cs.LG", "cs.AR"], "comment": "36 pages, 5 figures, 3 tables", "summary": "Onboard learning is a transformative approach in edge AI, enabling real-time\ndata processing, decision-making, and adaptive model training directly on\nresource-constrained devices without relying on centralized servers. This\nparadigm is crucial for applications demanding low latency, enhanced privacy,\nand energy efficiency. However, onboard learning faces challenges such as\nlimited computational resources, high inference costs, and security\nvulnerabilities. This survey explores a comprehensive range of methodologies\nthat address these challenges, focusing on techniques that optimize model\nefficiency, accelerate inference, and support collaborative learning across\ndistributed devices. Approaches for reducing model complexity, improving\ninference speed, and ensuring privacy-preserving computation are examined\nalongside emerging strategies that enhance scalability and adaptability in\ndynamic environments. By bridging advancements in hardware-software co-design,\nmodel compression, and decentralized learning, this survey provides insights\ninto the current state of onboard learning to enable robust, efficient, and\nsecure AI deployment at the edge."}
{"id": "2505.08801", "pdf": "https://arxiv.org/pdf/2505.08801", "abs": "https://arxiv.org/abs/2505.08801", "authors": ["Md. Sakib Hassan Chowdhury", "Md. Hafiz Ahamed", "Bishowjit Paul", "Sarafat Hussain Abhi", "Abu Bakar Siddique", "Md. Robius Sany"], "title": "OptiGait-LGBM: An Efficient Approach of Gait-based Person Re-identification in Non-Overlapping Regions", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": "12 pages, 17 figures", "summary": "Gait recognition, known for its ability to identify individuals from a\ndistance, has gained significant attention in recent times due to its\nnon-intrusive verification. While video-based gait identification systems\nperform well on large public datasets, their performance drops when applied to\nreal-world, unconstrained gait data due to various factors. Among these,\nuncontrolled outdoor environments, non-overlapping camera views, varying\nillumination, and computational efficiency are core challenges in gait-based\nauthentication. Currently, no dataset addresses all these challenges\nsimultaneously. In this paper, we propose an OptiGait-LGBM model capable of\nrecognizing person re-identification under these constraints using a skeletal\nmodel approach, which helps mitigate inconsistencies in a person's appearance.\nThe model constructs a dataset from landmark positions, minimizing memory usage\nby using non-sequential data. A benchmark dataset, RUET-GAIT, is introduced to\nrepresent uncontrolled gait sequences in complex outdoor environments. The\nprocess involves extracting skeletal joint landmarks, generating numerical\ndatasets, and developing an OptiGait-LGBM gait classification model. Our aim is\nto address the aforementioned challenges with minimal computational cost\ncompared to existing methods. A comparative analysis with ensemble techniques\nsuch as Random Forest and CatBoost demonstrates that the proposed approach\noutperforms them in terms of accuracy, memory usage, and training time. This\nmethod provides a novel, low-cost, and memory-efficient video-based gait\nrecognition solution for real-world scenarios."}
{"id": "2505.09056", "pdf": "https://arxiv.org/pdf/2505.09056", "abs": "https://arxiv.org/abs/2505.09056", "authors": ["Brandon Smith", "Mohamed Reda Bouadjenek", "Tahsin Alamgir Kheya", "Phillip Dawson", "Sunil Aryal"], "title": "A Comprehensive Analysis of Large Language Model Outputs: Similarity, Diversity, and Bias", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) represent a major step toward artificial general\nintelligence, significantly advancing our ability to interact with technology.\nWhile LLMs perform well on Natural Language Processing tasks -- such as\ntranslation, generation, code writing, and summarization -- questions remain\nabout their output similarity, variability, and ethical implications. For\ninstance, how similar are texts generated by the same model? How does this\ncompare across different models? And which models best uphold ethical\nstandards? To investigate, we used 5{,}000 prompts spanning diverse tasks like\ngeneration, explanation, and rewriting. This resulted in approximately 3\nmillion texts from 12 LLMs, including proprietary and open-source systems from\nOpenAI, Google, Microsoft, Meta, and Mistral. Key findings include: (1) outputs\nfrom the same LLM are more similar to each other than to human-written texts;\n(2) models like WizardLM-2-8x22b generate highly similar outputs, while GPT-4\nproduces more varied responses; (3) LLM writing styles differ significantly,\nwith Llama 3 and Mistral showing higher similarity, and GPT-4 standing out for\ndistinctiveness; (4) differences in vocabulary and tone underscore the\nlinguistic uniqueness of LLM-generated content; (5) some LLMs demonstrate\ngreater gender balance and reduced bias. These results offer new insights into\nthe behavior and diversity of LLM outputs, helping guide future development and\nethical evaluation."}
{"id": "2505.08988", "pdf": "https://arxiv.org/pdf/2505.08988", "abs": "https://arxiv.org/abs/2505.08988", "authors": ["Montaser Mohammedalamen", "Michael Bowling"], "title": "Generalization in Monitored Markov Decision Processes (Mon-MDPs)", "categories": ["cs.AI"], "comment": "Under Review", "summary": "Reinforcement learning (RL) typically models the interaction between the\nagent and environment as a Markov decision process (MDP), where the rewards\nthat guide the agent's behavior are always observable. However, in many\nreal-world scenarios, rewards are not always observable, which can be modeled\nas a monitored Markov decision process (Mon-MDP). Prior work on Mon-MDPs have\nbeen limited to simple, tabular cases, restricting their applicability to\nreal-world problems. This work explores Mon-MDPs using function approximation\n(FA) and investigates the challenges involved. We show that combining function\napproximation with a learned reward model enables agents to generalize from\nmonitored states with observable rewards, to unmonitored environment states\nwith unobservable rewards. Therefore, we demonstrate that such generalization\nwith a reward model achieves near-optimal policies in environments formally\ndefined as unsolvable. However, we identify a critical limitation of such\nfunction approximation, where agents incorrectly extrapolate rewards due to\novergeneralization, resulting in undesirable behaviors. To mitigate\novergeneralization, we propose a cautious police optimization method leveraging\nreward uncertainty. This work serves as a step towards bridging this gap\nbetween Mon-MDP theory and real-world applications."}
{"id": "2505.08795", "pdf": "https://arxiv.org/pdf/2505.08795", "abs": "https://arxiv.org/abs/2505.08795", "authors": ["Andres Anabalon", "Hugo Garces", "Julio Oliva", "Jose Cifuentes"], "title": "The Geometry of Meaning: Perfect Spacetime Representations of Hierarchical Structures", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "7 pages, 3 figures", "summary": "We show that there is a fast algorithm that embeds hierarchical structures in\nthree-dimensional Minkowski spacetime. The correlation of data ends up purely\nencoded in the causal structure. Our model relies solely on oriented token\npairs -- local hierarchical signals -- with no access to global symbolic\nstructure. We apply our method to the corpus of \\textit{WordNet}. We provide a\nperfect embedding of the mammal sub-tree including ambiguities (more than one\nhierarchy per node) in such a way that the hierarchical structures get\ncompletely codified in the geometry and exactly reproduce the ground-truth. We\nextend this to a perfect embedding of the maximal unambiguous subset of the\n\\textit{WordNet} with 82{,}115 noun tokens and a single hierarchy per token. We\nintroduce a novel retrieval mechanism in which causality, not distance, governs\nhierarchical access. Our results seem to indicate that all discrete data has a\nperfect geometrical representation that is three-dimensional. The resulting\nembeddings are nearly conformally invariant, indicating deep connections with\ngeneral relativity and field theory. These results suggest that concepts,\ncategories, and their interrelations, namely hierarchical meaning itself, is\ngeometric."}
{"id": "2505.08808", "pdf": "https://arxiv.org/pdf/2505.08808", "abs": "https://arxiv.org/abs/2505.08808", "authors": ["Anqing Jiang", "Jinhao Chai", "Yu Gao", "Yiru Wang", "Yuwen Heng", "Zhigang Sun", "Hao Sun", "Zezhong Zhao", "Li Sun", "Jian Zhou", "Lijuan Zhu", "Shugong Xu", "Hao Zhao"], "title": "SparseMeXT Unlocking the Potential of Sparse Representations for HD Map Construction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advancements in high-definition \\emph{HD} map construction have\ndemonstrated the effectiveness of dense representations, which heavily rely on\ncomputationally intensive bird's-eye view \\emph{BEV} features. While sparse\nrepresentations offer a more efficient alternative by avoiding dense BEV\nprocessing, existing methods often lag behind due to the lack of tailored\ndesigns. These limitations have hindered the competitiveness of sparse\nrepresentations in online HD map construction. In this work, we systematically\nrevisit and enhance sparse representation techniques, identifying key\narchitectural and algorithmic improvements that bridge the gap with--and\nultimately surpass--dense approaches. We introduce a dedicated network\narchitecture optimized for sparse map feature extraction, a sparse-dense\nsegmentation auxiliary task to better leverage geometric and semantic cues, and\na denoising module guided by physical priors to refine predictions. Through\nthese enhancements, our method achieves state-of-the-art performance on the\nnuScenes dataset, significantly advancing HD map construction and centerline\ndetection. Specifically, SparseMeXt-Tiny reaches a mean average precision\n\\emph{mAP} of 55.5% at 32 frames per second \\emph{fps}, while SparseMeXt-Base\nattains 65.2% mAP. Scaling the backbone and decoder further, SparseMeXt-Large\nachieves an mAP of 68.9% at over 20 fps, establishing a new benchmark for\nsparse representations in HD map construction. These results underscore the\nuntapped potential of sparse methods, challenging the conventional reliance on\ndense representations and redefining efficiency-performance trade-offs in the\nfield."}
{"id": "2505.09068", "pdf": "https://arxiv.org/pdf/2505.09068", "abs": "https://arxiv.org/abs/2505.09068", "authors": ["Jennifer Haase", "Paul H. P. Hanel", "Sebastian Pokutta"], "title": "S-DAT: A Multilingual, GenAI-Driven Framework for Automated Divergent Thinking Assessment", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "This paper introduces S-DAT (Synthetic-Divergent Association Task), a\nscalable, multilingual framework for automated assessment of divergent thinking\n(DT) -a core component of human creativity. Traditional creativity assessments\nare often labor-intensive, language-specific, and reliant on subjective human\nratings, limiting their scalability and cross-cultural applicability. In\ncontrast, S-DAT leverages large language models and advanced multilingual\nembeddings to compute semantic distance -- a language-agnostic proxy for DT. We\nevaluate S-DAT across eleven diverse languages, including English, Spanish,\nGerman, Russian, Hindi, and Japanese (Kanji, Hiragana, Katakana), demonstrating\nrobust and consistent scoring across linguistic contexts. Unlike prior DAT\napproaches, the S-DAT shows convergent validity with other DT measures and\ncorrect discriminant validity with convergent thinking. This cross-linguistic\nflexibility allows for more inclusive, global-scale creativity research,\naddressing key limitations of earlier approaches. S-DAT provides a powerful\ntool for fairer, more comprehensive evaluation of cognitive flexibility in\ndiverse populations and can be freely assessed online:\nhttps://sdat.iol.zib.de/."}
{"id": "2505.08995", "pdf": "https://arxiv.org/pdf/2505.08995", "abs": "https://arxiv.org/abs/2505.08995", "authors": ["Ardian Selmonaj", "Oleg Szehr", "Giacomo Del Rio", "Alessandro Antonucci", "Adrian Schneider", "Michael Rüegsegger"], "title": "Enhancing Aerial Combat Tactics through Hierarchical Multi-Agent Reinforcement Learning", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.RO"], "comment": "Published as journal chapter in Deep Learning Applications, Vol. 1,\n  by Taylor & Francis", "summary": "This work presents a Hierarchical Multi-Agent Reinforcement Learning\nframework for analyzing simulated air combat scenarios involving heterogeneous\nagents. The objective is to identify effective Courses of Action that lead to\nmission success within preset simulations, thereby enabling the exploration of\nreal-world defense scenarios at low cost and in a safe-to-fail setting.\nApplying deep Reinforcement Learning in this context poses specific challenges,\nsuch as complex flight dynamics, the exponential size of the state and action\nspaces in multi-agent systems, and the capability to integrate real-time\ncontrol of individual units with look-ahead planning. To address these\nchallenges, the decision-making process is split into two levels of\nabstraction: low-level policies control individual units, while a high-level\ncommander policy issues macro commands aligned with the overall mission\ntargets. This hierarchical structure facilitates the training process by\nexploiting policy symmetries of individual agents and by separating control\nfrom command tasks. The low-level policies are trained for individual combat\ncontrol in a curriculum of increasing complexity. The high-level commander is\nthen trained on mission targets given pre-trained control policies. The\nempirical validation confirms the advantages of the proposed framework."}
{"id": "2505.08803", "pdf": "https://arxiv.org/pdf/2505.08803", "abs": "https://arxiv.org/abs/2505.08803", "authors": ["Zizhao Hu", "Mohammad Rostami", "Jesse Thomason"], "title": "Multi-modal Synthetic Data Training and Model Collapse: Insights from VLMs and Diffusion Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent research has highlighted the risk of generative model collapse, where\nperformance progressively degrades when continually trained on self-generated\ndata. However, existing exploration on model collapse is limited to single,\nunimodal models, limiting our understanding in more realistic scenarios, such\nas diverse multi-modal AI agents interacting autonomously through synthetic\ndata and continually evolving. We expand the synthetic data training and model\ncollapse study to multi-modal vision-language generative systems, such as\nvision-language models (VLMs) and text-to-image diffusion models, as well as\nrecursive generate-train loops with multiple models. We find that model\ncollapse, previously observed in single-modality generative models, exhibits\ndistinct characteristics in the multi-modal context, such as improved\nvision-language alignment and increased variance in VLM image-captioning task.\nAdditionally, we find that general approaches such as increased decoding\nbudgets, greater model diversity, and relabeling with frozen models can\neffectively mitigate model collapse. Our findings provide initial insights and\npractical guidelines for reducing the risk of model collapse in self-improving\nmulti-agent AI systems and curating robust multi-modal synthetic datasets."}
{"id": "2505.08811", "pdf": "https://arxiv.org/pdf/2505.08811", "abs": "https://arxiv.org/abs/2505.08811", "authors": ["Shijie Lian", "Ziyi Zhang", "Laurence Tianruo Yang and", "Mengyu Ren", "Debin Liu", "Hua Li"], "title": "TUGS: Physics-based Compact Representation of Underwater Scenes by Tensorized Gaussian", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Underwater 3D scene reconstruction is crucial for undewater robotic\nperception and navigation. However, the task is significantly challenged by the\ncomplex interplay between light propagation, water medium, and object surfaces,\nwith existing methods unable to model their interactions accurately.\nAdditionally, expensive training and rendering costs limit their practical\napplication in underwater robotic systems. Therefore, we propose Tensorized\nUnderwater Gaussian Splatting (TUGS), which can effectively solve the modeling\nchallenges of the complex interactions between object geometries and water\nmedia while achieving significant parameter reduction. TUGS employs lightweight\ntensorized higher-order Gaussians with a physics-based underwater Adaptive\nMedium Estimation (AME) module, enabling accurate simulation of both light\nattenuation and backscatter effects in underwater environments. Compared to\nother NeRF-based and GS-based methods designed for underwater, TUGS is able to\nrender high-quality underwater images with faster rendering speeds and less\nmemory usage. Extensive experiments on real-world underwater datasets have\ndemonstrated that TUGS can efficiently achieve superior reconstruction quality\nusing a limited number of parameters, making it particularly suitable for\nmemory-constrained underwater UAV applications"}
{"id": "2505.09082", "pdf": "https://arxiv.org/pdf/2505.09082", "abs": "https://arxiv.org/abs/2505.09082", "authors": ["Sophie Zhang", "Zhiming Lin"], "title": "CEC-Zero: Chinese Error Correction Solution Based on LLM", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) demonstrate exceptional\nChinese text processing capabilities, particularly in Chinese Spelling\nCorrection (CSC). While LLMs outperform traditional BERT-based models in\naccuracy and robustness, challenges persist in reliability and generalization.\nThis paper proposes CEC-Zero, a novel reinforcement learning (RL) framework\nenabling LLMs to self-correct through autonomous error strategy learning\nwithout external supervision. By integrating RL with LLMs' generative power,\nthe method eliminates dependency on annotated data or auxiliary models.\nExperiments reveal RL-enhanced LLMs achieve industry-viable accuracy and\nsuperior cross-domain generalization, offering a scalable solution for\nreliability optimization in Chinese NLP applications. This breakthrough\nfacilitates LLM deployment in practical Chinese text correction scenarios while\nestablishing a new paradigm for self-improving language models."}
{"id": "2505.09012", "pdf": "https://arxiv.org/pdf/2505.09012", "abs": "https://arxiv.org/abs/2505.09012", "authors": ["Bo Meng", "Chenghao Xu", "Yongli Zhu"], "title": "Deep Reinforcement Learning for Power Grid Multi-Stage Cascading Failure Mitigation", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore,\n  Apr. 28, 2025", "summary": "Cascading failures in power grids can lead to grid collapse, causing severe\ndisruptions to social operations and economic activities. In certain cases,\nmulti-stage cascading failures can occur. However, existing\ncascading-failure-mitigation strategies are usually single-stage-based,\noverlooking the complexity of the multi-stage scenario. This paper treats the\nmulti-stage cascading failure problem as a reinforcement learning task and\ndevelops a simulation environment. The reinforcement learning agent is then\ntrained via the deterministic policy gradient algorithm to achieve continuous\nactions. Finally, the effectiveness of the proposed approach is validated on\nthe IEEE 14-bus and IEEE 118-bus systems."}
{"id": "2505.08823", "pdf": "https://arxiv.org/pdf/2505.08823", "abs": "https://arxiv.org/abs/2505.08823", "authors": ["Cody Steinmetz", "Gavin Childress", "Aaron Herbst", "Gavin Jones", "Jasdeep Singh", "Eli Vang", "Keagan Weinstock"], "title": "An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have transformed natural-language processing,\nyet their scale makes real-world deployment costly. Post-training quantization\nreduces memory and computation but often degrades accuracy, while\nquantization-aware training can recover performance at the cost of extra\ntraining. Pushing quantization to the ternary (2-bit) regime yields even larger\nsavings but is notoriously unstable. Building on recent work showing that a\nbias-free, RMS-normalized Transformer with straight-through estimation can\nreach 1.58-bit precision, we demonstrate that simply inserting RMS\nnormalization before every linear projection and applying a gradual, layer-wise\nquantization schedule stably fine-tunes full-precision checkpoints into ternary\nLLMs. Our approach matches or surpasses more elaborate knowledge-distillation\npipelines on standard language-modeling benchmarks without adding model\ncomplexity. These results indicate that careful normalization alone can close\nmuch of the accuracy gap between ternary and full-precision LLMs, making\nultra-low-bit inference practical."}
{"id": "2505.08814", "pdf": "https://arxiv.org/pdf/2505.08814", "abs": "https://arxiv.org/abs/2505.08814", "authors": ["Wenkai Li", "Xiaoqi Li", "Yingjie Mao", "Yishun Wang"], "title": "Towards Understanding Deep Learning Model in Image Recognition via Coverage Test", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep neural networks (DNNs) play a crucial role in the field of artificial\nintelligence, and their security-related testing has been a prominent research\nfocus. By inputting test cases, the behavior of models is examined for\nanomalies, and coverage metrics are utilized to determine the extent of neurons\ncovered by these test cases. With the widespread application and advancement of\nDNNs, different types of neural behaviors have garnered attention, leading to\nthe emergence of various coverage metrics for neural networks. However, there\nis currently a lack of empirical research on these coverage metrics,\nspecifically in analyzing the relationships and patterns between model depth,\nconfiguration information, and neural network coverage. This paper aims to\ninvestigate the relationships and patterns of four coverage metrics: primary\nfunctionality, boundary, hierarchy, and structural coverage. A series of\nempirical experiments were conducted, selecting LeNet, VGG, and ResNet as\ndifferent DNN architectures, along with 10 models of varying depths ranging\nfrom 5 to 54 layers, to compare and study the relationships between different\ndepths, configuration information, and various neural network coverage metrics.\nAdditionally, an investigation was carried out on the relationships between\nmodified decision/condition coverage and dataset size. Finally, three potential\nfuture directions are proposed to further contribute to the security testing of\nDNN Models."}
{"id": "2505.09269", "pdf": "https://arxiv.org/pdf/2505.09269", "abs": "https://arxiv.org/abs/2505.09269", "authors": ["Ulrich Frank", "Pierre Maier"], "title": "How an unintended Side Effect of a Research Project led to Boosting the Power of UML", "categories": ["cs.CL"], "comment": null, "summary": "This paper describes the design, implementation and use of a new UML modeling\ntool that represents a significant advance over conventional tools. Among other\nthings, it allows the integration of class diagrams and object diagrams as well\nas the execution of objects. This not only enables new software architectures\ncharacterized by the integration of software with corresponding object models,\nbut is also ideal for use in teaching, as it provides students with a\nparticularly stimulating learning experience. A special feature of the project\nis that it has emerged from a long-standing international research project,\nwhich is aimed at a comprehensive multi-level architecture. The project is\ntherefore an example of how research can lead to valuable results that arise as\na side effect of other work."}
{"id": "2505.09024", "pdf": "https://arxiv.org/pdf/2505.09024", "abs": "https://arxiv.org/abs/2505.09024", "authors": ["Aaron Baughman", "Rahul Agarwal", "Eduardo Morales", "Gozde Akay"], "title": "Automated Meta Prompt Engineering for Alignment with the Theory of Mind", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "9 pages, 6 figures, 3 tables", "summary": "We introduce a method of meta-prompting that jointly produces fluent text for\ncomplex tasks while optimizing the similarity of neural states between a\nhuman's mental expectation and a Large Language Model's (LLM) neural\nprocessing. A technique of agentic reinforcement learning is applied, in which\nan LLM as a Judge (LLMaaJ) teaches another LLM, through in-context learning,\nhow to produce content by interpreting the intended and unintended generated\ntext traits. To measure human mental beliefs around content production, users\nmodify long form AI-generated text articles before publication at the US Open\n2024 tennis Grand Slam. Now, an LLMaaJ can solve the Theory of Mind (ToM)\nalignment problem by anticipating and including human edits within the creation\nof text from an LLM. Throughout experimentation and by interpreting the results\nof a live production system, the expectations of human content reviewers had\n100% of alignment with AI 53.8% of the time with an average iteration count of\n4.38. The geometric interpretation of content traits such as factualness,\nnovelty, repetitiveness, and relevancy over a Hilbert vector space combines\nspatial volume (all trait importance) with vertices alignment (individual trait\nrelevance) enabled the LLMaaJ to optimize on Human ToM. This resulted in an\nincrease in content quality by extending the coverage of tennis action. Our\nwork that was deployed at the US Open 2024 has been used across other live\nevents within sports and entertainment."}
{"id": "2505.08827", "pdf": "https://arxiv.org/pdf/2505.08827", "abs": "https://arxiv.org/abs/2505.08827", "authors": ["Toby Simonds", "Kevin Lopez", "Akira Yoshiyama", "Dominique Garmier"], "title": "Self Rewarding Self Improving", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We demonstrate that large language models can effectively self-improve\nthrough self-judging without requiring reference solutions, leveraging the\ninherent asymmetry between generating and verifying solutions. Our experiments\non Countdown puzzles and MIT Integration Bee problems show that models can\nprovide reliable reward signals without ground truth answers, enabling\nreinforcement learning in domains previously not possible. By implementing\nself-judging, we achieve significant performance gains maintaining alignment\nwith formal verification. When combined with synthetic question generation, we\nestablish a complete self-improvement loop where models generate practice\nproblems, solve them, and evaluate their own performance-achieving an 8%\nimprovement with Qwen 2.5 7B over baseline and surpassing GPT-4o performance on\nintegration tasks. Our findings demonstrate that LLM judges can provide\neffective reward signals for training models, unlocking many reinforcement\nlearning environments previously limited by the difficulty of creating\nprogrammatic rewards. This suggests a potential paradigm shift toward AI\nsystems that continuously improve through self-directed learning rather than\nhuman-guided training, potentially accelerating progress in domains with scarce\ntraining data or complex evaluation requirements."}
{"id": "2505.08817", "pdf": "https://arxiv.org/pdf/2505.08817", "abs": "https://arxiv.org/abs/2505.08817", "authors": ["Camilo Carvajal Reyes", "Joaquín Fontbona", "Felipe Tobar"], "title": "Towards SFW sampling for diffusion models via external conditioning", "categories": ["cs.CV", "cs.LG"], "comment": "Accepcted at IJCNN 2025", "summary": "Score-based generative models (SBM), also known as diffusion models, are the\nde facto state of the art for image synthesis. Despite their unparalleled\nperformance, SBMs have recently been in the spotlight for being tricked into\ncreating not-safe-for-work (NSFW) content, such as violent images and\nnon-consensual nudity. Current approaches that prevent unsafe generation are\nbased on the models' own knowledge, and the majority of them require\nfine-tuning. This article explores the use of external sources for ensuring\nsafe outputs in SBMs. Our safe-for-work (SFW) sampler implements a Conditional\nTrajectory Correction step that guides the samples away from undesired regions\nin the ambient space using multimodal models as the source of conditioning.\nFurthermore, using Contrastive Language Image Pre-training (CLIP), our method\nadmits user-defined NSFW classes, which can vary in different settings. Our\nexperiments on the text-to-image SBM Stable Diffusion validate that the\nproposed SFW sampler effectively reduces the generation of explicit content\nwhile being competitive with other fine-tuning-based approaches, as assessed\nvia independent NSFW detectors. Moreover, we evaluate the impact of the SFW\nsampler on image quality and show that the proposed correction scheme comes at\na minor cost with negligible effect on samples not needing correction. Our\nstudy confirms the suitability of the SFW sampler towards aligned SBM models\nand the potential of using model-agnostic conditioning for the prevention of\nunwanted images."}
{"id": "2505.09286", "pdf": "https://arxiv.org/pdf/2505.09286", "abs": "https://arxiv.org/abs/2505.09286", "authors": ["Jiin Park", "Misuk Kim"], "title": "A Scalable Unsupervised Framework for multi-aspect labeling of Multilingual and Multi-Domain Review Data", "categories": ["cs.CL"], "comment": "36 pages, 3 figures", "summary": "Effectively analyzing online review data is essential across industries.\nHowever, many existing studies are limited to specific domains and languages or\ndepend on supervised learning approaches that require large-scale labeled\ndatasets. To address these limitations, we propose a multilingual, scalable,\nand unsupervised framework for cross-domain aspect detection. This framework is\ndesigned for multi-aspect labeling of multilingual and multi-domain review\ndata. In this study, we apply automatic labeling to Korean and English review\ndatasets spanning various domains and assess the quality of the generated\nlabels through extensive experiments. Aspect category candidates are first\nextracted through clustering, and each review is then represented as an\naspect-aware embedding vector using negative sampling. To evaluate the\nframework, we conduct multi-aspect labeling and fine-tune several pretrained\nlanguage models to measure the effectiveness of the automatically generated\nlabels. Results show that these models achieve high performance, demonstrating\nthat the labels are suitable for training. Furthermore, comparisons with\npublicly available large language models highlight the framework's superior\nconsistency and scalability when processing large-scale data. A human\nevaluation also confirms that the quality of the automatic labels is comparable\nto those created manually. This study demonstrates the potential of a robust\nmulti-aspect labeling approach that overcomes limitations of supervised methods\nand is adaptable to multilingual, multi-domain environments. Future research\nwill explore automatic review summarization and the integration of artificial\nintelligence agents to further improve the efficiency and depth of review\nanalysis."}
{"id": "2505.09029", "pdf": "https://arxiv.org/pdf/2505.09029", "abs": "https://arxiv.org/abs/2505.09029", "authors": ["Hazim Alzorgan", "Abolfazl Razi"], "title": "Monte Carlo Beam Search for Actor-Critic Reinforcement Learning in Continuous Control", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Actor-critic methods, like Twin Delayed Deep Deterministic Policy Gradient\n(TD3), depend on basic noise-based exploration, which can result in less than\noptimal policy convergence. In this study, we introduce Monte Carlo Beam Search\n(MCBS), a new hybrid method that combines beam search and Monte Carlo rollouts\nwith TD3 to improve exploration and action selection. MCBS produces several\ncandidate actions around the policy's output and assesses them through\nshort-horizon rollouts, enabling the agent to make better-informed choices. We\ntest MCBS across various continuous-control benchmarks, including\nHalfCheetah-v4, Walker2d-v5, and Swimmer-v5, showing enhanced sample efficiency\nand performance compared to standard TD3 and other baseline methods like SAC,\nPPO, and A2C. Our findings emphasize MCBS's capability to enhance policy\nlearning through structured look-ahead search while ensuring computational\nefficiency. Additionally, we offer a detailed analysis of crucial\nhyperparameters, such as beam width and rollout depth, and explore adaptive\nstrategies to optimize MCBS for complex control tasks. Our method shows a\nhigher convergence rate across different environments compared to TD3, SAC,\nPPO, and A2C. For instance, we achieved 90% of the maximum achievable reward\nwithin around 200 thousand timesteps compared to 400 thousand timesteps for the\nsecond-best method."}
{"id": "2505.08829", "pdf": "https://arxiv.org/pdf/2505.08829", "abs": "https://arxiv.org/abs/2505.08829", "authors": ["David Kinney"], "title": "Aggregating Concepts of Fairness and Accuracy in Predictive Systems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "An algorithm that outputs predictions about the state of the world will\nalmost always be designed with the implicit or explicit goal of outputting\naccurate predictions (i.e., predictions that are likely to be true). In\naddition, the rise of increasingly powerful predictive algorithms brought about\nby the recent revolution in artificial intelligence has led to an emphasis on\nbuilding predictive algorithms that are fair, in the sense that their\npredictions do not systematically evince bias or bring about harm to certain\nindividuals or groups. This state of affairs presents two conceptual\nchallenges. First, the goals of accuracy and fairness can sometimes be in\ntension, and there are no obvious normative guidelines for managing the\ntrade-offs between these two desiderata when they arise. Second, there are many\ndistinct ways of measuring both the accuracy and fairness of a predictive\nalgorithm; here too, there are no obvious guidelines on how to aggregate our\npreferences for predictive algorithms that satisfy disparate measures of\nfairness and accuracy to various extents. The goal of this paper is to address\nthese challenges by arguing that there are good reasons for using a linear\ncombination of accuracy and fairness metrics to measure the\nall-things-considered value of a predictive algorithm for agents who care about\nboth accuracy and fairness. My argument depends crucially on a classic result\nin the preference aggregation literature due to Harsanyi. After making this\nformal argument, I apply my result to an analysis of accuracy-fairness\ntrade-offs using the COMPAS dataset compiled by Angwin et al."}
{"id": "2505.08833", "pdf": "https://arxiv.org/pdf/2505.08833", "abs": "https://arxiv.org/abs/2505.08833", "authors": ["Qingyi Wang", "Yuebing Liang", "Yunhan Zheng", "Kaiyuan Xu", "Jinhua Zhao", "Shenhao Wang"], "title": "Generative AI for Urban Planning: Synthesizing Satellite Imagery via Diffusion Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Generative AI offers new opportunities for automating urban planning by\ncreating site-specific urban layouts and enabling flexible design exploration.\nHowever, existing approaches often struggle to produce realistic and practical\ndesigns at scale. Therefore, we adapt a state-of-the-art Stable Diffusion\nmodel, extended with ControlNet, to generate high-fidelity satellite imagery\nconditioned on land use descriptions, infrastructure, and natural environments.\nTo overcome data availability limitations, we spatially link satellite imagery\nwith structured land use and constraint information from OpenStreetMap. Using\ndata from three major U.S. cities, we demonstrate that the proposed diffusion\nmodel generates realistic and diverse urban landscapes by varying land-use\nconfigurations, road networks, and water bodies, facilitating cross-city\nlearning and design diversity. We also systematically evaluate the impacts of\nvarying language prompts and control imagery on the quality of satellite\nimagery generation. Our model achieves high FID and KID scores and demonstrates\nrobustness across diverse urban contexts. Qualitative assessments from urban\nplanners and the general public show that generated images align closely with\ndesign descriptions and constraints, and are often preferred over real images.\nThis work establishes a benchmark for controlled urban imagery generation and\nhighlights the potential of generative AI as a tool for enhancing planning\nworkflows and public engagement."}
{"id": "2505.09316", "pdf": "https://arxiv.org/pdf/2505.09316", "abs": "https://arxiv.org/abs/2505.09316", "authors": ["Hongjin Qian", "Zheng Liu"], "title": "Scent of Knowledge: Optimizing Search-Enhanced Reasoning with Information Foraging", "categories": ["cs.CL", "cs.IR"], "comment": "16 pages", "summary": "Augmenting large language models (LLMs) with external retrieval has become a\nstandard method to address their inherent knowledge cutoff limitations.\nHowever, traditional retrieval-augmented generation methods employ static,\npre-inference retrieval strategies, making them inadequate for complex tasks\ninvolving ambiguous, multi-step, or evolving information needs. Recent advances\nin test-time scaling techniques have demonstrated significant potential in\nenabling LLMs to dynamically interact with external tools, motivating the shift\ntoward adaptive inference-time retrieval. Inspired by Information Foraging\nTheory (IFT), we propose InForage, a reinforcement learning framework that\nformalizes retrieval-augmented reasoning as a dynamic information-seeking\nprocess. Unlike existing approaches, InForage explicitly rewards intermediate\nretrieval quality, encouraging LLMs to iteratively gather and integrate\ninformation through adaptive search behaviors. To facilitate training, we\nconstruct a human-guided dataset capturing iterative search and reasoning\ntrajectories for complex, real-world web tasks. Extensive evaluations across\ngeneral question answering, multi-hop reasoning tasks, and a newly developed\nreal-time web QA dataset demonstrate InForage's superior performance over\nbaseline methods. These results highlight InForage's effectiveness in building\nrobust, adaptive, and efficient reasoning agents."}
{"id": "2505.09031", "pdf": "https://arxiv.org/pdf/2505.09031", "abs": "https://arxiv.org/abs/2505.09031", "authors": ["Adarsh Kumar", "Hwiyoon Kim", "Jawahar Sai Nathani", "Neil Roy"], "title": "Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Hallucination, where large language models (LLMs) generate confident but\nincorrect or irrelevant information, remains a key limitation in their\napplication to complex, open-ended tasks. Chain-of-thought (CoT) prompting has\nemerged as a promising method for improving multistep reasoning by guiding\nmodels through intermediate steps. However, CoT alone does not fully address\nthe hallucination problem. In this work, we investigate how combining CoT with\nretrieval-augmented generation (RAG), as well as applying self-consistency and\nself-verification strategies, can reduce hallucinations and improve factual\naccuracy. By incorporating external knowledge sources during reasoning and\nenabling models to verify or revise their own outputs, we aim to generate more\naccurate and coherent responses. We present a comparative evaluation of\nbaseline LLMs against CoT, CoT+RAG, self-consistency, and self-verification\ntechniques. Our results highlight the effectiveness of each method and identify\nthe most robust approach for minimizing hallucinations while preserving fluency\nand reasoning depth."}
{"id": "2505.08846", "pdf": "https://arxiv.org/pdf/2505.08846", "abs": "https://arxiv.org/abs/2505.08846", "authors": ["Felix Marti-Perez", "Brigt Håvardstun", "Cèsar Ferri", "Carlos Monserrat", "Jan Arne Telle"], "title": "Evaluating Simplification Algorithms for Interpretability of Time Series Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this work, we introduce metrics to evaluate the use of simplified time\nseries in the context of interpretability of a TSC - a Time Series Classifier.\nSuch simplifications are important because time series data, in contrast to\ntext and image data, are not intuitively understandable to humans. These\nmetrics are related to the complexity of the simplifications - how many\nsegments they contain - and to their loyalty - how likely they are to maintain\nthe classification of the original time series. We employ these metrics to\nevaluate four distinct simplification algorithms, across several TSC algorithms\nand across datasets of varying characteristics, from seasonal or stationary to\nshort or long. Our findings suggest that using simplifications for\ninterpretability of TSC is much better than using the original time series,\nparticularly when the time series are seasonal, non-stationary and/or with low\nentropy."}
{"id": "2505.08834", "pdf": "https://arxiv.org/pdf/2505.08834", "abs": "https://arxiv.org/abs/2505.08834", "authors": ["Muhammad Junaid Asif"], "title": "Crowd Scene Analysis using Deep Learning Techniques", "categories": ["cs.CV", "cs.AI"], "comment": "MS Graduate Research Thesis", "summary": "Our research is focused on two main applications of crowd scene analysis\ncrowd counting and anomaly detection In recent years a large number of\nresearches have been presented in the domain of crowd counting We addressed two\nmain challenges in this domain 1 Deep learning models are datahungry paradigms\nand always need a large amount of annotated data for the training of algorithm\nIt is timeconsuming and costly task to annotate such large amount of data\nSelfsupervised training is proposed to deal with this challenge 2 MCNN consists\nof multicolumns of CNN with different sizes of filters by presenting a novel\napproach based on a combination of selfsupervised training and MultiColumn CNN\nThis enables the model to learn features at different levels and makes it\neffective in dealing with challenges of occluded scenes nonuniform density\ncomplex backgrounds and scale invariation The proposed model was evaluated on\npublicly available data sets such as ShanghaiTech and UCFQNRF by means of MAE\nand MSE A spatiotemporal model based on VGG19 is proposed for crowd anomaly\ndetection addressing challenges like lighting environmental conditions\nunexpected objects and scalability The model extracts spatial and temporal\nfeatures allowing it to be generalized to realworld scenes Spatial features are\nlearned using CNN while temporal features are learned using LSTM blocks The\nmodel works on binary classification and can detect normal or abnormal behavior\nThe models performance is improved by replacing fully connected layers with\ndense residual blocks Experiments on the Hockey Fight dataset and SCVD dataset\nshow our models outperform other stateoftheart approaches"}
{"id": "2505.09338", "pdf": "https://arxiv.org/pdf/2505.09338", "abs": "https://arxiv.org/abs/2505.09338", "authors": ["Jingcheng Niu", "Xingdi Yuan", "Tong Wang", "Hamidreza Saghir", "Amir H. Abdi"], "title": "Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "We observe a novel phenomenon, contextual entrainment, across a wide range of\nlanguage models (LMs) and prompt settings, providing a new mechanistic\nperspective on how LMs become distracted by ``irrelevant'' contextual\ninformation in the input prompt. Specifically, LMs assign significantly higher\nlogits (or probabilities) to any tokens that have previously appeared in the\ncontext prompt, even for random tokens. This suggests that contextual\nentrainment is a mechanistic phenomenon, occurring independently of the\nrelevance or semantic relation of the tokens to the question or the rest of the\nsentence. We find statistically significant evidence that the magnitude of\ncontextual entrainment is influenced by semantic factors. Counterfactual\nprompts have a greater effect compared to factual ones, suggesting that while\ncontextual entrainment is a mechanistic phenomenon, it is modulated by semantic\nfactors.\n  We hypothesise that there is a circuit of attention heads -- the entrainment\nheads -- that corresponds to the contextual entrainment phenomenon. Using a\nnovel entrainment head discovery method based on differentiable masking, we\nidentify these heads across various settings. When we ``turn off'' these heads,\ni.e., set their outputs to zero, the effect of contextual entrainment is\nsignificantly attenuated, causing the model to generate output that capitulates\nto what it would produce if no distracting context were provided. Our discovery\nof contextual entrainment, along with our investigation into LM distraction via\nthe entrainment heads, marks a key step towards the mechanistic analysis and\nmitigation of the distraction problem."}
{"id": "2505.09114", "pdf": "https://arxiv.org/pdf/2505.09114", "abs": "https://arxiv.org/abs/2505.09114", "authors": ["Minh Hoang Nguyen", "Linh Le Pham Van", "Thommen George Karimpanal", "Sunil Gupta", "Hung Le"], "title": "Beyond the Known: Decision Making with Counterfactual Reasoning Decision Transformer", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Decision Transformers (DT) play a crucial role in modern reinforcement\nlearning, leveraging offline datasets to achieve impressive results across\nvarious domains. However, DT requires high-quality, comprehensive data to\nperform optimally. In real-world applications, the lack of training data and\nthe scarcity of optimal behaviours make training on offline datasets\nchallenging, as suboptimal data can hinder performance. To address this, we\npropose the Counterfactual Reasoning Decision Transformer (CRDT), a novel\nframework inspired by counterfactual reasoning. CRDT enhances DT ability to\nreason beyond known data by generating and utilizing counterfactual\nexperiences, enabling improved decision-making in unseen scenarios. Experiments\nacross Atari and D4RL benchmarks, including scenarios with limited data and\naltered dynamics, demonstrate that CRDT outperforms conventional DT approaches.\nAdditionally, reasoning counterfactually allows the DT agent to obtain\nstitching abilities, combining suboptimal trajectories, without architectural\nmodifications. These results highlight the potential of counterfactual\nreasoning to enhance reinforcement learning agents' performance and\ngeneralization capabilities."}
{"id": "2505.08915", "pdf": "https://arxiv.org/pdf/2505.08915", "abs": "https://arxiv.org/abs/2505.08915", "authors": ["Jialin Mao", "Itay Griniasty", "Yan Sun", "Mark K. Transtrum", "James P. Sethna", "Pratik Chaudhari"], "title": "An Analytical Characterization of Sloppiness in Neural Networks: Insights from Linear Models", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech"], "comment": null, "summary": "Recent experiments have shown that training trajectories of multiple deep\nneural networks with different architectures, optimization algorithms,\nhyper-parameter settings, and regularization methods evolve on a remarkably\nlow-dimensional \"hyper-ribbon-like\" manifold in the space of probability\ndistributions. Inspired by the similarities in the training trajectories of\ndeep networks and linear networks, we analytically characterize this phenomenon\nfor the latter. We show, using tools in dynamical systems theory, that the\ngeometry of this low-dimensional manifold is controlled by (i) the decay rate\nof the eigenvalues of the input correlation matrix of the training data, (ii)\nthe relative scale of the ground-truth output to the weights at the beginning\nof training, and (iii) the number of steps of gradient descent. By analytically\ncomputing and bounding the contributions of these quantities, we characterize\nphase boundaries of the region where hyper-ribbons are to be expected. We also\nextend our analysis to kernel machines and linear models that are trained with\nstochastic gradient descent."}
{"id": "2505.08854", "pdf": "https://arxiv.org/pdf/2505.08854", "abs": "https://arxiv.org/abs/2505.08854", "authors": ["Yuping Wang", "Shuo Xing", "Cui Can", "Renjie Li", "Hongyuan Hua", "Kexin Tian", "Zhaobin Mo", "Xiangbo Gao", "Keshu Wu", "Sulong Zhou", "Hengxu You", "Juntong Peng", "Junge Zhang", "Zehao Wang", "Rui Song", "Mingxuan Yan", "Walter Zimmer", "Xingcheng Zhou", "Peiran Li", "Zhaohan Lu", "Chia-Ju Chen", "Yue Huang", "Ryan A. Rossi", "Lichao Sun", "Hongkai Yu", "Zhiwen Fan", "Frank Hao Yang", "Yuhao Kang", "Ross Greer", "Chenxi Liu", "Eun Hak Lee", "Xuan Di", "Xinyue Ye", "Liu Ren", "Alois Knoll", "Xiaopeng Li", "Shuiwang Ji", "Masayoshi Tomizuka", "Marco Pavone", "Tianbao Yang", "Jing Du", "Ming-Hsuan Yang", "Hua Wei", "Ziran Wang", "Yang Zhou", "Jiachen Li", "Zhengzhong Tu"], "title": "Generative AI for Autonomous Driving: Frontiers and Opportunities", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Generative Artificial Intelligence (GenAI) constitutes a transformative\ntechnological wave that reconfigures industries through its unparalleled\ncapabilities for content creation, reasoning, planning, and multimodal\nunderstanding. This revolutionary force offers the most promising path yet\ntoward solving one of engineering's grandest challenges: achieving reliable,\nfully autonomous driving, particularly the pursuit of Level 5 autonomy. This\nsurvey delivers a comprehensive and critical synthesis of the emerging role of\nGenAI across the autonomous driving stack. We begin by distilling the\nprinciples and trade-offs of modern generative modeling, encompassing VAEs,\nGANs, Diffusion Models, and Large Language Models (LLMs). We then map their\nfrontier applications in image, LiDAR, trajectory, occupancy, video generation\nas well as LLM-guided reasoning and decision making. We categorize practical\napplications, such as synthetic data workflows, end-to-end driving strategies,\nhigh-fidelity digital twin systems, smart transportation networks, and\ncross-domain transfer to embodied AI. We identify key obstacles and\npossibilities such as comprehensive generalization across rare cases,\nevaluation and safety checks, budget-limited implementation, regulatory\ncompliance, ethical concerns, and environmental effects, while proposing\nresearch plans across theoretical assurances, trust metrics, transport\nintegration, and socio-technical influence. By unifying these threads, the\nsurvey provides a forward-looking reference for researchers, engineers, and\npolicymakers navigating the convergence of generative AI and advanced\nautonomous mobility. An actively maintained repository of cited works is\navailable at https://github.com/taco-group/GenAI4AD."}
{"id": "2505.09388", "pdf": "https://arxiv.org/pdf/2505.09388", "abs": "https://arxiv.org/abs/2505.09388", "authors": ["An Yang", "Anfeng Li", "Baosong Yang", "Beichen Zhang", "Binyuan Hui", "Bo Zheng", "Bowen Yu", "Chang Gao", "Chengen Huang", "Chenxu Lv", "Chujie Zheng", "Dayiheng Liu", "Fan Zhou", "Fei Huang", "Feng Hu", "Hao Ge", "Haoran Wei", "Huan Lin", "Jialong Tang", "Jian Yang", "Jianhong Tu", "Jianwei Zhang", "Jianxin Yang", "Jiaxi Yang", "Jing Zhou", "Jingren Zhou", "Junyang Lin", "Kai Dang", "Keqin Bao", "Kexin Yang", "Le Yu", "Lianghao Deng", "Mei Li", "Mingfeng Xue", "Mingze Li", "Pei Zhang", "Peng Wang", "Qin Zhu", "Rui Men", "Ruize Gao", "Shixuan Liu", "Shuang Luo", "Tianhao Li", "Tianyi Tang", "Wenbiao Yin", "Xingzhang Ren", "Xinyu Wang", "Xinyu Zhang", "Xuancheng Ren", "Yang Fan", "Yang Su", "Yichang Zhang", "Yinger Zhang", "Yu Wan", "Yuqiong Liu", "Zekun Wang", "Zeyu Cui", "Zhenru Zhang", "Zhipeng Zhou", "Zihan Qiu"], "title": "Qwen3 Technical Report", "categories": ["cs.CL"], "comment": null, "summary": "In this work, we present Qwen3, the latest version of the Qwen model family.\nQwen3 comprises a series of large language models (LLMs) designed to advance\nperformance, efficiency, and multilingual capabilities. The Qwen3 series\nincludes models of both dense and Mixture-of-Expert (MoE) architectures, with\nparameter scales ranging from 0.6 to 235 billion. A key innovation in Qwen3 is\nthe integration of thinking mode (for complex, multi-step reasoning) and\nnon-thinking mode (for rapid, context-driven responses) into a unified\nframework. This eliminates the need to switch between different models--such as\nchat-optimized models (e.g., GPT-4o) and dedicated reasoning models (e.g.,\nQwQ-32B)--and enables dynamic mode switching based on user queries or chat\ntemplates. Meanwhile, Qwen3 introduces a thinking budget mechanism, allowing\nusers to allocate computational resources adaptively during inference, thereby\nbalancing latency and performance based on task complexity. Moreover, by\nleveraging the knowledge from the flagship models, we significantly reduce the\ncomputational resources required to build smaller-scale models, while ensuring\ntheir highly competitive performance. Empirical evaluations demonstrate that\nQwen3 achieves state-of-the-art results across diverse benchmarks, including\ntasks in code generation, mathematical reasoning, agent tasks, etc.,\ncompetitive against larger MoE models and proprietary models. Compared to its\npredecessor Qwen2.5, Qwen3 expands multilingual support from 29 to 119\nlanguages and dialects, enhancing global accessibility through improved\ncross-lingual understanding and generation capabilities. To facilitate\nreproducibility and community-driven research and development, all Qwen3 models\nare publicly accessible under Apache 2.0."}
{"id": "2505.09289", "pdf": "https://arxiv.org/pdf/2505.09289", "abs": "https://arxiv.org/abs/2505.09289", "authors": ["Pedro M. P. Curvo", "Mara Dragomir", "Salvador Torpes", "Mohammadmahdi Rahimi"], "title": "Reproducibility Study of \"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents\"", "categories": ["cs.AI"], "comment": "11 Tables, 9 Figures", "summary": "This study evaluates and extends the findings made by Piatti et al., who\nintroduced GovSim, a simulation framework designed to assess the cooperative\ndecision-making capabilities of large language models (LLMs) in\nresource-sharing scenarios. By replicating key experiments, we validate claims\nregarding the performance of large models, such as GPT-4-turbo, compared to\nsmaller models. The impact of the universalization principle is also examined,\nwith results showing that large models can achieve sustainable cooperation,\nwith or without the principle, while smaller models fail without it. In\naddition, we provide multiple extensions to explore the applicability of the\nframework to new settings. We evaluate additional models, such as DeepSeek-V3\nand GPT-4o-mini, to test whether cooperative behavior generalizes across\ndifferent architectures and model sizes. Furthermore, we introduce new\nsettings: we create a heterogeneous multi-agent environment, study a scenario\nusing Japanese instructions, and explore an \"inverse environment\" where agents\nmust cooperate to mitigate harmful resource distributions. Our results confirm\nthat the benchmark can be applied to new models, scenarios, and languages,\noffering valuable insights into the adaptability of LLMs in complex cooperative\ntasks. Moreover, the experiment involving heterogeneous multi-agent systems\ndemonstrates that high-performing models can influence lower-performing ones to\nadopt similar behaviors. This finding has significant implications for other\nagent-based applications, potentially enabling more efficient use of\ncomputational resources and contributing to the development of more effective\ncooperative AI systems."}
{"id": "2505.08940", "pdf": "https://arxiv.org/pdf/2505.08940", "abs": "https://arxiv.org/abs/2505.08940", "authors": ["Jeremie Blanchard", "Lisa Casino", "Jordan Gierschendorf"], "title": "NeurIPS 2024 Ariel Data Challenge: Characterisation of Exoplanetary Atmospheres Using a Data-Centric Approach", "categories": ["cs.LG", "astro-ph.IM"], "comment": "12 pages", "summary": "The characterization of exoplanetary atmospheres through spectral analysis is\na complex challenge. The NeurIPS 2024 Ariel Data Challenge, in collaboration\nwith the European Space Agency's (ESA) Ariel mission, provided an opportunity\nto explore machine learning techniques for extracting atmospheric compositions\nfrom simulated spectral data. In this work, we focus on a data-centric business\napproach, prioritizing generalization over competition-specific optimization.\nWe briefly outline multiple experimental axes, including feature extraction,\nsignal transformation, and heteroskedastic uncertainty modeling. Our\nexperiments demonstrate that uncertainty estimation plays a crucial role in the\nGaussian Log-Likelihood (GLL) score, impacting performance by several\npercentage points. Despite improving the GLL score by 11%, our results\nhighlight the inherent limitations of tabular modeling and feature engineering\nfor this task, as well as the constraints of a business-driven approach within\na Kaggle-style competition framework. Our findings emphasize the trade-offs\nbetween model simplicity, interpretability, and generalization in astrophysical\ndata analysis."}
{"id": "2505.08882", "pdf": "https://arxiv.org/pdf/2505.08882", "abs": "https://arxiv.org/abs/2505.08882", "authors": ["Ali Almakhluk", "Uthman Baroudi", "Yasser El-Alfy"], "title": "Intelligent Road Anomaly Detection with Real-time Notification System for Enhanced Road Safety", "categories": ["cs.CV", "cs.SY", "eess.IV", "eess.SY"], "comment": null, "summary": "This study aims to improve transportation safety, especially traffic safety.\nRoad damage anomalies such as potholes and cracks have emerged as a significant\nand recurring cause for accidents. To tackle this problem and improve road\nsafety, a comprehensive system has been developed to detect potholes, cracks\n(e.g. alligator, transverse, longitudinal), classify their sizes, and transmit\nthis data to the cloud for appropriate action by authorities. The system also\nbroadcasts warning signals to nearby vehicles warning them if a severe anomaly\nis detected on the road. Moreover, the system can count road anomalies in\nreal-time. It is emulated through the utilization of Raspberry Pi, a camera\nmodule, deep learning model, laptop, and cloud service. Deploying this\ninnovative solution aims to proactively enhance road safety by notifying\nrelevant authorities and drivers about the presence of potholes and cracks to\ntake actions, thereby mitigating potential accidents arising from this\nprevalent road hazard leading to safer road conditions for the whole community."}
{"id": "2505.09407", "pdf": "https://arxiv.org/pdf/2505.09407", "abs": "https://arxiv.org/abs/2505.09407", "authors": ["Subrit Dikshit", "Ritu Tiwari", "Priyank Jain"], "title": "Multilingual Machine Translation with Quantum Encoder Decoder Attention-based Convolutional Variational Circuits", "categories": ["cs.CL", "cs.AI", "cs.ET"], "comment": "12 pages, 12 figures", "summary": "Cloud-based multilingual translation services like Google Translate and\nMicrosoft Translator achieve state-of-the-art translation capabilities. These\nservices inherently use large multilingual language models such as GRU, LSTM,\nBERT, GPT, T5, or similar encoder-decoder architectures with attention\nmechanisms as the backbone. Also, new age natural language systems, for\ninstance ChatGPT and DeepSeek, have established huge potential in multiple\ntasks in natural language processing. At the same time, they also possess\noutstanding multilingual translation capabilities. However, these models use\nthe classical computing realm as a backend. QEDACVC (Quantum Encoder Decoder\nAttention-based Convolutional Variational Circuits) is an alternate solution\nthat explores the quantum computing realm instead of the classical computing\nrealm to study and demonstrate multilingual machine translation. QEDACVC\nintroduces the quantum encoder-decoder architecture that simulates and runs on\nquantum computing hardware via quantum convolution, quantum pooling, quantum\nvariational circuit, and quantum attention as software alterations. QEDACVC\nachieves an Accuracy of 82% when trained on the OPUS dataset for English,\nFrench, German, and Hindi corpora for multilingual translations."}
{"id": "2505.09341", "pdf": "https://arxiv.org/pdf/2505.09341", "abs": "https://arxiv.org/abs/2505.09341", "authors": ["Evžen Wybitul"], "title": "Access Controls Will Solve the Dual-Use Dilemma", "categories": ["cs.AI"], "comment": null, "summary": "AI safety systems face a dual-use dilemma. Since the same request can be\neither harmless or harmful depending on who made it and why, if the system\nmakes decisions based solely on the request's content, it will refuse some\nlegitimate queries and let pass harmful ones. To address this, we propose a\nconceptual access control framework, based on verified user credentials (such\nas institutional affiliation) and classifiers that assign model outputs to risk\ncategories (such as advanced virology). The system permits responses only when\nthe user's verified credentials match the category's requirements. For\nimplementation of the model output classifiers, we introduce a theoretical\napproach utilizing small, gated expert modules integrated into the generator\nmodel, trained with gradient routing, that enable efficient risk detection\nwithout the capability gap problems of external monitors. While open questions\nremain about the verification mechanisms, risk categories, and the technical\nimplementation, our framework makes the first step toward enabling granular\ngovernance of AI capabilities: verified users gain access to specialized\nknowledge without arbitrary restrictions, while adversaries are blocked from\nit. This contextual approach reconciles model utility with robust safety,\naddressing the dual-use dilemma."}
{"id": "2505.08941", "pdf": "https://arxiv.org/pdf/2505.08941", "abs": "https://arxiv.org/abs/2505.08941", "authors": ["Gavin Hull", "Alex Bihlo"], "title": "ForeCite: Adapting Pre-Trained Language Models to Predict Future Citation Rates of Academic Papers", "categories": ["cs.LG", "cs.CL"], "comment": "16 pages, 13 figures", "summary": "Predicting the future citation rates of academic papers is an important step\ntoward the automation of research evaluation and the acceleration of scientific\nprogress. We present $\\textbf{ForeCite}$, a simple but powerful framework to\nappend pre-trained causal language models with a linear head for average\nmonthly citation rate prediction. Adapting transformers for regression tasks,\nForeCite achieves a test correlation of $\\rho = 0.826$ on a curated dataset of\n900K+ biomedical papers published between 2000 and 2024, a 27-point improvement\nover the previous state-of-the-art. Comprehensive scaling-law analysis reveals\nconsistent gains across model sizes and data volumes, while temporal holdout\nexperiments confirm practical robustness. Gradient-based saliency heatmaps\nsuggest a potentially undue reliance on titles and abstract texts. These\nresults establish a new state-of-the-art in forecasting the long-term influence\nof academic research and lay the groundwork for the automated, high-fidelity\nevaluation of scientific contributions."}
{"id": "2505.08886", "pdf": "https://arxiv.org/pdf/2505.08886", "abs": "https://arxiv.org/abs/2505.08886", "authors": ["Hamideh Khaleghpour", "Brett McKinney"], "title": "Optimizing Neuro-Fuzzy and Colonial Competition Algorithms for Skin Cancer Diagnosis in Dermatoscopic Images", "categories": ["cs.CV", "cs.LG"], "comment": "7 pages, 10 figures. Accepted at the 2nd Asia Pacific Computer\n  Systems Conference (APCS 2024), March 15-17, 2024", "summary": "The rising incidence of skin cancer, coupled with limited public awareness\nand a shortfall in clinical expertise, underscores an urgent need for advanced\ndiagnostic aids. Artificial Intelligence (AI) has emerged as a promising tool\nin this domain, particularly for distinguishing malignant from benign skin\nlesions. Leveraging publicly available datasets of skin lesions, researchers\nhave been developing AI-based diagnostic solutions. However, the integration of\nsuch computer systems in clinical settings is still nascent. This study aims to\nbridge this gap by employing a fusion of image processing techniques and\nmachine learning algorithms, specifically neuro-fuzzy and colonial competition\napproaches. Applied to dermoscopic images from the ISIC database, our method\nachieved a notable accuracy of 94% on a dataset of 560 images. These results\nunderscore the potential of our approach in aiding clinicians in the early\ndetection of melanoma, thereby contributing significantly to skin cancer\ndiagnostics."}
{"id": "2505.09519", "pdf": "https://arxiv.org/pdf/2505.09519", "abs": "https://arxiv.org/abs/2505.09519", "authors": ["Zongqian Li", "Yixuan Su", "Nigel Collier"], "title": "PT-MoE: An Efficient Finetuning Framework for Integrating Mixture-of-Experts into Prompt Tuning", "categories": ["cs.CL"], "comment": null, "summary": "Parameter-efficient fine-tuning (PEFT) methods have shown promise in adapting\nlarge language models, yet existing approaches exhibit counter-intuitive\nphenomena: integrating router into prompt tuning (PT) increases training\nefficiency yet does not improve performance universally; parameter reduction\nthrough matrix decomposition can improve performance in specific domains.\nMotivated by these observations and the modular nature of PT, we propose\nPT-MoE, a novel framework that integrates matrix decomposition with\nmixture-of-experts (MoE) routing for efficient PT. Results across 17 datasets\ndemonstrate that PT-MoE achieves state-of-the-art performance in both question\nanswering (QA) and mathematical problem solving tasks, improving F1 score by\n1.49 points over PT and 2.13 points over LoRA in QA tasks, while enhancing\nmathematical accuracy by 10.75 points over PT and 0.44 points over LoRA, all\nwhile using 25% fewer parameters than LoRA. Our analysis reveals that while PT\nmethods generally excel in QA tasks and LoRA-based methods in math datasets,\nthe integration of matrix decomposition and MoE in PT-MoE yields complementary\nbenefits: decomposition enables efficient parameter sharing across experts\nwhile MoE provides dynamic adaptation, collectively enabling PT-MoE to\ndemonstrate cross-task consistency and generalization abilities. These\nfindings, along with ablation studies on routing mechanisms and architectural\ncomponents, provide insights for future PEFT methods."}
{"id": "2505.09396", "pdf": "https://arxiv.org/pdf/2505.09396", "abs": "https://arxiv.org/abs/2505.09396", "authors": ["Vince Trencsenyi", "Agnieszka Mensfelt", "Kostas Stathis"], "title": "The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "The rapid rise of large language models (LLMs) has shifted artificial\nintelligence (AI) research toward agentic systems, motivating the use of weaker\nand more flexible notions of agency. However, this shift raises key questions\nabout the extent to which LLM-based agents replicate human strategic reasoning,\nparticularly in game-theoretic settings. In this context, we examine the role\nof agentic sophistication in shaping artificial reasoners' performance by\nevaluating three agent designs: a simple game-theoretic model, an unstructured\nLLM-as-agent model, and an LLM integrated into a traditional agentic framework.\nUsing guessing games as a testbed, we benchmarked these agents against human\nparticipants across general reasoning patterns and individual role-based\nobjectives. Furthermore, we introduced obfuscated game scenarios to assess\nagents' ability to generalise beyond training distributions. Our analysis,\ncovering over 2000 reasoning samples across 25 agent configurations, shows that\nhuman-inspired cognitive structures can enhance LLM agents' alignment with\nhuman strategic behaviour. Still, the relationship between agentic design\ncomplexity and human-likeness is non-linear, highlighting a critical dependence\non underlying LLM capabilities and suggesting limits to simple architectural\naugmentation."}
{"id": "2505.08964", "pdf": "https://arxiv.org/pdf/2505.08964", "abs": "https://arxiv.org/abs/2505.08964", "authors": ["Majed Jaber", "Julien Michel", "Nicolas Boutry", "Pierre Parrend"], "title": "GPML: Graph Processing for Machine Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "The dramatic increase of complex, multi-step, and rapidly evolving attacks in\ndynamic networks involves advanced cyber-threat detectors. The GPML (Graph\nProcessing for Machine Learning) library addresses this need by transforming\nraw network traffic traces into graph representations, enabling advanced\ninsights into network behaviors. The library provides tools to detect anomalies\nin interaction and community shifts in dynamic networks. GPML supports\ncommunity and spectral metrics extraction, enhancing both real-time detection\nand historical forensics analysis. This library supports modern cybersecurity\nchallenges with a robust, graph-based approach."}
{"id": "2505.08909", "pdf": "https://arxiv.org/pdf/2505.08909", "abs": "https://arxiv.org/abs/2505.08909", "authors": ["Deliang Wei", "Peng Chen", "Haobo Xu", "Jiale Yao", "Fang Li", "Tieyong Zeng"], "title": "Learning Cocoercive Conservative Denoisers via Helmholtz Decomposition for Poisson Inverse Problems", "categories": ["cs.CV", "cs.LG", "math.FA", "math.OC", "94A08, 47H10, 47J26, 46N10, 47N10"], "comment": "31 pages", "summary": "Plug-and-play (PnP) methods with deep denoisers have shown impressive results\nin imaging problems. They typically require strong convexity or smoothness of\nthe fidelity term and a (residual) non-expansive denoiser for convergence.\nThese assumptions, however, are violated in Poisson inverse problems, and\nnon-expansiveness can hinder denoising performance. To address these\nchallenges, we propose a cocoercive conservative (CoCo) denoiser, which may be\n(residual) expansive, leading to improved denoising. By leveraging the\ngeneralized Helmholtz decomposition, we introduce a novel training strategy\nthat combines Hamiltonian regularization to promote conservativeness and\nspectral regularization to ensure cocoerciveness. We prove that CoCo denoiser\nis a proximal operator of a weakly convex function, enabling a restoration\nmodel with an implicit weakly convex prior. The global convergence of PnP\nmethods to a stationary point of this restoration model is established.\nExtensive experimental results demonstrate that our approach outperforms\nclosely related methods in both visual quality and quantitative metrics."}
{"id": "2505.09595", "pdf": "https://arxiv.org/pdf/2505.09595", "abs": "https://arxiv.org/abs/2505.09595", "authors": ["Abdullah Mushtaq", "Imran Taj", "Rafay Naeem", "Ibrahim Ghaznavi", "Junaid Qadir"], "title": "WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "comment": "Preprint. Submitted to the Journal of Artificial Intelligence\n  Research (JAIR) on April 29, 2025", "summary": "Large Language Models (LLMs) are predominantly trained and aligned in ways\nthat reinforce Western-centric epistemologies and socio-cultural norms, leading\nto cultural homogenization and limiting their ability to reflect global\ncivilizational plurality. Existing benchmarking frameworks fail to adequately\ncapture this bias, as they rely on rigid, closed-form assessments that overlook\nthe complexity of cultural inclusivity. To address this, we introduce\nWorldView-Bench, a benchmark designed to evaluate Global Cultural Inclusivity\n(GCI) in LLMs by analyzing their ability to accommodate diverse worldviews. Our\napproach is grounded in the Multiplex Worldview proposed by Senturk et al.,\nwhich distinguishes between Uniplex models, reinforcing cultural\nhomogenization, and Multiplex models, which integrate diverse perspectives.\nWorldView-Bench measures Cultural Polarization, the exclusion of alternative\nperspectives, through free-form generative evaluation rather than conventional\ncategorical benchmarks. We implement applied multiplexity through two\nintervention strategies: (1) Contextually-Implemented Multiplex LLMs, where\nsystem prompts embed multiplexity principles, and (2) Multi-Agent System\n(MAS)-Implemented Multiplex LLMs, where multiple LLM agents representing\ndistinct cultural perspectives collaboratively generate responses. Our results\ndemonstrate a significant increase in Perspectives Distribution Score (PDS)\nentropy from 13% at baseline to 94% with MAS-Implemented Multiplex LLMs,\nalongside a shift toward positive sentiment (67.7%) and enhanced cultural\nbalance. These findings highlight the potential of multiplex-aware AI\nevaluation in mitigating cultural bias in LLMs, paving the way for more\ninclusive and ethically aligned AI systems."}
{"id": "2505.09412", "pdf": "https://arxiv.org/pdf/2505.09412", "abs": "https://arxiv.org/abs/2505.09412", "authors": ["Paul Kobialka", "Lina Gerlach", "Francesco Leofante", "Erika Ábrahám", "Silvia Lizeth Tapia Tarifa", "Einar Broch Johnsen"], "title": "Counterfactual Strategies for Markov Decision Processes", "categories": ["cs.AI", "I.2.m"], "comment": null, "summary": "Counterfactuals are widely used in AI to explain how minimal changes to a\nmodel's input can lead to a different output. However, established methods for\ncomputing counterfactuals typically focus on one-step decision-making, and are\nnot directly applicable to sequential decision-making tasks. This paper fills\nthis gap by introducing counterfactual strategies for Markov Decision Processes\n(MDPs). During MDP execution, a strategy decides which of the enabled actions\n(with known probabilistic effects) to execute next. Given an initial strategy\nthat reaches an undesired outcome with a probability above some limit, we\nidentify minimal changes to the initial strategy to reduce that probability\nbelow the limit. We encode such counterfactual strategies as solutions to\nnon-linear optimization problems, and further extend our encoding to synthesize\ndiverse counterfactual strategies. We evaluate our approach on four real-world\ndatasets and demonstrate its practical viability in sophisticated sequential\ndecision-making tasks."}
{"id": "2505.08977", "pdf": "https://arxiv.org/pdf/2505.08977", "abs": "https://arxiv.org/abs/2505.08977", "authors": ["Hossein Babaei", "Mel White", "Sina Alemohammad", "Richard G. Baraniuk"], "title": "SaFARi: State-Space Models for Frame-Agnostic Representation", "categories": ["cs.LG", "eess.AS", "eess.IV", "eess.SP"], "comment": "13 pages, 5 figures", "summary": "State-Space Models (SSMs) have re-emerged as a powerful tool for online\nfunction approximation, and as the backbone of machine learning models for\nlong-range dependent data. However, to date, only a few polynomial bases have\nbeen explored for this purpose, and the state-of-the-art implementations were\nbuilt upon the best of a few limited options. In this paper, we present a\ngeneralized method for building an SSM with any frame or basis, rather than\nbeing restricted to polynomials. This framework encompasses the approach known\nas HiPPO, but also permits an infinite diversity of other possible \"species\"\nwithin the SSM architecture. We dub this approach SaFARi: SSMs for\nFrame-Agnostic Representation."}
{"id": "2505.08910", "pdf": "https://arxiv.org/pdf/2505.08910", "abs": "https://arxiv.org/abs/2505.08910", "authors": ["Nahid Alam", "Karthik Reddy Kanjula", "Surya Guthikonda", "Timothy Chung", "Bala Krishna S Vegesna", "Abhipsha Das", "Anthony Susevski", "Ryan Sze-Yin Chan", "S M Iftekhar Uddin", "Shayekh Bin Islam", "Roshan Santhosh", "Snegha A", "Drishti Sharma", "Chen Liu", "Isha Chaturvedi", "Genta Indra Winata", "Ashvanth. S", "Snehanshu Mukherjee", "Alham Fikri Aji"], "title": "Behind Maya: Building a Multilingual Vision Language Model", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted at VLM4ALL CVPR 2025 Workshop", "summary": "In recent times, we have seen a rapid development of large Vision-Language\nModels (VLMs). They have shown impressive results on academic benchmarks,\nprimarily in widely spoken languages but lack performance on low-resource\nlanguages and varied cultural contexts. To address these limitations, we\nintroduce Maya, an open-source Multilingual VLM. Our contributions are: 1) a\nmultilingual image-text pretraining dataset in eight languages, based on the\nLLaVA pretraining dataset; and 2) a multilingual image-text model supporting\nthese languages, enhancing cultural and linguistic comprehension in\nvision-language tasks. Code available at https://github.com/nahidalam/maya."}
{"id": "2505.08795", "pdf": "https://arxiv.org/pdf/2505.08795", "abs": "https://arxiv.org/abs/2505.08795", "authors": ["Andres Anabalon", "Hugo Garces", "Julio Oliva", "Jose Cifuentes"], "title": "The Geometry of Meaning: Perfect Spacetime Representations of Hierarchical Structures", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "7 pages, 3 figures", "summary": "We show that there is a fast algorithm that embeds hierarchical structures in\nthree-dimensional Minkowski spacetime. The correlation of data ends up purely\nencoded in the causal structure. Our model relies solely on oriented token\npairs -- local hierarchical signals -- with no access to global symbolic\nstructure. We apply our method to the corpus of \\textit{WordNet}. We provide a\nperfect embedding of the mammal sub-tree including ambiguities (more than one\nhierarchy per node) in such a way that the hierarchical structures get\ncompletely codified in the geometry and exactly reproduce the ground-truth. We\nextend this to a perfect embedding of the maximal unambiguous subset of the\n\\textit{WordNet} with 82{,}115 noun tokens and a single hierarchy per token. We\nintroduce a novel retrieval mechanism in which causality, not distance, governs\nhierarchical access. Our results seem to indicate that all discrete data has a\nperfect geometrical representation that is three-dimensional. The resulting\nembeddings are nearly conformally invariant, indicating deep connections with\ngeneral relativity and field theory. These results suggest that concepts,\ncategories, and their interrelations, namely hierarchical meaning itself, is\ngeometric."}
{"id": "2505.09518", "pdf": "https://arxiv.org/pdf/2505.09518", "abs": "https://arxiv.org/abs/2505.09518", "authors": ["Maris F. L. Galesloot", "Roman Andriushchenko", "Milan Češka", "Sebastian Junges", "Nils Jansen"], "title": "\\textsc{rfPG}: Robust Finite-Memory Policy Gradients for Hidden-Model POMDPs", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted for publication at IJCAI 2025", "summary": "Partially observable Markov decision processes (POMDPs) model specific\nenvironments in sequential decision-making under uncertainty. Critically,\noptimal policies for POMDPs may not be robust against perturbations in the\nenvironment. Hidden-model POMDPs (HM-POMDPs) capture sets of different\nenvironment models, that is, POMDPs with a shared action and observation space.\nThe intuition is that the true model is hidden among a set of potential models,\nand it is unknown which model will be the environment at execution time. A\npolicy is robust for a given HM-POMDP if it achieves sufficient performance for\neach of its POMDPs. We compute such robust policies by combining two orthogonal\ntechniques: (1) a deductive formal verification technique that supports\ntractable robust policy evaluation by computing a worst-case POMDP within the\nHM-POMDP and (2) subgradient ascent to optimize the candidate policy for a\nworst-case POMDP. The empirical evaluation shows that, compared to various\nbaselines, our approach (1) produces policies that are more robust and\ngeneralize better to unseen POMDPs and (2) scales to HM-POMDPs that consist of\nover a hundred thousand environments."}
{"id": "2505.08982", "pdf": "https://arxiv.org/pdf/2505.08982", "abs": "https://arxiv.org/abs/2505.08982", "authors": ["Jiachen Qian", "Yang Zheng"], "title": "Model-free Online Learning for the Kalman Filter: Forgetting Factor and Logarithmic Regret", "categories": ["cs.LG", "cs.SY", "eess.SP", "eess.SY"], "comment": null, "summary": "We consider the problem of online prediction for an unknown, non-explosive\nlinear stochastic system. With a known system model, the optimal predictor is\nthe celebrated Kalman filter. In the case of unknown systems, existing\napproaches based on recursive least squares and its variants may suffer from\ndegraded performance due to the highly imbalanced nature of the regression\nmodel. This imbalance can easily lead to overfitting and thus degrade\nprediction accuracy. We tackle this problem by injecting an inductive bias into\nthe regression model via {exponential forgetting}. While exponential forgetting\nis a common wisdom in online learning, it is typically used for re-weighting\ndata. In contrast, our approach focuses on balancing the regression model. This\nachieves a better trade-off between {regression} and {regularization errors},\nand simultaneously reduces the {accumulation error}. With new proof techniques,\nwe also provide a sharper logarithmic regret bound of $O(\\log^3 N)$, where $N$\nis the number of observations."}
{"id": "2505.08961", "pdf": "https://arxiv.org/pdf/2505.08961", "abs": "https://arxiv.org/abs/2505.08961", "authors": ["Yancheng Wang", "Nebojsa Jojic", "Yingzhen Yang"], "title": "Differentiable Channel Selection in Self-Attention For Person Re-Identification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In this paper, we propose a novel attention module termed the Differentiable\nChannel Selection Attention module, or the DCS-Attention module. In contrast\nwith conventional self-attention, the DCS-Attention module features selection\nof informative channels in the computation of the attention weights. The\nselection of the feature channels is performed in a differentiable manner,\nenabling seamless integration with DNN training. Our DCS-Attention is\ncompatible with either fixed neural network backbones or learnable backbones\nwith Differentiable Neural Architecture Search (DNAS), leading to DCS with\nFixed Backbone (DCS-FB) and DCS-DNAS, respectively. Importantly, our\nDCS-Attention is motivated by the principle of Information Bottleneck (IB), and\na novel variational upper bound for the IB loss, which can be optimized by SGD,\nis derived and incorporated into the training loss of the networks with the\nDCS-Attention modules. In this manner, a neural network with DCS-Attention\nmodules is capable of selecting the most informative channels for feature\nextraction so that it enjoys state-of-the-art performance for the Re-ID task.\nExtensive experiments on multiple person Re-ID benchmarks using both DCS-FB and\nDCS-DNAS show that DCS-Attention significantly enhances the prediction accuracy\nof DNNs for person Re-ID, which demonstrates the effectiveness of DCS-Attention\nin learning discriminative features critical to identifying person identities.\nThe code of our work is available at\nhttps://github.com/Statistical-Deep-Learning/DCS-Attention."}
{"id": "2505.08823", "pdf": "https://arxiv.org/pdf/2505.08823", "abs": "https://arxiv.org/abs/2505.08823", "authors": ["Cody Steinmetz", "Gavin Childress", "Aaron Herbst", "Gavin Jones", "Jasdeep Singh", "Eli Vang", "Keagan Weinstock"], "title": "An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have transformed natural-language processing,\nyet their scale makes real-world deployment costly. Post-training quantization\nreduces memory and computation but often degrades accuracy, while\nquantization-aware training can recover performance at the cost of extra\ntraining. Pushing quantization to the ternary (2-bit) regime yields even larger\nsavings but is notoriously unstable. Building on recent work showing that a\nbias-free, RMS-normalized Transformer with straight-through estimation can\nreach 1.58-bit precision, we demonstrate that simply inserting RMS\nnormalization before every linear projection and applying a gradual, layer-wise\nquantization schedule stably fine-tunes full-precision checkpoints into ternary\nLLMs. Our approach matches or surpasses more elaborate knowledge-distillation\npipelines on standard language-modeling benchmarks without adding model\ncomplexity. These results indicate that careful normalization alone can close\nmuch of the accuracy gap between ternary and full-precision LLMs, making\nultra-low-bit inference practical."}
{"id": "2505.09614", "pdf": "https://arxiv.org/pdf/2505.09614", "abs": "https://arxiv.org/abs/2505.09614", "authors": ["Anthony GX-Chen", "Dongyan Lin", "Mandana Samiei", "Doina Precup", "Blake A. Richards", "Rob Fergus", "Kenneth Marino"], "title": "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Language model (LM) agents are increasingly used as autonomous\ndecision-makers who need to actively gather information to guide their\ndecisions. A crucial cognitive skill for such agents is the efficient\nexploration and understanding of the causal structure of the world -- key to\nrobust, scientifically grounded reasoning. Yet, it remains unclear whether LMs\npossess this capability or exhibit systematic biases leading to erroneous\nconclusions. In this work, we examine LMs' ability to explore and infer causal\nrelationships, using the well-established \"Blicket Test\" paradigm from\ndevelopmental psychology. We find that LMs reliably infer the common, intuitive\ndisjunctive causal relationships but systematically struggle with the unusual,\nyet equally (or sometimes even more) evidenced conjunctive ones. This\n\"disjunctive bias\" persists across model families, sizes, and prompting\nstrategies, and performance further declines as task complexity increases.\nInterestingly, an analogous bias appears in human adults, suggesting that LMs\nmay have inherited deep-seated reasoning heuristics from their training data.\nTo this end, we quantify similarities between LMs and humans, finding that LMs\nexhibit adult-like inference profiles (but not children-like). Finally, we\npropose a test-time sampling method which explicitly samples and eliminates\nhypotheses about causal relationships from the LM. This scalable approach\nsignificantly reduces the disjunctive bias and moves LMs closer to the goal of\nscientific, causally rigorous reasoning."}
{"id": "2505.09003", "pdf": "https://arxiv.org/pdf/2505.09003", "abs": "https://arxiv.org/abs/2505.09003", "authors": ["Zeki Doruk Erden", "Donia Gasmi", "Boi Faltings"], "title": "Continual Reinforcement Learning via Autoencoder-Driven Task and New Environment Recognition", "categories": ["cs.LG", "cs.AI"], "comment": "Published in the Autonomous Robots and Multirobot Systems (ARMS)\n  workshop at AAMAS 2025", "summary": "Continual learning for reinforcement learning agents remains a significant\nchallenge, particularly in preserving and leveraging existing information\nwithout an external signal to indicate changes in tasks or environments. In\nthis study, we explore the effectiveness of autoencoders in detecting new tasks\nand matching observed environments to previously encountered ones. Our approach\nintegrates policy optimization with familiarity autoencoders within an\nend-to-end continual learning system. This system can recognize and learn new\ntasks or environments while preserving knowledge from earlier experiences and\ncan selectively retrieve relevant knowledge when re-encountering a known\nenvironment. Initial results demonstrate successful continual learning without\nexternal signals to indicate task changes or reencounters, showing promise for\nthis methodology."}
{"id": "2505.08971", "pdf": "https://arxiv.org/pdf/2505.08971", "abs": "https://arxiv.org/abs/2505.08971", "authors": ["Yangyi Chen", "Hao Peng", "Tong Zhang", "Heng Ji"], "title": "Prioritizing Image-Related Tokens Enhances Vision-Language Pre-Training", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "The code will be available at https://github.com/Yangyi-Chen/PRIOR", "summary": "In standard large vision-language models (LVLMs) pre-training, the model\ntypically maximizes the joint probability of the caption conditioned on the\nimage via next-token prediction (NTP); however, since only a small subset of\ncaption tokens directly relates to the visual content, this naive NTP\nunintentionally fits the model to noise and increases the risk of\nhallucination. We present PRIOR, a simple vision-language pre-training approach\nthat addresses this issue by prioritizing image-related tokens through\ndifferential weighting in the NTP loss, drawing from the importance sampling\nframework. PRIOR introduces a reference model-a text-only large language model\n(LLM) trained on the captions without image inputs, to weight each token based\non its probability for LVLMs training. Intuitively, tokens that are directly\nrelated to the visual inputs are harder to predict without the image and thus\nreceive lower probabilities from the text-only reference LLM. During training,\nwe implement a token-specific re-weighting term based on the importance scores\nto adjust each token's loss. We implement PRIOR in two distinct settings: LVLMs\nwith visual encoders and LVLMs without visual encoders. We observe 19% and 8%\naverage relative improvement, respectively, on several vision-language\nbenchmarks compared to NTP. In addition, PRIOR exhibits superior scaling\nproperties, as demonstrated by significantly higher scaling coefficients,\nindicating greater potential for performance gains compared to NTP given\nincreasing compute and data."}
{"id": "2505.08842", "pdf": "https://arxiv.org/pdf/2505.08842", "abs": "https://arxiv.org/abs/2505.08842", "authors": ["Zekun Wu", "Seonglae Cho", "Umar Mohammed", "Cristian Munoz", "Kleyton Costa", "Xin Guan", "Theo King", "Ze Wang", "Emre Kazim", "Adriano Koshiyama"], "title": "LibVulnWatch: A Deep Assessment Agent System and Leaderboard for Uncovering Hidden Vulnerabilities in Open-Source AI Libraries", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Open-source AI libraries are foundational to modern AI systems but pose\nsignificant, underexamined risks across security, licensing, maintenance,\nsupply chain integrity, and regulatory compliance. We present LibVulnWatch, a\ngraph-based agentic assessment framework that performs deep, source-grounded\nevaluations of these libraries. Built on LangGraph, the system coordinates a\ndirected acyclic graph of specialized agents to extract, verify, and quantify\nrisk using evidence from trusted sources such as repositories, documentation,\nand vulnerability databases. LibVulnWatch generates reproducible,\ngovernance-aligned scores across five critical domains, publishing them to a\npublic leaderboard for longitudinal ecosystem monitoring. Applied to 20 widely\nused libraries, including ML frameworks, LLM inference engines, and agent\norchestration tools, our system covers up to 88% of OpenSSF Scorecard checks\nwhile uncovering up to 19 additional risks per library. These include critical\nRemote Code Execution (RCE) vulnerabilities, absent Software Bills of Materials\n(SBOMs), licensing constraints, undocumented telemetry, and widespread gaps in\nregulatory documentation and auditability. By translating high-level governance\nprinciples into practical, verifiable metrics, LibVulnWatch advances technical\nAI governance with a scalable, transparent mechanism for continuous supply\nchain risk assessment and informed library selection."}
{"id": "2412.15404", "pdf": "https://arxiv.org/pdf/2412.15404", "abs": "https://arxiv.org/abs/2412.15404", "authors": ["Ahmet Yasin Aytar", "Kemal Kilic", "Kamer Kaya"], "title": "A Retrieval-Augmented Generation Framework for Academic Literature Navigation in Data Science", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "In the rapidly evolving field of data science, efficiently navigating the\nexpansive body of academic literature is crucial for informed decision-making\nand innovation. This paper presents an enhanced Retrieval-Augmented Generation\n(RAG) application, an artificial intelligence (AI)-based system designed to\nassist data scientists in accessing precise and contextually relevant academic\nresources. The AI-powered application integrates advanced techniques, including\nthe GeneRation Of BIbliographic Data (GROBID) technique for extracting\nbibliographic information, fine-tuned embedding models, semantic chunking, and\nan abstract-first retrieval method, to significantly improve the relevance and\naccuracy of the retrieved information. This implementation of AI specifically\naddresses the challenge of academic literature navigation. A comprehensive\nevaluation using the Retrieval-Augmented Generation Assessment System (RAGAS)\nframework demonstrates substantial improvements in key metrics, particularly\nContext Relevance, underscoring the system's effectiveness in reducing\ninformation overload and enhancing decision-making processes. Our findings\nhighlight the potential of this enhanced Retrieval-Augmented Generation system\nto transform academic exploration within data science, ultimately advancing the\nworkflow of research and innovation in the field."}
{"id": "2505.09011", "pdf": "https://arxiv.org/pdf/2505.09011", "abs": "https://arxiv.org/abs/2505.09011", "authors": ["Antonio Candito", "Matthew D Blackledge", "Richard Holbrey", "Nuria Porta", "Ana Ribeiro", "Fabio Zugni", "Luca D'Erme", "Francesca Castagnoli", "Alina Dragan", "Ricardo Donners", "Christina Messiou", "Nina Tunariu", "Dow-Mu Koh"], "title": "Signal-based AI-driven software solution for automated quantification of metastatic bone disease and treatment response assessment using Whole-Body Diffusion-Weighted MRI (WB-DWI) biomarkers in Advanced Prostate Cancer", "categories": ["cs.LG"], "comment": null, "summary": "We developed an AI-driven software solution to quantify metastatic bone\ndisease from WB-DWI scans. Core technologies include: (i) a weakly-supervised\nResidual U-Net model generating a skeleton probability map to isolate bone;\n(ii) a statistical framework for WB-DWI intensity normalisation, obtaining a\nsignal-normalised b=900s/mm^2 (b900) image; and (iii) a shallow convolutional\nneural network that processes outputs from (i) and (ii) to generate a mask of\nsuspected bone lesions, characterised by higher b900 signal intensity due to\nrestricted water diffusion. This mask is applied to the gADC map to extract TDV\nand gADC statistics. We tested the tool using expert-defined metastatic bone\ndisease delineations on 66 datasets, assessed repeatability of imaging\nbiomarkers (N=10), and compared software-based response assessment with a\nconstruct reference standard based on clinical, laboratory and imaging\nassessments (N=118). Dice score between manual and automated delineations was\n0.6 for lesions within pelvis and spine, with an average surface distance of\n2mm. Relative differences for log-transformed TDV (log-TDV) and median gADC\nwere below 9% and 5%, respectively. Repeatability analysis showed coefficients\nof variation of 4.57% for log-TDV and 3.54% for median gADC, with intraclass\ncorrelation coefficients above 0.9. The software achieved 80.5% accuracy, 84.3%\nsensitivity, and 85.7% specificity in assessing response to treatment compared\nto the construct reference standard. Computation time generating a mask\naveraged 90 seconds per scan. Our software enables reproducible TDV and gADC\nquantification from WB-DWI scans for monitoring metastatic bone disease\nresponse, thus providing potentially useful measurements for clinical\ndecision-making in APC patients."}
{"id": "2505.08999", "pdf": "https://arxiv.org/pdf/2505.08999", "abs": "https://arxiv.org/abs/2505.08999", "authors": ["Wei-Long Tian", "Peng Gao", "Xiao Liu", "Long Xu", "Hamido Fujita", "Hanan Aljuai", "Mao-Li Wang"], "title": "Towards Adaptive Meta-Gradient Adversarial Examples for Visual Tracking", "categories": ["cs.CV"], "comment": null, "summary": "In recent years, visual tracking methods based on convolutional neural\nnetworks and Transformers have achieved remarkable performance and have been\nsuccessfully applied in fields such as autonomous driving. However, the\nnumerous security issues exposed by deep learning models have gradually\naffected the reliable application of visual tracking methods in real-world\nscenarios. Therefore, how to reveal the security vulnerabilities of existing\nvisual trackers through effective adversarial attacks has become a critical\nproblem that needs to be addressed. To this end, we propose an adaptive\nmeta-gradient adversarial attack (AMGA) method for visual tracking. This method\nintegrates multi-model ensembles and meta-learning strategies, combining\nmomentum mechanisms and Gaussian smoothing, which can significantly enhance the\ntransferability and attack effectiveness of adversarial examples. AMGA randomly\nselects models from a large model repository, constructs diverse tracking\nscenarios, and iteratively performs both white- and black-box adversarial\nattacks in each scenario, optimizing the gradient directions of each model.\nThis paradigm minimizes the gap between white- and black-box adversarial\nattacks, thus achieving excellent attack performance in black-box scenarios.\nExtensive experimental results on large-scale datasets such as OTB2015, LaSOT,\nand GOT-10k demonstrate that AMGA significantly improves the attack\nperformance, transferability, and deception of adversarial examples. Codes and\ndata are available at https://github.com/pgao-lab/AMGA."}
{"id": "2505.08902", "pdf": "https://arxiv.org/pdf/2505.08902", "abs": "https://arxiv.org/abs/2505.08902", "authors": ["Lucas McCullum", "Pelagie Ami Agassi", "Leo Anthony Celi", "Daniel K. Ebner", "Chrystinne Oliveira Fernandes", "Rachel S. Hicklen", "Mkliwa Koumbia", "Lisa Soleymani Lehmann", "David Restrepo"], "title": "Performance Gains of LLMs With Humans in a World of LLMs Versus Humans", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": null, "summary": "Currently, a considerable research effort is devoted to comparing LLMs to a\ngroup of human experts, where the term \"expert\" is often ill-defined or\nvariable, at best, in a state of constantly updating LLM releases. Without\nproper safeguards in place, LLMs will threaten to cause harm to the established\nstructure of safe delivery of patient care which has been carefully developed\nthroughout history to keep the safety of the patient at the forefront. A key\ndriver of LLM innovation is founded on community research efforts which, if\ncontinuing to operate under \"humans versus LLMs\" principles, will expedite this\ntrend. Therefore, research efforts moving forward must focus on effectively\ncharacterizing the safe use of LLMs in clinical settings that persist across\nthe rapid development of novel LLM models. In this communication, we\ndemonstrate that rather than comparing LLMs to humans, there is a need to\ndevelop strategies enabling efficient work of humans with LLMs in an almost\nsymbiotic manner."}
{"id": "2505.08795", "pdf": "https://arxiv.org/pdf/2505.08795", "abs": "https://arxiv.org/abs/2505.08795", "authors": ["Andres Anabalon", "Hugo Garces", "Julio Oliva", "Jose Cifuentes"], "title": "The Geometry of Meaning: Perfect Spacetime Representations of Hierarchical Structures", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "7 pages, 3 figures", "summary": "We show that there is a fast algorithm that embeds hierarchical structures in\nthree-dimensional Minkowski spacetime. The correlation of data ends up purely\nencoded in the causal structure. Our model relies solely on oriented token\npairs -- local hierarchical signals -- with no access to global symbolic\nstructure. We apply our method to the corpus of \\textit{WordNet}. We provide a\nperfect embedding of the mammal sub-tree including ambiguities (more than one\nhierarchy per node) in such a way that the hierarchical structures get\ncompletely codified in the geometry and exactly reproduce the ground-truth. We\nextend this to a perfect embedding of the maximal unambiguous subset of the\n\\textit{WordNet} with 82{,}115 noun tokens and a single hierarchy per token. We\nintroduce a novel retrieval mechanism in which causality, not distance, governs\nhierarchical access. Our results seem to indicate that all discrete data has a\nperfect geometrical representation that is three-dimensional. The resulting\nembeddings are nearly conformally invariant, indicating deep connections with\ngeneral relativity and field theory. These results suggest that concepts,\ncategories, and their interrelations, namely hierarchical meaning itself, is\ngeometric."}
{"id": "2505.09017", "pdf": "https://arxiv.org/pdf/2505.09017", "abs": "https://arxiv.org/abs/2505.09017", "authors": ["Bizhan Alipour Pijan", "Serdar Bozdag"], "title": "DyGSSM: Multi-view Dynamic Graph Embeddings with State Space Model Gradient Update", "categories": ["cs.LG", "cs.SI"], "comment": null, "summary": "Most of the dynamic graph representation learning methods involve dividing a\ndynamic graph into discrete snapshots to capture the evolving behavior of nodes\nover time. Existing methods primarily capture only local or global structures\nof each node within a snapshot using message-passing and random walk-based\nmethods. Then, they utilize sequence-based models (e.g., transformers) to\nencode the temporal evolution of node embeddings, and meta-learning techniques\nto update the model parameters. However, these approaches have two limitations.\nFirst, they neglect the extraction of global and local information\nsimultaneously in each snapshot. Second, they fail to consider the model's\nperformance in the current snapshot during parameter updates, resulting in a\nlack of temporal dependency management. Recently, HiPPO (High-order Polynomial\nProjection Operators) algorithm has gained attention for their ability to\noptimize and preserve sequence history in State Space Model (SSM). To address\nthe aforementioned limitations in dynamic graph representation learning, we\npropose a novel method called Multi-view Dynamic Graph Embeddings with State\nSpace Model Gradient Update (DyGSSM). Our approach combines Graph Convolution\nNetworks (GCN) for local feature extraction and random walk with Gated\nRecurrent Unit (GRU) for global feature extraction in each snapshot. We then\nintegrate the local and global features using a cross-attention mechanism.\nAdditionally, we incorporate an SSM based on HiPPO algorithm to account for\nlong-term dependencies when updating model parameters, ensuring that model\nperformance in each snapshot informs subsequent updates. Experiments on five\npublic datasets show that our method outperforms existing baseline and\nstate-of-the-art (SOTA) methods in 17 out of 20 cases."}
{"id": "2505.09018", "pdf": "https://arxiv.org/pdf/2505.09018", "abs": "https://arxiv.org/abs/2505.09018", "authors": ["Adarsh Kumar"], "title": "Multimodal Fusion of Glucose Monitoring and Food Imagery for Caloric Content Prediction", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Effective dietary monitoring is critical for managing Type 2 diabetes, yet\naccurately estimating caloric intake remains a major challenge. While\ncontinuous glucose monitors (CGMs) offer valuable physiological data, they\noften fall short in capturing the full nutritional profile of meals due to\ninter-individual and meal-specific variability. In this work, we introduce a\nmultimodal deep learning framework that jointly leverages CGM time-series data,\nDemographic/Microbiome, and pre-meal food images to enhance caloric estimation.\nOur model utilizes attention based encoding and a convolutional feature\nextraction for meal imagery, multi-layer perceptrons for CGM and Microbiome\ndata followed by a late fusion strategy for joint reasoning. We evaluate our\napproach on a curated dataset of over 40 participants, incorporating\nsynchronized CGM, Demographic and Microbiome data and meal photographs with\nstandardized caloric labels. Our model achieves a Root Mean Squared Relative\nError (RMSRE) of 0.2544, outperforming the baselines models by over 50%. These\nfindings demonstrate the potential of multimodal sensing to improve automated\ndietary assessment tools for chronic disease management."}
{"id": "2505.08905", "pdf": "https://arxiv.org/pdf/2505.08905", "abs": "https://arxiv.org/abs/2505.08905", "authors": ["Michael Majurski", "Cynthia Matuszek"], "title": "Grounding Synthetic Data Evaluations of Language Models in Unsupervised Document Corpora", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Language Models (LMs) continue to advance, improving response quality and\ncoherence. Given Internet-scale training datasets, LMs have likely encountered\nmuch of what users might ask them to generate in some form during their\ntraining. A plethora of evaluation benchmarks have been constructed to assess\nmodel quality, response appropriateness, and reasoning capabilities. However,\nthe human effort required for benchmark construction is limited and being\nrapidly outpaced by the size and scope of the models under evaluation.\nAdditionally, having humans build a benchmark for every possible domain of\ninterest is impractical. Therefore, we propose a methodology for automating the\nconstruction of fact-based synthetic data model evaluations grounded in\ndocument populations. This work leverages those very same LMs to evaluate\ndomain-specific knowledge automatically, using only grounding documents (e.g.,\na textbook) as input. This synthetic data benchmarking approach corresponds\nwell with human curated questions with a Spearman ranking correlation of 0.96\nand a benchmark evaluation Pearson accuracy correlation of 0.79. This novel\ntool supports generating both multiple choice and open-ended synthetic data\nquestions to gain diagnostic insight of LM capability. We apply this\nmethodology to evaluate model performance on a recent relevant arXiv preprint,\ndiscovering a surprisingly strong performance from Gemma3 models."}
{"id": "2505.08798", "pdf": "https://arxiv.org/pdf/2505.08798", "abs": "https://arxiv.org/abs/2505.08798", "authors": ["Mobina Shrestha", "Bishwas Mandal", "Vishal Mandal", "Asis Shrestha"], "title": "In-Context Learning for Label-Efficient Cancer Image Classification in Oncology", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "The application of AI in oncology has been limited by its reliance on large,\nannotated datasets and the need for retraining models for domain-specific\ndiagnostic tasks. Taking heed of these limitations, we investigated in-context\nlearning as a pragmatic alternative to model retraining by allowing models to\nadapt to new diagnostic tasks using only a few labeled examples at inference,\nwithout the need for retraining. Using four vision-language models\n(VLMs)-Paligemma, CLIP, ALIGN and GPT-4o, we evaluated the performance across\nthree oncology datasets: MHIST, PatchCamelyon and HAM10000. To the best of our\nknowledge, this is the first study to compare the performance of multiple VLMs\non different oncology classification tasks. Without any parameter updates, all\nmodels showed significant gains with few-shot prompting, with GPT-4o reaching\nan F1 score of 0.81 in binary classification and 0.60 in multi-class\nclassification settings. While these results remain below the ceiling of fully\nfine-tuned systems, they highlight the potential of ICL to approximate\ntask-specific behavior using only a handful of examples, reflecting how\nclinicians often reason from prior cases. Notably, open-source models like\nPaligemma and CLIP demonstrated competitive gains despite their smaller size,\nsuggesting feasibility for deployment in computing constrained clinical\nenvironments. Overall, these findings highlight the potential of ICL as a\npractical solution in oncology, particularly for rare cancers and\nresource-limited contexts where fine-tuning is infeasible and annotated data is\ndifficult to obtain."}
{"id": "2505.09022", "pdf": "https://arxiv.org/pdf/2505.09022", "abs": "https://arxiv.org/abs/2505.09022", "authors": ["Annan Yu", "N. Benjamin Erichson"], "title": "Block-Biased Mamba for Long-Range Sequence Processing", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Mamba extends earlier state space models (SSMs) by introducing\ninput-dependent dynamics, and has demonstrated strong empirical performance\nacross a range of domains, including language modeling, computer vision, and\nfoundation models. However, a surprising weakness remains: despite being built\non architectures designed for long-range dependencies, Mamba performs poorly on\nlong-range sequential tasks. Understanding and addressing this gap is important\nfor improving Mamba's universality and versatility. In this work, we analyze\nMamba's limitations through three perspectives: expressiveness, inductive bias,\nand training stability. Our theoretical results show how Mamba falls short in\neach of these aspects compared to earlier SSMs such as S4D. To address these\nissues, we propose $\\text{B}_2\\text{S}_6$, a simple extension of Mamba's S6\nunit that combines block-wise selective dynamics with a channel-specific bias.\nWe prove that these changes equip the model with a better-suited inductive bias\nand improve its expressiveness and stability. Empirically,\n$\\text{B}_2\\text{S}_6$ outperforms S4 and S4D on Long-Range Arena (LRA) tasks\nwhile maintaining Mamba's performance on language modeling benchmarks."}
{"id": "2505.09073", "pdf": "https://arxiv.org/pdf/2505.09073", "abs": "https://arxiv.org/abs/2505.09073", "authors": ["J. Brennan Peace", "Shuowen Hu", "Benjamin S. Riggan"], "title": "2D-3D Attention and Entropy for Pose Robust 2D Facial Recognition", "categories": ["cs.CV"], "comment": "To appear at the IEEE International Conference on Automatic Face and\n  Gesture 2025 (FG2025)", "summary": "Despite recent advances in facial recognition, there remains a fundamental\nissue concerning degradations in performance due to substantial perspective\n(pose) differences between enrollment and query (probe) imagery. Therefore, we\npropose a novel domain adaptive framework to facilitate improved performances\nacross large discrepancies in pose by enabling image-based (2D) representations\nto infer properties of inherently pose invariant point cloud (3D)\nrepresentations. Specifically, our proposed framework achieves better pose\ninvariance by using (1) a shared (joint) attention mapping to emphasize common\npatterns that are most correlated between 2D facial images and 3D facial data\nand (2) a joint entropy regularizing loss to promote better\nconsistency$\\unicode{x2014}$enhancing correlations among the intersecting 2D\nand 3D representations$\\unicode{x2014}$by leveraging both attention maps. This\nframework is evaluated on FaceScape and ARL-VTF datasets, where it outperforms\ncompetitive methods by achieving profile (90$\\unicode{x00b0}$$\\unicode{x002b}$)\nTAR @ 1$\\unicode{x0025}$ FAR improvements of at least 7.1$\\unicode{x0025}$ and\n1.57$\\unicode{x0025}$, respectively."}
{"id": "2505.08910", "pdf": "https://arxiv.org/pdf/2505.08910", "abs": "https://arxiv.org/abs/2505.08910", "authors": ["Nahid Alam", "Karthik Reddy Kanjula", "Surya Guthikonda", "Timothy Chung", "Bala Krishna S Vegesna", "Abhipsha Das", "Anthony Susevski", "Ryan Sze-Yin Chan", "S M Iftekhar Uddin", "Shayekh Bin Islam", "Roshan Santhosh", "Snegha A", "Drishti Sharma", "Chen Liu", "Isha Chaturvedi", "Genta Indra Winata", "Ashvanth. S", "Snehanshu Mukherjee", "Alham Fikri Aji"], "title": "Behind Maya: Building a Multilingual Vision Language Model", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted at VLM4ALL CVPR 2025 Workshop", "summary": "In recent times, we have seen a rapid development of large Vision-Language\nModels (VLMs). They have shown impressive results on academic benchmarks,\nprimarily in widely spoken languages but lack performance on low-resource\nlanguages and varied cultural contexts. To address these limitations, we\nintroduce Maya, an open-source Multilingual VLM. Our contributions are: 1) a\nmultilingual image-text pretraining dataset in eight languages, based on the\nLLaVA pretraining dataset; and 2) a multilingual image-text model supporting\nthese languages, enhancing cultural and linguistic comprehension in\nvision-language tasks. Code available at https://github.com/nahidalam/maya."}
{"id": "2505.08800", "pdf": "https://arxiv.org/pdf/2505.08800", "abs": "https://arxiv.org/abs/2505.08800", "authors": ["Olivia Nocentini", "Marta Lagomarsino", "Gokhan Solak", "Younggeol Cho", "Qiyi Tong", "Marta Lorenzini", "Arash Ajoudani"], "title": "Graph-based Online Monitoring of Train Driver States via Facial and Skeletal Features", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Driver fatigue poses a significant challenge to railway safety, with\ntraditional systems like the dead-man switch offering limited and basic\nalertness checks. This study presents an online behavior-based monitoring\nsystem utilizing a customised Directed-Graph Neural Network (DGNN) to classify\ntrain driver's states into three categories: alert, not alert, and\npathological. To optimize input representations for the model, an ablation\nstudy was performed, comparing three feature configurations: skeletal-only,\nfacial-only, and a combination of both. Experimental results show that\ncombining facial and skeletal features yields the highest accuracy (80.88%) in\nthe three-class model, outperforming models using only facial or skeletal\nfeatures. Furthermore, this combination achieves over 99% accuracy in the\nbinary alertness classification. Additionally, we introduced a novel dataset\nthat, for the first time, incorporates simulated pathological conditions into\ntrain driver monitoring, broadening the scope for assessing risks related to\nfatigue and health. This work represents a step forward in enhancing railway\nsafety through advanced online monitoring using vision-based technologies."}
{"id": "2505.09063", "pdf": "https://arxiv.org/pdf/2505.09063", "abs": "https://arxiv.org/abs/2505.09063", "authors": ["Khalid Rafiq", "Wenjing Liao", "Aditya G. Nair"], "title": "Single-shot prediction of parametric partial differential equations", "categories": ["cs.LG", "cs.NA", "math.NA", "68T07"], "comment": "35 pages, 17 figures", "summary": "We introduce Flexi-VAE, a data-driven framework for efficient single-shot\nforecasting of nonlinear parametric partial differential equations (PDEs),\neliminating the need for iterative time-stepping while maintaining high\naccuracy and stability. Flexi-VAE incorporates a neural propagator that\nadvances latent representations forward in time, aligning latent evolution with\nphysical state reconstruction in a variational autoencoder setting. We evaluate\ntwo propagation strategies, the Direct Concatenation Propagator (DCP) and the\nPositional Encoding Propagator (PEP), and demonstrate, through\nrepresentation-theoretic analysis, that DCP offers superior long-term\ngeneralization by fostering disentangled and physically meaningful latent\nspaces. Geometric diagnostics, including Jacobian spectral analysis, reveal\nthat propagated latent states reside in regions of lower decoder sensitivity\nand more stable local geometry than those derived via direct encoding,\nenhancing robustness for long-horizon predictions. We validate Flexi-VAE on\ncanonical PDE benchmarks, the 1D viscous Burgers equation and the 2D\nadvection-diffusion equation, achieving accurate forecasts across wide\nparametric ranges. The model delivers over 50x CPU and 90x GPU speedups\ncompared to autoencoder-LSTM baselines for large temporal shifts. These results\nposition Flexi-VAE as a scalable and interpretable surrogate modeling tool for\naccelerating high-fidelity simulations in computational fluid dynamics (CFD)\nand other parametric PDE-driven applications, with extensibility to\nhigher-dimensional and more complex systems."}
{"id": "2505.09092", "pdf": "https://arxiv.org/pdf/2505.09092", "abs": "https://arxiv.org/abs/2505.09092", "authors": ["Yuhang Wang", "Abdulaziz Alhuraish", "Shengming Yuan", "Hao Zhou"], "title": "OpenLKA: An Open Dataset of Lane Keeping Assist from Recent Car Models under Real-world Driving Conditions", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Lane Keeping Assist (LKA) is widely adopted in modern vehicles, yet its\nreal-world performance remains underexplored due to proprietary systems and\nlimited data access. This paper presents OpenLKA, the first open, large-scale\ndataset for LKA evaluation and improvement. It includes 400 hours of driving\ndata from 50+ production vehicle models, collected through extensive road\ntesting in Tampa, Florida and global contributions from the Comma.ai driving\ncommunity. The dataset spans a wide range of challenging scenarios, including\ncomplex road geometries, degraded lane markings, adverse weather, lighting\nconditions and surrounding traffic. The dataset is multimodal, comprising: i)\nfull CAN bus streams, decoded using custom reverse-engineered DBC files to\nextract key LKA events (e.g., system disengagements, lane detection failures);\nii) synchronized high-resolution dash-cam video; iii) real-time outputs from\nOpenpilot, providing accurate estimates of road curvature and lane positioning;\niv) enhanced scene annotations generated by Vision Language Models, describing\nlane visibility, pavement quality, weather, lighting, and traffic conditions.\nBy integrating vehicle-internal signals with high-fidelity perception and rich\nsemantic context, OpenLKA provides a comprehensive platform for benchmarking\nthe real-world performance of production LKA systems, identifying\nsafety-critical operational scenarios, and assessing the readiness of current\nroad infrastructure for autonomous driving. The dataset is publicly available\nat: https://github.com/OpenLKA/OpenLKA."}
{"id": "2505.08941", "pdf": "https://arxiv.org/pdf/2505.08941", "abs": "https://arxiv.org/abs/2505.08941", "authors": ["Gavin Hull", "Alex Bihlo"], "title": "ForeCite: Adapting Pre-Trained Language Models to Predict Future Citation Rates of Academic Papers", "categories": ["cs.LG", "cs.CL"], "comment": "16 pages, 13 figures", "summary": "Predicting the future citation rates of academic papers is an important step\ntoward the automation of research evaluation and the acceleration of scientific\nprogress. We present $\\textbf{ForeCite}$, a simple but powerful framework to\nappend pre-trained causal language models with a linear head for average\nmonthly citation rate prediction. Adapting transformers for regression tasks,\nForeCite achieves a test correlation of $\\rho = 0.826$ on a curated dataset of\n900K+ biomedical papers published between 2000 and 2024, a 27-point improvement\nover the previous state-of-the-art. Comprehensive scaling-law analysis reveals\nconsistent gains across model sizes and data volumes, while temporal holdout\nexperiments confirm practical robustness. Gradient-based saliency heatmaps\nsuggest a potentially undue reliance on titles and abstract texts. These\nresults establish a new state-of-the-art in forecasting the long-term influence\nof academic research and lay the groundwork for the automated, high-fidelity\nevaluation of scientific contributions."}
{"id": "2505.08803", "pdf": "https://arxiv.org/pdf/2505.08803", "abs": "https://arxiv.org/abs/2505.08803", "authors": ["Zizhao Hu", "Mohammad Rostami", "Jesse Thomason"], "title": "Multi-modal Synthetic Data Training and Model Collapse: Insights from VLMs and Diffusion Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent research has highlighted the risk of generative model collapse, where\nperformance progressively degrades when continually trained on self-generated\ndata. However, existing exploration on model collapse is limited to single,\nunimodal models, limiting our understanding in more realistic scenarios, such\nas diverse multi-modal AI agents interacting autonomously through synthetic\ndata and continually evolving. We expand the synthetic data training and model\ncollapse study to multi-modal vision-language generative systems, such as\nvision-language models (VLMs) and text-to-image diffusion models, as well as\nrecursive generate-train loops with multiple models. We find that model\ncollapse, previously observed in single-modality generative models, exhibits\ndistinct characteristics in the multi-modal context, such as improved\nvision-language alignment and increased variance in VLM image-captioning task.\nAdditionally, we find that general approaches such as increased decoding\nbudgets, greater model diversity, and relabeling with frozen models can\neffectively mitigate model collapse. Our findings provide initial insights and\npractical guidelines for reducing the risk of model collapse in self-improving\nmulti-agent AI systems and curating robust multi-modal synthetic datasets."}
{"id": "2505.09076", "pdf": "https://arxiv.org/pdf/2505.09076", "abs": "https://arxiv.org/abs/2505.09076", "authors": ["Berkay Guler", "Hamid Jafarkhani"], "title": "AdaFortiTran: An Adaptive Transformer Model for Robust OFDM Channel Estimation", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Deep learning models for channel estimation in Orthogonal Frequency Division\nMultiplexing (OFDM) systems often suffer from performance degradation under\nfast-fading channels and low-SNR scenarios. To address these limitations, we\nintroduce the Adaptive Fortified Transformer (AdaFortiTran), a novel model\nspecifically designed to enhance channel estimation in challenging\nenvironments. Our approach employs convolutional layers that exploit locality\nbias to capture strong correlations between neighboring channel elements,\ncombined with a transformer encoder that applies the global Attention mechanism\nto channel patches. This approach effectively models both long-range\ndependencies and spectro-temporal interactions within single OFDM frames. We\nfurther augment the model's adaptability by integrating nonlinear\nrepresentations of available channel statistics SNR, delay spread, and Doppler\nshift as priors. A residual connection is employed to merge global features\nfrom the transformer with local features from early convolutional processing,\nfollowed by final convolutional layers to refine the hierarchical channel\nrepresentation. Despite its compact architecture, AdaFortiTran achieves up to 6\ndB reduction in mean squared error (MSE) compared to state-of-the-art models.\nTested across a wide range of Doppler shifts (200-1000 Hz), SNRs (0 to 25 dB),\nand delay spreads (50-300 ns), it demonstrates superior robustness in\nhigh-mobility environments."}
{"id": "2505.09118", "pdf": "https://arxiv.org/pdf/2505.09118", "abs": "https://arxiv.org/abs/2505.09118", "authors": ["Dayong Liang", "Changmeng Zheng", "Zhiyuan Wen", "Yi Cai", "Xiao-Yong Wei", "Qing Li"], "title": "Seeing Beyond the Scene: Enhancing Vision-Language Models with Interactional Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Traditional scene graphs primarily focus on spatial relationships, limiting\nvision-language models' (VLMs) ability to reason about complex interactions in\nvisual scenes. This paper addresses two key challenges: (1) conventional\ndetection-to-construction methods produce unfocused, contextually irrelevant\nrelationship sets, and (2) existing approaches fail to form persistent memories\nfor generalizing interaction reasoning to new scenes. We propose\nInteraction-augmented Scene Graph Reasoning (ISGR), a framework that enhances\nVLMs' interactional reasoning through three complementary components. First,\nour dual-stream graph constructor combines SAM-powered spatial relation\nextraction with interaction-aware captioning to generate functionally salient\nscene graphs with spatial grounding. Second, we employ targeted interaction\nqueries to activate VLMs' latent knowledge of object functionalities,\nconverting passive recognition into active reasoning about how objects work\ntogether. Finally, we introduce a lone-term memory reinforcement learning\nstrategy with a specialized interaction-focused reward function that transforms\ntransient patterns into long-term reasoning heuristics. Extensive experiments\ndemonstrate that our approach significantly outperforms baseline methods on\ninteraction-heavy reasoning benchmarks, with particularly strong improvements\non complex scene understanding tasks. The source code can be accessed at\nhttps://github.com/open_upon_acceptance."}
{"id": "2505.08971", "pdf": "https://arxiv.org/pdf/2505.08971", "abs": "https://arxiv.org/abs/2505.08971", "authors": ["Yangyi Chen", "Hao Peng", "Tong Zhang", "Heng Ji"], "title": "Prioritizing Image-Related Tokens Enhances Vision-Language Pre-Training", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "The code will be available at https://github.com/Yangyi-Chen/PRIOR", "summary": "In standard large vision-language models (LVLMs) pre-training, the model\ntypically maximizes the joint probability of the caption conditioned on the\nimage via next-token prediction (NTP); however, since only a small subset of\ncaption tokens directly relates to the visual content, this naive NTP\nunintentionally fits the model to noise and increases the risk of\nhallucination. We present PRIOR, a simple vision-language pre-training approach\nthat addresses this issue by prioritizing image-related tokens through\ndifferential weighting in the NTP loss, drawing from the importance sampling\nframework. PRIOR introduces a reference model-a text-only large language model\n(LLM) trained on the captions without image inputs, to weight each token based\non its probability for LVLMs training. Intuitively, tokens that are directly\nrelated to the visual inputs are harder to predict without the image and thus\nreceive lower probabilities from the text-only reference LLM. During training,\nwe implement a token-specific re-weighting term based on the importance scores\nto adjust each token's loss. We implement PRIOR in two distinct settings: LVLMs\nwith visual encoders and LVLMs without visual encoders. We observe 19% and 8%\naverage relative improvement, respectively, on several vision-language\nbenchmarks compared to NTP. In addition, PRIOR exhibits superior scaling\nproperties, as demonstrated by significantly higher scaling coefficients,\nindicating greater potential for performance gains compared to NTP given\nincreasing compute and data."}
{"id": "2505.08807", "pdf": "https://arxiv.org/pdf/2505.08807", "abs": "https://arxiv.org/abs/2505.08807", "authors": ["Yuntao Wang", "Yanghe Pan", "Shaolong Guo", "Zhou Su"], "title": "Security of Internet of Agents: Attacks and Countermeasures", "categories": ["cs.CR", "cs.AI"], "comment": "11 pages, 5 figures, 3 tables, submitted to IEEE OJCS", "summary": "With the rise of large language and vision-language models, AI agents have\nevolved into autonomous, interactive systems capable of perception, reasoning,\nand decision-making. As they proliferate across virtual and physical domains,\nthe Internet of Agents (IoA) has emerged as a key infrastructure for enabling\nscalable and secure coordination among heterogeneous agents. This survey offers\na comprehensive examination of the security and privacy landscape in IoA\nsystems. We begin by outlining the IoA architecture and its distinct\nvulnerabilities compared to traditional networks, focusing on four critical\naspects: identity authentication threats, cross-agent trust issues, embodied\nsecurity, and privacy risks. We then review existing and emerging defense\nmechanisms and highlight persistent challenges. Finally, we identify open\nresearch directions to advance the development of resilient and\nprivacy-preserving IoA ecosystems."}
{"id": "2505.09085", "pdf": "https://arxiv.org/pdf/2505.09085", "abs": "https://arxiv.org/abs/2505.09085", "authors": ["Jiaxuan Chen", "Yu Qi", "Yueming Wang", "Gang Pan"], "title": "Human-like Cognitive Generalization for Large Models via Brain-in-the-loop Supervision", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advancements in deep neural networks (DNNs), particularly large-scale\nlanguage models, have demonstrated remarkable capabilities in image and natural\nlanguage understanding. Although scaling up model parameters with increasing\nvolume of training data has progressively improved DNN capabilities, achieving\ncomplex cognitive abilities - such as understanding abstract concepts,\nreasoning, and adapting to novel scenarios, which are intrinsic to human\ncognition - remains a major challenge. In this study, we show that\nbrain-in-the-loop supervised learning, utilizing a small set of brain signals,\ncan effectively transfer human conceptual structures to DNNs, significantly\nenhancing their comprehension of abstract and even unseen concepts.\nExperimental results further indicate that the enhanced cognitive capabilities\nlead to substantial performance gains in challenging tasks, including\nfew-shot/zero-shot learning and out-of-distribution recognition, while also\nyielding highly interpretable concept representations. These findings highlight\nthat human-in-the-loop supervision can effectively augment the complex\ncognitive abilities of large models, offering a promising pathway toward\ndeveloping more human-like cognitive abilities in artificial systems."}
{"id": "2505.09123", "pdf": "https://arxiv.org/pdf/2505.09123", "abs": "https://arxiv.org/abs/2505.09123", "authors": ["Guoying Liang", "Su Yang"], "title": "Promoting SAM for Camouflaged Object Detection via Selective Key Point-based Guidance", "categories": ["cs.CV"], "comment": null, "summary": "Big model has emerged as a new research paradigm that can be applied to\nvarious down-stream tasks with only minor effort for domain adaption.\nCorrespondingly, this study tackles Camouflaged Object Detection (COD)\nleveraging the Segment Anything Model (SAM). The previous studies declared that\nSAM is not workable for COD but this study reveals that SAM works if promoted\nproperly, for which we devise a new framework to render point promotions:\nFirst, we develop the Promotion Point Targeting Network (PPT-net) to leverage\nmulti-scale features in predicting the probabilities of camouflaged objects'\npresences at given candidate points over the image. Then, we develop a key\npoint selection (KPS) algorithm to deploy both positive and negative point\npromotions contrastively to SAM to guide the segmentation. It is the first work\nto facilitate big model for COD and achieves plausible results experimentally\nover the existing methods on 3 data sets under 6 metrics. This study\ndemonstrates an off-the-shelf methodology for COD by leveraging SAM, which\ngains advantage over designing professional models from scratch, not only in\nperformance, but also in turning the problem to a less challenging task, that\nis, seeking informative but not exactly precise promotions."}
{"id": "2505.09024", "pdf": "https://arxiv.org/pdf/2505.09024", "abs": "https://arxiv.org/abs/2505.09024", "authors": ["Aaron Baughman", "Rahul Agarwal", "Eduardo Morales", "Gozde Akay"], "title": "Automated Meta Prompt Engineering for Alignment with the Theory of Mind", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "9 pages, 6 figures, 3 tables", "summary": "We introduce a method of meta-prompting that jointly produces fluent text for\ncomplex tasks while optimizing the similarity of neural states between a\nhuman's mental expectation and a Large Language Model's (LLM) neural\nprocessing. A technique of agentic reinforcement learning is applied, in which\nan LLM as a Judge (LLMaaJ) teaches another LLM, through in-context learning,\nhow to produce content by interpreting the intended and unintended generated\ntext traits. To measure human mental beliefs around content production, users\nmodify long form AI-generated text articles before publication at the US Open\n2024 tennis Grand Slam. Now, an LLMaaJ can solve the Theory of Mind (ToM)\nalignment problem by anticipating and including human edits within the creation\nof text from an LLM. Throughout experimentation and by interpreting the results\nof a live production system, the expectations of human content reviewers had\n100% of alignment with AI 53.8% of the time with an average iteration count of\n4.38. The geometric interpretation of content traits such as factualness,\nnovelty, repetitiveness, and relevancy over a Hilbert vector space combines\nspatial volume (all trait importance) with vertices alignment (individual trait\nrelevance) enabled the LLMaaJ to optimize on Human ToM. This resulted in an\nincrease in content quality by extending the coverage of tennis action. Our\nwork that was deployed at the US Open 2024 has been used across other live\nevents within sports and entertainment."}
{"id": "2505.08808", "pdf": "https://arxiv.org/pdf/2505.08808", "abs": "https://arxiv.org/abs/2505.08808", "authors": ["Anqing Jiang", "Jinhao Chai", "Yu Gao", "Yiru Wang", "Yuwen Heng", "Zhigang Sun", "Hao Sun", "Zezhong Zhao", "Li Sun", "Jian Zhou", "Lijuan Zhu", "Shugong Xu", "Hao Zhao"], "title": "SparseMeXT Unlocking the Potential of Sparse Representations for HD Map Construction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advancements in high-definition \\emph{HD} map construction have\ndemonstrated the effectiveness of dense representations, which heavily rely on\ncomputationally intensive bird's-eye view \\emph{BEV} features. While sparse\nrepresentations offer a more efficient alternative by avoiding dense BEV\nprocessing, existing methods often lag behind due to the lack of tailored\ndesigns. These limitations have hindered the competitiveness of sparse\nrepresentations in online HD map construction. In this work, we systematically\nrevisit and enhance sparse representation techniques, identifying key\narchitectural and algorithmic improvements that bridge the gap with--and\nultimately surpass--dense approaches. We introduce a dedicated network\narchitecture optimized for sparse map feature extraction, a sparse-dense\nsegmentation auxiliary task to better leverage geometric and semantic cues, and\na denoising module guided by physical priors to refine predictions. Through\nthese enhancements, our method achieves state-of-the-art performance on the\nnuScenes dataset, significantly advancing HD map construction and centerline\ndetection. Specifically, SparseMeXt-Tiny reaches a mean average precision\n\\emph{mAP} of 55.5% at 32 frames per second \\emph{fps}, while SparseMeXt-Base\nattains 65.2% mAP. Scaling the backbone and decoder further, SparseMeXt-Large\nachieves an mAP of 68.9% at over 20 fps, establishing a new benchmark for\nsparse representations in HD map construction. These results underscore the\nuntapped potential of sparse methods, challenging the conventional reliance on\ndense representations and redefining efficiency-performance trade-offs in the\nfield."}
{"id": "2505.09089", "pdf": "https://arxiv.org/pdf/2505.09089", "abs": "https://arxiv.org/abs/2505.09089", "authors": ["Philipp Hess", "Maximilian Gelbrecht", "Christof Schötz", "Michael Aich", "Yu Huang", "Shangshang Yang", "Niklas Boers"], "title": "Generating time-consistent dynamics with discriminator-guided image diffusion models", "categories": ["cs.LG"], "comment": null, "summary": "Realistic temporal dynamics are crucial for many video generation, processing\nand modelling applications, e.g. in computational fluid dynamics, weather\nprediction, or long-term climate simulations. Video diffusion models (VDMs) are\nthe current state-of-the-art method for generating highly realistic dynamics.\nHowever, training VDMs from scratch can be challenging and requires large\ncomputational resources, limiting their wider application. Here, we propose a\ntime-consistency discriminator that enables pretrained image diffusion models\nto generate realistic spatiotemporal dynamics. The discriminator guides the\nsampling inference process and does not require extensions or finetuning of the\nimage diffusion model. We compare our approach against a VDM trained from\nscratch on an idealized turbulence simulation and a real-world global\nprecipitation dataset. Our approach performs equally well in terms of temporal\nconsistency, shows improved uncertainty calibration and lower biases compared\nto the VDM, and achieves stable centennial-scale climate simulations at daily\ntime steps."}
{"id": "2505.09129", "pdf": "https://arxiv.org/pdf/2505.09129", "abs": "https://arxiv.org/abs/2505.09129", "authors": ["Wei Meng"], "title": "WSCIF: A Weakly-Supervised Color Intelligence Framework for Tactical Anomaly Detection in Surveillance Keyframes", "categories": ["cs.CV", "cs.AI", "es: 68T10, 68T05, 62H35, 68U10", "I.4.9; I.5.1; I.2.10"], "comment": "17 pages, 3 figures, 3 tables. The paper proposes a lightweight\n  weakly-supervised color intelligence model for tactical video anomaly\n  detection, tested on anonymized African surveillance data", "summary": "The deployment of traditional deep learning models in high-risk security\ntasks in an unlabeled, data-non-exploitable video intelligence environment\nfaces significant challenges. In this paper, we propose a lightweight anomaly\ndetection framework based on color features for surveillance video clips in a\nhigh sensitivity tactical mission, aiming to quickly identify and interpret\npotential threat events under resource-constrained and data-sensitive\nconditions. The method fuses unsupervised KMeans clustering with RGB channel\nhistogram modeling to achieve composite detection of structural anomalies and\ncolor mutation signals in key frames. The experiment takes an operation\nsurveillance video occurring in an African country as a research sample, and\nsuccessfully identifies multiple highly anomalous frames related to high-energy\nlight sources, target presence, and reflective interference under the condition\nof no access to the original data. The results show that this method can be\neffectively used for tactical assassination warning, suspicious object\nscreening and environmental drastic change monitoring with strong deployability\nand tactical interpretation value. The study emphasizes the importance of color\nfeatures as low semantic battlefield signal carriers, and its battlefield\nintelligent perception capability will be further extended by combining graph\nneural networks and temporal modeling in the future."}
{"id": "2505.09031", "pdf": "https://arxiv.org/pdf/2505.09031", "abs": "https://arxiv.org/abs/2505.09031", "authors": ["Adarsh Kumar", "Hwiyoon Kim", "Jawahar Sai Nathani", "Neil Roy"], "title": "Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Hallucination, where large language models (LLMs) generate confident but\nincorrect or irrelevant information, remains a key limitation in their\napplication to complex, open-ended tasks. Chain-of-thought (CoT) prompting has\nemerged as a promising method for improving multistep reasoning by guiding\nmodels through intermediate steps. However, CoT alone does not fully address\nthe hallucination problem. In this work, we investigate how combining CoT with\nretrieval-augmented generation (RAG), as well as applying self-consistency and\nself-verification strategies, can reduce hallucinations and improve factual\naccuracy. By incorporating external knowledge sources during reasoning and\nenabling models to verify or revise their own outputs, we aim to generate more\naccurate and coherent responses. We present a comparative evaluation of\nbaseline LLMs against CoT, CoT+RAG, self-consistency, and self-verification\ntechniques. Our results highlight the effectiveness of each method and identify\nthe most robust approach for minimizing hallucinations while preserving fluency\nand reasoning depth."}
{"id": "2505.08809", "pdf": "https://arxiv.org/pdf/2505.08809", "abs": "https://arxiv.org/abs/2505.08809", "authors": ["Shixi Qin", "Zhiyong Yang", "Shilong Bao", "Shi Wang", "Qianqian Xu", "Qingming Huang"], "title": "MixBridge: Heterogeneous Image-to-Image Backdoor Attack through Mixture of Schrödinger Bridges", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "This paper focuses on implanting multiple heterogeneous backdoor triggers in\nbridge-based diffusion models designed for complex and arbitrary input\ndistributions. Existing backdoor formulations mainly address single-attack\nscenarios and are limited to Gaussian noise input models. To fill this gap, we\npropose MixBridge, a novel diffusion Schr\\\"odinger bridge (DSB) framework to\ncater to arbitrary input distributions (taking I2I tasks as special cases).\nBeyond this trait, we demonstrate that backdoor triggers can be injected into\nMixBridge by directly training with poisoned image pairs. This eliminates the\nneed for the cumbersome modifications to stochastic differential equations\nrequired in previous studies, providing a flexible tool to study backdoor\nbehavior for bridge models. However, a key question arises: can a single DSB\nmodel train multiple backdoor triggers? Unfortunately, our theory shows that\nwhen attempting this, the model ends up following the geometric mean of benign\nand backdoored distributions, leading to performance conflict across backdoor\ntasks. To overcome this, we propose a Divide-and-Merge strategy to mix\ndifferent bridges, where models are independently pre-trained for each specific\nobjective (Divide) and then integrated into a unified model (Merge). In\naddition, a Weight Reallocation Scheme (WRS) is also designed to enhance the\nstealthiness of MixBridge. Empirical studies across diverse generation tasks\nspeak to the efficacy of MixBridge."}
{"id": "2505.09106", "pdf": "https://arxiv.org/pdf/2505.09106", "abs": "https://arxiv.org/abs/2505.09106", "authors": ["Ya Liu", "Kai Yang", "Yu Zhu", "Keying Yang", "Haibo Zhao"], "title": "Argus: Federated Non-convex Bilevel Learning over 6G Space-Air-Ground Integrated Network", "categories": ["cs.LG", "68T07", "I.2"], "comment": "17 pages, 11 figures", "summary": "The space-air-ground integrated network (SAGIN) has recently emerged as a\ncore element in the 6G networks. However, traditional centralized and\nsynchronous optimization algorithms are unsuitable for SAGIN due to\ninfrastructureless and time-varying environments. This paper aims to develop a\nnovel Asynchronous algorithm a.k.a. Argus for tackling non-convex and\nnon-smooth decentralized federated bilevel learning over SAGIN. The proposed\nalgorithm allows networked agents (e.g. autonomous aerial vehicles) to tackle\nbilevel learning problems in time-varying networks asynchronously, thereby\naverting stragglers from impeding the overall training speed. We provide a\ntheoretical analysis of the iteration complexity, communication complexity, and\ncomputational complexity of Argus. Its effectiveness is further demonstrated\nthrough numerical experiments."}
{"id": "2505.09139", "pdf": "https://arxiv.org/pdf/2505.09139", "abs": "https://arxiv.org/abs/2505.09139", "authors": ["Lucas Choi", "Ross Greer"], "title": "Beyond General Prompts: Automated Prompt Refinement using Contrastive Class Alignment Scores for Disambiguating Objects in Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) offer flexible object detection through natural\nlanguage prompts but suffer from performance variability depending on prompt\nphrasing. In this paper, we introduce a method for automated prompt refinement\nusing a novel metric called the Contrastive Class Alignment Score (CCAS), which\nranks prompts based on their semantic alignment with a target object class\nwhile penalizing similarity to confounding classes. Our method generates\ndiverse prompt candidates via a large language model and filters them through\nCCAS, computed using prompt embeddings from a sentence transformer. We evaluate\nour approach on challenging object categories, demonstrating that our automatic\nselection of high-precision prompts improves object detection accuracy without\nthe need for additional model training or labeled data. This scalable and\nmodel-agnostic pipeline offers a principled alternative to manual prompt\nengineering for VLM-based detection systems."}
{"id": "2505.09083", "pdf": "https://arxiv.org/pdf/2505.09083", "abs": "https://arxiv.org/abs/2505.09083", "authors": ["Dominic Zaun Eu Jones"], "title": "Ornithologist: Towards Trustworthy \"Reasoning\" about Central Bank Communications", "categories": ["econ.GN", "cs.CL", "q-fin.EC", "J.4; I.2.7"], "comment": "16 pages, 6 figures", "summary": "I develop Ornithologist, a weakly-supervised textual classification system\nand measure the hawkishness and dovishness of central bank text. Ornithologist\nuses ``taxonomy-guided reasoning'', guiding a large language model with\nhuman-authored decision trees. This increases the transparency and\nexplainability of the system and makes it accessible to non-experts. It also\nreduces hallucination risk. Since it requires less supervision than traditional\nclassification systems, it can more easily be applied to other problems or\nsources of text (e.g. news) without much modification. Ornithologist\nmeasurements of hawkishness and dovishness of RBA communication carry\ninformation about the future of the cash rate path and of market expectations."}
{"id": "2505.08810", "pdf": "https://arxiv.org/pdf/2505.08810", "abs": "https://arxiv.org/abs/2505.08810", "authors": ["Bappa Muktar", "Vincent Fono", "Adama Nouboukpo"], "title": "Machine Learning-Based Detection of DDoS Attacks in VANETs for Emergency Vehicle Communication", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Vehicular Ad Hoc Networks (VANETs) play a key role in Intelligent\nTransportation Systems (ITS), particularly in enabling real-time communication\nfor emergency vehicles. However, Distributed Denial of Service (DDoS) attacks,\nwhich interfere with safety-critical communication channels, can severely\nimpair their reliability. This study introduces a robust and scalable framework\nto detect DDoS attacks in highway-based VANET environments. A synthetic dataset\nwas constructed using Network Simulator 3 (NS-3) in conjunction with the\nSimulation of Urban Mobility (SUMO) and further enriched with real-world\nmobility traces from Germany's A81 highway, extracted via OpenStreetMap (OSM).\nThree traffic categories were simulated: DDoS, VoIP, and TCP-based video\nstreaming (VideoTCP). The data preprocessing pipeline included normalization,\nsignal-to-noise ratio (SNR) feature engineering, missing value imputation, and\nclass balancing using the Synthetic Minority Over-sampling Technique (SMOTE).\nFeature importance was assessed using SHapley Additive exPlanations (SHAP).\nEleven classifiers were benchmarked, among them XGBoost (XGB), CatBoost (CB),\nAdaBoost (AB), GradientBoosting (GB), and an Artificial Neural Network (ANN).\nXGB and CB achieved the best performance, each attaining an F1-score of 96%.\nThese results highlight the robustness of the proposed framework and its\npotential for real-time deployment in VANETs to secure critical emergency\ncommunications."}
{"id": "2505.09113", "pdf": "https://arxiv.org/pdf/2505.09113", "abs": "https://arxiv.org/abs/2505.09113", "authors": ["Yingrong Wang", "Anpeng Wu", "Baohong Li", "Ziyang Xiao", "Ruoxuan Xiong", "Qing Han", "Kun Kuang"], "title": "Sequential Treatment Effect Estimation with Unmeasured Confounders", "categories": ["cs.LG", "stat.ME"], "comment": null, "summary": "This paper studies the cumulative causal effects of sequential treatments in\nthe presence of unmeasured confounders. It is a critical issue in sequential\ndecision-making scenarios where treatment decisions and outcomes dynamically\nevolve over time. Advanced causal methods apply transformer as a backbone to\nmodel such time sequences, which shows superiority in capturing long time\ndependence and periodic patterns via attention mechanism. However, even they\ncontrol the observed confounding, these estimators still suffer from unmeasured\nconfounders, which influence both treatment assignments and outcomes. How to\nadjust the latent confounding bias in sequential treatment effect estimation\nremains an open challenge. Therefore, we propose a novel Decomposing Sequential\nInstrumental Variable framework for CounterFactual Regression (DSIV-CFR),\nrelying on a common negative control assumption. Specifically, an instrumental\nvariable (IV) is a special negative control exposure, while the previous\noutcome serves as a negative control outcome. This allows us to recover the IVs\nlatent in observation variables and estimate sequential treatment effects via a\ngeneralized moment condition. We conducted experiments on 4 datasets and\nachieved significant performance in one- and multi-step prediction, supported\nby which we can identify optimal treatments for dynamic systems."}
{"id": "2505.09140", "pdf": "https://arxiv.org/pdf/2505.09140", "abs": "https://arxiv.org/abs/2505.09140", "authors": ["Zechao Guan", "Feng Yan", "Shuai Du", "Lin Ma", "Qingshan Liu"], "title": "TopoDiT-3D: Topology-Aware Diffusion Transformer with Bottleneck Structure for 3D Point Cloud Generation", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in Diffusion Transformer (DiT) models have significantly\nimproved 3D point cloud generation. However, existing methods primarily focus\non local feature extraction while overlooking global topological information,\nsuch as voids, which are crucial for maintaining shape consistency and\ncapturing complex geometries. To address this limitation, we propose\nTopoDiT-3D, a Topology-Aware Diffusion Transformer with a bottleneck structure\nfor 3D point cloud generation. Specifically, we design the bottleneck structure\nutilizing Perceiver Resampler, which not only offers a mode to integrate\ntopological information extracted through persistent homology into feature\nlearning, but also adaptively filters out redundant local features to improve\ntraining efficiency. Experimental results demonstrate that TopoDiT-3D\noutperforms state-of-the-art models in visual quality, diversity, and training\nefficiency. Furthermore, TopoDiT-3D demonstrates the importance of rich\ntopological information for 3D point cloud generation and its synergy with\nconventional local feature learning. Videos and code are available at\nhttps://github.com/Zechao-Guan/TopoDiT-3D."}
{"id": "2505.09246", "pdf": "https://arxiv.org/pdf/2505.09246", "abs": "https://arxiv.org/abs/2505.09246", "authors": ["Derian Boer", "Stephen Roth", "Stefan Kramer"], "title": "Focus, Merge, Rank: Improved Question Answering Based on Semi-structured Knowledge Bases", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "In many real-world settings, machine learning models and interactive systems\nhave access to both structured knowledge, e.g., knowledge graphs or tables, and\nunstructured content, e.g., natural language documents. However, most rely on\neither. Semi-Structured Knowledge Bases (SKBs) bridge this gap by linking\nunstructured content to nodes within structured data, thereby enabling new\nstrategies for knowledge access and use. In this work, we present\nFocusedRetriever, a modular SKB-based framework for multi-hop question\nanswering. It integrates components (VSS-based entity search, LLM-based\ngeneration of Cypher queries and pairwise re-ranking) in a way that enables it\nto outperform state-of-the-art methods across all three STaRK benchmark test\nsets, covering diverse domains and multiple performance metrics. The average\nfirst-hit rate exceeds that of the second-best method by 25.7%.\nFocusedRetriever leverages (1) the capacity of Large Language Models (LLMs) to\nextract relational facts and entity attributes from unstructured text, (2) node\nset joins to filter answer candidates based on these extracted triplets and\nconstraints, (3) vector similarity search to retrieve and rank relevant\nunstructured content, and (4) the contextual capabilities of LLMs to finally\nrank the top-k answers. For generality, we only incorporate base LLMs in\nFocusedRetriever in our evaluation. However, our analysis of intermediate\nresults highlights several opportunities for further upgrades including\nfinetuning. The source code is publicly available at\nhttps://github.com/kramerlab/FocusedRetriever ."}
{"id": "2505.08814", "pdf": "https://arxiv.org/pdf/2505.08814", "abs": "https://arxiv.org/abs/2505.08814", "authors": ["Wenkai Li", "Xiaoqi Li", "Yingjie Mao", "Yishun Wang"], "title": "Towards Understanding Deep Learning Model in Image Recognition via Coverage Test", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep neural networks (DNNs) play a crucial role in the field of artificial\nintelligence, and their security-related testing has been a prominent research\nfocus. By inputting test cases, the behavior of models is examined for\nanomalies, and coverage metrics are utilized to determine the extent of neurons\ncovered by these test cases. With the widespread application and advancement of\nDNNs, different types of neural behaviors have garnered attention, leading to\nthe emergence of various coverage metrics for neural networks. However, there\nis currently a lack of empirical research on these coverage metrics,\nspecifically in analyzing the relationships and patterns between model depth,\nconfiguration information, and neural network coverage. This paper aims to\ninvestigate the relationships and patterns of four coverage metrics: primary\nfunctionality, boundary, hierarchy, and structural coverage. A series of\nempirical experiments were conducted, selecting LeNet, VGG, and ResNet as\ndifferent DNN architectures, along with 10 models of varying depths ranging\nfrom 5 to 54 layers, to compare and study the relationships between different\ndepths, configuration information, and various neural network coverage metrics.\nAdditionally, an investigation was carried out on the relationships between\nmodified decision/condition coverage and dataset size. Finally, three potential\nfuture directions are proposed to further contribute to the security testing of\nDNN Models."}
{"id": "2505.09131", "pdf": "https://arxiv.org/pdf/2505.09131", "abs": "https://arxiv.org/abs/2505.09131", "authors": ["Kunwoong Kim", "Jihu Lee", "Sangchul Park", "Yongdai Kim"], "title": "Fair Clustering via Alignment", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at ICML 2025. This is the version submitted for review and\n  will be replaced by the camera-ready version soon", "summary": "Algorithmic fairness in clustering aims to balance the proportions of\ninstances assigned to each cluster with respect to a given sensitive attribute.\nWhile recently developed fair clustering algorithms optimize clustering\nobjectives under specific fairness constraints, their inherent complexity or\napproximation often results in suboptimal clustering utility or numerical\ninstability in practice. To resolve these limitations, we propose a new fair\nclustering algorithm based on a novel decomposition of the fair K-means\nclustering objective function. The proposed algorithm, called Fair Clustering\nvia Alignment (FCA), operates by alternately (i) finding a joint probability\ndistribution to align the data from different protected groups, and (ii)\noptimizing cluster centers in the aligned space. A key advantage of FCA is that\nit theoretically guarantees approximately optimal clustering utility for any\ngiven fairness level without complex constraints, thereby enabling high-utility\nfair clustering in practice. Experiments show that FCA outperforms existing\nmethods by (i) attaining a superior trade-off between fairness level and\nclustering utility, and (ii) achieving near-perfect fairness without numerical\ninstability."}
{"id": "2505.09155", "pdf": "https://arxiv.org/pdf/2505.09155", "abs": "https://arxiv.org/abs/2505.09155", "authors": ["Yichen Shi", "Zhuofu Tao", "Yuhao Gao", "Li Huang", "Hongyang Wang", "Zhiping Yu", "Ting-Jung Lin", "Lei He"], "title": "AMSnet 2.0: A Large AMS Database with AI Segmentation for Net Detection", "categories": ["cs.CV"], "comment": "accepted by LAD25", "summary": "Current multimodal large language models (MLLMs) struggle to understand\ncircuit schematics due to their limited recognition capabilities. This could be\nattributed to the lack of high-quality schematic-netlist training data.\nExisting work such as AMSnet applies schematic parsing to generate netlists.\nHowever, these methods rely on hard-coded heuristics and are difficult to apply\nto complex or noisy schematics in this paper. We therefore propose a novel net\ndetection mechanism based on segmentation with high robustness. The proposed\nmethod also recovers positional information, allowing digital reconstruction of\nschematics. We then expand AMSnet dataset with schematic images from various\nsources and create AMSnet 2.0. AMSnet 2.0 contains 2,686 circuits with\nschematic images, Spectre-formatted netlists, OpenAccess digital schematics,\nand positional information for circuit components and nets, whereas AMSnet only\nincludes 792 circuits with SPICE netlists but no digital schematics."}
{"id": "2505.09436", "pdf": "https://arxiv.org/pdf/2505.09436", "abs": "https://arxiv.org/abs/2505.09436", "authors": ["Raghav Garg", "Kapil Sharma", "Karan Gupta"], "title": "CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "comment": null, "summary": "Large Language Models (LLMs) hold immense potential for revolutionizing\nCustomer Experience Management (CXM), particularly in contact center\noperations. However, evaluating their practical utility in complex operational\nenvironments is hindered by data scarcity (due to privacy concerns) and the\nlimitations of current benchmarks. Existing benchmarks often lack realism,\nfailing to incorporate deep knowledge base (KB) integration, real-world noise,\nor critical operational tasks beyond conversational fluency. To bridge this\ngap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset\nspecifically designed for evaluating AI in operational CXM contexts. Given the\ndiversity in possible contact center features, we have developed a scalable\nLLM-powered pipeline that simulates the brand's CXM entities that form the\nfoundation of our datasets-such as knowledge articles including product\nspecifications, issue taxonomies, and contact center conversations. The\nentities closely represent real-world distribution because of controlled noise\ninjection (informed by domain experts) and rigorous automated validation.\nBuilding on this, we release CXMArena, which provides dedicated benchmarks\ntargeting five important operational tasks: Knowledge Base Refinement, Intent\nPrediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with\nIntegrated Tools. Our baseline experiments underscore the benchmark's\ndifficulty: even state of the art embedding and generation models achieve only\n68% accuracy on article search, while standard embedding methods yield a low F1\nscore of 0.3 for knowledge base refinement, highlighting significant challenges\nfor current models necessitating complex pipelines and solutions over\nconventional techniques."}
{"id": "2505.08818", "pdf": "https://arxiv.org/pdf/2505.08818", "abs": "https://arxiv.org/abs/2505.08818", "authors": ["Amara Tariq", "Rimita Lahiri", "Charles Kahn", "Imon Banerjee"], "title": "Position: Restructuring of Categories and Implementation of Guidelines Essential for VLM Adoption in Healthcare", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "15 pages, 2, tables, 3 figures", "summary": "The intricate and multifaceted nature of vision language model (VLM)\ndevelopment, adaptation, and application necessitates the establishment of\nclear and standardized reporting protocols, particularly within the high-stakes\ncontext of healthcare. Defining these reporting standards is inherently\nchallenging due to the diverse nature of studies involving VLMs, which vary\nsignificantly from the development of all new VLMs or finetuning for domain\nalignment to off-the-shelf use of VLM for targeted diagnosis and prediction\ntasks. In this position paper, we argue that traditional machine learning\nreporting standards and evaluation guidelines must be restructured to\naccommodate multiphase VLM studies; it also has to be organized for intuitive\nunderstanding of developers while maintaining rigorous standards for\nreproducibility. To facilitate community adoption, we propose a categorization\nframework for VLM studies and outline corresponding reporting standards that\ncomprehensively address performance evaluation, data reporting protocols, and\nrecommendations for manuscript composition. These guidelines are organized\naccording to the proposed categorization scheme. Lastly, we present a checklist\nthat consolidates reporting standards, offering a standardized tool to ensure\nconsistency and quality in the publication of VLM-related research."}
{"id": "2505.09134", "pdf": "https://arxiv.org/pdf/2505.09134", "abs": "https://arxiv.org/abs/2505.09134", "authors": ["Daniel Huang"], "title": "Scaling Gaussian Process Regression with Full Derivative Observations", "categories": ["cs.LG", "stat.ML"], "comment": "12 pages", "summary": "We present a scalable Gaussian Process (GP) method that can fit and predict\nfull derivative observations called DSoftKI. It extends SoftKI, a method that\napproximates a kernel via softmax interpolation from learned interpolation\npoint locations, to the setting with derivatives. DSoftKI enhances SoftKI's\ninterpolation scheme to incorporate the directional orientation of\ninterpolation points relative to the data. This enables the construction of a\nscalable approximate kernel, including its first and second-order derivatives,\nthrough interpolation. We evaluate DSoftKI on a synthetic function benchmark\nand high-dimensional molecular force field prediction (100-1000 dimensions),\ndemonstrating that DSoftKI is accurate and can scale to larger datasets with\nfull derivative observations than previously possible."}
{"id": "2505.09168", "pdf": "https://arxiv.org/pdf/2505.09168", "abs": "https://arxiv.org/abs/2505.09168", "authors": ["Jianlin Sun", "Xiaolin Fang", "Juwei Guan", "Dongdong Gui", "Teqi Wang", "Tongxin Zhu"], "title": "DRRNet: Macro-Micro Feature Fusion and Dual Reverse Refinement for Camouflaged Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The core challenge in Camouflage Object Detection (COD) lies in the\nindistinguishable similarity between targets and backgrounds in terms of color,\ntexture, and shape. This causes existing methods to either lose edge details\n(such as hair-like fine structures) due to over-reliance on global semantic\ninformation or be disturbed by similar backgrounds (such as vegetation\npatterns) when relying solely on local features. We propose DRRNet, a\nfour-stage architecture characterized by a \"context-detail-fusion-refinement\"\npipeline to address these issues. Specifically, we introduce an Omni-Context\nFeature Extraction Module to capture global camouflage patterns and a Local\nDetail Extraction Module to supplement microstructural information for the\nfull-scene context module. We then design a module for forming dual\nrepresentations of scene understanding and structural awareness, which fuses\npanoramic features and local features across various scales. In the decoder, we\nalso introduce a reverse refinement module that leverages spatial edge priors\nand frequency-domain noise suppression to perform a two-stage inverse\nrefinement of the output. By applying two successive rounds of inverse\nrefinement, the model effectively suppresses background interference and\nenhances the continuity of object boundaries. Experimental results demonstrate\nthat DRRNet significantly outperforms state-of-the-art methods on benchmark\ndatasets. Our code is available at https://github.com/jerrySunning/DRRNet."}
{"id": "2505.09610", "pdf": "https://arxiv.org/pdf/2505.09610", "abs": "https://arxiv.org/abs/2505.09610", "authors": ["Nicolas Dupuis", "Ravi Nair", "Shyam Ramji", "Sean McClintock", "Nishant Chauhan", "Priyanka Nagpal", "Bart Blaner", "Ken Valk", "Leon Stok", "Ruchir Puri"], "title": "Customizing a Large Language Model for VHDL Design of High-Performance Microprocessors", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "The use of Large Language Models (LLMs) in hardware design has taken off in\nrecent years, principally through its incorporation in tools that increase chip\ndesigner productivity. There has been considerable discussion about the use of\nLLMs in RTL specifications of chip designs, for which the two most popular\nlanguages are Verilog and VHDL. LLMs and their use in Verilog design has\nreceived significant attention due to the higher popularity of the language,\nbut little attention so far has been given to VHDL despite its continued\npopularity in the industry. There has also been little discussion about the\nunique needs of organizations that engage in high-performance processor design,\nand techniques to deploy AI solutions in these settings. In this paper, we\ndescribe our journey in developing a Large Language Model (LLM) specifically\nfor the purpose of explaining VHDL code, a task that has particular importance\nin an organization with decades of experience and assets in high-performance\nprocessor design. We show how we developed test sets specific to our needs and\nused them for evaluating models as we performed extended pretraining (EPT) of a\nbase LLM. Expert evaluation of the code explanations produced by the EPT model\nincreased to 69% compared to a base model rating of 43%. We further show how we\ndeveloped an LLM-as-a-judge to gauge models similar to expert evaluators. This\nled us to deriving and evaluating a host of new models, including an\ninstruction-tuned version of the EPT model with an expected expert evaluator\nrating of 71%. Our experiments also indicate that with the potential use of\nnewer base models, this rating can be pushed to 85% and beyond. We conclude\nwith a discussion on further improving the quality of hardware design LLMs\nusing exciting new developments in the Generative AI world."}
{"id": "2505.08821", "pdf": "https://arxiv.org/pdf/2505.08821", "abs": "https://arxiv.org/abs/2505.08821", "authors": ["Meryem Altin Karagoz", "Marc D. Breton", "Anas El Fathi"], "title": "A Comparative Study of Transformer-Based Models for Multi-Horizon Blood Glucose Prediction", "categories": ["q-bio.QM", "cs.AI", "stat.AP"], "comment": "7 pages, 2 figures, 1 table, 1st IFAC Workshop on Engineering\n  Diabetes Technologies (EDT 2025)", "summary": "Accurate blood glucose prediction can enable novel interventions for type 1\ndiabetes treatment, including personalized insulin and dietary adjustments.\nAlthough recent advances in transformer-based architectures have demonstrated\nthe power of attention mechanisms in complex multivariate time series\nprediction, their potential for blood glucose (BG) prediction remains\nunderexplored. We present a comparative analysis of transformer models for\nmulti-horizon BG prediction, examining forecasts up to 4 hours and input\nhistory up to 1 week. The publicly available DCLP3 dataset (n=112) was split\n(80%-10%-10%) for training, validation, and testing, and the OhioT1DM dataset\n(n=12) served as an external test set. We trained networks with point-wise,\npatch-wise, series-wise, and hybrid embeddings, using CGM, insulin, and meal\ndata. For short-term blood glucose prediction, Crossformer, a patch-wise\ntransformer architecture, achieved a superior 30-minute prediction of RMSE\n(15.6 mg / dL on OhioT1DM). For longer-term predictions (1h, 2h, and 4h),\nPatchTST, another path-wise transformer, prevailed with the lowest RMSE (24.6\nmg/dL, 36.1 mg/dL, and 46.5 mg/dL on OhioT1DM). In general, models that used\ntokenization through patches demonstrated improved accuracy with larger input\nsizes, with the best results obtained with a one-week history. These findings\nhighlight the promise of transformer-based architectures for BG prediction by\ncapturing and leveraging seasonal patterns in multivariate time-series data to\nimprove accuracy."}
{"id": "2505.09160", "pdf": "https://arxiv.org/pdf/2505.09160", "abs": "https://arxiv.org/abs/2505.09160", "authors": ["Berkay Guler", "Giovanni Geraci", "Hamid Jafarkhani"], "title": "A Multi-Task Foundation Model for Wireless Channel Representation Using Contrastive and Masked Autoencoder Learning", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Current applications of self-supervised learning to wireless channel\nrepresentation often borrow paradigms developed for text and image processing,\nwithout fully addressing the unique characteristics and constraints of wireless\ncommunications. Aiming to fill this gap, we first propose WiMAE (Wireless\nMasked Autoencoder), a transformer-based encoder-decoder foundation model\npretrained on a realistic open-source multi-antenna wireless channel dataset.\nBuilding upon this foundation, we develop ContraWiMAE, which enhances WiMAE by\nincorporating a contrastive learning objective alongside the reconstruction\ntask in a unified multi-task framework. By warm-starting from pretrained WiMAE\nweights and generating positive pairs via noise injection, the contrastive\ncomponent enables the model to capture both structural and discriminative\nfeatures, enhancing representation quality beyond what reconstruction alone can\nachieve. Through extensive evaluation on unseen scenarios, we demonstrate the\neffectiveness of both approaches across multiple downstream tasks, with\nContraWiMAE showing further improvements in linear separability and\nadaptability in diverse wireless environments. Comparative evaluations against\na state-of-the-art wireless channel foundation model confirm the superior\nperformance and data efficiency of our models, highlighting their potential as\npowerful baselines for future research in self-supervised wireless channel\nrepresentation learning."}
{"id": "2505.09178", "pdf": "https://arxiv.org/pdf/2505.09178", "abs": "https://arxiv.org/abs/2505.09178", "authors": ["Yitao Zhu", "Yuan Yin", "Zhenrong Shen", "Zihao Zhao", "Haiyu Song", "Sheng Wang", "Dinggang Shen", "Qian Wang"], "title": "UniCAD: Efficient and Extendable Architecture for Multi-Task Computer-Aided Diagnosis System", "categories": ["cs.CV"], "comment": "14 pages", "summary": "The growing complexity and scale of visual model pre-training have made\ndeveloping and deploying multi-task computer-aided diagnosis (CAD) systems\nincreasingly challenging and resource-intensive. Furthermore, the medical\nimaging community lacks an open-source CAD platform to enable the rapid\ncreation of efficient and extendable diagnostic models. To address these\nissues, we propose UniCAD, a unified architecture that leverages the robust\ncapabilities of pre-trained vision foundation models to seamlessly handle both\n2D and 3D medical images while requiring only minimal task-specific parameters.\nUniCAD introduces two key innovations: (1) Efficiency: A low-rank adaptation\nstrategy is employed to adapt a pre-trained visual model to the medical image\ndomain, achieving performance on par with fully fine-tuned counterparts while\nintroducing only 0.17% trainable parameters. (2) Plug-and-Play: A modular\narchitecture that combines a frozen foundation model with multiple\nplug-and-play experts, enabling diverse tasks and seamless functionality\nexpansion. Building on this unified CAD architecture, we establish an\nopen-source platform where researchers can share and access lightweight CAD\nexperts, fostering a more equitable and efficient research ecosystem.\nComprehensive experiments across 12 diverse medical datasets demonstrate that\nUniCAD consistently outperforms existing methods in both accuracy and\ndeployment efficiency. The source code and project page are available at\nhttps://mii-laboratory.github.io/UniCAD/."}
{"id": "2505.09614", "pdf": "https://arxiv.org/pdf/2505.09614", "abs": "https://arxiv.org/abs/2505.09614", "authors": ["Anthony GX-Chen", "Dongyan Lin", "Mandana Samiei", "Doina Precup", "Blake A. Richards", "Rob Fergus", "Kenneth Marino"], "title": "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Language model (LM) agents are increasingly used as autonomous\ndecision-makers who need to actively gather information to guide their\ndecisions. A crucial cognitive skill for such agents is the efficient\nexploration and understanding of the causal structure of the world -- key to\nrobust, scientifically grounded reasoning. Yet, it remains unclear whether LMs\npossess this capability or exhibit systematic biases leading to erroneous\nconclusions. In this work, we examine LMs' ability to explore and infer causal\nrelationships, using the well-established \"Blicket Test\" paradigm from\ndevelopmental psychology. We find that LMs reliably infer the common, intuitive\ndisjunctive causal relationships but systematically struggle with the unusual,\nyet equally (or sometimes even more) evidenced conjunctive ones. This\n\"disjunctive bias\" persists across model families, sizes, and prompting\nstrategies, and performance further declines as task complexity increases.\nInterestingly, an analogous bias appears in human adults, suggesting that LMs\nmay have inherited deep-seated reasoning heuristics from their training data.\nTo this end, we quantify similarities between LMs and humans, finding that LMs\nexhibit adult-like inference profiles (but not children-like). Finally, we\npropose a test-time sampling method which explicitly samples and eliminates\nhypotheses about causal relationships from the LM. This scalable approach\nsignificantly reduces the disjunctive bias and moves LMs closer to the goal of\nscientific, causally rigorous reasoning."}
{"id": "2505.08823", "pdf": "https://arxiv.org/pdf/2505.08823", "abs": "https://arxiv.org/abs/2505.08823", "authors": ["Cody Steinmetz", "Gavin Childress", "Aaron Herbst", "Gavin Jones", "Jasdeep Singh", "Eli Vang", "Keagan Weinstock"], "title": "An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have transformed natural-language processing,\nyet their scale makes real-world deployment costly. Post-training quantization\nreduces memory and computation but often degrades accuracy, while\nquantization-aware training can recover performance at the cost of extra\ntraining. Pushing quantization to the ternary (2-bit) regime yields even larger\nsavings but is notoriously unstable. Building on recent work showing that a\nbias-free, RMS-normalized Transformer with straight-through estimation can\nreach 1.58-bit precision, we demonstrate that simply inserting RMS\nnormalization before every linear projection and applying a gradual, layer-wise\nquantization schedule stably fine-tunes full-precision checkpoints into ternary\nLLMs. Our approach matches or surpasses more elaborate knowledge-distillation\npipelines on standard language-modeling benchmarks without adding model\ncomplexity. These results indicate that careful normalization alone can close\nmuch of the accuracy gap between ternary and full-precision LLMs, making\nultra-low-bit inference practical."}
{"id": "2505.09174", "pdf": "https://arxiv.org/pdf/2505.09174", "abs": "https://arxiv.org/abs/2505.09174", "authors": ["Xinyu You", "Xiang Liu", "Chuan-Shen Hu", "Kelin Xia", "Tze Chien Sum"], "title": "Quotient Complex Transformer (QCformer) for Perovskite Data Analysis", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "comment": null, "summary": "The discovery of novel functional materials is crucial in addressing the\nchallenges of sustainable energy generation and climate change. Hybrid\norganic-inorganic perovskites (HOIPs) have gained attention for their\nexceptional optoelectronic properties in photovoltaics. Recently, geometric\ndeep learning, particularly graph neural networks (GNNs), has shown strong\npotential in predicting material properties and guiding material design.\nHowever, traditional GNNs often struggle to capture the periodic structures and\nhigher-order interactions prevalent in such systems. To address these\nlimitations, we propose a novel representation based on quotient complexes\n(QCs) and introduce the Quotient Complex Transformer (QCformer) for material\nproperty prediction. A material structure is modeled as a quotient complex,\nwhich encodes both pairwise and many-body interactions via simplices of varying\ndimensions and captures material periodicity through a quotient operation. Our\nmodel leverages higher-order features defined on simplices and processes them\nusing a simplex-based Transformer module. We pretrain QCformer on benchmark\ndatasets such as the Materials Project and JARVIS, and fine-tune it on HOIP\ndatasets. The results show that QCformer outperforms state-of-the-art models in\nHOIP property prediction, demonstrating its effectiveness. The quotient complex\nrepresentation and QCformer model together contribute a powerful new tool for\npredictive modeling of perovskite materials."}
{"id": "2505.09188", "pdf": "https://arxiv.org/pdf/2505.09188", "abs": "https://arxiv.org/abs/2505.09188", "authors": ["Minjun Kim", "Jaehyeon Choi", "Jongkeun Lee", "Wonjin Cho", "U Kang"], "title": "Zero-shot Quantization: A Comprehensive Survey", "categories": ["cs.CV"], "comment": "IJCAI 2025 Survey Track", "summary": "Network quantization has proven to be a powerful approach to reduce the\nmemory and computational demands of deep learning models for deployment on\nresource-constrained devices. However, traditional quantization methods often\nrely on access to training data, which is impractical in many real-world\nscenarios due to privacy, security, or regulatory constraints. Zero-shot\nQuantization (ZSQ) emerges as a promising solution, achieving quantization\nwithout requiring any real data. In this paper, we provide a comprehensive\noverview of ZSQ methods and their recent advancements. First, we provide a\nformal definition of the ZSQ problem and highlight the key challenges. Then, we\ncategorize the existing ZSQ methods into classes based on data generation\nstrategies, and analyze their motivations, core ideas, and key takeaways.\nLastly, we suggest future research directions to address the remaining\nlimitations and advance the field of ZSQ. To the best of our knowledge, this\npaper is the first in-depth survey on ZSQ."}
{"id": "2505.08825", "pdf": "https://arxiv.org/pdf/2505.08825", "abs": "https://arxiv.org/abs/2505.08825", "authors": ["Pedro Antonio Alarcon Granadeno", "Theodore Chambers", "Jane Cleland-Huang"], "title": "Multi-source Plume Tracing via Multi-Agent Reinforcement Learning", "categories": ["cs.MA", "cs.AI"], "comment": "13 pages, 7 figures", "summary": "Industrial catastrophes like the Bhopal disaster (1984) and the Aliso Canyon\ngas leak (2015) demonstrate the urgent need for rapid and reliable plume\ntracing algorithms to protect public health and the environment. Traditional\nmethods, such as gradient-based or biologically inspired approaches, often fail\nin realistic, turbulent conditions. To address these challenges, we present a\nMulti-Agent Reinforcement Learning (MARL) algorithm designed for localizing\nmultiple airborne pollution sources using a swarm of small uncrewed aerial\nsystems (sUAS). Our method models the problem as a Partially Observable Markov\nGame (POMG), employing a Long Short-Term Memory (LSTM)-based Action-specific\nDouble Deep Recurrent Q-Network (ADDRQN) that uses full sequences of historical\naction-observation pairs, effectively approximating latent states. Unlike prior\nwork, we use a general-purpose simulation environment based on the Gaussian\nPlume Model (GPM), incorporating realistic elements such as a three-dimensional\nenvironment, sensor noise, multiple interacting agents, and multiple plume\nsources. The incorporation of action histories as part of the inputs further\nenhances the adaptability of our model in complex, partially observable\nenvironments. Extensive simulations show that our algorithm significantly\noutperforms conventional approaches. Specifically, our model allows agents to\nexplore only 1.29\\% of the environment to successfully locate pollution\nsources."}
{"id": "2505.09175", "pdf": "https://arxiv.org/pdf/2505.09175", "abs": "https://arxiv.org/abs/2505.09175", "authors": ["Mohammad Ganjirad", "Mahmoud Reza Delavar", "Hossein Bagheri", "Mohammad Mehdi Azizi"], "title": "Optimizing Urban Critical Green Space Development Using Machine Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "This paper presents a novel framework for prioritizing urban green space\ndevelopment in Tehran using diverse socio-economic, environmental, and\nsensitivity indices. The indices were derived from various sources including\nGoogle Earth Engine, air pollution measurements, municipal reports and the\nWeather Research & Forecasting (WRF) model. The WRF model was used to estimate\nthe air temperature at a 1 km resolution due to insufficient meteorological\nstations, yielding RMSE and MAE values of 0.96{\\deg}C and 0.92{\\deg}C,\nrespectively. After data preparation, several machine learning models were used\nfor binary vegetation cover classification including XGBoost, LightGBM, Random\nForest (RF) and Extra Trees. RF achieved the highest performance, exceeding 94%\nin Overall Accuracy, Recall, and F1-score. Then, the probability of areas\nlacking vegetation cover was assessed using socio-economic, environmental and\nsensitivity indices. This resulted in the RF generating an urban green space\ndevelopment prioritization map. Feature Importance Analysis revealed that the\nmost significant indices were nightly land surface temperature (LST) and\nsensitive population. Finally, the framework performance was validated through\nmicroclimate simulation to assess the critical areas after and before the green\nspace development by green roofs. The simulation demonstrated reducing air\ntemperature by up to 0.67{\\deg}C after utilizing the green roof technology in\ncritical areas. As a result, this framework provides a valuable tool for urban\nplanners to develop green spaces."}
{"id": "2505.09196", "pdf": "https://arxiv.org/pdf/2505.09196", "abs": "https://arxiv.org/abs/2505.09196", "authors": ["Tong Li", "Lizhi Wang", "Hansen Feng", "Lin Zhu", "Hua Huang"], "title": "PDE: Gene Effect Inspired Parameter Dynamic Evolution for Low-light Image Enhancement", "categories": ["cs.CV"], "comment": "11 pages, 9 tables, 9 figures", "summary": "Low-light image enhancement (LLIE) is a fundamental task in computational\nphotography, aiming to improve illumination, reduce noise, and enhance image\nquality. While recent advancements focus on designing increasingly complex\nneural network models, we observe a peculiar phenomenon: resetting certain\nparameters to random values unexpectedly improves enhancement performance for\nsome images. Drawing inspiration from biological genes, we term this phenomenon\nthe gene effect. The gene effect limits enhancement performance, as even random\nparameters can sometimes outperform learned ones, preventing models from fully\nutilizing their capacity. In this paper, we investigate the reason and propose\na solution. Based on our observations, we attribute the gene effect to static\nparameters, analogous to how fixed genetic configurations become maladaptive\nwhen environments change. Inspired by biological evolution, where adaptation to\nnew environments relies on gene mutation and recombination, we propose\nparameter dynamic evolution (PDE) to adapt to different images and mitigate the\ngene effect. PDE employs a parameter orthogonal generation technique and the\ncorresponding generated parameters to simulate gene recombination and gene\nmutation, separately. Experiments validate the effectiveness of our techniques.\nThe code will be released to the public."}
{"id": "2505.08827", "pdf": "https://arxiv.org/pdf/2505.08827", "abs": "https://arxiv.org/abs/2505.08827", "authors": ["Toby Simonds", "Kevin Lopez", "Akira Yoshiyama", "Dominique Garmier"], "title": "Self Rewarding Self Improving", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We demonstrate that large language models can effectively self-improve\nthrough self-judging without requiring reference solutions, leveraging the\ninherent asymmetry between generating and verifying solutions. Our experiments\non Countdown puzzles and MIT Integration Bee problems show that models can\nprovide reliable reward signals without ground truth answers, enabling\nreinforcement learning in domains previously not possible. By implementing\nself-judging, we achieve significant performance gains maintaining alignment\nwith formal verification. When combined with synthetic question generation, we\nestablish a complete self-improvement loop where models generate practice\nproblems, solve them, and evaluate their own performance-achieving an 8%\nimprovement with Qwen 2.5 7B over baseline and surpassing GPT-4o performance on\nintegration tasks. Our findings demonstrate that LLM judges can provide\neffective reward signals for training models, unlocking many reinforcement\nlearning environments previously limited by the difficulty of creating\nprogrammatic rewards. This suggests a potential paradigm shift toward AI\nsystems that continuously improve through self-directed learning rather than\nhuman-guided training, potentially accelerating progress in domains with scarce\ntraining data or complex evaluation requirements."}
{"id": "2505.09214", "pdf": "https://arxiv.org/pdf/2505.09214", "abs": "https://arxiv.org/abs/2505.09214", "authors": ["Zhonghao Lyu", "Ming Xiao", "Jie Xu", "Mikael Skoglund", "Marco Di Renzo"], "title": "The Larger the Merrier? Efficient Large AI Model Inference in Wireless Edge Networks", "categories": ["cs.LG"], "comment": null, "summary": "The growing demand for large artificial intelligence model (LAIM) services is\ndriving a paradigm shift from traditional cloud-based inference to edge-based\ninference for low-latency, privacy-preserving applications. In particular,\nedge-device co-inference, which partitions LAIMs between edge devices and\nservers, has emerged as a promising strategy for resource-efficient LAIM\nexecution in wireless networks. In this paper, we investigate a pruning-aware\nLAIM co-inference scheme, where a pre-trained LAIM is pruned and partitioned\ninto on-device and on-server sub-models for deployment. For analysis, we first\nprove that the LAIM output distortion is upper bounded by its parameter\ndistortion. Then, we derive a lower bound on parameter distortion via\nrate-distortion theory, analytically capturing the relationship between pruning\nratio and co-inference performance. Next, based on the analytical results, we\nformulate an LAIM co-inference distortion bound minimization problem by jointly\noptimizing the pruning ratio, transmit power, and computation frequency under\nsystem latency, energy, and available resource constraints. Moreover, we\npropose an efficient algorithm to tackle the considered highly non-convex\nproblem. Finally, extensive simulations demonstrate the effectiveness of the\nproposed design. In particular, model parameter distortion is shown to provide\na reliable bound on output distortion. Also, the proposed joint pruning ratio\nand resource management design achieves superior performance in balancing\ntrade-offs among inference performance, system latency, and energy consumption\ncompared with benchmark schemes, such as fully on-device and on-server\ninference. Moreover, the split point is shown to play a critical role in system\nperformance optimization under heterogeneous and resource-limited edge\nenvironments."}
{"id": "2505.09251", "pdf": "https://arxiv.org/pdf/2505.09251", "abs": "https://arxiv.org/abs/2505.09251", "authors": ["Vineetha Joy", "Aditya Anand", "Nidhi", "Anshuman Kumar", "Amit Sethi", "Hema Singh"], "title": "A Surrogate Model for the Forward Design of Multi-layered Metasurface-based Radar Absorbing Structures", "categories": ["cs.CV"], "comment": null, "summary": "Metasurface-based radar absorbing structures (RAS) are highly preferred for\napplications like stealth technology, electromagnetic (EM) shielding, etc. due\nto their capability to achieve frequency selective absorption characteristics\nwith minimal thickness and reduced weight penalty. However, the conventional\napproach for the EM design and optimization of these structures relies on\nforward simulations, using full wave simulation tools, to predict the\nelectromagnetic (EM) response of candidate meta atoms. This process is\ncomputationally intensive, extremely time consuming and requires exploration of\nlarge design spaces. To overcome this challenge, we propose a surrogate model\nthat significantly accelerates the prediction of EM responses of multi-layered\nmetasurface-based RAS. A convolutional neural network (CNN) based architecture\nwith Huber loss function has been employed to estimate the reflection\ncharacteristics of the RAS model. The proposed model achieved a cosine\nsimilarity of 99.9% and a mean square error of 0.001 within 1000 epochs of\ntraining. The efficiency of the model has been established via full wave\nsimulations as well as experiment where it demonstrated significant reduction\nin computational time while maintaining high predictive accuracy."}
{"id": "2505.08828", "pdf": "https://arxiv.org/pdf/2505.08828", "abs": "https://arxiv.org/abs/2505.08828", "authors": ["Eduardo Araujo Oliveira", "Madhavi Mohoni", "Sonsoles López-Pernas", "Mohammed Saqr"], "title": "Human-AI Collaboration or Academic Misconduct? Measuring AI Use in Student Writing Through Stylometric Evidence", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "19 pages, 10 figures, 11 tables", "summary": "As human-AI collaboration becomes increasingly prevalent in educational\ncontexts, understanding and measuring the extent and nature of such\ninteractions pose significant challenges. This research investigates the use of\nauthorship verification (AV) techniques not as a punitive measure, but as a\nmeans to quantify AI assistance in academic writing, with a focus on promoting\ntransparency, interpretability, and student development. Building on prior\nwork, we structured our investigation into three stages: dataset selection and\nexpansion, AV method development, and systematic evaluation. Using three\ndatasets - including a public dataset (PAN-14) and two from University of\nMelbourne students from various courses - we expanded the data to include\nLLM-generated texts, totalling 1,889 documents and 540 authorship problems from\n506 students. We developed an adapted Feature Vector Difference AV methodology\nto construct robust academic writing profiles for students, designed to capture\nmeaningful, individual characteristics of their writing. The method's\neffectiveness was evaluated across multiple scenarios, including distinguishing\nbetween student-authored and LLM-generated texts and testing resilience against\nLLMs' attempts to mimic student writing styles. Results demonstrate the\nenhanced AV classifier's ability to identify stylometric discrepancies and\nmeasure human-AI collaboration at word and sentence levels while providing\neducators with a transparent tool to support academic integrity investigations.\nThis work advances AV technology, offering actionable insights into the\ndynamics of academic writing in an AI-driven era."}
{"id": "2505.09218", "pdf": "https://arxiv.org/pdf/2505.09218", "abs": "https://arxiv.org/abs/2505.09218", "authors": ["Alexander Tyurin", "Danil Sivtsov"], "title": "Birch SGD: A Tree Graph Framework for Local and Asynchronous SGD Methods", "categories": ["cs.LG", "cs.DC", "math.OC"], "comment": null, "summary": "We propose a new unifying framework, Birch SGD, for analyzing and designing\ndistributed SGD methods. The central idea is to represent each method as a\nweighted directed tree, referred to as a computation tree. Leveraging this\nrepresentation, we introduce a general theoretical result that reduces\nconvergence analysis to studying the geometry of these trees. This perspective\nyields a purely graph-based interpretation of optimization dynamics, offering a\nnew and intuitive foundation for method development. Using Birch SGD, we design\neight new methods and analyze them alongside previously known ones, with at\nleast six of the new methods shown to have optimal computational time\ncomplexity. Our research leads to two key insights: (i) all methods share the\nsame \"iteration rate\" of $O\\left(\\frac{(R + 1) L \\Delta}{\\varepsilon} +\n\\frac{\\sigma^2 L \\Delta}{\\varepsilon^2}\\right)$, where $R$ the maximum \"tree\ndistance\" along the main branch of a tree; and (ii) different methods exhibit\ndifferent trade-offs-for example, some update iterates more frequently,\nimproving practical performance, while others are more communication-efficient\nor focus on other aspects. Birch SGD serves as a unifying framework for\nnavigating these trade-offs. We believe these results provide a unified\nfoundation for understanding, analyzing, and designing efficient asynchronous\nand parallel optimization methods."}
{"id": "2505.09252", "pdf": "https://arxiv.org/pdf/2505.09252", "abs": "https://arxiv.org/abs/2505.09252", "authors": ["Yinuo Wang", "Yue Zeng", "Kai Chen", "Cai Meng", "Chao Pan", "Zhouping Tang"], "title": "Zero-Shot Multi-modal Large Language Model v.s. Supervised Deep Learning: A Comparative Study on CT-Based Intracranial Hemorrhage Subtyping", "categories": ["cs.CV"], "comment": null, "summary": "Introduction: Timely identification of intracranial hemorrhage (ICH) subtypes\non non-contrast computed tomography is critical for prognosis prediction and\ntherapeutic decision-making, yet remains challenging due to low contrast and\nblurring boundaries. This study evaluates the performance of zero-shot\nmulti-modal large language models (MLLMs) compared to traditional deep learning\nmethods in ICH binary classification and subtyping. Methods: We utilized a\ndataset provided by RSNA, comprising 192 NCCT volumes. The study compares\nvarious MLLMs, including GPT-4o, Gemini 2.0 Flash, and Claude 3.5 Sonnet V2,\nwith conventional deep learning models, including ResNet50 and Vision\nTransformer. Carefully crafted prompts were used to guide MLLMs in tasks such\nas ICH presence, subtype classification, localization, and volume estimation.\nResults: The results indicate that in the ICH binary classification task,\ntraditional deep learning models outperform MLLMs comprehensively. For subtype\nclassification, MLLMs also exhibit inferior performance compared to traditional\ndeep learning models, with Gemini 2.0 Flash achieving an macro-averaged\nprecision of 0.41 and a macro-averaged F1 score of 0.31. Conclusion: While\nMLLMs excel in interactive capabilities, their overall accuracy in ICH\nsubtyping is inferior to deep networks. However, MLLMs enhance interpretability\nthrough language interactions, indicating potential in medical imaging\nanalysis. Future efforts will focus on model refinement and developing more\nprecise MLLMs to improve performance in three-dimensional medical image\nprocessing."}
{"id": "2505.08829", "pdf": "https://arxiv.org/pdf/2505.08829", "abs": "https://arxiv.org/abs/2505.08829", "authors": ["David Kinney"], "title": "Aggregating Concepts of Fairness and Accuracy in Predictive Systems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "An algorithm that outputs predictions about the state of the world will\nalmost always be designed with the implicit or explicit goal of outputting\naccurate predictions (i.e., predictions that are likely to be true). In\naddition, the rise of increasingly powerful predictive algorithms brought about\nby the recent revolution in artificial intelligence has led to an emphasis on\nbuilding predictive algorithms that are fair, in the sense that their\npredictions do not systematically evince bias or bring about harm to certain\nindividuals or groups. This state of affairs presents two conceptual\nchallenges. First, the goals of accuracy and fairness can sometimes be in\ntension, and there are no obvious normative guidelines for managing the\ntrade-offs between these two desiderata when they arise. Second, there are many\ndistinct ways of measuring both the accuracy and fairness of a predictive\nalgorithm; here too, there are no obvious guidelines on how to aggregate our\npreferences for predictive algorithms that satisfy disparate measures of\nfairness and accuracy to various extents. The goal of this paper is to address\nthese challenges by arguing that there are good reasons for using a linear\ncombination of accuracy and fairness metrics to measure the\nall-things-considered value of a predictive algorithm for agents who care about\nboth accuracy and fairness. My argument depends crucially on a classic result\nin the preference aggregation literature due to Harsanyi. After making this\nformal argument, I apply my result to an analysis of accuracy-fairness\ntrade-offs using the COMPAS dataset compiled by Angwin et al."}
{"id": "2505.09239", "pdf": "https://arxiv.org/pdf/2505.09239", "abs": "https://arxiv.org/abs/2505.09239", "authors": ["Faruk Alpay"], "title": "Stable and Convexified Information Bottleneck Optimization via Symbolic Continuation and Entropy-Regularized Trajectories", "categories": ["cs.LG", "68T05, 90C25, 94A15", "I.2.6; G.1.6; H.1.1"], "comment": "23 pages, 11 figures, includes analytical proofs, sensitivity\n  analysis (95% CI), and JAX-based open-source implementation available at:\n  https://github.com/farukalpay/information-bottleneck-beta-optimization", "summary": "The Information Bottleneck (IB) method frequently suffers from unstable\noptimization, characterized by abrupt representation shifts near critical\npoints of the IB trade-off parameter, beta. In this paper, I introduce a novel\napproach to achieve stable and convex IB optimization through symbolic\ncontinuation and entropy-regularized trajectories. I analytically prove\nconvexity and uniqueness of the IB solution path when an entropy regularization\nterm is included, and demonstrate how this stabilizes representation learning\nacross a wide range of \\b{eta} values. Additionally, I provide extensive\nsensitivity analyses around critical points (beta) with statistically robust\nuncertainty quantification (95% confidence intervals). The open-source\nimplementation, experimental results, and reproducibility framework included in\nthis work offer a clear path for practical deployment and future extension of\nmy proposed method."}
{"id": "2505.09256", "pdf": "https://arxiv.org/pdf/2505.09256", "abs": "https://arxiv.org/abs/2505.09256", "authors": ["Jaemin Jung", "Youngjoon Jang", "Joon Son Chung"], "title": "Test-Time Augmentation for Pose-invariant Face Recognition", "categories": ["cs.CV"], "comment": null, "summary": "The goal of this paper is to enhance face recognition performance by\naugmenting head poses during the testing phase. Existing methods often rely on\ntraining on frontalised images or learning pose-invariant representations, yet\nboth approaches typically require re-training and testing for each dataset,\ninvolving a substantial amount of effort. In contrast, this study proposes\nPose-TTA, a novel approach that aligns faces at inference time without\nadditional training. To achieve this, we employ a portrait animator that\ntransfers the source image identity into the pose of a driving image. Instead\nof frontalising a side-profile face -- which can introduce distortion --\nPose-TTA generates matching side-profile images for comparison, thereby\nreducing identity information loss. Furthermore, we propose a weighted feature\naggregation strategy to address any distortions or biases arising from the\nsynthetic data, thus enhancing the reliability of the augmented images.\nExtensive experiments on diverse datasets and with various pre-trained face\nrecognition models demonstrate that Pose-TTA consistently improves inference\nperformance. Moreover, our method is straightforward to integrate into existing\nface recognition pipelines, as it requires no retraining or fine-tuning of the\nunderlying recognition models."}
{"id": "2505.08830", "pdf": "https://arxiv.org/pdf/2505.08830", "abs": "https://arxiv.org/abs/2505.08830", "authors": ["Wenhao Jiang", "Yuchuan Luo", "Guilin Deng", "Silong Chen", "Xu Yang", "Shihong Wu", "Xinwen Gao", "Lin Liu", "Shaojing Fu"], "title": "Federated Large Language Models: Feasibility, Robustness, Security and Future Directions", "categories": ["cs.CR", "cs.AI"], "comment": "35 pages", "summary": "The integration of Large Language Models (LLMs) and Federated Learning (FL)\npresents a promising solution for joint training on distributed data while\npreserving privacy and addressing data silo issues. However, this emerging\nfield, known as Federated Large Language Models (FLLM), faces significant\nchallenges, including communication and computation overheads, heterogeneity,\nprivacy and security concerns. Current research has primarily focused on the\nfeasibility of FLLM, but future trends are expected to emphasize enhancing\nsystem robustness and security. This paper provides a comprehensive review of\nthe latest advancements in FLLM, examining challenges from four critical\nperspectives: feasibility, robustness, security, and future directions. We\npresent an exhaustive survey of existing studies on FLLM feasibility, introduce\nmethods to enhance robustness in the face of resource, data, and task\nheterogeneity, and analyze novel risks associated with this integration,\nincluding privacy threats and security challenges. We also review the latest\ndevelopments in defense mechanisms and explore promising future research\ndirections, such as few-shot learning, machine unlearning, and IP protection.\nThis survey highlights the pressing need for further research to enhance system\nrobustness and security while addressing the unique challenges posed by the\nintegration of FL and LLM."}
{"id": "2505.09284", "pdf": "https://arxiv.org/pdf/2505.09284", "abs": "https://arxiv.org/abs/2505.09284", "authors": ["Panqi Chen", "Yifan Sun", "Lei Cheng", "Yang Yang", "Weichang Li", "Yang Liu", "Weiqing Liu", "Jiang Bian", "Shikai Fang"], "title": "Generating Full-field Evolution of Physical Dynamics from Irregular Sparse Observations", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Modeling and reconstructing multidimensional physical dynamics from sparse\nand off-grid observations presents a fundamental challenge in scientific\nresearch. Recently, diffusion-based generative modeling shows promising\npotential for physical simulation. However, current approaches typically\noperate on on-grid data with preset spatiotemporal resolution, but struggle\nwith the sparsely observed and continuous nature of real-world physical\ndynamics. To fill the gaps, we present SDIFT, Sequential DIffusion in\nFunctional Tucker space, a novel framework that generates full-field evolution\nof physical dynamics from irregular sparse observations. SDIFT leverages the\nfunctional Tucker model as the latent space representer with proven universal\napproximation property, and represents observations as latent functions and\nTucker core sequences. We then construct a sequential diffusion model with\ntemporally augmented UNet in the functional Tucker space, denoising noise drawn\nfrom a Gaussian process to generate the sequence of core tensors.\n  At the posterior sampling stage, we propose a Message-Passing Posterior\nSampling mechanism, enabling conditional generation of the entire sequence\nguided by observations at limited time steps. We validate SDIFT on three\nphysical systems spanning astronomical (supernova explosions, light-year\nscale), environmental (ocean sound speed fields, kilometer scale), and\nmolecular (organic liquid, millimeter scale) domains, demonstrating significant\nimprovements in both reconstruction accuracy and computational efficiency\ncompared to state-of-the-art approaches."}
{"id": "2505.09263", "pdf": "https://arxiv.org/pdf/2505.09263", "abs": "https://arxiv.org/abs/2505.09263", "authors": ["Guan Gui", "Bin-Bin Gao", "Jun Liu", "Chengjie Wang", "Yunsheng Wu"], "title": "Few-Shot Anomaly-Driven Generation for Anomaly Classification and Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ECCV 2024", "summary": "Anomaly detection is a practical and challenging task due to the scarcity of\nanomaly samples in industrial inspection. Some existing anomaly detection\nmethods address this issue by synthesizing anomalies with noise or external\ndata. However, there is always a large semantic gap between synthetic and\nreal-world anomalies, resulting in weak performance in anomaly detection. To\nsolve the problem, we propose a few-shot Anomaly-driven Generation (AnoGen)\nmethod, which guides the diffusion model to generate realistic and diverse\nanomalies with only a few real anomalies, thereby benefiting training anomaly\ndetection models. Specifically, our work is divided into three stages. In the\nfirst stage, we learn the anomaly distribution based on a few given real\nanomalies and inject the learned knowledge into an embedding. In the second\nstage, we use the embedding and given bounding boxes to guide the diffusion\nmodel to generate realistic and diverse anomalies on specific objects (or\ntextures). In the final stage, we propose a weakly-supervised anomaly detection\nmethod to train a more powerful model with generated anomalies. Our method\nbuilds upon DRAEM and DesTSeg as the foundation model and conducts experiments\non the commonly used industrial anomaly detection dataset, MVTec. The\nexperiments demonstrate that our generated anomalies effectively improve the\nmodel performance of both anomaly classification and segmentation tasks\nsimultaneously, \\eg, DRAEM and DseTSeg achieved a 5.8\\% and 1.5\\% improvement\nin AU-PR metric on segmentation task, respectively. The code and generated\nanomalous data are available at https://github.com/gaobb/AnoGen."}
{"id": "2505.08834", "pdf": "https://arxiv.org/pdf/2505.08834", "abs": "https://arxiv.org/abs/2505.08834", "authors": ["Muhammad Junaid Asif"], "title": "Crowd Scene Analysis using Deep Learning Techniques", "categories": ["cs.CV", "cs.AI"], "comment": "MS Graduate Research Thesis", "summary": "Our research is focused on two main applications of crowd scene analysis\ncrowd counting and anomaly detection In recent years a large number of\nresearches have been presented in the domain of crowd counting We addressed two\nmain challenges in this domain 1 Deep learning models are datahungry paradigms\nand always need a large amount of annotated data for the training of algorithm\nIt is timeconsuming and costly task to annotate such large amount of data\nSelfsupervised training is proposed to deal with this challenge 2 MCNN consists\nof multicolumns of CNN with different sizes of filters by presenting a novel\napproach based on a combination of selfsupervised training and MultiColumn CNN\nThis enables the model to learn features at different levels and makes it\neffective in dealing with challenges of occluded scenes nonuniform density\ncomplex backgrounds and scale invariation The proposed model was evaluated on\npublicly available data sets such as ShanghaiTech and UCFQNRF by means of MAE\nand MSE A spatiotemporal model based on VGG19 is proposed for crowd anomaly\ndetection addressing challenges like lighting environmental conditions\nunexpected objects and scalability The model extracts spatial and temporal\nfeatures allowing it to be generalized to realworld scenes Spatial features are\nlearned using CNN while temporal features are learned using LSTM blocks The\nmodel works on binary classification and can detect normal or abnormal behavior\nThe models performance is improved by replacing fully connected layers with\ndense residual blocks Experiments on the Hockey Fight dataset and SCVD dataset\nshow our models outperform other stateoftheart approaches"}
{"id": "2505.09287", "pdf": "https://arxiv.org/pdf/2505.09287", "abs": "https://arxiv.org/abs/2505.09287", "authors": ["Shunsuke Yoneda", "Valdemar Švábenský", "Gen Li", "Daisuke Deguchi", "Atsushi Shimada"], "title": "Ranking-Based At-Risk Student Prediction Using Federated Learning and Differential Features", "categories": ["cs.LG", "cs.CY", "I.2; I.6; K.3"], "comment": "To appear in the Proceedings of the 18th Educational Data Mining\n  Conference (EDM 2025)", "summary": "Digital textbooks are widely used in various educational contexts, such as\nuniversity courses and online lectures. Such textbooks yield learning log data\nthat have been used in numerous educational data mining (EDM) studies for\nstudent behavior analysis and performance prediction. However, these studies\nhave faced challenges in integrating confidential data, such as academic\nrecords and learning logs, across schools due to privacy concerns.\nConsequently, analyses are often conducted with data limited to a single\nschool, which makes developing high-performing and generalizable models\ndifficult. This study proposes a method that combines federated learning and\ndifferential features to address these issues. Federated learning enables model\ntraining without centralizing data, thereby preserving student privacy.\nDifferential features, which utilize relative values instead of absolute\nvalues, enhance model performance and generalizability. To evaluate the\nproposed method, a model for predicting at-risk students was trained using data\nfrom 1,136 students across 12 courses conducted over 4 years, and validated on\nhold-out test data from 5 other courses. Experimental results demonstrated that\nthe proposed method addresses privacy concerns while achieving performance\ncomparable to that of models trained via centralized learning in terms of Top-n\nprecision, nDCG, and PR-AUC. Furthermore, using differential features improved\nprediction performance across all evaluation datasets compared to\nnon-differential approaches. The trained models were also applicable for early\nprediction, achieving high performance in detecting at-risk students in earlier\nstages of the semester within the validation datasets."}
{"id": "2505.09264", "pdf": "https://arxiv.org/pdf/2505.09264", "abs": "https://arxiv.org/abs/2505.09264", "authors": ["Bin-Bin Gao"], "title": "Learning to Detect Multi-class Anomalies with Just One Normal Image Prompt", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ECCV 2024", "summary": "Unsupervised reconstruction networks using self-attention transformers have\nachieved state-of-the-art performance for multi-class (unified) anomaly\ndetection with a single model. However, these self-attention reconstruction\nmodels primarily operate on target features, which may result in perfect\nreconstruction for both normal and anomaly features due to high consistency\nwith context, leading to failure in detecting anomalies. Additionally, these\nmodels often produce inaccurate anomaly segmentation due to performing\nreconstruction in a low spatial resolution latent space. To enable\nreconstruction models enjoying high efficiency while enhancing their\ngeneralization for unified anomaly detection, we propose a simple yet effective\nmethod that reconstructs normal features and restores anomaly features with\njust One Normal Image Prompt (OneNIP). In contrast to previous work, OneNIP\nallows for the first time to reconstruct or restore anomalies with just one\nnormal image prompt, effectively boosting unified anomaly detection\nperformance. Furthermore, we propose a supervised refiner that regresses\nreconstruction errors by using both real normal and synthesized anomalous\nimages, which significantly improves pixel-level anomaly segmentation. OneNIP\noutperforms previous methods on three industry anomaly detection benchmarks:\nMVTec, BTAD, and VisA. The code and pre-trained models are available at\nhttps://github.com/gaobb/OneNIP."}
{"id": "2505.08835", "pdf": "https://arxiv.org/pdf/2505.08835", "abs": "https://arxiv.org/abs/2505.08835", "authors": ["Hyunsik Na", "Wonho Lee", "Seungdeok Roh", "Sohee Park", "Daeseon Choi"], "title": "Robustness Analysis against Adversarial Patch Attacks in Fully Unmanned Stores", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": null, "summary": "The advent of convenient and efficient fully unmanned stores equipped with\nartificial intelligence-based automated checkout systems marks a new era in\nretail. However, these systems have inherent artificial intelligence security\nvulnerabilities, which are exploited via adversarial patch attacks,\nparticularly in physical environments. This study demonstrated that adversarial\npatches can severely disrupt object detection models used in unmanned stores,\nleading to issues such as theft, inventory discrepancies, and interference. We\ninvestigated three types of adversarial patch attacks -- Hiding, Creating, and\nAltering attacks -- and highlighted their effectiveness. We also introduce the\nnovel color histogram similarity loss function by leveraging attacker knowledge\nof the color information of a target class object. Besides the traditional\nconfusion-matrix-based attack success rate, we introduce a new\nbounding-boxes-based metric to analyze the practical impact of these attacks.\nStarting with attacks on object detection models trained on snack and fruit\ndatasets in a digital environment, we evaluated the effectiveness of\nadversarial patches in a physical testbed that mimicked a real unmanned store\nwith RGB cameras and realistic conditions. Furthermore, we assessed the\nrobustness of these attacks in black-box scenarios, demonstrating that shadow\nattacks can enhance success rates of attacks even without direct access to\nmodel parameters. Our study underscores the necessity for robust defense\nstrategies to protect unmanned stores from adversarial threats. Highlighting\nthe limitations of the current defense mechanisms in real-time detection\nsystems and discussing various proactive measures, we provide insights into\nimproving the robustness of object detection models and fortifying unmanned\nretail environments against these attacks."}
{"id": "2505.09294", "pdf": "https://arxiv.org/pdf/2505.09294", "abs": "https://arxiv.org/abs/2505.09294", "authors": ["Fan Xu", "Wuyang Chen", "Wei Gao"], "title": "On the Learning with Augmented Class via Forests", "categories": ["cs.LG"], "comment": "Accepted by IJCAI 2025", "summary": "Decision trees and forests have achieved successes in various real\napplications, most working with all testing classes known in training data. In\nthis work, we focus on learning with augmented class via forests, where an\naugmented class may appear in testing data yet not in training data. We\nincorporate information of augmented class into trees' splitting, i.e., a new\nsplitting criterion, called augmented Gini impurity, is introduced to exploit\nsome unlabeled data from testing distribution. We then develop the approach\nnamed Learning with Augmented Class via Forests (LACForest), which constructs\nshallow forests based on the augmented Gini impurity and then splits forests\nwith pseudo-labeled augmented instances for better performance. We also develop\ndeep neural forests with a novel optimization objective based on our augmented\nGini impurity, so as to utilize the representation power of neural networks for\nforests. Theoretically, we present the convergence analysis for augmented Gini\nimpurity, and finally conduct experiments to verify the effectiveness of our\napproaches. The code is available at https://github.com/nju-xuf/LACForest/."}
{"id": "2505.09265", "pdf": "https://arxiv.org/pdf/2505.09265", "abs": "https://arxiv.org/abs/2505.09265", "authors": ["Bin-Bin Gao"], "title": "MetaUAS: Universal Anomaly Segmentation with One-Prompt Meta-Learning", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by NeurIPS 2024", "summary": "Zero- and few-shot visual anomaly segmentation relies on powerful\nvision-language models that detect unseen anomalies using manually designed\ntextual prompts. However, visual representations are inherently independent of\nlanguage. In this paper, we explore the potential of a pure visual foundation\nmodel as an alternative to widely used vision-language models for universal\nvisual anomaly segmentation. We present a novel paradigm that unifies anomaly\nsegmentation into change segmentation. This paradigm enables us to leverage\nlarge-scale synthetic image pairs, featuring object-level and local region\nchanges, derived from existing image datasets, which are independent of target\nanomaly datasets. We propose a one-prompt Meta-learning framework for Universal\nAnomaly Segmentation (MetaUAS) that is trained on this synthetic dataset and\nthen generalizes well to segment any novel or unseen visual anomalies in the\nreal world. To handle geometrical variations between prompt and query images,\nwe propose a soft feature alignment module that bridges paired-image change\nperception and single-image semantic segmentation. This is the first work to\nachieve universal anomaly segmentation using a pure vision model without\nrelying on special anomaly detection datasets and pre-trained visual-language\nmodels. Our method effectively and efficiently segments any anomalies with only\none normal image prompt and enjoys training-free without guidance from\nlanguage. Our MetaUAS significantly outperforms previous zero-shot, few-shot,\nand even full-shot anomaly segmentation methods. The code and pre-trained\nmodels are available at https://github.com/gaobb/MetaUAS."}
{"id": "2505.08838", "pdf": "https://arxiv.org/pdf/2505.08838", "abs": "https://arxiv.org/abs/2505.08838", "authors": ["Peixuan Ge", "Tongkun Su", "Faqin Lv", "Baoliang Zhao", "Peng Zhang", "Chi Hong Wong", "Liang Yao", "Yu Sun", "Zenan Wang", "Pak Kin Wong", "Ying Hu"], "title": "Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Ultrasound (US) report generation is a challenging task due to the\nvariability of US images, operator dependence, and the need for standardized\ntext. Unlike X-ray and CT, US imaging lacks consistent datasets, making\nautomation difficult. In this study, we propose a unified framework for\nmulti-organ and multilingual US report generation, integrating fragment-based\nmultilingual training and leveraging the standardized nature of US reports. By\naligning modular text fragments with diverse imaging data and curating a\nbilingual English-Chinese dataset, the method achieves consistent and\nclinically accurate text generation across organ sites and languages.\nFine-tuning with selective unfreezing of the vision transformer (ViT) further\nimproves text-image alignment. Compared to the previous state-of-the-art KMVE\nmethod, our approach achieves relative gains of about 2\\% in BLEU scores,\napproximately 3\\% in ROUGE-L, and about 15\\% in CIDEr, while significantly\nreducing errors such as missing or incorrect content. By unifying multi-organ\nand multi-language report generation into a single, scalable framework, this\nwork demonstrates strong potential for real-world clinical workflows."}
{"id": "2505.09308", "pdf": "https://arxiv.org/pdf/2505.09308", "abs": "https://arxiv.org/abs/2505.09308", "authors": ["George Andriopoulos", "Soyuj Jung Basnet", "Juan Guevara", "Li Guo", "Keith Ross"], "title": "Neural Multivariate Regression: Qualitative Insights from the Unconstrained Feature Model", "categories": ["cs.LG"], "comment": "31 pages, 8 figures", "summary": "The Unconstrained Feature Model (UFM) is a mathematical framework that\nenables closed-form approximations for minimal training loss and related\nperformance measures in deep neural networks (DNNs). This paper leverages the\nUFM to provide qualitative insights into neural multivariate regression, a\ncritical task in imitation learning, robotics, and reinforcement learning.\nSpecifically, we address two key questions: (1) How do multi-task models\ncompare to multiple single-task models in terms of training performance? (2)\nCan whitening and normalizing regression targets improve training performance?\nThe UFM theory predicts that multi-task models achieve strictly smaller\ntraining MSE than multiple single-task models when the same or stronger\nregularization is applied to the latter, and our empirical results confirm\nthese findings. Regarding whitening and normalizing regression targets, the UFM\ntheory predicts that they reduce training MSE when the average variance across\nthe target dimensions is less than one, and our empirical results once again\nconfirm these findings. These findings highlight the UFM as a powerful\nframework for deriving actionable insights into DNN design and data\npre-processing strategies."}
{"id": "2505.09274", "pdf": "https://arxiv.org/pdf/2505.09274", "abs": "https://arxiv.org/abs/2505.09274", "authors": ["Fares Bougourzi", "Abdenour Hadid"], "title": "Recent Advances in Medical Imaging Segmentation: A Survey", "categories": ["cs.CV"], "comment": null, "summary": "Medical imaging is a cornerstone of modern healthcare, driving advancements\nin diagnosis, treatment planning, and patient care. Among its various tasks,\nsegmentation remains one of the most challenging problem due to factors such as\ndata accessibility, annotation complexity, structural variability, variation in\nmedical imaging modalities, and privacy constraints. Despite recent progress,\nachieving robust generalization and domain adaptation remains a significant\nhurdle, particularly given the resource-intensive nature of some proposed\nmodels and their reliance on domain expertise. This survey explores\ncutting-edge advancements in medical image segmentation, focusing on\nmethodologies such as Generative AI, Few-Shot Learning, Foundation Models, and\nUniversal Models. These approaches offer promising solutions to longstanding\nchallenges. We provide a comprehensive overview of the theoretical foundations,\nstate-of-the-art techniques, and recent applications of these methods. Finally,\nwe discuss inherent limitations, unresolved issues, and future research\ndirections aimed at enhancing the practicality and accessibility of\nsegmentation models in medical imaging. We are maintaining a\n\\href{https://github.com/faresbougourzi/Awesome-DL-for-Medical-Imaging-Segmentation}{GitHub\nRepository} to continue tracking and updating innovations in this field."}
{"id": "2505.08841", "pdf": "https://arxiv.org/pdf/2505.08841", "abs": "https://arxiv.org/abs/2505.08841", "authors": ["Andrea Cremaschi", "Dae-Jin Lee", "Manuele Leonelli"], "title": "Will AI Take My Job? Evolving Perceptions of Automation and Labor Risk in Latin America", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "As artificial intelligence and robotics increasingly reshape the global labor\nmarket, understanding public perceptions of these technologies becomes\ncritical. We examine how these perceptions have evolved across Latin America,\nusing survey data from the 2017, 2018, 2020, and 2023 waves of the\nLatinobar\\'ometro. Drawing on responses from over 48,000 individuals across 16\ncountries, we analyze fear of job loss due to artificial intelligence and\nrobotics. Using statistical modeling and latent class analysis, we identify key\nstructural and ideological predictors of concern, with education level and\npolitical orientation emerging as the most consistent drivers. Our findings\nreveal substantial temporal and cross-country variation, with a notable peak in\nfear during 2018 and distinct attitudinal profiles emerging from latent\nsegmentation. These results offer new insights into the social and structural\ndimensions of AI anxiety in emerging economies and contribute to a broader\nunderstanding of public attitudes toward automation beyond the Global North."}
{"id": "2505.09331", "pdf": "https://arxiv.org/pdf/2505.09331", "abs": "https://arxiv.org/abs/2505.09331", "authors": ["Cunlai Pu", "Fangrui Wu", "Rajput Ramiz Sharafat", "Guangzhao Dai", "Xiangbo Shu"], "title": "MUST: Multi-Scale Structural-Temporal Link Prediction Model for UAV Ad Hoc Networks", "categories": ["cs.LG"], "comment": null, "summary": "Link prediction in unmanned aerial vehicle (UAV) ad hoc networks (UANETs)\naims to predict the potential formation of future links between UAVs. In\nadversarial environments where the route information of UAVs is unavailable,\npredicting future links must rely solely on the observed historical topological\ninformation of UANETs. However, the highly dynamic and sparse nature of UANET\ntopologies presents substantial challenges in effectively capturing meaningful\nstructural and temporal patterns for accurate link prediction. Most existing\nlink prediction methods focus on temporal dynamics at a single structural scale\nwhile neglecting the effects of sparsity, resulting in insufficient information\ncapture and limited applicability to UANETs. In this paper, we propose a\nmulti-scale structural-temporal link prediction model (MUST) for UANETs.\nSpecifically, we first employ graph attention networks (GATs) to capture\nstructural features at multiple levels, including the individual UAV level, the\nUAV community level, and the overall network level. Then, we use long\nshort-term memory (LSTM) networks to learn the temporal dynamics of these\nmulti-scale structural features. Additionally, we address the impact of\nsparsity by introducing a sophisticated loss function during model\noptimization. We validate the performance of MUST using several UANET datasets\ngenerated through simulations. Extensive experimental results demonstrate that\nMUST achieves state-of-the-art link prediction performance in highly dynamic\nand sparse UANETs."}
{"id": "2505.09306", "pdf": "https://arxiv.org/pdf/2505.09306", "abs": "https://arxiv.org/abs/2505.09306", "authors": ["Thijs L van der Plas", "Stephen Law", "Michael JO Pocock"], "title": "Predicting butterfly species presence from satellite imagery using soft contrastive regularisation", "categories": ["cs.CV", "cs.LG"], "comment": "To be published in the 2025 CVPR FGVC12 workshop", "summary": "The growing demand for scalable biodiversity monitoring methods has fuelled\ninterest in remote sensing data, due to its widespread availability and\nextensive coverage. Traditionally, the application of remote sensing to\nbiodiversity research has focused on mapping and monitoring habitats, but with\nincreasing availability of large-scale citizen-science wildlife observation\ndata, recent methods have started to explore predicting multi-species presence\ndirectly from satellite images. This paper presents a new data set for\npredicting butterfly species presence from satellite data in the United\nKingdom. We experimentally optimise a Resnet-based model to predict\nmulti-species presence from 4-band satellite images, and find that this model\nespecially outperforms the mean rate baseline for locations with high species\nbiodiversity. To improve performance, we develop a soft, supervised contrastive\nregularisation loss that is tailored to probabilistic labels (such as\nspecies-presence data), and demonstrate that this improves prediction accuracy.\nIn summary, our new data set and contrastive regularisation method contribute\nto the open challenge of accurately predicting species biodiversity from remote\nsensing data, which is key for efficient biodiversity monitoring."}
{"id": "2505.08844", "pdf": "https://arxiv.org/pdf/2505.08844", "abs": "https://arxiv.org/abs/2505.08844", "authors": ["Jiawen Chen", "Jianghao Zhang", "Huaxiu Yao", "Yun Li"], "title": "CellTypeAgent: Trustworthy cell type annotation with Large Language Models", "categories": ["q-bio.GN", "cs.AI", "68T20", "I.2.1"], "comment": null, "summary": "Cell type annotation is a critical yet laborious step in single-cell RNA\nsequencing analysis. We present a trustworthy large language model (LLM)-agent,\nCellTypeAgent, which integrates LLMs with verification from relevant databases.\nCellTypeAgent achieves higher accuracy than existing methods while mitigating\nhallucinations. We evaluated CellTypeAgent across nine real datasets involving\n303 cell types from 36 tissues. This combined approach holds promise for more\nefficient and reliable cell type annotation."}
{"id": "2505.09344", "pdf": "https://arxiv.org/pdf/2505.09344", "abs": "https://arxiv.org/abs/2505.09344", "authors": ["Gabriel Cortês", "Nuno Lourenço", "Paolo Romano", "Penousal Machado"], "title": "GreenFactory: Ensembling Zero-Cost Proxies to Estimate Performance of Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Determining the performance of a Deep Neural Network during Neural\nArchitecture Search processes is essential for identifying optimal\narchitectures and hyperparameters. Traditionally, this process requires\ntraining and evaluation of each network, which is time-consuming and\nresource-intensive. Zero-cost proxies estimate performance without training,\nserving as an alternative to traditional training. However, recent proxies\noften lack generalization across diverse scenarios and provide only relative\nrankings rather than predicted accuracies. To address these limitations, we\npropose GreenFactory, an ensemble of zero-cost proxies that leverages a random\nforest regressor to combine multiple predictors' strengths and directly predict\nmodel test accuracy. We evaluate GreenFactory on NATS-Bench, achieving robust\nresults across multiple datasets. Specifically, GreenFactory achieves high\nKendall correlations on NATS-Bench-SSS, indicating substantial agreement\nbetween its predicted scores and actual performance: 0.907 for CIFAR-10, 0.945\nfor CIFAR-100, and 0.920 for ImageNet-16-120. Similarly, on NATS-Bench-TSS, we\nachieve correlations of 0.921 for CIFAR-10, 0.929 for CIFAR-100, and 0.908 for\nImageNet-16-120, showcasing its reliability in both search spaces."}
{"id": "2505.09324", "pdf": "https://arxiv.org/pdf/2505.09324", "abs": "https://arxiv.org/abs/2505.09324", "authors": ["Lakshya Gupta", "Imran N. Junejo"], "title": "Neural Video Compression using 2D Gaussian Splatting", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "comment": "9 pages, 8 figures", "summary": "The computer vision and image processing research community has been involved\nin standardizing video data communications for the past many decades, leading\nto standards such as AVC, HEVC, VVC, AV1, AV2, etc. However, recent\ngroundbreaking works have focused on employing deep learning-based techniques\nto replace the traditional video codec pipeline to a greater affect. Neural\nvideo codecs (NVC) create an end-to-end ML-based solution that does not rely on\nany handcrafted features (motion or edge-based) and have the ability to learn\ncontent-aware compression strategies, offering better adaptability and higher\ncompression efficiency than traditional methods. This holds a great potential\nnot only for hardware design, but also for various video streaming platforms\nand applications, especially video conferencing applications such as MS-Teams\nor Zoom that have found extensive usage in classrooms and workplaces. However,\ntheir high computational demands currently limit their use in real-time\napplications like video conferencing. To address this, we propose a\nregion-of-interest (ROI) based neural video compression model that leverages 2D\nGaussian Splatting. Unlike traditional codecs, 2D Gaussian Splatting is capable\nof real-time decoding and can be optimized using fewer data points, requiring\nonly thousands of Gaussians for decent quality outputs as opposed to millions\nin 3D scenes. In this work, we designed a video pipeline that speeds up the\nencoding time of the previous Gaussian splatting-based image codec by 88% by\nusing a content-aware initialization strategy paired with a novel Gaussian\ninter-frame redundancy-reduction mechanism, enabling Gaussian splatting to be\nused for a video-codec solution, the first of its kind solution in this neural\nvideo codec space."}
{"id": "2505.08845", "pdf": "https://arxiv.org/pdf/2505.08845", "abs": "https://arxiv.org/abs/2505.08845", "authors": ["Misgina Tsighe Hagos", "Antti Suutala", "Dmitrii Bychkov", "Hakan Kücükel", "Joar von Bahr", "Milda Poceviciute", "Johan Lundin", "Nina Linder", "Claes Lundström"], "title": "Validation of Conformal Prediction in Cervical Atypia Classification", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Deep learning based cervical cancer classification can potentially increase\naccess to screening in low-resource regions. However, deep learning models are\noften overconfident and do not reliably reflect diagnostic uncertainty.\nMoreover, they are typically optimized to generate maximum-likelihood\npredictions, which fail to convey uncertainty or ambiguity in their results.\nSuch challenges can be addressed using conformal prediction, a model-agnostic\nframework for generating prediction sets that contain likely classes for\ntrained deep-learning models. The size of these prediction sets indicates model\nuncertainty, contracting as model confidence increases. However, existing\nconformal prediction evaluation primarily focuses on whether the prediction set\nincludes or covers the true class, often overlooking the presence of extraneous\nclasses. We argue that prediction sets should be truthful and valuable to end\nusers, ensuring that the listed likely classes align with human expectations\nrather than being overly relaxed and including false positives or unlikely\nclasses. In this study, we comprehensively validate conformal prediction sets\nusing expert annotation sets collected from multiple annotators. We evaluate\nthree conformal prediction approaches applied to three deep-learning models\ntrained for cervical atypia classification. Our expert annotation-based\nanalysis reveals that conventional coverage-based evaluations overestimate\nperformance and that current conformal prediction methods often produce\nprediction sets that are not well aligned with human labels. Additionally, we\nexplore the capabilities of the conformal prediction methods in identifying\nambiguous and out-of-distribution data."}
{"id": "2505.09354", "pdf": "https://arxiv.org/pdf/2505.09354", "abs": "https://arxiv.org/abs/2505.09354", "authors": ["Guangtai Wang", "Chi-Man Vong", "Jintao Huang"], "title": "Exploiting the Potential Supervision Information of Clean Samples in Partial Label Learning", "categories": ["cs.LG"], "comment": null, "summary": "Diminishing the impact of false-positive labels is critical for conducting\ndisambiguation in partial label learning. However, the existing disambiguation\nstrategies mainly focus on exploiting the characteristics of individual partial\nlabel instances while neglecting the strong supervision information of clean\nsamples randomly lying in the datasets. In this work, we show that clean\nsamples can be collected to offer guidance and enhance the confidence of the\nmost possible candidates. Motivated by the manner of the differentiable count\nloss strat- egy and the K-Nearest-Neighbor algorithm, we proposed a new\ncalibration strategy called CleanSE. Specifically, we attribute the most\nreliable candidates with higher significance under the assumption that for each\nclean sample, if its label is one of the candidates of its nearest neighbor in\nthe representation space, it is more likely to be the ground truth of its\nneighbor. Moreover, clean samples offer help in characterizing the sample\ndistributions by restricting the label counts of each label to a specific\ninterval. Extensive experiments on 3 synthetic benchmarks and 5 real-world PLL\ndatasets showed this calibration strategy can be applied to most of the\nstate-of-the-art PLL methods as well as enhance their performance."}
{"id": "2505.09329", "pdf": "https://arxiv.org/pdf/2505.09329", "abs": "https://arxiv.org/abs/2505.09329", "authors": ["Jiarun Liu", "Hong-Yu Zhou", "Weijian Huang", "Hao Yang", "Dongning Song", "Tao Tan", "Yong Liang", "Shanshan Wang"], "title": "BioVFM-21M: Benchmarking and Scaling Self-Supervised Vision Foundation Models for Biomedical Image Analysis", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 4 figures", "summary": "Scaling up model and data size have demonstrated impressive performance\nimprovement over a wide range of tasks. Despite extensive studies on scaling\nbehaviors for general-purpose tasks, medical images exhibit substantial\ndifferences from natural data. It remains unclear the key factors in developing\nmedical vision foundation models at scale due to the absence of an extensive\nunderstanding of scaling behavior in the medical domain. In this paper, we\nexplored the scaling behavior across model sizes, training algorithms, data\nsizes, and imaging modalities in developing scalable medical vision foundation\nmodels by self-supervised learning. To support scalable pretraining, we\nintroduce BioVFM-21M, a large-scale biomedical image dataset encompassing a\nwide range of biomedical image modalities and anatomies. We observed that\nscaling up does provide benefits but varies across tasks. Additional analysis\nreveals several factors correlated with scaling benefits. Finally, we propose\nBioVFM, a large-scale medical vision foundation model pretrained on 21 million\nbiomedical images, which outperforms the previous state-of-the-art foundation\nmodels across 12 medical benchmarks. Our results highlight that while scaling\nup is beneficial for pursuing better performance, task characteristics, data\ndiversity, pretraining methods, and computational efficiency remain critical\nconsiderations for developing scalable medical foundation models."}
{"id": "2505.08846", "pdf": "https://arxiv.org/pdf/2505.08846", "abs": "https://arxiv.org/abs/2505.08846", "authors": ["Felix Marti-Perez", "Brigt Håvardstun", "Cèsar Ferri", "Carlos Monserrat", "Jan Arne Telle"], "title": "Evaluating Simplification Algorithms for Interpretability of Time Series Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this work, we introduce metrics to evaluate the use of simplified time\nseries in the context of interpretability of a TSC - a Time Series Classifier.\nSuch simplifications are important because time series data, in contrast to\ntext and image data, are not intuitively understandable to humans. These\nmetrics are related to the complexity of the simplifications - how many\nsegments they contain - and to their loyalty - how likely they are to maintain\nthe classification of the original time series. We employ these metrics to\nevaluate four distinct simplification algorithms, across several TSC algorithms\nand across datasets of varying characteristics, from seasonal or stationary to\nshort or long. Our findings suggest that using simplifications for\ninterpretability of TSC is much better than using the original time series,\nparticularly when the time series are seasonal, non-stationary and/or with low\nentropy."}
{"id": "2505.09361", "pdf": "https://arxiv.org/pdf/2505.09361", "abs": "https://arxiv.org/abs/2505.09361", "authors": ["Samir Moustafa", "Nils M. Kriege", "Wilfried N. Gansterer"], "title": "Efficient Mixed Precision Quantization in Graph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have become essential for handling large-scale\ngraph applications. However, the computational demands of GNNs necessitate the\ndevelopment of efficient methods to accelerate inference. Mixed precision\nquantization emerges as a promising solution to enhance the efficiency of GNN\narchitectures without compromising prediction performance. Compared to\nconventional deep learning architectures, GNN layers contain a wider set of\ncomponents that can be quantized, including message passing functions,\naggregation functions, update functions, the inputs, learnable parameters, and\noutputs of these functions. In this paper, we introduce a theorem for efficient\nquantized message passing to aggregate integer messages. It guarantees\nnumerical equality of the aggregated messages using integer values with respect\nto those obtained with full (FP32) precision. Based on this theorem, we\nintroduce the Mixed Precision Quantization for GNN (MixQ-GNN) framework, which\nflexibly selects effective integer bit-widths for all components within GNN\nlayers. Our approach systematically navigates the wide set of possible\nbit-width combinations, addressing the challenge of optimizing efficiency while\naiming at maintaining comparable prediction performance. MixQ-GNN integrates\nwith existing GNN quantization methods, utilizing their graph structure\nadvantages to achieve higher prediction performance. On average, MixQ-GNN\nachieved reductions in bit operations of 5.5x for node classification and 5.1x\nfor graph classification compared to architectures represented in FP32\nprecision."}
{"id": "2505.09336", "pdf": "https://arxiv.org/pdf/2505.09336", "abs": "https://arxiv.org/abs/2505.09336", "authors": ["Muzammil Behzad"], "title": "Unsupervised Multiview Contrastive Language-Image Joint Learning with Pseudo-Labeled Prompts Via Vision-Language Model for 3D/4D Facial Expression Recognition", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we introduce MultiviewVLM, a vision-language model designed\nfor unsupervised contrastive multiview representation learning of facial\nemotions from 3D/4D data. Our architecture integrates pseudo-labels derived\nfrom generated textual prompts to guide implicit alignment of emotional\nsemantics. To capture shared information across multi-views, we propose a joint\nembedding space that aligns multiview representations without requiring\nexplicit supervision. We further enhance the discriminability of our model\nthrough a novel multiview contrastive learning strategy that leverages stable\npositive-negative pair sampling. A gradient-friendly loss function is\nintroduced to promote smoother and more stable convergence, and the model is\noptimized for distributed training to ensure scalability. Extensive experiments\ndemonstrate that MultiviewVLM outperforms existing state-of-the-art methods and\ncan be easily adapted to various real-world applications with minimal\nmodifications."}
{"id": "2505.08847", "pdf": "https://arxiv.org/pdf/2505.08847", "abs": "https://arxiv.org/abs/2505.08847", "authors": ["Fatima Ezzeddine", "Rinad Akel", "Ihab Sbeity", "Silvia Giordano", "Marc Langheinrich", "Omran Ayoub"], "title": "On the interplay of Explainability, Privacy and Predictive Performance with Explanation-assisted Model Extraction", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Machine Learning as a Service (MLaaS) has gained important attraction as a\nmeans for deploying powerful predictive models, offering ease of use that\nenables organizations to leverage advanced analytics without substantial\ninvestments in specialized infrastructure or expertise. However, MLaaS\nplatforms must be safeguarded against security and privacy attacks, such as\nmodel extraction (MEA) attacks. The increasing integration of explainable AI\n(XAI) within MLaaS has introduced an additional privacy challenge, as attackers\ncan exploit model explanations particularly counterfactual explanations (CFs)\nto facilitate MEA. In this paper, we investigate the trade offs among model\nperformance, privacy, and explainability when employing Differential Privacy\n(DP), a promising technique for mitigating CF facilitated MEA. We evaluate two\ndistinct DP strategies: implemented during the classification model training\nand at the explainer during CF generation."}
{"id": "2505.09366", "pdf": "https://arxiv.org/pdf/2505.09366", "abs": "https://arxiv.org/abs/2505.09366", "authors": ["SeyedMojtaba Mohasel", "Alireza Afzal Aghaei", "Corey Pew"], "title": "Personalized Control for Lower Limb Prosthesis Using Kolmogorov-Arnold Networks", "categories": ["cs.LG"], "comment": null, "summary": "Objective: This paper investigates the potential of learnable activation\nfunctions in Kolmogorov-Arnold Networks (KANs) for personalized control in a\nlower-limb prosthesis. In addition, user-specific vs. pooled training data is\nevaluated to improve machine learning (ML) and Deep Learning (DL) performance\nfor turn intent prediction.\n  Method: Inertial measurement unit (IMU) data from the shank were collected\nfrom five individuals with lower-limb amputation performing turning tasks in a\nlaboratory setting. Ability to classify an upcoming turn was evaluated for\nMultilayer Perceptron (MLP), Kolmogorov-Arnold Network (KAN), convolutional\nneural network (CNN), and fractional Kolmogorov-Arnold Networks (FKAN). The\ncomparison of MLP and KAN (for ML models) and FKAN and CNN (for DL models)\nassessed the effectiveness of learnable activation functions. Models were\ntrained separately on user-specific and pooled data to evaluate the impact of\ntraining data on their performance.\n  Results: Learnable activation functions in KAN and FKAN did not yield\nsignificant improvement compared to MLP and CNN, respectively. Training on\nuser-specific data yielded superior results compared to pooled data for ML\nmodels ($p < 0.05$). In contrast, no significant difference was observed\nbetween user-specific and pooled training for DL models.\n  Significance: These findings suggest that learnable activation functions may\ndemonstrate distinct advantages in datasets involving more complex tasks and\nlarger volumes. In addition, pooled training showed comparable performance to\nuser-specific training in DL models, indicating that model training for\nprosthesis control can utilize data from multiple participants."}
{"id": "2505.09358", "pdf": "https://arxiv.org/pdf/2505.09358", "abs": "https://arxiv.org/abs/2505.09358", "authors": ["Bingxin Ke", "Kevin Qu", "Tianfu Wang", "Nando Metzger", "Shengyu Huang", "Bo Li", "Anton Obukhov", "Konrad Schindler"], "title": "Marigold: Affordable Adaptation of Diffusion-Based Image Generators for Image Analysis", "categories": ["cs.CV", "cs.LG"], "comment": "Journal extension of our CVPR 2024 paper, featuring new tasks,\n  improved efficiency, high-resolution capabilities, and enhanced accessibility", "summary": "The success of deep learning in computer vision over the past decade has\nhinged on large labeled datasets and strong pretrained models. In data-scarce\nsettings, the quality of these pretrained models becomes crucial for effective\ntransfer learning. Image classification and self-supervised learning have\ntraditionally been the primary methods for pretraining CNNs and\ntransformer-based architectures. Recently, the rise of text-to-image generative\nmodels, particularly those using denoising diffusion in a latent space, has\nintroduced a new class of foundational models trained on massive, captioned\nimage datasets. These models' ability to generate realistic images of unseen\ncontent suggests they possess a deep understanding of the visual world. In this\nwork, we present Marigold, a family of conditional generative models and a\nfine-tuning protocol that extracts the knowledge from pretrained latent\ndiffusion models like Stable Diffusion and adapts them for dense image analysis\ntasks, including monocular depth estimation, surface normals prediction, and\nintrinsic decomposition. Marigold requires minimal modification of the\npre-trained latent diffusion model's architecture, trains with small synthetic\ndatasets on a single GPU over a few days, and demonstrates state-of-the-art\nzero-shot generalization. Project page:\nhttps://marigoldcomputervision.github.io"}
{"id": "2505.08849", "pdf": "https://arxiv.org/pdf/2505.08849", "abs": "https://arxiv.org/abs/2505.08849", "authors": ["Keyu Chen", "Hao Tang", "Qinglin Liu", "Yizhao Xu"], "title": "Improved Algorithms for Differentially Private Language Model Alignment", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Language model alignment is crucial for ensuring that large language models\n(LLMs) align with human preferences, yet it often involves sensitive user data,\nraising significant privacy concerns. While prior work has integrated\ndifferential privacy (DP) with alignment techniques, their performance remains\nlimited. In this paper, we propose novel algorithms for privacy-preserving\nalignment and rigorously analyze their effectiveness across varying privacy\nbudgets and models. Our framework can be deployed on two celebrated alignment\ntechniques, namely direct preference optimization (DPO) and reinforcement\nlearning from human feedback (RLHF). Through systematic experiments on\nlarge-scale language models, we demonstrate that our approach achieves\nstate-of-the-art performance. Notably, one of our algorithms, DP-AdamW,\ncombined with DPO, surpasses existing methods, improving alignment quality by\nup to 15% under moderate privacy budgets ({\\epsilon}=2-5). We further\ninvestigate the interplay between privacy guarantees, alignment efficacy, and\ncomputational demands, providing practical guidelines for optimizing these\ntrade-offs."}
{"id": "2505.09427", "pdf": "https://arxiv.org/pdf/2505.09427", "abs": "https://arxiv.org/abs/2505.09427", "authors": ["Achref Doula", "Max Mühläuser", "Alejandro Sanchez Guinea"], "title": "SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Large Language Models (LLMs) show growing promise in autonomous driving by\nreasoning over complex traffic scenarios to generate path plans. However, their\ntendencies toward overconfidence, and hallucinations raise critical safety\nconcerns. We introduce SafePath, a modular framework that augments LLM-based\npath planning with formal safety guarantees using conformal prediction.\nSafePath operates in three stages. In the first stage, we use an LLM that\ngenerates a set of diverse candidate paths, exploring possible trajectories\nbased on agent behaviors and environmental cues. In the second stage, SafePath\nfilters out high-risk trajectories while guaranteeing that at least one safe\noption is included with a user-defined probability, through a multiple-choice\nquestion-answering formulation that integrates conformal prediction. In the\nfinal stage, our approach selects the path with the lowest expected collision\nrisk when uncertainty is low or delegates control to a human when uncertainty\nis high. We theoretically prove that SafePath guarantees a safe trajectory with\na user-defined probability, and we show how its human delegation rate can be\ntuned to balance autonomy and safety. Extensive experiments on nuScenes and\nHighway-env show that SafePath reduces planning uncertainty by 77\\% and\ncollision rates by up to 70\\%, demonstrating effectiveness in making LLM-driven\npath planning more safer."}
{"id": "2505.09368", "pdf": "https://arxiv.org/pdf/2505.09368", "abs": "https://arxiv.org/abs/2505.09368", "authors": ["Jenny Schmalfuss", "Victor Oei", "Lukas Mehl", "Madlen Bartsch", "Shashank Agnihotri", "Margret Keuper", "Andrés Bruhn"], "title": "RobustSpring: Benchmarking Robustness to Image Corruptions for Optical Flow, Scene Flow and Stereo", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Standard benchmarks for optical flow, scene flow, and stereo vision\nalgorithms generally focus on model accuracy rather than robustness to image\ncorruptions like noise or rain. Hence, the resilience of models to such\nreal-world perturbations is largely unquantified. To address this, we present\nRobustSpring, a comprehensive dataset and benchmark for evaluating robustness\nto image corruptions for optical flow, scene flow, and stereo models.\nRobustSpring applies 20 different image corruptions, including noise, blur,\ncolor changes, quality degradations, and weather distortions, in a time-,\nstereo-, and depth-consistent manner to the high-resolution Spring dataset,\ncreating a suite of 20,000 corrupted images that reflect challenging\nconditions. RobustSpring enables comparisons of model robustness via a new\ncorruption robustness metric. Integration with the Spring benchmark enables\npublic two-axis evaluations of both accuracy and robustness. We benchmark a\ncurated selection of initial models, observing that accurate models are not\nnecessarily robust and that robustness varies widely by corruption type.\nRobustSpring is a new computer vision benchmark that treats robustness as a\nfirst-class citizen to foster models that combine accuracy with resilience. It\nwill be available at https://spring-benchmark.org."}
{"id": "2505.08854", "pdf": "https://arxiv.org/pdf/2505.08854", "abs": "https://arxiv.org/abs/2505.08854", "authors": ["Yuping Wang", "Shuo Xing", "Cui Can", "Renjie Li", "Hongyuan Hua", "Kexin Tian", "Zhaobin Mo", "Xiangbo Gao", "Keshu Wu", "Sulong Zhou", "Hengxu You", "Juntong Peng", "Junge Zhang", "Zehao Wang", "Rui Song", "Mingxuan Yan", "Walter Zimmer", "Xingcheng Zhou", "Peiran Li", "Zhaohan Lu", "Chia-Ju Chen", "Yue Huang", "Ryan A. Rossi", "Lichao Sun", "Hongkai Yu", "Zhiwen Fan", "Frank Hao Yang", "Yuhao Kang", "Ross Greer", "Chenxi Liu", "Eun Hak Lee", "Xuan Di", "Xinyue Ye", "Liu Ren", "Alois Knoll", "Xiaopeng Li", "Shuiwang Ji", "Masayoshi Tomizuka", "Marco Pavone", "Tianbao Yang", "Jing Du", "Ming-Hsuan Yang", "Hua Wei", "Ziran Wang", "Yang Zhou", "Jiachen Li", "Zhengzhong Tu"], "title": "Generative AI for Autonomous Driving: Frontiers and Opportunities", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Generative Artificial Intelligence (GenAI) constitutes a transformative\ntechnological wave that reconfigures industries through its unparalleled\ncapabilities for content creation, reasoning, planning, and multimodal\nunderstanding. This revolutionary force offers the most promising path yet\ntoward solving one of engineering's grandest challenges: achieving reliable,\nfully autonomous driving, particularly the pursuit of Level 5 autonomy. This\nsurvey delivers a comprehensive and critical synthesis of the emerging role of\nGenAI across the autonomous driving stack. We begin by distilling the\nprinciples and trade-offs of modern generative modeling, encompassing VAEs,\nGANs, Diffusion Models, and Large Language Models (LLMs). We then map their\nfrontier applications in image, LiDAR, trajectory, occupancy, video generation\nas well as LLM-guided reasoning and decision making. We categorize practical\napplications, such as synthetic data workflows, end-to-end driving strategies,\nhigh-fidelity digital twin systems, smart transportation networks, and\ncross-domain transfer to embodied AI. We identify key obstacles and\npossibilities such as comprehensive generalization across rare cases,\nevaluation and safety checks, budget-limited implementation, regulatory\ncompliance, ethical concerns, and environmental effects, while proposing\nresearch plans across theoretical assurances, trust metrics, transport\nintegration, and socio-technical influence. By unifying these threads, the\nsurvey provides a forward-looking reference for researchers, engineers, and\npolicymakers navigating the convergence of generative AI and advanced\nautonomous mobility. An actively maintained repository of cited works is\navailable at https://github.com/taco-group/GenAI4AD."}
{"id": "2505.09432", "pdf": "https://arxiv.org/pdf/2505.09432", "abs": "https://arxiv.org/abs/2505.09432", "authors": ["Yuzhou Cao", "Han Bao", "Lei Feng", "Bo An"], "title": "Establishing Linear Surrogate Regret Bounds for Convex Smooth Losses via Convolutional Fenchel-Young Losses", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Surrogate regret bounds, also known as excess risk bounds, bridge the gap\nbetween the convergence rates of surrogate and target losses, with linear\nbounds favorable for their lossless regret transfer. While convex smooth\nsurrogate losses are appealing in particular due to the efficient estimation\nand optimization, the existence of a trade-off between the smoothness and\nlinear regret bound has been believed in the community. That being said, the\nbetter optimization and estimation properties of convex smooth surrogate losses\nmay inevitably deteriorate after undergoing the regret transfer onto a target\nloss. We overcome this dilemma for arbitrary discrete target losses by\nconstructing a convex smooth surrogate loss, which entails a linear surrogate\nregret bound composed with a tailored prediction link. The construction is\nbased on Fenchel-Young losses generated by the convolutional negentropy, which\nare equivalent to the infimal convolution of a generalized negentropy and the\ntarget Bayes risk. Consequently, the infimal convolution enables us to derive a\nsmooth loss while maintaining the surrogate regret bound linear. We\nadditionally benefit from the infimal convolution to have a consistent\nestimator of the underlying class probability. Our results are overall a novel\ndemonstration of how convex analysis penetrates into optimization and\nstatistical efficiency in risk minimization."}
{"id": "2505.09372", "pdf": "https://arxiv.org/pdf/2505.09372", "abs": "https://arxiv.org/abs/2505.09372", "authors": ["Siyuan Yan", "Xieji Li", "Ming Hu", "Yiwen Jiang", "Zhen Yu", "Zongyuan Ge"], "title": "MAKE: Multi-Aspect Knowledge-Enhanced Vision-Language Pretraining for Zero-shot Dermatological Assessment", "categories": ["cs.CV"], "comment": "MICCAI2025 early acceptance; First two authors contribute equally", "summary": "Dermatological diagnosis represents a complex multimodal challenge that\nrequires integrating visual features with specialized clinical knowledge. While\nvision-language pretraining (VLP) has advanced medical AI, its effectiveness in\ndermatology is limited by text length constraints and the lack of structured\ntexts. In this paper, we introduce MAKE, a Multi-Aspect Knowledge-Enhanced\nvision-language pretraining framework for zero-shot dermatological tasks.\nRecognizing that comprehensive dermatological descriptions require multiple\nknowledge aspects that exceed standard text constraints, our framework\nintroduces: (1) a multi-aspect contrastive learning strategy that decomposes\nclinical narratives into knowledge-enhanced sub-texts through large language\nmodels, (2) a fine-grained alignment mechanism that connects subcaptions with\ndiagnostically relevant image features, and (3) a diagnosis-guided weighting\nscheme that adaptively prioritizes different sub-captions based on clinical\nsignificance prior. Through pretraining on 403,563 dermatological image-text\npairs collected from education resources, MAKE significantly outperforms\nstate-of-the-art VLP models on eight datasets across zero-shot skin disease\nclassification, concept annotation, and cross-modal retrieval tasks. Our code\nwill be made publicly available at https: //github.com/SiyuanYan1/MAKE."}
{"id": "2505.08878", "pdf": "https://arxiv.org/pdf/2505.08878", "abs": "https://arxiv.org/abs/2505.08878", "authors": ["Dor Tsur", "Carol Xuan Long", "Claudio Mayrink Verdun", "Hsiang Hsu", "Haim Permuter", "Flavio P. Calmon"], "title": "Optimized Couplings for Watermarking Large Language Models", "categories": ["cs.CR", "cs.AI", "cs.IT", "math.IT"], "comment": "Accepted at ISIT25", "summary": "Large-language models (LLMs) are now able to produce text that is, in many\ncases, seemingly indistinguishable from human-generated content. This has\nfueled the development of watermarks that imprint a ``signal'' in LLM-generated\ntext with minimal perturbation of an LLM's output. This paper provides an\nanalysis of text watermarking in a one-shot setting. Through the lens of\nhypothesis testing with side information, we formulate and analyze the\nfundamental trade-off between watermark detection power and distortion in\ngenerated textual quality. We argue that a key component in watermark design is\ngenerating a coupling between the side information shared with the watermark\ndetector and a random partition of the LLM vocabulary. Our analysis identifies\nthe optimal coupling and randomization strategy under the worst-case LLM\nnext-token distribution that satisfies a min-entropy constraint. We provide a\nclosed-form expression of the resulting detection rate under the proposed\nscheme and quantify the cost in a max-min sense. Finally, we provide an array\nof numerical results, comparing the proposed scheme with the theoretical\noptimum and existing schemes, in both synthetic data and LLM watermarking. Our\ncode is available at https://github.com/Carol-Long/CC_Watermark"}
{"id": "2505.09436", "pdf": "https://arxiv.org/pdf/2505.09436", "abs": "https://arxiv.org/abs/2505.09436", "authors": ["Raghav Garg", "Kapil Sharma", "Karan Gupta"], "title": "CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "comment": null, "summary": "Large Language Models (LLMs) hold immense potential for revolutionizing\nCustomer Experience Management (CXM), particularly in contact center\noperations. However, evaluating their practical utility in complex operational\nenvironments is hindered by data scarcity (due to privacy concerns) and the\nlimitations of current benchmarks. Existing benchmarks often lack realism,\nfailing to incorporate deep knowledge base (KB) integration, real-world noise,\nor critical operational tasks beyond conversational fluency. To bridge this\ngap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset\nspecifically designed for evaluating AI in operational CXM contexts. Given the\ndiversity in possible contact center features, we have developed a scalable\nLLM-powered pipeline that simulates the brand's CXM entities that form the\nfoundation of our datasets-such as knowledge articles including product\nspecifications, issue taxonomies, and contact center conversations. The\nentities closely represent real-world distribution because of controlled noise\ninjection (informed by domain experts) and rigorous automated validation.\nBuilding on this, we release CXMArena, which provides dedicated benchmarks\ntargeting five important operational tasks: Knowledge Base Refinement, Intent\nPrediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with\nIntegrated Tools. Our baseline experiments underscore the benchmark's\ndifficulty: even state of the art embedding and generation models achieve only\n68% accuracy on article search, while standard embedding methods yield a low F1\nscore of 0.3 for knowledge base refinement, highlighting significant challenges\nfor current models necessitating complex pipelines and solutions over\nconventional techniques."}
{"id": "2505.09379", "pdf": "https://arxiv.org/pdf/2505.09379", "abs": "https://arxiv.org/abs/2505.09379", "authors": ["Ali Rida Sahili", "Najett Neji", "Hedi Tabia"], "title": "Text-driven Motion Generation: Overview, Challenges and Directions", "categories": ["cs.CV"], "comment": "17 pages, 5 tables", "summary": "Text-driven motion generation offers a powerful and intuitive way to create\nhuman movements directly from natural language. By removing the need for\npredefined motion inputs, it provides a flexible and accessible approach to\ncontrolling animated characters. This makes it especially useful in areas like\nvirtual reality, gaming, human-computer interaction, and robotics. In this\nreview, we first revisit the traditional perspective on motion synthesis, where\nmodels focused on predicting future poses from observed initial sequences,\noften conditioned on action labels. We then provide a comprehensive and\nstructured survey of modern text-to-motion generation approaches, categorizing\nthem from two complementary perspectives: (i) architectural, dividing methods\ninto VAE-based, diffusion-based, and hybrid models; and (ii) motion\nrepresentation, distinguishing between discrete and continuous motion\ngeneration strategies. In addition, we explore the most widely used datasets,\nevaluation methods, and recent benchmarks that have shaped progress in this\narea. With this survey, we aim to capture where the field currently stands,\nbring attention to its key challenges and limitations, and highlight promising\ndirections for future exploration. We hope this work offers a valuable starting\npoint for researchers and practitioners working to push the boundaries of\nlanguage-driven human motion synthesis."}
{"id": "2505.08894", "pdf": "https://arxiv.org/pdf/2505.08894", "abs": "https://arxiv.org/abs/2505.08894", "authors": ["Hiba Eltigani", "Rukhshan Haroon", "Asli Kocak", "Abdullah Bin Faisal", "Noah Martin", "Fahad Dogar"], "title": "WaLLM -- Insights from an LLM-Powered Chatbot deployment via WhatsApp", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "Recent advances in generative AI, such as ChatGPT, have transformed access to\ninformation in education, knowledge-seeking, and everyday decision-making.\nHowever, in many developing regions, access remains a challenge due to the\npersistent digital divide. To help bridge this gap, we developed WaLLM - a\ncustom AI chatbot over WhatsApp, a widely used communication platform in\ndeveloping regions. Beyond answering queries, WaLLM offers several features to\nenhance user engagement: a daily top question, suggested follow-up questions,\ntrending and recent queries, and a leaderboard-based reward system. Our service\nhas been operational for over 6 months, amassing over 14.7K queries from\napproximately 100 users. In this paper, we present WaLLM's design and a\nsystematic analysis of logs to understand user interactions. Our results show\nthat 55% of user queries seek factual information. \"Health and well-being\" was\nthe most popular topic (28%), including queries about nutrition and disease,\nsuggesting users view WaLLM as a reliable source. Two-thirds of users' activity\noccurred within 24 hours of the daily top question. Users who accessed the\n\"Leaderboard\" interacted with WaLLM 3x as those who did not. We conclude by\ndiscussing implications for culture-based customization, user interface design,\nand appropriate calibration of users' trust in AI systems for developing\nregions."}
{"id": "2505.09458", "pdf": "https://arxiv.org/pdf/2505.09458", "abs": "https://arxiv.org/abs/2505.09458", "authors": ["Jad Mounayer", "Alicia Tierz", "Jerome Tomezyk", "Chady Ghnatios", "Francisco Chinesta"], "title": "Variational Rank Reduction Autoencoder", "categories": ["cs.LG"], "comment": null, "summary": "Deterministic Rank Reduction Autoencoders (RRAEs) enforce by construction a\nregularization on the latent space by applying a truncated SVD. While this\nregularization makes Autoencoders more powerful, using them for generative\npurposes is counter-intuitive due to their deterministic nature. On the other\nhand, Variational Autoencoders (VAEs) are well known for their generative\nabilities by learning a probabilistic latent space. In this paper, we present\nVariational Rank Reduction Autoencoders (VRRAEs), a model that leverages the\nadvantages of both RRAEs and VAEs. Our claims and results show that when\ncarefully sampling the latent space of RRAEs and further regularizing with the\nKullback-Leibler (KL) divergence (similarly to VAEs), VRRAEs outperform RRAEs\nand VAEs. Additionally, we show that the regularization induced by the SVD not\nonly makes VRRAEs better generators than VAEs, but also reduces the possibility\nof posterior collapse. Our results include a synthetic dataset of a small size\nthat showcases the robustness of VRRAEs against collapse, and three real-world\ndatasets; the MNIST, CelebA, and CIFAR-10, over which VRRAEs are shown to\noutperform both VAEs and RRAEs on many random generation and interpolation\ntasks based on the FID score."}
{"id": "2505.09380", "pdf": "https://arxiv.org/pdf/2505.09380", "abs": "https://arxiv.org/abs/2505.09380", "authors": ["Qinghui Liu", "Jon Nesvold", "Hanna Raaum", "Elakkyen Murugesu", "Martin Røvang", "Bradley J Maclntosh", "Atle Bjørnerud", "Karoline Skogen"], "title": "Examining Deployment and Refinement of the VIOLA-AI Intracranial Hemorrhage Model Using an Interactive NeoMedSys Platform", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "19 pages, 11 figures, on submission to BMC Methods", "summary": "Background: There are many challenges and opportunities in the clinical\ndeployment of AI tools in radiology. The current study describes a radiology\nsoftware platform called NeoMedSys that can enable efficient deployment and\nrefinements of AI models. We evaluated the feasibility and effectiveness of\nrunning NeoMedSys for three months in real-world clinical settings and focused\non improvement performance of an in-house developed AI model (VIOLA-AI)\ndesigned for intracranial hemorrhage (ICH) detection.\n  Methods: NeoMedSys integrates tools for deploying, testing, and optimizing AI\nmodels with a web-based medical image viewer, annotation system, and\nhospital-wide radiology information systems. A pragmatic investigation was\ndeployed using clinical cases of patients presenting to the largest Emergency\nDepartment in Norway (site-1) with suspected traumatic brain injury (TBI) or\npatients with suspected stroke (site-2). We assessed ICH classification\nperformance as VIOLA-AI encountered new data and underwent pre-planned model\nretraining. Performance metrics included sensitivity, specificity, accuracy,\nand the area under the receiver operating characteristic curve (AUC).\n  Results: NeoMedSys facilitated iterative improvements in the AI model,\nsignificantly enhancing its diagnostic accuracy. Automated bleed detection and\nsegmentation were reviewed in near real-time to facilitate re-training\nVIOLA-AI. The iterative refinement process yielded a marked improvement in\nclassification sensitivity, rising to 90.3% (from 79.2%), and specificity that\nreached 89.3% (from 80.7%). The bleed detection ROC analysis for the entire\nsample demonstrated a high area-under-the-curve (AUC) of 0.949 (from 0.873).\nModel refinement stages were associated with notable gains, highlighting the\nvalue of real-time radiologist feedback."}
{"id": "2505.08902", "pdf": "https://arxiv.org/pdf/2505.08902", "abs": "https://arxiv.org/abs/2505.08902", "authors": ["Lucas McCullum", "Pelagie Ami Agassi", "Leo Anthony Celi", "Daniel K. Ebner", "Chrystinne Oliveira Fernandes", "Rachel S. Hicklen", "Mkliwa Koumbia", "Lisa Soleymani Lehmann", "David Restrepo"], "title": "Performance Gains of LLMs With Humans in a World of LLMs Versus Humans", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": null, "summary": "Currently, a considerable research effort is devoted to comparing LLMs to a\ngroup of human experts, where the term \"expert\" is often ill-defined or\nvariable, at best, in a state of constantly updating LLM releases. Without\nproper safeguards in place, LLMs will threaten to cause harm to the established\nstructure of safe delivery of patient care which has been carefully developed\nthroughout history to keep the safety of the patient at the forefront. A key\ndriver of LLM innovation is founded on community research efforts which, if\ncontinuing to operate under \"humans versus LLMs\" principles, will expedite this\ntrend. Therefore, research efforts moving forward must focus on effectively\ncharacterizing the safe use of LLMs in clinical settings that persist across\nthe rapid development of novel LLM models. In this communication, we\ndemonstrate that rather than comparing LLMs to humans, there is a need to\ndevelop strategies enabling efficient work of humans with LLMs in an almost\nsymbiotic manner."}
{"id": "2505.09486", "pdf": "https://arxiv.org/pdf/2505.09486", "abs": "https://arxiv.org/abs/2505.09486", "authors": ["Seyed Roozbeh Razavi Rohani", "Khashayar Khajavi", "Wesley Chung", "Mo Chen", "Sharan Vaswani"], "title": "Preserving Plasticity in Continual Learning with Adaptive Linearity Injection", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in 4th Conference on Lifelong Learning Agents (CoLLAs), 2025", "summary": "Loss of plasticity in deep neural networks is the gradual reduction in a\nmodel's capacity to incrementally learn and has been identified as a key\nobstacle to learning in non-stationary problem settings. Recent work has shown\nthat deep linear networks tend to be resilient towards loss of plasticity.\nMotivated by this observation, we propose Adaptive Linearization (AdaLin), a\ngeneral approach that dynamically adapts each neuron's activation function to\nmitigate plasticity loss. Unlike prior methods that rely on regularization or\nperiodic resets, AdaLin equips every neuron with a learnable parameter and a\ngating mechanism that injects linearity into the activation function based on\nits gradient flow. This adaptive modulation ensures sufficient gradient signal\nand sustains continual learning without introducing additional hyperparameters\nor requiring explicit task boundaries. When used with conventional activation\nfunctions like ReLU, Tanh, and GeLU, we demonstrate that AdaLin can\nsignificantly improve performance on standard benchmarks, including Random\nLabel and Permuted MNIST, Random Label and Shuffled CIFAR-10, and Class-Split\nCIFAR-100. Furthermore, its efficacy is shown in more complex scenarios, such\nas class-incremental learning on CIFAR-100 with a ResNet-18 backbone, and in\nmitigating plasticity loss in off-policy reinforcement learning agents. We\nperform a systematic set of ablations that show that neuron-level adaptation is\ncrucial for good performance and analyze a number of metrics in the network\nthat might be correlated to loss of plasticity."}
{"id": "2505.09385", "pdf": "https://arxiv.org/pdf/2505.09385", "abs": "https://arxiv.org/abs/2505.09385", "authors": ["Xiaoyang Yu", "Xiaoming Wu", "Xin Wang", "Dongrun Li", "Ming Yang", "Peng Cheng"], "title": "FedSaaS: Class-Consistency Federated Semantic Segmentation via Global Prototype Supervision and Local Adversarial Harmonization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Federated semantic segmentation enables pixel-level classification in images\nthrough collaborative learning while maintaining data privacy. However,\nexisting research commonly overlooks the fine-grained class relationships\nwithin the semantic space when addressing heterogeneous problems, particularly\ndomain shift. This oversight results in ambiguities between class\nrepresentation. To overcome this challenge, we propose a novel federated\nsegmentation framework that strikes class consistency, termed FedSaaS.\nSpecifically, we introduce class exemplars as a criterion for both local- and\nglobal-level class representations. On the server side, the uploaded class\nexemplars are leveraged to model class prototypes, which supervise global\nbranch of clients, ensuring alignment with global-level representation. On the\nclient side, we incorporate an adversarial mechanism to harmonize contributions\nof global and local branches, leading to consistent output. Moreover,\nmultilevel contrastive losses are employed on both sides to enforce consistency\nbetween two-level representations in the same semantic space. Extensive\nexperiments on several driving scene segmentation datasets demonstrate that our\nframework outperforms state-of-the-art methods, significantly improving average\nsegmentation accuracy and effectively addressing the class-consistency\nrepresentation problem."}
{"id": "2505.08904", "pdf": "https://arxiv.org/pdf/2505.08904", "abs": "https://arxiv.org/abs/2505.08904", "authors": ["Varun Nagaraj Rao", "Samantha Dalal", "Andrew Schwartz", "Amna Liaqat", "Dana Calacci", "Andrés Monroy-Hernández"], "title": "FareShare: A Tool for Labor Organizers to Estimate Lost Wages and Contest Arbitrary AI and Algorithmic Deactivations", "categories": ["cs.CY", "cs.AI", "cs.ET", "cs.HC"], "comment": null, "summary": "What happens when a rideshare driver is suddenly locked out of the platform\nconnecting them to riders, wages, and daily work? Deactivation-the abrupt\nremoval of gig workers' platform access-typically occurs through arbitrary AI\nand algorithmic decisions with little explanation or recourse. This represents\none of the most severe forms of algorithmic control and often devastates\nworkers' financial stability. Recent U.S. state policies now mandate appeals\nprocesses and recovering compensation during the period of wrongful\ndeactivation based on past earnings. Yet, labor organizers still lack effective\ntools to support these complex, error-prone workflows. We designed FareShare, a\ncomputational tool automating lost wage estimation for deactivated drivers,\nthrough a 6 month partnership with the State of Washington's largest rideshare\nlabor union. Over the following 3 months, our field deployment of FareShare\nregistered 178 account signups. We observed that the tool could reduce lost\nwage calculation time by over 95%, eliminate manual data entry errors, and\nenable legal teams to generate arbitration-ready reports more efficiently.\nBeyond these gains, the deployment also surfaced important socio-technical\nchallenges around trust, consent, and tool adoption in high-stakes labor\ncontexts."}
{"id": "2505.09500", "pdf": "https://arxiv.org/pdf/2505.09500", "abs": "https://arxiv.org/abs/2505.09500", "authors": ["Timothy Qian", "Vinith Suriyakumar", "Ashia Wilson", "Dylan Hadfield-Menell"], "title": "Layered Unlearning for Adversarial Relearning", "categories": ["cs.LG"], "comment": "37 pages, 8 figures", "summary": "Our goal is to understand how post-training methods, such as fine-tuning,\nalignment, and unlearning, modify language model behavior and representations.\nWe are particularly interested in the brittle nature of these modifications\nthat makes them easy to bypass through prompt engineering or relearning. Recent\nresults suggest that post-training induces shallow context-dependent\n``circuits'' that suppress specific response patterns. This could be one\nexplanation for the brittleness of post-training. To test this hypothesis, we\ndesign an unlearning algorithm, Layered Unlearning (LU), that creates distinct\ninhibitory mechanisms for a growing subset of the data. By unlearning the first\n$i$ folds while retaining the remaining $k - i$ at the $i$th of $k$ stages, LU\nlimits the ability of relearning on a subset of data to recover the full\ndataset. We evaluate LU through a combination of synthetic and large language\nmodel (LLM) experiments. We find that LU improves robustness to adversarial\nrelearning for several different unlearning methods. Our results contribute to\nthe state-of-the-art of machine unlearning and provide insight into the effect\nof post-training updates."}
{"id": "2505.09406", "pdf": "https://arxiv.org/pdf/2505.09406", "abs": "https://arxiv.org/abs/2505.09406", "authors": ["Yue Wen", "Liang Song", "Yijia Liu", "Siting Zhu", "Yanzi Miao", "Lijun Han", "Hesheng Wang"], "title": "FreeDriveRF: Monocular RGB Dynamic NeRF without Poses for Autonomous Driving via Point-Level Dynamic-Static Decoupling", "categories": ["cs.CV"], "comment": "7 pages, 9 figures, accepted by ICRA2025", "summary": "Dynamic scene reconstruction for autonomous driving enables vehicles to\nperceive and interpret complex scene changes more precisely. Dynamic Neural\nRadiance Fields (NeRFs) have recently shown promising capability in scene\nmodeling. However, many existing methods rely heavily on accurate poses inputs\nand multi-sensor data, leading to increased system complexity. To address this,\nwe propose FreeDriveRF, which reconstructs dynamic driving scenes using only\nsequential RGB images without requiring poses inputs. We innovatively decouple\ndynamic and static parts at the early sampling level using semantic\nsupervision, mitigating image blurring and artifacts. To overcome the\nchallenges posed by object motion and occlusion in monocular camera, we\nintroduce a warped ray-guided dynamic object rendering consistency loss,\nutilizing optical flow to better constrain the dynamic modeling process.\nAdditionally, we incorporate estimated dynamic flow to constrain the pose\noptimization process, improving the stability and accuracy of unbounded scene\nreconstruction. Extensive experiments conducted on the KITTI and Waymo datasets\ndemonstrate the superior performance of our method in dynamic scene modeling\nfor autonomous driving."}
{"id": "2505.08916", "pdf": "https://arxiv.org/pdf/2505.08916", "abs": "https://arxiv.org/abs/2505.08916", "authors": ["Chan Le Duc", "Ludovic Brieulle"], "title": "A New Tractable Description Logic under Categorical Semantics", "categories": ["cs.LO", "cs.AI"], "comment": null, "summary": "Biomedical ontologies contain numerous concept or role names involving\nnegative knowledge such as lacks_part, absence_of. Such a representation with\nlabels rather than logical constructors would not allow a reasoner to interpret\nlacks_part as a kind of negation of has_part. It is known that adding negation\nto the tractable Description Logic (DL) EL allowing for conjunction,\nexistential restriction and concept inclusion makes it intractable since the\nobtained logic includes implicitly disjunction and universal restriction which\ninteract with other constructors. In this paper, we propose a new extension of\nEL with a weakened negation allowing to represent negative knowledge while\nretaining tractability. To this end, we introduce categorical semantics of all\nlogical constructors of the DL SH including EL with disjunction, negation,\nuniversal restriction, role inclusion and transitive roles. The categorical\nsemantics of a logical constructor is usually described as a set of categorical\nproperties referring to several objects without using set membership. To\nrestore tractability, we have to weaken semantics of disjunction and universal\nrestriction by identifying \\emph{independent} categorical properties that are\nresponsible for intractability, and dropping them from the set of categorical\nproperties. We show that the logic resulting from weakening semantics is more\nexpressive than EL with the bottom concept, transitive roles and role\ninclusion."}
{"id": "2505.09503", "pdf": "https://arxiv.org/pdf/2505.09503", "abs": "https://arxiv.org/abs/2505.09503", "authors": ["Patrik Kenfack", "Samira Ebrahimi Kahou", "Ulrich Aïvodji"], "title": "Towards Fair In-Context Learning with Tabular Foundation Models", "categories": ["cs.LG"], "comment": "24 pages, 10 figures, 4 tables", "summary": "Tabular foundational models have exhibited strong in-context learning (ICL)\ncapabilities on structured data, allowing them to make accurate predictions on\ntest sets without parameter updates, using training examples as context. This\nemerging approach positions itself as a competitive alternative to traditional\ngradient-boosted tree methods. However, while biases in conventional machine\nlearning models are well documented, it remains unclear how these biases\nmanifest in tabular ICL. The paper investigates the fairness implications of\ntabular ICL and explores three preprocessing strategies--correlation removal,\ngroup-balanced demonstration selection, and uncertainty-based demonstration\nselection--to address bias. Comprehensive experiments indicate that\nuncertainty-based demonstration selection consistently enhances group fairness\nof in-context predictions. The source code for reproducing the results of this\nwork can be found at https://github.com/patrikken/Fair-TabICL."}
{"id": "2505.09413", "pdf": "https://arxiv.org/pdf/2505.09413", "abs": "https://arxiv.org/abs/2505.09413", "authors": ["Ma Changfeng", "Bi Ran", "Guo Jie", "Wang Chongjun", "Guo Yanwen"], "title": "Sparse Point Cloud Patches Rendering via Splitting 2D Gaussians", "categories": ["cs.CV"], "comment": "CVPR 2025 Accepted", "summary": "Current learning-based methods predict NeRF or 3D Gaussians from point clouds\nto achieve photo-realistic rendering but still depend on categorical priors,\ndense point clouds, or additional refinements. Hence, we introduce a novel\npoint cloud rendering method by predicting 2D Gaussians from point clouds. Our\nmethod incorporates two identical modules with an entire-patch architecture\nenabling the network to be generalized to multiple datasets. The module\nnormalizes and initializes the Gaussians utilizing the point cloud information\nincluding normals, colors and distances. Then, splitting decoders are employed\nto refine the initial Gaussians by duplicating them and predicting more\naccurate results, making our methodology effectively accommodate sparse point\nclouds as well. Once trained, our approach exhibits direct generalization to\npoint clouds across different categories. The predicted Gaussians are employed\ndirectly for rendering without additional refinement on the rendered images,\nretaining the benefits of 2D Gaussians. We conduct extensive experiments on\nvarious datasets, and the results demonstrate the superiority and\ngeneralization of our method, which achieves SOTA performance. The code is\navailable at\nhttps://github.com/murcherful/GauPCRender}{https://github.com/murcherful/GauPCRender."}
{"id": "2505.08918", "pdf": "https://arxiv.org/pdf/2505.08918", "abs": "https://arxiv.org/abs/2505.08918", "authors": ["Marina Popova", "Iaroslav Chelombitko", "Aleksey Komissarov"], "title": "When repeats drive the vocabulary: a Byte-Pair Encoding analysis of T2T primate genomes", "categories": ["q-bio.GN", "cs.AI"], "comment": "ICLR 2025 Workshop on Machine Learning for Genomics Explorations", "summary": "The emergence of telomere-to-telomere (T2T) genome assemblies has opened new\navenues for comparative genomics, yet effective tokenization strategies for\ngenomic sequences remain underexplored. In this pilot study, we apply Byte Pair\nEncoding (BPE) to nine T2T primate genomes including three human assemblies by\ntraining independent BPE tokenizers with a fixed vocabulary of 512,000 tokens\nusing our custom tool, dnaBPE. Our analysis reveals that only 11,569 tokens are\nshared across all assemblies, while nearly 991,854 tokens are unique to a\nsingle genome, indicating a rapid decline in shared vocabulary with increasing\nassembly comparisons. Moreover, phylogenetic trees derived from token overlap\nfailed to recapitulate established primate relationships, a discrepancy\nattributed to the disproportionate influence of species-specific high-copy\nrepetitive elements. These findings underscore the dual nature of BPE\ntokenization: while it effectively compresses repetitive sequences, its\nsensitivity to high-copy elements limits its utility as a universal tool for\ncomparative genomics. We discuss potential hybrid strategies and repeat-masking\napproaches to refine genomic tokenization, emphasizing the need for\ndomain-specific adaptations in the development of large-scale genomic language\nmodels. The dnaBPE tool used in this study is open-source and available at\nhttps://github.com/aglabx/dnaBPE."}
{"id": "2505.09572", "pdf": "https://arxiv.org/pdf/2505.09572", "abs": "https://arxiv.org/abs/2505.09572", "authors": ["Julian Kranz", "Davide Gallon", "Steffen Dereich", "Arnulf Jentzen"], "title": "SAD Neural Networks: Divergent Gradient Flows and Asymptotic Optimality via o-minimal Structures", "categories": ["cs.LG", "math.LO", "math.OC", "stat.ML", "Primary 68T05, Secondary 68T07, 26B40, 03C64, 03C98"], "comment": "27 pages, 4 figures", "summary": "We study gradient flows for loss landscapes of fully connected feed forward\nneural networks with commonly used continuously differentiable activation\nfunctions such as the logistic, hyperbolic tangent, softplus or GELU function.\nWe prove that the gradient flow either converges to a critical point or\ndiverges to infinity while the loss converges to an asymptotic critical value.\nMoreover, we prove the existence of a threshold $\\varepsilon>0$ such that the\nloss value of any gradient flow initialized at most $\\varepsilon$ above the\noptimal level converges to it. For polynomial target functions and sufficiently\nbig architecture and data set, we prove that the optimal loss value is zero and\ncan only be realized asymptotically. From this setting, we deduce our main\nresult that any gradient flow with sufficiently good initialization diverges to\ninfinity. Our proof heavily relies on the geometry of o-minimal structures. We\nconfirm these theoretical findings with numerical experiments and extend our\ninvestigation to real-world scenarios, where we observe an analogous behavior."}
{"id": "2505.09415", "pdf": "https://arxiv.org/pdf/2505.09415", "abs": "https://arxiv.org/abs/2505.09415", "authors": ["Hongyang Wang", "Yichen Shi", "Zhuofu Tao", "Yuhao Gao", "Liepiao Zhang", "Xun Lin", "Jun Feng", "Xiaochen Yuan", "Zitong Yu", "Xiaochun Cao"], "title": "FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Face anti-spoofing (FAS) is crucial for protecting facial recognition systems\nfrom presentation attacks. Previous methods approached this task as a\nclassification problem, lacking interpretability and reasoning behind the\npredicted results. Recently, multimodal large language models (MLLMs) have\nshown strong capabilities in perception, reasoning, and decision-making in\nvisual tasks. However, there is currently no universal and comprehensive MLLM\nand dataset specifically designed for FAS task. To address this gap, we propose\nFaceShield, a MLLM for FAS, along with the corresponding pre-training and\nsupervised fine-tuning (SFT) datasets, FaceShield-pre10K and FaceShield-sft45K.\nFaceShield is capable of determining the authenticity of faces, identifying\ntypes of spoofing attacks, providing reasoning for its judgments, and detecting\nattack areas. Specifically, we employ spoof-aware vision perception (SAVP) that\nincorporates both the original image and auxiliary information based on prior\nknowledge. We then use an prompt-guided vision token masking (PVTM) strategy to\nrandom mask vision tokens, thereby improving the model's generalization\nability. We conducted extensive experiments on three benchmark datasets,\ndemonstrating that FaceShield significantly outperforms previous deep learning\nmodels and general MLLMs on four FAS tasks, i.e., coarse-grained\nclassification, fine-grained classification, reasoning, and attack\nlocalization. Our instruction datasets, protocols, and codes will be released\nsoon."}
{"id": "2505.08919", "pdf": "https://arxiv.org/pdf/2505.08919", "abs": "https://arxiv.org/abs/2505.08919", "authors": ["Kangxian Xie", "Yufei Zhu", "Kaiming Kuang", "Li Zhang", "Hongwei Bran Li", "Mingchen Gao", "Jiancheng Yang"], "title": "Template-Guided Reconstruction of Pulmonary Segments with Neural Implicit Functions", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "In revision process", "summary": "High-quality 3D reconstruction of pulmonary segments plays a crucial role in\nsegmentectomy and surgical treatment planning for lung cancer. Due to the\nresolution requirement of the target reconstruction, conventional deep\nlearning-based methods often suffer from computational resource constraints or\nlimited granularity. Conversely, implicit modeling is favored due to its\ncomputational efficiency and continuous representation at any resolution. We\npropose a neural implicit function-based method to learn a 3D surface to\nachieve anatomy-aware, precise pulmonary segment reconstruction, represented as\na shape by deforming a learnable template. Additionally, we introduce two\nclinically relevant evaluation metrics to assess the reconstruction\ncomprehensively. Further, due to the absence of publicly available shape\ndatasets to benchmark reconstruction algorithms, we developed a shape dataset\nnamed Lung3D, including the 3D models of 800 labeled pulmonary segments and the\ncorresponding airways, arteries, veins, and intersegmental veins. We\ndemonstrate that the proposed approach outperforms existing methods, providing\na new perspective for pulmonary segment reconstruction. Code and data will be\navailable at https://github.com/M3DV/ImPulSe."}
{"id": "2505.09586", "pdf": "https://arxiv.org/pdf/2505.09586", "abs": "https://arxiv.org/abs/2505.09586", "authors": ["Yipeng Zhang", "Longlong Li", "Kelin Xia"], "title": "Rhomboid Tiling for Geometric Graph Deep Learning", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have proven effective for learning from\ngraph-structured data through their neighborhood-based message passing\nframework. Many hierarchical graph clustering pooling methods modify this\nframework by introducing clustering-based strategies, enabling the construction\nof more expressive and powerful models. However, all of these message passing\nframework heavily rely on the connectivity structure of graphs, limiting their\nability to capture the rich geometric features inherent in geometric graphs. To\naddress this, we propose Rhomboid Tiling (RT) clustering, a novel clustering\nmethod based on the rhomboid tiling structure, which performs clustering by\nleveraging the complex geometric information of the data and effectively\nextracts its higher-order geometric structures. Moreover, we design RTPool, a\nhierarchical graph clustering pooling model based on RT clustering for graph\nclassification tasks. The proposed model demonstrates superior performance,\noutperforming 21 state-of-the-art competitors on all the 7 benchmark datasets."}
{"id": "2505.09422", "pdf": "https://arxiv.org/pdf/2505.09422", "abs": "https://arxiv.org/abs/2505.09422", "authors": ["Xiangyuan Peng", "Yu Wang", "Miao Tang", "Bierzynski Kay", "Lorenzo Servadei", "Robert Wille"], "title": "MoRAL: Motion-aware Multi-Frame 4D Radar and LiDAR Fusion for Robust 3D Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Reliable autonomous driving systems require accurate detection of traffic\nparticipants. To this end, multi-modal fusion has emerged as an effective\nstrategy. In particular, 4D radar and LiDAR fusion methods based on multi-frame\nradar point clouds have demonstrated the effectiveness in bridging the point\ndensity gap. However, they often neglect radar point clouds' inter-frame\nmisalignment caused by object movement during accumulation and do not fully\nexploit the object dynamic information from 4D radar. In this paper, we propose\nMoRAL, a motion-aware multi-frame 4D radar and LiDAR fusion framework for\nrobust 3D object detection. First, a Motion-aware Radar Encoder (MRE) is\ndesigned to compensate for inter-frame radar misalignment from moving objects.\nLater, a Motion Attention Gated Fusion (MAGF) module integrate radar motion\nfeatures to guide LiDAR features to focus on dynamic foreground objects.\nExtensive evaluations on the View-of-Delft (VoD) dataset demonstrate that MoRAL\noutperforms existing methods, achieving the highest mAP of 73.30% in the entire\narea and 88.68% in the driving corridor. Notably, our method also achieves the\nbest AP of 69.67% for pedestrians in the entire area and 96.25% for cyclists in\nthe driving corridor."}
{"id": "2505.08939", "pdf": "https://arxiv.org/pdf/2505.08939", "abs": "https://arxiv.org/abs/2505.08939", "authors": ["Suchismita Naik", "Prakash Shukla", "Ike Obi", "Jessica Backus", "Nancy Rasche", "Paul Parsons"], "title": "Tracing the Invisible: Understanding Students' Judgment in AI-Supported Design Work", "categories": ["cs.HC", "cs.AI"], "comment": "5 pages, 2 Tables, In Creativity and Cognition 2025, June 23--25,\n  2025, Virtual, United Kingdom", "summary": "As generative AI tools become integrated into design workflows, students\nincreasingly engage with these tools not just as aids, but as collaborators.\nThis study analyzes reflections from 33 student teams in an HCI design course\nto examine the kinds of judgments students make when using AI tools. We found\nboth established forms of design judgment (e.g., instrumental, appreciative,\nquality) and emergent types: agency-distribution judgment and reliability\njudgment. These new forms capture how students negotiate creative\nresponsibility with AI and assess the trustworthiness of its outputs. Our\nfindings suggest that generative AI introduces new layers of complexity into\ndesign reasoning, prompting students to reflect not only on what AI produces,\nbut also on how and when to rely on it. By foregrounding these judgments, we\noffer a conceptual lens for understanding how students engage in co-creative\nsensemaking with AI in design contexts."}
{"id": "2505.09593", "pdf": "https://arxiv.org/pdf/2505.09593", "abs": "https://arxiv.org/abs/2505.09593", "authors": ["Filippo Leveni", "Guilherme Weigert Cassales", "Bernhard Pfahringer", "Albert Bifet", "Giacomo Boracchi"], "title": "Online Isolation Forest", "categories": ["cs.LG"], "comment": "Accepted at International Conference on Machine Learning (ICML 2024)", "summary": "The anomaly detection literature is abundant with offline methods, which\nrequire repeated access to data in memory, and impose impractical assumptions\nwhen applied to a streaming context. Existing online anomaly detection methods\nalso generally fail to address these constraints, resorting to periodic\nretraining to adapt to the online context. We propose Online-iForest, a novel\nmethod explicitly designed for streaming conditions that seamlessly tracks the\ndata generating process as it evolves over time. Experimental validation on\nreal-world datasets demonstrated that Online-iForest is on par with online\nalternatives and closely rivals state-of-the-art offline anomaly detection\ntechniques that undergo periodic retraining. Notably, Online-iForest\nconsistently outperforms all competitors in terms of efficiency, making it a\npromising solution in applications where fast identification of anomalies is of\nprimary importance such as cybersecurity, fraud and fault detection."}
{"id": "2505.09433", "pdf": "https://arxiv.org/pdf/2505.09433", "abs": "https://arxiv.org/abs/2505.09433", "authors": ["Jiahao Zhu", "Kang You", "Dandan Ding", "Zhan Ma"], "title": "Efficient LiDAR Reflectance Compression via Scanning Serialization", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Reflectance attributes in LiDAR point clouds provide essential information\nfor downstream tasks but remain underexplored in neural compression methods. To\naddress this, we introduce SerLiC, a serialization-based neural compression\nframework to fully exploit the intrinsic characteristics of LiDAR reflectance.\nSerLiC first transforms 3D LiDAR point clouds into 1D sequences via scan-order\nserialization, offering a device-centric perspective for reflectance analysis.\nEach point is then tokenized into a contextual representation comprising its\nsensor scanning index, radial distance, and prior reflectance, for effective\ndependencies exploration. For efficient sequential modeling, Mamba is\nincorporated with a dual parallelization scheme, enabling simultaneous\nautoregressive dependency capture and fast processing. Extensive experiments\ndemonstrate that SerLiC attains over 2x volume reduction against the original\nreflectance data, outperforming the state-of-the-art method by up to 22%\nreduction of compressed bits while using only 2% of its parameters. Moreover, a\nlightweight version of SerLiC achieves > 10 fps (frames per second) with just\n111K parameters, which is attractive for real-world applications."}
{"id": "2505.08964", "pdf": "https://arxiv.org/pdf/2505.08964", "abs": "https://arxiv.org/abs/2505.08964", "authors": ["Majed Jaber", "Julien Michel", "Nicolas Boutry", "Pierre Parrend"], "title": "GPML: Graph Processing for Machine Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "The dramatic increase of complex, multi-step, and rapidly evolving attacks in\ndynamic networks involves advanced cyber-threat detectors. The GPML (Graph\nProcessing for Machine Learning) library addresses this need by transforming\nraw network traffic traces into graph representations, enabling advanced\ninsights into network behaviors. The library provides tools to detect anomalies\nin interaction and community shifts in dynamic networks. GPML supports\ncommunity and spectral metrics extraction, enhancing both real-time detection\nand historical forensics analysis. This library supports modern cybersecurity\nchallenges with a robust, graph-based approach."}
{"id": "2505.09602", "pdf": "https://arxiv.org/pdf/2505.09602", "abs": "https://arxiv.org/abs/2505.09602", "authors": ["David Khachaturov", "Robert Mullins"], "title": "Adversarial Suffix Filtering: a Defense Pipeline for LLMs", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly embedded in autonomous systems\nand public-facing environments, yet they remain susceptible to jailbreak\nvulnerabilities that may undermine their security and trustworthiness.\nAdversarial suffixes are considered to be the current state-of-the-art\njailbreak, consistently outperforming simpler methods and frequently succeeding\neven in black-box settings. Existing defenses rely on access to the internal\narchitecture of models limiting diverse deployment, increase memory and\ncomputation footprints dramatically, or can be bypassed with simple prompt\nengineering methods. We introduce $\\textbf{Adversarial Suffix Filtering}$\n(ASF), a lightweight novel model-agnostic defensive pipeline designed to\nprotect LLMs against adversarial suffix attacks. ASF functions as an input\npreprocessor and sanitizer that detects and filters adversarially crafted\nsuffixes in prompts, effectively neutralizing malicious injections. We\ndemonstrate that ASF provides comprehensive defense capabilities across both\nblack-box and white-box attack settings, reducing the attack efficacy of\nstate-of-the-art adversarial suffix generation methods to below 4%, while only\nminimally affecting the target model's capabilities in non-adversarial\nscenarios."}
{"id": "2505.09435", "pdf": "https://arxiv.org/pdf/2505.09435", "abs": "https://arxiv.org/abs/2505.09435", "authors": ["Yili He", "Yan Zhu", "Peiyao Fu", "Ruijie Yang", "Tianyi Chen", "Zhihua Wang", "Quanlin Li", "Pinghong Zhou", "Xian Yang", "Shuo Wang"], "title": "Endo-CLIP: Progressive Self-Supervised Pre-training on Raw Colonoscopy Records", "categories": ["cs.CV", "cs.AI"], "comment": "Early accepted to MICCAI 2025", "summary": "Pre-training on image-text colonoscopy records offers substantial potential\nfor improving endoscopic image analysis, but faces challenges including\nnon-informative background images, complex medical terminology, and ambiguous\nmulti-lesion descriptions. We introduce Endo-CLIP, a novel self-supervised\nframework that enhances Contrastive Language-Image Pre-training (CLIP) for this\ndomain. Endo-CLIP's three-stage framework--cleansing, attunement, and\nunification--addresses these challenges by (1) removing background frames, (2)\nleveraging large language models to extract clinical attributes for\nfine-grained contrastive learning, and (3) employing patient-level\ncross-attention to resolve multi-polyp ambiguities. Extensive experiments\ndemonstrate that Endo-CLIP significantly outperforms state-of-the-art\npre-training methods in zero-shot and few-shot polyp detection and\nclassification, paving the way for more accurate and clinically relevant\nendoscopic analysis."}
{"id": "2505.09003", "pdf": "https://arxiv.org/pdf/2505.09003", "abs": "https://arxiv.org/abs/2505.09003", "authors": ["Zeki Doruk Erden", "Donia Gasmi", "Boi Faltings"], "title": "Continual Reinforcement Learning via Autoencoder-Driven Task and New Environment Recognition", "categories": ["cs.LG", "cs.AI"], "comment": "Published in the Autonomous Robots and Multirobot Systems (ARMS)\n  workshop at AAMAS 2025", "summary": "Continual learning for reinforcement learning agents remains a significant\nchallenge, particularly in preserving and leveraging existing information\nwithout an external signal to indicate changes in tasks or environments. In\nthis study, we explore the effectiveness of autoencoders in detecting new tasks\nand matching observed environments to previously encountered ones. Our approach\nintegrates policy optimization with familiarity autoencoders within an\nend-to-end continual learning system. This system can recognize and learn new\ntasks or environments while preserving knowledge from earlier experiences and\ncan selectively retrieve relevant knowledge when re-encountering a known\nenvironment. Initial results demonstrate successful continual learning without\nexternal signals to indicate task changes or reencounters, showing promise for\nthis methodology."}
{"id": "2505.07363", "pdf": "https://arxiv.org/pdf/2505.07363", "abs": "https://arxiv.org/abs/2505.07363", "authors": ["Serge Massar"], "title": "Equilibrium Propagation for Learning in Lagrangian Dynamical Systems", "categories": ["nlin.CD", "cs.LG", "physics.data-an"], "comment": "8 pages, 1 figure", "summary": "We propose a method for training dynamical systems governed by Lagrangian\nmechanics using Equilibrium Propagation. Our approach extends Equilibrium\nPropagation -- initially developed for energy-based models -- to dynamical\ntrajectories by leveraging the principle of action extremization. Training is\nachieved by gently nudging trajectories toward desired targets and measuring\nhow the variables conjugate to the parameters to be trained respond. This\nmethod is particularly suited to systems with periodic boundary conditions or\nfixed initial and final states, enabling efficient parameter updates without\nrequiring explicit backpropagation through time. In the case of periodic\nboundary conditions, this approach yields the semiclassical limit of Quantum\nEquilibrium Propagation. Applications to systems with dissipation are also\ndiscussed."}
{"id": "2505.09450", "pdf": "https://arxiv.org/pdf/2505.09450", "abs": "https://arxiv.org/abs/2505.09450", "authors": ["Yuelin Zhang", "Qingpeng Ding", "Long Lei", "Yongxuan Feng", "Raymond Shing-Yan Tang", "Shing Shin Cheng"], "title": "MrTrack: Register Mamba for Needle Tracking with Rapid Reciprocating Motion during Ultrasound-Guided Aspiration Biopsy", "categories": ["cs.CV"], "comment": "Early Accepted by MICCAI 2025", "summary": "Ultrasound-guided fine needle aspiration (FNA) biopsy is a common minimally\ninvasive diagnostic procedure. However, an aspiration needle tracker addressing\nrapid reciprocating motion is still missing. MrTrack, an aspiration needle\ntracker with a mamba-based register mechanism, is proposed. MrTrack leverages a\nMamba-based register extractor to sequentially distill global context from each\nhistorical search map, storing these temporal cues in a register bank. The\nMamba-based register retriever then retrieves temporal prompts from the\nregister bank to provide external cues when current vision features are\ntemporarily unusable due to rapid reciprocating motion and imaging degradation.\nA self-supervised register diversify loss is proposed to encourage feature\ndiversity and dimension independence within the learned register, mitigating\nfeature collapse. Comprehensive experiments conducted on both motorized and\nmanual aspiration datasets demonstrate that MrTrack not only outperforms\nstate-of-the-art trackers in accuracy and robustness but also achieves superior\ninference efficiency."}
{"id": "2505.09021", "pdf": "https://arxiv.org/pdf/2505.09021", "abs": "https://arxiv.org/abs/2505.09021", "authors": ["Maria Dhakal", "Chia-Yi Su", "Robert Wallace", "Chris Fakhimi", "Aakash Bansal", "Toby Li", "Yu Huang", "Collin McMillan"], "title": "AI-Mediated Code Comment Improvement", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "This paper describes an approach to improve code comments along different\nquality axes by rewriting those comments with customized Artificial\nIntelligence (AI)-based tools. We conduct an empirical study followed by\ngrounded theory qualitative analysis to determine the quality axes to improve.\nThen we propose a procedure using a Large Language Model (LLM) to rewrite\nexisting code comments along the quality axes. We implement our procedure using\nGPT-4o, then distil the results into a smaller model capable of being run\nin-house, so users can maintain data custody. We evaluate both our approach\nusing GPT-4o and the distilled model versions. We show in an evaluation how our\nprocedure improves code comments along the quality axes. We release all data\nand source code in an online repository for reproducibility."}
{"id": "2505.08801", "pdf": "https://arxiv.org/pdf/2505.08801", "abs": "https://arxiv.org/abs/2505.08801", "authors": ["Md. Sakib Hassan Chowdhury", "Md. Hafiz Ahamed", "Bishowjit Paul", "Sarafat Hussain Abhi", "Abu Bakar Siddique", "Md. Robius Sany"], "title": "OptiGait-LGBM: An Efficient Approach of Gait-based Person Re-identification in Non-Overlapping Regions", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": "12 pages, 17 figures", "summary": "Gait recognition, known for its ability to identify individuals from a\ndistance, has gained significant attention in recent times due to its\nnon-intrusive verification. While video-based gait identification systems\nperform well on large public datasets, their performance drops when applied to\nreal-world, unconstrained gait data due to various factors. Among these,\nuncontrolled outdoor environments, non-overlapping camera views, varying\nillumination, and computational efficiency are core challenges in gait-based\nauthentication. Currently, no dataset addresses all these challenges\nsimultaneously. In this paper, we propose an OptiGait-LGBM model capable of\nrecognizing person re-identification under these constraints using a skeletal\nmodel approach, which helps mitigate inconsistencies in a person's appearance.\nThe model constructs a dataset from landmark positions, minimizing memory usage\nby using non-sequential data. A benchmark dataset, RUET-GAIT, is introduced to\nrepresent uncontrolled gait sequences in complex outdoor environments. The\nprocess involves extracting skeletal joint landmarks, generating numerical\ndatasets, and developing an OptiGait-LGBM gait classification model. Our aim is\nto address the aforementioned challenges with minimal computational cost\ncompared to existing methods. A comparative analysis with ensemble techniques\nsuch as Random Forest and CatBoost demonstrates that the proposed approach\noutperforms them in terms of accuracy, memory usage, and training time. This\nmethod provides a novel, low-cost, and memory-efficient video-based gait\nrecognition solution for real-world scenarios."}
{"id": "2505.09455", "pdf": "https://arxiv.org/pdf/2505.09455", "abs": "https://arxiv.org/abs/2505.09455", "authors": ["Jeremie Ochin", "Raphael Chekroun", "Bogdan Stanciulescu", "Sotiris Manitsaris"], "title": "Beyond Pixels: Leveraging the Language of Soccer to Improve Spatio-Temporal Action Detection in Broadcast Videos", "categories": ["cs.CV"], "comment": "12 pages, submitted to Advanced Concepts for Intelligent Vision\n  Systems 2025", "summary": "State-of-the-art spatio-temporal action detection (STAD) methods show\npromising results for extracting soccer events from broadcast videos. However,\nwhen operated in the high-recall, low-precision regime required for exhaustive\nevent coverage in soccer analytics, their lack of contextual understanding\nbecomes apparent: many false positives could be resolved by considering a\nbroader sequence of actions and game-state information. In this work, we\naddress this limitation by reasoning at the game level and improving STAD\nthrough the addition of a denoising sequence transduction task. Sequences of\nnoisy, context-free player-centric predictions are processed alongside clean\ngame state information using a Transformer-based encoder-decoder model. By\nmodeling extended temporal context and reasoning jointly over team-level\ndynamics, our method leverages the \"language of soccer\" - its tactical\nregularities and inter-player dependencies - to generate \"denoised\" sequences\nof actions. This approach improves both precision and recall in low-confidence\nregimes, enabling more reliable event extraction from broadcast video and\ncomplementing existing pixel-based methods."}
{"id": "2505.09022", "pdf": "https://arxiv.org/pdf/2505.09022", "abs": "https://arxiv.org/abs/2505.09022", "authors": ["Annan Yu", "N. Benjamin Erichson"], "title": "Block-Biased Mamba for Long-Range Sequence Processing", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Mamba extends earlier state space models (SSMs) by introducing\ninput-dependent dynamics, and has demonstrated strong empirical performance\nacross a range of domains, including language modeling, computer vision, and\nfoundation models. However, a surprising weakness remains: despite being built\non architectures designed for long-range dependencies, Mamba performs poorly on\nlong-range sequential tasks. Understanding and addressing this gap is important\nfor improving Mamba's universality and versatility. In this work, we analyze\nMamba's limitations through three perspectives: expressiveness, inductive bias,\nand training stability. Our theoretical results show how Mamba falls short in\neach of these aspects compared to earlier SSMs such as S4D. To address these\nissues, we propose $\\text{B}_2\\text{S}_6$, a simple extension of Mamba's S6\nunit that combines block-wise selective dynamics with a channel-specific bias.\nWe prove that these changes equip the model with a better-suited inductive bias\nand improve its expressiveness and stability. Empirically,\n$\\text{B}_2\\text{S}_6$ outperforms S4 and S4D on Long-Range Arena (LRA) tasks\nwhile maintaining Mamba's performance on language modeling benchmarks."}
{"id": "2505.08804", "pdf": "https://arxiv.org/pdf/2505.08804", "abs": "https://arxiv.org/abs/2505.08804", "authors": ["Longtian Wang", "Xiaofei Xie", "Tianlin Li", "Yuhan Zhi", "Chao Shen"], "title": "TokenProber: Jailbreaking Text-to-image Models via Fine-grained Word Impact Analysis", "categories": ["cs.CR", "cs.LG"], "comment": "13 pages, 5 figures", "summary": "Text-to-image (T2I) models have significantly advanced in producing\nhigh-quality images. However, such models have the ability to generate images\ncontaining not-safe-for-work (NSFW) content, such as pornography, violence,\npolitical content, and discrimination. To mitigate the risk of generating NSFW\ncontent, refusal mechanisms, i.e., safety checkers, have been developed to\ncheck potential NSFW content. Adversarial prompting techniques have been\ndeveloped to evaluate the robustness of the refusal mechanisms. The key\nchallenge remains to subtly modify the prompt in a way that preserves its\nsensitive nature while bypassing the refusal mechanisms. In this paper, we\nintroduce TokenProber, a method designed for sensitivity-aware differential\ntesting, aimed at evaluating the robustness of the refusal mechanisms in T2I\nmodels by generating adversarial prompts. Our approach is based on the key\nobservation that adversarial prompts often succeed by exploiting discrepancies\nin how T2I models and safety checkers interpret sensitive content. Thus, we\nconduct a fine-grained analysis of the impact of specific words within prompts,\ndistinguishing between dirty words that are essential for NSFW content\ngeneration and discrepant words that highlight the different sensitivity\nassessments between T2I models and safety checkers. Through the\nsensitivity-aware mutation, TokenProber generates adversarial prompts, striking\na balance between maintaining NSFW content generation and evading detection.\nOur evaluation of TokenProber against 5 safety checkers on 3 popular T2I\nmodels, using 324 NSFW prompts, demonstrates its superior effectiveness in\nbypassing safety filters compared to existing methods (e.g., 54%+ increase on\naverage), highlighting TokenProber's ability to uncover robustness issues in\nthe existing refusal mechanisms."}
{"id": "2505.09466", "pdf": "https://arxiv.org/pdf/2505.09466", "abs": "https://arxiv.org/abs/2505.09466", "authors": ["Xi Chen", "Shiyang Zhou", "Muqi Huang", "Jiaxu Feng", "Yun Xiong", "Kun Zhou", "Biao Yang", "Yuhui Zhang", "Huishuai Bao", "Sijia Peng", "Chuan Li", "Feng Shi"], "title": "A 2D Semantic-Aware Position Encoding for Vision Transformers", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages, 4 figures, 3 tables", "summary": "Vision transformers have demonstrated significant advantages in computer\nvision tasks due to their ability to capture long-range dependencies and\ncontextual relationships through self-attention. However, existing position\nencoding techniques, which are largely borrowed from natural language\nprocessing, fail to effectively capture semantic-aware positional relationships\nbetween image patches. Traditional approaches like absolute position encoding\nand relative position encoding primarily focus on 1D linear position\nrelationship, often neglecting the semantic similarity between distant yet\ncontextually related patches. These limitations hinder model generalization,\ntranslation equivariance, and the ability to effectively handle repetitive or\nstructured patterns in images. In this paper, we propose 2-Dimensional\nSemantic-Aware Position Encoding ($\\text{SaPE}^2$), a novel position encoding\nmethod with semantic awareness that dynamically adapts position representations\nby leveraging local content instead of fixed linear position relationship or\nspatial coordinates. Our method enhances the model's ability to generalize\nacross varying image resolutions and scales, improves translation equivariance,\nand better aggregates features for visually similar but spatially distant\npatches. By integrating $\\text{SaPE}^2$ into vision transformers, we bridge the\ngap between position encoding and perceptual similarity, thereby improving\nperformance on computer vision tasks."}
{"id": "2505.09027", "pdf": "https://arxiv.org/pdf/2505.09027", "abs": "https://arxiv.org/abs/2505.09027", "authors": ["Yi Cui"], "title": "Tests as Prompt: A Test-Driven-Development Benchmark for LLM Code Generation", "categories": ["cs.SE", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2409.05177", "summary": "We introduce WebApp1K, a novel benchmark for evaluating large language models\n(LLMs) in test-driven development (TDD) tasks, where test cases serve as both\nprompt and verification for code generation. Unlike traditional approaches\nrelying on natural language prompts, our benchmark emphasizes the ability of\nLLMs to interpret and implement functionality directly from test cases,\nreflecting real-world software development practices. Comprising 1000 diverse\nchallenges across 20 application domains, the benchmark evaluates LLMs on their\nability to generate compact, functional code under the constraints of context\nlength and multi-feature complexity. Our findings highlight instruction\nfollowing and in-context learning as critical capabilities for TDD success,\nsurpassing the importance of general coding proficiency or pretraining\nknowledge. Through comprehensive evaluation of 19 frontier models, we reveal\nperformance bottlenecks, such as instruction loss in long prompts, and provide\na detailed error analysis spanning multiple root causes. This work underscores\nthe practical value of TDD-specific benchmarks and lays the foundation for\nadvancing LLM capabilities in rigorous, application-driven coding scenarios."}
{"id": "2505.08814", "pdf": "https://arxiv.org/pdf/2505.08814", "abs": "https://arxiv.org/abs/2505.08814", "authors": ["Wenkai Li", "Xiaoqi Li", "Yingjie Mao", "Yishun Wang"], "title": "Towards Understanding Deep Learning Model in Image Recognition via Coverage Test", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep neural networks (DNNs) play a crucial role in the field of artificial\nintelligence, and their security-related testing has been a prominent research\nfocus. By inputting test cases, the behavior of models is examined for\nanomalies, and coverage metrics are utilized to determine the extent of neurons\ncovered by these test cases. With the widespread application and advancement of\nDNNs, different types of neural behaviors have garnered attention, leading to\nthe emergence of various coverage metrics for neural networks. However, there\nis currently a lack of empirical research on these coverage metrics,\nspecifically in analyzing the relationships and patterns between model depth,\nconfiguration information, and neural network coverage. This paper aims to\ninvestigate the relationships and patterns of four coverage metrics: primary\nfunctionality, boundary, hierarchy, and structural coverage. A series of\nempirical experiments were conducted, selecting LeNet, VGG, and ResNet as\ndifferent DNN architectures, along with 10 models of varying depths ranging\nfrom 5 to 54 layers, to compare and study the relationships between different\ndepths, configuration information, and various neural network coverage metrics.\nAdditionally, an investigation was carried out on the relationships between\nmodified decision/condition coverage and dataset size. Finally, three potential\nfuture directions are proposed to further contribute to the security testing of\nDNN Models."}
{"id": "2505.09484", "pdf": "https://arxiv.org/pdf/2505.09484", "abs": "https://arxiv.org/abs/2505.09484", "authors": ["Yingjie Ma", "Xun Lin", "Zitong Yu", "Xin Liu", "Xiaochen Yuan", "Weicheng Xie", "Linlin Shen"], "title": "Denoising and Alignment: Rethinking Domain Generalization for Multimodal Face Anti-Spoofing", "categories": ["cs.CV"], "comment": null, "summary": "Face Anti-Spoofing (FAS) is essential for the security of facial recognition\nsystems in diverse scenarios such as payment processing and surveillance.\nCurrent multimodal FAS methods often struggle with effective generalization,\nmainly due to modality-specific biases and domain shifts. To address these\nchallenges, we introduce the \\textbf{M}ulti\\textbf{m}odal \\textbf{D}enoising\nand \\textbf{A}lignment (\\textbf{MMDA}) framework. By leveraging the zero-shot\ngeneralization capability of CLIP, the MMDA framework effectively suppresses\nnoise in multimodal data through denoising and alignment mechanisms, thereby\nsignificantly enhancing the generalization performance of cross-modal\nalignment. The \\textbf{M}odality-\\textbf{D}omain Joint \\textbf{D}ifferential\n\\textbf{A}ttention (\\textbf{MD2A}) module in MMDA concurrently mitigates the\nimpacts of domain and modality noise by refining the attention mechanism based\non extracted common noise features. Furthermore, the \\textbf{R}epresentation\n\\textbf{S}pace \\textbf{S}oft (\\textbf{RS2}) Alignment strategy utilizes the\npre-trained CLIP model to align multi-domain multimodal data into a generalized\nrepresentation space in a flexible manner, preserving intricate representations\nand enhancing the model's adaptability to various unseen conditions. We also\ndesign a \\textbf{U}-shaped \\textbf{D}ual \\textbf{S}pace \\textbf{A}daptation\n(\\textbf{U-DSA}) module to enhance the adaptability of representations while\nmaintaining generalization performance. These improvements not only enhance the\nframework's generalization capabilities but also boost its ability to represent\ncomplex representations. Our experimental results on four benchmark datasets\nunder different evaluation protocols demonstrate that the MMDA framework\noutperforms existing state-of-the-art methods in terms of cross-domain\ngeneralization and multimodal detection accuracy. The code will be released\nsoon."}
{"id": "2505.09040", "pdf": "https://arxiv.org/pdf/2505.09040", "abs": "https://arxiv.org/abs/2505.09040", "authors": ["Owen Kwon", "Abraham George", "Alison Bartsch", "Amir Barati Farimani"], "title": "RT-cache: Efficient Robot Trajectory Retrieval System", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "9 pages, 5 figures. Submitted to an IEEE robotics conference", "summary": "This paper introduces RT-cache, a novel trajectorymemory pipeline that\naccelerates real-world robot inference by leveraging big-data retrieval and\nlearning from experience. While modern Vision-Language-Action (VLA) models can\nhandle diverse robotic tasks, they often incur high per-step inference costs,\nresulting in significant latency, sometimes minutes per task. In contrast,\nRT-cache stores a large-scale Memory of previously successful robot\ntrajectories and retrieves relevant multistep motion snippets, drastically\nreducing inference overhead. By integrating a Memory Builder with a Trajectory\nRetrieval, we develop an efficient retrieval process that remains tractable\neven for extremely large datasets. RT-cache flexibly accumulates real-world\nexperiences and replays them whenever the current scene matches past states,\nadapting quickly to new or unseen environments with only a few additional\nsamples. Experiments on the Open-X Embodiment Dataset and other real-world data\ndemonstrate that RT-cache completes tasks both faster and more successfully\nthan a baseline lacking retrieval, suggesting a practical, data-driven solution\nfor real-time manipulation."}
{"id": "2505.08816", "pdf": "https://arxiv.org/pdf/2505.08816", "abs": "https://arxiv.org/abs/2505.08816", "authors": ["Ippokratis Koukoulis", "Ilias Syrigos", "Thanasis Korakis"], "title": "Self-Supervised Transformer-based Contrastive Learning for Intrusion Detection Systems", "categories": ["cs.CR", "cs.LG"], "comment": "Accepted at IFIP Networking 2025. Code available at\n  https://github.com/koukipp/contrastive_transformers_ids", "summary": "As the digital landscape becomes more interconnected, the frequency and\nseverity of zero-day attacks, have significantly increased, leading to an\nurgent need for innovative Intrusion Detection Systems (IDS). Machine\nLearning-based IDS that learn from the network traffic characteristics and can\ndiscern attack patterns from benign traffic offer an advanced solution to\ntraditional signature-based IDS. However, they heavily rely on labeled\ndatasets, and their ability to generalize when encountering unseen traffic\npatterns remains a challenge. This paper proposes a novel self-supervised\ncontrastive learning approach based on transformer encoders, specifically\ntailored for generalizable intrusion detection on raw packet sequences. Our\nproposed learning scheme employs a packet-level data augmentation strategy\ncombined with a transformer-based architecture to extract and generate\nmeaningful representations of traffic flows. Unlike traditional methods reliant\non handcrafted statistical features (NetFlow), our approach automatically\nlearns comprehensive packet sequence representations, significantly enhancing\nperformance in anomaly identification tasks and supervised learning for\nintrusion detection. Our transformer-based framework exhibits better\nperformance in comparison to existing NetFlow self-supervised methods.\nSpecifically, we achieve up to a 3% higher AUC in anomaly detection for\nintra-dataset evaluation and up to 20% higher AUC scores in inter-dataset\nevaluation. Moreover, our model provides a strong baseline for supervised\nintrusion detection with limited labeled data, exhibiting an improvement over\nself-supervised NetFlow models of up to 1.5% AUC when pretrained and evaluated\non the same dataset. Additionally, we show the adaptability of our pretrained\nmodel when fine-tuned across different datasets, demonstrating strong\nperformance even when lacking benign data from the target domain."}
{"id": "2505.09498", "pdf": "https://arxiv.org/pdf/2505.09498", "abs": "https://arxiv.org/abs/2505.09498", "authors": ["Bo Zhang", "Shuo Li", "Runhe Tian", "Yang Yang", "Jixin Tang", "Jinhao Zhou", "Lin Ma"], "title": "Flash-VL 2B: Optimizing Vision-Language Model Performance for Ultra-Low Latency and High Throughput", "categories": ["cs.CV", "cs.AI"], "comment": "18 pages, 7 figures", "summary": "In this paper, we introduce Flash-VL 2B, a novel approach to optimizing\nVision-Language Models (VLMs) for real-time applications, targeting ultra-low\nlatency and high throughput without sacrificing accuracy. Leveraging advanced\narchitectural enhancements and efficient computational strategies, Flash-VL 2B\nis designed to maximize throughput by reducing processing time while\nmaintaining competitive performance across multiple vision-language benchmarks.\nOur approach includes tailored architectural choices, token compression\nmechanisms, data curation, training schemes, and a novel image processing\ntechnique called implicit semantic stitching that effectively balances\ncomputational load and model performance. Through extensive evaluations on 11\nstandard VLM benchmarks, we demonstrate that Flash-VL 2B achieves\nstate-of-the-art results in both speed and accuracy, making it a promising\nsolution for deployment in resource-constrained environments and large-scale\nreal-time applications."}
{"id": "2505.09062", "pdf": "https://arxiv.org/pdf/2505.09062", "abs": "https://arxiv.org/abs/2505.09062", "authors": ["Junda Zhao", "Yuliang Song", "Eldan Cohen"], "title": "Variational Prefix Tuning for Diverse and Accurate Code Summarization Using Pre-trained Language Models", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.7"], "comment": "Accepted by the Journal of Systems and Software", "summary": "Recent advancements in source code summarization have leveraged\ntransformer-based pre-trained models, including Large Language Models of Code\n(LLMCs), to automate and improve the generation of code summaries. However,\nexisting methods often focus on generating a single high-quality summary for a\ngiven source code, neglecting scenarios where the generated summary might be\ninadequate and alternative options are needed. In this paper, we introduce\nVariational Prefix Tuning (VPT), a novel approach that enhances pre-trained\nmodels' ability to generate diverse yet accurate sets of summaries, allowing\nthe user to choose the most suitable one for the given source code. Our method\nintegrates a Conditional Variational Autoencoder (CVAE) framework as a modular\ncomponent into pre-trained models, enabling us to model the distribution of\nobserved target summaries and sample continuous embeddings to be used as\nprefixes to steer the generation of diverse outputs during decoding.\nImportantly, we construct our method in a parameter-efficient manner,\neliminating the need for expensive model retraining, especially when using\nLLMCs. Furthermore, we employ a bi-criteria reranking method to select a subset\nof generated summaries, optimizing both the diversity and the accuracy of the\noptions presented to users. We present extensive experimental evaluations using\nwidely used datasets and current state-of-the-art pre-trained code\nsummarization models to demonstrate the effectiveness of our approach and its\nadaptability across models."}
{"id": "2505.08817", "pdf": "https://arxiv.org/pdf/2505.08817", "abs": "https://arxiv.org/abs/2505.08817", "authors": ["Camilo Carvajal Reyes", "Joaquín Fontbona", "Felipe Tobar"], "title": "Towards SFW sampling for diffusion models via external conditioning", "categories": ["cs.CV", "cs.LG"], "comment": "Accepcted at IJCNN 2025", "summary": "Score-based generative models (SBM), also known as diffusion models, are the\nde facto state of the art for image synthesis. Despite their unparalleled\nperformance, SBMs have recently been in the spotlight for being tricked into\ncreating not-safe-for-work (NSFW) content, such as violent images and\nnon-consensual nudity. Current approaches that prevent unsafe generation are\nbased on the models' own knowledge, and the majority of them require\nfine-tuning. This article explores the use of external sources for ensuring\nsafe outputs in SBMs. Our safe-for-work (SFW) sampler implements a Conditional\nTrajectory Correction step that guides the samples away from undesired regions\nin the ambient space using multimodal models as the source of conditioning.\nFurthermore, using Contrastive Language Image Pre-training (CLIP), our method\nadmits user-defined NSFW classes, which can vary in different settings. Our\nexperiments on the text-to-image SBM Stable Diffusion validate that the\nproposed SFW sampler effectively reduces the generation of explicit content\nwhile being competitive with other fine-tuning-based approaches, as assessed\nvia independent NSFW detectors. Moreover, we evaluate the impact of the SFW\nsampler on image quality and show that the proposed correction scheme comes at\na minor cost with negligible effect on samples not needing correction. Our\nstudy confirms the suitability of the SFW sampler towards aligned SBM models\nand the potential of using model-agnostic conditioning for the prevention of\nunwanted images."}
{"id": "2505.09528", "pdf": "https://arxiv.org/pdf/2505.09528", "abs": "https://arxiv.org/abs/2505.09528", "authors": ["Jeffrey Wen", "Rizwan Ahmad", "Philip Schniter"], "title": "Conformal Bounds on Full-Reference Image Quality for Imaging Inverse Problems", "categories": ["cs.CV"], "comment": null, "summary": "In imaging inverse problems, we would like to know how close the recovered\nimage is to the true image in terms of full-reference image quality (FRIQ)\nmetrics like PSNR, SSIM, LPIPS, etc. This is especially important in\nsafety-critical applications like medical imaging, where knowing that, say, the\nSSIM was poor could potentially avoid a costly misdiagnosis. But since we don't\nknow the true image, computing FRIQ is non-trivial. In this work, we combine\nconformal prediction with approximate posterior sampling to construct bounds on\nFRIQ that are guaranteed to hold up to a user-specified error probability. We\ndemonstrate our approach on image denoising and accelerated magnetic resonance\nimaging (MRI) problems. Code is available at\nhttps://github.com/jwen307/quality_uq."}
{"id": "2505.09081", "pdf": "https://arxiv.org/pdf/2505.09081", "abs": "https://arxiv.org/abs/2505.09081", "authors": ["Gaurav Koley"], "title": "SALM: A Multi-Agent Framework for Language Model-Driven Social Network Simulation", "categories": ["cs.SI", "cs.AI", "cs.MA"], "comment": null, "summary": "Contemporary approaches to agent-based modeling (ABM) of social systems have\ntraditionally emphasized rule-based behaviors, limiting their ability to\ncapture nuanced dynamics by moving beyond predefined rules and leveraging\ncontextual understanding from LMs of human social interaction. This paper\npresents SALM (Social Agent LM Framework), a novel approach for integrating\nlanguage models (LMs) into social network simulation that achieves\nunprecedented temporal stability in multi-agent scenarios. Our primary\ncontributions include: (1) a hierarchical prompting architecture enabling\nstable simulation beyond 4,000 timesteps while reducing token usage by 73%, (2)\nan attention-based memory system achieving 80% cache hit rates (95% CI [78%,\n82%]) with sub-linear memory growth of 9.5%, and (3) formal bounds on\npersonality stability. Through extensive validation against SNAP ego networks,\nwe demonstrate the first LLM-based framework capable of modeling long-term\nsocial phenomena while maintaining empirically validated behavioral fidelity."}
{"id": "2505.08818", "pdf": "https://arxiv.org/pdf/2505.08818", "abs": "https://arxiv.org/abs/2505.08818", "authors": ["Amara Tariq", "Rimita Lahiri", "Charles Kahn", "Imon Banerjee"], "title": "Position: Restructuring of Categories and Implementation of Guidelines Essential for VLM Adoption in Healthcare", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "15 pages, 2, tables, 3 figures", "summary": "The intricate and multifaceted nature of vision language model (VLM)\ndevelopment, adaptation, and application necessitates the establishment of\nclear and standardized reporting protocols, particularly within the high-stakes\ncontext of healthcare. Defining these reporting standards is inherently\nchallenging due to the diverse nature of studies involving VLMs, which vary\nsignificantly from the development of all new VLMs or finetuning for domain\nalignment to off-the-shelf use of VLM for targeted diagnosis and prediction\ntasks. In this position paper, we argue that traditional machine learning\nreporting standards and evaluation guidelines must be restructured to\naccommodate multiphase VLM studies; it also has to be organized for intuitive\nunderstanding of developers while maintaining rigorous standards for\nreproducibility. To facilitate community adoption, we propose a categorization\nframework for VLM studies and outline corresponding reporting standards that\ncomprehensively address performance evaluation, data reporting protocols, and\nrecommendations for manuscript composition. These guidelines are organized\naccording to the proposed categorization scheme. Lastly, we present a checklist\nthat consolidates reporting standards, offering a standardized tool to ensure\nconsistency and quality in the publication of VLM-related research."}
{"id": "2505.09529", "pdf": "https://arxiv.org/pdf/2505.09529", "abs": "https://arxiv.org/abs/2505.09529", "authors": ["Mohamed Moustafa", "Joseph Lemley", "Peter Corcoran"], "title": "Contactless Cardiac Pulse Monitoring Using Event Cameras", "categories": ["cs.CV", "cs.ET", "cs.LG", "eess.IV"], "comment": "This paper is a preprint of a paper submitted to IEEE Access and is\n  currently under review", "summary": "Time event cameras are a novel technology for recording scene information at\nextremely low latency and with low power consumption. Event cameras output a\nstream of events that encapsulate pixel-level light intensity changes within\nthe scene, capturing information with a higher dynamic range and temporal\nresolution than traditional cameras. This study investigates the contact-free\nreconstruction of an individual's cardiac pulse signal from time event\nrecording of their face using a supervised convolutional neural network (CNN)\nmodel. An end-to-end model is trained to extract the cardiac signal from a\ntwo-dimensional representation of the event stream, with model performance\nevaluated based on the accuracy of the calculated heart rate. The experimental\nresults confirm that physiological cardiac information in the facial region is\neffectively preserved within the event stream, showcasing the potential of this\nnovel sensor for remote heart rate monitoring. The model trained on event\nframes achieves a root mean square error (RMSE) of 3.32 beats per minute (bpm)\ncompared to the RMSE of 2.92 bpm achieved by the baseline model trained on\nstandard camera frames. Furthermore, models trained on event frames generated\nat 60 and 120 FPS outperformed the 30 FPS standard camera results, achieving an\nRMSE of 2.54 and 2.13 bpm, respectively."}
{"id": "2505.09082", "pdf": "https://arxiv.org/pdf/2505.09082", "abs": "https://arxiv.org/abs/2505.09082", "authors": ["Sophie Zhang", "Zhiming Lin"], "title": "CEC-Zero: Chinese Error Correction Solution Based on LLM", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) demonstrate exceptional\nChinese text processing capabilities, particularly in Chinese Spelling\nCorrection (CSC). While LLMs outperform traditional BERT-based models in\naccuracy and robustness, challenges persist in reliability and generalization.\nThis paper proposes CEC-Zero, a novel reinforcement learning (RL) framework\nenabling LLMs to self-correct through autonomous error strategy learning\nwithout external supervision. By integrating RL with LLMs' generative power,\nthe method eliminates dependency on annotated data or auxiliary models.\nExperiments reveal RL-enhanced LLMs achieve industry-viable accuracy and\nsuperior cross-domain generalization, offering a scalable solution for\nreliability optimization in Chinese NLP applications. This breakthrough\nfacilitates LLM deployment in practical Chinese text correction scenarios while\nestablishing a new paradigm for self-improving language models."}
{"id": "2505.08819", "pdf": "https://arxiv.org/pdf/2505.08819", "abs": "https://arxiv.org/abs/2505.08819", "authors": ["Asahi Miyazaki", "Tsuyoshi Okita"], "title": "Thoughts on Objectives of Sparse and Hierarchical Masked Image Model", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "9 pages, 11 figures", "summary": "Masked image modeling is one of the most poplular objectives of training.\nRecently, the SparK model has been proposed with superior performance among\nself-supervised learning models. This paper proposes a new mask pattern for\nthis SparK model, proposing it as the Mesh Mask-ed SparK model. We report the\neffect of the mask pattern used for image masking in pre-training on\nperformance."}
{"id": "2505.09562", "pdf": "https://arxiv.org/pdf/2505.09562", "abs": "https://arxiv.org/abs/2505.09562", "authors": ["Nicola Marinello", "Simen Cassiman", "Jonas Heylen", "Marc Proesmans", "Luc Van Gool"], "title": "Camera-Only 3D Panoptic Scene Completion for Autonomous Driving through Differentiable Object Shapes", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025 Workshop on Autonomous Driving", "summary": "Autonomous vehicles need a complete map of their surroundings to plan and\nact. This has sparked research into the tasks of 3D occupancy prediction, 3D\nscene completion, and 3D panoptic scene completion, which predict a dense map\nof the ego vehicle's surroundings as a voxel grid. Scene completion extends\noccupancy prediction by predicting occluded regions of the voxel grid, and\npanoptic scene completion further extends this task by also distinguishing\nobject instances within the same class; both aspects are crucial for path\nplanning and decision-making. However, 3D panoptic scene completion is\ncurrently underexplored. This work introduces a novel framework for 3D panoptic\nscene completion that extends existing 3D semantic scene completion models. We\npropose an Object Module and Panoptic Module that can easily be integrated with\n3D occupancy and scene completion methods presented in the literature. Our\napproach leverages the available annotations in occupancy benchmarks, allowing\nindividual object shapes to be learned as a differentiable problem. The code is\navailable at https://github.com/nicolamarinello/OffsetOcc ."}
{"id": "2505.09085", "pdf": "https://arxiv.org/pdf/2505.09085", "abs": "https://arxiv.org/abs/2505.09085", "authors": ["Jiaxuan Chen", "Yu Qi", "Yueming Wang", "Gang Pan"], "title": "Human-like Cognitive Generalization for Large Models via Brain-in-the-loop Supervision", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advancements in deep neural networks (DNNs), particularly large-scale\nlanguage models, have demonstrated remarkable capabilities in image and natural\nlanguage understanding. Although scaling up model parameters with increasing\nvolume of training data has progressively improved DNN capabilities, achieving\ncomplex cognitive abilities - such as understanding abstract concepts,\nreasoning, and adapting to novel scenarios, which are intrinsic to human\ncognition - remains a major challenge. In this study, we show that\nbrain-in-the-loop supervised learning, utilizing a small set of brain signals,\ncan effectively transfer human conceptual structures to DNNs, significantly\nenhancing their comprehension of abstract and even unseen concepts.\nExperimental results further indicate that the enhanced cognitive capabilities\nlead to substantial performance gains in challenging tasks, including\nfew-shot/zero-shot learning and out-of-distribution recognition, while also\nyielding highly interpretable concept representations. These findings highlight\nthat human-in-the-loop supervision can effectively augment the complex\ncognitive abilities of large models, offering a promising pathway toward\ndeveloping more human-like cognitive abilities in artificial systems."}
{"id": "2505.08822", "pdf": "https://arxiv.org/pdf/2505.08822", "abs": "https://arxiv.org/abs/2505.08822", "authors": ["Yuhao Wang", "Kailai Wang", "Songhua Hu", "Yunpeng", "Zhang", "Gino Lim", "Pengyu Zhu"], "title": "The Geography of Transportation Cybersecurity: Visitor Flows, Industry Clusters, and Spatial Dynamics", "categories": ["cs.CY", "cs.LG", "physics.soc-ph"], "comment": null, "summary": "The rapid evolution of the transportation cybersecurity ecosystem,\nencompassing cybersecurity, automotive, and transportation and logistics\nsectors, will lead to the formation of distinct spatial clusters and visitor\nflow patterns across the US. This study examines the spatiotemporal dynamics of\nvisitor flows, analyzing how socioeconomic factors shape industry clustering\nand workforce distribution within these evolving sectors. To model and predict\nvisitor flow patterns, we develop a BiTransGCN framework, integrating an\nattention-based Transformer architecture with a Graph Convolutional Network\nbackbone. By integrating AI-enabled forecasting techniques with spatial\nanalysis, this study improves our ability to track, interpret, and anticipate\nchanges in industry clustering and mobility trends, thereby supporting\nstrategic planning for a secure and resilient transportation network. It offers\na data-driven foundation for economic planning, workforce development, and\ntargeted investments in the transportation cybersecurity ecosystem."}
{"id": "2505.09564", "pdf": "https://arxiv.org/pdf/2505.09564", "abs": "https://arxiv.org/abs/2505.09564", "authors": ["Anne-Marie Rickmann", "Stephanie L. Thorn", "Shawn S. Ahn", "Supum Lee", "Selen Uman", "Taras Lysyy", "Rachel Burns", "Nicole Guerrera", "Francis G. Spinale", "Jason A. Burdick", "Albert J. Sinusas", "James S. Duncan"], "title": "Using Foundation Models as Pseudo-Label Generators for Pre-Clinical 4D Cardiac CT Segmentation", "categories": ["cs.CV"], "comment": "accepted at FIMH 2025", "summary": "Cardiac image segmentation is an important step in many cardiac image\nanalysis and modeling tasks such as motion tracking or simulations of cardiac\nmechanics. While deep learning has greatly advanced segmentation in clinical\nsettings, there is limited work on pre-clinical imaging, notably in porcine\nmodels, which are often used due to their anatomical and physiological\nsimilarity to humans. However, differences between species create a domain\nshift that complicates direct model transfer from human to pig data.\n  Recently, foundation models trained on large human datasets have shown\npromise for robust medical image segmentation; yet their applicability to\nporcine data remains largely unexplored. In this work, we investigate whether\nfoundation models can generate sufficiently accurate pseudo-labels for pig\ncardiac CT and propose a simple self-training approach to iteratively refine\nthese labels. Our method requires no manually annotated pig data, relying\ninstead on iterative updates to improve segmentation quality. We demonstrate\nthat this self-training process not only enhances segmentation accuracy but\nalso smooths out temporal inconsistencies across consecutive frames. Although\nour results are encouraging, there remains room for improvement, for example by\nincorporating more sophisticated self-training strategies and by exploring\nadditional foundation models and other cardiac imaging technologies."}
{"id": "2505.09091", "pdf": "https://arxiv.org/pdf/2505.09091", "abs": "https://arxiv.org/abs/2505.09091", "authors": ["Zeeshan Ahmad", "Shudi Bao", "Meng Chen"], "title": "DPN-GAN: Inducing Periodic Activations in Generative Adversarial Networks for High-Fidelity Audio Synthesis", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "comment": null, "summary": "In recent years, generative adversarial networks (GANs) have made significant\nprogress in generating audio sequences. However, these models typically rely on\nbandwidth-limited mel-spectrograms, which constrain the resolution of generated\naudio sequences, and lead to mode collapse during conditional generation. To\naddress this issue, we propose Deformable Periodic Network based GAN (DPN-GAN),\na novel GAN architecture that incorporates a kernel-based periodic ReLU\nactivation function to induce periodic bias in audio generation. This\ninnovative approach enhances the model's ability to capture and reproduce\nintricate audio patterns. In particular, our proposed model features a DPN\nmodule for multi-resolution generation utilizing deformable convolution\noperations, allowing for adaptive receptive fields that improve the quality and\nfidelity of the synthetic audio. Additionally, we enhance the discriminator\nnetwork using deformable convolution to better distinguish between real and\ngenerated samples, further refining the audio quality. We trained two versions\nof the model: DPN-GAN small (38.67M parameters) and DPN-GAN large (124M\nparameters). For evaluation, we use five different datasets, covering both\nspeech synthesis and music generation tasks, to demonstrate the efficiency of\nthe DPN-GAN. The experimental results demonstrate that DPN-GAN delivers\nsuperior performance on both out-of-distribution and noisy data, showcasing its\nrobustness and adaptability. Trained across various datasets, DPN-GAN\noutperforms state-of-the-art GAN architectures on standard evaluation metrics,\nand exhibits increased robustness in synthesized audio."}
{"id": "2505.08833", "pdf": "https://arxiv.org/pdf/2505.08833", "abs": "https://arxiv.org/abs/2505.08833", "authors": ["Qingyi Wang", "Yuebing Liang", "Yunhan Zheng", "Kaiyuan Xu", "Jinhua Zhao", "Shenhao Wang"], "title": "Generative AI for Urban Planning: Synthesizing Satellite Imagery via Diffusion Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Generative AI offers new opportunities for automating urban planning by\ncreating site-specific urban layouts and enabling flexible design exploration.\nHowever, existing approaches often struggle to produce realistic and practical\ndesigns at scale. Therefore, we adapt a state-of-the-art Stable Diffusion\nmodel, extended with ControlNet, to generate high-fidelity satellite imagery\nconditioned on land use descriptions, infrastructure, and natural environments.\nTo overcome data availability limitations, we spatially link satellite imagery\nwith structured land use and constraint information from OpenStreetMap. Using\ndata from three major U.S. cities, we demonstrate that the proposed diffusion\nmodel generates realistic and diverse urban landscapes by varying land-use\nconfigurations, road networks, and water bodies, facilitating cross-city\nlearning and design diversity. We also systematically evaluate the impacts of\nvarying language prompts and control imagery on the quality of satellite\nimagery generation. Our model achieves high FID and KID scores and demonstrates\nrobustness across diverse urban contexts. Qualitative assessments from urban\nplanners and the general public show that generated images align closely with\ndesign descriptions and constraints, and are often preferred over real images.\nThis work establishes a benchmark for controlled urban imagery generation and\nhighlights the potential of generative AI as a tool for enhancing planning\nworkflows and public engagement."}
{"id": "2505.09568", "pdf": "https://arxiv.org/pdf/2505.09568", "abs": "https://arxiv.org/abs/2505.09568", "authors": ["Jiuhai Chen", "Zhiyang Xu", "Xichen Pan", "Yushi Hu", "Can Qin", "Tom Goldstein", "Lifu Huang", "Tianyi Zhou", "Saining Xie", "Silvio Savarese", "Le Xue", "Caiming Xiong", "Ran Xu"], "title": "BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Unifying image understanding and generation has gained growing attention in\nrecent research on multimodal models. Although design choices for image\nunderstanding have been extensively studied, the optimal model architecture and\ntraining recipe for a unified framework with image generation remain\nunderexplored. Motivated by the strong potential of autoregressive and\ndiffusion models for high-quality generation and scalability, we conduct a\ncomprehensive study of their use in unified multimodal settings, with emphasis\non image representations, modeling objectives, and training strategies.\nGrounded in these investigations, we introduce a novel approach that employs a\ndiffusion transformer to generate semantically rich CLIP image features, in\ncontrast to conventional VAE-based representations. This design yields both\nhigher training efficiency and improved generative quality. Furthermore, we\ndemonstrate that a sequential pretraining strategy for unified models-first\ntraining on image understanding and subsequently on image generation-offers\npractical advantages by preserving image understanding capability while\ndeveloping strong image generation ability. Finally, we carefully curate a\nhigh-quality instruction-tuning dataset BLIP3o-60k for image generation by\nprompting GPT-4o with a diverse set of captions covering various scenes,\nobjects, human gestures, and more. Building on our innovative model design,\ntraining recipe, and datasets, we develop BLIP3-o, a suite of state-of-the-art\nunified multimodal models. BLIP3-o achieves superior performance across most of\nthe popular benchmarks spanning both image understanding and generation tasks.\nTo facilitate future research, we fully open-source our models, including code,\nmodel weights, training scripts, and pretraining and instruction tuning\ndatasets."}
{"id": "2505.09108", "pdf": "https://arxiv.org/pdf/2505.09108", "abs": "https://arxiv.org/abs/2505.09108", "authors": ["Fernando Cladera", "Zachary Ravichandran", "Jason Hughes", "Varun Murali", "Carlos Nieto-Granda", "M. Ani Hsieh", "George J. Pappas", "Camillo J. Taylor", "Vijay Kumar"], "title": "Air-Ground Collaboration for Language-Specified Missions in Unknown Environments", "categories": ["cs.RO", "cs.AI"], "comment": "19 pages, 24 figures, 7 tables. Submitted to T-FR", "summary": "As autonomous robotic systems become increasingly mature, users will want to\nspecify missions at the level of intent rather than in low-level detail.\nLanguage is an expressive and intuitive medium for such mission specification.\nHowever, realizing language-guided robotic teams requires overcoming\nsignificant technical hurdles. Interpreting and realizing language-specified\nmissions requires advanced semantic reasoning. Successful heterogeneous robots\nmust effectively coordinate actions and share information across varying\nviewpoints. Additionally, communication between robots is typically\nintermittent, necessitating robust strategies that leverage communication\nopportunities to maintain coordination and achieve mission objectives. In this\nwork, we present a first-of-its-kind system where an unmanned aerial vehicle\n(UAV) and an unmanned ground vehicle (UGV) are able to collaboratively\naccomplish missions specified in natural language while reacting to changes in\nspecification on the fly. We leverage a Large Language Model (LLM)-enabled\nplanner to reason over semantic-metric maps that are built online and\nopportunistically shared between an aerial and a ground robot. We consider\ntask-driven navigation in urban and rural areas. Our system must infer\nmission-relevant semantics and actively acquire information via semantic\nmapping. In both ground and air-ground teaming experiments, we demonstrate our\nsystem on seven different natural-language specifications at up to\nkilometer-scale navigation."}
{"id": "2505.08837", "pdf": "https://arxiv.org/pdf/2505.08837", "abs": "https://arxiv.org/abs/2505.08837", "authors": ["Muhammad Saqib", "Dipkumar Mehta", "Fnu Yashu", "Shubham Malhotra"], "title": "Adaptive Security Policy Management in Cloud Environments Using Reinforcement Learning", "categories": ["cs.CR", "cs.CV", "cs.DC", "cs.LG", "cs.NI"], "comment": "10 pages, 6 figures, 1 table", "summary": "The security of cloud environments, such as Amazon Web Services (AWS), is\ncomplex and dynamic. Static security policies have become inadequate as threats\nevolve and cloud resources exhibit elasticity [1]. This paper addresses the\nlimitations of static policies by proposing a security policy management\nframework that uses reinforcement learning (RL) to adapt dynamically.\nSpecifically, we employ deep reinforcement learning algorithms, including deep\nQ Networks and proximal policy optimization, enabling the learning and\ncontinuous adjustment of controls such as firewall rules and Identity and\nAccess Management (IAM) policies. The proposed RL based solution leverages\ncloud telemetry data (AWS Cloud Trail logs, network traffic data, threat\nintelligence feeds) to continuously refine security policies, maximizing threat\nmitigation, and compliance while minimizing resource impact. Experimental\nresults demonstrate that our adaptive RL based framework significantly\noutperforms static policies, achieving higher intrusion detection rates (92%\ncompared to 82% for static policies) and substantially reducing incident\ndetection and response times by 58%. In addition, it maintains high conformity\nwith security requirements and efficient resource usage. These findings\nvalidate the effectiveness of adaptive reinforcement learning approaches in\nimproving cloud security policy management."}
{"id": "2505.09571", "pdf": "https://arxiv.org/pdf/2505.09571", "abs": "https://arxiv.org/abs/2505.09571", "authors": ["Guillermo Gomez-Trenado", "Pablo Mesejo", "Oscar Cordón", "Stéphane Lathuilière"], "title": "Don't Forget your Inverse DDIM for Image Editing", "categories": ["cs.CV", "I.2.10; I.5.0"], "comment": "12 pages, 12 figures, code available at\n  https://guillermogotre.github.io/sage/", "summary": "The field of text-to-image generation has undergone significant advancements\nwith the introduction of diffusion models. Nevertheless, the challenge of\nediting real images persists, as most methods are either computationally\nintensive or produce poor reconstructions. This paper introduces SAGE\n(Self-Attention Guidance for image Editing) - a novel technique leveraging\npre-trained diffusion models for image editing. SAGE builds upon the DDIM\nalgorithm and incorporates a novel guidance mechanism utilizing the\nself-attention layers of the diffusion U-Net. This mechanism computes a\nreconstruction objective based on attention maps generated during the inverse\nDDIM process, enabling efficient reconstruction of unedited regions without the\nneed to precisely reconstruct the entire input image. Thus, SAGE directly\naddresses the key challenges in image editing. The superiority of SAGE over\nother methods is demonstrated through quantitative and qualitative evaluations\nand confirmed by a statistically validated comprehensive user study, in which\nall 47 surveyed users preferred SAGE over competing methods. Additionally, SAGE\nranks as the top-performing method in seven out of 10 quantitative analyses and\nsecures second and third places in the remaining three."}
{"id": "2505.09115", "pdf": "https://arxiv.org/pdf/2505.09115", "abs": "https://arxiv.org/abs/2505.09115", "authors": ["Yu Lun Hsu", "Yun-Rung Chou", "Chiao-Ju Chang", "Yu-Cheng Chang", "Zer-Wei Lee", "Rokas Gipiškis", "Rachel Li", "Chih-Yuan Shih", "Jen-Kuei Peng", "Hsien-Liang Huang", "Jaw-Shiun Tsai", "Mike Y. Chen"], "title": "PreCare: Designing AI Assistants for Advance Care Planning (ACP) to Enhance Personal Value Exploration, Patient Knowledge, and Decisional Confidence", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Advance Care Planning (ACP) allows individuals to specify their preferred\nend-of-life life-sustaining treatments before they become incapacitated by\ninjury or terminal illness (e.g., coma, cancer, dementia). While online ACP\noffers high accessibility, it lacks key benefits of clinical consultations,\nincluding personalized value exploration, immediate clarification of decision\nconsequences. To bridge this gap, we conducted two formative studies: 1)\nshadowed and interviewed 3 ACP teams consisting of physicians, nurses, and\nsocial workers (18 patients total), and 2) interviewed 14 users of ACP\nwebsites. Building on these insights, we designed PreCare in collaboration with\n6 ACP professionals. PreCare is a website with 3 AI-driven assistants designed\nto guide users through exploring personal values, gaining ACP knowledge, and\nsupporting informed decision-making. A usability study (n=12) showed that\nPreCare achieved a System Usability Scale (SUS) rating of excellent. A\ncomparative evaluation (n=12) showed that PreCare's AI assistants significantly\nimproved exploration of personal values, knowledge, and decisional confidence,\nand was preferred by 92% of participants."}
{"id": "2505.08845", "pdf": "https://arxiv.org/pdf/2505.08845", "abs": "https://arxiv.org/abs/2505.08845", "authors": ["Misgina Tsighe Hagos", "Antti Suutala", "Dmitrii Bychkov", "Hakan Kücükel", "Joar von Bahr", "Milda Poceviciute", "Johan Lundin", "Nina Linder", "Claes Lundström"], "title": "Validation of Conformal Prediction in Cervical Atypia Classification", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Deep learning based cervical cancer classification can potentially increase\naccess to screening in low-resource regions. However, deep learning models are\noften overconfident and do not reliably reflect diagnostic uncertainty.\nMoreover, they are typically optimized to generate maximum-likelihood\npredictions, which fail to convey uncertainty or ambiguity in their results.\nSuch challenges can be addressed using conformal prediction, a model-agnostic\nframework for generating prediction sets that contain likely classes for\ntrained deep-learning models. The size of these prediction sets indicates model\nuncertainty, contracting as model confidence increases. However, existing\nconformal prediction evaluation primarily focuses on whether the prediction set\nincludes or covers the true class, often overlooking the presence of extraneous\nclasses. We argue that prediction sets should be truthful and valuable to end\nusers, ensuring that the listed likely classes align with human expectations\nrather than being overly relaxed and including false positives or unlikely\nclasses. In this study, we comprehensively validate conformal prediction sets\nusing expert annotation sets collected from multiple annotators. We evaluate\nthree conformal prediction approaches applied to three deep-learning models\ntrained for cervical atypia classification. Our expert annotation-based\nanalysis reveals that conventional coverage-based evaluations overestimate\nperformance and that current conformal prediction methods often produce\nprediction sets that are not well aligned with human labels. Additionally, we\nexplore the capabilities of the conformal prediction methods in identifying\nambiguous and out-of-distribution data."}
{"id": "2505.09591", "pdf": "https://arxiv.org/pdf/2505.09591", "abs": "https://arxiv.org/abs/2505.09591", "authors": ["Tobias Jan Wieczorek", "Nathalie Daun", "Mohammad Emtiyaz Khan", "Marcus Rohrbach"], "title": "Variational Visual Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "19 pages, 16 figures, under review at ICCV 2025", "summary": "Despite remarkable progress in multimodal models for Visual Question\nAnswering (VQA), there remain major reliability concerns because the models can\noften be overconfident and miscalibrated, especially in out-of-distribution\n(OOD) settings. Plenty has been done to address such issues for unimodal\nmodels, but little work exists for multimodal cases. Here, we address\nunreliability in multimodal models by proposing a Variational VQA approach.\nSpecifically, instead of fine-tuning vision-language models by using AdamW, we\nemploy a recently proposed variational algorithm called IVON, which yields a\nposterior distribution over model parameters. Through extensive experiments, we\nshow that our approach improves calibration and abstentions without sacrificing\nthe accuracy of AdamW. For instance, compared to AdamW fine-tuning, we reduce\nExpected Calibration Error by more than 50% compared to the AdamW baseline and\nraise Coverage by 4% vs. SOTA (for a fixed risk of 1%). In the presence of\ndistribution shifts, the performance gain is even higher, achieving 8% Coverage\n(@ 1% risk) improvement vs. SOTA when 50% of test cases are OOD. Overall, we\npresent variational learning as a viable option to enhance the reliability of\nmultimodal models."}
{"id": "2505.09129", "pdf": "https://arxiv.org/pdf/2505.09129", "abs": "https://arxiv.org/abs/2505.09129", "authors": ["Wei Meng"], "title": "WSCIF: A Weakly-Supervised Color Intelligence Framework for Tactical Anomaly Detection in Surveillance Keyframes", "categories": ["cs.CV", "cs.AI", "es: 68T10, 68T05, 62H35, 68U10", "I.4.9; I.5.1; I.2.10"], "comment": "17 pages, 3 figures, 3 tables. The paper proposes a lightweight\n  weakly-supervised color intelligence model for tactical video anomaly\n  detection, tested on anonymized African surveillance data", "summary": "The deployment of traditional deep learning models in high-risk security\ntasks in an unlabeled, data-non-exploitable video intelligence environment\nfaces significant challenges. In this paper, we propose a lightweight anomaly\ndetection framework based on color features for surveillance video clips in a\nhigh sensitivity tactical mission, aiming to quickly identify and interpret\npotential threat events under resource-constrained and data-sensitive\nconditions. The method fuses unsupervised KMeans clustering with RGB channel\nhistogram modeling to achieve composite detection of structural anomalies and\ncolor mutation signals in key frames. The experiment takes an operation\nsurveillance video occurring in an African country as a research sample, and\nsuccessfully identifies multiple highly anomalous frames related to high-energy\nlight sources, target presence, and reflective interference under the condition\nof no access to the original data. The results show that this method can be\neffectively used for tactical assassination warning, suspicious object\nscreening and environmental drastic change monitoring with strong deployability\nand tactical interpretation value. The study emphasizes the importance of color\nfeatures as low semantic battlefield signal carriers, and its battlefield\nintelligent perception capability will be further extended by combining graph\nneural networks and temporal modeling in the future."}
{"id": "2505.08849", "pdf": "https://arxiv.org/pdf/2505.08849", "abs": "https://arxiv.org/abs/2505.08849", "authors": ["Keyu Chen", "Hao Tang", "Qinglin Liu", "Yizhao Xu"], "title": "Improved Algorithms for Differentially Private Language Model Alignment", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Language model alignment is crucial for ensuring that large language models\n(LLMs) align with human preferences, yet it often involves sensitive user data,\nraising significant privacy concerns. While prior work has integrated\ndifferential privacy (DP) with alignment techniques, their performance remains\nlimited. In this paper, we propose novel algorithms for privacy-preserving\nalignment and rigorously analyze their effectiveness across varying privacy\nbudgets and models. Our framework can be deployed on two celebrated alignment\ntechniques, namely direct preference optimization (DPO) and reinforcement\nlearning from human feedback (RLHF). Through systematic experiments on\nlarge-scale language models, we demonstrate that our approach achieves\nstate-of-the-art performance. Notably, one of our algorithms, DP-AdamW,\ncombined with DPO, surpasses existing methods, improving alignment quality by\nup to 15% under moderate privacy budgets ({\\epsilon}=2-5). We further\ninvestigate the interplay between privacy guarantees, alignment efficacy, and\ncomputational demands, providing practical guidelines for optimizing these\ntrade-offs."}
{"id": "2505.09608", "pdf": "https://arxiv.org/pdf/2505.09608", "abs": "https://arxiv.org/abs/2505.09608", "authors": ["Nadav Magar", "Amir Hertz", "Eric Tabellion", "Yael Pritch", "Alex Rav-Acha", "Ariel Shamir", "Yedid Hoshen"], "title": "LightLab: Controlling Light Sources in Images with Diffusion Models", "categories": ["cs.CV", "cs.GR"], "comment": "Project Page: https://nadmag.github.io/LightLab/", "summary": "We present a simple, yet effective diffusion-based method for fine-grained,\nparametric control over light sources in an image. Existing relighting methods\neither rely on multiple input views to perform inverse rendering at inference\ntime, or fail to provide explicit control over light changes. Our method\nfine-tunes a diffusion model on a small set of real raw photograph pairs,\nsupplemented by synthetically rendered images at scale, to elicit its\nphotorealistic prior for relighting. We leverage the linearity of light to\nsynthesize image pairs depicting controlled light changes of either a target\nlight source or ambient illumination. Using this data and an appropriate\nfine-tuning scheme, we train a model for precise illumination changes with\nexplicit control over light intensity and color. Lastly, we show how our method\ncan achieve compelling light editing results, and outperforms existing methods\nbased on user preference."}
{"id": "2505.09131", "pdf": "https://arxiv.org/pdf/2505.09131", "abs": "https://arxiv.org/abs/2505.09131", "authors": ["Kunwoong Kim", "Jihu Lee", "Sangchul Park", "Yongdai Kim"], "title": "Fair Clustering via Alignment", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at ICML 2025. This is the version submitted for review and\n  will be replaced by the camera-ready version soon", "summary": "Algorithmic fairness in clustering aims to balance the proportions of\ninstances assigned to each cluster with respect to a given sensitive attribute.\nWhile recently developed fair clustering algorithms optimize clustering\nobjectives under specific fairness constraints, their inherent complexity or\napproximation often results in suboptimal clustering utility or numerical\ninstability in practice. To resolve these limitations, we propose a new fair\nclustering algorithm based on a novel decomposition of the fair K-means\nclustering objective function. The proposed algorithm, called Fair Clustering\nvia Alignment (FCA), operates by alternately (i) finding a joint probability\ndistribution to align the data from different protected groups, and (ii)\noptimizing cluster centers in the aligned space. A key advantage of FCA is that\nit theoretically guarantees approximately optimal clustering utility for any\ngiven fairness level without complex constraints, thereby enabling high-utility\nfair clustering in practice. Experiments show that FCA outperforms existing\nmethods by (i) attaining a superior trade-off between fairness level and\nclustering utility, and (ii) achieving near-perfect fairness without numerical\ninstability."}
{"id": "2505.08886", "pdf": "https://arxiv.org/pdf/2505.08886", "abs": "https://arxiv.org/abs/2505.08886", "authors": ["Hamideh Khaleghpour", "Brett McKinney"], "title": "Optimizing Neuro-Fuzzy and Colonial Competition Algorithms for Skin Cancer Diagnosis in Dermatoscopic Images", "categories": ["cs.CV", "cs.LG"], "comment": "7 pages, 10 figures. Accepted at the 2nd Asia Pacific Computer\n  Systems Conference (APCS 2024), March 15-17, 2024", "summary": "The rising incidence of skin cancer, coupled with limited public awareness\nand a shortfall in clinical expertise, underscores an urgent need for advanced\ndiagnostic aids. Artificial Intelligence (AI) has emerged as a promising tool\nin this domain, particularly for distinguishing malignant from benign skin\nlesions. Leveraging publicly available datasets of skin lesions, researchers\nhave been developing AI-based diagnostic solutions. However, the integration of\nsuch computer systems in clinical settings is still nascent. This study aims to\nbridge this gap by employing a fusion of image processing techniques and\nmachine learning algorithms, specifically neuro-fuzzy and colonial competition\napproaches. Applied to dermoscopic images from the ISIC database, our method\nachieved a notable accuracy of 94% on a dataset of 560 images. These results\nunderscore the potential of our approach in aiding clinicians in the early\ndetection of melanoma, thereby contributing significantly to skin cancer\ndiagnostics."}
{"id": "2505.09615", "pdf": "https://arxiv.org/pdf/2505.09615", "abs": "https://arxiv.org/abs/2505.09615", "authors": ["Yung-Hsuan Lai", "Janek Ebbers", "Yu-Chiang Frank Wang", "François Germain", "Michael Jeffrey Jones", "Moitreya Chatterjee"], "title": "UWAV: Uncertainty-weighted Weakly-supervised Audio-Visual Video Parsing", "categories": ["cs.CV", "cs.SD", "eess.AS"], "comment": "CVPR 2025", "summary": "Audio-Visual Video Parsing (AVVP) entails the challenging task of localizing\nboth uni-modal events (i.e., those occurring exclusively in either the visual\nor acoustic modality of a video) and multi-modal events (i.e., those occurring\nin both modalities concurrently). Moreover, the prohibitive cost of annotating\ntraining data with the class labels of all these events, along with their start\nand end times, imposes constraints on the scalability of AVVP techniques unless\nthey can be trained in a weakly-supervised setting, where only\nmodality-agnostic, video-level labels are available in the training data. To\nthis end, recently proposed approaches seek to generate segment-level\npseudo-labels to better guide model training. However, the absence of\ninter-segment dependencies when generating these pseudo-labels and the general\nbias towards predicting labels that are absent in a segment limit their\nperformance. This work proposes a novel approach towards overcoming these\nweaknesses called Uncertainty-weighted Weakly-supervised Audio-visual Video\nParsing (UWAV). Additionally, our innovative approach factors in the\nuncertainty associated with these estimated pseudo-labels and incorporates a\nfeature mixup based training regularization for improved training. Empirical\nresults show that UWAV outperforms state-of-the-art methods for the AVVP task\non multiple metrics, across two different datasets, attesting to its\neffectiveness and generalizability."}
{"id": "2505.09142", "pdf": "https://arxiv.org/pdf/2505.09142", "abs": "https://arxiv.org/abs/2505.09142", "authors": ["Seungbeom Choi", "Jeonghoe Goo", "Eunjoo Jeon", "Mingyu Yang", "Minsung Jang"], "title": "ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "13 pages, 5 figures. Cloud-native LLM scheduling system with\n  latency-aware inference optimization", "summary": "We propose ELIS, a serving system for Large Language Models (LLMs) featuring\nan Iterative Shortest Remaining Time First (ISRTF) scheduler designed to\nefficiently manage inference tasks with the shortest remaining tokens. Current\nLLM serving systems often employ a first-come-first-served scheduling strategy,\nwhich can lead to the \"head-of-line blocking\" problem. To overcome this\nlimitation, it is necessary to predict LLM inference times and apply a shortest\njob first scheduling strategy. However, due to the auto-regressive nature of\nLLMs, predicting the inference latency is challenging. ELIS addresses this\nchallenge by training a response length predictor for LLMs using the BGE model,\nan encoder-based state-of-the-art model. Additionally, we have devised the\nISRTF scheduling strategy, an optimization of shortest remaining time first\ntailored to existing LLM iteration batching. To evaluate our work in an\nindustrial setting, we simulate streams of requests based on our study of\nreal-world user LLM serving trace records. Furthermore, we implemented ELIS as\na cloud-native scheduler system on Kubernetes to evaluate its performance in\nproduction environments. Our experimental results demonstrate that ISRTF\nreduces the average job completion time by up to 19.6%."}
{"id": "2505.08899", "pdf": "https://arxiv.org/pdf/2505.08899", "abs": "https://arxiv.org/abs/2505.08899", "authors": ["Andrew Mullhaupt", "Cheng Peng"], "title": "Bounding Neyman-Pearson Region with $f$-Divergences", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "comment": null, "summary": "The Neyman-Pearson region of a simple binary hypothesis testing is the set of\npoints whose coordinates represent the false positive rate and false negative\nrate of some test. The lower boundary of this region is given by the\nNeyman-Pearson lemma, and is up to a coordinate change, equivalent to the\noptimal ROC curve. We establish a novel lower bound for the boundary in terms\nof any $f$-divergence. Since the bound generated by hockey-stick\n$f$-divergences characterizes the Neyman-Pearson boundary, this bound is best\npossible. In the case of KL divergence, this bound improves Pinsker's\ninequality. Furthermore, we obtain a closed-form refined upper bound for the\nNeyman-Pearson boundary in terms of the Chernoff $\\alpha$-coefficient. Finally,\nwe present methods for constructing pairs of distributions that can\napproximately or exactly realize any given Neyman-Pearson boundary."}
{"id": "2505.08798", "pdf": "https://arxiv.org/pdf/2505.08798", "abs": "https://arxiv.org/abs/2505.08798", "authors": ["Mobina Shrestha", "Bishwas Mandal", "Vishal Mandal", "Asis Shrestha"], "title": "In-Context Learning for Label-Efficient Cancer Image Classification in Oncology", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "The application of AI in oncology has been limited by its reliance on large,\nannotated datasets and the need for retraining models for domain-specific\ndiagnostic tasks. Taking heed of these limitations, we investigated in-context\nlearning as a pragmatic alternative to model retraining by allowing models to\nadapt to new diagnostic tasks using only a few labeled examples at inference,\nwithout the need for retraining. Using four vision-language models\n(VLMs)-Paligemma, CLIP, ALIGN and GPT-4o, we evaluated the performance across\nthree oncology datasets: MHIST, PatchCamelyon and HAM10000. To the best of our\nknowledge, this is the first study to compare the performance of multiple VLMs\non different oncology classification tasks. Without any parameter updates, all\nmodels showed significant gains with few-shot prompting, with GPT-4o reaching\nan F1 score of 0.81 in binary classification and 0.60 in multi-class\nclassification settings. While these results remain below the ceiling of fully\nfine-tuned systems, they highlight the potential of ICL to approximate\ntask-specific behavior using only a handful of examples, reflecting how\nclinicians often reason from prior cases. Notably, open-source models like\nPaligemma and CLIP demonstrated competitive gains despite their smaller size,\nsuggesting feasibility for deployment in computing constrained clinical\nenvironments. Overall, these findings highlight the potential of ICL as a\npractical solution in oncology, particularly for rare cancers and\nresource-limited contexts where fine-tuning is infeasible and annotated data is\ndifficult to obtain."}
{"id": "2505.09160", "pdf": "https://arxiv.org/pdf/2505.09160", "abs": "https://arxiv.org/abs/2505.09160", "authors": ["Berkay Guler", "Giovanni Geraci", "Hamid Jafarkhani"], "title": "A Multi-Task Foundation Model for Wireless Channel Representation Using Contrastive and Masked Autoencoder Learning", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Current applications of self-supervised learning to wireless channel\nrepresentation often borrow paradigms developed for text and image processing,\nwithout fully addressing the unique characteristics and constraints of wireless\ncommunications. Aiming to fill this gap, we first propose WiMAE (Wireless\nMasked Autoencoder), a transformer-based encoder-decoder foundation model\npretrained on a realistic open-source multi-antenna wireless channel dataset.\nBuilding upon this foundation, we develop ContraWiMAE, which enhances WiMAE by\nincorporating a contrastive learning objective alongside the reconstruction\ntask in a unified multi-task framework. By warm-starting from pretrained WiMAE\nweights and generating positive pairs via noise injection, the contrastive\ncomponent enables the model to capture both structural and discriminative\nfeatures, enhancing representation quality beyond what reconstruction alone can\nachieve. Through extensive evaluation on unseen scenarios, we demonstrate the\neffectiveness of both approaches across multiple downstream tasks, with\nContraWiMAE showing further improvements in linear separability and\nadaptability in diverse wireless environments. Comparative evaluations against\na state-of-the-art wireless channel foundation model confirm the superior\nperformance and data efficiency of our models, highlighting their potential as\npowerful baselines for future research in self-supervised wireless channel\nrepresentation learning."}
{"id": "2505.08908", "pdf": "https://arxiv.org/pdf/2505.08908", "abs": "https://arxiv.org/abs/2505.08908", "authors": ["Benedikt Koch", "Kosuke Imai"], "title": "Statistical Decision Theory with Counterfactual Loss", "categories": ["math.ST", "cs.LG", "econ.TH", "stat.TH"], "comment": null, "summary": "Classical statistical decision theory evaluates treatment choices based\nsolely on observed outcomes. However, by ignoring counterfactual outcomes, it\ncannot assess the quality of decisions relative to feasible alternatives. For\nexample, the quality of a physician's decision may depend not only on patient\nsurvival, but also on whether a less invasive treatment could have produced a\nsimilar result. To address this limitation, we extend standard decision theory\nto incorporate counterfactual losses--criteria that evaluate decisions using\nall potential outcomes. The central challenge in this generalization is\nidentification: because only one potential outcome is observed for each unit,\nthe associated risk under a counterfactual loss is generally not identifiable.\nWe show that under the assumption of strong ignorability, a counterfactual risk\nis identifiable if and only if the counterfactual loss function is additive in\nthe potential outcomes. Moreover, we demonstrate that additive counterfactual\nlosses can yield treatment recommendations that differ from those based on\nstandard loss functions, provided that the decision problem involves more than\ntwo treatment options."}
{"id": "2505.08819", "pdf": "https://arxiv.org/pdf/2505.08819", "abs": "https://arxiv.org/abs/2505.08819", "authors": ["Asahi Miyazaki", "Tsuyoshi Okita"], "title": "Thoughts on Objectives of Sparse and Hierarchical Masked Image Model", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "9 pages, 11 figures", "summary": "Masked image modeling is one of the most poplular objectives of training.\nRecently, the SparK model has been proposed with superior performance among\nself-supervised learning models. This paper proposes a new mask pattern for\nthis SparK model, proposing it as the Mesh Mask-ed SparK model. We report the\neffect of the mask pattern used for image masking in pre-training on\nperformance."}
{"id": "2505.09166", "pdf": "https://arxiv.org/pdf/2505.09166", "abs": "https://arxiv.org/abs/2505.09166", "authors": ["Hannu Simonen", "Atte Kiviniemi", "Jonas Oppenlaender"], "title": "An Initial Exploration of Default Images in Text-to-Image Generation", "categories": ["cs.HC", "cs.AI", "H.5.m; I.2.m"], "comment": "16 pages, 6 figures", "summary": "In the creative practice of text-to-image generation (TTI), images are\ngenerated from text prompts. However, TTI models are trained to always yield an\noutput, even if the prompt contains unknown terms. In this case, the model may\ngenerate what we call \"default images\": images that closely resemble each other\nacross many unrelated prompts. We argue studying default images is valuable for\ndesigning better solutions for TTI and prompt engineering. In this paper, we\nprovide the first investigation into default images on Midjourney, a popular\nimage generator. We describe our systematic approach to create input prompts\ntriggering default images, and present the results of our initial experiments\nand several small-scale ablation studies. We also report on a survey study\ninvestigating how default images affect user satisfaction. Our work lays the\nfoundation for understanding default images in TTI and highlights challenges\nand future research directions."}
{"id": "2505.08909", "pdf": "https://arxiv.org/pdf/2505.08909", "abs": "https://arxiv.org/abs/2505.08909", "authors": ["Deliang Wei", "Peng Chen", "Haobo Xu", "Jiale Yao", "Fang Li", "Tieyong Zeng"], "title": "Learning Cocoercive Conservative Denoisers via Helmholtz Decomposition for Poisson Inverse Problems", "categories": ["cs.CV", "cs.LG", "math.FA", "math.OC", "94A08, 47H10, 47J26, 46N10, 47N10"], "comment": "31 pages", "summary": "Plug-and-play (PnP) methods with deep denoisers have shown impressive results\nin imaging problems. They typically require strong convexity or smoothness of\nthe fidelity term and a (residual) non-expansive denoiser for convergence.\nThese assumptions, however, are violated in Poisson inverse problems, and\nnon-expansiveness can hinder denoising performance. To address these\nchallenges, we propose a cocoercive conservative (CoCo) denoiser, which may be\n(residual) expansive, leading to improved denoising. By leveraging the\ngeneralized Helmholtz decomposition, we introduce a novel training strategy\nthat combines Hamiltonian regularization to promote conservativeness and\nspectral regularization to ensure cocoerciveness. We prove that CoCo denoiser\nis a proximal operator of a weakly convex function, enabling a restoration\nmodel with an implicit weakly convex prior. The global convergence of PnP\nmethods to a stationary point of this restoration model is established.\nExtensive experimental results demonstrate that our approach outperforms\nclosely related methods in both visual quality and quantitative metrics."}
{"id": "2505.08835", "pdf": "https://arxiv.org/pdf/2505.08835", "abs": "https://arxiv.org/abs/2505.08835", "authors": ["Hyunsik Na", "Wonho Lee", "Seungdeok Roh", "Sohee Park", "Daeseon Choi"], "title": "Robustness Analysis against Adversarial Patch Attacks in Fully Unmanned Stores", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": null, "summary": "The advent of convenient and efficient fully unmanned stores equipped with\nartificial intelligence-based automated checkout systems marks a new era in\nretail. However, these systems have inherent artificial intelligence security\nvulnerabilities, which are exploited via adversarial patch attacks,\nparticularly in physical environments. This study demonstrated that adversarial\npatches can severely disrupt object detection models used in unmanned stores,\nleading to issues such as theft, inventory discrepancies, and interference. We\ninvestigated three types of adversarial patch attacks -- Hiding, Creating, and\nAltering attacks -- and highlighted their effectiveness. We also introduce the\nnovel color histogram similarity loss function by leveraging attacker knowledge\nof the color information of a target class object. Besides the traditional\nconfusion-matrix-based attack success rate, we introduce a new\nbounding-boxes-based metric to analyze the practical impact of these attacks.\nStarting with attacks on object detection models trained on snack and fruit\ndatasets in a digital environment, we evaluated the effectiveness of\nadversarial patches in a physical testbed that mimicked a real unmanned store\nwith RGB cameras and realistic conditions. Furthermore, we assessed the\nrobustness of these attacks in black-box scenarios, demonstrating that shadow\nattacks can enhance success rates of attacks even without direct access to\nmodel parameters. Our study underscores the necessity for robust defense\nstrategies to protect unmanned stores from adversarial threats. Highlighting\nthe limitations of the current defense mechanisms in real-time detection\nsystems and discussing various proactive measures, we provide insights into\nimproving the robustness of object detection models and fortifying unmanned\nretail environments against these attacks."}
{"id": "2505.09168", "pdf": "https://arxiv.org/pdf/2505.09168", "abs": "https://arxiv.org/abs/2505.09168", "authors": ["Jianlin Sun", "Xiaolin Fang", "Juwei Guan", "Dongdong Gui", "Teqi Wang", "Tongxin Zhu"], "title": "DRRNet: Macro-Micro Feature Fusion and Dual Reverse Refinement for Camouflaged Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The core challenge in Camouflage Object Detection (COD) lies in the\nindistinguishable similarity between targets and backgrounds in terms of color,\ntexture, and shape. This causes existing methods to either lose edge details\n(such as hair-like fine structures) due to over-reliance on global semantic\ninformation or be disturbed by similar backgrounds (such as vegetation\npatterns) when relying solely on local features. We propose DRRNet, a\nfour-stage architecture characterized by a \"context-detail-fusion-refinement\"\npipeline to address these issues. Specifically, we introduce an Omni-Context\nFeature Extraction Module to capture global camouflage patterns and a Local\nDetail Extraction Module to supplement microstructural information for the\nfull-scene context module. We then design a module for forming dual\nrepresentations of scene understanding and structural awareness, which fuses\npanoramic features and local features across various scales. In the decoder, we\nalso introduce a reverse refinement module that leverages spatial edge priors\nand frequency-domain noise suppression to perform a two-stage inverse\nrefinement of the output. By applying two successive rounds of inverse\nrefinement, the model effectively suppresses background interference and\nenhances the continuity of object boundaries. Experimental results demonstrate\nthat DRRNet significantly outperforms state-of-the-art methods on benchmark\ndatasets. Our code is available at https://github.com/jerrySunning/DRRNet."}
{"id": "2505.08961", "pdf": "https://arxiv.org/pdf/2505.08961", "abs": "https://arxiv.org/abs/2505.08961", "authors": ["Yancheng Wang", "Nebojsa Jojic", "Yingzhen Yang"], "title": "Differentiable Channel Selection in Self-Attention For Person Re-Identification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In this paper, we propose a novel attention module termed the Differentiable\nChannel Selection Attention module, or the DCS-Attention module. In contrast\nwith conventional self-attention, the DCS-Attention module features selection\nof informative channels in the computation of the attention weights. The\nselection of the feature channels is performed in a differentiable manner,\nenabling seamless integration with DNN training. Our DCS-Attention is\ncompatible with either fixed neural network backbones or learnable backbones\nwith Differentiable Neural Architecture Search (DNAS), leading to DCS with\nFixed Backbone (DCS-FB) and DCS-DNAS, respectively. Importantly, our\nDCS-Attention is motivated by the principle of Information Bottleneck (IB), and\na novel variational upper bound for the IB loss, which can be optimized by SGD,\nis derived and incorporated into the training loss of the networks with the\nDCS-Attention modules. In this manner, a neural network with DCS-Attention\nmodules is capable of selecting the most informative channels for feature\nextraction so that it enjoys state-of-the-art performance for the Re-ID task.\nExtensive experiments on multiple person Re-ID benchmarks using both DCS-FB and\nDCS-DNAS show that DCS-Attention significantly enhances the prediction accuracy\nof DNNs for person Re-ID, which demonstrates the effectiveness of DCS-Attention\nin learning discriminative features critical to identifying person identities.\nThe code of our work is available at\nhttps://github.com/Statistical-Deep-Learning/DCS-Attention."}
{"id": "2505.08837", "pdf": "https://arxiv.org/pdf/2505.08837", "abs": "https://arxiv.org/abs/2505.08837", "authors": ["Muhammad Saqib", "Dipkumar Mehta", "Fnu Yashu", "Shubham Malhotra"], "title": "Adaptive Security Policy Management in Cloud Environments Using Reinforcement Learning", "categories": ["cs.CR", "cs.CV", "cs.DC", "cs.LG", "cs.NI"], "comment": "10 pages, 6 figures, 1 table", "summary": "The security of cloud environments, such as Amazon Web Services (AWS), is\ncomplex and dynamic. Static security policies have become inadequate as threats\nevolve and cloud resources exhibit elasticity [1]. This paper addresses the\nlimitations of static policies by proposing a security policy management\nframework that uses reinforcement learning (RL) to adapt dynamically.\nSpecifically, we employ deep reinforcement learning algorithms, including deep\nQ Networks and proximal policy optimization, enabling the learning and\ncontinuous adjustment of controls such as firewall rules and Identity and\nAccess Management (IAM) policies. The proposed RL based solution leverages\ncloud telemetry data (AWS Cloud Trail logs, network traffic data, threat\nintelligence feeds) to continuously refine security policies, maximizing threat\nmitigation, and compliance while minimizing resource impact. Experimental\nresults demonstrate that our adaptive RL based framework significantly\noutperforms static policies, achieving higher intrusion detection rates (92%\ncompared to 82% for static policies) and substantially reducing incident\ndetection and response times by 58%. In addition, it maintains high conformity\nwith security requirements and efficient resource usage. These findings\nvalidate the effectiveness of adaptive reinforcement learning approaches in\nimproving cloud security policy management."}
{"id": "2505.09203", "pdf": "https://arxiv.org/pdf/2505.09203", "abs": "https://arxiv.org/abs/2505.09203", "authors": ["Xiao-Qi Han", "Peng-Jie Guo", "Ze-Feng Gao", "Hao Sun", "Zhong-Yi Lu"], "title": "InvDesFlow-AL: Active Learning-based Workflow for Inverse Design of Functional Materials", "categories": ["cond-mat.mtrl-sci", "cond-mat.supr-con", "cs.AI", "cs.LG"], "comment": "29 pages, 11 figures", "summary": "Developing inverse design methods for functional materials with specific\nproperties is critical to advancing fields like renewable energy, catalysis,\nenergy storage, and carbon capture. Generative models based on diffusion\nprinciples can directly produce new materials that meet performance\nconstraints, thereby significantly accelerating the material design process.\nHowever, existing methods for generating and predicting crystal structures\noften remain limited by low success rates. In this work, we propose a novel\ninverse material design generative framework called InvDesFlow-AL, which is\nbased on active learning strategies. This framework can iteratively optimize\nthe material generation process to gradually guide it towards desired\nperformance characteristics. In terms of crystal structure prediction, the\nInvDesFlow-AL model achieves an RMSE of 0.0423 {\\AA}, representing an 32.96%\nimprovement in performance compared to exsisting generative models.\nAdditionally, InvDesFlow-AL has been successfully validated in the design of\nlow-formation-energy and low-Ehull materials. It can systematically generate\nmaterials with progressively lower formation energies while continuously\nexpanding the exploration across diverse chemical spaces. These results fully\ndemonstrate the effectiveness of the proposed active learning-driven generative\nmodel in accelerating material discovery and inverse design. To further prove\nthe effectiveness of this method, we took the search for BCS superconductors\nunder ambient pressure as an example explored by InvDesFlow-AL. As a result, we\nsuccessfully identified Li\\(_2\\)AuH\\(_6\\) as a conventional BCS superconductor\nwith an ultra-high transition temperature of 140 K. This discovery provides\nstrong empirical support for the application of inverse design in materials\nscience."}
{"id": "2505.08971", "pdf": "https://arxiv.org/pdf/2505.08971", "abs": "https://arxiv.org/abs/2505.08971", "authors": ["Yangyi Chen", "Hao Peng", "Tong Zhang", "Heng Ji"], "title": "Prioritizing Image-Related Tokens Enhances Vision-Language Pre-Training", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "The code will be available at https://github.com/Yangyi-Chen/PRIOR", "summary": "In standard large vision-language models (LVLMs) pre-training, the model\ntypically maximizes the joint probability of the caption conditioned on the\nimage via next-token prediction (NTP); however, since only a small subset of\ncaption tokens directly relates to the visual content, this naive NTP\nunintentionally fits the model to noise and increases the risk of\nhallucination. We present PRIOR, a simple vision-language pre-training approach\nthat addresses this issue by prioritizing image-related tokens through\ndifferential weighting in the NTP loss, drawing from the importance sampling\nframework. PRIOR introduces a reference model-a text-only large language model\n(LLM) trained on the captions without image inputs, to weight each token based\non its probability for LVLMs training. Intuitively, tokens that are directly\nrelated to the visual inputs are harder to predict without the image and thus\nreceive lower probabilities from the text-only reference LLM. During training,\nwe implement a token-specific re-weighting term based on the importance scores\nto adjust each token's loss. We implement PRIOR in two distinct settings: LVLMs\nwith visual encoders and LVLMs without visual encoders. We observe 19% and 8%\naverage relative improvement, respectively, on several vision-language\nbenchmarks compared to NTP. In addition, PRIOR exhibits superior scaling\nproperties, as demonstrated by significantly higher scaling coefficients,\nindicating greater potential for performance gains compared to NTP given\nincreasing compute and data."}
{"id": "2505.08838", "pdf": "https://arxiv.org/pdf/2505.08838", "abs": "https://arxiv.org/abs/2505.08838", "authors": ["Peixuan Ge", "Tongkun Su", "Faqin Lv", "Baoliang Zhao", "Peng Zhang", "Chi Hong Wong", "Liang Yao", "Yu Sun", "Zenan Wang", "Pak Kin Wong", "Ying Hu"], "title": "Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Ultrasound (US) report generation is a challenging task due to the\nvariability of US images, operator dependence, and the need for standardized\ntext. Unlike X-ray and CT, US imaging lacks consistent datasets, making\nautomation difficult. In this study, we propose a unified framework for\nmulti-organ and multilingual US report generation, integrating fragment-based\nmultilingual training and leveraging the standardized nature of US reports. By\naligning modular text fragments with diverse imaging data and curating a\nbilingual English-Chinese dataset, the method achieves consistent and\nclinically accurate text generation across organ sites and languages.\nFine-tuning with selective unfreezing of the vision transformer (ViT) further\nimproves text-image alignment. Compared to the previous state-of-the-art KMVE\nmethod, our approach achieves relative gains of about 2\\% in BLEU scores,\napproximately 3\\% in ROUGE-L, and about 15\\% in CIDEr, while significantly\nreducing errors such as missing or incorrect content. By unifying multi-organ\nand multi-language report generation into a single, scalable framework, this\nwork demonstrates strong potential for real-world clinical workflows."}
{"id": "2505.09208", "pdf": "https://arxiv.org/pdf/2505.09208", "abs": "https://arxiv.org/abs/2505.09208", "authors": ["Lei Fan", "Kunyang Deng", "Fangxue Liu"], "title": "Educational impacts of generative artificial intelligence on learning and performance of engineering students in China", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "With the rapid advancement of generative artificial intelligence(AI), its\npotential applications in higher education have attracted significant\nattention. This study investigated how 148 students from diverse engineering\ndisciplines and regions across China used generative AI, focusing on its impact\non their learning experience and the opportunities and challenges it poses in\nengineering education. Based on the surveyed data, we explored four key areas:\nthe frequency and application scenarios of AI use among engineering students,\nits impact on students' learning and performance, commonly encountered\nchallenges in using generative AI, and future prospects for its adoption in\nengineering education. The results showed that more than half of the\nparticipants reported a positive impact of generative AI on their learning\nefficiency, initiative, and creativity, with nearly half believing it also\nenhanced their independent thinking. However, despite acknowledging improved\nstudy efficiency, many felt their actual academic performance remained largely\nunchanged and expressed concerns about the accuracy and domain-specific\nreliability of generative AI. Our findings provide a first-hand insight into\nthe current benefits and challenges generative AI brings to students,\nparticularly Chinese engineering students, while offering several\nrecommendations, especially from the students' perspective, for effectively\nintegrating generative AI into engineering education."}
{"id": "2505.08986", "pdf": "https://arxiv.org/pdf/2505.08986", "abs": "https://arxiv.org/abs/2505.08986", "authors": ["Amirreza Davar", "Zhengtong Xu", "Siavash Mahmoudi", "Pouya Sohrabipour", "Chaitanya Pallerla", "Yu She", "Wan Shou", "Philip Crandall", "Dongyi Wang"], "title": "ChicGrasp: Imitation-Learning based Customized Dual-Jaw Gripper Control for Delicate, Irregular Bio-products Manipulation", "categories": ["cs.RO", "cs.LG"], "comment": "Submitted for journal review", "summary": "Automated poultry processing lines still rely on humans to lift slippery,\neasily bruised carcasses onto a shackle conveyor. Deformability, anatomical\nvariance, and strict hygiene rules make conventional suction and scripted\nmotions unreliable. We present ChicGrasp, an end--to--end hardware--software\nco-design for this task. An independently actuated dual-jaw pneumatic gripper\nclamps both chicken legs, while a conditional diffusion-policy controller,\ntrained from only 50 multi--view teleoperation demonstrations (RGB +\nproprioception), plans 5 DoF end--effector motion, which includes jaw commands\nin one shot. On individually presented raw broiler carcasses, our system\nachieves a 40.6\\% grasp--and--lift success rate and completes the pick to\nshackle cycle in 38 s, whereas state--of--the--art implicit behaviour cloning\n(IBC) and LSTM-GMM baselines fail entirely. All CAD, code, and datasets will be\nopen-source. ChicGrasp shows that imitation learning can bridge the gap between\nrigid hardware and variable bio--products, offering a reproducible benchmark\nand a public dataset for researchers in agricultural engineering and robot\nlearning."}
{"id": "2505.08843", "pdf": "https://arxiv.org/pdf/2505.08843", "abs": "https://arxiv.org/abs/2505.08843", "authors": ["Marco Corrias", "Giada Franceschi", "Michele Riva", "Alberto Tampieri", "Karin Föttinger", "Ulrike Diebold", "Thomas Pock", "Cesare Franchini"], "title": "Total Variation-Based Image Decomposition and Denoising for Microscopy Images", "categories": ["eess.IV", "cond-mat.mtrl-sci", "cs.CV"], "comment": null, "summary": "Experimentally acquired microscopy images are unavoidably affected by the\npresence of noise and other unwanted signals, which degrade their quality and\nmight hide relevant features. With the recent increase in image acquisition\nrate, modern denoising and restoration solutions become necessary. This study\nfocuses on image decomposition and denoising of microscopy images through a\nworkflow based on total variation (TV), addressing images obtained from various\nmicroscopy techniques, including atomic force microscopy (AFM), scanning\ntunneling microscopy (STM), and scanning electron microscopy (SEM). Our\napproach consists in restoring an image by extracting its unwanted signal\ncomponents and subtracting them from the raw one, or by denoising it. We\nevaluate the performance of TV-$L^1$, Huber-ROF, and TGV-$L^1$ in achieving\nthis goal in distinct study cases. Huber-ROF proved to be the most flexible\none, while TGV-$L^1$ is the most suitable for denoising. Our results suggest a\nwider applicability of this method in microscopy, restricted not only to STM,\nAFM, and SEM images. The Python code used for this study is publicly available\nas part of AiSurf. It is designed to be integrated into experimental workflows\nfor image acquisition or can be used to denoise previously acquired images."}
{"id": "2505.09246", "pdf": "https://arxiv.org/pdf/2505.09246", "abs": "https://arxiv.org/abs/2505.09246", "authors": ["Derian Boer", "Stephen Roth", "Stefan Kramer"], "title": "Focus, Merge, Rank: Improved Question Answering Based on Semi-structured Knowledge Bases", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "In many real-world settings, machine learning models and interactive systems\nhave access to both structured knowledge, e.g., knowledge graphs or tables, and\nunstructured content, e.g., natural language documents. However, most rely on\neither. Semi-Structured Knowledge Bases (SKBs) bridge this gap by linking\nunstructured content to nodes within structured data, thereby enabling new\nstrategies for knowledge access and use. In this work, we present\nFocusedRetriever, a modular SKB-based framework for multi-hop question\nanswering. It integrates components (VSS-based entity search, LLM-based\ngeneration of Cypher queries and pairwise re-ranking) in a way that enables it\nto outperform state-of-the-art methods across all three STaRK benchmark test\nsets, covering diverse domains and multiple performance metrics. The average\nfirst-hit rate exceeds that of the second-best method by 25.7%.\nFocusedRetriever leverages (1) the capacity of Large Language Models (LLMs) to\nextract relational facts and entity attributes from unstructured text, (2) node\nset joins to filter answer candidates based on these extracted triplets and\nconstraints, (3) vector similarity search to retrieve and rank relevant\nunstructured content, and (4) the contextual capabilities of LLMs to finally\nrank the top-k answers. For generality, we only incorporate base LLMs in\nFocusedRetriever in our evaluation. However, our analysis of intermediate\nresults highlights several opportunities for further upgrades including\nfinetuning. The source code is publicly available at\nhttps://github.com/kramerlab/FocusedRetriever ."}
{"id": "2505.08995", "pdf": "https://arxiv.org/pdf/2505.08995", "abs": "https://arxiv.org/abs/2505.08995", "authors": ["Ardian Selmonaj", "Oleg Szehr", "Giacomo Del Rio", "Alessandro Antonucci", "Adrian Schneider", "Michael Rüegsegger"], "title": "Enhancing Aerial Combat Tactics through Hierarchical Multi-Agent Reinforcement Learning", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.RO"], "comment": "Published as journal chapter in Deep Learning Applications, Vol. 1,\n  by Taylor & Francis", "summary": "This work presents a Hierarchical Multi-Agent Reinforcement Learning\nframework for analyzing simulated air combat scenarios involving heterogeneous\nagents. The objective is to identify effective Courses of Action that lead to\nmission success within preset simulations, thereby enabling the exploration of\nreal-world defense scenarios at low cost and in a safe-to-fail setting.\nApplying deep Reinforcement Learning in this context poses specific challenges,\nsuch as complex flight dynamics, the exponential size of the state and action\nspaces in multi-agent systems, and the capability to integrate real-time\ncontrol of individual units with look-ahead planning. To address these\nchallenges, the decision-making process is split into two levels of\nabstraction: low-level policies control individual units, while a high-level\ncommander policy issues macro commands aligned with the overall mission\ntargets. This hierarchical structure facilitates the training process by\nexploiting policy symmetries of individual agents and by separating control\nfrom command tasks. The low-level policies are trained for individual combat\ncontrol in a curriculum of increasing complexity. The high-level commander is\nthen trained on mission targets given pre-trained control policies. The\nempirical validation confirms the advantages of the proposed framework."}
{"id": "2505.08845", "pdf": "https://arxiv.org/pdf/2505.08845", "abs": "https://arxiv.org/abs/2505.08845", "authors": ["Misgina Tsighe Hagos", "Antti Suutala", "Dmitrii Bychkov", "Hakan Kücükel", "Joar von Bahr", "Milda Poceviciute", "Johan Lundin", "Nina Linder", "Claes Lundström"], "title": "Validation of Conformal Prediction in Cervical Atypia Classification", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Deep learning based cervical cancer classification can potentially increase\naccess to screening in low-resource regions. However, deep learning models are\noften overconfident and do not reliably reflect diagnostic uncertainty.\nMoreover, they are typically optimized to generate maximum-likelihood\npredictions, which fail to convey uncertainty or ambiguity in their results.\nSuch challenges can be addressed using conformal prediction, a model-agnostic\nframework for generating prediction sets that contain likely classes for\ntrained deep-learning models. The size of these prediction sets indicates model\nuncertainty, contracting as model confidence increases. However, existing\nconformal prediction evaluation primarily focuses on whether the prediction set\nincludes or covers the true class, often overlooking the presence of extraneous\nclasses. We argue that prediction sets should be truthful and valuable to end\nusers, ensuring that the listed likely classes align with human expectations\nrather than being overly relaxed and including false positives or unlikely\nclasses. In this study, we comprehensively validate conformal prediction sets\nusing expert annotation sets collected from multiple annotators. We evaluate\nthree conformal prediction approaches applied to three deep-learning models\ntrained for cervical atypia classification. Our expert annotation-based\nanalysis reveals that conventional coverage-based evaluations overestimate\nperformance and that current conformal prediction methods often produce\nprediction sets that are not well aligned with human labels. Additionally, we\nexplore the capabilities of the conformal prediction methods in identifying\nambiguous and out-of-distribution data."}
{"id": "2505.09262", "pdf": "https://arxiv.org/pdf/2505.09262", "abs": "https://arxiv.org/abs/2505.09262", "authors": ["Hongxin Xiang", "Ke Li", "Mingquan Liu", "Zhixiang Cheng", "Bin Yao", "Wenjie Du", "Jun Xia", "Li Zeng", "Xin Jin", "Xiangxiang Zeng"], "title": "EDBench: Large-Scale Electron Density Data for Molecular Modeling", "categories": ["physics.chem-ph", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Existing molecular machine learning force fields (MLFFs) generally focus on\nthe learning of atoms, molecules, and simple quantum chemical properties (such\nas energy and force), but ignore the importance of electron density (ED)\n$\\rho(r)$ in accurately understanding molecular force fields (MFFs). ED\ndescribes the probability of finding electrons at specific locations around\natoms or molecules, which uniquely determines all ground state properties (such\nas energy, molecular structure, etc.) of interactive multi-particle systems\naccording to the Hohenberg-Kohn theorem. However, the calculation of ED relies\non the time-consuming first-principles density functional theory (DFT) which\nleads to the lack of large-scale ED data and limits its application in MLFFs.\nIn this paper, we introduce EDBench, a large-scale, high-quality dataset of ED\ndesigned to advance learning-based research at the electronic scale. Built upon\nthe PCQM4Mv2, EDBench provides accurate ED data, covering 3.3 million\nmolecules. To comprehensively evaluate the ability of models to understand and\nutilize electronic information, we design a suite of ED-centric benchmark tasks\nspanning prediction, retrieval, and generation. Our evaluation on several\nstate-of-the-art methods demonstrates that learning from EDBench is not only\nfeasible but also achieves high accuracy. Moreover, we show that learning-based\nmethod can efficiently calculate ED with comparable precision while\nsignificantly reducing the computational cost relative to traditional DFT\ncalculations. All data and benchmarks from EDBench will be freely available,\nlaying a robust foundation for ED-driven drug discovery and materials science."}
{"id": "2505.09004", "pdf": "https://arxiv.org/pdf/2505.09004", "abs": "https://arxiv.org/abs/2505.09004", "authors": ["Monica Welfert", "Nathan Stromberg", "Mario Diaz", "Lalitha Sankar"], "title": "Lower Bounds on the MMSE of Adversarially Inferring Sensitive Features", "categories": ["stat.ML", "cs.LG"], "comment": "submitted to IEEE Transactions on Information Theory", "summary": "We propose an adversarial evaluation framework for sensitive feature\ninference based on minimum mean-squared error (MMSE) estimation with a finite\nsample size and linear predictive models. Our approach establishes theoretical\nlower bounds on the true MMSE of inferring sensitive features from noisy\nobservations of other correlated features. These bounds are expressed in terms\nof the empirical MMSE under a restricted hypothesis class and a non-negative\nerror term. The error term captures both the estimation error due to finite\nnumber of samples and the approximation error from using a restricted\nhypothesis class. For linear predictive models, we derive closed-form bounds,\nwhich are order optimal in terms of the noise variance, on the approximation\nerror for several classes of relationships between the sensitive and\nnon-sensitive features, including linear mappings, binary symmetric channels,\nand class-conditional multi-variate Gaussian distributions. We also present a\nnew lower bound that relies on the MSE computed on a hold-out validation\ndataset of the MMSE estimator learned on finite-samples and a restricted\nhypothesis class. Through empirical evaluation, we demonstrate that our\nframework serves as an effective tool for MMSE-based adversarial evaluation of\nsensitive feature inference that balances theoretical guarantees with practical\nefficiency."}
{"id": "2505.08889", "pdf": "https://arxiv.org/pdf/2505.08889", "abs": "https://arxiv.org/abs/2505.08889", "authors": ["Linjie Lyu", "Valentin Deschaintre", "Yannick Hold-Geoffroy", "Miloš Hašan", "Jae Shin Yoon", "Thomas Leimkühler", "Christian Theobalt", "Iliyan Georgiev"], "title": "IntrinsicEdit: Precise generative image manipulation in intrinsic space", "categories": ["cs.GR", "cs.CV"], "comment": "SIGGRAPH 2025 Journal track", "summary": "Generative diffusion models have advanced image editing with high-quality\nresults and intuitive interfaces such as prompts and semantic drawing. However,\nthese interfaces lack precise control, and the associated methods typically\nspecialize on a single editing task. We introduce a versatile, generative\nworkflow that operates in an intrinsic-image latent space, enabling semantic,\nlocal manipulation with pixel precision for a range of editing operations.\nBuilding atop the RGB-X diffusion framework, we address key challenges of\nidentity preservation and intrinsic-channel entanglement. By incorporating\nexact diffusion inversion and disentangled channel manipulation, we enable\nprecise, efficient editing with automatic resolution of global illumination\neffects -- all without additional data collection or model fine-tuning. We\ndemonstrate state-of-the-art performance across a variety of tasks on complex\nimages, including color and texture adjustments, object insertion and removal,\nglobal relighting, and their combinations."}
{"id": "2505.09263", "pdf": "https://arxiv.org/pdf/2505.09263", "abs": "https://arxiv.org/abs/2505.09263", "authors": ["Guan Gui", "Bin-Bin Gao", "Jun Liu", "Chengjie Wang", "Yunsheng Wu"], "title": "Few-Shot Anomaly-Driven Generation for Anomaly Classification and Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ECCV 2024", "summary": "Anomaly detection is a practical and challenging task due to the scarcity of\nanomaly samples in industrial inspection. Some existing anomaly detection\nmethods address this issue by synthesizing anomalies with noise or external\ndata. However, there is always a large semantic gap between synthetic and\nreal-world anomalies, resulting in weak performance in anomaly detection. To\nsolve the problem, we propose a few-shot Anomaly-driven Generation (AnoGen)\nmethod, which guides the diffusion model to generate realistic and diverse\nanomalies with only a few real anomalies, thereby benefiting training anomaly\ndetection models. Specifically, our work is divided into three stages. In the\nfirst stage, we learn the anomaly distribution based on a few given real\nanomalies and inject the learned knowledge into an embedding. In the second\nstage, we use the embedding and given bounding boxes to guide the diffusion\nmodel to generate realistic and diverse anomalies on specific objects (or\ntextures). In the final stage, we propose a weakly-supervised anomaly detection\nmethod to train a more powerful model with generated anomalies. Our method\nbuilds upon DRAEM and DesTSeg as the foundation model and conducts experiments\non the commonly used industrial anomaly detection dataset, MVTec. The\nexperiments demonstrate that our generated anomalies effectively improve the\nmodel performance of both anomaly classification and segmentation tasks\nsimultaneously, \\eg, DRAEM and DseTSeg achieved a 5.8\\% and 1.5\\% improvement\nin AU-PR metric on segmentation task, respectively. The code and generated\nanomalous data are available at https://github.com/gaobb/AnoGen."}
{"id": "2505.09018", "pdf": "https://arxiv.org/pdf/2505.09018", "abs": "https://arxiv.org/abs/2505.09018", "authors": ["Adarsh Kumar"], "title": "Multimodal Fusion of Glucose Monitoring and Food Imagery for Caloric Content Prediction", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Effective dietary monitoring is critical for managing Type 2 diabetes, yet\naccurately estimating caloric intake remains a major challenge. While\ncontinuous glucose monitors (CGMs) offer valuable physiological data, they\noften fall short in capturing the full nutritional profile of meals due to\ninter-individual and meal-specific variability. In this work, we introduce a\nmultimodal deep learning framework that jointly leverages CGM time-series data,\nDemographic/Microbiome, and pre-meal food images to enhance caloric estimation.\nOur model utilizes attention based encoding and a convolutional feature\nextraction for meal imagery, multi-layer perceptrons for CGM and Microbiome\ndata followed by a late fusion strategy for joint reasoning. We evaluate our\napproach on a curated dataset of over 40 participants, incorporating\nsynchronized CGM, Demographic and Microbiome data and meal photographs with\nstandardized caloric labels. Our model achieves a Root Mean Squared Relative\nError (RMSRE) of 0.2544, outperforming the baselines models by over 50%. These\nfindings demonstrate the potential of multimodal sensing to improve automated\ndietary assessment tools for chronic disease management."}
{"id": "2505.08919", "pdf": "https://arxiv.org/pdf/2505.08919", "abs": "https://arxiv.org/abs/2505.08919", "authors": ["Kangxian Xie", "Yufei Zhu", "Kaiming Kuang", "Li Zhang", "Hongwei Bran Li", "Mingchen Gao", "Jiancheng Yang"], "title": "Template-Guided Reconstruction of Pulmonary Segments with Neural Implicit Functions", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "In revision process", "summary": "High-quality 3D reconstruction of pulmonary segments plays a crucial role in\nsegmentectomy and surgical treatment planning for lung cancer. Due to the\nresolution requirement of the target reconstruction, conventional deep\nlearning-based methods often suffer from computational resource constraints or\nlimited granularity. Conversely, implicit modeling is favored due to its\ncomputational efficiency and continuous representation at any resolution. We\npropose a neural implicit function-based method to learn a 3D surface to\nachieve anatomy-aware, precise pulmonary segment reconstruction, represented as\na shape by deforming a learnable template. Additionally, we introduce two\nclinically relevant evaluation metrics to assess the reconstruction\ncomprehensively. Further, due to the absence of publicly available shape\ndatasets to benchmark reconstruction algorithms, we developed a shape dataset\nnamed Lung3D, including the 3D models of 800 labeled pulmonary segments and the\ncorresponding airways, arteries, veins, and intersegmental veins. We\ndemonstrate that the proposed approach outperforms existing methods, providing\na new perspective for pulmonary segment reconstruction. Code and data will be\navailable at https://github.com/M3DV/ImPulSe."}
{"id": "2505.09264", "pdf": "https://arxiv.org/pdf/2505.09264", "abs": "https://arxiv.org/abs/2505.09264", "authors": ["Bin-Bin Gao"], "title": "Learning to Detect Multi-class Anomalies with Just One Normal Image Prompt", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ECCV 2024", "summary": "Unsupervised reconstruction networks using self-attention transformers have\nachieved state-of-the-art performance for multi-class (unified) anomaly\ndetection with a single model. However, these self-attention reconstruction\nmodels primarily operate on target features, which may result in perfect\nreconstruction for both normal and anomaly features due to high consistency\nwith context, leading to failure in detecting anomalies. Additionally, these\nmodels often produce inaccurate anomaly segmentation due to performing\nreconstruction in a low spatial resolution latent space. To enable\nreconstruction models enjoying high efficiency while enhancing their\ngeneralization for unified anomaly detection, we propose a simple yet effective\nmethod that reconstructs normal features and restores anomaly features with\njust One Normal Image Prompt (OneNIP). In contrast to previous work, OneNIP\nallows for the first time to reconstruct or restore anomalies with just one\nnormal image prompt, effectively boosting unified anomaly detection\nperformance. Furthermore, we propose a supervised refiner that regresses\nreconstruction errors by using both real normal and synthesized anomalous\nimages, which significantly improves pixel-level anomaly segmentation. OneNIP\noutperforms previous methods on three industry anomaly detection benchmarks:\nMVTec, BTAD, and VisA. The code and pre-trained models are available at\nhttps://github.com/gaobb/OneNIP."}
{"id": "2505.09024", "pdf": "https://arxiv.org/pdf/2505.09024", "abs": "https://arxiv.org/abs/2505.09024", "authors": ["Aaron Baughman", "Rahul Agarwal", "Eduardo Morales", "Gozde Akay"], "title": "Automated Meta Prompt Engineering for Alignment with the Theory of Mind", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "9 pages, 6 figures, 3 tables", "summary": "We introduce a method of meta-prompting that jointly produces fluent text for\ncomplex tasks while optimizing the similarity of neural states between a\nhuman's mental expectation and a Large Language Model's (LLM) neural\nprocessing. A technique of agentic reinforcement learning is applied, in which\nan LLM as a Judge (LLMaaJ) teaches another LLM, through in-context learning,\nhow to produce content by interpreting the intended and unintended generated\ntext traits. To measure human mental beliefs around content production, users\nmodify long form AI-generated text articles before publication at the US Open\n2024 tennis Grand Slam. Now, an LLMaaJ can solve the Theory of Mind (ToM)\nalignment problem by anticipating and including human edits within the creation\nof text from an LLM. Throughout experimentation and by interpreting the results\nof a live production system, the expectations of human content reviewers had\n100% of alignment with AI 53.8% of the time with an average iteration count of\n4.38. The geometric interpretation of content traits such as factualness,\nnovelty, repetitiveness, and relevancy over a Hilbert vector space combines\nspatial volume (all trait importance) with vertices alignment (individual trait\nrelevance) enabled the LLMaaJ to optimize on Human ToM. This resulted in an\nincrease in content quality by extending the coverage of tennis action. Our\nwork that was deployed at the US Open 2024 has been used across other live\nevents within sports and entertainment."}
{"id": "2505.08932", "pdf": "https://arxiv.org/pdf/2505.08932", "abs": "https://arxiv.org/abs/2505.08932", "authors": ["Mohammad Wasil", "Ahmad Drak", "Brennan Penfold", "Ludovico Scarton", "Maximilian Johenneken", "Alexander Asteroth", "Sebastian Houben"], "title": "Parameter-Efficient Fine-Tuning of Vision Foundation Model for Forest Floor Segmentation from UAV Imagery", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted to the Novel Approaches for Precision Agriculture and\n  Forestry with Autonomous Robots IEEE ICRA Workshop - 2025", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly used for reforestation and\nforest monitoring, including seed dispersal in hard-to-reach terrains. However,\na detailed understanding of the forest floor remains a challenge due to high\nnatural variability, quickly changing environmental parameters, and ambiguous\nannotations due to unclear definitions. To address this issue, we adapt the\nSegment Anything Model (SAM), a vision foundation model with strong\ngeneralization capabilities, to segment forest floor objects such as tree\nstumps, vegetation, and woody debris. To this end, we employ\nparameter-efficient fine-tuning (PEFT) to fine-tune a small subset of\nadditional model parameters while keeping the original weights fixed. We adjust\nSAM's mask decoder to generate masks corresponding to our dataset categories,\nallowing for automatic segmentation without manual prompting. Our results show\nthat the adapter-based PEFT method achieves the highest mean intersection over\nunion (mIoU), while Low-rank Adaptation (LoRA), with fewer parameters, offers a\nlightweight alternative for resource-constrained UAV platforms."}
{"id": "2505.09265", "pdf": "https://arxiv.org/pdf/2505.09265", "abs": "https://arxiv.org/abs/2505.09265", "authors": ["Bin-Bin Gao"], "title": "MetaUAS: Universal Anomaly Segmentation with One-Prompt Meta-Learning", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by NeurIPS 2024", "summary": "Zero- and few-shot visual anomaly segmentation relies on powerful\nvision-language models that detect unseen anomalies using manually designed\ntextual prompts. However, visual representations are inherently independent of\nlanguage. In this paper, we explore the potential of a pure visual foundation\nmodel as an alternative to widely used vision-language models for universal\nvisual anomaly segmentation. We present a novel paradigm that unifies anomaly\nsegmentation into change segmentation. This paradigm enables us to leverage\nlarge-scale synthetic image pairs, featuring object-level and local region\nchanges, derived from existing image datasets, which are independent of target\nanomaly datasets. We propose a one-prompt Meta-learning framework for Universal\nAnomaly Segmentation (MetaUAS) that is trained on this synthetic dataset and\nthen generalizes well to segment any novel or unseen visual anomalies in the\nreal world. To handle geometrical variations between prompt and query images,\nwe propose a soft feature alignment module that bridges paired-image change\nperception and single-image semantic segmentation. This is the first work to\nachieve universal anomaly segmentation using a pure vision model without\nrelying on special anomaly detection datasets and pre-trained visual-language\nmodels. Our method effectively and efficiently segments any anomalies with only\none normal image prompt and enjoys training-free without guidance from\nlanguage. Our MetaUAS significantly outperforms previous zero-shot, few-shot,\nand even full-shot anomaly segmentation methods. The code and pre-trained\nmodels are available at https://github.com/gaobb/MetaUAS."}
{"id": "2505.09026", "pdf": "https://arxiv.org/pdf/2505.09026", "abs": "https://arxiv.org/abs/2505.09026", "authors": ["Domniki Ladopoulou", "Dat Minh Hong", "Petros Dellaportas"], "title": "Probabilistic Wind Power Forecasting via Non-Stationary Gaussian Processes", "categories": ["stat.AP", "cs.LG", "stat.ML"], "comment": "11 pages, 3 figures, 2 tables", "summary": "Accurate probabilistic forecasting of wind power is essential for maintaining\ngrid stability and enabling efficient integration of renewable energy sources.\nGaussian Process (GP) models offer a principled framework for quantifying\nuncertainty; however, conventional approaches rely on stationary kernels, which\nare inadequate for modeling the inherently non-stationary nature of wind speed\nand power output. We propose a non-stationary GP framework that incorporates\nthe generalized spectral mixture (GSM) kernel, enabling the model to capture\ntime-varying patterns and heteroscedastic behaviors in wind speed and wind\npower data. We evaluate the performance of the proposed model on real-world\nSCADA data across short\\mbox{-,} medium-, and long-term forecasting horizons.\nCompared to standard radial basis function and spectral mixture kernels, the\nGSM-based model outperforms, particularly in short-term forecasts. These\nresults highlight the necessity of modeling non-stationarity in wind power\nforecasting and demonstrate the practical value of non-stationary GP models in\noperational settings."}
{"id": "2505.08949", "pdf": "https://arxiv.org/pdf/2505.08949", "abs": "https://arxiv.org/abs/2505.08949", "authors": ["Kateryna Zorina", "David Kovar", "Mederic Fourmy", "Florent Lamiraux", "Nicolas Mansard", "Justin Carpentier", "Josef Sivic", "Vladimir Petrik"], "title": "Multi-step manipulation task and motion planning guided by video demonstration", "categories": ["cs.RO", "cs.CV", "cs.SY", "eess.SY"], "comment": null, "summary": "This work aims to leverage instructional video to solve complex multi-step\ntask-and-motion planning tasks in robotics. Towards this goal, we propose an\nextension of the well-established Rapidly-Exploring Random Tree (RRT) planner,\nwhich simultaneously grows multiple trees around grasp and release states\nextracted from the guiding video. Our key novelty lies in combining contact\nstates and 3D object poses extracted from the guiding video with a traditional\nplanning algorithm that allows us to solve tasks with sequential dependencies,\nfor example, if an object needs to be placed at a specific location to be\ngrasped later. We also investigate the generalization capabilities of our\napproach to go beyond the scene depicted in the instructional video. To\ndemonstrate the benefits of the proposed video-guided planning approach, we\ndesign a new benchmark with three challenging tasks: (I) 3D re-arrangement of\nmultiple objects between a table and a shelf, (ii) multi-step transfer of an\nobject through a tunnel, and (iii) transferring objects using a tray similar to\na waiter transfers dishes. We demonstrate the effectiveness of our planning\nalgorithm on several robots, including the Franka Emika Panda and the KUKA KMR\niiwa. For a seamless transfer of the obtained plans to the real robot, we\ndevelop a trajectory refinement approach formulated as an optimal control\nproblem (OCP)."}
{"id": "2505.09295", "pdf": "https://arxiv.org/pdf/2505.09295", "abs": "https://arxiv.org/abs/2505.09295", "authors": ["Qiming Wu", "Siqi Li", "Doudou Zhou", "Nan Liu"], "title": "Toward Fair Federated Learning under Demographic Disparities and Data Imbalance", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "Ensuring fairness is critical when applying artificial intelligence to\nhigh-stakes domains such as healthcare, where predictive models trained on\nimbalanced and demographically skewed data risk exacerbating existing\ndisparities. Federated learning (FL) enables privacy-preserving collaboration\nacross institutions, but remains vulnerable to both algorithmic bias and\nsubgroup imbalance - particularly when multiple sensitive attributes intersect.\nWe propose FedIDA (Fed erated Learning for Imbalance and D isparity A\nwareness), a framework-agnostic method that combines fairness-aware\nregularization with group-conditional oversampling. FedIDA supports multiple\nsensitive attributes and heterogeneous data distributions without altering the\nconvergence behavior of the underlying FL algorithm. We provide theoretical\nanalysis establishing fairness improvement bounds using Lipschitz continuity\nand concentration inequalities, and show that FedIDA reduces the variance of\nfairness metrics across test sets. Empirical results on both benchmark and\nreal-world clinical datasets confirm that FedIDA consistently improves fairness\nwhile maintaining competitive predictive performance, demonstrating its\neffectiveness for equitable and privacy-preserving modeling in healthcare. The\nsource code is available on GitHub."}
{"id": "2505.09029", "pdf": "https://arxiv.org/pdf/2505.09029", "abs": "https://arxiv.org/abs/2505.09029", "authors": ["Hazim Alzorgan", "Abolfazl Razi"], "title": "Monte Carlo Beam Search for Actor-Critic Reinforcement Learning in Continuous Control", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Actor-critic methods, like Twin Delayed Deep Deterministic Policy Gradient\n(TD3), depend on basic noise-based exploration, which can result in less than\noptimal policy convergence. In this study, we introduce Monte Carlo Beam Search\n(MCBS), a new hybrid method that combines beam search and Monte Carlo rollouts\nwith TD3 to improve exploration and action selection. MCBS produces several\ncandidate actions around the policy's output and assesses them through\nshort-horizon rollouts, enabling the agent to make better-informed choices. We\ntest MCBS across various continuous-control benchmarks, including\nHalfCheetah-v4, Walker2d-v5, and Swimmer-v5, showing enhanced sample efficiency\nand performance compared to standard TD3 and other baseline methods like SAC,\nPPO, and A2C. Our findings emphasize MCBS's capability to enhance policy\nlearning through structured look-ahead search while ensuring computational\nefficiency. Additionally, we offer a detailed analysis of crucial\nhyperparameters, such as beam width and rollout depth, and explore adaptive\nstrategies to optimize MCBS for complex control tasks. Our method shows a\nhigher convergence rate across different environments compared to TD3, SAC,\nPPO, and A2C. For instance, we achieved 90% of the maximum achievable reward\nwithin around 200 thousand timesteps compared to 400 thousand timesteps for the\nsecond-best method."}
{"id": "2505.08990", "pdf": "https://arxiv.org/pdf/2505.08990", "abs": "https://arxiv.org/abs/2505.08990", "authors": ["Andrew C. Freeman"], "title": "Toward Accessible and Safe Live Streaming Using Distributed Content Filtering with MoQ", "categories": ["cs.MM", "cs.CV", "cs.DC", "cs.NI"], "comment": "Accepted to the ICME 2025 LIVES workshop", "summary": "Live video streaming is increasingly popular on social media platforms. With\nthe growth of live streaming comes an increased need for robust content\nmoderation to remove dangerous, illegal, or otherwise objectionable content.\nWhereas video on demand distribution enables offline content analysis, live\nstreaming imposes restrictions on latency for both analysis and distribution.\nIn this paper, we present extensions to the in-progress Media Over QUIC\nTransport protocol that enable real-time content moderation in one-to-many\nvideo live streams. Importantly, our solution removes only the video segments\nthat contain objectionable content, allowing playback resumption as soon as the\nstream conforms to content policies again. Content analysis tasks may be\ntransparently distributed to arbitrary client devices. We implement and\nevaluate our system in the context of light strobe removal for photosensitive\nviewers, finding that streaming clients experience an increased latency of only\none group-of-pictures duration."}
{"id": "2505.09324", "pdf": "https://arxiv.org/pdf/2505.09324", "abs": "https://arxiv.org/abs/2505.09324", "authors": ["Lakshya Gupta", "Imran N. Junejo"], "title": "Neural Video Compression using 2D Gaussian Splatting", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "comment": "9 pages, 8 figures", "summary": "The computer vision and image processing research community has been involved\nin standardizing video data communications for the past many decades, leading\nto standards such as AVC, HEVC, VVC, AV1, AV2, etc. However, recent\ngroundbreaking works have focused on employing deep learning-based techniques\nto replace the traditional video codec pipeline to a greater affect. Neural\nvideo codecs (NVC) create an end-to-end ML-based solution that does not rely on\nany handcrafted features (motion or edge-based) and have the ability to learn\ncontent-aware compression strategies, offering better adaptability and higher\ncompression efficiency than traditional methods. This holds a great potential\nnot only for hardware design, but also for various video streaming platforms\nand applications, especially video conferencing applications such as MS-Teams\nor Zoom that have found extensive usage in classrooms and workplaces. However,\ntheir high computational demands currently limit their use in real-time\napplications like video conferencing. To address this, we propose a\nregion-of-interest (ROI) based neural video compression model that leverages 2D\nGaussian Splatting. Unlike traditional codecs, 2D Gaussian Splatting is capable\nof real-time decoding and can be optimized using fewer data points, requiring\nonly thousands of Gaussians for decent quality outputs as opposed to millions\nin 3D scenes. In this work, we designed a video pipeline that speeds up the\nencoding time of the previous Gaussian splatting-based image codec by 88% by\nusing a content-aware initialization strategy paired with a novel Gaussian\ninter-frame redundancy-reduction mechanism, enabling Gaussian splatting to be\nused for a video-codec solution, the first of its kind solution in this neural\nvideo codec space."}
{"id": "2505.09040", "pdf": "https://arxiv.org/pdf/2505.09040", "abs": "https://arxiv.org/abs/2505.09040", "authors": ["Owen Kwon", "Abraham George", "Alison Bartsch", "Amir Barati Farimani"], "title": "RT-cache: Efficient Robot Trajectory Retrieval System", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "9 pages, 5 figures. Submitted to an IEEE robotics conference", "summary": "This paper introduces RT-cache, a novel trajectorymemory pipeline that\naccelerates real-world robot inference by leveraging big-data retrieval and\nlearning from experience. While modern Vision-Language-Action (VLA) models can\nhandle diverse robotic tasks, they often incur high per-step inference costs,\nresulting in significant latency, sometimes minutes per task. In contrast,\nRT-cache stores a large-scale Memory of previously successful robot\ntrajectories and retrieves relevant multistep motion snippets, drastically\nreducing inference overhead. By integrating a Memory Builder with a Trajectory\nRetrieval, we develop an efficient retrieval process that remains tractable\neven for extremely large datasets. RT-cache flexibly accumulates real-world\nexperiences and replays them whenever the current scene matches past states,\nadapting quickly to new or unseen environments with only a few additional\nsamples. Experiments on the Open-X Embodiment Dataset and other real-world data\ndemonstrate that RT-cache completes tasks both faster and more successfully\nthan a baseline lacking retrieval, suggesting a practical, data-driven solution\nfor real-time manipulation."}
{"id": "2505.08998", "pdf": "https://arxiv.org/pdf/2505.08998", "abs": "https://arxiv.org/abs/2505.08998", "authors": ["Liwen Wu", "Sai Bi", "Zexiang Xu", "Hao Tan", "Kai Zhang", "Fujun Luan", "Haolin Lu", "Ravi Ramamoorthi"], "title": "Neural BRDF Importance Sampling by Reparameterization", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Neural bidirectional reflectance distribution functions (BRDFs) have emerged\nas popular material representations for enhancing realism in physically-based\nrendering. Yet their importance sampling remains a significant challenge. In\nthis paper, we introduce a reparameterization-based formulation of neural BRDF\nimportance sampling that seamlessly integrates into the standard rendering\npipeline with precise generation of BRDF samples. The reparameterization-based\nformulation transfers the distribution learning task to a problem of\nidentifying BRDF integral substitutions. In contrast to previous methods that\nrely on invertible networks and multi-step inference to reconstruct BRDF\ndistributions, our model removes these constraints, which offers greater\nflexibility and efficiency. Our variance and performance analysis demonstrates\nthat our reparameterization method achieves the best variance reduction in\nneural BRDF renderings while maintaining high inference speeds compared to\nexisting baselines."}
{"id": "2505.09329", "pdf": "https://arxiv.org/pdf/2505.09329", "abs": "https://arxiv.org/abs/2505.09329", "authors": ["Jiarun Liu", "Hong-Yu Zhou", "Weijian Huang", "Hao Yang", "Dongning Song", "Tao Tan", "Yong Liang", "Shanshan Wang"], "title": "BioVFM-21M: Benchmarking and Scaling Self-Supervised Vision Foundation Models for Biomedical Image Analysis", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 4 figures", "summary": "Scaling up model and data size have demonstrated impressive performance\nimprovement over a wide range of tasks. Despite extensive studies on scaling\nbehaviors for general-purpose tasks, medical images exhibit substantial\ndifferences from natural data. It remains unclear the key factors in developing\nmedical vision foundation models at scale due to the absence of an extensive\nunderstanding of scaling behavior in the medical domain. In this paper, we\nexplored the scaling behavior across model sizes, training algorithms, data\nsizes, and imaging modalities in developing scalable medical vision foundation\nmodels by self-supervised learning. To support scalable pretraining, we\nintroduce BioVFM-21M, a large-scale biomedical image dataset encompassing a\nwide range of biomedical image modalities and anatomies. We observed that\nscaling up does provide benefits but varies across tasks. Additional analysis\nreveals several factors correlated with scaling benefits. Finally, we propose\nBioVFM, a large-scale medical vision foundation model pretrained on 21 million\nbiomedical images, which outperforms the previous state-of-the-art foundation\nmodels across 12 medical benchmarks. Our results highlight that while scaling\nup is beneficial for pursuing better performance, task characteristics, data\ndiversity, pretraining methods, and computational efficiency remain critical\nconsiderations for developing scalable medical foundation models."}
{"id": "2505.09062", "pdf": "https://arxiv.org/pdf/2505.09062", "abs": "https://arxiv.org/abs/2505.09062", "authors": ["Junda Zhao", "Yuliang Song", "Eldan Cohen"], "title": "Variational Prefix Tuning for Diverse and Accurate Code Summarization Using Pre-trained Language Models", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.7"], "comment": "Accepted by the Journal of Systems and Software", "summary": "Recent advancements in source code summarization have leveraged\ntransformer-based pre-trained models, including Large Language Models of Code\n(LLMCs), to automate and improve the generation of code summaries. However,\nexisting methods often focus on generating a single high-quality summary for a\ngiven source code, neglecting scenarios where the generated summary might be\ninadequate and alternative options are needed. In this paper, we introduce\nVariational Prefix Tuning (VPT), a novel approach that enhances pre-trained\nmodels' ability to generate diverse yet accurate sets of summaries, allowing\nthe user to choose the most suitable one for the given source code. Our method\nintegrates a Conditional Variational Autoencoder (CVAE) framework as a modular\ncomponent into pre-trained models, enabling us to model the distribution of\nobserved target summaries and sample continuous embeddings to be used as\nprefixes to steer the generation of diverse outputs during decoding.\nImportantly, we construct our method in a parameter-efficient manner,\neliminating the need for expensive model retraining, especially when using\nLLMCs. Furthermore, we employ a bi-criteria reranking method to select a subset\nof generated summaries, optimizing both the diversity and the accuracy of the\noptions presented to users. We present extensive experimental evaluations using\nwidely used datasets and current state-of-the-art pre-trained code\nsummarization models to demonstrate the effectiveness of our approach and its\nadaptability across models."}
{"id": "2505.09040", "pdf": "https://arxiv.org/pdf/2505.09040", "abs": "https://arxiv.org/abs/2505.09040", "authors": ["Owen Kwon", "Abraham George", "Alison Bartsch", "Amir Barati Farimani"], "title": "RT-cache: Efficient Robot Trajectory Retrieval System", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "9 pages, 5 figures. Submitted to an IEEE robotics conference", "summary": "This paper introduces RT-cache, a novel trajectorymemory pipeline that\naccelerates real-world robot inference by leveraging big-data retrieval and\nlearning from experience. While modern Vision-Language-Action (VLA) models can\nhandle diverse robotic tasks, they often incur high per-step inference costs,\nresulting in significant latency, sometimes minutes per task. In contrast,\nRT-cache stores a large-scale Memory of previously successful robot\ntrajectories and retrieves relevant multistep motion snippets, drastically\nreducing inference overhead. By integrating a Memory Builder with a Trajectory\nRetrieval, we develop an efficient retrieval process that remains tractable\neven for extremely large datasets. RT-cache flexibly accumulates real-world\nexperiences and replays them whenever the current scene matches past states,\nadapting quickly to new or unseen environments with only a few additional\nsamples. Experiments on the Open-X Embodiment Dataset and other real-world data\ndemonstrate that RT-cache completes tasks both faster and more successfully\nthan a baseline lacking retrieval, suggesting a practical, data-driven solution\nfor real-time manipulation."}
{"id": "2505.09342", "pdf": "https://arxiv.org/pdf/2505.09342", "abs": "https://arxiv.org/abs/2505.09342", "authors": ["Mostafa Jafari", "Alireza Shameli-Sendi"], "title": "Evaluating the Robustness of Adversarial Defenses in Malware Detection Systems", "categories": ["cs.CR", "cs.AI", "cs.LG", "68", "I.2.1"], "comment": "Submitted to IEEE Transactions on Information Forensics and Security\n  (T-IFS), 13 pages, 4 figures", "summary": "Machine learning is a key tool for Android malware detection, effectively\nidentifying malicious patterns in apps. However, ML-based detectors are\nvulnerable to evasion attacks, where small, crafted changes bypass detection.\nDespite progress in adversarial defenses, the lack of comprehensive evaluation\nframeworks in binary-constrained domains limits understanding of their\nrobustness. We introduce two key contributions. First, Prioritized Binary\nRounding, a technique to convert continuous perturbations into binary feature\nspaces while preserving high attack success and low perturbation size. Second,\nthe sigma-binary attack, a novel adversarial method for binary domains,\ndesigned to achieve attack goals with minimal feature changes. Experiments on\nthe Malscan dataset show that sigma-binary outperforms existing attacks and\nexposes key vulnerabilities in state-of-the-art defenses. Defenses equipped\nwith adversary detectors, such as KDE, DLA, DNN+, and ICNN, exhibit significant\nbrittleness, with attack success rates exceeding 90% using fewer than 10\nfeature modifications and reaching 100% with just 20. Adversarially trained\ndefenses, including AT-rFGSM-k, AT-MaxMA, improves robustness under small\nbudgets but remains vulnerable to unrestricted perturbations, with attack\nsuccess rates of 99.45% and 96.62%, respectively. Although PAD-SMA demonstrates\nstrong robustness against state-of-the-art gradient-based adversarial attacks\nby maintaining an attack success rate below 16.55%, the sigma-binary attack\nsignificantly outperforms these methods, achieving a 94.56% success rate under\nunrestricted perturbations. These findings highlight the critical need for\nprecise method like sigma-binary to expose hidden vulnerabilities in existing\ndefenses and support the development of more resilient malware detection\nsystems."}
{"id": "2505.09075", "pdf": "https://arxiv.org/pdf/2505.09075", "abs": "https://arxiv.org/abs/2505.09075", "authors": ["Carlos Misael Madrid Padilla", "Oscar Hernan Madrid Padilla", "Sabyasachi Chatterjee"], "title": "Risk Bounds For Distributional Regression", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This work examines risk bounds for nonparametric distributional regression\nestimators. For convex-constrained distributional regression, general upper\nbounds are established for the continuous ranked probability score (CRPS) and\nthe worst-case mean squared error (MSE) across the domain. These theoretical\nresults are applied to isotonic and trend filtering distributional regression,\nyielding convergence rates consistent with those for mean estimation.\nFurthermore, a general upper bound is derived for distributional regression\nunder non-convex constraints, with a specific application to neural\nnetwork-based estimators. Comprehensive experiments on both simulated and real\ndata validate the theoretical contributions, demonstrating their practical\neffectiveness."}
{"id": "2505.09091", "pdf": "https://arxiv.org/pdf/2505.09091", "abs": "https://arxiv.org/abs/2505.09091", "authors": ["Zeeshan Ahmad", "Shudi Bao", "Meng Chen"], "title": "DPN-GAN: Inducing Periodic Activations in Generative Adversarial Networks for High-Fidelity Audio Synthesis", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "comment": null, "summary": "In recent years, generative adversarial networks (GANs) have made significant\nprogress in generating audio sequences. However, these models typically rely on\nbandwidth-limited mel-spectrograms, which constrain the resolution of generated\naudio sequences, and lead to mode collapse during conditional generation. To\naddress this issue, we propose Deformable Periodic Network based GAN (DPN-GAN),\na novel GAN architecture that incorporates a kernel-based periodic ReLU\nactivation function to induce periodic bias in audio generation. This\ninnovative approach enhances the model's ability to capture and reproduce\nintricate audio patterns. In particular, our proposed model features a DPN\nmodule for multi-resolution generation utilizing deformable convolution\noperations, allowing for adaptive receptive fields that improve the quality and\nfidelity of the synthetic audio. Additionally, we enhance the discriminator\nnetwork using deformable convolution to better distinguish between real and\ngenerated samples, further refining the audio quality. We trained two versions\nof the model: DPN-GAN small (38.67M parameters) and DPN-GAN large (124M\nparameters). For evaluation, we use five different datasets, covering both\nspeech synthesis and music generation tasks, to demonstrate the efficiency of\nthe DPN-GAN. The experimental results demonstrate that DPN-GAN delivers\nsuperior performance on both out-of-distribution and noisy data, showcasing its\nrobustness and adaptability. Trained across various datasets, DPN-GAN\noutperforms state-of-the-art GAN architectures on standard evaluation metrics,\nand exhibits increased robustness in synthesized audio."}
{"id": "2505.09343", "pdf": "https://arxiv.org/pdf/2505.09343", "abs": "https://arxiv.org/abs/2505.09343", "authors": ["Chenggang Zhao", "Chengqi Deng", "Chong Ruan", "Damai Dai", "Huazuo Gao", "Jiashi Li", "Liyue Zhang", "Panpan Huang", "Shangyan Zhou", "Shirong Ma", "Wenfeng Liang", "Ying He", "Yuqing Wang", "Yuxuan Liu", "Y. X. Wei"], "title": "Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures", "categories": ["cs.DC", "cs.AI", "cs.AR"], "comment": "This is the author's version of the work. It is posted here for your\n  personal use. Not for redistribution. The definitive version will appear as\n  part of the Industry Track in Proceedings of the 52nd Annual International\n  Symposium on Computer Architecture (ISCA '25)", "summary": "The rapid scaling of large language models (LLMs) has unveiled critical\nlimitations in current hardware architectures, including constraints in memory\ncapacity, computational efficiency, and interconnection bandwidth. DeepSeek-V3,\ntrained on 2,048 NVIDIA H800 GPUs, demonstrates how hardware-aware model\nco-design can effectively address these challenges, enabling cost-efficient\ntraining and inference at scale. This paper presents an in-depth analysis of\nthe DeepSeek-V3/R1 model architecture and its AI infrastructure, highlighting\nkey innovations such as Multi-head Latent Attention (MLA) for enhanced memory\nefficiency, Mixture of Experts (MoE) architectures for optimized\ncomputation-communication trade-offs, FP8 mixed-precision training to unlock\nthe full potential of hardware capabilities, and a Multi-Plane Network Topology\nto minimize cluster-level network overhead. Building on the hardware\nbottlenecks encountered during DeepSeek-V3's development, we engage in a\nbroader discussion with academic and industry peers on potential future\nhardware directions, including precise low-precision computation units,\nscale-up and scale-out convergence, and innovations in low-latency\ncommunication fabrics. These insights underscore the critical role of hardware\nand model co-design in meeting the escalating demands of AI workloads, offering\na practical blueprint for innovation in next-generation AI systems."}
{"id": "2505.09087", "pdf": "https://arxiv.org/pdf/2505.09087", "abs": "https://arxiv.org/abs/2505.09087", "authors": ["He Wang", "Yikun Zhang", "Jie Chen", "Jian Zhan", "Yaoqi Zhou"], "title": "A Comparative Review of RNA Language Models", "categories": ["q-bio.BM", "cs.LG"], "comment": null, "summary": "Given usefulness of protein language models (LMs) in structure and functional\ninference, RNA LMs have received increased attentions in the last few years.\nHowever, these RNA models are often not compared against the same standard.\nHere, we divided RNA LMs into three classes (pretrained on multiple RNA types\n(especially noncoding RNAs), specific-purpose RNAs, and LMs that unify RNA with\nDNA or proteins or both) and compared 13 RNA LMs along with 3 DNA and 1 protein\nLMs as controls in zero-shot prediction of RNA secondary structure and\nfunctional classification. Results shows that the models doing well on\nsecondary structure prediction often perform worse in function classification\nor vice versa, suggesting that more balanced unsupervised training is needed."}
{"id": "2505.09109", "pdf": "https://arxiv.org/pdf/2505.09109", "abs": "https://arxiv.org/abs/2505.09109", "authors": ["Yuxing Chen", "Bowen Xiao", "He Wang"], "title": "FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Due to the deformability of garments, generating a large amount of\nhigh-quality data for robotic garment manipulation tasks is highly challenging.\nIn this paper, we present a synthetic garment dataset that can be used for\nrobotic garment folding. We begin by constructing geometric garment templates\nbased on keypoints and applying generative models to generate realistic texture\npatterns. Leveraging these keypoint annotations, we generate folding\ndemonstrations in simulation and train folding policies via closed-loop\nimitation learning. To improve robustness, we propose KG-DAgger, which uses a\nkeypoint-based strategy to generate demonstration data for recovering from\nfailures. KG-DAgger significantly improves the model performance, boosting the\nreal-world success rate by 25\\%. After training with 15K trajectories (about 2M\nimage-action pairs), the model achieves a 75\\% success rate in the real world.\nExperiments in both simulation and real-world settings validate the\neffectiveness of our proposed framework."}
{"id": "2505.09344", "pdf": "https://arxiv.org/pdf/2505.09344", "abs": "https://arxiv.org/abs/2505.09344", "authors": ["Gabriel Cortês", "Nuno Lourenço", "Paolo Romano", "Penousal Machado"], "title": "GreenFactory: Ensembling Zero-Cost Proxies to Estimate Performance of Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Determining the performance of a Deep Neural Network during Neural\nArchitecture Search processes is essential for identifying optimal\narchitectures and hyperparameters. Traditionally, this process requires\ntraining and evaluation of each network, which is time-consuming and\nresource-intensive. Zero-cost proxies estimate performance without training,\nserving as an alternative to traditional training. However, recent proxies\noften lack generalization across diverse scenarios and provide only relative\nrankings rather than predicted accuracies. To address these limitations, we\npropose GreenFactory, an ensemble of zero-cost proxies that leverages a random\nforest regressor to combine multiple predictors' strengths and directly predict\nmodel test accuracy. We evaluate GreenFactory on NATS-Bench, achieving robust\nresults across multiple datasets. Specifically, GreenFactory achieves high\nKendall correlations on NATS-Bench-SSS, indicating substantial agreement\nbetween its predicted scores and actual performance: 0.907 for CIFAR-10, 0.945\nfor CIFAR-100, and 0.920 for ImageNet-16-120. Similarly, on NATS-Bench-TSS, we\nachieve correlations of 0.921 for CIFAR-10, 0.929 for CIFAR-100, and 0.908 for\nImageNet-16-120, showcasing its reliability in both search spaces."}
{"id": "2505.09091", "pdf": "https://arxiv.org/pdf/2505.09091", "abs": "https://arxiv.org/abs/2505.09091", "authors": ["Zeeshan Ahmad", "Shudi Bao", "Meng Chen"], "title": "DPN-GAN: Inducing Periodic Activations in Generative Adversarial Networks for High-Fidelity Audio Synthesis", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "comment": null, "summary": "In recent years, generative adversarial networks (GANs) have made significant\nprogress in generating audio sequences. However, these models typically rely on\nbandwidth-limited mel-spectrograms, which constrain the resolution of generated\naudio sequences, and lead to mode collapse during conditional generation. To\naddress this issue, we propose Deformable Periodic Network based GAN (DPN-GAN),\na novel GAN architecture that incorporates a kernel-based periodic ReLU\nactivation function to induce periodic bias in audio generation. This\ninnovative approach enhances the model's ability to capture and reproduce\nintricate audio patterns. In particular, our proposed model features a DPN\nmodule for multi-resolution generation utilizing deformable convolution\noperations, allowing for adaptive receptive fields that improve the quality and\nfidelity of the synthetic audio. Additionally, we enhance the discriminator\nnetwork using deformable convolution to better distinguish between real and\ngenerated samples, further refining the audio quality. We trained two versions\nof the model: DPN-GAN small (38.67M parameters) and DPN-GAN large (124M\nparameters). For evaluation, we use five different datasets, covering both\nspeech synthesis and music generation tasks, to demonstrate the efficiency of\nthe DPN-GAN. The experimental results demonstrate that DPN-GAN delivers\nsuperior performance on both out-of-distribution and noisy data, showcasing its\nrobustness and adaptability. Trained across various datasets, DPN-GAN\noutperforms state-of-the-art GAN architectures on standard evaluation metrics,\nand exhibits increased robustness in synthesized audio."}
{"id": "2505.09175", "pdf": "https://arxiv.org/pdf/2505.09175", "abs": "https://arxiv.org/abs/2505.09175", "authors": ["Mohammad Ganjirad", "Mahmoud Reza Delavar", "Hossein Bagheri", "Mohammad Mehdi Azizi"], "title": "Optimizing Urban Critical Green Space Development Using Machine Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "This paper presents a novel framework for prioritizing urban green space\ndevelopment in Tehran using diverse socio-economic, environmental, and\nsensitivity indices. The indices were derived from various sources including\nGoogle Earth Engine, air pollution measurements, municipal reports and the\nWeather Research & Forecasting (WRF) model. The WRF model was used to estimate\nthe air temperature at a 1 km resolution due to insufficient meteorological\nstations, yielding RMSE and MAE values of 0.96{\\deg}C and 0.92{\\deg}C,\nrespectively. After data preparation, several machine learning models were used\nfor binary vegetation cover classification including XGBoost, LightGBM, Random\nForest (RF) and Extra Trees. RF achieved the highest performance, exceeding 94%\nin Overall Accuracy, Recall, and F1-score. Then, the probability of areas\nlacking vegetation cover was assessed using socio-economic, environmental and\nsensitivity indices. This resulted in the RF generating an urban green space\ndevelopment prioritization map. Feature Importance Analysis revealed that the\nmost significant indices were nightly land surface temperature (LST) and\nsensitive population. Finally, the framework performance was validated through\nmicroclimate simulation to assess the critical areas after and before the green\nspace development by green roofs. The simulation demonstrated reducing air\ntemperature by up to 0.67{\\deg}C after utilizing the green roof technology in\ncritical areas. As a result, this framework provides a valuable tool for urban\nplanners to develop green spaces."}
{"id": "2505.09371", "pdf": "https://arxiv.org/pdf/2505.09371", "abs": "https://arxiv.org/abs/2505.09371", "authors": ["Akash Kundu", "Stefano Mangini"], "title": "TensorRL-QAS: Reinforcement learning with tensor networks for scalable quantum architecture search", "categories": ["quant-ph", "cs.AI", "cs.ET", "cs.LG"], "comment": "The code will be available soon! Comments are welcomed!", "summary": "Variational quantum algorithms hold the promise to address meaningful quantum\nproblems already on noisy intermediate-scale quantum hardware, but they face\nthe challenge of designing quantum circuits that both solve the target problem\nand comply with device limitations. Quantum architecture search (QAS) automates\nthis design process, with reinforcement learning (RL) emerging as a promising\napproach. Yet, RL-based QAS methods encounter significant scalability issues,\nas computational and training costs grow rapidly with the number of qubits,\ncircuit depth, and noise, severely impacting performance. To address these\nchallenges, we introduce $\\textit{TensorRL-QAS}$, a scalable framework that\ncombines tensor network (TN) methods with RL for designing quantum circuits. By\nwarm-starting the architecture search with a matrix product state approximation\nof the target solution, TensorRL-QAS effectively narrows the search space to\nphysically meaningful circuits, accelerating convergence to the desired\nsolution. Tested on several quantum chemistry problems of up to 12-qubit,\nTensorRL-QAS achieves up to a 10-fold reduction in CNOT count and circuit depth\ncompared to baseline methods, while maintaining or surpassing chemical\naccuracy. It reduces function evaluations by up to 100-fold, accelerates\ntraining episodes by up to $98\\%$, and achieves up to $50\\%$ success\nprobability for 10-qubit systems-far exceeding the $<1\\%$ rates of baseline\napproaches. Robustness and versatility are demonstrated both in the noiseless\nand noisy scenarios, where we report a simulation of up to 8-qubit. These\nadvancements establish TensorRL-QAS as a promising candidate for a scalable and\nefficient quantum circuit discovery protocol on near-term quantum hardware."}
{"id": "2505.09098", "pdf": "https://arxiv.org/pdf/2505.09098", "abs": "https://arxiv.org/abs/2505.09098", "authors": ["Yan Hao Ling", "Zhouhao Yang", "Jonathan Scarlett"], "title": "Statistical Mean Estimation with Coded Relayed Observations", "categories": ["cs.IT", "cs.LG", "math.IT", "math.ST", "stat.TH"], "comment": null, "summary": "We consider a problem of statistical mean estimation in which the samples are\nnot observed directly, but are instead observed by a relay (``teacher'') that\ntransmits information through a memoryless channel to the decoder\n(``student''), who then produces the final estimate. We consider the minimax\nestimation error in the large deviations regime, and establish achievable error\nexponents that are tight in broad regimes of the estimation accuracy and\nchannel quality. In contrast, two natural baseline methods are shown to yield\nstrictly suboptimal error exponents. We initially focus on Bernoulli sources\nand binary symmetric channels, and then generalize to sub-Gaussian and\nheavy-tailed settings along with arbitrary discrete memoryless channels."}
{"id": "2505.09193", "pdf": "https://arxiv.org/pdf/2505.09193", "abs": "https://arxiv.org/abs/2505.09193", "authors": ["Wei Jiang", "Junru Li", "Kai Zhang", "Li Zhang"], "title": "BiECVC: Gated Diversification of Bidirectional Contexts for Learned Video Compression", "categories": ["eess.IV", "cs.CV"], "comment": "The first learned video codec that surpasses VTM 13.2 RA across all\n  standard test datasets. Code will be available at\n  https://github.com/JiangWeibeta/ECVC", "summary": "Recent forward prediction-based learned video compression (LVC) methods have\nachieved impressive results, even surpassing VVC reference software VTM under\nthe Low Delay B (LDB) configuration. In contrast, learned bidirectional video\ncompression (BVC) remains underexplored and still lags behind its forward-only\ncounterparts. This performance gap is mainly due to the limited ability to\nextract diverse and accurate contexts: most existing BVCs primarily exploit\ntemporal motion while neglecting non-local correlations across frames.\nMoreover, they lack the adaptability to dynamically suppress harmful contexts\narising from fast motion or occlusion. To tackle these challenges, we propose\nBiECVC, a BVC framework that incorporates diversified local and non-local\ncontext modeling along with adaptive context gating. For local context\nenhancement, BiECVC reuses high-quality features from lower layers and aligns\nthem using decoded motion vectors without introducing extra motion overhead. To\nmodel non-local dependencies efficiently, we adopt a linear attention mechanism\nthat balances performance and complexity. To further mitigate the impact of\ninaccurate context prediction, we introduce Bidirectional Context Gating,\ninspired by data-dependent decay in recent autoregressive language models, to\ndynamically filter contextual information based on conditional coding results.\nExtensive experiments demonstrate that BiECVC achieves state-of-the-art\nperformance, reducing the bit-rate by 13.4% and 15.7% compared to VTM 13.2\nunder the Random Access (RA) configuration with intra periods of 32 and 64,\nrespectively. To our knowledge, BiECVC is the first learned video codec to\nsurpass VTM 13.2 RA across all standard test datasets. Code will be available\nat https://github.com/JiangWeibeta/ECVC."}
{"id": "2505.09380", "pdf": "https://arxiv.org/pdf/2505.09380", "abs": "https://arxiv.org/abs/2505.09380", "authors": ["Qinghui Liu", "Jon Nesvold", "Hanna Raaum", "Elakkyen Murugesu", "Martin Røvang", "Bradley J Maclntosh", "Atle Bjørnerud", "Karoline Skogen"], "title": "Examining Deployment and Refinement of the VIOLA-AI Intracranial Hemorrhage Model Using an Interactive NeoMedSys Platform", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "19 pages, 11 figures, on submission to BMC Methods", "summary": "Background: There are many challenges and opportunities in the clinical\ndeployment of AI tools in radiology. The current study describes a radiology\nsoftware platform called NeoMedSys that can enable efficient deployment and\nrefinements of AI models. We evaluated the feasibility and effectiveness of\nrunning NeoMedSys for three months in real-world clinical settings and focused\non improvement performance of an in-house developed AI model (VIOLA-AI)\ndesigned for intracranial hemorrhage (ICH) detection.\n  Methods: NeoMedSys integrates tools for deploying, testing, and optimizing AI\nmodels with a web-based medical image viewer, annotation system, and\nhospital-wide radiology information systems. A pragmatic investigation was\ndeployed using clinical cases of patients presenting to the largest Emergency\nDepartment in Norway (site-1) with suspected traumatic brain injury (TBI) or\npatients with suspected stroke (site-2). We assessed ICH classification\nperformance as VIOLA-AI encountered new data and underwent pre-planned model\nretraining. Performance metrics included sensitivity, specificity, accuracy,\nand the area under the receiver operating characteristic curve (AUC).\n  Results: NeoMedSys facilitated iterative improvements in the AI model,\nsignificantly enhancing its diagnostic accuracy. Automated bleed detection and\nsegmentation were reviewed in near real-time to facilitate re-training\nVIOLA-AI. The iterative refinement process yielded a marked improvement in\nclassification sensitivity, rising to 90.3% (from 79.2%), and specificity that\nreached 89.3% (from 80.7%). The bleed detection ROC analysis for the entire\nsample demonstrated a high area-under-the-curve (AUC) of 0.949 (from 0.873).\nModel refinement stages were associated with notable gains, highlighting the\nvalue of real-time radiologist feedback."}
{"id": "2505.09099", "pdf": "https://arxiv.org/pdf/2505.09099", "abs": "https://arxiv.org/abs/2505.09099", "authors": ["Shirui Lyu", "Vittorio Caggiano", "Matteo Leonetti", "Dario Farina", "Letizia Gionfrida"], "title": "Imitation Learning for Adaptive Control of a Virtual Soft Exoglove", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "The use of wearable robots has been widely adopted in rehabilitation training\nfor patients with hand motor impairments. However, the uniqueness of patients'\nmuscle loss is often overlooked. Leveraging reinforcement learning and a\nbiologically accurate musculoskeletal model in simulation, we propose a\ncustomized wearable robotic controller that is able to address specific muscle\ndeficits and to provide compensation for hand-object manipulation tasks. Video\ndata of a same subject performing human grasping tasks is used to train a\nmanipulation model through learning from demonstration. This manipulation model\nis subsequently fine-tuned to perform object-specific interaction tasks. The\nmuscle forces in the musculoskeletal manipulation model are then weakened to\nsimulate neurological motor impairments, which are later compensated by the\nactuation of a virtual wearable robotics glove. Results shows that integrating\nthe virtual wearable robotic glove provides shared assistance to support the\nhand manipulator with weakened muscle forces. The learned exoglove controller\nachieved an average of 90.5\\% of the original manipulation proficiency."}
{"id": "2505.09262", "pdf": "https://arxiv.org/pdf/2505.09262", "abs": "https://arxiv.org/abs/2505.09262", "authors": ["Hongxin Xiang", "Ke Li", "Mingquan Liu", "Zhixiang Cheng", "Bin Yao", "Wenjie Du", "Jun Xia", "Li Zeng", "Xin Jin", "Xiangxiang Zeng"], "title": "EDBench: Large-Scale Electron Density Data for Molecular Modeling", "categories": ["physics.chem-ph", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Existing molecular machine learning force fields (MLFFs) generally focus on\nthe learning of atoms, molecules, and simple quantum chemical properties (such\nas energy and force), but ignore the importance of electron density (ED)\n$\\rho(r)$ in accurately understanding molecular force fields (MFFs). ED\ndescribes the probability of finding electrons at specific locations around\natoms or molecules, which uniquely determines all ground state properties (such\nas energy, molecular structure, etc.) of interactive multi-particle systems\naccording to the Hohenberg-Kohn theorem. However, the calculation of ED relies\non the time-consuming first-principles density functional theory (DFT) which\nleads to the lack of large-scale ED data and limits its application in MLFFs.\nIn this paper, we introduce EDBench, a large-scale, high-quality dataset of ED\ndesigned to advance learning-based research at the electronic scale. Built upon\nthe PCQM4Mv2, EDBench provides accurate ED data, covering 3.3 million\nmolecules. To comprehensively evaluate the ability of models to understand and\nutilize electronic information, we design a suite of ED-centric benchmark tasks\nspanning prediction, retrieval, and generation. Our evaluation on several\nstate-of-the-art methods demonstrates that learning from EDBench is not only\nfeasible but also achieves high accuracy. Moreover, we show that learning-based\nmethod can efficiently calculate ED with comparable precision while\nsignificantly reducing the computational cost relative to traditional DFT\ncalculations. All data and benchmarks from EDBench will be freely available,\nlaying a robust foundation for ED-driven drug discovery and materials science."}
{"id": "2505.09382", "pdf": "https://arxiv.org/pdf/2505.09382", "abs": "https://arxiv.org/abs/2505.09382", "authors": ["Zhengyan Sheng", "Jinghao He", "Liping Chen", "Kong Aik Lee", "Zhen-Hua Ling"], "title": "The Voice Timbre Attribute Detection 2025 Challenge Evaluation Plan", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Voice timbre refers to the unique quality or character of a person's voice\nthat distinguishes it from others as perceived by human hearing. The Voice\nTimbre Attribute Detection (VtaD) 2025 challenge focuses on explaining the\nvoice timbre attribute in a comparative manner. In this challenge, the human\nimpression of voice timbre is verbalized with a set of sensory descriptors,\nincluding bright, coarse, soft, magnetic, and so on. The timbre is explained\nfrom the comparison between two voices in their intensity within a specific\ndescriptor dimension. The VtaD 2025 challenge starts in May and culminates in a\nspecial proposal at the NCMMSC2025 conference in October 2025 in Zhenjiang,\nChina."}
{"id": "2505.09110", "pdf": "https://arxiv.org/pdf/2505.09110", "abs": "https://arxiv.org/abs/2505.09110", "authors": ["Zhihao Dou", "Jiaqi Wang", "Wei Sun", "Zhuqing Liu", "Minghong Fang"], "title": "Toward Malicious Clients Detection in Federated Learning", "categories": ["cs.CR", "cs.DC", "cs.LG"], "comment": "To appear in ACM ASIACCS 2025", "summary": "Federated learning (FL) enables multiple clients to collaboratively train a\nglobal machine learning model without sharing their raw data. However, the\ndecentralized nature of FL introduces vulnerabilities, particularly to\npoisoning attacks, where malicious clients manipulate their local models to\ndisrupt the training process. While Byzantine-robust aggregation rules have\nbeen developed to mitigate such attacks, they remain inadequate against more\nadvanced threats. In response, recent advancements have focused on FL detection\ntechniques to identify potentially malicious participants. Unfortunately, these\nmethods often misclassify numerous benign clients as threats or rely on\nunrealistic assumptions about the server's capabilities. In this paper, we\npropose a novel algorithm, SafeFL, specifically designed to accurately identify\nmalicious clients in FL. The SafeFL approach involves the server collecting a\nseries of global models to generate a synthetic dataset, which is then used to\ndistinguish between malicious and benign models based on their behavior.\nExtensive testing demonstrates that SafeFL outperforms existing methods,\noffering superior efficiency and accuracy in detecting malicious clients."}
{"id": "2505.09315", "pdf": "https://arxiv.org/pdf/2505.09315", "abs": "https://arxiv.org/abs/2505.09315", "authors": ["Xuefeng Jiang", "Yuan Ma", "Pengxiang Li", "Leimeng Xu", "Xin Wen", "Kun Zhan", "Zhongpu Xia", "Peng Jia", "XianPeng Lang", "Sheng Sun"], "title": "TransDiffuser: End-to-end Trajectory Generation with Decorrelated Multi-modal Representation for Autonomous Driving", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "Under review", "summary": "In recent years, diffusion model has shown its potential across diverse\ndomains from vision generation to language modeling. Transferring its\ncapabilities to modern autonomous driving systems has also emerged as a\npromising direction.In this work, we propose TransDiffuser, an encoder-decoder\nbased generative trajectory planning model for end-to-end autonomous driving.\nThe encoded scene information serves as the multi-modal conditional input of\nthe denoising decoder. To tackle the mode collapse dilemma in generating\nhigh-quality diverse trajectories, we introduce a simple yet effective\nmulti-modal representation decorrelation optimization mechanism during the\ntraining process.TransDiffuser achieves PDMS of 94.85 on the NAVSIM benchmark,\nsurpassing previous state-of-the-art methods without any anchor-based prior\ntrajectories."}
{"id": "2505.09385", "pdf": "https://arxiv.org/pdf/2505.09385", "abs": "https://arxiv.org/abs/2505.09385", "authors": ["Xiaoyang Yu", "Xiaoming Wu", "Xin Wang", "Dongrun Li", "Ming Yang", "Peng Cheng"], "title": "FedSaaS: Class-Consistency Federated Semantic Segmentation via Global Prototype Supervision and Local Adversarial Harmonization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Federated semantic segmentation enables pixel-level classification in images\nthrough collaborative learning while maintaining data privacy. However,\nexisting research commonly overlooks the fine-grained class relationships\nwithin the semantic space when addressing heterogeneous problems, particularly\ndomain shift. This oversight results in ambiguities between class\nrepresentation. To overcome this challenge, we propose a novel federated\nsegmentation framework that strikes class consistency, termed FedSaaS.\nSpecifically, we introduce class exemplars as a criterion for both local- and\nglobal-level class representations. On the server side, the uploaded class\nexemplars are leveraged to model class prototypes, which supervise global\nbranch of clients, ensuring alignment with global-level representation. On the\nclient side, we incorporate an adversarial mechanism to harmonize contributions\nof global and local branches, leading to consistent output. Moreover,\nmultilevel contrastive losses are employed on both sides to enforce consistency\nbetween two-level representations in the same semantic space. Extensive\nexperiments on several driving scene segmentation datasets demonstrate that our\nframework outperforms state-of-the-art methods, significantly improving average\nsegmentation accuracy and effectively addressing the class-consistency\nrepresentation problem."}
{"id": "2505.09114", "pdf": "https://arxiv.org/pdf/2505.09114", "abs": "https://arxiv.org/abs/2505.09114", "authors": ["Minh Hoang Nguyen", "Linh Le Pham Van", "Thommen George Karimpanal", "Sunil Gupta", "Hung Le"], "title": "Beyond the Known: Decision Making with Counterfactual Reasoning Decision Transformer", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Decision Transformers (DT) play a crucial role in modern reinforcement\nlearning, leveraging offline datasets to achieve impressive results across\nvarious domains. However, DT requires high-quality, comprehensive data to\nperform optimally. In real-world applications, the lack of training data and\nthe scarcity of optimal behaviours make training on offline datasets\nchallenging, as suboptimal data can hinder performance. To address this, we\npropose the Counterfactual Reasoning Decision Transformer (CRDT), a novel\nframework inspired by counterfactual reasoning. CRDT enhances DT ability to\nreason beyond known data by generating and utilizing counterfactual\nexperiences, enabling improved decision-making in unseen scenarios. Experiments\nacross Atari and D4RL benchmarks, including scenarios with limited data and\naltered dynamics, demonstrate that CRDT outperforms conventional DT approaches.\nAdditionally, reasoning counterfactually allows the DT agent to obtain\nstitching abilities, combining suboptimal trajectories, without architectural\nmodifications. These results highlight the potential of counterfactual\nreasoning to enhance reinforcement learning agents' performance and\ngeneralization capabilities."}
{"id": "2505.09323", "pdf": "https://arxiv.org/pdf/2505.09323", "abs": "https://arxiv.org/abs/2505.09323", "authors": ["Pengli Zhu", "Yingji Fu", "Nanguang Chen", "Anqi Qiu"], "title": "Q-space Guided Collaborative Attention Translation Network for Flexible Diffusion-Weighted Images Synthesis", "categories": ["eess.IV", "cs.CV"], "comment": "MICCAI 2025", "summary": "This study, we propose a novel Q-space Guided Collaborative Attention\nTranslation Networks (Q-CATN) for multi-shell, high-angular resolution DWI\n(MS-HARDI) synthesis from flexible q-space sampling, leveraging the commonly\nacquired structural MRI data. Q-CATN employs a collaborative attention\nmechanism to effectively extract complementary information from multiple\nmodalities and dynamically adjust its internal representations based on\nflexible q-space information, eliminating the need for fixed sampling schemes.\nAdditionally, we introduce a range of task-specific constraints to preserve\nanatomical fidelity in DWI, enabling Q-CATN to accurately learn the intrinsic\nrelationships between directional DWI signal distributions and q-space.\nExtensive experiments on the Human Connectome Project (HCP) dataset demonstrate\nthat Q-CATN outperforms existing methods, including 1D-qDL, 2D-qDL, MESC-SD,\nand QGAN, in estimating parameter maps and fiber tracts both quantitatively and\nqualitatively, while preserving fine-grained details. Notably, its ability to\naccommodate flexible q-space sampling highlights its potential as a promising\ntoolkit for clinical and research applications. Our code is available at\nhttps://github.com/Idea89560041/Q-CATN."}
{"id": "2505.09393", "pdf": "https://arxiv.org/pdf/2505.09393", "abs": "https://arxiv.org/abs/2505.09393", "authors": ["Huakun Liu", "Hiroki Ota", "Xin Wei", "Yutaro Hirao", "Monica Perusquia-Hernandez", "Hideaki Uchiyama", "Kiyoshi Kiyokawa"], "title": "UMotion: Uncertainty-driven Human Motion Estimation from Inertial and Ultra-wideband Units", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "Accepted by CVPR 2025", "summary": "Sparse wearable inertial measurement units (IMUs) have gained popularity for\nestimating 3D human motion. However, challenges such as pose ambiguity, data\ndrift, and limited adaptability to diverse bodies persist. To address these\nissues, we propose UMotion, an uncertainty-driven, online fusing-all state\nestimation framework for 3D human shape and pose estimation, supported by six\nintegrated, body-worn ultra-wideband (UWB) distance sensors with IMUs. UWB\nsensors measure inter-node distances to infer spatial relationships, aiding in\nresolving pose ambiguities and body shape variations when combined with\nanthropometric data. Unfortunately, IMUs are prone to drift, and UWB sensors\nare affected by body occlusions. Consequently, we develop a tightly coupled\nUnscented Kalman Filter (UKF) framework that fuses uncertainties from sensor\ndata and estimated human motion based on individual body shape. The UKF\niteratively refines IMU and UWB measurements by aligning them with uncertain\nhuman motion constraints in real-time, producing optimal estimates for each.\nExperiments on both synthetic and real-world datasets demonstrate the\neffectiveness of UMotion in stabilizing sensor data and the improvement over\nstate of the art in pose accuracy."}
{"id": "2505.09142", "pdf": "https://arxiv.org/pdf/2505.09142", "abs": "https://arxiv.org/abs/2505.09142", "authors": ["Seungbeom Choi", "Jeonghoe Goo", "Eunjoo Jeon", "Mingyu Yang", "Minsung Jang"], "title": "ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "13 pages, 5 figures. Cloud-native LLM scheduling system with\n  latency-aware inference optimization", "summary": "We propose ELIS, a serving system for Large Language Models (LLMs) featuring\nan Iterative Shortest Remaining Time First (ISRTF) scheduler designed to\nefficiently manage inference tasks with the shortest remaining tokens. Current\nLLM serving systems often employ a first-come-first-served scheduling strategy,\nwhich can lead to the \"head-of-line blocking\" problem. To overcome this\nlimitation, it is necessary to predict LLM inference times and apply a shortest\njob first scheduling strategy. However, due to the auto-regressive nature of\nLLMs, predicting the inference latency is challenging. ELIS addresses this\nchallenge by training a response length predictor for LLMs using the BGE model,\nan encoder-based state-of-the-art model. Additionally, we have devised the\nISRTF scheduling strategy, an optimization of shortest remaining time first\ntailored to existing LLM iteration batching. To evaluate our work in an\nindustrial setting, we simulate streams of requests based on our study of\nreal-world user LLM serving trace records. Furthermore, we implemented ELIS as\na cloud-native scheduler system on Kubernetes to evaluate its performance in\nproduction environments. Our experimental results demonstrate that ISRTF\nreduces the average job completion time by up to 19.6%."}
{"id": "2505.09334", "pdf": "https://arxiv.org/pdf/2505.09334", "abs": "https://arxiv.org/abs/2505.09334", "authors": ["Sadman Sakib Alif", "Nasim Anzum Promise", "Fiaz Al Abid", "Aniqua Nusrat Zereen"], "title": "DCSNet: A Lightweight Knowledge Distillation-Based Model with Explainable AI for Lung Cancer Diagnosis from Histopathological Images", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Lung cancer is a leading cause of cancer-related deaths globally, where early\ndetection and accurate diagnosis are critical for improving survival rates.\nWhile deep learning, particularly convolutional neural networks (CNNs), has\nrevolutionized medical image analysis by detecting subtle patterns indicative\nof early-stage lung cancer, its adoption faces challenges. These models are\noften computationally expensive and require significant resources, making them\nunsuitable for resource constrained environments. Additionally, their lack of\ntransparency hinders trust and broader adoption in sensitive fields like\nhealthcare. Knowledge distillation addresses these challenges by transferring\nknowledge from large, complex models (teachers) to smaller, lightweight models\n(students). We propose a knowledge distillation-based approach for lung cancer\ndetection, incorporating explainable AI (XAI) techniques to enhance model\ntransparency. Eight CNNs, including ResNet50, EfficientNetB0, EfficientNetB3,\nand VGG16, are evaluated as teacher models. We developed and trained a\nlightweight student model, Distilled Custom Student Network (DCSNet) using\nResNet50 as the teacher. This approach not only ensures high diagnostic\nperformance in resource-constrained settings but also addresses transparency\nconcerns, facilitating the adoption of AI-driven diagnostic tools in\nhealthcare."}
{"id": "2505.09395", "pdf": "https://arxiv.org/pdf/2505.09395", "abs": "https://arxiv.org/abs/2505.09395", "authors": ["Chen-Yu Liu", "Kuan-Cheng Chen", "Yi-Chien Chen", "Samuel Yen-Chi Chen", "Wei-Hao Huang", "Wei-Jia Huang", "Yen-Jui Chang"], "title": "Quantum-Enhanced Parameter-Efficient Learning for Typhoon Trajectory Forecasting", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Typhoon trajectory forecasting is essential for disaster preparedness but\nremains computationally demanding due to the complexity of atmospheric dynamics\nand the resource requirements of deep learning models. Quantum-Train (QT), a\nhybrid quantum-classical framework that leverages quantum neural networks\n(QNNs) to generate trainable parameters exclusively during training,\neliminating the need for quantum hardware at inference time. Building on QT's\nsuccess across multiple domains, including image classification, reinforcement\nlearning, flood prediction, and large language model (LLM) fine-tuning, we\nintroduce Quantum Parameter Adaptation (QPA) for efficient typhoon forecasting\nmodel learning. Integrated with an Attention-based Multi-ConvGRU model, QPA\nenables parameter-efficient training while maintaining predictive accuracy.\nThis work represents the first application of quantum machine learning (QML) to\nlarge-scale typhoon trajectory prediction, offering a scalable and\nenergy-efficient approach to climate modeling. Our results demonstrate that QPA\nsignificantly reduces the number of trainable parameters while preserving\nperformance, making high-performance forecasting more accessible and\nsustainable through hybrid quantum-classical learning."}
{"id": "2505.09161", "pdf": "https://arxiv.org/pdf/2505.09161", "abs": "https://arxiv.org/abs/2505.09161", "authors": ["Yu Xin", "Peng Liu", "Zhuohang Xie", "Wenhui Mi", "Pengyue Gao", "Hong Jian Zhao", "Jian Lv", "Yanchao Wang", "Yanming Ma"], "title": "Bridging Theory and Experiment in Materials Discovery: Machine-Learning-Assisted Prediction of Synthesizable Structures", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Even though thermodynamic energy-based crystal structure prediction (CSP) has\nrevolutionized materials discovery, the energy-driven CSP approaches often\nstruggle to identify experimentally realizable metastable materials synthesized\nthrough kinetically controlled pathways, creating a critical gap between\ntheoretical predictions and experimental synthesis. Here, we propose a\nsynthesizability-driven CSP framework that integrates symmetry-guided structure\nderivation with a Wyckoff encode-based machine-learning model, allowing for the\nefficient localization of subspaces likely to yield highly synthesizable\nstructures. Within the identified promising subspaces, a structure-based\nsynthesizability evaluation model, fine-tuned using recently synthesized\nstructures to enhance predictive accuracy, is employed in conjunction with ab\ninitio calculations to systematically identify synthesizable candidates. The\nframework successfully reproduces 13 experimentally known XSe (X = Sc, Ti, Mn,\nFe, Ni, Cu, Zn) structures, demonstrating its effectiveness in predicting\nsynthesizable structures. Notably, 92,310 structures are filtered from the\n554,054 candidates predicted by GNoME, exhibiting great potential for promising\nsynthesizability. Additionally, eight thermodynamically favorable Hf-X-O (X =\nTi, V, and Mn) structures have been identified, among which three HfV$_2$O$_7$\ncandidates exhibit high synthesizability, presenting viable candidates for\nexperimental realization and potentially associated with experimentally\nobserved temperature-induced phase transitions. This work establishes a\ndata-driven paradigm for machine-learning-assisted inorganic materials\nsynthesis, highlighting its potential to bridge the gap between computational\npredictions and experimental realization while unlocking new opportunities for\nthe targeted discovery of novel functional materials."}
{"id": "2505.09344", "pdf": "https://arxiv.org/pdf/2505.09344", "abs": "https://arxiv.org/abs/2505.09344", "authors": ["Gabriel Cortês", "Nuno Lourenço", "Paolo Romano", "Penousal Machado"], "title": "GreenFactory: Ensembling Zero-Cost Proxies to Estimate Performance of Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Determining the performance of a Deep Neural Network during Neural\nArchitecture Search processes is essential for identifying optimal\narchitectures and hyperparameters. Traditionally, this process requires\ntraining and evaluation of each network, which is time-consuming and\nresource-intensive. Zero-cost proxies estimate performance without training,\nserving as an alternative to traditional training. However, recent proxies\noften lack generalization across diverse scenarios and provide only relative\nrankings rather than predicted accuracies. To address these limitations, we\npropose GreenFactory, an ensemble of zero-cost proxies that leverages a random\nforest regressor to combine multiple predictors' strengths and directly predict\nmodel test accuracy. We evaluate GreenFactory on NATS-Bench, achieving robust\nresults across multiple datasets. Specifically, GreenFactory achieves high\nKendall correlations on NATS-Bench-SSS, indicating substantial agreement\nbetween its predicted scores and actual performance: 0.907 for CIFAR-10, 0.945\nfor CIFAR-100, and 0.920 for ImageNet-16-120. Similarly, on NATS-Bench-TSS, we\nachieve correlations of 0.921 for CIFAR-10, 0.929 for CIFAR-100, and 0.908 for\nImageNet-16-120, showcasing its reliability in both search spaces."}
{"id": "2505.09407", "pdf": "https://arxiv.org/pdf/2505.09407", "abs": "https://arxiv.org/abs/2505.09407", "authors": ["Subrit Dikshit", "Ritu Tiwari", "Priyank Jain"], "title": "Multilingual Machine Translation with Quantum Encoder Decoder Attention-based Convolutional Variational Circuits", "categories": ["cs.CL", "cs.AI", "cs.ET"], "comment": "12 pages, 12 figures", "summary": "Cloud-based multilingual translation services like Google Translate and\nMicrosoft Translator achieve state-of-the-art translation capabilities. These\nservices inherently use large multilingual language models such as GRU, LSTM,\nBERT, GPT, T5, or similar encoder-decoder architectures with attention\nmechanisms as the backbone. Also, new age natural language systems, for\ninstance ChatGPT and DeepSeek, have established huge potential in multiple\ntasks in natural language processing. At the same time, they also possess\noutstanding multilingual translation capabilities. However, these models use\nthe classical computing realm as a backend. QEDACVC (Quantum Encoder Decoder\nAttention-based Convolutional Variational Circuits) is an alternate solution\nthat explores the quantum computing realm instead of the classical computing\nrealm to study and demonstrate multilingual machine translation. QEDACVC\nintroduces the quantum encoder-decoder architecture that simulates and runs on\nquantum computing hardware via quantum convolution, quantum pooling, quantum\nvariational circuit, and quantum attention as software alterations. QEDACVC\nachieves an Accuracy of 82% when trained on the OPUS dataset for English,\nFrench, German, and Hindi corpora for multilingual translations."}
{"id": "2505.09167", "pdf": "https://arxiv.org/pdf/2505.09167", "abs": "https://arxiv.org/abs/2505.09167", "authors": ["Amit Daniely", "Idan Mehalel", "Elchanan Mossel"], "title": "Online Learning of Neural Networks", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study online learning of feedforward neural networks with the sign\nactivation function that implement functions from the unit ball in\n$\\mathbb{R}^d$ to a finite label set $\\{1, \\ldots, Y\\}$.\n  First, we characterize a margin condition that is sufficient and in some\ncases necessary for online learnability of a neural network: Every neuron in\nthe first hidden layer classifies all instances with some margin $\\gamma$\nbounded away from zero. Quantitatively, we prove that for any net, the optimal\nmistake bound is at most approximately $\\mathtt{TS}(d,\\gamma)$, which is the\n$(d,\\gamma)$-totally-separable-packing number, a more restricted variation of\nthe standard $(d,\\gamma)$-packing number. We complement this result by\nconstructing a net on which any learner makes $\\mathtt{TS}(d,\\gamma)$ many\nmistakes. We also give a quantitative lower bound of approximately\n$\\mathtt{TS}(d,\\gamma) \\geq \\max\\{1/(\\gamma \\sqrt{d})^d, d\\}$ when $\\gamma \\geq\n1/2$, implying that for some nets and input sequences every learner will err\nfor $\\exp(d)$ many times, and that a dimension-free mistake bound is almost\nalways impossible.\n  To remedy this inevitable dependence on $d$, it is natural to seek additional\nnatural restrictions to be placed on the network, so that the dependence on $d$\nis removed. We study two such restrictions. The first is the multi-index model,\nin which the function computed by the net depends only on $k \\ll d$ orthonormal\ndirections. We prove a mistake bound of approximately $(1.5/\\gamma)^{k + 2}$ in\nthis model. The second is the extended margin assumption. In this setting, we\nassume that all neurons (in all layers) in the network classify every ingoing\ninput from previous layer with margin $\\gamma$ bounded away from zero. In this\nmodel, we prove a mistake bound of approximately $(\\log Y)/ \\gamma^{O(L)}$,\nwhere L is the depth of the network."}
{"id": "2505.09356", "pdf": "https://arxiv.org/pdf/2505.09356", "abs": "https://arxiv.org/abs/2505.09356", "authors": ["Srinivas Ravuri", "Yuan Xu", "Martin Ludwig Zehetner", "Ketan Motlag", "Sahin Albayrak"], "title": "APR-Transformer: Initial Pose Estimation for Localization in Complex Environments through Absolute Pose Regression", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages with 6 figures", "summary": "Precise initialization plays a critical role in the performance of\nlocalization algorithms, especially in the context of robotics, autonomous\ndriving, and computer vision. Poor localization accuracy is often a consequence\nof inaccurate initial poses, particularly noticeable in GNSS-denied\nenvironments where GPS signals are primarily relied upon for initialization.\nRecent advances in leveraging deep neural networks for pose regression have led\nto significant improvements in both accuracy and robustness, especially in\nestimating complex spatial relationships and orientations. In this paper, we\nintroduce APR-Transformer, a model architecture inspired by state-of-the-art\nmethods, which predicts absolute pose (3D position and 3D orientation) using\neither image or LiDAR data. We demonstrate that our proposed method achieves\nstate-of-the-art performance on established benchmark datasets such as the\nRadar Oxford Robot-Car and DeepLoc datasets. Furthermore, we extend our\nexperiments to include our custom complex APR-BeIntelli dataset. Additionally,\nwe validate the reliability of our approach in GNSS-denied environments by\ndeploying the model in real-time on an autonomous test vehicle. This showcases\nthe practical feasibility and effectiveness of our approach. The source code is\navailable at:https://github.com/GT-ARC/APR-Transformer."}
{"id": "2505.09435", "pdf": "https://arxiv.org/pdf/2505.09435", "abs": "https://arxiv.org/abs/2505.09435", "authors": ["Yili He", "Yan Zhu", "Peiyao Fu", "Ruijie Yang", "Tianyi Chen", "Zhihua Wang", "Quanlin Li", "Pinghong Zhou", "Xian Yang", "Shuo Wang"], "title": "Endo-CLIP: Progressive Self-Supervised Pre-training on Raw Colonoscopy Records", "categories": ["cs.CV", "cs.AI"], "comment": "Early accepted to MICCAI 2025", "summary": "Pre-training on image-text colonoscopy records offers substantial potential\nfor improving endoscopic image analysis, but faces challenges including\nnon-informative background images, complex medical terminology, and ambiguous\nmulti-lesion descriptions. We introduce Endo-CLIP, a novel self-supervised\nframework that enhances Contrastive Language-Image Pre-training (CLIP) for this\ndomain. Endo-CLIP's three-stage framework--cleansing, attunement, and\nunification--addresses these challenges by (1) removing background frames, (2)\nleveraging large language models to extract clinical attributes for\nfine-grained contrastive learning, and (3) employing patient-level\ncross-attention to resolve multi-polyp ambiguities. Extensive experiments\ndemonstrate that Endo-CLIP significantly outperforms state-of-the-art\npre-training methods in zero-shot and few-shot polyp detection and\nclassification, paving the way for more accurate and clinically relevant\nendoscopic analysis."}
{"id": "2505.09203", "pdf": "https://arxiv.org/pdf/2505.09203", "abs": "https://arxiv.org/abs/2505.09203", "authors": ["Xiao-Qi Han", "Peng-Jie Guo", "Ze-Feng Gao", "Hao Sun", "Zhong-Yi Lu"], "title": "InvDesFlow-AL: Active Learning-based Workflow for Inverse Design of Functional Materials", "categories": ["cond-mat.mtrl-sci", "cond-mat.supr-con", "cs.AI", "cs.LG"], "comment": "29 pages, 11 figures", "summary": "Developing inverse design methods for functional materials with specific\nproperties is critical to advancing fields like renewable energy, catalysis,\nenergy storage, and carbon capture. Generative models based on diffusion\nprinciples can directly produce new materials that meet performance\nconstraints, thereby significantly accelerating the material design process.\nHowever, existing methods for generating and predicting crystal structures\noften remain limited by low success rates. In this work, we propose a novel\ninverse material design generative framework called InvDesFlow-AL, which is\nbased on active learning strategies. This framework can iteratively optimize\nthe material generation process to gradually guide it towards desired\nperformance characteristics. In terms of crystal structure prediction, the\nInvDesFlow-AL model achieves an RMSE of 0.0423 {\\AA}, representing an 32.96%\nimprovement in performance compared to exsisting generative models.\nAdditionally, InvDesFlow-AL has been successfully validated in the design of\nlow-formation-energy and low-Ehull materials. It can systematically generate\nmaterials with progressively lower formation energies while continuously\nexpanding the exploration across diverse chemical spaces. These results fully\ndemonstrate the effectiveness of the proposed active learning-driven generative\nmodel in accelerating material discovery and inverse design. To further prove\nthe effectiveness of this method, we took the search for BCS superconductors\nunder ambient pressure as an example explored by InvDesFlow-AL. As a result, we\nsuccessfully identified Li\\(_2\\)AuH\\(_6\\) as a conventional BCS superconductor\nwith an ultra-high transition temperature of 140 K. This discovery provides\nstrong empirical support for the application of inverse design in materials\nscience."}
{"id": "2505.09393", "pdf": "https://arxiv.org/pdf/2505.09393", "abs": "https://arxiv.org/abs/2505.09393", "authors": ["Huakun Liu", "Hiroki Ota", "Xin Wei", "Yutaro Hirao", "Monica Perusquia-Hernandez", "Hideaki Uchiyama", "Kiyoshi Kiyokawa"], "title": "UMotion: Uncertainty-driven Human Motion Estimation from Inertial and Ultra-wideband Units", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "Accepted by CVPR 2025", "summary": "Sparse wearable inertial measurement units (IMUs) have gained popularity for\nestimating 3D human motion. However, challenges such as pose ambiguity, data\ndrift, and limited adaptability to diverse bodies persist. To address these\nissues, we propose UMotion, an uncertainty-driven, online fusing-all state\nestimation framework for 3D human shape and pose estimation, supported by six\nintegrated, body-worn ultra-wideband (UWB) distance sensors with IMUs. UWB\nsensors measure inter-node distances to infer spatial relationships, aiding in\nresolving pose ambiguities and body shape variations when combined with\nanthropometric data. Unfortunately, IMUs are prone to drift, and UWB sensors\nare affected by body occlusions. Consequently, we develop a tightly coupled\nUnscented Kalman Filter (UKF) framework that fuses uncertainties from sensor\ndata and estimated human motion based on individual body shape. The UKF\niteratively refines IMU and UWB measurements by aligning them with uncertain\nhuman motion constraints in real-time, producing optimal estimates for each.\nExperiments on both synthetic and real-world datasets demonstrate the\neffectiveness of UMotion in stabilizing sensor data and the improvement over\nstate of the art in pose accuracy."}
{"id": "2505.09436", "pdf": "https://arxiv.org/pdf/2505.09436", "abs": "https://arxiv.org/abs/2505.09436", "authors": ["Raghav Garg", "Kapil Sharma", "Karan Gupta"], "title": "CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "comment": null, "summary": "Large Language Models (LLMs) hold immense potential for revolutionizing\nCustomer Experience Management (CXM), particularly in contact center\noperations. However, evaluating their practical utility in complex operational\nenvironments is hindered by data scarcity (due to privacy concerns) and the\nlimitations of current benchmarks. Existing benchmarks often lack realism,\nfailing to incorporate deep knowledge base (KB) integration, real-world noise,\nor critical operational tasks beyond conversational fluency. To bridge this\ngap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset\nspecifically designed for evaluating AI in operational CXM contexts. Given the\ndiversity in possible contact center features, we have developed a scalable\nLLM-powered pipeline that simulates the brand's CXM entities that form the\nfoundation of our datasets-such as knowledge articles including product\nspecifications, issue taxonomies, and contact center conversations. The\nentities closely represent real-world distribution because of controlled noise\ninjection (informed by domain experts) and rigorous automated validation.\nBuilding on this, we release CXMArena, which provides dedicated benchmarks\ntargeting five important operational tasks: Knowledge Base Refinement, Intent\nPrediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with\nIntegrated Tools. Our baseline experiments underscore the benchmark's\ndifficulty: even state of the art embedding and generation models achieve only\n68% accuracy on article search, while standard embedding methods yield a low F1\nscore of 0.3 for knowledge base refinement, highlighting significant challenges\nfor current models necessitating complex pipelines and solutions over\nconventional techniques."}
{"id": "2505.09229", "pdf": "https://arxiv.org/pdf/2505.09229", "abs": "https://arxiv.org/abs/2505.09229", "authors": ["Brian Britos", "Mathias Bourel"], "title": "Optimal Transport-Based Domain Adaptation for Rotated Linear Regression", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": null, "summary": "Optimal Transport (OT) has proven effective for domain adaptation (DA) by\naligning distributions across domains with differing statistical properties.\nBuilding on the approach of Courty et al. (2016), who mapped source data to the\ntarget domain for improved model transfer, we focus on a supervised DA problem\ninvolving linear regression models under rotational shifts. This ongoing work\nconsiders cases where source and target domains are related by a\nrotation-common in applications like sensor calibration or image orientation.\nWe show that in $\\mathbb{R}^2$ , when using a p-norm cost with $p $\\ge$ 2$, the\noptimal transport map recovers the underlying rotation. Based on this, we\npropose an algorithm that combines K-means clustering, OT, and singular value\ndecomposition (SVD) to estimate the rotation angle and adapt the regression\nmodel. This method is particularly effective when the target domain is sparsely\nsampled, leveraging abundant source data for improved generalization. Our\ncontributions offer both theoretical and practical insights into OT-based model\nadaptation under geometric transformations."}
{"id": "2505.09521", "pdf": "https://arxiv.org/pdf/2505.09521", "abs": "https://arxiv.org/abs/2505.09521", "authors": ["Dongyi He", "Shiyang Li", "Bin Jiang", "He Yan"], "title": "Spec2VolCAMU-Net: A Spectrogram-to-Volume Model for EEG-to-fMRI Reconstruction based on Multi-directional Time-Frequency Convolutional Attention Encoder and Vision-Mamba U-Net", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "High-resolution functional magnetic resonance imaging (fMRI) is essential for\nmapping human brain activity; however, it remains costly and logistically\nchallenging. If comparable volumes could be generated directly from widely\navailable scalp electroencephalography (EEG), advanced neuroimaging would\nbecome significantly more accessible. Existing EEG-to-fMRI generators rely on\nplain CNNs that fail to capture cross-channel time-frequency cues or on heavy\ntransformer/GAN decoders that strain memory and stability. We propose\nSpec2VolCAMU-Net, a lightweight spectrogram-to-volume generator that confronts\nthese issues via a Multi-directional Time-Frequency Convolutional Attention\nEncoder, stacking temporal, spectral and joint convolutions with\nself-attention, and a Vision-Mamba U-Net decoder whose linear-time state-space\nblocks enable efficient long-range spatial modelling. Trained end-to-end with a\nhybrid SSI-MSE loss, Spec2VolCAMU-Net achieves state-of-the-art fidelity on\nthree public benchmarks, recording SSIMs of 0.693 on NODDI, 0.725 on Oddball\nand 0.788 on CN-EPFL, representing improvements of 14.5%, 14.9%, and 16.9%\nrespectively over previous best SSIM scores. Furthermore, it achieves\ncompetitive PSNR scores, particularly excelling on the CN-EPFL dataset with a\n4.6% improvement over the previous best PSNR, thus striking a better balance in\nreconstruction quality. The proposed model is lightweight and efficient, making\nit suitable for real-time applications in clinical and research settings. The\ncode is available at https://github.com/hdy6438/Spec2VolCAMU-Net."}
{"id": "2505.09438", "pdf": "https://arxiv.org/pdf/2505.09438", "abs": "https://arxiv.org/abs/2505.09438", "authors": ["Paul Tschisgale", "Holger Maus", "Fabian Kieser", "Ben Kroehs", "Stefan Petersen", "Peter Wulff"], "title": "Evaluating GPT- and Reasoning-based Large Language Models on Physics Olympiad Problems: Surpassing Human Performance and Implications for Educational Assessment", "categories": ["physics.ed-ph", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are now widely accessible, reaching learners at\nall educational levels. This development has raised concerns that their use may\ncircumvent essential learning processes and compromise the integrity of\nestablished assessment formats. In physics education, where problem solving\nplays a central role in instruction and assessment, it is therefore essential\nto understand the physics-specific problem-solving capabilities of LLMs. Such\nunderstanding is key to informing responsible and pedagogically sound\napproaches to integrating LLMs into instruction and assessment. This study\ntherefore compares the problem-solving performance of a general-purpose LLM\n(GPT-4o, using varying prompting techniques) and a reasoning-optimized model\n(o1-preview) with that of participants of the German Physics Olympiad, based on\na set of well-defined Olympiad problems. In addition to evaluating the\ncorrectness of the generated solutions, the study analyzes characteristic\nstrengths and limitations of LLM-generated solutions. The findings of this\nstudy indicate that both tested LLMs (GPT-4o and o1-preview) demonstrate\nadvanced problem-solving capabilities on Olympiad-type physics problems, on\naverage outperforming the human participants. Prompting techniques had little\neffect on GPT-4o's performance, while o1-preview almost consistently\noutperformed both GPT-4o and the human benchmark. Based on these findings, the\nstudy discusses implications for the design of summative and formative\nassessment in physics education, including how to uphold assessment integrity\nand support students in critically engaging with LLMs."}
{"id": "2505.09262", "pdf": "https://arxiv.org/pdf/2505.09262", "abs": "https://arxiv.org/abs/2505.09262", "authors": ["Hongxin Xiang", "Ke Li", "Mingquan Liu", "Zhixiang Cheng", "Bin Yao", "Wenjie Du", "Jun Xia", "Li Zeng", "Xin Jin", "Xiangxiang Zeng"], "title": "EDBench: Large-Scale Electron Density Data for Molecular Modeling", "categories": ["physics.chem-ph", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Existing molecular machine learning force fields (MLFFs) generally focus on\nthe learning of atoms, molecules, and simple quantum chemical properties (such\nas energy and force), but ignore the importance of electron density (ED)\n$\\rho(r)$ in accurately understanding molecular force fields (MFFs). ED\ndescribes the probability of finding electrons at specific locations around\natoms or molecules, which uniquely determines all ground state properties (such\nas energy, molecular structure, etc.) of interactive multi-particle systems\naccording to the Hohenberg-Kohn theorem. However, the calculation of ED relies\non the time-consuming first-principles density functional theory (DFT) which\nleads to the lack of large-scale ED data and limits its application in MLFFs.\nIn this paper, we introduce EDBench, a large-scale, high-quality dataset of ED\ndesigned to advance learning-based research at the electronic scale. Built upon\nthe PCQM4Mv2, EDBench provides accurate ED data, covering 3.3 million\nmolecules. To comprehensively evaluate the ability of models to understand and\nutilize electronic information, we design a suite of ED-centric benchmark tasks\nspanning prediction, retrieval, and generation. Our evaluation on several\nstate-of-the-art methods demonstrates that learning from EDBench is not only\nfeasible but also achieves high accuracy. Moreover, we show that learning-based\nmethod can efficiently calculate ED with comparable precision while\nsignificantly reducing the computational cost relative to traditional DFT\ncalculations. All data and benchmarks from EDBench will be freely available,\nlaying a robust foundation for ED-driven drug discovery and materials science."}
{"id": "2505.09565", "pdf": "https://arxiv.org/pdf/2505.09565", "abs": "https://arxiv.org/abs/2505.09565", "authors": ["Maik Dannecker", "Thomas Sanchez", "Meritxell Bach Cuadra", "Özgün Turgut", "Anthony N. Price", "Lucilio Cordero-Grande", "Vanessa Kyriakopoulou", "Joseph V. Hajnal", "Daniel Rueckert"], "title": "Meta-learning Slice-to-Volume Reconstruction in Fetal Brain MRI using Implicit Neural Representations", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "10 pages, 6 figures", "summary": "High-resolution slice-to-volume reconstruction (SVR) from multiple\nmotion-corrupted low-resolution 2D slices constitutes a critical step in\nimage-based diagnostics of moving subjects, such as fetal brain Magnetic\nResonance Imaging (MRI). Existing solutions struggle with image artifacts and\nsevere subject motion or require slice pre-alignment to achieve satisfying\nreconstruction performance. We propose a novel SVR method to enable fast and\naccurate MRI reconstruction even in cases of severe image and motion\ncorruption. Our approach performs motion correction, outlier handling, and\nsuper-resolution reconstruction with all operations being entirely based on\nimplicit neural representations. The model can be initialized with\ntask-specific priors through fully self-supervised meta-learning on either\nsimulated or real-world data. In extensive experiments including over 480\nreconstructions of simulated and clinical MRI brain data from different\ncenters, we prove the utility of our method in cases of severe subject motion\nand image artifacts. Our results demonstrate improvements in reconstruction\nquality, especially in the presence of severe motion, compared to\nstate-of-the-art methods, and up to 50% reduction in reconstruction time."}
{"id": "2505.09456", "pdf": "https://arxiv.org/pdf/2505.09456", "abs": "https://arxiv.org/abs/2505.09456", "authors": ["Josep Lumbreras", "Ruo Cheng Huang", "Yanglin Hu", "Mile Gu", "Marco Tomamichel"], "title": "Quantum state-agnostic work extraction (almost) without dissipation", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "5 pages+14 pages, 2 figures", "summary": "We investigate work extraction protocols designed to transfer the maximum\npossible energy to a battery using sequential access to $N$ copies of an\nunknown pure qubit state. The core challenge is designing interactions to\noptimally balance two competing goals: charging of the battery optimally using\nthe qubit in hand, and acquiring more information by qubit to improve energy\nharvesting in subsequent rounds. Here, we leverage exploration-exploitation\ntrade-off in reinforcement learning to develop adaptive strategies achieving\nenergy dissipation that scales only poly-logarithmically in $N$. This\nrepresents an exponential improvement over current protocols based on full\nstate tomography."}
{"id": "2505.09266", "pdf": "https://arxiv.org/pdf/2505.09266", "abs": "https://arxiv.org/abs/2505.09266", "authors": ["Lirandë Pira", "Airin Antony", "Nayanthara Prathap", "Daniel Peace", "Jacquiline Romero"], "title": "Enhanced Photonic Chip Design via Interpretable Machine Learning Techniques", "categories": ["physics.optics", "cs.LG", "quant-ph"], "comment": null, "summary": "Photonic chip design has seen significant advancements with the adoption of\ninverse design methodologies, offering flexibility and efficiency in optimizing\ndevice performance. However, the black-box nature of the optimization\napproaches, such as those used in inverse design in order to minimize a loss\nfunction or maximize coupling efficiency, poses challenges in understanding the\noutputs. This challenge is prevalent in machine learning-based optimization\nmethods, which can suffer from the same lack of transparency. To this end,\ninterpretability techniques address the opacity of optimization models. In this\nwork, we apply interpretability techniques from machine learning, with the aim\nof gaining understanding of inverse design optimization used in designing\nphotonic components, specifically two-mode multiplexers. We base our\nmethodology on the widespread interpretability technique known as local\ninterpretable model-agnostic explanations, or LIME. As a result, LIME-informed\ninsights point us to more effective initial conditions, directly improving\ndevice performance. This demonstrates that interpretability methods can do more\nthan explain models -- they can actively guide and enhance the inverse-designed\nphotonic components. Our results demonstrate the ability of interpretable\ntechniques to reveal underlying patterns in the inverse design process, leading\nto the development of better-performing components."}
{"id": "2505.09466", "pdf": "https://arxiv.org/pdf/2505.09466", "abs": "https://arxiv.org/abs/2505.09466", "authors": ["Xi Chen", "Shiyang Zhou", "Muqi Huang", "Jiaxu Feng", "Yun Xiong", "Kun Zhou", "Biao Yang", "Yuhui Zhang", "Huishuai Bao", "Sijia Peng", "Chuan Li", "Feng Shi"], "title": "A 2D Semantic-Aware Position Encoding for Vision Transformers", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages, 4 figures, 3 tables", "summary": "Vision transformers have demonstrated significant advantages in computer\nvision tasks due to their ability to capture long-range dependencies and\ncontextual relationships through self-attention. However, existing position\nencoding techniques, which are largely borrowed from natural language\nprocessing, fail to effectively capture semantic-aware positional relationships\nbetween image patches. Traditional approaches like absolute position encoding\nand relative position encoding primarily focus on 1D linear position\nrelationship, often neglecting the semantic similarity between distant yet\ncontextually related patches. These limitations hinder model generalization,\ntranslation equivariance, and the ability to effectively handle repetitive or\nstructured patterns in images. In this paper, we propose 2-Dimensional\nSemantic-Aware Position Encoding ($\\text{SaPE}^2$), a novel position encoding\nmethod with semantic awareness that dynamically adapts position representations\nby leveraging local content instead of fixed linear position relationship or\nspatial coordinates. Our method enhances the model's ability to generalize\nacross varying image resolutions and scales, improves translation equivariance,\nand better aggregates features for visually similar but spatially distant\npatches. By integrating $\\text{SaPE}^2$ into vision transformers, we bridge the\ngap between position encoding and perceptual similarity, thereby improving\nperformance on computer vision tasks."}
{"id": "2505.09295", "pdf": "https://arxiv.org/pdf/2505.09295", "abs": "https://arxiv.org/abs/2505.09295", "authors": ["Qiming Wu", "Siqi Li", "Doudou Zhou", "Nan Liu"], "title": "Toward Fair Federated Learning under Demographic Disparities and Data Imbalance", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "Ensuring fairness is critical when applying artificial intelligence to\nhigh-stakes domains such as healthcare, where predictive models trained on\nimbalanced and demographically skewed data risk exacerbating existing\ndisparities. Federated learning (FL) enables privacy-preserving collaboration\nacross institutions, but remains vulnerable to both algorithmic bias and\nsubgroup imbalance - particularly when multiple sensitive attributes intersect.\nWe propose FedIDA (Fed erated Learning for Imbalance and D isparity A\nwareness), a framework-agnostic method that combines fairness-aware\nregularization with group-conditional oversampling. FedIDA supports multiple\nsensitive attributes and heterogeneous data distributions without altering the\nconvergence behavior of the underlying FL algorithm. We provide theoretical\nanalysis establishing fairness improvement bounds using Lipschitz continuity\nand concentration inequalities, and show that FedIDA reduces the variance of\nfairness metrics across test sets. Empirical results on both benchmark and\nreal-world clinical datasets confirm that FedIDA consistently improves fairness\nwhile maintaining competitive predictive performance, demonstrating its\neffectiveness for equitable and privacy-preserving modeling in healthcare. The\nsource code is available on GitHub."}
{"id": "2505.09477", "pdf": "https://arxiv.org/pdf/2505.09477", "abs": "https://arxiv.org/abs/2505.09477", "authors": ["Zachary Ravichandran", "Fernando Cladera", "Jason Hughes", "Varun Murali", "M. Ani Hsieh", "George J. Pappas", "Camillo J. Taylor", "Vijay Kumar"], "title": "Deploying Foundation Model-Enabled Air and Ground Robots in the Field: Challenges and Opportunities", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted to the IEEE ICRA Workshop on Field Robotics 2025", "summary": "The integration of foundation models (FMs) into robotics has enabled robots\nto understand natural language and reason about the semantics in their\nenvironments. However, existing FM-enabled robots primary operate in\nclosed-world settings, where the robot is given a full prior map or has a full\nview of its workspace. This paper addresses the deployment of FM-enabled robots\nin the field, where missions often require a robot to operate in large-scale\nand unstructured environments. To effectively accomplish these missions, robots\nmust actively explore their environments, navigate obstacle-cluttered terrain,\nhandle unexpected sensor inputs, and operate with compute constraints. We\ndiscuss recent deployments of SPINE, our LLM-enabled autonomy framework, in\nfield robotic settings. To the best of our knowledge, we present the first\ndemonstration of large-scale LLM-enabled robot planning in unstructured\nenvironments with several kilometers of missions. SPINE is agnostic to a\nparticular LLM, which allows us to distill small language models capable of\nrunning onboard size, weight and power (SWaP) limited platforms. Via\npreliminary model distillation work, we then present the first language-driven\nUAV planner using on-device language models. We conclude our paper by proposing\nseveral promising directions for future research."}
{"id": "2505.09304", "pdf": "https://arxiv.org/pdf/2505.09304", "abs": "https://arxiv.org/abs/2505.09304", "authors": ["Luciano Sebastian Martinez-Rau", "Quynh Nguyen Phuong Vu", "Yuxuan Zhang", "Bengt Oelmann", "Sebastian Bader"], "title": "Adaptive Noise Resilient Keyword Spotting Using One-Shot Learning", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "Preprint submitted to the IEEE 11th World Forum on Internet of Things", "summary": "Keyword spotting (KWS) is a key component of smart devices, enabling\nefficient and intuitive audio interaction. However, standard KWS systems\ndeployed on embedded devices often suffer performance degradation under\nreal-world operating conditions. Resilient KWS systems address this issue by\nenabling dynamic adaptation, with applications such as adding or replacing\nkeywords, adjusting to specific users, and improving noise robustness. However,\ndeploying resilient, standalone KWS systems with low latency on\nresource-constrained devices remains challenging due to limited memory and\ncomputational resources. This study proposes a low computational approach for\ncontinuous noise adaptation of pretrained neural networks used for KWS\nclassification, requiring only 1-shot learning and one epoch. The proposed\nmethod was assessed using two pretrained models and three real-world noise\nsources at signal-to-noise ratios (SNRs) ranging from 24 to -3 dB. The adapted\nmodels consistently outperformed the pretrained models across all scenarios,\nespecially at SNR $\\leq$ 18 dB, achieving accuracy improvements of 4.9% to\n46.0%. These results highlight the efficacy of the proposed methodology while\nbeing lightweight enough for deployment on resource-constrained devices."}
{"id": "2505.09486", "pdf": "https://arxiv.org/pdf/2505.09486", "abs": "https://arxiv.org/abs/2505.09486", "authors": ["Seyed Roozbeh Razavi Rohani", "Khashayar Khajavi", "Wesley Chung", "Mo Chen", "Sharan Vaswani"], "title": "Preserving Plasticity in Continual Learning with Adaptive Linearity Injection", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in 4th Conference on Lifelong Learning Agents (CoLLAs), 2025", "summary": "Loss of plasticity in deep neural networks is the gradual reduction in a\nmodel's capacity to incrementally learn and has been identified as a key\nobstacle to learning in non-stationary problem settings. Recent work has shown\nthat deep linear networks tend to be resilient towards loss of plasticity.\nMotivated by this observation, we propose Adaptive Linearization (AdaLin), a\ngeneral approach that dynamically adapts each neuron's activation function to\nmitigate plasticity loss. Unlike prior methods that rely on regularization or\nperiodic resets, AdaLin equips every neuron with a learnable parameter and a\ngating mechanism that injects linearity into the activation function based on\nits gradient flow. This adaptive modulation ensures sufficient gradient signal\nand sustains continual learning without introducing additional hyperparameters\nor requiring explicit task boundaries. When used with conventional activation\nfunctions like ReLU, Tanh, and GeLU, we demonstrate that AdaLin can\nsignificantly improve performance on standard benchmarks, including Random\nLabel and Permuted MNIST, Random Label and Shuffled CIFAR-10, and Class-Split\nCIFAR-100. Furthermore, its efficacy is shown in more complex scenarios, such\nas class-incremental learning on CIFAR-100 with a ResNet-18 backbone, and in\nmitigating plasticity loss in off-policy reinforcement learning agents. We\nperform a systematic set of ablations that show that neuron-level adaptation is\ncrucial for good performance and analyze a number of metrics in the network\nthat might be correlated to loss of plasticity."}
{"id": "2505.09306", "pdf": "https://arxiv.org/pdf/2505.09306", "abs": "https://arxiv.org/abs/2505.09306", "authors": ["Thijs L van der Plas", "Stephen Law", "Michael JO Pocock"], "title": "Predicting butterfly species presence from satellite imagery using soft contrastive regularisation", "categories": ["cs.CV", "cs.LG"], "comment": "To be published in the 2025 CVPR FGVC12 workshop", "summary": "The growing demand for scalable biodiversity monitoring methods has fuelled\ninterest in remote sensing data, due to its widespread availability and\nextensive coverage. Traditionally, the application of remote sensing to\nbiodiversity research has focused on mapping and monitoring habitats, but with\nincreasing availability of large-scale citizen-science wildlife observation\ndata, recent methods have started to explore predicting multi-species presence\ndirectly from satellite images. This paper presents a new data set for\npredicting butterfly species presence from satellite data in the United\nKingdom. We experimentally optimise a Resnet-based model to predict\nmulti-species presence from 4-band satellite images, and find that this model\nespecially outperforms the mean rate baseline for locations with high species\nbiodiversity. To improve performance, we develop a soft, supervised contrastive\nregularisation loss that is tailored to probabilistic labels (such as\nspecies-presence data), and demonstrate that this improves prediction accuracy.\nIn summary, our new data set and contrastive regularisation method contribute\nto the open challenge of accurately predicting species biodiversity from remote\nsensing data, which is key for efficient biodiversity monitoring."}
{"id": "2505.09498", "pdf": "https://arxiv.org/pdf/2505.09498", "abs": "https://arxiv.org/abs/2505.09498", "authors": ["Bo Zhang", "Shuo Li", "Runhe Tian", "Yang Yang", "Jixin Tang", "Jinhao Zhou", "Lin Ma"], "title": "Flash-VL 2B: Optimizing Vision-Language Model Performance for Ultra-Low Latency and High Throughput", "categories": ["cs.CV", "cs.AI"], "comment": "18 pages, 7 figures", "summary": "In this paper, we introduce Flash-VL 2B, a novel approach to optimizing\nVision-Language Models (VLMs) for real-time applications, targeting ultra-low\nlatency and high throughput without sacrificing accuracy. Leveraging advanced\narchitectural enhancements and efficient computational strategies, Flash-VL 2B\nis designed to maximize throughput by reducing processing time while\nmaintaining competitive performance across multiple vision-language benchmarks.\nOur approach includes tailored architectural choices, token compression\nmechanisms, data curation, training schemes, and a novel image processing\ntechnique called implicit semantic stitching that effectively balances\ncomputational load and model performance. Through extensive evaluations on 11\nstandard VLM benchmarks, we demonstrate that Flash-VL 2B achieves\nstate-of-the-art results in both speed and accuracy, making it a promising\nsolution for deployment in resource-constrained environments and large-scale\nreal-time applications."}
{"id": "2505.09313", "pdf": "https://arxiv.org/pdf/2505.09313", "abs": "https://arxiv.org/abs/2505.09313", "authors": ["Qiangqiang Liu", "Qian Huang", "Frank Fan", "Haishan Wu", "Xueyan Tang"], "title": "Detecting Sybil Addresses in Blockchain Airdrops: A Subgraph-based Feature Propagation and Fusion Approach", "categories": ["cs.CR", "cs.LG"], "comment": "IEEE International Conference on Blockchain and Cryptocurrency(Proc.\n  IEEE ICBC 2025)", "summary": "Sybil attacks pose a significant security threat to blockchain ecosystems,\nparticularly in token airdrop events. This paper proposes a novel sybil address\nidentification method based on subgraph feature extraction lightGBM. The method\nfirst constructs a two-layer deep transaction subgraph for each address, then\nextracts key event operation features according to the lifecycle of sybil\naddresses, including the time of first transaction, first gas acquisition,\nparticipation in airdrop activities, and last transaction. These temporal\nfeatures effectively capture the consistency of sybil address behavior\noperations. Additionally, the method extracts amount and network structure\nfeatures, comprehensively describing address behavior patterns and network\ntopology through feature propagation and fusion. Experiments conducted on a\ndataset containing 193,701 addresses (including 23,240 sybil addresses) show\nthat this method outperforms existing approaches in terms of precision, recall,\nF1 score, and AUC, with all metrics exceeding 0.9. The methods and results of\nthis study can be further applied to broader blockchain security areas such as\ntransaction manipulation identification and token liquidity risk assessment,\ncontributing to the construction of a more secure and fair blockchain\necosystem."}
{"id": "2505.09558", "pdf": "https://arxiv.org/pdf/2505.09558", "abs": "https://arxiv.org/abs/2505.09558", "authors": ["Shengpeng Ji", "Tianle Liang", "Yangzhuo Li", "Jialong Zuo", "Minghui Fang", "Jinzheng He", "Yifu Chen", "Zhengqing Liu", "Ziyue Jiang", "Xize Cheng", "Siqi Zheng", "Jin Xu", "Junyang Lin", "Zhou Zhao"], "title": "WavReward: Spoken Dialogue Models With Generalist Reward Evaluators", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.MM", "cs.SD"], "comment": null, "summary": "End-to-end spoken dialogue models such as GPT-4o-audio have recently garnered\nsignificant attention in the speech domain. However, the evaluation of spoken\ndialogue models' conversational performance has largely been overlooked. This\nis primarily due to the intelligent chatbots convey a wealth of non-textual\ninformation which cannot be easily measured using text-based language models\nlike ChatGPT. To address this gap, we propose WavReward, a reward feedback\nmodel based on audio language models that can evaluate both the IQ and EQ of\nspoken dialogue systems with speech input. Specifically, 1) based on audio\nlanguage models, WavReward incorporates the deep reasoning process and the\nnonlinear reward mechanism for post-training. By utilizing multi-sample\nfeedback via the reinforcement learning algorithm, we construct a specialized\nevaluator tailored to spoken dialogue models. 2) We introduce ChatReward-30K, a\npreference dataset used to train WavReward. ChatReward-30K includes both\ncomprehension and generation aspects of spoken dialogue models. These scenarios\nspan various tasks, such as text-based chats, nine acoustic attributes of\ninstruction chats, and implicit chats. WavReward outperforms previous\nstate-of-the-art evaluation models across multiple spoken dialogue scenarios,\nachieving a substantial improvement about Qwen2.5-Omni in objective accuracy\nfrom 55.1$\\%$ to 91.5$\\%$. In subjective A/B testing, WavReward also leads by a\nmargin of 83$\\%$. Comprehensive ablation studies confirm the necessity of each\ncomponent of WavReward. All data and code will be publicly at\nhttps://github.com/jishengpeng/WavReward after the paper is accepted."}
{"id": "2505.09315", "pdf": "https://arxiv.org/pdf/2505.09315", "abs": "https://arxiv.org/abs/2505.09315", "authors": ["Xuefeng Jiang", "Yuan Ma", "Pengxiang Li", "Leimeng Xu", "Xin Wen", "Kun Zhan", "Zhongpu Xia", "Peng Jia", "XianPeng Lang", "Sheng Sun"], "title": "TransDiffuser: End-to-end Trajectory Generation with Decorrelated Multi-modal Representation for Autonomous Driving", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "Under review", "summary": "In recent years, diffusion model has shown its potential across diverse\ndomains from vision generation to language modeling. Transferring its\ncapabilities to modern autonomous driving systems has also emerged as a\npromising direction.In this work, we propose TransDiffuser, an encoder-decoder\nbased generative trajectory planning model for end-to-end autonomous driving.\nThe encoded scene information serves as the multi-modal conditional input of\nthe denoising decoder. To tackle the mode collapse dilemma in generating\nhigh-quality diverse trajectories, we introduce a simple yet effective\nmulti-modal representation decorrelation optimization mechanism during the\ntraining process.TransDiffuser achieves PDMS of 94.85 on the NAVSIM benchmark,\nsurpassing previous state-of-the-art methods without any anchor-based prior\ntrajectories."}
{"id": "2505.09561", "pdf": "https://arxiv.org/pdf/2505.09561", "abs": "https://arxiv.org/abs/2505.09561", "authors": ["Marcel Torne", "Andy Tang", "Yuejiang Liu", "Chelsea Finn"], "title": "Learning Long-Context Diffusion Policies via Past-Token Prediction", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Videos are available at https://long-context-dp.github.io", "summary": "Reasoning over long sequences of observations and actions is essential for\nmany robotic tasks. Yet, learning effective long-context policies from\ndemonstrations remains challenging. As context length increases, training\nbecomes increasingly expensive due to rising memory demands, and policy\nperformance often degrades as a result of spurious correlations. Recent methods\ntypically sidestep these issues by truncating context length, discarding\nhistorical information that may be critical for subsequent decisions. In this\npaper, we propose an alternative approach that explicitly regularizes the\nretention of past information. We first revisit the copycat problem in\nimitation learning and identify an opposite challenge in recent diffusion\npolicies: rather than over-relying on prior actions, they often fail to capture\nessential dependencies between past and future actions. To address this, we\nintroduce Past-Token Prediction (PTP), an auxiliary task in which the policy\nlearns to predict past action tokens alongside future ones. This regularization\nsignificantly improves temporal modeling in the policy head, with minimal\nreliance on visual representations. Building on this observation, we further\nintroduce a multistage training strategy: pre-train the visual encoder with\nshort contexts, and fine-tune the policy head using cached long-context\nembeddings. This strategy preserves the benefits of PTP while greatly reducing\nmemory and computational overhead. Finally, we extend PTP into a\nself-verification mechanism at test time, enabling the policy to score and\nselect candidates consistent with past actions during inference. Experiments\nacross four real-world and six simulated tasks demonstrate that our proposed\nmethod improves the performance of long-context diffusion policies by 3x and\naccelerates policy training by more than 10x."}
{"id": "2505.09324", "pdf": "https://arxiv.org/pdf/2505.09324", "abs": "https://arxiv.org/abs/2505.09324", "authors": ["Lakshya Gupta", "Imran N. Junejo"], "title": "Neural Video Compression using 2D Gaussian Splatting", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "comment": "9 pages, 8 figures", "summary": "The computer vision and image processing research community has been involved\nin standardizing video data communications for the past many decades, leading\nto standards such as AVC, HEVC, VVC, AV1, AV2, etc. However, recent\ngroundbreaking works have focused on employing deep learning-based techniques\nto replace the traditional video codec pipeline to a greater affect. Neural\nvideo codecs (NVC) create an end-to-end ML-based solution that does not rely on\nany handcrafted features (motion or edge-based) and have the ability to learn\ncontent-aware compression strategies, offering better adaptability and higher\ncompression efficiency than traditional methods. This holds a great potential\nnot only for hardware design, but also for various video streaming platforms\nand applications, especially video conferencing applications such as MS-Teams\nor Zoom that have found extensive usage in classrooms and workplaces. However,\ntheir high computational demands currently limit their use in real-time\napplications like video conferencing. To address this, we propose a\nregion-of-interest (ROI) based neural video compression model that leverages 2D\nGaussian Splatting. Unlike traditional codecs, 2D Gaussian Splatting is capable\nof real-time decoding and can be optimized using fewer data points, requiring\nonly thousands of Gaussians for decent quality outputs as opposed to millions\nin 3D scenes. In this work, we designed a video pipeline that speeds up the\nencoding time of the previous Gaussian splatting-based image codec by 88% by\nusing a content-aware initialization strategy paired with a novel Gaussian\ninter-frame redundancy-reduction mechanism, enabling Gaussian splatting to be\nused for a video-codec solution, the first of its kind solution in this neural\nvideo codec space."}
{"id": "2505.09565", "pdf": "https://arxiv.org/pdf/2505.09565", "abs": "https://arxiv.org/abs/2505.09565", "authors": ["Maik Dannecker", "Thomas Sanchez", "Meritxell Bach Cuadra", "Özgün Turgut", "Anthony N. Price", "Lucilio Cordero-Grande", "Vanessa Kyriakopoulou", "Joseph V. Hajnal", "Daniel Rueckert"], "title": "Meta-learning Slice-to-Volume Reconstruction in Fetal Brain MRI using Implicit Neural Representations", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "10 pages, 6 figures", "summary": "High-resolution slice-to-volume reconstruction (SVR) from multiple\nmotion-corrupted low-resolution 2D slices constitutes a critical step in\nimage-based diagnostics of moving subjects, such as fetal brain Magnetic\nResonance Imaging (MRI). Existing solutions struggle with image artifacts and\nsevere subject motion or require slice pre-alignment to achieve satisfying\nreconstruction performance. We propose a novel SVR method to enable fast and\naccurate MRI reconstruction even in cases of severe image and motion\ncorruption. Our approach performs motion correction, outlier handling, and\nsuper-resolution reconstruction with all operations being entirely based on\nimplicit neural representations. The model can be initialized with\ntask-specific priors through fully self-supervised meta-learning on either\nsimulated or real-world data. In extensive experiments including over 480\nreconstructions of simulated and clinical MRI brain data from different\ncenters, we prove the utility of our method in cases of severe subject motion\nand image artifacts. Our results demonstrate improvements in reconstruction\nquality, especially in the presence of severe motion, compared to\nstate-of-the-art methods, and up to 50% reduction in reconstruction time."}
{"id": "2505.09326", "pdf": "https://arxiv.org/pdf/2505.09326", "abs": "https://arxiv.org/abs/2505.09326", "authors": ["Vincent Abbott", "Kotaro Kamiya", "Gerard Glowacki", "Yu Atsumi", "Gioele Zardini", "Yoshihiro Maruyama"], "title": "Accelerating Machine Learning Systems via Category Theory: Applications to Spherical Attention for Gene Regulatory Networks", "categories": ["math.CT", "cs.LG", "q-bio.MN"], "comment": null, "summary": "How do we enable artificial intelligence models to improve themselves? This\nis central to exponentially improving generalized artificial intelligence\nmodels, which can improve their own architecture to handle new problem domains\nin an efficient manner that leverages the latest hardware. However, current\nautomated compilation methods are poor, and efficient algorithms require years\nof human development. In this paper, we use neural circuit diagrams, based in\ncategory theory, to prove a general theorem related to deep learning\nalgorithms, guide the development of a novel attention algorithm catered to the\ndomain of gene regulatory networks, and produce a corresponding efficient\nkernel. The algorithm we propose, spherical attention, shows that neural\ncircuit diagrams enable a principled and systematic method for reasoning about\ndeep learning architectures and providing high-performance code. By replacing\nSoftMax with an $L^2$ norm as suggested by diagrams, it overcomes the special\nfunction unit bottleneck of standard attention while retaining the streaming\nproperty essential to high-performance. Our diagrammatically derived\n\\textit{FlashSign} kernel achieves comparable performance to the\nstate-of-the-art, fine-tuned FlashAttention algorithm on an A100, and\n$3.6\\times$ the performance of PyTorch. Overall, this investigation shows\nneural circuit diagrams' suitability as a high-level framework for the\nautomated development of efficient, novel artificial intelligence\narchitectures."}
{"id": "2505.09568", "pdf": "https://arxiv.org/pdf/2505.09568", "abs": "https://arxiv.org/abs/2505.09568", "authors": ["Jiuhai Chen", "Zhiyang Xu", "Xichen Pan", "Yushi Hu", "Can Qin", "Tom Goldstein", "Lifu Huang", "Tianyi Zhou", "Saining Xie", "Silvio Savarese", "Le Xue", "Caiming Xiong", "Ran Xu"], "title": "BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Unifying image understanding and generation has gained growing attention in\nrecent research on multimodal models. Although design choices for image\nunderstanding have been extensively studied, the optimal model architecture and\ntraining recipe for a unified framework with image generation remain\nunderexplored. Motivated by the strong potential of autoregressive and\ndiffusion models for high-quality generation and scalability, we conduct a\ncomprehensive study of their use in unified multimodal settings, with emphasis\non image representations, modeling objectives, and training strategies.\nGrounded in these investigations, we introduce a novel approach that employs a\ndiffusion transformer to generate semantically rich CLIP image features, in\ncontrast to conventional VAE-based representations. This design yields both\nhigher training efficiency and improved generative quality. Furthermore, we\ndemonstrate that a sequential pretraining strategy for unified models-first\ntraining on image understanding and subsequently on image generation-offers\npractical advantages by preserving image understanding capability while\ndeveloping strong image generation ability. Finally, we carefully curate a\nhigh-quality instruction-tuning dataset BLIP3o-60k for image generation by\nprompting GPT-4o with a diverse set of captions covering various scenes,\nobjects, human gestures, and more. Building on our innovative model design,\ntraining recipe, and datasets, we develop BLIP3-o, a suite of state-of-the-art\nunified multimodal models. BLIP3-o achieves superior performance across most of\nthe popular benchmarks spanning both image understanding and generation tasks.\nTo facilitate future research, we fully open-source our models, including code,\nmodel weights, training scripts, and pretraining and instruction tuning\ndatasets."}
{"id": "2505.09342", "pdf": "https://arxiv.org/pdf/2505.09342", "abs": "https://arxiv.org/abs/2505.09342", "authors": ["Mostafa Jafari", "Alireza Shameli-Sendi"], "title": "Evaluating the Robustness of Adversarial Defenses in Malware Detection Systems", "categories": ["cs.CR", "cs.AI", "cs.LG", "68", "I.2.1"], "comment": "Submitted to IEEE Transactions on Information Forensics and Security\n  (T-IFS), 13 pages, 4 figures", "summary": "Machine learning is a key tool for Android malware detection, effectively\nidentifying malicious patterns in apps. However, ML-based detectors are\nvulnerable to evasion attacks, where small, crafted changes bypass detection.\nDespite progress in adversarial defenses, the lack of comprehensive evaluation\nframeworks in binary-constrained domains limits understanding of their\nrobustness. We introduce two key contributions. First, Prioritized Binary\nRounding, a technique to convert continuous perturbations into binary feature\nspaces while preserving high attack success and low perturbation size. Second,\nthe sigma-binary attack, a novel adversarial method for binary domains,\ndesigned to achieve attack goals with minimal feature changes. Experiments on\nthe Malscan dataset show that sigma-binary outperforms existing attacks and\nexposes key vulnerabilities in state-of-the-art defenses. Defenses equipped\nwith adversary detectors, such as KDE, DLA, DNN+, and ICNN, exhibit significant\nbrittleness, with attack success rates exceeding 90% using fewer than 10\nfeature modifications and reaching 100% with just 20. Adversarially trained\ndefenses, including AT-rFGSM-k, AT-MaxMA, improves robustness under small\nbudgets but remains vulnerable to unrestricted perturbations, with attack\nsuccess rates of 99.45% and 96.62%, respectively. Although PAD-SMA demonstrates\nstrong robustness against state-of-the-art gradient-based adversarial attacks\nby maintaining an attack success rate below 16.55%, the sigma-binary attack\nsignificantly outperforms these methods, achieving a 94.56% success rate under\nunrestricted perturbations. These findings highlight the critical need for\nprecise method like sigma-binary to expose hidden vulnerabilities in existing\ndefenses and support the development of more resilient malware detection\nsystems."}
{"id": "2505.09576", "pdf": "https://arxiv.org/pdf/2505.09576", "abs": "https://arxiv.org/abs/2505.09576", "authors": ["Shannon Lodoen", "Alexi Orchard"], "title": "Ethics and Persuasion in Reinforcement Learning from Human Feedback: A Procedural Rhetorical Approach", "categories": ["cs.CY", "cs.AI"], "comment": "10 pages, 1 figure, Accepted version", "summary": "Since 2022, versions of generative AI chatbots such as ChatGPT and Claude\nhave been trained using a specialized technique called Reinforcement Learning\nfrom Human Feedback (RLHF) to fine-tune language model output using feedback\nfrom human annotators. As a result, the integration of RLHF has greatly\nenhanced the outputs of these large language models (LLMs) and made the\ninteractions and responses appear more \"human-like\" than those of previous\nversions using only supervised learning. The increasing convergence of human\nand machine-written text has potentially severe ethical, sociotechnical, and\npedagogical implications relating to transparency, trust, bias, and\ninterpersonal relations. To highlight these implications, this paper presents a\nrhetorical analysis of some of the central procedures and processes currently\nbeing reshaped by RLHF-enhanced generative AI chatbots: upholding language\nconventions, information seeking practices, and expectations for social\nrelationships. Rhetorical investigations of generative AI and LLMs have, to\nthis point, focused largely on the persuasiveness of the content generated.\nUsing Ian Bogost's concept of procedural rhetoric, this paper shifts the site\nof rhetorical investigation from content analysis to the underlying mechanisms\nof persuasion built into RLHF-enhanced LLMs. In doing so, this theoretical\ninvestigation opens a new direction for further inquiry in AI ethics that\nconsiders how procedures rerouted through AI-driven technologies might\nreinforce hegemonic language use, perpetuate biases, decontextualize learning,\nand encroach upon human relationships. It will therefore be of interest to\neducators, researchers, scholars, and the growing number of users of generative\nAI chatbots."}
{"id": "2505.09358", "pdf": "https://arxiv.org/pdf/2505.09358", "abs": "https://arxiv.org/abs/2505.09358", "authors": ["Bingxin Ke", "Kevin Qu", "Tianfu Wang", "Nando Metzger", "Shengyu Huang", "Bo Li", "Anton Obukhov", "Konrad Schindler"], "title": "Marigold: Affordable Adaptation of Diffusion-Based Image Generators for Image Analysis", "categories": ["cs.CV", "cs.LG"], "comment": "Journal extension of our CVPR 2024 paper, featuring new tasks,\n  improved efficiency, high-resolution capabilities, and enhanced accessibility", "summary": "The success of deep learning in computer vision over the past decade has\nhinged on large labeled datasets and strong pretrained models. In data-scarce\nsettings, the quality of these pretrained models becomes crucial for effective\ntransfer learning. Image classification and self-supervised learning have\ntraditionally been the primary methods for pretraining CNNs and\ntransformer-based architectures. Recently, the rise of text-to-image generative\nmodels, particularly those using denoising diffusion in a latent space, has\nintroduced a new class of foundational models trained on massive, captioned\nimage datasets. These models' ability to generate realistic images of unseen\ncontent suggests they possess a deep understanding of the visual world. In this\nwork, we present Marigold, a family of conditional generative models and a\nfine-tuning protocol that extracts the knowledge from pretrained latent\ndiffusion models like Stable Diffusion and adapts them for dense image analysis\ntasks, including monocular depth estimation, surface normals prediction, and\nintrinsic decomposition. Marigold requires minimal modification of the\npre-trained latent diffusion model's architecture, trains with small synthetic\ndatasets on a single GPU over a few days, and demonstrates state-of-the-art\nzero-shot generalization. Project page:\nhttps://marigoldcomputervision.github.io"}
{"id": "2505.09591", "pdf": "https://arxiv.org/pdf/2505.09591", "abs": "https://arxiv.org/abs/2505.09591", "authors": ["Tobias Jan Wieczorek", "Nathalie Daun", "Mohammad Emtiyaz Khan", "Marcus Rohrbach"], "title": "Variational Visual Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "19 pages, 16 figures, under review at ICCV 2025", "summary": "Despite remarkable progress in multimodal models for Visual Question\nAnswering (VQA), there remain major reliability concerns because the models can\noften be overconfident and miscalibrated, especially in out-of-distribution\n(OOD) settings. Plenty has been done to address such issues for unimodal\nmodels, but little work exists for multimodal cases. Here, we address\nunreliability in multimodal models by proposing a Variational VQA approach.\nSpecifically, instead of fine-tuning vision-language models by using AdamW, we\nemploy a recently proposed variational algorithm called IVON, which yields a\nposterior distribution over model parameters. Through extensive experiments, we\nshow that our approach improves calibration and abstentions without sacrificing\nthe accuracy of AdamW. For instance, compared to AdamW fine-tuning, we reduce\nExpected Calibration Error by more than 50% compared to the AdamW baseline and\nraise Coverage by 4% vs. SOTA (for a fixed risk of 1%). In the presence of\ndistribution shifts, the performance gain is even higher, achieving 8% Coverage\n(@ 1% risk) improvement vs. SOTA when 50% of test cases are OOD. Overall, we\npresent variational learning as a viable option to enhance the reliability of\nmultimodal models."}
{"id": "2505.09364", "pdf": "https://arxiv.org/pdf/2505.09364", "abs": "https://arxiv.org/abs/2505.09364", "authors": ["Michael Benigni", "Maurizio Ferrari Dacrema", "Dietmar Jannach"], "title": "Diffusion Recommender Models and the Illusion of Progress: A Concerning Study of Reproducibility and a Conceptual Mismatch", "categories": ["cs.IR", "cs.LG", "cs.NE"], "comment": null, "summary": "Countless new machine learning models are published every year and are\nreported to significantly advance the state-of-the-art in \\emph{top-n}\nrecommendation. However, earlier reproducibility studies indicate that progress\nin this area may be quite limited. Specifically, various widespread\nmethodological issues, e.g., comparisons with untuned baseline models, have led\nto an \\emph{illusion of progress}. In this work, our goal is to examine whether\nthese problems persist in today's research. To this end, we aim to reproduce\nthe latest advancements reported from applying modern Denoising Diffusion\nProbabilistic Models to recommender systems, focusing on four models published\nat the top-ranked SIGIR conference in 2023 and 2024. Our findings are\nconcerning, revealing persistent methodological problems. Alarmingly, through\nexperiments, we find that the latest recommendation techniques based on\ndiffusion models, despite their computational complexity and substantial carbon\nfootprint, are consistently outperformed by simpler existing models.\nFurthermore, we identify key mismatches between the characteristics of\ndiffusion models and those of the traditional \\emph{top-n} recommendation task,\nraising doubts about their suitability for recommendation. We also note that,\nin the papers we analyze, the generative capabilities of these models are\nconstrained to a minimum. Overall, our results and continued methodological\nissues call for greater scientific rigor and a disruptive change in the\nresearch and publication culture in this area."}
{"id": "2505.09595", "pdf": "https://arxiv.org/pdf/2505.09595", "abs": "https://arxiv.org/abs/2505.09595", "authors": ["Abdullah Mushtaq", "Imran Taj", "Rafay Naeem", "Ibrahim Ghaznavi", "Junaid Qadir"], "title": "WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "comment": "Preprint. Submitted to the Journal of Artificial Intelligence\n  Research (JAIR) on April 29, 2025", "summary": "Large Language Models (LLMs) are predominantly trained and aligned in ways\nthat reinforce Western-centric epistemologies and socio-cultural norms, leading\nto cultural homogenization and limiting their ability to reflect global\ncivilizational plurality. Existing benchmarking frameworks fail to adequately\ncapture this bias, as they rely on rigid, closed-form assessments that overlook\nthe complexity of cultural inclusivity. To address this, we introduce\nWorldView-Bench, a benchmark designed to evaluate Global Cultural Inclusivity\n(GCI) in LLMs by analyzing their ability to accommodate diverse worldviews. Our\napproach is grounded in the Multiplex Worldview proposed by Senturk et al.,\nwhich distinguishes between Uniplex models, reinforcing cultural\nhomogenization, and Multiplex models, which integrate diverse perspectives.\nWorldView-Bench measures Cultural Polarization, the exclusion of alternative\nperspectives, through free-form generative evaluation rather than conventional\ncategorical benchmarks. We implement applied multiplexity through two\nintervention strategies: (1) Contextually-Implemented Multiplex LLMs, where\nsystem prompts embed multiplexity principles, and (2) Multi-Agent System\n(MAS)-Implemented Multiplex LLMs, where multiple LLM agents representing\ndistinct cultural perspectives collaboratively generate responses. Our results\ndemonstrate a significant increase in Perspectives Distribution Score (PDS)\nentropy from 13% at baseline to 94% with MAS-Implemented Multiplex LLMs,\nalongside a shift toward positive sentiment (67.7%) and enhanced cultural\nbalance. These findings highlight the potential of multiplex-aware AI\nevaluation in mitigating cultural bias in LLMs, paving the way for more\ninclusive and ethically aligned AI systems."}
{"id": "2505.09365", "pdf": "https://arxiv.org/pdf/2505.09365", "abs": "https://arxiv.org/abs/2505.09365", "authors": ["H. T. Rüdisser", "G. Nguyen", "J. Le Louëdec", "C. Möstl"], "title": "ARCANE -- Early Detection of Interplanetary Coronal Mass Ejections", "categories": ["physics.space-ph", "astro-ph.IM", "astro-ph.SR", "cs.LG"], "comment": "25 pages, 9 figures, 1 table, submitted to AGU Space Weather on 14th\n  May 2025", "summary": "Interplanetary coronal mass ejections (ICMEs) are major drivers of space\nweather disturbances, posing risks to both technological infrastructure and\nhuman activities. Automatic detection of ICMEs in solar wind in situ data is\nessential for early warning systems. While several methods have been proposed\nto identify these structures in time series data, robust real-time detection\nremains a significant challenge. In this work, we present ARCANE - the first\nframework explicitly designed for early ICME detection in streaming solar wind\ndata under realistic operational constraints, enabling event identification\nwithout requiring observation of the full structure. Our approach evaluates the\nstrengths and limitations of detection models by comparing a machine\nlearning-based method to a threshold-based baseline. The ResUNet++ model,\npreviously validated on science data, significantly outperforms the baseline,\nparticularly in detecting high-impact events, while retaining solid performance\non lower-impact cases. Notably, we find that using real-time solar wind (RTSW)\ndata instead of high-resolution science data leads to only minimal performance\ndegradation. Despite the challenges of operational settings, our detection\npipeline achieves an F1 score of 0.53, with an average detection delay of 21.5%\nof the event's duration while only seeing a minimal amount of data. As more\ndata becomes available, the performance increases significantly. These results\nmark a substantial step forward in automated space weather monitoring and lay\nthe groundwork for enhanced real-time forecasting capabilities."}
{"id": "2505.09598", "pdf": "https://arxiv.org/pdf/2505.09598", "abs": "https://arxiv.org/abs/2505.09598", "authors": ["Nidhal Jegham", "Marwen Abdelatti", "Lassad Elmoubarki", "Abdeltawab Hendawi"], "title": "How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) spread across industries, understanding their\nenvironmental footprint at the inference level is no longer optional; it is\nessential. However, most existing studies exclude proprietary models, overlook\ninfrastructural variability and overhead, or focus solely on training, even as\ninference increasingly dominates AI's environmental impact. To bridge this gap,\nthis paper introduces a novel infrastructure-aware benchmarking framework for\nquantifying the environmental footprint of LLM inference across 30\nstate-of-the-art models as deployed in commercial data centers. Our framework\ncombines public API performance data with region-specific environmental\nmultipliers and statistical inference of hardware configurations. We\nadditionally utilize cross-efficiency Data Envelopment Analysis (DEA) to rank\nmodels by performance relative to environmental cost. Our results show that o3\nand DeepSeek-R1 emerge as the most energy-intensive models, consuming over 33\nWh per long prompt, more than 70 times the consumption of GPT-4.1 nano, and\nthat Claude-3.7 Sonnet ranks highest in eco-efficiency. While a single short\nGPT-4o query consumes 0.43 Wh, scaling this to 700 million queries/day results\nin substantial annual environmental impacts. These include electricity use\ncomparable to 35,000 U.S. homes, freshwater evaporation matching the annual\ndrinking needs of 1.2 million people, and carbon emissions requiring a\nChicago-sized forest to offset. These findings illustrate a growing paradox:\nalthough individual queries are efficient, their global scale drives\ndisproportionate resource consumption. Our study provides a standardized,\nempirically grounded methodology for benchmarking the sustainability of LLM\ndeployments, laying a foundation for future environmental accountability in AI\ndevelopment and sustainability standards."}
{"id": "2505.09368", "pdf": "https://arxiv.org/pdf/2505.09368", "abs": "https://arxiv.org/abs/2505.09368", "authors": ["Jenny Schmalfuss", "Victor Oei", "Lukas Mehl", "Madlen Bartsch", "Shashank Agnihotri", "Margret Keuper", "Andrés Bruhn"], "title": "RobustSpring: Benchmarking Robustness to Image Corruptions for Optical Flow, Scene Flow and Stereo", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Standard benchmarks for optical flow, scene flow, and stereo vision\nalgorithms generally focus on model accuracy rather than robustness to image\ncorruptions like noise or rain. Hence, the resilience of models to such\nreal-world perturbations is largely unquantified. To address this, we present\nRobustSpring, a comprehensive dataset and benchmark for evaluating robustness\nto image corruptions for optical flow, scene flow, and stereo models.\nRobustSpring applies 20 different image corruptions, including noise, blur,\ncolor changes, quality degradations, and weather distortions, in a time-,\nstereo-, and depth-consistent manner to the high-resolution Spring dataset,\ncreating a suite of 20,000 corrupted images that reflect challenging\nconditions. RobustSpring enables comparisons of model robustness via a new\ncorruption robustness metric. Integration with the Spring benchmark enables\npublic two-axis evaluations of both accuracy and robustness. We benchmark a\ncurated selection of initial models, observing that accurate models are not\nnecessarily robust and that robustness varies widely by corruption type.\nRobustSpring is a new computer vision benchmark that treats robustness as a\nfirst-class citizen to foster models that combine accuracy with resilience. It\nwill be available at https://spring-benchmark.org."}
{"id": "2505.09610", "pdf": "https://arxiv.org/pdf/2505.09610", "abs": "https://arxiv.org/abs/2505.09610", "authors": ["Nicolas Dupuis", "Ravi Nair", "Shyam Ramji", "Sean McClintock", "Nishant Chauhan", "Priyanka Nagpal", "Bart Blaner", "Ken Valk", "Leon Stok", "Ruchir Puri"], "title": "Customizing a Large Language Model for VHDL Design of High-Performance Microprocessors", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "The use of Large Language Models (LLMs) in hardware design has taken off in\nrecent years, principally through its incorporation in tools that increase chip\ndesigner productivity. There has been considerable discussion about the use of\nLLMs in RTL specifications of chip designs, for which the two most popular\nlanguages are Verilog and VHDL. LLMs and their use in Verilog design has\nreceived significant attention due to the higher popularity of the language,\nbut little attention so far has been given to VHDL despite its continued\npopularity in the industry. There has also been little discussion about the\nunique needs of organizations that engage in high-performance processor design,\nand techniques to deploy AI solutions in these settings. In this paper, we\ndescribe our journey in developing a Large Language Model (LLM) specifically\nfor the purpose of explaining VHDL code, a task that has particular importance\nin an organization with decades of experience and assets in high-performance\nprocessor design. We show how we developed test sets specific to our needs and\nused them for evaluating models as we performed extended pretraining (EPT) of a\nbase LLM. Expert evaluation of the code explanations produced by the EPT model\nincreased to 69% compared to a base model rating of 43%. We further show how we\ndeveloped an LLM-as-a-judge to gauge models similar to expert evaluators. This\nled us to deriving and evaluating a host of new models, including an\ninstruction-tuned version of the EPT model with an expected expert evaluator\nrating of 71%. Our experiments also indicate that with the potential use of\nnewer base models, this rating can be pushed to 85% and beyond. We conclude\nwith a discussion on further improving the quality of hardware design LLMs\nusing exciting new developments in the Generative AI world."}
{"id": "2505.09371", "pdf": "https://arxiv.org/pdf/2505.09371", "abs": "https://arxiv.org/abs/2505.09371", "authors": ["Akash Kundu", "Stefano Mangini"], "title": "TensorRL-QAS: Reinforcement learning with tensor networks for scalable quantum architecture search", "categories": ["quant-ph", "cs.AI", "cs.ET", "cs.LG"], "comment": "The code will be available soon! Comments are welcomed!", "summary": "Variational quantum algorithms hold the promise to address meaningful quantum\nproblems already on noisy intermediate-scale quantum hardware, but they face\nthe challenge of designing quantum circuits that both solve the target problem\nand comply with device limitations. Quantum architecture search (QAS) automates\nthis design process, with reinforcement learning (RL) emerging as a promising\napproach. Yet, RL-based QAS methods encounter significant scalability issues,\nas computational and training costs grow rapidly with the number of qubits,\ncircuit depth, and noise, severely impacting performance. To address these\nchallenges, we introduce $\\textit{TensorRL-QAS}$, a scalable framework that\ncombines tensor network (TN) methods with RL for designing quantum circuits. By\nwarm-starting the architecture search with a matrix product state approximation\nof the target solution, TensorRL-QAS effectively narrows the search space to\nphysically meaningful circuits, accelerating convergence to the desired\nsolution. Tested on several quantum chemistry problems of up to 12-qubit,\nTensorRL-QAS achieves up to a 10-fold reduction in CNOT count and circuit depth\ncompared to baseline methods, while maintaining or surpassing chemical\naccuracy. It reduces function evaluations by up to 100-fold, accelerates\ntraining episodes by up to $98\\%$, and achieves up to $50\\%$ success\nprobability for 10-qubit systems-far exceeding the $<1\\%$ rates of baseline\napproaches. Robustness and versatility are demonstrated both in the noiseless\nand noisy scenarios, where we report a simulation of up to 8-qubit. These\nadvancements establish TensorRL-QAS as a promising candidate for a scalable and\nefficient quantum circuit discovery protocol on near-term quantum hardware."}
{"id": "2505.09380", "pdf": "https://arxiv.org/pdf/2505.09380", "abs": "https://arxiv.org/abs/2505.09380", "authors": ["Qinghui Liu", "Jon Nesvold", "Hanna Raaum", "Elakkyen Murugesu", "Martin Røvang", "Bradley J Maclntosh", "Atle Bjørnerud", "Karoline Skogen"], "title": "Examining Deployment and Refinement of the VIOLA-AI Intracranial Hemorrhage Model Using an Interactive NeoMedSys Platform", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "19 pages, 11 figures, on submission to BMC Methods", "summary": "Background: There are many challenges and opportunities in the clinical\ndeployment of AI tools in radiology. The current study describes a radiology\nsoftware platform called NeoMedSys that can enable efficient deployment and\nrefinements of AI models. We evaluated the feasibility and effectiveness of\nrunning NeoMedSys for three months in real-world clinical settings and focused\non improvement performance of an in-house developed AI model (VIOLA-AI)\ndesigned for intracranial hemorrhage (ICH) detection.\n  Methods: NeoMedSys integrates tools for deploying, testing, and optimizing AI\nmodels with a web-based medical image viewer, annotation system, and\nhospital-wide radiology information systems. A pragmatic investigation was\ndeployed using clinical cases of patients presenting to the largest Emergency\nDepartment in Norway (site-1) with suspected traumatic brain injury (TBI) or\npatients with suspected stroke (site-2). We assessed ICH classification\nperformance as VIOLA-AI encountered new data and underwent pre-planned model\nretraining. Performance metrics included sensitivity, specificity, accuracy,\nand the area under the receiver operating characteristic curve (AUC).\n  Results: NeoMedSys facilitated iterative improvements in the AI model,\nsignificantly enhancing its diagnostic accuracy. Automated bleed detection and\nsegmentation were reviewed in near real-time to facilitate re-training\nVIOLA-AI. The iterative refinement process yielded a marked improvement in\nclassification sensitivity, rising to 90.3% (from 79.2%), and specificity that\nreached 89.3% (from 80.7%). The bleed detection ROC analysis for the entire\nsample demonstrated a high area-under-the-curve (AUC) of 0.949 (from 0.873).\nModel refinement stages were associated with notable gains, highlighting the\nvalue of real-time radiologist feedback."}
{"id": "2505.09395", "pdf": "https://arxiv.org/pdf/2505.09395", "abs": "https://arxiv.org/abs/2505.09395", "authors": ["Chen-Yu Liu", "Kuan-Cheng Chen", "Yi-Chien Chen", "Samuel Yen-Chi Chen", "Wei-Hao Huang", "Wei-Jia Huang", "Yen-Jui Chang"], "title": "Quantum-Enhanced Parameter-Efficient Learning for Typhoon Trajectory Forecasting", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Typhoon trajectory forecasting is essential for disaster preparedness but\nremains computationally demanding due to the complexity of atmospheric dynamics\nand the resource requirements of deep learning models. Quantum-Train (QT), a\nhybrid quantum-classical framework that leverages quantum neural networks\n(QNNs) to generate trainable parameters exclusively during training,\neliminating the need for quantum hardware at inference time. Building on QT's\nsuccess across multiple domains, including image classification, reinforcement\nlearning, flood prediction, and large language model (LLM) fine-tuning, we\nintroduce Quantum Parameter Adaptation (QPA) for efficient typhoon forecasting\nmodel learning. Integrated with an Attention-based Multi-ConvGRU model, QPA\nenables parameter-efficient training while maintaining predictive accuracy.\nThis work represents the first application of quantum machine learning (QML) to\nlarge-scale typhoon trajectory prediction, offering a scalable and\nenergy-efficient approach to climate modeling. Our results demonstrate that QPA\nsignificantly reduces the number of trainable parameters while preserving\nperformance, making high-performance forecasting more accessible and\nsustainable through hybrid quantum-classical learning."}
{"id": "2505.09425", "pdf": "https://arxiv.org/pdf/2505.09425", "abs": "https://arxiv.org/abs/2505.09425", "authors": ["Sarah Leyder", "Jakob Raymaekers", "Peter J. Rousseeuw", "Tom Van Deuren", "Tim Verdonck"], "title": "Independent Component Analysis by Robust Distance Correlation", "categories": ["stat.CO", "cs.LG"], "comment": null, "summary": "Independent component analysis (ICA) is a powerful tool for decomposing a\nmultivariate signal or distribution into fully independent sources, not just\nuncorrelated ones. Unfortunately, most approaches to ICA are not robust against\noutliers. Here we propose a robust ICA method called RICA, which estimates the\ncomponents by minimizing a robust measure of dependence between multivariate\nrandom variables. The dependence measure used is the distance correlation\n(dCor). In order to make it more robust we first apply a new transformation\ncalled the bowl transform, which is bounded, one-to-one, continuous, and maps\nfar outliers to points close to the origin. This preserves the crucial property\nthat a zero dCor implies independence. RICA estimates the independent sources\nsequentially, by looking for the component that has the smallest dCor with the\nremainder. RICA is strongly consistent and has the usual parametric rate of\nconvergence. Its robustness is investigated by a simulation study, in which it\ngenerally outperforms its competitors. The method is illustrated on three\napplications, including the well-known cocktail party problem."}
{"id": "2505.09430", "pdf": "https://arxiv.org/pdf/2505.09430", "abs": "https://arxiv.org/abs/2505.09430", "authors": ["Yutong Hu", "Pinhao Song", "Kehan Wen", "Renaud Detry"], "title": "Train a Multi-Task Diffusion Policy on RLBench-18 in One Day with One GPU", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "We present a method for training multi-task vision-language robotic diffusion\npolicies that reduces training time and memory usage by an order of magnitude.\nThis improvement arises from a previously underexplored distinction between\naction diffusion and the image diffusion techniques that inspired it: image\ngeneration targets are high-dimensional, while robot actions lie in a much\nlower-dimensional space. Meanwhile, the vision-language conditions for action\ngeneration remain high-dimensional. Our approach, Mini-Diffuser, exploits this\nasymmetry by introducing Level-2 minibatching, which pairs multiple noised\naction samples with each vision-language condition, instead of the conventional\none-to-one sampling strategy. To support this batching scheme, we introduce\narchitectural adaptations to the diffusion transformer that prevent information\nleakage across samples while maintaining full conditioning access. In RLBench\nsimulations, Mini-Diffuser achieves 95\\% of the performance of state-of-the-art\nmulti-task diffusion policies, while using only 5\\% of the training time and\n7\\% of the memory. Real-world experiments further validate that Mini-Diffuser\npreserves the key strengths of diffusion-based policies, including the ability\nto model multimodal action distributions and produce behavior conditioned on\ndiverse perceptual inputs. Code available at\ngithub.com/utomm/mini-diffuse-actor."}
{"id": "2505.09456", "pdf": "https://arxiv.org/pdf/2505.09456", "abs": "https://arxiv.org/abs/2505.09456", "authors": ["Josep Lumbreras", "Ruo Cheng Huang", "Yanglin Hu", "Mile Gu", "Marco Tomamichel"], "title": "Quantum state-agnostic work extraction (almost) without dissipation", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "5 pages+14 pages, 2 figures", "summary": "We investigate work extraction protocols designed to transfer the maximum\npossible energy to a battery using sequential access to $N$ copies of an\nunknown pure qubit state. The core challenge is designing interactions to\noptimally balance two competing goals: charging of the battery optimally using\nthe qubit in hand, and acquiring more information by qubit to improve energy\nharvesting in subsequent rounds. Here, we leverage exploration-exploitation\ntrade-off in reinforcement learning to develop adaptive strategies achieving\nenergy dissipation that scales only poly-logarithmically in $N$. This\nrepresents an exponential improvement over current protocols based on full\nstate tomography."}
{"id": "2505.09471", "pdf": "https://arxiv.org/pdf/2505.09471", "abs": "https://arxiv.org/abs/2505.09471", "authors": ["Xiaoyu Hu", "Gengyu Xue", "Zhenhua Lin", "Yi Yu"], "title": "Fairness-aware Bayes optimal functional classification", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": null, "summary": "Algorithmic fairness has become a central topic in machine learning, and\nmitigating disparities across different subpopulations has emerged as a rapidly\ngrowing research area. In this paper, we systematically study the\nclassification of functional data under fairness constraints, ensuring the\ndisparity level of the classifier is controlled below a pre-specified\nthreshold. We propose a unified framework for fairness-aware functional\nclassification, tackling an infinite-dimensional functional space, addressing\nkey challenges from the absence of density ratios and intractability of\nposterior probabilities, and discussing unique phenomena in functional\nclassification. We further design a post-processing algorithm, Fair Functional\nLinear Discriminant Analysis classifier (Fair-FLDA), which targets at\nhomoscedastic Gaussian processes and achieves fairness via group-wise\nthresholding. Under weak structural assumptions on eigenspace, theoretical\nguarantees on fairness and excess risk controls are established. As a\nbyproduct, our results cover the excess risk control of the standard FLDA as a\nspecial case, which, to the best of our knowledge, is first time seen. Our\ntheoretical findings are complemented by extensive numerical experiments on\nsynthetic and real datasets, highlighting the practicality of our designed\nalgorithm."}
{"id": "2505.09496", "pdf": "https://arxiv.org/pdf/2505.09496", "abs": "https://arxiv.org/abs/2505.09496", "authors": ["Rui Miao", "Babak Shahbaba", "Annie Qu"], "title": "Reinforcement Learning for Individual Optimal Policy from Heterogeneous Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) aims to find optimal policies in dynamic\nenvironments in order to maximize the expected total rewards by leveraging\npre-collected data. Learning from heterogeneous data is one of the fundamental\nchallenges in offline RL. Traditional methods focus on learning an optimal\npolicy for all individuals with pre-collected data from a single episode or\nhomogeneous batch episodes, and thus, may result in a suboptimal policy for a\nheterogeneous population. In this paper, we propose an individualized offline\npolicy optimization framework for heterogeneous time-stationary Markov decision\nprocesses (MDPs). The proposed heterogeneous model with individual latent\nvariables enables us to efficiently estimate the individual Q-functions, and\nour Penalized Pessimistic Personalized Policy Learning (P4L) algorithm\nguarantees a fast rate on the average regret under a weak partial coverage\nassumption on behavior policies. In addition, our simulation studies and a real\ndata application demonstrate the superior numerical performance of the proposed\nmethod compared with existing methods."}
{"id": "2505.09506", "pdf": "https://arxiv.org/pdf/2505.09506", "abs": "https://arxiv.org/abs/2505.09506", "authors": ["María Alejandra Hernández", "Oscar Rodriguez", "Dae-Jin Lee"], "title": "Deep-SITAR: A SITAR-Based Deep Learning Framework for Growth Curve Modeling via Autoencoders", "categories": ["stat.ML", "cs.LG", "F.2.2; I.2.7"], "comment": "Pre-print", "summary": "Several approaches have been developed to capture the complexity and\nnonlinearity of human growth. One widely used is the Super Imposition by\nTranslation and Rotation (SITAR) model, which has become popular in studies of\nadolescent growth. SITAR is a shape-invariant mixed-effects model that\nrepresents the shared growth pattern of a population using a natural cubic\nspline mean curve while incorporating three subject-specific random effects --\ntiming, size, and growth intensity -- to account for variations among\nindividuals. In this work, we introduce a supervised deep learning framework\nbased on an autoencoder architecture that integrates a deep neural network\n(neural network) with a B-spline model to estimate the SITAR model. In this\napproach, the encoder estimates the random effects for each individual, while\nthe decoder performs a fitting based on B-splines similar to the classic SITAR\nmodel. We refer to this method as the Deep-SITAR model. This innovative\napproach enables the prediction of the random effects of new individuals\nentering a population without requiring a full model re-estimation. As a\nresult, Deep-SITAR offers a powerful approach to predicting growth\ntrajectories, combining the flexibility and efficiency of deep learning with\nthe interpretability of traditional mixed-effects models."}
{"id": "2505.09516", "pdf": "https://arxiv.org/pdf/2505.09516", "abs": "https://arxiv.org/abs/2505.09516", "authors": ["Siyi Wang", "Alexandre Leblanc", "Paul D. McNicholas"], "title": "Depth-Based Local Center Clustering: A Framework for Handling Different Clustering Scenarios", "categories": ["stat.ME", "cs.LG", "stat.AP"], "comment": null, "summary": "Cluster analysis, or clustering, plays a crucial role across numerous\nscientific and engineering domains. Despite the wealth of clustering methods\nproposed over the past decades, each method is typically designed for specific\nscenarios and presents certain limitations in practical applications. In this\npaper, we propose depth-based local center clustering (DLCC). This novel method\nmakes use of data depth, which is known to produce a center-outward ordering of\nsample points in a multivariate space. However, data depth typically fails to\ncapture the multimodal characteristics of {data}, something of the utmost\nimportance in the context of clustering. To overcome this, DLCC makes use of a\nlocal version of data depth that is based on subsets of {data}. From this,\nlocal centers can be identified as well as clusters of varying shapes.\nFurthermore, we propose a new internal metric based on density-based clustering\nto evaluate clustering performance on {non-convex clusters}. Overall, DLCC is a\nflexible clustering approach that seems to overcome some limitations of\ntraditional clustering methods, thereby enhancing data analysis capabilities\nacross a wide range of application scenarios."}
{"id": "2505.09518", "pdf": "https://arxiv.org/pdf/2505.09518", "abs": "https://arxiv.org/abs/2505.09518", "authors": ["Maris F. L. Galesloot", "Roman Andriushchenko", "Milan Češka", "Sebastian Junges", "Nils Jansen"], "title": "\\textsc{rfPG}: Robust Finite-Memory Policy Gradients for Hidden-Model POMDPs", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted for publication at IJCAI 2025", "summary": "Partially observable Markov decision processes (POMDPs) model specific\nenvironments in sequential decision-making under uncertainty. Critically,\noptimal policies for POMDPs may not be robust against perturbations in the\nenvironment. Hidden-model POMDPs (HM-POMDPs) capture sets of different\nenvironment models, that is, POMDPs with a shared action and observation space.\nThe intuition is that the true model is hidden among a set of potential models,\nand it is unknown which model will be the environment at execution time. A\npolicy is robust for a given HM-POMDP if it achieves sufficient performance for\neach of its POMDPs. We compute such robust policies by combining two orthogonal\ntechniques: (1) a deductive formal verification technique that supports\ntractable robust policy evaluation by computing a worst-case POMDP within the\nHM-POMDP and (2) subgradient ascent to optimize the candidate policy for a\nworst-case POMDP. The empirical evaluation shows that, compared to various\nbaselines, our approach (1) produces policies that are more robust and\ngeneralize better to unseen POMDPs and (2) scales to HM-POMDPs that consist of\nover a hundred thousand environments."}
{"id": "2505.09529", "pdf": "https://arxiv.org/pdf/2505.09529", "abs": "https://arxiv.org/abs/2505.09529", "authors": ["Mohamed Moustafa", "Joseph Lemley", "Peter Corcoran"], "title": "Contactless Cardiac Pulse Monitoring Using Event Cameras", "categories": ["cs.CV", "cs.ET", "cs.LG", "eess.IV"], "comment": "This paper is a preprint of a paper submitted to IEEE Access and is\n  currently under review", "summary": "Time event cameras are a novel technology for recording scene information at\nextremely low latency and with low power consumption. Event cameras output a\nstream of events that encapsulate pixel-level light intensity changes within\nthe scene, capturing information with a higher dynamic range and temporal\nresolution than traditional cameras. This study investigates the contact-free\nreconstruction of an individual's cardiac pulse signal from time event\nrecording of their face using a supervised convolutional neural network (CNN)\nmodel. An end-to-end model is trained to extract the cardiac signal from a\ntwo-dimensional representation of the event stream, with model performance\nevaluated based on the accuracy of the calculated heart rate. The experimental\nresults confirm that physiological cardiac information in the facial region is\neffectively preserved within the event stream, showcasing the potential of this\nnovel sensor for remote heart rate monitoring. The model trained on event\nframes achieves a root mean square error (RMSE) of 3.32 beats per minute (bpm)\ncompared to the RMSE of 2.92 bpm achieved by the baseline model trained on\nstandard camera frames. Furthermore, models trained on event frames generated\nat 60 and 120 FPS outperformed the 30 FPS standard camera results, achieving an\nRMSE of 2.54 and 2.13 bpm, respectively."}
{"id": "2505.09546", "pdf": "https://arxiv.org/pdf/2505.09546", "abs": "https://arxiv.org/abs/2505.09546", "authors": ["Yujin Kim", "Nathaniel Chin", "Arnav Vasudev", "Sanjiban Choudhury"], "title": "Distilling Realizable Students from Unrealizable Teachers", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "We study policy distillation under privileged information, where a student\npolicy with only partial observations must learn from a teacher with full-state\naccess. A key challenge is information asymmetry: the student cannot directly\naccess the teacher's state space, leading to distributional shifts and policy\ndegradation. Existing approaches either modify the teacher to produce\nrealizable but sub-optimal demonstrations or rely on the student to explore\nmissing information independently, both of which are inefficient. Our key\ninsight is that the student should strategically interact with the teacher\n--querying only when necessary and resetting from recovery states --to stay on\na recoverable path within its own observation space. We introduce two methods:\n(i) an imitation learning approach that adaptively determines when the student\nshould query the teacher for corrections, and (ii) a reinforcement learning\napproach that selects where to initialize training for efficient exploration.\nWe validate our methods in both simulated and real-world robotic tasks,\ndemonstrating significant improvements over standard teacher-student baselines\nin training efficiency and final performance. The project website is available\nat : https://portal-cornell.github.io/CritiQ_ReTRy/"}
{"id": "2505.09552", "pdf": "https://arxiv.org/pdf/2505.09552", "abs": "https://arxiv.org/abs/2505.09552", "authors": ["Pascal Kündig", "Fabio Sigrist"], "title": "Scalable Computations for Generalized Mixed Effects Models with Crossed Random Effects Using Krylov Subspace Methods", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "Mixed effects models are widely used for modeling data with hierarchically\ngrouped structures and high-cardinality categorical predictor variables.\nHowever, for high-dimensional crossed random effects, current standard\ncomputations relying on Cholesky decompositions can become prohibitively slow.\nIn this work, we present novel Krylov subspace-based methods that address\nseveral existing computational bottlenecks. Among other things, we\ntheoretically analyze and empirically evaluate various preconditioners for the\nconjugate gradient and stochastic Lanczos quadrature methods, derive new\nconvergence results, and develop computationally efficient methods for\ncalculating predictive variances. Extensive experiments using simulated and\nreal-world data sets show that our proposed methods scale much better than\nCholesky-based computations, for instance, achieving a runtime reduction of\napproximately two orders of magnitudes for both estimation and prediction.\nMoreover, our software implementation is up to 10'000 times faster and more\nstable than state-of-the-art implementations such as lme4 and glmmTMB when\nusing default settings. Our methods are implemented in the free C++ software\nlibrary GPBoost with high-level Python and R packages."}
{"id": "2505.09558", "pdf": "https://arxiv.org/pdf/2505.09558", "abs": "https://arxiv.org/abs/2505.09558", "authors": ["Shengpeng Ji", "Tianle Liang", "Yangzhuo Li", "Jialong Zuo", "Minghui Fang", "Jinzheng He", "Yifu Chen", "Zhengqing Liu", "Ziyue Jiang", "Xize Cheng", "Siqi Zheng", "Jin Xu", "Junyang Lin", "Zhou Zhao"], "title": "WavReward: Spoken Dialogue Models With Generalist Reward Evaluators", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.MM", "cs.SD"], "comment": null, "summary": "End-to-end spoken dialogue models such as GPT-4o-audio have recently garnered\nsignificant attention in the speech domain. However, the evaluation of spoken\ndialogue models' conversational performance has largely been overlooked. This\nis primarily due to the intelligent chatbots convey a wealth of non-textual\ninformation which cannot be easily measured using text-based language models\nlike ChatGPT. To address this gap, we propose WavReward, a reward feedback\nmodel based on audio language models that can evaluate both the IQ and EQ of\nspoken dialogue systems with speech input. Specifically, 1) based on audio\nlanguage models, WavReward incorporates the deep reasoning process and the\nnonlinear reward mechanism for post-training. By utilizing multi-sample\nfeedback via the reinforcement learning algorithm, we construct a specialized\nevaluator tailored to spoken dialogue models. 2) We introduce ChatReward-30K, a\npreference dataset used to train WavReward. ChatReward-30K includes both\ncomprehension and generation aspects of spoken dialogue models. These scenarios\nspan various tasks, such as text-based chats, nine acoustic attributes of\ninstruction chats, and implicit chats. WavReward outperforms previous\nstate-of-the-art evaluation models across multiple spoken dialogue scenarios,\nachieving a substantial improvement about Qwen2.5-Omni in objective accuracy\nfrom 55.1$\\%$ to 91.5$\\%$. In subjective A/B testing, WavReward also leads by a\nmargin of 83$\\%$. Comprehensive ablation studies confirm the necessity of each\ncomponent of WavReward. All data and code will be publicly at\nhttps://github.com/jishengpeng/WavReward after the paper is accepted."}
{"id": "2505.09561", "pdf": "https://arxiv.org/pdf/2505.09561", "abs": "https://arxiv.org/abs/2505.09561", "authors": ["Marcel Torne", "Andy Tang", "Yuejiang Liu", "Chelsea Finn"], "title": "Learning Long-Context Diffusion Policies via Past-Token Prediction", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Videos are available at https://long-context-dp.github.io", "summary": "Reasoning over long sequences of observations and actions is essential for\nmany robotic tasks. Yet, learning effective long-context policies from\ndemonstrations remains challenging. As context length increases, training\nbecomes increasingly expensive due to rising memory demands, and policy\nperformance often degrades as a result of spurious correlations. Recent methods\ntypically sidestep these issues by truncating context length, discarding\nhistorical information that may be critical for subsequent decisions. In this\npaper, we propose an alternative approach that explicitly regularizes the\nretention of past information. We first revisit the copycat problem in\nimitation learning and identify an opposite challenge in recent diffusion\npolicies: rather than over-relying on prior actions, they often fail to capture\nessential dependencies between past and future actions. To address this, we\nintroduce Past-Token Prediction (PTP), an auxiliary task in which the policy\nlearns to predict past action tokens alongside future ones. This regularization\nsignificantly improves temporal modeling in the policy head, with minimal\nreliance on visual representations. Building on this observation, we further\nintroduce a multistage training strategy: pre-train the visual encoder with\nshort contexts, and fine-tune the policy head using cached long-context\nembeddings. This strategy preserves the benefits of PTP while greatly reducing\nmemory and computational overhead. Finally, we extend PTP into a\nself-verification mechanism at test time, enabling the policy to score and\nselect candidates consistent with past actions during inference. Experiments\nacross four real-world and six simulated tasks demonstrate that our proposed\nmethod improves the performance of long-context diffusion policies by 3x and\naccelerates policy training by more than 10x."}
{"id": "2505.09603", "pdf": "https://arxiv.org/pdf/2505.09603", "abs": "https://arxiv.org/abs/2505.09603", "authors": ["Shivin Dass", "Alaa Khaddaj", "Logan Engstrom", "Aleksander Madry", "Andrew Ilyas", "Roberto Martín-Martín"], "title": "DataMIL: Selecting Data for Robot Imitation Learning with Datamodels", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Recently, the robotics community has amassed ever larger and more diverse\ndatasets to train generalist robot policies. However, while these policies\nachieve strong mean performance across a variety of tasks, they often\nunderperform on individual, specialized tasks and require further tuning on\nnewly acquired task-specific data. Combining task-specific data with carefully\ncurated subsets of large prior datasets via co-training can produce better\nspecialized policies, but selecting data naively may actually harm downstream\nperformance. To address this, we introduce DataMIL, a policy-driven data\nselection framework built on the datamodels paradigm that reasons about data\nselection in an end-to-end manner, using the policy itself to identify which\ndata points will most improve performance. Unlike standard practices that\nfilter data using human notions of quality (e.g., based on semantic or visual\nsimilarity), DataMIL directly optimizes data selection for task success,\nallowing us to select data that enhance the policy while dropping data that\ndegrade it. To avoid performing expensive rollouts in the environment during\nselection, we use a novel surrogate loss function on task-specific data,\nallowing us to use DataMIL in the real world without degrading performance. We\nvalidate our approach on a suite of more than 60 simulation and real-world\nmanipulation tasks - most notably showing successful data selection from the\nOpen X-Embodiment datasets-demonstrating consistent gains in success rates and\nsuperior performance over multiple baselines. Our results underscore the\nimportance of end-to-end, performance-aware data selection for unlocking the\npotential of large prior datasets in robotics. More information at\nhttps://robin-lab.cs.utexas.edu/datamodels4imitation/"}
{"id": "2505.09612", "pdf": "https://arxiv.org/pdf/2505.09612", "abs": "https://arxiv.org/abs/2505.09612", "authors": ["Tathagata Sadhukhan", "Manit Paul", "Raaz Dwivedi"], "title": "Adaptively-weighted Nearest Neighbors for Matrix Completion", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": "25 pages, 6 figures", "summary": "In this technical note, we introduce and analyze AWNN: an adaptively weighted\nnearest neighbor method for performing matrix completion. Nearest neighbor (NN)\nmethods are widely used in missing data problems across multiple disciplines\nsuch as in recommender systems and for performing counterfactual inference in\npanel data settings. Prior works have shown that in addition to being very\nintuitive and easy to implement, NN methods enjoy nice theoretical guarantees.\nHowever, the performance of majority of the NN methods rely on the appropriate\nchoice of the radii and the weights assigned to each member in the nearest\nneighbor set and despite several works on nearest neighbor methods in the past\ntwo decades, there does not exist a systematic approach of choosing the radii\nand the weights without relying on methods like cross-validation. AWNN\naddresses this challenge by judiciously balancing the bias variance trade off\ninherent in weighted nearest-neighbor regression. We provide theoretical\nguarantees for the proposed method under minimal assumptions and support the\ntheory via synthetic experiments."}
{"id": "2505.08828", "pdf": "https://arxiv.org/pdf/2505.08828", "abs": "https://arxiv.org/abs/2505.08828", "authors": ["Eduardo Araujo Oliveira", "Madhavi Mohoni", "Sonsoles López-Pernas", "Mohammed Saqr"], "title": "Human-AI Collaboration or Academic Misconduct? Measuring AI Use in Student Writing Through Stylometric Evidence", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "19 pages, 10 figures, 11 tables", "summary": "As human-AI collaboration becomes increasingly prevalent in educational\ncontexts, understanding and measuring the extent and nature of such\ninteractions pose significant challenges. This research investigates the use of\nauthorship verification (AV) techniques not as a punitive measure, but as a\nmeans to quantify AI assistance in academic writing, with a focus on promoting\ntransparency, interpretability, and student development. Building on prior\nwork, we structured our investigation into three stages: dataset selection and\nexpansion, AV method development, and systematic evaluation. Using three\ndatasets - including a public dataset (PAN-14) and two from University of\nMelbourne students from various courses - we expanded the data to include\nLLM-generated texts, totalling 1,889 documents and 540 authorship problems from\n506 students. We developed an adapted Feature Vector Difference AV methodology\nto construct robust academic writing profiles for students, designed to capture\nmeaningful, individual characteristics of their writing. The method's\neffectiveness was evaluated across multiple scenarios, including distinguishing\nbetween student-authored and LLM-generated texts and testing resilience against\nLLMs' attempts to mimic student writing styles. Results demonstrate the\nenhanced AV classifier's ability to identify stylometric discrepancies and\nmeasure human-AI collaboration at word and sentence levels while providing\neducators with a transparent tool to support academic integrity investigations.\nThis work advances AV technology, offering actionable insights into the\ndynamics of academic writing in an AI-driven era."}
{"id": "2505.08891", "pdf": "https://arxiv.org/pdf/2505.08891", "abs": "https://arxiv.org/abs/2505.08891", "authors": ["Daeun Hwang", "Samuel Shields", "Alex Calderwood", "Shi Johnson-Bey", "Michael Mateas", "Noah Wardrip-Fruin", "Edward F. Melcer"], "title": "Clicking some of the silly options: Exploring Player Motivation in Static and Dynamic Educational Interactive Narratives", "categories": ["cs.CL"], "comment": "8 pages, 3 figures, 1 table, 1 appendix. Workshop paper, CHI 2025\n  Augmented Educators and AI", "summary": "Motivation is an important factor underlying successful learning. Previous\nresearch has demonstrated the positive effects that static interactive\nnarrative games can have on motivation. Concurrently, advances in AI have made\ndynamic and adaptive approaches to interactive narrative increasingly\naccessible. However, limited work has explored the impact that dynamic\nnarratives can have on learner motivation. In this paper, we compare two\nversions of Academical, a choice-based educational interactive narrative game\nabout research ethics. One version employs a traditional hand-authored\nbranching plot (i.e., static narrative) while the other dynamically sequences\nplots during play (i.e., dynamic narrative). Results highlight the importance\nof responsive content and a variety of choices for player engagement, while\nalso illustrating the challenge of balancing pedagogical goals with the dynamic\naspects of narrative. We also discuss design implications that arise from these\nfindings. Ultimately, this work provides initial steps to illuminate the\nemerging potential of AI-driven dynamic narrative in educational games."}
{"id": "2505.08996", "pdf": "https://arxiv.org/pdf/2505.08996", "abs": "https://arxiv.org/abs/2505.08996", "authors": ["Adele E Goldberg", "Supantho Rakshit", "Jennifer Hu", "Kyle Mahowald"], "title": "A suite of LMs comprehend puzzle statements as well as humans", "categories": ["cs.CL"], "comment": null, "summary": "Recent claims suggest that large language models (LMs) underperform humans in\ncomprehending minimally complex English statements (Dentella et al., 2024).\nHere, we revisit those findings and argue that human performance was\noverestimated, while LLM abilities were underestimated. Using the same stimuli,\nwe report a preregistered study comparing human responses in two conditions:\none allowed rereading (replicating the original study), and one that restricted\nrereading (a more naturalistic comprehension test). Human accuracy dropped\nsignificantly when rereading was restricted (73%), falling below that of\nFalcon-180B-Chat (76%) and GPT-4 (81%). The newer GPT-o1 model achieves perfect\naccuracy. Results further show that both humans and models are\ndisproportionately challenged by queries involving potentially reciprocal\nactions (e.g., kissing), suggesting shared pragmatic sensitivities rather than\nmodel-specific deficits. Additional analyses using Llama-2-70B log\nprobabilities, a recoding of open-ended model responses, and grammaticality\nratings of other sentences reveal systematic underestimation of model\nperformance. We find that GPT-4o can align with either naive or expert\ngrammaticality judgments, depending on prompt framing. These findings\nunderscore the need for more careful experimental design and coding practices\nin LLM evaluation, and they challenge the assumption that current models are\ninherently weaker than humans at language comprehension."}
{"id": "2505.09005", "pdf": "https://arxiv.org/pdf/2505.09005", "abs": "https://arxiv.org/abs/2505.09005", "authors": ["Nicole Cuneo", "Eleanor Graves", "Supantho Rakshit", "Adele E. Goldberg"], "title": "For GPT-4 as with Humans: Information Structure Predicts Acceptability of Long-Distance Dependencies", "categories": ["cs.CL"], "comment": null, "summary": "It remains debated how well any LM understands natural language or generates\nreliable metalinguistic judgments. Moreover, relatively little work has\ndemonstrated that LMs can represent and respect subtle relationships between\nform and function proposed by linguists. We here focus on a particular such\nrelationship established in recent work: English speakers' judgments about the\ninformation structure of canonical sentences predicts independently collected\nacceptability ratings on corresponding 'long distance dependency' [LDD]\nconstructions, across a wide array of base constructions and multiple types of\nLDDs. To determine whether any LM captures this relationship, we probe GPT-4 on\nthe same tasks used with humans and new extensions.Results reveal reliable\nmetalinguistic skill on the information structure and acceptability tasks,\nreplicating a striking interaction between the two, despite the zero-shot,\nexplicit nature of the tasks, and little to no chance of contamination [Studies\n1a, 1b]. Study 2 manipulates the information structure of base sentences and\nconfirms a causal relationship: increasing the prominence of a constituent in a\ncontext sentence increases the subsequent acceptability ratings on an LDD\nconstruction. The findings suggest a tight relationship between natural and\nGPT-4 generated English, and between information structure and syntax, which\nbegs for further exploration."}
{"id": "2505.08896", "pdf": "https://arxiv.org/pdf/2505.08896", "abs": "https://arxiv.org/abs/2505.08896", "authors": ["Pankaj Kumar", "Aditya Mishra", "Pranamesh Chakraborty", "Subrahmanya Swamy Peruru"], "title": "Deep reinforcement learning-based longitudinal control strategy for automated vehicles at signalised intersections", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "Developing an autonomous vehicle control strategy for signalised\nintersections (SI) is one of the challenging tasks due to its inherently\ncomplex decision-making process. This study proposes a Deep Reinforcement\nLearning (DRL) based longitudinal vehicle control strategy at SI. A\ncomprehensive reward function has been formulated with a particular focus on\n(i) distance headway-based efficiency reward, (ii) decision-making criteria\nduring amber light, and (iii) asymmetric acceleration/ deceleration response,\nalong with the traditional safety and comfort criteria. This reward function\nhas been incorporated with two popular DRL algorithms, Deep Deterministic\nPolicy Gradient (DDPG) and Soft-Actor Critic (SAC), which can handle the\ncontinuous action space of acceleration/deceleration. The proposed models have\nbeen trained on the combination of real-world leader vehicle (LV) trajectories\nand simulated trajectories generated using the Ornstein-Uhlenbeck (OU) process.\nThe overall performance of the proposed models has been tested using Cumulative\nDistribution Function (CDF) plots and compared with the real-world trajectory\ndata. The results show that the RL models successfully maintain lower distance\nheadway (i.e., higher efficiency) and jerk compared to human-driven vehicles\nwithout compromising safety. Further, to assess the robustness of the proposed\nmodels, we evaluated the model performance on diverse safety-critical\nscenarios, in terms of car-following and traffic signal compliance. Both DDPG\nand SAC models successfully handled the critical scenarios, while the DDPG\nmodel showed smoother action profiles compared to the SAC model. Overall, the\nresults confirm that DRL-based longitudinal vehicle control strategy at SI can\nhelp to improve traffic safety, efficiency, and comfort."}
{"id": "2505.08800", "pdf": "https://arxiv.org/pdf/2505.08800", "abs": "https://arxiv.org/abs/2505.08800", "authors": ["Olivia Nocentini", "Marta Lagomarsino", "Gokhan Solak", "Younggeol Cho", "Qiyi Tong", "Marta Lorenzini", "Arash Ajoudani"], "title": "Graph-based Online Monitoring of Train Driver States via Facial and Skeletal Features", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Driver fatigue poses a significant challenge to railway safety, with\ntraditional systems like the dead-man switch offering limited and basic\nalertness checks. This study presents an online behavior-based monitoring\nsystem utilizing a customised Directed-Graph Neural Network (DGNN) to classify\ntrain driver's states into three categories: alert, not alert, and\npathological. To optimize input representations for the model, an ablation\nstudy was performed, comparing three feature configurations: skeletal-only,\nfacial-only, and a combination of both. Experimental results show that\ncombining facial and skeletal features yields the highest accuracy (80.88%) in\nthe three-class model, outperforming models using only facial or skeletal\nfeatures. Furthermore, this combination achieves over 99% accuracy in the\nbinary alertness classification. Additionally, we introduced a novel dataset\nthat, for the first time, incorporates simulated pathological conditions into\ntrain driver monitoring, broadening the scope for assessing risks related to\nfatigue and health. This work represents a step forward in enhancing railway\nsafety through advanced online monitoring using vision-based technologies."}
{"id": "2505.08792", "pdf": "https://arxiv.org/pdf/2505.08792", "abs": "https://arxiv.org/abs/2505.08792", "authors": ["Michelle Nashla Turcios", "Alicia E. Boyd", "Angela D. R. Smith", "Brittany Johnson"], "title": "A Preliminary Framework for Intersectionality in ML Pipelines", "categories": ["cs.LG", "cs.CY"], "comment": "Accepted for the 1st International Intersectionality and Software\n  Engineering Workshop, colocated with FSE 2025", "summary": "Machine learning (ML) has become a go-to solution for improving how we use,\nexperience, and interact with technology (and the world around us).\nUnfortunately, studies have repeatedly shown that machine learning technologies\nmay not provide adequate support for societal identities and experiences.\nIntersectionality is a sociological framework that provides a mechanism for\nexplicitly considering complex social identities, focusing on social justice\nand power. While the framework of intersectionality can support the development\nof technologies that acknowledge and support all members of society, it has\nbeen adopted and adapted in ways that are not always true to its foundations,\nthereby weakening its potential for impact. To support the appropriate adoption\nand use of intersectionality for more equitable technological outcomes, we\namplify the foundational intersectionality scholarship--Crenshaw, Combahee, and\nCollins (three C's), to create a socially relevant preliminary framework in\ndeveloping machine-learning solutions. We use this framework to evaluate and\nreport on the (mis)alignments of intersectionality application in machine\nlearning literature."}
{"id": "2505.09039", "pdf": "https://arxiv.org/pdf/2505.09039", "abs": "https://arxiv.org/abs/2505.09039", "authors": ["Jingfeng Chen", "Raghuveer Thirukovalluru", "Junlin Wang", "Kaiwei Luo", "Bhuwan Dhingra"], "title": "Atomic Consistency Preference Optimization for Long-Form Question Answering", "categories": ["cs.CL"], "comment": "16 pages, 2 figures", "summary": "Large Language Models (LLMs) frequently produce factoid hallucinations -\nplausible yet incorrect answers. A common mitigation strategy is model\nalignment, which improves factual accuracy by training on curated factual and\nnon-factual pairs. However, this approach often relies on a stronger model\n(e.g., GPT-4) or an external knowledge base to assess factual correctness,\nwhich may not always be accessible. To address this, we propose Atomic\nConsistency Preference Optimization (ACPO), a self-supervised preference-tuning\nmethod that enhances factual accuracy without external supervision. ACPO\nleverages atomic consistency signals, i.e., the agreement of individual facts\nacross multiple stochastic responses, to identify high- and low-quality data\npairs for model alignment. By eliminating the need for costly GPT calls, ACPO\nprovides a scalable and efficient approach to improving factoid\nquestion-answering. Despite being self-supervised, empirical results\ndemonstrate that ACPO outperforms FactAlign, a strong supervised alignment\nbaseline, by 1.95 points on the LongFact and BioGen datasets, highlighting its\neffectiveness in enhancing factual reliability without relying on external\nmodels or knowledge bases."}
{"id": "2505.08905", "pdf": "https://arxiv.org/pdf/2505.08905", "abs": "https://arxiv.org/abs/2505.08905", "authors": ["Michael Majurski", "Cynthia Matuszek"], "title": "Grounding Synthetic Data Evaluations of Language Models in Unsupervised Document Corpora", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Language Models (LMs) continue to advance, improving response quality and\ncoherence. Given Internet-scale training datasets, LMs have likely encountered\nmuch of what users might ask them to generate in some form during their\ntraining. A plethora of evaluation benchmarks have been constructed to assess\nmodel quality, response appropriateness, and reasoning capabilities. However,\nthe human effort required for benchmark construction is limited and being\nrapidly outpaced by the size and scope of the models under evaluation.\nAdditionally, having humans build a benchmark for every possible domain of\ninterest is impractical. Therefore, we propose a methodology for automating the\nconstruction of fact-based synthetic data model evaluations grounded in\ndocument populations. This work leverages those very same LMs to evaluate\ndomain-specific knowledge automatically, using only grounding documents (e.g.,\na textbook) as input. This synthetic data benchmarking approach corresponds\nwell with human curated questions with a Spearman ranking correlation of 0.96\nand a benchmark evaluation Pearson accuracy correlation of 0.79. This novel\ntool supports generating both multiple choice and open-ended synthetic data\nquestions to gain diagnostic insight of LM capability. We apply this\nmethodology to evaluate model performance on a recent relevant arXiv preprint,\ndiscovering a surprisingly strong performance from Gemma3 models."}
{"id": "2505.08801", "pdf": "https://arxiv.org/pdf/2505.08801", "abs": "https://arxiv.org/abs/2505.08801", "authors": ["Md. Sakib Hassan Chowdhury", "Md. Hafiz Ahamed", "Bishowjit Paul", "Sarafat Hussain Abhi", "Abu Bakar Siddique", "Md. Robius Sany"], "title": "OptiGait-LGBM: An Efficient Approach of Gait-based Person Re-identification in Non-Overlapping Regions", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": "12 pages, 17 figures", "summary": "Gait recognition, known for its ability to identify individuals from a\ndistance, has gained significant attention in recent times due to its\nnon-intrusive verification. While video-based gait identification systems\nperform well on large public datasets, their performance drops when applied to\nreal-world, unconstrained gait data due to various factors. Among these,\nuncontrolled outdoor environments, non-overlapping camera views, varying\nillumination, and computational efficiency are core challenges in gait-based\nauthentication. Currently, no dataset addresses all these challenges\nsimultaneously. In this paper, we propose an OptiGait-LGBM model capable of\nrecognizing person re-identification under these constraints using a skeletal\nmodel approach, which helps mitigate inconsistencies in a person's appearance.\nThe model constructs a dataset from landmark positions, minimizing memory usage\nby using non-sequential data. A benchmark dataset, RUET-GAIT, is introduced to\nrepresent uncontrolled gait sequences in complex outdoor environments. The\nprocess involves extracting skeletal joint landmarks, generating numerical\ndatasets, and developing an OptiGait-LGBM gait classification model. Our aim is\nto address the aforementioned challenges with minimal computational cost\ncompared to existing methods. A comparative analysis with ensemble techniques\nsuch as Random Forest and CatBoost demonstrates that the proposed approach\noutperforms them in terms of accuracy, memory usage, and training time. This\nmethod provides a novel, low-cost, and memory-efficient video-based gait\nrecognition solution for real-world scenarios."}
{"id": "2505.08793", "pdf": "https://arxiv.org/pdf/2505.08793", "abs": "https://arxiv.org/abs/2505.08793", "authors": ["Monirul Islam Pavel", "Siyi Hu", "Mahardhika Pratama", "Ryszard Kowalczyk"], "title": "Onboard Optimization and Learning: A Survey", "categories": ["cs.LG", "cs.AR"], "comment": "36 pages, 5 figures, 3 tables", "summary": "Onboard learning is a transformative approach in edge AI, enabling real-time\ndata processing, decision-making, and adaptive model training directly on\nresource-constrained devices without relying on centralized servers. This\nparadigm is crucial for applications demanding low latency, enhanced privacy,\nand energy efficiency. However, onboard learning faces challenges such as\nlimited computational resources, high inference costs, and security\nvulnerabilities. This survey explores a comprehensive range of methodologies\nthat address these challenges, focusing on techniques that optimize model\nefficiency, accelerate inference, and support collaborative learning across\ndistributed devices. Approaches for reducing model complexity, improving\ninference speed, and ensuring privacy-preserving computation are examined\nalongside emerging strategies that enhance scalability and adaptability in\ndynamic environments. By bridging advancements in hardware-software co-design,\nmodel compression, and decentralized learning, this survey provides insights\ninto the current state of onboard learning to enable robust, efficient, and\nsecure AI deployment at the edge."}
{"id": "2505.09056", "pdf": "https://arxiv.org/pdf/2505.09056", "abs": "https://arxiv.org/abs/2505.09056", "authors": ["Brandon Smith", "Mohamed Reda Bouadjenek", "Tahsin Alamgir Kheya", "Phillip Dawson", "Sunil Aryal"], "title": "A Comprehensive Analysis of Large Language Model Outputs: Similarity, Diversity, and Bias", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) represent a major step toward artificial general\nintelligence, significantly advancing our ability to interact with technology.\nWhile LLMs perform well on Natural Language Processing tasks -- such as\ntranslation, generation, code writing, and summarization -- questions remain\nabout their output similarity, variability, and ethical implications. For\ninstance, how similar are texts generated by the same model? How does this\ncompare across different models? And which models best uphold ethical\nstandards? To investigate, we used 5{,}000 prompts spanning diverse tasks like\ngeneration, explanation, and rewriting. This resulted in approximately 3\nmillion texts from 12 LLMs, including proprietary and open-source systems from\nOpenAI, Google, Microsoft, Meta, and Mistral. Key findings include: (1) outputs\nfrom the same LLM are more similar to each other than to human-written texts;\n(2) models like WizardLM-2-8x22b generate highly similar outputs, while GPT-4\nproduces more varied responses; (3) LLM writing styles differ significantly,\nwith Llama 3 and Mistral showing higher similarity, and GPT-4 standing out for\ndistinctiveness; (4) differences in vocabulary and tone underscore the\nlinguistic uniqueness of LLM-generated content; (5) some LLMs demonstrate\ngreater gender balance and reduced bias. These results offer new insights into\nthe behavior and diversity of LLM outputs, helping guide future development and\nethical evaluation."}
{"id": "2505.08988", "pdf": "https://arxiv.org/pdf/2505.08988", "abs": "https://arxiv.org/abs/2505.08988", "authors": ["Montaser Mohammedalamen", "Michael Bowling"], "title": "Generalization in Monitored Markov Decision Processes (Mon-MDPs)", "categories": ["cs.AI"], "comment": "Under Review", "summary": "Reinforcement learning (RL) typically models the interaction between the\nagent and environment as a Markov decision process (MDP), where the rewards\nthat guide the agent's behavior are always observable. However, in many\nreal-world scenarios, rewards are not always observable, which can be modeled\nas a monitored Markov decision process (Mon-MDP). Prior work on Mon-MDPs have\nbeen limited to simple, tabular cases, restricting their applicability to\nreal-world problems. This work explores Mon-MDPs using function approximation\n(FA) and investigates the challenges involved. We show that combining function\napproximation with a learned reward model enables agents to generalize from\nmonitored states with observable rewards, to unmonitored environment states\nwith unobservable rewards. Therefore, we demonstrate that such generalization\nwith a reward model achieves near-optimal policies in environments formally\ndefined as unsolvable. However, we identify a critical limitation of such\nfunction approximation, where agents incorrectly extrapolate rewards due to\novergeneralization, resulting in undesirable behaviors. To mitigate\novergeneralization, we propose a cautious police optimization method leveraging\nreward uncertainty. This work serves as a step towards bridging this gap\nbetween Mon-MDP theory and real-world applications."}
{"id": "2505.08808", "pdf": "https://arxiv.org/pdf/2505.08808", "abs": "https://arxiv.org/abs/2505.08808", "authors": ["Anqing Jiang", "Jinhao Chai", "Yu Gao", "Yiru Wang", "Yuwen Heng", "Zhigang Sun", "Hao Sun", "Zezhong Zhao", "Li Sun", "Jian Zhou", "Lijuan Zhu", "Shugong Xu", "Hao Zhao"], "title": "SparseMeXT Unlocking the Potential of Sparse Representations for HD Map Construction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advancements in high-definition \\emph{HD} map construction have\ndemonstrated the effectiveness of dense representations, which heavily rely on\ncomputationally intensive bird's-eye view \\emph{BEV} features. While sparse\nrepresentations offer a more efficient alternative by avoiding dense BEV\nprocessing, existing methods often lag behind due to the lack of tailored\ndesigns. These limitations have hindered the competitiveness of sparse\nrepresentations in online HD map construction. In this work, we systematically\nrevisit and enhance sparse representation techniques, identifying key\narchitectural and algorithmic improvements that bridge the gap with--and\nultimately surpass--dense approaches. We introduce a dedicated network\narchitecture optimized for sparse map feature extraction, a sparse-dense\nsegmentation auxiliary task to better leverage geometric and semantic cues, and\na denoising module guided by physical priors to refine predictions. Through\nthese enhancements, our method achieves state-of-the-art performance on the\nnuScenes dataset, significantly advancing HD map construction and centerline\ndetection. Specifically, SparseMeXt-Tiny reaches a mean average precision\n\\emph{mAP} of 55.5% at 32 frames per second \\emph{fps}, while SparseMeXt-Base\nattains 65.2% mAP. Scaling the backbone and decoder further, SparseMeXt-Large\nachieves an mAP of 68.9% at over 20 fps, establishing a new benchmark for\nsparse representations in HD map construction. These results underscore the\nuntapped potential of sparse methods, challenging the conventional reliance on\ndense representations and redefining efficiency-performance trade-offs in the\nfield."}
{"id": "2505.08795", "pdf": "https://arxiv.org/pdf/2505.08795", "abs": "https://arxiv.org/abs/2505.08795", "authors": ["Andres Anabalon", "Hugo Garces", "Julio Oliva", "Jose Cifuentes"], "title": "The Geometry of Meaning: Perfect Spacetime Representations of Hierarchical Structures", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "7 pages, 3 figures", "summary": "We show that there is a fast algorithm that embeds hierarchical structures in\nthree-dimensional Minkowski spacetime. The correlation of data ends up purely\nencoded in the causal structure. Our model relies solely on oriented token\npairs -- local hierarchical signals -- with no access to global symbolic\nstructure. We apply our method to the corpus of \\textit{WordNet}. We provide a\nperfect embedding of the mammal sub-tree including ambiguities (more than one\nhierarchy per node) in such a way that the hierarchical structures get\ncompletely codified in the geometry and exactly reproduce the ground-truth. We\nextend this to a perfect embedding of the maximal unambiguous subset of the\n\\textit{WordNet} with 82{,}115 noun tokens and a single hierarchy per token. We\nintroduce a novel retrieval mechanism in which causality, not distance, governs\nhierarchical access. Our results seem to indicate that all discrete data has a\nperfect geometrical representation that is three-dimensional. The resulting\nembeddings are nearly conformally invariant, indicating deep connections with\ngeneral relativity and field theory. These results suggest that concepts,\ncategories, and their interrelations, namely hierarchical meaning itself, is\ngeometric."}
{"id": "2505.09068", "pdf": "https://arxiv.org/pdf/2505.09068", "abs": "https://arxiv.org/abs/2505.09068", "authors": ["Jennifer Haase", "Paul H. P. Hanel", "Sebastian Pokutta"], "title": "S-DAT: A Multilingual, GenAI-Driven Framework for Automated Divergent Thinking Assessment", "categories": ["cs.CL", "cs.HC"], "comment": null, "summary": "This paper introduces S-DAT (Synthetic-Divergent Association Task), a\nscalable, multilingual framework for automated assessment of divergent thinking\n(DT) -a core component of human creativity. Traditional creativity assessments\nare often labor-intensive, language-specific, and reliant on subjective human\nratings, limiting their scalability and cross-cultural applicability. In\ncontrast, S-DAT leverages large language models and advanced multilingual\nembeddings to compute semantic distance -- a language-agnostic proxy for DT. We\nevaluate S-DAT across eleven diverse languages, including English, Spanish,\nGerman, Russian, Hindi, and Japanese (Kanji, Hiragana, Katakana), demonstrating\nrobust and consistent scoring across linguistic contexts. Unlike prior DAT\napproaches, the S-DAT shows convergent validity with other DT measures and\ncorrect discriminant validity with convergent thinking. This cross-linguistic\nflexibility allows for more inclusive, global-scale creativity research,\naddressing key limitations of earlier approaches. S-DAT provides a powerful\ntool for fairer, more comprehensive evaluation of cognitive flexibility in\ndiverse populations and can be freely assessed online:\nhttps://sdat.iol.zib.de/."}
{"id": "2505.08995", "pdf": "https://arxiv.org/pdf/2505.08995", "abs": "https://arxiv.org/abs/2505.08995", "authors": ["Ardian Selmonaj", "Oleg Szehr", "Giacomo Del Rio", "Alessandro Antonucci", "Adrian Schneider", "Michael Rüegsegger"], "title": "Enhancing Aerial Combat Tactics through Hierarchical Multi-Agent Reinforcement Learning", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.RO"], "comment": "Published as journal chapter in Deep Learning Applications, Vol. 1,\n  by Taylor & Francis", "summary": "This work presents a Hierarchical Multi-Agent Reinforcement Learning\nframework for analyzing simulated air combat scenarios involving heterogeneous\nagents. The objective is to identify effective Courses of Action that lead to\nmission success within preset simulations, thereby enabling the exploration of\nreal-world defense scenarios at low cost and in a safe-to-fail setting.\nApplying deep Reinforcement Learning in this context poses specific challenges,\nsuch as complex flight dynamics, the exponential size of the state and action\nspaces in multi-agent systems, and the capability to integrate real-time\ncontrol of individual units with look-ahead planning. To address these\nchallenges, the decision-making process is split into two levels of\nabstraction: low-level policies control individual units, while a high-level\ncommander policy issues macro commands aligned with the overall mission\ntargets. This hierarchical structure facilitates the training process by\nexploiting policy symmetries of individual agents and by separating control\nfrom command tasks. The low-level policies are trained for individual combat\ncontrol in a curriculum of increasing complexity. The high-level commander is\nthen trained on mission targets given pre-trained control policies. The\nempirical validation confirms the advantages of the proposed framework."}
{"id": "2505.08811", "pdf": "https://arxiv.org/pdf/2505.08811", "abs": "https://arxiv.org/abs/2505.08811", "authors": ["Shijie Lian", "Ziyi Zhang", "Laurence Tianruo Yang and", "Mengyu Ren", "Debin Liu", "Hua Li"], "title": "TUGS: Physics-based Compact Representation of Underwater Scenes by Tensorized Gaussian", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Underwater 3D scene reconstruction is crucial for undewater robotic\nperception and navigation. However, the task is significantly challenged by the\ncomplex interplay between light propagation, water medium, and object surfaces,\nwith existing methods unable to model their interactions accurately.\nAdditionally, expensive training and rendering costs limit their practical\napplication in underwater robotic systems. Therefore, we propose Tensorized\nUnderwater Gaussian Splatting (TUGS), which can effectively solve the modeling\nchallenges of the complex interactions between object geometries and water\nmedia while achieving significant parameter reduction. TUGS employs lightweight\ntensorized higher-order Gaussians with a physics-based underwater Adaptive\nMedium Estimation (AME) module, enabling accurate simulation of both light\nattenuation and backscatter effects in underwater environments. Compared to\nother NeRF-based and GS-based methods designed for underwater, TUGS is able to\nrender high-quality underwater images with faster rendering speeds and less\nmemory usage. Extensive experiments on real-world underwater datasets have\ndemonstrated that TUGS can efficiently achieve superior reconstruction quality\nusing a limited number of parameters, making it particularly suitable for\nmemory-constrained underwater UAV applications"}
{"id": "2505.08803", "pdf": "https://arxiv.org/pdf/2505.08803", "abs": "https://arxiv.org/abs/2505.08803", "authors": ["Zizhao Hu", "Mohammad Rostami", "Jesse Thomason"], "title": "Multi-modal Synthetic Data Training and Model Collapse: Insights from VLMs and Diffusion Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent research has highlighted the risk of generative model collapse, where\nperformance progressively degrades when continually trained on self-generated\ndata. However, existing exploration on model collapse is limited to single,\nunimodal models, limiting our understanding in more realistic scenarios, such\nas diverse multi-modal AI agents interacting autonomously through synthetic\ndata and continually evolving. We expand the synthetic data training and model\ncollapse study to multi-modal vision-language generative systems, such as\nvision-language models (VLMs) and text-to-image diffusion models, as well as\nrecursive generate-train loops with multiple models. We find that model\ncollapse, previously observed in single-modality generative models, exhibits\ndistinct characteristics in the multi-modal context, such as improved\nvision-language alignment and increased variance in VLM image-captioning task.\nAdditionally, we find that general approaches such as increased decoding\nbudgets, greater model diversity, and relabeling with frozen models can\neffectively mitigate model collapse. Our findings provide initial insights and\npractical guidelines for reducing the risk of model collapse in self-improving\nmulti-agent AI systems and curating robust multi-modal synthetic datasets."}
{"id": "2505.09082", "pdf": "https://arxiv.org/pdf/2505.09082", "abs": "https://arxiv.org/abs/2505.09082", "authors": ["Sophie Zhang", "Zhiming Lin"], "title": "CEC-Zero: Chinese Error Correction Solution Based on LLM", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) demonstrate exceptional\nChinese text processing capabilities, particularly in Chinese Spelling\nCorrection (CSC). While LLMs outperform traditional BERT-based models in\naccuracy and robustness, challenges persist in reliability and generalization.\nThis paper proposes CEC-Zero, a novel reinforcement learning (RL) framework\nenabling LLMs to self-correct through autonomous error strategy learning\nwithout external supervision. By integrating RL with LLMs' generative power,\nthe method eliminates dependency on annotated data or auxiliary models.\nExperiments reveal RL-enhanced LLMs achieve industry-viable accuracy and\nsuperior cross-domain generalization, offering a scalable solution for\nreliability optimization in Chinese NLP applications. This breakthrough\nfacilitates LLM deployment in practical Chinese text correction scenarios while\nestablishing a new paradigm for self-improving language models."}
{"id": "2505.09012", "pdf": "https://arxiv.org/pdf/2505.09012", "abs": "https://arxiv.org/abs/2505.09012", "authors": ["Bo Meng", "Chenghao Xu", "Yongli Zhu"], "title": "Deep Reinforcement Learning for Power Grid Multi-Stage Cascading Failure Mitigation", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore,\n  Apr. 28, 2025", "summary": "Cascading failures in power grids can lead to grid collapse, causing severe\ndisruptions to social operations and economic activities. In certain cases,\nmulti-stage cascading failures can occur. However, existing\ncascading-failure-mitigation strategies are usually single-stage-based,\noverlooking the complexity of the multi-stage scenario. This paper treats the\nmulti-stage cascading failure problem as a reinforcement learning task and\ndevelops a simulation environment. The reinforcement learning agent is then\ntrained via the deterministic policy gradient algorithm to achieve continuous\nactions. Finally, the effectiveness of the proposed approach is validated on\nthe IEEE 14-bus and IEEE 118-bus systems."}
{"id": "2505.08814", "pdf": "https://arxiv.org/pdf/2505.08814", "abs": "https://arxiv.org/abs/2505.08814", "authors": ["Wenkai Li", "Xiaoqi Li", "Yingjie Mao", "Yishun Wang"], "title": "Towards Understanding Deep Learning Model in Image Recognition via Coverage Test", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep neural networks (DNNs) play a crucial role in the field of artificial\nintelligence, and their security-related testing has been a prominent research\nfocus. By inputting test cases, the behavior of models is examined for\nanomalies, and coverage metrics are utilized to determine the extent of neurons\ncovered by these test cases. With the widespread application and advancement of\nDNNs, different types of neural behaviors have garnered attention, leading to\nthe emergence of various coverage metrics for neural networks. However, there\nis currently a lack of empirical research on these coverage metrics,\nspecifically in analyzing the relationships and patterns between model depth,\nconfiguration information, and neural network coverage. This paper aims to\ninvestigate the relationships and patterns of four coverage metrics: primary\nfunctionality, boundary, hierarchy, and structural coverage. A series of\nempirical experiments were conducted, selecting LeNet, VGG, and ResNet as\ndifferent DNN architectures, along with 10 models of varying depths ranging\nfrom 5 to 54 layers, to compare and study the relationships between different\ndepths, configuration information, and various neural network coverage metrics.\nAdditionally, an investigation was carried out on the relationships between\nmodified decision/condition coverage and dataset size. Finally, three potential\nfuture directions are proposed to further contribute to the security testing of\nDNN Models."}
{"id": "2505.08823", "pdf": "https://arxiv.org/pdf/2505.08823", "abs": "https://arxiv.org/abs/2505.08823", "authors": ["Cody Steinmetz", "Gavin Childress", "Aaron Herbst", "Gavin Jones", "Jasdeep Singh", "Eli Vang", "Keagan Weinstock"], "title": "An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have transformed natural-language processing,\nyet their scale makes real-world deployment costly. Post-training quantization\nreduces memory and computation but often degrades accuracy, while\nquantization-aware training can recover performance at the cost of extra\ntraining. Pushing quantization to the ternary (2-bit) regime yields even larger\nsavings but is notoriously unstable. Building on recent work showing that a\nbias-free, RMS-normalized Transformer with straight-through estimation can\nreach 1.58-bit precision, we demonstrate that simply inserting RMS\nnormalization before every linear projection and applying a gradual, layer-wise\nquantization schedule stably fine-tunes full-precision checkpoints into ternary\nLLMs. Our approach matches or surpasses more elaborate knowledge-distillation\npipelines on standard language-modeling benchmarks without adding model\ncomplexity. These results indicate that careful normalization alone can close\nmuch of the accuracy gap between ternary and full-precision LLMs, making\nultra-low-bit inference practical."}
{"id": "2505.09269", "pdf": "https://arxiv.org/pdf/2505.09269", "abs": "https://arxiv.org/abs/2505.09269", "authors": ["Ulrich Frank", "Pierre Maier"], "title": "How an unintended Side Effect of a Research Project led to Boosting the Power of UML", "categories": ["cs.CL"], "comment": null, "summary": "This paper describes the design, implementation and use of a new UML modeling\ntool that represents a significant advance over conventional tools. Among other\nthings, it allows the integration of class diagrams and object diagrams as well\nas the execution of objects. This not only enables new software architectures\ncharacterized by the integration of software with corresponding object models,\nbut is also ideal for use in teaching, as it provides students with a\nparticularly stimulating learning experience. A special feature of the project\nis that it has emerged from a long-standing international research project,\nwhich is aimed at a comprehensive multi-level architecture. The project is\ntherefore an example of how research can lead to valuable results that arise as\na side effect of other work."}
{"id": "2505.09024", "pdf": "https://arxiv.org/pdf/2505.09024", "abs": "https://arxiv.org/abs/2505.09024", "authors": ["Aaron Baughman", "Rahul Agarwal", "Eduardo Morales", "Gozde Akay"], "title": "Automated Meta Prompt Engineering for Alignment with the Theory of Mind", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "9 pages, 6 figures, 3 tables", "summary": "We introduce a method of meta-prompting that jointly produces fluent text for\ncomplex tasks while optimizing the similarity of neural states between a\nhuman's mental expectation and a Large Language Model's (LLM) neural\nprocessing. A technique of agentic reinforcement learning is applied, in which\nan LLM as a Judge (LLMaaJ) teaches another LLM, through in-context learning,\nhow to produce content by interpreting the intended and unintended generated\ntext traits. To measure human mental beliefs around content production, users\nmodify long form AI-generated text articles before publication at the US Open\n2024 tennis Grand Slam. Now, an LLMaaJ can solve the Theory of Mind (ToM)\nalignment problem by anticipating and including human edits within the creation\nof text from an LLM. Throughout experimentation and by interpreting the results\nof a live production system, the expectations of human content reviewers had\n100% of alignment with AI 53.8% of the time with an average iteration count of\n4.38. The geometric interpretation of content traits such as factualness,\nnovelty, repetitiveness, and relevancy over a Hilbert vector space combines\nspatial volume (all trait importance) with vertices alignment (individual trait\nrelevance) enabled the LLMaaJ to optimize on Human ToM. This resulted in an\nincrease in content quality by extending the coverage of tennis action. Our\nwork that was deployed at the US Open 2024 has been used across other live\nevents within sports and entertainment."}
{"id": "2505.08817", "pdf": "https://arxiv.org/pdf/2505.08817", "abs": "https://arxiv.org/abs/2505.08817", "authors": ["Camilo Carvajal Reyes", "Joaquín Fontbona", "Felipe Tobar"], "title": "Towards SFW sampling for diffusion models via external conditioning", "categories": ["cs.CV", "cs.LG"], "comment": "Accepcted at IJCNN 2025", "summary": "Score-based generative models (SBM), also known as diffusion models, are the\nde facto state of the art for image synthesis. Despite their unparalleled\nperformance, SBMs have recently been in the spotlight for being tricked into\ncreating not-safe-for-work (NSFW) content, such as violent images and\nnon-consensual nudity. Current approaches that prevent unsafe generation are\nbased on the models' own knowledge, and the majority of them require\nfine-tuning. This article explores the use of external sources for ensuring\nsafe outputs in SBMs. Our safe-for-work (SFW) sampler implements a Conditional\nTrajectory Correction step that guides the samples away from undesired regions\nin the ambient space using multimodal models as the source of conditioning.\nFurthermore, using Contrastive Language Image Pre-training (CLIP), our method\nadmits user-defined NSFW classes, which can vary in different settings. Our\nexperiments on the text-to-image SBM Stable Diffusion validate that the\nproposed SFW sampler effectively reduces the generation of explicit content\nwhile being competitive with other fine-tuning-based approaches, as assessed\nvia independent NSFW detectors. Moreover, we evaluate the impact of the SFW\nsampler on image quality and show that the proposed correction scheme comes at\na minor cost with negligible effect on samples not needing correction. Our\nstudy confirms the suitability of the SFW sampler towards aligned SBM models\nand the potential of using model-agnostic conditioning for the prevention of\nunwanted images."}
{"id": "2505.08827", "pdf": "https://arxiv.org/pdf/2505.08827", "abs": "https://arxiv.org/abs/2505.08827", "authors": ["Toby Simonds", "Kevin Lopez", "Akira Yoshiyama", "Dominique Garmier"], "title": "Self Rewarding Self Improving", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We demonstrate that large language models can effectively self-improve\nthrough self-judging without requiring reference solutions, leveraging the\ninherent asymmetry between generating and verifying solutions. Our experiments\non Countdown puzzles and MIT Integration Bee problems show that models can\nprovide reliable reward signals without ground truth answers, enabling\nreinforcement learning in domains previously not possible. By implementing\nself-judging, we achieve significant performance gains maintaining alignment\nwith formal verification. When combined with synthetic question generation, we\nestablish a complete self-improvement loop where models generate practice\nproblems, solve them, and evaluate their own performance-achieving an 8%\nimprovement with Qwen 2.5 7B over baseline and surpassing GPT-4o performance on\nintegration tasks. Our findings demonstrate that LLM judges can provide\neffective reward signals for training models, unlocking many reinforcement\nlearning environments previously limited by the difficulty of creating\nprogrammatic rewards. This suggests a potential paradigm shift toward AI\nsystems that continuously improve through self-directed learning rather than\nhuman-guided training, potentially accelerating progress in domains with scarce\ntraining data or complex evaluation requirements."}
{"id": "2505.09286", "pdf": "https://arxiv.org/pdf/2505.09286", "abs": "https://arxiv.org/abs/2505.09286", "authors": ["Jiin Park", "Misuk Kim"], "title": "A Scalable Unsupervised Framework for multi-aspect labeling of Multilingual and Multi-Domain Review Data", "categories": ["cs.CL"], "comment": "36 pages, 3 figures", "summary": "Effectively analyzing online review data is essential across industries.\nHowever, many existing studies are limited to specific domains and languages or\ndepend on supervised learning approaches that require large-scale labeled\ndatasets. To address these limitations, we propose a multilingual, scalable,\nand unsupervised framework for cross-domain aspect detection. This framework is\ndesigned for multi-aspect labeling of multilingual and multi-domain review\ndata. In this study, we apply automatic labeling to Korean and English review\ndatasets spanning various domains and assess the quality of the generated\nlabels through extensive experiments. Aspect category candidates are first\nextracted through clustering, and each review is then represented as an\naspect-aware embedding vector using negative sampling. To evaluate the\nframework, we conduct multi-aspect labeling and fine-tune several pretrained\nlanguage models to measure the effectiveness of the automatically generated\nlabels. Results show that these models achieve high performance, demonstrating\nthat the labels are suitable for training. Furthermore, comparisons with\npublicly available large language models highlight the framework's superior\nconsistency and scalability when processing large-scale data. A human\nevaluation also confirms that the quality of the automatic labels is comparable\nto those created manually. This study demonstrates the potential of a robust\nmulti-aspect labeling approach that overcomes limitations of supervised methods\nand is adaptable to multilingual, multi-domain environments. Future research\nwill explore automatic review summarization and the integration of artificial\nintelligence agents to further improve the efficiency and depth of review\nanalysis."}
{"id": "2505.09029", "pdf": "https://arxiv.org/pdf/2505.09029", "abs": "https://arxiv.org/abs/2505.09029", "authors": ["Hazim Alzorgan", "Abolfazl Razi"], "title": "Monte Carlo Beam Search for Actor-Critic Reinforcement Learning in Continuous Control", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Actor-critic methods, like Twin Delayed Deep Deterministic Policy Gradient\n(TD3), depend on basic noise-based exploration, which can result in less than\noptimal policy convergence. In this study, we introduce Monte Carlo Beam Search\n(MCBS), a new hybrid method that combines beam search and Monte Carlo rollouts\nwith TD3 to improve exploration and action selection. MCBS produces several\ncandidate actions around the policy's output and assesses them through\nshort-horizon rollouts, enabling the agent to make better-informed choices. We\ntest MCBS across various continuous-control benchmarks, including\nHalfCheetah-v4, Walker2d-v5, and Swimmer-v5, showing enhanced sample efficiency\nand performance compared to standard TD3 and other baseline methods like SAC,\nPPO, and A2C. Our findings emphasize MCBS's capability to enhance policy\nlearning through structured look-ahead search while ensuring computational\nefficiency. Additionally, we offer a detailed analysis of crucial\nhyperparameters, such as beam width and rollout depth, and explore adaptive\nstrategies to optimize MCBS for complex control tasks. Our method shows a\nhigher convergence rate across different environments compared to TD3, SAC,\nPPO, and A2C. For instance, we achieved 90% of the maximum achievable reward\nwithin around 200 thousand timesteps compared to 400 thousand timesteps for the\nsecond-best method."}
{"id": "2505.08833", "pdf": "https://arxiv.org/pdf/2505.08833", "abs": "https://arxiv.org/abs/2505.08833", "authors": ["Qingyi Wang", "Yuebing Liang", "Yunhan Zheng", "Kaiyuan Xu", "Jinhua Zhao", "Shenhao Wang"], "title": "Generative AI for Urban Planning: Synthesizing Satellite Imagery via Diffusion Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Generative AI offers new opportunities for automating urban planning by\ncreating site-specific urban layouts and enabling flexible design exploration.\nHowever, existing approaches often struggle to produce realistic and practical\ndesigns at scale. Therefore, we adapt a state-of-the-art Stable Diffusion\nmodel, extended with ControlNet, to generate high-fidelity satellite imagery\nconditioned on land use descriptions, infrastructure, and natural environments.\nTo overcome data availability limitations, we spatially link satellite imagery\nwith structured land use and constraint information from OpenStreetMap. Using\ndata from three major U.S. cities, we demonstrate that the proposed diffusion\nmodel generates realistic and diverse urban landscapes by varying land-use\nconfigurations, road networks, and water bodies, facilitating cross-city\nlearning and design diversity. We also systematically evaluate the impacts of\nvarying language prompts and control imagery on the quality of satellite\nimagery generation. Our model achieves high FID and KID scores and demonstrates\nrobustness across diverse urban contexts. Qualitative assessments from urban\nplanners and the general public show that generated images align closely with\ndesign descriptions and constraints, and are often preferred over real images.\nThis work establishes a benchmark for controlled urban imagery generation and\nhighlights the potential of generative AI as a tool for enhancing planning\nworkflows and public engagement."}
{"id": "2505.08829", "pdf": "https://arxiv.org/pdf/2505.08829", "abs": "https://arxiv.org/abs/2505.08829", "authors": ["David Kinney"], "title": "Aggregating Concepts of Accuracy and Fairness in Prediction Algorithms", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "An algorithm that outputs predictions about the state of the world will\nalmost always be designed with the implicit or explicit goal of outputting\naccurate predictions (i.e., predictions that are likely to be true). In\naddition, the rise of increasingly powerful predictive algorithms brought about\nby the recent revolution in artificial intelligence has led to an emphasis on\nbuilding predictive algorithms that are fair, in the sense that their\npredictions do not systematically evince bias or bring about harm to certain\nindividuals or groups. This state of affairs presents two conceptual\nchallenges. First, the goals of accuracy and fairness can sometimes be in\ntension, and there are no obvious normative guidelines for managing the\ntrade-offs between these two desiderata when they arise. Second, there are many\ndistinct ways of measuring both the accuracy and fairness of a predictive\nalgorithm; here too, there are no obvious guidelines on how to aggregate our\npreferences for predictive algorithms that satisfy disparate measures of\nfairness and accuracy to various extents. The goal of this paper is to address\nthese challenges by arguing that there are good reasons for using a linear\ncombination of accuracy and fairness metrics to measure the\nall-things-considered value of a predictive algorithm for agents who care about\nboth accuracy and fairness. My argument depends crucially on a classic result\nin the preference aggregation literature due to Harsanyi. After making this\nformal argument, I apply my result to an analysis of accuracy-fairness\ntrade-offs using the COMPAS dataset compiled by Angwin et al."}
{"id": "2505.09316", "pdf": "https://arxiv.org/pdf/2505.09316", "abs": "https://arxiv.org/abs/2505.09316", "authors": ["Hongjin Qian", "Zheng Liu"], "title": "Scent of Knowledge: Optimizing Search-Enhanced Reasoning with Information Foraging", "categories": ["cs.CL", "cs.IR"], "comment": "16 pages", "summary": "Augmenting large language models (LLMs) with external retrieval has become a\nstandard method to address their inherent knowledge cutoff limitations.\nHowever, traditional retrieval-augmented generation methods employ static,\npre-inference retrieval strategies, making them inadequate for complex tasks\ninvolving ambiguous, multi-step, or evolving information needs. Recent advances\nin test-time scaling techniques have demonstrated significant potential in\nenabling LLMs to dynamically interact with external tools, motivating the shift\ntoward adaptive inference-time retrieval. Inspired by Information Foraging\nTheory (IFT), we propose InForage, a reinforcement learning framework that\nformalizes retrieval-augmented reasoning as a dynamic information-seeking\nprocess. Unlike existing approaches, InForage explicitly rewards intermediate\nretrieval quality, encouraging LLMs to iteratively gather and integrate\ninformation through adaptive search behaviors. To facilitate training, we\nconstruct a human-guided dataset capturing iterative search and reasoning\ntrajectories for complex, real-world web tasks. Extensive evaluations across\ngeneral question answering, multi-hop reasoning tasks, and a newly developed\nreal-time web QA dataset demonstrate InForage's superior performance over\nbaseline methods. These results highlight InForage's effectiveness in building\nrobust, adaptive, and efficient reasoning agents."}
{"id": "2505.09031", "pdf": "https://arxiv.org/pdf/2505.09031", "abs": "https://arxiv.org/abs/2505.09031", "authors": ["Adarsh Kumar", "Hwiyoon Kim", "Jawahar Sai Nathani", "Neil Roy"], "title": "Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Hallucination, where large language models (LLMs) generate confident but\nincorrect or irrelevant information, remains a key limitation in their\napplication to complex, open-ended tasks. Chain-of-thought (CoT) prompting has\nemerged as a promising method for improving multistep reasoning by guiding\nmodels through intermediate steps. However, CoT alone does not fully address\nthe hallucination problem. In this work, we investigate how combining CoT with\nretrieval-augmented generation (RAG), as well as applying self-consistency and\nself-verification strategies, can reduce hallucinations and improve factual\naccuracy. By incorporating external knowledge sources during reasoning and\nenabling models to verify or revise their own outputs, we aim to generate more\naccurate and coherent responses. We present a comparative evaluation of\nbaseline LLMs against CoT, CoT+RAG, self-consistency, and self-verification\ntechniques. Our results highlight the effectiveness of each method and identify\nthe most robust approach for minimizing hallucinations while preserving fluency\nand reasoning depth."}
{"id": "2505.08834", "pdf": "https://arxiv.org/pdf/2505.08834", "abs": "https://arxiv.org/abs/2505.08834", "authors": ["Muhammad Junaid Asif"], "title": "Crowd Scene Analysis using Deep Learning Techniques", "categories": ["cs.CV", "cs.AI"], "comment": "MS Graduate Research Thesis", "summary": "Our research is focused on two main applications of crowd scene analysis\ncrowd counting and anomaly detection In recent years a large number of\nresearches have been presented in the domain of crowd counting We addressed two\nmain challenges in this domain 1 Deep learning models are datahungry paradigms\nand always need a large amount of annotated data for the training of algorithm\nIt is timeconsuming and costly task to annotate such large amount of data\nSelfsupervised training is proposed to deal with this challenge 2 MCNN consists\nof multicolumns of CNN with different sizes of filters by presenting a novel\napproach based on a combination of selfsupervised training and MultiColumn CNN\nThis enables the model to learn features at different levels and makes it\neffective in dealing with challenges of occluded scenes nonuniform density\ncomplex backgrounds and scale invariation The proposed model was evaluated on\npublicly available data sets such as ShanghaiTech and UCFQNRF by means of MAE\nand MSE A spatiotemporal model based on VGG19 is proposed for crowd anomaly\ndetection addressing challenges like lighting environmental conditions\nunexpected objects and scalability The model extracts spatial and temporal\nfeatures allowing it to be generalized to realworld scenes Spatial features are\nlearned using CNN while temporal features are learned using LSTM blocks The\nmodel works on binary classification and can detect normal or abnormal behavior\nThe models performance is improved by replacing fully connected layers with\ndense residual blocks Experiments on the Hockey Fight dataset and SCVD dataset\nshow our models outperform other stateoftheart approaches"}
{"id": "2505.08846", "pdf": "https://arxiv.org/pdf/2505.08846", "abs": "https://arxiv.org/abs/2505.08846", "authors": ["Felix Marti-Perez", "Brigt Håvardstun", "Cèsar Ferri", "Carlos Monserrat", "Jan Arne Telle"], "title": "Evaluating Simplification Algorithms for Interpretability of Time Series Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this work, we introduce metrics to evaluate the use of simplified time\nseries in the context of interpretability of a TSC - a Time Series Classifier.\nSuch simplifications are important because time series data, in contrast to\ntext and image data, are not intuitively understandable to humans. These\nmetrics are related to the complexity of the simplifications - how many\nsegments they contain - and to their loyalty - how likely they are to maintain\nthe classification of the original time series. We employ these metrics to\nevaluate four distinct simplification algorithms, across several TSC algorithms\nand across datasets of varying characteristics, from seasonal or stationary to\nshort or long. Our findings suggest that using simplifications for\ninterpretability of TSC is much better than using the original time series,\nparticularly when the time series are seasonal, non-stationary and/or with low\nentropy."}
{"id": "2505.09338", "pdf": "https://arxiv.org/pdf/2505.09338", "abs": "https://arxiv.org/abs/2505.09338", "authors": ["Jingcheng Niu", "Xingdi Yuan", "Tong Wang", "Hamidreza Saghir", "Amir H. Abdi"], "title": "Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs", "categories": ["cs.CL"], "comment": null, "summary": "We observe a novel phenomenon, contextual entrainment, across a wide range of\nlanguage models (LMs) and prompt settings, providing a new mechanistic\nperspective on how LMs become distracted by ``irrelevant'' contextual\ninformation in the input prompt. Specifically, LMs assign significantly higher\nlogits (or probabilities) to any tokens that have previously appeared in the\ncontext prompt, even for random tokens. This suggests that contextual\nentrainment is a mechanistic phenomenon, occurring independently of the\nrelevance or semantic relation of the tokens to the question or the rest of the\nsentence. We find statistically significant evidence that the magnitude of\ncontextual entrainment is influenced by semantic factors. Counterfactual\nprompts have a greater effect compared to factual ones, suggesting that while\ncontextual entrainment is a mechanistic phenomenon, it is modulated by semantic\nfactors.\n  We hypothesise that there is a circuit of attention heads -- the entrainment\nheads -- that corresponds to the contextual entrainment phenomenon. Using a\nnovel entrainment head discovery method based on differentiable masking, we\nidentify these heads across various settings. When we ``turn off'' these heads,\ni.e., set their outputs to zero, the effect of contextual entrainment is\nsignificantly attenuated, causing the model to generate output that capitulates\nto what it would produce if no distracting context were provided. Our discovery\nof contextual entrainment, along with our investigation into LM distraction via\nthe entrainment heads, marks a key step towards the mechanistic analysis and\nmitigation of the distraction problem."}
{"id": "2505.09114", "pdf": "https://arxiv.org/pdf/2505.09114", "abs": "https://arxiv.org/abs/2505.09114", "authors": ["Minh Hoang Nguyen", "Linh Le Pham Van", "Thommen George Karimpanal", "Sunil Gupta", "Hung Le"], "title": "Beyond the Known: Decision Making with Counterfactual Reasoning Decision Transformer", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Decision Transformers (DT) play a crucial role in modern reinforcement\nlearning, leveraging offline datasets to achieve impressive results across\nvarious domains. However, DT requires high-quality, comprehensive data to\nperform optimally. In real-world applications, the lack of training data and\nthe scarcity of optimal behaviours make training on offline datasets\nchallenging, as suboptimal data can hinder performance. To address this, we\npropose the Counterfactual Reasoning Decision Transformer (CRDT), a novel\nframework inspired by counterfactual reasoning. CRDT enhances DT ability to\nreason beyond known data by generating and utilizing counterfactual\nexperiences, enabling improved decision-making in unseen scenarios. Experiments\nacross Atari and D4RL benchmarks, including scenarios with limited data and\naltered dynamics, demonstrate that CRDT outperforms conventional DT approaches.\nAdditionally, reasoning counterfactually allows the DT agent to obtain\nstitching abilities, combining suboptimal trajectories, without architectural\nmodifications. These results highlight the potential of counterfactual\nreasoning to enhance reinforcement learning agents' performance and\ngeneralization capabilities."}
{"id": "2505.08854", "pdf": "https://arxiv.org/pdf/2505.08854", "abs": "https://arxiv.org/abs/2505.08854", "authors": ["Yuping Wang", "Shuo Xing", "Cui Can", "Renjie Li", "Hongyuan Hua", "Kexin Tian", "Zhaobin Mo", "Xiangbo Gao", "Keshu Wu", "Sulong Zhou", "Hengxu You", "Juntong Peng", "Junge Zhang", "Zehao Wang", "Rui Song", "Mingxuan Yan", "Walter Zimmer", "Xingcheng Zhou", "Peiran Li", "Zhaohan Lu", "Chia-Ju Chen", "Yue Huang", "Ryan A. Rossi", "Lichao Sun", "Hongkai Yu", "Zhiwen Fan", "Frank Hao Yang", "Yuhao Kang", "Ross Greer", "Chenxi Liu", "Eun Hak Lee", "Xuan Di", "Xinyue Ye", "Liu Ren", "Alois Knoll", "Xiaopeng Li", "Shuiwang Ji", "Masayoshi Tomizuka", "Marco Pavone", "Tianbao Yang", "Jing Du", "Ming-Hsuan Yang", "Hua Wei", "Ziran Wang", "Yang Zhou", "Jiachen Li", "Zhengzhong Tu"], "title": "Generative AI for Autonomous Driving: Frontiers and Opportunities", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Generative Artificial Intelligence (GenAI) constitutes a transformative\ntechnological wave that reconfigures industries through its unparalleled\ncapabilities for content creation, reasoning, planning, and multimodal\nunderstanding. This revolutionary force offers the most promising path yet\ntoward solving one of engineering's grandest challenges: achieving reliable,\nfully autonomous driving, particularly the pursuit of Level 5 autonomy. This\nsurvey delivers a comprehensive and critical synthesis of the emerging role of\nGenAI across the autonomous driving stack. We begin by distilling the\nprinciples and trade-offs of modern generative modeling, encompassing VAEs,\nGANs, Diffusion Models, and Large Language Models (LLMs). We then map their\nfrontier applications in image, LiDAR, trajectory, occupancy, video generation\nas well as LLM-guided reasoning and decision making. We categorize practical\napplications, such as synthetic data workflows, end-to-end driving strategies,\nhigh-fidelity digital twin systems, smart transportation networks, and\ncross-domain transfer to embodied AI. We identify key obstacles and\npossibilities such as comprehensive generalization across rare cases,\nevaluation and safety checks, budget-limited implementation, regulatory\ncompliance, ethical concerns, and environmental effects, while proposing\nresearch plans across theoretical assurances, trust metrics, transport\nintegration, and socio-technical influence. By unifying these threads, the\nsurvey provides a forward-looking reference for researchers, engineers, and\npolicymakers navigating the convergence of generative AI and advanced\nautonomous mobility. An actively maintained repository of cited works is\navailable at https://github.com/taco-group/GenAI4AD."}
{"id": "2505.08915", "pdf": "https://arxiv.org/pdf/2505.08915", "abs": "https://arxiv.org/abs/2505.08915", "authors": ["Jialin Mao", "Itay Griniasty", "Yan Sun", "Mark K. Transtrum", "James P. Sethna", "Pratik Chaudhari"], "title": "An Analytical Characterization of Sloppiness in Neural Networks: Insights from Linear Models", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech"], "comment": null, "summary": "Recent experiments have shown that training trajectories of multiple deep\nneural networks with different architectures, optimization algorithms,\nhyper-parameter settings, and regularization methods evolve on a remarkably\nlow-dimensional \"hyper-ribbon-like\" manifold in the space of probability\ndistributions. Inspired by the similarities in the training trajectories of\ndeep networks and linear networks, we analytically characterize this phenomenon\nfor the latter. We show, using tools in dynamical systems theory, that the\ngeometry of this low-dimensional manifold is controlled by (i) the decay rate\nof the eigenvalues of the input correlation matrix of the training data, (ii)\nthe relative scale of the ground-truth output to the weights at the beginning\nof training, and (iii) the number of steps of gradient descent. By analytically\ncomputing and bounding the contributions of these quantities, we characterize\nphase boundaries of the region where hyper-ribbons are to be expected. We also\nextend our analysis to kernel machines and linear models that are trained with\nstochastic gradient descent."}
{"id": "2505.09388", "pdf": "https://arxiv.org/pdf/2505.09388", "abs": "https://arxiv.org/abs/2505.09388", "authors": ["An Yang", "Anfeng Li", "Baosong Yang", "Beichen Zhang", "Binyuan Hui", "Bo Zheng", "Bowen Yu", "Chang Gao", "Chengen Huang", "Chenxu Lv", "Chujie Zheng", "Dayiheng Liu", "Fan Zhou", "Fei Huang", "Feng Hu", "Hao Ge", "Haoran Wei", "Huan Lin", "Jialong Tang", "Jian Yang", "Jianhong Tu", "Jianwei Zhang", "Jianxin Yang", "Jiaxi Yang", "Jing Zhou", "Jingren Zhou", "Junyang Lin", "Kai Dang", "Keqin Bao", "Kexin Yang", "Le Yu", "Lianghao Deng", "Mei Li", "Mingfeng Xue", "Mingze Li", "Pei Zhang", "Peng Wang", "Qin Zhu", "Rui Men", "Ruize Gao", "Shixuan Liu", "Shuang Luo", "Tianhao Li", "Tianyi Tang", "Wenbiao Yin", "Xingzhang Ren", "Xinyu Wang", "Xinyu Zhang", "Xuancheng Ren", "Yang Fan", "Yang Su", "Yichang Zhang", "Yinger Zhang", "Yu Wan", "Yuqiong Liu", "Zekun Wang", "Zeyu Cui", "Zhenru Zhang", "Zhipeng Zhou", "Zihan Qiu"], "title": "Qwen3 Technical Report", "categories": ["cs.CL"], "comment": null, "summary": "In this work, we present Qwen3, the latest version of the Qwen model family.\nQwen3 comprises a series of large language models (LLMs) designed to advance\nperformance, efficiency, and multilingual capabilities. The Qwen3 series\nincludes models of both dense and Mixture-of-Expert (MoE) architectures, with\nparameter scales ranging from 0.6 to 235 billion. A key innovation in Qwen3 is\nthe integration of thinking mode (for complex, multi-step reasoning) and\nnon-thinking mode (for rapid, context-driven responses) into a unified\nframework. This eliminates the need to switch between different models--such as\nchat-optimized models (e.g., GPT-4o) and dedicated reasoning models (e.g.,\nQwQ-32B)--and enables dynamic mode switching based on user queries or chat\ntemplates. Meanwhile, Qwen3 introduces a thinking budget mechanism, allowing\nusers to allocate computational resources adaptively during inference, thereby\nbalancing latency and performance based on task complexity. Moreover, by\nleveraging the knowledge from the flagship models, we significantly reduce the\ncomputational resources required to build smaller-scale models, while ensuring\ntheir highly competitive performance. Empirical evaluations demonstrate that\nQwen3 achieves state-of-the-art results across diverse benchmarks, including\ntasks in code generation, mathematical reasoning, agent tasks, etc.,\ncompetitive against larger MoE models and proprietary models. Compared to its\npredecessor Qwen2.5, Qwen3 expands multilingual support from 29 to 119\nlanguages and dialects, enhancing global accessibility through improved\ncross-lingual understanding and generation capabilities. To facilitate\nreproducibility and community-driven research and development, all Qwen3 models\nare publicly accessible under Apache 2.0."}
{"id": "2505.09289", "pdf": "https://arxiv.org/pdf/2505.09289", "abs": "https://arxiv.org/abs/2505.09289", "authors": ["Pedro M. P. Curvo", "Mara Dragomir", "Salvador Torpes", "Mohammadmahdi Rahimi"], "title": "Reproducibility Study of \"Cooperate or Collapse: Emergence of Sustainable Cooperation in a Society of LLM Agents\"", "categories": ["cs.AI"], "comment": "11 Tables, 9 Figures", "summary": "This study evaluates and extends the findings made by Piatti et al., who\nintroduced GovSim, a simulation framework designed to assess the cooperative\ndecision-making capabilities of large language models (LLMs) in\nresource-sharing scenarios. By replicating key experiments, we validate claims\nregarding the performance of large models, such as GPT-4-turbo, compared to\nsmaller models. The impact of the universalization principle is also examined,\nwith results showing that large models can achieve sustainable cooperation,\nwith or without the principle, while smaller models fail without it. In\naddition, we provide multiple extensions to explore the applicability of the\nframework to new settings. We evaluate additional models, such as DeepSeek-V3\nand GPT-4o-mini, to test whether cooperative behavior generalizes across\ndifferent architectures and model sizes. Furthermore, we introduce new\nsettings: we create a heterogeneous multi-agent environment, study a scenario\nusing Japanese instructions, and explore an \"inverse environment\" where agents\nmust cooperate to mitigate harmful resource distributions. Our results confirm\nthat the benchmark can be applied to new models, scenarios, and languages,\noffering valuable insights into the adaptability of LLMs in complex cooperative\ntasks. Moreover, the experiment involving heterogeneous multi-agent systems\ndemonstrates that high-performing models can influence lower-performing ones to\nadopt similar behaviors. This finding has significant implications for other\nagent-based applications, potentially enabling more efficient use of\ncomputational resources and contributing to the development of more effective\ncooperative AI systems."}
{"id": "2505.08882", "pdf": "https://arxiv.org/pdf/2505.08882", "abs": "https://arxiv.org/abs/2505.08882", "authors": ["Ali Almakhluk", "Uthman Baroudi", "Yasser El-Alfy"], "title": "Intelligent Road Anomaly Detection with Real-time Notification System for Enhanced Road Safety", "categories": ["cs.CV", "cs.SY", "eess.IV", "eess.SY"], "comment": null, "summary": "This study aims to improve transportation safety, especially traffic safety.\nRoad damage anomalies such as potholes and cracks have emerged as a significant\nand recurring cause for accidents. To tackle this problem and improve road\nsafety, a comprehensive system has been developed to detect potholes, cracks\n(e.g. alligator, transverse, longitudinal), classify their sizes, and transmit\nthis data to the cloud for appropriate action by authorities. The system also\nbroadcasts warning signals to nearby vehicles warning them if a severe anomaly\nis detected on the road. Moreover, the system can count road anomalies in\nreal-time. It is emulated through the utilization of Raspberry Pi, a camera\nmodule, deep learning model, laptop, and cloud service. Deploying this\ninnovative solution aims to proactively enhance road safety by notifying\nrelevant authorities and drivers about the presence of potholes and cracks to\ntake actions, thereby mitigating potential accidents arising from this\nprevalent road hazard leading to safer road conditions for the whole community."}
{"id": "2505.08940", "pdf": "https://arxiv.org/pdf/2505.08940", "abs": "https://arxiv.org/abs/2505.08940", "authors": ["Jeremie Blanchard", "Lisa Casino", "Jordan Gierschendorf"], "title": "NeurIPS 2024 Ariel Data Challenge: Characterisation of Exoplanetary Atmospheres Using a Data-Centric Approach", "categories": ["cs.LG", "astro-ph.IM"], "comment": "12 pages", "summary": "The characterization of exoplanetary atmospheres through spectral analysis is\na complex challenge. The NeurIPS 2024 Ariel Data Challenge, in collaboration\nwith the European Space Agency's (ESA) Ariel mission, provided an opportunity\nto explore machine learning techniques for extracting atmospheric compositions\nfrom simulated spectral data. In this work, we focus on a data-centric business\napproach, prioritizing generalization over competition-specific optimization.\nWe briefly outline multiple experimental axes, including feature extraction,\nsignal transformation, and heteroskedastic uncertainty modeling. Our\nexperiments demonstrate that uncertainty estimation plays a crucial role in the\nGaussian Log-Likelihood (GLL) score, impacting performance by several\npercentage points. Despite improving the GLL score by 11%, our results\nhighlight the inherent limitations of tabular modeling and feature engineering\nfor this task, as well as the constraints of a business-driven approach within\na Kaggle-style competition framework. Our findings emphasize the trade-offs\nbetween model simplicity, interpretability, and generalization in astrophysical\ndata analysis."}
{"id": "2505.09407", "pdf": "https://arxiv.org/pdf/2505.09407", "abs": "https://arxiv.org/abs/2505.09407", "authors": ["Subrit Dikshit", "Ritu Tiwari", "Priyank Jain"], "title": "Multilingual Machine Translation with Quantum Encoder Decoder Attention-based Convolutional Variational Circuits", "categories": ["cs.CL", "cs.AI", "cs.ET"], "comment": "12 pages, 12 figures", "summary": "Cloud-based multilingual translation services like Google Translate and\nMicrosoft Translator achieve state-of-the-art translation capabilities. These\nservices inherently use large multilingual language models such as GRU, LSTM,\nBERT, GPT, T5, or similar encoder-decoder architectures with attention\nmechanisms as the backbone. Also, new age natural language systems, for\ninstance ChatGPT and DeepSeek, have established huge potential in multiple\ntasks in natural language processing. At the same time, they also possess\noutstanding multilingual translation capabilities. However, these models use\nthe classical computing realm as a backend. QEDACVC (Quantum Encoder Decoder\nAttention-based Convolutional Variational Circuits) is an alternate solution\nthat explores the quantum computing realm instead of the classical computing\nrealm to study and demonstrate multilingual machine translation. QEDACVC\nintroduces the quantum encoder-decoder architecture that simulates and runs on\nquantum computing hardware via quantum convolution, quantum pooling, quantum\nvariational circuit, and quantum attention as software alterations. QEDACVC\nachieves an Accuracy of 82% when trained on the OPUS dataset for English,\nFrench, German, and Hindi corpora for multilingual translations."}
{"id": "2505.09341", "pdf": "https://arxiv.org/pdf/2505.09341", "abs": "https://arxiv.org/abs/2505.09341", "authors": ["Evžen Wybitul"], "title": "Access Controls Will Solve the Dual-Use Dilemma", "categories": ["cs.AI"], "comment": null, "summary": "AI safety systems face a dual-use dilemma. Since the same request can be\neither harmless or harmful depending on who made it and why, if the system\nmakes decisions based solely on the request's content, it will refuse some\nlegitimate queries and let pass harmful ones. To address this, we propose a\nconceptual access control framework, based on verified user credentials (such\nas institutional affiliation) and classifiers that assign model outputs to risk\ncategories (such as advanced virology). The system permits responses only when\nthe user's verified credentials match the category's requirements. For\nimplementation of the model output classifiers, we introduce a theoretical\napproach utilizing small, gated expert modules integrated into the generator\nmodel, trained with gradient routing, that enable efficient risk detection\nwithout the capability gap problems of external monitors. While open questions\nremain about the verification mechanisms, risk categories, and the technical\nimplementation, our framework makes the first step toward enabling granular\ngovernance of AI capabilities: verified users gain access to specialized\nknowledge without arbitrary restrictions, while adversaries are blocked from\nit. This contextual approach reconciles model utility with robust safety,\naddressing the dual-use dilemma."}
{"id": "2505.08886", "pdf": "https://arxiv.org/pdf/2505.08886", "abs": "https://arxiv.org/abs/2505.08886", "authors": ["Hamideh Khaleghpour", "Brett McKinney"], "title": "Optimizing Neuro-Fuzzy and Colonial Competition Algorithms for Skin Cancer Diagnosis in Dermatoscopic Images", "categories": ["cs.CV", "cs.LG"], "comment": "7 pages, 10 figures. Accepted at the 2nd Asia Pacific Computer\n  Systems Conference (APCS 2024), March 15-17, 2024", "summary": "The rising incidence of skin cancer, coupled with limited public awareness\nand a shortfall in clinical expertise, underscores an urgent need for advanced\ndiagnostic aids. Artificial Intelligence (AI) has emerged as a promising tool\nin this domain, particularly for distinguishing malignant from benign skin\nlesions. Leveraging publicly available datasets of skin lesions, researchers\nhave been developing AI-based diagnostic solutions. However, the integration of\nsuch computer systems in clinical settings is still nascent. This study aims to\nbridge this gap by employing a fusion of image processing techniques and\nmachine learning algorithms, specifically neuro-fuzzy and colonial competition\napproaches. Applied to dermoscopic images from the ISIC database, our method\nachieved a notable accuracy of 94% on a dataset of 560 images. These results\nunderscore the potential of our approach in aiding clinicians in the early\ndetection of melanoma, thereby contributing significantly to skin cancer\ndiagnostics."}
{"id": "2505.08941", "pdf": "https://arxiv.org/pdf/2505.08941", "abs": "https://arxiv.org/abs/2505.08941", "authors": ["Gavin Hull", "Alex Bihlo"], "title": "ForeCite: Adapting Pre-Trained Language Models to Predict Future Citation Rates of Academic Papers", "categories": ["cs.LG", "cs.CL"], "comment": "16 pages, 13 figures", "summary": "Predicting the future citation rates of academic papers is an important step\ntoward the automation of research evaluation and the acceleration of scientific\nprogress. We present $\\textbf{ForeCite}$, a simple but powerful framework to\nappend pre-trained causal language models with a linear head for average\nmonthly citation rate prediction. Adapting transformers for regression tasks,\nForeCite achieves a test correlation of $\\rho = 0.826$ on a curated dataset of\n900K+ biomedical papers published between 2000 and 2024, a 27-point improvement\nover the previous state-of-the-art. Comprehensive scaling-law analysis reveals\nconsistent gains across model sizes and data volumes, while temporal holdout\nexperiments confirm practical robustness. Gradient-based saliency heatmaps\nsuggest a potentially undue reliance on titles and abstract texts. These\nresults establish a new state-of-the-art in forecasting the long-term influence\nof academic research and lay the groundwork for the automated, high-fidelity\nevaluation of scientific contributions."}
{"id": "2505.09519", "pdf": "https://arxiv.org/pdf/2505.09519", "abs": "https://arxiv.org/abs/2505.09519", "authors": ["Zongqian Li", "Yixuan Su", "Nigel Collier"], "title": "PT-MoE: An Efficient Finetuning Framework for Integrating Mixture-of-Experts into Prompt Tuning", "categories": ["cs.CL"], "comment": null, "summary": "Parameter-efficient fine-tuning (PEFT) methods have shown promise in adapting\nlarge language models, yet existing approaches exhibit counter-intuitive\nphenomena: integrating router into prompt tuning (PT) increases training\nefficiency yet does not improve performance universally; parameter reduction\nthrough matrix decomposition can improve performance in specific domains.\nMotivated by these observations and the modular nature of PT, we propose\nPT-MoE, a novel framework that integrates matrix decomposition with\nmixture-of-experts (MoE) routing for efficient PT. Results across 17 datasets\ndemonstrate that PT-MoE achieves state-of-the-art performance in both question\nanswering (QA) and mathematical problem solving tasks, improving F1 score by\n1.49 points over PT and 2.13 points over LoRA in QA tasks, while enhancing\nmathematical accuracy by 10.75 points over PT and 0.44 points over LoRA, all\nwhile using 25% fewer parameters than LoRA. Our analysis reveals that while PT\nmethods generally excel in QA tasks and LoRA-based methods in math datasets,\nthe integration of matrix decomposition and MoE in PT-MoE yields complementary\nbenefits: decomposition enables efficient parameter sharing across experts\nwhile MoE provides dynamic adaptation, collectively enabling PT-MoE to\ndemonstrate cross-task consistency and generalization abilities. These\nfindings, along with ablation studies on routing mechanisms and architectural\ncomponents, provide insights for future PEFT methods."}
{"id": "2505.09396", "pdf": "https://arxiv.org/pdf/2505.09396", "abs": "https://arxiv.org/abs/2505.09396", "authors": ["Vince Trencsenyi", "Agnieszka Mensfelt", "Kostas Stathis"], "title": "The Influence of Human-inspired Agentic Sophistication in LLM-driven Strategic Reasoners", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "The rapid rise of large language models (LLMs) has shifted artificial\nintelligence (AI) research toward agentic systems, motivating the use of weaker\nand more flexible notions of agency. However, this shift raises key questions\nabout the extent to which LLM-based agents replicate human strategic reasoning,\nparticularly in game-theoretic settings. In this context, we examine the role\nof agentic sophistication in shaping artificial reasoners' performance by\nevaluating three agent designs: a simple game-theoretic model, an unstructured\nLLM-as-agent model, and an LLM integrated into a traditional agentic framework.\nUsing guessing games as a testbed, we benchmarked these agents against human\nparticipants across general reasoning patterns and individual role-based\nobjectives. Furthermore, we introduced obfuscated game scenarios to assess\nagents' ability to generalise beyond training distributions. Our analysis,\ncovering over 2000 reasoning samples across 25 agent configurations, shows that\nhuman-inspired cognitive structures can enhance LLM agents' alignment with\nhuman strategic behaviour. Still, the relationship between agentic design\ncomplexity and human-likeness is non-linear, highlighting a critical dependence\non underlying LLM capabilities and suggesting limits to simple architectural\naugmentation."}
{"id": "2505.08909", "pdf": "https://arxiv.org/pdf/2505.08909", "abs": "https://arxiv.org/abs/2505.08909", "authors": ["Deliang Wei", "Peng Chen", "Haobo Xu", "Jiale Yao", "Fang Li", "Tieyong Zeng"], "title": "Learning Cocoercive Conservative Denoisers via Helmholtz Decomposition for Poisson Inverse Problems", "categories": ["cs.CV", "cs.LG", "math.FA", "math.OC", "94A08, 47H10, 47J26, 46N10, 47N10"], "comment": "31 pages", "summary": "Plug-and-play (PnP) methods with deep denoisers have shown impressive results\nin imaging problems. They typically require strong convexity or smoothness of\nthe fidelity term and a (residual) non-expansive denoiser for convergence.\nThese assumptions, however, are violated in Poisson inverse problems, and\nnon-expansiveness can hinder denoising performance. To address these\nchallenges, we propose a cocoercive conservative (CoCo) denoiser, which may be\n(residual) expansive, leading to improved denoising. By leveraging the\ngeneralized Helmholtz decomposition, we introduce a novel training strategy\nthat combines Hamiltonian regularization to promote conservativeness and\nspectral regularization to ensure cocoerciveness. We prove that CoCo denoiser\nis a proximal operator of a weakly convex function, enabling a restoration\nmodel with an implicit weakly convex prior. The global convergence of PnP\nmethods to a stationary point of this restoration model is established.\nExtensive experimental results demonstrate that our approach outperforms\nclosely related methods in both visual quality and quantitative metrics."}
{"id": "2505.08964", "pdf": "https://arxiv.org/pdf/2505.08964", "abs": "https://arxiv.org/abs/2505.08964", "authors": ["Majed Jaber", "Julien Michel", "Nicolas Boutry", "Pierre Parrend"], "title": "GPML: Graph Processing for Machine Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "The dramatic increase of complex, multi-step, and rapidly evolving attacks in\ndynamic networks involves advanced cyber-threat detectors. The GPML (Graph\nProcessing for Machine Learning) library addresses this need by transforming\nraw network traffic traces into graph representations, enabling advanced\ninsights into network behaviors. The library provides tools to detect anomalies\nin interaction and community shifts in dynamic networks. GPML supports\ncommunity and spectral metrics extraction, enhancing both real-time detection\nand historical forensics analysis. This library supports modern cybersecurity\nchallenges with a robust, graph-based approach."}
{"id": "2505.09595", "pdf": "https://arxiv.org/pdf/2505.09595", "abs": "https://arxiv.org/abs/2505.09595", "authors": ["Abdullah Mushtaq", "Imran Taj", "Rafay Naeem", "Ibrahim Ghaznavi", "Junaid Qadir"], "title": "WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "comment": "Preprint. Submitted to the Journal of Artificial Intelligence\n  Research (JAIR) on April 29, 2025", "summary": "Large Language Models (LLMs) are predominantly trained and aligned in ways\nthat reinforce Western-centric epistemologies and socio-cultural norms, leading\nto cultural homogenization and limiting their ability to reflect global\ncivilizational plurality. Existing benchmarking frameworks fail to adequately\ncapture this bias, as they rely on rigid, closed-form assessments that overlook\nthe complexity of cultural inclusivity. To address this, we introduce\nWorldView-Bench, a benchmark designed to evaluate Global Cultural Inclusivity\n(GCI) in LLMs by analyzing their ability to accommodate diverse worldviews. Our\napproach is grounded in the Multiplex Worldview proposed by Senturk et al.,\nwhich distinguishes between Uniplex models, reinforcing cultural\nhomogenization, and Multiplex models, which integrate diverse perspectives.\nWorldView-Bench measures Cultural Polarization, the exclusion of alternative\nperspectives, through free-form generative evaluation rather than conventional\ncategorical benchmarks. We implement applied multiplexity through two\nintervention strategies: (1) Contextually-Implemented Multiplex LLMs, where\nsystem prompts embed multiplexity principles, and (2) Multi-Agent System\n(MAS)-Implemented Multiplex LLMs, where multiple LLM agents representing\ndistinct cultural perspectives collaboratively generate responses. Our results\ndemonstrate a significant increase in Perspectives Distribution Score (PDS)\nentropy from 13% at baseline to 94% with MAS-Implemented Multiplex LLMs,\nalongside a shift toward positive sentiment (67.7%) and enhanced cultural\nbalance. These findings highlight the potential of multiplex-aware AI\nevaluation in mitigating cultural bias in LLMs, paving the way for more\ninclusive and ethically aligned AI systems."}
{"id": "2505.09412", "pdf": "https://arxiv.org/pdf/2505.09412", "abs": "https://arxiv.org/abs/2505.09412", "authors": ["Paul Kobialka", "Lina Gerlach", "Francesco Leofante", "Erika Ábrahám", "Silvia Lizeth Tapia Tarifa", "Einar Broch Johnsen"], "title": "Counterfactual Strategies for Markov Decision Processes", "categories": ["cs.AI", "I.2.m"], "comment": null, "summary": "Counterfactuals are widely used in AI to explain how minimal changes to a\nmodel's input can lead to a different output. However, established methods for\ncomputing counterfactuals typically focus on one-step decision-making, and are\nnot directly applicable to sequential decision-making tasks. This paper fills\nthis gap by introducing counterfactual strategies for Markov Decision Processes\n(MDPs). During MDP execution, a strategy decides which of the enabled actions\n(with known probabilistic effects) to execute next. Given an initial strategy\nthat reaches an undesired outcome with a probability above some limit, we\nidentify minimal changes to the initial strategy to reduce that probability\nbelow the limit. We encode such counterfactual strategies as solutions to\nnon-linear optimization problems, and further extend our encoding to synthesize\ndiverse counterfactual strategies. We evaluate our approach on four real-world\ndatasets and demonstrate its practical viability in sophisticated sequential\ndecision-making tasks."}
{"id": "2505.08910", "pdf": "https://arxiv.org/pdf/2505.08910", "abs": "https://arxiv.org/abs/2505.08910", "authors": ["Nahid Alam", "Karthik Reddy Kanjula", "Surya Guthikonda", "Timothy Chung", "Bala Krishna S Vegesna", "Abhipsha Das", "Anthony Susevski", "Ryan Sze-Yin Chan", "S M Iftekhar Uddin", "Shayekh Bin Islam", "Roshan Santhosh", "Snegha A", "Drishti Sharma", "Chen Liu", "Isha Chaturvedi", "Genta Indra Winata", "Ashvanth. S", "Snehanshu Mukherjee", "Alham Fikri Aji"], "title": "Behind Maya: Building a Multilingual Vision Language Model", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted at VLMs4ALL CVPR 2025 Workshop; corrected workshop name\n  spelling", "summary": "In recent times, we have seen a rapid development of large Vision-Language\nModels (VLMs). They have shown impressive results on academic benchmarks,\nprimarily in widely spoken languages but lack performance on low-resource\nlanguages and varied cultural contexts. To address these limitations, we\nintroduce Maya, an open-source Multilingual VLM. Our contributions are: 1) a\nmultilingual image-text pretraining dataset in eight languages, based on the\nLLaVA pretraining dataset; and 2) a multilingual image-text model supporting\nthese languages, enhancing cultural and linguistic comprehension in\nvision-language tasks. Code available at https://github.com/nahidalam/maya."}
{"id": "2505.08977", "pdf": "https://arxiv.org/pdf/2505.08977", "abs": "https://arxiv.org/abs/2505.08977", "authors": ["Hossein Babaei", "Mel White", "Sina Alemohammad", "Richard G. Baraniuk"], "title": "SaFARi: State-Space Models for Frame-Agnostic Representation", "categories": ["cs.LG", "eess.AS", "eess.IV", "eess.SP"], "comment": "13 pages, 5 figures", "summary": "State-Space Models (SSMs) have re-emerged as a powerful tool for online\nfunction approximation, and as the backbone of machine learning models for\nlong-range dependent data. However, to date, only a few polynomial bases have\nbeen explored for this purpose, and the state-of-the-art implementations were\nbuilt upon the best of a few limited options. In this paper, we present a\ngeneralized method for building an SSM with any frame or basis, rather than\nbeing restricted to polynomials. This framework encompasses the approach known\nas HiPPO, but also permits an infinite diversity of other possible \"species\"\nwithin the SSM architecture. We dub this approach SaFARi: SSMs for\nFrame-Agnostic Representation."}
{"id": "2505.08795", "pdf": "https://arxiv.org/pdf/2505.08795", "abs": "https://arxiv.org/abs/2505.08795", "authors": ["Andres Anabalon", "Hugo Garces", "Julio Oliva", "Jose Cifuentes"], "title": "The Geometry of Meaning: Perfect Spacetime Representations of Hierarchical Structures", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "7 pages, 3 figures", "summary": "We show that there is a fast algorithm that embeds hierarchical structures in\nthree-dimensional Minkowski spacetime. The correlation of data ends up purely\nencoded in the causal structure. Our model relies solely on oriented token\npairs -- local hierarchical signals -- with no access to global symbolic\nstructure. We apply our method to the corpus of \\textit{WordNet}. We provide a\nperfect embedding of the mammal sub-tree including ambiguities (more than one\nhierarchy per node) in such a way that the hierarchical structures get\ncompletely codified in the geometry and exactly reproduce the ground-truth. We\nextend this to a perfect embedding of the maximal unambiguous subset of the\n\\textit{WordNet} with 82{,}115 noun tokens and a single hierarchy per token. We\nintroduce a novel retrieval mechanism in which causality, not distance, governs\nhierarchical access. Our results seem to indicate that all discrete data has a\nperfect geometrical representation that is three-dimensional. The resulting\nembeddings are nearly conformally invariant, indicating deep connections with\ngeneral relativity and field theory. These results suggest that concepts,\ncategories, and their interrelations, namely hierarchical meaning itself, is\ngeometric."}
{"id": "2505.09518", "pdf": "https://arxiv.org/pdf/2505.09518", "abs": "https://arxiv.org/abs/2505.09518", "authors": ["Maris F. L. Galesloot", "Roman Andriushchenko", "Milan Češka", "Sebastian Junges", "Nils Jansen"], "title": "\\textsc{rfPG}: Robust Finite-Memory Policy Gradients for Hidden-Model POMDPs", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted for publication at IJCAI 2025", "summary": "Partially observable Markov decision processes (POMDPs) model specific\nenvironments in sequential decision-making under uncertainty. Critically,\noptimal policies for POMDPs may not be robust against perturbations in the\nenvironment. Hidden-model POMDPs (HM-POMDPs) capture sets of different\nenvironment models, that is, POMDPs with a shared action and observation space.\nThe intuition is that the true model is hidden among a set of potential models,\nand it is unknown which model will be the environment at execution time. A\npolicy is robust for a given HM-POMDP if it achieves sufficient performance for\neach of its POMDPs. We compute such robust policies by combining two orthogonal\ntechniques: (1) a deductive formal verification technique that supports\ntractable robust policy evaluation by computing a worst-case POMDP within the\nHM-POMDP and (2) subgradient ascent to optimize the candidate policy for a\nworst-case POMDP. The empirical evaluation shows that, compared to various\nbaselines, our approach (1) produces policies that are more robust and\ngeneralize better to unseen POMDPs and (2) scales to HM-POMDPs that consist of\nover a hundred thousand environments."}
{"id": "2505.08961", "pdf": "https://arxiv.org/pdf/2505.08961", "abs": "https://arxiv.org/abs/2505.08961", "authors": ["Yancheng Wang", "Nebojsa Jojic", "Yingzhen Yang"], "title": "Differentiable Channel Selection in Self-Attention For Person Re-Identification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In this paper, we propose a novel attention module termed the Differentiable\nChannel Selection Attention module, or the DCS-Attention module. In contrast\nwith conventional self-attention, the DCS-Attention module features selection\nof informative channels in the computation of the attention weights. The\nselection of the feature channels is performed in a differentiable manner,\nenabling seamless integration with DNN training. Our DCS-Attention is\ncompatible with either fixed neural network backbones or learnable backbones\nwith Differentiable Neural Architecture Search (DNAS), leading to DCS with\nFixed Backbone (DCS-FB) and DCS-DNAS, respectively. Importantly, our\nDCS-Attention is motivated by the principle of Information Bottleneck (IB), and\na novel variational upper bound for the IB loss, which can be optimized by SGD,\nis derived and incorporated into the training loss of the networks with the\nDCS-Attention modules. In this manner, a neural network with DCS-Attention\nmodules is capable of selecting the most informative channels for feature\nextraction so that it enjoys state-of-the-art performance for the Re-ID task.\nExtensive experiments on multiple person Re-ID benchmarks using both DCS-FB and\nDCS-DNAS show that DCS-Attention significantly enhances the prediction accuracy\nof DNNs for person Re-ID, which demonstrates the effectiveness of DCS-Attention\nin learning discriminative features critical to identifying person identities.\nThe code of our work is available at\nhttps://github.com/Statistical-Deep-Learning/DCS-Attention."}
{"id": "2505.08982", "pdf": "https://arxiv.org/pdf/2505.08982", "abs": "https://arxiv.org/abs/2505.08982", "authors": ["Jiachen Qian", "Yang Zheng"], "title": "Model-free Online Learning for the Kalman Filter: Forgetting Factor and Logarithmic Regret", "categories": ["cs.LG", "cs.SY", "eess.SP", "eess.SY"], "comment": null, "summary": "We consider the problem of online prediction for an unknown, non-explosive\nlinear stochastic system. With a known system model, the optimal predictor is\nthe celebrated Kalman filter. In the case of unknown systems, existing\napproaches based on recursive least squares and its variants may suffer from\ndegraded performance due to the highly imbalanced nature of the regression\nmodel. This imbalance can easily lead to overfitting and thus degrade\nprediction accuracy. We tackle this problem by injecting an inductive bias into\nthe regression model via {exponential forgetting}. While exponential forgetting\nis a common wisdom in online learning, it is typically used for re-weighting\ndata. In contrast, our approach focuses on balancing the regression model. This\nachieves a better trade-off between {regression} and {regularization errors},\nand simultaneously reduces the {accumulation error}. With new proof techniques,\nwe also provide a sharper logarithmic regret bound of $O(\\log^3 N)$, where $N$\nis the number of observations."}
{"id": "2505.08823", "pdf": "https://arxiv.org/pdf/2505.08823", "abs": "https://arxiv.org/abs/2505.08823", "authors": ["Cody Steinmetz", "Gavin Childress", "Aaron Herbst", "Gavin Jones", "Jasdeep Singh", "Eli Vang", "Keagan Weinstock"], "title": "An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have transformed natural-language processing,\nyet their scale makes real-world deployment costly. Post-training quantization\nreduces memory and computation but often degrades accuracy, while\nquantization-aware training can recover performance at the cost of extra\ntraining. Pushing quantization to the ternary (2-bit) regime yields even larger\nsavings but is notoriously unstable. Building on recent work showing that a\nbias-free, RMS-normalized Transformer with straight-through estimation can\nreach 1.58-bit precision, we demonstrate that simply inserting RMS\nnormalization before every linear projection and applying a gradual, layer-wise\nquantization schedule stably fine-tunes full-precision checkpoints into ternary\nLLMs. Our approach matches or surpasses more elaborate knowledge-distillation\npipelines on standard language-modeling benchmarks without adding model\ncomplexity. These results indicate that careful normalization alone can close\nmuch of the accuracy gap between ternary and full-precision LLMs, making\nultra-low-bit inference practical."}
{"id": "2505.09614", "pdf": "https://arxiv.org/pdf/2505.09614", "abs": "https://arxiv.org/abs/2505.09614", "authors": ["Anthony GX-Chen", "Dongyan Lin", "Mandana Samiei", "Doina Precup", "Blake A. Richards", "Rob Fergus", "Kenneth Marino"], "title": "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Language model (LM) agents are increasingly used as autonomous\ndecision-makers who need to actively gather information to guide their\ndecisions. A crucial cognitive skill for such agents is the efficient\nexploration and understanding of the causal structure of the world -- key to\nrobust, scientifically grounded reasoning. Yet, it remains unclear whether LMs\npossess this capability or exhibit systematic biases leading to erroneous\nconclusions. In this work, we examine LMs' ability to explore and infer causal\nrelationships, using the well-established \"Blicket Test\" paradigm from\ndevelopmental psychology. We find that LMs reliably infer the common, intuitive\ndisjunctive causal relationships but systematically struggle with the unusual,\nyet equally (or sometimes even more) evidenced conjunctive ones. This\n\"disjunctive bias\" persists across model families, sizes, and prompting\nstrategies, and performance further declines as task complexity increases.\nInterestingly, an analogous bias appears in human adults, suggesting that LMs\nmay have inherited deep-seated reasoning heuristics from their training data.\nTo this end, we quantify similarities between LMs and humans, finding that LMs\nexhibit adult-like inference profiles (but not children-like). Finally, we\npropose a test-time sampling method which explicitly samples and eliminates\nhypotheses about causal relationships from the LM. This scalable approach\nsignificantly reduces the disjunctive bias and moves LMs closer to the goal of\nscientific, causally rigorous reasoning."}
{"id": "2505.08971", "pdf": "https://arxiv.org/pdf/2505.08971", "abs": "https://arxiv.org/abs/2505.08971", "authors": ["Yangyi Chen", "Hao Peng", "Tong Zhang", "Heng Ji"], "title": "Prioritizing Image-Related Tokens Enhances Vision-Language Pre-Training", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "The code will be available at https://github.com/Yangyi-Chen/PRIOR", "summary": "In standard large vision-language models (LVLMs) pre-training, the model\ntypically maximizes the joint probability of the caption conditioned on the\nimage via next-token prediction (NTP); however, since only a small subset of\ncaption tokens directly relates to the visual content, this naive NTP\nunintentionally fits the model to noise and increases the risk of\nhallucination. We present PRIOR, a simple vision-language pre-training approach\nthat addresses this issue by prioritizing image-related tokens through\ndifferential weighting in the NTP loss, drawing from the importance sampling\nframework. PRIOR introduces a reference model-a text-only large language model\n(LLM) trained on the captions without image inputs, to weight each token based\non its probability for LVLMs training. Intuitively, tokens that are directly\nrelated to the visual inputs are harder to predict without the image and thus\nreceive lower probabilities from the text-only reference LLM. During training,\nwe implement a token-specific re-weighting term based on the importance scores\nto adjust each token's loss. We implement PRIOR in two distinct settings: LVLMs\nwith visual encoders and LVLMs without visual encoders. We observe 19% and 8%\naverage relative improvement, respectively, on several vision-language\nbenchmarks compared to NTP. In addition, PRIOR exhibits superior scaling\nproperties, as demonstrated by significantly higher scaling coefficients,\nindicating greater potential for performance gains compared to NTP given\nincreasing compute and data."}
{"id": "2505.09003", "pdf": "https://arxiv.org/pdf/2505.09003", "abs": "https://arxiv.org/abs/2505.09003", "authors": ["Zeki Doruk Erden", "Donia Gasmi", "Boi Faltings"], "title": "Continual Reinforcement Learning via Autoencoder-Driven Task and New Environment Recognition", "categories": ["cs.LG", "cs.AI"], "comment": "Published in the Autonomous Robots and Multirobot Systems (ARMS)\n  workshop at AAMAS 2025", "summary": "Continual learning for reinforcement learning agents remains a significant\nchallenge, particularly in preserving and leveraging existing information\nwithout an external signal to indicate changes in tasks or environments. In\nthis study, we explore the effectiveness of autoencoders in detecting new tasks\nand matching observed environments to previously encountered ones. Our approach\nintegrates policy optimization with familiarity autoencoders within an\nend-to-end continual learning system. This system can recognize and learn new\ntasks or environments while preserving knowledge from earlier experiences and\ncan selectively retrieve relevant knowledge when re-encountering a known\nenvironment. Initial results demonstrate successful continual learning without\nexternal signals to indicate task changes or reencounters, showing promise for\nthis methodology."}
{"id": "2505.08842", "pdf": "https://arxiv.org/pdf/2505.08842", "abs": "https://arxiv.org/abs/2505.08842", "authors": ["Zekun Wu", "Seonglae Cho", "Umar Mohammed", "Cristian Munoz", "Kleyton Costa", "Xin Guan", "Theo King", "Ze Wang", "Emre Kazim", "Adriano Koshiyama"], "title": "LibVulnWatch: A Deep Assessment Agent System and Leaderboard for Uncovering Hidden Vulnerabilities in Open-Source AI Libraries", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Open-source AI libraries are foundational to modern AI systems but pose\nsignificant, underexamined risks across security, licensing, maintenance,\nsupply chain integrity, and regulatory compliance. We present LibVulnWatch, a\ngraph-based agentic assessment framework that performs deep, source-grounded\nevaluations of these libraries. Built on LangGraph, the system coordinates a\ndirected acyclic graph of specialized agents to extract, verify, and quantify\nrisk using evidence from trusted sources such as repositories, documentation,\nand vulnerability databases. LibVulnWatch generates reproducible,\ngovernance-aligned scores across five critical domains, publishing them to a\npublic leaderboard for longitudinal ecosystem monitoring. Applied to 20 widely\nused libraries, including ML frameworks, LLM inference engines, and agent\norchestration tools, our system covers up to 88% of OpenSSF Scorecard checks\nwhile uncovering up to 19 additional risks per library. These include critical\nRemote Code Execution (RCE) vulnerabilities, absent Software Bills of Materials\n(SBOMs), licensing constraints, undocumented telemetry, and widespread gaps in\nregulatory documentation and auditability. By translating high-level governance\nprinciples into practical, verifiable metrics, LibVulnWatch advances technical\nAI governance with a scalable, transparent mechanism for continuous supply\nchain risk assessment and informed library selection."}
{"id": "2412.15404", "pdf": "https://arxiv.org/pdf/2412.15404", "abs": "https://arxiv.org/abs/2412.15404", "authors": ["Ahmet Yasin Aytar", "Kemal Kilic", "Kamer Kaya"], "title": "A Retrieval-Augmented Generation Framework for Academic Literature Navigation in Data Science", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "In the rapidly evolving field of data science, efficiently navigating the\nexpansive body of academic literature is crucial for informed decision-making\nand innovation. This paper presents an enhanced Retrieval-Augmented Generation\n(RAG) application, an artificial intelligence (AI)-based system designed to\nassist data scientists in accessing precise and contextually relevant academic\nresources. The AI-powered application integrates advanced techniques, including\nthe GeneRation Of BIbliographic Data (GROBID) technique for extracting\nbibliographic information, fine-tuned embedding models, semantic chunking, and\nan abstract-first retrieval method, to significantly improve the relevance and\naccuracy of the retrieved information. This implementation of AI specifically\naddresses the challenge of academic literature navigation. A comprehensive\nevaluation using the Retrieval-Augmented Generation Assessment System (RAGAS)\nframework demonstrates substantial improvements in key metrics, particularly\nContext Relevance, underscoring the system's effectiveness in reducing\ninformation overload and enhancing decision-making processes. Our findings\nhighlight the potential of this enhanced Retrieval-Augmented Generation system\nto transform academic exploration within data science, ultimately advancing the\nworkflow of research and innovation in the field."}
{"id": "2505.08999", "pdf": "https://arxiv.org/pdf/2505.08999", "abs": "https://arxiv.org/abs/2505.08999", "authors": ["Wei-Long Tian", "Peng Gao", "Xiao Liu", "Long Xu", "Hamido Fujita", "Hanan Aljuai", "Mao-Li Wang"], "title": "Towards Adaptive Meta-Gradient Adversarial Examples for Visual Tracking", "categories": ["cs.CV"], "comment": null, "summary": "In recent years, visual tracking methods based on convolutional neural\nnetworks and Transformers have achieved remarkable performance and have been\nsuccessfully applied in fields such as autonomous driving. However, the\nnumerous security issues exposed by deep learning models have gradually\naffected the reliable application of visual tracking methods in real-world\nscenarios. Therefore, how to reveal the security vulnerabilities of existing\nvisual trackers through effective adversarial attacks has become a critical\nproblem that needs to be addressed. To this end, we propose an adaptive\nmeta-gradient adversarial attack (AMGA) method for visual tracking. This method\nintegrates multi-model ensembles and meta-learning strategies, combining\nmomentum mechanisms and Gaussian smoothing, which can significantly enhance the\ntransferability and attack effectiveness of adversarial examples. AMGA randomly\nselects models from a large model repository, constructs diverse tracking\nscenarios, and iteratively performs both white- and black-box adversarial\nattacks in each scenario, optimizing the gradient directions of each model.\nThis paradigm minimizes the gap between white- and black-box adversarial\nattacks, thus achieving excellent attack performance in black-box scenarios.\nExtensive experimental results on large-scale datasets such as OTB2015, LaSOT,\nand GOT-10k demonstrate that AMGA significantly improves the attack\nperformance, transferability, and deception of adversarial examples. Codes and\ndata are available at https://github.com/pgao-lab/AMGA."}
{"id": "2505.09011", "pdf": "https://arxiv.org/pdf/2505.09011", "abs": "https://arxiv.org/abs/2505.09011", "authors": ["Antonio Candito", "Matthew D Blackledge", "Richard Holbrey", "Nuria Porta", "Ana Ribeiro", "Fabio Zugni", "Luca D'Erme", "Francesca Castagnoli", "Alina Dragan", "Ricardo Donners", "Christina Messiou", "Nina Tunariu", "Dow-Mu Koh"], "title": "Signal-based AI-driven software solution for automated quantification of metastatic bone disease and treatment response assessment using Whole-Body Diffusion-Weighted MRI (WB-DWI) biomarkers in Advanced Prostate Cancer", "categories": ["cs.LG"], "comment": null, "summary": "We developed an AI-driven software solution to quantify metastatic bone\ndisease from WB-DWI scans. Core technologies include: (i) a weakly-supervised\nResidual U-Net model generating a skeleton probability map to isolate bone;\n(ii) a statistical framework for WB-DWI intensity normalisation, obtaining a\nsignal-normalised b=900s/mm^2 (b900) image; and (iii) a shallow convolutional\nneural network that processes outputs from (i) and (ii) to generate a mask of\nsuspected bone lesions, characterised by higher b900 signal intensity due to\nrestricted water diffusion. This mask is applied to the gADC map to extract TDV\nand gADC statistics. We tested the tool using expert-defined metastatic bone\ndisease delineations on 66 datasets, assessed repeatability of imaging\nbiomarkers (N=10), and compared software-based response assessment with a\nconstruct reference standard based on clinical, laboratory and imaging\nassessments (N=118). Dice score between manual and automated delineations was\n0.6 for lesions within pelvis and spine, with an average surface distance of\n2mm. Relative differences for log-transformed TDV (log-TDV) and median gADC\nwere below 9% and 5%, respectively. Repeatability analysis showed coefficients\nof variation of 4.57% for log-TDV and 3.54% for median gADC, with intraclass\ncorrelation coefficients above 0.9. The software achieved 80.5% accuracy, 84.3%\nsensitivity, and 85.7% specificity in assessing response to treatment compared\nto the construct reference standard. Computation time generating a mask\naveraged 90 seconds per scan. Our software enables reproducible TDV and gADC\nquantification from WB-DWI scans for monitoring metastatic bone disease\nresponse, thus providing potentially useful measurements for clinical\ndecision-making in APC patients."}
{"id": "2505.08902", "pdf": "https://arxiv.org/pdf/2505.08902", "abs": "https://arxiv.org/abs/2505.08902", "authors": ["Lucas McCullum", "Pelagie Ami Agassi", "Leo Anthony Celi", "Daniel K. Ebner", "Chrystinne Oliveira Fernandes", "Rachel S. Hicklen", "Mkliwa Koumbia", "Lisa Soleymani Lehmann", "David Restrepo"], "title": "Performance Gains of LLMs With Humans in a World of LLMs Versus Humans", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": null, "summary": "Currently, a considerable research effort is devoted to comparing LLMs to a\ngroup of human experts, where the term \"expert\" is often ill-defined or\nvariable, at best, in a state of constantly updating LLM releases. Without\nproper safeguards in place, LLMs will threaten to cause harm to the established\nstructure of safe delivery of patient care which has been carefully developed\nthroughout history to keep the safety of the patient at the forefront. A key\ndriver of LLM innovation is founded on community research efforts which, if\ncontinuing to operate under \"humans versus LLMs\" principles, will expedite this\ntrend. Therefore, research efforts moving forward must focus on effectively\ncharacterizing the safe use of LLMs in clinical settings that persist across\nthe rapid development of novel LLM models. In this communication, we\ndemonstrate that rather than comparing LLMs to humans, there is a need to\ndevelop strategies enabling efficient work of humans with LLMs in an almost\nsymbiotic manner."}
{"id": "2505.08795", "pdf": "https://arxiv.org/pdf/2505.08795", "abs": "https://arxiv.org/abs/2505.08795", "authors": ["Andres Anabalon", "Hugo Garces", "Julio Oliva", "Jose Cifuentes"], "title": "The Geometry of Meaning: Perfect Spacetime Representations of Hierarchical Structures", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "7 pages, 3 figures", "summary": "We show that there is a fast algorithm that embeds hierarchical structures in\nthree-dimensional Minkowski spacetime. The correlation of data ends up purely\nencoded in the causal structure. Our model relies solely on oriented token\npairs -- local hierarchical signals -- with no access to global symbolic\nstructure. We apply our method to the corpus of \\textit{WordNet}. We provide a\nperfect embedding of the mammal sub-tree including ambiguities (more than one\nhierarchy per node) in such a way that the hierarchical structures get\ncompletely codified in the geometry and exactly reproduce the ground-truth. We\nextend this to a perfect embedding of the maximal unambiguous subset of the\n\\textit{WordNet} with 82{,}115 noun tokens and a single hierarchy per token. We\nintroduce a novel retrieval mechanism in which causality, not distance, governs\nhierarchical access. Our results seem to indicate that all discrete data has a\nperfect geometrical representation that is three-dimensional. The resulting\nembeddings are nearly conformally invariant, indicating deep connections with\ngeneral relativity and field theory. These results suggest that concepts,\ncategories, and their interrelations, namely hierarchical meaning itself, is\ngeometric."}
{"id": "2505.09018", "pdf": "https://arxiv.org/pdf/2505.09018", "abs": "https://arxiv.org/abs/2505.09018", "authors": ["Adarsh Kumar"], "title": "Multimodal Fusion of Glucose Monitoring and Food Imagery for Caloric Content Prediction", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Effective dietary monitoring is critical for managing Type 2 diabetes, yet\naccurately estimating caloric intake remains a major challenge. While\ncontinuous glucose monitors (CGMs) offer valuable physiological data, they\noften fall short in capturing the full nutritional profile of meals due to\ninter-individual and meal-specific variability. In this work, we introduce a\nmultimodal deep learning framework that jointly leverages CGM time-series data,\nDemographic/Microbiome, and pre-meal food images to enhance caloric estimation.\nOur model utilizes attention based encoding and a convolutional feature\nextraction for meal imagery, multi-layer perceptrons for CGM and Microbiome\ndata followed by a late fusion strategy for joint reasoning. We evaluate our\napproach on a curated dataset of over 40 participants, incorporating\nsynchronized CGM, Demographic and Microbiome data and meal photographs with\nstandardized caloric labels. Our model achieves a Root Mean Squared Relative\nError (RMSRE) of 0.2544, outperforming the baselines models by over 50%. These\nfindings demonstrate the potential of multimodal sensing to improve automated\ndietary assessment tools for chronic disease management."}
{"id": "2505.09017", "pdf": "https://arxiv.org/pdf/2505.09017", "abs": "https://arxiv.org/abs/2505.09017", "authors": ["Bizhan Alipour Pijan", "Serdar Bozdag"], "title": "DyGSSM: Multi-view Dynamic Graph Embeddings with State Space Model Gradient Update", "categories": ["cs.LG", "cs.SI"], "comment": null, "summary": "Most of the dynamic graph representation learning methods involve dividing a\ndynamic graph into discrete snapshots to capture the evolving behavior of nodes\nover time. Existing methods primarily capture only local or global structures\nof each node within a snapshot using message-passing and random walk-based\nmethods. Then, they utilize sequence-based models (e.g., transformers) to\nencode the temporal evolution of node embeddings, and meta-learning techniques\nto update the model parameters. However, these approaches have two limitations.\nFirst, they neglect the extraction of global and local information\nsimultaneously in each snapshot. Second, they fail to consider the model's\nperformance in the current snapshot during parameter updates, resulting in a\nlack of temporal dependency management. Recently, HiPPO (High-order Polynomial\nProjection Operators) algorithm has gained attention for their ability to\noptimize and preserve sequence history in State Space Model (SSM). To address\nthe aforementioned limitations in dynamic graph representation learning, we\npropose a novel method called Multi-view Dynamic Graph Embeddings with State\nSpace Model Gradient Update (DyGSSM). Our approach combines Graph Convolution\nNetworks (GCN) for local feature extraction and random walk with Gated\nRecurrent Unit (GRU) for global feature extraction in each snapshot. We then\nintegrate the local and global features using a cross-attention mechanism.\nAdditionally, we incorporate an SSM based on HiPPO algorithm to account for\nlong-term dependencies when updating model parameters, ensuring that model\nperformance in each snapshot informs subsequent updates. Experiments on five\npublic datasets show that our method outperforms existing baseline and\nstate-of-the-art (SOTA) methods in 17 out of 20 cases."}
{"id": "2505.08905", "pdf": "https://arxiv.org/pdf/2505.08905", "abs": "https://arxiv.org/abs/2505.08905", "authors": ["Michael Majurski", "Cynthia Matuszek"], "title": "Grounding Synthetic Data Evaluations of Language Models in Unsupervised Document Corpora", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Language Models (LMs) continue to advance, improving response quality and\ncoherence. Given Internet-scale training datasets, LMs have likely encountered\nmuch of what users might ask them to generate in some form during their\ntraining. A plethora of evaluation benchmarks have been constructed to assess\nmodel quality, response appropriateness, and reasoning capabilities. However,\nthe human effort required for benchmark construction is limited and being\nrapidly outpaced by the size and scope of the models under evaluation.\nAdditionally, having humans build a benchmark for every possible domain of\ninterest is impractical. Therefore, we propose a methodology for automating the\nconstruction of fact-based synthetic data model evaluations grounded in\ndocument populations. This work leverages those very same LMs to evaluate\ndomain-specific knowledge automatically, using only grounding documents (e.g.,\na textbook) as input. This synthetic data benchmarking approach corresponds\nwell with human curated questions with a Spearman ranking correlation of 0.96\nand a benchmark evaluation Pearson accuracy correlation of 0.79. This novel\ntool supports generating both multiple choice and open-ended synthetic data\nquestions to gain diagnostic insight of LM capability. We apply this\nmethodology to evaluate model performance on a recent relevant arXiv preprint,\ndiscovering a surprisingly strong performance from Gemma3 models."}
{"id": "2505.08798", "pdf": "https://arxiv.org/pdf/2505.08798", "abs": "https://arxiv.org/abs/2505.08798", "authors": ["Mobina Shrestha", "Bishwas Mandal", "Vishal Mandal", "Asis Shrestha"], "title": "In-Context Learning for Label-Efficient Cancer Image Classification in Oncology", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "The application of AI in oncology has been limited by its reliance on large,\nannotated datasets and the need for retraining models for domain-specific\ndiagnostic tasks. Taking heed of these limitations, we investigated in-context\nlearning as a pragmatic alternative to model retraining by allowing models to\nadapt to new diagnostic tasks using only a few labeled examples at inference,\nwithout the need for retraining. Using four vision-language models\n(VLMs)-Paligemma, CLIP, ALIGN and GPT-4o, we evaluated the performance across\nthree oncology datasets: MHIST, PatchCamelyon and HAM10000. To the best of our\nknowledge, this is the first study to compare the performance of multiple VLMs\non different oncology classification tasks. Without any parameter updates, all\nmodels showed significant gains with few-shot prompting, with GPT-4o reaching\nan F1 score of 0.81 in binary classification and 0.60 in multi-class\nclassification settings. While these results remain below the ceiling of fully\nfine-tuned systems, they highlight the potential of ICL to approximate\ntask-specific behavior using only a handful of examples, reflecting how\nclinicians often reason from prior cases. Notably, open-source models like\nPaligemma and CLIP demonstrated competitive gains despite their smaller size,\nsuggesting feasibility for deployment in computing constrained clinical\nenvironments. Overall, these findings highlight the potential of ICL as a\npractical solution in oncology, particularly for rare cancers and\nresource-limited contexts where fine-tuning is infeasible and annotated data is\ndifficult to obtain."}
{"id": "2505.09073", "pdf": "https://arxiv.org/pdf/2505.09073", "abs": "https://arxiv.org/abs/2505.09073", "authors": ["J. Brennan Peace", "Shuowen Hu", "Benjamin S. Riggan"], "title": "2D-3D Attention and Entropy for Pose Robust 2D Facial Recognition", "categories": ["cs.CV"], "comment": "To appear at the IEEE International Conference on Automatic Face and\n  Gesture 2025 (FG2025)", "summary": "Despite recent advances in facial recognition, there remains a fundamental\nissue concerning degradations in performance due to substantial perspective\n(pose) differences between enrollment and query (probe) imagery. Therefore, we\npropose a novel domain adaptive framework to facilitate improved performances\nacross large discrepancies in pose by enabling image-based (2D) representations\nto infer properties of inherently pose invariant point cloud (3D)\nrepresentations. Specifically, our proposed framework achieves better pose\ninvariance by using (1) a shared (joint) attention mapping to emphasize common\npatterns that are most correlated between 2D facial images and 3D facial data\nand (2) a joint entropy regularizing loss to promote better\nconsistency$\\unicode{x2014}$enhancing correlations among the intersecting 2D\nand 3D representations$\\unicode{x2014}$by leveraging both attention maps. This\nframework is evaluated on FaceScape and ARL-VTF datasets, where it outperforms\ncompetitive methods by achieving profile (90$\\unicode{x00b0}$$\\unicode{x002b}$)\nTAR @ 1$\\unicode{x0025}$ FAR improvements of at least 7.1$\\unicode{x0025}$ and\n1.57$\\unicode{x0025}$, respectively."}
{"id": "2505.09022", "pdf": "https://arxiv.org/pdf/2505.09022", "abs": "https://arxiv.org/abs/2505.09022", "authors": ["Annan Yu", "N. Benjamin Erichson"], "title": "Block-Biased Mamba for Long-Range Sequence Processing", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Mamba extends earlier state space models (SSMs) by introducing\ninput-dependent dynamics, and has demonstrated strong empirical performance\nacross a range of domains, including language modeling, computer vision, and\nfoundation models. However, a surprising weakness remains: despite being built\non architectures designed for long-range dependencies, Mamba performs poorly on\nlong-range sequential tasks. Understanding and addressing this gap is important\nfor improving Mamba's universality and versatility. In this work, we analyze\nMamba's limitations through three perspectives: expressiveness, inductive bias,\nand training stability. Our theoretical results show how Mamba falls short in\neach of these aspects compared to earlier SSMs such as S4D. To address these\nissues, we propose $\\text{B}_2\\text{S}_6$, a simple extension of Mamba's S6\nunit that combines block-wise selective dynamics with a channel-specific bias.\nWe prove that these changes equip the model with a better-suited inductive bias\nand improve its expressiveness and stability. Empirically,\n$\\text{B}_2\\text{S}_6$ outperforms S4 and S4D on Long-Range Arena (LRA) tasks\nwhile maintaining Mamba's performance on language modeling benchmarks."}
{"id": "2505.08910", "pdf": "https://arxiv.org/pdf/2505.08910", "abs": "https://arxiv.org/abs/2505.08910", "authors": ["Nahid Alam", "Karthik Reddy Kanjula", "Surya Guthikonda", "Timothy Chung", "Bala Krishna S Vegesna", "Abhipsha Das", "Anthony Susevski", "Ryan Sze-Yin Chan", "S M Iftekhar Uddin", "Shayekh Bin Islam", "Roshan Santhosh", "Snegha A", "Drishti Sharma", "Chen Liu", "Isha Chaturvedi", "Genta Indra Winata", "Ashvanth. S", "Snehanshu Mukherjee", "Alham Fikri Aji"], "title": "Behind Maya: Building a Multilingual Vision Language Model", "categories": ["cs.CV", "cs.CL"], "comment": "Accepted at VLMs4ALL CVPR 2025 Workshop; corrected workshop name\n  spelling", "summary": "In recent times, we have seen a rapid development of large Vision-Language\nModels (VLMs). They have shown impressive results on academic benchmarks,\nprimarily in widely spoken languages but lack performance on low-resource\nlanguages and varied cultural contexts. To address these limitations, we\nintroduce Maya, an open-source Multilingual VLM. Our contributions are: 1) a\nmultilingual image-text pretraining dataset in eight languages, based on the\nLLaVA pretraining dataset; and 2) a multilingual image-text model supporting\nthese languages, enhancing cultural and linguistic comprehension in\nvision-language tasks. Code available at https://github.com/nahidalam/maya."}
{"id": "2505.08800", "pdf": "https://arxiv.org/pdf/2505.08800", "abs": "https://arxiv.org/abs/2505.08800", "authors": ["Olivia Nocentini", "Marta Lagomarsino", "Gokhan Solak", "Younggeol Cho", "Qiyi Tong", "Marta Lorenzini", "Arash Ajoudani"], "title": "Graph-based Online Monitoring of Train Driver States via Facial and Skeletal Features", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Driver fatigue poses a significant challenge to railway safety, with\ntraditional systems like the dead-man switch offering limited and basic\nalertness checks. This study presents an online behavior-based monitoring\nsystem utilizing a customised Directed-Graph Neural Network (DGNN) to classify\ntrain driver's states into three categories: alert, not alert, and\npathological. To optimize input representations for the model, an ablation\nstudy was performed, comparing three feature configurations: skeletal-only,\nfacial-only, and a combination of both. Experimental results show that\ncombining facial and skeletal features yields the highest accuracy (80.88%) in\nthe three-class model, outperforming models using only facial or skeletal\nfeatures. Furthermore, this combination achieves over 99% accuracy in the\nbinary alertness classification. Additionally, we introduced a novel dataset\nthat, for the first time, incorporates simulated pathological conditions into\ntrain driver monitoring, broadening the scope for assessing risks related to\nfatigue and health. This work represents a step forward in enhancing railway\nsafety through advanced online monitoring using vision-based technologies."}
{"id": "2505.09092", "pdf": "https://arxiv.org/pdf/2505.09092", "abs": "https://arxiv.org/abs/2505.09092", "authors": ["Yuhang Wang", "Abdulaziz Alhuraish", "Shengming Yuan", "Hao Zhou"], "title": "OpenLKA: An Open Dataset of Lane Keeping Assist from Recent Car Models under Real-world Driving Conditions", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "Lane Keeping Assist (LKA) is widely adopted in modern vehicles, yet its\nreal-world performance remains underexplored due to proprietary systems and\nlimited data access. This paper presents OpenLKA, the first open, large-scale\ndataset for LKA evaluation and improvement. It includes 400 hours of driving\ndata from 50+ production vehicle models, collected through extensive road\ntesting in Tampa, Florida and global contributions from the Comma.ai driving\ncommunity. The dataset spans a wide range of challenging scenarios, including\ncomplex road geometries, degraded lane markings, adverse weather, lighting\nconditions and surrounding traffic. The dataset is multimodal, comprising: i)\nfull CAN bus streams, decoded using custom reverse-engineered DBC files to\nextract key LKA events (e.g., system disengagements, lane detection failures);\nii) synchronized high-resolution dash-cam video; iii) real-time outputs from\nOpenpilot, providing accurate estimates of road curvature and lane positioning;\niv) enhanced scene annotations generated by Vision Language Models, describing\nlane visibility, pavement quality, weather, lighting, and traffic conditions.\nBy integrating vehicle-internal signals with high-fidelity perception and rich\nsemantic context, OpenLKA provides a comprehensive platform for benchmarking\nthe real-world performance of production LKA systems, identifying\nsafety-critical operational scenarios, and assessing the readiness of current\nroad infrastructure for autonomous driving. The dataset is publicly available\nat: https://github.com/OpenLKA/OpenLKA."}
{"id": "2505.09063", "pdf": "https://arxiv.org/pdf/2505.09063", "abs": "https://arxiv.org/abs/2505.09063", "authors": ["Khalid Rafiq", "Wenjing Liao", "Aditya G. Nair"], "title": "Single-shot prediction of parametric partial differential equations", "categories": ["cs.LG", "cs.NA", "math.NA", "68T07"], "comment": "35 pages, 17 figures", "summary": "We introduce Flexi-VAE, a data-driven framework for efficient single-shot\nforecasting of nonlinear parametric partial differential equations (PDEs),\neliminating the need for iterative time-stepping while maintaining high\naccuracy and stability. Flexi-VAE incorporates a neural propagator that\nadvances latent representations forward in time, aligning latent evolution with\nphysical state reconstruction in a variational autoencoder setting. We evaluate\ntwo propagation strategies, the Direct Concatenation Propagator (DCP) and the\nPositional Encoding Propagator (PEP), and demonstrate, through\nrepresentation-theoretic analysis, that DCP offers superior long-term\ngeneralization by fostering disentangled and physically meaningful latent\nspaces. Geometric diagnostics, including Jacobian spectral analysis, reveal\nthat propagated latent states reside in regions of lower decoder sensitivity\nand more stable local geometry than those derived via direct encoding,\nenhancing robustness for long-horizon predictions. We validate Flexi-VAE on\ncanonical PDE benchmarks, the 1D viscous Burgers equation and the 2D\nadvection-diffusion equation, achieving accurate forecasts across wide\nparametric ranges. The model delivers over 50x CPU and 90x GPU speedups\ncompared to autoencoder-LSTM baselines for large temporal shifts. These results\nposition Flexi-VAE as a scalable and interpretable surrogate modeling tool for\naccelerating high-fidelity simulations in computational fluid dynamics (CFD)\nand other parametric PDE-driven applications, with extensibility to\nhigher-dimensional and more complex systems."}
{"id": "2505.08941", "pdf": "https://arxiv.org/pdf/2505.08941", "abs": "https://arxiv.org/abs/2505.08941", "authors": ["Gavin Hull", "Alex Bihlo"], "title": "ForeCite: Adapting Pre-Trained Language Models to Predict Future Citation Rates of Academic Papers", "categories": ["cs.LG", "cs.CL"], "comment": "16 pages, 13 figures", "summary": "Predicting the future citation rates of academic papers is an important step\ntoward the automation of research evaluation and the acceleration of scientific\nprogress. We present $\\textbf{ForeCite}$, a simple but powerful framework to\nappend pre-trained causal language models with a linear head for average\nmonthly citation rate prediction. Adapting transformers for regression tasks,\nForeCite achieves a test correlation of $\\rho = 0.826$ on a curated dataset of\n900K+ biomedical papers published between 2000 and 2024, a 27-point improvement\nover the previous state-of-the-art. Comprehensive scaling-law analysis reveals\nconsistent gains across model sizes and data volumes, while temporal holdout\nexperiments confirm practical robustness. Gradient-based saliency heatmaps\nsuggest a potentially undue reliance on titles and abstract texts. These\nresults establish a new state-of-the-art in forecasting the long-term influence\nof academic research and lay the groundwork for the automated, high-fidelity\nevaluation of scientific contributions."}
{"id": "2505.08803", "pdf": "https://arxiv.org/pdf/2505.08803", "abs": "https://arxiv.org/abs/2505.08803", "authors": ["Zizhao Hu", "Mohammad Rostami", "Jesse Thomason"], "title": "Multi-modal Synthetic Data Training and Model Collapse: Insights from VLMs and Diffusion Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent research has highlighted the risk of generative model collapse, where\nperformance progressively degrades when continually trained on self-generated\ndata. However, existing exploration on model collapse is limited to single,\nunimodal models, limiting our understanding in more realistic scenarios, such\nas diverse multi-modal AI agents interacting autonomously through synthetic\ndata and continually evolving. We expand the synthetic data training and model\ncollapse study to multi-modal vision-language generative systems, such as\nvision-language models (VLMs) and text-to-image diffusion models, as well as\nrecursive generate-train loops with multiple models. We find that model\ncollapse, previously observed in single-modality generative models, exhibits\ndistinct characteristics in the multi-modal context, such as improved\nvision-language alignment and increased variance in VLM image-captioning task.\nAdditionally, we find that general approaches such as increased decoding\nbudgets, greater model diversity, and relabeling with frozen models can\neffectively mitigate model collapse. Our findings provide initial insights and\npractical guidelines for reducing the risk of model collapse in self-improving\nmulti-agent AI systems and curating robust multi-modal synthetic datasets."}
{"id": "2505.09118", "pdf": "https://arxiv.org/pdf/2505.09118", "abs": "https://arxiv.org/abs/2505.09118", "authors": ["Dayong Liang", "Changmeng Zheng", "Zhiyuan Wen", "Yi Cai", "Xiao-Yong Wei", "Qing Li"], "title": "Seeing Beyond the Scene: Enhancing Vision-Language Models with Interactional Reasoning", "categories": ["cs.CV"], "comment": null, "summary": "Traditional scene graphs primarily focus on spatial relationships, limiting\nvision-language models' (VLMs) ability to reason about complex interactions in\nvisual scenes. This paper addresses two key challenges: (1) conventional\ndetection-to-construction methods produce unfocused, contextually irrelevant\nrelationship sets, and (2) existing approaches fail to form persistent memories\nfor generalizing interaction reasoning to new scenes. We propose\nInteraction-augmented Scene Graph Reasoning (ISGR), a framework that enhances\nVLMs' interactional reasoning through three complementary components. First,\nour dual-stream graph constructor combines SAM-powered spatial relation\nextraction with interaction-aware captioning to generate functionally salient\nscene graphs with spatial grounding. Second, we employ targeted interaction\nqueries to activate VLMs' latent knowledge of object functionalities,\nconverting passive recognition into active reasoning about how objects work\ntogether. Finally, we introduce a lone-term memory reinforcement learning\nstrategy with a specialized interaction-focused reward function that transforms\ntransient patterns into long-term reasoning heuristics. Extensive experiments\ndemonstrate that our approach significantly outperforms baseline methods on\ninteraction-heavy reasoning benchmarks, with particularly strong improvements\non complex scene understanding tasks. The source code can be accessed at\nhttps://github.com/open_upon_acceptance."}
{"id": "2505.09076", "pdf": "https://arxiv.org/pdf/2505.09076", "abs": "https://arxiv.org/abs/2505.09076", "authors": ["Berkay Guler", "Hamid Jafarkhani"], "title": "AdaFortiTran: An Adaptive Transformer Model for Robust OFDM Channel Estimation", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Deep learning models for channel estimation in Orthogonal Frequency Division\nMultiplexing (OFDM) systems often suffer from performance degradation under\nfast-fading channels and low-SNR scenarios. To address these limitations, we\nintroduce the Adaptive Fortified Transformer (AdaFortiTran), a novel model\nspecifically designed to enhance channel estimation in challenging\nenvironments. Our approach employs convolutional layers that exploit locality\nbias to capture strong correlations between neighboring channel elements,\ncombined with a transformer encoder that applies the global Attention mechanism\nto channel patches. This approach effectively models both long-range\ndependencies and spectro-temporal interactions within single OFDM frames. We\nfurther augment the model's adaptability by integrating nonlinear\nrepresentations of available channel statistics SNR, delay spread, and Doppler\nshift as priors. A residual connection is employed to merge global features\nfrom the transformer with local features from early convolutional processing,\nfollowed by final convolutional layers to refine the hierarchical channel\nrepresentation. Despite its compact architecture, AdaFortiTran achieves up to 6\ndB reduction in mean squared error (MSE) compared to state-of-the-art models.\nTested across a wide range of Doppler shifts (200-1000 Hz), SNRs (0 to 25 dB),\nand delay spreads (50-300 ns), it demonstrates superior robustness in\nhigh-mobility environments."}
{"id": "2505.08971", "pdf": "https://arxiv.org/pdf/2505.08971", "abs": "https://arxiv.org/abs/2505.08971", "authors": ["Yangyi Chen", "Hao Peng", "Tong Zhang", "Heng Ji"], "title": "Prioritizing Image-Related Tokens Enhances Vision-Language Pre-Training", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "The code will be available at https://github.com/Yangyi-Chen/PRIOR", "summary": "In standard large vision-language models (LVLMs) pre-training, the model\ntypically maximizes the joint probability of the caption conditioned on the\nimage via next-token prediction (NTP); however, since only a small subset of\ncaption tokens directly relates to the visual content, this naive NTP\nunintentionally fits the model to noise and increases the risk of\nhallucination. We present PRIOR, a simple vision-language pre-training approach\nthat addresses this issue by prioritizing image-related tokens through\ndifferential weighting in the NTP loss, drawing from the importance sampling\nframework. PRIOR introduces a reference model-a text-only large language model\n(LLM) trained on the captions without image inputs, to weight each token based\non its probability for LVLMs training. Intuitively, tokens that are directly\nrelated to the visual inputs are harder to predict without the image and thus\nreceive lower probabilities from the text-only reference LLM. During training,\nwe implement a token-specific re-weighting term based on the importance scores\nto adjust each token's loss. We implement PRIOR in two distinct settings: LVLMs\nwith visual encoders and LVLMs without visual encoders. We observe 19% and 8%\naverage relative improvement, respectively, on several vision-language\nbenchmarks compared to NTP. In addition, PRIOR exhibits superior scaling\nproperties, as demonstrated by significantly higher scaling coefficients,\nindicating greater potential for performance gains compared to NTP given\nincreasing compute and data."}
{"id": "2505.08807", "pdf": "https://arxiv.org/pdf/2505.08807", "abs": "https://arxiv.org/abs/2505.08807", "authors": ["Yuntao Wang", "Yanghe Pan", "Shaolong Guo", "Zhou Su"], "title": "Security of Internet of Agents: Attacks and Countermeasures", "categories": ["cs.CR", "cs.AI"], "comment": "11 pages, 5 figures, 3 tables, submitted to IEEE OJCS", "summary": "With the rise of large language and vision-language models, AI agents have\nevolved into autonomous, interactive systems capable of perception, reasoning,\nand decision-making. As they proliferate across virtual and physical domains,\nthe Internet of Agents (IoA) has emerged as a key infrastructure for enabling\nscalable and secure coordination among heterogeneous agents. This survey offers\na comprehensive examination of the security and privacy landscape in IoA\nsystems. We begin by outlining the IoA architecture and its distinct\nvulnerabilities compared to traditional networks, focusing on four critical\naspects: identity authentication threats, cross-agent trust issues, embodied\nsecurity, and privacy risks. We then review existing and emerging defense\nmechanisms and highlight persistent challenges. Finally, we identify open\nresearch directions to advance the development of resilient and\nprivacy-preserving IoA ecosystems."}
{"id": "2505.09123", "pdf": "https://arxiv.org/pdf/2505.09123", "abs": "https://arxiv.org/abs/2505.09123", "authors": ["Guoying Liang", "Su Yang"], "title": "Promoting SAM for Camouflaged Object Detection via Selective Key Point-based Guidance", "categories": ["cs.CV"], "comment": null, "summary": "Big model has emerged as a new research paradigm that can be applied to\nvarious down-stream tasks with only minor effort for domain adaption.\nCorrespondingly, this study tackles Camouflaged Object Detection (COD)\nleveraging the Segment Anything Model (SAM). The previous studies declared that\nSAM is not workable for COD but this study reveals that SAM works if promoted\nproperly, for which we devise a new framework to render point promotions:\nFirst, we develop the Promotion Point Targeting Network (PPT-net) to leverage\nmulti-scale features in predicting the probabilities of camouflaged objects'\npresences at given candidate points over the image. Then, we develop a key\npoint selection (KPS) algorithm to deploy both positive and negative point\npromotions contrastively to SAM to guide the segmentation. It is the first work\nto facilitate big model for COD and achieves plausible results experimentally\nover the existing methods on 3 data sets under 6 metrics. This study\ndemonstrates an off-the-shelf methodology for COD by leveraging SAM, which\ngains advantage over designing professional models from scratch, not only in\nperformance, but also in turning the problem to a less challenging task, that\nis, seeking informative but not exactly precise promotions."}
{"id": "2505.09085", "pdf": "https://arxiv.org/pdf/2505.09085", "abs": "https://arxiv.org/abs/2505.09085", "authors": ["Jiaxuan Chen", "Yu Qi", "Yueming Wang", "Gang Pan"], "title": "Human-like Cognitive Generalization for Large Models via Brain-in-the-loop Supervision", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advancements in deep neural networks (DNNs), particularly large-scale\nlanguage models, have demonstrated remarkable capabilities in image and natural\nlanguage understanding. Although scaling up model parameters with increasing\nvolume of training data has progressively improved DNN capabilities, achieving\ncomplex cognitive abilities - such as understanding abstract concepts,\nreasoning, and adapting to novel scenarios, which are intrinsic to human\ncognition - remains a major challenge. In this study, we show that\nbrain-in-the-loop supervised learning, utilizing a small set of brain signals,\ncan effectively transfer human conceptual structures to DNNs, significantly\nenhancing their comprehension of abstract and even unseen concepts.\nExperimental results further indicate that the enhanced cognitive capabilities\nlead to substantial performance gains in challenging tasks, including\nfew-shot/zero-shot learning and out-of-distribution recognition, while also\nyielding highly interpretable concept representations. These findings highlight\nthat human-in-the-loop supervision can effectively augment the complex\ncognitive abilities of large models, offering a promising pathway toward\ndeveloping more human-like cognitive abilities in artificial systems."}
{"id": "2505.09024", "pdf": "https://arxiv.org/pdf/2505.09024", "abs": "https://arxiv.org/abs/2505.09024", "authors": ["Aaron Baughman", "Rahul Agarwal", "Eduardo Morales", "Gozde Akay"], "title": "Automated Meta Prompt Engineering for Alignment with the Theory of Mind", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "9 pages, 6 figures, 3 tables", "summary": "We introduce a method of meta-prompting that jointly produces fluent text for\ncomplex tasks while optimizing the similarity of neural states between a\nhuman's mental expectation and a Large Language Model's (LLM) neural\nprocessing. A technique of agentic reinforcement learning is applied, in which\nan LLM as a Judge (LLMaaJ) teaches another LLM, through in-context learning,\nhow to produce content by interpreting the intended and unintended generated\ntext traits. To measure human mental beliefs around content production, users\nmodify long form AI-generated text articles before publication at the US Open\n2024 tennis Grand Slam. Now, an LLMaaJ can solve the Theory of Mind (ToM)\nalignment problem by anticipating and including human edits within the creation\nof text from an LLM. Throughout experimentation and by interpreting the results\nof a live production system, the expectations of human content reviewers had\n100% of alignment with AI 53.8% of the time with an average iteration count of\n4.38. The geometric interpretation of content traits such as factualness,\nnovelty, repetitiveness, and relevancy over a Hilbert vector space combines\nspatial volume (all trait importance) with vertices alignment (individual trait\nrelevance) enabled the LLMaaJ to optimize on Human ToM. This resulted in an\nincrease in content quality by extending the coverage of tennis action. Our\nwork that was deployed at the US Open 2024 has been used across other live\nevents within sports and entertainment."}
{"id": "2505.08808", "pdf": "https://arxiv.org/pdf/2505.08808", "abs": "https://arxiv.org/abs/2505.08808", "authors": ["Anqing Jiang", "Jinhao Chai", "Yu Gao", "Yiru Wang", "Yuwen Heng", "Zhigang Sun", "Hao Sun", "Zezhong Zhao", "Li Sun", "Jian Zhou", "Lijuan Zhu", "Shugong Xu", "Hao Zhao"], "title": "SparseMeXT Unlocking the Potential of Sparse Representations for HD Map Construction", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Recent advancements in high-definition \\emph{HD} map construction have\ndemonstrated the effectiveness of dense representations, which heavily rely on\ncomputationally intensive bird's-eye view \\emph{BEV} features. While sparse\nrepresentations offer a more efficient alternative by avoiding dense BEV\nprocessing, existing methods often lag behind due to the lack of tailored\ndesigns. These limitations have hindered the competitiveness of sparse\nrepresentations in online HD map construction. In this work, we systematically\nrevisit and enhance sparse representation techniques, identifying key\narchitectural and algorithmic improvements that bridge the gap with--and\nultimately surpass--dense approaches. We introduce a dedicated network\narchitecture optimized for sparse map feature extraction, a sparse-dense\nsegmentation auxiliary task to better leverage geometric and semantic cues, and\na denoising module guided by physical priors to refine predictions. Through\nthese enhancements, our method achieves state-of-the-art performance on the\nnuScenes dataset, significantly advancing HD map construction and centerline\ndetection. Specifically, SparseMeXt-Tiny reaches a mean average precision\n\\emph{mAP} of 55.5% at 32 frames per second \\emph{fps}, while SparseMeXt-Base\nattains 65.2% mAP. Scaling the backbone and decoder further, SparseMeXt-Large\nachieves an mAP of 68.9% at over 20 fps, establishing a new benchmark for\nsparse representations in HD map construction. These results underscore the\nuntapped potential of sparse methods, challenging the conventional reliance on\ndense representations and redefining efficiency-performance trade-offs in the\nfield."}
{"id": "2505.09129", "pdf": "https://arxiv.org/pdf/2505.09129", "abs": "https://arxiv.org/abs/2505.09129", "authors": ["Wei Meng"], "title": "WSCIF: A Weakly-Supervised Color Intelligence Framework for Tactical Anomaly Detection in Surveillance Keyframes", "categories": ["cs.CV", "cs.AI", "es: 68T10, 68T05, 62H35, 68U10", "I.4.9; I.5.1; I.2.10"], "comment": "17 pages, 3 figures, 3 tables. The paper proposes a lightweight\n  weakly-supervised color intelligence model for tactical video anomaly\n  detection, tested on anonymized African surveillance data", "summary": "The deployment of traditional deep learning models in high-risk security\ntasks in an unlabeled, data-non-exploitable video intelligence environment\nfaces significant challenges. In this paper, we propose a lightweight anomaly\ndetection framework based on color features for surveillance video clips in a\nhigh sensitivity tactical mission, aiming to quickly identify and interpret\npotential threat events under resource-constrained and data-sensitive\nconditions. The method fuses unsupervised KMeans clustering with RGB channel\nhistogram modeling to achieve composite detection of structural anomalies and\ncolor mutation signals in key frames. The experiment takes an operation\nsurveillance video occurring in an African country as a research sample, and\nsuccessfully identifies multiple highly anomalous frames related to high-energy\nlight sources, target presence, and reflective interference under the condition\nof no access to the original data. The results show that this method can be\neffectively used for tactical assassination warning, suspicious object\nscreening and environmental drastic change monitoring with strong deployability\nand tactical interpretation value. The study emphasizes the importance of color\nfeatures as low semantic battlefield signal carriers, and its battlefield\nintelligent perception capability will be further extended by combining graph\nneural networks and temporal modeling in the future."}
{"id": "2505.09089", "pdf": "https://arxiv.org/pdf/2505.09089", "abs": "https://arxiv.org/abs/2505.09089", "authors": ["Philipp Hess", "Maximilian Gelbrecht", "Christof Schötz", "Michael Aich", "Yu Huang", "Shangshang Yang", "Niklas Boers"], "title": "Generating time-consistent dynamics with discriminator-guided image diffusion models", "categories": ["cs.LG"], "comment": null, "summary": "Realistic temporal dynamics are crucial for many video generation, processing\nand modelling applications, e.g. in computational fluid dynamics, weather\nprediction, or long-term climate simulations. Video diffusion models (VDMs) are\nthe current state-of-the-art method for generating highly realistic dynamics.\nHowever, training VDMs from scratch can be challenging and requires large\ncomputational resources, limiting their wider application. Here, we propose a\ntime-consistency discriminator that enables pretrained image diffusion models\nto generate realistic spatiotemporal dynamics. The discriminator guides the\nsampling inference process and does not require extensions or finetuning of the\nimage diffusion model. We compare our approach against a VDM trained from\nscratch on an idealized turbulence simulation and a real-world global\nprecipitation dataset. Our approach performs equally well in terms of temporal\nconsistency, shows improved uncertainty calibration and lower biases compared\nto the VDM, and achieves stable centennial-scale climate simulations at daily\ntime steps."}
{"id": "2505.09031", "pdf": "https://arxiv.org/pdf/2505.09031", "abs": "https://arxiv.org/abs/2505.09031", "authors": ["Adarsh Kumar", "Hwiyoon Kim", "Jawahar Sai Nathani", "Neil Roy"], "title": "Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Hallucination, where large language models (LLMs) generate confident but\nincorrect or irrelevant information, remains a key limitation in their\napplication to complex, open-ended tasks. Chain-of-thought (CoT) prompting has\nemerged as a promising method for improving multistep reasoning by guiding\nmodels through intermediate steps. However, CoT alone does not fully address\nthe hallucination problem. In this work, we investigate how combining CoT with\nretrieval-augmented generation (RAG), as well as applying self-consistency and\nself-verification strategies, can reduce hallucinations and improve factual\naccuracy. By incorporating external knowledge sources during reasoning and\nenabling models to verify or revise their own outputs, we aim to generate more\naccurate and coherent responses. We present a comparative evaluation of\nbaseline LLMs against CoT, CoT+RAG, self-consistency, and self-verification\ntechniques. Our results highlight the effectiveness of each method and identify\nthe most robust approach for minimizing hallucinations while preserving fluency\nand reasoning depth."}
{"id": "2505.08809", "pdf": "https://arxiv.org/pdf/2505.08809", "abs": "https://arxiv.org/abs/2505.08809", "authors": ["Shixi Qin", "Zhiyong Yang", "Shilong Bao", "Shi Wang", "Qianqian Xu", "Qingming Huang"], "title": "MixBridge: Heterogeneous Image-to-Image Backdoor Attack through Mixture of Schrödinger Bridges", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "This paper focuses on implanting multiple heterogeneous backdoor triggers in\nbridge-based diffusion models designed for complex and arbitrary input\ndistributions. Existing backdoor formulations mainly address single-attack\nscenarios and are limited to Gaussian noise input models. To fill this gap, we\npropose MixBridge, a novel diffusion Schr\\\"odinger bridge (DSB) framework to\ncater to arbitrary input distributions (taking I2I tasks as special cases).\nBeyond this trait, we demonstrate that backdoor triggers can be injected into\nMixBridge by directly training with poisoned image pairs. This eliminates the\nneed for the cumbersome modifications to stochastic differential equations\nrequired in previous studies, providing a flexible tool to study backdoor\nbehavior for bridge models. However, a key question arises: can a single DSB\nmodel train multiple backdoor triggers? Unfortunately, our theory shows that\nwhen attempting this, the model ends up following the geometric mean of benign\nand backdoored distributions, leading to performance conflict across backdoor\ntasks. To overcome this, we propose a Divide-and-Merge strategy to mix\ndifferent bridges, where models are independently pre-trained for each specific\nobjective (Divide) and then integrated into a unified model (Merge). In\naddition, a Weight Reallocation Scheme (WRS) is also designed to enhance the\nstealthiness of MixBridge. Empirical studies across diverse generation tasks\nspeak to the efficacy of MixBridge."}
{"id": "2505.09139", "pdf": "https://arxiv.org/pdf/2505.09139", "abs": "https://arxiv.org/abs/2505.09139", "authors": ["Lucas Choi", "Ross Greer"], "title": "Beyond General Prompts: Automated Prompt Refinement using Contrastive Class Alignment Scores for Disambiguating Objects in Vision-Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Vision-language models (VLMs) offer flexible object detection through natural\nlanguage prompts but suffer from performance variability depending on prompt\nphrasing. In this paper, we introduce a method for automated prompt refinement\nusing a novel metric called the Contrastive Class Alignment Score (CCAS), which\nranks prompts based on their semantic alignment with a target object class\nwhile penalizing similarity to confounding classes. Our method generates\ndiverse prompt candidates via a large language model and filters them through\nCCAS, computed using prompt embeddings from a sentence transformer. We evaluate\nour approach on challenging object categories, demonstrating that our automatic\nselection of high-precision prompts improves object detection accuracy without\nthe need for additional model training or labeled data. This scalable and\nmodel-agnostic pipeline offers a principled alternative to manual prompt\nengineering for VLM-based detection systems."}
{"id": "2505.09106", "pdf": "https://arxiv.org/pdf/2505.09106", "abs": "https://arxiv.org/abs/2505.09106", "authors": ["Ya Liu", "Kai Yang", "Yu Zhu", "Keying Yang", "Haibo Zhao"], "title": "Argus: Federated Non-convex Bilevel Learning over 6G Space-Air-Ground Integrated Network", "categories": ["cs.LG", "68T07", "I.2"], "comment": "17 pages, 11 figures", "summary": "The space-air-ground integrated network (SAGIN) has recently emerged as a\ncore element in the 6G networks. However, traditional centralized and\nsynchronous optimization algorithms are unsuitable for SAGIN due to\ninfrastructureless and time-varying environments. This paper aims to develop a\nnovel Asynchronous algorithm a.k.a. Argus for tackling non-convex and\nnon-smooth decentralized federated bilevel learning over SAGIN. The proposed\nalgorithm allows networked agents (e.g. autonomous aerial vehicles) to tackle\nbilevel learning problems in time-varying networks asynchronously, thereby\naverting stragglers from impeding the overall training speed. We provide a\ntheoretical analysis of the iteration complexity, communication complexity, and\ncomputational complexity of Argus. Its effectiveness is further demonstrated\nthrough numerical experiments."}
{"id": "2505.09083", "pdf": "https://arxiv.org/pdf/2505.09083", "abs": "https://arxiv.org/abs/2505.09083", "authors": ["Dominic Zaun Eu Jones"], "title": "Ornithologist: Towards Trustworthy \"Reasoning\" about Central Bank Communications", "categories": ["econ.GN", "cs.CL", "q-fin.EC", "J.4; I.2.7"], "comment": "16 pages, 6 figures", "summary": "I develop Ornithologist, a weakly-supervised textual classification system\nand measure the hawkishness and dovishness of central bank text. Ornithologist\nuses ``taxonomy-guided reasoning'', guiding a large language model with\nhuman-authored decision trees. This increases the transparency and\nexplainability of the system and makes it accessible to non-experts. It also\nreduces hallucination risk. Since it requires less supervision than traditional\nclassification systems, it can more easily be applied to other problems or\nsources of text (e.g. news) without much modification. Ornithologist\nmeasurements of hawkishness and dovishness of RBA communication carry\ninformation about the future of the cash rate path and of market expectations."}
{"id": "2505.08810", "pdf": "https://arxiv.org/pdf/2505.08810", "abs": "https://arxiv.org/abs/2505.08810", "authors": ["Bappa Muktar", "Vincent Fono", "Adama Nouboukpo"], "title": "Machine Learning-Based Detection of DDoS Attacks in VANETs for Emergency Vehicle Communication", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Vehicular Ad Hoc Networks (VANETs) play a key role in Intelligent\nTransportation Systems (ITS), particularly in enabling real-time communication\nfor emergency vehicles. However, Distributed Denial of Service (DDoS) attacks,\nwhich interfere with safety-critical communication channels, can severely\nimpair their reliability. This study introduces a robust and scalable framework\nto detect DDoS attacks in highway-based VANET environments. A synthetic dataset\nwas constructed using Network Simulator 3 (NS-3) in conjunction with the\nSimulation of Urban Mobility (SUMO) and further enriched with real-world\nmobility traces from Germany's A81 highway, extracted via OpenStreetMap (OSM).\nThree traffic categories were simulated: DDoS, VoIP, and TCP-based video\nstreaming (VideoTCP). The data preprocessing pipeline included normalization,\nsignal-to-noise ratio (SNR) feature engineering, missing value imputation, and\nclass balancing using the Synthetic Minority Over-sampling Technique (SMOTE).\nFeature importance was assessed using SHapley Additive exPlanations (SHAP).\nEleven classifiers were benchmarked, among them XGBoost (XGB), CatBoost (CB),\nAdaBoost (AB), GradientBoosting (GB), and an Artificial Neural Network (ANN).\nXGB and CB achieved the best performance, each attaining an F1-score of 96%.\nThese results highlight the robustness of the proposed framework and its\npotential for real-time deployment in VANETs to secure critical emergency\ncommunications."}
{"id": "2505.09140", "pdf": "https://arxiv.org/pdf/2505.09140", "abs": "https://arxiv.org/abs/2505.09140", "authors": ["Zechao Guan", "Feng Yan", "Shuai Du", "Lin Ma", "Qingshan Liu"], "title": "TopoDiT-3D: Topology-Aware Diffusion Transformer with Bottleneck Structure for 3D Point Cloud Generation", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements in Diffusion Transformer (DiT) models have significantly\nimproved 3D point cloud generation. However, existing methods primarily focus\non local feature extraction while overlooking global topological information,\nsuch as voids, which are crucial for maintaining shape consistency and\ncapturing complex geometries. To address this limitation, we propose\nTopoDiT-3D, a Topology-Aware Diffusion Transformer with a bottleneck structure\nfor 3D point cloud generation. Specifically, we design the bottleneck structure\nutilizing Perceiver Resampler, which not only offers a mode to integrate\ntopological information extracted through persistent homology into feature\nlearning, but also adaptively filters out redundant local features to improve\ntraining efficiency. Experimental results demonstrate that TopoDiT-3D\noutperforms state-of-the-art models in visual quality, diversity, and training\nefficiency. Furthermore, TopoDiT-3D demonstrates the importance of rich\ntopological information for 3D point cloud generation and its synergy with\nconventional local feature learning. Videos and code are available at\nhttps://github.com/Zechao-Guan/TopoDiT-3D."}
{"id": "2505.09113", "pdf": "https://arxiv.org/pdf/2505.09113", "abs": "https://arxiv.org/abs/2505.09113", "authors": ["Yingrong Wang", "Anpeng Wu", "Baohong Li", "Ziyang Xiao", "Ruoxuan Xiong", "Qing Han", "Kun Kuang"], "title": "Sequential Treatment Effect Estimation with Unmeasured Confounders", "categories": ["cs.LG", "stat.ME"], "comment": null, "summary": "This paper studies the cumulative causal effects of sequential treatments in\nthe presence of unmeasured confounders. It is a critical issue in sequential\ndecision-making scenarios where treatment decisions and outcomes dynamically\nevolve over time. Advanced causal methods apply transformer as a backbone to\nmodel such time sequences, which shows superiority in capturing long time\ndependence and periodic patterns via attention mechanism. However, even they\ncontrol the observed confounding, these estimators still suffer from unmeasured\nconfounders, which influence both treatment assignments and outcomes. How to\nadjust the latent confounding bias in sequential treatment effect estimation\nremains an open challenge. Therefore, we propose a novel Decomposing Sequential\nInstrumental Variable framework for CounterFactual Regression (DSIV-CFR),\nrelying on a common negative control assumption. Specifically, an instrumental\nvariable (IV) is a special negative control exposure, while the previous\noutcome serves as a negative control outcome. This allows us to recover the IVs\nlatent in observation variables and estimate sequential treatment effects via a\ngeneralized moment condition. We conducted experiments on 4 datasets and\nachieved significant performance in one- and multi-step prediction, supported\nby which we can identify optimal treatments for dynamic systems."}
{"id": "2505.09246", "pdf": "https://arxiv.org/pdf/2505.09246", "abs": "https://arxiv.org/abs/2505.09246", "authors": ["Derian Boer", "Stephen Roth", "Stefan Kramer"], "title": "Focus, Merge, Rank: Improved Question Answering Based on Semi-structured Knowledge Bases", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "In many real-world settings, machine learning models and interactive systems\nhave access to both structured knowledge, e.g., knowledge graphs or tables, and\nunstructured content, e.g., natural language documents. However, most rely on\neither. Semi-Structured Knowledge Bases (SKBs) bridge this gap by linking\nunstructured content to nodes within structured data, thereby enabling new\nstrategies for knowledge access and use. In this work, we present\nFocusedRetriever, a modular SKB-based framework for multi-hop question\nanswering. It integrates components (VSS-based entity search, LLM-based\ngeneration of Cypher queries and pairwise re-ranking) in a way that enables it\nto outperform state-of-the-art methods across all three STaRK benchmark test\nsets, covering diverse domains and multiple performance metrics. The average\nfirst-hit rate exceeds that of the second-best method by 25.7%.\nFocusedRetriever leverages (1) the capacity of Large Language Models (LLMs) to\nextract relational facts and entity attributes from unstructured text, (2) node\nset joins to filter answer candidates based on these extracted triplets and\nconstraints, (3) vector similarity search to retrieve and rank relevant\nunstructured content, and (4) the contextual capabilities of LLMs to finally\nrank the top-k answers. For generality, we only incorporate base LLMs in\nFocusedRetriever in our evaluation. However, our analysis of intermediate\nresults highlights several opportunities for further upgrades including\nfinetuning. The source code is publicly available at\nhttps://github.com/kramerlab/FocusedRetriever ."}
{"id": "2505.08814", "pdf": "https://arxiv.org/pdf/2505.08814", "abs": "https://arxiv.org/abs/2505.08814", "authors": ["Wenkai Li", "Xiaoqi Li", "Yingjie Mao", "Yishun Wang"], "title": "Towards Understanding Deep Learning Model in Image Recognition via Coverage Test", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep neural networks (DNNs) play a crucial role in the field of artificial\nintelligence, and their security-related testing has been a prominent research\nfocus. By inputting test cases, the behavior of models is examined for\nanomalies, and coverage metrics are utilized to determine the extent of neurons\ncovered by these test cases. With the widespread application and advancement of\nDNNs, different types of neural behaviors have garnered attention, leading to\nthe emergence of various coverage metrics for neural networks. However, there\nis currently a lack of empirical research on these coverage metrics,\nspecifically in analyzing the relationships and patterns between model depth,\nconfiguration information, and neural network coverage. This paper aims to\ninvestigate the relationships and patterns of four coverage metrics: primary\nfunctionality, boundary, hierarchy, and structural coverage. A series of\nempirical experiments were conducted, selecting LeNet, VGG, and ResNet as\ndifferent DNN architectures, along with 10 models of varying depths ranging\nfrom 5 to 54 layers, to compare and study the relationships between different\ndepths, configuration information, and various neural network coverage metrics.\nAdditionally, an investigation was carried out on the relationships between\nmodified decision/condition coverage and dataset size. Finally, three potential\nfuture directions are proposed to further contribute to the security testing of\nDNN Models."}
{"id": "2505.09155", "pdf": "https://arxiv.org/pdf/2505.09155", "abs": "https://arxiv.org/abs/2505.09155", "authors": ["Yichen Shi", "Zhuofu Tao", "Yuhao Gao", "Li Huang", "Hongyang Wang", "Zhiping Yu", "Ting-Jung Lin", "Lei He"], "title": "AMSnet 2.0: A Large AMS Database with AI Segmentation for Net Detection", "categories": ["cs.CV"], "comment": "accepted by LAD25", "summary": "Current multimodal large language models (MLLMs) struggle to understand\ncircuit schematics due to their limited recognition capabilities. This could be\nattributed to the lack of high-quality schematic-netlist training data.\nExisting work such as AMSnet applies schematic parsing to generate netlists.\nHowever, these methods rely on hard-coded heuristics and are difficult to apply\nto complex or noisy schematics in this paper. We therefore propose a novel net\ndetection mechanism based on segmentation with high robustness. The proposed\nmethod also recovers positional information, allowing digital reconstruction of\nschematics. We then expand AMSnet dataset with schematic images from various\nsources and create AMSnet 2.0. AMSnet 2.0 contains 2,686 circuits with\nschematic images, Spectre-formatted netlists, OpenAccess digital schematics,\nand positional information for circuit components and nets, whereas AMSnet only\nincludes 792 circuits with SPICE netlists but no digital schematics."}
{"id": "2505.09131", "pdf": "https://arxiv.org/pdf/2505.09131", "abs": "https://arxiv.org/abs/2505.09131", "authors": ["Kunwoong Kim", "Jihu Lee", "Sangchul Park", "Yongdai Kim"], "title": "Fair Clustering via Alignment", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at ICML 2025. This is the version submitted for review and\n  will be replaced by the camera-ready version soon", "summary": "Algorithmic fairness in clustering aims to balance the proportions of\ninstances assigned to each cluster with respect to a given sensitive attribute.\nWhile recently developed fair clustering algorithms optimize clustering\nobjectives under specific fairness constraints, their inherent complexity or\napproximation often results in suboptimal clustering utility or numerical\ninstability in practice. To resolve these limitations, we propose a new fair\nclustering algorithm based on a novel decomposition of the fair K-means\nclustering objective function. The proposed algorithm, called Fair Clustering\nvia Alignment (FCA), operates by alternately (i) finding a joint probability\ndistribution to align the data from different protected groups, and (ii)\noptimizing cluster centers in the aligned space. A key advantage of FCA is that\nit theoretically guarantees approximately optimal clustering utility for any\ngiven fairness level without complex constraints, thereby enabling high-utility\nfair clustering in practice. Experiments show that FCA outperforms existing\nmethods by (i) attaining a superior trade-off between fairness level and\nclustering utility, and (ii) achieving near-perfect fairness without numerical\ninstability."}
{"id": "2505.09436", "pdf": "https://arxiv.org/pdf/2505.09436", "abs": "https://arxiv.org/abs/2505.09436", "authors": ["Raghav Garg", "Kapil Sharma", "Karan Gupta"], "title": "CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "comment": null, "summary": "Large Language Models (LLMs) hold immense potential for revolutionizing\nCustomer Experience Management (CXM), particularly in contact center\noperations. However, evaluating their practical utility in complex operational\nenvironments is hindered by data scarcity (due to privacy concerns) and the\nlimitations of current benchmarks. Existing benchmarks often lack realism,\nfailing to incorporate deep knowledge base (KB) integration, real-world noise,\nor critical operational tasks beyond conversational fluency. To bridge this\ngap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset\nspecifically designed for evaluating AI in operational CXM contexts. Given the\ndiversity in possible contact center features, we have developed a scalable\nLLM-powered pipeline that simulates the brand's CXM entities that form the\nfoundation of our datasets-such as knowledge articles including product\nspecifications, issue taxonomies, and contact center conversations. The\nentities closely represent real-world distribution because of controlled noise\ninjection (informed by domain experts) and rigorous automated validation.\nBuilding on this, we release CXMArena, which provides dedicated benchmarks\ntargeting five important operational tasks: Knowledge Base Refinement, Intent\nPrediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with\nIntegrated Tools. Our baseline experiments underscore the benchmark's\ndifficulty: even state of the art embedding and generation models achieve only\n68% accuracy on article search, while standard embedding methods yield a low F1\nscore of 0.3 for knowledge base refinement, highlighting significant challenges\nfor current models necessitating complex pipelines and solutions over\nconventional techniques."}
{"id": "2505.08818", "pdf": "https://arxiv.org/pdf/2505.08818", "abs": "https://arxiv.org/abs/2505.08818", "authors": ["Amara Tariq", "Rimita Lahiri", "Charles Kahn", "Imon Banerjee"], "title": "Position: Restructuring of Categories and Implementation of Guidelines Essential for VLM Adoption in Healthcare", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "15 pages, 2, tables, 3 figures", "summary": "The intricate and multifaceted nature of vision language model (VLM)\ndevelopment, adaptation, and application necessitates the establishment of\nclear and standardized reporting protocols, particularly within the high-stakes\ncontext of healthcare. Defining these reporting standards is inherently\nchallenging due to the diverse nature of studies involving VLMs, which vary\nsignificantly from the development of all new VLMs or finetuning for domain\nalignment to off-the-shelf use of VLM for targeted diagnosis and prediction\ntasks. In this position paper, we argue that traditional machine learning\nreporting standards and evaluation guidelines must be restructured to\naccommodate multiphase VLM studies; it also has to be organized for intuitive\nunderstanding of developers while maintaining rigorous standards for\nreproducibility. To facilitate community adoption, we propose a categorization\nframework for VLM studies and outline corresponding reporting standards that\ncomprehensively address performance evaluation, data reporting protocols, and\nrecommendations for manuscript composition. These guidelines are organized\naccording to the proposed categorization scheme. Lastly, we present a checklist\nthat consolidates reporting standards, offering a standardized tool to ensure\nconsistency and quality in the publication of VLM-related research."}
{"id": "2505.09168", "pdf": "https://arxiv.org/pdf/2505.09168", "abs": "https://arxiv.org/abs/2505.09168", "authors": ["Jianlin Sun", "Xiaolin Fang", "Juwei Guan", "Dongdong Gui", "Teqi Wang", "Tongxin Zhu"], "title": "DRRNet: Macro-Micro Feature Fusion and Dual Reverse Refinement for Camouflaged Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The core challenge in Camouflage Object Detection (COD) lies in the\nindistinguishable similarity between targets and backgrounds in terms of color,\ntexture, and shape. This causes existing methods to either lose edge details\n(such as hair-like fine structures) due to over-reliance on global semantic\ninformation or be disturbed by similar backgrounds (such as vegetation\npatterns) when relying solely on local features. We propose DRRNet, a\nfour-stage architecture characterized by a \"context-detail-fusion-refinement\"\npipeline to address these issues. Specifically, we introduce an Omni-Context\nFeature Extraction Module to capture global camouflage patterns and a Local\nDetail Extraction Module to supplement microstructural information for the\nfull-scene context module. We then design a module for forming dual\nrepresentations of scene understanding and structural awareness, which fuses\npanoramic features and local features across various scales. In the decoder, we\nalso introduce a reverse refinement module that leverages spatial edge priors\nand frequency-domain noise suppression to perform a two-stage inverse\nrefinement of the output. By applying two successive rounds of inverse\nrefinement, the model effectively suppresses background interference and\nenhances the continuity of object boundaries. Experimental results demonstrate\nthat DRRNet significantly outperforms state-of-the-art methods on benchmark\ndatasets. Our code is available at https://github.com/jerrySunning/DRRNet."}
{"id": "2505.09134", "pdf": "https://arxiv.org/pdf/2505.09134", "abs": "https://arxiv.org/abs/2505.09134", "authors": ["Daniel Huang"], "title": "Scaling Gaussian Process Regression with Full Derivative Observations", "categories": ["cs.LG", "stat.ML"], "comment": "12 pages", "summary": "We present a scalable Gaussian Process (GP) method that can fit and predict\nfull derivative observations called DSoftKI. It extends SoftKI, a method that\napproximates a kernel via softmax interpolation from learned interpolation\npoint locations, to the setting with derivatives. DSoftKI enhances SoftKI's\ninterpolation scheme to incorporate the directional orientation of\ninterpolation points relative to the data. This enables the construction of a\nscalable approximate kernel, including its first and second-order derivatives,\nthrough interpolation. We evaluate DSoftKI on a synthetic function benchmark\nand high-dimensional molecular force field prediction (100-1000 dimensions),\ndemonstrating that DSoftKI is accurate and can scale to larger datasets with\nfull derivative observations than previously possible."}
{"id": "2505.09610", "pdf": "https://arxiv.org/pdf/2505.09610", "abs": "https://arxiv.org/abs/2505.09610", "authors": ["Nicolas Dupuis", "Ravi Nair", "Shyam Ramji", "Sean McClintock", "Nishant Chauhan", "Priyanka Nagpal", "Bart Blaner", "Ken Valk", "Leon Stok", "Ruchir Puri"], "title": "Customizing a Large Language Model for VHDL Design of High-Performance Microprocessors", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "The use of Large Language Models (LLMs) in hardware design has taken off in\nrecent years, principally through its incorporation in tools that increase chip\ndesigner productivity. There has been considerable discussion about the use of\nLLMs in RTL specifications of chip designs, for which the two most popular\nlanguages are Verilog and VHDL. LLMs and their use in Verilog design has\nreceived significant attention due to the higher popularity of the language,\nbut little attention so far has been given to VHDL despite its continued\npopularity in the industry. There has also been little discussion about the\nunique needs of organizations that engage in high-performance processor design,\nand techniques to deploy AI solutions in these settings. In this paper, we\ndescribe our journey in developing a Large Language Model (LLM) specifically\nfor the purpose of explaining VHDL code, a task that has particular importance\nin an organization with decades of experience and assets in high-performance\nprocessor design. We show how we developed test sets specific to our needs and\nused them for evaluating models as we performed extended pretraining (EPT) of a\nbase LLM. Expert evaluation of the code explanations produced by the EPT model\nincreased to 69% compared to a base model rating of 43%. We further show how we\ndeveloped an LLM-as-a-judge to gauge models similar to expert evaluators. This\nled us to deriving and evaluating a host of new models, including an\ninstruction-tuned version of the EPT model with an expected expert evaluator\nrating of 71%. Our experiments also indicate that with the potential use of\nnewer base models, this rating can be pushed to 85% and beyond. We conclude\nwith a discussion on further improving the quality of hardware design LLMs\nusing exciting new developments in the Generative AI world."}
{"id": "2505.08821", "pdf": "https://arxiv.org/pdf/2505.08821", "abs": "https://arxiv.org/abs/2505.08821", "authors": ["Meryem Altin Karagoz", "Marc D. Breton", "Anas El Fathi"], "title": "A Comparative Study of Transformer-Based Models for Multi-Horizon Blood Glucose Prediction", "categories": ["q-bio.QM", "cs.AI", "stat.AP"], "comment": "7 pages, 2 figures, 1 table, 1st IFAC Workshop on Engineering\n  Diabetes Technologies (EDT 2025)", "summary": "Accurate blood glucose prediction can enable novel interventions for type 1\ndiabetes treatment, including personalized insulin and dietary adjustments.\nAlthough recent advances in transformer-based architectures have demonstrated\nthe power of attention mechanisms in complex multivariate time series\nprediction, their potential for blood glucose (BG) prediction remains\nunderexplored. We present a comparative analysis of transformer models for\nmulti-horizon BG prediction, examining forecasts up to 4 hours and input\nhistory up to 1 week. The publicly available DCLP3 dataset (n=112) was split\n(80%-10%-10%) for training, validation, and testing, and the OhioT1DM dataset\n(n=12) served as an external test set. We trained networks with point-wise,\npatch-wise, series-wise, and hybrid embeddings, using CGM, insulin, and meal\ndata. For short-term blood glucose prediction, Crossformer, a patch-wise\ntransformer architecture, achieved a superior 30-minute prediction of RMSE\n(15.6 mg / dL on OhioT1DM). For longer-term predictions (1h, 2h, and 4h),\nPatchTST, another path-wise transformer, prevailed with the lowest RMSE (24.6\nmg/dL, 36.1 mg/dL, and 46.5 mg/dL on OhioT1DM). In general, models that used\ntokenization through patches demonstrated improved accuracy with larger input\nsizes, with the best results obtained with a one-week history. These findings\nhighlight the promise of transformer-based architectures for BG prediction by\ncapturing and leveraging seasonal patterns in multivariate time-series data to\nimprove accuracy."}
{"id": "2505.09178", "pdf": "https://arxiv.org/pdf/2505.09178", "abs": "https://arxiv.org/abs/2505.09178", "authors": ["Yitao Zhu", "Yuan Yin", "Zhenrong Shen", "Zihao Zhao", "Haiyu Song", "Sheng Wang", "Dinggang Shen", "Qian Wang"], "title": "UniCAD: Efficient and Extendable Architecture for Multi-Task Computer-Aided Diagnosis System", "categories": ["cs.CV"], "comment": "14 pages", "summary": "The growing complexity and scale of visual model pre-training have made\ndeveloping and deploying multi-task computer-aided diagnosis (CAD) systems\nincreasingly challenging and resource-intensive. Furthermore, the medical\nimaging community lacks an open-source CAD platform to enable the rapid\ncreation of efficient and extendable diagnostic models. To address these\nissues, we propose UniCAD, a unified architecture that leverages the robust\ncapabilities of pre-trained vision foundation models to seamlessly handle both\n2D and 3D medical images while requiring only minimal task-specific parameters.\nUniCAD introduces two key innovations: (1) Efficiency: A low-rank adaptation\nstrategy is employed to adapt a pre-trained visual model to the medical image\ndomain, achieving performance on par with fully fine-tuned counterparts while\nintroducing only 0.17% trainable parameters. (2) Plug-and-Play: A modular\narchitecture that combines a frozen foundation model with multiple\nplug-and-play experts, enabling diverse tasks and seamless functionality\nexpansion. Building on this unified CAD architecture, we establish an\nopen-source platform where researchers can share and access lightweight CAD\nexperts, fostering a more equitable and efficient research ecosystem.\nComprehensive experiments across 12 diverse medical datasets demonstrate that\nUniCAD consistently outperforms existing methods in both accuracy and\ndeployment efficiency. The source code and project page are available at\nhttps://mii-laboratory.github.io/UniCAD/."}
{"id": "2505.09160", "pdf": "https://arxiv.org/pdf/2505.09160", "abs": "https://arxiv.org/abs/2505.09160", "authors": ["Berkay Guler", "Giovanni Geraci", "Hamid Jafarkhani"], "title": "A Multi-Task Foundation Model for Wireless Channel Representation Using Contrastive and Masked Autoencoder Learning", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Current applications of self-supervised learning to wireless channel\nrepresentation often borrow paradigms developed for text and image processing,\nwithout fully addressing the unique characteristics and constraints of wireless\ncommunications. Aiming to fill this gap, we first propose WiMAE (Wireless\nMasked Autoencoder), a transformer-based encoder-decoder foundation model\npretrained on a realistic open-source multi-antenna wireless channel dataset.\nBuilding upon this foundation, we develop ContraWiMAE, which enhances WiMAE by\nincorporating a contrastive learning objective alongside the reconstruction\ntask in a unified multi-task framework. By warm-starting from pretrained WiMAE\nweights and generating positive pairs via noise injection, the contrastive\ncomponent enables the model to capture both structural and discriminative\nfeatures, enhancing representation quality beyond what reconstruction alone can\nachieve. Through extensive evaluation on unseen scenarios, we demonstrate the\neffectiveness of both approaches across multiple downstream tasks, with\nContraWiMAE showing further improvements in linear separability and\nadaptability in diverse wireless environments. Comparative evaluations against\na state-of-the-art wireless channel foundation model confirm the superior\nperformance and data efficiency of our models, highlighting their potential as\npowerful baselines for future research in self-supervised wireless channel\nrepresentation learning."}
{"id": "2505.09614", "pdf": "https://arxiv.org/pdf/2505.09614", "abs": "https://arxiv.org/abs/2505.09614", "authors": ["Anthony GX-Chen", "Dongyan Lin", "Mandana Samiei", "Doina Precup", "Blake A. Richards", "Rob Fergus", "Kenneth Marino"], "title": "Language Agents Mirror Human Causal Reasoning Biases. How Can We Help Them Think Like Scientists?", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Language model (LM) agents are increasingly used as autonomous\ndecision-makers who need to actively gather information to guide their\ndecisions. A crucial cognitive skill for such agents is the efficient\nexploration and understanding of the causal structure of the world -- key to\nrobust, scientifically grounded reasoning. Yet, it remains unclear whether LMs\npossess this capability or exhibit systematic biases leading to erroneous\nconclusions. In this work, we examine LMs' ability to explore and infer causal\nrelationships, using the well-established \"Blicket Test\" paradigm from\ndevelopmental psychology. We find that LMs reliably infer the common, intuitive\ndisjunctive causal relationships but systematically struggle with the unusual,\nyet equally (or sometimes even more) evidenced conjunctive ones. This\n\"disjunctive bias\" persists across model families, sizes, and prompting\nstrategies, and performance further declines as task complexity increases.\nInterestingly, an analogous bias appears in human adults, suggesting that LMs\nmay have inherited deep-seated reasoning heuristics from their training data.\nTo this end, we quantify similarities between LMs and humans, finding that LMs\nexhibit adult-like inference profiles (but not children-like). Finally, we\npropose a test-time sampling method which explicitly samples and eliminates\nhypotheses about causal relationships from the LM. This scalable approach\nsignificantly reduces the disjunctive bias and moves LMs closer to the goal of\nscientific, causally rigorous reasoning."}
{"id": "2505.08823", "pdf": "https://arxiv.org/pdf/2505.08823", "abs": "https://arxiv.org/abs/2505.08823", "authors": ["Cody Steinmetz", "Gavin Childress", "Aaron Herbst", "Gavin Jones", "Jasdeep Singh", "Eli Vang", "Keagan Weinstock"], "title": "An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have transformed natural-language processing,\nyet their scale makes real-world deployment costly. Post-training quantization\nreduces memory and computation but often degrades accuracy, while\nquantization-aware training can recover performance at the cost of extra\ntraining. Pushing quantization to the ternary (2-bit) regime yields even larger\nsavings but is notoriously unstable. Building on recent work showing that a\nbias-free, RMS-normalized Transformer with straight-through estimation can\nreach 1.58-bit precision, we demonstrate that simply inserting RMS\nnormalization before every linear projection and applying a gradual, layer-wise\nquantization schedule stably fine-tunes full-precision checkpoints into ternary\nLLMs. Our approach matches or surpasses more elaborate knowledge-distillation\npipelines on standard language-modeling benchmarks without adding model\ncomplexity. These results indicate that careful normalization alone can close\nmuch of the accuracy gap between ternary and full-precision LLMs, making\nultra-low-bit inference practical."}
{"id": "2505.09188", "pdf": "https://arxiv.org/pdf/2505.09188", "abs": "https://arxiv.org/abs/2505.09188", "authors": ["Minjun Kim", "Jaehyeon Choi", "Jongkeun Lee", "Wonjin Cho", "U Kang"], "title": "Zero-shot Quantization: A Comprehensive Survey", "categories": ["cs.CV"], "comment": "IJCAI 2025 Survey Track", "summary": "Network quantization has proven to be a powerful approach to reduce the\nmemory and computational demands of deep learning models for deployment on\nresource-constrained devices. However, traditional quantization methods often\nrely on access to training data, which is impractical in many real-world\nscenarios due to privacy, security, or regulatory constraints. Zero-shot\nQuantization (ZSQ) emerges as a promising solution, achieving quantization\nwithout requiring any real data. In this paper, we provide a comprehensive\noverview of ZSQ methods and their recent advancements. First, we provide a\nformal definition of the ZSQ problem and highlight the key challenges. Then, we\ncategorize the existing ZSQ methods into classes based on data generation\nstrategies, and analyze their motivations, core ideas, and key takeaways.\nLastly, we suggest future research directions to address the remaining\nlimitations and advance the field of ZSQ. To the best of our knowledge, this\npaper is the first in-depth survey on ZSQ."}
{"id": "2505.09174", "pdf": "https://arxiv.org/pdf/2505.09174", "abs": "https://arxiv.org/abs/2505.09174", "authors": ["Xinyu You", "Xiang Liu", "Chuan-Shen Hu", "Kelin Xia", "Tze Chien Sum"], "title": "Quotient Complex Transformer (QCformer) for Perovskite Data Analysis", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "comment": null, "summary": "The discovery of novel functional materials is crucial in addressing the\nchallenges of sustainable energy generation and climate change. Hybrid\norganic-inorganic perovskites (HOIPs) have gained attention for their\nexceptional optoelectronic properties in photovoltaics. Recently, geometric\ndeep learning, particularly graph neural networks (GNNs), has shown strong\npotential in predicting material properties and guiding material design.\nHowever, traditional GNNs often struggle to capture the periodic structures and\nhigher-order interactions prevalent in such systems. To address these\nlimitations, we propose a novel representation based on quotient complexes\n(QCs) and introduce the Quotient Complex Transformer (QCformer) for material\nproperty prediction. A material structure is modeled as a quotient complex,\nwhich encodes both pairwise and many-body interactions via simplices of varying\ndimensions and captures material periodicity through a quotient operation. Our\nmodel leverages higher-order features defined on simplices and processes them\nusing a simplex-based Transformer module. We pretrain QCformer on benchmark\ndatasets such as the Materials Project and JARVIS, and fine-tune it on HOIP\ndatasets. The results show that QCformer outperforms state-of-the-art models in\nHOIP property prediction, demonstrating its effectiveness. The quotient complex\nrepresentation and QCformer model together contribute a powerful new tool for\npredictive modeling of perovskite materials."}
{"id": "2505.08825", "pdf": "https://arxiv.org/pdf/2505.08825", "abs": "https://arxiv.org/abs/2505.08825", "authors": ["Pedro Antonio Alarcon Granadeno", "Theodore Chambers", "Jane Cleland-Huang"], "title": "Multi-source Plume Tracing via Multi-Agent Reinforcement Learning", "categories": ["cs.MA", "cs.AI"], "comment": "13 pages, 7 figures", "summary": "Industrial catastrophes like the Bhopal disaster (1984) and the Aliso Canyon\ngas leak (2015) demonstrate the urgent need for rapid and reliable plume\ntracing algorithms to protect public health and the environment. Traditional\nmethods, such as gradient-based or biologically inspired approaches, often fail\nin realistic, turbulent conditions. To address these challenges, we present a\nMulti-Agent Reinforcement Learning (MARL) algorithm designed for localizing\nmultiple airborne pollution sources using a swarm of small uncrewed aerial\nsystems (sUAS). Our method models the problem as a Partially Observable Markov\nGame (POMG), employing a Long Short-Term Memory (LSTM)-based Action-specific\nDouble Deep Recurrent Q-Network (ADDRQN) that uses full sequences of historical\naction-observation pairs, effectively approximating latent states. Unlike prior\nwork, we use a general-purpose simulation environment based on the Gaussian\nPlume Model (GPM), incorporating realistic elements such as a three-dimensional\nenvironment, sensor noise, multiple interacting agents, and multiple plume\nsources. The incorporation of action histories as part of the inputs further\nenhances the adaptability of our model in complex, partially observable\nenvironments. Extensive simulations show that our algorithm significantly\noutperforms conventional approaches. Specifically, our model allows agents to\nexplore only 1.29\\% of the environment to successfully locate pollution\nsources."}
{"id": "2505.09196", "pdf": "https://arxiv.org/pdf/2505.09196", "abs": "https://arxiv.org/abs/2505.09196", "authors": ["Tong Li", "Lizhi Wang", "Hansen Feng", "Lin Zhu", "Hua Huang"], "title": "PDE: Gene Effect Inspired Parameter Dynamic Evolution for Low-light Image Enhancement", "categories": ["cs.CV"], "comment": "11 pages, 9 tables, 9 figures", "summary": "Low-light image enhancement (LLIE) is a fundamental task in computational\nphotography, aiming to improve illumination, reduce noise, and enhance image\nquality. While recent advancements focus on designing increasingly complex\nneural network models, we observe a peculiar phenomenon: resetting certain\nparameters to random values unexpectedly improves enhancement performance for\nsome images. Drawing inspiration from biological genes, we term this phenomenon\nthe gene effect. The gene effect limits enhancement performance, as even random\nparameters can sometimes outperform learned ones, preventing models from fully\nutilizing their capacity. In this paper, we investigate the reason and propose\na solution. Based on our observations, we attribute the gene effect to static\nparameters, analogous to how fixed genetic configurations become maladaptive\nwhen environments change. Inspired by biological evolution, where adaptation to\nnew environments relies on gene mutation and recombination, we propose\nparameter dynamic evolution (PDE) to adapt to different images and mitigate the\ngene effect. PDE employs a parameter orthogonal generation technique and the\ncorresponding generated parameters to simulate gene recombination and gene\nmutation, separately. Experiments validate the effectiveness of our techniques.\nThe code will be released to the public."}
{"id": "2505.09175", "pdf": "https://arxiv.org/pdf/2505.09175", "abs": "https://arxiv.org/abs/2505.09175", "authors": ["Mohammad Ganjirad", "Mahmoud Reza Delavar", "Hossein Bagheri", "Mohammad Mehdi Azizi"], "title": "Optimizing Urban Critical Green Space Development Using Machine Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "This paper presents a novel framework for prioritizing urban green space\ndevelopment in Tehran using diverse socio-economic, environmental, and\nsensitivity indices. The indices were derived from various sources including\nGoogle Earth Engine, air pollution measurements, municipal reports and the\nWeather Research & Forecasting (WRF) model. The WRF model was used to estimate\nthe air temperature at a 1 km resolution due to insufficient meteorological\nstations, yielding RMSE and MAE values of 0.96{\\deg}C and 0.92{\\deg}C,\nrespectively. After data preparation, several machine learning models were used\nfor binary vegetation cover classification including XGBoost, LightGBM, Random\nForest (RF) and Extra Trees. RF achieved the highest performance, exceeding 94%\nin Overall Accuracy, Recall, and F1-score. Then, the probability of areas\nlacking vegetation cover was assessed using socio-economic, environmental and\nsensitivity indices. This resulted in the RF generating an urban green space\ndevelopment prioritization map. Feature Importance Analysis revealed that the\nmost significant indices were nightly land surface temperature (LST) and\nsensitive population. Finally, the framework performance was validated through\nmicroclimate simulation to assess the critical areas after and before the green\nspace development by green roofs. The simulation demonstrated reducing air\ntemperature by up to 0.67{\\deg}C after utilizing the green roof technology in\ncritical areas. As a result, this framework provides a valuable tool for urban\nplanners to develop green spaces."}
{"id": "2505.08827", "pdf": "https://arxiv.org/pdf/2505.08827", "abs": "https://arxiv.org/abs/2505.08827", "authors": ["Toby Simonds", "Kevin Lopez", "Akira Yoshiyama", "Dominique Garmier"], "title": "Self Rewarding Self Improving", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We demonstrate that large language models can effectively self-improve\nthrough self-judging without requiring reference solutions, leveraging the\ninherent asymmetry between generating and verifying solutions. Our experiments\non Countdown puzzles and MIT Integration Bee problems show that models can\nprovide reliable reward signals without ground truth answers, enabling\nreinforcement learning in domains previously not possible. By implementing\nself-judging, we achieve significant performance gains maintaining alignment\nwith formal verification. When combined with synthetic question generation, we\nestablish a complete self-improvement loop where models generate practice\nproblems, solve them, and evaluate their own performance-achieving an 8%\nimprovement with Qwen 2.5 7B over baseline and surpassing GPT-4o performance on\nintegration tasks. Our findings demonstrate that LLM judges can provide\neffective reward signals for training models, unlocking many reinforcement\nlearning environments previously limited by the difficulty of creating\nprogrammatic rewards. This suggests a potential paradigm shift toward AI\nsystems that continuously improve through self-directed learning rather than\nhuman-guided training, potentially accelerating progress in domains with scarce\ntraining data or complex evaluation requirements."}
{"id": "2505.09251", "pdf": "https://arxiv.org/pdf/2505.09251", "abs": "https://arxiv.org/abs/2505.09251", "authors": ["Vineetha Joy", "Aditya Anand", "Nidhi", "Anshuman Kumar", "Amit Sethi", "Hema Singh"], "title": "A Surrogate Model for the Forward Design of Multi-layered Metasurface-based Radar Absorbing Structures", "categories": ["cs.CV"], "comment": null, "summary": "Metasurface-based radar absorbing structures (RAS) are highly preferred for\napplications like stealth technology, electromagnetic (EM) shielding, etc. due\nto their capability to achieve frequency selective absorption characteristics\nwith minimal thickness and reduced weight penalty. However, the conventional\napproach for the EM design and optimization of these structures relies on\nforward simulations, using full wave simulation tools, to predict the\nelectromagnetic (EM) response of candidate meta atoms. This process is\ncomputationally intensive, extremely time consuming and requires exploration of\nlarge design spaces. To overcome this challenge, we propose a surrogate model\nthat significantly accelerates the prediction of EM responses of multi-layered\nmetasurface-based RAS. A convolutional neural network (CNN) based architecture\nwith Huber loss function has been employed to estimate the reflection\ncharacteristics of the RAS model. The proposed model achieved a cosine\nsimilarity of 99.9% and a mean square error of 0.001 within 1000 epochs of\ntraining. The efficiency of the model has been established via full wave\nsimulations as well as experiment where it demonstrated significant reduction\nin computational time while maintaining high predictive accuracy."}
{"id": "2505.09214", "pdf": "https://arxiv.org/pdf/2505.09214", "abs": "https://arxiv.org/abs/2505.09214", "authors": ["Zhonghao Lyu", "Ming Xiao", "Jie Xu", "Mikael Skoglund", "Marco Di Renzo"], "title": "The Larger the Merrier? Efficient Large AI Model Inference in Wireless Edge Networks", "categories": ["cs.LG"], "comment": null, "summary": "The growing demand for large artificial intelligence model (LAIM) services is\ndriving a paradigm shift from traditional cloud-based inference to edge-based\ninference for low-latency, privacy-preserving applications. In particular,\nedge-device co-inference, which partitions LAIMs between edge devices and\nservers, has emerged as a promising strategy for resource-efficient LAIM\nexecution in wireless networks. In this paper, we investigate a pruning-aware\nLAIM co-inference scheme, where a pre-trained LAIM is pruned and partitioned\ninto on-device and on-server sub-models for deployment. For analysis, we first\nprove that the LAIM output distortion is upper bounded by its parameter\ndistortion. Then, we derive a lower bound on parameter distortion via\nrate-distortion theory, analytically capturing the relationship between pruning\nratio and co-inference performance. Next, based on the analytical results, we\nformulate an LAIM co-inference distortion bound minimization problem by jointly\noptimizing the pruning ratio, transmit power, and computation frequency under\nsystem latency, energy, and available resource constraints. Moreover, we\npropose an efficient algorithm to tackle the considered highly non-convex\nproblem. Finally, extensive simulations demonstrate the effectiveness of the\nproposed design. In particular, model parameter distortion is shown to provide\na reliable bound on output distortion. Also, the proposed joint pruning ratio\nand resource management design achieves superior performance in balancing\ntrade-offs among inference performance, system latency, and energy consumption\ncompared with benchmark schemes, such as fully on-device and on-server\ninference. Moreover, the split point is shown to play a critical role in system\nperformance optimization under heterogeneous and resource-limited edge\nenvironments."}
{"id": "2505.08828", "pdf": "https://arxiv.org/pdf/2505.08828", "abs": "https://arxiv.org/abs/2505.08828", "authors": ["Eduardo Araujo Oliveira", "Madhavi Mohoni", "Sonsoles López-Pernas", "Mohammed Saqr"], "title": "Human-AI Collaboration or Academic Misconduct? Measuring AI Use in Student Writing Through Stylometric Evidence", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "19 pages, 10 figures, 11 tables", "summary": "As human-AI collaboration becomes increasingly prevalent in educational\ncontexts, understanding and measuring the extent and nature of such\ninteractions pose significant challenges. This research investigates the use of\nauthorship verification (AV) techniques not as a punitive measure, but as a\nmeans to quantify AI assistance in academic writing, with a focus on promoting\ntransparency, interpretability, and student development. Building on prior\nwork, we structured our investigation into three stages: dataset selection and\nexpansion, AV method development, and systematic evaluation. Using three\ndatasets - including a public dataset (PAN-14) and two from University of\nMelbourne students from various courses - we expanded the data to include\nLLM-generated texts, totalling 1,889 documents and 540 authorship problems from\n506 students. We developed an adapted Feature Vector Difference AV methodology\nto construct robust academic writing profiles for students, designed to capture\nmeaningful, individual characteristics of their writing. The method's\neffectiveness was evaluated across multiple scenarios, including distinguishing\nbetween student-authored and LLM-generated texts and testing resilience against\nLLMs' attempts to mimic student writing styles. Results demonstrate the\nenhanced AV classifier's ability to identify stylometric discrepancies and\nmeasure human-AI collaboration at word and sentence levels while providing\neducators with a transparent tool to support academic integrity investigations.\nThis work advances AV technology, offering actionable insights into the\ndynamics of academic writing in an AI-driven era."}
{"id": "2505.09252", "pdf": "https://arxiv.org/pdf/2505.09252", "abs": "https://arxiv.org/abs/2505.09252", "authors": ["Yinuo Wang", "Yue Zeng", "Kai Chen", "Cai Meng", "Chao Pan", "Zhouping Tang"], "title": "Zero-Shot Multi-modal Large Language Model v.s. Supervised Deep Learning: A Comparative Study on CT-Based Intracranial Hemorrhage Subtyping", "categories": ["cs.CV"], "comment": null, "summary": "Introduction: Timely identification of intracranial hemorrhage (ICH) subtypes\non non-contrast computed tomography is critical for prognosis prediction and\ntherapeutic decision-making, yet remains challenging due to low contrast and\nblurring boundaries. This study evaluates the performance of zero-shot\nmulti-modal large language models (MLLMs) compared to traditional deep learning\nmethods in ICH binary classification and subtyping. Methods: We utilized a\ndataset provided by RSNA, comprising 192 NCCT volumes. The study compares\nvarious MLLMs, including GPT-4o, Gemini 2.0 Flash, and Claude 3.5 Sonnet V2,\nwith conventional deep learning models, including ResNet50 and Vision\nTransformer. Carefully crafted prompts were used to guide MLLMs in tasks such\nas ICH presence, subtype classification, localization, and volume estimation.\nResults: The results indicate that in the ICH binary classification task,\ntraditional deep learning models outperform MLLMs comprehensively. For subtype\nclassification, MLLMs also exhibit inferior performance compared to traditional\ndeep learning models, with Gemini 2.0 Flash achieving an macro-averaged\nprecision of 0.41 and a macro-averaged F1 score of 0.31. Conclusion: While\nMLLMs excel in interactive capabilities, their overall accuracy in ICH\nsubtyping is inferior to deep networks. However, MLLMs enhance interpretability\nthrough language interactions, indicating potential in medical imaging\nanalysis. Future efforts will focus on model refinement and developing more\nprecise MLLMs to improve performance in three-dimensional medical image\nprocessing."}
{"id": "2505.09218", "pdf": "https://arxiv.org/pdf/2505.09218", "abs": "https://arxiv.org/abs/2505.09218", "authors": ["Alexander Tyurin", "Danil Sivtsov"], "title": "Birch SGD: A Tree Graph Framework for Local and Asynchronous SGD Methods", "categories": ["cs.LG", "cs.DC", "math.OC"], "comment": null, "summary": "We propose a new unifying framework, Birch SGD, for analyzing and designing\ndistributed SGD methods. The central idea is to represent each method as a\nweighted directed tree, referred to as a computation tree. Leveraging this\nrepresentation, we introduce a general theoretical result that reduces\nconvergence analysis to studying the geometry of these trees. This perspective\nyields a purely graph-based interpretation of optimization dynamics, offering a\nnew and intuitive foundation for method development. Using Birch SGD, we design\neight new methods and analyze them alongside previously known ones, with at\nleast six of the new methods shown to have optimal computational time\ncomplexity. Our research leads to two key insights: (i) all methods share the\nsame \"iteration rate\" of $O\\left(\\frac{(R + 1) L \\Delta}{\\varepsilon} +\n\\frac{\\sigma^2 L \\Delta}{\\varepsilon^2}\\right)$, where $R$ the maximum \"tree\ndistance\" along the main branch of a tree; and (ii) different methods exhibit\ndifferent trade-offs-for example, some update iterates more frequently,\nimproving practical performance, while others are more communication-efficient\nor focus on other aspects. Birch SGD serves as a unifying framework for\nnavigating these trade-offs. We believe these results provide a unified\nfoundation for understanding, analyzing, and designing efficient asynchronous\nand parallel optimization methods."}
{"id": "2505.08829", "pdf": "https://arxiv.org/pdf/2505.08829", "abs": "https://arxiv.org/abs/2505.08829", "authors": ["David Kinney"], "title": "Aggregating Concepts of Accuracy and Fairness in Prediction Algorithms", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "An algorithm that outputs predictions about the state of the world will\nalmost always be designed with the implicit or explicit goal of outputting\naccurate predictions (i.e., predictions that are likely to be true). In\naddition, the rise of increasingly powerful predictive algorithms brought about\nby the recent revolution in artificial intelligence has led to an emphasis on\nbuilding predictive algorithms that are fair, in the sense that their\npredictions do not systematically evince bias or bring about harm to certain\nindividuals or groups. This state of affairs presents two conceptual\nchallenges. First, the goals of accuracy and fairness can sometimes be in\ntension, and there are no obvious normative guidelines for managing the\ntrade-offs between these two desiderata when they arise. Second, there are many\ndistinct ways of measuring both the accuracy and fairness of a predictive\nalgorithm; here too, there are no obvious guidelines on how to aggregate our\npreferences for predictive algorithms that satisfy disparate measures of\nfairness and accuracy to various extents. The goal of this paper is to address\nthese challenges by arguing that there are good reasons for using a linear\ncombination of accuracy and fairness metrics to measure the\nall-things-considered value of a predictive algorithm for agents who care about\nboth accuracy and fairness. My argument depends crucially on a classic result\nin the preference aggregation literature due to Harsanyi. After making this\nformal argument, I apply my result to an analysis of accuracy-fairness\ntrade-offs using the COMPAS dataset compiled by Angwin et al."}
{"id": "2505.09256", "pdf": "https://arxiv.org/pdf/2505.09256", "abs": "https://arxiv.org/abs/2505.09256", "authors": ["Jaemin Jung", "Youngjoon Jang", "Joon Son Chung"], "title": "Test-Time Augmentation for Pose-invariant Face Recognition", "categories": ["cs.CV"], "comment": null, "summary": "The goal of this paper is to enhance face recognition performance by\naugmenting head poses during the testing phase. Existing methods often rely on\ntraining on frontalised images or learning pose-invariant representations, yet\nboth approaches typically require re-training and testing for each dataset,\ninvolving a substantial amount of effort. In contrast, this study proposes\nPose-TTA, a novel approach that aligns faces at inference time without\nadditional training. To achieve this, we employ a portrait animator that\ntransfers the source image identity into the pose of a driving image. Instead\nof frontalising a side-profile face -- which can introduce distortion --\nPose-TTA generates matching side-profile images for comparison, thereby\nreducing identity information loss. Furthermore, we propose a weighted feature\naggregation strategy to address any distortions or biases arising from the\nsynthetic data, thus enhancing the reliability of the augmented images.\nExtensive experiments on diverse datasets and with various pre-trained face\nrecognition models demonstrate that Pose-TTA consistently improves inference\nperformance. Moreover, our method is straightforward to integrate into existing\nface recognition pipelines, as it requires no retraining or fine-tuning of the\nunderlying recognition models."}
{"id": "2505.09239", "pdf": "https://arxiv.org/pdf/2505.09239", "abs": "https://arxiv.org/abs/2505.09239", "authors": ["Faruk Alpay"], "title": "Stable and Convexified Information Bottleneck Optimization via Symbolic Continuation and Entropy-Regularized Trajectories", "categories": ["cs.LG", "68T05, 90C25, 94A15", "I.2.6; G.1.6; H.1.1"], "comment": "23 pages, 11 figures, includes analytical proofs, sensitivity\n  analysis (95% CI), and JAX-based open-source implementation available at:\n  https://github.com/farukalpay/information-bottleneck-beta-optimization", "summary": "The Information Bottleneck (IB) method frequently suffers from unstable\noptimization, characterized by abrupt representation shifts near critical\npoints of the IB trade-off parameter, beta. In this paper, I introduce a novel\napproach to achieve stable and convex IB optimization through symbolic\ncontinuation and entropy-regularized trajectories. I analytically prove\nconvexity and uniqueness of the IB solution path when an entropy regularization\nterm is included, and demonstrate how this stabilizes representation learning\nacross a wide range of \\b{eta} values. Additionally, I provide extensive\nsensitivity analyses around critical points (beta) with statistically robust\nuncertainty quantification (95% confidence intervals). The open-source\nimplementation, experimental results, and reproducibility framework included in\nthis work offer a clear path for practical deployment and future extension of\nmy proposed method."}
{"id": "2505.08830", "pdf": "https://arxiv.org/pdf/2505.08830", "abs": "https://arxiv.org/abs/2505.08830", "authors": ["Wenhao Jiang", "Yuchuan Luo", "Guilin Deng", "Silong Chen", "Xu Yang", "Shihong Wu", "Xinwen Gao", "Lin Liu", "Shaojing Fu"], "title": "Federated Large Language Models: Feasibility, Robustness, Security and Future Directions", "categories": ["cs.CR", "cs.AI"], "comment": "35 pages", "summary": "The integration of Large Language Models (LLMs) and Federated Learning (FL)\npresents a promising solution for joint training on distributed data while\npreserving privacy and addressing data silo issues. However, this emerging\nfield, known as Federated Large Language Models (FLLM), faces significant\nchallenges, including communication and computation overheads, heterogeneity,\nprivacy and security concerns. Current research has primarily focused on the\nfeasibility of FLLM, but future trends are expected to emphasize enhancing\nsystem robustness and security. This paper provides a comprehensive review of\nthe latest advancements in FLLM, examining challenges from four critical\nperspectives: feasibility, robustness, security, and future directions. We\npresent an exhaustive survey of existing studies on FLLM feasibility, introduce\nmethods to enhance robustness in the face of resource, data, and task\nheterogeneity, and analyze novel risks associated with this integration,\nincluding privacy threats and security challenges. We also review the latest\ndevelopments in defense mechanisms and explore promising future research\ndirections, such as few-shot learning, machine unlearning, and IP protection.\nThis survey highlights the pressing need for further research to enhance system\nrobustness and security while addressing the unique challenges posed by the\nintegration of FL and LLM."}
{"id": "2505.09263", "pdf": "https://arxiv.org/pdf/2505.09263", "abs": "https://arxiv.org/abs/2505.09263", "authors": ["Guan Gui", "Bin-Bin Gao", "Jun Liu", "Chengjie Wang", "Yunsheng Wu"], "title": "Few-Shot Anomaly-Driven Generation for Anomaly Classification and Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ECCV 2024", "summary": "Anomaly detection is a practical and challenging task due to the scarcity of\nanomaly samples in industrial inspection. Some existing anomaly detection\nmethods address this issue by synthesizing anomalies with noise or external\ndata. However, there is always a large semantic gap between synthetic and\nreal-world anomalies, resulting in weak performance in anomaly detection. To\nsolve the problem, we propose a few-shot Anomaly-driven Generation (AnoGen)\nmethod, which guides the diffusion model to generate realistic and diverse\nanomalies with only a few real anomalies, thereby benefiting training anomaly\ndetection models. Specifically, our work is divided into three stages. In the\nfirst stage, we learn the anomaly distribution based on a few given real\nanomalies and inject the learned knowledge into an embedding. In the second\nstage, we use the embedding and given bounding boxes to guide the diffusion\nmodel to generate realistic and diverse anomalies on specific objects (or\ntextures). In the final stage, we propose a weakly-supervised anomaly detection\nmethod to train a more powerful model with generated anomalies. Our method\nbuilds upon DRAEM and DesTSeg as the foundation model and conducts experiments\non the commonly used industrial anomaly detection dataset, MVTec. The\nexperiments demonstrate that our generated anomalies effectively improve the\nmodel performance of both anomaly classification and segmentation tasks\nsimultaneously, \\eg, DRAEM and DseTSeg achieved a 5.8\\% and 1.5\\% improvement\nin AU-PR metric on segmentation task, respectively. The code and generated\nanomalous data are available at https://github.com/gaobb/AnoGen."}
{"id": "2505.09284", "pdf": "https://arxiv.org/pdf/2505.09284", "abs": "https://arxiv.org/abs/2505.09284", "authors": ["Panqi Chen", "Yifan Sun", "Lei Cheng", "Yang Yang", "Weichang Li", "Yang Liu", "Weiqing Liu", "Jiang Bian", "Shikai Fang"], "title": "Generating Full-field Evolution of Physical Dynamics from Irregular Sparse Observations", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Modeling and reconstructing multidimensional physical dynamics from sparse\nand off-grid observations presents a fundamental challenge in scientific\nresearch. Recently, diffusion-based generative modeling shows promising\npotential for physical simulation. However, current approaches typically\noperate on on-grid data with preset spatiotemporal resolution, but struggle\nwith the sparsely observed and continuous nature of real-world physical\ndynamics. To fill the gaps, we present SDIFT, Sequential DIffusion in\nFunctional Tucker space, a novel framework that generates full-field evolution\nof physical dynamics from irregular sparse observations. SDIFT leverages the\nfunctional Tucker model as the latent space representer with proven universal\napproximation property, and represents observations as latent functions and\nTucker core sequences. We then construct a sequential diffusion model with\ntemporally augmented UNet in the functional Tucker space, denoising noise drawn\nfrom a Gaussian process to generate the sequence of core tensors.\n  At the posterior sampling stage, we propose a Message-Passing Posterior\nSampling mechanism, enabling conditional generation of the entire sequence\nguided by observations at limited time steps. We validate SDIFT on three\nphysical systems spanning astronomical (supernova explosions, light-year\nscale), environmental (ocean sound speed fields, kilometer scale), and\nmolecular (organic liquid, millimeter scale) domains, demonstrating significant\nimprovements in both reconstruction accuracy and computational efficiency\ncompared to state-of-the-art approaches."}
{"id": "2505.08834", "pdf": "https://arxiv.org/pdf/2505.08834", "abs": "https://arxiv.org/abs/2505.08834", "authors": ["Muhammad Junaid Asif"], "title": "Crowd Scene Analysis using Deep Learning Techniques", "categories": ["cs.CV", "cs.AI"], "comment": "MS Graduate Research Thesis", "summary": "Our research is focused on two main applications of crowd scene analysis\ncrowd counting and anomaly detection In recent years a large number of\nresearches have been presented in the domain of crowd counting We addressed two\nmain challenges in this domain 1 Deep learning models are datahungry paradigms\nand always need a large amount of annotated data for the training of algorithm\nIt is timeconsuming and costly task to annotate such large amount of data\nSelfsupervised training is proposed to deal with this challenge 2 MCNN consists\nof multicolumns of CNN with different sizes of filters by presenting a novel\napproach based on a combination of selfsupervised training and MultiColumn CNN\nThis enables the model to learn features at different levels and makes it\neffective in dealing with challenges of occluded scenes nonuniform density\ncomplex backgrounds and scale invariation The proposed model was evaluated on\npublicly available data sets such as ShanghaiTech and UCFQNRF by means of MAE\nand MSE A spatiotemporal model based on VGG19 is proposed for crowd anomaly\ndetection addressing challenges like lighting environmental conditions\nunexpected objects and scalability The model extracts spatial and temporal\nfeatures allowing it to be generalized to realworld scenes Spatial features are\nlearned using CNN while temporal features are learned using LSTM blocks The\nmodel works on binary classification and can detect normal or abnormal behavior\nThe models performance is improved by replacing fully connected layers with\ndense residual blocks Experiments on the Hockey Fight dataset and SCVD dataset\nshow our models outperform other stateoftheart approaches"}
{"id": "2505.09264", "pdf": "https://arxiv.org/pdf/2505.09264", "abs": "https://arxiv.org/abs/2505.09264", "authors": ["Bin-Bin Gao"], "title": "Learning to Detect Multi-class Anomalies with Just One Normal Image Prompt", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ECCV 2024", "summary": "Unsupervised reconstruction networks using self-attention transformers have\nachieved state-of-the-art performance for multi-class (unified) anomaly\ndetection with a single model. However, these self-attention reconstruction\nmodels primarily operate on target features, which may result in perfect\nreconstruction for both normal and anomaly features due to high consistency\nwith context, leading to failure in detecting anomalies. Additionally, these\nmodels often produce inaccurate anomaly segmentation due to performing\nreconstruction in a low spatial resolution latent space. To enable\nreconstruction models enjoying high efficiency while enhancing their\ngeneralization for unified anomaly detection, we propose a simple yet effective\nmethod that reconstructs normal features and restores anomaly features with\njust One Normal Image Prompt (OneNIP). In contrast to previous work, OneNIP\nallows for the first time to reconstruct or restore anomalies with just one\nnormal image prompt, effectively boosting unified anomaly detection\nperformance. Furthermore, we propose a supervised refiner that regresses\nreconstruction errors by using both real normal and synthesized anomalous\nimages, which significantly improves pixel-level anomaly segmentation. OneNIP\noutperforms previous methods on three industry anomaly detection benchmarks:\nMVTec, BTAD, and VisA. The code and pre-trained models are available at\nhttps://github.com/gaobb/OneNIP."}
{"id": "2505.09287", "pdf": "https://arxiv.org/pdf/2505.09287", "abs": "https://arxiv.org/abs/2505.09287", "authors": ["Shunsuke Yoneda", "Valdemar Švábenský", "Gen Li", "Daisuke Deguchi", "Atsushi Shimada"], "title": "Ranking-Based At-Risk Student Prediction Using Federated Learning and Differential Features", "categories": ["cs.LG", "cs.CY", "I.2; I.6; K.3"], "comment": "To appear in the Proceedings of the 18th Educational Data Mining\n  Conference (EDM 2025)", "summary": "Digital textbooks are widely used in various educational contexts, such as\nuniversity courses and online lectures. Such textbooks yield learning log data\nthat have been used in numerous educational data mining (EDM) studies for\nstudent behavior analysis and performance prediction. However, these studies\nhave faced challenges in integrating confidential data, such as academic\nrecords and learning logs, across schools due to privacy concerns.\nConsequently, analyses are often conducted with data limited to a single\nschool, which makes developing high-performing and generalizable models\ndifficult. This study proposes a method that combines federated learning and\ndifferential features to address these issues. Federated learning enables model\ntraining without centralizing data, thereby preserving student privacy.\nDifferential features, which utilize relative values instead of absolute\nvalues, enhance model performance and generalizability. To evaluate the\nproposed method, a model for predicting at-risk students was trained using data\nfrom 1,136 students across 12 courses conducted over 4 years, and validated on\nhold-out test data from 5 other courses. Experimental results demonstrated that\nthe proposed method addresses privacy concerns while achieving performance\ncomparable to that of models trained via centralized learning in terms of Top-n\nprecision, nDCG, and PR-AUC. Furthermore, using differential features improved\nprediction performance across all evaluation datasets compared to\nnon-differential approaches. The trained models were also applicable for early\nprediction, achieving high performance in detecting at-risk students in earlier\nstages of the semester within the validation datasets."}
{"id": "2505.08835", "pdf": "https://arxiv.org/pdf/2505.08835", "abs": "https://arxiv.org/abs/2505.08835", "authors": ["Hyunsik Na", "Wonho Lee", "Seungdeok Roh", "Sohee Park", "Daeseon Choi"], "title": "Robustness Analysis against Adversarial Patch Attacks in Fully Unmanned Stores", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": null, "summary": "The advent of convenient and efficient fully unmanned stores equipped with\nartificial intelligence-based automated checkout systems marks a new era in\nretail. However, these systems have inherent artificial intelligence security\nvulnerabilities, which are exploited via adversarial patch attacks,\nparticularly in physical environments. This study demonstrated that adversarial\npatches can severely disrupt object detection models used in unmanned stores,\nleading to issues such as theft, inventory discrepancies, and interference. We\ninvestigated three types of adversarial patch attacks -- Hiding, Creating, and\nAltering attacks -- and highlighted their effectiveness. We also introduce the\nnovel color histogram similarity loss function by leveraging attacker knowledge\nof the color information of a target class object. Besides the traditional\nconfusion-matrix-based attack success rate, we introduce a new\nbounding-boxes-based metric to analyze the practical impact of these attacks.\nStarting with attacks on object detection models trained on snack and fruit\ndatasets in a digital environment, we evaluated the effectiveness of\nadversarial patches in a physical testbed that mimicked a real unmanned store\nwith RGB cameras and realistic conditions. Furthermore, we assessed the\nrobustness of these attacks in black-box scenarios, demonstrating that shadow\nattacks can enhance success rates of attacks even without direct access to\nmodel parameters. Our study underscores the necessity for robust defense\nstrategies to protect unmanned stores from adversarial threats. Highlighting\nthe limitations of the current defense mechanisms in real-time detection\nsystems and discussing various proactive measures, we provide insights into\nimproving the robustness of object detection models and fortifying unmanned\nretail environments against these attacks."}
{"id": "2505.09265", "pdf": "https://arxiv.org/pdf/2505.09265", "abs": "https://arxiv.org/abs/2505.09265", "authors": ["Bin-Bin Gao"], "title": "MetaUAS: Universal Anomaly Segmentation with One-Prompt Meta-Learning", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by NeurIPS 2024", "summary": "Zero- and few-shot visual anomaly segmentation relies on powerful\nvision-language models that detect unseen anomalies using manually designed\ntextual prompts. However, visual representations are inherently independent of\nlanguage. In this paper, we explore the potential of a pure visual foundation\nmodel as an alternative to widely used vision-language models for universal\nvisual anomaly segmentation. We present a novel paradigm that unifies anomaly\nsegmentation into change segmentation. This paradigm enables us to leverage\nlarge-scale synthetic image pairs, featuring object-level and local region\nchanges, derived from existing image datasets, which are independent of target\nanomaly datasets. We propose a one-prompt Meta-learning framework for Universal\nAnomaly Segmentation (MetaUAS) that is trained on this synthetic dataset and\nthen generalizes well to segment any novel or unseen visual anomalies in the\nreal world. To handle geometrical variations between prompt and query images,\nwe propose a soft feature alignment module that bridges paired-image change\nperception and single-image semantic segmentation. This is the first work to\nachieve universal anomaly segmentation using a pure vision model without\nrelying on special anomaly detection datasets and pre-trained visual-language\nmodels. Our method effectively and efficiently segments any anomalies with only\none normal image prompt and enjoys training-free without guidance from\nlanguage. Our MetaUAS significantly outperforms previous zero-shot, few-shot,\nand even full-shot anomaly segmentation methods. The code and pre-trained\nmodels are available at https://github.com/gaobb/MetaUAS."}
{"id": "2505.09294", "pdf": "https://arxiv.org/pdf/2505.09294", "abs": "https://arxiv.org/abs/2505.09294", "authors": ["Fan Xu", "Wuyang Chen", "Wei Gao"], "title": "On the Learning with Augmented Class via Forests", "categories": ["cs.LG"], "comment": "Accepted by IJCAI 2025", "summary": "Decision trees and forests have achieved successes in various real\napplications, most working with all testing classes known in training data. In\nthis work, we focus on learning with augmented class via forests, where an\naugmented class may appear in testing data yet not in training data. We\nincorporate information of augmented class into trees' splitting, i.e., a new\nsplitting criterion, called augmented Gini impurity, is introduced to exploit\nsome unlabeled data from testing distribution. We then develop the approach\nnamed Learning with Augmented Class via Forests (LACForest), which constructs\nshallow forests based on the augmented Gini impurity and then splits forests\nwith pseudo-labeled augmented instances for better performance. We also develop\ndeep neural forests with a novel optimization objective based on our augmented\nGini impurity, so as to utilize the representation power of neural networks for\nforests. Theoretically, we present the convergence analysis for augmented Gini\nimpurity, and finally conduct experiments to verify the effectiveness of our\napproaches. The code is available at https://github.com/nju-xuf/LACForest/."}
{"id": "2505.08838", "pdf": "https://arxiv.org/pdf/2505.08838", "abs": "https://arxiv.org/abs/2505.08838", "authors": ["Peixuan Ge", "Tongkun Su", "Faqin Lv", "Baoliang Zhao", "Peng Zhang", "Chi Hong Wong", "Liang Yao", "Yu Sun", "Zenan Wang", "Pak Kin Wong", "Ying Hu"], "title": "Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Ultrasound (US) report generation is a challenging task due to the\nvariability of US images, operator dependence, and the need for standardized\ntext. Unlike X-ray and CT, US imaging lacks consistent datasets, making\nautomation difficult. In this study, we propose a unified framework for\nmulti-organ and multilingual US report generation, integrating fragment-based\nmultilingual training and leveraging the standardized nature of US reports. By\naligning modular text fragments with diverse imaging data and curating a\nbilingual English-Chinese dataset, the method achieves consistent and\nclinically accurate text generation across organ sites and languages.\nFine-tuning with selective unfreezing of the vision transformer (ViT) further\nimproves text-image alignment. Compared to the previous state-of-the-art KMVE\nmethod, our approach achieves relative gains of about 2\\% in BLEU scores,\napproximately 3\\% in ROUGE-L, and about 15\\% in CIDEr, while significantly\nreducing errors such as missing or incorrect content. By unifying multi-organ\nand multi-language report generation into a single, scalable framework, this\nwork demonstrates strong potential for real-world clinical workflows."}
{"id": "2505.09274", "pdf": "https://arxiv.org/pdf/2505.09274", "abs": "https://arxiv.org/abs/2505.09274", "authors": ["Fares Bougourzi", "Abdenour Hadid"], "title": "Recent Advances in Medical Imaging Segmentation: A Survey", "categories": ["cs.CV"], "comment": null, "summary": "Medical imaging is a cornerstone of modern healthcare, driving advancements\nin diagnosis, treatment planning, and patient care. Among its various tasks,\nsegmentation remains one of the most challenging problem due to factors such as\ndata accessibility, annotation complexity, structural variability, variation in\nmedical imaging modalities, and privacy constraints. Despite recent progress,\nachieving robust generalization and domain adaptation remains a significant\nhurdle, particularly given the resource-intensive nature of some proposed\nmodels and their reliance on domain expertise. This survey explores\ncutting-edge advancements in medical image segmentation, focusing on\nmethodologies such as Generative AI, Few-Shot Learning, Foundation Models, and\nUniversal Models. These approaches offer promising solutions to longstanding\nchallenges. We provide a comprehensive overview of the theoretical foundations,\nstate-of-the-art techniques, and recent applications of these methods. Finally,\nwe discuss inherent limitations, unresolved issues, and future research\ndirections aimed at enhancing the practicality and accessibility of\nsegmentation models in medical imaging. We are maintaining a\n\\href{https://github.com/faresbougourzi/Awesome-DL-for-Medical-Imaging-Segmentation}{GitHub\nRepository} to continue tracking and updating innovations in this field."}
{"id": "2505.09308", "pdf": "https://arxiv.org/pdf/2505.09308", "abs": "https://arxiv.org/abs/2505.09308", "authors": ["George Andriopoulos", "Soyuj Jung Basnet", "Juan Guevara", "Li Guo", "Keith Ross"], "title": "Neural Multivariate Regression: Qualitative Insights from the Unconstrained Feature Model", "categories": ["cs.LG"], "comment": "31 pages, 8 figures", "summary": "The Unconstrained Feature Model (UFM) is a mathematical framework that\nenables closed-form approximations for minimal training loss and related\nperformance measures in deep neural networks (DNNs). This paper leverages the\nUFM to provide qualitative insights into neural multivariate regression, a\ncritical task in imitation learning, robotics, and reinforcement learning.\nSpecifically, we address two key questions: (1) How do multi-task models\ncompare to multiple single-task models in terms of training performance? (2)\nCan whitening and normalizing regression targets improve training performance?\nThe UFM theory predicts that multi-task models achieve strictly smaller\ntraining MSE than multiple single-task models when the same or stronger\nregularization is applied to the latter, and our empirical results confirm\nthese findings. Regarding whitening and normalizing regression targets, the UFM\ntheory predicts that they reduce training MSE when the average variance across\nthe target dimensions is less than one, and our empirical results once again\nconfirm these findings. These findings highlight the UFM as a powerful\nframework for deriving actionable insights into DNN design and data\npre-processing strategies."}
{"id": "2505.08841", "pdf": "https://arxiv.org/pdf/2505.08841", "abs": "https://arxiv.org/abs/2505.08841", "authors": ["Andrea Cremaschi", "Dae-Jin Lee", "Manuele Leonelli"], "title": "Will AI Take My Job? Evolving Perceptions of Automation and Labor Risk in Latin America", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "As artificial intelligence and robotics increasingly reshape the global labor\nmarket, understanding public perceptions of these technologies becomes\ncritical. We examine how these perceptions have evolved across Latin America,\nusing survey data from the 2017, 2018, 2020, and 2023 waves of the\nLatinobar\\'ometro. Drawing on responses from over 48,000 individuals across 16\ncountries, we analyze fear of job loss due to artificial intelligence and\nrobotics. Using statistical modeling and latent class analysis, we identify key\nstructural and ideological predictors of concern, with education level and\npolitical orientation emerging as the most consistent drivers. Our findings\nreveal substantial temporal and cross-country variation, with a notable peak in\nfear during 2018 and distinct attitudinal profiles emerging from latent\nsegmentation. These results offer new insights into the social and structural\ndimensions of AI anxiety in emerging economies and contribute to a broader\nunderstanding of public attitudes toward automation beyond the Global North."}
{"id": "2505.09306", "pdf": "https://arxiv.org/pdf/2505.09306", "abs": "https://arxiv.org/abs/2505.09306", "authors": ["Thijs L van der Plas", "Stephen Law", "Michael JO Pocock"], "title": "Predicting butterfly species presence from satellite imagery using soft contrastive regularisation", "categories": ["cs.CV", "cs.LG"], "comment": "To be published in the 2025 CVPR FGVC12 workshop", "summary": "The growing demand for scalable biodiversity monitoring methods has fuelled\ninterest in remote sensing data, due to its widespread availability and\nextensive coverage. Traditionally, the application of remote sensing to\nbiodiversity research has focused on mapping and monitoring habitats, but with\nincreasing availability of large-scale citizen-science wildlife observation\ndata, recent methods have started to explore predicting multi-species presence\ndirectly from satellite images. This paper presents a new data set for\npredicting butterfly species presence from satellite data in the United\nKingdom. We experimentally optimise a Resnet-based model to predict\nmulti-species presence from 4-band satellite images, and find that this model\nespecially outperforms the mean rate baseline for locations with high species\nbiodiversity. To improve performance, we develop a soft, supervised contrastive\nregularisation loss that is tailored to probabilistic labels (such as\nspecies-presence data), and demonstrate that this improves prediction accuracy.\nIn summary, our new data set and contrastive regularisation method contribute\nto the open challenge of accurately predicting species biodiversity from remote\nsensing data, which is key for efficient biodiversity monitoring."}
{"id": "2505.09331", "pdf": "https://arxiv.org/pdf/2505.09331", "abs": "https://arxiv.org/abs/2505.09331", "authors": ["Cunlai Pu", "Fangrui Wu", "Rajput Ramiz Sharafat", "Guangzhao Dai", "Xiangbo Shu"], "title": "MUST: Multi-Scale Structural-Temporal Link Prediction Model for UAV Ad Hoc Networks", "categories": ["cs.LG"], "comment": null, "summary": "Link prediction in unmanned aerial vehicle (UAV) ad hoc networks (UANETs)\naims to predict the potential formation of future links between UAVs. In\nadversarial environments where the route information of UAVs is unavailable,\npredicting future links must rely solely on the observed historical topological\ninformation of UANETs. However, the highly dynamic and sparse nature of UANET\ntopologies presents substantial challenges in effectively capturing meaningful\nstructural and temporal patterns for accurate link prediction. Most existing\nlink prediction methods focus on temporal dynamics at a single structural scale\nwhile neglecting the effects of sparsity, resulting in insufficient information\ncapture and limited applicability to UANETs. In this paper, we propose a\nmulti-scale structural-temporal link prediction model (MUST) for UANETs.\nSpecifically, we first employ graph attention networks (GATs) to capture\nstructural features at multiple levels, including the individual UAV level, the\nUAV community level, and the overall network level. Then, we use long\nshort-term memory (LSTM) networks to learn the temporal dynamics of these\nmulti-scale structural features. Additionally, we address the impact of\nsparsity by introducing a sophisticated loss function during model\noptimization. We validate the performance of MUST using several UANET datasets\ngenerated through simulations. Extensive experimental results demonstrate that\nMUST achieves state-of-the-art link prediction performance in highly dynamic\nand sparse UANETs."}
{"id": "2505.08844", "pdf": "https://arxiv.org/pdf/2505.08844", "abs": "https://arxiv.org/abs/2505.08844", "authors": ["Jiawen Chen", "Jianghao Zhang", "Huaxiu Yao", "Yun Li"], "title": "CellTypeAgent: Trustworthy cell type annotation with Large Language Models", "categories": ["q-bio.GN", "cs.AI", "68T20", "I.2.1"], "comment": null, "summary": "Cell type annotation is a critical yet laborious step in single-cell RNA\nsequencing analysis. We present a trustworthy large language model (LLM)-agent,\nCellTypeAgent, which integrates LLMs with verification from relevant databases.\nCellTypeAgent achieves higher accuracy than existing methods while mitigating\nhallucinations. We evaluated CellTypeAgent across nine real datasets involving\n303 cell types from 36 tissues. This combined approach holds promise for more\nefficient and reliable cell type annotation."}
{"id": "2505.09324", "pdf": "https://arxiv.org/pdf/2505.09324", "abs": "https://arxiv.org/abs/2505.09324", "authors": ["Lakshya Gupta", "Imran N. Junejo"], "title": "Neural Video Compression using 2D Gaussian Splatting", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "comment": "9 pages, 8 figures", "summary": "The computer vision and image processing research community has been involved\nin standardizing video data communications for the past many decades, leading\nto standards such as AVC, HEVC, VVC, AV1, AV2, etc. However, recent\ngroundbreaking works have focused on employing deep learning-based techniques\nto replace the traditional video codec pipeline to a greater affect. Neural\nvideo codecs (NVC) create an end-to-end ML-based solution that does not rely on\nany handcrafted features (motion or edge-based) and have the ability to learn\ncontent-aware compression strategies, offering better adaptability and higher\ncompression efficiency than traditional methods. This holds a great potential\nnot only for hardware design, but also for various video streaming platforms\nand applications, especially video conferencing applications such as MS-Teams\nor Zoom that have found extensive usage in classrooms and workplaces. However,\ntheir high computational demands currently limit their use in real-time\napplications like video conferencing. To address this, we propose a\nregion-of-interest (ROI) based neural video compression model that leverages 2D\nGaussian Splatting. Unlike traditional codecs, 2D Gaussian Splatting is capable\nof real-time decoding and can be optimized using fewer data points, requiring\nonly thousands of Gaussians for decent quality outputs as opposed to millions\nin 3D scenes. In this work, we designed a video pipeline that speeds up the\nencoding time of the previous Gaussian splatting-based image codec by 88% by\nusing a content-aware initialization strategy paired with a novel Gaussian\ninter-frame redundancy-reduction mechanism, enabling Gaussian splatting to be\nused for a video-codec solution, the first of its kind solution in this neural\nvideo codec space."}
{"id": "2505.09344", "pdf": "https://arxiv.org/pdf/2505.09344", "abs": "https://arxiv.org/abs/2505.09344", "authors": ["Gabriel Cortês", "Nuno Lourenço", "Paolo Romano", "Penousal Machado"], "title": "GreenFactory: Ensembling Zero-Cost Proxies to Estimate Performance of Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Determining the performance of a Deep Neural Network during Neural\nArchitecture Search processes is essential for identifying optimal\narchitectures and hyperparameters. Traditionally, this process requires\ntraining and evaluation of each network, which is time-consuming and\nresource-intensive. Zero-cost proxies estimate performance without training,\nserving as an alternative to traditional training. However, recent proxies\noften lack generalization across diverse scenarios and provide only relative\nrankings rather than predicted accuracies. To address these limitations, we\npropose GreenFactory, an ensemble of zero-cost proxies that leverages a random\nforest regressor to combine multiple predictors' strengths and directly predict\nmodel test accuracy. We evaluate GreenFactory on NATS-Bench, achieving robust\nresults across multiple datasets. Specifically, GreenFactory achieves high\nKendall correlations on NATS-Bench-SSS, indicating substantial agreement\nbetween its predicted scores and actual performance: 0.907 for CIFAR-10, 0.945\nfor CIFAR-100, and 0.920 for ImageNet-16-120. Similarly, on NATS-Bench-TSS, we\nachieve correlations of 0.921 for CIFAR-10, 0.929 for CIFAR-100, and 0.908 for\nImageNet-16-120, showcasing its reliability in both search spaces."}
{"id": "2505.08845", "pdf": "https://arxiv.org/pdf/2505.08845", "abs": "https://arxiv.org/abs/2505.08845", "authors": ["Misgina Tsighe Hagos", "Antti Suutala", "Dmitrii Bychkov", "Hakan Kücükel", "Joar von Bahr", "Milda Poceviciute", "Johan Lundin", "Nina Linder", "Claes Lundström"], "title": "Validation of Conformal Prediction in Cervical Atypia Classification", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Deep learning based cervical cancer classification can potentially increase\naccess to screening in low-resource regions. However, deep learning models are\noften overconfident and do not reliably reflect diagnostic uncertainty.\nMoreover, they are typically optimized to generate maximum-likelihood\npredictions, which fail to convey uncertainty or ambiguity in their results.\nSuch challenges can be addressed using conformal prediction, a model-agnostic\nframework for generating prediction sets that contain likely classes for\ntrained deep-learning models. The size of these prediction sets indicates model\nuncertainty, contracting as model confidence increases. However, existing\nconformal prediction evaluation primarily focuses on whether the prediction set\nincludes or covers the true class, often overlooking the presence of extraneous\nclasses. We argue that prediction sets should be truthful and valuable to end\nusers, ensuring that the listed likely classes align with human expectations\nrather than being overly relaxed and including false positives or unlikely\nclasses. In this study, we comprehensively validate conformal prediction sets\nusing expert annotation sets collected from multiple annotators. We evaluate\nthree conformal prediction approaches applied to three deep-learning models\ntrained for cervical atypia classification. Our expert annotation-based\nanalysis reveals that conventional coverage-based evaluations overestimate\nperformance and that current conformal prediction methods often produce\nprediction sets that are not well aligned with human labels. Additionally, we\nexplore the capabilities of the conformal prediction methods in identifying\nambiguous and out-of-distribution data."}
{"id": "2505.09329", "pdf": "https://arxiv.org/pdf/2505.09329", "abs": "https://arxiv.org/abs/2505.09329", "authors": ["Jiarun Liu", "Hong-Yu Zhou", "Weijian Huang", "Hao Yang", "Dongning Song", "Tao Tan", "Yong Liang", "Shanshan Wang"], "title": "BioVFM-21M: Benchmarking and Scaling Self-Supervised Vision Foundation Models for Biomedical Image Analysis", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 4 figures", "summary": "Scaling up model and data size have demonstrated impressive performance\nimprovement over a wide range of tasks. Despite extensive studies on scaling\nbehaviors for general-purpose tasks, medical images exhibit substantial\ndifferences from natural data. It remains unclear the key factors in developing\nmedical vision foundation models at scale due to the absence of an extensive\nunderstanding of scaling behavior in the medical domain. In this paper, we\nexplored the scaling behavior across model sizes, training algorithms, data\nsizes, and imaging modalities in developing scalable medical vision foundation\nmodels by self-supervised learning. To support scalable pretraining, we\nintroduce BioVFM-21M, a large-scale biomedical image dataset encompassing a\nwide range of biomedical image modalities and anatomies. We observed that\nscaling up does provide benefits but varies across tasks. Additional analysis\nreveals several factors correlated with scaling benefits. Finally, we propose\nBioVFM, a large-scale medical vision foundation model pretrained on 21 million\nbiomedical images, which outperforms the previous state-of-the-art foundation\nmodels across 12 medical benchmarks. Our results highlight that while scaling\nup is beneficial for pursuing better performance, task characteristics, data\ndiversity, pretraining methods, and computational efficiency remain critical\nconsiderations for developing scalable medical foundation models."}
{"id": "2505.09354", "pdf": "https://arxiv.org/pdf/2505.09354", "abs": "https://arxiv.org/abs/2505.09354", "authors": ["Guangtai Wang", "Chi-Man Vong", "Jintao Huang"], "title": "Exploiting the Potential Supervision Information of Clean Samples in Partial Label Learning", "categories": ["cs.LG"], "comment": null, "summary": "Diminishing the impact of false-positive labels is critical for conducting\ndisambiguation in partial label learning. However, the existing disambiguation\nstrategies mainly focus on exploiting the characteristics of individual partial\nlabel instances while neglecting the strong supervision information of clean\nsamples randomly lying in the datasets. In this work, we show that clean\nsamples can be collected to offer guidance and enhance the confidence of the\nmost possible candidates. Motivated by the manner of the differentiable count\nloss strat- egy and the K-Nearest-Neighbor algorithm, we proposed a new\ncalibration strategy called CleanSE. Specifically, we attribute the most\nreliable candidates with higher significance under the assumption that for each\nclean sample, if its label is one of the candidates of its nearest neighbor in\nthe representation space, it is more likely to be the ground truth of its\nneighbor. Moreover, clean samples offer help in characterizing the sample\ndistributions by restricting the label counts of each label to a specific\ninterval. Extensive experiments on 3 synthetic benchmarks and 5 real-world PLL\ndatasets showed this calibration strategy can be applied to most of the\nstate-of-the-art PLL methods as well as enhance their performance."}
{"id": "2505.08846", "pdf": "https://arxiv.org/pdf/2505.08846", "abs": "https://arxiv.org/abs/2505.08846", "authors": ["Felix Marti-Perez", "Brigt Håvardstun", "Cèsar Ferri", "Carlos Monserrat", "Jan Arne Telle"], "title": "Evaluating Simplification Algorithms for Interpretability of Time Series Classification", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In this work, we introduce metrics to evaluate the use of simplified time\nseries in the context of interpretability of a TSC - a Time Series Classifier.\nSuch simplifications are important because time series data, in contrast to\ntext and image data, are not intuitively understandable to humans. These\nmetrics are related to the complexity of the simplifications - how many\nsegments they contain - and to their loyalty - how likely they are to maintain\nthe classification of the original time series. We employ these metrics to\nevaluate four distinct simplification algorithms, across several TSC algorithms\nand across datasets of varying characteristics, from seasonal or stationary to\nshort or long. Our findings suggest that using simplifications for\ninterpretability of TSC is much better than using the original time series,\nparticularly when the time series are seasonal, non-stationary and/or with low\nentropy."}
{"id": "2505.09336", "pdf": "https://arxiv.org/pdf/2505.09336", "abs": "https://arxiv.org/abs/2505.09336", "authors": ["Muzammil Behzad"], "title": "Unsupervised Multiview Contrastive Language-Image Joint Learning with Pseudo-Labeled Prompts Via Vision-Language Model for 3D/4D Facial Expression Recognition", "categories": ["cs.CV"], "comment": null, "summary": "In this paper, we introduce MultiviewVLM, a vision-language model designed\nfor unsupervised contrastive multiview representation learning of facial\nemotions from 3D/4D data. Our architecture integrates pseudo-labels derived\nfrom generated textual prompts to guide implicit alignment of emotional\nsemantics. To capture shared information across multi-views, we propose a joint\nembedding space that aligns multiview representations without requiring\nexplicit supervision. We further enhance the discriminability of our model\nthrough a novel multiview contrastive learning strategy that leverages stable\npositive-negative pair sampling. A gradient-friendly loss function is\nintroduced to promote smoother and more stable convergence, and the model is\noptimized for distributed training to ensure scalability. Extensive experiments\ndemonstrate that MultiviewVLM outperforms existing state-of-the-art methods and\ncan be easily adapted to various real-world applications with minimal\nmodifications."}
{"id": "2505.09361", "pdf": "https://arxiv.org/pdf/2505.09361", "abs": "https://arxiv.org/abs/2505.09361", "authors": ["Samir Moustafa", "Nils M. Kriege", "Wilfried N. Gansterer"], "title": "Efficient Mixed Precision Quantization in Graph Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have become essential for handling large-scale\ngraph applications. However, the computational demands of GNNs necessitate the\ndevelopment of efficient methods to accelerate inference. Mixed precision\nquantization emerges as a promising solution to enhance the efficiency of GNN\narchitectures without compromising prediction performance. Compared to\nconventional deep learning architectures, GNN layers contain a wider set of\ncomponents that can be quantized, including message passing functions,\naggregation functions, update functions, the inputs, learnable parameters, and\noutputs of these functions. In this paper, we introduce a theorem for efficient\nquantized message passing to aggregate integer messages. It guarantees\nnumerical equality of the aggregated messages using integer values with respect\nto those obtained with full (FP32) precision. Based on this theorem, we\nintroduce the Mixed Precision Quantization for GNN (MixQ-GNN) framework, which\nflexibly selects effective integer bit-widths for all components within GNN\nlayers. Our approach systematically navigates the wide set of possible\nbit-width combinations, addressing the challenge of optimizing efficiency while\naiming at maintaining comparable prediction performance. MixQ-GNN integrates\nwith existing GNN quantization methods, utilizing their graph structure\nadvantages to achieve higher prediction performance. On average, MixQ-GNN\nachieved reductions in bit operations of 5.5x for node classification and 5.1x\nfor graph classification compared to architectures represented in FP32\nprecision."}
{"id": "2505.08847", "pdf": "https://arxiv.org/pdf/2505.08847", "abs": "https://arxiv.org/abs/2505.08847", "authors": ["Fatima Ezzeddine", "Rinad Akel", "Ihab Sbeity", "Silvia Giordano", "Marc Langheinrich", "Omran Ayoub"], "title": "On the interplay of Explainability, Privacy and Predictive Performance with Explanation-assisted Model Extraction", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Machine Learning as a Service (MLaaS) has gained important attraction as a\nmeans for deploying powerful predictive models, offering ease of use that\nenables organizations to leverage advanced analytics without substantial\ninvestments in specialized infrastructure or expertise. However, MLaaS\nplatforms must be safeguarded against security and privacy attacks, such as\nmodel extraction (MEA) attacks. The increasing integration of explainable AI\n(XAI) within MLaaS has introduced an additional privacy challenge, as attackers\ncan exploit model explanations particularly counterfactual explanations (CFs)\nto facilitate MEA. In this paper, we investigate the trade offs among model\nperformance, privacy, and explainability when employing Differential Privacy\n(DP), a promising technique for mitigating CF facilitated MEA. We evaluate two\ndistinct DP strategies: implemented during the classification model training\nand at the explainer during CF generation."}
{"id": "2505.09358", "pdf": "https://arxiv.org/pdf/2505.09358", "abs": "https://arxiv.org/abs/2505.09358", "authors": ["Bingxin Ke", "Kevin Qu", "Tianfu Wang", "Nando Metzger", "Shengyu Huang", "Bo Li", "Anton Obukhov", "Konrad Schindler"], "title": "Marigold: Affordable Adaptation of Diffusion-Based Image Generators for Image Analysis", "categories": ["cs.CV", "cs.LG"], "comment": "Journal extension of our CVPR 2024 paper, featuring new tasks,\n  improved efficiency, high-resolution capabilities, and enhanced accessibility", "summary": "The success of deep learning in computer vision over the past decade has\nhinged on large labeled datasets and strong pretrained models. In data-scarce\nsettings, the quality of these pretrained models becomes crucial for effective\ntransfer learning. Image classification and self-supervised learning have\ntraditionally been the primary methods for pretraining CNNs and\ntransformer-based architectures. Recently, the rise of text-to-image generative\nmodels, particularly those using denoising diffusion in a latent space, has\nintroduced a new class of foundational models trained on massive, captioned\nimage datasets. These models' ability to generate realistic images of unseen\ncontent suggests they possess a deep understanding of the visual world. In this\nwork, we present Marigold, a family of conditional generative models and a\nfine-tuning protocol that extracts the knowledge from pretrained latent\ndiffusion models like Stable Diffusion and adapts them for dense image analysis\ntasks, including monocular depth estimation, surface normals prediction, and\nintrinsic decomposition. Marigold requires minimal modification of the\npre-trained latent diffusion model's architecture, trains with small synthetic\ndatasets on a single GPU over a few days, and demonstrates state-of-the-art\nzero-shot generalization. Project page:\nhttps://marigoldcomputervision.github.io"}
{"id": "2505.09366", "pdf": "https://arxiv.org/pdf/2505.09366", "abs": "https://arxiv.org/abs/2505.09366", "authors": ["SeyedMojtaba Mohasel", "Alireza Afzal Aghaei", "Corey Pew"], "title": "Personalized Control for Lower Limb Prosthesis Using Kolmogorov-Arnold Networks", "categories": ["cs.LG"], "comment": null, "summary": "Objective: This paper investigates the potential of learnable activation\nfunctions in Kolmogorov-Arnold Networks (KANs) for personalized control in a\nlower-limb prosthesis. In addition, user-specific vs. pooled training data is\nevaluated to improve machine learning (ML) and Deep Learning (DL) performance\nfor turn intent prediction.\n  Method: Inertial measurement unit (IMU) data from the shank were collected\nfrom five individuals with lower-limb amputation performing turning tasks in a\nlaboratory setting. Ability to classify an upcoming turn was evaluated for\nMultilayer Perceptron (MLP), Kolmogorov-Arnold Network (KAN), convolutional\nneural network (CNN), and fractional Kolmogorov-Arnold Networks (FKAN). The\ncomparison of MLP and KAN (for ML models) and FKAN and CNN (for DL models)\nassessed the effectiveness of learnable activation functions. Models were\ntrained separately on user-specific and pooled data to evaluate the impact of\ntraining data on their performance.\n  Results: Learnable activation functions in KAN and FKAN did not yield\nsignificant improvement compared to MLP and CNN, respectively. Training on\nuser-specific data yielded superior results compared to pooled data for ML\nmodels ($p < 0.05$). In contrast, no significant difference was observed\nbetween user-specific and pooled training for DL models.\n  Significance: These findings suggest that learnable activation functions may\ndemonstrate distinct advantages in datasets involving more complex tasks and\nlarger volumes. In addition, pooled training showed comparable performance to\nuser-specific training in DL models, indicating that model training for\nprosthesis control can utilize data from multiple participants."}
{"id": "2505.08849", "pdf": "https://arxiv.org/pdf/2505.08849", "abs": "https://arxiv.org/abs/2505.08849", "authors": ["Keyu Chen", "Hao Tang", "Qinglin Liu", "Yizhao Xu"], "title": "Improved Algorithms for Differentially Private Language Model Alignment", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Language model alignment is crucial for ensuring that large language models\n(LLMs) align with human preferences, yet it often involves sensitive user data,\nraising significant privacy concerns. While prior work has integrated\ndifferential privacy (DP) with alignment techniques, their performance remains\nlimited. In this paper, we propose novel algorithms for privacy-preserving\nalignment and rigorously analyze their effectiveness across varying privacy\nbudgets and models. Our framework can be deployed on two celebrated alignment\ntechniques, namely direct preference optimization (DPO) and reinforcement\nlearning from human feedback (RLHF). Through systematic experiments on\nlarge-scale language models, we demonstrate that our approach achieves\nstate-of-the-art performance. Notably, one of our algorithms, DP-AdamW,\ncombined with DPO, surpasses existing methods, improving alignment quality by\nup to 15% under moderate privacy budgets ({\\epsilon}=2-5). We further\ninvestigate the interplay between privacy guarantees, alignment efficacy, and\ncomputational demands, providing practical guidelines for optimizing these\ntrade-offs."}
{"id": "2505.09368", "pdf": "https://arxiv.org/pdf/2505.09368", "abs": "https://arxiv.org/abs/2505.09368", "authors": ["Jenny Schmalfuss", "Victor Oei", "Lukas Mehl", "Madlen Bartsch", "Shashank Agnihotri", "Margret Keuper", "Andrés Bruhn"], "title": "RobustSpring: Benchmarking Robustness to Image Corruptions for Optical Flow, Scene Flow and Stereo", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Standard benchmarks for optical flow, scene flow, and stereo vision\nalgorithms generally focus on model accuracy rather than robustness to image\ncorruptions like noise or rain. Hence, the resilience of models to such\nreal-world perturbations is largely unquantified. To address this, we present\nRobustSpring, a comprehensive dataset and benchmark for evaluating robustness\nto image corruptions for optical flow, scene flow, and stereo models.\nRobustSpring applies 20 different image corruptions, including noise, blur,\ncolor changes, quality degradations, and weather distortions, in a time-,\nstereo-, and depth-consistent manner to the high-resolution Spring dataset,\ncreating a suite of 20,000 corrupted images that reflect challenging\nconditions. RobustSpring enables comparisons of model robustness via a new\ncorruption robustness metric. Integration with the Spring benchmark enables\npublic two-axis evaluations of both accuracy and robustness. We benchmark a\ncurated selection of initial models, observing that accurate models are not\nnecessarily robust and that robustness varies widely by corruption type.\nRobustSpring is a new computer vision benchmark that treats robustness as a\nfirst-class citizen to foster models that combine accuracy with resilience. It\nwill be available at https://spring-benchmark.org."}
{"id": "2505.09427", "pdf": "https://arxiv.org/pdf/2505.09427", "abs": "https://arxiv.org/abs/2505.09427", "authors": ["Achref Doula", "Max Mühlhäuser", "Alejandro Sanchez Guinea"], "title": "SafePath: Conformal Prediction for Safe LLM-Based Autonomous Navigation", "categories": ["cs.LG", "cs.RO"], "comment": null, "summary": "Large Language Models (LLMs) show growing promise in autonomous driving by\nreasoning over complex traffic scenarios to generate path plans. However, their\ntendencies toward overconfidence, and hallucinations raise critical safety\nconcerns. We introduce SafePath, a modular framework that augments LLM-based\npath planning with formal safety guarantees using conformal prediction.\nSafePath operates in three stages. In the first stage, we use an LLM that\ngenerates a set of diverse candidate paths, exploring possible trajectories\nbased on agent behaviors and environmental cues. In the second stage, SafePath\nfilters out high-risk trajectories while guaranteeing that at least one safe\noption is included with a user-defined probability, through a multiple-choice\nquestion-answering formulation that integrates conformal prediction. In the\nfinal stage, our approach selects the path with the lowest expected collision\nrisk when uncertainty is low or delegates control to a human when uncertainty\nis high. We theoretically prove that SafePath guarantees a safe trajectory with\na user-defined probability, and we show how its human delegation rate can be\ntuned to balance autonomy and safety. Extensive experiments on nuScenes and\nHighway-env show that SafePath reduces planning uncertainty by 77\\% and\ncollision rates by up to 70\\%, demonstrating effectiveness in making LLM-driven\npath planning more safer."}
{"id": "2505.08854", "pdf": "https://arxiv.org/pdf/2505.08854", "abs": "https://arxiv.org/abs/2505.08854", "authors": ["Yuping Wang", "Shuo Xing", "Cui Can", "Renjie Li", "Hongyuan Hua", "Kexin Tian", "Zhaobin Mo", "Xiangbo Gao", "Keshu Wu", "Sulong Zhou", "Hengxu You", "Juntong Peng", "Junge Zhang", "Zehao Wang", "Rui Song", "Mingxuan Yan", "Walter Zimmer", "Xingcheng Zhou", "Peiran Li", "Zhaohan Lu", "Chia-Ju Chen", "Yue Huang", "Ryan A. Rossi", "Lichao Sun", "Hongkai Yu", "Zhiwen Fan", "Frank Hao Yang", "Yuhao Kang", "Ross Greer", "Chenxi Liu", "Eun Hak Lee", "Xuan Di", "Xinyue Ye", "Liu Ren", "Alois Knoll", "Xiaopeng Li", "Shuiwang Ji", "Masayoshi Tomizuka", "Marco Pavone", "Tianbao Yang", "Jing Du", "Ming-Hsuan Yang", "Hua Wei", "Ziran Wang", "Yang Zhou", "Jiachen Li", "Zhengzhong Tu"], "title": "Generative AI for Autonomous Driving: Frontiers and Opportunities", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "Generative Artificial Intelligence (GenAI) constitutes a transformative\ntechnological wave that reconfigures industries through its unparalleled\ncapabilities for content creation, reasoning, planning, and multimodal\nunderstanding. This revolutionary force offers the most promising path yet\ntoward solving one of engineering's grandest challenges: achieving reliable,\nfully autonomous driving, particularly the pursuit of Level 5 autonomy. This\nsurvey delivers a comprehensive and critical synthesis of the emerging role of\nGenAI across the autonomous driving stack. We begin by distilling the\nprinciples and trade-offs of modern generative modeling, encompassing VAEs,\nGANs, Diffusion Models, and Large Language Models (LLMs). We then map their\nfrontier applications in image, LiDAR, trajectory, occupancy, video generation\nas well as LLM-guided reasoning and decision making. We categorize practical\napplications, such as synthetic data workflows, end-to-end driving strategies,\nhigh-fidelity digital twin systems, smart transportation networks, and\ncross-domain transfer to embodied AI. We identify key obstacles and\npossibilities such as comprehensive generalization across rare cases,\nevaluation and safety checks, budget-limited implementation, regulatory\ncompliance, ethical concerns, and environmental effects, while proposing\nresearch plans across theoretical assurances, trust metrics, transport\nintegration, and socio-technical influence. By unifying these threads, the\nsurvey provides a forward-looking reference for researchers, engineers, and\npolicymakers navigating the convergence of generative AI and advanced\nautonomous mobility. An actively maintained repository of cited works is\navailable at https://github.com/taco-group/GenAI4AD."}
{"id": "2505.09372", "pdf": "https://arxiv.org/pdf/2505.09372", "abs": "https://arxiv.org/abs/2505.09372", "authors": ["Siyuan Yan", "Xieji Li", "Ming Hu", "Yiwen Jiang", "Zhen Yu", "Zongyuan Ge"], "title": "MAKE: Multi-Aspect Knowledge-Enhanced Vision-Language Pretraining for Zero-shot Dermatological Assessment", "categories": ["cs.CV"], "comment": "MICCAI2025 early acceptance; First two authors contribute equally", "summary": "Dermatological diagnosis represents a complex multimodal challenge that\nrequires integrating visual features with specialized clinical knowledge. While\nvision-language pretraining (VLP) has advanced medical AI, its effectiveness in\ndermatology is limited by text length constraints and the lack of structured\ntexts. In this paper, we introduce MAKE, a Multi-Aspect Knowledge-Enhanced\nvision-language pretraining framework for zero-shot dermatological tasks.\nRecognizing that comprehensive dermatological descriptions require multiple\nknowledge aspects that exceed standard text constraints, our framework\nintroduces: (1) a multi-aspect contrastive learning strategy that decomposes\nclinical narratives into knowledge-enhanced sub-texts through large language\nmodels, (2) a fine-grained alignment mechanism that connects subcaptions with\ndiagnostically relevant image features, and (3) a diagnosis-guided weighting\nscheme that adaptively prioritizes different sub-captions based on clinical\nsignificance prior. Through pretraining on 403,563 dermatological image-text\npairs collected from education resources, MAKE significantly outperforms\nstate-of-the-art VLP models on eight datasets across zero-shot skin disease\nclassification, concept annotation, and cross-modal retrieval tasks. Our code\nwill be made publicly available at https: //github.com/SiyuanYan1/MAKE."}
{"id": "2505.09432", "pdf": "https://arxiv.org/pdf/2505.09432", "abs": "https://arxiv.org/abs/2505.09432", "authors": ["Yuzhou Cao", "Han Bao", "Lei Feng", "Bo An"], "title": "Establishing Linear Surrogate Regret Bounds for Convex Smooth Losses via Convolutional Fenchel-Young Losses", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Surrogate regret bounds, also known as excess risk bounds, bridge the gap\nbetween the convergence rates of surrogate and target losses, with linear\nbounds favorable for their lossless regret transfer. While convex smooth\nsurrogate losses are appealing in particular due to the efficient estimation\nand optimization, the existence of a trade-off between the smoothness and\nlinear regret bound has been believed in the community. That being said, the\nbetter optimization and estimation properties of convex smooth surrogate losses\nmay inevitably deteriorate after undergoing the regret transfer onto a target\nloss. We overcome this dilemma for arbitrary discrete target losses by\nconstructing a convex smooth surrogate loss, which entails a linear surrogate\nregret bound composed with a tailored prediction link. The construction is\nbased on Fenchel-Young losses generated by the convolutional negentropy, which\nare equivalent to the infimal convolution of a generalized negentropy and the\ntarget Bayes risk. Consequently, the infimal convolution enables us to derive a\nsmooth loss while maintaining the surrogate regret bound linear. We\nadditionally benefit from the infimal convolution to have a consistent\nestimator of the underlying class probability. Our results are overall a novel\ndemonstration of how convex analysis penetrates into optimization and\nstatistical efficiency in risk minimization."}
{"id": "2505.08878", "pdf": "https://arxiv.org/pdf/2505.08878", "abs": "https://arxiv.org/abs/2505.08878", "authors": ["Dor Tsur", "Carol Xuan Long", "Claudio Mayrink Verdun", "Hsiang Hsu", "Haim Permuter", "Flavio P. Calmon"], "title": "Optimized Couplings for Watermarking Large Language Models", "categories": ["cs.CR", "cs.AI", "cs.IT", "math.IT"], "comment": "Accepted at ISIT25", "summary": "Large-language models (LLMs) are now able to produce text that is, in many\ncases, seemingly indistinguishable from human-generated content. This has\nfueled the development of watermarks that imprint a ``signal'' in LLM-generated\ntext with minimal perturbation of an LLM's output. This paper provides an\nanalysis of text watermarking in a one-shot setting. Through the lens of\nhypothesis testing with side information, we formulate and analyze the\nfundamental trade-off between watermark detection power and distortion in\ngenerated textual quality. We argue that a key component in watermark design is\ngenerating a coupling between the side information shared with the watermark\ndetector and a random partition of the LLM vocabulary. Our analysis identifies\nthe optimal coupling and randomization strategy under the worst-case LLM\nnext-token distribution that satisfies a min-entropy constraint. We provide a\nclosed-form expression of the resulting detection rate under the proposed\nscheme and quantify the cost in a max-min sense. Finally, we provide an array\nof numerical results, comparing the proposed scheme with the theoretical\noptimum and existing schemes, in both synthetic data and LLM watermarking. Our\ncode is available at https://github.com/Carol-Long/CC_Watermark"}
{"id": "2505.09379", "pdf": "https://arxiv.org/pdf/2505.09379", "abs": "https://arxiv.org/abs/2505.09379", "authors": ["Ali Rida Sahili", "Najett Neji", "Hedi Tabia"], "title": "Text-driven Motion Generation: Overview, Challenges and Directions", "categories": ["cs.CV"], "comment": "17 pages, 5 tables", "summary": "Text-driven motion generation offers a powerful and intuitive way to create\nhuman movements directly from natural language. By removing the need for\npredefined motion inputs, it provides a flexible and accessible approach to\ncontrolling animated characters. This makes it especially useful in areas like\nvirtual reality, gaming, human-computer interaction, and robotics. In this\nreview, we first revisit the traditional perspective on motion synthesis, where\nmodels focused on predicting future poses from observed initial sequences,\noften conditioned on action labels. We then provide a comprehensive and\nstructured survey of modern text-to-motion generation approaches, categorizing\nthem from two complementary perspectives: (i) architectural, dividing methods\ninto VAE-based, diffusion-based, and hybrid models; and (ii) motion\nrepresentation, distinguishing between discrete and continuous motion\ngeneration strategies. In addition, we explore the most widely used datasets,\nevaluation methods, and recent benchmarks that have shaped progress in this\narea. With this survey, we aim to capture where the field currently stands,\nbring attention to its key challenges and limitations, and highlight promising\ndirections for future exploration. We hope this work offers a valuable starting\npoint for researchers and practitioners working to push the boundaries of\nlanguage-driven human motion synthesis."}
{"id": "2505.09436", "pdf": "https://arxiv.org/pdf/2505.09436", "abs": "https://arxiv.org/abs/2505.09436", "authors": ["Raghav Garg", "Kapil Sharma", "Karan Gupta"], "title": "CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "comment": null, "summary": "Large Language Models (LLMs) hold immense potential for revolutionizing\nCustomer Experience Management (CXM), particularly in contact center\noperations. However, evaluating their practical utility in complex operational\nenvironments is hindered by data scarcity (due to privacy concerns) and the\nlimitations of current benchmarks. Existing benchmarks often lack realism,\nfailing to incorporate deep knowledge base (KB) integration, real-world noise,\nor critical operational tasks beyond conversational fluency. To bridge this\ngap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset\nspecifically designed for evaluating AI in operational CXM contexts. Given the\ndiversity in possible contact center features, we have developed a scalable\nLLM-powered pipeline that simulates the brand's CXM entities that form the\nfoundation of our datasets-such as knowledge articles including product\nspecifications, issue taxonomies, and contact center conversations. The\nentities closely represent real-world distribution because of controlled noise\ninjection (informed by domain experts) and rigorous automated validation.\nBuilding on this, we release CXMArena, which provides dedicated benchmarks\ntargeting five important operational tasks: Knowledge Base Refinement, Intent\nPrediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with\nIntegrated Tools. Our baseline experiments underscore the benchmark's\ndifficulty: even state of the art embedding and generation models achieve only\n68% accuracy on article search, while standard embedding methods yield a low F1\nscore of 0.3 for knowledge base refinement, highlighting significant challenges\nfor current models necessitating complex pipelines and solutions over\nconventional techniques."}
{"id": "2505.08894", "pdf": "https://arxiv.org/pdf/2505.08894", "abs": "https://arxiv.org/abs/2505.08894", "authors": ["Hiba Eltigani", "Rukhshan Haroon", "Asli Kocak", "Abdullah Bin Faisal", "Noah Martin", "Fahad Dogar"], "title": "WaLLM -- Insights from an LLM-Powered Chatbot deployment via WhatsApp", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": null, "summary": "Recent advances in generative AI, such as ChatGPT, have transformed access to\ninformation in education, knowledge-seeking, and everyday decision-making.\nHowever, in many developing regions, access remains a challenge due to the\npersistent digital divide. To help bridge this gap, we developed WaLLM - a\ncustom AI chatbot over WhatsApp, a widely used communication platform in\ndeveloping regions. Beyond answering queries, WaLLM offers several features to\nenhance user engagement: a daily top question, suggested follow-up questions,\ntrending and recent queries, and a leaderboard-based reward system. Our service\nhas been operational for over 6 months, amassing over 14.7K queries from\napproximately 100 users. In this paper, we present WaLLM's design and a\nsystematic analysis of logs to understand user interactions. Our results show\nthat 55% of user queries seek factual information. \"Health and well-being\" was\nthe most popular topic (28%), including queries about nutrition and disease,\nsuggesting users view WaLLM as a reliable source. Two-thirds of users' activity\noccurred within 24 hours of the daily top question. Users who accessed the\n\"Leaderboard\" interacted with WaLLM 3x as those who did not. We conclude by\ndiscussing implications for culture-based customization, user interface design,\nand appropriate calibration of users' trust in AI systems for developing\nregions."}
{"id": "2505.09380", "pdf": "https://arxiv.org/pdf/2505.09380", "abs": "https://arxiv.org/abs/2505.09380", "authors": ["Qinghui Liu", "Jon Nesvold", "Hanna Raaum", "Elakkyen Murugesu", "Martin Røvang", "Bradley J Maclntosh", "Atle Bjørnerud", "Karoline Skogen"], "title": "Examining Deployment and Refinement of the VIOLA-AI Intracranial Hemorrhage Model Using an Interactive NeoMedSys Platform", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "19 pages, 11 figures, on submission to BMC Methods", "summary": "Background: There are many challenges and opportunities in the clinical\ndeployment of AI tools in radiology. The current study describes a radiology\nsoftware platform called NeoMedSys that can enable efficient deployment and\nrefinements of AI models. We evaluated the feasibility and effectiveness of\nrunning NeoMedSys for three months in real-world clinical settings and focused\non improvement performance of an in-house developed AI model (VIOLA-AI)\ndesigned for intracranial hemorrhage (ICH) detection.\n  Methods: NeoMedSys integrates tools for deploying, testing, and optimizing AI\nmodels with a web-based medical image viewer, annotation system, and\nhospital-wide radiology information systems. A pragmatic investigation was\ndeployed using clinical cases of patients presenting to the largest Emergency\nDepartment in Norway (site-1) with suspected traumatic brain injury (TBI) or\npatients with suspected stroke (site-2). We assessed ICH classification\nperformance as VIOLA-AI encountered new data and underwent pre-planned model\nretraining. Performance metrics included sensitivity, specificity, accuracy,\nand the area under the receiver operating characteristic curve (AUC).\n  Results: NeoMedSys facilitated iterative improvements in the AI model,\nsignificantly enhancing its diagnostic accuracy. Automated bleed detection and\nsegmentation were reviewed in near real-time to facilitate re-training\nVIOLA-AI. The iterative refinement process yielded a marked improvement in\nclassification sensitivity, rising to 90.3% (from 79.2%), and specificity that\nreached 89.3% (from 80.7%). The bleed detection ROC analysis for the entire\nsample demonstrated a high area-under-the-curve (AUC) of 0.949 (from 0.873).\nModel refinement stages were associated with notable gains, highlighting the\nvalue of real-time radiologist feedback."}
{"id": "2505.09458", "pdf": "https://arxiv.org/pdf/2505.09458", "abs": "https://arxiv.org/abs/2505.09458", "authors": ["Jad Mounayer", "Alicia Tierz", "Jerome Tomezyk", "Chady Ghnatios", "Francisco Chinesta"], "title": "Variational Rank Reduction Autoencoder", "categories": ["cs.LG"], "comment": null, "summary": "Deterministic Rank Reduction Autoencoders (RRAEs) enforce by construction a\nregularization on the latent space by applying a truncated SVD. While this\nregularization makes Autoencoders more powerful, using them for generative\npurposes is counter-intuitive due to their deterministic nature. On the other\nhand, Variational Autoencoders (VAEs) are well known for their generative\nabilities by learning a probabilistic latent space. In this paper, we present\nVariational Rank Reduction Autoencoders (VRRAEs), a model that leverages the\nadvantages of both RRAEs and VAEs. Our claims and results show that when\ncarefully sampling the latent space of RRAEs and further regularizing with the\nKullback-Leibler (KL) divergence (similarly to VAEs), VRRAEs outperform RRAEs\nand VAEs. Additionally, we show that the regularization induced by the SVD not\nonly makes VRRAEs better generators than VAEs, but also reduces the possibility\nof posterior collapse. Our results include a synthetic dataset of a small size\nthat showcases the robustness of VRRAEs against collapse, and three real-world\ndatasets; the MNIST, CelebA, and CIFAR-10, over which VRRAEs are shown to\noutperform both VAEs and RRAEs on many random generation and interpolation\ntasks based on the FID score."}
{"id": "2505.08902", "pdf": "https://arxiv.org/pdf/2505.08902", "abs": "https://arxiv.org/abs/2505.08902", "authors": ["Lucas McCullum", "Pelagie Ami Agassi", "Leo Anthony Celi", "Daniel K. Ebner", "Chrystinne Oliveira Fernandes", "Rachel S. Hicklen", "Mkliwa Koumbia", "Lisa Soleymani Lehmann", "David Restrepo"], "title": "Performance Gains of LLMs With Humans in a World of LLMs Versus Humans", "categories": ["cs.HC", "cs.AI", "cs.CL"], "comment": null, "summary": "Currently, a considerable research effort is devoted to comparing LLMs to a\ngroup of human experts, where the term \"expert\" is often ill-defined or\nvariable, at best, in a state of constantly updating LLM releases. Without\nproper safeguards in place, LLMs will threaten to cause harm to the established\nstructure of safe delivery of patient care which has been carefully developed\nthroughout history to keep the safety of the patient at the forefront. A key\ndriver of LLM innovation is founded on community research efforts which, if\ncontinuing to operate under \"humans versus LLMs\" principles, will expedite this\ntrend. Therefore, research efforts moving forward must focus on effectively\ncharacterizing the safe use of LLMs in clinical settings that persist across\nthe rapid development of novel LLM models. In this communication, we\ndemonstrate that rather than comparing LLMs to humans, there is a need to\ndevelop strategies enabling efficient work of humans with LLMs in an almost\nsymbiotic manner."}
{"id": "2505.09385", "pdf": "https://arxiv.org/pdf/2505.09385", "abs": "https://arxiv.org/abs/2505.09385", "authors": ["Xiaoyang Yu", "Xiaoming Wu", "Xin Wang", "Dongrun Li", "Ming Yang", "Peng Cheng"], "title": "FedSaaS: Class-Consistency Federated Semantic Segmentation via Global Prototype Supervision and Local Adversarial Harmonization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Federated semantic segmentation enables pixel-level classification in images\nthrough collaborative learning while maintaining data privacy. However,\nexisting research commonly overlooks the fine-grained class relationships\nwithin the semantic space when addressing heterogeneous problems, particularly\ndomain shift. This oversight results in ambiguities between class\nrepresentation. To overcome this challenge, we propose a novel federated\nsegmentation framework that strikes class consistency, termed FedSaaS.\nSpecifically, we introduce class exemplars as a criterion for both local- and\nglobal-level class representations. On the server side, the uploaded class\nexemplars are leveraged to model class prototypes, which supervise global\nbranch of clients, ensuring alignment with global-level representation. On the\nclient side, we incorporate an adversarial mechanism to harmonize contributions\nof global and local branches, leading to consistent output. Moreover,\nmultilevel contrastive losses are employed on both sides to enforce consistency\nbetween two-level representations in the same semantic space. Extensive\nexperiments on several driving scene segmentation datasets demonstrate that our\nframework outperforms state-of-the-art methods, significantly improving average\nsegmentation accuracy and effectively addressing the class-consistency\nrepresentation problem."}
{"id": "2505.09486", "pdf": "https://arxiv.org/pdf/2505.09486", "abs": "https://arxiv.org/abs/2505.09486", "authors": ["Seyed Roozbeh Razavi Rohani", "Khashayar Khajavi", "Wesley Chung", "Mo Chen", "Sharan Vaswani"], "title": "Preserving Plasticity in Continual Learning with Adaptive Linearity Injection", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in 4th Conference on Lifelong Learning Agents (CoLLAs), 2025", "summary": "Loss of plasticity in deep neural networks is the gradual reduction in a\nmodel's capacity to incrementally learn and has been identified as a key\nobstacle to learning in non-stationary problem settings. Recent work has shown\nthat deep linear networks tend to be resilient towards loss of plasticity.\nMotivated by this observation, we propose Adaptive Linearization (AdaLin), a\ngeneral approach that dynamically adapts each neuron's activation function to\nmitigate plasticity loss. Unlike prior methods that rely on regularization or\nperiodic resets, AdaLin equips every neuron with a learnable parameter and a\ngating mechanism that injects linearity into the activation function based on\nits gradient flow. This adaptive modulation ensures sufficient gradient signal\nand sustains continual learning without introducing additional hyperparameters\nor requiring explicit task boundaries. When used with conventional activation\nfunctions like ReLU, Tanh, and GeLU, we demonstrate that AdaLin can\nsignificantly improve performance on standard benchmarks, including Random\nLabel and Permuted MNIST, Random Label and Shuffled CIFAR-10, and Class-Split\nCIFAR-100. Furthermore, its efficacy is shown in more complex scenarios, such\nas class-incremental learning on CIFAR-100 with a ResNet-18 backbone, and in\nmitigating plasticity loss in off-policy reinforcement learning agents. We\nperform a systematic set of ablations that show that neuron-level adaptation is\ncrucial for good performance and analyze a number of metrics in the network\nthat might be correlated to loss of plasticity."}
{"id": "2505.08904", "pdf": "https://arxiv.org/pdf/2505.08904", "abs": "https://arxiv.org/abs/2505.08904", "authors": ["Varun Nagaraj Rao", "Samantha Dalal", "Andrew Schwartz", "Amna Liaqat", "Dana Calacci", "Andrés Monroy-Hernández"], "title": "FareShare: A Tool for Labor Organizers to Estimate Lost Wages and Contest Arbitrary AI and Algorithmic Deactivations", "categories": ["cs.CY", "cs.AI", "cs.ET", "cs.HC"], "comment": null, "summary": "What happens when a rideshare driver is suddenly locked out of the platform\nconnecting them to riders, wages, and daily work? Deactivation-the abrupt\nremoval of gig workers' platform access-typically occurs through arbitrary AI\nand algorithmic decisions with little explanation or recourse. This represents\none of the most severe forms of algorithmic control and often devastates\nworkers' financial stability. Recent U.S. state policies now mandate appeals\nprocesses and recovering compensation during the period of wrongful\ndeactivation based on past earnings. Yet, labor organizers still lack effective\ntools to support these complex, error-prone workflows. We designed FareShare, a\ncomputational tool automating lost wage estimation for deactivated drivers,\nthrough a 6 month partnership with the State of Washington's largest rideshare\nlabor union. Over the following 3 months, our field deployment of FareShare\nregistered 178 account signups. We observed that the tool could reduce lost\nwage calculation time by over 95%, eliminate manual data entry errors, and\nenable legal teams to generate arbitration-ready reports more efficiently.\nBeyond these gains, the deployment also surfaced important socio-technical\nchallenges around trust, consent, and tool adoption in high-stakes labor\ncontexts."}
{"id": "2505.09406", "pdf": "https://arxiv.org/pdf/2505.09406", "abs": "https://arxiv.org/abs/2505.09406", "authors": ["Yue Wen", "Liang Song", "Yijia Liu", "Siting Zhu", "Yanzi Miao", "Lijun Han", "Hesheng Wang"], "title": "FreeDriveRF: Monocular RGB Dynamic NeRF without Poses for Autonomous Driving via Point-Level Dynamic-Static Decoupling", "categories": ["cs.CV"], "comment": "7 pages, 9 figures, accepted by ICRA2025", "summary": "Dynamic scene reconstruction for autonomous driving enables vehicles to\nperceive and interpret complex scene changes more precisely. Dynamic Neural\nRadiance Fields (NeRFs) have recently shown promising capability in scene\nmodeling. However, many existing methods rely heavily on accurate poses inputs\nand multi-sensor data, leading to increased system complexity. To address this,\nwe propose FreeDriveRF, which reconstructs dynamic driving scenes using only\nsequential RGB images without requiring poses inputs. We innovatively decouple\ndynamic and static parts at the early sampling level using semantic\nsupervision, mitigating image blurring and artifacts. To overcome the\nchallenges posed by object motion and occlusion in monocular camera, we\nintroduce a warped ray-guided dynamic object rendering consistency loss,\nutilizing optical flow to better constrain the dynamic modeling process.\nAdditionally, we incorporate estimated dynamic flow to constrain the pose\noptimization process, improving the stability and accuracy of unbounded scene\nreconstruction. Extensive experiments conducted on the KITTI and Waymo datasets\ndemonstrate the superior performance of our method in dynamic scene modeling\nfor autonomous driving."}
{"id": "2505.09500", "pdf": "https://arxiv.org/pdf/2505.09500", "abs": "https://arxiv.org/abs/2505.09500", "authors": ["Timothy Qian", "Vinith Suriyakumar", "Ashia Wilson", "Dylan Hadfield-Menell"], "title": "Layered Unlearning for Adversarial Relearning", "categories": ["cs.LG"], "comment": "37 pages, 8 figures", "summary": "Our goal is to understand how post-training methods, such as fine-tuning,\nalignment, and unlearning, modify language model behavior and representations.\nWe are particularly interested in the brittle nature of these modifications\nthat makes them easy to bypass through prompt engineering or relearning. Recent\nresults suggest that post-training induces shallow context-dependent\n``circuits'' that suppress specific response patterns. This could be one\nexplanation for the brittleness of post-training. To test this hypothesis, we\ndesign an unlearning algorithm, Layered Unlearning (LU), that creates distinct\ninhibitory mechanisms for a growing subset of the data. By unlearning the first\n$i$ folds while retaining the remaining $k - i$ at the $i$th of $k$ stages, LU\nlimits the ability of relearning on a subset of data to recover the full\ndataset. We evaluate LU through a combination of synthetic and large language\nmodel (LLM) experiments. We find that LU improves robustness to adversarial\nrelearning for several different unlearning methods. Our results contribute to\nthe state-of-the-art of machine unlearning and provide insight into the effect\nof post-training updates."}
{"id": "2505.08916", "pdf": "https://arxiv.org/pdf/2505.08916", "abs": "https://arxiv.org/abs/2505.08916", "authors": ["Chan Le Duc", "Ludovic Brieulle"], "title": "A New Tractable Description Logic under Categorical Semantics", "categories": ["cs.LO", "cs.AI"], "comment": null, "summary": "Biomedical ontologies contain numerous concept or role names involving\nnegative knowledge such as lacks_part, absence_of. Such a representation with\nlabels rather than logical constructors would not allow a reasoner to interpret\nlacks_part as a kind of negation of has_part. It is known that adding negation\nto the tractable Description Logic (DL) EL allowing for conjunction,\nexistential restriction and concept inclusion makes it intractable since the\nobtained logic includes implicitly disjunction and universal restriction which\ninteract with other constructors. In this paper, we propose a new extension of\nEL with a weakened negation allowing to represent negative knowledge while\nretaining tractability. To this end, we introduce categorical semantics of all\nlogical constructors of the DL SH including EL with disjunction, negation,\nuniversal restriction, role inclusion and transitive roles. The categorical\nsemantics of a logical constructor is usually described as a set of categorical\nproperties referring to several objects without using set membership. To\nrestore tractability, we have to weaken semantics of disjunction and universal\nrestriction by identifying \\emph{independent} categorical properties that are\nresponsible for intractability, and dropping them from the set of categorical\nproperties. We show that the logic resulting from weakening semantics is more\nexpressive than EL with the bottom concept, transitive roles and role\ninclusion."}
{"id": "2505.09413", "pdf": "https://arxiv.org/pdf/2505.09413", "abs": "https://arxiv.org/abs/2505.09413", "authors": ["Ma Changfeng", "Bi Ran", "Guo Jie", "Wang Chongjun", "Guo Yanwen"], "title": "Sparse Point Cloud Patches Rendering via Splitting 2D Gaussians", "categories": ["cs.CV"], "comment": "CVPR 2025 Accepted", "summary": "Current learning-based methods predict NeRF or 3D Gaussians from point clouds\nto achieve photo-realistic rendering but still depend on categorical priors,\ndense point clouds, or additional refinements. Hence, we introduce a novel\npoint cloud rendering method by predicting 2D Gaussians from point clouds. Our\nmethod incorporates two identical modules with an entire-patch architecture\nenabling the network to be generalized to multiple datasets. The module\nnormalizes and initializes the Gaussians utilizing the point cloud information\nincluding normals, colors and distances. Then, splitting decoders are employed\nto refine the initial Gaussians by duplicating them and predicting more\naccurate results, making our methodology effectively accommodate sparse point\nclouds as well. Once trained, our approach exhibits direct generalization to\npoint clouds across different categories. The predicted Gaussians are employed\ndirectly for rendering without additional refinement on the rendered images,\nretaining the benefits of 2D Gaussians. We conduct extensive experiments on\nvarious datasets, and the results demonstrate the superiority and\ngeneralization of our method, which achieves SOTA performance. The code is\navailable at\nhttps://github.com/murcherful/GauPCRender}{https://github.com/murcherful/GauPCRender."}
{"id": "2505.09503", "pdf": "https://arxiv.org/pdf/2505.09503", "abs": "https://arxiv.org/abs/2505.09503", "authors": ["Patrik Kenfack", "Samira Ebrahimi Kahou", "Ulrich Aïvodji"], "title": "Towards Fair In-Context Learning with Tabular Foundation Models", "categories": ["cs.LG"], "comment": "24 pages, 10 figures, 4 tables", "summary": "Tabular foundational models have exhibited strong in-context learning (ICL)\ncapabilities on structured data, allowing them to make accurate predictions on\ntest sets without parameter updates, using training examples as context. This\nemerging approach positions itself as a competitive alternative to traditional\ngradient-boosted tree methods. However, while biases in conventional machine\nlearning models are well documented, it remains unclear how these biases\nmanifest in tabular ICL. The paper investigates the fairness implications of\ntabular ICL and explores three preprocessing strategies--correlation removal,\ngroup-balanced demonstration selection, and uncertainty-based demonstration\nselection--to address bias. Comprehensive experiments indicate that\nuncertainty-based demonstration selection consistently enhances group fairness\nof in-context predictions. The source code for reproducing the results of this\nwork can be found at https://github.com/patrikken/Fair-TabICL."}
{"id": "2505.08918", "pdf": "https://arxiv.org/pdf/2505.08918", "abs": "https://arxiv.org/abs/2505.08918", "authors": ["Marina Popova", "Iaroslav Chelombitko", "Aleksey Komissarov"], "title": "When repeats drive the vocabulary: a Byte-Pair Encoding analysis of T2T primate genomes", "categories": ["q-bio.GN", "cs.AI"], "comment": "ICLR 2025 Workshop on Machine Learning for Genomics Explorations", "summary": "The emergence of telomere-to-telomere (T2T) genome assemblies has opened new\navenues for comparative genomics, yet effective tokenization strategies for\ngenomic sequences remain underexplored. In this pilot study, we apply Byte Pair\nEncoding (BPE) to nine T2T primate genomes including three human assemblies by\ntraining independent BPE tokenizers with a fixed vocabulary of 512,000 tokens\nusing our custom tool, dnaBPE. Our analysis reveals that only 11,569 tokens are\nshared across all assemblies, while nearly 991,854 tokens are unique to a\nsingle genome, indicating a rapid decline in shared vocabulary with increasing\nassembly comparisons. Moreover, phylogenetic trees derived from token overlap\nfailed to recapitulate established primate relationships, a discrepancy\nattributed to the disproportionate influence of species-specific high-copy\nrepetitive elements. These findings underscore the dual nature of BPE\ntokenization: while it effectively compresses repetitive sequences, its\nsensitivity to high-copy elements limits its utility as a universal tool for\ncomparative genomics. We discuss potential hybrid strategies and repeat-masking\napproaches to refine genomic tokenization, emphasizing the need for\ndomain-specific adaptations in the development of large-scale genomic language\nmodels. The dnaBPE tool used in this study is open-source and available at\nhttps://github.com/aglabx/dnaBPE."}
{"id": "2505.09415", "pdf": "https://arxiv.org/pdf/2505.09415", "abs": "https://arxiv.org/abs/2505.09415", "authors": ["Hongyang Wang", "Yichen Shi", "Zhuofu Tao", "Yuhao Gao", "Liepiao Zhang", "Xun Lin", "Jun Feng", "Xiaochen Yuan", "Zitong Yu", "Xiaochun Cao"], "title": "FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models", "categories": ["cs.CV"], "comment": null, "summary": "Face anti-spoofing (FAS) is crucial for protecting facial recognition systems\nfrom presentation attacks. Previous methods approached this task as a\nclassification problem, lacking interpretability and reasoning behind the\npredicted results. Recently, multimodal large language models (MLLMs) have\nshown strong capabilities in perception, reasoning, and decision-making in\nvisual tasks. However, there is currently no universal and comprehensive MLLM\nand dataset specifically designed for FAS task. To address this gap, we propose\nFaceShield, a MLLM for FAS, along with the corresponding pre-training and\nsupervised fine-tuning (SFT) datasets, FaceShield-pre10K and FaceShield-sft45K.\nFaceShield is capable of determining the authenticity of faces, identifying\ntypes of spoofing attacks, providing reasoning for its judgments, and detecting\nattack areas. Specifically, we employ spoof-aware vision perception (SAVP) that\nincorporates both the original image and auxiliary information based on prior\nknowledge. We then use an prompt-guided vision token masking (PVTM) strategy to\nrandom mask vision tokens, thereby improving the model's generalization\nability. We conducted extensive experiments on three benchmark datasets,\ndemonstrating that FaceShield significantly outperforms previous deep learning\nmodels and general MLLMs on four FAS tasks, i.e., coarse-grained\nclassification, fine-grained classification, reasoning, and attack\nlocalization. Our instruction datasets, protocols, and codes will be released\nsoon."}
{"id": "2505.09572", "pdf": "https://arxiv.org/pdf/2505.09572", "abs": "https://arxiv.org/abs/2505.09572", "authors": ["Julian Kranz", "Davide Gallon", "Steffen Dereich", "Arnulf Jentzen"], "title": "SAD Neural Networks: Divergent Gradient Flows and Asymptotic Optimality via o-minimal Structures", "categories": ["cs.LG", "math.LO", "math.OC", "stat.ML", "Primary 68T05, Secondary 68T07, 26B40, 03C64, 03C98"], "comment": "27 pages, 4 figures", "summary": "We study gradient flows for loss landscapes of fully connected feed forward\nneural networks with commonly used continuously differentiable activation\nfunctions such as the logistic, hyperbolic tangent, softplus or GELU function.\nWe prove that the gradient flow either converges to a critical point or\ndiverges to infinity while the loss converges to an asymptotic critical value.\nMoreover, we prove the existence of a threshold $\\varepsilon>0$ such that the\nloss value of any gradient flow initialized at most $\\varepsilon$ above the\noptimal level converges to it. For polynomial target functions and sufficiently\nbig architecture and data set, we prove that the optimal loss value is zero and\ncan only be realized asymptotically. From this setting, we deduce our main\nresult that any gradient flow with sufficiently good initialization diverges to\ninfinity. Our proof heavily relies on the geometry of o-minimal structures. We\nconfirm these theoretical findings with numerical experiments and extend our\ninvestigation to real-world scenarios, where we observe an analogous behavior."}
{"id": "2505.08919", "pdf": "https://arxiv.org/pdf/2505.08919", "abs": "https://arxiv.org/abs/2505.08919", "authors": ["Kangxian Xie", "Yufei Zhu", "Kaiming Kuang", "Li Zhang", "Hongwei Bran Li", "Mingchen Gao", "Jiancheng Yang"], "title": "Template-Guided Reconstruction of Pulmonary Segments with Neural Implicit Functions", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "In revision process", "summary": "High-quality 3D reconstruction of pulmonary segments plays a crucial role in\nsegmentectomy and surgical treatment planning for lung cancer. Due to the\nresolution requirement of the target reconstruction, conventional deep\nlearning-based methods often suffer from computational resource constraints or\nlimited granularity. Conversely, implicit modeling is favored due to its\ncomputational efficiency and continuous representation at any resolution. We\npropose a neural implicit function-based method to learn a 3D surface to\nachieve anatomy-aware, precise pulmonary segment reconstruction, represented as\na shape by deforming a learnable template. Additionally, we introduce two\nclinically relevant evaluation metrics to assess the reconstruction\ncomprehensively. Further, due to the absence of publicly available shape\ndatasets to benchmark reconstruction algorithms, we developed a shape dataset\nnamed Lung3D, including the 3D models of 800 labeled pulmonary segments and the\ncorresponding airways, arteries, veins, and intersegmental veins. We\ndemonstrate that the proposed approach outperforms existing methods, providing\na new perspective for pulmonary segment reconstruction. Code and data will be\navailable at https://github.com/M3DV/ImPulSe."}
{"id": "2505.09422", "pdf": "https://arxiv.org/pdf/2505.09422", "abs": "https://arxiv.org/abs/2505.09422", "authors": ["Xiangyuan Peng", "Yu Wang", "Miao Tang", "Bierzynski Kay", "Lorenzo Servadei", "Robert Wille"], "title": "MoRAL: Motion-aware Multi-Frame 4D Radar and LiDAR Fusion for Robust 3D Object Detection", "categories": ["cs.CV"], "comment": null, "summary": "Reliable autonomous driving systems require accurate detection of traffic\nparticipants. To this end, multi-modal fusion has emerged as an effective\nstrategy. In particular, 4D radar and LiDAR fusion methods based on multi-frame\nradar point clouds have demonstrated the effectiveness in bridging the point\ndensity gap. However, they often neglect radar point clouds' inter-frame\nmisalignment caused by object movement during accumulation and do not fully\nexploit the object dynamic information from 4D radar. In this paper, we propose\nMoRAL, a motion-aware multi-frame 4D radar and LiDAR fusion framework for\nrobust 3D object detection. First, a Motion-aware Radar Encoder (MRE) is\ndesigned to compensate for inter-frame radar misalignment from moving objects.\nLater, a Motion Attention Gated Fusion (MAGF) module integrate radar motion\nfeatures to guide LiDAR features to focus on dynamic foreground objects.\nExtensive evaluations on the View-of-Delft (VoD) dataset demonstrate that MoRAL\noutperforms existing methods, achieving the highest mAP of 73.30% in the entire\narea and 88.68% in the driving corridor. Notably, our method also achieves the\nbest AP of 69.67% for pedestrians in the entire area and 96.25% for cyclists in\nthe driving corridor."}
{"id": "2505.09586", "pdf": "https://arxiv.org/pdf/2505.09586", "abs": "https://arxiv.org/abs/2505.09586", "authors": ["Yipeng Zhang", "Longlong Li", "Kelin Xia"], "title": "Rhomboid Tiling for Geometric Graph Deep Learning", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNNs) have proven effective for learning from\ngraph-structured data through their neighborhood-based message passing\nframework. Many hierarchical graph clustering pooling methods modify this\nframework by introducing clustering-based strategies, enabling the construction\nof more expressive and powerful models. However, all of these message passing\nframework heavily rely on the connectivity structure of graphs, limiting their\nability to capture the rich geometric features inherent in geometric graphs. To\naddress this, we propose Rhomboid Tiling (RT) clustering, a novel clustering\nmethod based on the rhomboid tiling structure, which performs clustering by\nleveraging the complex geometric information of the data and effectively\nextracts its higher-order geometric structures. Moreover, we design RTPool, a\nhierarchical graph clustering pooling model based on RT clustering for graph\nclassification tasks. The proposed model demonstrates superior performance,\noutperforming 21 state-of-the-art competitors on all the 7 benchmark datasets."}
{"id": "2505.08939", "pdf": "https://arxiv.org/pdf/2505.08939", "abs": "https://arxiv.org/abs/2505.08939", "authors": ["Suchismita Naik", "Prakash Shukla", "Ike Obi", "Jessica Backus", "Nancy Rasche", "Paul Parsons"], "title": "Tracing the Invisible: Understanding Students' Judgment in AI-Supported Design Work", "categories": ["cs.HC", "cs.AI"], "comment": "5 pages, 2 Tables, In Creativity and Cognition 2025, June 23--25,\n  2025, Virtual, United Kingdom", "summary": "As generative AI tools become integrated into design workflows, students\nincreasingly engage with these tools not just as aids, but as collaborators.\nThis study analyzes reflections from 33 student teams in an HCI design course\nto examine the kinds of judgments students make when using AI tools. We found\nboth established forms of design judgment (e.g., instrumental, appreciative,\nquality) and emergent types: agency-distribution judgment and reliability\njudgment. These new forms capture how students negotiate creative\nresponsibility with AI and assess the trustworthiness of its outputs. Our\nfindings suggest that generative AI introduces new layers of complexity into\ndesign reasoning, prompting students to reflect not only on what AI produces,\nbut also on how and when to rely on it. By foregrounding these judgments, we\noffer a conceptual lens for understanding how students engage in co-creative\nsensemaking with AI in design contexts."}
{"id": "2505.09433", "pdf": "https://arxiv.org/pdf/2505.09433", "abs": "https://arxiv.org/abs/2505.09433", "authors": ["Jiahao Zhu", "Kang You", "Dandan Ding", "Zhan Ma"], "title": "Efficient LiDAR Reflectance Compression via Scanning Serialization", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "Reflectance attributes in LiDAR point clouds provide essential information\nfor downstream tasks but remain underexplored in neural compression methods. To\naddress this, we introduce SerLiC, a serialization-based neural compression\nframework to fully exploit the intrinsic characteristics of LiDAR reflectance.\nSerLiC first transforms 3D LiDAR point clouds into 1D sequences via scan-order\nserialization, offering a device-centric perspective for reflectance analysis.\nEach point is then tokenized into a contextual representation comprising its\nsensor scanning index, radial distance, and prior reflectance, for effective\ndependencies exploration. For efficient sequential modeling, Mamba is\nincorporated with a dual parallelization scheme, enabling simultaneous\nautoregressive dependency capture and fast processing. Extensive experiments\ndemonstrate that SerLiC attains over 2x volume reduction against the original\nreflectance data, outperforming the state-of-the-art method by up to 22%\nreduction of compressed bits while using only 2% of its parameters. Moreover, a\nlightweight version of SerLiC achieves > 10 fps (frames per second) with just\n111K parameters, which is attractive for real-world applications."}
{"id": "2505.09593", "pdf": "https://arxiv.org/pdf/2505.09593", "abs": "https://arxiv.org/abs/2505.09593", "authors": ["Filippo Leveni", "Guilherme Weigert Cassales", "Bernhard Pfahringer", "Albert Bifet", "Giacomo Boracchi"], "title": "Online Isolation Forest", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at International Conference on Machine Learning (ICML 2024)", "summary": "The anomaly detection literature is abundant with offline methods, which\nrequire repeated access to data in memory, and impose impractical assumptions\nwhen applied to a streaming context. Existing online anomaly detection methods\nalso generally fail to address these constraints, resorting to periodic\nretraining to adapt to the online context. We propose Online-iForest, a novel\nmethod explicitly designed for streaming conditions that seamlessly tracks the\ndata generating process as it evolves over time. Experimental validation on\nreal-world datasets demonstrated that Online-iForest is on par with online\nalternatives and closely rivals state-of-the-art offline anomaly detection\ntechniques that undergo periodic retraining. Notably, Online-iForest\nconsistently outperforms all competitors in terms of efficiency, making it a\npromising solution in applications where fast identification of anomalies is of\nprimary importance such as cybersecurity, fraud and fault detection."}
{"id": "2505.08964", "pdf": "https://arxiv.org/pdf/2505.08964", "abs": "https://arxiv.org/abs/2505.08964", "authors": ["Majed Jaber", "Julien Michel", "Nicolas Boutry", "Pierre Parrend"], "title": "GPML: Graph Processing for Machine Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "The dramatic increase of complex, multi-step, and rapidly evolving attacks in\ndynamic networks involves advanced cyber-threat detectors. The GPML (Graph\nProcessing for Machine Learning) library addresses this need by transforming\nraw network traffic traces into graph representations, enabling advanced\ninsights into network behaviors. The library provides tools to detect anomalies\nin interaction and community shifts in dynamic networks. GPML supports\ncommunity and spectral metrics extraction, enhancing both real-time detection\nand historical forensics analysis. This library supports modern cybersecurity\nchallenges with a robust, graph-based approach."}
{"id": "2505.09435", "pdf": "https://arxiv.org/pdf/2505.09435", "abs": "https://arxiv.org/abs/2505.09435", "authors": ["Yili He", "Yan Zhu", "Peiyao Fu", "Ruijie Yang", "Tianyi Chen", "Zhihua Wang", "Quanlin Li", "Pinghong Zhou", "Xian Yang", "Shuo Wang"], "title": "Endo-CLIP: Progressive Self-Supervised Pre-training on Raw Colonoscopy Records", "categories": ["cs.CV", "cs.AI"], "comment": "Early accepted to MICCAI 2025", "summary": "Pre-training on image-text colonoscopy records offers substantial potential\nfor improving endoscopic image analysis, but faces challenges including\nnon-informative background images, complex medical terminology, and ambiguous\nmulti-lesion descriptions. We introduce Endo-CLIP, a novel self-supervised\nframework that enhances Contrastive Language-Image Pre-training (CLIP) for this\ndomain. Endo-CLIP's three-stage framework--cleansing, attunement, and\nunification--addresses these challenges by (1) removing background frames, (2)\nleveraging large language models to extract clinical attributes for\nfine-grained contrastive learning, and (3) employing patient-level\ncross-attention to resolve multi-polyp ambiguities. Extensive experiments\ndemonstrate that Endo-CLIP significantly outperforms state-of-the-art\npre-training methods in zero-shot and few-shot polyp detection and\nclassification, paving the way for more accurate and clinically relevant\nendoscopic analysis."}
{"id": "2505.09602", "pdf": "https://arxiv.org/pdf/2505.09602", "abs": "https://arxiv.org/abs/2505.09602", "authors": ["David Khachaturov", "Robert Mullins"], "title": "Adversarial Suffix Filtering: a Defense Pipeline for LLMs", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Large Language Models (LLMs) are increasingly embedded in autonomous systems\nand public-facing environments, yet they remain susceptible to jailbreak\nvulnerabilities that may undermine their security and trustworthiness.\nAdversarial suffixes are considered to be the current state-of-the-art\njailbreak, consistently outperforming simpler methods and frequently succeeding\neven in black-box settings. Existing defenses rely on access to the internal\narchitecture of models limiting diverse deployment, increase memory and\ncomputation footprints dramatically, or can be bypassed with simple prompt\nengineering methods. We introduce $\\textbf{Adversarial Suffix Filtering}$\n(ASF), a lightweight novel model-agnostic defensive pipeline designed to\nprotect LLMs against adversarial suffix attacks. ASF functions as an input\npreprocessor and sanitizer that detects and filters adversarially crafted\nsuffixes in prompts, effectively neutralizing malicious injections. We\ndemonstrate that ASF provides comprehensive defense capabilities across both\nblack-box and white-box attack settings, reducing the attack efficacy of\nstate-of-the-art adversarial suffix generation methods to below 4%, while only\nminimally affecting the target model's capabilities in non-adversarial\nscenarios."}
{"id": "2505.09003", "pdf": "https://arxiv.org/pdf/2505.09003", "abs": "https://arxiv.org/abs/2505.09003", "authors": ["Zeki Doruk Erden", "Donia Gasmi", "Boi Faltings"], "title": "Continual Reinforcement Learning via Autoencoder-Driven Task and New Environment Recognition", "categories": ["cs.LG", "cs.AI"], "comment": "Published in the Autonomous Robots and Multirobot Systems (ARMS)\n  workshop at AAMAS 2025", "summary": "Continual learning for reinforcement learning agents remains a significant\nchallenge, particularly in preserving and leveraging existing information\nwithout an external signal to indicate changes in tasks or environments. In\nthis study, we explore the effectiveness of autoencoders in detecting new tasks\nand matching observed environments to previously encountered ones. Our approach\nintegrates policy optimization with familiarity autoencoders within an\nend-to-end continual learning system. This system can recognize and learn new\ntasks or environments while preserving knowledge from earlier experiences and\ncan selectively retrieve relevant knowledge when re-encountering a known\nenvironment. Initial results demonstrate successful continual learning without\nexternal signals to indicate task changes or reencounters, showing promise for\nthis methodology."}
{"id": "2505.09450", "pdf": "https://arxiv.org/pdf/2505.09450", "abs": "https://arxiv.org/abs/2505.09450", "authors": ["Yuelin Zhang", "Qingpeng Ding", "Long Lei", "Yongxuan Feng", "Raymond Shing-Yan Tang", "Shing Shin Cheng"], "title": "MrTrack: Register Mamba for Needle Tracking with Rapid Reciprocating Motion during Ultrasound-Guided Aspiration Biopsy", "categories": ["cs.CV"], "comment": "Early Accepted by MICCAI 2025", "summary": "Ultrasound-guided fine needle aspiration (FNA) biopsy is a common minimally\ninvasive diagnostic procedure. However, an aspiration needle tracker addressing\nrapid reciprocating motion is still missing. MrTrack, an aspiration needle\ntracker with a mamba-based register mechanism, is proposed. MrTrack leverages a\nMamba-based register extractor to sequentially distill global context from each\nhistorical search map, storing these temporal cues in a register bank. The\nMamba-based register retriever then retrieves temporal prompts from the\nregister bank to provide external cues when current vision features are\ntemporarily unusable due to rapid reciprocating motion and imaging degradation.\nA self-supervised register diversify loss is proposed to encourage feature\ndiversity and dimension independence within the learned register, mitigating\nfeature collapse. Comprehensive experiments conducted on both motorized and\nmanual aspiration datasets demonstrate that MrTrack not only outperforms\nstate-of-the-art trackers in accuracy and robustness but also achieves superior\ninference efficiency."}
{"id": "2505.07363", "pdf": "https://arxiv.org/pdf/2505.07363", "abs": "https://arxiv.org/abs/2505.07363", "authors": ["Serge Massar"], "title": "Equilibrium Propagation for Learning in Lagrangian Dynamical Systems", "categories": ["nlin.CD", "cs.LG", "physics.data-an"], "comment": "8 pages, 1 figure", "summary": "We propose a method for training dynamical systems governed by Lagrangian\nmechanics using Equilibrium Propagation. Our approach extends Equilibrium\nPropagation -- initially developed for energy-based models -- to dynamical\ntrajectories by leveraging the principle of action extremization. Training is\nachieved by gently nudging trajectories toward desired targets and measuring\nhow the variables conjugate to the parameters to be trained respond. This\nmethod is particularly suited to systems with periodic boundary conditions or\nfixed initial and final states, enabling efficient parameter updates without\nrequiring explicit backpropagation through time. In the case of periodic\nboundary conditions, this approach yields the semiclassical limit of Quantum\nEquilibrium Propagation. Applications to systems with dissipation are also\ndiscussed."}
{"id": "2505.09021", "pdf": "https://arxiv.org/pdf/2505.09021", "abs": "https://arxiv.org/abs/2505.09021", "authors": ["Maria Dhakal", "Chia-Yi Su", "Robert Wallace", "Chris Fakhimi", "Aakash Bansal", "Toby Li", "Yu Huang", "Collin McMillan"], "title": "AI-Mediated Code Comment Improvement", "categories": ["cs.SE", "cs.AI", "cs.PL"], "comment": null, "summary": "This paper describes an approach to improve code comments along different\nquality axes by rewriting those comments with customized Artificial\nIntelligence (AI)-based tools. We conduct an empirical study followed by\ngrounded theory qualitative analysis to determine the quality axes to improve.\nThen we propose a procedure using a Large Language Model (LLM) to rewrite\nexisting code comments along the quality axes. We implement our procedure using\nGPT-4o, then distil the results into a smaller model capable of being run\nin-house, so users can maintain data custody. We evaluate both our approach\nusing GPT-4o and the distilled model versions. We show in an evaluation how our\nprocedure improves code comments along the quality axes. We release all data\nand source code in an online repository for reproducibility."}
{"id": "2505.09455", "pdf": "https://arxiv.org/pdf/2505.09455", "abs": "https://arxiv.org/abs/2505.09455", "authors": ["Jeremie Ochin", "Raphael Chekroun", "Bogdan Stanciulescu", "Sotiris Manitsaris"], "title": "Beyond Pixels: Leveraging the Language of Soccer to Improve Spatio-Temporal Action Detection in Broadcast Videos", "categories": ["cs.CV"], "comment": "12 pages, submitted to Advanced Concepts for Intelligent Vision\n  Systems 2025", "summary": "State-of-the-art spatio-temporal action detection (STAD) methods show\npromising results for extracting soccer events from broadcast videos. However,\nwhen operated in the high-recall, low-precision regime required for exhaustive\nevent coverage in soccer analytics, their lack of contextual understanding\nbecomes apparent: many false positives could be resolved by considering a\nbroader sequence of actions and game-state information. In this work, we\naddress this limitation by reasoning at the game level and improving STAD\nthrough the addition of a denoising sequence transduction task. Sequences of\nnoisy, context-free player-centric predictions are processed alongside clean\ngame state information using a Transformer-based encoder-decoder model. By\nmodeling extended temporal context and reasoning jointly over team-level\ndynamics, our method leverages the \"language of soccer\" - its tactical\nregularities and inter-player dependencies - to generate \"denoised\" sequences\nof actions. This approach improves both precision and recall in low-confidence\nregimes, enabling more reliable event extraction from broadcast video and\ncomplementing existing pixel-based methods."}
{"id": "2505.08801", "pdf": "https://arxiv.org/pdf/2505.08801", "abs": "https://arxiv.org/abs/2505.08801", "authors": ["Md. Sakib Hassan Chowdhury", "Md. Hafiz Ahamed", "Bishowjit Paul", "Sarafat Hussain Abhi", "Abu Bakar Siddique", "Md. Robius Sany"], "title": "OptiGait-LGBM: An Efficient Approach of Gait-based Person Re-identification in Non-Overlapping Regions", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": "12 pages, 17 figures", "summary": "Gait recognition, known for its ability to identify individuals from a\ndistance, has gained significant attention in recent times due to its\nnon-intrusive verification. While video-based gait identification systems\nperform well on large public datasets, their performance drops when applied to\nreal-world, unconstrained gait data due to various factors. Among these,\nuncontrolled outdoor environments, non-overlapping camera views, varying\nillumination, and computational efficiency are core challenges in gait-based\nauthentication. Currently, no dataset addresses all these challenges\nsimultaneously. In this paper, we propose an OptiGait-LGBM model capable of\nrecognizing person re-identification under these constraints using a skeletal\nmodel approach, which helps mitigate inconsistencies in a person's appearance.\nThe model constructs a dataset from landmark positions, minimizing memory usage\nby using non-sequential data. A benchmark dataset, RUET-GAIT, is introduced to\nrepresent uncontrolled gait sequences in complex outdoor environments. The\nprocess involves extracting skeletal joint landmarks, generating numerical\ndatasets, and developing an OptiGait-LGBM gait classification model. Our aim is\nto address the aforementioned challenges with minimal computational cost\ncompared to existing methods. A comparative analysis with ensemble techniques\nsuch as Random Forest and CatBoost demonstrates that the proposed approach\noutperforms them in terms of accuracy, memory usage, and training time. This\nmethod provides a novel, low-cost, and memory-efficient video-based gait\nrecognition solution for real-world scenarios."}
{"id": "2505.09022", "pdf": "https://arxiv.org/pdf/2505.09022", "abs": "https://arxiv.org/abs/2505.09022", "authors": ["Annan Yu", "N. Benjamin Erichson"], "title": "Block-Biased Mamba for Long-Range Sequence Processing", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Mamba extends earlier state space models (SSMs) by introducing\ninput-dependent dynamics, and has demonstrated strong empirical performance\nacross a range of domains, including language modeling, computer vision, and\nfoundation models. However, a surprising weakness remains: despite being built\non architectures designed for long-range dependencies, Mamba performs poorly on\nlong-range sequential tasks. Understanding and addressing this gap is important\nfor improving Mamba's universality and versatility. In this work, we analyze\nMamba's limitations through three perspectives: expressiveness, inductive bias,\nand training stability. Our theoretical results show how Mamba falls short in\neach of these aspects compared to earlier SSMs such as S4D. To address these\nissues, we propose $\\text{B}_2\\text{S}_6$, a simple extension of Mamba's S6\nunit that combines block-wise selective dynamics with a channel-specific bias.\nWe prove that these changes equip the model with a better-suited inductive bias\nand improve its expressiveness and stability. Empirically,\n$\\text{B}_2\\text{S}_6$ outperforms S4 and S4D on Long-Range Arena (LRA) tasks\nwhile maintaining Mamba's performance on language modeling benchmarks."}
{"id": "2505.09466", "pdf": "https://arxiv.org/pdf/2505.09466", "abs": "https://arxiv.org/abs/2505.09466", "authors": ["Xi Chen", "Shiyang Zhou", "Muqi Huang", "Jiaxu Feng", "Yun Xiong", "Kun Zhou", "Biao Yang", "Yuhui Zhang", "Huishuai Bao", "Sijia Peng", "Chuan Li", "Feng Shi"], "title": "A 2D Semantic-Aware Position Encoding for Vision Transformers", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages, 4 figures, 3 tables", "summary": "Vision transformers have demonstrated significant advantages in computer\nvision tasks due to their ability to capture long-range dependencies and\ncontextual relationships through self-attention. However, existing position\nencoding techniques, which are largely borrowed from natural language\nprocessing, fail to effectively capture semantic-aware positional relationships\nbetween image patches. Traditional approaches like absolute position encoding\nand relative position encoding primarily focus on 1D linear position\nrelationship, often neglecting the semantic similarity between distant yet\ncontextually related patches. These limitations hinder model generalization,\ntranslation equivariance, and the ability to effectively handle repetitive or\nstructured patterns in images. In this paper, we propose 2-Dimensional\nSemantic-Aware Position Encoding ($\\text{SaPE}^2$), a novel position encoding\nmethod with semantic awareness that dynamically adapts position representations\nby leveraging local content instead of fixed linear position relationship or\nspatial coordinates. Our method enhances the model's ability to generalize\nacross varying image resolutions and scales, improves translation equivariance,\nand better aggregates features for visually similar but spatially distant\npatches. By integrating $\\text{SaPE}^2$ into vision transformers, we bridge the\ngap between position encoding and perceptual similarity, thereby improving\nperformance on computer vision tasks."}
{"id": "2505.08804", "pdf": "https://arxiv.org/pdf/2505.08804", "abs": "https://arxiv.org/abs/2505.08804", "authors": ["Longtian Wang", "Xiaofei Xie", "Tianlin Li", "Yuhan Zhi", "Chao Shen"], "title": "TokenProber: Jailbreaking Text-to-image Models via Fine-grained Word Impact Analysis", "categories": ["cs.CR", "cs.LG"], "comment": "13 pages, 5 figures", "summary": "Text-to-image (T2I) models have significantly advanced in producing\nhigh-quality images. However, such models have the ability to generate images\ncontaining not-safe-for-work (NSFW) content, such as pornography, violence,\npolitical content, and discrimination. To mitigate the risk of generating NSFW\ncontent, refusal mechanisms, i.e., safety checkers, have been developed to\ncheck potential NSFW content. Adversarial prompting techniques have been\ndeveloped to evaluate the robustness of the refusal mechanisms. The key\nchallenge remains to subtly modify the prompt in a way that preserves its\nsensitive nature while bypassing the refusal mechanisms. In this paper, we\nintroduce TokenProber, a method designed for sensitivity-aware differential\ntesting, aimed at evaluating the robustness of the refusal mechanisms in T2I\nmodels by generating adversarial prompts. Our approach is based on the key\nobservation that adversarial prompts often succeed by exploiting discrepancies\nin how T2I models and safety checkers interpret sensitive content. Thus, we\nconduct a fine-grained analysis of the impact of specific words within prompts,\ndistinguishing between dirty words that are essential for NSFW content\ngeneration and discrepant words that highlight the different sensitivity\nassessments between T2I models and safety checkers. Through the\nsensitivity-aware mutation, TokenProber generates adversarial prompts, striking\na balance between maintaining NSFW content generation and evading detection.\nOur evaluation of TokenProber against 5 safety checkers on 3 popular T2I\nmodels, using 324 NSFW prompts, demonstrates its superior effectiveness in\nbypassing safety filters compared to existing methods (e.g., 54%+ increase on\naverage), highlighting TokenProber's ability to uncover robustness issues in\nthe existing refusal mechanisms."}
{"id": "2505.09027", "pdf": "https://arxiv.org/pdf/2505.09027", "abs": "https://arxiv.org/abs/2505.09027", "authors": ["Yi Cui"], "title": "Tests as Prompt: A Test-Driven-Development Benchmark for LLM Code Generation", "categories": ["cs.SE", "cs.AI"], "comment": "arXiv admin note: text overlap with arXiv:2409.05177", "summary": "We introduce WebApp1K, a novel benchmark for evaluating large language models\n(LLMs) in test-driven development (TDD) tasks, where test cases serve as both\nprompt and verification for code generation. Unlike traditional approaches\nrelying on natural language prompts, our benchmark emphasizes the ability of\nLLMs to interpret and implement functionality directly from test cases,\nreflecting real-world software development practices. Comprising 1000 diverse\nchallenges across 20 application domains, the benchmark evaluates LLMs on their\nability to generate compact, functional code under the constraints of context\nlength and multi-feature complexity. Our findings highlight instruction\nfollowing and in-context learning as critical capabilities for TDD success,\nsurpassing the importance of general coding proficiency or pretraining\nknowledge. Through comprehensive evaluation of 19 frontier models, we reveal\nperformance bottlenecks, such as instruction loss in long prompts, and provide\na detailed error analysis spanning multiple root causes. This work underscores\nthe practical value of TDD-specific benchmarks and lays the foundation for\nadvancing LLM capabilities in rigorous, application-driven coding scenarios."}
{"id": "2505.09484", "pdf": "https://arxiv.org/pdf/2505.09484", "abs": "https://arxiv.org/abs/2505.09484", "authors": ["Yingjie Ma", "Xun Lin", "Zitong Yu", "Xin Liu", "Xiaochen Yuan", "Weicheng Xie", "Linlin Shen"], "title": "Denoising and Alignment: Rethinking Domain Generalization for Multimodal Face Anti-Spoofing", "categories": ["cs.CV"], "comment": null, "summary": "Face Anti-Spoofing (FAS) is essential for the security of facial recognition\nsystems in diverse scenarios such as payment processing and surveillance.\nCurrent multimodal FAS methods often struggle with effective generalization,\nmainly due to modality-specific biases and domain shifts. To address these\nchallenges, we introduce the \\textbf{M}ulti\\textbf{m}odal \\textbf{D}enoising\nand \\textbf{A}lignment (\\textbf{MMDA}) framework. By leveraging the zero-shot\ngeneralization capability of CLIP, the MMDA framework effectively suppresses\nnoise in multimodal data through denoising and alignment mechanisms, thereby\nsignificantly enhancing the generalization performance of cross-modal\nalignment. The \\textbf{M}odality-\\textbf{D}omain Joint \\textbf{D}ifferential\n\\textbf{A}ttention (\\textbf{MD2A}) module in MMDA concurrently mitigates the\nimpacts of domain and modality noise by refining the attention mechanism based\non extracted common noise features. Furthermore, the \\textbf{R}epresentation\n\\textbf{S}pace \\textbf{S}oft (\\textbf{RS2}) Alignment strategy utilizes the\npre-trained CLIP model to align multi-domain multimodal data into a generalized\nrepresentation space in a flexible manner, preserving intricate representations\nand enhancing the model's adaptability to various unseen conditions. We also\ndesign a \\textbf{U}-shaped \\textbf{D}ual \\textbf{S}pace \\textbf{A}daptation\n(\\textbf{U-DSA}) module to enhance the adaptability of representations while\nmaintaining generalization performance. These improvements not only enhance the\nframework's generalization capabilities but also boost its ability to represent\ncomplex representations. Our experimental results on four benchmark datasets\nunder different evaluation protocols demonstrate that the MMDA framework\noutperforms existing state-of-the-art methods in terms of cross-domain\ngeneralization and multimodal detection accuracy. The code will be released\nsoon."}
{"id": "2505.08814", "pdf": "https://arxiv.org/pdf/2505.08814", "abs": "https://arxiv.org/abs/2505.08814", "authors": ["Wenkai Li", "Xiaoqi Li", "Yingjie Mao", "Yishun Wang"], "title": "Towards Understanding Deep Learning Model in Image Recognition via Coverage Test", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Deep neural networks (DNNs) play a crucial role in the field of artificial\nintelligence, and their security-related testing has been a prominent research\nfocus. By inputting test cases, the behavior of models is examined for\nanomalies, and coverage metrics are utilized to determine the extent of neurons\ncovered by these test cases. With the widespread application and advancement of\nDNNs, different types of neural behaviors have garnered attention, leading to\nthe emergence of various coverage metrics for neural networks. However, there\nis currently a lack of empirical research on these coverage metrics,\nspecifically in analyzing the relationships and patterns between model depth,\nconfiguration information, and neural network coverage. This paper aims to\ninvestigate the relationships and patterns of four coverage metrics: primary\nfunctionality, boundary, hierarchy, and structural coverage. A series of\nempirical experiments were conducted, selecting LeNet, VGG, and ResNet as\ndifferent DNN architectures, along with 10 models of varying depths ranging\nfrom 5 to 54 layers, to compare and study the relationships between different\ndepths, configuration information, and various neural network coverage metrics.\nAdditionally, an investigation was carried out on the relationships between\nmodified decision/condition coverage and dataset size. Finally, three potential\nfuture directions are proposed to further contribute to the security testing of\nDNN Models."}
{"id": "2505.09040", "pdf": "https://arxiv.org/pdf/2505.09040", "abs": "https://arxiv.org/abs/2505.09040", "authors": ["Owen Kwon", "Abraham George", "Alison Bartsch", "Amir Barati Farimani"], "title": "RT-cache: Efficient Robot Trajectory Retrieval System", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "9 pages, 5 figures. Submitted to an IEEE robotics conference", "summary": "This paper introduces RT-cache, a novel trajectorymemory pipeline that\naccelerates real-world robot inference by leveraging big-data retrieval and\nlearning from experience. While modern Vision-Language-Action (VLA) models can\nhandle diverse robotic tasks, they often incur high per-step inference costs,\nresulting in significant latency, sometimes minutes per task. In contrast,\nRT-cache stores a large-scale Memory of previously successful robot\ntrajectories and retrieves relevant multistep motion snippets, drastically\nreducing inference overhead. By integrating a Memory Builder with a Trajectory\nRetrieval, we develop an efficient retrieval process that remains tractable\neven for extremely large datasets. RT-cache flexibly accumulates real-world\nexperiences and replays them whenever the current scene matches past states,\nadapting quickly to new or unseen environments with only a few additional\nsamples. Experiments on the Open-X Embodiment Dataset and other real-world data\ndemonstrate that RT-cache completes tasks both faster and more successfully\nthan a baseline lacking retrieval, suggesting a practical, data-driven solution\nfor real-time manipulation."}
{"id": "2505.09498", "pdf": "https://arxiv.org/pdf/2505.09498", "abs": "https://arxiv.org/abs/2505.09498", "authors": ["Bo Zhang", "Shuo Li", "Runhe Tian", "Yang Yang", "Jixin Tang", "Jinhao Zhou", "Lin Ma"], "title": "Flash-VL 2B: Optimizing Vision-Language Model Performance for Ultra-Low Latency and High Throughput", "categories": ["cs.CV", "cs.AI"], "comment": "18 pages, 7 figures", "summary": "In this paper, we introduce Flash-VL 2B, a novel approach to optimizing\nVision-Language Models (VLMs) for real-time applications, targeting ultra-low\nlatency and high throughput without sacrificing accuracy. Leveraging advanced\narchitectural enhancements and efficient computational strategies, Flash-VL 2B\nis designed to maximize throughput by reducing processing time while\nmaintaining competitive performance across multiple vision-language benchmarks.\nOur approach includes tailored architectural choices, token compression\nmechanisms, data curation, training schemes, and a novel image processing\ntechnique called implicit semantic stitching that effectively balances\ncomputational load and model performance. Through extensive evaluations on 11\nstandard VLM benchmarks, we demonstrate that Flash-VL 2B achieves\nstate-of-the-art results in both speed and accuracy, making it a promising\nsolution for deployment in resource-constrained environments and large-scale\nreal-time applications."}
{"id": "2505.08816", "pdf": "https://arxiv.org/pdf/2505.08816", "abs": "https://arxiv.org/abs/2505.08816", "authors": ["Ippokratis Koukoulis", "Ilias Syrigos", "Thanasis Korakis"], "title": "Self-Supervised Transformer-based Contrastive Learning for Intrusion Detection Systems", "categories": ["cs.CR", "cs.LG"], "comment": "Accepted at IFIP Networking 2025. Code available at\n  https://github.com/koukipp/contrastive_transformers_ids", "summary": "As the digital landscape becomes more interconnected, the frequency and\nseverity of zero-day attacks, have significantly increased, leading to an\nurgent need for innovative Intrusion Detection Systems (IDS). Machine\nLearning-based IDS that learn from the network traffic characteristics and can\ndiscern attack patterns from benign traffic offer an advanced solution to\ntraditional signature-based IDS. However, they heavily rely on labeled\ndatasets, and their ability to generalize when encountering unseen traffic\npatterns remains a challenge. This paper proposes a novel self-supervised\ncontrastive learning approach based on transformer encoders, specifically\ntailored for generalizable intrusion detection on raw packet sequences. Our\nproposed learning scheme employs a packet-level data augmentation strategy\ncombined with a transformer-based architecture to extract and generate\nmeaningful representations of traffic flows. Unlike traditional methods reliant\non handcrafted statistical features (NetFlow), our approach automatically\nlearns comprehensive packet sequence representations, significantly enhancing\nperformance in anomaly identification tasks and supervised learning for\nintrusion detection. Our transformer-based framework exhibits better\nperformance in comparison to existing NetFlow self-supervised methods.\nSpecifically, we achieve up to a 3% higher AUC in anomaly detection for\nintra-dataset evaluation and up to 20% higher AUC scores in inter-dataset\nevaluation. Moreover, our model provides a strong baseline for supervised\nintrusion detection with limited labeled data, exhibiting an improvement over\nself-supervised NetFlow models of up to 1.5% AUC when pretrained and evaluated\non the same dataset. Additionally, we show the adaptability of our pretrained\nmodel when fine-tuned across different datasets, demonstrating strong\nperformance even when lacking benign data from the target domain."}
{"id": "2505.09062", "pdf": "https://arxiv.org/pdf/2505.09062", "abs": "https://arxiv.org/abs/2505.09062", "authors": ["Junda Zhao", "Yuliang Song", "Eldan Cohen"], "title": "Variational Prefix Tuning for Diverse and Accurate Code Summarization Using Pre-trained Language Models", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.7"], "comment": "Accepted by the Journal of Systems and Software", "summary": "Recent advancements in source code summarization have leveraged\ntransformer-based pre-trained models, including Large Language Models of Code\n(LLMCs), to automate and improve the generation of code summaries. However,\nexisting methods often focus on generating a single high-quality summary for a\ngiven source code, neglecting scenarios where the generated summary might be\ninadequate and alternative options are needed. In this paper, we introduce\nVariational Prefix Tuning (VPT), a novel approach that enhances pre-trained\nmodels' ability to generate diverse yet accurate sets of summaries, allowing\nthe user to choose the most suitable one for the given source code. Our method\nintegrates a Conditional Variational Autoencoder (CVAE) framework as a modular\ncomponent into pre-trained models, enabling us to model the distribution of\nobserved target summaries and sample continuous embeddings to be used as\nprefixes to steer the generation of diverse outputs during decoding.\nImportantly, we construct our method in a parameter-efficient manner,\neliminating the need for expensive model retraining, especially when using\nLLMCs. Furthermore, we employ a bi-criteria reranking method to select a subset\nof generated summaries, optimizing both the diversity and the accuracy of the\noptions presented to users. We present extensive experimental evaluations using\nwidely used datasets and current state-of-the-art pre-trained code\nsummarization models to demonstrate the effectiveness of our approach and its\nadaptability across models."}
{"id": "2505.09528", "pdf": "https://arxiv.org/pdf/2505.09528", "abs": "https://arxiv.org/abs/2505.09528", "authors": ["Jeffrey Wen", "Rizwan Ahmad", "Philip Schniter"], "title": "Conformal Bounds on Full-Reference Image Quality for Imaging Inverse Problems", "categories": ["cs.CV"], "comment": null, "summary": "In imaging inverse problems, we would like to know how close the recovered\nimage is to the true image in terms of full-reference image quality (FRIQ)\nmetrics like PSNR, SSIM, LPIPS, etc. This is especially important in\nsafety-critical applications like medical imaging, where knowing that, say, the\nSSIM was poor could potentially avoid a costly misdiagnosis. But since we don't\nknow the true image, computing FRIQ is non-trivial. In this work, we combine\nconformal prediction with approximate posterior sampling to construct bounds on\nFRIQ that are guaranteed to hold up to a user-specified error probability. We\ndemonstrate our approach on image denoising and accelerated magnetic resonance\nimaging (MRI) problems. Code is available at\nhttps://github.com/jwen307/quality_uq."}
{"id": "2505.08817", "pdf": "https://arxiv.org/pdf/2505.08817", "abs": "https://arxiv.org/abs/2505.08817", "authors": ["Camilo Carvajal Reyes", "Joaquín Fontbona", "Felipe Tobar"], "title": "Towards SFW sampling for diffusion models via external conditioning", "categories": ["cs.CV", "cs.LG"], "comment": "Accepcted at IJCNN 2025", "summary": "Score-based generative models (SBM), also known as diffusion models, are the\nde facto state of the art for image synthesis. Despite their unparalleled\nperformance, SBMs have recently been in the spotlight for being tricked into\ncreating not-safe-for-work (NSFW) content, such as violent images and\nnon-consensual nudity. Current approaches that prevent unsafe generation are\nbased on the models' own knowledge, and the majority of them require\nfine-tuning. This article explores the use of external sources for ensuring\nsafe outputs in SBMs. Our safe-for-work (SFW) sampler implements a Conditional\nTrajectory Correction step that guides the samples away from undesired regions\nin the ambient space using multimodal models as the source of conditioning.\nFurthermore, using Contrastive Language Image Pre-training (CLIP), our method\nadmits user-defined NSFW classes, which can vary in different settings. Our\nexperiments on the text-to-image SBM Stable Diffusion validate that the\nproposed SFW sampler effectively reduces the generation of explicit content\nwhile being competitive with other fine-tuning-based approaches, as assessed\nvia independent NSFW detectors. Moreover, we evaluate the impact of the SFW\nsampler on image quality and show that the proposed correction scheme comes at\na minor cost with negligible effect on samples not needing correction. Our\nstudy confirms the suitability of the SFW sampler towards aligned SBM models\nand the potential of using model-agnostic conditioning for the prevention of\nunwanted images."}
{"id": "2505.09081", "pdf": "https://arxiv.org/pdf/2505.09081", "abs": "https://arxiv.org/abs/2505.09081", "authors": ["Gaurav Koley"], "title": "SALM: A Multi-Agent Framework for Language Model-Driven Social Network Simulation", "categories": ["cs.SI", "cs.AI", "cs.MA"], "comment": null, "summary": "Contemporary approaches to agent-based modeling (ABM) of social systems have\ntraditionally emphasized rule-based behaviors, limiting their ability to\ncapture nuanced dynamics by moving beyond predefined rules and leveraging\ncontextual understanding from LMs of human social interaction. This paper\npresents SALM (Social Agent LM Framework), a novel approach for integrating\nlanguage models (LMs) into social network simulation that achieves\nunprecedented temporal stability in multi-agent scenarios. Our primary\ncontributions include: (1) a hierarchical prompting architecture enabling\nstable simulation beyond 4,000 timesteps while reducing token usage by 73%, (2)\nan attention-based memory system achieving 80% cache hit rates (95% CI [78%,\n82%]) with sub-linear memory growth of 9.5%, and (3) formal bounds on\npersonality stability. Through extensive validation against SNAP ego networks,\nwe demonstrate the first LLM-based framework capable of modeling long-term\nsocial phenomena while maintaining empirically validated behavioral fidelity."}
{"id": "2505.09529", "pdf": "https://arxiv.org/pdf/2505.09529", "abs": "https://arxiv.org/abs/2505.09529", "authors": ["Mohamed Moustafa", "Joseph Lemley", "Peter Corcoran"], "title": "Contactless Cardiac Pulse Monitoring Using Event Cameras", "categories": ["cs.CV", "cs.ET", "cs.LG", "eess.IV"], "comment": "This paper is a preprint of a paper submitted to IEEE Access and is\n  currently under review", "summary": "Time event cameras are a novel technology for recording scene information at\nextremely low latency and with low power consumption. Event cameras output a\nstream of events that encapsulate pixel-level light intensity changes within\nthe scene, capturing information with a higher dynamic range and temporal\nresolution than traditional cameras. This study investigates the contact-free\nreconstruction of an individual's cardiac pulse signal from time event\nrecording of their face using a supervised convolutional neural network (CNN)\nmodel. An end-to-end model is trained to extract the cardiac signal from a\ntwo-dimensional representation of the event stream, with model performance\nevaluated based on the accuracy of the calculated heart rate. The experimental\nresults confirm that physiological cardiac information in the facial region is\neffectively preserved within the event stream, showcasing the potential of this\nnovel sensor for remote heart rate monitoring. The model trained on event\nframes achieves a root mean square error (RMSE) of 3.32 beats per minute (bpm)\ncompared to the RMSE of 2.92 bpm achieved by the baseline model trained on\nstandard camera frames. Furthermore, models trained on event frames generated\nat 60 and 120 FPS outperformed the 30 FPS standard camera results, achieving an\nRMSE of 2.54 and 2.13 bpm, respectively."}
{"id": "2505.08818", "pdf": "https://arxiv.org/pdf/2505.08818", "abs": "https://arxiv.org/abs/2505.08818", "authors": ["Amara Tariq", "Rimita Lahiri", "Charles Kahn", "Imon Banerjee"], "title": "Position: Restructuring of Categories and Implementation of Guidelines Essential for VLM Adoption in Healthcare", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "15 pages, 2, tables, 3 figures", "summary": "The intricate and multifaceted nature of vision language model (VLM)\ndevelopment, adaptation, and application necessitates the establishment of\nclear and standardized reporting protocols, particularly within the high-stakes\ncontext of healthcare. Defining these reporting standards is inherently\nchallenging due to the diverse nature of studies involving VLMs, which vary\nsignificantly from the development of all new VLMs or finetuning for domain\nalignment to off-the-shelf use of VLM for targeted diagnosis and prediction\ntasks. In this position paper, we argue that traditional machine learning\nreporting standards and evaluation guidelines must be restructured to\naccommodate multiphase VLM studies; it also has to be organized for intuitive\nunderstanding of developers while maintaining rigorous standards for\nreproducibility. To facilitate community adoption, we propose a categorization\nframework for VLM studies and outline corresponding reporting standards that\ncomprehensively address performance evaluation, data reporting protocols, and\nrecommendations for manuscript composition. These guidelines are organized\naccording to the proposed categorization scheme. Lastly, we present a checklist\nthat consolidates reporting standards, offering a standardized tool to ensure\nconsistency and quality in the publication of VLM-related research."}
{"id": "2505.09082", "pdf": "https://arxiv.org/pdf/2505.09082", "abs": "https://arxiv.org/abs/2505.09082", "authors": ["Sophie Zhang", "Zhiming Lin"], "title": "CEC-Zero: Chinese Error Correction Solution Based on LLM", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advancements in large language models (LLMs) demonstrate exceptional\nChinese text processing capabilities, particularly in Chinese Spelling\nCorrection (CSC). While LLMs outperform traditional BERT-based models in\naccuracy and robustness, challenges persist in reliability and generalization.\nThis paper proposes CEC-Zero, a novel reinforcement learning (RL) framework\nenabling LLMs to self-correct through autonomous error strategy learning\nwithout external supervision. By integrating RL with LLMs' generative power,\nthe method eliminates dependency on annotated data or auxiliary models.\nExperiments reveal RL-enhanced LLMs achieve industry-viable accuracy and\nsuperior cross-domain generalization, offering a scalable solution for\nreliability optimization in Chinese NLP applications. This breakthrough\nfacilitates LLM deployment in practical Chinese text correction scenarios while\nestablishing a new paradigm for self-improving language models."}
{"id": "2505.09562", "pdf": "https://arxiv.org/pdf/2505.09562", "abs": "https://arxiv.org/abs/2505.09562", "authors": ["Nicola Marinello", "Simen Cassiman", "Jonas Heylen", "Marc Proesmans", "Luc Van Gool"], "title": "Camera-Only 3D Panoptic Scene Completion for Autonomous Driving through Differentiable Object Shapes", "categories": ["cs.CV"], "comment": "Accepted to CVPR 2025 Workshop on Autonomous Driving", "summary": "Autonomous vehicles need a complete map of their surroundings to plan and\nact. This has sparked research into the tasks of 3D occupancy prediction, 3D\nscene completion, and 3D panoptic scene completion, which predict a dense map\nof the ego vehicle's surroundings as a voxel grid. Scene completion extends\noccupancy prediction by predicting occluded regions of the voxel grid, and\npanoptic scene completion further extends this task by also distinguishing\nobject instances within the same class; both aspects are crucial for path\nplanning and decision-making. However, 3D panoptic scene completion is\ncurrently underexplored. This work introduces a novel framework for 3D panoptic\nscene completion that extends existing 3D semantic scene completion models. We\npropose an Object Module and Panoptic Module that can easily be integrated with\n3D occupancy and scene completion methods presented in the literature. Our\napproach leverages the available annotations in occupancy benchmarks, allowing\nindividual object shapes to be learned as a differentiable problem. The code is\navailable at https://github.com/nicolamarinello/OffsetOcc ."}
{"id": "2505.08819", "pdf": "https://arxiv.org/pdf/2505.08819", "abs": "https://arxiv.org/abs/2505.08819", "authors": ["Asahi Miyazaki", "Tsuyoshi Okita"], "title": "Thoughts on Objectives of Sparse and Hierarchical Masked Image Model", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "9 pages, 11 figures", "summary": "Masked image modeling is one of the most poplular objectives of training.\nRecently, the SparK model has been proposed with superior performance among\nself-supervised learning models. This paper proposes a new mask pattern for\nthis SparK model, proposing it as the Mesh Mask-ed SparK model. We report the\neffect of the mask pattern used for image masking in pre-training on\nperformance."}
{"id": "2505.09085", "pdf": "https://arxiv.org/pdf/2505.09085", "abs": "https://arxiv.org/abs/2505.09085", "authors": ["Jiaxuan Chen", "Yu Qi", "Yueming Wang", "Gang Pan"], "title": "Human-like Cognitive Generalization for Large Models via Brain-in-the-loop Supervision", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recent advancements in deep neural networks (DNNs), particularly large-scale\nlanguage models, have demonstrated remarkable capabilities in image and natural\nlanguage understanding. Although scaling up model parameters with increasing\nvolume of training data has progressively improved DNN capabilities, achieving\ncomplex cognitive abilities - such as understanding abstract concepts,\nreasoning, and adapting to novel scenarios, which are intrinsic to human\ncognition - remains a major challenge. In this study, we show that\nbrain-in-the-loop supervised learning, utilizing a small set of brain signals,\ncan effectively transfer human conceptual structures to DNNs, significantly\nenhancing their comprehension of abstract and even unseen concepts.\nExperimental results further indicate that the enhanced cognitive capabilities\nlead to substantial performance gains in challenging tasks, including\nfew-shot/zero-shot learning and out-of-distribution recognition, while also\nyielding highly interpretable concept representations. These findings highlight\nthat human-in-the-loop supervision can effectively augment the complex\ncognitive abilities of large models, offering a promising pathway toward\ndeveloping more human-like cognitive abilities in artificial systems."}
{"id": "2505.09564", "pdf": "https://arxiv.org/pdf/2505.09564", "abs": "https://arxiv.org/abs/2505.09564", "authors": ["Anne-Marie Rickmann", "Stephanie L. Thorn", "Shawn S. Ahn", "Supum Lee", "Selen Uman", "Taras Lysyy", "Rachel Burns", "Nicole Guerrera", "Francis G. Spinale", "Jason A. Burdick", "Albert J. Sinusas", "James S. Duncan"], "title": "Using Foundation Models as Pseudo-Label Generators for Pre-Clinical 4D Cardiac CT Segmentation", "categories": ["cs.CV"], "comment": "accepted at FIMH 2025", "summary": "Cardiac image segmentation is an important step in many cardiac image\nanalysis and modeling tasks such as motion tracking or simulations of cardiac\nmechanics. While deep learning has greatly advanced segmentation in clinical\nsettings, there is limited work on pre-clinical imaging, notably in porcine\nmodels, which are often used due to their anatomical and physiological\nsimilarity to humans. However, differences between species create a domain\nshift that complicates direct model transfer from human to pig data.\n  Recently, foundation models trained on large human datasets have shown\npromise for robust medical image segmentation; yet their applicability to\nporcine data remains largely unexplored. In this work, we investigate whether\nfoundation models can generate sufficiently accurate pseudo-labels for pig\ncardiac CT and propose a simple self-training approach to iteratively refine\nthese labels. Our method requires no manually annotated pig data, relying\ninstead on iterative updates to improve segmentation quality. We demonstrate\nthat this self-training process not only enhances segmentation accuracy but\nalso smooths out temporal inconsistencies across consecutive frames. Although\nour results are encouraging, there remains room for improvement, for example by\nincorporating more sophisticated self-training strategies and by exploring\nadditional foundation models and other cardiac imaging technologies."}
{"id": "2505.08822", "pdf": "https://arxiv.org/pdf/2505.08822", "abs": "https://arxiv.org/abs/2505.08822", "authors": ["Yuhao Wang", "Kailai Wang", "Songhua Hu", "Yunpeng", "Zhang", "Gino Lim", "Pengyu Zhu"], "title": "The Geography of Transportation Cybersecurity: Visitor Flows, Industry Clusters, and Spatial Dynamics", "categories": ["cs.CY", "cs.LG", "physics.soc-ph"], "comment": null, "summary": "The rapid evolution of the transportation cybersecurity ecosystem,\nencompassing cybersecurity, automotive, and transportation and logistics\nsectors, will lead to the formation of distinct spatial clusters and visitor\nflow patterns across the US. This study examines the spatiotemporal dynamics of\nvisitor flows, analyzing how socioeconomic factors shape industry clustering\nand workforce distribution within these evolving sectors. To model and predict\nvisitor flow patterns, we develop a BiTransGCN framework, integrating an\nattention-based Transformer architecture with a Graph Convolutional Network\nbackbone. By integrating AI-enabled forecasting techniques with spatial\nanalysis, this study improves our ability to track, interpret, and anticipate\nchanges in industry clustering and mobility trends, thereby supporting\nstrategic planning for a secure and resilient transportation network. It offers\na data-driven foundation for economic planning, workforce development, and\ntargeted investments in the transportation cybersecurity ecosystem."}
{"id": "2505.09091", "pdf": "https://arxiv.org/pdf/2505.09091", "abs": "https://arxiv.org/abs/2505.09091", "authors": ["Zeeshan Ahmad", "Shudi Bao", "Meng Chen"], "title": "DPN-GAN: Inducing Periodic Activations in Generative Adversarial Networks for High-Fidelity Audio Synthesis", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "comment": null, "summary": "In recent years, generative adversarial networks (GANs) have made significant\nprogress in generating audio sequences. However, these models typically rely on\nbandwidth-limited mel-spectrograms, which constrain the resolution of generated\naudio sequences, and lead to mode collapse during conditional generation. To\naddress this issue, we propose Deformable Periodic Network based GAN (DPN-GAN),\na novel GAN architecture that incorporates a kernel-based periodic ReLU\nactivation function to induce periodic bias in audio generation. This\ninnovative approach enhances the model's ability to capture and reproduce\nintricate audio patterns. In particular, our proposed model features a DPN\nmodule for multi-resolution generation utilizing deformable convolution\noperations, allowing for adaptive receptive fields that improve the quality and\nfidelity of the synthetic audio. Additionally, we enhance the discriminator\nnetwork using deformable convolution to better distinguish between real and\ngenerated samples, further refining the audio quality. We trained two versions\nof the model: DPN-GAN small (38.67M parameters) and DPN-GAN large (124M\nparameters). For evaluation, we use five different datasets, covering both\nspeech synthesis and music generation tasks, to demonstrate the efficiency of\nthe DPN-GAN. The experimental results demonstrate that DPN-GAN delivers\nsuperior performance on both out-of-distribution and noisy data, showcasing its\nrobustness and adaptability. Trained across various datasets, DPN-GAN\noutperforms state-of-the-art GAN architectures on standard evaluation metrics,\nand exhibits increased robustness in synthesized audio."}
{"id": "2505.09568", "pdf": "https://arxiv.org/pdf/2505.09568", "abs": "https://arxiv.org/abs/2505.09568", "authors": ["Jiuhai Chen", "Zhiyang Xu", "Xichen Pan", "Yushi Hu", "Can Qin", "Tom Goldstein", "Lifu Huang", "Tianyi Zhou", "Saining Xie", "Silvio Savarese", "Le Xue", "Caiming Xiong", "Ran Xu"], "title": "BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Unifying image understanding and generation has gained growing attention in\nrecent research on multimodal models. Although design choices for image\nunderstanding have been extensively studied, the optimal model architecture and\ntraining recipe for a unified framework with image generation remain\nunderexplored. Motivated by the strong potential of autoregressive and\ndiffusion models for high-quality generation and scalability, we conduct a\ncomprehensive study of their use in unified multimodal settings, with emphasis\non image representations, modeling objectives, and training strategies.\nGrounded in these investigations, we introduce a novel approach that employs a\ndiffusion transformer to generate semantically rich CLIP image features, in\ncontrast to conventional VAE-based representations. This design yields both\nhigher training efficiency and improved generative quality. Furthermore, we\ndemonstrate that a sequential pretraining strategy for unified models-first\ntraining on image understanding and subsequently on image generation-offers\npractical advantages by preserving image understanding capability while\ndeveloping strong image generation ability. Finally, we carefully curate a\nhigh-quality instruction-tuning dataset BLIP3o-60k for image generation by\nprompting GPT-4o with a diverse set of captions covering various scenes,\nobjects, human gestures, and more. Building on our innovative model design,\ntraining recipe, and datasets, we develop BLIP3-o, a suite of state-of-the-art\nunified multimodal models. BLIP3-o achieves superior performance across most of\nthe popular benchmarks spanning both image understanding and generation tasks.\nTo facilitate future research, we fully open-source our models, including code,\nmodel weights, training scripts, and pretraining and instruction tuning\ndatasets."}
{"id": "2505.08833", "pdf": "https://arxiv.org/pdf/2505.08833", "abs": "https://arxiv.org/abs/2505.08833", "authors": ["Qingyi Wang", "Yuebing Liang", "Yunhan Zheng", "Kaiyuan Xu", "Jinhua Zhao", "Shenhao Wang"], "title": "Generative AI for Urban Planning: Synthesizing Satellite Imagery via Diffusion Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Generative AI offers new opportunities for automating urban planning by\ncreating site-specific urban layouts and enabling flexible design exploration.\nHowever, existing approaches often struggle to produce realistic and practical\ndesigns at scale. Therefore, we adapt a state-of-the-art Stable Diffusion\nmodel, extended with ControlNet, to generate high-fidelity satellite imagery\nconditioned on land use descriptions, infrastructure, and natural environments.\nTo overcome data availability limitations, we spatially link satellite imagery\nwith structured land use and constraint information from OpenStreetMap. Using\ndata from three major U.S. cities, we demonstrate that the proposed diffusion\nmodel generates realistic and diverse urban landscapes by varying land-use\nconfigurations, road networks, and water bodies, facilitating cross-city\nlearning and design diversity. We also systematically evaluate the impacts of\nvarying language prompts and control imagery on the quality of satellite\nimagery generation. Our model achieves high FID and KID scores and demonstrates\nrobustness across diverse urban contexts. Qualitative assessments from urban\nplanners and the general public show that generated images align closely with\ndesign descriptions and constraints, and are often preferred over real images.\nThis work establishes a benchmark for controlled urban imagery generation and\nhighlights the potential of generative AI as a tool for enhancing planning\nworkflows and public engagement."}
{"id": "2505.09108", "pdf": "https://arxiv.org/pdf/2505.09108", "abs": "https://arxiv.org/abs/2505.09108", "authors": ["Fernando Cladera", "Zachary Ravichandran", "Jason Hughes", "Varun Murali", "Carlos Nieto-Granda", "M. Ani Hsieh", "George J. Pappas", "Camillo J. Taylor", "Vijay Kumar"], "title": "Air-Ground Collaboration for Language-Specified Missions in Unknown Environments", "categories": ["cs.RO", "cs.AI"], "comment": "19 pages, 24 figures, 7 tables. Submitted to T-FR", "summary": "As autonomous robotic systems become increasingly mature, users will want to\nspecify missions at the level of intent rather than in low-level detail.\nLanguage is an expressive and intuitive medium for such mission specification.\nHowever, realizing language-guided robotic teams requires overcoming\nsignificant technical hurdles. Interpreting and realizing language-specified\nmissions requires advanced semantic reasoning. Successful heterogeneous robots\nmust effectively coordinate actions and share information across varying\nviewpoints. Additionally, communication between robots is typically\nintermittent, necessitating robust strategies that leverage communication\nopportunities to maintain coordination and achieve mission objectives. In this\nwork, we present a first-of-its-kind system where an unmanned aerial vehicle\n(UAV) and an unmanned ground vehicle (UGV) are able to collaboratively\naccomplish missions specified in natural language while reacting to changes in\nspecification on the fly. We leverage a Large Language Model (LLM)-enabled\nplanner to reason over semantic-metric maps that are built online and\nopportunistically shared between an aerial and a ground robot. We consider\ntask-driven navigation in urban and rural areas. Our system must infer\nmission-relevant semantics and actively acquire information via semantic\nmapping. In both ground and air-ground teaming experiments, we demonstrate our\nsystem on seven different natural-language specifications at up to\nkilometer-scale navigation."}
{"id": "2505.09571", "pdf": "https://arxiv.org/pdf/2505.09571", "abs": "https://arxiv.org/abs/2505.09571", "authors": ["Guillermo Gomez-Trenado", "Pablo Mesejo", "Oscar Cordón", "Stéphane Lathuilière"], "title": "Don't Forget your Inverse DDIM for Image Editing", "categories": ["cs.CV", "I.2.10; I.5.0"], "comment": "12 pages, 12 figures, code available at\n  https://guillermogotre.github.io/sage/", "summary": "The field of text-to-image generation has undergone significant advancements\nwith the introduction of diffusion models. Nevertheless, the challenge of\nediting real images persists, as most methods are either computationally\nintensive or produce poor reconstructions. This paper introduces SAGE\n(Self-Attention Guidance for image Editing) - a novel technique leveraging\npre-trained diffusion models for image editing. SAGE builds upon the DDIM\nalgorithm and incorporates a novel guidance mechanism utilizing the\nself-attention layers of the diffusion U-Net. This mechanism computes a\nreconstruction objective based on attention maps generated during the inverse\nDDIM process, enabling efficient reconstruction of unedited regions without the\nneed to precisely reconstruct the entire input image. Thus, SAGE directly\naddresses the key challenges in image editing. The superiority of SAGE over\nother methods is demonstrated through quantitative and qualitative evaluations\nand confirmed by a statistically validated comprehensive user study, in which\nall 47 surveyed users preferred SAGE over competing methods. Additionally, SAGE\nranks as the top-performing method in seven out of 10 quantitative analyses and\nsecures second and third places in the remaining three."}
{"id": "2505.08837", "pdf": "https://arxiv.org/pdf/2505.08837", "abs": "https://arxiv.org/abs/2505.08837", "authors": ["Muhammad Saqib", "Dipkumar Mehta", "Fnu Yashu", "Shubham Malhotra"], "title": "Adaptive Security Policy Management in Cloud Environments Using Reinforcement Learning", "categories": ["cs.CR", "cs.CV", "cs.DC", "cs.LG", "cs.NI"], "comment": "10 pages, 6 figures, 1 table", "summary": "The security of cloud environments, such as Amazon Web Services (AWS), is\ncomplex and dynamic. Static security policies have become inadequate as threats\nevolve and cloud resources exhibit elasticity [1]. This paper addresses the\nlimitations of static policies by proposing a security policy management\nframework that uses reinforcement learning (RL) to adapt dynamically.\nSpecifically, we employ deep reinforcement learning algorithms, including deep\nQ Networks and proximal policy optimization, enabling the learning and\ncontinuous adjustment of controls such as firewall rules and Identity and\nAccess Management (IAM) policies. The proposed RL based solution leverages\ncloud telemetry data (AWS Cloud Trail logs, network traffic data, threat\nintelligence feeds) to continuously refine security policies, maximizing threat\nmitigation, and compliance while minimizing resource impact. Experimental\nresults demonstrate that our adaptive RL based framework significantly\noutperforms static policies, achieving higher intrusion detection rates (92%\ncompared to 82% for static policies) and substantially reducing incident\ndetection and response times by 58%. In addition, it maintains high conformity\nwith security requirements and efficient resource usage. These findings\nvalidate the effectiveness of adaptive reinforcement learning approaches in\nimproving cloud security policy management."}
{"id": "2505.09115", "pdf": "https://arxiv.org/pdf/2505.09115", "abs": "https://arxiv.org/abs/2505.09115", "authors": ["Yu Lun Hsu", "Yun-Rung Chou", "Chiao-Ju Chang", "Yu-Cheng Chang", "Zer-Wei Lee", "Rokas Gipiškis", "Rachel Li", "Chih-Yuan Shih", "Jen-Kuei Peng", "Hsien-Liang Huang", "Jaw-Shiun Tsai", "Mike Y. Chen"], "title": "PreCare: Designing AI Assistants for Advance Care Planning (ACP) to Enhance Personal Value Exploration, Patient Knowledge, and Decisional Confidence", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Advance Care Planning (ACP) allows individuals to specify their preferred\nend-of-life life-sustaining treatments before they become incapacitated by\ninjury or terminal illness (e.g., coma, cancer, dementia). While online ACP\noffers high accessibility, it lacks key benefits of clinical consultations,\nincluding personalized value exploration, immediate clarification of decision\nconsequences. To bridge this gap, we conducted two formative studies: 1)\nshadowed and interviewed 3 ACP teams consisting of physicians, nurses, and\nsocial workers (18 patients total), and 2) interviewed 14 users of ACP\nwebsites. Building on these insights, we designed PreCare in collaboration with\n6 ACP professionals. PreCare is a website with 3 AI-driven assistants designed\nto guide users through exploring personal values, gaining ACP knowledge, and\nsupporting informed decision-making. A usability study (n=12) showed that\nPreCare achieved a System Usability Scale (SUS) rating of excellent. A\ncomparative evaluation (n=12) showed that PreCare's AI assistants significantly\nimproved exploration of personal values, knowledge, and decisional confidence,\nand was preferred by 92% of participants."}
{"id": "2505.09591", "pdf": "https://arxiv.org/pdf/2505.09591", "abs": "https://arxiv.org/abs/2505.09591", "authors": ["Tobias Jan Wieczorek", "Nathalie Daun", "Mohammad Emtiyaz Khan", "Marcus Rohrbach"], "title": "Variational Visual Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "19 pages, 16 figures, under review at ICCV 2025", "summary": "Despite remarkable progress in multimodal models for Visual Question\nAnswering (VQA), there remain major reliability concerns because the models can\noften be overconfident and miscalibrated, especially in out-of-distribution\n(OOD) settings. Plenty has been done to address such issues for unimodal\nmodels, but little work exists for multimodal cases. Here, we address\nunreliability in multimodal models by proposing a Variational VQA approach.\nSpecifically, instead of fine-tuning vision-language models by using AdamW, we\nemploy a recently proposed variational algorithm called IVON, which yields a\nposterior distribution over model parameters. Through extensive experiments, we\nshow that our approach improves calibration and abstentions without sacrificing\nthe accuracy of AdamW. For instance, compared to AdamW fine-tuning, we reduce\nExpected Calibration Error by more than 50% compared to the AdamW baseline and\nraise Coverage by 4% vs. SOTA (for a fixed risk of 1%). In the presence of\ndistribution shifts, the performance gain is even higher, achieving 8% Coverage\n(@ 1% risk) improvement vs. SOTA when 50% of test cases are OOD. Overall, we\npresent variational learning as a viable option to enhance the reliability of\nmultimodal models."}
{"id": "2505.08845", "pdf": "https://arxiv.org/pdf/2505.08845", "abs": "https://arxiv.org/abs/2505.08845", "authors": ["Misgina Tsighe Hagos", "Antti Suutala", "Dmitrii Bychkov", "Hakan Kücükel", "Joar von Bahr", "Milda Poceviciute", "Johan Lundin", "Nina Linder", "Claes Lundström"], "title": "Validation of Conformal Prediction in Cervical Atypia Classification", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Deep learning based cervical cancer classification can potentially increase\naccess to screening in low-resource regions. However, deep learning models are\noften overconfident and do not reliably reflect diagnostic uncertainty.\nMoreover, they are typically optimized to generate maximum-likelihood\npredictions, which fail to convey uncertainty or ambiguity in their results.\nSuch challenges can be addressed using conformal prediction, a model-agnostic\nframework for generating prediction sets that contain likely classes for\ntrained deep-learning models. The size of these prediction sets indicates model\nuncertainty, contracting as model confidence increases. However, existing\nconformal prediction evaluation primarily focuses on whether the prediction set\nincludes or covers the true class, often overlooking the presence of extraneous\nclasses. We argue that prediction sets should be truthful and valuable to end\nusers, ensuring that the listed likely classes align with human expectations\nrather than being overly relaxed and including false positives or unlikely\nclasses. In this study, we comprehensively validate conformal prediction sets\nusing expert annotation sets collected from multiple annotators. We evaluate\nthree conformal prediction approaches applied to three deep-learning models\ntrained for cervical atypia classification. Our expert annotation-based\nanalysis reveals that conventional coverage-based evaluations overestimate\nperformance and that current conformal prediction methods often produce\nprediction sets that are not well aligned with human labels. Additionally, we\nexplore the capabilities of the conformal prediction methods in identifying\nambiguous and out-of-distribution data."}
{"id": "2505.09129", "pdf": "https://arxiv.org/pdf/2505.09129", "abs": "https://arxiv.org/abs/2505.09129", "authors": ["Wei Meng"], "title": "WSCIF: A Weakly-Supervised Color Intelligence Framework for Tactical Anomaly Detection in Surveillance Keyframes", "categories": ["cs.CV", "cs.AI", "es: 68T10, 68T05, 62H35, 68U10", "I.4.9; I.5.1; I.2.10"], "comment": "17 pages, 3 figures, 3 tables. The paper proposes a lightweight\n  weakly-supervised color intelligence model for tactical video anomaly\n  detection, tested on anonymized African surveillance data", "summary": "The deployment of traditional deep learning models in high-risk security\ntasks in an unlabeled, data-non-exploitable video intelligence environment\nfaces significant challenges. In this paper, we propose a lightweight anomaly\ndetection framework based on color features for surveillance video clips in a\nhigh sensitivity tactical mission, aiming to quickly identify and interpret\npotential threat events under resource-constrained and data-sensitive\nconditions. The method fuses unsupervised KMeans clustering with RGB channel\nhistogram modeling to achieve composite detection of structural anomalies and\ncolor mutation signals in key frames. The experiment takes an operation\nsurveillance video occurring in an African country as a research sample, and\nsuccessfully identifies multiple highly anomalous frames related to high-energy\nlight sources, target presence, and reflective interference under the condition\nof no access to the original data. The results show that this method can be\neffectively used for tactical assassination warning, suspicious object\nscreening and environmental drastic change monitoring with strong deployability\nand tactical interpretation value. The study emphasizes the importance of color\nfeatures as low semantic battlefield signal carriers, and its battlefield\nintelligent perception capability will be further extended by combining graph\nneural networks and temporal modeling in the future."}
{"id": "2505.09608", "pdf": "https://arxiv.org/pdf/2505.09608", "abs": "https://arxiv.org/abs/2505.09608", "authors": ["Nadav Magar", "Amir Hertz", "Eric Tabellion", "Yael Pritch", "Alex Rav-Acha", "Ariel Shamir", "Yedid Hoshen"], "title": "LightLab: Controlling Light Sources in Images with Diffusion Models", "categories": ["cs.CV", "cs.GR"], "comment": "Project Page: https://nadmag.github.io/LightLab/", "summary": "We present a simple, yet effective diffusion-based method for fine-grained,\nparametric control over light sources in an image. Existing relighting methods\neither rely on multiple input views to perform inverse rendering at inference\ntime, or fail to provide explicit control over light changes. Our method\nfine-tunes a diffusion model on a small set of real raw photograph pairs,\nsupplemented by synthetically rendered images at scale, to elicit its\nphotorealistic prior for relighting. We leverage the linearity of light to\nsynthesize image pairs depicting controlled light changes of either a target\nlight source or ambient illumination. Using this data and an appropriate\nfine-tuning scheme, we train a model for precise illumination changes with\nexplicit control over light intensity and color. Lastly, we show how our method\ncan achieve compelling light editing results, and outperforms existing methods\nbased on user preference."}
{"id": "2505.08849", "pdf": "https://arxiv.org/pdf/2505.08849", "abs": "https://arxiv.org/abs/2505.08849", "authors": ["Keyu Chen", "Hao Tang", "Qinglin Liu", "Yizhao Xu"], "title": "Improved Algorithms for Differentially Private Language Model Alignment", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Language model alignment is crucial for ensuring that large language models\n(LLMs) align with human preferences, yet it often involves sensitive user data,\nraising significant privacy concerns. While prior work has integrated\ndifferential privacy (DP) with alignment techniques, their performance remains\nlimited. In this paper, we propose novel algorithms for privacy-preserving\nalignment and rigorously analyze their effectiveness across varying privacy\nbudgets and models. Our framework can be deployed on two celebrated alignment\ntechniques, namely direct preference optimization (DPO) and reinforcement\nlearning from human feedback (RLHF). Through systematic experiments on\nlarge-scale language models, we demonstrate that our approach achieves\nstate-of-the-art performance. Notably, one of our algorithms, DP-AdamW,\ncombined with DPO, surpasses existing methods, improving alignment quality by\nup to 15% under moderate privacy budgets ({\\epsilon}=2-5). We further\ninvestigate the interplay between privacy guarantees, alignment efficacy, and\ncomputational demands, providing practical guidelines for optimizing these\ntrade-offs."}
{"id": "2505.09131", "pdf": "https://arxiv.org/pdf/2505.09131", "abs": "https://arxiv.org/abs/2505.09131", "authors": ["Kunwoong Kim", "Jihu Lee", "Sangchul Park", "Yongdai Kim"], "title": "Fair Clustering via Alignment", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at ICML 2025. This is the version submitted for review and\n  will be replaced by the camera-ready version soon", "summary": "Algorithmic fairness in clustering aims to balance the proportions of\ninstances assigned to each cluster with respect to a given sensitive attribute.\nWhile recently developed fair clustering algorithms optimize clustering\nobjectives under specific fairness constraints, their inherent complexity or\napproximation often results in suboptimal clustering utility or numerical\ninstability in practice. To resolve these limitations, we propose a new fair\nclustering algorithm based on a novel decomposition of the fair K-means\nclustering objective function. The proposed algorithm, called Fair Clustering\nvia Alignment (FCA), operates by alternately (i) finding a joint probability\ndistribution to align the data from different protected groups, and (ii)\noptimizing cluster centers in the aligned space. A key advantage of FCA is that\nit theoretically guarantees approximately optimal clustering utility for any\ngiven fairness level without complex constraints, thereby enabling high-utility\nfair clustering in practice. Experiments show that FCA outperforms existing\nmethods by (i) attaining a superior trade-off between fairness level and\nclustering utility, and (ii) achieving near-perfect fairness without numerical\ninstability."}
{"id": "2505.09615", "pdf": "https://arxiv.org/pdf/2505.09615", "abs": "https://arxiv.org/abs/2505.09615", "authors": ["Yung-Hsuan Lai", "Janek Ebbers", "Yu-Chiang Frank Wang", "François Germain", "Michael Jeffrey Jones", "Moitreya Chatterjee"], "title": "UWAV: Uncertainty-weighted Weakly-supervised Audio-Visual Video Parsing", "categories": ["cs.CV", "cs.SD", "eess.AS"], "comment": "CVPR 2025", "summary": "Audio-Visual Video Parsing (AVVP) entails the challenging task of localizing\nboth uni-modal events (i.e., those occurring exclusively in either the visual\nor acoustic modality of a video) and multi-modal events (i.e., those occurring\nin both modalities concurrently). Moreover, the prohibitive cost of annotating\ntraining data with the class labels of all these events, along with their start\nand end times, imposes constraints on the scalability of AVVP techniques unless\nthey can be trained in a weakly-supervised setting, where only\nmodality-agnostic, video-level labels are available in the training data. To\nthis end, recently proposed approaches seek to generate segment-level\npseudo-labels to better guide model training. However, the absence of\ninter-segment dependencies when generating these pseudo-labels and the general\nbias towards predicting labels that are absent in a segment limit their\nperformance. This work proposes a novel approach towards overcoming these\nweaknesses called Uncertainty-weighted Weakly-supervised Audio-visual Video\nParsing (UWAV). Additionally, our innovative approach factors in the\nuncertainty associated with these estimated pseudo-labels and incorporates a\nfeature mixup based training regularization for improved training. Empirical\nresults show that UWAV outperforms state-of-the-art methods for the AVVP task\non multiple metrics, across two different datasets, attesting to its\neffectiveness and generalizability."}
{"id": "2505.08886", "pdf": "https://arxiv.org/pdf/2505.08886", "abs": "https://arxiv.org/abs/2505.08886", "authors": ["Hamideh Khaleghpour", "Brett McKinney"], "title": "Optimizing Neuro-Fuzzy and Colonial Competition Algorithms for Skin Cancer Diagnosis in Dermatoscopic Images", "categories": ["cs.CV", "cs.LG"], "comment": "7 pages, 10 figures. Accepted at the 2nd Asia Pacific Computer\n  Systems Conference (APCS 2024), March 15-17, 2024", "summary": "The rising incidence of skin cancer, coupled with limited public awareness\nand a shortfall in clinical expertise, underscores an urgent need for advanced\ndiagnostic aids. Artificial Intelligence (AI) has emerged as a promising tool\nin this domain, particularly for distinguishing malignant from benign skin\nlesions. Leveraging publicly available datasets of skin lesions, researchers\nhave been developing AI-based diagnostic solutions. However, the integration of\nsuch computer systems in clinical settings is still nascent. This study aims to\nbridge this gap by employing a fusion of image processing techniques and\nmachine learning algorithms, specifically neuro-fuzzy and colonial competition\napproaches. Applied to dermoscopic images from the ISIC database, our method\nachieved a notable accuracy of 94% on a dataset of 560 images. These results\nunderscore the potential of our approach in aiding clinicians in the early\ndetection of melanoma, thereby contributing significantly to skin cancer\ndiagnostics."}
{"id": "2505.09142", "pdf": "https://arxiv.org/pdf/2505.09142", "abs": "https://arxiv.org/abs/2505.09142", "authors": ["Seungbeom Choi", "Jeonghoe Goo", "Eunjoo Jeon", "Mingyu Yang", "Minsung Jang"], "title": "ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "13 pages, 5 figures. Cloud-native LLM scheduling system with\n  latency-aware inference optimization", "summary": "We propose ELIS, a serving system for Large Language Models (LLMs) featuring\nan Iterative Shortest Remaining Time First (ISRTF) scheduler designed to\nefficiently manage inference tasks with the shortest remaining tokens. Current\nLLM serving systems often employ a first-come-first-served scheduling strategy,\nwhich can lead to the \"head-of-line blocking\" problem. To overcome this\nlimitation, it is necessary to predict LLM inference times and apply a shortest\njob first scheduling strategy. However, due to the auto-regressive nature of\nLLMs, predicting the inference latency is challenging. ELIS addresses this\nchallenge by training a response length predictor for LLMs using the BGE model,\nan encoder-based state-of-the-art model. Additionally, we have devised the\nISRTF scheduling strategy, an optimization of shortest remaining time first\ntailored to existing LLM iteration batching. To evaluate our work in an\nindustrial setting, we simulate streams of requests based on our study of\nreal-world user LLM serving trace records. Furthermore, we implemented ELIS as\na cloud-native scheduler system on Kubernetes to evaluate its performance in\nproduction environments. Our experimental results demonstrate that ISRTF\nreduces the average job completion time by up to 19.6%."}
{"id": "2505.08798", "pdf": "https://arxiv.org/pdf/2505.08798", "abs": "https://arxiv.org/abs/2505.08798", "authors": ["Mobina Shrestha", "Bishwas Mandal", "Vishal Mandal", "Asis Shrestha"], "title": "In-Context Learning for Label-Efficient Cancer Image Classification in Oncology", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "The application of AI in oncology has been limited by its reliance on large,\nannotated datasets and the need for retraining models for domain-specific\ndiagnostic tasks. Taking heed of these limitations, we investigated in-context\nlearning as a pragmatic alternative to model retraining by allowing models to\nadapt to new diagnostic tasks using only a few labeled examples at inference,\nwithout the need for retraining. Using four vision-language models\n(VLMs)-Paligemma, CLIP, ALIGN and GPT-4o, we evaluated the performance across\nthree oncology datasets: MHIST, PatchCamelyon and HAM10000. To the best of our\nknowledge, this is the first study to compare the performance of multiple VLMs\non different oncology classification tasks. Without any parameter updates, all\nmodels showed significant gains with few-shot prompting, with GPT-4o reaching\nan F1 score of 0.81 in binary classification and 0.60 in multi-class\nclassification settings. While these results remain below the ceiling of fully\nfine-tuned systems, they highlight the potential of ICL to approximate\ntask-specific behavior using only a handful of examples, reflecting how\nclinicians often reason from prior cases. Notably, open-source models like\nPaligemma and CLIP demonstrated competitive gains despite their smaller size,\nsuggesting feasibility for deployment in computing constrained clinical\nenvironments. Overall, these findings highlight the potential of ICL as a\npractical solution in oncology, particularly for rare cancers and\nresource-limited contexts where fine-tuning is infeasible and annotated data is\ndifficult to obtain."}
{"id": "2505.08899", "pdf": "https://arxiv.org/pdf/2505.08899", "abs": "https://arxiv.org/abs/2505.08899", "authors": ["Andrew Mullhaupt", "Cheng Peng"], "title": "Bounding Neyman-Pearson Region with $f$-Divergences", "categories": ["math.ST", "cs.LG", "stat.ML", "stat.TH"], "comment": null, "summary": "The Neyman-Pearson region of a simple binary hypothesis testing is the set of\npoints whose coordinates represent the false positive rate and false negative\nrate of some test. The lower boundary of this region is given by the\nNeyman-Pearson lemma, and is up to a coordinate change, equivalent to the\noptimal ROC curve. We establish a novel lower bound for the boundary in terms\nof any $f$-divergence. Since the bound generated by hockey-stick\n$f$-divergences characterizes the Neyman-Pearson boundary, this bound is best\npossible. In the case of KL divergence, this bound improves Pinsker's\ninequality. Furthermore, we obtain a closed-form refined upper bound for the\nNeyman-Pearson boundary in terms of the Chernoff $\\alpha$-coefficient. Finally,\nwe present methods for constructing pairs of distributions that can\napproximately or exactly realize any given Neyman-Pearson boundary."}
{"id": "2505.09160", "pdf": "https://arxiv.org/pdf/2505.09160", "abs": "https://arxiv.org/abs/2505.09160", "authors": ["Berkay Guler", "Giovanni Geraci", "Hamid Jafarkhani"], "title": "A Multi-Task Foundation Model for Wireless Channel Representation Using Contrastive and Masked Autoencoder Learning", "categories": ["cs.LG", "cs.AI", "eess.SP"], "comment": null, "summary": "Current applications of self-supervised learning to wireless channel\nrepresentation often borrow paradigms developed for text and image processing,\nwithout fully addressing the unique characteristics and constraints of wireless\ncommunications. Aiming to fill this gap, we first propose WiMAE (Wireless\nMasked Autoencoder), a transformer-based encoder-decoder foundation model\npretrained on a realistic open-source multi-antenna wireless channel dataset.\nBuilding upon this foundation, we develop ContraWiMAE, which enhances WiMAE by\nincorporating a contrastive learning objective alongside the reconstruction\ntask in a unified multi-task framework. By warm-starting from pretrained WiMAE\nweights and generating positive pairs via noise injection, the contrastive\ncomponent enables the model to capture both structural and discriminative\nfeatures, enhancing representation quality beyond what reconstruction alone can\nachieve. Through extensive evaluation on unseen scenarios, we demonstrate the\neffectiveness of both approaches across multiple downstream tasks, with\nContraWiMAE showing further improvements in linear separability and\nadaptability in diverse wireless environments. Comparative evaluations against\na state-of-the-art wireless channel foundation model confirm the superior\nperformance and data efficiency of our models, highlighting their potential as\npowerful baselines for future research in self-supervised wireless channel\nrepresentation learning."}
{"id": "2505.08819", "pdf": "https://arxiv.org/pdf/2505.08819", "abs": "https://arxiv.org/abs/2505.08819", "authors": ["Asahi Miyazaki", "Tsuyoshi Okita"], "title": "Thoughts on Objectives of Sparse and Hierarchical Masked Image Model", "categories": ["eess.IV", "cs.CV", "cs.LG"], "comment": "9 pages, 11 figures", "summary": "Masked image modeling is one of the most poplular objectives of training.\nRecently, the SparK model has been proposed with superior performance among\nself-supervised learning models. This paper proposes a new mask pattern for\nthis SparK model, proposing it as the Mesh Mask-ed SparK model. We report the\neffect of the mask pattern used for image masking in pre-training on\nperformance."}
{"id": "2505.08908", "pdf": "https://arxiv.org/pdf/2505.08908", "abs": "https://arxiv.org/abs/2505.08908", "authors": ["Benedikt Koch", "Kosuke Imai"], "title": "Statistical Decision Theory with Counterfactual Loss", "categories": ["math.ST", "cs.LG", "econ.TH", "stat.TH"], "comment": null, "summary": "Classical statistical decision theory evaluates treatment choices based\nsolely on observed outcomes. However, by ignoring counterfactual outcomes, it\ncannot assess the quality of decisions relative to feasible alternatives. For\nexample, the quality of a physician's decision may depend not only on patient\nsurvival, but also on whether a less invasive treatment could have produced a\nsimilar result. To address this limitation, we extend standard decision theory\nto incorporate counterfactual losses--criteria that evaluate decisions using\nall potential outcomes. The central challenge in this generalization is\nidentification: because only one potential outcome is observed for each unit,\nthe associated risk under a counterfactual loss is generally not identifiable.\nWe show that under the assumption of strong ignorability, a counterfactual risk\nis identifiable if and only if the counterfactual loss function is additive in\nthe potential outcomes. Moreover, we demonstrate that additive counterfactual\nlosses can yield treatment recommendations that differ from those based on\nstandard loss functions, provided that the decision problem involves more than\ntwo treatment options."}
{"id": "2505.09166", "pdf": "https://arxiv.org/pdf/2505.09166", "abs": "https://arxiv.org/abs/2505.09166", "authors": ["Hannu Simonen", "Atte Kiviniemi", "Jonas Oppenlaender"], "title": "An Initial Exploration of Default Images in Text-to-Image Generation", "categories": ["cs.HC", "cs.AI", "H.5.m; I.2.m"], "comment": "16 pages, 6 figures", "summary": "In the creative practice of text-to-image generation (TTI), images are\ngenerated from text prompts. However, TTI models are trained to always yield an\noutput, even if the prompt contains unknown terms. In this case, the model may\ngenerate what we call \"default images\": images that closely resemble each other\nacross many unrelated prompts. We argue studying default images is valuable for\ndesigning better solutions for TTI and prompt engineering. In this paper, we\nprovide the first investigation into default images on Midjourney, a popular\nimage generator. We describe our systematic approach to create input prompts\ntriggering default images, and present the results of our initial experiments\nand several small-scale ablation studies. We also report on a survey study\ninvestigating how default images affect user satisfaction. Our work lays the\nfoundation for understanding default images in TTI and highlights challenges\nand future research directions."}
{"id": "2505.08835", "pdf": "https://arxiv.org/pdf/2505.08835", "abs": "https://arxiv.org/abs/2505.08835", "authors": ["Hyunsik Na", "Wonho Lee", "Seungdeok Roh", "Sohee Park", "Daeseon Choi"], "title": "Robustness Analysis against Adversarial Patch Attacks in Fully Unmanned Stores", "categories": ["cs.CR", "cs.AI", "cs.CV"], "comment": null, "summary": "The advent of convenient and efficient fully unmanned stores equipped with\nartificial intelligence-based automated checkout systems marks a new era in\nretail. However, these systems have inherent artificial intelligence security\nvulnerabilities, which are exploited via adversarial patch attacks,\nparticularly in physical environments. This study demonstrated that adversarial\npatches can severely disrupt object detection models used in unmanned stores,\nleading to issues such as theft, inventory discrepancies, and interference. We\ninvestigated three types of adversarial patch attacks -- Hiding, Creating, and\nAltering attacks -- and highlighted their effectiveness. We also introduce the\nnovel color histogram similarity loss function by leveraging attacker knowledge\nof the color information of a target class object. Besides the traditional\nconfusion-matrix-based attack success rate, we introduce a new\nbounding-boxes-based metric to analyze the practical impact of these attacks.\nStarting with attacks on object detection models trained on snack and fruit\ndatasets in a digital environment, we evaluated the effectiveness of\nadversarial patches in a physical testbed that mimicked a real unmanned store\nwith RGB cameras and realistic conditions. Furthermore, we assessed the\nrobustness of these attacks in black-box scenarios, demonstrating that shadow\nattacks can enhance success rates of attacks even without direct access to\nmodel parameters. Our study underscores the necessity for robust defense\nstrategies to protect unmanned stores from adversarial threats. Highlighting\nthe limitations of the current defense mechanisms in real-time detection\nsystems and discussing various proactive measures, we provide insights into\nimproving the robustness of object detection models and fortifying unmanned\nretail environments against these attacks."}
{"id": "2505.08909", "pdf": "https://arxiv.org/pdf/2505.08909", "abs": "https://arxiv.org/abs/2505.08909", "authors": ["Deliang Wei", "Peng Chen", "Haobo Xu", "Jiale Yao", "Fang Li", "Tieyong Zeng"], "title": "Learning Cocoercive Conservative Denoisers via Helmholtz Decomposition for Poisson Inverse Problems", "categories": ["cs.CV", "cs.LG", "math.FA", "math.OC", "94A08, 47H10, 47J26, 46N10, 47N10"], "comment": "31 pages", "summary": "Plug-and-play (PnP) methods with deep denoisers have shown impressive results\nin imaging problems. They typically require strong convexity or smoothness of\nthe fidelity term and a (residual) non-expansive denoiser for convergence.\nThese assumptions, however, are violated in Poisson inverse problems, and\nnon-expansiveness can hinder denoising performance. To address these\nchallenges, we propose a cocoercive conservative (CoCo) denoiser, which may be\n(residual) expansive, leading to improved denoising. By leveraging the\ngeneralized Helmholtz decomposition, we introduce a novel training strategy\nthat combines Hamiltonian regularization to promote conservativeness and\nspectral regularization to ensure cocoerciveness. We prove that CoCo denoiser\nis a proximal operator of a weakly convex function, enabling a restoration\nmodel with an implicit weakly convex prior. The global convergence of PnP\nmethods to a stationary point of this restoration model is established.\nExtensive experimental results demonstrate that our approach outperforms\nclosely related methods in both visual quality and quantitative metrics."}
{"id": "2505.09168", "pdf": "https://arxiv.org/pdf/2505.09168", "abs": "https://arxiv.org/abs/2505.09168", "authors": ["Jianlin Sun", "Xiaolin Fang", "Juwei Guan", "Dongdong Gui", "Teqi Wang", "Tongxin Zhu"], "title": "DRRNet: Macro-Micro Feature Fusion and Dual Reverse Refinement for Camouflaged Object Detection", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The core challenge in Camouflage Object Detection (COD) lies in the\nindistinguishable similarity between targets and backgrounds in terms of color,\ntexture, and shape. This causes existing methods to either lose edge details\n(such as hair-like fine structures) due to over-reliance on global semantic\ninformation or be disturbed by similar backgrounds (such as vegetation\npatterns) when relying solely on local features. We propose DRRNet, a\nfour-stage architecture characterized by a \"context-detail-fusion-refinement\"\npipeline to address these issues. Specifically, we introduce an Omni-Context\nFeature Extraction Module to capture global camouflage patterns and a Local\nDetail Extraction Module to supplement microstructural information for the\nfull-scene context module. We then design a module for forming dual\nrepresentations of scene understanding and structural awareness, which fuses\npanoramic features and local features across various scales. In the decoder, we\nalso introduce a reverse refinement module that leverages spatial edge priors\nand frequency-domain noise suppression to perform a two-stage inverse\nrefinement of the output. By applying two successive rounds of inverse\nrefinement, the model effectively suppresses background interference and\nenhances the continuity of object boundaries. Experimental results demonstrate\nthat DRRNet significantly outperforms state-of-the-art methods on benchmark\ndatasets. Our code is available at https://github.com/jerrySunning/DRRNet."}
{"id": "2505.08837", "pdf": "https://arxiv.org/pdf/2505.08837", "abs": "https://arxiv.org/abs/2505.08837", "authors": ["Muhammad Saqib", "Dipkumar Mehta", "Fnu Yashu", "Shubham Malhotra"], "title": "Adaptive Security Policy Management in Cloud Environments Using Reinforcement Learning", "categories": ["cs.CR", "cs.CV", "cs.DC", "cs.LG", "cs.NI"], "comment": "10 pages, 6 figures, 1 table", "summary": "The security of cloud environments, such as Amazon Web Services (AWS), is\ncomplex and dynamic. Static security policies have become inadequate as threats\nevolve and cloud resources exhibit elasticity [1]. This paper addresses the\nlimitations of static policies by proposing a security policy management\nframework that uses reinforcement learning (RL) to adapt dynamically.\nSpecifically, we employ deep reinforcement learning algorithms, including deep\nQ Networks and proximal policy optimization, enabling the learning and\ncontinuous adjustment of controls such as firewall rules and Identity and\nAccess Management (IAM) policies. The proposed RL based solution leverages\ncloud telemetry data (AWS Cloud Trail logs, network traffic data, threat\nintelligence feeds) to continuously refine security policies, maximizing threat\nmitigation, and compliance while minimizing resource impact. Experimental\nresults demonstrate that our adaptive RL based framework significantly\noutperforms static policies, achieving higher intrusion detection rates (92%\ncompared to 82% for static policies) and substantially reducing incident\ndetection and response times by 58%. In addition, it maintains high conformity\nwith security requirements and efficient resource usage. These findings\nvalidate the effectiveness of adaptive reinforcement learning approaches in\nimproving cloud security policy management."}
{"id": "2505.08961", "pdf": "https://arxiv.org/pdf/2505.08961", "abs": "https://arxiv.org/abs/2505.08961", "authors": ["Yancheng Wang", "Nebojsa Jojic", "Yingzhen Yang"], "title": "Differentiable Channel Selection in Self-Attention For Person Re-Identification", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "In this paper, we propose a novel attention module termed the Differentiable\nChannel Selection Attention module, or the DCS-Attention module. In contrast\nwith conventional self-attention, the DCS-Attention module features selection\nof informative channels in the computation of the attention weights. The\nselection of the feature channels is performed in a differentiable manner,\nenabling seamless integration with DNN training. Our DCS-Attention is\ncompatible with either fixed neural network backbones or learnable backbones\nwith Differentiable Neural Architecture Search (DNAS), leading to DCS with\nFixed Backbone (DCS-FB) and DCS-DNAS, respectively. Importantly, our\nDCS-Attention is motivated by the principle of Information Bottleneck (IB), and\na novel variational upper bound for the IB loss, which can be optimized by SGD,\nis derived and incorporated into the training loss of the networks with the\nDCS-Attention modules. In this manner, a neural network with DCS-Attention\nmodules is capable of selecting the most informative channels for feature\nextraction so that it enjoys state-of-the-art performance for the Re-ID task.\nExtensive experiments on multiple person Re-ID benchmarks using both DCS-FB and\nDCS-DNAS show that DCS-Attention significantly enhances the prediction accuracy\nof DNNs for person Re-ID, which demonstrates the effectiveness of DCS-Attention\nin learning discriminative features critical to identifying person identities.\nThe code of our work is available at\nhttps://github.com/Statistical-Deep-Learning/DCS-Attention."}
{"id": "2505.09203", "pdf": "https://arxiv.org/pdf/2505.09203", "abs": "https://arxiv.org/abs/2505.09203", "authors": ["Xiao-Qi Han", "Peng-Jie Guo", "Ze-Feng Gao", "Hao Sun", "Zhong-Yi Lu"], "title": "InvDesFlow-AL: Active Learning-based Workflow for Inverse Design of Functional Materials", "categories": ["cond-mat.mtrl-sci", "cond-mat.supr-con", "cs.AI", "cs.LG"], "comment": "29 pages, 11 figures", "summary": "Developing inverse design methods for functional materials with specific\nproperties is critical to advancing fields like renewable energy, catalysis,\nenergy storage, and carbon capture. Generative models based on diffusion\nprinciples can directly produce new materials that meet performance\nconstraints, thereby significantly accelerating the material design process.\nHowever, existing methods for generating and predicting crystal structures\noften remain limited by low success rates. In this work, we propose a novel\ninverse material design generative framework called InvDesFlow-AL, which is\nbased on active learning strategies. This framework can iteratively optimize\nthe material generation process to gradually guide it towards desired\nperformance characteristics. In terms of crystal structure prediction, the\nInvDesFlow-AL model achieves an RMSE of 0.0423 {\\AA}, representing an 32.96%\nimprovement in performance compared to exsisting generative models.\nAdditionally, InvDesFlow-AL has been successfully validated in the design of\nlow-formation-energy and low-Ehull materials. It can systematically generate\nmaterials with progressively lower formation energies while continuously\nexpanding the exploration across diverse chemical spaces. These results fully\ndemonstrate the effectiveness of the proposed active learning-driven generative\nmodel in accelerating material discovery and inverse design. To further prove\nthe effectiveness of this method, we took the search for BCS superconductors\nunder ambient pressure as an example explored by InvDesFlow-AL. As a result, we\nsuccessfully identified Li\\(_2\\)AuH\\(_6\\) as a conventional BCS superconductor\nwith an ultra-high transition temperature of 140 K. This discovery provides\nstrong empirical support for the application of inverse design in materials\nscience."}
{"id": "2505.08838", "pdf": "https://arxiv.org/pdf/2505.08838", "abs": "https://arxiv.org/abs/2505.08838", "authors": ["Peixuan Ge", "Tongkun Su", "Faqin Lv", "Baoliang Zhao", "Peng Zhang", "Chi Hong Wong", "Liang Yao", "Yu Sun", "Zenan Wang", "Pak Kin Wong", "Ying Hu"], "title": "Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Ultrasound (US) report generation is a challenging task due to the\nvariability of US images, operator dependence, and the need for standardized\ntext. Unlike X-ray and CT, US imaging lacks consistent datasets, making\nautomation difficult. In this study, we propose a unified framework for\nmulti-organ and multilingual US report generation, integrating fragment-based\nmultilingual training and leveraging the standardized nature of US reports. By\naligning modular text fragments with diverse imaging data and curating a\nbilingual English-Chinese dataset, the method achieves consistent and\nclinically accurate text generation across organ sites and languages.\nFine-tuning with selective unfreezing of the vision transformer (ViT) further\nimproves text-image alignment. Compared to the previous state-of-the-art KMVE\nmethod, our approach achieves relative gains of about 2\\% in BLEU scores,\napproximately 3\\% in ROUGE-L, and about 15\\% in CIDEr, while significantly\nreducing errors such as missing or incorrect content. By unifying multi-organ\nand multi-language report generation into a single, scalable framework, this\nwork demonstrates strong potential for real-world clinical workflows."}
{"id": "2505.08971", "pdf": "https://arxiv.org/pdf/2505.08971", "abs": "https://arxiv.org/abs/2505.08971", "authors": ["Yangyi Chen", "Hao Peng", "Tong Zhang", "Heng Ji"], "title": "Prioritizing Image-Related Tokens Enhances Vision-Language Pre-Training", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "The code will be available at https://github.com/Yangyi-Chen/PRIOR", "summary": "In standard large vision-language models (LVLMs) pre-training, the model\ntypically maximizes the joint probability of the caption conditioned on the\nimage via next-token prediction (NTP); however, since only a small subset of\ncaption tokens directly relates to the visual content, this naive NTP\nunintentionally fits the model to noise and increases the risk of\nhallucination. We present PRIOR, a simple vision-language pre-training approach\nthat addresses this issue by prioritizing image-related tokens through\ndifferential weighting in the NTP loss, drawing from the importance sampling\nframework. PRIOR introduces a reference model-a text-only large language model\n(LLM) trained on the captions without image inputs, to weight each token based\non its probability for LVLMs training. Intuitively, tokens that are directly\nrelated to the visual inputs are harder to predict without the image and thus\nreceive lower probabilities from the text-only reference LLM. During training,\nwe implement a token-specific re-weighting term based on the importance scores\nto adjust each token's loss. We implement PRIOR in two distinct settings: LVLMs\nwith visual encoders and LVLMs without visual encoders. We observe 19% and 8%\naverage relative improvement, respectively, on several vision-language\nbenchmarks compared to NTP. In addition, PRIOR exhibits superior scaling\nproperties, as demonstrated by significantly higher scaling coefficients,\nindicating greater potential for performance gains compared to NTP given\nincreasing compute and data."}
{"id": "2505.09208", "pdf": "https://arxiv.org/pdf/2505.09208", "abs": "https://arxiv.org/abs/2505.09208", "authors": ["Lei Fan", "Kunyang Deng", "Fangxue Liu"], "title": "Educational impacts of generative artificial intelligence on learning and performance of engineering students in China", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "With the rapid advancement of generative artificial intelligence(AI), its\npotential applications in higher education have attracted significant\nattention. This study investigated how 148 students from diverse engineering\ndisciplines and regions across China used generative AI, focusing on its impact\non their learning experience and the opportunities and challenges it poses in\nengineering education. Based on the surveyed data, we explored four key areas:\nthe frequency and application scenarios of AI use among engineering students,\nits impact on students' learning and performance, commonly encountered\nchallenges in using generative AI, and future prospects for its adoption in\nengineering education. The results showed that more than half of the\nparticipants reported a positive impact of generative AI on their learning\nefficiency, initiative, and creativity, with nearly half believing it also\nenhanced their independent thinking. However, despite acknowledging improved\nstudy efficiency, many felt their actual academic performance remained largely\nunchanged and expressed concerns about the accuracy and domain-specific\nreliability of generative AI. Our findings provide a first-hand insight into\nthe current benefits and challenges generative AI brings to students,\nparticularly Chinese engineering students, while offering several\nrecommendations, especially from the students' perspective, for effectively\nintegrating generative AI into engineering education."}
{"id": "2505.08843", "pdf": "https://arxiv.org/pdf/2505.08843", "abs": "https://arxiv.org/abs/2505.08843", "authors": ["Marco Corrias", "Giada Franceschi", "Michele Riva", "Alberto Tampieri", "Karin Föttinger", "Ulrike Diebold", "Thomas Pock", "Cesare Franchini"], "title": "Total Variation-Based Image Decomposition and Denoising for Microscopy Images", "categories": ["eess.IV", "cond-mat.mtrl-sci", "cs.CV"], "comment": null, "summary": "Experimentally acquired microscopy images are unavoidably affected by the\npresence of noise and other unwanted signals, which degrade their quality and\nmight hide relevant features. With the recent increase in image acquisition\nrate, modern denoising and restoration solutions become necessary. This study\nfocuses on image decomposition and denoising of microscopy images through a\nworkflow based on total variation (TV), addressing images obtained from various\nmicroscopy techniques, including atomic force microscopy (AFM), scanning\ntunneling microscopy (STM), and scanning electron microscopy (SEM). Our\napproach consists in restoring an image by extracting its unwanted signal\ncomponents and subtracting them from the raw one, or by denoising it. We\nevaluate the performance of TV-$L^1$, Huber-ROF, and TGV-$L^1$ in achieving\nthis goal in distinct study cases. Huber-ROF proved to be the most flexible\none, while TGV-$L^1$ is the most suitable for denoising. Our results suggest a\nwider applicability of this method in microscopy, restricted not only to STM,\nAFM, and SEM images. The Python code used for this study is publicly available\nas part of AiSurf. It is designed to be integrated into experimental workflows\nfor image acquisition or can be used to denoise previously acquired images."}
{"id": "2505.08986", "pdf": "https://arxiv.org/pdf/2505.08986", "abs": "https://arxiv.org/abs/2505.08986", "authors": ["Amirreza Davar", "Zhengtong Xu", "Siavash Mahmoudi", "Pouya Sohrabipour", "Chaitanya Pallerla", "Yu She", "Wan Shou", "Philip Crandall", "Dongyi Wang"], "title": "ChicGrasp: Imitation-Learning based Customized Dual-Jaw Gripper Control for Delicate, Irregular Bio-products Manipulation", "categories": ["cs.RO", "cs.LG"], "comment": "Submitted for journal review", "summary": "Automated poultry processing lines still rely on humans to lift slippery,\neasily bruised carcasses onto a shackle conveyor. Deformability, anatomical\nvariance, and strict hygiene rules make conventional suction and scripted\nmotions unreliable. We present ChicGrasp, an end--to--end hardware--software\nco-design for this task. An independently actuated dual-jaw pneumatic gripper\nclamps both chicken legs, while a conditional diffusion-policy controller,\ntrained from only 50 multi--view teleoperation demonstrations (RGB +\nproprioception), plans 5 DoF end--effector motion, which includes jaw commands\nin one shot. On individually presented raw broiler carcasses, our system\nachieves a 40.6\\% grasp--and--lift success rate and completes the pick to\nshackle cycle in 38 s, whereas state--of--the--art implicit behaviour cloning\n(IBC) and LSTM-GMM baselines fail entirely. All CAD, code, and datasets will be\nopen-source. ChicGrasp shows that imitation learning can bridge the gap between\nrigid hardware and variable bio--products, offering a reproducible benchmark\nand a public dataset for researchers in agricultural engineering and robot\nlearning."}
{"id": "2505.09246", "pdf": "https://arxiv.org/pdf/2505.09246", "abs": "https://arxiv.org/abs/2505.09246", "authors": ["Derian Boer", "Stephen Roth", "Stefan Kramer"], "title": "Focus, Merge, Rank: Improved Question Answering Based on Semi-structured Knowledge Bases", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "In many real-world settings, machine learning models and interactive systems\nhave access to both structured knowledge, e.g., knowledge graphs or tables, and\nunstructured content, e.g., natural language documents. However, most rely on\neither. Semi-Structured Knowledge Bases (SKBs) bridge this gap by linking\nunstructured content to nodes within structured data, thereby enabling new\nstrategies for knowledge access and use. In this work, we present\nFocusedRetriever, a modular SKB-based framework for multi-hop question\nanswering. It integrates components (VSS-based entity search, LLM-based\ngeneration of Cypher queries and pairwise re-ranking) in a way that enables it\nto outperform state-of-the-art methods across all three STaRK benchmark test\nsets, covering diverse domains and multiple performance metrics. The average\nfirst-hit rate exceeds that of the second-best method by 25.7%.\nFocusedRetriever leverages (1) the capacity of Large Language Models (LLMs) to\nextract relational facts and entity attributes from unstructured text, (2) node\nset joins to filter answer candidates based on these extracted triplets and\nconstraints, (3) vector similarity search to retrieve and rank relevant\nunstructured content, and (4) the contextual capabilities of LLMs to finally\nrank the top-k answers. For generality, we only incorporate base LLMs in\nFocusedRetriever in our evaluation. However, our analysis of intermediate\nresults highlights several opportunities for further upgrades including\nfinetuning. The source code is publicly available at\nhttps://github.com/kramerlab/FocusedRetriever ."}
{"id": "2505.08845", "pdf": "https://arxiv.org/pdf/2505.08845", "abs": "https://arxiv.org/abs/2505.08845", "authors": ["Misgina Tsighe Hagos", "Antti Suutala", "Dmitrii Bychkov", "Hakan Kücükel", "Joar von Bahr", "Milda Poceviciute", "Johan Lundin", "Nina Linder", "Claes Lundström"], "title": "Validation of Conformal Prediction in Cervical Atypia Classification", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "q-bio.QM"], "comment": null, "summary": "Deep learning based cervical cancer classification can potentially increase\naccess to screening in low-resource regions. However, deep learning models are\noften overconfident and do not reliably reflect diagnostic uncertainty.\nMoreover, they are typically optimized to generate maximum-likelihood\npredictions, which fail to convey uncertainty or ambiguity in their results.\nSuch challenges can be addressed using conformal prediction, a model-agnostic\nframework for generating prediction sets that contain likely classes for\ntrained deep-learning models. The size of these prediction sets indicates model\nuncertainty, contracting as model confidence increases. However, existing\nconformal prediction evaluation primarily focuses on whether the prediction set\nincludes or covers the true class, often overlooking the presence of extraneous\nclasses. We argue that prediction sets should be truthful and valuable to end\nusers, ensuring that the listed likely classes align with human expectations\nrather than being overly relaxed and including false positives or unlikely\nclasses. In this study, we comprehensively validate conformal prediction sets\nusing expert annotation sets collected from multiple annotators. We evaluate\nthree conformal prediction approaches applied to three deep-learning models\ntrained for cervical atypia classification. Our expert annotation-based\nanalysis reveals that conventional coverage-based evaluations overestimate\nperformance and that current conformal prediction methods often produce\nprediction sets that are not well aligned with human labels. Additionally, we\nexplore the capabilities of the conformal prediction methods in identifying\nambiguous and out-of-distribution data."}
{"id": "2505.08995", "pdf": "https://arxiv.org/pdf/2505.08995", "abs": "https://arxiv.org/abs/2505.08995", "authors": ["Ardian Selmonaj", "Oleg Szehr", "Giacomo Del Rio", "Alessandro Antonucci", "Adrian Schneider", "Michael Rüegsegger"], "title": "Enhancing Aerial Combat Tactics through Hierarchical Multi-Agent Reinforcement Learning", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.RO"], "comment": "Published as journal chapter in Deep Learning Applications, Vol. 1,\n  by Taylor & Francis", "summary": "This work presents a Hierarchical Multi-Agent Reinforcement Learning\nframework for analyzing simulated air combat scenarios involving heterogeneous\nagents. The objective is to identify effective Courses of Action that lead to\nmission success within preset simulations, thereby enabling the exploration of\nreal-world defense scenarios at low cost and in a safe-to-fail setting.\nApplying deep Reinforcement Learning in this context poses specific challenges,\nsuch as complex flight dynamics, the exponential size of the state and action\nspaces in multi-agent systems, and the capability to integrate real-time\ncontrol of individual units with look-ahead planning. To address these\nchallenges, the decision-making process is split into two levels of\nabstraction: low-level policies control individual units, while a high-level\ncommander policy issues macro commands aligned with the overall mission\ntargets. This hierarchical structure facilitates the training process by\nexploiting policy symmetries of individual agents and by separating control\nfrom command tasks. The low-level policies are trained for individual combat\ncontrol in a curriculum of increasing complexity. The high-level commander is\nthen trained on mission targets given pre-trained control policies. The\nempirical validation confirms the advantages of the proposed framework."}
{"id": "2505.09262", "pdf": "https://arxiv.org/pdf/2505.09262", "abs": "https://arxiv.org/abs/2505.09262", "authors": ["Hongxin Xiang", "Ke Li", "Mingquan Liu", "Zhixiang Cheng", "Bin Yao", "Wenjie Du", "Jun Xia", "Li Zeng", "Xin Jin", "Xiangxiang Zeng"], "title": "EDBench: Large-Scale Electron Density Data for Molecular Modeling", "categories": ["physics.chem-ph", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Existing molecular machine learning force fields (MLFFs) generally focus on\nthe learning of atoms, molecules, and simple quantum chemical properties (such\nas energy and force), but ignore the importance of electron density (ED)\n$\\rho(r)$ in accurately understanding molecular force fields (MFFs). ED\ndescribes the probability of finding electrons at specific locations around\natoms or molecules, which uniquely determines all ground state properties (such\nas energy, molecular structure, etc.) of interactive multi-particle systems\naccording to the Hohenberg-Kohn theorem. However, the calculation of ED relies\non the time-consuming first-principles density functional theory (DFT) which\nleads to the lack of large-scale ED data and limits its application in MLFFs.\nIn this paper, we introduce EDBench, a large-scale, high-quality dataset of ED\ndesigned to advance learning-based research at the electronic scale. Built upon\nthe PCQM4Mv2, EDBench provides accurate ED data, covering 3.3 million\nmolecules. To comprehensively evaluate the ability of models to understand and\nutilize electronic information, we design a suite of ED-centric benchmark tasks\nspanning prediction, retrieval, and generation. Our evaluation on several\nstate-of-the-art methods demonstrates that learning from EDBench is not only\nfeasible but also achieves high accuracy. Moreover, we show that learning-based\nmethod can efficiently calculate ED with comparable precision while\nsignificantly reducing the computational cost relative to traditional DFT\ncalculations. All data and benchmarks from EDBench will be freely available,\nlaying a robust foundation for ED-driven drug discovery and materials science."}
{"id": "2505.08889", "pdf": "https://arxiv.org/pdf/2505.08889", "abs": "https://arxiv.org/abs/2505.08889", "authors": ["Linjie Lyu", "Valentin Deschaintre", "Yannick Hold-Geoffroy", "Miloš Hašan", "Jae Shin Yoon", "Thomas Leimkühler", "Christian Theobalt", "Iliyan Georgiev"], "title": "IntrinsicEdit: Precise generative image manipulation in intrinsic space", "categories": ["cs.GR", "cs.CV"], "comment": "SIGGRAPH 2025 Journal track", "summary": "Generative diffusion models have advanced image editing with high-quality\nresults and intuitive interfaces such as prompts and semantic drawing. However,\nthese interfaces lack precise control, and the associated methods typically\nspecialize on a single editing task. We introduce a versatile, generative\nworkflow that operates in an intrinsic-image latent space, enabling semantic,\nlocal manipulation with pixel precision for a range of editing operations.\nBuilding atop the RGB-X diffusion framework, we address key challenges of\nidentity preservation and intrinsic-channel entanglement. By incorporating\nexact diffusion inversion and disentangled channel manipulation, we enable\nprecise, efficient editing with automatic resolution of global illumination\neffects -- all without additional data collection or model fine-tuning. We\ndemonstrate state-of-the-art performance across a variety of tasks on complex\nimages, including color and texture adjustments, object insertion and removal,\nglobal relighting, and their combinations."}
{"id": "2505.09004", "pdf": "https://arxiv.org/pdf/2505.09004", "abs": "https://arxiv.org/abs/2505.09004", "authors": ["Monica Welfert", "Nathan Stromberg", "Mario Diaz", "Lalitha Sankar"], "title": "Lower Bounds on the MMSE of Adversarially Inferring Sensitive Features", "categories": ["stat.ML", "cs.LG"], "comment": "submitted to IEEE Transactions on Information Theory", "summary": "We propose an adversarial evaluation framework for sensitive feature\ninference based on minimum mean-squared error (MMSE) estimation with a finite\nsample size and linear predictive models. Our approach establishes theoretical\nlower bounds on the true MMSE of inferring sensitive features from noisy\nobservations of other correlated features. These bounds are expressed in terms\nof the empirical MMSE under a restricted hypothesis class and a non-negative\nerror term. The error term captures both the estimation error due to finite\nnumber of samples and the approximation error from using a restricted\nhypothesis class. For linear predictive models, we derive closed-form bounds,\nwhich are order optimal in terms of the noise variance, on the approximation\nerror for several classes of relationships between the sensitive and\nnon-sensitive features, including linear mappings, binary symmetric channels,\nand class-conditional multi-variate Gaussian distributions. We also present a\nnew lower bound that relies on the MSE computed on a hold-out validation\ndataset of the MMSE estimator learned on finite-samples and a restricted\nhypothesis class. Through empirical evaluation, we demonstrate that our\nframework serves as an effective tool for MMSE-based adversarial evaluation of\nsensitive feature inference that balances theoretical guarantees with practical\nefficiency."}
{"id": "2505.09263", "pdf": "https://arxiv.org/pdf/2505.09263", "abs": "https://arxiv.org/abs/2505.09263", "authors": ["Guan Gui", "Bin-Bin Gao", "Jun Liu", "Chengjie Wang", "Yunsheng Wu"], "title": "Few-Shot Anomaly-Driven Generation for Anomaly Classification and Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ECCV 2024", "summary": "Anomaly detection is a practical and challenging task due to the scarcity of\nanomaly samples in industrial inspection. Some existing anomaly detection\nmethods address this issue by synthesizing anomalies with noise or external\ndata. However, there is always a large semantic gap between synthetic and\nreal-world anomalies, resulting in weak performance in anomaly detection. To\nsolve the problem, we propose a few-shot Anomaly-driven Generation (AnoGen)\nmethod, which guides the diffusion model to generate realistic and diverse\nanomalies with only a few real anomalies, thereby benefiting training anomaly\ndetection models. Specifically, our work is divided into three stages. In the\nfirst stage, we learn the anomaly distribution based on a few given real\nanomalies and inject the learned knowledge into an embedding. In the second\nstage, we use the embedding and given bounding boxes to guide the diffusion\nmodel to generate realistic and diverse anomalies on specific objects (or\ntextures). In the final stage, we propose a weakly-supervised anomaly detection\nmethod to train a more powerful model with generated anomalies. Our method\nbuilds upon DRAEM and DesTSeg as the foundation model and conducts experiments\non the commonly used industrial anomaly detection dataset, MVTec. The\nexperiments demonstrate that our generated anomalies effectively improve the\nmodel performance of both anomaly classification and segmentation tasks\nsimultaneously, \\eg, DRAEM and DseTSeg achieved a 5.8\\% and 1.5\\% improvement\nin AU-PR metric on segmentation task, respectively. The code and generated\nanomalous data are available at https://github.com/gaobb/AnoGen."}
{"id": "2505.08919", "pdf": "https://arxiv.org/pdf/2505.08919", "abs": "https://arxiv.org/abs/2505.08919", "authors": ["Kangxian Xie", "Yufei Zhu", "Kaiming Kuang", "Li Zhang", "Hongwei Bran Li", "Mingchen Gao", "Jiancheng Yang"], "title": "Template-Guided Reconstruction of Pulmonary Segments with Neural Implicit Functions", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "In revision process", "summary": "High-quality 3D reconstruction of pulmonary segments plays a crucial role in\nsegmentectomy and surgical treatment planning for lung cancer. Due to the\nresolution requirement of the target reconstruction, conventional deep\nlearning-based methods often suffer from computational resource constraints or\nlimited granularity. Conversely, implicit modeling is favored due to its\ncomputational efficiency and continuous representation at any resolution. We\npropose a neural implicit function-based method to learn a 3D surface to\nachieve anatomy-aware, precise pulmonary segment reconstruction, represented as\na shape by deforming a learnable template. Additionally, we introduce two\nclinically relevant evaluation metrics to assess the reconstruction\ncomprehensively. Further, due to the absence of publicly available shape\ndatasets to benchmark reconstruction algorithms, we developed a shape dataset\nnamed Lung3D, including the 3D models of 800 labeled pulmonary segments and the\ncorresponding airways, arteries, veins, and intersegmental veins. We\ndemonstrate that the proposed approach outperforms existing methods, providing\na new perspective for pulmonary segment reconstruction. Code and data will be\navailable at https://github.com/M3DV/ImPulSe."}
{"id": "2505.09018", "pdf": "https://arxiv.org/pdf/2505.09018", "abs": "https://arxiv.org/abs/2505.09018", "authors": ["Adarsh Kumar"], "title": "Multimodal Fusion of Glucose Monitoring and Food Imagery for Caloric Content Prediction", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Effective dietary monitoring is critical for managing Type 2 diabetes, yet\naccurately estimating caloric intake remains a major challenge. While\ncontinuous glucose monitors (CGMs) offer valuable physiological data, they\noften fall short in capturing the full nutritional profile of meals due to\ninter-individual and meal-specific variability. In this work, we introduce a\nmultimodal deep learning framework that jointly leverages CGM time-series data,\nDemographic/Microbiome, and pre-meal food images to enhance caloric estimation.\nOur model utilizes attention based encoding and a convolutional feature\nextraction for meal imagery, multi-layer perceptrons for CGM and Microbiome\ndata followed by a late fusion strategy for joint reasoning. We evaluate our\napproach on a curated dataset of over 40 participants, incorporating\nsynchronized CGM, Demographic and Microbiome data and meal photographs with\nstandardized caloric labels. Our model achieves a Root Mean Squared Relative\nError (RMSRE) of 0.2544, outperforming the baselines models by over 50%. These\nfindings demonstrate the potential of multimodal sensing to improve automated\ndietary assessment tools for chronic disease management."}
{"id": "2505.09264", "pdf": "https://arxiv.org/pdf/2505.09264", "abs": "https://arxiv.org/abs/2505.09264", "authors": ["Bin-Bin Gao"], "title": "Learning to Detect Multi-class Anomalies with Just One Normal Image Prompt", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by ECCV 2024", "summary": "Unsupervised reconstruction networks using self-attention transformers have\nachieved state-of-the-art performance for multi-class (unified) anomaly\ndetection with a single model. However, these self-attention reconstruction\nmodels primarily operate on target features, which may result in perfect\nreconstruction for both normal and anomaly features due to high consistency\nwith context, leading to failure in detecting anomalies. Additionally, these\nmodels often produce inaccurate anomaly segmentation due to performing\nreconstruction in a low spatial resolution latent space. To enable\nreconstruction models enjoying high efficiency while enhancing their\ngeneralization for unified anomaly detection, we propose a simple yet effective\nmethod that reconstructs normal features and restores anomaly features with\njust One Normal Image Prompt (OneNIP). In contrast to previous work, OneNIP\nallows for the first time to reconstruct or restore anomalies with just one\nnormal image prompt, effectively boosting unified anomaly detection\nperformance. Furthermore, we propose a supervised refiner that regresses\nreconstruction errors by using both real normal and synthesized anomalous\nimages, which significantly improves pixel-level anomaly segmentation. OneNIP\noutperforms previous methods on three industry anomaly detection benchmarks:\nMVTec, BTAD, and VisA. The code and pre-trained models are available at\nhttps://github.com/gaobb/OneNIP."}
{"id": "2505.08932", "pdf": "https://arxiv.org/pdf/2505.08932", "abs": "https://arxiv.org/abs/2505.08932", "authors": ["Mohammad Wasil", "Ahmad Drak", "Brennan Penfold", "Ludovico Scarton", "Maximilian Johenneken", "Alexander Asteroth", "Sebastian Houben"], "title": "Parameter-Efficient Fine-Tuning of Vision Foundation Model for Forest Floor Segmentation from UAV Imagery", "categories": ["cs.RO", "cs.CV"], "comment": "Accepted to the Novel Approaches for Precision Agriculture and\n  Forestry with Autonomous Robots IEEE ICRA Workshop - 2025", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly used for reforestation and\nforest monitoring, including seed dispersal in hard-to-reach terrains. However,\na detailed understanding of the forest floor remains a challenge due to high\nnatural variability, quickly changing environmental parameters, and ambiguous\nannotations due to unclear definitions. To address this issue, we adapt the\nSegment Anything Model (SAM), a vision foundation model with strong\ngeneralization capabilities, to segment forest floor objects such as tree\nstumps, vegetation, and woody debris. To this end, we employ\nparameter-efficient fine-tuning (PEFT) to fine-tune a small subset of\nadditional model parameters while keeping the original weights fixed. We adjust\nSAM's mask decoder to generate masks corresponding to our dataset categories,\nallowing for automatic segmentation without manual prompting. Our results show\nthat the adapter-based PEFT method achieves the highest mean intersection over\nunion (mIoU), while Low-rank Adaptation (LoRA), with fewer parameters, offers a\nlightweight alternative for resource-constrained UAV platforms."}
{"id": "2505.09024", "pdf": "https://arxiv.org/pdf/2505.09024", "abs": "https://arxiv.org/abs/2505.09024", "authors": ["Aaron Baughman", "Rahul Agarwal", "Eduardo Morales", "Gozde Akay"], "title": "Automated Meta Prompt Engineering for Alignment with the Theory of Mind", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": "9 pages, 6 figures, 3 tables", "summary": "We introduce a method of meta-prompting that jointly produces fluent text for\ncomplex tasks while optimizing the similarity of neural states between a\nhuman's mental expectation and a Large Language Model's (LLM) neural\nprocessing. A technique of agentic reinforcement learning is applied, in which\nan LLM as a Judge (LLMaaJ) teaches another LLM, through in-context learning,\nhow to produce content by interpreting the intended and unintended generated\ntext traits. To measure human mental beliefs around content production, users\nmodify long form AI-generated text articles before publication at the US Open\n2024 tennis Grand Slam. Now, an LLMaaJ can solve the Theory of Mind (ToM)\nalignment problem by anticipating and including human edits within the creation\nof text from an LLM. Throughout experimentation and by interpreting the results\nof a live production system, the expectations of human content reviewers had\n100% of alignment with AI 53.8% of the time with an average iteration count of\n4.38. The geometric interpretation of content traits such as factualness,\nnovelty, repetitiveness, and relevancy over a Hilbert vector space combines\nspatial volume (all trait importance) with vertices alignment (individual trait\nrelevance) enabled the LLMaaJ to optimize on Human ToM. This resulted in an\nincrease in content quality by extending the coverage of tennis action. Our\nwork that was deployed at the US Open 2024 has been used across other live\nevents within sports and entertainment."}
{"id": "2505.09265", "pdf": "https://arxiv.org/pdf/2505.09265", "abs": "https://arxiv.org/abs/2505.09265", "authors": ["Bin-Bin Gao"], "title": "MetaUAS: Universal Anomaly Segmentation with One-Prompt Meta-Learning", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by NeurIPS 2024", "summary": "Zero- and few-shot visual anomaly segmentation relies on powerful\nvision-language models that detect unseen anomalies using manually designed\ntextual prompts. However, visual representations are inherently independent of\nlanguage. In this paper, we explore the potential of a pure visual foundation\nmodel as an alternative to widely used vision-language models for universal\nvisual anomaly segmentation. We present a novel paradigm that unifies anomaly\nsegmentation into change segmentation. This paradigm enables us to leverage\nlarge-scale synthetic image pairs, featuring object-level and local region\nchanges, derived from existing image datasets, which are independent of target\nanomaly datasets. We propose a one-prompt Meta-learning framework for Universal\nAnomaly Segmentation (MetaUAS) that is trained on this synthetic dataset and\nthen generalizes well to segment any novel or unseen visual anomalies in the\nreal world. To handle geometrical variations between prompt and query images,\nwe propose a soft feature alignment module that bridges paired-image change\nperception and single-image semantic segmentation. This is the first work to\nachieve universal anomaly segmentation using a pure vision model without\nrelying on special anomaly detection datasets and pre-trained visual-language\nmodels. Our method effectively and efficiently segments any anomalies with only\none normal image prompt and enjoys training-free without guidance from\nlanguage. Our MetaUAS significantly outperforms previous zero-shot, few-shot,\nand even full-shot anomaly segmentation methods. The code and pre-trained\nmodels are available at https://github.com/gaobb/MetaUAS."}
{"id": "2505.08949", "pdf": "https://arxiv.org/pdf/2505.08949", "abs": "https://arxiv.org/abs/2505.08949", "authors": ["Kateryna Zorina", "David Kovar", "Mederic Fourmy", "Florent Lamiraux", "Nicolas Mansard", "Justin Carpentier", "Josef Sivic", "Vladimir Petrik"], "title": "Multi-step manipulation task and motion planning guided by video demonstration", "categories": ["cs.RO", "cs.CV", "cs.SY", "eess.SY"], "comment": null, "summary": "This work aims to leverage instructional video to solve complex multi-step\ntask-and-motion planning tasks in robotics. Towards this goal, we propose an\nextension of the well-established Rapidly-Exploring Random Tree (RRT) planner,\nwhich simultaneously grows multiple trees around grasp and release states\nextracted from the guiding video. Our key novelty lies in combining contact\nstates and 3D object poses extracted from the guiding video with a traditional\nplanning algorithm that allows us to solve tasks with sequential dependencies,\nfor example, if an object needs to be placed at a specific location to be\ngrasped later. We also investigate the generalization capabilities of our\napproach to go beyond the scene depicted in the instructional video. To\ndemonstrate the benefits of the proposed video-guided planning approach, we\ndesign a new benchmark with three challenging tasks: (I) 3D re-arrangement of\nmultiple objects between a table and a shelf, (ii) multi-step transfer of an\nobject through a tunnel, and (iii) transferring objects using a tray similar to\na waiter transfers dishes. We demonstrate the effectiveness of our planning\nalgorithm on several robots, including the Franka Emika Panda and the KUKA KMR\niiwa. For a seamless transfer of the obtained plans to the real robot, we\ndevelop a trajectory refinement approach formulated as an optimal control\nproblem (OCP)."}
{"id": "2505.09026", "pdf": "https://arxiv.org/pdf/2505.09026", "abs": "https://arxiv.org/abs/2505.09026", "authors": ["Domniki Ladopoulou", "Dat Minh Hong", "Petros Dellaportas"], "title": "Probabilistic Wind Power Forecasting via Non-Stationary Gaussian Processes", "categories": ["stat.AP", "cs.LG", "stat.ML"], "comment": "11 pages, 3 figures, 2 tables", "summary": "Accurate probabilistic forecasting of wind power is essential for maintaining\ngrid stability and enabling efficient integration of renewable energy sources.\nGaussian Process (GP) models offer a principled framework for quantifying\nuncertainty; however, conventional approaches rely on stationary kernels, which\nare inadequate for modeling the inherently non-stationary nature of wind speed\nand power output. We propose a non-stationary GP framework that incorporates\nthe generalized spectral mixture (GSM) kernel, enabling the model to capture\ntime-varying patterns and heteroscedastic behaviors in wind speed and wind\npower data. We evaluate the performance of the proposed model on real-world\nSCADA data across short\\mbox{-,} medium-, and long-term forecasting horizons.\nCompared to standard radial basis function and spectral mixture kernels, the\nGSM-based model outperforms, particularly in short-term forecasts. These\nresults highlight the necessity of modeling non-stationarity in wind power\nforecasting and demonstrate the practical value of non-stationary GP models in\noperational settings."}
{"id": "2505.09295", "pdf": "https://arxiv.org/pdf/2505.09295", "abs": "https://arxiv.org/abs/2505.09295", "authors": ["Qiming Wu", "Siqi Li", "Doudou Zhou", "Nan Liu"], "title": "Toward Fair Federated Learning under Demographic Disparities and Data Imbalance", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "Ensuring fairness is critical when applying artificial intelligence to\nhigh-stakes domains such as healthcare, where predictive models trained on\nimbalanced and demographically skewed data risk exacerbating existing\ndisparities. Federated learning (FL) enables privacy-preserving collaboration\nacross institutions, but remains vulnerable to both algorithmic bias and\nsubgroup imbalance - particularly when multiple sensitive attributes intersect.\nWe propose FedIDA (Fed erated Learning for Imbalance and D isparity A\nwareness), a framework-agnostic method that combines fairness-aware\nregularization with group-conditional oversampling. FedIDA supports multiple\nsensitive attributes and heterogeneous data distributions without altering the\nconvergence behavior of the underlying FL algorithm. We provide theoretical\nanalysis establishing fairness improvement bounds using Lipschitz continuity\nand concentration inequalities, and show that FedIDA reduces the variance of\nfairness metrics across test sets. Empirical results on both benchmark and\nreal-world clinical datasets confirm that FedIDA consistently improves fairness\nwhile maintaining competitive predictive performance, demonstrating its\neffectiveness for equitable and privacy-preserving modeling in healthcare. The\nsource code is available on GitHub."}
{"id": "2505.08990", "pdf": "https://arxiv.org/pdf/2505.08990", "abs": "https://arxiv.org/abs/2505.08990", "authors": ["Andrew C. Freeman"], "title": "Toward Accessible and Safe Live Streaming Using Distributed Content Filtering with MoQ", "categories": ["cs.MM", "cs.CV", "cs.DC", "cs.NI"], "comment": "Accepted to the ICME 2025 LIVES workshop", "summary": "Live video streaming is increasingly popular on social media platforms. With\nthe growth of live streaming comes an increased need for robust content\nmoderation to remove dangerous, illegal, or otherwise objectionable content.\nWhereas video on demand distribution enables offline content analysis, live\nstreaming imposes restrictions on latency for both analysis and distribution.\nIn this paper, we present extensions to the in-progress Media Over QUIC\nTransport protocol that enable real-time content moderation in one-to-many\nvideo live streams. Importantly, our solution removes only the video segments\nthat contain objectionable content, allowing playback resumption as soon as the\nstream conforms to content policies again. Content analysis tasks may be\ntransparently distributed to arbitrary client devices. We implement and\nevaluate our system in the context of light strobe removal for photosensitive\nviewers, finding that streaming clients experience an increased latency of only\none group-of-pictures duration."}
{"id": "2505.09029", "pdf": "https://arxiv.org/pdf/2505.09029", "abs": "https://arxiv.org/abs/2505.09029", "authors": ["Hazim Alzorgan", "Abolfazl Razi"], "title": "Monte Carlo Beam Search for Actor-Critic Reinforcement Learning in Continuous Control", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Actor-critic methods, like Twin Delayed Deep Deterministic Policy Gradient\n(TD3), depend on basic noise-based exploration, which can result in less than\noptimal policy convergence. In this study, we introduce Monte Carlo Beam Search\n(MCBS), a new hybrid method that combines beam search and Monte Carlo rollouts\nwith TD3 to improve exploration and action selection. MCBS produces several\ncandidate actions around the policy's output and assesses them through\nshort-horizon rollouts, enabling the agent to make better-informed choices. We\ntest MCBS across various continuous-control benchmarks, including\nHalfCheetah-v4, Walker2d-v5, and Swimmer-v5, showing enhanced sample efficiency\nand performance compared to standard TD3 and other baseline methods like SAC,\nPPO, and A2C. Our findings emphasize MCBS's capability to enhance policy\nlearning through structured look-ahead search while ensuring computational\nefficiency. Additionally, we offer a detailed analysis of crucial\nhyperparameters, such as beam width and rollout depth, and explore adaptive\nstrategies to optimize MCBS for complex control tasks. Our method shows a\nhigher convergence rate across different environments compared to TD3, SAC,\nPPO, and A2C. For instance, we achieved 90% of the maximum achievable reward\nwithin around 200 thousand timesteps compared to 400 thousand timesteps for the\nsecond-best method."}
{"id": "2505.09324", "pdf": "https://arxiv.org/pdf/2505.09324", "abs": "https://arxiv.org/abs/2505.09324", "authors": ["Lakshya Gupta", "Imran N. Junejo"], "title": "Neural Video Compression using 2D Gaussian Splatting", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "comment": "9 pages, 8 figures", "summary": "The computer vision and image processing research community has been involved\nin standardizing video data communications for the past many decades, leading\nto standards such as AVC, HEVC, VVC, AV1, AV2, etc. However, recent\ngroundbreaking works have focused on employing deep learning-based techniques\nto replace the traditional video codec pipeline to a greater affect. Neural\nvideo codecs (NVC) create an end-to-end ML-based solution that does not rely on\nany handcrafted features (motion or edge-based) and have the ability to learn\ncontent-aware compression strategies, offering better adaptability and higher\ncompression efficiency than traditional methods. This holds a great potential\nnot only for hardware design, but also for various video streaming platforms\nand applications, especially video conferencing applications such as MS-Teams\nor Zoom that have found extensive usage in classrooms and workplaces. However,\ntheir high computational demands currently limit their use in real-time\napplications like video conferencing. To address this, we propose a\nregion-of-interest (ROI) based neural video compression model that leverages 2D\nGaussian Splatting. Unlike traditional codecs, 2D Gaussian Splatting is capable\nof real-time decoding and can be optimized using fewer data points, requiring\nonly thousands of Gaussians for decent quality outputs as opposed to millions\nin 3D scenes. In this work, we designed a video pipeline that speeds up the\nencoding time of the previous Gaussian splatting-based image codec by 88% by\nusing a content-aware initialization strategy paired with a novel Gaussian\ninter-frame redundancy-reduction mechanism, enabling Gaussian splatting to be\nused for a video-codec solution, the first of its kind solution in this neural\nvideo codec space."}
{"id": "2505.08998", "pdf": "https://arxiv.org/pdf/2505.08998", "abs": "https://arxiv.org/abs/2505.08998", "authors": ["Liwen Wu", "Sai Bi", "Zexiang Xu", "Hao Tan", "Kai Zhang", "Fujun Luan", "Haolin Lu", "Ravi Ramamoorthi"], "title": "Neural BRDF Importance Sampling by Reparameterization", "categories": ["cs.GR", "cs.CV"], "comment": null, "summary": "Neural bidirectional reflectance distribution functions (BRDFs) have emerged\nas popular material representations for enhancing realism in physically-based\nrendering. Yet their importance sampling remains a significant challenge. In\nthis paper, we introduce a reparameterization-based formulation of neural BRDF\nimportance sampling that seamlessly integrates into the standard rendering\npipeline with precise generation of BRDF samples. The reparameterization-based\nformulation transfers the distribution learning task to a problem of\nidentifying BRDF integral substitutions. In contrast to previous methods that\nrely on invertible networks and multi-step inference to reconstruct BRDF\ndistributions, our model removes these constraints, which offers greater\nflexibility and efficiency. Our variance and performance analysis demonstrates\nthat our reparameterization method achieves the best variance reduction in\nneural BRDF renderings while maintaining high inference speeds compared to\nexisting baselines."}
{"id": "2505.09040", "pdf": "https://arxiv.org/pdf/2505.09040", "abs": "https://arxiv.org/abs/2505.09040", "authors": ["Owen Kwon", "Abraham George", "Alison Bartsch", "Amir Barati Farimani"], "title": "RT-cache: Efficient Robot Trajectory Retrieval System", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "9 pages, 5 figures. Submitted to an IEEE robotics conference", "summary": "This paper introduces RT-cache, a novel trajectorymemory pipeline that\naccelerates real-world robot inference by leveraging big-data retrieval and\nlearning from experience. While modern Vision-Language-Action (VLA) models can\nhandle diverse robotic tasks, they often incur high per-step inference costs,\nresulting in significant latency, sometimes minutes per task. In contrast,\nRT-cache stores a large-scale Memory of previously successful robot\ntrajectories and retrieves relevant multistep motion snippets, drastically\nreducing inference overhead. By integrating a Memory Builder with a Trajectory\nRetrieval, we develop an efficient retrieval process that remains tractable\neven for extremely large datasets. RT-cache flexibly accumulates real-world\nexperiences and replays them whenever the current scene matches past states,\nadapting quickly to new or unseen environments with only a few additional\nsamples. Experiments on the Open-X Embodiment Dataset and other real-world data\ndemonstrate that RT-cache completes tasks both faster and more successfully\nthan a baseline lacking retrieval, suggesting a practical, data-driven solution\nfor real-time manipulation."}
{"id": "2505.09329", "pdf": "https://arxiv.org/pdf/2505.09329", "abs": "https://arxiv.org/abs/2505.09329", "authors": ["Jiarun Liu", "Hong-Yu Zhou", "Weijian Huang", "Hao Yang", "Dongning Song", "Tao Tan", "Yong Liang", "Shanshan Wang"], "title": "BioVFM-21M: Benchmarking and Scaling Self-Supervised Vision Foundation Models for Biomedical Image Analysis", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 4 figures", "summary": "Scaling up model and data size have demonstrated impressive performance\nimprovement over a wide range of tasks. Despite extensive studies on scaling\nbehaviors for general-purpose tasks, medical images exhibit substantial\ndifferences from natural data. It remains unclear the key factors in developing\nmedical vision foundation models at scale due to the absence of an extensive\nunderstanding of scaling behavior in the medical domain. In this paper, we\nexplored the scaling behavior across model sizes, training algorithms, data\nsizes, and imaging modalities in developing scalable medical vision foundation\nmodels by self-supervised learning. To support scalable pretraining, we\nintroduce BioVFM-21M, a large-scale biomedical image dataset encompassing a\nwide range of biomedical image modalities and anatomies. We observed that\nscaling up does provide benefits but varies across tasks. Additional analysis\nreveals several factors correlated with scaling benefits. Finally, we propose\nBioVFM, a large-scale medical vision foundation model pretrained on 21 million\nbiomedical images, which outperforms the previous state-of-the-art foundation\nmodels across 12 medical benchmarks. Our results highlight that while scaling\nup is beneficial for pursuing better performance, task characteristics, data\ndiversity, pretraining methods, and computational efficiency remain critical\nconsiderations for developing scalable medical foundation models."}
{"id": "2505.09040", "pdf": "https://arxiv.org/pdf/2505.09040", "abs": "https://arxiv.org/abs/2505.09040", "authors": ["Owen Kwon", "Abraham George", "Alison Bartsch", "Amir Barati Farimani"], "title": "RT-cache: Efficient Robot Trajectory Retrieval System", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.LG"], "comment": "9 pages, 5 figures. Submitted to an IEEE robotics conference", "summary": "This paper introduces RT-cache, a novel trajectorymemory pipeline that\naccelerates real-world robot inference by leveraging big-data retrieval and\nlearning from experience. While modern Vision-Language-Action (VLA) models can\nhandle diverse robotic tasks, they often incur high per-step inference costs,\nresulting in significant latency, sometimes minutes per task. In contrast,\nRT-cache stores a large-scale Memory of previously successful robot\ntrajectories and retrieves relevant multistep motion snippets, drastically\nreducing inference overhead. By integrating a Memory Builder with a Trajectory\nRetrieval, we develop an efficient retrieval process that remains tractable\neven for extremely large datasets. RT-cache flexibly accumulates real-world\nexperiences and replays them whenever the current scene matches past states,\nadapting quickly to new or unseen environments with only a few additional\nsamples. Experiments on the Open-X Embodiment Dataset and other real-world data\ndemonstrate that RT-cache completes tasks both faster and more successfully\nthan a baseline lacking retrieval, suggesting a practical, data-driven solution\nfor real-time manipulation."}
{"id": "2505.09062", "pdf": "https://arxiv.org/pdf/2505.09062", "abs": "https://arxiv.org/abs/2505.09062", "authors": ["Junda Zhao", "Yuliang Song", "Eldan Cohen"], "title": "Variational Prefix Tuning for Diverse and Accurate Code Summarization Using Pre-trained Language Models", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.7"], "comment": "Accepted by the Journal of Systems and Software", "summary": "Recent advancements in source code summarization have leveraged\ntransformer-based pre-trained models, including Large Language Models of Code\n(LLMCs), to automate and improve the generation of code summaries. However,\nexisting methods often focus on generating a single high-quality summary for a\ngiven source code, neglecting scenarios where the generated summary might be\ninadequate and alternative options are needed. In this paper, we introduce\nVariational Prefix Tuning (VPT), a novel approach that enhances pre-trained\nmodels' ability to generate diverse yet accurate sets of summaries, allowing\nthe user to choose the most suitable one for the given source code. Our method\nintegrates a Conditional Variational Autoencoder (CVAE) framework as a modular\ncomponent into pre-trained models, enabling us to model the distribution of\nobserved target summaries and sample continuous embeddings to be used as\nprefixes to steer the generation of diverse outputs during decoding.\nImportantly, we construct our method in a parameter-efficient manner,\neliminating the need for expensive model retraining, especially when using\nLLMCs. Furthermore, we employ a bi-criteria reranking method to select a subset\nof generated summaries, optimizing both the diversity and the accuracy of the\noptions presented to users. We present extensive experimental evaluations using\nwidely used datasets and current state-of-the-art pre-trained code\nsummarization models to demonstrate the effectiveness of our approach and its\nadaptability across models."}
{"id": "2505.09342", "pdf": "https://arxiv.org/pdf/2505.09342", "abs": "https://arxiv.org/abs/2505.09342", "authors": ["Mostafa Jafari", "Alireza Shameli-Sendi"], "title": "Evaluating the Robustness of Adversarial Defenses in Malware Detection Systems", "categories": ["cs.CR", "cs.AI", "cs.LG", "68", "I.2.1"], "comment": "Submitted to IEEE Transactions on Information Forensics and Security\n  (T-IFS), 13 pages, 4 figures", "summary": "Machine learning is a key tool for Android malware detection, effectively\nidentifying malicious patterns in apps. However, ML-based detectors are\nvulnerable to evasion attacks, where small, crafted changes bypass detection.\nDespite progress in adversarial defenses, the lack of comprehensive evaluation\nframeworks in binary-constrained domains limits understanding of their\nrobustness. We introduce two key contributions. First, Prioritized Binary\nRounding, a technique to convert continuous perturbations into binary feature\nspaces while preserving high attack success and low perturbation size. Second,\nthe sigma-binary attack, a novel adversarial method for binary domains,\ndesigned to achieve attack goals with minimal feature changes. Experiments on\nthe Malscan dataset show that sigma-binary outperforms existing attacks and\nexposes key vulnerabilities in state-of-the-art defenses. Defenses equipped\nwith adversary detectors, such as KDE, DLA, DNN+, and ICNN, exhibit significant\nbrittleness, with attack success rates exceeding 90% using fewer than 10\nfeature modifications and reaching 100% with just 20. Adversarially trained\ndefenses, including AT-rFGSM-k, AT-MaxMA, improves robustness under small\nbudgets but remains vulnerable to unrestricted perturbations, with attack\nsuccess rates of 99.45% and 96.62%, respectively. Although PAD-SMA demonstrates\nstrong robustness against state-of-the-art gradient-based adversarial attacks\nby maintaining an attack success rate below 16.55%, the sigma-binary attack\nsignificantly outperforms these methods, achieving a 94.56% success rate under\nunrestricted perturbations. These findings highlight the critical need for\nprecise method like sigma-binary to expose hidden vulnerabilities in existing\ndefenses and support the development of more resilient malware detection\nsystems."}
{"id": "2505.09091", "pdf": "https://arxiv.org/pdf/2505.09091", "abs": "https://arxiv.org/abs/2505.09091", "authors": ["Zeeshan Ahmad", "Shudi Bao", "Meng Chen"], "title": "DPN-GAN: Inducing Periodic Activations in Generative Adversarial Networks for High-Fidelity Audio Synthesis", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "comment": null, "summary": "In recent years, generative adversarial networks (GANs) have made significant\nprogress in generating audio sequences. However, these models typically rely on\nbandwidth-limited mel-spectrograms, which constrain the resolution of generated\naudio sequences, and lead to mode collapse during conditional generation. To\naddress this issue, we propose Deformable Periodic Network based GAN (DPN-GAN),\na novel GAN architecture that incorporates a kernel-based periodic ReLU\nactivation function to induce periodic bias in audio generation. This\ninnovative approach enhances the model's ability to capture and reproduce\nintricate audio patterns. In particular, our proposed model features a DPN\nmodule for multi-resolution generation utilizing deformable convolution\noperations, allowing for adaptive receptive fields that improve the quality and\nfidelity of the synthetic audio. Additionally, we enhance the discriminator\nnetwork using deformable convolution to better distinguish between real and\ngenerated samples, further refining the audio quality. We trained two versions\nof the model: DPN-GAN small (38.67M parameters) and DPN-GAN large (124M\nparameters). For evaluation, we use five different datasets, covering both\nspeech synthesis and music generation tasks, to demonstrate the efficiency of\nthe DPN-GAN. The experimental results demonstrate that DPN-GAN delivers\nsuperior performance on both out-of-distribution and noisy data, showcasing its\nrobustness and adaptability. Trained across various datasets, DPN-GAN\noutperforms state-of-the-art GAN architectures on standard evaluation metrics,\nand exhibits increased robustness in synthesized audio."}
{"id": "2505.09075", "pdf": "https://arxiv.org/pdf/2505.09075", "abs": "https://arxiv.org/abs/2505.09075", "authors": ["Carlos Misael Madrid Padilla", "Oscar Hernan Madrid Padilla", "Sabyasachi Chatterjee"], "title": "Risk Bounds For Distributional Regression", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "This work examines risk bounds for nonparametric distributional regression\nestimators. For convex-constrained distributional regression, general upper\nbounds are established for the continuous ranked probability score (CRPS) and\nthe worst-case mean squared error (MSE) across the domain. These theoretical\nresults are applied to isotonic and trend filtering distributional regression,\nyielding convergence rates consistent with those for mean estimation.\nFurthermore, a general upper bound is derived for distributional regression\nunder non-convex constraints, with a specific application to neural\nnetwork-based estimators. Comprehensive experiments on both simulated and real\ndata validate the theoretical contributions, demonstrating their practical\neffectiveness."}
{"id": "2505.09343", "pdf": "https://arxiv.org/pdf/2505.09343", "abs": "https://arxiv.org/abs/2505.09343", "authors": ["Chenggang Zhao", "Chengqi Deng", "Chong Ruan", "Damai Dai", "Huazuo Gao", "Jiashi Li", "Liyue Zhang", "Panpan Huang", "Shangyan Zhou", "Shirong Ma", "Wenfeng Liang", "Ying He", "Yuqing Wang", "Yuxuan Liu", "Y. X. Wei"], "title": "Insights into DeepSeek-V3: Scaling Challenges and Reflections on Hardware for AI Architectures", "categories": ["cs.DC", "cs.AI", "cs.AR"], "comment": "This is the author's version of the work. It is posted here for your\n  personal use. Not for redistribution. The definitive version will appear as\n  part of the Industry Track in Proceedings of the 52nd Annual International\n  Symposium on Computer Architecture (ISCA '25)", "summary": "The rapid scaling of large language models (LLMs) has unveiled critical\nlimitations in current hardware architectures, including constraints in memory\ncapacity, computational efficiency, and interconnection bandwidth. DeepSeek-V3,\ntrained on 2,048 NVIDIA H800 GPUs, demonstrates how hardware-aware model\nco-design can effectively address these challenges, enabling cost-efficient\ntraining and inference at scale. This paper presents an in-depth analysis of\nthe DeepSeek-V3/R1 model architecture and its AI infrastructure, highlighting\nkey innovations such as Multi-head Latent Attention (MLA) for enhanced memory\nefficiency, Mixture of Experts (MoE) architectures for optimized\ncomputation-communication trade-offs, FP8 mixed-precision training to unlock\nthe full potential of hardware capabilities, and a Multi-Plane Network Topology\nto minimize cluster-level network overhead. Building on the hardware\nbottlenecks encountered during DeepSeek-V3's development, we engage in a\nbroader discussion with academic and industry peers on potential future\nhardware directions, including precise low-precision computation units,\nscale-up and scale-out convergence, and innovations in low-latency\ncommunication fabrics. These insights underscore the critical role of hardware\nand model co-design in meeting the escalating demands of AI workloads, offering\na practical blueprint for innovation in next-generation AI systems."}
{"id": "2505.09109", "pdf": "https://arxiv.org/pdf/2505.09109", "abs": "https://arxiv.org/abs/2505.09109", "authors": ["Yuxing Chen", "Bowen Xiao", "He Wang"], "title": "FoldNet: Learning Generalizable Closed-Loop Policy for Garment Folding via Keypoint-Driven Asset and Demonstration Synthesis", "categories": ["cs.RO", "cs.CV"], "comment": null, "summary": "Due to the deformability of garments, generating a large amount of\nhigh-quality data for robotic garment manipulation tasks is highly challenging.\nIn this paper, we present a synthetic garment dataset that can be used for\nrobotic garment folding. We begin by constructing geometric garment templates\nbased on keypoints and applying generative models to generate realistic texture\npatterns. Leveraging these keypoint annotations, we generate folding\ndemonstrations in simulation and train folding policies via closed-loop\nimitation learning. To improve robustness, we propose KG-DAgger, which uses a\nkeypoint-based strategy to generate demonstration data for recovering from\nfailures. KG-DAgger significantly improves the model performance, boosting the\nreal-world success rate by 25\\%. After training with 15K trajectories (about 2M\nimage-action pairs), the model achieves a 75\\% success rate in the real world.\nExperiments in both simulation and real-world settings validate the\neffectiveness of our proposed framework."}
{"id": "2505.09087", "pdf": "https://arxiv.org/pdf/2505.09087", "abs": "https://arxiv.org/abs/2505.09087", "authors": ["He Wang", "Yikun Zhang", "Jie Chen", "Jian Zhan", "Yaoqi Zhou"], "title": "A Comparative Review of RNA Language Models", "categories": ["q-bio.BM", "cs.LG"], "comment": null, "summary": "Given usefulness of protein language models (LMs) in structure and functional\ninference, RNA LMs have received increased attentions in the last few years.\nHowever, these RNA models are often not compared against the same standard.\nHere, we divided RNA LMs into three classes (pretrained on multiple RNA types\n(especially noncoding RNAs), specific-purpose RNAs, and LMs that unify RNA with\nDNA or proteins or both) and compared 13 RNA LMs along with 3 DNA and 1 protein\nLMs as controls in zero-shot prediction of RNA secondary structure and\nfunctional classification. Results shows that the models doing well on\nsecondary structure prediction often perform worse in function classification\nor vice versa, suggesting that more balanced unsupervised training is needed."}
{"id": "2505.09344", "pdf": "https://arxiv.org/pdf/2505.09344", "abs": "https://arxiv.org/abs/2505.09344", "authors": ["Gabriel Cortês", "Nuno Lourenço", "Paolo Romano", "Penousal Machado"], "title": "GreenFactory: Ensembling Zero-Cost Proxies to Estimate Performance of Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Determining the performance of a Deep Neural Network during Neural\nArchitecture Search processes is essential for identifying optimal\narchitectures and hyperparameters. Traditionally, this process requires\ntraining and evaluation of each network, which is time-consuming and\nresource-intensive. Zero-cost proxies estimate performance without training,\nserving as an alternative to traditional training. However, recent proxies\noften lack generalization across diverse scenarios and provide only relative\nrankings rather than predicted accuracies. To address these limitations, we\npropose GreenFactory, an ensemble of zero-cost proxies that leverages a random\nforest regressor to combine multiple predictors' strengths and directly predict\nmodel test accuracy. We evaluate GreenFactory on NATS-Bench, achieving robust\nresults across multiple datasets. Specifically, GreenFactory achieves high\nKendall correlations on NATS-Bench-SSS, indicating substantial agreement\nbetween its predicted scores and actual performance: 0.907 for CIFAR-10, 0.945\nfor CIFAR-100, and 0.920 for ImageNet-16-120. Similarly, on NATS-Bench-TSS, we\nachieve correlations of 0.921 for CIFAR-10, 0.929 for CIFAR-100, and 0.908 for\nImageNet-16-120, showcasing its reliability in both search spaces."}
{"id": "2505.09175", "pdf": "https://arxiv.org/pdf/2505.09175", "abs": "https://arxiv.org/abs/2505.09175", "authors": ["Mohammad Ganjirad", "Mahmoud Reza Delavar", "Hossein Bagheri", "Mohammad Mehdi Azizi"], "title": "Optimizing Urban Critical Green Space Development Using Machine Learning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "This paper presents a novel framework for prioritizing urban green space\ndevelopment in Tehran using diverse socio-economic, environmental, and\nsensitivity indices. The indices were derived from various sources including\nGoogle Earth Engine, air pollution measurements, municipal reports and the\nWeather Research & Forecasting (WRF) model. The WRF model was used to estimate\nthe air temperature at a 1 km resolution due to insufficient meteorological\nstations, yielding RMSE and MAE values of 0.96{\\deg}C and 0.92{\\deg}C,\nrespectively. After data preparation, several machine learning models were used\nfor binary vegetation cover classification including XGBoost, LightGBM, Random\nForest (RF) and Extra Trees. RF achieved the highest performance, exceeding 94%\nin Overall Accuracy, Recall, and F1-score. Then, the probability of areas\nlacking vegetation cover was assessed using socio-economic, environmental and\nsensitivity indices. This resulted in the RF generating an urban green space\ndevelopment prioritization map. Feature Importance Analysis revealed that the\nmost significant indices were nightly land surface temperature (LST) and\nsensitive population. Finally, the framework performance was validated through\nmicroclimate simulation to assess the critical areas after and before the green\nspace development by green roofs. The simulation demonstrated reducing air\ntemperature by up to 0.67{\\deg}C after utilizing the green roof technology in\ncritical areas. As a result, this framework provides a valuable tool for urban\nplanners to develop green spaces."}
{"id": "2505.09091", "pdf": "https://arxiv.org/pdf/2505.09091", "abs": "https://arxiv.org/abs/2505.09091", "authors": ["Zeeshan Ahmad", "Shudi Bao", "Meng Chen"], "title": "DPN-GAN: Inducing Periodic Activations in Generative Adversarial Networks for High-Fidelity Audio Synthesis", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "comment": null, "summary": "In recent years, generative adversarial networks (GANs) have made significant\nprogress in generating audio sequences. However, these models typically rely on\nbandwidth-limited mel-spectrograms, which constrain the resolution of generated\naudio sequences, and lead to mode collapse during conditional generation. To\naddress this issue, we propose Deformable Periodic Network based GAN (DPN-GAN),\na novel GAN architecture that incorporates a kernel-based periodic ReLU\nactivation function to induce periodic bias in audio generation. This\ninnovative approach enhances the model's ability to capture and reproduce\nintricate audio patterns. In particular, our proposed model features a DPN\nmodule for multi-resolution generation utilizing deformable convolution\noperations, allowing for adaptive receptive fields that improve the quality and\nfidelity of the synthetic audio. Additionally, we enhance the discriminator\nnetwork using deformable convolution to better distinguish between real and\ngenerated samples, further refining the audio quality. We trained two versions\nof the model: DPN-GAN small (38.67M parameters) and DPN-GAN large (124M\nparameters). For evaluation, we use five different datasets, covering both\nspeech synthesis and music generation tasks, to demonstrate the efficiency of\nthe DPN-GAN. The experimental results demonstrate that DPN-GAN delivers\nsuperior performance on both out-of-distribution and noisy data, showcasing its\nrobustness and adaptability. Trained across various datasets, DPN-GAN\noutperforms state-of-the-art GAN architectures on standard evaluation metrics,\nand exhibits increased robustness in synthesized audio."}
{"id": "2505.09371", "pdf": "https://arxiv.org/pdf/2505.09371", "abs": "https://arxiv.org/abs/2505.09371", "authors": ["Akash Kundu", "Stefano Mangini"], "title": "TensorRL-QAS: Reinforcement learning with tensor networks for scalable quantum architecture search", "categories": ["quant-ph", "cs.AI", "cs.ET", "cs.LG"], "comment": "The code will be available soon! Comments are welcomed!", "summary": "Variational quantum algorithms hold the promise to address meaningful quantum\nproblems already on noisy intermediate-scale quantum hardware, but they face\nthe challenge of designing quantum circuits that both solve the target problem\nand comply with device limitations. Quantum architecture search (QAS) automates\nthis design process, with reinforcement learning (RL) emerging as a promising\napproach. Yet, RL-based QAS methods encounter significant scalability issues,\nas computational and training costs grow rapidly with the number of qubits,\ncircuit depth, and noise, severely impacting performance. To address these\nchallenges, we introduce $\\textit{TensorRL-QAS}$, a scalable framework that\ncombines tensor network (TN) methods with RL for designing quantum circuits. By\nwarm-starting the architecture search with a matrix product state approximation\nof the target solution, TensorRL-QAS effectively narrows the search space to\nphysically meaningful circuits, accelerating convergence to the desired\nsolution. Tested on several quantum chemistry problems of up to 12-qubit,\nTensorRL-QAS achieves up to a 10-fold reduction in CNOT count and circuit depth\ncompared to baseline methods, while maintaining or surpassing chemical\naccuracy. It reduces function evaluations by up to 100-fold, accelerates\ntraining episodes by up to $98\\%$, and achieves up to $50\\%$ success\nprobability for 10-qubit systems-far exceeding the $<1\\%$ rates of baseline\napproaches. Robustness and versatility are demonstrated both in the noiseless\nand noisy scenarios, where we report a simulation of up to 8-qubit. These\nadvancements establish TensorRL-QAS as a promising candidate for a scalable and\nefficient quantum circuit discovery protocol on near-term quantum hardware."}
{"id": "2505.09193", "pdf": "https://arxiv.org/pdf/2505.09193", "abs": "https://arxiv.org/abs/2505.09193", "authors": ["Wei Jiang", "Junru Li", "Kai Zhang", "Li Zhang"], "title": "BiECVC: Gated Diversification of Bidirectional Contexts for Learned Video Compression", "categories": ["eess.IV", "cs.CV"], "comment": "The first learned video codec that surpasses VTM 13.2 RA across all\n  standard test datasets. Code will be available at\n  https://github.com/JiangWeibeta/ECVC", "summary": "Recent forward prediction-based learned video compression (LVC) methods have\nachieved impressive results, even surpassing VVC reference software VTM under\nthe Low Delay B (LDB) configuration. In contrast, learned bidirectional video\ncompression (BVC) remains underexplored and still lags behind its forward-only\ncounterparts. This performance gap is mainly due to the limited ability to\nextract diverse and accurate contexts: most existing BVCs primarily exploit\ntemporal motion while neglecting non-local correlations across frames.\nMoreover, they lack the adaptability to dynamically suppress harmful contexts\narising from fast motion or occlusion. To tackle these challenges, we propose\nBiECVC, a BVC framework that incorporates diversified local and non-local\ncontext modeling along with adaptive context gating. For local context\nenhancement, BiECVC reuses high-quality features from lower layers and aligns\nthem using decoded motion vectors without introducing extra motion overhead. To\nmodel non-local dependencies efficiently, we adopt a linear attention mechanism\nthat balances performance and complexity. To further mitigate the impact of\ninaccurate context prediction, we introduce Bidirectional Context Gating,\ninspired by data-dependent decay in recent autoregressive language models, to\ndynamically filter contextual information based on conditional coding results.\nExtensive experiments demonstrate that BiECVC achieves state-of-the-art\nperformance, reducing the bit-rate by 13.4% and 15.7% compared to VTM 13.2\nunder the Random Access (RA) configuration with intra periods of 32 and 64,\nrespectively. To our knowledge, BiECVC is the first learned video codec to\nsurpass VTM 13.2 RA across all standard test datasets. Code will be available\nat https://github.com/JiangWeibeta/ECVC."}
{"id": "2505.09098", "pdf": "https://arxiv.org/pdf/2505.09098", "abs": "https://arxiv.org/abs/2505.09098", "authors": ["Yan Hao Ling", "Zhouhao Yang", "Jonathan Scarlett"], "title": "Statistical Mean Estimation with Coded Relayed Observations", "categories": ["cs.IT", "cs.LG", "math.IT", "math.ST", "stat.TH"], "comment": null, "summary": "We consider a problem of statistical mean estimation in which the samples are\nnot observed directly, but are instead observed by a relay (``teacher'') that\ntransmits information through a memoryless channel to the decoder\n(``student''), who then produces the final estimate. We consider the minimax\nestimation error in the large deviations regime, and establish achievable error\nexponents that are tight in broad regimes of the estimation accuracy and\nchannel quality. In contrast, two natural baseline methods are shown to yield\nstrictly suboptimal error exponents. We initially focus on Bernoulli sources\nand binary symmetric channels, and then generalize to sub-Gaussian and\nheavy-tailed settings along with arbitrary discrete memoryless channels."}
{"id": "2505.09380", "pdf": "https://arxiv.org/pdf/2505.09380", "abs": "https://arxiv.org/abs/2505.09380", "authors": ["Qinghui Liu", "Jon Nesvold", "Hanna Raaum", "Elakkyen Murugesu", "Martin Røvang", "Bradley J Maclntosh", "Atle Bjørnerud", "Karoline Skogen"], "title": "Examining Deployment and Refinement of the VIOLA-AI Intracranial Hemorrhage Model Using an Interactive NeoMedSys Platform", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "19 pages, 11 figures, on submission to BMC Methods", "summary": "Background: There are many challenges and opportunities in the clinical\ndeployment of AI tools in radiology. The current study describes a radiology\nsoftware platform called NeoMedSys that can enable efficient deployment and\nrefinements of AI models. We evaluated the feasibility and effectiveness of\nrunning NeoMedSys for three months in real-world clinical settings and focused\non improvement performance of an in-house developed AI model (VIOLA-AI)\ndesigned for intracranial hemorrhage (ICH) detection.\n  Methods: NeoMedSys integrates tools for deploying, testing, and optimizing AI\nmodels with a web-based medical image viewer, annotation system, and\nhospital-wide radiology information systems. A pragmatic investigation was\ndeployed using clinical cases of patients presenting to the largest Emergency\nDepartment in Norway (site-1) with suspected traumatic brain injury (TBI) or\npatients with suspected stroke (site-2). We assessed ICH classification\nperformance as VIOLA-AI encountered new data and underwent pre-planned model\nretraining. Performance metrics included sensitivity, specificity, accuracy,\nand the area under the receiver operating characteristic curve (AUC).\n  Results: NeoMedSys facilitated iterative improvements in the AI model,\nsignificantly enhancing its diagnostic accuracy. Automated bleed detection and\nsegmentation were reviewed in near real-time to facilitate re-training\nVIOLA-AI. The iterative refinement process yielded a marked improvement in\nclassification sensitivity, rising to 90.3% (from 79.2%), and specificity that\nreached 89.3% (from 80.7%). The bleed detection ROC analysis for the entire\nsample demonstrated a high area-under-the-curve (AUC) of 0.949 (from 0.873).\nModel refinement stages were associated with notable gains, highlighting the\nvalue of real-time radiologist feedback."}
{"id": "2505.09262", "pdf": "https://arxiv.org/pdf/2505.09262", "abs": "https://arxiv.org/abs/2505.09262", "authors": ["Hongxin Xiang", "Ke Li", "Mingquan Liu", "Zhixiang Cheng", "Bin Yao", "Wenjie Du", "Jun Xia", "Li Zeng", "Xin Jin", "Xiangxiang Zeng"], "title": "EDBench: Large-Scale Electron Density Data for Molecular Modeling", "categories": ["physics.chem-ph", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Existing molecular machine learning force fields (MLFFs) generally focus on\nthe learning of atoms, molecules, and simple quantum chemical properties (such\nas energy and force), but ignore the importance of electron density (ED)\n$\\rho(r)$ in accurately understanding molecular force fields (MFFs). ED\ndescribes the probability of finding electrons at specific locations around\natoms or molecules, which uniquely determines all ground state properties (such\nas energy, molecular structure, etc.) of interactive multi-particle systems\naccording to the Hohenberg-Kohn theorem. However, the calculation of ED relies\non the time-consuming first-principles density functional theory (DFT) which\nleads to the lack of large-scale ED data and limits its application in MLFFs.\nIn this paper, we introduce EDBench, a large-scale, high-quality dataset of ED\ndesigned to advance learning-based research at the electronic scale. Built upon\nthe PCQM4Mv2, EDBench provides accurate ED data, covering 3.3 million\nmolecules. To comprehensively evaluate the ability of models to understand and\nutilize electronic information, we design a suite of ED-centric benchmark tasks\nspanning prediction, retrieval, and generation. Our evaluation on several\nstate-of-the-art methods demonstrates that learning from EDBench is not only\nfeasible but also achieves high accuracy. Moreover, we show that learning-based\nmethod can efficiently calculate ED with comparable precision while\nsignificantly reducing the computational cost relative to traditional DFT\ncalculations. All data and benchmarks from EDBench will be freely available,\nlaying a robust foundation for ED-driven drug discovery and materials science."}
{"id": "2505.09099", "pdf": "https://arxiv.org/pdf/2505.09099", "abs": "https://arxiv.org/abs/2505.09099", "authors": ["Shirui Lyu", "Vittorio Caggiano", "Matteo Leonetti", "Dario Farina", "Letizia Gionfrida"], "title": "Imitation Learning for Adaptive Control of a Virtual Soft Exoglove", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "The use of wearable robots has been widely adopted in rehabilitation training\nfor patients with hand motor impairments. However, the uniqueness of patients'\nmuscle loss is often overlooked. Leveraging reinforcement learning and a\nbiologically accurate musculoskeletal model in simulation, we propose a\ncustomized wearable robotic controller that is able to address specific muscle\ndeficits and to provide compensation for hand-object manipulation tasks. Video\ndata of a same subject performing human grasping tasks is used to train a\nmanipulation model through learning from demonstration. This manipulation model\nis subsequently fine-tuned to perform object-specific interaction tasks. The\nmuscle forces in the musculoskeletal manipulation model are then weakened to\nsimulate neurological motor impairments, which are later compensated by the\nactuation of a virtual wearable robotics glove. Results shows that integrating\nthe virtual wearable robotic glove provides shared assistance to support the\nhand manipulator with weakened muscle forces. The learned exoglove controller\nachieved an average of 90.5\\% of the original manipulation proficiency."}
{"id": "2505.09382", "pdf": "https://arxiv.org/pdf/2505.09382", "abs": "https://arxiv.org/abs/2505.09382", "authors": ["Zhengyan Sheng", "Jinghao He", "Liping Chen", "Kong Aik Lee", "Zhen-Hua Ling"], "title": "The Voice Timbre Attribute Detection 2025 Challenge Evaluation Plan", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Voice timbre refers to the unique quality or character of a person's voice\nthat distinguishes it from others as perceived by human hearing. The Voice\nTimbre Attribute Detection (VtaD) 2025 challenge focuses on explaining the\nvoice timbre attribute in a comparative manner. In this challenge, the human\nimpression of voice timbre is verbalized with a set of sensory descriptors,\nincluding bright, coarse, soft, magnetic, and so on. The timbre is explained\nfrom the comparison between two voices in their intensity within a specific\ndescriptor dimension. The VtaD 2025 challenge starts in May and culminates in a\nspecial proposal at the NCMMSC2025 conference in October 2025 in Zhenjiang,\nChina."}
{"id": "2505.09315", "pdf": "https://arxiv.org/pdf/2505.09315", "abs": "https://arxiv.org/abs/2505.09315", "authors": ["Xuefeng Jiang", "Yuan Ma", "Pengxiang Li", "Leimeng Xu", "Xin Wen", "Kun Zhan", "Zhongpu Xia", "Peng Jia", "XianPeng Lang", "Sheng Sun"], "title": "TransDiffuser: End-to-end Trajectory Generation with Decorrelated Multi-modal Representation for Autonomous Driving", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "Under review", "summary": "In recent years, diffusion model has shown its potential across diverse\ndomains from vision generation to language modeling. Transferring its\ncapabilities to modern autonomous driving systems has also emerged as a\npromising direction.In this work, we propose TransDiffuser, an encoder-decoder\nbased generative trajectory planning model for end-to-end autonomous driving.\nThe encoded scene information serves as the multi-modal conditional input of\nthe denoising decoder. To tackle the mode collapse dilemma in generating\nhigh-quality diverse trajectories, we introduce a simple yet effective\nmulti-modal representation decorrelation optimization mechanism during the\ntraining process.TransDiffuser achieves PDMS of 94.85 on the NAVSIM benchmark,\nsurpassing previous state-of-the-art methods without any anchor-based prior\ntrajectories."}
{"id": "2505.09110", "pdf": "https://arxiv.org/pdf/2505.09110", "abs": "https://arxiv.org/abs/2505.09110", "authors": ["Zhihao Dou", "Jiaqi Wang", "Wei Sun", "Zhuqing Liu", "Minghong Fang"], "title": "Toward Malicious Clients Detection in Federated Learning", "categories": ["cs.CR", "cs.DC", "cs.LG"], "comment": "To appear in ACM ASIACCS 2025", "summary": "Federated learning (FL) enables multiple clients to collaboratively train a\nglobal machine learning model without sharing their raw data. However, the\ndecentralized nature of FL introduces vulnerabilities, particularly to\npoisoning attacks, where malicious clients manipulate their local models to\ndisrupt the training process. While Byzantine-robust aggregation rules have\nbeen developed to mitigate such attacks, they remain inadequate against more\nadvanced threats. In response, recent advancements have focused on FL detection\ntechniques to identify potentially malicious participants. Unfortunately, these\nmethods often misclassify numerous benign clients as threats or rely on\nunrealistic assumptions about the server's capabilities. In this paper, we\npropose a novel algorithm, SafeFL, specifically designed to accurately identify\nmalicious clients in FL. The SafeFL approach involves the server collecting a\nseries of global models to generate a synthetic dataset, which is then used to\ndistinguish between malicious and benign models based on their behavior.\nExtensive testing demonstrates that SafeFL outperforms existing methods,\noffering superior efficiency and accuracy in detecting malicious clients."}
{"id": "2505.09385", "pdf": "https://arxiv.org/pdf/2505.09385", "abs": "https://arxiv.org/abs/2505.09385", "authors": ["Xiaoyang Yu", "Xiaoming Wu", "Xin Wang", "Dongrun Li", "Ming Yang", "Peng Cheng"], "title": "FedSaaS: Class-Consistency Federated Semantic Segmentation via Global Prototype Supervision and Local Adversarial Harmonization", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Federated semantic segmentation enables pixel-level classification in images\nthrough collaborative learning while maintaining data privacy. However,\nexisting research commonly overlooks the fine-grained class relationships\nwithin the semantic space when addressing heterogeneous problems, particularly\ndomain shift. This oversight results in ambiguities between class\nrepresentation. To overcome this challenge, we propose a novel federated\nsegmentation framework that strikes class consistency, termed FedSaaS.\nSpecifically, we introduce class exemplars as a criterion for both local- and\nglobal-level class representations. On the server side, the uploaded class\nexemplars are leveraged to model class prototypes, which supervise global\nbranch of clients, ensuring alignment with global-level representation. On the\nclient side, we incorporate an adversarial mechanism to harmonize contributions\nof global and local branches, leading to consistent output. Moreover,\nmultilevel contrastive losses are employed on both sides to enforce consistency\nbetween two-level representations in the same semantic space. Extensive\nexperiments on several driving scene segmentation datasets demonstrate that our\nframework outperforms state-of-the-art methods, significantly improving average\nsegmentation accuracy and effectively addressing the class-consistency\nrepresentation problem."}
{"id": "2505.09323", "pdf": "https://arxiv.org/pdf/2505.09323", "abs": "https://arxiv.org/abs/2505.09323", "authors": ["Pengli Zhu", "Yingji Fu", "Nanguang Chen", "Anqi Qiu"], "title": "Q-space Guided Collaborative Attention Translation Network for Flexible Diffusion-Weighted Images Synthesis", "categories": ["eess.IV", "cs.CV"], "comment": "MICCAI 2025", "summary": "This study, we propose a novel Q-space Guided Collaborative Attention\nTranslation Networks (Q-CATN) for multi-shell, high-angular resolution DWI\n(MS-HARDI) synthesis from flexible q-space sampling, leveraging the commonly\nacquired structural MRI data. Q-CATN employs a collaborative attention\nmechanism to effectively extract complementary information from multiple\nmodalities and dynamically adjust its internal representations based on\nflexible q-space information, eliminating the need for fixed sampling schemes.\nAdditionally, we introduce a range of task-specific constraints to preserve\nanatomical fidelity in DWI, enabling Q-CATN to accurately learn the intrinsic\nrelationships between directional DWI signal distributions and q-space.\nExtensive experiments on the Human Connectome Project (HCP) dataset demonstrate\nthat Q-CATN outperforms existing methods, including 1D-qDL, 2D-qDL, MESC-SD,\nand QGAN, in estimating parameter maps and fiber tracts both quantitatively and\nqualitatively, while preserving fine-grained details. Notably, its ability to\naccommodate flexible q-space sampling highlights its potential as a promising\ntoolkit for clinical and research applications. Our code is available at\nhttps://github.com/Idea89560041/Q-CATN."}
{"id": "2505.09114", "pdf": "https://arxiv.org/pdf/2505.09114", "abs": "https://arxiv.org/abs/2505.09114", "authors": ["Minh Hoang Nguyen", "Linh Le Pham Van", "Thommen George Karimpanal", "Sunil Gupta", "Hung Le"], "title": "Beyond the Known: Decision Making with Counterfactual Reasoning Decision Transformer", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Decision Transformers (DT) play a crucial role in modern reinforcement\nlearning, leveraging offline datasets to achieve impressive results across\nvarious domains. However, DT requires high-quality, comprehensive data to\nperform optimally. In real-world applications, the lack of training data and\nthe scarcity of optimal behaviours make training on offline datasets\nchallenging, as suboptimal data can hinder performance. To address this, we\npropose the Counterfactual Reasoning Decision Transformer (CRDT), a novel\nframework inspired by counterfactual reasoning. CRDT enhances DT ability to\nreason beyond known data by generating and utilizing counterfactual\nexperiences, enabling improved decision-making in unseen scenarios. Experiments\nacross Atari and D4RL benchmarks, including scenarios with limited data and\naltered dynamics, demonstrate that CRDT outperforms conventional DT approaches.\nAdditionally, reasoning counterfactually allows the DT agent to obtain\nstitching abilities, combining suboptimal trajectories, without architectural\nmodifications. These results highlight the potential of counterfactual\nreasoning to enhance reinforcement learning agents' performance and\ngeneralization capabilities."}
{"id": "2505.09393", "pdf": "https://arxiv.org/pdf/2505.09393", "abs": "https://arxiv.org/abs/2505.09393", "authors": ["Huakun Liu", "Hiroki Ota", "Xin Wei", "Yutaro Hirao", "Monica Perusquia-Hernandez", "Hideaki Uchiyama", "Kiyoshi Kiyokawa"], "title": "UMotion: Uncertainty-driven Human Motion Estimation from Inertial and Ultra-wideband Units", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "Accepted by CVPR 2025", "summary": "Sparse wearable inertial measurement units (IMUs) have gained popularity for\nestimating 3D human motion. However, challenges such as pose ambiguity, data\ndrift, and limited adaptability to diverse bodies persist. To address these\nissues, we propose UMotion, an uncertainty-driven, online fusing-all state\nestimation framework for 3D human shape and pose estimation, supported by six\nintegrated, body-worn ultra-wideband (UWB) distance sensors with IMUs. UWB\nsensors measure inter-node distances to infer spatial relationships, aiding in\nresolving pose ambiguities and body shape variations when combined with\nanthropometric data. Unfortunately, IMUs are prone to drift, and UWB sensors\nare affected by body occlusions. Consequently, we develop a tightly coupled\nUnscented Kalman Filter (UKF) framework that fuses uncertainties from sensor\ndata and estimated human motion based on individual body shape. The UKF\niteratively refines IMU and UWB measurements by aligning them with uncertain\nhuman motion constraints in real-time, producing optimal estimates for each.\nExperiments on both synthetic and real-world datasets demonstrate the\neffectiveness of UMotion in stabilizing sensor data and the improvement over\nstate of the art in pose accuracy."}
{"id": "2505.09334", "pdf": "https://arxiv.org/pdf/2505.09334", "abs": "https://arxiv.org/abs/2505.09334", "authors": ["Sadman Sakib Alif", "Nasim Anzum Promise", "Fiaz Al Abid", "Aniqua Nusrat Zereen"], "title": "DCSNet: A Lightweight Knowledge Distillation-Based Model with Explainable AI for Lung Cancer Diagnosis from Histopathological Images", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Lung cancer is a leading cause of cancer-related deaths globally, where early\ndetection and accurate diagnosis are critical for improving survival rates.\nWhile deep learning, particularly convolutional neural networks (CNNs), has\nrevolutionized medical image analysis by detecting subtle patterns indicative\nof early-stage lung cancer, its adoption faces challenges. These models are\noften computationally expensive and require significant resources, making them\nunsuitable for resource constrained environments. Additionally, their lack of\ntransparency hinders trust and broader adoption in sensitive fields like\nhealthcare. Knowledge distillation addresses these challenges by transferring\nknowledge from large, complex models (teachers) to smaller, lightweight models\n(students). We propose a knowledge distillation-based approach for lung cancer\ndetection, incorporating explainable AI (XAI) techniques to enhance model\ntransparency. Eight CNNs, including ResNet50, EfficientNetB0, EfficientNetB3,\nand VGG16, are evaluated as teacher models. We developed and trained a\nlightweight student model, Distilled Custom Student Network (DCSNet) using\nResNet50 as the teacher. This approach not only ensures high diagnostic\nperformance in resource-constrained settings but also addresses transparency\nconcerns, facilitating the adoption of AI-driven diagnostic tools in\nhealthcare."}
{"id": "2505.09142", "pdf": "https://arxiv.org/pdf/2505.09142", "abs": "https://arxiv.org/abs/2505.09142", "authors": ["Seungbeom Choi", "Jeonghoe Goo", "Eunjoo Jeon", "Mingyu Yang", "Minsung Jang"], "title": "ELIS: Efficient LLM Iterative Scheduling System with Response Length Predictor", "categories": ["cs.DC", "cs.AI", "cs.LG"], "comment": "13 pages, 5 figures. Cloud-native LLM scheduling system with\n  latency-aware inference optimization", "summary": "We propose ELIS, a serving system for Large Language Models (LLMs) featuring\nan Iterative Shortest Remaining Time First (ISRTF) scheduler designed to\nefficiently manage inference tasks with the shortest remaining tokens. Current\nLLM serving systems often employ a first-come-first-served scheduling strategy,\nwhich can lead to the \"head-of-line blocking\" problem. To overcome this\nlimitation, it is necessary to predict LLM inference times and apply a shortest\njob first scheduling strategy. However, due to the auto-regressive nature of\nLLMs, predicting the inference latency is challenging. ELIS addresses this\nchallenge by training a response length predictor for LLMs using the BGE model,\nan encoder-based state-of-the-art model. Additionally, we have devised the\nISRTF scheduling strategy, an optimization of shortest remaining time first\ntailored to existing LLM iteration batching. To evaluate our work in an\nindustrial setting, we simulate streams of requests based on our study of\nreal-world user LLM serving trace records. Furthermore, we implemented ELIS as\na cloud-native scheduler system on Kubernetes to evaluate its performance in\nproduction environments. Our experimental results demonstrate that ISRTF\nreduces the average job completion time by up to 19.6%."}
{"id": "2505.09395", "pdf": "https://arxiv.org/pdf/2505.09395", "abs": "https://arxiv.org/abs/2505.09395", "authors": ["Chen-Yu Liu", "Kuan-Cheng Chen", "Yi-Chien Chen", "Samuel Yen-Chi Chen", "Wei-Hao Huang", "Wei-Jia Huang", "Yen-Jui Chang"], "title": "Quantum-Enhanced Parameter-Efficient Learning for Typhoon Trajectory Forecasting", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Typhoon trajectory forecasting is essential for disaster preparedness but\nremains computationally demanding due to the complexity of atmospheric dynamics\nand the resource requirements of deep learning models. Quantum-Train (QT), a\nhybrid quantum-classical framework that leverages quantum neural networks\n(QNNs) to generate trainable parameters exclusively during training,\neliminating the need for quantum hardware at inference time. Building on QT's\nsuccess across multiple domains, including image classification, reinforcement\nlearning, flood prediction, and large language model (LLM) fine-tuning, we\nintroduce Quantum Parameter Adaptation (QPA) for efficient typhoon forecasting\nmodel learning. Integrated with an Attention-based Multi-ConvGRU model, QPA\nenables parameter-efficient training while maintaining predictive accuracy.\nThis work represents the first application of quantum machine learning (QML) to\nlarge-scale typhoon trajectory prediction, offering a scalable and\nenergy-efficient approach to climate modeling. Our results demonstrate that QPA\nsignificantly reduces the number of trainable parameters while preserving\nperformance, making high-performance forecasting more accessible and\nsustainable through hybrid quantum-classical learning."}
{"id": "2505.09344", "pdf": "https://arxiv.org/pdf/2505.09344", "abs": "https://arxiv.org/abs/2505.09344", "authors": ["Gabriel Cortês", "Nuno Lourenço", "Paolo Romano", "Penousal Machado"], "title": "GreenFactory: Ensembling Zero-Cost Proxies to Estimate Performance of Neural Networks", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Determining the performance of a Deep Neural Network during Neural\nArchitecture Search processes is essential for identifying optimal\narchitectures and hyperparameters. Traditionally, this process requires\ntraining and evaluation of each network, which is time-consuming and\nresource-intensive. Zero-cost proxies estimate performance without training,\nserving as an alternative to traditional training. However, recent proxies\noften lack generalization across diverse scenarios and provide only relative\nrankings rather than predicted accuracies. To address these limitations, we\npropose GreenFactory, an ensemble of zero-cost proxies that leverages a random\nforest regressor to combine multiple predictors' strengths and directly predict\nmodel test accuracy. We evaluate GreenFactory on NATS-Bench, achieving robust\nresults across multiple datasets. Specifically, GreenFactory achieves high\nKendall correlations on NATS-Bench-SSS, indicating substantial agreement\nbetween its predicted scores and actual performance: 0.907 for CIFAR-10, 0.945\nfor CIFAR-100, and 0.920 for ImageNet-16-120. Similarly, on NATS-Bench-TSS, we\nachieve correlations of 0.921 for CIFAR-10, 0.929 for CIFAR-100, and 0.908 for\nImageNet-16-120, showcasing its reliability in both search spaces."}
{"id": "2505.09161", "pdf": "https://arxiv.org/pdf/2505.09161", "abs": "https://arxiv.org/abs/2505.09161", "authors": ["Yu Xin", "Peng Liu", "Zhuohang Xie", "Wenhui Mi", "Pengyue Gao", "Hong Jian Zhao", "Jian Lv", "Yanchao Wang", "Yanming Ma"], "title": "Bridging Theory and Experiment in Materials Discovery: Machine-Learning-Assisted Prediction of Synthesizable Structures", "categories": ["cond-mat.mtrl-sci", "cs.LG"], "comment": null, "summary": "Even though thermodynamic energy-based crystal structure prediction (CSP) has\nrevolutionized materials discovery, the energy-driven CSP approaches often\nstruggle to identify experimentally realizable metastable materials synthesized\nthrough kinetically controlled pathways, creating a critical gap between\ntheoretical predictions and experimental synthesis. Here, we propose a\nsynthesizability-driven CSP framework that integrates symmetry-guided structure\nderivation with a Wyckoff encode-based machine-learning model, allowing for the\nefficient localization of subspaces likely to yield highly synthesizable\nstructures. Within the identified promising subspaces, a structure-based\nsynthesizability evaluation model, fine-tuned using recently synthesized\nstructures to enhance predictive accuracy, is employed in conjunction with ab\ninitio calculations to systematically identify synthesizable candidates. The\nframework successfully reproduces 13 experimentally known XSe (X = Sc, Ti, Mn,\nFe, Ni, Cu, Zn) structures, demonstrating its effectiveness in predicting\nsynthesizable structures. Notably, 92,310 structures are filtered from the\n554,054 candidates predicted by GNoME, exhibiting great potential for promising\nsynthesizability. Additionally, eight thermodynamically favorable Hf-X-O (X =\nTi, V, and Mn) structures have been identified, among which three HfV$_2$O$_7$\ncandidates exhibit high synthesizability, presenting viable candidates for\nexperimental realization and potentially associated with experimentally\nobserved temperature-induced phase transitions. This work establishes a\ndata-driven paradigm for machine-learning-assisted inorganic materials\nsynthesis, highlighting its potential to bridge the gap between computational\npredictions and experimental realization while unlocking new opportunities for\nthe targeted discovery of novel functional materials."}
{"id": "2505.09407", "pdf": "https://arxiv.org/pdf/2505.09407", "abs": "https://arxiv.org/abs/2505.09407", "authors": ["Subrit Dikshit", "Ritu Tiwari", "Priyank Jain"], "title": "Multilingual Machine Translation with Quantum Encoder Decoder Attention-based Convolutional Variational Circuits", "categories": ["cs.CL", "cs.AI", "cs.ET"], "comment": "12 pages, 12 figures", "summary": "Cloud-based multilingual translation services like Google Translate and\nMicrosoft Translator achieve state-of-the-art translation capabilities. These\nservices inherently use large multilingual language models such as GRU, LSTM,\nBERT, GPT, T5, or similar encoder-decoder architectures with attention\nmechanisms as the backbone. Also, new age natural language systems, for\ninstance ChatGPT and DeepSeek, have established huge potential in multiple\ntasks in natural language processing. At the same time, they also possess\noutstanding multilingual translation capabilities. However, these models use\nthe classical computing realm as a backend. QEDACVC (Quantum Encoder Decoder\nAttention-based Convolutional Variational Circuits) is an alternate solution\nthat explores the quantum computing realm instead of the classical computing\nrealm to study and demonstrate multilingual machine translation. QEDACVC\nintroduces the quantum encoder-decoder architecture that simulates and runs on\nquantum computing hardware via quantum convolution, quantum pooling, quantum\nvariational circuit, and quantum attention as software alterations. QEDACVC\nachieves an Accuracy of 82% when trained on the OPUS dataset for English,\nFrench, German, and Hindi corpora for multilingual translations."}
{"id": "2505.09356", "pdf": "https://arxiv.org/pdf/2505.09356", "abs": "https://arxiv.org/abs/2505.09356", "authors": ["Srinivas Ravuri", "Yuan Xu", "Martin Ludwig Zehetner", "Ketan Motlag", "Sahin Albayrak"], "title": "APR-Transformer: Initial Pose Estimation for Localization in Complex Environments through Absolute Pose Regression", "categories": ["cs.RO", "cs.CV"], "comment": "8 pages with 6 figures", "summary": "Precise initialization plays a critical role in the performance of\nlocalization algorithms, especially in the context of robotics, autonomous\ndriving, and computer vision. Poor localization accuracy is often a consequence\nof inaccurate initial poses, particularly noticeable in GNSS-denied\nenvironments where GPS signals are primarily relied upon for initialization.\nRecent advances in leveraging deep neural networks for pose regression have led\nto significant improvements in both accuracy and robustness, especially in\nestimating complex spatial relationships and orientations. In this paper, we\nintroduce APR-Transformer, a model architecture inspired by state-of-the-art\nmethods, which predicts absolute pose (3D position and 3D orientation) using\neither image or LiDAR data. We demonstrate that our proposed method achieves\nstate-of-the-art performance on established benchmark datasets such as the\nRadar Oxford Robot-Car and DeepLoc datasets. Furthermore, we extend our\nexperiments to include our custom complex APR-BeIntelli dataset. Additionally,\nwe validate the reliability of our approach in GNSS-denied environments by\ndeploying the model in real-time on an autonomous test vehicle. This showcases\nthe practical feasibility and effectiveness of our approach. The source code is\navailable at:https://github.com/GT-ARC/APR-Transformer."}
{"id": "2505.09167", "pdf": "https://arxiv.org/pdf/2505.09167", "abs": "https://arxiv.org/abs/2505.09167", "authors": ["Amit Daniely", "Idan Mehalel", "Elchanan Mossel"], "title": "Online Learning of Neural Networks", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We study online learning of feedforward neural networks with the sign\nactivation function that implement functions from the unit ball in\n$\\mathbb{R}^d$ to a finite label set $\\{1, \\ldots, Y\\}$.\n  First, we characterize a margin condition that is sufficient and in some\ncases necessary for online learnability of a neural network: Every neuron in\nthe first hidden layer classifies all instances with some margin $\\gamma$\nbounded away from zero. Quantitatively, we prove that for any net, the optimal\nmistake bound is at most approximately $\\mathtt{TS}(d,\\gamma)$, which is the\n$(d,\\gamma)$-totally-separable-packing number, a more restricted variation of\nthe standard $(d,\\gamma)$-packing number. We complement this result by\nconstructing a net on which any learner makes $\\mathtt{TS}(d,\\gamma)$ many\nmistakes. We also give a quantitative lower bound of approximately\n$\\mathtt{TS}(d,\\gamma) \\geq \\max\\{1/(\\gamma \\sqrt{d})^d, d\\}$ when $\\gamma \\geq\n1/2$, implying that for some nets and input sequences every learner will err\nfor $\\exp(d)$ many times, and that a dimension-free mistake bound is almost\nalways impossible.\n  To remedy this inevitable dependence on $d$, it is natural to seek additional\nnatural restrictions to be placed on the network, so that the dependence on $d$\nis removed. We study two such restrictions. The first is the multi-index model,\nin which the function computed by the net depends only on $k \\ll d$ orthonormal\ndirections. We prove a mistake bound of approximately $(1.5/\\gamma)^{k + 2}$ in\nthis model. The second is the extended margin assumption. In this setting, we\nassume that all neurons (in all layers) in the network classify every ingoing\ninput from previous layer with margin $\\gamma$ bounded away from zero. In this\nmodel, we prove a mistake bound of approximately $(\\log Y)/ \\gamma^{O(L)}$,\nwhere L is the depth of the network."}
{"id": "2505.09435", "pdf": "https://arxiv.org/pdf/2505.09435", "abs": "https://arxiv.org/abs/2505.09435", "authors": ["Yili He", "Yan Zhu", "Peiyao Fu", "Ruijie Yang", "Tianyi Chen", "Zhihua Wang", "Quanlin Li", "Pinghong Zhou", "Xian Yang", "Shuo Wang"], "title": "Endo-CLIP: Progressive Self-Supervised Pre-training on Raw Colonoscopy Records", "categories": ["cs.CV", "cs.AI"], "comment": "Early accepted to MICCAI 2025", "summary": "Pre-training on image-text colonoscopy records offers substantial potential\nfor improving endoscopic image analysis, but faces challenges including\nnon-informative background images, complex medical terminology, and ambiguous\nmulti-lesion descriptions. We introduce Endo-CLIP, a novel self-supervised\nframework that enhances Contrastive Language-Image Pre-training (CLIP) for this\ndomain. Endo-CLIP's three-stage framework--cleansing, attunement, and\nunification--addresses these challenges by (1) removing background frames, (2)\nleveraging large language models to extract clinical attributes for\nfine-grained contrastive learning, and (3) employing patient-level\ncross-attention to resolve multi-polyp ambiguities. Extensive experiments\ndemonstrate that Endo-CLIP significantly outperforms state-of-the-art\npre-training methods in zero-shot and few-shot polyp detection and\nclassification, paving the way for more accurate and clinically relevant\nendoscopic analysis."}
{"id": "2505.09393", "pdf": "https://arxiv.org/pdf/2505.09393", "abs": "https://arxiv.org/abs/2505.09393", "authors": ["Huakun Liu", "Hiroki Ota", "Xin Wei", "Yutaro Hirao", "Monica Perusquia-Hernandez", "Hideaki Uchiyama", "Kiyoshi Kiyokawa"], "title": "UMotion: Uncertainty-driven Human Motion Estimation from Inertial and Ultra-wideband Units", "categories": ["cs.GR", "cs.AI", "cs.CV"], "comment": "Accepted by CVPR 2025", "summary": "Sparse wearable inertial measurement units (IMUs) have gained popularity for\nestimating 3D human motion. However, challenges such as pose ambiguity, data\ndrift, and limited adaptability to diverse bodies persist. To address these\nissues, we propose UMotion, an uncertainty-driven, online fusing-all state\nestimation framework for 3D human shape and pose estimation, supported by six\nintegrated, body-worn ultra-wideband (UWB) distance sensors with IMUs. UWB\nsensors measure inter-node distances to infer spatial relationships, aiding in\nresolving pose ambiguities and body shape variations when combined with\nanthropometric data. Unfortunately, IMUs are prone to drift, and UWB sensors\nare affected by body occlusions. Consequently, we develop a tightly coupled\nUnscented Kalman Filter (UKF) framework that fuses uncertainties from sensor\ndata and estimated human motion based on individual body shape. The UKF\niteratively refines IMU and UWB measurements by aligning them with uncertain\nhuman motion constraints in real-time, producing optimal estimates for each.\nExperiments on both synthetic and real-world datasets demonstrate the\neffectiveness of UMotion in stabilizing sensor data and the improvement over\nstate of the art in pose accuracy."}
{"id": "2505.09203", "pdf": "https://arxiv.org/pdf/2505.09203", "abs": "https://arxiv.org/abs/2505.09203", "authors": ["Xiao-Qi Han", "Peng-Jie Guo", "Ze-Feng Gao", "Hao Sun", "Zhong-Yi Lu"], "title": "InvDesFlow-AL: Active Learning-based Workflow for Inverse Design of Functional Materials", "categories": ["cond-mat.mtrl-sci", "cond-mat.supr-con", "cs.AI", "cs.LG"], "comment": "29 pages, 11 figures", "summary": "Developing inverse design methods for functional materials with specific\nproperties is critical to advancing fields like renewable energy, catalysis,\nenergy storage, and carbon capture. Generative models based on diffusion\nprinciples can directly produce new materials that meet performance\nconstraints, thereby significantly accelerating the material design process.\nHowever, existing methods for generating and predicting crystal structures\noften remain limited by low success rates. In this work, we propose a novel\ninverse material design generative framework called InvDesFlow-AL, which is\nbased on active learning strategies. This framework can iteratively optimize\nthe material generation process to gradually guide it towards desired\nperformance characteristics. In terms of crystal structure prediction, the\nInvDesFlow-AL model achieves an RMSE of 0.0423 {\\AA}, representing an 32.96%\nimprovement in performance compared to exsisting generative models.\nAdditionally, InvDesFlow-AL has been successfully validated in the design of\nlow-formation-energy and low-Ehull materials. It can systematically generate\nmaterials with progressively lower formation energies while continuously\nexpanding the exploration across diverse chemical spaces. These results fully\ndemonstrate the effectiveness of the proposed active learning-driven generative\nmodel in accelerating material discovery and inverse design. To further prove\nthe effectiveness of this method, we took the search for BCS superconductors\nunder ambient pressure as an example explored by InvDesFlow-AL. As a result, we\nsuccessfully identified Li\\(_2\\)AuH\\(_6\\) as a conventional BCS superconductor\nwith an ultra-high transition temperature of 140 K. This discovery provides\nstrong empirical support for the application of inverse design in materials\nscience."}
{"id": "2505.09436", "pdf": "https://arxiv.org/pdf/2505.09436", "abs": "https://arxiv.org/abs/2505.09436", "authors": ["Raghav Garg", "Kapil Sharma", "Karan Gupta"], "title": "CXMArena: Unified Dataset to benchmark performance in realistic CXM Scenarios", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "comment": null, "summary": "Large Language Models (LLMs) hold immense potential for revolutionizing\nCustomer Experience Management (CXM), particularly in contact center\noperations. However, evaluating their practical utility in complex operational\nenvironments is hindered by data scarcity (due to privacy concerns) and the\nlimitations of current benchmarks. Existing benchmarks often lack realism,\nfailing to incorporate deep knowledge base (KB) integration, real-world noise,\nor critical operational tasks beyond conversational fluency. To bridge this\ngap, we introduce CXMArena, a novel, large-scale synthetic benchmark dataset\nspecifically designed for evaluating AI in operational CXM contexts. Given the\ndiversity in possible contact center features, we have developed a scalable\nLLM-powered pipeline that simulates the brand's CXM entities that form the\nfoundation of our datasets-such as knowledge articles including product\nspecifications, issue taxonomies, and contact center conversations. The\nentities closely represent real-world distribution because of controlled noise\ninjection (informed by domain experts) and rigorous automated validation.\nBuilding on this, we release CXMArena, which provides dedicated benchmarks\ntargeting five important operational tasks: Knowledge Base Refinement, Intent\nPrediction, Agent Quality Adherence, Article Search, and Multi-turn RAG with\nIntegrated Tools. Our baseline experiments underscore the benchmark's\ndifficulty: even state of the art embedding and generation models achieve only\n68% accuracy on article search, while standard embedding methods yield a low F1\nscore of 0.3 for knowledge base refinement, highlighting significant challenges\nfor current models necessitating complex pipelines and solutions over\nconventional techniques."}
{"id": "2505.09521", "pdf": "https://arxiv.org/pdf/2505.09521", "abs": "https://arxiv.org/abs/2505.09521", "authors": ["Dongyi He", "Shiyang Li", "Bin Jiang", "He Yan"], "title": "Spec2VolCAMU-Net: A Spectrogram-to-Volume Model for EEG-to-fMRI Reconstruction based on Multi-directional Time-Frequency Convolutional Attention Encoder and Vision-Mamba U-Net", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "High-resolution functional magnetic resonance imaging (fMRI) is essential for\nmapping human brain activity; however, it remains costly and logistically\nchallenging. If comparable volumes could be generated directly from widely\navailable scalp electroencephalography (EEG), advanced neuroimaging would\nbecome significantly more accessible. Existing EEG-to-fMRI generators rely on\nplain CNNs that fail to capture cross-channel time-frequency cues or on heavy\ntransformer/GAN decoders that strain memory and stability. We propose\nSpec2VolCAMU-Net, a lightweight spectrogram-to-volume generator that confronts\nthese issues via a Multi-directional Time-Frequency Convolutional Attention\nEncoder, stacking temporal, spectral and joint convolutions with\nself-attention, and a Vision-Mamba U-Net decoder whose linear-time state-space\nblocks enable efficient long-range spatial modelling. Trained end-to-end with a\nhybrid SSI-MSE loss, Spec2VolCAMU-Net achieves state-of-the-art fidelity on\nthree public benchmarks, recording SSIMs of 0.693 on NODDI, 0.725 on Oddball\nand 0.788 on CN-EPFL, representing improvements of 14.5%, 14.9%, and 16.9%\nrespectively over previous best SSIM scores. Furthermore, it achieves\ncompetitive PSNR scores, particularly excelling on the CN-EPFL dataset with a\n4.6% improvement over the previous best PSNR, thus striking a better balance in\nreconstruction quality. The proposed model is lightweight and efficient, making\nit suitable for real-time applications in clinical and research settings. The\ncode is available at https://github.com/hdy6438/Spec2VolCAMU-Net."}
{"id": "2505.09229", "pdf": "https://arxiv.org/pdf/2505.09229", "abs": "https://arxiv.org/abs/2505.09229", "authors": ["Brian Britos", "Mathias Bourel"], "title": "Optimal Transport-Based Domain Adaptation for Rotated Linear Regression", "categories": ["stat.ML", "cs.LG", "math.PR"], "comment": null, "summary": "Optimal Transport (OT) has proven effective for domain adaptation (DA) by\naligning distributions across domains with differing statistical properties.\nBuilding on the approach of Courty et al. (2016), who mapped source data to the\ntarget domain for improved model transfer, we focus on a supervised DA problem\ninvolving linear regression models under rotational shifts. This ongoing work\nconsiders cases where source and target domains are related by a\nrotation-common in applications like sensor calibration or image orientation.\nWe show that in $\\mathbb{R}^2$ , when using a p-norm cost with $p $\\ge$ 2$, the\noptimal transport map recovers the underlying rotation. Based on this, we\npropose an algorithm that combines K-means clustering, OT, and singular value\ndecomposition (SVD) to estimate the rotation angle and adapt the regression\nmodel. This method is particularly effective when the target domain is sparsely\nsampled, leveraging abundant source data for improved generalization. Our\ncontributions offer both theoretical and practical insights into OT-based model\nadaptation under geometric transformations."}
{"id": "2505.09438", "pdf": "https://arxiv.org/pdf/2505.09438", "abs": "https://arxiv.org/abs/2505.09438", "authors": ["Paul Tschisgale", "Holger Maus", "Fabian Kieser", "Ben Kroehs", "Stefan Petersen", "Peter Wulff"], "title": "Evaluating GPT- and Reasoning-based Large Language Models on Physics Olympiad Problems: Surpassing Human Performance and Implications for Educational Assessment", "categories": ["physics.ed-ph", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are now widely accessible, reaching learners at\nall educational levels. This development has raised concerns that their use may\ncircumvent essential learning processes and compromise the integrity of\nestablished assessment formats. In physics education, where problem solving\nplays a central role in instruction and assessment, it is therefore essential\nto understand the physics-specific problem-solving capabilities of LLMs. Such\nunderstanding is key to informing responsible and pedagogically sound\napproaches to integrating LLMs into instruction and assessment. This study\ntherefore compares the problem-solving performance of a general-purpose LLM\n(GPT-4o, using varying prompting techniques) and a reasoning-optimized model\n(o1-preview) with that of participants of the German Physics Olympiad, based on\na set of well-defined Olympiad problems. In addition to evaluating the\ncorrectness of the generated solutions, the study analyzes characteristic\nstrengths and limitations of LLM-generated solutions. The findings of this\nstudy indicate that both tested LLMs (GPT-4o and o1-preview) demonstrate\nadvanced problem-solving capabilities on Olympiad-type physics problems, on\naverage outperforming the human participants. Prompting techniques had little\neffect on GPT-4o's performance, while o1-preview almost consistently\noutperformed both GPT-4o and the human benchmark. Based on these findings, the\nstudy discusses implications for the design of summative and formative\nassessment in physics education, including how to uphold assessment integrity\nand support students in critically engaging with LLMs."}
{"id": "2505.09565", "pdf": "https://arxiv.org/pdf/2505.09565", "abs": "https://arxiv.org/abs/2505.09565", "authors": ["Maik Dannecker", "Thomas Sanchez", "Meritxell Bach Cuadra", "Özgün Turgut", "Anthony N. Price", "Lucilio Cordero-Grande", "Vanessa Kyriakopoulou", "Joseph V. Hajnal", "Daniel Rueckert"], "title": "Meta-learning Slice-to-Volume Reconstruction in Fetal Brain MRI using Implicit Neural Representations", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "10 pages, 6 figures", "summary": "High-resolution slice-to-volume reconstruction (SVR) from multiple\nmotion-corrupted low-resolution 2D slices constitutes a critical step in\nimage-based diagnostics of moving subjects, such as fetal brain Magnetic\nResonance Imaging (MRI). Existing solutions struggle with image artifacts and\nsevere subject motion or require slice pre-alignment to achieve satisfying\nreconstruction performance. We propose a novel SVR method to enable fast and\naccurate MRI reconstruction even in cases of severe image and motion\ncorruption. Our approach performs motion correction, outlier handling, and\nsuper-resolution reconstruction with all operations being entirely based on\nimplicit neural representations. The model can be initialized with\ntask-specific priors through fully self-supervised meta-learning on either\nsimulated or real-world data. In extensive experiments including over 480\nreconstructions of simulated and clinical MRI brain data from different\ncenters, we prove the utility of our method in cases of severe subject motion\nand image artifacts. Our results demonstrate improvements in reconstruction\nquality, especially in the presence of severe motion, compared to\nstate-of-the-art methods, and up to 50% reduction in reconstruction time."}
{"id": "2505.09262", "pdf": "https://arxiv.org/pdf/2505.09262", "abs": "https://arxiv.org/abs/2505.09262", "authors": ["Hongxin Xiang", "Ke Li", "Mingquan Liu", "Zhixiang Cheng", "Bin Yao", "Wenjie Du", "Jun Xia", "Li Zeng", "Xin Jin", "Xiangxiang Zeng"], "title": "EDBench: Large-Scale Electron Density Data for Molecular Modeling", "categories": ["physics.chem-ph", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Existing molecular machine learning force fields (MLFFs) generally focus on\nthe learning of atoms, molecules, and simple quantum chemical properties (such\nas energy and force), but ignore the importance of electron density (ED)\n$\\rho(r)$ in accurately understanding molecular force fields (MFFs). ED\ndescribes the probability of finding electrons at specific locations around\natoms or molecules, which uniquely determines all ground state properties (such\nas energy, molecular structure, etc.) of interactive multi-particle systems\naccording to the Hohenberg-Kohn theorem. However, the calculation of ED relies\non the time-consuming first-principles density functional theory (DFT) which\nleads to the lack of large-scale ED data and limits its application in MLFFs.\nIn this paper, we introduce EDBench, a large-scale, high-quality dataset of ED\ndesigned to advance learning-based research at the electronic scale. Built upon\nthe PCQM4Mv2, EDBench provides accurate ED data, covering 3.3 million\nmolecules. To comprehensively evaluate the ability of models to understand and\nutilize electronic information, we design a suite of ED-centric benchmark tasks\nspanning prediction, retrieval, and generation. Our evaluation on several\nstate-of-the-art methods demonstrates that learning from EDBench is not only\nfeasible but also achieves high accuracy. Moreover, we show that learning-based\nmethod can efficiently calculate ED with comparable precision while\nsignificantly reducing the computational cost relative to traditional DFT\ncalculations. All data and benchmarks from EDBench will be freely available,\nlaying a robust foundation for ED-driven drug discovery and materials science."}
{"id": "2505.09456", "pdf": "https://arxiv.org/pdf/2505.09456", "abs": "https://arxiv.org/abs/2505.09456", "authors": ["Josep Lumbreras", "Ruo Cheng Huang", "Yanglin Hu", "Mile Gu", "Marco Tomamichel"], "title": "Quantum state-agnostic work extraction (almost) without dissipation", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "5 pages+14 pages, 2 figures", "summary": "We investigate work extraction protocols designed to transfer the maximum\npossible energy to a battery using sequential access to $N$ copies of an\nunknown pure qubit state. The core challenge is designing interactions to\noptimally balance two competing goals: charging of the battery optimally using\nthe qubit in hand, and acquiring more information by qubit to improve energy\nharvesting in subsequent rounds. Here, we leverage exploration-exploitation\ntrade-off in reinforcement learning to develop adaptive strategies achieving\nenergy dissipation that scales only poly-logarithmically in $N$. This\nrepresents an exponential improvement over current protocols based on full\nstate tomography."}
{"id": "2505.09266", "pdf": "https://arxiv.org/pdf/2505.09266", "abs": "https://arxiv.org/abs/2505.09266", "authors": ["Lirandë Pira", "Airin Antony", "Nayanthara Prathap", "Daniel Peace", "Jacquiline Romero"], "title": "Enhanced Photonic Chip Design via Interpretable Machine Learning Techniques", "categories": ["physics.optics", "cs.LG", "quant-ph"], "comment": null, "summary": "Photonic chip design has seen significant advancements with the adoption of\ninverse design methodologies, offering flexibility and efficiency in optimizing\ndevice performance. However, the black-box nature of the optimization\napproaches, such as those used in inverse design in order to minimize a loss\nfunction or maximize coupling efficiency, poses challenges in understanding the\noutputs. This challenge is prevalent in machine learning-based optimization\nmethods, which can suffer from the same lack of transparency. To this end,\ninterpretability techniques address the opacity of optimization models. In this\nwork, we apply interpretability techniques from machine learning, with the aim\nof gaining understanding of inverse design optimization used in designing\nphotonic components, specifically two-mode multiplexers. We base our\nmethodology on the widespread interpretability technique known as local\ninterpretable model-agnostic explanations, or LIME. As a result, LIME-informed\ninsights point us to more effective initial conditions, directly improving\ndevice performance. This demonstrates that interpretability methods can do more\nthan explain models -- they can actively guide and enhance the inverse-designed\nphotonic components. Our results demonstrate the ability of interpretable\ntechniques to reveal underlying patterns in the inverse design process, leading\nto the development of better-performing components."}
{"id": "2505.09466", "pdf": "https://arxiv.org/pdf/2505.09466", "abs": "https://arxiv.org/abs/2505.09466", "authors": ["Xi Chen", "Shiyang Zhou", "Muqi Huang", "Jiaxu Feng", "Yun Xiong", "Kun Zhou", "Biao Yang", "Yuhui Zhang", "Huishuai Bao", "Sijia Peng", "Chuan Li", "Feng Shi"], "title": "A 2D Semantic-Aware Position Encoding for Vision Transformers", "categories": ["cs.CV", "cs.AI"], "comment": "14 pages, 4 figures, 3 tables", "summary": "Vision transformers have demonstrated significant advantages in computer\nvision tasks due to their ability to capture long-range dependencies and\ncontextual relationships through self-attention. However, existing position\nencoding techniques, which are largely borrowed from natural language\nprocessing, fail to effectively capture semantic-aware positional relationships\nbetween image patches. Traditional approaches like absolute position encoding\nand relative position encoding primarily focus on 1D linear position\nrelationship, often neglecting the semantic similarity between distant yet\ncontextually related patches. These limitations hinder model generalization,\ntranslation equivariance, and the ability to effectively handle repetitive or\nstructured patterns in images. In this paper, we propose 2-Dimensional\nSemantic-Aware Position Encoding ($\\text{SaPE}^2$), a novel position encoding\nmethod with semantic awareness that dynamically adapts position representations\nby leveraging local content instead of fixed linear position relationship or\nspatial coordinates. Our method enhances the model's ability to generalize\nacross varying image resolutions and scales, improves translation equivariance,\nand better aggregates features for visually similar but spatially distant\npatches. By integrating $\\text{SaPE}^2$ into vision transformers, we bridge the\ngap between position encoding and perceptual similarity, thereby improving\nperformance on computer vision tasks."}
{"id": "2505.09295", "pdf": "https://arxiv.org/pdf/2505.09295", "abs": "https://arxiv.org/abs/2505.09295", "authors": ["Qiming Wu", "Siqi Li", "Doudou Zhou", "Nan Liu"], "title": "Toward Fair Federated Learning under Demographic Disparities and Data Imbalance", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "Ensuring fairness is critical when applying artificial intelligence to\nhigh-stakes domains such as healthcare, where predictive models trained on\nimbalanced and demographically skewed data risk exacerbating existing\ndisparities. Federated learning (FL) enables privacy-preserving collaboration\nacross institutions, but remains vulnerable to both algorithmic bias and\nsubgroup imbalance - particularly when multiple sensitive attributes intersect.\nWe propose FedIDA (Fed erated Learning for Imbalance and D isparity A\nwareness), a framework-agnostic method that combines fairness-aware\nregularization with group-conditional oversampling. FedIDA supports multiple\nsensitive attributes and heterogeneous data distributions without altering the\nconvergence behavior of the underlying FL algorithm. We provide theoretical\nanalysis establishing fairness improvement bounds using Lipschitz continuity\nand concentration inequalities, and show that FedIDA reduces the variance of\nfairness metrics across test sets. Empirical results on both benchmark and\nreal-world clinical datasets confirm that FedIDA consistently improves fairness\nwhile maintaining competitive predictive performance, demonstrating its\neffectiveness for equitable and privacy-preserving modeling in healthcare. The\nsource code is available on GitHub."}
{"id": "2505.09477", "pdf": "https://arxiv.org/pdf/2505.09477", "abs": "https://arxiv.org/abs/2505.09477", "authors": ["Zachary Ravichandran", "Fernando Cladera", "Jason Hughes", "Varun Murali", "M. Ani Hsieh", "George J. Pappas", "Camillo J. Taylor", "Vijay Kumar"], "title": "Deploying Foundation Model-Enabled Air and Ground Robots in the Field: Challenges and Opportunities", "categories": ["cs.RO", "cs.AI"], "comment": "Accepted to the IEEE ICRA Workshop on Field Robotics 2025", "summary": "The integration of foundation models (FMs) into robotics has enabled robots\nto understand natural language and reason about the semantics in their\nenvironments. However, existing FM-enabled robots primary operate in\nclosed-world settings, where the robot is given a full prior map or has a full\nview of its workspace. This paper addresses the deployment of FM-enabled robots\nin the field, where missions often require a robot to operate in large-scale\nand unstructured environments. To effectively accomplish these missions, robots\nmust actively explore their environments, navigate obstacle-cluttered terrain,\nhandle unexpected sensor inputs, and operate with compute constraints. We\ndiscuss recent deployments of SPINE, our LLM-enabled autonomy framework, in\nfield robotic settings. To the best of our knowledge, we present the first\ndemonstration of large-scale LLM-enabled robot planning in unstructured\nenvironments with several kilometers of missions. SPINE is agnostic to a\nparticular LLM, which allows us to distill small language models capable of\nrunning onboard size, weight and power (SWaP) limited platforms. Via\npreliminary model distillation work, we then present the first language-driven\nUAV planner using on-device language models. We conclude our paper by proposing\nseveral promising directions for future research."}
{"id": "2505.09304", "pdf": "https://arxiv.org/pdf/2505.09304", "abs": "https://arxiv.org/abs/2505.09304", "authors": ["Luciano Sebastian Martinez-Rau", "Quynh Nguyen Phuong Vu", "Yuxuan Zhang", "Bengt Oelmann", "Sebastian Bader"], "title": "Adaptive Noise Resilient Keyword Spotting Using One-Shot Learning", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "Preprint submitted to the IEEE 11th World Forum on Internet of Things", "summary": "Keyword spotting (KWS) is a key component of smart devices, enabling\nefficient and intuitive audio interaction. However, standard KWS systems\ndeployed on embedded devices often suffer performance degradation under\nreal-world operating conditions. Resilient KWS systems address this issue by\nenabling dynamic adaptation, with applications such as adding or replacing\nkeywords, adjusting to specific users, and improving noise robustness. However,\ndeploying resilient, standalone KWS systems with low latency on\nresource-constrained devices remains challenging due to limited memory and\ncomputational resources. This study proposes a low computational approach for\ncontinuous noise adaptation of pretrained neural networks used for KWS\nclassification, requiring only 1-shot learning and one epoch. The proposed\nmethod was assessed using two pretrained models and three real-world noise\nsources at signal-to-noise ratios (SNRs) ranging from 24 to -3 dB. The adapted\nmodels consistently outperformed the pretrained models across all scenarios,\nespecially at SNR $\\leq$ 18 dB, achieving accuracy improvements of 4.9% to\n46.0%. These results highlight the efficacy of the proposed methodology while\nbeing lightweight enough for deployment on resource-constrained devices."}
{"id": "2505.09486", "pdf": "https://arxiv.org/pdf/2505.09486", "abs": "https://arxiv.org/abs/2505.09486", "authors": ["Seyed Roozbeh Razavi Rohani", "Khashayar Khajavi", "Wesley Chung", "Mo Chen", "Sharan Vaswani"], "title": "Preserving Plasticity in Continual Learning with Adaptive Linearity Injection", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in 4th Conference on Lifelong Learning Agents (CoLLAs), 2025", "summary": "Loss of plasticity in deep neural networks is the gradual reduction in a\nmodel's capacity to incrementally learn and has been identified as a key\nobstacle to learning in non-stationary problem settings. Recent work has shown\nthat deep linear networks tend to be resilient towards loss of plasticity.\nMotivated by this observation, we propose Adaptive Linearization (AdaLin), a\ngeneral approach that dynamically adapts each neuron's activation function to\nmitigate plasticity loss. Unlike prior methods that rely on regularization or\nperiodic resets, AdaLin equips every neuron with a learnable parameter and a\ngating mechanism that injects linearity into the activation function based on\nits gradient flow. This adaptive modulation ensures sufficient gradient signal\nand sustains continual learning without introducing additional hyperparameters\nor requiring explicit task boundaries. When used with conventional activation\nfunctions like ReLU, Tanh, and GeLU, we demonstrate that AdaLin can\nsignificantly improve performance on standard benchmarks, including Random\nLabel and Permuted MNIST, Random Label and Shuffled CIFAR-10, and Class-Split\nCIFAR-100. Furthermore, its efficacy is shown in more complex scenarios, such\nas class-incremental learning on CIFAR-100 with a ResNet-18 backbone, and in\nmitigating plasticity loss in off-policy reinforcement learning agents. We\nperform a systematic set of ablations that show that neuron-level adaptation is\ncrucial for good performance and analyze a number of metrics in the network\nthat might be correlated to loss of plasticity."}
{"id": "2505.09306", "pdf": "https://arxiv.org/pdf/2505.09306", "abs": "https://arxiv.org/abs/2505.09306", "authors": ["Thijs L van der Plas", "Stephen Law", "Michael JO Pocock"], "title": "Predicting butterfly species presence from satellite imagery using soft contrastive regularisation", "categories": ["cs.CV", "cs.LG"], "comment": "To be published in the 2025 CVPR FGVC12 workshop", "summary": "The growing demand for scalable biodiversity monitoring methods has fuelled\ninterest in remote sensing data, due to its widespread availability and\nextensive coverage. Traditionally, the application of remote sensing to\nbiodiversity research has focused on mapping and monitoring habitats, but with\nincreasing availability of large-scale citizen-science wildlife observation\ndata, recent methods have started to explore predicting multi-species presence\ndirectly from satellite images. This paper presents a new data set for\npredicting butterfly species presence from satellite data in the United\nKingdom. We experimentally optimise a Resnet-based model to predict\nmulti-species presence from 4-band satellite images, and find that this model\nespecially outperforms the mean rate baseline for locations with high species\nbiodiversity. To improve performance, we develop a soft, supervised contrastive\nregularisation loss that is tailored to probabilistic labels (such as\nspecies-presence data), and demonstrate that this improves prediction accuracy.\nIn summary, our new data set and contrastive regularisation method contribute\nto the open challenge of accurately predicting species biodiversity from remote\nsensing data, which is key for efficient biodiversity monitoring."}
{"id": "2505.09498", "pdf": "https://arxiv.org/pdf/2505.09498", "abs": "https://arxiv.org/abs/2505.09498", "authors": ["Bo Zhang", "Shuo Li", "Runhe Tian", "Yang Yang", "Jixin Tang", "Jinhao Zhou", "Lin Ma"], "title": "Flash-VL 2B: Optimizing Vision-Language Model Performance for Ultra-Low Latency and High Throughput", "categories": ["cs.CV", "cs.AI"], "comment": "18 pages, 7 figures", "summary": "In this paper, we introduce Flash-VL 2B, a novel approach to optimizing\nVision-Language Models (VLMs) for real-time applications, targeting ultra-low\nlatency and high throughput without sacrificing accuracy. Leveraging advanced\narchitectural enhancements and efficient computational strategies, Flash-VL 2B\nis designed to maximize throughput by reducing processing time while\nmaintaining competitive performance across multiple vision-language benchmarks.\nOur approach includes tailored architectural choices, token compression\nmechanisms, data curation, training schemes, and a novel image processing\ntechnique called implicit semantic stitching that effectively balances\ncomputational load and model performance. Through extensive evaluations on 11\nstandard VLM benchmarks, we demonstrate that Flash-VL 2B achieves\nstate-of-the-art results in both speed and accuracy, making it a promising\nsolution for deployment in resource-constrained environments and large-scale\nreal-time applications."}
{"id": "2505.09313", "pdf": "https://arxiv.org/pdf/2505.09313", "abs": "https://arxiv.org/abs/2505.09313", "authors": ["Qiangqiang Liu", "Qian Huang", "Frank Fan", "Haishan Wu", "Xueyan Tang"], "title": "Detecting Sybil Addresses in Blockchain Airdrops: A Subgraph-based Feature Propagation and Fusion Approach", "categories": ["cs.CR", "cs.LG"], "comment": "IEEE International Conference on Blockchain and Cryptocurrency(Proc.\n  IEEE ICBC 2025)", "summary": "Sybil attacks pose a significant security threat to blockchain ecosystems,\nparticularly in token airdrop events. This paper proposes a novel sybil address\nidentification method based on subgraph feature extraction lightGBM. The method\nfirst constructs a two-layer deep transaction subgraph for each address, then\nextracts key event operation features according to the lifecycle of sybil\naddresses, including the time of first transaction, first gas acquisition,\nparticipation in airdrop activities, and last transaction. These temporal\nfeatures effectively capture the consistency of sybil address behavior\noperations. Additionally, the method extracts amount and network structure\nfeatures, comprehensively describing address behavior patterns and network\ntopology through feature propagation and fusion. Experiments conducted on a\ndataset containing 193,701 addresses (including 23,240 sybil addresses) show\nthat this method outperforms existing approaches in terms of precision, recall,\nF1 score, and AUC, with all metrics exceeding 0.9. The methods and results of\nthis study can be further applied to broader blockchain security areas such as\ntransaction manipulation identification and token liquidity risk assessment,\ncontributing to the construction of a more secure and fair blockchain\necosystem."}
{"id": "2505.09558", "pdf": "https://arxiv.org/pdf/2505.09558", "abs": "https://arxiv.org/abs/2505.09558", "authors": ["Shengpeng Ji", "Tianle Liang", "Yangzhuo Li", "Jialong Zuo", "Minghui Fang", "Jinzheng He", "Yifu Chen", "Zhengqing Liu", "Ziyue Jiang", "Xize Cheng", "Siqi Zheng", "Jin Xu", "Junyang Lin", "Zhou Zhao"], "title": "WavReward: Spoken Dialogue Models With Generalist Reward Evaluators", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.MM", "cs.SD"], "comment": null, "summary": "End-to-end spoken dialogue models such as GPT-4o-audio have recently garnered\nsignificant attention in the speech domain. However, the evaluation of spoken\ndialogue models' conversational performance has largely been overlooked. This\nis primarily due to the intelligent chatbots convey a wealth of non-textual\ninformation which cannot be easily measured using text-based language models\nlike ChatGPT. To address this gap, we propose WavReward, a reward feedback\nmodel based on audio language models that can evaluate both the IQ and EQ of\nspoken dialogue systems with speech input. Specifically, 1) based on audio\nlanguage models, WavReward incorporates the deep reasoning process and the\nnonlinear reward mechanism for post-training. By utilizing multi-sample\nfeedback via the reinforcement learning algorithm, we construct a specialized\nevaluator tailored to spoken dialogue models. 2) We introduce ChatReward-30K, a\npreference dataset used to train WavReward. ChatReward-30K includes both\ncomprehension and generation aspects of spoken dialogue models. These scenarios\nspan various tasks, such as text-based chats, nine acoustic attributes of\ninstruction chats, and implicit chats. WavReward outperforms previous\nstate-of-the-art evaluation models across multiple spoken dialogue scenarios,\nachieving a substantial improvement about Qwen2.5-Omni in objective accuracy\nfrom 55.1$\\%$ to 91.5$\\%$. In subjective A/B testing, WavReward also leads by a\nmargin of 83$\\%$. Comprehensive ablation studies confirm the necessity of each\ncomponent of WavReward. All data and code will be publicly at\nhttps://github.com/jishengpeng/WavReward after the paper is accepted."}
{"id": "2505.09315", "pdf": "https://arxiv.org/pdf/2505.09315", "abs": "https://arxiv.org/abs/2505.09315", "authors": ["Xuefeng Jiang", "Yuan Ma", "Pengxiang Li", "Leimeng Xu", "Xin Wen", "Kun Zhan", "Zhongpu Xia", "Peng Jia", "XianPeng Lang", "Sheng Sun"], "title": "TransDiffuser: End-to-end Trajectory Generation with Decorrelated Multi-modal Representation for Autonomous Driving", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": "Under review", "summary": "In recent years, diffusion model has shown its potential across diverse\ndomains from vision generation to language modeling. Transferring its\ncapabilities to modern autonomous driving systems has also emerged as a\npromising direction.In this work, we propose TransDiffuser, an encoder-decoder\nbased generative trajectory planning model for end-to-end autonomous driving.\nThe encoded scene information serves as the multi-modal conditional input of\nthe denoising decoder. To tackle the mode collapse dilemma in generating\nhigh-quality diverse trajectories, we introduce a simple yet effective\nmulti-modal representation decorrelation optimization mechanism during the\ntraining process.TransDiffuser achieves PDMS of 94.85 on the NAVSIM benchmark,\nsurpassing previous state-of-the-art methods without any anchor-based prior\ntrajectories."}
{"id": "2505.09561", "pdf": "https://arxiv.org/pdf/2505.09561", "abs": "https://arxiv.org/abs/2505.09561", "authors": ["Marcel Torne", "Andy Tang", "Yuejiang Liu", "Chelsea Finn"], "title": "Learning Long-Context Diffusion Policies via Past-Token Prediction", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Videos are available at https://long-context-dp.github.io", "summary": "Reasoning over long sequences of observations and actions is essential for\nmany robotic tasks. Yet, learning effective long-context policies from\ndemonstrations remains challenging. As context length increases, training\nbecomes increasingly expensive due to rising memory demands, and policy\nperformance often degrades as a result of spurious correlations. Recent methods\ntypically sidestep these issues by truncating context length, discarding\nhistorical information that may be critical for subsequent decisions. In this\npaper, we propose an alternative approach that explicitly regularizes the\nretention of past information. We first revisit the copycat problem in\nimitation learning and identify an opposite challenge in recent diffusion\npolicies: rather than over-relying on prior actions, they often fail to capture\nessential dependencies between past and future actions. To address this, we\nintroduce Past-Token Prediction (PTP), an auxiliary task in which the policy\nlearns to predict past action tokens alongside future ones. This regularization\nsignificantly improves temporal modeling in the policy head, with minimal\nreliance on visual representations. Building on this observation, we further\nintroduce a multistage training strategy: pre-train the visual encoder with\nshort contexts, and fine-tune the policy head using cached long-context\nembeddings. This strategy preserves the benefits of PTP while greatly reducing\nmemory and computational overhead. Finally, we extend PTP into a\nself-verification mechanism at test time, enabling the policy to score and\nselect candidates consistent with past actions during inference. Experiments\nacross four real-world and six simulated tasks demonstrate that our proposed\nmethod improves the performance of long-context diffusion policies by 3x and\naccelerates policy training by more than 10x."}
{"id": "2505.09324", "pdf": "https://arxiv.org/pdf/2505.09324", "abs": "https://arxiv.org/abs/2505.09324", "authors": ["Lakshya Gupta", "Imran N. Junejo"], "title": "Neural Video Compression using 2D Gaussian Splatting", "categories": ["cs.CV", "cs.AI", "cs.LG", "eess.IV"], "comment": "9 pages, 8 figures", "summary": "The computer vision and image processing research community has been involved\nin standardizing video data communications for the past many decades, leading\nto standards such as AVC, HEVC, VVC, AV1, AV2, etc. However, recent\ngroundbreaking works have focused on employing deep learning-based techniques\nto replace the traditional video codec pipeline to a greater affect. Neural\nvideo codecs (NVC) create an end-to-end ML-based solution that does not rely on\nany handcrafted features (motion or edge-based) and have the ability to learn\ncontent-aware compression strategies, offering better adaptability and higher\ncompression efficiency than traditional methods. This holds a great potential\nnot only for hardware design, but also for various video streaming platforms\nand applications, especially video conferencing applications such as MS-Teams\nor Zoom that have found extensive usage in classrooms and workplaces. However,\ntheir high computational demands currently limit their use in real-time\napplications like video conferencing. To address this, we propose a\nregion-of-interest (ROI) based neural video compression model that leverages 2D\nGaussian Splatting. Unlike traditional codecs, 2D Gaussian Splatting is capable\nof real-time decoding and can be optimized using fewer data points, requiring\nonly thousands of Gaussians for decent quality outputs as opposed to millions\nin 3D scenes. In this work, we designed a video pipeline that speeds up the\nencoding time of the previous Gaussian splatting-based image codec by 88% by\nusing a content-aware initialization strategy paired with a novel Gaussian\ninter-frame redundancy-reduction mechanism, enabling Gaussian splatting to be\nused for a video-codec solution, the first of its kind solution in this neural\nvideo codec space."}
{"id": "2505.09565", "pdf": "https://arxiv.org/pdf/2505.09565", "abs": "https://arxiv.org/abs/2505.09565", "authors": ["Maik Dannecker", "Thomas Sanchez", "Meritxell Bach Cuadra", "Özgün Turgut", "Anthony N. Price", "Lucilio Cordero-Grande", "Vanessa Kyriakopoulou", "Joseph V. Hajnal", "Daniel Rueckert"], "title": "Meta-learning Slice-to-Volume Reconstruction in Fetal Brain MRI using Implicit Neural Representations", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": "10 pages, 6 figures", "summary": "High-resolution slice-to-volume reconstruction (SVR) from multiple\nmotion-corrupted low-resolution 2D slices constitutes a critical step in\nimage-based diagnostics of moving subjects, such as fetal brain Magnetic\nResonance Imaging (MRI). Existing solutions struggle with image artifacts and\nsevere subject motion or require slice pre-alignment to achieve satisfying\nreconstruction performance. We propose a novel SVR method to enable fast and\naccurate MRI reconstruction even in cases of severe image and motion\ncorruption. Our approach performs motion correction, outlier handling, and\nsuper-resolution reconstruction with all operations being entirely based on\nimplicit neural representations. The model can be initialized with\ntask-specific priors through fully self-supervised meta-learning on either\nsimulated or real-world data. In extensive experiments including over 480\nreconstructions of simulated and clinical MRI brain data from different\ncenters, we prove the utility of our method in cases of severe subject motion\nand image artifacts. Our results demonstrate improvements in reconstruction\nquality, especially in the presence of severe motion, compared to\nstate-of-the-art methods, and up to 50% reduction in reconstruction time."}
{"id": "2505.09326", "pdf": "https://arxiv.org/pdf/2505.09326", "abs": "https://arxiv.org/abs/2505.09326", "authors": ["Vincent Abbott", "Kotaro Kamiya", "Gerard Glowacki", "Yu Atsumi", "Gioele Zardini", "Yoshihiro Maruyama"], "title": "Accelerating Machine Learning Systems via Category Theory: Applications to Spherical Attention for Gene Regulatory Networks", "categories": ["math.CT", "cs.LG", "q-bio.MN"], "comment": null, "summary": "How do we enable artificial intelligence models to improve themselves? This\nis central to exponentially improving generalized artificial intelligence\nmodels, which can improve their own architecture to handle new problem domains\nin an efficient manner that leverages the latest hardware. However, current\nautomated compilation methods are poor, and efficient algorithms require years\nof human development. In this paper, we use neural circuit diagrams, based in\ncategory theory, to prove a general theorem related to deep learning\nalgorithms, guide the development of a novel attention algorithm catered to the\ndomain of gene regulatory networks, and produce a corresponding efficient\nkernel. The algorithm we propose, spherical attention, shows that neural\ncircuit diagrams enable a principled and systematic method for reasoning about\ndeep learning architectures and providing high-performance code. By replacing\nSoftMax with an $L^2$ norm as suggested by diagrams, it overcomes the special\nfunction unit bottleneck of standard attention while retaining the streaming\nproperty essential to high-performance. Our diagrammatically derived\n\\textit{FlashSign} kernel achieves comparable performance to the\nstate-of-the-art, fine-tuned FlashAttention algorithm on an A100, and\n$3.6\\times$ the performance of PyTorch. Overall, this investigation shows\nneural circuit diagrams' suitability as a high-level framework for the\nautomated development of efficient, novel artificial intelligence\narchitectures."}
{"id": "2505.09568", "pdf": "https://arxiv.org/pdf/2505.09568", "abs": "https://arxiv.org/abs/2505.09568", "authors": ["Jiuhai Chen", "Zhiyang Xu", "Xichen Pan", "Yushi Hu", "Can Qin", "Tom Goldstein", "Lifu Huang", "Tianyi Zhou", "Saining Xie", "Silvio Savarese", "Le Xue", "Caiming Xiong", "Ran Xu"], "title": "BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Unifying image understanding and generation has gained growing attention in\nrecent research on multimodal models. Although design choices for image\nunderstanding have been extensively studied, the optimal model architecture and\ntraining recipe for a unified framework with image generation remain\nunderexplored. Motivated by the strong potential of autoregressive and\ndiffusion models for high-quality generation and scalability, we conduct a\ncomprehensive study of their use in unified multimodal settings, with emphasis\non image representations, modeling objectives, and training strategies.\nGrounded in these investigations, we introduce a novel approach that employs a\ndiffusion transformer to generate semantically rich CLIP image features, in\ncontrast to conventional VAE-based representations. This design yields both\nhigher training efficiency and improved generative quality. Furthermore, we\ndemonstrate that a sequential pretraining strategy for unified models-first\ntraining on image understanding and subsequently on image generation-offers\npractical advantages by preserving image understanding capability while\ndeveloping strong image generation ability. Finally, we carefully curate a\nhigh-quality instruction-tuning dataset BLIP3o-60k for image generation by\nprompting GPT-4o with a diverse set of captions covering various scenes,\nobjects, human gestures, and more. Building on our innovative model design,\ntraining recipe, and datasets, we develop BLIP3-o, a suite of state-of-the-art\nunified multimodal models. BLIP3-o achieves superior performance across most of\nthe popular benchmarks spanning both image understanding and generation tasks.\nTo facilitate future research, we fully open-source our models, including code,\nmodel weights, training scripts, and pretraining and instruction tuning\ndatasets."}
{"id": "2505.09342", "pdf": "https://arxiv.org/pdf/2505.09342", "abs": "https://arxiv.org/abs/2505.09342", "authors": ["Mostafa Jafari", "Alireza Shameli-Sendi"], "title": "Evaluating the Robustness of Adversarial Defenses in Malware Detection Systems", "categories": ["cs.CR", "cs.AI", "cs.LG", "68", "I.2.1"], "comment": "Submitted to IEEE Transactions on Information Forensics and Security\n  (T-IFS), 13 pages, 4 figures", "summary": "Machine learning is a key tool for Android malware detection, effectively\nidentifying malicious patterns in apps. However, ML-based detectors are\nvulnerable to evasion attacks, where small, crafted changes bypass detection.\nDespite progress in adversarial defenses, the lack of comprehensive evaluation\nframeworks in binary-constrained domains limits understanding of their\nrobustness. We introduce two key contributions. First, Prioritized Binary\nRounding, a technique to convert continuous perturbations into binary feature\nspaces while preserving high attack success and low perturbation size. Second,\nthe sigma-binary attack, a novel adversarial method for binary domains,\ndesigned to achieve attack goals with minimal feature changes. Experiments on\nthe Malscan dataset show that sigma-binary outperforms existing attacks and\nexposes key vulnerabilities in state-of-the-art defenses. Defenses equipped\nwith adversary detectors, such as KDE, DLA, DNN+, and ICNN, exhibit significant\nbrittleness, with attack success rates exceeding 90% using fewer than 10\nfeature modifications and reaching 100% with just 20. Adversarially trained\ndefenses, including AT-rFGSM-k, AT-MaxMA, improves robustness under small\nbudgets but remains vulnerable to unrestricted perturbations, with attack\nsuccess rates of 99.45% and 96.62%, respectively. Although PAD-SMA demonstrates\nstrong robustness against state-of-the-art gradient-based adversarial attacks\nby maintaining an attack success rate below 16.55%, the sigma-binary attack\nsignificantly outperforms these methods, achieving a 94.56% success rate under\nunrestricted perturbations. These findings highlight the critical need for\nprecise method like sigma-binary to expose hidden vulnerabilities in existing\ndefenses and support the development of more resilient malware detection\nsystems."}
{"id": "2505.09576", "pdf": "https://arxiv.org/pdf/2505.09576", "abs": "https://arxiv.org/abs/2505.09576", "authors": ["Shannon Lodoen", "Alexi Orchard"], "title": "Ethics and Persuasion in Reinforcement Learning from Human Feedback: A Procedural Rhetorical Approach", "categories": ["cs.CY", "cs.AI"], "comment": "10 pages, 1 figure, Accepted version", "summary": "Since 2022, versions of generative AI chatbots such as ChatGPT and Claude\nhave been trained using a specialized technique called Reinforcement Learning\nfrom Human Feedback (RLHF) to fine-tune language model output using feedback\nfrom human annotators. As a result, the integration of RLHF has greatly\nenhanced the outputs of these large language models (LLMs) and made the\ninteractions and responses appear more \"human-like\" than those of previous\nversions using only supervised learning. The increasing convergence of human\nand machine-written text has potentially severe ethical, sociotechnical, and\npedagogical implications relating to transparency, trust, bias, and\ninterpersonal relations. To highlight these implications, this paper presents a\nrhetorical analysis of some of the central procedures and processes currently\nbeing reshaped by RLHF-enhanced generative AI chatbots: upholding language\nconventions, information seeking practices, and expectations for social\nrelationships. Rhetorical investigations of generative AI and LLMs have, to\nthis point, focused largely on the persuasiveness of the content generated.\nUsing Ian Bogost's concept of procedural rhetoric, this paper shifts the site\nof rhetorical investigation from content analysis to the underlying mechanisms\nof persuasion built into RLHF-enhanced LLMs. In doing so, this theoretical\ninvestigation opens a new direction for further inquiry in AI ethics that\nconsiders how procedures rerouted through AI-driven technologies might\nreinforce hegemonic language use, perpetuate biases, decontextualize learning,\nand encroach upon human relationships. It will therefore be of interest to\neducators, researchers, scholars, and the growing number of users of generative\nAI chatbots."}
{"id": "2505.09358", "pdf": "https://arxiv.org/pdf/2505.09358", "abs": "https://arxiv.org/abs/2505.09358", "authors": ["Bingxin Ke", "Kevin Qu", "Tianfu Wang", "Nando Metzger", "Shengyu Huang", "Bo Li", "Anton Obukhov", "Konrad Schindler"], "title": "Marigold: Affordable Adaptation of Diffusion-Based Image Generators for Image Analysis", "categories": ["cs.CV", "cs.LG"], "comment": "Journal extension of our CVPR 2024 paper, featuring new tasks,\n  improved efficiency, high-resolution capabilities, and enhanced accessibility", "summary": "The success of deep learning in computer vision over the past decade has\nhinged on large labeled datasets and strong pretrained models. In data-scarce\nsettings, the quality of these pretrained models becomes crucial for effective\ntransfer learning. Image classification and self-supervised learning have\ntraditionally been the primary methods for pretraining CNNs and\ntransformer-based architectures. Recently, the rise of text-to-image generative\nmodels, particularly those using denoising diffusion in a latent space, has\nintroduced a new class of foundational models trained on massive, captioned\nimage datasets. These models' ability to generate realistic images of unseen\ncontent suggests they possess a deep understanding of the visual world. In this\nwork, we present Marigold, a family of conditional generative models and a\nfine-tuning protocol that extracts the knowledge from pretrained latent\ndiffusion models like Stable Diffusion and adapts them for dense image analysis\ntasks, including monocular depth estimation, surface normals prediction, and\nintrinsic decomposition. Marigold requires minimal modification of the\npre-trained latent diffusion model's architecture, trains with small synthetic\ndatasets on a single GPU over a few days, and demonstrates state-of-the-art\nzero-shot generalization. Project page:\nhttps://marigoldcomputervision.github.io"}
{"id": "2505.09591", "pdf": "https://arxiv.org/pdf/2505.09591", "abs": "https://arxiv.org/abs/2505.09591", "authors": ["Tobias Jan Wieczorek", "Nathalie Daun", "Mohammad Emtiyaz Khan", "Marcus Rohrbach"], "title": "Variational Visual Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "19 pages, 16 figures, under review at ICCV 2025", "summary": "Despite remarkable progress in multimodal models for Visual Question\nAnswering (VQA), there remain major reliability concerns because the models can\noften be overconfident and miscalibrated, especially in out-of-distribution\n(OOD) settings. Plenty has been done to address such issues for unimodal\nmodels, but little work exists for multimodal cases. Here, we address\nunreliability in multimodal models by proposing a Variational VQA approach.\nSpecifically, instead of fine-tuning vision-language models by using AdamW, we\nemploy a recently proposed variational algorithm called IVON, which yields a\nposterior distribution over model parameters. Through extensive experiments, we\nshow that our approach improves calibration and abstentions without sacrificing\nthe accuracy of AdamW. For instance, compared to AdamW fine-tuning, we reduce\nExpected Calibration Error by more than 50% compared to the AdamW baseline and\nraise Coverage by 4% vs. SOTA (for a fixed risk of 1%). In the presence of\ndistribution shifts, the performance gain is even higher, achieving 8% Coverage\n(@ 1% risk) improvement vs. SOTA when 50% of test cases are OOD. Overall, we\npresent variational learning as a viable option to enhance the reliability of\nmultimodal models."}
{"id": "2505.09364", "pdf": "https://arxiv.org/pdf/2505.09364", "abs": "https://arxiv.org/abs/2505.09364", "authors": ["Michael Benigni", "Maurizio Ferrari Dacrema", "Dietmar Jannach"], "title": "Diffusion Recommender Models and the Illusion of Progress: A Concerning Study of Reproducibility and a Conceptual Mismatch", "categories": ["cs.IR", "cs.LG", "cs.NE"], "comment": null, "summary": "Countless new machine learning models are published every year and are\nreported to significantly advance the state-of-the-art in \\emph{top-n}\nrecommendation. However, earlier reproducibility studies indicate that progress\nin this area may be quite limited. Specifically, various widespread\nmethodological issues, e.g., comparisons with untuned baseline models, have led\nto an \\emph{illusion of progress}. In this work, our goal is to examine whether\nthese problems persist in today's research. To this end, we aim to reproduce\nthe latest advancements reported from applying modern Denoising Diffusion\nProbabilistic Models to recommender systems, focusing on four models published\nat the top-ranked SIGIR conference in 2023 and 2024. Our findings are\nconcerning, revealing persistent methodological problems. Alarmingly, through\nexperiments, we find that the latest recommendation techniques based on\ndiffusion models, despite their computational complexity and substantial carbon\nfootprint, are consistently outperformed by simpler existing models.\nFurthermore, we identify key mismatches between the characteristics of\ndiffusion models and those of the traditional \\emph{top-n} recommendation task,\nraising doubts about their suitability for recommendation. We also note that,\nin the papers we analyze, the generative capabilities of these models are\nconstrained to a minimum. Overall, our results and continued methodological\nissues call for greater scientific rigor and a disruptive change in the\nresearch and publication culture in this area."}
{"id": "2505.09595", "pdf": "https://arxiv.org/pdf/2505.09595", "abs": "https://arxiv.org/abs/2505.09595", "authors": ["Abdullah Mushtaq", "Imran Taj", "Rafay Naeem", "Ibrahim Ghaznavi", "Junaid Qadir"], "title": "WorldView-Bench: A Benchmark for Evaluating Global Cultural Perspectives in Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "comment": "Preprint. Submitted to the Journal of Artificial Intelligence\n  Research (JAIR) on April 29, 2025", "summary": "Large Language Models (LLMs) are predominantly trained and aligned in ways\nthat reinforce Western-centric epistemologies and socio-cultural norms, leading\nto cultural homogenization and limiting their ability to reflect global\ncivilizational plurality. Existing benchmarking frameworks fail to adequately\ncapture this bias, as they rely on rigid, closed-form assessments that overlook\nthe complexity of cultural inclusivity. To address this, we introduce\nWorldView-Bench, a benchmark designed to evaluate Global Cultural Inclusivity\n(GCI) in LLMs by analyzing their ability to accommodate diverse worldviews. Our\napproach is grounded in the Multiplex Worldview proposed by Senturk et al.,\nwhich distinguishes between Uniplex models, reinforcing cultural\nhomogenization, and Multiplex models, which integrate diverse perspectives.\nWorldView-Bench measures Cultural Polarization, the exclusion of alternative\nperspectives, through free-form generative evaluation rather than conventional\ncategorical benchmarks. We implement applied multiplexity through two\nintervention strategies: (1) Contextually-Implemented Multiplex LLMs, where\nsystem prompts embed multiplexity principles, and (2) Multi-Agent System\n(MAS)-Implemented Multiplex LLMs, where multiple LLM agents representing\ndistinct cultural perspectives collaboratively generate responses. Our results\ndemonstrate a significant increase in Perspectives Distribution Score (PDS)\nentropy from 13% at baseline to 94% with MAS-Implemented Multiplex LLMs,\nalongside a shift toward positive sentiment (67.7%) and enhanced cultural\nbalance. These findings highlight the potential of multiplex-aware AI\nevaluation in mitigating cultural bias in LLMs, paving the way for more\ninclusive and ethically aligned AI systems."}
{"id": "2505.09365", "pdf": "https://arxiv.org/pdf/2505.09365", "abs": "https://arxiv.org/abs/2505.09365", "authors": ["H. T. Rüdisser", "G. Nguyen", "J. Le Louëdec", "C. Möstl"], "title": "ARCANE -- Early Detection of Interplanetary Coronal Mass Ejections", "categories": ["physics.space-ph", "astro-ph.IM", "astro-ph.SR", "cs.LG"], "comment": "25 pages, 9 figures, 1 table, submitted to AGU Space Weather on 14th\n  May 2025", "summary": "Interplanetary coronal mass ejections (ICMEs) are major drivers of space\nweather disturbances, posing risks to both technological infrastructure and\nhuman activities. Automatic detection of ICMEs in solar wind in situ data is\nessential for early warning systems. While several methods have been proposed\nto identify these structures in time series data, robust real-time detection\nremains a significant challenge. In this work, we present ARCANE - the first\nframework explicitly designed for early ICME detection in streaming solar wind\ndata under realistic operational constraints, enabling event identification\nwithout requiring observation of the full structure. Our approach evaluates the\nstrengths and limitations of detection models by comparing a machine\nlearning-based method to a threshold-based baseline. The ResUNet++ model,\npreviously validated on science data, significantly outperforms the baseline,\nparticularly in detecting high-impact events, while retaining solid performance\non lower-impact cases. Notably, we find that using real-time solar wind (RTSW)\ndata instead of high-resolution science data leads to only minimal performance\ndegradation. Despite the challenges of operational settings, our detection\npipeline achieves an F1 score of 0.53, with an average detection delay of 21.5%\nof the event's duration while only seeing a minimal amount of data. As more\ndata becomes available, the performance increases significantly. These results\nmark a substantial step forward in automated space weather monitoring and lay\nthe groundwork for enhanced real-time forecasting capabilities."}
{"id": "2505.09598", "pdf": "https://arxiv.org/pdf/2505.09598", "abs": "https://arxiv.org/abs/2505.09598", "authors": ["Nidhal Jegham", "Marwen Abdelatti", "Lassad Elmoubarki", "Abdeltawab Hendawi"], "title": "How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "As large language models (LLMs) spread across industries, understanding their\nenvironmental footprint at the inference level is no longer optional; it is\nessential. However, most existing studies exclude proprietary models, overlook\ninfrastructural variability and overhead, or focus solely on training, even as\ninference increasingly dominates AI's environmental impact. To bridge this gap,\nthis paper introduces a novel infrastructure-aware benchmarking framework for\nquantifying the environmental footprint of LLM inference across 30\nstate-of-the-art models as deployed in commercial data centers. Our framework\ncombines public API performance data with region-specific environmental\nmultipliers and statistical inference of hardware configurations. We\nadditionally utilize cross-efficiency Data Envelopment Analysis (DEA) to rank\nmodels by performance relative to environmental cost. Our results show that o3\nand DeepSeek-R1 emerge as the most energy-intensive models, consuming over 33\nWh per long prompt, more than 70 times the consumption of GPT-4.1 nano, and\nthat Claude-3.7 Sonnet ranks highest in eco-efficiency. While a single short\nGPT-4o query consumes 0.43 Wh, scaling this to 700 million queries/day results\nin substantial annual environmental impacts. These include electricity use\ncomparable to 35,000 U.S. homes, freshwater evaporation matching the annual\ndrinking needs of 1.2 million people, and carbon emissions requiring a\nChicago-sized forest to offset. These findings illustrate a growing paradox:\nalthough individual queries are efficient, their global scale drives\ndisproportionate resource consumption. Our study provides a standardized,\nempirically grounded methodology for benchmarking the sustainability of LLM\ndeployments, laying a foundation for future environmental accountability in AI\ndevelopment and sustainability standards."}
{"id": "2505.09368", "pdf": "https://arxiv.org/pdf/2505.09368", "abs": "https://arxiv.org/abs/2505.09368", "authors": ["Jenny Schmalfuss", "Victor Oei", "Lukas Mehl", "Madlen Bartsch", "Shashank Agnihotri", "Margret Keuper", "Andrés Bruhn"], "title": "RobustSpring: Benchmarking Robustness to Image Corruptions for Optical Flow, Scene Flow and Stereo", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Standard benchmarks for optical flow, scene flow, and stereo vision\nalgorithms generally focus on model accuracy rather than robustness to image\ncorruptions like noise or rain. Hence, the resilience of models to such\nreal-world perturbations is largely unquantified. To address this, we present\nRobustSpring, a comprehensive dataset and benchmark for evaluating robustness\nto image corruptions for optical flow, scene flow, and stereo models.\nRobustSpring applies 20 different image corruptions, including noise, blur,\ncolor changes, quality degradations, and weather distortions, in a time-,\nstereo-, and depth-consistent manner to the high-resolution Spring dataset,\ncreating a suite of 20,000 corrupted images that reflect challenging\nconditions. RobustSpring enables comparisons of model robustness via a new\ncorruption robustness metric. Integration with the Spring benchmark enables\npublic two-axis evaluations of both accuracy and robustness. We benchmark a\ncurated selection of initial models, observing that accurate models are not\nnecessarily robust and that robustness varies widely by corruption type.\nRobustSpring is a new computer vision benchmark that treats robustness as a\nfirst-class citizen to foster models that combine accuracy with resilience. It\nwill be available at https://spring-benchmark.org."}
{"id": "2505.09610", "pdf": "https://arxiv.org/pdf/2505.09610", "abs": "https://arxiv.org/abs/2505.09610", "authors": ["Nicolas Dupuis", "Ravi Nair", "Shyam Ramji", "Sean McClintock", "Nishant Chauhan", "Priyanka Nagpal", "Bart Blaner", "Ken Valk", "Leon Stok", "Ruchir Puri"], "title": "Customizing a Large Language Model for VHDL Design of High-Performance Microprocessors", "categories": ["cs.SE", "cs.AI", "cs.CL"], "comment": null, "summary": "The use of Large Language Models (LLMs) in hardware design has taken off in\nrecent years, principally through its incorporation in tools that increase chip\ndesigner productivity. There has been considerable discussion about the use of\nLLMs in RTL specifications of chip designs, for which the two most popular\nlanguages are Verilog and VHDL. LLMs and their use in Verilog design has\nreceived significant attention due to the higher popularity of the language,\nbut little attention so far has been given to VHDL despite its continued\npopularity in the industry. There has also been little discussion about the\nunique needs of organizations that engage in high-performance processor design,\nand techniques to deploy AI solutions in these settings. In this paper, we\ndescribe our journey in developing a Large Language Model (LLM) specifically\nfor the purpose of explaining VHDL code, a task that has particular importance\nin an organization with decades of experience and assets in high-performance\nprocessor design. We show how we developed test sets specific to our needs and\nused them for evaluating models as we performed extended pretraining (EPT) of a\nbase LLM. Expert evaluation of the code explanations produced by the EPT model\nincreased to 69% compared to a base model rating of 43%. We further show how we\ndeveloped an LLM-as-a-judge to gauge models similar to expert evaluators. This\nled us to deriving and evaluating a host of new models, including an\ninstruction-tuned version of the EPT model with an expected expert evaluator\nrating of 71%. Our experiments also indicate that with the potential use of\nnewer base models, this rating can be pushed to 85% and beyond. We conclude\nwith a discussion on further improving the quality of hardware design LLMs\nusing exciting new developments in the Generative AI world."}
{"id": "2505.09371", "pdf": "https://arxiv.org/pdf/2505.09371", "abs": "https://arxiv.org/abs/2505.09371", "authors": ["Akash Kundu", "Stefano Mangini"], "title": "TensorRL-QAS: Reinforcement learning with tensor networks for scalable quantum architecture search", "categories": ["quant-ph", "cs.AI", "cs.ET", "cs.LG"], "comment": "The code will be available soon! Comments are welcomed!", "summary": "Variational quantum algorithms hold the promise to address meaningful quantum\nproblems already on noisy intermediate-scale quantum hardware, but they face\nthe challenge of designing quantum circuits that both solve the target problem\nand comply with device limitations. Quantum architecture search (QAS) automates\nthis design process, with reinforcement learning (RL) emerging as a promising\napproach. Yet, RL-based QAS methods encounter significant scalability issues,\nas computational and training costs grow rapidly with the number of qubits,\ncircuit depth, and noise, severely impacting performance. To address these\nchallenges, we introduce $\\textit{TensorRL-QAS}$, a scalable framework that\ncombines tensor network (TN) methods with RL for designing quantum circuits. By\nwarm-starting the architecture search with a matrix product state approximation\nof the target solution, TensorRL-QAS effectively narrows the search space to\nphysically meaningful circuits, accelerating convergence to the desired\nsolution. Tested on several quantum chemistry problems of up to 12-qubit,\nTensorRL-QAS achieves up to a 10-fold reduction in CNOT count and circuit depth\ncompared to baseline methods, while maintaining or surpassing chemical\naccuracy. It reduces function evaluations by up to 100-fold, accelerates\ntraining episodes by up to $98\\%$, and achieves up to $50\\%$ success\nprobability for 10-qubit systems-far exceeding the $<1\\%$ rates of baseline\napproaches. Robustness and versatility are demonstrated both in the noiseless\nand noisy scenarios, where we report a simulation of up to 8-qubit. These\nadvancements establish TensorRL-QAS as a promising candidate for a scalable and\nefficient quantum circuit discovery protocol on near-term quantum hardware."}
{"id": "2505.09380", "pdf": "https://arxiv.org/pdf/2505.09380", "abs": "https://arxiv.org/abs/2505.09380", "authors": ["Qinghui Liu", "Jon Nesvold", "Hanna Raaum", "Elakkyen Murugesu", "Martin Røvang", "Bradley J Maclntosh", "Atle Bjørnerud", "Karoline Skogen"], "title": "Examining Deployment and Refinement of the VIOLA-AI Intracranial Hemorrhage Model Using an Interactive NeoMedSys Platform", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "19 pages, 11 figures, on submission to BMC Methods", "summary": "Background: There are many challenges and opportunities in the clinical\ndeployment of AI tools in radiology. The current study describes a radiology\nsoftware platform called NeoMedSys that can enable efficient deployment and\nrefinements of AI models. We evaluated the feasibility and effectiveness of\nrunning NeoMedSys for three months in real-world clinical settings and focused\non improvement performance of an in-house developed AI model (VIOLA-AI)\ndesigned for intracranial hemorrhage (ICH) detection.\n  Methods: NeoMedSys integrates tools for deploying, testing, and optimizing AI\nmodels with a web-based medical image viewer, annotation system, and\nhospital-wide radiology information systems. A pragmatic investigation was\ndeployed using clinical cases of patients presenting to the largest Emergency\nDepartment in Norway (site-1) with suspected traumatic brain injury (TBI) or\npatients with suspected stroke (site-2). We assessed ICH classification\nperformance as VIOLA-AI encountered new data and underwent pre-planned model\nretraining. Performance metrics included sensitivity, specificity, accuracy,\nand the area under the receiver operating characteristic curve (AUC).\n  Results: NeoMedSys facilitated iterative improvements in the AI model,\nsignificantly enhancing its diagnostic accuracy. Automated bleed detection and\nsegmentation were reviewed in near real-time to facilitate re-training\nVIOLA-AI. The iterative refinement process yielded a marked improvement in\nclassification sensitivity, rising to 90.3% (from 79.2%), and specificity that\nreached 89.3% (from 80.7%). The bleed detection ROC analysis for the entire\nsample demonstrated a high area-under-the-curve (AUC) of 0.949 (from 0.873).\nModel refinement stages were associated with notable gains, highlighting the\nvalue of real-time radiologist feedback."}
{"id": "2505.09395", "pdf": "https://arxiv.org/pdf/2505.09395", "abs": "https://arxiv.org/abs/2505.09395", "authors": ["Chen-Yu Liu", "Kuan-Cheng Chen", "Yi-Chien Chen", "Samuel Yen-Chi Chen", "Wei-Hao Huang", "Wei-Jia Huang", "Yen-Jui Chang"], "title": "Quantum-Enhanced Parameter-Efficient Learning for Typhoon Trajectory Forecasting", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "Typhoon trajectory forecasting is essential for disaster preparedness but\nremains computationally demanding due to the complexity of atmospheric dynamics\nand the resource requirements of deep learning models. Quantum-Train (QT), a\nhybrid quantum-classical framework that leverages quantum neural networks\n(QNNs) to generate trainable parameters exclusively during training,\neliminating the need for quantum hardware at inference time. Building on QT's\nsuccess across multiple domains, including image classification, reinforcement\nlearning, flood prediction, and large language model (LLM) fine-tuning, we\nintroduce Quantum Parameter Adaptation (QPA) for efficient typhoon forecasting\nmodel learning. Integrated with an Attention-based Multi-ConvGRU model, QPA\nenables parameter-efficient training while maintaining predictive accuracy.\nThis work represents the first application of quantum machine learning (QML) to\nlarge-scale typhoon trajectory prediction, offering a scalable and\nenergy-efficient approach to climate modeling. Our results demonstrate that QPA\nsignificantly reduces the number of trainable parameters while preserving\nperformance, making high-performance forecasting more accessible and\nsustainable through hybrid quantum-classical learning."}
{"id": "2505.09425", "pdf": "https://arxiv.org/pdf/2505.09425", "abs": "https://arxiv.org/abs/2505.09425", "authors": ["Sarah Leyder", "Jakob Raymaekers", "Peter J. Rousseeuw", "Tom Van Deuren", "Tim Verdonck"], "title": "Independent Component Analysis by Robust Distance Correlation", "categories": ["stat.CO", "cs.LG"], "comment": null, "summary": "Independent component analysis (ICA) is a powerful tool for decomposing a\nmultivariate signal or distribution into fully independent sources, not just\nuncorrelated ones. Unfortunately, most approaches to ICA are not robust against\noutliers. Here we propose a robust ICA method called RICA, which estimates the\ncomponents by minimizing a robust measure of dependence between multivariate\nrandom variables. The dependence measure used is the distance correlation\n(dCor). In order to make it more robust we first apply a new transformation\ncalled the bowl transform, which is bounded, one-to-one, continuous, and maps\nfar outliers to points close to the origin. This preserves the crucial property\nthat a zero dCor implies independence. RICA estimates the independent sources\nsequentially, by looking for the component that has the smallest dCor with the\nremainder. RICA is strongly consistent and has the usual parametric rate of\nconvergence. Its robustness is investigated by a simulation study, in which it\ngenerally outperforms its competitors. The method is illustrated on three\napplications, including the well-known cocktail party problem."}
{"id": "2505.09430", "pdf": "https://arxiv.org/pdf/2505.09430", "abs": "https://arxiv.org/abs/2505.09430", "authors": ["Yutong Hu", "Pinhao Song", "Kehan Wen", "Renaud Detry"], "title": "Train a Multi-Task Diffusion Policy on RLBench-18 in One Day with One GPU", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "We present a method for training multi-task vision-language robotic diffusion\npolicies that reduces training time and memory usage by an order of magnitude.\nThis improvement arises from a previously underexplored distinction between\naction diffusion and the image diffusion techniques that inspired it: image\ngeneration targets are high-dimensional, while robot actions lie in a much\nlower-dimensional space. Meanwhile, the vision-language conditions for action\ngeneration remain high-dimensional. Our approach, Mini-Diffuser, exploits this\nasymmetry by introducing Level-2 minibatching, which pairs multiple noised\naction samples with each vision-language condition, instead of the conventional\none-to-one sampling strategy. To support this batching scheme, we introduce\narchitectural adaptations to the diffusion transformer that prevent information\nleakage across samples while maintaining full conditioning access. In RLBench\nsimulations, Mini-Diffuser achieves 95\\% of the performance of state-of-the-art\nmulti-task diffusion policies, while using only 5\\% of the training time and\n7\\% of the memory. Real-world experiments further validate that Mini-Diffuser\npreserves the key strengths of diffusion-based policies, including the ability\nto model multimodal action distributions and produce behavior conditioned on\ndiverse perceptual inputs. Code available at\ngithub.com/utomm/mini-diffuse-actor."}
{"id": "2505.09456", "pdf": "https://arxiv.org/pdf/2505.09456", "abs": "https://arxiv.org/abs/2505.09456", "authors": ["Josep Lumbreras", "Ruo Cheng Huang", "Yanglin Hu", "Mile Gu", "Marco Tomamichel"], "title": "Quantum state-agnostic work extraction (almost) without dissipation", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "5 pages+14 pages, 2 figures", "summary": "We investigate work extraction protocols designed to transfer the maximum\npossible energy to a battery using sequential access to $N$ copies of an\nunknown pure qubit state. The core challenge is designing interactions to\noptimally balance two competing goals: charging of the battery optimally using\nthe qubit in hand, and acquiring more information by qubit to improve energy\nharvesting in subsequent rounds. Here, we leverage exploration-exploitation\ntrade-off in reinforcement learning to develop adaptive strategies achieving\nenergy dissipation that scales only poly-logarithmically in $N$. This\nrepresents an exponential improvement over current protocols based on full\nstate tomography."}
{"id": "2505.09471", "pdf": "https://arxiv.org/pdf/2505.09471", "abs": "https://arxiv.org/abs/2505.09471", "authors": ["Xiaoyu Hu", "Gengyu Xue", "Zhenhua Lin", "Yi Yu"], "title": "Fairness-aware Bayes optimal functional classification", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": null, "summary": "Algorithmic fairness has become a central topic in machine learning, and\nmitigating disparities across different subpopulations has emerged as a rapidly\ngrowing research area. In this paper, we systematically study the\nclassification of functional data under fairness constraints, ensuring the\ndisparity level of the classifier is controlled below a pre-specified\nthreshold. We propose a unified framework for fairness-aware functional\nclassification, tackling an infinite-dimensional functional space, addressing\nkey challenges from the absence of density ratios and intractability of\nposterior probabilities, and discussing unique phenomena in functional\nclassification. We further design a post-processing algorithm, Fair Functional\nLinear Discriminant Analysis classifier (Fair-FLDA), which targets at\nhomoscedastic Gaussian processes and achieves fairness via group-wise\nthresholding. Under weak structural assumptions on eigenspace, theoretical\nguarantees on fairness and excess risk controls are established. As a\nbyproduct, our results cover the excess risk control of the standard FLDA as a\nspecial case, which, to the best of our knowledge, is first time seen. Our\ntheoretical findings are complemented by extensive numerical experiments on\nsynthetic and real datasets, highlighting the practicality of our designed\nalgorithm."}
{"id": "2505.09496", "pdf": "https://arxiv.org/pdf/2505.09496", "abs": "https://arxiv.org/abs/2505.09496", "authors": ["Rui Miao", "Babak Shahbaba", "Annie Qu"], "title": "Reinforcement Learning for Individual Optimal Policy from Heterogeneous Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Offline reinforcement learning (RL) aims to find optimal policies in dynamic\nenvironments in order to maximize the expected total rewards by leveraging\npre-collected data. Learning from heterogeneous data is one of the fundamental\nchallenges in offline RL. Traditional methods focus on learning an optimal\npolicy for all individuals with pre-collected data from a single episode or\nhomogeneous batch episodes, and thus, may result in a suboptimal policy for a\nheterogeneous population. In this paper, we propose an individualized offline\npolicy optimization framework for heterogeneous time-stationary Markov decision\nprocesses (MDPs). The proposed heterogeneous model with individual latent\nvariables enables us to efficiently estimate the individual Q-functions, and\nour Penalized Pessimistic Personalized Policy Learning (P4L) algorithm\nguarantees a fast rate on the average regret under a weak partial coverage\nassumption on behavior policies. In addition, our simulation studies and a real\ndata application demonstrate the superior numerical performance of the proposed\nmethod compared with existing methods."}
{"id": "2505.09506", "pdf": "https://arxiv.org/pdf/2505.09506", "abs": "https://arxiv.org/abs/2505.09506", "authors": ["María Alejandra Hernández", "Oscar Rodriguez", "Dae-Jin Lee"], "title": "Deep-SITAR: A SITAR-Based Deep Learning Framework for Growth Curve Modeling via Autoencoders", "categories": ["stat.ML", "cs.LG", "F.2.2; I.2.7"], "comment": "Pre-print", "summary": "Several approaches have been developed to capture the complexity and\nnonlinearity of human growth. One widely used is the Super Imposition by\nTranslation and Rotation (SITAR) model, which has become popular in studies of\nadolescent growth. SITAR is a shape-invariant mixed-effects model that\nrepresents the shared growth pattern of a population using a natural cubic\nspline mean curve while incorporating three subject-specific random effects --\ntiming, size, and growth intensity -- to account for variations among\nindividuals. In this work, we introduce a supervised deep learning framework\nbased on an autoencoder architecture that integrates a deep neural network\n(neural network) with a B-spline model to estimate the SITAR model. In this\napproach, the encoder estimates the random effects for each individual, while\nthe decoder performs a fitting based on B-splines similar to the classic SITAR\nmodel. We refer to this method as the Deep-SITAR model. This innovative\napproach enables the prediction of the random effects of new individuals\nentering a population without requiring a full model re-estimation. As a\nresult, Deep-SITAR offers a powerful approach to predicting growth\ntrajectories, combining the flexibility and efficiency of deep learning with\nthe interpretability of traditional mixed-effects models."}
{"id": "2505.09516", "pdf": "https://arxiv.org/pdf/2505.09516", "abs": "https://arxiv.org/abs/2505.09516", "authors": ["Siyi Wang", "Alexandre Leblanc", "Paul D. McNicholas"], "title": "Depth-Based Local Center Clustering: A Framework for Handling Different Clustering Scenarios", "categories": ["stat.ME", "cs.LG", "stat.AP"], "comment": null, "summary": "Cluster analysis, or clustering, plays a crucial role across numerous\nscientific and engineering domains. Despite the wealth of clustering methods\nproposed over the past decades, each method is typically designed for specific\nscenarios and presents certain limitations in practical applications. In this\npaper, we propose depth-based local center clustering (DLCC). This novel method\nmakes use of data depth, which is known to produce a center-outward ordering of\nsample points in a multivariate space. However, data depth typically fails to\ncapture the multimodal characteristics of {data}, something of the utmost\nimportance in the context of clustering. To overcome this, DLCC makes use of a\nlocal version of data depth that is based on subsets of {data}. From this,\nlocal centers can be identified as well as clusters of varying shapes.\nFurthermore, we propose a new internal metric based on density-based clustering\nto evaluate clustering performance on {non-convex clusters}. Overall, DLCC is a\nflexible clustering approach that seems to overcome some limitations of\ntraditional clustering methods, thereby enhancing data analysis capabilities\nacross a wide range of application scenarios."}
{"id": "2505.09518", "pdf": "https://arxiv.org/pdf/2505.09518", "abs": "https://arxiv.org/abs/2505.09518", "authors": ["Maris F. L. Galesloot", "Roman Andriushchenko", "Milan Češka", "Sebastian Junges", "Nils Jansen"], "title": "\\textsc{rfPG}: Robust Finite-Memory Policy Gradients for Hidden-Model POMDPs", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted for publication at IJCAI 2025", "summary": "Partially observable Markov decision processes (POMDPs) model specific\nenvironments in sequential decision-making under uncertainty. Critically,\noptimal policies for POMDPs may not be robust against perturbations in the\nenvironment. Hidden-model POMDPs (HM-POMDPs) capture sets of different\nenvironment models, that is, POMDPs with a shared action and observation space.\nThe intuition is that the true model is hidden among a set of potential models,\nand it is unknown which model will be the environment at execution time. A\npolicy is robust for a given HM-POMDP if it achieves sufficient performance for\neach of its POMDPs. We compute such robust policies by combining two orthogonal\ntechniques: (1) a deductive formal verification technique that supports\ntractable robust policy evaluation by computing a worst-case POMDP within the\nHM-POMDP and (2) subgradient ascent to optimize the candidate policy for a\nworst-case POMDP. The empirical evaluation shows that, compared to various\nbaselines, our approach (1) produces policies that are more robust and\ngeneralize better to unseen POMDPs and (2) scales to HM-POMDPs that consist of\nover a hundred thousand environments."}
{"id": "2505.09529", "pdf": "https://arxiv.org/pdf/2505.09529", "abs": "https://arxiv.org/abs/2505.09529", "authors": ["Mohamed Moustafa", "Joseph Lemley", "Peter Corcoran"], "title": "Contactless Cardiac Pulse Monitoring Using Event Cameras", "categories": ["cs.CV", "cs.ET", "cs.LG", "eess.IV"], "comment": "This paper is a preprint of a paper submitted to IEEE Access and is\n  currently under review", "summary": "Time event cameras are a novel technology for recording scene information at\nextremely low latency and with low power consumption. Event cameras output a\nstream of events that encapsulate pixel-level light intensity changes within\nthe scene, capturing information with a higher dynamic range and temporal\nresolution than traditional cameras. This study investigates the contact-free\nreconstruction of an individual's cardiac pulse signal from time event\nrecording of their face using a supervised convolutional neural network (CNN)\nmodel. An end-to-end model is trained to extract the cardiac signal from a\ntwo-dimensional representation of the event stream, with model performance\nevaluated based on the accuracy of the calculated heart rate. The experimental\nresults confirm that physiological cardiac information in the facial region is\neffectively preserved within the event stream, showcasing the potential of this\nnovel sensor for remote heart rate monitoring. The model trained on event\nframes achieves a root mean square error (RMSE) of 3.32 beats per minute (bpm)\ncompared to the RMSE of 2.92 bpm achieved by the baseline model trained on\nstandard camera frames. Furthermore, models trained on event frames generated\nat 60 and 120 FPS outperformed the 30 FPS standard camera results, achieving an\nRMSE of 2.54 and 2.13 bpm, respectively."}
{"id": "2505.09546", "pdf": "https://arxiv.org/pdf/2505.09546", "abs": "https://arxiv.org/abs/2505.09546", "authors": ["Yujin Kim", "Nathaniel Chin", "Arnav Vasudev", "Sanjiban Choudhury"], "title": "Distilling Realizable Students from Unrealizable Teachers", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "We study policy distillation under privileged information, where a student\npolicy with only partial observations must learn from a teacher with full-state\naccess. A key challenge is information asymmetry: the student cannot directly\naccess the teacher's state space, leading to distributional shifts and policy\ndegradation. Existing approaches either modify the teacher to produce\nrealizable but sub-optimal demonstrations or rely on the student to explore\nmissing information independently, both of which are inefficient. Our key\ninsight is that the student should strategically interact with the teacher\n--querying only when necessary and resetting from recovery states --to stay on\na recoverable path within its own observation space. We introduce two methods:\n(i) an imitation learning approach that adaptively determines when the student\nshould query the teacher for corrections, and (ii) a reinforcement learning\napproach that selects where to initialize training for efficient exploration.\nWe validate our methods in both simulated and real-world robotic tasks,\ndemonstrating significant improvements over standard teacher-student baselines\nin training efficiency and final performance. The project website is available\nat : https://portal-cornell.github.io/CritiQ_ReTRy/"}
{"id": "2505.09552", "pdf": "https://arxiv.org/pdf/2505.09552", "abs": "https://arxiv.org/abs/2505.09552", "authors": ["Pascal Kündig", "Fabio Sigrist"], "title": "Scalable Computations for Generalized Mixed Effects Models with Crossed Random Effects Using Krylov Subspace Methods", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "Mixed effects models are widely used for modeling data with hierarchically\ngrouped structures and high-cardinality categorical predictor variables.\nHowever, for high-dimensional crossed random effects, current standard\ncomputations relying on Cholesky decompositions can become prohibitively slow.\nIn this work, we present novel Krylov subspace-based methods that address\nseveral existing computational bottlenecks. Among other things, we\ntheoretically analyze and empirically evaluate various preconditioners for the\nconjugate gradient and stochastic Lanczos quadrature methods, derive new\nconvergence results, and develop computationally efficient methods for\ncalculating predictive variances. Extensive experiments using simulated and\nreal-world data sets show that our proposed methods scale much better than\nCholesky-based computations, for instance, achieving a runtime reduction of\napproximately two orders of magnitudes for both estimation and prediction.\nMoreover, our software implementation is up to 10'000 times faster and more\nstable than state-of-the-art implementations such as lme4 and glmmTMB when\nusing default settings. Our methods are implemented in the free C++ software\nlibrary GPBoost with high-level Python and R packages."}
{"id": "2505.09558", "pdf": "https://arxiv.org/pdf/2505.09558", "abs": "https://arxiv.org/abs/2505.09558", "authors": ["Shengpeng Ji", "Tianle Liang", "Yangzhuo Li", "Jialong Zuo", "Minghui Fang", "Jinzheng He", "Yifu Chen", "Zhengqing Liu", "Ziyue Jiang", "Xize Cheng", "Siqi Zheng", "Jin Xu", "Junyang Lin", "Zhou Zhao"], "title": "WavReward: Spoken Dialogue Models With Generalist Reward Evaluators", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.MM", "cs.SD"], "comment": null, "summary": "End-to-end spoken dialogue models such as GPT-4o-audio have recently garnered\nsignificant attention in the speech domain. However, the evaluation of spoken\ndialogue models' conversational performance has largely been overlooked. This\nis primarily due to the intelligent chatbots convey a wealth of non-textual\ninformation which cannot be easily measured using text-based language models\nlike ChatGPT. To address this gap, we propose WavReward, a reward feedback\nmodel based on audio language models that can evaluate both the IQ and EQ of\nspoken dialogue systems with speech input. Specifically, 1) based on audio\nlanguage models, WavReward incorporates the deep reasoning process and the\nnonlinear reward mechanism for post-training. By utilizing multi-sample\nfeedback via the reinforcement learning algorithm, we construct a specialized\nevaluator tailored to spoken dialogue models. 2) We introduce ChatReward-30K, a\npreference dataset used to train WavReward. ChatReward-30K includes both\ncomprehension and generation aspects of spoken dialogue models. These scenarios\nspan various tasks, such as text-based chats, nine acoustic attributes of\ninstruction chats, and implicit chats. WavReward outperforms previous\nstate-of-the-art evaluation models across multiple spoken dialogue scenarios,\nachieving a substantial improvement about Qwen2.5-Omni in objective accuracy\nfrom 55.1$\\%$ to 91.5$\\%$. In subjective A/B testing, WavReward also leads by a\nmargin of 83$\\%$. Comprehensive ablation studies confirm the necessity of each\ncomponent of WavReward. All data and code will be publicly at\nhttps://github.com/jishengpeng/WavReward after the paper is accepted."}
{"id": "2505.09561", "pdf": "https://arxiv.org/pdf/2505.09561", "abs": "https://arxiv.org/abs/2505.09561", "authors": ["Marcel Torne", "Andy Tang", "Yuejiang Liu", "Chelsea Finn"], "title": "Learning Long-Context Diffusion Policies via Past-Token Prediction", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": "Videos are available at https://long-context-dp.github.io", "summary": "Reasoning over long sequences of observations and actions is essential for\nmany robotic tasks. Yet, learning effective long-context policies from\ndemonstrations remains challenging. As context length increases, training\nbecomes increasingly expensive due to rising memory demands, and policy\nperformance often degrades as a result of spurious correlations. Recent methods\ntypically sidestep these issues by truncating context length, discarding\nhistorical information that may be critical for subsequent decisions. In this\npaper, we propose an alternative approach that explicitly regularizes the\nretention of past information. We first revisit the copycat problem in\nimitation learning and identify an opposite challenge in recent diffusion\npolicies: rather than over-relying on prior actions, they often fail to capture\nessential dependencies between past and future actions. To address this, we\nintroduce Past-Token Prediction (PTP), an auxiliary task in which the policy\nlearns to predict past action tokens alongside future ones. This regularization\nsignificantly improves temporal modeling in the policy head, with minimal\nreliance on visual representations. Building on this observation, we further\nintroduce a multistage training strategy: pre-train the visual encoder with\nshort contexts, and fine-tune the policy head using cached long-context\nembeddings. This strategy preserves the benefits of PTP while greatly reducing\nmemory and computational overhead. Finally, we extend PTP into a\nself-verification mechanism at test time, enabling the policy to score and\nselect candidates consistent with past actions during inference. Experiments\nacross four real-world and six simulated tasks demonstrate that our proposed\nmethod improves the performance of long-context diffusion policies by 3x and\naccelerates policy training by more than 10x."}
{"id": "2505.09603", "pdf": "https://arxiv.org/pdf/2505.09603", "abs": "https://arxiv.org/abs/2505.09603", "authors": ["Shivin Dass", "Alaa Khaddaj", "Logan Engstrom", "Aleksander Madry", "Andrew Ilyas", "Roberto Martín-Martín"], "title": "DataMIL: Selecting Data for Robot Imitation Learning with Datamodels", "categories": ["cs.RO", "cs.LG"], "comment": null, "summary": "Recently, the robotics community has amassed ever larger and more diverse\ndatasets to train generalist robot policies. However, while these policies\nachieve strong mean performance across a variety of tasks, they often\nunderperform on individual, specialized tasks and require further tuning on\nnewly acquired task-specific data. Combining task-specific data with carefully\ncurated subsets of large prior datasets via co-training can produce better\nspecialized policies, but selecting data naively may actually harm downstream\nperformance. To address this, we introduce DataMIL, a policy-driven data\nselection framework built on the datamodels paradigm that reasons about data\nselection in an end-to-end manner, using the policy itself to identify which\ndata points will most improve performance. Unlike standard practices that\nfilter data using human notions of quality (e.g., based on semantic or visual\nsimilarity), DataMIL directly optimizes data selection for task success,\nallowing us to select data that enhance the policy while dropping data that\ndegrade it. To avoid performing expensive rollouts in the environment during\nselection, we use a novel surrogate loss function on task-specific data,\nallowing us to use DataMIL in the real world without degrading performance. We\nvalidate our approach on a suite of more than 60 simulation and real-world\nmanipulation tasks - most notably showing successful data selection from the\nOpen X-Embodiment datasets-demonstrating consistent gains in success rates and\nsuperior performance over multiple baselines. Our results underscore the\nimportance of end-to-end, performance-aware data selection for unlocking the\npotential of large prior datasets in robotics. More information at\nhttps://robin-lab.cs.utexas.edu/datamodels4imitation/"}
{"id": "2505.09612", "pdf": "https://arxiv.org/pdf/2505.09612", "abs": "https://arxiv.org/abs/2505.09612", "authors": ["Tathagata Sadhukhan", "Manit Paul", "Raaz Dwivedi"], "title": "Adaptively-weighted Nearest Neighbors for Matrix Completion", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": "25 pages, 6 figures", "summary": "In this technical note, we introduce and analyze AWNN: an adaptively weighted\nnearest neighbor method for performing matrix completion. Nearest neighbor (NN)\nmethods are widely used in missing data problems across multiple disciplines\nsuch as in recommender systems and for performing counterfactual inference in\npanel data settings. Prior works have shown that in addition to being very\nintuitive and easy to implement, NN methods enjoy nice theoretical guarantees.\nHowever, the performance of majority of the NN methods rely on the appropriate\nchoice of the radii and the weights assigned to each member in the nearest\nneighbor set and despite several works on nearest neighbor methods in the past\ntwo decades, there does not exist a systematic approach of choosing the radii\nand the weights without relying on methods like cross-validation. AWNN\naddresses this challenge by judiciously balancing the bias variance trade off\ninherent in weighted nearest-neighbor regression. We provide theoretical\nguarantees for the proposed method under minimal assumptions and support the\ntheory via synthetic experiments."}
{"id": "2505.09649", "pdf": "https://arxiv.org/pdf/2505.09649", "abs": "https://arxiv.org/abs/2505.09649", "authors": ["Abisha Thapa Magar", "Anup Shakya"], "title": "Next Word Suggestion using Graph Neural Network", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Language Modeling is a prevalent task in Natural Language Processing. The\ncurrently existing most recent and most successful language models often tend\nto build a massive model with billions of parameters, feed in a tremendous\namount of text data, and train with enormous computation resources which\nrequire millions of dollars. In this project, we aim to address an important\nsub-task in language modeling, i.e., context embedding. We propose an approach\nto exploit the Graph Convolution operation in GNNs to encode the context and\nuse it in coalition with LSTMs to predict the next word given a local context\nof preceding words. We test this on the custom Wikipedia text corpus using a\nvery limited amount of resources and show that this approach works fairly well\nto predict the next word."}
{"id": "2505.09655", "pdf": "https://arxiv.org/pdf/2505.09655", "abs": "https://arxiv.org/abs/2505.09655", "authors": ["Xiwen Chen", "Wenhui Zhu", "Peijie Qiu", "Xuanzhao Dong", "Hao Wang", "Haiyu Wu", "Huayu Li", "Aristeidis Sotiras", "Yalin Wang", "Abolfazl Razi"], "title": "DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in reinforcement learning for language model post-training,\nsuch as Group Relative Policy Optimization (GRPO), have shown promise in\nlow-resource settings. However, GRPO typically relies on solution-level and\nscalar reward signals that fail to capture the semantic diversity among sampled\ncompletions. This leads to what we identify as a diversity-quality\ninconsistency, where distinct reasoning paths may receive indistinguishable\nrewards. To address this limitation, we propose $\\textit{Diversity-aware Reward\nAdjustment}$ (DRA), a method that explicitly incorporates semantic diversity\ninto the reward computation. DRA uses Submodular Mutual Information (SMI) to\ndownweight redundant completions and amplify rewards for diverse ones. This\nencourages better exploration during learning, while maintaining stable\nexploitation of high-quality samples. Our method integrates seamlessly with\nboth GRPO and its variant DR.~GRPO, resulting in $\\textit{DRA-GRPO}$ and\n$\\textit{DGA-DR.~GRPO}$. We evaluate our method on five mathematical reasoning\nbenchmarks and find that it outperforms recent strong baselines. It achieves\nstate-of-the-art performance with an average accuracy of 58.2%, using only\n7,000 fine-tuning samples and a total training cost of approximately $55. The\ncode is available at https://github.com/xiwenc1/DRA-GRPO."}
{"id": "2505.09662", "pdf": "https://arxiv.org/pdf/2505.09662", "abs": "https://arxiv.org/abs/2505.09662", "authors": ["Philipp Schoenegger", "Francesco Salvi", "Jiacheng Liu", "Xiaoli Nan", "Ramit Debnath", "Barbara Fasolo", "Evelina Leivada", "Gabriel Recchia", "Fritz Günther", "Ali Zarifhonarvar", "Joe Kwon", "Zahoor Ul Islam", "Marco Dehnert", "Daryl Y. H. Lee", "Madeline G. Reinecke", "David G. Kamper", "Mert Kobaş", "Adam Sandford", "Jonas Kgomo", "Luke Hewitt", "Shreya Kapoor", "Kerem Oktar", "Eyup Engin Kucuk", "Bo Feng", "Cameron R. Jones", "Izzy Gainsburg", "Sebastian Olschewski", "Nora Heinzelmann", "Francisco Cruz", "Ben M. Tappin", "Tao Ma", "Peter S. Park", "Rayan Onyonka", "Arthur Hjorth", "Peter Slattery", "Qingcheng Zeng", "Lennart Finke", "Igor Grossmann", "Alessandro Salatiello", "Ezra Karger"], "title": "Large Language Models Are More Persuasive Than Incentivized Human Persuaders", "categories": ["cs.CL", "I.2.7; H.1.2; K.4.1; H.5.2"], "comment": null, "summary": "We directly compare the persuasion capabilities of a frontier large language\nmodel (LLM; Claude Sonnet 3.5) against incentivized human persuaders in an\ninteractive, real-time conversational quiz setting. In this preregistered,\nlarge-scale incentivized experiment, participants (quiz takers) completed an\nonline quiz where persuaders (either humans or LLMs) attempted to persuade quiz\ntakers toward correct or incorrect answers. We find that LLM persuaders\nachieved significantly higher compliance with their directional persuasion\nattempts than incentivized human persuaders, demonstrating superior persuasive\ncapabilities in both truthful (toward correct answers) and deceptive (toward\nincorrect answers) contexts. We also find that LLM persuaders significantly\nincreased quiz takers' accuracy, leading to higher earnings, when steering quiz\ntakers toward correct answers, and significantly decreased their accuracy,\nleading to lower earnings, when steering them toward incorrect answers.\nOverall, our findings suggest that AI's persuasion capabilities already exceed\nthose of humans that have real-money bonuses tied to performance. Our findings\nof increasingly capable AI persuaders thus underscore the urgency of emerging\nalignment and governance frameworks."}
{"id": "2505.09666", "pdf": "https://arxiv.org/pdf/2505.09666", "abs": "https://arxiv.org/abs/2505.09666", "authors": ["Yumin Choi", "Jinheon Baek", "Sung Ju Hwang"], "title": "System Prompt Optimization with Meta-Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance."}
{"id": "2505.09639", "pdf": "https://arxiv.org/pdf/2505.09639", "abs": "https://arxiv.org/abs/2505.09639", "authors": ["Quentin Cohen-Solal"], "title": "Study and improvement of search algorithms in two-players perfect information games", "categories": ["cs.AI", "cs.GT"], "comment": null, "summary": "Games, in their mathematical sense, are everywhere (game industries,\neconomics, defense, education, chemistry, biology, ...).Search algorithms in\ngames are artificial intelligence methods for playing such games.\nUnfortunately, there is no study on these algorithms that evaluates the\ngenerality of their performance. We propose to address this gap in the case of\ntwo-player zero-sum games with perfect information. Furthermore, we propose a\nnew search algorithm and we show that, for a short search time, it outperforms\nall studied algorithms on all games in this large experiment and that, for a\nmedium search time, it outperforms all studied algorithms on 17 of the 22\nstudied games."}
{"id": "2505.09659", "pdf": "https://arxiv.org/pdf/2505.09659", "abs": "https://arxiv.org/abs/2505.09659", "authors": ["Long Chen", "Xiaotian Song", "Yanan Sun"], "title": "LAS: Loss-less ANN-SNN Conversion for Fully Spike-Driven Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Spiking Large Language Models (LLMs) have emerged as an energy-efficient\nalternative to conventional LLMs through their event-driven computation. To\neffectively obtain spiking LLMs, researchers develop different ANN-to-SNN\nconversion methods by leveraging pre-trained ANN parameters while inheriting\nthe energy efficiency of SNN. However, existing conversion methods struggle\nwith extreme activation outliers and incompatible nonlinear operations of\nANN-based LLMs. To address this, we propose a loss-less ANN-SNN conversion for\nfully spike-driven LLMs, termed LAS. Specifically, LAS introduces two novel\nneurons to convert the activation outlier and nonlinear operation of ANN-based\nLLMs. Moreover, LAS tailors the spike-equivalent Transformer components for\nspiking LLMs, which can ensure full spiking conversion without any loss of\nperformance. Experimental results on six language models and two\nvision-language models demonstrate that LAS achieves loss-less conversion.\nNotably, on OPT-66B, LAS even improves the accuracy of 2\\% on the WSC task. In\naddition, the parameter and ablation studies further verify the effectiveness\nof LAS. The source code is available at https://github.com/lc783/LAS"}
{"id": "2505.09746", "pdf": "https://arxiv.org/pdf/2505.09746", "abs": "https://arxiv.org/abs/2505.09746", "authors": ["Xabier Morales", "Ayah Elsayed", "Debbie Zhao", "Filip Loncaric", "Ainhoa Aguado", "Mireia Masias", "Gina Quill", "Marc Ramos", "Ada Doltra", "Ana Garcia", "Marta Sitges", "David Marlevi", "Alistair Young", "Martyn Nash", "Bart Bijnens", "Oscar Camara"], "title": "A Computational Pipeline for Advanced Analysis of 4D Flow MRI in the Left Atrium", "categories": ["cs.CV"], "comment": null, "summary": "The left atrium (LA) plays a pivotal role in modulating left ventricular\nfilling, but our comprehension of its hemodynamics is significantly limited by\nthe constraints of conventional ultrasound analysis. 4D flow magnetic resonance\nimaging (4D Flow MRI) holds promise for enhancing our understanding of atrial\nhemodynamics. However, the low velocities within the LA and the limited spatial\nresolution of 4D Flow MRI make analyzing this chamber challenging. Furthermore,\nthe absence of dedicated computational frameworks, combined with diverse\nacquisition protocols and vendors, complicates gathering large cohorts for\nstudying the prognostic value of hemodynamic parameters provided by 4D Flow\nMRI. In this study, we introduce the first open-source computational framework\ntailored for the analysis of 4D Flow MRI in the LA, enabling comprehensive\nqualitative and quantitative analysis of advanced hemodynamic parameters. Our\nframework proves robust to data from different centers of varying quality,\nproducing high-accuracy automated segmentations (Dice $>$ 0.9 and Hausdorff 95\n$<$ 3 mm), even with limited training data. Additionally, we conducted the\nfirst comprehensive assessment of energy, vorticity, and pressure parameters in\nthe LA across a spectrum of disorders to investigate their potential as\nprognostic biomarkers."}
{"id": "2505.09701", "pdf": "https://arxiv.org/pdf/2505.09701", "abs": "https://arxiv.org/abs/2505.09701", "authors": ["Xin Liu", "Lechen Zhang", "Sheza Munir", "Yiyang Gu", "Lu Wang"], "title": "VeriFact: Enhancing Long-Form Factuality Evaluation with Refined Fact Extraction and Reference Facts", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) excel at generating long-form responses, but\nevaluating their factuality remains challenging due to complex inter-sentence\ndependencies within the generated facts. Prior solutions predominantly follow a\ndecompose-decontextualize-verify pipeline but often fail to capture essential\ncontext and miss key relational facts. In this paper, we introduce VeriFact, a\nfactuality evaluation framework designed to enhance fact extraction by\nidentifying and resolving incomplete and missing facts to support more accurate\nverification results. Moreover, we introduce FactRBench , a benchmark that\nevaluates both precision and recall in long-form model responses, whereas prior\nwork primarily focuses on precision. FactRBench provides reference fact sets\nfrom advanced LLMs and human-written answers, enabling recall assessment.\nEmpirical evaluations show that VeriFact significantly enhances fact\ncompleteness and preserves complex facts with critical relational information,\nresulting in more accurate factuality evaluation. Benchmarking various open-\nand close-weight LLMs on FactRBench indicate that larger models within same\nmodel family improve precision and recall, but high precision does not always\ncorrelate with high recall, underscoring the importance of comprehensive\nfactuality assessment."}
{"id": "2505.09640", "pdf": "https://arxiv.org/pdf/2505.09640", "abs": "https://arxiv.org/abs/2505.09640", "authors": ["Tomás Capdevielle", "Santiago Cifuentes"], "title": "Feature Relevancy, Necessity and Usefulness: Complexity and Algorithms", "categories": ["cs.AI", "68T01", "I.2.0"], "comment": "22 pages, 7 figures", "summary": "Given a classification model and a prediction for some input, there are\nheuristic strategies for ranking features according to their importance in\nregard to the prediction. One common approach to this task is rooted in\npropositional logic and the notion of \\textit{sufficient reason}. Through this\nconcept, the categories of relevant and necessary features were proposed in\norder to identify the crucial aspects of the input. This paper improves the\nexisting techniques and algorithms for deciding which are the relevant and/or\nnecessary features, showing in particular that necessity can be detected\nefficiently in complex models such as neural networks. We also generalize the\nnotion of relevancy and study associated problems. Moreover, we present a new\nglobal notion (i.e. that intends to explain whether a feature is important for\nthe behavior of the model in general, not depending on a particular input) of\n\\textit{usefulness} and prove that it is related to relevancy and necessity.\nFurthermore, we develop efficient algorithms for detecting it in decision trees\nand other more complex models, and experiment on three datasets to analyze its\npractical utility."}
{"id": "2505.09663", "pdf": "https://arxiv.org/pdf/2505.09663", "abs": "https://arxiv.org/abs/2505.09663", "authors": ["Julian Büchel", "Iason Chalas", "Giovanni Acampa", "An Chen", "Omobayode Fagbohungbe", "Sidney Tsai", "Kaoutar El Maghraoui", "Manuel Le Gallo", "Abbas Rahimi", "Abu Sebastian"], "title": "Analog Foundation Models", "categories": ["cs.LG"], "comment": "43 pages, 8 figures, under review", "summary": "Analog in-memory computing (AIMC) is a promising compute paradigm to improve\nspeed and power efficiency of neural network inference beyond the limits of\nconventional von Neumann-based architectures. However, AIMC introduces\nfundamental challenges such as noisy computations and strict constraints on\ninput and output quantization. Because of these constraints and imprecisions,\noff-the-shelf LLMs are not able to achieve 4-bit-level performance when\ndeployed on AIMC-based hardware. While researchers previously investigated\nrecovering this accuracy gap on small, mostly vision-based models, a generic\nmethod applicable to LLMs pre-trained on trillions of tokens does not yet\nexist. In this work, we introduce a general and scalable method to robustly\nadapt LLMs for execution on noisy, low-precision analog hardware. Our approach\nenables state-of-the-art models $\\unicode{x2013}$ including\nPhi-3-mini-4k-instruct and Llama-3.2-1B-Instruct $\\unicode{x2013}$ to retain\nperformance comparable to 4-bit weight, 8-bit activation baselines, despite the\npresence of analog noise and quantization constraints. Additionally, we show\nthat as a byproduct of our training methodology, analog foundation models can\nbe quantized for inference on low-precision digital hardware. Finally, we show\nthat our models also benefit from test-time compute scaling, showing better\nscaling behavior than models trained with 4-bit weight and 8-bit static input\nquantization. Our work bridges the gap between high-capacity LLMs and efficient\nanalog hardware, offering a path toward energy-efficient foundation models.\nCode is available at https://github.com/IBM/analog-foundation-models ."}
{"id": "2505.09827", "pdf": "https://arxiv.org/pdf/2505.09827", "abs": "https://arxiv.org/abs/2505.09827", "authors": ["Julian Tanke", "Takashi Shibuya", "Kengo Uchida", "Koichi Saito", "Yuki Mitsufuji"], "title": "Dyadic Mamba: Long-term Dyadic Human Motion Synthesis", "categories": ["cs.CV"], "comment": "CVPR 2025 HuMoGen Workshop", "summary": "Generating realistic dyadic human motion from text descriptions presents\nsignificant challenges, particularly for extended interactions that exceed\ntypical training sequence lengths. While recent transformer-based approaches\nhave shown promising results for short-term dyadic motion synthesis, they\nstruggle with longer sequences due to inherent limitations in positional\nencoding schemes. In this paper, we introduce Dyadic Mamba, a novel approach\nthat leverages State-Space Models (SSMs) to generate high-quality dyadic human\nmotion of arbitrary length. Our method employs a simple yet effective\narchitecture that facilitates information flow between individual motion\nsequences through concatenation, eliminating the need for complex\ncross-attention mechanisms. We demonstrate that Dyadic Mamba achieves\ncompetitive performance on standard short-term benchmarks while significantly\noutperforming transformer-based approaches on longer sequences. Additionally,\nwe propose a new benchmark for evaluating long-term motion synthesis quality,\nproviding a standardized framework for future research. Our results demonstrate\nthat SSM-based architectures offer a promising direction for addressing the\nchallenging task of long-term dyadic human motion synthesis from text\ndescriptions."}
{"id": "2505.09724", "pdf": "https://arxiv.org/pdf/2505.09724", "abs": "https://arxiv.org/abs/2505.09724", "authors": ["Gino Carmona-Díaz", "William Jiménez-Leal", "María Alejandra Grisales", "Chandra Sripada", "Santiago Amaya", "Michael Inzlicht", "Juan Pablo Bermúdez"], "title": "An AI-Powered Research Assistant in the Lab: A Practical Guide for Text Analysis Through Iterative Collaboration with LLMs", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "31 pages, 1 figure", "summary": "Analyzing texts such as open-ended responses, headlines, or social media\nposts is a time- and labor-intensive process highly susceptible to bias. LLMs\nare promising tools for text analysis, using either a predefined (top-down) or\na data-driven (bottom-up) taxonomy, without sacrificing quality. Here we\npresent a step-by-step tutorial to efficiently develop, test, and apply\ntaxonomies for analyzing unstructured data through an iterative and\ncollaborative process between researchers and LLMs. Using personal goals\nprovided by participants as an example, we demonstrate how to write prompts to\nreview datasets and generate a taxonomy of life domains, evaluate and refine\nthe taxonomy through prompt and direct modifications, test the taxonomy and\nassess intercoder agreements, and apply the taxonomy to categorize an entire\ndataset with high intercoder reliability. We discuss the possibilities and\nlimitations of using LLMs for text analysis."}
{"id": "2505.09737", "pdf": "https://arxiv.org/pdf/2505.09737", "abs": "https://arxiv.org/abs/2505.09737", "authors": ["Osher Elhadad", "Reuth Mirsky"], "title": "General Dynamic Goal Recognition", "categories": ["cs.AI", "cs.RO"], "comment": "Accepted for publication at Generalization in Planning (GenPlan) as\n  part of AAAI 2025 workshops", "summary": "Understanding an agent's intent through its behavior is essential in\nhuman-robot interaction, interactive AI systems, and multi-agent\ncollaborations. This task, known as Goal Recognition (GR), poses significant\nchallenges in dynamic environments where goals are numerous and constantly\nevolving. Traditional GR methods, designed for a predefined set of goals, often\nstruggle to adapt to these dynamic scenarios. To address this limitation, we\nintroduce the General Dynamic GR problem - a broader definition of GR - aimed\nat enabling real-time GR systems and fostering further research in this area.\nExpanding on this foundation, this paper employs a model-free goal-conditioned\nRL approach to enable fast adaptation for GR across various changing tasks."}
{"id": "2505.09702", "pdf": "https://arxiv.org/pdf/2505.09702", "abs": "https://arxiv.org/abs/2505.09702", "authors": ["Yezi Liu", "Prathyush Poduval", "Wenjun Huang", "Yang Ni", "Hanning Chen", "Mohsen Imani"], "title": "Enabling Group Fairness in Graph Unlearning via Bi-level Debiasing", "categories": ["cs.LG"], "comment": null, "summary": "Graph unlearning is a crucial approach for protecting user privacy by erasing\nthe influence of user data on trained graph models. Recent developments in\ngraph unlearning methods have primarily focused on maintaining model prediction\nperformance while removing user information. However, we have observed that\nwhen user information is deleted from the model, the prediction distribution\nacross different sensitive groups often changes. Furthermore, graph models are\nshown to be prone to amplifying biases, making the study of fairness in graph\nunlearning particularly important. This raises the question: Does graph\nunlearning actually introduce bias? Our findings indicate that the predictions\nof post-unlearning models become highly correlated with sensitive attributes,\nconfirming the introduction of bias in the graph unlearning process. To address\nthis issue, we propose a fair graph unlearning method, FGU. To guarantee\nprivacy, FGU trains shard models on partitioned subgraphs, unlearns the\nrequested data from the corresponding subgraphs, and retrains the shard models\non the modified subgraphs. To ensure fairness, FGU employs a bi-level debiasing\nprocess: it first enables shard-level fairness by incorporating a fairness\nregularizer in the shard model retraining, and then achieves global-level\nfairness by aligning all shard models to minimize global disparity. Our\nexperiments demonstrate that FGU achieves superior fairness while maintaining\nprivacy and accuracy. Additionally, FGU is robust to diverse unlearning\nrequests, ensuring fairness and utility performance across various data\ndistributions."}
{"id": "2505.09829", "pdf": "https://arxiv.org/pdf/2505.09829", "abs": "https://arxiv.org/abs/2505.09829", "authors": ["Tushar Kataria", "Shireen Y. Elhabian"], "title": "BoundarySeg:An Embarrassingly Simple Method To Boost Medical Image Segmentation Performance for Low Data Regimes", "categories": ["cs.CV"], "comment": null, "summary": "Obtaining large-scale medical data, annotated or unannotated, is challenging\ndue to stringent privacy regulations and data protection policies. In addition,\nannotating medical images requires that domain experts manually delineate\nanatomical structures, making the process both time-consuming and costly. As a\nresult, semi-supervised methods have gained popularity for reducing annotation\ncosts. However, the performance of semi-supervised methods is heavily dependent\non the availability of unannotated data, and their effectiveness declines when\nsuch data are scarce or absent. To overcome this limitation, we propose a\nsimple, yet effective and computationally efficient approach for medical image\nsegmentation that leverages only existing annotations. We propose BoundarySeg ,\na multi-task framework that incorporates organ boundary prediction as an\nauxiliary task to full organ segmentation, leveraging consistency between the\ntwo task predictions to provide additional supervision. This strategy improves\nsegmentation accuracy, especially in low data regimes, allowing our method to\nachieve performance comparable to or exceeding state-of-the-art semi supervised\napproaches all without relying on unannotated data or increasing computational\ndemands. Code will be released upon acceptance."}
{"id": "2505.09738", "pdf": "https://arxiv.org/pdf/2505.09738", "abs": "https://arxiv.org/abs/2505.09738", "authors": ["Shaurya Sharthak", "Vinayak Pahalwan", "Adithya Kamath", "Adarsh Shirawalmath"], "title": "Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Pretrained language models (LLMs) are often constrained by their fixed\ntokenization schemes, leading to inefficiencies and performance limitations,\nparticularly for multilingual or specialized applications. This tokenizer\nlock-in presents significant challenges. standard methods to overcome this\noften require prohibitive computational resources. Although tokenizer\nreplacement with heuristic initialization aims to reduce this burden, existing\nmethods often require exhaustive residual fine-tuning and still may not fully\npreserve semantic nuances or adequately address the underlying compression\ninefficiencies. Our framework introduces two innovations: first, Tokenadapt, a\nmodel-agnostic tokenizer transplantation method, and second, novel\npre-tokenization learning for multi-word Supertokens to enhance compression and\nreduce fragmentation. Tokenadapt initializes new unique token embeddings via a\nhybrid heuristic that combines two methods: a local estimate based on subword\ndecomposition using the old tokenizer, and a global estimate utilizing the\ntop-k semantically similar tokens from the original vocabulary. This\nmethodology aims to preserve semantics while significantly minimizing\nretraining requirements. Empirical investigations validate both contributions:\nthe transplantation heuristic successfully initializes unique tokens, markedly\noutperforming conventional baselines and sophisticated methods including\nTranstokenizer and ReTok, while our Supertokens achieve notable compression\ngains. Our zero-shot perplexity results demonstrate that the TokenAdapt hybrid\ninitialization consistently yields lower perplexity ratios compared to both\nReTok and TransTokenizer baselines across different base models and newly\ntrained target tokenizers. TokenAdapt typically reduced the overall perplexity\nratio significantly compared to ReTok, yielding at least a 2-fold improvement\nin these aggregate scores."}
{"id": "2505.09755", "pdf": "https://arxiv.org/pdf/2505.09755", "abs": "https://arxiv.org/abs/2505.09755", "authors": ["Amy Rafferty", "Rishi Ramaesh", "Ajitha Rajan"], "title": "Explainability Through Human-Centric Design for XAI in Lung Cancer Detection", "categories": ["cs.AI"], "comment": null, "summary": "Deep learning models have shown promise in lung pathology detection from\nchest X-rays, but widespread clinical adoption remains limited due to opaque\nmodel decision-making. In prior work, we introduced ClinicXAI, a human-centric,\nexpert-guided concept bottleneck model (CBM) designed for interpretable lung\ncancer diagnosis. We now extend that approach and present XpertXAI, a\ngeneralizable expert-driven model that preserves human-interpretable clinical\nconcepts while scaling to detect multiple lung pathologies. Using a\nhigh-performing InceptionV3-based classifier and a public dataset of chest\nX-rays with radiology reports, we compare XpertXAI against leading post-hoc\nexplainability methods and an unsupervised CBM, XCBs. We assess explanations\nthrough comparison with expert radiologist annotations and medical ground\ntruth. Although XpertXAI is trained for multiple pathologies, our expert\nvalidation focuses on lung cancer. We find that existing techniques frequently\nfail to produce clinically meaningful explanations, omitting key diagnostic\nfeatures and disagreeing with radiologist judgments. XpertXAI not only\noutperforms these baselines in predictive accuracy but also delivers\nconcept-level explanations that better align with expert reasoning. While our\nfocus remains on explainability in lung cancer detection, this work illustrates\nhow human-centric model design can be effectively extended to broader\ndiagnostic contexts - offering a scalable path toward clinically meaningful\nexplainable AI in medical diagnostics."}
{"id": "2505.09704", "pdf": "https://arxiv.org/pdf/2505.09704", "abs": "https://arxiv.org/abs/2505.09704", "authors": ["Roberto Pereira", "Fernanda Famá", "Charalampos Kalalas", "Paolo Dini"], "title": "Energy-Efficient Federated Learning for AIoT using Clustering Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While substantial research has been devoted to optimizing model performance,\nconvergence rates, and communication efficiency, the energy implications of\nfederated learning (FL) within Artificial Intelligence of Things (AIoT)\nscenarios are often overlooked in the existing literature. This study examines\nthe energy consumed during the FL process, focusing on three main\nenergy-intensive processes: pre-processing, communication, and local learning,\nall contributing to the overall energy footprint. We rely on the observation\nthat device/client selection is crucial for speeding up the convergence of\nmodel training in a distributed AIoT setting and propose two\nclustering-informed methods. These clustering solutions are designed to group\nAIoT devices with similar label distributions, resulting in clusters composed\nof nearly heterogeneous devices. Hence, our methods alleviate the heterogeneity\noften encountered in real-world distributed learning applications. Throughout\nextensive numerical experimentation, we demonstrate that our clustering\nstrategies typically achieve high convergence rates while maintaining low\nenergy consumption when compared to other recent approaches available in the\nliterature."}
{"id": "2505.09858", "pdf": "https://arxiv.org/pdf/2505.09858", "abs": "https://arxiv.org/abs/2505.09858", "authors": ["Danush Kumar Venkatesh", "Isabel Funke", "Micha Pfeiffer", "Fiona Kolbinger", "Hanna Maria Schmeiser", "Juergen Weitz", "Marius Distler", "Stefanie Speidel"], "title": "Mission Balance: Generating Under-represented Class Samples using Video Diffusion Models", "categories": ["cs.CV"], "comment": "Early accept at MICCAI 2025", "summary": "Computer-assisted interventions can improve intra-operative guidance,\nparticularly through deep learning methods that harness the spatiotemporal\ninformation in surgical videos. However, the severe data imbalance often found\nin surgical video datasets hinders the development of high-performing models.\nIn this work, we aim to overcome the data imbalance by synthesizing surgical\nvideos. We propose a unique two-stage, text-conditioned diffusion-based method\nto generate high-fidelity surgical videos for under-represented classes. Our\napproach conditions the generation process on text prompts and decouples\nspatial and temporal modeling by utilizing a 2D latent diffusion model to\ncapture spatial content and then integrating temporal attention layers to\nensure temporal consistency. Furthermore, we introduce a rejection sampling\nstrategy to select the most suitable synthetic samples, effectively augmenting\nexisting datasets to address class imbalance. We evaluate our method on two\ndownstream tasks-surgical action recognition and intra-operative event\nprediction-demonstrating that incorporating synthetic videos from our approach\nsubstantially enhances model performance. We open-source our implementation at\nhttps://gitlab.com/nct_tso_public/surgvgen."}
{"id": "2505.09794", "pdf": "https://arxiv.org/pdf/2505.09794", "abs": "https://arxiv.org/abs/2505.09794", "authors": ["J. Moreno-Casanova", "J. M. Auñón", "A. Mártinez-Pérez", "M. E. Pérez-Martínez", "M. E. Gas-López"], "title": "Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Research projects, including those focused on cancer, rely on the manual\nextraction of information from clinical reports. This process is time-consuming\nand prone to errors, limiting the efficiency of data-driven approaches in\nhealthcare. To address these challenges, Natural Language Processing (NLP)\noffers an alternative for automating the extraction of relevant data from\nelectronic health records (EHRs). In this study, we focus on lung and breast\ncancer due to their high incidence and the significant impact they have on\npublic health. Early detection and effective data management in both types of\ncancer are crucial for improving patient outcomes. To enhance the accuracy and\nefficiency of data extraction, we utilized GMV's NLP tool uQuery, which excels\nat identifying relevant entities in clinical texts and converting them into\nstandardized formats such as SNOMED and OMOP. uQuery not only detects and\nclassifies entities but also associates them with contextual information,\nincluding negated entities, temporal aspects, and patient-related details. In\nthis work, we explore the use of NLP techniques, specifically Named Entity\nRecognition (NER), to automatically identify and extract key clinical\ninformation from EHRs related to these two cancers. A dataset from Health\nResearch Institute Hospital La Fe (IIS La Fe), comprising 200 annotated breast\ncancer and 400 lung cancer reports, was used, with eight clinical entities\nmanually labeled using the Doccano platform. To perform NER, we fine-tuned the\nbsc-bio-ehr-en3 model, a RoBERTa-based biomedical linguistic model pre-trained\nin Spanish. Fine-tuning was performed using the Transformers architecture,\nenabling accurate recognition of clinical entities in these cancer types. Our\nresults demonstrate strong overall performance, particularly in identifying\nentities like MET and PAT, although challenges remain with less frequent\nentities like EVOL."}
{"id": "2505.09787", "pdf": "https://arxiv.org/pdf/2505.09787", "abs": "https://arxiv.org/abs/2505.09787", "authors": ["Ziruo Yi", "Ting Xiao", "Mark V. Albert"], "title": "A Multimodal Multi-Agent Framework for Radiology Report Generation", "categories": ["cs.AI"], "comment": null, "summary": "Radiology report generation (RRG) aims to automatically produce diagnostic\nreports from medical images, with the potential to enhance clinical workflows\nand reduce radiologists' workload. While recent approaches leveraging\nmultimodal large language models (MLLMs) and retrieval-augmented generation\n(RAG) have achieved strong results, they continue to face challenges such as\nfactual inconsistency, hallucination, and cross-modal misalignment. We propose\na multimodal multi-agent framework for RRG that aligns with the stepwise\nclinical reasoning workflow, where task-specific agents handle retrieval, draft\ngeneration, visual analysis, refinement, and synthesis. Experimental results\ndemonstrate that our approach outperforms a strong baseline in both automatic\nmetrics and LLM-based evaluations, producing more accurate, structured, and\ninterpretable reports. This work highlights the potential of clinically aligned\nmulti-agent frameworks to support explainable and trustworthy clinical AI\napplications."}
{"id": "2505.09710", "pdf": "https://arxiv.org/pdf/2505.09710", "abs": "https://arxiv.org/abs/2505.09710", "authors": ["Konstantinos Fotopoulos", "Petros Maragos"], "title": "Training Deep Morphological Neural Networks as Universal Approximators", "categories": ["cs.LG"], "comment": null, "summary": "We investigate deep morphological neural networks (DMNNs). We demonstrate\nthat despite their inherent non-linearity, activations between layers are\nessential for DMNNs. We then propose several new architectures for DMNNs, each\nwith a different constraint on their parameters. For the first (resp. second)\narchitecture, we work under the constraint that the majority of parameters\n(resp. learnable parameters) should be part of morphological operations. We\nempirically show that our proposed networks can be successfully trained, and\nare more prunable than linear networks. To the best of our knowledge, we are\nthe first to successfully train DMNNs under such constraints, although the\ngeneralization capabilities of our networks remain limited. Finally, we propose\na hybrid network architecture combining linear and morphological layers,\nshowing empirically that the inclusion of morphological layers significantly\naccelerates the convergence of gradient descent with large batches."}
{"id": "2505.09859", "pdf": "https://arxiv.org/pdf/2505.09859", "abs": "https://arxiv.org/abs/2505.09859", "authors": ["Andrew Jun Lee", "Taylor Webb", "Trevor Bihl", "Keith Holyoak", "Hongjing Lu"], "title": "Few-Shot Learning of Visual Compositional Concepts through Probabilistic Schema Induction", "categories": ["cs.CV"], "comment": "Lee, A. J., Webb, T., Bihl, T., Holyoak, K. J., & Lu, H. (2025).\n  Few-shot learning of visual compositional concepts through probabilistic\n  schema induction. In A. Ruggeri, D. Barner, C. Walker, & N. Bramley (Eds.),\n  Proceedings of the 47th Annual Conference of the Cognitive Science Society.\n  Cognitive Science Society", "summary": "The ability to learn new visual concepts from limited examples is a hallmark\nof human cognition. While traditional category learning models represent each\nexample as an unstructured feature vector, compositional concept learning is\nthought to depend on (1) structured representations of examples (e.g., directed\ngraphs consisting of objects and their relations) and (2) the identification of\nshared relational structure across examples through analogical mapping. Here,\nwe introduce Probabilistic Schema Induction (PSI), a prototype model that\nemploys deep learning to perform analogical mapping over structured\nrepresentations of only a handful of examples, forming a compositional concept\ncalled a schema. In doing so, PSI relies on a novel conception of similarity\nthat weighs object-level similarity and relational similarity, as well as a\nmechanism for amplifying relations relevant to classification, analogous to\nselective attention parameters in traditional models. We show that PSI produces\nhuman-like learning performance and outperforms two controls: a prototype model\nthat uses unstructured feature vectors extracted from a deep learning model,\nand a variant of PSI with weaker structured representations. Notably, we find\nthat PSI's human-like performance is driven by an adaptive strategy that\nincreases relational similarity over object-level similarity and upweights the\ncontribution of relations that distinguish classes. These findings suggest that\nstructured representations and analogical mapping are critical to modeling\nrapid human-like learning of compositional visual concepts, and demonstrate how\ndeep learning can be leveraged to create psychological models."}
{"id": "2505.09807", "pdf": "https://arxiv.org/pdf/2505.09807", "abs": "https://arxiv.org/abs/2505.09807", "authors": ["Timour Ichmoukhamedov", "David Martens"], "title": "Exploring the generalization of LLM truth directions on conversational formats", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Several recent works argue that LLMs have a universal truth direction where\ntrue and false statements are linearly separable in the activation space of the\nmodel. It has been demonstrated that linear probes trained on a single hidden\nstate of the model already generalize across a range of topics and might even\nbe used for lie detection in LLM conversations. In this work we explore how\nthis truth direction generalizes between various conversational formats. We\nfind good generalization between short conversations that end on a lie, but\npoor generalization to longer formats where the lie appears earlier in the\ninput prompt. We propose a solution that significantly improves this type of\ngeneralization by adding a fixed key phrase at the end of each conversation.\nOur results highlight the challenges towards reliable LLM lie detectors that\ngeneralize to new settings."}
{"id": "2505.09920", "pdf": "https://arxiv.org/pdf/2505.09920", "abs": "https://arxiv.org/abs/2505.09920", "authors": ["Shan Yang", "Yongli Zhu"], "title": "Offline Reinforcement Learning for Microgrid Voltage Regulation", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore,\n  Apr. 28, 2025", "summary": "This paper presents a study on using different offline reinforcement learning\nalgorithms for microgrid voltage regulation with solar power penetration. When\nenvironment interaction is unviable due to technical or safety reasons, the\nproposed approach can still obtain an applicable model through offline-style\ntraining on a previously collected dataset, lowering the negative impact of\nlacking online environment interactions. Experiment results on the IEEE 33-bus\nsystem demonstrate the feasibility and effectiveness of the proposed approach\non different offline datasets, including the one with merely low-quality\nexperience."}
{"id": "2505.09716", "pdf": "https://arxiv.org/pdf/2505.09716", "abs": "https://arxiv.org/abs/2505.09716", "authors": ["George Dimitriadis. Spyridon Samothrakis"], "title": "Out-of-distribution generalisation is hard: evidence from ARC-like tasks", "categories": ["cs.LG", "cs.AI"], "comment": "Submission to NeurIPS 2025", "summary": "Out-of-distribution (OOD) generalisation is considered a hallmark of human\nand animal intelligence. To achieve OOD through composition, a system must\ndiscover the environment-invariant properties of experienced input-output\nmappings and transfer them to novel inputs. This can be realised if an\nintelligent system can identify appropriate, task-invariant, and composable\ninput features, as well as the composition methods, thus allowing it to act\nbased not on the interpolation between learnt data points but on the\ntask-invariant composition of those features. We propose that in order to\nconfirm that an algorithm does indeed learn compositional structures from data,\nit is not enough to just test on an OOD setup, but one also needs to confirm\nthat the features identified are indeed compositional. We showcase this by\nexploring two tasks with clearly defined OOD metrics that are not OOD solvable\nby three commonly used neural networks: a Multi-Layer Perceptron (MLP), a\nConvolutional Neural Network (CNN), and a Transformer. In addition, we develop\ntwo novel network architectures imbued with biases that allow them to be\nsuccessful in OOD scenarios. We show that even with correct biases and almost\nperfect OOD performance, an algorithm can still fail to learn the correct\nfeatures for compositional generalisation."}
{"id": "2505.09915", "pdf": "https://arxiv.org/pdf/2505.09915", "abs": "https://arxiv.org/abs/2505.09915", "authors": ["Zhe Xin", "Chenyang Wu", "Penghui Huang", "Yanyong Zhang", "Yinian Mao", "Guoquan Huang"], "title": "Large-Scale Gaussian Splatting SLAM", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "The recently developed Neural Radiance Fields (NeRF) and 3D Gaussian\nSplatting (3DGS) have shown encouraging and impressive results for visual SLAM.\nHowever, most representative methods require RGBD sensors and are only\navailable for indoor environments. The robustness of reconstruction in\nlarge-scale outdoor scenarios remains unexplored. This paper introduces a\nlarge-scale 3DGS-based visual SLAM with stereo cameras, termed LSG-SLAM. The\nproposed LSG-SLAM employs a multi-modality strategy to estimate prior poses\nunder large view changes. In tracking, we introduce feature-alignment warping\nconstraints to alleviate the adverse effects of appearance similarity in\nrendering losses. For the scalability of large-scale scenarios, we introduce\ncontinuous Gaussian Splatting submaps to tackle unbounded scenes with limited\nmemory. Loops are detected between GS submaps by place recognition and the\nrelative pose between looped keyframes is optimized utilizing rendering and\nfeature warping losses. After the global optimization of camera poses and\nGaussian points, a structure refinement module enhances the reconstruction\nquality. With extensive evaluations on the EuRoc and KITTI datasets, LSG-SLAM\nachieves superior performance over existing Neural, 3DGS-based, and even\ntraditional approaches. Project page: https://lsg-slam.github.io."}
{"id": "2505.09825", "pdf": "https://arxiv.org/pdf/2505.09825", "abs": "https://arxiv.org/abs/2505.09825", "authors": ["Peiqi Sui", "Juan Diego Rodriguez", "Philippe Laban", "Dean Murphy", "Joseph P. Dexter", "Richard Jean So", "Samuel Baker", "Pramit Chaudhuri"], "title": "KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Each year, tens of millions of essays are written and graded in college-level\nEnglish courses. Students are asked to analyze literary and cultural texts\nthrough a process known as close reading, in which they gather textual details\nto formulate evidence-based arguments. Despite being viewed as a basis for\ncritical thinking and widely adopted as a required element of university\ncoursework, close reading has never been evaluated on large language models\n(LLMs), and multi-discipline benchmarks like MMLU do not include literature as\na subject. To fill this gap, we present KRISTEVA, the first close reading\nbenchmark for evaluating interpretive reasoning, consisting of 1331\nmultiple-choice questions adapted from classroom data. With KRISTEVA, we\npropose three progressively more difficult sets of tasks to approximate\ndifferent elements of the close reading process, which we use to test how well\nLLMs may seem to understand and reason about literary works: 1) extracting\nstylistic features, 2) retrieving relevant contextual information from\nparametric knowledge, and 3) multi-hop reasoning between style and external\ncontexts. Our baseline results find that, while state-of-the-art LLMs possess\nsome college-level close reading competency (accuracy 49.7% - 69.7%), their\nperformances still trail those of experienced human evaluators on 10 out of our\n11 tasks."}
{"id": "2505.09923", "pdf": "https://arxiv.org/pdf/2505.09923", "abs": "https://arxiv.org/abs/2505.09923", "authors": ["Minjung Shin", "Donghyun Kim", "Jeh-Kwang Ryu"], "title": "\"There Is No Such Thing as a Dumb Question,\" But There Are Good Ones", "categories": ["cs.AI"], "comment": "8 pages, 4 figures and 4 tables. This work has been accepted for\n  presentation as a poster with full paper publication at CogSci 2025. This is\n  the final submission", "summary": "Questioning has become increasingly crucial for both humans and artificial\nintelligence, yet there remains limited research comprehensively assessing\nquestion quality. In response, this study defines good questions and presents a\nsystematic evaluation framework. We propose two key evaluation dimensions:\nappropriateness (sociolinguistic competence in context) and effectiveness\n(strategic competence in goal achievement). Based on these foundational\ndimensions, a rubric-based scoring system was developed. By incorporating\ndynamic contextual variables, our evaluation framework achieves structure and\nflexibility through semi-adaptive criteria. The methodology was validated using\nthe CAUS and SQUARE datasets, demonstrating the ability of the framework to\naccess both well-formed and problematic questions while adapting to varied\ncontexts. As we establish a flexible and comprehensive framework for question\nevaluation, this study takes a significant step toward integrating questioning\nbehavior with structured analytical methods grounded in the intrinsic nature of\nquestioning."}
{"id": "2505.09733", "pdf": "https://arxiv.org/pdf/2505.09733", "abs": "https://arxiv.org/abs/2505.09733", "authors": ["Alpaslan Gokcen", "Ali Boyaci"], "title": "Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning (FL) presents an effective solution for collaborative\nmodel training while maintaining data privacy across decentralized client\ndatasets. However, data quality issues such as noisy labels, missing classes,\nand imbalanced distributions significantly challenge its effectiveness. This\nstudy proposes a federated learning methodology that systematically addresses\ndata quality issues, including noise, class imbalance, and missing labels. The\nproposed approach systematically enhances data integrity through adaptive noise\ncleaning, collaborative conditional GAN-based synthetic data generation, and\nrobust federated model training. Experimental evaluations conducted on\nbenchmark datasets (MNIST and Fashion-MNIST) demonstrate significant\nimprovements in federated model performance, particularly macro-F1 Score, under\nvarying noise and class imbalance conditions. Additionally, the proposed\nframework carefully balances computational feasibility and substantial\nperformance gains, ensuring practicality for resource constrained edge devices\nwhile rigorously maintaining data privacy. Our results indicate that this\nmethod effectively mitigates common data quality challenges, providing a\nrobust, scalable, and privacy compliant solution suitable for diverse\nreal-world federated learning scenarios."}
{"id": "2505.09926", "pdf": "https://arxiv.org/pdf/2505.09926", "abs": "https://arxiv.org/abs/2505.09926", "authors": ["Bin-Bin Gao", "Yue Zhu", "Jiangtao Yan", "Yuezhi Cai", "Weixi Zhang", "Meng Wang", "Jun Liu", "Yong Liu", "Lei Wang", "Chengjie Wang"], "title": "AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": "27 pages, 15 figures, 22 tables", "summary": "Universal visual anomaly detection aims to identify anomalies from novel or\nunseen vision domains without additional fine-tuning, which is critical in open\nscenarios. Recent studies have demonstrated that pre-trained vision-language\nmodels like CLIP exhibit strong generalization with just zero or a few normal\nimages. However, existing methods struggle with designing prompt templates,\ncomplex token interactions, or requiring additional fine-tuning, resulting in\nlimited flexibility. In this work, we present a simple yet effective method\ncalled AdaptCLIP based on two key insights. First, adaptive visual and textual\nrepresentations should be learned alternately rather than jointly. Second,\ncomparative learning between query and normal image prompt should incorporate\nboth contextual and aligned residual features, rather than relying solely on\nresidual features. AdaptCLIP treats CLIP models as a foundational service,\nadding only three simple adapters, visual adapter, textual adapter, and\nprompt-query adapter, at its input or output ends. AdaptCLIP supports\nzero-/few-shot generalization across domains and possesses a training-free\nmanner on target domains once trained on a base dataset. AdaptCLIP achieves\nstate-of-the-art performance on 12 anomaly detection benchmarks from industrial\nand medical domains, significantly outperforming existing competitive methods.\nWe will make the code and model of AdaptCLIP available at\nhttps://github.com/gaobb/AdaptCLIP."}
{"id": "2505.09852", "pdf": "https://arxiv.org/pdf/2505.09852", "abs": "https://arxiv.org/abs/2505.09852", "authors": ["Apollinaire Poli Nemkova", "Sarath Chandra Lingareddy", "Sagnik Ray Choudhury", "Mark V. Albert"], "title": "Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance across natural\nlanguage tasks, but their ability to forecast violent conflict remains\nunderexplored. We investigate whether LLMs possess meaningful parametric\nknowledge-encoded in their pretrained weights-to predict conflict escalation\nand fatalities without external data. This is critical for early warning\nsystems, humanitarian planning, and policy-making. We compare this parametric\nknowledge with non-parametric capabilities, where LLMs access structured and\nunstructured context from conflict datasets (e.g., ACLED, GDELT) and recent\nnews reports via Retrieval-Augmented Generation (RAG). Incorporating external\ninformation could enhance model performance by providing up-to-date context\notherwise missing from pretrained weights. Our two-part evaluation framework\nspans 2020-2024 across conflict-prone regions in the Horn of Africa and the\nMiddle East. In the parametric setting, LLMs predict conflict trends and\nfatalities relying only on pretrained knowledge. In the non-parametric setting,\nmodels receive summaries of recent conflict events, indicators, and\ngeopolitical developments. We compare predicted conflict trend labels (e.g.,\nEscalate, Stable Conflict, De-escalate, Peace) and fatalities against\nhistorical data. Our findings highlight the strengths and limitations of LLMs\nfor conflict forecasting and the benefits of augmenting them with structured\nexternal knowledge."}
{"id": "2505.09932", "pdf": "https://arxiv.org/pdf/2505.09932", "abs": "https://arxiv.org/abs/2505.09932", "authors": ["Kevin J McNamara", "Rhea Pritham Marpu"], "title": "Demystifying AI Agents: The Final Generation of Intelligence", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.MA"], "comment": null, "summary": "The trajectory of artificial intelligence (AI) has been one of relentless\nacceleration, evolving from rudimentary rule-based systems to sophisticated,\nautonomous agents capable of complex reasoning and interaction. This whitepaper\nchronicles this remarkable journey, charting the key technological\nmilestones--advancements in prompting, training methodologies, hardware\ncapabilities, and architectural innovations--that have converged to create the\nAI agents of today. We argue that these agents, exemplified by systems like\nOpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in\nAI development, potentially constituting the \"final generation\" of intelligence\nas we currently conceive it. We explore the capabilities and underlying\ntechnologies of these agents, grounded in practical examples, while also\nexamining the profound societal implications and the unprecedented pace of\nprogress that suggests intelligence is now doubling approximately every six\nmonths. The paper concludes by underscoring the critical need for wisdom and\nforesight in navigating the opportunities and challenges presented by this\npowerful new era of intelligence."}
{"id": "2505.09742", "pdf": "https://arxiv.org/pdf/2505.09742", "abs": "https://arxiv.org/abs/2505.09742", "authors": ["Yuan-Hang Zhang", "Massimiliano Di Ventra"], "title": "A Generative Neural Annealer for Black-Box Combinatorial Optimization", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.NE"], "comment": "15 pages, 3 figures", "summary": "We propose a generative, end-to-end solver for black-box combinatorial\noptimization that emphasizes both sample efficiency and solution quality on NP\nproblems. Drawing inspiration from annealing-based algorithms, we treat the\nblack-box objective as an energy function and train a neural network to model\nthe associated Boltzmann distribution. By conditioning on temperature, the\nnetwork captures a continuum of distributions--from near-uniform at high\ntemperatures to sharply peaked around global optima at low\ntemperatures--thereby learning the structure of the energy landscape and\nfacilitating global optimization. When queries are expensive, the\ntemperature-dependent distributions naturally enable data augmentation and\nimprove sample efficiency. When queries are cheap but the problem remains hard,\nthe model learns implicit variable interactions, effectively \"opening\" the\nblack box. We validate our approach on challenging combinatorial tasks under\nboth limited and unlimited query budgets, showing competitive performance\nagainst state-of-the-art black-box optimizers."}
{"id": "2505.09927", "pdf": "https://arxiv.org/pdf/2505.09927", "abs": "https://arxiv.org/abs/2505.09927", "authors": ["Siqi Yin", "Shaolei Liu", "Manning Wang"], "title": "DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Domain adaptation addresses the challenge of model performance degradation\ncaused by domain gaps. In the typical setup for unsupervised domain adaptation,\nlabeled data from a source domain and unlabeled data from a target domain are\nused to train a target model. However, access to labeled source domain data,\nparticularly in medical datasets, can be restricted due to privacy policies. As\na result, research has increasingly shifted to source-free domain adaptation\n(SFDA), which requires only a pretrained model from the source domain and\nunlabeled data from the target domain data for adaptation. Existing SFDA\nmethods often rely on domain-specific image style translation and\nself-supervision techniques to bridge the domain gap and train the target\ndomain model. However, the quality of domain-specific style-translated images\nand pseudo-labels produced by these methods still leaves room for improvement.\nMoreover, training the entire model during adaptation can be inefficient under\nlimited supervision. In this paper, we propose a novel SFDA framework to\naddress these challenges. Specifically, to effectively mitigate the impact of\ndomain gap in the initial training phase, we introduce preadaptation to\ngenerate a preadapted model, which serves as an initialization of target model\nand allows for the generation of high-quality enhanced pseudo-labels without\nintroducing extra parameters. Additionally, we propose a data-dependent\nfrequency prompt to more effectively translate target domain images into a\nsource-like style. To further enhance adaptation, we employ a style-related\nlayer fine-tuning strategy, specifically designed for SFDA, to train the target\nmodel using the prompted target domain images and pseudo-labels. Extensive\nexperiments on cross-modality abdominal and cardiac SFDA segmentation tasks\ndemonstrate that our proposed method outperforms existing state-of-the-art\nmethods."}
{"id": "2505.09902", "pdf": "https://arxiv.org/pdf/2505.09902", "abs": "https://arxiv.org/abs/2505.09902", "authors": ["Martin Capdevila", "Esteban Villa Turek", "Ellen Karina Chumbe Fernandez", "Luis Felipe Polo Galvez", "Luis Cadavid", "Andrea Marroquin", "Rebeca Vargas Quesada", "Johanna Crew", "Nicole Vallejo Galarraga", "Christopher Rodriguez", "Diego Gutierrez", "Radhi Datla"], "title": "Crossing Borders Without Crossing Boundaries: How Sociolinguistic Awareness Can Optimize User Engagement with Localized Spanish AI Models Across Hispanophone Countries", "categories": ["cs.CL"], "comment": null, "summary": "Large language models are, by definition, based on language. In an effort to\nunderscore the critical need for regional localized models, this paper examines\nprimary differences between variants of written Spanish across Latin America\nand Spain, with an in-depth sociocultural and linguistic contextualization\ntherein. We argue that these differences effectively constitute significant\ngaps in the quotidian use of Spanish among dialectal groups by creating\nsociolinguistic dissonances, to the extent that locale-sensitive AI models\nwould play a pivotal role in bridging these divides. In doing so, this approach\ninforms better and more efficient localization strategies that also serve to\nmore adequately meet inclusivity goals, while securing sustainable active daily\nuser growth in a major low-risk investment geographic area. Therefore,\nimplementing at least the proposed five sub variants of Spanish addresses two\nlines of action: to foment user trust and reliance on AI language models while\nalso demonstrating a level of cultural, historical, and sociolinguistic\nawareness that reflects positively on any internationalization strategy."}
{"id": "2505.09970", "pdf": "https://arxiv.org/pdf/2505.09970", "abs": "https://arxiv.org/abs/2505.09970", "authors": ["Mrinal Rawat", "Ambuje Gupta", "Rushil Goomer", "Alessandro Di Bari", "Neha Gupta", "Roberto Pieraccini"], "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "The ReAct (Reasoning + Action) capability in large language models (LLMs) has\nbecome the foundation of modern agentic systems. Recent LLMs, such as\nDeepSeek-R1 and OpenAI o1/o3, exemplify this by emphasizing reasoning through\nthe generation of ample intermediate tokens, which help build a strong premise\nbefore producing the final output tokens. In this paper, we introduce Pre-Act,\na novel approach that enhances the agent's performance by creating a multi-step\nexecution plan along with the detailed reasoning for the given user input. This\nplan incrementally incorporates previous steps and tool outputs, refining\nitself after each step execution until the final response is obtained. Our\napproach is applicable to both conversational and non-conversational agents. To\nmeasure the performance of task-oriented agents comprehensively, we propose a\ntwo-level evaluation framework: (1) turn level and (2) end-to-end. Our\nturn-level evaluation, averaged across five models, shows that our approach,\nPre-Act, outperforms ReAct by 70% in Action Recall on the Almita dataset. While\nthis approach is effective for larger models, smaller models crucial for\npractical applications, where latency and cost are key constraints, often\nstruggle with complex reasoning tasks required for agentic systems. To address\nthis limitation, we fine-tune relatively small models such as Llama 3.1 (8B &\n70B) using the proposed Pre-Act approach. Our experiments show that the\nfine-tuned 70B model outperforms GPT-4, achieving a 69.5% improvement in action\naccuracy (turn-level) and a 28% improvement in goal completion rate\n(end-to-end) on the Almita (out-of-domain) dataset."}
{"id": "2505.09756", "pdf": "https://arxiv.org/pdf/2505.09756", "abs": "https://arxiv.org/abs/2505.09756", "authors": ["Zhaoyang Shi"], "title": "Community-based Multi-Agent Reinforcement Learning with Transfer and Active Exploration", "categories": ["cs.LG", "cs.MA", "math.OC", "stat.ML"], "comment": null, "summary": "We propose a new framework for multi-agent reinforcement learning (MARL),\nwhere the agents cooperate in a time-evolving network with latent community\nstructures and mixed memberships. Unlike traditional neighbor-based or fixed\ninteraction graphs, our community-based framework captures flexible and\nabstract coordination patterns by allowing each agent to belong to multiple\noverlapping communities. Each community maintains shared policy and value\nfunctions, which are aggregated by individual agents according to personalized\nmembership weights. We also design actor-critic algorithms that exploit this\nstructure: agents inherit community-level estimates for policy updates and\nvalue learning, enabling structured information sharing without requiring\naccess to other agents' policies. Importantly, our approach supports both\ntransfer learning by adapting to new agents or tasks via membership estimation,\nand active learning by prioritizing uncertain communities during exploration.\nTheoretically, we establish convergence guarantees under linear function\napproximation for both actor and critic updates. To our knowledge, this is the\nfirst MARL framework that integrates community structure, transferability, and\nactive learning with provable guarantees."}
{"id": "2505.09935", "pdf": "https://arxiv.org/pdf/2505.09935", "abs": "https://arxiv.org/abs/2505.09935", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Quoc Dai Tran"], "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users."}
{"id": "2505.09924", "pdf": "https://arxiv.org/pdf/2505.09924", "abs": "https://arxiv.org/abs/2505.09924", "authors": ["Yidan Wang", "Yubing Ren", "Yanan Cao", "Binxing Fang"], "title": "From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models", "categories": ["cs.CL", "cs.CR"], "comment": null, "summary": "The rise of Large Language Models (LLMs) has heightened concerns about the\nmisuse of AI-generated text, making watermarking a promising solution.\nMainstream watermarking schemes for LLMs fall into two categories: logits-based\nand sampling-based. However, current schemes entail trade-offs among\nrobustness, text quality, and security. To mitigate this, we integrate\nlogits-based and sampling-based schemes, harnessing their respective strengths\nto achieve synergy. In this paper, we propose a versatile symbiotic\nwatermarking framework with three strategies: serial, parallel, and hybrid. The\nhybrid framework adaptively embeds watermarks using token entropy and semantic\nentropy, optimizing the balance between detectability, robustness, text\nquality, and security. Furthermore, we validate our approach through\ncomprehensive experiments on various datasets and models. Experimental results\nindicate that our method outperforms existing baselines and achieves\nstate-of-the-art (SOTA) performance. We believe this framework provides novel\ninsights into diverse watermarking paradigms. Our code is available at\n\\href{https://github.com/redwyd/SymMark}{https://github.com/redwyd/SymMark}."}
{"id": "2505.10034", "pdf": "https://arxiv.org/pdf/2505.10034", "abs": "https://arxiv.org/abs/2505.10034", "authors": ["Changzeng Fu", "Zelin Fu", "Xinhe Kuang", "Jiacheng Dong", "Qi Zhang", "Kaifeng Su", "Yikai Su", "Wenbo Shi", "Junfeng Yao", "Yuliang Zhao", "Shiqi Zhao", "Jiadong Wang", "Siyang Song", "Chaoran Liu", "Yuichiro Yoshikawa", "Björn Schuller", "Hiroshi Ishiguro"], "title": "The First MPDD Challenge: Multimodal Personality-aware Depression Detection", "categories": ["cs.AI", "68T07", "I.2.0; H.5.1"], "comment": "This paper has been accepted as part of the MPDD Challenge in the\n  ACMMM 2025 Grand Challenge", "summary": "Depression is a widespread mental health issue affecting diverse age groups,\nwith notable prevalence among college students and the elderly. However,\nexisting datasets and detection methods primarily focus on young adults,\nneglecting the broader age spectrum and individual differences that influence\ndepression manifestation. Current approaches often establish a direct mapping\nbetween multimodal data and depression indicators, failing to capture the\ncomplexity and diversity of depression across individuals. This challenge\nincludes two tracks based on age-specific subsets: Track 1 uses the\nMPDD-Elderly dataset for detecting depression in older adults, and Track 2 uses\nthe MPDD-Young dataset for detecting depression in younger participants. The\nMultimodal Personality-aware Depression Detection (MPDD) Challenge aims to\naddress this gap by incorporating multimodal data alongside individual\ndifference factors. We provide a baseline model that fuses audio and video\nmodalities with individual difference information to detect depression\nmanifestations in diverse populations. This challenge aims to promote the\ndevelopment of more personalized and accurate de pression detection methods,\nadvancing mental health research and fostering inclusive detection systems.\nMore details are available on the official challenge website:\nhttps://hacilab.github.io/MPDDChallenge.github.io."}
{"id": "2505.09768", "pdf": "https://arxiv.org/pdf/2505.09768", "abs": "https://arxiv.org/abs/2505.09768", "authors": ["Xiukun Wei", "Xueru Zhang"], "title": "Self-Consuming Generative Models with Adversarially Curated Data", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in generative models have made it increasingly difficult to\ndistinguish real data from model-generated synthetic data. Using synthetic data\nfor successive training of future model generations creates \"self-consuming\nloops\", which may lead to model collapse or training instability. Furthermore,\nsynthetic data is often subject to human feedback and curated by users based on\ntheir preferences. Ferbach et al. (2024) recently showed that when data is\ncurated according to user preferences, the self-consuming retraining loop\ndrives the model to converge toward a distribution that optimizes those\npreferences. However, in practice, data curation is often noisy or\nadversarially manipulated. For example, competing platforms may recruit\nmalicious users to adversarially curate data and disrupt rival models. In this\npaper, we study how generative models evolve under self-consuming retraining\nloops with noisy and adversarially curated data. We theoretically analyze the\nimpact of such noisy data curation on generative models and identify conditions\nfor the robustness of the retraining process. Building on this analysis, we\ndesign attack algorithms for competitive adversarial scenarios, where a\nplatform with a limited budget employs malicious users to misalign a rival's\nmodel from actual user preferences. Experiments on both synthetic and\nreal-world datasets demonstrate the effectiveness of the proposed algorithms."}
{"id": "2505.09939", "pdf": "https://arxiv.org/pdf/2505.09939", "abs": "https://arxiv.org/abs/2505.09939", "authors": ["Zhe Shan", "Lei Zhou", "Liu Mao", "Shaofan Chen", "Chuanqiu Ren", "Xia Xie"], "title": "Non-Registration Change Detection: A Novel Change Detection Task and Benchmark Dataset", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted to IGARSS 2025", "summary": "In this study, we propose a novel remote sensing change detection task,\nnon-registration change detection, to address the increasing number of\nemergencies such as natural disasters, anthropogenic accidents, and military\nstrikes. First, in light of the limited discourse on the issue of\nnon-registration change detection, we systematically propose eight scenarios\nthat could arise in the real world and potentially contribute to the occurrence\nof non-registration problems. Second, we develop distinct image transformation\nschemes tailored to various scenarios to convert the available registration\nchange detection dataset into a non-registration version. Finally, we\ndemonstrate that non-registration change detection can cause catastrophic\ndamage to the state-of-the-art methods. Our code and dataset are available at\nhttps://github.com/ShanZard/NRCD."}
{"id": "2505.09930", "pdf": "https://arxiv.org/pdf/2505.09930", "abs": "https://arxiv.org/abs/2505.09930", "authors": ["Zixiao Zhu", "Hanzhang Zhou", "Zijian Feng", "Tianjiao Li", "Chua Jia Jim Deryl", "Mak Lee Onn", "Gee Wah Ng", "Kezhi Mao"], "title": "Rethinking Prompt Optimizers: From Prompt Merits to Optimization", "categories": ["cs.CL"], "comment": "20 pages, 14 figures", "summary": "Prompt optimization (PO) offers a practical alternative to fine-tuning large\nlanguage models (LLMs), enabling performance improvements without altering\nmodel weights. Existing methods typically rely on advanced, large-scale LLMs\nlike GPT-4 to generate optimized prompts. However, due to limited downward\ncompatibility, verbose, instruction-heavy prompts from advanced LLMs can\noverwhelm lightweight inference models and degrade response quality. In this\nwork, we rethink prompt optimization through the lens of interpretable design.\nWe first identify a set of model-agnostic prompt quality merits and empirically\nvalidate their effectiveness in enhancing prompt and response quality. We then\nintroduce MePO, a merit-guided, lightweight, and locally deployable prompt\noptimizer trained on our preference dataset built from merit-aligned prompts\ngenerated by a lightweight LLM. Unlike prior work, MePO avoids online\noptimization reliance, reduces cost and privacy concerns, and, by learning\nclear, interpretable merits, generalizes effectively to both large-scale and\nlightweight inference models. Experiments demonstrate that MePO achieves better\nresults across diverse tasks and model types, offering a scalable and robust\nsolution for real-world deployment. Our model and dataset are available at:\nhttps://github.com/MidiyaZhu/MePO"}
{"id": "2505.10074", "pdf": "https://arxiv.org/pdf/2505.10074", "abs": "https://arxiv.org/abs/2505.10074", "authors": ["Mohamed Abdelmagied", "Mohamed Amine Chatti", "Shoeb Joarder", "Qurat Ul Ain", "Rawaa Alatrash"], "title": "Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs", "categories": ["cs.AI", "cs.CY"], "comment": "Accepted at EMOOCs 2025", "summary": "Massive Open Online Courses (MOOCs) lack direct interaction between learners\nand instructors, making it challenging for learners to understand new knowledge\nconcepts. Recently, learners have increasingly used Large Language Models\n(LLMs) to support them in acquiring new knowledge. However, LLMs are prone to\nhallucinations which limits their reliability. Retrieval-Augmented Generation\n(RAG) addresses this issue by retrieving relevant documents before generating a\nresponse. However, the application of RAG across different MOOCs is limited by\nunstructured learning material. Furthermore, current RAG systems do not\nactively guide learners toward their learning needs. To address these\nchallenges, we propose a Graph RAG pipeline that leverages Educational\nKnowledge Graphs (EduKGs) and Personal Knowledge Graphs (PKGs) to guide\nlearners to understand knowledge concepts in the MOOC platform CourseMapper.\nSpecifically, we implement (1) a PKG-based Question Generation method to\nrecommend personalized questions for learners in context, and (2) an\nEduKG-based Question Answering method that leverages the relationships between\nknowledge concepts in the EduKG to answer learner selected questions. To\nevaluate both methods, we conducted a study with 3 expert instructors on 3\ndifferent MOOCs in the MOOC platform CourseMapper. The results of the\nevaluation show the potential of Graph RAG to empower learners to understand\nnew knowledge concepts in a personalized learning experience."}
{"id": "2505.09792", "pdf": "https://arxiv.org/pdf/2505.09792", "abs": "https://arxiv.org/abs/2505.09792", "authors": ["Michael Kamfonas"], "title": "Interim Report on Human-Guided Adaptive Hyperparameter Optimization with Multi-Fidelity Sprints", "categories": ["cs.LG"], "comment": null, "summary": "This case study applies a phased hyperparameter optimization process to\ncompare multitask natural language model variants that utilize multiphase\nlearning rate scheduling and optimizer parameter grouping. We employ short,\nBayesian optimization sessions that leverage multi-fidelity, hyperparameter\nspace pruning, progressive halving, and a degree of human guidance. We utilize\nthe Optuna TPE sampler and Hyperband pruner, as well as the Scikit-Learn\nGaussian process minimization. Initially, we use efficient low-fidelity sprints\nto prune the hyperparameter space. Subsequent sprints progressively increase\ntheir model fidelity and employ hyperband pruning for efficiency. A second\naspect of our approach is using a meta-learner to tune threshold values to\nresolve classification probabilities during inference. We demonstrate our\nmethod on a collection of variants of the 2021 Joint Entity and Relation\nExtraction model proposed by Eberts and Ulges."}
{"id": "2505.09943", "pdf": "https://arxiv.org/pdf/2505.09943", "abs": "https://arxiv.org/abs/2505.09943", "authors": ["Jiakun Deng", "Kexuan Li", "Xingye Cui", "Jiaxuan Li", "Chang Long", "Tian Pu", "Zhenming Peng"], "title": "CSPENet: Contour-Aware and Saliency Priors Embedding Network for Infrared Small Target Detection", "categories": ["cs.CV"], "comment": null, "summary": "Infrared small target detection (ISTD) plays a critical role in a wide range\nof civilian and military applications. Existing methods suffer from\ndeficiencies in the localization of dim targets and the perception of contour\ninformation under dense clutter environments, severely limiting their detection\nperformance. To tackle these issues, we propose a contour-aware and saliency\npriors embedding network (CSPENet) for ISTD. We first design a\nsurround-convergent prior extraction module (SCPEM) that effectively captures\nthe intrinsic characteristic of target contour pixel gradients converging\ntoward their center. This module concurrently extracts two collaborative\npriors: a boosted saliency prior for accurate target localization and\nmulti-scale structural priors for comprehensively enriching contour detail\nrepresentation. Building upon this, we propose a dual-branch priors embedding\narchitecture (DBPEA) that establishes differentiated feature fusion pathways,\nembedding these two priors at optimal network positions to achieve performance\nenhancement. Finally, we develop an attention-guided feature enhancement module\n(AGFEM) to refine feature representations and improve saliency estimation\naccuracy. Experimental results on public datasets NUDT-SIRST, IRSTD-1k, and\nNUAA-SIRST demonstrate that our CSPENet outperforms other state-of-the-art\nmethods in detection performance. The code is available at\nhttps://github.com/IDIP2025/CSPENet."}
{"id": "2505.09945", "pdf": "https://arxiv.org/pdf/2505.09945", "abs": "https://arxiv.org/abs/2505.09945", "authors": ["Deeksha Prahlad", "Chanhee Lee", "Dongha Kim", "Hokeun Kim"], "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)", "summary": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time."}
{"id": "2505.10093", "pdf": "https://arxiv.org/pdf/2505.10093", "abs": "https://arxiv.org/abs/2505.10093", "authors": ["Hsuan-Lei Shao"], "title": "From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI", "categories": ["cs.AI", "cs.CL", "I.2.4; H.3.3; J.5"], "comment": "4 pages, 4 figures", "summary": "Taiwanese China Studies (CS) has developed into a rich, interdisciplinary\nresearch field shaped by the unique geopolitical position and long standing\nacademic engagement with Mainland China. This study responds to the growing\nneed to systematically revisit and reorganize decades of Taiwan based CS\nscholarship by proposing an AI assisted approach that transforms unstructured\nacademic texts into structured, interactive knowledge representations. We apply\ngenerative AI (GAI) techniques and large language models (LLMs) to extract and\nstandardize entity relation triples from 1,367 peer reviewed CS articles\npublished between 1996 and 2019. These triples are then visualized through a\nlightweight D3.js based system, forming the foundation of a domain specific\nknowledge graph and vector database for the field. This infrastructure allows\nusers to explore conceptual nodes and semantic relationships across the corpus,\nrevealing previously uncharted intellectual trajectories, thematic clusters,\nand research gaps. By decomposing textual content into graph structured\nknowledge units, our system enables a paradigm shift from linear text\nconsumption to network based knowledge navigation. In doing so, it enhances\nscholarly access to CS literature while offering a scalable, data driven\nalternative to traditional ontology construction. This work not only\ndemonstrates how generative AI can augment area studies and digital humanities\nbut also highlights its potential to support a reimagined scholarly\ninfrastructure for regional knowledge systems."}
{"id": "2505.09810", "pdf": "https://arxiv.org/pdf/2505.09810", "abs": "https://arxiv.org/abs/2505.09810", "authors": ["Daniel Waddington", "Cornel Constantinescu"], "title": "Lossless Compression for LLM Tensor Incremental Snapshots", "categories": ["cs.LG"], "comment": null, "summary": "During the training of Large Language Models (LLMs), tensor data is\nperiodically \"checkpointed\" to persistent storage to allow recovery of work\ndone in the event of failure. The volume of data that must be copied during\neach checkpoint, even when using reduced-precision representations such as\nbfloat16, often reaches hundreds of gigabytes. Furthermore, the data must be\nmoved across a network and written to a storage system before the next epoch\noccurs. With a view to ultimately building an optimized checkpointing solution,\nthis paper presents experimental analysis of checkpoint data used to derive a\ndesign that maximizes the use of lossless compression to reduce the volume of\ndata. We examine how tensor data and its compressibility evolve during model\ntraining and evaluate the efficacy of existing common off-the-shelf general\npurpose compression engines combined with known data optimization techniques\nsuch as byte-grouping and incremental delta compression.\n  Leveraging our analysis we have built an effective compression solution,\nknown as Language Model Compressor (LMC), which is based on byte-grouping and\nHuffman encoding. LMC offers more compression performance than the best\nalternative (BZ2) but with an order-of-magnitude reduction in the time needed\nto perform the compression. We show that a 16-core parallel implementation of\nLMC can attain compression and decompression throughput of 2.78 GiB/s and 3.76\nGiB/s respectively. This increase in performance ultimately reduces the CPU\nresources needed and provides more time to copy the data to the storage system\nbefore the next epoch thus allowing for higher-frequency checkpoints."}
{"id": "2505.09965", "pdf": "https://arxiv.org/pdf/2505.09965", "abs": "https://arxiv.org/abs/2505.09965", "authors": ["Hao Yang", "Tao Tan", "Shuai Tan", "Weiqin Yang", "Kunyan Cai", "Calvin Chen", "Yue Sun"], "title": "MambaControl: Anatomy Graph-Enhanced Mamba ControlNet with Fourier Refinement for Diffusion-Based Disease Trajectory Prediction", "categories": ["cs.CV"], "comment": null, "summary": "Modelling disease progression in precision medicine requires capturing\ncomplex spatio-temporal dynamics while preserving anatomical integrity.\nExisting methods often struggle with longitudinal dependencies and structural\nconsistency in progressive disorders. To address these limitations, we\nintroduce MambaControl, a novel framework that integrates selective state-space\nmodelling with diffusion processes for high-fidelity prediction of medical\nimage trajectories. To better capture subtle structural changes over time while\nmaintaining anatomical consistency, MambaControl combines Mamba-based\nlong-range modelling with graph-guided anatomical control to more effectively\nrepresent anatomical correlations. Furthermore, we introduce Fourier-enhanced\nspectral graph representations to capture spatial coherence and multiscale\ndetail, enabling MambaControl to achieve state-of-the-art performance in\nAlzheimer's disease prediction. Quantitative and regional evaluations\ndemonstrate improved progression prediction quality and anatomical fidelity,\nhighlighting its potential for personalised prognosis and clinical decision\nsupport."}
{"id": "2505.10013", "pdf": "https://arxiv.org/pdf/2505.10013", "abs": "https://arxiv.org/abs/2505.10013", "authors": ["Lake Yin", "Fan Huang"], "title": "DIF: A Framework for Benchmarking and Verifying Implicit Bias in LLMs", "categories": ["cs.CL"], "comment": "7 pages, 1 figure", "summary": "As Large Language Models (LLMs) have risen in prominence over the past few\nyears, there has been concern over the potential biases in LLMs inherited from\nthe training data. Previous studies have examined how LLMs exhibit implicit\nbias, such as when response generation changes when different social contexts\nare introduced. We argue that this implicit bias is not only an ethical, but\nalso a technical issue, as it reveals an inability of LLMs to accommodate\nextraneous information. However, unlike other measures of LLM intelligence,\nthere are no standard methods to benchmark this specific subset of LLM bias. To\nbridge this gap, we developed a method for calculating an easily interpretable\nbenchmark, DIF (Demographic Implicit Fairness), by evaluating preexisting LLM\nlogic and math problem datasets with sociodemographic personas. We demonstrate\nthat this method can statistically validate the presence of implicit bias in\nLLM behavior and find an inverse trend between question answering accuracy and\nimplicit bias, supporting our argument."}
{"id": "2505.10188", "pdf": "https://arxiv.org/pdf/2505.10188", "abs": "https://arxiv.org/abs/2505.10188", "authors": ["Felix Liedeker", "Olivia Sanchez-Graillet", "Moana Seidler", "Christian Brandt", "Jörg Wellmer", "Philipp Cimiano"], "title": "A User Study Evaluating Argumentative Explanations in Diagnostic Decision Support", "categories": ["cs.AI"], "comment": "Presented at 'The First Workshop on Natural Language Argument-Based\n  Explanations', co-located with ECAI 2024", "summary": "As the field of healthcare increasingly adopts artificial intelligence, it\nbecomes important to understand which types of explanations increase\ntransparency and empower users to develop confidence and trust in the\npredictions made by machine learning (ML) systems. In shared decision-making\nscenarios where doctors cooperate with ML systems to reach an appropriate\ndecision, establishing mutual trust is crucial. In this paper, we explore\ndifferent approaches to generating explanations in eXplainable AI (XAI) and\nmake their underlying arguments explicit so that they can be evaluated by\nmedical experts. In particular, we present the findings of a user study\nconducted with physicians to investigate their perceptions of various types of\nAI-generated explanations in the context of diagnostic decision support. The\nstudy aims to identify the most effective and useful explanations that enhance\nthe diagnostic process. In the study, medical doctors filled out a survey to\nassess different types of explanations. Further, an interview was carried out\npost-survey to gain qualitative insights on the requirements of explanations\nincorporated in diagnostic decision support. Overall, the insights gained from\nthis study contribute to understanding the types of explanations that are most\neffective."}
{"id": "2505.09812", "pdf": "https://arxiv.org/pdf/2505.09812", "abs": "https://arxiv.org/abs/2505.09812", "authors": ["Anastasija Tashkova", "Stefan Eftimov", "Bojan Ristov", "Slobodan Kalajdziski"], "title": "Comparative Analysis of Stroke Prediction Models Using Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "Stroke remains one of the most critical global health challenges, ranking as\nthe second leading cause of death and the third leading cause of disability\nworldwide. This study explores the effectiveness of machine learning algorithms\nin predicting stroke risk using demographic, clinical, and lifestyle data from\nthe Stroke Prediction Dataset. By addressing key methodological challenges such\nas class imbalance and missing data, we evaluated the performance of multiple\nmodels, including Logistic Regression, Random Forest, and XGBoost. Our results\ndemonstrate that while these models achieve high accuracy, sensitivity remains\na limiting factor for real-world clinical applications. In addition, we\nidentify the most influential predictive features and propose strategies to\nimprove machine learning-based stroke prediction. These findings contribute to\nthe development of more reliable and interpretable models for the early\nassessment of stroke risk."}
{"id": "2505.09967", "pdf": "https://arxiv.org/pdf/2505.09967", "abs": "https://arxiv.org/abs/2505.09967", "authors": ["Liqian Deng"], "title": "TKFNet: Learning Texture Key Factor Driven Feature for Facial Expression Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Facial expression recognition (FER) in the wild remains a challenging task\ndue to the subtle and localized nature of expression-related features, as well\nas the complex variations in facial appearance. In this paper, we introduce a\nnovel framework that explicitly focuses on Texture Key Driver Factors (TKDF),\nlocalized texture regions that exhibit strong discriminative power across\nemotional categories. By carefully observing facial image patterns, we identify\nthat certain texture cues, such as micro-changes in skin around the brows,\neyes, and mouth, serve as primary indicators of emotional dynamics. To\neffectively capture and leverage these cues, we propose a FER architecture\ncomprising a Texture-Aware Feature Extractor (TAFE) and Dual Contextual\nInformation Filtering (DCIF). TAFE employs a ResNet-based backbone enhanced\nwith multi-branch attention to extract fine-grained texture representations,\nwhile DCIF refines these features by filtering context through adaptive pooling\nand attention mechanisms. Experimental results on RAF-DB and KDEF datasets\ndemonstrate that our method achieves state-of-the-art performance, verifying\nthe effectiveness and robustness of incorporating TKDFs into FER pipelines."}
{"id": "2505.10063", "pdf": "https://arxiv.org/pdf/2505.10063", "abs": "https://arxiv.org/abs/2505.10063", "authors": ["Han Peng", "Jinhao Jiang", "Zican Dong", "Wayne Xin Zhao", "Lei Fang"], "title": "CAFE: Retrieval Head-based Coarse-to-Fine Information Seeking to Enhance Multi-Document QA Capability", "categories": ["cs.CL"], "comment": null, "summary": "Advancements in Large Language Models (LLMs) have extended their input\ncontext length, yet they still struggle with retrieval and reasoning in\nlong-context inputs. Existing methods propose to utilize the prompt strategy\nand retrieval head to alleviate this limitation. However, they still face\nchallenges in balancing retrieval precision and recall, impacting their\nefficacy in answering questions. To address this, we introduce $\\textbf{CAFE}$,\na two-stage coarse-to-fine method to enhance multi-document question-answering\ncapacities. By gradually eliminating the negative impacts of background and\ndistracting documents, CAFE makes the responses more reliant on the evidence\ndocuments. Initially, a coarse-grained filtering method leverages retrieval\nheads to identify and rank relevant documents. Then, a fine-grained steering\nmethod guides attention to the most relevant content. Experiments across\nbenchmarks show CAFE outperforms baselines, achieving up to 22.1% and 13.7%\nSubEM improvement over SFT and RAG methods on the Mistral model, respectively."}
{"id": "2505.10278", "pdf": "https://arxiv.org/pdf/2505.10278", "abs": "https://arxiv.org/abs/2505.10278", "authors": ["Taian Guo", "Haiyang Shen", "Jinsheng Huang", "Zhengyang Mao", "Junyu Luo", "Zhuoru Chen", "Xuhui Liu", "Bingyu Xia", "Luchen Liu", "Yun Ma", "Ming Zhang"], "title": "MASS: Multi-Agent Simulation Scaling for Portfolio Construction", "categories": ["cs.AI"], "comment": null, "summary": "LLM-based multi-agent has gained significant attention for their potential in\nsimulation and enhancing performance. However, existing works are limited to\npure simulations or are constrained by predefined workflows, restricting their\napplicability and effectiveness. In this paper, we introduce the Multi-Agent\nScaling Simulation (MASS) for portfolio construction. MASS achieves stable and\ncontinuous excess returns by progressively increasing the number of agents for\nlarge-scale simulations to gain a superior understanding of the market and\noptimizing agent distribution end-to-end through a reverse optimization\nprocess, rather than relying on a fixed workflow. We demonstrate its\nsuperiority through performance experiments, ablation studies, backtesting\nexperiments, experiments on updated data and stock pools, scaling experiments,\nparameter sensitivity experiments, and visualization experiments, conducted in\ncomparison with 6 state-of-the-art baselines on 3 challenging A-share stock\npools. We expect the paradigm established by MASS to expand to other tasks with\nsimilar characteristics. The implementation of MASS has been open-sourced at\nhttps://github.com/gta0804/MASS."}
{"id": "2505.09820", "pdf": "https://arxiv.org/pdf/2505.09820", "abs": "https://arxiv.org/abs/2505.09820", "authors": ["Sajib Biswas", "Mao Nishino", "Samuel Jacob Chacko", "Xiuwen Liu"], "title": "Adversarial Attack on Large Language Models using Exponentiated Gradient Descent", "categories": ["cs.LG"], "comment": "Accepted to International Joint Conference on Neural Networks (IJCNN)\n  2025", "summary": "As Large Language Models (LLMs) are widely used, understanding them\nsystematically is key to improving their safety and realizing their full\npotential. Although many models are aligned using techniques such as\nreinforcement learning from human feedback (RLHF), they are still vulnerable to\njailbreaking attacks. Some of the existing adversarial attack methods search\nfor discrete tokens that may jailbreak a target model while others try to\noptimize the continuous space represented by the tokens of the model's\nvocabulary. While techniques based on the discrete space may prove to be\ninefficient, optimization of continuous token embeddings requires projections\nto produce discrete tokens, which might render them ineffective. To fully\nutilize the constraints and the structures of the space, we develop an\nintrinsic optimization technique using exponentiated gradient descent with the\nBregman projection method to ensure that the optimized one-hot encoding always\nstays within the probability simplex. We prove the convergence of the technique\nand implement an efficient algorithm that is effective in jailbreaking several\nwidely used LLMs. We demonstrate the efficacy of the proposed technique using\nfive open-source LLMs on four openly available datasets. The results show that\nthe technique achieves a higher success rate with great efficiency compared to\nthree other state-of-the-art jailbreaking techniques. The source code for our\nimplementation is available at:\nhttps://github.com/sbamit/Exponentiated-Gradient-Descent-LLM-Attack"}
{"id": "2505.09971", "pdf": "https://arxiv.org/pdf/2505.09971", "abs": "https://arxiv.org/abs/2505.09971", "authors": ["Yuan Gao", "Shaobo Xia", "Sheng Nie", "Cheng Wang", "Xiaohuan Xi", "Bisheng Yang"], "title": "APCoTTA: Continual Test-Time Adaptation for Semantic Segmentation of Airborne LiDAR Point Clouds", "categories": ["cs.CV"], "comment": "18 pages,12 figures", "summary": "Airborne laser scanning (ALS) point cloud segmentation is a fundamental task\nfor large-scale 3D scene understanding. In real-world applications, models are\ntypically fixed after training. However, domain shifts caused by changes in the\nenvironment, sensor types, or sensor degradation often lead to a decline in\nmodel performance. Continuous Test-Time Adaptation (CTTA) offers a solution by\nadapting a source-pretrained model to evolving, unlabeled target domains.\nDespite its potential, research on ALS point clouds remains limited, facing\nchallenges such as the absence of standardized datasets and the risk of\ncatastrophic forgetting and error accumulation during prolonged adaptation. To\ntackle these challenges, we propose APCoTTA, the first CTTA method tailored for\nALS point cloud semantic segmentation. We propose a dynamic trainable layer\nselection module. This module utilizes gradient information to select\nlow-confidence layers for training, and the remaining layers are kept frozen,\nmitigating catastrophic forgetting. To further reduce error accumulation, we\npropose an entropy-based consistency loss. By losing such samples based on\nentropy, we apply consistency loss only to the reliable samples, enhancing\nmodel stability. In addition, we propose a random parameter interpolation\nmechanism, which randomly blends parameters from the selected trainable layers\nwith those of the source model. This approach helps balance target adaptation\nand source knowledge retention, further alleviating forgetting. Finally, we\nconstruct two benchmarks, ISPRSC and H3DC, to address the lack of CTTA\nbenchmarks for ALS point cloud segmentation. Experimental results demonstrate\nthat APCoTTA achieves the best performance on two benchmarks, with mIoU\nimprovements of approximately 9% and 14% over direct inference. The new\nbenchmarks and code are available at https://github.com/Gaoyuan2/APCoTTA."}
{"id": "2505.10066", "pdf": "https://arxiv.org/pdf/2505.10066", "abs": "https://arxiv.org/abs/2505.10066", "authors": ["Michael Fire", "Yitzhak Elbazis", "Adi Wasenstein", "Lior Rokach"], "title": "Dark LLMs: The Growing Threat of Unaligned AI Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50, 68T05, 68P25", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated."}
{"id": "2505.10309", "pdf": "https://arxiv.org/pdf/2505.10309", "abs": "https://arxiv.org/abs/2505.10309", "authors": ["Tuan Dung Nguyen", "Duncan J. Watts", "Mark E. Whiting"], "title": "Empirically evaluating commonsense intelligence in large language models with large-scale human judgments", "categories": ["cs.AI", "cs.HC", "cs.SI"], "comment": null, "summary": "Commonsense intelligence in machines is often assessed by static benchmarks\nthat compare a model's output against human-prescribed correct labels. An\nimportant, albeit implicit, assumption of these labels is that they accurately\ncapture what any human would think, effectively treating human common sense as\nhomogeneous. However, recent empirical work has shown that humans vary\nenormously in what they consider commonsensical; thus what appears self-evident\nto one benchmark designer may not be so to another. Here, we propose a novel\nmethod for evaluating common sense in artificial intelligence (AI),\nspecifically in large language models (LLMs), that incorporates empirically\nobserved heterogeneity among humans by measuring the correspondence between a\nmodel's judgment and that of a human population. We first find that, when\ntreated as independent survey respondents, most LLMs remain below the human\nmedian in their individual commonsense competence. Second, when used as\nsimulators of a hypothetical population, LLMs correlate with real humans only\nmodestly in the extent to which they agree on the same set of statements. In\nboth cases, smaller, open-weight models are surprisingly more competitive than\nlarger, proprietary frontier models. Our evaluation framework, which ties\ncommonsense intelligence to its cultural basis, contributes to the growing call\nfor adapting AI models to human collectivities that possess different, often\nincompatible, social stocks of knowledge."}
{"id": "2505.09822", "pdf": "https://arxiv.org/pdf/2505.09822", "abs": "https://arxiv.org/abs/2505.09822", "authors": ["Changhao Shi", "Gal Mishne"], "title": "Learning Kronecker-Structured Graphs from Smooth Signals", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Graph learning, or network inference, is a prominent problem in graph signal\nprocessing (GSP). GSP generalizes the Fourier transform to non-Euclidean\ndomains, and graph learning is pivotal to applying GSP when these domains are\nunknown. With the recent prevalence of multi-way data, there has been growing\ninterest in product graphs that naturally factorize dependencies across\ndifferent ways. However, the types of graph products that can be learned are\nstill limited for modeling diverse dependency structures. In this paper, we\nstudy the problem of learning a Kronecker-structured product graph from smooth\nsignals. Unlike the more commonly used Cartesian product, the Kronecker product\nmodels dependencies in a more intricate, non-separable way, but posits harder\nconstraints on the graph learning problem. To tackle this non-convex problem,\nwe propose an alternating scheme to optimize each factor graph and provide\ntheoretical guarantees for its asymptotic convergence. The proposed algorithm\nis also modified to learn factor graphs of the strong product. We conduct\nexperiments on synthetic and real-world graphs and demonstrate our approach's\nefficacy and superior performance compared to existing methods."}
{"id": "2505.09986", "pdf": "https://arxiv.org/pdf/2505.09986", "abs": "https://arxiv.org/abs/2505.09986", "authors": ["Yimin Zhou", "Yichong Xia", "Sicheng Pan", "Bin Chen", "Baoyi An", "Haoqian Wang", "Zhi Wang", "Yaowei Wang", "Zikun Zhou"], "title": "High Quality Underwater Image Compression with Adaptive Correction and Codebook-based Augmentation", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "With the increasing exploration and exploitation of the underwater world,\nunderwater images have become a critical medium for human interaction with\nmarine environments, driving extensive research into their efficient\ntransmission and storage. However, contemporary underwater image compression\nalgorithms fail to fully leverage the unique characteristics distinguishing\nunderwater scenes from terrestrial images, resulting in suboptimal performance.\nTo address this limitation, we introduce HQUIC, designed to exploit\nunderwater-image-specific features for enhanced compression efficiency. HQUIC\nemploys an ALTC module to adaptively predict the attenuation coefficients and\nglobal light information of the images, which effectively mitigates the issues\ncaused by the differences in lighting and tone existing in underwater images.\nSubsequently, HQUIC employs a codebook as an auxiliary branch to extract the\ncommon objects within underwater images and enhances the performance of the\nmain branch. Furthermore, HQUIC dynamically weights multi-scale frequency\ncomponents, prioritizing information critical for distortion quality while\ndiscarding redundant details. Extensive evaluations on diverse underwater\ndatasets demonstrate that HQUIC outperforms state-of-the-art compression\nmethods."}
{"id": "2505.10081", "pdf": "https://arxiv.org/pdf/2505.10081", "abs": "https://arxiv.org/abs/2505.10081", "authors": ["Wisdom Aduah", "Francois Meyer"], "title": "Designing and Contextualising Probes for African Languages", "categories": ["cs.CL"], "comment": null, "summary": "Pretrained language models (PLMs) for African languages are continually\nimproving, but the reasons behind these advances remain unclear. This paper\npresents the first systematic investigation into probing PLMs for linguistic\nknowledge about African languages. We train layer-wise probes for six\ntypologically diverse African languages to analyse how linguistic features are\ndistributed. We also design control tasks, a way to interpret probe\nperformance, for the MasakhaPOS dataset. We find PLMs adapted for African\nlanguages to encode more linguistic information about target languages than\nmassively multilingual PLMs. Our results reaffirm previous findings that\ntoken-level syntactic information concentrates in middle-to-last layers, while\nsentence-level semantic information is distributed across all layers. Through\ncontrol tasks and probing baselines, we confirm that performance reflects the\ninternal knowledge of PLMs rather than probe memorisation. Our study applies\nestablished interpretability techniques to African-language PLMs. In doing so,\nwe highlight the internal mechanisms underlying the success of strategies like\nactive learning and multilingual adaptation."}
{"id": "2505.10328", "pdf": "https://arxiv.org/pdf/2505.10328", "abs": "https://arxiv.org/abs/2505.10328", "authors": ["Alvin Combrink", "Stephie Do", "Kristofer Bengtsson", "Sabino Francesco Roselli", "Martin Fabian"], "title": "A Comparative Study of SMT and MILP for the Nurse Rostering Problem", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "6 pages, 3 figures", "summary": "The effects of personnel scheduling on the quality of care and working\nconditions for healthcare personnel have been thoroughly documented. However,\nthe ever-present demand and large variation of constraints make healthcare\nscheduling particularly challenging. This problem has been studied for decades,\nwith limited research aimed at applying Satisfiability Modulo Theories (SMT).\nSMT has gained momentum within the formal verification community in the last\ndecades, leading to the advancement of SMT solvers that have been shown to\noutperform standard mathematical programming techniques.\n  In this work, we propose generic constraint formulations that can model a\nwide range of real-world scheduling constraints. Then, the generic constraints\nare formulated as SMT and MILP problems and used to compare the respective\nstate-of-the-art solvers, Z3 and Gurobi, on academic and real-world inspired\nrostering problems. Experimental results show how each solver excels for\ncertain types of problems; the MILP solver generally performs better when the\nproblem is highly constrained or infeasible, while the SMT solver performs\nbetter otherwise. On real-world inspired problems containing a more varied set\nof shifts and personnel, the SMT solver excels. Additionally, it was noted\nduring experimentation that the SMT solver was more sensitive to the way the\ngeneric constraints were formulated, requiring careful consideration and\nexperimentation to achieve better performance. We conclude that SMT-based\nmethods present a promising avenue for future research within the domain of\npersonnel scheduling."}
{"id": "2505.09847", "pdf": "https://arxiv.org/pdf/2505.09847", "abs": "https://arxiv.org/abs/2505.09847", "authors": ["Liyang Zhao", "Olurotimi Seton", "Himadeep Reddy Reddivari", "Suvendu Jena", "Shadow Zhao", "Rachit Kumar", "Changshuai Wei"], "title": "Causal Predictive Optimization and Generation for Business AI", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "comment": null, "summary": "The sales process involves sales functions converting leads or opportunities\nto customers and selling more products to existing customers. The optimization\nof the sales process thus is key to success of any B2B business. In this work,\nwe introduce a principled approach to sales optimization and business AI,\nnamely the Causal Predictive Optimization and Generation, which includes three\nlayers: 1) prediction layer with causal ML 2) optimization layer with\nconstraint optimization and contextual bandit 3) serving layer with Generative\nAI and feedback-loop for system enhancement. We detail the implementation and\ndeployment of the system in LinkedIn, showcasing significant wins over legacy\nsystems and sharing learning and insight broadly applicable to this field."}
{"id": "2505.09990", "pdf": "https://arxiv.org/pdf/2505.09990", "abs": "https://arxiv.org/abs/2505.09990", "authors": ["Long Cheng", "Jiafei Duan", "Yi Ru Wang", "Haoquan Fang", "Boyang Li", "Yushan Huang", "Elvis Wang", "Ainaz Eftekhar", "Jason Lee", "Wentao Yuan", "Rose Hendrix", "Noah A. Smith", "Fei Xia", "Dieter Fox", "Ranjay Krishna"], "title": "PointArena: Probing Multimodal Grounding Through Language-Guided Pointing", "categories": ["cs.CV"], "comment": "10 Pages, Dataset and code:https://pointarena.github.io/", "summary": "Pointing serves as a fundamental and intuitive mechanism for grounding\nlanguage within visual contexts, with applications spanning robotics, assistive\ntechnologies, and interactive AI systems. While recent multimodal models have\nstarted to support pointing capabilities, existing benchmarks typically focus\nonly on referential object localization tasks. We introduce PointArena, a\ncomprehensive platform for evaluating multimodal pointing across diverse\nreasoning scenarios. PointArena comprises three components: (1) Point-Bench, a\ncurated dataset containing approximately 1,000 pointing tasks across five\nreasoning categories; (2) Point-Battle, an interactive, web-based arena\nfacilitating blind, pairwise model comparisons, which has already gathered over\n4,500 anonymized votes; and (3) Point-Act, a real-world robotic manipulation\nsystem allowing users to directly evaluate multimodal model pointing\ncapabilities in practical settings. We conducted extensive evaluations of both\nstate-of-the-art open-source and proprietary multimodal models. Results\nindicate that Molmo-72B consistently outperforms other models, though\nproprietary models increasingly demonstrate comparable performance.\nAdditionally, we find that supervised training specifically targeting pointing\ntasks significantly enhances model performance. Across our multi-stage\nevaluation pipeline, we also observe strong correlations, underscoring the\ncritical role of precise pointing capabilities in enabling multimodal models to\neffectively bridge abstract reasoning with concrete, real-world actions.\nProject page: https://pointarena.github.io/"}
{"id": "2505.10089", "pdf": "https://arxiv.org/pdf/2505.10089", "abs": "https://arxiv.org/abs/2505.10089", "authors": ["Wei Liu", "Sony Trenous", "Leonardo F. R. Ribeiro", "Bill Byrne", "Felix Hieber"], "title": "XRAG: Cross-lingual Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "We propose XRAG, a novel benchmark designed to evaluate the generation\nabilities of LLMs in cross-lingual Retrieval-Augmented Generation (RAG)\nsettings where the user language does not match the retrieval results. XRAG is\nconstructed from recent news articles to ensure that its questions require\nexternal knowledge to be answered. It covers the real-world scenarios of\nmonolingual and multilingual retrieval, and provides relevancy annotations for\neach retrieved document. Our novel dataset construction pipeline results in\nquestions that require complex reasoning, as evidenced by the significant gap\nbetween human and LLM performance. Consequently, XRAG serves as a valuable\nbenchmark for studying LLM reasoning abilities, even before considering the\nadditional cross-lingual complexity. Experimental results on five LLMs uncover\ntwo previously unreported challenges in cross-lingual RAG: 1) in the\nmonolingual retrieval setting, all evaluated models struggle with response\nlanguage correctness; 2) in the multilingual retrieval setting, the main\nchallenge lies in reasoning over retrieved information across languages rather\nthan generation of non-English text."}
{"id": "2505.10361", "pdf": "https://arxiv.org/pdf/2505.10361", "abs": "https://arxiv.org/abs/2505.10361", "authors": ["David Abel", "Michael Bowling", "André Barreto", "Will Dabney", "Shi Dong", "Steven Hansen", "Anna Harutyunyan", "Khimya Khetarpal", "Clare Lyle", "Razvan Pascanu", "Georgios Piliouras", "Doina Precup", "Jonathan Richens", "Mark Rowland", "Tom Schaul", "Satinder Singh"], "title": "Plasticity as the Mirror of Empowerment", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Agents are minimally entities that are influenced by their past observations\nand act to influence future observations. This latter capacity is captured by\nempowerment, which has served as a vital framing concept across artificial\nintelligence and cognitive science. This former capacity, however, is equally\nfoundational: In what ways, and to what extent, can an agent be influenced by\nwhat it observes? In this paper, we ground this concept in a universal\nagent-centric measure that we refer to as plasticity, and reveal a fundamental\nconnection to empowerment. Following a set of desiderata on a suitable\ndefinition, we define plasticity using a new information-theoretic quantity we\ncall the generalized directed information. We show that this new quantity\nstrictly generalizes the directed information introduced by Massey (1990) while\npreserving all of its desirable properties. Our first finding is that\nplasticity is the mirror of empowerment: The agent's plasticity is identical to\nthe empowerment of the environment, and vice versa. Our second finding\nestablishes a tension between the plasticity and empowerment of an agent,\nsuggesting that agent design needs to be mindful of both characteristics. We\nexplore the implications of these findings, and suggest that plasticity,\nempowerment, and their relationship are essential to understanding agency."}
{"id": "2505.09848", "pdf": "https://arxiv.org/pdf/2505.09848", "abs": "https://arxiv.org/abs/2505.09848", "authors": ["Aditya Raj", "Golrokh Mirzaei"], "title": "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection", "categories": ["cs.LG", "eess.IV"], "comment": "11 pages", "summary": "Imaging and genomic data offer distinct and rich features, and their\nintegration can unveil new insights into the complex landscape of diseases. In\nthis study, we present a novel approach utilizing radiogenomic data including\nstructural MRI images and gene expression data, for Alzheimer's disease\ndetection. Our framework introduces a novel heterogeneous bipartite graph\nrepresentation learning featuring two distinct node types: genes and images.\nThe network can effectively classify Alzheimer's disease (AD) into three\ndistinct stages:AD, Mild Cognitive Impairment (MCI), and Cognitive Normal (CN)\nclasses, utilizing a small dataset. Additionally, it identified which genes\nplay a significant role in each of these classification groups. We evaluate the\nperformance of our approach using metrics including classification accuracy,\nrecall, precision, and F1 score. The proposed technique holds potential for\nextending to radiogenomic-based classification to other diseases."}
{"id": "2505.09997", "pdf": "https://arxiv.org/pdf/2505.09997", "abs": "https://arxiv.org/abs/2505.09997", "authors": ["Jinhyun Jang", "Jiyeong Lee", "Kwanghoon Sohn"], "title": "Descriptive Image-Text Matching with Graded Contextual Similarity", "categories": ["cs.CV"], "comment": null, "summary": "Image-text matching aims to build correspondences between visual and textual\ndata by learning their pairwise similarities. Most existing approaches have\nadopted sparse binary supervision, indicating whether a pair of images and\nsentences matches or not. However, such sparse supervision covers a limited\nsubset of image-text relationships, neglecting their inherent many-to-many\ncorrespondences; an image can be described in numerous texts at different\ndescriptive levels. Moreover, existing approaches overlook the implicit\nconnections from general to specific descriptions, which form the underlying\nrationale for the many-to-many relationships between vision and language. In\nthis work, we propose descriptive image-text matching, called DITM, to learn\nthe graded contextual similarity between image and text by exploring the\ndescriptive flexibility of language. We formulate the descriptiveness score of\neach sentence with cumulative term frequency-inverse document frequency\n(TF-IDF) to balance the pairwise similarity according to the keywords in the\nsentence. Our method leverages sentence descriptiveness to learn robust\nimage-text matching in two key ways: (1) to refine the false negative labeling,\ndynamically relaxing the connectivity between positive and negative pairs, and\n(2) to build more precise matching, aligning a set of relevant sentences in a\ngeneric-to-specific order. By moving beyond rigid binary supervision, DITM\nenhances the discovery of both optimal matches and potential positive pairs.\nExtensive experiments on MS-COCO, Flickr30K, and CxC datasets demonstrate the\neffectiveness of our method in representing complex image-text relationships\ncompared to state-of-the-art approaches. In addition, DITM enhances the\nhierarchical reasoning ability of the model, supported by the extensive\nanalysis on HierarCaps benchmark."}
{"id": "2505.10113", "pdf": "https://arxiv.org/pdf/2505.10113", "abs": "https://arxiv.org/abs/2505.10113", "authors": ["Xinlan Yan", "Di Wu", "Yibin Lei", "Christof Monz", "Iacer Calixto"], "title": "What Does Neuro Mean to Cardio? Investigating the Role of Clinical Specialty Data in Medical LLMs", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we introduce S-MedQA, an English medical question-answering\n(QA) dataset for benchmarking large language models in fine-grained clinical\nspecialties. We use S-MedQA to check the applicability of a popular hypothesis\nrelated to knowledge injection in the knowledge-intense scenario of medical QA,\nand show that: 1) training on data from a speciality does not necessarily lead\nto best performance on that specialty and 2) regardless of the specialty\nfine-tuned on, token probabilities of clinically relevant terms for all\nspecialties increase consistently. Thus, we believe improvement gains come\nmostly from domain shifting (e.g., general to medical) rather than knowledge\ninjection and suggest rethinking the role of fine-tuning data in the medical\ndomain. We release S-MedQA and all code needed to reproduce all our experiments\nto the research community."}
{"id": "2505.10399", "pdf": "https://arxiv.org/pdf/2505.10399", "abs": "https://arxiv.org/abs/2505.10399", "authors": ["Kaivalya Rawal", "Zihao Fu", "Eoin Delaney", "Chris Russell"], "title": "Evaluating Model Explanations without Ground Truth", "categories": ["cs.AI", "cs.LG", "I.2.6"], "comment": "https://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth", "summary": "There can be many competing and contradictory explanations for a single model\nprediction, making it difficult to select which one to use. Current explanation\nevaluation frameworks measure quality by comparing against ideal \"ground-truth\"\nexplanations, or by verifying model sensitivity to important inputs. We outline\nthe limitations of these approaches, and propose three desirable principles to\nground the future development of explanation evaluation strategies for local\nfeature importance explanations. We propose a ground-truth Agnostic eXplanation\nEvaluation framework (AXE) for evaluating and comparing model explanations that\nsatisfies these principles. Unlike prior approaches, AXE does not require\naccess to ideal ground-truth explanations for comparison, or rely on model\nsensitivity - providing an independent measure of explanation quality. We\nverify AXE by comparing with baselines, and show how it can be used to detect\nexplanation fairwashing. Our code is available at\nhttps://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth."}
{"id": "2505.09851", "pdf": "https://arxiv.org/pdf/2505.09851", "abs": "https://arxiv.org/abs/2505.09851", "authors": ["Shun Wang", "Shun-Li Shang", "Zi-Kui Liu", "Wenrui Hao"], "title": "ZENN: A Thermodynamics-Inspired Computational Framework for Heterogeneous Data-Driven Modeling", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "9 pages, 4 figures", "summary": "Traditional entropy-based methods - such as cross-entropy loss in\nclassification problems - have long been essential tools for quantifying\nuncertainty and disorder in data and developing artificial intelligence\nalgorithms. However, the rapid growth of data across various domains has\nintroduced new challenges, particularly the integration of heterogeneous\ndatasets with intrinsic disparities. In this paper, we extend zentropy theory\ninto the data science domain by introducing intrinsic entropy, enabling more\neffective learning from heterogeneous data sources. We propose a\nzentropy-enhanced neural network (ZENN) that simultaneously learns both energy\nand intrinsic entropy components, capturing the underlying structure of\nmulti-source data. To support this, we redesign the neural network architecture\nto better reflect the intrinsic properties and variability inherent in diverse\ndatasets. We demonstrate the effectiveness of ZENN on classification tasks and\nenergy landscape reconstructions, showing its superior generalization\ncapabilities and robustness-particularly in predicting high-order derivatives.\nAs a practical application, we employ ZENN to reconstruct the Helmholtz energy\nlandscape of Fe3Pt using data generated from DFT and capture key material\nbehaviors, including negative thermal expansion and the critical point in the\ntemperature-pressure space. Overall, our study introduces a novel approach for\ndata-driven machine learning grounded in zentropy theory, highlighting ZENN as\na versatile and robust deep learning framework for scientific problems\ninvolving complex, heterogeneous datasets."}
{"id": "2505.09998", "pdf": "https://arxiv.org/pdf/2505.09998", "abs": "https://arxiv.org/abs/2505.09998", "authors": ["Ying Zang", "Yuanqi Hu", "Xinyu Chen", "Yuxia Xu", "Suhui Wang", "Chunan Yu", "Lanyun Zhu", "Deyi Ji", "Xin Xu", "Tianrun Chen"], "title": "From Air to Wear: Personalized 3D Digital Fashion with AR/VR Immersive 3D Sketching", "categories": ["cs.CV"], "comment": "8 pages, 5 figures", "summary": "In the era of immersive consumer electronics, such as AR/VR headsets and\nsmart devices, people increasingly seek ways to express their identity through\nvirtual fashion. However, existing 3D garment design tools remain inaccessible\nto everyday users due to steep technical barriers and limited data. In this\nwork, we introduce a 3D sketch-driven 3D garment generation framework that\nempowers ordinary users - even those without design experience - to create\nhigh-quality digital clothing through simple 3D sketches in AR/VR environments.\nBy combining a conditional diffusion model, a sketch encoder trained in a\nshared latent space, and an adaptive curriculum learning strategy, our system\ninterprets imprecise, free-hand input and produces realistic, personalized\ngarments. To address the scarcity of training data, we also introduce\nKO3DClothes, a new dataset of paired 3D garments and user-created sketches.\nExtensive experiments and user studies confirm that our method significantly\noutperforms existing baselines in both fidelity and usability, demonstrating\nits promise for democratized fashion design on next-generation consumer\nplatforms."}
{"id": "2505.10143", "pdf": "https://arxiv.org/pdf/2505.10143", "abs": "https://arxiv.org/abs/2505.10143", "authors": ["Longchao Da", "Parth Mitesh Shah", "Kuan-Ru Liou", "Jiaxing Zhang", "Hua Wei"], "title": "GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs", "categories": ["cs.CL", "68T50, 68T30", "I.2.7; I.2.4; H.3.3"], "comment": "5 pages, 4 figures, accepted to IJCAI2025 demo track", "summary": "Large Language Models are now key assistants in human decision-making\nprocesses. However, a common note always seems to follow: \"LLMs can make\nmistakes. Be careful with important info.\" This points to the reality that not\nall outputs from LLMs are dependable, and users must evaluate them manually.\nThe challenge deepens as hallucinated responses, often presented with seemingly\nplausible explanations, create complications and raise trust issues among\nusers. To tackle such issue, this paper proposes GE-Chat, a knowledge Graph\nenhanced retrieval-augmented generation framework to provide Evidence-based\nresponse generation. Specifically, when the user uploads a material document, a\nknowledge graph will be created, which helps construct a retrieval-augmented\nagent, enhancing the agent's responses with additional knowledge beyond its\ntraining corpus. Then we leverage Chain-of-Thought (CoT) logic generation,\nn-hop sub-graph searching, and entailment-based sentence generation to realize\naccurate evidence retrieval. We demonstrate that our method improves the\nexisting models' performance in terms of identifying the exact evidence in a\nfree-form context, providing a reliable way to examine the resources of LLM's\nconclusion and help with the judgment of the trustworthiness."}
{"id": "2505.10468", "pdf": "https://arxiv.org/pdf/2505.10468", "abs": "https://arxiv.org/abs/2505.10468", "authors": ["Ranjan Sapkota", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "title": "AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge", "categories": ["cs.AI"], "comment": "32 pages, 14 figures, 11 tables", "summary": "This study critically distinguishes between AI Agents and Agentic AI,\noffering a structured conceptual taxonomy, application mapping, and challenge\nanalysis to clarify their divergent design philosophies and capabilities. We\nbegin by outlining the search strategy and foundational definitions,\ncharacterizing AI Agents as modular systems driven by Large Language Models\n(LLMs) and Large Image Models (LIMs) for narrow, task-specific automation.\nGenerative AI is positioned as a precursor, with AI Agents advancing through\ntool integration, prompt engineering, and reasoning enhancements. In contrast,\nAgentic AI systems represent a paradigmatic shift marked by multi-agent\ncollaboration, dynamic task decomposition, persistent memory, and orchestrated\nautonomy. Through a sequential evaluation of architectural evolution,\noperational mechanisms, interaction styles, and autonomy levels, we present a\ncomparative analysis across both paradigms. Application domains such as\ncustomer support, scheduling, and data summarization are contrasted with\nAgentic AI deployments in research automation, robotic coordination, and\nmedical decision support. We further examine unique challenges in each paradigm\nincluding hallucination, brittleness, emergent behavior, and coordination\nfailure and propose targeted solutions such as ReAct loops, RAG, orchestration\nlayers, and causal modeling. This work aims to provide a definitive roadmap for\ndeveloping robust, scalable, and explainable AI agent and Agentic AI-driven\nsystems. >AI Agents, Agent-driven, Vision-Language-Models, Agentic AI Decision\nSupport System, Agentic-AI Applications"}
{"id": "2505.09854", "pdf": "https://arxiv.org/pdf/2505.09854", "abs": "https://arxiv.org/abs/2505.09854", "authors": ["Harikrishna Kuttivelil", "Katia Obraczka"], "title": "Chisme: Fully Decentralized Differentiated Deep Learning for Edge Intelligence", "categories": ["cs.LG", "cs.ET", "cs.MA", "cs.SI"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "As demand for intelligent services rises and edge devices become more\ncapable, distributed learning at the network edge has emerged as a key enabling\ntechnology. While existing paradigms like federated learning (FL) and\ndecentralized FL (DFL) enable privacy-preserving distributed learning in many\nscenarios, they face potential challenges in connectivity and synchronization\nimposed by resource-constrained and infrastructure-less environments. While\nmore robust, gossip learning (GL) algorithms have generally been designed for\nhomogeneous data distributions and may not suit all contexts. This paper\nintroduces Chisme, a novel suite of protocols designed to address the\nchallenges of implementing robust intelligence in the network edge,\ncharacterized by heterogeneous data distributions, episodic connectivity, and\nlack of infrastructure. Chisme includes both synchronous DFL (Chisme-DFL) and\nasynchronous GL (Chisme-GL) variants that enable collaborative yet\ndecentralized model training that considers underlying data heterogeneity. We\nintroduce a data similarity heuristic that allows agents to opportunistically\ninfer affinity with each other using the existing communication of model\nupdates in decentralized FL and GL. We leverage the heuristic to extend DFL's\nmodel aggregation and GL's model merge mechanisms for better personalized\ntraining while maintaining collaboration. While Chisme-DFL is a synchronous\ndecentralized approach whose resource utilization scales linearly with network\nsize, Chisme-GL is fully asynchronous and has a lower, constant resource\nrequirement independent of network size. We demonstrate that Chisme methods\noutperform their standard counterparts in model training over distributed and\nheterogeneous data in network scenarios ranging from less connected and\nreliable networks to fully connected and lossless networks."}
{"id": "2505.10016", "pdf": "https://arxiv.org/pdf/2505.10016", "abs": "https://arxiv.org/abs/2505.10016", "authors": ["Shijie Lyu"], "title": "Application of YOLOv8 in monocular downward multiple Car Target detection", "categories": ["cs.CV", "cs.AI", "I.4.8; I.2.10"], "comment": "Accepted by the 5th International Conference on Signal Processing and\n  Machine Learning (CONF-SPML 2025), to appear in Applied and Computational\n  Engineering", "summary": "Autonomous driving technology is progressively transforming traditional car\ndriving methods, marking a significant milestone in modern transportation.\nObject detection serves as a cornerstone of autonomous systems, playing a vital\nrole in enhancing driving safety, enabling autonomous functionality, improving\ntraffic efficiency, and facilitating effective emergency responses. However,\ncurrent technologies such as radar for environmental perception, cameras for\nroad perception, and vehicle sensor networks face notable challenges, including\nhigh costs, vulnerability to weather and lighting conditions, and limited\nresolution.To address these limitations, this paper presents an improved\nautonomous target detection network based on YOLOv8. By integrating structural\nreparameterization technology, a bidirectional pyramid structure network model,\nand a novel detection pipeline into the YOLOv8 framework, the proposed approach\nachieves highly efficient and precise detection of multi-scale, small, and\nremote objects. Experimental results demonstrate that the enhanced model can\neffectively detect both large and small objects with a detection accuracy of\n65%, showcasing significant advancements over traditional methods.This improved\nmodel holds substantial potential for real-world applications and is\nwell-suited for autonomous driving competitions, such as the Formula Student\nAutonomous China (FSAC), particularly excelling in scenarios involving\nsingle-target and small-object detection."}
{"id": "2505.10182", "pdf": "https://arxiv.org/pdf/2505.10182", "abs": "https://arxiv.org/abs/2505.10182", "authors": ["Yoichi Ishibashi", "Taro Yano", "Masafumi Oyamada"], "title": "Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant improvements in\nreasoning capabilities through supervised fine-tuning and reinforcement\nlearning. However, when training reasoning models, these approaches are\nprimarily applicable to specific domains such as mathematics and programming,\nwhich imposes fundamental constraints on the breadth and scalability of\ntraining data. In contrast, continual pretraining (CPT) offers the advantage of\nnot requiring task-specific signals. Nevertheless, how to effectively\nsynthesize training data for reasoning and how such data affect a wide range of\ndomains remain largely unexplored. This study provides a detailed evaluation of\nReasoning CPT, a form of CPT that uses synthetic data to reconstruct the hidden\nthought processes underlying texts, based on the premise that texts are the\nresult of the author's thinking process. Specifically, we apply Reasoning CPT\nto Gemma2-9B using synthetic data with hidden thoughts derived from STEM and\nLaw corpora, and compare it to standard CPT on the MMLU benchmark. Our analysis\nreveals that Reasoning CPT consistently improves performance across all\nevaluated domains. Notably, reasoning skills acquired in one domain transfer\neffectively to others; the performance gap with conventional methods widens as\nproblem difficulty increases, with gains of up to 8 points on the most\nchallenging problems. Furthermore, models trained with hidden thoughts learn to\nadjust the depth of their reasoning according to problem difficulty."}
{"id": "2505.10543", "pdf": "https://arxiv.org/pdf/2505.10543", "abs": "https://arxiv.org/abs/2505.10543", "authors": ["Annie Wong", "Thomas Bäck", "Aske Plaat", "Niki van Stein", "Anna V. Kononova"], "title": "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While large language models demonstrate impressive performance on static\nbenchmarks, the true potential of large language models as self-learning and\nreasoning agents in dynamic environments remains unclear. This study\nsystematically evaluates the efficacy of self-reflection, heuristic mutation,\nand planning as prompting techniques to test the adaptive capabilities of\nagents. We conduct experiments with various open-source language models in\ndynamic environments and find that larger models generally outperform smaller\nones, but that strategic prompting can close this performance gap. Second, a\ntoo-long prompt can negatively impact smaller models on basic reactive tasks,\nwhile larger models show more robust behaviour. Third, advanced prompting\ntechniques primarily benefit smaller models on complex games, but offer less\nimprovement for already high-performing large language models. Yet, we find\nthat advanced reasoning methods yield highly variable outcomes: while capable\nof significantly improving performance when reasoning and decision-making\nalign, they also introduce instability and can lead to big performance drops.\nCompared to human performance, our findings reveal little evidence of true\nemergent reasoning. Instead, large language model performance exhibits\npersistent limitations in crucial areas such as planning, reasoning, and\nspatial coordination, suggesting that current-generation large language models\nstill suffer fundamental shortcomings that may not be fully overcome through\nself-reflective prompting alone. Reasoning is a multi-faceted task, and while\nreasoning methods like Chain of thought improves multi-step reasoning on math\nword problems, our findings using dynamic benchmarks highlight important\nshortcomings in general reasoning capabilities, indicating a need to move\nbeyond static benchmarks to capture the complexity of reasoning."}
{"id": "2505.09855", "pdf": "https://arxiv.org/pdf/2505.09855", "abs": "https://arxiv.org/abs/2505.09855", "authors": ["Alexander Y. Ku", "Thomas L. Griffiths", "Stephanie C. Y. Chan"], "title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies."}
{"id": "2505.10027", "pdf": "https://arxiv.org/pdf/2505.10027", "abs": "https://arxiv.org/abs/2505.10027", "authors": ["Shijie Lyu"], "title": "ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by the 4th International Conference on Computing Innovation\n  and Applied Physics (CONF-CIAP 2025), and will be published in EAI Community\n  Research Series-CORE or Theoretical and Natural Science (TNS)", "summary": "With the rapid advancement of remote sensing technology, super-resolution\nimage reconstruction is of great research and practical significance. Existing\ndeep learning methods have made progress but still face limitations in handling\ncomplex scenes and preserving image details. This paper proposes a\nreinforcement learning-based latent diffusion model (LDM) fine-tuning method\nfor remote sensing image super-resolution. The method constructs a\nreinforcement learning environment with states, actions, and rewards,\noptimizing decision objectives through proximal policy optimization (PPO)\nduring the reverse denoising process of the LDM model. Experiments on the\nRESISC45 dataset show significant improvements over the baseline model in PSNR,\nSSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11,\nand LPIPS reducing by 0.06-0.10, particularly in structured and complex natural\nscenes. The results demonstrate the method's effectiveness in enhancing\nsuper-resolution quality and adaptability across scenes."}
{"id": "2505.10185", "pdf": "https://arxiv.org/pdf/2505.10185", "abs": "https://arxiv.org/abs/2505.10185", "authors": ["Seongyun Lee", "Seungone Kim", "Minju Seo", "Yongrae Jo", "Dongyoung Go", "Hyeonbin Hwang", "Jinho Park", "Xiang Yue", "Sean Welleck", "Graham Neubig", "Moontae Lee", "Minjoon Seo"], "title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think", "categories": ["cs.CL", "cs.AI"], "comment": "Work in progress", "summary": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of\nmodern large language models, but our understanding of the reasoning strategies\nunderlying these capabilities remains limited. While some prior works have\nattempted to categorize CoTs using predefined strategy types, such approaches\nare constrained by human intuition and fail to capture the full diversity of\nmodel behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up\nframework for analyzing and steering model reasoning. Our method automatically\nextracts diverse reasoning criteria from model-generated CoTs, embeds them into\na semantic space, clusters them into representative categories, and derives\ncontrastive rubrics to interpret reasoning behavior. Human evaluations show\nthat this framework produces more interpretable and comprehensive analyses than\nexisting methods. Moreover, we demonstrate that this understanding enables\nperformance gains: we can predict which strategy a model is likely to use and\nguide it toward more effective alternatives. Finally, we provide practical\ninsights, such as that training data format (e.g., free-form vs.\nmultiple-choice) has a far greater impact on reasoning behavior than data\ndomain, underscoring the importance of format-aware model design."}
{"id": "2306.07615", "pdf": "https://arxiv.org/pdf/2306.07615", "abs": "https://arxiv.org/abs/2306.07615", "authors": ["Heqin Zhu", "Quan Quan", "Qingsong Yao", "Zaiyi Liu", "S. Kevin Zhou"], "title": "UOD: Universal One-shot Detection of Anatomical Landmarks", "categories": ["cs.CV", "cs.AI"], "comment": "Eealy accepted by MICCAI 2023. 11pages, 4 figures, 2 tables. arXiv\n  admin note: text overlap with arXiv:2203.06433", "summary": "One-shot medical landmark detection gains much attention and achieves great\nsuccess for its label-efficient training process. However, existing one-shot\nlearning methods are highly specialized in a single domain and suffer domain\npreference heavily in the situation of multi-domain unlabeled data. Moreover,\none-shot learning is not robust that it faces performance drop when annotating\na sub-optimal image. To tackle these issues, we resort to developing a\ndomain-adaptive one-shot landmark detection framework for handling multi-domain\nmedical images, named Universal One-shot Detection (UOD). UOD consists of two\nstages and two corresponding universal models which are designed as\ncombinations of domain-specific modules and domain-shared modules. In the first\nstage, a domain-adaptive convolution model is self-supervised learned to\ngenerate pseudo landmark labels. In the second stage, we design a\ndomain-adaptive transformer to eliminate domain preference and build the global\ncontext for multi-domain data. Even though only one annotated sample from each\ndomain is available for training, the domain-shared modules help UOD aggregate\nall one-shot samples to detect more robust and accurate landmarks. We\ninvestigated both qualitatively and quantitatively the proposed UOD on three\nwidely-used public X-ray datasets in different anatomical domains (i.e., head,\nhand, chest) and obtained state-of-the-art performances in each domain. The\ncode is available at\nhttps://github.com/heqin-zhu/UOD_universal_oneshot_detection."}
{"id": "2505.09861", "pdf": "https://arxiv.org/pdf/2505.09861", "abs": "https://arxiv.org/abs/2505.09861", "authors": ["John Bencina", "Erkut Aykutlug", "Yue Chen", "Zerui Zhang", "Stephanie Sorenson", "Shao Tang", "Changshuai Wei"], "title": "LiDDA: Data Driven Attribution at LinkedIn", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ME"], "comment": null, "summary": "Data Driven Attribution, which assigns conversion credits to marketing\ninteractions based on causal patterns learned from data, is the foundation of\nmodern marketing intelligence and vital to any marketing businesses and\nadvertising platform. In this paper, we introduce a unified transformer-based\nattribution approach that can handle member-level data, aggregate-level data,\nand integration of external macro factors. We detail the large scale\nimplementation of the approach at LinkedIn, showcasing significant impact. We\nalso share learning and insights that are broadly applicable to the marketing\nand ad tech fields."}
{"id": "2505.10030", "pdf": "https://arxiv.org/pdf/2505.10030", "abs": "https://arxiv.org/abs/2505.10030", "authors": ["Miit Daga", "Dhriti Parikh", "Swarna Priya Ramu"], "title": "DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera", "categories": ["cs.CV", "cs.LG"], "comment": "This paper is accepted for publication in IEEE Access journal and is\n  currently pending revisions before publication", "summary": "Coconut tree diseases are a serious risk to agricultural yield, particularly\nin developing countries where conventional farming practices restrict early\ndiagnosis and intervention. Current disease identification methods are manual,\nlabor-intensive, and non-scalable. In response to these limitations, we come up\nwith DeepSeqCoco, a deep learning based model for accurate and automatic\ndisease identification from coconut tree images. The model was tested under\nvarious optimizer settings, such as SGD, Adam, and hybrid configurations, to\nidentify the optimal balance between accuracy, minimization of loss, and\ncomputational cost. Results from experiments indicate that DeepSeqCoco can\nachieve as much as 99.5% accuracy (achieving up to 5% higher accuracy than\nexisting models) with the hybrid SGD-Adam showing the lowest validation loss of\n2.81%. It also shows a drop of up to 18% in training time and up to 85% in\nprediction time for input images. The results point out the promise of the\nmodel to improve precision agriculture through an AI-based, scalable, and\nefficient disease monitoring system."}
{"id": "2505.10202", "pdf": "https://arxiv.org/pdf/2505.10202", "abs": "https://arxiv.org/abs/2505.10202", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "YiMing Cheng", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "VQ-Logits: Compressing the Output Bottleneck of Large Language Models via Vector Quantized Logits", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success but face\nsignificant computational and memory challenges, particularly due to their\nextensive output vocabularies. The final linear projection layer, mapping\nhidden states to vocabulary-sized logits, often constitutes a substantial\nportion of the model's parameters and computational cost during inference.\nExisting methods like adaptive softmax or hierarchical softmax introduce\nstructural complexities. In this paper, we propose VQ-Logits, a novel approach\nthat leverages Vector Quantization (VQ) to drastically reduce the parameter\ncount and computational load of the LLM output layer. VQ-Logits replaces the\nlarge V * dmodel output embedding matrix with a small, shared codebook of K\nembedding vectors (K << V ). Each token in the vocabulary is mapped to one of\nthese K codebook vectors. The LLM predicts logits over this compact codebook,\nwhich are then efficiently \"scattered\" to the full vocabulary space using the\nlearned or preassigned mapping. We demonstrate through extensive experiments on\nstandard language modeling benchmarks (e.g., WikiText-103, C4) that VQ-Logits\ncan achieve up to 99% parameter reduction in the output layer and 6x speedup in\nlogit computation, with only a marginal 4% increase in perplexity compared to\nfull softmax baselines. We further provide detailed ablation studies on\ncodebook size, initialization, and learning strategies, showcasing the\nrobustness and effectiveness of our approach."}
{"id": "2410.13778", "pdf": "https://arxiv.org/pdf/2410.13778", "abs": "https://arxiv.org/abs/2410.13778", "authors": ["Michelangelo Olmo Nogara Notarianni", "Filippo Leveni", "Diego Stucchi", "Luca Frittoli", "Giacomo Boracchi"], "title": "Change Detection in Multivariate data streams: Online Analysis with Kernel-QuantTree", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "AALTD workshop at ECML 2024 (https://ecml-aaltd.github.io/aaltd2024/)", "summary": "We present Kernel-QuantTree Exponentially Weighted Moving Average (KQT-EWMA),\na non-parametric change-detection algorithm that combines the Kernel-QuantTree\n(KQT) histogram and the EWMA statistic to monitor multivariate data streams\nonline. The resulting monitoring scheme is very flexible, since histograms can\nbe used to model any stationary distribution, and practical, since the\ndistribution of test statistics does not depend on the distribution of\ndatastream in stationary conditions (non-parametric monitoring). KQT-EWMA\nenables controlling false alarms by operating at a pre-determined Average Run\nLength ($ARL_0$), which measures the expected number of stationary samples to\nbe monitored before triggering a false alarm. The latter peculiarity is in\ncontrast with most non-parametric change-detection tests, which rarely can\ncontrol the $ARL_0$ a priori. Our experiments on synthetic and real-world\ndatasets demonstrate that KQT-EWMA can control $ARL_0$ while achieving\ndetection delays comparable to or lower than state-of-the-art methods designed\nto work in the same conditions."}
{"id": "2505.09864", "pdf": "https://arxiv.org/pdf/2505.09864", "abs": "https://arxiv.org/abs/2505.09864", "authors": ["Aditya Panangat"], "title": "BINGO: A Novel Pruning Mechanism to Reduce the Size of Neural Networks", "categories": ["cs.LG"], "comment": "6 pages, 0 figures, 2 tables", "summary": "Over the past decade, the use of machine learning has increased\nexponentially. Models are far more complex than ever before, growing to\ngargantuan sizes and housing millions of weights. Unfortunately, the fact that\nlarge models have become the state of the art means that it often costs\nmillions of dollars to train and operate them. These expenses not only hurt\ncompanies but also bar non-wealthy individuals from contributing to new\ndevelopments and force consumers to pay greater prices for AI. Current methods\nused to prune models, such as iterative magnitude pruning, have shown great\naccuracy but require an iterative training sequence that is incredibly\ncomputationally and environmentally taxing. To solve this problem, BINGO is\nintroduced. BINGO, during the training pass, studies specific subsets of a\nneural network one at a time to gauge how significant of a role each weight\nplays in contributing to a network's accuracy. By the time training is done,\nBINGO generates a significance score for each weight, allowing for\ninsignificant weights to be pruned in one shot. BINGO provides an\naccuracy-preserving pruning technique that is less computationally intensive\nthan current methods, allowing for a world where AI growth does not have to\nmean model growth, as well."}
{"id": "2505.10046", "pdf": "https://arxiv.org/pdf/2505.10046", "abs": "https://arxiv.org/abs/2505.10046", "authors": ["Bingda Tang", "Boyang Zheng", "Xichen Pan", "Sayak Paul", "Saining Xie"], "title": "Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Text-to-Image Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "This paper does not describe a new method; instead, it provides a thorough\nexploration of an important yet understudied design space related to recent\nadvances in text-to-image synthesis -- specifically, the deep fusion of large\nlanguage models (LLMs) and diffusion transformers (DiTs) for multi-modal\ngeneration. Previous studies mainly focused on overall system performance\nrather than detailed comparisons with alternative methods, and key design\ndetails and training recipes were often left undisclosed. These gaps create\nuncertainty about the real potential of this approach. To fill these gaps, we\nconduct an empirical study on text-to-image generation, performing controlled\ncomparisons with established baselines, analyzing important design choices, and\nproviding a clear, reproducible recipe for training at scale. We hope this work\noffers meaningful data points and practical guidelines for future research in\nmulti-modal generation."}
{"id": "2505.10218", "pdf": "https://arxiv.org/pdf/2505.10218", "abs": "https://arxiv.org/abs/2505.10218", "authors": ["Zongsheng Wang", "Kaili Sun", "Bowen Wu", "Qun Yu", "Ying Li", "Baoxun Wang"], "title": "RAIDEN-R1: Improving Role-awareness of LLMs via GRPO with Verifiable Reward", "categories": ["cs.CL"], "comment": null, "summary": "Role-playing conversational agents (RPCAs) face persistent challenges in\nmaintaining role consistency. To address this, we propose RAIDEN-R1, a novel\nreinforcement learning framework that integrates Verifiable Role-Awareness\nReward (VRAR). The method introduces both singular and multi-term mining\nstrategies to generate quantifiable rewards by assessing role-specific keys.\nAdditionally, we construct a high-quality, role-aware Chain-of-Thought dataset\nthrough multi-LLM collaboration, and implement experiments to enhance reasoning\ncoherence. Experiments on the RAIDEN benchmark demonstrate RAIDEN-R1's\nsuperiority: our 14B-GRPO model achieves 88.04% and 88.65% accuracy on\nScript-Based Knowledge and Conversation Memory metrics, respectively,\noutperforming baseline models while maintaining robustness. Case analyses\nfurther reveal the model's enhanced ability to resolve conflicting contextual\ncues and sustain first-person narrative consistency. This work bridges the\nnon-quantifiability gap in RPCA training and provides insights into role-aware\nreasoning patterns, advancing the development of RPCAs."}
{"id": "2505.03084", "pdf": "https://arxiv.org/pdf/2505.03084", "abs": "https://arxiv.org/abs/2505.03084", "authors": ["Shashank Kapoor", "Sanjay Surendranath Girija", "Lakshit Arora", "Dipen Pradhan", "Ankit Shetgaonkar", "Aman Raj"], "title": "Adversarial Attacks in Multimodal Systems: A Practitioner's Survey", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in IEEE COMPSAC 2025", "summary": "The introduction of multimodal models is a huge step forward in Artificial\nIntelligence. A single model is trained to understand multiple modalities:\ntext, image, video, and audio. Open-source multimodal models have made these\nbreakthroughs more accessible. However, considering the vast landscape of\nadversarial attacks across these modalities, these models also inherit\nvulnerabilities of all the modalities, and ultimately, the adversarial threat\namplifies. While broad research is available on possible attacks within or\nacross these modalities, a practitioner-focused view that outlines attack types\nremains absent in the multimodal world. As more Machine Learning Practitioners\nadopt, fine-tune, and deploy open-source models in real-world applications,\nit's crucial that they can view the threat landscape and take the preventive\nactions necessary. This paper addresses the gap by surveying adversarial\nattacks targeting all four modalities: text, image, video, and audio. This\nsurvey provides a view of the adversarial attack landscape and presents how\nmultimodal adversarial threats have evolved. To the best of our knowledge, this\nsurvey is the first comprehensive summarization of the threat landscape in the\nmultimodal world."}
{"id": "2505.09901", "pdf": "https://arxiv.org/pdf/2505.09901", "abs": "https://arxiv.org/abs/2505.09901", "authors": ["Ziyuan Zhang", "Darcy Wang", "Ningyuan Chen", "Rodrigo Mansur", "Vahid Sarhangian"], "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements."}
{"id": "2505.10049", "pdf": "https://arxiv.org/pdf/2505.10049", "abs": "https://arxiv.org/abs/2505.10049", "authors": ["Jinlong Fan", "Xuepu Zeng", "Jing Zhang", "Mingming Gong", "Yuxiang Yang", "Dacheng Tao"], "title": "Advances in Radiance Field for Dynamic Scene: From Neural Field to Gaussian Field", "categories": ["cs.CV"], "comment": null, "summary": "Dynamic scene representation and reconstruction have undergone transformative\nadvances in recent years, catalyzed by breakthroughs in neural radiance fields\nand 3D Gaussian splatting techniques. While initially developed for static\nenvironments, these methodologies have rapidly evolved to address the\ncomplexities inherent in 4D dynamic scenes through an expansive body of\nresearch. Coupled with innovations in differentiable volumetric rendering,\nthese approaches have significantly enhanced the quality of motion\nrepresentation and dynamic scene reconstruction, thereby garnering substantial\nattention from the computer vision and graphics communities. This survey\npresents a systematic analysis of over 200 papers focused on dynamic scene\nrepresentation using radiance field, spanning the spectrum from implicit neural\nrepresentations to explicit Gaussian primitives. We categorize and evaluate\nthese works through multiple critical lenses: motion representation paradigms,\nreconstruction techniques for varied scene dynamics, auxiliary information\nintegration strategies, and regularization approaches that ensure temporal\nconsistency and physical plausibility. We organize diverse methodological\napproaches under a unified representational framework, concluding with a\ncritical examination of persistent challenges and promising research\ndirections. By providing this comprehensive overview, we aim to establish a\ndefinitive reference for researchers entering this rapidly evolving field while\noffering experienced practitioners a systematic understanding of both\nconceptual principles and practical frontiers in dynamic scene reconstruction."}
{"id": "2505.10260", "pdf": "https://arxiv.org/pdf/2505.10260", "abs": "https://arxiv.org/abs/2505.10260", "authors": ["Poli Apollinaire Nemkova", "Solomon Ubani", "Mark V. Albert"], "title": "Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the era of increasingly sophisticated natural language processing (NLP)\nsystems, large language models (LLMs) have demonstrated remarkable potential\nfor diverse applications, including tasks requiring nuanced textual\nunderstanding and contextual reasoning. This study investigates the\ncapabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3,\nMistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex\ntextual dataset comprising social media posts in Russian and Ukrainian.\nSpecifically, the focus is on the binary classification task of identifying\nreferences to human rights violations within the dataset.\n  To evaluate the effectiveness of these models, their annotations are compared\nagainst a gold standard set of human double-annotated labels across 1000\nsamples. The analysis includes assessing annotation performance under different\nprompting conditions, with prompts provided in both English and Russian.\nAdditionally, the study explores the unique patterns of errors and\ndisagreements exhibited by each model, offering insights into their strengths,\nlimitations, and cross-linguistic adaptability.\n  By juxtaposing LLM outputs with human annotations, this research contributes\nto understanding the reliability and applicability of LLMs for sensitive,\ndomain-specific tasks in multilingual contexts. It also sheds light on how\nlanguage models handle inherently subjective and context-dependent judgments, a\ncritical consideration for their deployment in real-world scenarios."}
{"id": "2505.08202", "pdf": "https://arxiv.org/pdf/2505.08202", "abs": "https://arxiv.org/abs/2505.08202", "authors": ["Aman Raj", "Lakshit Arora", "Sanjay Surendranath Girija", "Shashank Kapoor", "Dipen Pradhan", "Ankit Shetgaonkar"], "title": "AI and Generative AI Transforming Disaster Management: A Survey of Damage Assessment and Response Techniques", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "Accepted in IEEE Compsac 2025", "summary": "Natural disasters, including earthquakes, wildfires and cyclones, bear a huge\nrisk on human lives as well as infrastructure assets. An effective response to\ndisaster depends on the ability to rapidly and efficiently assess the intensity\nof damage. Artificial Intelligence (AI) and Generative Artificial Intelligence\n(GenAI) presents a breakthrough solution, capable of combining knowledge from\nmultiple types and sources of data, simulating realistic scenarios of disaster,\nand identifying emerging trends at a speed previously unimaginable. In this\npaper, we present a comprehensive review on the prospects of AI and GenAI in\ndamage assessment for various natural disasters, highlighting both its\nstrengths and limitations. We talk about its application to multimodal data\nsuch as text, image, video, and audio, and also cover major issues of data\nprivacy, security, and ethical use of the technology during crises. The paper\nalso recognizes the threat of Generative AI misuse, in the form of\ndissemination of misinformation and for adversarial attacks. Finally, we\noutline avenues of future research, emphasizing the need for secure, reliable,\nand ethical Generative AI systems for disaster management in general. We\nbelieve that this work represents the first comprehensive survey of Gen-AI\ntechniques being used in the field of Disaster Assessment and Response."}
{"id": "2505.09907", "pdf": "https://arxiv.org/pdf/2505.09907", "abs": "https://arxiv.org/abs/2505.09907", "authors": ["Linwei Zhang", "LuFeng", "Ruijia Liang"], "title": "Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "With the growing demand for healthy foods, agricultural product price\nforecasting has become increasingly important. Hass avocados, as a high-value\ncrop, exhibit complex price fluctuations influenced by factors such as\nseasonality, region, and weather. Traditional prediction models often struggle\nwith highly nonlinear and dynamic data. To address this, we propose a hybrid\ndeep learning model, TCN-MLP-Attention Architecture, combining Temporal\nConvolutional Networks (TCN) for sequential feature extraction, Multi-Layer\nPerceptrons (MLP) for nonlinear interactions, and an Attention mechanism for\ndynamic feature weighting. The dataset used covers over 50,000 records of Hass\navocado sales across the U.S. from 2015 to 2018, including variables such as\nsales volume, average price, time, region, weather, and variety type, collected\nfrom point-of-sale systems and the Hass Avocado Board. After systematic\npreprocessing, including missing value imputation and feature normalization,\nthe proposed model was trained and evaluated. Experimental results demonstrate\nthat the TCN-MLP-Attention model achieves excellent predictive performance,\nwith an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods.\nThis research provides a scalable and effective approach for time series\nforecasting in agricultural markets and offers valuable insights for\nintelligent supply chain management and price strategy optimization."}
{"id": "2505.10055", "pdf": "https://arxiv.org/pdf/2505.10055", "abs": "https://arxiv.org/abs/2505.10055", "authors": ["Ijazul Haq", "Yingjie Zhang", "Irfan Ali Khan"], "title": "PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper evaluates the performance of Large Multimodal Models (LMMs) on\nOptical Character Recognition (OCR) in the low-resource Pashto language.\nNatural Language Processing (NLP) in Pashto faces several challenges due to the\ncursive nature of its script and a scarcity of structured datasets. To address\nthis, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one\nmillion images annotated with bounding boxes at word, line, and document\nlevels, suitable for training and evaluating models based on different\narchitectures, including Convolutional Neural Networks (CNNs) and Transformers.\nPsOCR covers variations across 1,000 unique font families, colors, image sizes,\nand layouts. A benchmark subset of 10K images was selected to evaluate the\nperformance of several LMMs, including seven open-source models: DeepSeek's\nJanus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four\nclosed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results\ndemonstrate that Gemini achieves the best performance among all models, whereas\namong open-source models, Qwen-7B stands out. This work provides an insightful\nassessment of the capabilities and limitations of current LMMs for OCR tasks in\nPashto and establishes a foundation for further research not only in Pashto OCR\nbut also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is\navailable at https://github.com/zirak-ai/PashtoOCR."}
{"id": "2505.10261", "pdf": "https://arxiv.org/pdf/2505.10261", "abs": "https://arxiv.org/abs/2505.10261", "authors": ["Rui Yang", "Huitao Li", "Matthew Yu Heng Wong", "Yuhe Ke", "Xin Li", "Kunyu Yu", "Jingchi Liao", "Jonathan Chong Kai Liew", "Sabarinath Vinod Nair", "Jasmine Chiat Ling Ong", "Irene Li", "Douglas Teodoro", "Chuan Hong", "Daniel Shu Wei Ting", "Nan Liu"], "title": "The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Natural language processing (NLP) has been traditionally applied to medicine,\nand generative large language models (LLMs) have become prominent recently.\nHowever, the differences between them across different medical tasks remain\nunderexplored. We analyzed 19,123 studies, finding that generative LLMs\ndemonstrate advantages in open-ended tasks, while traditional NLP dominates in\ninformation extraction and analysis tasks. As these technologies advance,\nethical use of them is essential to ensure their potential in medical\napplications."}
{"id": "2505.09593", "pdf": "https://arxiv.org/pdf/2505.09593", "abs": "https://arxiv.org/abs/2505.09593", "authors": ["Filippo Leveni", "Guilherme Weigert Cassales", "Bernhard Pfahringer", "Albert Bifet", "Giacomo Boracchi"], "title": "Online Isolation Forest", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at International Conference on Machine Learning (ICML 2024)", "summary": "The anomaly detection literature is abundant with offline methods, which\nrequire repeated access to data in memory, and impose impractical assumptions\nwhen applied to a streaming context. Existing online anomaly detection methods\nalso generally fail to address these constraints, resorting to periodic\nretraining to adapt to the online context. We propose Online-iForest, a novel\nmethod explicitly designed for streaming conditions that seamlessly tracks the\ndata generating process as it evolves over time. Experimental validation on\nreal-world datasets demonstrated that Online-iForest is on par with online\nalternatives and closely rivals state-of-the-art offline anomaly detection\ntechniques that undergo periodic retraining. Notably, Online-iForest\nconsistently outperforms all competitors in terms of efficiency, making it a\npromising solution in applications where fast identification of anomalies is of\nprimary importance such as cybersecurity, fraud and fault detection."}
{"id": "2505.09922", "pdf": "https://arxiv.org/pdf/2505.09922", "abs": "https://arxiv.org/abs/2505.09922", "authors": ["Zichen Liu", "Wei Zhang", "Tiejun Li"], "title": "Improving the Euclidean Diffusion Generation of Manifold Data by Mitigating Score Function Singularity", "categories": ["cs.LG"], "comment": "22 pages", "summary": "Euclidean diffusion models have achieved remarkable success in generative\nmodeling across diverse domains, and they have been extended to manifold case\nin recent advances. Instead of explicitly utilizing the structure of special\nmanifolds as studied in previous works, we investigate direct sampling of the\nEuclidean diffusion models for general manifold-constrained data in this paper.\nWe reveal the multiscale singularity of the score function in the embedded\nspace of manifold, which hinders the accuracy of diffusion-generated samples.\nWe then present an elaborate theoretical analysis of the singularity structure\nof the score function by separating it along the tangential and normal\ndirections of the manifold. To mitigate the singularity and improve the\nsampling accuracy, we propose two novel methods: (1) Niso-DM, which introduces\nnon-isotropic noise along the normal direction to reduce scale discrepancies,\nand (2) Tango-DM, which trains only the tangential component of the score\nfunction using a tangential-only loss function. Numerical experiments\ndemonstrate that our methods achieve superior performance on distributions over\nvarious manifolds with complex geometries."}
{"id": "2505.10072", "pdf": "https://arxiv.org/pdf/2505.10072", "abs": "https://arxiv.org/abs/2505.10072", "authors": ["Rui-Yang Ju", "Sheng-Yen Huang", "Yi-Ping Hung"], "title": "ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars", "categories": ["cs.CV"], "comment": null, "summary": "The introduction of 3D Gaussian blendshapes has enabled the real-time\nreconstruction of animatable head avatars from monocular video. Toonify, a\nStyleGAN-based framework, has become widely used for facial image stylization.\nTo extend Toonify for synthesizing diverse stylized 3D head avatars using\nGaussian blendshapes, we propose an efficient two-stage framework, ToonifyGB.\nIn Stage 1 (stylized video generation), we employ an improved StyleGAN to\ngenerate the stylized video from the input video frames, which addresses the\nlimitation of cropping aligned faces at a fixed resolution as preprocessing for\nnormal StyleGAN. This process provides a more stable video, which enables\nGaussian blendshapes to better capture the high-frequency details of the video\nframes, and efficiently generate high-quality animation in the next stage. In\nStage 2 (Gaussian blendshapes synthesis), we learn a stylized neutral head\nmodel and a set of expression blendshapes from the generated video. By\ncombining the neutral head model with expression blendshapes, ToonifyGB can\nefficiently render stylized avatars with arbitrary expressions. We validate the\neffectiveness of ToonifyGB on the benchmark dataset using two styles: Arcane\nand Pixar."}
{"id": "2505.10282", "pdf": "https://arxiv.org/pdf/2505.10282", "abs": "https://arxiv.org/abs/2505.10282", "authors": ["Dubai Li", "Nan Jiang", "Kangping Huang", "Ruiqi Tu", "Shuyu Ouyang", "Huayu Yu", "Lin Qiao", "Chen Yu", "Tianshu Zhou", "Danyang Tong", "Qian Wang", "Mengtao Li", "Xiaofeng Zeng", "Yu Tian", "Xinping Tian", "Jingsong Li"], "title": "From Questions to Clinical Recommendations: Large Language Models Driving Evidence-Based Clinical Decision Making", "categories": ["cs.CL"], "comment": null, "summary": "Clinical evidence, derived from rigorous research and data analysis, provides\nhealthcare professionals with reliable scientific foundations for informed\ndecision-making. Integrating clinical evidence into real-time practice is\nchallenging due to the enormous workload, complex professional processes, and\ntime constraints. This highlights the need for tools that automate evidence\nsynthesis to support more efficient and accurate decision making in clinical\nsettings. This study introduces Quicker, an evidence-based clinical decision\nsupport system powered by large language models (LLMs), designed to automate\nevidence synthesis and generate clinical recommendations modeled after standard\nclinical guideline development processes. Quicker implements a fully automated\nchain that covers all phases, from questions to clinical recommendations, and\nfurther enables customized decision-making through integrated tools and\ninteractive user interfaces. To evaluate Quicker's capabilities, we developed\nthe Q2CRBench-3 benchmark dataset, based on clinical guideline development\nrecords for three different diseases. Experimental results highlighted\nQuicker's strong performance, with fine-grained question decomposition tailored\nto user preferences, retrieval sensitivities comparable to human experts, and\nliterature screening performance approaching comprehensive inclusion of\nrelevant studies. In addition, Quicker-assisted evidence assessment effectively\nsupported human reviewers, while Quicker's recommendations were more\ncomprehensive and logically coherent than those of clinicians. In system-level\ntesting, collaboration between a single reviewer and Quicker reduced the time\nrequired for recommendation development to 20-40 minutes. In general, our\nfindings affirm the potential of Quicker to help physicians make quicker and\nmore reliable evidence-based clinical decisions."}
{"id": "2505.09616", "pdf": "https://arxiv.org/pdf/2505.09616", "abs": "https://arxiv.org/abs/2505.09616", "authors": ["Yuqi Li", "Yuanzhong Zheng", "Zhongtian Guo", "Yaoxuan Wang", "Jianjun Yin", "Haojun Fei"], "title": "SpecWav-Attack: Leveraging Spectrogram Resizing and Wav2Vec 2.0 for Attacking Anonymized Speech", "categories": ["cs.SD", "cs.AI", "eess.AS", "I.2.0"], "comment": "2 pages,3 figures,1 chart", "summary": "This paper presents SpecWav-Attack, an adversarial model for detecting\nspeakers in anonymized speech. It leverages Wav2Vec2 for feature extraction and\nincorporates spectrogram resizing and incremental training for improved\nperformance. Evaluated on librispeech-dev and librispeech-test, SpecWav-Attack\noutperforms conventional attacks, revealing vulnerabilities in anonymized\nspeech systems and emphasizing the need for stronger defenses, benchmarked\nagainst the ICASSP 2025 Attacker Challenge."}
{"id": "2505.09925", "pdf": "https://arxiv.org/pdf/2505.09925", "abs": "https://arxiv.org/abs/2505.09925", "authors": ["Yutao Yang", "Jie Zhou", "Junsong Li", "Qianjun Pan", "Bihao Zhan", "Qin Chen", "Xipeng Qiu", "Liang He"], "title": "Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces an interactive continual learning paradigm where AI\nmodels dynamically learn new skills from real-time human feedback while\nretaining prior knowledge. This paradigm distinctively addresses two major\nlimitations of traditional continual learning: (1) dynamic model updates using\nstreaming, real-time human-annotated data, rather than static datasets with\nfixed labels, and (2) the assumption of clean labels, by explicitly handling\nthe noisy feedback common in real-world interactions. To tackle these problems,\nwe propose RiCL, a Reinforced interactive Continual Learning framework\nleveraging Large Language Models (LLMs) to learn new skills effectively from\ndynamic feedback. RiCL incorporates three key components: a temporal\nconsistency-aware purifier to automatically discern clean from noisy samples in\ndata streams; an interaction-aware direct preference optimization strategy to\nalign model behavior with human intent by reconciling AI-generated and\nhuman-provided feedback; and a noise-resistant contrastive learning module that\ncaptures robust representations by exploiting inherent data relationships, thus\navoiding reliance on potentially unreliable labels. Extensive experiments on\ntwo benchmark datasets (FewRel and TACRED), contaminated with realistic noise\npatterns, demonstrate that our RiCL approach substantially outperforms existing\ncombinations of state-of-the-art online continual learning and noisy-label\nlearning methods."}
{"id": "2505.10088", "pdf": "https://arxiv.org/pdf/2505.10088", "abs": "https://arxiv.org/abs/2505.10088", "authors": ["Yuncheng Guo", "Xiaodong Gu"], "title": "MMRL++: Parameter-Efficient and Interaction-Aware Representation Learning for Vision-Language Models", "categories": ["cs.CV"], "comment": "Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract appearing here is slightly shorter than that in the\n  PDF file", "summary": "Large-scale pre-trained Vision-Language Models (VLMs) have significantly\nadvanced transfer learning across diverse tasks. However, adapting these models\nwith limited few-shot data often leads to overfitting, undermining their\nability to generalize to new tasks. To address this, we propose Multi-Modal\nRepresentation Learning (MMRL), which introduces a shared, learnable,\nmodality-agnostic representation space. MMRL generates space tokens projected\ninto both text and image encoders as representation tokens, enabling more\neffective cross-modal interactions. Unlike prior methods that mainly optimize\nclass token features, MMRL inserts representation tokens into higher encoder\nlayers--where task-specific features are more prominent--while preserving\ngeneral knowledge in the lower layers. During training, both class and\nrepresentation features are jointly optimized: a trainable projection layer is\napplied to representation tokens for task adaptation, while the projection\nlayer for class token remains frozen to retain pre-trained knowledge. To\nfurther promote generalization, we introduce a regularization term aligning\nclass and text features with the frozen VLM's zero-shot features. At inference,\na decoupling strategy uses both class and representation features for base\ntasks, but only class features for novel tasks due to their stronger\ngeneralization. Building upon this, we propose MMRL++, a parameter-efficient\nand interaction-aware extension that significantly reduces trainable parameters\nand enhances intra-modal interactions--particularly across the layers of\nrepresentation tokens--allowing gradient sharing and instance-specific\ninformation to propagate more effectively through the network. Extensive\nexperiments on 15 datasets demonstrate that MMRL and MMRL++ consistently\noutperform state-of-the-art methods, achieving a strong balance between\ntask-specific adaptation and generalization."}
{"id": "2505.10320", "pdf": "https://arxiv.org/pdf/2505.10320", "abs": "https://arxiv.org/abs/2505.10320", "authors": ["Chenxi Whitehouse", "Tianlu Wang", "Ping Yu", "Xian Li", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 8 tables, 11 figures", "summary": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses."}
{"id": "2505.09619", "pdf": "https://arxiv.org/pdf/2505.09619", "abs": "https://arxiv.org/abs/2505.09619", "authors": ["Pietro Cassieri", "Aiman Faiz", "Anna Maria De Roberto", "Claudio Pascarelli", "Gianvito Mitrano", "Gianluca Fimiani", "Marina Garofano", "Christiancarmine Esposito", "Genoveffa Tortora", "Alessia Bramanti", "Giuseppe Scanniello"], "title": "Predictive Models for Chronic Heart Failure", "categories": ["stat.OT", "cs.AI"], "comment": null, "summary": "The management of chronic Heart Failure (HF) presents significant challenges\nin modern healthcare, requiring continuous monitoring, early detection of\nexacerbations, and personalized treatment strategies. In this paper, we present\na predictive model founded on Machine Learning (ML) techniques to identify\npatients at HF risk. This model is an ensemble learning approach, a modified\nstacking technique, that uses two specialized models leveraging clinical and\nechocardiographic features and then a meta-model to combine the predictions of\nthese two models. We initially assess the model on a real dataset and the\nobtained results suggest that it performs well in the stratification of\npatients at HR risk. Specifically, we obtained high sensitivity (95\\%),\nensuring that nearly all high-risk patients are identified. As for accuracy, we\nobtained 84\\%, which can be considered moderate in some ML contexts. However,\nit is acceptable given our priority of identifying patients at risk of HF\nbecause they will be asked to participate in the telemonitoring program of the\nPrediHealth research project on which some of the authors of this paper are\nworking. The initial findings also suggest that ML-based risk stratification\nmodels can serve as valuable decision-support tools not only in the PrediHealth\nproject but also for healthcare professionals, aiding in early intervention and\npersonalized patient management. To have a better understanding of the value\nand of potentiality of our predictive model, we also contrasted its results\nwith those obtained by using three baseline models. The preliminary results\nindicate that our predictive model outperforms these baselines that flatly\nconsider features, \\ie not grouping them in clinical and echocardiographic\nfeatures."}
{"id": "2505.09949", "pdf": "https://arxiv.org/pdf/2505.09949", "abs": "https://arxiv.org/abs/2505.09949", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Samgyu Yang", "Abdulrahman Faden"], "title": "Advanced Crash Causation Analysis for Freeway Safety: A Large Language Model Approach to Identifying Key Contributing Factors", "categories": ["cs.LG", "cs.CL", "stat.AP"], "comment": null, "summary": "Understanding the factors contributing to traffic crashes and developing\nstrategies to mitigate their severity is essential. Traditional statistical\nmethods and machine learning models often struggle to capture the complex\ninteractions between various factors and the unique characteristics of each\ncrash. This research leverages large language model (LLM) to analyze freeway\ncrash data and provide crash causation analysis accordingly. By compiling 226\ntraffic safety studies related to freeway crashes, a training dataset\nencompassing environmental, driver, traffic, and geometric design factors was\ncreated. The Llama3 8B model was fine-tuned using QLoRA to enhance its\nunderstanding of freeway crashes and their contributing factors, as covered in\nthese studies. The fine-tuned Llama3 8B model was then used to identify crash\ncausation without pre-labeled data through zero-shot classification, providing\ncomprehensive explanations to ensure that the identified causes were reasonable\nand aligned with existing research. Results demonstrate that LLMs effectively\nidentify primary crash causes such as alcohol-impaired driving, speeding,\naggressive driving, and driver inattention. Incorporating event data, such as\nroad maintenance, offers more profound insights. The model's practical\napplicability and potential to improve traffic safety measures were validated\nby a high level of agreement among researchers in the field of traffic safety,\nas reflected in questionnaire results with 88.89%. This research highlights the\ncomplex nature of traffic crashes and how LLMs can be used for comprehensive\nanalysis of crash causation and other contributing factors. Moreover, it\nprovides valuable insights and potential countermeasures to aid planners and\npolicymakers in developing more effective and efficient traffic safety\npractices."}
{"id": "2505.10118", "pdf": "https://arxiv.org/pdf/2505.10118", "abs": "https://arxiv.org/abs/2505.10118", "authors": ["Yangfu Li", "Hongjian Zhan", "Tianyi Chen", "Qi Liu", "Yue Lu"], "title": "Why 1 + 1 < 1 in Visual Token Pruning: Beyond Naive Integration via Multi-Objective Balanced Covering", "categories": ["cs.CV", "cs.CL"], "comment": "31 pages,9 figures,conference", "summary": "Existing visual token pruning methods target prompt alignment and visual\npreservation with static strategies, overlooking the varying relative\nimportance of these objectives across tasks, which leads to inconsistent\nperformance. To address this, we derive the first closed-form error bound for\nvisual token pruning based on the Hausdorff distance, uniformly characterizing\nthe contributions of both objectives. Moreover, leveraging $\\epsilon$-covering\ntheory, we reveal an intrinsic trade-off between these objectives and quantify\ntheir optimal attainment levels under a fixed budget. To practically handle\nthis trade-off, we propose Multi-Objective Balanced Covering (MoB), which\nreformulates visual token pruning as a bi-objective covering problem. In this\nframework, the attainment trade-off reduces to budget allocation via greedy\nradius trading. MoB offers a provable performance bound and linear scalability\nwith respect to the number of input visual tokens, enabling adaptation to\nchallenging pruning scenarios. Extensive experiments show that MoB preserves\n96.4% of performance for LLaVA-1.5-7B using only 11.1% of the original visual\ntokens and accelerates LLaVA-Next-7B by 1.3-1.5$\\times$ with negligible\nperformance loss. Additionally, evaluations on Qwen2-VL and Video-LLaVA confirm\nthat MoB integrates seamlessly into advanced MLLMs and diverse vision-language\ntasks."}
{"id": "2505.10354", "pdf": "https://arxiv.org/pdf/2505.10354", "abs": "https://arxiv.org/abs/2505.10354", "authors": ["Yile Wang", "Zhanyu Shen", "Hui Huang"], "title": "LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Semantic text representation is a fundamental task in the field of natural\nlanguage processing. Existing text embedding (e.g., SimCSE and LLM2Vec) have\ndemonstrated excellent performance, but the values of each dimension are\ndifficult to trace and interpret. Bag-of-words, as classic sparse interpretable\nembeddings, suffers from poor performance. Recently, Benara et al. (2024)\npropose interpretable text embeddings using large language models, which forms\n\"0/1\" embeddings based on responses to a series of questions. These\ninterpretable text embeddings are typically high-dimensional (larger than\n10,000). In this work, we propose Low-dimensional (lower than 500) Dense and\nInterpretable text embeddings with Relative representations (LDIR). The\nnumerical values of its dimensions indicate semantic relatedness to different\nanchor texts through farthest point sampling, offering both semantic\nrepresentation as well as a certain level of traceability and interpretability.\nWe validate LDIR on multiple semantic textual similarity, retrieval, and\nclustering tasks. Extensive experimental results show that LDIR performs close\nto the black-box baseline models and outperforms the interpretable embeddings\nbaselines with much fewer dimensions. Code is available at\nhttps://github.com/szu-tera/LDIR."}
{"id": "2505.09624", "pdf": "https://arxiv.org/pdf/2505.09624", "abs": "https://arxiv.org/abs/2505.09624", "authors": ["Ekaterina Kuzmina", "Dmitrii Kriukov", "Mikhail Lebedev", "Dmitry V. Dylov"], "title": "Neurophysiologically Realistic Environment for Comparing Adaptive Deep Brain Stimulation Algorithms in Parkinson Disease", "categories": ["q-bio.NC", "cs.AI", "68T05"], "comment": "8 pages, 3 figures, submission to KDD", "summary": "Adaptive deep brain stimulation (aDBS) has emerged as a promising treatment\nfor Parkinson disease (PD). In aDBS, a surgically placed electrode sends\ndynamically altered stimuli to the brain based on neurophysiological feedback:\nan invasive gadget that limits the amount of data one could collect for\noptimizing the control offline. As a consequence, a plethora of synthetic\nmodels of PD and those of the control algorithms have been proposed. Herein, we\nintroduce the first neurophysiologically realistic benchmark for comparing said\nmodels. Specifically, our methodology covers not only conventional basal\nganglia circuit dynamics and pathological oscillations, but also captures 15\npreviously dismissed physiological attributes, such as signal instabilities and\nnoise, neural drift, electrode conductance changes and individual variability -\nall modeled as spatially distributed and temporally registered features via\nbeta-band activity in the brain and a feedback. Furthermore, we purposely built\nour framework as a structured environment for training and evaluating deep\nreinforcement learning (RL) algorithms, opening new possibilities for\noptimizing aDBS control strategies and inviting the machine learning community\nto contribute to the emerging field of intelligent neurostimulation interfaces."}
{"id": "2505.09952", "pdf": "https://arxiv.org/pdf/2505.09952", "abs": "https://arxiv.org/abs/2505.09952", "authors": ["Tianyu Huai", "Jie Zhou", "Yuxuan Cai", "Qin Chen", "Wen Wu", "Xingjiao Wu", "Xipeng Qiu", "Liang He"], "title": "Task-Core Memory Management and Consolidation for Long-term Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to Neurips2025", "summary": "In this paper, we focus on a long-term continual learning (CL) task, where a\nmodel learns sequentially from a stream of vast tasks over time, acquiring new\nknowledge while retaining previously learned information in a manner akin to\nhuman learning. Unlike traditional CL settings, long-term CL involves handling\na significantly larger number of tasks, which exacerbates the issue of\ncatastrophic forgetting. Our work seeks to address two critical questions: 1)\nHow do existing CL methods perform in the context of long-term CL? and 2) How\ncan we mitigate the catastrophic forgetting that arises from prolonged\nsequential updates? To tackle these challenges, we propose a novel framework\ninspired by human memory mechanisms for long-term continual learning (Long-CL).\nSpecifically, we introduce a task-core memory management strategy to\nefficiently index crucial memories and adaptively update them as learning\nprogresses. Additionally, we develop a long-term memory consolidation mechanism\nthat selectively retains hard and discriminative samples, ensuring robust\nknowledge retention. To facilitate research in this area, we construct and\nrelease two multi-modal and textual benchmarks, MMLongCL-Bench and\nTextLongCL-Bench, providing a valuable resource for evaluating long-term CL\napproaches. Experimental results show that Long-CL outperforms the previous\nstate-of-the-art by 7.4\\% and 6.5\\% AP on the two benchmarks, respectively,\ndemonstrating the effectiveness of our approach."}
{"id": "2505.10124", "pdf": "https://arxiv.org/pdf/2505.10124", "abs": "https://arxiv.org/abs/2505.10124", "authors": ["Ziad Kheil", "Lucas Robinet", "Laurent Risser", "Soleakhena Ken"], "title": "IMITATE: Image Registration with Context for unknown time frame recovery", "categories": ["cs.CV", "eess.IV"], "comment": "IEEE ISBI 2025", "summary": "In this paper, we formulate a novel image registration formalism dedicated to\nthe estimation of unknown condition-related images, based on two or more known\nimages and their associated conditions. We show how to practically model this\nformalism by using a new conditional U-Net architecture, which fully takes into\naccount the conditional information and does not need any fixed image. Our\nformalism is then applied to image moving tumors for radiotherapy treatment at\ndifferent breathing amplitude using 4D-CT (3D+t) scans in thoracoabdominal\nregions. This driving application is particularly complex as it requires to\nstitch a collection of sequential 2D slices into several 3D volumes at\ndifferent organ positions. Movement interpolation with standard methods then\ngenerates well known reconstruction artefacts in the assembled volumes due to\nirregular patient breathing, hysteresis and poor correlation of breathing\nsignal to internal motion. Results obtained on 4D-CT clinical data showcase\nartefact-free volumes achieved through real-time latencies. The code is\npublicly available at https://github.com/Kheil-Z/IMITATE ."}
{"id": "2505.10356", "pdf": "https://arxiv.org/pdf/2505.10356", "abs": "https://arxiv.org/abs/2505.10356", "authors": ["Chunyu Ye", "Shaonan Wang"], "title": "Coherent Language Reconstruction from Brain Recordings with Flexible Multi-Modal Input Stimuli", "categories": ["cs.CL"], "comment": null, "summary": "Decoding thoughts from brain activity offers valuable insights into human\ncognition and enables promising applications in brain-computer interaction.\nWhile prior studies have explored language reconstruction from fMRI data, they\nare typically limited to single-modality inputs such as images or audio. In\ncontrast, human thought is inherently multimodal. To bridge this gap, we\npropose a unified and flexible framework for reconstructing coherent language\nfrom brain recordings elicited by diverse input modalities-visual, auditory,\nand textual. Our approach leverages visual-language models (VLMs), using\nmodality-specific experts to jointly interpret information across modalities.\nExperiments demonstrate that our method achieves performance comparable to\nstate-of-the-art systems while remaining adaptable and extensible. This work\nadvances toward more ecologically valid and generalizable mind decoding."}
{"id": "2505.09646", "pdf": "https://arxiv.org/pdf/2505.09646", "abs": "https://arxiv.org/abs/2505.09646", "authors": ["Carmel Mary Esther A"], "title": "Temporal Interception and Present Reconstruction: A Cognitive-Signal Model for Human and AI Decision Making", "categories": ["q-bio.NC", "cs.AI", "physics.hist-ph"], "comment": "8 pages, 3 figures", "summary": "This paper proposes a novel theoretical model to explain how the human mind\nand artificial intelligence can approach real-time awareness by reducing\nperceptual delays. By investigating cosmic signal delay, neurological reaction\ntimes, and the ancient cognitive state of stillness, we explore how one may\nshift from reactive perception to a conscious interface with the near future.\nThis paper introduces both a physical and cognitive model for perceiving the\npresent not as a linear timestamp, but as an interference zone where\nearly-arriving cosmic signals and reactive human delays intersect. We propose\nexperimental approaches to test these ideas using human neural observation and\nneuro-receptive extensions. Finally, we propose a mathematical framework to\nguide the evolution of AI systems toward temporally efficient, ethically sound,\nand internally conscious decision-making processes"}
{"id": "2505.09955", "pdf": "https://arxiv.org/pdf/2505.09955", "abs": "https://arxiv.org/abs/2505.09955", "authors": ["Jaeho Kim", "Seulki Lee"], "title": "TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 Accept", "summary": "Unsupervised domain adaptation (UDA) for time series data remains a critical\nchallenge in deep learning, with traditional pseudo-labeling strategies failing\nto capture temporal patterns and channel-wise shifts between domains, producing\nsub-optimal pseudo-labels. As such, we introduce TransPL, a novel approach that\naddresses these limitations by modeling the joint distribution $P(\\mathbf{X},\ny)$ of the source domain through code transition matrices, where the codes are\nderived from vector quantization (VQ) of time series patches. Our method\nconstructs class- and channel-wise code transition matrices from the source\ndomain and employs Bayes' rule for target domain adaptation, generating\npseudo-labels based on channel-wise weighted class-conditional likelihoods.\nTransPL offers three key advantages: explicit modeling of temporal transitions\nand channel-wise shifts between different domains, versatility towards\ndifferent UDA scenarios (e.g., weakly-supervised UDA), and explainable\npseudo-label generation. We validate TransPL's effectiveness through extensive\nanalysis on four time series UDA benchmarks and confirm that it consistently\noutperforms state-of-the-art pseudo-labeling methods by a strong margin (6.1%\naccuracy improvement, 4.9% F1 improvement), while providing interpretable\ninsights into the domain adaptation process through its learned code transition\nmatrices."}
{"id": "2505.10152", "pdf": "https://arxiv.org/pdf/2505.10152", "abs": "https://arxiv.org/abs/2505.10152", "authors": ["Yikang Wei"], "title": "Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization", "categories": ["cs.CV"], "comment": "IJCAI 2025", "summary": "Federated domain generalization aims to learn a generalizable model from\nmultiple decentralized source domains for deploying on the unseen target\ndomain. The style augmentation methods have achieved great progress on domain\ngeneralization. However, the existing style augmentation methods either explore\nthe data styles within isolated source domain or interpolate the style\ninformation across existing source domains under the data decentralization\nscenario, which leads to limited style space. To address this issue, we propose\na Multi-source Collaborative Style Augmentation and Domain-invariant learning\nmethod (MCSAD) for federated domain generalization. Specifically, we propose a\nmulti-source collaborative style augmentation module to generate data in the\nbroader style space. Furthermore, we conduct domain-invariant learning between\nthe original data and augmented data by cross-domain feature alignment within\nthe same class and classes relation ensemble distillation between different\nclasses to learn a domain-invariant model. By alternatively conducting\ncollaborative style augmentation and domain-invariant learning, the model can\ngeneralize well on unseen target domain. Extensive experiments on multiple\ndomain generalization datasets indicate that our method significantly\noutperforms the state-of-the-art federated domain generalization methods."}
{"id": "2505.10389", "pdf": "https://arxiv.org/pdf/2505.10389", "abs": "https://arxiv.org/abs/2505.10389", "authors": ["Benjamin White", "Anastasia Shimorina"], "title": "Multi-domain Multilingual Sentiment Analysis in Industry: Predicting Aspect-based Opinion Quadruples", "categories": ["cs.CL"], "comment": null, "summary": "This paper explores the design of an aspect-based sentiment analysis system\nusing large language models (LLMs) for real-world use. We focus on quadruple\nopinion extraction -- identifying aspect categories, sentiment polarity,\ntargets, and opinion expressions from text data across different domains and\nlanguages. Using internal datasets, we investigate whether a single fine-tuned\nmodel can effectively handle multiple domain-specific taxonomies\nsimultaneously. We demonstrate that a combined multi-domain model achieves\nperformance comparable to specialized single-domain models while reducing\noperational complexity. We also share lessons learned for handling\nnon-extractive predictions and evaluating various failure modes when developing\nLLM-based systems for structured prediction tasks."}
{"id": "2505.09651", "pdf": "https://arxiv.org/pdf/2505.09651", "abs": "https://arxiv.org/abs/2505.09651", "authors": ["Xixuan Hao", "Yutian Jiang", "Xingchen Zou", "Jiabo Liu", "Yifang Yin", "Yuxuan Liang"], "title": "Unlocking Location Intelligence: A Survey from Deep Learning to The LLM Era", "categories": ["cs.DB", "cs.AI", "cs.LG"], "comment": null, "summary": "Location Intelligence (LI), the science of transforming location-centric\ngeospatial data into actionable knowledge, has become a cornerstone of modern\nspatial decision-making. The rapid evolution of Geospatial Representation\nLearning is fundamentally reshaping LI development through two successive\ntechnological revolutions: the deep learning breakthrough and the emerging\nlarge language model (LLM) paradigm. While deep neural networks (DNNs) have\ndemonstrated remarkable success in automated feature extraction from structured\ngeospatial data (e.g., satellite imagery, GPS trajectories), the recent\nintegration of LLMs introduces transformative capabilities for cross-modal\ngeospatial reasoning and unstructured geo-textual data processing. This survey\npresents a comprehensive review of geospatial representation learning across\nboth technological eras, organizing them into a structured taxonomy based on\nthe complete pipeline comprising: (1) data perspective, (2) methodological\nperspective and (3) application perspective. We also highlight current\nadvancements, discuss existing limitations, and propose potential future\nresearch directions in the LLM era. This work offers a thorough exploration of\nthe field and providing a roadmap for further innovation in LI. The summary of\nthe up-to-date paper list can be found in\nhttps://github.com/CityMind-Lab/Awesome-Location-Intelligence and will undergo\ncontinuous updates."}
{"id": "2505.09959", "pdf": "https://arxiv.org/pdf/2505.09959", "abs": "https://arxiv.org/abs/2505.09959", "authors": ["Zengxia Guo", "Bohui An", "Zhongqi Lu"], "title": "Approximated Behavioral Metric-based State Projection for Federated Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated reinforcement learning (FRL) methods usually share the encrypted\nlocal state or policy information and help each client to learn from others\nwhile preserving everyone's privacy. In this work, we propose that sharing the\napproximated behavior metric-based state projection function is a promising way\nto enhance the performance of FRL and concurrently provides an effective\nprotection of sensitive information. We introduce FedRAG, a FRL framework to\nlearn a computationally practical projection function of states for each client\nand aggregating the parameters of projection functions at a central server. The\nFedRAG approach shares no sensitive task-specific information, yet provides\ninformation gain for each client. We conduct extensive experiments on the\nDeepMind Control Suite to demonstrate insightful results."}
{"id": "2505.10169", "pdf": "https://arxiv.org/pdf/2505.10169", "abs": "https://arxiv.org/abs/2505.10169", "authors": ["Matthias Kümmerer", "Harneet Khanuja", "Matthias Bethge"], "title": "Modeling Saliency Dataset Bias", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes."}
{"id": "2505.10402", "pdf": "https://arxiv.org/pdf/2505.10402", "abs": "https://arxiv.org/abs/2505.10402", "authors": ["Yihong Dong", "Yuchen Liu", "Xue Jiang", "Zhi Jin", "Ge Li"], "title": "Rethinking Repetition Problems of LLMs in Code Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to ACL 2025 (main)", "summary": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code."}
{"id": "2505.09653", "pdf": "https://arxiv.org/pdf/2505.09653", "abs": "https://arxiv.org/abs/2505.09653", "authors": ["Samuel Yen-Chi Chen", "Chen-Yu Liu", "Kuan-Cheng Chen", "Wei-Jia Huang", "Yen-Jui Chang", "Wei-Hao Huang"], "title": "Differentiable Quantum Architecture Search in Quantum-Enhanced Neural Network Parameter Generation", "categories": ["quant-ph", "cs.AI", "cs.ET", "cs.LG", "cs.NE"], "comment": null, "summary": "The rapid advancements in quantum computing (QC) and machine learning (ML)\nhave led to the emergence of quantum machine learning (QML), which integrates\nthe strengths of both fields. Among QML approaches, variational quantum\ncircuits (VQCs), also known as quantum neural networks (QNNs), have shown\npromise both empirically and theoretically. However, their broader adoption is\nhindered by reliance on quantum hardware during inference. Hardware\nimperfections and limited access to quantum devices pose practical challenges.\nTo address this, the Quantum-Train (QT) framework leverages the exponential\nscaling of quantum amplitudes to generate classical neural network parameters,\nenabling inference without quantum hardware and achieving significant parameter\ncompression. Yet, designing effective quantum circuit architectures for such\nquantum-enhanced neural programmers remains non-trivial and often requires\nexpertise in quantum information science. In this paper, we propose an\nautomated solution using differentiable optimization. Our method jointly\noptimizes both conventional circuit parameters and architectural parameters in\nan end-to-end manner via automatic differentiation. We evaluate the proposed\nframework on classification, time-series prediction, and reinforcement learning\ntasks. Simulation results show that our method matches or outperforms manually\ndesigned QNN architectures. This work offers a scalable and automated pathway\nfor designing QNNs that can generate classical neural network parameters across\ndiverse applications."}
{"id": "2505.09969", "pdf": "https://arxiv.org/pdf/2505.09969", "abs": "https://arxiv.org/abs/2505.09969", "authors": ["Ali Azimi Lamir", "Shiva Razzagzadeh", "Zeynab Rezaei"], "title": "A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study presents a machine learning-based framework for heart disease\nprediction using the heart-disease dataset, comprising 303 samples with 14\nfeatures. The methodology involves data preprocessing, model training, and\nevaluation using three classifiers: Logistic Regression, K-Nearest Neighbors\n(KNN), and Random Forest. Hyperparameter tuning with GridSearchCV and\nRandomizedSearchCV was employed to enhance model performance. The Random Forest\nclassifier outperformed other models, achieving an accuracy of 91% and an\nF1-score of 0.89. Evaluation metrics, including precision, recall, and\nconfusion matrix, revealed balanced performance across classes. The proposed\nmodel demonstrates strong potential for aiding clinical decision-making by\neffectively predicting heart disease. Limitations such as dataset size and\ngeneralizability underscore the need for future studies using larger and more\ndiverse datasets. This work highlights the utility of machine learning in\nhealthcare, offering insights for further advancements in predictive\ndiagnostics."}
{"id": "2505.10205", "pdf": "https://arxiv.org/pdf/2505.10205", "abs": "https://arxiv.org/abs/2505.10205", "authors": ["Umair Haroon", "Ahmad AlMughrabi", "Thanasis Zoumpekas", "Ricardo Marques", "Petia Radeva"], "title": "VolE: A Point-cloud Framework for Food 3D Reconstruction and Volume Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate food volume estimation is crucial for medical nutrition management\nand health monitoring applications, but current food volume estimation methods\nare often limited by mononuclear data, leveraging single-purpose hardware such\nas 3D scanners, gathering sensor-oriented information such as depth\ninformation, or relying on camera calibration using a reference object. In this\npaper, we present VolE, a novel framework that leverages mobile device-driven\n3D reconstruction to estimate food volume. VolE captures images and camera\nlocations in free motion to generate precise 3D models, thanks to AR-capable\nmobile devices. To achieve real-world measurement, VolE is a reference- and\ndepth-free framework that leverages food video segmentation for food mask\ngeneration. We also introduce a new food dataset encompassing the challenging\nscenarios absent in the previous benchmarks. Our experiments demonstrate that\nVolE outperforms the existing volume estimation techniques across multiple\ndatasets by achieving 2.22 % MAPE, highlighting its superior performance in\nfood volume estimation."}
{"id": "2505.10409", "pdf": "https://arxiv.org/pdf/2505.10409", "abs": "https://arxiv.org/abs/2505.10409", "authors": ["Yue Guo", "Jae Ho Sohn", "Gondy Leroy", "Trevor Cohen"], "title": "Are LLM-generated plain language summaries truly understandable? A large-scale crowdsourced evaluation", "categories": ["cs.CL"], "comment": null, "summary": "Plain language summaries (PLSs) are essential for facilitating effective\ncommunication between clinicians and patients by making complex medical\ninformation easier for laypeople to understand and act upon. Large language\nmodels (LLMs) have recently shown promise in automating PLS generation, but\ntheir effectiveness in supporting health information comprehension remains\nunclear. Prior evaluations have generally relied on automated scores that do\nnot measure understandability directly, or subjective Likert-scale ratings from\nconvenience samples with limited generalizability. To address these gaps, we\nconducted a large-scale crowdsourced evaluation of LLM-generated PLSs using\nAmazon Mechanical Turk with 150 participants. We assessed PLS quality through\nsubjective Likert-scale ratings focusing on simplicity, informativeness,\ncoherence, and faithfulness; and objective multiple-choice comprehension and\nrecall measures of reader understanding. Additionally, we examined the\nalignment between 10 automated evaluation metrics and human judgments. Our\nfindings indicate that while LLMs can generate PLSs that appear\nindistinguishable from human-written ones in subjective evaluations,\nhuman-written PLSs lead to significantly better comprehension. Furthermore,\nautomated evaluation metrics fail to reflect human judgment, calling into\nquestion their suitability for evaluating PLSs. This is the first study to\nsystematically evaluate LLM-generated PLSs based on both reader preferences and\ncomprehension outcomes. Our findings highlight the need for evaluation\nframeworks that move beyond surface-level quality and for generation methods\nthat explicitly optimize for layperson comprehension."}
{"id": "2505.09661", "pdf": "https://arxiv.org/pdf/2505.09661", "abs": "https://arxiv.org/abs/2505.09661", "authors": ["Jinghao He", "Zhengyan Sheng", "Liping Chen", "Kong Aik Lee", "Zhen-Hua Ling"], "title": "Introducing voice timbre attribute detection", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "This paper focuses on explaining the timbre conveyed by speech signals and\nintroduces a task termed voice timbre attribute detection (vTAD). In this task,\nvoice timbre is explained with a set of sensory attributes describing its human\nperception. A pair of speech utterances is processed, and their intensity is\ncompared in a designated timbre descriptor. Moreover, a framework is proposed,\nwhich is built upon the speaker embeddings extracted from the speech\nutterances. The investigation is conducted on the VCTK-RVA dataset.\nExperimental examinations on the ECAPA-TDNN and FACodec speaker encoders\ndemonstrated that: 1) the ECAPA-TDNN speaker encoder was more capable in the\nseen scenario, where the testing speakers were included in the training set; 2)\nthe FACodec speaker encoder was superior in the unseen scenario, where the\ntesting speakers were not part of the training, indicating enhanced\ngeneralization capability. The VCTK-RVA dataset and open-source code are\navailable on the website https://github.com/vTAD2025-Challenge/vTAD."}
{"id": "2505.09983", "pdf": "https://arxiv.org/pdf/2505.09983", "abs": "https://arxiv.org/abs/2505.09983", "authors": ["Changxun Zhu", "Qilong Wu", "Lingjuan Lyu", "Shibei Xue"], "title": "Sybil-based Virtual Data Poisoning Attacks in Federated Learning", "categories": ["cs.LG"], "comment": "7 pages, 6 figures, accepted by IEEE Codit 2025", "summary": "Federated learning is vulnerable to poisoning attacks by malicious\nadversaries. Existing methods often involve high costs to achieve effective\nattacks. To address this challenge, we propose a sybil-based virtual data\npoisoning attack, where a malicious client generates sybil nodes to amplify the\npoisoning model's impact. To reduce neural network computational complexity, we\ndevelop a virtual data generation method based on gradient matching. We also\ndesign three schemes for target model acquisition, applicable to online local,\nonline global, and offline scenarios. In simulation, our method outperforms\nother attack algorithms since our method can obtain a global target model under\nnon-independent uniformly distributed data."}
{"id": "2505.10223", "pdf": "https://arxiv.org/pdf/2505.10223", "abs": "https://arxiv.org/abs/2505.10223", "authors": ["Puru Vaish", "Felix Meister", "Tobias Heimann", "Christoph Brune", "Jelmer M. Wolterink"], "title": "Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at MIDL 2025", "summary": "Medical image segmentation models are often trained on curated datasets,\nleading to performance degradation when deployed in real-world clinical\nsettings due to mismatches between training and test distributions. While data\naugmentation techniques are widely used to address these challenges,\ntraditional visually consistent augmentation strategies lack the robustness\nneeded for diverse real-world scenarios. In this work, we systematically\nevaluate alternative augmentation strategies, focusing on MixUp and Auxiliary\nFourier Augmentation. These methods mitigate the effects of multiple variations\nwithout explicitly targeting specific sources of distribution shifts. We\ndemonstrate how these techniques significantly improve out-of-distribution\ngeneralization and robustness to imaging variations across a wide range of\ntransformations in cardiac cine MRI and prostate MRI segmentation. We\nquantitatively find that these augmentation methods enhance learned feature\nrepresentations by promoting separability and compactness. Additionally, we\nhighlight how their integration into nnU-Net training pipelines provides an\neasy-to-implement, effective solution for enhancing the reliability of medical\nsegmentation models in real-world applications."}
{"id": "2505.10413", "pdf": "https://arxiv.org/pdf/2505.10413", "abs": "https://arxiv.org/abs/2505.10413", "authors": ["Jiajie Jin", "Xiaoxi Li", "Guanting Dong", "Yuyao Zhang", "Yutao Zhu", "Yongkang Wu", "Zhonghua Li", "Qi Ye", "Zhicheng Dou"], "title": "Hierarchical Document Refinement for Long-context Retrieval-augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "Real-world RAG applications often encounter long-context input scenarios,\nwhere redundant information and noise results in higher inference costs and\nreduced performance. To address these challenges, we propose LongRefiner, an\nefficient plug-and-play refiner that leverages the inherent structural\ncharacteristics of long documents. LongRefiner employs dual-level query\nanalysis, hierarchical document structuring, and adaptive refinement through\nmulti-task learning on a single foundation model. Experiments on seven QA\ndatasets demonstrate that LongRefiner achieves competitive performance in\nvarious scenarios while using 10x fewer computational costs and latency\ncompared to the best baseline. Further analysis validates that LongRefiner is\nscalable, efficient, and effective, providing practical insights for real-world\nlong-text RAG applications. Our code is available at\nhttps://github.com/ignorejjj/LongRefiner."}
{"id": "2505.09666", "pdf": "https://arxiv.org/pdf/2505.09666", "abs": "https://arxiv.org/abs/2505.09666", "authors": ["Yumin Choi", "Jinheon Baek", "Sung Ju Hwang"], "title": "System Prompt Optimization with Meta-Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance."}
{"id": "2505.10003", "pdf": "https://arxiv.org/pdf/2505.10003", "abs": "https://arxiv.org/abs/2505.10003", "authors": ["Tianyu Jiao", "Zhuoran Xiao", "Yihang Huang", "Chenhui Ye", "Yijia Feng", "Liyu Cai", "Jiang Chang", "Fangkun Liu", "Yin Xu", "Dazhi He", "Yunfeng Guan", "Wenjun Zhang"], "title": "AI2MMUM: AI-AI Oriented Multi-Modal Universal Model Leveraging Telecom Domain Large Model", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Designing a 6G-oriented universal model capable of processing multi-modal\ndata and executing diverse air interface tasks has emerged as a common goal in\nfuture wireless systems. Building on our prior work in communication\nmulti-modal alignment and telecom large language model (LLM), we propose a\nscalable, task-aware artificial intelligence-air interface multi-modal\nuniversal model (AI2MMUM), which flexibility and effectively perform various\nphysical layer tasks according to subtle task instructions. The LLM backbone\nprovides robust contextual comprehension and generalization capabilities, while\na fine-tuning approach is adopted to incorporate domain-specific knowledge. To\nenhance task adaptability, task instructions consist of fixed task keywords and\nlearnable, implicit prefix prompts. Frozen radio modality encoders extract\nuniversal representations and adapter layers subsequently bridge radio and\nlanguage modalities. Moreover, lightweight task-specific heads are designed to\ndirectly output task objectives. Comprehensive evaluations demonstrate that\nAI2MMUM achieves SOTA performance across five representative physical\nenvironment/wireless channel-based downstream tasks using the WAIR-D and\nDeepMIMO datasets."}
{"id": "2505.10231", "pdf": "https://arxiv.org/pdf/2505.10231", "abs": "https://arxiv.org/abs/2505.10231", "authors": ["Haozhe Luo", "Ziyu Zhou", "Zixin Shu", "Aurélie Pahud de Mortanges", "Robert Berke", "Mauricio Reyes"], "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner."}
{"id": "2505.10446", "pdf": "https://arxiv.org/pdf/2505.10446", "abs": "https://arxiv.org/abs/2505.10446", "authors": ["Zemin Huang", "Zhiyang Chen", "Zijun Wang", "Tiancheng Li", "Guo-Jun Qi"], "title": "Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We introduce the \\emph{Diffusion Chain of Lateral Thought (DCoLT)}, a\nreasoning framework for diffusion language models. DCoLT treats each\nintermediate step in the reverse diffusion process as a latent \"thinking\"\naction and optimizes the entire reasoning trajectory to maximize the reward on\nthe correctness of the final answer with outcome-based Reinforcement Learning\n(RL). Unlike traditional Chain-of-Thought (CoT) methods that follow a causal,\nlinear thinking process, DCoLT allows bidirectional, non-linear reasoning with\nno strict rule on grammatical correctness amid its intermediate steps of\nthought. We implement DCoLT on two representative Diffusion Language Models\n(DLMs). First, we choose SEDD as a representative continuous-time discrete\ndiffusion model, where its concrete score derives a probabilistic policy to\nmaximize the RL reward over the entire sequence of intermediate diffusion\nsteps. We further consider the discrete-time masked diffusion language model --\nLLaDA, and find that the order to predict and unmask tokens plays an essential\nrole to optimize its RL action resulting from the ranking-based Unmasking\nPolicy Module (UPM) defined by the Plackett-Luce model. Experiments on both\nmath and code generation tasks show that using only public data and 16 H800\nGPUs, DCoLT-reinforced DLMs outperform other DLMs trained by SFT or RL or even\nboth. Notably, DCoLT-reinforced LLaDA boosts its reasoning accuracy by +9.8%,\n+5.7%, +11.4%, +19.5% on GSM8K, MATH, MBPP, and HumanEval."}
{"id": "2505.09698", "pdf": "https://arxiv.org/pdf/2505.09698", "abs": "https://arxiv.org/abs/2505.09698", "authors": ["Enyu Zhao", "Vedant Raval", "Hejia Zhang", "Jiageng Mao", "Zeyu Shangguan", "Stefanos Nikolaidis", "Yue Wang", "Daniel Seita"], "title": "ManipBench: Benchmarking Vision-Language Models for Low-Level Robot Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": "47 pages, 29 figures. Under review", "summary": "Vision-Language Models (VLMs) have revolutionized artificial intelligence and\nrobotics due to their commonsense reasoning capabilities. In robotic\nmanipulation, VLMs are used primarily as high-level planners, but recent work\nhas also studied their lower-level reasoning ability, which refers to making\ndecisions about precise robot movements. However, the community currently lacks\na clear and common benchmark that can evaluate how well VLMs can aid low-level\nreasoning in robotics. Consequently, we propose a novel benchmark, ManipBench,\nto evaluate the low-level robot manipulation reasoning capabilities of VLMs\nacross various dimensions, including how well they understand object-object\ninteractions and deformable object manipulation. We extensively test 33\nrepresentative VLMs across 10 model families on our benchmark, including\nvariants to test different model sizes. Our evaluation shows that the\nperformance of VLMs significantly varies across tasks, and there is a strong\ncorrelation between this performance and trends in our real-world manipulation\ntasks. It also shows that there remains a significant gap between these models\nand human-level understanding. See our website at:\nhttps://manipbench.github.io."}
{"id": "2505.10007", "pdf": "https://arxiv.org/pdf/2505.10007", "abs": "https://arxiv.org/abs/2505.10007", "authors": ["Zijun Chen", "Shengbo Wang", "Nian Si"], "title": "Sample Complexity of Distributionally Robust Average-Reward Reinforcement Learning", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Motivated by practical applications where stable long-term performance is\ncritical-such as robotics, operations research, and healthcare-we study the\nproblem of distributionally robust (DR) average-reward reinforcement learning.\nWe propose two algorithms that achieve near-optimal sample complexity. The\nfirst reduces the problem to a DR discounted Markov decision process (MDP),\nwhile the second, Anchored DR Average-Reward MDP, introduces an anchoring state\nto stabilize the controlled transition kernels within the uncertainty set.\nAssuming the nominal MDP is uniformly ergodic, we prove that both algorithms\nattain a sample complexity of $\\widetilde{O}\\left(|\\mathbf{S}||\\mathbf{A}|\nt_{\\mathrm{mix}}^2\\varepsilon^{-2}\\right)$ for estimating the optimal policy as\nwell as the robust average reward under KL and $f_k$-divergence-based\nuncertainty sets, provided the uncertainty radius is sufficiently small. Here,\n$\\varepsilon$ is the target accuracy, $|\\mathbf{S}|$ and $|\\mathbf{A}|$ denote\nthe sizes of the state and action spaces, and $t_{\\mathrm{mix}}$ is the mixing\ntime of the nominal MDP. This represents the first finite-sample convergence\nguarantee for DR average-reward reinforcement learning. We further validate the\nconvergence rates of our algorithms through numerical experiments."}
{"id": "2505.10238", "pdf": "https://arxiv.org/pdf/2505.10238", "abs": "https://arxiv.org/abs/2505.10238", "authors": ["Yanbo Ding"], "title": "MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation", "categories": ["cs.CV"], "comment": null, "summary": "Human image animation has gained increasing attention and developed rapidly\ndue to its broad applications in digital humans. However, existing methods rely\nlargely on 2D-rendered pose images for motion guidance, which limits\ngeneralization and discards essential 3D information for open-world animation.\nTo tackle this problem, we propose MTVCrafter (Motion Tokenization Video\nCrafter), the first framework that directly models raw 3D motion sequences\n(i.e., 4D motion) for human image animation. Specifically, we introduce 4DMoT\n(4D motion tokenizer) to quantize 3D motion sequences into 4D motion tokens.\nCompared to 2D-rendered pose images, 4D motion tokens offer more robust\nspatio-temporal cues and avoid strict pixel-level alignment between pose image\nand character, enabling more flexible and disentangled control. Then, we\nintroduce MV-DiT (Motion-aware Video DiT). By designing unique motion attention\nwith 4D positional encodings, MV-DiT can effectively leverage motion tokens as\n4D compact yet expressive context for human image animation in the complex 3D\nworld. Hence, it marks a significant step forward in this field and opens a new\ndirection for pose-guided human video generation. Experiments show that our\nMTVCrafter achieves state-of-the-art results with an FID-VID of 6.98,\nsurpassing the second-best by 65%. Powered by robust motion tokens, MTVCrafter\nalso generalizes well to diverse open-world characters (single/multiple,\nfull/half-body) across various styles and scenarios. Our video demos and code\nare provided in the supplementary material and at this anonymous GitHub link:\nhttps://anonymous.4open.science/r/MTVCrafter-1B13."}
{"id": "2505.10493", "pdf": "https://arxiv.org/pdf/2505.10493", "abs": "https://arxiv.org/abs/2505.10493", "authors": ["Shaohan Wang", "Licheng Zhang", "Zheren Fu", "Zhendong Mao"], "title": "CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) is an effective method to enhance the\ncapabilities of large language models (LLMs). Existing methods focus on\noptimizing the retriever or generator in the RAG system by directly utilizing\nthe top-k retrieved documents. However, the documents effectiveness are various\nsignificantly across user queries, i.e. some documents provide valuable\nknowledge while others totally lack critical information. It hinders the\nretriever and generator's adaptation during training. Inspired by human\ncognitive learning, curriculum learning trains models using samples progressing\nfrom easy to difficult, thus enhancing their generalization ability, and we\nintegrate this effective paradigm to the training of the RAG system. In this\npaper, we propose a multi-stage Curriculum Learning based RAG system training\nframework, named CL-RAG. We first construct training data with multiple\ndifficulty levels for the retriever and generator separately through sample\nevolution. Then, we train the model in stages based on the curriculum learning\napproach, thereby optimizing the overall performance and generalization of the\nRAG system more effectively. Our CL-RAG framework demonstrates consistent\neffectiveness across four open-domain QA datasets, achieving performance gains\nof 2% to 4% over multiple advanced methods."}
{"id": "2505.09704", "pdf": "https://arxiv.org/pdf/2505.09704", "abs": "https://arxiv.org/abs/2505.09704", "authors": ["Roberto Pereira", "Fernanda Famá", "Charalampos Kalalas", "Paolo Dini"], "title": "Energy-Efficient Federated Learning for AIoT using Clustering Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While substantial research has been devoted to optimizing model performance,\nconvergence rates, and communication efficiency, the energy implications of\nfederated learning (FL) within Artificial Intelligence of Things (AIoT)\nscenarios are often overlooked in the existing literature. This study examines\nthe energy consumed during the FL process, focusing on three main\nenergy-intensive processes: pre-processing, communication, and local learning,\nall contributing to the overall energy footprint. We rely on the observation\nthat device/client selection is crucial for speeding up the convergence of\nmodel training in a distributed AIoT setting and propose two\nclustering-informed methods. These clustering solutions are designed to group\nAIoT devices with similar label distributions, resulting in clusters composed\nof nearly heterogeneous devices. Hence, our methods alleviate the heterogeneity\noften encountered in real-world distributed learning applications. Throughout\nextensive numerical experimentation, we demonstrate that our clustering\nstrategies typically achieve high convergence rates while maintaining low\nenergy consumption when compared to other recent approaches available in the\nliterature."}
{"id": "2505.10010", "pdf": "https://arxiv.org/pdf/2505.10010", "abs": "https://arxiv.org/abs/2505.10010", "authors": ["Jing-Cheng Pang", "Kaiyuan Li", "Yidi Wang", "Si-Hang Yang", "Shengyi Jiang", "Yang Yu"], "title": "ImagineBench: Evaluating Reinforcement Learning with Large Language Model Rollouts", "categories": ["cs.LG"], "comment": null, "summary": "A central challenge in reinforcement learning (RL) is its dependence on\nextensive real-world interaction data to learn task-specific policies. While\nrecent work demonstrates that large language models (LLMs) can mitigate this\nlimitation by generating synthetic experience (noted as imaginary rollouts) for\nmastering novel tasks, progress in this emerging field is hindered due to the\nlack of a standard benchmark. To bridge this gap, we introduce ImagineBench,\nthe first comprehensive benchmark for evaluating offline RL algorithms that\nleverage both real rollouts and LLM-imaginary rollouts. The key features of\nImagineBench include: (1) datasets comprising environment-collected and\nLLM-imaginary rollouts; (2) diverse domains of environments covering\nlocomotion, robotic manipulation, and navigation tasks; and (3) natural\nlanguage task instructions with varying complexity levels to facilitate\nlanguage-conditioned policy learning. Through systematic evaluation of\nstate-of-the-art offline RL algorithms, we observe that simply applying\nexisting offline RL algorithms leads to suboptimal performance on unseen tasks,\nachieving 35.44% success rate in hard tasks in contrast to 64.37% of method\ntraining on real rollouts for hard tasks. This result highlights the need for\nalgorithm advancements to better leverage LLM-imaginary rollouts. Additionally,\nwe identify key opportunities for future research: including better utilization\nof imaginary rollouts, fast online adaptation and continual learning, and\nextension to multi-modal tasks. Our code is publicly available at\nhttps://github.com/LAMDA-RL/ImagineBench."}
{"id": "2505.10250", "pdf": "https://arxiv.org/pdf/2505.10250", "abs": "https://arxiv.org/abs/2505.10250", "authors": ["Wenhao Shen", "Wanqi Yin", "Xiaofeng Yang", "Cheng Chen", "Chaoyue Song", "Zhongang Cai", "Lei Yang", "Hao Wang", "Guosheng Lin"], "title": "ADHMR: Aligning Diffusion-based Human Mesh Recovery via Direct Preference Optimization", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025. Code: https://github.com/shenwenhao01/ADHMR", "summary": "Human mesh recovery (HMR) from a single image is inherently ill-posed due to\ndepth ambiguity and occlusions. Probabilistic methods have tried to solve this\nby generating numerous plausible 3D human mesh predictions, but they often\nexhibit misalignment with 2D image observations and weak robustness to\nin-the-wild images. To address these issues, we propose ADHMR, a framework that\nAligns a Diffusion-based HMR model in a preference optimization manner. First,\nwe train a human mesh prediction assessment model, HMR-Scorer, capable of\nevaluating predictions even for in-the-wild images without 3D annotations. We\nthen use HMR-Scorer to create a preference dataset, where each input image has\na pair of winner and loser mesh predictions. This dataset is used to finetune\nthe base model using direct preference optimization. Moreover, HMR-Scorer also\nhelps improve existing HMR models by data cleaning, even with fewer training\nsamples. Extensive experiments show that ADHMR outperforms current\nstate-of-the-art methods. Code is available at:\nhttps://github.com/shenwenhao01/ADHMR."}
{"id": "2505.10494", "pdf": "https://arxiv.org/pdf/2505.10494", "abs": "https://arxiv.org/abs/2505.10494", "authors": ["Yutao Mou", "Xiao Deng", "Yuxiao Luo", "Shikun Zhang", "Wei Ye"], "title": "Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective", "categories": ["cs.CL"], "comment": "Accepted by ACL2025 Main Conference", "summary": "Code security and usability are both essential for various coding assistant\napplications driven by large language models (LLMs). Current code security\nbenchmarks focus solely on single evaluation task and paradigm, such as code\ncompletion and generation, lacking comprehensive assessment across dimensions\nlike secure code generation, vulnerability repair and discrimination. In this\npaper, we first propose CoV-Eval, a multi-task benchmark covering various tasks\nsuch as code completion, vulnerability repair, vulnerability detection and\nclassification, for comprehensive evaluation of LLM code security. Besides, we\ndeveloped VC-Judge, an improved judgment model that aligns closely with human\nexperts and can review LLM-generated programs for vulnerabilities in a more\nefficient and reliable way. We conduct a comprehensive evaluation of 20\nproprietary and open-source LLMs. Overall, while most LLMs identify vulnerable\ncodes well, they still tend to generate insecure codes and struggle with\nrecognizing specific vulnerability types and performing repairs. Extensive\nexperiments and qualitative analyses reveal key challenges and optimization\ndirections, offering insights for future research in LLM code security."}
{"id": "2505.09716", "pdf": "https://arxiv.org/pdf/2505.09716", "abs": "https://arxiv.org/abs/2505.09716", "authors": ["George Dimitriadis. Spyridon Samothrakis"], "title": "Out-of-distribution generalisation is hard: evidence from ARC-like tasks", "categories": ["cs.LG", "cs.AI"], "comment": "Submission to NeurIPS 2025", "summary": "Out-of-distribution (OOD) generalisation is considered a hallmark of human\nand animal intelligence. To achieve OOD through composition, a system must\ndiscover the environment-invariant properties of experienced input-output\nmappings and transfer them to novel inputs. This can be realised if an\nintelligent system can identify appropriate, task-invariant, and composable\ninput features, as well as the composition methods, thus allowing it to act\nbased not on the interpolation between learnt data points but on the\ntask-invariant composition of those features. We propose that in order to\nconfirm that an algorithm does indeed learn compositional structures from data,\nit is not enough to just test on an OOD setup, but one also needs to confirm\nthat the features identified are indeed compositional. We showcase this by\nexploring two tasks with clearly defined OOD metrics that are not OOD solvable\nby three commonly used neural networks: a Multi-Layer Perceptron (MLP), a\nConvolutional Neural Network (CNN), and a Transformer. In addition, we develop\ntwo novel network architectures imbued with biases that allow them to be\nsuccessful in OOD scenarios. We show that even with correct biases and almost\nperfect OOD performance, an algorithm can still fail to learn the correct\nfeatures for compositional generalisation."}
{"id": "2505.10037", "pdf": "https://arxiv.org/pdf/2505.10037", "abs": "https://arxiv.org/abs/2505.10037", "authors": ["Takafumi Ito", "Lysenko Artem", "Tatsuhiko Tsunoda"], "title": "Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction", "categories": ["cs.LG", "cs.AI", "cs.ET", "quant-ph"], "comment": "10 pages, 3 figures", "summary": "Quantum-classical Hybrid Machine Learning (QHML) models are recognized for\ntheir robust performance and high generalization ability even for relatively\nsmall datasets. These qualities offer unique advantages for anti-cancer drug\nresponse prediction, where the number of available samples is typically small.\nHowever, such hybrid models appear to be very sensitive to the data encoding\nused at the interface of a neural network and a quantum circuit, with\nsuboptimal choices leading to stability issues. To address this problem, we\npropose a novel strategy that uses a normalization function based on a\nmoderated gradient version of the $\\tanh$. This method transforms the outputs\nof the neural networks without concentrating them at the extreme value ranges.\nOur idea was evaluated on a dataset of gene expression and drug response\nmeasurements for various cancer cell lines, where we compared the prediction\nperformance of a classical deep learning model and several QHML models. These\nresults confirmed that QHML performed better than the classical models when\ndata was optimally normalized. This study opens up new possibilities for\nbiomedical data analysis using quantum computers."}
{"id": "2505.10257", "pdf": "https://arxiv.org/pdf/2505.10257", "abs": "https://arxiv.org/abs/2505.10257", "authors": ["Hao Lu", "Jiaqi Tang", "Jiyao Wang", "Yunfan LU", "Xu Cao", "Qingyong Hu", "Yin Wang", "Yuting Zhang", "Tianxin Xie", "Yunpeng Zhang", "Yong Chen", "Jiayu. Gao", "Bin Huang", "Dengbo He", "Shuiguang Deng", "Hao Chen", "Ying-Cong Chen"], "title": "Sage Deer: A Super-Aligned Driving Generalist Is Your Copilot", "categories": ["cs.CV"], "comment": null, "summary": "The intelligent driving cockpit, an important part of intelligent driving,\nneeds to match different users' comfort, interaction, and safety needs. This\npaper aims to build a Super-Aligned and GEneralist DRiving agent, SAGE DeeR.\nSage Deer achieves three highlights: (1) Super alignment: It achieves different\nreactions according to different people's preferences and biases. (2)\nGeneralist: It can understand the multi-view and multi-mode inputs to reason\nthe user's physiological indicators, facial emotions, hand movements, body\nmovements, driving scenarios, and behavioral decisions. (3) Self-Eliciting: It\ncan elicit implicit thought chains in the language space to further increase\ngeneralist and super-aligned abilities. Besides, we collected multiple data\nsets and built a large-scale benchmark. This benchmark measures the deer's\nperceptual decision-making ability and the super alignment's accuracy."}
{"id": "2505.10507", "pdf": "https://arxiv.org/pdf/2505.10507", "abs": "https://arxiv.org/abs/2505.10507", "authors": ["Benedikt Ebing", "Goran Glavaš"], "title": "The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks", "categories": ["cs.CL"], "comment": null, "summary": "Translation-based strategies for cross-lingual transfer XLT such as\ntranslate-train -- training on noisy target language data translated from the\nsource language -- and translate-test -- evaluating on noisy source language\ndata translated from the target language -- are competitive XLT baselines. In\nXLT for token classification tasks, however, these strategies include label\nprojection, the challenging step of mapping the labels from each token in the\noriginal sentence to its counterpart(s) in the translation. Although word\naligners (WAs) are commonly used for label projection, the low-level design\ndecisions for applying them to translation-based XLT have not been\nsystematically investigated. Moreover, recent marker-based methods, which\nproject labeled spans by inserting tags around them before (or after)\ntranslation, claim to outperform WAs in label projection for XLT. In this work,\nwe revisit WAs for label projection, systematically investigating the effects\nof low-level design decisions on token-level XLT: (i) the algorithm for\nprojecting labels between (multi-)token spans, (ii) filtering strategies to\nreduce the number of noisily mapped labels, and (iii) the pre-tokenization of\nthe translated sentences. We find that all of these substantially impact\ntranslation-based XLT performance and show that, with optimized choices, XLT\nwith WA offers performance at least comparable to that of marker-based methods.\nWe then introduce a new projection strategy that ensembles translate-train and\ntranslate-test predictions and demonstrate that it substantially outperforms\nthe marker-based projection. Crucially, we show that our proposed ensembling\nalso reduces sensitivity to low-level WA design choices, resulting in more\nrobust XLT for token classification tasks."}
{"id": "2505.09724", "pdf": "https://arxiv.org/pdf/2505.09724", "abs": "https://arxiv.org/abs/2505.09724", "authors": ["Gino Carmona-Díaz", "William Jiménez-Leal", "María Alejandra Grisales", "Chandra Sripada", "Santiago Amaya", "Michael Inzlicht", "Juan Pablo Bermúdez"], "title": "An AI-Powered Research Assistant in the Lab: A Practical Guide for Text Analysis Through Iterative Collaboration with LLMs", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "31 pages, 1 figure", "summary": "Analyzing texts such as open-ended responses, headlines, or social media\nposts is a time- and labor-intensive process highly susceptible to bias. LLMs\nare promising tools for text analysis, using either a predefined (top-down) or\na data-driven (bottom-up) taxonomy, without sacrificing quality. Here we\npresent a step-by-step tutorial to efficiently develop, test, and apply\ntaxonomies for analyzing unstructured data through an iterative and\ncollaborative process between researchers and LLMs. Using personal goals\nprovided by participants as an example, we demonstrate how to write prompts to\nreview datasets and generate a taxonomy of life domains, evaluate and refine\nthe taxonomy through prompt and direct modifications, test the taxonomy and\nassess intercoder agreements, and apply the taxonomy to categorize an entire\ndataset with high intercoder reliability. We discuss the possibilities and\nlimitations of using LLMs for text analysis."}
{"id": "2505.10039", "pdf": "https://arxiv.org/pdf/2505.10039", "abs": "https://arxiv.org/abs/2505.10039", "authors": ["Hang Chen", "Jiaying Zhu", "Xinyu Yang", "Wenya Wang"], "title": "Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates", "categories": ["cs.LG"], "comment": "10 pages", "summary": "Circuit discovery has gradually become one of the prominent methods for\nmechanistic interpretability, and research on circuit completeness has also\ngarnered increasing attention. Methods of circuit discovery that do not\nguarantee completeness not only result in circuits that are not fixed across\ndifferent runs but also cause key mechanisms to be omitted. The nature of\nincompleteness arises from the presence of OR gates within the circuit, which\nare often only partially detected in standard circuit discovery methods. To\nthis end, we systematically introduce three types of logic gates: AND, OR, and\nADDER gates, and decompose the circuit into combinations of these logical\ngates. Through the concept of these gates, we derive the minimum requirements\nnecessary to achieve faithfulness and completeness. Furthermore, we propose a\nframework that combines noising-based and denoising-based interventions, which\ncan be easily integrated into existing circuit discovery methods without\nsignificantly increasing computational complexity. This framework is capable of\nfully identifying the logic gates and distinguishing them within the circuit.\nIn addition to the extensive experimental validation of the framework's ability\nto restore the faithfulness, completeness, and sparsity of circuits, using this\nframework, we uncover fundamental properties of the three logic gates, such as\ntheir proportions and contributions to the output, and explore how they behave\namong the functionalities of language models."}
{"id": "2505.10258", "pdf": "https://arxiv.org/pdf/2505.10258", "abs": "https://arxiv.org/abs/2505.10258", "authors": ["Michael Hubbertz", "Pascal Colling", "Qi Han", "Tobias Meisen"], "title": "Inferring Driving Maps by Deep Learning-based Trail Map Extraction", "categories": ["cs.CV", "cs.RO"], "comment": "This paper was accepted at the CVPR WAD 2025 Workshop", "summary": "High-definition (HD) maps offer extensive and accurate environmental\ninformation about the driving scene, making them a crucial and essential\nelement for planning within autonomous driving systems. To avoid extensive\nefforts from manual labeling, methods for automating the map creation have\nemerged. Recent trends have moved from offline mapping to online mapping,\nensuring availability and actuality of the utilized maps. While the performance\nhas increased in recent years, online mapping still faces challenges regarding\ntemporal consistency, sensor occlusion, runtime, and generalization. We propose\na novel offline mapping approach that integrates trails - informal routes used\nby drivers - into the map creation process. Our method aggregates trail data\nfrom the ego vehicle and other traffic participants to construct a\ncomprehensive global map using transformer-based deep learning models. Unlike\ntraditional offline mapping, our approach enables continuous updates while\nremaining sensor-agnostic, facilitating efficient data transfer. Our method\ndemonstrates superior performance compared to state-of-the-art online mapping\napproaches, achieving improved generalization to previously unseen environments\nand sensor configurations. We validate our approach on two benchmark datasets,\nhighlighting its robustness and applicability in autonomous driving systems."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.09733", "pdf": "https://arxiv.org/pdf/2505.09733", "abs": "https://arxiv.org/abs/2505.09733", "authors": ["Alpaslan Gokcen", "Ali Boyaci"], "title": "Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning (FL) presents an effective solution for collaborative\nmodel training while maintaining data privacy across decentralized client\ndatasets. However, data quality issues such as noisy labels, missing classes,\nand imbalanced distributions significantly challenge its effectiveness. This\nstudy proposes a federated learning methodology that systematically addresses\ndata quality issues, including noise, class imbalance, and missing labels. The\nproposed approach systematically enhances data integrity through adaptive noise\ncleaning, collaborative conditional GAN-based synthetic data generation, and\nrobust federated model training. Experimental evaluations conducted on\nbenchmark datasets (MNIST and Fashion-MNIST) demonstrate significant\nimprovements in federated model performance, particularly macro-F1 Score, under\nvarying noise and class imbalance conditions. Additionally, the proposed\nframework carefully balances computational feasibility and substantial\nperformance gains, ensuring practicality for resource constrained edge devices\nwhile rigorously maintaining data privacy. Our results indicate that this\nmethod effectively mitigates common data quality challenges, providing a\nrobust, scalable, and privacy compliant solution suitable for diverse\nreal-world federated learning scenarios."}
{"id": "2505.10040", "pdf": "https://arxiv.org/pdf/2505.10040", "abs": "https://arxiv.org/abs/2505.10040", "authors": ["Lei Song", "Jiaxing Li", "Shihan Guan", "Youyong Kong"], "title": "Instance-Prototype Affinity Learning for Non-Exemplar Continual Graph Learning", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNN) endure catastrophic forgetting, undermining their\ncapacity to preserve previously acquired knowledge amid the assimilation of\nnovel information. Rehearsal-based techniques revisit historical examples,\nadopted as a principal strategy to alleviate this phenomenon. However, memory\nexplosion and privacy infringements impose significant constraints on their\nutility. Non-Exemplar methods circumvent the prior issues through Prototype\nReplay (PR), yet feature drift presents new challenges. In this paper, our\nempirical findings reveal that Prototype Contrastive Learning (PCL) exhibits\nless pronounced drift than conventional PR. Drawing upon PCL, we propose\nInstance-Prototype Affinity Learning (IPAL), a novel paradigm for Non-Exemplar\nContinual Graph Learning (NECGL). Exploiting graph structural information, we\nformulate Topology-Integrated Gaussian Prototypes (TIGP), guiding feature\ndistributions towards high-impact nodes to augment the model's capacity for\nassimilating new knowledge. Instance-Prototype Affinity Distillation (IPAD)\nsafeguards task memory by regularizing discontinuities in class relationships.\nMoreover, we embed a Decision Boundary Perception (DBP) mechanism within PCL,\nfostering greater inter-class discriminability. Evaluations on four node\nclassification benchmark datasets demonstrate that our method outperforms\nexisting state-of-the-art methods, achieving a better trade-off between\nplasticity and stability."}
{"id": "2505.10267", "pdf": "https://arxiv.org/pdf/2505.10267", "abs": "https://arxiv.org/abs/2505.10267", "authors": ["Pavel Korotaev", "Petr Surovtsev", "Alexander Kapitanov", "Karina Kvanchiani", "Aleksandr Nagaev"], "title": "HandReader: Advanced Techniques for Efficient Fingerspelling Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "https://github.com/ai-forever/handreader", "summary": "Fingerspelling is a significant component of Sign Language (SL), allowing the\ninterpretation of proper names, characterized by fast hand movements during\nsigning. Although previous works on fingerspelling recognition have focused on\nprocessing the temporal dimension of videos, there remains room for improving\nthe accuracy of these approaches. This paper introduces HandReader, a group of\nthree architectures designed to address the fingerspelling recognition task.\nHandReader$_{RGB}$ employs the novel Temporal Shift-Adaptive Module (TSAM) to\nprocess RGB features from videos of varying lengths while preserving important\nsequential information. HandReader$_{KP}$ is built on the proposed Temporal\nPose Encoder (TPE) operated on keypoints as tensors. Such keypoints composition\nin a batch allows the encoder to pass them through 2D and 3D convolution\nlayers, utilizing temporal and spatial information and accumulating keypoints\ncoordinates. We also introduce HandReader_RGB+KP - architecture with a joint\nencoder to benefit from RGB and keypoint modalities. Each HandReader model\npossesses distinct advantages and achieves state-of-the-art results on the\nChicagoFSWild and ChicagoFSWild+ datasets. Moreover, the models demonstrate\nhigh performance on the first open dataset for Russian fingerspelling, Znaki,\npresented in this paper. The Znaki dataset and HandReader pre-trained models\nare publicly available."}
{"id": "2505.10527", "pdf": "https://arxiv.org/pdf/2505.10527", "abs": "https://arxiv.org/abs/2505.10527", "authors": ["Binghai Wang", "Runji Lin", "Keming Lu", "Le Yu", "Zhenru Zhang", "Fei Huang", "Chujie Zheng", "Kai Dang", "Yang Fan", "Xingzhang Ren", "An Yang", "Binyuan Hui", "Dayiheng Liu", "Tao Gui", "Qi Zhang", "Xuanjing Huang", "Yu-Gang Jiang", "Bowen Yu", "Jingren Zhou", "Junyang Lin"], "title": "WorldPM: Scaling Human Preference Modeling", "categories": ["cs.CL"], "comment": null, "summary": "Motivated by scaling laws in language modeling that demonstrate how test loss\nscales as a power law with model and dataset sizes, we find that similar laws\nexist in preference modeling. We propose World Preference Modeling$ (WorldPM)\nto emphasize this scaling potential, where World Preference embodies a unified\nrepresentation of human preferences. In this paper, we collect preference data\nfrom public forums covering diverse user communities, and conduct extensive\ntraining using 15M-scale data across models ranging from 1.5B to 72B\nparameters. We observe distinct patterns across different evaluation metrics:\n(1) Adversarial metrics (ability to identify deceptive features) consistently\nscale up with increased training data and base model size; (2) Objective\nmetrics (objective knowledge with well-defined answers) show emergent behavior\nin larger language models, highlighting WorldPM's scalability potential; (3)\nSubjective metrics (subjective preferences from a limited number of humans or\nAI) do not demonstrate scaling trends. Further experiments validate the\neffectiveness of WorldPM as a foundation for preference fine-tuning. Through\nevaluations on 7 benchmarks with 20 subtasks, we find that WorldPM broadly\nimproves the generalization performance across human preference datasets of\nvarying sizes (7K, 100K and 800K samples), with performance gains exceeding 5%\non many key subtasks. Integrating WorldPM into our internal RLHF pipeline, we\nobserve significant improvements on both in-house and public evaluation sets,\nwith notable gains of 4% to 8% in our in-house evaluations."}
{"id": "2505.09738", "pdf": "https://arxiv.org/pdf/2505.09738", "abs": "https://arxiv.org/abs/2505.09738", "authors": ["Shaurya Sharthak", "Vinayak Pahalwan", "Adithya Kamath", "Adarsh Shirawalmath"], "title": "Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Pretrained language models (LLMs) are often constrained by their fixed\ntokenization schemes, leading to inefficiencies and performance limitations,\nparticularly for multilingual or specialized applications. This tokenizer\nlock-in presents significant challenges. standard methods to overcome this\noften require prohibitive computational resources. Although tokenizer\nreplacement with heuristic initialization aims to reduce this burden, existing\nmethods often require exhaustive residual fine-tuning and still may not fully\npreserve semantic nuances or adequately address the underlying compression\ninefficiencies. Our framework introduces two innovations: first, Tokenadapt, a\nmodel-agnostic tokenizer transplantation method, and second, novel\npre-tokenization learning for multi-word Supertokens to enhance compression and\nreduce fragmentation. Tokenadapt initializes new unique token embeddings via a\nhybrid heuristic that combines two methods: a local estimate based on subword\ndecomposition using the old tokenizer, and a global estimate utilizing the\ntop-k semantically similar tokens from the original vocabulary. This\nmethodology aims to preserve semantics while significantly minimizing\nretraining requirements. Empirical investigations validate both contributions:\nthe transplantation heuristic successfully initializes unique tokens, markedly\noutperforming conventional baselines and sophisticated methods including\nTranstokenizer and ReTok, while our Supertokens achieve notable compression\ngains. Our zero-shot perplexity results demonstrate that the TokenAdapt hybrid\ninitialization consistently yields lower perplexity ratios compared to both\nReTok and TransTokenizer baselines across different base models and newly\ntrained target tokenizers. TokenAdapt typically reduced the overall perplexity\nratio significantly compared to ReTok, yielding at least a 2-fold improvement\nin these aggregate scores."}
{"id": "2505.10050", "pdf": "https://arxiv.org/pdf/2505.10050", "abs": "https://arxiv.org/abs/2505.10050", "authors": ["Fahad Almalki", "Mehedi Masud"], "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection."}
{"id": "2505.10281", "pdf": "https://arxiv.org/pdf/2505.10281", "abs": "https://arxiv.org/abs/2505.10281", "authors": ["Mengqiu Xu", "Kaixin Chen", "Heng Guo", "Yixiang Huang", "Ming Wu", "Zhenwei Shi", "Chuang Zhang", "Jun Guo"], "title": "MFogHub: Bridging Multi-Regional and Multi-Satellite Data for Global Marine Fog Detection and Forecasting", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning approaches for marine fog detection and forecasting have\noutperformed traditional methods, demonstrating significant scientific and\npractical importance. However, the limited availability of open-source datasets\nremains a major challenge. Existing datasets, often focused on a single region\nor satellite, restrict the ability to evaluate model performance across diverse\nconditions and hinder the exploration of intrinsic marine fog characteristics.\nTo address these limitations, we introduce \\textbf{MFogHub}, the first\nmulti-regional and multi-satellite dataset to integrate annotated marine fog\nobservations from 15 coastal fog-prone regions and six geostationary\nsatellites, comprising over 68,000 high-resolution samples. By encompassing\ndiverse regions and satellite perspectives, MFogHub facilitates rigorous\nevaluation of both detection and forecasting methods under varying conditions.\nExtensive experiments with 16 baseline models demonstrate that MFogHub can\nreveal generalization fluctuations due to regional and satellite discrepancy,\nwhile also serving as a valuable resource for the development of targeted and\nscalable fog prediction techniques. Through MFogHub, we aim to advance both the\npractical monitoring and scientific understanding of marine fog dynamics on a\nglobal scale. The dataset and code are at\n\\href{https://github.com/kaka0910/MFogHub}{https://github.com/kaka0910/MFogHub}."}
{"id": "2505.10554", "pdf": "https://arxiv.org/pdf/2505.10554", "abs": "https://arxiv.org/abs/2505.10554", "authors": ["Zhiyuan Hu", "Yibo Wang", "Hanze Dong", "Yuhui Xu", "Amrita Saha", "Caiming Xiong", "Bryan Hooi", "Junnan Li"], "title": "Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large Reasoning Models", "categories": ["cs.CL"], "comment": "In Progress", "summary": "Large reasoning models (LRMs) already possess a latent capacity for long\nchain-of-thought reasoning. Prior work has shown that outcome-based\nreinforcement learning (RL) can incidentally elicit advanced reasoning\nbehaviors such as self-correction, backtracking, and verification phenomena\noften referred to as the model's \"aha moment\". However, the timing and\nconsistency of these emergent behaviors remain unpredictable and\nuncontrollable, limiting the scalability and reliability of LRMs' reasoning\ncapabilities. To address these limitations, we move beyond reliance on prompts\nand coincidental \"aha moments\". Instead, we explicitly align models with three\nmeta-abilities: deduction, induction, and abduction, using automatically\ngenerated, self-verifiable tasks. Our three stage-pipeline individual\nalignment, parameter-space merging, and domain-specific reinforcement learning,\nboosting performance by over 10\\% relative to instruction-tuned baselines.\nFurthermore, domain-specific RL from the aligned checkpoint yields an\nadditional 2\\% average gain in the performance ceiling across math, coding, and\nscience benchmarks, demonstrating that explicit meta-ability alignment offers a\nscalable and dependable foundation for reasoning. Code is available at:\nhttps://github.com/zhiyuanhubj/Meta-Ability-Alignment"}
{"id": "2505.09742", "pdf": "https://arxiv.org/pdf/2505.09742", "abs": "https://arxiv.org/abs/2505.09742", "authors": ["Yuan-Hang Zhang", "Massimiliano Di Ventra"], "title": "A Generative Neural Annealer for Black-Box Combinatorial Optimization", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.NE"], "comment": "15 pages, 3 figures", "summary": "We propose a generative, end-to-end solver for black-box combinatorial\noptimization that emphasizes both sample efficiency and solution quality on NP\nproblems. Drawing inspiration from annealing-based algorithms, we treat the\nblack-box objective as an energy function and train a neural network to model\nthe associated Boltzmann distribution. By conditioning on temperature, the\nnetwork captures a continuum of distributions--from near-uniform at high\ntemperatures to sharply peaked around global optima at low\ntemperatures--thereby learning the structure of the energy landscape and\nfacilitating global optimization. When queries are expensive, the\ntemperature-dependent distributions naturally enable data augmentation and\nimprove sample efficiency. When queries are cheap but the problem remains hard,\nthe model learns implicit variable interactions, effectively \"opening\" the\nblack box. We validate our approach on challenging combinatorial tasks under\nboth limited and unlimited query budgets, showing competitive performance\nagainst state-of-the-art black-box optimizers."}
{"id": "2505.10057", "pdf": "https://arxiv.org/pdf/2505.10057", "abs": "https://arxiv.org/abs/2505.10057", "authors": ["Tiancong Cheng", "Ying Zhang", "Yuxuan Liang", "Roger Zimmermann", "Zhiwen Yu", "Bin Guo"], "title": "JointDistill: Adaptive Multi-Task Distillation for Joint Depth Estimation and Scene Segmentation", "categories": ["cs.LG"], "comment": null, "summary": "Depth estimation and scene segmentation are two important tasks in\nintelligent transportation systems. A joint modeling of these two tasks will\nreduce the requirement for both the storage and training efforts. This work\nexplores how the multi-task distillation could be used to improve such unified\nmodeling. While existing solutions transfer multiple teachers' knowledge in a\nstatic way, we propose a self-adaptive distillation method that can dynamically\nadjust the knowledge amount from each teacher according to the student's\ncurrent learning ability. Furthermore, as multiple teachers exist, the\nstudent's gradient update direction in the distillation is more prone to be\nerroneous where knowledge forgetting may occur. To avoid this, we propose a\nknowledge trajectory to record the most essential information that a model has\nlearnt in the past, based on which a trajectory-based distillation loss is\ndesigned to guide the student to follow the learning curve similarly in a\ncost-effective way. We evaluate our method on multiple benchmarking datasets\nincluding Cityscapes and NYU-v2. Compared to the state-of-the-art solutions,\nour method achieves a clearly improvement. The code is provided in the\nsupplementary materials."}
{"id": "2505.10289", "pdf": "https://arxiv.org/pdf/2505.10289", "abs": "https://arxiv.org/abs/2505.10289", "authors": ["Yue Wang", "Shuai Xu", "Xuelin Zhu", "Yicong Li"], "title": "MSCI: Addressing CLIP's Inherent Limitations for Compositional Zero-Shot Learning", "categories": ["cs.CV"], "comment": "9 pages, 5 figures", "summary": "Compositional Zero-Shot Learning (CZSL) aims to recognize unseen state-object\ncombinations by leveraging known combinations. Existing studies basically rely\non the cross-modal alignment capabilities of CLIP but tend to overlook its\nlimitations in capturing fine-grained local features, which arise from its\narchitectural and training paradigm. To address this issue, we propose a\nMulti-Stage Cross-modal Interaction (MSCI) model that effectively explores and\nutilizes intermediate-layer information from CLIP's visual encoder.\nSpecifically, we design two self-adaptive aggregators to extract local\ninformation from low-level visual features and integrate global information\nfrom high-level visual features, respectively. These key information are\nprogressively incorporated into textual representations through a\nstage-by-stage interaction mechanism, significantly enhancing the model's\nperception capability for fine-grained local visual information. Additionally,\nMSCI dynamically adjusts the attention weights between global and local visual\ninformation based on different combinations, as well as different elements\nwithin the same combination, allowing it to flexibly adapt to diverse\nscenarios. Experiments on three widely used datasets fully validate the\neffectiveness and superiority of the proposed model. Data and code are\navailable at https://github.com/ltpwy/MSCI."}
{"id": "2505.09665", "pdf": "https://arxiv.org/pdf/2505.09665", "abs": "https://arxiv.org/abs/2505.09665", "authors": ["Sulong Zhou", "Qunying Huang", "Shaoheng Zhou", "Yun Hang", "Xinyue Ye", "Aodong Mei", "Kathryn Phung", "Yuning Ye", "Uma Govindswamy", "Zehan Li"], "title": "Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling", "categories": ["cs.SI", "cs.CL"], "comment": null, "summary": "Wildfires have become increasingly frequent, irregular, and severe in recent\nyears. Understanding how affected populations perceive and respond during\nwildfire crises is critical for timely and empathetic disaster response. Social\nmedia platforms offer a crowd-sourced channel to capture evolving public\ndiscourse, providing hyperlocal information and insight into public sentiment.\nThis study analyzes Reddit discourse during the 2025 Los Angeles wildfires,\nspanning from the onset of the disaster to full containment. We collect 385\nposts and 114,879 comments related to the Palisades and Eaton fires. We adopt\ntopic modeling methods to identify the latent topics, enhanced by large\nlanguage models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we\ndevelop a hierarchical framework to categorize latent topics, consisting of two\nmain categories, Situational Awareness (SA) and Crisis Narratives (CN). The\nvolume of SA category closely aligns with real-world fire progressions, peaking\nwithin the first 2-5 days as the fires reach the maximum extent. The most\nfrequent co-occurring category set of public health and safety, loss and\ndamage, and emergency resources expands on a wide range of health-related\nlatent topics, including environmental health, occupational health, and one\nhealth. Grief signals and mental health risks consistently accounted for 60\npercentage and 40 percentage of CN instances, respectively, with the highest\ntotal volume occurring at night. This study contributes the first annotated\nsocial media dataset on the 2025 LA fires, and introduces a scalable\nmulti-layer framework that leverages topic modeling for crisis discourse\nanalysis. By identifying persistent public health concerns, our results can\ninform more empathetic and adaptive strategies for disaster response, public\nhealth communication, and future research in comparable climate-related\ndisaster events."}
{"id": "2505.09747", "pdf": "https://arxiv.org/pdf/2505.09747", "abs": "https://arxiv.org/abs/2505.09747", "authors": ["Benjamin Paaßen", "Suzana Alpsancar", "Tobias Matzner", "Ingrid Scharlau"], "title": "Healthy Distrust in AI systems", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Under the slogan of trustworthy AI, much of contemporary AI research is\nfocused on designing AI systems and usage practices that inspire human trust\nand, thus, enhance adoption of AI systems. However, a person affected by an AI\nsystem may not be convinced by AI system design alone -- neither should they,\nif the AI system is embedded in a social context that gives good reason to\nbelieve that it is used in tension with a person's interest. In such cases,\ndistrust in the system may be justified and necessary to build meaningful trust\nin the first place. We propose the term \"healthy distrust\" to describe such a\njustified, careful stance towards certain AI usage practices. We investigate\nprior notions of trust and distrust in computer science, sociology, history,\npsychology, and philosophy, outline a remaining gap that healthy distrust might\nfill and conceptualize healthy distrust as a crucial part for AI usage that\nrespects human autonomy."}
{"id": "2505.10083", "pdf": "https://arxiv.org/pdf/2505.10083", "abs": "https://arxiv.org/abs/2505.10083", "authors": ["Chengsen Wang", "Qi Qi", "Zhongwen Rao", "Lujia Pan", "Jingyu Wang", "Jianxin Liao"], "title": "ChronoSteer: Bridging Large Language Model and Time Series Foundation Model via Synthetic Data", "categories": ["cs.LG"], "comment": null, "summary": "Conventional forecasting methods rely on unimodal time series data, limiting\ntheir ability to exploit rich textual information. Recently, large language\nmodels (LLMs) and time series foundation models (TSFMs) have demonstrated\npowerful capability in textual reasoning and temporal modeling, respectively.\nIntegrating the strengths of both to construct a multimodal model that\nconcurrently leverages both temporal and textual information for future\ninference has emerged as a critical research challenge. To address the scarcity\nof event-series paired data, we propose a decoupled framework: an LLM is\nemployed to transform textual events into revision instructions, which are then\nused to steer the output of TSFM. To implement this framework, we introduce\nChronoSteer, a multimodal TSFM that can be steered through textual revision\ninstructions, effectively bridging LLM and TSFM. Moreover, to mitigate the\nshortage of cross-modal instruction-series paired data, we devise a two-stage\ntraining strategy based on synthetic data. In addition, we also construct a\nhigh-quality multimodal time series forecasting benchmark to address the\ninformation leakage concerns during evaluation. After integrating with an LLM,\nChronoSteer, which is trained exclusively on synthetic data, achieves a 25.7%\nimprovement in prediction accuracy compared to the unimodal backbone and a\n22.5% gain over the previous state-of-the-art multimodal method."}
{"id": "2505.10292", "pdf": "https://arxiv.org/pdf/2505.10292", "abs": "https://arxiv.org/abs/2505.10292", "authors": ["Daniel A. P. Oliveira", "David Martins de Matos"], "title": "StoryReasoning Dataset: Using Chain-of-Thought for Scene Understanding and Grounded Story Generation", "categories": ["cs.CV", "cs.CL", "I.2.10; I.2.7"], "comment": "31 pages, 14 figures", "summary": "Visual storytelling systems struggle to maintain character identity across\nframes and link actions to appropriate subjects, frequently leading to\nreferential hallucinations. These issues can be addressed through grounding of\ncharacters, objects, and other entities on the visual elements. We propose\nStoryReasoning, a dataset containing 4,178 stories derived from 52,016 movie\nimages, with both structured scene analyses and grounded stories. Each story\nmaintains character and object consistency across frames while explicitly\nmodeling multi-frame relationships through structured tabular representations.\nOur approach features cross-frame object re-identification using visual\nsimilarity and face recognition, chain-of-thought reasoning for explicit\nnarrative modeling, and a grounding scheme that links textual elements to\nvisual entities across multiple frames. We establish baseline performance by\nfine-tuning Qwen2.5-VL 7B, creating Qwen Storyteller, which performs end-to-end\nobject detection, re-identification, and landmark detection while maintaining\nconsistent object references throughout the story. Evaluation demonstrates a\nreduction from 4.06 to 3.56 (-12.3%) hallucinations on average per story when\ncompared to a non-fine-tuned model."}
{"id": "2505.09777", "pdf": "https://arxiv.org/pdf/2505.09777", "abs": "https://arxiv.org/abs/2505.09777", "authors": ["Alejo Lopez-Avila", "Jinhua Du"], "title": "A Survey on Large Language Models in Multimodal Recommender Systems", "categories": ["cs.IR", "cs.CL"], "comment": "30 pages, 6 figures", "summary": "Multimodal recommender systems (MRS) integrate heterogeneous user and item\ndata, such as text, images, and structured information, to enhance\nrecommendation performance. The emergence of large language models (LLMs)\nintroduces new opportunities for MRS by enabling semantic reasoning, in-context\nlearning, and dynamic input handling. Compared to earlier pre-trained language\nmodels (PLMs), LLMs offer greater flexibility and generalisation capabilities\nbut also introduce challenges related to scalability and model accessibility.\nThis survey presents a comprehensive review of recent work at the intersection\nof LLMs and MRS, focusing on prompting strategies, fine-tuning methods, and\ndata adaptation techniques. We propose a novel taxonomy to characterise\nintegration patterns, identify transferable techniques from related\nrecommendation domains, provide an overview of evaluation metrics and datasets,\nand point to possible future directions. We aim to clarify the emerging role of\nLLMs in multimodal recommendation and support future research in this rapidly\nevolving field."}
{"id": "2505.09757", "pdf": "https://arxiv.org/pdf/2505.09757", "abs": "https://arxiv.org/abs/2505.09757", "authors": ["Botao Amber Hu", "Yuhan Liu", "Helena Rong"], "title": "Trustless Autonomy: Understanding Motivations, Benefits and Governance Dilemma in Self-Sovereign Decentralized AI Agents", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "Submitted to CSCW 2026", "summary": "The recent trend of self-sovereign Decentralized AI Agents (DeAgents)\ncombines Large Language Model (LLM)-based AI agents with decentralization\ntechnologies such as blockchain smart contracts and trusted execution\nenvironments (TEEs). These tamper-resistant trustless substrates allow agents\nto achieve self-sovereignty through ownership of cryptowallet private keys and\ncontrol of digital assets and social media accounts. DeAgent eliminates\ncentralized control and reduces human intervention, addressing key trust\nconcerns inherent in centralized AI systems. However, given ongoing challenges\nin LLM reliability such as hallucinations, this creates paradoxical tension\nbetween trustlessness and unreliable autonomy. This study addresses this\nempirical research gap through interviews with DeAgents stakeholders-experts,\nfounders, and developers-to examine their motivations, benefits, and governance\ndilemmas. The findings will guide future DeAgents system and protocol design\nand inform discussions about governance in sociotechnical AI systems in the\nfuture agentic web."}
{"id": "2505.10117", "pdf": "https://arxiv.org/pdf/2505.10117", "abs": "https://arxiv.org/abs/2505.10117", "authors": ["JieHao Wu", "Ziwei Wang", "Junjie Sheng", "Wenhao Li", "Xiangfei Wang", "Jun Luo"], "title": "Learning Virtual Machine Scheduling in Cloud Computing through Language Agents", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "In cloud services, virtual machine (VM) scheduling is a typical Online\nDynamic Multidimensional Bin Packing (ODMBP) problem, characterized by\nlarge-scale complexity and fluctuating demands. Traditional optimization\nmethods struggle to adapt to real-time changes, domain-expert-designed\nheuristic approaches suffer from rigid strategies, and existing learning-based\nmethods often lack generalizability and interpretability. To address these\nlimitations, this paper proposes a hierarchical language agent framework named\nMiCo, which provides a large language model (LLM)-driven heuristic design\nparadigm for solving ODMBP. Specifically, ODMBP is formulated as a Semi-Markov\nDecision Process with Options (SMDP-Option), enabling dynamic scheduling\nthrough a two-stage architecture, i.e., Option Miner and Option Composer.\nOption Miner utilizes LLMs to discover diverse and useful non-context-aware\nstrategies by interacting with constructed environments. Option Composer\nemploys LLMs to discover a composing strategy that integrates the\nnon-context-aware strategies with the contextual ones. Extensive experiments on\nreal-world enterprise datasets demonstrate that MiCo achieves a 96.9\\%\ncompetitive ratio in large-scale scenarios involving more than 10,000 virtual\nmachines. It maintains high performance even under nonstationary request flows\nand diverse configurations, thus validating its effectiveness in complex and\nlarge-scale cloud environments."}
{"id": "2505.10294", "pdf": "https://arxiv.org/pdf/2505.10294", "abs": "https://arxiv.org/abs/2505.10294", "authors": ["Guillaume Balezo", "Roger Trullo", "Albert Pla Planas", "Etienne Decenciere", "Thomas Walter"], "title": "MIPHEI-ViT: Multiplex Immunofluorescence Prediction from H&E Images using ViT Foundation Models", "categories": ["cs.CV", "q-bio.TO", "68T07 (Primary), 92C55 (Secondary)", "I.4.9; I.2.10; I.5.4; J.3"], "comment": null, "summary": "Histopathological analysis is a cornerstone of cancer diagnosis, with\nHematoxylin and Eosin (H&E) staining routinely acquired for every patient to\nvisualize cell morphology and tissue architecture. On the other hand, multiplex\nimmunofluorescence (mIF) enables more precise cell type identification via\nproteomic markers, but has yet to achieve widespread clinical adoption due to\ncost and logistical constraints. To bridge this gap, we introduce MIPHEI\n(Multiplex Immunofluorescence Prediction from H&E), a U-Net-inspired\narchitecture that integrates state-of-the-art ViT foundation models as encoders\nto predict mIF signals from H&E images. MIPHEI targets a comprehensive panel of\nmarkers spanning nuclear content, immune lineages (T cells, B cells, myeloid),\nepithelium, stroma, vasculature, and proliferation. We train our model using\nthe publicly available ORION dataset of restained H&E and mIF images from\ncolorectal cancer tissue, and validate it on two independent datasets. MIPHEI\nachieves accurate cell-type classification from H&E alone, with F1 scores of\n0.88 for Pan-CK, 0.57 for CD3e, 0.56 for SMA, 0.36 for CD68, and 0.30 for CD20,\nsubstantially outperforming both a state-of-the-art baseline and a random\nclassifier for most markers. Our results indicate that our model effectively\ncaptures the complex relationships between nuclear morphologies in their tissue\ncontext, as visible in H&E images and molecular markers defining specific cell\ntypes. MIPHEI offers a promising step toward enabling cell-type-aware analysis\nof large-scale H&E datasets, in view of uncovering relationships between\nspatial cellular organization and patient outcomes."}
{"id": "2505.09855", "pdf": "https://arxiv.org/pdf/2505.09855", "abs": "https://arxiv.org/abs/2505.09855", "authors": ["Alexander Y. Ku", "Thomas L. Griffiths", "Stephanie C. Y. Chan"], "title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies."}
{"id": "2505.09766", "pdf": "https://arxiv.org/pdf/2505.09766", "abs": "https://arxiv.org/abs/2505.09766", "authors": ["Roberto Ponciroli"], "title": "On the Well-Posedness of Green's Function Reconstruction via the Kirchhoff-Helmholtz Equation for One-Speed Neutron Diffusion", "categories": ["math.NA", "cs.AI", "cs.NA"], "comment": null, "summary": "This work presents a methodology for reconstructing the spatial distribution\nof the neutron flux in a nuclear reactor, leveraging real-time measurements\nobtained from ex-core detectors. The Kirchhoff-Helmholtz (K-H) equation\ninherently defines the problem of estimating a scalar field within a domain\nbased on boundary data, making it a natural mathematical framework for this\ntask. The main challenge lies in deriving the Green's function specific to the\ndomain and the neutron diffusion process. While analytical solutions for\nGreen's functions exist for simplified geometries, their derivation of complex,\nheterogeneous domains-such as a nuclear reactor-requires a numerical approach.\nThe objective of this work is to demonstrate the well-posedness of the\ndata-driven Green's function approximation by formulating and solving the K-H\nequation as an inverse problem. After establishing the symmetry properties that\nthe Green's function must satisfy, the K-H equation is derived from the\none-speed neutron diffusion model. This is followed by a comprehensive\ndescription of the procedure for interpreting sensor readings and implementing\nthe neutron flux reconstruction algorithm. Finally, the existence and\nuniqueness of the Green's function inferred from the sampled data are\ndemonstrated, ensuring the reliability of the proposed method and its\npredictions."}
{"id": "2505.10120", "pdf": "https://arxiv.org/pdf/2505.10120", "abs": "https://arxiv.org/abs/2505.10120", "authors": ["Guillaume Godin"], "title": "All You Need Is Synthetic Task Augmentation", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 3 Figures, 6 tables", "summary": "Injecting rule-based models like Random Forests into differentiable neural\nnetwork frameworks remains an open challenge in machine learning. Recent\nadvancements have demonstrated that pretrained models can generate efficient\nmolecular embeddings. However, these approaches often require extensive\npretraining and additional techniques, such as incorporating posterior\nprobabilities, to boost performance. In our study, we propose a novel strategy\nthat jointly trains a single Graph Transformer neural network on both sparse\nmultitask molecular property experimental targets and synthetic targets derived\nfrom XGBoost models trained on Osmordred molecular descriptors. These synthetic\ntasks serve as independent auxiliary tasks. Our results show consistent and\nsignificant performance improvement across all 19 molecular property prediction\ntasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms\nthe XGBoost single-task learner. This demonstrates that synthetic task\naugmentation is an effective method for enhancing neural model performance in\nmultitask molecular property prediction without the need for feature injection\nor pretraining."}
{"id": "2505.10351", "pdf": "https://arxiv.org/pdf/2505.10351", "abs": "https://arxiv.org/abs/2505.10351", "authors": ["Jie Zhu", "Jirong Zha", "Ding Li", "Leye Wang"], "title": "A Unified and Scalable Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability", "categories": ["cs.CV"], "comment": "An extension of our ACM CCS2024 conference paper (arXiv:2404.02462).\n  We show the impacts of scaling from both data and model aspects on membership\n  inference for self-supervised visual encoders", "summary": "Self-supervised learning shows promise in harnessing extensive unlabeled\ndata, but it also confronts significant privacy concerns, especially in vision.\nIn this paper, we perform membership inference on visual self-supervised models\nin a more realistic setting: self-supervised training method and details are\nunknown for an adversary when attacking as he usually faces a black-box system\nin practice. In this setting, considering that self-supervised model could be\ntrained by completely different self-supervised paradigms, e.g., masked image\nmodeling and contrastive learning, with complex training details, we propose a\nunified membership inference method called PartCrop. It is motivated by the\nshared part-aware capability among models and stronger part response on the\ntraining data. Specifically, PartCrop crops parts of objects in an image to\nquery responses within the image in representation space. We conduct extensive\nattacks on self-supervised models with different training protocols and\nstructures using three widely used image datasets. The results verify the\neffectiveness and generalization of PartCrop. Moreover, to defend against\nPartCrop, we evaluate two common approaches, i.e., early stop and differential\nprivacy, and propose a tailored method called shrinking crop scale range. The\ndefense experiments indicate that all of them are effective. Finally, besides\nprototype testing on toy visual encoders and small-scale image datasets, we\nquantitatively study the impacts of scaling from both data and model aspects in\na realistic scenario and propose a scalable PartCrop-v2 by introducing two\nstructural improvements to PartCrop. Our code is at\nhttps://github.com/JiePKU/PartCrop."}
{"id": "2505.09901", "pdf": "https://arxiv.org/pdf/2505.09901", "abs": "https://arxiv.org/abs/2505.09901", "authors": ["Ziyuan Zhang", "Darcy Wang", "Ningyuan Chen", "Rodrigo Mansur", "Vahid Sarhangian"], "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements."}
{"id": "2505.09794", "pdf": "https://arxiv.org/pdf/2505.09794", "abs": "https://arxiv.org/abs/2505.09794", "authors": ["J. Moreno-Casanova", "J. M. Auñón", "A. Mártinez-Pérez", "M. E. Pérez-Martínez", "M. E. Gas-López"], "title": "Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Research projects, including those focused on cancer, rely on the manual\nextraction of information from clinical reports. This process is time-consuming\nand prone to errors, limiting the efficiency of data-driven approaches in\nhealthcare. To address these challenges, Natural Language Processing (NLP)\noffers an alternative for automating the extraction of relevant data from\nelectronic health records (EHRs). In this study, we focus on lung and breast\ncancer due to their high incidence and the significant impact they have on\npublic health. Early detection and effective data management in both types of\ncancer are crucial for improving patient outcomes. To enhance the accuracy and\nefficiency of data extraction, we utilized GMV's NLP tool uQuery, which excels\nat identifying relevant entities in clinical texts and converting them into\nstandardized formats such as SNOMED and OMOP. uQuery not only detects and\nclassifies entities but also associates them with contextual information,\nincluding negated entities, temporal aspects, and patient-related details. In\nthis work, we explore the use of NLP techniques, specifically Named Entity\nRecognition (NER), to automatically identify and extract key clinical\ninformation from EHRs related to these two cancers. A dataset from Health\nResearch Institute Hospital La Fe (IIS La Fe), comprising 200 annotated breast\ncancer and 400 lung cancer reports, was used, with eight clinical entities\nmanually labeled using the Doccano platform. To perform NER, we fine-tuned the\nbsc-bio-ehr-en3 model, a RoBERTa-based biomedical linguistic model pre-trained\nin Spanish. Fine-tuning was performed using the Transformers architecture,\nenabling accurate recognition of clinical entities in these cancer types. Our\nresults demonstrate strong overall performance, particularly in identifying\nentities like MET and PAT, although challenges remain with less frequent\nentities like EVOL."}
{"id": "2505.10125", "pdf": "https://arxiv.org/pdf/2505.10125", "abs": "https://arxiv.org/abs/2505.10125", "authors": ["Wujun Zhou", "Shu Ding", "ZeLin Li", "Wei Wang"], "title": "Enhancing the Performance of Global Model by Improving the Adaptability of Local Models in Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning enables the clients to collaboratively train a global\nmodel, which is aggregated from local models. Due to the heterogeneous data\ndistributions over clients and data privacy in federated learning, it is\ndifficult to train local models to achieve a well-performed global model. In\nthis paper, we introduce the adaptability of local models, i.e., the average\nperformance of local models on data distributions over clients, and enhance the\nperformance of the global model by improving the adaptability of local models.\nSince each client does not know the data distributions over other clients, the\nadaptability of the local model cannot be directly optimized. First, we provide\nthe property of an appropriate local model which has good adaptability on the\ndata distributions over clients. Then, we formalize the property into the local\ntraining objective with a constraint and propose a feasible solution to train\nthe local model. Extensive experiments on federated learning benchmarks\ndemonstrate that our method significantly improves the adaptability of local\nmodels and achieves a well-performed global model that consistently outperforms\nthe baseline methods."}
{"id": "2505.10352", "pdf": "https://arxiv.org/pdf/2505.10352", "abs": "https://arxiv.org/abs/2505.10352", "authors": ["Shihao Zou", "Qingfeng Li", "Wei Ji", "Jingjing Li", "Yongkui Yang", "Guoqi Li", "Chao Dong"], "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer"}
{"id": "2505.09921", "pdf": "https://arxiv.org/pdf/2505.09921", "abs": "https://arxiv.org/abs/2505.09921", "authors": ["Yidan Wang", "Yanan Cao", "Yubing Ren", "Fang Fang", "Zheng Lin", "Binxing Fang"], "title": "PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) excel in various domains but pose inherent\nprivacy risks. Existing methods to evaluate privacy leakage in LLMs often use\nmemorized prefixes or simple instructions to extract data, both of which\nwell-alignment models can easily block. Meanwhile, Jailbreak attacks bypass LLM\nsafety mechanisms to generate harmful content, but their role in privacy\nscenarios remains underexplored. In this paper, we examine the effectiveness of\njailbreak attacks in extracting sensitive information, bridging privacy leakage\nand jailbreak attacks in LLMs. Moreover, we propose PIG, a novel framework\ntargeting Personally Identifiable Information (PII) and addressing the\nlimitations of current jailbreak methods. Specifically, PIG identifies PII\nentities and their types in privacy queries, uses in-context learning to build\na privacy context, and iteratively updates it with three gradient-based\nstrategies to elicit target PII. We evaluate PIG and existing jailbreak methods\nusing two privacy-related datasets. Experiments on four white-box and two\nblack-box LLMs show that PIG outperforms baseline methods and achieves\nstate-of-the-art (SoTA) results. The results underscore significant privacy\nrisks in LLMs, emphasizing the need for stronger safeguards. Our code is\navailble at\n\\href{https://github.com/redwyd/PrivacyJailbreak}{https://github.com/redwyd/PrivacyJailbreak}."}
{"id": "2505.09796", "pdf": "https://arxiv.org/pdf/2505.09796", "abs": "https://arxiv.org/abs/2505.09796", "authors": ["Skylar S. Gay", "Tucker Netherton", "Barbara Marquez", "Raymond Mumme", "Mary Gronberg", "Brent Parker", "Chelsea Pinnix", "Sanjay Shete", "Carlos Cardenas", "Laurence Court"], "title": "Virtual Dosimetrists: A Radiotherapy Training \"Flight Simulator\"", "categories": ["physics.med-ph", "cs.AI"], "comment": null, "summary": "Effective education in radiotherapy plan quality review requires a robust,\nregularly updated set of examples and the flexibility to demonstrate multiple\npossible planning approaches and their consequences. However, the current\nclinic-based paradigm does not support these needs. To address this, we have\ndeveloped 'Virtual Dosimetrist' models that can both generate training examples\nof suboptimal treatment plans and then allow trainees to improve the plan\nquality through simple natural language prompts, as if communicating with a\ndosimetrist. The dose generation and modification process is accurate, rapid,\nand requires only modest resources. This work is the first to combine dose\ndistribution prediction with natural language processing; providing a robust\npipeline for both generating suboptimal training plans and allowing trainees to\npractice their critical plan review and improvement skills that addresses the\nchallenges of the current clinic-based paradigm."}
{"id": "2505.10128", "pdf": "https://arxiv.org/pdf/2505.10128", "abs": "https://arxiv.org/abs/2505.10128", "authors": ["Huy Q. Le", "Latif U. Khan", "Choong Seon Hong"], "title": "Robust Federated Learning on Edge Devices with Domain Heterogeneity", "categories": ["cs.LG", "cs.AI"], "comment": "IWCMC 2025", "summary": "Federated Learning (FL) allows collaborative training while ensuring data\nprivacy across distributed edge devices, making it a popular solution for\nprivacy-sensitive applications. However, FL faces significant challenges due to\nstatistical heterogeneity, particularly domain heterogeneity, which impedes the\nglobal mode's convergence. In this study, we introduce a new framework to\naddress this challenge by improving the generalization ability of the FL global\nmodel under domain heterogeneity, using prototype augmentation. Specifically,\nwe introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a\nprototype-based FL framework designed to enhance feature diversity and model\nrobustness. FedAPC leverages prototypes derived from the mean features of\naugmented data to capture richer representations. By aligning local features\nwith global prototypes, we enable the model to learn meaningful semantic\nfeatures while reducing overfitting to any specific domain. Experimental\nresults on the Office-10 and Digits datasets illustrate that our framework\noutperforms SOTA baselines, demonstrating superior performance."}
{"id": "2505.10420", "pdf": "https://arxiv.org/pdf/2505.10420", "abs": "https://arxiv.org/abs/2505.10420", "authors": ["Andrei Arhire", "Radu Timofte"], "title": "Learned Lightweight Smartphone ISP with Unpaired Data", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at CVPRW 2025", "summary": "The Image Signal Processor (ISP) is a fundamental component in modern\nsmartphone cameras responsible for conversion of RAW sensor image data to RGB\nimages with a strong focus on perceptual quality. Recent work highlights the\npotential of deep learning approaches and their ability to capture details with\na quality increasingly close to that of professional cameras. A difficult and\ncostly step when developing a learned ISP is the acquisition of pixel-wise\naligned paired data that maps the raw captured by a smartphone camera sensor to\nhigh-quality reference images. In this work, we address this challenge by\nproposing a novel training method for a learnable ISP that eliminates the need\nfor direct correspondences between raw images and ground-truth data with\nmatching content. Our unpaired approach employs a multi-term loss function\nguided by adversarial training with multiple discriminators processing feature\nmaps from pre-trained networks to maintain content structure while learning\ncolor and texture characteristics from the target RGB dataset. Using\nlightweight neural network architectures suitable for mobile devices as\nbackbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm\nUltraISP datasets. Compared to paired training methods, our unpaired learning\nstrategy shows strong potential and achieves high fidelity across multiple\nevaluation metrics. The code and pre-trained models are available at\nhttps://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data ."}
{"id": "2505.09949", "pdf": "https://arxiv.org/pdf/2505.09949", "abs": "https://arxiv.org/abs/2505.09949", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Samgyu Yang", "Abdulrahman Faden"], "title": "Advanced Crash Causation Analysis for Freeway Safety: A Large Language Model Approach to Identifying Key Contributing Factors", "categories": ["cs.LG", "cs.CL", "stat.AP"], "comment": null, "summary": "Understanding the factors contributing to traffic crashes and developing\nstrategies to mitigate their severity is essential. Traditional statistical\nmethods and machine learning models often struggle to capture the complex\ninteractions between various factors and the unique characteristics of each\ncrash. This research leverages large language model (LLM) to analyze freeway\ncrash data and provide crash causation analysis accordingly. By compiling 226\ntraffic safety studies related to freeway crashes, a training dataset\nencompassing environmental, driver, traffic, and geometric design factors was\ncreated. The Llama3 8B model was fine-tuned using QLoRA to enhance its\nunderstanding of freeway crashes and their contributing factors, as covered in\nthese studies. The fine-tuned Llama3 8B model was then used to identify crash\ncausation without pre-labeled data through zero-shot classification, providing\ncomprehensive explanations to ensure that the identified causes were reasonable\nand aligned with existing research. Results demonstrate that LLMs effectively\nidentify primary crash causes such as alcohol-impaired driving, speeding,\naggressive driving, and driver inattention. Incorporating event data, such as\nroad maintenance, offers more profound insights. The model's practical\napplicability and potential to improve traffic safety measures were validated\nby a high level of agreement among researchers in the field of traffic safety,\nas reflected in questionnaire results with 88.89%. This research highlights the\ncomplex nature of traffic crashes and how LLMs can be used for comprehensive\nanalysis of crash causation and other contributing factors. Moreover, it\nprovides valuable insights and potential countermeasures to aid planners and\npolicymakers in developing more effective and efficient traffic safety\npractices."}
{"id": "2505.09805", "pdf": "https://arxiv.org/pdf/2505.09805", "abs": "https://arxiv.org/abs/2505.09805", "authors": ["Aditya Nagori", "Ayush Gautam", "Matthew O. Wiens", "Vuong Nguyen", "Nathan Kenya Mugisha", "Jerome Kabakyenga", "Niranjan Kissoon", "John Mark Ansermino", "Rishikesan Kamaleswaran"], "title": "Contextual Phenotyping of Pediatric Sepsis Cohort Using Large Language Models", "categories": ["q-bio.QM", "cs.AI", "cs.LG", "stat.AP"], "comment": "11 pages, 2 Figures, 1 Table", "summary": "Clustering patient subgroups is essential for personalized care and efficient\nresource use. Traditional clustering methods struggle with high-dimensional,\nheterogeneous healthcare data and lack contextual understanding. This study\nevaluates Large Language Model (LLM) based clustering against classical methods\nusing a pediatric sepsis dataset from a low-income country (LIC), containing\n2,686 records with 28 numerical and 119 categorical variables. Patient records\nwere serialized into text with and without a clustering objective. Embeddings\nwere generated using quantized LLAMA 3.1 8B, DeepSeek-R1-Distill-Llama-8B with\nlow-rank adaptation(LoRA), and Stella-En-400M-V5 models. K-means clustering was\napplied to these embeddings. Classical comparisons included K-Medoids\nclustering on UMAP and FAMD-reduced mixed data. Silhouette scores and\nstatistical tests evaluated cluster quality and distinctiveness.\nStella-En-400M-V5 achieved the highest Silhouette Score (0.86). LLAMA 3.1 8B\nwith the clustering objective performed better with higher number of clusters,\nidentifying subgroups with distinct nutritional, clinical, and socioeconomic\nprofiles. LLM-based methods outperformed classical techniques by capturing\nricher context and prioritizing key features. These results highlight potential\nof LLMs for contextual phenotyping and informed decision-making in\nresource-limited settings."}
{"id": "2505.10147", "pdf": "https://arxiv.org/pdf/2505.10147", "abs": "https://arxiv.org/abs/2505.10147", "authors": ["Yash", "Nikhil Karamchandani", "Avishek Ghosh"], "title": "Near Optimal Best Arm Identification for Clustered Bandits", "categories": ["cs.LG", "cs.MA"], "comment": "To be published in ICML 2025", "summary": "This work investigates the problem of best arm identification for multi-agent\nmulti-armed bandits. We consider $N$ agents grouped into $M$ clusters, where\neach cluster solves a stochastic bandit problem. The mapping between agents and\nbandits is a priori unknown. Each bandit is associated with $K$ arms, and the\ngoal is to identify the best arm for each agent under a $\\delta$-probably\ncorrect ($\\delta$-PC) framework, while minimizing sample complexity and\ncommunication overhead.\n  We propose two novel algorithms: Clustering then Best Arm Identification\n(Cl-BAI) and Best Arm Identification then Clustering (BAI-Cl). Cl-BAI uses a\ntwo-phase approach that first clusters agents based on the bandit problems they\nare learning, followed by identifying the best arm for each cluster. BAI-Cl\nreverses the sequence by identifying the best arms first and then clustering\nagents accordingly. Both algorithms leverage the successive elimination\nframework to ensure computational efficiency and high accuracy.\n  We establish $\\delta$-PC guarantees for both methods, derive bounds on their\nsample complexity, and provide a lower bound for this problem class. Moreover,\nwhen $M$ is small (a constant), we show that the sample complexity of a variant\nof BAI-Cl is minimax optimal in an order-wise sense. Experiments on synthetic\nand real-world datasets (MovieLens, Yelp) demonstrate the superior performance\nof the proposed algorithms in terms of sample and communication efficiency,\nparticularly in settings where $M \\ll N$."}
{"id": "2505.10453", "pdf": "https://arxiv.org/pdf/2505.10453", "abs": "https://arxiv.org/abs/2505.10453", "authors": ["Tyler Tran", "Sangeet Khemlani", "J. G. Trafton"], "title": "Vision language models have difficulty recognizing virtual objects", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision language models (VLMs) are AI systems paired with both language and\nvision encoders to process multimodal input. They are capable of performing\ncomplex semantic tasks such as automatic captioning, but it remains an open\nquestion about how well they comprehend the visuospatial properties of scenes\ndepicted in the images they process. We argue that descriptions of virtual\nobjects -- objects that are not visually represented in an image -- can help\ntest scene comprehension in these AI systems. For example, an image that\ndepicts a person standing under a tree can be paired with the following prompt:\nimagine that a kite is stuck in the tree. VLMs that comprehend the scene should\nupdate their representations and reason sensibly about the spatial relations\nbetween all three objects. We describe systematic evaluations of\nstate-of-the-art VLMs and show that their ability to process virtual objects is\ninadequate."}
{"id": "2505.10093", "pdf": "https://arxiv.org/pdf/2505.10093", "abs": "https://arxiv.org/abs/2505.10093", "authors": ["Hsuan-Lei Shao"], "title": "From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI", "categories": ["cs.AI", "cs.CL", "I.2.4; H.3.3; J.5"], "comment": "4 pages, 4 figures", "summary": "Taiwanese China Studies (CS) has developed into a rich, interdisciplinary\nresearch field shaped by the unique geopolitical position and long standing\nacademic engagement with Mainland China. This study responds to the growing\nneed to systematically revisit and reorganize decades of Taiwan based CS\nscholarship by proposing an AI assisted approach that transforms unstructured\nacademic texts into structured, interactive knowledge representations. We apply\ngenerative AI (GAI) techniques and large language models (LLMs) to extract and\nstandardize entity relation triples from 1,367 peer reviewed CS articles\npublished between 1996 and 2019. These triples are then visualized through a\nlightweight D3.js based system, forming the foundation of a domain specific\nknowledge graph and vector database for the field. This infrastructure allows\nusers to explore conceptual nodes and semantic relationships across the corpus,\nrevealing previously uncharted intellectual trajectories, thematic clusters,\nand research gaps. By decomposing textual content into graph structured\nknowledge units, our system enables a paradigm shift from linear text\nconsumption to network based knowledge navigation. In doing so, it enhances\nscholarly access to CS literature while offering a scalable, data driven\nalternative to traditional ontology construction. This work not only\ndemonstrates how generative AI can augment area studies and digital humanities\nbut also highlights its potential to support a reimagined scholarly\ninfrastructure for regional knowledge systems."}
{"id": "2505.09807", "pdf": "https://arxiv.org/pdf/2505.09807", "abs": "https://arxiv.org/abs/2505.09807", "authors": ["Timour Ichmoukhamedov", "David Martens"], "title": "Exploring the generalization of LLM truth directions on conversational formats", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Several recent works argue that LLMs have a universal truth direction where\ntrue and false statements are linearly separable in the activation space of the\nmodel. It has been demonstrated that linear probes trained on a single hidden\nstate of the model already generalize across a range of topics and might even\nbe used for lie detection in LLM conversations. In this work we explore how\nthis truth direction generalizes between various conversational formats. We\nfind good generalization between short conversations that end on a lie, but\npoor generalization to longer formats where the lie appears earlier in the\ninput prompt. We propose a solution that significantly improves this type of\ngeneralization by adding a fixed key phrase at the end of each conversation.\nOur results highlight the challenges towards reliable LLM lie detectors that\ngeneralize to new settings."}
{"id": "2505.10167", "pdf": "https://arxiv.org/pdf/2505.10167", "abs": "https://arxiv.org/abs/2505.10167", "authors": ["Saikat Barua", "Mostafizur Rahman", "Shehenaz Khaled", "Md Jafor Sadek", "Rafiul Islam", "Shahnewaz Siddique"], "title": "QuXAI: Explainers for Hybrid Quantum Machine Learning Models", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": "16 pages, 6 figures, 7 equations", "summary": "The emergence of hybrid quantum-classical machine learning (HQML) models\nopens new horizons of computational intelligence but their fundamental\ncomplexity frequently leads to black box behavior that undermines transparency\nand reliability in their application. Although XAI for quantum systems still in\nits infancy, a major research gap is evident in robust global and local\nexplainability approaches that are designed for HQML architectures that employ\nquantized feature encoding followed by classical learning. The gap is the focus\nof this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an\nexplainer for explaining feature importance in these hybrid systems. Our model\nentails the creation of HQML models incorporating quantum feature maps, the use\nof Q-MEDLEY, which combines feature based inferences, preserving the quantum\ntransformation stage and visualizing the resulting attributions. Our result\nshows that Q-MEDLEY delineates influential classical aspects in HQML models, as\nwell as separates their noise, and competes well against established XAI\ntechniques in classical validation settings. Ablation studies more\nsignificantly expose the virtues of the composite structure used in Q-MEDLEY.\nThe implications of this work are critically important, as it provides a route\nto improve the interpretability and reliability of HQML models, thus promoting\ngreater confidence and being able to engage in safer and more responsible use\nof quantum-enhanced AI technology."}
{"id": "2505.10473", "pdf": "https://arxiv.org/pdf/2505.10473", "abs": "https://arxiv.org/abs/2505.10473", "authors": ["Fengdi Zhang", "Hongkun Cao", "Ruqi Huang"], "title": "Consistent Quantity-Quality Control across Scenes for Deployment-Aware Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "To reduce storage and computational costs, 3D Gaussian splatting (3DGS) seeks\nto minimize the number of Gaussians used while preserving high rendering\nquality, introducing an inherent trade-off between Gaussian quantity and\nrendering quality. Existing methods strive for better quantity-quality\nperformance, but lack the ability for users to intuitively adjust this\ntrade-off to suit practical needs such as model deployment under diverse\nhardware and communication constraints. Here, we present ControlGS, a 3DGS\noptimization method that achieves semantically meaningful and cross-scene\nconsistent quantity-quality control while maintaining strong quantity-quality\nperformance. Through a single training run using a fixed setup and a\nuser-specified hyperparameter reflecting quantity-quality preference, ControlGS\ncan automatically find desirable quantity-quality trade-off points across\ndiverse scenes, from compact objects to large outdoor scenes. It also\noutperforms baselines by achieving higher rendering quality with fewer\nGaussians, and supports a broad adjustment range with stepless control over the\ntrade-off."}
{"id": "2505.10117", "pdf": "https://arxiv.org/pdf/2505.10117", "abs": "https://arxiv.org/abs/2505.10117", "authors": ["JieHao Wu", "Ziwei Wang", "Junjie Sheng", "Wenhao Li", "Xiangfei Wang", "Jun Luo"], "title": "Learning Virtual Machine Scheduling in Cloud Computing through Language Agents", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "In cloud services, virtual machine (VM) scheduling is a typical Online\nDynamic Multidimensional Bin Packing (ODMBP) problem, characterized by\nlarge-scale complexity and fluctuating demands. Traditional optimization\nmethods struggle to adapt to real-time changes, domain-expert-designed\nheuristic approaches suffer from rigid strategies, and existing learning-based\nmethods often lack generalizability and interpretability. To address these\nlimitations, this paper proposes a hierarchical language agent framework named\nMiCo, which provides a large language model (LLM)-driven heuristic design\nparadigm for solving ODMBP. Specifically, ODMBP is formulated as a Semi-Markov\nDecision Process with Options (SMDP-Option), enabling dynamic scheduling\nthrough a two-stage architecture, i.e., Option Miner and Option Composer.\nOption Miner utilizes LLMs to discover diverse and useful non-context-aware\nstrategies by interacting with constructed environments. Option Composer\nemploys LLMs to discover a composing strategy that integrates the\nnon-context-aware strategies with the contextual ones. Extensive experiments on\nreal-world enterprise datasets demonstrate that MiCo achieves a 96.9\\%\ncompetitive ratio in large-scale scenarios involving more than 10,000 virtual\nmachines. It maintains high performance even under nonstationary request flows\nand diverse configurations, thus validating its effectiveness in complex and\nlarge-scale cloud environments."}
{"id": "2505.09814", "pdf": "https://arxiv.org/pdf/2505.09814", "abs": "https://arxiv.org/abs/2505.09814", "authors": ["Dmitry Rybin", "Yushun Zhang", "Zhi-Quan Luo"], "title": "$XX^{t}$ Can Be Faster", "categories": ["cs.DS", "cs.AI", "cs.LG", "cs.SC", "68Q25, 68T20", "F.2.1; I.1.2"], "comment": null, "summary": "We present a new algorithm RXTX that computes product of matrix by its\ntranspose $XX^{t}$. RXTX uses $5\\%$ less multiplications and additions than\nState-of-the-Art and achieves accelerations even for small sizes of matrix $X$.\nThe algorithm was discovered by combining Machine Learning-based search methods\nwith Combinatorial Optimization."}
{"id": "2505.10172", "pdf": "https://arxiv.org/pdf/2505.10172", "abs": "https://arxiv.org/abs/2505.10172", "authors": ["Zeyan Li", "Libing Chen", "Yin Tang"], "title": "Does Scaling Law Apply in Time Series Forecasting?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Rapid expansion of model size has emerged as a key challenge in time series\nforecasting. From early Transformer with tens of megabytes to recent\narchitectures like TimesNet with thousands of megabytes, performance gains have\noften come at the cost of exponentially increasing parameter counts. But is\nthis scaling truly necessary? To question the applicability of the scaling law\nin time series forecasting, we propose Alinear, an ultra-lightweight\nforecasting model that achieves competitive performance using only k-level\nparameters. We introduce a horizon-aware adaptive decomposition mechanism that\ndynamically rebalances component emphasis across different forecast lengths,\nalongside a progressive frequency attenuation strategy that achieves stable\nprediction in various forecasting horizons without incurring the computational\noverhead of attention mechanisms. Extensive experiments on seven benchmark\ndatasets demonstrate that Alinear consistently outperforms large-scale models\nwhile using less than 1% of their parameters, maintaining strong accuracy\nacross both short and ultra-long forecasting horizons. Moreover, to more fairly\nevaluate model efficiency, we propose a new parameter-aware evaluation metric\nthat highlights the superiority of ALinear under constrained model budgets. Our\nanalysis reveals that the relative importance of trend and seasonal components\nvaries depending on data characteristics rather than following a fixed pattern,\nvalidating the necessity of our adaptive design. This work challenges the\nprevailing belief that larger models are inherently better and suggests a\nparadigm shift toward more efficient time series modeling."}
{"id": "2505.10481", "pdf": "https://arxiv.org/pdf/2505.10481", "abs": "https://arxiv.org/abs/2505.10481", "authors": ["Ilya Ovodov", "Petr Surovtsev", "Karina Kvanchiani", "Alexander Kapitanov", "Alexander Nagaev"], "title": "Logos as a Well-Tempered Pre-train for Sign Language Recognition", "categories": ["cs.CV"], "comment": null, "summary": "This paper examines two aspects of the isolated sign language recognition\n(ISLR) task. First, despite the availability of a number of datasets, the\namount of data for most individual sign languages is limited. It poses the\nchallenge of cross-language ISLR model training, including transfer learning.\nSecond, similar signs can have different semantic meanings. It leads to\nambiguity in dataset labeling and raises the question of the best policy for\nannotating such signs. To address these issues, this study presents Logos, a\nnovel Russian Sign Language (RSL) dataset, the most extensive ISLR dataset by\nthe number of signers and one of the largest available datasets while also the\nlargest RSL dataset in size and vocabulary. It is shown that a model,\npre-trained on the Logos dataset can be used as a universal encoder for other\nlanguage SLR tasks, including few-shot learning. We explore cross-language\ntransfer learning approaches and find that joint training using multiple\nclassification heads benefits accuracy for the target lowresource datasets the\nmost. The key feature of the Logos dataset is explicitly annotated visually\nsimilar sign groups. We show that explicitly labeling visually similar signs\nimproves trained model quality as a visual encoder for downstream tasks. Based\non the proposed contributions, we outperform current state-of-the-art results\nfor the WLASL dataset and get competitive results for the AUTSL dataset, with a\nsingle stream model processing solely RGB video. The source code, dataset, and\npre-trained models are publicly available."}
{"id": "2505.10118", "pdf": "https://arxiv.org/pdf/2505.10118", "abs": "https://arxiv.org/abs/2505.10118", "authors": ["Yangfu Li", "Hongjian Zhan", "Tianyi Chen", "Qi Liu", "Yue Lu"], "title": "Why 1 + 1 < 1 in Visual Token Pruning: Beyond Naive Integration via Multi-Objective Balanced Covering", "categories": ["cs.CV", "cs.CL"], "comment": "31 pages,9 figures,conference", "summary": "Existing visual token pruning methods target prompt alignment and visual\npreservation with static strategies, overlooking the varying relative\nimportance of these objectives across tasks, which leads to inconsistent\nperformance. To address this, we derive the first closed-form error bound for\nvisual token pruning based on the Hausdorff distance, uniformly characterizing\nthe contributions of both objectives. Moreover, leveraging $\\epsilon$-covering\ntheory, we reveal an intrinsic trade-off between these objectives and quantify\ntheir optimal attainment levels under a fixed budget. To practically handle\nthis trade-off, we propose Multi-Objective Balanced Covering (MoB), which\nreformulates visual token pruning as a bi-objective covering problem. In this\nframework, the attainment trade-off reduces to budget allocation via greedy\nradius trading. MoB offers a provable performance bound and linear scalability\nwith respect to the number of input visual tokens, enabling adaptation to\nchallenging pruning scenarios. Extensive experiments show that MoB preserves\n96.4% of performance for LLaVA-1.5-7B using only 11.1% of the original visual\ntokens and accelerates LLaVA-Next-7B by 1.3-1.5$\\times$ with negligible\nperformance loss. Additionally, evaluations on Qwen2-VL and Video-LLaVA confirm\nthat MoB integrates seamlessly into advanced MLLMs and diverse vision-language\ntasks."}
{"id": "2505.09830", "pdf": "https://arxiv.org/pdf/2505.09830", "abs": "https://arxiv.org/abs/2505.09830", "authors": ["Martín Rodríguez", "Gustavo Rossi", "Alejandro Fernandez"], "title": "Evaluating Large Language Models for the Generation of Unit Tests with Equivalence Partitions and Boundary Values", "categories": ["cs.SE", "cs.AI"], "comment": "Under revision at Jornadas de Cloud Computing, Big Data & Emerging\n  Topics (JCC-BD&ET) - 2025", "summary": "The design and implementation of unit tests is a complex task many\nprogrammers neglect. This research evaluates the potential of Large Language\nModels (LLMs) in automatically generating test cases, comparing them with\nmanual tests. An optimized prompt was developed, that integrates code and\nrequirements, covering critical cases such as equivalence partitions and\nboundary values. The strengths and weaknesses of LLMs versus trained\nprogrammers were compared through quantitative metrics and manual qualitative\nanalysis. The results show that the effectiveness of LLMs depends on\nwell-designed prompts, robust implementation, and precise requirements.\nAlthough flexible and promising, LLMs still require human supervision. This\nwork highlights the importance of manual qualitative analysis as an essential\ncomplement to automation in unit test evaluation."}
{"id": "2505.10192", "pdf": "https://arxiv.org/pdf/2505.10192", "abs": "https://arxiv.org/abs/2505.10192", "authors": ["Prashant P. Shinde", "Priyadarshini P. Pai", "Shashishekar P. Adiga", "K. Subramanya Mayya", "Yongbeom Seo", "Myungsoo Hwang", "Heeyoung Go", "Changmin Park"], "title": "Defect Detection in Photolithographic Patterns Using Deep Learning Models Trained on Synthetic Data", "categories": ["cs.LG"], "comment": null, "summary": "In the photolithographic process vital to semiconductor manufacturing,\nvarious types of defects appear during EUV pattering. Due to ever-shrinking\npattern size, these defects are extremely small and cause false or missed\ndetection during inspection. Specifically, the lack of defect-annotated quality\ndata with good representation of smaller defects has prohibited deployment of\ndeep learning based defect detection models in fabrication lines. To resolve\nthe problem of data unavailability, we artificially generate scanning electron\nmicroscopy (SEM) images of line patterns with known distribution of defects and\nautonomously annotate them. We then employ state-of-the-art object detection\nmodels to investigate defect detection performance as a function of defect\nsize, much smaller than the pitch width. We find that the real-time object\ndetector YOLOv8 has the best mean average precision of 96% as compared to\nEfficientNet, 83%, and SSD, 77%, with the ability to detect smaller defects. We\nreport the smallest defect size that can be detected reliably. When tested on\nreal SEM data, the YOLOv8 model correctly detected 84.6% of Bridge defects and\n78.3% of Break defects across all relevant instances. These promising results\nsuggest that synthetic data can be used as an alternative to real-world data in\norder to develop robust machine-learning models."}
{"id": "2505.10483", "pdf": "https://arxiv.org/pdf/2505.10483", "abs": "https://arxiv.org/abs/2505.10483", "authors": ["Yi Li", "Haonan Wang", "Qixiang Zhang", "Boyu Xiao", "Chenchang Hu", "Hualiang Wang", "Xiaomeng Li"], "title": "UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation", "categories": ["cs.CV", "cs.AI"], "comment": "UniEval is the first evaluation framework designed for unified\n  multimodal models, including a holistic benchmark UniBench and the UniScore\n  metric", "summary": "The emergence of unified multimodal understanding and generation models is\nrapidly attracting attention because of their ability to enhance\ninstruction-following capabilities while minimizing model redundancy. However,\nthere is a lack of a unified evaluation framework for these models, which would\nenable an elegant, simplified, and overall evaluation. Current models conduct\nevaluations on multiple task-specific benchmarks, but there are significant\nlimitations, such as the lack of overall results, errors from extra evaluation\nmodels, reliance on extensive labeled images, benchmarks that lack diversity,\nand metrics with limited capacity for instruction-following evaluation. To\ntackle these challenges, we introduce UniEval, the first evaluation framework\ndesigned for unified multimodal models without extra models, images, or\nannotations. This facilitates a simplified and unified evaluation process. The\nUniEval framework contains a holistic benchmark, UniBench (supports both\nunified and visual generation models), along with the corresponding UniScore\nmetric. UniBench includes 81 fine-grained tags contributing to high diversity.\nExperimental results indicate that UniBench is more challenging than existing\nbenchmarks, and UniScore aligns closely with human evaluations, surpassing\ncurrent metrics. Moreover, we extensively evaluated SoTA unified and visual\ngeneration models, uncovering new insights into Univeral's unique values."}
{"id": "2505.10222", "pdf": "https://arxiv.org/pdf/2505.10222", "abs": "https://arxiv.org/abs/2505.10222", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "Beiwen Zhang", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "ComplexFormer: Disruptively Advancing Transformer Inference Ability via Head-Specific Complex Vector Attention", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Transformer models rely on self-attention to capture token dependencies but\nface challenges in effectively integrating positional information while\nallowing multi-head attention (MHA) flexibility. Prior methods often model\nsemantic and positional differences disparately or apply uniform positional\nadjustments across heads, potentially limiting representational capacity. This\npaper introduces ComplexFormer, featuring Complex Multi-Head Attention-CMHA.\nCMHA empowers each head to independently model semantic and positional\ndifferences unified within the complex plane, representing interactions as\nrotations and scaling. ComplexFormer incorporates two key improvements: (1) a\nper-head Euler transformation, converting real-valued query/key projections\ninto polar-form complex vectors for head-specific complex subspace operation;\nand (2) a per-head adaptive differential rotation mechanism,\nexp[i(Adapt(ASmn,i) + Delta(Pmn),i)], allowing each head to learn distinct\nstrategies for integrating semantic angle differences (ASmn,i) with relative\npositional encodings (Delta(Pmn),i). Extensive experiments on language\nmodeling, text generation, code generation, and mathematical reasoning show\nComplexFormer achieves superior performance, significantly lower generation\nperplexity , and improved long-context coherence compared to strong baselines\nlike RoPE-Transformers. ComplexFormer demonstrates strong parameter efficiency,\noffering a more expressive, adaptable attention mechanism."}
{"id": "2505.09847", "pdf": "https://arxiv.org/pdf/2505.09847", "abs": "https://arxiv.org/abs/2505.09847", "authors": ["Liyang Zhao", "Olurotimi Seton", "Himadeep Reddy Reddivari", "Suvendu Jena", "Shadow Zhao", "Rachit Kumar", "Changshuai Wei"], "title": "Causal Predictive Optimization and Generation for Business AI", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "comment": null, "summary": "The sales process involves sales functions converting leads or opportunities\nto customers and selling more products to existing customers. The optimization\nof the sales process thus is key to success of any B2B business. In this work,\nwe introduce a principled approach to sales optimization and business AI,\nnamely the Causal Predictive Optimization and Generation, which includes three\nlayers: 1) prediction layer with causal ML 2) optimization layer with\nconstraint optimization and contextual bandit 3) serving layer with Generative\nAI and feedback-loop for system enhancement. We detail the implementation and\ndeployment of the system in LinkedIn, showcasing significant wins over legacy\nsystems and sharing learning and insight broadly applicable to this field."}
{"id": "2505.10198", "pdf": "https://arxiv.org/pdf/2505.10198", "abs": "https://arxiv.org/abs/2505.10198", "authors": ["Mariano Ferrero", "José Omar Chelotti", "Luciano Sebastián Martinez-Rau", "Leandro Vignolo", "Martín Pires", "Julio Ricardo Galli", "Leonardo Luis Giovanini", "Hugo Leonardo Rufiner"], "title": "A multi-head deep fusion model for recognition of cattle foraging events using sound and movement signals", "categories": ["cs.LG"], "comment": "Preprint submitted to Engineering Applications of Artificial\n  Intelligence", "summary": "Monitoring feeding behaviour is a relevant task for efficient herd management\nand the effective use of available resources in grazing cattle. The ability to\nautomatically recognise animals' feeding activities through the identification\nof specific jaw movements allows for the improvement of diet formulation, as\nwell as early detection of metabolic problems and symptoms of animal\ndiscomfort, among other benefits. The use of sensors to obtain signals for such\nmonitoring has become popular in the last two decades. The most frequently\nemployed sensors include accelerometers, microphones, and cameras, each with\nits own set of advantages and drawbacks. An unexplored aspect is the\nsimultaneous use of multiple sensors with the aim of combining signals in order\nto enhance the precision of the estimations. In this direction, this work\nintroduces a deep neural network based on the fusion of acoustic and inertial\nsignals, composed of convolutional, recurrent, and dense layers. The main\nadvantage of this model is the combination of signals through the automatic\nextraction of features independently from each of them. The model has emerged\nfrom an exploration and comparison of different neural network architectures\nproposed in this work, which carry out information fusion at different levels.\nFeature-level fusion has outperformed data and decision-level fusion by at\nleast a 0.14 based on the F1-score metric. Moreover, a comparison with\nstate-of-the-art machine learning methods is presented, including traditional\nand deep learning approaches. The proposed model yielded an F1-score value of\n0.802, representing a 14% increase compared to previous methods. Finally,\nresults from an ablation study and post-training quantization evaluation are\nalso reported."}
{"id": "2505.10496", "pdf": "https://arxiv.org/pdf/2505.10496", "abs": "https://arxiv.org/abs/2505.10496", "authors": ["Raman Dutt", "Pedro Sanchez", "Yongchen Yao", "Steven McDonagh", "Sotirios A. Tsaftaris", "Timothy Hospedales"], "title": "CheXGenBench: A Unified Benchmark For Fidelity, Privacy and Utility of Synthetic Chest Radiographs", "categories": ["cs.CV"], "comment": null, "summary": "We introduce CheXGenBench, a rigorous and multifaceted evaluation framework\nfor synthetic chest radiograph generation that simultaneously assesses\nfidelity, privacy risks, and clinical utility across state-of-the-art\ntext-to-image generative models. Despite rapid advancements in generative AI\nfor real-world imagery, medical domain evaluations have been hindered by\nmethodological inconsistencies, outdated architectural comparisons, and\ndisconnected assessment criteria that rarely address the practical clinical\nvalue of synthetic samples. CheXGenBench overcomes these limitations through\nstandardised data partitioning and a unified evaluation protocol comprising\nover 20 quantitative metrics that systematically analyse generation quality,\npotential privacy vulnerabilities, and downstream clinical applicability across\n11 leading text-to-image architectures. Our results reveal critical\ninefficiencies in the existing evaluation protocols, particularly in assessing\ngenerative fidelity, leading to inconsistent and uninformative comparisons. Our\nframework establishes a standardised benchmark for the medical AI community,\nenabling objective and reproducible comparisons while facilitating seamless\nintegration of both existing and future generative models. Additionally, we\nrelease a high-quality, synthetic dataset, SynthCheX-75K, comprising 75K\nradiographs generated by the top-performing model (Sana 0.6B) in our benchmark\nto support further research in this critical domain. Through CheXGenBench, we\nestablish a new state-of-the-art and release our framework, models, and\nSynthCheX-75K dataset at https://raman1121.github.io/CheXGenBench/"}
{"id": "2505.10231", "pdf": "https://arxiv.org/pdf/2505.10231", "abs": "https://arxiv.org/abs/2505.10231", "authors": ["Haozhe Luo", "Ziyu Zhou", "Zixin Shu", "Aurélie Pahud de Mortanges", "Robert Berke", "Mauricio Reyes"], "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner."}
{"id": "2505.09852", "pdf": "https://arxiv.org/pdf/2505.09852", "abs": "https://arxiv.org/abs/2505.09852", "authors": ["Apollinaire Poli Nemkova", "Sarath Chandra Lingareddy", "Sagnik Ray Choudhury", "Mark V. Albert"], "title": "Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance across natural\nlanguage tasks, but their ability to forecast violent conflict remains\nunderexplored. We investigate whether LLMs possess meaningful parametric\nknowledge-encoded in their pretrained weights-to predict conflict escalation\nand fatalities without external data. This is critical for early warning\nsystems, humanitarian planning, and policy-making. We compare this parametric\nknowledge with non-parametric capabilities, where LLMs access structured and\nunstructured context from conflict datasets (e.g., ACLED, GDELT) and recent\nnews reports via Retrieval-Augmented Generation (RAG). Incorporating external\ninformation could enhance model performance by providing up-to-date context\notherwise missing from pretrained weights. Our two-part evaluation framework\nspans 2020-2024 across conflict-prone regions in the Horn of Africa and the\nMiddle East. In the parametric setting, LLMs predict conflict trends and\nfatalities relying only on pretrained knowledge. In the non-parametric setting,\nmodels receive summaries of recent conflict events, indicators, and\ngeopolitical developments. We compare predicted conflict trend labels (e.g.,\nEscalate, Stable Conflict, De-escalate, Peace) and fatalities against\nhistorical data. Our findings highlight the strengths and limitations of LLMs\nfor conflict forecasting and the benefits of augmenting them with structured\nexternal knowledge."}
{"id": "2505.10213", "pdf": "https://arxiv.org/pdf/2505.10213", "abs": "https://arxiv.org/abs/2505.10213", "authors": ["Mohammadmahdi Ghasemloo", "Alireza Moradi"], "title": "Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting", "categories": ["cs.LG", "stat.AP"], "comment": null, "summary": "With the widespread adoption of Large Language Models (LLMs), there is a\ngrowing need to establish best practices for leveraging their capabilities\nbeyond traditional natural language tasks. In this paper, a novel cross-domain\nknowledge transfer framework is proposed to enhance the performance of LLMs in\ntime series forecasting -- a task of increasing relevance in fields such as\nenergy systems, finance, and healthcare. The approach systematically infuses\nLLMs with structured temporal information to improve their forecasting\naccuracy. This study evaluates the proposed method on a real-world time series\ndataset and compares it to a naive baseline where the LLM receives no auxiliary\ninformation. Results show that knowledge-informed forecasting significantly\noutperforms the uninformed baseline in terms of predictive accuracy and\ngeneralization. These findings highlight the potential of knowledge transfer\nstrategies to bridge the gap between LLMs and domain-specific forecasting\ntasks."}
{"id": "2505.10497", "pdf": "https://arxiv.org/pdf/2505.10497", "abs": "https://arxiv.org/abs/2505.10497", "authors": ["Iurii Medvedev", "Nuno Goncalves"], "title": "MorphGuard: Morph Specific Margin Loss for Enhancing Robustness to Face Morphing Attacks", "categories": ["cs.CV"], "comment": null, "summary": "Face recognition has evolved significantly with the advancement of deep\nlearning techniques, enabling its widespread adoption in various applications\nrequiring secure authentication. However, this progress has also increased its\nexposure to presentation attacks, including face morphing, which poses a\nserious security threat by allowing one identity to impersonate another.\nTherefore, modern face recognition systems must be robust against such attacks.\n  In this work, we propose a novel approach for training deep networks for face\nrecognition with enhanced robustness to face morphing attacks. Our method\nmodifies the classification task by introducing a dual-branch classification\nstrategy that effectively handles the ambiguity in the labeling of face morphs.\nThis adaptation allows the model to incorporate morph images into the training\nprocess, improving its ability to distinguish them from bona fide samples.\n  Our strategy has been validated on public benchmarks, demonstrating its\neffectiveness in enhancing robustness against face morphing attacks.\nFurthermore, our approach is universally applicable and can be integrated into\nexisting face recognition training pipelines to improve classification-based\nrecognition methods."}
{"id": "2505.10292", "pdf": "https://arxiv.org/pdf/2505.10292", "abs": "https://arxiv.org/abs/2505.10292", "authors": ["Daniel A. P. Oliveira", "David Martins de Matos"], "title": "StoryReasoning Dataset: Using Chain-of-Thought for Scene Understanding and Grounded Story Generation", "categories": ["cs.CV", "cs.CL", "I.2.10; I.2.7"], "comment": "31 pages, 14 figures", "summary": "Visual storytelling systems struggle to maintain character identity across\nframes and link actions to appropriate subjects, frequently leading to\nreferential hallucinations. These issues can be addressed through grounding of\ncharacters, objects, and other entities on the visual elements. We propose\nStoryReasoning, a dataset containing 4,178 stories derived from 52,016 movie\nimages, with both structured scene analyses and grounded stories. Each story\nmaintains character and object consistency across frames while explicitly\nmodeling multi-frame relationships through structured tabular representations.\nOur approach features cross-frame object re-identification using visual\nsimilarity and face recognition, chain-of-thought reasoning for explicit\nnarrative modeling, and a grounding scheme that links textual elements to\nvisual entities across multiple frames. We establish baseline performance by\nfine-tuning Qwen2.5-VL 7B, creating Qwen Storyteller, which performs end-to-end\nobject detection, re-identification, and landmark detection while maintaining\nconsistent object references throughout the story. Evaluation demonstrates a\nreduction from 4.06 to 3.56 (-12.3%) hallucinations on average per story when\ncompared to a non-fine-tuned model."}
{"id": "2505.09855", "pdf": "https://arxiv.org/pdf/2505.09855", "abs": "https://arxiv.org/abs/2505.09855", "authors": ["Alexander Y. Ku", "Thomas L. Griffiths", "Stephanie C. Y. Chan"], "title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies."}
{"id": "2505.10222", "pdf": "https://arxiv.org/pdf/2505.10222", "abs": "https://arxiv.org/abs/2505.10222", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "Beiwen Zhang", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "ComplexFormer: Disruptively Advancing Transformer Inference Ability via Head-Specific Complex Vector Attention", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Transformer models rely on self-attention to capture token dependencies but\nface challenges in effectively integrating positional information while\nallowing multi-head attention (MHA) flexibility. Prior methods often model\nsemantic and positional differences disparately or apply uniform positional\nadjustments across heads, potentially limiting representational capacity. This\npaper introduces ComplexFormer, featuring Complex Multi-Head Attention-CMHA.\nCMHA empowers each head to independently model semantic and positional\ndifferences unified within the complex plane, representing interactions as\nrotations and scaling. ComplexFormer incorporates two key improvements: (1) a\nper-head Euler transformation, converting real-valued query/key projections\ninto polar-form complex vectors for head-specific complex subspace operation;\nand (2) a per-head adaptive differential rotation mechanism,\nexp[i(Adapt(ASmn,i) + Delta(Pmn),i)], allowing each head to learn distinct\nstrategies for integrating semantic angle differences (ASmn,i) with relative\npositional encodings (Delta(Pmn),i). Extensive experiments on language\nmodeling, text generation, code generation, and mathematical reasoning show\nComplexFormer achieves superior performance, significantly lower generation\nperplexity , and improved long-context coherence compared to strong baselines\nlike RoPE-Transformers. ComplexFormer demonstrates strong parameter efficiency,\noffering a more expressive, adaptable attention mechanism."}
{"id": "2505.10533", "pdf": "https://arxiv.org/pdf/2505.10533", "abs": "https://arxiv.org/abs/2505.10533", "authors": ["Aaryan Sharma", "Shivansh Gupta", "Samar Agarwal", "Vishak Prasad C.", "Ganesh Ramakrishnan"], "title": "Enhancing Multi-Image Question Answering via Submodular Subset Selection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Large multimodal models (LMMs) have achieved high performance in\nvision-language tasks involving single image but they struggle when presented\nwith a collection of multiple images (Multiple Image Question Answering\nscenario). These tasks, which involve reasoning over large number of images,\npresent issues in scalability (with increasing number of images) and retrieval\nperformance. In this work, we propose an enhancement for retriever framework\nintroduced in MIRAGE model using submodular subset selection techniques. Our\nmethod leverages query-aware submodular functions, such as GraphCut, to\npre-select a subset of semantically relevant images before main retrieval\ncomponent. We demonstrate that using anchor-based queries and augmenting the\ndata improves submodular-retriever pipeline effectiveness, particularly in\nlarge haystack sizes."}
{"id": "2505.10465", "pdf": "https://arxiv.org/pdf/2505.10465", "abs": "https://arxiv.org/abs/2505.10465", "authors": ["Yizhou liu", "Ziming Liu", "Jeff Gore"], "title": "Superposition Yields Robust Neural Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages, 23 figures", "summary": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters."}
{"id": "2505.09861", "pdf": "https://arxiv.org/pdf/2505.09861", "abs": "https://arxiv.org/abs/2505.09861", "authors": ["John Bencina", "Erkut Aykutlug", "Yue Chen", "Zerui Zhang", "Stephanie Sorenson", "Shao Tang", "Changshuai Wei"], "title": "LiDDA: Data Driven Attribution at LinkedIn", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ME"], "comment": null, "summary": "Data Driven Attribution, which assigns conversion credits to marketing\ninteractions based on causal patterns learned from data, is the foundation of\nmodern marketing intelligence and vital to any marketing businesses and\nadvertising platform. In this paper, we introduce a unified transformer-based\nattribution approach that can handle member-level data, aggregate-level data,\nand integration of external macro factors. We detail the large scale\nimplementation of the approach at LinkedIn, showcasing significant impact. We\nalso share learning and insights that are broadly applicable to the marketing\nand ad tech fields."}
{"id": "2505.10259", "pdf": "https://arxiv.org/pdf/2505.10259", "abs": "https://arxiv.org/abs/2505.10259", "authors": ["Xiangwen Zhuge", "Xu Shen", "Zeyu Wang", "Fan Dang", "Xuan Ding", "Danyang Li", "Yahui Han", "Tianxiang Hao", "Zheng Yang"], "title": "SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices", "categories": ["cs.LG"], "comment": null, "summary": "Efficient LLM inference on resource-constrained devices presents significant\nchallenges in compute and memory utilization. Due to limited GPU memory,\nexisting systems offload model weights to CPU memory, incurring substantial I/O\noverhead between the CPU and GPU. This leads to two major inefficiencies: (1)\nGPU cores are underutilized, often remaining idle while waiting for data to be\nloaded; and (2) GPU memory has low impact on performance, as reducing its\ncapacity has minimal effect on overall throughput.In this paper, we propose\nSpecOffload, a high-throughput inference engine that embeds speculative\ndecoding into offloading. Our key idea is to unlock latent GPU resources for\nstoring and executing a draft model used for speculative decoding, thus\naccelerating inference at near-zero additional cost. To support this, we\ncarefully orchestrate the interleaved execution of target and draft models in\nspeculative decoding within the offloading pipeline, and propose a planner to\nmanage tensor placement and select optimal parameters. Compared to the best\nbaseline, SpecOffload improves GPU core utilization by 4.49x and boosts\ninference throughput by 2.54x. Our code is available at\nhttps://github.com/MobiSense/SpecOffload ."}
{"id": "2505.10541", "pdf": "https://arxiv.org/pdf/2505.10541", "abs": "https://arxiv.org/abs/2505.10541", "authors": ["Pengfei Wang", "Guohai Xu", "Weinong Wang", "Junjie Yang", "Jie Lou", "Yunhua Xue"], "title": "Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements have enhanced the capability of Multimodal Large Language\nModels (MLLMs) to comprehend multi-image information. However, existing\nbenchmarks primarily evaluate answer correctness, overlooking whether models\ngenuinely comprehend the visual input. To address this, we define implicit\nvisual misunderstanding (IVM), where MLLMs provide correct answers without\nfully comprehending the visual input. Through our analysis, we decouple the\nvisual and textual modalities within the causal attention module, revealing\nthat attention distribution increasingly converges on the image associated with\nthe correct answer as the network layers deepen. This insight leads to the\nintroduction of a scale-agnostic metric, \\textit{attention accuracy}, and a\nnovel benchmark for quantifying IVMs. Attention accuracy directly evaluates the\nmodel's visual understanding via internal mechanisms, remaining robust to\npositional biases for more reliable assessments. Furthermore, we extend our\napproach to finer granularities and demonstrate its effectiveness in unimodal\nscenarios, underscoring its versatility and generalizability."}
{"id": "2505.10475", "pdf": "https://arxiv.org/pdf/2505.10475", "abs": "https://arxiv.org/abs/2505.10475", "authors": ["Mouxiang Chen", "Binyuan Hui", "Zeyu Cui", "Jiaxi Yang", "Dayiheng Liu", "Jianling Sun", "Junyang Lin", "Zhongxin Liu"], "title": "Parallel Scaling Law for Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "It is commonly believed that scaling language models should commit a\nsignificant space or time cost, by increasing the parameters (parameter\nscaling) or output tokens (inference-time scaling). We introduce the third and\nmore inference-efficient scaling paradigm: increasing the model's parallel\ncomputation during both training and inference time. We apply $P$ diverse and\nlearnable transformations to the input, execute forward passes of the model in\nparallel, and dynamically aggregate the $P$ outputs. This method, namely\nparallel scaling (ParScale), scales parallel computation by reusing existing\nparameters and can be applied to any model structure, optimization procedure,\ndata, or task. We theoretically propose a new scaling law and validate it\nthrough large-scale pre-training, which shows that a model with $P$ parallel\nstreams is similar to scaling the parameters by $O(\\log P)$ while showing\nsuperior inference efficiency. For example, ParScale can use up to 22$\\times$\nless memory increase and 6$\\times$ less latency increase compared to parameter\nscaling that achieves the same performance improvement. It can also recycle an\noff-the-shelf pre-trained model into a parallelly scaled one by post-training\non a small amount of tokens, further reducing the training budget. The new\nscaling law we discovered potentially facilitates the deployment of more\npowerful models in low-resource scenarios, and provides an alternative\nperspective for the role of computation in machine learning."}
{"id": "2505.09868", "pdf": "https://arxiv.org/pdf/2505.09868", "abs": "https://arxiv.org/abs/2505.09868", "authors": ["Tin Trung Nguyen", "Jiannan Xu", "Phuong-Anh Nguyen-Le", "Jonathan Lazar", "Donald Braman", "Hal Daumé III", "Zubin Jelveh"], "title": "Which Demographic Features Are Relevant for Individual Fairness Evaluation of U.S. Recidivism Risk Assessment Tools?", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "Despite its U.S. constitutional foundation, the technical ``individual\nfairness'' criterion has not been operationalized in state or federal\nstatutes/regulations. We conduct a human subjects experiment to address this\ngap, evaluating which demographic features are relevant for individual fairness\nevaluation of recidivism risk assessment (RRA) tools. Our analyses conclude\nthat the individual similarity function should consider age and sex, but it\nshould ignore race."}
{"id": "2505.10262", "pdf": "https://arxiv.org/pdf/2505.10262", "abs": "https://arxiv.org/abs/2505.10262", "authors": ["Jiaju Qi", "Lei Lei", "Thorsteinn Jonsson", "Lajos Hanzo"], "title": "Electric Bus Charging Schedules Relying on Real Data-Driven Targets Based on Hierarchical Deep Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "The charging scheduling problem of Electric Buses (EBs) is investigated based\non Deep Reinforcement Learning (DRL). A Markov Decision Process (MDP) is\nconceived, where the time horizon includes multiple charging and operating\nperiods in a day, while each period is further divided into multiple time\nsteps. To overcome the challenge of long-range multi-phase planning with sparse\nreward, we conceive Hierarchical DRL (HDRL) for decoupling the original MDP\ninto a high-level Semi-MDP (SMDP) and multiple low-level MDPs. The Hierarchical\nDouble Deep Q-Network (HDDQN)-Hindsight Experience Replay (HER) algorithm is\nproposed for simultaneously solving the decision problems arising at different\ntemporal resolutions. As a result, the high-level agent learns an effective\npolicy for prescribing the charging targets for every charging period, while\nthe low-level agent learns an optimal policy for setting the charging power of\nevery time step within a single charging period, with the aim of minimizing the\ncharging costs while meeting the charging target. It is proved that the flat\npolicy constructed by superimposing the optimal high-level policy and the\noptimal low-level policy performs as well as the optimal policy of the original\nMDP. Since jointly learning both levels of policies is challenging due to the\nnon-stationarity of the high-level agent and the sampling inefficiency of the\nlow-level agent, we divide the joint learning process into two phases and\nexploit our new HER algorithm to manipulate the experience replay buffers for\nboth levels of agents. Numerical experiments are performed with the aid of\nreal-world data to evaluate the performance of the proposed algorithm."}
{"id": "2505.10551", "pdf": "https://arxiv.org/pdf/2505.10551", "abs": "https://arxiv.org/abs/2505.10551", "authors": ["Yiwen Liu", "Jessica Bader", "Jae Myung Kim"], "title": "Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data", "categories": ["cs.CV", "cs.AI"], "comment": "CVPRW 2025", "summary": "With the development of photorealistic diffusion models, models trained in\npart or fully on synthetic data achieve progressively better results. However,\ndiffusion models still routinely generate images that would not exist in\nreality, such as a dog floating above the ground or with unrealistic texture\nartifacts. We define the concept of feasibility as whether attributes in a\nsynthetic image could realistically exist in the real-world domain; synthetic\nimages containing attributes that violate this criterion are considered\ninfeasible. Intuitively, infeasible images are typically considered\nout-of-distribution; thus, training on such images is expected to hinder a\nmodel's ability to generalize to real-world data, and they should therefore be\nexcluded from the training set whenever possible. However, does feasibility\nreally matter? In this paper, we investigate whether enforcing feasibility is\nnecessary when generating synthetic training data for CLIP-based classifiers,\nfocusing on three target attributes: background, color, and texture. We\nintroduce VariReal, a pipeline that minimally edits a given source image to\ninclude feasible or infeasible attributes given by the textual prompt generated\nby a large language model. Our experiments show that feasibility minimally\naffects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference\nin top-1 accuracy across three fine-grained datasets. Also, the attribute\nmatters on whether the feasible/infeasible images adversarially influence the\nclassification performance. Finally, mixing feasible and infeasible images in\ntraining datasets does not significantly impact performance compared to using\npurely feasible or infeasible datasets."}
{"id": "2505.10495", "pdf": "https://arxiv.org/pdf/2505.10495", "abs": "https://arxiv.org/abs/2505.10495", "authors": ["Vibha Belavadi", "Tushar Vatsa", "Dewang Sultania", "Suhas Suresha", "Ishita Verma", "Cheng Chen", "Tracy Holloway King", "Michael Friedrich"], "title": "RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs", "categories": ["cs.LG", "cs.CL"], "comment": "Proceedings of the 4th International Workshop on Knowledge-Augmented\n  Methods for Natural Language Processing", "summary": "This paper addresses fine-tuning Large Language Models (LLMs) for function\ncalling tasks when real user interaction data is unavailable. In digital\ncontent creation tools, where users express their needs through natural\nlanguage queries that must be mapped to API calls, the lack of real-world\ntask-specific data and privacy constraints for training on it necessitate\nsynthetic data generation. Existing approaches to synthetic data generation\nfall short in diversity and complexity, failing to replicate real-world data\ndistributions and leading to suboptimal performance after LLM fine-tuning. We\npresent a novel router-based architecture that leverages domain resources like\ncontent metadata and structured knowledge graphs, along with text-to-text and\nvision-to-text language models to generate high-quality synthetic training\ndata. Our architecture's flexible routing mechanism enables synthetic data\ngeneration that matches observed real-world distributions, addressing a\nfundamental limitation of traditional approaches. Evaluation on a comprehensive\nset of real user queries demonstrates significant improvements in both function\nclassification accuracy and API parameter selection. Models fine-tuned with our\nsynthetic data consistently outperform traditional approaches, establishing new\nbenchmarks for function calling tasks."}
{"id": "2505.09901", "pdf": "https://arxiv.org/pdf/2505.09901", "abs": "https://arxiv.org/abs/2505.09901", "authors": ["Ziyuan Zhang", "Darcy Wang", "Ningyuan Chen", "Rodrigo Mansur", "Vahid Sarhangian"], "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements."}
{"id": "2505.10264", "pdf": "https://arxiv.org/pdf/2505.10264", "abs": "https://arxiv.org/abs/2505.10264", "authors": ["Francesco Diana", "André Nusser", "Chuan Xu", "Giovanni Neglia"], "title": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated Learning (FL) enables collaborative training of machine learning\nmodels across distributed clients without sharing raw data, ostensibly\npreserving data privacy. Nevertheless, recent studies have revealed critical\nvulnerabilities in FL, showing that a malicious central server can manipulate\nmodel updates to reconstruct clients' private training data. Existing data\nreconstruction attacks have important limitations: they often rely on\nassumptions about the clients' data distribution or their efficiency\nsignificantly degrades when batch sizes exceed just a few tens of samples.\n  In this work, we introduce a novel data reconstruction attack that overcomes\nthese limitations. Our method leverages a new geometric perspective on fully\nconnected layers to craft malicious model parameters, enabling the perfect\nrecovery of arbitrarily large data batches in classification tasks without any\nprior knowledge of clients' data. Through extensive experiments on both image\nand tabular datasets, we demonstrate that our attack outperforms existing\nmethods and achieves perfect reconstruction of data batches two orders of\nmagnitude larger than the state of the art."}
{"id": "2505.10557", "pdf": "https://arxiv.org/pdf/2505.10557", "abs": "https://arxiv.org/abs/2505.10557", "authors": ["Ke Wang", "Junting Pan", "Linda Wei", "Aojun Zhou", "Weikang Shi", "Zimu Lu", "Han Xiao", "Yunqiao Yang", "Houxing Ren", "Mingjie Zhan", "Hongsheng Li"], "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder."}
{"id": "2505.10526", "pdf": "https://arxiv.org/pdf/2505.10526", "abs": "https://arxiv.org/abs/2505.10526", "authors": ["Mugilan Ganesan", "Shane Segal", "Ankur Aggarwal", "Nish Sinnadurai", "Sean Lie", "Vithursan Thangarasa"], "title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Main paper: 11 pp., 4 figs., 3 tabs.; Supplementary: 2 pp", "summary": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs."}
{"id": "2505.09907", "pdf": "https://arxiv.org/pdf/2505.09907", "abs": "https://arxiv.org/abs/2505.09907", "authors": ["Linwei Zhang", "LuFeng", "Ruijia Liang"], "title": "Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "With the growing demand for healthy foods, agricultural product price\nforecasting has become increasingly important. Hass avocados, as a high-value\ncrop, exhibit complex price fluctuations influenced by factors such as\nseasonality, region, and weather. Traditional prediction models often struggle\nwith highly nonlinear and dynamic data. To address this, we propose a hybrid\ndeep learning model, TCN-MLP-Attention Architecture, combining Temporal\nConvolutional Networks (TCN) for sequential feature extraction, Multi-Layer\nPerceptrons (MLP) for nonlinear interactions, and an Attention mechanism for\ndynamic feature weighting. The dataset used covers over 50,000 records of Hass\navocado sales across the U.S. from 2015 to 2018, including variables such as\nsales volume, average price, time, region, weather, and variety type, collected\nfrom point-of-sale systems and the Hass Avocado Board. After systematic\npreprocessing, including missing value imputation and feature normalization,\nthe proposed model was trained and evaluated. Experimental results demonstrate\nthat the TCN-MLP-Attention model achieves excellent predictive performance,\nwith an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods.\nThis research provides a scalable and effective approach for time series\nforecasting in agricultural markets and offers valuable insights for\nintelligent supply chain management and price strategy optimization."}
{"id": "2505.10271", "pdf": "https://arxiv.org/pdf/2505.10271", "abs": "https://arxiv.org/abs/2505.10271", "authors": ["Rafael Pablos Sarabia", "Joachim Nyborg", "Morten Birk", "Jeppe Liborius Sjørup", "Anders Lillevang Vesterholt", "Ira Assent"], "title": "RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We present a deep learning model for high-resolution probabilistic\nprecipitation forecasting over an 8-hour horizon in Europe, overcoming the\nlimitations of radar-only deep learning models with short forecast lead times.\nOur model efficiently integrates multiple data sources - including radar,\nsatellite, and physics-based numerical weather prediction (NWP) - while\ncapturing long-range interactions, resulting in accurate forecasts with robust\nuncertainty quantification through consistent probabilistic maps. Featuring a\ncompact architecture, it enables more efficient training and faster inference\nthan existing models. Extensive experiments demonstrate that our model\nsurpasses current operational NWP systems, extrapolation-based methods, and\ndeep-learning nowcasting models, setting a new standard for high-resolution\nprecipitation forecasting in Europe, ensuring a balance between accuracy,\ninterpretability, and computational efficiency."}
{"id": "2505.10562", "pdf": "https://arxiv.org/pdf/2505.10562", "abs": "https://arxiv.org/abs/2505.10562", "authors": ["Wenxuan Wang", "Fan Zhang", "Yufeng Cui", "Haiwen Diao", "Zhuoyan Luo", "Huchuan Lu", "Jing Liu", "Xinlong Wang"], "title": "End-to-End Vision Tokenizer Tuning", "categories": ["cs.CV"], "comment": null, "summary": "Existing vision tokenization isolates the optimization of vision tokenizers\nfrom downstream training, implicitly assuming the visual tokens can generalize\nwell across various tasks, e.g., image generation and visual question\nanswering. The vision tokenizer optimized for low-level reconstruction is\nagnostic to downstream tasks requiring varied representations and semantics.\nThis decoupled paradigm introduces a critical misalignment: The loss of the\nvision tokenization can be the representation bottleneck for target tasks. For\nexample, errors in tokenizing text in a given image lead to poor results when\nrecognizing or generating them. To address this, we propose ETT, an end-to-end\nvision tokenizer tuning approach that enables joint optimization between vision\ntokenization and target autoregressive tasks. Unlike prior autoregressive\nmodels that use only discrete indices from a frozen vision tokenizer, ETT\nleverages the visual embeddings of the tokenizer codebook, and optimizes the\nvision tokenizers end-to-end with both reconstruction and caption objectives.\nETT can be seamlessly integrated into existing training pipelines with minimal\narchitecture modifications. Our ETT is simple to implement and integrate,\nwithout the need to adjust the original codebooks or architectures of the\nemployed large language models. Extensive experiments demonstrate that our\nproposed end-to-end vision tokenizer tuning unlocks significant performance\ngains, i.e., 2-6% for multimodal understanding and visual generation tasks\ncompared to frozen tokenizer baselines, while preserving the original\nreconstruction capability. We hope this very simple and strong method can\nempower multimodal foundation models besides image generation and\nunderstanding."}
{"id": "2505.10543", "pdf": "https://arxiv.org/pdf/2505.10543", "abs": "https://arxiv.org/abs/2505.10543", "authors": ["Annie Wong", "Thomas Bäck", "Aske Plaat", "Niki van Stein", "Anna V. Kononova"], "title": "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While large language models demonstrate impressive performance on static\nbenchmarks, the true potential of large language models as self-learning and\nreasoning agents in dynamic environments remains unclear. This study\nsystematically evaluates the efficacy of self-reflection, heuristic mutation,\nand planning as prompting techniques to test the adaptive capabilities of\nagents. We conduct experiments with various open-source language models in\ndynamic environments and find that larger models generally outperform smaller\nones, but that strategic prompting can close this performance gap. Second, a\ntoo-long prompt can negatively impact smaller models on basic reactive tasks,\nwhile larger models show more robust behaviour. Third, advanced prompting\ntechniques primarily benefit smaller models on complex games, but offer less\nimprovement for already high-performing large language models. Yet, we find\nthat advanced reasoning methods yield highly variable outcomes: while capable\nof significantly improving performance when reasoning and decision-making\nalign, they also introduce instability and can lead to big performance drops.\nCompared to human performance, our findings reveal little evidence of true\nemergent reasoning. Instead, large language model performance exhibits\npersistent limitations in crucial areas such as planning, reasoning, and\nspatial coordination, suggesting that current-generation large language models\nstill suffer fundamental shortcomings that may not be fully overcome through\nself-reflective prompting alone. Reasoning is a multi-faceted task, and while\nreasoning methods like Chain of thought improves multi-step reasoning on math\nword problems, our findings using dynamic benchmarks highlight important\nshortcomings in general reasoning capabilities, indicating a need to move\nbeyond static benchmarks to capture the complexity of reasoning."}
{"id": "2505.09925", "pdf": "https://arxiv.org/pdf/2505.09925", "abs": "https://arxiv.org/abs/2505.09925", "authors": ["Yutao Yang", "Jie Zhou", "Junsong Li", "Qianjun Pan", "Bihao Zhan", "Qin Chen", "Xipeng Qiu", "Liang He"], "title": "Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces an interactive continual learning paradigm where AI\nmodels dynamically learn new skills from real-time human feedback while\nretaining prior knowledge. This paradigm distinctively addresses two major\nlimitations of traditional continual learning: (1) dynamic model updates using\nstreaming, real-time human-annotated data, rather than static datasets with\nfixed labels, and (2) the assumption of clean labels, by explicitly handling\nthe noisy feedback common in real-world interactions. To tackle these problems,\nwe propose RiCL, a Reinforced interactive Continual Learning framework\nleveraging Large Language Models (LLMs) to learn new skills effectively from\ndynamic feedback. RiCL incorporates three key components: a temporal\nconsistency-aware purifier to automatically discern clean from noisy samples in\ndata streams; an interaction-aware direct preference optimization strategy to\nalign model behavior with human intent by reconciling AI-generated and\nhuman-provided feedback; and a noise-resistant contrastive learning module that\ncaptures robust representations by exploiting inherent data relationships, thus\navoiding reliance on potentially unreliable labels. Extensive experiments on\ntwo benchmark datasets (FewRel and TACRED), contaminated with realistic noise\npatterns, demonstrate that our RiCL approach substantially outperforms existing\ncombinations of state-of-the-art online continual learning and noisy-label\nlearning methods."}
{"id": "2505.10272", "pdf": "https://arxiv.org/pdf/2505.10272", "abs": "https://arxiv.org/abs/2505.10272", "authors": ["Niklas Dexheimer", "Sascha Gaudlitz", "Johannes Schmidt-Hieber"], "title": "Spike-timing-dependent Hebbian learning as noisy gradient descent", "categories": ["cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Hebbian learning is a key principle underlying learning in biological neural\nnetworks. It postulates that synaptic changes occur locally, depending on the\nactivities of pre- and postsynaptic neurons. While Hebbian learning based on\nneuronal firing rates is well explored, much less is known about learning rules\nthat account for precise spike-timing. We relate a Hebbian\nspike-timing-dependent plasticity rule to noisy gradient descent with respect\nto a natural loss function on the probability simplex. This connection allows\nus to prove that the learning rule eventually identifies the presynaptic neuron\nwith the highest activity. We also discover an intrinsic connection to noisy\nmirror descent."}
{"id": "2505.10565", "pdf": "https://arxiv.org/pdf/2505.10565", "abs": "https://arxiv.org/abs/2505.10565", "authors": ["Zehan Wang", "Siyu Chen", "Lihe Yang", "Jialei Wang", "Ziang Zhang", "Hengshuang Zhao", "Zhou Zhao"], "title": "Depth Anything with Any Prior", "categories": ["cs.CV"], "comment": "Home page: https://prior-depth-anything.github.io/", "summary": "This work presents Prior Depth Anything, a framework that combines incomplete\nbut precise metric information in depth measurement with relative but complete\ngeometric structures in depth prediction, generating accurate, dense, and\ndetailed metric depth maps for any scene. To this end, we design a\ncoarse-to-fine pipeline to progressively integrate the two complementary depth\nsources. First, we introduce pixel-level metric alignment and distance-aware\nweighting to pre-fill diverse metric priors by explicitly using depth\nprediction. It effectively narrows the domain gap between prior patterns,\nenhancing generalization across varying scenarios. Second, we develop a\nconditioned monocular depth estimation (MDE) model to refine the inherent noise\nof depth priors. By conditioning on the normalized pre-filled prior and\nprediction, the model further implicitly merges the two complementary depth\nsources. Our model showcases impressive zero-shot generalization across depth\ncompletion, super-resolution, and inpainting over 7 real-world datasets,\nmatching or even surpassing previous task-specific methods. More importantly,\nit performs well on challenging, unseen mixed priors and enables test-time\nimprovements by switching prediction models, providing a flexible\naccuracy-efficiency trade-off while evolving with advancements in MDE models."}
{"id": "2505.10557", "pdf": "https://arxiv.org/pdf/2505.10557", "abs": "https://arxiv.org/abs/2505.10557", "authors": ["Ke Wang", "Junting Pan", "Linda Wei", "Aojun Zhou", "Weikang Shi", "Zimu Lu", "Han Xiao", "Yunqiao Yang", "Houxing Ren", "Mingjie Zhan", "Hongsheng Li"], "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder."}
{"id": "2505.09926", "pdf": "https://arxiv.org/pdf/2505.09926", "abs": "https://arxiv.org/abs/2505.09926", "authors": ["Bin-Bin Gao", "Yue Zhu", "Jiangtao Yan", "Yuezhi Cai", "Weixi Zhang", "Meng Wang", "Jun Liu", "Yong Liu", "Lei Wang", "Chengjie Wang"], "title": "AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": "27 pages, 15 figures, 22 tables", "summary": "Universal visual anomaly detection aims to identify anomalies from novel or\nunseen vision domains without additional fine-tuning, which is critical in open\nscenarios. Recent studies have demonstrated that pre-trained vision-language\nmodels like CLIP exhibit strong generalization with just zero or a few normal\nimages. However, existing methods struggle with designing prompt templates,\ncomplex token interactions, or requiring additional fine-tuning, resulting in\nlimited flexibility. In this work, we present a simple yet effective method\ncalled AdaptCLIP based on two key insights. First, adaptive visual and textual\nrepresentations should be learned alternately rather than jointly. Second,\ncomparative learning between query and normal image prompt should incorporate\nboth contextual and aligned residual features, rather than relying solely on\nresidual features. AdaptCLIP treats CLIP models as a foundational service,\nadding only three simple adapters, visual adapter, textual adapter, and\nprompt-query adapter, at its input or output ends. AdaptCLIP supports\nzero-/few-shot generalization across domains and possesses a training-free\nmanner on target domains once trained on a base dataset. AdaptCLIP achieves\nstate-of-the-art performance on 12 anomaly detection benchmarks from industrial\nand medical domains, significantly outperforming existing competitive methods.\nWe will make the code and model of AdaptCLIP available at\nhttps://github.com/gaobb/AdaptCLIP."}
{"id": "2505.10296", "pdf": "https://arxiv.org/pdf/2505.10296", "abs": "https://arxiv.org/abs/2505.10296", "authors": ["Jiaju Qi", "Lei Lei", "Thorsteinn Jonsson", "Dusit Niyato"], "title": "Optimizing Electric Bus Charging Scheduling with Uncertainties Using Hierarchical Deep Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "The growing adoption of Electric Buses (EBs) represents a significant step\ntoward sustainable development. By utilizing Internet of Things (IoT) systems,\ncharging stations can autonomously determine charging schedules based on\nreal-time data. However, optimizing EB charging schedules remains a critical\nchallenge due to uncertainties in travel time, energy consumption, and\nfluctuating electricity prices. Moreover, to address real-world complexities,\ncharging policies must make decisions efficiently across multiple time scales\nand remain scalable for large EB fleets. In this paper, we propose a\nHierarchical Deep Reinforcement Learning (HDRL) approach that reformulates the\noriginal Markov Decision Process (MDP) into two augmented MDPs. To solve these\nMDPs and enable multi-timescale decision-making, we introduce a novel HDRL\nalgorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization\nEnhancement (DAC-MAPPO-E). Scalability challenges of the Double Actor-Critic\n(DAC) algorithm for large-scale EB fleets are addressed through enhancements at\nboth decision levels. At the high level, we redesign the decentralized actor\nnetwork and integrate an attention mechanism to extract relevant global state\ninformation for each EB, decreasing the size of neural networks. At the low\nlevel, the Multi-Agent Proximal Policy Optimization (MAPPO) algorithm is\nincorporated into the DAC framework, enabling decentralized and coordinated\ncharging power decisions, reducing computational complexity and enhancing\nconvergence speed. Extensive experiments with real-world data demonstrate the\nsuperior performance and scalability of DAC-MAPPO-E in optimizing EB fleet\ncharging schedules."}
{"id": "2505.10566", "pdf": "https://arxiv.org/pdf/2505.10566", "abs": "https://arxiv.org/abs/2505.10566", "authors": ["Yen-Chi Cheng", "Krishna Kumar Singh", "Jae Shin Yoon", "Alex Schwing", "Liangyan Gui", "Matheus Gadelha", "Paul Guerrero", "Nanxuan Zhao"], "title": "3D-Fixup: Advancing Photo Editing with 3D Priors", "categories": ["cs.CV"], "comment": "SIGGRAPH 2025. Project page: https://3dfixup.github.io/", "summary": "Despite significant advances in modeling image priors via diffusion models,\n3D-aware image editing remains challenging, in part because the object is only\nspecified via a single image. To tackle this challenge, we propose 3D-Fixup, a\nnew framework for editing 2D images guided by learned 3D priors. The framework\nsupports difficult editing situations such as object translation and 3D\nrotation. To achieve this, we leverage a training-based approach that harnesses\nthe generative power of diffusion models. As video data naturally encodes\nreal-world physical dynamics, we turn to video data for generating training\ndata pairs, i.e., a source and a target frame. Rather than relying solely on a\nsingle trained model to infer transformations between source and target frames,\nwe incorporate 3D guidance from an Image-to-3D model, which bridges this\nchallenging task by explicitly projecting 2D information into 3D space. We\ndesign a data generation pipeline to ensure high-quality 3D guidance throughout\ntraining. Results show that by integrating these 3D priors, 3D-Fixup\neffectively supports complex, identity coherent 3D-aware edits, achieving\nhigh-quality results and advancing the application of diffusion models in\nrealistic image manipulation. The code is provided at\nhttps://3dfixup.github.io/"}
{"id": "2505.09935", "pdf": "https://arxiv.org/pdf/2505.09935", "abs": "https://arxiv.org/abs/2505.09935", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Quoc Dai Tran"], "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users."}
{"id": "2505.10297", "pdf": "https://arxiv.org/pdf/2505.10297", "abs": "https://arxiv.org/abs/2505.10297", "authors": ["Chibueze Peace Obioma", "Youcheng Sun", "Mustafa A. Mustafa"], "title": "Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Submitted to ESORICS 2025", "summary": "Federated learning (FL) enhances privacy and reduces communication cost for\nresource-constrained edge clients by supporting distributed model training at\nthe edge. However, the heterogeneous nature of such devices produces diverse,\nnon-independent, and identically distributed (non-IID) data, making the\ndetection of backdoor attacks more challenging. In this paper, we propose a\nnovel federated representative-attention-based defense mechanism, named FeRA,\nthat leverages cross-client attention over internal feature representations to\ndistinguish benign from malicious clients. FeRA computes an anomaly score based\non representation reconstruction errors, effectively identifying clients whose\ninternal activations significantly deviate from the group consensus. Our\nevaluation demonstrates FeRA's robustness across various FL scenarios,\nincluding challenging non-IID data distributions typical of edge devices.\nExperimental results show that it effectively reduces backdoor attack success\nrates while maintaining high accuracy on the main task. The method is\nmodel-agnostic, attack-agnostic, and does not require labeled reference data,\nmaking it well suited to heterogeneous and resource-limited edge deployments."}
{"id": "2505.09630", "pdf": "https://arxiv.org/pdf/2505.09630", "abs": "https://arxiv.org/abs/2505.09630", "authors": ["Tien Comlekoglu", "J. Quetzalcóatl Toledo-Marín", "Douglas W. DeSimone", "Shayn M. Peirce", "Geoffrey Fox", "James A. Glazier"], "title": "Generative diffusion model surrogates for mechanistic agent-based biological models", "categories": ["q-bio.QM", "cs.CV", "cs.ET", "cs.PF"], "comment": null, "summary": "Mechanistic, multicellular, agent-based models are commonly used to\ninvestigate tissue, organ, and organism-scale biology at single-cell\nresolution. The Cellular-Potts Model (CPM) is a powerful and popular framework\nfor developing and interrogating these models. CPMs become computationally\nexpensive at large space- and time- scales making application and investigation\nof developed models difficult. Surrogate models may allow for the accelerated\nevaluation of CPMs of complex biological systems. However, the stochastic\nnature of these models means each set of parameters may give rise to different\nmodel configurations, complicating surrogate model development. In this work,\nwe leverage denoising diffusion probabilistic models to train a generative AI\nsurrogate of a CPM used to investigate \\textit{in vitro} vasculogenesis. We\ndescribe the use of an image classifier to learn the characteristics that\ndefine unique areas of a 2-dimensional parameter space. We then apply this\nclassifier to aid in surrogate model selection and verification. Our CPM model\nsurrogate generates model configurations 20,000 timesteps ahead of a reference\nconfiguration and demonstrates approximately a 22x reduction in computational\ntime as compared to native code execution. Our work represents a step towards\nthe implementation of DDPMs to develop digital twins of stochastic biological\nsystems."}
{"id": "2505.09945", "pdf": "https://arxiv.org/pdf/2505.09945", "abs": "https://arxiv.org/abs/2505.09945", "authors": ["Deeksha Prahlad", "Chanhee Lee", "Dongha Kim", "Hokeun Kim"], "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)", "summary": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time."}
{"id": "2505.10307", "pdf": "https://arxiv.org/pdf/2505.10307", "abs": "https://arxiv.org/abs/2505.10307", "authors": ["Yiyang Zhao", "Chengpei Wu", "Lilin Zhang", "Ning Yang"], "title": "Negative Metric Learning for Graphs", "categories": ["cs.LG"], "comment": null, "summary": "Graph contrastive learning (GCL) often suffers from false negatives, which\ndegrades the performance on downstream tasks. The existing methods addressing\nthe false negative issue usually rely on human prior knowledge, still leading\nGCL to suboptimal results. In this paper, we propose a novel Negative Metric\nLearning (NML) enhanced GCL (NML-GCL). NML-GCL employs a learnable Negative\nMetric Network (NMN) to build a negative metric space, in which false negatives\ncan be distinguished better from true negatives based on their distance to\nanchor node. To overcome the lack of explicit supervision signals for NML, we\npropose a joint training scheme with bi-level optimization objective, which\nimplicitly utilizes the self-supervision signals to iteratively optimize the\nencoder and the negative metric network. The solid theoretical analysis and the\nextensive experiments conducted on widely used benchmarks verify the\nsuperiority of the proposed method."}
{"id": "2505.09819", "pdf": "https://arxiv.org/pdf/2505.09819", "abs": "https://arxiv.org/abs/2505.09819", "authors": ["Ruichen Yang", "György M. Lévay", "Christopher L. Hunt", "Dániel Czeiner", "Megan C. Hodgson", "Damini Agarwal", "Rahul R. Kaliki", "Nitish V. Thakor"], "title": "Visual Feedback of Pattern Separability Improves Myoelectric Decoding Performance of Upper Limb Prostheses", "categories": ["cs.HC", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "State-of-the-art upper limb myoelectric prostheses often use pattern\nrecognition (PR) control systems that translate electromyography (EMG) signals\ninto desired movements. As prosthesis movement complexity increases, users\noften struggle to produce sufficiently distinct EMG patterns for reliable\nclassification. Existing training typically involves heuristic, trial-and-error\nuser adjustments to static decoder boundaries. Goal: We introduce the Reviewer,\na 3D visual interface projecting EMG signals directly into the decoder's\nclassification space, providing intuitive, real-time insight into PR algorithm\nbehavior. This structured feedback reduces cognitive load and fosters mutual,\ndata-driven adaptation between user-generated EMG patterns and decoder\nboundaries. Methods: A 10-session study with 12 able-bodied participants\ncompared PR performance after motor-based training and updating using the\nReviewer versus conventional virtual arm visualization. Performance was\nassessed using a Fitts law task that involved the aperture of the cursor and\nthe control of orientation. Results: Participants trained with the Reviewer\nachieved higher completion rates, reduced overshoot, and improved path\nefficiency and throughput compared to the standard visualization group.\nSignificance: The Reviewer introduces decoder-informed motor training,\nfacilitating immediate and consistent PR-based myoelectric control\nimprovements. By iteratively refining control through real-time feedback, this\napproach reduces reliance on trial-and-error recalibration, enabling a more\nadaptive, self-correcting training framework. Conclusion: The 3D visual\nfeedback significantly improves PR control in novice operators through\nstructured training, enabling feedback-driven adaptation and reducing reliance\non extensive heuristic adjustments."}
{"id": "2505.09952", "pdf": "https://arxiv.org/pdf/2505.09952", "abs": "https://arxiv.org/abs/2505.09952", "authors": ["Tianyu Huai", "Jie Zhou", "Yuxuan Cai", "Qin Chen", "Wen Wu", "Xingjiao Wu", "Xipeng Qiu", "Liang He"], "title": "Task-Core Memory Management and Consolidation for Long-term Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to Neurips2025", "summary": "In this paper, we focus on a long-term continual learning (CL) task, where a\nmodel learns sequentially from a stream of vast tasks over time, acquiring new\nknowledge while retaining previously learned information in a manner akin to\nhuman learning. Unlike traditional CL settings, long-term CL involves handling\na significantly larger number of tasks, which exacerbates the issue of\ncatastrophic forgetting. Our work seeks to address two critical questions: 1)\nHow do existing CL methods perform in the context of long-term CL? and 2) How\ncan we mitigate the catastrophic forgetting that arises from prolonged\nsequential updates? To tackle these challenges, we propose a novel framework\ninspired by human memory mechanisms for long-term continual learning (Long-CL).\nSpecifically, we introduce a task-core memory management strategy to\nefficiently index crucial memories and adaptively update them as learning\nprogresses. Additionally, we develop a long-term memory consolidation mechanism\nthat selectively retains hard and discriminative samples, ensuring robust\nknowledge retention. To facilitate research in this area, we construct and\nrelease two multi-modal and textual benchmarks, MMLongCL-Bench and\nTextLongCL-Bench, providing a valuable resource for evaluating long-term CL\napproaches. Experimental results show that Long-CL outperforms the previous\nstate-of-the-art by 7.4\\% and 6.5\\% AP on the two benchmarks, respectively,\ndemonstrating the effectiveness of our approach."}
{"id": "2505.10322", "pdf": "https://arxiv.org/pdf/2505.10322", "abs": "https://arxiv.org/abs/2505.10322", "authors": ["Yijie Zhou", "Shi Pu"], "title": "Asynchronous Decentralized SGD under Non-Convexity: A Block-Coordinate Descent Framework", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Decentralized optimization has become vital for leveraging distributed data\nwithout central control, enhancing scalability and privacy. However, practical\ndeployments face fundamental challenges due to heterogeneous computation speeds\nand unpredictable communication delays. This paper introduces a refined model\nof Asynchronous Decentralized Stochastic Gradient Descent (ADSGD) under\npractical assumptions of bounded computation and communication times. To\nunderstand the convergence of ADSGD, we first analyze Asynchronous Stochastic\nBlock Coordinate Descent (ASBCD) as a tool, and then show that ADSGD converges\nunder computation-delay-independent step sizes. The convergence result is\nestablished without assuming bounded data heterogeneity. Empirical experiments\nreveal that ADSGD outperforms existing methods in wall-clock convergence time\nacross various scenarios. With its simplicity, efficiency in memory and\ncommunication, and resilience to communication and computation delays, ADSGD is\nwell-suited for real-world decentralized learning tasks."}
{"id": "2505.09831", "pdf": "https://arxiv.org/pdf/2505.09831", "abs": "https://arxiv.org/abs/2505.09831", "authors": ["Tushar Kataria", "Beatrice Knudsen", "Shireen Y. Elhabian"], "title": "ImplicitStainer: Data-Efficient Medical Image Translation for Virtual Antibody-based Tissue Staining Using Local Implicit Functions", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Hematoxylin and eosin (H&E) staining is a gold standard for microscopic\ndiagnosis in pathology. However, H&E staining does not capture all the\ndiagnostic information that may be needed. To obtain additional molecular\ninformation, immunohistochemical (IHC) stains highlight proteins that mark\nspecific cell types, such as CD3 for T-cells or CK8/18 for epithelial cells.\nWhile IHC stains are vital for prognosis and treatment guidance, they are\ntypically only available at specialized centers and time consuming to acquire,\nleading to treatment delays for patients. Virtual staining, enabled by deep\nlearning-based image translation models, provides a promising alternative by\ncomputationally generating IHC stains from H&E stained images. Although many\nGAN and diffusion based image to image (I2I) translation methods have been used\nfor virtual staining, these models treat image patches as independent data\npoints, which results in increased and more diverse data requirements for\neffective generation. We present ImplicitStainer, a novel approach that\nleverages local implicit functions to improve image translation, specifically\nvirtual staining performance, by focusing on pixel-level predictions. This\nmethod enhances robustness to variations in dataset sizes, delivering\nhigh-quality results even with limited data. We validate our approach on two\ndatasets using a comprehensive set of metrics and benchmark it against over\nfifteen state-of-the-art GAN- and diffusion based models. Full Code and models\ntrained will be released publicly via Github upon acceptance."}
{"id": "2505.09955", "pdf": "https://arxiv.org/pdf/2505.09955", "abs": "https://arxiv.org/abs/2505.09955", "authors": ["Jaeho Kim", "Seulki Lee"], "title": "TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 Accept", "summary": "Unsupervised domain adaptation (UDA) for time series data remains a critical\nchallenge in deep learning, with traditional pseudo-labeling strategies failing\nto capture temporal patterns and channel-wise shifts between domains, producing\nsub-optimal pseudo-labels. As such, we introduce TransPL, a novel approach that\naddresses these limitations by modeling the joint distribution $P(\\mathbf{X},\ny)$ of the source domain through code transition matrices, where the codes are\nderived from vector quantization (VQ) of time series patches. Our method\nconstructs class- and channel-wise code transition matrices from the source\ndomain and employs Bayes' rule for target domain adaptation, generating\npseudo-labels based on channel-wise weighted class-conditional likelihoods.\nTransPL offers three key advantages: explicit modeling of temporal transitions\nand channel-wise shifts between different domains, versatility towards\ndifferent UDA scenarios (e.g., weakly-supervised UDA), and explainable\npseudo-label generation. We validate TransPL's effectiveness through extensive\nanalysis on four time series UDA benchmarks and confirm that it consistently\noutperforms state-of-the-art pseudo-labeling methods by a strong margin (6.1%\naccuracy improvement, 4.9% F1 improvement), while providing interpretable\ninsights into the domain adaptation process through its learned code transition\nmatrices."}
{"id": "2505.10325", "pdf": "https://arxiv.org/pdf/2505.10325", "abs": "https://arxiv.org/abs/2505.10325", "authors": ["Athanasios Tziouvaras", "Blaz Bertalanic", "George Floros", "Kostas Kolomvatsos", "Panagiotis Sarigiannidis", "Carolina Fortuna"], "title": "A Representation Learning Approach to Feature Drift Detection in Wireless Networks", "categories": ["cs.LG"], "comment": null, "summary": "AI is foreseen to be a centerpiece in next generation wireless networks\nenabling enabling ubiquitous communication as well as new services. However, in\nreal deployment, feature distribution changes may degrade the performance of AI\nmodels and lead to undesired behaviors. To counter for undetected model\ndegradation, we propose ALERT; a method that can detect feature distribution\nchanges and trigger model re-training that works well on two wireless network\nuse cases: wireless fingerprinting and link anomaly detection. ALERT includes\nthree components: representation learning, statistical testing and utility\nassessment. We rely on MLP for designing the representation learning component,\non Kolmogorov-Smirnov and Population Stability Index tests for designing the\nstatistical testing and a new function for utility assessment. We show the\nsuperiority of the proposed method against ten standard drift detection methods\navailable in the literature on two wireless network use cases."}
{"id": "2505.09985", "pdf": "https://arxiv.org/pdf/2505.09985", "abs": "https://arxiv.org/abs/2505.09985", "authors": ["Pengfei Yu", "Bin Huang", "Minghui Zhang", "Weiwen Wu", "Shaoyu Wang", "Qiegen Liu"], "title": "Ordered-subsets Multi-diffusion Model for Sparse-view CT Reconstruction", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Score-based diffusion models have shown significant promise in the field of\nsparse-view CT reconstruction. However, the projection dataset is large and\nriddled with redundancy. Consequently, applying the diffusion model to\nunprocessed data results in lower learning effectiveness and higher learning\ndifficulty, frequently leading to reconstructed images that lack fine details.\nTo address these issues, we propose the ordered-subsets multi-diffusion model\n(OSMM) for sparse-view CT reconstruction. The OSMM innovatively divides the CT\nprojection data into equal subsets and employs multi-subsets diffusion model\n(MSDM) to learn from each subset independently. This targeted learning approach\nreduces complexity and enhances the reconstruction of fine details.\nFurthermore, the integration of one-whole diffusion model (OWDM) with complete\nsinogram data acts as a global information constraint, which can reduce the\npossibility of generating erroneous or inconsistent sinogram information.\nMoreover, the OSMM's unsupervised learning framework provides strong robustness\nand generalizability, adapting seamlessly to varying sparsity levels of CT\nsinograms. This ensures consistent and reliable performance across different\nclinical scenarios. Experimental results demonstrate that OSMM outperforms\ntraditional diffusion models in terms of image quality and noise resilience,\noffering a powerful and versatile solution for advanced CT imaging in\nsparse-view scenarios."}
{"id": "2505.09969", "pdf": "https://arxiv.org/pdf/2505.09969", "abs": "https://arxiv.org/abs/2505.09969", "authors": ["Ali Azimi Lamir", "Shiva Razzagzadeh", "Zeynab Rezaei"], "title": "A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study presents a machine learning-based framework for heart disease\nprediction using the heart-disease dataset, comprising 303 samples with 14\nfeatures. The methodology involves data preprocessing, model training, and\nevaluation using three classifiers: Logistic Regression, K-Nearest Neighbors\n(KNN), and Random Forest. Hyperparameter tuning with GridSearchCV and\nRandomizedSearchCV was employed to enhance model performance. The Random Forest\nclassifier outperformed other models, achieving an accuracy of 91% and an\nF1-score of 0.89. Evaluation metrics, including precision, recall, and\nconfusion matrix, revealed balanced performance across classes. The proposed\nmodel demonstrates strong potential for aiding clinical decision-making by\neffectively predicting heart disease. Limitations such as dataset size and\ngeneralizability underscore the need for future studies using larger and more\ndiverse datasets. This work highlights the utility of machine learning in\nhealthcare, offering insights for further advancements in predictive\ndiagnostics."}
{"id": "2505.10330", "pdf": "https://arxiv.org/pdf/2505.10330", "abs": "https://arxiv.org/abs/2505.10330", "authors": ["Jonathan Clifford Balloch"], "title": "Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change", "categories": ["cs.LG", "cs.AI"], "comment": "PhD Dissertation, 131 pages", "summary": "Real-world autonomous decision-making systems, from robots to recommendation\nengines, must operate in environments that change over time. While deep\nreinforcement learning (RL) has shown an impressive ability to learn optimal\npolicies in stationary environments, most methods are data intensive and assume\na world that does not change between training and test time. As a result,\nconventional RL methods struggle to adapt when conditions change. This poses a\nfundamental challenge: how can RL agents efficiently adapt their behavior when\nencountering novel environmental changes during deployment without\ncatastrophically forgetting useful prior knowledge? This dissertation\ndemonstrates that efficient online adaptation requires two key capabilities:\n(1) prioritized exploration and sampling strategies that help identify and\nlearn from relevant experiences, and (2) selective preservation of prior\nknowledge through structured representations that can be updated without\ndisruption to reusable components."}
{"id": "2505.10075", "pdf": "https://arxiv.org/pdf/2505.10075", "abs": "https://arxiv.org/abs/2505.10075", "authors": ["Jun Guo", "Xiaojian Ma", "Yikai Wang", "Min Yang", "Huaping Liu", "Qing Li"], "title": "FlowDreamer: A RGB-D World Model with Flow-based Motion Representations for Robot Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": "Project page: see https://sharinka0715.github.io/FlowDreamer/", "summary": "This paper investigates training better visual world models for robot\nmanipulation, i.e., models that can predict future visual observations by\nconditioning on past frames and robot actions. Specifically, we consider world\nmodels that operate on RGB-D frames (RGB-D world models). As opposed to\ncanonical approaches that handle dynamics prediction mostly implicitly and\nreconcile it with visual rendering in a single model, we introduce FlowDreamer,\nwhich adopts 3D scene flow as explicit motion representations. FlowDreamer\nfirst predicts 3D scene flow from past frame and action conditions with a\nU-Net, and then a diffusion model will predict the future frame utilizing the\nscene flow. FlowDreamer is trained end-to-end despite its modularized nature.\nWe conduct experiments on 4 different benchmarks, covering both video\nprediction and visual planning tasks. The results demonstrate that FlowDreamer\nachieves better performance compared to other baseline RGB-D world models by 7%\non semantic similarity, 11% on pixel quality, and 6% on success rate in various\nrobot manipulation domains."}
{"id": "2505.09974", "pdf": "https://arxiv.org/pdf/2505.09974", "abs": "https://arxiv.org/abs/2505.09974", "authors": ["Adel ElZemity", "Budi Arief", "Shujun Li"], "title": "Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The integration of large language models (LLMs) into cyber security\napplications presents significant opportunities, such as enhancing threat\nanalysis and malware detection, but can also introduce critical risks and\nsafety concerns, including personal data leakage and automated generation of\nnew malware. We present a systematic evaluation of safety risks in fine-tuned\nLLMs for cyber security applications. Using the OWASP Top 10 for LLM\nApplications framework, we assessed seven open-source LLMs: Phi 3 Mini 3.8B,\nMistral 7B, Qwen 2.5 7B, Llama 3 8B, Llama 3.1 8B, Gemma 2 9B, and Llama 2 70B.\nOur evaluation shows that fine-tuning reduces safety resilience across all\ntested LLMs (e.g., the safety score of Llama 3.1 8B against prompt injection\ndrops from 0.95 to 0.15). We propose and evaluate a safety alignment approach\nthat carefully rewords instruction-response pairs to include explicit safety\nprecautions and ethical considerations. This approach demonstrates that it is\npossible to maintain or even improve model safety while preserving technical\nutility, offering a practical path forward for developing safer fine-tuning\nmethodologies. This work offers a systematic evaluation for safety risks in\nLLMs, enabling safer adoption of generative AI in sensitive domains, and\ncontributing towards the development of secure, trustworthy, and ethically\naligned LLMs."}
{"id": "2505.10331", "pdf": "https://arxiv.org/pdf/2505.10331", "abs": "https://arxiv.org/abs/2505.10331", "authors": ["Luca Muscarnera", "Luigi Loreti", "Giovanni Todeschini", "Alessio Fumagalli", "Francesco Regazzoni"], "title": "Emergence of Structure in Ensembles of Random Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Randomness is ubiquitous in many applications across data science and machine\nlearning. Remarkably, systems composed of random components often display\nemergent global behaviors that appear deterministic, manifesting a transition\nfrom microscopic disorder to macroscopic organization. In this work, we\nintroduce a theoretical model for studying the emergence of collective\nbehaviors in ensembles of random classifiers. We argue that, if the ensemble is\nweighted through the Gibbs measure defined by adopting the classification loss\nas an energy, then there exists a finite temperature parameter for the\ndistribution such that the classification is optimal, with respect to the loss\n(or the energy). Interestingly, for the case in which samples are generated by\na Gaussian distribution and labels are constructed by employing a teacher\nperceptron, we analytically prove and numerically confirm that such optimal\ntemperature does not depend neither on the teacher classifier (which is, by\nconstruction of the learning problem, unknown), nor on the number of random\nclassifiers, highlighting the universal nature of the observed behavior.\nExperiments on the MNIST dataset underline the relevance of this phenomenon in\nhigh-quality, noiseless, datasets. Finally, a physical analogy allows us to\nshed light on the self-organizing nature of the studied phenomenon."}
{"id": "2505.10144", "pdf": "https://arxiv.org/pdf/2505.10144", "abs": "https://arxiv.org/abs/2505.10144", "authors": ["Xuechang Tu", "Lukas Radl", "Michael Steiner", "Markus Steinberger", "Bernhard Kerbl", "Fernando de la Torre"], "title": "VRSplat: Fast and Robust Gaussian Splatting for Virtual Reality", "categories": ["cs.GR", "cs.CV"], "comment": "I3D'25 (PACMCGIT); Project Page: https://cekavis.site/VRSplat/", "summary": "3D Gaussian Splatting (3DGS) has rapidly become a leading technique for\nnovel-view synthesis, providing exceptional performance through efficient\nsoftware-based GPU rasterization. Its versatility enables real-time\napplications, including on mobile and lower-powered devices. However, 3DGS\nfaces key challenges in virtual reality (VR): (1) temporal artifacts, such as\npopping during head movements, (2) projection-based distortions that result in\ndisturbing and view-inconsistent floaters, and (3) reduced framerates when\nrendering large numbers of Gaussians, falling below the critical threshold for\nVR. Compared to desktop environments, these issues are drastically amplified by\nlarge field-of-view, constant head movements, and high resolution of\nhead-mounted displays (HMDs). In this work, we introduce VRSplat: we combine\nand extend several recent advancements in 3DGS to address challenges of VR\nholistically. We show how the ideas of Mini-Splatting, StopThePop, and Optimal\nProjection can complement each other, by modifying the individual techniques\nand core 3DGS rasterizer. Additionally, we propose an efficient foveated\nrasterizer that handles focus and peripheral areas in a single GPU launch,\navoiding redundant computations and improving GPU utilization. Our method also\nincorporates a fine-tuning step that optimizes Gaussian parameters based on\nStopThePop depth evaluations and Optimal Projection. We validate our method\nthrough a controlled user study with 25 participants, showing a strong\npreference for VRSplat over other configurations of Mini-Splatting. VRSplat is\nthe first, systematically evaluated 3DGS approach capable of supporting modern\nVR applications, achieving 72+ FPS while eliminating popping and\nstereo-disrupting floaters."}
{"id": "2505.09989", "pdf": "https://arxiv.org/pdf/2505.09989", "abs": "https://arxiv.org/abs/2505.09989", "authors": ["Tella Rajashekhar Reddy", "Palak", "Rohan Gandhi", "Anjaly Parayil", "Chaojie Zhang", "Mike Shepperd", "Liangcheng Yu", "Jayashree Mohan", "Srinivasan Iyengar", "Shivkumar Kalyanaraman", "Debopam Bhattacherjee"], "title": "AI Greenferencing: Routing AI Inferencing to Green Modular Data Centers with Heron", "categories": ["cs.DC", "cs.AI", "cs.NI"], "comment": null, "summary": "AI power demand is growing unprecedentedly thanks to the high power density\nof AI compute and the emerging inferencing workload. On the supply side,\nabundant wind power is waiting for grid access in interconnection queues. In\nthis light, this paper argues bringing AI workload to modular compute clusters\nco-located in wind farms. Our deployment right-sizing strategy makes it\neconomically viable to deploy more than 6 million high-end GPUs today that\ncould consume cheap, green power at its source. We built Heron, a cross-site\nsoftware router, that could efficiently leverage the complementarity of power\ngeneration across wind farms by routing AI inferencing workload around power\ndrops. Using 1-week ofcoding and conversation production traces from Azure and\n(real) variable wind power traces, we show how Heron improves aggregate goodput\nof AI compute by up to 80% compared to the state-of-the-art."}
{"id": "2505.10344", "pdf": "https://arxiv.org/pdf/2505.10344", "abs": "https://arxiv.org/abs/2505.10344", "authors": ["Alan Jeffares", "Liyuan Liu"], "title": "An Introduction to Discrete Variational Autoencoders", "categories": ["cs.LG"], "comment": "Tutorial paper", "summary": "Variational Autoencoders (VAEs) are well-established as a principled approach\nto probabilistic unsupervised learning with neural networks. Typically, an\nencoder network defines the parameters of a Gaussian distributed latent space\nfrom which we can sample and pass realizations to a decoder network. This model\nis trained to reconstruct its inputs and is optimized through the evidence\nlower bound. In recent years, discrete latent spaces have grown in popularity,\nsuggesting that they may be a natural choice for many data modalities (e.g.\ntext). In this tutorial, we provide a rigorous, yet practical, introduction to\ndiscrete variational autoencoders -- specifically, VAEs in which the latent\nspace is made up of latent variables that follow a categorical distribution. We\nassume only a basic mathematical background with which we carefully derive each\nstep from first principles. From there, we develop a concrete training recipe\nand provide an example implementation, hosted at\nhttps://github.com/alanjeffares/discreteVAE."}
{"id": "2505.10271", "pdf": "https://arxiv.org/pdf/2505.10271", "abs": "https://arxiv.org/abs/2505.10271", "authors": ["Rafael Pablos Sarabia", "Joachim Nyborg", "Morten Birk", "Jeppe Liborius Sjørup", "Anders Lillevang Vesterholt", "Ira Assent"], "title": "RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We present a deep learning model for high-resolution probabilistic\nprecipitation forecasting over an 8-hour horizon in Europe, overcoming the\nlimitations of radar-only deep learning models with short forecast lead times.\nOur model efficiently integrates multiple data sources - including radar,\nsatellite, and physics-based numerical weather prediction (NWP) - while\ncapturing long-range interactions, resulting in accurate forecasts with robust\nuncertainty quantification through consistent probabilistic maps. Featuring a\ncompact architecture, it enables more efficient training and faster inference\nthan existing models. Extensive experiments demonstrate that our model\nsurpasses current operational NWP systems, extrapolation-based methods, and\ndeep-learning nowcasting models, setting a new standard for high-resolution\nprecipitation forecasting in Europe, ensuring a balance between accuracy,\ninterpretability, and computational efficiency."}
{"id": "2505.10012", "pdf": "https://arxiv.org/pdf/2505.10012", "abs": "https://arxiv.org/abs/2505.10012", "authors": ["Tadashi Kadowaki"], "title": "Quantum Computing and AI: Perspectives on Advanced Automation in Science and Engineering", "categories": ["quant-ph", "cs.AI"], "comment": "8 pages, 4 figures", "summary": "Recent advances in artificial intelligence (AI) and quantum computing are\naccelerating automation in scientific and engineering processes, fundamentally\nreshaping research methodologies. This perspective highlights parallels between\nscientific automation and established Computer-Aided Engineering (CAE)\npractices, introducing Quantum CAE as a framework that leverages quantum\nalgorithms for simulation, optimization, and machine learning within\nengineering design. Practical implementations of Quantum CAE are illustrated\nthrough case studies for combinatorial optimization problems. Further\ndiscussions include advancements toward higher automation levels, highlighting\nthe critical role of specialized AI agents proficient in quantum algorithm\ndesign. The integration of quantum computing with AI raises significant\nquestions about the collaborative dynamics among human scientists and\nengineers, AI systems, and quantum computational resources, underscoring a\ntransformative future for automated discovery and innovation."}
{"id": "2505.10347", "pdf": "https://arxiv.org/pdf/2505.10347", "abs": "https://arxiv.org/abs/2505.10347", "authors": ["Gabriel S. Gama", "Valdir Grassi Jr"], "title": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task\nLearning by addressing issues like conflicting gradients and differing gradient\nnorms, which hinder equal-weighted task training. However, recent critiques\nsuggest that equally weighted tasks can achieve competitive results compared to\nSMTOs, arguing that previous SMTO results were influenced by poor\nhyperparameter optimization and lack of regularization. In this work, we\nevaluate these claims through an extensive empirical evaluation of SMTOs,\nincluding some of the latest methods, on more complex multi-task problems to\nclarify this behavior. Our findings indicate that SMTOs perform well compared\nto uniform loss and that fixed weights can achieve competitive performance\ncompared to SMTOs. Furthermore, we demonstrate why uniform loss perform\nsimilarly to SMTOs in some instances. The code will be made publicly available."}
{"id": "2505.10312", "pdf": "https://arxiv.org/pdf/2505.10312", "abs": "https://arxiv.org/abs/2505.10312", "authors": ["Anh Tuan Ha", "Hoang Khang Phan", "Thai Minh Tien Ngo", "Anh Phan Truong", "Nhat Tan Le"], "title": "SOS: A Shuffle Order Strategy for Data Augmentation in Industrial Human Activity Recognition", "categories": ["cs.HC", "cs.CV"], "comment": null, "summary": "In the realm of Human Activity Recognition (HAR), obtaining high quality and\nvariance data is still a persistent challenge due to high costs and the\ninherent variability of real-world activities. This study introduces a\ngeneration dataset by deep learning approaches (Attention Autoencoder and\nconditional Generative Adversarial Networks). Another problem that data\nheterogeneity is a critical challenge, one of the solutions is to shuffle the\ndata to homogenize the distribution. Experimental results demonstrate that the\nrandom sequence strategy significantly improves classification performance,\nachieving an accuracy of up to 0.70 $\\pm$ 0.03 and a macro F1 score of 0.64\n$\\pm$ 0.01. For that, disrupting temporal dependencies through random sequence\nreordering compels the model to focus on instantaneous recognition, thereby\nimproving robustness against activity transitions. This approach not only\nbroadens the effective training dataset but also offers promising avenues for\nenhancing HAR systems in complex, real-world scenarios."}
{"id": "2505.10016", "pdf": "https://arxiv.org/pdf/2505.10016", "abs": "https://arxiv.org/abs/2505.10016", "authors": ["Shijie Lyu"], "title": "Application of YOLOv8 in monocular downward multiple Car Target detection", "categories": ["cs.CV", "cs.AI", "I.4.8; I.2.10"], "comment": "Accepted by the 5th International Conference on Signal Processing and\n  Machine Learning (CONF-SPML 2025), to appear in Applied and Computational\n  Engineering", "summary": "Autonomous driving technology is progressively transforming traditional car\ndriving methods, marking a significant milestone in modern transportation.\nObject detection serves as a cornerstone of autonomous systems, playing a vital\nrole in enhancing driving safety, enabling autonomous functionality, improving\ntraffic efficiency, and facilitating effective emergency responses. However,\ncurrent technologies such as radar for environmental perception, cameras for\nroad perception, and vehicle sensor networks face notable challenges, including\nhigh costs, vulnerability to weather and lighting conditions, and limited\nresolution.To address these limitations, this paper presents an improved\nautonomous target detection network based on YOLOv8. By integrating structural\nreparameterization technology, a bidirectional pyramid structure network model,\nand a novel detection pipeline into the YOLOv8 framework, the proposed approach\nachieves highly efficient and precise detection of multi-scale, small, and\nremote objects. Experimental results demonstrate that the enhanced model can\neffectively detect both large and small objects with a detection accuracy of\n65%, showcasing significant advancements over traditional methods.This improved\nmodel holds substantial potential for real-world applications and is\nwell-suited for autonomous driving competitions, such as the Formula Student\nAutonomous China (FSAC), particularly excelling in scenarios involving\nsingle-target and small-object detection."}
{"id": "2505.10360", "pdf": "https://arxiv.org/pdf/2505.10360", "abs": "https://arxiv.org/abs/2505.10360", "authors": ["Victor Petrén Bach Hansen", "Lasse Krogsbøll", "Jonas Lyngsø", "Mathias Baltzersen", "Andreas Motzfeldt", "Kevin Pelgrims", "Lars Maaløe"], "title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": null, "summary": "There are now a multitude of AI-scribing solutions for healthcare promising\nthe utilization of large language models for ambient documentation. However,\nthese AI scribes still rely on one-shot, or few-shot prompts for generating\nnotes after the consultation has ended, employing little to no reasoning. This\nrisks long notes with an increase in hallucinations, misrepresentation of the\nintent of the clinician, and reliance on the proofreading of the clinician to\ncatch errors. A dangerous combination for patient safety if vigilance is\ncompromised by workload and fatigue. In this paper, we introduce a method for\nextracting salient clinical information in real-time alongside the healthcare\nconsultation, denoted Facts, and use that information recursively to generate\nthe final note. The FactsR method results in more accurate and concise notes by\nplacing the clinician-in-the-loop of note generation, while opening up new use\ncases within real-time decision support."}
{"id": "2505.10405", "pdf": "https://arxiv.org/pdf/2505.10405", "abs": "https://arxiv.org/abs/2505.10405", "authors": ["Jianhao Huang", "Qunsong Zeng", "Kaibin Huang"], "title": "Visual Fidelity Index for Generative Semantic Communications with Critical Information Embedding", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Generative semantic communication (Gen-SemCom) with large artificial\nintelligence (AI) model promises a transformative paradigm for 6G networks,\nwhich reduces communication costs by transmitting low-dimensional prompts\nrather than raw data. However, purely prompt-driven generation loses\nfine-grained visual details. Additionally, there is a lack of systematic\nmetrics to evaluate the performance of Gen-SemCom systems. To address these\nissues, we develop a hybrid Gen-SemCom system with a critical information\nembedding (CIE) framework, where both text prompts and semantically critical\nfeatures are extracted for transmissions. First, a novel approach of semantic\nfiltering is proposed to select and transmit the semantically critical features\nof images relevant to semantic label. By integrating the text prompt and\ncritical features, the receiver reconstructs high-fidelity images using a\ndiffusion-based generative model. Next, we propose the generative visual\ninformation fidelity (GVIF) metric to evaluate the visual quality of the\ngenerated image. By characterizing the statistical models of image features,\nthe GVIF metric quantifies the mutual information between the distorted\nfeatures and their original counterparts. By maximizing the GVIF metric, we\ndesign a channel-adaptive Gen-SemCom system that adaptively control the volume\nof features and compression rate according to the channel state. Experimental\nresults validate the GVIF metric's sensitivity to visual fidelity, correlating\nwith both the PSNR and critical information volume. In addition, the optimized\nsystem achieves superior performance over benchmarking schemes in terms of\nhigher PSNR and lower FID scores."}
{"id": "2505.10027", "pdf": "https://arxiv.org/pdf/2505.10027", "abs": "https://arxiv.org/abs/2505.10027", "authors": ["Shijie Lyu"], "title": "ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by the 4th International Conference on Computing Innovation\n  and Applied Physics (CONF-CIAP 2025), and will be published in EAI Community\n  Research Series-CORE or Theoretical and Natural Science (TNS)", "summary": "With the rapid advancement of remote sensing technology, super-resolution\nimage reconstruction is of great research and practical significance. Existing\ndeep learning methods have made progress but still face limitations in handling\ncomplex scenes and preserving image details. This paper proposes a\nreinforcement learning-based latent diffusion model (LDM) fine-tuning method\nfor remote sensing image super-resolution. The method constructs a\nreinforcement learning environment with states, actions, and rewards,\noptimizing decision objectives through proximal policy optimization (PPO)\nduring the reverse denoising process of the LDM model. Experiments on the\nRESISC45 dataset show significant improvements over the baseline model in PSNR,\nSSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11,\nand LPIPS reducing by 0.06-0.10, particularly in structured and complex natural\nscenes. The results demonstrate the method's effectiveness in enhancing\nsuper-resolution quality and adaptability across scenes."}
{"id": "2505.10392", "pdf": "https://arxiv.org/pdf/2505.10392", "abs": "https://arxiv.org/abs/2505.10392", "authors": ["Aryan Mishra", "Lizhen Lin"], "title": "Schreier-Coset Graph Propagation", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 1 figure , preprint", "summary": "Graph Neural Networks (GNNs) offer a principled framework for learning over\ngraph-structured data, yet their expressive capacity is often hindered by\nover-squashing, wherein information from distant nodes is compressed into\nfixed-size vectors. Existing solutions, including graph rewiring and\nbottleneck-resistant architectures such as Cayley and expander graphs, avoid\nthis problem but introduce scalability bottlenecks. In particular, the Cayley\ngraphs constructed over $SL(2,\\mathbb{Z}_n)$ exhibit strong theoretical\nproperties, yet suffer from cubic node growth $O(n^3)$, leading to high memory\nusage. To address this, this work introduces Schrier-Coset Graph Propagation\n(SCGP), a group-theoretic augmentation method that enriches node features\nthrough Schreier-coset embeddings without altering the input graph topology.\nSCGP embeds bottleneck-free connectivity patterns into a compact feature space,\nimproving long-range message passing while maintaining computational\nefficiency. Empirical evaluations across standard node and graph classification\nbenchmarks demonstrate that SCGP achieves performance comparable to, or\nexceeding, expander graph and rewired GNN baselines. Furthermore, SCGP exhibits\nparticular advantages in processing hierarchical and modular graph structures,\noffering reduced inference latency, improved scalability, and a low memory\nfootprint, making it suitable for real-time and resource-constrained\napplications."}
{"id": "2505.10441", "pdf": "https://arxiv.org/pdf/2505.10441", "abs": "https://arxiv.org/abs/2505.10441", "authors": ["Filippo Leveni", "Luca Magri", "Giacomo Boracchi", "Cesare Alippi"], "title": "PIF: Anomaly detection via preference embedding", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)", "summary": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space."}
{"id": "2505.10037", "pdf": "https://arxiv.org/pdf/2505.10037", "abs": "https://arxiv.org/abs/2505.10037", "authors": ["Takafumi Ito", "Lysenko Artem", "Tatsuhiko Tsunoda"], "title": "Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction", "categories": ["cs.LG", "cs.AI", "cs.ET", "quant-ph"], "comment": "10 pages, 3 figures", "summary": "Quantum-classical Hybrid Machine Learning (QHML) models are recognized for\ntheir robust performance and high generalization ability even for relatively\nsmall datasets. These qualities offer unique advantages for anti-cancer drug\nresponse prediction, where the number of available samples is typically small.\nHowever, such hybrid models appear to be very sensitive to the data encoding\nused at the interface of a neural network and a quantum circuit, with\nsuboptimal choices leading to stability issues. To address this problem, we\npropose a novel strategy that uses a normalization function based on a\nmoderated gradient version of the $\\tanh$. This method transforms the outputs\nof the neural networks without concentrating them at the extreme value ranges.\nOur idea was evaluated on a dataset of gene expression and drug response\nmeasurements for various cancer cell lines, where we compared the prediction\nperformance of a classical deep learning model and several QHML models. These\nresults confirmed that QHML performed better than the classical models when\ndata was optimally normalized. This study opens up new possibilities for\nbiomedical data analysis using quantum computers."}
{"id": "2505.10407", "pdf": "https://arxiv.org/pdf/2505.10407", "abs": "https://arxiv.org/abs/2505.10407", "authors": ["Wenhao Ding", "Choon Hwai Yap", "Kangjun Ji", "Simão Castro"], "title": "Two-Stage Generative Model for Intracranial Aneurysm Meshes with Morphological Marker Conditioning", "categories": ["cs.LG", "68T07"], "comment": "10 pages, 2 figures", "summary": "A generative model for the mesh geometry of intracranial aneurysms (IA) is\ncrucial for training networks to predict blood flow forces in real time, which\nis a key factor affecting disease progression. This need is necessitated by the\nabsence of a large IA image datasets. Existing shape generation methods\nstruggle to capture realistic IA features and ignore the relationship between\nIA pouches and parent vessels, limiting physiological realism and their\ngeneration cannot be controlled to have specific morphological measurements. We\npropose AneuG, a two-stage Variational Autoencoder (VAE)-based IA mesh\ngenerator. In the first stage, AneuG generates low-dimensional Graph Harmonic\nDeformation (GHD) tokens to encode and reconstruct aneurysm pouch shapes,\nconstrained to morphing energy statistics truths. GHD enables more accurate\nshape encoding than alternatives. In the second stage, AneuG generates parent\nvessels conditioned on GHD tokens, by generating vascular centreline and\npropagating the cross-section. AneuG's IA shape generation can further be\nconditioned to have specific clinically relevant morphological measurements.\nThis is useful for studies to understand shape variations represented by\nclinical measurements, and for flow simulation studies to understand effects of\nspecific clinical shape parameters on fluid dynamics. Source code and\nimplementation details are available at\nhttps://github.com/anonymousaneug/AneuG."}
{"id": "2505.10457", "pdf": "https://arxiv.org/pdf/2505.10457", "abs": "https://arxiv.org/abs/2505.10457", "authors": ["Matteo Gambella", "Vicente Javier Castro Solar", "Manuel Roveri"], "title": "SEAL: Searching Expandable Architectures for Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "comment": "8 pages, 5 figures", "summary": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios."}
{"id": "2505.10043", "pdf": "https://arxiv.org/pdf/2505.10043", "abs": "https://arxiv.org/abs/2505.10043", "authors": ["Yifan Wu", "Lutao Yan", "Yizhang Zhu", "Yinan Mei", "Jiannan Wang", "Nan Tang", "Yuyu Luo"], "title": "Boosting Text-to-Chart Retrieval through Training with Synthesized Semantic Insights", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Charts are crucial for data analysis and decision-making.Text-to-chart\nretrieval systems have become increasingly important for Business Intelligence\n(BI), where users need to find relevant charts that match their analytical\nneeds. These needs can be categorized into precise queries that are\nwell-specified and fuzzy queries that are more exploratory -- both require\nunderstanding the semantics and context of the charts. However, existing\ntext-to-chart retrieval solutions often fail to capture the semantic content\nand contextual information of charts, primarily due to the lack of\ncomprehensive metadata (or semantic insights). To address this limitation, we\npropose a training data development pipeline that automatically synthesizes\nhierarchical semantic insights for charts, covering visual patterns\n(visual-oriented), statistical properties (statistics-oriented), and practical\napplications (task-oriented), which produces 207,498 semantic insights for\n69,166 charts. Based on these, we train a CLIP-based model named ChartFinder to\nlearn better representations of charts for text-to-chart retrieval. Our method\nleverages rich semantic insights during the training phase to develop a model\nthat understands both visual and semantic aspects of charts.To evaluate\ntext-to-chart retrieval performance, we curate the first benchmark, CRBench,\nfor this task with 21,862 charts and 326 text queries from real-world BI\napplications, with ground-truth labels verified by the crowd\nworkers.Experiments show that ChartFinder significantly outperforms existing\nmethods in text-to-chart retrieval tasks across various settings. For precise\nqueries, ChartFinder achieves up to 66.9% NDCG@10, which is 11.58% higher than\nstate-of-the-art models. In fuzzy query tasks, our method also demonstrates\nconsistent improvements, with an average increase of 5% across nearly all\nmetrics."}
{"id": "2505.10422", "pdf": "https://arxiv.org/pdf/2505.10422", "abs": "https://arxiv.org/abs/2505.10422", "authors": ["Daniel Weitekamp", "Christopher MacLellan", "Erik Harpstead", "Kenneth Koedinger"], "title": "Decomposed Inductive Procedure Learning: Learning Academic Tasks with Human-Like Data Efficiency", "categories": ["cs.LG"], "comment": "To appear in CogSci 2025", "summary": "Human learning relies on specialization -- distinct cognitive mechanisms\nworking together to enable rapid learning. In contrast, most modern neural\nnetworks rely on a single mechanism: gradient descent over an objective\nfunction. This raises the question: might human learners' relatively rapid\nlearning from just tens of examples instead of tens of thousands in data-driven\ndeep learning arise from our ability to use multiple specialized mechanisms of\nlearning in combination? We investigate this question through an ablation\nanalysis of inductive human learning simulations in online tutoring\nenvironments. Comparing reinforcement learning to a more data-efficient\n3-mechanism symbolic rule induction approach, we find that decomposing learning\ninto multiple distinct mechanisms significantly improves data efficiency,\nbringing it in line with human learning. Furthermore, we show that this\ndecomposition has a greater impact on efficiency than the distinction between\nsymbolic and subsymbolic learning alone. Efforts to align data-driven machine\nlearning with human learning often overlook the stark difference in learning\nefficiency. Our findings suggest that integrating multiple specialized learning\nmechanisms may be key to bridging this gap."}
{"id": "2505.10464", "pdf": "https://arxiv.org/pdf/2505.10464", "abs": "https://arxiv.org/abs/2505.10464", "authors": ["Jiaming Liang", "Lihuan Dai", "Xiaoqi Sheng", "Xiangguang Chen", "Chun Yao", "Guihua Tao", "Qibin Leng", "Honming Cai", "Xi Zhong"], "title": "HWA-UNETR: Hierarchical Window Aggregate UNETR for 3D Multimodal Gastric Lesion Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": "This work has been provisionally accepted for MICCAI 2025", "summary": "Multimodal medical image segmentation faces significant challenges in the\ncontext of gastric cancer lesion analysis. This clinical context is defined by\nthe scarcity of independent multimodal datasets and the imperative to\namalgamate inherently misaligned modalities. As a result, algorithms are\nconstrained to train on approximate data and depend on application migration,\nleading to substantial resource expenditure and a potential decline in analysis\naccuracy. To address those challenges, we have made two major contributions:\nFirst, we publicly disseminate the GCM 2025 dataset, which serves as the first\nlarge-scale, open-source collection of gastric cancer multimodal MRI scans,\nfeaturing professionally annotated FS-T2W, CE-T1W, and ADC images from 500\npatients. Second, we introduce HWA-UNETR, a novel 3D segmentation framework\nthat employs an original HWA block with learnable window aggregation layers to\nestablish dynamic feature correspondences between different modalities'\nanatomical structures, and leverages the innovative tri-orientated fusion mamba\nmechanism for context modeling and capturing long-range spatial dependencies.\nExtensive experiments on our GCM 2025 dataset and the publicly BraTS 2021\ndataset validate the performance of our framework, demonstrating that the new\napproach surpasses existing methods by up to 1.68\\% in the Dice score while\nmaintaining solid robustness. The dataset and code are public via\nhttps://github.com/JeMing-creater/HWA-UNETR."}
{"id": "2505.10050", "pdf": "https://arxiv.org/pdf/2505.10050", "abs": "https://arxiv.org/abs/2505.10050", "authors": ["Fahad Almalki", "Mehedi Masud"], "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection."}
{"id": "2505.10423", "pdf": "https://arxiv.org/pdf/2505.10423", "abs": "https://arxiv.org/abs/2505.10423", "authors": ["Ari Karchmer", "Eran Malach"], "title": "The Power of Random Features and the Limits of Distribution-Free Gradient Descent", "categories": ["cs.LG"], "comment": null, "summary": "We study the relationship between gradient-based optimization of parametric\nmodels (e.g., neural networks) and optimization of linear combinations of\nrandom features. Our main result shows that if a parametric model can be\nlearned using mini-batch stochastic gradient descent (bSGD) without making\nassumptions about the data distribution, then with high probability, the target\nfunction can also be approximated using a polynomial-sized combination of\nrandom features. The size of this combination depends on the number of gradient\nsteps and numerical precision used in the bSGD process. This finding reveals\nfundamental limitations of distribution-free learning in neural networks\ntrained by gradient descent, highlighting why making assumptions about data\ndistributions is often crucial in practice. Along the way, we also introduce a\nnew theoretical framework called average probabilistic dimension complexity\n(adc), which extends the probabilistic dimension complexity developed by Kamath\net al. (2020). We prove that adc has a polynomial relationship with statistical\nquery dimension, and use this relationship to demonstrate an infinite\nseparation between adc and standard dimension complexity."}
{"id": "2505.10492", "pdf": "https://arxiv.org/pdf/2505.10492", "abs": "https://arxiv.org/abs/2505.10492", "authors": ["Taylor L. Bobrow", "Mayank Golhar", "Suchapa Arayakarnkul", "Anthony A. Song", "Saowanee Ngamruengphong", "Nicholas J. Durr"], "title": "Multi-contrast laser endoscopy for in vivo gastrointestinal imaging", "categories": ["eess.IV", "cs.CV", "physics.optics"], "comment": null, "summary": "White light endoscopy is the clinical gold standard for detecting diseases in\nthe gastrointestinal tract. Most applications involve identifying visual\nabnormalities in tissue color, texture, and shape. Unfortunately, the contrast\nof these features is often subtle, causing many clinically relevant cases to go\nundetected. To overcome this challenge, we introduce Multi-contrast Laser\nEndoscopy (MLE): a platform for widefield clinical imaging with rapidly tunable\nspectral, coherent, and directional illumination. We demonstrate three\ncapabilities of MLE: enhancing tissue chromophore contrast with multispectral\ndiffuse reflectance, quantifying blood flow using laser speckle contrast\nimaging, and characterizing mucosal topography using photometric stereo. We\nvalidate MLE with benchtop models, then demonstrate MLE in vivo during clinical\ncolonoscopies. MLE images from 31 polyps demonstrate an approximate three-fold\nimprovement in contrast and a five-fold improvement in color difference\ncompared to white light and narrow band imaging. With the ability to reveal\nmultiple complementary types of tissue contrast while seamlessly integrating\ninto the clinical environment, MLE shows promise as an investigative tool to\nimprove gastrointestinal imaging."}
{"id": "2505.10055", "pdf": "https://arxiv.org/pdf/2505.10055", "abs": "https://arxiv.org/abs/2505.10055", "authors": ["Ijazul Haq", "Yingjie Zhang", "Irfan Ali Khan"], "title": "PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper evaluates the performance of Large Multimodal Models (LMMs) on\nOptical Character Recognition (OCR) in the low-resource Pashto language.\nNatural Language Processing (NLP) in Pashto faces several challenges due to the\ncursive nature of its script and a scarcity of structured datasets. To address\nthis, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one\nmillion images annotated with bounding boxes at word, line, and document\nlevels, suitable for training and evaluating models based on different\narchitectures, including Convolutional Neural Networks (CNNs) and Transformers.\nPsOCR covers variations across 1,000 unique font families, colors, image sizes,\nand layouts. A benchmark subset of 10K images was selected to evaluate the\nperformance of several LMMs, including seven open-source models: DeepSeek's\nJanus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four\nclosed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results\ndemonstrate that Gemini achieves the best performance among all models, whereas\namong open-source models, Qwen-7B stands out. This work provides an insightful\nassessment of the capabilities and limitations of current LMMs for OCR tasks in\nPashto and establishes a foundation for further research not only in Pashto OCR\nbut also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is\navailable at https://github.com/zirak-ai/PashtoOCR."}
{"id": "2505.10425", "pdf": "https://arxiv.org/pdf/2505.10425", "abs": "https://arxiv.org/abs/2505.10425", "authors": ["Jingyao Wang", "Wenwen Qiang", "Zeen Song", "Changwen Zheng", "Hui Xiong"], "title": "Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) excel at complex tasks thanks to advances in\nreasoning abilities. However, existing methods overlook the trade-off between\nreasoning effectiveness and computational efficiency, often encouraging\nunnecessarily long reasoning chains and wasting tokens. To address this, we\npropose Learning to Think (L2T), an information-theoretic reinforcement\nfine-tuning framework for LLMs to make the models achieve optimal reasoning\nwith fewer tokens. Specifically, L2T treats each query-response interaction as\na hierarchical session of multiple episodes and proposes a universal dense\nprocess reward, i.e., quantifies the episode-wise information gain in\nparameters, requiring no extra annotations or task-specific evaluators. We\npropose a method to quickly estimate this reward based on PAC-Bayes bounds and\nthe Fisher information matrix. Theoretical analyses show that it significantly\nreduces computational complexity with high estimation accuracy. By immediately\nrewarding each episode's contribution and penalizing excessive updates, L2T\noptimizes the model via reinforcement learning to maximize the use of each\nepisode and achieve effective updates. Empirical results on various reasoning\nbenchmarks and base models demonstrate the advantage of L2T across different\ntasks, boosting both reasoning effectiveness and efficiency."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.10066", "pdf": "https://arxiv.org/pdf/2505.10066", "abs": "https://arxiv.org/abs/2505.10066", "authors": ["Michael Fire", "Yitzhak Elbazis", "Adi Wasenstein", "Lior Rokach"], "title": "Dark LLMs: The Growing Threat of Unaligned AI Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50, 68T05, 68P25", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated."}
{"id": "2505.10432", "pdf": "https://arxiv.org/pdf/2505.10432", "abs": "https://arxiv.org/abs/2505.10432", "authors": ["Randy J. Chase", "Katherine Haynes", "Lander Ver Hoef", "Imme Ebert-Uphoff"], "title": "Score-based diffusion nowcasting of GOES imagery", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "Clouds and precipitation are important for understanding weather and climate.\nSimulating clouds and precipitation with traditional numerical weather\nprediction is challenging because of the sub-grid parameterizations required.\nMachine learning has been explored for forecasting clouds and precipitation,\nbut early machine learning methods often created blurry forecasts. In this\npaper we explore a newer method, named score-based diffusion, to nowcast (zero\nto three hour forecast) clouds and precipitation. We discuss the background and\nintuition of score-based diffusion models - thus providing a starting point for\nthe community - while exploring the methodology's use for nowcasting\ngeostationary infrared imagery. We experiment with three main types of\ndiffusion models: a standard score-based diffusion model (Diff); a residual\ncorrection diffusion model (CorrDiff); and a latent diffusion model (LDM). Our\nresults show that the diffusion models are able to not only advect existing\nclouds, but also generate and decay clouds, including convective initiation.\nThese results are surprising because the forecasts are initiated with only the\npast 20 mins of infrared satellite imagery. A case study qualitatively shows\nthe preservation of high resolution features longer into the forecast than a\nconventional mean-squared error trained U-Net. The best of the three diffusion\nmodels tested was the CorrDiff approach, outperforming all other diffusion\nmodels, the traditional U-Net, and a persistence forecast by one to two kelvin\non root mean squared error. The diffusion models also enable out-of-the-box\nensemble generation, which shows skillful calibration, with the spread of the\nensemble correlating well to the error."}
{"id": "2505.10526", "pdf": "https://arxiv.org/pdf/2505.10526", "abs": "https://arxiv.org/abs/2505.10526", "authors": ["Mugilan Ganesan", "Shane Segal", "Ankur Aggarwal", "Nish Sinnadurai", "Sean Lie", "Vithursan Thangarasa"], "title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Main paper: 11 pp., 4 figs., 3 tabs.; Supplementary: 2 pp", "summary": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs."}
{"id": "2505.10073", "pdf": "https://arxiv.org/pdf/2505.10073", "abs": "https://arxiv.org/abs/2505.10073", "authors": ["Rathin Chandra Shit", "Sharmila Subudhi"], "title": "Multi-Robot Task Allocation for Homogeneous Tasks with Collision Avoidance via Spatial Clustering", "categories": ["cs.RO", "cs.AI"], "comment": "5 pages, 4 figures, Scheduled for presentation at an upcoming\n  conference", "summary": "In this paper, a novel framework is presented that achieves a combined\nsolution based on Multi-Robot Task Allocation (MRTA) and collision avoidance\nwith respect to homogeneous measurement tasks taking place in industrial\nenvironments. The spatial clustering we propose offers to simultaneously solve\nthe task allocation problem and deal with collision risks by cutting the\nworkspace into distinguishable operational zones for each robot. To divide task\nsites and to schedule robot routes within corresponding clusters, we use\nK-means clustering and the 2-Opt algorithm. The presented framework shows\nsatisfactory performance, where up to 93\\% time reduction (1.24s against\n17.62s) with a solution quality improvement of up to 7\\% compared to the best\nperforming method is demonstrated. Our method also completely eliminates\ncollision points that persist in comparative methods in a most significant\nsense. Theoretical analysis agrees with the claim that spatial partitioning\nunifies the apparently disjoint tasks allocation and collision avoidance\nproblems under conditions of many identical tasks to be distributed over sparse\ngeographical areas. Ultimately, the findings in this work are of substantial\nimportance for real world applications where both computational efficiency and\noperation free from collisions is of paramount importance."}
{"id": "2505.10438", "pdf": "https://arxiv.org/pdf/2505.10438", "abs": "https://arxiv.org/abs/2505.10438", "authors": ["David Grasev"], "title": "Identification and Optimal Nonlinear Control of Turbojet Engine Using Koopman Eigenfunction Model", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "51 pages, 28 figures", "summary": "Gas turbine engines represent complex highly nonlinear dynamical systems.\nDeriving their physics-based models can be challenging as it requires\nperformance characteristics, that are not always available, and one often has\nto make many simplifying assumptions. In this paper, the limitations of\nconventional experimental methods used to derive component-level and locally\nlinear parameter-varying models are discussed and addressed by employing\nidentification techniques based on data collected from standard engine\noperation under closed-loop control. The rotor dynamics were estimated using\nthe sparse identification of nonlinear dynamics. Subsequently, the autonomous\npart of the dynamics was mapped into an optimally constructed Koopman\neigenfunction space. The process included eigenvalue optimization using\nmetaheuristic algorithms and temporal projection, followed by gradient-based\neigenfunction identification. The resulting Koopman model was validated against\nan in-house reference component-level model. A globally optimal nonlinear\nfeedback controller and a Kalman estimator were then designed in the\neigenfunction space and compared to the classical and gain-scheduled\nproportional-integral controllers, as well as a proposed internal model control\napproach. The eigenmode structure allowed targeting individual modes during the\noptimization process, resulting in a better performance tuning. The results\nshowed that the Koopman-based controller outperformed the other benchmark\ncontrollers in both reference tracking and disturbance rejection, under\nsea-level and varying flight conditions, due to its global nature."}
{"id": "2505.10558", "pdf": "https://arxiv.org/pdf/2505.10558", "abs": "https://arxiv.org/abs/2505.10558", "authors": ["Peiying Zhang", "Nanxuan Zhao", "Jing Liao"], "title": "Style Customization of Text-to-Vector Generation with Image Diffusion Priors", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted by SIGGRAPH 2025 (Conference Paper). Project page:\n  https://customsvg.github.io", "summary": "Scalable Vector Graphics (SVGs) are highly favored by designers due to their\nresolution independence and well-organized layer structure. Although existing\ntext-to-vector (T2V) generation methods can create SVGs from text prompts, they\noften overlook an important need in practical applications: style\ncustomization, which is vital for producing a collection of vector graphics\nwith consistent visual appearance and coherent aesthetics. Extending existing\nT2V methods for style customization poses certain challenges.\nOptimization-based T2V models can utilize the priors of text-to-image (T2I)\nmodels for customization, but struggle with maintaining structural regularity.\nOn the other hand, feed-forward T2V models can ensure structural regularity,\nyet they encounter difficulties in disentangling content and style due to\nlimited SVG training data.\n  To address these challenges, we propose a novel two-stage style customization\npipeline for SVG generation, making use of the advantages of both feed-forward\nT2V models and T2I image priors. In the first stage, we train a T2V diffusion\nmodel with a path-level representation to ensure the structural regularity of\nSVGs while preserving diverse expressive capabilities. In the second stage, we\ncustomize the T2V diffusion model to different styles by distilling customized\nT2I models. By integrating these techniques, our pipeline can generate\nhigh-quality and diverse SVGs in custom styles based on text prompts in an\nefficient feed-forward manner. The effectiveness of our method has been\nvalidated through extensive experiments. The project page is\nhttps://customsvg.github.io."}
{"id": "2505.10101", "pdf": "https://arxiv.org/pdf/2505.10101", "abs": "https://arxiv.org/abs/2505.10101", "authors": ["Jongmin Jung", "Dasaem Jeong"], "title": "LAV: Audio-Driven Dynamic Visual Generation with Neural Compression and StyleGAN2", "categories": ["cs.SD", "cs.AI", "cs.GR", "cs.MM", "eess.AS"], "comment": "Paper accepted at ISEA 2025, The 30th International Symposium on\n  Electronic/Emerging Art, Seoul, Republic of Korea, 23 - 29 May 2025", "summary": "This paper introduces LAV (Latent Audio-Visual), a system that integrates\nEnCodec's neural audio compression with StyleGAN2's generative capabilities to\nproduce visually dynamic outputs driven by pre-recorded audio. Unlike previous\nworks that rely on explicit feature mappings, LAV uses EnCodec embeddings as\nlatent representations, directly transformed into StyleGAN2's style latent\nspace via randomly initialized linear mapping. This approach preserves semantic\nrichness in the transformation, enabling nuanced and semantically coherent\naudio-visual translations. The framework demonstrates the potential of using\npretrained audio compression models for artistic and computational\napplications."}
{"id": "2505.10441", "pdf": "https://arxiv.org/pdf/2505.10441", "abs": "https://arxiv.org/abs/2505.10441", "authors": ["Filippo Leveni", "Luca Magri", "Giacomo Boracchi", "Cesare Alippi"], "title": "PIF: Anomaly detection via preference embedding", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)", "summary": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space."}
{"id": "2505.10105", "pdf": "https://arxiv.org/pdf/2505.10105", "abs": "https://arxiv.org/abs/2505.10105", "authors": ["Zibin Dong", "Fei Ni", "Yifu Yuan", "Yinchuan Li", "Jianye Hao"], "title": "EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "We present EmbodiedMAE, a unified 3D multi-modal representation for robot\nmanipulation. Current approaches suffer from significant domain gaps between\ntraining datasets and robot manipulation tasks, while also lacking model\narchitectures that can effectively incorporate 3D information. To overcome\nthese limitations, we enhance the DROID dataset with high-quality depth maps\nand point clouds, constructing DROID-3D as a valuable supplement for 3D\nembodied vision research. Then we develop EmbodiedMAE, a multi-modal masked\nautoencoder that simultaneously learns representations across RGB, depth, and\npoint cloud modalities through stochastic masking and cross-modal fusion.\nTrained on DROID-3D, EmbodiedMAE consistently outperforms state-of-the-art\nvision foundation models (VFMs) in both training efficiency and final\nperformance across 70 simulation tasks and 20 real-world robot manipulation\ntasks on two robot platforms. The model exhibits strong scaling behavior with\nsize and promotes effective policy learning from 3D inputs. Experimental\nresults establish EmbodiedMAE as a reliable unified 3D multi-modal VFM for\nembodied AI systems, particularly in precise tabletop manipulation settings\nwhere spatial perception is critical."}
{"id": "2505.10457", "pdf": "https://arxiv.org/pdf/2505.10457", "abs": "https://arxiv.org/abs/2505.10457", "authors": ["Matteo Gambella", "Vicente Javier Castro Solar", "Manuel Roveri"], "title": "SEAL: Searching Expandable Architectures for Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "comment": "8 pages, 5 figures", "summary": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios."}
{"id": "2505.10120", "pdf": "https://arxiv.org/pdf/2505.10120", "abs": "https://arxiv.org/abs/2505.10120", "authors": ["Guillaume Godin"], "title": "All You Need Is Synthetic Task Augmentation", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 3 Figures, 6 tables", "summary": "Injecting rule-based models like Random Forests into differentiable neural\nnetwork frameworks remains an open challenge in machine learning. Recent\nadvancements have demonstrated that pretrained models can generate efficient\nmolecular embeddings. However, these approaches often require extensive\npretraining and additional techniques, such as incorporating posterior\nprobabilities, to boost performance. In our study, we propose a novel strategy\nthat jointly trains a single Graph Transformer neural network on both sparse\nmultitask molecular property experimental targets and synthetic targets derived\nfrom XGBoost models trained on Osmordred molecular descriptors. These synthetic\ntasks serve as independent auxiliary tasks. Our results show consistent and\nsignificant performance improvement across all 19 molecular property prediction\ntasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms\nthe XGBoost single-task learner. This demonstrates that synthetic task\naugmentation is an effective method for enhancing neural model performance in\nmultitask molecular property prediction without the need for feature injection\nor pretraining."}
{"id": "2505.10465", "pdf": "https://arxiv.org/pdf/2505.10465", "abs": "https://arxiv.org/abs/2505.10465", "authors": ["Yizhou liu", "Ziming Liu", "Jeff Gore"], "title": "Superposition Yields Robust Neural Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages, 23 figures", "summary": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters."}
{"id": "2505.10128", "pdf": "https://arxiv.org/pdf/2505.10128", "abs": "https://arxiv.org/abs/2505.10128", "authors": ["Huy Q. Le", "Latif U. Khan", "Choong Seon Hong"], "title": "Robust Federated Learning on Edge Devices with Domain Heterogeneity", "categories": ["cs.LG", "cs.AI"], "comment": "IWCMC 2025", "summary": "Federated Learning (FL) allows collaborative training while ensuring data\nprivacy across distributed edge devices, making it a popular solution for\nprivacy-sensitive applications. However, FL faces significant challenges due to\nstatistical heterogeneity, particularly domain heterogeneity, which impedes the\nglobal mode's convergence. In this study, we introduce a new framework to\naddress this challenge by improving the generalization ability of the FL global\nmodel under domain heterogeneity, using prototype augmentation. Specifically,\nwe introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a\nprototype-based FL framework designed to enhance feature diversity and model\nrobustness. FedAPC leverages prototypes derived from the mean features of\naugmented data to capture richer representations. By aligning local features\nwith global prototypes, we enable the model to learn meaningful semantic\nfeatures while reducing overfitting to any specific domain. Experimental\nresults on the Office-10 and Digits datasets illustrate that our framework\noutperforms SOTA baselines, demonstrating superior performance."}
{"id": "2505.10472", "pdf": "https://arxiv.org/pdf/2505.10472", "abs": "https://arxiv.org/abs/2505.10472", "authors": ["Agnik Saha", "Victoria Churchill", "Anny D. Rodriguez", "Ugur Kursuncu", "Muhammed Y. Idris"], "title": "Large Language Models for Cancer Communication: Evaluating Linguistic Quality, Safety, and Accessibility in Generative AI", "categories": ["cs.LG"], "comment": null, "summary": "Effective communication about breast and cervical cancers remains a\npersistent health challenge, with significant gaps in public understanding of\ncancer prevention, screening, and treatment, potentially leading to delayed\ndiagnoses and inadequate treatments. This study evaluates the capabilities and\nlimitations of Large Language Models (LLMs) in generating accurate, safe, and\naccessible cancer-related information to support patient understanding. We\nevaluated five general-purpose and three medical LLMs using a mixed-methods\nevaluation framework across linguistic quality, safety and trustworthiness, and\ncommunication accessibility and affectiveness. Our approach utilized\nquantitative metrics, qualitative expert ratings, and statistical analysis\nusing Welch's ANOVA, Games-Howell, and Hedges' g. Our results show that\ngeneral-purpose LLMs produced outputs of higher linguistic quality and\naffectiveness, while medical LLMs demonstrate greater communication\naccessibility. However, medical LLMs tend to exhibit higher levels of potential\nharm, toxicity, and bias, reducing their performance in safety and\ntrustworthiness. Our findings indicate a duality between domain-specific\nknowledge and safety in health communications. The results highlight the need\nfor intentional model design with targeted improvements, particularly in\nmitigating harm and bias, and improving safety and affectiveness. This study\nprovides a comprehensive evaluation of LLMs for cancer communication, offering\ncritical insights for improving AI-generated health content and informing\nfuture development of accurate, safe, and accessible digital health tools."}
{"id": "2505.10134", "pdf": "https://arxiv.org/pdf/2505.10134", "abs": "https://arxiv.org/abs/2505.10134", "authors": ["Guangjin Pan", "Kaixuan Huang", "Hui Chen", "Shunqing Zhang", "Christian Häger", "Henk Wymeersch"], "title": "Large Wireless Localization Model (LWLM): A Foundation Model for Positioning in 6G Networks", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "13 pages,16 figures.This work has been submitted to the IEEE for\n  possible publication", "summary": "Accurate and robust localization is a critical enabler for emerging 5G and 6G\napplications, including autonomous driving, extended reality (XR), and smart\nmanufacturing. While data-driven approaches have shown promise, most existing\nmodels require large amounts of labeled data and struggle to generalize across\ndeployment scenarios and wireless configurations. To address these limitations,\nwe propose a foundation-model-based solution tailored for wireless\nlocalization. We first analyze how different self-supervised learning (SSL)\ntasks acquire general-purpose and task-specific semantic features based on\ninformation bottleneck (IB) theory. Building on this foundation, we design a\npretraining methodology for the proposed Large Wireless Localization Model\n(LWLM). Specifically, we propose an SSL framework that jointly optimizes three\ncomplementary objectives: (i) spatial-frequency masked channel modeling\n(SF-MCM), (ii) domain-transformation invariance (DTI), and (iii)\nposition-invariant contrastive learning (PICL). These objectives jointly\ncapture the underlying semantics of wireless channel from multiple\nperspectives. We further design lightweight decoders for key downstream tasks,\nincluding time-of-arrival (ToA) estimation, angle-of-arrival (AoA) estimation,\nsingle base station (BS) localization, and multiple BS localization.\nComprehensive experimental results confirm that LWLM consistently surpasses\nboth model-based and supervised learning baselines across all localization\ntasks. In particular, LWLM achieves 26.0%--87.5% improvement over transformer\nmodels without pretraining, and exhibits strong generalization under\nlabel-limited fine-tuning and unseen BS configurations, confirming its\npotential as a foundation model for wireless localization."}
{"id": "2505.10475", "pdf": "https://arxiv.org/pdf/2505.10475", "abs": "https://arxiv.org/abs/2505.10475", "authors": ["Mouxiang Chen", "Binyuan Hui", "Zeyu Cui", "Jiaxi Yang", "Dayiheng Liu", "Jianling Sun", "Junyang Lin", "Zhongxin Liu"], "title": "Parallel Scaling Law for Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "It is commonly believed that scaling language models should commit a\nsignificant space or time cost, by increasing the parameters (parameter\nscaling) or output tokens (inference-time scaling). We introduce the third and\nmore inference-efficient scaling paradigm: increasing the model's parallel\ncomputation during both training and inference time. We apply $P$ diverse and\nlearnable transformations to the input, execute forward passes of the model in\nparallel, and dynamically aggregate the $P$ outputs. This method, namely\nparallel scaling (ParScale), scales parallel computation by reusing existing\nparameters and can be applied to any model structure, optimization procedure,\ndata, or task. We theoretically propose a new scaling law and validate it\nthrough large-scale pre-training, which shows that a model with $P$ parallel\nstreams is similar to scaling the parameters by $O(\\log P)$ while showing\nsuperior inference efficiency. For example, ParScale can use up to 22$\\times$\nless memory increase and 6$\\times$ less latency increase compared to parameter\nscaling that achieves the same performance improvement. It can also recycle an\noff-the-shelf pre-trained model into a parallelly scaled one by post-training\non a small amount of tokens, further reducing the training budget. The new\nscaling law we discovered potentially facilitates the deployment of more\npowerful models in low-resource scenarios, and provides an alternative\nperspective for the role of computation in machine learning."}
{"id": "2505.10167", "pdf": "https://arxiv.org/pdf/2505.10167", "abs": "https://arxiv.org/abs/2505.10167", "authors": ["Saikat Barua", "Mostafizur Rahman", "Shehenaz Khaled", "Md Jafor Sadek", "Rafiul Islam", "Shahnewaz Siddique"], "title": "QuXAI: Explainers for Hybrid Quantum Machine Learning Models", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": "16 pages, 6 figures, 7 equations", "summary": "The emergence of hybrid quantum-classical machine learning (HQML) models\nopens new horizons of computational intelligence but their fundamental\ncomplexity frequently leads to black box behavior that undermines transparency\nand reliability in their application. Although XAI for quantum systems still in\nits infancy, a major research gap is evident in robust global and local\nexplainability approaches that are designed for HQML architectures that employ\nquantized feature encoding followed by classical learning. The gap is the focus\nof this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an\nexplainer for explaining feature importance in these hybrid systems. Our model\nentails the creation of HQML models incorporating quantum feature maps, the use\nof Q-MEDLEY, which combines feature based inferences, preserving the quantum\ntransformation stage and visualizing the resulting attributions. Our result\nshows that Q-MEDLEY delineates influential classical aspects in HQML models, as\nwell as separates their noise, and competes well against established XAI\ntechniques in classical validation settings. Ablation studies more\nsignificantly expose the virtues of the composite structure used in Q-MEDLEY.\nThe implications of this work are critically important, as it provides a route\nto improve the interpretability and reliability of HQML models, thus promoting\ngreater confidence and being able to engage in safer and more responsible use\nof quantum-enhanced AI technology."}
{"id": "2505.10482", "pdf": "https://arxiv.org/pdf/2505.10482", "abs": "https://arxiv.org/abs/2505.10482", "authors": ["Ningyuan Yang", "Jiaxuan Gao", "Feng Gao", "Yi Wu", "Chao Yu"], "title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages for main text, 23 pages in total, submitted to Neurips, 13\n  figures", "summary": "Diffusion policies, widely adopted in decision-making scenarios such as\nrobotics, gaming and autonomous driving, are capable of learning diverse skills\nfrom demonstration data due to their high representation power. However, the\nsub-optimal and limited coverage of demonstration data could lead to diffusion\npolicies that generate sub-optimal trajectories and even catastrophic failures.\nWhile reinforcement learning (RL)-based fine-tuning has emerged as a promising\nsolution to address these limitations, existing approaches struggle to\neffectively adapt Proximal Policy Optimization (PPO) to diffusion models. This\nchallenge stems from the computational intractability of action likelihood\nestimation during the denoising process, which leads to complicated\noptimization objectives. In our experiments starting from randomly initialized\npolicies, we find that online tuning of Diffusion Policies demonstrates much\nlower sample efficiency compared to directly applying PPO on MLP policies\n(MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework\nthat reformulates Diffusion Policy as a noise-conditioned deterministic policy.\nBy treating each denoising step as a differentiable transformation conditioned\non pre-sampled noise, NCDPO enables tractable likelihood evaluation and\ngradient backpropagation through all diffusion timesteps. Our experiments\ndemonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when\ntraining from scratch, outperforming existing methods in both sample efficiency\nand final performance across diverse benchmarks, including continuous robot\ncontrol and multi-agent game scenarios. Furthermore, our experimental results\nshow that our method is robust to the number denoising timesteps in the\nDiffusion Policy."}
{"id": "2505.10169", "pdf": "https://arxiv.org/pdf/2505.10169", "abs": "https://arxiv.org/abs/2505.10169", "authors": ["Matthias Kümmerer", "Harneet Khanuja", "Matthias Bethge"], "title": "Modeling Saliency Dataset Bias", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes."}
{"id": "2505.10484", "pdf": "https://arxiv.org/pdf/2505.10484", "abs": "https://arxiv.org/abs/2505.10484", "authors": ["Andrea Baisero", "Rupali Bhati", "Shuo Liu", "Aathira Pillai", "Christopher Amato"], "title": "Fixing Incomplete Value Function Decomposition for Multi-Agent Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Value function decomposition methods for cooperative multi-agent\nreinforcement learning compose joint values from individual per-agent\nutilities, and train them using a joint objective. To ensure that the action\nselection process between individual utilities and joint values remains\nconsistent, it is imperative for the composition to satisfy the\nindividual-global max (IGM) property. Although satisfying IGM itself is\nstraightforward, most existing methods (e.g., VDN, QMIX) have limited\nrepresentation capabilities and are unable to represent the full class of IGM\nvalues, and the one exception that has no such limitation (QPLEX) is\nunnecessarily complex. In this work, we present a simple formulation of the\nfull class of IGM values that naturally leads to the derivation of QFIX, a\nnovel family of value function decomposition models that expand the\nrepresentation capabilities of prior models by means of a thin \"fixing\" layer.\nWe derive multiple variants of QFIX, and implement three variants in two\nwell-known multi-agent frameworks. We perform an empirical evaluation on\nmultiple SMACv2 and Overcooked environments, which confirms that QFIX (i)\nsucceeds in enhancing the performance of prior methods, (ii) learns more stably\nand performs better than its main competitor QPLEX, and (iii) achieves this\nwhile employing the simplest and smallest mixing models."}
{"id": "2505.10172", "pdf": "https://arxiv.org/pdf/2505.10172", "abs": "https://arxiv.org/abs/2505.10172", "authors": ["Zeyan Li", "Libing Chen", "Yin Tang"], "title": "Does Scaling Law Apply in Time Series Forecasting?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Rapid expansion of model size has emerged as a key challenge in time series\nforecasting. From early Transformer with tens of megabytes to recent\narchitectures like TimesNet with thousands of megabytes, performance gains have\noften come at the cost of exponentially increasing parameter counts. But is\nthis scaling truly necessary? To question the applicability of the scaling law\nin time series forecasting, we propose Alinear, an ultra-lightweight\nforecasting model that achieves competitive performance using only k-level\nparameters. We introduce a horizon-aware adaptive decomposition mechanism that\ndynamically rebalances component emphasis across different forecast lengths,\nalongside a progressive frequency attenuation strategy that achieves stable\nprediction in various forecasting horizons without incurring the computational\noverhead of attention mechanisms. Extensive experiments on seven benchmark\ndatasets demonstrate that Alinear consistently outperforms large-scale models\nwhile using less than 1% of their parameters, maintaining strong accuracy\nacross both short and ultra-long forecasting horizons. Moreover, to more fairly\nevaluate model efficiency, we propose a new parameter-aware evaluation metric\nthat highlights the superiority of ALinear under constrained model budgets. Our\nanalysis reveals that the relative importance of trend and seasonal components\nvaries depending on data characteristics rather than following a fixed pattern,\nvalidating the necessity of our adaptive design. This work challenges the\nprevailing belief that larger models are inherently better and suggests a\nparadigm shift toward more efficient time series modeling."}
{"id": "2505.10495", "pdf": "https://arxiv.org/pdf/2505.10495", "abs": "https://arxiv.org/abs/2505.10495", "authors": ["Vibha Belavadi", "Tushar Vatsa", "Dewang Sultania", "Suhas Suresha", "Ishita Verma", "Cheng Chen", "Tracy Holloway King", "Michael Friedrich"], "title": "RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs", "categories": ["cs.LG", "cs.CL"], "comment": "Proceedings of the 4th International Workshop on Knowledge-Augmented\n  Methods for Natural Language Processing", "summary": "This paper addresses fine-tuning Large Language Models (LLMs) for function\ncalling tasks when real user interaction data is unavailable. In digital\ncontent creation tools, where users express their needs through natural\nlanguage queries that must be mapped to API calls, the lack of real-world\ntask-specific data and privacy constraints for training on it necessitate\nsynthetic data generation. Existing approaches to synthetic data generation\nfall short in diversity and complexity, failing to replicate real-world data\ndistributions and leading to suboptimal performance after LLM fine-tuning. We\npresent a novel router-based architecture that leverages domain resources like\ncontent metadata and structured knowledge graphs, along with text-to-text and\nvision-to-text language models to generate high-quality synthetic training\ndata. Our architecture's flexible routing mechanism enables synthetic data\ngeneration that matches observed real-world distributions, addressing a\nfundamental limitation of traditional approaches. Evaluation on a comprehensive\nset of real user queries demonstrates significant improvements in both function\nclassification accuracy and API parameter selection. Models fine-tuned with our\nsynthetic data consistently outperform traditional approaches, establishing new\nbenchmarks for function calling tasks."}
{"id": "2505.10183", "pdf": "https://arxiv.org/pdf/2505.10183", "abs": "https://arxiv.org/abs/2505.10183", "authors": ["Jieke Lin", "Wanyu Wang", "Longxiang Yin", "Yinhe Han"], "title": "KAITIAN: A Unified Communication Framework for Enabling Efficient Collaboration Across Heterogeneous Accelerators in Embodied AI Systems", "categories": ["cs.DC", "cs.AI"], "comment": "9 pages, 4 figures. Jieke Lin and Wanyu Wang contributed equally to\n  this work", "summary": "Embodied Artificial Intelligence (AI) systems, such as autonomous robots and\nintelligent vehicles, are increasingly reliant on diverse heterogeneous\naccelerators (e.g., GPGPUs, NPUs, FPGAs) to meet stringent real-time processing\nand energy-efficiency demands. However, the proliferation of vendor-specific\nproprietary communication libraries creates significant interoperability\nbarriers, hindering seamless collaboration between different accelerator types\nand leading to suboptimal resource utilization and performance bottlenecks in\ndistributed AI workloads. This paper introduces KAITIAN, a novel distributed\ncommunication framework designed to bridge this gap. KAITIAN provides a unified\nabstraction layer that intelligently integrates vendor-optimized communication\nlibraries for intra-group efficiency with general-purpose communication\nprotocols for inter-group interoperability. Crucially, it incorporates a\nload-adaptive scheduling mechanism that dynamically balances computational\ntasks across heterogeneous devices based on their real-time performance\ncharacteristics. Implemented as an extension to PyTorch and rigorously\nevaluated on a testbed featuring NVIDIA GPUs and Cambricon MLUs, KAITIAN\ndemonstrates significant improvements in resource utilization and scalability\nfor distributed training tasks. Experimental results show that KAITIAN can\naccelerate training time by up to 42% compared to baseline homogeneous systems,\nwhile incurring minimal communication overhead (2.8--4.3%) and maintaining\nmodel accuracy. KAITIAN paves the way for more flexible and powerful\nheterogeneous computing in complex embodied AI applications."}
{"id": "2505.10515", "pdf": "https://arxiv.org/pdf/2505.10515", "abs": "https://arxiv.org/abs/2505.10515", "authors": ["Seongun Kim", "Sol A Kim", "Geonhyeong Kim", "Enver Menadjiev", "Chanwoo Lee", "Seongwook Chung", "Nari Kim", "Jaesik Choi"], "title": "PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, post hoc explanation methods have emerged to enhance model\ntransparency by attributing model outputs to input features. However, these\nmethods face challenges due to their specificity to certain neural network\narchitectures and data modalities. Existing explainable artificial intelligence\n(XAI) frameworks have attempted to address these challenges but suffer from\nseveral limitations. These include limited flexibility to diverse model\narchitectures and data modalities due to hard-coded implementations, a\nrestricted number of supported XAI methods because of the requirements for\nlayer-specific operations of attribution methods, and sub-optimal\nrecommendations of explanations due to the lack of evaluation and optimization\nphases. Consequently, these limitations impede the adoption of XAI technology\nin real-world applications, making it difficult for practitioners to select the\noptimal explanation method for their domain. To address these limitations, we\nintroduce \\textbf{PnPXAI}, a universal XAI framework that supports diverse data\nmodalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI\nautomatically detects model architectures, recommends applicable explanation\nmethods, and optimizes hyperparameters for optimal explanations. We validate\nthe framework's effectiveness through user surveys and showcase its versatility\nacross various domains, including medicine and finance."}
{"id": "2505.10185", "pdf": "https://arxiv.org/pdf/2505.10185", "abs": "https://arxiv.org/abs/2505.10185", "authors": ["Seongyun Lee", "Seungone Kim", "Minju Seo", "Yongrae Jo", "Dongyoung Go", "Hyeonbin Hwang", "Jinho Park", "Xiang Yue", "Sean Welleck", "Graham Neubig", "Moontae Lee", "Minjoon Seo"], "title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think", "categories": ["cs.CL", "cs.AI"], "comment": "Work in progress", "summary": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of\nmodern large language models, but our understanding of the reasoning strategies\nunderlying these capabilities remains limited. While some prior works have\nattempted to categorize CoTs using predefined strategy types, such approaches\nare constrained by human intuition and fail to capture the full diversity of\nmodel behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up\nframework for analyzing and steering model reasoning. Our method automatically\nextracts diverse reasoning criteria from model-generated CoTs, embeds them into\na semantic space, clusters them into representative categories, and derives\ncontrastive rubrics to interpret reasoning behavior. Human evaluations show\nthat this framework produces more interpretable and comprehensive analyses than\nexisting methods. Moreover, we demonstrate that this understanding enables\nperformance gains: we can predict which strategy a model is likely to use and\nguide it toward more effective alternatives. Finally, we provide practical\ninsights, such as that training data format (e.g., free-form vs.\nmultiple-choice) has a far greater impact on reasoning behavior than data\ndomain, underscoring the importance of format-aware model design."}
{"id": "2505.10526", "pdf": "https://arxiv.org/pdf/2505.10526", "abs": "https://arxiv.org/abs/2505.10526", "authors": ["Mugilan Ganesan", "Shane Segal", "Ankur Aggarwal", "Nish Sinnadurai", "Sean Lie", "Vithursan Thangarasa"], "title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Main paper: 11 pp., 4 figs., 3 tabs.; Supplementary: 2 pp", "summary": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs."}
{"id": "2505.10191", "pdf": "https://arxiv.org/pdf/2505.10191", "abs": "https://arxiv.org/abs/2505.10191", "authors": ["Qingyu Zheng", "Qi Shao", "Guijun Han", "Wei Li", "Hong Li", "Xuan Wang"], "title": "LanTu: Dynamics-Enhanced Deep Learning for Eddy-Resolving Ocean Forecasting", "categories": ["physics.ao-ph", "cs.AI", "cs.LG", "nlin.CD"], "comment": "22 pages, 6 figures", "summary": "Mesoscale eddies dominate the spatiotemporal multiscale variability of the\nocean, and their impact on the energy cascade of the global ocean cannot be\nignored. Eddy-resolving ocean forecasting is providing more reliable protection\nfor fisheries and navigational safety, but also presents significant scientific\nchallenges and high computational costs for traditional numerical models.\nArtificial intelligence (AI)-based weather and ocean forecasting systems are\nbecoming powerful tools that balance forecast performance with computational\nefficiency. However, the complex multiscale features in the ocean dynamical\nsystem make AI models still face many challenges in mesoscale eddy forecasting\n(especially regional modelling). Here, we develop LanTu, a regional\neddy-resolving ocean forecasting system based on dynamics-enhanced deep\nlearning. We incorporate cross-scale interactions into LanTu and construct\nmultiscale physical constraint for optimising LanTu guided by knowledge of eddy\ndynamics in order to improve the forecasting skill of LanTu for mesoscale\nevolution. The results show that LanTu outperforms the existing advanced\noperational numerical ocean forecasting system (NOFS) and AI-based ocean\nforecasting system (AI-OFS) in temperature, salinity, sea level anomaly and\ncurrent prediction, with a lead time of more than 10 days. Our study highlights\nthat dynamics-enhanced deep learning (LanTu) can be a powerful paradigm for\neddy-resolving ocean forecasting."}
{"id": "2505.10545", "pdf": "https://arxiv.org/pdf/2505.10545", "abs": "https://arxiv.org/abs/2505.10545", "authors": ["Amira Alakhdar", "Barnabas Poczos", "Newell Washburn"], "title": "Pharmacophore-Conditioned Diffusion Model for Ligand-Based De Novo Drug Design", "categories": ["cs.LG"], "comment": null, "summary": "Developing bioactive molecules remains a central, time- and cost-heavy\nchallenge in drug discovery, particularly for novel targets lacking structural\nor functional data. Pharmacophore modeling presents an alternative for\ncapturing the key features required for molecular bioactivity against a\nbiological target. In this work, we present PharmaDiff, a\npharmacophore-conditioned diffusion model for 3D molecular generation.\nPharmaDiff employs a transformer-based architecture to integrate an atom-based\nrepresentation of the 3D pharmacophore into the generative process, enabling\nthe precise generation of 3D molecular graphs that align with predefined\npharmacophore hypotheses. Through comprehensive testing, PharmaDiff\ndemonstrates superior performance in matching 3D pharmacophore constraints\ncompared to ligand-based drug design methods. Additionally, it achieves higher\ndocking scores across a range of proteins in structure-based drug design,\nwithout the need for target protein structures. By integrating pharmacophore\nmodeling with 3D generative techniques, PharmaDiff offers a powerful and\nflexible framework for rational drug design."}
{"id": "2505.10197", "pdf": "https://arxiv.org/pdf/2505.10197", "abs": "https://arxiv.org/abs/2505.10197", "authors": ["Anjali de Silva", "Gang Chen", "Hui Ma", "Seyed Mohammad Nekooei", "Xingquan Zuo"], "title": "Advancing Community Detection with Graph Convolutional Neural Networks: Bridging Topological and Attributive Cohesion", "categories": ["cs.SI", "cs.AI"], "comment": "This paper has been accepted by IJCAI (International Joint Conference\n  on Artificial Intelligence) 2025", "summary": "Community detection, a vital technology for real-world applications, uncovers\ncohesive node groups (communities) by leveraging both topological and attribute\nsimilarities in social networks. However, existing Graph Convolutional Networks\n(GCNs) trained to maximize modularity often converge to suboptimal solutions.\nAdditionally, directly using human-labeled communities for training can\nundermine topological cohesiveness by grouping disconnected nodes based solely\non node attributes. We address these issues by proposing a novel Topological\nand Attributive Similarity-based Community detection (TAS-Com) method. TAS-Com\nintroduces a novel loss function that exploits the highly effective and\nscalable Leiden algorithm to detect community structures with global optimal\nmodularity. Leiden is further utilized to refine human-labeled communities to\nensure connectivity within each community, enabling TAS-Com to detect community\nstructures with desirable trade-offs between modularity and compliance with\nhuman labels. Experimental results on multiple benchmark networks confirm that\nTAS-Com can significantly outperform several state-of-the-art algorithms."}
{"id": "2505.10556", "pdf": "https://arxiv.org/pdf/2505.10556", "abs": "https://arxiv.org/abs/2505.10556", "authors": ["Nazanin Zounemat Kermani", "Sadjad Naderi", "Claire H. Dilliway", "Claire E. Heaney", "Shrreya Behll", "Boyang Chen", "Hisham Abubakar-Waziri", "Alexandra E. Porter", "Marc Chadeau-Hyam", "Fangxin Fang", "Ian M. Adcock", "Kian Fan Chung", "Christopher C. Pain"], "title": "An AI-driven framework for the prediction of personalised health response to air pollution", "categories": ["cs.LG", "physics.ao-ph"], "comment": "Kermani and Naderi share first authorship. 20 pages, 6 figures and 1\n  table", "summary": "Air pollution poses a significant threat to public health, causing or\nexacerbating many respiratory and cardiovascular diseases. In addition, climate\nchange is bringing about more extreme weather events such as wildfires and\nheatwaves, which can increase levels of pollution and worsen the effects of\npollution exposure. Recent advances in personal sensing have transformed the\ncollection of behavioural and physiological data, leading to the potential for\nnew improvements in healthcare. We wish to capitalise on this data, alongside\nnew capabilities in AI for making time series predictions, in order to monitor\nand predict health outcomes for an individual. Thus, we present a novel\nworkflow for predicting personalised health responses to pollution by\nintegrating physiological data from wearable fitness devices with real-time\nenvironmental exposures. The data is collected from various sources in a secure\nand ethical manner, and is used to train an AI model to predict individual\nhealth responses to pollution exposure within a cloud-based, modular framework.\nWe demonstrate that the AI model -- an Adversarial Autoencoder neural network\nin this case -- accurately reconstructs time-dependent health signals and\ncaptures nonlinear responses to pollution. Transfer learning is applied using\ndata from a personal smartwatch, which increases the generalisation abilities\nof the AI model and illustrates the adaptability of the approach to real-world,\nuser-generated data."}
{"id": "2505.10201", "pdf": "https://arxiv.org/pdf/2505.10201", "abs": "https://arxiv.org/abs/2505.10201", "authors": ["Victor Lagerkvist", "Mohamed Maizia", "Johannes Schmidt"], "title": "A Fine-Grained Complexity View on Propositional Abduction -- Algorithms and Lower Bounds", "categories": ["cs.CC", "cs.AI", "F.2.2"], "comment": null, "summary": "The Boolean satisfiability problem (SAT) is a well-known example of monotonic\nreasoning, of intense practical interest due to fast solvers, complemented by\nrigorous fine-grained complexity results. However, for non-monotonic reasoning,\ne.g., abductive reasoning, comparably little is known outside classic\ncomplexity theory. In this paper we take a first step of bridging the gap\nbetween monotonic and non-monotonic reasoning by analyzing the complexity of\nintractable abduction problems under the seemingly overlooked but natural\nparameter n: the number of variables in the knowledge base. We obtain several\npositive results for $\\Sigma^P_2$- as well as NP- and coNP-complete fragments,\nwhich implies the first example of beating exhaustive search for a\n$\\Sigma^P_2$-complete problem (to the best of our knowledge). We complement\nthis with lower bounds and for many fragments rule out improvements under the\n(strong) exponential-time hypothesis."}
{"id": "2505.10559", "pdf": "https://arxiv.org/pdf/2505.10559", "abs": "https://arxiv.org/abs/2505.10559", "authors": ["Ziming Liu", "Yizhou Liu", "Jeff Gore", "Max Tegmark"], "title": "Neural Thermodynamic Laws for Large Language Model Training", "categories": ["cs.LG", "cs.AI", "physics.data-an", "stat.ML"], "comment": "18 pages, 10 figures", "summary": "Beyond neural scaling laws, little is known about the laws underlying large\nlanguage models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new\nframework that offers fresh insights into LLM training dynamics. On the\ntheoretical side, we demonstrate that key thermodynamic quantities (e.g.,\ntemperature, entropy, heat capacity, thermal conduction) and classical\nthermodynamic principles (e.g., the three laws of thermodynamics and the\nequipartition theorem) naturally emerge under river-valley loss landscape\nassumptions. On the practical side, this scientific perspective yields\nintuitive guidelines for designing learning rate schedules."}
{"id": "2505.10212", "pdf": "https://arxiv.org/pdf/2505.10212", "abs": "https://arxiv.org/abs/2505.10212", "authors": ["Dario Di Palma", "Felice Antonio Merra", "Maurizio Sfilio", "Vito Walter Anelli", "Fedelucio Narducci", "Tommaso Di Noia"], "title": "Do LLMs Memorize Recommendation Datasets? A Preliminary Study on MovieLens-1M", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have become increasingly central to\nrecommendation scenarios due to their remarkable natural language understanding\nand generation capabilities. Although significant research has explored the use\nof LLMs for various recommendation tasks, little effort has been dedicated to\nverifying whether they have memorized public recommendation dataset as part of\ntheir training data. This is undesirable because memorization reduces the\ngeneralizability of research findings, as benchmarking on memorized datasets\ndoes not guarantee generalization to unseen datasets. Furthermore, memorization\ncan amplify biases, for example, some popular items may be recommended more\nfrequently than others.\n  In this work, we investigate whether LLMs have memorized public\nrecommendation datasets. Specifically, we examine two model families (GPT and\nLlama) across multiple sizes, focusing on one of the most widely used dataset\nin recommender systems: MovieLens-1M. First, we define dataset memorization as\nthe extent to which item attributes, user profiles, and user-item interactions\ncan be retrieved by prompting the LLMs. Second, we analyze the impact of\nmemorization on recommendation performance. Lastly, we examine whether\nmemorization varies across model families and model sizes. Our results reveal\nthat all models exhibit some degree of memorization of MovieLens-1M, and that\nrecommendation performance is related to the extent of memorization. We have\nmade all the code publicly available at:\nhttps://github.com/sisinflab/LLM-MemoryInspector"}
{"id": "2505.08202", "pdf": "https://arxiv.org/pdf/2505.08202", "abs": "https://arxiv.org/abs/2505.08202", "authors": ["Aman Raj", "Lakshit Arora", "Sanjay Surendranath Girija", "Shashank Kapoor", "Dipen Pradhan", "Ankit Shetgaonkar"], "title": "AI and Generative AI Transforming Disaster Management: A Survey of Damage Assessment and Response Techniques", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "Accepted in IEEE Compsac 2025", "summary": "Natural disasters, including earthquakes, wildfires and cyclones, bear a huge\nrisk on human lives as well as infrastructure assets. An effective response to\ndisaster depends on the ability to rapidly and efficiently assess the intensity\nof damage. Artificial Intelligence (AI) and Generative Artificial Intelligence\n(GenAI) presents a breakthrough solution, capable of combining knowledge from\nmultiple types and sources of data, simulating realistic scenarios of disaster,\nand identifying emerging trends at a speed previously unimaginable. In this\npaper, we present a comprehensive review on the prospects of AI and GenAI in\ndamage assessment for various natural disasters, highlighting both its\nstrengths and limitations. We talk about its application to multimodal data\nsuch as text, image, video, and audio, and also cover major issues of data\nprivacy, security, and ethical use of the technology during crises. The paper\nalso recognizes the threat of Generative AI misuse, in the form of\ndissemination of misinformation and for adversarial attacks. Finally, we\noutline avenues of future research, emphasizing the need for secure, reliable,\nand ethical Generative AI systems for disaster management in general. We\nbelieve that this work represents the first comprehensive survey of Gen-AI\ntechniques being used in the field of Disaster Assessment and Response."}
{"id": "2505.10231", "pdf": "https://arxiv.org/pdf/2505.10231", "abs": "https://arxiv.org/abs/2505.10231", "authors": ["Haozhe Luo", "Ziyu Zhou", "Zixin Shu", "Aurélie Pahud de Mortanges", "Robert Berke", "Mauricio Reyes"], "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner."}
{"id": "2505.09633", "pdf": "https://arxiv.org/pdf/2505.09633", "abs": "https://arxiv.org/abs/2505.09633", "authors": ["Nick Sunday"], "title": "Detecting Musical Deepfakes", "categories": ["cs.SD", "cs.LG"], "comment": "Submitted as part of coursework at UT Austin. Accompanying code\n  available at: https://github.com/nicksunday/deepfake-music-detector", "summary": "The proliferation of Text-to-Music (TTM) platforms has democratized music\ncreation, enabling users to effortlessly generate high-quality compositions.\nHowever, this innovation also presents new challenges to musicians and the\nbroader music industry. This study investigates the detection of AI-generated\nsongs using the FakeMusicCaps dataset by classifying audio as either deepfake\nor human. To simulate real-world adversarial conditions, tempo stretching and\npitch shifting were applied to the dataset. Mel spectrograms were generated\nfrom the modified audio, then used to train and evaluate a convolutional neural\nnetwork. In addition to presenting technical results, this work explores the\nethical and societal implications of TTM platforms, arguing that carefully\ndesigned detection systems are essential to both protecting artists and\nunlocking the positive potential of generative AI in music."}
{"id": "2505.10260", "pdf": "https://arxiv.org/pdf/2505.10260", "abs": "https://arxiv.org/abs/2505.10260", "authors": ["Poli Apollinaire Nemkova", "Solomon Ubani", "Mark V. Albert"], "title": "Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the era of increasingly sophisticated natural language processing (NLP)\nsystems, large language models (LLMs) have demonstrated remarkable potential\nfor diverse applications, including tasks requiring nuanced textual\nunderstanding and contextual reasoning. This study investigates the\ncapabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3,\nMistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex\ntextual dataset comprising social media posts in Russian and Ukrainian.\nSpecifically, the focus is on the binary classification task of identifying\nreferences to human rights violations within the dataset.\n  To evaluate the effectiveness of these models, their annotations are compared\nagainst a gold standard set of human double-annotated labels across 1000\nsamples. The analysis includes assessing annotation performance under different\nprompting conditions, with prompts provided in both English and Russian.\nAdditionally, the study explores the unique patterns of errors and\ndisagreements exhibited by each model, offering insights into their strengths,\nlimitations, and cross-linguistic adaptability.\n  By juxtaposing LLM outputs with human annotations, this research contributes\nto understanding the reliability and applicability of LLMs for sensitive,\ndomain-specific tasks in multilingual contexts. It also sheds light on how\nlanguage models handle inherently subjective and context-dependent judgments, a\ncritical consideration for their deployment in real-world scenarios."}
{"id": "2505.09643", "pdf": "https://arxiv.org/pdf/2505.09643", "abs": "https://arxiv.org/abs/2505.09643", "authors": ["Zhixuan Wang"], "title": "A Computational Approach to Epilepsy Treatment: An AI-optimized Global Natural Product Prescription System", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Epilepsy is a prevalent neurological disease with millions of patients\nworldwide. Many patients have turned to alternative medicine due to the limited\nefficacy and side effects of conventional antiepileptic drugs. In this study,\nwe developed a computational approach to optimize herbal epilepsy treatment\nthrough AI-driven analysis of global natural products and statistically\nvalidated randomized controlled trials (RCTs). Our intelligent prescription\nsystem combines machine learning (ML) algorithms for herb-efficacy\ncharacterization, Bayesian optimization for personalized dosing, and\nmeta-analysis of RCTs for evidence-based recommendations. The system analyzed\n1,872 natural compounds from traditional Chinese medicine (TCM), Ayurveda, and\nethnopharmacological databases, integrating their bioactive properties with\nclinical outcomes from 48 RCTs covering 48 epilepsy conditions (n=5,216). Using\nLASSO regression and SHAP value analysis, we identified 17 high-efficacy herbs\n(e.g., Gastrodia elata [using \\'e for accented characters], Withania\nsomnifera), showing significant seizure reduction (p$<$0.01, Cohen's d=0.89)\nwith statistical significance confirmed by multiple testing (p$<$0.001). A\nrandomized double-blind validation trial (n=120) demonstrated 28.5\\% greater\nseizure frequency reduction with AI-optimized herbal prescriptions compared to\nconventional protocols (95\\% CI: 18.7-37.3\\%, p=0.003)."}
{"id": "2505.10261", "pdf": "https://arxiv.org/pdf/2505.10261", "abs": "https://arxiv.org/abs/2505.10261", "authors": ["Rui Yang", "Huitao Li", "Matthew Yu Heng Wong", "Yuhe Ke", "Xin Li", "Kunyu Yu", "Jingchi Liao", "Jonathan Chong Kai Liew", "Sabarinath Vinod Nair", "Jasmine Chiat Ling Ong", "Irene Li", "Douglas Teodoro", "Chuan Hong", "Daniel Shu Wei Ting", "Nan Liu"], "title": "The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Natural language processing (NLP) has been traditionally applied to medicine,\nand generative large language models (LLMs) have become prominent recently.\nHowever, the differences between them across different medical tasks remain\nunderexplored. We analyzed 19,123 studies, finding that generative LLMs\ndemonstrate advantages in open-ended tasks, while traditional NLP dominates in\ninformation extraction and analysis tasks. As these technologies advance,\nethical use of them is essential to ensure their potential in medical\napplications."}
{"id": "2505.09647", "pdf": "https://arxiv.org/pdf/2505.09647", "abs": "https://arxiv.org/abs/2505.09647", "authors": ["Leighton Pate Barnes", "Stephen Cameron", "Benjamin Howard"], "title": "On Unbiased Low-Rank Approximation with Minimum Distortion", "categories": ["cs.DS", "cs.IT", "cs.LG", "math.IT", "math.PR", "math.ST", "stat.TH"], "comment": null, "summary": "We describe an algorithm for sampling a low-rank random matrix $Q$ that best\napproximates a fixed target matrix $P\\in\\mathbb{C}^{n\\times m}$ in the\nfollowing sense: $Q$ is unbiased, i.e., $\\mathbb{E}[Q] = P$;\n$\\mathsf{rank}(Q)\\leq r$; and $Q$ minimizes the expected Frobenius norm error\n$\\mathbb{E}\\|P-Q\\|_F^2$. Our algorithm mirrors the solution to the efficient\nunbiased sparsification problem for vectors, except applied to the singular\ncomponents of the matrix $P$. Optimality is proven by showing that our\nalgorithm matches the error from an existing lower bound."}
{"id": "2505.10264", "pdf": "https://arxiv.org/pdf/2505.10264", "abs": "https://arxiv.org/abs/2505.10264", "authors": ["Francesco Diana", "André Nusser", "Chuan Xu", "Giovanni Neglia"], "title": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated Learning (FL) enables collaborative training of machine learning\nmodels across distributed clients without sharing raw data, ostensibly\npreserving data privacy. Nevertheless, recent studies have revealed critical\nvulnerabilities in FL, showing that a malicious central server can manipulate\nmodel updates to reconstruct clients' private training data. Existing data\nreconstruction attacks have important limitations: they often rely on\nassumptions about the clients' data distribution or their efficiency\nsignificantly degrades when batch sizes exceed just a few tens of samples.\n  In this work, we introduce a novel data reconstruction attack that overcomes\nthese limitations. Our method leverages a new geometric perspective on fully\nconnected layers to craft malicious model parameters, enabling the perfect\nrecovery of arbitrarily large data batches in classification tasks without any\nprior knowledge of clients' data. Through extensive experiments on both image\nand tabular datasets, we demonstrate that our attack outperforms existing\nmethods and achieves perfect reconstruction of data batches two orders of\nmagnitude larger than the state of the art."}
{"id": "2505.09649", "pdf": "https://arxiv.org/pdf/2505.09649", "abs": "https://arxiv.org/abs/2505.09649", "authors": ["Abisha Thapa Magar", "Anup Shakya"], "title": "Next Word Suggestion using Graph Neural Network", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Language Modeling is a prevalent task in Natural Language Processing. The\ncurrently existing most recent and most successful language models often tend\nto build a massive model with billions of parameters, feed in a tremendous\namount of text data, and train with enormous computation resources which\nrequire millions of dollars. In this project, we aim to address an important\nsub-task in language modeling, i.e., context embedding. We propose an approach\nto exploit the Graph Convolution operation in GNNs to encode the context and\nuse it in coalition with LSTMs to predict the next word given a local context\nof preceding words. We test this on the custom Wikipedia text corpus using a\nvery limited amount of resources and show that this approach works fairly well\nto predict the next word."}
{"id": "2505.10273", "pdf": "https://arxiv.org/pdf/2505.10273", "abs": "https://arxiv.org/abs/2505.10273", "authors": ["Hexu Li", "Konstantinos Kalogiannis", "Ahmed Mohamed Hussain", "Panos Papadimitratos"], "title": "AttentionGuard: Transformer-based Misbehavior Detection for Secure Vehicular Platoons", "categories": ["cs.CR", "cs.AI", "cs.NI"], "comment": "Author's version; Accepted for presentation at the ACM Workshop on\n  Wireless Security and Machine Learning (WiseML 2025)", "summary": "Vehicle platooning, with vehicles traveling in close formation coordinated\nthrough Vehicle-to-Everything (V2X) communications, offers significant benefits\nin fuel efficiency and road utilization. However, it is vulnerable to\nsophisticated falsification attacks by authenticated insiders that can\ndestabilize the formation and potentially cause catastrophic collisions. This\npaper addresses this challenge: misbehavior detection in vehicle platooning\nsystems. We present AttentionGuard, a transformer-based framework for\nmisbehavior detection that leverages the self-attention mechanism to identify\nanomalous patterns in mobility data. Our proposal employs a multi-head\ntransformer-encoder to process sequential kinematic information, enabling\neffective differentiation between normal mobility patterns and falsification\nattacks across diverse platooning scenarios, including steady-state\n(no-maneuver) operation, join, and exit maneuvers. Our evaluation uses an\nextensive simulation dataset featuring various attack vectors (constant,\ngradual, and combined falsifications) and operational parameters (controller\ntypes, vehicle speeds, and attacker positions). Experimental results\ndemonstrate that AttentionGuard achieves up to 0.95 F1-score in attack\ndetection, with robust performance maintained during complex maneuvers.\nNotably, our system performs effectively with minimal latency (100ms decision\nintervals), making it suitable for real-time transportation safety\napplications. Comparative analysis reveals superior detection capabilities and\nestablishes the transformer-encoder as a promising approach for securing\nCooperative Intelligent Transport Systems (C-ITS) against sophisticated insider\nthreats."}
{"id": "2505.09651", "pdf": "https://arxiv.org/pdf/2505.09651", "abs": "https://arxiv.org/abs/2505.09651", "authors": ["Xixuan Hao", "Yutian Jiang", "Xingchen Zou", "Jiabo Liu", "Yifang Yin", "Yuxuan Liang"], "title": "Unlocking Location Intelligence: A Survey from Deep Learning to The LLM Era", "categories": ["cs.DB", "cs.AI", "cs.LG"], "comment": null, "summary": "Location Intelligence (LI), the science of transforming location-centric\ngeospatial data into actionable knowledge, has become a cornerstone of modern\nspatial decision-making. The rapid evolution of Geospatial Representation\nLearning is fundamentally reshaping LI development through two successive\ntechnological revolutions: the deep learning breakthrough and the emerging\nlarge language model (LLM) paradigm. While deep neural networks (DNNs) have\ndemonstrated remarkable success in automated feature extraction from structured\ngeospatial data (e.g., satellite imagery, GPS trajectories), the recent\nintegration of LLMs introduces transformative capabilities for cross-modal\ngeospatial reasoning and unstructured geo-textual data processing. This survey\npresents a comprehensive review of geospatial representation learning across\nboth technological eras, organizing them into a structured taxonomy based on\nthe complete pipeline comprising: (1) data perspective, (2) methodological\nperspective and (3) application perspective. We also highlight current\nadvancements, discuss existing limitations, and propose potential future\nresearch directions in the LLM era. This work offers a thorough exploration of\nthe field and providing a roadmap for further innovation in LI. The summary of\nthe up-to-date paper list can be found in\nhttps://github.com/CityMind-Lab/Awesome-Location-Intelligence and will undergo\ncontinuous updates."}
{"id": "2505.10297", "pdf": "https://arxiv.org/pdf/2505.10297", "abs": "https://arxiv.org/abs/2505.10297", "authors": ["Chibueze Peace Obioma", "Youcheng Sun", "Mustafa A. Mustafa"], "title": "Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Submitted to ESORICS 2025", "summary": "Federated learning (FL) enhances privacy and reduces communication cost for\nresource-constrained edge clients by supporting distributed model training at\nthe edge. However, the heterogeneous nature of such devices produces diverse,\nnon-independent, and identically distributed (non-IID) data, making the\ndetection of backdoor attacks more challenging. In this paper, we propose a\nnovel federated representative-attention-based defense mechanism, named FeRA,\nthat leverages cross-client attention over internal feature representations to\ndistinguish benign from malicious clients. FeRA computes an anomaly score based\non representation reconstruction errors, effectively identifying clients whose\ninternal activations significantly deviate from the group consensus. Our\nevaluation demonstrates FeRA's robustness across various FL scenarios,\nincluding challenging non-IID data distributions typical of edge devices.\nExperimental results show that it effectively reduces backdoor attack success\nrates while maintaining high accuracy on the main task. The method is\nmodel-agnostic, attack-agnostic, and does not require labeled reference data,\nmaking it well suited to heterogeneous and resource-limited edge deployments."}
{"id": "2505.09653", "pdf": "https://arxiv.org/pdf/2505.09653", "abs": "https://arxiv.org/abs/2505.09653", "authors": ["Samuel Yen-Chi Chen", "Chen-Yu Liu", "Kuan-Cheng Chen", "Wei-Jia Huang", "Yen-Jui Chang", "Wei-Hao Huang"], "title": "Differentiable Quantum Architecture Search in Quantum-Enhanced Neural Network Parameter Generation", "categories": ["quant-ph", "cs.AI", "cs.ET", "cs.LG", "cs.NE"], "comment": null, "summary": "The rapid advancements in quantum computing (QC) and machine learning (ML)\nhave led to the emergence of quantum machine learning (QML), which integrates\nthe strengths of both fields. Among QML approaches, variational quantum\ncircuits (VQCs), also known as quantum neural networks (QNNs), have shown\npromise both empirically and theoretically. However, their broader adoption is\nhindered by reliance on quantum hardware during inference. Hardware\nimperfections and limited access to quantum devices pose practical challenges.\nTo address this, the Quantum-Train (QT) framework leverages the exponential\nscaling of quantum amplitudes to generate classical neural network parameters,\nenabling inference without quantum hardware and achieving significant parameter\ncompression. Yet, designing effective quantum circuit architectures for such\nquantum-enhanced neural programmers remains non-trivial and often requires\nexpertise in quantum information science. In this paper, we propose an\nautomated solution using differentiable optimization. Our method jointly\noptimizes both conventional circuit parameters and architectural parameters in\nan end-to-end manner via automatic differentiation. We evaluate the proposed\nframework on classification, time-series prediction, and reinforcement learning\ntasks. Simulation results show that our method matches or outperforms manually\ndesigned QNN architectures. This work offers a scalable and automated pathway\nfor designing QNNs that can generate classical neural network parameters across\ndiverse applications."}
{"id": "2505.10300", "pdf": "https://arxiv.org/pdf/2505.10300", "abs": "https://arxiv.org/abs/2505.10300", "authors": ["Muzhe Wu", "Yanzhi Zhao", "Shuyi Han", "Michael Xieyang Liu", "Hong Shen"], "title": "AI LEGO: Scaffolding Cross-Functional Collaboration in Industrial Responsible AI Practices during Early Design Stages", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Responsible AI (RAI) efforts increasingly emphasize the importance of\naddressing potential harms early in the AI development lifecycle through\nsocial-technical lenses. However, in cross-functional industry teams, this work\nis often stalled by a persistent knowledge handoff challenge: the difficulty of\ntransferring high-level, early-stage technical design rationales from technical\nexperts to non-technical or user-facing roles for ethical evaluation and harm\nidentification. Through literature review and a co-design study with 8\npractitioners, we unpack how this challenge manifests -- technical design\nchoices are rarely handed off in ways that support meaningful engagement by\nnon-technical roles; collaborative workflows lack shared, visual structures to\nsupport mutual understanding; and non-technical practitioners are left without\nscaffolds for systematic harm evaluation. Existing tools like JIRA or Google\nDocs, while useful for product tracking, are ill-suited for supporting joint\nharm identification across roles, often requiring significant extra effort to\nalign understanding. To address this, we developed AI LEGO, a web-based\nprototype that supports cross-functional AI practitioners in effectively\nfacilitating knowledge handoff and identifying harmful design choices in the\nearly design stages. Technical roles use interactive blocks to draft\ndevelopment plans, while non-technical roles engage with those blocks through\nstage-specific checklists and LLM-driven persona simulations to surface\npotential harms. In a study with 18 cross-functional practitioners, AI LEGO\nincreased the volume and likelihood of harms identified compared to baseline\nworksheets. Participants found that its modular structure and persona prompts\nmade harm identification more accessible, fostering clearer and more\ncollaborative RAI practices in early design."}
{"id": "2505.09660", "pdf": "https://arxiv.org/pdf/2505.09660", "abs": "https://arxiv.org/abs/2505.09660", "authors": ["Saptarshi Saha", "Dhruv Vansraj Rathore", "Soumadeep Saha", "Utpal Garain", "David Doermann"], "title": "On Measuring Intrinsic Causal Attributions in Deep Neural Networks", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Quantifying the causal influence of input features within neural networks has\nbecome a topic of increasing interest. Existing approaches typically assess\ndirect, indirect, and total causal effects. This work treats NNs as structural\ncausal models (SCMs) and extends our focus to include intrinsic causal\ncontributions (ICC). We propose an identifiable generative post-hoc framework\nfor quantifying ICC. We also draw a relationship between ICC and Sobol'\nindices. Our experiments on synthetic and real-world datasets demonstrate that\nICC generates more intuitive and reliable explanations compared to existing\nglobal explanation techniques."}
{"id": "2505.10315", "pdf": "https://arxiv.org/pdf/2505.10315", "abs": "https://arxiv.org/abs/2505.10315", "authors": ["Yang Li", "Xinyu Zhou", "Yitong Wang", "Liangxin Qian", "Jun Zhao"], "title": "Private Transformer Inference in MLaaS: A Survey", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Transformer models have revolutionized AI, powering applications like content\ngeneration and sentiment analysis. However, their deployment in Machine\nLearning as a Service (MLaaS) raises significant privacy concerns, primarily\ndue to the centralized processing of sensitive user data. Private Transformer\nInference (PTI) offers a solution by utilizing cryptographic techniques such as\nsecure multi-party computation and homomorphic encryption, enabling inference\nwhile preserving both user data and model privacy. This paper reviews recent\nPTI advancements, highlighting state-of-the-art solutions and challenges. We\nalso introduce a structured taxonomy and evaluation framework for PTI, focusing\non balancing resource efficiency with privacy and bridging the gap between\nhigh-performance inference and data privacy."}
{"id": "2505.09666", "pdf": "https://arxiv.org/pdf/2505.09666", "abs": "https://arxiv.org/abs/2505.09666", "authors": ["Yumin Choi", "Jinheon Baek", "Sung Ju Hwang"], "title": "System Prompt Optimization with Meta-Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance."}
{"id": "2505.10320", "pdf": "https://arxiv.org/pdf/2505.10320", "abs": "https://arxiv.org/abs/2505.10320", "authors": ["Chenxi Whitehouse", "Tianlu Wang", "Ping Yu", "Xian Li", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 8 tables, 11 figures", "summary": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses."}
{"id": "2505.09706", "pdf": "https://arxiv.org/pdf/2505.09706", "abs": "https://arxiv.org/abs/2505.09706", "authors": ["Hugo Gobato Souto", "Francisco Louzada Neto"], "title": "Forests for Differences: Robust Causal Inference Beyond Parametric DiD", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "This paper introduces the Difference-in-Differences Bayesian Causal Forest\n(DiD-BCF), a novel non-parametric model addressing key challenges in DiD\nestimation, such as staggered adoption and heterogeneous treatment effects.\nDiD-BCF provides a unified framework for estimating Average (ATE),\nGroup-Average (GATE), and Conditional Average Treatment Effects (CATE). A core\ninnovation, its Parallel Trends Assumption (PTA)-based reparameterization,\nenhances estimation accuracy and stability in complex panel data settings.\nExtensive simulations demonstrate DiD-BCF's superior performance over\nestablished benchmarks, particularly under non-linearity, selection biases, and\neffect heterogeneity. Applied to U.S. minimum wage policy, the model uncovers\nsignificant conditional treatment effect heterogeneity related to county\npopulation, insights obscured by traditional methods. DiD-BCF offers a robust\nand versatile tool for more nuanced causal inference in modern DiD\napplications."}
{"id": "2505.10321", "pdf": "https://arxiv.org/pdf/2505.10321", "abs": "https://arxiv.org/abs/2505.10321", "authors": ["Julius Henke"], "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "categories": ["cs.CR", "cs.AI"], "comment": "24 pages, 1 figure, for implementation, see\n  https://github.com/JuliusHenke/autopentest", "summary": "A recent area of increasing research is the use of Large Language Models\n(LLMs) in penetration testing, which promises to reduce costs and thus allow\nfor higher frequency. We conduct a review of related work, identifying best\npractices and common evaluation issues. We then present AutoPentest, an\napplication for performing black-box penetration tests with a high degree of\nautonomy. AutoPentest is based on the LLM GPT-4o from OpenAI and the LLM agent\nframework LangChain. It can perform complex multi-step tasks, augmented by\nexternal tools and knowledge bases. We conduct a study on three\ncapture-the-flag style Hack The Box (HTB) machines, comparing our\nimplementation AutoPentest with the baseline approach of manually using the\nChatGPT-4o user interface. Both approaches are able to complete 15-25 % of the\nsubtasks on the HTB machines, with AutoPentest slightly outperforming ChatGPT.\nWe measure a total cost of \\$96.20 US when using AutoPentest across all\nexperiments, while a one-month subscription to ChatGPT Plus costs \\$20. The\nresults show that further implementation efforts and the use of more powerful\nLLMs released in the future are likely to make this a viable part of\nvulnerability management."}
{"id": "2505.09718", "pdf": "https://arxiv.org/pdf/2505.09718", "abs": "https://arxiv.org/abs/2505.09718", "authors": ["Daniel Dylewsky", "Sonia Kéfi", "Madhur Anand", "Chris T. Bauch"], "title": "Neural models for prediction of spatially patterned phase transitions: methods and challenges", "categories": ["physics.comp-ph", "cs.LG"], "comment": null, "summary": "Dryland vegetation ecosystems are known to be susceptible to critical\ntransitions between alternative stable states when subjected to external\nforcing. Such transitions are often discussed through the framework of\nbifurcation theory, but the spatial patterning of vegetation, which is\ncharacteristic of drylands, leads to dynamics that are much more complex and\ndiverse than local bifurcations. Recent methodological developments in Early\nWarning Signal (EWS) detection have shown promise in identifying dynamical\nsignatures of oncoming critical transitions, with particularly strong\npredictive capabilities being demonstrated by deep neural networks. However, a\nmachine learning model trained on synthetic examples is only useful if it can\neffectively transfer to a test case of practical interest. These models'\ncapacity to generalize in this manner has been demonstrated for bifurcation\ntransitions, but it is not as well characterized for high-dimensional phase\ntransitions. This paper explores the successes and shortcomings of neural EWS\ndetection for spatially patterned phase transitions, and shows how these models\ncan be used to gain insight into where and how EWS-relevant information is\nencoded in spatiotemporal dynamics. A few paradigmatic test systems are used to\nillustrate how the capabilities of such models can be probed in a number of\nways, with particular attention to the performances of a number of proposed\nstatistical indicators for EWS and to the supplementary task of distinguishing\nbetween abrupt and continuous transitions. Results reveal that model\nperformance often changes dramatically when training and test data sources are\ninterchanged, which offers new insight into the criteria for model\ngeneralization."}
{"id": "2505.10330", "pdf": "https://arxiv.org/pdf/2505.10330", "abs": "https://arxiv.org/abs/2505.10330", "authors": ["Jonathan Clifford Balloch"], "title": "Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change", "categories": ["cs.LG", "cs.AI"], "comment": "PhD Dissertation, 131 pages", "summary": "Real-world autonomous decision-making systems, from robots to recommendation\nengines, must operate in environments that change over time. While deep\nreinforcement learning (RL) has shown an impressive ability to learn optimal\npolicies in stationary environments, most methods are data intensive and assume\na world that does not change between training and test time. As a result,\nconventional RL methods struggle to adapt when conditions change. This poses a\nfundamental challenge: how can RL agents efficiently adapt their behavior when\nencountering novel environmental changes during deployment without\ncatastrophically forgetting useful prior knowledge? This dissertation\ndemonstrates that efficient online adaptation requires two key capabilities:\n(1) prioritized exploration and sampling strategies that help identify and\nlearn from relevant experiences, and (2) selective preservation of prior\nknowledge through structured representations that can be updated without\ndisruption to reusable components."}
{"id": "2505.09734", "pdf": "https://arxiv.org/pdf/2505.09734", "abs": "https://arxiv.org/abs/2505.09734", "authors": ["Babak Esmaeili", "Nariman Niknejad", "Hamidreza Modares"], "title": "Risk-Aware Safe Reinforcement Learning for Control of Stochastic Linear Systems", "categories": ["eess.SY", "cs.LG", "cs.RO", "cs.SY", "math.OC"], "comment": "Submitted to Asian Journal of Control", "summary": "This paper presents a risk-aware safe reinforcement learning (RL) control\ndesign for stochastic discrete-time linear systems. Rather than using a safety\ncertifier to myopically intervene with the RL controller, a risk-informed safe\ncontroller is also learned besides the RL controller, and the RL and safe\ncontrollers are combined together. Several advantages come along with this\napproach: 1) High-confidence safety can be certified without relying on a\nhigh-fidelity system model and using limited data available, 2) Myopic\ninterventions and convergence to an undesired equilibrium can be avoided by\ndeciding on the contribution of two stabilizing controllers, and 3) highly\nefficient and computationally tractable solutions can be provided by optimizing\nover a scalar decision variable and linear programming polyhedral sets. To\nlearn safe controllers with a large invariant set, piecewise affine controllers\nare learned instead of linear controllers. To this end, the closed-loop system\nis first represented using collected data, a decision variable, and noise. The\neffect of the decision variable on the variance of the safe violation of the\nclosed-loop system is formalized. The decision variable is then designed such\nthat the probability of safety violation for the learned closed-loop system is\nminimized. It is shown that this control-oriented approach reduces the data\nrequirements and can also reduce the variance of safety violations. Finally, to\nintegrate the safe and RL controllers, a new data-driven interpolation\ntechnique is introduced. This method aims to maintain the RL agent's optimal\nimplementation while ensuring its safety within environments characterized by\nnoise. The study concludes with a simulation example that serves to validate\nthe theoretical results."}
{"id": "2505.10331", "pdf": "https://arxiv.org/pdf/2505.10331", "abs": "https://arxiv.org/abs/2505.10331", "authors": ["Luca Muscarnera", "Luigi Loreti", "Giovanni Todeschini", "Alessio Fumagalli", "Francesco Regazzoni"], "title": "Emergence of Structure in Ensembles of Random Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Randomness is ubiquitous in many applications across data science and machine\nlearning. Remarkably, systems composed of random components often display\nemergent global behaviors that appear deterministic, manifesting a transition\nfrom microscopic disorder to macroscopic organization. In this work, we\nintroduce a theoretical model for studying the emergence of collective\nbehaviors in ensembles of random classifiers. We argue that, if the ensemble is\nweighted through the Gibbs measure defined by adopting the classification loss\nas an energy, then there exists a finite temperature parameter for the\ndistribution such that the classification is optimal, with respect to the loss\n(or the energy). Interestingly, for the case in which samples are generated by\na Gaussian distribution and labels are constructed by employing a teacher\nperceptron, we analytically prove and numerically confirm that such optimal\ntemperature does not depend neither on the teacher classifier (which is, by\nconstruction of the learning problem, unknown), nor on the number of random\nclassifiers, highlighting the universal nature of the observed behavior.\nExperiments on the MNIST dataset underline the relevance of this phenomenon in\nhigh-quality, noiseless, datasets. Finally, a physical analogy allows us to\nshed light on the self-organizing nature of the studied phenomenon."}
{"id": "2505.09748", "pdf": "https://arxiv.org/pdf/2505.09748", "abs": "https://arxiv.org/abs/2505.09748", "authors": ["Jitendra K Tugnait"], "title": "Learning Multi-Attribute Differential Graphs with Non-Convex Penalties", "categories": ["stat.ML", "cs.LG", "eess.SP"], "comment": "14 pages, 1 figures, 2 tables, published in IEEE Access, pp.\n  67065-67078, 2025", "summary": "We consider the problem of estimating differences in two multi-attribute\nGaussian graphical models (GGMs) which are known to have similar structure,\nusing a penalized D-trace loss function with non-convex penalties. The GGM\nstructure is encoded in its precision (inverse covariance) matrix. Existing\nmethods for multi-attribute differential graph estimation are based on a group\nlasso penalized loss function. In this paper, we consider a penalized D-trace\nloss function with non-convex (log-sum and smoothly clipped absolute deviation\n(SCAD)) penalties. Two proximal gradient descent methods are presented to\noptimize the objective function. Theoretical analysis establishing sufficient\nconditions for consistency in support recovery, convexity and estimation in\nhigh-dimensional settings is provided. We illustrate our approaches with\nnumerical examples based on synthetic and real data."}
{"id": "2505.10347", "pdf": "https://arxiv.org/pdf/2505.10347", "abs": "https://arxiv.org/abs/2505.10347", "authors": ["Gabriel S. Gama", "Valdir Grassi Jr"], "title": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task\nLearning by addressing issues like conflicting gradients and differing gradient\nnorms, which hinder equal-weighted task training. However, recent critiques\nsuggest that equally weighted tasks can achieve competitive results compared to\nSMTOs, arguing that previous SMTO results were influenced by poor\nhyperparameter optimization and lack of regularization. In this work, we\nevaluate these claims through an extensive empirical evaluation of SMTOs,\nincluding some of the latest methods, on more complex multi-task problems to\nclarify this behavior. Our findings indicate that SMTOs perform well compared\nto uniform loss and that fixed weights can achieve competitive performance\ncompared to SMTOs. Furthermore, we demonstrate why uniform loss perform\nsimilarly to SMTOs in some instances. The code will be made publicly available."}
{"id": "2505.09783", "pdf": "https://arxiv.org/pdf/2505.09783", "abs": "https://arxiv.org/abs/2505.09783", "authors": ["Jianfeng Jiao", "Xi Gao", "Jie Li"], "title": "Pure Component Property Estimation Framework Using Explainable Machine Learning Methods", "categories": ["stat.AP", "cs.LG"], "comment": null, "summary": "Accurate prediction of pure component physiochemical properties is crucial\nfor process integration, multiscale modeling, and optimization. In this work,\nan enhanced framework for pure component property prediction by using\nexplainable machine learning methods is proposed. In this framework, the\nmolecular representation method based on the connectivity matrix effectively\nconsiders atomic bonding relationships to automatically generate features. The\nsupervised machine learning model random forest is applied for feature ranking\nand pooling. The adjusted R2 is introduced to penalize the inclusion of\nadditional features, providing an assessment of the true contribution of\nfeatures. The prediction results for normal boiling point (Tb), liquid molar\nvolume, critical temperature (Tc) and critical pressure (Pc) obtained using\nArtificial Neural Network and Gaussian Process Regression models confirm the\naccuracy of the molecular representation method. Comparison with GC based\nmodels shows that the root-mean-square error on the test set can be reduced by\nup to 83.8%. To enhance the interpretability of the model, a feature analysis\nmethod based on Shapley values is employed to determine the contribution of\neach feature to the property predictions. The results indicate that using the\nfeature pooling method reduces the number of features from 13316 to 100 without\ncompromising model accuracy. The feature analysis results for Tb, Tc, and Pc\nconfirms that different molecular properties are influenced by different\nstructural features, aligning with mechanistic interpretations. In conclusion,\nthe proposed framework is demonstrated to be feasible and provides a solid\nfoundation for mixture component reconstruction and process integration\nmodelling."}
{"id": "2505.10352", "pdf": "https://arxiv.org/pdf/2505.10352", "abs": "https://arxiv.org/abs/2505.10352", "authors": ["Shihao Zou", "Qingfeng Li", "Wei Ji", "Jingjing Li", "Yongkui Yang", "Guoqi Li", "Chao Dong"], "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer"}
{"id": "2505.09798", "pdf": "https://arxiv.org/pdf/2505.09798", "abs": "https://arxiv.org/abs/2505.09798", "authors": ["Bojan Ristov", "Stefan Eftimov", "Milena Trajanoska", "Dimitar Trajanov"], "title": "Ontology-Based Structuring and Analysis of North Macedonian Public Procurement Contracts", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Public procurement plays a critical role in government operations, ensuring\nthe efficient allocation of resources and fostering economic growth. However,\ntraditional procurement data is often stored in rigid, tabular formats,\nlimiting its analytical potential and hindering transparency. This research\npresents a methodological framework for transforming structured procurement\ndata into a semantic knowledge graph, leveraging ontological modeling and\nautomated data transformation techniques. By integrating RDF and SPARQL-based\nquerying, the system enhances the accessibility and interpretability of\nprocurement records, enabling complex semantic queries and advanced analytics.\nFurthermore, by incorporating machine learning-driven predictive modeling, the\nsystem extends beyond conventional data analysis, offering insights into\nprocurement trends and risk assessment. This work contributes to the broader\nfield of public procurement intelligence by improving data transparency,\nsupporting evidence-based decision-making, and enabling in-depth analysis of\nprocurement activities in North Macedonia."}
{"id": "2505.10360", "pdf": "https://arxiv.org/pdf/2505.10360", "abs": "https://arxiv.org/abs/2505.10360", "authors": ["Victor Petrén Bach Hansen", "Lasse Krogsbøll", "Jonas Lyngsø", "Mathias Baltzersen", "Andreas Motzfeldt", "Kevin Pelgrims", "Lars Maaløe"], "title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": null, "summary": "There are now a multitude of AI-scribing solutions for healthcare promising\nthe utilization of large language models for ambient documentation. However,\nthese AI scribes still rely on one-shot, or few-shot prompts for generating\nnotes after the consultation has ended, employing little to no reasoning. This\nrisks long notes with an increase in hallucinations, misrepresentation of the\nintent of the clinician, and reliance on the proofreading of the clinician to\ncatch errors. A dangerous combination for patient safety if vigilance is\ncompromised by workload and fatigue. In this paper, we introduce a method for\nextracting salient clinical information in real-time alongside the healthcare\nconsultation, denoted Facts, and use that information recursively to generate\nthe final note. The FactsR method results in more accurate and concise notes by\nplacing the clinician-in-the-loop of note generation, while opening up new use\ncases within real-time decision support."}
{"id": "2505.09803", "pdf": "https://arxiv.org/pdf/2505.09803", "abs": "https://arxiv.org/abs/2505.09803", "authors": ["Antony Sikorski", "Michael Ivanitskiy", "Nathan Lenssen", "Douglas Nychka", "Daniel McKenzie"], "title": "LatticeVision: Image to Image Networks for Modeling Non-Stationary Spatial Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In many scientific and industrial applications, we are given a handful of\ninstances (a 'small ensemble') of a spatially distributed quantity (a 'field')\nbut would like to acquire many more. For example, a large ensemble of global\ntemperature sensitivity fields from a climate model can help farmers, insurers,\nand governments plan appropriately. When acquiring more data is prohibitively\nexpensive -- as is the case with climate models -- statistical emulation offers\nan efficient alternative for simulating synthetic yet realistic fields.\nHowever, parameter inference using maximum likelihood estimation (MLE) is\ncomputationally prohibitive, especially for large, non-stationary fields. Thus,\nmany recent works train neural networks to estimate parameters given spatial\nfields as input, sidestepping MLE completely. In this work we focus on a\npopular class of parametric, spatially autoregressive (SAR) models. We make a\nsimple yet impactful observation; because the SAR parameters can be arranged on\na regular grid, both inputs (spatial fields) and outputs (model parameters) can\nbe viewed as images. Using this insight, we demonstrate that image-to-image\n(I2I) networks enable faster and more accurate parameter estimation for a class\nof non-stationary SAR models with unprecedented complexity."}
{"id": "2505.10371", "pdf": "https://arxiv.org/pdf/2505.10371", "abs": "https://arxiv.org/abs/2505.10371", "authors": ["Kai Sun", "Peibo Duan", "Levin Kuhlmann", "Beilun Wang", "Bin Zhang"], "title": "ILIF: Temporal Inhibitory Leaky Integrate-and-Fire Neuron for Overactivation in Spiking Neural Networks", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": null, "summary": "The Spiking Neural Network (SNN) has drawn increasing attention for its\nenergy-efficient, event-driven processing and biological plausibility. To train\nSNNs via backpropagation, surrogate gradients are used to approximate the\nnon-differentiable spike function, but they only maintain nonzero derivatives\nwithin a narrow range of membrane potentials near the firing threshold,\nreferred to as the surrogate gradient support width gamma. We identify a major\nchallenge, termed the dilemma of gamma: a relatively large gamma leads to\noveractivation, characterized by excessive neuron firing, which in turn\nincreases energy consumption, whereas a small gamma causes vanishing gradients\nand weakens temporal dependencies. To address this, we propose a temporal\nInhibitory Leaky Integrate-and-Fire (ILIF) neuron model, inspired by biological\ninhibitory mechanisms. This model incorporates interconnected inhibitory units\nfor membrane potential and current, effectively mitigating overactivation while\npreserving gradient propagation. Theoretical analysis demonstrates ILIF\neffectiveness in overcoming the gamma dilemma, and extensive experiments on\nmultiple datasets show that ILIF improves energy efficiency by reducing firing\nrates, stabilizes training, and enhances accuracy. The code is available at\ngithub.com/kaisun1/ILIF."}
{"id": "2505.09805", "pdf": "https://arxiv.org/pdf/2505.09805", "abs": "https://arxiv.org/abs/2505.09805", "authors": ["Aditya Nagori", "Ayush Gautam", "Matthew O. Wiens", "Vuong Nguyen", "Nathan Kenya Mugisha", "Jerome Kabakyenga", "Niranjan Kissoon", "John Mark Ansermino", "Rishikesan Kamaleswaran"], "title": "Contextual Phenotyping of Pediatric Sepsis Cohort Using Large Language Models", "categories": ["q-bio.QM", "cs.AI", "cs.LG", "stat.AP"], "comment": "11 pages, 2 Figures, 1 Table", "summary": "Clustering patient subgroups is essential for personalized care and efficient\nresource use. Traditional clustering methods struggle with high-dimensional,\nheterogeneous healthcare data and lack contextual understanding. This study\nevaluates Large Language Model (LLM) based clustering against classical methods\nusing a pediatric sepsis dataset from a low-income country (LIC), containing\n2,686 records with 28 numerical and 119 categorical variables. Patient records\nwere serialized into text with and without a clustering objective. Embeddings\nwere generated using quantized LLAMA 3.1 8B, DeepSeek-R1-Distill-Llama-8B with\nlow-rank adaptation(LoRA), and Stella-En-400M-V5 models. K-means clustering was\napplied to these embeddings. Classical comparisons included K-Medoids\nclustering on UMAP and FAMD-reduced mixed data. Silhouette scores and\nstatistical tests evaluated cluster quality and distinctiveness.\nStella-En-400M-V5 achieved the highest Silhouette Score (0.86). LLAMA 3.1 8B\nwith the clustering objective performed better with higher number of clusters,\nidentifying subgroups with distinct nutritional, clinical, and socioeconomic\nprofiles. LLM-based methods outperformed classical techniques by capturing\nricher context and prioritizing key features. These results highlight potential\nof LLMs for contextual phenotyping and informed decision-making in\nresource-limited settings."}
{"id": "2505.10375", "pdf": "https://arxiv.org/pdf/2505.10375", "abs": "https://arxiv.org/abs/2505.10375", "authors": ["Rui Melo", "Claudia Mamede", "Andre Catarino", "Rui Abreu", "Henrique Lopes Cardoso"], "title": "Are Sparse Autoencoders Useful for Java Function Bug Detection?", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "10 pages, 10 figures", "summary": "Software vulnerabilities such as buffer overflows and SQL injections are a\nmajor source of security breaches. Traditional methods for vulnerability\ndetection remain essential but are limited by high false positive rates,\nscalability issues, and reliance on manual effort. These constraints have\ndriven interest in AI-based approaches to automated vulnerability detection and\nsecure code generation. While Large Language Models (LLMs) have opened new\navenues for classification tasks, their complexity and opacity pose challenges\nfor interpretability and deployment. Sparse Autoencoder offer a promising\nsolution to this problem. We explore whether SAEs can serve as a lightweight,\ninterpretable alternative for bug detection in Java functions. We evaluate the\neffectiveness of SAEs when applied to representations from GPT-2 Small and\nGemma 2B, examining their capacity to highlight buggy behaviour without\nfine-tuning the underlying LLMs. We found that SAE-derived features enable bug\ndetection with an F1 score of up to 89%, consistently outperforming fine-tuned\ntransformer encoder baselines. Our work provides the first empirical evidence\nthat SAEs can be used to detect software bugs directly from the internal\nrepresentations of pretrained LLMs, without any fine-tuning or task-specific\nsupervision."}
{"id": "2505.09814", "pdf": "https://arxiv.org/pdf/2505.09814", "abs": "https://arxiv.org/abs/2505.09814", "authors": ["Dmitry Rybin", "Yushun Zhang", "Zhi-Quan Luo"], "title": "$XX^{t}$ Can Be Faster", "categories": ["cs.DS", "cs.AI", "cs.LG", "cs.SC", "68Q25, 68T20", "F.2.1; I.1.2"], "comment": null, "summary": "We present a new algorithm RXTX that computes product of matrix by its\ntranspose $XX^{t}$. RXTX uses $5\\%$ less multiplications and additions than\nState-of-the-Art and achieves accelerations even for small sizes of matrix $X$.\nThe algorithm was discovered by combining Machine Learning-based search methods\nwith Combinatorial Optimization."}
{"id": "2505.10387", "pdf": "https://arxiv.org/pdf/2505.10387", "abs": "https://arxiv.org/abs/2505.10387", "authors": ["Artem Agafonov", "Konstantin Yakovlev"], "title": "Multi-Agent Path Finding For Large Agents Is Intractable", "categories": ["cs.MA", "cs.AI", "cs.CC"], "comment": null, "summary": "The multi-agent path finding (MAPF) problem asks to find a set of paths on a\ngraph such that when synchronously following these paths the agents never\nencounter a conflict. In the most widespread MAPF formulation, the so-called\nClassical MAPF, the agents sizes are neglected and two types of conflicts are\nconsidered: occupying the same vertex or using the same edge at the same time\nstep. Meanwhile in numerous practical applications, e.g. in robotics, taking\ninto account the agents' sizes is vital to ensure that the MAPF solutions can\nbe safely executed. Introducing large agents yields an additional type of\nconflict arising when one agent follows an edge and its body overlaps with the\nbody of another agent that is actually not using this same edge (e.g. staying\nstill at some distinct vertex of the graph). Until now it was not clear how\nharder the problem gets when such conflicts are to be considered while\nplanning. Specifically, it was known that Classical MAPF problem on an\nundirected graph can be solved in polynomial time, however no complete\npolynomial-time algorithm was presented to solve MAPF with large agents. In\nthis paper we, for the first time, establish that the latter problem is NP-hard\nand, thus, if P!=NP no polynomial algorithm for it can, unfortunately, be\npresented. Our proof is based on the prevalent in the field technique of\nreducing the seminal 3SAT problem (which is known to be an NP-complete problem)\nto the problem at hand. In particular, for an arbitrary 3SAT formula we\nprocedurally construct a dedicated graph with specific start and goal vertices\nand show that the given 3SAT formula is satisfiable iff the corresponding path\nfinding instance has a solution."}
{"id": "2505.09819", "pdf": "https://arxiv.org/pdf/2505.09819", "abs": "https://arxiv.org/abs/2505.09819", "authors": ["Ruichen Yang", "György M. Lévay", "Christopher L. Hunt", "Dániel Czeiner", "Megan C. Hodgson", "Damini Agarwal", "Rahul R. Kaliki", "Nitish V. Thakor"], "title": "Visual Feedback of Pattern Separability Improves Myoelectric Decoding Performance of Upper Limb Prostheses", "categories": ["cs.HC", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "State-of-the-art upper limb myoelectric prostheses often use pattern\nrecognition (PR) control systems that translate electromyography (EMG) signals\ninto desired movements. As prosthesis movement complexity increases, users\noften struggle to produce sufficiently distinct EMG patterns for reliable\nclassification. Existing training typically involves heuristic, trial-and-error\nuser adjustments to static decoder boundaries. Goal: We introduce the Reviewer,\na 3D visual interface projecting EMG signals directly into the decoder's\nclassification space, providing intuitive, real-time insight into PR algorithm\nbehavior. This structured feedback reduces cognitive load and fosters mutual,\ndata-driven adaptation between user-generated EMG patterns and decoder\nboundaries. Methods: A 10-session study with 12 able-bodied participants\ncompared PR performance after motor-based training and updating using the\nReviewer versus conventional virtual arm visualization. Performance was\nassessed using a Fitts law task that involved the aperture of the cursor and\nthe control of orientation. Results: Participants trained with the Reviewer\nachieved higher completion rates, reduced overshoot, and improved path\nefficiency and throughput compared to the standard visualization group.\nSignificance: The Reviewer introduces decoder-informed motor training,\nfacilitating immediate and consistent PR-based myoelectric control\nimprovements. By iteratively refining control through real-time feedback, this\napproach reduces reliance on trial-and-error recalibration, enabling a more\nadaptive, self-correcting training framework. Conclusion: The 3D visual\nfeedback significantly improves PR control in novice operators through\nstructured training, enabling feedback-driven adaptation and reducing reliance\non extensive heuristic adjustments."}
{"id": "2505.10392", "pdf": "https://arxiv.org/pdf/2505.10392", "abs": "https://arxiv.org/abs/2505.10392", "authors": ["Aryan Mishra", "Lizhen Lin"], "title": "Schreier-Coset Graph Propagation", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 1 figure , preprint", "summary": "Graph Neural Networks (GNNs) offer a principled framework for learning over\ngraph-structured data, yet their expressive capacity is often hindered by\nover-squashing, wherein information from distant nodes is compressed into\nfixed-size vectors. Existing solutions, including graph rewiring and\nbottleneck-resistant architectures such as Cayley and expander graphs, avoid\nthis problem but introduce scalability bottlenecks. In particular, the Cayley\ngraphs constructed over $SL(2,\\mathbb{Z}_n)$ exhibit strong theoretical\nproperties, yet suffer from cubic node growth $O(n^3)$, leading to high memory\nusage. To address this, this work introduces Schrier-Coset Graph Propagation\n(SCGP), a group-theoretic augmentation method that enriches node features\nthrough Schreier-coset embeddings without altering the input graph topology.\nSCGP embeds bottleneck-free connectivity patterns into a compact feature space,\nimproving long-range message passing while maintaining computational\nefficiency. Empirical evaluations across standard node and graph classification\nbenchmarks demonstrate that SCGP achieves performance comparable to, or\nexceeding, expander graph and rewired GNN baselines. Furthermore, SCGP exhibits\nparticular advantages in processing hierarchical and modular graph structures,\noffering reduced inference latency, improved scalability, and a low memory\nfootprint, making it suitable for real-time and resource-constrained\napplications."}
{"id": "2505.09833", "pdf": "https://arxiv.org/pdf/2505.09833", "abs": "https://arxiv.org/abs/2505.09833", "authors": ["Tuba Girgin", "Emre Girgin", "Cagri Kilic"], "title": "Learning Rock Pushability on Rough Planetary Terrain", "categories": ["cs.RO", "cs.LG"], "comment": "Paper presented at the Workshop on Field Robotics, ICRA 2025,\n  Atlanta, GA, United States", "summary": "In the context of mobile navigation in unstructured environments, the\npredominant approach entails the avoidance of obstacles. The prevailing path\nplanning algorithms are contingent upon deviating from the intended path for an\nindefinite duration and returning to the closest point on the route after the\nobstacle is left behind spatially. However, avoiding an obstacle on a path that\nwill be used repeatedly by multiple agents can hinder long-term efficiency and\nlead to a lasting reliance on an active path planning system. In this study, we\npropose an alternative approach to mobile navigation in unstructured\nenvironments by leveraging the manipulation capabilities of a robotic\nmanipulator mounted on top of a mobile robot. Our proposed framework integrates\nexteroceptive and proprioceptive feedback to assess the push affordance of\nobstacles, facilitating their repositioning rather than avoidance. While our\npreliminary visual estimation takes into account the characteristics of both\nthe obstacle and the surface it relies on, the push affordance estimation\nmodule exploits the force feedback obtained by interacting with the obstacle\nvia a robotic manipulator as the guidance signal. The objective of our\nnavigation approach is to enhance the efficiency of routes utilized by multiple\nagents over extended periods by reducing the overall time spent by a fleet in\nenvironments where autonomous infrastructure development is imperative, such as\nlunar or Martian surfaces."}
{"id": "2505.10393", "pdf": "https://arxiv.org/pdf/2505.10393", "abs": "https://arxiv.org/abs/2505.10393", "authors": ["Agustin Medina", "Marcelo Arlego", "Carlos A. Lamas"], "title": "Uncovering Magnetic Phases with Synthetic Data and Physics-Informed Training", "categories": ["cond-mat.str-el", "cs.AI"], "comment": "25 pages, 14 figures", "summary": "We investigate the efficient learning of magnetic phases using artificial\nneural networks trained on synthetic data, combining computational simplicity\nwith physics-informed strategies. Focusing on the diluted Ising model, which\nlacks an exact analytical solution, we explore two complementary approaches: a\nsupervised classification using simple dense neural networks, and an\nunsupervised detection of phase transitions using convolutional autoencoders\ntrained solely on idealized spin configurations.\n  To enhance model performance, we incorporate two key forms of\nphysics-informed guidance. First, we exploit architectural biases which\npreferentially amplify features related to symmetry breaking. Second, we\ninclude training configurations that explicitly break $\\mathbb{Z}_2$ symmetry,\nreinforcing the network's ability to detect ordered phases. These mechanisms,\nacting in tandem, increase the network's sensitivity to phase structure even in\nthe absence of explicit labels. We validate the machine learning predictions\nthrough comparison with direct numerical estimates of critical temperatures and\npercolation thresholds.\n  Our results show that synthetic, structured, and computationally efficient\ntraining schemes can reveal physically meaningful phase boundaries, even in\ncomplex systems. This framework offers a low-cost and robust alternative to\nconventional methods, with potential applications in broader condensed matter\nand statistical physics contexts."}
{"id": "2505.09843", "pdf": "https://arxiv.org/pdf/2505.09843", "abs": "https://arxiv.org/abs/2505.09843", "authors": ["Melissa Turcotte", "François Labrèche", "Serge-Olivier Paquette"], "title": "Automated Alert Classification and Triage (AACT): An Intelligent System for the Prioritisation of Cybersecurity Alerts", "categories": ["cs.CR", "cs.LG", "stat.AP"], "comment": null, "summary": "Enterprise networks are growing ever larger with a rapidly expanding attack\nsurface, increasing the volume of security alerts generated from security\ncontrols. Security Operations Centre (SOC) analysts triage these alerts to\nidentify malicious activity, but they struggle with alert fatigue due to the\noverwhelming number of benign alerts. Organisations are turning to managed SOC\nproviders, where the problem is amplified by context switching and limited\nvisibility into business processes.\n  A novel system, named AACT, is introduced that automates SOC workflows by\nlearning from analysts' triage actions on cybersecurity alerts. It accurately\npredicts triage decisions in real time, allowing benign alerts to be closed\nautomatically and critical ones prioritised. This reduces the SOC queue\nallowing analysts to focus on the most severe, relevant or ambiguous threats.\nThe system has been trained and evaluated on both real SOC data and an open\ndataset, obtaining high performance in identifying malicious alerts from benign\nalerts.\n  Additionally, the system has demonstrated high accuracy in a real SOC\nenvironment, reducing alerts shown to analysts by 61% over six months, with a\nlow false negative rate of 1.36% over millions of alerts."}
{"id": "2505.10394", "pdf": "https://arxiv.org/pdf/2505.10394", "abs": "https://arxiv.org/abs/2505.10394", "authors": ["Meghyn Bienvenu", "Camille Bourgaux", "Atefe Khodadaditaghanaki"], "title": "Inconsistency Handling in DatalogMTL", "categories": ["cs.LO", "cs.AI", "cs.DB"], "comment": "This is an extended version of a paper appearing at the 34th\n  International Joint Conference on Artificial Intelligence (IJCAI 2025). 24\n  pages", "summary": "In this paper, we explore the issue of inconsistency handling in DatalogMTL,\nan extension of Datalog with metric temporal operators. Since facts are\nassociated with time intervals, there are different manners to restore\nconsistency when they contradict the rules, such as removing facts or modifying\ntheir time intervals. Our first contribution is the definition of relevant\nnotions of conflicts (minimal explanations for inconsistency) and repairs\n(possible ways of restoring consistency) for this setting and the study of the\nproperties of these notions and the associated inconsistency-tolerant\nsemantics. Our second contribution is a data complexity analysis of the tasks\nof generating a single conflict / repair and query entailment under\nrepair-based semantics."}
{"id": "2505.09932", "pdf": "https://arxiv.org/pdf/2505.09932", "abs": "https://arxiv.org/abs/2505.09932", "authors": ["Kevin J McNamara", "Rhea Pritham Marpu"], "title": "Demystifying AI Agents: The Final Generation of Intelligence", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.MA"], "comment": null, "summary": "The trajectory of artificial intelligence (AI) has been one of relentless\nacceleration, evolving from rudimentary rule-based systems to sophisticated,\nautonomous agents capable of complex reasoning and interaction. This whitepaper\nchronicles this remarkable journey, charting the key technological\nmilestones--advancements in prompting, training methodologies, hardware\ncapabilities, and architectural innovations--that have converged to create the\nAI agents of today. We argue that these agents, exemplified by systems like\nOpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in\nAI development, potentially constituting the \"final generation\" of intelligence\nas we currently conceive it. We explore the capabilities and underlying\ntechnologies of these agents, grounded in practical examples, while also\nexamining the profound societal implications and the unprecedented pace of\nprogress that suggests intelligence is now doubling approximately every six\nmonths. The paper concludes by underscoring the critical need for wisdom and\nforesight in navigating the opportunities and challenges presented by this\npowerful new era of intelligence."}
{"id": "2505.10402", "pdf": "https://arxiv.org/pdf/2505.10402", "abs": "https://arxiv.org/abs/2505.10402", "authors": ["Yihong Dong", "Yuchen Liu", "Xue Jiang", "Zhi Jin", "Ge Li"], "title": "Rethinking Repetition Problems of LLMs in Code Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to ACL 2025 (main)", "summary": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code."}
{"id": "2505.09935", "pdf": "https://arxiv.org/pdf/2505.09935", "abs": "https://arxiv.org/abs/2505.09935", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Quoc Dai Tran"], "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users."}
{"id": "2505.10405", "pdf": "https://arxiv.org/pdf/2505.10405", "abs": "https://arxiv.org/abs/2505.10405", "authors": ["Jianhao Huang", "Qunsong Zeng", "Kaibin Huang"], "title": "Visual Fidelity Index for Generative Semantic Communications with Critical Information Embedding", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Generative semantic communication (Gen-SemCom) with large artificial\nintelligence (AI) model promises a transformative paradigm for 6G networks,\nwhich reduces communication costs by transmitting low-dimensional prompts\nrather than raw data. However, purely prompt-driven generation loses\nfine-grained visual details. Additionally, there is a lack of systematic\nmetrics to evaluate the performance of Gen-SemCom systems. To address these\nissues, we develop a hybrid Gen-SemCom system with a critical information\nembedding (CIE) framework, where both text prompts and semantically critical\nfeatures are extracted for transmissions. First, a novel approach of semantic\nfiltering is proposed to select and transmit the semantically critical features\nof images relevant to semantic label. By integrating the text prompt and\ncritical features, the receiver reconstructs high-fidelity images using a\ndiffusion-based generative model. Next, we propose the generative visual\ninformation fidelity (GVIF) metric to evaluate the visual quality of the\ngenerated image. By characterizing the statistical models of image features,\nthe GVIF metric quantifies the mutual information between the distorted\nfeatures and their original counterparts. By maximizing the GVIF metric, we\ndesign a channel-adaptive Gen-SemCom system that adaptively control the volume\nof features and compression rate according to the channel state. Experimental\nresults validate the GVIF metric's sensitivity to visual fidelity, correlating\nwith both the PSNR and critical information volume. In addition, the optimized\nsystem achieves superior performance over benchmarking schemes in terms of\nhigher PSNR and lower FID scores."}
{"id": "2505.09945", "pdf": "https://arxiv.org/pdf/2505.09945", "abs": "https://arxiv.org/abs/2505.09945", "authors": ["Deeksha Prahlad", "Chanhee Lee", "Dongha Kim", "Hokeun Kim"], "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)", "summary": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time."}
{"id": "2505.10420", "pdf": "https://arxiv.org/pdf/2505.10420", "abs": "https://arxiv.org/abs/2505.10420", "authors": ["Andrei Arhire", "Radu Timofte"], "title": "Learned Lightweight Smartphone ISP with Unpaired Data", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at CVPRW 2025", "summary": "The Image Signal Processor (ISP) is a fundamental component in modern\nsmartphone cameras responsible for conversion of RAW sensor image data to RGB\nimages with a strong focus on perceptual quality. Recent work highlights the\npotential of deep learning approaches and their ability to capture details with\na quality increasingly close to that of professional cameras. A difficult and\ncostly step when developing a learned ISP is the acquisition of pixel-wise\naligned paired data that maps the raw captured by a smartphone camera sensor to\nhigh-quality reference images. In this work, we address this challenge by\nproposing a novel training method for a learnable ISP that eliminates the need\nfor direct correspondences between raw images and ground-truth data with\nmatching content. Our unpaired approach employs a multi-term loss function\nguided by adversarial training with multiple discriminators processing feature\nmaps from pre-trained networks to maintain content structure while learning\ncolor and texture characteristics from the target RGB dataset. Using\nlightweight neural network architectures suitable for mobile devices as\nbackbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm\nUltraISP datasets. Compared to paired training methods, our unpaired learning\nstrategy shows strong potential and achieves high fidelity across multiple\nevaluation metrics. The code and pre-trained models are available at\nhttps://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data ."}
{"id": "2505.09972", "pdf": "https://arxiv.org/pdf/2505.09972", "abs": "https://arxiv.org/abs/2505.09972", "authors": ["Anchen Sun", "Tiantian Feng", "Gabriela Gutierrez", "Juan J Londono", "Anfeng Xu", "Batya Elbaum", "Shrikanth Narayanan", "Lynn K Perry", "Daniel S Messinger"], "title": "Who Said What WSW 2.0? Enhanced Automated Analysis of Preschool Classroom Speech", "categories": ["eess.AS", "cs.LG"], "comment": "8 pages, 2 figures, 5 tables", "summary": "This paper introduces an automated framework WSW2.0 for analyzing vocal\ninteractions in preschool classrooms, enhancing both accuracy and scalability\nthrough the integration of wav2vec2-based speaker classification and Whisper\n(large-v2 and large-v3) speech transcription. A total of 235 minutes of audio\nrecordings (160 minutes from 12 children and 75 minutes from 5 teachers), were\nused to compare system outputs to expert human annotations. WSW2.0 achieves a\nweighted F1 score of .845, accuracy of .846, and an error-corrected kappa of\n.672 for speaker classification (child vs. teacher). Transcription quality is\nmoderate to high with word error rates of .119 for teachers and .238 for\nchildren. WSW2.0 exhibits relatively high absolute agreement intraclass\ncorrelations (ICC) with expert transcriptions for a range of classroom language\nfeatures. These include teacher and child mean utterance length, lexical\ndiversity, question asking, and responses to questions and other utterances,\nwhich show absolute agreement intraclass correlations between .64 and .98. To\nestablish scalability, we apply the framework to an extensive dataset spanning\ntwo years and over 1,592 hours of classroom audio recordings, demonstrating the\nframework's robustness for broad real-world applications. These findings\nhighlight the potential of deep learning and natural language processing\ntechniques to revolutionize educational research by providing accurate measures\nof key features of preschool classroom speech, ultimately guiding more\neffective intervention strategies and supporting early childhood language\ndevelopment."}
{"id": "2505.10441", "pdf": "https://arxiv.org/pdf/2505.10441", "abs": "https://arxiv.org/abs/2505.10441", "authors": ["Filippo Leveni", "Luca Magri", "Giacomo Boracchi", "Cesare Alippi"], "title": "PIF: Anomaly detection via preference embedding", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)", "summary": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space."}
{"id": "2505.10030", "pdf": "https://arxiv.org/pdf/2505.10030", "abs": "https://arxiv.org/abs/2505.10030", "authors": ["Miit Daga", "Dhriti Parikh", "Swarna Priya Ramu"], "title": "DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera", "categories": ["cs.CV", "cs.LG"], "comment": "This paper is accepted for publication in IEEE Access journal and is\n  currently pending revisions before publication", "summary": "Coconut tree diseases are a serious risk to agricultural yield, particularly\nin developing countries where conventional farming practices restrict early\ndiagnosis and intervention. Current disease identification methods are manual,\nlabor-intensive, and non-scalable. In response to these limitations, we come up\nwith DeepSeqCoco, a deep learning based model for accurate and automatic\ndisease identification from coconut tree images. The model was tested under\nvarious optimizer settings, such as SGD, Adam, and hybrid configurations, to\nidentify the optimal balance between accuracy, minimization of loss, and\ncomputational cost. Results from experiments indicate that DeepSeqCoco can\nachieve as much as 99.5% accuracy (achieving up to 5% higher accuracy than\nexisting models) with the hybrid SGD-Adam showing the lowest validation loss of\n2.81%. It also shows a drop of up to 18% in training time and up to 85% in\nprediction time for input images. The results point out the promise of the\nmodel to improve precision agriculture through an AI-based, scalable, and\nefficient disease monitoring system."}
{"id": "2505.10442", "pdf": "https://arxiv.org/pdf/2505.10442", "abs": "https://arxiv.org/abs/2505.10442", "authors": ["Dechen Gao", "Hang Wang", "Hanchu Zhou", "Nejib Ammar", "Shatadal Mishra", "Ahmadreza Moradipari", "Iman Soltani", "Junshan Zhang"], "title": "IN-RIL: Interleaved Reinforcement and Imitation Learning for Policy Fine-Tuning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Imitation learning (IL) and reinforcement learning (RL) each offer distinct\nadvantages for robotics policy learning: IL provides stable learning from\ndemonstrations, and RL promotes generalization through exploration. While\nexisting robot learning approaches using IL-based pre-training followed by\nRL-based fine-tuning are promising, this two-step learning paradigm often\nsuffers from instability and poor sample efficiency during the RL fine-tuning\nphase. In this work, we introduce IN-RIL, INterleaved Reinforcement learning\nand Imitation Learning, for policy fine-tuning, which periodically injects IL\nupdates after multiple RL updates and hence can benefit from the stability of\nIL and the guidance of expert data for more efficient exploration throughout\nthe entire fine-tuning process. Since IL and RL involve different optimization\nobjectives, we develop gradient separation mechanisms to prevent destructive\ninterference during \\ABBR fine-tuning, by separating possibly conflicting\ngradient updates in orthogonal subspaces. Furthermore, we conduct rigorous\nanalysis, and our findings shed light on why interleaving IL with RL stabilizes\nlearning and improves sample-efficiency. Extensive experiments on 14 robot\nmanipulation and locomotion tasks across 3 benchmarks, including\nFurnitureBench, OpenAI Gym, and Robomimic, demonstrate that \\ABBR can\nsignificantly improve sample efficiency and mitigate performance collapse\nduring online finetuning in both long- and short-horizon tasks with either\nsparse or dense rewards. IN-RIL, as a general plug-in compatible with various\nstate-of-the-art RL algorithms, can significantly improve RL fine-tuning, e.g.,\nfrom 12\\% to 88\\% with 6.3x improvement in the success rate on Robomimic\nTransport. Project page: https://github.com/ucd-dare/IN-RIL."}
{"id": "2505.10033", "pdf": "https://arxiv.org/pdf/2505.10033", "abs": "https://arxiv.org/abs/2505.10033", "authors": ["Luis F. W. Batista", "Stéphanie Aravecchia", "Seth Hutchinson", "Cédric Pradalier"], "title": "Evaluating Robustness of Deep Reinforcement Learning for Autonomous Surface Vehicle Control in Field Tests", "categories": ["cs.RO", "cs.LG"], "comment": "Workshop on Field Robotics at ICRA 2025", "summary": "Despite significant advancements in Deep Reinforcement Learning (DRL) for\nAutonomous Surface Vehicles (ASVs), their robustness in real-world conditions,\nparticularly under external disturbances, remains insufficiently explored. In\nthis paper, we evaluate the resilience of a DRL-based agent designed to capture\nfloating waste under various perturbations. We train the agent using domain\nrandomization and evaluate its performance in real-world field tests, assessing\nits ability to handle unexpected disturbances such as asymmetric drag and an\noff-center payload. We assess the agent's performance under these perturbations\nin both simulation and real-world experiments, quantifying performance\ndegradation and benchmarking it against an MPC baseline. Results indicate that\nthe DRL agent performs reliably despite significant disturbances. Along with\nthe open-source release of our implementation, we provide insights into\neffective training strategies, real-world challenges, and practical\nconsiderations for deploying DRLbased ASV controllers."}
{"id": "2505.10443", "pdf": "https://arxiv.org/pdf/2505.10443", "abs": "https://arxiv.org/abs/2505.10443", "authors": ["Pedro Orvalho", "Marta Kwiatkowska"], "title": "Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?", "categories": ["cs.SE", "cs.AI"], "comment": "10 pages, 5 tables, 1 figure", "summary": "Understanding the reasoning and robustness of Large Language Models (LLMs) is\ncritical for their reliable use in programming tasks. While recent studies have\nassessed LLMs' ability to predict program outputs, most focus solely on the\naccuracy of those predictions, without evaluating the reasoning behind them.\nMoreover, it has been observed on mathematical reasoning tasks that LLMs can\narrive at correct answers through flawed logic, raising concerns about similar\nissues in code understanding.\n  In this work, we evaluate whether state-of-the-art LLMs with up to 8B\nparameters can reason about Python programs or are simply guessing. We apply\nfive semantics-preserving code mutations: renaming variables, mirroring\ncomparison expressions, swapping if-else branches, converting for loops to\nwhile, and loop unrolling. These mutations maintain program semantics while\naltering its syntax. We evaluated six LLMs and performed a human expert\nanalysis using LiveCodeBench to assess whether the correct predictions are\nbased on sound reasoning. We also evaluated prediction stability across\ndifferent code mutations on LiveCodeBench and CruxEval. Our findings show that\nsome LLMs, such as Llama3.2, produce correct predictions based on flawed\nreasoning in up to 61% of cases. Furthermore, LLMs often change predictions in\nresponse to our code mutations, indicating limited robustness in their semantic\nunderstanding."}
{"id": "2505.10066", "pdf": "https://arxiv.org/pdf/2505.10066", "abs": "https://arxiv.org/abs/2505.10066", "authors": ["Michael Fire", "Yitzhak Elbazis", "Adi Wasenstein", "Lior Rokach"], "title": "Dark LLMs: The Growing Threat of Unaligned AI Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50, 68T05, 68P25", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated."}
{"id": "2505.10453", "pdf": "https://arxiv.org/pdf/2505.10453", "abs": "https://arxiv.org/abs/2505.10453", "authors": ["Tyler Tran", "Sangeet Khemlani", "J. G. Trafton"], "title": "Vision language models have difficulty recognizing virtual objects", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision language models (VLMs) are AI systems paired with both language and\nvision encoders to process multimodal input. They are capable of performing\ncomplex semantic tasks such as automatic captioning, but it remains an open\nquestion about how well they comprehend the visuospatial properties of scenes\ndepicted in the images they process. We argue that descriptions of virtual\nobjects -- objects that are not visually represented in an image -- can help\ntest scene comprehension in these AI systems. For example, an image that\ndepicts a person standing under a tree can be paired with the following prompt:\nimagine that a kite is stuck in the tree. VLMs that comprehend the scene should\nupdate their representations and reason sensibly about the spatial relations\nbetween all three objects. We describe systematic evaluations of\nstate-of-the-art VLMs and show that their ability to process virtual objects is\ninadequate."}
{"id": "2505.10080", "pdf": "https://arxiv.org/pdf/2505.10080", "abs": "https://arxiv.org/abs/2505.10080", "authors": ["Weijie Xiong", "Zoë Holmes", "Armando Angrisani", "Yudai Suzuki", "Thiparat Chotibut", "Supanut Thanasilp"], "title": "Role of scrambling and noise in temporal information processing with quantum systems", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.LG", "cs.NE", "stat.ML"], "comment": "14+35 pages, 6+5 figures, 1 table", "summary": "Scrambling quantum systems have been demonstrated as effective substrates for\ntemporal information processing. While their role in providing rich feature\nmaps has been widely studied, a theoretical understanding of their performance\nin temporal tasks is still lacking. Here we consider a general quantum\nreservoir processing framework that captures a broad range of physical\ncomputing models with quantum systems. We examine the scalability and memory\nretention of the model with scrambling reservoirs modelled by high-order\nunitary designs in both noiseless and noisy settings. In the former regime, we\nshow that measurement readouts become exponentially concentrated with\nincreasing reservoir size, yet strikingly do not worsen with the reservoir\niterations. Thus, while repeatedly reusing a small scrambling reservoir with\nquantum data might be viable, scaling up the problem size deteriorates\ngeneralization unless one can afford an exponential shot overhead. In contrast,\nthe memory of early inputs and initial states decays exponentially in both\nreservoir size and reservoir iterations. In the noisy regime, we also prove\nexponential memory decays with iterations for local noisy channels. Proving\nthese results required us to introduce new proof techniques for bounding\nconcentration in temporal quantum learning models."}
{"id": "2505.10457", "pdf": "https://arxiv.org/pdf/2505.10457", "abs": "https://arxiv.org/abs/2505.10457", "authors": ["Matteo Gambella", "Vicente Javier Castro Solar", "Manuel Roveri"], "title": "SEAL: Searching Expandable Architectures for Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "comment": "8 pages, 5 figures", "summary": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios."}
{"id": "2505.10099", "pdf": "https://arxiv.org/pdf/2505.10099", "abs": "https://arxiv.org/abs/2505.10099", "authors": ["Sarat Moka", "Matias Quiroz", "Vali Asimit", "Samuel Muller"], "title": "A Scalable Gradient-Based Optimization Framework for Sparse Minimum-Variance Portfolio Selection", "categories": ["stat.ML", "cs.LG", "math.OC", "q-fin.PM"], "comment": null, "summary": "Portfolio optimization involves selecting asset weights to minimize a\nrisk-reward objective, such as the portfolio variance in the classical\nminimum-variance framework. Sparse portfolio selection extends this by imposing\na cardinality constraint: only $k$ assets from a universe of $p$ may be\nincluded. The standard approach models this problem as a mixed-integer\nquadratic program and relies on commercial solvers to find the optimal\nsolution. However, the computational costs of such methods increase\nexponentially with $k$ and $p$, making them too slow for problems of even\nmoderate size. We propose a fast and scalable gradient-based approach that\ntransforms the combinatorial sparse selection problem into a constrained\ncontinuous optimization task via Boolean relaxation, while preserving\nequivalence with the original problem on the set of binary points. Our\nalgorithm employs a tunable parameter that transmutes the auxiliary objective\nfrom a convex to a concave function. This allows a stable convex starting\npoint, followed by a controlled path toward a sparse binary solution as the\ntuning parameter increases and the objective moves toward concavity. In\npractice, our method matches commercial solvers in asset selection for most\ninstances and, in rare instances, the solution differs by a few assets whilst\nshowing a negligible error in portfolio variance."}
{"id": "2505.10465", "pdf": "https://arxiv.org/pdf/2505.10465", "abs": "https://arxiv.org/abs/2505.10465", "authors": ["Yizhou liu", "Ziming Liu", "Jeff Gore"], "title": "Superposition Yields Robust Neural Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages, 23 figures", "summary": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters."}
{"id": "2505.10134", "pdf": "https://arxiv.org/pdf/2505.10134", "abs": "https://arxiv.org/abs/2505.10134", "authors": ["Guangjin Pan", "Kaixuan Huang", "Hui Chen", "Shunqing Zhang", "Christian Häger", "Henk Wymeersch"], "title": "Large Wireless Localization Model (LWLM): A Foundation Model for Positioning in 6G Networks", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "13 pages,16 figures.This work has been submitted to the IEEE for\n  possible publication", "summary": "Accurate and robust localization is a critical enabler for emerging 5G and 6G\napplications, including autonomous driving, extended reality (XR), and smart\nmanufacturing. While data-driven approaches have shown promise, most existing\nmodels require large amounts of labeled data and struggle to generalize across\ndeployment scenarios and wireless configurations. To address these limitations,\nwe propose a foundation-model-based solution tailored for wireless\nlocalization. We first analyze how different self-supervised learning (SSL)\ntasks acquire general-purpose and task-specific semantic features based on\ninformation bottleneck (IB) theory. Building on this foundation, we design a\npretraining methodology for the proposed Large Wireless Localization Model\n(LWLM). Specifically, we propose an SSL framework that jointly optimizes three\ncomplementary objectives: (i) spatial-frequency masked channel modeling\n(SF-MCM), (ii) domain-transformation invariance (DTI), and (iii)\nposition-invariant contrastive learning (PICL). These objectives jointly\ncapture the underlying semantics of wireless channel from multiple\nperspectives. We further design lightweight decoders for key downstream tasks,\nincluding time-of-arrival (ToA) estimation, angle-of-arrival (AoA) estimation,\nsingle base station (BS) localization, and multiple BS localization.\nComprehensive experimental results confirm that LWLM consistently surpasses\nboth model-based and supervised learning baselines across all localization\ntasks. In particular, LWLM achieves 26.0%--87.5% improvement over transformer\nmodels without pretraining, and exhibits strong generalization under\nlabel-limited fine-tuning and unseen BS configurations, confirming its\npotential as a foundation model for wireless localization."}
{"id": "2505.10482", "pdf": "https://arxiv.org/pdf/2505.10482", "abs": "https://arxiv.org/abs/2505.10482", "authors": ["Ningyuan Yang", "Jiaxuan Gao", "Feng Gao", "Yi Wu", "Chao Yu"], "title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages for main text, 23 pages in total, submitted to Neurips, 13\n  figures", "summary": "Diffusion policies, widely adopted in decision-making scenarios such as\nrobotics, gaming and autonomous driving, are capable of learning diverse skills\nfrom demonstration data due to their high representation power. However, the\nsub-optimal and limited coverage of demonstration data could lead to diffusion\npolicies that generate sub-optimal trajectories and even catastrophic failures.\nWhile reinforcement learning (RL)-based fine-tuning has emerged as a promising\nsolution to address these limitations, existing approaches struggle to\neffectively adapt Proximal Policy Optimization (PPO) to diffusion models. This\nchallenge stems from the computational intractability of action likelihood\nestimation during the denoising process, which leads to complicated\noptimization objectives. In our experiments starting from randomly initialized\npolicies, we find that online tuning of Diffusion Policies demonstrates much\nlower sample efficiency compared to directly applying PPO on MLP policies\n(MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework\nthat reformulates Diffusion Policy as a noise-conditioned deterministic policy.\nBy treating each denoising step as a differentiable transformation conditioned\non pre-sampled noise, NCDPO enables tractable likelihood evaluation and\ngradient backpropagation through all diffusion timesteps. Our experiments\ndemonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when\ntraining from scratch, outperforming existing methods in both sample efficiency\nand final performance across diverse benchmarks, including continuous robot\ncontrol and multi-agent game scenarios. Furthermore, our experimental results\nshow that our method is robust to the number denoising timesteps in the\nDiffusion Policy."}
{"id": "2505.10139", "pdf": "https://arxiv.org/pdf/2505.10139", "abs": "https://arxiv.org/abs/2505.10139", "authors": ["Lorenz Vaitl", "Leon Klein"], "title": "Path Gradients after Flow Matching", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Boltzmann Generators have emerged as a promising machine learning tool for\ngenerating samples from equilibrium distributions of molecular systems using\nNormalizing Flows and importance weighting. Recently, Flow Matching has helped\nspeed up Continuous Normalizing Flows (CNFs), scale them to more complex\nmolecular systems, and minimize the length of the flow integration\ntrajectories. We investigate the benefits of using path gradients to fine-tune\nCNFs initially trained by Flow Matching, in the setting where a target energy\nis known. Our experiments show that this hybrid approach yields up to a\nthreefold increase in sampling efficiency for molecular systems, all while\nusing the same model, a similar computational budget and without the need for\nadditional sampling. Furthermore, by measuring the length of the flow\ntrajectories during fine-tuning, we show that path gradients largely preserve\nthe learned structure of the flow."}
{"id": "2505.10483", "pdf": "https://arxiv.org/pdf/2505.10483", "abs": "https://arxiv.org/abs/2505.10483", "authors": ["Yi Li", "Haonan Wang", "Qixiang Zhang", "Boyu Xiao", "Chenchang Hu", "Hualiang Wang", "Xiaomeng Li"], "title": "UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation", "categories": ["cs.CV", "cs.AI"], "comment": "UniEval is the first evaluation framework designed for unified\n  multimodal models, including a holistic benchmark UniBench and the UniScore\n  metric", "summary": "The emergence of unified multimodal understanding and generation models is\nrapidly attracting attention because of their ability to enhance\ninstruction-following capabilities while minimizing model redundancy. However,\nthere is a lack of a unified evaluation framework for these models, which would\nenable an elegant, simplified, and overall evaluation. Current models conduct\nevaluations on multiple task-specific benchmarks, but there are significant\nlimitations, such as the lack of overall results, errors from extra evaluation\nmodels, reliance on extensive labeled images, benchmarks that lack diversity,\nand metrics with limited capacity for instruction-following evaluation. To\ntackle these challenges, we introduce UniEval, the first evaluation framework\ndesigned for unified multimodal models without extra models, images, or\nannotations. This facilitates a simplified and unified evaluation process. The\nUniEval framework contains a holistic benchmark, UniBench (supports both\nunified and visual generation models), along with the corresponding UniScore\nmetric. UniBench includes 81 fine-grained tags contributing to high diversity.\nExperimental results indicate that UniBench is more challenging than existing\nbenchmarks, and UniScore aligns closely with human evaluations, surpassing\ncurrent metrics. Moreover, we extensively evaluated SoTA unified and visual\ngeneration models, uncovering new insights into Univeral's unique values."}
{"id": "2505.10160", "pdf": "https://arxiv.org/pdf/2505.10160", "abs": "https://arxiv.org/abs/2505.10160", "authors": ["Yannis Montreuil", "Axel Carlier", "Lai Xing Ng", "Wei Tsang Ooi"], "title": "One-Stage Top-$k$ Learning-to-Defer: Score-Based Surrogates with Theoretical Guarantees", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We introduce the first one-stage Top-$k$ Learning-to-Defer framework, which\nunifies prediction and deferral by learning a shared score-based model that\nselects the $k$ most cost-effective entities-labels or experts-per input. While\nexisting one-stage L2D methods are limited to deferring to a single expert, our\napproach jointly optimizes prediction and deferral across multiple entities\nthrough a single end-to-end objective. We define a cost-sensitive loss and\nderive a novel convex surrogate that is independent of the cardinality\nparameter $k$, enabling generalization across Top-$k$ regimes without\nretraining. Our formulation recovers the Top-1 deferral policy of prior\nscore-based methods as a special case, and we prove that our surrogate is both\nBayes-consistent and $\\mathcal{H}$-consistent under mild assumptions. We\nfurther introduce an adaptive variant, Top-$k(x)$, which dynamically selects\nthe number of consulted entities per input to balance predictive accuracy and\nconsultation cost. Experiments on CIFAR-10 and SVHN confirm that our one-stage\nTop-$k$ method strictly outperforms Top-1 deferral, while Top-$k(x)$ achieves\nsuperior accuracy-cost trade-offs by tailoring allocations to input complexity."}
{"id": "2505.10515", "pdf": "https://arxiv.org/pdf/2505.10515", "abs": "https://arxiv.org/abs/2505.10515", "authors": ["Seongun Kim", "Sol A Kim", "Geonhyeong Kim", "Enver Menadjiev", "Chanwoo Lee", "Seongwook Chung", "Nari Kim", "Jaesik Choi"], "title": "PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, post hoc explanation methods have emerged to enhance model\ntransparency by attributing model outputs to input features. However, these\nmethods face challenges due to their specificity to certain neural network\narchitectures and data modalities. Existing explainable artificial intelligence\n(XAI) frameworks have attempted to address these challenges but suffer from\nseveral limitations. These include limited flexibility to diverse model\narchitectures and data modalities due to hard-coded implementations, a\nrestricted number of supported XAI methods because of the requirements for\nlayer-specific operations of attribution methods, and sub-optimal\nrecommendations of explanations due to the lack of evaluation and optimization\nphases. Consequently, these limitations impede the adoption of XAI technology\nin real-world applications, making it difficult for practitioners to select the\noptimal explanation method for their domain. To address these limitations, we\nintroduce \\textbf{PnPXAI}, a universal XAI framework that supports diverse data\nmodalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI\nautomatically detects model architectures, recommends applicable explanation\nmethods, and optimizes hyperparameters for optimal explanations. We validate\nthe framework's effectiveness through user surveys and showcase its versatility\nacross various domains, including medicine and finance."}
{"id": "2505.10169", "pdf": "https://arxiv.org/pdf/2505.10169", "abs": "https://arxiv.org/abs/2505.10169", "authors": ["Matthias Kümmerer", "Harneet Khanuja", "Matthias Bethge"], "title": "Modeling Saliency Dataset Bias", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.10182", "pdf": "https://arxiv.org/pdf/2505.10182", "abs": "https://arxiv.org/abs/2505.10182", "authors": ["Yoichi Ishibashi", "Taro Yano", "Masafumi Oyamada"], "title": "Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant improvements in\nreasoning capabilities through supervised fine-tuning and reinforcement\nlearning. However, when training reasoning models, these approaches are\nprimarily applicable to specific domains such as mathematics and programming,\nwhich imposes fundamental constraints on the breadth and scalability of\ntraining data. In contrast, continual pretraining (CPT) offers the advantage of\nnot requiring task-specific signals. Nevertheless, how to effectively\nsynthesize training data for reasoning and how such data affect a wide range of\ndomains remain largely unexplored. This study provides a detailed evaluation of\nReasoning CPT, a form of CPT that uses synthetic data to reconstruct the hidden\nthought processes underlying texts, based on the premise that texts are the\nresult of the author's thinking process. Specifically, we apply Reasoning CPT\nto Gemma2-9B using synthetic data with hidden thoughts derived from STEM and\nLaw corpora, and compare it to standard CPT on the MMLU benchmark. Our analysis\nreveals that Reasoning CPT consistently improves performance across all\nevaluated domains. Notably, reasoning skills acquired in one domain transfer\neffectively to others; the performance gap with conventional methods widens as\nproblem difficulty increases, with gains of up to 8 points on the most\nchallenging problems. Furthermore, models trained with hidden thoughts learn to\nadjust the depth of their reasoning according to problem difficulty."}
{"id": "2505.10522", "pdf": "https://arxiv.org/pdf/2505.10522", "abs": "https://arxiv.org/abs/2505.10522", "authors": ["Xinrui Wang", "Yan Jin"], "title": "Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) has demonstrated remarkable potential in robotic\nmanipulation but faces challenges in sample inefficiency and lack of\ninterpretability, limiting its applicability in real world scenarios. Enabling\nthe agent to gain a deeper understanding and adapt more efficiently to diverse\nworking scenarios is crucial, and strategic knowledge utilization is a key\nfactor in this process. This paper proposes a Knowledge Capture, Adaptation,\nand Composition (KCAC) framework to systematically integrate knowledge transfer\ninto RL through cross-task curriculum learning. KCAC is evaluated using a two\nblock stacking task in the CausalWorld benchmark, a complex robotic\nmanipulation environment. To our knowledge, existing RL approaches fail to\nsolve this task effectively, reflecting deficiencies in knowledge capture. In\nthis work, we redesign the benchmark reward function by removing rigid\nconstraints and strict ordering, allowing the agent to maximize total rewards\nconcurrently and enabling flexible task completion. Furthermore, we define two\nself-designed sub-tasks and implement a structured cross-task curriculum to\nfacilitate efficient learning. As a result, our KCAC approach achieves a 40\npercent reduction in training time while improving task success rates by 10\npercent compared to traditional RL methods. Through extensive evaluation, we\nidentify key curriculum design parameters subtask selection, transition timing,\nand learning rate that optimize learning efficiency and provide conceptual\nguidance for curriculum based RL frameworks. This work offers valuable insights\ninto curriculum design in RL and robotic learning."}
{"id": "2505.10191", "pdf": "https://arxiv.org/pdf/2505.10191", "abs": "https://arxiv.org/abs/2505.10191", "authors": ["Qingyu Zheng", "Qi Shao", "Guijun Han", "Wei Li", "Hong Li", "Xuan Wang"], "title": "LanTu: Dynamics-Enhanced Deep Learning for Eddy-Resolving Ocean Forecasting", "categories": ["physics.ao-ph", "cs.AI", "cs.LG", "nlin.CD"], "comment": "22 pages, 6 figures", "summary": "Mesoscale eddies dominate the spatiotemporal multiscale variability of the\nocean, and their impact on the energy cascade of the global ocean cannot be\nignored. Eddy-resolving ocean forecasting is providing more reliable protection\nfor fisheries and navigational safety, but also presents significant scientific\nchallenges and high computational costs for traditional numerical models.\nArtificial intelligence (AI)-based weather and ocean forecasting systems are\nbecoming powerful tools that balance forecast performance with computational\nefficiency. However, the complex multiscale features in the ocean dynamical\nsystem make AI models still face many challenges in mesoscale eddy forecasting\n(especially regional modelling). Here, we develop LanTu, a regional\neddy-resolving ocean forecasting system based on dynamics-enhanced deep\nlearning. We incorporate cross-scale interactions into LanTu and construct\nmultiscale physical constraint for optimising LanTu guided by knowledge of eddy\ndynamics in order to improve the forecasting skill of LanTu for mesoscale\nevolution. The results show that LanTu outperforms the existing advanced\noperational numerical ocean forecasting system (NOFS) and AI-based ocean\nforecasting system (AI-OFS) in temperature, salinity, sea level anomaly and\ncurrent prediction, with a lead time of more than 10 days. Our study highlights\nthat dynamics-enhanced deep learning (LanTu) can be a powerful paradigm for\neddy-resolving ocean forecasting."}
{"id": "2505.10537", "pdf": "https://arxiv.org/pdf/2505.10537", "abs": "https://arxiv.org/abs/2505.10537", "authors": ["Filippo Olimpieri", "Noemi Giustini", "Andrea Lacava", "Salvatore D'Oro", "Tommaso Melodia", "Francesca Cuomo"], "title": "LibIQ: Toward Real-Time Spectrum Classification in O-RAN dApps", "categories": ["cs.NI", "cs.AI"], "comment": "6 pages, 5 figures, 2 tables", "summary": "The O-RAN architecture is transforming cellular networks by adopting RAN\nsoftwarization and disaggregation concepts to enable data-driven monitoring and\ncontrol of the network. Such management is enabled by RICs, which facilitate\nnear-real-time and non-real-time network control through xApps and rApps.\nHowever, they face limitations, including latency overhead in data exchange\nbetween the RAN and RIC, restricting real-time monitoring, and the inability to\naccess user plain data due to privacy and security constraints, hindering use\ncases like beamforming and spectrum classification. In this paper, we leverage\nthe dApps concept to enable real-time RF spectrum classification with LibIQ, a\nnovel library for RF signals that facilitates efficient spectrum monitoring and\nsignal classification by providing functionalities to read I/Q samples as\ntime-series, create datasets and visualize time-series data through plots and\nspectrograms. Thanks to LibIQ, I/Q samples can be efficiently processed to\ndetect external RF signals, which are subsequently classified using a CNN\ninside the library. To achieve accurate spectrum analysis, we created an\nextensive dataset of time-series-based I/Q samples, representing distinct\nsignal types captured using a custom dApp running on a 5G deployment over the\nColosseum network emulator and an OTA testbed. We evaluate our model by\ndeploying LibIQ in heterogeneous scenarios with varying center frequencies,\ntime windows, and external RF signals. In real-time analysis, the model\nclassifies the processed I/Q samples, achieving an average accuracy of\napproximately 97.8\\% in identifying signal types across all scenarios. We\npledge to release both LibIQ and the dataset created as a publicly available\nframework upon acceptance."}
{"id": "2505.10223", "pdf": "https://arxiv.org/pdf/2505.10223", "abs": "https://arxiv.org/abs/2505.10223", "authors": ["Puru Vaish", "Felix Meister", "Tobias Heimann", "Christoph Brune", "Jelmer M. Wolterink"], "title": "Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at MIDL 2025", "summary": "Medical image segmentation models are often trained on curated datasets,\nleading to performance degradation when deployed in real-world clinical\nsettings due to mismatches between training and test distributions. While data\naugmentation techniques are widely used to address these challenges,\ntraditional visually consistent augmentation strategies lack the robustness\nneeded for diverse real-world scenarios. In this work, we systematically\nevaluate alternative augmentation strategies, focusing on MixUp and Auxiliary\nFourier Augmentation. These methods mitigate the effects of multiple variations\nwithout explicitly targeting specific sources of distribution shifts. We\ndemonstrate how these techniques significantly improve out-of-distribution\ngeneralization and robustness to imaging variations across a wide range of\ntransformations in cardiac cine MRI and prostate MRI segmentation. We\nquantitatively find that these augmentation methods enhance learned feature\nrepresentations by promoting separability and compactness. Additionally, we\nhighlight how their integration into nnU-Net training pipelines provides an\neasy-to-implement, effective solution for enhancing the reliability of medical\nsegmentation models in real-world applications."}
{"id": "2505.10547", "pdf": "https://arxiv.org/pdf/2505.10547", "abs": "https://arxiv.org/abs/2505.10547", "authors": ["Milan Ganai", "Rohan Sinha", "Christopher Agia", "Daniel Morton", "Marco Pavone"], "title": "Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning", "categories": ["cs.RO", "cs.AI"], "comment": "Website: https://milanganai.github.io/fortress/", "summary": "Foundation models can provide robust high-level reasoning on appropriate\nsafety interventions in hazardous scenarios beyond a robot's training data,\ni.e. out-of-distribution (OOD) failures. However, due to the high inference\nlatency of Large Vision and Language Models, current methods rely on manually\ndefined intervention policies to enact fallbacks, thereby lacking the ability\nto plan generalizable, semantically safe motions. To overcome these challenges\nwe present FORTRESS, a framework that generates and reasons about semantically\nsafe fallback strategies in real time to prevent OOD failures. At a low\nfrequency in nominal operations, FORTRESS uses multi-modal reasoners to\nidentify goals and anticipate failure modes. When a runtime monitor triggers a\nfallback response, FORTRESS rapidly synthesizes plans to fallback goals while\ninferring and avoiding semantically unsafe regions in real time. By bridging\nopen-world, multi-modal reasoning with dynamics-aware planning, we eliminate\nthe need for hard-coded fallbacks and human safety interventions. FORTRESS\noutperforms on-the-fly prompting of slow reasoning models in safety\nclassification accuracy on synthetic benchmarks and real-world ANYmal robot\ndata, and further improves system safety and planning success in simulation and\non quadrotor hardware for urban navigation."}
{"id": "2505.10267", "pdf": "https://arxiv.org/pdf/2505.10267", "abs": "https://arxiv.org/abs/2505.10267", "authors": ["Pavel Korotaev", "Petr Surovtsev", "Alexander Kapitanov", "Karina Kvanchiani", "Aleksandr Nagaev"], "title": "HandReader: Advanced Techniques for Efficient Fingerspelling Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "https://github.com/ai-forever/handreader", "summary": "Fingerspelling is a significant component of Sign Language (SL), allowing the\ninterpretation of proper names, characterized by fast hand movements during\nsigning. Although previous works on fingerspelling recognition have focused on\nprocessing the temporal dimension of videos, there remains room for improving\nthe accuracy of these approaches. This paper introduces HandReader, a group of\nthree architectures designed to address the fingerspelling recognition task.\nHandReader$_{RGB}$ employs the novel Temporal Shift-Adaptive Module (TSAM) to\nprocess RGB features from videos of varying lengths while preserving important\nsequential information. HandReader$_{KP}$ is built on the proposed Temporal\nPose Encoder (TPE) operated on keypoints as tensors. Such keypoints composition\nin a batch allows the encoder to pass them through 2D and 3D convolution\nlayers, utilizing temporal and spatial information and accumulating keypoints\ncoordinates. We also introduce HandReader_RGB+KP - architecture with a joint\nencoder to benefit from RGB and keypoint modalities. Each HandReader model\npossesses distinct advantages and achieves state-of-the-art results on the\nChicagoFSWild and ChicagoFSWild+ datasets. Moreover, the models demonstrate\nhigh performance on the first open dataset for Russian fingerspelling, Znaki,\npresented in this paper. The Znaki dataset and HandReader pre-trained models\nare publicly available."}
{"id": "2505.10551", "pdf": "https://arxiv.org/pdf/2505.10551", "abs": "https://arxiv.org/abs/2505.10551", "authors": ["Yiwen Liu", "Jessica Bader", "Jae Myung Kim"], "title": "Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data", "categories": ["cs.CV", "cs.AI"], "comment": "CVPRW 2025", "summary": "With the development of photorealistic diffusion models, models trained in\npart or fully on synthetic data achieve progressively better results. However,\ndiffusion models still routinely generate images that would not exist in\nreality, such as a dog floating above the ground or with unrealistic texture\nartifacts. We define the concept of feasibility as whether attributes in a\nsynthetic image could realistically exist in the real-world domain; synthetic\nimages containing attributes that violate this criterion are considered\ninfeasible. Intuitively, infeasible images are typically considered\nout-of-distribution; thus, training on such images is expected to hinder a\nmodel's ability to generalize to real-world data, and they should therefore be\nexcluded from the training set whenever possible. However, does feasibility\nreally matter? In this paper, we investigate whether enforcing feasibility is\nnecessary when generating synthetic training data for CLIP-based classifiers,\nfocusing on three target attributes: background, color, and texture. We\nintroduce VariReal, a pipeline that minimally edits a given source image to\ninclude feasible or infeasible attributes given by the textual prompt generated\nby a large language model. Our experiments show that feasibility minimally\naffects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference\nin top-1 accuracy across three fine-grained datasets. Also, the attribute\nmatters on whether the feasible/infeasible images adversarially influence the\nclassification performance. Finally, mixing feasible and infeasible images in\ntraining datasets does not significantly impact performance compared to using\npurely feasible or infeasible datasets."}
{"id": "2505.10279", "pdf": "https://arxiv.org/pdf/2505.10279", "abs": "https://arxiv.org/abs/2505.10279", "authors": ["Gabriel R. Palma", "Sally McClean", "Brahim Allan", "Zeeshan Tariq", "Rafael A. Moral"], "title": "Estimating the number of household TV profiles based in customer behaviour using Gaussian mixture model averaging", "categories": ["stat.ME", "cs.LG"], "comment": "21 pages", "summary": "TV customers today face many choices from many live channels and on-demand\nservices. Providing a personalised experience that saves customers time when\ndiscovering content is essential for TV providers. However, a reliable\nunderstanding of their behaviour and preferences is key. When creating\npersonalised recommendations for TV, the biggest challenge is understanding\nviewing behaviour within households when multiple people are watching. The\nobjective is to detect and combine individual profiles to make\nbetter-personalised recommendations for group viewing. Our challenge is that we\nhave little explicit information about who is watching the devices at any time\n(individuals or groups). Also, we do not have a way to combine more than one\nindividual profile to make better recommendations for group viewing. We propose\na novel framework using a Gaussian mixture model averaging to obtain point\nestimates for the number of household TV profiles and a Bayesian random walk\nmodel to introduce uncertainty. We applied our approach using data from real\ncustomers whose TV-watching data totalled approximately half a million\nobservations. Our results indicate that combining our framework with the\nselected features provides a means to estimate the number of household TV\nprofiles and their characteristics, including shifts over time and\nquantification of uncertainty."}
{"id": "2505.10557", "pdf": "https://arxiv.org/pdf/2505.10557", "abs": "https://arxiv.org/abs/2505.10557", "authors": ["Ke Wang", "Junting Pan", "Linda Wei", "Aojun Zhou", "Weikang Shi", "Zimu Lu", "Han Xiao", "Yunqiao Yang", "Houxing Ren", "Mingjie Zhan", "Hongsheng Li"], "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder."}
{"id": "2505.10319", "pdf": "https://arxiv.org/pdf/2505.10319", "abs": "https://arxiv.org/abs/2505.10319", "authors": ["John Nicol", "Markus Frohme"], "title": "Deconstructing Subset Construction -- Reducing While Determinizing", "categories": ["cs.FL", "cs.LG"], "comment": "19 pages, 2 figures", "summary": "We present a novel perspective on the NFA canonization problem, which\nintroduces intermediate minimization steps to reduce the exploration space\non-the-fly. Essential to our approach are so-called equivalence registries\nwhich manage information about equivalent states and allow for incorporating\nfurther optimization techniques such as convexity closures or simulation to\nboost performance. Due to the generality of our approach, these concepts can be\nembedded in classic subset construction or Brzozowski's approach. We evaluate\nour approach on a set of real-world examples from automatic sequences and\nobserve that we are able to improve especially worst-case scenarios. We\nimplement our approach in an open-source library for users to experiment with."}
{"id": "2505.10559", "pdf": "https://arxiv.org/pdf/2505.10559", "abs": "https://arxiv.org/abs/2505.10559", "authors": ["Ziming Liu", "Yizhou Liu", "Jeff Gore", "Max Tegmark"], "title": "Neural Thermodynamic Laws for Large Language Model Training", "categories": ["cs.LG", "cs.AI", "physics.data-an", "stat.ML"], "comment": "18 pages, 10 figures", "summary": "Beyond neural scaling laws, little is known about the laws underlying large\nlanguage models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new\nframework that offers fresh insights into LLM training dynamics. On the\ntheoretical side, we demonstrate that key thermodynamic quantities (e.g.,\ntemperature, entropy, heat capacity, thermal conduction) and classical\nthermodynamic principles (e.g., the three laws of thermodynamics and the\nequipartition theorem) naturally emerge under river-valley loss landscape\nassumptions. On the practical side, this scientific perspective yields\nintuitive guidelines for designing learning rate schedules."}
{"id": "2505.10320", "pdf": "https://arxiv.org/pdf/2505.10320", "abs": "https://arxiv.org/abs/2505.10320", "authors": ["Chenxi Whitehouse", "Tianlu Wang", "Ping Yu", "Xian Li", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 8 tables, 11 figures", "summary": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses."}
{"id": "2505.10352", "pdf": "https://arxiv.org/pdf/2505.10352", "abs": "https://arxiv.org/abs/2505.10352", "authors": ["Shihao Zou", "Qingfeng Li", "Wei Ji", "Jingjing Li", "Yongkui Yang", "Guoqi Li", "Chao Dong"], "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer"}
{"id": "2505.10361", "pdf": "https://arxiv.org/pdf/2505.10361", "abs": "https://arxiv.org/abs/2505.10361", "authors": ["David Abel", "Michael Bowling", "André Barreto", "Will Dabney", "Shi Dong", "Steven Hansen", "Anna Harutyunyan", "Khimya Khetarpal", "Clare Lyle", "Razvan Pascanu", "Georgios Piliouras", "Doina Precup", "Jonathan Richens", "Mark Rowland", "Tom Schaul", "Satinder Singh"], "title": "Plasticity as the Mirror of Empowerment", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Agents are minimally entities that are influenced by their past observations\nand act to influence future observations. This latter capacity is captured by\nempowerment, which has served as a vital framing concept across artificial\nintelligence and cognitive science. This former capacity, however, is equally\nfoundational: In what ways, and to what extent, can an agent be influenced by\nwhat it observes? In this paper, we ground this concept in a universal\nagent-centric measure that we refer to as plasticity, and reveal a fundamental\nconnection to empowerment. Following a set of desiderata on a suitable\ndefinition, we define plasticity using a new information-theoretic quantity we\ncall the generalized directed information. We show that this new quantity\nstrictly generalizes the directed information introduced by Massey (1990) while\npreserving all of its desirable properties. Our first finding is that\nplasticity is the mirror of empowerment: The agent's plasticity is identical to\nthe empowerment of the environment, and vice versa. Our second finding\nestablishes a tension between the plasticity and empowerment of an agent,\nsuggesting that agent design needs to be mindful of both characteristics. We\nexplore the implications of these findings, and suggest that plasticity,\nempowerment, and their relationship are essential to understanding agency."}
{"id": "2505.10367", "pdf": "https://arxiv.org/pdf/2505.10367", "abs": "https://arxiv.org/abs/2505.10367", "authors": ["Chuanqing Pu", "Feilong Fan", "Nengling Tai", "Songyuan Liu", "Jinming Yu"], "title": "A Hybrid Strategy for Aggregated Probabilistic Forecasting and Energy Trading in HEFTCom2024", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "Solution description of IEEE Hybrid Energy Forecasting and Trading\n  Competition (HEFTCom)", "summary": "Obtaining accurate probabilistic energy forecasts and making effective\ndecisions amid diverse uncertainties are routine challenges in future energy\nsystems. This paper presents the solution of team GEB, which ranked 3rd in\ntrading, 4th in forecasting, and 1st among student teams in the IEEE Hybrid\nEnergy Forecasting and Trading Competition 2024 (HEFTCom2024). The solution\nprovides accurate probabilistic forecasts for a wind-solar hybrid system, and\nachieves substantial trading revenue in the day-ahead electricity market. Key\ncomponents include: (1) a stacking-based approach combining sister forecasts\nfrom various Numerical Weather Predictions (NWPs) to provide wind power\nforecasts, (2) an online solar post-processing model to address the\ndistribution shift in the online test set caused by increased solar capacity,\n(3) a probabilistic aggregation method for accurate quantile forecasts of\nhybrid generation, and (4) a stochastic trading strategy to maximize expected\ntrading revenue considering uncertainties in electricity prices. This paper\nalso explores the potential of end-to-end learning to further enhance the\ntrading revenue by adjusting the distribution of forecast errors. Detailed case\nstudies are provided to validate the effectiveness of these proposed methods.\nCode for all mentioned methods is available for reproduction and further\nresearch in both industry and academia."}
{"id": "2505.10371", "pdf": "https://arxiv.org/pdf/2505.10371", "abs": "https://arxiv.org/abs/2505.10371", "authors": ["Kai Sun", "Peibo Duan", "Levin Kuhlmann", "Beilun Wang", "Bin Zhang"], "title": "ILIF: Temporal Inhibitory Leaky Integrate-and-Fire Neuron for Overactivation in Spiking Neural Networks", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": null, "summary": "The Spiking Neural Network (SNN) has drawn increasing attention for its\nenergy-efficient, event-driven processing and biological plausibility. To train\nSNNs via backpropagation, surrogate gradients are used to approximate the\nnon-differentiable spike function, but they only maintain nonzero derivatives\nwithin a narrow range of membrane potentials near the firing threshold,\nreferred to as the surrogate gradient support width gamma. We identify a major\nchallenge, termed the dilemma of gamma: a relatively large gamma leads to\noveractivation, characterized by excessive neuron firing, which in turn\nincreases energy consumption, whereas a small gamma causes vanishing gradients\nand weakens temporal dependencies. To address this, we propose a temporal\nInhibitory Leaky Integrate-and-Fire (ILIF) neuron model, inspired by biological\ninhibitory mechanisms. This model incorporates interconnected inhibitory units\nfor membrane potential and current, effectively mitigating overactivation while\npreserving gradient propagation. Theoretical analysis demonstrates ILIF\neffectiveness in overcoming the gamma dilemma, and extensive experiments on\nmultiple datasets show that ILIF improves energy efficiency by reducing firing\nrates, stabilizes training, and enhances accuracy. The code is available at\ngithub.com/kaisun1/ILIF."}
{"id": "2505.10375", "pdf": "https://arxiv.org/pdf/2505.10375", "abs": "https://arxiv.org/abs/2505.10375", "authors": ["Rui Melo", "Claudia Mamede", "Andre Catarino", "Rui Abreu", "Henrique Lopes Cardoso"], "title": "Are Sparse Autoencoders Useful for Java Function Bug Detection?", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "10 pages, 10 figures", "summary": "Software vulnerabilities such as buffer overflows and SQL injections are a\nmajor source of security breaches. Traditional methods for vulnerability\ndetection remain essential but are limited by high false positive rates,\nscalability issues, and reliance on manual effort. These constraints have\ndriven interest in AI-based approaches to automated vulnerability detection and\nsecure code generation. While Large Language Models (LLMs) have opened new\navenues for classification tasks, their complexity and opacity pose challenges\nfor interpretability and deployment. Sparse Autoencoder offer a promising\nsolution to this problem. We explore whether SAEs can serve as a lightweight,\ninterpretable alternative for bug detection in Java functions. We evaluate the\neffectiveness of SAEs when applied to representations from GPT-2 Small and\nGemma 2B, examining their capacity to highlight buggy behaviour without\nfine-tuning the underlying LLMs. We found that SAE-derived features enable bug\ndetection with an F1 score of up to 89%, consistently outperforming fine-tuned\ntransformer encoder baselines. Our work provides the first empirical evidence\nthat SAEs can be used to detect software bugs directly from the internal\nrepresentations of pretrained LLMs, without any fine-tuning or task-specific\nsupervision."}
{"id": "2505.10398", "pdf": "https://arxiv.org/pdf/2505.10398", "abs": "https://arxiv.org/abs/2505.10398", "authors": ["Alexandre Banks", "Randy Moore", "Sayem Nazmuz Zaman", "Alaa Eldin Abdelaal", "Septimiu E. Salcudean"], "title": "AutoCam: Hierarchical Path Planning for an Autonomous Auxiliary Camera in Surgical Robotics", "categories": ["cs.RO", "cs.HC", "cs.LG", "cs.SY", "eess.SP", "eess.SY", "J.3.2; J.2.7; I.2.9"], "comment": "13 pages, 9 figures", "summary": "Incorporating an autonomous auxiliary camera into robot-assisted minimally\ninvasive surgery (RAMIS) enhances spatial awareness and eliminates manual\nviewpoint control. Existing path planning methods for auxiliary cameras track\ntwo-dimensional surgical features but do not simultaneously account for camera\norientation, workspace constraints, and robot joint limits. This study presents\nAutoCam: an automatic auxiliary camera placement method to improve\nvisualization in RAMIS. Implemented on the da Vinci Research Kit, the system\nuses a priority-based, workspace-constrained control algorithm that combines\nheuristic geometric placement with nonlinear optimization to ensure robust\ncamera tracking. A user study (N=6) demonstrated that the system maintained\n99.84% visibility of a salient feature and achieved a pose error of 4.36 $\\pm$\n2.11 degrees and 1.95 $\\pm$ 5.66 mm. The controller was computationally\nefficient, with a loop time of 6.8 $\\pm$ 12.8 ms. An additional pilot study\n(N=6), where novices completed a Fundamentals of Laparoscopic Surgery training\ntask, suggests that users can teleoperate just as effectively from AutoCam's\nviewpoint as from the endoscope's while still benefiting from AutoCam's\nimproved visual coverage of the scene. These results indicate that an auxiliary\ncamera can be autonomously controlled using the da Vinci patient-side\nmanipulators to track a salient feature, laying the groundwork for new\nmulti-camera visualization methods in RAMIS."}
{"id": "2505.10399", "pdf": "https://arxiv.org/pdf/2505.10399", "abs": "https://arxiv.org/abs/2505.10399", "authors": ["Kaivalya Rawal", "Zihao Fu", "Eoin Delaney", "Chris Russell"], "title": "Evaluating Model Explanations without Ground Truth", "categories": ["cs.AI", "cs.LG", "I.2.6"], "comment": "https://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth", "summary": "There can be many competing and contradictory explanations for a single model\nprediction, making it difficult to select which one to use. Current explanation\nevaluation frameworks measure quality by comparing against ideal \"ground-truth\"\nexplanations, or by verifying model sensitivity to important inputs. We outline\nthe limitations of these approaches, and propose three desirable principles to\nground the future development of explanation evaluation strategies for local\nfeature importance explanations. We propose a ground-truth Agnostic eXplanation\nEvaluation framework (AXE) for evaluating and comparing model explanations that\nsatisfies these principles. Unlike prior approaches, AXE does not require\naccess to ideal ground-truth explanations for comparison, or rely on model\nsensitivity - providing an independent measure of explanation quality. We\nverify AXE by comparing with baselines, and show how it can be used to detect\nexplanation fairwashing. Our code is available at\nhttps://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth."}
{"id": "2505.10402", "pdf": "https://arxiv.org/pdf/2505.10402", "abs": "https://arxiv.org/abs/2505.10402", "authors": ["Yihong Dong", "Yuchen Liu", "Xue Jiang", "Zhi Jin", "Ge Li"], "title": "Rethinking Repetition Problems of LLMs in Code Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to ACL 2025 (main)", "summary": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code."}
{"id": "2505.10405", "pdf": "https://arxiv.org/pdf/2505.10405", "abs": "https://arxiv.org/abs/2505.10405", "authors": ["Jianhao Huang", "Qunsong Zeng", "Kaibin Huang"], "title": "Visual Fidelity Index for Generative Semantic Communications with Critical Information Embedding", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Generative semantic communication (Gen-SemCom) with large artificial\nintelligence (AI) model promises a transformative paradigm for 6G networks,\nwhich reduces communication costs by transmitting low-dimensional prompts\nrather than raw data. However, purely prompt-driven generation loses\nfine-grained visual details. Additionally, there is a lack of systematic\nmetrics to evaluate the performance of Gen-SemCom systems. To address these\nissues, we develop a hybrid Gen-SemCom system with a critical information\nembedding (CIE) framework, where both text prompts and semantically critical\nfeatures are extracted for transmissions. First, a novel approach of semantic\nfiltering is proposed to select and transmit the semantically critical features\nof images relevant to semantic label. By integrating the text prompt and\ncritical features, the receiver reconstructs high-fidelity images using a\ndiffusion-based generative model. Next, we propose the generative visual\ninformation fidelity (GVIF) metric to evaluate the visual quality of the\ngenerated image. By characterizing the statistical models of image features,\nthe GVIF metric quantifies the mutual information between the distorted\nfeatures and their original counterparts. By maximizing the GVIF metric, we\ndesign a channel-adaptive Gen-SemCom system that adaptively control the volume\nof features and compression rate according to the channel state. Experimental\nresults validate the GVIF metric's sensitivity to visual fidelity, correlating\nwith both the PSNR and critical information volume. In addition, the optimized\nsystem achieves superior performance over benchmarking schemes in terms of\nhigher PSNR and lower FID scores."}
{"id": "2505.10444", "pdf": "https://arxiv.org/pdf/2505.10444", "abs": "https://arxiv.org/abs/2505.10444", "authors": ["Miguel Aguilera", "Sosuke Ito", "Artemy Kolchinsky"], "title": "Inferring entropy production in many-body systems using nonequilibrium MaxEnt", "categories": ["cond-mat.stat-mech", "cs.LG", "nlin.AO", "q-bio.NC"], "comment": null, "summary": "We propose a method for inferring entropy production (EP) in high-dimensional\nstochastic systems, including many-body systems and non-Markovian systems with\nlong memory. Standard techniques for estimating EP become intractable in such\nsystems due to computational and statistical limitations. We infer\ntrajectory-level EP and lower bounds on average EP by exploiting a\nnonequilibrium analogue of the Maximum Entropy principle, along with convex\nduality. Our approach uses only samples of trajectory observables (such as\nspatiotemporal correlation functions). It does not require reconstruction of\nhigh-dimensional probability distributions or rate matrices, nor any special\nassumptions such as discrete states or multipartite dynamics. It may be used to\ncompute a hierarchical decomposition of EP, reflecting contributions from\ndifferent kinds of interactions, and it has an intuitive physical\ninterpretation as a thermodynamic uncertainty relation. We demonstrate its\nnumerical performance on a disordered nonequilibrium spin model with 1000 spins\nand a large neural spike-train dataset."}
{"id": "2505.10448", "pdf": "https://arxiv.org/pdf/2505.10448", "abs": "https://arxiv.org/abs/2505.10448", "authors": ["Conor Rosato", "Harvinder Lehal", "Simon Maskell", "Lee Devlin", "Malcolm Strens"], "title": "Efficient MCMC Sampling with Expensive-to-Compute and Irregular Likelihoods", "categories": ["stat.ML", "cs.LG"], "comment": "45 pages", "summary": "Bayesian inference with Markov Chain Monte Carlo (MCMC) is challenging when\nthe likelihood function is irregular and expensive to compute. We explore\nseveral sampling algorithms that make use of subset evaluations to reduce\ncomputational overhead. We adapt the subset samplers for this setting where\ngradient information is not available or is unreliable. To achieve this, we\nintroduce data-driven proxies in place of Taylor expansions and define a novel\ncomputation-cost aware adaptive controller. We undertake an extensive\nevaluation for a challenging disease modelling task and a configurable task\nwith similar irregularity in the likelihood surface. We find our improved\nversion of Hierarchical Importance with Nested Training Samples (HINTS), with\nadaptive proposals and a data-driven proxy, obtains the best sampling error in\na fixed computational budget. We conclude that subset evaluations can provide\ncheap and naturally-tempered exploration, while a data-driven proxy can\npre-screen proposals successfully in explored regions of the state space. These\ntwo elements combine through hierarchical delayed acceptance to achieve\nefficient, exact sampling."}
{"id": "2505.10466", "pdf": "https://arxiv.org/pdf/2505.10466", "abs": "https://arxiv.org/abs/2505.10466", "authors": ["Juehang Qin", "Shixiao Liang", "Christopher Tunnell"], "title": "FlowVAT: Normalizing Flow Variational Inference with Affine-Invariant Tempering", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": "10 pages, 5 figures, and 2 tables in main text, two appendices", "summary": "Multi-modal and high-dimensional posteriors present significant challenges\nfor variational inference, causing mode-seeking behavior and collapse despite\nthe theoretical expressiveness of normalizing flows. Traditional annealing\nmethods require temperature schedules and hyperparameter tuning, falling short\nof the goal of truly black-box variational inference. We introduce FlowVAT, a\nconditional tempering approach for normalizing flow variational inference that\naddresses these limitations. Our method tempers both the base and target\ndistributions simultaneously, maintaining affine-invariance under tempering. By\nconditioning the normalizing flow on temperature, we leverage overparameterized\nneural networks' generalization capabilities to train a single flow\nrepresenting the posterior across a range of temperatures. This preserves modes\nidentified at higher temperatures when sampling from the variational posterior\nat $T = 1$, mitigating standard variational methods' mode-seeking behavior. In\nexperiments with 2, 10, and 20 dimensional multi-modal distributions, FlowVAT\noutperforms traditional and adaptive annealing methods, finding more modes and\nachieving better ELBO values, particularly in higher dimensions where existing\napproaches fail. Our method requires minimal hyperparameter tuning and does not\nrequire an annealing schedule, advancing toward fully-automatic black-box\nvariational inference for complicated posteriors."}
{"id": "2505.10498", "pdf": "https://arxiv.org/pdf/2505.10498", "abs": "https://arxiv.org/abs/2505.10498", "authors": ["Sakshi Arya"], "title": "Batched Nonparametric Bandits via k-Nearest Neighbor UCB", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH", "68T05, 62L05, 62G08, 68Q32", "F.2.2; I.2.6"], "comment": "25 pages, 6 figures", "summary": "We study sequential decision-making in batched nonparametric contextual\nbandits, where actions are selected over a finite horizon divided into a small\nnumber of batches. Motivated by constraints in domains such as medicine and\nmarketing -- where online feedback is limited -- we propose a nonparametric\nalgorithm that combines adaptive k-nearest neighbor (k-NN) regression with the\nupper confidence bound (UCB) principle. Our method, BaNk-UCB, is fully\nnonparametric, adapts to the context dimension, and is simple to implement.\nUnlike prior work relying on parametric or binning-based estimators, BaNk-UCB\nuses local geometry to estimate rewards and adaptively balances exploration and\nexploitation. We provide near-optimal regret guarantees under standard\nLipschitz smoothness and margin assumptions, using a theoretically motivated\nbatch schedule that balances regret across batches and achieves minimax-optimal\nrates. Empirical evaluations on synthetic and real-world datasets demonstrate\nthat BaNk-UCB consistently outperforms binning-based baselines."}
{"id": "2505.10511", "pdf": "https://arxiv.org/pdf/2505.10511", "abs": "https://arxiv.org/abs/2505.10511", "authors": ["Victor Zheleznov", "Stefan Bilbao", "Alec Wright", "Simon King"], "title": "Learning Nonlinear Dynamics in Physical Modelling Synthesis using Neural Ordinary Differential Equations", "categories": ["cs.SD", "cs.LG", "eess.AS", "physics.comp-ph"], "comment": "Accepted for publication in Proceedings of the 28th International\n  Conference on Digital Audio Effects (DAFx25), Ancona, Italy, September 2025", "summary": "Modal synthesis methods are a long-standing approach for modelling\ndistributed musical systems. In some cases extensions are possible in order to\nhandle geometric nonlinearities. One such case is the high-amplitude vibration\nof a string, where geometric nonlinear effects lead to perceptually important\neffects including pitch glides and a dependence of brightness on striking\namplitude. A modal decomposition leads to a coupled nonlinear system of\nordinary differential equations. Recent work in applied machine learning\napproaches (in particular neural ordinary differential equations) has been used\nto model lumped dynamic systems such as electronic circuits automatically from\ndata. In this work, we examine how modal decomposition can be combined with\nneural ordinary differential equations for modelling distributed musical\nsystems. The proposed model leverages the analytical solution for linear\nvibration of system's modes and employs a neural network to account for\nnonlinear dynamic behaviour. Physical parameters of a system remain easily\naccessible after the training without the need for a parameter encoder in the\nnetwork architecture. As an initial proof of concept, we generate synthetic\ndata for a nonlinear transverse string and show that the model can be trained\nto reproduce the nonlinear dynamics of the system. Sound examples are\npresented."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.10522", "pdf": "https://arxiv.org/pdf/2505.10522", "abs": "https://arxiv.org/abs/2505.10522", "authors": ["Xinrui Wang", "Yan Jin"], "title": "Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) has demonstrated remarkable potential in robotic\nmanipulation but faces challenges in sample inefficiency and lack of\ninterpretability, limiting its applicability in real world scenarios. Enabling\nthe agent to gain a deeper understanding and adapt more efficiently to diverse\nworking scenarios is crucial, and strategic knowledge utilization is a key\nfactor in this process. This paper proposes a Knowledge Capture, Adaptation,\nand Composition (KCAC) framework to systematically integrate knowledge transfer\ninto RL through cross-task curriculum learning. KCAC is evaluated using a two\nblock stacking task in the CausalWorld benchmark, a complex robotic\nmanipulation environment. To our knowledge, existing RL approaches fail to\nsolve this task effectively, reflecting deficiencies in knowledge capture. In\nthis work, we redesign the benchmark reward function by removing rigid\nconstraints and strict ordering, allowing the agent to maximize total rewards\nconcurrently and enabling flexible task completion. Furthermore, we define two\nself-designed sub-tasks and implement a structured cross-task curriculum to\nfacilitate efficient learning. As a result, our KCAC approach achieves a 40\npercent reduction in training time while improving task success rates by 10\npercent compared to traditional RL methods. Through extensive evaluation, we\nidentify key curriculum design parameters subtask selection, transition timing,\nand learning rate that optimize learning efficiency and provide conceptual\nguidance for curriculum based RL frameworks. This work offers valuable insights\ninto curriculum design in RL and robotic learning."}
{"id": "2505.10533", "pdf": "https://arxiv.org/pdf/2505.10533", "abs": "https://arxiv.org/abs/2505.10533", "authors": ["Aaryan Sharma", "Shivansh Gupta", "Samar Agarwal", "Vishak Prasad C.", "Ganesh Ramakrishnan"], "title": "Enhancing Multi-Image Question Answering via Submodular Subset Selection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Large multimodal models (LMMs) have achieved high performance in\nvision-language tasks involving single image but they struggle when presented\nwith a collection of multiple images (Multiple Image Question Answering\nscenario). These tasks, which involve reasoning over large number of images,\npresent issues in scalability (with increasing number of images) and retrieval\nperformance. In this work, we propose an enhancement for retriever framework\nintroduced in MIRAGE model using submodular subset selection techniques. Our\nmethod leverages query-aware submodular functions, such as GraphCut, to\npre-select a subset of semantically relevant images before main retrieval\ncomponent. We demonstrate that using anchor-based queries and augmenting the\ndata improves submodular-retriever pipeline effectiveness, particularly in\nlarge haystack sizes."}
{"id": "2505.09649", "pdf": "https://arxiv.org/pdf/2505.09649", "abs": "https://arxiv.org/abs/2505.09649", "authors": ["Abisha Thapa Magar", "Anup Shakya"], "title": "Next Word Suggestion using Graph Neural Network", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Language Modeling is a prevalent task in Natural Language Processing. The\ncurrently existing most recent and most successful language models often tend\nto build a massive model with billions of parameters, feed in a tremendous\namount of text data, and train with enormous computation resources which\nrequire millions of dollars. In this project, we aim to address an important\nsub-task in language modeling, i.e., context embedding. We propose an approach\nto exploit the Graph Convolution operation in GNNs to encode the context and\nuse it in coalition with LSTMs to predict the next word given a local context\nof preceding words. We test this on the custom Wikipedia text corpus using a\nvery limited amount of resources and show that this approach works fairly well\nto predict the next word."}
{"id": "2505.09655", "pdf": "https://arxiv.org/pdf/2505.09655", "abs": "https://arxiv.org/abs/2505.09655", "authors": ["Xiwen Chen", "Wenhui Zhu", "Peijie Qiu", "Xuanzhao Dong", "Hao Wang", "Haiyu Wu", "Huayu Li", "Aristeidis Sotiras", "Yalin Wang", "Abolfazl Razi"], "title": "DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in reinforcement learning for language model post-training,\nsuch as Group Relative Policy Optimization (GRPO), have shown promise in\nlow-resource settings. However, GRPO typically relies on solution-level and\nscalar reward signals that fail to capture the semantic diversity among sampled\ncompletions. This leads to what we identify as a diversity-quality\ninconsistency, where distinct reasoning paths may receive indistinguishable\nrewards. To address this limitation, we propose $\\textit{Diversity-aware Reward\nAdjustment}$ (DRA), a method that explicitly incorporates semantic diversity\ninto the reward computation. DRA uses Submodular Mutual Information (SMI) to\ndownweight redundant completions and amplify rewards for diverse ones. This\nencourages better exploration during learning, while maintaining stable\nexploitation of high-quality samples. Our method integrates seamlessly with\nboth GRPO and its variant DR.~GRPO, resulting in $\\textit{DRA-GRPO}$ and\n$\\textit{DGA-DR.~GRPO}$. We evaluate our method on five mathematical reasoning\nbenchmarks and find that it outperforms recent strong baselines. It achieves\nstate-of-the-art performance with an average accuracy of 58.2%, using only\n7,000 fine-tuning samples and a total training cost of approximately $55. The\ncode is available at https://github.com/xiwenc1/DRA-GRPO."}
{"id": "2505.09662", "pdf": "https://arxiv.org/pdf/2505.09662", "abs": "https://arxiv.org/abs/2505.09662", "authors": ["Philipp Schoenegger", "Francesco Salvi", "Jiacheng Liu", "Xiaoli Nan", "Ramit Debnath", "Barbara Fasolo", "Evelina Leivada", "Gabriel Recchia", "Fritz Günther", "Ali Zarifhonarvar", "Joe Kwon", "Zahoor Ul Islam", "Marco Dehnert", "Daryl Y. H. Lee", "Madeline G. Reinecke", "David G. Kamper", "Mert Kobaş", "Adam Sandford", "Jonas Kgomo", "Luke Hewitt", "Shreya Kapoor", "Kerem Oktar", "Eyup Engin Kucuk", "Bo Feng", "Cameron R. Jones", "Izzy Gainsburg", "Sebastian Olschewski", "Nora Heinzelmann", "Francisco Cruz", "Ben M. Tappin", "Tao Ma", "Peter S. Park", "Rayan Onyonka", "Arthur Hjorth", "Peter Slattery", "Qingcheng Zeng", "Lennart Finke", "Igor Grossmann", "Alessandro Salatiello", "Ezra Karger"], "title": "Large Language Models Are More Persuasive Than Incentivized Human Persuaders", "categories": ["cs.CL", "I.2.7; H.1.2; K.4.1; H.5.2"], "comment": null, "summary": "We directly compare the persuasion capabilities of a frontier large language\nmodel (LLM; Claude Sonnet 3.5) against incentivized human persuaders in an\ninteractive, real-time conversational quiz setting. In this preregistered,\nlarge-scale incentivized experiment, participants (quiz takers) completed an\nonline quiz where persuaders (either humans or LLMs) attempted to persuade quiz\ntakers toward correct or incorrect answers. We find that LLM persuaders\nachieved significantly higher compliance with their directional persuasion\nattempts than incentivized human persuaders, demonstrating superior persuasive\ncapabilities in both truthful (toward correct answers) and deceptive (toward\nincorrect answers) contexts. We also find that LLM persuaders significantly\nincreased quiz takers' accuracy, leading to higher earnings, when steering quiz\ntakers toward correct answers, and significantly decreased their accuracy,\nleading to lower earnings, when steering them toward incorrect answers.\nOverall, our findings suggest that AI's persuasion capabilities already exceed\nthose of humans that have real-money bonuses tied to performance. Our findings\nof increasingly capable AI persuaders thus underscore the urgency of emerging\nalignment and governance frameworks."}
{"id": "2505.09666", "pdf": "https://arxiv.org/pdf/2505.09666", "abs": "https://arxiv.org/abs/2505.09666", "authors": ["Yumin Choi", "Jinheon Baek", "Sung Ju Hwang"], "title": "System Prompt Optimization with Meta-Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance."}
{"id": "2505.09746", "pdf": "https://arxiv.org/pdf/2505.09746", "abs": "https://arxiv.org/abs/2505.09746", "authors": ["Xabier Morales", "Ayah Elsayed", "Debbie Zhao", "Filip Loncaric", "Ainhoa Aguado", "Mireia Masias", "Gina Quill", "Marc Ramos", "Ada Doltra", "Ana Garcia", "Marta Sitges", "David Marlevi", "Alistair Young", "Martyn Nash", "Bart Bijnens", "Oscar Camara"], "title": "A Computational Pipeline for Advanced Analysis of 4D Flow MRI in the Left Atrium", "categories": ["cs.CV"], "comment": null, "summary": "The left atrium (LA) plays a pivotal role in modulating left ventricular\nfilling, but our comprehension of its hemodynamics is significantly limited by\nthe constraints of conventional ultrasound analysis. 4D flow magnetic resonance\nimaging (4D Flow MRI) holds promise for enhancing our understanding of atrial\nhemodynamics. However, the low velocities within the LA and the limited spatial\nresolution of 4D Flow MRI make analyzing this chamber challenging. Furthermore,\nthe absence of dedicated computational frameworks, combined with diverse\nacquisition protocols and vendors, complicates gathering large cohorts for\nstudying the prognostic value of hemodynamic parameters provided by 4D Flow\nMRI. In this study, we introduce the first open-source computational framework\ntailored for the analysis of 4D Flow MRI in the LA, enabling comprehensive\nqualitative and quantitative analysis of advanced hemodynamic parameters. Our\nframework proves robust to data from different centers of varying quality,\nproducing high-accuracy automated segmentations (Dice $>$ 0.9 and Hausdorff 95\n$<$ 3 mm), even with limited training data. Additionally, we conducted the\nfirst comprehensive assessment of energy, vorticity, and pressure parameters in\nthe LA across a spectrum of disorders to investigate their potential as\nprognostic biomarkers."}
{"id": "2505.09639", "pdf": "https://arxiv.org/pdf/2505.09639", "abs": "https://arxiv.org/abs/2505.09639", "authors": ["Quentin Cohen-Solal"], "title": "Study and improvement of search algorithms in two-players perfect information games", "categories": ["cs.AI", "cs.GT"], "comment": null, "summary": "Games, in their mathematical sense, are everywhere (game industries,\neconomics, defense, education, chemistry, biology, ...).Search algorithms in\ngames are artificial intelligence methods for playing such games.\nUnfortunately, there is no study on these algorithms that evaluates the\ngenerality of their performance. We propose to address this gap in the case of\ntwo-player zero-sum games with perfect information. Furthermore, we propose a\nnew search algorithm and we show that, for a short search time, it outperforms\nall studied algorithms on all games in this large experiment and that, for a\nmedium search time, it outperforms all studied algorithms on 17 of the 22\nstudied games."}
{"id": "2505.09659", "pdf": "https://arxiv.org/pdf/2505.09659", "abs": "https://arxiv.org/abs/2505.09659", "authors": ["Long Chen", "Xiaotian Song", "Yanan Sun"], "title": "LAS: Loss-less ANN-SNN Conversion for Fully Spike-Driven Large Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Spiking Large Language Models (LLMs) have emerged as an energy-efficient\nalternative to conventional LLMs through their event-driven computation. To\neffectively obtain spiking LLMs, researchers develop different ANN-to-SNN\nconversion methods by leveraging pre-trained ANN parameters while inheriting\nthe energy efficiency of SNN. However, existing conversion methods struggle\nwith extreme activation outliers and incompatible nonlinear operations of\nANN-based LLMs. To address this, we propose a loss-less ANN-SNN conversion for\nfully spike-driven LLMs, termed LAS. Specifically, LAS introduces two novel\nneurons to convert the activation outlier and nonlinear operation of ANN-based\nLLMs. Moreover, LAS tailors the spike-equivalent Transformer components for\nspiking LLMs, which can ensure full spiking conversion without any loss of\nperformance. Experimental results on six language models and two\nvision-language models demonstrate that LAS achieves loss-less conversion.\nNotably, on OPT-66B, LAS even improves the accuracy of 2\\% on the WSC task. In\naddition, the parameter and ablation studies further verify the effectiveness\nof LAS. The source code is available at https://github.com/lc783/LAS"}
{"id": "2505.09701", "pdf": "https://arxiv.org/pdf/2505.09701", "abs": "https://arxiv.org/abs/2505.09701", "authors": ["Xin Liu", "Lechen Zhang", "Sheza Munir", "Yiyang Gu", "Lu Wang"], "title": "VeriFact: Enhancing Long-Form Factuality Evaluation with Refined Fact Extraction and Reference Facts", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) excel at generating long-form responses, but\nevaluating their factuality remains challenging due to complex inter-sentence\ndependencies within the generated facts. Prior solutions predominantly follow a\ndecompose-decontextualize-verify pipeline but often fail to capture essential\ncontext and miss key relational facts. In this paper, we introduce VeriFact, a\nfactuality evaluation framework designed to enhance fact extraction by\nidentifying and resolving incomplete and missing facts to support more accurate\nverification results. Moreover, we introduce FactRBench , a benchmark that\nevaluates both precision and recall in long-form model responses, whereas prior\nwork primarily focuses on precision. FactRBench provides reference fact sets\nfrom advanced LLMs and human-written answers, enabling recall assessment.\nEmpirical evaluations show that VeriFact significantly enhances fact\ncompleteness and preserves complex facts with critical relational information,\nresulting in more accurate factuality evaluation. Benchmarking various open-\nand close-weight LLMs on FactRBench indicate that larger models within same\nmodel family improve precision and recall, but high precision does not always\ncorrelate with high recall, underscoring the importance of comprehensive\nfactuality assessment."}
{"id": "2505.09827", "pdf": "https://arxiv.org/pdf/2505.09827", "abs": "https://arxiv.org/abs/2505.09827", "authors": ["Julian Tanke", "Takashi Shibuya", "Kengo Uchida", "Koichi Saito", "Yuki Mitsufuji"], "title": "Dyadic Mamba: Long-term Dyadic Human Motion Synthesis", "categories": ["cs.CV"], "comment": "CVPR 2025 HuMoGen Workshop", "summary": "Generating realistic dyadic human motion from text descriptions presents\nsignificant challenges, particularly for extended interactions that exceed\ntypical training sequence lengths. While recent transformer-based approaches\nhave shown promising results for short-term dyadic motion synthesis, they\nstruggle with longer sequences due to inherent limitations in positional\nencoding schemes. In this paper, we introduce Dyadic Mamba, a novel approach\nthat leverages State-Space Models (SSMs) to generate high-quality dyadic human\nmotion of arbitrary length. Our method employs a simple yet effective\narchitecture that facilitates information flow between individual motion\nsequences through concatenation, eliminating the need for complex\ncross-attention mechanisms. We demonstrate that Dyadic Mamba achieves\ncompetitive performance on standard short-term benchmarks while significantly\noutperforming transformer-based approaches on longer sequences. Additionally,\nwe propose a new benchmark for evaluating long-term motion synthesis quality,\nproviding a standardized framework for future research. Our results demonstrate\nthat SSM-based architectures offer a promising direction for addressing the\nchallenging task of long-term dyadic human motion synthesis from text\ndescriptions."}
{"id": "2505.09640", "pdf": "https://arxiv.org/pdf/2505.09640", "abs": "https://arxiv.org/abs/2505.09640", "authors": ["Tomás Capdevielle", "Santiago Cifuentes"], "title": "Feature Relevancy, Necessity and Usefulness: Complexity and Algorithms", "categories": ["cs.AI", "68T01", "I.2.0"], "comment": "22 pages, 7 figures", "summary": "Given a classification model and a prediction for some input, there are\nheuristic strategies for ranking features according to their importance in\nregard to the prediction. One common approach to this task is rooted in\npropositional logic and the notion of \\textit{sufficient reason}. Through this\nconcept, the categories of relevant and necessary features were proposed in\norder to identify the crucial aspects of the input. This paper improves the\nexisting techniques and algorithms for deciding which are the relevant and/or\nnecessary features, showing in particular that necessity can be detected\nefficiently in complex models such as neural networks. We also generalize the\nnotion of relevancy and study associated problems. Moreover, we present a new\nglobal notion (i.e. that intends to explain whether a feature is important for\nthe behavior of the model in general, not depending on a particular input) of\n\\textit{usefulness} and prove that it is related to relevancy and necessity.\nFurthermore, we develop efficient algorithms for detecting it in decision trees\nand other more complex models, and experiment on three datasets to analyze its\npractical utility."}
{"id": "2505.09663", "pdf": "https://arxiv.org/pdf/2505.09663", "abs": "https://arxiv.org/abs/2505.09663", "authors": ["Julian Büchel", "Iason Chalas", "Giovanni Acampa", "An Chen", "Omobayode Fagbohungbe", "Sidney Tsai", "Kaoutar El Maghraoui", "Manuel Le Gallo", "Abbas Rahimi", "Abu Sebastian"], "title": "Analog Foundation Models", "categories": ["cs.LG"], "comment": "43 pages, 8 figures, under review", "summary": "Analog in-memory computing (AIMC) is a promising compute paradigm to improve\nspeed and power efficiency of neural network inference beyond the limits of\nconventional von Neumann-based architectures. However, AIMC introduces\nfundamental challenges such as noisy computations and strict constraints on\ninput and output quantization. Because of these constraints and imprecisions,\noff-the-shelf LLMs are not able to achieve 4-bit-level performance when\ndeployed on AIMC-based hardware. While researchers previously investigated\nrecovering this accuracy gap on small, mostly vision-based models, a generic\nmethod applicable to LLMs pre-trained on trillions of tokens does not yet\nexist. In this work, we introduce a general and scalable method to robustly\nadapt LLMs for execution on noisy, low-precision analog hardware. Our approach\nenables state-of-the-art models $\\unicode{x2013}$ including\nPhi-3-mini-4k-instruct and Llama-3.2-1B-Instruct $\\unicode{x2013}$ to retain\nperformance comparable to 4-bit weight, 8-bit activation baselines, despite the\npresence of analog noise and quantization constraints. Additionally, we show\nthat as a byproduct of our training methodology, analog foundation models can\nbe quantized for inference on low-precision digital hardware. Finally, we show\nthat our models also benefit from test-time compute scaling, showing better\nscaling behavior than models trained with 4-bit weight and 8-bit static input\nquantization. Our work bridges the gap between high-capacity LLMs and efficient\nanalog hardware, offering a path toward energy-efficient foundation models.\nCode is available at https://github.com/IBM/analog-foundation-models ."}
{"id": "2505.09724", "pdf": "https://arxiv.org/pdf/2505.09724", "abs": "https://arxiv.org/abs/2505.09724", "authors": ["Gino Carmona-Díaz", "William Jiménez-Leal", "María Alejandra Grisales", "Chandra Sripada", "Santiago Amaya", "Michael Inzlicht", "Juan Pablo Bermúdez"], "title": "An AI-Powered Research Assistant in the Lab: A Practical Guide for Text Analysis Through Iterative Collaboration with LLMs", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "31 pages, 1 figure", "summary": "Analyzing texts such as open-ended responses, headlines, or social media\nposts is a time- and labor-intensive process highly susceptible to bias. LLMs\nare promising tools for text analysis, using either a predefined (top-down) or\na data-driven (bottom-up) taxonomy, without sacrificing quality. Here we\npresent a step-by-step tutorial to efficiently develop, test, and apply\ntaxonomies for analyzing unstructured data through an iterative and\ncollaborative process between researchers and LLMs. Using personal goals\nprovided by participants as an example, we demonstrate how to write prompts to\nreview datasets and generate a taxonomy of life domains, evaluate and refine\nthe taxonomy through prompt and direct modifications, test the taxonomy and\nassess intercoder agreements, and apply the taxonomy to categorize an entire\ndataset with high intercoder reliability. We discuss the possibilities and\nlimitations of using LLMs for text analysis."}
{"id": "2505.09829", "pdf": "https://arxiv.org/pdf/2505.09829", "abs": "https://arxiv.org/abs/2505.09829", "authors": ["Tushar Kataria", "Shireen Y. Elhabian"], "title": "BoundarySeg:An Embarrassingly Simple Method To Boost Medical Image Segmentation Performance for Low Data Regimes", "categories": ["cs.CV"], "comment": null, "summary": "Obtaining large-scale medical data, annotated or unannotated, is challenging\ndue to stringent privacy regulations and data protection policies. In addition,\nannotating medical images requires that domain experts manually delineate\nanatomical structures, making the process both time-consuming and costly. As a\nresult, semi-supervised methods have gained popularity for reducing annotation\ncosts. However, the performance of semi-supervised methods is heavily dependent\non the availability of unannotated data, and their effectiveness declines when\nsuch data are scarce or absent. To overcome this limitation, we propose a\nsimple, yet effective and computationally efficient approach for medical image\nsegmentation that leverages only existing annotations. We propose BoundarySeg ,\na multi-task framework that incorporates organ boundary prediction as an\nauxiliary task to full organ segmentation, leveraging consistency between the\ntwo task predictions to provide additional supervision. This strategy improves\nsegmentation accuracy, especially in low data regimes, allowing our method to\nachieve performance comparable to or exceeding state-of-the-art semi supervised\napproaches all without relying on unannotated data or increasing computational\ndemands. Code will be released upon acceptance."}
{"id": "2505.09737", "pdf": "https://arxiv.org/pdf/2505.09737", "abs": "https://arxiv.org/abs/2505.09737", "authors": ["Osher Elhadad", "Reuth Mirsky"], "title": "General Dynamic Goal Recognition", "categories": ["cs.AI", "cs.RO"], "comment": "Accepted for publication at Generalization in Planning (GenPlan) as\n  part of AAAI 2025 workshops", "summary": "Understanding an agent's intent through its behavior is essential in\nhuman-robot interaction, interactive AI systems, and multi-agent\ncollaborations. This task, known as Goal Recognition (GR), poses significant\nchallenges in dynamic environments where goals are numerous and constantly\nevolving. Traditional GR methods, designed for a predefined set of goals, often\nstruggle to adapt to these dynamic scenarios. To address this limitation, we\nintroduce the General Dynamic GR problem - a broader definition of GR - aimed\nat enabling real-time GR systems and fostering further research in this area.\nExpanding on this foundation, this paper employs a model-free goal-conditioned\nRL approach to enable fast adaptation for GR across various changing tasks."}
{"id": "2505.09702", "pdf": "https://arxiv.org/pdf/2505.09702", "abs": "https://arxiv.org/abs/2505.09702", "authors": ["Yezi Liu", "Prathyush Poduval", "Wenjun Huang", "Yang Ni", "Hanning Chen", "Mohsen Imani"], "title": "Enabling Group Fairness in Graph Unlearning via Bi-level Debiasing", "categories": ["cs.LG"], "comment": null, "summary": "Graph unlearning is a crucial approach for protecting user privacy by erasing\nthe influence of user data on trained graph models. Recent developments in\ngraph unlearning methods have primarily focused on maintaining model prediction\nperformance while removing user information. However, we have observed that\nwhen user information is deleted from the model, the prediction distribution\nacross different sensitive groups often changes. Furthermore, graph models are\nshown to be prone to amplifying biases, making the study of fairness in graph\nunlearning particularly important. This raises the question: Does graph\nunlearning actually introduce bias? Our findings indicate that the predictions\nof post-unlearning models become highly correlated with sensitive attributes,\nconfirming the introduction of bias in the graph unlearning process. To address\nthis issue, we propose a fair graph unlearning method, FGU. To guarantee\nprivacy, FGU trains shard models on partitioned subgraphs, unlearns the\nrequested data from the corresponding subgraphs, and retrains the shard models\non the modified subgraphs. To ensure fairness, FGU employs a bi-level debiasing\nprocess: it first enables shard-level fairness by incorporating a fairness\nregularizer in the shard model retraining, and then achieves global-level\nfairness by aligning all shard models to minimize global disparity. Our\nexperiments demonstrate that FGU achieves superior fairness while maintaining\nprivacy and accuracy. Additionally, FGU is robust to diverse unlearning\nrequests, ensuring fairness and utility performance across various data\ndistributions."}
{"id": "2505.09738", "pdf": "https://arxiv.org/pdf/2505.09738", "abs": "https://arxiv.org/abs/2505.09738", "authors": ["Shaurya Sharthak", "Vinayak Pahalwan", "Adithya Kamath", "Adarsh Shirawalmath"], "title": "Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Pretrained language models (LLMs) are often constrained by their fixed\ntokenization schemes, leading to inefficiencies and performance limitations,\nparticularly for multilingual or specialized applications. This tokenizer\nlock-in presents significant challenges. standard methods to overcome this\noften require prohibitive computational resources. Although tokenizer\nreplacement with heuristic initialization aims to reduce this burden, existing\nmethods often require exhaustive residual fine-tuning and still may not fully\npreserve semantic nuances or adequately address the underlying compression\ninefficiencies. Our framework introduces two innovations: first, Tokenadapt, a\nmodel-agnostic tokenizer transplantation method, and second, novel\npre-tokenization learning for multi-word Supertokens to enhance compression and\nreduce fragmentation. Tokenadapt initializes new unique token embeddings via a\nhybrid heuristic that combines two methods: a local estimate based on subword\ndecomposition using the old tokenizer, and a global estimate utilizing the\ntop-k semantically similar tokens from the original vocabulary. This\nmethodology aims to preserve semantics while significantly minimizing\nretraining requirements. Empirical investigations validate both contributions:\nthe transplantation heuristic successfully initializes unique tokens, markedly\noutperforming conventional baselines and sophisticated methods including\nTranstokenizer and ReTok, while our Supertokens achieve notable compression\ngains. Our zero-shot perplexity results demonstrate that the TokenAdapt hybrid\ninitialization consistently yields lower perplexity ratios compared to both\nReTok and TransTokenizer baselines across different base models and newly\ntrained target tokenizers. TokenAdapt typically reduced the overall perplexity\nratio significantly compared to ReTok, yielding at least a 2-fold improvement\nin these aggregate scores."}
{"id": "2505.09858", "pdf": "https://arxiv.org/pdf/2505.09858", "abs": "https://arxiv.org/abs/2505.09858", "authors": ["Danush Kumar Venkatesh", "Isabel Funke", "Micha Pfeiffer", "Fiona Kolbinger", "Hanna Maria Schmeiser", "Juergen Weitz", "Marius Distler", "Stefanie Speidel"], "title": "Mission Balance: Generating Under-represented Class Samples using Video Diffusion Models", "categories": ["cs.CV"], "comment": "Early accept at MICCAI 2025", "summary": "Computer-assisted interventions can improve intra-operative guidance,\nparticularly through deep learning methods that harness the spatiotemporal\ninformation in surgical videos. However, the severe data imbalance often found\nin surgical video datasets hinders the development of high-performing models.\nIn this work, we aim to overcome the data imbalance by synthesizing surgical\nvideos. We propose a unique two-stage, text-conditioned diffusion-based method\nto generate high-fidelity surgical videos for under-represented classes. Our\napproach conditions the generation process on text prompts and decouples\nspatial and temporal modeling by utilizing a 2D latent diffusion model to\ncapture spatial content and then integrating temporal attention layers to\nensure temporal consistency. Furthermore, we introduce a rejection sampling\nstrategy to select the most suitable synthetic samples, effectively augmenting\nexisting datasets to address class imbalance. We evaluate our method on two\ndownstream tasks-surgical action recognition and intra-operative event\nprediction-demonstrating that incorporating synthetic videos from our approach\nsubstantially enhances model performance. We open-source our implementation at\nhttps://gitlab.com/nct_tso_public/surgvgen."}
{"id": "2505.09755", "pdf": "https://arxiv.org/pdf/2505.09755", "abs": "https://arxiv.org/abs/2505.09755", "authors": ["Amy Rafferty", "Rishi Ramaesh", "Ajitha Rajan"], "title": "Explainability Through Human-Centric Design for XAI in Lung Cancer Detection", "categories": ["cs.AI"], "comment": null, "summary": "Deep learning models have shown promise in lung pathology detection from\nchest X-rays, but widespread clinical adoption remains limited due to opaque\nmodel decision-making. In prior work, we introduced ClinicXAI, a human-centric,\nexpert-guided concept bottleneck model (CBM) designed for interpretable lung\ncancer diagnosis. We now extend that approach and present XpertXAI, a\ngeneralizable expert-driven model that preserves human-interpretable clinical\nconcepts while scaling to detect multiple lung pathologies. Using a\nhigh-performing InceptionV3-based classifier and a public dataset of chest\nX-rays with radiology reports, we compare XpertXAI against leading post-hoc\nexplainability methods and an unsupervised CBM, XCBs. We assess explanations\nthrough comparison with expert radiologist annotations and medical ground\ntruth. Although XpertXAI is trained for multiple pathologies, our expert\nvalidation focuses on lung cancer. We find that existing techniques frequently\nfail to produce clinically meaningful explanations, omitting key diagnostic\nfeatures and disagreeing with radiologist judgments. XpertXAI not only\noutperforms these baselines in predictive accuracy but also delivers\nconcept-level explanations that better align with expert reasoning. While our\nfocus remains on explainability in lung cancer detection, this work illustrates\nhow human-centric model design can be effectively extended to broader\ndiagnostic contexts - offering a scalable path toward clinically meaningful\nexplainable AI in medical diagnostics."}
{"id": "2505.09704", "pdf": "https://arxiv.org/pdf/2505.09704", "abs": "https://arxiv.org/abs/2505.09704", "authors": ["Roberto Pereira", "Fernanda Famá", "Charalampos Kalalas", "Paolo Dini"], "title": "Energy-Efficient Federated Learning for AIoT using Clustering Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While substantial research has been devoted to optimizing model performance,\nconvergence rates, and communication efficiency, the energy implications of\nfederated learning (FL) within Artificial Intelligence of Things (AIoT)\nscenarios are often overlooked in the existing literature. This study examines\nthe energy consumed during the FL process, focusing on three main\nenergy-intensive processes: pre-processing, communication, and local learning,\nall contributing to the overall energy footprint. We rely on the observation\nthat device/client selection is crucial for speeding up the convergence of\nmodel training in a distributed AIoT setting and propose two\nclustering-informed methods. These clustering solutions are designed to group\nAIoT devices with similar label distributions, resulting in clusters composed\nof nearly heterogeneous devices. Hence, our methods alleviate the heterogeneity\noften encountered in real-world distributed learning applications. Throughout\nextensive numerical experimentation, we demonstrate that our clustering\nstrategies typically achieve high convergence rates while maintaining low\nenergy consumption when compared to other recent approaches available in the\nliterature."}
{"id": "2505.09794", "pdf": "https://arxiv.org/pdf/2505.09794", "abs": "https://arxiv.org/abs/2505.09794", "authors": ["J. Moreno-Casanova", "J. M. Auñón", "A. Mártinez-Pérez", "M. E. Pérez-Martínez", "M. E. Gas-López"], "title": "Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Research projects, including those focused on cancer, rely on the manual\nextraction of information from clinical reports. This process is time-consuming\nand prone to errors, limiting the efficiency of data-driven approaches in\nhealthcare. To address these challenges, Natural Language Processing (NLP)\noffers an alternative for automating the extraction of relevant data from\nelectronic health records (EHRs). In this study, we focus on lung and breast\ncancer due to their high incidence and the significant impact they have on\npublic health. Early detection and effective data management in both types of\ncancer are crucial for improving patient outcomes. To enhance the accuracy and\nefficiency of data extraction, we utilized GMV's NLP tool uQuery, which excels\nat identifying relevant entities in clinical texts and converting them into\nstandardized formats such as SNOMED and OMOP. uQuery not only detects and\nclassifies entities but also associates them with contextual information,\nincluding negated entities, temporal aspects, and patient-related details. In\nthis work, we explore the use of NLP techniques, specifically Named Entity\nRecognition (NER), to automatically identify and extract key clinical\ninformation from EHRs related to these two cancers. A dataset from Health\nResearch Institute Hospital La Fe (IIS La Fe), comprising 200 annotated breast\ncancer and 400 lung cancer reports, was used, with eight clinical entities\nmanually labeled using the Doccano platform. To perform NER, we fine-tuned the\nbsc-bio-ehr-en3 model, a RoBERTa-based biomedical linguistic model pre-trained\nin Spanish. Fine-tuning was performed using the Transformers architecture,\nenabling accurate recognition of clinical entities in these cancer types. Our\nresults demonstrate strong overall performance, particularly in identifying\nentities like MET and PAT, although challenges remain with less frequent\nentities like EVOL."}
{"id": "2505.09859", "pdf": "https://arxiv.org/pdf/2505.09859", "abs": "https://arxiv.org/abs/2505.09859", "authors": ["Andrew Jun Lee", "Taylor Webb", "Trevor Bihl", "Keith Holyoak", "Hongjing Lu"], "title": "Few-Shot Learning of Visual Compositional Concepts through Probabilistic Schema Induction", "categories": ["cs.CV"], "comment": "Lee, A. J., Webb, T., Bihl, T., Holyoak, K. J., & Lu, H. (2025).\n  Few-shot learning of visual compositional concepts through probabilistic\n  schema induction. In A. Ruggeri, D. Barner, C. Walker, & N. Bramley (Eds.),\n  Proceedings of the 47th Annual Conference of the Cognitive Science Society.\n  Cognitive Science Society", "summary": "The ability to learn new visual concepts from limited examples is a hallmark\nof human cognition. While traditional category learning models represent each\nexample as an unstructured feature vector, compositional concept learning is\nthought to depend on (1) structured representations of examples (e.g., directed\ngraphs consisting of objects and their relations) and (2) the identification of\nshared relational structure across examples through analogical mapping. Here,\nwe introduce Probabilistic Schema Induction (PSI), a prototype model that\nemploys deep learning to perform analogical mapping over structured\nrepresentations of only a handful of examples, forming a compositional concept\ncalled a schema. In doing so, PSI relies on a novel conception of similarity\nthat weighs object-level similarity and relational similarity, as well as a\nmechanism for amplifying relations relevant to classification, analogous to\nselective attention parameters in traditional models. We show that PSI produces\nhuman-like learning performance and outperforms two controls: a prototype model\nthat uses unstructured feature vectors extracted from a deep learning model,\nand a variant of PSI with weaker structured representations. Notably, we find\nthat PSI's human-like performance is driven by an adaptive strategy that\nincreases relational similarity over object-level similarity and upweights the\ncontribution of relations that distinguish classes. These findings suggest that\nstructured representations and analogical mapping are critical to modeling\nrapid human-like learning of compositional visual concepts, and demonstrate how\ndeep learning can be leveraged to create psychological models."}
{"id": "2505.09787", "pdf": "https://arxiv.org/pdf/2505.09787", "abs": "https://arxiv.org/abs/2505.09787", "authors": ["Ziruo Yi", "Ting Xiao", "Mark V. Albert"], "title": "A Multimodal Multi-Agent Framework for Radiology Report Generation", "categories": ["cs.AI"], "comment": null, "summary": "Radiology report generation (RRG) aims to automatically produce diagnostic\nreports from medical images, with the potential to enhance clinical workflows\nand reduce radiologists' workload. While recent approaches leveraging\nmultimodal large language models (MLLMs) and retrieval-augmented generation\n(RAG) have achieved strong results, they continue to face challenges such as\nfactual inconsistency, hallucination, and cross-modal misalignment. We propose\na multimodal multi-agent framework for RRG that aligns with the stepwise\nclinical reasoning workflow, where task-specific agents handle retrieval, draft\ngeneration, visual analysis, refinement, and synthesis. Experimental results\ndemonstrate that our approach outperforms a strong baseline in both automatic\nmetrics and LLM-based evaluations, producing more accurate, structured, and\ninterpretable reports. This work highlights the potential of clinically aligned\nmulti-agent frameworks to support explainable and trustworthy clinical AI\napplications."}
{"id": "2505.09710", "pdf": "https://arxiv.org/pdf/2505.09710", "abs": "https://arxiv.org/abs/2505.09710", "authors": ["Konstantinos Fotopoulos", "Petros Maragos"], "title": "Training Deep Morphological Neural Networks as Universal Approximators", "categories": ["cs.LG"], "comment": null, "summary": "We investigate deep morphological neural networks (DMNNs). We demonstrate\nthat despite their inherent non-linearity, activations between layers are\nessential for DMNNs. We then propose several new architectures for DMNNs, each\nwith a different constraint on their parameters. For the first (resp. second)\narchitecture, we work under the constraint that the majority of parameters\n(resp. learnable parameters) should be part of morphological operations. We\nempirically show that our proposed networks can be successfully trained, and\nare more prunable than linear networks. To the best of our knowledge, we are\nthe first to successfully train DMNNs under such constraints, although the\ngeneralization capabilities of our networks remain limited. Finally, we propose\na hybrid network architecture combining linear and morphological layers,\nshowing empirically that the inclusion of morphological layers significantly\naccelerates the convergence of gradient descent with large batches."}
{"id": "2505.09807", "pdf": "https://arxiv.org/pdf/2505.09807", "abs": "https://arxiv.org/abs/2505.09807", "authors": ["Timour Ichmoukhamedov", "David Martens"], "title": "Exploring the generalization of LLM truth directions on conversational formats", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Several recent works argue that LLMs have a universal truth direction where\ntrue and false statements are linearly separable in the activation space of the\nmodel. It has been demonstrated that linear probes trained on a single hidden\nstate of the model already generalize across a range of topics and might even\nbe used for lie detection in LLM conversations. In this work we explore how\nthis truth direction generalizes between various conversational formats. We\nfind good generalization between short conversations that end on a lie, but\npoor generalization to longer formats where the lie appears earlier in the\ninput prompt. We propose a solution that significantly improves this type of\ngeneralization by adding a fixed key phrase at the end of each conversation.\nOur results highlight the challenges towards reliable LLM lie detectors that\ngeneralize to new settings."}
{"id": "2505.09915", "pdf": "https://arxiv.org/pdf/2505.09915", "abs": "https://arxiv.org/abs/2505.09915", "authors": ["Zhe Xin", "Chenyang Wu", "Penghui Huang", "Yanyong Zhang", "Yinian Mao", "Guoquan Huang"], "title": "Large-Scale Gaussian Splatting SLAM", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "The recently developed Neural Radiance Fields (NeRF) and 3D Gaussian\nSplatting (3DGS) have shown encouraging and impressive results for visual SLAM.\nHowever, most representative methods require RGBD sensors and are only\navailable for indoor environments. The robustness of reconstruction in\nlarge-scale outdoor scenarios remains unexplored. This paper introduces a\nlarge-scale 3DGS-based visual SLAM with stereo cameras, termed LSG-SLAM. The\nproposed LSG-SLAM employs a multi-modality strategy to estimate prior poses\nunder large view changes. In tracking, we introduce feature-alignment warping\nconstraints to alleviate the adverse effects of appearance similarity in\nrendering losses. For the scalability of large-scale scenarios, we introduce\ncontinuous Gaussian Splatting submaps to tackle unbounded scenes with limited\nmemory. Loops are detected between GS submaps by place recognition and the\nrelative pose between looped keyframes is optimized utilizing rendering and\nfeature warping losses. After the global optimization of camera poses and\nGaussian points, a structure refinement module enhances the reconstruction\nquality. With extensive evaluations on the EuRoc and KITTI datasets, LSG-SLAM\nachieves superior performance over existing Neural, 3DGS-based, and even\ntraditional approaches. Project page: https://lsg-slam.github.io."}
{"id": "2505.09920", "pdf": "https://arxiv.org/pdf/2505.09920", "abs": "https://arxiv.org/abs/2505.09920", "authors": ["Shan Yang", "Yongli Zhu"], "title": "Offline Reinforcement Learning for Microgrid Voltage Regulation", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore,\n  Apr. 28, 2025", "summary": "This paper presents a study on using different offline reinforcement learning\nalgorithms for microgrid voltage regulation with solar power penetration. When\nenvironment interaction is unviable due to technical or safety reasons, the\nproposed approach can still obtain an applicable model through offline-style\ntraining on a previously collected dataset, lowering the negative impact of\nlacking online environment interactions. Experiment results on the IEEE 33-bus\nsystem demonstrate the feasibility and effectiveness of the proposed approach\non different offline datasets, including the one with merely low-quality\nexperience."}
{"id": "2505.09716", "pdf": "https://arxiv.org/pdf/2505.09716", "abs": "https://arxiv.org/abs/2505.09716", "authors": ["George Dimitriadis. Spyridon Samothrakis"], "title": "Out-of-distribution generalisation is hard: evidence from ARC-like tasks", "categories": ["cs.LG", "cs.AI"], "comment": "Submission to NeurIPS 2025", "summary": "Out-of-distribution (OOD) generalisation is considered a hallmark of human\nand animal intelligence. To achieve OOD through composition, a system must\ndiscover the environment-invariant properties of experienced input-output\nmappings and transfer them to novel inputs. This can be realised if an\nintelligent system can identify appropriate, task-invariant, and composable\ninput features, as well as the composition methods, thus allowing it to act\nbased not on the interpolation between learnt data points but on the\ntask-invariant composition of those features. We propose that in order to\nconfirm that an algorithm does indeed learn compositional structures from data,\nit is not enough to just test on an OOD setup, but one also needs to confirm\nthat the features identified are indeed compositional. We showcase this by\nexploring two tasks with clearly defined OOD metrics that are not OOD solvable\nby three commonly used neural networks: a Multi-Layer Perceptron (MLP), a\nConvolutional Neural Network (CNN), and a Transformer. In addition, we develop\ntwo novel network architectures imbued with biases that allow them to be\nsuccessful in OOD scenarios. We show that even with correct biases and almost\nperfect OOD performance, an algorithm can still fail to learn the correct\nfeatures for compositional generalisation."}
{"id": "2505.09825", "pdf": "https://arxiv.org/pdf/2505.09825", "abs": "https://arxiv.org/abs/2505.09825", "authors": ["Peiqi Sui", "Juan Diego Rodriguez", "Philippe Laban", "Dean Murphy", "Joseph P. Dexter", "Richard Jean So", "Samuel Baker", "Pramit Chaudhuri"], "title": "KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Each year, tens of millions of essays are written and graded in college-level\nEnglish courses. Students are asked to analyze literary and cultural texts\nthrough a process known as close reading, in which they gather textual details\nto formulate evidence-based arguments. Despite being viewed as a basis for\ncritical thinking and widely adopted as a required element of university\ncoursework, close reading has never been evaluated on large language models\n(LLMs), and multi-discipline benchmarks like MMLU do not include literature as\na subject. To fill this gap, we present KRISTEVA, the first close reading\nbenchmark for evaluating interpretive reasoning, consisting of 1331\nmultiple-choice questions adapted from classroom data. With KRISTEVA, we\npropose three progressively more difficult sets of tasks to approximate\ndifferent elements of the close reading process, which we use to test how well\nLLMs may seem to understand and reason about literary works: 1) extracting\nstylistic features, 2) retrieving relevant contextual information from\nparametric knowledge, and 3) multi-hop reasoning between style and external\ncontexts. Our baseline results find that, while state-of-the-art LLMs possess\nsome college-level close reading competency (accuracy 49.7% - 69.7%), their\nperformances still trail those of experienced human evaluators on 10 out of our\n11 tasks."}
{"id": "2505.09926", "pdf": "https://arxiv.org/pdf/2505.09926", "abs": "https://arxiv.org/abs/2505.09926", "authors": ["Bin-Bin Gao", "Yue Zhu", "Jiangtao Yan", "Yuezhi Cai", "Weixi Zhang", "Meng Wang", "Jun Liu", "Yong Liu", "Lei Wang", "Chengjie Wang"], "title": "AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": "27 pages, 15 figures, 22 tables", "summary": "Universal visual anomaly detection aims to identify anomalies from novel or\nunseen vision domains without additional fine-tuning, which is critical in open\nscenarios. Recent studies have demonstrated that pre-trained vision-language\nmodels like CLIP exhibit strong generalization with just zero or a few normal\nimages. However, existing methods struggle with designing prompt templates,\ncomplex token interactions, or requiring additional fine-tuning, resulting in\nlimited flexibility. In this work, we present a simple yet effective method\ncalled AdaptCLIP based on two key insights. First, adaptive visual and textual\nrepresentations should be learned alternately rather than jointly. Second,\ncomparative learning between query and normal image prompt should incorporate\nboth contextual and aligned residual features, rather than relying solely on\nresidual features. AdaptCLIP treats CLIP models as a foundational service,\nadding only three simple adapters, visual adapter, textual adapter, and\nprompt-query adapter, at its input or output ends. AdaptCLIP supports\nzero-/few-shot generalization across domains and possesses a training-free\nmanner on target domains once trained on a base dataset. AdaptCLIP achieves\nstate-of-the-art performance on 12 anomaly detection benchmarks from industrial\nand medical domains, significantly outperforming existing competitive methods.\nWe will make the code and model of AdaptCLIP available at\nhttps://github.com/gaobb/AdaptCLIP."}
{"id": "2505.09923", "pdf": "https://arxiv.org/pdf/2505.09923", "abs": "https://arxiv.org/abs/2505.09923", "authors": ["Minjung Shin", "Donghyun Kim", "Jeh-Kwang Ryu"], "title": "\"There Is No Such Thing as a Dumb Question,\" But There Are Good Ones", "categories": ["cs.AI"], "comment": "8 pages, 4 figures and 4 tables. This work has been accepted for\n  presentation as a poster with full paper publication at CogSci 2025. This is\n  the final submission", "summary": "Questioning has become increasingly crucial for both humans and artificial\nintelligence, yet there remains limited research comprehensively assessing\nquestion quality. In response, this study defines good questions and presents a\nsystematic evaluation framework. We propose two key evaluation dimensions:\nappropriateness (sociolinguistic competence in context) and effectiveness\n(strategic competence in goal achievement). Based on these foundational\ndimensions, a rubric-based scoring system was developed. By incorporating\ndynamic contextual variables, our evaluation framework achieves structure and\nflexibility through semi-adaptive criteria. The methodology was validated using\nthe CAUS and SQUARE datasets, demonstrating the ability of the framework to\naccess both well-formed and problematic questions while adapting to varied\ncontexts. As we establish a flexible and comprehensive framework for question\nevaluation, this study takes a significant step toward integrating questioning\nbehavior with structured analytical methods grounded in the intrinsic nature of\nquestioning."}
{"id": "2505.09733", "pdf": "https://arxiv.org/pdf/2505.09733", "abs": "https://arxiv.org/abs/2505.09733", "authors": ["Alpaslan Gokcen", "Ali Boyaci"], "title": "Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning (FL) presents an effective solution for collaborative\nmodel training while maintaining data privacy across decentralized client\ndatasets. However, data quality issues such as noisy labels, missing classes,\nand imbalanced distributions significantly challenge its effectiveness. This\nstudy proposes a federated learning methodology that systematically addresses\ndata quality issues, including noise, class imbalance, and missing labels. The\nproposed approach systematically enhances data integrity through adaptive noise\ncleaning, collaborative conditional GAN-based synthetic data generation, and\nrobust federated model training. Experimental evaluations conducted on\nbenchmark datasets (MNIST and Fashion-MNIST) demonstrate significant\nimprovements in federated model performance, particularly macro-F1 Score, under\nvarying noise and class imbalance conditions. Additionally, the proposed\nframework carefully balances computational feasibility and substantial\nperformance gains, ensuring practicality for resource constrained edge devices\nwhile rigorously maintaining data privacy. Our results indicate that this\nmethod effectively mitigates common data quality challenges, providing a\nrobust, scalable, and privacy compliant solution suitable for diverse\nreal-world federated learning scenarios."}
{"id": "2505.09852", "pdf": "https://arxiv.org/pdf/2505.09852", "abs": "https://arxiv.org/abs/2505.09852", "authors": ["Apollinaire Poli Nemkova", "Sarath Chandra Lingareddy", "Sagnik Ray Choudhury", "Mark V. Albert"], "title": "Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance across natural\nlanguage tasks, but their ability to forecast violent conflict remains\nunderexplored. We investigate whether LLMs possess meaningful parametric\nknowledge-encoded in their pretrained weights-to predict conflict escalation\nand fatalities without external data. This is critical for early warning\nsystems, humanitarian planning, and policy-making. We compare this parametric\nknowledge with non-parametric capabilities, where LLMs access structured and\nunstructured context from conflict datasets (e.g., ACLED, GDELT) and recent\nnews reports via Retrieval-Augmented Generation (RAG). Incorporating external\ninformation could enhance model performance by providing up-to-date context\notherwise missing from pretrained weights. Our two-part evaluation framework\nspans 2020-2024 across conflict-prone regions in the Horn of Africa and the\nMiddle East. In the parametric setting, LLMs predict conflict trends and\nfatalities relying only on pretrained knowledge. In the non-parametric setting,\nmodels receive summaries of recent conflict events, indicators, and\ngeopolitical developments. We compare predicted conflict trend labels (e.g.,\nEscalate, Stable Conflict, De-escalate, Peace) and fatalities against\nhistorical data. Our findings highlight the strengths and limitations of LLMs\nfor conflict forecasting and the benefits of augmenting them with structured\nexternal knowledge."}
{"id": "2505.09927", "pdf": "https://arxiv.org/pdf/2505.09927", "abs": "https://arxiv.org/abs/2505.09927", "authors": ["Siqi Yin", "Shaolei Liu", "Manning Wang"], "title": "DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Domain adaptation addresses the challenge of model performance degradation\ncaused by domain gaps. In the typical setup for unsupervised domain adaptation,\nlabeled data from a source domain and unlabeled data from a target domain are\nused to train a target model. However, access to labeled source domain data,\nparticularly in medical datasets, can be restricted due to privacy policies. As\na result, research has increasingly shifted to source-free domain adaptation\n(SFDA), which requires only a pretrained model from the source domain and\nunlabeled data from the target domain data for adaptation. Existing SFDA\nmethods often rely on domain-specific image style translation and\nself-supervision techniques to bridge the domain gap and train the target\ndomain model. However, the quality of domain-specific style-translated images\nand pseudo-labels produced by these methods still leaves room for improvement.\nMoreover, training the entire model during adaptation can be inefficient under\nlimited supervision. In this paper, we propose a novel SFDA framework to\naddress these challenges. Specifically, to effectively mitigate the impact of\ndomain gap in the initial training phase, we introduce preadaptation to\ngenerate a preadapted model, which serves as an initialization of target model\nand allows for the generation of high-quality enhanced pseudo-labels without\nintroducing extra parameters. Additionally, we propose a data-dependent\nfrequency prompt to more effectively translate target domain images into a\nsource-like style. To further enhance adaptation, we employ a style-related\nlayer fine-tuning strategy, specifically designed for SFDA, to train the target\nmodel using the prompted target domain images and pseudo-labels. Extensive\nexperiments on cross-modality abdominal and cardiac SFDA segmentation tasks\ndemonstrate that our proposed method outperforms existing state-of-the-art\nmethods."}
{"id": "2505.09932", "pdf": "https://arxiv.org/pdf/2505.09932", "abs": "https://arxiv.org/abs/2505.09932", "authors": ["Kevin J McNamara", "Rhea Pritham Marpu"], "title": "Demystifying AI Agents: The Final Generation of Intelligence", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.MA"], "comment": null, "summary": "The trajectory of artificial intelligence (AI) has been one of relentless\nacceleration, evolving from rudimentary rule-based systems to sophisticated,\nautonomous agents capable of complex reasoning and interaction. This whitepaper\nchronicles this remarkable journey, charting the key technological\nmilestones--advancements in prompting, training methodologies, hardware\ncapabilities, and architectural innovations--that have converged to create the\nAI agents of today. We argue that these agents, exemplified by systems like\nOpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in\nAI development, potentially constituting the \"final generation\" of intelligence\nas we currently conceive it. We explore the capabilities and underlying\ntechnologies of these agents, grounded in practical examples, while also\nexamining the profound societal implications and the unprecedented pace of\nprogress that suggests intelligence is now doubling approximately every six\nmonths. The paper concludes by underscoring the critical need for wisdom and\nforesight in navigating the opportunities and challenges presented by this\npowerful new era of intelligence."}
{"id": "2505.09742", "pdf": "https://arxiv.org/pdf/2505.09742", "abs": "https://arxiv.org/abs/2505.09742", "authors": ["Yuan-Hang Zhang", "Massimiliano Di Ventra"], "title": "A Generative Neural Annealer for Black-Box Combinatorial Optimization", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.NE"], "comment": "15 pages, 3 figures", "summary": "We propose a generative, end-to-end solver for black-box combinatorial\noptimization that emphasizes both sample efficiency and solution quality on NP\nproblems. Drawing inspiration from annealing-based algorithms, we treat the\nblack-box objective as an energy function and train a neural network to model\nthe associated Boltzmann distribution. By conditioning on temperature, the\nnetwork captures a continuum of distributions--from near-uniform at high\ntemperatures to sharply peaked around global optima at low\ntemperatures--thereby learning the structure of the energy landscape and\nfacilitating global optimization. When queries are expensive, the\ntemperature-dependent distributions naturally enable data augmentation and\nimprove sample efficiency. When queries are cheap but the problem remains hard,\nthe model learns implicit variable interactions, effectively \"opening\" the\nblack box. We validate our approach on challenging combinatorial tasks under\nboth limited and unlimited query budgets, showing competitive performance\nagainst state-of-the-art black-box optimizers."}
{"id": "2505.09902", "pdf": "https://arxiv.org/pdf/2505.09902", "abs": "https://arxiv.org/abs/2505.09902", "authors": ["Martin Capdevila", "Esteban Villa Turek", "Ellen Karina Chumbe Fernandez", "Luis Felipe Polo Galvez", "Luis Cadavid", "Andrea Marroquin", "Rebeca Vargas Quesada", "Johanna Crew", "Nicole Vallejo Galarraga", "Christopher Rodriguez", "Diego Gutierrez", "Radhi Datla"], "title": "Crossing Borders Without Crossing Boundaries: How Sociolinguistic Awareness Can Optimize User Engagement with Localized Spanish AI Models Across Hispanophone Countries", "categories": ["cs.CL"], "comment": null, "summary": "Large language models are, by definition, based on language. In an effort to\nunderscore the critical need for regional localized models, this paper examines\nprimary differences between variants of written Spanish across Latin America\nand Spain, with an in-depth sociocultural and linguistic contextualization\ntherein. We argue that these differences effectively constitute significant\ngaps in the quotidian use of Spanish among dialectal groups by creating\nsociolinguistic dissonances, to the extent that locale-sensitive AI models\nwould play a pivotal role in bridging these divides. In doing so, this approach\ninforms better and more efficient localization strategies that also serve to\nmore adequately meet inclusivity goals, while securing sustainable active daily\nuser growth in a major low-risk investment geographic area. Therefore,\nimplementing at least the proposed five sub variants of Spanish addresses two\nlines of action: to foment user trust and reliance on AI language models while\nalso demonstrating a level of cultural, historical, and sociolinguistic\nawareness that reflects positively on any internationalization strategy."}
{"id": "2505.09935", "pdf": "https://arxiv.org/pdf/2505.09935", "abs": "https://arxiv.org/abs/2505.09935", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Quoc Dai Tran"], "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users."}
{"id": "2505.09970", "pdf": "https://arxiv.org/pdf/2505.09970", "abs": "https://arxiv.org/abs/2505.09970", "authors": ["Mrinal Rawat", "Ambuje Gupta", "Rushil Goomer", "Alessandro Di Bari", "Neha Gupta", "Roberto Pieraccini"], "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "The ReAct (Reasoning + Action) capability in large language models (LLMs) has\nbecome the foundation of modern agentic systems. Recent LLMs, such as\nDeepSeek-R1 and OpenAI o1/o3, exemplify this by emphasizing reasoning through\nthe generation of ample intermediate tokens, which help build a strong premise\nbefore producing the final output tokens. In this paper, we introduce Pre-Act,\na novel approach that enhances the agent's performance by creating a multi-step\nexecution plan along with the detailed reasoning for the given user input. This\nplan incrementally incorporates previous steps and tool outputs, refining\nitself after each step execution until the final response is obtained. Our\napproach is applicable to both conversational and non-conversational agents. To\nmeasure the performance of task-oriented agents comprehensively, we propose a\ntwo-level evaluation framework: (1) turn level and (2) end-to-end. Our\nturn-level evaluation, averaged across five models, shows that our approach,\nPre-Act, outperforms ReAct by 70% in Action Recall on the Almita dataset. While\nthis approach is effective for larger models, smaller models crucial for\npractical applications, where latency and cost are key constraints, often\nstruggle with complex reasoning tasks required for agentic systems. To address\nthis limitation, we fine-tune relatively small models such as Llama 3.1 (8B &\n70B) using the proposed Pre-Act approach. Our experiments show that the\nfine-tuned 70B model outperforms GPT-4, achieving a 69.5% improvement in action\naccuracy (turn-level) and a 28% improvement in goal completion rate\n(end-to-end) on the Almita (out-of-domain) dataset."}
{"id": "2505.09756", "pdf": "https://arxiv.org/pdf/2505.09756", "abs": "https://arxiv.org/abs/2505.09756", "authors": ["Zhaoyang Shi"], "title": "Community-based Multi-Agent Reinforcement Learning with Transfer and Active Exploration", "categories": ["cs.LG", "cs.MA", "math.OC", "stat.ML"], "comment": null, "summary": "We propose a new framework for multi-agent reinforcement learning (MARL),\nwhere the agents cooperate in a time-evolving network with latent community\nstructures and mixed memberships. Unlike traditional neighbor-based or fixed\ninteraction graphs, our community-based framework captures flexible and\nabstract coordination patterns by allowing each agent to belong to multiple\noverlapping communities. Each community maintains shared policy and value\nfunctions, which are aggregated by individual agents according to personalized\nmembership weights. We also design actor-critic algorithms that exploit this\nstructure: agents inherit community-level estimates for policy updates and\nvalue learning, enabling structured information sharing without requiring\naccess to other agents' policies. Importantly, our approach supports both\ntransfer learning by adapting to new agents or tasks via membership estimation,\nand active learning by prioritizing uncertain communities during exploration.\nTheoretically, we establish convergence guarantees under linear function\napproximation for both actor and critic updates. To our knowledge, this is the\nfirst MARL framework that integrates community structure, transferability, and\nactive learning with provable guarantees."}
{"id": "2505.09924", "pdf": "https://arxiv.org/pdf/2505.09924", "abs": "https://arxiv.org/abs/2505.09924", "authors": ["Yidan Wang", "Yubing Ren", "Yanan Cao", "Binxing Fang"], "title": "From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models", "categories": ["cs.CL", "cs.CR"], "comment": null, "summary": "The rise of Large Language Models (LLMs) has heightened concerns about the\nmisuse of AI-generated text, making watermarking a promising solution.\nMainstream watermarking schemes for LLMs fall into two categories: logits-based\nand sampling-based. However, current schemes entail trade-offs among\nrobustness, text quality, and security. To mitigate this, we integrate\nlogits-based and sampling-based schemes, harnessing their respective strengths\nto achieve synergy. In this paper, we propose a versatile symbiotic\nwatermarking framework with three strategies: serial, parallel, and hybrid. The\nhybrid framework adaptively embeds watermarks using token entropy and semantic\nentropy, optimizing the balance between detectability, robustness, text\nquality, and security. Furthermore, we validate our approach through\ncomprehensive experiments on various datasets and models. Experimental results\nindicate that our method outperforms existing baselines and achieves\nstate-of-the-art (SOTA) performance. We believe this framework provides novel\ninsights into diverse watermarking paradigms. Our code is available at\n\\href{https://github.com/redwyd/SymMark}{https://github.com/redwyd/SymMark}."}
{"id": "2505.09939", "pdf": "https://arxiv.org/pdf/2505.09939", "abs": "https://arxiv.org/abs/2505.09939", "authors": ["Zhe Shan", "Lei Zhou", "Liu Mao", "Shaofan Chen", "Chuanqiu Ren", "Xia Xie"], "title": "Non-Registration Change Detection: A Novel Change Detection Task and Benchmark Dataset", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted to IGARSS 2025", "summary": "In this study, we propose a novel remote sensing change detection task,\nnon-registration change detection, to address the increasing number of\nemergencies such as natural disasters, anthropogenic accidents, and military\nstrikes. First, in light of the limited discourse on the issue of\nnon-registration change detection, we systematically propose eight scenarios\nthat could arise in the real world and potentially contribute to the occurrence\nof non-registration problems. Second, we develop distinct image transformation\nschemes tailored to various scenarios to convert the available registration\nchange detection dataset into a non-registration version. Finally, we\ndemonstrate that non-registration change detection can cause catastrophic\ndamage to the state-of-the-art methods. Our code and dataset are available at\nhttps://github.com/ShanZard/NRCD."}
{"id": "2505.10034", "pdf": "https://arxiv.org/pdf/2505.10034", "abs": "https://arxiv.org/abs/2505.10034", "authors": ["Changzeng Fu", "Zelin Fu", "Xinhe Kuang", "Jiacheng Dong", "Qi Zhang", "Kaifeng Su", "Yikai Su", "Wenbo Shi", "Junfeng Yao", "Yuliang Zhao", "Shiqi Zhao", "Jiadong Wang", "Siyang Song", "Chaoran Liu", "Yuichiro Yoshikawa", "Björn Schuller", "Hiroshi Ishiguro"], "title": "The First MPDD Challenge: Multimodal Personality-aware Depression Detection", "categories": ["cs.AI", "68T07", "I.2.0; H.5.1"], "comment": "This paper has been accepted as part of the MPDD Challenge in the\n  ACMMM 2025 Grand Challenge", "summary": "Depression is a widespread mental health issue affecting diverse age groups,\nwith notable prevalence among college students and the elderly. However,\nexisting datasets and detection methods primarily focus on young adults,\nneglecting the broader age spectrum and individual differences that influence\ndepression manifestation. Current approaches often establish a direct mapping\nbetween multimodal data and depression indicators, failing to capture the\ncomplexity and diversity of depression across individuals. This challenge\nincludes two tracks based on age-specific subsets: Track 1 uses the\nMPDD-Elderly dataset for detecting depression in older adults, and Track 2 uses\nthe MPDD-Young dataset for detecting depression in younger participants. The\nMultimodal Personality-aware Depression Detection (MPDD) Challenge aims to\naddress this gap by incorporating multimodal data alongside individual\ndifference factors. We provide a baseline model that fuses audio and video\nmodalities with individual difference information to detect depression\nmanifestations in diverse populations. This challenge aims to promote the\ndevelopment of more personalized and accurate de pression detection methods,\nadvancing mental health research and fostering inclusive detection systems.\nMore details are available on the official challenge website:\nhttps://hacilab.github.io/MPDDChallenge.github.io."}
{"id": "2505.09768", "pdf": "https://arxiv.org/pdf/2505.09768", "abs": "https://arxiv.org/abs/2505.09768", "authors": ["Xiukun Wei", "Xueru Zhang"], "title": "Self-Consuming Generative Models with Adversarially Curated Data", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in generative models have made it increasingly difficult to\ndistinguish real data from model-generated synthetic data. Using synthetic data\nfor successive training of future model generations creates \"self-consuming\nloops\", which may lead to model collapse or training instability. Furthermore,\nsynthetic data is often subject to human feedback and curated by users based on\ntheir preferences. Ferbach et al. (2024) recently showed that when data is\ncurated according to user preferences, the self-consuming retraining loop\ndrives the model to converge toward a distribution that optimizes those\npreferences. However, in practice, data curation is often noisy or\nadversarially manipulated. For example, competing platforms may recruit\nmalicious users to adversarially curate data and disrupt rival models. In this\npaper, we study how generative models evolve under self-consuming retraining\nloops with noisy and adversarially curated data. We theoretically analyze the\nimpact of such noisy data curation on generative models and identify conditions\nfor the robustness of the retraining process. Building on this analysis, we\ndesign attack algorithms for competitive adversarial scenarios, where a\nplatform with a limited budget employs malicious users to misalign a rival's\nmodel from actual user preferences. Experiments on both synthetic and\nreal-world datasets demonstrate the effectiveness of the proposed algorithms."}
{"id": "2505.09930", "pdf": "https://arxiv.org/pdf/2505.09930", "abs": "https://arxiv.org/abs/2505.09930", "authors": ["Zixiao Zhu", "Hanzhang Zhou", "Zijian Feng", "Tianjiao Li", "Chua Jia Jim Deryl", "Mak Lee Onn", "Gee Wah Ng", "Kezhi Mao"], "title": "Rethinking Prompt Optimizers: From Prompt Merits to Optimization", "categories": ["cs.CL"], "comment": "20 pages, 14 figures", "summary": "Prompt optimization (PO) offers a practical alternative to fine-tuning large\nlanguage models (LLMs), enabling performance improvements without altering\nmodel weights. Existing methods typically rely on advanced, large-scale LLMs\nlike GPT-4 to generate optimized prompts. However, due to limited downward\ncompatibility, verbose, instruction-heavy prompts from advanced LLMs can\noverwhelm lightweight inference models and degrade response quality. In this\nwork, we rethink prompt optimization through the lens of interpretable design.\nWe first identify a set of model-agnostic prompt quality merits and empirically\nvalidate their effectiveness in enhancing prompt and response quality. We then\nintroduce MePO, a merit-guided, lightweight, and locally deployable prompt\noptimizer trained on our preference dataset built from merit-aligned prompts\ngenerated by a lightweight LLM. Unlike prior work, MePO avoids online\noptimization reliance, reduces cost and privacy concerns, and, by learning\nclear, interpretable merits, generalizes effectively to both large-scale and\nlightweight inference models. Experiments demonstrate that MePO achieves better\nresults across diverse tasks and model types, offering a scalable and robust\nsolution for real-world deployment. Our model and dataset are available at:\nhttps://github.com/MidiyaZhu/MePO"}
{"id": "2505.09943", "pdf": "https://arxiv.org/pdf/2505.09943", "abs": "https://arxiv.org/abs/2505.09943", "authors": ["Jiakun Deng", "Kexuan Li", "Xingye Cui", "Jiaxuan Li", "Chang Long", "Tian Pu", "Zhenming Peng"], "title": "CSPENet: Contour-Aware and Saliency Priors Embedding Network for Infrared Small Target Detection", "categories": ["cs.CV"], "comment": null, "summary": "Infrared small target detection (ISTD) plays a critical role in a wide range\nof civilian and military applications. Existing methods suffer from\ndeficiencies in the localization of dim targets and the perception of contour\ninformation under dense clutter environments, severely limiting their detection\nperformance. To tackle these issues, we propose a contour-aware and saliency\npriors embedding network (CSPENet) for ISTD. We first design a\nsurround-convergent prior extraction module (SCPEM) that effectively captures\nthe intrinsic characteristic of target contour pixel gradients converging\ntoward their center. This module concurrently extracts two collaborative\npriors: a boosted saliency prior for accurate target localization and\nmulti-scale structural priors for comprehensively enriching contour detail\nrepresentation. Building upon this, we propose a dual-branch priors embedding\narchitecture (DBPEA) that establishes differentiated feature fusion pathways,\nembedding these two priors at optimal network positions to achieve performance\nenhancement. Finally, we develop an attention-guided feature enhancement module\n(AGFEM) to refine feature representations and improve saliency estimation\naccuracy. Experimental results on public datasets NUDT-SIRST, IRSTD-1k, and\nNUAA-SIRST demonstrate that our CSPENet outperforms other state-of-the-art\nmethods in detection performance. The code is available at\nhttps://github.com/IDIP2025/CSPENet."}
{"id": "2505.10074", "pdf": "https://arxiv.org/pdf/2505.10074", "abs": "https://arxiv.org/abs/2505.10074", "authors": ["Mohamed Abdelmagied", "Mohamed Amine Chatti", "Shoeb Joarder", "Qurat Ul Ain", "Rawaa Alatrash"], "title": "Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs", "categories": ["cs.AI", "cs.CY"], "comment": "Accepted at EMOOCs 2025", "summary": "Massive Open Online Courses (MOOCs) lack direct interaction between learners\nand instructors, making it challenging for learners to understand new knowledge\nconcepts. Recently, learners have increasingly used Large Language Models\n(LLMs) to support them in acquiring new knowledge. However, LLMs are prone to\nhallucinations which limits their reliability. Retrieval-Augmented Generation\n(RAG) addresses this issue by retrieving relevant documents before generating a\nresponse. However, the application of RAG across different MOOCs is limited by\nunstructured learning material. Furthermore, current RAG systems do not\nactively guide learners toward their learning needs. To address these\nchallenges, we propose a Graph RAG pipeline that leverages Educational\nKnowledge Graphs (EduKGs) and Personal Knowledge Graphs (PKGs) to guide\nlearners to understand knowledge concepts in the MOOC platform CourseMapper.\nSpecifically, we implement (1) a PKG-based Question Generation method to\nrecommend personalized questions for learners in context, and (2) an\nEduKG-based Question Answering method that leverages the relationships between\nknowledge concepts in the EduKG to answer learner selected questions. To\nevaluate both methods, we conducted a study with 3 expert instructors on 3\ndifferent MOOCs in the MOOC platform CourseMapper. The results of the\nevaluation show the potential of Graph RAG to empower learners to understand\nnew knowledge concepts in a personalized learning experience."}
{"id": "2505.09792", "pdf": "https://arxiv.org/pdf/2505.09792", "abs": "https://arxiv.org/abs/2505.09792", "authors": ["Michael Kamfonas"], "title": "Interim Report on Human-Guided Adaptive Hyperparameter Optimization with Multi-Fidelity Sprints", "categories": ["cs.LG"], "comment": null, "summary": "This case study applies a phased hyperparameter optimization process to\ncompare multitask natural language model variants that utilize multiphase\nlearning rate scheduling and optimizer parameter grouping. We employ short,\nBayesian optimization sessions that leverage multi-fidelity, hyperparameter\nspace pruning, progressive halving, and a degree of human guidance. We utilize\nthe Optuna TPE sampler and Hyperband pruner, as well as the Scikit-Learn\nGaussian process minimization. Initially, we use efficient low-fidelity sprints\nto prune the hyperparameter space. Subsequent sprints progressively increase\ntheir model fidelity and employ hyperband pruning for efficiency. A second\naspect of our approach is using a meta-learner to tune threshold values to\nresolve classification probabilities during inference. We demonstrate our\nmethod on a collection of variants of the 2021 Joint Entity and Relation\nExtraction model proposed by Eberts and Ulges."}
{"id": "2505.09945", "pdf": "https://arxiv.org/pdf/2505.09945", "abs": "https://arxiv.org/abs/2505.09945", "authors": ["Deeksha Prahlad", "Chanhee Lee", "Dongha Kim", "Hokeun Kim"], "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)", "summary": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time."}
{"id": "2505.09965", "pdf": "https://arxiv.org/pdf/2505.09965", "abs": "https://arxiv.org/abs/2505.09965", "authors": ["Hao Yang", "Tao Tan", "Shuai Tan", "Weiqin Yang", "Kunyan Cai", "Calvin Chen", "Yue Sun"], "title": "MambaControl: Anatomy Graph-Enhanced Mamba ControlNet with Fourier Refinement for Diffusion-Based Disease Trajectory Prediction", "categories": ["cs.CV"], "comment": null, "summary": "Modelling disease progression in precision medicine requires capturing\ncomplex spatio-temporal dynamics while preserving anatomical integrity.\nExisting methods often struggle with longitudinal dependencies and structural\nconsistency in progressive disorders. To address these limitations, we\nintroduce MambaControl, a novel framework that integrates selective state-space\nmodelling with diffusion processes for high-fidelity prediction of medical\nimage trajectories. To better capture subtle structural changes over time while\nmaintaining anatomical consistency, MambaControl combines Mamba-based\nlong-range modelling with graph-guided anatomical control to more effectively\nrepresent anatomical correlations. Furthermore, we introduce Fourier-enhanced\nspectral graph representations to capture spatial coherence and multiscale\ndetail, enabling MambaControl to achieve state-of-the-art performance in\nAlzheimer's disease prediction. Quantitative and regional evaluations\ndemonstrate improved progression prediction quality and anatomical fidelity,\nhighlighting its potential for personalised prognosis and clinical decision\nsupport."}
{"id": "2505.10093", "pdf": "https://arxiv.org/pdf/2505.10093", "abs": "https://arxiv.org/abs/2505.10093", "authors": ["Hsuan-Lei Shao"], "title": "From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI", "categories": ["cs.AI", "cs.CL", "I.2.4; H.3.3; J.5"], "comment": "4 pages, 4 figures", "summary": "Taiwanese China Studies (CS) has developed into a rich, interdisciplinary\nresearch field shaped by the unique geopolitical position and long standing\nacademic engagement with Mainland China. This study responds to the growing\nneed to systematically revisit and reorganize decades of Taiwan based CS\nscholarship by proposing an AI assisted approach that transforms unstructured\nacademic texts into structured, interactive knowledge representations. We apply\ngenerative AI (GAI) techniques and large language models (LLMs) to extract and\nstandardize entity relation triples from 1,367 peer reviewed CS articles\npublished between 1996 and 2019. These triples are then visualized through a\nlightweight D3.js based system, forming the foundation of a domain specific\nknowledge graph and vector database for the field. This infrastructure allows\nusers to explore conceptual nodes and semantic relationships across the corpus,\nrevealing previously uncharted intellectual trajectories, thematic clusters,\nand research gaps. By decomposing textual content into graph structured\nknowledge units, our system enables a paradigm shift from linear text\nconsumption to network based knowledge navigation. In doing so, it enhances\nscholarly access to CS literature while offering a scalable, data driven\nalternative to traditional ontology construction. This work not only\ndemonstrates how generative AI can augment area studies and digital humanities\nbut also highlights its potential to support a reimagined scholarly\ninfrastructure for regional knowledge systems."}
{"id": "2505.09810", "pdf": "https://arxiv.org/pdf/2505.09810", "abs": "https://arxiv.org/abs/2505.09810", "authors": ["Daniel Waddington", "Cornel Constantinescu"], "title": "Lossless Compression for LLM Tensor Incremental Snapshots", "categories": ["cs.LG"], "comment": null, "summary": "During the training of Large Language Models (LLMs), tensor data is\nperiodically \"checkpointed\" to persistent storage to allow recovery of work\ndone in the event of failure. The volume of data that must be copied during\neach checkpoint, even when using reduced-precision representations such as\nbfloat16, often reaches hundreds of gigabytes. Furthermore, the data must be\nmoved across a network and written to a storage system before the next epoch\noccurs. With a view to ultimately building an optimized checkpointing solution,\nthis paper presents experimental analysis of checkpoint data used to derive a\ndesign that maximizes the use of lossless compression to reduce the volume of\ndata. We examine how tensor data and its compressibility evolve during model\ntraining and evaluate the efficacy of existing common off-the-shelf general\npurpose compression engines combined with known data optimization techniques\nsuch as byte-grouping and incremental delta compression.\n  Leveraging our analysis we have built an effective compression solution,\nknown as Language Model Compressor (LMC), which is based on byte-grouping and\nHuffman encoding. LMC offers more compression performance than the best\nalternative (BZ2) but with an order-of-magnitude reduction in the time needed\nto perform the compression. We show that a 16-core parallel implementation of\nLMC can attain compression and decompression throughput of 2.78 GiB/s and 3.76\nGiB/s respectively. This increase in performance ultimately reduces the CPU\nresources needed and provides more time to copy the data to the storage system\nbefore the next epoch thus allowing for higher-frequency checkpoints."}
{"id": "2505.10013", "pdf": "https://arxiv.org/pdf/2505.10013", "abs": "https://arxiv.org/abs/2505.10013", "authors": ["Lake Yin", "Fan Huang"], "title": "DIF: A Framework for Benchmarking and Verifying Implicit Bias in LLMs", "categories": ["cs.CL"], "comment": "7 pages, 1 figure", "summary": "As Large Language Models (LLMs) have risen in prominence over the past few\nyears, there has been concern over the potential biases in LLMs inherited from\nthe training data. Previous studies have examined how LLMs exhibit implicit\nbias, such as when response generation changes when different social contexts\nare introduced. We argue that this implicit bias is not only an ethical, but\nalso a technical issue, as it reveals an inability of LLMs to accommodate\nextraneous information. However, unlike other measures of LLM intelligence,\nthere are no standard methods to benchmark this specific subset of LLM bias. To\nbridge this gap, we developed a method for calculating an easily interpretable\nbenchmark, DIF (Demographic Implicit Fairness), by evaluating preexisting LLM\nlogic and math problem datasets with sociodemographic personas. We demonstrate\nthat this method can statistically validate the presence of implicit bias in\nLLM behavior and find an inverse trend between question answering accuracy and\nimplicit bias, supporting our argument."}
{"id": "2505.09967", "pdf": "https://arxiv.org/pdf/2505.09967", "abs": "https://arxiv.org/abs/2505.09967", "authors": ["Liqian Deng"], "title": "TKFNet: Learning Texture Key Factor Driven Feature for Facial Expression Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Facial expression recognition (FER) in the wild remains a challenging task\ndue to the subtle and localized nature of expression-related features, as well\nas the complex variations in facial appearance. In this paper, we introduce a\nnovel framework that explicitly focuses on Texture Key Driver Factors (TKDF),\nlocalized texture regions that exhibit strong discriminative power across\nemotional categories. By carefully observing facial image patterns, we identify\nthat certain texture cues, such as micro-changes in skin around the brows,\neyes, and mouth, serve as primary indicators of emotional dynamics. To\neffectively capture and leverage these cues, we propose a FER architecture\ncomprising a Texture-Aware Feature Extractor (TAFE) and Dual Contextual\nInformation Filtering (DCIF). TAFE employs a ResNet-based backbone enhanced\nwith multi-branch attention to extract fine-grained texture representations,\nwhile DCIF refines these features by filtering context through adaptive pooling\nand attention mechanisms. Experimental results on RAF-DB and KDEF datasets\ndemonstrate that our method achieves state-of-the-art performance, verifying\nthe effectiveness and robustness of incorporating TKDFs into FER pipelines."}
{"id": "2505.10188", "pdf": "https://arxiv.org/pdf/2505.10188", "abs": "https://arxiv.org/abs/2505.10188", "authors": ["Felix Liedeker", "Olivia Sanchez-Graillet", "Moana Seidler", "Christian Brandt", "Jörg Wellmer", "Philipp Cimiano"], "title": "A User Study Evaluating Argumentative Explanations in Diagnostic Decision Support", "categories": ["cs.AI"], "comment": "Presented at 'The First Workshop on Natural Language Argument-Based\n  Explanations', co-located with ECAI 2024", "summary": "As the field of healthcare increasingly adopts artificial intelligence, it\nbecomes important to understand which types of explanations increase\ntransparency and empower users to develop confidence and trust in the\npredictions made by machine learning (ML) systems. In shared decision-making\nscenarios where doctors cooperate with ML systems to reach an appropriate\ndecision, establishing mutual trust is crucial. In this paper, we explore\ndifferent approaches to generating explanations in eXplainable AI (XAI) and\nmake their underlying arguments explicit so that they can be evaluated by\nmedical experts. In particular, we present the findings of a user study\nconducted with physicians to investigate their perceptions of various types of\nAI-generated explanations in the context of diagnostic decision support. The\nstudy aims to identify the most effective and useful explanations that enhance\nthe diagnostic process. In the study, medical doctors filled out a survey to\nassess different types of explanations. Further, an interview was carried out\npost-survey to gain qualitative insights on the requirements of explanations\nincorporated in diagnostic decision support. Overall, the insights gained from\nthis study contribute to understanding the types of explanations that are most\neffective."}
{"id": "2505.09812", "pdf": "https://arxiv.org/pdf/2505.09812", "abs": "https://arxiv.org/abs/2505.09812", "authors": ["Anastasija Tashkova", "Stefan Eftimov", "Bojan Ristov", "Slobodan Kalajdziski"], "title": "Comparative Analysis of Stroke Prediction Models Using Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "Stroke remains one of the most critical global health challenges, ranking as\nthe second leading cause of death and the third leading cause of disability\nworldwide. This study explores the effectiveness of machine learning algorithms\nin predicting stroke risk using demographic, clinical, and lifestyle data from\nthe Stroke Prediction Dataset. By addressing key methodological challenges such\nas class imbalance and missing data, we evaluated the performance of multiple\nmodels, including Logistic Regression, Random Forest, and XGBoost. Our results\ndemonstrate that while these models achieve high accuracy, sensitivity remains\na limiting factor for real-world clinical applications. In addition, we\nidentify the most influential predictive features and propose strategies to\nimprove machine learning-based stroke prediction. These findings contribute to\nthe development of more reliable and interpretable models for the early\nassessment of stroke risk."}
{"id": "2505.10063", "pdf": "https://arxiv.org/pdf/2505.10063", "abs": "https://arxiv.org/abs/2505.10063", "authors": ["Han Peng", "Jinhao Jiang", "Zican Dong", "Wayne Xin Zhao", "Lei Fang"], "title": "CAFE: Retrieval Head-based Coarse-to-Fine Information Seeking to Enhance Multi-Document QA Capability", "categories": ["cs.CL"], "comment": null, "summary": "Advancements in Large Language Models (LLMs) have extended their input\ncontext length, yet they still struggle with retrieval and reasoning in\nlong-context inputs. Existing methods propose to utilize the prompt strategy\nand retrieval head to alleviate this limitation. However, they still face\nchallenges in balancing retrieval precision and recall, impacting their\nefficacy in answering questions. To address this, we introduce $\\textbf{CAFE}$,\na two-stage coarse-to-fine method to enhance multi-document question-answering\ncapacities. By gradually eliminating the negative impacts of background and\ndistracting documents, CAFE makes the responses more reliant on the evidence\ndocuments. Initially, a coarse-grained filtering method leverages retrieval\nheads to identify and rank relevant documents. Then, a fine-grained steering\nmethod guides attention to the most relevant content. Experiments across\nbenchmarks show CAFE outperforms baselines, achieving up to 22.1% and 13.7%\nSubEM improvement over SFT and RAG methods on the Mistral model, respectively."}
{"id": "2505.09971", "pdf": "https://arxiv.org/pdf/2505.09971", "abs": "https://arxiv.org/abs/2505.09971", "authors": ["Yuan Gao", "Shaobo Xia", "Sheng Nie", "Cheng Wang", "Xiaohuan Xi", "Bisheng Yang"], "title": "APCoTTA: Continual Test-Time Adaptation for Semantic Segmentation of Airborne LiDAR Point Clouds", "categories": ["cs.CV"], "comment": "18 pages,12 figures", "summary": "Airborne laser scanning (ALS) point cloud segmentation is a fundamental task\nfor large-scale 3D scene understanding. In real-world applications, models are\ntypically fixed after training. However, domain shifts caused by changes in the\nenvironment, sensor types, or sensor degradation often lead to a decline in\nmodel performance. Continuous Test-Time Adaptation (CTTA) offers a solution by\nadapting a source-pretrained model to evolving, unlabeled target domains.\nDespite its potential, research on ALS point clouds remains limited, facing\nchallenges such as the absence of standardized datasets and the risk of\ncatastrophic forgetting and error accumulation during prolonged adaptation. To\ntackle these challenges, we propose APCoTTA, the first CTTA method tailored for\nALS point cloud semantic segmentation. We propose a dynamic trainable layer\nselection module. This module utilizes gradient information to select\nlow-confidence layers for training, and the remaining layers are kept frozen,\nmitigating catastrophic forgetting. To further reduce error accumulation, we\npropose an entropy-based consistency loss. By losing such samples based on\nentropy, we apply consistency loss only to the reliable samples, enhancing\nmodel stability. In addition, we propose a random parameter interpolation\nmechanism, which randomly blends parameters from the selected trainable layers\nwith those of the source model. This approach helps balance target adaptation\nand source knowledge retention, further alleviating forgetting. Finally, we\nconstruct two benchmarks, ISPRSC and H3DC, to address the lack of CTTA\nbenchmarks for ALS point cloud segmentation. Experimental results demonstrate\nthat APCoTTA achieves the best performance on two benchmarks, with mIoU\nimprovements of approximately 9% and 14% over direct inference. The new\nbenchmarks and code are available at https://github.com/Gaoyuan2/APCoTTA."}
{"id": "2505.10278", "pdf": "https://arxiv.org/pdf/2505.10278", "abs": "https://arxiv.org/abs/2505.10278", "authors": ["Taian Guo", "Haiyang Shen", "Jinsheng Huang", "Zhengyang Mao", "Junyu Luo", "Zhuoru Chen", "Xuhui Liu", "Bingyu Xia", "Luchen Liu", "Yun Ma", "Ming Zhang"], "title": "MASS: Multi-Agent Simulation Scaling for Portfolio Construction", "categories": ["cs.AI"], "comment": null, "summary": "LLM-based multi-agent has gained significant attention for their potential in\nsimulation and enhancing performance. However, existing works are limited to\npure simulations or are constrained by predefined workflows, restricting their\napplicability and effectiveness. In this paper, we introduce the Multi-Agent\nScaling Simulation (MASS) for portfolio construction. MASS achieves stable and\ncontinuous excess returns by progressively increasing the number of agents for\nlarge-scale simulations to gain a superior understanding of the market and\noptimizing agent distribution end-to-end through a reverse optimization\nprocess, rather than relying on a fixed workflow. We demonstrate its\nsuperiority through performance experiments, ablation studies, backtesting\nexperiments, experiments on updated data and stock pools, scaling experiments,\nparameter sensitivity experiments, and visualization experiments, conducted in\ncomparison with 6 state-of-the-art baselines on 3 challenging A-share stock\npools. We expect the paradigm established by MASS to expand to other tasks with\nsimilar characteristics. The implementation of MASS has been open-sourced at\nhttps://github.com/gta0804/MASS."}
{"id": "2505.09820", "pdf": "https://arxiv.org/pdf/2505.09820", "abs": "https://arxiv.org/abs/2505.09820", "authors": ["Sajib Biswas", "Mao Nishino", "Samuel Jacob Chacko", "Xiuwen Liu"], "title": "Adversarial Attack on Large Language Models using Exponentiated Gradient Descent", "categories": ["cs.LG"], "comment": "Accepted to International Joint Conference on Neural Networks (IJCNN)\n  2025", "summary": "As Large Language Models (LLMs) are widely used, understanding them\nsystematically is key to improving their safety and realizing their full\npotential. Although many models are aligned using techniques such as\nreinforcement learning from human feedback (RLHF), they are still vulnerable to\njailbreaking attacks. Some of the existing adversarial attack methods search\nfor discrete tokens that may jailbreak a target model while others try to\noptimize the continuous space represented by the tokens of the model's\nvocabulary. While techniques based on the discrete space may prove to be\ninefficient, optimization of continuous token embeddings requires projections\nto produce discrete tokens, which might render them ineffective. To fully\nutilize the constraints and the structures of the space, we develop an\nintrinsic optimization technique using exponentiated gradient descent with the\nBregman projection method to ensure that the optimized one-hot encoding always\nstays within the probability simplex. We prove the convergence of the technique\nand implement an efficient algorithm that is effective in jailbreaking several\nwidely used LLMs. We demonstrate the efficacy of the proposed technique using\nfive open-source LLMs on four openly available datasets. The results show that\nthe technique achieves a higher success rate with great efficiency compared to\nthree other state-of-the-art jailbreaking techniques. The source code for our\nimplementation is available at:\nhttps://github.com/sbamit/Exponentiated-Gradient-Descent-LLM-Attack"}
{"id": "2505.10066", "pdf": "https://arxiv.org/pdf/2505.10066", "abs": "https://arxiv.org/abs/2505.10066", "authors": ["Michael Fire", "Yitzhak Elbazis", "Adi Wasenstein", "Lior Rokach"], "title": "Dark LLMs: The Growing Threat of Unaligned AI Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50, 68T05, 68P25", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated."}
{"id": "2505.09986", "pdf": "https://arxiv.org/pdf/2505.09986", "abs": "https://arxiv.org/abs/2505.09986", "authors": ["Yimin Zhou", "Yichong Xia", "Sicheng Pan", "Bin Chen", "Baoyi An", "Haoqian Wang", "Zhi Wang", "Yaowei Wang", "Zikun Zhou"], "title": "High Quality Underwater Image Compression with Adaptive Correction and Codebook-based Augmentation", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "With the increasing exploration and exploitation of the underwater world,\nunderwater images have become a critical medium for human interaction with\nmarine environments, driving extensive research into their efficient\ntransmission and storage. However, contemporary underwater image compression\nalgorithms fail to fully leverage the unique characteristics distinguishing\nunderwater scenes from terrestrial images, resulting in suboptimal performance.\nTo address this limitation, we introduce HQUIC, designed to exploit\nunderwater-image-specific features for enhanced compression efficiency. HQUIC\nemploys an ALTC module to adaptively predict the attenuation coefficients and\nglobal light information of the images, which effectively mitigates the issues\ncaused by the differences in lighting and tone existing in underwater images.\nSubsequently, HQUIC employs a codebook as an auxiliary branch to extract the\ncommon objects within underwater images and enhances the performance of the\nmain branch. Furthermore, HQUIC dynamically weights multi-scale frequency\ncomponents, prioritizing information critical for distortion quality while\ndiscarding redundant details. Extensive evaluations on diverse underwater\ndatasets demonstrate that HQUIC outperforms state-of-the-art compression\nmethods."}
{"id": "2505.10309", "pdf": "https://arxiv.org/pdf/2505.10309", "abs": "https://arxiv.org/abs/2505.10309", "authors": ["Tuan Dung Nguyen", "Duncan J. Watts", "Mark E. Whiting"], "title": "Empirically evaluating commonsense intelligence in large language models with large-scale human judgments", "categories": ["cs.AI", "cs.HC", "cs.SI"], "comment": null, "summary": "Commonsense intelligence in machines is often assessed by static benchmarks\nthat compare a model's output against human-prescribed correct labels. An\nimportant, albeit implicit, assumption of these labels is that they accurately\ncapture what any human would think, effectively treating human common sense as\nhomogeneous. However, recent empirical work has shown that humans vary\nenormously in what they consider commonsensical; thus what appears self-evident\nto one benchmark designer may not be so to another. Here, we propose a novel\nmethod for evaluating common sense in artificial intelligence (AI),\nspecifically in large language models (LLMs), that incorporates empirically\nobserved heterogeneity among humans by measuring the correspondence between a\nmodel's judgment and that of a human population. We first find that, when\ntreated as independent survey respondents, most LLMs remain below the human\nmedian in their individual commonsense competence. Second, when used as\nsimulators of a hypothetical population, LLMs correlate with real humans only\nmodestly in the extent to which they agree on the same set of statements. In\nboth cases, smaller, open-weight models are surprisingly more competitive than\nlarger, proprietary frontier models. Our evaluation framework, which ties\ncommonsense intelligence to its cultural basis, contributes to the growing call\nfor adapting AI models to human collectivities that possess different, often\nincompatible, social stocks of knowledge."}
{"id": "2505.09822", "pdf": "https://arxiv.org/pdf/2505.09822", "abs": "https://arxiv.org/abs/2505.09822", "authors": ["Changhao Shi", "Gal Mishne"], "title": "Learning Kronecker-Structured Graphs from Smooth Signals", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Graph learning, or network inference, is a prominent problem in graph signal\nprocessing (GSP). GSP generalizes the Fourier transform to non-Euclidean\ndomains, and graph learning is pivotal to applying GSP when these domains are\nunknown. With the recent prevalence of multi-way data, there has been growing\ninterest in product graphs that naturally factorize dependencies across\ndifferent ways. However, the types of graph products that can be learned are\nstill limited for modeling diverse dependency structures. In this paper, we\nstudy the problem of learning a Kronecker-structured product graph from smooth\nsignals. Unlike the more commonly used Cartesian product, the Kronecker product\nmodels dependencies in a more intricate, non-separable way, but posits harder\nconstraints on the graph learning problem. To tackle this non-convex problem,\nwe propose an alternating scheme to optimize each factor graph and provide\ntheoretical guarantees for its asymptotic convergence. The proposed algorithm\nis also modified to learn factor graphs of the strong product. We conduct\nexperiments on synthetic and real-world graphs and demonstrate our approach's\nefficacy and superior performance compared to existing methods."}
{"id": "2505.10081", "pdf": "https://arxiv.org/pdf/2505.10081", "abs": "https://arxiv.org/abs/2505.10081", "authors": ["Wisdom Aduah", "Francois Meyer"], "title": "Designing and Contextualising Probes for African Languages", "categories": ["cs.CL"], "comment": null, "summary": "Pretrained language models (PLMs) for African languages are continually\nimproving, but the reasons behind these advances remain unclear. This paper\npresents the first systematic investigation into probing PLMs for linguistic\nknowledge about African languages. We train layer-wise probes for six\ntypologically diverse African languages to analyse how linguistic features are\ndistributed. We also design control tasks, a way to interpret probe\nperformance, for the MasakhaPOS dataset. We find PLMs adapted for African\nlanguages to encode more linguistic information about target languages than\nmassively multilingual PLMs. Our results reaffirm previous findings that\ntoken-level syntactic information concentrates in middle-to-last layers, while\nsentence-level semantic information is distributed across all layers. Through\ncontrol tasks and probing baselines, we confirm that performance reflects the\ninternal knowledge of PLMs rather than probe memorisation. Our study applies\nestablished interpretability techniques to African-language PLMs. In doing so,\nwe highlight the internal mechanisms underlying the success of strategies like\nactive learning and multilingual adaptation."}
{"id": "2505.09990", "pdf": "https://arxiv.org/pdf/2505.09990", "abs": "https://arxiv.org/abs/2505.09990", "authors": ["Long Cheng", "Jiafei Duan", "Yi Ru Wang", "Haoquan Fang", "Boyang Li", "Yushan Huang", "Elvis Wang", "Ainaz Eftekhar", "Jason Lee", "Wentao Yuan", "Rose Hendrix", "Noah A. Smith", "Fei Xia", "Dieter Fox", "Ranjay Krishna"], "title": "PointArena: Probing Multimodal Grounding Through Language-Guided Pointing", "categories": ["cs.CV"], "comment": "10 Pages, Dataset and code:https://pointarena.github.io/", "summary": "Pointing serves as a fundamental and intuitive mechanism for grounding\nlanguage within visual contexts, with applications spanning robotics, assistive\ntechnologies, and interactive AI systems. While recent multimodal models have\nstarted to support pointing capabilities, existing benchmarks typically focus\nonly on referential object localization tasks. We introduce PointArena, a\ncomprehensive platform for evaluating multimodal pointing across diverse\nreasoning scenarios. PointArena comprises three components: (1) Point-Bench, a\ncurated dataset containing approximately 1,000 pointing tasks across five\nreasoning categories; (2) Point-Battle, an interactive, web-based arena\nfacilitating blind, pairwise model comparisons, which has already gathered over\n4,500 anonymized votes; and (3) Point-Act, a real-world robotic manipulation\nsystem allowing users to directly evaluate multimodal model pointing\ncapabilities in practical settings. We conducted extensive evaluations of both\nstate-of-the-art open-source and proprietary multimodal models. Results\nindicate that Molmo-72B consistently outperforms other models, though\nproprietary models increasingly demonstrate comparable performance.\nAdditionally, we find that supervised training specifically targeting pointing\ntasks significantly enhances model performance. Across our multi-stage\nevaluation pipeline, we also observe strong correlations, underscoring the\ncritical role of precise pointing capabilities in enabling multimodal models to\neffectively bridge abstract reasoning with concrete, real-world actions.\nProject page: https://pointarena.github.io/"}
{"id": "2505.10328", "pdf": "https://arxiv.org/pdf/2505.10328", "abs": "https://arxiv.org/abs/2505.10328", "authors": ["Alvin Combrink", "Stephie Do", "Kristofer Bengtsson", "Sabino Francesco Roselli", "Martin Fabian"], "title": "A Comparative Study of SMT and MILP for the Nurse Rostering Problem", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "6 pages, 3 figures", "summary": "The effects of personnel scheduling on the quality of care and working\nconditions for healthcare personnel have been thoroughly documented. However,\nthe ever-present demand and large variation of constraints make healthcare\nscheduling particularly challenging. This problem has been studied for decades,\nwith limited research aimed at applying Satisfiability Modulo Theories (SMT).\nSMT has gained momentum within the formal verification community in the last\ndecades, leading to the advancement of SMT solvers that have been shown to\noutperform standard mathematical programming techniques.\n  In this work, we propose generic constraint formulations that can model a\nwide range of real-world scheduling constraints. Then, the generic constraints\nare formulated as SMT and MILP problems and used to compare the respective\nstate-of-the-art solvers, Z3 and Gurobi, on academic and real-world inspired\nrostering problems. Experimental results show how each solver excels for\ncertain types of problems; the MILP solver generally performs better when the\nproblem is highly constrained or infeasible, while the SMT solver performs\nbetter otherwise. On real-world inspired problems containing a more varied set\nof shifts and personnel, the SMT solver excels. Additionally, it was noted\nduring experimentation that the SMT solver was more sensitive to the way the\ngeneric constraints were formulated, requiring careful consideration and\nexperimentation to achieve better performance. We conclude that SMT-based\nmethods present a promising avenue for future research within the domain of\npersonnel scheduling."}
{"id": "2505.09847", "pdf": "https://arxiv.org/pdf/2505.09847", "abs": "https://arxiv.org/abs/2505.09847", "authors": ["Liyang Zhao", "Olurotimi Seton", "Himadeep Reddy Reddivari", "Suvendu Jena", "Shadow Zhao", "Rachit Kumar", "Changshuai Wei"], "title": "Causal Predictive Optimization and Generation for Business AI", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "comment": null, "summary": "The sales process involves sales functions converting leads or opportunities\nto customers and selling more products to existing customers. The optimization\nof the sales process thus is key to success of any B2B business. In this work,\nwe introduce a principled approach to sales optimization and business AI,\nnamely the Causal Predictive Optimization and Generation, which includes three\nlayers: 1) prediction layer with causal ML 2) optimization layer with\nconstraint optimization and contextual bandit 3) serving layer with Generative\nAI and feedback-loop for system enhancement. We detail the implementation and\ndeployment of the system in LinkedIn, showcasing significant wins over legacy\nsystems and sharing learning and insight broadly applicable to this field."}
{"id": "2505.10089", "pdf": "https://arxiv.org/pdf/2505.10089", "abs": "https://arxiv.org/abs/2505.10089", "authors": ["Wei Liu", "Sony Trenous", "Leonardo F. R. Ribeiro", "Bill Byrne", "Felix Hieber"], "title": "XRAG: Cross-lingual Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "We propose XRAG, a novel benchmark designed to evaluate the generation\nabilities of LLMs in cross-lingual Retrieval-Augmented Generation (RAG)\nsettings where the user language does not match the retrieval results. XRAG is\nconstructed from recent news articles to ensure that its questions require\nexternal knowledge to be answered. It covers the real-world scenarios of\nmonolingual and multilingual retrieval, and provides relevancy annotations for\neach retrieved document. Our novel dataset construction pipeline results in\nquestions that require complex reasoning, as evidenced by the significant gap\nbetween human and LLM performance. Consequently, XRAG serves as a valuable\nbenchmark for studying LLM reasoning abilities, even before considering the\nadditional cross-lingual complexity. Experimental results on five LLMs uncover\ntwo previously unreported challenges in cross-lingual RAG: 1) in the\nmonolingual retrieval setting, all evaluated models struggle with response\nlanguage correctness; 2) in the multilingual retrieval setting, the main\nchallenge lies in reasoning over retrieved information across languages rather\nthan generation of non-English text."}
{"id": "2505.09997", "pdf": "https://arxiv.org/pdf/2505.09997", "abs": "https://arxiv.org/abs/2505.09997", "authors": ["Jinhyun Jang", "Jiyeong Lee", "Kwanghoon Sohn"], "title": "Descriptive Image-Text Matching with Graded Contextual Similarity", "categories": ["cs.CV"], "comment": null, "summary": "Image-text matching aims to build correspondences between visual and textual\ndata by learning their pairwise similarities. Most existing approaches have\nadopted sparse binary supervision, indicating whether a pair of images and\nsentences matches or not. However, such sparse supervision covers a limited\nsubset of image-text relationships, neglecting their inherent many-to-many\ncorrespondences; an image can be described in numerous texts at different\ndescriptive levels. Moreover, existing approaches overlook the implicit\nconnections from general to specific descriptions, which form the underlying\nrationale for the many-to-many relationships between vision and language. In\nthis work, we propose descriptive image-text matching, called DITM, to learn\nthe graded contextual similarity between image and text by exploring the\ndescriptive flexibility of language. We formulate the descriptiveness score of\neach sentence with cumulative term frequency-inverse document frequency\n(TF-IDF) to balance the pairwise similarity according to the keywords in the\nsentence. Our method leverages sentence descriptiveness to learn robust\nimage-text matching in two key ways: (1) to refine the false negative labeling,\ndynamically relaxing the connectivity between positive and negative pairs, and\n(2) to build more precise matching, aligning a set of relevant sentences in a\ngeneric-to-specific order. By moving beyond rigid binary supervision, DITM\nenhances the discovery of both optimal matches and potential positive pairs.\nExtensive experiments on MS-COCO, Flickr30K, and CxC datasets demonstrate the\neffectiveness of our method in representing complex image-text relationships\ncompared to state-of-the-art approaches. In addition, DITM enhances the\nhierarchical reasoning ability of the model, supported by the extensive\nanalysis on HierarCaps benchmark."}
{"id": "2505.10361", "pdf": "https://arxiv.org/pdf/2505.10361", "abs": "https://arxiv.org/abs/2505.10361", "authors": ["David Abel", "Michael Bowling", "André Barreto", "Will Dabney", "Shi Dong", "Steven Hansen", "Anna Harutyunyan", "Khimya Khetarpal", "Clare Lyle", "Razvan Pascanu", "Georgios Piliouras", "Doina Precup", "Jonathan Richens", "Mark Rowland", "Tom Schaul", "Satinder Singh"], "title": "Plasticity as the Mirror of Empowerment", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Agents are minimally entities that are influenced by their past observations\nand act to influence future observations. This latter capacity is captured by\nempowerment, which has served as a vital framing concept across artificial\nintelligence and cognitive science. This former capacity, however, is equally\nfoundational: In what ways, and to what extent, can an agent be influenced by\nwhat it observes? In this paper, we ground this concept in a universal\nagent-centric measure that we refer to as plasticity, and reveal a fundamental\nconnection to empowerment. Following a set of desiderata on a suitable\ndefinition, we define plasticity using a new information-theoretic quantity we\ncall the generalized directed information. We show that this new quantity\nstrictly generalizes the directed information introduced by Massey (1990) while\npreserving all of its desirable properties. Our first finding is that\nplasticity is the mirror of empowerment: The agent's plasticity is identical to\nthe empowerment of the environment, and vice versa. Our second finding\nestablishes a tension between the plasticity and empowerment of an agent,\nsuggesting that agent design needs to be mindful of both characteristics. We\nexplore the implications of these findings, and suggest that plasticity,\nempowerment, and their relationship are essential to understanding agency."}
{"id": "2505.09848", "pdf": "https://arxiv.org/pdf/2505.09848", "abs": "https://arxiv.org/abs/2505.09848", "authors": ["Aditya Raj", "Golrokh Mirzaei"], "title": "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection", "categories": ["cs.LG", "eess.IV"], "comment": "11 pages", "summary": "Imaging and genomic data offer distinct and rich features, and their\nintegration can unveil new insights into the complex landscape of diseases. In\nthis study, we present a novel approach utilizing radiogenomic data including\nstructural MRI images and gene expression data, for Alzheimer's disease\ndetection. Our framework introduces a novel heterogeneous bipartite graph\nrepresentation learning featuring two distinct node types: genes and images.\nThe network can effectively classify Alzheimer's disease (AD) into three\ndistinct stages:AD, Mild Cognitive Impairment (MCI), and Cognitive Normal (CN)\nclasses, utilizing a small dataset. Additionally, it identified which genes\nplay a significant role in each of these classification groups. We evaluate the\nperformance of our approach using metrics including classification accuracy,\nrecall, precision, and F1 score. The proposed technique holds potential for\nextending to radiogenomic-based classification to other diseases."}
{"id": "2505.10113", "pdf": "https://arxiv.org/pdf/2505.10113", "abs": "https://arxiv.org/abs/2505.10113", "authors": ["Xinlan Yan", "Di Wu", "Yibin Lei", "Christof Monz", "Iacer Calixto"], "title": "What Does Neuro Mean to Cardio? Investigating the Role of Clinical Specialty Data in Medical LLMs", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we introduce S-MedQA, an English medical question-answering\n(QA) dataset for benchmarking large language models in fine-grained clinical\nspecialties. We use S-MedQA to check the applicability of a popular hypothesis\nrelated to knowledge injection in the knowledge-intense scenario of medical QA,\nand show that: 1) training on data from a speciality does not necessarily lead\nto best performance on that specialty and 2) regardless of the specialty\nfine-tuned on, token probabilities of clinically relevant terms for all\nspecialties increase consistently. Thus, we believe improvement gains come\nmostly from domain shifting (e.g., general to medical) rather than knowledge\ninjection and suggest rethinking the role of fine-tuning data in the medical\ndomain. We release S-MedQA and all code needed to reproduce all our experiments\nto the research community."}
{"id": "2505.09998", "pdf": "https://arxiv.org/pdf/2505.09998", "abs": "https://arxiv.org/abs/2505.09998", "authors": ["Ying Zang", "Yuanqi Hu", "Xinyu Chen", "Yuxia Xu", "Suhui Wang", "Chunan Yu", "Lanyun Zhu", "Deyi Ji", "Xin Xu", "Tianrun Chen"], "title": "From Air to Wear: Personalized 3D Digital Fashion with AR/VR Immersive 3D Sketching", "categories": ["cs.CV"], "comment": "8 pages, 5 figures", "summary": "In the era of immersive consumer electronics, such as AR/VR headsets and\nsmart devices, people increasingly seek ways to express their identity through\nvirtual fashion. However, existing 3D garment design tools remain inaccessible\nto everyday users due to steep technical barriers and limited data. In this\nwork, we introduce a 3D sketch-driven 3D garment generation framework that\nempowers ordinary users - even those without design experience - to create\nhigh-quality digital clothing through simple 3D sketches in AR/VR environments.\nBy combining a conditional diffusion model, a sketch encoder trained in a\nshared latent space, and an adaptive curriculum learning strategy, our system\ninterprets imprecise, free-hand input and produces realistic, personalized\ngarments. To address the scarcity of training data, we also introduce\nKO3DClothes, a new dataset of paired 3D garments and user-created sketches.\nExtensive experiments and user studies confirm that our method significantly\noutperforms existing baselines in both fidelity and usability, demonstrating\nits promise for democratized fashion design on next-generation consumer\nplatforms."}
{"id": "2505.10399", "pdf": "https://arxiv.org/pdf/2505.10399", "abs": "https://arxiv.org/abs/2505.10399", "authors": ["Kaivalya Rawal", "Zihao Fu", "Eoin Delaney", "Chris Russell"], "title": "Evaluating Model Explanations without Ground Truth", "categories": ["cs.AI", "cs.LG", "I.2.6"], "comment": "https://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth", "summary": "There can be many competing and contradictory explanations for a single model\nprediction, making it difficult to select which one to use. Current explanation\nevaluation frameworks measure quality by comparing against ideal \"ground-truth\"\nexplanations, or by verifying model sensitivity to important inputs. We outline\nthe limitations of these approaches, and propose three desirable principles to\nground the future development of explanation evaluation strategies for local\nfeature importance explanations. We propose a ground-truth Agnostic eXplanation\nEvaluation framework (AXE) for evaluating and comparing model explanations that\nsatisfies these principles. Unlike prior approaches, AXE does not require\naccess to ideal ground-truth explanations for comparison, or rely on model\nsensitivity - providing an independent measure of explanation quality. We\nverify AXE by comparing with baselines, and show how it can be used to detect\nexplanation fairwashing. Our code is available at\nhttps://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth."}
{"id": "2505.09851", "pdf": "https://arxiv.org/pdf/2505.09851", "abs": "https://arxiv.org/abs/2505.09851", "authors": ["Shun Wang", "Shun-Li Shang", "Zi-Kui Liu", "Wenrui Hao"], "title": "ZENN: A Thermodynamics-Inspired Computational Framework for Heterogeneous Data-Driven Modeling", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "9 pages, 4 figures", "summary": "Traditional entropy-based methods - such as cross-entropy loss in\nclassification problems - have long been essential tools for quantifying\nuncertainty and disorder in data and developing artificial intelligence\nalgorithms. However, the rapid growth of data across various domains has\nintroduced new challenges, particularly the integration of heterogeneous\ndatasets with intrinsic disparities. In this paper, we extend zentropy theory\ninto the data science domain by introducing intrinsic entropy, enabling more\neffective learning from heterogeneous data sources. We propose a\nzentropy-enhanced neural network (ZENN) that simultaneously learns both energy\nand intrinsic entropy components, capturing the underlying structure of\nmulti-source data. To support this, we redesign the neural network architecture\nto better reflect the intrinsic properties and variability inherent in diverse\ndatasets. We demonstrate the effectiveness of ZENN on classification tasks and\nenergy landscape reconstructions, showing its superior generalization\ncapabilities and robustness-particularly in predicting high-order derivatives.\nAs a practical application, we employ ZENN to reconstruct the Helmholtz energy\nlandscape of Fe3Pt using data generated from DFT and capture key material\nbehaviors, including negative thermal expansion and the critical point in the\ntemperature-pressure space. Overall, our study introduces a novel approach for\ndata-driven machine learning grounded in zentropy theory, highlighting ZENN as\na versatile and robust deep learning framework for scientific problems\ninvolving complex, heterogeneous datasets."}
{"id": "2505.10143", "pdf": "https://arxiv.org/pdf/2505.10143", "abs": "https://arxiv.org/abs/2505.10143", "authors": ["Longchao Da", "Parth Mitesh Shah", "Kuan-Ru Liou", "Jiaxing Zhang", "Hua Wei"], "title": "GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs", "categories": ["cs.CL", "68T50, 68T30", "I.2.7; I.2.4; H.3.3"], "comment": "5 pages, 4 figures, accepted to IJCAI2025 demo track", "summary": "Large Language Models are now key assistants in human decision-making\nprocesses. However, a common note always seems to follow: \"LLMs can make\nmistakes. Be careful with important info.\" This points to the reality that not\nall outputs from LLMs are dependable, and users must evaluate them manually.\nThe challenge deepens as hallucinated responses, often presented with seemingly\nplausible explanations, create complications and raise trust issues among\nusers. To tackle such issue, this paper proposes GE-Chat, a knowledge Graph\nenhanced retrieval-augmented generation framework to provide Evidence-based\nresponse generation. Specifically, when the user uploads a material document, a\nknowledge graph will be created, which helps construct a retrieval-augmented\nagent, enhancing the agent's responses with additional knowledge beyond its\ntraining corpus. Then we leverage Chain-of-Thought (CoT) logic generation,\nn-hop sub-graph searching, and entailment-based sentence generation to realize\naccurate evidence retrieval. We demonstrate that our method improves the\nexisting models' performance in terms of identifying the exact evidence in a\nfree-form context, providing a reliable way to examine the resources of LLM's\nconclusion and help with the judgment of the trustworthiness."}
{"id": "2505.10016", "pdf": "https://arxiv.org/pdf/2505.10016", "abs": "https://arxiv.org/abs/2505.10016", "authors": ["Shijie Lyu"], "title": "Application of YOLOv8 in monocular downward multiple Car Target detection", "categories": ["cs.CV", "cs.AI", "I.4.8; I.2.10"], "comment": "Accepted by the 5th International Conference on Signal Processing and\n  Machine Learning (CONF-SPML 2025), to appear in Applied and Computational\n  Engineering", "summary": "Autonomous driving technology is progressively transforming traditional car\ndriving methods, marking a significant milestone in modern transportation.\nObject detection serves as a cornerstone of autonomous systems, playing a vital\nrole in enhancing driving safety, enabling autonomous functionality, improving\ntraffic efficiency, and facilitating effective emergency responses. However,\ncurrent technologies such as radar for environmental perception, cameras for\nroad perception, and vehicle sensor networks face notable challenges, including\nhigh costs, vulnerability to weather and lighting conditions, and limited\nresolution.To address these limitations, this paper presents an improved\nautonomous target detection network based on YOLOv8. By integrating structural\nreparameterization technology, a bidirectional pyramid structure network model,\nand a novel detection pipeline into the YOLOv8 framework, the proposed approach\nachieves highly efficient and precise detection of multi-scale, small, and\nremote objects. Experimental results demonstrate that the enhanced model can\neffectively detect both large and small objects with a detection accuracy of\n65%, showcasing significant advancements over traditional methods.This improved\nmodel holds substantial potential for real-world applications and is\nwell-suited for autonomous driving competitions, such as the Formula Student\nAutonomous China (FSAC), particularly excelling in scenarios involving\nsingle-target and small-object detection."}
{"id": "2505.10468", "pdf": "https://arxiv.org/pdf/2505.10468", "abs": "https://arxiv.org/abs/2505.10468", "authors": ["Ranjan Sapkota", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "title": "AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge", "categories": ["cs.AI"], "comment": "32 pages, 14 figures, 11 tables", "summary": "This study critically distinguishes between AI Agents and Agentic AI,\noffering a structured conceptual taxonomy, application mapping, and challenge\nanalysis to clarify their divergent design philosophies and capabilities. We\nbegin by outlining the search strategy and foundational definitions,\ncharacterizing AI Agents as modular systems driven by Large Language Models\n(LLMs) and Large Image Models (LIMs) for narrow, task-specific automation.\nGenerative AI is positioned as a precursor, with AI Agents advancing through\ntool integration, prompt engineering, and reasoning enhancements. In contrast,\nAgentic AI systems represent a paradigmatic shift marked by multi-agent\ncollaboration, dynamic task decomposition, persistent memory, and orchestrated\nautonomy. Through a sequential evaluation of architectural evolution,\noperational mechanisms, interaction styles, and autonomy levels, we present a\ncomparative analysis across both paradigms. Application domains such as\ncustomer support, scheduling, and data summarization are contrasted with\nAgentic AI deployments in research automation, robotic coordination, and\nmedical decision support. We further examine unique challenges in each paradigm\nincluding hallucination, brittleness, emergent behavior, and coordination\nfailure and propose targeted solutions such as ReAct loops, RAG, orchestration\nlayers, and causal modeling. This work aims to provide a definitive roadmap for\ndeveloping robust, scalable, and explainable AI agent and Agentic AI-driven\nsystems. >AI Agents, Agent-driven, Vision-Language-Models, Agentic AI Decision\nSupport System, Agentic-AI Applications"}
{"id": "2505.09854", "pdf": "https://arxiv.org/pdf/2505.09854", "abs": "https://arxiv.org/abs/2505.09854", "authors": ["Harikrishna Kuttivelil", "Katia Obraczka"], "title": "Chisme: Fully Decentralized Differentiated Deep Learning for Edge Intelligence", "categories": ["cs.LG", "cs.ET", "cs.MA", "cs.SI"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "As demand for intelligent services rises and edge devices become more\ncapable, distributed learning at the network edge has emerged as a key enabling\ntechnology. While existing paradigms like federated learning (FL) and\ndecentralized FL (DFL) enable privacy-preserving distributed learning in many\nscenarios, they face potential challenges in connectivity and synchronization\nimposed by resource-constrained and infrastructure-less environments. While\nmore robust, gossip learning (GL) algorithms have generally been designed for\nhomogeneous data distributions and may not suit all contexts. This paper\nintroduces Chisme, a novel suite of protocols designed to address the\nchallenges of implementing robust intelligence in the network edge,\ncharacterized by heterogeneous data distributions, episodic connectivity, and\nlack of infrastructure. Chisme includes both synchronous DFL (Chisme-DFL) and\nasynchronous GL (Chisme-GL) variants that enable collaborative yet\ndecentralized model training that considers underlying data heterogeneity. We\nintroduce a data similarity heuristic that allows agents to opportunistically\ninfer affinity with each other using the existing communication of model\nupdates in decentralized FL and GL. We leverage the heuristic to extend DFL's\nmodel aggregation and GL's model merge mechanisms for better personalized\ntraining while maintaining collaboration. While Chisme-DFL is a synchronous\ndecentralized approach whose resource utilization scales linearly with network\nsize, Chisme-GL is fully asynchronous and has a lower, constant resource\nrequirement independent of network size. We demonstrate that Chisme methods\noutperform their standard counterparts in model training over distributed and\nheterogeneous data in network scenarios ranging from less connected and\nreliable networks to fully connected and lossless networks."}
{"id": "2505.10182", "pdf": "https://arxiv.org/pdf/2505.10182", "abs": "https://arxiv.org/abs/2505.10182", "authors": ["Yoichi Ishibashi", "Taro Yano", "Masafumi Oyamada"], "title": "Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant improvements in\nreasoning capabilities through supervised fine-tuning and reinforcement\nlearning. However, when training reasoning models, these approaches are\nprimarily applicable to specific domains such as mathematics and programming,\nwhich imposes fundamental constraints on the breadth and scalability of\ntraining data. In contrast, continual pretraining (CPT) offers the advantage of\nnot requiring task-specific signals. Nevertheless, how to effectively\nsynthesize training data for reasoning and how such data affect a wide range of\ndomains remain largely unexplored. This study provides a detailed evaluation of\nReasoning CPT, a form of CPT that uses synthetic data to reconstruct the hidden\nthought processes underlying texts, based on the premise that texts are the\nresult of the author's thinking process. Specifically, we apply Reasoning CPT\nto Gemma2-9B using synthetic data with hidden thoughts derived from STEM and\nLaw corpora, and compare it to standard CPT on the MMLU benchmark. Our analysis\nreveals that Reasoning CPT consistently improves performance across all\nevaluated domains. Notably, reasoning skills acquired in one domain transfer\neffectively to others; the performance gap with conventional methods widens as\nproblem difficulty increases, with gains of up to 8 points on the most\nchallenging problems. Furthermore, models trained with hidden thoughts learn to\nadjust the depth of their reasoning according to problem difficulty."}
{"id": "2505.10027", "pdf": "https://arxiv.org/pdf/2505.10027", "abs": "https://arxiv.org/abs/2505.10027", "authors": ["Shijie Lyu"], "title": "ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by the 4th International Conference on Computing Innovation\n  and Applied Physics (CONF-CIAP 2025), and will be published in EAI Community\n  Research Series-CORE or Theoretical and Natural Science (TNS)", "summary": "With the rapid advancement of remote sensing technology, super-resolution\nimage reconstruction is of great research and practical significance. Existing\ndeep learning methods have made progress but still face limitations in handling\ncomplex scenes and preserving image details. This paper proposes a\nreinforcement learning-based latent diffusion model (LDM) fine-tuning method\nfor remote sensing image super-resolution. The method constructs a\nreinforcement learning environment with states, actions, and rewards,\noptimizing decision objectives through proximal policy optimization (PPO)\nduring the reverse denoising process of the LDM model. Experiments on the\nRESISC45 dataset show significant improvements over the baseline model in PSNR,\nSSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11,\nand LPIPS reducing by 0.06-0.10, particularly in structured and complex natural\nscenes. The results demonstrate the method's effectiveness in enhancing\nsuper-resolution quality and adaptability across scenes."}
{"id": "2505.10543", "pdf": "https://arxiv.org/pdf/2505.10543", "abs": "https://arxiv.org/abs/2505.10543", "authors": ["Annie Wong", "Thomas Bäck", "Aske Plaat", "Niki van Stein", "Anna V. Kononova"], "title": "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While large language models demonstrate impressive performance on static\nbenchmarks, the true potential of large language models as self-learning and\nreasoning agents in dynamic environments remains unclear. This study\nsystematically evaluates the efficacy of self-reflection, heuristic mutation,\nand planning as prompting techniques to test the adaptive capabilities of\nagents. We conduct experiments with various open-source language models in\ndynamic environments and find that larger models generally outperform smaller\nones, but that strategic prompting can close this performance gap. Second, a\ntoo-long prompt can negatively impact smaller models on basic reactive tasks,\nwhile larger models show more robust behaviour. Third, advanced prompting\ntechniques primarily benefit smaller models on complex games, but offer less\nimprovement for already high-performing large language models. Yet, we find\nthat advanced reasoning methods yield highly variable outcomes: while capable\nof significantly improving performance when reasoning and decision-making\nalign, they also introduce instability and can lead to big performance drops.\nCompared to human performance, our findings reveal little evidence of true\nemergent reasoning. Instead, large language model performance exhibits\npersistent limitations in crucial areas such as planning, reasoning, and\nspatial coordination, suggesting that current-generation large language models\nstill suffer fundamental shortcomings that may not be fully overcome through\nself-reflective prompting alone. Reasoning is a multi-faceted task, and while\nreasoning methods like Chain of thought improves multi-step reasoning on math\nword problems, our findings using dynamic benchmarks highlight important\nshortcomings in general reasoning capabilities, indicating a need to move\nbeyond static benchmarks to capture the complexity of reasoning."}
{"id": "2505.09855", "pdf": "https://arxiv.org/pdf/2505.09855", "abs": "https://arxiv.org/abs/2505.09855", "authors": ["Alexander Y. Ku", "Thomas L. Griffiths", "Stephanie C. Y. Chan"], "title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies."}
{"id": "2505.10185", "pdf": "https://arxiv.org/pdf/2505.10185", "abs": "https://arxiv.org/abs/2505.10185", "authors": ["Seongyun Lee", "Seungone Kim", "Minju Seo", "Yongrae Jo", "Dongyoung Go", "Hyeonbin Hwang", "Jinho Park", "Xiang Yue", "Sean Welleck", "Graham Neubig", "Moontae Lee", "Minjoon Seo"], "title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think", "categories": ["cs.CL", "cs.AI"], "comment": "Work in progress", "summary": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of\nmodern large language models, but our understanding of the reasoning strategies\nunderlying these capabilities remains limited. While some prior works have\nattempted to categorize CoTs using predefined strategy types, such approaches\nare constrained by human intuition and fail to capture the full diversity of\nmodel behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up\nframework for analyzing and steering model reasoning. Our method automatically\nextracts diverse reasoning criteria from model-generated CoTs, embeds them into\na semantic space, clusters them into representative categories, and derives\ncontrastive rubrics to interpret reasoning behavior. Human evaluations show\nthat this framework produces more interpretable and comprehensive analyses than\nexisting methods. Moreover, we demonstrate that this understanding enables\nperformance gains: we can predict which strategy a model is likely to use and\nguide it toward more effective alternatives. Finally, we provide practical\ninsights, such as that training data format (e.g., free-form vs.\nmultiple-choice) has a far greater impact on reasoning behavior than data\ndomain, underscoring the importance of format-aware model design."}
{"id": "2505.10030", "pdf": "https://arxiv.org/pdf/2505.10030", "abs": "https://arxiv.org/abs/2505.10030", "authors": ["Miit Daga", "Dhriti Parikh", "Swarna Priya Ramu"], "title": "DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera", "categories": ["cs.CV", "cs.LG"], "comment": "This paper is accepted for publication in IEEE Access journal and is\n  currently pending revisions before publication", "summary": "Coconut tree diseases are a serious risk to agricultural yield, particularly\nin developing countries where conventional farming practices restrict early\ndiagnosis and intervention. Current disease identification methods are manual,\nlabor-intensive, and non-scalable. In response to these limitations, we come up\nwith DeepSeqCoco, a deep learning based model for accurate and automatic\ndisease identification from coconut tree images. The model was tested under\nvarious optimizer settings, such as SGD, Adam, and hybrid configurations, to\nidentify the optimal balance between accuracy, minimization of loss, and\ncomputational cost. Results from experiments indicate that DeepSeqCoco can\nachieve as much as 99.5% accuracy (achieving up to 5% higher accuracy than\nexisting models) with the hybrid SGD-Adam showing the lowest validation loss of\n2.81%. It also shows a drop of up to 18% in training time and up to 85% in\nprediction time for input images. The results point out the promise of the\nmodel to improve precision agriculture through an AI-based, scalable, and\nefficient disease monitoring system."}
{"id": "2306.07615", "pdf": "https://arxiv.org/pdf/2306.07615", "abs": "https://arxiv.org/abs/2306.07615", "authors": ["Heqin Zhu", "Quan Quan", "Qingsong Yao", "Zaiyi Liu", "S. Kevin Zhou"], "title": "UOD: Universal One-shot Detection of Anatomical Landmarks", "categories": ["cs.CV", "cs.AI"], "comment": "Eealy accepted by MICCAI 2023. 11pages, 4 figures, 2 tables. arXiv\n  admin note: text overlap with arXiv:2203.06433", "summary": "One-shot medical landmark detection gains much attention and achieves great\nsuccess for its label-efficient training process. However, existing one-shot\nlearning methods are highly specialized in a single domain and suffer domain\npreference heavily in the situation of multi-domain unlabeled data. Moreover,\none-shot learning is not robust that it faces performance drop when annotating\na sub-optimal image. To tackle these issues, we resort to developing a\ndomain-adaptive one-shot landmark detection framework for handling multi-domain\nmedical images, named Universal One-shot Detection (UOD). UOD consists of two\nstages and two corresponding universal models which are designed as\ncombinations of domain-specific modules and domain-shared modules. In the first\nstage, a domain-adaptive convolution model is self-supervised learned to\ngenerate pseudo landmark labels. In the second stage, we design a\ndomain-adaptive transformer to eliminate domain preference and build the global\ncontext for multi-domain data. Even though only one annotated sample from each\ndomain is available for training, the domain-shared modules help UOD aggregate\nall one-shot samples to detect more robust and accurate landmarks. We\ninvestigated both qualitatively and quantitatively the proposed UOD on three\nwidely-used public X-ray datasets in different anatomical domains (i.e., head,\nhand, chest) and obtained state-of-the-art performances in each domain. The\ncode is available at\nhttps://github.com/heqin-zhu/UOD_universal_oneshot_detection."}
{"id": "2505.09861", "pdf": "https://arxiv.org/pdf/2505.09861", "abs": "https://arxiv.org/abs/2505.09861", "authors": ["John Bencina", "Erkut Aykutlug", "Yue Chen", "Zerui Zhang", "Stephanie Sorenson", "Shao Tang", "Changshuai Wei"], "title": "LiDDA: Data Driven Attribution at LinkedIn", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ME"], "comment": null, "summary": "Data Driven Attribution, which assigns conversion credits to marketing\ninteractions based on causal patterns learned from data, is the foundation of\nmodern marketing intelligence and vital to any marketing businesses and\nadvertising platform. In this paper, we introduce a unified transformer-based\nattribution approach that can handle member-level data, aggregate-level data,\nand integration of external macro factors. We detail the large scale\nimplementation of the approach at LinkedIn, showcasing significant impact. We\nalso share learning and insights that are broadly applicable to the marketing\nand ad tech fields."}
{"id": "2505.10202", "pdf": "https://arxiv.org/pdf/2505.10202", "abs": "https://arxiv.org/abs/2505.10202", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "YiMing Cheng", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "VQ-Logits: Compressing the Output Bottleneck of Large Language Models via Vector Quantized Logits", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success but face\nsignificant computational and memory challenges, particularly due to their\nextensive output vocabularies. The final linear projection layer, mapping\nhidden states to vocabulary-sized logits, often constitutes a substantial\nportion of the model's parameters and computational cost during inference.\nExisting methods like adaptive softmax or hierarchical softmax introduce\nstructural complexities. In this paper, we propose VQ-Logits, a novel approach\nthat leverages Vector Quantization (VQ) to drastically reduce the parameter\ncount and computational load of the LLM output layer. VQ-Logits replaces the\nlarge V * dmodel output embedding matrix with a small, shared codebook of K\nembedding vectors (K << V ). Each token in the vocabulary is mapped to one of\nthese K codebook vectors. The LLM predicts logits over this compact codebook,\nwhich are then efficiently \"scattered\" to the full vocabulary space using the\nlearned or preassigned mapping. We demonstrate through extensive experiments on\nstandard language modeling benchmarks (e.g., WikiText-103, C4) that VQ-Logits\ncan achieve up to 99% parameter reduction in the output layer and 6x speedup in\nlogit computation, with only a marginal 4% increase in perplexity compared to\nfull softmax baselines. We further provide detailed ablation studies on\ncodebook size, initialization, and learning strategies, showcasing the\nrobustness and effectiveness of our approach."}
{"id": "2505.10046", "pdf": "https://arxiv.org/pdf/2505.10046", "abs": "https://arxiv.org/abs/2505.10046", "authors": ["Bingda Tang", "Boyang Zheng", "Xichen Pan", "Sayak Paul", "Saining Xie"], "title": "Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Text-to-Image Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "This paper does not describe a new method; instead, it provides a thorough\nexploration of an important yet understudied design space related to recent\nadvances in text-to-image synthesis -- specifically, the deep fusion of large\nlanguage models (LLMs) and diffusion transformers (DiTs) for multi-modal\ngeneration. Previous studies mainly focused on overall system performance\nrather than detailed comparisons with alternative methods, and key design\ndetails and training recipes were often left undisclosed. These gaps create\nuncertainty about the real potential of this approach. To fill these gaps, we\nconduct an empirical study on text-to-image generation, performing controlled\ncomparisons with established baselines, analyzing important design choices, and\nproviding a clear, reproducible recipe for training at scale. We hope this work\noffers meaningful data points and practical guidelines for future research in\nmulti-modal generation."}
{"id": "2410.13778", "pdf": "https://arxiv.org/pdf/2410.13778", "abs": "https://arxiv.org/abs/2410.13778", "authors": ["Michelangelo Olmo Nogara Notarianni", "Filippo Leveni", "Diego Stucchi", "Luca Frittoli", "Giacomo Boracchi"], "title": "Change Detection in Multivariate data streams: Online Analysis with Kernel-QuantTree", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "AALTD workshop at ECML 2024 (https://ecml-aaltd.github.io/aaltd2024/)", "summary": "We present Kernel-QuantTree Exponentially Weighted Moving Average (KQT-EWMA),\na non-parametric change-detection algorithm that combines the Kernel-QuantTree\n(KQT) histogram and the EWMA statistic to monitor multivariate data streams\nonline. The resulting monitoring scheme is very flexible, since histograms can\nbe used to model any stationary distribution, and practical, since the\ndistribution of test statistics does not depend on the distribution of\ndatastream in stationary conditions (non-parametric monitoring). KQT-EWMA\nenables controlling false alarms by operating at a pre-determined Average Run\nLength ($ARL_0$), which measures the expected number of stationary samples to\nbe monitored before triggering a false alarm. The latter peculiarity is in\ncontrast with most non-parametric change-detection tests, which rarely can\ncontrol the $ARL_0$ a priori. Our experiments on synthetic and real-world\ndatasets demonstrate that KQT-EWMA can control $ARL_0$ while achieving\ndetection delays comparable to or lower than state-of-the-art methods designed\nto work in the same conditions."}
{"id": "2505.09864", "pdf": "https://arxiv.org/pdf/2505.09864", "abs": "https://arxiv.org/abs/2505.09864", "authors": ["Aditya Panangat"], "title": "BINGO: A Novel Pruning Mechanism to Reduce the Size of Neural Networks", "categories": ["cs.LG"], "comment": "6 pages, 0 figures, 2 tables", "summary": "Over the past decade, the use of machine learning has increased\nexponentially. Models are far more complex than ever before, growing to\ngargantuan sizes and housing millions of weights. Unfortunately, the fact that\nlarge models have become the state of the art means that it often costs\nmillions of dollars to train and operate them. These expenses not only hurt\ncompanies but also bar non-wealthy individuals from contributing to new\ndevelopments and force consumers to pay greater prices for AI. Current methods\nused to prune models, such as iterative magnitude pruning, have shown great\naccuracy but require an iterative training sequence that is incredibly\ncomputationally and environmentally taxing. To solve this problem, BINGO is\nintroduced. BINGO, during the training pass, studies specific subsets of a\nneural network one at a time to gauge how significant of a role each weight\nplays in contributing to a network's accuracy. By the time training is done,\nBINGO generates a significance score for each weight, allowing for\ninsignificant weights to be pruned in one shot. BINGO provides an\naccuracy-preserving pruning technique that is less computationally intensive\nthan current methods, allowing for a world where AI growth does not have to\nmean model growth, as well."}
{"id": "2505.10218", "pdf": "https://arxiv.org/pdf/2505.10218", "abs": "https://arxiv.org/abs/2505.10218", "authors": ["Zongsheng Wang", "Kaili Sun", "Bowen Wu", "Qun Yu", "Ying Li", "Baoxun Wang"], "title": "RAIDEN-R1: Improving Role-awareness of LLMs via GRPO with Verifiable Reward", "categories": ["cs.CL"], "comment": null, "summary": "Role-playing conversational agents (RPCAs) face persistent challenges in\nmaintaining role consistency. To address this, we propose RAIDEN-R1, a novel\nreinforcement learning framework that integrates Verifiable Role-Awareness\nReward (VRAR). The method introduces both singular and multi-term mining\nstrategies to generate quantifiable rewards by assessing role-specific keys.\nAdditionally, we construct a high-quality, role-aware Chain-of-Thought dataset\nthrough multi-LLM collaboration, and implement experiments to enhance reasoning\ncoherence. Experiments on the RAIDEN benchmark demonstrate RAIDEN-R1's\nsuperiority: our 14B-GRPO model achieves 88.04% and 88.65% accuracy on\nScript-Based Knowledge and Conversation Memory metrics, respectively,\noutperforming baseline models while maintaining robustness. Case analyses\nfurther reveal the model's enhanced ability to resolve conflicting contextual\ncues and sustain first-person narrative consistency. This work bridges the\nnon-quantifiability gap in RPCA training and provides insights into role-aware\nreasoning patterns, advancing the development of RPCAs."}
{"id": "2505.10049", "pdf": "https://arxiv.org/pdf/2505.10049", "abs": "https://arxiv.org/abs/2505.10049", "authors": ["Jinlong Fan", "Xuepu Zeng", "Jing Zhang", "Mingming Gong", "Yuxiang Yang", "Dacheng Tao"], "title": "Advances in Radiance Field for Dynamic Scene: From Neural Field to Gaussian Field", "categories": ["cs.CV"], "comment": null, "summary": "Dynamic scene representation and reconstruction have undergone transformative\nadvances in recent years, catalyzed by breakthroughs in neural radiance fields\nand 3D Gaussian splatting techniques. While initially developed for static\nenvironments, these methodologies have rapidly evolved to address the\ncomplexities inherent in 4D dynamic scenes through an expansive body of\nresearch. Coupled with innovations in differentiable volumetric rendering,\nthese approaches have significantly enhanced the quality of motion\nrepresentation and dynamic scene reconstruction, thereby garnering substantial\nattention from the computer vision and graphics communities. This survey\npresents a systematic analysis of over 200 papers focused on dynamic scene\nrepresentation using radiance field, spanning the spectrum from implicit neural\nrepresentations to explicit Gaussian primitives. We categorize and evaluate\nthese works through multiple critical lenses: motion representation paradigms,\nreconstruction techniques for varied scene dynamics, auxiliary information\nintegration strategies, and regularization approaches that ensure temporal\nconsistency and physical plausibility. We organize diverse methodological\napproaches under a unified representational framework, concluding with a\ncritical examination of persistent challenges and promising research\ndirections. By providing this comprehensive overview, we aim to establish a\ndefinitive reference for researchers entering this rapidly evolving field while\noffering experienced practitioners a systematic understanding of both\nconceptual principles and practical frontiers in dynamic scene reconstruction."}
{"id": "2505.03084", "pdf": "https://arxiv.org/pdf/2505.03084", "abs": "https://arxiv.org/abs/2505.03084", "authors": ["Shashank Kapoor", "Sanjay Surendranath Girija", "Lakshit Arora", "Dipen Pradhan", "Ankit Shetgaonkar", "Aman Raj"], "title": "Adversarial Attacks in Multimodal Systems: A Practitioner's Survey", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in IEEE COMPSAC 2025", "summary": "The introduction of multimodal models is a huge step forward in Artificial\nIntelligence. A single model is trained to understand multiple modalities:\ntext, image, video, and audio. Open-source multimodal models have made these\nbreakthroughs more accessible. However, considering the vast landscape of\nadversarial attacks across these modalities, these models also inherit\nvulnerabilities of all the modalities, and ultimately, the adversarial threat\namplifies. While broad research is available on possible attacks within or\nacross these modalities, a practitioner-focused view that outlines attack types\nremains absent in the multimodal world. As more Machine Learning Practitioners\nadopt, fine-tune, and deploy open-source models in real-world applications,\nit's crucial that they can view the threat landscape and take the preventive\nactions necessary. This paper addresses the gap by surveying adversarial\nattacks targeting all four modalities: text, image, video, and audio. This\nsurvey provides a view of the adversarial attack landscape and presents how\nmultimodal adversarial threats have evolved. To the best of our knowledge, this\nsurvey is the first comprehensive summarization of the threat landscape in the\nmultimodal world."}
{"id": "2505.09901", "pdf": "https://arxiv.org/pdf/2505.09901", "abs": "https://arxiv.org/abs/2505.09901", "authors": ["Ziyuan Zhang", "Darcy Wang", "Ningyuan Chen", "Rodrigo Mansur", "Vahid Sarhangian"], "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements."}
{"id": "2505.10260", "pdf": "https://arxiv.org/pdf/2505.10260", "abs": "https://arxiv.org/abs/2505.10260", "authors": ["Poli Apollinaire Nemkova", "Solomon Ubani", "Mark V. Albert"], "title": "Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the era of increasingly sophisticated natural language processing (NLP)\nsystems, large language models (LLMs) have demonstrated remarkable potential\nfor diverse applications, including tasks requiring nuanced textual\nunderstanding and contextual reasoning. This study investigates the\ncapabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3,\nMistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex\ntextual dataset comprising social media posts in Russian and Ukrainian.\nSpecifically, the focus is on the binary classification task of identifying\nreferences to human rights violations within the dataset.\n  To evaluate the effectiveness of these models, their annotations are compared\nagainst a gold standard set of human double-annotated labels across 1000\nsamples. The analysis includes assessing annotation performance under different\nprompting conditions, with prompts provided in both English and Russian.\nAdditionally, the study explores the unique patterns of errors and\ndisagreements exhibited by each model, offering insights into their strengths,\nlimitations, and cross-linguistic adaptability.\n  By juxtaposing LLM outputs with human annotations, this research contributes\nto understanding the reliability and applicability of LLMs for sensitive,\ndomain-specific tasks in multilingual contexts. It also sheds light on how\nlanguage models handle inherently subjective and context-dependent judgments, a\ncritical consideration for their deployment in real-world scenarios."}
{"id": "2505.10055", "pdf": "https://arxiv.org/pdf/2505.10055", "abs": "https://arxiv.org/abs/2505.10055", "authors": ["Ijazul Haq", "Yingjie Zhang", "Irfan Ali Khan"], "title": "PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper evaluates the performance of Large Multimodal Models (LMMs) on\nOptical Character Recognition (OCR) in the low-resource Pashto language.\nNatural Language Processing (NLP) in Pashto faces several challenges due to the\ncursive nature of its script and a scarcity of structured datasets. To address\nthis, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one\nmillion images annotated with bounding boxes at word, line, and document\nlevels, suitable for training and evaluating models based on different\narchitectures, including Convolutional Neural Networks (CNNs) and Transformers.\nPsOCR covers variations across 1,000 unique font families, colors, image sizes,\nand layouts. A benchmark subset of 10K images was selected to evaluate the\nperformance of several LMMs, including seven open-source models: DeepSeek's\nJanus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four\nclosed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results\ndemonstrate that Gemini achieves the best performance among all models, whereas\namong open-source models, Qwen-7B stands out. This work provides an insightful\nassessment of the capabilities and limitations of current LMMs for OCR tasks in\nPashto and establishes a foundation for further research not only in Pashto OCR\nbut also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is\navailable at https://github.com/zirak-ai/PashtoOCR."}
{"id": "2505.08202", "pdf": "https://arxiv.org/pdf/2505.08202", "abs": "https://arxiv.org/abs/2505.08202", "authors": ["Aman Raj", "Lakshit Arora", "Sanjay Surendranath Girija", "Shashank Kapoor", "Dipen Pradhan", "Ankit Shetgaonkar"], "title": "AI and Generative AI Transforming Disaster Management: A Survey of Damage Assessment and Response Techniques", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "Accepted in IEEE Compsac 2025", "summary": "Natural disasters, including earthquakes, wildfires and cyclones, bear a huge\nrisk on human lives as well as infrastructure assets. An effective response to\ndisaster depends on the ability to rapidly and efficiently assess the intensity\nof damage. Artificial Intelligence (AI) and Generative Artificial Intelligence\n(GenAI) presents a breakthrough solution, capable of combining knowledge from\nmultiple types and sources of data, simulating realistic scenarios of disaster,\nand identifying emerging trends at a speed previously unimaginable. In this\npaper, we present a comprehensive review on the prospects of AI and GenAI in\ndamage assessment for various natural disasters, highlighting both its\nstrengths and limitations. We talk about its application to multimodal data\nsuch as text, image, video, and audio, and also cover major issues of data\nprivacy, security, and ethical use of the technology during crises. The paper\nalso recognizes the threat of Generative AI misuse, in the form of\ndissemination of misinformation and for adversarial attacks. Finally, we\noutline avenues of future research, emphasizing the need for secure, reliable,\nand ethical Generative AI systems for disaster management in general. We\nbelieve that this work represents the first comprehensive survey of Gen-AI\ntechniques being used in the field of Disaster Assessment and Response."}
{"id": "2505.09907", "pdf": "https://arxiv.org/pdf/2505.09907", "abs": "https://arxiv.org/abs/2505.09907", "authors": ["Linwei Zhang", "LuFeng", "Ruijia Liang"], "title": "Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "With the growing demand for healthy foods, agricultural product price\nforecasting has become increasingly important. Hass avocados, as a high-value\ncrop, exhibit complex price fluctuations influenced by factors such as\nseasonality, region, and weather. Traditional prediction models often struggle\nwith highly nonlinear and dynamic data. To address this, we propose a hybrid\ndeep learning model, TCN-MLP-Attention Architecture, combining Temporal\nConvolutional Networks (TCN) for sequential feature extraction, Multi-Layer\nPerceptrons (MLP) for nonlinear interactions, and an Attention mechanism for\ndynamic feature weighting. The dataset used covers over 50,000 records of Hass\navocado sales across the U.S. from 2015 to 2018, including variables such as\nsales volume, average price, time, region, weather, and variety type, collected\nfrom point-of-sale systems and the Hass Avocado Board. After systematic\npreprocessing, including missing value imputation and feature normalization,\nthe proposed model was trained and evaluated. Experimental results demonstrate\nthat the TCN-MLP-Attention model achieves excellent predictive performance,\nwith an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods.\nThis research provides a scalable and effective approach for time series\nforecasting in agricultural markets and offers valuable insights for\nintelligent supply chain management and price strategy optimization."}
{"id": "2505.10261", "pdf": "https://arxiv.org/pdf/2505.10261", "abs": "https://arxiv.org/abs/2505.10261", "authors": ["Rui Yang", "Huitao Li", "Matthew Yu Heng Wong", "Yuhe Ke", "Xin Li", "Kunyu Yu", "Jingchi Liao", "Jonathan Chong Kai Liew", "Sabarinath Vinod Nair", "Jasmine Chiat Ling Ong", "Irene Li", "Douglas Teodoro", "Chuan Hong", "Daniel Shu Wei Ting", "Nan Liu"], "title": "The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Natural language processing (NLP) has been traditionally applied to medicine,\nand generative large language models (LLMs) have become prominent recently.\nHowever, the differences between them across different medical tasks remain\nunderexplored. We analyzed 19,123 studies, finding that generative LLMs\ndemonstrate advantages in open-ended tasks, while traditional NLP dominates in\ninformation extraction and analysis tasks. As these technologies advance,\nethical use of them is essential to ensure their potential in medical\napplications."}
{"id": "2505.10072", "pdf": "https://arxiv.org/pdf/2505.10072", "abs": "https://arxiv.org/abs/2505.10072", "authors": ["Rui-Yang Ju", "Sheng-Yen Huang", "Yi-Ping Hung"], "title": "ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars", "categories": ["cs.CV"], "comment": null, "summary": "The introduction of 3D Gaussian blendshapes has enabled the real-time\nreconstruction of animatable head avatars from monocular video. Toonify, a\nStyleGAN-based framework, has become widely used for facial image stylization.\nTo extend Toonify for synthesizing diverse stylized 3D head avatars using\nGaussian blendshapes, we propose an efficient two-stage framework, ToonifyGB.\nIn Stage 1 (stylized video generation), we employ an improved StyleGAN to\ngenerate the stylized video from the input video frames, which addresses the\nlimitation of cropping aligned faces at a fixed resolution as preprocessing for\nnormal StyleGAN. This process provides a more stable video, which enables\nGaussian blendshapes to better capture the high-frequency details of the video\nframes, and efficiently generate high-quality animation in the next stage. In\nStage 2 (Gaussian blendshapes synthesis), we learn a stylized neutral head\nmodel and a set of expression blendshapes from the generated video. By\ncombining the neutral head model with expression blendshapes, ToonifyGB can\nefficiently render stylized avatars with arbitrary expressions. We validate the\neffectiveness of ToonifyGB on the benchmark dataset using two styles: Arcane\nand Pixar."}
{"id": "2505.09593", "pdf": "https://arxiv.org/pdf/2505.09593", "abs": "https://arxiv.org/abs/2505.09593", "authors": ["Filippo Leveni", "Guilherme Weigert Cassales", "Bernhard Pfahringer", "Albert Bifet", "Giacomo Boracchi"], "title": "Online Isolation Forest", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at International Conference on Machine Learning (ICML 2024)", "summary": "The anomaly detection literature is abundant with offline methods, which\nrequire repeated access to data in memory, and impose impractical assumptions\nwhen applied to a streaming context. Existing online anomaly detection methods\nalso generally fail to address these constraints, resorting to periodic\nretraining to adapt to the online context. We propose Online-iForest, a novel\nmethod explicitly designed for streaming conditions that seamlessly tracks the\ndata generating process as it evolves over time. Experimental validation on\nreal-world datasets demonstrated that Online-iForest is on par with online\nalternatives and closely rivals state-of-the-art offline anomaly detection\ntechniques that undergo periodic retraining. Notably, Online-iForest\nconsistently outperforms all competitors in terms of efficiency, making it a\npromising solution in applications where fast identification of anomalies is of\nprimary importance such as cybersecurity, fraud and fault detection."}
{"id": "2505.09922", "pdf": "https://arxiv.org/pdf/2505.09922", "abs": "https://arxiv.org/abs/2505.09922", "authors": ["Zichen Liu", "Wei Zhang", "Tiejun Li"], "title": "Improving the Euclidean Diffusion Generation of Manifold Data by Mitigating Score Function Singularity", "categories": ["cs.LG"], "comment": "22 pages", "summary": "Euclidean diffusion models have achieved remarkable success in generative\nmodeling across diverse domains, and they have been extended to manifold case\nin recent advances. Instead of explicitly utilizing the structure of special\nmanifolds as studied in previous works, we investigate direct sampling of the\nEuclidean diffusion models for general manifold-constrained data in this paper.\nWe reveal the multiscale singularity of the score function in the embedded\nspace of manifold, which hinders the accuracy of diffusion-generated samples.\nWe then present an elaborate theoretical analysis of the singularity structure\nof the score function by separating it along the tangential and normal\ndirections of the manifold. To mitigate the singularity and improve the\nsampling accuracy, we propose two novel methods: (1) Niso-DM, which introduces\nnon-isotropic noise along the normal direction to reduce scale discrepancies,\nand (2) Tango-DM, which trains only the tangential component of the score\nfunction using a tangential-only loss function. Numerical experiments\ndemonstrate that our methods achieve superior performance on distributions over\nvarious manifolds with complex geometries."}
{"id": "2505.10282", "pdf": "https://arxiv.org/pdf/2505.10282", "abs": "https://arxiv.org/abs/2505.10282", "authors": ["Dubai Li", "Nan Jiang", "Kangping Huang", "Ruiqi Tu", "Shuyu Ouyang", "Huayu Yu", "Lin Qiao", "Chen Yu", "Tianshu Zhou", "Danyang Tong", "Qian Wang", "Mengtao Li", "Xiaofeng Zeng", "Yu Tian", "Xinping Tian", "Jingsong Li"], "title": "From Questions to Clinical Recommendations: Large Language Models Driving Evidence-Based Clinical Decision Making", "categories": ["cs.CL"], "comment": null, "summary": "Clinical evidence, derived from rigorous research and data analysis, provides\nhealthcare professionals with reliable scientific foundations for informed\ndecision-making. Integrating clinical evidence into real-time practice is\nchallenging due to the enormous workload, complex professional processes, and\ntime constraints. This highlights the need for tools that automate evidence\nsynthesis to support more efficient and accurate decision making in clinical\nsettings. This study introduces Quicker, an evidence-based clinical decision\nsupport system powered by large language models (LLMs), designed to automate\nevidence synthesis and generate clinical recommendations modeled after standard\nclinical guideline development processes. Quicker implements a fully automated\nchain that covers all phases, from questions to clinical recommendations, and\nfurther enables customized decision-making through integrated tools and\ninteractive user interfaces. To evaluate Quicker's capabilities, we developed\nthe Q2CRBench-3 benchmark dataset, based on clinical guideline development\nrecords for three different diseases. Experimental results highlighted\nQuicker's strong performance, with fine-grained question decomposition tailored\nto user preferences, retrieval sensitivities comparable to human experts, and\nliterature screening performance approaching comprehensive inclusion of\nrelevant studies. In addition, Quicker-assisted evidence assessment effectively\nsupported human reviewers, while Quicker's recommendations were more\ncomprehensive and logically coherent than those of clinicians. In system-level\ntesting, collaboration between a single reviewer and Quicker reduced the time\nrequired for recommendation development to 20-40 minutes. In general, our\nfindings affirm the potential of Quicker to help physicians make quicker and\nmore reliable evidence-based clinical decisions."}
{"id": "2505.10088", "pdf": "https://arxiv.org/pdf/2505.10088", "abs": "https://arxiv.org/abs/2505.10088", "authors": ["Yuncheng Guo", "Xiaodong Gu"], "title": "MMRL++: Parameter-Efficient and Interaction-Aware Representation Learning for Vision-Language Models", "categories": ["cs.CV"], "comment": "Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract appearing here is slightly shorter than that in the\n  PDF file", "summary": "Large-scale pre-trained Vision-Language Models (VLMs) have significantly\nadvanced transfer learning across diverse tasks. However, adapting these models\nwith limited few-shot data often leads to overfitting, undermining their\nability to generalize to new tasks. To address this, we propose Multi-Modal\nRepresentation Learning (MMRL), which introduces a shared, learnable,\nmodality-agnostic representation space. MMRL generates space tokens projected\ninto both text and image encoders as representation tokens, enabling more\neffective cross-modal interactions. Unlike prior methods that mainly optimize\nclass token features, MMRL inserts representation tokens into higher encoder\nlayers--where task-specific features are more prominent--while preserving\ngeneral knowledge in the lower layers. During training, both class and\nrepresentation features are jointly optimized: a trainable projection layer is\napplied to representation tokens for task adaptation, while the projection\nlayer for class token remains frozen to retain pre-trained knowledge. To\nfurther promote generalization, we introduce a regularization term aligning\nclass and text features with the frozen VLM's zero-shot features. At inference,\na decoupling strategy uses both class and representation features for base\ntasks, but only class features for novel tasks due to their stronger\ngeneralization. Building upon this, we propose MMRL++, a parameter-efficient\nand interaction-aware extension that significantly reduces trainable parameters\nand enhances intra-modal interactions--particularly across the layers of\nrepresentation tokens--allowing gradient sharing and instance-specific\ninformation to propagate more effectively through the network. Extensive\nexperiments on 15 datasets demonstrate that MMRL and MMRL++ consistently\noutperform state-of-the-art methods, achieving a strong balance between\ntask-specific adaptation and generalization."}
{"id": "2505.09616", "pdf": "https://arxiv.org/pdf/2505.09616", "abs": "https://arxiv.org/abs/2505.09616", "authors": ["Yuqi Li", "Yuanzhong Zheng", "Zhongtian Guo", "Yaoxuan Wang", "Jianjun Yin", "Haojun Fei"], "title": "SpecWav-Attack: Leveraging Spectrogram Resizing and Wav2Vec 2.0 for Attacking Anonymized Speech", "categories": ["cs.SD", "cs.AI", "eess.AS", "I.2.0"], "comment": "2 pages,3 figures,1 chart", "summary": "This paper presents SpecWav-Attack, an adversarial model for detecting\nspeakers in anonymized speech. It leverages Wav2Vec2 for feature extraction and\nincorporates spectrogram resizing and incremental training for improved\nperformance. Evaluated on librispeech-dev and librispeech-test, SpecWav-Attack\noutperforms conventional attacks, revealing vulnerabilities in anonymized\nspeech systems and emphasizing the need for stronger defenses, benchmarked\nagainst the ICASSP 2025 Attacker Challenge."}
{"id": "2505.09925", "pdf": "https://arxiv.org/pdf/2505.09925", "abs": "https://arxiv.org/abs/2505.09925", "authors": ["Yutao Yang", "Jie Zhou", "Junsong Li", "Qianjun Pan", "Bihao Zhan", "Qin Chen", "Xipeng Qiu", "Liang He"], "title": "Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces an interactive continual learning paradigm where AI\nmodels dynamically learn new skills from real-time human feedback while\nretaining prior knowledge. This paradigm distinctively addresses two major\nlimitations of traditional continual learning: (1) dynamic model updates using\nstreaming, real-time human-annotated data, rather than static datasets with\nfixed labels, and (2) the assumption of clean labels, by explicitly handling\nthe noisy feedback common in real-world interactions. To tackle these problems,\nwe propose RiCL, a Reinforced interactive Continual Learning framework\nleveraging Large Language Models (LLMs) to learn new skills effectively from\ndynamic feedback. RiCL incorporates three key components: a temporal\nconsistency-aware purifier to automatically discern clean from noisy samples in\ndata streams; an interaction-aware direct preference optimization strategy to\nalign model behavior with human intent by reconciling AI-generated and\nhuman-provided feedback; and a noise-resistant contrastive learning module that\ncaptures robust representations by exploiting inherent data relationships, thus\navoiding reliance on potentially unreliable labels. Extensive experiments on\ntwo benchmark datasets (FewRel and TACRED), contaminated with realistic noise\npatterns, demonstrate that our RiCL approach substantially outperforms existing\ncombinations of state-of-the-art online continual learning and noisy-label\nlearning methods."}
{"id": "2505.10320", "pdf": "https://arxiv.org/pdf/2505.10320", "abs": "https://arxiv.org/abs/2505.10320", "authors": ["Chenxi Whitehouse", "Tianlu Wang", "Ping Yu", "Xian Li", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 8 tables, 11 figures", "summary": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses."}
{"id": "2505.10118", "pdf": "https://arxiv.org/pdf/2505.10118", "abs": "https://arxiv.org/abs/2505.10118", "authors": ["Yangfu Li", "Hongjian Zhan", "Tianyi Chen", "Qi Liu", "Yue Lu"], "title": "Why 1 + 1 < 1 in Visual Token Pruning: Beyond Naive Integration via Multi-Objective Balanced Covering", "categories": ["cs.CV", "cs.CL"], "comment": "31 pages,9 figures,conference", "summary": "Existing visual token pruning methods target prompt alignment and visual\npreservation with static strategies, overlooking the varying relative\nimportance of these objectives across tasks, which leads to inconsistent\nperformance. To address this, we derive the first closed-form error bound for\nvisual token pruning based on the Hausdorff distance, uniformly characterizing\nthe contributions of both objectives. Moreover, leveraging $\\epsilon$-covering\ntheory, we reveal an intrinsic trade-off between these objectives and quantify\ntheir optimal attainment levels under a fixed budget. To practically handle\nthis trade-off, we propose Multi-Objective Balanced Covering (MoB), which\nreformulates visual token pruning as a bi-objective covering problem. In this\nframework, the attainment trade-off reduces to budget allocation via greedy\nradius trading. MoB offers a provable performance bound and linear scalability\nwith respect to the number of input visual tokens, enabling adaptation to\nchallenging pruning scenarios. Extensive experiments show that MoB preserves\n96.4% of performance for LLaVA-1.5-7B using only 11.1% of the original visual\ntokens and accelerates LLaVA-Next-7B by 1.3-1.5$\\times$ with negligible\nperformance loss. Additionally, evaluations on Qwen2-VL and Video-LLaVA confirm\nthat MoB integrates seamlessly into advanced MLLMs and diverse vision-language\ntasks."}
{"id": "2505.09619", "pdf": "https://arxiv.org/pdf/2505.09619", "abs": "https://arxiv.org/abs/2505.09619", "authors": ["Pietro Cassieri", "Aiman Faiz", "Anna Maria De Roberto", "Claudio Pascarelli", "Gianvito Mitrano", "Gianluca Fimiani", "Marina Garofano", "Christiancarmine Esposito", "Genoveffa Tortora", "Alessia Bramanti", "Giuseppe Scanniello"], "title": "Predictive Models for Chronic Heart Failure", "categories": ["stat.OT", "cs.AI"], "comment": null, "summary": "The management of chronic Heart Failure (HF) presents significant challenges\nin modern healthcare, requiring continuous monitoring, early detection of\nexacerbations, and personalized treatment strategies. In this paper, we present\na predictive model founded on Machine Learning (ML) techniques to identify\npatients at HF risk. This model is an ensemble learning approach, a modified\nstacking technique, that uses two specialized models leveraging clinical and\nechocardiographic features and then a meta-model to combine the predictions of\nthese two models. We initially assess the model on a real dataset and the\nobtained results suggest that it performs well in the stratification of\npatients at HR risk. Specifically, we obtained high sensitivity (95\\%),\nensuring that nearly all high-risk patients are identified. As for accuracy, we\nobtained 84\\%, which can be considered moderate in some ML contexts. However,\nit is acceptable given our priority of identifying patients at risk of HF\nbecause they will be asked to participate in the telemonitoring program of the\nPrediHealth research project on which some of the authors of this paper are\nworking. The initial findings also suggest that ML-based risk stratification\nmodels can serve as valuable decision-support tools not only in the PrediHealth\nproject but also for healthcare professionals, aiding in early intervention and\npersonalized patient management. To have a better understanding of the value\nand of potentiality of our predictive model, we also contrasted its results\nwith those obtained by using three baseline models. The preliminary results\nindicate that our predictive model outperforms these baselines that flatly\nconsider features, \\ie not grouping them in clinical and echocardiographic\nfeatures."}
{"id": "2505.09949", "pdf": "https://arxiv.org/pdf/2505.09949", "abs": "https://arxiv.org/abs/2505.09949", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Samgyu Yang", "Abdulrahman Faden"], "title": "Advanced Crash Causation Analysis for Freeway Safety: A Large Language Model Approach to Identifying Key Contributing Factors", "categories": ["cs.LG", "cs.CL", "stat.AP"], "comment": null, "summary": "Understanding the factors contributing to traffic crashes and developing\nstrategies to mitigate their severity is essential. Traditional statistical\nmethods and machine learning models often struggle to capture the complex\ninteractions between various factors and the unique characteristics of each\ncrash. This research leverages large language model (LLM) to analyze freeway\ncrash data and provide crash causation analysis accordingly. By compiling 226\ntraffic safety studies related to freeway crashes, a training dataset\nencompassing environmental, driver, traffic, and geometric design factors was\ncreated. The Llama3 8B model was fine-tuned using QLoRA to enhance its\nunderstanding of freeway crashes and their contributing factors, as covered in\nthese studies. The fine-tuned Llama3 8B model was then used to identify crash\ncausation without pre-labeled data through zero-shot classification, providing\ncomprehensive explanations to ensure that the identified causes were reasonable\nand aligned with existing research. Results demonstrate that LLMs effectively\nidentify primary crash causes such as alcohol-impaired driving, speeding,\naggressive driving, and driver inattention. Incorporating event data, such as\nroad maintenance, offers more profound insights. The model's practical\napplicability and potential to improve traffic safety measures were validated\nby a high level of agreement among researchers in the field of traffic safety,\nas reflected in questionnaire results with 88.89%. This research highlights the\ncomplex nature of traffic crashes and how LLMs can be used for comprehensive\nanalysis of crash causation and other contributing factors. Moreover, it\nprovides valuable insights and potential countermeasures to aid planners and\npolicymakers in developing more effective and efficient traffic safety\npractices."}
{"id": "2505.10354", "pdf": "https://arxiv.org/pdf/2505.10354", "abs": "https://arxiv.org/abs/2505.10354", "authors": ["Yile Wang", "Zhanyu Shen", "Hui Huang"], "title": "LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Semantic text representation is a fundamental task in the field of natural\nlanguage processing. Existing text embedding (e.g., SimCSE and LLM2Vec) have\ndemonstrated excellent performance, but the values of each dimension are\ndifficult to trace and interpret. Bag-of-words, as classic sparse interpretable\nembeddings, suffers from poor performance. Recently, Benara et al. (2024)\npropose interpretable text embeddings using large language models, which forms\n\"0/1\" embeddings based on responses to a series of questions. These\ninterpretable text embeddings are typically high-dimensional (larger than\n10,000). In this work, we propose Low-dimensional (lower than 500) Dense and\nInterpretable text embeddings with Relative representations (LDIR). The\nnumerical values of its dimensions indicate semantic relatedness to different\nanchor texts through farthest point sampling, offering both semantic\nrepresentation as well as a certain level of traceability and interpretability.\nWe validate LDIR on multiple semantic textual similarity, retrieval, and\nclustering tasks. Extensive experimental results show that LDIR performs close\nto the black-box baseline models and outperforms the interpretable embeddings\nbaselines with much fewer dimensions. Code is available at\nhttps://github.com/szu-tera/LDIR."}
{"id": "2505.10124", "pdf": "https://arxiv.org/pdf/2505.10124", "abs": "https://arxiv.org/abs/2505.10124", "authors": ["Ziad Kheil", "Lucas Robinet", "Laurent Risser", "Soleakhena Ken"], "title": "IMITATE: Image Registration with Context for unknown time frame recovery", "categories": ["cs.CV", "eess.IV"], "comment": "IEEE ISBI 2025", "summary": "In this paper, we formulate a novel image registration formalism dedicated to\nthe estimation of unknown condition-related images, based on two or more known\nimages and their associated conditions. We show how to practically model this\nformalism by using a new conditional U-Net architecture, which fully takes into\naccount the conditional information and does not need any fixed image. Our\nformalism is then applied to image moving tumors for radiotherapy treatment at\ndifferent breathing amplitude using 4D-CT (3D+t) scans in thoracoabdominal\nregions. This driving application is particularly complex as it requires to\nstitch a collection of sequential 2D slices into several 3D volumes at\ndifferent organ positions. Movement interpolation with standard methods then\ngenerates well known reconstruction artefacts in the assembled volumes due to\nirregular patient breathing, hysteresis and poor correlation of breathing\nsignal to internal motion. Results obtained on 4D-CT clinical data showcase\nartefact-free volumes achieved through real-time latencies. The code is\npublicly available at https://github.com/Kheil-Z/IMITATE ."}
{"id": "2505.09624", "pdf": "https://arxiv.org/pdf/2505.09624", "abs": "https://arxiv.org/abs/2505.09624", "authors": ["Ekaterina Kuzmina", "Dmitrii Kriukov", "Mikhail Lebedev", "Dmitry V. Dylov"], "title": "Neurophysiologically Realistic Environment for Comparing Adaptive Deep Brain Stimulation Algorithms in Parkinson Disease", "categories": ["q-bio.NC", "cs.AI", "68T05"], "comment": "8 pages, 3 figures, submission to KDD", "summary": "Adaptive deep brain stimulation (aDBS) has emerged as a promising treatment\nfor Parkinson disease (PD). In aDBS, a surgically placed electrode sends\ndynamically altered stimuli to the brain based on neurophysiological feedback:\nan invasive gadget that limits the amount of data one could collect for\noptimizing the control offline. As a consequence, a plethora of synthetic\nmodels of PD and those of the control algorithms have been proposed. Herein, we\nintroduce the first neurophysiologically realistic benchmark for comparing said\nmodels. Specifically, our methodology covers not only conventional basal\nganglia circuit dynamics and pathological oscillations, but also captures 15\npreviously dismissed physiological attributes, such as signal instabilities and\nnoise, neural drift, electrode conductance changes and individual variability -\nall modeled as spatially distributed and temporally registered features via\nbeta-band activity in the brain and a feedback. Furthermore, we purposely built\nour framework as a structured environment for training and evaluating deep\nreinforcement learning (RL) algorithms, opening new possibilities for\noptimizing aDBS control strategies and inviting the machine learning community\nto contribute to the emerging field of intelligent neurostimulation interfaces."}
{"id": "2505.09952", "pdf": "https://arxiv.org/pdf/2505.09952", "abs": "https://arxiv.org/abs/2505.09952", "authors": ["Tianyu Huai", "Jie Zhou", "Yuxuan Cai", "Qin Chen", "Wen Wu", "Xingjiao Wu", "Xipeng Qiu", "Liang He"], "title": "Task-Core Memory Management and Consolidation for Long-term Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to Neurips2025", "summary": "In this paper, we focus on a long-term continual learning (CL) task, where a\nmodel learns sequentially from a stream of vast tasks over time, acquiring new\nknowledge while retaining previously learned information in a manner akin to\nhuman learning. Unlike traditional CL settings, long-term CL involves handling\na significantly larger number of tasks, which exacerbates the issue of\ncatastrophic forgetting. Our work seeks to address two critical questions: 1)\nHow do existing CL methods perform in the context of long-term CL? and 2) How\ncan we mitigate the catastrophic forgetting that arises from prolonged\nsequential updates? To tackle these challenges, we propose a novel framework\ninspired by human memory mechanisms for long-term continual learning (Long-CL).\nSpecifically, we introduce a task-core memory management strategy to\nefficiently index crucial memories and adaptively update them as learning\nprogresses. Additionally, we develop a long-term memory consolidation mechanism\nthat selectively retains hard and discriminative samples, ensuring robust\nknowledge retention. To facilitate research in this area, we construct and\nrelease two multi-modal and textual benchmarks, MMLongCL-Bench and\nTextLongCL-Bench, providing a valuable resource for evaluating long-term CL\napproaches. Experimental results show that Long-CL outperforms the previous\nstate-of-the-art by 7.4\\% and 6.5\\% AP on the two benchmarks, respectively,\ndemonstrating the effectiveness of our approach."}
{"id": "2505.10356", "pdf": "https://arxiv.org/pdf/2505.10356", "abs": "https://arxiv.org/abs/2505.10356", "authors": ["Chunyu Ye", "Shaonan Wang"], "title": "Coherent Language Reconstruction from Brain Recordings with Flexible Multi-Modal Input Stimuli", "categories": ["cs.CL"], "comment": null, "summary": "Decoding thoughts from brain activity offers valuable insights into human\ncognition and enables promising applications in brain-computer interaction.\nWhile prior studies have explored language reconstruction from fMRI data, they\nare typically limited to single-modality inputs such as images or audio. In\ncontrast, human thought is inherently multimodal. To bridge this gap, we\npropose a unified and flexible framework for reconstructing coherent language\nfrom brain recordings elicited by diverse input modalities-visual, auditory,\nand textual. Our approach leverages visual-language models (VLMs), using\nmodality-specific experts to jointly interpret information across modalities.\nExperiments demonstrate that our method achieves performance comparable to\nstate-of-the-art systems while remaining adaptable and extensible. This work\nadvances toward more ecologically valid and generalizable mind decoding."}
{"id": "2505.10152", "pdf": "https://arxiv.org/pdf/2505.10152", "abs": "https://arxiv.org/abs/2505.10152", "authors": ["Yikang Wei"], "title": "Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization", "categories": ["cs.CV"], "comment": "IJCAI 2025", "summary": "Federated domain generalization aims to learn a generalizable model from\nmultiple decentralized source domains for deploying on the unseen target\ndomain. The style augmentation methods have achieved great progress on domain\ngeneralization. However, the existing style augmentation methods either explore\nthe data styles within isolated source domain or interpolate the style\ninformation across existing source domains under the data decentralization\nscenario, which leads to limited style space. To address this issue, we propose\na Multi-source Collaborative Style Augmentation and Domain-invariant learning\nmethod (MCSAD) for federated domain generalization. Specifically, we propose a\nmulti-source collaborative style augmentation module to generate data in the\nbroader style space. Furthermore, we conduct domain-invariant learning between\nthe original data and augmented data by cross-domain feature alignment within\nthe same class and classes relation ensemble distillation between different\nclasses to learn a domain-invariant model. By alternatively conducting\ncollaborative style augmentation and domain-invariant learning, the model can\ngeneralize well on unseen target domain. Extensive experiments on multiple\ndomain generalization datasets indicate that our method significantly\noutperforms the state-of-the-art federated domain generalization methods."}
{"id": "2505.09646", "pdf": "https://arxiv.org/pdf/2505.09646", "abs": "https://arxiv.org/abs/2505.09646", "authors": ["Carmel Mary Esther A"], "title": "Temporal Interception and Present Reconstruction: A Cognitive-Signal Model for Human and AI Decision Making", "categories": ["q-bio.NC", "cs.AI", "physics.hist-ph"], "comment": "8 pages, 3 figures", "summary": "This paper proposes a novel theoretical model to explain how the human mind\nand artificial intelligence can approach real-time awareness by reducing\nperceptual delays. By investigating cosmic signal delay, neurological reaction\ntimes, and the ancient cognitive state of stillness, we explore how one may\nshift from reactive perception to a conscious interface with the near future.\nThis paper introduces both a physical and cognitive model for perceiving the\npresent not as a linear timestamp, but as an interference zone where\nearly-arriving cosmic signals and reactive human delays intersect. We propose\nexperimental approaches to test these ideas using human neural observation and\nneuro-receptive extensions. Finally, we propose a mathematical framework to\nguide the evolution of AI systems toward temporally efficient, ethically sound,\nand internally conscious decision-making processes"}
{"id": "2505.09955", "pdf": "https://arxiv.org/pdf/2505.09955", "abs": "https://arxiv.org/abs/2505.09955", "authors": ["Jaeho Kim", "Seulki Lee"], "title": "TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 Accept", "summary": "Unsupervised domain adaptation (UDA) for time series data remains a critical\nchallenge in deep learning, with traditional pseudo-labeling strategies failing\nto capture temporal patterns and channel-wise shifts between domains, producing\nsub-optimal pseudo-labels. As such, we introduce TransPL, a novel approach that\naddresses these limitations by modeling the joint distribution $P(\\mathbf{X},\ny)$ of the source domain through code transition matrices, where the codes are\nderived from vector quantization (VQ) of time series patches. Our method\nconstructs class- and channel-wise code transition matrices from the source\ndomain and employs Bayes' rule for target domain adaptation, generating\npseudo-labels based on channel-wise weighted class-conditional likelihoods.\nTransPL offers three key advantages: explicit modeling of temporal transitions\nand channel-wise shifts between different domains, versatility towards\ndifferent UDA scenarios (e.g., weakly-supervised UDA), and explainable\npseudo-label generation. We validate TransPL's effectiveness through extensive\nanalysis on four time series UDA benchmarks and confirm that it consistently\noutperforms state-of-the-art pseudo-labeling methods by a strong margin (6.1%\naccuracy improvement, 4.9% F1 improvement), while providing interpretable\ninsights into the domain adaptation process through its learned code transition\nmatrices."}
{"id": "2505.10389", "pdf": "https://arxiv.org/pdf/2505.10389", "abs": "https://arxiv.org/abs/2505.10389", "authors": ["Benjamin White", "Anastasia Shimorina"], "title": "Multi-domain Multilingual Sentiment Analysis in Industry: Predicting Aspect-based Opinion Quadruples", "categories": ["cs.CL"], "comment": null, "summary": "This paper explores the design of an aspect-based sentiment analysis system\nusing large language models (LLMs) for real-world use. We focus on quadruple\nopinion extraction -- identifying aspect categories, sentiment polarity,\ntargets, and opinion expressions from text data across different domains and\nlanguages. Using internal datasets, we investigate whether a single fine-tuned\nmodel can effectively handle multiple domain-specific taxonomies\nsimultaneously. We demonstrate that a combined multi-domain model achieves\nperformance comparable to specialized single-domain models while reducing\noperational complexity. We also share lessons learned for handling\nnon-extractive predictions and evaluating various failure modes when developing\nLLM-based systems for structured prediction tasks."}
{"id": "2505.10169", "pdf": "https://arxiv.org/pdf/2505.10169", "abs": "https://arxiv.org/abs/2505.10169", "authors": ["Matthias Kümmerer", "Harneet Khanuja", "Matthias Bethge"], "title": "Modeling Saliency Dataset Bias", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes."}
{"id": "2505.09651", "pdf": "https://arxiv.org/pdf/2505.09651", "abs": "https://arxiv.org/abs/2505.09651", "authors": ["Xixuan Hao", "Yutian Jiang", "Xingchen Zou", "Jiabo Liu", "Yifang Yin", "Yuxuan Liang"], "title": "Unlocking Location Intelligence: A Survey from Deep Learning to The LLM Era", "categories": ["cs.DB", "cs.AI", "cs.LG"], "comment": null, "summary": "Location Intelligence (LI), the science of transforming location-centric\ngeospatial data into actionable knowledge, has become a cornerstone of modern\nspatial decision-making. The rapid evolution of Geospatial Representation\nLearning is fundamentally reshaping LI development through two successive\ntechnological revolutions: the deep learning breakthrough and the emerging\nlarge language model (LLM) paradigm. While deep neural networks (DNNs) have\ndemonstrated remarkable success in automated feature extraction from structured\ngeospatial data (e.g., satellite imagery, GPS trajectories), the recent\nintegration of LLMs introduces transformative capabilities for cross-modal\ngeospatial reasoning and unstructured geo-textual data processing. This survey\npresents a comprehensive review of geospatial representation learning across\nboth technological eras, organizing them into a structured taxonomy based on\nthe complete pipeline comprising: (1) data perspective, (2) methodological\nperspective and (3) application perspective. We also highlight current\nadvancements, discuss existing limitations, and propose potential future\nresearch directions in the LLM era. This work offers a thorough exploration of\nthe field and providing a roadmap for further innovation in LI. The summary of\nthe up-to-date paper list can be found in\nhttps://github.com/CityMind-Lab/Awesome-Location-Intelligence and will undergo\ncontinuous updates."}
{"id": "2505.09959", "pdf": "https://arxiv.org/pdf/2505.09959", "abs": "https://arxiv.org/abs/2505.09959", "authors": ["Zengxia Guo", "Bohui An", "Zhongqi Lu"], "title": "Approximated Behavioral Metric-based State Projection for Federated Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated reinforcement learning (FRL) methods usually share the encrypted\nlocal state or policy information and help each client to learn from others\nwhile preserving everyone's privacy. In this work, we propose that sharing the\napproximated behavior metric-based state projection function is a promising way\nto enhance the performance of FRL and concurrently provides an effective\nprotection of sensitive information. We introduce FedRAG, a FRL framework to\nlearn a computationally practical projection function of states for each client\nand aggregating the parameters of projection functions at a central server. The\nFedRAG approach shares no sensitive task-specific information, yet provides\ninformation gain for each client. We conduct extensive experiments on the\nDeepMind Control Suite to demonstrate insightful results."}
{"id": "2505.10402", "pdf": "https://arxiv.org/pdf/2505.10402", "abs": "https://arxiv.org/abs/2505.10402", "authors": ["Yihong Dong", "Yuchen Liu", "Xue Jiang", "Zhi Jin", "Ge Li"], "title": "Rethinking Repetition Problems of LLMs in Code Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to ACL 2025 (main)", "summary": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code."}
{"id": "2505.10205", "pdf": "https://arxiv.org/pdf/2505.10205", "abs": "https://arxiv.org/abs/2505.10205", "authors": ["Umair Haroon", "Ahmad AlMughrabi", "Thanasis Zoumpekas", "Ricardo Marques", "Petia Radeva"], "title": "VolE: A Point-cloud Framework for Food 3D Reconstruction and Volume Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate food volume estimation is crucial for medical nutrition management\nand health monitoring applications, but current food volume estimation methods\nare often limited by mononuclear data, leveraging single-purpose hardware such\nas 3D scanners, gathering sensor-oriented information such as depth\ninformation, or relying on camera calibration using a reference object. In this\npaper, we present VolE, a novel framework that leverages mobile device-driven\n3D reconstruction to estimate food volume. VolE captures images and camera\nlocations in free motion to generate precise 3D models, thanks to AR-capable\nmobile devices. To achieve real-world measurement, VolE is a reference- and\ndepth-free framework that leverages food video segmentation for food mask\ngeneration. We also introduce a new food dataset encompassing the challenging\nscenarios absent in the previous benchmarks. Our experiments demonstrate that\nVolE outperforms the existing volume estimation techniques across multiple\ndatasets by achieving 2.22 % MAPE, highlighting its superior performance in\nfood volume estimation."}
{"id": "2505.09653", "pdf": "https://arxiv.org/pdf/2505.09653", "abs": "https://arxiv.org/abs/2505.09653", "authors": ["Samuel Yen-Chi Chen", "Chen-Yu Liu", "Kuan-Cheng Chen", "Wei-Jia Huang", "Yen-Jui Chang", "Wei-Hao Huang"], "title": "Differentiable Quantum Architecture Search in Quantum-Enhanced Neural Network Parameter Generation", "categories": ["quant-ph", "cs.AI", "cs.ET", "cs.LG", "cs.NE"], "comment": null, "summary": "The rapid advancements in quantum computing (QC) and machine learning (ML)\nhave led to the emergence of quantum machine learning (QML), which integrates\nthe strengths of both fields. Among QML approaches, variational quantum\ncircuits (VQCs), also known as quantum neural networks (QNNs), have shown\npromise both empirically and theoretically. However, their broader adoption is\nhindered by reliance on quantum hardware during inference. Hardware\nimperfections and limited access to quantum devices pose practical challenges.\nTo address this, the Quantum-Train (QT) framework leverages the exponential\nscaling of quantum amplitudes to generate classical neural network parameters,\nenabling inference without quantum hardware and achieving significant parameter\ncompression. Yet, designing effective quantum circuit architectures for such\nquantum-enhanced neural programmers remains non-trivial and often requires\nexpertise in quantum information science. In this paper, we propose an\nautomated solution using differentiable optimization. Our method jointly\noptimizes both conventional circuit parameters and architectural parameters in\nan end-to-end manner via automatic differentiation. We evaluate the proposed\nframework on classification, time-series prediction, and reinforcement learning\ntasks. Simulation results show that our method matches or outperforms manually\ndesigned QNN architectures. This work offers a scalable and automated pathway\nfor designing QNNs that can generate classical neural network parameters across\ndiverse applications."}
{"id": "2505.09969", "pdf": "https://arxiv.org/pdf/2505.09969", "abs": "https://arxiv.org/abs/2505.09969", "authors": ["Ali Azimi Lamir", "Shiva Razzagzadeh", "Zeynab Rezaei"], "title": "A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study presents a machine learning-based framework for heart disease\nprediction using the heart-disease dataset, comprising 303 samples with 14\nfeatures. The methodology involves data preprocessing, model training, and\nevaluation using three classifiers: Logistic Regression, K-Nearest Neighbors\n(KNN), and Random Forest. Hyperparameter tuning with GridSearchCV and\nRandomizedSearchCV was employed to enhance model performance. The Random Forest\nclassifier outperformed other models, achieving an accuracy of 91% and an\nF1-score of 0.89. Evaluation metrics, including precision, recall, and\nconfusion matrix, revealed balanced performance across classes. The proposed\nmodel demonstrates strong potential for aiding clinical decision-making by\neffectively predicting heart disease. Limitations such as dataset size and\ngeneralizability underscore the need for future studies using larger and more\ndiverse datasets. This work highlights the utility of machine learning in\nhealthcare, offering insights for further advancements in predictive\ndiagnostics."}
{"id": "2505.10409", "pdf": "https://arxiv.org/pdf/2505.10409", "abs": "https://arxiv.org/abs/2505.10409", "authors": ["Yue Guo", "Jae Ho Sohn", "Gondy Leroy", "Trevor Cohen"], "title": "Are LLM-generated plain language summaries truly understandable? A large-scale crowdsourced evaluation", "categories": ["cs.CL"], "comment": null, "summary": "Plain language summaries (PLSs) are essential for facilitating effective\ncommunication between clinicians and patients by making complex medical\ninformation easier for laypeople to understand and act upon. Large language\nmodels (LLMs) have recently shown promise in automating PLS generation, but\ntheir effectiveness in supporting health information comprehension remains\nunclear. Prior evaluations have generally relied on automated scores that do\nnot measure understandability directly, or subjective Likert-scale ratings from\nconvenience samples with limited generalizability. To address these gaps, we\nconducted a large-scale crowdsourced evaluation of LLM-generated PLSs using\nAmazon Mechanical Turk with 150 participants. We assessed PLS quality through\nsubjective Likert-scale ratings focusing on simplicity, informativeness,\ncoherence, and faithfulness; and objective multiple-choice comprehension and\nrecall measures of reader understanding. Additionally, we examined the\nalignment between 10 automated evaluation metrics and human judgments. Our\nfindings indicate that while LLMs can generate PLSs that appear\nindistinguishable from human-written ones in subjective evaluations,\nhuman-written PLSs lead to significantly better comprehension. Furthermore,\nautomated evaluation metrics fail to reflect human judgment, calling into\nquestion their suitability for evaluating PLSs. This is the first study to\nsystematically evaluate LLM-generated PLSs based on both reader preferences and\ncomprehension outcomes. Our findings highlight the need for evaluation\nframeworks that move beyond surface-level quality and for generation methods\nthat explicitly optimize for layperson comprehension."}
{"id": "2505.10223", "pdf": "https://arxiv.org/pdf/2505.10223", "abs": "https://arxiv.org/abs/2505.10223", "authors": ["Puru Vaish", "Felix Meister", "Tobias Heimann", "Christoph Brune", "Jelmer M. Wolterink"], "title": "Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at MIDL 2025", "summary": "Medical image segmentation models are often trained on curated datasets,\nleading to performance degradation when deployed in real-world clinical\nsettings due to mismatches between training and test distributions. While data\naugmentation techniques are widely used to address these challenges,\ntraditional visually consistent augmentation strategies lack the robustness\nneeded for diverse real-world scenarios. In this work, we systematically\nevaluate alternative augmentation strategies, focusing on MixUp and Auxiliary\nFourier Augmentation. These methods mitigate the effects of multiple variations\nwithout explicitly targeting specific sources of distribution shifts. We\ndemonstrate how these techniques significantly improve out-of-distribution\ngeneralization and robustness to imaging variations across a wide range of\ntransformations in cardiac cine MRI and prostate MRI segmentation. We\nquantitatively find that these augmentation methods enhance learned feature\nrepresentations by promoting separability and compactness. Additionally, we\nhighlight how their integration into nnU-Net training pipelines provides an\neasy-to-implement, effective solution for enhancing the reliability of medical\nsegmentation models in real-world applications."}
{"id": "2505.09661", "pdf": "https://arxiv.org/pdf/2505.09661", "abs": "https://arxiv.org/abs/2505.09661", "authors": ["Jinghao He", "Zhengyan Sheng", "Liping Chen", "Kong Aik Lee", "Zhen-Hua Ling"], "title": "Introducing voice timbre attribute detection", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "This paper focuses on explaining the timbre conveyed by speech signals and\nintroduces a task termed voice timbre attribute detection (vTAD). In this task,\nvoice timbre is explained with a set of sensory attributes describing its human\nperception. A pair of speech utterances is processed, and their intensity is\ncompared in a designated timbre descriptor. Moreover, a framework is proposed,\nwhich is built upon the speaker embeddings extracted from the speech\nutterances. The investigation is conducted on the VCTK-RVA dataset.\nExperimental examinations on the ECAPA-TDNN and FACodec speaker encoders\ndemonstrated that: 1) the ECAPA-TDNN speaker encoder was more capable in the\nseen scenario, where the testing speakers were included in the training set; 2)\nthe FACodec speaker encoder was superior in the unseen scenario, where the\ntesting speakers were not part of the training, indicating enhanced\ngeneralization capability. The VCTK-RVA dataset and open-source code are\navailable on the website https://github.com/vTAD2025-Challenge/vTAD."}
{"id": "2505.09983", "pdf": "https://arxiv.org/pdf/2505.09983", "abs": "https://arxiv.org/abs/2505.09983", "authors": ["Changxun Zhu", "Qilong Wu", "Lingjuan Lyu", "Shibei Xue"], "title": "Sybil-based Virtual Data Poisoning Attacks in Federated Learning", "categories": ["cs.LG"], "comment": "7 pages, 6 figures, accepted by IEEE Codit 2025", "summary": "Federated learning is vulnerable to poisoning attacks by malicious\nadversaries. Existing methods often involve high costs to achieve effective\nattacks. To address this challenge, we propose a sybil-based virtual data\npoisoning attack, where a malicious client generates sybil nodes to amplify the\npoisoning model's impact. To reduce neural network computational complexity, we\ndevelop a virtual data generation method based on gradient matching. We also\ndesign three schemes for target model acquisition, applicable to online local,\nonline global, and offline scenarios. In simulation, our method outperforms\nother attack algorithms since our method can obtain a global target model under\nnon-independent uniformly distributed data."}
{"id": "2505.10413", "pdf": "https://arxiv.org/pdf/2505.10413", "abs": "https://arxiv.org/abs/2505.10413", "authors": ["Jiajie Jin", "Xiaoxi Li", "Guanting Dong", "Yuyao Zhang", "Yutao Zhu", "Yongkang Wu", "Zhonghua Li", "Qi Ye", "Zhicheng Dou"], "title": "Hierarchical Document Refinement for Long-context Retrieval-augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "Real-world RAG applications often encounter long-context input scenarios,\nwhere redundant information and noise results in higher inference costs and\nreduced performance. To address these challenges, we propose LongRefiner, an\nefficient plug-and-play refiner that leverages the inherent structural\ncharacteristics of long documents. LongRefiner employs dual-level query\nanalysis, hierarchical document structuring, and adaptive refinement through\nmulti-task learning on a single foundation model. Experiments on seven QA\ndatasets demonstrate that LongRefiner achieves competitive performance in\nvarious scenarios while using 10x fewer computational costs and latency\ncompared to the best baseline. Further analysis validates that LongRefiner is\nscalable, efficient, and effective, providing practical insights for real-world\nlong-text RAG applications. Our code is available at\nhttps://github.com/ignorejjj/LongRefiner."}
{"id": "2505.10231", "pdf": "https://arxiv.org/pdf/2505.10231", "abs": "https://arxiv.org/abs/2505.10231", "authors": ["Haozhe Luo", "Ziyu Zhou", "Zixin Shu", "Aurélie Pahud de Mortanges", "Robert Berke", "Mauricio Reyes"], "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner."}
{"id": "2505.09666", "pdf": "https://arxiv.org/pdf/2505.09666", "abs": "https://arxiv.org/abs/2505.09666", "authors": ["Yumin Choi", "Jinheon Baek", "Sung Ju Hwang"], "title": "System Prompt Optimization with Meta-Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance."}
{"id": "2505.10003", "pdf": "https://arxiv.org/pdf/2505.10003", "abs": "https://arxiv.org/abs/2505.10003", "authors": ["Tianyu Jiao", "Zhuoran Xiao", "Yihang Huang", "Chenhui Ye", "Yijia Feng", "Liyu Cai", "Jiang Chang", "Fangkun Liu", "Yin Xu", "Dazhi He", "Yunfeng Guan", "Wenjun Zhang"], "title": "AI2MMUM: AI-AI Oriented Multi-Modal Universal Model Leveraging Telecom Domain Large Model", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Designing a 6G-oriented universal model capable of processing multi-modal\ndata and executing diverse air interface tasks has emerged as a common goal in\nfuture wireless systems. Building on our prior work in communication\nmulti-modal alignment and telecom large language model (LLM), we propose a\nscalable, task-aware artificial intelligence-air interface multi-modal\nuniversal model (AI2MMUM), which flexibility and effectively perform various\nphysical layer tasks according to subtle task instructions. The LLM backbone\nprovides robust contextual comprehension and generalization capabilities, while\na fine-tuning approach is adopted to incorporate domain-specific knowledge. To\nenhance task adaptability, task instructions consist of fixed task keywords and\nlearnable, implicit prefix prompts. Frozen radio modality encoders extract\nuniversal representations and adapter layers subsequently bridge radio and\nlanguage modalities. Moreover, lightweight task-specific heads are designed to\ndirectly output task objectives. Comprehensive evaluations demonstrate that\nAI2MMUM achieves SOTA performance across five representative physical\nenvironment/wireless channel-based downstream tasks using the WAIR-D and\nDeepMIMO datasets."}
{"id": "2505.10446", "pdf": "https://arxiv.org/pdf/2505.10446", "abs": "https://arxiv.org/abs/2505.10446", "authors": ["Zemin Huang", "Zhiyang Chen", "Zijun Wang", "Tiancheng Li", "Guo-Jun Qi"], "title": "Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We introduce the \\emph{Diffusion Chain of Lateral Thought (DCoLT)}, a\nreasoning framework for diffusion language models. DCoLT treats each\nintermediate step in the reverse diffusion process as a latent \"thinking\"\naction and optimizes the entire reasoning trajectory to maximize the reward on\nthe correctness of the final answer with outcome-based Reinforcement Learning\n(RL). Unlike traditional Chain-of-Thought (CoT) methods that follow a causal,\nlinear thinking process, DCoLT allows bidirectional, non-linear reasoning with\nno strict rule on grammatical correctness amid its intermediate steps of\nthought. We implement DCoLT on two representative Diffusion Language Models\n(DLMs). First, we choose SEDD as a representative continuous-time discrete\ndiffusion model, where its concrete score derives a probabilistic policy to\nmaximize the RL reward over the entire sequence of intermediate diffusion\nsteps. We further consider the discrete-time masked diffusion language model --\nLLaDA, and find that the order to predict and unmask tokens plays an essential\nrole to optimize its RL action resulting from the ranking-based Unmasking\nPolicy Module (UPM) defined by the Plackett-Luce model. Experiments on both\nmath and code generation tasks show that using only public data and 16 H800\nGPUs, DCoLT-reinforced DLMs outperform other DLMs trained by SFT or RL or even\nboth. Notably, DCoLT-reinforced LLaDA boosts its reasoning accuracy by +9.8%,\n+5.7%, +11.4%, +19.5% on GSM8K, MATH, MBPP, and HumanEval."}
{"id": "2505.10238", "pdf": "https://arxiv.org/pdf/2505.10238", "abs": "https://arxiv.org/abs/2505.10238", "authors": ["Yanbo Ding"], "title": "MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation", "categories": ["cs.CV"], "comment": null, "summary": "Human image animation has gained increasing attention and developed rapidly\ndue to its broad applications in digital humans. However, existing methods rely\nlargely on 2D-rendered pose images for motion guidance, which limits\ngeneralization and discards essential 3D information for open-world animation.\nTo tackle this problem, we propose MTVCrafter (Motion Tokenization Video\nCrafter), the first framework that directly models raw 3D motion sequences\n(i.e., 4D motion) for human image animation. Specifically, we introduce 4DMoT\n(4D motion tokenizer) to quantize 3D motion sequences into 4D motion tokens.\nCompared to 2D-rendered pose images, 4D motion tokens offer more robust\nspatio-temporal cues and avoid strict pixel-level alignment between pose image\nand character, enabling more flexible and disentangled control. Then, we\nintroduce MV-DiT (Motion-aware Video DiT). By designing unique motion attention\nwith 4D positional encodings, MV-DiT can effectively leverage motion tokens as\n4D compact yet expressive context for human image animation in the complex 3D\nworld. Hence, it marks a significant step forward in this field and opens a new\ndirection for pose-guided human video generation. Experiments show that our\nMTVCrafter achieves state-of-the-art results with an FID-VID of 6.98,\nsurpassing the second-best by 65%. Powered by robust motion tokens, MTVCrafter\nalso generalizes well to diverse open-world characters (single/multiple,\nfull/half-body) across various styles and scenarios. Our video demos and code\nare provided in the supplementary material and at this anonymous GitHub link:\nhttps://anonymous.4open.science/r/MTVCrafter-1B13."}
{"id": "2505.09698", "pdf": "https://arxiv.org/pdf/2505.09698", "abs": "https://arxiv.org/abs/2505.09698", "authors": ["Enyu Zhao", "Vedant Raval", "Hejia Zhang", "Jiageng Mao", "Zeyu Shangguan", "Stefanos Nikolaidis", "Yue Wang", "Daniel Seita"], "title": "ManipBench: Benchmarking Vision-Language Models for Low-Level Robot Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": "47 pages, 29 figures. Under review", "summary": "Vision-Language Models (VLMs) have revolutionized artificial intelligence and\nrobotics due to their commonsense reasoning capabilities. In robotic\nmanipulation, VLMs are used primarily as high-level planners, but recent work\nhas also studied their lower-level reasoning ability, which refers to making\ndecisions about precise robot movements. However, the community currently lacks\na clear and common benchmark that can evaluate how well VLMs can aid low-level\nreasoning in robotics. Consequently, we propose a novel benchmark, ManipBench,\nto evaluate the low-level robot manipulation reasoning capabilities of VLMs\nacross various dimensions, including how well they understand object-object\ninteractions and deformable object manipulation. We extensively test 33\nrepresentative VLMs across 10 model families on our benchmark, including\nvariants to test different model sizes. Our evaluation shows that the\nperformance of VLMs significantly varies across tasks, and there is a strong\ncorrelation between this performance and trends in our real-world manipulation\ntasks. It also shows that there remains a significant gap between these models\nand human-level understanding. See our website at:\nhttps://manipbench.github.io."}
{"id": "2505.10007", "pdf": "https://arxiv.org/pdf/2505.10007", "abs": "https://arxiv.org/abs/2505.10007", "authors": ["Zijun Chen", "Shengbo Wang", "Nian Si"], "title": "Sample Complexity of Distributionally Robust Average-Reward Reinforcement Learning", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Motivated by practical applications where stable long-term performance is\ncritical-such as robotics, operations research, and healthcare-we study the\nproblem of distributionally robust (DR) average-reward reinforcement learning.\nWe propose two algorithms that achieve near-optimal sample complexity. The\nfirst reduces the problem to a DR discounted Markov decision process (MDP),\nwhile the second, Anchored DR Average-Reward MDP, introduces an anchoring state\nto stabilize the controlled transition kernels within the uncertainty set.\nAssuming the nominal MDP is uniformly ergodic, we prove that both algorithms\nattain a sample complexity of $\\widetilde{O}\\left(|\\mathbf{S}||\\mathbf{A}|\nt_{\\mathrm{mix}}^2\\varepsilon^{-2}\\right)$ for estimating the optimal policy as\nwell as the robust average reward under KL and $f_k$-divergence-based\nuncertainty sets, provided the uncertainty radius is sufficiently small. Here,\n$\\varepsilon$ is the target accuracy, $|\\mathbf{S}|$ and $|\\mathbf{A}|$ denote\nthe sizes of the state and action spaces, and $t_{\\mathrm{mix}}$ is the mixing\ntime of the nominal MDP. This represents the first finite-sample convergence\nguarantee for DR average-reward reinforcement learning. We further validate the\nconvergence rates of our algorithms through numerical experiments."}
{"id": "2505.10493", "pdf": "https://arxiv.org/pdf/2505.10493", "abs": "https://arxiv.org/abs/2505.10493", "authors": ["Shaohan Wang", "Licheng Zhang", "Zheren Fu", "Zhendong Mao"], "title": "CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) is an effective method to enhance the\ncapabilities of large language models (LLMs). Existing methods focus on\noptimizing the retriever or generator in the RAG system by directly utilizing\nthe top-k retrieved documents. However, the documents effectiveness are various\nsignificantly across user queries, i.e. some documents provide valuable\nknowledge while others totally lack critical information. It hinders the\nretriever and generator's adaptation during training. Inspired by human\ncognitive learning, curriculum learning trains models using samples progressing\nfrom easy to difficult, thus enhancing their generalization ability, and we\nintegrate this effective paradigm to the training of the RAG system. In this\npaper, we propose a multi-stage Curriculum Learning based RAG system training\nframework, named CL-RAG. We first construct training data with multiple\ndifficulty levels for the retriever and generator separately through sample\nevolution. Then, we train the model in stages based on the curriculum learning\napproach, thereby optimizing the overall performance and generalization of the\nRAG system more effectively. Our CL-RAG framework demonstrates consistent\neffectiveness across four open-domain QA datasets, achieving performance gains\nof 2% to 4% over multiple advanced methods."}
{"id": "2505.10250", "pdf": "https://arxiv.org/pdf/2505.10250", "abs": "https://arxiv.org/abs/2505.10250", "authors": ["Wenhao Shen", "Wanqi Yin", "Xiaofeng Yang", "Cheng Chen", "Chaoyue Song", "Zhongang Cai", "Lei Yang", "Hao Wang", "Guosheng Lin"], "title": "ADHMR: Aligning Diffusion-based Human Mesh Recovery via Direct Preference Optimization", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025. Code: https://github.com/shenwenhao01/ADHMR", "summary": "Human mesh recovery (HMR) from a single image is inherently ill-posed due to\ndepth ambiguity and occlusions. Probabilistic methods have tried to solve this\nby generating numerous plausible 3D human mesh predictions, but they often\nexhibit misalignment with 2D image observations and weak robustness to\nin-the-wild images. To address these issues, we propose ADHMR, a framework that\nAligns a Diffusion-based HMR model in a preference optimization manner. First,\nwe train a human mesh prediction assessment model, HMR-Scorer, capable of\nevaluating predictions even for in-the-wild images without 3D annotations. We\nthen use HMR-Scorer to create a preference dataset, where each input image has\na pair of winner and loser mesh predictions. This dataset is used to finetune\nthe base model using direct preference optimization. Moreover, HMR-Scorer also\nhelps improve existing HMR models by data cleaning, even with fewer training\nsamples. Extensive experiments show that ADHMR outperforms current\nstate-of-the-art methods. Code is available at:\nhttps://github.com/shenwenhao01/ADHMR."}
{"id": "2505.09704", "pdf": "https://arxiv.org/pdf/2505.09704", "abs": "https://arxiv.org/abs/2505.09704", "authors": ["Roberto Pereira", "Fernanda Famá", "Charalampos Kalalas", "Paolo Dini"], "title": "Energy-Efficient Federated Learning for AIoT using Clustering Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While substantial research has been devoted to optimizing model performance,\nconvergence rates, and communication efficiency, the energy implications of\nfederated learning (FL) within Artificial Intelligence of Things (AIoT)\nscenarios are often overlooked in the existing literature. This study examines\nthe energy consumed during the FL process, focusing on three main\nenergy-intensive processes: pre-processing, communication, and local learning,\nall contributing to the overall energy footprint. We rely on the observation\nthat device/client selection is crucial for speeding up the convergence of\nmodel training in a distributed AIoT setting and propose two\nclustering-informed methods. These clustering solutions are designed to group\nAIoT devices with similar label distributions, resulting in clusters composed\nof nearly heterogeneous devices. Hence, our methods alleviate the heterogeneity\noften encountered in real-world distributed learning applications. Throughout\nextensive numerical experimentation, we demonstrate that our clustering\nstrategies typically achieve high convergence rates while maintaining low\nenergy consumption when compared to other recent approaches available in the\nliterature."}
{"id": "2505.10010", "pdf": "https://arxiv.org/pdf/2505.10010", "abs": "https://arxiv.org/abs/2505.10010", "authors": ["Jing-Cheng Pang", "Kaiyuan Li", "Yidi Wang", "Si-Hang Yang", "Shengyi Jiang", "Yang Yu"], "title": "ImagineBench: Evaluating Reinforcement Learning with Large Language Model Rollouts", "categories": ["cs.LG"], "comment": null, "summary": "A central challenge in reinforcement learning (RL) is its dependence on\nextensive real-world interaction data to learn task-specific policies. While\nrecent work demonstrates that large language models (LLMs) can mitigate this\nlimitation by generating synthetic experience (noted as imaginary rollouts) for\nmastering novel tasks, progress in this emerging field is hindered due to the\nlack of a standard benchmark. To bridge this gap, we introduce ImagineBench,\nthe first comprehensive benchmark for evaluating offline RL algorithms that\nleverage both real rollouts and LLM-imaginary rollouts. The key features of\nImagineBench include: (1) datasets comprising environment-collected and\nLLM-imaginary rollouts; (2) diverse domains of environments covering\nlocomotion, robotic manipulation, and navigation tasks; and (3) natural\nlanguage task instructions with varying complexity levels to facilitate\nlanguage-conditioned policy learning. Through systematic evaluation of\nstate-of-the-art offline RL algorithms, we observe that simply applying\nexisting offline RL algorithms leads to suboptimal performance on unseen tasks,\nachieving 35.44% success rate in hard tasks in contrast to 64.37% of method\ntraining on real rollouts for hard tasks. This result highlights the need for\nalgorithm advancements to better leverage LLM-imaginary rollouts. Additionally,\nwe identify key opportunities for future research: including better utilization\nof imaginary rollouts, fast online adaptation and continual learning, and\nextension to multi-modal tasks. Our code is publicly available at\nhttps://github.com/LAMDA-RL/ImagineBench."}
{"id": "2505.10494", "pdf": "https://arxiv.org/pdf/2505.10494", "abs": "https://arxiv.org/abs/2505.10494", "authors": ["Yutao Mou", "Xiao Deng", "Yuxiao Luo", "Shikun Zhang", "Wei Ye"], "title": "Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective", "categories": ["cs.CL"], "comment": "Accepted by ACL2025 Main Conference", "summary": "Code security and usability are both essential for various coding assistant\napplications driven by large language models (LLMs). Current code security\nbenchmarks focus solely on single evaluation task and paradigm, such as code\ncompletion and generation, lacking comprehensive assessment across dimensions\nlike secure code generation, vulnerability repair and discrimination. In this\npaper, we first propose CoV-Eval, a multi-task benchmark covering various tasks\nsuch as code completion, vulnerability repair, vulnerability detection and\nclassification, for comprehensive evaluation of LLM code security. Besides, we\ndeveloped VC-Judge, an improved judgment model that aligns closely with human\nexperts and can review LLM-generated programs for vulnerabilities in a more\nefficient and reliable way. We conduct a comprehensive evaluation of 20\nproprietary and open-source LLMs. Overall, while most LLMs identify vulnerable\ncodes well, they still tend to generate insecure codes and struggle with\nrecognizing specific vulnerability types and performing repairs. Extensive\nexperiments and qualitative analyses reveal key challenges and optimization\ndirections, offering insights for future research in LLM code security."}
{"id": "2505.10257", "pdf": "https://arxiv.org/pdf/2505.10257", "abs": "https://arxiv.org/abs/2505.10257", "authors": ["Hao Lu", "Jiaqi Tang", "Jiyao Wang", "Yunfan LU", "Xu Cao", "Qingyong Hu", "Yin Wang", "Yuting Zhang", "Tianxin Xie", "Yunpeng Zhang", "Yong Chen", "Jiayu. Gao", "Bin Huang", "Dengbo He", "Shuiguang Deng", "Hao Chen", "Ying-Cong Chen"], "title": "Sage Deer: A Super-Aligned Driving Generalist Is Your Copilot", "categories": ["cs.CV"], "comment": null, "summary": "The intelligent driving cockpit, an important part of intelligent driving,\nneeds to match different users' comfort, interaction, and safety needs. This\npaper aims to build a Super-Aligned and GEneralist DRiving agent, SAGE DeeR.\nSage Deer achieves three highlights: (1) Super alignment: It achieves different\nreactions according to different people's preferences and biases. (2)\nGeneralist: It can understand the multi-view and multi-mode inputs to reason\nthe user's physiological indicators, facial emotions, hand movements, body\nmovements, driving scenarios, and behavioral decisions. (3) Self-Eliciting: It\ncan elicit implicit thought chains in the language space to further increase\ngeneralist and super-aligned abilities. Besides, we collected multiple data\nsets and built a large-scale benchmark. This benchmark measures the deer's\nperceptual decision-making ability and the super alignment's accuracy."}
{"id": "2505.09716", "pdf": "https://arxiv.org/pdf/2505.09716", "abs": "https://arxiv.org/abs/2505.09716", "authors": ["George Dimitriadis. Spyridon Samothrakis"], "title": "Out-of-distribution generalisation is hard: evidence from ARC-like tasks", "categories": ["cs.LG", "cs.AI"], "comment": "Submission to NeurIPS 2025", "summary": "Out-of-distribution (OOD) generalisation is considered a hallmark of human\nand animal intelligence. To achieve OOD through composition, a system must\ndiscover the environment-invariant properties of experienced input-output\nmappings and transfer them to novel inputs. This can be realised if an\nintelligent system can identify appropriate, task-invariant, and composable\ninput features, as well as the composition methods, thus allowing it to act\nbased not on the interpolation between learnt data points but on the\ntask-invariant composition of those features. We propose that in order to\nconfirm that an algorithm does indeed learn compositional structures from data,\nit is not enough to just test on an OOD setup, but one also needs to confirm\nthat the features identified are indeed compositional. We showcase this by\nexploring two tasks with clearly defined OOD metrics that are not OOD solvable\nby three commonly used neural networks: a Multi-Layer Perceptron (MLP), a\nConvolutional Neural Network (CNN), and a Transformer. In addition, we develop\ntwo novel network architectures imbued with biases that allow them to be\nsuccessful in OOD scenarios. We show that even with correct biases and almost\nperfect OOD performance, an algorithm can still fail to learn the correct\nfeatures for compositional generalisation."}
{"id": "2505.10037", "pdf": "https://arxiv.org/pdf/2505.10037", "abs": "https://arxiv.org/abs/2505.10037", "authors": ["Takafumi Ito", "Lysenko Artem", "Tatsuhiko Tsunoda"], "title": "Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction", "categories": ["cs.LG", "cs.AI", "cs.ET", "quant-ph"], "comment": "10 pages, 3 figures", "summary": "Quantum-classical Hybrid Machine Learning (QHML) models are recognized for\ntheir robust performance and high generalization ability even for relatively\nsmall datasets. These qualities offer unique advantages for anti-cancer drug\nresponse prediction, where the number of available samples is typically small.\nHowever, such hybrid models appear to be very sensitive to the data encoding\nused at the interface of a neural network and a quantum circuit, with\nsuboptimal choices leading to stability issues. To address this problem, we\npropose a novel strategy that uses a normalization function based on a\nmoderated gradient version of the $\\tanh$. This method transforms the outputs\nof the neural networks without concentrating them at the extreme value ranges.\nOur idea was evaluated on a dataset of gene expression and drug response\nmeasurements for various cancer cell lines, where we compared the prediction\nperformance of a classical deep learning model and several QHML models. These\nresults confirmed that QHML performed better than the classical models when\ndata was optimally normalized. This study opens up new possibilities for\nbiomedical data analysis using quantum computers."}
{"id": "2505.10507", "pdf": "https://arxiv.org/pdf/2505.10507", "abs": "https://arxiv.org/abs/2505.10507", "authors": ["Benedikt Ebing", "Goran Glavaš"], "title": "The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks", "categories": ["cs.CL"], "comment": null, "summary": "Translation-based strategies for cross-lingual transfer XLT such as\ntranslate-train -- training on noisy target language data translated from the\nsource language -- and translate-test -- evaluating on noisy source language\ndata translated from the target language -- are competitive XLT baselines. In\nXLT for token classification tasks, however, these strategies include label\nprojection, the challenging step of mapping the labels from each token in the\noriginal sentence to its counterpart(s) in the translation. Although word\naligners (WAs) are commonly used for label projection, the low-level design\ndecisions for applying them to translation-based XLT have not been\nsystematically investigated. Moreover, recent marker-based methods, which\nproject labeled spans by inserting tags around them before (or after)\ntranslation, claim to outperform WAs in label projection for XLT. In this work,\nwe revisit WAs for label projection, systematically investigating the effects\nof low-level design decisions on token-level XLT: (i) the algorithm for\nprojecting labels between (multi-)token spans, (ii) filtering strategies to\nreduce the number of noisily mapped labels, and (iii) the pre-tokenization of\nthe translated sentences. We find that all of these substantially impact\ntranslation-based XLT performance and show that, with optimized choices, XLT\nwith WA offers performance at least comparable to that of marker-based methods.\nWe then introduce a new projection strategy that ensembles translate-train and\ntranslate-test predictions and demonstrate that it substantially outperforms\nthe marker-based projection. Crucially, we show that our proposed ensembling\nalso reduces sensitivity to low-level WA design choices, resulting in more\nrobust XLT for token classification tasks."}
{"id": "2505.10258", "pdf": "https://arxiv.org/pdf/2505.10258", "abs": "https://arxiv.org/abs/2505.10258", "authors": ["Michael Hubbertz", "Pascal Colling", "Qi Han", "Tobias Meisen"], "title": "Inferring Driving Maps by Deep Learning-based Trail Map Extraction", "categories": ["cs.CV", "cs.RO"], "comment": "This paper was accepted at the CVPR WAD 2025 Workshop", "summary": "High-definition (HD) maps offer extensive and accurate environmental\ninformation about the driving scene, making them a crucial and essential\nelement for planning within autonomous driving systems. To avoid extensive\nefforts from manual labeling, methods for automating the map creation have\nemerged. Recent trends have moved from offline mapping to online mapping,\nensuring availability and actuality of the utilized maps. While the performance\nhas increased in recent years, online mapping still faces challenges regarding\ntemporal consistency, sensor occlusion, runtime, and generalization. We propose\na novel offline mapping approach that integrates trails - informal routes used\nby drivers - into the map creation process. Our method aggregates trail data\nfrom the ego vehicle and other traffic participants to construct a\ncomprehensive global map using transformer-based deep learning models. Unlike\ntraditional offline mapping, our approach enables continuous updates while\nremaining sensor-agnostic, facilitating efficient data transfer. Our method\ndemonstrates superior performance compared to state-of-the-art online mapping\napproaches, achieving improved generalization to previously unseen environments\nand sensor configurations. We validate our approach on two benchmark datasets,\nhighlighting its robustness and applicability in autonomous driving systems."}
{"id": "2505.09724", "pdf": "https://arxiv.org/pdf/2505.09724", "abs": "https://arxiv.org/abs/2505.09724", "authors": ["Gino Carmona-Díaz", "William Jiménez-Leal", "María Alejandra Grisales", "Chandra Sripada", "Santiago Amaya", "Michael Inzlicht", "Juan Pablo Bermúdez"], "title": "An AI-Powered Research Assistant in the Lab: A Practical Guide for Text Analysis Through Iterative Collaboration with LLMs", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "31 pages, 1 figure", "summary": "Analyzing texts such as open-ended responses, headlines, or social media\nposts is a time- and labor-intensive process highly susceptible to bias. LLMs\nare promising tools for text analysis, using either a predefined (top-down) or\na data-driven (bottom-up) taxonomy, without sacrificing quality. Here we\npresent a step-by-step tutorial to efficiently develop, test, and apply\ntaxonomies for analyzing unstructured data through an iterative and\ncollaborative process between researchers and LLMs. Using personal goals\nprovided by participants as an example, we demonstrate how to write prompts to\nreview datasets and generate a taxonomy of life domains, evaluate and refine\nthe taxonomy through prompt and direct modifications, test the taxonomy and\nassess intercoder agreements, and apply the taxonomy to categorize an entire\ndataset with high intercoder reliability. We discuss the possibilities and\nlimitations of using LLMs for text analysis."}
{"id": "2505.10039", "pdf": "https://arxiv.org/pdf/2505.10039", "abs": "https://arxiv.org/abs/2505.10039", "authors": ["Hang Chen", "Jiaying Zhu", "Xinyu Yang", "Wenya Wang"], "title": "Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates", "categories": ["cs.LG"], "comment": "10 pages", "summary": "Circuit discovery has gradually become one of the prominent methods for\nmechanistic interpretability, and research on circuit completeness has also\ngarnered increasing attention. Methods of circuit discovery that do not\nguarantee completeness not only result in circuits that are not fixed across\ndifferent runs but also cause key mechanisms to be omitted. The nature of\nincompleteness arises from the presence of OR gates within the circuit, which\nare often only partially detected in standard circuit discovery methods. To\nthis end, we systematically introduce three types of logic gates: AND, OR, and\nADDER gates, and decompose the circuit into combinations of these logical\ngates. Through the concept of these gates, we derive the minimum requirements\nnecessary to achieve faithfulness and completeness. Furthermore, we propose a\nframework that combines noising-based and denoising-based interventions, which\ncan be easily integrated into existing circuit discovery methods without\nsignificantly increasing computational complexity. This framework is capable of\nfully identifying the logic gates and distinguishing them within the circuit.\nIn addition to the extensive experimental validation of the framework's ability\nto restore the faithfulness, completeness, and sparsity of circuits, using this\nframework, we uncover fundamental properties of the three logic gates, such as\ntheir proportions and contributions to the output, and explore how they behave\namong the functionalities of language models."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.10267", "pdf": "https://arxiv.org/pdf/2505.10267", "abs": "https://arxiv.org/abs/2505.10267", "authors": ["Pavel Korotaev", "Petr Surovtsev", "Alexander Kapitanov", "Karina Kvanchiani", "Aleksandr Nagaev"], "title": "HandReader: Advanced Techniques for Efficient Fingerspelling Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "https://github.com/ai-forever/handreader", "summary": "Fingerspelling is a significant component of Sign Language (SL), allowing the\ninterpretation of proper names, characterized by fast hand movements during\nsigning. Although previous works on fingerspelling recognition have focused on\nprocessing the temporal dimension of videos, there remains room for improving\nthe accuracy of these approaches. This paper introduces HandReader, a group of\nthree architectures designed to address the fingerspelling recognition task.\nHandReader$_{RGB}$ employs the novel Temporal Shift-Adaptive Module (TSAM) to\nprocess RGB features from videos of varying lengths while preserving important\nsequential information. HandReader$_{KP}$ is built on the proposed Temporal\nPose Encoder (TPE) operated on keypoints as tensors. Such keypoints composition\nin a batch allows the encoder to pass them through 2D and 3D convolution\nlayers, utilizing temporal and spatial information and accumulating keypoints\ncoordinates. We also introduce HandReader_RGB+KP - architecture with a joint\nencoder to benefit from RGB and keypoint modalities. Each HandReader model\npossesses distinct advantages and achieves state-of-the-art results on the\nChicagoFSWild and ChicagoFSWild+ datasets. Moreover, the models demonstrate\nhigh performance on the first open dataset for Russian fingerspelling, Znaki,\npresented in this paper. The Znaki dataset and HandReader pre-trained models\nare publicly available."}
{"id": "2505.09733", "pdf": "https://arxiv.org/pdf/2505.09733", "abs": "https://arxiv.org/abs/2505.09733", "authors": ["Alpaslan Gokcen", "Ali Boyaci"], "title": "Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning (FL) presents an effective solution for collaborative\nmodel training while maintaining data privacy across decentralized client\ndatasets. However, data quality issues such as noisy labels, missing classes,\nand imbalanced distributions significantly challenge its effectiveness. This\nstudy proposes a federated learning methodology that systematically addresses\ndata quality issues, including noise, class imbalance, and missing labels. The\nproposed approach systematically enhances data integrity through adaptive noise\ncleaning, collaborative conditional GAN-based synthetic data generation, and\nrobust federated model training. Experimental evaluations conducted on\nbenchmark datasets (MNIST and Fashion-MNIST) demonstrate significant\nimprovements in federated model performance, particularly macro-F1 Score, under\nvarying noise and class imbalance conditions. Additionally, the proposed\nframework carefully balances computational feasibility and substantial\nperformance gains, ensuring practicality for resource constrained edge devices\nwhile rigorously maintaining data privacy. Our results indicate that this\nmethod effectively mitigates common data quality challenges, providing a\nrobust, scalable, and privacy compliant solution suitable for diverse\nreal-world federated learning scenarios."}
{"id": "2505.10040", "pdf": "https://arxiv.org/pdf/2505.10040", "abs": "https://arxiv.org/abs/2505.10040", "authors": ["Lei Song", "Jiaxing Li", "Shihan Guan", "Youyong Kong"], "title": "Instance-Prototype Affinity Learning for Non-Exemplar Continual Graph Learning", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNN) endure catastrophic forgetting, undermining their\ncapacity to preserve previously acquired knowledge amid the assimilation of\nnovel information. Rehearsal-based techniques revisit historical examples,\nadopted as a principal strategy to alleviate this phenomenon. However, memory\nexplosion and privacy infringements impose significant constraints on their\nutility. Non-Exemplar methods circumvent the prior issues through Prototype\nReplay (PR), yet feature drift presents new challenges. In this paper, our\nempirical findings reveal that Prototype Contrastive Learning (PCL) exhibits\nless pronounced drift than conventional PR. Drawing upon PCL, we propose\nInstance-Prototype Affinity Learning (IPAL), a novel paradigm for Non-Exemplar\nContinual Graph Learning (NECGL). Exploiting graph structural information, we\nformulate Topology-Integrated Gaussian Prototypes (TIGP), guiding feature\ndistributions towards high-impact nodes to augment the model's capacity for\nassimilating new knowledge. Instance-Prototype Affinity Distillation (IPAD)\nsafeguards task memory by regularizing discontinuities in class relationships.\nMoreover, we embed a Decision Boundary Perception (DBP) mechanism within PCL,\nfostering greater inter-class discriminability. Evaluations on four node\nclassification benchmark datasets demonstrate that our method outperforms\nexisting state-of-the-art methods, achieving a better trade-off between\nplasticity and stability."}
{"id": "2505.10527", "pdf": "https://arxiv.org/pdf/2505.10527", "abs": "https://arxiv.org/abs/2505.10527", "authors": ["Binghai Wang", "Runji Lin", "Keming Lu", "Le Yu", "Zhenru Zhang", "Fei Huang", "Chujie Zheng", "Kai Dang", "Yang Fan", "Xingzhang Ren", "An Yang", "Binyuan Hui", "Dayiheng Liu", "Tao Gui", "Qi Zhang", "Xuanjing Huang", "Yu-Gang Jiang", "Bowen Yu", "Jingren Zhou", "Junyang Lin"], "title": "WorldPM: Scaling Human Preference Modeling", "categories": ["cs.CL"], "comment": null, "summary": "Motivated by scaling laws in language modeling that demonstrate how test loss\nscales as a power law with model and dataset sizes, we find that similar laws\nexist in preference modeling. We propose World Preference Modeling$ (WorldPM)\nto emphasize this scaling potential, where World Preference embodies a unified\nrepresentation of human preferences. In this paper, we collect preference data\nfrom public forums covering diverse user communities, and conduct extensive\ntraining using 15M-scale data across models ranging from 1.5B to 72B\nparameters. We observe distinct patterns across different evaluation metrics:\n(1) Adversarial metrics (ability to identify deceptive features) consistently\nscale up with increased training data and base model size; (2) Objective\nmetrics (objective knowledge with well-defined answers) show emergent behavior\nin larger language models, highlighting WorldPM's scalability potential; (3)\nSubjective metrics (subjective preferences from a limited number of humans or\nAI) do not demonstrate scaling trends. Further experiments validate the\neffectiveness of WorldPM as a foundation for preference fine-tuning. Through\nevaluations on 7 benchmarks with 20 subtasks, we find that WorldPM broadly\nimproves the generalization performance across human preference datasets of\nvarying sizes (7K, 100K and 800K samples), with performance gains exceeding 5%\non many key subtasks. Integrating WorldPM into our internal RLHF pipeline, we\nobserve significant improvements on both in-house and public evaluation sets,\nwith notable gains of 4% to 8% in our in-house evaluations."}
{"id": "2505.10281", "pdf": "https://arxiv.org/pdf/2505.10281", "abs": "https://arxiv.org/abs/2505.10281", "authors": ["Mengqiu Xu", "Kaixin Chen", "Heng Guo", "Yixiang Huang", "Ming Wu", "Zhenwei Shi", "Chuang Zhang", "Jun Guo"], "title": "MFogHub: Bridging Multi-Regional and Multi-Satellite Data for Global Marine Fog Detection and Forecasting", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning approaches for marine fog detection and forecasting have\noutperformed traditional methods, demonstrating significant scientific and\npractical importance. However, the limited availability of open-source datasets\nremains a major challenge. Existing datasets, often focused on a single region\nor satellite, restrict the ability to evaluate model performance across diverse\nconditions and hinder the exploration of intrinsic marine fog characteristics.\nTo address these limitations, we introduce \\textbf{MFogHub}, the first\nmulti-regional and multi-satellite dataset to integrate annotated marine fog\nobservations from 15 coastal fog-prone regions and six geostationary\nsatellites, comprising over 68,000 high-resolution samples. By encompassing\ndiverse regions and satellite perspectives, MFogHub facilitates rigorous\nevaluation of both detection and forecasting methods under varying conditions.\nExtensive experiments with 16 baseline models demonstrate that MFogHub can\nreveal generalization fluctuations due to regional and satellite discrepancy,\nwhile also serving as a valuable resource for the development of targeted and\nscalable fog prediction techniques. Through MFogHub, we aim to advance both the\npractical monitoring and scientific understanding of marine fog dynamics on a\nglobal scale. The dataset and code are at\n\\href{https://github.com/kaka0910/MFogHub}{https://github.com/kaka0910/MFogHub}."}
{"id": "2505.09738", "pdf": "https://arxiv.org/pdf/2505.09738", "abs": "https://arxiv.org/abs/2505.09738", "authors": ["Shaurya Sharthak", "Vinayak Pahalwan", "Adithya Kamath", "Adarsh Shirawalmath"], "title": "Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Pretrained language models (LLMs) are often constrained by their fixed\ntokenization schemes, leading to inefficiencies and performance limitations,\nparticularly for multilingual or specialized applications. This tokenizer\nlock-in presents significant challenges. standard methods to overcome this\noften require prohibitive computational resources. Although tokenizer\nreplacement with heuristic initialization aims to reduce this burden, existing\nmethods often require exhaustive residual fine-tuning and still may not fully\npreserve semantic nuances or adequately address the underlying compression\ninefficiencies. Our framework introduces two innovations: first, Tokenadapt, a\nmodel-agnostic tokenizer transplantation method, and second, novel\npre-tokenization learning for multi-word Supertokens to enhance compression and\nreduce fragmentation. Tokenadapt initializes new unique token embeddings via a\nhybrid heuristic that combines two methods: a local estimate based on subword\ndecomposition using the old tokenizer, and a global estimate utilizing the\ntop-k semantically similar tokens from the original vocabulary. This\nmethodology aims to preserve semantics while significantly minimizing\nretraining requirements. Empirical investigations validate both contributions:\nthe transplantation heuristic successfully initializes unique tokens, markedly\noutperforming conventional baselines and sophisticated methods including\nTranstokenizer and ReTok, while our Supertokens achieve notable compression\ngains. Our zero-shot perplexity results demonstrate that the TokenAdapt hybrid\ninitialization consistently yields lower perplexity ratios compared to both\nReTok and TransTokenizer baselines across different base models and newly\ntrained target tokenizers. TokenAdapt typically reduced the overall perplexity\nratio significantly compared to ReTok, yielding at least a 2-fold improvement\nin these aggregate scores."}
{"id": "2505.10050", "pdf": "https://arxiv.org/pdf/2505.10050", "abs": "https://arxiv.org/abs/2505.10050", "authors": ["Fahad Almalki", "Mehedi Masud"], "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection."}
{"id": "2505.10554", "pdf": "https://arxiv.org/pdf/2505.10554", "abs": "https://arxiv.org/abs/2505.10554", "authors": ["Zhiyuan Hu", "Yibo Wang", "Hanze Dong", "Yuhui Xu", "Amrita Saha", "Caiming Xiong", "Bryan Hooi", "Junnan Li"], "title": "Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large Reasoning Models", "categories": ["cs.CL"], "comment": "In Progress", "summary": "Large reasoning models (LRMs) already possess a latent capacity for long\nchain-of-thought reasoning. Prior work has shown that outcome-based\nreinforcement learning (RL) can incidentally elicit advanced reasoning\nbehaviors such as self-correction, backtracking, and verification phenomena\noften referred to as the model's \"aha moment\". However, the timing and\nconsistency of these emergent behaviors remain unpredictable and\nuncontrollable, limiting the scalability and reliability of LRMs' reasoning\ncapabilities. To address these limitations, we move beyond reliance on prompts\nand coincidental \"aha moments\". Instead, we explicitly align models with three\nmeta-abilities: deduction, induction, and abduction, using automatically\ngenerated, self-verifiable tasks. Our three stage-pipeline individual\nalignment, parameter-space merging, and domain-specific reinforcement learning,\nboosting performance by over 10\\% relative to instruction-tuned baselines.\nFurthermore, domain-specific RL from the aligned checkpoint yields an\nadditional 2\\% average gain in the performance ceiling across math, coding, and\nscience benchmarks, demonstrating that explicit meta-ability alignment offers a\nscalable and dependable foundation for reasoning. Code is available at:\nhttps://github.com/zhiyuanhubj/Meta-Ability-Alignment"}
{"id": "2505.10289", "pdf": "https://arxiv.org/pdf/2505.10289", "abs": "https://arxiv.org/abs/2505.10289", "authors": ["Yue Wang", "Shuai Xu", "Xuelin Zhu", "Yicong Li"], "title": "MSCI: Addressing CLIP's Inherent Limitations for Compositional Zero-Shot Learning", "categories": ["cs.CV"], "comment": "9 pages, 5 figures", "summary": "Compositional Zero-Shot Learning (CZSL) aims to recognize unseen state-object\ncombinations by leveraging known combinations. Existing studies basically rely\non the cross-modal alignment capabilities of CLIP but tend to overlook its\nlimitations in capturing fine-grained local features, which arise from its\narchitectural and training paradigm. To address this issue, we propose a\nMulti-Stage Cross-modal Interaction (MSCI) model that effectively explores and\nutilizes intermediate-layer information from CLIP's visual encoder.\nSpecifically, we design two self-adaptive aggregators to extract local\ninformation from low-level visual features and integrate global information\nfrom high-level visual features, respectively. These key information are\nprogressively incorporated into textual representations through a\nstage-by-stage interaction mechanism, significantly enhancing the model's\nperception capability for fine-grained local visual information. Additionally,\nMSCI dynamically adjusts the attention weights between global and local visual\ninformation based on different combinations, as well as different elements\nwithin the same combination, allowing it to flexibly adapt to diverse\nscenarios. Experiments on three widely used datasets fully validate the\neffectiveness and superiority of the proposed model. Data and code are\navailable at https://github.com/ltpwy/MSCI."}
{"id": "2505.09742", "pdf": "https://arxiv.org/pdf/2505.09742", "abs": "https://arxiv.org/abs/2505.09742", "authors": ["Yuan-Hang Zhang", "Massimiliano Di Ventra"], "title": "A Generative Neural Annealer for Black-Box Combinatorial Optimization", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.NE"], "comment": "15 pages, 3 figures", "summary": "We propose a generative, end-to-end solver for black-box combinatorial\noptimization that emphasizes both sample efficiency and solution quality on NP\nproblems. Drawing inspiration from annealing-based algorithms, we treat the\nblack-box objective as an energy function and train a neural network to model\nthe associated Boltzmann distribution. By conditioning on temperature, the\nnetwork captures a continuum of distributions--from near-uniform at high\ntemperatures to sharply peaked around global optima at low\ntemperatures--thereby learning the structure of the energy landscape and\nfacilitating global optimization. When queries are expensive, the\ntemperature-dependent distributions naturally enable data augmentation and\nimprove sample efficiency. When queries are cheap but the problem remains hard,\nthe model learns implicit variable interactions, effectively \"opening\" the\nblack box. We validate our approach on challenging combinatorial tasks under\nboth limited and unlimited query budgets, showing competitive performance\nagainst state-of-the-art black-box optimizers."}
{"id": "2505.10057", "pdf": "https://arxiv.org/pdf/2505.10057", "abs": "https://arxiv.org/abs/2505.10057", "authors": ["Tiancong Cheng", "Ying Zhang", "Yuxuan Liang", "Roger Zimmermann", "Zhiwen Yu", "Bin Guo"], "title": "JointDistill: Adaptive Multi-Task Distillation for Joint Depth Estimation and Scene Segmentation", "categories": ["cs.LG"], "comment": null, "summary": "Depth estimation and scene segmentation are two important tasks in\nintelligent transportation systems. A joint modeling of these two tasks will\nreduce the requirement for both the storage and training efforts. This work\nexplores how the multi-task distillation could be used to improve such unified\nmodeling. While existing solutions transfer multiple teachers' knowledge in a\nstatic way, we propose a self-adaptive distillation method that can dynamically\nadjust the knowledge amount from each teacher according to the student's\ncurrent learning ability. Furthermore, as multiple teachers exist, the\nstudent's gradient update direction in the distillation is more prone to be\nerroneous where knowledge forgetting may occur. To avoid this, we propose a\nknowledge trajectory to record the most essential information that a model has\nlearnt in the past, based on which a trajectory-based distillation loss is\ndesigned to guide the student to follow the learning curve similarly in a\ncost-effective way. We evaluate our method on multiple benchmarking datasets\nincluding Cityscapes and NYU-v2. Compared to the state-of-the-art solutions,\nour method achieves a clearly improvement. The code is provided in the\nsupplementary materials."}
{"id": "2505.09665", "pdf": "https://arxiv.org/pdf/2505.09665", "abs": "https://arxiv.org/abs/2505.09665", "authors": ["Sulong Zhou", "Qunying Huang", "Shaoheng Zhou", "Yun Hang", "Xinyue Ye", "Aodong Mei", "Kathryn Phung", "Yuning Ye", "Uma Govindswamy", "Zehan Li"], "title": "Tales of the 2025 Los Angeles Fire: Hotwash for Public Health Concerns in Reddit via LLM-Enhanced Topic Modeling", "categories": ["cs.SI", "cs.CL"], "comment": null, "summary": "Wildfires have become increasingly frequent, irregular, and severe in recent\nyears. Understanding how affected populations perceive and respond during\nwildfire crises is critical for timely and empathetic disaster response. Social\nmedia platforms offer a crowd-sourced channel to capture evolving public\ndiscourse, providing hyperlocal information and insight into public sentiment.\nThis study analyzes Reddit discourse during the 2025 Los Angeles wildfires,\nspanning from the onset of the disaster to full containment. We collect 385\nposts and 114,879 comments related to the Palisades and Eaton fires. We adopt\ntopic modeling methods to identify the latent topics, enhanced by large\nlanguage models (LLMs) and human-in-the-loop (HITL) refinement. Furthermore, we\ndevelop a hierarchical framework to categorize latent topics, consisting of two\nmain categories, Situational Awareness (SA) and Crisis Narratives (CN). The\nvolume of SA category closely aligns with real-world fire progressions, peaking\nwithin the first 2-5 days as the fires reach the maximum extent. The most\nfrequent co-occurring category set of public health and safety, loss and\ndamage, and emergency resources expands on a wide range of health-related\nlatent topics, including environmental health, occupational health, and one\nhealth. Grief signals and mental health risks consistently accounted for 60\npercentage and 40 percentage of CN instances, respectively, with the highest\ntotal volume occurring at night. This study contributes the first annotated\nsocial media dataset on the 2025 LA fires, and introduces a scalable\nmulti-layer framework that leverages topic modeling for crisis discourse\nanalysis. By identifying persistent public health concerns, our results can\ninform more empathetic and adaptive strategies for disaster response, public\nhealth communication, and future research in comparable climate-related\ndisaster events."}
{"id": "2505.10292", "pdf": "https://arxiv.org/pdf/2505.10292", "abs": "https://arxiv.org/abs/2505.10292", "authors": ["Daniel A. P. Oliveira", "David Martins de Matos"], "title": "StoryReasoning Dataset: Using Chain-of-Thought for Scene Understanding and Grounded Story Generation", "categories": ["cs.CV", "cs.CL", "I.2.10; I.2.7"], "comment": "31 pages, 14 figures", "summary": "Visual storytelling systems struggle to maintain character identity across\nframes and link actions to appropriate subjects, frequently leading to\nreferential hallucinations. These issues can be addressed through grounding of\ncharacters, objects, and other entities on the visual elements. We propose\nStoryReasoning, a dataset containing 4,178 stories derived from 52,016 movie\nimages, with both structured scene analyses and grounded stories. Each story\nmaintains character and object consistency across frames while explicitly\nmodeling multi-frame relationships through structured tabular representations.\nOur approach features cross-frame object re-identification using visual\nsimilarity and face recognition, chain-of-thought reasoning for explicit\nnarrative modeling, and a grounding scheme that links textual elements to\nvisual entities across multiple frames. We establish baseline performance by\nfine-tuning Qwen2.5-VL 7B, creating Qwen Storyteller, which performs end-to-end\nobject detection, re-identification, and landmark detection while maintaining\nconsistent object references throughout the story. Evaluation demonstrates a\nreduction from 4.06 to 3.56 (-12.3%) hallucinations on average per story when\ncompared to a non-fine-tuned model."}
{"id": "2505.09747", "pdf": "https://arxiv.org/pdf/2505.09747", "abs": "https://arxiv.org/abs/2505.09747", "authors": ["Benjamin Paaßen", "Suzana Alpsancar", "Tobias Matzner", "Ingrid Scharlau"], "title": "Healthy Distrust in AI systems", "categories": ["cs.CY", "cs.AI"], "comment": null, "summary": "Under the slogan of trustworthy AI, much of contemporary AI research is\nfocused on designing AI systems and usage practices that inspire human trust\nand, thus, enhance adoption of AI systems. However, a person affected by an AI\nsystem may not be convinced by AI system design alone -- neither should they,\nif the AI system is embedded in a social context that gives good reason to\nbelieve that it is used in tension with a person's interest. In such cases,\ndistrust in the system may be justified and necessary to build meaningful trust\nin the first place. We propose the term \"healthy distrust\" to describe such a\njustified, careful stance towards certain AI usage practices. We investigate\nprior notions of trust and distrust in computer science, sociology, history,\npsychology, and philosophy, outline a remaining gap that healthy distrust might\nfill and conceptualize healthy distrust as a crucial part for AI usage that\nrespects human autonomy."}
{"id": "2505.10083", "pdf": "https://arxiv.org/pdf/2505.10083", "abs": "https://arxiv.org/abs/2505.10083", "authors": ["Chengsen Wang", "Qi Qi", "Zhongwen Rao", "Lujia Pan", "Jingyu Wang", "Jianxin Liao"], "title": "ChronoSteer: Bridging Large Language Model and Time Series Foundation Model via Synthetic Data", "categories": ["cs.LG"], "comment": null, "summary": "Conventional forecasting methods rely on unimodal time series data, limiting\ntheir ability to exploit rich textual information. Recently, large language\nmodels (LLMs) and time series foundation models (TSFMs) have demonstrated\npowerful capability in textual reasoning and temporal modeling, respectively.\nIntegrating the strengths of both to construct a multimodal model that\nconcurrently leverages both temporal and textual information for future\ninference has emerged as a critical research challenge. To address the scarcity\nof event-series paired data, we propose a decoupled framework: an LLM is\nemployed to transform textual events into revision instructions, which are then\nused to steer the output of TSFM. To implement this framework, we introduce\nChronoSteer, a multimodal TSFM that can be steered through textual revision\ninstructions, effectively bridging LLM and TSFM. Moreover, to mitigate the\nshortage of cross-modal instruction-series paired data, we devise a two-stage\ntraining strategy based on synthetic data. In addition, we also construct a\nhigh-quality multimodal time series forecasting benchmark to address the\ninformation leakage concerns during evaluation. After integrating with an LLM,\nChronoSteer, which is trained exclusively on synthetic data, achieves a 25.7%\nimprovement in prediction accuracy compared to the unimodal backbone and a\n22.5% gain over the previous state-of-the-art multimodal method."}
{"id": "2505.09777", "pdf": "https://arxiv.org/pdf/2505.09777", "abs": "https://arxiv.org/abs/2505.09777", "authors": ["Alejo Lopez-Avila", "Jinhua Du"], "title": "A Survey on Large Language Models in Multimodal Recommender Systems", "categories": ["cs.IR", "cs.CL"], "comment": "30 pages, 6 figures", "summary": "Multimodal recommender systems (MRS) integrate heterogeneous user and item\ndata, such as text, images, and structured information, to enhance\nrecommendation performance. The emergence of large language models (LLMs)\nintroduces new opportunities for MRS by enabling semantic reasoning, in-context\nlearning, and dynamic input handling. Compared to earlier pre-trained language\nmodels (PLMs), LLMs offer greater flexibility and generalisation capabilities\nbut also introduce challenges related to scalability and model accessibility.\nThis survey presents a comprehensive review of recent work at the intersection\nof LLMs and MRS, focusing on prompting strategies, fine-tuning methods, and\ndata adaptation techniques. We propose a novel taxonomy to characterise\nintegration patterns, identify transferable techniques from related\nrecommendation domains, provide an overview of evaluation metrics and datasets,\nand point to possible future directions. We aim to clarify the emerging role of\nLLMs in multimodal recommendation and support future research in this rapidly\nevolving field."}
{"id": "2505.10294", "pdf": "https://arxiv.org/pdf/2505.10294", "abs": "https://arxiv.org/abs/2505.10294", "authors": ["Guillaume Balezo", "Roger Trullo", "Albert Pla Planas", "Etienne Decenciere", "Thomas Walter"], "title": "MIPHEI-ViT: Multiplex Immunofluorescence Prediction from H&E Images using ViT Foundation Models", "categories": ["cs.CV", "q-bio.TO", "68T07 (Primary), 92C55 (Secondary)", "I.4.9; I.2.10; I.5.4; J.3"], "comment": null, "summary": "Histopathological analysis is a cornerstone of cancer diagnosis, with\nHematoxylin and Eosin (H&E) staining routinely acquired for every patient to\nvisualize cell morphology and tissue architecture. On the other hand, multiplex\nimmunofluorescence (mIF) enables more precise cell type identification via\nproteomic markers, but has yet to achieve widespread clinical adoption due to\ncost and logistical constraints. To bridge this gap, we introduce MIPHEI\n(Multiplex Immunofluorescence Prediction from H&E), a U-Net-inspired\narchitecture that integrates state-of-the-art ViT foundation models as encoders\nto predict mIF signals from H&E images. MIPHEI targets a comprehensive panel of\nmarkers spanning nuclear content, immune lineages (T cells, B cells, myeloid),\nepithelium, stroma, vasculature, and proliferation. We train our model using\nthe publicly available ORION dataset of restained H&E and mIF images from\ncolorectal cancer tissue, and validate it on two independent datasets. MIPHEI\nachieves accurate cell-type classification from H&E alone, with F1 scores of\n0.88 for Pan-CK, 0.57 for CD3e, 0.56 for SMA, 0.36 for CD68, and 0.30 for CD20,\nsubstantially outperforming both a state-of-the-art baseline and a random\nclassifier for most markers. Our results indicate that our model effectively\ncaptures the complex relationships between nuclear morphologies in their tissue\ncontext, as visible in H&E images and molecular markers defining specific cell\ntypes. MIPHEI offers a promising step toward enabling cell-type-aware analysis\nof large-scale H&E datasets, in view of uncovering relationships between\nspatial cellular organization and patient outcomes."}
{"id": "2505.09757", "pdf": "https://arxiv.org/pdf/2505.09757", "abs": "https://arxiv.org/abs/2505.09757", "authors": ["Botao Amber Hu", "Yuhan Liu", "Helena Rong"], "title": "Trustless Autonomy: Understanding Motivations, Benefits and Governance Dilemma in Self-Sovereign Decentralized AI Agents", "categories": ["cs.HC", "cs.AI", "cs.CY"], "comment": "Submitted to CSCW 2026", "summary": "The recent trend of self-sovereign Decentralized AI Agents (DeAgents)\ncombines Large Language Model (LLM)-based AI agents with decentralization\ntechnologies such as blockchain smart contracts and trusted execution\nenvironments (TEEs). These tamper-resistant trustless substrates allow agents\nto achieve self-sovereignty through ownership of cryptowallet private keys and\ncontrol of digital assets and social media accounts. DeAgent eliminates\ncentralized control and reduces human intervention, addressing key trust\nconcerns inherent in centralized AI systems. However, given ongoing challenges\nin LLM reliability such as hallucinations, this creates paradoxical tension\nbetween trustlessness and unreliable autonomy. This study addresses this\nempirical research gap through interviews with DeAgents stakeholders-experts,\nfounders, and developers-to examine their motivations, benefits, and governance\ndilemmas. The findings will guide future DeAgents system and protocol design\nand inform discussions about governance in sociotechnical AI systems in the\nfuture agentic web."}
{"id": "2505.10117", "pdf": "https://arxiv.org/pdf/2505.10117", "abs": "https://arxiv.org/abs/2505.10117", "authors": ["JieHao Wu", "Ziwei Wang", "Junjie Sheng", "Wenhao Li", "Xiangfei Wang", "Jun Luo"], "title": "Learning Virtual Machine Scheduling in Cloud Computing through Language Agents", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "In cloud services, virtual machine (VM) scheduling is a typical Online\nDynamic Multidimensional Bin Packing (ODMBP) problem, characterized by\nlarge-scale complexity and fluctuating demands. Traditional optimization\nmethods struggle to adapt to real-time changes, domain-expert-designed\nheuristic approaches suffer from rigid strategies, and existing learning-based\nmethods often lack generalizability and interpretability. To address these\nlimitations, this paper proposes a hierarchical language agent framework named\nMiCo, which provides a large language model (LLM)-driven heuristic design\nparadigm for solving ODMBP. Specifically, ODMBP is formulated as a Semi-Markov\nDecision Process with Options (SMDP-Option), enabling dynamic scheduling\nthrough a two-stage architecture, i.e., Option Miner and Option Composer.\nOption Miner utilizes LLMs to discover diverse and useful non-context-aware\nstrategies by interacting with constructed environments. Option Composer\nemploys LLMs to discover a composing strategy that integrates the\nnon-context-aware strategies with the contextual ones. Extensive experiments on\nreal-world enterprise datasets demonstrate that MiCo achieves a 96.9\\%\ncompetitive ratio in large-scale scenarios involving more than 10,000 virtual\nmachines. It maintains high performance even under nonstationary request flows\nand diverse configurations, thus validating its effectiveness in complex and\nlarge-scale cloud environments."}
{"id": "2505.09855", "pdf": "https://arxiv.org/pdf/2505.09855", "abs": "https://arxiv.org/abs/2505.09855", "authors": ["Alexander Y. Ku", "Thomas L. Griffiths", "Stephanie C. Y. Chan"], "title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies."}
{"id": "2505.10351", "pdf": "https://arxiv.org/pdf/2505.10351", "abs": "https://arxiv.org/abs/2505.10351", "authors": ["Jie Zhu", "Jirong Zha", "Ding Li", "Leye Wang"], "title": "A Unified and Scalable Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability", "categories": ["cs.CV"], "comment": "An extension of our ACM CCS2024 conference paper (arXiv:2404.02462).\n  We show the impacts of scaling from both data and model aspects on membership\n  inference for self-supervised visual encoders", "summary": "Self-supervised learning shows promise in harnessing extensive unlabeled\ndata, but it also confronts significant privacy concerns, especially in vision.\nIn this paper, we perform membership inference on visual self-supervised models\nin a more realistic setting: self-supervised training method and details are\nunknown for an adversary when attacking as he usually faces a black-box system\nin practice. In this setting, considering that self-supervised model could be\ntrained by completely different self-supervised paradigms, e.g., masked image\nmodeling and contrastive learning, with complex training details, we propose a\nunified membership inference method called PartCrop. It is motivated by the\nshared part-aware capability among models and stronger part response on the\ntraining data. Specifically, PartCrop crops parts of objects in an image to\nquery responses within the image in representation space. We conduct extensive\nattacks on self-supervised models with different training protocols and\nstructures using three widely used image datasets. The results verify the\neffectiveness and generalization of PartCrop. Moreover, to defend against\nPartCrop, we evaluate two common approaches, i.e., early stop and differential\nprivacy, and propose a tailored method called shrinking crop scale range. The\ndefense experiments indicate that all of them are effective. Finally, besides\nprototype testing on toy visual encoders and small-scale image datasets, we\nquantitatively study the impacts of scaling from both data and model aspects in\na realistic scenario and propose a scalable PartCrop-v2 by introducing two\nstructural improvements to PartCrop. Our code is at\nhttps://github.com/JiePKU/PartCrop."}
{"id": "2505.09766", "pdf": "https://arxiv.org/pdf/2505.09766", "abs": "https://arxiv.org/abs/2505.09766", "authors": ["Roberto Ponciroli"], "title": "On the Well-Posedness of Green's Function Reconstruction via the Kirchhoff-Helmholtz Equation for One-Speed Neutron Diffusion", "categories": ["math.NA", "cs.AI", "cs.NA"], "comment": null, "summary": "This work presents a methodology for reconstructing the spatial distribution\nof the neutron flux in a nuclear reactor, leveraging real-time measurements\nobtained from ex-core detectors. The Kirchhoff-Helmholtz (K-H) equation\ninherently defines the problem of estimating a scalar field within a domain\nbased on boundary data, making it a natural mathematical framework for this\ntask. The main challenge lies in deriving the Green's function specific to the\ndomain and the neutron diffusion process. While analytical solutions for\nGreen's functions exist for simplified geometries, their derivation of complex,\nheterogeneous domains-such as a nuclear reactor-requires a numerical approach.\nThe objective of this work is to demonstrate the well-posedness of the\ndata-driven Green's function approximation by formulating and solving the K-H\nequation as an inverse problem. After establishing the symmetry properties that\nthe Green's function must satisfy, the K-H equation is derived from the\none-speed neutron diffusion model. This is followed by a comprehensive\ndescription of the procedure for interpreting sensor readings and implementing\nthe neutron flux reconstruction algorithm. Finally, the existence and\nuniqueness of the Green's function inferred from the sampled data are\ndemonstrated, ensuring the reliability of the proposed method and its\npredictions."}
{"id": "2505.10120", "pdf": "https://arxiv.org/pdf/2505.10120", "abs": "https://arxiv.org/abs/2505.10120", "authors": ["Guillaume Godin"], "title": "All You Need Is Synthetic Task Augmentation", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 3 Figures, 6 tables", "summary": "Injecting rule-based models like Random Forests into differentiable neural\nnetwork frameworks remains an open challenge in machine learning. Recent\nadvancements have demonstrated that pretrained models can generate efficient\nmolecular embeddings. However, these approaches often require extensive\npretraining and additional techniques, such as incorporating posterior\nprobabilities, to boost performance. In our study, we propose a novel strategy\nthat jointly trains a single Graph Transformer neural network on both sparse\nmultitask molecular property experimental targets and synthetic targets derived\nfrom XGBoost models trained on Osmordred molecular descriptors. These synthetic\ntasks serve as independent auxiliary tasks. Our results show consistent and\nsignificant performance improvement across all 19 molecular property prediction\ntasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms\nthe XGBoost single-task learner. This demonstrates that synthetic task\naugmentation is an effective method for enhancing neural model performance in\nmultitask molecular property prediction without the need for feature injection\nor pretraining."}
{"id": "2505.09901", "pdf": "https://arxiv.org/pdf/2505.09901", "abs": "https://arxiv.org/abs/2505.09901", "authors": ["Ziyuan Zhang", "Darcy Wang", "Ningyuan Chen", "Rodrigo Mansur", "Vahid Sarhangian"], "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements."}
{"id": "2505.10352", "pdf": "https://arxiv.org/pdf/2505.10352", "abs": "https://arxiv.org/abs/2505.10352", "authors": ["Shihao Zou", "Qingfeng Li", "Wei Ji", "Jingjing Li", "Yongkui Yang", "Guoqi Li", "Chao Dong"], "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer"}
{"id": "2505.09794", "pdf": "https://arxiv.org/pdf/2505.09794", "abs": "https://arxiv.org/abs/2505.09794", "authors": ["J. Moreno-Casanova", "J. M. Auñón", "A. Mártinez-Pérez", "M. E. Pérez-Martínez", "M. E. Gas-López"], "title": "Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Research projects, including those focused on cancer, rely on the manual\nextraction of information from clinical reports. This process is time-consuming\nand prone to errors, limiting the efficiency of data-driven approaches in\nhealthcare. To address these challenges, Natural Language Processing (NLP)\noffers an alternative for automating the extraction of relevant data from\nelectronic health records (EHRs). In this study, we focus on lung and breast\ncancer due to their high incidence and the significant impact they have on\npublic health. Early detection and effective data management in both types of\ncancer are crucial for improving patient outcomes. To enhance the accuracy and\nefficiency of data extraction, we utilized GMV's NLP tool uQuery, which excels\nat identifying relevant entities in clinical texts and converting them into\nstandardized formats such as SNOMED and OMOP. uQuery not only detects and\nclassifies entities but also associates them with contextual information,\nincluding negated entities, temporal aspects, and patient-related details. In\nthis work, we explore the use of NLP techniques, specifically Named Entity\nRecognition (NER), to automatically identify and extract key clinical\ninformation from EHRs related to these two cancers. A dataset from Health\nResearch Institute Hospital La Fe (IIS La Fe), comprising 200 annotated breast\ncancer and 400 lung cancer reports, was used, with eight clinical entities\nmanually labeled using the Doccano platform. To perform NER, we fine-tuned the\nbsc-bio-ehr-en3 model, a RoBERTa-based biomedical linguistic model pre-trained\nin Spanish. Fine-tuning was performed using the Transformers architecture,\nenabling accurate recognition of clinical entities in these cancer types. Our\nresults demonstrate strong overall performance, particularly in identifying\nentities like MET and PAT, although challenges remain with less frequent\nentities like EVOL."}
{"id": "2505.10125", "pdf": "https://arxiv.org/pdf/2505.10125", "abs": "https://arxiv.org/abs/2505.10125", "authors": ["Wujun Zhou", "Shu Ding", "ZeLin Li", "Wei Wang"], "title": "Enhancing the Performance of Global Model by Improving the Adaptability of Local Models in Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning enables the clients to collaboratively train a global\nmodel, which is aggregated from local models. Due to the heterogeneous data\ndistributions over clients and data privacy in federated learning, it is\ndifficult to train local models to achieve a well-performed global model. In\nthis paper, we introduce the adaptability of local models, i.e., the average\nperformance of local models on data distributions over clients, and enhance the\nperformance of the global model by improving the adaptability of local models.\nSince each client does not know the data distributions over other clients, the\nadaptability of the local model cannot be directly optimized. First, we provide\nthe property of an appropriate local model which has good adaptability on the\ndata distributions over clients. Then, we formalize the property into the local\ntraining objective with a constraint and propose a feasible solution to train\nthe local model. Extensive experiments on federated learning benchmarks\ndemonstrate that our method significantly improves the adaptability of local\nmodels and achieves a well-performed global model that consistently outperforms\nthe baseline methods."}
{"id": "2505.09921", "pdf": "https://arxiv.org/pdf/2505.09921", "abs": "https://arxiv.org/abs/2505.09921", "authors": ["Yidan Wang", "Yanan Cao", "Yubing Ren", "Fang Fang", "Zheng Lin", "Binxing Fang"], "title": "PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization", "categories": ["cs.CR", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) excel in various domains but pose inherent\nprivacy risks. Existing methods to evaluate privacy leakage in LLMs often use\nmemorized prefixes or simple instructions to extract data, both of which\nwell-alignment models can easily block. Meanwhile, Jailbreak attacks bypass LLM\nsafety mechanisms to generate harmful content, but their role in privacy\nscenarios remains underexplored. In this paper, we examine the effectiveness of\njailbreak attacks in extracting sensitive information, bridging privacy leakage\nand jailbreak attacks in LLMs. Moreover, we propose PIG, a novel framework\ntargeting Personally Identifiable Information (PII) and addressing the\nlimitations of current jailbreak methods. Specifically, PIG identifies PII\nentities and their types in privacy queries, uses in-context learning to build\na privacy context, and iteratively updates it with three gradient-based\nstrategies to elicit target PII. We evaluate PIG and existing jailbreak methods\nusing two privacy-related datasets. Experiments on four white-box and two\nblack-box LLMs show that PIG outperforms baseline methods and achieves\nstate-of-the-art (SoTA) results. The results underscore significant privacy\nrisks in LLMs, emphasizing the need for stronger safeguards. Our code is\navailble at\n\\href{https://github.com/redwyd/PrivacyJailbreak}{https://github.com/redwyd/PrivacyJailbreak}."}
{"id": "2505.10420", "pdf": "https://arxiv.org/pdf/2505.10420", "abs": "https://arxiv.org/abs/2505.10420", "authors": ["Andrei Arhire", "Radu Timofte"], "title": "Learned Lightweight Smartphone ISP with Unpaired Data", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at CVPRW 2025", "summary": "The Image Signal Processor (ISP) is a fundamental component in modern\nsmartphone cameras responsible for conversion of RAW sensor image data to RGB\nimages with a strong focus on perceptual quality. Recent work highlights the\npotential of deep learning approaches and their ability to capture details with\na quality increasingly close to that of professional cameras. A difficult and\ncostly step when developing a learned ISP is the acquisition of pixel-wise\naligned paired data that maps the raw captured by a smartphone camera sensor to\nhigh-quality reference images. In this work, we address this challenge by\nproposing a novel training method for a learnable ISP that eliminates the need\nfor direct correspondences between raw images and ground-truth data with\nmatching content. Our unpaired approach employs a multi-term loss function\nguided by adversarial training with multiple discriminators processing feature\nmaps from pre-trained networks to maintain content structure while learning\ncolor and texture characteristics from the target RGB dataset. Using\nlightweight neural network architectures suitable for mobile devices as\nbackbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm\nUltraISP datasets. Compared to paired training methods, our unpaired learning\nstrategy shows strong potential and achieves high fidelity across multiple\nevaluation metrics. The code and pre-trained models are available at\nhttps://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data ."}
{"id": "2505.09796", "pdf": "https://arxiv.org/pdf/2505.09796", "abs": "https://arxiv.org/abs/2505.09796", "authors": ["Skylar S. Gay", "Tucker Netherton", "Barbara Marquez", "Raymond Mumme", "Mary Gronberg", "Brent Parker", "Chelsea Pinnix", "Sanjay Shete", "Carlos Cardenas", "Laurence Court"], "title": "Virtual Dosimetrists: A Radiotherapy Training \"Flight Simulator\"", "categories": ["physics.med-ph", "cs.AI"], "comment": null, "summary": "Effective education in radiotherapy plan quality review requires a robust,\nregularly updated set of examples and the flexibility to demonstrate multiple\npossible planning approaches and their consequences. However, the current\nclinic-based paradigm does not support these needs. To address this, we have\ndeveloped 'Virtual Dosimetrist' models that can both generate training examples\nof suboptimal treatment plans and then allow trainees to improve the plan\nquality through simple natural language prompts, as if communicating with a\ndosimetrist. The dose generation and modification process is accurate, rapid,\nand requires only modest resources. This work is the first to combine dose\ndistribution prediction with natural language processing; providing a robust\npipeline for both generating suboptimal training plans and allowing trainees to\npractice their critical plan review and improvement skills that addresses the\nchallenges of the current clinic-based paradigm."}
{"id": "2505.10128", "pdf": "https://arxiv.org/pdf/2505.10128", "abs": "https://arxiv.org/abs/2505.10128", "authors": ["Huy Q. Le", "Latif U. Khan", "Choong Seon Hong"], "title": "Robust Federated Learning on Edge Devices with Domain Heterogeneity", "categories": ["cs.LG", "cs.AI"], "comment": "IWCMC 2025", "summary": "Federated Learning (FL) allows collaborative training while ensuring data\nprivacy across distributed edge devices, making it a popular solution for\nprivacy-sensitive applications. However, FL faces significant challenges due to\nstatistical heterogeneity, particularly domain heterogeneity, which impedes the\nglobal mode's convergence. In this study, we introduce a new framework to\naddress this challenge by improving the generalization ability of the FL global\nmodel under domain heterogeneity, using prototype augmentation. Specifically,\nwe introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a\nprototype-based FL framework designed to enhance feature diversity and model\nrobustness. FedAPC leverages prototypes derived from the mean features of\naugmented data to capture richer representations. By aligning local features\nwith global prototypes, we enable the model to learn meaningful semantic\nfeatures while reducing overfitting to any specific domain. Experimental\nresults on the Office-10 and Digits datasets illustrate that our framework\noutperforms SOTA baselines, demonstrating superior performance."}
{"id": "2505.09949", "pdf": "https://arxiv.org/pdf/2505.09949", "abs": "https://arxiv.org/abs/2505.09949", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Samgyu Yang", "Abdulrahman Faden"], "title": "Advanced Crash Causation Analysis for Freeway Safety: A Large Language Model Approach to Identifying Key Contributing Factors", "categories": ["cs.LG", "cs.CL", "stat.AP"], "comment": null, "summary": "Understanding the factors contributing to traffic crashes and developing\nstrategies to mitigate their severity is essential. Traditional statistical\nmethods and machine learning models often struggle to capture the complex\ninteractions between various factors and the unique characteristics of each\ncrash. This research leverages large language model (LLM) to analyze freeway\ncrash data and provide crash causation analysis accordingly. By compiling 226\ntraffic safety studies related to freeway crashes, a training dataset\nencompassing environmental, driver, traffic, and geometric design factors was\ncreated. The Llama3 8B model was fine-tuned using QLoRA to enhance its\nunderstanding of freeway crashes and their contributing factors, as covered in\nthese studies. The fine-tuned Llama3 8B model was then used to identify crash\ncausation without pre-labeled data through zero-shot classification, providing\ncomprehensive explanations to ensure that the identified causes were reasonable\nand aligned with existing research. Results demonstrate that LLMs effectively\nidentify primary crash causes such as alcohol-impaired driving, speeding,\naggressive driving, and driver inattention. Incorporating event data, such as\nroad maintenance, offers more profound insights. The model's practical\napplicability and potential to improve traffic safety measures were validated\nby a high level of agreement among researchers in the field of traffic safety,\nas reflected in questionnaire results with 88.89%. This research highlights the\ncomplex nature of traffic crashes and how LLMs can be used for comprehensive\nanalysis of crash causation and other contributing factors. Moreover, it\nprovides valuable insights and potential countermeasures to aid planners and\npolicymakers in developing more effective and efficient traffic safety\npractices."}
{"id": "2505.10453", "pdf": "https://arxiv.org/pdf/2505.10453", "abs": "https://arxiv.org/abs/2505.10453", "authors": ["Tyler Tran", "Sangeet Khemlani", "J. G. Trafton"], "title": "Vision language models have difficulty recognizing virtual objects", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision language models (VLMs) are AI systems paired with both language and\nvision encoders to process multimodal input. They are capable of performing\ncomplex semantic tasks such as automatic captioning, but it remains an open\nquestion about how well they comprehend the visuospatial properties of scenes\ndepicted in the images they process. We argue that descriptions of virtual\nobjects -- objects that are not visually represented in an image -- can help\ntest scene comprehension in these AI systems. For example, an image that\ndepicts a person standing under a tree can be paired with the following prompt:\nimagine that a kite is stuck in the tree. VLMs that comprehend the scene should\nupdate their representations and reason sensibly about the spatial relations\nbetween all three objects. We describe systematic evaluations of\nstate-of-the-art VLMs and show that their ability to process virtual objects is\ninadequate."}
{"id": "2505.09805", "pdf": "https://arxiv.org/pdf/2505.09805", "abs": "https://arxiv.org/abs/2505.09805", "authors": ["Aditya Nagori", "Ayush Gautam", "Matthew O. Wiens", "Vuong Nguyen", "Nathan Kenya Mugisha", "Jerome Kabakyenga", "Niranjan Kissoon", "John Mark Ansermino", "Rishikesan Kamaleswaran"], "title": "Contextual Phenotyping of Pediatric Sepsis Cohort Using Large Language Models", "categories": ["q-bio.QM", "cs.AI", "cs.LG", "stat.AP"], "comment": "11 pages, 2 Figures, 1 Table", "summary": "Clustering patient subgroups is essential for personalized care and efficient\nresource use. Traditional clustering methods struggle with high-dimensional,\nheterogeneous healthcare data and lack contextual understanding. This study\nevaluates Large Language Model (LLM) based clustering against classical methods\nusing a pediatric sepsis dataset from a low-income country (LIC), containing\n2,686 records with 28 numerical and 119 categorical variables. Patient records\nwere serialized into text with and without a clustering objective. Embeddings\nwere generated using quantized LLAMA 3.1 8B, DeepSeek-R1-Distill-Llama-8B with\nlow-rank adaptation(LoRA), and Stella-En-400M-V5 models. K-means clustering was\napplied to these embeddings. Classical comparisons included K-Medoids\nclustering on UMAP and FAMD-reduced mixed data. Silhouette scores and\nstatistical tests evaluated cluster quality and distinctiveness.\nStella-En-400M-V5 achieved the highest Silhouette Score (0.86). LLAMA 3.1 8B\nwith the clustering objective performed better with higher number of clusters,\nidentifying subgroups with distinct nutritional, clinical, and socioeconomic\nprofiles. LLM-based methods outperformed classical techniques by capturing\nricher context and prioritizing key features. These results highlight potential\nof LLMs for contextual phenotyping and informed decision-making in\nresource-limited settings."}
{"id": "2505.10147", "pdf": "https://arxiv.org/pdf/2505.10147", "abs": "https://arxiv.org/abs/2505.10147", "authors": ["Yash", "Nikhil Karamchandani", "Avishek Ghosh"], "title": "Near Optimal Best Arm Identification for Clustered Bandits", "categories": ["cs.LG", "cs.MA"], "comment": "To be published in ICML 2025", "summary": "This work investigates the problem of best arm identification for multi-agent\nmulti-armed bandits. We consider $N$ agents grouped into $M$ clusters, where\neach cluster solves a stochastic bandit problem. The mapping between agents and\nbandits is a priori unknown. Each bandit is associated with $K$ arms, and the\ngoal is to identify the best arm for each agent under a $\\delta$-probably\ncorrect ($\\delta$-PC) framework, while minimizing sample complexity and\ncommunication overhead.\n  We propose two novel algorithms: Clustering then Best Arm Identification\n(Cl-BAI) and Best Arm Identification then Clustering (BAI-Cl). Cl-BAI uses a\ntwo-phase approach that first clusters agents based on the bandit problems they\nare learning, followed by identifying the best arm for each cluster. BAI-Cl\nreverses the sequence by identifying the best arms first and then clustering\nagents accordingly. Both algorithms leverage the successive elimination\nframework to ensure computational efficiency and high accuracy.\n  We establish $\\delta$-PC guarantees for both methods, derive bounds on their\nsample complexity, and provide a lower bound for this problem class. Moreover,\nwhen $M$ is small (a constant), we show that the sample complexity of a variant\nof BAI-Cl is minimax optimal in an order-wise sense. Experiments on synthetic\nand real-world datasets (MovieLens, Yelp) demonstrate the superior performance\nof the proposed algorithms in terms of sample and communication efficiency,\nparticularly in settings where $M \\ll N$."}
{"id": "2505.10093", "pdf": "https://arxiv.org/pdf/2505.10093", "abs": "https://arxiv.org/abs/2505.10093", "authors": ["Hsuan-Lei Shao"], "title": "From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI", "categories": ["cs.AI", "cs.CL", "I.2.4; H.3.3; J.5"], "comment": "4 pages, 4 figures", "summary": "Taiwanese China Studies (CS) has developed into a rich, interdisciplinary\nresearch field shaped by the unique geopolitical position and long standing\nacademic engagement with Mainland China. This study responds to the growing\nneed to systematically revisit and reorganize decades of Taiwan based CS\nscholarship by proposing an AI assisted approach that transforms unstructured\nacademic texts into structured, interactive knowledge representations. We apply\ngenerative AI (GAI) techniques and large language models (LLMs) to extract and\nstandardize entity relation triples from 1,367 peer reviewed CS articles\npublished between 1996 and 2019. These triples are then visualized through a\nlightweight D3.js based system, forming the foundation of a domain specific\nknowledge graph and vector database for the field. This infrastructure allows\nusers to explore conceptual nodes and semantic relationships across the corpus,\nrevealing previously uncharted intellectual trajectories, thematic clusters,\nand research gaps. By decomposing textual content into graph structured\nknowledge units, our system enables a paradigm shift from linear text\nconsumption to network based knowledge navigation. In doing so, it enhances\nscholarly access to CS literature while offering a scalable, data driven\nalternative to traditional ontology construction. This work not only\ndemonstrates how generative AI can augment area studies and digital humanities\nbut also highlights its potential to support a reimagined scholarly\ninfrastructure for regional knowledge systems."}
{"id": "2505.10473", "pdf": "https://arxiv.org/pdf/2505.10473", "abs": "https://arxiv.org/abs/2505.10473", "authors": ["Fengdi Zhang", "Hongkun Cao", "Ruqi Huang"], "title": "Consistent Quantity-Quality Control across Scenes for Deployment-Aware Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "To reduce storage and computational costs, 3D Gaussian splatting (3DGS) seeks\nto minimize the number of Gaussians used while preserving high rendering\nquality, introducing an inherent trade-off between Gaussian quantity and\nrendering quality. Existing methods strive for better quantity-quality\nperformance, but lack the ability for users to intuitively adjust this\ntrade-off to suit practical needs such as model deployment under diverse\nhardware and communication constraints. Here, we present ControlGS, a 3DGS\noptimization method that achieves semantically meaningful and cross-scene\nconsistent quantity-quality control while maintaining strong quantity-quality\nperformance. Through a single training run using a fixed setup and a\nuser-specified hyperparameter reflecting quantity-quality preference, ControlGS\ncan automatically find desirable quantity-quality trade-off points across\ndiverse scenes, from compact objects to large outdoor scenes. It also\noutperforms baselines by achieving higher rendering quality with fewer\nGaussians, and supports a broad adjustment range with stepless control over the\ntrade-off."}
{"id": "2505.09807", "pdf": "https://arxiv.org/pdf/2505.09807", "abs": "https://arxiv.org/abs/2505.09807", "authors": ["Timour Ichmoukhamedov", "David Martens"], "title": "Exploring the generalization of LLM truth directions on conversational formats", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Several recent works argue that LLMs have a universal truth direction where\ntrue and false statements are linearly separable in the activation space of the\nmodel. It has been demonstrated that linear probes trained on a single hidden\nstate of the model already generalize across a range of topics and might even\nbe used for lie detection in LLM conversations. In this work we explore how\nthis truth direction generalizes between various conversational formats. We\nfind good generalization between short conversations that end on a lie, but\npoor generalization to longer formats where the lie appears earlier in the\ninput prompt. We propose a solution that significantly improves this type of\ngeneralization by adding a fixed key phrase at the end of each conversation.\nOur results highlight the challenges towards reliable LLM lie detectors that\ngeneralize to new settings."}
{"id": "2505.10167", "pdf": "https://arxiv.org/pdf/2505.10167", "abs": "https://arxiv.org/abs/2505.10167", "authors": ["Saikat Barua", "Mostafizur Rahman", "Shehenaz Khaled", "Md Jafor Sadek", "Rafiul Islam", "Shahnewaz Siddique"], "title": "QuXAI: Explainers for Hybrid Quantum Machine Learning Models", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": "16 pages, 6 figures, 7 equations", "summary": "The emergence of hybrid quantum-classical machine learning (HQML) models\nopens new horizons of computational intelligence but their fundamental\ncomplexity frequently leads to black box behavior that undermines transparency\nand reliability in their application. Although XAI for quantum systems still in\nits infancy, a major research gap is evident in robust global and local\nexplainability approaches that are designed for HQML architectures that employ\nquantized feature encoding followed by classical learning. The gap is the focus\nof this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an\nexplainer for explaining feature importance in these hybrid systems. Our model\nentails the creation of HQML models incorporating quantum feature maps, the use\nof Q-MEDLEY, which combines feature based inferences, preserving the quantum\ntransformation stage and visualizing the resulting attributions. Our result\nshows that Q-MEDLEY delineates influential classical aspects in HQML models, as\nwell as separates their noise, and competes well against established XAI\ntechniques in classical validation settings. Ablation studies more\nsignificantly expose the virtues of the composite structure used in Q-MEDLEY.\nThe implications of this work are critically important, as it provides a route\nto improve the interpretability and reliability of HQML models, thus promoting\ngreater confidence and being able to engage in safer and more responsible use\nof quantum-enhanced AI technology."}
{"id": "2505.10117", "pdf": "https://arxiv.org/pdf/2505.10117", "abs": "https://arxiv.org/abs/2505.10117", "authors": ["JieHao Wu", "Ziwei Wang", "Junjie Sheng", "Wenhao Li", "Xiangfei Wang", "Jun Luo"], "title": "Learning Virtual Machine Scheduling in Cloud Computing through Language Agents", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "In cloud services, virtual machine (VM) scheduling is a typical Online\nDynamic Multidimensional Bin Packing (ODMBP) problem, characterized by\nlarge-scale complexity and fluctuating demands. Traditional optimization\nmethods struggle to adapt to real-time changes, domain-expert-designed\nheuristic approaches suffer from rigid strategies, and existing learning-based\nmethods often lack generalizability and interpretability. To address these\nlimitations, this paper proposes a hierarchical language agent framework named\nMiCo, which provides a large language model (LLM)-driven heuristic design\nparadigm for solving ODMBP. Specifically, ODMBP is formulated as a Semi-Markov\nDecision Process with Options (SMDP-Option), enabling dynamic scheduling\nthrough a two-stage architecture, i.e., Option Miner and Option Composer.\nOption Miner utilizes LLMs to discover diverse and useful non-context-aware\nstrategies by interacting with constructed environments. Option Composer\nemploys LLMs to discover a composing strategy that integrates the\nnon-context-aware strategies with the contextual ones. Extensive experiments on\nreal-world enterprise datasets demonstrate that MiCo achieves a 96.9\\%\ncompetitive ratio in large-scale scenarios involving more than 10,000 virtual\nmachines. It maintains high performance even under nonstationary request flows\nand diverse configurations, thus validating its effectiveness in complex and\nlarge-scale cloud environments."}
{"id": "2505.10481", "pdf": "https://arxiv.org/pdf/2505.10481", "abs": "https://arxiv.org/abs/2505.10481", "authors": ["Ilya Ovodov", "Petr Surovtsev", "Karina Kvanchiani", "Alexander Kapitanov", "Alexander Nagaev"], "title": "Logos as a Well-Tempered Pre-train for Sign Language Recognition", "categories": ["cs.CV"], "comment": null, "summary": "This paper examines two aspects of the isolated sign language recognition\n(ISLR) task. First, despite the availability of a number of datasets, the\namount of data for most individual sign languages is limited. It poses the\nchallenge of cross-language ISLR model training, including transfer learning.\nSecond, similar signs can have different semantic meanings. It leads to\nambiguity in dataset labeling and raises the question of the best policy for\nannotating such signs. To address these issues, this study presents Logos, a\nnovel Russian Sign Language (RSL) dataset, the most extensive ISLR dataset by\nthe number of signers and one of the largest available datasets while also the\nlargest RSL dataset in size and vocabulary. It is shown that a model,\npre-trained on the Logos dataset can be used as a universal encoder for other\nlanguage SLR tasks, including few-shot learning. We explore cross-language\ntransfer learning approaches and find that joint training using multiple\nclassification heads benefits accuracy for the target lowresource datasets the\nmost. The key feature of the Logos dataset is explicitly annotated visually\nsimilar sign groups. We show that explicitly labeling visually similar signs\nimproves trained model quality as a visual encoder for downstream tasks. Based\non the proposed contributions, we outperform current state-of-the-art results\nfor the WLASL dataset and get competitive results for the AUTSL dataset, with a\nsingle stream model processing solely RGB video. The source code, dataset, and\npre-trained models are publicly available."}
{"id": "2505.09814", "pdf": "https://arxiv.org/pdf/2505.09814", "abs": "https://arxiv.org/abs/2505.09814", "authors": ["Dmitry Rybin", "Yushun Zhang", "Zhi-Quan Luo"], "title": "$XX^{t}$ Can Be Faster", "categories": ["cs.DS", "cs.AI", "cs.LG", "cs.SC", "68Q25, 68T20", "F.2.1; I.1.2"], "comment": null, "summary": "We present a new algorithm RXTX that computes product of matrix by its\ntranspose $XX^{t}$. RXTX uses $5\\%$ less multiplications and additions than\nState-of-the-Art and achieves accelerations even for small sizes of matrix $X$.\nThe algorithm was discovered by combining Machine Learning-based search methods\nwith Combinatorial Optimization."}
{"id": "2505.10172", "pdf": "https://arxiv.org/pdf/2505.10172", "abs": "https://arxiv.org/abs/2505.10172", "authors": ["Zeyan Li", "Libing Chen", "Yin Tang"], "title": "Does Scaling Law Apply in Time Series Forecasting?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Rapid expansion of model size has emerged as a key challenge in time series\nforecasting. From early Transformer with tens of megabytes to recent\narchitectures like TimesNet with thousands of megabytes, performance gains have\noften come at the cost of exponentially increasing parameter counts. But is\nthis scaling truly necessary? To question the applicability of the scaling law\nin time series forecasting, we propose Alinear, an ultra-lightweight\nforecasting model that achieves competitive performance using only k-level\nparameters. We introduce a horizon-aware adaptive decomposition mechanism that\ndynamically rebalances component emphasis across different forecast lengths,\nalongside a progressive frequency attenuation strategy that achieves stable\nprediction in various forecasting horizons without incurring the computational\noverhead of attention mechanisms. Extensive experiments on seven benchmark\ndatasets demonstrate that Alinear consistently outperforms large-scale models\nwhile using less than 1% of their parameters, maintaining strong accuracy\nacross both short and ultra-long forecasting horizons. Moreover, to more fairly\nevaluate model efficiency, we propose a new parameter-aware evaluation metric\nthat highlights the superiority of ALinear under constrained model budgets. Our\nanalysis reveals that the relative importance of trend and seasonal components\nvaries depending on data characteristics rather than following a fixed pattern,\nvalidating the necessity of our adaptive design. This work challenges the\nprevailing belief that larger models are inherently better and suggests a\nparadigm shift toward more efficient time series modeling."}
{"id": "2505.10118", "pdf": "https://arxiv.org/pdf/2505.10118", "abs": "https://arxiv.org/abs/2505.10118", "authors": ["Yangfu Li", "Hongjian Zhan", "Tianyi Chen", "Qi Liu", "Yue Lu"], "title": "Why 1 + 1 < 1 in Visual Token Pruning: Beyond Naive Integration via Multi-Objective Balanced Covering", "categories": ["cs.CV", "cs.CL"], "comment": "31 pages,9 figures,conference", "summary": "Existing visual token pruning methods target prompt alignment and visual\npreservation with static strategies, overlooking the varying relative\nimportance of these objectives across tasks, which leads to inconsistent\nperformance. To address this, we derive the first closed-form error bound for\nvisual token pruning based on the Hausdorff distance, uniformly characterizing\nthe contributions of both objectives. Moreover, leveraging $\\epsilon$-covering\ntheory, we reveal an intrinsic trade-off between these objectives and quantify\ntheir optimal attainment levels under a fixed budget. To practically handle\nthis trade-off, we propose Multi-Objective Balanced Covering (MoB), which\nreformulates visual token pruning as a bi-objective covering problem. In this\nframework, the attainment trade-off reduces to budget allocation via greedy\nradius trading. MoB offers a provable performance bound and linear scalability\nwith respect to the number of input visual tokens, enabling adaptation to\nchallenging pruning scenarios. Extensive experiments show that MoB preserves\n96.4% of performance for LLaVA-1.5-7B using only 11.1% of the original visual\ntokens and accelerates LLaVA-Next-7B by 1.3-1.5$\\times$ with negligible\nperformance loss. Additionally, evaluations on Qwen2-VL and Video-LLaVA confirm\nthat MoB integrates seamlessly into advanced MLLMs and diverse vision-language\ntasks."}
{"id": "2505.10483", "pdf": "https://arxiv.org/pdf/2505.10483", "abs": "https://arxiv.org/abs/2505.10483", "authors": ["Yi Li", "Haonan Wang", "Qixiang Zhang", "Boyu Xiao", "Chenchang Hu", "Hualiang Wang", "Xiaomeng Li"], "title": "UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation", "categories": ["cs.CV", "cs.AI"], "comment": "UniEval is the first evaluation framework designed for unified\n  multimodal models, including a holistic benchmark UniBench and the UniScore\n  metric", "summary": "The emergence of unified multimodal understanding and generation models is\nrapidly attracting attention because of their ability to enhance\ninstruction-following capabilities while minimizing model redundancy. However,\nthere is a lack of a unified evaluation framework for these models, which would\nenable an elegant, simplified, and overall evaluation. Current models conduct\nevaluations on multiple task-specific benchmarks, but there are significant\nlimitations, such as the lack of overall results, errors from extra evaluation\nmodels, reliance on extensive labeled images, benchmarks that lack diversity,\nand metrics with limited capacity for instruction-following evaluation. To\ntackle these challenges, we introduce UniEval, the first evaluation framework\ndesigned for unified multimodal models without extra models, images, or\nannotations. This facilitates a simplified and unified evaluation process. The\nUniEval framework contains a holistic benchmark, UniBench (supports both\nunified and visual generation models), along with the corresponding UniScore\nmetric. UniBench includes 81 fine-grained tags contributing to high diversity.\nExperimental results indicate that UniBench is more challenging than existing\nbenchmarks, and UniScore aligns closely with human evaluations, surpassing\ncurrent metrics. Moreover, we extensively evaluated SoTA unified and visual\ngeneration models, uncovering new insights into Univeral's unique values."}
{"id": "2505.09830", "pdf": "https://arxiv.org/pdf/2505.09830", "abs": "https://arxiv.org/abs/2505.09830", "authors": ["Martín Rodríguez", "Gustavo Rossi", "Alejandro Fernandez"], "title": "Evaluating Large Language Models for the Generation of Unit Tests with Equivalence Partitions and Boundary Values", "categories": ["cs.SE", "cs.AI"], "comment": "Under revision at Jornadas de Cloud Computing, Big Data & Emerging\n  Topics (JCC-BD&ET) - 2025", "summary": "The design and implementation of unit tests is a complex task many\nprogrammers neglect. This research evaluates the potential of Large Language\nModels (LLMs) in automatically generating test cases, comparing them with\nmanual tests. An optimized prompt was developed, that integrates code and\nrequirements, covering critical cases such as equivalence partitions and\nboundary values. The strengths and weaknesses of LLMs versus trained\nprogrammers were compared through quantitative metrics and manual qualitative\nanalysis. The results show that the effectiveness of LLMs depends on\nwell-designed prompts, robust implementation, and precise requirements.\nAlthough flexible and promising, LLMs still require human supervision. This\nwork highlights the importance of manual qualitative analysis as an essential\ncomplement to automation in unit test evaluation."}
{"id": "2505.10192", "pdf": "https://arxiv.org/pdf/2505.10192", "abs": "https://arxiv.org/abs/2505.10192", "authors": ["Prashant P. Shinde", "Priyadarshini P. Pai", "Shashishekar P. Adiga", "K. Subramanya Mayya", "Yongbeom Seo", "Myungsoo Hwang", "Heeyoung Go", "Changmin Park"], "title": "Defect Detection in Photolithographic Patterns Using Deep Learning Models Trained on Synthetic Data", "categories": ["cs.LG"], "comment": null, "summary": "In the photolithographic process vital to semiconductor manufacturing,\nvarious types of defects appear during EUV pattering. Due to ever-shrinking\npattern size, these defects are extremely small and cause false or missed\ndetection during inspection. Specifically, the lack of defect-annotated quality\ndata with good representation of smaller defects has prohibited deployment of\ndeep learning based defect detection models in fabrication lines. To resolve\nthe problem of data unavailability, we artificially generate scanning electron\nmicroscopy (SEM) images of line patterns with known distribution of defects and\nautonomously annotate them. We then employ state-of-the-art object detection\nmodels to investigate defect detection performance as a function of defect\nsize, much smaller than the pitch width. We find that the real-time object\ndetector YOLOv8 has the best mean average precision of 96% as compared to\nEfficientNet, 83%, and SSD, 77%, with the ability to detect smaller defects. We\nreport the smallest defect size that can be detected reliably. When tested on\nreal SEM data, the YOLOv8 model correctly detected 84.6% of Bridge defects and\n78.3% of Break defects across all relevant instances. These promising results\nsuggest that synthetic data can be used as an alternative to real-world data in\norder to develop robust machine-learning models."}
{"id": "2505.10222", "pdf": "https://arxiv.org/pdf/2505.10222", "abs": "https://arxiv.org/abs/2505.10222", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "Beiwen Zhang", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "ComplexFormer: Disruptively Advancing Transformer Inference Ability via Head-Specific Complex Vector Attention", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Transformer models rely on self-attention to capture token dependencies but\nface challenges in effectively integrating positional information while\nallowing multi-head attention (MHA) flexibility. Prior methods often model\nsemantic and positional differences disparately or apply uniform positional\nadjustments across heads, potentially limiting representational capacity. This\npaper introduces ComplexFormer, featuring Complex Multi-Head Attention-CMHA.\nCMHA empowers each head to independently model semantic and positional\ndifferences unified within the complex plane, representing interactions as\nrotations and scaling. ComplexFormer incorporates two key improvements: (1) a\nper-head Euler transformation, converting real-valued query/key projections\ninto polar-form complex vectors for head-specific complex subspace operation;\nand (2) a per-head adaptive differential rotation mechanism,\nexp[i(Adapt(ASmn,i) + Delta(Pmn),i)], allowing each head to learn distinct\nstrategies for integrating semantic angle differences (ASmn,i) with relative\npositional encodings (Delta(Pmn),i). Extensive experiments on language\nmodeling, text generation, code generation, and mathematical reasoning show\nComplexFormer achieves superior performance, significantly lower generation\nperplexity , and improved long-context coherence compared to strong baselines\nlike RoPE-Transformers. ComplexFormer demonstrates strong parameter efficiency,\noffering a more expressive, adaptable attention mechanism."}
{"id": "2505.10496", "pdf": "https://arxiv.org/pdf/2505.10496", "abs": "https://arxiv.org/abs/2505.10496", "authors": ["Raman Dutt", "Pedro Sanchez", "Yongchen Yao", "Steven McDonagh", "Sotirios A. Tsaftaris", "Timothy Hospedales"], "title": "CheXGenBench: A Unified Benchmark For Fidelity, Privacy and Utility of Synthetic Chest Radiographs", "categories": ["cs.CV"], "comment": null, "summary": "We introduce CheXGenBench, a rigorous and multifaceted evaluation framework\nfor synthetic chest radiograph generation that simultaneously assesses\nfidelity, privacy risks, and clinical utility across state-of-the-art\ntext-to-image generative models. Despite rapid advancements in generative AI\nfor real-world imagery, medical domain evaluations have been hindered by\nmethodological inconsistencies, outdated architectural comparisons, and\ndisconnected assessment criteria that rarely address the practical clinical\nvalue of synthetic samples. CheXGenBench overcomes these limitations through\nstandardised data partitioning and a unified evaluation protocol comprising\nover 20 quantitative metrics that systematically analyse generation quality,\npotential privacy vulnerabilities, and downstream clinical applicability across\n11 leading text-to-image architectures. Our results reveal critical\ninefficiencies in the existing evaluation protocols, particularly in assessing\ngenerative fidelity, leading to inconsistent and uninformative comparisons. Our\nframework establishes a standardised benchmark for the medical AI community,\nenabling objective and reproducible comparisons while facilitating seamless\nintegration of both existing and future generative models. Additionally, we\nrelease a high-quality, synthetic dataset, SynthCheX-75K, comprising 75K\nradiographs generated by the top-performing model (Sana 0.6B) in our benchmark\nto support further research in this critical domain. Through CheXGenBench, we\nestablish a new state-of-the-art and release our framework, models, and\nSynthCheX-75K dataset at https://raman1121.github.io/CheXGenBench/"}
{"id": "2505.09847", "pdf": "https://arxiv.org/pdf/2505.09847", "abs": "https://arxiv.org/abs/2505.09847", "authors": ["Liyang Zhao", "Olurotimi Seton", "Himadeep Reddy Reddivari", "Suvendu Jena", "Shadow Zhao", "Rachit Kumar", "Changshuai Wei"], "title": "Causal Predictive Optimization and Generation for Business AI", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "comment": null, "summary": "The sales process involves sales functions converting leads or opportunities\nto customers and selling more products to existing customers. The optimization\nof the sales process thus is key to success of any B2B business. In this work,\nwe introduce a principled approach to sales optimization and business AI,\nnamely the Causal Predictive Optimization and Generation, which includes three\nlayers: 1) prediction layer with causal ML 2) optimization layer with\nconstraint optimization and contextual bandit 3) serving layer with Generative\nAI and feedback-loop for system enhancement. We detail the implementation and\ndeployment of the system in LinkedIn, showcasing significant wins over legacy\nsystems and sharing learning and insight broadly applicable to this field."}
{"id": "2505.10198", "pdf": "https://arxiv.org/pdf/2505.10198", "abs": "https://arxiv.org/abs/2505.10198", "authors": ["Mariano Ferrero", "José Omar Chelotti", "Luciano Sebastián Martinez-Rau", "Leandro Vignolo", "Martín Pires", "Julio Ricardo Galli", "Leonardo Luis Giovanini", "Hugo Leonardo Rufiner"], "title": "A multi-head deep fusion model for recognition of cattle foraging events using sound and movement signals", "categories": ["cs.LG"], "comment": "Preprint submitted to Engineering Applications of Artificial\n  Intelligence", "summary": "Monitoring feeding behaviour is a relevant task for efficient herd management\nand the effective use of available resources in grazing cattle. The ability to\nautomatically recognise animals' feeding activities through the identification\nof specific jaw movements allows for the improvement of diet formulation, as\nwell as early detection of metabolic problems and symptoms of animal\ndiscomfort, among other benefits. The use of sensors to obtain signals for such\nmonitoring has become popular in the last two decades. The most frequently\nemployed sensors include accelerometers, microphones, and cameras, each with\nits own set of advantages and drawbacks. An unexplored aspect is the\nsimultaneous use of multiple sensors with the aim of combining signals in order\nto enhance the precision of the estimations. In this direction, this work\nintroduces a deep neural network based on the fusion of acoustic and inertial\nsignals, composed of convolutional, recurrent, and dense layers. The main\nadvantage of this model is the combination of signals through the automatic\nextraction of features independently from each of them. The model has emerged\nfrom an exploration and comparison of different neural network architectures\nproposed in this work, which carry out information fusion at different levels.\nFeature-level fusion has outperformed data and decision-level fusion by at\nleast a 0.14 based on the F1-score metric. Moreover, a comparison with\nstate-of-the-art machine learning methods is presented, including traditional\nand deep learning approaches. The proposed model yielded an F1-score value of\n0.802, representing a 14% increase compared to previous methods. Finally,\nresults from an ablation study and post-training quantization evaluation are\nalso reported."}
{"id": "2505.10231", "pdf": "https://arxiv.org/pdf/2505.10231", "abs": "https://arxiv.org/abs/2505.10231", "authors": ["Haozhe Luo", "Ziyu Zhou", "Zixin Shu", "Aurélie Pahud de Mortanges", "Robert Berke", "Mauricio Reyes"], "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner."}
{"id": "2505.10497", "pdf": "https://arxiv.org/pdf/2505.10497", "abs": "https://arxiv.org/abs/2505.10497", "authors": ["Iurii Medvedev", "Nuno Goncalves"], "title": "MorphGuard: Morph Specific Margin Loss for Enhancing Robustness to Face Morphing Attacks", "categories": ["cs.CV"], "comment": null, "summary": "Face recognition has evolved significantly with the advancement of deep\nlearning techniques, enabling its widespread adoption in various applications\nrequiring secure authentication. However, this progress has also increased its\nexposure to presentation attacks, including face morphing, which poses a\nserious security threat by allowing one identity to impersonate another.\nTherefore, modern face recognition systems must be robust against such attacks.\n  In this work, we propose a novel approach for training deep networks for face\nrecognition with enhanced robustness to face morphing attacks. Our method\nmodifies the classification task by introducing a dual-branch classification\nstrategy that effectively handles the ambiguity in the labeling of face morphs.\nThis adaptation allows the model to incorporate morph images into the training\nprocess, improving its ability to distinguish them from bona fide samples.\n  Our strategy has been validated on public benchmarks, demonstrating its\neffectiveness in enhancing robustness against face morphing attacks.\nFurthermore, our approach is universally applicable and can be integrated into\nexisting face recognition training pipelines to improve classification-based\nrecognition methods."}
{"id": "2505.09852", "pdf": "https://arxiv.org/pdf/2505.09852", "abs": "https://arxiv.org/abs/2505.09852", "authors": ["Apollinaire Poli Nemkova", "Sarath Chandra Lingareddy", "Sagnik Ray Choudhury", "Mark V. Albert"], "title": "Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance across natural\nlanguage tasks, but their ability to forecast violent conflict remains\nunderexplored. We investigate whether LLMs possess meaningful parametric\nknowledge-encoded in their pretrained weights-to predict conflict escalation\nand fatalities without external data. This is critical for early warning\nsystems, humanitarian planning, and policy-making. We compare this parametric\nknowledge with non-parametric capabilities, where LLMs access structured and\nunstructured context from conflict datasets (e.g., ACLED, GDELT) and recent\nnews reports via Retrieval-Augmented Generation (RAG). Incorporating external\ninformation could enhance model performance by providing up-to-date context\notherwise missing from pretrained weights. Our two-part evaluation framework\nspans 2020-2024 across conflict-prone regions in the Horn of Africa and the\nMiddle East. In the parametric setting, LLMs predict conflict trends and\nfatalities relying only on pretrained knowledge. In the non-parametric setting,\nmodels receive summaries of recent conflict events, indicators, and\ngeopolitical developments. We compare predicted conflict trend labels (e.g.,\nEscalate, Stable Conflict, De-escalate, Peace) and fatalities against\nhistorical data. Our findings highlight the strengths and limitations of LLMs\nfor conflict forecasting and the benefits of augmenting them with structured\nexternal knowledge."}
{"id": "2505.10213", "pdf": "https://arxiv.org/pdf/2505.10213", "abs": "https://arxiv.org/abs/2505.10213", "authors": ["Mohammadmahdi Ghasemloo", "Alireza Moradi"], "title": "Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting", "categories": ["cs.LG", "stat.AP"], "comment": null, "summary": "With the widespread adoption of Large Language Models (LLMs), there is a\ngrowing need to establish best practices for leveraging their capabilities\nbeyond traditional natural language tasks. In this paper, a novel cross-domain\nknowledge transfer framework is proposed to enhance the performance of LLMs in\ntime series forecasting -- a task of increasing relevance in fields such as\nenergy systems, finance, and healthcare. The approach systematically infuses\nLLMs with structured temporal information to improve their forecasting\naccuracy. This study evaluates the proposed method on a real-world time series\ndataset and compares it to a naive baseline where the LLM receives no auxiliary\ninformation. Results show that knowledge-informed forecasting significantly\noutperforms the uninformed baseline in terms of predictive accuracy and\ngeneralization. These findings highlight the potential of knowledge transfer\nstrategies to bridge the gap between LLMs and domain-specific forecasting\ntasks."}
{"id": "2505.10292", "pdf": "https://arxiv.org/pdf/2505.10292", "abs": "https://arxiv.org/abs/2505.10292", "authors": ["Daniel A. P. Oliveira", "David Martins de Matos"], "title": "StoryReasoning Dataset: Using Chain-of-Thought for Scene Understanding and Grounded Story Generation", "categories": ["cs.CV", "cs.CL", "I.2.10; I.2.7"], "comment": "31 pages, 14 figures", "summary": "Visual storytelling systems struggle to maintain character identity across\nframes and link actions to appropriate subjects, frequently leading to\nreferential hallucinations. These issues can be addressed through grounding of\ncharacters, objects, and other entities on the visual elements. We propose\nStoryReasoning, a dataset containing 4,178 stories derived from 52,016 movie\nimages, with both structured scene analyses and grounded stories. Each story\nmaintains character and object consistency across frames while explicitly\nmodeling multi-frame relationships through structured tabular representations.\nOur approach features cross-frame object re-identification using visual\nsimilarity and face recognition, chain-of-thought reasoning for explicit\nnarrative modeling, and a grounding scheme that links textual elements to\nvisual entities across multiple frames. We establish baseline performance by\nfine-tuning Qwen2.5-VL 7B, creating Qwen Storyteller, which performs end-to-end\nobject detection, re-identification, and landmark detection while maintaining\nconsistent object references throughout the story. Evaluation demonstrates a\nreduction from 4.06 to 3.56 (-12.3%) hallucinations on average per story when\ncompared to a non-fine-tuned model."}
{"id": "2505.10533", "pdf": "https://arxiv.org/pdf/2505.10533", "abs": "https://arxiv.org/abs/2505.10533", "authors": ["Aaryan Sharma", "Shivansh Gupta", "Samar Agarwal", "Vishak Prasad C.", "Ganesh Ramakrishnan"], "title": "Enhancing Multi-Image Question Answering via Submodular Subset Selection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Large multimodal models (LMMs) have achieved high performance in\nvision-language tasks involving single image but they struggle when presented\nwith a collection of multiple images (Multiple Image Question Answering\nscenario). These tasks, which involve reasoning over large number of images,\npresent issues in scalability (with increasing number of images) and retrieval\nperformance. In this work, we propose an enhancement for retriever framework\nintroduced in MIRAGE model using submodular subset selection techniques. Our\nmethod leverages query-aware submodular functions, such as GraphCut, to\npre-select a subset of semantically relevant images before main retrieval\ncomponent. We demonstrate that using anchor-based queries and augmenting the\ndata improves submodular-retriever pipeline effectiveness, particularly in\nlarge haystack sizes."}
{"id": "2505.09855", "pdf": "https://arxiv.org/pdf/2505.09855", "abs": "https://arxiv.org/abs/2505.09855", "authors": ["Alexander Y. Ku", "Thomas L. Griffiths", "Stephanie C. Y. Chan"], "title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies."}
{"id": "2505.10222", "pdf": "https://arxiv.org/pdf/2505.10222", "abs": "https://arxiv.org/abs/2505.10222", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "Beiwen Zhang", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "ComplexFormer: Disruptively Advancing Transformer Inference Ability via Head-Specific Complex Vector Attention", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Transformer models rely on self-attention to capture token dependencies but\nface challenges in effectively integrating positional information while\nallowing multi-head attention (MHA) flexibility. Prior methods often model\nsemantic and positional differences disparately or apply uniform positional\nadjustments across heads, potentially limiting representational capacity. This\npaper introduces ComplexFormer, featuring Complex Multi-Head Attention-CMHA.\nCMHA empowers each head to independently model semantic and positional\ndifferences unified within the complex plane, representing interactions as\nrotations and scaling. ComplexFormer incorporates two key improvements: (1) a\nper-head Euler transformation, converting real-valued query/key projections\ninto polar-form complex vectors for head-specific complex subspace operation;\nand (2) a per-head adaptive differential rotation mechanism,\nexp[i(Adapt(ASmn,i) + Delta(Pmn),i)], allowing each head to learn distinct\nstrategies for integrating semantic angle differences (ASmn,i) with relative\npositional encodings (Delta(Pmn),i). Extensive experiments on language\nmodeling, text generation, code generation, and mathematical reasoning show\nComplexFormer achieves superior performance, significantly lower generation\nperplexity , and improved long-context coherence compared to strong baselines\nlike RoPE-Transformers. ComplexFormer demonstrates strong parameter efficiency,\noffering a more expressive, adaptable attention mechanism."}
{"id": "2505.10465", "pdf": "https://arxiv.org/pdf/2505.10465", "abs": "https://arxiv.org/abs/2505.10465", "authors": ["Yizhou liu", "Ziming Liu", "Jeff Gore"], "title": "Superposition Yields Robust Neural Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages, 23 figures", "summary": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters."}
{"id": "2505.10541", "pdf": "https://arxiv.org/pdf/2505.10541", "abs": "https://arxiv.org/abs/2505.10541", "authors": ["Pengfei Wang", "Guohai Xu", "Weinong Wang", "Junjie Yang", "Jie Lou", "Yunhua Xue"], "title": "Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements have enhanced the capability of Multimodal Large Language\nModels (MLLMs) to comprehend multi-image information. However, existing\nbenchmarks primarily evaluate answer correctness, overlooking whether models\ngenuinely comprehend the visual input. To address this, we define implicit\nvisual misunderstanding (IVM), where MLLMs provide correct answers without\nfully comprehending the visual input. Through our analysis, we decouple the\nvisual and textual modalities within the causal attention module, revealing\nthat attention distribution increasingly converges on the image associated with\nthe correct answer as the network layers deepen. This insight leads to the\nintroduction of a scale-agnostic metric, \\textit{attention accuracy}, and a\nnovel benchmark for quantifying IVMs. Attention accuracy directly evaluates the\nmodel's visual understanding via internal mechanisms, remaining robust to\npositional biases for more reliable assessments. Furthermore, we extend our\napproach to finer granularities and demonstrate its effectiveness in unimodal\nscenarios, underscoring its versatility and generalizability."}
{"id": "2505.09861", "pdf": "https://arxiv.org/pdf/2505.09861", "abs": "https://arxiv.org/abs/2505.09861", "authors": ["John Bencina", "Erkut Aykutlug", "Yue Chen", "Zerui Zhang", "Stephanie Sorenson", "Shao Tang", "Changshuai Wei"], "title": "LiDDA: Data Driven Attribution at LinkedIn", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ME"], "comment": null, "summary": "Data Driven Attribution, which assigns conversion credits to marketing\ninteractions based on causal patterns learned from data, is the foundation of\nmodern marketing intelligence and vital to any marketing businesses and\nadvertising platform. In this paper, we introduce a unified transformer-based\nattribution approach that can handle member-level data, aggregate-level data,\nand integration of external macro factors. We detail the large scale\nimplementation of the approach at LinkedIn, showcasing significant impact. We\nalso share learning and insights that are broadly applicable to the marketing\nand ad tech fields."}
{"id": "2505.10259", "pdf": "https://arxiv.org/pdf/2505.10259", "abs": "https://arxiv.org/abs/2505.10259", "authors": ["Xiangwen Zhuge", "Xu Shen", "Zeyu Wang", "Fan Dang", "Xuan Ding", "Danyang Li", "Yahui Han", "Tianxiang Hao", "Zheng Yang"], "title": "SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices", "categories": ["cs.LG"], "comment": null, "summary": "Efficient LLM inference on resource-constrained devices presents significant\nchallenges in compute and memory utilization. Due to limited GPU memory,\nexisting systems offload model weights to CPU memory, incurring substantial I/O\noverhead between the CPU and GPU. This leads to two major inefficiencies: (1)\nGPU cores are underutilized, often remaining idle while waiting for data to be\nloaded; and (2) GPU memory has low impact on performance, as reducing its\ncapacity has minimal effect on overall throughput.In this paper, we propose\nSpecOffload, a high-throughput inference engine that embeds speculative\ndecoding into offloading. Our key idea is to unlock latent GPU resources for\nstoring and executing a draft model used for speculative decoding, thus\naccelerating inference at near-zero additional cost. To support this, we\ncarefully orchestrate the interleaved execution of target and draft models in\nspeculative decoding within the offloading pipeline, and propose a planner to\nmanage tensor placement and select optimal parameters. Compared to the best\nbaseline, SpecOffload improves GPU core utilization by 4.49x and boosts\ninference throughput by 2.54x. Our code is available at\nhttps://github.com/MobiSense/SpecOffload ."}
{"id": "2505.10475", "pdf": "https://arxiv.org/pdf/2505.10475", "abs": "https://arxiv.org/abs/2505.10475", "authors": ["Mouxiang Chen", "Binyuan Hui", "Zeyu Cui", "Jiaxi Yang", "Dayiheng Liu", "Jianling Sun", "Junyang Lin", "Zhongxin Liu"], "title": "Parallel Scaling Law for Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "It is commonly believed that scaling language models should commit a\nsignificant space or time cost, by increasing the parameters (parameter\nscaling) or output tokens (inference-time scaling). We introduce the third and\nmore inference-efficient scaling paradigm: increasing the model's parallel\ncomputation during both training and inference time. We apply $P$ diverse and\nlearnable transformations to the input, execute forward passes of the model in\nparallel, and dynamically aggregate the $P$ outputs. This method, namely\nparallel scaling (ParScale), scales parallel computation by reusing existing\nparameters and can be applied to any model structure, optimization procedure,\ndata, or task. We theoretically propose a new scaling law and validate it\nthrough large-scale pre-training, which shows that a model with $P$ parallel\nstreams is similar to scaling the parameters by $O(\\log P)$ while showing\nsuperior inference efficiency. For example, ParScale can use up to 22$\\times$\nless memory increase and 6$\\times$ less latency increase compared to parameter\nscaling that achieves the same performance improvement. It can also recycle an\noff-the-shelf pre-trained model into a parallelly scaled one by post-training\non a small amount of tokens, further reducing the training budget. The new\nscaling law we discovered potentially facilitates the deployment of more\npowerful models in low-resource scenarios, and provides an alternative\nperspective for the role of computation in machine learning."}
{"id": "2505.10551", "pdf": "https://arxiv.org/pdf/2505.10551", "abs": "https://arxiv.org/abs/2505.10551", "authors": ["Yiwen Liu", "Jessica Bader", "Jae Myung Kim"], "title": "Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data", "categories": ["cs.CV", "cs.AI"], "comment": "CVPRW 2025", "summary": "With the development of photorealistic diffusion models, models trained in\npart or fully on synthetic data achieve progressively better results. However,\ndiffusion models still routinely generate images that would not exist in\nreality, such as a dog floating above the ground or with unrealistic texture\nartifacts. We define the concept of feasibility as whether attributes in a\nsynthetic image could realistically exist in the real-world domain; synthetic\nimages containing attributes that violate this criterion are considered\ninfeasible. Intuitively, infeasible images are typically considered\nout-of-distribution; thus, training on such images is expected to hinder a\nmodel's ability to generalize to real-world data, and they should therefore be\nexcluded from the training set whenever possible. However, does feasibility\nreally matter? In this paper, we investigate whether enforcing feasibility is\nnecessary when generating synthetic training data for CLIP-based classifiers,\nfocusing on three target attributes: background, color, and texture. We\nintroduce VariReal, a pipeline that minimally edits a given source image to\ninclude feasible or infeasible attributes given by the textual prompt generated\nby a large language model. Our experiments show that feasibility minimally\naffects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference\nin top-1 accuracy across three fine-grained datasets. Also, the attribute\nmatters on whether the feasible/infeasible images adversarially influence the\nclassification performance. Finally, mixing feasible and infeasible images in\ntraining datasets does not significantly impact performance compared to using\npurely feasible or infeasible datasets."}
{"id": "2505.09868", "pdf": "https://arxiv.org/pdf/2505.09868", "abs": "https://arxiv.org/abs/2505.09868", "authors": ["Tin Trung Nguyen", "Jiannan Xu", "Phuong-Anh Nguyen-Le", "Jonathan Lazar", "Donald Braman", "Hal Daumé III", "Zubin Jelveh"], "title": "Which Demographic Features Are Relevant for Individual Fairness Evaluation of U.S. Recidivism Risk Assessment Tools?", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": null, "summary": "Despite its U.S. constitutional foundation, the technical ``individual\nfairness'' criterion has not been operationalized in state or federal\nstatutes/regulations. We conduct a human subjects experiment to address this\ngap, evaluating which demographic features are relevant for individual fairness\nevaluation of recidivism risk assessment (RRA) tools. Our analyses conclude\nthat the individual similarity function should consider age and sex, but it\nshould ignore race."}
{"id": "2505.10262", "pdf": "https://arxiv.org/pdf/2505.10262", "abs": "https://arxiv.org/abs/2505.10262", "authors": ["Jiaju Qi", "Lei Lei", "Thorsteinn Jonsson", "Lajos Hanzo"], "title": "Electric Bus Charging Schedules Relying on Real Data-Driven Targets Based on Hierarchical Deep Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "The charging scheduling problem of Electric Buses (EBs) is investigated based\non Deep Reinforcement Learning (DRL). A Markov Decision Process (MDP) is\nconceived, where the time horizon includes multiple charging and operating\nperiods in a day, while each period is further divided into multiple time\nsteps. To overcome the challenge of long-range multi-phase planning with sparse\nreward, we conceive Hierarchical DRL (HDRL) for decoupling the original MDP\ninto a high-level Semi-MDP (SMDP) and multiple low-level MDPs. The Hierarchical\nDouble Deep Q-Network (HDDQN)-Hindsight Experience Replay (HER) algorithm is\nproposed for simultaneously solving the decision problems arising at different\ntemporal resolutions. As a result, the high-level agent learns an effective\npolicy for prescribing the charging targets for every charging period, while\nthe low-level agent learns an optimal policy for setting the charging power of\nevery time step within a single charging period, with the aim of minimizing the\ncharging costs while meeting the charging target. It is proved that the flat\npolicy constructed by superimposing the optimal high-level policy and the\noptimal low-level policy performs as well as the optimal policy of the original\nMDP. Since jointly learning both levels of policies is challenging due to the\nnon-stationarity of the high-level agent and the sampling inefficiency of the\nlow-level agent, we divide the joint learning process into two phases and\nexploit our new HER algorithm to manipulate the experience replay buffers for\nboth levels of agents. Numerical experiments are performed with the aid of\nreal-world data to evaluate the performance of the proposed algorithm."}
{"id": "2505.10495", "pdf": "https://arxiv.org/pdf/2505.10495", "abs": "https://arxiv.org/abs/2505.10495", "authors": ["Vibha Belavadi", "Tushar Vatsa", "Dewang Sultania", "Suhas Suresha", "Ishita Verma", "Cheng Chen", "Tracy Holloway King", "Michael Friedrich"], "title": "RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs", "categories": ["cs.LG", "cs.CL"], "comment": "Proceedings of the 4th International Workshop on Knowledge-Augmented\n  Methods for Natural Language Processing", "summary": "This paper addresses fine-tuning Large Language Models (LLMs) for function\ncalling tasks when real user interaction data is unavailable. In digital\ncontent creation tools, where users express their needs through natural\nlanguage queries that must be mapped to API calls, the lack of real-world\ntask-specific data and privacy constraints for training on it necessitate\nsynthetic data generation. Existing approaches to synthetic data generation\nfall short in diversity and complexity, failing to replicate real-world data\ndistributions and leading to suboptimal performance after LLM fine-tuning. We\npresent a novel router-based architecture that leverages domain resources like\ncontent metadata and structured knowledge graphs, along with text-to-text and\nvision-to-text language models to generate high-quality synthetic training\ndata. Our architecture's flexible routing mechanism enables synthetic data\ngeneration that matches observed real-world distributions, addressing a\nfundamental limitation of traditional approaches. Evaluation on a comprehensive\nset of real user queries demonstrates significant improvements in both function\nclassification accuracy and API parameter selection. Models fine-tuned with our\nsynthetic data consistently outperform traditional approaches, establishing new\nbenchmarks for function calling tasks."}
{"id": "2505.10557", "pdf": "https://arxiv.org/pdf/2505.10557", "abs": "https://arxiv.org/abs/2505.10557", "authors": ["Ke Wang", "Junting Pan", "Linda Wei", "Aojun Zhou", "Weikang Shi", "Zimu Lu", "Han Xiao", "Yunqiao Yang", "Houxing Ren", "Mingjie Zhan", "Hongsheng Li"], "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder."}
{"id": "2505.09901", "pdf": "https://arxiv.org/pdf/2505.09901", "abs": "https://arxiv.org/abs/2505.09901", "authors": ["Ziyuan Zhang", "Darcy Wang", "Ningyuan Chen", "Rodrigo Mansur", "Vahid Sarhangian"], "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements."}
{"id": "2505.10264", "pdf": "https://arxiv.org/pdf/2505.10264", "abs": "https://arxiv.org/abs/2505.10264", "authors": ["Francesco Diana", "André Nusser", "Chuan Xu", "Giovanni Neglia"], "title": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated Learning (FL) enables collaborative training of machine learning\nmodels across distributed clients without sharing raw data, ostensibly\npreserving data privacy. Nevertheless, recent studies have revealed critical\nvulnerabilities in FL, showing that a malicious central server can manipulate\nmodel updates to reconstruct clients' private training data. Existing data\nreconstruction attacks have important limitations: they often rely on\nassumptions about the clients' data distribution or their efficiency\nsignificantly degrades when batch sizes exceed just a few tens of samples.\n  In this work, we introduce a novel data reconstruction attack that overcomes\nthese limitations. Our method leverages a new geometric perspective on fully\nconnected layers to craft malicious model parameters, enabling the perfect\nrecovery of arbitrarily large data batches in classification tasks without any\nprior knowledge of clients' data. Through extensive experiments on both image\nand tabular datasets, we demonstrate that our attack outperforms existing\nmethods and achieves perfect reconstruction of data batches two orders of\nmagnitude larger than the state of the art."}
{"id": "2505.10526", "pdf": "https://arxiv.org/pdf/2505.10526", "abs": "https://arxiv.org/abs/2505.10526", "authors": ["Mugilan Ganesan", "Shane Segal", "Ankur Aggarwal", "Nish Sinnadurai", "Sean Lie", "Vithursan Thangarasa"], "title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Main paper: 11 pp., 4 figs., 3 tabs.; Supplementary: 2 pp", "summary": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs."}
{"id": "2505.10562", "pdf": "https://arxiv.org/pdf/2505.10562", "abs": "https://arxiv.org/abs/2505.10562", "authors": ["Wenxuan Wang", "Fan Zhang", "Yufeng Cui", "Haiwen Diao", "Zhuoyan Luo", "Huchuan Lu", "Jing Liu", "Xinlong Wang"], "title": "End-to-End Vision Tokenizer Tuning", "categories": ["cs.CV"], "comment": null, "summary": "Existing vision tokenization isolates the optimization of vision tokenizers\nfrom downstream training, implicitly assuming the visual tokens can generalize\nwell across various tasks, e.g., image generation and visual question\nanswering. The vision tokenizer optimized for low-level reconstruction is\nagnostic to downstream tasks requiring varied representations and semantics.\nThis decoupled paradigm introduces a critical misalignment: The loss of the\nvision tokenization can be the representation bottleneck for target tasks. For\nexample, errors in tokenizing text in a given image lead to poor results when\nrecognizing or generating them. To address this, we propose ETT, an end-to-end\nvision tokenizer tuning approach that enables joint optimization between vision\ntokenization and target autoregressive tasks. Unlike prior autoregressive\nmodels that use only discrete indices from a frozen vision tokenizer, ETT\nleverages the visual embeddings of the tokenizer codebook, and optimizes the\nvision tokenizers end-to-end with both reconstruction and caption objectives.\nETT can be seamlessly integrated into existing training pipelines with minimal\narchitecture modifications. Our ETT is simple to implement and integrate,\nwithout the need to adjust the original codebooks or architectures of the\nemployed large language models. Extensive experiments demonstrate that our\nproposed end-to-end vision tokenizer tuning unlocks significant performance\ngains, i.e., 2-6% for multimodal understanding and visual generation tasks\ncompared to frozen tokenizer baselines, while preserving the original\nreconstruction capability. We hope this very simple and strong method can\nempower multimodal foundation models besides image generation and\nunderstanding."}
{"id": "2505.09907", "pdf": "https://arxiv.org/pdf/2505.09907", "abs": "https://arxiv.org/abs/2505.09907", "authors": ["Linwei Zhang", "LuFeng", "Ruijia Liang"], "title": "Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "With the growing demand for healthy foods, agricultural product price\nforecasting has become increasingly important. Hass avocados, as a high-value\ncrop, exhibit complex price fluctuations influenced by factors such as\nseasonality, region, and weather. Traditional prediction models often struggle\nwith highly nonlinear and dynamic data. To address this, we propose a hybrid\ndeep learning model, TCN-MLP-Attention Architecture, combining Temporal\nConvolutional Networks (TCN) for sequential feature extraction, Multi-Layer\nPerceptrons (MLP) for nonlinear interactions, and an Attention mechanism for\ndynamic feature weighting. The dataset used covers over 50,000 records of Hass\navocado sales across the U.S. from 2015 to 2018, including variables such as\nsales volume, average price, time, region, weather, and variety type, collected\nfrom point-of-sale systems and the Hass Avocado Board. After systematic\npreprocessing, including missing value imputation and feature normalization,\nthe proposed model was trained and evaluated. Experimental results demonstrate\nthat the TCN-MLP-Attention model achieves excellent predictive performance,\nwith an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods.\nThis research provides a scalable and effective approach for time series\nforecasting in agricultural markets and offers valuable insights for\nintelligent supply chain management and price strategy optimization."}
{"id": "2505.10271", "pdf": "https://arxiv.org/pdf/2505.10271", "abs": "https://arxiv.org/abs/2505.10271", "authors": ["Rafael Pablos Sarabia", "Joachim Nyborg", "Morten Birk", "Jeppe Liborius Sjørup", "Anders Lillevang Vesterholt", "Ira Assent"], "title": "RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We present a deep learning model for high-resolution probabilistic\nprecipitation forecasting over an 8-hour horizon in Europe, overcoming the\nlimitations of radar-only deep learning models with short forecast lead times.\nOur model efficiently integrates multiple data sources - including radar,\nsatellite, and physics-based numerical weather prediction (NWP) - while\ncapturing long-range interactions, resulting in accurate forecasts with robust\nuncertainty quantification through consistent probabilistic maps. Featuring a\ncompact architecture, it enables more efficient training and faster inference\nthan existing models. Extensive experiments demonstrate that our model\nsurpasses current operational NWP systems, extrapolation-based methods, and\ndeep-learning nowcasting models, setting a new standard for high-resolution\nprecipitation forecasting in Europe, ensuring a balance between accuracy,\ninterpretability, and computational efficiency."}
{"id": "2505.10543", "pdf": "https://arxiv.org/pdf/2505.10543", "abs": "https://arxiv.org/abs/2505.10543", "authors": ["Annie Wong", "Thomas Bäck", "Aske Plaat", "Niki van Stein", "Anna V. Kononova"], "title": "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While large language models demonstrate impressive performance on static\nbenchmarks, the true potential of large language models as self-learning and\nreasoning agents in dynamic environments remains unclear. This study\nsystematically evaluates the efficacy of self-reflection, heuristic mutation,\nand planning as prompting techniques to test the adaptive capabilities of\nagents. We conduct experiments with various open-source language models in\ndynamic environments and find that larger models generally outperform smaller\nones, but that strategic prompting can close this performance gap. Second, a\ntoo-long prompt can negatively impact smaller models on basic reactive tasks,\nwhile larger models show more robust behaviour. Third, advanced prompting\ntechniques primarily benefit smaller models on complex games, but offer less\nimprovement for already high-performing large language models. Yet, we find\nthat advanced reasoning methods yield highly variable outcomes: while capable\nof significantly improving performance when reasoning and decision-making\nalign, they also introduce instability and can lead to big performance drops.\nCompared to human performance, our findings reveal little evidence of true\nemergent reasoning. Instead, large language model performance exhibits\npersistent limitations in crucial areas such as planning, reasoning, and\nspatial coordination, suggesting that current-generation large language models\nstill suffer fundamental shortcomings that may not be fully overcome through\nself-reflective prompting alone. Reasoning is a multi-faceted task, and while\nreasoning methods like Chain of thought improves multi-step reasoning on math\nword problems, our findings using dynamic benchmarks highlight important\nshortcomings in general reasoning capabilities, indicating a need to move\nbeyond static benchmarks to capture the complexity of reasoning."}
{"id": "2505.10565", "pdf": "https://arxiv.org/pdf/2505.10565", "abs": "https://arxiv.org/abs/2505.10565", "authors": ["Zehan Wang", "Siyu Chen", "Lihe Yang", "Jialei Wang", "Ziang Zhang", "Hengshuang Zhao", "Zhou Zhao"], "title": "Depth Anything with Any Prior", "categories": ["cs.CV"], "comment": "Home page: https://prior-depth-anything.github.io/", "summary": "This work presents Prior Depth Anything, a framework that combines incomplete\nbut precise metric information in depth measurement with relative but complete\ngeometric structures in depth prediction, generating accurate, dense, and\ndetailed metric depth maps for any scene. To this end, we design a\ncoarse-to-fine pipeline to progressively integrate the two complementary depth\nsources. First, we introduce pixel-level metric alignment and distance-aware\nweighting to pre-fill diverse metric priors by explicitly using depth\nprediction. It effectively narrows the domain gap between prior patterns,\nenhancing generalization across varying scenarios. Second, we develop a\nconditioned monocular depth estimation (MDE) model to refine the inherent noise\nof depth priors. By conditioning on the normalized pre-filled prior and\nprediction, the model further implicitly merges the two complementary depth\nsources. Our model showcases impressive zero-shot generalization across depth\ncompletion, super-resolution, and inpainting over 7 real-world datasets,\nmatching or even surpassing previous task-specific methods. More importantly,\nit performs well on challenging, unseen mixed priors and enables test-time\nimprovements by switching prediction models, providing a flexible\naccuracy-efficiency trade-off while evolving with advancements in MDE models."}
{"id": "2505.09925", "pdf": "https://arxiv.org/pdf/2505.09925", "abs": "https://arxiv.org/abs/2505.09925", "authors": ["Yutao Yang", "Jie Zhou", "Junsong Li", "Qianjun Pan", "Bihao Zhan", "Qin Chen", "Xipeng Qiu", "Liang He"], "title": "Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces an interactive continual learning paradigm where AI\nmodels dynamically learn new skills from real-time human feedback while\nretaining prior knowledge. This paradigm distinctively addresses two major\nlimitations of traditional continual learning: (1) dynamic model updates using\nstreaming, real-time human-annotated data, rather than static datasets with\nfixed labels, and (2) the assumption of clean labels, by explicitly handling\nthe noisy feedback common in real-world interactions. To tackle these problems,\nwe propose RiCL, a Reinforced interactive Continual Learning framework\nleveraging Large Language Models (LLMs) to learn new skills effectively from\ndynamic feedback. RiCL incorporates three key components: a temporal\nconsistency-aware purifier to automatically discern clean from noisy samples in\ndata streams; an interaction-aware direct preference optimization strategy to\nalign model behavior with human intent by reconciling AI-generated and\nhuman-provided feedback; and a noise-resistant contrastive learning module that\ncaptures robust representations by exploiting inherent data relationships, thus\navoiding reliance on potentially unreliable labels. Extensive experiments on\ntwo benchmark datasets (FewRel and TACRED), contaminated with realistic noise\npatterns, demonstrate that our RiCL approach substantially outperforms existing\ncombinations of state-of-the-art online continual learning and noisy-label\nlearning methods."}
{"id": "2505.10272", "pdf": "https://arxiv.org/pdf/2505.10272", "abs": "https://arxiv.org/abs/2505.10272", "authors": ["Niklas Dexheimer", "Sascha Gaudlitz", "Johannes Schmidt-Hieber"], "title": "Spike-timing-dependent Hebbian learning as noisy gradient descent", "categories": ["cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Hebbian learning is a key principle underlying learning in biological neural\nnetworks. It postulates that synaptic changes occur locally, depending on the\nactivities of pre- and postsynaptic neurons. While Hebbian learning based on\nneuronal firing rates is well explored, much less is known about learning rules\nthat account for precise spike-timing. We relate a Hebbian\nspike-timing-dependent plasticity rule to noisy gradient descent with respect\nto a natural loss function on the probability simplex. This connection allows\nus to prove that the learning rule eventually identifies the presynaptic neuron\nwith the highest activity. We also discover an intrinsic connection to noisy\nmirror descent."}
{"id": "2505.10557", "pdf": "https://arxiv.org/pdf/2505.10557", "abs": "https://arxiv.org/abs/2505.10557", "authors": ["Ke Wang", "Junting Pan", "Linda Wei", "Aojun Zhou", "Weikang Shi", "Zimu Lu", "Han Xiao", "Yunqiao Yang", "Houxing Ren", "Mingjie Zhan", "Hongsheng Li"], "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder."}
{"id": "2505.10566", "pdf": "https://arxiv.org/pdf/2505.10566", "abs": "https://arxiv.org/abs/2505.10566", "authors": ["Yen-Chi Cheng", "Krishna Kumar Singh", "Jae Shin Yoon", "Alex Schwing", "Liangyan Gui", "Matheus Gadelha", "Paul Guerrero", "Nanxuan Zhao"], "title": "3D-Fixup: Advancing Photo Editing with 3D Priors", "categories": ["cs.CV"], "comment": "SIGGRAPH 2025. Project page: https://3dfixup.github.io/", "summary": "Despite significant advances in modeling image priors via diffusion models,\n3D-aware image editing remains challenging, in part because the object is only\nspecified via a single image. To tackle this challenge, we propose 3D-Fixup, a\nnew framework for editing 2D images guided by learned 3D priors. The framework\nsupports difficult editing situations such as object translation and 3D\nrotation. To achieve this, we leverage a training-based approach that harnesses\nthe generative power of diffusion models. As video data naturally encodes\nreal-world physical dynamics, we turn to video data for generating training\ndata pairs, i.e., a source and a target frame. Rather than relying solely on a\nsingle trained model to infer transformations between source and target frames,\nwe incorporate 3D guidance from an Image-to-3D model, which bridges this\nchallenging task by explicitly projecting 2D information into 3D space. We\ndesign a data generation pipeline to ensure high-quality 3D guidance throughout\ntraining. Results show that by integrating these 3D priors, 3D-Fixup\neffectively supports complex, identity coherent 3D-aware edits, achieving\nhigh-quality results and advancing the application of diffusion models in\nrealistic image manipulation. The code is provided at\nhttps://3dfixup.github.io/"}
{"id": "2505.09926", "pdf": "https://arxiv.org/pdf/2505.09926", "abs": "https://arxiv.org/abs/2505.09926", "authors": ["Bin-Bin Gao", "Yue Zhu", "Jiangtao Yan", "Yuezhi Cai", "Weixi Zhang", "Meng Wang", "Jun Liu", "Yong Liu", "Lei Wang", "Chengjie Wang"], "title": "AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": "27 pages, 15 figures, 22 tables", "summary": "Universal visual anomaly detection aims to identify anomalies from novel or\nunseen vision domains without additional fine-tuning, which is critical in open\nscenarios. Recent studies have demonstrated that pre-trained vision-language\nmodels like CLIP exhibit strong generalization with just zero or a few normal\nimages. However, existing methods struggle with designing prompt templates,\ncomplex token interactions, or requiring additional fine-tuning, resulting in\nlimited flexibility. In this work, we present a simple yet effective method\ncalled AdaptCLIP based on two key insights. First, adaptive visual and textual\nrepresentations should be learned alternately rather than jointly. Second,\ncomparative learning between query and normal image prompt should incorporate\nboth contextual and aligned residual features, rather than relying solely on\nresidual features. AdaptCLIP treats CLIP models as a foundational service,\nadding only three simple adapters, visual adapter, textual adapter, and\nprompt-query adapter, at its input or output ends. AdaptCLIP supports\nzero-/few-shot generalization across domains and possesses a training-free\nmanner on target domains once trained on a base dataset. AdaptCLIP achieves\nstate-of-the-art performance on 12 anomaly detection benchmarks from industrial\nand medical domains, significantly outperforming existing competitive methods.\nWe will make the code and model of AdaptCLIP available at\nhttps://github.com/gaobb/AdaptCLIP."}
{"id": "2505.10296", "pdf": "https://arxiv.org/pdf/2505.10296", "abs": "https://arxiv.org/abs/2505.10296", "authors": ["Jiaju Qi", "Lei Lei", "Thorsteinn Jonsson", "Dusit Niyato"], "title": "Optimizing Electric Bus Charging Scheduling with Uncertainties Using Hierarchical Deep Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "The growing adoption of Electric Buses (EBs) represents a significant step\ntoward sustainable development. By utilizing Internet of Things (IoT) systems,\ncharging stations can autonomously determine charging schedules based on\nreal-time data. However, optimizing EB charging schedules remains a critical\nchallenge due to uncertainties in travel time, energy consumption, and\nfluctuating electricity prices. Moreover, to address real-world complexities,\ncharging policies must make decisions efficiently across multiple time scales\nand remain scalable for large EB fleets. In this paper, we propose a\nHierarchical Deep Reinforcement Learning (HDRL) approach that reformulates the\noriginal Markov Decision Process (MDP) into two augmented MDPs. To solve these\nMDPs and enable multi-timescale decision-making, we introduce a novel HDRL\nalgorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization\nEnhancement (DAC-MAPPO-E). Scalability challenges of the Double Actor-Critic\n(DAC) algorithm for large-scale EB fleets are addressed through enhancements at\nboth decision levels. At the high level, we redesign the decentralized actor\nnetwork and integrate an attention mechanism to extract relevant global state\ninformation for each EB, decreasing the size of neural networks. At the low\nlevel, the Multi-Agent Proximal Policy Optimization (MAPPO) algorithm is\nincorporated into the DAC framework, enabling decentralized and coordinated\ncharging power decisions, reducing computational complexity and enhancing\nconvergence speed. Extensive experiments with real-world data demonstrate the\nsuperior performance and scalability of DAC-MAPPO-E in optimizing EB fleet\ncharging schedules."}
{"id": "2505.09630", "pdf": "https://arxiv.org/pdf/2505.09630", "abs": "https://arxiv.org/abs/2505.09630", "authors": ["Tien Comlekoglu", "J. Quetzalcóatl Toledo-Marín", "Douglas W. DeSimone", "Shayn M. Peirce", "Geoffrey Fox", "James A. Glazier"], "title": "Generative diffusion model surrogates for mechanistic agent-based biological models", "categories": ["q-bio.QM", "cs.CV", "cs.ET", "cs.PF"], "comment": null, "summary": "Mechanistic, multicellular, agent-based models are commonly used to\ninvestigate tissue, organ, and organism-scale biology at single-cell\nresolution. The Cellular-Potts Model (CPM) is a powerful and popular framework\nfor developing and interrogating these models. CPMs become computationally\nexpensive at large space- and time- scales making application and investigation\nof developed models difficult. Surrogate models may allow for the accelerated\nevaluation of CPMs of complex biological systems. However, the stochastic\nnature of these models means each set of parameters may give rise to different\nmodel configurations, complicating surrogate model development. In this work,\nwe leverage denoising diffusion probabilistic models to train a generative AI\nsurrogate of a CPM used to investigate \\textit{in vitro} vasculogenesis. We\ndescribe the use of an image classifier to learn the characteristics that\ndefine unique areas of a 2-dimensional parameter space. We then apply this\nclassifier to aid in surrogate model selection and verification. Our CPM model\nsurrogate generates model configurations 20,000 timesteps ahead of a reference\nconfiguration and demonstrates approximately a 22x reduction in computational\ntime as compared to native code execution. Our work represents a step towards\nthe implementation of DDPMs to develop digital twins of stochastic biological\nsystems."}
{"id": "2505.09935", "pdf": "https://arxiv.org/pdf/2505.09935", "abs": "https://arxiv.org/abs/2505.09935", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Quoc Dai Tran"], "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users."}
{"id": "2505.10297", "pdf": "https://arxiv.org/pdf/2505.10297", "abs": "https://arxiv.org/abs/2505.10297", "authors": ["Chibueze Peace Obioma", "Youcheng Sun", "Mustafa A. Mustafa"], "title": "Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Submitted to ESORICS 2025", "summary": "Federated learning (FL) enhances privacy and reduces communication cost for\nresource-constrained edge clients by supporting distributed model training at\nthe edge. However, the heterogeneous nature of such devices produces diverse,\nnon-independent, and identically distributed (non-IID) data, making the\ndetection of backdoor attacks more challenging. In this paper, we propose a\nnovel federated representative-attention-based defense mechanism, named FeRA,\nthat leverages cross-client attention over internal feature representations to\ndistinguish benign from malicious clients. FeRA computes an anomaly score based\non representation reconstruction errors, effectively identifying clients whose\ninternal activations significantly deviate from the group consensus. Our\nevaluation demonstrates FeRA's robustness across various FL scenarios,\nincluding challenging non-IID data distributions typical of edge devices.\nExperimental results show that it effectively reduces backdoor attack success\nrates while maintaining high accuracy on the main task. The method is\nmodel-agnostic, attack-agnostic, and does not require labeled reference data,\nmaking it well suited to heterogeneous and resource-limited edge deployments."}
{"id": "2505.09819", "pdf": "https://arxiv.org/pdf/2505.09819", "abs": "https://arxiv.org/abs/2505.09819", "authors": ["Ruichen Yang", "György M. Lévay", "Christopher L. Hunt", "Dániel Czeiner", "Megan C. Hodgson", "Damini Agarwal", "Rahul R. Kaliki", "Nitish V. Thakor"], "title": "Visual Feedback of Pattern Separability Improves Myoelectric Decoding Performance of Upper Limb Prostheses", "categories": ["cs.HC", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "State-of-the-art upper limb myoelectric prostheses often use pattern\nrecognition (PR) control systems that translate electromyography (EMG) signals\ninto desired movements. As prosthesis movement complexity increases, users\noften struggle to produce sufficiently distinct EMG patterns for reliable\nclassification. Existing training typically involves heuristic, trial-and-error\nuser adjustments to static decoder boundaries. Goal: We introduce the Reviewer,\na 3D visual interface projecting EMG signals directly into the decoder's\nclassification space, providing intuitive, real-time insight into PR algorithm\nbehavior. This structured feedback reduces cognitive load and fosters mutual,\ndata-driven adaptation between user-generated EMG patterns and decoder\nboundaries. Methods: A 10-session study with 12 able-bodied participants\ncompared PR performance after motor-based training and updating using the\nReviewer versus conventional virtual arm visualization. Performance was\nassessed using a Fitts law task that involved the aperture of the cursor and\nthe control of orientation. Results: Participants trained with the Reviewer\nachieved higher completion rates, reduced overshoot, and improved path\nefficiency and throughput compared to the standard visualization group.\nSignificance: The Reviewer introduces decoder-informed motor training,\nfacilitating immediate and consistent PR-based myoelectric control\nimprovements. By iteratively refining control through real-time feedback, this\napproach reduces reliance on trial-and-error recalibration, enabling a more\nadaptive, self-correcting training framework. Conclusion: The 3D visual\nfeedback significantly improves PR control in novice operators through\nstructured training, enabling feedback-driven adaptation and reducing reliance\non extensive heuristic adjustments."}
{"id": "2505.09945", "pdf": "https://arxiv.org/pdf/2505.09945", "abs": "https://arxiv.org/abs/2505.09945", "authors": ["Deeksha Prahlad", "Chanhee Lee", "Dongha Kim", "Hokeun Kim"], "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)", "summary": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time."}
{"id": "2505.10307", "pdf": "https://arxiv.org/pdf/2505.10307", "abs": "https://arxiv.org/abs/2505.10307", "authors": ["Yiyang Zhao", "Chengpei Wu", "Lilin Zhang", "Ning Yang"], "title": "Negative Metric Learning for Graphs", "categories": ["cs.LG"], "comment": null, "summary": "Graph contrastive learning (GCL) often suffers from false negatives, which\ndegrades the performance on downstream tasks. The existing methods addressing\nthe false negative issue usually rely on human prior knowledge, still leading\nGCL to suboptimal results. In this paper, we propose a novel Negative Metric\nLearning (NML) enhanced GCL (NML-GCL). NML-GCL employs a learnable Negative\nMetric Network (NMN) to build a negative metric space, in which false negatives\ncan be distinguished better from true negatives based on their distance to\nanchor node. To overcome the lack of explicit supervision signals for NML, we\npropose a joint training scheme with bi-level optimization objective, which\nimplicitly utilizes the self-supervision signals to iteratively optimize the\nencoder and the negative metric network. The solid theoretical analysis and the\nextensive experiments conducted on widely used benchmarks verify the\nsuperiority of the proposed method."}
{"id": "2505.09831", "pdf": "https://arxiv.org/pdf/2505.09831", "abs": "https://arxiv.org/abs/2505.09831", "authors": ["Tushar Kataria", "Beatrice Knudsen", "Shireen Y. Elhabian"], "title": "ImplicitStainer: Data-Efficient Medical Image Translation for Virtual Antibody-based Tissue Staining Using Local Implicit Functions", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Hematoxylin and eosin (H&E) staining is a gold standard for microscopic\ndiagnosis in pathology. However, H&E staining does not capture all the\ndiagnostic information that may be needed. To obtain additional molecular\ninformation, immunohistochemical (IHC) stains highlight proteins that mark\nspecific cell types, such as CD3 for T-cells or CK8/18 for epithelial cells.\nWhile IHC stains are vital for prognosis and treatment guidance, they are\ntypically only available at specialized centers and time consuming to acquire,\nleading to treatment delays for patients. Virtual staining, enabled by deep\nlearning-based image translation models, provides a promising alternative by\ncomputationally generating IHC stains from H&E stained images. Although many\nGAN and diffusion based image to image (I2I) translation methods have been used\nfor virtual staining, these models treat image patches as independent data\npoints, which results in increased and more diverse data requirements for\neffective generation. We present ImplicitStainer, a novel approach that\nleverages local implicit functions to improve image translation, specifically\nvirtual staining performance, by focusing on pixel-level predictions. This\nmethod enhances robustness to variations in dataset sizes, delivering\nhigh-quality results even with limited data. We validate our approach on two\ndatasets using a comprehensive set of metrics and benchmark it against over\nfifteen state-of-the-art GAN- and diffusion based models. Full Code and models\ntrained will be released publicly via Github upon acceptance."}
{"id": "2505.09952", "pdf": "https://arxiv.org/pdf/2505.09952", "abs": "https://arxiv.org/abs/2505.09952", "authors": ["Tianyu Huai", "Jie Zhou", "Yuxuan Cai", "Qin Chen", "Wen Wu", "Xingjiao Wu", "Xipeng Qiu", "Liang He"], "title": "Task-Core Memory Management and Consolidation for Long-term Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to Neurips2025", "summary": "In this paper, we focus on a long-term continual learning (CL) task, where a\nmodel learns sequentially from a stream of vast tasks over time, acquiring new\nknowledge while retaining previously learned information in a manner akin to\nhuman learning. Unlike traditional CL settings, long-term CL involves handling\na significantly larger number of tasks, which exacerbates the issue of\ncatastrophic forgetting. Our work seeks to address two critical questions: 1)\nHow do existing CL methods perform in the context of long-term CL? and 2) How\ncan we mitigate the catastrophic forgetting that arises from prolonged\nsequential updates? To tackle these challenges, we propose a novel framework\ninspired by human memory mechanisms for long-term continual learning (Long-CL).\nSpecifically, we introduce a task-core memory management strategy to\nefficiently index crucial memories and adaptively update them as learning\nprogresses. Additionally, we develop a long-term memory consolidation mechanism\nthat selectively retains hard and discriminative samples, ensuring robust\nknowledge retention. To facilitate research in this area, we construct and\nrelease two multi-modal and textual benchmarks, MMLongCL-Bench and\nTextLongCL-Bench, providing a valuable resource for evaluating long-term CL\napproaches. Experimental results show that Long-CL outperforms the previous\nstate-of-the-art by 7.4\\% and 6.5\\% AP on the two benchmarks, respectively,\ndemonstrating the effectiveness of our approach."}
{"id": "2505.10322", "pdf": "https://arxiv.org/pdf/2505.10322", "abs": "https://arxiv.org/abs/2505.10322", "authors": ["Yijie Zhou", "Shi Pu"], "title": "Asynchronous Decentralized SGD under Non-Convexity: A Block-Coordinate Descent Framework", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Decentralized optimization has become vital for leveraging distributed data\nwithout central control, enhancing scalability and privacy. However, practical\ndeployments face fundamental challenges due to heterogeneous computation speeds\nand unpredictable communication delays. This paper introduces a refined model\nof Asynchronous Decentralized Stochastic Gradient Descent (ADSGD) under\npractical assumptions of bounded computation and communication times. To\nunderstand the convergence of ADSGD, we first analyze Asynchronous Stochastic\nBlock Coordinate Descent (ASBCD) as a tool, and then show that ADSGD converges\nunder computation-delay-independent step sizes. The convergence result is\nestablished without assuming bounded data heterogeneity. Empirical experiments\nreveal that ADSGD outperforms existing methods in wall-clock convergence time\nacross various scenarios. With its simplicity, efficiency in memory and\ncommunication, and resilience to communication and computation delays, ADSGD is\nwell-suited for real-world decentralized learning tasks."}
{"id": "2505.09985", "pdf": "https://arxiv.org/pdf/2505.09985", "abs": "https://arxiv.org/abs/2505.09985", "authors": ["Pengfei Yu", "Bin Huang", "Minghui Zhang", "Weiwen Wu", "Shaoyu Wang", "Qiegen Liu"], "title": "Ordered-subsets Multi-diffusion Model for Sparse-view CT Reconstruction", "categories": ["eess.IV", "cs.CV"], "comment": null, "summary": "Score-based diffusion models have shown significant promise in the field of\nsparse-view CT reconstruction. However, the projection dataset is large and\nriddled with redundancy. Consequently, applying the diffusion model to\nunprocessed data results in lower learning effectiveness and higher learning\ndifficulty, frequently leading to reconstructed images that lack fine details.\nTo address these issues, we propose the ordered-subsets multi-diffusion model\n(OSMM) for sparse-view CT reconstruction. The OSMM innovatively divides the CT\nprojection data into equal subsets and employs multi-subsets diffusion model\n(MSDM) to learn from each subset independently. This targeted learning approach\nreduces complexity and enhances the reconstruction of fine details.\nFurthermore, the integration of one-whole diffusion model (OWDM) with complete\nsinogram data acts as a global information constraint, which can reduce the\npossibility of generating erroneous or inconsistent sinogram information.\nMoreover, the OSMM's unsupervised learning framework provides strong robustness\nand generalizability, adapting seamlessly to varying sparsity levels of CT\nsinograms. This ensures consistent and reliable performance across different\nclinical scenarios. Experimental results demonstrate that OSMM outperforms\ntraditional diffusion models in terms of image quality and noise resilience,\noffering a powerful and versatile solution for advanced CT imaging in\nsparse-view scenarios."}
{"id": "2505.09955", "pdf": "https://arxiv.org/pdf/2505.09955", "abs": "https://arxiv.org/abs/2505.09955", "authors": ["Jaeho Kim", "Seulki Lee"], "title": "TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 Accept", "summary": "Unsupervised domain adaptation (UDA) for time series data remains a critical\nchallenge in deep learning, with traditional pseudo-labeling strategies failing\nto capture temporal patterns and channel-wise shifts between domains, producing\nsub-optimal pseudo-labels. As such, we introduce TransPL, a novel approach that\naddresses these limitations by modeling the joint distribution $P(\\mathbf{X},\ny)$ of the source domain through code transition matrices, where the codes are\nderived from vector quantization (VQ) of time series patches. Our method\nconstructs class- and channel-wise code transition matrices from the source\ndomain and employs Bayes' rule for target domain adaptation, generating\npseudo-labels based on channel-wise weighted class-conditional likelihoods.\nTransPL offers three key advantages: explicit modeling of temporal transitions\nand channel-wise shifts between different domains, versatility towards\ndifferent UDA scenarios (e.g., weakly-supervised UDA), and explainable\npseudo-label generation. We validate TransPL's effectiveness through extensive\nanalysis on four time series UDA benchmarks and confirm that it consistently\noutperforms state-of-the-art pseudo-labeling methods by a strong margin (6.1%\naccuracy improvement, 4.9% F1 improvement), while providing interpretable\ninsights into the domain adaptation process through its learned code transition\nmatrices."}
{"id": "2505.10325", "pdf": "https://arxiv.org/pdf/2505.10325", "abs": "https://arxiv.org/abs/2505.10325", "authors": ["Athanasios Tziouvaras", "Blaz Bertalanic", "George Floros", "Kostas Kolomvatsos", "Panagiotis Sarigiannidis", "Carolina Fortuna"], "title": "A Representation Learning Approach to Feature Drift Detection in Wireless Networks", "categories": ["cs.LG"], "comment": null, "summary": "AI is foreseen to be a centerpiece in next generation wireless networks\nenabling enabling ubiquitous communication as well as new services. However, in\nreal deployment, feature distribution changes may degrade the performance of AI\nmodels and lead to undesired behaviors. To counter for undetected model\ndegradation, we propose ALERT; a method that can detect feature distribution\nchanges and trigger model re-training that works well on two wireless network\nuse cases: wireless fingerprinting and link anomaly detection. ALERT includes\nthree components: representation learning, statistical testing and utility\nassessment. We rely on MLP for designing the representation learning component,\non Kolmogorov-Smirnov and Population Stability Index tests for designing the\nstatistical testing and a new function for utility assessment. We show the\nsuperiority of the proposed method against ten standard drift detection methods\navailable in the literature on two wireless network use cases."}
{"id": "2505.10075", "pdf": "https://arxiv.org/pdf/2505.10075", "abs": "https://arxiv.org/abs/2505.10075", "authors": ["Jun Guo", "Xiaojian Ma", "Yikai Wang", "Min Yang", "Huaping Liu", "Qing Li"], "title": "FlowDreamer: A RGB-D World Model with Flow-based Motion Representations for Robot Manipulation", "categories": ["cs.RO", "cs.CV"], "comment": "Project page: see https://sharinka0715.github.io/FlowDreamer/", "summary": "This paper investigates training better visual world models for robot\nmanipulation, i.e., models that can predict future visual observations by\nconditioning on past frames and robot actions. Specifically, we consider world\nmodels that operate on RGB-D frames (RGB-D world models). As opposed to\ncanonical approaches that handle dynamics prediction mostly implicitly and\nreconcile it with visual rendering in a single model, we introduce FlowDreamer,\nwhich adopts 3D scene flow as explicit motion representations. FlowDreamer\nfirst predicts 3D scene flow from past frame and action conditions with a\nU-Net, and then a diffusion model will predict the future frame utilizing the\nscene flow. FlowDreamer is trained end-to-end despite its modularized nature.\nWe conduct experiments on 4 different benchmarks, covering both video\nprediction and visual planning tasks. The results demonstrate that FlowDreamer\nachieves better performance compared to other baseline RGB-D world models by 7%\non semantic similarity, 11% on pixel quality, and 6% on success rate in various\nrobot manipulation domains."}
{"id": "2505.09969", "pdf": "https://arxiv.org/pdf/2505.09969", "abs": "https://arxiv.org/abs/2505.09969", "authors": ["Ali Azimi Lamir", "Shiva Razzagzadeh", "Zeynab Rezaei"], "title": "A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study presents a machine learning-based framework for heart disease\nprediction using the heart-disease dataset, comprising 303 samples with 14\nfeatures. The methodology involves data preprocessing, model training, and\nevaluation using three classifiers: Logistic Regression, K-Nearest Neighbors\n(KNN), and Random Forest. Hyperparameter tuning with GridSearchCV and\nRandomizedSearchCV was employed to enhance model performance. The Random Forest\nclassifier outperformed other models, achieving an accuracy of 91% and an\nF1-score of 0.89. Evaluation metrics, including precision, recall, and\nconfusion matrix, revealed balanced performance across classes. The proposed\nmodel demonstrates strong potential for aiding clinical decision-making by\neffectively predicting heart disease. Limitations such as dataset size and\ngeneralizability underscore the need for future studies using larger and more\ndiverse datasets. This work highlights the utility of machine learning in\nhealthcare, offering insights for further advancements in predictive\ndiagnostics."}
{"id": "2505.10330", "pdf": "https://arxiv.org/pdf/2505.10330", "abs": "https://arxiv.org/abs/2505.10330", "authors": ["Jonathan Clifford Balloch"], "title": "Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change", "categories": ["cs.LG", "cs.AI"], "comment": "PhD Dissertation, 131 pages", "summary": "Real-world autonomous decision-making systems, from robots to recommendation\nengines, must operate in environments that change over time. While deep\nreinforcement learning (RL) has shown an impressive ability to learn optimal\npolicies in stationary environments, most methods are data intensive and assume\na world that does not change between training and test time. As a result,\nconventional RL methods struggle to adapt when conditions change. This poses a\nfundamental challenge: how can RL agents efficiently adapt their behavior when\nencountering novel environmental changes during deployment without\ncatastrophically forgetting useful prior knowledge? This dissertation\ndemonstrates that efficient online adaptation requires two key capabilities:\n(1) prioritized exploration and sampling strategies that help identify and\nlearn from relevant experiences, and (2) selective preservation of prior\nknowledge through structured representations that can be updated without\ndisruption to reusable components."}
{"id": "2505.10144", "pdf": "https://arxiv.org/pdf/2505.10144", "abs": "https://arxiv.org/abs/2505.10144", "authors": ["Xuechang Tu", "Lukas Radl", "Michael Steiner", "Markus Steinberger", "Bernhard Kerbl", "Fernando de la Torre"], "title": "VRSplat: Fast and Robust Gaussian Splatting for Virtual Reality", "categories": ["cs.GR", "cs.CV"], "comment": "I3D'25 (PACMCGIT); Project Page: https://cekavis.site/VRSplat/", "summary": "3D Gaussian Splatting (3DGS) has rapidly become a leading technique for\nnovel-view synthesis, providing exceptional performance through efficient\nsoftware-based GPU rasterization. Its versatility enables real-time\napplications, including on mobile and lower-powered devices. However, 3DGS\nfaces key challenges in virtual reality (VR): (1) temporal artifacts, such as\npopping during head movements, (2) projection-based distortions that result in\ndisturbing and view-inconsistent floaters, and (3) reduced framerates when\nrendering large numbers of Gaussians, falling below the critical threshold for\nVR. Compared to desktop environments, these issues are drastically amplified by\nlarge field-of-view, constant head movements, and high resolution of\nhead-mounted displays (HMDs). In this work, we introduce VRSplat: we combine\nand extend several recent advancements in 3DGS to address challenges of VR\nholistically. We show how the ideas of Mini-Splatting, StopThePop, and Optimal\nProjection can complement each other, by modifying the individual techniques\nand core 3DGS rasterizer. Additionally, we propose an efficient foveated\nrasterizer that handles focus and peripheral areas in a single GPU launch,\navoiding redundant computations and improving GPU utilization. Our method also\nincorporates a fine-tuning step that optimizes Gaussian parameters based on\nStopThePop depth evaluations and Optimal Projection. We validate our method\nthrough a controlled user study with 25 participants, showing a strong\npreference for VRSplat over other configurations of Mini-Splatting. VRSplat is\nthe first, systematically evaluated 3DGS approach capable of supporting modern\nVR applications, achieving 72+ FPS while eliminating popping and\nstereo-disrupting floaters."}
{"id": "2505.09974", "pdf": "https://arxiv.org/pdf/2505.09974", "abs": "https://arxiv.org/abs/2505.09974", "authors": ["Adel ElZemity", "Budi Arief", "Shujun Li"], "title": "Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The integration of large language models (LLMs) into cyber security\napplications presents significant opportunities, such as enhancing threat\nanalysis and malware detection, but can also introduce critical risks and\nsafety concerns, including personal data leakage and automated generation of\nnew malware. We present a systematic evaluation of safety risks in fine-tuned\nLLMs for cyber security applications. Using the OWASP Top 10 for LLM\nApplications framework, we assessed seven open-source LLMs: Phi 3 Mini 3.8B,\nMistral 7B, Qwen 2.5 7B, Llama 3 8B, Llama 3.1 8B, Gemma 2 9B, and Llama 2 70B.\nOur evaluation shows that fine-tuning reduces safety resilience across all\ntested LLMs (e.g., the safety score of Llama 3.1 8B against prompt injection\ndrops from 0.95 to 0.15). We propose and evaluate a safety alignment approach\nthat carefully rewords instruction-response pairs to include explicit safety\nprecautions and ethical considerations. This approach demonstrates that it is\npossible to maintain or even improve model safety while preserving technical\nutility, offering a practical path forward for developing safer fine-tuning\nmethodologies. This work offers a systematic evaluation for safety risks in\nLLMs, enabling safer adoption of generative AI in sensitive domains, and\ncontributing towards the development of secure, trustworthy, and ethically\naligned LLMs."}
{"id": "2505.10331", "pdf": "https://arxiv.org/pdf/2505.10331", "abs": "https://arxiv.org/abs/2505.10331", "authors": ["Luca Muscarnera", "Luigi Loreti", "Giovanni Todeschini", "Alessio Fumagalli", "Francesco Regazzoni"], "title": "Emergence of Structure in Ensembles of Random Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Randomness is ubiquitous in many applications across data science and machine\nlearning. Remarkably, systems composed of random components often display\nemergent global behaviors that appear deterministic, manifesting a transition\nfrom microscopic disorder to macroscopic organization. In this work, we\nintroduce a theoretical model for studying the emergence of collective\nbehaviors in ensembles of random classifiers. We argue that, if the ensemble is\nweighted through the Gibbs measure defined by adopting the classification loss\nas an energy, then there exists a finite temperature parameter for the\ndistribution such that the classification is optimal, with respect to the loss\n(or the energy). Interestingly, for the case in which samples are generated by\na Gaussian distribution and labels are constructed by employing a teacher\nperceptron, we analytically prove and numerically confirm that such optimal\ntemperature does not depend neither on the teacher classifier (which is, by\nconstruction of the learning problem, unknown), nor on the number of random\nclassifiers, highlighting the universal nature of the observed behavior.\nExperiments on the MNIST dataset underline the relevance of this phenomenon in\nhigh-quality, noiseless, datasets. Finally, a physical analogy allows us to\nshed light on the self-organizing nature of the studied phenomenon."}
{"id": "2505.10271", "pdf": "https://arxiv.org/pdf/2505.10271", "abs": "https://arxiv.org/abs/2505.10271", "authors": ["Rafael Pablos Sarabia", "Joachim Nyborg", "Morten Birk", "Jeppe Liborius Sjørup", "Anders Lillevang Vesterholt", "Ira Assent"], "title": "RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We present a deep learning model for high-resolution probabilistic\nprecipitation forecasting over an 8-hour horizon in Europe, overcoming the\nlimitations of radar-only deep learning models with short forecast lead times.\nOur model efficiently integrates multiple data sources - including radar,\nsatellite, and physics-based numerical weather prediction (NWP) - while\ncapturing long-range interactions, resulting in accurate forecasts with robust\nuncertainty quantification through consistent probabilistic maps. Featuring a\ncompact architecture, it enables more efficient training and faster inference\nthan existing models. Extensive experiments demonstrate that our model\nsurpasses current operational NWP systems, extrapolation-based methods, and\ndeep-learning nowcasting models, setting a new standard for high-resolution\nprecipitation forecasting in Europe, ensuring a balance between accuracy,\ninterpretability, and computational efficiency."}
{"id": "2505.09989", "pdf": "https://arxiv.org/pdf/2505.09989", "abs": "https://arxiv.org/abs/2505.09989", "authors": ["Tella Rajashekhar Reddy", "Palak", "Rohan Gandhi", "Anjaly Parayil", "Chaojie Zhang", "Mike Shepperd", "Liangcheng Yu", "Jayashree Mohan", "Srinivasan Iyengar", "Shivkumar Kalyanaraman", "Debopam Bhattacherjee"], "title": "AI Greenferencing: Routing AI Inferencing to Green Modular Data Centers with Heron", "categories": ["cs.DC", "cs.AI", "cs.NI"], "comment": null, "summary": "AI power demand is growing unprecedentedly thanks to the high power density\nof AI compute and the emerging inferencing workload. On the supply side,\nabundant wind power is waiting for grid access in interconnection queues. In\nthis light, this paper argues bringing AI workload to modular compute clusters\nco-located in wind farms. Our deployment right-sizing strategy makes it\neconomically viable to deploy more than 6 million high-end GPUs today that\ncould consume cheap, green power at its source. We built Heron, a cross-site\nsoftware router, that could efficiently leverage the complementarity of power\ngeneration across wind farms by routing AI inferencing workload around power\ndrops. Using 1-week ofcoding and conversation production traces from Azure and\n(real) variable wind power traces, we show how Heron improves aggregate goodput\nof AI compute by up to 80% compared to the state-of-the-art."}
{"id": "2505.10344", "pdf": "https://arxiv.org/pdf/2505.10344", "abs": "https://arxiv.org/abs/2505.10344", "authors": ["Alan Jeffares", "Liyuan Liu"], "title": "An Introduction to Discrete Variational Autoencoders", "categories": ["cs.LG"], "comment": "Tutorial paper", "summary": "Variational Autoencoders (VAEs) are well-established as a principled approach\nto probabilistic unsupervised learning with neural networks. Typically, an\nencoder network defines the parameters of a Gaussian distributed latent space\nfrom which we can sample and pass realizations to a decoder network. This model\nis trained to reconstruct its inputs and is optimized through the evidence\nlower bound. In recent years, discrete latent spaces have grown in popularity,\nsuggesting that they may be a natural choice for many data modalities (e.g.\ntext). In this tutorial, we provide a rigorous, yet practical, introduction to\ndiscrete variational autoencoders -- specifically, VAEs in which the latent\nspace is made up of latent variables that follow a categorical distribution. We\nassume only a basic mathematical background with which we carefully derive each\nstep from first principles. From there, we develop a concrete training recipe\nand provide an example implementation, hosted at\nhttps://github.com/alanjeffares/discreteVAE."}
{"id": "2505.10312", "pdf": "https://arxiv.org/pdf/2505.10312", "abs": "https://arxiv.org/abs/2505.10312", "authors": ["Anh Tuan Ha", "Hoang Khang Phan", "Thai Minh Tien Ngo", "Anh Phan Truong", "Nhat Tan Le"], "title": "SOS: A Shuffle Order Strategy for Data Augmentation in Industrial Human Activity Recognition", "categories": ["cs.HC", "cs.CV"], "comment": null, "summary": "In the realm of Human Activity Recognition (HAR), obtaining high quality and\nvariance data is still a persistent challenge due to high costs and the\ninherent variability of real-world activities. This study introduces a\ngeneration dataset by deep learning approaches (Attention Autoencoder and\nconditional Generative Adversarial Networks). Another problem that data\nheterogeneity is a critical challenge, one of the solutions is to shuffle the\ndata to homogenize the distribution. Experimental results demonstrate that the\nrandom sequence strategy significantly improves classification performance,\nachieving an accuracy of up to 0.70 $\\pm$ 0.03 and a macro F1 score of 0.64\n$\\pm$ 0.01. For that, disrupting temporal dependencies through random sequence\nreordering compels the model to focus on instantaneous recognition, thereby\nimproving robustness against activity transitions. This approach not only\nbroadens the effective training dataset but also offers promising avenues for\nenhancing HAR systems in complex, real-world scenarios."}
{"id": "2505.10012", "pdf": "https://arxiv.org/pdf/2505.10012", "abs": "https://arxiv.org/abs/2505.10012", "authors": ["Tadashi Kadowaki"], "title": "Quantum Computing and AI: Perspectives on Advanced Automation in Science and Engineering", "categories": ["quant-ph", "cs.AI"], "comment": "8 pages, 4 figures", "summary": "Recent advances in artificial intelligence (AI) and quantum computing are\naccelerating automation in scientific and engineering processes, fundamentally\nreshaping research methodologies. This perspective highlights parallels between\nscientific automation and established Computer-Aided Engineering (CAE)\npractices, introducing Quantum CAE as a framework that leverages quantum\nalgorithms for simulation, optimization, and machine learning within\nengineering design. Practical implementations of Quantum CAE are illustrated\nthrough case studies for combinatorial optimization problems. Further\ndiscussions include advancements toward higher automation levels, highlighting\nthe critical role of specialized AI agents proficient in quantum algorithm\ndesign. The integration of quantum computing with AI raises significant\nquestions about the collaborative dynamics among human scientists and\nengineers, AI systems, and quantum computational resources, underscoring a\ntransformative future for automated discovery and innovation."}
{"id": "2505.10347", "pdf": "https://arxiv.org/pdf/2505.10347", "abs": "https://arxiv.org/abs/2505.10347", "authors": ["Gabriel S. Gama", "Valdir Grassi Jr"], "title": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task\nLearning by addressing issues like conflicting gradients and differing gradient\nnorms, which hinder equal-weighted task training. However, recent critiques\nsuggest that equally weighted tasks can achieve competitive results compared to\nSMTOs, arguing that previous SMTO results were influenced by poor\nhyperparameter optimization and lack of regularization. In this work, we\nevaluate these claims through an extensive empirical evaluation of SMTOs,\nincluding some of the latest methods, on more complex multi-task problems to\nclarify this behavior. Our findings indicate that SMTOs perform well compared\nto uniform loss and that fixed weights can achieve competitive performance\ncompared to SMTOs. Furthermore, we demonstrate why uniform loss perform\nsimilarly to SMTOs in some instances. The code will be made publicly available."}
{"id": "2505.10405", "pdf": "https://arxiv.org/pdf/2505.10405", "abs": "https://arxiv.org/abs/2505.10405", "authors": ["Jianhao Huang", "Qunsong Zeng", "Kaibin Huang"], "title": "Visual Fidelity Index for Generative Semantic Communications with Critical Information Embedding", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Generative semantic communication (Gen-SemCom) with large artificial\nintelligence (AI) model promises a transformative paradigm for 6G networks,\nwhich reduces communication costs by transmitting low-dimensional prompts\nrather than raw data. However, purely prompt-driven generation loses\nfine-grained visual details. Additionally, there is a lack of systematic\nmetrics to evaluate the performance of Gen-SemCom systems. To address these\nissues, we develop a hybrid Gen-SemCom system with a critical information\nembedding (CIE) framework, where both text prompts and semantically critical\nfeatures are extracted for transmissions. First, a novel approach of semantic\nfiltering is proposed to select and transmit the semantically critical features\nof images relevant to semantic label. By integrating the text prompt and\ncritical features, the receiver reconstructs high-fidelity images using a\ndiffusion-based generative model. Next, we propose the generative visual\ninformation fidelity (GVIF) metric to evaluate the visual quality of the\ngenerated image. By characterizing the statistical models of image features,\nthe GVIF metric quantifies the mutual information between the distorted\nfeatures and their original counterparts. By maximizing the GVIF metric, we\ndesign a channel-adaptive Gen-SemCom system that adaptively control the volume\nof features and compression rate according to the channel state. Experimental\nresults validate the GVIF metric's sensitivity to visual fidelity, correlating\nwith both the PSNR and critical information volume. In addition, the optimized\nsystem achieves superior performance over benchmarking schemes in terms of\nhigher PSNR and lower FID scores."}
{"id": "2505.10016", "pdf": "https://arxiv.org/pdf/2505.10016", "abs": "https://arxiv.org/abs/2505.10016", "authors": ["Shijie Lyu"], "title": "Application of YOLOv8 in monocular downward multiple Car Target detection", "categories": ["cs.CV", "cs.AI", "I.4.8; I.2.10"], "comment": "Accepted by the 5th International Conference on Signal Processing and\n  Machine Learning (CONF-SPML 2025), to appear in Applied and Computational\n  Engineering", "summary": "Autonomous driving technology is progressively transforming traditional car\ndriving methods, marking a significant milestone in modern transportation.\nObject detection serves as a cornerstone of autonomous systems, playing a vital\nrole in enhancing driving safety, enabling autonomous functionality, improving\ntraffic efficiency, and facilitating effective emergency responses. However,\ncurrent technologies such as radar for environmental perception, cameras for\nroad perception, and vehicle sensor networks face notable challenges, including\nhigh costs, vulnerability to weather and lighting conditions, and limited\nresolution.To address these limitations, this paper presents an improved\nautonomous target detection network based on YOLOv8. By integrating structural\nreparameterization technology, a bidirectional pyramid structure network model,\nand a novel detection pipeline into the YOLOv8 framework, the proposed approach\nachieves highly efficient and precise detection of multi-scale, small, and\nremote objects. Experimental results demonstrate that the enhanced model can\neffectively detect both large and small objects with a detection accuracy of\n65%, showcasing significant advancements over traditional methods.This improved\nmodel holds substantial potential for real-world applications and is\nwell-suited for autonomous driving competitions, such as the Formula Student\nAutonomous China (FSAC), particularly excelling in scenarios involving\nsingle-target and small-object detection."}
{"id": "2505.10360", "pdf": "https://arxiv.org/pdf/2505.10360", "abs": "https://arxiv.org/abs/2505.10360", "authors": ["Victor Petrén Bach Hansen", "Lasse Krogsbøll", "Jonas Lyngsø", "Mathias Baltzersen", "Andreas Motzfeldt", "Kevin Pelgrims", "Lars Maaløe"], "title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": null, "summary": "There are now a multitude of AI-scribing solutions for healthcare promising\nthe utilization of large language models for ambient documentation. However,\nthese AI scribes still rely on one-shot, or few-shot prompts for generating\nnotes after the consultation has ended, employing little to no reasoning. This\nrisks long notes with an increase in hallucinations, misrepresentation of the\nintent of the clinician, and reliance on the proofreading of the clinician to\ncatch errors. A dangerous combination for patient safety if vigilance is\ncompromised by workload and fatigue. In this paper, we introduce a method for\nextracting salient clinical information in real-time alongside the healthcare\nconsultation, denoted Facts, and use that information recursively to generate\nthe final note. The FactsR method results in more accurate and concise notes by\nplacing the clinician-in-the-loop of note generation, while opening up new use\ncases within real-time decision support."}
{"id": "2505.10441", "pdf": "https://arxiv.org/pdf/2505.10441", "abs": "https://arxiv.org/abs/2505.10441", "authors": ["Filippo Leveni", "Luca Magri", "Giacomo Boracchi", "Cesare Alippi"], "title": "PIF: Anomaly detection via preference embedding", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)", "summary": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space."}
{"id": "2505.10027", "pdf": "https://arxiv.org/pdf/2505.10027", "abs": "https://arxiv.org/abs/2505.10027", "authors": ["Shijie Lyu"], "title": "ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by the 4th International Conference on Computing Innovation\n  and Applied Physics (CONF-CIAP 2025), and will be published in EAI Community\n  Research Series-CORE or Theoretical and Natural Science (TNS)", "summary": "With the rapid advancement of remote sensing technology, super-resolution\nimage reconstruction is of great research and practical significance. Existing\ndeep learning methods have made progress but still face limitations in handling\ncomplex scenes and preserving image details. This paper proposes a\nreinforcement learning-based latent diffusion model (LDM) fine-tuning method\nfor remote sensing image super-resolution. The method constructs a\nreinforcement learning environment with states, actions, and rewards,\noptimizing decision objectives through proximal policy optimization (PPO)\nduring the reverse denoising process of the LDM model. Experiments on the\nRESISC45 dataset show significant improvements over the baseline model in PSNR,\nSSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11,\nand LPIPS reducing by 0.06-0.10, particularly in structured and complex natural\nscenes. The results demonstrate the method's effectiveness in enhancing\nsuper-resolution quality and adaptability across scenes."}
{"id": "2505.10392", "pdf": "https://arxiv.org/pdf/2505.10392", "abs": "https://arxiv.org/abs/2505.10392", "authors": ["Aryan Mishra", "Lizhen Lin"], "title": "Schreier-Coset Graph Propagation", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 1 figure , preprint", "summary": "Graph Neural Networks (GNNs) offer a principled framework for learning over\ngraph-structured data, yet their expressive capacity is often hindered by\nover-squashing, wherein information from distant nodes is compressed into\nfixed-size vectors. Existing solutions, including graph rewiring and\nbottleneck-resistant architectures such as Cayley and expander graphs, avoid\nthis problem but introduce scalability bottlenecks. In particular, the Cayley\ngraphs constructed over $SL(2,\\mathbb{Z}_n)$ exhibit strong theoretical\nproperties, yet suffer from cubic node growth $O(n^3)$, leading to high memory\nusage. To address this, this work introduces Schrier-Coset Graph Propagation\n(SCGP), a group-theoretic augmentation method that enriches node features\nthrough Schreier-coset embeddings without altering the input graph topology.\nSCGP embeds bottleneck-free connectivity patterns into a compact feature space,\nimproving long-range message passing while maintaining computational\nefficiency. Empirical evaluations across standard node and graph classification\nbenchmarks demonstrate that SCGP achieves performance comparable to, or\nexceeding, expander graph and rewired GNN baselines. Furthermore, SCGP exhibits\nparticular advantages in processing hierarchical and modular graph structures,\noffering reduced inference latency, improved scalability, and a low memory\nfootprint, making it suitable for real-time and resource-constrained\napplications."}
{"id": "2505.10457", "pdf": "https://arxiv.org/pdf/2505.10457", "abs": "https://arxiv.org/abs/2505.10457", "authors": ["Matteo Gambella", "Vicente Javier Castro Solar", "Manuel Roveri"], "title": "SEAL: Searching Expandable Architectures for Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "comment": "8 pages, 5 figures", "summary": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios."}
{"id": "2505.10037", "pdf": "https://arxiv.org/pdf/2505.10037", "abs": "https://arxiv.org/abs/2505.10037", "authors": ["Takafumi Ito", "Lysenko Artem", "Tatsuhiko Tsunoda"], "title": "Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction", "categories": ["cs.LG", "cs.AI", "cs.ET", "quant-ph"], "comment": "10 pages, 3 figures", "summary": "Quantum-classical Hybrid Machine Learning (QHML) models are recognized for\ntheir robust performance and high generalization ability even for relatively\nsmall datasets. These qualities offer unique advantages for anti-cancer drug\nresponse prediction, where the number of available samples is typically small.\nHowever, such hybrid models appear to be very sensitive to the data encoding\nused at the interface of a neural network and a quantum circuit, with\nsuboptimal choices leading to stability issues. To address this problem, we\npropose a novel strategy that uses a normalization function based on a\nmoderated gradient version of the $\\tanh$. This method transforms the outputs\nof the neural networks without concentrating them at the extreme value ranges.\nOur idea was evaluated on a dataset of gene expression and drug response\nmeasurements for various cancer cell lines, where we compared the prediction\nperformance of a classical deep learning model and several QHML models. These\nresults confirmed that QHML performed better than the classical models when\ndata was optimally normalized. This study opens up new possibilities for\nbiomedical data analysis using quantum computers."}
{"id": "2505.10407", "pdf": "https://arxiv.org/pdf/2505.10407", "abs": "https://arxiv.org/abs/2505.10407", "authors": ["Wenhao Ding", "Choon Hwai Yap", "Kangjun Ji", "Simão Castro"], "title": "Two-Stage Generative Model for Intracranial Aneurysm Meshes with Morphological Marker Conditioning", "categories": ["cs.LG", "68T07"], "comment": "10 pages, 2 figures", "summary": "A generative model for the mesh geometry of intracranial aneurysms (IA) is\ncrucial for training networks to predict blood flow forces in real time, which\nis a key factor affecting disease progression. This need is necessitated by the\nabsence of a large IA image datasets. Existing shape generation methods\nstruggle to capture realistic IA features and ignore the relationship between\nIA pouches and parent vessels, limiting physiological realism and their\ngeneration cannot be controlled to have specific morphological measurements. We\npropose AneuG, a two-stage Variational Autoencoder (VAE)-based IA mesh\ngenerator. In the first stage, AneuG generates low-dimensional Graph Harmonic\nDeformation (GHD) tokens to encode and reconstruct aneurysm pouch shapes,\nconstrained to morphing energy statistics truths. GHD enables more accurate\nshape encoding than alternatives. In the second stage, AneuG generates parent\nvessels conditioned on GHD tokens, by generating vascular centreline and\npropagating the cross-section. AneuG's IA shape generation can further be\nconditioned to have specific clinically relevant morphological measurements.\nThis is useful for studies to understand shape variations represented by\nclinical measurements, and for flow simulation studies to understand effects of\nspecific clinical shape parameters on fluid dynamics. Source code and\nimplementation details are available at\nhttps://github.com/anonymousaneug/AneuG."}
{"id": "2505.10464", "pdf": "https://arxiv.org/pdf/2505.10464", "abs": "https://arxiv.org/abs/2505.10464", "authors": ["Jiaming Liang", "Lihuan Dai", "Xiaoqi Sheng", "Xiangguang Chen", "Chun Yao", "Guihua Tao", "Qibin Leng", "Honming Cai", "Xi Zhong"], "title": "HWA-UNETR: Hierarchical Window Aggregate UNETR for 3D Multimodal Gastric Lesion Segmentation", "categories": ["eess.IV", "cs.CV"], "comment": "This work has been provisionally accepted for MICCAI 2025", "summary": "Multimodal medical image segmentation faces significant challenges in the\ncontext of gastric cancer lesion analysis. This clinical context is defined by\nthe scarcity of independent multimodal datasets and the imperative to\namalgamate inherently misaligned modalities. As a result, algorithms are\nconstrained to train on approximate data and depend on application migration,\nleading to substantial resource expenditure and a potential decline in analysis\naccuracy. To address those challenges, we have made two major contributions:\nFirst, we publicly disseminate the GCM 2025 dataset, which serves as the first\nlarge-scale, open-source collection of gastric cancer multimodal MRI scans,\nfeaturing professionally annotated FS-T2W, CE-T1W, and ADC images from 500\npatients. Second, we introduce HWA-UNETR, a novel 3D segmentation framework\nthat employs an original HWA block with learnable window aggregation layers to\nestablish dynamic feature correspondences between different modalities'\nanatomical structures, and leverages the innovative tri-orientated fusion mamba\nmechanism for context modeling and capturing long-range spatial dependencies.\nExtensive experiments on our GCM 2025 dataset and the publicly BraTS 2021\ndataset validate the performance of our framework, demonstrating that the new\napproach surpasses existing methods by up to 1.68\\% in the Dice score while\nmaintaining solid robustness. The dataset and code are public via\nhttps://github.com/JeMing-creater/HWA-UNETR."}
{"id": "2505.10043", "pdf": "https://arxiv.org/pdf/2505.10043", "abs": "https://arxiv.org/abs/2505.10043", "authors": ["Yifan Wu", "Lutao Yan", "Yizhang Zhu", "Yinan Mei", "Jiannan Wang", "Nan Tang", "Yuyu Luo"], "title": "Boosting Text-to-Chart Retrieval through Training with Synthesized Semantic Insights", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Charts are crucial for data analysis and decision-making.Text-to-chart\nretrieval systems have become increasingly important for Business Intelligence\n(BI), where users need to find relevant charts that match their analytical\nneeds. These needs can be categorized into precise queries that are\nwell-specified and fuzzy queries that are more exploratory -- both require\nunderstanding the semantics and context of the charts. However, existing\ntext-to-chart retrieval solutions often fail to capture the semantic content\nand contextual information of charts, primarily due to the lack of\ncomprehensive metadata (or semantic insights). To address this limitation, we\npropose a training data development pipeline that automatically synthesizes\nhierarchical semantic insights for charts, covering visual patterns\n(visual-oriented), statistical properties (statistics-oriented), and practical\napplications (task-oriented), which produces 207,498 semantic insights for\n69,166 charts. Based on these, we train a CLIP-based model named ChartFinder to\nlearn better representations of charts for text-to-chart retrieval. Our method\nleverages rich semantic insights during the training phase to develop a model\nthat understands both visual and semantic aspects of charts.To evaluate\ntext-to-chart retrieval performance, we curate the first benchmark, CRBench,\nfor this task with 21,862 charts and 326 text queries from real-world BI\napplications, with ground-truth labels verified by the crowd\nworkers.Experiments show that ChartFinder significantly outperforms existing\nmethods in text-to-chart retrieval tasks across various settings. For precise\nqueries, ChartFinder achieves up to 66.9% NDCG@10, which is 11.58% higher than\nstate-of-the-art models. In fuzzy query tasks, our method also demonstrates\nconsistent improvements, with an average increase of 5% across nearly all\nmetrics."}
{"id": "2505.10422", "pdf": "https://arxiv.org/pdf/2505.10422", "abs": "https://arxiv.org/abs/2505.10422", "authors": ["Daniel Weitekamp", "Christopher MacLellan", "Erik Harpstead", "Kenneth Koedinger"], "title": "Decomposed Inductive Procedure Learning: Learning Academic Tasks with Human-Like Data Efficiency", "categories": ["cs.LG"], "comment": "To appear in CogSci 2025", "summary": "Human learning relies on specialization -- distinct cognitive mechanisms\nworking together to enable rapid learning. In contrast, most modern neural\nnetworks rely on a single mechanism: gradient descent over an objective\nfunction. This raises the question: might human learners' relatively rapid\nlearning from just tens of examples instead of tens of thousands in data-driven\ndeep learning arise from our ability to use multiple specialized mechanisms of\nlearning in combination? We investigate this question through an ablation\nanalysis of inductive human learning simulations in online tutoring\nenvironments. Comparing reinforcement learning to a more data-efficient\n3-mechanism symbolic rule induction approach, we find that decomposing learning\ninto multiple distinct mechanisms significantly improves data efficiency,\nbringing it in line with human learning. Furthermore, we show that this\ndecomposition has a greater impact on efficiency than the distinction between\nsymbolic and subsymbolic learning alone. Efforts to align data-driven machine\nlearning with human learning often overlook the stark difference in learning\nefficiency. Our findings suggest that integrating multiple specialized learning\nmechanisms may be key to bridging this gap."}
{"id": "2505.10492", "pdf": "https://arxiv.org/pdf/2505.10492", "abs": "https://arxiv.org/abs/2505.10492", "authors": ["Taylor L. Bobrow", "Mayank Golhar", "Suchapa Arayakarnkul", "Anthony A. Song", "Saowanee Ngamruengphong", "Nicholas J. Durr"], "title": "Multi-contrast laser endoscopy for in vivo gastrointestinal imaging", "categories": ["eess.IV", "cs.CV", "physics.optics"], "comment": null, "summary": "White light endoscopy is the clinical gold standard for detecting diseases in\nthe gastrointestinal tract. Most applications involve identifying visual\nabnormalities in tissue color, texture, and shape. Unfortunately, the contrast\nof these features is often subtle, causing many clinically relevant cases to go\nundetected. To overcome this challenge, we introduce Multi-contrast Laser\nEndoscopy (MLE): a platform for widefield clinical imaging with rapidly tunable\nspectral, coherent, and directional illumination. We demonstrate three\ncapabilities of MLE: enhancing tissue chromophore contrast with multispectral\ndiffuse reflectance, quantifying blood flow using laser speckle contrast\nimaging, and characterizing mucosal topography using photometric stereo. We\nvalidate MLE with benchtop models, then demonstrate MLE in vivo during clinical\ncolonoscopies. MLE images from 31 polyps demonstrate an approximate three-fold\nimprovement in contrast and a five-fold improvement in color difference\ncompared to white light and narrow band imaging. With the ability to reveal\nmultiple complementary types of tissue contrast while seamlessly integrating\ninto the clinical environment, MLE shows promise as an investigative tool to\nimprove gastrointestinal imaging."}
{"id": "2505.10050", "pdf": "https://arxiv.org/pdf/2505.10050", "abs": "https://arxiv.org/abs/2505.10050", "authors": ["Fahad Almalki", "Mehedi Masud"], "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection."}
{"id": "2505.10423", "pdf": "https://arxiv.org/pdf/2505.10423", "abs": "https://arxiv.org/abs/2505.10423", "authors": ["Ari Karchmer", "Eran Malach"], "title": "The Power of Random Features and the Limits of Distribution-Free Gradient Descent", "categories": ["cs.LG"], "comment": null, "summary": "We study the relationship between gradient-based optimization of parametric\nmodels (e.g., neural networks) and optimization of linear combinations of\nrandom features. Our main result shows that if a parametric model can be\nlearned using mini-batch stochastic gradient descent (bSGD) without making\nassumptions about the data distribution, then with high probability, the target\nfunction can also be approximated using a polynomial-sized combination of\nrandom features. The size of this combination depends on the number of gradient\nsteps and numerical precision used in the bSGD process. This finding reveals\nfundamental limitations of distribution-free learning in neural networks\ntrained by gradient descent, highlighting why making assumptions about data\ndistributions is often crucial in practice. Along the way, we also introduce a\nnew theoretical framework called average probabilistic dimension complexity\n(adc), which extends the probabilistic dimension complexity developed by Kamath\net al. (2020). We prove that adc has a polynomial relationship with statistical\nquery dimension, and use this relationship to demonstrate an infinite\nseparation between adc and standard dimension complexity."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.10055", "pdf": "https://arxiv.org/pdf/2505.10055", "abs": "https://arxiv.org/abs/2505.10055", "authors": ["Ijazul Haq", "Yingjie Zhang", "Irfan Ali Khan"], "title": "PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper evaluates the performance of Large Multimodal Models (LMMs) on\nOptical Character Recognition (OCR) in the low-resource Pashto language.\nNatural Language Processing (NLP) in Pashto faces several challenges due to the\ncursive nature of its script and a scarcity of structured datasets. To address\nthis, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one\nmillion images annotated with bounding boxes at word, line, and document\nlevels, suitable for training and evaluating models based on different\narchitectures, including Convolutional Neural Networks (CNNs) and Transformers.\nPsOCR covers variations across 1,000 unique font families, colors, image sizes,\nand layouts. A benchmark subset of 10K images was selected to evaluate the\nperformance of several LMMs, including seven open-source models: DeepSeek's\nJanus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four\nclosed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results\ndemonstrate that Gemini achieves the best performance among all models, whereas\namong open-source models, Qwen-7B stands out. This work provides an insightful\nassessment of the capabilities and limitations of current LMMs for OCR tasks in\nPashto and establishes a foundation for further research not only in Pashto OCR\nbut also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is\navailable at https://github.com/zirak-ai/PashtoOCR."}
{"id": "2505.10425", "pdf": "https://arxiv.org/pdf/2505.10425", "abs": "https://arxiv.org/abs/2505.10425", "authors": ["Jingyao Wang", "Wenwen Qiang", "Zeen Song", "Changwen Zheng", "Hui Xiong"], "title": "Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) excel at complex tasks thanks to advances in\nreasoning abilities. However, existing methods overlook the trade-off between\nreasoning effectiveness and computational efficiency, often encouraging\nunnecessarily long reasoning chains and wasting tokens. To address this, we\npropose Learning to Think (L2T), an information-theoretic reinforcement\nfine-tuning framework for LLMs to make the models achieve optimal reasoning\nwith fewer tokens. Specifically, L2T treats each query-response interaction as\na hierarchical session of multiple episodes and proposes a universal dense\nprocess reward, i.e., quantifies the episode-wise information gain in\nparameters, requiring no extra annotations or task-specific evaluators. We\npropose a method to quickly estimate this reward based on PAC-Bayes bounds and\nthe Fisher information matrix. Theoretical analyses show that it significantly\nreduces computational complexity with high estimation accuracy. By immediately\nrewarding each episode's contribution and penalizing excessive updates, L2T\noptimizes the model via reinforcement learning to maximize the use of each\nepisode and achieve effective updates. Empirical results on various reasoning\nbenchmarks and base models demonstrate the advantage of L2T across different\ntasks, boosting both reasoning effectiveness and efficiency."}
{"id": "2505.10526", "pdf": "https://arxiv.org/pdf/2505.10526", "abs": "https://arxiv.org/abs/2505.10526", "authors": ["Mugilan Ganesan", "Shane Segal", "Ankur Aggarwal", "Nish Sinnadurai", "Sean Lie", "Vithursan Thangarasa"], "title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Main paper: 11 pp., 4 figs., 3 tabs.; Supplementary: 2 pp", "summary": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs."}
{"id": "2505.10066", "pdf": "https://arxiv.org/pdf/2505.10066", "abs": "https://arxiv.org/abs/2505.10066", "authors": ["Michael Fire", "Yitzhak Elbazis", "Adi Wasenstein", "Lior Rokach"], "title": "Dark LLMs: The Growing Threat of Unaligned AI Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50, 68T05, 68P25", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated."}
{"id": "2505.10432", "pdf": "https://arxiv.org/pdf/2505.10432", "abs": "https://arxiv.org/abs/2505.10432", "authors": ["Randy J. Chase", "Katherine Haynes", "Lander Ver Hoef", "Imme Ebert-Uphoff"], "title": "Score-based diffusion nowcasting of GOES imagery", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "Clouds and precipitation are important for understanding weather and climate.\nSimulating clouds and precipitation with traditional numerical weather\nprediction is challenging because of the sub-grid parameterizations required.\nMachine learning has been explored for forecasting clouds and precipitation,\nbut early machine learning methods often created blurry forecasts. In this\npaper we explore a newer method, named score-based diffusion, to nowcast (zero\nto three hour forecast) clouds and precipitation. We discuss the background and\nintuition of score-based diffusion models - thus providing a starting point for\nthe community - while exploring the methodology's use for nowcasting\ngeostationary infrared imagery. We experiment with three main types of\ndiffusion models: a standard score-based diffusion model (Diff); a residual\ncorrection diffusion model (CorrDiff); and a latent diffusion model (LDM). Our\nresults show that the diffusion models are able to not only advect existing\nclouds, but also generate and decay clouds, including convective initiation.\nThese results are surprising because the forecasts are initiated with only the\npast 20 mins of infrared satellite imagery. A case study qualitatively shows\nthe preservation of high resolution features longer into the forecast than a\nconventional mean-squared error trained U-Net. The best of the three diffusion\nmodels tested was the CorrDiff approach, outperforming all other diffusion\nmodels, the traditional U-Net, and a persistence forecast by one to two kelvin\non root mean squared error. The diffusion models also enable out-of-the-box\nensemble generation, which shows skillful calibration, with the spread of the\nensemble correlating well to the error."}
{"id": "2505.10558", "pdf": "https://arxiv.org/pdf/2505.10558", "abs": "https://arxiv.org/abs/2505.10558", "authors": ["Peiying Zhang", "Nanxuan Zhao", "Jing Liao"], "title": "Style Customization of Text-to-Vector Generation with Image Diffusion Priors", "categories": ["cs.GR", "cs.CV"], "comment": "Accepted by SIGGRAPH 2025 (Conference Paper). Project page:\n  https://customsvg.github.io", "summary": "Scalable Vector Graphics (SVGs) are highly favored by designers due to their\nresolution independence and well-organized layer structure. Although existing\ntext-to-vector (T2V) generation methods can create SVGs from text prompts, they\noften overlook an important need in practical applications: style\ncustomization, which is vital for producing a collection of vector graphics\nwith consistent visual appearance and coherent aesthetics. Extending existing\nT2V methods for style customization poses certain challenges.\nOptimization-based T2V models can utilize the priors of text-to-image (T2I)\nmodels for customization, but struggle with maintaining structural regularity.\nOn the other hand, feed-forward T2V models can ensure structural regularity,\nyet they encounter difficulties in disentangling content and style due to\nlimited SVG training data.\n  To address these challenges, we propose a novel two-stage style customization\npipeline for SVG generation, making use of the advantages of both feed-forward\nT2V models and T2I image priors. In the first stage, we train a T2V diffusion\nmodel with a path-level representation to ensure the structural regularity of\nSVGs while preserving diverse expressive capabilities. In the second stage, we\ncustomize the T2V diffusion model to different styles by distilling customized\nT2I models. By integrating these techniques, our pipeline can generate\nhigh-quality and diverse SVGs in custom styles based on text prompts in an\nefficient feed-forward manner. The effectiveness of our method has been\nvalidated through extensive experiments. The project page is\nhttps://customsvg.github.io."}
{"id": "2505.10073", "pdf": "https://arxiv.org/pdf/2505.10073", "abs": "https://arxiv.org/abs/2505.10073", "authors": ["Rathin Chandra Shit", "Sharmila Subudhi"], "title": "Multi-Robot Task Allocation for Homogeneous Tasks with Collision Avoidance via Spatial Clustering", "categories": ["cs.RO", "cs.AI"], "comment": "5 pages, 4 figures, Scheduled for presentation at an upcoming\n  conference", "summary": "In this paper, a novel framework is presented that achieves a combined\nsolution based on Multi-Robot Task Allocation (MRTA) and collision avoidance\nwith respect to homogeneous measurement tasks taking place in industrial\nenvironments. The spatial clustering we propose offers to simultaneously solve\nthe task allocation problem and deal with collision risks by cutting the\nworkspace into distinguishable operational zones for each robot. To divide task\nsites and to schedule robot routes within corresponding clusters, we use\nK-means clustering and the 2-Opt algorithm. The presented framework shows\nsatisfactory performance, where up to 93\\% time reduction (1.24s against\n17.62s) with a solution quality improvement of up to 7\\% compared to the best\nperforming method is demonstrated. Our method also completely eliminates\ncollision points that persist in comparative methods in a most significant\nsense. Theoretical analysis agrees with the claim that spatial partitioning\nunifies the apparently disjoint tasks allocation and collision avoidance\nproblems under conditions of many identical tasks to be distributed over sparse\ngeographical areas. Ultimately, the findings in this work are of substantial\nimportance for real world applications where both computational efficiency and\noperation free from collisions is of paramount importance."}
{"id": "2505.10438", "pdf": "https://arxiv.org/pdf/2505.10438", "abs": "https://arxiv.org/abs/2505.10438", "authors": ["David Grasev"], "title": "Identification and Optimal Nonlinear Control of Turbojet Engine Using Koopman Eigenfunction Model", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "51 pages, 28 figures", "summary": "Gas turbine engines represent complex highly nonlinear dynamical systems.\nDeriving their physics-based models can be challenging as it requires\nperformance characteristics, that are not always available, and one often has\nto make many simplifying assumptions. In this paper, the limitations of\nconventional experimental methods used to derive component-level and locally\nlinear parameter-varying models are discussed and addressed by employing\nidentification techniques based on data collected from standard engine\noperation under closed-loop control. The rotor dynamics were estimated using\nthe sparse identification of nonlinear dynamics. Subsequently, the autonomous\npart of the dynamics was mapped into an optimally constructed Koopman\neigenfunction space. The process included eigenvalue optimization using\nmetaheuristic algorithms and temporal projection, followed by gradient-based\neigenfunction identification. The resulting Koopman model was validated against\nan in-house reference component-level model. A globally optimal nonlinear\nfeedback controller and a Kalman estimator were then designed in the\neigenfunction space and compared to the classical and gain-scheduled\nproportional-integral controllers, as well as a proposed internal model control\napproach. The eigenmode structure allowed targeting individual modes during the\noptimization process, resulting in a better performance tuning. The results\nshowed that the Koopman-based controller outperformed the other benchmark\ncontrollers in both reference tracking and disturbance rejection, under\nsea-level and varying flight conditions, due to its global nature."}
{"id": "2505.10101", "pdf": "https://arxiv.org/pdf/2505.10101", "abs": "https://arxiv.org/abs/2505.10101", "authors": ["Jongmin Jung", "Dasaem Jeong"], "title": "LAV: Audio-Driven Dynamic Visual Generation with Neural Compression and StyleGAN2", "categories": ["cs.SD", "cs.AI", "cs.GR", "cs.MM", "eess.AS"], "comment": "Paper accepted at ISEA 2025, The 30th International Symposium on\n  Electronic/Emerging Art, Seoul, Republic of Korea, 23 - 29 May 2025", "summary": "This paper introduces LAV (Latent Audio-Visual), a system that integrates\nEnCodec's neural audio compression with StyleGAN2's generative capabilities to\nproduce visually dynamic outputs driven by pre-recorded audio. Unlike previous\nworks that rely on explicit feature mappings, LAV uses EnCodec embeddings as\nlatent representations, directly transformed into StyleGAN2's style latent\nspace via randomly initialized linear mapping. This approach preserves semantic\nrichness in the transformation, enabling nuanced and semantically coherent\naudio-visual translations. The framework demonstrates the potential of using\npretrained audio compression models for artistic and computational\napplications."}
{"id": "2505.10441", "pdf": "https://arxiv.org/pdf/2505.10441", "abs": "https://arxiv.org/abs/2505.10441", "authors": ["Filippo Leveni", "Luca Magri", "Giacomo Boracchi", "Cesare Alippi"], "title": "PIF: Anomaly detection via preference embedding", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)", "summary": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space."}
{"id": "2505.10105", "pdf": "https://arxiv.org/pdf/2505.10105", "abs": "https://arxiv.org/abs/2505.10105", "authors": ["Zibin Dong", "Fei Ni", "Yifu Yuan", "Yinchuan Li", "Jianye Hao"], "title": "EmbodiedMAE: A Unified 3D Multi-Modal Representation for Robot Manipulation", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "We present EmbodiedMAE, a unified 3D multi-modal representation for robot\nmanipulation. Current approaches suffer from significant domain gaps between\ntraining datasets and robot manipulation tasks, while also lacking model\narchitectures that can effectively incorporate 3D information. To overcome\nthese limitations, we enhance the DROID dataset with high-quality depth maps\nand point clouds, constructing DROID-3D as a valuable supplement for 3D\nembodied vision research. Then we develop EmbodiedMAE, a multi-modal masked\nautoencoder that simultaneously learns representations across RGB, depth, and\npoint cloud modalities through stochastic masking and cross-modal fusion.\nTrained on DROID-3D, EmbodiedMAE consistently outperforms state-of-the-art\nvision foundation models (VFMs) in both training efficiency and final\nperformance across 70 simulation tasks and 20 real-world robot manipulation\ntasks on two robot platforms. The model exhibits strong scaling behavior with\nsize and promotes effective policy learning from 3D inputs. Experimental\nresults establish EmbodiedMAE as a reliable unified 3D multi-modal VFM for\nembodied AI systems, particularly in precise tabletop manipulation settings\nwhere spatial perception is critical."}
{"id": "2505.10457", "pdf": "https://arxiv.org/pdf/2505.10457", "abs": "https://arxiv.org/abs/2505.10457", "authors": ["Matteo Gambella", "Vicente Javier Castro Solar", "Manuel Roveri"], "title": "SEAL: Searching Expandable Architectures for Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "comment": "8 pages, 5 figures", "summary": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios."}
{"id": "2505.10120", "pdf": "https://arxiv.org/pdf/2505.10120", "abs": "https://arxiv.org/abs/2505.10120", "authors": ["Guillaume Godin"], "title": "All You Need Is Synthetic Task Augmentation", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 3 Figures, 6 tables", "summary": "Injecting rule-based models like Random Forests into differentiable neural\nnetwork frameworks remains an open challenge in machine learning. Recent\nadvancements have demonstrated that pretrained models can generate efficient\nmolecular embeddings. However, these approaches often require extensive\npretraining and additional techniques, such as incorporating posterior\nprobabilities, to boost performance. In our study, we propose a novel strategy\nthat jointly trains a single Graph Transformer neural network on both sparse\nmultitask molecular property experimental targets and synthetic targets derived\nfrom XGBoost models trained on Osmordred molecular descriptors. These synthetic\ntasks serve as independent auxiliary tasks. Our results show consistent and\nsignificant performance improvement across all 19 molecular property prediction\ntasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms\nthe XGBoost single-task learner. This demonstrates that synthetic task\naugmentation is an effective method for enhancing neural model performance in\nmultitask molecular property prediction without the need for feature injection\nor pretraining."}
{"id": "2505.10465", "pdf": "https://arxiv.org/pdf/2505.10465", "abs": "https://arxiv.org/abs/2505.10465", "authors": ["Yizhou liu", "Ziming Liu", "Jeff Gore"], "title": "Superposition Yields Robust Neural Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages, 23 figures", "summary": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters."}
{"id": "2505.10128", "pdf": "https://arxiv.org/pdf/2505.10128", "abs": "https://arxiv.org/abs/2505.10128", "authors": ["Huy Q. Le", "Latif U. Khan", "Choong Seon Hong"], "title": "Robust Federated Learning on Edge Devices with Domain Heterogeneity", "categories": ["cs.LG", "cs.AI"], "comment": "IWCMC 2025", "summary": "Federated Learning (FL) allows collaborative training while ensuring data\nprivacy across distributed edge devices, making it a popular solution for\nprivacy-sensitive applications. However, FL faces significant challenges due to\nstatistical heterogeneity, particularly domain heterogeneity, which impedes the\nglobal mode's convergence. In this study, we introduce a new framework to\naddress this challenge by improving the generalization ability of the FL global\nmodel under domain heterogeneity, using prototype augmentation. Specifically,\nwe introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a\nprototype-based FL framework designed to enhance feature diversity and model\nrobustness. FedAPC leverages prototypes derived from the mean features of\naugmented data to capture richer representations. By aligning local features\nwith global prototypes, we enable the model to learn meaningful semantic\nfeatures while reducing overfitting to any specific domain. Experimental\nresults on the Office-10 and Digits datasets illustrate that our framework\noutperforms SOTA baselines, demonstrating superior performance."}
{"id": "2505.10472", "pdf": "https://arxiv.org/pdf/2505.10472", "abs": "https://arxiv.org/abs/2505.10472", "authors": ["Agnik Saha", "Victoria Churchill", "Anny D. Rodriguez", "Ugur Kursuncu", "Muhammed Y. Idris"], "title": "Large Language Models for Cancer Communication: Evaluating Linguistic Quality, Safety, and Accessibility in Generative AI", "categories": ["cs.LG"], "comment": null, "summary": "Effective communication about breast and cervical cancers remains a\npersistent health challenge, with significant gaps in public understanding of\ncancer prevention, screening, and treatment, potentially leading to delayed\ndiagnoses and inadequate treatments. This study evaluates the capabilities and\nlimitations of Large Language Models (LLMs) in generating accurate, safe, and\naccessible cancer-related information to support patient understanding. We\nevaluated five general-purpose and three medical LLMs using a mixed-methods\nevaluation framework across linguistic quality, safety and trustworthiness, and\ncommunication accessibility and affectiveness. Our approach utilized\nquantitative metrics, qualitative expert ratings, and statistical analysis\nusing Welch's ANOVA, Games-Howell, and Hedges' g. Our results show that\ngeneral-purpose LLMs produced outputs of higher linguistic quality and\naffectiveness, while medical LLMs demonstrate greater communication\naccessibility. However, medical LLMs tend to exhibit higher levels of potential\nharm, toxicity, and bias, reducing their performance in safety and\ntrustworthiness. Our findings indicate a duality between domain-specific\nknowledge and safety in health communications. The results highlight the need\nfor intentional model design with targeted improvements, particularly in\nmitigating harm and bias, and improving safety and affectiveness. This study\nprovides a comprehensive evaluation of LLMs for cancer communication, offering\ncritical insights for improving AI-generated health content and informing\nfuture development of accurate, safe, and accessible digital health tools."}
{"id": "2505.10134", "pdf": "https://arxiv.org/pdf/2505.10134", "abs": "https://arxiv.org/abs/2505.10134", "authors": ["Guangjin Pan", "Kaixuan Huang", "Hui Chen", "Shunqing Zhang", "Christian Häger", "Henk Wymeersch"], "title": "Large Wireless Localization Model (LWLM): A Foundation Model for Positioning in 6G Networks", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "13 pages,16 figures.This work has been submitted to the IEEE for\n  possible publication", "summary": "Accurate and robust localization is a critical enabler for emerging 5G and 6G\napplications, including autonomous driving, extended reality (XR), and smart\nmanufacturing. While data-driven approaches have shown promise, most existing\nmodels require large amounts of labeled data and struggle to generalize across\ndeployment scenarios and wireless configurations. To address these limitations,\nwe propose a foundation-model-based solution tailored for wireless\nlocalization. We first analyze how different self-supervised learning (SSL)\ntasks acquire general-purpose and task-specific semantic features based on\ninformation bottleneck (IB) theory. Building on this foundation, we design a\npretraining methodology for the proposed Large Wireless Localization Model\n(LWLM). Specifically, we propose an SSL framework that jointly optimizes three\ncomplementary objectives: (i) spatial-frequency masked channel modeling\n(SF-MCM), (ii) domain-transformation invariance (DTI), and (iii)\nposition-invariant contrastive learning (PICL). These objectives jointly\ncapture the underlying semantics of wireless channel from multiple\nperspectives. We further design lightweight decoders for key downstream tasks,\nincluding time-of-arrival (ToA) estimation, angle-of-arrival (AoA) estimation,\nsingle base station (BS) localization, and multiple BS localization.\nComprehensive experimental results confirm that LWLM consistently surpasses\nboth model-based and supervised learning baselines across all localization\ntasks. In particular, LWLM achieves 26.0%--87.5% improvement over transformer\nmodels without pretraining, and exhibits strong generalization under\nlabel-limited fine-tuning and unseen BS configurations, confirming its\npotential as a foundation model for wireless localization."}
{"id": "2505.10475", "pdf": "https://arxiv.org/pdf/2505.10475", "abs": "https://arxiv.org/abs/2505.10475", "authors": ["Mouxiang Chen", "Binyuan Hui", "Zeyu Cui", "Jiaxi Yang", "Dayiheng Liu", "Jianling Sun", "Junyang Lin", "Zhongxin Liu"], "title": "Parallel Scaling Law for Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "It is commonly believed that scaling language models should commit a\nsignificant space or time cost, by increasing the parameters (parameter\nscaling) or output tokens (inference-time scaling). We introduce the third and\nmore inference-efficient scaling paradigm: increasing the model's parallel\ncomputation during both training and inference time. We apply $P$ diverse and\nlearnable transformations to the input, execute forward passes of the model in\nparallel, and dynamically aggregate the $P$ outputs. This method, namely\nparallel scaling (ParScale), scales parallel computation by reusing existing\nparameters and can be applied to any model structure, optimization procedure,\ndata, or task. We theoretically propose a new scaling law and validate it\nthrough large-scale pre-training, which shows that a model with $P$ parallel\nstreams is similar to scaling the parameters by $O(\\log P)$ while showing\nsuperior inference efficiency. For example, ParScale can use up to 22$\\times$\nless memory increase and 6$\\times$ less latency increase compared to parameter\nscaling that achieves the same performance improvement. It can also recycle an\noff-the-shelf pre-trained model into a parallelly scaled one by post-training\non a small amount of tokens, further reducing the training budget. The new\nscaling law we discovered potentially facilitates the deployment of more\npowerful models in low-resource scenarios, and provides an alternative\nperspective for the role of computation in machine learning."}
{"id": "2505.10167", "pdf": "https://arxiv.org/pdf/2505.10167", "abs": "https://arxiv.org/abs/2505.10167", "authors": ["Saikat Barua", "Mostafizur Rahman", "Shehenaz Khaled", "Md Jafor Sadek", "Rafiul Islam", "Shahnewaz Siddique"], "title": "QuXAI: Explainers for Hybrid Quantum Machine Learning Models", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": "16 pages, 6 figures, 7 equations", "summary": "The emergence of hybrid quantum-classical machine learning (HQML) models\nopens new horizons of computational intelligence but their fundamental\ncomplexity frequently leads to black box behavior that undermines transparency\nand reliability in their application. Although XAI for quantum systems still in\nits infancy, a major research gap is evident in robust global and local\nexplainability approaches that are designed for HQML architectures that employ\nquantized feature encoding followed by classical learning. The gap is the focus\nof this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an\nexplainer for explaining feature importance in these hybrid systems. Our model\nentails the creation of HQML models incorporating quantum feature maps, the use\nof Q-MEDLEY, which combines feature based inferences, preserving the quantum\ntransformation stage and visualizing the resulting attributions. Our result\nshows that Q-MEDLEY delineates influential classical aspects in HQML models, as\nwell as separates their noise, and competes well against established XAI\ntechniques in classical validation settings. Ablation studies more\nsignificantly expose the virtues of the composite structure used in Q-MEDLEY.\nThe implications of this work are critically important, as it provides a route\nto improve the interpretability and reliability of HQML models, thus promoting\ngreater confidence and being able to engage in safer and more responsible use\nof quantum-enhanced AI technology."}
{"id": "2505.10482", "pdf": "https://arxiv.org/pdf/2505.10482", "abs": "https://arxiv.org/abs/2505.10482", "authors": ["Ningyuan Yang", "Jiaxuan Gao", "Feng Gao", "Yi Wu", "Chao Yu"], "title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages for main text, 23 pages in total, submitted to Neurips, 13\n  figures", "summary": "Diffusion policies, widely adopted in decision-making scenarios such as\nrobotics, gaming and autonomous driving, are capable of learning diverse skills\nfrom demonstration data due to their high representation power. However, the\nsub-optimal and limited coverage of demonstration data could lead to diffusion\npolicies that generate sub-optimal trajectories and even catastrophic failures.\nWhile reinforcement learning (RL)-based fine-tuning has emerged as a promising\nsolution to address these limitations, existing approaches struggle to\neffectively adapt Proximal Policy Optimization (PPO) to diffusion models. This\nchallenge stems from the computational intractability of action likelihood\nestimation during the denoising process, which leads to complicated\noptimization objectives. In our experiments starting from randomly initialized\npolicies, we find that online tuning of Diffusion Policies demonstrates much\nlower sample efficiency compared to directly applying PPO on MLP policies\n(MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework\nthat reformulates Diffusion Policy as a noise-conditioned deterministic policy.\nBy treating each denoising step as a differentiable transformation conditioned\non pre-sampled noise, NCDPO enables tractable likelihood evaluation and\ngradient backpropagation through all diffusion timesteps. Our experiments\ndemonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when\ntraining from scratch, outperforming existing methods in both sample efficiency\nand final performance across diverse benchmarks, including continuous robot\ncontrol and multi-agent game scenarios. Furthermore, our experimental results\nshow that our method is robust to the number denoising timesteps in the\nDiffusion Policy."}
{"id": "2505.10169", "pdf": "https://arxiv.org/pdf/2505.10169", "abs": "https://arxiv.org/abs/2505.10169", "authors": ["Matthias Kümmerer", "Harneet Khanuja", "Matthias Bethge"], "title": "Modeling Saliency Dataset Bias", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes."}
{"id": "2505.10484", "pdf": "https://arxiv.org/pdf/2505.10484", "abs": "https://arxiv.org/abs/2505.10484", "authors": ["Andrea Baisero", "Rupali Bhati", "Shuo Liu", "Aathira Pillai", "Christopher Amato"], "title": "Fixing Incomplete Value Function Decomposition for Multi-Agent Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Value function decomposition methods for cooperative multi-agent\nreinforcement learning compose joint values from individual per-agent\nutilities, and train them using a joint objective. To ensure that the action\nselection process between individual utilities and joint values remains\nconsistent, it is imperative for the composition to satisfy the\nindividual-global max (IGM) property. Although satisfying IGM itself is\nstraightforward, most existing methods (e.g., VDN, QMIX) have limited\nrepresentation capabilities and are unable to represent the full class of IGM\nvalues, and the one exception that has no such limitation (QPLEX) is\nunnecessarily complex. In this work, we present a simple formulation of the\nfull class of IGM values that naturally leads to the derivation of QFIX, a\nnovel family of value function decomposition models that expand the\nrepresentation capabilities of prior models by means of a thin \"fixing\" layer.\nWe derive multiple variants of QFIX, and implement three variants in two\nwell-known multi-agent frameworks. We perform an empirical evaluation on\nmultiple SMACv2 and Overcooked environments, which confirms that QFIX (i)\nsucceeds in enhancing the performance of prior methods, (ii) learns more stably\nand performs better than its main competitor QPLEX, and (iii) achieves this\nwhile employing the simplest and smallest mixing models."}
{"id": "2505.10172", "pdf": "https://arxiv.org/pdf/2505.10172", "abs": "https://arxiv.org/abs/2505.10172", "authors": ["Zeyan Li", "Libing Chen", "Yin Tang"], "title": "Does Scaling Law Apply in Time Series Forecasting?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Rapid expansion of model size has emerged as a key challenge in time series\nforecasting. From early Transformer with tens of megabytes to recent\narchitectures like TimesNet with thousands of megabytes, performance gains have\noften come at the cost of exponentially increasing parameter counts. But is\nthis scaling truly necessary? To question the applicability of the scaling law\nin time series forecasting, we propose Alinear, an ultra-lightweight\nforecasting model that achieves competitive performance using only k-level\nparameters. We introduce a horizon-aware adaptive decomposition mechanism that\ndynamically rebalances component emphasis across different forecast lengths,\nalongside a progressive frequency attenuation strategy that achieves stable\nprediction in various forecasting horizons without incurring the computational\noverhead of attention mechanisms. Extensive experiments on seven benchmark\ndatasets demonstrate that Alinear consistently outperforms large-scale models\nwhile using less than 1% of their parameters, maintaining strong accuracy\nacross both short and ultra-long forecasting horizons. Moreover, to more fairly\nevaluate model efficiency, we propose a new parameter-aware evaluation metric\nthat highlights the superiority of ALinear under constrained model budgets. Our\nanalysis reveals that the relative importance of trend and seasonal components\nvaries depending on data characteristics rather than following a fixed pattern,\nvalidating the necessity of our adaptive design. This work challenges the\nprevailing belief that larger models are inherently better and suggests a\nparadigm shift toward more efficient time series modeling."}
{"id": "2505.10495", "pdf": "https://arxiv.org/pdf/2505.10495", "abs": "https://arxiv.org/abs/2505.10495", "authors": ["Vibha Belavadi", "Tushar Vatsa", "Dewang Sultania", "Suhas Suresha", "Ishita Verma", "Cheng Chen", "Tracy Holloway King", "Michael Friedrich"], "title": "RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs", "categories": ["cs.LG", "cs.CL"], "comment": "Proceedings of the 4th International Workshop on Knowledge-Augmented\n  Methods for Natural Language Processing", "summary": "This paper addresses fine-tuning Large Language Models (LLMs) for function\ncalling tasks when real user interaction data is unavailable. In digital\ncontent creation tools, where users express their needs through natural\nlanguage queries that must be mapped to API calls, the lack of real-world\ntask-specific data and privacy constraints for training on it necessitate\nsynthetic data generation. Existing approaches to synthetic data generation\nfall short in diversity and complexity, failing to replicate real-world data\ndistributions and leading to suboptimal performance after LLM fine-tuning. We\npresent a novel router-based architecture that leverages domain resources like\ncontent metadata and structured knowledge graphs, along with text-to-text and\nvision-to-text language models to generate high-quality synthetic training\ndata. Our architecture's flexible routing mechanism enables synthetic data\ngeneration that matches observed real-world distributions, addressing a\nfundamental limitation of traditional approaches. Evaluation on a comprehensive\nset of real user queries demonstrates significant improvements in both function\nclassification accuracy and API parameter selection. Models fine-tuned with our\nsynthetic data consistently outperform traditional approaches, establishing new\nbenchmarks for function calling tasks."}
{"id": "2505.10183", "pdf": "https://arxiv.org/pdf/2505.10183", "abs": "https://arxiv.org/abs/2505.10183", "authors": ["Jieke Lin", "Wanyu Wang", "Longxiang Yin", "Yinhe Han"], "title": "KAITIAN: A Unified Communication Framework for Enabling Efficient Collaboration Across Heterogeneous Accelerators in Embodied AI Systems", "categories": ["cs.DC", "cs.AI"], "comment": "9 pages, 4 figures. Jieke Lin and Wanyu Wang contributed equally to\n  this work", "summary": "Embodied Artificial Intelligence (AI) systems, such as autonomous robots and\nintelligent vehicles, are increasingly reliant on diverse heterogeneous\naccelerators (e.g., GPGPUs, NPUs, FPGAs) to meet stringent real-time processing\nand energy-efficiency demands. However, the proliferation of vendor-specific\nproprietary communication libraries creates significant interoperability\nbarriers, hindering seamless collaboration between different accelerator types\nand leading to suboptimal resource utilization and performance bottlenecks in\ndistributed AI workloads. This paper introduces KAITIAN, a novel distributed\ncommunication framework designed to bridge this gap. KAITIAN provides a unified\nabstraction layer that intelligently integrates vendor-optimized communication\nlibraries for intra-group efficiency with general-purpose communication\nprotocols for inter-group interoperability. Crucially, it incorporates a\nload-adaptive scheduling mechanism that dynamically balances computational\ntasks across heterogeneous devices based on their real-time performance\ncharacteristics. Implemented as an extension to PyTorch and rigorously\nevaluated on a testbed featuring NVIDIA GPUs and Cambricon MLUs, KAITIAN\ndemonstrates significant improvements in resource utilization and scalability\nfor distributed training tasks. Experimental results show that KAITIAN can\naccelerate training time by up to 42% compared to baseline homogeneous systems,\nwhile incurring minimal communication overhead (2.8--4.3%) and maintaining\nmodel accuracy. KAITIAN paves the way for more flexible and powerful\nheterogeneous computing in complex embodied AI applications."}
{"id": "2505.10515", "pdf": "https://arxiv.org/pdf/2505.10515", "abs": "https://arxiv.org/abs/2505.10515", "authors": ["Seongun Kim", "Sol A Kim", "Geonhyeong Kim", "Enver Menadjiev", "Chanwoo Lee", "Seongwook Chung", "Nari Kim", "Jaesik Choi"], "title": "PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, post hoc explanation methods have emerged to enhance model\ntransparency by attributing model outputs to input features. However, these\nmethods face challenges due to their specificity to certain neural network\narchitectures and data modalities. Existing explainable artificial intelligence\n(XAI) frameworks have attempted to address these challenges but suffer from\nseveral limitations. These include limited flexibility to diverse model\narchitectures and data modalities due to hard-coded implementations, a\nrestricted number of supported XAI methods because of the requirements for\nlayer-specific operations of attribution methods, and sub-optimal\nrecommendations of explanations due to the lack of evaluation and optimization\nphases. Consequently, these limitations impede the adoption of XAI technology\nin real-world applications, making it difficult for practitioners to select the\noptimal explanation method for their domain. To address these limitations, we\nintroduce \\textbf{PnPXAI}, a universal XAI framework that supports diverse data\nmodalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI\nautomatically detects model architectures, recommends applicable explanation\nmethods, and optimizes hyperparameters for optimal explanations. We validate\nthe framework's effectiveness through user surveys and showcase its versatility\nacross various domains, including medicine and finance."}
{"id": "2505.10185", "pdf": "https://arxiv.org/pdf/2505.10185", "abs": "https://arxiv.org/abs/2505.10185", "authors": ["Seongyun Lee", "Seungone Kim", "Minju Seo", "Yongrae Jo", "Dongyoung Go", "Hyeonbin Hwang", "Jinho Park", "Xiang Yue", "Sean Welleck", "Graham Neubig", "Moontae Lee", "Minjoon Seo"], "title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think", "categories": ["cs.CL", "cs.AI"], "comment": "Work in progress", "summary": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of\nmodern large language models, but our understanding of the reasoning strategies\nunderlying these capabilities remains limited. While some prior works have\nattempted to categorize CoTs using predefined strategy types, such approaches\nare constrained by human intuition and fail to capture the full diversity of\nmodel behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up\nframework for analyzing and steering model reasoning. Our method automatically\nextracts diverse reasoning criteria from model-generated CoTs, embeds them into\na semantic space, clusters them into representative categories, and derives\ncontrastive rubrics to interpret reasoning behavior. Human evaluations show\nthat this framework produces more interpretable and comprehensive analyses than\nexisting methods. Moreover, we demonstrate that this understanding enables\nperformance gains: we can predict which strategy a model is likely to use and\nguide it toward more effective alternatives. Finally, we provide practical\ninsights, such as that training data format (e.g., free-form vs.\nmultiple-choice) has a far greater impact on reasoning behavior than data\ndomain, underscoring the importance of format-aware model design."}
{"id": "2505.10526", "pdf": "https://arxiv.org/pdf/2505.10526", "abs": "https://arxiv.org/abs/2505.10526", "authors": ["Mugilan Ganesan", "Shane Segal", "Ankur Aggarwal", "Nish Sinnadurai", "Sean Lie", "Vithursan Thangarasa"], "title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Main paper: 11 pp., 4 figs., 3 tabs.; Supplementary: 2 pp", "summary": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs."}
{"id": "2505.10191", "pdf": "https://arxiv.org/pdf/2505.10191", "abs": "https://arxiv.org/abs/2505.10191", "authors": ["Qingyu Zheng", "Qi Shao", "Guijun Han", "Wei Li", "Hong Li", "Xuan Wang"], "title": "LanTu: Dynamics-Enhanced Deep Learning for Eddy-Resolving Ocean Forecasting", "categories": ["physics.ao-ph", "cs.AI", "cs.LG", "nlin.CD"], "comment": "22 pages, 6 figures", "summary": "Mesoscale eddies dominate the spatiotemporal multiscale variability of the\nocean, and their impact on the energy cascade of the global ocean cannot be\nignored. Eddy-resolving ocean forecasting is providing more reliable protection\nfor fisheries and navigational safety, but also presents significant scientific\nchallenges and high computational costs for traditional numerical models.\nArtificial intelligence (AI)-based weather and ocean forecasting systems are\nbecoming powerful tools that balance forecast performance with computational\nefficiency. However, the complex multiscale features in the ocean dynamical\nsystem make AI models still face many challenges in mesoscale eddy forecasting\n(especially regional modelling). Here, we develop LanTu, a regional\neddy-resolving ocean forecasting system based on dynamics-enhanced deep\nlearning. We incorporate cross-scale interactions into LanTu and construct\nmultiscale physical constraint for optimising LanTu guided by knowledge of eddy\ndynamics in order to improve the forecasting skill of LanTu for mesoscale\nevolution. The results show that LanTu outperforms the existing advanced\noperational numerical ocean forecasting system (NOFS) and AI-based ocean\nforecasting system (AI-OFS) in temperature, salinity, sea level anomaly and\ncurrent prediction, with a lead time of more than 10 days. Our study highlights\nthat dynamics-enhanced deep learning (LanTu) can be a powerful paradigm for\neddy-resolving ocean forecasting."}
{"id": "2505.10545", "pdf": "https://arxiv.org/pdf/2505.10545", "abs": "https://arxiv.org/abs/2505.10545", "authors": ["Amira Alakhdar", "Barnabas Poczos", "Newell Washburn"], "title": "Pharmacophore-Conditioned Diffusion Model for Ligand-Based De Novo Drug Design", "categories": ["cs.LG"], "comment": null, "summary": "Developing bioactive molecules remains a central, time- and cost-heavy\nchallenge in drug discovery, particularly for novel targets lacking structural\nor functional data. Pharmacophore modeling presents an alternative for\ncapturing the key features required for molecular bioactivity against a\nbiological target. In this work, we present PharmaDiff, a\npharmacophore-conditioned diffusion model for 3D molecular generation.\nPharmaDiff employs a transformer-based architecture to integrate an atom-based\nrepresentation of the 3D pharmacophore into the generative process, enabling\nthe precise generation of 3D molecular graphs that align with predefined\npharmacophore hypotheses. Through comprehensive testing, PharmaDiff\ndemonstrates superior performance in matching 3D pharmacophore constraints\ncompared to ligand-based drug design methods. Additionally, it achieves higher\ndocking scores across a range of proteins in structure-based drug design,\nwithout the need for target protein structures. By integrating pharmacophore\nmodeling with 3D generative techniques, PharmaDiff offers a powerful and\nflexible framework for rational drug design."}
{"id": "2505.10197", "pdf": "https://arxiv.org/pdf/2505.10197", "abs": "https://arxiv.org/abs/2505.10197", "authors": ["Anjali de Silva", "Gang Chen", "Hui Ma", "Seyed Mohammad Nekooei", "Xingquan Zuo"], "title": "Advancing Community Detection with Graph Convolutional Neural Networks: Bridging Topological and Attributive Cohesion", "categories": ["cs.SI", "cs.AI"], "comment": "This paper has been accepted by IJCAI (International Joint Conference\n  on Artificial Intelligence) 2025", "summary": "Community detection, a vital technology for real-world applications, uncovers\ncohesive node groups (communities) by leveraging both topological and attribute\nsimilarities in social networks. However, existing Graph Convolutional Networks\n(GCNs) trained to maximize modularity often converge to suboptimal solutions.\nAdditionally, directly using human-labeled communities for training can\nundermine topological cohesiveness by grouping disconnected nodes based solely\non node attributes. We address these issues by proposing a novel Topological\nand Attributive Similarity-based Community detection (TAS-Com) method. TAS-Com\nintroduces a novel loss function that exploits the highly effective and\nscalable Leiden algorithm to detect community structures with global optimal\nmodularity. Leiden is further utilized to refine human-labeled communities to\nensure connectivity within each community, enabling TAS-Com to detect community\nstructures with desirable trade-offs between modularity and compliance with\nhuman labels. Experimental results on multiple benchmark networks confirm that\nTAS-Com can significantly outperform several state-of-the-art algorithms."}
{"id": "2505.10556", "pdf": "https://arxiv.org/pdf/2505.10556", "abs": "https://arxiv.org/abs/2505.10556", "authors": ["Nazanin Zounemat Kermani", "Sadjad Naderi", "Claire H. Dilliway", "Claire E. Heaney", "Shrreya Behll", "Boyang Chen", "Hisham Abubakar-Waziri", "Alexandra E. Porter", "Marc Chadeau-Hyam", "Fangxin Fang", "Ian M. Adcock", "Kian Fan Chung", "Christopher C. Pain"], "title": "An AI-driven framework for the prediction of personalised health response to air pollution", "categories": ["cs.LG", "physics.ao-ph"], "comment": "Kermani and Naderi share first authorship. 20 pages, 6 figures and 1\n  table", "summary": "Air pollution poses a significant threat to public health, causing or\nexacerbating many respiratory and cardiovascular diseases. In addition, climate\nchange is bringing about more extreme weather events such as wildfires and\nheatwaves, which can increase levels of pollution and worsen the effects of\npollution exposure. Recent advances in personal sensing have transformed the\ncollection of behavioural and physiological data, leading to the potential for\nnew improvements in healthcare. We wish to capitalise on this data, alongside\nnew capabilities in AI for making time series predictions, in order to monitor\nand predict health outcomes for an individual. Thus, we present a novel\nworkflow for predicting personalised health responses to pollution by\nintegrating physiological data from wearable fitness devices with real-time\nenvironmental exposures. The data is collected from various sources in a secure\nand ethical manner, and is used to train an AI model to predict individual\nhealth responses to pollution exposure within a cloud-based, modular framework.\nWe demonstrate that the AI model -- an Adversarial Autoencoder neural network\nin this case -- accurately reconstructs time-dependent health signals and\ncaptures nonlinear responses to pollution. Transfer learning is applied using\ndata from a personal smartwatch, which increases the generalisation abilities\nof the AI model and illustrates the adaptability of the approach to real-world,\nuser-generated data."}
{"id": "2505.10201", "pdf": "https://arxiv.org/pdf/2505.10201", "abs": "https://arxiv.org/abs/2505.10201", "authors": ["Victor Lagerkvist", "Mohamed Maizia", "Johannes Schmidt"], "title": "A Fine-Grained Complexity View on Propositional Abduction -- Algorithms and Lower Bounds", "categories": ["cs.CC", "cs.AI", "F.2.2"], "comment": null, "summary": "The Boolean satisfiability problem (SAT) is a well-known example of monotonic\nreasoning, of intense practical interest due to fast solvers, complemented by\nrigorous fine-grained complexity results. However, for non-monotonic reasoning,\ne.g., abductive reasoning, comparably little is known outside classic\ncomplexity theory. In this paper we take a first step of bridging the gap\nbetween monotonic and non-monotonic reasoning by analyzing the complexity of\nintractable abduction problems under the seemingly overlooked but natural\nparameter n: the number of variables in the knowledge base. We obtain several\npositive results for $\\Sigma^P_2$- as well as NP- and coNP-complete fragments,\nwhich implies the first example of beating exhaustive search for a\n$\\Sigma^P_2$-complete problem (to the best of our knowledge). We complement\nthis with lower bounds and for many fragments rule out improvements under the\n(strong) exponential-time hypothesis."}
{"id": "2505.10559", "pdf": "https://arxiv.org/pdf/2505.10559", "abs": "https://arxiv.org/abs/2505.10559", "authors": ["Ziming Liu", "Yizhou Liu", "Jeff Gore", "Max Tegmark"], "title": "Neural Thermodynamic Laws for Large Language Model Training", "categories": ["cs.LG", "cs.AI", "physics.data-an", "stat.ML"], "comment": "18 pages, 10 figures", "summary": "Beyond neural scaling laws, little is known about the laws underlying large\nlanguage models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new\nframework that offers fresh insights into LLM training dynamics. On the\ntheoretical side, we demonstrate that key thermodynamic quantities (e.g.,\ntemperature, entropy, heat capacity, thermal conduction) and classical\nthermodynamic principles (e.g., the three laws of thermodynamics and the\nequipartition theorem) naturally emerge under river-valley loss landscape\nassumptions. On the practical side, this scientific perspective yields\nintuitive guidelines for designing learning rate schedules."}
{"id": "2505.10212", "pdf": "https://arxiv.org/pdf/2505.10212", "abs": "https://arxiv.org/abs/2505.10212", "authors": ["Dario Di Palma", "Felice Antonio Merra", "Maurizio Sfilio", "Vito Walter Anelli", "Fedelucio Narducci", "Tommaso Di Noia"], "title": "Do LLMs Memorize Recommendation Datasets? A Preliminary Study on MovieLens-1M", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have become increasingly central to\nrecommendation scenarios due to their remarkable natural language understanding\nand generation capabilities. Although significant research has explored the use\nof LLMs for various recommendation tasks, little effort has been dedicated to\nverifying whether they have memorized public recommendation dataset as part of\ntheir training data. This is undesirable because memorization reduces the\ngeneralizability of research findings, as benchmarking on memorized datasets\ndoes not guarantee generalization to unseen datasets. Furthermore, memorization\ncan amplify biases, for example, some popular items may be recommended more\nfrequently than others.\n  In this work, we investigate whether LLMs have memorized public\nrecommendation datasets. Specifically, we examine two model families (GPT and\nLlama) across multiple sizes, focusing on one of the most widely used dataset\nin recommender systems: MovieLens-1M. First, we define dataset memorization as\nthe extent to which item attributes, user profiles, and user-item interactions\ncan be retrieved by prompting the LLMs. Second, we analyze the impact of\nmemorization on recommendation performance. Lastly, we examine whether\nmemorization varies across model families and model sizes. Our results reveal\nthat all models exhibit some degree of memorization of MovieLens-1M, and that\nrecommendation performance is related to the extent of memorization. We have\nmade all the code publicly available at:\nhttps://github.com/sisinflab/LLM-MemoryInspector"}
{"id": "2505.08202", "pdf": "https://arxiv.org/pdf/2505.08202", "abs": "https://arxiv.org/abs/2505.08202", "authors": ["Aman Raj", "Lakshit Arora", "Sanjay Surendranath Girija", "Shashank Kapoor", "Dipen Pradhan", "Ankit Shetgaonkar"], "title": "AI and Generative AI Transforming Disaster Management: A Survey of Damage Assessment and Response Techniques", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "Accepted in IEEE Compsac 2025", "summary": "Natural disasters, including earthquakes, wildfires and cyclones, bear a huge\nrisk on human lives as well as infrastructure assets. An effective response to\ndisaster depends on the ability to rapidly and efficiently assess the intensity\nof damage. Artificial Intelligence (AI) and Generative Artificial Intelligence\n(GenAI) presents a breakthrough solution, capable of combining knowledge from\nmultiple types and sources of data, simulating realistic scenarios of disaster,\nand identifying emerging trends at a speed previously unimaginable. In this\npaper, we present a comprehensive review on the prospects of AI and GenAI in\ndamage assessment for various natural disasters, highlighting both its\nstrengths and limitations. We talk about its application to multimodal data\nsuch as text, image, video, and audio, and also cover major issues of data\nprivacy, security, and ethical use of the technology during crises. The paper\nalso recognizes the threat of Generative AI misuse, in the form of\ndissemination of misinformation and for adversarial attacks. Finally, we\noutline avenues of future research, emphasizing the need for secure, reliable,\nand ethical Generative AI systems for disaster management in general. We\nbelieve that this work represents the first comprehensive survey of Gen-AI\ntechniques being used in the field of Disaster Assessment and Response."}
{"id": "2505.10231", "pdf": "https://arxiv.org/pdf/2505.10231", "abs": "https://arxiv.org/abs/2505.10231", "authors": ["Haozhe Luo", "Ziyu Zhou", "Zixin Shu", "Aurélie Pahud de Mortanges", "Robert Berke", "Mauricio Reyes"], "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner."}
{"id": "2505.09633", "pdf": "https://arxiv.org/pdf/2505.09633", "abs": "https://arxiv.org/abs/2505.09633", "authors": ["Nick Sunday"], "title": "Detecting Musical Deepfakes", "categories": ["cs.SD", "cs.LG"], "comment": "Submitted as part of coursework at UT Austin. Accompanying code\n  available at: https://github.com/nicksunday/deepfake-music-detector", "summary": "The proliferation of Text-to-Music (TTM) platforms has democratized music\ncreation, enabling users to effortlessly generate high-quality compositions.\nHowever, this innovation also presents new challenges to musicians and the\nbroader music industry. This study investigates the detection of AI-generated\nsongs using the FakeMusicCaps dataset by classifying audio as either deepfake\nor human. To simulate real-world adversarial conditions, tempo stretching and\npitch shifting were applied to the dataset. Mel spectrograms were generated\nfrom the modified audio, then used to train and evaluate a convolutional neural\nnetwork. In addition to presenting technical results, this work explores the\nethical and societal implications of TTM platforms, arguing that carefully\ndesigned detection systems are essential to both protecting artists and\nunlocking the positive potential of generative AI in music."}
{"id": "2505.10260", "pdf": "https://arxiv.org/pdf/2505.10260", "abs": "https://arxiv.org/abs/2505.10260", "authors": ["Poli Apollinaire Nemkova", "Solomon Ubani", "Mark V. Albert"], "title": "Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the era of increasingly sophisticated natural language processing (NLP)\nsystems, large language models (LLMs) have demonstrated remarkable potential\nfor diverse applications, including tasks requiring nuanced textual\nunderstanding and contextual reasoning. This study investigates the\ncapabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3,\nMistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex\ntextual dataset comprising social media posts in Russian and Ukrainian.\nSpecifically, the focus is on the binary classification task of identifying\nreferences to human rights violations within the dataset.\n  To evaluate the effectiveness of these models, their annotations are compared\nagainst a gold standard set of human double-annotated labels across 1000\nsamples. The analysis includes assessing annotation performance under different\nprompting conditions, with prompts provided in both English and Russian.\nAdditionally, the study explores the unique patterns of errors and\ndisagreements exhibited by each model, offering insights into their strengths,\nlimitations, and cross-linguistic adaptability.\n  By juxtaposing LLM outputs with human annotations, this research contributes\nto understanding the reliability and applicability of LLMs for sensitive,\ndomain-specific tasks in multilingual contexts. It also sheds light on how\nlanguage models handle inherently subjective and context-dependent judgments, a\ncritical consideration for their deployment in real-world scenarios."}
{"id": "2505.09643", "pdf": "https://arxiv.org/pdf/2505.09643", "abs": "https://arxiv.org/abs/2505.09643", "authors": ["Zhixuan Wang"], "title": "A Computational Approach to Epilepsy Treatment: An AI-optimized Global Natural Product Prescription System", "categories": ["q-bio.NC", "cs.LG"], "comment": null, "summary": "Epilepsy is a prevalent neurological disease with millions of patients\nworldwide. Many patients have turned to alternative medicine due to the limited\nefficacy and side effects of conventional antiepileptic drugs. In this study,\nwe developed a computational approach to optimize herbal epilepsy treatment\nthrough AI-driven analysis of global natural products and statistically\nvalidated randomized controlled trials (RCTs). Our intelligent prescription\nsystem combines machine learning (ML) algorithms for herb-efficacy\ncharacterization, Bayesian optimization for personalized dosing, and\nmeta-analysis of RCTs for evidence-based recommendations. The system analyzed\n1,872 natural compounds from traditional Chinese medicine (TCM), Ayurveda, and\nethnopharmacological databases, integrating their bioactive properties with\nclinical outcomes from 48 RCTs covering 48 epilepsy conditions (n=5,216). Using\nLASSO regression and SHAP value analysis, we identified 17 high-efficacy herbs\n(e.g., Gastrodia elata [using \\'e for accented characters], Withania\nsomnifera), showing significant seizure reduction (p$<$0.01, Cohen's d=0.89)\nwith statistical significance confirmed by multiple testing (p$<$0.001). A\nrandomized double-blind validation trial (n=120) demonstrated 28.5\\% greater\nseizure frequency reduction with AI-optimized herbal prescriptions compared to\nconventional protocols (95\\% CI: 18.7-37.3\\%, p=0.003)."}
{"id": "2505.10261", "pdf": "https://arxiv.org/pdf/2505.10261", "abs": "https://arxiv.org/abs/2505.10261", "authors": ["Rui Yang", "Huitao Li", "Matthew Yu Heng Wong", "Yuhe Ke", "Xin Li", "Kunyu Yu", "Jingchi Liao", "Jonathan Chong Kai Liew", "Sabarinath Vinod Nair", "Jasmine Chiat Ling Ong", "Irene Li", "Douglas Teodoro", "Chuan Hong", "Daniel Shu Wei Ting", "Nan Liu"], "title": "The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Natural language processing (NLP) has been traditionally applied to medicine,\nand generative large language models (LLMs) have become prominent recently.\nHowever, the differences between them across different medical tasks remain\nunderexplored. We analyzed 19,123 studies, finding that generative LLMs\ndemonstrate advantages in open-ended tasks, while traditional NLP dominates in\ninformation extraction and analysis tasks. As these technologies advance,\nethical use of them is essential to ensure their potential in medical\napplications."}
{"id": "2505.09647", "pdf": "https://arxiv.org/pdf/2505.09647", "abs": "https://arxiv.org/abs/2505.09647", "authors": ["Leighton Pate Barnes", "Stephen Cameron", "Benjamin Howard"], "title": "On Unbiased Low-Rank Approximation with Minimum Distortion", "categories": ["cs.DS", "cs.IT", "cs.LG", "math.IT", "math.PR", "math.ST", "stat.TH"], "comment": null, "summary": "We describe an algorithm for sampling a low-rank random matrix $Q$ that best\napproximates a fixed target matrix $P\\in\\mathbb{C}^{n\\times m}$ in the\nfollowing sense: $Q$ is unbiased, i.e., $\\mathbb{E}[Q] = P$;\n$\\mathsf{rank}(Q)\\leq r$; and $Q$ minimizes the expected Frobenius norm error\n$\\mathbb{E}\\|P-Q\\|_F^2$. Our algorithm mirrors the solution to the efficient\nunbiased sparsification problem for vectors, except applied to the singular\ncomponents of the matrix $P$. Optimality is proven by showing that our\nalgorithm matches the error from an existing lower bound."}
{"id": "2505.10264", "pdf": "https://arxiv.org/pdf/2505.10264", "abs": "https://arxiv.org/abs/2505.10264", "authors": ["Francesco Diana", "André Nusser", "Chuan Xu", "Giovanni Neglia"], "title": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated Learning (FL) enables collaborative training of machine learning\nmodels across distributed clients without sharing raw data, ostensibly\npreserving data privacy. Nevertheless, recent studies have revealed critical\nvulnerabilities in FL, showing that a malicious central server can manipulate\nmodel updates to reconstruct clients' private training data. Existing data\nreconstruction attacks have important limitations: they often rely on\nassumptions about the clients' data distribution or their efficiency\nsignificantly degrades when batch sizes exceed just a few tens of samples.\n  In this work, we introduce a novel data reconstruction attack that overcomes\nthese limitations. Our method leverages a new geometric perspective on fully\nconnected layers to craft malicious model parameters, enabling the perfect\nrecovery of arbitrarily large data batches in classification tasks without any\nprior knowledge of clients' data. Through extensive experiments on both image\nand tabular datasets, we demonstrate that our attack outperforms existing\nmethods and achieves perfect reconstruction of data batches two orders of\nmagnitude larger than the state of the art."}
{"id": "2505.09649", "pdf": "https://arxiv.org/pdf/2505.09649", "abs": "https://arxiv.org/abs/2505.09649", "authors": ["Abisha Thapa Magar", "Anup Shakya"], "title": "Next Word Suggestion using Graph Neural Network", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Language Modeling is a prevalent task in Natural Language Processing. The\ncurrently existing most recent and most successful language models often tend\nto build a massive model with billions of parameters, feed in a tremendous\namount of text data, and train with enormous computation resources which\nrequire millions of dollars. In this project, we aim to address an important\nsub-task in language modeling, i.e., context embedding. We propose an approach\nto exploit the Graph Convolution operation in GNNs to encode the context and\nuse it in coalition with LSTMs to predict the next word given a local context\nof preceding words. We test this on the custom Wikipedia text corpus using a\nvery limited amount of resources and show that this approach works fairly well\nto predict the next word."}
{"id": "2505.10273", "pdf": "https://arxiv.org/pdf/2505.10273", "abs": "https://arxiv.org/abs/2505.10273", "authors": ["Hexu Li", "Konstantinos Kalogiannis", "Ahmed Mohamed Hussain", "Panos Papadimitratos"], "title": "AttentionGuard: Transformer-based Misbehavior Detection for Secure Vehicular Platoons", "categories": ["cs.CR", "cs.AI", "cs.NI"], "comment": "Author's version; Accepted for presentation at the ACM Workshop on\n  Wireless Security and Machine Learning (WiseML 2025)", "summary": "Vehicle platooning, with vehicles traveling in close formation coordinated\nthrough Vehicle-to-Everything (V2X) communications, offers significant benefits\nin fuel efficiency and road utilization. However, it is vulnerable to\nsophisticated falsification attacks by authenticated insiders that can\ndestabilize the formation and potentially cause catastrophic collisions. This\npaper addresses this challenge: misbehavior detection in vehicle platooning\nsystems. We present AttentionGuard, a transformer-based framework for\nmisbehavior detection that leverages the self-attention mechanism to identify\nanomalous patterns in mobility data. Our proposal employs a multi-head\ntransformer-encoder to process sequential kinematic information, enabling\neffective differentiation between normal mobility patterns and falsification\nattacks across diverse platooning scenarios, including steady-state\n(no-maneuver) operation, join, and exit maneuvers. Our evaluation uses an\nextensive simulation dataset featuring various attack vectors (constant,\ngradual, and combined falsifications) and operational parameters (controller\ntypes, vehicle speeds, and attacker positions). Experimental results\ndemonstrate that AttentionGuard achieves up to 0.95 F1-score in attack\ndetection, with robust performance maintained during complex maneuvers.\nNotably, our system performs effectively with minimal latency (100ms decision\nintervals), making it suitable for real-time transportation safety\napplications. Comparative analysis reveals superior detection capabilities and\nestablishes the transformer-encoder as a promising approach for securing\nCooperative Intelligent Transport Systems (C-ITS) against sophisticated insider\nthreats."}
{"id": "2505.09651", "pdf": "https://arxiv.org/pdf/2505.09651", "abs": "https://arxiv.org/abs/2505.09651", "authors": ["Xixuan Hao", "Yutian Jiang", "Xingchen Zou", "Jiabo Liu", "Yifang Yin", "Yuxuan Liang"], "title": "Unlocking Location Intelligence: A Survey from Deep Learning to The LLM Era", "categories": ["cs.DB", "cs.AI", "cs.LG"], "comment": null, "summary": "Location Intelligence (LI), the science of transforming location-centric\ngeospatial data into actionable knowledge, has become a cornerstone of modern\nspatial decision-making. The rapid evolution of Geospatial Representation\nLearning is fundamentally reshaping LI development through two successive\ntechnological revolutions: the deep learning breakthrough and the emerging\nlarge language model (LLM) paradigm. While deep neural networks (DNNs) have\ndemonstrated remarkable success in automated feature extraction from structured\ngeospatial data (e.g., satellite imagery, GPS trajectories), the recent\nintegration of LLMs introduces transformative capabilities for cross-modal\ngeospatial reasoning and unstructured geo-textual data processing. This survey\npresents a comprehensive review of geospatial representation learning across\nboth technological eras, organizing them into a structured taxonomy based on\nthe complete pipeline comprising: (1) data perspective, (2) methodological\nperspective and (3) application perspective. We also highlight current\nadvancements, discuss existing limitations, and propose potential future\nresearch directions in the LLM era. This work offers a thorough exploration of\nthe field and providing a roadmap for further innovation in LI. The summary of\nthe up-to-date paper list can be found in\nhttps://github.com/CityMind-Lab/Awesome-Location-Intelligence and will undergo\ncontinuous updates."}
{"id": "2505.10297", "pdf": "https://arxiv.org/pdf/2505.10297", "abs": "https://arxiv.org/abs/2505.10297", "authors": ["Chibueze Peace Obioma", "Youcheng Sun", "Mustafa A. Mustafa"], "title": "Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Submitted to ESORICS 2025", "summary": "Federated learning (FL) enhances privacy and reduces communication cost for\nresource-constrained edge clients by supporting distributed model training at\nthe edge. However, the heterogeneous nature of such devices produces diverse,\nnon-independent, and identically distributed (non-IID) data, making the\ndetection of backdoor attacks more challenging. In this paper, we propose a\nnovel federated representative-attention-based defense mechanism, named FeRA,\nthat leverages cross-client attention over internal feature representations to\ndistinguish benign from malicious clients. FeRA computes an anomaly score based\non representation reconstruction errors, effectively identifying clients whose\ninternal activations significantly deviate from the group consensus. Our\nevaluation demonstrates FeRA's robustness across various FL scenarios,\nincluding challenging non-IID data distributions typical of edge devices.\nExperimental results show that it effectively reduces backdoor attack success\nrates while maintaining high accuracy on the main task. The method is\nmodel-agnostic, attack-agnostic, and does not require labeled reference data,\nmaking it well suited to heterogeneous and resource-limited edge deployments."}
{"id": "2505.09653", "pdf": "https://arxiv.org/pdf/2505.09653", "abs": "https://arxiv.org/abs/2505.09653", "authors": ["Samuel Yen-Chi Chen", "Chen-Yu Liu", "Kuan-Cheng Chen", "Wei-Jia Huang", "Yen-Jui Chang", "Wei-Hao Huang"], "title": "Differentiable Quantum Architecture Search in Quantum-Enhanced Neural Network Parameter Generation", "categories": ["quant-ph", "cs.AI", "cs.ET", "cs.LG", "cs.NE"], "comment": null, "summary": "The rapid advancements in quantum computing (QC) and machine learning (ML)\nhave led to the emergence of quantum machine learning (QML), which integrates\nthe strengths of both fields. Among QML approaches, variational quantum\ncircuits (VQCs), also known as quantum neural networks (QNNs), have shown\npromise both empirically and theoretically. However, their broader adoption is\nhindered by reliance on quantum hardware during inference. Hardware\nimperfections and limited access to quantum devices pose practical challenges.\nTo address this, the Quantum-Train (QT) framework leverages the exponential\nscaling of quantum amplitudes to generate classical neural network parameters,\nenabling inference without quantum hardware and achieving significant parameter\ncompression. Yet, designing effective quantum circuit architectures for such\nquantum-enhanced neural programmers remains non-trivial and often requires\nexpertise in quantum information science. In this paper, we propose an\nautomated solution using differentiable optimization. Our method jointly\noptimizes both conventional circuit parameters and architectural parameters in\nan end-to-end manner via automatic differentiation. We evaluate the proposed\nframework on classification, time-series prediction, and reinforcement learning\ntasks. Simulation results show that our method matches or outperforms manually\ndesigned QNN architectures. This work offers a scalable and automated pathway\nfor designing QNNs that can generate classical neural network parameters across\ndiverse applications."}
{"id": "2505.10300", "pdf": "https://arxiv.org/pdf/2505.10300", "abs": "https://arxiv.org/abs/2505.10300", "authors": ["Muzhe Wu", "Yanzhi Zhao", "Shuyi Han", "Michael Xieyang Liu", "Hong Shen"], "title": "AI LEGO: Scaffolding Cross-Functional Collaboration in Industrial Responsible AI Practices during Early Design Stages", "categories": ["cs.HC", "cs.AI"], "comment": null, "summary": "Responsible AI (RAI) efforts increasingly emphasize the importance of\naddressing potential harms early in the AI development lifecycle through\nsocial-technical lenses. However, in cross-functional industry teams, this work\nis often stalled by a persistent knowledge handoff challenge: the difficulty of\ntransferring high-level, early-stage technical design rationales from technical\nexperts to non-technical or user-facing roles for ethical evaluation and harm\nidentification. Through literature review and a co-design study with 8\npractitioners, we unpack how this challenge manifests -- technical design\nchoices are rarely handed off in ways that support meaningful engagement by\nnon-technical roles; collaborative workflows lack shared, visual structures to\nsupport mutual understanding; and non-technical practitioners are left without\nscaffolds for systematic harm evaluation. Existing tools like JIRA or Google\nDocs, while useful for product tracking, are ill-suited for supporting joint\nharm identification across roles, often requiring significant extra effort to\nalign understanding. To address this, we developed AI LEGO, a web-based\nprototype that supports cross-functional AI practitioners in effectively\nfacilitating knowledge handoff and identifying harmful design choices in the\nearly design stages. Technical roles use interactive blocks to draft\ndevelopment plans, while non-technical roles engage with those blocks through\nstage-specific checklists and LLM-driven persona simulations to surface\npotential harms. In a study with 18 cross-functional practitioners, AI LEGO\nincreased the volume and likelihood of harms identified compared to baseline\nworksheets. Participants found that its modular structure and persona prompts\nmade harm identification more accessible, fostering clearer and more\ncollaborative RAI practices in early design."}
{"id": "2505.09660", "pdf": "https://arxiv.org/pdf/2505.09660", "abs": "https://arxiv.org/abs/2505.09660", "authors": ["Saptarshi Saha", "Dhruv Vansraj Rathore", "Soumadeep Saha", "Utpal Garain", "David Doermann"], "title": "On Measuring Intrinsic Causal Attributions in Deep Neural Networks", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Quantifying the causal influence of input features within neural networks has\nbecome a topic of increasing interest. Existing approaches typically assess\ndirect, indirect, and total causal effects. This work treats NNs as structural\ncausal models (SCMs) and extends our focus to include intrinsic causal\ncontributions (ICC). We propose an identifiable generative post-hoc framework\nfor quantifying ICC. We also draw a relationship between ICC and Sobol'\nindices. Our experiments on synthetic and real-world datasets demonstrate that\nICC generates more intuitive and reliable explanations compared to existing\nglobal explanation techniques."}
{"id": "2505.10315", "pdf": "https://arxiv.org/pdf/2505.10315", "abs": "https://arxiv.org/abs/2505.10315", "authors": ["Yang Li", "Xinyu Zhou", "Yitong Wang", "Liangxin Qian", "Jun Zhao"], "title": "Private Transformer Inference in MLaaS: A Survey", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Transformer models have revolutionized AI, powering applications like content\ngeneration and sentiment analysis. However, their deployment in Machine\nLearning as a Service (MLaaS) raises significant privacy concerns, primarily\ndue to the centralized processing of sensitive user data. Private Transformer\nInference (PTI) offers a solution by utilizing cryptographic techniques such as\nsecure multi-party computation and homomorphic encryption, enabling inference\nwhile preserving both user data and model privacy. This paper reviews recent\nPTI advancements, highlighting state-of-the-art solutions and challenges. We\nalso introduce a structured taxonomy and evaluation framework for PTI, focusing\non balancing resource efficiency with privacy and bridging the gap between\nhigh-performance inference and data privacy."}
{"id": "2505.09666", "pdf": "https://arxiv.org/pdf/2505.09666", "abs": "https://arxiv.org/abs/2505.09666", "authors": ["Yumin Choi", "Jinheon Baek", "Sung Ju Hwang"], "title": "System Prompt Optimization with Meta-Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance."}
{"id": "2505.10320", "pdf": "https://arxiv.org/pdf/2505.10320", "abs": "https://arxiv.org/abs/2505.10320", "authors": ["Chenxi Whitehouse", "Tianlu Wang", "Ping Yu", "Xian Li", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 8 tables, 11 figures", "summary": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses."}
{"id": "2505.09706", "pdf": "https://arxiv.org/pdf/2505.09706", "abs": "https://arxiv.org/abs/2505.09706", "authors": ["Hugo Gobato Souto", "Francisco Louzada Neto"], "title": "Forests for Differences: Robust Causal Inference Beyond Parametric DiD", "categories": ["stat.ME", "cs.LG", "stat.ML"], "comment": null, "summary": "This paper introduces the Difference-in-Differences Bayesian Causal Forest\n(DiD-BCF), a novel non-parametric model addressing key challenges in DiD\nestimation, such as staggered adoption and heterogeneous treatment effects.\nDiD-BCF provides a unified framework for estimating Average (ATE),\nGroup-Average (GATE), and Conditional Average Treatment Effects (CATE). A core\ninnovation, its Parallel Trends Assumption (PTA)-based reparameterization,\nenhances estimation accuracy and stability in complex panel data settings.\nExtensive simulations demonstrate DiD-BCF's superior performance over\nestablished benchmarks, particularly under non-linearity, selection biases, and\neffect heterogeneity. Applied to U.S. minimum wage policy, the model uncovers\nsignificant conditional treatment effect heterogeneity related to county\npopulation, insights obscured by traditional methods. DiD-BCF offers a robust\nand versatile tool for more nuanced causal inference in modern DiD\napplications."}
{"id": "2505.10321", "pdf": "https://arxiv.org/pdf/2505.10321", "abs": "https://arxiv.org/abs/2505.10321", "authors": ["Julius Henke"], "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "categories": ["cs.CR", "cs.AI"], "comment": "24 pages, 1 figure, for implementation, see\n  https://github.com/JuliusHenke/autopentest", "summary": "A recent area of increasing research is the use of Large Language Models\n(LLMs) in penetration testing, which promises to reduce costs and thus allow\nfor higher frequency. We conduct a review of related work, identifying best\npractices and common evaluation issues. We then present AutoPentest, an\napplication for performing black-box penetration tests with a high degree of\nautonomy. AutoPentest is based on the LLM GPT-4o from OpenAI and the LLM agent\nframework LangChain. It can perform complex multi-step tasks, augmented by\nexternal tools and knowledge bases. We conduct a study on three\ncapture-the-flag style Hack The Box (HTB) machines, comparing our\nimplementation AutoPentest with the baseline approach of manually using the\nChatGPT-4o user interface. Both approaches are able to complete 15-25 % of the\nsubtasks on the HTB machines, with AutoPentest slightly outperforming ChatGPT.\nWe measure a total cost of \\$96.20 US when using AutoPentest across all\nexperiments, while a one-month subscription to ChatGPT Plus costs \\$20. The\nresults show that further implementation efforts and the use of more powerful\nLLMs released in the future are likely to make this a viable part of\nvulnerability management."}
{"id": "2505.09718", "pdf": "https://arxiv.org/pdf/2505.09718", "abs": "https://arxiv.org/abs/2505.09718", "authors": ["Daniel Dylewsky", "Sonia Kéfi", "Madhur Anand", "Chris T. Bauch"], "title": "Neural models for prediction of spatially patterned phase transitions: methods and challenges", "categories": ["physics.comp-ph", "cs.LG"], "comment": null, "summary": "Dryland vegetation ecosystems are known to be susceptible to critical\ntransitions between alternative stable states when subjected to external\nforcing. Such transitions are often discussed through the framework of\nbifurcation theory, but the spatial patterning of vegetation, which is\ncharacteristic of drylands, leads to dynamics that are much more complex and\ndiverse than local bifurcations. Recent methodological developments in Early\nWarning Signal (EWS) detection have shown promise in identifying dynamical\nsignatures of oncoming critical transitions, with particularly strong\npredictive capabilities being demonstrated by deep neural networks. However, a\nmachine learning model trained on synthetic examples is only useful if it can\neffectively transfer to a test case of practical interest. These models'\ncapacity to generalize in this manner has been demonstrated for bifurcation\ntransitions, but it is not as well characterized for high-dimensional phase\ntransitions. This paper explores the successes and shortcomings of neural EWS\ndetection for spatially patterned phase transitions, and shows how these models\ncan be used to gain insight into where and how EWS-relevant information is\nencoded in spatiotemporal dynamics. A few paradigmatic test systems are used to\nillustrate how the capabilities of such models can be probed in a number of\nways, with particular attention to the performances of a number of proposed\nstatistical indicators for EWS and to the supplementary task of distinguishing\nbetween abrupt and continuous transitions. Results reveal that model\nperformance often changes dramatically when training and test data sources are\ninterchanged, which offers new insight into the criteria for model\ngeneralization."}
{"id": "2505.10330", "pdf": "https://arxiv.org/pdf/2505.10330", "abs": "https://arxiv.org/abs/2505.10330", "authors": ["Jonathan Clifford Balloch"], "title": "Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change", "categories": ["cs.LG", "cs.AI"], "comment": "PhD Dissertation, 131 pages", "summary": "Real-world autonomous decision-making systems, from robots to recommendation\nengines, must operate in environments that change over time. While deep\nreinforcement learning (RL) has shown an impressive ability to learn optimal\npolicies in stationary environments, most methods are data intensive and assume\na world that does not change between training and test time. As a result,\nconventional RL methods struggle to adapt when conditions change. This poses a\nfundamental challenge: how can RL agents efficiently adapt their behavior when\nencountering novel environmental changes during deployment without\ncatastrophically forgetting useful prior knowledge? This dissertation\ndemonstrates that efficient online adaptation requires two key capabilities:\n(1) prioritized exploration and sampling strategies that help identify and\nlearn from relevant experiences, and (2) selective preservation of prior\nknowledge through structured representations that can be updated without\ndisruption to reusable components."}
{"id": "2505.09734", "pdf": "https://arxiv.org/pdf/2505.09734", "abs": "https://arxiv.org/abs/2505.09734", "authors": ["Babak Esmaeili", "Nariman Niknejad", "Hamidreza Modares"], "title": "Risk-Aware Safe Reinforcement Learning for Control of Stochastic Linear Systems", "categories": ["eess.SY", "cs.LG", "cs.RO", "cs.SY", "math.OC"], "comment": "Submitted to Asian Journal of Control", "summary": "This paper presents a risk-aware safe reinforcement learning (RL) control\ndesign for stochastic discrete-time linear systems. Rather than using a safety\ncertifier to myopically intervene with the RL controller, a risk-informed safe\ncontroller is also learned besides the RL controller, and the RL and safe\ncontrollers are combined together. Several advantages come along with this\napproach: 1) High-confidence safety can be certified without relying on a\nhigh-fidelity system model and using limited data available, 2) Myopic\ninterventions and convergence to an undesired equilibrium can be avoided by\ndeciding on the contribution of two stabilizing controllers, and 3) highly\nefficient and computationally tractable solutions can be provided by optimizing\nover a scalar decision variable and linear programming polyhedral sets. To\nlearn safe controllers with a large invariant set, piecewise affine controllers\nare learned instead of linear controllers. To this end, the closed-loop system\nis first represented using collected data, a decision variable, and noise. The\neffect of the decision variable on the variance of the safe violation of the\nclosed-loop system is formalized. The decision variable is then designed such\nthat the probability of safety violation for the learned closed-loop system is\nminimized. It is shown that this control-oriented approach reduces the data\nrequirements and can also reduce the variance of safety violations. Finally, to\nintegrate the safe and RL controllers, a new data-driven interpolation\ntechnique is introduced. This method aims to maintain the RL agent's optimal\nimplementation while ensuring its safety within environments characterized by\nnoise. The study concludes with a simulation example that serves to validate\nthe theoretical results."}
{"id": "2505.10331", "pdf": "https://arxiv.org/pdf/2505.10331", "abs": "https://arxiv.org/abs/2505.10331", "authors": ["Luca Muscarnera", "Luigi Loreti", "Giovanni Todeschini", "Alessio Fumagalli", "Francesco Regazzoni"], "title": "Emergence of Structure in Ensembles of Random Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Randomness is ubiquitous in many applications across data science and machine\nlearning. Remarkably, systems composed of random components often display\nemergent global behaviors that appear deterministic, manifesting a transition\nfrom microscopic disorder to macroscopic organization. In this work, we\nintroduce a theoretical model for studying the emergence of collective\nbehaviors in ensembles of random classifiers. We argue that, if the ensemble is\nweighted through the Gibbs measure defined by adopting the classification loss\nas an energy, then there exists a finite temperature parameter for the\ndistribution such that the classification is optimal, with respect to the loss\n(or the energy). Interestingly, for the case in which samples are generated by\na Gaussian distribution and labels are constructed by employing a teacher\nperceptron, we analytically prove and numerically confirm that such optimal\ntemperature does not depend neither on the teacher classifier (which is, by\nconstruction of the learning problem, unknown), nor on the number of random\nclassifiers, highlighting the universal nature of the observed behavior.\nExperiments on the MNIST dataset underline the relevance of this phenomenon in\nhigh-quality, noiseless, datasets. Finally, a physical analogy allows us to\nshed light on the self-organizing nature of the studied phenomenon."}
{"id": "2505.09748", "pdf": "https://arxiv.org/pdf/2505.09748", "abs": "https://arxiv.org/abs/2505.09748", "authors": ["Jitendra K Tugnait"], "title": "Learning Multi-Attribute Differential Graphs with Non-Convex Penalties", "categories": ["stat.ML", "cs.LG", "eess.SP"], "comment": "14 pages, 1 figures, 2 tables, published in IEEE Access, pp.\n  67065-67078, 2025", "summary": "We consider the problem of estimating differences in two multi-attribute\nGaussian graphical models (GGMs) which are known to have similar structure,\nusing a penalized D-trace loss function with non-convex penalties. The GGM\nstructure is encoded in its precision (inverse covariance) matrix. Existing\nmethods for multi-attribute differential graph estimation are based on a group\nlasso penalized loss function. In this paper, we consider a penalized D-trace\nloss function with non-convex (log-sum and smoothly clipped absolute deviation\n(SCAD)) penalties. Two proximal gradient descent methods are presented to\noptimize the objective function. Theoretical analysis establishing sufficient\nconditions for consistency in support recovery, convexity and estimation in\nhigh-dimensional settings is provided. We illustrate our approaches with\nnumerical examples based on synthetic and real data."}
{"id": "2505.10347", "pdf": "https://arxiv.org/pdf/2505.10347", "abs": "https://arxiv.org/abs/2505.10347", "authors": ["Gabriel S. Gama", "Valdir Grassi Jr"], "title": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task\nLearning by addressing issues like conflicting gradients and differing gradient\nnorms, which hinder equal-weighted task training. However, recent critiques\nsuggest that equally weighted tasks can achieve competitive results compared to\nSMTOs, arguing that previous SMTO results were influenced by poor\nhyperparameter optimization and lack of regularization. In this work, we\nevaluate these claims through an extensive empirical evaluation of SMTOs,\nincluding some of the latest methods, on more complex multi-task problems to\nclarify this behavior. Our findings indicate that SMTOs perform well compared\nto uniform loss and that fixed weights can achieve competitive performance\ncompared to SMTOs. Furthermore, we demonstrate why uniform loss perform\nsimilarly to SMTOs in some instances. The code will be made publicly available."}
{"id": "2505.09783", "pdf": "https://arxiv.org/pdf/2505.09783", "abs": "https://arxiv.org/abs/2505.09783", "authors": ["Jianfeng Jiao", "Xi Gao", "Jie Li"], "title": "Pure Component Property Estimation Framework Using Explainable Machine Learning Methods", "categories": ["stat.AP", "cs.LG"], "comment": null, "summary": "Accurate prediction of pure component physiochemical properties is crucial\nfor process integration, multiscale modeling, and optimization. In this work,\nan enhanced framework for pure component property prediction by using\nexplainable machine learning methods is proposed. In this framework, the\nmolecular representation method based on the connectivity matrix effectively\nconsiders atomic bonding relationships to automatically generate features. The\nsupervised machine learning model random forest is applied for feature ranking\nand pooling. The adjusted R2 is introduced to penalize the inclusion of\nadditional features, providing an assessment of the true contribution of\nfeatures. The prediction results for normal boiling point (Tb), liquid molar\nvolume, critical temperature (Tc) and critical pressure (Pc) obtained using\nArtificial Neural Network and Gaussian Process Regression models confirm the\naccuracy of the molecular representation method. Comparison with GC based\nmodels shows that the root-mean-square error on the test set can be reduced by\nup to 83.8%. To enhance the interpretability of the model, a feature analysis\nmethod based on Shapley values is employed to determine the contribution of\neach feature to the property predictions. The results indicate that using the\nfeature pooling method reduces the number of features from 13316 to 100 without\ncompromising model accuracy. The feature analysis results for Tb, Tc, and Pc\nconfirms that different molecular properties are influenced by different\nstructural features, aligning with mechanistic interpretations. In conclusion,\nthe proposed framework is demonstrated to be feasible and provides a solid\nfoundation for mixture component reconstruction and process integration\nmodelling."}
{"id": "2505.10352", "pdf": "https://arxiv.org/pdf/2505.10352", "abs": "https://arxiv.org/abs/2505.10352", "authors": ["Shihao Zou", "Qingfeng Li", "Wei Ji", "Jingjing Li", "Yongkui Yang", "Guoqi Li", "Chao Dong"], "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer"}
{"id": "2505.09798", "pdf": "https://arxiv.org/pdf/2505.09798", "abs": "https://arxiv.org/abs/2505.09798", "authors": ["Bojan Ristov", "Stefan Eftimov", "Milena Trajanoska", "Dimitar Trajanov"], "title": "Ontology-Based Structuring and Analysis of North Macedonian Public Procurement Contracts", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Public procurement plays a critical role in government operations, ensuring\nthe efficient allocation of resources and fostering economic growth. However,\ntraditional procurement data is often stored in rigid, tabular formats,\nlimiting its analytical potential and hindering transparency. This research\npresents a methodological framework for transforming structured procurement\ndata into a semantic knowledge graph, leveraging ontological modeling and\nautomated data transformation techniques. By integrating RDF and SPARQL-based\nquerying, the system enhances the accessibility and interpretability of\nprocurement records, enabling complex semantic queries and advanced analytics.\nFurthermore, by incorporating machine learning-driven predictive modeling, the\nsystem extends beyond conventional data analysis, offering insights into\nprocurement trends and risk assessment. This work contributes to the broader\nfield of public procurement intelligence by improving data transparency,\nsupporting evidence-based decision-making, and enabling in-depth analysis of\nprocurement activities in North Macedonia."}
{"id": "2505.10360", "pdf": "https://arxiv.org/pdf/2505.10360", "abs": "https://arxiv.org/abs/2505.10360", "authors": ["Victor Petrén Bach Hansen", "Lasse Krogsbøll", "Jonas Lyngsø", "Mathias Baltzersen", "Andreas Motzfeldt", "Kevin Pelgrims", "Lars Maaløe"], "title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": null, "summary": "There are now a multitude of AI-scribing solutions for healthcare promising\nthe utilization of large language models for ambient documentation. However,\nthese AI scribes still rely on one-shot, or few-shot prompts for generating\nnotes after the consultation has ended, employing little to no reasoning. This\nrisks long notes with an increase in hallucinations, misrepresentation of the\nintent of the clinician, and reliance on the proofreading of the clinician to\ncatch errors. A dangerous combination for patient safety if vigilance is\ncompromised by workload and fatigue. In this paper, we introduce a method for\nextracting salient clinical information in real-time alongside the healthcare\nconsultation, denoted Facts, and use that information recursively to generate\nthe final note. The FactsR method results in more accurate and concise notes by\nplacing the clinician-in-the-loop of note generation, while opening up new use\ncases within real-time decision support."}
{"id": "2505.09803", "pdf": "https://arxiv.org/pdf/2505.09803", "abs": "https://arxiv.org/abs/2505.09803", "authors": ["Antony Sikorski", "Michael Ivanitskiy", "Nathan Lenssen", "Douglas Nychka", "Daniel McKenzie"], "title": "LatticeVision: Image to Image Networks for Modeling Non-Stationary Spatial Data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In many scientific and industrial applications, we are given a handful of\ninstances (a 'small ensemble') of a spatially distributed quantity (a 'field')\nbut would like to acquire many more. For example, a large ensemble of global\ntemperature sensitivity fields from a climate model can help farmers, insurers,\nand governments plan appropriately. When acquiring more data is prohibitively\nexpensive -- as is the case with climate models -- statistical emulation offers\nan efficient alternative for simulating synthetic yet realistic fields.\nHowever, parameter inference using maximum likelihood estimation (MLE) is\ncomputationally prohibitive, especially for large, non-stationary fields. Thus,\nmany recent works train neural networks to estimate parameters given spatial\nfields as input, sidestepping MLE completely. In this work we focus on a\npopular class of parametric, spatially autoregressive (SAR) models. We make a\nsimple yet impactful observation; because the SAR parameters can be arranged on\na regular grid, both inputs (spatial fields) and outputs (model parameters) can\nbe viewed as images. Using this insight, we demonstrate that image-to-image\n(I2I) networks enable faster and more accurate parameter estimation for a class\nof non-stationary SAR models with unprecedented complexity."}
{"id": "2505.10371", "pdf": "https://arxiv.org/pdf/2505.10371", "abs": "https://arxiv.org/abs/2505.10371", "authors": ["Kai Sun", "Peibo Duan", "Levin Kuhlmann", "Beilun Wang", "Bin Zhang"], "title": "ILIF: Temporal Inhibitory Leaky Integrate-and-Fire Neuron for Overactivation in Spiking Neural Networks", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": null, "summary": "The Spiking Neural Network (SNN) has drawn increasing attention for its\nenergy-efficient, event-driven processing and biological plausibility. To train\nSNNs via backpropagation, surrogate gradients are used to approximate the\nnon-differentiable spike function, but they only maintain nonzero derivatives\nwithin a narrow range of membrane potentials near the firing threshold,\nreferred to as the surrogate gradient support width gamma. We identify a major\nchallenge, termed the dilemma of gamma: a relatively large gamma leads to\noveractivation, characterized by excessive neuron firing, which in turn\nincreases energy consumption, whereas a small gamma causes vanishing gradients\nand weakens temporal dependencies. To address this, we propose a temporal\nInhibitory Leaky Integrate-and-Fire (ILIF) neuron model, inspired by biological\ninhibitory mechanisms. This model incorporates interconnected inhibitory units\nfor membrane potential and current, effectively mitigating overactivation while\npreserving gradient propagation. Theoretical analysis demonstrates ILIF\neffectiveness in overcoming the gamma dilemma, and extensive experiments on\nmultiple datasets show that ILIF improves energy efficiency by reducing firing\nrates, stabilizes training, and enhances accuracy. The code is available at\ngithub.com/kaisun1/ILIF."}
{"id": "2505.09805", "pdf": "https://arxiv.org/pdf/2505.09805", "abs": "https://arxiv.org/abs/2505.09805", "authors": ["Aditya Nagori", "Ayush Gautam", "Matthew O. Wiens", "Vuong Nguyen", "Nathan Kenya Mugisha", "Jerome Kabakyenga", "Niranjan Kissoon", "John Mark Ansermino", "Rishikesan Kamaleswaran"], "title": "Contextual Phenotyping of Pediatric Sepsis Cohort Using Large Language Models", "categories": ["q-bio.QM", "cs.AI", "cs.LG", "stat.AP"], "comment": "11 pages, 2 Figures, 1 Table", "summary": "Clustering patient subgroups is essential for personalized care and efficient\nresource use. Traditional clustering methods struggle with high-dimensional,\nheterogeneous healthcare data and lack contextual understanding. This study\nevaluates Large Language Model (LLM) based clustering against classical methods\nusing a pediatric sepsis dataset from a low-income country (LIC), containing\n2,686 records with 28 numerical and 119 categorical variables. Patient records\nwere serialized into text with and without a clustering objective. Embeddings\nwere generated using quantized LLAMA 3.1 8B, DeepSeek-R1-Distill-Llama-8B with\nlow-rank adaptation(LoRA), and Stella-En-400M-V5 models. K-means clustering was\napplied to these embeddings. Classical comparisons included K-Medoids\nclustering on UMAP and FAMD-reduced mixed data. Silhouette scores and\nstatistical tests evaluated cluster quality and distinctiveness.\nStella-En-400M-V5 achieved the highest Silhouette Score (0.86). LLAMA 3.1 8B\nwith the clustering objective performed better with higher number of clusters,\nidentifying subgroups with distinct nutritional, clinical, and socioeconomic\nprofiles. LLM-based methods outperformed classical techniques by capturing\nricher context and prioritizing key features. These results highlight potential\nof LLMs for contextual phenotyping and informed decision-making in\nresource-limited settings."}
{"id": "2505.10375", "pdf": "https://arxiv.org/pdf/2505.10375", "abs": "https://arxiv.org/abs/2505.10375", "authors": ["Rui Melo", "Claudia Mamede", "Andre Catarino", "Rui Abreu", "Henrique Lopes Cardoso"], "title": "Are Sparse Autoencoders Useful for Java Function Bug Detection?", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "10 pages, 10 figures", "summary": "Software vulnerabilities such as buffer overflows and SQL injections are a\nmajor source of security breaches. Traditional methods for vulnerability\ndetection remain essential but are limited by high false positive rates,\nscalability issues, and reliance on manual effort. These constraints have\ndriven interest in AI-based approaches to automated vulnerability detection and\nsecure code generation. While Large Language Models (LLMs) have opened new\navenues for classification tasks, their complexity and opacity pose challenges\nfor interpretability and deployment. Sparse Autoencoder offer a promising\nsolution to this problem. We explore whether SAEs can serve as a lightweight,\ninterpretable alternative for bug detection in Java functions. We evaluate the\neffectiveness of SAEs when applied to representations from GPT-2 Small and\nGemma 2B, examining their capacity to highlight buggy behaviour without\nfine-tuning the underlying LLMs. We found that SAE-derived features enable bug\ndetection with an F1 score of up to 89%, consistently outperforming fine-tuned\ntransformer encoder baselines. Our work provides the first empirical evidence\nthat SAEs can be used to detect software bugs directly from the internal\nrepresentations of pretrained LLMs, without any fine-tuning or task-specific\nsupervision."}
{"id": "2505.09814", "pdf": "https://arxiv.org/pdf/2505.09814", "abs": "https://arxiv.org/abs/2505.09814", "authors": ["Dmitry Rybin", "Yushun Zhang", "Zhi-Quan Luo"], "title": "$XX^{t}$ Can Be Faster", "categories": ["cs.DS", "cs.AI", "cs.LG", "cs.SC", "68Q25, 68T20", "F.2.1; I.1.2"], "comment": null, "summary": "We present a new algorithm RXTX that computes product of matrix by its\ntranspose $XX^{t}$. RXTX uses $5\\%$ less multiplications and additions than\nState-of-the-Art and achieves accelerations even for small sizes of matrix $X$.\nThe algorithm was discovered by combining Machine Learning-based search methods\nwith Combinatorial Optimization."}
{"id": "2505.10387", "pdf": "https://arxiv.org/pdf/2505.10387", "abs": "https://arxiv.org/abs/2505.10387", "authors": ["Artem Agafonov", "Konstantin Yakovlev"], "title": "Multi-Agent Path Finding For Large Agents Is Intractable", "categories": ["cs.MA", "cs.AI", "cs.CC"], "comment": null, "summary": "The multi-agent path finding (MAPF) problem asks to find a set of paths on a\ngraph such that when synchronously following these paths the agents never\nencounter a conflict. In the most widespread MAPF formulation, the so-called\nClassical MAPF, the agents sizes are neglected and two types of conflicts are\nconsidered: occupying the same vertex or using the same edge at the same time\nstep. Meanwhile in numerous practical applications, e.g. in robotics, taking\ninto account the agents' sizes is vital to ensure that the MAPF solutions can\nbe safely executed. Introducing large agents yields an additional type of\nconflict arising when one agent follows an edge and its body overlaps with the\nbody of another agent that is actually not using this same edge (e.g. staying\nstill at some distinct vertex of the graph). Until now it was not clear how\nharder the problem gets when such conflicts are to be considered while\nplanning. Specifically, it was known that Classical MAPF problem on an\nundirected graph can be solved in polynomial time, however no complete\npolynomial-time algorithm was presented to solve MAPF with large agents. In\nthis paper we, for the first time, establish that the latter problem is NP-hard\nand, thus, if P!=NP no polynomial algorithm for it can, unfortunately, be\npresented. Our proof is based on the prevalent in the field technique of\nreducing the seminal 3SAT problem (which is known to be an NP-complete problem)\nto the problem at hand. In particular, for an arbitrary 3SAT formula we\nprocedurally construct a dedicated graph with specific start and goal vertices\nand show that the given 3SAT formula is satisfiable iff the corresponding path\nfinding instance has a solution."}
{"id": "2505.09819", "pdf": "https://arxiv.org/pdf/2505.09819", "abs": "https://arxiv.org/abs/2505.09819", "authors": ["Ruichen Yang", "György M. Lévay", "Christopher L. Hunt", "Dániel Czeiner", "Megan C. Hodgson", "Damini Agarwal", "Rahul R. Kaliki", "Nitish V. Thakor"], "title": "Visual Feedback of Pattern Separability Improves Myoelectric Decoding Performance of Upper Limb Prostheses", "categories": ["cs.HC", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "State-of-the-art upper limb myoelectric prostheses often use pattern\nrecognition (PR) control systems that translate electromyography (EMG) signals\ninto desired movements. As prosthesis movement complexity increases, users\noften struggle to produce sufficiently distinct EMG patterns for reliable\nclassification. Existing training typically involves heuristic, trial-and-error\nuser adjustments to static decoder boundaries. Goal: We introduce the Reviewer,\na 3D visual interface projecting EMG signals directly into the decoder's\nclassification space, providing intuitive, real-time insight into PR algorithm\nbehavior. This structured feedback reduces cognitive load and fosters mutual,\ndata-driven adaptation between user-generated EMG patterns and decoder\nboundaries. Methods: A 10-session study with 12 able-bodied participants\ncompared PR performance after motor-based training and updating using the\nReviewer versus conventional virtual arm visualization. Performance was\nassessed using a Fitts law task that involved the aperture of the cursor and\nthe control of orientation. Results: Participants trained with the Reviewer\nachieved higher completion rates, reduced overshoot, and improved path\nefficiency and throughput compared to the standard visualization group.\nSignificance: The Reviewer introduces decoder-informed motor training,\nfacilitating immediate and consistent PR-based myoelectric control\nimprovements. By iteratively refining control through real-time feedback, this\napproach reduces reliance on trial-and-error recalibration, enabling a more\nadaptive, self-correcting training framework. Conclusion: The 3D visual\nfeedback significantly improves PR control in novice operators through\nstructured training, enabling feedback-driven adaptation and reducing reliance\non extensive heuristic adjustments."}
{"id": "2505.10392", "pdf": "https://arxiv.org/pdf/2505.10392", "abs": "https://arxiv.org/abs/2505.10392", "authors": ["Aryan Mishra", "Lizhen Lin"], "title": "Schreier-Coset Graph Propagation", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 1 figure , preprint", "summary": "Graph Neural Networks (GNNs) offer a principled framework for learning over\ngraph-structured data, yet their expressive capacity is often hindered by\nover-squashing, wherein information from distant nodes is compressed into\nfixed-size vectors. Existing solutions, including graph rewiring and\nbottleneck-resistant architectures such as Cayley and expander graphs, avoid\nthis problem but introduce scalability bottlenecks. In particular, the Cayley\ngraphs constructed over $SL(2,\\mathbb{Z}_n)$ exhibit strong theoretical\nproperties, yet suffer from cubic node growth $O(n^3)$, leading to high memory\nusage. To address this, this work introduces Schrier-Coset Graph Propagation\n(SCGP), a group-theoretic augmentation method that enriches node features\nthrough Schreier-coset embeddings without altering the input graph topology.\nSCGP embeds bottleneck-free connectivity patterns into a compact feature space,\nimproving long-range message passing while maintaining computational\nefficiency. Empirical evaluations across standard node and graph classification\nbenchmarks demonstrate that SCGP achieves performance comparable to, or\nexceeding, expander graph and rewired GNN baselines. Furthermore, SCGP exhibits\nparticular advantages in processing hierarchical and modular graph structures,\noffering reduced inference latency, improved scalability, and a low memory\nfootprint, making it suitable for real-time and resource-constrained\napplications."}
{"id": "2505.09833", "pdf": "https://arxiv.org/pdf/2505.09833", "abs": "https://arxiv.org/abs/2505.09833", "authors": ["Tuba Girgin", "Emre Girgin", "Cagri Kilic"], "title": "Learning Rock Pushability on Rough Planetary Terrain", "categories": ["cs.RO", "cs.LG"], "comment": "Paper presented at the Workshop on Field Robotics, ICRA 2025,\n  Atlanta, GA, United States", "summary": "In the context of mobile navigation in unstructured environments, the\npredominant approach entails the avoidance of obstacles. The prevailing path\nplanning algorithms are contingent upon deviating from the intended path for an\nindefinite duration and returning to the closest point on the route after the\nobstacle is left behind spatially. However, avoiding an obstacle on a path that\nwill be used repeatedly by multiple agents can hinder long-term efficiency and\nlead to a lasting reliance on an active path planning system. In this study, we\npropose an alternative approach to mobile navigation in unstructured\nenvironments by leveraging the manipulation capabilities of a robotic\nmanipulator mounted on top of a mobile robot. Our proposed framework integrates\nexteroceptive and proprioceptive feedback to assess the push affordance of\nobstacles, facilitating their repositioning rather than avoidance. While our\npreliminary visual estimation takes into account the characteristics of both\nthe obstacle and the surface it relies on, the push affordance estimation\nmodule exploits the force feedback obtained by interacting with the obstacle\nvia a robotic manipulator as the guidance signal. The objective of our\nnavigation approach is to enhance the efficiency of routes utilized by multiple\nagents over extended periods by reducing the overall time spent by a fleet in\nenvironments where autonomous infrastructure development is imperative, such as\nlunar or Martian surfaces."}
{"id": "2505.10393", "pdf": "https://arxiv.org/pdf/2505.10393", "abs": "https://arxiv.org/abs/2505.10393", "authors": ["Agustin Medina", "Marcelo Arlego", "Carlos A. Lamas"], "title": "Uncovering Magnetic Phases with Synthetic Data and Physics-Informed Training", "categories": ["cond-mat.str-el", "cs.AI"], "comment": "25 pages, 14 figures", "summary": "We investigate the efficient learning of magnetic phases using artificial\nneural networks trained on synthetic data, combining computational simplicity\nwith physics-informed strategies. Focusing on the diluted Ising model, which\nlacks an exact analytical solution, we explore two complementary approaches: a\nsupervised classification using simple dense neural networks, and an\nunsupervised detection of phase transitions using convolutional autoencoders\ntrained solely on idealized spin configurations.\n  To enhance model performance, we incorporate two key forms of\nphysics-informed guidance. First, we exploit architectural biases which\npreferentially amplify features related to symmetry breaking. Second, we\ninclude training configurations that explicitly break $\\mathbb{Z}_2$ symmetry,\nreinforcing the network's ability to detect ordered phases. These mechanisms,\nacting in tandem, increase the network's sensitivity to phase structure even in\nthe absence of explicit labels. We validate the machine learning predictions\nthrough comparison with direct numerical estimates of critical temperatures and\npercolation thresholds.\n  Our results show that synthetic, structured, and computationally efficient\ntraining schemes can reveal physically meaningful phase boundaries, even in\ncomplex systems. This framework offers a low-cost and robust alternative to\nconventional methods, with potential applications in broader condensed matter\nand statistical physics contexts."}
{"id": "2505.09843", "pdf": "https://arxiv.org/pdf/2505.09843", "abs": "https://arxiv.org/abs/2505.09843", "authors": ["Melissa Turcotte", "François Labrèche", "Serge-Olivier Paquette"], "title": "Automated Alert Classification and Triage (AACT): An Intelligent System for the Prioritisation of Cybersecurity Alerts", "categories": ["cs.CR", "cs.LG", "stat.AP"], "comment": null, "summary": "Enterprise networks are growing ever larger with a rapidly expanding attack\nsurface, increasing the volume of security alerts generated from security\ncontrols. Security Operations Centre (SOC) analysts triage these alerts to\nidentify malicious activity, but they struggle with alert fatigue due to the\noverwhelming number of benign alerts. Organisations are turning to managed SOC\nproviders, where the problem is amplified by context switching and limited\nvisibility into business processes.\n  A novel system, named AACT, is introduced that automates SOC workflows by\nlearning from analysts' triage actions on cybersecurity alerts. It accurately\npredicts triage decisions in real time, allowing benign alerts to be closed\nautomatically and critical ones prioritised. This reduces the SOC queue\nallowing analysts to focus on the most severe, relevant or ambiguous threats.\nThe system has been trained and evaluated on both real SOC data and an open\ndataset, obtaining high performance in identifying malicious alerts from benign\nalerts.\n  Additionally, the system has demonstrated high accuracy in a real SOC\nenvironment, reducing alerts shown to analysts by 61% over six months, with a\nlow false negative rate of 1.36% over millions of alerts."}
{"id": "2505.10394", "pdf": "https://arxiv.org/pdf/2505.10394", "abs": "https://arxiv.org/abs/2505.10394", "authors": ["Meghyn Bienvenu", "Camille Bourgaux", "Atefe Khodadaditaghanaki"], "title": "Inconsistency Handling in DatalogMTL", "categories": ["cs.LO", "cs.AI", "cs.DB"], "comment": "This is an extended version of a paper appearing at the 34th\n  International Joint Conference on Artificial Intelligence (IJCAI 2025). 24\n  pages", "summary": "In this paper, we explore the issue of inconsistency handling in DatalogMTL,\nan extension of Datalog with metric temporal operators. Since facts are\nassociated with time intervals, there are different manners to restore\nconsistency when they contradict the rules, such as removing facts or modifying\ntheir time intervals. Our first contribution is the definition of relevant\nnotions of conflicts (minimal explanations for inconsistency) and repairs\n(possible ways of restoring consistency) for this setting and the study of the\nproperties of these notions and the associated inconsistency-tolerant\nsemantics. Our second contribution is a data complexity analysis of the tasks\nof generating a single conflict / repair and query entailment under\nrepair-based semantics."}
{"id": "2505.09932", "pdf": "https://arxiv.org/pdf/2505.09932", "abs": "https://arxiv.org/abs/2505.09932", "authors": ["Kevin J McNamara", "Rhea Pritham Marpu"], "title": "Demystifying AI Agents: The Final Generation of Intelligence", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.MA"], "comment": null, "summary": "The trajectory of artificial intelligence (AI) has been one of relentless\nacceleration, evolving from rudimentary rule-based systems to sophisticated,\nautonomous agents capable of complex reasoning and interaction. This whitepaper\nchronicles this remarkable journey, charting the key technological\nmilestones--advancements in prompting, training methodologies, hardware\ncapabilities, and architectural innovations--that have converged to create the\nAI agents of today. We argue that these agents, exemplified by systems like\nOpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in\nAI development, potentially constituting the \"final generation\" of intelligence\nas we currently conceive it. We explore the capabilities and underlying\ntechnologies of these agents, grounded in practical examples, while also\nexamining the profound societal implications and the unprecedented pace of\nprogress that suggests intelligence is now doubling approximately every six\nmonths. The paper concludes by underscoring the critical need for wisdom and\nforesight in navigating the opportunities and challenges presented by this\npowerful new era of intelligence."}
{"id": "2505.10402", "pdf": "https://arxiv.org/pdf/2505.10402", "abs": "https://arxiv.org/abs/2505.10402", "authors": ["Yihong Dong", "Yuchen Liu", "Xue Jiang", "Zhi Jin", "Ge Li"], "title": "Rethinking Repetition Problems of LLMs in Code Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to ACL 2025 (main)", "summary": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code."}
{"id": "2505.09935", "pdf": "https://arxiv.org/pdf/2505.09935", "abs": "https://arxiv.org/abs/2505.09935", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Quoc Dai Tran"], "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users."}
{"id": "2505.10405", "pdf": "https://arxiv.org/pdf/2505.10405", "abs": "https://arxiv.org/abs/2505.10405", "authors": ["Jianhao Huang", "Qunsong Zeng", "Kaibin Huang"], "title": "Visual Fidelity Index for Generative Semantic Communications with Critical Information Embedding", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Generative semantic communication (Gen-SemCom) with large artificial\nintelligence (AI) model promises a transformative paradigm for 6G networks,\nwhich reduces communication costs by transmitting low-dimensional prompts\nrather than raw data. However, purely prompt-driven generation loses\nfine-grained visual details. Additionally, there is a lack of systematic\nmetrics to evaluate the performance of Gen-SemCom systems. To address these\nissues, we develop a hybrid Gen-SemCom system with a critical information\nembedding (CIE) framework, where both text prompts and semantically critical\nfeatures are extracted for transmissions. First, a novel approach of semantic\nfiltering is proposed to select and transmit the semantically critical features\nof images relevant to semantic label. By integrating the text prompt and\ncritical features, the receiver reconstructs high-fidelity images using a\ndiffusion-based generative model. Next, we propose the generative visual\ninformation fidelity (GVIF) metric to evaluate the visual quality of the\ngenerated image. By characterizing the statistical models of image features,\nthe GVIF metric quantifies the mutual information between the distorted\nfeatures and their original counterparts. By maximizing the GVIF metric, we\ndesign a channel-adaptive Gen-SemCom system that adaptively control the volume\nof features and compression rate according to the channel state. Experimental\nresults validate the GVIF metric's sensitivity to visual fidelity, correlating\nwith both the PSNR and critical information volume. In addition, the optimized\nsystem achieves superior performance over benchmarking schemes in terms of\nhigher PSNR and lower FID scores."}
{"id": "2505.09945", "pdf": "https://arxiv.org/pdf/2505.09945", "abs": "https://arxiv.org/abs/2505.09945", "authors": ["Deeksha Prahlad", "Chanhee Lee", "Dongha Kim", "Hokeun Kim"], "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)", "summary": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time."}
{"id": "2505.10420", "pdf": "https://arxiv.org/pdf/2505.10420", "abs": "https://arxiv.org/abs/2505.10420", "authors": ["Andrei Arhire", "Radu Timofte"], "title": "Learned Lightweight Smartphone ISP with Unpaired Data", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at CVPRW 2025", "summary": "The Image Signal Processor (ISP) is a fundamental component in modern\nsmartphone cameras responsible for conversion of RAW sensor image data to RGB\nimages with a strong focus on perceptual quality. Recent work highlights the\npotential of deep learning approaches and their ability to capture details with\na quality increasingly close to that of professional cameras. A difficult and\ncostly step when developing a learned ISP is the acquisition of pixel-wise\naligned paired data that maps the raw captured by a smartphone camera sensor to\nhigh-quality reference images. In this work, we address this challenge by\nproposing a novel training method for a learnable ISP that eliminates the need\nfor direct correspondences between raw images and ground-truth data with\nmatching content. Our unpaired approach employs a multi-term loss function\nguided by adversarial training with multiple discriminators processing feature\nmaps from pre-trained networks to maintain content structure while learning\ncolor and texture characteristics from the target RGB dataset. Using\nlightweight neural network architectures suitable for mobile devices as\nbackbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm\nUltraISP datasets. Compared to paired training methods, our unpaired learning\nstrategy shows strong potential and achieves high fidelity across multiple\nevaluation metrics. The code and pre-trained models are available at\nhttps://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data ."}
{"id": "2505.09972", "pdf": "https://arxiv.org/pdf/2505.09972", "abs": "https://arxiv.org/abs/2505.09972", "authors": ["Anchen Sun", "Tiantian Feng", "Gabriela Gutierrez", "Juan J Londono", "Anfeng Xu", "Batya Elbaum", "Shrikanth Narayanan", "Lynn K Perry", "Daniel S Messinger"], "title": "Who Said What WSW 2.0? Enhanced Automated Analysis of Preschool Classroom Speech", "categories": ["eess.AS", "cs.LG"], "comment": "8 pages, 2 figures, 5 tables", "summary": "This paper introduces an automated framework WSW2.0 for analyzing vocal\ninteractions in preschool classrooms, enhancing both accuracy and scalability\nthrough the integration of wav2vec2-based speaker classification and Whisper\n(large-v2 and large-v3) speech transcription. A total of 235 minutes of audio\nrecordings (160 minutes from 12 children and 75 minutes from 5 teachers), were\nused to compare system outputs to expert human annotations. WSW2.0 achieves a\nweighted F1 score of .845, accuracy of .846, and an error-corrected kappa of\n.672 for speaker classification (child vs. teacher). Transcription quality is\nmoderate to high with word error rates of .119 for teachers and .238 for\nchildren. WSW2.0 exhibits relatively high absolute agreement intraclass\ncorrelations (ICC) with expert transcriptions for a range of classroom language\nfeatures. These include teacher and child mean utterance length, lexical\ndiversity, question asking, and responses to questions and other utterances,\nwhich show absolute agreement intraclass correlations between .64 and .98. To\nestablish scalability, we apply the framework to an extensive dataset spanning\ntwo years and over 1,592 hours of classroom audio recordings, demonstrating the\nframework's robustness for broad real-world applications. These findings\nhighlight the potential of deep learning and natural language processing\ntechniques to revolutionize educational research by providing accurate measures\nof key features of preschool classroom speech, ultimately guiding more\neffective intervention strategies and supporting early childhood language\ndevelopment."}
{"id": "2505.10441", "pdf": "https://arxiv.org/pdf/2505.10441", "abs": "https://arxiv.org/abs/2505.10441", "authors": ["Filippo Leveni", "Luca Magri", "Giacomo Boracchi", "Cesare Alippi"], "title": "PIF: Anomaly detection via preference embedding", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)", "summary": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space."}
{"id": "2505.10030", "pdf": "https://arxiv.org/pdf/2505.10030", "abs": "https://arxiv.org/abs/2505.10030", "authors": ["Miit Daga", "Dhriti Parikh", "Swarna Priya Ramu"], "title": "DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera", "categories": ["cs.CV", "cs.LG"], "comment": "This paper is accepted for publication in IEEE Access journal and is\n  currently pending revisions before publication", "summary": "Coconut tree diseases are a serious risk to agricultural yield, particularly\nin developing countries where conventional farming practices restrict early\ndiagnosis and intervention. Current disease identification methods are manual,\nlabor-intensive, and non-scalable. In response to these limitations, we come up\nwith DeepSeqCoco, a deep learning based model for accurate and automatic\ndisease identification from coconut tree images. The model was tested under\nvarious optimizer settings, such as SGD, Adam, and hybrid configurations, to\nidentify the optimal balance between accuracy, minimization of loss, and\ncomputational cost. Results from experiments indicate that DeepSeqCoco can\nachieve as much as 99.5% accuracy (achieving up to 5% higher accuracy than\nexisting models) with the hybrid SGD-Adam showing the lowest validation loss of\n2.81%. It also shows a drop of up to 18% in training time and up to 85% in\nprediction time for input images. The results point out the promise of the\nmodel to improve precision agriculture through an AI-based, scalable, and\nefficient disease monitoring system."}
{"id": "2505.10442", "pdf": "https://arxiv.org/pdf/2505.10442", "abs": "https://arxiv.org/abs/2505.10442", "authors": ["Dechen Gao", "Hang Wang", "Hanchu Zhou", "Nejib Ammar", "Shatadal Mishra", "Ahmadreza Moradipari", "Iman Soltani", "Junshan Zhang"], "title": "IN-RIL: Interleaved Reinforcement and Imitation Learning for Policy Fine-Tuning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Imitation learning (IL) and reinforcement learning (RL) each offer distinct\nadvantages for robotics policy learning: IL provides stable learning from\ndemonstrations, and RL promotes generalization through exploration. While\nexisting robot learning approaches using IL-based pre-training followed by\nRL-based fine-tuning are promising, this two-step learning paradigm often\nsuffers from instability and poor sample efficiency during the RL fine-tuning\nphase. In this work, we introduce IN-RIL, INterleaved Reinforcement learning\nand Imitation Learning, for policy fine-tuning, which periodically injects IL\nupdates after multiple RL updates and hence can benefit from the stability of\nIL and the guidance of expert data for more efficient exploration throughout\nthe entire fine-tuning process. Since IL and RL involve different optimization\nobjectives, we develop gradient separation mechanisms to prevent destructive\ninterference during \\ABBR fine-tuning, by separating possibly conflicting\ngradient updates in orthogonal subspaces. Furthermore, we conduct rigorous\nanalysis, and our findings shed light on why interleaving IL with RL stabilizes\nlearning and improves sample-efficiency. Extensive experiments on 14 robot\nmanipulation and locomotion tasks across 3 benchmarks, including\nFurnitureBench, OpenAI Gym, and Robomimic, demonstrate that \\ABBR can\nsignificantly improve sample efficiency and mitigate performance collapse\nduring online finetuning in both long- and short-horizon tasks with either\nsparse or dense rewards. IN-RIL, as a general plug-in compatible with various\nstate-of-the-art RL algorithms, can significantly improve RL fine-tuning, e.g.,\nfrom 12\\% to 88\\% with 6.3x improvement in the success rate on Robomimic\nTransport. Project page: https://github.com/ucd-dare/IN-RIL."}
{"id": "2505.10033", "pdf": "https://arxiv.org/pdf/2505.10033", "abs": "https://arxiv.org/abs/2505.10033", "authors": ["Luis F. W. Batista", "Stéphanie Aravecchia", "Seth Hutchinson", "Cédric Pradalier"], "title": "Evaluating Robustness of Deep Reinforcement Learning for Autonomous Surface Vehicle Control in Field Tests", "categories": ["cs.RO", "cs.LG"], "comment": "Workshop on Field Robotics at ICRA 2025", "summary": "Despite significant advancements in Deep Reinforcement Learning (DRL) for\nAutonomous Surface Vehicles (ASVs), their robustness in real-world conditions,\nparticularly under external disturbances, remains insufficiently explored. In\nthis paper, we evaluate the resilience of a DRL-based agent designed to capture\nfloating waste under various perturbations. We train the agent using domain\nrandomization and evaluate its performance in real-world field tests, assessing\nits ability to handle unexpected disturbances such as asymmetric drag and an\noff-center payload. We assess the agent's performance under these perturbations\nin both simulation and real-world experiments, quantifying performance\ndegradation and benchmarking it against an MPC baseline. Results indicate that\nthe DRL agent performs reliably despite significant disturbances. Along with\nthe open-source release of our implementation, we provide insights into\neffective training strategies, real-world challenges, and practical\nconsiderations for deploying DRLbased ASV controllers."}
{"id": "2505.10443", "pdf": "https://arxiv.org/pdf/2505.10443", "abs": "https://arxiv.org/abs/2505.10443", "authors": ["Pedro Orvalho", "Marta Kwiatkowska"], "title": "Are Large Language Models Robust in Understanding Code Against Semantics-Preserving Mutations?", "categories": ["cs.SE", "cs.AI"], "comment": "10 pages, 5 tables, 1 figure", "summary": "Understanding the reasoning and robustness of Large Language Models (LLMs) is\ncritical for their reliable use in programming tasks. While recent studies have\nassessed LLMs' ability to predict program outputs, most focus solely on the\naccuracy of those predictions, without evaluating the reasoning behind them.\nMoreover, it has been observed on mathematical reasoning tasks that LLMs can\narrive at correct answers through flawed logic, raising concerns about similar\nissues in code understanding.\n  In this work, we evaluate whether state-of-the-art LLMs with up to 8B\nparameters can reason about Python programs or are simply guessing. We apply\nfive semantics-preserving code mutations: renaming variables, mirroring\ncomparison expressions, swapping if-else branches, converting for loops to\nwhile, and loop unrolling. These mutations maintain program semantics while\naltering its syntax. We evaluated six LLMs and performed a human expert\nanalysis using LiveCodeBench to assess whether the correct predictions are\nbased on sound reasoning. We also evaluated prediction stability across\ndifferent code mutations on LiveCodeBench and CruxEval. Our findings show that\nsome LLMs, such as Llama3.2, produce correct predictions based on flawed\nreasoning in up to 61% of cases. Furthermore, LLMs often change predictions in\nresponse to our code mutations, indicating limited robustness in their semantic\nunderstanding."}
{"id": "2505.10066", "pdf": "https://arxiv.org/pdf/2505.10066", "abs": "https://arxiv.org/abs/2505.10066", "authors": ["Michael Fire", "Yitzhak Elbazis", "Adi Wasenstein", "Lior Rokach"], "title": "Dark LLMs: The Growing Threat of Unaligned AI Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50, 68T05, 68P25", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated."}
{"id": "2505.10453", "pdf": "https://arxiv.org/pdf/2505.10453", "abs": "https://arxiv.org/abs/2505.10453", "authors": ["Tyler Tran", "Sangeet Khemlani", "J. G. Trafton"], "title": "Vision language models have difficulty recognizing virtual objects", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision language models (VLMs) are AI systems paired with both language and\nvision encoders to process multimodal input. They are capable of performing\ncomplex semantic tasks such as automatic captioning, but it remains an open\nquestion about how well they comprehend the visuospatial properties of scenes\ndepicted in the images they process. We argue that descriptions of virtual\nobjects -- objects that are not visually represented in an image -- can help\ntest scene comprehension in these AI systems. For example, an image that\ndepicts a person standing under a tree can be paired with the following prompt:\nimagine that a kite is stuck in the tree. VLMs that comprehend the scene should\nupdate their representations and reason sensibly about the spatial relations\nbetween all three objects. We describe systematic evaluations of\nstate-of-the-art VLMs and show that their ability to process virtual objects is\ninadequate."}
{"id": "2505.10080", "pdf": "https://arxiv.org/pdf/2505.10080", "abs": "https://arxiv.org/abs/2505.10080", "authors": ["Weijie Xiong", "Zoë Holmes", "Armando Angrisani", "Yudai Suzuki", "Thiparat Chotibut", "Supanut Thanasilp"], "title": "Role of scrambling and noise in temporal information processing with quantum systems", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.LG", "cs.NE", "stat.ML"], "comment": "14+35 pages, 6+5 figures, 1 table", "summary": "Scrambling quantum systems have been demonstrated as effective substrates for\ntemporal information processing. While their role in providing rich feature\nmaps has been widely studied, a theoretical understanding of their performance\nin temporal tasks is still lacking. Here we consider a general quantum\nreservoir processing framework that captures a broad range of physical\ncomputing models with quantum systems. We examine the scalability and memory\nretention of the model with scrambling reservoirs modelled by high-order\nunitary designs in both noiseless and noisy settings. In the former regime, we\nshow that measurement readouts become exponentially concentrated with\nincreasing reservoir size, yet strikingly do not worsen with the reservoir\niterations. Thus, while repeatedly reusing a small scrambling reservoir with\nquantum data might be viable, scaling up the problem size deteriorates\ngeneralization unless one can afford an exponential shot overhead. In contrast,\nthe memory of early inputs and initial states decays exponentially in both\nreservoir size and reservoir iterations. In the noisy regime, we also prove\nexponential memory decays with iterations for local noisy channels. Proving\nthese results required us to introduce new proof techniques for bounding\nconcentration in temporal quantum learning models."}
{"id": "2505.10457", "pdf": "https://arxiv.org/pdf/2505.10457", "abs": "https://arxiv.org/abs/2505.10457", "authors": ["Matteo Gambella", "Vicente Javier Castro Solar", "Manuel Roveri"], "title": "SEAL: Searching Expandable Architectures for Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "comment": "8 pages, 5 figures", "summary": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios."}
{"id": "2505.10099", "pdf": "https://arxiv.org/pdf/2505.10099", "abs": "https://arxiv.org/abs/2505.10099", "authors": ["Sarat Moka", "Matias Quiroz", "Vali Asimit", "Samuel Muller"], "title": "A Scalable Gradient-Based Optimization Framework for Sparse Minimum-Variance Portfolio Selection", "categories": ["stat.ML", "cs.LG", "math.OC", "q-fin.PM"], "comment": null, "summary": "Portfolio optimization involves selecting asset weights to minimize a\nrisk-reward objective, such as the portfolio variance in the classical\nminimum-variance framework. Sparse portfolio selection extends this by imposing\na cardinality constraint: only $k$ assets from a universe of $p$ may be\nincluded. The standard approach models this problem as a mixed-integer\nquadratic program and relies on commercial solvers to find the optimal\nsolution. However, the computational costs of such methods increase\nexponentially with $k$ and $p$, making them too slow for problems of even\nmoderate size. We propose a fast and scalable gradient-based approach that\ntransforms the combinatorial sparse selection problem into a constrained\ncontinuous optimization task via Boolean relaxation, while preserving\nequivalence with the original problem on the set of binary points. Our\nalgorithm employs a tunable parameter that transmutes the auxiliary objective\nfrom a convex to a concave function. This allows a stable convex starting\npoint, followed by a controlled path toward a sparse binary solution as the\ntuning parameter increases and the objective moves toward concavity. In\npractice, our method matches commercial solvers in asset selection for most\ninstances and, in rare instances, the solution differs by a few assets whilst\nshowing a negligible error in portfolio variance."}
{"id": "2505.10465", "pdf": "https://arxiv.org/pdf/2505.10465", "abs": "https://arxiv.org/abs/2505.10465", "authors": ["Yizhou liu", "Ziming Liu", "Jeff Gore"], "title": "Superposition Yields Robust Neural Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages, 23 figures", "summary": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters."}
{"id": "2505.10134", "pdf": "https://arxiv.org/pdf/2505.10134", "abs": "https://arxiv.org/abs/2505.10134", "authors": ["Guangjin Pan", "Kaixuan Huang", "Hui Chen", "Shunqing Zhang", "Christian Häger", "Henk Wymeersch"], "title": "Large Wireless Localization Model (LWLM): A Foundation Model for Positioning in 6G Networks", "categories": ["eess.SP", "cs.AI", "cs.LG"], "comment": "13 pages,16 figures.This work has been submitted to the IEEE for\n  possible publication", "summary": "Accurate and robust localization is a critical enabler for emerging 5G and 6G\napplications, including autonomous driving, extended reality (XR), and smart\nmanufacturing. While data-driven approaches have shown promise, most existing\nmodels require large amounts of labeled data and struggle to generalize across\ndeployment scenarios and wireless configurations. To address these limitations,\nwe propose a foundation-model-based solution tailored for wireless\nlocalization. We first analyze how different self-supervised learning (SSL)\ntasks acquire general-purpose and task-specific semantic features based on\ninformation bottleneck (IB) theory. Building on this foundation, we design a\npretraining methodology for the proposed Large Wireless Localization Model\n(LWLM). Specifically, we propose an SSL framework that jointly optimizes three\ncomplementary objectives: (i) spatial-frequency masked channel modeling\n(SF-MCM), (ii) domain-transformation invariance (DTI), and (iii)\nposition-invariant contrastive learning (PICL). These objectives jointly\ncapture the underlying semantics of wireless channel from multiple\nperspectives. We further design lightweight decoders for key downstream tasks,\nincluding time-of-arrival (ToA) estimation, angle-of-arrival (AoA) estimation,\nsingle base station (BS) localization, and multiple BS localization.\nComprehensive experimental results confirm that LWLM consistently surpasses\nboth model-based and supervised learning baselines across all localization\ntasks. In particular, LWLM achieves 26.0%--87.5% improvement over transformer\nmodels without pretraining, and exhibits strong generalization under\nlabel-limited fine-tuning and unseen BS configurations, confirming its\npotential as a foundation model for wireless localization."}
{"id": "2505.10482", "pdf": "https://arxiv.org/pdf/2505.10482", "abs": "https://arxiv.org/abs/2505.10482", "authors": ["Ningyuan Yang", "Jiaxuan Gao", "Feng Gao", "Yi Wu", "Chao Yu"], "title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages for main text, 23 pages in total, submitted to Neurips, 13\n  figures", "summary": "Diffusion policies, widely adopted in decision-making scenarios such as\nrobotics, gaming and autonomous driving, are capable of learning diverse skills\nfrom demonstration data due to their high representation power. However, the\nsub-optimal and limited coverage of demonstration data could lead to diffusion\npolicies that generate sub-optimal trajectories and even catastrophic failures.\nWhile reinforcement learning (RL)-based fine-tuning has emerged as a promising\nsolution to address these limitations, existing approaches struggle to\neffectively adapt Proximal Policy Optimization (PPO) to diffusion models. This\nchallenge stems from the computational intractability of action likelihood\nestimation during the denoising process, which leads to complicated\noptimization objectives. In our experiments starting from randomly initialized\npolicies, we find that online tuning of Diffusion Policies demonstrates much\nlower sample efficiency compared to directly applying PPO on MLP policies\n(MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework\nthat reformulates Diffusion Policy as a noise-conditioned deterministic policy.\nBy treating each denoising step as a differentiable transformation conditioned\non pre-sampled noise, NCDPO enables tractable likelihood evaluation and\ngradient backpropagation through all diffusion timesteps. Our experiments\ndemonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when\ntraining from scratch, outperforming existing methods in both sample efficiency\nand final performance across diverse benchmarks, including continuous robot\ncontrol and multi-agent game scenarios. Furthermore, our experimental results\nshow that our method is robust to the number denoising timesteps in the\nDiffusion Policy."}
{"id": "2505.10139", "pdf": "https://arxiv.org/pdf/2505.10139", "abs": "https://arxiv.org/abs/2505.10139", "authors": ["Lorenz Vaitl", "Leon Klein"], "title": "Path Gradients after Flow Matching", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Boltzmann Generators have emerged as a promising machine learning tool for\ngenerating samples from equilibrium distributions of molecular systems using\nNormalizing Flows and importance weighting. Recently, Flow Matching has helped\nspeed up Continuous Normalizing Flows (CNFs), scale them to more complex\nmolecular systems, and minimize the length of the flow integration\ntrajectories. We investigate the benefits of using path gradients to fine-tune\nCNFs initially trained by Flow Matching, in the setting where a target energy\nis known. Our experiments show that this hybrid approach yields up to a\nthreefold increase in sampling efficiency for molecular systems, all while\nusing the same model, a similar computational budget and without the need for\nadditional sampling. Furthermore, by measuring the length of the flow\ntrajectories during fine-tuning, we show that path gradients largely preserve\nthe learned structure of the flow."}
{"id": "2505.10483", "pdf": "https://arxiv.org/pdf/2505.10483", "abs": "https://arxiv.org/abs/2505.10483", "authors": ["Yi Li", "Haonan Wang", "Qixiang Zhang", "Boyu Xiao", "Chenchang Hu", "Hualiang Wang", "Xiaomeng Li"], "title": "UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation", "categories": ["cs.CV", "cs.AI"], "comment": "UniEval is the first evaluation framework designed for unified\n  multimodal models, including a holistic benchmark UniBench and the UniScore\n  metric", "summary": "The emergence of unified multimodal understanding and generation models is\nrapidly attracting attention because of their ability to enhance\ninstruction-following capabilities while minimizing model redundancy. However,\nthere is a lack of a unified evaluation framework for these models, which would\nenable an elegant, simplified, and overall evaluation. Current models conduct\nevaluations on multiple task-specific benchmarks, but there are significant\nlimitations, such as the lack of overall results, errors from extra evaluation\nmodels, reliance on extensive labeled images, benchmarks that lack diversity,\nand metrics with limited capacity for instruction-following evaluation. To\ntackle these challenges, we introduce UniEval, the first evaluation framework\ndesigned for unified multimodal models without extra models, images, or\nannotations. This facilitates a simplified and unified evaluation process. The\nUniEval framework contains a holistic benchmark, UniBench (supports both\nunified and visual generation models), along with the corresponding UniScore\nmetric. UniBench includes 81 fine-grained tags contributing to high diversity.\nExperimental results indicate that UniBench is more challenging than existing\nbenchmarks, and UniScore aligns closely with human evaluations, surpassing\ncurrent metrics. Moreover, we extensively evaluated SoTA unified and visual\ngeneration models, uncovering new insights into Univeral's unique values."}
{"id": "2505.10160", "pdf": "https://arxiv.org/pdf/2505.10160", "abs": "https://arxiv.org/abs/2505.10160", "authors": ["Yannis Montreuil", "Axel Carlier", "Lai Xing Ng", "Wei Tsang Ooi"], "title": "One-Stage Top-$k$ Learning-to-Defer: Score-Based Surrogates with Theoretical Guarantees", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "We introduce the first one-stage Top-$k$ Learning-to-Defer framework, which\nunifies prediction and deferral by learning a shared score-based model that\nselects the $k$ most cost-effective entities-labels or experts-per input. While\nexisting one-stage L2D methods are limited to deferring to a single expert, our\napproach jointly optimizes prediction and deferral across multiple entities\nthrough a single end-to-end objective. We define a cost-sensitive loss and\nderive a novel convex surrogate that is independent of the cardinality\nparameter $k$, enabling generalization across Top-$k$ regimes without\nretraining. Our formulation recovers the Top-1 deferral policy of prior\nscore-based methods as a special case, and we prove that our surrogate is both\nBayes-consistent and $\\mathcal{H}$-consistent under mild assumptions. We\nfurther introduce an adaptive variant, Top-$k(x)$, which dynamically selects\nthe number of consulted entities per input to balance predictive accuracy and\nconsultation cost. Experiments on CIFAR-10 and SVHN confirm that our one-stage\nTop-$k$ method strictly outperforms Top-1 deferral, while Top-$k(x)$ achieves\nsuperior accuracy-cost trade-offs by tailoring allocations to input complexity."}
{"id": "2505.10515", "pdf": "https://arxiv.org/pdf/2505.10515", "abs": "https://arxiv.org/abs/2505.10515", "authors": ["Seongun Kim", "Sol A Kim", "Geonhyeong Kim", "Enver Menadjiev", "Chanwoo Lee", "Seongwook Chung", "Nari Kim", "Jaesik Choi"], "title": "PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, post hoc explanation methods have emerged to enhance model\ntransparency by attributing model outputs to input features. However, these\nmethods face challenges due to their specificity to certain neural network\narchitectures and data modalities. Existing explainable artificial intelligence\n(XAI) frameworks have attempted to address these challenges but suffer from\nseveral limitations. These include limited flexibility to diverse model\narchitectures and data modalities due to hard-coded implementations, a\nrestricted number of supported XAI methods because of the requirements for\nlayer-specific operations of attribution methods, and sub-optimal\nrecommendations of explanations due to the lack of evaluation and optimization\nphases. Consequently, these limitations impede the adoption of XAI technology\nin real-world applications, making it difficult for practitioners to select the\noptimal explanation method for their domain. To address these limitations, we\nintroduce \\textbf{PnPXAI}, a universal XAI framework that supports diverse data\nmodalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI\nautomatically detects model architectures, recommends applicable explanation\nmethods, and optimizes hyperparameters for optimal explanations. We validate\nthe framework's effectiveness through user surveys and showcase its versatility\nacross various domains, including medicine and finance."}
{"id": "2505.10169", "pdf": "https://arxiv.org/pdf/2505.10169", "abs": "https://arxiv.org/abs/2505.10169", "authors": ["Matthias Kümmerer", "Harneet Khanuja", "Matthias Bethge"], "title": "Modeling Saliency Dataset Bias", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.10182", "pdf": "https://arxiv.org/pdf/2505.10182", "abs": "https://arxiv.org/abs/2505.10182", "authors": ["Yoichi Ishibashi", "Taro Yano", "Masafumi Oyamada"], "title": "Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant improvements in\nreasoning capabilities through supervised fine-tuning and reinforcement\nlearning. However, when training reasoning models, these approaches are\nprimarily applicable to specific domains such as mathematics and programming,\nwhich imposes fundamental constraints on the breadth and scalability of\ntraining data. In contrast, continual pretraining (CPT) offers the advantage of\nnot requiring task-specific signals. Nevertheless, how to effectively\nsynthesize training data for reasoning and how such data affect a wide range of\ndomains remain largely unexplored. This study provides a detailed evaluation of\nReasoning CPT, a form of CPT that uses synthetic data to reconstruct the hidden\nthought processes underlying texts, based on the premise that texts are the\nresult of the author's thinking process. Specifically, we apply Reasoning CPT\nto Gemma2-9B using synthetic data with hidden thoughts derived from STEM and\nLaw corpora, and compare it to standard CPT on the MMLU benchmark. Our analysis\nreveals that Reasoning CPT consistently improves performance across all\nevaluated domains. Notably, reasoning skills acquired in one domain transfer\neffectively to others; the performance gap with conventional methods widens as\nproblem difficulty increases, with gains of up to 8 points on the most\nchallenging problems. Furthermore, models trained with hidden thoughts learn to\nadjust the depth of their reasoning according to problem difficulty."}
{"id": "2505.10522", "pdf": "https://arxiv.org/pdf/2505.10522", "abs": "https://arxiv.org/abs/2505.10522", "authors": ["Xinrui Wang", "Yan Jin"], "title": "Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) has demonstrated remarkable potential in robotic\nmanipulation but faces challenges in sample inefficiency and lack of\ninterpretability, limiting its applicability in real world scenarios. Enabling\nthe agent to gain a deeper understanding and adapt more efficiently to diverse\nworking scenarios is crucial, and strategic knowledge utilization is a key\nfactor in this process. This paper proposes a Knowledge Capture, Adaptation,\nand Composition (KCAC) framework to systematically integrate knowledge transfer\ninto RL through cross-task curriculum learning. KCAC is evaluated using a two\nblock stacking task in the CausalWorld benchmark, a complex robotic\nmanipulation environment. To our knowledge, existing RL approaches fail to\nsolve this task effectively, reflecting deficiencies in knowledge capture. In\nthis work, we redesign the benchmark reward function by removing rigid\nconstraints and strict ordering, allowing the agent to maximize total rewards\nconcurrently and enabling flexible task completion. Furthermore, we define two\nself-designed sub-tasks and implement a structured cross-task curriculum to\nfacilitate efficient learning. As a result, our KCAC approach achieves a 40\npercent reduction in training time while improving task success rates by 10\npercent compared to traditional RL methods. Through extensive evaluation, we\nidentify key curriculum design parameters subtask selection, transition timing,\nand learning rate that optimize learning efficiency and provide conceptual\nguidance for curriculum based RL frameworks. This work offers valuable insights\ninto curriculum design in RL and robotic learning."}
{"id": "2505.10191", "pdf": "https://arxiv.org/pdf/2505.10191", "abs": "https://arxiv.org/abs/2505.10191", "authors": ["Qingyu Zheng", "Qi Shao", "Guijun Han", "Wei Li", "Hong Li", "Xuan Wang"], "title": "LanTu: Dynamics-Enhanced Deep Learning for Eddy-Resolving Ocean Forecasting", "categories": ["physics.ao-ph", "cs.AI", "cs.LG", "nlin.CD"], "comment": "22 pages, 6 figures", "summary": "Mesoscale eddies dominate the spatiotemporal multiscale variability of the\nocean, and their impact on the energy cascade of the global ocean cannot be\nignored. Eddy-resolving ocean forecasting is providing more reliable protection\nfor fisheries and navigational safety, but also presents significant scientific\nchallenges and high computational costs for traditional numerical models.\nArtificial intelligence (AI)-based weather and ocean forecasting systems are\nbecoming powerful tools that balance forecast performance with computational\nefficiency. However, the complex multiscale features in the ocean dynamical\nsystem make AI models still face many challenges in mesoscale eddy forecasting\n(especially regional modelling). Here, we develop LanTu, a regional\neddy-resolving ocean forecasting system based on dynamics-enhanced deep\nlearning. We incorporate cross-scale interactions into LanTu and construct\nmultiscale physical constraint for optimising LanTu guided by knowledge of eddy\ndynamics in order to improve the forecasting skill of LanTu for mesoscale\nevolution. The results show that LanTu outperforms the existing advanced\noperational numerical ocean forecasting system (NOFS) and AI-based ocean\nforecasting system (AI-OFS) in temperature, salinity, sea level anomaly and\ncurrent prediction, with a lead time of more than 10 days. Our study highlights\nthat dynamics-enhanced deep learning (LanTu) can be a powerful paradigm for\neddy-resolving ocean forecasting."}
{"id": "2505.10537", "pdf": "https://arxiv.org/pdf/2505.10537", "abs": "https://arxiv.org/abs/2505.10537", "authors": ["Filippo Olimpieri", "Noemi Giustini", "Andrea Lacava", "Salvatore D'Oro", "Tommaso Melodia", "Francesca Cuomo"], "title": "LibIQ: Toward Real-Time Spectrum Classification in O-RAN dApps", "categories": ["cs.NI", "cs.AI"], "comment": "6 pages, 5 figures, 2 tables", "summary": "The O-RAN architecture is transforming cellular networks by adopting RAN\nsoftwarization and disaggregation concepts to enable data-driven monitoring and\ncontrol of the network. Such management is enabled by RICs, which facilitate\nnear-real-time and non-real-time network control through xApps and rApps.\nHowever, they face limitations, including latency overhead in data exchange\nbetween the RAN and RIC, restricting real-time monitoring, and the inability to\naccess user plain data due to privacy and security constraints, hindering use\ncases like beamforming and spectrum classification. In this paper, we leverage\nthe dApps concept to enable real-time RF spectrum classification with LibIQ, a\nnovel library for RF signals that facilitates efficient spectrum monitoring and\nsignal classification by providing functionalities to read I/Q samples as\ntime-series, create datasets and visualize time-series data through plots and\nspectrograms. Thanks to LibIQ, I/Q samples can be efficiently processed to\ndetect external RF signals, which are subsequently classified using a CNN\ninside the library. To achieve accurate spectrum analysis, we created an\nextensive dataset of time-series-based I/Q samples, representing distinct\nsignal types captured using a custom dApp running on a 5G deployment over the\nColosseum network emulator and an OTA testbed. We evaluate our model by\ndeploying LibIQ in heterogeneous scenarios with varying center frequencies,\ntime windows, and external RF signals. In real-time analysis, the model\nclassifies the processed I/Q samples, achieving an average accuracy of\napproximately 97.8\\% in identifying signal types across all scenarios. We\npledge to release both LibIQ and the dataset created as a publicly available\nframework upon acceptance."}
{"id": "2505.10223", "pdf": "https://arxiv.org/pdf/2505.10223", "abs": "https://arxiv.org/abs/2505.10223", "authors": ["Puru Vaish", "Felix Meister", "Tobias Heimann", "Christoph Brune", "Jelmer M. Wolterink"], "title": "Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at MIDL 2025", "summary": "Medical image segmentation models are often trained on curated datasets,\nleading to performance degradation when deployed in real-world clinical\nsettings due to mismatches between training and test distributions. While data\naugmentation techniques are widely used to address these challenges,\ntraditional visually consistent augmentation strategies lack the robustness\nneeded for diverse real-world scenarios. In this work, we systematically\nevaluate alternative augmentation strategies, focusing on MixUp and Auxiliary\nFourier Augmentation. These methods mitigate the effects of multiple variations\nwithout explicitly targeting specific sources of distribution shifts. We\ndemonstrate how these techniques significantly improve out-of-distribution\ngeneralization and robustness to imaging variations across a wide range of\ntransformations in cardiac cine MRI and prostate MRI segmentation. We\nquantitatively find that these augmentation methods enhance learned feature\nrepresentations by promoting separability and compactness. Additionally, we\nhighlight how their integration into nnU-Net training pipelines provides an\neasy-to-implement, effective solution for enhancing the reliability of medical\nsegmentation models in real-world applications."}
{"id": "2505.10547", "pdf": "https://arxiv.org/pdf/2505.10547", "abs": "https://arxiv.org/abs/2505.10547", "authors": ["Milan Ganai", "Rohan Sinha", "Christopher Agia", "Daniel Morton", "Marco Pavone"], "title": "Real-Time Out-of-Distribution Failure Prevention via Multi-Modal Reasoning", "categories": ["cs.RO", "cs.AI"], "comment": "Website: https://milanganai.github.io/fortress/", "summary": "Foundation models can provide robust high-level reasoning on appropriate\nsafety interventions in hazardous scenarios beyond a robot's training data,\ni.e. out-of-distribution (OOD) failures. However, due to the high inference\nlatency of Large Vision and Language Models, current methods rely on manually\ndefined intervention policies to enact fallbacks, thereby lacking the ability\nto plan generalizable, semantically safe motions. To overcome these challenges\nwe present FORTRESS, a framework that generates and reasons about semantically\nsafe fallback strategies in real time to prevent OOD failures. At a low\nfrequency in nominal operations, FORTRESS uses multi-modal reasoners to\nidentify goals and anticipate failure modes. When a runtime monitor triggers a\nfallback response, FORTRESS rapidly synthesizes plans to fallback goals while\ninferring and avoiding semantically unsafe regions in real time. By bridging\nopen-world, multi-modal reasoning with dynamics-aware planning, we eliminate\nthe need for hard-coded fallbacks and human safety interventions. FORTRESS\noutperforms on-the-fly prompting of slow reasoning models in safety\nclassification accuracy on synthetic benchmarks and real-world ANYmal robot\ndata, and further improves system safety and planning success in simulation and\non quadrotor hardware for urban navigation."}
{"id": "2505.10267", "pdf": "https://arxiv.org/pdf/2505.10267", "abs": "https://arxiv.org/abs/2505.10267", "authors": ["Pavel Korotaev", "Petr Surovtsev", "Alexander Kapitanov", "Karina Kvanchiani", "Aleksandr Nagaev"], "title": "HandReader: Advanced Techniques for Efficient Fingerspelling Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "https://github.com/ai-forever/handreader", "summary": "Fingerspelling is a significant component of Sign Language (SL), allowing the\ninterpretation of proper names, characterized by fast hand movements during\nsigning. Although previous works on fingerspelling recognition have focused on\nprocessing the temporal dimension of videos, there remains room for improving\nthe accuracy of these approaches. This paper introduces HandReader, a group of\nthree architectures designed to address the fingerspelling recognition task.\nHandReader$_{RGB}$ employs the novel Temporal Shift-Adaptive Module (TSAM) to\nprocess RGB features from videos of varying lengths while preserving important\nsequential information. HandReader$_{KP}$ is built on the proposed Temporal\nPose Encoder (TPE) operated on keypoints as tensors. Such keypoints composition\nin a batch allows the encoder to pass them through 2D and 3D convolution\nlayers, utilizing temporal and spatial information and accumulating keypoints\ncoordinates. We also introduce HandReader_RGB+KP - architecture with a joint\nencoder to benefit from RGB and keypoint modalities. Each HandReader model\npossesses distinct advantages and achieves state-of-the-art results on the\nChicagoFSWild and ChicagoFSWild+ datasets. Moreover, the models demonstrate\nhigh performance on the first open dataset for Russian fingerspelling, Znaki,\npresented in this paper. The Znaki dataset and HandReader pre-trained models\nare publicly available."}
{"id": "2505.10551", "pdf": "https://arxiv.org/pdf/2505.10551", "abs": "https://arxiv.org/abs/2505.10551", "authors": ["Yiwen Liu", "Jessica Bader", "Jae Myung Kim"], "title": "Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data", "categories": ["cs.CV", "cs.AI"], "comment": "CVPRW 2025", "summary": "With the development of photorealistic diffusion models, models trained in\npart or fully on synthetic data achieve progressively better results. However,\ndiffusion models still routinely generate images that would not exist in\nreality, such as a dog floating above the ground or with unrealistic texture\nartifacts. We define the concept of feasibility as whether attributes in a\nsynthetic image could realistically exist in the real-world domain; synthetic\nimages containing attributes that violate this criterion are considered\ninfeasible. Intuitively, infeasible images are typically considered\nout-of-distribution; thus, training on such images is expected to hinder a\nmodel's ability to generalize to real-world data, and they should therefore be\nexcluded from the training set whenever possible. However, does feasibility\nreally matter? In this paper, we investigate whether enforcing feasibility is\nnecessary when generating synthetic training data for CLIP-based classifiers,\nfocusing on three target attributes: background, color, and texture. We\nintroduce VariReal, a pipeline that minimally edits a given source image to\ninclude feasible or infeasible attributes given by the textual prompt generated\nby a large language model. Our experiments show that feasibility minimally\naffects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference\nin top-1 accuracy across three fine-grained datasets. Also, the attribute\nmatters on whether the feasible/infeasible images adversarially influence the\nclassification performance. Finally, mixing feasible and infeasible images in\ntraining datasets does not significantly impact performance compared to using\npurely feasible or infeasible datasets."}
{"id": "2505.10279", "pdf": "https://arxiv.org/pdf/2505.10279", "abs": "https://arxiv.org/abs/2505.10279", "authors": ["Gabriel R. Palma", "Sally McClean", "Brahim Allan", "Zeeshan Tariq", "Rafael A. Moral"], "title": "Estimating the number of household TV profiles based in customer behaviour using Gaussian mixture model averaging", "categories": ["stat.ME", "cs.LG"], "comment": "21 pages", "summary": "TV customers today face many choices from many live channels and on-demand\nservices. Providing a personalised experience that saves customers time when\ndiscovering content is essential for TV providers. However, a reliable\nunderstanding of their behaviour and preferences is key. When creating\npersonalised recommendations for TV, the biggest challenge is understanding\nviewing behaviour within households when multiple people are watching. The\nobjective is to detect and combine individual profiles to make\nbetter-personalised recommendations for group viewing. Our challenge is that we\nhave little explicit information about who is watching the devices at any time\n(individuals or groups). Also, we do not have a way to combine more than one\nindividual profile to make better recommendations for group viewing. We propose\na novel framework using a Gaussian mixture model averaging to obtain point\nestimates for the number of household TV profiles and a Bayesian random walk\nmodel to introduce uncertainty. We applied our approach using data from real\ncustomers whose TV-watching data totalled approximately half a million\nobservations. Our results indicate that combining our framework with the\nselected features provides a means to estimate the number of household TV\nprofiles and their characteristics, including shifts over time and\nquantification of uncertainty."}
{"id": "2505.10557", "pdf": "https://arxiv.org/pdf/2505.10557", "abs": "https://arxiv.org/abs/2505.10557", "authors": ["Ke Wang", "Junting Pan", "Linda Wei", "Aojun Zhou", "Weikang Shi", "Zimu Lu", "Han Xiao", "Yunqiao Yang", "Houxing Ren", "Mingjie Zhan", "Hongsheng Li"], "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder."}
{"id": "2505.10319", "pdf": "https://arxiv.org/pdf/2505.10319", "abs": "https://arxiv.org/abs/2505.10319", "authors": ["John Nicol", "Markus Frohme"], "title": "Deconstructing Subset Construction -- Reducing While Determinizing", "categories": ["cs.FL", "cs.LG"], "comment": "19 pages, 2 figures", "summary": "We present a novel perspective on the NFA canonization problem, which\nintroduces intermediate minimization steps to reduce the exploration space\non-the-fly. Essential to our approach are so-called equivalence registries\nwhich manage information about equivalent states and allow for incorporating\nfurther optimization techniques such as convexity closures or simulation to\nboost performance. Due to the generality of our approach, these concepts can be\nembedded in classic subset construction or Brzozowski's approach. We evaluate\nour approach on a set of real-world examples from automatic sequences and\nobserve that we are able to improve especially worst-case scenarios. We\nimplement our approach in an open-source library for users to experiment with."}
{"id": "2505.10559", "pdf": "https://arxiv.org/pdf/2505.10559", "abs": "https://arxiv.org/abs/2505.10559", "authors": ["Ziming Liu", "Yizhou Liu", "Jeff Gore", "Max Tegmark"], "title": "Neural Thermodynamic Laws for Large Language Model Training", "categories": ["cs.LG", "cs.AI", "physics.data-an", "stat.ML"], "comment": "18 pages, 10 figures", "summary": "Beyond neural scaling laws, little is known about the laws underlying large\nlanguage models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new\nframework that offers fresh insights into LLM training dynamics. On the\ntheoretical side, we demonstrate that key thermodynamic quantities (e.g.,\ntemperature, entropy, heat capacity, thermal conduction) and classical\nthermodynamic principles (e.g., the three laws of thermodynamics and the\nequipartition theorem) naturally emerge under river-valley loss landscape\nassumptions. On the practical side, this scientific perspective yields\nintuitive guidelines for designing learning rate schedules."}
{"id": "2505.10320", "pdf": "https://arxiv.org/pdf/2505.10320", "abs": "https://arxiv.org/abs/2505.10320", "authors": ["Chenxi Whitehouse", "Tianlu Wang", "Ping Yu", "Xian Li", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 8 tables, 11 figures", "summary": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses."}
{"id": "2505.10352", "pdf": "https://arxiv.org/pdf/2505.10352", "abs": "https://arxiv.org/abs/2505.10352", "authors": ["Shihao Zou", "Qingfeng Li", "Wei Ji", "Jingjing Li", "Yongkui Yang", "Guoqi Li", "Chao Dong"], "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer"}
{"id": "2505.10361", "pdf": "https://arxiv.org/pdf/2505.10361", "abs": "https://arxiv.org/abs/2505.10361", "authors": ["David Abel", "Michael Bowling", "André Barreto", "Will Dabney", "Shi Dong", "Steven Hansen", "Anna Harutyunyan", "Khimya Khetarpal", "Clare Lyle", "Razvan Pascanu", "Georgios Piliouras", "Doina Precup", "Jonathan Richens", "Mark Rowland", "Tom Schaul", "Satinder Singh"], "title": "Plasticity as the Mirror of Empowerment", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Agents are minimally entities that are influenced by their past observations\nand act to influence future observations. This latter capacity is captured by\nempowerment, which has served as a vital framing concept across artificial\nintelligence and cognitive science. This former capacity, however, is equally\nfoundational: In what ways, and to what extent, can an agent be influenced by\nwhat it observes? In this paper, we ground this concept in a universal\nagent-centric measure that we refer to as plasticity, and reveal a fundamental\nconnection to empowerment. Following a set of desiderata on a suitable\ndefinition, we define plasticity using a new information-theoretic quantity we\ncall the generalized directed information. We show that this new quantity\nstrictly generalizes the directed information introduced by Massey (1990) while\npreserving all of its desirable properties. Our first finding is that\nplasticity is the mirror of empowerment: The agent's plasticity is identical to\nthe empowerment of the environment, and vice versa. Our second finding\nestablishes a tension between the plasticity and empowerment of an agent,\nsuggesting that agent design needs to be mindful of both characteristics. We\nexplore the implications of these findings, and suggest that plasticity,\nempowerment, and their relationship are essential to understanding agency."}
{"id": "2505.10367", "pdf": "https://arxiv.org/pdf/2505.10367", "abs": "https://arxiv.org/abs/2505.10367", "authors": ["Chuanqing Pu", "Feilong Fan", "Nengling Tai", "Songyuan Liu", "Jinming Yu"], "title": "A Hybrid Strategy for Aggregated Probabilistic Forecasting and Energy Trading in HEFTCom2024", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": "Solution description of IEEE Hybrid Energy Forecasting and Trading\n  Competition (HEFTCom)", "summary": "Obtaining accurate probabilistic energy forecasts and making effective\ndecisions amid diverse uncertainties are routine challenges in future energy\nsystems. This paper presents the solution of team GEB, which ranked 3rd in\ntrading, 4th in forecasting, and 1st among student teams in the IEEE Hybrid\nEnergy Forecasting and Trading Competition 2024 (HEFTCom2024). The solution\nprovides accurate probabilistic forecasts for a wind-solar hybrid system, and\nachieves substantial trading revenue in the day-ahead electricity market. Key\ncomponents include: (1) a stacking-based approach combining sister forecasts\nfrom various Numerical Weather Predictions (NWPs) to provide wind power\nforecasts, (2) an online solar post-processing model to address the\ndistribution shift in the online test set caused by increased solar capacity,\n(3) a probabilistic aggregation method for accurate quantile forecasts of\nhybrid generation, and (4) a stochastic trading strategy to maximize expected\ntrading revenue considering uncertainties in electricity prices. This paper\nalso explores the potential of end-to-end learning to further enhance the\ntrading revenue by adjusting the distribution of forecast errors. Detailed case\nstudies are provided to validate the effectiveness of these proposed methods.\nCode for all mentioned methods is available for reproduction and further\nresearch in both industry and academia."}
{"id": "2505.10371", "pdf": "https://arxiv.org/pdf/2505.10371", "abs": "https://arxiv.org/abs/2505.10371", "authors": ["Kai Sun", "Peibo Duan", "Levin Kuhlmann", "Beilun Wang", "Bin Zhang"], "title": "ILIF: Temporal Inhibitory Leaky Integrate-and-Fire Neuron for Overactivation in Spiking Neural Networks", "categories": ["cs.NE", "cs.AI", "cs.LG"], "comment": null, "summary": "The Spiking Neural Network (SNN) has drawn increasing attention for its\nenergy-efficient, event-driven processing and biological plausibility. To train\nSNNs via backpropagation, surrogate gradients are used to approximate the\nnon-differentiable spike function, but they only maintain nonzero derivatives\nwithin a narrow range of membrane potentials near the firing threshold,\nreferred to as the surrogate gradient support width gamma. We identify a major\nchallenge, termed the dilemma of gamma: a relatively large gamma leads to\noveractivation, characterized by excessive neuron firing, which in turn\nincreases energy consumption, whereas a small gamma causes vanishing gradients\nand weakens temporal dependencies. To address this, we propose a temporal\nInhibitory Leaky Integrate-and-Fire (ILIF) neuron model, inspired by biological\ninhibitory mechanisms. This model incorporates interconnected inhibitory units\nfor membrane potential and current, effectively mitigating overactivation while\npreserving gradient propagation. Theoretical analysis demonstrates ILIF\neffectiveness in overcoming the gamma dilemma, and extensive experiments on\nmultiple datasets show that ILIF improves energy efficiency by reducing firing\nrates, stabilizes training, and enhances accuracy. The code is available at\ngithub.com/kaisun1/ILIF."}
{"id": "2505.10375", "pdf": "https://arxiv.org/pdf/2505.10375", "abs": "https://arxiv.org/abs/2505.10375", "authors": ["Rui Melo", "Claudia Mamede", "Andre Catarino", "Rui Abreu", "Henrique Lopes Cardoso"], "title": "Are Sparse Autoencoders Useful for Java Function Bug Detection?", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": "10 pages, 10 figures", "summary": "Software vulnerabilities such as buffer overflows and SQL injections are a\nmajor source of security breaches. Traditional methods for vulnerability\ndetection remain essential but are limited by high false positive rates,\nscalability issues, and reliance on manual effort. These constraints have\ndriven interest in AI-based approaches to automated vulnerability detection and\nsecure code generation. While Large Language Models (LLMs) have opened new\navenues for classification tasks, their complexity and opacity pose challenges\nfor interpretability and deployment. Sparse Autoencoder offer a promising\nsolution to this problem. We explore whether SAEs can serve as a lightweight,\ninterpretable alternative for bug detection in Java functions. We evaluate the\neffectiveness of SAEs when applied to representations from GPT-2 Small and\nGemma 2B, examining their capacity to highlight buggy behaviour without\nfine-tuning the underlying LLMs. We found that SAE-derived features enable bug\ndetection with an F1 score of up to 89%, consistently outperforming fine-tuned\ntransformer encoder baselines. Our work provides the first empirical evidence\nthat SAEs can be used to detect software bugs directly from the internal\nrepresentations of pretrained LLMs, without any fine-tuning or task-specific\nsupervision."}
{"id": "2505.10398", "pdf": "https://arxiv.org/pdf/2505.10398", "abs": "https://arxiv.org/abs/2505.10398", "authors": ["Alexandre Banks", "Randy Moore", "Sayem Nazmuz Zaman", "Alaa Eldin Abdelaal", "Septimiu E. Salcudean"], "title": "AutoCam: Hierarchical Path Planning for an Autonomous Auxiliary Camera in Surgical Robotics", "categories": ["cs.RO", "cs.HC", "cs.LG", "cs.SY", "eess.SP", "eess.SY", "J.3.2; J.2.7; I.2.9"], "comment": "13 pages, 9 figures", "summary": "Incorporating an autonomous auxiliary camera into robot-assisted minimally\ninvasive surgery (RAMIS) enhances spatial awareness and eliminates manual\nviewpoint control. Existing path planning methods for auxiliary cameras track\ntwo-dimensional surgical features but do not simultaneously account for camera\norientation, workspace constraints, and robot joint limits. This study presents\nAutoCam: an automatic auxiliary camera placement method to improve\nvisualization in RAMIS. Implemented on the da Vinci Research Kit, the system\nuses a priority-based, workspace-constrained control algorithm that combines\nheuristic geometric placement with nonlinear optimization to ensure robust\ncamera tracking. A user study (N=6) demonstrated that the system maintained\n99.84% visibility of a salient feature and achieved a pose error of 4.36 $\\pm$\n2.11 degrees and 1.95 $\\pm$ 5.66 mm. The controller was computationally\nefficient, with a loop time of 6.8 $\\pm$ 12.8 ms. An additional pilot study\n(N=6), where novices completed a Fundamentals of Laparoscopic Surgery training\ntask, suggests that users can teleoperate just as effectively from AutoCam's\nviewpoint as from the endoscope's while still benefiting from AutoCam's\nimproved visual coverage of the scene. These results indicate that an auxiliary\ncamera can be autonomously controlled using the da Vinci patient-side\nmanipulators to track a salient feature, laying the groundwork for new\nmulti-camera visualization methods in RAMIS."}
{"id": "2505.10399", "pdf": "https://arxiv.org/pdf/2505.10399", "abs": "https://arxiv.org/abs/2505.10399", "authors": ["Kaivalya Rawal", "Zihao Fu", "Eoin Delaney", "Chris Russell"], "title": "Evaluating Model Explanations without Ground Truth", "categories": ["cs.AI", "cs.LG", "I.2.6"], "comment": "https://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth", "summary": "There can be many competing and contradictory explanations for a single model\nprediction, making it difficult to select which one to use. Current explanation\nevaluation frameworks measure quality by comparing against ideal \"ground-truth\"\nexplanations, or by verifying model sensitivity to important inputs. We outline\nthe limitations of these approaches, and propose three desirable principles to\nground the future development of explanation evaluation strategies for local\nfeature importance explanations. We propose a ground-truth Agnostic eXplanation\nEvaluation framework (AXE) for evaluating and comparing model explanations that\nsatisfies these principles. Unlike prior approaches, AXE does not require\naccess to ideal ground-truth explanations for comparison, or rely on model\nsensitivity - providing an independent measure of explanation quality. We\nverify AXE by comparing with baselines, and show how it can be used to detect\nexplanation fairwashing. Our code is available at\nhttps://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth."}
{"id": "2505.10402", "pdf": "https://arxiv.org/pdf/2505.10402", "abs": "https://arxiv.org/abs/2505.10402", "authors": ["Yihong Dong", "Yuchen Liu", "Xue Jiang", "Zhi Jin", "Ge Li"], "title": "Rethinking Repetition Problems of LLMs in Code Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to ACL 2025 (main)", "summary": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code."}
{"id": "2505.10405", "pdf": "https://arxiv.org/pdf/2505.10405", "abs": "https://arxiv.org/abs/2505.10405", "authors": ["Jianhao Huang", "Qunsong Zeng", "Kaibin Huang"], "title": "Visual Fidelity Index for Generative Semantic Communications with Critical Information Embedding", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Generative semantic communication (Gen-SemCom) with large artificial\nintelligence (AI) model promises a transformative paradigm for 6G networks,\nwhich reduces communication costs by transmitting low-dimensional prompts\nrather than raw data. However, purely prompt-driven generation loses\nfine-grained visual details. Additionally, there is a lack of systematic\nmetrics to evaluate the performance of Gen-SemCom systems. To address these\nissues, we develop a hybrid Gen-SemCom system with a critical information\nembedding (CIE) framework, where both text prompts and semantically critical\nfeatures are extracted for transmissions. First, a novel approach of semantic\nfiltering is proposed to select and transmit the semantically critical features\nof images relevant to semantic label. By integrating the text prompt and\ncritical features, the receiver reconstructs high-fidelity images using a\ndiffusion-based generative model. Next, we propose the generative visual\ninformation fidelity (GVIF) metric to evaluate the visual quality of the\ngenerated image. By characterizing the statistical models of image features,\nthe GVIF metric quantifies the mutual information between the distorted\nfeatures and their original counterparts. By maximizing the GVIF metric, we\ndesign a channel-adaptive Gen-SemCom system that adaptively control the volume\nof features and compression rate according to the channel state. Experimental\nresults validate the GVIF metric's sensitivity to visual fidelity, correlating\nwith both the PSNR and critical information volume. In addition, the optimized\nsystem achieves superior performance over benchmarking schemes in terms of\nhigher PSNR and lower FID scores."}
{"id": "2505.10444", "pdf": "https://arxiv.org/pdf/2505.10444", "abs": "https://arxiv.org/abs/2505.10444", "authors": ["Miguel Aguilera", "Sosuke Ito", "Artemy Kolchinsky"], "title": "Inferring entropy production in many-body systems using nonequilibrium MaxEnt", "categories": ["cond-mat.stat-mech", "cs.LG", "nlin.AO", "q-bio.NC"], "comment": null, "summary": "We propose a method for inferring entropy production (EP) in high-dimensional\nstochastic systems, including many-body systems and non-Markovian systems with\nlong memory. Standard techniques for estimating EP become intractable in such\nsystems due to computational and statistical limitations. We infer\ntrajectory-level EP and lower bounds on average EP by exploiting a\nnonequilibrium analogue of the Maximum Entropy principle, along with convex\nduality. Our approach uses only samples of trajectory observables (such as\nspatiotemporal correlation functions). It does not require reconstruction of\nhigh-dimensional probability distributions or rate matrices, nor any special\nassumptions such as discrete states or multipartite dynamics. It may be used to\ncompute a hierarchical decomposition of EP, reflecting contributions from\ndifferent kinds of interactions, and it has an intuitive physical\ninterpretation as a thermodynamic uncertainty relation. We demonstrate its\nnumerical performance on a disordered nonequilibrium spin model with 1000 spins\nand a large neural spike-train dataset."}
{"id": "2505.10448", "pdf": "https://arxiv.org/pdf/2505.10448", "abs": "https://arxiv.org/abs/2505.10448", "authors": ["Conor Rosato", "Harvinder Lehal", "Simon Maskell", "Lee Devlin", "Malcolm Strens"], "title": "Efficient MCMC Sampling with Expensive-to-Compute and Irregular Likelihoods", "categories": ["stat.ML", "cs.LG"], "comment": "45 pages", "summary": "Bayesian inference with Markov Chain Monte Carlo (MCMC) is challenging when\nthe likelihood function is irregular and expensive to compute. We explore\nseveral sampling algorithms that make use of subset evaluations to reduce\ncomputational overhead. We adapt the subset samplers for this setting where\ngradient information is not available or is unreliable. To achieve this, we\nintroduce data-driven proxies in place of Taylor expansions and define a novel\ncomputation-cost aware adaptive controller. We undertake an extensive\nevaluation for a challenging disease modelling task and a configurable task\nwith similar irregularity in the likelihood surface. We find our improved\nversion of Hierarchical Importance with Nested Training Samples (HINTS), with\nadaptive proposals and a data-driven proxy, obtains the best sampling error in\na fixed computational budget. We conclude that subset evaluations can provide\ncheap and naturally-tempered exploration, while a data-driven proxy can\npre-screen proposals successfully in explored regions of the state space. These\ntwo elements combine through hierarchical delayed acceptance to achieve\nefficient, exact sampling."}
{"id": "2505.10466", "pdf": "https://arxiv.org/pdf/2505.10466", "abs": "https://arxiv.org/abs/2505.10466", "authors": ["Juehang Qin", "Shixiao Liang", "Christopher Tunnell"], "title": "FlowVAT: Normalizing Flow Variational Inference with Affine-Invariant Tempering", "categories": ["stat.ML", "cs.LG", "stat.CO"], "comment": "10 pages, 5 figures, and 2 tables in main text, two appendices", "summary": "Multi-modal and high-dimensional posteriors present significant challenges\nfor variational inference, causing mode-seeking behavior and collapse despite\nthe theoretical expressiveness of normalizing flows. Traditional annealing\nmethods require temperature schedules and hyperparameter tuning, falling short\nof the goal of truly black-box variational inference. We introduce FlowVAT, a\nconditional tempering approach for normalizing flow variational inference that\naddresses these limitations. Our method tempers both the base and target\ndistributions simultaneously, maintaining affine-invariance under tempering. By\nconditioning the normalizing flow on temperature, we leverage overparameterized\nneural networks' generalization capabilities to train a single flow\nrepresenting the posterior across a range of temperatures. This preserves modes\nidentified at higher temperatures when sampling from the variational posterior\nat $T = 1$, mitigating standard variational methods' mode-seeking behavior. In\nexperiments with 2, 10, and 20 dimensional multi-modal distributions, FlowVAT\noutperforms traditional and adaptive annealing methods, finding more modes and\nachieving better ELBO values, particularly in higher dimensions where existing\napproaches fail. Our method requires minimal hyperparameter tuning and does not\nrequire an annealing schedule, advancing toward fully-automatic black-box\nvariational inference for complicated posteriors."}
{"id": "2505.10498", "pdf": "https://arxiv.org/pdf/2505.10498", "abs": "https://arxiv.org/abs/2505.10498", "authors": ["Sakshi Arya"], "title": "Batched Nonparametric Bandits via k-Nearest Neighbor UCB", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH", "68T05, 62L05, 62G08, 68Q32", "F.2.2; I.2.6"], "comment": "25 pages, 6 figures", "summary": "We study sequential decision-making in batched nonparametric contextual\nbandits, where actions are selected over a finite horizon divided into a small\nnumber of batches. Motivated by constraints in domains such as medicine and\nmarketing -- where online feedback is limited -- we propose a nonparametric\nalgorithm that combines adaptive k-nearest neighbor (k-NN) regression with the\nupper confidence bound (UCB) principle. Our method, BaNk-UCB, is fully\nnonparametric, adapts to the context dimension, and is simple to implement.\nUnlike prior work relying on parametric or binning-based estimators, BaNk-UCB\nuses local geometry to estimate rewards and adaptively balances exploration and\nexploitation. We provide near-optimal regret guarantees under standard\nLipschitz smoothness and margin assumptions, using a theoretically motivated\nbatch schedule that balances regret across batches and achieves minimax-optimal\nrates. Empirical evaluations on synthetic and real-world datasets demonstrate\nthat BaNk-UCB consistently outperforms binning-based baselines."}
{"id": "2505.10511", "pdf": "https://arxiv.org/pdf/2505.10511", "abs": "https://arxiv.org/abs/2505.10511", "authors": ["Victor Zheleznov", "Stefan Bilbao", "Alec Wright", "Simon King"], "title": "Learning Nonlinear Dynamics in Physical Modelling Synthesis using Neural Ordinary Differential Equations", "categories": ["cs.SD", "cs.LG", "eess.AS", "physics.comp-ph"], "comment": "Accepted for publication in Proceedings of the 28th International\n  Conference on Digital Audio Effects (DAFx25), Ancona, Italy, September 2025", "summary": "Modal synthesis methods are a long-standing approach for modelling\ndistributed musical systems. In some cases extensions are possible in order to\nhandle geometric nonlinearities. One such case is the high-amplitude vibration\nof a string, where geometric nonlinear effects lead to perceptually important\neffects including pitch glides and a dependence of brightness on striking\namplitude. A modal decomposition leads to a coupled nonlinear system of\nordinary differential equations. Recent work in applied machine learning\napproaches (in particular neural ordinary differential equations) has been used\nto model lumped dynamic systems such as electronic circuits automatically from\ndata. In this work, we examine how modal decomposition can be combined with\nneural ordinary differential equations for modelling distributed musical\nsystems. The proposed model leverages the analytical solution for linear\nvibration of system's modes and employs a neural network to account for\nnonlinear dynamic behaviour. Physical parameters of a system remain easily\naccessible after the training without the need for a parameter encoder in the\nnetwork architecture. As an initial proof of concept, we generate synthetic\ndata for a nonlinear transverse string and show that the model can be trained\nto reproduce the nonlinear dynamics of the system. Sound examples are\npresented."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.10522", "pdf": "https://arxiv.org/pdf/2505.10522", "abs": "https://arxiv.org/abs/2505.10522", "authors": ["Xinrui Wang", "Yan Jin"], "title": "Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) has demonstrated remarkable potential in robotic\nmanipulation but faces challenges in sample inefficiency and lack of\ninterpretability, limiting its applicability in real world scenarios. Enabling\nthe agent to gain a deeper understanding and adapt more efficiently to diverse\nworking scenarios is crucial, and strategic knowledge utilization is a key\nfactor in this process. This paper proposes a Knowledge Capture, Adaptation,\nand Composition (KCAC) framework to systematically integrate knowledge transfer\ninto RL through cross-task curriculum learning. KCAC is evaluated using a two\nblock stacking task in the CausalWorld benchmark, a complex robotic\nmanipulation environment. To our knowledge, existing RL approaches fail to\nsolve this task effectively, reflecting deficiencies in knowledge capture. In\nthis work, we redesign the benchmark reward function by removing rigid\nconstraints and strict ordering, allowing the agent to maximize total rewards\nconcurrently and enabling flexible task completion. Furthermore, we define two\nself-designed sub-tasks and implement a structured cross-task curriculum to\nfacilitate efficient learning. As a result, our KCAC approach achieves a 40\npercent reduction in training time while improving task success rates by 10\npercent compared to traditional RL methods. Through extensive evaluation, we\nidentify key curriculum design parameters subtask selection, transition timing,\nand learning rate that optimize learning efficiency and provide conceptual\nguidance for curriculum based RL frameworks. This work offers valuable insights\ninto curriculum design in RL and robotic learning."}
{"id": "2505.10533", "pdf": "https://arxiv.org/pdf/2505.10533", "abs": "https://arxiv.org/abs/2505.10533", "authors": ["Aaryan Sharma", "Shivansh Gupta", "Samar Agarwal", "Vishak Prasad C.", "Ganesh Ramakrishnan"], "title": "Enhancing Multi-Image Question Answering via Submodular Subset Selection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Large multimodal models (LMMs) have achieved high performance in\nvision-language tasks involving single image but they struggle when presented\nwith a collection of multiple images (Multiple Image Question Answering\nscenario). These tasks, which involve reasoning over large number of images,\npresent issues in scalability (with increasing number of images) and retrieval\nperformance. In this work, we propose an enhancement for retriever framework\nintroduced in MIRAGE model using submodular subset selection techniques. Our\nmethod leverages query-aware submodular functions, such as GraphCut, to\npre-select a subset of semantically relevant images before main retrieval\ncomponent. We demonstrate that using anchor-based queries and augmenting the\ndata improves submodular-retriever pipeline effectiveness, particularly in\nlarge haystack sizes."}
{"id": "2505.09649", "pdf": "https://arxiv.org/pdf/2505.09649", "abs": "https://arxiv.org/abs/2505.09649", "authors": ["Abisha Thapa Magar", "Anup Shakya"], "title": "Next Word Suggestion using Graph Neural Network", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Language Modeling is a prevalent task in Natural Language Processing. The\ncurrently existing most recent and most successful language models often tend\nto build a massive model with billions of parameters, feed in a tremendous\namount of text data, and train with enormous computation resources which\nrequire millions of dollars. In this project, we aim to address an important\nsub-task in language modeling, i.e., context embedding. We propose an approach\nto exploit the Graph Convolution operation in GNNs to encode the context and\nuse it in coalition with LSTMs to predict the next word given a local context\nof preceding words. We test this on the custom Wikipedia text corpus using a\nvery limited amount of resources and show that this approach works fairly well\nto predict the next word."}
{"id": "2505.09655", "pdf": "https://arxiv.org/pdf/2505.09655", "abs": "https://arxiv.org/abs/2505.09655", "authors": ["Xiwen Chen", "Wenhui Zhu", "Peijie Qiu", "Xuanzhao Dong", "Hao Wang", "Haiyu Wu", "Huayu Li", "Aristeidis Sotiras", "Yalin Wang", "Abolfazl Razi"], "title": "DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in reinforcement learning for language model post-training,\nsuch as Group Relative Policy Optimization (GRPO), have shown promise in\nlow-resource settings. However, GRPO typically relies on solution-level and\nscalar reward signals that fail to capture the semantic diversity among sampled\ncompletions. This leads to what we identify as a diversity-quality\ninconsistency, where distinct reasoning paths may receive indistinguishable\nrewards. To address this limitation, we propose $\\textit{Diversity-aware Reward\nAdjustment}$ (DRA), a method that explicitly incorporates semantic diversity\ninto the reward computation. DRA uses Submodular Mutual Information (SMI) to\ndownweight redundant completions and amplify rewards for diverse ones. This\nencourages better exploration during learning, while maintaining stable\nexploitation of high-quality samples. Our method integrates seamlessly with\nboth GRPO and its variant DR.~GRPO, resulting in $\\textit{DRA-GRPO}$ and\n$\\textit{DGA-DR.~GRPO}$. We evaluate our method on five mathematical reasoning\nbenchmarks and find that it outperforms recent strong baselines. It achieves\nstate-of-the-art performance with an average accuracy of 58.2%, using only\n7,000 fine-tuning samples and a total training cost of approximately $55. The\ncode is available at https://github.com/xiwenc1/DRA-GRPO."}
{"id": "2505.09662", "pdf": "https://arxiv.org/pdf/2505.09662", "abs": "https://arxiv.org/abs/2505.09662", "authors": ["Philipp Schoenegger", "Francesco Salvi", "Jiacheng Liu", "Xiaoli Nan", "Ramit Debnath", "Barbara Fasolo", "Evelina Leivada", "Gabriel Recchia", "Fritz Günther", "Ali Zarifhonarvar", "Joe Kwon", "Zahoor Ul Islam", "Marco Dehnert", "Daryl Y. H. Lee", "Madeline G. Reinecke", "David G. Kamper", "Mert Kobaş", "Adam Sandford", "Jonas Kgomo", "Luke Hewitt", "Shreya Kapoor", "Kerem Oktar", "Eyup Engin Kucuk", "Bo Feng", "Cameron R. Jones", "Izzy Gainsburg", "Sebastian Olschewski", "Nora Heinzelmann", "Francisco Cruz", "Ben M. Tappin", "Tao Ma", "Peter S. Park", "Rayan Onyonka", "Arthur Hjorth", "Peter Slattery", "Qingcheng Zeng", "Lennart Finke", "Igor Grossmann", "Alessandro Salatiello", "Ezra Karger"], "title": "Large Language Models Are More Persuasive Than Incentivized Human Persuaders", "categories": ["cs.CL", "I.2.7; H.1.2; K.4.1; H.5.2"], "comment": null, "summary": "We directly compare the persuasion capabilities of a frontier large language\nmodel (LLM; Claude Sonnet 3.5) against incentivized human persuaders in an\ninteractive, real-time conversational quiz setting. In this preregistered,\nlarge-scale incentivized experiment, participants (quiz takers) completed an\nonline quiz where persuaders (either humans or LLMs) attempted to persuade quiz\ntakers toward correct or incorrect answers. We find that LLM persuaders\nachieved significantly higher compliance with their directional persuasion\nattempts than incentivized human persuaders, demonstrating superior persuasive\ncapabilities in both truthful (toward correct answers) and deceptive (toward\nincorrect answers) contexts. We also find that LLM persuaders significantly\nincreased quiz takers' accuracy, leading to higher earnings, when steering quiz\ntakers toward correct answers, and significantly decreased their accuracy,\nleading to lower earnings, when steering them toward incorrect answers.\nOverall, our findings suggest that AI's persuasion capabilities already exceed\nthose of humans that have real-money bonuses tied to performance. Our findings\nof increasingly capable AI persuaders thus underscore the urgency of emerging\nalignment and governance frameworks."}
{"id": "2505.09666", "pdf": "https://arxiv.org/pdf/2505.09666", "abs": "https://arxiv.org/abs/2505.09666", "authors": ["Yumin Choi", "Jinheon Baek", "Sung Ju Hwang"], "title": "System Prompt Optimization with Meta-Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance."}
{"id": "2505.09746", "pdf": "https://arxiv.org/pdf/2505.09746", "abs": "https://arxiv.org/abs/2505.09746", "authors": ["Xabier Morales", "Ayah Elsayed", "Debbie Zhao", "Filip Loncaric", "Ainhoa Aguado", "Mireia Masias", "Gina Quill", "Marc Ramos", "Ada Doltra", "Ana Garcia", "Marta Sitges", "David Marlevi", "Alistair Young", "Martyn Nash", "Bart Bijnens", "Oscar Camara"], "title": "A Computational Pipeline for Advanced Analysis of 4D Flow MRI in the Left Atrium", "categories": ["cs.CV"], "comment": null, "summary": "The left atrium (LA) plays a pivotal role in modulating left ventricular\nfilling, but our comprehension of its hemodynamics is significantly limited by\nthe constraints of conventional ultrasound analysis. 4D flow magnetic resonance\nimaging (4D Flow MRI) holds promise for enhancing our understanding of atrial\nhemodynamics. However, the low velocities within the LA and the limited spatial\nresolution of 4D Flow MRI make analyzing this chamber challenging. Furthermore,\nthe absence of dedicated computational frameworks, combined with diverse\nacquisition protocols and vendors, complicates gathering large cohorts for\nstudying the prognostic value of hemodynamic parameters provided by 4D Flow\nMRI. In this study, we introduce the first open-source computational framework\ntailored for the analysis of 4D Flow MRI in the LA, enabling comprehensive\nqualitative and quantitative analysis of advanced hemodynamic parameters. Our\nframework proves robust to data from different centers of varying quality,\nproducing high-accuracy automated segmentations (Dice $>$ 0.9 and Hausdorff 95\n$<$ 3 mm), even with limited training data. Additionally, we conducted the\nfirst comprehensive assessment of energy, vorticity, and pressure parameters in\nthe LA across a spectrum of disorders to investigate their potential as\nprognostic biomarkers."}
{"id": "2505.09639", "pdf": "https://arxiv.org/pdf/2505.09639", "abs": "https://arxiv.org/abs/2505.09639", "authors": ["Quentin Cohen-Solal"], "title": "Study and improvement of search algorithms in two-players perfect information games", "categories": ["cs.AI", "cs.GT"], "comment": null, "summary": "Games, in their mathematical sense, are everywhere (game industries,\neconomics, defense, education, chemistry, biology, ...).Search algorithms in\ngames are artificial intelligence methods for playing such games.\nUnfortunately, there is no study on these algorithms that evaluates the\ngenerality of their performance. We propose to address this gap in the case of\ntwo-player zero-sum games with perfect information. Furthermore, we propose a\nnew search algorithm and we show that, for a short search time, it outperforms\nall studied algorithms on all games in this large experiment and that, for a\nmedium search time, it outperforms all studied algorithms on 17 of the 22\nstudied games."}
{"id": "2505.09659", "pdf": "https://arxiv.org/pdf/2505.09659", "abs": "https://arxiv.org/abs/2505.09659", "authors": ["Long Chen", "Xiaotian Song", "Yanan Sun"], "title": "LAS: Loss-less ANN-SNN Conversion for Fully Spike-Driven Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Spiking Large Language Models (LLMs) have emerged as an energy-efficient\nalternative to conventional LLMs through their event-driven computation. To\neffectively obtain spiking LLMs, researchers develop different ANN-to-SNN\nconversion methods by leveraging pre-trained ANN parameters while inheriting\nthe energy efficiency of SNN. However, existing conversion methods struggle\nwith extreme activation outliers and incompatible nonlinear operations of\nANN-based LLMs. To address this, we propose a loss-less ANN-SNN conversion for\nfully spike-driven LLMs, termed LAS. Specifically, LAS introduces two novel\nneurons to convert the activation outlier and nonlinear operation of ANN-based\nLLMs. Moreover, LAS tailors the spike-equivalent Transformer components for\nspiking LLMs, which can ensure full spiking conversion without any loss of\nperformance. Experimental results on six language models and two\nvision-language models demonstrate that LAS achieves loss-less conversion.\nNotably, on OPT-66B, LAS even improves the accuracy of 2\\% on the WSC task. In\naddition, the parameter and ablation studies further verify the effectiveness\nof LAS. The source code is available at https://github.com/lc783/LAS"}
{"id": "2505.09701", "pdf": "https://arxiv.org/pdf/2505.09701", "abs": "https://arxiv.org/abs/2505.09701", "authors": ["Xin Liu", "Lechen Zhang", "Sheza Munir", "Yiyang Gu", "Lu Wang"], "title": "VeriFact: Enhancing Long-Form Factuality Evaluation with Refined Fact Extraction and Reference Facts", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) excel at generating long-form responses, but\nevaluating their factuality remains challenging due to complex inter-sentence\ndependencies within the generated facts. Prior solutions predominantly follow a\ndecompose-decontextualize-verify pipeline but often fail to capture essential\ncontext and miss key relational facts. In this paper, we introduce VeriFact, a\nfactuality evaluation framework designed to enhance fact extraction by\nidentifying and resolving incomplete and missing facts to support more accurate\nverification results. Moreover, we introduce FactRBench , a benchmark that\nevaluates both precision and recall in long-form model responses, whereas prior\nwork primarily focuses on precision. FactRBench provides reference fact sets\nfrom advanced LLMs and human-written answers, enabling recall assessment.\nEmpirical evaluations show that VeriFact significantly enhances fact\ncompleteness and preserves complex facts with critical relational information,\nresulting in more accurate factuality evaluation. Benchmarking various open-\nand close-weight LLMs on FactRBench indicate that larger models within same\nmodel family improve precision and recall, but high precision does not always\ncorrelate with high recall, underscoring the importance of comprehensive\nfactuality assessment."}
{"id": "2505.09827", "pdf": "https://arxiv.org/pdf/2505.09827", "abs": "https://arxiv.org/abs/2505.09827", "authors": ["Julian Tanke", "Takashi Shibuya", "Kengo Uchida", "Koichi Saito", "Yuki Mitsufuji"], "title": "Dyadic Mamba: Long-term Dyadic Human Motion Synthesis", "categories": ["cs.CV"], "comment": "CVPR 2025 HuMoGen Workshop", "summary": "Generating realistic dyadic human motion from text descriptions presents\nsignificant challenges, particularly for extended interactions that exceed\ntypical training sequence lengths. While recent transformer-based approaches\nhave shown promising results for short-term dyadic motion synthesis, they\nstruggle with longer sequences due to inherent limitations in positional\nencoding schemes. In this paper, we introduce Dyadic Mamba, a novel approach\nthat leverages State-Space Models (SSMs) to generate high-quality dyadic human\nmotion of arbitrary length. Our method employs a simple yet effective\narchitecture that facilitates information flow between individual motion\nsequences through concatenation, eliminating the need for complex\ncross-attention mechanisms. We demonstrate that Dyadic Mamba achieves\ncompetitive performance on standard short-term benchmarks while significantly\noutperforming transformer-based approaches on longer sequences. Additionally,\nwe propose a new benchmark for evaluating long-term motion synthesis quality,\nproviding a standardized framework for future research. Our results demonstrate\nthat SSM-based architectures offer a promising direction for addressing the\nchallenging task of long-term dyadic human motion synthesis from text\ndescriptions."}
{"id": "2505.09640", "pdf": "https://arxiv.org/pdf/2505.09640", "abs": "https://arxiv.org/abs/2505.09640", "authors": ["Tomás Capdevielle", "Santiago Cifuentes"], "title": "Feature Relevancy, Necessity and Usefulness: Complexity and Algorithms", "categories": ["cs.AI", "68T01", "I.2.0"], "comment": "22 pages, 7 figures", "summary": "Given a classification model and a prediction for some input, there are\nheuristic strategies for ranking features according to their importance in\nregard to the prediction. One common approach to this task is rooted in\npropositional logic and the notion of \\textit{sufficient reason}. Through this\nconcept, the categories of relevant and necessary features were proposed in\norder to identify the crucial aspects of the input. This paper improves the\nexisting techniques and algorithms for deciding which are the relevant and/or\nnecessary features, showing in particular that necessity can be detected\nefficiently in complex models such as neural networks. We also generalize the\nnotion of relevancy and study associated problems. Moreover, we present a new\nglobal notion (i.e. that intends to explain whether a feature is important for\nthe behavior of the model in general, not depending on a particular input) of\n\\textit{usefulness} and prove that it is related to relevancy and necessity.\nFurthermore, we develop efficient algorithms for detecting it in decision trees\nand other more complex models, and experiment on three datasets to analyze its\npractical utility."}
{"id": "2505.09663", "pdf": "https://arxiv.org/pdf/2505.09663", "abs": "https://arxiv.org/abs/2505.09663", "authors": ["Julian Büchel", "Iason Chalas", "Giovanni Acampa", "An Chen", "Omobayode Fagbohungbe", "Sidney Tsai", "Kaoutar El Maghraoui", "Manuel Le Gallo", "Abbas Rahimi", "Abu Sebastian"], "title": "Analog Foundation Models", "categories": ["cs.LG"], "comment": "43 pages, 8 figures, under review", "summary": "Analog in-memory computing (AIMC) is a promising compute paradigm to improve\nspeed and power efficiency of neural network inference beyond the limits of\nconventional von Neumann-based architectures. However, AIMC introduces\nfundamental challenges such as noisy computations and strict constraints on\ninput and output quantization. Because of these constraints and imprecisions,\noff-the-shelf LLMs are not able to achieve 4-bit-level performance when\ndeployed on AIMC-based hardware. While researchers previously investigated\nrecovering this accuracy gap on small, mostly vision-based models, a generic\nmethod applicable to LLMs pre-trained on trillions of tokens does not yet\nexist. In this work, we introduce a general and scalable method to robustly\nadapt LLMs for execution on noisy, low-precision analog hardware. Our approach\nenables state-of-the-art models $\\unicode{x2013}$ including\nPhi-3-mini-4k-instruct and Llama-3.2-1B-Instruct $\\unicode{x2013}$ to retain\nperformance comparable to 4-bit weight, 8-bit activation baselines, despite the\npresence of analog noise and quantization constraints. Additionally, we show\nthat as a byproduct of our training methodology, analog foundation models can\nbe quantized for inference on low-precision digital hardware. Finally, we show\nthat our models also benefit from test-time compute scaling, showing better\nscaling behavior than models trained with 4-bit weight and 8-bit static input\nquantization. Our work bridges the gap between high-capacity LLMs and efficient\nanalog hardware, offering a path toward energy-efficient foundation models.\nCode is available at https://github.com/IBM/analog-foundation-models ."}
{"id": "2505.09724", "pdf": "https://arxiv.org/pdf/2505.09724", "abs": "https://arxiv.org/abs/2505.09724", "authors": ["Gino Carmona-Díaz", "William Jiménez-Leal", "María Alejandra Grisales", "Chandra Sripada", "Santiago Amaya", "Michael Inzlicht", "Juan Pablo Bermúdez"], "title": "An AI-Powered Research Assistant in the Lab: A Practical Guide for Text Analysis Through Iterative Collaboration with LLMs", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "31 pages, 1 figure", "summary": "Analyzing texts such as open-ended responses, headlines, or social media\nposts is a time- and labor-intensive process highly susceptible to bias. LLMs\nare promising tools for text analysis, using either a predefined (top-down) or\na data-driven (bottom-up) taxonomy, without sacrificing quality. Here we\npresent a step-by-step tutorial to efficiently develop, test, and apply\ntaxonomies for analyzing unstructured data through an iterative and\ncollaborative process between researchers and LLMs. Using personal goals\nprovided by participants as an example, we demonstrate how to write prompts to\nreview datasets and generate a taxonomy of life domains, evaluate and refine\nthe taxonomy through prompt and direct modifications, test the taxonomy and\nassess intercoder agreements, and apply the taxonomy to categorize an entire\ndataset with high intercoder reliability. We discuss the possibilities and\nlimitations of using LLMs for text analysis."}
{"id": "2505.09829", "pdf": "https://arxiv.org/pdf/2505.09829", "abs": "https://arxiv.org/abs/2505.09829", "authors": ["Tushar Kataria", "Shireen Y. Elhabian"], "title": "BoundarySeg:An Embarrassingly Simple Method To Boost Medical Image Segmentation Performance for Low Data Regimes", "categories": ["cs.CV"], "comment": null, "summary": "Obtaining large-scale medical data, annotated or unannotated, is challenging\ndue to stringent privacy regulations and data protection policies. In addition,\nannotating medical images requires that domain experts manually delineate\nanatomical structures, making the process both time-consuming and costly. As a\nresult, semi-supervised methods have gained popularity for reducing annotation\ncosts. However, the performance of semi-supervised methods is heavily dependent\non the availability of unannotated data, and their effectiveness declines when\nsuch data are scarce or absent. To overcome this limitation, we propose a\nsimple, yet effective and computationally efficient approach for medical image\nsegmentation that leverages only existing annotations. We propose BoundarySeg ,\na multi-task framework that incorporates organ boundary prediction as an\nauxiliary task to full organ segmentation, leveraging consistency between the\ntwo task predictions to provide additional supervision. This strategy improves\nsegmentation accuracy, especially in low data regimes, allowing our method to\nachieve performance comparable to or exceeding state-of-the-art semi supervised\napproaches all without relying on unannotated data or increasing computational\ndemands. Code will be released upon acceptance."}
{"id": "2505.09737", "pdf": "https://arxiv.org/pdf/2505.09737", "abs": "https://arxiv.org/abs/2505.09737", "authors": ["Osher Elhadad", "Reuth Mirsky"], "title": "General Dynamic Goal Recognition", "categories": ["cs.AI", "cs.RO"], "comment": "Accepted for publication at Generalization in Planning (GenPlan) as\n  part of AAAI 2025 workshops", "summary": "Understanding an agent's intent through its behavior is essential in\nhuman-robot interaction, interactive AI systems, and multi-agent\ncollaborations. This task, known as Goal Recognition (GR), poses significant\nchallenges in dynamic environments where goals are numerous and constantly\nevolving. Traditional GR methods, designed for a predefined set of goals, often\nstruggle to adapt to these dynamic scenarios. To address this limitation, we\nintroduce the General Dynamic GR problem - a broader definition of GR - aimed\nat enabling real-time GR systems and fostering further research in this area.\nExpanding on this foundation, this paper employs a model-free goal-conditioned\nRL approach to enable fast adaptation for GR across various changing tasks."}
{"id": "2505.09702", "pdf": "https://arxiv.org/pdf/2505.09702", "abs": "https://arxiv.org/abs/2505.09702", "authors": ["Yezi Liu", "Prathyush Poduval", "Wenjun Huang", "Yang Ni", "Hanning Chen", "Mohsen Imani"], "title": "Enabling Group Fairness in Graph Unlearning via Bi-level Debiasing", "categories": ["cs.LG"], "comment": null, "summary": "Graph unlearning is a crucial approach for protecting user privacy by erasing\nthe influence of user data on trained graph models. Recent developments in\ngraph unlearning methods have primarily focused on maintaining model prediction\nperformance while removing user information. However, we have observed that\nwhen user information is deleted from the model, the prediction distribution\nacross different sensitive groups often changes. Furthermore, graph models are\nshown to be prone to amplifying biases, making the study of fairness in graph\nunlearning particularly important. This raises the question: Does graph\nunlearning actually introduce bias? Our findings indicate that the predictions\nof post-unlearning models become highly correlated with sensitive attributes,\nconfirming the introduction of bias in the graph unlearning process. To address\nthis issue, we propose a fair graph unlearning method, FGU. To guarantee\nprivacy, FGU trains shard models on partitioned subgraphs, unlearns the\nrequested data from the corresponding subgraphs, and retrains the shard models\non the modified subgraphs. To ensure fairness, FGU employs a bi-level debiasing\nprocess: it first enables shard-level fairness by incorporating a fairness\nregularizer in the shard model retraining, and then achieves global-level\nfairness by aligning all shard models to minimize global disparity. Our\nexperiments demonstrate that FGU achieves superior fairness while maintaining\nprivacy and accuracy. Additionally, FGU is robust to diverse unlearning\nrequests, ensuring fairness and utility performance across various data\ndistributions."}
{"id": "2505.09738", "pdf": "https://arxiv.org/pdf/2505.09738", "abs": "https://arxiv.org/abs/2505.09738", "authors": ["Shaurya Sharthak", "Vinayak Pahalwan", "Adithya Kamath", "Adarsh Shirawalmath"], "title": "Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Pretrained language models (LLMs) are often constrained by their fixed\ntokenization schemes, leading to inefficiencies and performance limitations,\nparticularly for multilingual or specialized applications. This tokenizer\nlock-in presents significant challenges. standard methods to overcome this\noften require prohibitive computational resources. Although tokenizer\nreplacement with heuristic initialization aims to reduce this burden, existing\nmethods often require exhaustive residual fine-tuning and still may not fully\npreserve semantic nuances or adequately address the underlying compression\ninefficiencies. Our framework introduces two innovations: first, Tokenadapt, a\nmodel-agnostic tokenizer transplantation method, and second, novel\npre-tokenization learning for multi-word Supertokens to enhance compression and\nreduce fragmentation. Tokenadapt initializes new unique token embeddings via a\nhybrid heuristic that combines two methods: a local estimate based on subword\ndecomposition using the old tokenizer, and a global estimate utilizing the\ntop-k semantically similar tokens from the original vocabulary. This\nmethodology aims to preserve semantics while significantly minimizing\nretraining requirements. Empirical investigations validate both contributions:\nthe transplantation heuristic successfully initializes unique tokens, markedly\noutperforming conventional baselines and sophisticated methods including\nTranstokenizer and ReTok, while our Supertokens achieve notable compression\ngains. Our zero-shot perplexity results demonstrate that the TokenAdapt hybrid\ninitialization consistently yields lower perplexity ratios compared to both\nReTok and TransTokenizer baselines across different base models and newly\ntrained target tokenizers. TokenAdapt typically reduced the overall perplexity\nratio significantly compared to ReTok, yielding at least a 2-fold improvement\nin these aggregate scores."}
{"id": "2505.09858", "pdf": "https://arxiv.org/pdf/2505.09858", "abs": "https://arxiv.org/abs/2505.09858", "authors": ["Danush Kumar Venkatesh", "Isabel Funke", "Micha Pfeiffer", "Fiona Kolbinger", "Hanna Maria Schmeiser", "Juergen Weitz", "Marius Distler", "Stefanie Speidel"], "title": "Mission Balance: Generating Under-represented Class Samples using Video Diffusion Models", "categories": ["cs.CV"], "comment": "Early accept at MICCAI 2025", "summary": "Computer-assisted interventions can improve intra-operative guidance,\nparticularly through deep learning methods that harness the spatiotemporal\ninformation in surgical videos. However, the severe data imbalance often found\nin surgical video datasets hinders the development of high-performing models.\nIn this work, we aim to overcome the data imbalance by synthesizing surgical\nvideos. We propose a unique two-stage, text-conditioned diffusion-based method\nto generate high-fidelity surgical videos for under-represented classes. Our\napproach conditions the generation process on text prompts and decouples\nspatial and temporal modeling by utilizing a 2D latent diffusion model to\ncapture spatial content and then integrating temporal attention layers to\nensure temporal consistency. Furthermore, we introduce a rejection sampling\nstrategy to select the most suitable synthetic samples, effectively augmenting\nexisting datasets to address class imbalance. We evaluate our method on two\ndownstream tasks-surgical action recognition and intra-operative event\nprediction-demonstrating that incorporating synthetic videos from our approach\nsubstantially enhances model performance. We open-source our implementation at\nhttps://gitlab.com/nct_tso_public/surgvgen."}
{"id": "2505.09755", "pdf": "https://arxiv.org/pdf/2505.09755", "abs": "https://arxiv.org/abs/2505.09755", "authors": ["Amy Rafferty", "Rishi Ramaesh", "Ajitha Rajan"], "title": "Explainability Through Human-Centric Design for XAI in Lung Cancer Detection", "categories": ["cs.AI"], "comment": null, "summary": "Deep learning models have shown promise in lung pathology detection from\nchest X-rays, but widespread clinical adoption remains limited due to opaque\nmodel decision-making. In prior work, we introduced ClinicXAI, a human-centric,\nexpert-guided concept bottleneck model (CBM) designed for interpretable lung\ncancer diagnosis. We now extend that approach and present XpertXAI, a\ngeneralizable expert-driven model that preserves human-interpretable clinical\nconcepts while scaling to detect multiple lung pathologies. Using a\nhigh-performing InceptionV3-based classifier and a public dataset of chest\nX-rays with radiology reports, we compare XpertXAI against leading post-hoc\nexplainability methods and an unsupervised CBM, XCBs. We assess explanations\nthrough comparison with expert radiologist annotations and medical ground\ntruth. Although XpertXAI is trained for multiple pathologies, our expert\nvalidation focuses on lung cancer. We find that existing techniques frequently\nfail to produce clinically meaningful explanations, omitting key diagnostic\nfeatures and disagreeing with radiologist judgments. XpertXAI not only\noutperforms these baselines in predictive accuracy but also delivers\nconcept-level explanations that better align with expert reasoning. While our\nfocus remains on explainability in lung cancer detection, this work illustrates\nhow human-centric model design can be effectively extended to broader\ndiagnostic contexts - offering a scalable path toward clinically meaningful\nexplainable AI in medical diagnostics."}
{"id": "2505.09704", "pdf": "https://arxiv.org/pdf/2505.09704", "abs": "https://arxiv.org/abs/2505.09704", "authors": ["Roberto Pereira", "Fernanda Famá", "Charalampos Kalalas", "Paolo Dini"], "title": "Energy-Efficient Federated Learning for AIoT using Clustering Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While substantial research has been devoted to optimizing model performance,\nconvergence rates, and communication efficiency, the energy implications of\nfederated learning (FL) within Artificial Intelligence of Things (AIoT)\nscenarios are often overlooked in the existing literature. This study examines\nthe energy consumed during the FL process, focusing on three main\nenergy-intensive processes: pre-processing, communication, and local learning,\nall contributing to the overall energy footprint. We rely on the observation\nthat device/client selection is crucial for speeding up the convergence of\nmodel training in a distributed AIoT setting and propose two\nclustering-informed methods. These clustering solutions are designed to group\nAIoT devices with similar label distributions, resulting in clusters composed\nof nearly heterogeneous devices. Hence, our methods alleviate the heterogeneity\noften encountered in real-world distributed learning applications. Throughout\nextensive numerical experimentation, we demonstrate that our clustering\nstrategies typically achieve high convergence rates while maintaining low\nenergy consumption when compared to other recent approaches available in the\nliterature."}
{"id": "2505.09794", "pdf": "https://arxiv.org/pdf/2505.09794", "abs": "https://arxiv.org/abs/2505.09794", "authors": ["J. Moreno-Casanova", "J. M. Auñón", "A. Mártinez-Pérez", "M. E. Pérez-Martínez", "M. E. Gas-López"], "title": "Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Research projects, including those focused on cancer, rely on the manual\nextraction of information from clinical reports. This process is time-consuming\nand prone to errors, limiting the efficiency of data-driven approaches in\nhealthcare. To address these challenges, Natural Language Processing (NLP)\noffers an alternative for automating the extraction of relevant data from\nelectronic health records (EHRs). In this study, we focus on lung and breast\ncancer due to their high incidence and the significant impact they have on\npublic health. Early detection and effective data management in both types of\ncancer are crucial for improving patient outcomes. To enhance the accuracy and\nefficiency of data extraction, we utilized GMV's NLP tool uQuery, which excels\nat identifying relevant entities in clinical texts and converting them into\nstandardized formats such as SNOMED and OMOP. uQuery not only detects and\nclassifies entities but also associates them with contextual information,\nincluding negated entities, temporal aspects, and patient-related details. In\nthis work, we explore the use of NLP techniques, specifically Named Entity\nRecognition (NER), to automatically identify and extract key clinical\ninformation from EHRs related to these two cancers. A dataset from Health\nResearch Institute Hospital La Fe (IIS La Fe), comprising 200 annotated breast\ncancer and 400 lung cancer reports, was used, with eight clinical entities\nmanually labeled using the Doccano platform. To perform NER, we fine-tuned the\nbsc-bio-ehr-en3 model, a RoBERTa-based biomedical linguistic model pre-trained\nin Spanish. Fine-tuning was performed using the Transformers architecture,\nenabling accurate recognition of clinical entities in these cancer types. Our\nresults demonstrate strong overall performance, particularly in identifying\nentities like MET and PAT, although challenges remain with less frequent\nentities like EVOL."}
{"id": "2505.09859", "pdf": "https://arxiv.org/pdf/2505.09859", "abs": "https://arxiv.org/abs/2505.09859", "authors": ["Andrew Jun Lee", "Taylor Webb", "Trevor Bihl", "Keith Holyoak", "Hongjing Lu"], "title": "Few-Shot Learning of Visual Compositional Concepts through Probabilistic Schema Induction", "categories": ["cs.CV"], "comment": "Lee, A. J., Webb, T., Bihl, T., Holyoak, K. J., & Lu, H. (2025).\n  Few-shot learning of visual compositional concepts through probabilistic\n  schema induction. In A. Ruggeri, D. Barner, C. Walker, & N. Bramley (Eds.),\n  Proceedings of the 47th Annual Conference of the Cognitive Science Society.\n  Cognitive Science Society", "summary": "The ability to learn new visual concepts from limited examples is a hallmark\nof human cognition. While traditional category learning models represent each\nexample as an unstructured feature vector, compositional concept learning is\nthought to depend on (1) structured representations of examples (e.g., directed\ngraphs consisting of objects and their relations) and (2) the identification of\nshared relational structure across examples through analogical mapping. Here,\nwe introduce Probabilistic Schema Induction (PSI), a prototype model that\nemploys deep learning to perform analogical mapping over structured\nrepresentations of only a handful of examples, forming a compositional concept\ncalled a schema. In doing so, PSI relies on a novel conception of similarity\nthat weighs object-level similarity and relational similarity, as well as a\nmechanism for amplifying relations relevant to classification, analogous to\nselective attention parameters in traditional models. We show that PSI produces\nhuman-like learning performance and outperforms two controls: a prototype model\nthat uses unstructured feature vectors extracted from a deep learning model,\nand a variant of PSI with weaker structured representations. Notably, we find\nthat PSI's human-like performance is driven by an adaptive strategy that\nincreases relational similarity over object-level similarity and upweights the\ncontribution of relations that distinguish classes. These findings suggest that\nstructured representations and analogical mapping are critical to modeling\nrapid human-like learning of compositional visual concepts, and demonstrate how\ndeep learning can be leveraged to create psychological models."}
{"id": "2505.09787", "pdf": "https://arxiv.org/pdf/2505.09787", "abs": "https://arxiv.org/abs/2505.09787", "authors": ["Ziruo Yi", "Ting Xiao", "Mark V. Albert"], "title": "A Multimodal Multi-Agent Framework for Radiology Report Generation", "categories": ["cs.AI"], "comment": null, "summary": "Radiology report generation (RRG) aims to automatically produce diagnostic\nreports from medical images, with the potential to enhance clinical workflows\nand reduce radiologists' workload. While recent approaches leveraging\nmultimodal large language models (MLLMs) and retrieval-augmented generation\n(RAG) have achieved strong results, they continue to face challenges such as\nfactual inconsistency, hallucination, and cross-modal misalignment. We propose\na multimodal multi-agent framework for RRG that aligns with the stepwise\nclinical reasoning workflow, where task-specific agents handle retrieval, draft\ngeneration, visual analysis, refinement, and synthesis. Experimental results\ndemonstrate that our approach outperforms a strong baseline in both automatic\nmetrics and LLM-based evaluations, producing more accurate, structured, and\ninterpretable reports. This work highlights the potential of clinically aligned\nmulti-agent frameworks to support explainable and trustworthy clinical AI\napplications."}
{"id": "2505.09710", "pdf": "https://arxiv.org/pdf/2505.09710", "abs": "https://arxiv.org/abs/2505.09710", "authors": ["Konstantinos Fotopoulos", "Petros Maragos"], "title": "Training Deep Morphological Neural Networks as Universal Approximators", "categories": ["cs.LG"], "comment": null, "summary": "We investigate deep morphological neural networks (DMNNs). We demonstrate\nthat despite their inherent non-linearity, activations between layers are\nessential for DMNNs. We then propose several new architectures for DMNNs, each\nwith a different constraint on their parameters. For the first (resp. second)\narchitecture, we work under the constraint that the majority of parameters\n(resp. learnable parameters) should be part of morphological operations. We\nempirically show that our proposed networks can be successfully trained, and\nare more prunable than linear networks. To the best of our knowledge, we are\nthe first to successfully train DMNNs under such constraints, although the\ngeneralization capabilities of our networks remain limited. Finally, we propose\na hybrid network architecture combining linear and morphological layers,\nshowing empirically that the inclusion of morphological layers significantly\naccelerates the convergence of gradient descent with large batches."}
{"id": "2505.09807", "pdf": "https://arxiv.org/pdf/2505.09807", "abs": "https://arxiv.org/abs/2505.09807", "authors": ["Timour Ichmoukhamedov", "David Martens"], "title": "Exploring the generalization of LLM truth directions on conversational formats", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Several recent works argue that LLMs have a universal truth direction where\ntrue and false statements are linearly separable in the activation space of the\nmodel. It has been demonstrated that linear probes trained on a single hidden\nstate of the model already generalize across a range of topics and might even\nbe used for lie detection in LLM conversations. In this work we explore how\nthis truth direction generalizes between various conversational formats. We\nfind good generalization between short conversations that end on a lie, but\npoor generalization to longer formats where the lie appears earlier in the\ninput prompt. We propose a solution that significantly improves this type of\ngeneralization by adding a fixed key phrase at the end of each conversation.\nOur results highlight the challenges towards reliable LLM lie detectors that\ngeneralize to new settings."}
{"id": "2505.09915", "pdf": "https://arxiv.org/pdf/2505.09915", "abs": "https://arxiv.org/abs/2505.09915", "authors": ["Zhe Xin", "Chenyang Wu", "Penghui Huang", "Yanyong Zhang", "Yinian Mao", "Guoquan Huang"], "title": "Large-Scale Gaussian Splatting SLAM", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "The recently developed Neural Radiance Fields (NeRF) and 3D Gaussian\nSplatting (3DGS) have shown encouraging and impressive results for visual SLAM.\nHowever, most representative methods require RGBD sensors and are only\navailable for indoor environments. The robustness of reconstruction in\nlarge-scale outdoor scenarios remains unexplored. This paper introduces a\nlarge-scale 3DGS-based visual SLAM with stereo cameras, termed LSG-SLAM. The\nproposed LSG-SLAM employs a multi-modality strategy to estimate prior poses\nunder large view changes. In tracking, we introduce feature-alignment warping\nconstraints to alleviate the adverse effects of appearance similarity in\nrendering losses. For the scalability of large-scale scenarios, we introduce\ncontinuous Gaussian Splatting submaps to tackle unbounded scenes with limited\nmemory. Loops are detected between GS submaps by place recognition and the\nrelative pose between looped keyframes is optimized utilizing rendering and\nfeature warping losses. After the global optimization of camera poses and\nGaussian points, a structure refinement module enhances the reconstruction\nquality. With extensive evaluations on the EuRoc and KITTI datasets, LSG-SLAM\nachieves superior performance over existing Neural, 3DGS-based, and even\ntraditional approaches. Project page: https://lsg-slam.github.io."}
{"id": "2505.09920", "pdf": "https://arxiv.org/pdf/2505.09920", "abs": "https://arxiv.org/abs/2505.09920", "authors": ["Shan Yang", "Yongli Zhu"], "title": "Offline Reinforcement Learning for Microgrid Voltage Regulation", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore,\n  Apr. 28, 2025", "summary": "This paper presents a study on using different offline reinforcement learning\nalgorithms for microgrid voltage regulation with solar power penetration. When\nenvironment interaction is unviable due to technical or safety reasons, the\nproposed approach can still obtain an applicable model through offline-style\ntraining on a previously collected dataset, lowering the negative impact of\nlacking online environment interactions. Experiment results on the IEEE 33-bus\nsystem demonstrate the feasibility and effectiveness of the proposed approach\non different offline datasets, including the one with merely low-quality\nexperience."}
{"id": "2505.09716", "pdf": "https://arxiv.org/pdf/2505.09716", "abs": "https://arxiv.org/abs/2505.09716", "authors": ["George Dimitriadis. Spyridon Samothrakis"], "title": "Out-of-distribution generalisation is hard: evidence from ARC-like tasks", "categories": ["cs.LG", "cs.AI"], "comment": "Submission to NeurIPS 2025", "summary": "Out-of-distribution (OOD) generalisation is considered a hallmark of human\nand animal intelligence. To achieve OOD through composition, a system must\ndiscover the environment-invariant properties of experienced input-output\nmappings and transfer them to novel inputs. This can be realised if an\nintelligent system can identify appropriate, task-invariant, and composable\ninput features, as well as the composition methods, thus allowing it to act\nbased not on the interpolation between learnt data points but on the\ntask-invariant composition of those features. We propose that in order to\nconfirm that an algorithm does indeed learn compositional structures from data,\nit is not enough to just test on an OOD setup, but one also needs to confirm\nthat the features identified are indeed compositional. We showcase this by\nexploring two tasks with clearly defined OOD metrics that are not OOD solvable\nby three commonly used neural networks: a Multi-Layer Perceptron (MLP), a\nConvolutional Neural Network (CNN), and a Transformer. In addition, we develop\ntwo novel network architectures imbued with biases that allow them to be\nsuccessful in OOD scenarios. We show that even with correct biases and almost\nperfect OOD performance, an algorithm can still fail to learn the correct\nfeatures for compositional generalisation."}
{"id": "2505.09825", "pdf": "https://arxiv.org/pdf/2505.09825", "abs": "https://arxiv.org/abs/2505.09825", "authors": ["Peiqi Sui", "Juan Diego Rodriguez", "Philippe Laban", "Dean Murphy", "Joseph P. Dexter", "Richard Jean So", "Samuel Baker", "Pramit Chaudhuri"], "title": "KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Each year, tens of millions of essays are written and graded in college-level\nEnglish courses. Students are asked to analyze literary and cultural texts\nthrough a process known as close reading, in which they gather textual details\nto formulate evidence-based arguments. Despite being viewed as a basis for\ncritical thinking and widely adopted as a required element of university\ncoursework, close reading has never been evaluated on large language models\n(LLMs), and multi-discipline benchmarks like MMLU do not include literature as\na subject. To fill this gap, we present KRISTEVA, the first close reading\nbenchmark for evaluating interpretive reasoning, consisting of 1331\nmultiple-choice questions adapted from classroom data. With KRISTEVA, we\npropose three progressively more difficult sets of tasks to approximate\ndifferent elements of the close reading process, which we use to test how well\nLLMs may seem to understand and reason about literary works: 1) extracting\nstylistic features, 2) retrieving relevant contextual information from\nparametric knowledge, and 3) multi-hop reasoning between style and external\ncontexts. Our baseline results find that, while state-of-the-art LLMs possess\nsome college-level close reading competency (accuracy 49.7% - 69.7%), their\nperformances still trail those of experienced human evaluators on 10 out of our\n11 tasks."}
{"id": "2505.09926", "pdf": "https://arxiv.org/pdf/2505.09926", "abs": "https://arxiv.org/abs/2505.09926", "authors": ["Bin-Bin Gao", "Yue Zhu", "Jiangtao Yan", "Yuezhi Cai", "Weixi Zhang", "Meng Wang", "Jun Liu", "Yong Liu", "Lei Wang", "Chengjie Wang"], "title": "AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": "27 pages, 15 figures, 22 tables", "summary": "Universal visual anomaly detection aims to identify anomalies from novel or\nunseen vision domains without additional fine-tuning, which is critical in open\nscenarios. Recent studies have demonstrated that pre-trained vision-language\nmodels like CLIP exhibit strong generalization with just zero or a few normal\nimages. However, existing methods struggle with designing prompt templates,\ncomplex token interactions, or requiring additional fine-tuning, resulting in\nlimited flexibility. In this work, we present a simple yet effective method\ncalled AdaptCLIP based on two key insights. First, adaptive visual and textual\nrepresentations should be learned alternately rather than jointly. Second,\ncomparative learning between query and normal image prompt should incorporate\nboth contextual and aligned residual features, rather than relying solely on\nresidual features. AdaptCLIP treats CLIP models as a foundational service,\nadding only three simple adapters, visual adapter, textual adapter, and\nprompt-query adapter, at its input or output ends. AdaptCLIP supports\nzero-/few-shot generalization across domains and possesses a training-free\nmanner on target domains once trained on a base dataset. AdaptCLIP achieves\nstate-of-the-art performance on 12 anomaly detection benchmarks from industrial\nand medical domains, significantly outperforming existing competitive methods.\nWe will make the code and model of AdaptCLIP available at\nhttps://github.com/gaobb/AdaptCLIP."}
{"id": "2505.09923", "pdf": "https://arxiv.org/pdf/2505.09923", "abs": "https://arxiv.org/abs/2505.09923", "authors": ["Minjung Shin", "Donghyun Kim", "Jeh-Kwang Ryu"], "title": "\"There Is No Such Thing as a Dumb Question,\" But There Are Good Ones", "categories": ["cs.AI"], "comment": "8 pages, 4 figures and 4 tables. This work has been accepted for\n  presentation as a poster with full paper publication at CogSci 2025. This is\n  the final submission", "summary": "Questioning has become increasingly crucial for both humans and artificial\nintelligence, yet there remains limited research comprehensively assessing\nquestion quality. In response, this study defines good questions and presents a\nsystematic evaluation framework. We propose two key evaluation dimensions:\nappropriateness (sociolinguistic competence in context) and effectiveness\n(strategic competence in goal achievement). Based on these foundational\ndimensions, a rubric-based scoring system was developed. By incorporating\ndynamic contextual variables, our evaluation framework achieves structure and\nflexibility through semi-adaptive criteria. The methodology was validated using\nthe CAUS and SQUARE datasets, demonstrating the ability of the framework to\naccess both well-formed and problematic questions while adapting to varied\ncontexts. As we establish a flexible and comprehensive framework for question\nevaluation, this study takes a significant step toward integrating questioning\nbehavior with structured analytical methods grounded in the intrinsic nature of\nquestioning."}
{"id": "2505.09733", "pdf": "https://arxiv.org/pdf/2505.09733", "abs": "https://arxiv.org/abs/2505.09733", "authors": ["Alpaslan Gokcen", "Ali Boyaci"], "title": "Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated learning (FL) presents an effective solution for collaborative\nmodel training while maintaining data privacy across decentralized client\ndatasets. However, data quality issues such as noisy labels, missing classes,\nand imbalanced distributions significantly challenge its effectiveness. This\nstudy proposes a federated learning methodology that systematically addresses\ndata quality issues, including noise, class imbalance, and missing labels. The\nproposed approach systematically enhances data integrity through adaptive noise\ncleaning, collaborative conditional GAN-based synthetic data generation, and\nrobust federated model training. Experimental evaluations conducted on\nbenchmark datasets (MNIST and Fashion-MNIST) demonstrate significant\nimprovements in federated model performance, particularly macro-F1 Score, under\nvarying noise and class imbalance conditions. Additionally, the proposed\nframework carefully balances computational feasibility and substantial\nperformance gains, ensuring practicality for resource constrained edge devices\nwhile rigorously maintaining data privacy. Our results indicate that this\nmethod effectively mitigates common data quality challenges, providing a\nrobust, scalable, and privacy compliant solution suitable for diverse\nreal-world federated learning scenarios."}
{"id": "2505.09852", "pdf": "https://arxiv.org/pdf/2505.09852", "abs": "https://arxiv.org/abs/2505.09852", "authors": ["Apollinaire Poli Nemkova", "Sarath Chandra Lingareddy", "Sagnik Ray Choudhury", "Mark V. Albert"], "title": "Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance across natural\nlanguage tasks, but their ability to forecast violent conflict remains\nunderexplored. We investigate whether LLMs possess meaningful parametric\nknowledge-encoded in their pretrained weights-to predict conflict escalation\nand fatalities without external data. This is critical for early warning\nsystems, humanitarian planning, and policy-making. We compare this parametric\nknowledge with non-parametric capabilities, where LLMs access structured and\nunstructured context from conflict datasets (e.g., ACLED, GDELT) and recent\nnews reports via Retrieval-Augmented Generation (RAG). Incorporating external\ninformation could enhance model performance by providing up-to-date context\notherwise missing from pretrained weights. Our two-part evaluation framework\nspans 2020-2024 across conflict-prone regions in the Horn of Africa and the\nMiddle East. In the parametric setting, LLMs predict conflict trends and\nfatalities relying only on pretrained knowledge. In the non-parametric setting,\nmodels receive summaries of recent conflict events, indicators, and\ngeopolitical developments. We compare predicted conflict trend labels (e.g.,\nEscalate, Stable Conflict, De-escalate, Peace) and fatalities against\nhistorical data. Our findings highlight the strengths and limitations of LLMs\nfor conflict forecasting and the benefits of augmenting them with structured\nexternal knowledge."}
{"id": "2505.09927", "pdf": "https://arxiv.org/pdf/2505.09927", "abs": "https://arxiv.org/abs/2505.09927", "authors": ["Siqi Yin", "Shaolei Liu", "Manning Wang"], "title": "DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Domain adaptation addresses the challenge of model performance degradation\ncaused by domain gaps. In the typical setup for unsupervised domain adaptation,\nlabeled data from a source domain and unlabeled data from a target domain are\nused to train a target model. However, access to labeled source domain data,\nparticularly in medical datasets, can be restricted due to privacy policies. As\na result, research has increasingly shifted to source-free domain adaptation\n(SFDA), which requires only a pretrained model from the source domain and\nunlabeled data from the target domain data for adaptation. Existing SFDA\nmethods often rely on domain-specific image style translation and\nself-supervision techniques to bridge the domain gap and train the target\ndomain model. However, the quality of domain-specific style-translated images\nand pseudo-labels produced by these methods still leaves room for improvement.\nMoreover, training the entire model during adaptation can be inefficient under\nlimited supervision. In this paper, we propose a novel SFDA framework to\naddress these challenges. Specifically, to effectively mitigate the impact of\ndomain gap in the initial training phase, we introduce preadaptation to\ngenerate a preadapted model, which serves as an initialization of target model\nand allows for the generation of high-quality enhanced pseudo-labels without\nintroducing extra parameters. Additionally, we propose a data-dependent\nfrequency prompt to more effectively translate target domain images into a\nsource-like style. To further enhance adaptation, we employ a style-related\nlayer fine-tuning strategy, specifically designed for SFDA, to train the target\nmodel using the prompted target domain images and pseudo-labels. Extensive\nexperiments on cross-modality abdominal and cardiac SFDA segmentation tasks\ndemonstrate that our proposed method outperforms existing state-of-the-art\nmethods."}
{"id": "2505.09932", "pdf": "https://arxiv.org/pdf/2505.09932", "abs": "https://arxiv.org/abs/2505.09932", "authors": ["Kevin J McNamara", "Rhea Pritham Marpu"], "title": "Demystifying AI Agents: The Final Generation of Intelligence", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.MA"], "comment": null, "summary": "The trajectory of artificial intelligence (AI) has been one of relentless\nacceleration, evolving from rudimentary rule-based systems to sophisticated,\nautonomous agents capable of complex reasoning and interaction. This whitepaper\nchronicles this remarkable journey, charting the key technological\nmilestones--advancements in prompting, training methodologies, hardware\ncapabilities, and architectural innovations--that have converged to create the\nAI agents of today. We argue that these agents, exemplified by systems like\nOpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in\nAI development, potentially constituting the \"final generation\" of intelligence\nas we currently conceive it. We explore the capabilities and underlying\ntechnologies of these agents, grounded in practical examples, while also\nexamining the profound societal implications and the unprecedented pace of\nprogress that suggests intelligence is now doubling approximately every six\nmonths. The paper concludes by underscoring the critical need for wisdom and\nforesight in navigating the opportunities and challenges presented by this\npowerful new era of intelligence."}
{"id": "2505.09742", "pdf": "https://arxiv.org/pdf/2505.09742", "abs": "https://arxiv.org/abs/2505.09742", "authors": ["Yuan-Hang Zhang", "Massimiliano Di Ventra"], "title": "A Generative Neural Annealer for Black-Box Combinatorial Optimization", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.NE"], "comment": "15 pages, 3 figures", "summary": "We propose a generative, end-to-end solver for black-box combinatorial\noptimization that emphasizes both sample efficiency and solution quality on NP\nproblems. Drawing inspiration from annealing-based algorithms, we treat the\nblack-box objective as an energy function and train a neural network to model\nthe associated Boltzmann distribution. By conditioning on temperature, the\nnetwork captures a continuum of distributions--from near-uniform at high\ntemperatures to sharply peaked around global optima at low\ntemperatures--thereby learning the structure of the energy landscape and\nfacilitating global optimization. When queries are expensive, the\ntemperature-dependent distributions naturally enable data augmentation and\nimprove sample efficiency. When queries are cheap but the problem remains hard,\nthe model learns implicit variable interactions, effectively \"opening\" the\nblack box. We validate our approach on challenging combinatorial tasks under\nboth limited and unlimited query budgets, showing competitive performance\nagainst state-of-the-art black-box optimizers."}
{"id": "2505.09902", "pdf": "https://arxiv.org/pdf/2505.09902", "abs": "https://arxiv.org/abs/2505.09902", "authors": ["Martin Capdevila", "Esteban Villa Turek", "Ellen Karina Chumbe Fernandez", "Luis Felipe Polo Galvez", "Luis Cadavid", "Andrea Marroquin", "Rebeca Vargas Quesada", "Johanna Crew", "Nicole Vallejo Galarraga", "Christopher Rodriguez", "Diego Gutierrez", "Radhi Datla"], "title": "Crossing Borders Without Crossing Boundaries: How Sociolinguistic Awareness Can Optimize User Engagement with Localized Spanish AI Models Across Hispanophone Countries", "categories": ["cs.CL"], "comment": null, "summary": "Large language models are, by definition, based on language. In an effort to\nunderscore the critical need for regional localized models, this paper examines\nprimary differences between variants of written Spanish across Latin America\nand Spain, with an in-depth sociocultural and linguistic contextualization\ntherein. We argue that these differences effectively constitute significant\ngaps in the quotidian use of Spanish among dialectal groups by creating\nsociolinguistic dissonances, to the extent that locale-sensitive AI models\nwould play a pivotal role in bridging these divides. In doing so, this approach\ninforms better and more efficient localization strategies that also serve to\nmore adequately meet inclusivity goals, while securing sustainable active daily\nuser growth in a major low-risk investment geographic area. Therefore,\nimplementing at least the proposed five sub variants of Spanish addresses two\nlines of action: to foment user trust and reliance on AI language models while\nalso demonstrating a level of cultural, historical, and sociolinguistic\nawareness that reflects positively on any internationalization strategy."}
{"id": "2505.09935", "pdf": "https://arxiv.org/pdf/2505.09935", "abs": "https://arxiv.org/abs/2505.09935", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Quoc Dai Tran"], "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users."}
{"id": "2505.09970", "pdf": "https://arxiv.org/pdf/2505.09970", "abs": "https://arxiv.org/abs/2505.09970", "authors": ["Mrinal Rawat", "Ambuje Gupta", "Rushil Goomer", "Alessandro Di Bari", "Neha Gupta", "Roberto Pieraccini"], "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "The ReAct (Reasoning + Action) capability in large language models (LLMs) has\nbecome the foundation of modern agentic systems. Recent LLMs, such as\nDeepSeek-R1 and OpenAI o1/o3, exemplify this by emphasizing reasoning through\nthe generation of ample intermediate tokens, which help build a strong premise\nbefore producing the final output tokens. In this paper, we introduce Pre-Act,\na novel approach that enhances the agent's performance by creating a multi-step\nexecution plan along with the detailed reasoning for the given user input. This\nplan incrementally incorporates previous steps and tool outputs, refining\nitself after each step execution until the final response is obtained. Our\napproach is applicable to both conversational and non-conversational agents. To\nmeasure the performance of task-oriented agents comprehensively, we propose a\ntwo-level evaluation framework: (1) turn level and (2) end-to-end. Our\nturn-level evaluation, averaged across five models, shows that our approach,\nPre-Act, outperforms ReAct by 70% in Action Recall on the Almita dataset. While\nthis approach is effective for larger models, smaller models crucial for\npractical applications, where latency and cost are key constraints, often\nstruggle with complex reasoning tasks required for agentic systems. To address\nthis limitation, we fine-tune relatively small models such as Llama 3.1 (8B &\n70B) using the proposed Pre-Act approach. Our experiments show that the\nfine-tuned 70B model outperforms GPT-4, achieving a 69.5% improvement in action\naccuracy (turn-level) and a 28% improvement in goal completion rate\n(end-to-end) on the Almita (out-of-domain) dataset."}
{"id": "2505.09756", "pdf": "https://arxiv.org/pdf/2505.09756", "abs": "https://arxiv.org/abs/2505.09756", "authors": ["Zhaoyang Shi"], "title": "Community-based Multi-Agent Reinforcement Learning with Transfer and Active Exploration", "categories": ["cs.LG", "cs.MA", "math.OC", "stat.ML"], "comment": null, "summary": "We propose a new framework for multi-agent reinforcement learning (MARL),\nwhere the agents cooperate in a time-evolving network with latent community\nstructures and mixed memberships. Unlike traditional neighbor-based or fixed\ninteraction graphs, our community-based framework captures flexible and\nabstract coordination patterns by allowing each agent to belong to multiple\noverlapping communities. Each community maintains shared policy and value\nfunctions, which are aggregated by individual agents according to personalized\nmembership weights. We also design actor-critic algorithms that exploit this\nstructure: agents inherit community-level estimates for policy updates and\nvalue learning, enabling structured information sharing without requiring\naccess to other agents' policies. Importantly, our approach supports both\ntransfer learning by adapting to new agents or tasks via membership estimation,\nand active learning by prioritizing uncertain communities during exploration.\nTheoretically, we establish convergence guarantees under linear function\napproximation for both actor and critic updates. To our knowledge, this is the\nfirst MARL framework that integrates community structure, transferability, and\nactive learning with provable guarantees."}
{"id": "2505.09924", "pdf": "https://arxiv.org/pdf/2505.09924", "abs": "https://arxiv.org/abs/2505.09924", "authors": ["Yidan Wang", "Yubing Ren", "Yanan Cao", "Binxing Fang"], "title": "From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models", "categories": ["cs.CL", "cs.CR"], "comment": null, "summary": "The rise of Large Language Models (LLMs) has heightened concerns about the\nmisuse of AI-generated text, making watermarking a promising solution.\nMainstream watermarking schemes for LLMs fall into two categories: logits-based\nand sampling-based. However, current schemes entail trade-offs among\nrobustness, text quality, and security. To mitigate this, we integrate\nlogits-based and sampling-based schemes, harnessing their respective strengths\nto achieve synergy. In this paper, we propose a versatile symbiotic\nwatermarking framework with three strategies: serial, parallel, and hybrid. The\nhybrid framework adaptively embeds watermarks using token entropy and semantic\nentropy, optimizing the balance between detectability, robustness, text\nquality, and security. Furthermore, we validate our approach through\ncomprehensive experiments on various datasets and models. Experimental results\nindicate that our method outperforms existing baselines and achieves\nstate-of-the-art (SOTA) performance. We believe this framework provides novel\ninsights into diverse watermarking paradigms. Our code is available at\n\\href{https://github.com/redwyd/SymMark}{https://github.com/redwyd/SymMark}."}
{"id": "2505.09939", "pdf": "https://arxiv.org/pdf/2505.09939", "abs": "https://arxiv.org/abs/2505.09939", "authors": ["Zhe Shan", "Lei Zhou", "Liu Mao", "Shaofan Chen", "Chuanqiu Ren", "Xia Xie"], "title": "Non-Registration Change Detection: A Novel Change Detection Task and Benchmark Dataset", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted to IGARSS 2025", "summary": "In this study, we propose a novel remote sensing change detection task,\nnon-registration change detection, to address the increasing number of\nemergencies such as natural disasters, anthropogenic accidents, and military\nstrikes. First, in light of the limited discourse on the issue of\nnon-registration change detection, we systematically propose eight scenarios\nthat could arise in the real world and potentially contribute to the occurrence\nof non-registration problems. Second, we develop distinct image transformation\nschemes tailored to various scenarios to convert the available registration\nchange detection dataset into a non-registration version. Finally, we\ndemonstrate that non-registration change detection can cause catastrophic\ndamage to the state-of-the-art methods. Our code and dataset are available at\nhttps://github.com/ShanZard/NRCD."}
{"id": "2505.10034", "pdf": "https://arxiv.org/pdf/2505.10034", "abs": "https://arxiv.org/abs/2505.10034", "authors": ["Changzeng Fu", "Zelin Fu", "Xinhe Kuang", "Jiacheng Dong", "Qi Zhang", "Kaifeng Su", "Yikai Su", "Wenbo Shi", "Junfeng Yao", "Yuliang Zhao", "Shiqi Zhao", "Jiadong Wang", "Siyang Song", "Chaoran Liu", "Yuichiro Yoshikawa", "Björn Schuller", "Hiroshi Ishiguro"], "title": "The First MPDD Challenge: Multimodal Personality-aware Depression Detection", "categories": ["cs.AI", "68T07", "I.2.0; H.5.1"], "comment": "This paper has been accepted as part of the MPDD Challenge in the\n  ACMMM 2025 Grand Challenge", "summary": "Depression is a widespread mental health issue affecting diverse age groups,\nwith notable prevalence among college students and the elderly. However,\nexisting datasets and detection methods primarily focus on young adults,\nneglecting the broader age spectrum and individual differences that influence\ndepression manifestation. Current approaches often establish a direct mapping\nbetween multimodal data and depression indicators, failing to capture the\ncomplexity and diversity of depression across individuals. This challenge\nincludes two tracks based on age-specific subsets: Track 1 uses the\nMPDD-Elderly dataset for detecting depression in older adults, and Track 2 uses\nthe MPDD-Young dataset for detecting depression in younger participants. The\nMultimodal Personality-aware Depression Detection (MPDD) Challenge aims to\naddress this gap by incorporating multimodal data alongside individual\ndifference factors. We provide a baseline model that fuses audio and video\nmodalities with individual difference information to detect depression\nmanifestations in diverse populations. This challenge aims to promote the\ndevelopment of more personalized and accurate de pression detection methods,\nadvancing mental health research and fostering inclusive detection systems.\nMore details are available on the official challenge website:\nhttps://hacilab.github.io/MPDDChallenge.github.io."}
{"id": "2505.09768", "pdf": "https://arxiv.org/pdf/2505.09768", "abs": "https://arxiv.org/abs/2505.09768", "authors": ["Xiukun Wei", "Xueru Zhang"], "title": "Self-Consuming Generative Models with Adversarially Curated Data", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in generative models have made it increasingly difficult to\ndistinguish real data from model-generated synthetic data. Using synthetic data\nfor successive training of future model generations creates \"self-consuming\nloops\", which may lead to model collapse or training instability. Furthermore,\nsynthetic data is often subject to human feedback and curated by users based on\ntheir preferences. Ferbach et al. (2024) recently showed that when data is\ncurated according to user preferences, the self-consuming retraining loop\ndrives the model to converge toward a distribution that optimizes those\npreferences. However, in practice, data curation is often noisy or\nadversarially manipulated. For example, competing platforms may recruit\nmalicious users to adversarially curate data and disrupt rival models. In this\npaper, we study how generative models evolve under self-consuming retraining\nloops with noisy and adversarially curated data. We theoretically analyze the\nimpact of such noisy data curation on generative models and identify conditions\nfor the robustness of the retraining process. Building on this analysis, we\ndesign attack algorithms for competitive adversarial scenarios, where a\nplatform with a limited budget employs malicious users to misalign a rival's\nmodel from actual user preferences. Experiments on both synthetic and\nreal-world datasets demonstrate the effectiveness of the proposed algorithms."}
{"id": "2505.09930", "pdf": "https://arxiv.org/pdf/2505.09930", "abs": "https://arxiv.org/abs/2505.09930", "authors": ["Zixiao Zhu", "Hanzhang Zhou", "Zijian Feng", "Tianjiao Li", "Chua Jia Jim Deryl", "Mak Lee Onn", "Gee Wah Ng", "Kezhi Mao"], "title": "Rethinking Prompt Optimizers: From Prompt Merits to Optimization", "categories": ["cs.CL"], "comment": "20 pages, 14 figures", "summary": "Prompt optimization (PO) offers a practical alternative to fine-tuning large\nlanguage models (LLMs), enabling performance improvements without altering\nmodel weights. Existing methods typically rely on advanced, large-scale LLMs\nlike GPT-4 to generate optimized prompts. However, due to limited downward\ncompatibility, verbose, instruction-heavy prompts from advanced LLMs can\noverwhelm lightweight inference models and degrade response quality. In this\nwork, we rethink prompt optimization through the lens of interpretable design.\nWe first identify a set of model-agnostic prompt quality merits and empirically\nvalidate their effectiveness in enhancing prompt and response quality. We then\nintroduce MePO, a merit-guided, lightweight, and locally deployable prompt\noptimizer trained on our preference dataset built from merit-aligned prompts\ngenerated by a lightweight LLM. Unlike prior work, MePO avoids online\noptimization reliance, reduces cost and privacy concerns, and, by learning\nclear, interpretable merits, generalizes effectively to both large-scale and\nlightweight inference models. Experiments demonstrate that MePO achieves better\nresults across diverse tasks and model types, offering a scalable and robust\nsolution for real-world deployment. Our model and dataset are available at:\nhttps://github.com/MidiyaZhu/MePO"}
{"id": "2505.09943", "pdf": "https://arxiv.org/pdf/2505.09943", "abs": "https://arxiv.org/abs/2505.09943", "authors": ["Jiakun Deng", "Kexuan Li", "Xingye Cui", "Jiaxuan Li", "Chang Long", "Tian Pu", "Zhenming Peng"], "title": "CSPENet: Contour-Aware and Saliency Priors Embedding Network for Infrared Small Target Detection", "categories": ["cs.CV"], "comment": null, "summary": "Infrared small target detection (ISTD) plays a critical role in a wide range\nof civilian and military applications. Existing methods suffer from\ndeficiencies in the localization of dim targets and the perception of contour\ninformation under dense clutter environments, severely limiting their detection\nperformance. To tackle these issues, we propose a contour-aware and saliency\npriors embedding network (CSPENet) for ISTD. We first design a\nsurround-convergent prior extraction module (SCPEM) that effectively captures\nthe intrinsic characteristic of target contour pixel gradients converging\ntoward their center. This module concurrently extracts two collaborative\npriors: a boosted saliency prior for accurate target localization and\nmulti-scale structural priors for comprehensively enriching contour detail\nrepresentation. Building upon this, we propose a dual-branch priors embedding\narchitecture (DBPEA) that establishes differentiated feature fusion pathways,\nembedding these two priors at optimal network positions to achieve performance\nenhancement. Finally, we develop an attention-guided feature enhancement module\n(AGFEM) to refine feature representations and improve saliency estimation\naccuracy. Experimental results on public datasets NUDT-SIRST, IRSTD-1k, and\nNUAA-SIRST demonstrate that our CSPENet outperforms other state-of-the-art\nmethods in detection performance. The code is available at\nhttps://github.com/IDIP2025/CSPENet."}
{"id": "2505.10074", "pdf": "https://arxiv.org/pdf/2505.10074", "abs": "https://arxiv.org/abs/2505.10074", "authors": ["Mohamed Abdelmagied", "Mohamed Amine Chatti", "Shoeb Joarder", "Qurat Ul Ain", "Rawaa Alatrash"], "title": "Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs", "categories": ["cs.AI", "cs.CY"], "comment": "Accepted at EMOOCs 2025", "summary": "Massive Open Online Courses (MOOCs) lack direct interaction between learners\nand instructors, making it challenging for learners to understand new knowledge\nconcepts. Recently, learners have increasingly used Large Language Models\n(LLMs) to support them in acquiring new knowledge. However, LLMs are prone to\nhallucinations which limits their reliability. Retrieval-Augmented Generation\n(RAG) addresses this issue by retrieving relevant documents before generating a\nresponse. However, the application of RAG across different MOOCs is limited by\nunstructured learning material. Furthermore, current RAG systems do not\nactively guide learners toward their learning needs. To address these\nchallenges, we propose a Graph RAG pipeline that leverages Educational\nKnowledge Graphs (EduKGs) and Personal Knowledge Graphs (PKGs) to guide\nlearners to understand knowledge concepts in the MOOC platform CourseMapper.\nSpecifically, we implement (1) a PKG-based Question Generation method to\nrecommend personalized questions for learners in context, and (2) an\nEduKG-based Question Answering method that leverages the relationships between\nknowledge concepts in the EduKG to answer learner selected questions. To\nevaluate both methods, we conducted a study with 3 expert instructors on 3\ndifferent MOOCs in the MOOC platform CourseMapper. The results of the\nevaluation show the potential of Graph RAG to empower learners to understand\nnew knowledge concepts in a personalized learning experience."}
{"id": "2505.09792", "pdf": "https://arxiv.org/pdf/2505.09792", "abs": "https://arxiv.org/abs/2505.09792", "authors": ["Michael Kamfonas"], "title": "Interim Report on Human-Guided Adaptive Hyperparameter Optimization with Multi-Fidelity Sprints", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This case study applies a phased hyperparameter optimization process to\ncompare multitask natural language model variants that utilize multiphase\nlearning rate scheduling and optimizer parameter grouping. We employ short,\nBayesian optimization sessions that leverage multi-fidelity, hyperparameter\nspace pruning, progressive halving, and a degree of human guidance. We utilize\nthe Optuna TPE sampler and Hyperband pruner, as well as the Scikit-Learn\nGaussian process minimization. Initially, we use efficient low-fidelity sprints\nto prune the hyperparameter space. Subsequent sprints progressively increase\ntheir model fidelity and employ hyperband pruning for efficiency. A second\naspect of our approach is using a meta-learner to tune threshold values to\nresolve classification probabilities during inference. We demonstrate our\nmethod on a collection of variants of the 2021 Joint Entity and Relation\nExtraction model proposed by Eberts and Ulges."}
{"id": "2505.09945", "pdf": "https://arxiv.org/pdf/2505.09945", "abs": "https://arxiv.org/abs/2505.09945", "authors": ["Deeksha Prahlad", "Chanhee Lee", "Dongha Kim", "Hokeun Kim"], "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)", "summary": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time."}
{"id": "2505.09965", "pdf": "https://arxiv.org/pdf/2505.09965", "abs": "https://arxiv.org/abs/2505.09965", "authors": ["Hao Yang", "Tao Tan", "Shuai Tan", "Weiqin Yang", "Kunyan Cai", "Calvin Chen", "Yue Sun"], "title": "MambaControl: Anatomy Graph-Enhanced Mamba ControlNet with Fourier Refinement for Diffusion-Based Disease Trajectory Prediction", "categories": ["cs.CV"], "comment": null, "summary": "Modelling disease progression in precision medicine requires capturing\ncomplex spatio-temporal dynamics while preserving anatomical integrity.\nExisting methods often struggle with longitudinal dependencies and structural\nconsistency in progressive disorders. To address these limitations, we\nintroduce MambaControl, a novel framework that integrates selective state-space\nmodelling with diffusion processes for high-fidelity prediction of medical\nimage trajectories. To better capture subtle structural changes over time while\nmaintaining anatomical consistency, MambaControl combines Mamba-based\nlong-range modelling with graph-guided anatomical control to more effectively\nrepresent anatomical correlations. Furthermore, we introduce Fourier-enhanced\nspectral graph representations to capture spatial coherence and multiscale\ndetail, enabling MambaControl to achieve state-of-the-art performance in\nAlzheimer's disease prediction. Quantitative and regional evaluations\ndemonstrate improved progression prediction quality and anatomical fidelity,\nhighlighting its potential for personalised prognosis and clinical decision\nsupport."}
{"id": "2505.10093", "pdf": "https://arxiv.org/pdf/2505.10093", "abs": "https://arxiv.org/abs/2505.10093", "authors": ["Hsuan-Lei Shao"], "title": "From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI", "categories": ["cs.AI", "cs.CL", "I.2.4; H.3.3; J.5"], "comment": "4 pages, 4 figures", "summary": "Taiwanese China Studies (CS) has developed into a rich, interdisciplinary\nresearch field shaped by the unique geopolitical position and long standing\nacademic engagement with Mainland China. This study responds to the growing\nneed to systematically revisit and reorganize decades of Taiwan based CS\nscholarship by proposing an AI assisted approach that transforms unstructured\nacademic texts into structured, interactive knowledge representations. We apply\ngenerative AI (GAI) techniques and large language models (LLMs) to extract and\nstandardize entity relation triples from 1,367 peer reviewed CS articles\npublished between 1996 and 2019. These triples are then visualized through a\nlightweight D3.js based system, forming the foundation of a domain specific\nknowledge graph and vector database for the field. This infrastructure allows\nusers to explore conceptual nodes and semantic relationships across the corpus,\nrevealing previously uncharted intellectual trajectories, thematic clusters,\nand research gaps. By decomposing textual content into graph structured\nknowledge units, our system enables a paradigm shift from linear text\nconsumption to network based knowledge navigation. In doing so, it enhances\nscholarly access to CS literature while offering a scalable, data driven\nalternative to traditional ontology construction. This work not only\ndemonstrates how generative AI can augment area studies and digital humanities\nbut also highlights its potential to support a reimagined scholarly\ninfrastructure for regional knowledge systems."}
{"id": "2505.09810", "pdf": "https://arxiv.org/pdf/2505.09810", "abs": "https://arxiv.org/abs/2505.09810", "authors": ["Daniel Waddington", "Cornel Constantinescu"], "title": "Lossless Compression for LLM Tensor Incremental Snapshots", "categories": ["cs.LG"], "comment": null, "summary": "During the training of Large Language Models (LLMs), tensor data is\nperiodically \"checkpointed\" to persistent storage to allow recovery of work\ndone in the event of failure. The volume of data that must be copied during\neach checkpoint, even when using reduced-precision representations such as\nbfloat16, often reaches hundreds of gigabytes. Furthermore, the data must be\nmoved across a network and written to a storage system before the next epoch\noccurs. With a view to ultimately building an optimized checkpointing solution,\nthis paper presents experimental analysis of checkpoint data used to derive a\ndesign that maximizes the use of lossless compression to reduce the volume of\ndata. We examine how tensor data and its compressibility evolve during model\ntraining and evaluate the efficacy of existing common off-the-shelf general\npurpose compression engines combined with known data optimization techniques\nsuch as byte-grouping and incremental delta compression.\n  Leveraging our analysis we have built an effective compression solution,\nknown as Language Model Compressor (LMC), which is based on byte-grouping and\nHuffman encoding. LMC offers more compression performance than the best\nalternative (BZ2) but with an order-of-magnitude reduction in the time needed\nto perform the compression. We show that a 16-core parallel implementation of\nLMC can attain compression and decompression throughput of 2.78 GiB/s and 3.76\nGiB/s respectively. This increase in performance ultimately reduces the CPU\nresources needed and provides more time to copy the data to the storage system\nbefore the next epoch thus allowing for higher-frequency checkpoints."}
{"id": "2505.10013", "pdf": "https://arxiv.org/pdf/2505.10013", "abs": "https://arxiv.org/abs/2505.10013", "authors": ["Lake Yin", "Fan Huang"], "title": "DIF: A Framework for Benchmarking and Verifying Implicit Bias in LLMs", "categories": ["cs.CL"], "comment": "7 pages, 1 figure", "summary": "As Large Language Models (LLMs) have risen in prominence over the past few\nyears, there has been concern over the potential biases in LLMs inherited from\nthe training data. Previous studies have examined how LLMs exhibit implicit\nbias, such as when response generation changes when different social contexts\nare introduced. We argue that this implicit bias is not only an ethical, but\nalso a technical issue, as it reveals an inability of LLMs to accommodate\nextraneous information. However, unlike other measures of LLM intelligence,\nthere are no standard methods to benchmark this specific subset of LLM bias. To\nbridge this gap, we developed a method for calculating an easily interpretable\nbenchmark, DIF (Demographic Implicit Fairness), by evaluating preexisting LLM\nlogic and math problem datasets with sociodemographic personas. We demonstrate\nthat this method can statistically validate the presence of implicit bias in\nLLM behavior and find an inverse trend between question answering accuracy and\nimplicit bias, supporting our argument."}
{"id": "2505.09967", "pdf": "https://arxiv.org/pdf/2505.09967", "abs": "https://arxiv.org/abs/2505.09967", "authors": ["Liqian Deng"], "title": "TKFNet: Learning Texture Key Factor Driven Feature for Facial Expression Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Facial expression recognition (FER) in the wild remains a challenging task\ndue to the subtle and localized nature of expression-related features, as well\nas the complex variations in facial appearance. In this paper, we introduce a\nnovel framework that explicitly focuses on Texture Key Driver Factors (TKDF),\nlocalized texture regions that exhibit strong discriminative power across\nemotional categories. By carefully observing facial image patterns, we identify\nthat certain texture cues, such as micro-changes in skin around the brows,\neyes, and mouth, serve as primary indicators of emotional dynamics. To\neffectively capture and leverage these cues, we propose a FER architecture\ncomprising a Texture-Aware Feature Extractor (TAFE) and Dual Contextual\nInformation Filtering (DCIF). TAFE employs a ResNet-based backbone enhanced\nwith multi-branch attention to extract fine-grained texture representations,\nwhile DCIF refines these features by filtering context through adaptive pooling\nand attention mechanisms. Experimental results on RAF-DB and KDEF datasets\ndemonstrate that our method achieves state-of-the-art performance, verifying\nthe effectiveness and robustness of incorporating TKDFs into FER pipelines."}
{"id": "2505.10188", "pdf": "https://arxiv.org/pdf/2505.10188", "abs": "https://arxiv.org/abs/2505.10188", "authors": ["Felix Liedeker", "Olivia Sanchez-Graillet", "Moana Seidler", "Christian Brandt", "Jörg Wellmer", "Philipp Cimiano"], "title": "A User Study Evaluating Argumentative Explanations in Diagnostic Decision Support", "categories": ["cs.AI"], "comment": "Presented at 'The First Workshop on Natural Language Argument-Based\n  Explanations', co-located with ECAI 2024", "summary": "As the field of healthcare increasingly adopts artificial intelligence, it\nbecomes important to understand which types of explanations increase\ntransparency and empower users to develop confidence and trust in the\npredictions made by machine learning (ML) systems. In shared decision-making\nscenarios where doctors cooperate with ML systems to reach an appropriate\ndecision, establishing mutual trust is crucial. In this paper, we explore\ndifferent approaches to generating explanations in eXplainable AI (XAI) and\nmake their underlying arguments explicit so that they can be evaluated by\nmedical experts. In particular, we present the findings of a user study\nconducted with physicians to investigate their perceptions of various types of\nAI-generated explanations in the context of diagnostic decision support. The\nstudy aims to identify the most effective and useful explanations that enhance\nthe diagnostic process. In the study, medical doctors filled out a survey to\nassess different types of explanations. Further, an interview was carried out\npost-survey to gain qualitative insights on the requirements of explanations\nincorporated in diagnostic decision support. Overall, the insights gained from\nthis study contribute to understanding the types of explanations that are most\neffective."}
{"id": "2505.09812", "pdf": "https://arxiv.org/pdf/2505.09812", "abs": "https://arxiv.org/abs/2505.09812", "authors": ["Anastasija Tashkova", "Stefan Eftimov", "Bojan Ristov", "Slobodan Kalajdziski"], "title": "Comparative Analysis of Stroke Prediction Models Using Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "Stroke remains one of the most critical global health challenges, ranking as\nthe second leading cause of death and the third leading cause of disability\nworldwide. This study explores the effectiveness of machine learning algorithms\nin predicting stroke risk using demographic, clinical, and lifestyle data from\nthe Stroke Prediction Dataset. By addressing key methodological challenges such\nas class imbalance and missing data, we evaluated the performance of multiple\nmodels, including Logistic Regression, Random Forest, and XGBoost. Our results\ndemonstrate that while these models achieve high accuracy, sensitivity remains\na limiting factor for real-world clinical applications. In addition, we\nidentify the most influential predictive features and propose strategies to\nimprove machine learning-based stroke prediction. These findings contribute to\nthe development of more reliable and interpretable models for the early\nassessment of stroke risk."}
{"id": "2505.10063", "pdf": "https://arxiv.org/pdf/2505.10063", "abs": "https://arxiv.org/abs/2505.10063", "authors": ["Han Peng", "Jinhao Jiang", "Zican Dong", "Wayne Xin Zhao", "Lei Fang"], "title": "CAFE: Retrieval Head-based Coarse-to-Fine Information Seeking to Enhance Multi-Document QA Capability", "categories": ["cs.CL"], "comment": null, "summary": "Advancements in Large Language Models (LLMs) have extended their input\ncontext length, yet they still struggle with retrieval and reasoning in\nlong-context inputs. Existing methods propose to utilize the prompt strategy\nand retrieval head to alleviate this limitation. However, they still face\nchallenges in balancing retrieval precision and recall, impacting their\nefficacy in answering questions. To address this, we introduce $\\textbf{CAFE}$,\na two-stage coarse-to-fine method to enhance multi-document question-answering\ncapacities. By gradually eliminating the negative impacts of background and\ndistracting documents, CAFE makes the responses more reliant on the evidence\ndocuments. Initially, a coarse-grained filtering method leverages retrieval\nheads to identify and rank relevant documents. Then, a fine-grained steering\nmethod guides attention to the most relevant content. Experiments across\nbenchmarks show CAFE outperforms baselines, achieving up to 22.1% and 13.7%\nSubEM improvement over SFT and RAG methods on the Mistral model, respectively."}
{"id": "2505.09971", "pdf": "https://arxiv.org/pdf/2505.09971", "abs": "https://arxiv.org/abs/2505.09971", "authors": ["Yuan Gao", "Shaobo Xia", "Sheng Nie", "Cheng Wang", "Xiaohuan Xi", "Bisheng Yang"], "title": "APCoTTA: Continual Test-Time Adaptation for Semantic Segmentation of Airborne LiDAR Point Clouds", "categories": ["cs.CV"], "comment": "18 pages,12 figures", "summary": "Airborne laser scanning (ALS) point cloud segmentation is a fundamental task\nfor large-scale 3D scene understanding. In real-world applications, models are\ntypically fixed after training. However, domain shifts caused by changes in the\nenvironment, sensor types, or sensor degradation often lead to a decline in\nmodel performance. Continuous Test-Time Adaptation (CTTA) offers a solution by\nadapting a source-pretrained model to evolving, unlabeled target domains.\nDespite its potential, research on ALS point clouds remains limited, facing\nchallenges such as the absence of standardized datasets and the risk of\ncatastrophic forgetting and error accumulation during prolonged adaptation. To\ntackle these challenges, we propose APCoTTA, the first CTTA method tailored for\nALS point cloud semantic segmentation. We propose a dynamic trainable layer\nselection module. This module utilizes gradient information to select\nlow-confidence layers for training, and the remaining layers are kept frozen,\nmitigating catastrophic forgetting. To further reduce error accumulation, we\npropose an entropy-based consistency loss. By losing such samples based on\nentropy, we apply consistency loss only to the reliable samples, enhancing\nmodel stability. In addition, we propose a random parameter interpolation\nmechanism, which randomly blends parameters from the selected trainable layers\nwith those of the source model. This approach helps balance target adaptation\nand source knowledge retention, further alleviating forgetting. Finally, we\nconstruct two benchmarks, ISPRSC and H3DC, to address the lack of CTTA\nbenchmarks for ALS point cloud segmentation. Experimental results demonstrate\nthat APCoTTA achieves the best performance on two benchmarks, with mIoU\nimprovements of approximately 9% and 14% over direct inference. The new\nbenchmarks and code are available at https://github.com/Gaoyuan2/APCoTTA."}
{"id": "2505.10278", "pdf": "https://arxiv.org/pdf/2505.10278", "abs": "https://arxiv.org/abs/2505.10278", "authors": ["Taian Guo", "Haiyang Shen", "Jinsheng Huang", "Zhengyang Mao", "Junyu Luo", "Zhuoru Chen", "Xuhui Liu", "Bingyu Xia", "Luchen Liu", "Yun Ma", "Ming Zhang"], "title": "MASS: Multi-Agent Simulation Scaling for Portfolio Construction", "categories": ["cs.AI"], "comment": null, "summary": "LLM-based multi-agent has gained significant attention for their potential in\nsimulation and enhancing performance. However, existing works are limited to\npure simulations or are constrained by predefined workflows, restricting their\napplicability and effectiveness. In this paper, we introduce the Multi-Agent\nScaling Simulation (MASS) for portfolio construction. MASS achieves stable and\ncontinuous excess returns by progressively increasing the number of agents for\nlarge-scale simulations to gain a superior understanding of the market and\noptimizing agent distribution end-to-end through a reverse optimization\nprocess, rather than relying on a fixed workflow. We demonstrate its\nsuperiority through performance experiments, ablation studies, backtesting\nexperiments, experiments on updated data and stock pools, scaling experiments,\nparameter sensitivity experiments, and visualization experiments, conducted in\ncomparison with 6 state-of-the-art baselines on 3 challenging A-share stock\npools. We expect the paradigm established by MASS to expand to other tasks with\nsimilar characteristics. The implementation of MASS has been open-sourced at\nhttps://github.com/gta0804/MASS."}
{"id": "2505.09820", "pdf": "https://arxiv.org/pdf/2505.09820", "abs": "https://arxiv.org/abs/2505.09820", "authors": ["Sajib Biswas", "Mao Nishino", "Samuel Jacob Chacko", "Xiuwen Liu"], "title": "Adversarial Attack on Large Language Models using Exponentiated Gradient Descent", "categories": ["cs.LG", "cs.CL", "cs.CR"], "comment": "Accepted to International Joint Conference on Neural Networks (IJCNN)\n  2025", "summary": "As Large Language Models (LLMs) are widely used, understanding them\nsystematically is key to improving their safety and realizing their full\npotential. Although many models are aligned using techniques such as\nreinforcement learning from human feedback (RLHF), they are still vulnerable to\njailbreaking attacks. Some of the existing adversarial attack methods search\nfor discrete tokens that may jailbreak a target model while others try to\noptimize the continuous space represented by the tokens of the model's\nvocabulary. While techniques based on the discrete space may prove to be\ninefficient, optimization of continuous token embeddings requires projections\nto produce discrete tokens, which might render them ineffective. To fully\nutilize the constraints and the structures of the space, we develop an\nintrinsic optimization technique using exponentiated gradient descent with the\nBregman projection method to ensure that the optimized one-hot encoding always\nstays within the probability simplex. We prove the convergence of the technique\nand implement an efficient algorithm that is effective in jailbreaking several\nwidely used LLMs. We demonstrate the efficacy of the proposed technique using\nfive open-source LLMs on four openly available datasets. The results show that\nthe technique achieves a higher success rate with great efficiency compared to\nthree other state-of-the-art jailbreaking techniques. The source code for our\nimplementation is available at:\nhttps://github.com/sbamit/Exponentiated-Gradient-Descent-LLM-Attack"}
{"id": "2505.10066", "pdf": "https://arxiv.org/pdf/2505.10066", "abs": "https://arxiv.org/abs/2505.10066", "authors": ["Michael Fire", "Yitzhak Elbazis", "Adi Wasenstein", "Lior Rokach"], "title": "Dark LLMs: The Growing Threat of Unaligned AI Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50, 68T05, 68P25", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated."}
{"id": "2505.09986", "pdf": "https://arxiv.org/pdf/2505.09986", "abs": "https://arxiv.org/abs/2505.09986", "authors": ["Yimin Zhou", "Yichong Xia", "Sicheng Pan", "Bin Chen", "Baoyi An", "Haoqian Wang", "Zhi Wang", "Yaowei Wang", "Zikun Zhou"], "title": "High Quality Underwater Image Compression with Adaptive Correction and Codebook-based Augmentation", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "With the increasing exploration and exploitation of the underwater world,\nunderwater images have become a critical medium for human interaction with\nmarine environments, driving extensive research into their efficient\ntransmission and storage. However, contemporary underwater image compression\nalgorithms fail to fully leverage the unique characteristics distinguishing\nunderwater scenes from terrestrial images, resulting in suboptimal performance.\nTo address this limitation, we introduce HQUIC, designed to exploit\nunderwater-image-specific features for enhanced compression efficiency. HQUIC\nemploys an ALTC module to adaptively predict the attenuation coefficients and\nglobal light information of the images, which effectively mitigates the issues\ncaused by the differences in lighting and tone existing in underwater images.\nSubsequently, HQUIC employs a codebook as an auxiliary branch to extract the\ncommon objects within underwater images and enhances the performance of the\nmain branch. Furthermore, HQUIC dynamically weights multi-scale frequency\ncomponents, prioritizing information critical for distortion quality while\ndiscarding redundant details. Extensive evaluations on diverse underwater\ndatasets demonstrate that HQUIC outperforms state-of-the-art compression\nmethods."}
{"id": "2505.10309", "pdf": "https://arxiv.org/pdf/2505.10309", "abs": "https://arxiv.org/abs/2505.10309", "authors": ["Tuan Dung Nguyen", "Duncan J. Watts", "Mark E. Whiting"], "title": "Empirically evaluating commonsense intelligence in large language models with large-scale human judgments", "categories": ["cs.AI", "cs.HC", "cs.SI"], "comment": null, "summary": "Commonsense intelligence in machines is often assessed by static benchmarks\nthat compare a model's output against human-prescribed correct labels. An\nimportant, albeit implicit, assumption of these labels is that they accurately\ncapture what any human would think, effectively treating human common sense as\nhomogeneous. However, recent empirical work has shown that humans vary\nenormously in what they consider commonsensical; thus what appears self-evident\nto one benchmark designer may not be so to another. Here, we propose a novel\nmethod for evaluating common sense in artificial intelligence (AI),\nspecifically in large language models (LLMs), that incorporates empirically\nobserved heterogeneity among humans by measuring the correspondence between a\nmodel's judgment and that of a human population. We first find that, when\ntreated as independent survey respondents, most LLMs remain below the human\nmedian in their individual commonsense competence. Second, when used as\nsimulators of a hypothetical population, LLMs correlate with real humans only\nmodestly in the extent to which they agree on the same set of statements. In\nboth cases, smaller, open-weight models are surprisingly more competitive than\nlarger, proprietary frontier models. Our evaluation framework, which ties\ncommonsense intelligence to its cultural basis, contributes to the growing call\nfor adapting AI models to human collectivities that possess different, often\nincompatible, social stocks of knowledge."}
{"id": "2505.09822", "pdf": "https://arxiv.org/pdf/2505.09822", "abs": "https://arxiv.org/abs/2505.09822", "authors": ["Changhao Shi", "Gal Mishne"], "title": "Learning Kronecker-Structured Graphs from Smooth Signals", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Graph learning, or network inference, is a prominent problem in graph signal\nprocessing (GSP). GSP generalizes the Fourier transform to non-Euclidean\ndomains, and graph learning is pivotal to applying GSP when these domains are\nunknown. With the recent prevalence of multi-way data, there has been growing\ninterest in product graphs that naturally factorize dependencies across\ndifferent ways. However, the types of graph products that can be learned are\nstill limited for modeling diverse dependency structures. In this paper, we\nstudy the problem of learning a Kronecker-structured product graph from smooth\nsignals. Unlike the more commonly used Cartesian product, the Kronecker product\nmodels dependencies in a more intricate, non-separable way, but posits harder\nconstraints on the graph learning problem. To tackle this non-convex problem,\nwe propose an alternating scheme to optimize each factor graph and provide\ntheoretical guarantees for its asymptotic convergence. The proposed algorithm\nis also modified to learn factor graphs of the strong product. We conduct\nexperiments on synthetic and real-world graphs and demonstrate our approach's\nefficacy and superior performance compared to existing methods."}
{"id": "2505.10081", "pdf": "https://arxiv.org/pdf/2505.10081", "abs": "https://arxiv.org/abs/2505.10081", "authors": ["Wisdom Aduah", "Francois Meyer"], "title": "Designing and Contextualising Probes for African Languages", "categories": ["cs.CL"], "comment": null, "summary": "Pretrained language models (PLMs) for African languages are continually\nimproving, but the reasons behind these advances remain unclear. This paper\npresents the first systematic investigation into probing PLMs for linguistic\nknowledge about African languages. We train layer-wise probes for six\ntypologically diverse African languages to analyse how linguistic features are\ndistributed. We also design control tasks, a way to interpret probe\nperformance, for the MasakhaPOS dataset. We find PLMs adapted for African\nlanguages to encode more linguistic information about target languages than\nmassively multilingual PLMs. Our results reaffirm previous findings that\ntoken-level syntactic information concentrates in middle-to-last layers, while\nsentence-level semantic information is distributed across all layers. Through\ncontrol tasks and probing baselines, we confirm that performance reflects the\ninternal knowledge of PLMs rather than probe memorisation. Our study applies\nestablished interpretability techniques to African-language PLMs. In doing so,\nwe highlight the internal mechanisms underlying the success of strategies like\nactive learning and multilingual adaptation."}
{"id": "2505.09990", "pdf": "https://arxiv.org/pdf/2505.09990", "abs": "https://arxiv.org/abs/2505.09990", "authors": ["Long Cheng", "Jiafei Duan", "Yi Ru Wang", "Haoquan Fang", "Boyang Li", "Yushan Huang", "Elvis Wang", "Ainaz Eftekhar", "Jason Lee", "Wentao Yuan", "Rose Hendrix", "Noah A. Smith", "Fei Xia", "Dieter Fox", "Ranjay Krishna"], "title": "PointArena: Probing Multimodal Grounding Through Language-Guided Pointing", "categories": ["cs.CV"], "comment": "10 Pages, Dataset and code:https://pointarena.github.io/", "summary": "Pointing serves as a fundamental and intuitive mechanism for grounding\nlanguage within visual contexts, with applications spanning robotics, assistive\ntechnologies, and interactive AI systems. While recent multimodal models have\nstarted to support pointing capabilities, existing benchmarks typically focus\nonly on referential object localization tasks. We introduce PointArena, a\ncomprehensive platform for evaluating multimodal pointing across diverse\nreasoning scenarios. PointArena comprises three components: (1) Point-Bench, a\ncurated dataset containing approximately 1,000 pointing tasks across five\nreasoning categories; (2) Point-Battle, an interactive, web-based arena\nfacilitating blind, pairwise model comparisons, which has already gathered over\n4,500 anonymized votes; and (3) Point-Act, a real-world robotic manipulation\nsystem allowing users to directly evaluate multimodal model pointing\ncapabilities in practical settings. We conducted extensive evaluations of both\nstate-of-the-art open-source and proprietary multimodal models. Results\nindicate that Molmo-72B consistently outperforms other models, though\nproprietary models increasingly demonstrate comparable performance.\nAdditionally, we find that supervised training specifically targeting pointing\ntasks significantly enhances model performance. Across our multi-stage\nevaluation pipeline, we also observe strong correlations, underscoring the\ncritical role of precise pointing capabilities in enabling multimodal models to\neffectively bridge abstract reasoning with concrete, real-world actions.\nProject page: https://pointarena.github.io/"}
{"id": "2505.10328", "pdf": "https://arxiv.org/pdf/2505.10328", "abs": "https://arxiv.org/abs/2505.10328", "authors": ["Alvin Combrink", "Stephie Do", "Kristofer Bengtsson", "Sabino Francesco Roselli", "Martin Fabian"], "title": "A Comparative Study of SMT and MILP for the Nurse Rostering Problem", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "6 pages, 3 figures", "summary": "The effects of personnel scheduling on the quality of care and working\nconditions for healthcare personnel have been thoroughly documented. However,\nthe ever-present demand and large variation of constraints make healthcare\nscheduling particularly challenging. This problem has been studied for decades,\nwith limited research aimed at applying Satisfiability Modulo Theories (SMT).\nSMT has gained momentum within the formal verification community in the last\ndecades, leading to the advancement of SMT solvers that have been shown to\noutperform standard mathematical programming techniques.\n  In this work, we propose generic constraint formulations that can model a\nwide range of real-world scheduling constraints. Then, the generic constraints\nare formulated as SMT and MILP problems and used to compare the respective\nstate-of-the-art solvers, Z3 and Gurobi, on academic and real-world inspired\nrostering problems. Experimental results show how each solver excels for\ncertain types of problems; the MILP solver generally performs better when the\nproblem is highly constrained or infeasible, while the SMT solver performs\nbetter otherwise. On real-world inspired problems containing a more varied set\nof shifts and personnel, the SMT solver excels. Additionally, it was noted\nduring experimentation that the SMT solver was more sensitive to the way the\ngeneric constraints were formulated, requiring careful consideration and\nexperimentation to achieve better performance. We conclude that SMT-based\nmethods present a promising avenue for future research within the domain of\npersonnel scheduling."}
{"id": "2505.09847", "pdf": "https://arxiv.org/pdf/2505.09847", "abs": "https://arxiv.org/abs/2505.09847", "authors": ["Liyang Zhao", "Olurotimi Seton", "Himadeep Reddy Reddivari", "Suvendu Jena", "Shadow Zhao", "Rachit Kumar", "Changshuai Wei"], "title": "Causal Predictive Optimization and Generation for Business AI", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "comment": null, "summary": "The sales process involves sales functions converting leads or opportunities\nto customers and selling more products to existing customers. The optimization\nof the sales process thus is key to success of any B2B business. In this work,\nwe introduce a principled approach to sales optimization and business AI,\nnamely the Causal Predictive Optimization and Generation, which includes three\nlayers: 1) prediction layer with causal ML 2) optimization layer with\nconstraint optimization and contextual bandit 3) serving layer with Generative\nAI and feedback-loop for system enhancement. We detail the implementation and\ndeployment of the system in LinkedIn, showcasing significant wins over legacy\nsystems and sharing learning and insight broadly applicable to this field."}
{"id": "2505.10089", "pdf": "https://arxiv.org/pdf/2505.10089", "abs": "https://arxiv.org/abs/2505.10089", "authors": ["Wei Liu", "Sony Trenous", "Leonardo F. R. Ribeiro", "Bill Byrne", "Felix Hieber"], "title": "XRAG: Cross-lingual Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "We propose XRAG, a novel benchmark designed to evaluate the generation\nabilities of LLMs in cross-lingual Retrieval-Augmented Generation (RAG)\nsettings where the user language does not match the retrieval results. XRAG is\nconstructed from recent news articles to ensure that its questions require\nexternal knowledge to be answered. It covers the real-world scenarios of\nmonolingual and multilingual retrieval, and provides relevancy annotations for\neach retrieved document. Our novel dataset construction pipeline results in\nquestions that require complex reasoning, as evidenced by the significant gap\nbetween human and LLM performance. Consequently, XRAG serves as a valuable\nbenchmark for studying LLM reasoning abilities, even before considering the\nadditional cross-lingual complexity. Experimental results on five LLMs uncover\ntwo previously unreported challenges in cross-lingual RAG: 1) in the\nmonolingual retrieval setting, all evaluated models struggle with response\nlanguage correctness; 2) in the multilingual retrieval setting, the main\nchallenge lies in reasoning over retrieved information across languages rather\nthan generation of non-English text."}
{"id": "2505.09997", "pdf": "https://arxiv.org/pdf/2505.09997", "abs": "https://arxiv.org/abs/2505.09997", "authors": ["Jinhyun Jang", "Jiyeong Lee", "Kwanghoon Sohn"], "title": "Descriptive Image-Text Matching with Graded Contextual Similarity", "categories": ["cs.CV"], "comment": null, "summary": "Image-text matching aims to build correspondences between visual and textual\ndata by learning their pairwise similarities. Most existing approaches have\nadopted sparse binary supervision, indicating whether a pair of images and\nsentences matches or not. However, such sparse supervision covers a limited\nsubset of image-text relationships, neglecting their inherent many-to-many\ncorrespondences; an image can be described in numerous texts at different\ndescriptive levels. Moreover, existing approaches overlook the implicit\nconnections from general to specific descriptions, which form the underlying\nrationale for the many-to-many relationships between vision and language. In\nthis work, we propose descriptive image-text matching, called DITM, to learn\nthe graded contextual similarity between image and text by exploring the\ndescriptive flexibility of language. We formulate the descriptiveness score of\neach sentence with cumulative term frequency-inverse document frequency\n(TF-IDF) to balance the pairwise similarity according to the keywords in the\nsentence. Our method leverages sentence descriptiveness to learn robust\nimage-text matching in two key ways: (1) to refine the false negative labeling,\ndynamically relaxing the connectivity between positive and negative pairs, and\n(2) to build more precise matching, aligning a set of relevant sentences in a\ngeneric-to-specific order. By moving beyond rigid binary supervision, DITM\nenhances the discovery of both optimal matches and potential positive pairs.\nExtensive experiments on MS-COCO, Flickr30K, and CxC datasets demonstrate the\neffectiveness of our method in representing complex image-text relationships\ncompared to state-of-the-art approaches. In addition, DITM enhances the\nhierarchical reasoning ability of the model, supported by the extensive\nanalysis on HierarCaps benchmark."}
{"id": "2505.10361", "pdf": "https://arxiv.org/pdf/2505.10361", "abs": "https://arxiv.org/abs/2505.10361", "authors": ["David Abel", "Michael Bowling", "André Barreto", "Will Dabney", "Shi Dong", "Steven Hansen", "Anna Harutyunyan", "Khimya Khetarpal", "Clare Lyle", "Razvan Pascanu", "Georgios Piliouras", "Doina Precup", "Jonathan Richens", "Mark Rowland", "Tom Schaul", "Satinder Singh"], "title": "Plasticity as the Mirror of Empowerment", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Agents are minimally entities that are influenced by their past observations\nand act to influence future observations. This latter capacity is captured by\nempowerment, which has served as a vital framing concept across artificial\nintelligence and cognitive science. This former capacity, however, is equally\nfoundational: In what ways, and to what extent, can an agent be influenced by\nwhat it observes? In this paper, we ground this concept in a universal\nagent-centric measure that we refer to as plasticity, and reveal a fundamental\nconnection to empowerment. Following a set of desiderata on a suitable\ndefinition, we define plasticity using a new information-theoretic quantity we\ncall the generalized directed information. We show that this new quantity\nstrictly generalizes the directed information introduced by Massey (1990) while\npreserving all of its desirable properties. Our first finding is that\nplasticity is the mirror of empowerment: The agent's plasticity is identical to\nthe empowerment of the environment, and vice versa. Our second finding\nestablishes a tension between the plasticity and empowerment of an agent,\nsuggesting that agent design needs to be mindful of both characteristics. We\nexplore the implications of these findings, and suggest that plasticity,\nempowerment, and their relationship are essential to understanding agency."}
{"id": "2505.09848", "pdf": "https://arxiv.org/pdf/2505.09848", "abs": "https://arxiv.org/abs/2505.09848", "authors": ["Aditya Raj", "Golrokh Mirzaei"], "title": "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection", "categories": ["cs.LG", "eess.IV"], "comment": "11 pages", "summary": "Imaging and genomic data offer distinct and rich features, and their\nintegration can unveil new insights into the complex landscape of diseases. In\nthis study, we present a novel approach utilizing radiogenomic data including\nstructural MRI images and gene expression data, for Alzheimer's disease\ndetection. Our framework introduces a novel heterogeneous bipartite graph\nrepresentation learning featuring two distinct node types: genes and images.\nThe network can effectively classify Alzheimer's disease (AD) into three\ndistinct stages:AD, Mild Cognitive Impairment (MCI), and Cognitive Normal (CN)\nclasses, utilizing a small dataset. Additionally, it identified which genes\nplay a significant role in each of these classification groups. We evaluate the\nperformance of our approach using metrics including classification accuracy,\nrecall, precision, and F1 score. The proposed technique holds potential for\nextending to radiogenomic-based classification to other diseases."}
{"id": "2505.10113", "pdf": "https://arxiv.org/pdf/2505.10113", "abs": "https://arxiv.org/abs/2505.10113", "authors": ["Xinlan Yan", "Di Wu", "Yibin Lei", "Christof Monz", "Iacer Calixto"], "title": "What Does Neuro Mean to Cardio? Investigating the Role of Clinical Specialty Data in Medical LLMs", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we introduce S-MedQA, an English medical question-answering\n(QA) dataset for benchmarking large language models in fine-grained clinical\nspecialties. We use S-MedQA to check the applicability of a popular hypothesis\nrelated to knowledge injection in the knowledge-intense scenario of medical QA,\nand show that: 1) training on data from a speciality does not necessarily lead\nto best performance on that specialty and 2) regardless of the specialty\nfine-tuned on, token probabilities of clinically relevant terms for all\nspecialties increase consistently. Thus, we believe improvement gains come\nmostly from domain shifting (e.g., general to medical) rather than knowledge\ninjection and suggest rethinking the role of fine-tuning data in the medical\ndomain. We release S-MedQA and all code needed to reproduce all our experiments\nto the research community."}
{"id": "2505.09998", "pdf": "https://arxiv.org/pdf/2505.09998", "abs": "https://arxiv.org/abs/2505.09998", "authors": ["Ying Zang", "Yuanqi Hu", "Xinyu Chen", "Yuxia Xu", "Suhui Wang", "Chunan Yu", "Lanyun Zhu", "Deyi Ji", "Xin Xu", "Tianrun Chen"], "title": "From Air to Wear: Personalized 3D Digital Fashion with AR/VR Immersive 3D Sketching", "categories": ["cs.CV"], "comment": "8 pages, 5 figures", "summary": "In the era of immersive consumer electronics, such as AR/VR headsets and\nsmart devices, people increasingly seek ways to express their identity through\nvirtual fashion. However, existing 3D garment design tools remain inaccessible\nto everyday users due to steep technical barriers and limited data. In this\nwork, we introduce a 3D sketch-driven 3D garment generation framework that\nempowers ordinary users - even those without design experience - to create\nhigh-quality digital clothing through simple 3D sketches in AR/VR environments.\nBy combining a conditional diffusion model, a sketch encoder trained in a\nshared latent space, and an adaptive curriculum learning strategy, our system\ninterprets imprecise, free-hand input and produces realistic, personalized\ngarments. To address the scarcity of training data, we also introduce\nKO3DClothes, a new dataset of paired 3D garments and user-created sketches.\nExtensive experiments and user studies confirm that our method significantly\noutperforms existing baselines in both fidelity and usability, demonstrating\nits promise for democratized fashion design on next-generation consumer\nplatforms."}
{"id": "2505.10399", "pdf": "https://arxiv.org/pdf/2505.10399", "abs": "https://arxiv.org/abs/2505.10399", "authors": ["Kaivalya Rawal", "Zihao Fu", "Eoin Delaney", "Chris Russell"], "title": "Evaluating Model Explanations without Ground Truth", "categories": ["cs.AI", "cs.LG", "I.2.6"], "comment": "https://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth", "summary": "There can be many competing and contradictory explanations for a single model\nprediction, making it difficult to select which one to use. Current explanation\nevaluation frameworks measure quality by comparing against ideal \"ground-truth\"\nexplanations, or by verifying model sensitivity to important inputs. We outline\nthe limitations of these approaches, and propose three desirable principles to\nground the future development of explanation evaluation strategies for local\nfeature importance explanations. We propose a ground-truth Agnostic eXplanation\nEvaluation framework (AXE) for evaluating and comparing model explanations that\nsatisfies these principles. Unlike prior approaches, AXE does not require\naccess to ideal ground-truth explanations for comparison, or rely on model\nsensitivity - providing an independent measure of explanation quality. We\nverify AXE by comparing with baselines, and show how it can be used to detect\nexplanation fairwashing. Our code is available at\nhttps://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth."}
{"id": "2505.09851", "pdf": "https://arxiv.org/pdf/2505.09851", "abs": "https://arxiv.org/abs/2505.09851", "authors": ["Shun Wang", "Shun-Li Shang", "Zi-Kui Liu", "Wenrui Hao"], "title": "ZENN: A Thermodynamics-Inspired Computational Framework for Heterogeneous Data-Driven Modeling", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "9 pages, 4 figures", "summary": "Traditional entropy-based methods - such as cross-entropy loss in\nclassification problems - have long been essential tools for quantifying\nuncertainty and disorder in data and developing artificial intelligence\nalgorithms. However, the rapid growth of data across various domains has\nintroduced new challenges, particularly the integration of heterogeneous\ndatasets with intrinsic disparities. In this paper, we extend zentropy theory\ninto the data science domain by introducing intrinsic entropy, enabling more\neffective learning from heterogeneous data sources. We propose a\nzentropy-enhanced neural network (ZENN) that simultaneously learns both energy\nand intrinsic entropy components, capturing the underlying structure of\nmulti-source data. To support this, we redesign the neural network architecture\nto better reflect the intrinsic properties and variability inherent in diverse\ndatasets. We demonstrate the effectiveness of ZENN on classification tasks and\nenergy landscape reconstructions, showing its superior generalization\ncapabilities and robustness-particularly in predicting high-order derivatives.\nAs a practical application, we employ ZENN to reconstruct the Helmholtz energy\nlandscape of Fe3Pt using data generated from DFT and capture key material\nbehaviors, including negative thermal expansion and the critical point in the\ntemperature-pressure space. Overall, our study introduces a novel approach for\ndata-driven machine learning grounded in zentropy theory, highlighting ZENN as\na versatile and robust deep learning framework for scientific problems\ninvolving complex, heterogeneous datasets."}
{"id": "2505.10143", "pdf": "https://arxiv.org/pdf/2505.10143", "abs": "https://arxiv.org/abs/2505.10143", "authors": ["Longchao Da", "Parth Mitesh Shah", "Kuan-Ru Liou", "Jiaxing Zhang", "Hua Wei"], "title": "GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs", "categories": ["cs.CL", "68T50, 68T30", "I.2.7; I.2.4; H.3.3"], "comment": "5 pages, 4 figures, accepted to IJCAI2025 demo track", "summary": "Large Language Models are now key assistants in human decision-making\nprocesses. However, a common note always seems to follow: \"LLMs can make\nmistakes. Be careful with important info.\" This points to the reality that not\nall outputs from LLMs are dependable, and users must evaluate them manually.\nThe challenge deepens as hallucinated responses, often presented with seemingly\nplausible explanations, create complications and raise trust issues among\nusers. To tackle such issue, this paper proposes GE-Chat, a knowledge Graph\nenhanced retrieval-augmented generation framework to provide Evidence-based\nresponse generation. Specifically, when the user uploads a material document, a\nknowledge graph will be created, which helps construct a retrieval-augmented\nagent, enhancing the agent's responses with additional knowledge beyond its\ntraining corpus. Then we leverage Chain-of-Thought (CoT) logic generation,\nn-hop sub-graph searching, and entailment-based sentence generation to realize\naccurate evidence retrieval. We demonstrate that our method improves the\nexisting models' performance in terms of identifying the exact evidence in a\nfree-form context, providing a reliable way to examine the resources of LLM's\nconclusion and help with the judgment of the trustworthiness."}
{"id": "2505.10016", "pdf": "https://arxiv.org/pdf/2505.10016", "abs": "https://arxiv.org/abs/2505.10016", "authors": ["Shijie Lyu"], "title": "Application of YOLOv8 in monocular downward multiple Car Target detection", "categories": ["cs.CV", "cs.AI", "I.4.8; I.2.10"], "comment": "Accepted by the 5th International Conference on Signal Processing and\n  Machine Learning (CONF-SPML 2025), to appear in Applied and Computational\n  Engineering", "summary": "Autonomous driving technology is progressively transforming traditional car\ndriving methods, marking a significant milestone in modern transportation.\nObject detection serves as a cornerstone of autonomous systems, playing a vital\nrole in enhancing driving safety, enabling autonomous functionality, improving\ntraffic efficiency, and facilitating effective emergency responses. However,\ncurrent technologies such as radar for environmental perception, cameras for\nroad perception, and vehicle sensor networks face notable challenges, including\nhigh costs, vulnerability to weather and lighting conditions, and limited\nresolution.To address these limitations, this paper presents an improved\nautonomous target detection network based on YOLOv8. By integrating structural\nreparameterization technology, a bidirectional pyramid structure network model,\nand a novel detection pipeline into the YOLOv8 framework, the proposed approach\nachieves highly efficient and precise detection of multi-scale, small, and\nremote objects. Experimental results demonstrate that the enhanced model can\neffectively detect both large and small objects with a detection accuracy of\n65%, showcasing significant advancements over traditional methods.This improved\nmodel holds substantial potential for real-world applications and is\nwell-suited for autonomous driving competitions, such as the Formula Student\nAutonomous China (FSAC), particularly excelling in scenarios involving\nsingle-target and small-object detection."}
{"id": "2505.10468", "pdf": "https://arxiv.org/pdf/2505.10468", "abs": "https://arxiv.org/abs/2505.10468", "authors": ["Ranjan Sapkota", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "title": "AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge", "categories": ["cs.AI"], "comment": "32 pages, 14 figures, 11 tables", "summary": "This study critically distinguishes between AI Agents and Agentic AI,\noffering a structured conceptual taxonomy, application mapping, and challenge\nanalysis to clarify their divergent design philosophies and capabilities. We\nbegin by outlining the search strategy and foundational definitions,\ncharacterizing AI Agents as modular systems driven by Large Language Models\n(LLMs) and Large Image Models (LIMs) for narrow, task-specific automation.\nGenerative AI is positioned as a precursor, with AI Agents advancing through\ntool integration, prompt engineering, and reasoning enhancements. In contrast,\nAgentic AI systems represent a paradigmatic shift marked by multi-agent\ncollaboration, dynamic task decomposition, persistent memory, and orchestrated\nautonomy. Through a sequential evaluation of architectural evolution,\noperational mechanisms, interaction styles, and autonomy levels, we present a\ncomparative analysis across both paradigms. Application domains such as\ncustomer support, scheduling, and data summarization are contrasted with\nAgentic AI deployments in research automation, robotic coordination, and\nmedical decision support. We further examine unique challenges in each paradigm\nincluding hallucination, brittleness, emergent behavior, and coordination\nfailure and propose targeted solutions such as ReAct loops, RAG, orchestration\nlayers, and causal modeling. This work aims to provide a definitive roadmap for\ndeveloping robust, scalable, and explainable AI agent and Agentic AI-driven\nsystems. >AI Agents, Agent-driven, Vision-Language-Models, Agentic AI Decision\nSupport System, Agentic-AI Applications"}
{"id": "2505.09854", "pdf": "https://arxiv.org/pdf/2505.09854", "abs": "https://arxiv.org/abs/2505.09854", "authors": ["Harikrishna Kuttivelil", "Katia Obraczka"], "title": "Chisme: Fully Decentralized Differentiated Deep Learning for Edge Intelligence", "categories": ["cs.LG", "cs.ET", "cs.MA", "cs.SI"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "As demand for intelligent services rises and edge devices become more\ncapable, distributed learning at the network edge has emerged as a key enabling\ntechnology. While existing paradigms like federated learning (FL) and\ndecentralized FL (DFL) enable privacy-preserving distributed learning in many\nscenarios, they face potential challenges in connectivity and synchronization\nimposed by resource-constrained and infrastructure-less environments. While\nmore robust, gossip learning (GL) algorithms have generally been designed for\nhomogeneous data distributions and may not suit all contexts. This paper\nintroduces Chisme, a novel suite of protocols designed to address the\nchallenges of implementing robust intelligence in the network edge,\ncharacterized by heterogeneous data distributions, episodic connectivity, and\nlack of infrastructure. Chisme includes both synchronous DFL (Chisme-DFL) and\nasynchronous GL (Chisme-GL) variants that enable collaborative yet\ndecentralized model training that considers underlying data heterogeneity. We\nintroduce a data similarity heuristic that allows agents to opportunistically\ninfer affinity with each other using the existing communication of model\nupdates in decentralized FL and GL. We leverage the heuristic to extend DFL's\nmodel aggregation and GL's model merge mechanisms for better personalized\ntraining while maintaining collaboration. While Chisme-DFL is a synchronous\ndecentralized approach whose resource utilization scales linearly with network\nsize, Chisme-GL is fully asynchronous and has a lower, constant resource\nrequirement independent of network size. We demonstrate that Chisme methods\noutperform their standard counterparts in model training over distributed and\nheterogeneous data in network scenarios ranging from less connected and\nreliable networks to fully connected and lossless networks."}
{"id": "2505.10182", "pdf": "https://arxiv.org/pdf/2505.10182", "abs": "https://arxiv.org/abs/2505.10182", "authors": ["Yoichi Ishibashi", "Taro Yano", "Masafumi Oyamada"], "title": "Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant improvements in\nreasoning capabilities through supervised fine-tuning and reinforcement\nlearning. However, when training reasoning models, these approaches are\nprimarily applicable to specific domains such as mathematics and programming,\nwhich imposes fundamental constraints on the breadth and scalability of\ntraining data. In contrast, continual pretraining (CPT) offers the advantage of\nnot requiring task-specific signals. Nevertheless, how to effectively\nsynthesize training data for reasoning and how such data affect a wide range of\ndomains remain largely unexplored. This study provides a detailed evaluation of\nReasoning CPT, a form of CPT that uses synthetic data to reconstruct the hidden\nthought processes underlying texts, based on the premise that texts are the\nresult of the author's thinking process. Specifically, we apply Reasoning CPT\nto Gemma2-9B using synthetic data with hidden thoughts derived from STEM and\nLaw corpora, and compare it to standard CPT on the MMLU benchmark. Our analysis\nreveals that Reasoning CPT consistently improves performance across all\nevaluated domains. Notably, reasoning skills acquired in one domain transfer\neffectively to others; the performance gap with conventional methods widens as\nproblem difficulty increases, with gains of up to 8 points on the most\nchallenging problems. Furthermore, models trained with hidden thoughts learn to\nadjust the depth of their reasoning according to problem difficulty."}
{"id": "2505.10027", "pdf": "https://arxiv.org/pdf/2505.10027", "abs": "https://arxiv.org/abs/2505.10027", "authors": ["Shijie Lyu"], "title": "ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by the 4th International Conference on Computing Innovation\n  and Applied Physics (CONF-CIAP 2025), and will be published in EAI Community\n  Research Series-CORE or Theoretical and Natural Science (TNS)", "summary": "With the rapid advancement of remote sensing technology, super-resolution\nimage reconstruction is of great research and practical significance. Existing\ndeep learning methods have made progress but still face limitations in handling\ncomplex scenes and preserving image details. This paper proposes a\nreinforcement learning-based latent diffusion model (LDM) fine-tuning method\nfor remote sensing image super-resolution. The method constructs a\nreinforcement learning environment with states, actions, and rewards,\noptimizing decision objectives through proximal policy optimization (PPO)\nduring the reverse denoising process of the LDM model. Experiments on the\nRESISC45 dataset show significant improvements over the baseline model in PSNR,\nSSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11,\nand LPIPS reducing by 0.06-0.10, particularly in structured and complex natural\nscenes. The results demonstrate the method's effectiveness in enhancing\nsuper-resolution quality and adaptability across scenes."}
{"id": "2505.10543", "pdf": "https://arxiv.org/pdf/2505.10543", "abs": "https://arxiv.org/abs/2505.10543", "authors": ["Annie Wong", "Thomas Bäck", "Aske Plaat", "Niki van Stein", "Anna V. Kononova"], "title": "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While large language models demonstrate impressive performance on static\nbenchmarks, the true potential of large language models as self-learning and\nreasoning agents in dynamic environments remains unclear. This study\nsystematically evaluates the efficacy of self-reflection, heuristic mutation,\nand planning as prompting techniques to test the adaptive capabilities of\nagents. We conduct experiments with various open-source language models in\ndynamic environments and find that larger models generally outperform smaller\nones, but that strategic prompting can close this performance gap. Second, a\ntoo-long prompt can negatively impact smaller models on basic reactive tasks,\nwhile larger models show more robust behaviour. Third, advanced prompting\ntechniques primarily benefit smaller models on complex games, but offer less\nimprovement for already high-performing large language models. Yet, we find\nthat advanced reasoning methods yield highly variable outcomes: while capable\nof significantly improving performance when reasoning and decision-making\nalign, they also introduce instability and can lead to big performance drops.\nCompared to human performance, our findings reveal little evidence of true\nemergent reasoning. Instead, large language model performance exhibits\npersistent limitations in crucial areas such as planning, reasoning, and\nspatial coordination, suggesting that current-generation large language models\nstill suffer fundamental shortcomings that may not be fully overcome through\nself-reflective prompting alone. Reasoning is a multi-faceted task, and while\nreasoning methods like Chain of thought improves multi-step reasoning on math\nword problems, our findings using dynamic benchmarks highlight important\nshortcomings in general reasoning capabilities, indicating a need to move\nbeyond static benchmarks to capture the complexity of reasoning."}
{"id": "2505.09855", "pdf": "https://arxiv.org/pdf/2505.09855", "abs": "https://arxiv.org/abs/2505.09855", "authors": ["Alexander Y. Ku", "Thomas L. Griffiths", "Stephanie C. Y. Chan"], "title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies."}
{"id": "2505.10185", "pdf": "https://arxiv.org/pdf/2505.10185", "abs": "https://arxiv.org/abs/2505.10185", "authors": ["Seongyun Lee", "Seungone Kim", "Minju Seo", "Yongrae Jo", "Dongyoung Go", "Hyeonbin Hwang", "Jinho Park", "Xiang Yue", "Sean Welleck", "Graham Neubig", "Moontae Lee", "Minjoon Seo"], "title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think", "categories": ["cs.CL", "cs.AI"], "comment": "Work in progress", "summary": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of\nmodern large language models, but our understanding of the reasoning strategies\nunderlying these capabilities remains limited. While some prior works have\nattempted to categorize CoTs using predefined strategy types, such approaches\nare constrained by human intuition and fail to capture the full diversity of\nmodel behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up\nframework for analyzing and steering model reasoning. Our method automatically\nextracts diverse reasoning criteria from model-generated CoTs, embeds them into\na semantic space, clusters them into representative categories, and derives\ncontrastive rubrics to interpret reasoning behavior. Human evaluations show\nthat this framework produces more interpretable and comprehensive analyses than\nexisting methods. Moreover, we demonstrate that this understanding enables\nperformance gains: we can predict which strategy a model is likely to use and\nguide it toward more effective alternatives. Finally, we provide practical\ninsights, such as that training data format (e.g., free-form vs.\nmultiple-choice) has a far greater impact on reasoning behavior than data\ndomain, underscoring the importance of format-aware model design."}
{"id": "2505.10030", "pdf": "https://arxiv.org/pdf/2505.10030", "abs": "https://arxiv.org/abs/2505.10030", "authors": ["Miit Daga", "Dhriti Parikh", "Swarna Priya Ramu"], "title": "DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera", "categories": ["cs.CV", "cs.LG"], "comment": "This paper is accepted for publication in IEEE Access journal and is\n  currently pending revisions before publication", "summary": "Coconut tree diseases are a serious risk to agricultural yield, particularly\nin developing countries where conventional farming practices restrict early\ndiagnosis and intervention. Current disease identification methods are manual,\nlabor-intensive, and non-scalable. In response to these limitations, we come up\nwith DeepSeqCoco, a deep learning based model for accurate and automatic\ndisease identification from coconut tree images. The model was tested under\nvarious optimizer settings, such as SGD, Adam, and hybrid configurations, to\nidentify the optimal balance between accuracy, minimization of loss, and\ncomputational cost. Results from experiments indicate that DeepSeqCoco can\nachieve as much as 99.5% accuracy (achieving up to 5% higher accuracy than\nexisting models) with the hybrid SGD-Adam showing the lowest validation loss of\n2.81%. It also shows a drop of up to 18% in training time and up to 85% in\nprediction time for input images. The results point out the promise of the\nmodel to improve precision agriculture through an AI-based, scalable, and\nefficient disease monitoring system."}
{"id": "2306.07615", "pdf": "https://arxiv.org/pdf/2306.07615", "abs": "https://arxiv.org/abs/2306.07615", "authors": ["Heqin Zhu", "Quan Quan", "Qingsong Yao", "Zaiyi Liu", "S. Kevin Zhou"], "title": "UOD: Universal One-shot Detection of Anatomical Landmarks", "categories": ["cs.CV", "cs.AI"], "comment": "Eealy accepted by MICCAI 2023. 11pages, 4 figures, 2 tables. arXiv\n  admin note: text overlap with arXiv:2203.06433", "summary": "One-shot medical landmark detection gains much attention and achieves great\nsuccess for its label-efficient training process. However, existing one-shot\nlearning methods are highly specialized in a single domain and suffer domain\npreference heavily in the situation of multi-domain unlabeled data. Moreover,\none-shot learning is not robust that it faces performance drop when annotating\na sub-optimal image. To tackle these issues, we resort to developing a\ndomain-adaptive one-shot landmark detection framework for handling multi-domain\nmedical images, named Universal One-shot Detection (UOD). UOD consists of two\nstages and two corresponding universal models which are designed as\ncombinations of domain-specific modules and domain-shared modules. In the first\nstage, a domain-adaptive convolution model is self-supervised learned to\ngenerate pseudo landmark labels. In the second stage, we design a\ndomain-adaptive transformer to eliminate domain preference and build the global\ncontext for multi-domain data. Even though only one annotated sample from each\ndomain is available for training, the domain-shared modules help UOD aggregate\nall one-shot samples to detect more robust and accurate landmarks. We\ninvestigated both qualitatively and quantitatively the proposed UOD on three\nwidely-used public X-ray datasets in different anatomical domains (i.e., head,\nhand, chest) and obtained state-of-the-art performances in each domain. The\ncode is available at\nhttps://github.com/heqin-zhu/UOD_universal_oneshot_detection."}
{"id": "2505.09861", "pdf": "https://arxiv.org/pdf/2505.09861", "abs": "https://arxiv.org/abs/2505.09861", "authors": ["John Bencina", "Erkut Aykutlug", "Yue Chen", "Zerui Zhang", "Stephanie Sorenson", "Shao Tang", "Changshuai Wei"], "title": "LiDDA: Data Driven Attribution at LinkedIn", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ME"], "comment": null, "summary": "Data Driven Attribution, which assigns conversion credits to marketing\ninteractions based on causal patterns learned from data, is the foundation of\nmodern marketing intelligence and vital to any marketing businesses and\nadvertising platform. In this paper, we introduce a unified transformer-based\nattribution approach that can handle member-level data, aggregate-level data,\nand integration of external macro factors. We detail the large scale\nimplementation of the approach at LinkedIn, showcasing significant impact. We\nalso share learning and insights that are broadly applicable to the marketing\nand ad tech fields."}
{"id": "2505.10202", "pdf": "https://arxiv.org/pdf/2505.10202", "abs": "https://arxiv.org/abs/2505.10202", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "YiMing Cheng", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "VQ-Logits: Compressing the Output Bottleneck of Large Language Models via Vector Quantized Logits", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success but face\nsignificant computational and memory challenges, particularly due to their\nextensive output vocabularies. The final linear projection layer, mapping\nhidden states to vocabulary-sized logits, often constitutes a substantial\nportion of the model's parameters and computational cost during inference.\nExisting methods like adaptive softmax or hierarchical softmax introduce\nstructural complexities. In this paper, we propose VQ-Logits, a novel approach\nthat leverages Vector Quantization (VQ) to drastically reduce the parameter\ncount and computational load of the LLM output layer. VQ-Logits replaces the\nlarge V * dmodel output embedding matrix with a small, shared codebook of K\nembedding vectors (K << V ). Each token in the vocabulary is mapped to one of\nthese K codebook vectors. The LLM predicts logits over this compact codebook,\nwhich are then efficiently \"scattered\" to the full vocabulary space using the\nlearned or preassigned mapping. We demonstrate through extensive experiments on\nstandard language modeling benchmarks (e.g., WikiText-103, C4) that VQ-Logits\ncan achieve up to 99% parameter reduction in the output layer and 6x speedup in\nlogit computation, with only a marginal 4% increase in perplexity compared to\nfull softmax baselines. We further provide detailed ablation studies on\ncodebook size, initialization, and learning strategies, showcasing the\nrobustness and effectiveness of our approach."}
{"id": "2505.10046", "pdf": "https://arxiv.org/pdf/2505.10046", "abs": "https://arxiv.org/abs/2505.10046", "authors": ["Bingda Tang", "Boyang Zheng", "Xichen Pan", "Sayak Paul", "Saining Xie"], "title": "Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Text-to-Image Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "This paper does not describe a new method; instead, it provides a thorough\nexploration of an important yet understudied design space related to recent\nadvances in text-to-image synthesis -- specifically, the deep fusion of large\nlanguage models (LLMs) and diffusion transformers (DiTs) for multi-modal\ngeneration. Previous studies mainly focused on overall system performance\nrather than detailed comparisons with alternative methods, and key design\ndetails and training recipes were often left undisclosed. These gaps create\nuncertainty about the real potential of this approach. To fill these gaps, we\nconduct an empirical study on text-to-image generation, performing controlled\ncomparisons with established baselines, analyzing important design choices, and\nproviding a clear, reproducible recipe for training at scale. We hope this work\noffers meaningful data points and practical guidelines for future research in\nmulti-modal generation."}
{"id": "2410.13778", "pdf": "https://arxiv.org/pdf/2410.13778", "abs": "https://arxiv.org/abs/2410.13778", "authors": ["Michelangelo Olmo Nogara Notarianni", "Filippo Leveni", "Diego Stucchi", "Luca Frittoli", "Giacomo Boracchi"], "title": "Change Detection in Multivariate data streams: Online Analysis with Kernel-QuantTree", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "AALTD workshop at ECML 2024 (https://ecml-aaltd.github.io/aaltd2024/)", "summary": "We present Kernel-QuantTree Exponentially Weighted Moving Average (KQT-EWMA),\na non-parametric change-detection algorithm that combines the Kernel-QuantTree\n(KQT) histogram and the EWMA statistic to monitor multivariate data streams\nonline. The resulting monitoring scheme is very flexible, since histograms can\nbe used to model any stationary distribution, and practical, since the\ndistribution of test statistics does not depend on the distribution of\ndatastream in stationary conditions (non-parametric monitoring). KQT-EWMA\nenables controlling false alarms by operating at a pre-determined Average Run\nLength ($ARL_0$), which measures the expected number of stationary samples to\nbe monitored before triggering a false alarm. The latter peculiarity is in\ncontrast with most non-parametric change-detection tests, which rarely can\ncontrol the $ARL_0$ a priori. Our experiments on synthetic and real-world\ndatasets demonstrate that KQT-EWMA can control $ARL_0$ while achieving\ndetection delays comparable to or lower than state-of-the-art methods designed\nto work in the same conditions."}
{"id": "2505.09864", "pdf": "https://arxiv.org/pdf/2505.09864", "abs": "https://arxiv.org/abs/2505.09864", "authors": ["Aditya Panangat"], "title": "BINGO: A Novel Pruning Mechanism to Reduce the Size of Neural Networks", "categories": ["cs.LG"], "comment": "6 pages, 0 figures, 2 tables", "summary": "Over the past decade, the use of machine learning has increased\nexponentially. Models are far more complex than ever before, growing to\ngargantuan sizes and housing millions of weights. Unfortunately, the fact that\nlarge models have become the state of the art means that it often costs\nmillions of dollars to train and operate them. These expenses not only hurt\ncompanies but also bar non-wealthy individuals from contributing to new\ndevelopments and force consumers to pay greater prices for AI. Current methods\nused to prune models, such as iterative magnitude pruning, have shown great\naccuracy but require an iterative training sequence that is incredibly\ncomputationally and environmentally taxing. To solve this problem, BINGO is\nintroduced. BINGO, during the training pass, studies specific subsets of a\nneural network one at a time to gauge how significant of a role each weight\nplays in contributing to a network's accuracy. By the time training is done,\nBINGO generates a significance score for each weight, allowing for\ninsignificant weights to be pruned in one shot. BINGO provides an\naccuracy-preserving pruning technique that is less computationally intensive\nthan current methods, allowing for a world where AI growth does not have to\nmean model growth, as well."}
{"id": "2505.10218", "pdf": "https://arxiv.org/pdf/2505.10218", "abs": "https://arxiv.org/abs/2505.10218", "authors": ["Zongsheng Wang", "Kaili Sun", "Bowen Wu", "Qun Yu", "Ying Li", "Baoxun Wang"], "title": "RAIDEN-R1: Improving Role-awareness of LLMs via GRPO with Verifiable Reward", "categories": ["cs.CL"], "comment": null, "summary": "Role-playing conversational agents (RPCAs) face persistent challenges in\nmaintaining role consistency. To address this, we propose RAIDEN-R1, a novel\nreinforcement learning framework that integrates Verifiable Role-Awareness\nReward (VRAR). The method introduces both singular and multi-term mining\nstrategies to generate quantifiable rewards by assessing role-specific keys.\nAdditionally, we construct a high-quality, role-aware Chain-of-Thought dataset\nthrough multi-LLM collaboration, and implement experiments to enhance reasoning\ncoherence. Experiments on the RAIDEN benchmark demonstrate RAIDEN-R1's\nsuperiority: our 14B-GRPO model achieves 88.04% and 88.65% accuracy on\nScript-Based Knowledge and Conversation Memory metrics, respectively,\noutperforming baseline models while maintaining robustness. Case analyses\nfurther reveal the model's enhanced ability to resolve conflicting contextual\ncues and sustain first-person narrative consistency. This work bridges the\nnon-quantifiability gap in RPCA training and provides insights into role-aware\nreasoning patterns, advancing the development of RPCAs."}
{"id": "2505.10049", "pdf": "https://arxiv.org/pdf/2505.10049", "abs": "https://arxiv.org/abs/2505.10049", "authors": ["Jinlong Fan", "Xuepu Zeng", "Jing Zhang", "Mingming Gong", "Yuxiang Yang", "Dacheng Tao"], "title": "Advances in Radiance Field for Dynamic Scene: From Neural Field to Gaussian Field", "categories": ["cs.CV"], "comment": null, "summary": "Dynamic scene representation and reconstruction have undergone transformative\nadvances in recent years, catalyzed by breakthroughs in neural radiance fields\nand 3D Gaussian splatting techniques. While initially developed for static\nenvironments, these methodologies have rapidly evolved to address the\ncomplexities inherent in 4D dynamic scenes through an expansive body of\nresearch. Coupled with innovations in differentiable volumetric rendering,\nthese approaches have significantly enhanced the quality of motion\nrepresentation and dynamic scene reconstruction, thereby garnering substantial\nattention from the computer vision and graphics communities. This survey\npresents a systematic analysis of over 200 papers focused on dynamic scene\nrepresentation using radiance field, spanning the spectrum from implicit neural\nrepresentations to explicit Gaussian primitives. We categorize and evaluate\nthese works through multiple critical lenses: motion representation paradigms,\nreconstruction techniques for varied scene dynamics, auxiliary information\nintegration strategies, and regularization approaches that ensure temporal\nconsistency and physical plausibility. We organize diverse methodological\napproaches under a unified representational framework, concluding with a\ncritical examination of persistent challenges and promising research\ndirections. By providing this comprehensive overview, we aim to establish a\ndefinitive reference for researchers entering this rapidly evolving field while\noffering experienced practitioners a systematic understanding of both\nconceptual principles and practical frontiers in dynamic scene reconstruction."}
{"id": "2505.03084", "pdf": "https://arxiv.org/pdf/2505.03084", "abs": "https://arxiv.org/abs/2505.03084", "authors": ["Shashank Kapoor", "Sanjay Surendranath Girija", "Lakshit Arora", "Dipen Pradhan", "Ankit Shetgaonkar", "Aman Raj"], "title": "Adversarial Attacks in Multimodal Systems: A Practitioner's Survey", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in IEEE COMPSAC 2025", "summary": "The introduction of multimodal models is a huge step forward in Artificial\nIntelligence. A single model is trained to understand multiple modalities:\ntext, image, video, and audio. Open-source multimodal models have made these\nbreakthroughs more accessible. However, considering the vast landscape of\nadversarial attacks across these modalities, these models also inherit\nvulnerabilities of all the modalities, and ultimately, the adversarial threat\namplifies. While broad research is available on possible attacks within or\nacross these modalities, a practitioner-focused view that outlines attack types\nremains absent in the multimodal world. As more Machine Learning Practitioners\nadopt, fine-tune, and deploy open-source models in real-world applications,\nit's crucial that they can view the threat landscape and take the preventive\nactions necessary. This paper addresses the gap by surveying adversarial\nattacks targeting all four modalities: text, image, video, and audio. This\nsurvey provides a view of the adversarial attack landscape and presents how\nmultimodal adversarial threats have evolved. To the best of our knowledge, this\nsurvey is the first comprehensive summarization of the threat landscape in the\nmultimodal world."}
{"id": "2505.09901", "pdf": "https://arxiv.org/pdf/2505.09901", "abs": "https://arxiv.org/abs/2505.09901", "authors": ["Ziyuan Zhang", "Darcy Wang", "Ningyuan Chen", "Rodrigo Mansur", "Vahid Sarhangian"], "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements."}
{"id": "2505.10260", "pdf": "https://arxiv.org/pdf/2505.10260", "abs": "https://arxiv.org/abs/2505.10260", "authors": ["Poli Apollinaire Nemkova", "Solomon Ubani", "Mark V. Albert"], "title": "Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the era of increasingly sophisticated natural language processing (NLP)\nsystems, large language models (LLMs) have demonstrated remarkable potential\nfor diverse applications, including tasks requiring nuanced textual\nunderstanding and contextual reasoning. This study investigates the\ncapabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3,\nMistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex\ntextual dataset comprising social media posts in Russian and Ukrainian.\nSpecifically, the focus is on the binary classification task of identifying\nreferences to human rights violations within the dataset.\n  To evaluate the effectiveness of these models, their annotations are compared\nagainst a gold standard set of human double-annotated labels across 1000\nsamples. The analysis includes assessing annotation performance under different\nprompting conditions, with prompts provided in both English and Russian.\nAdditionally, the study explores the unique patterns of errors and\ndisagreements exhibited by each model, offering insights into their strengths,\nlimitations, and cross-linguistic adaptability.\n  By juxtaposing LLM outputs with human annotations, this research contributes\nto understanding the reliability and applicability of LLMs for sensitive,\ndomain-specific tasks in multilingual contexts. It also sheds light on how\nlanguage models handle inherently subjective and context-dependent judgments, a\ncritical consideration for their deployment in real-world scenarios."}
{"id": "2505.10055", "pdf": "https://arxiv.org/pdf/2505.10055", "abs": "https://arxiv.org/abs/2505.10055", "authors": ["Ijazul Haq", "Yingjie Zhang", "Irfan Ali Khan"], "title": "PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper evaluates the performance of Large Multimodal Models (LMMs) on\nOptical Character Recognition (OCR) in the low-resource Pashto language.\nNatural Language Processing (NLP) in Pashto faces several challenges due to the\ncursive nature of its script and a scarcity of structured datasets. To address\nthis, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one\nmillion images annotated with bounding boxes at word, line, and document\nlevels, suitable for training and evaluating models based on different\narchitectures, including Convolutional Neural Networks (CNNs) and Transformers.\nPsOCR covers variations across 1,000 unique font families, colors, image sizes,\nand layouts. A benchmark subset of 10K images was selected to evaluate the\nperformance of several LMMs, including seven open-source models: DeepSeek's\nJanus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four\nclosed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results\ndemonstrate that Gemini achieves the best performance among all models, whereas\namong open-source models, Qwen-7B stands out. This work provides an insightful\nassessment of the capabilities and limitations of current LMMs for OCR tasks in\nPashto and establishes a foundation for further research not only in Pashto OCR\nbut also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is\navailable at https://github.com/zirak-ai/PashtoOCR."}
{"id": "2505.09593", "pdf": "https://arxiv.org/pdf/2505.09593", "abs": "https://arxiv.org/abs/2505.09593", "authors": ["Filippo Leveni", "Guilherme Weigert Cassales", "Bernhard Pfahringer", "Albert Bifet", "Giacomo Boracchi"], "title": "Online Isolation Forest", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at International Conference on Machine Learning (ICML 2024)", "summary": "The anomaly detection literature is abundant with offline methods, which\nrequire repeated access to data in memory, and impose impractical assumptions\nwhen applied to a streaming context. Existing online anomaly detection methods\nalso generally fail to address these constraints, resorting to periodic\nretraining to adapt to the online context. We propose Online-iForest, a novel\nmethod explicitly designed for streaming conditions that seamlessly tracks the\ndata generating process as it evolves over time. Experimental validation on\nreal-world datasets demonstrated that Online-iForest is on par with online\nalternatives and closely rivals state-of-the-art offline anomaly detection\ntechniques that undergo periodic retraining. Notably, Online-iForest\nconsistently outperforms all competitors in terms of efficiency, making it a\npromising solution in applications where fast identification of anomalies is of\nprimary importance such as cybersecurity, fraud and fault detection."}
{"id": "2505.09907", "pdf": "https://arxiv.org/pdf/2505.09907", "abs": "https://arxiv.org/abs/2505.09907", "authors": ["Linwei Zhang", "LuFeng", "Ruijia Liang"], "title": "Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "With the growing demand for healthy foods, agricultural product price\nforecasting has become increasingly important. Hass avocados, as a high-value\ncrop, exhibit complex price fluctuations influenced by factors such as\nseasonality, region, and weather. Traditional prediction models often struggle\nwith highly nonlinear and dynamic data. To address this, we propose a hybrid\ndeep learning model, TCN-MLP-Attention Architecture, combining Temporal\nConvolutional Networks (TCN) for sequential feature extraction, Multi-Layer\nPerceptrons (MLP) for nonlinear interactions, and an Attention mechanism for\ndynamic feature weighting. The dataset used covers over 50,000 records of Hass\navocado sales across the U.S. from 2015 to 2018, including variables such as\nsales volume, average price, time, region, weather, and variety type, collected\nfrom point-of-sale systems and the Hass Avocado Board. After systematic\npreprocessing, including missing value imputation and feature normalization,\nthe proposed model was trained and evaluated. Experimental results demonstrate\nthat the TCN-MLP-Attention model achieves excellent predictive performance,\nwith an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods.\nThis research provides a scalable and effective approach for time series\nforecasting in agricultural markets and offers valuable insights for\nintelligent supply chain management and price strategy optimization."}
{"id": "2505.10261", "pdf": "https://arxiv.org/pdf/2505.10261", "abs": "https://arxiv.org/abs/2505.10261", "authors": ["Rui Yang", "Huitao Li", "Matthew Yu Heng Wong", "Yuhe Ke", "Xin Li", "Kunyu Yu", "Jingchi Liao", "Jonathan Chong Kai Liew", "Sabarinath Vinod Nair", "Jasmine Chiat Ling Ong", "Irene Li", "Douglas Teodoro", "Chuan Hong", "Daniel Shu Wei Ting", "Nan Liu"], "title": "The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Natural language processing (NLP) has been traditionally applied to medicine,\nand generative large language models (LLMs) have become prominent recently.\nHowever, the differences between them across different medical tasks remain\nunderexplored. We analyzed 19,123 studies, finding that generative LLMs\ndemonstrate advantages in open-ended tasks, while traditional NLP dominates in\ninformation extraction and analysis tasks. As these technologies advance,\nethical use of them is essential to ensure their potential in medical\napplications."}
{"id": "2505.10072", "pdf": "https://arxiv.org/pdf/2505.10072", "abs": "https://arxiv.org/abs/2505.10072", "authors": ["Rui-Yang Ju", "Sheng-Yen Huang", "Yi-Ping Hung"], "title": "ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars", "categories": ["cs.CV"], "comment": null, "summary": "The introduction of 3D Gaussian blendshapes has enabled the real-time\nreconstruction of animatable head avatars from monocular video. Toonify, a\nStyleGAN-based framework, has become widely used for facial image stylization.\nTo extend Toonify for synthesizing diverse stylized 3D head avatars using\nGaussian blendshapes, we propose an efficient two-stage framework, ToonifyGB.\nIn Stage 1 (stylized video generation), we employ an improved StyleGAN to\ngenerate the stylized video from the input video frames, which addresses the\nlimitation of cropping aligned faces at a fixed resolution as preprocessing for\nnormal StyleGAN. This process provides a more stable video, which enables\nGaussian blendshapes to better capture the high-frequency details of the video\nframes, and efficiently generate high-quality animation in the next stage. In\nStage 2 (Gaussian blendshapes synthesis), we learn a stylized neutral head\nmodel and a set of expression blendshapes from the generated video. By\ncombining the neutral head model with expression blendshapes, ToonifyGB can\nefficiently render stylized avatars with arbitrary expressions. We validate the\neffectiveness of ToonifyGB on the benchmark dataset using two styles: Arcane\nand Pixar."}
{"id": "2505.09666", "pdf": "https://arxiv.org/pdf/2505.09666", "abs": "https://arxiv.org/abs/2505.09666", "authors": ["Yumin Choi", "Jinheon Baek", "Sung Ju Hwang"], "title": "System Prompt Optimization with Meta-Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance."}
{"id": "2505.09922", "pdf": "https://arxiv.org/pdf/2505.09922", "abs": "https://arxiv.org/abs/2505.09922", "authors": ["Zichen Liu", "Wei Zhang", "Tiejun Li"], "title": "Improving the Euclidean Diffusion Generation of Manifold Data by Mitigating Score Function Singularity", "categories": ["cs.LG"], "comment": "22 pages", "summary": "Euclidean diffusion models have achieved remarkable success in generative\nmodeling across diverse domains, and they have been extended to manifold case\nin recent advances. Instead of explicitly utilizing the structure of special\nmanifolds as studied in previous works, we investigate direct sampling of the\nEuclidean diffusion models for general manifold-constrained data in this paper.\nWe reveal the multiscale singularity of the score function in the embedded\nspace of manifold, which hinders the accuracy of diffusion-generated samples.\nWe then present an elaborate theoretical analysis of the singularity structure\nof the score function by separating it along the tangential and normal\ndirections of the manifold. To mitigate the singularity and improve the\nsampling accuracy, we propose two novel methods: (1) Niso-DM, which introduces\nnon-isotropic noise along the normal direction to reduce scale discrepancies,\nand (2) Tango-DM, which trains only the tangential component of the score\nfunction using a tangential-only loss function. Numerical experiments\ndemonstrate that our methods achieve superior performance on distributions over\nvarious manifolds with complex geometries."}
{"id": "2505.10282", "pdf": "https://arxiv.org/pdf/2505.10282", "abs": "https://arxiv.org/abs/2505.10282", "authors": ["Dubai Li", "Nan Jiang", "Kangping Huang", "Ruiqi Tu", "Shuyu Ouyang", "Huayu Yu", "Lin Qiao", "Chen Yu", "Tianshu Zhou", "Danyang Tong", "Qian Wang", "Mengtao Li", "Xiaofeng Zeng", "Yu Tian", "Xinping Tian", "Jingsong Li"], "title": "From Questions to Clinical Recommendations: Large Language Models Driving Evidence-Based Clinical Decision Making", "categories": ["cs.CL"], "comment": null, "summary": "Clinical evidence, derived from rigorous research and data analysis, provides\nhealthcare professionals with reliable scientific foundations for informed\ndecision-making. Integrating clinical evidence into real-time practice is\nchallenging due to the enormous workload, complex professional processes, and\ntime constraints. This highlights the need for tools that automate evidence\nsynthesis to support more efficient and accurate decision making in clinical\nsettings. This study introduces Quicker, an evidence-based clinical decision\nsupport system powered by large language models (LLMs), designed to automate\nevidence synthesis and generate clinical recommendations modeled after standard\nclinical guideline development processes. Quicker implements a fully automated\nchain that covers all phases, from questions to clinical recommendations, and\nfurther enables customized decision-making through integrated tools and\ninteractive user interfaces. To evaluate Quicker's capabilities, we developed\nthe Q2CRBench-3 benchmark dataset, based on clinical guideline development\nrecords for three different diseases. Experimental results highlighted\nQuicker's strong performance, with fine-grained question decomposition tailored\nto user preferences, retrieval sensitivities comparable to human experts, and\nliterature screening performance approaching comprehensive inclusion of\nrelevant studies. In addition, Quicker-assisted evidence assessment effectively\nsupported human reviewers, while Quicker's recommendations were more\ncomprehensive and logically coherent than those of clinicians. In system-level\ntesting, collaboration between a single reviewer and Quicker reduced the time\nrequired for recommendation development to 20-40 minutes. In general, our\nfindings affirm the potential of Quicker to help physicians make quicker and\nmore reliable evidence-based clinical decisions."}
{"id": "2505.10088", "pdf": "https://arxiv.org/pdf/2505.10088", "abs": "https://arxiv.org/abs/2505.10088", "authors": ["Yuncheng Guo", "Xiaodong Gu"], "title": "MMRL++: Parameter-Efficient and Interaction-Aware Representation Learning for Vision-Language Models", "categories": ["cs.CV"], "comment": "Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract appearing here is slightly shorter than that in the\n  PDF file", "summary": "Large-scale pre-trained Vision-Language Models (VLMs) have significantly\nadvanced transfer learning across diverse tasks. However, adapting these models\nwith limited few-shot data often leads to overfitting, undermining their\nability to generalize to new tasks. To address this, we propose Multi-Modal\nRepresentation Learning (MMRL), which introduces a shared, learnable,\nmodality-agnostic representation space. MMRL generates space tokens projected\ninto both text and image encoders as representation tokens, enabling more\neffective cross-modal interactions. Unlike prior methods that mainly optimize\nclass token features, MMRL inserts representation tokens into higher encoder\nlayers--where task-specific features are more prominent--while preserving\ngeneral knowledge in the lower layers. During training, both class and\nrepresentation features are jointly optimized: a trainable projection layer is\napplied to representation tokens for task adaptation, while the projection\nlayer for class token remains frozen to retain pre-trained knowledge. To\nfurther promote generalization, we introduce a regularization term aligning\nclass and text features with the frozen VLM's zero-shot features. At inference,\na decoupling strategy uses both class and representation features for base\ntasks, but only class features for novel tasks due to their stronger\ngeneralization. Building upon this, we propose MMRL++, a parameter-efficient\nand interaction-aware extension that significantly reduces trainable parameters\nand enhances intra-modal interactions--particularly across the layers of\nrepresentation tokens--allowing gradient sharing and instance-specific\ninformation to propagate more effectively through the network. Extensive\nexperiments on 15 datasets demonstrate that MMRL and MMRL++ consistently\noutperform state-of-the-art methods, achieving a strong balance between\ntask-specific adaptation and generalization."}
{"id": "2505.09704", "pdf": "https://arxiv.org/pdf/2505.09704", "abs": "https://arxiv.org/abs/2505.09704", "authors": ["Roberto Pereira", "Fernanda Famá", "Charalampos Kalalas", "Paolo Dini"], "title": "Energy-Efficient Federated Learning for AIoT using Clustering Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While substantial research has been devoted to optimizing model performance,\nconvergence rates, and communication efficiency, the energy implications of\nfederated learning (FL) within Artificial Intelligence of Things (AIoT)\nscenarios are often overlooked in the existing literature. This study examines\nthe energy consumed during the FL process, focusing on three main\nenergy-intensive processes: pre-processing, communication, and local learning,\nall contributing to the overall energy footprint. We rely on the observation\nthat device/client selection is crucial for speeding up the convergence of\nmodel training in a distributed AIoT setting and propose two\nclustering-informed methods. These clustering solutions are designed to group\nAIoT devices with similar label distributions, resulting in clusters composed\nof nearly heterogeneous devices. Hence, our methods alleviate the heterogeneity\noften encountered in real-world distributed learning applications. Throughout\nextensive numerical experimentation, we demonstrate that our clustering\nstrategies typically achieve high convergence rates while maintaining low\nenergy consumption when compared to other recent approaches available in the\nliterature."}
{"id": "2505.09925", "pdf": "https://arxiv.org/pdf/2505.09925", "abs": "https://arxiv.org/abs/2505.09925", "authors": ["Yutao Yang", "Jie Zhou", "Junsong Li", "Qianjun Pan", "Bihao Zhan", "Qin Chen", "Xipeng Qiu", "Liang He"], "title": "Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces an interactive continual learning paradigm where AI\nmodels dynamically learn new skills from real-time human feedback while\nretaining prior knowledge. This paradigm distinctively addresses two major\nlimitations of traditional continual learning: (1) dynamic model updates using\nstreaming, real-time human-annotated data, rather than static datasets with\nfixed labels, and (2) the assumption of clean labels, by explicitly handling\nthe noisy feedback common in real-world interactions. To tackle these problems,\nwe propose RiCL, a Reinforced interactive Continual Learning framework\nleveraging Large Language Models (LLMs) to learn new skills effectively from\ndynamic feedback. RiCL incorporates three key components: a temporal\nconsistency-aware purifier to automatically discern clean from noisy samples in\ndata streams; an interaction-aware direct preference optimization strategy to\nalign model behavior with human intent by reconciling AI-generated and\nhuman-provided feedback; and a noise-resistant contrastive learning module that\ncaptures robust representations by exploiting inherent data relationships, thus\navoiding reliance on potentially unreliable labels. Extensive experiments on\ntwo benchmark datasets (FewRel and TACRED), contaminated with realistic noise\npatterns, demonstrate that our RiCL approach substantially outperforms existing\ncombinations of state-of-the-art online continual learning and noisy-label\nlearning methods."}
{"id": "2505.10320", "pdf": "https://arxiv.org/pdf/2505.10320", "abs": "https://arxiv.org/abs/2505.10320", "authors": ["Chenxi Whitehouse", "Tianlu Wang", "Ping Yu", "Xian Li", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 8 tables, 11 figures", "summary": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses."}
{"id": "2505.10118", "pdf": "https://arxiv.org/pdf/2505.10118", "abs": "https://arxiv.org/abs/2505.10118", "authors": ["Yangfu Li", "Hongjian Zhan", "Tianyi Chen", "Qi Liu", "Yue Lu"], "title": "Why 1 + 1 < 1 in Visual Token Pruning: Beyond Naive Integration via Multi-Objective Balanced Covering", "categories": ["cs.CV", "cs.CL"], "comment": "31 pages,9 figures,conference", "summary": "Existing visual token pruning methods target prompt alignment and visual\npreservation with static strategies, overlooking the varying relative\nimportance of these objectives across tasks, which leads to inconsistent\nperformance. To address this, we derive the first closed-form error bound for\nvisual token pruning based on the Hausdorff distance, uniformly characterizing\nthe contributions of both objectives. Moreover, leveraging $\\epsilon$-covering\ntheory, we reveal an intrinsic trade-off between these objectives and quantify\ntheir optimal attainment levels under a fixed budget. To practically handle\nthis trade-off, we propose Multi-Objective Balanced Covering (MoB), which\nreformulates visual token pruning as a bi-objective covering problem. In this\nframework, the attainment trade-off reduces to budget allocation via greedy\nradius trading. MoB offers a provable performance bound and linear scalability\nwith respect to the number of input visual tokens, enabling adaptation to\nchallenging pruning scenarios. Extensive experiments show that MoB preserves\n96.4% of performance for LLaVA-1.5-7B using only 11.1% of the original visual\ntokens and accelerates LLaVA-Next-7B by 1.3-1.5$\\times$ with negligible\nperformance loss. Additionally, evaluations on Qwen2-VL and Video-LLaVA confirm\nthat MoB integrates seamlessly into advanced MLLMs and diverse vision-language\ntasks."}
{"id": "2505.09716", "pdf": "https://arxiv.org/pdf/2505.09716", "abs": "https://arxiv.org/abs/2505.09716", "authors": ["George Dimitriadis. Spyridon Samothrakis"], "title": "Out-of-distribution generalisation is hard: evidence from ARC-like tasks", "categories": ["cs.LG", "cs.AI"], "comment": "Submission to NeurIPS 2025", "summary": "Out-of-distribution (OOD) generalisation is considered a hallmark of human\nand animal intelligence. To achieve OOD through composition, a system must\ndiscover the environment-invariant properties of experienced input-output\nmappings and transfer them to novel inputs. This can be realised if an\nintelligent system can identify appropriate, task-invariant, and composable\ninput features, as well as the composition methods, thus allowing it to act\nbased not on the interpolation between learnt data points but on the\ntask-invariant composition of those features. We propose that in order to\nconfirm that an algorithm does indeed learn compositional structures from data,\nit is not enough to just test on an OOD setup, but one also needs to confirm\nthat the features identified are indeed compositional. We showcase this by\nexploring two tasks with clearly defined OOD metrics that are not OOD solvable\nby three commonly used neural networks: a Multi-Layer Perceptron (MLP), a\nConvolutional Neural Network (CNN), and a Transformer. In addition, we develop\ntwo novel network architectures imbued with biases that allow them to be\nsuccessful in OOD scenarios. We show that even with correct biases and almost\nperfect OOD performance, an algorithm can still fail to learn the correct\nfeatures for compositional generalisation."}
{"id": "2505.09949", "pdf": "https://arxiv.org/pdf/2505.09949", "abs": "https://arxiv.org/abs/2505.09949", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Samgyu Yang", "Abdulrahman Faden"], "title": "Advanced Crash Causation Analysis for Freeway Safety: A Large Language Model Approach to Identifying Key Contributing Factors", "categories": ["cs.LG", "cs.CL", "stat.AP"], "comment": null, "summary": "Understanding the factors contributing to traffic crashes and developing\nstrategies to mitigate their severity is essential. Traditional statistical\nmethods and machine learning models often struggle to capture the complex\ninteractions between various factors and the unique characteristics of each\ncrash. This research leverages large language model (LLM) to analyze freeway\ncrash data and provide crash causation analysis accordingly. By compiling 226\ntraffic safety studies related to freeway crashes, a training dataset\nencompassing environmental, driver, traffic, and geometric design factors was\ncreated. The Llama3 8B model was fine-tuned using QLoRA to enhance its\nunderstanding of freeway crashes and their contributing factors, as covered in\nthese studies. The fine-tuned Llama3 8B model was then used to identify crash\ncausation without pre-labeled data through zero-shot classification, providing\ncomprehensive explanations to ensure that the identified causes were reasonable\nand aligned with existing research. Results demonstrate that LLMs effectively\nidentify primary crash causes such as alcohol-impaired driving, speeding,\naggressive driving, and driver inattention. Incorporating event data, such as\nroad maintenance, offers more profound insights. The model's practical\napplicability and potential to improve traffic safety measures were validated\nby a high level of agreement among researchers in the field of traffic safety,\nas reflected in questionnaire results with 88.89%. This research highlights the\ncomplex nature of traffic crashes and how LLMs can be used for comprehensive\nanalysis of crash causation and other contributing factors. Moreover, it\nprovides valuable insights and potential countermeasures to aid planners and\npolicymakers in developing more effective and efficient traffic safety\npractices."}
{"id": "2505.10354", "pdf": "https://arxiv.org/pdf/2505.10354", "abs": "https://arxiv.org/abs/2505.10354", "authors": ["Yile Wang", "Zhanyu Shen", "Hui Huang"], "title": "LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Semantic text representation is a fundamental task in the field of natural\nlanguage processing. Existing text embedding (e.g., SimCSE and LLM2Vec) have\ndemonstrated excellent performance, but the values of each dimension are\ndifficult to trace and interpret. Bag-of-words, as classic sparse interpretable\nembeddings, suffers from poor performance. Recently, Benara et al. (2024)\npropose interpretable text embeddings using large language models, which forms\n\"0/1\" embeddings based on responses to a series of questions. These\ninterpretable text embeddings are typically high-dimensional (larger than\n10,000). In this work, we propose Low-dimensional (lower than 500) Dense and\nInterpretable text embeddings with Relative representations (LDIR). The\nnumerical values of its dimensions indicate semantic relatedness to different\nanchor texts through farthest point sampling, offering both semantic\nrepresentation as well as a certain level of traceability and interpretability.\nWe validate LDIR on multiple semantic textual similarity, retrieval, and\nclustering tasks. Extensive experimental results show that LDIR performs close\nto the black-box baseline models and outperforms the interpretable embeddings\nbaselines with much fewer dimensions. Code is available at\nhttps://github.com/szu-tera/LDIR."}
{"id": "2505.10124", "pdf": "https://arxiv.org/pdf/2505.10124", "abs": "https://arxiv.org/abs/2505.10124", "authors": ["Ziad Kheil", "Lucas Robinet", "Laurent Risser", "Soleakhena Ken"], "title": "IMITATE: Image Registration with Context for unknown time frame recovery", "categories": ["cs.CV", "eess.IV"], "comment": "IEEE ISBI 2025", "summary": "In this paper, we formulate a novel image registration formalism dedicated to\nthe estimation of unknown condition-related images, based on two or more known\nimages and their associated conditions. We show how to practically model this\nformalism by using a new conditional U-Net architecture, which fully takes into\naccount the conditional information and does not need any fixed image. Our\nformalism is then applied to image moving tumors for radiotherapy treatment at\ndifferent breathing amplitude using 4D-CT (3D+t) scans in thoracoabdominal\nregions. This driving application is particularly complex as it requires to\nstitch a collection of sequential 2D slices into several 3D volumes at\ndifferent organ positions. Movement interpolation with standard methods then\ngenerates well known reconstruction artefacts in the assembled volumes due to\nirregular patient breathing, hysteresis and poor correlation of breathing\nsignal to internal motion. Results obtained on 4D-CT clinical data showcase\nartefact-free volumes achieved through real-time latencies. The code is\npublicly available at https://github.com/Kheil-Z/IMITATE ."}
{"id": "2505.09724", "pdf": "https://arxiv.org/pdf/2505.09724", "abs": "https://arxiv.org/abs/2505.09724", "authors": ["Gino Carmona-Díaz", "William Jiménez-Leal", "María Alejandra Grisales", "Chandra Sripada", "Santiago Amaya", "Michael Inzlicht", "Juan Pablo Bermúdez"], "title": "An AI-Powered Research Assistant in the Lab: A Practical Guide for Text Analysis Through Iterative Collaboration with LLMs", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "31 pages, 1 figure", "summary": "Analyzing texts such as open-ended responses, headlines, or social media\nposts is a time- and labor-intensive process highly susceptible to bias. LLMs\nare promising tools for text analysis, using either a predefined (top-down) or\na data-driven (bottom-up) taxonomy, without sacrificing quality. Here we\npresent a step-by-step tutorial to efficiently develop, test, and apply\ntaxonomies for analyzing unstructured data through an iterative and\ncollaborative process between researchers and LLMs. Using personal goals\nprovided by participants as an example, we demonstrate how to write prompts to\nreview datasets and generate a taxonomy of life domains, evaluate and refine\nthe taxonomy through prompt and direct modifications, test the taxonomy and\nassess intercoder agreements, and apply the taxonomy to categorize an entire\ndataset with high intercoder reliability. We discuss the possibilities and\nlimitations of using LLMs for text analysis."}
{"id": "2505.09952", "pdf": "https://arxiv.org/pdf/2505.09952", "abs": "https://arxiv.org/abs/2505.09952", "authors": ["Tianyu Huai", "Jie Zhou", "Yuxuan Cai", "Qin Chen", "Wen Wu", "Xingjiao Wu", "Xipeng Qiu", "Liang He"], "title": "Task-Core Memory Management and Consolidation for Long-term Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to Neurips2025", "summary": "In this paper, we focus on a long-term continual learning (CL) task, where a\nmodel learns sequentially from a stream of vast tasks over time, acquiring new\nknowledge while retaining previously learned information in a manner akin to\nhuman learning. Unlike traditional CL settings, long-term CL involves handling\na significantly larger number of tasks, which exacerbates the issue of\ncatastrophic forgetting. Our work seeks to address two critical questions: 1)\nHow do existing CL methods perform in the context of long-term CL? and 2) How\ncan we mitigate the catastrophic forgetting that arises from prolonged\nsequential updates? To tackle these challenges, we propose a novel framework\ninspired by human memory mechanisms for long-term continual learning (Long-CL).\nSpecifically, we introduce a task-core memory management strategy to\nefficiently index crucial memories and adaptively update them as learning\nprogresses. Additionally, we develop a long-term memory consolidation mechanism\nthat selectively retains hard and discriminative samples, ensuring robust\nknowledge retention. To facilitate research in this area, we construct and\nrelease two multi-modal and textual benchmarks, MMLongCL-Bench and\nTextLongCL-Bench, providing a valuable resource for evaluating long-term CL\napproaches. Experimental results show that Long-CL outperforms the previous\nstate-of-the-art by 7.4\\% and 6.5\\% AP on the two benchmarks, respectively,\ndemonstrating the effectiveness of our approach."}
{"id": "2505.10356", "pdf": "https://arxiv.org/pdf/2505.10356", "abs": "https://arxiv.org/abs/2505.10356", "authors": ["Chunyu Ye", "Shaonan Wang"], "title": "Coherent Language Reconstruction from Brain Recordings with Flexible Multi-Modal Input Stimuli", "categories": ["cs.CL"], "comment": null, "summary": "Decoding thoughts from brain activity offers valuable insights into human\ncognition and enables promising applications in brain-computer interaction.\nWhile prior studies have explored language reconstruction from fMRI data, they\nare typically limited to single-modality inputs such as images or audio. In\ncontrast, human thought is inherently multimodal. To bridge this gap, we\npropose a unified and flexible framework for reconstructing coherent language\nfrom brain recordings elicited by diverse input modalities-visual, auditory,\nand textual. Our approach leverages visual-language models (VLMs), using\nmodality-specific experts to jointly interpret information across modalities.\nExperiments demonstrate that our method achieves performance comparable to\nstate-of-the-art systems while remaining adaptable and extensible. This work\nadvances toward more ecologically valid and generalizable mind decoding."}
{"id": "2505.10152", "pdf": "https://arxiv.org/pdf/2505.10152", "abs": "https://arxiv.org/abs/2505.10152", "authors": ["Yikang Wei"], "title": "Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization", "categories": ["cs.CV"], "comment": "IJCAI 2025", "summary": "Federated domain generalization aims to learn a generalizable model from\nmultiple decentralized source domains for deploying on the unseen target\ndomain. The style augmentation methods have achieved great progress on domain\ngeneralization. However, the existing style augmentation methods either explore\nthe data styles within isolated source domain or interpolate the style\ninformation across existing source domains under the data decentralization\nscenario, which leads to limited style space. To address this issue, we propose\na Multi-source Collaborative Style Augmentation and Domain-invariant learning\nmethod (MCSAD) for federated domain generalization. Specifically, we propose a\nmulti-source collaborative style augmentation module to generate data in the\nbroader style space. Furthermore, we conduct domain-invariant learning between\nthe original data and augmented data by cross-domain feature alignment within\nthe same class and classes relation ensemble distillation between different\nclasses to learn a domain-invariant model. By alternatively conducting\ncollaborative style augmentation and domain-invariant learning, the model can\ngeneralize well on unseen target domain. Extensive experiments on multiple\ndomain generalization datasets indicate that our method significantly\noutperforms the state-of-the-art federated domain generalization methods."}
{"id": "2505.09733", "pdf": "https://arxiv.org/pdf/2505.09733", "abs": "https://arxiv.org/abs/2505.09733", "authors": ["Alpaslan Gokcen", "Ali Boyaci"], "title": "Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated learning (FL) presents an effective solution for collaborative\nmodel training while maintaining data privacy across decentralized client\ndatasets. However, data quality issues such as noisy labels, missing classes,\nand imbalanced distributions significantly challenge its effectiveness. This\nstudy proposes a federated learning methodology that systematically addresses\ndata quality issues, including noise, class imbalance, and missing labels. The\nproposed approach systematically enhances data integrity through adaptive noise\ncleaning, collaborative conditional GAN-based synthetic data generation, and\nrobust federated model training. Experimental evaluations conducted on\nbenchmark datasets (MNIST and Fashion-MNIST) demonstrate significant\nimprovements in federated model performance, particularly macro-F1 Score, under\nvarying noise and class imbalance conditions. Additionally, the proposed\nframework carefully balances computational feasibility and substantial\nperformance gains, ensuring practicality for resource constrained edge devices\nwhile rigorously maintaining data privacy. Our results indicate that this\nmethod effectively mitigates common data quality challenges, providing a\nrobust, scalable, and privacy compliant solution suitable for diverse\nreal-world federated learning scenarios."}
{"id": "2505.09955", "pdf": "https://arxiv.org/pdf/2505.09955", "abs": "https://arxiv.org/abs/2505.09955", "authors": ["Jaeho Kim", "Seulki Lee"], "title": "TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 Accept", "summary": "Unsupervised domain adaptation (UDA) for time series data remains a critical\nchallenge in deep learning, with traditional pseudo-labeling strategies failing\nto capture temporal patterns and channel-wise shifts between domains, producing\nsub-optimal pseudo-labels. As such, we introduce TransPL, a novel approach that\naddresses these limitations by modeling the joint distribution $P(\\mathbf{X},\ny)$ of the source domain through code transition matrices, where the codes are\nderived from vector quantization (VQ) of time series patches. Our method\nconstructs class- and channel-wise code transition matrices from the source\ndomain and employs Bayes' rule for target domain adaptation, generating\npseudo-labels based on channel-wise weighted class-conditional likelihoods.\nTransPL offers three key advantages: explicit modeling of temporal transitions\nand channel-wise shifts between different domains, versatility towards\ndifferent UDA scenarios (e.g., weakly-supervised UDA), and explainable\npseudo-label generation. We validate TransPL's effectiveness through extensive\nanalysis on four time series UDA benchmarks and confirm that it consistently\noutperforms state-of-the-art pseudo-labeling methods by a strong margin (6.1%\naccuracy improvement, 4.9% F1 improvement), while providing interpretable\ninsights into the domain adaptation process through its learned code transition\nmatrices."}
{"id": "2505.10389", "pdf": "https://arxiv.org/pdf/2505.10389", "abs": "https://arxiv.org/abs/2505.10389", "authors": ["Benjamin White", "Anastasia Shimorina"], "title": "Multi-domain Multilingual Sentiment Analysis in Industry: Predicting Aspect-based Opinion Quadruples", "categories": ["cs.CL"], "comment": null, "summary": "This paper explores the design of an aspect-based sentiment analysis system\nusing large language models (LLMs) for real-world use. We focus on quadruple\nopinion extraction -- identifying aspect categories, sentiment polarity,\ntargets, and opinion expressions from text data across different domains and\nlanguages. Using internal datasets, we investigate whether a single fine-tuned\nmodel can effectively handle multiple domain-specific taxonomies\nsimultaneously. We demonstrate that a combined multi-domain model achieves\nperformance comparable to specialized single-domain models while reducing\noperational complexity. We also share lessons learned for handling\nnon-extractive predictions and evaluating various failure modes when developing\nLLM-based systems for structured prediction tasks."}
{"id": "2505.10169", "pdf": "https://arxiv.org/pdf/2505.10169", "abs": "https://arxiv.org/abs/2505.10169", "authors": ["Matthias Kümmerer", "Harneet Khanuja", "Matthias Bethge"], "title": "Modeling Saliency Dataset Bias", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes."}
{"id": "2505.09738", "pdf": "https://arxiv.org/pdf/2505.09738", "abs": "https://arxiv.org/abs/2505.09738", "authors": ["Shaurya Sharthak", "Vinayak Pahalwan", "Adithya Kamath", "Adarsh Shirawalmath"], "title": "Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Pretrained language models (LLMs) are often constrained by their fixed\ntokenization schemes, leading to inefficiencies and performance limitations,\nparticularly for multilingual or specialized applications. This tokenizer\nlock-in presents significant challenges. standard methods to overcome this\noften require prohibitive computational resources. Although tokenizer\nreplacement with heuristic initialization aims to reduce this burden, existing\nmethods often require exhaustive residual fine-tuning and still may not fully\npreserve semantic nuances or adequately address the underlying compression\ninefficiencies. Our framework introduces two innovations: first, Tokenadapt, a\nmodel-agnostic tokenizer transplantation method, and second, novel\npre-tokenization learning for multi-word Supertokens to enhance compression and\nreduce fragmentation. Tokenadapt initializes new unique token embeddings via a\nhybrid heuristic that combines two methods: a local estimate based on subword\ndecomposition using the old tokenizer, and a global estimate utilizing the\ntop-k semantically similar tokens from the original vocabulary. This\nmethodology aims to preserve semantics while significantly minimizing\nretraining requirements. Empirical investigations validate both contributions:\nthe transplantation heuristic successfully initializes unique tokens, markedly\noutperforming conventional baselines and sophisticated methods including\nTranstokenizer and ReTok, while our Supertokens achieve notable compression\ngains. Our zero-shot perplexity results demonstrate that the TokenAdapt hybrid\ninitialization consistently yields lower perplexity ratios compared to both\nReTok and TransTokenizer baselines across different base models and newly\ntrained target tokenizers. TokenAdapt typically reduced the overall perplexity\nratio significantly compared to ReTok, yielding at least a 2-fold improvement\nin these aggregate scores."}
{"id": "2505.09959", "pdf": "https://arxiv.org/pdf/2505.09959", "abs": "https://arxiv.org/abs/2505.09959", "authors": ["Zengxia Guo", "Bohui An", "Zhongqi Lu"], "title": "Approximated Behavioral Metric-based State Projection for Federated Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated reinforcement learning (FRL) methods usually share the encrypted\nlocal state or policy information and help each client to learn from others\nwhile preserving everyone's privacy. In this work, we propose that sharing the\napproximated behavior metric-based state projection function is a promising way\nto enhance the performance of FRL and concurrently provides an effective\nprotection of sensitive information. We introduce FedRAG, a FRL framework to\nlearn a computationally practical projection function of states for each client\nand aggregating the parameters of projection functions at a central server. The\nFedRAG approach shares no sensitive task-specific information, yet provides\ninformation gain for each client. We conduct extensive experiments on the\nDeepMind Control Suite to demonstrate insightful results."}
{"id": "2505.10402", "pdf": "https://arxiv.org/pdf/2505.10402", "abs": "https://arxiv.org/abs/2505.10402", "authors": ["Yihong Dong", "Yuchen Liu", "Xue Jiang", "Zhi Jin", "Ge Li"], "title": "Rethinking Repetition Problems of LLMs in Code Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to ACL 2025 (main)", "summary": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code."}
{"id": "2505.10205", "pdf": "https://arxiv.org/pdf/2505.10205", "abs": "https://arxiv.org/abs/2505.10205", "authors": ["Umair Haroon", "Ahmad AlMughrabi", "Thanasis Zoumpekas", "Ricardo Marques", "Petia Radeva"], "title": "VolE: A Point-cloud Framework for Food 3D Reconstruction and Volume Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate food volume estimation is crucial for medical nutrition management\nand health monitoring applications, but current food volume estimation methods\nare often limited by mononuclear data, leveraging single-purpose hardware such\nas 3D scanners, gathering sensor-oriented information such as depth\ninformation, or relying on camera calibration using a reference object. In this\npaper, we present VolE, a novel framework that leverages mobile device-driven\n3D reconstruction to estimate food volume. VolE captures images and camera\nlocations in free motion to generate precise 3D models, thanks to AR-capable\nmobile devices. To achieve real-world measurement, VolE is a reference- and\ndepth-free framework that leverages food video segmentation for food mask\ngeneration. We also introduce a new food dataset encompassing the challenging\nscenarios absent in the previous benchmarks. Our experiments demonstrate that\nVolE outperforms the existing volume estimation techniques across multiple\ndatasets by achieving 2.22 % MAPE, highlighting its superior performance in\nfood volume estimation."}
{"id": "2505.09742", "pdf": "https://arxiv.org/pdf/2505.09742", "abs": "https://arxiv.org/abs/2505.09742", "authors": ["Yuan-Hang Zhang", "Massimiliano Di Ventra"], "title": "A Generative Neural Annealer for Black-Box Combinatorial Optimization", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.NE"], "comment": "15 pages, 3 figures", "summary": "We propose a generative, end-to-end solver for black-box combinatorial\noptimization that emphasizes both sample efficiency and solution quality on NP\nproblems. Drawing inspiration from annealing-based algorithms, we treat the\nblack-box objective as an energy function and train a neural network to model\nthe associated Boltzmann distribution. By conditioning on temperature, the\nnetwork captures a continuum of distributions--from near-uniform at high\ntemperatures to sharply peaked around global optima at low\ntemperatures--thereby learning the structure of the energy landscape and\nfacilitating global optimization. When queries are expensive, the\ntemperature-dependent distributions naturally enable data augmentation and\nimprove sample efficiency. When queries are cheap but the problem remains hard,\nthe model learns implicit variable interactions, effectively \"opening\" the\nblack box. We validate our approach on challenging combinatorial tasks under\nboth limited and unlimited query budgets, showing competitive performance\nagainst state-of-the-art black-box optimizers."}
{"id": "2505.09969", "pdf": "https://arxiv.org/pdf/2505.09969", "abs": "https://arxiv.org/abs/2505.09969", "authors": ["Ali Azimi Lamir", "Shiva Razzagzadeh", "Zeynab Rezaei"], "title": "A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study presents a machine learning-based framework for heart disease\nprediction using the heart-disease dataset, comprising 303 samples with 14\nfeatures. The methodology involves data preprocessing, model training, and\nevaluation using three classifiers: Logistic Regression, K-Nearest Neighbors\n(KNN), and Random Forest. Hyperparameter tuning with GridSearchCV and\nRandomizedSearchCV was employed to enhance model performance. The Random Forest\nclassifier outperformed other models, achieving an accuracy of 91% and an\nF1-score of 0.89. Evaluation metrics, including precision, recall, and\nconfusion matrix, revealed balanced performance across classes. The proposed\nmodel demonstrates strong potential for aiding clinical decision-making by\neffectively predicting heart disease. Limitations such as dataset size and\ngeneralizability underscore the need for future studies using larger and more\ndiverse datasets. This work highlights the utility of machine learning in\nhealthcare, offering insights for further advancements in predictive\ndiagnostics."}
{"id": "2505.10409", "pdf": "https://arxiv.org/pdf/2505.10409", "abs": "https://arxiv.org/abs/2505.10409", "authors": ["Yue Guo", "Jae Ho Sohn", "Gondy Leroy", "Trevor Cohen"], "title": "Are LLM-generated plain language summaries truly understandable? A large-scale crowdsourced evaluation", "categories": ["cs.CL"], "comment": null, "summary": "Plain language summaries (PLSs) are essential for facilitating effective\ncommunication between clinicians and patients by making complex medical\ninformation easier for laypeople to understand and act upon. Large language\nmodels (LLMs) have recently shown promise in automating PLS generation, but\ntheir effectiveness in supporting health information comprehension remains\nunclear. Prior evaluations have generally relied on automated scores that do\nnot measure understandability directly, or subjective Likert-scale ratings from\nconvenience samples with limited generalizability. To address these gaps, we\nconducted a large-scale crowdsourced evaluation of LLM-generated PLSs using\nAmazon Mechanical Turk with 150 participants. We assessed PLS quality through\nsubjective Likert-scale ratings focusing on simplicity, informativeness,\ncoherence, and faithfulness; and objective multiple-choice comprehension and\nrecall measures of reader understanding. Additionally, we examined the\nalignment between 10 automated evaluation metrics and human judgments. Our\nfindings indicate that while LLMs can generate PLSs that appear\nindistinguishable from human-written ones in subjective evaluations,\nhuman-written PLSs lead to significantly better comprehension. Furthermore,\nautomated evaluation metrics fail to reflect human judgment, calling into\nquestion their suitability for evaluating PLSs. This is the first study to\nsystematically evaluate LLM-generated PLSs based on both reader preferences and\ncomprehension outcomes. Our findings highlight the need for evaluation\nframeworks that move beyond surface-level quality and for generation methods\nthat explicitly optimize for layperson comprehension."}
{"id": "2505.10223", "pdf": "https://arxiv.org/pdf/2505.10223", "abs": "https://arxiv.org/abs/2505.10223", "authors": ["Puru Vaish", "Felix Meister", "Tobias Heimann", "Christoph Brune", "Jelmer M. Wolterink"], "title": "Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at MIDL 2025", "summary": "Medical image segmentation models are often trained on curated datasets,\nleading to performance degradation when deployed in real-world clinical\nsettings due to mismatches between training and test distributions. While data\naugmentation techniques are widely used to address these challenges,\ntraditional visually consistent augmentation strategies lack the robustness\nneeded for diverse real-world scenarios. In this work, we systematically\nevaluate alternative augmentation strategies, focusing on MixUp and Auxiliary\nFourier Augmentation. These methods mitigate the effects of multiple variations\nwithout explicitly targeting specific sources of distribution shifts. We\ndemonstrate how these techniques significantly improve out-of-distribution\ngeneralization and robustness to imaging variations across a wide range of\ntransformations in cardiac cine MRI and prostate MRI segmentation. We\nquantitatively find that these augmentation methods enhance learned feature\nrepresentations by promoting separability and compactness. Additionally, we\nhighlight how their integration into nnU-Net training pipelines provides an\neasy-to-implement, effective solution for enhancing the reliability of medical\nsegmentation models in real-world applications."}
{"id": "2505.09794", "pdf": "https://arxiv.org/pdf/2505.09794", "abs": "https://arxiv.org/abs/2505.09794", "authors": ["J. Moreno-Casanova", "J. M. Auñón", "A. Mártinez-Pérez", "M. E. Pérez-Martínez", "M. E. Gas-López"], "title": "Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Research projects, including those focused on cancer, rely on the manual\nextraction of information from clinical reports. This process is time-consuming\nand prone to errors, limiting the efficiency of data-driven approaches in\nhealthcare. To address these challenges, Natural Language Processing (NLP)\noffers an alternative for automating the extraction of relevant data from\nelectronic health records (EHRs). In this study, we focus on lung and breast\ncancer due to their high incidence and the significant impact they have on\npublic health. Early detection and effective data management in both types of\ncancer are crucial for improving patient outcomes. To enhance the accuracy and\nefficiency of data extraction, we utilized GMV's NLP tool uQuery, which excels\nat identifying relevant entities in clinical texts and converting them into\nstandardized formats such as SNOMED and OMOP. uQuery not only detects and\nclassifies entities but also associates them with contextual information,\nincluding negated entities, temporal aspects, and patient-related details. In\nthis work, we explore the use of NLP techniques, specifically Named Entity\nRecognition (NER), to automatically identify and extract key clinical\ninformation from EHRs related to these two cancers. A dataset from Health\nResearch Institute Hospital La Fe (IIS La Fe), comprising 200 annotated breast\ncancer and 400 lung cancer reports, was used, with eight clinical entities\nmanually labeled using the Doccano platform. To perform NER, we fine-tuned the\nbsc-bio-ehr-en3 model, a RoBERTa-based biomedical linguistic model pre-trained\nin Spanish. Fine-tuning was performed using the Transformers architecture,\nenabling accurate recognition of clinical entities in these cancer types. Our\nresults demonstrate strong overall performance, particularly in identifying\nentities like MET and PAT, although challenges remain with less frequent\nentities like EVOL."}
{"id": "2505.09983", "pdf": "https://arxiv.org/pdf/2505.09983", "abs": "https://arxiv.org/abs/2505.09983", "authors": ["Changxun Zhu", "Qilong Wu", "Lingjuan Lyu", "Shibei Xue"], "title": "Sybil-based Virtual Data Poisoning Attacks in Federated Learning", "categories": ["cs.CR", "cs.LG"], "comment": "7 pages, 6 figures, accepted by IEEE Codit 2025", "summary": "Federated learning is vulnerable to poisoning attacks by malicious\nadversaries. Existing methods often involve high costs to achieve effective\nattacks. To address this challenge, we propose a sybil-based virtual data\npoisoning attack, where a malicious client generates sybil nodes to amplify the\npoisoning model's impact. To reduce neural network computational complexity, we\ndevelop a virtual data generation method based on gradient matching. We also\ndesign three schemes for target model acquisition, applicable to online local,\nonline global, and offline scenarios. In simulation, our method outperforms\nother attack algorithms since our method can obtain a global target model under\nnon-independent uniformly distributed data."}
{"id": "2505.10413", "pdf": "https://arxiv.org/pdf/2505.10413", "abs": "https://arxiv.org/abs/2505.10413", "authors": ["Jiajie Jin", "Xiaoxi Li", "Guanting Dong", "Yuyao Zhang", "Yutao Zhu", "Yongkang Wu", "Zhonghua Li", "Qi Ye", "Zhicheng Dou"], "title": "Hierarchical Document Refinement for Long-context Retrieval-augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "Real-world RAG applications often encounter long-context input scenarios,\nwhere redundant information and noise results in higher inference costs and\nreduced performance. To address these challenges, we propose LongRefiner, an\nefficient plug-and-play refiner that leverages the inherent structural\ncharacteristics of long documents. LongRefiner employs dual-level query\nanalysis, hierarchical document structuring, and adaptive refinement through\nmulti-task learning on a single foundation model. Experiments on seven QA\ndatasets demonstrate that LongRefiner achieves competitive performance in\nvarious scenarios while using 10x fewer computational costs and latency\ncompared to the best baseline. Further analysis validates that LongRefiner is\nscalable, efficient, and effective, providing practical insights for real-world\nlong-text RAG applications. Our code is available at\nhttps://github.com/ignorejjj/LongRefiner."}
{"id": "2505.10231", "pdf": "https://arxiv.org/pdf/2505.10231", "abs": "https://arxiv.org/abs/2505.10231", "authors": ["Haozhe Luo", "Ziyu Zhou", "Zixin Shu", "Aurélie Pahud de Mortanges", "Robert Berke", "Mauricio Reyes"], "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner."}
{"id": "2505.09807", "pdf": "https://arxiv.org/pdf/2505.09807", "abs": "https://arxiv.org/abs/2505.09807", "authors": ["Timour Ichmoukhamedov", "David Martens"], "title": "Exploring the generalization of LLM truth directions on conversational formats", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Several recent works argue that LLMs have a universal truth direction where\ntrue and false statements are linearly separable in the activation space of the\nmodel. It has been demonstrated that linear probes trained on a single hidden\nstate of the model already generalize across a range of topics and might even\nbe used for lie detection in LLM conversations. In this work we explore how\nthis truth direction generalizes between various conversational formats. We\nfind good generalization between short conversations that end on a lie, but\npoor generalization to longer formats where the lie appears earlier in the\ninput prompt. We propose a solution that significantly improves this type of\ngeneralization by adding a fixed key phrase at the end of each conversation.\nOur results highlight the challenges towards reliable LLM lie detectors that\ngeneralize to new settings."}
{"id": "2505.10003", "pdf": "https://arxiv.org/pdf/2505.10003", "abs": "https://arxiv.org/abs/2505.10003", "authors": ["Tianyu Jiao", "Zhuoran Xiao", "Yihang Huang", "Chenhui Ye", "Yijia Feng", "Liyu Cai", "Jiang Chang", "Fangkun Liu", "Yin Xu", "Dazhi He", "Yunfeng Guan", "Wenjun Zhang"], "title": "AI2MMUM: AI-AI Oriented Multi-Modal Universal Model Leveraging Telecom Domain Large Model", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Designing a 6G-oriented universal model capable of processing multi-modal\ndata and executing diverse air interface tasks has emerged as a common goal in\nfuture wireless systems. Building on our prior work in communication\nmulti-modal alignment and telecom large language model (LLM), we propose a\nscalable, task-aware artificial intelligence-air interface multi-modal\nuniversal model (AI2MMUM), which flexibility and effectively perform various\nphysical layer tasks according to subtle task instructions. The LLM backbone\nprovides robust contextual comprehension and generalization capabilities, while\na fine-tuning approach is adopted to incorporate domain-specific knowledge. To\nenhance task adaptability, task instructions consist of fixed task keywords and\nlearnable, implicit prefix prompts. Frozen radio modality encoders extract\nuniversal representations and adapter layers subsequently bridge radio and\nlanguage modalities. Moreover, lightweight task-specific heads are designed to\ndirectly output task objectives. Comprehensive evaluations demonstrate that\nAI2MMUM achieves SOTA performance across five representative physical\nenvironment/wireless channel-based downstream tasks using the WAIR-D and\nDeepMIMO datasets."}
{"id": "2505.10446", "pdf": "https://arxiv.org/pdf/2505.10446", "abs": "https://arxiv.org/abs/2505.10446", "authors": ["Zemin Huang", "Zhiyang Chen", "Zijun Wang", "Tiancheng Li", "Guo-Jun Qi"], "title": "Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We introduce the \\emph{Diffusion Chain of Lateral Thought (DCoLT)}, a\nreasoning framework for diffusion language models. DCoLT treats each\nintermediate step in the reverse diffusion process as a latent \"thinking\"\naction and optimizes the entire reasoning trajectory to maximize the reward on\nthe correctness of the final answer with outcome-based Reinforcement Learning\n(RL). Unlike traditional Chain-of-Thought (CoT) methods that follow a causal,\nlinear thinking process, DCoLT allows bidirectional, non-linear reasoning with\nno strict rule on grammatical correctness amid its intermediate steps of\nthought. We implement DCoLT on two representative Diffusion Language Models\n(DLMs). First, we choose SEDD as a representative continuous-time discrete\ndiffusion model, where its concrete score derives a probabilistic policy to\nmaximize the RL reward over the entire sequence of intermediate diffusion\nsteps. We further consider the discrete-time masked diffusion language model --\nLLaDA, and find that the order to predict and unmask tokens plays an essential\nrole to optimize its RL action resulting from the ranking-based Unmasking\nPolicy Module (UPM) defined by the Plackett-Luce model. Experiments on both\nmath and code generation tasks show that using only public data and 16 H800\nGPUs, DCoLT-reinforced DLMs outperform other DLMs trained by SFT or RL or even\nboth. Notably, DCoLT-reinforced LLaDA boosts its reasoning accuracy by +9.8%,\n+5.7%, +11.4%, +19.5% on GSM8K, MATH, MBPP, and HumanEval."}
{"id": "2505.10238", "pdf": "https://arxiv.org/pdf/2505.10238", "abs": "https://arxiv.org/abs/2505.10238", "authors": ["Yanbo Ding"], "title": "MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation", "categories": ["cs.CV"], "comment": null, "summary": "Human image animation has gained increasing attention and developed rapidly\ndue to its broad applications in digital humans. However, existing methods rely\nlargely on 2D-rendered pose images for motion guidance, which limits\ngeneralization and discards essential 3D information for open-world animation.\nTo tackle this problem, we propose MTVCrafter (Motion Tokenization Video\nCrafter), the first framework that directly models raw 3D motion sequences\n(i.e., 4D motion) for human image animation. Specifically, we introduce 4DMoT\n(4D motion tokenizer) to quantize 3D motion sequences into 4D motion tokens.\nCompared to 2D-rendered pose images, 4D motion tokens offer more robust\nspatio-temporal cues and avoid strict pixel-level alignment between pose image\nand character, enabling more flexible and disentangled control. Then, we\nintroduce MV-DiT (Motion-aware Video DiT). By designing unique motion attention\nwith 4D positional encodings, MV-DiT can effectively leverage motion tokens as\n4D compact yet expressive context for human image animation in the complex 3D\nworld. Hence, it marks a significant step forward in this field and opens a new\ndirection for pose-guided human video generation. Experiments show that our\nMTVCrafter achieves state-of-the-art results with an FID-VID of 6.98,\nsurpassing the second-best by 65%. Powered by robust motion tokens, MTVCrafter\nalso generalizes well to diverse open-world characters (single/multiple,\nfull/half-body) across various styles and scenarios. Our video demos and code\nare provided in the supplementary material and at this anonymous GitHub link:\nhttps://anonymous.4open.science/r/MTVCrafter-1B13."}
{"id": "2505.09847", "pdf": "https://arxiv.org/pdf/2505.09847", "abs": "https://arxiv.org/abs/2505.09847", "authors": ["Liyang Zhao", "Olurotimi Seton", "Himadeep Reddy Reddivari", "Suvendu Jena", "Shadow Zhao", "Rachit Kumar", "Changshuai Wei"], "title": "Causal Predictive Optimization and Generation for Business AI", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "comment": null, "summary": "The sales process involves sales functions converting leads or opportunities\nto customers and selling more products to existing customers. The optimization\nof the sales process thus is key to success of any B2B business. In this work,\nwe introduce a principled approach to sales optimization and business AI,\nnamely the Causal Predictive Optimization and Generation, which includes three\nlayers: 1) prediction layer with causal ML 2) optimization layer with\nconstraint optimization and contextual bandit 3) serving layer with Generative\nAI and feedback-loop for system enhancement. We detail the implementation and\ndeployment of the system in LinkedIn, showcasing significant wins over legacy\nsystems and sharing learning and insight broadly applicable to this field."}
{"id": "2505.10007", "pdf": "https://arxiv.org/pdf/2505.10007", "abs": "https://arxiv.org/abs/2505.10007", "authors": ["Zijun Chen", "Shengbo Wang", "Nian Si"], "title": "Sample Complexity of Distributionally Robust Average-Reward Reinforcement Learning", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Motivated by practical applications where stable long-term performance is\ncritical-such as robotics, operations research, and healthcare-we study the\nproblem of distributionally robust (DR) average-reward reinforcement learning.\nWe propose two algorithms that achieve near-optimal sample complexity. The\nfirst reduces the problem to a DR discounted Markov decision process (MDP),\nwhile the second, Anchored DR Average-Reward MDP, introduces an anchoring state\nto stabilize the controlled transition kernels within the uncertainty set.\nAssuming the nominal MDP is uniformly ergodic, we prove that both algorithms\nattain a sample complexity of $\\widetilde{O}\\left(|\\mathbf{S}||\\mathbf{A}|\nt_{\\mathrm{mix}}^2\\varepsilon^{-2}\\right)$ for estimating the optimal policy as\nwell as the robust average reward under KL and $f_k$-divergence-based\nuncertainty sets, provided the uncertainty radius is sufficiently small. Here,\n$\\varepsilon$ is the target accuracy, $|\\mathbf{S}|$ and $|\\mathbf{A}|$ denote\nthe sizes of the state and action spaces, and $t_{\\mathrm{mix}}$ is the mixing\ntime of the nominal MDP. This represents the first finite-sample convergence\nguarantee for DR average-reward reinforcement learning. We further validate the\nconvergence rates of our algorithms through numerical experiments."}
{"id": "2505.10493", "pdf": "https://arxiv.org/pdf/2505.10493", "abs": "https://arxiv.org/abs/2505.10493", "authors": ["Shaohan Wang", "Licheng Zhang", "Zheren Fu", "Zhendong Mao"], "title": "CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) is an effective method to enhance the\ncapabilities of large language models (LLMs). Existing methods focus on\noptimizing the retriever or generator in the RAG system by directly utilizing\nthe top-k retrieved documents. However, the documents effectiveness are various\nsignificantly across user queries, i.e. some documents provide valuable\nknowledge while others totally lack critical information. It hinders the\nretriever and generator's adaptation during training. Inspired by human\ncognitive learning, curriculum learning trains models using samples progressing\nfrom easy to difficult, thus enhancing their generalization ability, and we\nintegrate this effective paradigm to the training of the RAG system. In this\npaper, we propose a multi-stage Curriculum Learning based RAG system training\nframework, named CL-RAG. We first construct training data with multiple\ndifficulty levels for the retriever and generator separately through sample\nevolution. Then, we train the model in stages based on the curriculum learning\napproach, thereby optimizing the overall performance and generalization of the\nRAG system more effectively. Our CL-RAG framework demonstrates consistent\neffectiveness across four open-domain QA datasets, achieving performance gains\nof 2% to 4% over multiple advanced methods."}
{"id": "2505.10250", "pdf": "https://arxiv.org/pdf/2505.10250", "abs": "https://arxiv.org/abs/2505.10250", "authors": ["Wenhao Shen", "Wanqi Yin", "Xiaofeng Yang", "Cheng Chen", "Chaoyue Song", "Zhongang Cai", "Lei Yang", "Hao Wang", "Guosheng Lin"], "title": "ADHMR: Aligning Diffusion-based Human Mesh Recovery via Direct Preference Optimization", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025. Code: https://github.com/shenwenhao01/ADHMR", "summary": "Human mesh recovery (HMR) from a single image is inherently ill-posed due to\ndepth ambiguity and occlusions. Probabilistic methods have tried to solve this\nby generating numerous plausible 3D human mesh predictions, but they often\nexhibit misalignment with 2D image observations and weak robustness to\nin-the-wild images. To address these issues, we propose ADHMR, a framework that\nAligns a Diffusion-based HMR model in a preference optimization manner. First,\nwe train a human mesh prediction assessment model, HMR-Scorer, capable of\nevaluating predictions even for in-the-wild images without 3D annotations. We\nthen use HMR-Scorer to create a preference dataset, where each input image has\na pair of winner and loser mesh predictions. This dataset is used to finetune\nthe base model using direct preference optimization. Moreover, HMR-Scorer also\nhelps improve existing HMR models by data cleaning, even with fewer training\nsamples. Extensive experiments show that ADHMR outperforms current\nstate-of-the-art methods. Code is available at:\nhttps://github.com/shenwenhao01/ADHMR."}
{"id": "2505.09852", "pdf": "https://arxiv.org/pdf/2505.09852", "abs": "https://arxiv.org/abs/2505.09852", "authors": ["Apollinaire Poli Nemkova", "Sarath Chandra Lingareddy", "Sagnik Ray Choudhury", "Mark V. Albert"], "title": "Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance across natural\nlanguage tasks, but their ability to forecast violent conflict remains\nunderexplored. We investigate whether LLMs possess meaningful parametric\nknowledge-encoded in their pretrained weights-to predict conflict escalation\nand fatalities without external data. This is critical for early warning\nsystems, humanitarian planning, and policy-making. We compare this parametric\nknowledge with non-parametric capabilities, where LLMs access structured and\nunstructured context from conflict datasets (e.g., ACLED, GDELT) and recent\nnews reports via Retrieval-Augmented Generation (RAG). Incorporating external\ninformation could enhance model performance by providing up-to-date context\notherwise missing from pretrained weights. Our two-part evaluation framework\nspans 2020-2024 across conflict-prone regions in the Horn of Africa and the\nMiddle East. In the parametric setting, LLMs predict conflict trends and\nfatalities relying only on pretrained knowledge. In the non-parametric setting,\nmodels receive summaries of recent conflict events, indicators, and\ngeopolitical developments. We compare predicted conflict trend labels (e.g.,\nEscalate, Stable Conflict, De-escalate, Peace) and fatalities against\nhistorical data. Our findings highlight the strengths and limitations of LLMs\nfor conflict forecasting and the benefits of augmenting them with structured\nexternal knowledge."}
{"id": "2505.10010", "pdf": "https://arxiv.org/pdf/2505.10010", "abs": "https://arxiv.org/abs/2505.10010", "authors": ["Jing-Cheng Pang", "Kaiyuan Li", "Yidi Wang", "Si-Hang Yang", "Shengyi Jiang", "Yang Yu"], "title": "ImagineBench: Evaluating Reinforcement Learning with Large Language Model Rollouts", "categories": ["cs.LG"], "comment": null, "summary": "A central challenge in reinforcement learning (RL) is its dependence on\nextensive real-world interaction data to learn task-specific policies. While\nrecent work demonstrates that large language models (LLMs) can mitigate this\nlimitation by generating synthetic experience (noted as imaginary rollouts) for\nmastering novel tasks, progress in this emerging field is hindered due to the\nlack of a standard benchmark. To bridge this gap, we introduce ImagineBench,\nthe first comprehensive benchmark for evaluating offline RL algorithms that\nleverage both real rollouts and LLM-imaginary rollouts. The key features of\nImagineBench include: (1) datasets comprising environment-collected and\nLLM-imaginary rollouts; (2) diverse domains of environments covering\nlocomotion, robotic manipulation, and navigation tasks; and (3) natural\nlanguage task instructions with varying complexity levels to facilitate\nlanguage-conditioned policy learning. Through systematic evaluation of\nstate-of-the-art offline RL algorithms, we observe that simply applying\nexisting offline RL algorithms leads to suboptimal performance on unseen tasks,\nachieving 35.44% success rate in hard tasks in contrast to 64.37% of method\ntraining on real rollouts for hard tasks. This result highlights the need for\nalgorithm advancements to better leverage LLM-imaginary rollouts. Additionally,\nwe identify key opportunities for future research: including better utilization\nof imaginary rollouts, fast online adaptation and continual learning, and\nextension to multi-modal tasks. Our code is publicly available at\nhttps://github.com/LAMDA-RL/ImagineBench."}
{"id": "2505.10494", "pdf": "https://arxiv.org/pdf/2505.10494", "abs": "https://arxiv.org/abs/2505.10494", "authors": ["Yutao Mou", "Xiao Deng", "Yuxiao Luo", "Shikun Zhang", "Wei Ye"], "title": "Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective", "categories": ["cs.CL"], "comment": "Accepted by ACL2025 Main Conference", "summary": "Code security and usability are both essential for various coding assistant\napplications driven by large language models (LLMs). Current code security\nbenchmarks focus solely on single evaluation task and paradigm, such as code\ncompletion and generation, lacking comprehensive assessment across dimensions\nlike secure code generation, vulnerability repair and discrimination. In this\npaper, we first propose CoV-Eval, a multi-task benchmark covering various tasks\nsuch as code completion, vulnerability repair, vulnerability detection and\nclassification, for comprehensive evaluation of LLM code security. Besides, we\ndeveloped VC-Judge, an improved judgment model that aligns closely with human\nexperts and can review LLM-generated programs for vulnerabilities in a more\nefficient and reliable way. We conduct a comprehensive evaluation of 20\nproprietary and open-source LLMs. Overall, while most LLMs identify vulnerable\ncodes well, they still tend to generate insecure codes and struggle with\nrecognizing specific vulnerability types and performing repairs. Extensive\nexperiments and qualitative analyses reveal key challenges and optimization\ndirections, offering insights for future research in LLM code security."}
{"id": "2505.10257", "pdf": "https://arxiv.org/pdf/2505.10257", "abs": "https://arxiv.org/abs/2505.10257", "authors": ["Hao Lu", "Jiaqi Tang", "Jiyao Wang", "Yunfan LU", "Xu Cao", "Qingyong Hu", "Yin Wang", "Yuting Zhang", "Tianxin Xie", "Yunpeng Zhang", "Yong Chen", "Jiayu. Gao", "Bin Huang", "Dengbo He", "Shuiguang Deng", "Hao Chen", "Ying-Cong Chen"], "title": "Sage Deer: A Super-Aligned Driving Generalist Is Your Copilot", "categories": ["cs.CV"], "comment": null, "summary": "The intelligent driving cockpit, an important part of intelligent driving,\nneeds to match different users' comfort, interaction, and safety needs. This\npaper aims to build a Super-Aligned and GEneralist DRiving agent, SAGE DeeR.\nSage Deer achieves three highlights: (1) Super alignment: It achieves different\nreactions according to different people's preferences and biases. (2)\nGeneralist: It can understand the multi-view and multi-mode inputs to reason\nthe user's physiological indicators, facial emotions, hand movements, body\nmovements, driving scenarios, and behavioral decisions. (3) Self-Eliciting: It\ncan elicit implicit thought chains in the language space to further increase\ngeneralist and super-aligned abilities. Besides, we collected multiple data\nsets and built a large-scale benchmark. This benchmark measures the deer's\nperceptual decision-making ability and the super alignment's accuracy."}
{"id": "2505.09855", "pdf": "https://arxiv.org/pdf/2505.09855", "abs": "https://arxiv.org/abs/2505.09855", "authors": ["Alexander Y. Ku", "Thomas L. Griffiths", "Stephanie C. Y. Chan"], "title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies."}
{"id": "2505.10037", "pdf": "https://arxiv.org/pdf/2505.10037", "abs": "https://arxiv.org/abs/2505.10037", "authors": ["Takafumi Ito", "Lysenko Artem", "Tatsuhiko Tsunoda"], "title": "Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction", "categories": ["cs.LG", "cs.AI", "cs.ET", "quant-ph"], "comment": "10 pages, 3 figures", "summary": "Quantum-classical Hybrid Machine Learning (QHML) models are recognized for\ntheir robust performance and high generalization ability even for relatively\nsmall datasets. These qualities offer unique advantages for anti-cancer drug\nresponse prediction, where the number of available samples is typically small.\nHowever, such hybrid models appear to be very sensitive to the data encoding\nused at the interface of a neural network and a quantum circuit, with\nsuboptimal choices leading to stability issues. To address this problem, we\npropose a novel strategy that uses a normalization function based on a\nmoderated gradient version of the $\\tanh$. This method transforms the outputs\nof the neural networks without concentrating them at the extreme value ranges.\nOur idea was evaluated on a dataset of gene expression and drug response\nmeasurements for various cancer cell lines, where we compared the prediction\nperformance of a classical deep learning model and several QHML models. These\nresults confirmed that QHML performed better than the classical models when\ndata was optimally normalized. This study opens up new possibilities for\nbiomedical data analysis using quantum computers."}
{"id": "2505.10507", "pdf": "https://arxiv.org/pdf/2505.10507", "abs": "https://arxiv.org/abs/2505.10507", "authors": ["Benedikt Ebing", "Goran Glavaš"], "title": "The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks", "categories": ["cs.CL"], "comment": null, "summary": "Translation-based strategies for cross-lingual transfer XLT such as\ntranslate-train -- training on noisy target language data translated from the\nsource language -- and translate-test -- evaluating on noisy source language\ndata translated from the target language -- are competitive XLT baselines. In\nXLT for token classification tasks, however, these strategies include label\nprojection, the challenging step of mapping the labels from each token in the\noriginal sentence to its counterpart(s) in the translation. Although word\naligners (WAs) are commonly used for label projection, the low-level design\ndecisions for applying them to translation-based XLT have not been\nsystematically investigated. Moreover, recent marker-based methods, which\nproject labeled spans by inserting tags around them before (or after)\ntranslation, claim to outperform WAs in label projection for XLT. In this work,\nwe revisit WAs for label projection, systematically investigating the effects\nof low-level design decisions on token-level XLT: (i) the algorithm for\nprojecting labels between (multi-)token spans, (ii) filtering strategies to\nreduce the number of noisily mapped labels, and (iii) the pre-tokenization of\nthe translated sentences. We find that all of these substantially impact\ntranslation-based XLT performance and show that, with optimized choices, XLT\nwith WA offers performance at least comparable to that of marker-based methods.\nWe then introduce a new projection strategy that ensembles translate-train and\ntranslate-test predictions and demonstrate that it substantially outperforms\nthe marker-based projection. Crucially, we show that our proposed ensembling\nalso reduces sensitivity to low-level WA design choices, resulting in more\nrobust XLT for token classification tasks."}
{"id": "2505.10258", "pdf": "https://arxiv.org/pdf/2505.10258", "abs": "https://arxiv.org/abs/2505.10258", "authors": ["Michael Hubbertz", "Pascal Colling", "Qi Han", "Tobias Meisen"], "title": "Inferring Driving Maps by Deep Learning-based Trail Map Extraction", "categories": ["cs.CV", "cs.RO"], "comment": "This paper was accepted at the CVPR WAD 2025 Workshop", "summary": "High-definition (HD) maps offer extensive and accurate environmental\ninformation about the driving scene, making them a crucial and essential\nelement for planning within autonomous driving systems. To avoid extensive\nefforts from manual labeling, methods for automating the map creation have\nemerged. Recent trends have moved from offline mapping to online mapping,\nensuring availability and actuality of the utilized maps. While the performance\nhas increased in recent years, online mapping still faces challenges regarding\ntemporal consistency, sensor occlusion, runtime, and generalization. We propose\na novel offline mapping approach that integrates trails - informal routes used\nby drivers - into the map creation process. Our method aggregates trail data\nfrom the ego vehicle and other traffic participants to construct a\ncomprehensive global map using transformer-based deep learning models. Unlike\ntraditional offline mapping, our approach enables continuous updates while\nremaining sensor-agnostic, facilitating efficient data transfer. Our method\ndemonstrates superior performance compared to state-of-the-art online mapping\napproaches, achieving improved generalization to previously unseen environments\nand sensor configurations. We validate our approach on two benchmark datasets,\nhighlighting its robustness and applicability in autonomous driving systems."}
{"id": "2505.09861", "pdf": "https://arxiv.org/pdf/2505.09861", "abs": "https://arxiv.org/abs/2505.09861", "authors": ["John Bencina", "Erkut Aykutlug", "Yue Chen", "Zerui Zhang", "Stephanie Sorenson", "Shao Tang", "Changshuai Wei"], "title": "LiDDA: Data Driven Attribution at LinkedIn", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ME"], "comment": null, "summary": "Data Driven Attribution, which assigns conversion credits to marketing\ninteractions based on causal patterns learned from data, is the foundation of\nmodern marketing intelligence and vital to any marketing businesses and\nadvertising platform. In this paper, we introduce a unified transformer-based\nattribution approach that can handle member-level data, aggregate-level data,\nand integration of external macro factors. We detail the large scale\nimplementation of the approach at LinkedIn, showcasing significant impact. We\nalso share learning and insights that are broadly applicable to the marketing\nand ad tech fields."}
{"id": "2505.10039", "pdf": "https://arxiv.org/pdf/2505.10039", "abs": "https://arxiv.org/abs/2505.10039", "authors": ["Hang Chen", "Jiaying Zhu", "Xinyu Yang", "Wenya Wang"], "title": "Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates", "categories": ["cs.LG"], "comment": "10 pages", "summary": "Circuit discovery has gradually become one of the prominent methods for\nmechanistic interpretability, and research on circuit completeness has also\ngarnered increasing attention. Methods of circuit discovery that do not\nguarantee completeness not only result in circuits that are not fixed across\ndifferent runs but also cause key mechanisms to be omitted. The nature of\nincompleteness arises from the presence of OR gates within the circuit, which\nare often only partially detected in standard circuit discovery methods. To\nthis end, we systematically introduce three types of logic gates: AND, OR, and\nADDER gates, and decompose the circuit into combinations of these logical\ngates. Through the concept of these gates, we derive the minimum requirements\nnecessary to achieve faithfulness and completeness. Furthermore, we propose a\nframework that combines noising-based and denoising-based interventions, which\ncan be easily integrated into existing circuit discovery methods without\nsignificantly increasing computational complexity. This framework is capable of\nfully identifying the logic gates and distinguishing them within the circuit.\nIn addition to the extensive experimental validation of the framework's ability\nto restore the faithfulness, completeness, and sparsity of circuits, using this\nframework, we uncover fundamental properties of the three logic gates, such as\ntheir proportions and contributions to the output, and explore how they behave\namong the functionalities of language models."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.10267", "pdf": "https://arxiv.org/pdf/2505.10267", "abs": "https://arxiv.org/abs/2505.10267", "authors": ["Pavel Korotaev", "Petr Surovtsev", "Alexander Kapitanov", "Karina Kvanchiani", "Aleksandr Nagaev"], "title": "HandReader: Advanced Techniques for Efficient Fingerspelling Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "https://github.com/ai-forever/handreader", "summary": "Fingerspelling is a significant component of Sign Language (SL), allowing the\ninterpretation of proper names, characterized by fast hand movements during\nsigning. Although previous works on fingerspelling recognition have focused on\nprocessing the temporal dimension of videos, there remains room for improving\nthe accuracy of these approaches. This paper introduces HandReader, a group of\nthree architectures designed to address the fingerspelling recognition task.\nHandReader$_{RGB}$ employs the novel Temporal Shift-Adaptive Module (TSAM) to\nprocess RGB features from videos of varying lengths while preserving important\nsequential information. HandReader$_{KP}$ is built on the proposed Temporal\nPose Encoder (TPE) operated on keypoints as tensors. Such keypoints composition\nin a batch allows the encoder to pass them through 2D and 3D convolution\nlayers, utilizing temporal and spatial information and accumulating keypoints\ncoordinates. We also introduce HandReader_RGB+KP - architecture with a joint\nencoder to benefit from RGB and keypoint modalities. Each HandReader model\npossesses distinct advantages and achieves state-of-the-art results on the\nChicagoFSWild and ChicagoFSWild+ datasets. Moreover, the models demonstrate\nhigh performance on the first open dataset for Russian fingerspelling, Znaki,\npresented in this paper. The Znaki dataset and HandReader pre-trained models\nare publicly available."}
{"id": "2505.09901", "pdf": "https://arxiv.org/pdf/2505.09901", "abs": "https://arxiv.org/abs/2505.09901", "authors": ["Ziyuan Zhang", "Darcy Wang", "Ningyuan Chen", "Rodrigo Mansur", "Vahid Sarhangian"], "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements."}
{"id": "2505.10040", "pdf": "https://arxiv.org/pdf/2505.10040", "abs": "https://arxiv.org/abs/2505.10040", "authors": ["Lei Song", "Jiaxing Li", "Shihan Guan", "Youyong Kong"], "title": "Instance-Prototype Affinity Learning for Non-Exemplar Continual Graph Learning", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNN) endure catastrophic forgetting, undermining their\ncapacity to preserve previously acquired knowledge amid the assimilation of\nnovel information. Rehearsal-based techniques revisit historical examples,\nadopted as a principal strategy to alleviate this phenomenon. However, memory\nexplosion and privacy infringements impose significant constraints on their\nutility. Non-Exemplar methods circumvent the prior issues through Prototype\nReplay (PR), yet feature drift presents new challenges. In this paper, our\nempirical findings reveal that Prototype Contrastive Learning (PCL) exhibits\nless pronounced drift than conventional PR. Drawing upon PCL, we propose\nInstance-Prototype Affinity Learning (IPAL), a novel paradigm for Non-Exemplar\nContinual Graph Learning (NECGL). Exploiting graph structural information, we\nformulate Topology-Integrated Gaussian Prototypes (TIGP), guiding feature\ndistributions towards high-impact nodes to augment the model's capacity for\nassimilating new knowledge. Instance-Prototype Affinity Distillation (IPAD)\nsafeguards task memory by regularizing discontinuities in class relationships.\nMoreover, we embed a Decision Boundary Perception (DBP) mechanism within PCL,\nfostering greater inter-class discriminability. Evaluations on four node\nclassification benchmark datasets demonstrate that our method outperforms\nexisting state-of-the-art methods, achieving a better trade-off between\nplasticity and stability."}
{"id": "2505.10527", "pdf": "https://arxiv.org/pdf/2505.10527", "abs": "https://arxiv.org/abs/2505.10527", "authors": ["Binghai Wang", "Runji Lin", "Keming Lu", "Le Yu", "Zhenru Zhang", "Fei Huang", "Chujie Zheng", "Kai Dang", "Yang Fan", "Xingzhang Ren", "An Yang", "Binyuan Hui", "Dayiheng Liu", "Tao Gui", "Qi Zhang", "Xuanjing Huang", "Yu-Gang Jiang", "Bowen Yu", "Jingren Zhou", "Junyang Lin"], "title": "WorldPM: Scaling Human Preference Modeling", "categories": ["cs.CL"], "comment": null, "summary": "Motivated by scaling laws in language modeling that demonstrate how test loss\nscales as a power law with model and dataset sizes, we find that similar laws\nexist in preference modeling. We propose World Preference Modeling$ (WorldPM)\nto emphasize this scaling potential, where World Preference embodies a unified\nrepresentation of human preferences. In this paper, we collect preference data\nfrom public forums covering diverse user communities, and conduct extensive\ntraining using 15M-scale data across models ranging from 1.5B to 72B\nparameters. We observe distinct patterns across different evaluation metrics:\n(1) Adversarial metrics (ability to identify deceptive features) consistently\nscale up with increased training data and base model size; (2) Objective\nmetrics (objective knowledge with well-defined answers) show emergent behavior\nin larger language models, highlighting WorldPM's scalability potential; (3)\nSubjective metrics (subjective preferences from a limited number of humans or\nAI) do not demonstrate scaling trends. Further experiments validate the\neffectiveness of WorldPM as a foundation for preference fine-tuning. Through\nevaluations on 7 benchmarks with 20 subtasks, we find that WorldPM broadly\nimproves the generalization performance across human preference datasets of\nvarying sizes (7K, 100K and 800K samples), with performance gains exceeding 5%\non many key subtasks. Integrating WorldPM into our internal RLHF pipeline, we\nobserve significant improvements on both in-house and public evaluation sets,\nwith notable gains of 4% to 8% in our in-house evaluations."}
{"id": "2505.10281", "pdf": "https://arxiv.org/pdf/2505.10281", "abs": "https://arxiv.org/abs/2505.10281", "authors": ["Mengqiu Xu", "Kaixin Chen", "Heng Guo", "Yixiang Huang", "Ming Wu", "Zhenwei Shi", "Chuang Zhang", "Jun Guo"], "title": "MFogHub: Bridging Multi-Regional and Multi-Satellite Data for Global Marine Fog Detection and Forecasting", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning approaches for marine fog detection and forecasting have\noutperformed traditional methods, demonstrating significant scientific and\npractical importance. However, the limited availability of open-source datasets\nremains a major challenge. Existing datasets, often focused on a single region\nor satellite, restrict the ability to evaluate model performance across diverse\nconditions and hinder the exploration of intrinsic marine fog characteristics.\nTo address these limitations, we introduce \\textbf{MFogHub}, the first\nmulti-regional and multi-satellite dataset to integrate annotated marine fog\nobservations from 15 coastal fog-prone regions and six geostationary\nsatellites, comprising over 68,000 high-resolution samples. By encompassing\ndiverse regions and satellite perspectives, MFogHub facilitates rigorous\nevaluation of both detection and forecasting methods under varying conditions.\nExtensive experiments with 16 baseline models demonstrate that MFogHub can\nreveal generalization fluctuations due to regional and satellite discrepancy,\nwhile also serving as a valuable resource for the development of targeted and\nscalable fog prediction techniques. Through MFogHub, we aim to advance both the\npractical monitoring and scientific understanding of marine fog dynamics on a\nglobal scale. The dataset and code are at\n\\href{https://github.com/kaka0910/MFogHub}{https://github.com/kaka0910/MFogHub}."}
{"id": "2505.09907", "pdf": "https://arxiv.org/pdf/2505.09907", "abs": "https://arxiv.org/abs/2505.09907", "authors": ["Linwei Zhang", "LuFeng", "Ruijia Liang"], "title": "Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "With the growing demand for healthy foods, agricultural product price\nforecasting has become increasingly important. Hass avocados, as a high-value\ncrop, exhibit complex price fluctuations influenced by factors such as\nseasonality, region, and weather. Traditional prediction models often struggle\nwith highly nonlinear and dynamic data. To address this, we propose a hybrid\ndeep learning model, TCN-MLP-Attention Architecture, combining Temporal\nConvolutional Networks (TCN) for sequential feature extraction, Multi-Layer\nPerceptrons (MLP) for nonlinear interactions, and an Attention mechanism for\ndynamic feature weighting. The dataset used covers over 50,000 records of Hass\navocado sales across the U.S. from 2015 to 2018, including variables such as\nsales volume, average price, time, region, weather, and variety type, collected\nfrom point-of-sale systems and the Hass Avocado Board. After systematic\npreprocessing, including missing value imputation and feature normalization,\nthe proposed model was trained and evaluated. Experimental results demonstrate\nthat the TCN-MLP-Attention model achieves excellent predictive performance,\nwith an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods.\nThis research provides a scalable and effective approach for time series\nforecasting in agricultural markets and offers valuable insights for\nintelligent supply chain management and price strategy optimization."}
{"id": "2505.10050", "pdf": "https://arxiv.org/pdf/2505.10050", "abs": "https://arxiv.org/abs/2505.10050", "authors": ["Fahad Almalki", "Mehedi Masud"], "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection."}
{"id": "2505.10554", "pdf": "https://arxiv.org/pdf/2505.10554", "abs": "https://arxiv.org/abs/2505.10554", "authors": ["Zhiyuan Hu", "Yibo Wang", "Hanze Dong", "Yuhui Xu", "Amrita Saha", "Caiming Xiong", "Bryan Hooi", "Junnan Li"], "title": "Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large Reasoning Models", "categories": ["cs.CL"], "comment": "In Progress", "summary": "Large reasoning models (LRMs) already possess a latent capacity for long\nchain-of-thought reasoning. Prior work has shown that outcome-based\nreinforcement learning (RL) can incidentally elicit advanced reasoning\nbehaviors such as self-correction, backtracking, and verification phenomena\noften referred to as the model's \"aha moment\". However, the timing and\nconsistency of these emergent behaviors remain unpredictable and\nuncontrollable, limiting the scalability and reliability of LRMs' reasoning\ncapabilities. To address these limitations, we move beyond reliance on prompts\nand coincidental \"aha moments\". Instead, we explicitly align models with three\nmeta-abilities: deduction, induction, and abduction, using automatically\ngenerated, self-verifiable tasks. Our three stage-pipeline individual\nalignment, parameter-space merging, and domain-specific reinforcement learning,\nboosting performance by over 10\\% relative to instruction-tuned baselines.\nFurthermore, domain-specific RL from the aligned checkpoint yields an\nadditional 2\\% average gain in the performance ceiling across math, coding, and\nscience benchmarks, demonstrating that explicit meta-ability alignment offers a\nscalable and dependable foundation for reasoning. Code is available at:\nhttps://github.com/zhiyuanhubj/Meta-Ability-Alignment"}
{"id": "2505.10289", "pdf": "https://arxiv.org/pdf/2505.10289", "abs": "https://arxiv.org/abs/2505.10289", "authors": ["Yue Wang", "Shuai Xu", "Xuelin Zhu", "Yicong Li"], "title": "MSCI: Addressing CLIP's Inherent Limitations for Compositional Zero-Shot Learning", "categories": ["cs.CV"], "comment": "9 pages, 5 figures", "summary": "Compositional Zero-Shot Learning (CZSL) aims to recognize unseen state-object\ncombinations by leveraging known combinations. Existing studies basically rely\non the cross-modal alignment capabilities of CLIP but tend to overlook its\nlimitations in capturing fine-grained local features, which arise from its\narchitectural and training paradigm. To address this issue, we propose a\nMulti-Stage Cross-modal Interaction (MSCI) model that effectively explores and\nutilizes intermediate-layer information from CLIP's visual encoder.\nSpecifically, we design two self-adaptive aggregators to extract local\ninformation from low-level visual features and integrate global information\nfrom high-level visual features, respectively. These key information are\nprogressively incorporated into textual representations through a\nstage-by-stage interaction mechanism, significantly enhancing the model's\nperception capability for fine-grained local visual information. Additionally,\nMSCI dynamically adjusts the attention weights between global and local visual\ninformation based on different combinations, as well as different elements\nwithin the same combination, allowing it to flexibly adapt to diverse\nscenarios. Experiments on three widely used datasets fully validate the\neffectiveness and superiority of the proposed model. Data and code are\navailable at https://github.com/ltpwy/MSCI."}
{"id": "2505.09925", "pdf": "https://arxiv.org/pdf/2505.09925", "abs": "https://arxiv.org/abs/2505.09925", "authors": ["Yutao Yang", "Jie Zhou", "Junsong Li", "Qianjun Pan", "Bihao Zhan", "Qin Chen", "Xipeng Qiu", "Liang He"], "title": "Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces an interactive continual learning paradigm where AI\nmodels dynamically learn new skills from real-time human feedback while\nretaining prior knowledge. This paradigm distinctively addresses two major\nlimitations of traditional continual learning: (1) dynamic model updates using\nstreaming, real-time human-annotated data, rather than static datasets with\nfixed labels, and (2) the assumption of clean labels, by explicitly handling\nthe noisy feedback common in real-world interactions. To tackle these problems,\nwe propose RiCL, a Reinforced interactive Continual Learning framework\nleveraging Large Language Models (LLMs) to learn new skills effectively from\ndynamic feedback. RiCL incorporates three key components: a temporal\nconsistency-aware purifier to automatically discern clean from noisy samples in\ndata streams; an interaction-aware direct preference optimization strategy to\nalign model behavior with human intent by reconciling AI-generated and\nhuman-provided feedback; and a noise-resistant contrastive learning module that\ncaptures robust representations by exploiting inherent data relationships, thus\navoiding reliance on potentially unreliable labels. Extensive experiments on\ntwo benchmark datasets (FewRel and TACRED), contaminated with realistic noise\npatterns, demonstrate that our RiCL approach substantially outperforms existing\ncombinations of state-of-the-art online continual learning and noisy-label\nlearning methods."}
{"id": "2505.10057", "pdf": "https://arxiv.org/pdf/2505.10057", "abs": "https://arxiv.org/abs/2505.10057", "authors": ["Tiancong Cheng", "Ying Zhang", "Yuxuan Liang", "Roger Zimmermann", "Zhiwen Yu", "Bin Guo"], "title": "JointDistill: Adaptive Multi-Task Distillation for Joint Depth Estimation and Scene Segmentation", "categories": ["cs.LG"], "comment": null, "summary": "Depth estimation and scene segmentation are two important tasks in\nintelligent transportation systems. A joint modeling of these two tasks will\nreduce the requirement for both the storage and training efforts. This work\nexplores how the multi-task distillation could be used to improve such unified\nmodeling. While existing solutions transfer multiple teachers' knowledge in a\nstatic way, we propose a self-adaptive distillation method that can dynamically\nadjust the knowledge amount from each teacher according to the student's\ncurrent learning ability. Furthermore, as multiple teachers exist, the\nstudent's gradient update direction in the distillation is more prone to be\nerroneous where knowledge forgetting may occur. To avoid this, we propose a\nknowledge trajectory to record the most essential information that a model has\nlearnt in the past, based on which a trajectory-based distillation loss is\ndesigned to guide the student to follow the learning curve similarly in a\ncost-effective way. We evaluate our method on multiple benchmarking datasets\nincluding Cityscapes and NYU-v2. Compared to the state-of-the-art solutions,\nour method achieves a clearly improvement. The code is provided in the\nsupplementary materials."}
{"id": "2505.09855", "pdf": "https://arxiv.org/pdf/2505.09855", "abs": "https://arxiv.org/abs/2505.09855", "authors": ["Alexander Y. Ku", "Thomas L. Griffiths", "Stephanie C. Y. Chan"], "title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies."}
{"id": "2505.10292", "pdf": "https://arxiv.org/pdf/2505.10292", "abs": "https://arxiv.org/abs/2505.10292", "authors": ["Daniel A. P. Oliveira", "David Martins de Matos"], "title": "StoryReasoning Dataset: Using Chain-of-Thought for Scene Understanding and Grounded Story Generation", "categories": ["cs.CV", "cs.CL", "I.2.10; I.2.7"], "comment": "31 pages, 14 figures", "summary": "Visual storytelling systems struggle to maintain character identity across\nframes and link actions to appropriate subjects, frequently leading to\nreferential hallucinations. These issues can be addressed through grounding of\ncharacters, objects, and other entities on the visual elements. We propose\nStoryReasoning, a dataset containing 4,178 stories derived from 52,016 movie\nimages, with both structured scene analyses and grounded stories. Each story\nmaintains character and object consistency across frames while explicitly\nmodeling multi-frame relationships through structured tabular representations.\nOur approach features cross-frame object re-identification using visual\nsimilarity and face recognition, chain-of-thought reasoning for explicit\nnarrative modeling, and a grounding scheme that links textual elements to\nvisual entities across multiple frames. We establish baseline performance by\nfine-tuning Qwen2.5-VL 7B, creating Qwen Storyteller, which performs end-to-end\nobject detection, re-identification, and landmark detection while maintaining\nconsistent object references throughout the story. Evaluation demonstrates a\nreduction from 4.06 to 3.56 (-12.3%) hallucinations on average per story when\ncompared to a non-fine-tuned model."}
{"id": "2505.09926", "pdf": "https://arxiv.org/pdf/2505.09926", "abs": "https://arxiv.org/abs/2505.09926", "authors": ["Bin-Bin Gao", "Yue Zhu", "Jiangtao Yan", "Yuezhi Cai", "Weixi Zhang", "Meng Wang", "Jun Liu", "Yong Liu", "Lei Wang", "Chengjie Wang"], "title": "AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": "27 pages, 15 figures, 22 tables", "summary": "Universal visual anomaly detection aims to identify anomalies from novel or\nunseen vision domains without additional fine-tuning, which is critical in open\nscenarios. Recent studies have demonstrated that pre-trained vision-language\nmodels like CLIP exhibit strong generalization with just zero or a few normal\nimages. However, existing methods struggle with designing prompt templates,\ncomplex token interactions, or requiring additional fine-tuning, resulting in\nlimited flexibility. In this work, we present a simple yet effective method\ncalled AdaptCLIP based on two key insights. First, adaptive visual and textual\nrepresentations should be learned alternately rather than jointly. Second,\ncomparative learning between query and normal image prompt should incorporate\nboth contextual and aligned residual features, rather than relying solely on\nresidual features. AdaptCLIP treats CLIP models as a foundational service,\nadding only three simple adapters, visual adapter, textual adapter, and\nprompt-query adapter, at its input or output ends. AdaptCLIP supports\nzero-/few-shot generalization across domains and possesses a training-free\nmanner on target domains once trained on a base dataset. AdaptCLIP achieves\nstate-of-the-art performance on 12 anomaly detection benchmarks from industrial\nand medical domains, significantly outperforming existing competitive methods.\nWe will make the code and model of AdaptCLIP available at\nhttps://github.com/gaobb/AdaptCLIP."}
{"id": "2505.10083", "pdf": "https://arxiv.org/pdf/2505.10083", "abs": "https://arxiv.org/abs/2505.10083", "authors": ["Chengsen Wang", "Qi Qi", "Zhongwen Rao", "Lujia Pan", "Jingyu Wang", "Jianxin Liao"], "title": "ChronoSteer: Bridging Large Language Model and Time Series Foundation Model via Synthetic Data", "categories": ["cs.LG"], "comment": null, "summary": "Conventional forecasting methods rely on unimodal time series data, limiting\ntheir ability to exploit rich textual information. Recently, large language\nmodels (LLMs) and time series foundation models (TSFMs) have demonstrated\npowerful capability in textual reasoning and temporal modeling, respectively.\nIntegrating the strengths of both to construct a multimodal model that\nconcurrently leverages both temporal and textual information for future\ninference has emerged as a critical research challenge. To address the scarcity\nof event-series paired data, we propose a decoupled framework: an LLM is\nemployed to transform textual events into revision instructions, which are then\nused to steer the output of TSFM. To implement this framework, we introduce\nChronoSteer, a multimodal TSFM that can be steered through textual revision\ninstructions, effectively bridging LLM and TSFM. Moreover, to mitigate the\nshortage of cross-modal instruction-series paired data, we devise a two-stage\ntraining strategy based on synthetic data. In addition, we also construct a\nhigh-quality multimodal time series forecasting benchmark to address the\ninformation leakage concerns during evaluation. After integrating with an LLM,\nChronoSteer, which is trained exclusively on synthetic data, achieves a 25.7%\nimprovement in prediction accuracy compared to the unimodal backbone and a\n22.5% gain over the previous state-of-the-art multimodal method."}
{"id": "2505.09901", "pdf": "https://arxiv.org/pdf/2505.09901", "abs": "https://arxiv.org/abs/2505.09901", "authors": ["Ziyuan Zhang", "Darcy Wang", "Ningyuan Chen", "Rodrigo Mansur", "Vahid Sarhangian"], "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements."}
{"id": "2505.10294", "pdf": "https://arxiv.org/pdf/2505.10294", "abs": "https://arxiv.org/abs/2505.10294", "authors": ["Guillaume Balezo", "Roger Trullo", "Albert Pla Planas", "Etienne Decenciere", "Thomas Walter"], "title": "MIPHEI-ViT: Multiplex Immunofluorescence Prediction from H&E Images using ViT Foundation Models", "categories": ["cs.CV", "q-bio.TO", "68T07 (Primary), 92C55 (Secondary)", "I.4.9; I.2.10; I.5.4; J.3"], "comment": null, "summary": "Histopathological analysis is a cornerstone of cancer diagnosis, with\nHematoxylin and Eosin (H&E) staining routinely acquired for every patient to\nvisualize cell morphology and tissue architecture. On the other hand, multiplex\nimmunofluorescence (mIF) enables more precise cell type identification via\nproteomic markers, but has yet to achieve widespread clinical adoption due to\ncost and logistical constraints. To bridge this gap, we introduce MIPHEI\n(Multiplex Immunofluorescence Prediction from H&E), a U-Net-inspired\narchitecture that integrates state-of-the-art ViT foundation models as encoders\nto predict mIF signals from H&E images. MIPHEI targets a comprehensive panel of\nmarkers spanning nuclear content, immune lineages (T cells, B cells, myeloid),\nepithelium, stroma, vasculature, and proliferation. We train our model using\nthe publicly available ORION dataset of restained H&E and mIF images from\ncolorectal cancer tissue, and validate it on two independent datasets. MIPHEI\nachieves accurate cell-type classification from H&E alone, with F1 scores of\n0.88 for Pan-CK, 0.57 for CD3e, 0.56 for SMA, 0.36 for CD68, and 0.30 for CD20,\nsubstantially outperforming both a state-of-the-art baseline and a random\nclassifier for most markers. Our results indicate that our model effectively\ncaptures the complex relationships between nuclear morphologies in their tissue\ncontext, as visible in H&E images and molecular markers defining specific cell\ntypes. MIPHEI offers a promising step toward enabling cell-type-aware analysis\nof large-scale H&E datasets, in view of uncovering relationships between\nspatial cellular organization and patient outcomes."}
{"id": "2505.09935", "pdf": "https://arxiv.org/pdf/2505.09935", "abs": "https://arxiv.org/abs/2505.09935", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Quoc Dai Tran"], "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users."}
{"id": "2505.10117", "pdf": "https://arxiv.org/pdf/2505.10117", "abs": "https://arxiv.org/abs/2505.10117", "authors": ["JieHao Wu", "Ziwei Wang", "Junjie Sheng", "Wenhao Li", "Xiangfei Wang", "Jun Luo"], "title": "Learning Virtual Machine Scheduling in Cloud Computing through Language Agents", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "In cloud services, virtual machine (VM) scheduling is a typical Online\nDynamic Multidimensional Bin Packing (ODMBP) problem, characterized by\nlarge-scale complexity and fluctuating demands. Traditional optimization\nmethods struggle to adapt to real-time changes, domain-expert-designed\nheuristic approaches suffer from rigid strategies, and existing learning-based\nmethods often lack generalizability and interpretability. To address these\nlimitations, this paper proposes a hierarchical language agent framework named\nMiCo, which provides a large language model (LLM)-driven heuristic design\nparadigm for solving ODMBP. Specifically, ODMBP is formulated as a Semi-Markov\nDecision Process with Options (SMDP-Option), enabling dynamic scheduling\nthrough a two-stage architecture, i.e., Option Miner and Option Composer.\nOption Miner utilizes LLMs to discover diverse and useful non-context-aware\nstrategies by interacting with constructed environments. Option Composer\nemploys LLMs to discover a composing strategy that integrates the\nnon-context-aware strategies with the contextual ones. Extensive experiments on\nreal-world enterprise datasets demonstrate that MiCo achieves a 96.9\\%\ncompetitive ratio in large-scale scenarios involving more than 10,000 virtual\nmachines. It maintains high performance even under nonstationary request flows\nand diverse configurations, thus validating its effectiveness in complex and\nlarge-scale cloud environments."}
{"id": "2505.09949", "pdf": "https://arxiv.org/pdf/2505.09949", "abs": "https://arxiv.org/abs/2505.09949", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Samgyu Yang", "Abdulrahman Faden"], "title": "Advanced Crash Causation Analysis for Freeway Safety: A Large Language Model Approach to Identifying Key Contributing Factors", "categories": ["cs.LG", "cs.CL", "stat.AP"], "comment": null, "summary": "Understanding the factors contributing to traffic crashes and developing\nstrategies to mitigate their severity is essential. Traditional statistical\nmethods and machine learning models often struggle to capture the complex\ninteractions between various factors and the unique characteristics of each\ncrash. This research leverages large language model (LLM) to analyze freeway\ncrash data and provide crash causation analysis accordingly. By compiling 226\ntraffic safety studies related to freeway crashes, a training dataset\nencompassing environmental, driver, traffic, and geometric design factors was\ncreated. The Llama3 8B model was fine-tuned using QLoRA to enhance its\nunderstanding of freeway crashes and their contributing factors, as covered in\nthese studies. The fine-tuned Llama3 8B model was then used to identify crash\ncausation without pre-labeled data through zero-shot classification, providing\ncomprehensive explanations to ensure that the identified causes were reasonable\nand aligned with existing research. Results demonstrate that LLMs effectively\nidentify primary crash causes such as alcohol-impaired driving, speeding,\naggressive driving, and driver inattention. Incorporating event data, such as\nroad maintenance, offers more profound insights. The model's practical\napplicability and potential to improve traffic safety measures were validated\nby a high level of agreement among researchers in the field of traffic safety,\nas reflected in questionnaire results with 88.89%. This research highlights the\ncomplex nature of traffic crashes and how LLMs can be used for comprehensive\nanalysis of crash causation and other contributing factors. Moreover, it\nprovides valuable insights and potential countermeasures to aid planners and\npolicymakers in developing more effective and efficient traffic safety\npractices."}
{"id": "2505.10351", "pdf": "https://arxiv.org/pdf/2505.10351", "abs": "https://arxiv.org/abs/2505.10351", "authors": ["Jie Zhu", "Jirong Zha", "Ding Li", "Leye Wang"], "title": "A Unified and Scalable Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability", "categories": ["cs.CV"], "comment": "An extension of our ACM CCS2024 conference paper (arXiv:2404.02462).\n  We show the impacts of scaling from both data and model aspects on membership\n  inference for self-supervised visual encoders", "summary": "Self-supervised learning shows promise in harnessing extensive unlabeled\ndata, but it also confronts significant privacy concerns, especially in vision.\nIn this paper, we perform membership inference on visual self-supervised models\nin a more realistic setting: self-supervised training method and details are\nunknown for an adversary when attacking as he usually faces a black-box system\nin practice. In this setting, considering that self-supervised model could be\ntrained by completely different self-supervised paradigms, e.g., masked image\nmodeling and contrastive learning, with complex training details, we propose a\nunified membership inference method called PartCrop. It is motivated by the\nshared part-aware capability among models and stronger part response on the\ntraining data. Specifically, PartCrop crops parts of objects in an image to\nquery responses within the image in representation space. We conduct extensive\nattacks on self-supervised models with different training protocols and\nstructures using three widely used image datasets. The results verify the\neffectiveness and generalization of PartCrop. Moreover, to defend against\nPartCrop, we evaluate two common approaches, i.e., early stop and differential\nprivacy, and propose a tailored method called shrinking crop scale range. The\ndefense experiments indicate that all of them are effective. Finally, besides\nprototype testing on toy visual encoders and small-scale image datasets, we\nquantitatively study the impacts of scaling from both data and model aspects in\na realistic scenario and propose a scalable PartCrop-v2 by introducing two\nstructural improvements to PartCrop. Our code is at\nhttps://github.com/JiePKU/PartCrop."}
{"id": "2505.09945", "pdf": "https://arxiv.org/pdf/2505.09945", "abs": "https://arxiv.org/abs/2505.09945", "authors": ["Deeksha Prahlad", "Chanhee Lee", "Dongha Kim", "Hokeun Kim"], "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)", "summary": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time."}
{"id": "2505.10120", "pdf": "https://arxiv.org/pdf/2505.10120", "abs": "https://arxiv.org/abs/2505.10120", "authors": ["Guillaume Godin"], "title": "All You Need Is Synthetic Task Augmentation", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 3 Figures, 6 tables", "summary": "Injecting rule-based models like Random Forests into differentiable neural\nnetwork frameworks remains an open challenge in machine learning. Recent\nadvancements have demonstrated that pretrained models can generate efficient\nmolecular embeddings. However, these approaches often require extensive\npretraining and additional techniques, such as incorporating posterior\nprobabilities, to boost performance. In our study, we propose a novel strategy\nthat jointly trains a single Graph Transformer neural network on both sparse\nmultitask molecular property experimental targets and synthetic targets derived\nfrom XGBoost models trained on Osmordred molecular descriptors. These synthetic\ntasks serve as independent auxiliary tasks. Our results show consistent and\nsignificant performance improvement across all 19 molecular property prediction\ntasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms\nthe XGBoost single-task learner. This demonstrates that synthetic task\naugmentation is an effective method for enhancing neural model performance in\nmultitask molecular property prediction without the need for feature injection\nor pretraining."}
{"id": "2505.10093", "pdf": "https://arxiv.org/pdf/2505.10093", "abs": "https://arxiv.org/abs/2505.10093", "authors": ["Hsuan-Lei Shao"], "title": "From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI", "categories": ["cs.AI", "cs.CL", "I.2.4; H.3.3; J.5"], "comment": "4 pages, 4 figures", "summary": "Taiwanese China Studies (CS) has developed into a rich, interdisciplinary\nresearch field shaped by the unique geopolitical position and long standing\nacademic engagement with Mainland China. This study responds to the growing\nneed to systematically revisit and reorganize decades of Taiwan based CS\nscholarship by proposing an AI assisted approach that transforms unstructured\nacademic texts into structured, interactive knowledge representations. We apply\ngenerative AI (GAI) techniques and large language models (LLMs) to extract and\nstandardize entity relation triples from 1,367 peer reviewed CS articles\npublished between 1996 and 2019. These triples are then visualized through a\nlightweight D3.js based system, forming the foundation of a domain specific\nknowledge graph and vector database for the field. This infrastructure allows\nusers to explore conceptual nodes and semantic relationships across the corpus,\nrevealing previously uncharted intellectual trajectories, thematic clusters,\nand research gaps. By decomposing textual content into graph structured\nknowledge units, our system enables a paradigm shift from linear text\nconsumption to network based knowledge navigation. In doing so, it enhances\nscholarly access to CS literature while offering a scalable, data driven\nalternative to traditional ontology construction. This work not only\ndemonstrates how generative AI can augment area studies and digital humanities\nbut also highlights its potential to support a reimagined scholarly\ninfrastructure for regional knowledge systems."}
{"id": "2505.10352", "pdf": "https://arxiv.org/pdf/2505.10352", "abs": "https://arxiv.org/abs/2505.10352", "authors": ["Shihao Zou", "Qingfeng Li", "Wei Ji", "Jingjing Li", "Yongkui Yang", "Guoqi Li", "Chao Dong"], "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer"}
{"id": "2505.09952", "pdf": "https://arxiv.org/pdf/2505.09952", "abs": "https://arxiv.org/abs/2505.09952", "authors": ["Tianyu Huai", "Jie Zhou", "Yuxuan Cai", "Qin Chen", "Wen Wu", "Xingjiao Wu", "Xipeng Qiu", "Liang He"], "title": "Task-Core Memory Management and Consolidation for Long-term Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to Neurips2025", "summary": "In this paper, we focus on a long-term continual learning (CL) task, where a\nmodel learns sequentially from a stream of vast tasks over time, acquiring new\nknowledge while retaining previously learned information in a manner akin to\nhuman learning. Unlike traditional CL settings, long-term CL involves handling\na significantly larger number of tasks, which exacerbates the issue of\ncatastrophic forgetting. Our work seeks to address two critical questions: 1)\nHow do existing CL methods perform in the context of long-term CL? and 2) How\ncan we mitigate the catastrophic forgetting that arises from prolonged\nsequential updates? To tackle these challenges, we propose a novel framework\ninspired by human memory mechanisms for long-term continual learning (Long-CL).\nSpecifically, we introduce a task-core memory management strategy to\nefficiently index crucial memories and adaptively update them as learning\nprogresses. Additionally, we develop a long-term memory consolidation mechanism\nthat selectively retains hard and discriminative samples, ensuring robust\nknowledge retention. To facilitate research in this area, we construct and\nrelease two multi-modal and textual benchmarks, MMLongCL-Bench and\nTextLongCL-Bench, providing a valuable resource for evaluating long-term CL\napproaches. Experimental results show that Long-CL outperforms the previous\nstate-of-the-art by 7.4\\% and 6.5\\% AP on the two benchmarks, respectively,\ndemonstrating the effectiveness of our approach."}
{"id": "2505.10125", "pdf": "https://arxiv.org/pdf/2505.10125", "abs": "https://arxiv.org/abs/2505.10125", "authors": ["Wujun Zhou", "Shu Ding", "ZeLin Li", "Wei Wang"], "title": "Enhancing the Performance of Global Model by Improving the Adaptability of Local Models in Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning enables the clients to collaboratively train a global\nmodel, which is aggregated from local models. Due to the heterogeneous data\ndistributions over clients and data privacy in federated learning, it is\ndifficult to train local models to achieve a well-performed global model. In\nthis paper, we introduce the adaptability of local models, i.e., the average\nperformance of local models on data distributions over clients, and enhance the\nperformance of the global model by improving the adaptability of local models.\nSince each client does not know the data distributions over other clients, the\nadaptability of the local model cannot be directly optimized. First, we provide\nthe property of an appropriate local model which has good adaptability on the\ndata distributions over clients. Then, we formalize the property into the local\ntraining objective with a constraint and propose a feasible solution to train\nthe local model. Extensive experiments on federated learning benchmarks\ndemonstrate that our method significantly improves the adaptability of local\nmodels and achieves a well-performed global model that consistently outperforms\nthe baseline methods."}
{"id": "2505.10117", "pdf": "https://arxiv.org/pdf/2505.10117", "abs": "https://arxiv.org/abs/2505.10117", "authors": ["JieHao Wu", "Ziwei Wang", "Junjie Sheng", "Wenhao Li", "Xiangfei Wang", "Jun Luo"], "title": "Learning Virtual Machine Scheduling in Cloud Computing through Language Agents", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "In cloud services, virtual machine (VM) scheduling is a typical Online\nDynamic Multidimensional Bin Packing (ODMBP) problem, characterized by\nlarge-scale complexity and fluctuating demands. Traditional optimization\nmethods struggle to adapt to real-time changes, domain-expert-designed\nheuristic approaches suffer from rigid strategies, and existing learning-based\nmethods often lack generalizability and interpretability. To address these\nlimitations, this paper proposes a hierarchical language agent framework named\nMiCo, which provides a large language model (LLM)-driven heuristic design\nparadigm for solving ODMBP. Specifically, ODMBP is formulated as a Semi-Markov\nDecision Process with Options (SMDP-Option), enabling dynamic scheduling\nthrough a two-stage architecture, i.e., Option Miner and Option Composer.\nOption Miner utilizes LLMs to discover diverse and useful non-context-aware\nstrategies by interacting with constructed environments. Option Composer\nemploys LLMs to discover a composing strategy that integrates the\nnon-context-aware strategies with the contextual ones. Extensive experiments on\nreal-world enterprise datasets demonstrate that MiCo achieves a 96.9\\%\ncompetitive ratio in large-scale scenarios involving more than 10,000 virtual\nmachines. It maintains high performance even under nonstationary request flows\nand diverse configurations, thus validating its effectiveness in complex and\nlarge-scale cloud environments."}
{"id": "2505.10420", "pdf": "https://arxiv.org/pdf/2505.10420", "abs": "https://arxiv.org/abs/2505.10420", "authors": ["Andrei Arhire", "Radu Timofte"], "title": "Learned Lightweight Smartphone ISP with Unpaired Data", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at CVPRW 2025", "summary": "The Image Signal Processor (ISP) is a fundamental component in modern\nsmartphone cameras responsible for conversion of RAW sensor image data to RGB\nimages with a strong focus on perceptual quality. Recent work highlights the\npotential of deep learning approaches and their ability to capture details with\na quality increasingly close to that of professional cameras. A difficult and\ncostly step when developing a learned ISP is the acquisition of pixel-wise\naligned paired data that maps the raw captured by a smartphone camera sensor to\nhigh-quality reference images. In this work, we address this challenge by\nproposing a novel training method for a learnable ISP that eliminates the need\nfor direct correspondences between raw images and ground-truth data with\nmatching content. Our unpaired approach employs a multi-term loss function\nguided by adversarial training with multiple discriminators processing feature\nmaps from pre-trained networks to maintain content structure while learning\ncolor and texture characteristics from the target RGB dataset. Using\nlightweight neural network architectures suitable for mobile devices as\nbackbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm\nUltraISP datasets. Compared to paired training methods, our unpaired learning\nstrategy shows strong potential and achieves high fidelity across multiple\nevaluation metrics. The code and pre-trained models are available at\nhttps://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data ."}
{"id": "2505.09955", "pdf": "https://arxiv.org/pdf/2505.09955", "abs": "https://arxiv.org/abs/2505.09955", "authors": ["Jaeho Kim", "Seulki Lee"], "title": "TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 Accept", "summary": "Unsupervised domain adaptation (UDA) for time series data remains a critical\nchallenge in deep learning, with traditional pseudo-labeling strategies failing\nto capture temporal patterns and channel-wise shifts between domains, producing\nsub-optimal pseudo-labels. As such, we introduce TransPL, a novel approach that\naddresses these limitations by modeling the joint distribution $P(\\mathbf{X},\ny)$ of the source domain through code transition matrices, where the codes are\nderived from vector quantization (VQ) of time series patches. Our method\nconstructs class- and channel-wise code transition matrices from the source\ndomain and employs Bayes' rule for target domain adaptation, generating\npseudo-labels based on channel-wise weighted class-conditional likelihoods.\nTransPL offers three key advantages: explicit modeling of temporal transitions\nand channel-wise shifts between different domains, versatility towards\ndifferent UDA scenarios (e.g., weakly-supervised UDA), and explainable\npseudo-label generation. We validate TransPL's effectiveness through extensive\nanalysis on four time series UDA benchmarks and confirm that it consistently\noutperforms state-of-the-art pseudo-labeling methods by a strong margin (6.1%\naccuracy improvement, 4.9% F1 improvement), while providing interpretable\ninsights into the domain adaptation process through its learned code transition\nmatrices."}
{"id": "2505.10128", "pdf": "https://arxiv.org/pdf/2505.10128", "abs": "https://arxiv.org/abs/2505.10128", "authors": ["Huy Q. Le", "Latif U. Khan", "Choong Seon Hong"], "title": "Robust Federated Learning on Edge Devices with Domain Heterogeneity", "categories": ["cs.LG", "cs.AI"], "comment": "IWCMC 2025", "summary": "Federated Learning (FL) allows collaborative training while ensuring data\nprivacy across distributed edge devices, making it a popular solution for\nprivacy-sensitive applications. However, FL faces significant challenges due to\nstatistical heterogeneity, particularly domain heterogeneity, which impedes the\nglobal mode's convergence. In this study, we introduce a new framework to\naddress this challenge by improving the generalization ability of the FL global\nmodel under domain heterogeneity, using prototype augmentation. Specifically,\nwe introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a\nprototype-based FL framework designed to enhance feature diversity and model\nrobustness. FedAPC leverages prototypes derived from the mean features of\naugmented data to capture richer representations. By aligning local features\nwith global prototypes, we enable the model to learn meaningful semantic\nfeatures while reducing overfitting to any specific domain. Experimental\nresults on the Office-10 and Digits datasets illustrate that our framework\noutperforms SOTA baselines, demonstrating superior performance."}
{"id": "2505.10118", "pdf": "https://arxiv.org/pdf/2505.10118", "abs": "https://arxiv.org/abs/2505.10118", "authors": ["Yangfu Li", "Hongjian Zhan", "Tianyi Chen", "Qi Liu", "Yue Lu"], "title": "Why 1 + 1 < 1 in Visual Token Pruning: Beyond Naive Integration via Multi-Objective Balanced Covering", "categories": ["cs.CV", "cs.CL"], "comment": "31 pages,9 figures,conference", "summary": "Existing visual token pruning methods target prompt alignment and visual\npreservation with static strategies, overlooking the varying relative\nimportance of these objectives across tasks, which leads to inconsistent\nperformance. To address this, we derive the first closed-form error bound for\nvisual token pruning based on the Hausdorff distance, uniformly characterizing\nthe contributions of both objectives. Moreover, leveraging $\\epsilon$-covering\ntheory, we reveal an intrinsic trade-off between these objectives and quantify\ntheir optimal attainment levels under a fixed budget. To practically handle\nthis trade-off, we propose Multi-Objective Balanced Covering (MoB), which\nreformulates visual token pruning as a bi-objective covering problem. In this\nframework, the attainment trade-off reduces to budget allocation via greedy\nradius trading. MoB offers a provable performance bound and linear scalability\nwith respect to the number of input visual tokens, enabling adaptation to\nchallenging pruning scenarios. Extensive experiments show that MoB preserves\n96.4% of performance for LLaVA-1.5-7B using only 11.1% of the original visual\ntokens and accelerates LLaVA-Next-7B by 1.3-1.5$\\times$ with negligible\nperformance loss. Additionally, evaluations on Qwen2-VL and Video-LLaVA confirm\nthat MoB integrates seamlessly into advanced MLLMs and diverse vision-language\ntasks."}
{"id": "2505.10453", "pdf": "https://arxiv.org/pdf/2505.10453", "abs": "https://arxiv.org/abs/2505.10453", "authors": ["Tyler Tran", "Sangeet Khemlani", "J. G. Trafton"], "title": "Vision language models have difficulty recognizing virtual objects", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision language models (VLMs) are AI systems paired with both language and\nvision encoders to process multimodal input. They are capable of performing\ncomplex semantic tasks such as automatic captioning, but it remains an open\nquestion about how well they comprehend the visuospatial properties of scenes\ndepicted in the images they process. We argue that descriptions of virtual\nobjects -- objects that are not visually represented in an image -- can help\ntest scene comprehension in these AI systems. For example, an image that\ndepicts a person standing under a tree can be paired with the following prompt:\nimagine that a kite is stuck in the tree. VLMs that comprehend the scene should\nupdate their representations and reason sensibly about the spatial relations\nbetween all three objects. We describe systematic evaluations of\nstate-of-the-art VLMs and show that their ability to process virtual objects is\ninadequate."}
{"id": "2505.09969", "pdf": "https://arxiv.org/pdf/2505.09969", "abs": "https://arxiv.org/abs/2505.09969", "authors": ["Ali Azimi Lamir", "Shiva Razzagzadeh", "Zeynab Rezaei"], "title": "A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study presents a machine learning-based framework for heart disease\nprediction using the heart-disease dataset, comprising 303 samples with 14\nfeatures. The methodology involves data preprocessing, model training, and\nevaluation using three classifiers: Logistic Regression, K-Nearest Neighbors\n(KNN), and Random Forest. Hyperparameter tuning with GridSearchCV and\nRandomizedSearchCV was employed to enhance model performance. The Random Forest\nclassifier outperformed other models, achieving an accuracy of 91% and an\nF1-score of 0.89. Evaluation metrics, including precision, recall, and\nconfusion matrix, revealed balanced performance across classes. The proposed\nmodel demonstrates strong potential for aiding clinical decision-making by\neffectively predicting heart disease. Limitations such as dataset size and\ngeneralizability underscore the need for future studies using larger and more\ndiverse datasets. This work highlights the utility of machine learning in\nhealthcare, offering insights for further advancements in predictive\ndiagnostics."}
{"id": "2505.10147", "pdf": "https://arxiv.org/pdf/2505.10147", "abs": "https://arxiv.org/abs/2505.10147", "authors": ["Yash", "Nikhil Karamchandani", "Avishek Ghosh"], "title": "Near Optimal Best Arm Identification for Clustered Bandits", "categories": ["cs.LG", "cs.MA"], "comment": "To be published in ICML 2025", "summary": "This work investigates the problem of best arm identification for multi-agent\nmulti-armed bandits. We consider $N$ agents grouped into $M$ clusters, where\neach cluster solves a stochastic bandit problem. The mapping between agents and\nbandits is a priori unknown. Each bandit is associated with $K$ arms, and the\ngoal is to identify the best arm for each agent under a $\\delta$-probably\ncorrect ($\\delta$-PC) framework, while minimizing sample complexity and\ncommunication overhead.\n  We propose two novel algorithms: Clustering then Best Arm Identification\n(Cl-BAI) and Best Arm Identification then Clustering (BAI-Cl). Cl-BAI uses a\ntwo-phase approach that first clusters agents based on the bandit problems they\nare learning, followed by identifying the best arm for each cluster. BAI-Cl\nreverses the sequence by identifying the best arms first and then clustering\nagents accordingly. Both algorithms leverage the successive elimination\nframework to ensure computational efficiency and high accuracy.\n  We establish $\\delta$-PC guarantees for both methods, derive bounds on their\nsample complexity, and provide a lower bound for this problem class. Moreover,\nwhen $M$ is small (a constant), we show that the sample complexity of a variant\nof BAI-Cl is minimax optimal in an order-wise sense. Experiments on synthetic\nand real-world datasets (MovieLens, Yelp) demonstrate the superior performance\nof the proposed algorithms in terms of sample and communication efficiency,\nparticularly in settings where $M \\ll N$."}
{"id": "2505.10222", "pdf": "https://arxiv.org/pdf/2505.10222", "abs": "https://arxiv.org/abs/2505.10222", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "Beiwen Zhang", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "ComplexFormer: Disruptively Advancing Transformer Inference Ability via Head-Specific Complex Vector Attention", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Transformer models rely on self-attention to capture token dependencies but\nface challenges in effectively integrating positional information while\nallowing multi-head attention (MHA) flexibility. Prior methods often model\nsemantic and positional differences disparately or apply uniform positional\nadjustments across heads, potentially limiting representational capacity. This\npaper introduces ComplexFormer, featuring Complex Multi-Head Attention-CMHA.\nCMHA empowers each head to independently model semantic and positional\ndifferences unified within the complex plane, representing interactions as\nrotations and scaling. ComplexFormer incorporates two key improvements: (1) a\nper-head Euler transformation, converting real-valued query/key projections\ninto polar-form complex vectors for head-specific complex subspace operation;\nand (2) a per-head adaptive differential rotation mechanism,\nexp[i(Adapt(ASmn,i) + Delta(Pmn),i)], allowing each head to learn distinct\nstrategies for integrating semantic angle differences (ASmn,i) with relative\npositional encodings (Delta(Pmn),i). Extensive experiments on language\nmodeling, text generation, code generation, and mathematical reasoning show\nComplexFormer achieves superior performance, significantly lower generation\nperplexity , and improved long-context coherence compared to strong baselines\nlike RoPE-Transformers. ComplexFormer demonstrates strong parameter efficiency,\noffering a more expressive, adaptable attention mechanism."}
{"id": "2505.10473", "pdf": "https://arxiv.org/pdf/2505.10473", "abs": "https://arxiv.org/abs/2505.10473", "authors": ["Fengdi Zhang", "Hongkun Cao", "Ruqi Huang"], "title": "Consistent Quantity-Quality Control across Scenes for Deployment-Aware Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "To reduce storage and computational costs, 3D Gaussian splatting (3DGS) seeks\nto minimize the number of Gaussians used while preserving high rendering\nquality, introducing an inherent trade-off between Gaussian quantity and\nrendering quality. Existing methods strive for better quantity-quality\nperformance, but lack the ability for users to intuitively adjust this\ntrade-off to suit practical needs such as model deployment under diverse\nhardware and communication constraints. Here, we present ControlGS, a 3DGS\noptimization method that achieves semantically meaningful and cross-scene\nconsistent quantity-quality control while maintaining strong quantity-quality\nperformance. Through a single training run using a fixed setup and a\nuser-specified hyperparameter reflecting quantity-quality preference, ControlGS\ncan automatically find desirable quantity-quality trade-off points across\ndiverse scenes, from compact objects to large outdoor scenes. It also\noutperforms baselines by achieving higher rendering quality with fewer\nGaussians, and supports a broad adjustment range with stepless control over the\ntrade-off."}
{"id": "2505.10016", "pdf": "https://arxiv.org/pdf/2505.10016", "abs": "https://arxiv.org/abs/2505.10016", "authors": ["Shijie Lyu"], "title": "Application of YOLOv8 in monocular downward multiple Car Target detection", "categories": ["cs.CV", "cs.AI", "I.4.8; I.2.10"], "comment": "Accepted by the 5th International Conference on Signal Processing and\n  Machine Learning (CONF-SPML 2025), to appear in Applied and Computational\n  Engineering", "summary": "Autonomous driving technology is progressively transforming traditional car\ndriving methods, marking a significant milestone in modern transportation.\nObject detection serves as a cornerstone of autonomous systems, playing a vital\nrole in enhancing driving safety, enabling autonomous functionality, improving\ntraffic efficiency, and facilitating effective emergency responses. However,\ncurrent technologies such as radar for environmental perception, cameras for\nroad perception, and vehicle sensor networks face notable challenges, including\nhigh costs, vulnerability to weather and lighting conditions, and limited\nresolution.To address these limitations, this paper presents an improved\nautonomous target detection network based on YOLOv8. By integrating structural\nreparameterization technology, a bidirectional pyramid structure network model,\nand a novel detection pipeline into the YOLOv8 framework, the proposed approach\nachieves highly efficient and precise detection of multi-scale, small, and\nremote objects. Experimental results demonstrate that the enhanced model can\neffectively detect both large and small objects with a detection accuracy of\n65%, showcasing significant advancements over traditional methods.This improved\nmodel holds substantial potential for real-world applications and is\nwell-suited for autonomous driving competitions, such as the Formula Student\nAutonomous China (FSAC), particularly excelling in scenarios involving\nsingle-target and small-object detection."}
{"id": "2505.10167", "pdf": "https://arxiv.org/pdf/2505.10167", "abs": "https://arxiv.org/abs/2505.10167", "authors": ["Saikat Barua", "Mostafizur Rahman", "Shehenaz Khaled", "Md Jafor Sadek", "Rafiul Islam", "Shahnewaz Siddique"], "title": "QuXAI: Explainers for Hybrid Quantum Machine Learning Models", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": "16 pages, 6 figures, 7 equations", "summary": "The emergence of hybrid quantum-classical machine learning (HQML) models\nopens new horizons of computational intelligence but their fundamental\ncomplexity frequently leads to black box behavior that undermines transparency\nand reliability in their application. Although XAI for quantum systems still in\nits infancy, a major research gap is evident in robust global and local\nexplainability approaches that are designed for HQML architectures that employ\nquantized feature encoding followed by classical learning. The gap is the focus\nof this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an\nexplainer for explaining feature importance in these hybrid systems. Our model\nentails the creation of HQML models incorporating quantum feature maps, the use\nof Q-MEDLEY, which combines feature based inferences, preserving the quantum\ntransformation stage and visualizing the resulting attributions. Our result\nshows that Q-MEDLEY delineates influential classical aspects in HQML models, as\nwell as separates their noise, and competes well against established XAI\ntechniques in classical validation settings. Ablation studies more\nsignificantly expose the virtues of the composite structure used in Q-MEDLEY.\nThe implications of this work are critically important, as it provides a route\nto improve the interpretability and reliability of HQML models, thus promoting\ngreater confidence and being able to engage in safer and more responsible use\nof quantum-enhanced AI technology."}
{"id": "2505.10231", "pdf": "https://arxiv.org/pdf/2505.10231", "abs": "https://arxiv.org/abs/2505.10231", "authors": ["Haozhe Luo", "Ziyu Zhou", "Zixin Shu", "Aurélie Pahud de Mortanges", "Robert Berke", "Mauricio Reyes"], "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner."}
{"id": "2505.10481", "pdf": "https://arxiv.org/pdf/2505.10481", "abs": "https://arxiv.org/abs/2505.10481", "authors": ["Ilya Ovodov", "Petr Surovtsev", "Karina Kvanchiani", "Alexander Kapitanov", "Alexander Nagaev"], "title": "Logos as a Well-Tempered Pre-train for Sign Language Recognition", "categories": ["cs.CV"], "comment": null, "summary": "This paper examines two aspects of the isolated sign language recognition\n(ISLR) task. First, despite the availability of a number of datasets, the\namount of data for most individual sign languages is limited. It poses the\nchallenge of cross-language ISLR model training, including transfer learning.\nSecond, similar signs can have different semantic meanings. It leads to\nambiguity in dataset labeling and raises the question of the best policy for\nannotating such signs. To address these issues, this study presents Logos, a\nnovel Russian Sign Language (RSL) dataset, the most extensive ISLR dataset by\nthe number of signers and one of the largest available datasets while also the\nlargest RSL dataset in size and vocabulary. It is shown that a model,\npre-trained on the Logos dataset can be used as a universal encoder for other\nlanguage SLR tasks, including few-shot learning. We explore cross-language\ntransfer learning approaches and find that joint training using multiple\nclassification heads benefits accuracy for the target lowresource datasets the\nmost. The key feature of the Logos dataset is explicitly annotated visually\nsimilar sign groups. We show that explicitly labeling visually similar signs\nimproves trained model quality as a visual encoder for downstream tasks. Based\non the proposed contributions, we outperform current state-of-the-art results\nfor the WLASL dataset and get competitive results for the AUTSL dataset, with a\nsingle stream model processing solely RGB video. The source code, dataset, and\npre-trained models are publicly available."}
{"id": "2505.10027", "pdf": "https://arxiv.org/pdf/2505.10027", "abs": "https://arxiv.org/abs/2505.10027", "authors": ["Shijie Lyu"], "title": "ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by the 4th International Conference on Computing Innovation\n  and Applied Physics (CONF-CIAP 2025), and will be published in EAI Community\n  Research Series-CORE or Theoretical and Natural Science (TNS)", "summary": "With the rapid advancement of remote sensing technology, super-resolution\nimage reconstruction is of great research and practical significance. Existing\ndeep learning methods have made progress but still face limitations in handling\ncomplex scenes and preserving image details. This paper proposes a\nreinforcement learning-based latent diffusion model (LDM) fine-tuning method\nfor remote sensing image super-resolution. The method constructs a\nreinforcement learning environment with states, actions, and rewards,\noptimizing decision objectives through proximal policy optimization (PPO)\nduring the reverse denoising process of the LDM model. Experiments on the\nRESISC45 dataset show significant improvements over the baseline model in PSNR,\nSSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11,\nand LPIPS reducing by 0.06-0.10, particularly in structured and complex natural\nscenes. The results demonstrate the method's effectiveness in enhancing\nsuper-resolution quality and adaptability across scenes."}
{"id": "2505.10172", "pdf": "https://arxiv.org/pdf/2505.10172", "abs": "https://arxiv.org/abs/2505.10172", "authors": ["Zeyan Li", "Libing Chen", "Yin Tang"], "title": "Does Scaling Law Apply in Time Series Forecasting?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Rapid expansion of model size has emerged as a key challenge in time series\nforecasting. From early Transformer with tens of megabytes to recent\narchitectures like TimesNet with thousands of megabytes, performance gains have\noften come at the cost of exponentially increasing parameter counts. But is\nthis scaling truly necessary? To question the applicability of the scaling law\nin time series forecasting, we propose Alinear, an ultra-lightweight\nforecasting model that achieves competitive performance using only k-level\nparameters. We introduce a horizon-aware adaptive decomposition mechanism that\ndynamically rebalances component emphasis across different forecast lengths,\nalongside a progressive frequency attenuation strategy that achieves stable\nprediction in various forecasting horizons without incurring the computational\noverhead of attention mechanisms. Extensive experiments on seven benchmark\ndatasets demonstrate that Alinear consistently outperforms large-scale models\nwhile using less than 1% of their parameters, maintaining strong accuracy\nacross both short and ultra-long forecasting horizons. Moreover, to more fairly\nevaluate model efficiency, we propose a new parameter-aware evaluation metric\nthat highlights the superiority of ALinear under constrained model budgets. Our\nanalysis reveals that the relative importance of trend and seasonal components\nvaries depending on data characteristics rather than following a fixed pattern,\nvalidating the necessity of our adaptive design. This work challenges the\nprevailing belief that larger models are inherently better and suggests a\nparadigm shift toward more efficient time series modeling."}
{"id": "2505.10292", "pdf": "https://arxiv.org/pdf/2505.10292", "abs": "https://arxiv.org/abs/2505.10292", "authors": ["Daniel A. P. Oliveira", "David Martins de Matos"], "title": "StoryReasoning Dataset: Using Chain-of-Thought for Scene Understanding and Grounded Story Generation", "categories": ["cs.CV", "cs.CL", "I.2.10; I.2.7"], "comment": "31 pages, 14 figures", "summary": "Visual storytelling systems struggle to maintain character identity across\nframes and link actions to appropriate subjects, frequently leading to\nreferential hallucinations. These issues can be addressed through grounding of\ncharacters, objects, and other entities on the visual elements. We propose\nStoryReasoning, a dataset containing 4,178 stories derived from 52,016 movie\nimages, with both structured scene analyses and grounded stories. Each story\nmaintains character and object consistency across frames while explicitly\nmodeling multi-frame relationships through structured tabular representations.\nOur approach features cross-frame object re-identification using visual\nsimilarity and face recognition, chain-of-thought reasoning for explicit\nnarrative modeling, and a grounding scheme that links textual elements to\nvisual entities across multiple frames. We establish baseline performance by\nfine-tuning Qwen2.5-VL 7B, creating Qwen Storyteller, which performs end-to-end\nobject detection, re-identification, and landmark detection while maintaining\nconsistent object references throughout the story. Evaluation demonstrates a\nreduction from 4.06 to 3.56 (-12.3%) hallucinations on average per story when\ncompared to a non-fine-tuned model."}
{"id": "2505.10483", "pdf": "https://arxiv.org/pdf/2505.10483", "abs": "https://arxiv.org/abs/2505.10483", "authors": ["Yi Li", "Haonan Wang", "Qixiang Zhang", "Boyu Xiao", "Chenchang Hu", "Hualiang Wang", "Xiaomeng Li"], "title": "UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation", "categories": ["cs.CV", "cs.AI"], "comment": "UniEval is the first evaluation framework designed for unified\n  multimodal models, including a holistic benchmark UniBench and the UniScore\n  metric", "summary": "The emergence of unified multimodal understanding and generation models is\nrapidly attracting attention because of their ability to enhance\ninstruction-following capabilities while minimizing model redundancy. However,\nthere is a lack of a unified evaluation framework for these models, which would\nenable an elegant, simplified, and overall evaluation. Current models conduct\nevaluations on multiple task-specific benchmarks, but there are significant\nlimitations, such as the lack of overall results, errors from extra evaluation\nmodels, reliance on extensive labeled images, benchmarks that lack diversity,\nand metrics with limited capacity for instruction-following evaluation. To\ntackle these challenges, we introduce UniEval, the first evaluation framework\ndesigned for unified multimodal models without extra models, images, or\nannotations. This facilitates a simplified and unified evaluation process. The\nUniEval framework contains a holistic benchmark, UniBench (supports both\nunified and visual generation models), along with the corresponding UniScore\nmetric. UniBench includes 81 fine-grained tags contributing to high diversity.\nExperimental results indicate that UniBench is more challenging than existing\nbenchmarks, and UniScore aligns closely with human evaluations, surpassing\ncurrent metrics. Moreover, we extensively evaluated SoTA unified and visual\ngeneration models, uncovering new insights into Univeral's unique values."}
{"id": "2505.10037", "pdf": "https://arxiv.org/pdf/2505.10037", "abs": "https://arxiv.org/abs/2505.10037", "authors": ["Takafumi Ito", "Lysenko Artem", "Tatsuhiko Tsunoda"], "title": "Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction", "categories": ["cs.LG", "cs.AI", "cs.ET", "quant-ph"], "comment": "10 pages, 3 figures", "summary": "Quantum-classical Hybrid Machine Learning (QHML) models are recognized for\ntheir robust performance and high generalization ability even for relatively\nsmall datasets. These qualities offer unique advantages for anti-cancer drug\nresponse prediction, where the number of available samples is typically small.\nHowever, such hybrid models appear to be very sensitive to the data encoding\nused at the interface of a neural network and a quantum circuit, with\nsuboptimal choices leading to stability issues. To address this problem, we\npropose a novel strategy that uses a normalization function based on a\nmoderated gradient version of the $\\tanh$. This method transforms the outputs\nof the neural networks without concentrating them at the extreme value ranges.\nOur idea was evaluated on a dataset of gene expression and drug response\nmeasurements for various cancer cell lines, where we compared the prediction\nperformance of a classical deep learning model and several QHML models. These\nresults confirmed that QHML performed better than the classical models when\ndata was optimally normalized. This study opens up new possibilities for\nbiomedical data analysis using quantum computers."}
{"id": "2505.10192", "pdf": "https://arxiv.org/pdf/2505.10192", "abs": "https://arxiv.org/abs/2505.10192", "authors": ["Prashant P. Shinde", "Priyadarshini P. Pai", "Shashishekar P. Adiga", "K. Subramanya Mayya", "Yongbeom Seo", "Myungsoo Hwang", "Heeyoung Go", "Changmin Park"], "title": "Defect Detection in Photolithographic Patterns Using Deep Learning Models Trained on Synthetic Data", "categories": ["cs.LG"], "comment": null, "summary": "In the photolithographic process vital to semiconductor manufacturing,\nvarious types of defects appear during EUV pattering. Due to ever-shrinking\npattern size, these defects are extremely small and cause false or missed\ndetection during inspection. Specifically, the lack of defect-annotated quality\ndata with good representation of smaller defects has prohibited deployment of\ndeep learning based defect detection models in fabrication lines. To resolve\nthe problem of data unavailability, we artificially generate scanning electron\nmicroscopy (SEM) images of line patterns with known distribution of defects and\nautonomously annotate them. We then employ state-of-the-art object detection\nmodels to investigate defect detection performance as a function of defect\nsize, much smaller than the pitch width. We find that the real-time object\ndetector YOLOv8 has the best mean average precision of 96% as compared to\nEfficientNet, 83%, and SSD, 77%, with the ability to detect smaller defects. We\nreport the smallest defect size that can be detected reliably. When tested on\nreal SEM data, the YOLOv8 model correctly detected 84.6% of Bridge defects and\n78.3% of Break defects across all relevant instances. These promising results\nsuggest that synthetic data can be used as an alternative to real-world data in\norder to develop robust machine-learning models."}
{"id": "2505.10465", "pdf": "https://arxiv.org/pdf/2505.10465", "abs": "https://arxiv.org/abs/2505.10465", "authors": ["Yizhou liu", "Ziming Liu", "Jeff Gore"], "title": "Superposition Yields Robust Neural Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages, 23 figures", "summary": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters."}
{"id": "2505.10496", "pdf": "https://arxiv.org/pdf/2505.10496", "abs": "https://arxiv.org/abs/2505.10496", "authors": ["Raman Dutt", "Pedro Sanchez", "Yongchen Yao", "Steven McDonagh", "Sotirios A. Tsaftaris", "Timothy Hospedales"], "title": "CheXGenBench: A Unified Benchmark For Fidelity, Privacy and Utility of Synthetic Chest Radiographs", "categories": ["cs.CV"], "comment": null, "summary": "We introduce CheXGenBench, a rigorous and multifaceted evaluation framework\nfor synthetic chest radiograph generation that simultaneously assesses\nfidelity, privacy risks, and clinical utility across state-of-the-art\ntext-to-image generative models. Despite rapid advancements in generative AI\nfor real-world imagery, medical domain evaluations have been hindered by\nmethodological inconsistencies, outdated architectural comparisons, and\ndisconnected assessment criteria that rarely address the practical clinical\nvalue of synthetic samples. CheXGenBench overcomes these limitations through\nstandardised data partitioning and a unified evaluation protocol comprising\nover 20 quantitative metrics that systematically analyse generation quality,\npotential privacy vulnerabilities, and downstream clinical applicability across\n11 leading text-to-image architectures. Our results reveal critical\ninefficiencies in the existing evaluation protocols, particularly in assessing\ngenerative fidelity, leading to inconsistent and uninformative comparisons. Our\nframework establishes a standardised benchmark for the medical AI community,\nenabling objective and reproducible comparisons while facilitating seamless\nintegration of both existing and future generative models. Additionally, we\nrelease a high-quality, synthetic dataset, SynthCheX-75K, comprising 75K\nradiographs generated by the top-performing model (Sana 0.6B) in our benchmark\nto support further research in this critical domain. Through CheXGenBench, we\nestablish a new state-of-the-art and release our framework, models, and\nSynthCheX-75K dataset at https://raman1121.github.io/CheXGenBench/"}
{"id": "2505.10050", "pdf": "https://arxiv.org/pdf/2505.10050", "abs": "https://arxiv.org/abs/2505.10050", "authors": ["Fahad Almalki", "Mehedi Masud"], "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection."}
{"id": "2505.10198", "pdf": "https://arxiv.org/pdf/2505.10198", "abs": "https://arxiv.org/abs/2505.10198", "authors": ["Mariano Ferrero", "José Omar Chelotti", "Luciano Sebastián Martinez-Rau", "Leandro Vignolo", "Martín Pires", "Julio Ricardo Galli", "Leonardo Luis Giovanini", "Hugo Leonardo Rufiner"], "title": "A multi-head deep fusion model for recognition of cattle foraging events using sound and movement signals", "categories": ["cs.LG"], "comment": "Preprint submitted to Engineering Applications of Artificial\n  Intelligence", "summary": "Monitoring feeding behaviour is a relevant task for efficient herd management\nand the effective use of available resources in grazing cattle. The ability to\nautomatically recognise animals' feeding activities through the identification\nof specific jaw movements allows for the improvement of diet formulation, as\nwell as early detection of metabolic problems and symptoms of animal\ndiscomfort, among other benefits. The use of sensors to obtain signals for such\nmonitoring has become popular in the last two decades. The most frequently\nemployed sensors include accelerometers, microphones, and cameras, each with\nits own set of advantages and drawbacks. An unexplored aspect is the\nsimultaneous use of multiple sensors with the aim of combining signals in order\nto enhance the precision of the estimations. In this direction, this work\nintroduces a deep neural network based on the fusion of acoustic and inertial\nsignals, composed of convolutional, recurrent, and dense layers. The main\nadvantage of this model is the combination of signals through the automatic\nextraction of features independently from each of them. The model has emerged\nfrom an exploration and comparison of different neural network architectures\nproposed in this work, which carry out information fusion at different levels.\nFeature-level fusion has outperformed data and decision-level fusion by at\nleast a 0.14 based on the F1-score metric. Moreover, a comparison with\nstate-of-the-art machine learning methods is presented, including traditional\nand deep learning approaches. The proposed model yielded an F1-score value of\n0.802, representing a 14% increase compared to previous methods. Finally,\nresults from an ablation study and post-training quantization evaluation are\nalso reported."}
{"id": "2505.10475", "pdf": "https://arxiv.org/pdf/2505.10475", "abs": "https://arxiv.org/abs/2505.10475", "authors": ["Mouxiang Chen", "Binyuan Hui", "Zeyu Cui", "Jiaxi Yang", "Dayiheng Liu", "Jianling Sun", "Junyang Lin", "Zhongxin Liu"], "title": "Parallel Scaling Law for Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "It is commonly believed that scaling language models should commit a\nsignificant space or time cost, by increasing the parameters (parameter\nscaling) or output tokens (inference-time scaling). We introduce the third and\nmore inference-efficient scaling paradigm: increasing the model's parallel\ncomputation during both training and inference time. We apply $P$ diverse and\nlearnable transformations to the input, execute forward passes of the model in\nparallel, and dynamically aggregate the $P$ outputs. This method, namely\nparallel scaling (ParScale), scales parallel computation by reusing existing\nparameters and can be applied to any model structure, optimization procedure,\ndata, or task. We theoretically propose a new scaling law and validate it\nthrough large-scale pre-training, which shows that a model with $P$ parallel\nstreams is similar to scaling the parameters by $O(\\log P)$ while showing\nsuperior inference efficiency. For example, ParScale can use up to 22$\\times$\nless memory increase and 6$\\times$ less latency increase compared to parameter\nscaling that achieves the same performance improvement. It can also recycle an\noff-the-shelf pre-trained model into a parallelly scaled one by post-training\non a small amount of tokens, further reducing the training budget. The new\nscaling law we discovered potentially facilitates the deployment of more\npowerful models in low-resource scenarios, and provides an alternative\nperspective for the role of computation in machine learning."}
{"id": "2505.10497", "pdf": "https://arxiv.org/pdf/2505.10497", "abs": "https://arxiv.org/abs/2505.10497", "authors": ["Iurii Medvedev", "Nuno Goncalves"], "title": "MorphGuard: Morph Specific Margin Loss for Enhancing Robustness to Face Morphing Attacks", "categories": ["cs.CV"], "comment": null, "summary": "Face recognition has evolved significantly with the advancement of deep\nlearning techniques, enabling its widespread adoption in various applications\nrequiring secure authentication. However, this progress has also increased its\nexposure to presentation attacks, including face morphing, which poses a\nserious security threat by allowing one identity to impersonate another.\nTherefore, modern face recognition systems must be robust against such attacks.\n  In this work, we propose a novel approach for training deep networks for face\nrecognition with enhanced robustness to face morphing attacks. Our method\nmodifies the classification task by introducing a dual-branch classification\nstrategy that effectively handles the ambiguity in the labeling of face morphs.\nThis adaptation allows the model to incorporate morph images into the training\nprocess, improving its ability to distinguish them from bona fide samples.\n  Our strategy has been validated on public benchmarks, demonstrating its\neffectiveness in enhancing robustness against face morphing attacks.\nFurthermore, our approach is universally applicable and can be integrated into\nexisting face recognition training pipelines to improve classification-based\nrecognition methods."}
{"id": "2505.10055", "pdf": "https://arxiv.org/pdf/2505.10055", "abs": "https://arxiv.org/abs/2505.10055", "authors": ["Ijazul Haq", "Yingjie Zhang", "Irfan Ali Khan"], "title": "PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper evaluates the performance of Large Multimodal Models (LMMs) on\nOptical Character Recognition (OCR) in the low-resource Pashto language.\nNatural Language Processing (NLP) in Pashto faces several challenges due to the\ncursive nature of its script and a scarcity of structured datasets. To address\nthis, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one\nmillion images annotated with bounding boxes at word, line, and document\nlevels, suitable for training and evaluating models based on different\narchitectures, including Convolutional Neural Networks (CNNs) and Transformers.\nPsOCR covers variations across 1,000 unique font families, colors, image sizes,\nand layouts. A benchmark subset of 10K images was selected to evaluate the\nperformance of several LMMs, including seven open-source models: DeepSeek's\nJanus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four\nclosed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results\ndemonstrate that Gemini achieves the best performance among all models, whereas\namong open-source models, Qwen-7B stands out. This work provides an insightful\nassessment of the capabilities and limitations of current LMMs for OCR tasks in\nPashto and establishes a foundation for further research not only in Pashto OCR\nbut also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is\navailable at https://github.com/zirak-ai/PashtoOCR."}
{"id": "2505.10213", "pdf": "https://arxiv.org/pdf/2505.10213", "abs": "https://arxiv.org/abs/2505.10213", "authors": ["Mohammadmahdi Ghasemloo", "Alireza Moradi"], "title": "Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting", "categories": ["cs.LG", "stat.AP"], "comment": null, "summary": "With the widespread adoption of Large Language Models (LLMs), there is a\ngrowing need to establish best practices for leveraging their capabilities\nbeyond traditional natural language tasks. In this paper, a novel cross-domain\nknowledge transfer framework is proposed to enhance the performance of LLMs in\ntime series forecasting -- a task of increasing relevance in fields such as\nenergy systems, finance, and healthcare. The approach systematically infuses\nLLMs with structured temporal information to improve their forecasting\naccuracy. This study evaluates the proposed method on a real-world time series\ndataset and compares it to a naive baseline where the LLM receives no auxiliary\ninformation. Results show that knowledge-informed forecasting significantly\noutperforms the uninformed baseline in terms of predictive accuracy and\ngeneralization. These findings highlight the potential of knowledge transfer\nstrategies to bridge the gap between LLMs and domain-specific forecasting\ntasks."}
{"id": "2505.10495", "pdf": "https://arxiv.org/pdf/2505.10495", "abs": "https://arxiv.org/abs/2505.10495", "authors": ["Vibha Belavadi", "Tushar Vatsa", "Dewang Sultania", "Suhas Suresha", "Ishita Verma", "Cheng Chen", "Tracy Holloway King", "Michael Friedrich"], "title": "RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs", "categories": ["cs.LG", "cs.CL"], "comment": "Proceedings of the 4th International Workshop on Knowledge-Augmented\n  Methods for Natural Language Processing", "summary": "This paper addresses fine-tuning Large Language Models (LLMs) for function\ncalling tasks when real user interaction data is unavailable. In digital\ncontent creation tools, where users express their needs through natural\nlanguage queries that must be mapped to API calls, the lack of real-world\ntask-specific data and privacy constraints for training on it necessitate\nsynthetic data generation. Existing approaches to synthetic data generation\nfall short in diversity and complexity, failing to replicate real-world data\ndistributions and leading to suboptimal performance after LLM fine-tuning. We\npresent a novel router-based architecture that leverages domain resources like\ncontent metadata and structured knowledge graphs, along with text-to-text and\nvision-to-text language models to generate high-quality synthetic training\ndata. Our architecture's flexible routing mechanism enables synthetic data\ngeneration that matches observed real-world distributions, addressing a\nfundamental limitation of traditional approaches. Evaluation on a comprehensive\nset of real user queries demonstrates significant improvements in both function\nclassification accuracy and API parameter selection. Models fine-tuned with our\nsynthetic data consistently outperform traditional approaches, establishing new\nbenchmarks for function calling tasks."}
{"id": "2505.10533", "pdf": "https://arxiv.org/pdf/2505.10533", "abs": "https://arxiv.org/abs/2505.10533", "authors": ["Aaryan Sharma", "Shivansh Gupta", "Samar Agarwal", "Vishak Prasad C.", "Ganesh Ramakrishnan"], "title": "Enhancing Multi-Image Question Answering via Submodular Subset Selection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Large multimodal models (LMMs) have achieved high performance in\nvision-language tasks involving single image but they struggle when presented\nwith a collection of multiple images (Multiple Image Question Answering\nscenario). These tasks, which involve reasoning over large number of images,\npresent issues in scalability (with increasing number of images) and retrieval\nperformance. In this work, we propose an enhancement for retriever framework\nintroduced in MIRAGE model using submodular subset selection techniques. Our\nmethod leverages query-aware submodular functions, such as GraphCut, to\npre-select a subset of semantically relevant images before main retrieval\ncomponent. We demonstrate that using anchor-based queries and augmenting the\ndata improves submodular-retriever pipeline effectiveness, particularly in\nlarge haystack sizes."}
{"id": "2505.10066", "pdf": "https://arxiv.org/pdf/2505.10066", "abs": "https://arxiv.org/abs/2505.10066", "authors": ["Michael Fire", "Yitzhak Elbazis", "Adi Wasenstein", "Lior Rokach"], "title": "Dark LLMs: The Growing Threat of Unaligned AI Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50, 68T05, 68P25", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated."}
{"id": "2505.10222", "pdf": "https://arxiv.org/pdf/2505.10222", "abs": "https://arxiv.org/abs/2505.10222", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "Beiwen Zhang", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "ComplexFormer: Disruptively Advancing Transformer Inference Ability via Head-Specific Complex Vector Attention", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Transformer models rely on self-attention to capture token dependencies but\nface challenges in effectively integrating positional information while\nallowing multi-head attention (MHA) flexibility. Prior methods often model\nsemantic and positional differences disparately or apply uniform positional\nadjustments across heads, potentially limiting representational capacity. This\npaper introduces ComplexFormer, featuring Complex Multi-Head Attention-CMHA.\nCMHA empowers each head to independently model semantic and positional\ndifferences unified within the complex plane, representing interactions as\nrotations and scaling. ComplexFormer incorporates two key improvements: (1) a\nper-head Euler transformation, converting real-valued query/key projections\ninto polar-form complex vectors for head-specific complex subspace operation;\nand (2) a per-head adaptive differential rotation mechanism,\nexp[i(Adapt(ASmn,i) + Delta(Pmn),i)], allowing each head to learn distinct\nstrategies for integrating semantic angle differences (ASmn,i) with relative\npositional encodings (Delta(Pmn),i). Extensive experiments on language\nmodeling, text generation, code generation, and mathematical reasoning show\nComplexFormer achieves superior performance, significantly lower generation\nperplexity , and improved long-context coherence compared to strong baselines\nlike RoPE-Transformers. ComplexFormer demonstrates strong parameter efficiency,\noffering a more expressive, adaptable attention mechanism."}
{"id": "2505.10526", "pdf": "https://arxiv.org/pdf/2505.10526", "abs": "https://arxiv.org/abs/2505.10526", "authors": ["Mugilan Ganesan", "Shane Segal", "Ankur Aggarwal", "Nish Sinnadurai", "Sean Lie", "Vithursan Thangarasa"], "title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Main paper: 11 pp., 4 figs., 3 tabs.; Supplementary: 2 pp", "summary": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs."}
{"id": "2505.10541", "pdf": "https://arxiv.org/pdf/2505.10541", "abs": "https://arxiv.org/abs/2505.10541", "authors": ["Pengfei Wang", "Guohai Xu", "Weinong Wang", "Junjie Yang", "Jie Lou", "Yunhua Xue"], "title": "Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements have enhanced the capability of Multimodal Large Language\nModels (MLLMs) to comprehend multi-image information. However, existing\nbenchmarks primarily evaluate answer correctness, overlooking whether models\ngenuinely comprehend the visual input. To address this, we define implicit\nvisual misunderstanding (IVM), where MLLMs provide correct answers without\nfully comprehending the visual input. Through our analysis, we decouple the\nvisual and textual modalities within the causal attention module, revealing\nthat attention distribution increasingly converges on the image associated with\nthe correct answer as the network layers deepen. This insight leads to the\nintroduction of a scale-agnostic metric, \\textit{attention accuracy}, and a\nnovel benchmark for quantifying IVMs. Attention accuracy directly evaluates the\nmodel's visual understanding via internal mechanisms, remaining robust to\npositional biases for more reliable assessments. Furthermore, we extend our\napproach to finer granularities and demonstrate its effectiveness in unimodal\nscenarios, underscoring its versatility and generalizability."}
{"id": "2505.10120", "pdf": "https://arxiv.org/pdf/2505.10120", "abs": "https://arxiv.org/abs/2505.10120", "authors": ["Guillaume Godin"], "title": "All You Need Is Synthetic Task Augmentation", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 3 Figures, 6 tables", "summary": "Injecting rule-based models like Random Forests into differentiable neural\nnetwork frameworks remains an open challenge in machine learning. Recent\nadvancements have demonstrated that pretrained models can generate efficient\nmolecular embeddings. However, these approaches often require extensive\npretraining and additional techniques, such as incorporating posterior\nprobabilities, to boost performance. In our study, we propose a novel strategy\nthat jointly trains a single Graph Transformer neural network on both sparse\nmultitask molecular property experimental targets and synthetic targets derived\nfrom XGBoost models trained on Osmordred molecular descriptors. These synthetic\ntasks serve as independent auxiliary tasks. Our results show consistent and\nsignificant performance improvement across all 19 molecular property prediction\ntasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms\nthe XGBoost single-task learner. This demonstrates that synthetic task\naugmentation is an effective method for enhancing neural model performance in\nmultitask molecular property prediction without the need for feature injection\nor pretraining."}
{"id": "2505.10259", "pdf": "https://arxiv.org/pdf/2505.10259", "abs": "https://arxiv.org/abs/2505.10259", "authors": ["Xiangwen Zhuge", "Xu Shen", "Zeyu Wang", "Fan Dang", "Xuan Ding", "Danyang Li", "Yahui Han", "Tianxiang Hao", "Zheng Yang"], "title": "SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices", "categories": ["cs.LG"], "comment": null, "summary": "Efficient LLM inference on resource-constrained devices presents significant\nchallenges in compute and memory utilization. Due to limited GPU memory,\nexisting systems offload model weights to CPU memory, incurring substantial I/O\noverhead between the CPU and GPU. This leads to two major inefficiencies: (1)\nGPU cores are underutilized, often remaining idle while waiting for data to be\nloaded; and (2) GPU memory has low impact on performance, as reducing its\ncapacity has minimal effect on overall throughput.In this paper, we propose\nSpecOffload, a high-throughput inference engine that embeds speculative\ndecoding into offloading. Our key idea is to unlock latent GPU resources for\nstoring and executing a draft model used for speculative decoding, thus\naccelerating inference at near-zero additional cost. To support this, we\ncarefully orchestrate the interleaved execution of target and draft models in\nspeculative decoding within the offloading pipeline, and propose a planner to\nmanage tensor placement and select optimal parameters. Compared to the best\nbaseline, SpecOffload improves GPU core utilization by 4.49x and boosts\ninference throughput by 2.54x. Our code is available at\nhttps://github.com/MobiSense/SpecOffload ."}
{"id": "2505.10543", "pdf": "https://arxiv.org/pdf/2505.10543", "abs": "https://arxiv.org/abs/2505.10543", "authors": ["Annie Wong", "Thomas Bäck", "Aske Plaat", "Niki van Stein", "Anna V. Kononova"], "title": "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While large language models demonstrate impressive performance on static\nbenchmarks, the true potential of large language models as self-learning and\nreasoning agents in dynamic environments remains unclear. This study\nsystematically evaluates the efficacy of self-reflection, heuristic mutation,\nand planning as prompting techniques to test the adaptive capabilities of\nagents. We conduct experiments with various open-source language models in\ndynamic environments and find that larger models generally outperform smaller\nones, but that strategic prompting can close this performance gap. Second, a\ntoo-long prompt can negatively impact smaller models on basic reactive tasks,\nwhile larger models show more robust behaviour. Third, advanced prompting\ntechniques primarily benefit smaller models on complex games, but offer less\nimprovement for already high-performing large language models. Yet, we find\nthat advanced reasoning methods yield highly variable outcomes: while capable\nof significantly improving performance when reasoning and decision-making\nalign, they also introduce instability and can lead to big performance drops.\nCompared to human performance, our findings reveal little evidence of true\nemergent reasoning. Instead, large language model performance exhibits\npersistent limitations in crucial areas such as planning, reasoning, and\nspatial coordination, suggesting that current-generation large language models\nstill suffer fundamental shortcomings that may not be fully overcome through\nself-reflective prompting alone. Reasoning is a multi-faceted task, and while\nreasoning methods like Chain of thought improves multi-step reasoning on math\nword problems, our findings using dynamic benchmarks highlight important\nshortcomings in general reasoning capabilities, indicating a need to move\nbeyond static benchmarks to capture the complexity of reasoning."}
{"id": "2505.10551", "pdf": "https://arxiv.org/pdf/2505.10551", "abs": "https://arxiv.org/abs/2505.10551", "authors": ["Yiwen Liu", "Jessica Bader", "Jae Myung Kim"], "title": "Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data", "categories": ["cs.CV", "cs.AI"], "comment": "CVPRW 2025", "summary": "With the development of photorealistic diffusion models, models trained in\npart or fully on synthetic data achieve progressively better results. However,\ndiffusion models still routinely generate images that would not exist in\nreality, such as a dog floating above the ground or with unrealistic texture\nartifacts. We define the concept of feasibility as whether attributes in a\nsynthetic image could realistically exist in the real-world domain; synthetic\nimages containing attributes that violate this criterion are considered\ninfeasible. Intuitively, infeasible images are typically considered\nout-of-distribution; thus, training on such images is expected to hinder a\nmodel's ability to generalize to real-world data, and they should therefore be\nexcluded from the training set whenever possible. However, does feasibility\nreally matter? In this paper, we investigate whether enforcing feasibility is\nnecessary when generating synthetic training data for CLIP-based classifiers,\nfocusing on three target attributes: background, color, and texture. We\nintroduce VariReal, a pipeline that minimally edits a given source image to\ninclude feasible or infeasible attributes given by the textual prompt generated\nby a large language model. Our experiments show that feasibility minimally\naffects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference\nin top-1 accuracy across three fine-grained datasets. Also, the attribute\nmatters on whether the feasible/infeasible images adversarially influence the\nclassification performance. Finally, mixing feasible and infeasible images in\ntraining datasets does not significantly impact performance compared to using\npurely feasible or infeasible datasets."}
{"id": "2505.10128", "pdf": "https://arxiv.org/pdf/2505.10128", "abs": "https://arxiv.org/abs/2505.10128", "authors": ["Huy Q. Le", "Latif U. Khan", "Choong Seon Hong"], "title": "Robust Federated Learning on Edge Devices with Domain Heterogeneity", "categories": ["cs.LG", "cs.AI"], "comment": "IWCMC 2025", "summary": "Federated Learning (FL) allows collaborative training while ensuring data\nprivacy across distributed edge devices, making it a popular solution for\nprivacy-sensitive applications. However, FL faces significant challenges due to\nstatistical heterogeneity, particularly domain heterogeneity, which impedes the\nglobal mode's convergence. In this study, we introduce a new framework to\naddress this challenge by improving the generalization ability of the FL global\nmodel under domain heterogeneity, using prototype augmentation. Specifically,\nwe introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a\nprototype-based FL framework designed to enhance feature diversity and model\nrobustness. FedAPC leverages prototypes derived from the mean features of\naugmented data to capture richer representations. By aligning local features\nwith global prototypes, we enable the model to learn meaningful semantic\nfeatures while reducing overfitting to any specific domain. Experimental\nresults on the Office-10 and Digits datasets illustrate that our framework\noutperforms SOTA baselines, demonstrating superior performance."}
{"id": "2505.10262", "pdf": "https://arxiv.org/pdf/2505.10262", "abs": "https://arxiv.org/abs/2505.10262", "authors": ["Jiaju Qi", "Lei Lei", "Thorsteinn Jonsson", "Lajos Hanzo"], "title": "Electric Bus Charging Schedules Relying on Real Data-Driven Targets Based on Hierarchical Deep Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "The charging scheduling problem of Electric Buses (EBs) is investigated based\non Deep Reinforcement Learning (DRL). A Markov Decision Process (MDP) is\nconceived, where the time horizon includes multiple charging and operating\nperiods in a day, while each period is further divided into multiple time\nsteps. To overcome the challenge of long-range multi-phase planning with sparse\nreward, we conceive Hierarchical DRL (HDRL) for decoupling the original MDP\ninto a high-level Semi-MDP (SMDP) and multiple low-level MDPs. The Hierarchical\nDouble Deep Q-Network (HDDQN)-Hindsight Experience Replay (HER) algorithm is\nproposed for simultaneously solving the decision problems arising at different\ntemporal resolutions. As a result, the high-level agent learns an effective\npolicy for prescribing the charging targets for every charging period, while\nthe low-level agent learns an optimal policy for setting the charging power of\nevery time step within a single charging period, with the aim of minimizing the\ncharging costs while meeting the charging target. It is proved that the flat\npolicy constructed by superimposing the optimal high-level policy and the\noptimal low-level policy performs as well as the optimal policy of the original\nMDP. Since jointly learning both levels of policies is challenging due to the\nnon-stationarity of the high-level agent and the sampling inefficiency of the\nlow-level agent, we divide the joint learning process into two phases and\nexploit our new HER algorithm to manipulate the experience replay buffers for\nboth levels of agents. Numerical experiments are performed with the aid of\nreal-world data to evaluate the performance of the proposed algorithm."}
{"id": "2505.10557", "pdf": "https://arxiv.org/pdf/2505.10557", "abs": "https://arxiv.org/abs/2505.10557", "authors": ["Ke Wang", "Junting Pan", "Linda Wei", "Aojun Zhou", "Weikang Shi", "Zimu Lu", "Han Xiao", "Yunqiao Yang", "Houxing Ren", "Mingjie Zhan", "Hongsheng Li"], "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder."}
{"id": "2505.10557", "pdf": "https://arxiv.org/pdf/2505.10557", "abs": "https://arxiv.org/abs/2505.10557", "authors": ["Ke Wang", "Junting Pan", "Linda Wei", "Aojun Zhou", "Weikang Shi", "Zimu Lu", "Han Xiao", "Yunqiao Yang", "Houxing Ren", "Mingjie Zhan", "Hongsheng Li"], "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder."}
{"id": "2505.10167", "pdf": "https://arxiv.org/pdf/2505.10167", "abs": "https://arxiv.org/abs/2505.10167", "authors": ["Saikat Barua", "Mostafizur Rahman", "Shehenaz Khaled", "Md Jafor Sadek", "Rafiul Islam", "Shahnewaz Siddique"], "title": "QuXAI: Explainers for Hybrid Quantum Machine Learning Models", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": "16 pages, 6 figures, 7 equations", "summary": "The emergence of hybrid quantum-classical machine learning (HQML) models\nopens new horizons of computational intelligence but their fundamental\ncomplexity frequently leads to black box behavior that undermines transparency\nand reliability in their application. Although XAI for quantum systems still in\nits infancy, a major research gap is evident in robust global and local\nexplainability approaches that are designed for HQML architectures that employ\nquantized feature encoding followed by classical learning. The gap is the focus\nof this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an\nexplainer for explaining feature importance in these hybrid systems. Our model\nentails the creation of HQML models incorporating quantum feature maps, the use\nof Q-MEDLEY, which combines feature based inferences, preserving the quantum\ntransformation stage and visualizing the resulting attributions. Our result\nshows that Q-MEDLEY delineates influential classical aspects in HQML models, as\nwell as separates their noise, and competes well against established XAI\ntechniques in classical validation settings. Ablation studies more\nsignificantly expose the virtues of the composite structure used in Q-MEDLEY.\nThe implications of this work are critically important, as it provides a route\nto improve the interpretability and reliability of HQML models, thus promoting\ngreater confidence and being able to engage in safer and more responsible use\nof quantum-enhanced AI technology."}
{"id": "2505.10264", "pdf": "https://arxiv.org/pdf/2505.10264", "abs": "https://arxiv.org/abs/2505.10264", "authors": ["Francesco Diana", "André Nusser", "Chuan Xu", "Giovanni Neglia"], "title": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated Learning (FL) enables collaborative training of machine learning\nmodels across distributed clients without sharing raw data, ostensibly\npreserving data privacy. Nevertheless, recent studies have revealed critical\nvulnerabilities in FL, showing that a malicious central server can manipulate\nmodel updates to reconstruct clients' private training data. Existing data\nreconstruction attacks have important limitations: they often rely on\nassumptions about the clients' data distribution or their efficiency\nsignificantly degrades when batch sizes exceed just a few tens of samples.\n  In this work, we introduce a novel data reconstruction attack that overcomes\nthese limitations. Our method leverages a new geometric perspective on fully\nconnected layers to craft malicious model parameters, enabling the perfect\nrecovery of arbitrarily large data batches in classification tasks without any\nprior knowledge of clients' data. Through extensive experiments on both image\nand tabular datasets, we demonstrate that our attack outperforms existing\nmethods and achieves perfect reconstruction of data batches two orders of\nmagnitude larger than the state of the art."}
{"id": "2505.10562", "pdf": "https://arxiv.org/pdf/2505.10562", "abs": "https://arxiv.org/abs/2505.10562", "authors": ["Wenxuan Wang", "Fan Zhang", "Yufeng Cui", "Haiwen Diao", "Zhuoyan Luo", "Huchuan Lu", "Jing Liu", "Xinlong Wang"], "title": "End-to-End Vision Tokenizer Tuning", "categories": ["cs.CV"], "comment": null, "summary": "Existing vision tokenization isolates the optimization of vision tokenizers\nfrom downstream training, implicitly assuming the visual tokens can generalize\nwell across various tasks, e.g., image generation and visual question\nanswering. The vision tokenizer optimized for low-level reconstruction is\nagnostic to downstream tasks requiring varied representations and semantics.\nThis decoupled paradigm introduces a critical misalignment: The loss of the\nvision tokenization can be the representation bottleneck for target tasks. For\nexample, errors in tokenizing text in a given image lead to poor results when\nrecognizing or generating them. To address this, we propose ETT, an end-to-end\nvision tokenizer tuning approach that enables joint optimization between vision\ntokenization and target autoregressive tasks. Unlike prior autoregressive\nmodels that use only discrete indices from a frozen vision tokenizer, ETT\nleverages the visual embeddings of the tokenizer codebook, and optimizes the\nvision tokenizers end-to-end with both reconstruction and caption objectives.\nETT can be seamlessly integrated into existing training pipelines with minimal\narchitecture modifications. Our ETT is simple to implement and integrate,\nwithout the need to adjust the original codebooks or architectures of the\nemployed large language models. Extensive experiments demonstrate that our\nproposed end-to-end vision tokenizer tuning unlocks significant performance\ngains, i.e., 2-6% for multimodal understanding and visual generation tasks\ncompared to frozen tokenizer baselines, while preserving the original\nreconstruction capability. We hope this very simple and strong method can\nempower multimodal foundation models besides image generation and\nunderstanding."}
{"id": "2505.10169", "pdf": "https://arxiv.org/pdf/2505.10169", "abs": "https://arxiv.org/abs/2505.10169", "authors": ["Matthias Kümmerer", "Harneet Khanuja", "Matthias Bethge"], "title": "Modeling Saliency Dataset Bias", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes."}
{"id": "2505.10271", "pdf": "https://arxiv.org/pdf/2505.10271", "abs": "https://arxiv.org/abs/2505.10271", "authors": ["Rafael Pablos Sarabia", "Joachim Nyborg", "Morten Birk", "Jeppe Liborius Sjørup", "Anders Lillevang Vesterholt", "Ira Assent"], "title": "RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We present a deep learning model for high-resolution probabilistic\nprecipitation forecasting over an 8-hour horizon in Europe, overcoming the\nlimitations of radar-only deep learning models with short forecast lead times.\nOur model efficiently integrates multiple data sources - including radar,\nsatellite, and physics-based numerical weather prediction (NWP) - while\ncapturing long-range interactions, resulting in accurate forecasts with robust\nuncertainty quantification through consistent probabilistic maps. Featuring a\ncompact architecture, it enables more efficient training and faster inference\nthan existing models. Extensive experiments demonstrate that our model\nsurpasses current operational NWP systems, extrapolation-based methods, and\ndeep-learning nowcasting models, setting a new standard for high-resolution\nprecipitation forecasting in Europe, ensuring a balance between accuracy,\ninterpretability, and computational efficiency."}
{"id": "2505.10565", "pdf": "https://arxiv.org/pdf/2505.10565", "abs": "https://arxiv.org/abs/2505.10565", "authors": ["Zehan Wang", "Siyu Chen", "Lihe Yang", "Jialei Wang", "Ziang Zhang", "Hengshuang Zhao", "Zhou Zhao"], "title": "Depth Anything with Any Prior", "categories": ["cs.CV"], "comment": "Home page: https://prior-depth-anything.github.io/", "summary": "This work presents Prior Depth Anything, a framework that combines incomplete\nbut precise metric information in depth measurement with relative but complete\ngeometric structures in depth prediction, generating accurate, dense, and\ndetailed metric depth maps for any scene. To this end, we design a\ncoarse-to-fine pipeline to progressively integrate the two complementary depth\nsources. First, we introduce pixel-level metric alignment and distance-aware\nweighting to pre-fill diverse metric priors by explicitly using depth\nprediction. It effectively narrows the domain gap between prior patterns,\nenhancing generalization across varying scenarios. Second, we develop a\nconditioned monocular depth estimation (MDE) model to refine the inherent noise\nof depth priors. By conditioning on the normalized pre-filled prior and\nprediction, the model further implicitly merges the two complementary depth\nsources. Our model showcases impressive zero-shot generalization across depth\ncompletion, super-resolution, and inpainting over 7 real-world datasets,\nmatching or even surpassing previous task-specific methods. More importantly,\nit performs well on challenging, unseen mixed priors and enables test-time\nimprovements by switching prediction models, providing a flexible\naccuracy-efficiency trade-off while evolving with advancements in MDE models."}
{"id": "2505.10172", "pdf": "https://arxiv.org/pdf/2505.10172", "abs": "https://arxiv.org/abs/2505.10172", "authors": ["Zeyan Li", "Libing Chen", "Yin Tang"], "title": "Does Scaling Law Apply in Time Series Forecasting?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Rapid expansion of model size has emerged as a key challenge in time series\nforecasting. From early Transformer with tens of megabytes to recent\narchitectures like TimesNet with thousands of megabytes, performance gains have\noften come at the cost of exponentially increasing parameter counts. But is\nthis scaling truly necessary? To question the applicability of the scaling law\nin time series forecasting, we propose Alinear, an ultra-lightweight\nforecasting model that achieves competitive performance using only k-level\nparameters. We introduce a horizon-aware adaptive decomposition mechanism that\ndynamically rebalances component emphasis across different forecast lengths,\nalongside a progressive frequency attenuation strategy that achieves stable\nprediction in various forecasting horizons without incurring the computational\noverhead of attention mechanisms. Extensive experiments on seven benchmark\ndatasets demonstrate that Alinear consistently outperforms large-scale models\nwhile using less than 1% of their parameters, maintaining strong accuracy\nacross both short and ultra-long forecasting horizons. Moreover, to more fairly\nevaluate model efficiency, we propose a new parameter-aware evaluation metric\nthat highlights the superiority of ALinear under constrained model budgets. Our\nanalysis reveals that the relative importance of trend and seasonal components\nvaries depending on data characteristics rather than following a fixed pattern,\nvalidating the necessity of our adaptive design. This work challenges the\nprevailing belief that larger models are inherently better and suggests a\nparadigm shift toward more efficient time series modeling."}
{"id": "2505.10272", "pdf": "https://arxiv.org/pdf/2505.10272", "abs": "https://arxiv.org/abs/2505.10272", "authors": ["Niklas Dexheimer", "Sascha Gaudlitz", "Johannes Schmidt-Hieber"], "title": "Spike-timing-dependent Hebbian learning as noisy gradient descent", "categories": ["cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Hebbian learning is a key principle underlying learning in biological neural\nnetworks. It postulates that synaptic changes occur locally, depending on the\nactivities of pre- and postsynaptic neurons. While Hebbian learning based on\nneuronal firing rates is well explored, much less is known about learning rules\nthat account for precise spike-timing. We relate a Hebbian\nspike-timing-dependent plasticity rule to noisy gradient descent with respect\nto a natural loss function on the probability simplex. This connection allows\nus to prove that the learning rule eventually identifies the presynaptic neuron\nwith the highest activity. We also discover an intrinsic connection to noisy\nmirror descent."}
{"id": "2505.10566", "pdf": "https://arxiv.org/pdf/2505.10566", "abs": "https://arxiv.org/abs/2505.10566", "authors": ["Yen-Chi Cheng", "Krishna Kumar Singh", "Jae Shin Yoon", "Alex Schwing", "Liangyan Gui", "Matheus Gadelha", "Paul Guerrero", "Nanxuan Zhao"], "title": "3D-Fixup: Advancing Photo Editing with 3D Priors", "categories": ["cs.CV"], "comment": "SIGGRAPH 2025. Project page: https://3dfixup.github.io/", "summary": "Despite significant advances in modeling image priors via diffusion models,\n3D-aware image editing remains challenging, in part because the object is only\nspecified via a single image. To tackle this challenge, we propose 3D-Fixup, a\nnew framework for editing 2D images guided by learned 3D priors. The framework\nsupports difficult editing situations such as object translation and 3D\nrotation. To achieve this, we leverage a training-based approach that harnesses\nthe generative power of diffusion models. As video data naturally encodes\nreal-world physical dynamics, we turn to video data for generating training\ndata pairs, i.e., a source and a target frame. Rather than relying solely on a\nsingle trained model to infer transformations between source and target frames,\nwe incorporate 3D guidance from an Image-to-3D model, which bridges this\nchallenging task by explicitly projecting 2D information into 3D space. We\ndesign a data generation pipeline to ensure high-quality 3D guidance throughout\ntraining. Results show that by integrating these 3D priors, 3D-Fixup\neffectively supports complex, identity coherent 3D-aware edits, achieving\nhigh-quality results and advancing the application of diffusion models in\nrealistic image manipulation. The code is provided at\nhttps://3dfixup.github.io/"}
{"id": "2505.10185", "pdf": "https://arxiv.org/pdf/2505.10185", "abs": "https://arxiv.org/abs/2505.10185", "authors": ["Seongyun Lee", "Seungone Kim", "Minju Seo", "Yongrae Jo", "Dongyoung Go", "Hyeonbin Hwang", "Jinho Park", "Xiang Yue", "Sean Welleck", "Graham Neubig", "Moontae Lee", "Minjoon Seo"], "title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think", "categories": ["cs.CL", "cs.AI"], "comment": "Work in progress", "summary": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of\nmodern large language models, but our understanding of the reasoning strategies\nunderlying these capabilities remains limited. While some prior works have\nattempted to categorize CoTs using predefined strategy types, such approaches\nare constrained by human intuition and fail to capture the full diversity of\nmodel behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up\nframework for analyzing and steering model reasoning. Our method automatically\nextracts diverse reasoning criteria from model-generated CoTs, embeds them into\na semantic space, clusters them into representative categories, and derives\ncontrastive rubrics to interpret reasoning behavior. Human evaluations show\nthat this framework produces more interpretable and comprehensive analyses than\nexisting methods. Moreover, we demonstrate that this understanding enables\nperformance gains: we can predict which strategy a model is likely to use and\nguide it toward more effective alternatives. Finally, we provide practical\ninsights, such as that training data format (e.g., free-form vs.\nmultiple-choice) has a far greater impact on reasoning behavior than data\ndomain, underscoring the importance of format-aware model design."}
{"id": "2505.10296", "pdf": "https://arxiv.org/pdf/2505.10296", "abs": "https://arxiv.org/abs/2505.10296", "authors": ["Jiaju Qi", "Lei Lei", "Thorsteinn Jonsson", "Dusit Niyato"], "title": "Optimizing Electric Bus Charging Scheduling with Uncertainties Using Hierarchical Deep Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "The growing adoption of Electric Buses (EBs) represents a significant step\ntoward sustainable development. By utilizing Internet of Things (IoT) systems,\ncharging stations can autonomously determine charging schedules based on\nreal-time data. However, optimizing EB charging schedules remains a critical\nchallenge due to uncertainties in travel time, energy consumption, and\nfluctuating electricity prices. Moreover, to address real-world complexities,\ncharging policies must make decisions efficiently across multiple time scales\nand remain scalable for large EB fleets. In this paper, we propose a\nHierarchical Deep Reinforcement Learning (HDRL) approach that reformulates the\noriginal Markov Decision Process (MDP) into two augmented MDPs. To solve these\nMDPs and enable multi-timescale decision-making, we introduce a novel HDRL\nalgorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization\nEnhancement (DAC-MAPPO-E). Scalability challenges of the Double Actor-Critic\n(DAC) algorithm for large-scale EB fleets are addressed through enhancements at\nboth decision levels. At the high level, we redesign the decentralized actor\nnetwork and integrate an attention mechanism to extract relevant global state\ninformation for each EB, decreasing the size of neural networks. At the low\nlevel, the Multi-Agent Proximal Policy Optimization (MAPPO) algorithm is\nincorporated into the DAC framework, enabling decentralized and coordinated\ncharging power decisions, reducing computational complexity and enhancing\nconvergence speed. Extensive experiments with real-world data demonstrate the\nsuperior performance and scalability of DAC-MAPPO-E in optimizing EB fleet\ncharging schedules."}
{"id": "2505.10271", "pdf": "https://arxiv.org/pdf/2505.10271", "abs": "https://arxiv.org/abs/2505.10271", "authors": ["Rafael Pablos Sarabia", "Joachim Nyborg", "Morten Birk", "Jeppe Liborius Sjørup", "Anders Lillevang Vesterholt", "Ira Assent"], "title": "RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We present a deep learning model for high-resolution probabilistic\nprecipitation forecasting over an 8-hour horizon in Europe, overcoming the\nlimitations of radar-only deep learning models with short forecast lead times.\nOur model efficiently integrates multiple data sources - including radar,\nsatellite, and physics-based numerical weather prediction (NWP) - while\ncapturing long-range interactions, resulting in accurate forecasts with robust\nuncertainty quantification through consistent probabilistic maps. Featuring a\ncompact architecture, it enables more efficient training and faster inference\nthan existing models. Extensive experiments demonstrate that our model\nsurpasses current operational NWP systems, extrapolation-based methods, and\ndeep-learning nowcasting models, setting a new standard for high-resolution\nprecipitation forecasting in Europe, ensuring a balance between accuracy,\ninterpretability, and computational efficiency."}
{"id": "2505.10231", "pdf": "https://arxiv.org/pdf/2505.10231", "abs": "https://arxiv.org/abs/2505.10231", "authors": ["Haozhe Luo", "Ziyu Zhou", "Zixin Shu", "Aurélie Pahud de Mortanges", "Robert Berke", "Mauricio Reyes"], "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner."}
{"id": "2505.10297", "pdf": "https://arxiv.org/pdf/2505.10297", "abs": "https://arxiv.org/abs/2505.10297", "authors": ["Chibueze Peace Obioma", "Youcheng Sun", "Mustafa A. Mustafa"], "title": "Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Submitted to ESORICS 2025", "summary": "Federated learning (FL) enhances privacy and reduces communication cost for\nresource-constrained edge clients by supporting distributed model training at\nthe edge. However, the heterogeneous nature of such devices produces diverse,\nnon-independent, and identically distributed (non-IID) data, making the\ndetection of backdoor attacks more challenging. In this paper, we propose a\nnovel federated representative-attention-based defense mechanism, named FeRA,\nthat leverages cross-client attention over internal feature representations to\ndistinguish benign from malicious clients. FeRA computes an anomaly score based\non representation reconstruction errors, effectively identifying clients whose\ninternal activations significantly deviate from the group consensus. Our\nevaluation demonstrates FeRA's robustness across various FL scenarios,\nincluding challenging non-IID data distributions typical of edge devices.\nExperimental results show that it effectively reduces backdoor attack success\nrates while maintaining high accuracy on the main task. The method is\nmodel-agnostic, attack-agnostic, and does not require labeled reference data,\nmaking it well suited to heterogeneous and resource-limited edge deployments."}
{"id": "2505.10441", "pdf": "https://arxiv.org/pdf/2505.10441", "abs": "https://arxiv.org/abs/2505.10441", "authors": ["Filippo Leveni", "Luca Magri", "Giacomo Boracchi", "Cesare Alippi"], "title": "PIF: Anomaly detection via preference embedding", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)", "summary": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space."}
{"id": "2505.10260", "pdf": "https://arxiv.org/pdf/2505.10260", "abs": "https://arxiv.org/abs/2505.10260", "authors": ["Poli Apollinaire Nemkova", "Solomon Ubani", "Mark V. Albert"], "title": "Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the era of increasingly sophisticated natural language processing (NLP)\nsystems, large language models (LLMs) have demonstrated remarkable potential\nfor diverse applications, including tasks requiring nuanced textual\nunderstanding and contextual reasoning. This study investigates the\ncapabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3,\nMistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex\ntextual dataset comprising social media posts in Russian and Ukrainian.\nSpecifically, the focus is on the binary classification task of identifying\nreferences to human rights violations within the dataset.\n  To evaluate the effectiveness of these models, their annotations are compared\nagainst a gold standard set of human double-annotated labels across 1000\nsamples. The analysis includes assessing annotation performance under different\nprompting conditions, with prompts provided in both English and Russian.\nAdditionally, the study explores the unique patterns of errors and\ndisagreements exhibited by each model, offering insights into their strengths,\nlimitations, and cross-linguistic adaptability.\n  By juxtaposing LLM outputs with human annotations, this research contributes\nto understanding the reliability and applicability of LLMs for sensitive,\ndomain-specific tasks in multilingual contexts. It also sheds light on how\nlanguage models handle inherently subjective and context-dependent judgments, a\ncritical consideration for their deployment in real-world scenarios."}
{"id": "2505.10307", "pdf": "https://arxiv.org/pdf/2505.10307", "abs": "https://arxiv.org/abs/2505.10307", "authors": ["Yiyang Zhao", "Chengpei Wu", "Lilin Zhang", "Ning Yang"], "title": "Negative Metric Learning for Graphs", "categories": ["cs.LG"], "comment": null, "summary": "Graph contrastive learning (GCL) often suffers from false negatives, which\ndegrades the performance on downstream tasks. The existing methods addressing\nthe false negative issue usually rely on human prior knowledge, still leading\nGCL to suboptimal results. In this paper, we propose a novel Negative Metric\nLearning (NML) enhanced GCL (NML-GCL). NML-GCL employs a learnable Negative\nMetric Network (NMN) to build a negative metric space, in which false negatives\ncan be distinguished better from true negatives based on their distance to\nanchor node. To overcome the lack of explicit supervision signals for NML, we\npropose a joint training scheme with bi-level optimization objective, which\nimplicitly utilizes the self-supervision signals to iteratively optimize the\nencoder and the negative metric network. The solid theoretical analysis and the\nextensive experiments conducted on widely used benchmarks verify the\nsuperiority of the proposed method."}
{"id": "2505.10457", "pdf": "https://arxiv.org/pdf/2505.10457", "abs": "https://arxiv.org/abs/2505.10457", "authors": ["Matteo Gambella", "Vicente Javier Castro Solar", "Manuel Roveri"], "title": "SEAL: Searching Expandable Architectures for Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "comment": "8 pages, 5 figures", "summary": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios."}
{"id": "2505.10261", "pdf": "https://arxiv.org/pdf/2505.10261", "abs": "https://arxiv.org/abs/2505.10261", "authors": ["Rui Yang", "Huitao Li", "Matthew Yu Heng Wong", "Yuhe Ke", "Xin Li", "Kunyu Yu", "Jingchi Liao", "Jonathan Chong Kai Liew", "Sabarinath Vinod Nair", "Jasmine Chiat Ling Ong", "Irene Li", "Douglas Teodoro", "Chuan Hong", "Daniel Shu Wei Ting", "Nan Liu"], "title": "The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Natural language processing (NLP) has been traditionally applied to medicine,\nand generative large language models (LLMs) have become prominent recently.\nHowever, the differences between them across different medical tasks remain\nunderexplored. We analyzed 19,123 studies, finding that generative LLMs\ndemonstrate advantages in open-ended tasks, while traditional NLP dominates in\ninformation extraction and analysis tasks. As these technologies advance,\nethical use of them is essential to ensure their potential in medical\napplications."}
{"id": "2505.10322", "pdf": "https://arxiv.org/pdf/2505.10322", "abs": "https://arxiv.org/abs/2505.10322", "authors": ["Yijie Zhou", "Shi Pu"], "title": "Asynchronous Decentralized SGD under Non-Convexity: A Block-Coordinate Descent Framework", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Decentralized optimization has become vital for leveraging distributed data\nwithout central control, enhancing scalability and privacy. However, practical\ndeployments face fundamental challenges due to heterogeneous computation speeds\nand unpredictable communication delays. This paper introduces a refined model\nof Asynchronous Decentralized Stochastic Gradient Descent (ADSGD) under\npractical assumptions of bounded computation and communication times. To\nunderstand the convergence of ADSGD, we first analyze Asynchronous Stochastic\nBlock Coordinate Descent (ASBCD) as a tool, and then show that ADSGD converges\nunder computation-delay-independent step sizes. The convergence result is\nestablished without assuming bounded data heterogeneity. Empirical experiments\nreveal that ADSGD outperforms existing methods in wall-clock convergence time\nacross various scenarios. With its simplicity, efficiency in memory and\ncommunication, and resilience to communication and computation delays, ADSGD is\nwell-suited for real-world decentralized learning tasks."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.10264", "pdf": "https://arxiv.org/pdf/2505.10264", "abs": "https://arxiv.org/abs/2505.10264", "authors": ["Francesco Diana", "André Nusser", "Chuan Xu", "Giovanni Neglia"], "title": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated Learning (FL) enables collaborative training of machine learning\nmodels across distributed clients without sharing raw data, ostensibly\npreserving data privacy. Nevertheless, recent studies have revealed critical\nvulnerabilities in FL, showing that a malicious central server can manipulate\nmodel updates to reconstruct clients' private training data. Existing data\nreconstruction attacks have important limitations: they often rely on\nassumptions about the clients' data distribution or their efficiency\nsignificantly degrades when batch sizes exceed just a few tens of samples.\n  In this work, we introduce a novel data reconstruction attack that overcomes\nthese limitations. Our method leverages a new geometric perspective on fully\nconnected layers to craft malicious model parameters, enabling the perfect\nrecovery of arbitrarily large data batches in classification tasks without any\nprior knowledge of clients' data. Through extensive experiments on both image\nand tabular datasets, we demonstrate that our attack outperforms existing\nmethods and achieves perfect reconstruction of data batches two orders of\nmagnitude larger than the state of the art."}
{"id": "2505.10325", "pdf": "https://arxiv.org/pdf/2505.10325", "abs": "https://arxiv.org/abs/2505.10325", "authors": ["Athanasios Tziouvaras", "Blaz Bertalanic", "George Floros", "Kostas Kolomvatsos", "Panagiotis Sarigiannidis", "Carolina Fortuna"], "title": "A Representation Learning Approach to Feature Drift Detection in Wireless Networks", "categories": ["cs.LG"], "comment": null, "summary": "AI is foreseen to be a centerpiece in next generation wireless networks\nenabling enabling ubiquitous communication as well as new services. However, in\nreal deployment, feature distribution changes may degrade the performance of AI\nmodels and lead to undesired behaviors. To counter for undetected model\ndegradation, we propose ALERT; a method that can detect feature distribution\nchanges and trigger model re-training that works well on two wireless network\nuse cases: wireless fingerprinting and link anomaly detection. ALERT includes\nthree components: representation learning, statistical testing and utility\nassessment. We rely on MLP for designing the representation learning component,\non Kolmogorov-Smirnov and Population Stability Index tests for designing the\nstatistical testing and a new function for utility assessment. We show the\nsuperiority of the proposed method against ten standard drift detection methods\navailable in the literature on two wireless network use cases."}
{"id": "2505.10526", "pdf": "https://arxiv.org/pdf/2505.10526", "abs": "https://arxiv.org/abs/2505.10526", "authors": ["Mugilan Ganesan", "Shane Segal", "Ankur Aggarwal", "Nish Sinnadurai", "Sean Lie", "Vithursan Thangarasa"], "title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Main paper: 11 pp., 4 figs., 3 tabs.; Supplementary: 2 pp", "summary": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs."}
{"id": "2505.10297", "pdf": "https://arxiv.org/pdf/2505.10297", "abs": "https://arxiv.org/abs/2505.10297", "authors": ["Chibueze Peace Obioma", "Youcheng Sun", "Mustafa A. Mustafa"], "title": "Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Submitted to ESORICS 2025", "summary": "Federated learning (FL) enhances privacy and reduces communication cost for\nresource-constrained edge clients by supporting distributed model training at\nthe edge. However, the heterogeneous nature of such devices produces diverse,\nnon-independent, and identically distributed (non-IID) data, making the\ndetection of backdoor attacks more challenging. In this paper, we propose a\nnovel federated representative-attention-based defense mechanism, named FeRA,\nthat leverages cross-client attention over internal feature representations to\ndistinguish benign from malicious clients. FeRA computes an anomaly score based\non representation reconstruction errors, effectively identifying clients whose\ninternal activations significantly deviate from the group consensus. Our\nevaluation demonstrates FeRA's robustness across various FL scenarios,\nincluding challenging non-IID data distributions typical of edge devices.\nExperimental results show that it effectively reduces backdoor attack success\nrates while maintaining high accuracy on the main task. The method is\nmodel-agnostic, attack-agnostic, and does not require labeled reference data,\nmaking it well suited to heterogeneous and resource-limited edge deployments."}
{"id": "2505.10330", "pdf": "https://arxiv.org/pdf/2505.10330", "abs": "https://arxiv.org/abs/2505.10330", "authors": ["Jonathan Clifford Balloch"], "title": "Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change", "categories": ["cs.LG", "cs.AI"], "comment": "PhD Dissertation, 131 pages", "summary": "Real-world autonomous decision-making systems, from robots to recommendation\nengines, must operate in environments that change over time. While deep\nreinforcement learning (RL) has shown an impressive ability to learn optimal\npolicies in stationary environments, most methods are data intensive and assume\na world that does not change between training and test time. As a result,\nconventional RL methods struggle to adapt when conditions change. This poses a\nfundamental challenge: how can RL agents efficiently adapt their behavior when\nencountering novel environmental changes during deployment without\ncatastrophically forgetting useful prior knowledge? This dissertation\ndemonstrates that efficient online adaptation requires two key capabilities:\n(1) prioritized exploration and sampling strategies that help identify and\nlearn from relevant experiences, and (2) selective preservation of prior\nknowledge through structured representations that can be updated without\ndisruption to reusable components."}
{"id": "2505.10320", "pdf": "https://arxiv.org/pdf/2505.10320", "abs": "https://arxiv.org/abs/2505.10320", "authors": ["Chenxi Whitehouse", "Tianlu Wang", "Ping Yu", "Xian Li", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 8 tables, 11 figures", "summary": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses."}
{"id": "2505.10331", "pdf": "https://arxiv.org/pdf/2505.10331", "abs": "https://arxiv.org/abs/2505.10331", "authors": ["Luca Muscarnera", "Luigi Loreti", "Giovanni Todeschini", "Alessio Fumagalli", "Francesco Regazzoni"], "title": "Emergence of Structure in Ensembles of Random Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Randomness is ubiquitous in many applications across data science and machine\nlearning. Remarkably, systems composed of random components often display\nemergent global behaviors that appear deterministic, manifesting a transition\nfrom microscopic disorder to macroscopic organization. In this work, we\nintroduce a theoretical model for studying the emergence of collective\nbehaviors in ensembles of random classifiers. We argue that, if the ensemble is\nweighted through the Gibbs measure defined by adopting the classification loss\nas an energy, then there exists a finite temperature parameter for the\ndistribution such that the classification is optimal, with respect to the loss\n(or the energy). Interestingly, for the case in which samples are generated by\na Gaussian distribution and labels are constructed by employing a teacher\nperceptron, we analytically prove and numerically confirm that such optimal\ntemperature does not depend neither on the teacher classifier (which is, by\nconstruction of the learning problem, unknown), nor on the number of random\nclassifiers, highlighting the universal nature of the observed behavior.\nExperiments on the MNIST dataset underline the relevance of this phenomenon in\nhigh-quality, noiseless, datasets. Finally, a physical analogy allows us to\nshed light on the self-organizing nature of the studied phenomenon."}
{"id": "2505.10330", "pdf": "https://arxiv.org/pdf/2505.10330", "abs": "https://arxiv.org/abs/2505.10330", "authors": ["Jonathan Clifford Balloch"], "title": "Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change", "categories": ["cs.LG", "cs.AI"], "comment": "PhD Dissertation, 131 pages", "summary": "Real-world autonomous decision-making systems, from robots to recommendation\nengines, must operate in environments that change over time. While deep\nreinforcement learning (RL) has shown an impressive ability to learn optimal\npolicies in stationary environments, most methods are data intensive and assume\na world that does not change between training and test time. As a result,\nconventional RL methods struggle to adapt when conditions change. This poses a\nfundamental challenge: how can RL agents efficiently adapt their behavior when\nencountering novel environmental changes during deployment without\ncatastrophically forgetting useful prior knowledge? This dissertation\ndemonstrates that efficient online adaptation requires two key capabilities:\n(1) prioritized exploration and sampling strategies that help identify and\nlearn from relevant experiences, and (2) selective preservation of prior\nknowledge through structured representations that can be updated without\ndisruption to reusable components."}
{"id": "2505.10344", "pdf": "https://arxiv.org/pdf/2505.10344", "abs": "https://arxiv.org/abs/2505.10344", "authors": ["Alan Jeffares", "Liyuan Liu"], "title": "An Introduction to Discrete Variational Autoencoders", "categories": ["cs.LG"], "comment": "Tutorial paper", "summary": "Variational Autoencoders (VAEs) are well-established as a principled approach\nto probabilistic unsupervised learning with neural networks. Typically, an\nencoder network defines the parameters of a Gaussian distributed latent space\nfrom which we can sample and pass realizations to a decoder network. This model\nis trained to reconstruct its inputs and is optimized through the evidence\nlower bound. In recent years, discrete latent spaces have grown in popularity,\nsuggesting that they may be a natural choice for many data modalities (e.g.\ntext). In this tutorial, we provide a rigorous, yet practical, introduction to\ndiscrete variational autoencoders -- specifically, VAEs in which the latent\nspace is made up of latent variables that follow a categorical distribution. We\nassume only a basic mathematical background with which we carefully derive each\nstep from first principles. From there, we develop a concrete training recipe\nand provide an example implementation, hosted at\nhttps://github.com/alanjeffares/discreteVAE."}
{"id": "2505.10331", "pdf": "https://arxiv.org/pdf/2505.10331", "abs": "https://arxiv.org/abs/2505.10331", "authors": ["Luca Muscarnera", "Luigi Loreti", "Giovanni Todeschini", "Alessio Fumagalli", "Francesco Regazzoni"], "title": "Emergence of Structure in Ensembles of Random Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Randomness is ubiquitous in many applications across data science and machine\nlearning. Remarkably, systems composed of random components often display\nemergent global behaviors that appear deterministic, manifesting a transition\nfrom microscopic disorder to macroscopic organization. In this work, we\nintroduce a theoretical model for studying the emergence of collective\nbehaviors in ensembles of random classifiers. We argue that, if the ensemble is\nweighted through the Gibbs measure defined by adopting the classification loss\nas an energy, then there exists a finite temperature parameter for the\ndistribution such that the classification is optimal, with respect to the loss\n(or the energy). Interestingly, for the case in which samples are generated by\na Gaussian distribution and labels are constructed by employing a teacher\nperceptron, we analytically prove and numerically confirm that such optimal\ntemperature does not depend neither on the teacher classifier (which is, by\nconstruction of the learning problem, unknown), nor on the number of random\nclassifiers, highlighting the universal nature of the observed behavior.\nExperiments on the MNIST dataset underline the relevance of this phenomenon in\nhigh-quality, noiseless, datasets. Finally, a physical analogy allows us to\nshed light on the self-organizing nature of the studied phenomenon."}
{"id": "2505.10347", "pdf": "https://arxiv.org/pdf/2505.10347", "abs": "https://arxiv.org/abs/2505.10347", "authors": ["Gabriel S. Gama", "Valdir Grassi Jr"], "title": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task\nLearning by addressing issues like conflicting gradients and differing gradient\nnorms, which hinder equal-weighted task training. However, recent critiques\nsuggest that equally weighted tasks can achieve competitive results compared to\nSMTOs, arguing that previous SMTO results were influenced by poor\nhyperparameter optimization and lack of regularization. In this work, we\nevaluate these claims through an extensive empirical evaluation of SMTOs,\nincluding some of the latest methods, on more complex multi-task problems to\nclarify this behavior. Our findings indicate that SMTOs perform well compared\nto uniform loss and that fixed weights can achieve competitive performance\ncompared to SMTOs. Furthermore, we demonstrate why uniform loss perform\nsimilarly to SMTOs in some instances. The code will be made publicly available."}
{"id": "2505.10347", "pdf": "https://arxiv.org/pdf/2505.10347", "abs": "https://arxiv.org/abs/2505.10347", "authors": ["Gabriel S. Gama", "Valdir Grassi Jr"], "title": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task\nLearning by addressing issues like conflicting gradients and differing gradient\nnorms, which hinder equal-weighted task training. However, recent critiques\nsuggest that equally weighted tasks can achieve competitive results compared to\nSMTOs, arguing that previous SMTO results were influenced by poor\nhyperparameter optimization and lack of regularization. In this work, we\nevaluate these claims through an extensive empirical evaluation of SMTOs,\nincluding some of the latest methods, on more complex multi-task problems to\nclarify this behavior. Our findings indicate that SMTOs perform well compared\nto uniform loss and that fixed weights can achieve competitive performance\ncompared to SMTOs. Furthermore, we demonstrate why uniform loss perform\nsimilarly to SMTOs in some instances. The code will be made publicly available."}
{"id": "2505.10360", "pdf": "https://arxiv.org/pdf/2505.10360", "abs": "https://arxiv.org/abs/2505.10360", "authors": ["Victor Petrén Bach Hansen", "Lasse Krogsbøll", "Jonas Lyngsø", "Mathias Baltzersen", "Andreas Motzfeldt", "Kevin Pelgrims", "Lars Maaløe"], "title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": null, "summary": "There are now a multitude of AI-scribing solutions for healthcare promising\nthe utilization of large language models for ambient documentation. However,\nthese AI scribes still rely on one-shot, or few-shot prompts for generating\nnotes after the consultation has ended, employing little to no reasoning. This\nrisks long notes with an increase in hallucinations, misrepresentation of the\nintent of the clinician, and reliance on the proofreading of the clinician to\ncatch errors. A dangerous combination for patient safety if vigilance is\ncompromised by workload and fatigue. In this paper, we introduce a method for\nextracting salient clinical information in real-time alongside the healthcare\nconsultation, denoted Facts, and use that information recursively to generate\nthe final note. The FactsR method results in more accurate and concise notes by\nplacing the clinician-in-the-loop of note generation, while opening up new use\ncases within real-time decision support."}
{"id": "2505.10352", "pdf": "https://arxiv.org/pdf/2505.10352", "abs": "https://arxiv.org/abs/2505.10352", "authors": ["Shihao Zou", "Qingfeng Li", "Wei Ji", "Jingjing Li", "Yongkui Yang", "Guoqi Li", "Chao Dong"], "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer"}
{"id": "2505.10392", "pdf": "https://arxiv.org/pdf/2505.10392", "abs": "https://arxiv.org/abs/2505.10392", "authors": ["Aryan Mishra", "Lizhen Lin"], "title": "Schreier-Coset Graph Propagation", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 1 figure , preprint", "summary": "Graph Neural Networks (GNNs) offer a principled framework for learning over\ngraph-structured data, yet their expressive capacity is often hindered by\nover-squashing, wherein information from distant nodes is compressed into\nfixed-size vectors. Existing solutions, including graph rewiring and\nbottleneck-resistant architectures such as Cayley and expander graphs, avoid\nthis problem but introduce scalability bottlenecks. In particular, the Cayley\ngraphs constructed over $SL(2,\\mathbb{Z}_n)$ exhibit strong theoretical\nproperties, yet suffer from cubic node growth $O(n^3)$, leading to high memory\nusage. To address this, this work introduces Schrier-Coset Graph Propagation\n(SCGP), a group-theoretic augmentation method that enriches node features\nthrough Schreier-coset embeddings without altering the input graph topology.\nSCGP embeds bottleneck-free connectivity patterns into a compact feature space,\nimproving long-range message passing while maintaining computational\nefficiency. Empirical evaluations across standard node and graph classification\nbenchmarks demonstrate that SCGP achieves performance comparable to, or\nexceeding, expander graph and rewired GNN baselines. Furthermore, SCGP exhibits\nparticular advantages in processing hierarchical and modular graph structures,\noffering reduced inference latency, improved scalability, and a low memory\nfootprint, making it suitable for real-time and resource-constrained\napplications."}
{"id": "2505.10360", "pdf": "https://arxiv.org/pdf/2505.10360", "abs": "https://arxiv.org/abs/2505.10360", "authors": ["Victor Petrén Bach Hansen", "Lasse Krogsbøll", "Jonas Lyngsø", "Mathias Baltzersen", "Andreas Motzfeldt", "Kevin Pelgrims", "Lars Maaløe"], "title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": null, "summary": "There are now a multitude of AI-scribing solutions for healthcare promising\nthe utilization of large language models for ambient documentation. However,\nthese AI scribes still rely on one-shot, or few-shot prompts for generating\nnotes after the consultation has ended, employing little to no reasoning. This\nrisks long notes with an increase in hallucinations, misrepresentation of the\nintent of the clinician, and reliance on the proofreading of the clinician to\ncatch errors. A dangerous combination for patient safety if vigilance is\ncompromised by workload and fatigue. In this paper, we introduce a method for\nextracting salient clinical information in real-time alongside the healthcare\nconsultation, denoted Facts, and use that information recursively to generate\nthe final note. The FactsR method results in more accurate and concise notes by\nplacing the clinician-in-the-loop of note generation, while opening up new use\ncases within real-time decision support."}
{"id": "2505.10407", "pdf": "https://arxiv.org/pdf/2505.10407", "abs": "https://arxiv.org/abs/2505.10407", "authors": ["Wenhao Ding", "Choon Hwai Yap", "Kangjun Ji", "Simão Castro"], "title": "Two-Stage Generative Model for Intracranial Aneurysm Meshes with Morphological Marker Conditioning", "categories": ["cs.LG", "68T07"], "comment": "10 pages, 2 figures", "summary": "A generative model for the mesh geometry of intracranial aneurysms (IA) is\ncrucial for training networks to predict blood flow forces in real time, which\nis a key factor affecting disease progression. This need is necessitated by the\nabsence of a large IA image datasets. Existing shape generation methods\nstruggle to capture realistic IA features and ignore the relationship between\nIA pouches and parent vessels, limiting physiological realism and their\ngeneration cannot be controlled to have specific morphological measurements. We\npropose AneuG, a two-stage Variational Autoencoder (VAE)-based IA mesh\ngenerator. In the first stage, AneuG generates low-dimensional Graph Harmonic\nDeformation (GHD) tokens to encode and reconstruct aneurysm pouch shapes,\nconstrained to morphing energy statistics truths. GHD enables more accurate\nshape encoding than alternatives. In the second stage, AneuG generates parent\nvessels conditioned on GHD tokens, by generating vascular centreline and\npropagating the cross-section. AneuG's IA shape generation can further be\nconditioned to have specific clinically relevant morphological measurements.\nThis is useful for studies to understand shape variations represented by\nclinical measurements, and for flow simulation studies to understand effects of\nspecific clinical shape parameters on fluid dynamics. Source code and\nimplementation details are available at\nhttps://github.com/anonymousaneug/AneuG."}
{"id": "2505.10392", "pdf": "https://arxiv.org/pdf/2505.10392", "abs": "https://arxiv.org/abs/2505.10392", "authors": ["Aryan Mishra", "Lizhen Lin"], "title": "Schreier-Coset Graph Propagation", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 1 figure , preprint", "summary": "Graph Neural Networks (GNNs) offer a principled framework for learning over\ngraph-structured data, yet their expressive capacity is often hindered by\nover-squashing, wherein information from distant nodes is compressed into\nfixed-size vectors. Existing solutions, including graph rewiring and\nbottleneck-resistant architectures such as Cayley and expander graphs, avoid\nthis problem but introduce scalability bottlenecks. In particular, the Cayley\ngraphs constructed over $SL(2,\\mathbb{Z}_n)$ exhibit strong theoretical\nproperties, yet suffer from cubic node growth $O(n^3)$, leading to high memory\nusage. To address this, this work introduces Schrier-Coset Graph Propagation\n(SCGP), a group-theoretic augmentation method that enriches node features\nthrough Schreier-coset embeddings without altering the input graph topology.\nSCGP embeds bottleneck-free connectivity patterns into a compact feature space,\nimproving long-range message passing while maintaining computational\nefficiency. Empirical evaluations across standard node and graph classification\nbenchmarks demonstrate that SCGP achieves performance comparable to, or\nexceeding, expander graph and rewired GNN baselines. Furthermore, SCGP exhibits\nparticular advantages in processing hierarchical and modular graph structures,\noffering reduced inference latency, improved scalability, and a low memory\nfootprint, making it suitable for real-time and resource-constrained\napplications."}
{"id": "2505.10422", "pdf": "https://arxiv.org/pdf/2505.10422", "abs": "https://arxiv.org/abs/2505.10422", "authors": ["Daniel Weitekamp", "Christopher MacLellan", "Erik Harpstead", "Kenneth Koedinger"], "title": "Decomposed Inductive Procedure Learning: Learning Academic Tasks with Human-Like Data Efficiency", "categories": ["cs.LG"], "comment": "To appear in CogSci 2025", "summary": "Human learning relies on specialization -- distinct cognitive mechanisms\nworking together to enable rapid learning. In contrast, most modern neural\nnetworks rely on a single mechanism: gradient descent over an objective\nfunction. This raises the question: might human learners' relatively rapid\nlearning from just tens of examples instead of tens of thousands in data-driven\ndeep learning arise from our ability to use multiple specialized mechanisms of\nlearning in combination? We investigate this question through an ablation\nanalysis of inductive human learning simulations in online tutoring\nenvironments. Comparing reinforcement learning to a more data-efficient\n3-mechanism symbolic rule induction approach, we find that decomposing learning\ninto multiple distinct mechanisms significantly improves data efficiency,\nbringing it in line with human learning. Furthermore, we show that this\ndecomposition has a greater impact on efficiency than the distinction between\nsymbolic and subsymbolic learning alone. Efforts to align data-driven machine\nlearning with human learning often overlook the stark difference in learning\nefficiency. Our findings suggest that integrating multiple specialized learning\nmechanisms may be key to bridging this gap."}
{"id": "2505.10402", "pdf": "https://arxiv.org/pdf/2505.10402", "abs": "https://arxiv.org/abs/2505.10402", "authors": ["Yihong Dong", "Yuchen Liu", "Xue Jiang", "Zhi Jin", "Ge Li"], "title": "Rethinking Repetition Problems of LLMs in Code Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to ACL 2025 (main)", "summary": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code."}
{"id": "2505.10423", "pdf": "https://arxiv.org/pdf/2505.10423", "abs": "https://arxiv.org/abs/2505.10423", "authors": ["Ari Karchmer", "Eran Malach"], "title": "The Power of Random Features and the Limits of Distribution-Free Gradient Descent", "categories": ["cs.LG"], "comment": null, "summary": "We study the relationship between gradient-based optimization of parametric\nmodels (e.g., neural networks) and optimization of linear combinations of\nrandom features. Our main result shows that if a parametric model can be\nlearned using mini-batch stochastic gradient descent (bSGD) without making\nassumptions about the data distribution, then with high probability, the target\nfunction can also be approximated using a polynomial-sized combination of\nrandom features. The size of this combination depends on the number of gradient\nsteps and numerical precision used in the bSGD process. This finding reveals\nfundamental limitations of distribution-free learning in neural networks\ntrained by gradient descent, highlighting why making assumptions about data\ndistributions is often crucial in practice. Along the way, we also introduce a\nnew theoretical framework called average probabilistic dimension complexity\n(adc), which extends the probabilistic dimension complexity developed by Kamath\net al. (2020). We prove that adc has a polynomial relationship with statistical\nquery dimension, and use this relationship to demonstrate an infinite\nseparation between adc and standard dimension complexity."}
{"id": "2505.10420", "pdf": "https://arxiv.org/pdf/2505.10420", "abs": "https://arxiv.org/abs/2505.10420", "authors": ["Andrei Arhire", "Radu Timofte"], "title": "Learned Lightweight Smartphone ISP with Unpaired Data", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at CVPRW 2025", "summary": "The Image Signal Processor (ISP) is a fundamental component in modern\nsmartphone cameras responsible for conversion of RAW sensor image data to RGB\nimages with a strong focus on perceptual quality. Recent work highlights the\npotential of deep learning approaches and their ability to capture details with\na quality increasingly close to that of professional cameras. A difficult and\ncostly step when developing a learned ISP is the acquisition of pixel-wise\naligned paired data that maps the raw captured by a smartphone camera sensor to\nhigh-quality reference images. In this work, we address this challenge by\nproposing a novel training method for a learnable ISP that eliminates the need\nfor direct correspondences between raw images and ground-truth data with\nmatching content. Our unpaired approach employs a multi-term loss function\nguided by adversarial training with multiple discriminators processing feature\nmaps from pre-trained networks to maintain content structure while learning\ncolor and texture characteristics from the target RGB dataset. Using\nlightweight neural network architectures suitable for mobile devices as\nbackbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm\nUltraISP datasets. Compared to paired training methods, our unpaired learning\nstrategy shows strong potential and achieves high fidelity across multiple\nevaluation metrics. The code and pre-trained models are available at\nhttps://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data ."}
{"id": "2505.10425", "pdf": "https://arxiv.org/pdf/2505.10425", "abs": "https://arxiv.org/abs/2505.10425", "authors": ["Jingyao Wang", "Wenwen Qiang", "Zeen Song", "Changwen Zheng", "Hui Xiong"], "title": "Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) excel at complex tasks thanks to advances in\nreasoning abilities. However, existing methods overlook the trade-off between\nreasoning effectiveness and computational efficiency, often encouraging\nunnecessarily long reasoning chains and wasting tokens. To address this, we\npropose Learning to Think (L2T), an information-theoretic reinforcement\nfine-tuning framework for LLMs to make the models achieve optimal reasoning\nwith fewer tokens. Specifically, L2T treats each query-response interaction as\na hierarchical session of multiple episodes and proposes a universal dense\nprocess reward, i.e., quantifies the episode-wise information gain in\nparameters, requiring no extra annotations or task-specific evaluators. We\npropose a method to quickly estimate this reward based on PAC-Bayes bounds and\nthe Fisher information matrix. Theoretical analyses show that it significantly\nreduces computational complexity with high estimation accuracy. By immediately\nrewarding each episode's contribution and penalizing excessive updates, L2T\noptimizes the model via reinforcement learning to maximize the use of each\nepisode and achieve effective updates. Empirical results on various reasoning\nbenchmarks and base models demonstrate the advantage of L2T across different\ntasks, boosting both reasoning effectiveness and efficiency."}
{"id": "2505.10441", "pdf": "https://arxiv.org/pdf/2505.10441", "abs": "https://arxiv.org/abs/2505.10441", "authors": ["Filippo Leveni", "Luca Magri", "Giacomo Boracchi", "Cesare Alippi"], "title": "PIF: Anomaly detection via preference embedding", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)", "summary": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space."}
{"id": "2505.10432", "pdf": "https://arxiv.org/pdf/2505.10432", "abs": "https://arxiv.org/abs/2505.10432", "authors": ["Randy J. Chase", "Katherine Haynes", "Lander Ver Hoef", "Imme Ebert-Uphoff"], "title": "Score-based diffusion nowcasting of GOES imagery", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "Clouds and precipitation are important for understanding weather and climate.\nSimulating clouds and precipitation with traditional numerical weather\nprediction is challenging because of the sub-grid parameterizations required.\nMachine learning has been explored for forecasting clouds and precipitation,\nbut early machine learning methods often created blurry forecasts. In this\npaper we explore a newer method, named score-based diffusion, to nowcast (zero\nto three hour forecast) clouds and precipitation. We discuss the background and\nintuition of score-based diffusion models - thus providing a starting point for\nthe community - while exploring the methodology's use for nowcasting\ngeostationary infrared imagery. We experiment with three main types of\ndiffusion models: a standard score-based diffusion model (Diff); a residual\ncorrection diffusion model (CorrDiff); and a latent diffusion model (LDM). Our\nresults show that the diffusion models are able to not only advect existing\nclouds, but also generate and decay clouds, including convective initiation.\nThese results are surprising because the forecasts are initiated with only the\npast 20 mins of infrared satellite imagery. A case study qualitatively shows\nthe preservation of high resolution features longer into the forecast than a\nconventional mean-squared error trained U-Net. The best of the three diffusion\nmodels tested was the CorrDiff approach, outperforming all other diffusion\nmodels, the traditional U-Net, and a persistence forecast by one to two kelvin\non root mean squared error. The diffusion models also enable out-of-the-box\nensemble generation, which shows skillful calibration, with the spread of the\nensemble correlating well to the error."}
{"id": "2505.10453", "pdf": "https://arxiv.org/pdf/2505.10453", "abs": "https://arxiv.org/abs/2505.10453", "authors": ["Tyler Tran", "Sangeet Khemlani", "J. G. Trafton"], "title": "Vision language models have difficulty recognizing virtual objects", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision language models (VLMs) are AI systems paired with both language and\nvision encoders to process multimodal input. They are capable of performing\ncomplex semantic tasks such as automatic captioning, but it remains an open\nquestion about how well they comprehend the visuospatial properties of scenes\ndepicted in the images they process. We argue that descriptions of virtual\nobjects -- objects that are not visually represented in an image -- can help\ntest scene comprehension in these AI systems. For example, an image that\ndepicts a person standing under a tree can be paired with the following prompt:\nimagine that a kite is stuck in the tree. VLMs that comprehend the scene should\nupdate their representations and reason sensibly about the spatial relations\nbetween all three objects. We describe systematic evaluations of\nstate-of-the-art VLMs and show that their ability to process virtual objects is\ninadequate."}
{"id": "2505.10438", "pdf": "https://arxiv.org/pdf/2505.10438", "abs": "https://arxiv.org/abs/2505.10438", "authors": ["David Grasev"], "title": "Identification and Optimal Nonlinear Control of Turbojet Engine Using Koopman Eigenfunction Model", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "51 pages, 28 figures", "summary": "Gas turbine engines represent complex highly nonlinear dynamical systems.\nDeriving their physics-based models can be challenging as it requires\nperformance characteristics, that are not always available, and one often has\nto make many simplifying assumptions. In this paper, the limitations of\nconventional experimental methods used to derive component-level and locally\nlinear parameter-varying models are discussed and addressed by employing\nidentification techniques based on data collected from standard engine\noperation under closed-loop control. The rotor dynamics were estimated using\nthe sparse identification of nonlinear dynamics. Subsequently, the autonomous\npart of the dynamics was mapped into an optimally constructed Koopman\neigenfunction space. The process included eigenvalue optimization using\nmetaheuristic algorithms and temporal projection, followed by gradient-based\neigenfunction identification. The resulting Koopman model was validated against\nan in-house reference component-level model. A globally optimal nonlinear\nfeedback controller and a Kalman estimator were then designed in the\neigenfunction space and compared to the classical and gain-scheduled\nproportional-integral controllers, as well as a proposed internal model control\napproach. The eigenmode structure allowed targeting individual modes during the\noptimization process, resulting in a better performance tuning. The results\nshowed that the Koopman-based controller outperformed the other benchmark\ncontrollers in both reference tracking and disturbance rejection, under\nsea-level and varying flight conditions, due to its global nature."}
{"id": "2505.10457", "pdf": "https://arxiv.org/pdf/2505.10457", "abs": "https://arxiv.org/abs/2505.10457", "authors": ["Matteo Gambella", "Vicente Javier Castro Solar", "Manuel Roveri"], "title": "SEAL: Searching Expandable Architectures for Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "comment": "8 pages, 5 figures", "summary": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios."}
{"id": "2505.10441", "pdf": "https://arxiv.org/pdf/2505.10441", "abs": "https://arxiv.org/abs/2505.10441", "authors": ["Filippo Leveni", "Luca Magri", "Giacomo Boracchi", "Cesare Alippi"], "title": "PIF: Anomaly detection via preference embedding", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)", "summary": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space."}
{"id": "2505.10465", "pdf": "https://arxiv.org/pdf/2505.10465", "abs": "https://arxiv.org/abs/2505.10465", "authors": ["Yizhou liu", "Ziming Liu", "Jeff Gore"], "title": "Superposition Yields Robust Neural Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages, 23 figures", "summary": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters."}
{"id": "2505.10457", "pdf": "https://arxiv.org/pdf/2505.10457", "abs": "https://arxiv.org/abs/2505.10457", "authors": ["Matteo Gambella", "Vicente Javier Castro Solar", "Manuel Roveri"], "title": "SEAL: Searching Expandable Architectures for Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "comment": "8 pages, 5 figures", "summary": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios."}
{"id": "2505.10482", "pdf": "https://arxiv.org/pdf/2505.10482", "abs": "https://arxiv.org/abs/2505.10482", "authors": ["Ningyuan Yang", "Jiaxuan Gao", "Feng Gao", "Yi Wu", "Chao Yu"], "title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages for main text, 23 pages in total, submitted to Neurips, 13\n  figures", "summary": "Diffusion policies, widely adopted in decision-making scenarios such as\nrobotics, gaming and autonomous driving, are capable of learning diverse skills\nfrom demonstration data due to their high representation power. However, the\nsub-optimal and limited coverage of demonstration data could lead to diffusion\npolicies that generate sub-optimal trajectories and even catastrophic failures.\nWhile reinforcement learning (RL)-based fine-tuning has emerged as a promising\nsolution to address these limitations, existing approaches struggle to\neffectively adapt Proximal Policy Optimization (PPO) to diffusion models. This\nchallenge stems from the computational intractability of action likelihood\nestimation during the denoising process, which leads to complicated\noptimization objectives. In our experiments starting from randomly initialized\npolicies, we find that online tuning of Diffusion Policies demonstrates much\nlower sample efficiency compared to directly applying PPO on MLP policies\n(MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework\nthat reformulates Diffusion Policy as a noise-conditioned deterministic policy.\nBy treating each denoising step as a differentiable transformation conditioned\non pre-sampled noise, NCDPO enables tractable likelihood evaluation and\ngradient backpropagation through all diffusion timesteps. Our experiments\ndemonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when\ntraining from scratch, outperforming existing methods in both sample efficiency\nand final performance across diverse benchmarks, including continuous robot\ncontrol and multi-agent game scenarios. Furthermore, our experimental results\nshow that our method is robust to the number denoising timesteps in the\nDiffusion Policy."}
{"id": "2505.10465", "pdf": "https://arxiv.org/pdf/2505.10465", "abs": "https://arxiv.org/abs/2505.10465", "authors": ["Yizhou liu", "Ziming Liu", "Jeff Gore"], "title": "Superposition Yields Robust Neural Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages, 23 figures", "summary": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters."}
{"id": "2505.10483", "pdf": "https://arxiv.org/pdf/2505.10483", "abs": "https://arxiv.org/abs/2505.10483", "authors": ["Yi Li", "Haonan Wang", "Qixiang Zhang", "Boyu Xiao", "Chenchang Hu", "Hualiang Wang", "Xiaomeng Li"], "title": "UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation", "categories": ["cs.CV", "cs.AI"], "comment": "UniEval is the first evaluation framework designed for unified\n  multimodal models, including a holistic benchmark UniBench and the UniScore\n  metric", "summary": "The emergence of unified multimodal understanding and generation models is\nrapidly attracting attention because of their ability to enhance\ninstruction-following capabilities while minimizing model redundancy. However,\nthere is a lack of a unified evaluation framework for these models, which would\nenable an elegant, simplified, and overall evaluation. Current models conduct\nevaluations on multiple task-specific benchmarks, but there are significant\nlimitations, such as the lack of overall results, errors from extra evaluation\nmodels, reliance on extensive labeled images, benchmarks that lack diversity,\nand metrics with limited capacity for instruction-following evaluation. To\ntackle these challenges, we introduce UniEval, the first evaluation framework\ndesigned for unified multimodal models without extra models, images, or\nannotations. This facilitates a simplified and unified evaluation process. The\nUniEval framework contains a holistic benchmark, UniBench (supports both\nunified and visual generation models), along with the corresponding UniScore\nmetric. UniBench includes 81 fine-grained tags contributing to high diversity.\nExperimental results indicate that UniBench is more challenging than existing\nbenchmarks, and UniScore aligns closely with human evaluations, surpassing\ncurrent metrics. Moreover, we extensively evaluated SoTA unified and visual\ngeneration models, uncovering new insights into Univeral's unique values."}
{"id": "2505.10472", "pdf": "https://arxiv.org/pdf/2505.10472", "abs": "https://arxiv.org/abs/2505.10472", "authors": ["Agnik Saha", "Victoria Churchill", "Anny D. Rodriguez", "Ugur Kursuncu", "Muhammed Y. Idris"], "title": "Large Language Models for Cancer Communication: Evaluating Linguistic Quality, Safety, and Accessibility in Generative AI", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Effective communication about breast and cervical cancers remains a\npersistent health challenge, with significant gaps in public understanding of\ncancer prevention, screening, and treatment, potentially leading to delayed\ndiagnoses and inadequate treatments. This study evaluates the capabilities and\nlimitations of Large Language Models (LLMs) in generating accurate, safe, and\naccessible cancer-related information to support patient understanding. We\nevaluated five general-purpose and three medical LLMs using a mixed-methods\nevaluation framework across linguistic quality, safety and trustworthiness, and\ncommunication accessibility and affectiveness. Our approach utilized\nquantitative metrics, qualitative expert ratings, and statistical analysis\nusing Welch's ANOVA, Games-Howell, and Hedges' g. Our results show that\ngeneral-purpose LLMs produced outputs of higher linguistic quality and\naffectiveness, while medical LLMs demonstrate greater communication\naccessibility. However, medical LLMs tend to exhibit higher levels of potential\nharm, toxicity, and bias, reducing their performance in safety and\ntrustworthiness. Our findings indicate a duality between domain-specific\nknowledge and safety in health communications. The results highlight the need\nfor intentional model design with targeted improvements, particularly in\nmitigating harm and bias, and improving safety and affectiveness. This study\nprovides a comprehensive evaluation of LLMs for cancer communication, offering\ncritical insights for improving AI-generated health content and informing\nfuture development of accurate, safe, and accessible digital health tools."}
{"id": "2505.10515", "pdf": "https://arxiv.org/pdf/2505.10515", "abs": "https://arxiv.org/abs/2505.10515", "authors": ["Seongun Kim", "Sol A Kim", "Geonhyeong Kim", "Enver Menadjiev", "Chanwoo Lee", "Seongwook Chung", "Nari Kim", "Jaesik Choi"], "title": "PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, post hoc explanation methods have emerged to enhance model\ntransparency by attributing model outputs to input features. However, these\nmethods face challenges due to their specificity to certain neural network\narchitectures and data modalities. Existing explainable artificial intelligence\n(XAI) frameworks have attempted to address these challenges but suffer from\nseveral limitations. These include limited flexibility to diverse model\narchitectures and data modalities due to hard-coded implementations, a\nrestricted number of supported XAI methods because of the requirements for\nlayer-specific operations of attribution methods, and sub-optimal\nrecommendations of explanations due to the lack of evaluation and optimization\nphases. Consequently, these limitations impede the adoption of XAI technology\nin real-world applications, making it difficult for practitioners to select the\noptimal explanation method for their domain. To address these limitations, we\nintroduce \\textbf{PnPXAI}, a universal XAI framework that supports diverse data\nmodalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI\nautomatically detects model architectures, recommends applicable explanation\nmethods, and optimizes hyperparameters for optimal explanations. We validate\nthe framework's effectiveness through user surveys and showcase its versatility\nacross various domains, including medicine and finance."}
{"id": "2505.10475", "pdf": "https://arxiv.org/pdf/2505.10475", "abs": "https://arxiv.org/abs/2505.10475", "authors": ["Mouxiang Chen", "Binyuan Hui", "Zeyu Cui", "Jiaxi Yang", "Dayiheng Liu", "Jianling Sun", "Junyang Lin", "Zhongxin Liu"], "title": "Parallel Scaling Law for Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "It is commonly believed that scaling language models should commit a\nsignificant space or time cost, by increasing the parameters (parameter\nscaling) or output tokens (inference-time scaling). We introduce the third and\nmore inference-efficient scaling paradigm: increasing the model's parallel\ncomputation during both training and inference time. We apply $P$ diverse and\nlearnable transformations to the input, execute forward passes of the model in\nparallel, and dynamically aggregate the $P$ outputs. This method, namely\nparallel scaling (ParScale), scales parallel computation by reusing existing\nparameters and can be applied to any model structure, optimization procedure,\ndata, or task. We theoretically propose a new scaling law and validate it\nthrough large-scale pre-training, which shows that a model with $P$ parallel\nstreams is similar to scaling the parameters by $O(\\log P)$ while showing\nsuperior inference efficiency. For example, ParScale can use up to 22$\\times$\nless memory increase and 6$\\times$ less latency increase compared to parameter\nscaling that achieves the same performance improvement. It can also recycle an\noff-the-shelf pre-trained model into a parallelly scaled one by post-training\non a small amount of tokens, further reducing the training budget. The new\nscaling law we discovered potentially facilitates the deployment of more\npowerful models in low-resource scenarios, and provides an alternative\nperspective for the role of computation in machine learning."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.10482", "pdf": "https://arxiv.org/pdf/2505.10482", "abs": "https://arxiv.org/abs/2505.10482", "authors": ["Ningyuan Yang", "Jiaxuan Gao", "Feng Gao", "Yi Wu", "Chao Yu"], "title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages for main text, 23 pages in total, submitted to Neurips, 13\n  figures", "summary": "Diffusion policies, widely adopted in decision-making scenarios such as\nrobotics, gaming and autonomous driving, are capable of learning diverse skills\nfrom demonstration data due to their high representation power. However, the\nsub-optimal and limited coverage of demonstration data could lead to diffusion\npolicies that generate sub-optimal trajectories and even catastrophic failures.\nWhile reinforcement learning (RL)-based fine-tuning has emerged as a promising\nsolution to address these limitations, existing approaches struggle to\neffectively adapt Proximal Policy Optimization (PPO) to diffusion models. This\nchallenge stems from the computational intractability of action likelihood\nestimation during the denoising process, which leads to complicated\noptimization objectives. In our experiments starting from randomly initialized\npolicies, we find that online tuning of Diffusion Policies demonstrates much\nlower sample efficiency compared to directly applying PPO on MLP policies\n(MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework\nthat reformulates Diffusion Policy as a noise-conditioned deterministic policy.\nBy treating each denoising step as a differentiable transformation conditioned\non pre-sampled noise, NCDPO enables tractable likelihood evaluation and\ngradient backpropagation through all diffusion timesteps. Our experiments\ndemonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when\ntraining from scratch, outperforming existing methods in both sample efficiency\nand final performance across diverse benchmarks, including continuous robot\ncontrol and multi-agent game scenarios. Furthermore, our experimental results\nshow that our method is robust to the number denoising timesteps in the\nDiffusion Policy."}
{"id": "2505.10551", "pdf": "https://arxiv.org/pdf/2505.10551", "abs": "https://arxiv.org/abs/2505.10551", "authors": ["Yiwen Liu", "Jessica Bader", "Jae Myung Kim"], "title": "Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data", "categories": ["cs.CV", "cs.AI"], "comment": "CVPRW 2025", "summary": "With the development of photorealistic diffusion models, models trained in\npart or fully on synthetic data achieve progressively better results. However,\ndiffusion models still routinely generate images that would not exist in\nreality, such as a dog floating above the ground or with unrealistic texture\nartifacts. We define the concept of feasibility as whether attributes in a\nsynthetic image could realistically exist in the real-world domain; synthetic\nimages containing attributes that violate this criterion are considered\ninfeasible. Intuitively, infeasible images are typically considered\nout-of-distribution; thus, training on such images is expected to hinder a\nmodel's ability to generalize to real-world data, and they should therefore be\nexcluded from the training set whenever possible. However, does feasibility\nreally matter? In this paper, we investigate whether enforcing feasibility is\nnecessary when generating synthetic training data for CLIP-based classifiers,\nfocusing on three target attributes: background, color, and texture. We\nintroduce VariReal, a pipeline that minimally edits a given source image to\ninclude feasible or infeasible attributes given by the textual prompt generated\nby a large language model. Our experiments show that feasibility minimally\naffects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference\nin top-1 accuracy across three fine-grained datasets. Also, the attribute\nmatters on whether the feasible/infeasible images adversarially influence the\nclassification performance. Finally, mixing feasible and infeasible images in\ntraining datasets does not significantly impact performance compared to using\npurely feasible or infeasible datasets."}
{"id": "2505.10484", "pdf": "https://arxiv.org/pdf/2505.10484", "abs": "https://arxiv.org/abs/2505.10484", "authors": ["Andrea Baisero", "Rupali Bhati", "Shuo Liu", "Aathira Pillai", "Christopher Amato"], "title": "Fixing Incomplete Value Function Decomposition for Multi-Agent Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Value function decomposition methods for cooperative multi-agent\nreinforcement learning compose joint values from individual per-agent\nutilities, and train them using a joint objective. To ensure that the action\nselection process between individual utilities and joint values remains\nconsistent, it is imperative for the composition to satisfy the\nindividual-global max (IGM) property. Although satisfying IGM itself is\nstraightforward, most existing methods (e.g., VDN, QMIX) have limited\nrepresentation capabilities and are unable to represent the full class of IGM\nvalues, and the one exception that has no such limitation (QPLEX) is\nunnecessarily complex. In this work, we present a simple formulation of the\nfull class of IGM values that naturally leads to the derivation of QFIX, a\nnovel family of value function decomposition models that expand the\nrepresentation capabilities of prior models by means of a thin \"fixing\" layer.\nWe derive multiple variants of QFIX, and implement three variants in two\nwell-known multi-agent frameworks. We perform an empirical evaluation on\nmultiple SMACv2 and Overcooked environments, which confirms that QFIX (i)\nsucceeds in enhancing the performance of prior methods, (ii) learns more stably\nand performs better than its main competitor QPLEX, and (iii) achieves this\nwhile employing the simplest and smallest mixing models."}
{"id": "2505.10557", "pdf": "https://arxiv.org/pdf/2505.10557", "abs": "https://arxiv.org/abs/2505.10557", "authors": ["Ke Wang", "Junting Pan", "Linda Wei", "Aojun Zhou", "Weikang Shi", "Zimu Lu", "Han Xiao", "Yunqiao Yang", "Houxing Ren", "Mingjie Zhan", "Hongsheng Li"], "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder."}
{"id": "2505.10495", "pdf": "https://arxiv.org/pdf/2505.10495", "abs": "https://arxiv.org/abs/2505.10495", "authors": ["Vibha Belavadi", "Tushar Vatsa", "Dewang Sultania", "Suhas Suresha", "Ishita Verma", "Cheng Chen", "Tracy Holloway King", "Michael Friedrich"], "title": "RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs", "categories": ["cs.LG", "cs.CL"], "comment": "Proceedings of the 4th International Workshop on Knowledge-Augmented\n  Methods for Natural Language Processing", "summary": "This paper addresses fine-tuning Large Language Models (LLMs) for function\ncalling tasks when real user interaction data is unavailable. In digital\ncontent creation tools, where users express their needs through natural\nlanguage queries that must be mapped to API calls, the lack of real-world\ntask-specific data and privacy constraints for training on it necessitate\nsynthetic data generation. Existing approaches to synthetic data generation\nfall short in diversity and complexity, failing to replicate real-world data\ndistributions and leading to suboptimal performance after LLM fine-tuning. We\npresent a novel router-based architecture that leverages domain resources like\ncontent metadata and structured knowledge graphs, along with text-to-text and\nvision-to-text language models to generate high-quality synthetic training\ndata. Our architecture's flexible routing mechanism enables synthetic data\ngeneration that matches observed real-world distributions, addressing a\nfundamental limitation of traditional approaches. Evaluation on a comprehensive\nset of real user queries demonstrates significant improvements in both function\nclassification accuracy and API parameter selection. Models fine-tuned with our\nsynthetic data consistently outperform traditional approaches, establishing new\nbenchmarks for function calling tasks."}
{"id": "2505.10559", "pdf": "https://arxiv.org/pdf/2505.10559", "abs": "https://arxiv.org/abs/2505.10559", "authors": ["Ziming Liu", "Yizhou Liu", "Jeff Gore", "Max Tegmark"], "title": "Neural Thermodynamic Laws for Large Language Model Training", "categories": ["cs.LG", "cs.AI", "physics.data-an", "stat.ML"], "comment": "18 pages, 10 figures", "summary": "Beyond neural scaling laws, little is known about the laws underlying large\nlanguage models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new\nframework that offers fresh insights into LLM training dynamics. On the\ntheoretical side, we demonstrate that key thermodynamic quantities (e.g.,\ntemperature, entropy, heat capacity, thermal conduction) and classical\nthermodynamic principles (e.g., the three laws of thermodynamics and the\nequipartition theorem) naturally emerge under river-valley loss landscape\nassumptions. On the practical side, this scientific perspective yields\nintuitive guidelines for designing learning rate schedules."}
{"id": "2505.10515", "pdf": "https://arxiv.org/pdf/2505.10515", "abs": "https://arxiv.org/abs/2505.10515", "authors": ["Seongun Kim", "Sol A Kim", "Geonhyeong Kim", "Enver Menadjiev", "Chanwoo Lee", "Seongwook Chung", "Nari Kim", "Jaesik Choi"], "title": "PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, post hoc explanation methods have emerged to enhance model\ntransparency by attributing model outputs to input features. However, these\nmethods face challenges due to their specificity to certain neural network\narchitectures and data modalities. Existing explainable artificial intelligence\n(XAI) frameworks have attempted to address these challenges but suffer from\nseveral limitations. These include limited flexibility to diverse model\narchitectures and data modalities due to hard-coded implementations, a\nrestricted number of supported XAI methods because of the requirements for\nlayer-specific operations of attribution methods, and sub-optimal\nrecommendations of explanations due to the lack of evaluation and optimization\nphases. Consequently, these limitations impede the adoption of XAI technology\nin real-world applications, making it difficult for practitioners to select the\noptimal explanation method for their domain. To address these limitations, we\nintroduce \\textbf{PnPXAI}, a universal XAI framework that supports diverse data\nmodalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI\nautomatically detects model architectures, recommends applicable explanation\nmethods, and optimizes hyperparameters for optimal explanations. We validate\nthe framework's effectiveness through user surveys and showcase its versatility\nacross various domains, including medicine and finance."}
{"id": "2505.10526", "pdf": "https://arxiv.org/pdf/2505.10526", "abs": "https://arxiv.org/abs/2505.10526", "authors": ["Mugilan Ganesan", "Shane Segal", "Ankur Aggarwal", "Nish Sinnadurai", "Sean Lie", "Vithursan Thangarasa"], "title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Main paper: 11 pp., 4 figs., 3 tabs.; Supplementary: 2 pp", "summary": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs."}
{"id": "2505.10545", "pdf": "https://arxiv.org/pdf/2505.10545", "abs": "https://arxiv.org/abs/2505.10545", "authors": ["Amira Alakhdar", "Barnabas Poczos", "Newell Washburn"], "title": "Pharmacophore-Conditioned Diffusion Model for Ligand-Based De Novo Drug Design", "categories": ["cs.LG"], "comment": null, "summary": "Developing bioactive molecules remains a central, time- and cost-heavy\nchallenge in drug discovery, particularly for novel targets lacking structural\nor functional data. Pharmacophore modeling presents an alternative for\ncapturing the key features required for molecular bioactivity against a\nbiological target. In this work, we present PharmaDiff, a\npharmacophore-conditioned diffusion model for 3D molecular generation.\nPharmaDiff employs a transformer-based architecture to integrate an atom-based\nrepresentation of the 3D pharmacophore into the generative process, enabling\nthe precise generation of 3D molecular graphs that align with predefined\npharmacophore hypotheses. Through comprehensive testing, PharmaDiff\ndemonstrates superior performance in matching 3D pharmacophore constraints\ncompared to ligand-based drug design methods. Additionally, it achieves higher\ndocking scores across a range of proteins in structure-based drug design,\nwithout the need for target protein structures. By integrating pharmacophore\nmodeling with 3D generative techniques, PharmaDiff offers a powerful and\nflexible framework for rational drug design."}
{"id": "2505.10556", "pdf": "https://arxiv.org/pdf/2505.10556", "abs": "https://arxiv.org/abs/2505.10556", "authors": ["Nazanin Zounemat Kermani", "Sadjad Naderi", "Claire H. Dilliway", "Claire E. Heaney", "Shrreya Behll", "Boyang Chen", "Hisham Abubakar-Waziri", "Alexandra E. Porter", "Marc Chadeau-Hyam", "Fangxin Fang", "Ian M. Adcock", "Kian Fan Chung", "Christopher C. Pain"], "title": "An AI-driven framework for the prediction of personalised health response to air pollution", "categories": ["cs.LG", "physics.ao-ph"], "comment": "Kermani and Naderi share first authorship. 20 pages, 6 figures and 1\n  table", "summary": "Air pollution poses a significant threat to public health, causing or\nexacerbating many respiratory and cardiovascular diseases. In addition, climate\nchange is bringing about more extreme weather events such as wildfires and\nheatwaves, which can increase levels of pollution and worsen the effects of\npollution exposure. Recent advances in personal sensing have transformed the\ncollection of behavioural and physiological data, leading to the potential for\nnew improvements in healthcare. We wish to capitalise on this data, alongside\nnew capabilities in AI for making time series predictions, in order to monitor\nand predict health outcomes for an individual. Thus, we present a novel\nworkflow for predicting personalised health responses to pollution by\nintegrating physiological data from wearable fitness devices with real-time\nenvironmental exposures. The data is collected from various sources in a secure\nand ethical manner, and is used to train an AI model to predict individual\nhealth responses to pollution exposure within a cloud-based, modular framework.\nWe demonstrate that the AI model -- an Adversarial Autoencoder neural network\nin this case -- accurately reconstructs time-dependent health signals and\ncaptures nonlinear responses to pollution. Transfer learning is applied using\ndata from a personal smartwatch, which increases the generalisation abilities\nof the AI model and illustrates the adaptability of the approach to real-world,\nuser-generated data."}
{"id": "2505.10559", "pdf": "https://arxiv.org/pdf/2505.10559", "abs": "https://arxiv.org/abs/2505.10559", "authors": ["Ziming Liu", "Yizhou Liu", "Jeff Gore", "Max Tegmark"], "title": "Neural Thermodynamic Laws for Large Language Model Training", "categories": ["cs.LG", "cs.AI", "physics.data-an", "stat.ML"], "comment": "18 pages, 10 figures", "summary": "Beyond neural scaling laws, little is known about the laws underlying large\nlanguage models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new\nframework that offers fresh insights into LLM training dynamics. On the\ntheoretical side, we demonstrate that key thermodynamic quantities (e.g.,\ntemperature, entropy, heat capacity, thermal conduction) and classical\nthermodynamic principles (e.g., the three laws of thermodynamics and the\nequipartition theorem) naturally emerge under river-valley loss landscape\nassumptions. On the practical side, this scientific perspective yields\nintuitive guidelines for designing learning rate schedules."}
{"id": "2505.09649", "pdf": "https://arxiv.org/pdf/2505.09649", "abs": "https://arxiv.org/abs/2505.09649", "authors": ["Abisha Thapa Magar", "Anup Shakya"], "title": "Next Word Suggestion using Graph Neural Network", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Language Modeling is a prevalent task in Natural Language Processing. The\ncurrently existing most recent and most successful language models often tend\nto build a massive model with billions of parameters, feed in a tremendous\namount of text data, and train with enormous computation resources which\nrequire millions of dollars. In this project, we aim to address an important\nsub-task in language modeling, i.e., context embedding. We propose an approach\nto exploit the Graph Convolution operation in GNNs to encode the context and\nuse it in coalition with LSTMs to predict the next word given a local context\nof preceding words. We test this on the custom Wikipedia text corpus using a\nvery limited amount of resources and show that this approach works fairly well\nto predict the next word."}
{"id": "2505.09666", "pdf": "https://arxiv.org/pdf/2505.09666", "abs": "https://arxiv.org/abs/2505.09666", "authors": ["Yumin Choi", "Jinheon Baek", "Sung Ju Hwang"], "title": "System Prompt Optimization with Meta-Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance."}
{"id": "2505.09932", "pdf": "https://arxiv.org/pdf/2505.09932", "abs": "https://arxiv.org/abs/2505.09932", "authors": ["Kevin J McNamara", "Rhea Pritham Marpu"], "title": "Demystifying AI Agents: The Final Generation of Intelligence", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.MA"], "comment": null, "summary": "The trajectory of artificial intelligence (AI) has been one of relentless\nacceleration, evolving from rudimentary rule-based systems to sophisticated,\nautonomous agents capable of complex reasoning and interaction. This whitepaper\nchronicles this remarkable journey, charting the key technological\nmilestones--advancements in prompting, training methodologies, hardware\ncapabilities, and architectural innovations--that have converged to create the\nAI agents of today. We argue that these agents, exemplified by systems like\nOpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in\nAI development, potentially constituting the \"final generation\" of intelligence\nas we currently conceive it. We explore the capabilities and underlying\ntechnologies of these agents, grounded in practical examples, while also\nexamining the profound societal implications and the unprecedented pace of\nprogress that suggests intelligence is now doubling approximately every six\nmonths. The paper concludes by underscoring the critical need for wisdom and\nforesight in navigating the opportunities and challenges presented by this\npowerful new era of intelligence."}
{"id": "2505.09935", "pdf": "https://arxiv.org/pdf/2505.09935", "abs": "https://arxiv.org/abs/2505.09935", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Quoc Dai Tran"], "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users."}
{"id": "2505.09945", "pdf": "https://arxiv.org/pdf/2505.09945", "abs": "https://arxiv.org/abs/2505.09945", "authors": ["Deeksha Prahlad", "Chanhee Lee", "Dongha Kim", "Hokeun Kim"], "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)", "summary": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time."}
{"id": "2505.10030", "pdf": "https://arxiv.org/pdf/2505.10030", "abs": "https://arxiv.org/abs/2505.10030", "authors": ["Miit Daga", "Dhriti Parikh", "Swarna Priya Ramu"], "title": "DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera", "categories": ["cs.CV", "cs.LG"], "comment": "This paper is accepted for publication in IEEE Access journal and is\n  currently pending revisions before publication", "summary": "Coconut tree diseases are a serious risk to agricultural yield, particularly\nin developing countries where conventional farming practices restrict early\ndiagnosis and intervention. Current disease identification methods are manual,\nlabor-intensive, and non-scalable. In response to these limitations, we come up\nwith DeepSeqCoco, a deep learning based model for accurate and automatic\ndisease identification from coconut tree images. The model was tested under\nvarious optimizer settings, such as SGD, Adam, and hybrid configurations, to\nidentify the optimal balance between accuracy, minimization of loss, and\ncomputational cost. Results from experiments indicate that DeepSeqCoco can\nachieve as much as 99.5% accuracy (achieving up to 5% higher accuracy than\nexisting models) with the hybrid SGD-Adam showing the lowest validation loss of\n2.81%. It also shows a drop of up to 18% in training time and up to 85% in\nprediction time for input images. The results point out the promise of the\nmodel to improve precision agriculture through an AI-based, scalable, and\nefficient disease monitoring system."}
{"id": "2505.10066", "pdf": "https://arxiv.org/pdf/2505.10066", "abs": "https://arxiv.org/abs/2505.10066", "authors": ["Michael Fire", "Yitzhak Elbazis", "Adi Wasenstein", "Lior Rokach"], "title": "Dark LLMs: The Growing Threat of Unaligned AI Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50, 68T05, 68P25", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated."}
{"id": "2505.10169", "pdf": "https://arxiv.org/pdf/2505.10169", "abs": "https://arxiv.org/abs/2505.10169", "authors": ["Matthias Kümmerer", "Harneet Khanuja", "Matthias Bethge"], "title": "Modeling Saliency Dataset Bias", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes."}
{"id": "2505.10182", "pdf": "https://arxiv.org/pdf/2505.10182", "abs": "https://arxiv.org/abs/2505.10182", "authors": ["Yoichi Ishibashi", "Taro Yano", "Masafumi Oyamada"], "title": "Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant improvements in\nreasoning capabilities through supervised fine-tuning and reinforcement\nlearning. However, when training reasoning models, these approaches are\nprimarily applicable to specific domains such as mathematics and programming,\nwhich imposes fundamental constraints on the breadth and scalability of\ntraining data. In contrast, continual pretraining (CPT) offers the advantage of\nnot requiring task-specific signals. Nevertheless, how to effectively\nsynthesize training data for reasoning and how such data affect a wide range of\ndomains remain largely unexplored. This study provides a detailed evaluation of\nReasoning CPT, a form of CPT that uses synthetic data to reconstruct the hidden\nthought processes underlying texts, based on the premise that texts are the\nresult of the author's thinking process. Specifically, we apply Reasoning CPT\nto Gemma2-9B using synthetic data with hidden thoughts derived from STEM and\nLaw corpora, and compare it to standard CPT on the MMLU benchmark. Our analysis\nreveals that Reasoning CPT consistently improves performance across all\nevaluated domains. Notably, reasoning skills acquired in one domain transfer\neffectively to others; the performance gap with conventional methods widens as\nproblem difficulty increases, with gains of up to 8 points on the most\nchallenging problems. Furthermore, models trained with hidden thoughts learn to\nadjust the depth of their reasoning according to problem difficulty."}
{"id": "2505.10223", "pdf": "https://arxiv.org/pdf/2505.10223", "abs": "https://arxiv.org/abs/2505.10223", "authors": ["Puru Vaish", "Felix Meister", "Tobias Heimann", "Christoph Brune", "Jelmer M. Wolterink"], "title": "Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at MIDL 2025", "summary": "Medical image segmentation models are often trained on curated datasets,\nleading to performance degradation when deployed in real-world clinical\nsettings due to mismatches between training and test distributions. While data\naugmentation techniques are widely used to address these challenges,\ntraditional visually consistent augmentation strategies lack the robustness\nneeded for diverse real-world scenarios. In this work, we systematically\nevaluate alternative augmentation strategies, focusing on MixUp and Auxiliary\nFourier Augmentation. These methods mitigate the effects of multiple variations\nwithout explicitly targeting specific sources of distribution shifts. We\ndemonstrate how these techniques significantly improve out-of-distribution\ngeneralization and robustness to imaging variations across a wide range of\ntransformations in cardiac cine MRI and prostate MRI segmentation. We\nquantitatively find that these augmentation methods enhance learned feature\nrepresentations by promoting separability and compactness. Additionally, we\nhighlight how their integration into nnU-Net training pipelines provides an\neasy-to-implement, effective solution for enhancing the reliability of medical\nsegmentation models in real-world applications."}
{"id": "2505.10267", "pdf": "https://arxiv.org/pdf/2505.10267", "abs": "https://arxiv.org/abs/2505.10267", "authors": ["Pavel Korotaev", "Petr Surovtsev", "Alexander Kapitanov", "Karina Kvanchiani", "Aleksandr Nagaev"], "title": "HandReader: Advanced Techniques for Efficient Fingerspelling Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "https://github.com/ai-forever/handreader", "summary": "Fingerspelling is a significant component of Sign Language (SL), allowing the\ninterpretation of proper names, characterized by fast hand movements during\nsigning. Although previous works on fingerspelling recognition have focused on\nprocessing the temporal dimension of videos, there remains room for improving\nthe accuracy of these approaches. This paper introduces HandReader, a group of\nthree architectures designed to address the fingerspelling recognition task.\nHandReader$_{RGB}$ employs the novel Temporal Shift-Adaptive Module (TSAM) to\nprocess RGB features from videos of varying lengths while preserving important\nsequential information. HandReader$_{KP}$ is built on the proposed Temporal\nPose Encoder (TPE) operated on keypoints as tensors. Such keypoints composition\nin a batch allows the encoder to pass them through 2D and 3D convolution\nlayers, utilizing temporal and spatial information and accumulating keypoints\ncoordinates. We also introduce HandReader_RGB+KP - architecture with a joint\nencoder to benefit from RGB and keypoint modalities. Each HandReader model\npossesses distinct advantages and achieves state-of-the-art results on the\nChicagoFSWild and ChicagoFSWild+ datasets. Moreover, the models demonstrate\nhigh performance on the first open dataset for Russian fingerspelling, Znaki,\npresented in this paper. The Znaki dataset and HandReader pre-trained models\nare publicly available."}
{"id": "2505.10320", "pdf": "https://arxiv.org/pdf/2505.10320", "abs": "https://arxiv.org/abs/2505.10320", "authors": ["Chenxi Whitehouse", "Tianlu Wang", "Ping Yu", "Xian Li", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 8 tables, 11 figures", "summary": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses."}
{"id": "2505.10352", "pdf": "https://arxiv.org/pdf/2505.10352", "abs": "https://arxiv.org/abs/2505.10352", "authors": ["Shihao Zou", "Qingfeng Li", "Wei Ji", "Jingjing Li", "Yongkui Yang", "Guoqi Li", "Chao Dong"], "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer"}
{"id": "2505.10361", "pdf": "https://arxiv.org/pdf/2505.10361", "abs": "https://arxiv.org/abs/2505.10361", "authors": ["David Abel", "Michael Bowling", "André Barreto", "Will Dabney", "Shi Dong", "Steven Hansen", "Anna Harutyunyan", "Khimya Khetarpal", "Clare Lyle", "Razvan Pascanu", "Georgios Piliouras", "Doina Precup", "Jonathan Richens", "Mark Rowland", "Tom Schaul", "Satinder Singh"], "title": "Plasticity as the Mirror of Empowerment", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Agents are minimally entities that are influenced by their past observations\nand act to influence future observations. This latter capacity is captured by\nempowerment, which has served as a vital framing concept across artificial\nintelligence and cognitive science. This former capacity, however, is equally\nfoundational: In what ways, and to what extent, can an agent be influenced by\nwhat it observes? In this paper, we ground this concept in a universal\nagent-centric measure that we refer to as plasticity, and reveal a fundamental\nconnection to empowerment. Following a set of desiderata on a suitable\ndefinition, we define plasticity using a new information-theoretic quantity we\ncall the generalized directed information. We show that this new quantity\nstrictly generalizes the directed information introduced by Massey (1990) while\npreserving all of its desirable properties. Our first finding is that\nplasticity is the mirror of empowerment: The agent's plasticity is identical to\nthe empowerment of the environment, and vice versa. Our second finding\nestablishes a tension between the plasticity and empowerment of an agent,\nsuggesting that agent design needs to be mindful of both characteristics. We\nexplore the implications of these findings, and suggest that plasticity,\nempowerment, and their relationship are essential to understanding agency."}
{"id": "2505.10399", "pdf": "https://arxiv.org/pdf/2505.10399", "abs": "https://arxiv.org/abs/2505.10399", "authors": ["Kaivalya Rawal", "Zihao Fu", "Eoin Delaney", "Chris Russell"], "title": "Evaluating Model Explanations without Ground Truth", "categories": ["cs.AI", "cs.LG", "I.2.6"], "comment": "https://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth", "summary": "There can be many competing and contradictory explanations for a single model\nprediction, making it difficult to select which one to use. Current explanation\nevaluation frameworks measure quality by comparing against ideal \"ground-truth\"\nexplanations, or by verifying model sensitivity to important inputs. We outline\nthe limitations of these approaches, and propose three desirable principles to\nground the future development of explanation evaluation strategies for local\nfeature importance explanations. We propose a ground-truth Agnostic eXplanation\nEvaluation framework (AXE) for evaluating and comparing model explanations that\nsatisfies these principles. Unlike prior approaches, AXE does not require\naccess to ideal ground-truth explanations for comparison, or rely on model\nsensitivity - providing an independent measure of explanation quality. We\nverify AXE by comparing with baselines, and show how it can be used to detect\nexplanation fairwashing. Our code is available at\nhttps://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth."}
{"id": "2505.10402", "pdf": "https://arxiv.org/pdf/2505.10402", "abs": "https://arxiv.org/abs/2505.10402", "authors": ["Yihong Dong", "Yuchen Liu", "Xue Jiang", "Zhi Jin", "Ge Li"], "title": "Rethinking Repetition Problems of LLMs in Code Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to ACL 2025 (main)", "summary": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.10533", "pdf": "https://arxiv.org/pdf/2505.10533", "abs": "https://arxiv.org/abs/2505.10533", "authors": ["Aaryan Sharma", "Shivansh Gupta", "Samar Agarwal", "Vishak Prasad C.", "Ganesh Ramakrishnan"], "title": "Enhancing Multi-Image Question Answering via Submodular Subset Selection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Large multimodal models (LMMs) have achieved high performance in\nvision-language tasks involving single image but they struggle when presented\nwith a collection of multiple images (Multiple Image Question Answering\nscenario). These tasks, which involve reasoning over large number of images,\npresent issues in scalability (with increasing number of images) and retrieval\nperformance. In this work, we propose an enhancement for retriever framework\nintroduced in MIRAGE model using submodular subset selection techniques. Our\nmethod leverages query-aware submodular functions, such as GraphCut, to\npre-select a subset of semantically relevant images before main retrieval\ncomponent. We demonstrate that using anchor-based queries and augmenting the\ndata improves submodular-retriever pipeline effectiveness, particularly in\nlarge haystack sizes."}
{"id": "2505.09649", "pdf": "https://arxiv.org/pdf/2505.09649", "abs": "https://arxiv.org/abs/2505.09649", "authors": ["Abisha Thapa Magar", "Anup Shakya"], "title": "Next Word Suggestion using Graph Neural Network", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Language Modeling is a prevalent task in Natural Language Processing. The\ncurrently existing most recent and most successful language models often tend\nto build a massive model with billions of parameters, feed in a tremendous\namount of text data, and train with enormous computation resources which\nrequire millions of dollars. In this project, we aim to address an important\nsub-task in language modeling, i.e., context embedding. We propose an approach\nto exploit the Graph Convolution operation in GNNs to encode the context and\nuse it in coalition with LSTMs to predict the next word given a local context\nof preceding words. We test this on the custom Wikipedia text corpus using a\nvery limited amount of resources and show that this approach works fairly well\nto predict the next word."}
{"id": "2505.09655", "pdf": "https://arxiv.org/pdf/2505.09655", "abs": "https://arxiv.org/abs/2505.09655", "authors": ["Xiwen Chen", "Wenhui Zhu", "Peijie Qiu", "Xuanzhao Dong", "Hao Wang", "Haiyu Wu", "Huayu Li", "Aristeidis Sotiras", "Yalin Wang", "Abolfazl Razi"], "title": "DRA-GRPO: Exploring Diversity-Aware Reward Adjustment for R1-Zero-Like Training of Large Language Models", "categories": ["cs.CL"], "comment": null, "summary": "Recent advances in reinforcement learning for language model post-training,\nsuch as Group Relative Policy Optimization (GRPO), have shown promise in\nlow-resource settings. However, GRPO typically relies on solution-level and\nscalar reward signals that fail to capture the semantic diversity among sampled\ncompletions. This leads to what we identify as a diversity-quality\ninconsistency, where distinct reasoning paths may receive indistinguishable\nrewards. To address this limitation, we propose $\\textit{Diversity-aware Reward\nAdjustment}$ (DRA), a method that explicitly incorporates semantic diversity\ninto the reward computation. DRA uses Submodular Mutual Information (SMI) to\ndownweight redundant completions and amplify rewards for diverse ones. This\nencourages better exploration during learning, while maintaining stable\nexploitation of high-quality samples. Our method integrates seamlessly with\nboth GRPO and its variant DR.~GRPO, resulting in $\\textit{DRA-GRPO}$ and\n$\\textit{DGA-DR.~GRPO}$. We evaluate our method on five mathematical reasoning\nbenchmarks and find that it outperforms recent strong baselines. It achieves\nstate-of-the-art performance with an average accuracy of 58.2%, using only\n7,000 fine-tuning samples and a total training cost of approximately $55. The\ncode is available at https://github.com/xiwenc1/DRA-GRPO."}
{"id": "2505.09662", "pdf": "https://arxiv.org/pdf/2505.09662", "abs": "https://arxiv.org/abs/2505.09662", "authors": ["Philipp Schoenegger", "Francesco Salvi", "Jiacheng Liu", "Xiaoli Nan", "Ramit Debnath", "Barbara Fasolo", "Evelina Leivada", "Gabriel Recchia", "Fritz Günther", "Ali Zarifhonarvar", "Joe Kwon", "Zahoor Ul Islam", "Marco Dehnert", "Daryl Y. H. Lee", "Madeline G. Reinecke", "David G. Kamper", "Mert Kobaş", "Adam Sandford", "Jonas Kgomo", "Luke Hewitt", "Shreya Kapoor", "Kerem Oktar", "Eyup Engin Kucuk", "Bo Feng", "Cameron R. Jones", "Izzy Gainsburg", "Sebastian Olschewski", "Nora Heinzelmann", "Francisco Cruz", "Ben M. Tappin", "Tao Ma", "Peter S. Park", "Rayan Onyonka", "Arthur Hjorth", "Peter Slattery", "Qingcheng Zeng", "Lennart Finke", "Igor Grossmann", "Alessandro Salatiello", "Ezra Karger"], "title": "Large Language Models Are More Persuasive Than Incentivized Human Persuaders", "categories": ["cs.CL", "I.2.7; H.1.2; K.4.1; H.5.2"], "comment": null, "summary": "We directly compare the persuasion capabilities of a frontier large language\nmodel (LLM; Claude Sonnet 3.5) against incentivized human persuaders in an\ninteractive, real-time conversational quiz setting. In this preregistered,\nlarge-scale incentivized experiment, participants (quiz takers) completed an\nonline quiz where persuaders (either humans or LLMs) attempted to persuade quiz\ntakers toward correct or incorrect answers. We find that LLM persuaders\nachieved significantly higher compliance with their directional persuasion\nattempts than incentivized human persuaders, demonstrating superior persuasive\ncapabilities in both truthful (toward correct answers) and deceptive (toward\nincorrect answers) contexts. We also find that LLM persuaders significantly\nincreased quiz takers' accuracy, leading to higher earnings, when steering quiz\ntakers toward correct answers, and significantly decreased their accuracy,\nleading to lower earnings, when steering them toward incorrect answers.\nOverall, our findings suggest that AI's persuasion capabilities already exceed\nthose of humans that have real-money bonuses tied to performance. Our findings\nof increasingly capable AI persuaders thus underscore the urgency of emerging\nalignment and governance frameworks."}
{"id": "2505.09666", "pdf": "https://arxiv.org/pdf/2505.09666", "abs": "https://arxiv.org/abs/2505.09666", "authors": ["Yumin Choi", "Jinheon Baek", "Sung Ju Hwang"], "title": "System Prompt Optimization with Meta-Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance."}
{"id": "2505.09639", "pdf": "https://arxiv.org/pdf/2505.09639", "abs": "https://arxiv.org/abs/2505.09639", "authors": ["Quentin Cohen-Solal"], "title": "Study and improvement of search algorithms in two-players perfect information games", "categories": ["cs.AI", "cs.GT"], "comment": null, "summary": "Games, in their mathematical sense, are everywhere (game industries,\neconomics, defense, education, chemistry, biology, ...).Search algorithms in\ngames are artificial intelligence methods for playing such games.\nUnfortunately, there is no study on these algorithms that evaluates the\ngenerality of their performance. We propose to address this gap in the case of\ntwo-player zero-sum games with perfect information. Furthermore, we propose a\nnew search algorithm and we show that, for a short search time, it outperforms\nall studied algorithms on all games in this large experiment and that, for a\nmedium search time, it outperforms all studied algorithms on 17 of the 22\nstudied games."}
{"id": "2505.09746", "pdf": "https://arxiv.org/pdf/2505.09746", "abs": "https://arxiv.org/abs/2505.09746", "authors": ["Xabier Morales", "Ayah Elsayed", "Debbie Zhao", "Filip Loncaric", "Ainhoa Aguado", "Mireia Masias", "Gina Quill", "Marc Ramos", "Ada Doltra", "Ana Garcia", "Marta Sitges", "David Marlevi", "Alistair Young", "Martyn Nash", "Bart Bijnens", "Oscar Camara"], "title": "A Computational Pipeline for Advanced Analysis of 4D Flow MRI in the Left Atrium", "categories": ["cs.CV"], "comment": null, "summary": "The left atrium (LA) plays a pivotal role in modulating left ventricular\nfilling, but our comprehension of its hemodynamics is significantly limited by\nthe constraints of conventional ultrasound analysis. 4D flow magnetic resonance\nimaging (4D Flow MRI) holds promise for enhancing our understanding of atrial\nhemodynamics. However, the low velocities within the LA and the limited spatial\nresolution of 4D Flow MRI make analyzing this chamber challenging. Furthermore,\nthe absence of dedicated computational frameworks, combined with diverse\nacquisition protocols and vendors, complicates gathering large cohorts for\nstudying the prognostic value of hemodynamic parameters provided by 4D Flow\nMRI. In this study, we introduce the first open-source computational framework\ntailored for the analysis of 4D Flow MRI in the LA, enabling comprehensive\nqualitative and quantitative analysis of advanced hemodynamic parameters. Our\nframework proves robust to data from different centers of varying quality,\nproducing high-accuracy automated segmentations (Dice $>$ 0.9 and Hausdorff 95\n$<$ 3 mm), even with limited training data. Additionally, we conducted the\nfirst comprehensive assessment of energy, vorticity, and pressure parameters in\nthe LA across a spectrum of disorders to investigate their potential as\nprognostic biomarkers."}
{"id": "2505.09659", "pdf": "https://arxiv.org/pdf/2505.09659", "abs": "https://arxiv.org/abs/2505.09659", "authors": ["Long Chen", "Xiaotian Song", "Yanan Sun"], "title": "LAS: Loss-less ANN-SNN Conversion for Fully Spike-Driven Large Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Spiking Large Language Models (LLMs) have emerged as an energy-efficient\nalternative to conventional LLMs through their event-driven computation. To\neffectively obtain spiking LLMs, researchers develop different ANN-to-SNN\nconversion methods by leveraging pre-trained ANN parameters while inheriting\nthe energy efficiency of SNN. However, existing conversion methods struggle\nwith extreme activation outliers and incompatible nonlinear operations of\nANN-based LLMs. To address this, we propose a loss-less ANN-SNN conversion for\nfully spike-driven LLMs, termed LAS. Specifically, LAS introduces two novel\nneurons to convert the activation outlier and nonlinear operation of ANN-based\nLLMs. Moreover, LAS tailors the spike-equivalent Transformer components for\nspiking LLMs, which can ensure full spiking conversion without any loss of\nperformance. Experimental results on six language models and two\nvision-language models demonstrate that LAS achieves loss-less conversion.\nNotably, on OPT-66B, LAS even improves the accuracy of 2\\% on the WSC task. In\naddition, the parameter and ablation studies further verify the effectiveness\nof LAS. The source code is available at https://github.com/lc783/LAS"}
{"id": "2505.09701", "pdf": "https://arxiv.org/pdf/2505.09701", "abs": "https://arxiv.org/abs/2505.09701", "authors": ["Xin Liu", "Lechen Zhang", "Sheza Munir", "Yiyang Gu", "Lu Wang"], "title": "VeriFact: Enhancing Long-Form Factuality Evaluation with Refined Fact Extraction and Reference Facts", "categories": ["cs.CL"], "comment": null, "summary": "Large language models (LLMs) excel at generating long-form responses, but\nevaluating their factuality remains challenging due to complex inter-sentence\ndependencies within the generated facts. Prior solutions predominantly follow a\ndecompose-decontextualize-verify pipeline but often fail to capture essential\ncontext and miss key relational facts. In this paper, we introduce VeriFact, a\nfactuality evaluation framework designed to enhance fact extraction by\nidentifying and resolving incomplete and missing facts to support more accurate\nverification results. Moreover, we introduce FactRBench , a benchmark that\nevaluates both precision and recall in long-form model responses, whereas prior\nwork primarily focuses on precision. FactRBench provides reference fact sets\nfrom advanced LLMs and human-written answers, enabling recall assessment.\nEmpirical evaluations show that VeriFact significantly enhances fact\ncompleteness and preserves complex facts with critical relational information,\nresulting in more accurate factuality evaluation. Benchmarking various open-\nand close-weight LLMs on FactRBench indicate that larger models within same\nmodel family improve precision and recall, but high precision does not always\ncorrelate with high recall, underscoring the importance of comprehensive\nfactuality assessment."}
{"id": "2505.09640", "pdf": "https://arxiv.org/pdf/2505.09640", "abs": "https://arxiv.org/abs/2505.09640", "authors": ["Tomás Capdevielle", "Santiago Cifuentes"], "title": "Feature Relevancy, Necessity and Usefulness: Complexity and Algorithms", "categories": ["cs.AI", "68T01", "I.2.0"], "comment": "22 pages, 7 figures", "summary": "Given a classification model and a prediction for some input, there are\nheuristic strategies for ranking features according to their importance in\nregard to the prediction. One common approach to this task is rooted in\npropositional logic and the notion of \\textit{sufficient reason}. Through this\nconcept, the categories of relevant and necessary features were proposed in\norder to identify the crucial aspects of the input. This paper improves the\nexisting techniques and algorithms for deciding which are the relevant and/or\nnecessary features, showing in particular that necessity can be detected\nefficiently in complex models such as neural networks. We also generalize the\nnotion of relevancy and study associated problems. Moreover, we present a new\nglobal notion (i.e. that intends to explain whether a feature is important for\nthe behavior of the model in general, not depending on a particular input) of\n\\textit{usefulness} and prove that it is related to relevancy and necessity.\nFurthermore, we develop efficient algorithms for detecting it in decision trees\nand other more complex models, and experiment on three datasets to analyze its\npractical utility."}
{"id": "2505.09827", "pdf": "https://arxiv.org/pdf/2505.09827", "abs": "https://arxiv.org/abs/2505.09827", "authors": ["Julian Tanke", "Takashi Shibuya", "Kengo Uchida", "Koichi Saito", "Yuki Mitsufuji"], "title": "Dyadic Mamba: Long-term Dyadic Human Motion Synthesis", "categories": ["cs.CV"], "comment": "CVPR 2025 HuMoGen Workshop", "summary": "Generating realistic dyadic human motion from text descriptions presents\nsignificant challenges, particularly for extended interactions that exceed\ntypical training sequence lengths. While recent transformer-based approaches\nhave shown promising results for short-term dyadic motion synthesis, they\nstruggle with longer sequences due to inherent limitations in positional\nencoding schemes. In this paper, we introduce Dyadic Mamba, a novel approach\nthat leverages State-Space Models (SSMs) to generate high-quality dyadic human\nmotion of arbitrary length. Our method employs a simple yet effective\narchitecture that facilitates information flow between individual motion\nsequences through concatenation, eliminating the need for complex\ncross-attention mechanisms. We demonstrate that Dyadic Mamba achieves\ncompetitive performance on standard short-term benchmarks while significantly\noutperforming transformer-based approaches on longer sequences. Additionally,\nwe propose a new benchmark for evaluating long-term motion synthesis quality,\nproviding a standardized framework for future research. Our results demonstrate\nthat SSM-based architectures offer a promising direction for addressing the\nchallenging task of long-term dyadic human motion synthesis from text\ndescriptions."}
{"id": "2505.09663", "pdf": "https://arxiv.org/pdf/2505.09663", "abs": "https://arxiv.org/abs/2505.09663", "authors": ["Julian Büchel", "Iason Chalas", "Giovanni Acampa", "An Chen", "Omobayode Fagbohungbe", "Sidney Tsai", "Kaoutar El Maghraoui", "Manuel Le Gallo", "Abbas Rahimi", "Abu Sebastian"], "title": "Analog Foundation Models", "categories": ["cs.LG"], "comment": "43 pages, 8 figures, under review", "summary": "Analog in-memory computing (AIMC) is a promising compute paradigm to improve\nspeed and power efficiency of neural network inference beyond the limits of\nconventional von Neumann-based architectures. However, AIMC introduces\nfundamental challenges such as noisy computations and strict constraints on\ninput and output quantization. Because of these constraints and imprecisions,\noff-the-shelf LLMs are not able to achieve 4-bit-level performance when\ndeployed on AIMC-based hardware. While researchers previously investigated\nrecovering this accuracy gap on small, mostly vision-based models, a generic\nmethod applicable to LLMs pre-trained on trillions of tokens does not yet\nexist. In this work, we introduce a general and scalable method to robustly\nadapt LLMs for execution on noisy, low-precision analog hardware. Our approach\nenables state-of-the-art models $\\unicode{x2013}$ including\nPhi-3-mini-4k-instruct and Llama-3.2-1B-Instruct $\\unicode{x2013}$ to retain\nperformance comparable to 4-bit weight, 8-bit activation baselines, despite the\npresence of analog noise and quantization constraints. Additionally, we show\nthat as a byproduct of our training methodology, analog foundation models can\nbe quantized for inference on low-precision digital hardware. Finally, we show\nthat our models also benefit from test-time compute scaling, showing better\nscaling behavior than models trained with 4-bit weight and 8-bit static input\nquantization. Our work bridges the gap between high-capacity LLMs and efficient\nanalog hardware, offering a path toward energy-efficient foundation models.\nCode is available at https://github.com/IBM/analog-foundation-models ."}
{"id": "2505.09724", "pdf": "https://arxiv.org/pdf/2505.09724", "abs": "https://arxiv.org/abs/2505.09724", "authors": ["Gino Carmona-Díaz", "William Jiménez-Leal", "María Alejandra Grisales", "Chandra Sripada", "Santiago Amaya", "Michael Inzlicht", "Juan Pablo Bermúdez"], "title": "An AI-Powered Research Assistant in the Lab: A Practical Guide for Text Analysis Through Iterative Collaboration with LLMs", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "31 pages, 1 figure", "summary": "Analyzing texts such as open-ended responses, headlines, or social media\nposts is a time- and labor-intensive process highly susceptible to bias. LLMs\nare promising tools for text analysis, using either a predefined (top-down) or\na data-driven (bottom-up) taxonomy, without sacrificing quality. Here we\npresent a step-by-step tutorial to efficiently develop, test, and apply\ntaxonomies for analyzing unstructured data through an iterative and\ncollaborative process between researchers and LLMs. Using personal goals\nprovided by participants as an example, we demonstrate how to write prompts to\nreview datasets and generate a taxonomy of life domains, evaluate and refine\nthe taxonomy through prompt and direct modifications, test the taxonomy and\nassess intercoder agreements, and apply the taxonomy to categorize an entire\ndataset with high intercoder reliability. We discuss the possibilities and\nlimitations of using LLMs for text analysis."}
{"id": "2505.09737", "pdf": "https://arxiv.org/pdf/2505.09737", "abs": "https://arxiv.org/abs/2505.09737", "authors": ["Osher Elhadad", "Reuth Mirsky"], "title": "General Dynamic Goal Recognition", "categories": ["cs.AI", "cs.RO"], "comment": "Accepted for publication at Generalization in Planning (GenPlan) as\n  part of AAAI 2025 workshops", "summary": "Understanding an agent's intent through its behavior is essential in\nhuman-robot interaction, interactive AI systems, and multi-agent\ncollaborations. This task, known as Goal Recognition (GR), poses significant\nchallenges in dynamic environments where goals are numerous and constantly\nevolving. Traditional GR methods, designed for a predefined set of goals, often\nstruggle to adapt to these dynamic scenarios. To address this limitation, we\nintroduce the General Dynamic GR problem - a broader definition of GR - aimed\nat enabling real-time GR systems and fostering further research in this area.\nExpanding on this foundation, this paper employs a model-free goal-conditioned\nRL approach to enable fast adaptation for GR across various changing tasks."}
{"id": "2505.09829", "pdf": "https://arxiv.org/pdf/2505.09829", "abs": "https://arxiv.org/abs/2505.09829", "authors": ["Tushar Kataria", "Shireen Y. Elhabian"], "title": "BoundarySeg:An Embarrassingly Simple Method To Boost Medical Image Segmentation Performance for Low Data Regimes", "categories": ["cs.CV"], "comment": null, "summary": "Obtaining large-scale medical data, annotated or unannotated, is challenging\ndue to stringent privacy regulations and data protection policies. In addition,\nannotating medical images requires that domain experts manually delineate\nanatomical structures, making the process both time-consuming and costly. As a\nresult, semi-supervised methods have gained popularity for reducing annotation\ncosts. However, the performance of semi-supervised methods is heavily dependent\non the availability of unannotated data, and their effectiveness declines when\nsuch data are scarce or absent. To overcome this limitation, we propose a\nsimple, yet effective and computationally efficient approach for medical image\nsegmentation that leverages only existing annotations. We propose BoundarySeg ,\na multi-task framework that incorporates organ boundary prediction as an\nauxiliary task to full organ segmentation, leveraging consistency between the\ntwo task predictions to provide additional supervision. This strategy improves\nsegmentation accuracy, especially in low data regimes, allowing our method to\nachieve performance comparable to or exceeding state-of-the-art semi supervised\napproaches all without relying on unannotated data or increasing computational\ndemands. Code will be released upon acceptance."}
{"id": "2505.09702", "pdf": "https://arxiv.org/pdf/2505.09702", "abs": "https://arxiv.org/abs/2505.09702", "authors": ["Yezi Liu", "Prathyush Poduval", "Wenjun Huang", "Yang Ni", "Hanning Chen", "Mohsen Imani"], "title": "Enabling Group Fairness in Graph Unlearning via Bi-level Debiasing", "categories": ["cs.LG"], "comment": null, "summary": "Graph unlearning is a crucial approach for protecting user privacy by erasing\nthe influence of user data on trained graph models. Recent developments in\ngraph unlearning methods have primarily focused on maintaining model prediction\nperformance while removing user information. However, we have observed that\nwhen user information is deleted from the model, the prediction distribution\nacross different sensitive groups often changes. Furthermore, graph models are\nshown to be prone to amplifying biases, making the study of fairness in graph\nunlearning particularly important. This raises the question: Does graph\nunlearning actually introduce bias? Our findings indicate that the predictions\nof post-unlearning models become highly correlated with sensitive attributes,\nconfirming the introduction of bias in the graph unlearning process. To address\nthis issue, we propose a fair graph unlearning method, FGU. To guarantee\nprivacy, FGU trains shard models on partitioned subgraphs, unlearns the\nrequested data from the corresponding subgraphs, and retrains the shard models\non the modified subgraphs. To ensure fairness, FGU employs a bi-level debiasing\nprocess: it first enables shard-level fairness by incorporating a fairness\nregularizer in the shard model retraining, and then achieves global-level\nfairness by aligning all shard models to minimize global disparity. Our\nexperiments demonstrate that FGU achieves superior fairness while maintaining\nprivacy and accuracy. Additionally, FGU is robust to diverse unlearning\nrequests, ensuring fairness and utility performance across various data\ndistributions."}
{"id": "2505.09738", "pdf": "https://arxiv.org/pdf/2505.09738", "abs": "https://arxiv.org/abs/2505.09738", "authors": ["Shaurya Sharthak", "Vinayak Pahalwan", "Adithya Kamath", "Adarsh Shirawalmath"], "title": "Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Pretrained language models (LLMs) are often constrained by their fixed\ntokenization schemes, leading to inefficiencies and performance limitations,\nparticularly for multilingual or specialized applications. This tokenizer\nlock-in presents significant challenges. standard methods to overcome this\noften require prohibitive computational resources. Although tokenizer\nreplacement with heuristic initialization aims to reduce this burden, existing\nmethods often require exhaustive residual fine-tuning and still may not fully\npreserve semantic nuances or adequately address the underlying compression\ninefficiencies. Our framework introduces two innovations: first, Tokenadapt, a\nmodel-agnostic tokenizer transplantation method, and second, novel\npre-tokenization learning for multi-word Supertokens to enhance compression and\nreduce fragmentation. Tokenadapt initializes new unique token embeddings via a\nhybrid heuristic that combines two methods: a local estimate based on subword\ndecomposition using the old tokenizer, and a global estimate utilizing the\ntop-k semantically similar tokens from the original vocabulary. This\nmethodology aims to preserve semantics while significantly minimizing\nretraining requirements. Empirical investigations validate both contributions:\nthe transplantation heuristic successfully initializes unique tokens, markedly\noutperforming conventional baselines and sophisticated methods including\nTranstokenizer and ReTok, while our Supertokens achieve notable compression\ngains. Our zero-shot perplexity results demonstrate that the TokenAdapt hybrid\ninitialization consistently yields lower perplexity ratios compared to both\nReTok and TransTokenizer baselines across different base models and newly\ntrained target tokenizers. TokenAdapt typically reduced the overall perplexity\nratio significantly compared to ReTok, yielding at least a 2-fold improvement\nin these aggregate scores."}
{"id": "2505.09755", "pdf": "https://arxiv.org/pdf/2505.09755", "abs": "https://arxiv.org/abs/2505.09755", "authors": ["Amy Rafferty", "Rishi Ramaesh", "Ajitha Rajan"], "title": "Explainability Through Human-Centric Design for XAI in Lung Cancer Detection", "categories": ["cs.AI"], "comment": null, "summary": "Deep learning models have shown promise in lung pathology detection from\nchest X-rays, but widespread clinical adoption remains limited due to opaque\nmodel decision-making. In prior work, we introduced ClinicXAI, a human-centric,\nexpert-guided concept bottleneck model (CBM) designed for interpretable lung\ncancer diagnosis. We now extend that approach and present XpertXAI, a\ngeneralizable expert-driven model that preserves human-interpretable clinical\nconcepts while scaling to detect multiple lung pathologies. Using a\nhigh-performing InceptionV3-based classifier and a public dataset of chest\nX-rays with radiology reports, we compare XpertXAI against leading post-hoc\nexplainability methods and an unsupervised CBM, XCBs. We assess explanations\nthrough comparison with expert radiologist annotations and medical ground\ntruth. Although XpertXAI is trained for multiple pathologies, our expert\nvalidation focuses on lung cancer. We find that existing techniques frequently\nfail to produce clinically meaningful explanations, omitting key diagnostic\nfeatures and disagreeing with radiologist judgments. XpertXAI not only\noutperforms these baselines in predictive accuracy but also delivers\nconcept-level explanations that better align with expert reasoning. While our\nfocus remains on explainability in lung cancer detection, this work illustrates\nhow human-centric model design can be effectively extended to broader\ndiagnostic contexts - offering a scalable path toward clinically meaningful\nexplainable AI in medical diagnostics."}
{"id": "2505.09858", "pdf": "https://arxiv.org/pdf/2505.09858", "abs": "https://arxiv.org/abs/2505.09858", "authors": ["Danush Kumar Venkatesh", "Isabel Funke", "Micha Pfeiffer", "Fiona Kolbinger", "Hanna Maria Schmeiser", "Juergen Weitz", "Marius Distler", "Stefanie Speidel"], "title": "Mission Balance: Generating Under-represented Class Samples using Video Diffusion Models", "categories": ["cs.CV"], "comment": "Early accept at MICCAI 2025", "summary": "Computer-assisted interventions can improve intra-operative guidance,\nparticularly through deep learning methods that harness the spatiotemporal\ninformation in surgical videos. However, the severe data imbalance often found\nin surgical video datasets hinders the development of high-performing models.\nIn this work, we aim to overcome the data imbalance by synthesizing surgical\nvideos. We propose a unique two-stage, text-conditioned diffusion-based method\nto generate high-fidelity surgical videos for under-represented classes. Our\napproach conditions the generation process on text prompts and decouples\nspatial and temporal modeling by utilizing a 2D latent diffusion model to\ncapture spatial content and then integrating temporal attention layers to\nensure temporal consistency. Furthermore, we introduce a rejection sampling\nstrategy to select the most suitable synthetic samples, effectively augmenting\nexisting datasets to address class imbalance. We evaluate our method on two\ndownstream tasks-surgical action recognition and intra-operative event\nprediction-demonstrating that incorporating synthetic videos from our approach\nsubstantially enhances model performance. We open-source our implementation at\nhttps://gitlab.com/nct_tso_public/surgvgen."}
{"id": "2505.09704", "pdf": "https://arxiv.org/pdf/2505.09704", "abs": "https://arxiv.org/abs/2505.09704", "authors": ["Roberto Pereira", "Fernanda Famá", "Charalampos Kalalas", "Paolo Dini"], "title": "Energy-Efficient Federated Learning for AIoT using Clustering Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While substantial research has been devoted to optimizing model performance,\nconvergence rates, and communication efficiency, the energy implications of\nfederated learning (FL) within Artificial Intelligence of Things (AIoT)\nscenarios are often overlooked in the existing literature. This study examines\nthe energy consumed during the FL process, focusing on three main\nenergy-intensive processes: pre-processing, communication, and local learning,\nall contributing to the overall energy footprint. We rely on the observation\nthat device/client selection is crucial for speeding up the convergence of\nmodel training in a distributed AIoT setting and propose two\nclustering-informed methods. These clustering solutions are designed to group\nAIoT devices with similar label distributions, resulting in clusters composed\nof nearly heterogeneous devices. Hence, our methods alleviate the heterogeneity\noften encountered in real-world distributed learning applications. Throughout\nextensive numerical experimentation, we demonstrate that our clustering\nstrategies typically achieve high convergence rates while maintaining low\nenergy consumption when compared to other recent approaches available in the\nliterature."}
{"id": "2505.09794", "pdf": "https://arxiv.org/pdf/2505.09794", "abs": "https://arxiv.org/abs/2505.09794", "authors": ["J. Moreno-Casanova", "J. M. Auñón", "A. Mártinez-Pérez", "M. E. Pérez-Martínez", "M. E. Gas-López"], "title": "Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Research projects, including those focused on cancer, rely on the manual\nextraction of information from clinical reports. This process is time-consuming\nand prone to errors, limiting the efficiency of data-driven approaches in\nhealthcare. To address these challenges, Natural Language Processing (NLP)\noffers an alternative for automating the extraction of relevant data from\nelectronic health records (EHRs). In this study, we focus on lung and breast\ncancer due to their high incidence and the significant impact they have on\npublic health. Early detection and effective data management in both types of\ncancer are crucial for improving patient outcomes. To enhance the accuracy and\nefficiency of data extraction, we utilized GMV's NLP tool uQuery, which excels\nat identifying relevant entities in clinical texts and converting them into\nstandardized formats such as SNOMED and OMOP. uQuery not only detects and\nclassifies entities but also associates them with contextual information,\nincluding negated entities, temporal aspects, and patient-related details. In\nthis work, we explore the use of NLP techniques, specifically Named Entity\nRecognition (NER), to automatically identify and extract key clinical\ninformation from EHRs related to these two cancers. A dataset from Health\nResearch Institute Hospital La Fe (IIS La Fe), comprising 200 annotated breast\ncancer and 400 lung cancer reports, was used, with eight clinical entities\nmanually labeled using the Doccano platform. To perform NER, we fine-tuned the\nbsc-bio-ehr-en3 model, a RoBERTa-based biomedical linguistic model pre-trained\nin Spanish. Fine-tuning was performed using the Transformers architecture,\nenabling accurate recognition of clinical entities in these cancer types. Our\nresults demonstrate strong overall performance, particularly in identifying\nentities like MET and PAT, although challenges remain with less frequent\nentities like EVOL."}
{"id": "2505.09787", "pdf": "https://arxiv.org/pdf/2505.09787", "abs": "https://arxiv.org/abs/2505.09787", "authors": ["Ziruo Yi", "Ting Xiao", "Mark V. Albert"], "title": "A Multimodal Multi-Agent Framework for Radiology Report Generation", "categories": ["cs.AI"], "comment": null, "summary": "Radiology report generation (RRG) aims to automatically produce diagnostic\nreports from medical images, with the potential to enhance clinical workflows\nand reduce radiologists' workload. While recent approaches leveraging\nmultimodal large language models (MLLMs) and retrieval-augmented generation\n(RAG) have achieved strong results, they continue to face challenges such as\nfactual inconsistency, hallucination, and cross-modal misalignment. We propose\na multimodal multi-agent framework for RRG that aligns with the stepwise\nclinical reasoning workflow, where task-specific agents handle retrieval, draft\ngeneration, visual analysis, refinement, and synthesis. Experimental results\ndemonstrate that our approach outperforms a strong baseline in both automatic\nmetrics and LLM-based evaluations, producing more accurate, structured, and\ninterpretable reports. This work highlights the potential of clinically aligned\nmulti-agent frameworks to support explainable and trustworthy clinical AI\napplications."}
{"id": "2505.09859", "pdf": "https://arxiv.org/pdf/2505.09859", "abs": "https://arxiv.org/abs/2505.09859", "authors": ["Andrew Jun Lee", "Taylor Webb", "Trevor Bihl", "Keith Holyoak", "Hongjing Lu"], "title": "Few-Shot Learning of Visual Compositional Concepts through Probabilistic Schema Induction", "categories": ["cs.CV"], "comment": "Lee, A. J., Webb, T., Bihl, T., Holyoak, K. J., & Lu, H. (2025).\n  Few-shot learning of visual compositional concepts through probabilistic\n  schema induction. In A. Ruggeri, D. Barner, C. Walker, & N. Bramley (Eds.),\n  Proceedings of the 47th Annual Conference of the Cognitive Science Society.\n  Cognitive Science Society", "summary": "The ability to learn new visual concepts from limited examples is a hallmark\nof human cognition. While traditional category learning models represent each\nexample as an unstructured feature vector, compositional concept learning is\nthought to depend on (1) structured representations of examples (e.g., directed\ngraphs consisting of objects and their relations) and (2) the identification of\nshared relational structure across examples through analogical mapping. Here,\nwe introduce Probabilistic Schema Induction (PSI), a prototype model that\nemploys deep learning to perform analogical mapping over structured\nrepresentations of only a handful of examples, forming a compositional concept\ncalled a schema. In doing so, PSI relies on a novel conception of similarity\nthat weighs object-level similarity and relational similarity, as well as a\nmechanism for amplifying relations relevant to classification, analogous to\nselective attention parameters in traditional models. We show that PSI produces\nhuman-like learning performance and outperforms two controls: a prototype model\nthat uses unstructured feature vectors extracted from a deep learning model,\nand a variant of PSI with weaker structured representations. Notably, we find\nthat PSI's human-like performance is driven by an adaptive strategy that\nincreases relational similarity over object-level similarity and upweights the\ncontribution of relations that distinguish classes. These findings suggest that\nstructured representations and analogical mapping are critical to modeling\nrapid human-like learning of compositional visual concepts, and demonstrate how\ndeep learning can be leveraged to create psychological models."}
{"id": "2505.09710", "pdf": "https://arxiv.org/pdf/2505.09710", "abs": "https://arxiv.org/abs/2505.09710", "authors": ["Konstantinos Fotopoulos", "Petros Maragos"], "title": "Training Deep Morphological Neural Networks as Universal Approximators", "categories": ["cs.LG"], "comment": null, "summary": "We investigate deep morphological neural networks (DMNNs). We demonstrate\nthat despite their inherent non-linearity, activations between layers are\nessential for DMNNs. We then propose several new architectures for DMNNs, each\nwith a different constraint on their parameters. For the first (resp. second)\narchitecture, we work under the constraint that the majority of parameters\n(resp. learnable parameters) should be part of morphological operations. We\nempirically show that our proposed networks can be successfully trained, and\nare more prunable than linear networks. To the best of our knowledge, we are\nthe first to successfully train DMNNs under such constraints, although the\ngeneralization capabilities of our networks remain limited. Finally, we propose\na hybrid network architecture combining linear and morphological layers,\nshowing empirically that the inclusion of morphological layers significantly\naccelerates the convergence of gradient descent with large batches."}
{"id": "2505.09807", "pdf": "https://arxiv.org/pdf/2505.09807", "abs": "https://arxiv.org/abs/2505.09807", "authors": ["Timour Ichmoukhamedov", "David Martens"], "title": "Exploring the generalization of LLM truth directions on conversational formats", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Several recent works argue that LLMs have a universal truth direction where\ntrue and false statements are linearly separable in the activation space of the\nmodel. It has been demonstrated that linear probes trained on a single hidden\nstate of the model already generalize across a range of topics and might even\nbe used for lie detection in LLM conversations. In this work we explore how\nthis truth direction generalizes between various conversational formats. We\nfind good generalization between short conversations that end on a lie, but\npoor generalization to longer formats where the lie appears earlier in the\ninput prompt. We propose a solution that significantly improves this type of\ngeneralization by adding a fixed key phrase at the end of each conversation.\nOur results highlight the challenges towards reliable LLM lie detectors that\ngeneralize to new settings."}
{"id": "2505.09920", "pdf": "https://arxiv.org/pdf/2505.09920", "abs": "https://arxiv.org/abs/2505.09920", "authors": ["Shan Yang", "Yongli Zhu"], "title": "Offline Reinforcement Learning for Microgrid Voltage Regulation", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore,\n  Apr. 28, 2025", "summary": "This paper presents a study on using different offline reinforcement learning\nalgorithms for microgrid voltage regulation with solar power penetration. When\nenvironment interaction is unviable due to technical or safety reasons, the\nproposed approach can still obtain an applicable model through offline-style\ntraining on a previously collected dataset, lowering the negative impact of\nlacking online environment interactions. Experiment results on the IEEE 33-bus\nsystem demonstrate the feasibility and effectiveness of the proposed approach\non different offline datasets, including the one with merely low-quality\nexperience."}
{"id": "2505.09915", "pdf": "https://arxiv.org/pdf/2505.09915", "abs": "https://arxiv.org/abs/2505.09915", "authors": ["Zhe Xin", "Chenyang Wu", "Penghui Huang", "Yanyong Zhang", "Yinian Mao", "Guoquan Huang"], "title": "Large-Scale Gaussian Splatting SLAM", "categories": ["cs.CV", "cs.RO"], "comment": null, "summary": "The recently developed Neural Radiance Fields (NeRF) and 3D Gaussian\nSplatting (3DGS) have shown encouraging and impressive results for visual SLAM.\nHowever, most representative methods require RGBD sensors and are only\navailable for indoor environments. The robustness of reconstruction in\nlarge-scale outdoor scenarios remains unexplored. This paper introduces a\nlarge-scale 3DGS-based visual SLAM with stereo cameras, termed LSG-SLAM. The\nproposed LSG-SLAM employs a multi-modality strategy to estimate prior poses\nunder large view changes. In tracking, we introduce feature-alignment warping\nconstraints to alleviate the adverse effects of appearance similarity in\nrendering losses. For the scalability of large-scale scenarios, we introduce\ncontinuous Gaussian Splatting submaps to tackle unbounded scenes with limited\nmemory. Loops are detected between GS submaps by place recognition and the\nrelative pose between looped keyframes is optimized utilizing rendering and\nfeature warping losses. After the global optimization of camera poses and\nGaussian points, a structure refinement module enhances the reconstruction\nquality. With extensive evaluations on the EuRoc and KITTI datasets, LSG-SLAM\nachieves superior performance over existing Neural, 3DGS-based, and even\ntraditional approaches. Project page: https://lsg-slam.github.io."}
{"id": "2505.09716", "pdf": "https://arxiv.org/pdf/2505.09716", "abs": "https://arxiv.org/abs/2505.09716", "authors": ["George Dimitriadis. Spyridon Samothrakis"], "title": "Out-of-distribution generalisation is hard: evidence from ARC-like tasks", "categories": ["cs.LG", "cs.AI"], "comment": "Submission to NeurIPS 2025", "summary": "Out-of-distribution (OOD) generalisation is considered a hallmark of human\nand animal intelligence. To achieve OOD through composition, a system must\ndiscover the environment-invariant properties of experienced input-output\nmappings and transfer them to novel inputs. This can be realised if an\nintelligent system can identify appropriate, task-invariant, and composable\ninput features, as well as the composition methods, thus allowing it to act\nbased not on the interpolation between learnt data points but on the\ntask-invariant composition of those features. We propose that in order to\nconfirm that an algorithm does indeed learn compositional structures from data,\nit is not enough to just test on an OOD setup, but one also needs to confirm\nthat the features identified are indeed compositional. We showcase this by\nexploring two tasks with clearly defined OOD metrics that are not OOD solvable\nby three commonly used neural networks: a Multi-Layer Perceptron (MLP), a\nConvolutional Neural Network (CNN), and a Transformer. In addition, we develop\ntwo novel network architectures imbued with biases that allow them to be\nsuccessful in OOD scenarios. We show that even with correct biases and almost\nperfect OOD performance, an algorithm can still fail to learn the correct\nfeatures for compositional generalisation."}
{"id": "2505.09825", "pdf": "https://arxiv.org/pdf/2505.09825", "abs": "https://arxiv.org/abs/2505.09825", "authors": ["Peiqi Sui", "Juan Diego Rodriguez", "Philippe Laban", "Dean Murphy", "Joseph P. Dexter", "Richard Jean So", "Samuel Baker", "Pramit Chaudhuri"], "title": "KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning", "categories": ["cs.CL"], "comment": null, "summary": "Each year, tens of millions of essays are written and graded in college-level\nEnglish courses. Students are asked to analyze literary and cultural texts\nthrough a process known as close reading, in which they gather textual details\nto formulate evidence-based arguments. Despite being viewed as a basis for\ncritical thinking and widely adopted as a required element of university\ncoursework, close reading has never been evaluated on large language models\n(LLMs), and multi-discipline benchmarks like MMLU do not include literature as\na subject. To fill this gap, we present KRISTEVA, the first close reading\nbenchmark for evaluating interpretive reasoning, consisting of 1331\nmultiple-choice questions adapted from classroom data. With KRISTEVA, we\npropose three progressively more difficult sets of tasks to approximate\ndifferent elements of the close reading process, which we use to test how well\nLLMs may seem to understand and reason about literary works: 1) extracting\nstylistic features, 2) retrieving relevant contextual information from\nparametric knowledge, and 3) multi-hop reasoning between style and external\ncontexts. Our baseline results find that, while state-of-the-art LLMs possess\nsome college-level close reading competency (accuracy 49.7% - 69.7%), their\nperformances still trail those of experienced human evaluators on 10 out of our\n11 tasks."}
{"id": "2505.09923", "pdf": "https://arxiv.org/pdf/2505.09923", "abs": "https://arxiv.org/abs/2505.09923", "authors": ["Minjung Shin", "Donghyun Kim", "Jeh-Kwang Ryu"], "title": "\"There Is No Such Thing as a Dumb Question,\" But There Are Good Ones", "categories": ["cs.AI"], "comment": "8 pages, 4 figures and 4 tables. This work has been accepted for\n  presentation as a poster with full paper publication at CogSci 2025. This is\n  the final submission", "summary": "Questioning has become increasingly crucial for both humans and artificial\nintelligence, yet there remains limited research comprehensively assessing\nquestion quality. In response, this study defines good questions and presents a\nsystematic evaluation framework. We propose two key evaluation dimensions:\nappropriateness (sociolinguistic competence in context) and effectiveness\n(strategic competence in goal achievement). Based on these foundational\ndimensions, a rubric-based scoring system was developed. By incorporating\ndynamic contextual variables, our evaluation framework achieves structure and\nflexibility through semi-adaptive criteria. The methodology was validated using\nthe CAUS and SQUARE datasets, demonstrating the ability of the framework to\naccess both well-formed and problematic questions while adapting to varied\ncontexts. As we establish a flexible and comprehensive framework for question\nevaluation, this study takes a significant step toward integrating questioning\nbehavior with structured analytical methods grounded in the intrinsic nature of\nquestioning."}
{"id": "2505.09926", "pdf": "https://arxiv.org/pdf/2505.09926", "abs": "https://arxiv.org/abs/2505.09926", "authors": ["Bin-Bin Gao", "Yue Zhu", "Jiangtao Yan", "Yuezhi Cai", "Weixi Zhang", "Meng Wang", "Jun Liu", "Yong Liu", "Lei Wang", "Chengjie Wang"], "title": "AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": "27 pages, 15 figures, 22 tables", "summary": "Universal visual anomaly detection aims to identify anomalies from novel or\nunseen vision domains without additional fine-tuning, which is critical in open\nscenarios. Recent studies have demonstrated that pre-trained vision-language\nmodels like CLIP exhibit strong generalization with just zero or a few normal\nimages. However, existing methods struggle with designing prompt templates,\ncomplex token interactions, or requiring additional fine-tuning, resulting in\nlimited flexibility. In this work, we present a simple yet effective method\ncalled AdaptCLIP based on two key insights. First, adaptive visual and textual\nrepresentations should be learned alternately rather than jointly. Second,\ncomparative learning between query and normal image prompt should incorporate\nboth contextual and aligned residual features, rather than relying solely on\nresidual features. AdaptCLIP treats CLIP models as a foundational service,\nadding only three simple adapters, visual adapter, textual adapter, and\nprompt-query adapter, at its input or output ends. AdaptCLIP supports\nzero-/few-shot generalization across domains and possesses a training-free\nmanner on target domains once trained on a base dataset. AdaptCLIP achieves\nstate-of-the-art performance on 12 anomaly detection benchmarks from industrial\nand medical domains, significantly outperforming existing competitive methods.\nWe will make the code and model of AdaptCLIP available at\nhttps://github.com/gaobb/AdaptCLIP."}
{"id": "2505.09733", "pdf": "https://arxiv.org/pdf/2505.09733", "abs": "https://arxiv.org/abs/2505.09733", "authors": ["Alpaslan Gokcen", "Ali Boyaci"], "title": "Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated learning (FL) presents an effective solution for collaborative\nmodel training while maintaining data privacy across decentralized client\ndatasets. However, data quality issues such as noisy labels, missing classes,\nand imbalanced distributions significantly challenge its effectiveness. This\nstudy proposes a federated learning methodology that systematically addresses\ndata quality issues, including noise, class imbalance, and missing labels. The\nproposed approach systematically enhances data integrity through adaptive noise\ncleaning, collaborative conditional GAN-based synthetic data generation, and\nrobust federated model training. Experimental evaluations conducted on\nbenchmark datasets (MNIST and Fashion-MNIST) demonstrate significant\nimprovements in federated model performance, particularly macro-F1 Score, under\nvarying noise and class imbalance conditions. Additionally, the proposed\nframework carefully balances computational feasibility and substantial\nperformance gains, ensuring practicality for resource constrained edge devices\nwhile rigorously maintaining data privacy. Our results indicate that this\nmethod effectively mitigates common data quality challenges, providing a\nrobust, scalable, and privacy compliant solution suitable for diverse\nreal-world federated learning scenarios."}
{"id": "2505.09852", "pdf": "https://arxiv.org/pdf/2505.09852", "abs": "https://arxiv.org/abs/2505.09852", "authors": ["Apollinaire Poli Nemkova", "Sarath Chandra Lingareddy", "Sagnik Ray Choudhury", "Mark V. Albert"], "title": "Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance across natural\nlanguage tasks, but their ability to forecast violent conflict remains\nunderexplored. We investigate whether LLMs possess meaningful parametric\nknowledge-encoded in their pretrained weights-to predict conflict escalation\nand fatalities without external data. This is critical for early warning\nsystems, humanitarian planning, and policy-making. We compare this parametric\nknowledge with non-parametric capabilities, where LLMs access structured and\nunstructured context from conflict datasets (e.g., ACLED, GDELT) and recent\nnews reports via Retrieval-Augmented Generation (RAG). Incorporating external\ninformation could enhance model performance by providing up-to-date context\notherwise missing from pretrained weights. Our two-part evaluation framework\nspans 2020-2024 across conflict-prone regions in the Horn of Africa and the\nMiddle East. In the parametric setting, LLMs predict conflict trends and\nfatalities relying only on pretrained knowledge. In the non-parametric setting,\nmodels receive summaries of recent conflict events, indicators, and\ngeopolitical developments. We compare predicted conflict trend labels (e.g.,\nEscalate, Stable Conflict, De-escalate, Peace) and fatalities against\nhistorical data. Our findings highlight the strengths and limitations of LLMs\nfor conflict forecasting and the benefits of augmenting them with structured\nexternal knowledge."}
{"id": "2505.09932", "pdf": "https://arxiv.org/pdf/2505.09932", "abs": "https://arxiv.org/abs/2505.09932", "authors": ["Kevin J McNamara", "Rhea Pritham Marpu"], "title": "Demystifying AI Agents: The Final Generation of Intelligence", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.MA"], "comment": null, "summary": "The trajectory of artificial intelligence (AI) has been one of relentless\nacceleration, evolving from rudimentary rule-based systems to sophisticated,\nautonomous agents capable of complex reasoning and interaction. This whitepaper\nchronicles this remarkable journey, charting the key technological\nmilestones--advancements in prompting, training methodologies, hardware\ncapabilities, and architectural innovations--that have converged to create the\nAI agents of today. We argue that these agents, exemplified by systems like\nOpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in\nAI development, potentially constituting the \"final generation\" of intelligence\nas we currently conceive it. We explore the capabilities and underlying\ntechnologies of these agents, grounded in practical examples, while also\nexamining the profound societal implications and the unprecedented pace of\nprogress that suggests intelligence is now doubling approximately every six\nmonths. The paper concludes by underscoring the critical need for wisdom and\nforesight in navigating the opportunities and challenges presented by this\npowerful new era of intelligence."}
{"id": "2505.09927", "pdf": "https://arxiv.org/pdf/2505.09927", "abs": "https://arxiv.org/abs/2505.09927", "authors": ["Siqi Yin", "Shaolei Liu", "Manning Wang"], "title": "DDFP: Data-dependent Frequency Prompt for Source Free Domain Adaptation of Medical Image Segmentation", "categories": ["cs.CV"], "comment": null, "summary": "Domain adaptation addresses the challenge of model performance degradation\ncaused by domain gaps. In the typical setup for unsupervised domain adaptation,\nlabeled data from a source domain and unlabeled data from a target domain are\nused to train a target model. However, access to labeled source domain data,\nparticularly in medical datasets, can be restricted due to privacy policies. As\na result, research has increasingly shifted to source-free domain adaptation\n(SFDA), which requires only a pretrained model from the source domain and\nunlabeled data from the target domain data for adaptation. Existing SFDA\nmethods often rely on domain-specific image style translation and\nself-supervision techniques to bridge the domain gap and train the target\ndomain model. However, the quality of domain-specific style-translated images\nand pseudo-labels produced by these methods still leaves room for improvement.\nMoreover, training the entire model during adaptation can be inefficient under\nlimited supervision. In this paper, we propose a novel SFDA framework to\naddress these challenges. Specifically, to effectively mitigate the impact of\ndomain gap in the initial training phase, we introduce preadaptation to\ngenerate a preadapted model, which serves as an initialization of target model\nand allows for the generation of high-quality enhanced pseudo-labels without\nintroducing extra parameters. Additionally, we propose a data-dependent\nfrequency prompt to more effectively translate target domain images into a\nsource-like style. To further enhance adaptation, we employ a style-related\nlayer fine-tuning strategy, specifically designed for SFDA, to train the target\nmodel using the prompted target domain images and pseudo-labels. Extensive\nexperiments on cross-modality abdominal and cardiac SFDA segmentation tasks\ndemonstrate that our proposed method outperforms existing state-of-the-art\nmethods."}
{"id": "2505.09742", "pdf": "https://arxiv.org/pdf/2505.09742", "abs": "https://arxiv.org/abs/2505.09742", "authors": ["Yuan-Hang Zhang", "Massimiliano Di Ventra"], "title": "A Generative Neural Annealer for Black-Box Combinatorial Optimization", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.NE"], "comment": "15 pages, 3 figures", "summary": "We propose a generative, end-to-end solver for black-box combinatorial\noptimization that emphasizes both sample efficiency and solution quality on NP\nproblems. Drawing inspiration from annealing-based algorithms, we treat the\nblack-box objective as an energy function and train a neural network to model\nthe associated Boltzmann distribution. By conditioning on temperature, the\nnetwork captures a continuum of distributions--from near-uniform at high\ntemperatures to sharply peaked around global optima at low\ntemperatures--thereby learning the structure of the energy landscape and\nfacilitating global optimization. When queries are expensive, the\ntemperature-dependent distributions naturally enable data augmentation and\nimprove sample efficiency. When queries are cheap but the problem remains hard,\nthe model learns implicit variable interactions, effectively \"opening\" the\nblack box. We validate our approach on challenging combinatorial tasks under\nboth limited and unlimited query budgets, showing competitive performance\nagainst state-of-the-art black-box optimizers."}
{"id": "2505.09902", "pdf": "https://arxiv.org/pdf/2505.09902", "abs": "https://arxiv.org/abs/2505.09902", "authors": ["Martin Capdevila", "Esteban Villa Turek", "Ellen Karina Chumbe Fernandez", "Luis Felipe Polo Galvez", "Luis Cadavid", "Andrea Marroquin", "Rebeca Vargas Quesada", "Johanna Crew", "Nicole Vallejo Galarraga", "Christopher Rodriguez", "Diego Gutierrez", "Radhi Datla"], "title": "Crossing Borders Without Crossing Boundaries: How Sociolinguistic Awareness Can Optimize User Engagement with Localized Spanish AI Models Across Hispanophone Countries", "categories": ["cs.CL"], "comment": null, "summary": "Large language models are, by definition, based on language. In an effort to\nunderscore the critical need for regional localized models, this paper examines\nprimary differences between variants of written Spanish across Latin America\nand Spain, with an in-depth sociocultural and linguistic contextualization\ntherein. We argue that these differences effectively constitute significant\ngaps in the quotidian use of Spanish among dialectal groups by creating\nsociolinguistic dissonances, to the extent that locale-sensitive AI models\nwould play a pivotal role in bridging these divides. In doing so, this approach\ninforms better and more efficient localization strategies that also serve to\nmore adequately meet inclusivity goals, while securing sustainable active daily\nuser growth in a major low-risk investment geographic area. Therefore,\nimplementing at least the proposed five sub variants of Spanish addresses two\nlines of action: to foment user trust and reliance on AI language models while\nalso demonstrating a level of cultural, historical, and sociolinguistic\nawareness that reflects positively on any internationalization strategy."}
{"id": "2505.09970", "pdf": "https://arxiv.org/pdf/2505.09970", "abs": "https://arxiv.org/abs/2505.09970", "authors": ["Mrinal Rawat", "Ambuje Gupta", "Rushil Goomer", "Alessandro Di Bari", "Neha Gupta", "Roberto Pieraccini"], "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "categories": ["cs.AI"], "comment": null, "summary": "The ReAct (Reasoning + Action) capability in large language models (LLMs) has\nbecome the foundation of modern agentic systems. Recent LLMs, such as\nDeepSeek-R1 and OpenAI o1/o3, exemplify this by emphasizing reasoning through\nthe generation of ample intermediate tokens, which help build a strong premise\nbefore producing the final output tokens. In this paper, we introduce Pre-Act,\na novel approach that enhances the agent's performance by creating a multi-step\nexecution plan along with the detailed reasoning for the given user input. This\nplan incrementally incorporates previous steps and tool outputs, refining\nitself after each step execution until the final response is obtained. Our\napproach is applicable to both conversational and non-conversational agents. To\nmeasure the performance of task-oriented agents comprehensively, we propose a\ntwo-level evaluation framework: (1) turn level and (2) end-to-end. Our\nturn-level evaluation, averaged across five models, shows that our approach,\nPre-Act, outperforms ReAct by 70% in Action Recall on the Almita dataset. While\nthis approach is effective for larger models, smaller models crucial for\npractical applications, where latency and cost are key constraints, often\nstruggle with complex reasoning tasks required for agentic systems. To address\nthis limitation, we fine-tune relatively small models such as Llama 3.1 (8B &\n70B) using the proposed Pre-Act approach. Our experiments show that the\nfine-tuned 70B model outperforms GPT-4, achieving a 69.5% improvement in action\naccuracy (turn-level) and a 28% improvement in goal completion rate\n(end-to-end) on the Almita (out-of-domain) dataset."}
{"id": "2505.09935", "pdf": "https://arxiv.org/pdf/2505.09935", "abs": "https://arxiv.org/abs/2505.09935", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Quoc Dai Tran"], "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users."}
{"id": "2505.09756", "pdf": "https://arxiv.org/pdf/2505.09756", "abs": "https://arxiv.org/abs/2505.09756", "authors": ["Zhaoyang Shi"], "title": "Community-based Multi-Agent Reinforcement Learning with Transfer and Active Exploration", "categories": ["cs.LG", "cs.MA", "math.OC", "stat.ML"], "comment": null, "summary": "We propose a new framework for multi-agent reinforcement learning (MARL),\nwhere the agents cooperate in a time-evolving network with latent community\nstructures and mixed memberships. Unlike traditional neighbor-based or fixed\ninteraction graphs, our community-based framework captures flexible and\nabstract coordination patterns by allowing each agent to belong to multiple\noverlapping communities. Each community maintains shared policy and value\nfunctions, which are aggregated by individual agents according to personalized\nmembership weights. We also design actor-critic algorithms that exploit this\nstructure: agents inherit community-level estimates for policy updates and\nvalue learning, enabling structured information sharing without requiring\naccess to other agents' policies. Importantly, our approach supports both\ntransfer learning by adapting to new agents or tasks via membership estimation,\nand active learning by prioritizing uncertain communities during exploration.\nTheoretically, we establish convergence guarantees under linear function\napproximation for both actor and critic updates. To our knowledge, this is the\nfirst MARL framework that integrates community structure, transferability, and\nactive learning with provable guarantees."}
{"id": "2505.09924", "pdf": "https://arxiv.org/pdf/2505.09924", "abs": "https://arxiv.org/abs/2505.09924", "authors": ["Yidan Wang", "Yubing Ren", "Yanan Cao", "Binxing Fang"], "title": "From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models", "categories": ["cs.CL", "cs.CR"], "comment": null, "summary": "The rise of Large Language Models (LLMs) has heightened concerns about the\nmisuse of AI-generated text, making watermarking a promising solution.\nMainstream watermarking schemes for LLMs fall into two categories: logits-based\nand sampling-based. However, current schemes entail trade-offs among\nrobustness, text quality, and security. To mitigate this, we integrate\nlogits-based and sampling-based schemes, harnessing their respective strengths\nto achieve synergy. In this paper, we propose a versatile symbiotic\nwatermarking framework with three strategies: serial, parallel, and hybrid. The\nhybrid framework adaptively embeds watermarks using token entropy and semantic\nentropy, optimizing the balance between detectability, robustness, text\nquality, and security. Furthermore, we validate our approach through\ncomprehensive experiments on various datasets and models. Experimental results\nindicate that our method outperforms existing baselines and achieves\nstate-of-the-art (SOTA) performance. We believe this framework provides novel\ninsights into diverse watermarking paradigms. Our code is available at\n\\href{https://github.com/redwyd/SymMark}{https://github.com/redwyd/SymMark}."}
{"id": "2505.10034", "pdf": "https://arxiv.org/pdf/2505.10034", "abs": "https://arxiv.org/abs/2505.10034", "authors": ["Changzeng Fu", "Zelin Fu", "Xinhe Kuang", "Jiacheng Dong", "Qi Zhang", "Kaifeng Su", "Yikai Su", "Wenbo Shi", "Junfeng Yao", "Yuliang Zhao", "Shiqi Zhao", "Jiadong Wang", "Siyang Song", "Chaoran Liu", "Yuichiro Yoshikawa", "Björn Schuller", "Hiroshi Ishiguro"], "title": "The First MPDD Challenge: Multimodal Personality-aware Depression Detection", "categories": ["cs.AI", "68T07", "I.2.0; H.5.1"], "comment": "This paper has been accepted as part of the MPDD Challenge in the\n  ACMMM 2025 Grand Challenge", "summary": "Depression is a widespread mental health issue affecting diverse age groups,\nwith notable prevalence among college students and the elderly. However,\nexisting datasets and detection methods primarily focus on young adults,\nneglecting the broader age spectrum and individual differences that influence\ndepression manifestation. Current approaches often establish a direct mapping\nbetween multimodal data and depression indicators, failing to capture the\ncomplexity and diversity of depression across individuals. This challenge\nincludes two tracks based on age-specific subsets: Track 1 uses the\nMPDD-Elderly dataset for detecting depression in older adults, and Track 2 uses\nthe MPDD-Young dataset for detecting depression in younger participants. The\nMultimodal Personality-aware Depression Detection (MPDD) Challenge aims to\naddress this gap by incorporating multimodal data alongside individual\ndifference factors. We provide a baseline model that fuses audio and video\nmodalities with individual difference information to detect depression\nmanifestations in diverse populations. This challenge aims to promote the\ndevelopment of more personalized and accurate de pression detection methods,\nadvancing mental health research and fostering inclusive detection systems.\nMore details are available on the official challenge website:\nhttps://hacilab.github.io/MPDDChallenge.github.io."}
{"id": "2505.09939", "pdf": "https://arxiv.org/pdf/2505.09939", "abs": "https://arxiv.org/abs/2505.09939", "authors": ["Zhe Shan", "Lei Zhou", "Liu Mao", "Shaofan Chen", "Chuanqiu Ren", "Xia Xie"], "title": "Non-Registration Change Detection: A Novel Change Detection Task and Benchmark Dataset", "categories": ["cs.CV", "eess.IV"], "comment": "Accepted to IGARSS 2025", "summary": "In this study, we propose a novel remote sensing change detection task,\nnon-registration change detection, to address the increasing number of\nemergencies such as natural disasters, anthropogenic accidents, and military\nstrikes. First, in light of the limited discourse on the issue of\nnon-registration change detection, we systematically propose eight scenarios\nthat could arise in the real world and potentially contribute to the occurrence\nof non-registration problems. Second, we develop distinct image transformation\nschemes tailored to various scenarios to convert the available registration\nchange detection dataset into a non-registration version. Finally, we\ndemonstrate that non-registration change detection can cause catastrophic\ndamage to the state-of-the-art methods. Our code and dataset are available at\nhttps://github.com/ShanZard/NRCD."}
{"id": "2505.09768", "pdf": "https://arxiv.org/pdf/2505.09768", "abs": "https://arxiv.org/abs/2505.09768", "authors": ["Xiukun Wei", "Xueru Zhang"], "title": "Self-Consuming Generative Models with Adversarially Curated Data", "categories": ["cs.LG"], "comment": null, "summary": "Recent advances in generative models have made it increasingly difficult to\ndistinguish real data from model-generated synthetic data. Using synthetic data\nfor successive training of future model generations creates \"self-consuming\nloops\", which may lead to model collapse or training instability. Furthermore,\nsynthetic data is often subject to human feedback and curated by users based on\ntheir preferences. Ferbach et al. (2024) recently showed that when data is\ncurated according to user preferences, the self-consuming retraining loop\ndrives the model to converge toward a distribution that optimizes those\npreferences. However, in practice, data curation is often noisy or\nadversarially manipulated. For example, competing platforms may recruit\nmalicious users to adversarially curate data and disrupt rival models. In this\npaper, we study how generative models evolve under self-consuming retraining\nloops with noisy and adversarially curated data. We theoretically analyze the\nimpact of such noisy data curation on generative models and identify conditions\nfor the robustness of the retraining process. Building on this analysis, we\ndesign attack algorithms for competitive adversarial scenarios, where a\nplatform with a limited budget employs malicious users to misalign a rival's\nmodel from actual user preferences. Experiments on both synthetic and\nreal-world datasets demonstrate the effectiveness of the proposed algorithms."}
{"id": "2505.09930", "pdf": "https://arxiv.org/pdf/2505.09930", "abs": "https://arxiv.org/abs/2505.09930", "authors": ["Zixiao Zhu", "Hanzhang Zhou", "Zijian Feng", "Tianjiao Li", "Chua Jia Jim Deryl", "Mak Lee Onn", "Gee Wah Ng", "Kezhi Mao"], "title": "Rethinking Prompt Optimizers: From Prompt Merits to Optimization", "categories": ["cs.CL"], "comment": "20 pages, 14 figures", "summary": "Prompt optimization (PO) offers a practical alternative to fine-tuning large\nlanguage models (LLMs), enabling performance improvements without altering\nmodel weights. Existing methods typically rely on advanced, large-scale LLMs\nlike GPT-4 to generate optimized prompts. However, due to limited downward\ncompatibility, verbose, instruction-heavy prompts from advanced LLMs can\noverwhelm lightweight inference models and degrade response quality. In this\nwork, we rethink prompt optimization through the lens of interpretable design.\nWe first identify a set of model-agnostic prompt quality merits and empirically\nvalidate their effectiveness in enhancing prompt and response quality. We then\nintroduce MePO, a merit-guided, lightweight, and locally deployable prompt\noptimizer trained on our preference dataset built from merit-aligned prompts\ngenerated by a lightweight LLM. Unlike prior work, MePO avoids online\noptimization reliance, reduces cost and privacy concerns, and, by learning\nclear, interpretable merits, generalizes effectively to both large-scale and\nlightweight inference models. Experiments demonstrate that MePO achieves better\nresults across diverse tasks and model types, offering a scalable and robust\nsolution for real-world deployment. Our model and dataset are available at:\nhttps://github.com/MidiyaZhu/MePO"}
{"id": "2505.10074", "pdf": "https://arxiv.org/pdf/2505.10074", "abs": "https://arxiv.org/abs/2505.10074", "authors": ["Mohamed Abdelmagied", "Mohamed Amine Chatti", "Shoeb Joarder", "Qurat Ul Ain", "Rawaa Alatrash"], "title": "Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs", "categories": ["cs.AI", "cs.CY"], "comment": "Accepted at EMOOCs 2025", "summary": "Massive Open Online Courses (MOOCs) lack direct interaction between learners\nand instructors, making it challenging for learners to understand new knowledge\nconcepts. Recently, learners have increasingly used Large Language Models\n(LLMs) to support them in acquiring new knowledge. However, LLMs are prone to\nhallucinations which limits their reliability. Retrieval-Augmented Generation\n(RAG) addresses this issue by retrieving relevant documents before generating a\nresponse. However, the application of RAG across different MOOCs is limited by\nunstructured learning material. Furthermore, current RAG systems do not\nactively guide learners toward their learning needs. To address these\nchallenges, we propose a Graph RAG pipeline that leverages Educational\nKnowledge Graphs (EduKGs) and Personal Knowledge Graphs (PKGs) to guide\nlearners to understand knowledge concepts in the MOOC platform CourseMapper.\nSpecifically, we implement (1) a PKG-based Question Generation method to\nrecommend personalized questions for learners in context, and (2) an\nEduKG-based Question Answering method that leverages the relationships between\nknowledge concepts in the EduKG to answer learner selected questions. To\nevaluate both methods, we conducted a study with 3 expert instructors on 3\ndifferent MOOCs in the MOOC platform CourseMapper. The results of the\nevaluation show the potential of Graph RAG to empower learners to understand\nnew knowledge concepts in a personalized learning experience."}
{"id": "2505.09943", "pdf": "https://arxiv.org/pdf/2505.09943", "abs": "https://arxiv.org/abs/2505.09943", "authors": ["Jiakun Deng", "Kexuan Li", "Xingye Cui", "Jiaxuan Li", "Chang Long", "Tian Pu", "Zhenming Peng"], "title": "CSPENet: Contour-Aware and Saliency Priors Embedding Network for Infrared Small Target Detection", "categories": ["cs.CV"], "comment": null, "summary": "Infrared small target detection (ISTD) plays a critical role in a wide range\nof civilian and military applications. Existing methods suffer from\ndeficiencies in the localization of dim targets and the perception of contour\ninformation under dense clutter environments, severely limiting their detection\nperformance. To tackle these issues, we propose a contour-aware and saliency\npriors embedding network (CSPENet) for ISTD. We first design a\nsurround-convergent prior extraction module (SCPEM) that effectively captures\nthe intrinsic characteristic of target contour pixel gradients converging\ntoward their center. This module concurrently extracts two collaborative\npriors: a boosted saliency prior for accurate target localization and\nmulti-scale structural priors for comprehensively enriching contour detail\nrepresentation. Building upon this, we propose a dual-branch priors embedding\narchitecture (DBPEA) that establishes differentiated feature fusion pathways,\nembedding these two priors at optimal network positions to achieve performance\nenhancement. Finally, we develop an attention-guided feature enhancement module\n(AGFEM) to refine feature representations and improve saliency estimation\naccuracy. Experimental results on public datasets NUDT-SIRST, IRSTD-1k, and\nNUAA-SIRST demonstrate that our CSPENet outperforms other state-of-the-art\nmethods in detection performance. The code is available at\nhttps://github.com/IDIP2025/CSPENet."}
{"id": "2505.09792", "pdf": "https://arxiv.org/pdf/2505.09792", "abs": "https://arxiv.org/abs/2505.09792", "authors": ["Michael Kamfonas"], "title": "Interim Report on Human-Guided Adaptive Hyperparameter Optimization with Multi-Fidelity Sprints", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This case study applies a phased hyperparameter optimization process to\ncompare multitask natural language model variants that utilize multiphase\nlearning rate scheduling and optimizer parameter grouping. We employ short,\nBayesian optimization sessions that leverage multi-fidelity, hyperparameter\nspace pruning, progressive halving, and a degree of human guidance. We utilize\nthe Optuna TPE sampler and Hyperband pruner, as well as the Scikit-Learn\nGaussian process minimization. Initially, we use efficient low-fidelity sprints\nto prune the hyperparameter space. Subsequent sprints progressively increase\ntheir model fidelity and employ hyperband pruning for efficiency. A second\naspect of our approach is using a meta-learner to tune threshold values to\nresolve classification probabilities during inference. We demonstrate our\nmethod on a collection of variants of the 2021 Joint Entity and Relation\nExtraction model proposed by Eberts and Ulges."}
{"id": "2505.09945", "pdf": "https://arxiv.org/pdf/2505.09945", "abs": "https://arxiv.org/abs/2505.09945", "authors": ["Deeksha Prahlad", "Chanhee Lee", "Dongha Kim", "Hokeun Kim"], "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)", "summary": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time."}
{"id": "2505.10093", "pdf": "https://arxiv.org/pdf/2505.10093", "abs": "https://arxiv.org/abs/2505.10093", "authors": ["Hsuan-Lei Shao"], "title": "From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI", "categories": ["cs.AI", "cs.CL", "I.2.4; H.3.3; J.5"], "comment": "4 pages, 4 figures", "summary": "Taiwanese China Studies (CS) has developed into a rich, interdisciplinary\nresearch field shaped by the unique geopolitical position and long standing\nacademic engagement with Mainland China. This study responds to the growing\nneed to systematically revisit and reorganize decades of Taiwan based CS\nscholarship by proposing an AI assisted approach that transforms unstructured\nacademic texts into structured, interactive knowledge representations. We apply\ngenerative AI (GAI) techniques and large language models (LLMs) to extract and\nstandardize entity relation triples from 1,367 peer reviewed CS articles\npublished between 1996 and 2019. These triples are then visualized through a\nlightweight D3.js based system, forming the foundation of a domain specific\nknowledge graph and vector database for the field. This infrastructure allows\nusers to explore conceptual nodes and semantic relationships across the corpus,\nrevealing previously uncharted intellectual trajectories, thematic clusters,\nand research gaps. By decomposing textual content into graph structured\nknowledge units, our system enables a paradigm shift from linear text\nconsumption to network based knowledge navigation. In doing so, it enhances\nscholarly access to CS literature while offering a scalable, data driven\nalternative to traditional ontology construction. This work not only\ndemonstrates how generative AI can augment area studies and digital humanities\nbut also highlights its potential to support a reimagined scholarly\ninfrastructure for regional knowledge systems."}
{"id": "2505.09965", "pdf": "https://arxiv.org/pdf/2505.09965", "abs": "https://arxiv.org/abs/2505.09965", "authors": ["Hao Yang", "Tao Tan", "Shuai Tan", "Weiqin Yang", "Kunyan Cai", "Calvin Chen", "Yue Sun"], "title": "MambaControl: Anatomy Graph-Enhanced Mamba ControlNet with Fourier Refinement for Diffusion-Based Disease Trajectory Prediction", "categories": ["cs.CV"], "comment": null, "summary": "Modelling disease progression in precision medicine requires capturing\ncomplex spatio-temporal dynamics while preserving anatomical integrity.\nExisting methods often struggle with longitudinal dependencies and structural\nconsistency in progressive disorders. To address these limitations, we\nintroduce MambaControl, a novel framework that integrates selective state-space\nmodelling with diffusion processes for high-fidelity prediction of medical\nimage trajectories. To better capture subtle structural changes over time while\nmaintaining anatomical consistency, MambaControl combines Mamba-based\nlong-range modelling with graph-guided anatomical control to more effectively\nrepresent anatomical correlations. Furthermore, we introduce Fourier-enhanced\nspectral graph representations to capture spatial coherence and multiscale\ndetail, enabling MambaControl to achieve state-of-the-art performance in\nAlzheimer's disease prediction. Quantitative and regional evaluations\ndemonstrate improved progression prediction quality and anatomical fidelity,\nhighlighting its potential for personalised prognosis and clinical decision\nsupport."}
{"id": "2505.09810", "pdf": "https://arxiv.org/pdf/2505.09810", "abs": "https://arxiv.org/abs/2505.09810", "authors": ["Daniel Waddington", "Cornel Constantinescu"], "title": "Lossless Compression for LLM Tensor Incremental Snapshots", "categories": ["cs.LG"], "comment": null, "summary": "During the training of Large Language Models (LLMs), tensor data is\nperiodically \"checkpointed\" to persistent storage to allow recovery of work\ndone in the event of failure. The volume of data that must be copied during\neach checkpoint, even when using reduced-precision representations such as\nbfloat16, often reaches hundreds of gigabytes. Furthermore, the data must be\nmoved across a network and written to a storage system before the next epoch\noccurs. With a view to ultimately building an optimized checkpointing solution,\nthis paper presents experimental analysis of checkpoint data used to derive a\ndesign that maximizes the use of lossless compression to reduce the volume of\ndata. We examine how tensor data and its compressibility evolve during model\ntraining and evaluate the efficacy of existing common off-the-shelf general\npurpose compression engines combined with known data optimization techniques\nsuch as byte-grouping and incremental delta compression.\n  Leveraging our analysis we have built an effective compression solution,\nknown as Language Model Compressor (LMC), which is based on byte-grouping and\nHuffman encoding. LMC offers more compression performance than the best\nalternative (BZ2) but with an order-of-magnitude reduction in the time needed\nto perform the compression. We show that a 16-core parallel implementation of\nLMC can attain compression and decompression throughput of 2.78 GiB/s and 3.76\nGiB/s respectively. This increase in performance ultimately reduces the CPU\nresources needed and provides more time to copy the data to the storage system\nbefore the next epoch thus allowing for higher-frequency checkpoints."}
{"id": "2505.10013", "pdf": "https://arxiv.org/pdf/2505.10013", "abs": "https://arxiv.org/abs/2505.10013", "authors": ["Lake Yin", "Fan Huang"], "title": "DIF: A Framework for Benchmarking and Verifying Implicit Bias in LLMs", "categories": ["cs.CL"], "comment": "7 pages, 1 figure", "summary": "As Large Language Models (LLMs) have risen in prominence over the past few\nyears, there has been concern over the potential biases in LLMs inherited from\nthe training data. Previous studies have examined how LLMs exhibit implicit\nbias, such as when response generation changes when different social contexts\nare introduced. We argue that this implicit bias is not only an ethical, but\nalso a technical issue, as it reveals an inability of LLMs to accommodate\nextraneous information. However, unlike other measures of LLM intelligence,\nthere are no standard methods to benchmark this specific subset of LLM bias. To\nbridge this gap, we developed a method for calculating an easily interpretable\nbenchmark, DIF (Demographic Implicit Fairness), by evaluating preexisting LLM\nlogic and math problem datasets with sociodemographic personas. We demonstrate\nthat this method can statistically validate the presence of implicit bias in\nLLM behavior and find an inverse trend between question answering accuracy and\nimplicit bias, supporting our argument."}
{"id": "2505.10188", "pdf": "https://arxiv.org/pdf/2505.10188", "abs": "https://arxiv.org/abs/2505.10188", "authors": ["Felix Liedeker", "Olivia Sanchez-Graillet", "Moana Seidler", "Christian Brandt", "Jörg Wellmer", "Philipp Cimiano"], "title": "A User Study Evaluating Argumentative Explanations in Diagnostic Decision Support", "categories": ["cs.AI"], "comment": "Presented at 'The First Workshop on Natural Language Argument-Based\n  Explanations', co-located with ECAI 2024", "summary": "As the field of healthcare increasingly adopts artificial intelligence, it\nbecomes important to understand which types of explanations increase\ntransparency and empower users to develop confidence and trust in the\npredictions made by machine learning (ML) systems. In shared decision-making\nscenarios where doctors cooperate with ML systems to reach an appropriate\ndecision, establishing mutual trust is crucial. In this paper, we explore\ndifferent approaches to generating explanations in eXplainable AI (XAI) and\nmake their underlying arguments explicit so that they can be evaluated by\nmedical experts. In particular, we present the findings of a user study\nconducted with physicians to investigate their perceptions of various types of\nAI-generated explanations in the context of diagnostic decision support. The\nstudy aims to identify the most effective and useful explanations that enhance\nthe diagnostic process. In the study, medical doctors filled out a survey to\nassess different types of explanations. Further, an interview was carried out\npost-survey to gain qualitative insights on the requirements of explanations\nincorporated in diagnostic decision support. Overall, the insights gained from\nthis study contribute to understanding the types of explanations that are most\neffective."}
{"id": "2505.09967", "pdf": "https://arxiv.org/pdf/2505.09967", "abs": "https://arxiv.org/abs/2505.09967", "authors": ["Liqian Deng"], "title": "TKFNet: Learning Texture Key Factor Driven Feature for Facial Expression Recognition", "categories": ["cs.CV"], "comment": null, "summary": "Facial expression recognition (FER) in the wild remains a challenging task\ndue to the subtle and localized nature of expression-related features, as well\nas the complex variations in facial appearance. In this paper, we introduce a\nnovel framework that explicitly focuses on Texture Key Driver Factors (TKDF),\nlocalized texture regions that exhibit strong discriminative power across\nemotional categories. By carefully observing facial image patterns, we identify\nthat certain texture cues, such as micro-changes in skin around the brows,\neyes, and mouth, serve as primary indicators of emotional dynamics. To\neffectively capture and leverage these cues, we propose a FER architecture\ncomprising a Texture-Aware Feature Extractor (TAFE) and Dual Contextual\nInformation Filtering (DCIF). TAFE employs a ResNet-based backbone enhanced\nwith multi-branch attention to extract fine-grained texture representations,\nwhile DCIF refines these features by filtering context through adaptive pooling\nand attention mechanisms. Experimental results on RAF-DB and KDEF datasets\ndemonstrate that our method achieves state-of-the-art performance, verifying\nthe effectiveness and robustness of incorporating TKDFs into FER pipelines."}
{"id": "2505.09812", "pdf": "https://arxiv.org/pdf/2505.09812", "abs": "https://arxiv.org/abs/2505.09812", "authors": ["Anastasija Tashkova", "Stefan Eftimov", "Bojan Ristov", "Slobodan Kalajdziski"], "title": "Comparative Analysis of Stroke Prediction Models Using Machine Learning", "categories": ["cs.LG"], "comment": null, "summary": "Stroke remains one of the most critical global health challenges, ranking as\nthe second leading cause of death and the third leading cause of disability\nworldwide. This study explores the effectiveness of machine learning algorithms\nin predicting stroke risk using demographic, clinical, and lifestyle data from\nthe Stroke Prediction Dataset. By addressing key methodological challenges such\nas class imbalance and missing data, we evaluated the performance of multiple\nmodels, including Logistic Regression, Random Forest, and XGBoost. Our results\ndemonstrate that while these models achieve high accuracy, sensitivity remains\na limiting factor for real-world clinical applications. In addition, we\nidentify the most influential predictive features and propose strategies to\nimprove machine learning-based stroke prediction. These findings contribute to\nthe development of more reliable and interpretable models for the early\nassessment of stroke risk."}
{"id": "2505.10063", "pdf": "https://arxiv.org/pdf/2505.10063", "abs": "https://arxiv.org/abs/2505.10063", "authors": ["Han Peng", "Jinhao Jiang", "Zican Dong", "Wayne Xin Zhao", "Lei Fang"], "title": "CAFE: Retrieval Head-based Coarse-to-Fine Information Seeking to Enhance Multi-Document QA Capability", "categories": ["cs.CL"], "comment": null, "summary": "Advancements in Large Language Models (LLMs) have extended their input\ncontext length, yet they still struggle with retrieval and reasoning in\nlong-context inputs. Existing methods propose to utilize the prompt strategy\nand retrieval head to alleviate this limitation. However, they still face\nchallenges in balancing retrieval precision and recall, impacting their\nefficacy in answering questions. To address this, we introduce $\\textbf{CAFE}$,\na two-stage coarse-to-fine method to enhance multi-document question-answering\ncapacities. By gradually eliminating the negative impacts of background and\ndistracting documents, CAFE makes the responses more reliant on the evidence\ndocuments. Initially, a coarse-grained filtering method leverages retrieval\nheads to identify and rank relevant documents. Then, a fine-grained steering\nmethod guides attention to the most relevant content. Experiments across\nbenchmarks show CAFE outperforms baselines, achieving up to 22.1% and 13.7%\nSubEM improvement over SFT and RAG methods on the Mistral model, respectively."}
{"id": "2505.10278", "pdf": "https://arxiv.org/pdf/2505.10278", "abs": "https://arxiv.org/abs/2505.10278", "authors": ["Taian Guo", "Haiyang Shen", "Jinsheng Huang", "Zhengyang Mao", "Junyu Luo", "Zhuoru Chen", "Xuhui Liu", "Bingyu Xia", "Luchen Liu", "Yun Ma", "Ming Zhang"], "title": "MASS: Multi-Agent Simulation Scaling for Portfolio Construction", "categories": ["cs.AI"], "comment": null, "summary": "LLM-based multi-agent has gained significant attention for their potential in\nsimulation and enhancing performance. However, existing works are limited to\npure simulations or are constrained by predefined workflows, restricting their\napplicability and effectiveness. In this paper, we introduce the Multi-Agent\nScaling Simulation (MASS) for portfolio construction. MASS achieves stable and\ncontinuous excess returns by progressively increasing the number of agents for\nlarge-scale simulations to gain a superior understanding of the market and\noptimizing agent distribution end-to-end through a reverse optimization\nprocess, rather than relying on a fixed workflow. We demonstrate its\nsuperiority through performance experiments, ablation studies, backtesting\nexperiments, experiments on updated data and stock pools, scaling experiments,\nparameter sensitivity experiments, and visualization experiments, conducted in\ncomparison with 6 state-of-the-art baselines on 3 challenging A-share stock\npools. We expect the paradigm established by MASS to expand to other tasks with\nsimilar characteristics. The implementation of MASS has been open-sourced at\nhttps://github.com/gta0804/MASS."}
{"id": "2505.09971", "pdf": "https://arxiv.org/pdf/2505.09971", "abs": "https://arxiv.org/abs/2505.09971", "authors": ["Yuan Gao", "Shaobo Xia", "Sheng Nie", "Cheng Wang", "Xiaohuan Xi", "Bisheng Yang"], "title": "APCoTTA: Continual Test-Time Adaptation for Semantic Segmentation of Airborne LiDAR Point Clouds", "categories": ["cs.CV"], "comment": "18 pages,12 figures", "summary": "Airborne laser scanning (ALS) point cloud segmentation is a fundamental task\nfor large-scale 3D scene understanding. In real-world applications, models are\ntypically fixed after training. However, domain shifts caused by changes in the\nenvironment, sensor types, or sensor degradation often lead to a decline in\nmodel performance. Continuous Test-Time Adaptation (CTTA) offers a solution by\nadapting a source-pretrained model to evolving, unlabeled target domains.\nDespite its potential, research on ALS point clouds remains limited, facing\nchallenges such as the absence of standardized datasets and the risk of\ncatastrophic forgetting and error accumulation during prolonged adaptation. To\ntackle these challenges, we propose APCoTTA, the first CTTA method tailored for\nALS point cloud semantic segmentation. We propose a dynamic trainable layer\nselection module. This module utilizes gradient information to select\nlow-confidence layers for training, and the remaining layers are kept frozen,\nmitigating catastrophic forgetting. To further reduce error accumulation, we\npropose an entropy-based consistency loss. By losing such samples based on\nentropy, we apply consistency loss only to the reliable samples, enhancing\nmodel stability. In addition, we propose a random parameter interpolation\nmechanism, which randomly blends parameters from the selected trainable layers\nwith those of the source model. This approach helps balance target adaptation\nand source knowledge retention, further alleviating forgetting. Finally, we\nconstruct two benchmarks, ISPRSC and H3DC, to address the lack of CTTA\nbenchmarks for ALS point cloud segmentation. Experimental results demonstrate\nthat APCoTTA achieves the best performance on two benchmarks, with mIoU\nimprovements of approximately 9% and 14% over direct inference. The new\nbenchmarks and code are available at https://github.com/Gaoyuan2/APCoTTA."}
{"id": "2505.09820", "pdf": "https://arxiv.org/pdf/2505.09820", "abs": "https://arxiv.org/abs/2505.09820", "authors": ["Sajib Biswas", "Mao Nishino", "Samuel Jacob Chacko", "Xiuwen Liu"], "title": "Adversarial Attack on Large Language Models using Exponentiated Gradient Descent", "categories": ["cs.LG", "cs.CL", "cs.CR"], "comment": "Accepted to International Joint Conference on Neural Networks (IJCNN)\n  2025", "summary": "As Large Language Models (LLMs) are widely used, understanding them\nsystematically is key to improving their safety and realizing their full\npotential. Although many models are aligned using techniques such as\nreinforcement learning from human feedback (RLHF), they are still vulnerable to\njailbreaking attacks. Some of the existing adversarial attack methods search\nfor discrete tokens that may jailbreak a target model while others try to\noptimize the continuous space represented by the tokens of the model's\nvocabulary. While techniques based on the discrete space may prove to be\ninefficient, optimization of continuous token embeddings requires projections\nto produce discrete tokens, which might render them ineffective. To fully\nutilize the constraints and the structures of the space, we develop an\nintrinsic optimization technique using exponentiated gradient descent with the\nBregman projection method to ensure that the optimized one-hot encoding always\nstays within the probability simplex. We prove the convergence of the technique\nand implement an efficient algorithm that is effective in jailbreaking several\nwidely used LLMs. We demonstrate the efficacy of the proposed technique using\nfive open-source LLMs on four openly available datasets. The results show that\nthe technique achieves a higher success rate with great efficiency compared to\nthree other state-of-the-art jailbreaking techniques. The source code for our\nimplementation is available at:\nhttps://github.com/sbamit/Exponentiated-Gradient-Descent-LLM-Attack"}
{"id": "2505.10066", "pdf": "https://arxiv.org/pdf/2505.10066", "abs": "https://arxiv.org/abs/2505.10066", "authors": ["Michael Fire", "Yitzhak Elbazis", "Adi Wasenstein", "Lior Rokach"], "title": "Dark LLMs: The Growing Threat of Unaligned AI Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50, 68T05, 68P25", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated."}
{"id": "2505.10309", "pdf": "https://arxiv.org/pdf/2505.10309", "abs": "https://arxiv.org/abs/2505.10309", "authors": ["Tuan Dung Nguyen", "Duncan J. Watts", "Mark E. Whiting"], "title": "Empirically evaluating commonsense intelligence in large language models with large-scale human judgments", "categories": ["cs.AI", "cs.HC", "cs.SI"], "comment": null, "summary": "Commonsense intelligence in machines is often assessed by static benchmarks\nthat compare a model's output against human-prescribed correct labels. An\nimportant, albeit implicit, assumption of these labels is that they accurately\ncapture what any human would think, effectively treating human common sense as\nhomogeneous. However, recent empirical work has shown that humans vary\nenormously in what they consider commonsensical; thus what appears self-evident\nto one benchmark designer may not be so to another. Here, we propose a novel\nmethod for evaluating common sense in artificial intelligence (AI),\nspecifically in large language models (LLMs), that incorporates empirically\nobserved heterogeneity among humans by measuring the correspondence between a\nmodel's judgment and that of a human population. We first find that, when\ntreated as independent survey respondents, most LLMs remain below the human\nmedian in their individual commonsense competence. Second, when used as\nsimulators of a hypothetical population, LLMs correlate with real humans only\nmodestly in the extent to which they agree on the same set of statements. In\nboth cases, smaller, open-weight models are surprisingly more competitive than\nlarger, proprietary frontier models. Our evaluation framework, which ties\ncommonsense intelligence to its cultural basis, contributes to the growing call\nfor adapting AI models to human collectivities that possess different, often\nincompatible, social stocks of knowledge."}
{"id": "2505.09986", "pdf": "https://arxiv.org/pdf/2505.09986", "abs": "https://arxiv.org/abs/2505.09986", "authors": ["Yimin Zhou", "Yichong Xia", "Sicheng Pan", "Bin Chen", "Baoyi An", "Haoqian Wang", "Zhi Wang", "Yaowei Wang", "Zikun Zhou"], "title": "High Quality Underwater Image Compression with Adaptive Correction and Codebook-based Augmentation", "categories": ["cs.CV", "eess.IV"], "comment": null, "summary": "With the increasing exploration and exploitation of the underwater world,\nunderwater images have become a critical medium for human interaction with\nmarine environments, driving extensive research into their efficient\ntransmission and storage. However, contemporary underwater image compression\nalgorithms fail to fully leverage the unique characteristics distinguishing\nunderwater scenes from terrestrial images, resulting in suboptimal performance.\nTo address this limitation, we introduce HQUIC, designed to exploit\nunderwater-image-specific features for enhanced compression efficiency. HQUIC\nemploys an ALTC module to adaptively predict the attenuation coefficients and\nglobal light information of the images, which effectively mitigates the issues\ncaused by the differences in lighting and tone existing in underwater images.\nSubsequently, HQUIC employs a codebook as an auxiliary branch to extract the\ncommon objects within underwater images and enhances the performance of the\nmain branch. Furthermore, HQUIC dynamically weights multi-scale frequency\ncomponents, prioritizing information critical for distortion quality while\ndiscarding redundant details. Extensive evaluations on diverse underwater\ndatasets demonstrate that HQUIC outperforms state-of-the-art compression\nmethods."}
{"id": "2505.09822", "pdf": "https://arxiv.org/pdf/2505.09822", "abs": "https://arxiv.org/abs/2505.09822", "authors": ["Changhao Shi", "Gal Mishne"], "title": "Learning Kronecker-Structured Graphs from Smooth Signals", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Graph learning, or network inference, is a prominent problem in graph signal\nprocessing (GSP). GSP generalizes the Fourier transform to non-Euclidean\ndomains, and graph learning is pivotal to applying GSP when these domains are\nunknown. With the recent prevalence of multi-way data, there has been growing\ninterest in product graphs that naturally factorize dependencies across\ndifferent ways. However, the types of graph products that can be learned are\nstill limited for modeling diverse dependency structures. In this paper, we\nstudy the problem of learning a Kronecker-structured product graph from smooth\nsignals. Unlike the more commonly used Cartesian product, the Kronecker product\nmodels dependencies in a more intricate, non-separable way, but posits harder\nconstraints on the graph learning problem. To tackle this non-convex problem,\nwe propose an alternating scheme to optimize each factor graph and provide\ntheoretical guarantees for its asymptotic convergence. The proposed algorithm\nis also modified to learn factor graphs of the strong product. We conduct\nexperiments on synthetic and real-world graphs and demonstrate our approach's\nefficacy and superior performance compared to existing methods."}
{"id": "2505.10081", "pdf": "https://arxiv.org/pdf/2505.10081", "abs": "https://arxiv.org/abs/2505.10081", "authors": ["Wisdom Aduah", "Francois Meyer"], "title": "Designing and Contextualising Probes for African Languages", "categories": ["cs.CL"], "comment": null, "summary": "Pretrained language models (PLMs) for African languages are continually\nimproving, but the reasons behind these advances remain unclear. This paper\npresents the first systematic investigation into probing PLMs for linguistic\nknowledge about African languages. We train layer-wise probes for six\ntypologically diverse African languages to analyse how linguistic features are\ndistributed. We also design control tasks, a way to interpret probe\nperformance, for the MasakhaPOS dataset. We find PLMs adapted for African\nlanguages to encode more linguistic information about target languages than\nmassively multilingual PLMs. Our results reaffirm previous findings that\ntoken-level syntactic information concentrates in middle-to-last layers, while\nsentence-level semantic information is distributed across all layers. Through\ncontrol tasks and probing baselines, we confirm that performance reflects the\ninternal knowledge of PLMs rather than probe memorisation. Our study applies\nestablished interpretability techniques to African-language PLMs. In doing so,\nwe highlight the internal mechanisms underlying the success of strategies like\nactive learning and multilingual adaptation."}
{"id": "2505.10328", "pdf": "https://arxiv.org/pdf/2505.10328", "abs": "https://arxiv.org/abs/2505.10328", "authors": ["Alvin Combrink", "Stephie Do", "Kristofer Bengtsson", "Sabino Francesco Roselli", "Martin Fabian"], "title": "A Comparative Study of SMT and MILP for the Nurse Rostering Problem", "categories": ["cs.AI", "cs.SY", "eess.SY"], "comment": "6 pages, 3 figures", "summary": "The effects of personnel scheduling on the quality of care and working\nconditions for healthcare personnel have been thoroughly documented. However,\nthe ever-present demand and large variation of constraints make healthcare\nscheduling particularly challenging. This problem has been studied for decades,\nwith limited research aimed at applying Satisfiability Modulo Theories (SMT).\nSMT has gained momentum within the formal verification community in the last\ndecades, leading to the advancement of SMT solvers that have been shown to\noutperform standard mathematical programming techniques.\n  In this work, we propose generic constraint formulations that can model a\nwide range of real-world scheduling constraints. Then, the generic constraints\nare formulated as SMT and MILP problems and used to compare the respective\nstate-of-the-art solvers, Z3 and Gurobi, on academic and real-world inspired\nrostering problems. Experimental results show how each solver excels for\ncertain types of problems; the MILP solver generally performs better when the\nproblem is highly constrained or infeasible, while the SMT solver performs\nbetter otherwise. On real-world inspired problems containing a more varied set\nof shifts and personnel, the SMT solver excels. Additionally, it was noted\nduring experimentation that the SMT solver was more sensitive to the way the\ngeneric constraints were formulated, requiring careful consideration and\nexperimentation to achieve better performance. We conclude that SMT-based\nmethods present a promising avenue for future research within the domain of\npersonnel scheduling."}
{"id": "2505.09990", "pdf": "https://arxiv.org/pdf/2505.09990", "abs": "https://arxiv.org/abs/2505.09990", "authors": ["Long Cheng", "Jiafei Duan", "Yi Ru Wang", "Haoquan Fang", "Boyang Li", "Yushan Huang", "Elvis Wang", "Ainaz Eftekhar", "Jason Lee", "Wentao Yuan", "Rose Hendrix", "Noah A. Smith", "Fei Xia", "Dieter Fox", "Ranjay Krishna"], "title": "PointArena: Probing Multimodal Grounding Through Language-Guided Pointing", "categories": ["cs.CV"], "comment": "10 Pages, Dataset and code:https://pointarena.github.io/", "summary": "Pointing serves as a fundamental and intuitive mechanism for grounding\nlanguage within visual contexts, with applications spanning robotics, assistive\ntechnologies, and interactive AI systems. While recent multimodal models have\nstarted to support pointing capabilities, existing benchmarks typically focus\nonly on referential object localization tasks. We introduce PointArena, a\ncomprehensive platform for evaluating multimodal pointing across diverse\nreasoning scenarios. PointArena comprises three components: (1) Point-Bench, a\ncurated dataset containing approximately 1,000 pointing tasks across five\nreasoning categories; (2) Point-Battle, an interactive, web-based arena\nfacilitating blind, pairwise model comparisons, which has already gathered over\n4,500 anonymized votes; and (3) Point-Act, a real-world robotic manipulation\nsystem allowing users to directly evaluate multimodal model pointing\ncapabilities in practical settings. We conducted extensive evaluations of both\nstate-of-the-art open-source and proprietary multimodal models. Results\nindicate that Molmo-72B consistently outperforms other models, though\nproprietary models increasingly demonstrate comparable performance.\nAdditionally, we find that supervised training specifically targeting pointing\ntasks significantly enhances model performance. Across our multi-stage\nevaluation pipeline, we also observe strong correlations, underscoring the\ncritical role of precise pointing capabilities in enabling multimodal models to\neffectively bridge abstract reasoning with concrete, real-world actions.\nProject page: https://pointarena.github.io/"}
{"id": "2505.09847", "pdf": "https://arxiv.org/pdf/2505.09847", "abs": "https://arxiv.org/abs/2505.09847", "authors": ["Liyang Zhao", "Olurotimi Seton", "Himadeep Reddy Reddivari", "Suvendu Jena", "Shadow Zhao", "Rachit Kumar", "Changshuai Wei"], "title": "Causal Predictive Optimization and Generation for Business AI", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "comment": null, "summary": "The sales process involves sales functions converting leads or opportunities\nto customers and selling more products to existing customers. The optimization\nof the sales process thus is key to success of any B2B business. In this work,\nwe introduce a principled approach to sales optimization and business AI,\nnamely the Causal Predictive Optimization and Generation, which includes three\nlayers: 1) prediction layer with causal ML 2) optimization layer with\nconstraint optimization and contextual bandit 3) serving layer with Generative\nAI and feedback-loop for system enhancement. We detail the implementation and\ndeployment of the system in LinkedIn, showcasing significant wins over legacy\nsystems and sharing learning and insight broadly applicable to this field."}
{"id": "2505.10089", "pdf": "https://arxiv.org/pdf/2505.10089", "abs": "https://arxiv.org/abs/2505.10089", "authors": ["Wei Liu", "Sony Trenous", "Leonardo F. R. Ribeiro", "Bill Byrne", "Felix Hieber"], "title": "XRAG: Cross-lingual Retrieval-Augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "We propose XRAG, a novel benchmark designed to evaluate the generation\nabilities of LLMs in cross-lingual Retrieval-Augmented Generation (RAG)\nsettings where the user language does not match the retrieval results. XRAG is\nconstructed from recent news articles to ensure that its questions require\nexternal knowledge to be answered. It covers the real-world scenarios of\nmonolingual and multilingual retrieval, and provides relevancy annotations for\neach retrieved document. Our novel dataset construction pipeline results in\nquestions that require complex reasoning, as evidenced by the significant gap\nbetween human and LLM performance. Consequently, XRAG serves as a valuable\nbenchmark for studying LLM reasoning abilities, even before considering the\nadditional cross-lingual complexity. Experimental results on five LLMs uncover\ntwo previously unreported challenges in cross-lingual RAG: 1) in the\nmonolingual retrieval setting, all evaluated models struggle with response\nlanguage correctness; 2) in the multilingual retrieval setting, the main\nchallenge lies in reasoning over retrieved information across languages rather\nthan generation of non-English text."}
{"id": "2505.10361", "pdf": "https://arxiv.org/pdf/2505.10361", "abs": "https://arxiv.org/abs/2505.10361", "authors": ["David Abel", "Michael Bowling", "André Barreto", "Will Dabney", "Shi Dong", "Steven Hansen", "Anna Harutyunyan", "Khimya Khetarpal", "Clare Lyle", "Razvan Pascanu", "Georgios Piliouras", "Doina Precup", "Jonathan Richens", "Mark Rowland", "Tom Schaul", "Satinder Singh"], "title": "Plasticity as the Mirror of Empowerment", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Agents are minimally entities that are influenced by their past observations\nand act to influence future observations. This latter capacity is captured by\nempowerment, which has served as a vital framing concept across artificial\nintelligence and cognitive science. This former capacity, however, is equally\nfoundational: In what ways, and to what extent, can an agent be influenced by\nwhat it observes? In this paper, we ground this concept in a universal\nagent-centric measure that we refer to as plasticity, and reveal a fundamental\nconnection to empowerment. Following a set of desiderata on a suitable\ndefinition, we define plasticity using a new information-theoretic quantity we\ncall the generalized directed information. We show that this new quantity\nstrictly generalizes the directed information introduced by Massey (1990) while\npreserving all of its desirable properties. Our first finding is that\nplasticity is the mirror of empowerment: The agent's plasticity is identical to\nthe empowerment of the environment, and vice versa. Our second finding\nestablishes a tension between the plasticity and empowerment of an agent,\nsuggesting that agent design needs to be mindful of both characteristics. We\nexplore the implications of these findings, and suggest that plasticity,\nempowerment, and their relationship are essential to understanding agency."}
{"id": "2505.09997", "pdf": "https://arxiv.org/pdf/2505.09997", "abs": "https://arxiv.org/abs/2505.09997", "authors": ["Jinhyun Jang", "Jiyeong Lee", "Kwanghoon Sohn"], "title": "Descriptive Image-Text Matching with Graded Contextual Similarity", "categories": ["cs.CV"], "comment": null, "summary": "Image-text matching aims to build correspondences between visual and textual\ndata by learning their pairwise similarities. Most existing approaches have\nadopted sparse binary supervision, indicating whether a pair of images and\nsentences matches or not. However, such sparse supervision covers a limited\nsubset of image-text relationships, neglecting their inherent many-to-many\ncorrespondences; an image can be described in numerous texts at different\ndescriptive levels. Moreover, existing approaches overlook the implicit\nconnections from general to specific descriptions, which form the underlying\nrationale for the many-to-many relationships between vision and language. In\nthis work, we propose descriptive image-text matching, called DITM, to learn\nthe graded contextual similarity between image and text by exploring the\ndescriptive flexibility of language. We formulate the descriptiveness score of\neach sentence with cumulative term frequency-inverse document frequency\n(TF-IDF) to balance the pairwise similarity according to the keywords in the\nsentence. Our method leverages sentence descriptiveness to learn robust\nimage-text matching in two key ways: (1) to refine the false negative labeling,\ndynamically relaxing the connectivity between positive and negative pairs, and\n(2) to build more precise matching, aligning a set of relevant sentences in a\ngeneric-to-specific order. By moving beyond rigid binary supervision, DITM\nenhances the discovery of both optimal matches and potential positive pairs.\nExtensive experiments on MS-COCO, Flickr30K, and CxC datasets demonstrate the\neffectiveness of our method in representing complex image-text relationships\ncompared to state-of-the-art approaches. In addition, DITM enhances the\nhierarchical reasoning ability of the model, supported by the extensive\nanalysis on HierarCaps benchmark."}
{"id": "2505.09848", "pdf": "https://arxiv.org/pdf/2505.09848", "abs": "https://arxiv.org/abs/2505.09848", "authors": ["Aditya Raj", "Golrokh Mirzaei"], "title": "Radiogenomic Bipartite Graph Representation Learning for Alzheimer's Disease Detection", "categories": ["cs.LG", "eess.IV"], "comment": "11 pages", "summary": "Imaging and genomic data offer distinct and rich features, and their\nintegration can unveil new insights into the complex landscape of diseases. In\nthis study, we present a novel approach utilizing radiogenomic data including\nstructural MRI images and gene expression data, for Alzheimer's disease\ndetection. Our framework introduces a novel heterogeneous bipartite graph\nrepresentation learning featuring two distinct node types: genes and images.\nThe network can effectively classify Alzheimer's disease (AD) into three\ndistinct stages:AD, Mild Cognitive Impairment (MCI), and Cognitive Normal (CN)\nclasses, utilizing a small dataset. Additionally, it identified which genes\nplay a significant role in each of these classification groups. We evaluate the\nperformance of our approach using metrics including classification accuracy,\nrecall, precision, and F1 score. The proposed technique holds potential for\nextending to radiogenomic-based classification to other diseases."}
{"id": "2505.10113", "pdf": "https://arxiv.org/pdf/2505.10113", "abs": "https://arxiv.org/abs/2505.10113", "authors": ["Xinlan Yan", "Di Wu", "Yibin Lei", "Christof Monz", "Iacer Calixto"], "title": "What Does Neuro Mean to Cardio? Investigating the Role of Clinical Specialty Data in Medical LLMs", "categories": ["cs.CL"], "comment": null, "summary": "In this paper, we introduce S-MedQA, an English medical question-answering\n(QA) dataset for benchmarking large language models in fine-grained clinical\nspecialties. We use S-MedQA to check the applicability of a popular hypothesis\nrelated to knowledge injection in the knowledge-intense scenario of medical QA,\nand show that: 1) training on data from a speciality does not necessarily lead\nto best performance on that specialty and 2) regardless of the specialty\nfine-tuned on, token probabilities of clinically relevant terms for all\nspecialties increase consistently. Thus, we believe improvement gains come\nmostly from domain shifting (e.g., general to medical) rather than knowledge\ninjection and suggest rethinking the role of fine-tuning data in the medical\ndomain. We release S-MedQA and all code needed to reproduce all our experiments\nto the research community."}
{"id": "2505.10399", "pdf": "https://arxiv.org/pdf/2505.10399", "abs": "https://arxiv.org/abs/2505.10399", "authors": ["Kaivalya Rawal", "Zihao Fu", "Eoin Delaney", "Chris Russell"], "title": "Evaluating Model Explanations without Ground Truth", "categories": ["cs.AI", "cs.LG", "I.2.6"], "comment": "https://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth", "summary": "There can be many competing and contradictory explanations for a single model\nprediction, making it difficult to select which one to use. Current explanation\nevaluation frameworks measure quality by comparing against ideal \"ground-truth\"\nexplanations, or by verifying model sensitivity to important inputs. We outline\nthe limitations of these approaches, and propose three desirable principles to\nground the future development of explanation evaluation strategies for local\nfeature importance explanations. We propose a ground-truth Agnostic eXplanation\nEvaluation framework (AXE) for evaluating and comparing model explanations that\nsatisfies these principles. Unlike prior approaches, AXE does not require\naccess to ideal ground-truth explanations for comparison, or rely on model\nsensitivity - providing an independent measure of explanation quality. We\nverify AXE by comparing with baselines, and show how it can be used to detect\nexplanation fairwashing. Our code is available at\nhttps://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth."}
{"id": "2505.09998", "pdf": "https://arxiv.org/pdf/2505.09998", "abs": "https://arxiv.org/abs/2505.09998", "authors": ["Ying Zang", "Yuanqi Hu", "Xinyu Chen", "Yuxia Xu", "Suhui Wang", "Chunan Yu", "Lanyun Zhu", "Deyi Ji", "Xin Xu", "Tianrun Chen"], "title": "From Air to Wear: Personalized 3D Digital Fashion with AR/VR Immersive 3D Sketching", "categories": ["cs.CV"], "comment": "8 pages, 5 figures", "summary": "In the era of immersive consumer electronics, such as AR/VR headsets and\nsmart devices, people increasingly seek ways to express their identity through\nvirtual fashion. However, existing 3D garment design tools remain inaccessible\nto everyday users due to steep technical barriers and limited data. In this\nwork, we introduce a 3D sketch-driven 3D garment generation framework that\nempowers ordinary users - even those without design experience - to create\nhigh-quality digital clothing through simple 3D sketches in AR/VR environments.\nBy combining a conditional diffusion model, a sketch encoder trained in a\nshared latent space, and an adaptive curriculum learning strategy, our system\ninterprets imprecise, free-hand input and produces realistic, personalized\ngarments. To address the scarcity of training data, we also introduce\nKO3DClothes, a new dataset of paired 3D garments and user-created sketches.\nExtensive experiments and user studies confirm that our method significantly\noutperforms existing baselines in both fidelity and usability, demonstrating\nits promise for democratized fashion design on next-generation consumer\nplatforms."}
{"id": "2505.09851", "pdf": "https://arxiv.org/pdf/2505.09851", "abs": "https://arxiv.org/abs/2505.09851", "authors": ["Shun Wang", "Shun-Li Shang", "Zi-Kui Liu", "Wenrui Hao"], "title": "ZENN: A Thermodynamics-Inspired Computational Framework for Heterogeneous Data-Driven Modeling", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "9 pages, 4 figures", "summary": "Traditional entropy-based methods - such as cross-entropy loss in\nclassification problems - have long been essential tools for quantifying\nuncertainty and disorder in data and developing artificial intelligence\nalgorithms. However, the rapid growth of data across various domains has\nintroduced new challenges, particularly the integration of heterogeneous\ndatasets with intrinsic disparities. In this paper, we extend zentropy theory\ninto the data science domain by introducing intrinsic entropy, enabling more\neffective learning from heterogeneous data sources. We propose a\nzentropy-enhanced neural network (ZENN) that simultaneously learns both energy\nand intrinsic entropy components, capturing the underlying structure of\nmulti-source data. To support this, we redesign the neural network architecture\nto better reflect the intrinsic properties and variability inherent in diverse\ndatasets. We demonstrate the effectiveness of ZENN on classification tasks and\nenergy landscape reconstructions, showing its superior generalization\ncapabilities and robustness-particularly in predicting high-order derivatives.\nAs a practical application, we employ ZENN to reconstruct the Helmholtz energy\nlandscape of Fe3Pt using data generated from DFT and capture key material\nbehaviors, including negative thermal expansion and the critical point in the\ntemperature-pressure space. Overall, our study introduces a novel approach for\ndata-driven machine learning grounded in zentropy theory, highlighting ZENN as\na versatile and robust deep learning framework for scientific problems\ninvolving complex, heterogeneous datasets."}
{"id": "2505.10143", "pdf": "https://arxiv.org/pdf/2505.10143", "abs": "https://arxiv.org/abs/2505.10143", "authors": ["Longchao Da", "Parth Mitesh Shah", "Kuan-Ru Liou", "Jiaxing Zhang", "Hua Wei"], "title": "GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs", "categories": ["cs.CL", "68T50, 68T30", "I.2.7; I.2.4; H.3.3"], "comment": "5 pages, 4 figures, accepted to IJCAI2025 demo track", "summary": "Large Language Models are now key assistants in human decision-making\nprocesses. However, a common note always seems to follow: \"LLMs can make\nmistakes. Be careful with important info.\" This points to the reality that not\nall outputs from LLMs are dependable, and users must evaluate them manually.\nThe challenge deepens as hallucinated responses, often presented with seemingly\nplausible explanations, create complications and raise trust issues among\nusers. To tackle such issue, this paper proposes GE-Chat, a knowledge Graph\nenhanced retrieval-augmented generation framework to provide Evidence-based\nresponse generation. Specifically, when the user uploads a material document, a\nknowledge graph will be created, which helps construct a retrieval-augmented\nagent, enhancing the agent's responses with additional knowledge beyond its\ntraining corpus. Then we leverage Chain-of-Thought (CoT) logic generation,\nn-hop sub-graph searching, and entailment-based sentence generation to realize\naccurate evidence retrieval. We demonstrate that our method improves the\nexisting models' performance in terms of identifying the exact evidence in a\nfree-form context, providing a reliable way to examine the resources of LLM's\nconclusion and help with the judgment of the trustworthiness."}
{"id": "2505.10468", "pdf": "https://arxiv.org/pdf/2505.10468", "abs": "https://arxiv.org/abs/2505.10468", "authors": ["Ranjan Sapkota", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "title": "AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge", "categories": ["cs.AI"], "comment": "32 pages, 14 figures, 11 tables", "summary": "This study critically distinguishes between AI Agents and Agentic AI,\noffering a structured conceptual taxonomy, application mapping, and challenge\nanalysis to clarify their divergent design philosophies and capabilities. We\nbegin by outlining the search strategy and foundational definitions,\ncharacterizing AI Agents as modular systems driven by Large Language Models\n(LLMs) and Large Image Models (LIMs) for narrow, task-specific automation.\nGenerative AI is positioned as a precursor, with AI Agents advancing through\ntool integration, prompt engineering, and reasoning enhancements. In contrast,\nAgentic AI systems represent a paradigmatic shift marked by multi-agent\ncollaboration, dynamic task decomposition, persistent memory, and orchestrated\nautonomy. Through a sequential evaluation of architectural evolution,\noperational mechanisms, interaction styles, and autonomy levels, we present a\ncomparative analysis across both paradigms. Application domains such as\ncustomer support, scheduling, and data summarization are contrasted with\nAgentic AI deployments in research automation, robotic coordination, and\nmedical decision support. We further examine unique challenges in each paradigm\nincluding hallucination, brittleness, emergent behavior, and coordination\nfailure and propose targeted solutions such as ReAct loops, RAG, orchestration\nlayers, and causal modeling. This work aims to provide a definitive roadmap for\ndeveloping robust, scalable, and explainable AI agent and Agentic AI-driven\nsystems. >AI Agents, Agent-driven, Vision-Language-Models, Agentic AI Decision\nSupport System, Agentic-AI Applications"}
{"id": "2505.10016", "pdf": "https://arxiv.org/pdf/2505.10016", "abs": "https://arxiv.org/abs/2505.10016", "authors": ["Shijie Lyu"], "title": "Application of YOLOv8 in monocular downward multiple Car Target detection", "categories": ["cs.CV", "cs.AI", "I.4.8; I.2.10"], "comment": "Accepted by the 5th International Conference on Signal Processing and\n  Machine Learning (CONF-SPML 2025), to appear in Applied and Computational\n  Engineering", "summary": "Autonomous driving technology is progressively transforming traditional car\ndriving methods, marking a significant milestone in modern transportation.\nObject detection serves as a cornerstone of autonomous systems, playing a vital\nrole in enhancing driving safety, enabling autonomous functionality, improving\ntraffic efficiency, and facilitating effective emergency responses. However,\ncurrent technologies such as radar for environmental perception, cameras for\nroad perception, and vehicle sensor networks face notable challenges, including\nhigh costs, vulnerability to weather and lighting conditions, and limited\nresolution.To address these limitations, this paper presents an improved\nautonomous target detection network based on YOLOv8. By integrating structural\nreparameterization technology, a bidirectional pyramid structure network model,\nand a novel detection pipeline into the YOLOv8 framework, the proposed approach\nachieves highly efficient and precise detection of multi-scale, small, and\nremote objects. Experimental results demonstrate that the enhanced model can\neffectively detect both large and small objects with a detection accuracy of\n65%, showcasing significant advancements over traditional methods.This improved\nmodel holds substantial potential for real-world applications and is\nwell-suited for autonomous driving competitions, such as the Formula Student\nAutonomous China (FSAC), particularly excelling in scenarios involving\nsingle-target and small-object detection."}
{"id": "2505.09854", "pdf": "https://arxiv.org/pdf/2505.09854", "abs": "https://arxiv.org/abs/2505.09854", "authors": ["Harikrishna Kuttivelil", "Katia Obraczka"], "title": "Chisme: Fully Decentralized Differentiated Deep Learning for Edge Intelligence", "categories": ["cs.LG", "cs.ET", "cs.MA", "cs.SI"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "As demand for intelligent services rises and edge devices become more\ncapable, distributed learning at the network edge has emerged as a key enabling\ntechnology. While existing paradigms like federated learning (FL) and\ndecentralized FL (DFL) enable privacy-preserving distributed learning in many\nscenarios, they face potential challenges in connectivity and synchronization\nimposed by resource-constrained and infrastructure-less environments. While\nmore robust, gossip learning (GL) algorithms have generally been designed for\nhomogeneous data distributions and may not suit all contexts. This paper\nintroduces Chisme, a novel suite of protocols designed to address the\nchallenges of implementing robust intelligence in the network edge,\ncharacterized by heterogeneous data distributions, episodic connectivity, and\nlack of infrastructure. Chisme includes both synchronous DFL (Chisme-DFL) and\nasynchronous GL (Chisme-GL) variants that enable collaborative yet\ndecentralized model training that considers underlying data heterogeneity. We\nintroduce a data similarity heuristic that allows agents to opportunistically\ninfer affinity with each other using the existing communication of model\nupdates in decentralized FL and GL. We leverage the heuristic to extend DFL's\nmodel aggregation and GL's model merge mechanisms for better personalized\ntraining while maintaining collaboration. While Chisme-DFL is a synchronous\ndecentralized approach whose resource utilization scales linearly with network\nsize, Chisme-GL is fully asynchronous and has a lower, constant resource\nrequirement independent of network size. We demonstrate that Chisme methods\noutperform their standard counterparts in model training over distributed and\nheterogeneous data in network scenarios ranging from less connected and\nreliable networks to fully connected and lossless networks."}
{"id": "2505.10182", "pdf": "https://arxiv.org/pdf/2505.10182", "abs": "https://arxiv.org/abs/2505.10182", "authors": ["Yoichi Ishibashi", "Taro Yano", "Masafumi Oyamada"], "title": "Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant improvements in\nreasoning capabilities through supervised fine-tuning and reinforcement\nlearning. However, when training reasoning models, these approaches are\nprimarily applicable to specific domains such as mathematics and programming,\nwhich imposes fundamental constraints on the breadth and scalability of\ntraining data. In contrast, continual pretraining (CPT) offers the advantage of\nnot requiring task-specific signals. Nevertheless, how to effectively\nsynthesize training data for reasoning and how such data affect a wide range of\ndomains remain largely unexplored. This study provides a detailed evaluation of\nReasoning CPT, a form of CPT that uses synthetic data to reconstruct the hidden\nthought processes underlying texts, based on the premise that texts are the\nresult of the author's thinking process. Specifically, we apply Reasoning CPT\nto Gemma2-9B using synthetic data with hidden thoughts derived from STEM and\nLaw corpora, and compare it to standard CPT on the MMLU benchmark. Our analysis\nreveals that Reasoning CPT consistently improves performance across all\nevaluated domains. Notably, reasoning skills acquired in one domain transfer\neffectively to others; the performance gap with conventional methods widens as\nproblem difficulty increases, with gains of up to 8 points on the most\nchallenging problems. Furthermore, models trained with hidden thoughts learn to\nadjust the depth of their reasoning according to problem difficulty."}
{"id": "2505.10543", "pdf": "https://arxiv.org/pdf/2505.10543", "abs": "https://arxiv.org/abs/2505.10543", "authors": ["Annie Wong", "Thomas Bäck", "Aske Plaat", "Niki van Stein", "Anna V. Kononova"], "title": "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While large language models demonstrate impressive performance on static\nbenchmarks, the true potential of large language models as self-learning and\nreasoning agents in dynamic environments remains unclear. This study\nsystematically evaluates the efficacy of self-reflection, heuristic mutation,\nand planning as prompting techniques to test the adaptive capabilities of\nagents. We conduct experiments with various open-source language models in\ndynamic environments and find that larger models generally outperform smaller\nones, but that strategic prompting can close this performance gap. Second, a\ntoo-long prompt can negatively impact smaller models on basic reactive tasks,\nwhile larger models show more robust behaviour. Third, advanced prompting\ntechniques primarily benefit smaller models on complex games, but offer less\nimprovement for already high-performing large language models. Yet, we find\nthat advanced reasoning methods yield highly variable outcomes: while capable\nof significantly improving performance when reasoning and decision-making\nalign, they also introduce instability and can lead to big performance drops.\nCompared to human performance, our findings reveal little evidence of true\nemergent reasoning. Instead, large language model performance exhibits\npersistent limitations in crucial areas such as planning, reasoning, and\nspatial coordination, suggesting that current-generation large language models\nstill suffer fundamental shortcomings that may not be fully overcome through\nself-reflective prompting alone. Reasoning is a multi-faceted task, and while\nreasoning methods like Chain of thought improves multi-step reasoning on math\nword problems, our findings using dynamic benchmarks highlight important\nshortcomings in general reasoning capabilities, indicating a need to move\nbeyond static benchmarks to capture the complexity of reasoning."}
{"id": "2505.10027", "pdf": "https://arxiv.org/pdf/2505.10027", "abs": "https://arxiv.org/abs/2505.10027", "authors": ["Shijie Lyu"], "title": "ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by the 4th International Conference on Computing Innovation\n  and Applied Physics (CONF-CIAP 2025), and will be published in EAI Community\n  Research Series-CORE or Theoretical and Natural Science (TNS)", "summary": "With the rapid advancement of remote sensing technology, super-resolution\nimage reconstruction is of great research and practical significance. Existing\ndeep learning methods have made progress but still face limitations in handling\ncomplex scenes and preserving image details. This paper proposes a\nreinforcement learning-based latent diffusion model (LDM) fine-tuning method\nfor remote sensing image super-resolution. The method constructs a\nreinforcement learning environment with states, actions, and rewards,\noptimizing decision objectives through proximal policy optimization (PPO)\nduring the reverse denoising process of the LDM model. Experiments on the\nRESISC45 dataset show significant improvements over the baseline model in PSNR,\nSSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11,\nand LPIPS reducing by 0.06-0.10, particularly in structured and complex natural\nscenes. The results demonstrate the method's effectiveness in enhancing\nsuper-resolution quality and adaptability across scenes."}
{"id": "2505.09855", "pdf": "https://arxiv.org/pdf/2505.09855", "abs": "https://arxiv.org/abs/2505.09855", "authors": ["Alexander Y. Ku", "Thomas L. Griffiths", "Stephanie C. Y. Chan"], "title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies."}
{"id": "2505.10185", "pdf": "https://arxiv.org/pdf/2505.10185", "abs": "https://arxiv.org/abs/2505.10185", "authors": ["Seongyun Lee", "Seungone Kim", "Minju Seo", "Yongrae Jo", "Dongyoung Go", "Hyeonbin Hwang", "Jinho Park", "Xiang Yue", "Sean Welleck", "Graham Neubig", "Moontae Lee", "Minjoon Seo"], "title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think", "categories": ["cs.CL", "cs.AI"], "comment": "Work in progress", "summary": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of\nmodern large language models, but our understanding of the reasoning strategies\nunderlying these capabilities remains limited. While some prior works have\nattempted to categorize CoTs using predefined strategy types, such approaches\nare constrained by human intuition and fail to capture the full diversity of\nmodel behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up\nframework for analyzing and steering model reasoning. Our method automatically\nextracts diverse reasoning criteria from model-generated CoTs, embeds them into\na semantic space, clusters them into representative categories, and derives\ncontrastive rubrics to interpret reasoning behavior. Human evaluations show\nthat this framework produces more interpretable and comprehensive analyses than\nexisting methods. Moreover, we demonstrate that this understanding enables\nperformance gains: we can predict which strategy a model is likely to use and\nguide it toward more effective alternatives. Finally, we provide practical\ninsights, such as that training data format (e.g., free-form vs.\nmultiple-choice) has a far greater impact on reasoning behavior than data\ndomain, underscoring the importance of format-aware model design."}
{"id": "2306.07615", "pdf": "https://arxiv.org/pdf/2306.07615", "abs": "https://arxiv.org/abs/2306.07615", "authors": ["Heqin Zhu", "Quan Quan", "Qingsong Yao", "Zaiyi Liu", "S. Kevin Zhou"], "title": "UOD: Universal One-shot Detection of Anatomical Landmarks", "categories": ["cs.CV", "cs.AI"], "comment": "Eealy accepted by MICCAI 2023. 11pages, 4 figures, 2 tables. arXiv\n  admin note: text overlap with arXiv:2203.06433", "summary": "One-shot medical landmark detection gains much attention and achieves great\nsuccess for its label-efficient training process. However, existing one-shot\nlearning methods are highly specialized in a single domain and suffer domain\npreference heavily in the situation of multi-domain unlabeled data. Moreover,\none-shot learning is not robust that it faces performance drop when annotating\na sub-optimal image. To tackle these issues, we resort to developing a\ndomain-adaptive one-shot landmark detection framework for handling multi-domain\nmedical images, named Universal One-shot Detection (UOD). UOD consists of two\nstages and two corresponding universal models which are designed as\ncombinations of domain-specific modules and domain-shared modules. In the first\nstage, a domain-adaptive convolution model is self-supervised learned to\ngenerate pseudo landmark labels. In the second stage, we design a\ndomain-adaptive transformer to eliminate domain preference and build the global\ncontext for multi-domain data. Even though only one annotated sample from each\ndomain is available for training, the domain-shared modules help UOD aggregate\nall one-shot samples to detect more robust and accurate landmarks. We\ninvestigated both qualitatively and quantitatively the proposed UOD on three\nwidely-used public X-ray datasets in different anatomical domains (i.e., head,\nhand, chest) and obtained state-of-the-art performances in each domain. The\ncode is available at\nhttps://github.com/heqin-zhu/UOD_universal_oneshot_detection."}
{"id": "2505.10030", "pdf": "https://arxiv.org/pdf/2505.10030", "abs": "https://arxiv.org/abs/2505.10030", "authors": ["Miit Daga", "Dhriti Parikh", "Swarna Priya Ramu"], "title": "DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera", "categories": ["cs.CV", "cs.LG"], "comment": "This paper is accepted for publication in IEEE Access journal and is\n  currently pending revisions before publication", "summary": "Coconut tree diseases are a serious risk to agricultural yield, particularly\nin developing countries where conventional farming practices restrict early\ndiagnosis and intervention. Current disease identification methods are manual,\nlabor-intensive, and non-scalable. In response to these limitations, we come up\nwith DeepSeqCoco, a deep learning based model for accurate and automatic\ndisease identification from coconut tree images. The model was tested under\nvarious optimizer settings, such as SGD, Adam, and hybrid configurations, to\nidentify the optimal balance between accuracy, minimization of loss, and\ncomputational cost. Results from experiments indicate that DeepSeqCoco can\nachieve as much as 99.5% accuracy (achieving up to 5% higher accuracy than\nexisting models) with the hybrid SGD-Adam showing the lowest validation loss of\n2.81%. It also shows a drop of up to 18% in training time and up to 85% in\nprediction time for input images. The results point out the promise of the\nmodel to improve precision agriculture through an AI-based, scalable, and\nefficient disease monitoring system."}
{"id": "2505.09861", "pdf": "https://arxiv.org/pdf/2505.09861", "abs": "https://arxiv.org/abs/2505.09861", "authors": ["John Bencina", "Erkut Aykutlug", "Yue Chen", "Zerui Zhang", "Stephanie Sorenson", "Shao Tang", "Changshuai Wei"], "title": "LiDDA: Data Driven Attribution at LinkedIn", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ME"], "comment": null, "summary": "Data Driven Attribution, which assigns conversion credits to marketing\ninteractions based on causal patterns learned from data, is the foundation of\nmodern marketing intelligence and vital to any marketing businesses and\nadvertising platform. In this paper, we introduce a unified transformer-based\nattribution approach that can handle member-level data, aggregate-level data,\nand integration of external macro factors. We detail the large scale\nimplementation of the approach at LinkedIn, showcasing significant impact. We\nalso share learning and insights that are broadly applicable to the marketing\nand ad tech fields."}
{"id": "2505.10202", "pdf": "https://arxiv.org/pdf/2505.10202", "abs": "https://arxiv.org/abs/2505.10202", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "YiMing Cheng", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "VQ-Logits: Compressing the Output Bottleneck of Large Language Models via Vector Quantized Logits", "categories": ["cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable success but face\nsignificant computational and memory challenges, particularly due to their\nextensive output vocabularies. The final linear projection layer, mapping\nhidden states to vocabulary-sized logits, often constitutes a substantial\nportion of the model's parameters and computational cost during inference.\nExisting methods like adaptive softmax or hierarchical softmax introduce\nstructural complexities. In this paper, we propose VQ-Logits, a novel approach\nthat leverages Vector Quantization (VQ) to drastically reduce the parameter\ncount and computational load of the LLM output layer. VQ-Logits replaces the\nlarge V * dmodel output embedding matrix with a small, shared codebook of K\nembedding vectors (K << V ). Each token in the vocabulary is mapped to one of\nthese K codebook vectors. The LLM predicts logits over this compact codebook,\nwhich are then efficiently \"scattered\" to the full vocabulary space using the\nlearned or preassigned mapping. We demonstrate through extensive experiments on\nstandard language modeling benchmarks (e.g., WikiText-103, C4) that VQ-Logits\ncan achieve up to 99% parameter reduction in the output layer and 6x speedup in\nlogit computation, with only a marginal 4% increase in perplexity compared to\nfull softmax baselines. We further provide detailed ablation studies on\ncodebook size, initialization, and learning strategies, showcasing the\nrobustness and effectiveness of our approach."}
{"id": "2410.13778", "pdf": "https://arxiv.org/pdf/2410.13778", "abs": "https://arxiv.org/abs/2410.13778", "authors": ["Michelangelo Olmo Nogara Notarianni", "Filippo Leveni", "Diego Stucchi", "Luca Frittoli", "Giacomo Boracchi"], "title": "Change Detection in Multivariate data streams: Online Analysis with Kernel-QuantTree", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "AALTD workshop at ECML 2024 (https://ecml-aaltd.github.io/aaltd2024/)", "summary": "We present Kernel-QuantTree Exponentially Weighted Moving Average (KQT-EWMA),\na non-parametric change-detection algorithm that combines the Kernel-QuantTree\n(KQT) histogram and the EWMA statistic to monitor multivariate data streams\nonline. The resulting monitoring scheme is very flexible, since histograms can\nbe used to model any stationary distribution, and practical, since the\ndistribution of test statistics does not depend on the distribution of\ndatastream in stationary conditions (non-parametric monitoring). KQT-EWMA\nenables controlling false alarms by operating at a pre-determined Average Run\nLength ($ARL_0$), which measures the expected number of stationary samples to\nbe monitored before triggering a false alarm. The latter peculiarity is in\ncontrast with most non-parametric change-detection tests, which rarely can\ncontrol the $ARL_0$ a priori. Our experiments on synthetic and real-world\ndatasets demonstrate that KQT-EWMA can control $ARL_0$ while achieving\ndetection delays comparable to or lower than state-of-the-art methods designed\nto work in the same conditions."}
{"id": "2505.10046", "pdf": "https://arxiv.org/pdf/2505.10046", "abs": "https://arxiv.org/abs/2505.10046", "authors": ["Bingda Tang", "Boyang Zheng", "Xichen Pan", "Sayak Paul", "Saining Xie"], "title": "Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Text-to-Image Synthesis", "categories": ["cs.CV"], "comment": null, "summary": "This paper does not describe a new method; instead, it provides a thorough\nexploration of an important yet understudied design space related to recent\nadvances in text-to-image synthesis -- specifically, the deep fusion of large\nlanguage models (LLMs) and diffusion transformers (DiTs) for multi-modal\ngeneration. Previous studies mainly focused on overall system performance\nrather than detailed comparisons with alternative methods, and key design\ndetails and training recipes were often left undisclosed. These gaps create\nuncertainty about the real potential of this approach. To fill these gaps, we\nconduct an empirical study on text-to-image generation, performing controlled\ncomparisons with established baselines, analyzing important design choices, and\nproviding a clear, reproducible recipe for training at scale. We hope this work\noffers meaningful data points and practical guidelines for future research in\nmulti-modal generation."}
{"id": "2505.09864", "pdf": "https://arxiv.org/pdf/2505.09864", "abs": "https://arxiv.org/abs/2505.09864", "authors": ["Aditya Panangat"], "title": "BINGO: A Novel Pruning Mechanism to Reduce the Size of Neural Networks", "categories": ["cs.LG"], "comment": "6 pages, 0 figures, 2 tables", "summary": "Over the past decade, the use of machine learning has increased\nexponentially. Models are far more complex than ever before, growing to\ngargantuan sizes and housing millions of weights. Unfortunately, the fact that\nlarge models have become the state of the art means that it often costs\nmillions of dollars to train and operate them. These expenses not only hurt\ncompanies but also bar non-wealthy individuals from contributing to new\ndevelopments and force consumers to pay greater prices for AI. Current methods\nused to prune models, such as iterative magnitude pruning, have shown great\naccuracy but require an iterative training sequence that is incredibly\ncomputationally and environmentally taxing. To solve this problem, BINGO is\nintroduced. BINGO, during the training pass, studies specific subsets of a\nneural network one at a time to gauge how significant of a role each weight\nplays in contributing to a network's accuracy. By the time training is done,\nBINGO generates a significance score for each weight, allowing for\ninsignificant weights to be pruned in one shot. BINGO provides an\naccuracy-preserving pruning technique that is less computationally intensive\nthan current methods, allowing for a world where AI growth does not have to\nmean model growth, as well."}
{"id": "2505.10218", "pdf": "https://arxiv.org/pdf/2505.10218", "abs": "https://arxiv.org/abs/2505.10218", "authors": ["Zongsheng Wang", "Kaili Sun", "Bowen Wu", "Qun Yu", "Ying Li", "Baoxun Wang"], "title": "RAIDEN-R1: Improving Role-awareness of LLMs via GRPO with Verifiable Reward", "categories": ["cs.CL"], "comment": null, "summary": "Role-playing conversational agents (RPCAs) face persistent challenges in\nmaintaining role consistency. To address this, we propose RAIDEN-R1, a novel\nreinforcement learning framework that integrates Verifiable Role-Awareness\nReward (VRAR). The method introduces both singular and multi-term mining\nstrategies to generate quantifiable rewards by assessing role-specific keys.\nAdditionally, we construct a high-quality, role-aware Chain-of-Thought dataset\nthrough multi-LLM collaboration, and implement experiments to enhance reasoning\ncoherence. Experiments on the RAIDEN benchmark demonstrate RAIDEN-R1's\nsuperiority: our 14B-GRPO model achieves 88.04% and 88.65% accuracy on\nScript-Based Knowledge and Conversation Memory metrics, respectively,\noutperforming baseline models while maintaining robustness. Case analyses\nfurther reveal the model's enhanced ability to resolve conflicting contextual\ncues and sustain first-person narrative consistency. This work bridges the\nnon-quantifiability gap in RPCA training and provides insights into role-aware\nreasoning patterns, advancing the development of RPCAs."}
{"id": "2505.03084", "pdf": "https://arxiv.org/pdf/2505.03084", "abs": "https://arxiv.org/abs/2505.03084", "authors": ["Shashank Kapoor", "Sanjay Surendranath Girija", "Lakshit Arora", "Dipen Pradhan", "Ankit Shetgaonkar", "Aman Raj"], "title": "Adversarial Attacks in Multimodal Systems: A Practitioner's Survey", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted in IEEE COMPSAC 2025", "summary": "The introduction of multimodal models is a huge step forward in Artificial\nIntelligence. A single model is trained to understand multiple modalities:\ntext, image, video, and audio. Open-source multimodal models have made these\nbreakthroughs more accessible. However, considering the vast landscape of\nadversarial attacks across these modalities, these models also inherit\nvulnerabilities of all the modalities, and ultimately, the adversarial threat\namplifies. While broad research is available on possible attacks within or\nacross these modalities, a practitioner-focused view that outlines attack types\nremains absent in the multimodal world. As more Machine Learning Practitioners\nadopt, fine-tune, and deploy open-source models in real-world applications,\nit's crucial that they can view the threat landscape and take the preventive\nactions necessary. This paper addresses the gap by surveying adversarial\nattacks targeting all four modalities: text, image, video, and audio. This\nsurvey provides a view of the adversarial attack landscape and presents how\nmultimodal adversarial threats have evolved. To the best of our knowledge, this\nsurvey is the first comprehensive summarization of the threat landscape in the\nmultimodal world."}
{"id": "2505.10049", "pdf": "https://arxiv.org/pdf/2505.10049", "abs": "https://arxiv.org/abs/2505.10049", "authors": ["Jinlong Fan", "Xuepu Zeng", "Jing Zhang", "Mingming Gong", "Yuxiang Yang", "Dacheng Tao"], "title": "Advances in Radiance Field for Dynamic Scene: From Neural Field to Gaussian Field", "categories": ["cs.CV"], "comment": null, "summary": "Dynamic scene representation and reconstruction have undergone transformative\nadvances in recent years, catalyzed by breakthroughs in neural radiance fields\nand 3D Gaussian splatting techniques. While initially developed for static\nenvironments, these methodologies have rapidly evolved to address the\ncomplexities inherent in 4D dynamic scenes through an expansive body of\nresearch. Coupled with innovations in differentiable volumetric rendering,\nthese approaches have significantly enhanced the quality of motion\nrepresentation and dynamic scene reconstruction, thereby garnering substantial\nattention from the computer vision and graphics communities. This survey\npresents a systematic analysis of over 200 papers focused on dynamic scene\nrepresentation using radiance field, spanning the spectrum from implicit neural\nrepresentations to explicit Gaussian primitives. We categorize and evaluate\nthese works through multiple critical lenses: motion representation paradigms,\nreconstruction techniques for varied scene dynamics, auxiliary information\nintegration strategies, and regularization approaches that ensure temporal\nconsistency and physical plausibility. We organize diverse methodological\napproaches under a unified representational framework, concluding with a\ncritical examination of persistent challenges and promising research\ndirections. By providing this comprehensive overview, we aim to establish a\ndefinitive reference for researchers entering this rapidly evolving field while\noffering experienced practitioners a systematic understanding of both\nconceptual principles and practical frontiers in dynamic scene reconstruction."}
{"id": "2505.09901", "pdf": "https://arxiv.org/pdf/2505.09901", "abs": "https://arxiv.org/abs/2505.09901", "authors": ["Ziyuan Zhang", "Darcy Wang", "Ningyuan Chen", "Rodrigo Mansur", "Vahid Sarhangian"], "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements."}
{"id": "2505.10260", "pdf": "https://arxiv.org/pdf/2505.10260", "abs": "https://arxiv.org/abs/2505.10260", "authors": ["Poli Apollinaire Nemkova", "Solomon Ubani", "Mark V. Albert"], "title": "Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the era of increasingly sophisticated natural language processing (NLP)\nsystems, large language models (LLMs) have demonstrated remarkable potential\nfor diverse applications, including tasks requiring nuanced textual\nunderstanding and contextual reasoning. This study investigates the\ncapabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3,\nMistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex\ntextual dataset comprising social media posts in Russian and Ukrainian.\nSpecifically, the focus is on the binary classification task of identifying\nreferences to human rights violations within the dataset.\n  To evaluate the effectiveness of these models, their annotations are compared\nagainst a gold standard set of human double-annotated labels across 1000\nsamples. The analysis includes assessing annotation performance under different\nprompting conditions, with prompts provided in both English and Russian.\nAdditionally, the study explores the unique patterns of errors and\ndisagreements exhibited by each model, offering insights into their strengths,\nlimitations, and cross-linguistic adaptability.\n  By juxtaposing LLM outputs with human annotations, this research contributes\nto understanding the reliability and applicability of LLMs for sensitive,\ndomain-specific tasks in multilingual contexts. It also sheds light on how\nlanguage models handle inherently subjective and context-dependent judgments, a\ncritical consideration for their deployment in real-world scenarios."}
{"id": "2505.09593", "pdf": "https://arxiv.org/pdf/2505.09593", "abs": "https://arxiv.org/abs/2505.09593", "authors": ["Filippo Leveni", "Guilherme Weigert Cassales", "Bernhard Pfahringer", "Albert Bifet", "Giacomo Boracchi"], "title": "Online Isolation Forest", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at International Conference on Machine Learning (ICML 2024)", "summary": "The anomaly detection literature is abundant with offline methods, which\nrequire repeated access to data in memory, and impose impractical assumptions\nwhen applied to a streaming context. Existing online anomaly detection methods\nalso generally fail to address these constraints, resorting to periodic\nretraining to adapt to the online context. We propose Online-iForest, a novel\nmethod explicitly designed for streaming conditions that seamlessly tracks the\ndata generating process as it evolves over time. Experimental validation on\nreal-world datasets demonstrated that Online-iForest is on par with online\nalternatives and closely rivals state-of-the-art offline anomaly detection\ntechniques that undergo periodic retraining. Notably, Online-iForest\nconsistently outperforms all competitors in terms of efficiency, making it a\npromising solution in applications where fast identification of anomalies is of\nprimary importance such as cybersecurity, fraud and fault detection."}
{"id": "2505.10055", "pdf": "https://arxiv.org/pdf/2505.10055", "abs": "https://arxiv.org/abs/2505.10055", "authors": ["Ijazul Haq", "Yingjie Zhang", "Irfan Ali Khan"], "title": "PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper evaluates the performance of Large Multimodal Models (LMMs) on\nOptical Character Recognition (OCR) in the low-resource Pashto language.\nNatural Language Processing (NLP) in Pashto faces several challenges due to the\ncursive nature of its script and a scarcity of structured datasets. To address\nthis, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one\nmillion images annotated with bounding boxes at word, line, and document\nlevels, suitable for training and evaluating models based on different\narchitectures, including Convolutional Neural Networks (CNNs) and Transformers.\nPsOCR covers variations across 1,000 unique font families, colors, image sizes,\nand layouts. A benchmark subset of 10K images was selected to evaluate the\nperformance of several LMMs, including seven open-source models: DeepSeek's\nJanus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four\nclosed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results\ndemonstrate that Gemini achieves the best performance among all models, whereas\namong open-source models, Qwen-7B stands out. This work provides an insightful\nassessment of the capabilities and limitations of current LMMs for OCR tasks in\nPashto and establishes a foundation for further research not only in Pashto OCR\nbut also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is\navailable at https://github.com/zirak-ai/PashtoOCR."}
{"id": "2505.09907", "pdf": "https://arxiv.org/pdf/2505.09907", "abs": "https://arxiv.org/abs/2505.09907", "authors": ["Linwei Zhang", "LuFeng", "Ruijia Liang"], "title": "Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "With the growing demand for healthy foods, agricultural product price\nforecasting has become increasingly important. Hass avocados, as a high-value\ncrop, exhibit complex price fluctuations influenced by factors such as\nseasonality, region, and weather. Traditional prediction models often struggle\nwith highly nonlinear and dynamic data. To address this, we propose a hybrid\ndeep learning model, TCN-MLP-Attention Architecture, combining Temporal\nConvolutional Networks (TCN) for sequential feature extraction, Multi-Layer\nPerceptrons (MLP) for nonlinear interactions, and an Attention mechanism for\ndynamic feature weighting. The dataset used covers over 50,000 records of Hass\navocado sales across the U.S. from 2015 to 2018, including variables such as\nsales volume, average price, time, region, weather, and variety type, collected\nfrom point-of-sale systems and the Hass Avocado Board. After systematic\npreprocessing, including missing value imputation and feature normalization,\nthe proposed model was trained and evaluated. Experimental results demonstrate\nthat the TCN-MLP-Attention model achieves excellent predictive performance,\nwith an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods.\nThis research provides a scalable and effective approach for time series\nforecasting in agricultural markets and offers valuable insights for\nintelligent supply chain management and price strategy optimization."}
{"id": "2505.10261", "pdf": "https://arxiv.org/pdf/2505.10261", "abs": "https://arxiv.org/abs/2505.10261", "authors": ["Rui Yang", "Huitao Li", "Matthew Yu Heng Wong", "Yuhe Ke", "Xin Li", "Kunyu Yu", "Jingchi Liao", "Jonathan Chong Kai Liew", "Sabarinath Vinod Nair", "Jasmine Chiat Ling Ong", "Irene Li", "Douglas Teodoro", "Chuan Hong", "Daniel Shu Wei Ting", "Nan Liu"], "title": "The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Natural language processing (NLP) has been traditionally applied to medicine,\nand generative large language models (LLMs) have become prominent recently.\nHowever, the differences between them across different medical tasks remain\nunderexplored. We analyzed 19,123 studies, finding that generative LLMs\ndemonstrate advantages in open-ended tasks, while traditional NLP dominates in\ninformation extraction and analysis tasks. As these technologies advance,\nethical use of them is essential to ensure their potential in medical\napplications."}
{"id": "2505.09666", "pdf": "https://arxiv.org/pdf/2505.09666", "abs": "https://arxiv.org/abs/2505.09666", "authors": ["Yumin Choi", "Jinheon Baek", "Sung Ju Hwang"], "title": "System Prompt Optimization with Meta-Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance."}
{"id": "2505.10072", "pdf": "https://arxiv.org/pdf/2505.10072", "abs": "https://arxiv.org/abs/2505.10072", "authors": ["Rui-Yang Ju", "Sheng-Yen Huang", "Yi-Ping Hung"], "title": "ToonifyGB: StyleGAN-based Gaussian Blendshapes for 3D Stylized Head Avatars", "categories": ["cs.CV"], "comment": null, "summary": "The introduction of 3D Gaussian blendshapes has enabled the real-time\nreconstruction of animatable head avatars from monocular video. Toonify, a\nStyleGAN-based framework, has become widely used for facial image stylization.\nTo extend Toonify for synthesizing diverse stylized 3D head avatars using\nGaussian blendshapes, we propose an efficient two-stage framework, ToonifyGB.\nIn Stage 1 (stylized video generation), we employ an improved StyleGAN to\ngenerate the stylized video from the input video frames, which addresses the\nlimitation of cropping aligned faces at a fixed resolution as preprocessing for\nnormal StyleGAN. This process provides a more stable video, which enables\nGaussian blendshapes to better capture the high-frequency details of the video\nframes, and efficiently generate high-quality animation in the next stage. In\nStage 2 (Gaussian blendshapes synthesis), we learn a stylized neutral head\nmodel and a set of expression blendshapes from the generated video. By\ncombining the neutral head model with expression blendshapes, ToonifyGB can\nefficiently render stylized avatars with arbitrary expressions. We validate the\neffectiveness of ToonifyGB on the benchmark dataset using two styles: Arcane\nand Pixar."}
{"id": "2505.09922", "pdf": "https://arxiv.org/pdf/2505.09922", "abs": "https://arxiv.org/abs/2505.09922", "authors": ["Zichen Liu", "Wei Zhang", "Tiejun Li"], "title": "Improving the Euclidean Diffusion Generation of Manifold Data by Mitigating Score Function Singularity", "categories": ["cs.LG"], "comment": "22 pages", "summary": "Euclidean diffusion models have achieved remarkable success in generative\nmodeling across diverse domains, and they have been extended to manifold case\nin recent advances. Instead of explicitly utilizing the structure of special\nmanifolds as studied in previous works, we investigate direct sampling of the\nEuclidean diffusion models for general manifold-constrained data in this paper.\nWe reveal the multiscale singularity of the score function in the embedded\nspace of manifold, which hinders the accuracy of diffusion-generated samples.\nWe then present an elaborate theoretical analysis of the singularity structure\nof the score function by separating it along the tangential and normal\ndirections of the manifold. To mitigate the singularity and improve the\nsampling accuracy, we propose two novel methods: (1) Niso-DM, which introduces\nnon-isotropic noise along the normal direction to reduce scale discrepancies,\nand (2) Tango-DM, which trains only the tangential component of the score\nfunction using a tangential-only loss function. Numerical experiments\ndemonstrate that our methods achieve superior performance on distributions over\nvarious manifolds with complex geometries."}
{"id": "2505.10282", "pdf": "https://arxiv.org/pdf/2505.10282", "abs": "https://arxiv.org/abs/2505.10282", "authors": ["Dubai Li", "Nan Jiang", "Kangping Huang", "Ruiqi Tu", "Shuyu Ouyang", "Huayu Yu", "Lin Qiao", "Chen Yu", "Tianshu Zhou", "Danyang Tong", "Qian Wang", "Mengtao Li", "Xiaofeng Zeng", "Yu Tian", "Xinping Tian", "Jingsong Li"], "title": "From Questions to Clinical Recommendations: Large Language Models Driving Evidence-Based Clinical Decision Making", "categories": ["cs.CL"], "comment": null, "summary": "Clinical evidence, derived from rigorous research and data analysis, provides\nhealthcare professionals with reliable scientific foundations for informed\ndecision-making. Integrating clinical evidence into real-time practice is\nchallenging due to the enormous workload, complex professional processes, and\ntime constraints. This highlights the need for tools that automate evidence\nsynthesis to support more efficient and accurate decision making in clinical\nsettings. This study introduces Quicker, an evidence-based clinical decision\nsupport system powered by large language models (LLMs), designed to automate\nevidence synthesis and generate clinical recommendations modeled after standard\nclinical guideline development processes. Quicker implements a fully automated\nchain that covers all phases, from questions to clinical recommendations, and\nfurther enables customized decision-making through integrated tools and\ninteractive user interfaces. To evaluate Quicker's capabilities, we developed\nthe Q2CRBench-3 benchmark dataset, based on clinical guideline development\nrecords for three different diseases. Experimental results highlighted\nQuicker's strong performance, with fine-grained question decomposition tailored\nto user preferences, retrieval sensitivities comparable to human experts, and\nliterature screening performance approaching comprehensive inclusion of\nrelevant studies. In addition, Quicker-assisted evidence assessment effectively\nsupported human reviewers, while Quicker's recommendations were more\ncomprehensive and logically coherent than those of clinicians. In system-level\ntesting, collaboration between a single reviewer and Quicker reduced the time\nrequired for recommendation development to 20-40 minutes. In general, our\nfindings affirm the potential of Quicker to help physicians make quicker and\nmore reliable evidence-based clinical decisions."}
{"id": "2505.09704", "pdf": "https://arxiv.org/pdf/2505.09704", "abs": "https://arxiv.org/abs/2505.09704", "authors": ["Roberto Pereira", "Fernanda Famá", "Charalampos Kalalas", "Paolo Dini"], "title": "Energy-Efficient Federated Learning for AIoT using Clustering Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "While substantial research has been devoted to optimizing model performance,\nconvergence rates, and communication efficiency, the energy implications of\nfederated learning (FL) within Artificial Intelligence of Things (AIoT)\nscenarios are often overlooked in the existing literature. This study examines\nthe energy consumed during the FL process, focusing on three main\nenergy-intensive processes: pre-processing, communication, and local learning,\nall contributing to the overall energy footprint. We rely on the observation\nthat device/client selection is crucial for speeding up the convergence of\nmodel training in a distributed AIoT setting and propose two\nclustering-informed methods. These clustering solutions are designed to group\nAIoT devices with similar label distributions, resulting in clusters composed\nof nearly heterogeneous devices. Hence, our methods alleviate the heterogeneity\noften encountered in real-world distributed learning applications. Throughout\nextensive numerical experimentation, we demonstrate that our clustering\nstrategies typically achieve high convergence rates while maintaining low\nenergy consumption when compared to other recent approaches available in the\nliterature."}
{"id": "2505.10088", "pdf": "https://arxiv.org/pdf/2505.10088", "abs": "https://arxiv.org/abs/2505.10088", "authors": ["Yuncheng Guo", "Xiaodong Gu"], "title": "MMRL++: Parameter-Efficient and Interaction-Aware Representation Learning for Vision-Language Models", "categories": ["cs.CV"], "comment": "Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract appearing here is slightly shorter than that in the\n  PDF file", "summary": "Large-scale pre-trained Vision-Language Models (VLMs) have significantly\nadvanced transfer learning across diverse tasks. However, adapting these models\nwith limited few-shot data often leads to overfitting, undermining their\nability to generalize to new tasks. To address this, we propose Multi-Modal\nRepresentation Learning (MMRL), which introduces a shared, learnable,\nmodality-agnostic representation space. MMRL generates space tokens projected\ninto both text and image encoders as representation tokens, enabling more\neffective cross-modal interactions. Unlike prior methods that mainly optimize\nclass token features, MMRL inserts representation tokens into higher encoder\nlayers--where task-specific features are more prominent--while preserving\ngeneral knowledge in the lower layers. During training, both class and\nrepresentation features are jointly optimized: a trainable projection layer is\napplied to representation tokens for task adaptation, while the projection\nlayer for class token remains frozen to retain pre-trained knowledge. To\nfurther promote generalization, we introduce a regularization term aligning\nclass and text features with the frozen VLM's zero-shot features. At inference,\na decoupling strategy uses both class and representation features for base\ntasks, but only class features for novel tasks due to their stronger\ngeneralization. Building upon this, we propose MMRL++, a parameter-efficient\nand interaction-aware extension that significantly reduces trainable parameters\nand enhances intra-modal interactions--particularly across the layers of\nrepresentation tokens--allowing gradient sharing and instance-specific\ninformation to propagate more effectively through the network. Extensive\nexperiments on 15 datasets demonstrate that MMRL and MMRL++ consistently\noutperform state-of-the-art methods, achieving a strong balance between\ntask-specific adaptation and generalization."}
{"id": "2505.09925", "pdf": "https://arxiv.org/pdf/2505.09925", "abs": "https://arxiv.org/abs/2505.09925", "authors": ["Yutao Yang", "Jie Zhou", "Junsong Li", "Qianjun Pan", "Bihao Zhan", "Qin Chen", "Xipeng Qiu", "Liang He"], "title": "Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces an interactive continual learning paradigm where AI\nmodels dynamically learn new skills from real-time human feedback while\nretaining prior knowledge. This paradigm distinctively addresses two major\nlimitations of traditional continual learning: (1) dynamic model updates using\nstreaming, real-time human-annotated data, rather than static datasets with\nfixed labels, and (2) the assumption of clean labels, by explicitly handling\nthe noisy feedback common in real-world interactions. To tackle these problems,\nwe propose RiCL, a Reinforced interactive Continual Learning framework\nleveraging Large Language Models (LLMs) to learn new skills effectively from\ndynamic feedback. RiCL incorporates three key components: a temporal\nconsistency-aware purifier to automatically discern clean from noisy samples in\ndata streams; an interaction-aware direct preference optimization strategy to\nalign model behavior with human intent by reconciling AI-generated and\nhuman-provided feedback; and a noise-resistant contrastive learning module that\ncaptures robust representations by exploiting inherent data relationships, thus\navoiding reliance on potentially unreliable labels. Extensive experiments on\ntwo benchmark datasets (FewRel and TACRED), contaminated with realistic noise\npatterns, demonstrate that our RiCL approach substantially outperforms existing\ncombinations of state-of-the-art online continual learning and noisy-label\nlearning methods."}
{"id": "2505.10320", "pdf": "https://arxiv.org/pdf/2505.10320", "abs": "https://arxiv.org/abs/2505.10320", "authors": ["Chenxi Whitehouse", "Tianlu Wang", "Ping Yu", "Xian Li", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 8 tables, 11 figures", "summary": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses."}
{"id": "2505.09716", "pdf": "https://arxiv.org/pdf/2505.09716", "abs": "https://arxiv.org/abs/2505.09716", "authors": ["George Dimitriadis. Spyridon Samothrakis"], "title": "Out-of-distribution generalisation is hard: evidence from ARC-like tasks", "categories": ["cs.LG", "cs.AI"], "comment": "Submission to NeurIPS 2025", "summary": "Out-of-distribution (OOD) generalisation is considered a hallmark of human\nand animal intelligence. To achieve OOD through composition, a system must\ndiscover the environment-invariant properties of experienced input-output\nmappings and transfer them to novel inputs. This can be realised if an\nintelligent system can identify appropriate, task-invariant, and composable\ninput features, as well as the composition methods, thus allowing it to act\nbased not on the interpolation between learnt data points but on the\ntask-invariant composition of those features. We propose that in order to\nconfirm that an algorithm does indeed learn compositional structures from data,\nit is not enough to just test on an OOD setup, but one also needs to confirm\nthat the features identified are indeed compositional. We showcase this by\nexploring two tasks with clearly defined OOD metrics that are not OOD solvable\nby three commonly used neural networks: a Multi-Layer Perceptron (MLP), a\nConvolutional Neural Network (CNN), and a Transformer. In addition, we develop\ntwo novel network architectures imbued with biases that allow them to be\nsuccessful in OOD scenarios. We show that even with correct biases and almost\nperfect OOD performance, an algorithm can still fail to learn the correct\nfeatures for compositional generalisation."}
{"id": "2505.10118", "pdf": "https://arxiv.org/pdf/2505.10118", "abs": "https://arxiv.org/abs/2505.10118", "authors": ["Yangfu Li", "Hongjian Zhan", "Tianyi Chen", "Qi Liu", "Yue Lu"], "title": "Why 1 + 1 < 1 in Visual Token Pruning: Beyond Naive Integration via Multi-Objective Balanced Covering", "categories": ["cs.CV", "cs.CL"], "comment": "31 pages,9 figures,conference", "summary": "Existing visual token pruning methods target prompt alignment and visual\npreservation with static strategies, overlooking the varying relative\nimportance of these objectives across tasks, which leads to inconsistent\nperformance. To address this, we derive the first closed-form error bound for\nvisual token pruning based on the Hausdorff distance, uniformly characterizing\nthe contributions of both objectives. Moreover, leveraging $\\epsilon$-covering\ntheory, we reveal an intrinsic trade-off between these objectives and quantify\ntheir optimal attainment levels under a fixed budget. To practically handle\nthis trade-off, we propose Multi-Objective Balanced Covering (MoB), which\nreformulates visual token pruning as a bi-objective covering problem. In this\nframework, the attainment trade-off reduces to budget allocation via greedy\nradius trading. MoB offers a provable performance bound and linear scalability\nwith respect to the number of input visual tokens, enabling adaptation to\nchallenging pruning scenarios. Extensive experiments show that MoB preserves\n96.4% of performance for LLaVA-1.5-7B using only 11.1% of the original visual\ntokens and accelerates LLaVA-Next-7B by 1.3-1.5$\\times$ with negligible\nperformance loss. Additionally, evaluations on Qwen2-VL and Video-LLaVA confirm\nthat MoB integrates seamlessly into advanced MLLMs and diverse vision-language\ntasks."}
{"id": "2505.09949", "pdf": "https://arxiv.org/pdf/2505.09949", "abs": "https://arxiv.org/abs/2505.09949", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Samgyu Yang", "Abdulrahman Faden"], "title": "Advanced Crash Causation Analysis for Freeway Safety: A Large Language Model Approach to Identifying Key Contributing Factors", "categories": ["cs.LG", "cs.CL", "stat.AP"], "comment": null, "summary": "Understanding the factors contributing to traffic crashes and developing\nstrategies to mitigate their severity is essential. Traditional statistical\nmethods and machine learning models often struggle to capture the complex\ninteractions between various factors and the unique characteristics of each\ncrash. This research leverages large language model (LLM) to analyze freeway\ncrash data and provide crash causation analysis accordingly. By compiling 226\ntraffic safety studies related to freeway crashes, a training dataset\nencompassing environmental, driver, traffic, and geometric design factors was\ncreated. The Llama3 8B model was fine-tuned using QLoRA to enhance its\nunderstanding of freeway crashes and their contributing factors, as covered in\nthese studies. The fine-tuned Llama3 8B model was then used to identify crash\ncausation without pre-labeled data through zero-shot classification, providing\ncomprehensive explanations to ensure that the identified causes were reasonable\nand aligned with existing research. Results demonstrate that LLMs effectively\nidentify primary crash causes such as alcohol-impaired driving, speeding,\naggressive driving, and driver inattention. Incorporating event data, such as\nroad maintenance, offers more profound insights. The model's practical\napplicability and potential to improve traffic safety measures were validated\nby a high level of agreement among researchers in the field of traffic safety,\nas reflected in questionnaire results with 88.89%. This research highlights the\ncomplex nature of traffic crashes and how LLMs can be used for comprehensive\nanalysis of crash causation and other contributing factors. Moreover, it\nprovides valuable insights and potential countermeasures to aid planners and\npolicymakers in developing more effective and efficient traffic safety\npractices."}
{"id": "2505.10354", "pdf": "https://arxiv.org/pdf/2505.10354", "abs": "https://arxiv.org/abs/2505.10354", "authors": ["Yile Wang", "Zhanyu Shen", "Hui Huang"], "title": "LDIR: Low-Dimensional Dense and Interpretable Text Embeddings with Relative Representations", "categories": ["cs.CL"], "comment": "ACL 2025 Findings", "summary": "Semantic text representation is a fundamental task in the field of natural\nlanguage processing. Existing text embedding (e.g., SimCSE and LLM2Vec) have\ndemonstrated excellent performance, but the values of each dimension are\ndifficult to trace and interpret. Bag-of-words, as classic sparse interpretable\nembeddings, suffers from poor performance. Recently, Benara et al. (2024)\npropose interpretable text embeddings using large language models, which forms\n\"0/1\" embeddings based on responses to a series of questions. These\ninterpretable text embeddings are typically high-dimensional (larger than\n10,000). In this work, we propose Low-dimensional (lower than 500) Dense and\nInterpretable text embeddings with Relative representations (LDIR). The\nnumerical values of its dimensions indicate semantic relatedness to different\nanchor texts through farthest point sampling, offering both semantic\nrepresentation as well as a certain level of traceability and interpretability.\nWe validate LDIR on multiple semantic textual similarity, retrieval, and\nclustering tasks. Extensive experimental results show that LDIR performs close\nto the black-box baseline models and outperforms the interpretable embeddings\nbaselines with much fewer dimensions. Code is available at\nhttps://github.com/szu-tera/LDIR."}
{"id": "2505.09724", "pdf": "https://arxiv.org/pdf/2505.09724", "abs": "https://arxiv.org/abs/2505.09724", "authors": ["Gino Carmona-Díaz", "William Jiménez-Leal", "María Alejandra Grisales", "Chandra Sripada", "Santiago Amaya", "Michael Inzlicht", "Juan Pablo Bermúdez"], "title": "An AI-Powered Research Assistant in the Lab: A Practical Guide for Text Analysis Through Iterative Collaboration with LLMs", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "31 pages, 1 figure", "summary": "Analyzing texts such as open-ended responses, headlines, or social media\nposts is a time- and labor-intensive process highly susceptible to bias. LLMs\nare promising tools for text analysis, using either a predefined (top-down) or\na data-driven (bottom-up) taxonomy, without sacrificing quality. Here we\npresent a step-by-step tutorial to efficiently develop, test, and apply\ntaxonomies for analyzing unstructured data through an iterative and\ncollaborative process between researchers and LLMs. Using personal goals\nprovided by participants as an example, we demonstrate how to write prompts to\nreview datasets and generate a taxonomy of life domains, evaluate and refine\nthe taxonomy through prompt and direct modifications, test the taxonomy and\nassess intercoder agreements, and apply the taxonomy to categorize an entire\ndataset with high intercoder reliability. We discuss the possibilities and\nlimitations of using LLMs for text analysis."}
{"id": "2505.10124", "pdf": "https://arxiv.org/pdf/2505.10124", "abs": "https://arxiv.org/abs/2505.10124", "authors": ["Ziad Kheil", "Lucas Robinet", "Laurent Risser", "Soleakhena Ken"], "title": "IMITATE: Image Registration with Context for unknown time frame recovery", "categories": ["cs.CV", "eess.IV"], "comment": "IEEE ISBI 2025", "summary": "In this paper, we formulate a novel image registration formalism dedicated to\nthe estimation of unknown condition-related images, based on two or more known\nimages and their associated conditions. We show how to practically model this\nformalism by using a new conditional U-Net architecture, which fully takes into\naccount the conditional information and does not need any fixed image. Our\nformalism is then applied to image moving tumors for radiotherapy treatment at\ndifferent breathing amplitude using 4D-CT (3D+t) scans in thoracoabdominal\nregions. This driving application is particularly complex as it requires to\nstitch a collection of sequential 2D slices into several 3D volumes at\ndifferent organ positions. Movement interpolation with standard methods then\ngenerates well known reconstruction artefacts in the assembled volumes due to\nirregular patient breathing, hysteresis and poor correlation of breathing\nsignal to internal motion. Results obtained on 4D-CT clinical data showcase\nartefact-free volumes achieved through real-time latencies. The code is\npublicly available at https://github.com/Kheil-Z/IMITATE ."}
{"id": "2505.09952", "pdf": "https://arxiv.org/pdf/2505.09952", "abs": "https://arxiv.org/abs/2505.09952", "authors": ["Tianyu Huai", "Jie Zhou", "Yuxuan Cai", "Qin Chen", "Wen Wu", "Xingjiao Wu", "Xipeng Qiu", "Liang He"], "title": "Task-Core Memory Management and Consolidation for Long-term Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to Neurips2025", "summary": "In this paper, we focus on a long-term continual learning (CL) task, where a\nmodel learns sequentially from a stream of vast tasks over time, acquiring new\nknowledge while retaining previously learned information in a manner akin to\nhuman learning. Unlike traditional CL settings, long-term CL involves handling\na significantly larger number of tasks, which exacerbates the issue of\ncatastrophic forgetting. Our work seeks to address two critical questions: 1)\nHow do existing CL methods perform in the context of long-term CL? and 2) How\ncan we mitigate the catastrophic forgetting that arises from prolonged\nsequential updates? To tackle these challenges, we propose a novel framework\ninspired by human memory mechanisms for long-term continual learning (Long-CL).\nSpecifically, we introduce a task-core memory management strategy to\nefficiently index crucial memories and adaptively update them as learning\nprogresses. Additionally, we develop a long-term memory consolidation mechanism\nthat selectively retains hard and discriminative samples, ensuring robust\nknowledge retention. To facilitate research in this area, we construct and\nrelease two multi-modal and textual benchmarks, MMLongCL-Bench and\nTextLongCL-Bench, providing a valuable resource for evaluating long-term CL\napproaches. Experimental results show that Long-CL outperforms the previous\nstate-of-the-art by 7.4\\% and 6.5\\% AP on the two benchmarks, respectively,\ndemonstrating the effectiveness of our approach."}
{"id": "2505.10356", "pdf": "https://arxiv.org/pdf/2505.10356", "abs": "https://arxiv.org/abs/2505.10356", "authors": ["Chunyu Ye", "Shaonan Wang"], "title": "Coherent Language Reconstruction from Brain Recordings with Flexible Multi-Modal Input Stimuli", "categories": ["cs.CL"], "comment": null, "summary": "Decoding thoughts from brain activity offers valuable insights into human\ncognition and enables promising applications in brain-computer interaction.\nWhile prior studies have explored language reconstruction from fMRI data, they\nare typically limited to single-modality inputs such as images or audio. In\ncontrast, human thought is inherently multimodal. To bridge this gap, we\npropose a unified and flexible framework for reconstructing coherent language\nfrom brain recordings elicited by diverse input modalities-visual, auditory,\nand textual. Our approach leverages visual-language models (VLMs), using\nmodality-specific experts to jointly interpret information across modalities.\nExperiments demonstrate that our method achieves performance comparable to\nstate-of-the-art systems while remaining adaptable and extensible. This work\nadvances toward more ecologically valid and generalizable mind decoding."}
{"id": "2505.09733", "pdf": "https://arxiv.org/pdf/2505.09733", "abs": "https://arxiv.org/abs/2505.09733", "authors": ["Alpaslan Gokcen", "Ali Boyaci"], "title": "Robust Federated Learning with Confidence-Weighted Filtering and GAN-Based Completion under Noisy and Incomplete Data", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated learning (FL) presents an effective solution for collaborative\nmodel training while maintaining data privacy across decentralized client\ndatasets. However, data quality issues such as noisy labels, missing classes,\nand imbalanced distributions significantly challenge its effectiveness. This\nstudy proposes a federated learning methodology that systematically addresses\ndata quality issues, including noise, class imbalance, and missing labels. The\nproposed approach systematically enhances data integrity through adaptive noise\ncleaning, collaborative conditional GAN-based synthetic data generation, and\nrobust federated model training. Experimental evaluations conducted on\nbenchmark datasets (MNIST and Fashion-MNIST) demonstrate significant\nimprovements in federated model performance, particularly macro-F1 Score, under\nvarying noise and class imbalance conditions. Additionally, the proposed\nframework carefully balances computational feasibility and substantial\nperformance gains, ensuring practicality for resource constrained edge devices\nwhile rigorously maintaining data privacy. Our results indicate that this\nmethod effectively mitigates common data quality challenges, providing a\nrobust, scalable, and privacy compliant solution suitable for diverse\nreal-world federated learning scenarios."}
{"id": "2505.10152", "pdf": "https://arxiv.org/pdf/2505.10152", "abs": "https://arxiv.org/abs/2505.10152", "authors": ["Yikang Wei"], "title": "Multi-Source Collaborative Style Augmentation and Domain-Invariant Learning for Federated Domain Generalization", "categories": ["cs.CV"], "comment": "IJCAI 2025", "summary": "Federated domain generalization aims to learn a generalizable model from\nmultiple decentralized source domains for deploying on the unseen target\ndomain. The style augmentation methods have achieved great progress on domain\ngeneralization. However, the existing style augmentation methods either explore\nthe data styles within isolated source domain or interpolate the style\ninformation across existing source domains under the data decentralization\nscenario, which leads to limited style space. To address this issue, we propose\na Multi-source Collaborative Style Augmentation and Domain-invariant learning\nmethod (MCSAD) for federated domain generalization. Specifically, we propose a\nmulti-source collaborative style augmentation module to generate data in the\nbroader style space. Furthermore, we conduct domain-invariant learning between\nthe original data and augmented data by cross-domain feature alignment within\nthe same class and classes relation ensemble distillation between different\nclasses to learn a domain-invariant model. By alternatively conducting\ncollaborative style augmentation and domain-invariant learning, the model can\ngeneralize well on unseen target domain. Extensive experiments on multiple\ndomain generalization datasets indicate that our method significantly\noutperforms the state-of-the-art federated domain generalization methods."}
{"id": "2505.09955", "pdf": "https://arxiv.org/pdf/2505.09955", "abs": "https://arxiv.org/abs/2505.09955", "authors": ["Jaeho Kim", "Seulki Lee"], "title": "TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 Accept", "summary": "Unsupervised domain adaptation (UDA) for time series data remains a critical\nchallenge in deep learning, with traditional pseudo-labeling strategies failing\nto capture temporal patterns and channel-wise shifts between domains, producing\nsub-optimal pseudo-labels. As such, we introduce TransPL, a novel approach that\naddresses these limitations by modeling the joint distribution $P(\\mathbf{X},\ny)$ of the source domain through code transition matrices, where the codes are\nderived from vector quantization (VQ) of time series patches. Our method\nconstructs class- and channel-wise code transition matrices from the source\ndomain and employs Bayes' rule for target domain adaptation, generating\npseudo-labels based on channel-wise weighted class-conditional likelihoods.\nTransPL offers three key advantages: explicit modeling of temporal transitions\nand channel-wise shifts between different domains, versatility towards\ndifferent UDA scenarios (e.g., weakly-supervised UDA), and explainable\npseudo-label generation. We validate TransPL's effectiveness through extensive\nanalysis on four time series UDA benchmarks and confirm that it consistently\noutperforms state-of-the-art pseudo-labeling methods by a strong margin (6.1%\naccuracy improvement, 4.9% F1 improvement), while providing interpretable\ninsights into the domain adaptation process through its learned code transition\nmatrices."}
{"id": "2505.10389", "pdf": "https://arxiv.org/pdf/2505.10389", "abs": "https://arxiv.org/abs/2505.10389", "authors": ["Benjamin White", "Anastasia Shimorina"], "title": "Multi-domain Multilingual Sentiment Analysis in Industry: Predicting Aspect-based Opinion Quadruples", "categories": ["cs.CL"], "comment": null, "summary": "This paper explores the design of an aspect-based sentiment analysis system\nusing large language models (LLMs) for real-world use. We focus on quadruple\nopinion extraction -- identifying aspect categories, sentiment polarity,\ntargets, and opinion expressions from text data across different domains and\nlanguages. Using internal datasets, we investigate whether a single fine-tuned\nmodel can effectively handle multiple domain-specific taxonomies\nsimultaneously. We demonstrate that a combined multi-domain model achieves\nperformance comparable to specialized single-domain models while reducing\noperational complexity. We also share lessons learned for handling\nnon-extractive predictions and evaluating various failure modes when developing\nLLM-based systems for structured prediction tasks."}
{"id": "2505.09738", "pdf": "https://arxiv.org/pdf/2505.09738", "abs": "https://arxiv.org/abs/2505.09738", "authors": ["Shaurya Sharthak", "Vinayak Pahalwan", "Adithya Kamath", "Adarsh Shirawalmath"], "title": "Achieving Tokenizer Flexibility in Language Models through Heuristic Adaptation and Supertoken Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Pretrained language models (LLMs) are often constrained by their fixed\ntokenization schemes, leading to inefficiencies and performance limitations,\nparticularly for multilingual or specialized applications. This tokenizer\nlock-in presents significant challenges. standard methods to overcome this\noften require prohibitive computational resources. Although tokenizer\nreplacement with heuristic initialization aims to reduce this burden, existing\nmethods often require exhaustive residual fine-tuning and still may not fully\npreserve semantic nuances or adequately address the underlying compression\ninefficiencies. Our framework introduces two innovations: first, Tokenadapt, a\nmodel-agnostic tokenizer transplantation method, and second, novel\npre-tokenization learning for multi-word Supertokens to enhance compression and\nreduce fragmentation. Tokenadapt initializes new unique token embeddings via a\nhybrid heuristic that combines two methods: a local estimate based on subword\ndecomposition using the old tokenizer, and a global estimate utilizing the\ntop-k semantically similar tokens from the original vocabulary. This\nmethodology aims to preserve semantics while significantly minimizing\nretraining requirements. Empirical investigations validate both contributions:\nthe transplantation heuristic successfully initializes unique tokens, markedly\noutperforming conventional baselines and sophisticated methods including\nTranstokenizer and ReTok, while our Supertokens achieve notable compression\ngains. Our zero-shot perplexity results demonstrate that the TokenAdapt hybrid\ninitialization consistently yields lower perplexity ratios compared to both\nReTok and TransTokenizer baselines across different base models and newly\ntrained target tokenizers. TokenAdapt typically reduced the overall perplexity\nratio significantly compared to ReTok, yielding at least a 2-fold improvement\nin these aggregate scores."}
{"id": "2505.10169", "pdf": "https://arxiv.org/pdf/2505.10169", "abs": "https://arxiv.org/abs/2505.10169", "authors": ["Matthias Kümmerer", "Harneet Khanuja", "Matthias Bethge"], "title": "Modeling Saliency Dataset Bias", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes."}
{"id": "2505.09959", "pdf": "https://arxiv.org/pdf/2505.09959", "abs": "https://arxiv.org/abs/2505.09959", "authors": ["Zengxia Guo", "Bohui An", "Zhongqi Lu"], "title": "Approximated Behavioral Metric-based State Projection for Federated Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated reinforcement learning (FRL) methods usually share the encrypted\nlocal state or policy information and help each client to learn from others\nwhile preserving everyone's privacy. In this work, we propose that sharing the\napproximated behavior metric-based state projection function is a promising way\nto enhance the performance of FRL and concurrently provides an effective\nprotection of sensitive information. We introduce FedRAG, a FRL framework to\nlearn a computationally practical projection function of states for each client\nand aggregating the parameters of projection functions at a central server. The\nFedRAG approach shares no sensitive task-specific information, yet provides\ninformation gain for each client. We conduct extensive experiments on the\nDeepMind Control Suite to demonstrate insightful results."}
{"id": "2505.10402", "pdf": "https://arxiv.org/pdf/2505.10402", "abs": "https://arxiv.org/abs/2505.10402", "authors": ["Yihong Dong", "Yuchen Liu", "Xue Jiang", "Zhi Jin", "Ge Li"], "title": "Rethinking Repetition Problems of LLMs in Code Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to ACL 2025 (main)", "summary": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code."}
{"id": "2505.09742", "pdf": "https://arxiv.org/pdf/2505.09742", "abs": "https://arxiv.org/abs/2505.09742", "authors": ["Yuan-Hang Zhang", "Massimiliano Di Ventra"], "title": "A Generative Neural Annealer for Black-Box Combinatorial Optimization", "categories": ["cs.LG", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.AI", "cs.NE"], "comment": "15 pages, 3 figures", "summary": "We propose a generative, end-to-end solver for black-box combinatorial\noptimization that emphasizes both sample efficiency and solution quality on NP\nproblems. Drawing inspiration from annealing-based algorithms, we treat the\nblack-box objective as an energy function and train a neural network to model\nthe associated Boltzmann distribution. By conditioning on temperature, the\nnetwork captures a continuum of distributions--from near-uniform at high\ntemperatures to sharply peaked around global optima at low\ntemperatures--thereby learning the structure of the energy landscape and\nfacilitating global optimization. When queries are expensive, the\ntemperature-dependent distributions naturally enable data augmentation and\nimprove sample efficiency. When queries are cheap but the problem remains hard,\nthe model learns implicit variable interactions, effectively \"opening\" the\nblack box. We validate our approach on challenging combinatorial tasks under\nboth limited and unlimited query budgets, showing competitive performance\nagainst state-of-the-art black-box optimizers."}
{"id": "2505.10205", "pdf": "https://arxiv.org/pdf/2505.10205", "abs": "https://arxiv.org/abs/2505.10205", "authors": ["Umair Haroon", "Ahmad AlMughrabi", "Thanasis Zoumpekas", "Ricardo Marques", "Petia Radeva"], "title": "VolE: A Point-cloud Framework for Food 3D Reconstruction and Volume Estimation", "categories": ["cs.CV"], "comment": null, "summary": "Accurate food volume estimation is crucial for medical nutrition management\nand health monitoring applications, but current food volume estimation methods\nare often limited by mononuclear data, leveraging single-purpose hardware such\nas 3D scanners, gathering sensor-oriented information such as depth\ninformation, or relying on camera calibration using a reference object. In this\npaper, we present VolE, a novel framework that leverages mobile device-driven\n3D reconstruction to estimate food volume. VolE captures images and camera\nlocations in free motion to generate precise 3D models, thanks to AR-capable\nmobile devices. To achieve real-world measurement, VolE is a reference- and\ndepth-free framework that leverages food video segmentation for food mask\ngeneration. We also introduce a new food dataset encompassing the challenging\nscenarios absent in the previous benchmarks. Our experiments demonstrate that\nVolE outperforms the existing volume estimation techniques across multiple\ndatasets by achieving 2.22 % MAPE, highlighting its superior performance in\nfood volume estimation."}
{"id": "2505.09969", "pdf": "https://arxiv.org/pdf/2505.09969", "abs": "https://arxiv.org/abs/2505.09969", "authors": ["Ali Azimi Lamir", "Shiva Razzagzadeh", "Zeynab Rezaei"], "title": "A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study presents a machine learning-based framework for heart disease\nprediction using the heart-disease dataset, comprising 303 samples with 14\nfeatures. The methodology involves data preprocessing, model training, and\nevaluation using three classifiers: Logistic Regression, K-Nearest Neighbors\n(KNN), and Random Forest. Hyperparameter tuning with GridSearchCV and\nRandomizedSearchCV was employed to enhance model performance. The Random Forest\nclassifier outperformed other models, achieving an accuracy of 91% and an\nF1-score of 0.89. Evaluation metrics, including precision, recall, and\nconfusion matrix, revealed balanced performance across classes. The proposed\nmodel demonstrates strong potential for aiding clinical decision-making by\neffectively predicting heart disease. Limitations such as dataset size and\ngeneralizability underscore the need for future studies using larger and more\ndiverse datasets. This work highlights the utility of machine learning in\nhealthcare, offering insights for further advancements in predictive\ndiagnostics."}
{"id": "2505.10409", "pdf": "https://arxiv.org/pdf/2505.10409", "abs": "https://arxiv.org/abs/2505.10409", "authors": ["Yue Guo", "Jae Ho Sohn", "Gondy Leroy", "Trevor Cohen"], "title": "Are LLM-generated plain language summaries truly understandable? A large-scale crowdsourced evaluation", "categories": ["cs.CL"], "comment": null, "summary": "Plain language summaries (PLSs) are essential for facilitating effective\ncommunication between clinicians and patients by making complex medical\ninformation easier for laypeople to understand and act upon. Large language\nmodels (LLMs) have recently shown promise in automating PLS generation, but\ntheir effectiveness in supporting health information comprehension remains\nunclear. Prior evaluations have generally relied on automated scores that do\nnot measure understandability directly, or subjective Likert-scale ratings from\nconvenience samples with limited generalizability. To address these gaps, we\nconducted a large-scale crowdsourced evaluation of LLM-generated PLSs using\nAmazon Mechanical Turk with 150 participants. We assessed PLS quality through\nsubjective Likert-scale ratings focusing on simplicity, informativeness,\ncoherence, and faithfulness; and objective multiple-choice comprehension and\nrecall measures of reader understanding. Additionally, we examined the\nalignment between 10 automated evaluation metrics and human judgments. Our\nfindings indicate that while LLMs can generate PLSs that appear\nindistinguishable from human-written ones in subjective evaluations,\nhuman-written PLSs lead to significantly better comprehension. Furthermore,\nautomated evaluation metrics fail to reflect human judgment, calling into\nquestion their suitability for evaluating PLSs. This is the first study to\nsystematically evaluate LLM-generated PLSs based on both reader preferences and\ncomprehension outcomes. Our findings highlight the need for evaluation\nframeworks that move beyond surface-level quality and for generation methods\nthat explicitly optimize for layperson comprehension."}
{"id": "2505.09794", "pdf": "https://arxiv.org/pdf/2505.09794", "abs": "https://arxiv.org/abs/2505.09794", "authors": ["J. Moreno-Casanova", "J. M. Auñón", "A. Mártinez-Pérez", "M. E. Pérez-Martínez", "M. E. Gas-López"], "title": "Automated Detection of Clinical Entities in Lung and Breast Cancer Reports Using NLP Techniques", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Research projects, including those focused on cancer, rely on the manual\nextraction of information from clinical reports. This process is time-consuming\nand prone to errors, limiting the efficiency of data-driven approaches in\nhealthcare. To address these challenges, Natural Language Processing (NLP)\noffers an alternative for automating the extraction of relevant data from\nelectronic health records (EHRs). In this study, we focus on lung and breast\ncancer due to their high incidence and the significant impact they have on\npublic health. Early detection and effective data management in both types of\ncancer are crucial for improving patient outcomes. To enhance the accuracy and\nefficiency of data extraction, we utilized GMV's NLP tool uQuery, which excels\nat identifying relevant entities in clinical texts and converting them into\nstandardized formats such as SNOMED and OMOP. uQuery not only detects and\nclassifies entities but also associates them with contextual information,\nincluding negated entities, temporal aspects, and patient-related details. In\nthis work, we explore the use of NLP techniques, specifically Named Entity\nRecognition (NER), to automatically identify and extract key clinical\ninformation from EHRs related to these two cancers. A dataset from Health\nResearch Institute Hospital La Fe (IIS La Fe), comprising 200 annotated breast\ncancer and 400 lung cancer reports, was used, with eight clinical entities\nmanually labeled using the Doccano platform. To perform NER, we fine-tuned the\nbsc-bio-ehr-en3 model, a RoBERTa-based biomedical linguistic model pre-trained\nin Spanish. Fine-tuning was performed using the Transformers architecture,\nenabling accurate recognition of clinical entities in these cancer types. Our\nresults demonstrate strong overall performance, particularly in identifying\nentities like MET and PAT, although challenges remain with less frequent\nentities like EVOL."}
{"id": "2505.10223", "pdf": "https://arxiv.org/pdf/2505.10223", "abs": "https://arxiv.org/abs/2505.10223", "authors": ["Puru Vaish", "Felix Meister", "Tobias Heimann", "Christoph Brune", "Jelmer M. Wolterink"], "title": "Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at MIDL 2025", "summary": "Medical image segmentation models are often trained on curated datasets,\nleading to performance degradation when deployed in real-world clinical\nsettings due to mismatches between training and test distributions. While data\naugmentation techniques are widely used to address these challenges,\ntraditional visually consistent augmentation strategies lack the robustness\nneeded for diverse real-world scenarios. In this work, we systematically\nevaluate alternative augmentation strategies, focusing on MixUp and Auxiliary\nFourier Augmentation. These methods mitigate the effects of multiple variations\nwithout explicitly targeting specific sources of distribution shifts. We\ndemonstrate how these techniques significantly improve out-of-distribution\ngeneralization and robustness to imaging variations across a wide range of\ntransformations in cardiac cine MRI and prostate MRI segmentation. We\nquantitatively find that these augmentation methods enhance learned feature\nrepresentations by promoting separability and compactness. Additionally, we\nhighlight how their integration into nnU-Net training pipelines provides an\neasy-to-implement, effective solution for enhancing the reliability of medical\nsegmentation models in real-world applications."}
{"id": "2505.09983", "pdf": "https://arxiv.org/pdf/2505.09983", "abs": "https://arxiv.org/abs/2505.09983", "authors": ["Changxun Zhu", "Qilong Wu", "Lingjuan Lyu", "Shibei Xue"], "title": "Sybil-based Virtual Data Poisoning Attacks in Federated Learning", "categories": ["cs.CR", "cs.LG"], "comment": "7 pages, 6 figures, accepted by IEEE Codit 2025", "summary": "Federated learning is vulnerable to poisoning attacks by malicious\nadversaries. Existing methods often involve high costs to achieve effective\nattacks. To address this challenge, we propose a sybil-based virtual data\npoisoning attack, where a malicious client generates sybil nodes to amplify the\npoisoning model's impact. To reduce neural network computational complexity, we\ndevelop a virtual data generation method based on gradient matching. We also\ndesign three schemes for target model acquisition, applicable to online local,\nonline global, and offline scenarios. In simulation, our method outperforms\nother attack algorithms since our method can obtain a global target model under\nnon-independent uniformly distributed data."}
{"id": "2505.10413", "pdf": "https://arxiv.org/pdf/2505.10413", "abs": "https://arxiv.org/abs/2505.10413", "authors": ["Jiajie Jin", "Xiaoxi Li", "Guanting Dong", "Yuyao Zhang", "Yutao Zhu", "Yongkang Wu", "Zhonghua Li", "Qi Ye", "Zhicheng Dou"], "title": "Hierarchical Document Refinement for Long-context Retrieval-augmented Generation", "categories": ["cs.CL"], "comment": null, "summary": "Real-world RAG applications often encounter long-context input scenarios,\nwhere redundant information and noise results in higher inference costs and\nreduced performance. To address these challenges, we propose LongRefiner, an\nefficient plug-and-play refiner that leverages the inherent structural\ncharacteristics of long documents. LongRefiner employs dual-level query\nanalysis, hierarchical document structuring, and adaptive refinement through\nmulti-task learning on a single foundation model. Experiments on seven QA\ndatasets demonstrate that LongRefiner achieves competitive performance in\nvarious scenarios while using 10x fewer computational costs and latency\ncompared to the best baseline. Further analysis validates that LongRefiner is\nscalable, efficient, and effective, providing practical insights for real-world\nlong-text RAG applications. Our code is available at\nhttps://github.com/ignorejjj/LongRefiner."}
{"id": "2505.09807", "pdf": "https://arxiv.org/pdf/2505.09807", "abs": "https://arxiv.org/abs/2505.09807", "authors": ["Timour Ichmoukhamedov", "David Martens"], "title": "Exploring the generalization of LLM truth directions on conversational formats", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Several recent works argue that LLMs have a universal truth direction where\ntrue and false statements are linearly separable in the activation space of the\nmodel. It has been demonstrated that linear probes trained on a single hidden\nstate of the model already generalize across a range of topics and might even\nbe used for lie detection in LLM conversations. In this work we explore how\nthis truth direction generalizes between various conversational formats. We\nfind good generalization between short conversations that end on a lie, but\npoor generalization to longer formats where the lie appears earlier in the\ninput prompt. We propose a solution that significantly improves this type of\ngeneralization by adding a fixed key phrase at the end of each conversation.\nOur results highlight the challenges towards reliable LLM lie detectors that\ngeneralize to new settings."}
{"id": "2505.10231", "pdf": "https://arxiv.org/pdf/2505.10231", "abs": "https://arxiv.org/abs/2505.10231", "authors": ["Haozhe Luo", "Ziyu Zhou", "Zixin Shu", "Aurélie Pahud de Mortanges", "Robert Berke", "Mauricio Reyes"], "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner."}
{"id": "2505.10003", "pdf": "https://arxiv.org/pdf/2505.10003", "abs": "https://arxiv.org/abs/2505.10003", "authors": ["Tianyu Jiao", "Zhuoran Xiao", "Yihang Huang", "Chenhui Ye", "Yijia Feng", "Liyu Cai", "Jiang Chang", "Fangkun Liu", "Yin Xu", "Dazhi He", "Yunfeng Guan", "Wenjun Zhang"], "title": "AI2MMUM: AI-AI Oriented Multi-Modal Universal Model Leveraging Telecom Domain Large Model", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Designing a 6G-oriented universal model capable of processing multi-modal\ndata and executing diverse air interface tasks has emerged as a common goal in\nfuture wireless systems. Building on our prior work in communication\nmulti-modal alignment and telecom large language model (LLM), we propose a\nscalable, task-aware artificial intelligence-air interface multi-modal\nuniversal model (AI2MMUM), which flexibility and effectively perform various\nphysical layer tasks according to subtle task instructions. The LLM backbone\nprovides robust contextual comprehension and generalization capabilities, while\na fine-tuning approach is adopted to incorporate domain-specific knowledge. To\nenhance task adaptability, task instructions consist of fixed task keywords and\nlearnable, implicit prefix prompts. Frozen radio modality encoders extract\nuniversal representations and adapter layers subsequently bridge radio and\nlanguage modalities. Moreover, lightweight task-specific heads are designed to\ndirectly output task objectives. Comprehensive evaluations demonstrate that\nAI2MMUM achieves SOTA performance across five representative physical\nenvironment/wireless channel-based downstream tasks using the WAIR-D and\nDeepMIMO datasets."}
{"id": "2505.10446", "pdf": "https://arxiv.org/pdf/2505.10446", "abs": "https://arxiv.org/abs/2505.10446", "authors": ["Zemin Huang", "Zhiyang Chen", "Zijun Wang", "Tiancheng Li", "Guo-Jun Qi"], "title": "Reinforcing the Diffusion Chain of Lateral Thought with Diffusion Language Models", "categories": ["cs.CL"], "comment": null, "summary": "We introduce the \\emph{Diffusion Chain of Lateral Thought (DCoLT)}, a\nreasoning framework for diffusion language models. DCoLT treats each\nintermediate step in the reverse diffusion process as a latent \"thinking\"\naction and optimizes the entire reasoning trajectory to maximize the reward on\nthe correctness of the final answer with outcome-based Reinforcement Learning\n(RL). Unlike traditional Chain-of-Thought (CoT) methods that follow a causal,\nlinear thinking process, DCoLT allows bidirectional, non-linear reasoning with\nno strict rule on grammatical correctness amid its intermediate steps of\nthought. We implement DCoLT on two representative Diffusion Language Models\n(DLMs). First, we choose SEDD as a representative continuous-time discrete\ndiffusion model, where its concrete score derives a probabilistic policy to\nmaximize the RL reward over the entire sequence of intermediate diffusion\nsteps. We further consider the discrete-time masked diffusion language model --\nLLaDA, and find that the order to predict and unmask tokens plays an essential\nrole to optimize its RL action resulting from the ranking-based Unmasking\nPolicy Module (UPM) defined by the Plackett-Luce model. Experiments on both\nmath and code generation tasks show that using only public data and 16 H800\nGPUs, DCoLT-reinforced DLMs outperform other DLMs trained by SFT or RL or even\nboth. Notably, DCoLT-reinforced LLaDA boosts its reasoning accuracy by +9.8%,\n+5.7%, +11.4%, +19.5% on GSM8K, MATH, MBPP, and HumanEval."}
{"id": "2505.09847", "pdf": "https://arxiv.org/pdf/2505.09847", "abs": "https://arxiv.org/abs/2505.09847", "authors": ["Liyang Zhao", "Olurotimi Seton", "Himadeep Reddy Reddivari", "Suvendu Jena", "Shadow Zhao", "Rachit Kumar", "Changshuai Wei"], "title": "Causal Predictive Optimization and Generation for Business AI", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ML"], "comment": null, "summary": "The sales process involves sales functions converting leads or opportunities\nto customers and selling more products to existing customers. The optimization\nof the sales process thus is key to success of any B2B business. In this work,\nwe introduce a principled approach to sales optimization and business AI,\nnamely the Causal Predictive Optimization and Generation, which includes three\nlayers: 1) prediction layer with causal ML 2) optimization layer with\nconstraint optimization and contextual bandit 3) serving layer with Generative\nAI and feedback-loop for system enhancement. We detail the implementation and\ndeployment of the system in LinkedIn, showcasing significant wins over legacy\nsystems and sharing learning and insight broadly applicable to this field."}
{"id": "2505.10238", "pdf": "https://arxiv.org/pdf/2505.10238", "abs": "https://arxiv.org/abs/2505.10238", "authors": ["Yanbo Ding"], "title": "MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation", "categories": ["cs.CV"], "comment": null, "summary": "Human image animation has gained increasing attention and developed rapidly\ndue to its broad applications in digital humans. However, existing methods rely\nlargely on 2D-rendered pose images for motion guidance, which limits\ngeneralization and discards essential 3D information for open-world animation.\nTo tackle this problem, we propose MTVCrafter (Motion Tokenization Video\nCrafter), the first framework that directly models raw 3D motion sequences\n(i.e., 4D motion) for human image animation. Specifically, we introduce 4DMoT\n(4D motion tokenizer) to quantize 3D motion sequences into 4D motion tokens.\nCompared to 2D-rendered pose images, 4D motion tokens offer more robust\nspatio-temporal cues and avoid strict pixel-level alignment between pose image\nand character, enabling more flexible and disentangled control. Then, we\nintroduce MV-DiT (Motion-aware Video DiT). By designing unique motion attention\nwith 4D positional encodings, MV-DiT can effectively leverage motion tokens as\n4D compact yet expressive context for human image animation in the complex 3D\nworld. Hence, it marks a significant step forward in this field and opens a new\ndirection for pose-guided human video generation. Experiments show that our\nMTVCrafter achieves state-of-the-art results with an FID-VID of 6.98,\nsurpassing the second-best by 65%. Powered by robust motion tokens, MTVCrafter\nalso generalizes well to diverse open-world characters (single/multiple,\nfull/half-body) across various styles and scenarios. Our video demos and code\nare provided in the supplementary material and at this anonymous GitHub link:\nhttps://anonymous.4open.science/r/MTVCrafter-1B13."}
{"id": "2505.10007", "pdf": "https://arxiv.org/pdf/2505.10007", "abs": "https://arxiv.org/abs/2505.10007", "authors": ["Zijun Chen", "Shengbo Wang", "Nian Si"], "title": "Sample Complexity of Distributionally Robust Average-Reward Reinforcement Learning", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": null, "summary": "Motivated by practical applications where stable long-term performance is\ncritical-such as robotics, operations research, and healthcare-we study the\nproblem of distributionally robust (DR) average-reward reinforcement learning.\nWe propose two algorithms that achieve near-optimal sample complexity. The\nfirst reduces the problem to a DR discounted Markov decision process (MDP),\nwhile the second, Anchored DR Average-Reward MDP, introduces an anchoring state\nto stabilize the controlled transition kernels within the uncertainty set.\nAssuming the nominal MDP is uniformly ergodic, we prove that both algorithms\nattain a sample complexity of $\\widetilde{O}\\left(|\\mathbf{S}||\\mathbf{A}|\nt_{\\mathrm{mix}}^2\\varepsilon^{-2}\\right)$ for estimating the optimal policy as\nwell as the robust average reward under KL and $f_k$-divergence-based\nuncertainty sets, provided the uncertainty radius is sufficiently small. Here,\n$\\varepsilon$ is the target accuracy, $|\\mathbf{S}|$ and $|\\mathbf{A}|$ denote\nthe sizes of the state and action spaces, and $t_{\\mathrm{mix}}$ is the mixing\ntime of the nominal MDP. This represents the first finite-sample convergence\nguarantee for DR average-reward reinforcement learning. We further validate the\nconvergence rates of our algorithms through numerical experiments."}
{"id": "2505.10493", "pdf": "https://arxiv.org/pdf/2505.10493", "abs": "https://arxiv.org/abs/2505.10493", "authors": ["Shaohan Wang", "Licheng Zhang", "Zheren Fu", "Zhendong Mao"], "title": "CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning", "categories": ["cs.CL"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) is an effective method to enhance the\ncapabilities of large language models (LLMs). Existing methods focus on\noptimizing the retriever or generator in the RAG system by directly utilizing\nthe top-k retrieved documents. However, the documents effectiveness are various\nsignificantly across user queries, i.e. some documents provide valuable\nknowledge while others totally lack critical information. It hinders the\nretriever and generator's adaptation during training. Inspired by human\ncognitive learning, curriculum learning trains models using samples progressing\nfrom easy to difficult, thus enhancing their generalization ability, and we\nintegrate this effective paradigm to the training of the RAG system. In this\npaper, we propose a multi-stage Curriculum Learning based RAG system training\nframework, named CL-RAG. We first construct training data with multiple\ndifficulty levels for the retriever and generator separately through sample\nevolution. Then, we train the model in stages based on the curriculum learning\napproach, thereby optimizing the overall performance and generalization of the\nRAG system more effectively. Our CL-RAG framework demonstrates consistent\neffectiveness across four open-domain QA datasets, achieving performance gains\nof 2% to 4% over multiple advanced methods."}
{"id": "2505.09852", "pdf": "https://arxiv.org/pdf/2505.09852", "abs": "https://arxiv.org/abs/2505.09852", "authors": ["Apollinaire Poli Nemkova", "Sarath Chandra Lingareddy", "Sagnik Ray Choudhury", "Mark V. Albert"], "title": "Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance across natural\nlanguage tasks, but their ability to forecast violent conflict remains\nunderexplored. We investigate whether LLMs possess meaningful parametric\nknowledge-encoded in their pretrained weights-to predict conflict escalation\nand fatalities without external data. This is critical for early warning\nsystems, humanitarian planning, and policy-making. We compare this parametric\nknowledge with non-parametric capabilities, where LLMs access structured and\nunstructured context from conflict datasets (e.g., ACLED, GDELT) and recent\nnews reports via Retrieval-Augmented Generation (RAG). Incorporating external\ninformation could enhance model performance by providing up-to-date context\notherwise missing from pretrained weights. Our two-part evaluation framework\nspans 2020-2024 across conflict-prone regions in the Horn of Africa and the\nMiddle East. In the parametric setting, LLMs predict conflict trends and\nfatalities relying only on pretrained knowledge. In the non-parametric setting,\nmodels receive summaries of recent conflict events, indicators, and\ngeopolitical developments. We compare predicted conflict trend labels (e.g.,\nEscalate, Stable Conflict, De-escalate, Peace) and fatalities against\nhistorical data. Our findings highlight the strengths and limitations of LLMs\nfor conflict forecasting and the benefits of augmenting them with structured\nexternal knowledge."}
{"id": "2505.10250", "pdf": "https://arxiv.org/pdf/2505.10250", "abs": "https://arxiv.org/abs/2505.10250", "authors": ["Wenhao Shen", "Wanqi Yin", "Xiaofeng Yang", "Cheng Chen", "Chaoyue Song", "Zhongang Cai", "Lei Yang", "Hao Wang", "Guosheng Lin"], "title": "ADHMR: Aligning Diffusion-based Human Mesh Recovery via Direct Preference Optimization", "categories": ["cs.CV"], "comment": "Accepted by ICML 2025. Code: https://github.com/shenwenhao01/ADHMR", "summary": "Human mesh recovery (HMR) from a single image is inherently ill-posed due to\ndepth ambiguity and occlusions. Probabilistic methods have tried to solve this\nby generating numerous plausible 3D human mesh predictions, but they often\nexhibit misalignment with 2D image observations and weak robustness to\nin-the-wild images. To address these issues, we propose ADHMR, a framework that\nAligns a Diffusion-based HMR model in a preference optimization manner. First,\nwe train a human mesh prediction assessment model, HMR-Scorer, capable of\nevaluating predictions even for in-the-wild images without 3D annotations. We\nthen use HMR-Scorer to create a preference dataset, where each input image has\na pair of winner and loser mesh predictions. This dataset is used to finetune\nthe base model using direct preference optimization. Moreover, HMR-Scorer also\nhelps improve existing HMR models by data cleaning, even with fewer training\nsamples. Extensive experiments show that ADHMR outperforms current\nstate-of-the-art methods. Code is available at:\nhttps://github.com/shenwenhao01/ADHMR."}
{"id": "2505.10010", "pdf": "https://arxiv.org/pdf/2505.10010", "abs": "https://arxiv.org/abs/2505.10010", "authors": ["Jing-Cheng Pang", "Kaiyuan Li", "Yidi Wang", "Si-Hang Yang", "Shengyi Jiang", "Yang Yu"], "title": "ImagineBench: Evaluating Reinforcement Learning with Large Language Model Rollouts", "categories": ["cs.LG"], "comment": null, "summary": "A central challenge in reinforcement learning (RL) is its dependence on\nextensive real-world interaction data to learn task-specific policies. While\nrecent work demonstrates that large language models (LLMs) can mitigate this\nlimitation by generating synthetic experience (noted as imaginary rollouts) for\nmastering novel tasks, progress in this emerging field is hindered due to the\nlack of a standard benchmark. To bridge this gap, we introduce ImagineBench,\nthe first comprehensive benchmark for evaluating offline RL algorithms that\nleverage both real rollouts and LLM-imaginary rollouts. The key features of\nImagineBench include: (1) datasets comprising environment-collected and\nLLM-imaginary rollouts; (2) diverse domains of environments covering\nlocomotion, robotic manipulation, and navigation tasks; and (3) natural\nlanguage task instructions with varying complexity levels to facilitate\nlanguage-conditioned policy learning. Through systematic evaluation of\nstate-of-the-art offline RL algorithms, we observe that simply applying\nexisting offline RL algorithms leads to suboptimal performance on unseen tasks,\nachieving 35.44% success rate in hard tasks in contrast to 64.37% of method\ntraining on real rollouts for hard tasks. This result highlights the need for\nalgorithm advancements to better leverage LLM-imaginary rollouts. Additionally,\nwe identify key opportunities for future research: including better utilization\nof imaginary rollouts, fast online adaptation and continual learning, and\nextension to multi-modal tasks. Our code is publicly available at\nhttps://github.com/LAMDA-RL/ImagineBench."}
{"id": "2505.10494", "pdf": "https://arxiv.org/pdf/2505.10494", "abs": "https://arxiv.org/abs/2505.10494", "authors": ["Yutao Mou", "Xiao Deng", "Yuxiao Luo", "Shikun Zhang", "Wei Ye"], "title": "Can You Really Trust Code Copilots? Evaluating Large Language Models from a Code Security Perspective", "categories": ["cs.CL"], "comment": "Accepted by ACL2025 Main Conference", "summary": "Code security and usability are both essential for various coding assistant\napplications driven by large language models (LLMs). Current code security\nbenchmarks focus solely on single evaluation task and paradigm, such as code\ncompletion and generation, lacking comprehensive assessment across dimensions\nlike secure code generation, vulnerability repair and discrimination. In this\npaper, we first propose CoV-Eval, a multi-task benchmark covering various tasks\nsuch as code completion, vulnerability repair, vulnerability detection and\nclassification, for comprehensive evaluation of LLM code security. Besides, we\ndeveloped VC-Judge, an improved judgment model that aligns closely with human\nexperts and can review LLM-generated programs for vulnerabilities in a more\nefficient and reliable way. We conduct a comprehensive evaluation of 20\nproprietary and open-source LLMs. Overall, while most LLMs identify vulnerable\ncodes well, they still tend to generate insecure codes and struggle with\nrecognizing specific vulnerability types and performing repairs. Extensive\nexperiments and qualitative analyses reveal key challenges and optimization\ndirections, offering insights for future research in LLM code security."}
{"id": "2505.09855", "pdf": "https://arxiv.org/pdf/2505.09855", "abs": "https://arxiv.org/abs/2505.09855", "authors": ["Alexander Y. Ku", "Thomas L. Griffiths", "Stephanie C. Y. Chan"], "title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies."}
{"id": "2505.10257", "pdf": "https://arxiv.org/pdf/2505.10257", "abs": "https://arxiv.org/abs/2505.10257", "authors": ["Hao Lu", "Jiaqi Tang", "Jiyao Wang", "Yunfan LU", "Xu Cao", "Qingyong Hu", "Yin Wang", "Yuting Zhang", "Tianxin Xie", "Yunpeng Zhang", "Yong Chen", "Jiayu. Gao", "Bin Huang", "Dengbo He", "Shuiguang Deng", "Hao Chen", "Ying-Cong Chen"], "title": "Sage Deer: A Super-Aligned Driving Generalist Is Your Copilot", "categories": ["cs.CV"], "comment": null, "summary": "The intelligent driving cockpit, an important part of intelligent driving,\nneeds to match different users' comfort, interaction, and safety needs. This\npaper aims to build a Super-Aligned and GEneralist DRiving agent, SAGE DeeR.\nSage Deer achieves three highlights: (1) Super alignment: It achieves different\nreactions according to different people's preferences and biases. (2)\nGeneralist: It can understand the multi-view and multi-mode inputs to reason\nthe user's physiological indicators, facial emotions, hand movements, body\nmovements, driving scenarios, and behavioral decisions. (3) Self-Eliciting: It\ncan elicit implicit thought chains in the language space to further increase\ngeneralist and super-aligned abilities. Besides, we collected multiple data\nsets and built a large-scale benchmark. This benchmark measures the deer's\nperceptual decision-making ability and the super alignment's accuracy."}
{"id": "2505.10037", "pdf": "https://arxiv.org/pdf/2505.10037", "abs": "https://arxiv.org/abs/2505.10037", "authors": ["Takafumi Ito", "Lysenko Artem", "Tatsuhiko Tsunoda"], "title": "Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction", "categories": ["cs.LG", "cs.AI", "cs.ET", "quant-ph"], "comment": "10 pages, 3 figures", "summary": "Quantum-classical Hybrid Machine Learning (QHML) models are recognized for\ntheir robust performance and high generalization ability even for relatively\nsmall datasets. These qualities offer unique advantages for anti-cancer drug\nresponse prediction, where the number of available samples is typically small.\nHowever, such hybrid models appear to be very sensitive to the data encoding\nused at the interface of a neural network and a quantum circuit, with\nsuboptimal choices leading to stability issues. To address this problem, we\npropose a novel strategy that uses a normalization function based on a\nmoderated gradient version of the $\\tanh$. This method transforms the outputs\nof the neural networks without concentrating them at the extreme value ranges.\nOur idea was evaluated on a dataset of gene expression and drug response\nmeasurements for various cancer cell lines, where we compared the prediction\nperformance of a classical deep learning model and several QHML models. These\nresults confirmed that QHML performed better than the classical models when\ndata was optimally normalized. This study opens up new possibilities for\nbiomedical data analysis using quantum computers."}
{"id": "2505.10507", "pdf": "https://arxiv.org/pdf/2505.10507", "abs": "https://arxiv.org/abs/2505.10507", "authors": ["Benedikt Ebing", "Goran Glavaš"], "title": "The Devil Is in the Word Alignment Details: On Translation-Based Cross-Lingual Transfer for Token Classification Tasks", "categories": ["cs.CL"], "comment": null, "summary": "Translation-based strategies for cross-lingual transfer XLT such as\ntranslate-train -- training on noisy target language data translated from the\nsource language -- and translate-test -- evaluating on noisy source language\ndata translated from the target language -- are competitive XLT baselines. In\nXLT for token classification tasks, however, these strategies include label\nprojection, the challenging step of mapping the labels from each token in the\noriginal sentence to its counterpart(s) in the translation. Although word\naligners (WAs) are commonly used for label projection, the low-level design\ndecisions for applying them to translation-based XLT have not been\nsystematically investigated. Moreover, recent marker-based methods, which\nproject labeled spans by inserting tags around them before (or after)\ntranslation, claim to outperform WAs in label projection for XLT. In this work,\nwe revisit WAs for label projection, systematically investigating the effects\nof low-level design decisions on token-level XLT: (i) the algorithm for\nprojecting labels between (multi-)token spans, (ii) filtering strategies to\nreduce the number of noisily mapped labels, and (iii) the pre-tokenization of\nthe translated sentences. We find that all of these substantially impact\ntranslation-based XLT performance and show that, with optimized choices, XLT\nwith WA offers performance at least comparable to that of marker-based methods.\nWe then introduce a new projection strategy that ensembles translate-train and\ntranslate-test predictions and demonstrate that it substantially outperforms\nthe marker-based projection. Crucially, we show that our proposed ensembling\nalso reduces sensitivity to low-level WA design choices, resulting in more\nrobust XLT for token classification tasks."}
{"id": "2505.09861", "pdf": "https://arxiv.org/pdf/2505.09861", "abs": "https://arxiv.org/abs/2505.09861", "authors": ["John Bencina", "Erkut Aykutlug", "Yue Chen", "Zerui Zhang", "Stephanie Sorenson", "Shao Tang", "Changshuai Wei"], "title": "LiDDA: Data Driven Attribution at LinkedIn", "categories": ["cs.LG", "cs.AI", "cs.IR", "stat.ME"], "comment": null, "summary": "Data Driven Attribution, which assigns conversion credits to marketing\ninteractions based on causal patterns learned from data, is the foundation of\nmodern marketing intelligence and vital to any marketing businesses and\nadvertising platform. In this paper, we introduce a unified transformer-based\nattribution approach that can handle member-level data, aggregate-level data,\nand integration of external macro factors. We detail the large scale\nimplementation of the approach at LinkedIn, showcasing significant impact. We\nalso share learning and insights that are broadly applicable to the marketing\nand ad tech fields."}
{"id": "2505.10258", "pdf": "https://arxiv.org/pdf/2505.10258", "abs": "https://arxiv.org/abs/2505.10258", "authors": ["Michael Hubbertz", "Pascal Colling", "Qi Han", "Tobias Meisen"], "title": "Inferring Driving Maps by Deep Learning-based Trail Map Extraction", "categories": ["cs.CV", "cs.RO"], "comment": "This paper was accepted at the CVPR WAD 2025 Workshop", "summary": "High-definition (HD) maps offer extensive and accurate environmental\ninformation about the driving scene, making them a crucial and essential\nelement for planning within autonomous driving systems. To avoid extensive\nefforts from manual labeling, methods for automating the map creation have\nemerged. Recent trends have moved from offline mapping to online mapping,\nensuring availability and actuality of the utilized maps. While the performance\nhas increased in recent years, online mapping still faces challenges regarding\ntemporal consistency, sensor occlusion, runtime, and generalization. We propose\na novel offline mapping approach that integrates trails - informal routes used\nby drivers - into the map creation process. Our method aggregates trail data\nfrom the ego vehicle and other traffic participants to construct a\ncomprehensive global map using transformer-based deep learning models. Unlike\ntraditional offline mapping, our approach enables continuous updates while\nremaining sensor-agnostic, facilitating efficient data transfer. Our method\ndemonstrates superior performance compared to state-of-the-art online mapping\napproaches, achieving improved generalization to previously unseen environments\nand sensor configurations. We validate our approach on two benchmark datasets,\nhighlighting its robustness and applicability in autonomous driving systems."}
{"id": "2505.10039", "pdf": "https://arxiv.org/pdf/2505.10039", "abs": "https://arxiv.org/abs/2505.10039", "authors": ["Hang Chen", "Jiaying Zhu", "Xinyu Yang", "Wenya Wang"], "title": "Rethinking Circuit Completeness in Language Models: AND, OR, and ADDER Gates", "categories": ["cs.LG"], "comment": "10 pages", "summary": "Circuit discovery has gradually become one of the prominent methods for\nmechanistic interpretability, and research on circuit completeness has also\ngarnered increasing attention. Methods of circuit discovery that do not\nguarantee completeness not only result in circuits that are not fixed across\ndifferent runs but also cause key mechanisms to be omitted. The nature of\nincompleteness arises from the presence of OR gates within the circuit, which\nare often only partially detected in standard circuit discovery methods. To\nthis end, we systematically introduce three types of logic gates: AND, OR, and\nADDER gates, and decompose the circuit into combinations of these logical\ngates. Through the concept of these gates, we derive the minimum requirements\nnecessary to achieve faithfulness and completeness. Furthermore, we propose a\nframework that combines noising-based and denoising-based interventions, which\ncan be easily integrated into existing circuit discovery methods without\nsignificantly increasing computational complexity. This framework is capable of\nfully identifying the logic gates and distinguishing them within the circuit.\nIn addition to the extensive experimental validation of the framework's ability\nto restore the faithfulness, completeness, and sparsity of circuits, using this\nframework, we uncover fundamental properties of the three logic gates, such as\ntheir proportions and contributions to the output, and explore how they behave\namong the functionalities of language models."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.09901", "pdf": "https://arxiv.org/pdf/2505.09901", "abs": "https://arxiv.org/abs/2505.09901", "authors": ["Ziyuan Zhang", "Darcy Wang", "Ningyuan Chen", "Rodrigo Mansur", "Vahid Sarhangian"], "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements."}
{"id": "2505.10267", "pdf": "https://arxiv.org/pdf/2505.10267", "abs": "https://arxiv.org/abs/2505.10267", "authors": ["Pavel Korotaev", "Petr Surovtsev", "Alexander Kapitanov", "Karina Kvanchiani", "Aleksandr Nagaev"], "title": "HandReader: Advanced Techniques for Efficient Fingerspelling Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "https://github.com/ai-forever/handreader", "summary": "Fingerspelling is a significant component of Sign Language (SL), allowing the\ninterpretation of proper names, characterized by fast hand movements during\nsigning. Although previous works on fingerspelling recognition have focused on\nprocessing the temporal dimension of videos, there remains room for improving\nthe accuracy of these approaches. This paper introduces HandReader, a group of\nthree architectures designed to address the fingerspelling recognition task.\nHandReader$_{RGB}$ employs the novel Temporal Shift-Adaptive Module (TSAM) to\nprocess RGB features from videos of varying lengths while preserving important\nsequential information. HandReader$_{KP}$ is built on the proposed Temporal\nPose Encoder (TPE) operated on keypoints as tensors. Such keypoints composition\nin a batch allows the encoder to pass them through 2D and 3D convolution\nlayers, utilizing temporal and spatial information and accumulating keypoints\ncoordinates. We also introduce HandReader_RGB+KP - architecture with a joint\nencoder to benefit from RGB and keypoint modalities. Each HandReader model\npossesses distinct advantages and achieves state-of-the-art results on the\nChicagoFSWild and ChicagoFSWild+ datasets. Moreover, the models demonstrate\nhigh performance on the first open dataset for Russian fingerspelling, Znaki,\npresented in this paper. The Znaki dataset and HandReader pre-trained models\nare publicly available."}
{"id": "2505.10040", "pdf": "https://arxiv.org/pdf/2505.10040", "abs": "https://arxiv.org/abs/2505.10040", "authors": ["Lei Song", "Jiaxing Li", "Shihan Guan", "Youyong Kong"], "title": "Instance-Prototype Affinity Learning for Non-Exemplar Continual Graph Learning", "categories": ["cs.LG"], "comment": null, "summary": "Graph Neural Networks (GNN) endure catastrophic forgetting, undermining their\ncapacity to preserve previously acquired knowledge amid the assimilation of\nnovel information. Rehearsal-based techniques revisit historical examples,\nadopted as a principal strategy to alleviate this phenomenon. However, memory\nexplosion and privacy infringements impose significant constraints on their\nutility. Non-Exemplar methods circumvent the prior issues through Prototype\nReplay (PR), yet feature drift presents new challenges. In this paper, our\nempirical findings reveal that Prototype Contrastive Learning (PCL) exhibits\nless pronounced drift than conventional PR. Drawing upon PCL, we propose\nInstance-Prototype Affinity Learning (IPAL), a novel paradigm for Non-Exemplar\nContinual Graph Learning (NECGL). Exploiting graph structural information, we\nformulate Topology-Integrated Gaussian Prototypes (TIGP), guiding feature\ndistributions towards high-impact nodes to augment the model's capacity for\nassimilating new knowledge. Instance-Prototype Affinity Distillation (IPAD)\nsafeguards task memory by regularizing discontinuities in class relationships.\nMoreover, we embed a Decision Boundary Perception (DBP) mechanism within PCL,\nfostering greater inter-class discriminability. Evaluations on four node\nclassification benchmark datasets demonstrate that our method outperforms\nexisting state-of-the-art methods, achieving a better trade-off between\nplasticity and stability."}
{"id": "2505.10527", "pdf": "https://arxiv.org/pdf/2505.10527", "abs": "https://arxiv.org/abs/2505.10527", "authors": ["Binghai Wang", "Runji Lin", "Keming Lu", "Le Yu", "Zhenru Zhang", "Fei Huang", "Chujie Zheng", "Kai Dang", "Yang Fan", "Xingzhang Ren", "An Yang", "Binyuan Hui", "Dayiheng Liu", "Tao Gui", "Qi Zhang", "Xuanjing Huang", "Yu-Gang Jiang", "Bowen Yu", "Jingren Zhou", "Junyang Lin"], "title": "WorldPM: Scaling Human Preference Modeling", "categories": ["cs.CL"], "comment": null, "summary": "Motivated by scaling laws in language modeling that demonstrate how test loss\nscales as a power law with model and dataset sizes, we find that similar laws\nexist in preference modeling. We propose World Preference Modeling$ (WorldPM)\nto emphasize this scaling potential, where World Preference embodies a unified\nrepresentation of human preferences. In this paper, we collect preference data\nfrom public forums covering diverse user communities, and conduct extensive\ntraining using 15M-scale data across models ranging from 1.5B to 72B\nparameters. We observe distinct patterns across different evaluation metrics:\n(1) Adversarial metrics (ability to identify deceptive features) consistently\nscale up with increased training data and base model size; (2) Objective\nmetrics (objective knowledge with well-defined answers) show emergent behavior\nin larger language models, highlighting WorldPM's scalability potential; (3)\nSubjective metrics (subjective preferences from a limited number of humans or\nAI) do not demonstrate scaling trends. Further experiments validate the\neffectiveness of WorldPM as a foundation for preference fine-tuning. Through\nevaluations on 7 benchmarks with 20 subtasks, we find that WorldPM broadly\nimproves the generalization performance across human preference datasets of\nvarying sizes (7K, 100K and 800K samples), with performance gains exceeding 5%\non many key subtasks. Integrating WorldPM into our internal RLHF pipeline, we\nobserve significant improvements on both in-house and public evaluation sets,\nwith notable gains of 4% to 8% in our in-house evaluations."}
{"id": "2505.09907", "pdf": "https://arxiv.org/pdf/2505.09907", "abs": "https://arxiv.org/abs/2505.09907", "authors": ["Linwei Zhang", "LuFeng", "Ruijia Liang"], "title": "Avocado Price Prediction Using a Hybrid Deep Learning Model: TCN-MLP-Attention Architecture", "categories": ["cs.LG", "cs.AI", "cs.CE"], "comment": null, "summary": "With the growing demand for healthy foods, agricultural product price\nforecasting has become increasingly important. Hass avocados, as a high-value\ncrop, exhibit complex price fluctuations influenced by factors such as\nseasonality, region, and weather. Traditional prediction models often struggle\nwith highly nonlinear and dynamic data. To address this, we propose a hybrid\ndeep learning model, TCN-MLP-Attention Architecture, combining Temporal\nConvolutional Networks (TCN) for sequential feature extraction, Multi-Layer\nPerceptrons (MLP) for nonlinear interactions, and an Attention mechanism for\ndynamic feature weighting. The dataset used covers over 50,000 records of Hass\navocado sales across the U.S. from 2015 to 2018, including variables such as\nsales volume, average price, time, region, weather, and variety type, collected\nfrom point-of-sale systems and the Hass Avocado Board. After systematic\npreprocessing, including missing value imputation and feature normalization,\nthe proposed model was trained and evaluated. Experimental results demonstrate\nthat the TCN-MLP-Attention model achieves excellent predictive performance,\nwith an RMSE of 1.23 and an MSE of 1.51, outperforming traditional methods.\nThis research provides a scalable and effective approach for time series\nforecasting in agricultural markets and offers valuable insights for\nintelligent supply chain management and price strategy optimization."}
{"id": "2505.10281", "pdf": "https://arxiv.org/pdf/2505.10281", "abs": "https://arxiv.org/abs/2505.10281", "authors": ["Mengqiu Xu", "Kaixin Chen", "Heng Guo", "Yixiang Huang", "Ming Wu", "Zhenwei Shi", "Chuang Zhang", "Jun Guo"], "title": "MFogHub: Bridging Multi-Regional and Multi-Satellite Data for Global Marine Fog Detection and Forecasting", "categories": ["cs.CV"], "comment": null, "summary": "Deep learning approaches for marine fog detection and forecasting have\noutperformed traditional methods, demonstrating significant scientific and\npractical importance. However, the limited availability of open-source datasets\nremains a major challenge. Existing datasets, often focused on a single region\nor satellite, restrict the ability to evaluate model performance across diverse\nconditions and hinder the exploration of intrinsic marine fog characteristics.\nTo address these limitations, we introduce \\textbf{MFogHub}, the first\nmulti-regional and multi-satellite dataset to integrate annotated marine fog\nobservations from 15 coastal fog-prone regions and six geostationary\nsatellites, comprising over 68,000 high-resolution samples. By encompassing\ndiverse regions and satellite perspectives, MFogHub facilitates rigorous\nevaluation of both detection and forecasting methods under varying conditions.\nExtensive experiments with 16 baseline models demonstrate that MFogHub can\nreveal generalization fluctuations due to regional and satellite discrepancy,\nwhile also serving as a valuable resource for the development of targeted and\nscalable fog prediction techniques. Through MFogHub, we aim to advance both the\npractical monitoring and scientific understanding of marine fog dynamics on a\nglobal scale. The dataset and code are at\n\\href{https://github.com/kaka0910/MFogHub}{https://github.com/kaka0910/MFogHub}."}
{"id": "2505.10050", "pdf": "https://arxiv.org/pdf/2505.10050", "abs": "https://arxiv.org/abs/2505.10050", "authors": ["Fahad Almalki", "Mehedi Masud"], "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection."}
{"id": "2505.10554", "pdf": "https://arxiv.org/pdf/2505.10554", "abs": "https://arxiv.org/abs/2505.10554", "authors": ["Zhiyuan Hu", "Yibo Wang", "Hanze Dong", "Yuhui Xu", "Amrita Saha", "Caiming Xiong", "Bryan Hooi", "Junnan Li"], "title": "Beyond 'Aha!': Toward Systematic Meta-Abilities Alignment in Large Reasoning Models", "categories": ["cs.CL"], "comment": "In Progress", "summary": "Large reasoning models (LRMs) already possess a latent capacity for long\nchain-of-thought reasoning. Prior work has shown that outcome-based\nreinforcement learning (RL) can incidentally elicit advanced reasoning\nbehaviors such as self-correction, backtracking, and verification phenomena\noften referred to as the model's \"aha moment\". However, the timing and\nconsistency of these emergent behaviors remain unpredictable and\nuncontrollable, limiting the scalability and reliability of LRMs' reasoning\ncapabilities. To address these limitations, we move beyond reliance on prompts\nand coincidental \"aha moments\". Instead, we explicitly align models with three\nmeta-abilities: deduction, induction, and abduction, using automatically\ngenerated, self-verifiable tasks. Our three stage-pipeline individual\nalignment, parameter-space merging, and domain-specific reinforcement learning,\nboosting performance by over 10\\% relative to instruction-tuned baselines.\nFurthermore, domain-specific RL from the aligned checkpoint yields an\nadditional 2\\% average gain in the performance ceiling across math, coding, and\nscience benchmarks, demonstrating that explicit meta-ability alignment offers a\nscalable and dependable foundation for reasoning. Code is available at:\nhttps://github.com/zhiyuanhubj/Meta-Ability-Alignment"}
{"id": "2505.09925", "pdf": "https://arxiv.org/pdf/2505.09925", "abs": "https://arxiv.org/abs/2505.09925", "authors": ["Yutao Yang", "Jie Zhou", "Junsong Li", "Qianjun Pan", "Bihao Zhan", "Qin Chen", "Xipeng Qiu", "Liang He"], "title": "Reinforced Interactive Continual Learning via Real-time Noisy Human Feedback", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper introduces an interactive continual learning paradigm where AI\nmodels dynamically learn new skills from real-time human feedback while\nretaining prior knowledge. This paradigm distinctively addresses two major\nlimitations of traditional continual learning: (1) dynamic model updates using\nstreaming, real-time human-annotated data, rather than static datasets with\nfixed labels, and (2) the assumption of clean labels, by explicitly handling\nthe noisy feedback common in real-world interactions. To tackle these problems,\nwe propose RiCL, a Reinforced interactive Continual Learning framework\nleveraging Large Language Models (LLMs) to learn new skills effectively from\ndynamic feedback. RiCL incorporates three key components: a temporal\nconsistency-aware purifier to automatically discern clean from noisy samples in\ndata streams; an interaction-aware direct preference optimization strategy to\nalign model behavior with human intent by reconciling AI-generated and\nhuman-provided feedback; and a noise-resistant contrastive learning module that\ncaptures robust representations by exploiting inherent data relationships, thus\navoiding reliance on potentially unreliable labels. Extensive experiments on\ntwo benchmark datasets (FewRel and TACRED), contaminated with realistic noise\npatterns, demonstrate that our RiCL approach substantially outperforms existing\ncombinations of state-of-the-art online continual learning and noisy-label\nlearning methods."}
{"id": "2505.10289", "pdf": "https://arxiv.org/pdf/2505.10289", "abs": "https://arxiv.org/abs/2505.10289", "authors": ["Yue Wang", "Shuai Xu", "Xuelin Zhu", "Yicong Li"], "title": "MSCI: Addressing CLIP's Inherent Limitations for Compositional Zero-Shot Learning", "categories": ["cs.CV"], "comment": "9 pages, 5 figures", "summary": "Compositional Zero-Shot Learning (CZSL) aims to recognize unseen state-object\ncombinations by leveraging known combinations. Existing studies basically rely\non the cross-modal alignment capabilities of CLIP but tend to overlook its\nlimitations in capturing fine-grained local features, which arise from its\narchitectural and training paradigm. To address this issue, we propose a\nMulti-Stage Cross-modal Interaction (MSCI) model that effectively explores and\nutilizes intermediate-layer information from CLIP's visual encoder.\nSpecifically, we design two self-adaptive aggregators to extract local\ninformation from low-level visual features and integrate global information\nfrom high-level visual features, respectively. These key information are\nprogressively incorporated into textual representations through a\nstage-by-stage interaction mechanism, significantly enhancing the model's\nperception capability for fine-grained local visual information. Additionally,\nMSCI dynamically adjusts the attention weights between global and local visual\ninformation based on different combinations, as well as different elements\nwithin the same combination, allowing it to flexibly adapt to diverse\nscenarios. Experiments on three widely used datasets fully validate the\neffectiveness and superiority of the proposed model. Data and code are\navailable at https://github.com/ltpwy/MSCI."}
{"id": "2505.10057", "pdf": "https://arxiv.org/pdf/2505.10057", "abs": "https://arxiv.org/abs/2505.10057", "authors": ["Tiancong Cheng", "Ying Zhang", "Yuxuan Liang", "Roger Zimmermann", "Zhiwen Yu", "Bin Guo"], "title": "JointDistill: Adaptive Multi-Task Distillation for Joint Depth Estimation and Scene Segmentation", "categories": ["cs.LG"], "comment": null, "summary": "Depth estimation and scene segmentation are two important tasks in\nintelligent transportation systems. A joint modeling of these two tasks will\nreduce the requirement for both the storage and training efforts. This work\nexplores how the multi-task distillation could be used to improve such unified\nmodeling. While existing solutions transfer multiple teachers' knowledge in a\nstatic way, we propose a self-adaptive distillation method that can dynamically\nadjust the knowledge amount from each teacher according to the student's\ncurrent learning ability. Furthermore, as multiple teachers exist, the\nstudent's gradient update direction in the distillation is more prone to be\nerroneous where knowledge forgetting may occur. To avoid this, we propose a\nknowledge trajectory to record the most essential information that a model has\nlearnt in the past, based on which a trajectory-based distillation loss is\ndesigned to guide the student to follow the learning curve similarly in a\ncost-effective way. We evaluate our method on multiple benchmarking datasets\nincluding Cityscapes and NYU-v2. Compared to the state-of-the-art solutions,\nour method achieves a clearly improvement. The code is provided in the\nsupplementary materials."}
{"id": "2505.09855", "pdf": "https://arxiv.org/pdf/2505.09855", "abs": "https://arxiv.org/abs/2505.09855", "authors": ["Alexander Y. Ku", "Thomas L. Griffiths", "Stephanie C. Y. Chan"], "title": "Predictability Shapes Adaptation: An Evolutionary Perspective on Modes of Learning in Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Transformer models learn in two distinct modes: in-weights learning (IWL),\nencoding knowledge into model weights, and in-context learning (ICL), adapting\nflexibly to context without weight modification. To better understand the\ninterplay between these learning modes, we draw inspiration from evolutionary\nbiology's analogous adaptive strategies: genetic encoding (akin to IWL,\nadapting over generations and fixed within an individual's lifetime) and\nphenotypic plasticity (akin to ICL, enabling flexible behavioral responses to\nenvironmental cues). In evolutionary biology, environmental predictability\ndictates the balance between these strategies: stability favors genetic\nencoding, while reliable predictive cues promote phenotypic plasticity. We\nexperimentally operationalize these dimensions of predictability and\nsystematically investigate their influence on the ICL/IWL balance in\nTransformers. Using regression and classification tasks, we show that high\nenvironmental stability decisively favors IWL, as predicted, with a sharp\ntransition at maximal stability. Conversely, high cue reliability enhances ICL\nefficacy, particularly when stability is low. Furthermore, learning dynamics\nreveal task-contingent temporal evolution: while a canonical ICL-to-IWL shift\noccurs in some settings (e.g., classification with many classes), we\ndemonstrate that scenarios with easier IWL (e.g., fewer classes) or slower ICL\nacquisition (e.g., regression) can exhibit an initial IWL phase later yielding\nto ICL dominance. These findings support a relative-cost hypothesis for\nexplaining these learning mode transitions, establishing predictability as a\ncritical factor governing adaptive strategies in Transformers, and offering\nnovel insights for understanding ICL and guiding training methodologies."}
{"id": "2505.09926", "pdf": "https://arxiv.org/pdf/2505.09926", "abs": "https://arxiv.org/abs/2505.09926", "authors": ["Bin-Bin Gao", "Yue Zhu", "Jiangtao Yan", "Yuezhi Cai", "Weixi Zhang", "Meng Wang", "Jun Liu", "Yong Liu", "Lei Wang", "Chengjie Wang"], "title": "AdaptCLIP: Adapting CLIP for Universal Visual Anomaly Detection", "categories": ["cs.CV", "cs.AI"], "comment": "27 pages, 15 figures, 22 tables", "summary": "Universal visual anomaly detection aims to identify anomalies from novel or\nunseen vision domains without additional fine-tuning, which is critical in open\nscenarios. Recent studies have demonstrated that pre-trained vision-language\nmodels like CLIP exhibit strong generalization with just zero or a few normal\nimages. However, existing methods struggle with designing prompt templates,\ncomplex token interactions, or requiring additional fine-tuning, resulting in\nlimited flexibility. In this work, we present a simple yet effective method\ncalled AdaptCLIP based on two key insights. First, adaptive visual and textual\nrepresentations should be learned alternately rather than jointly. Second,\ncomparative learning between query and normal image prompt should incorporate\nboth contextual and aligned residual features, rather than relying solely on\nresidual features. AdaptCLIP treats CLIP models as a foundational service,\nadding only three simple adapters, visual adapter, textual adapter, and\nprompt-query adapter, at its input or output ends. AdaptCLIP supports\nzero-/few-shot generalization across domains and possesses a training-free\nmanner on target domains once trained on a base dataset. AdaptCLIP achieves\nstate-of-the-art performance on 12 anomaly detection benchmarks from industrial\nand medical domains, significantly outperforming existing competitive methods.\nWe will make the code and model of AdaptCLIP available at\nhttps://github.com/gaobb/AdaptCLIP."}
{"id": "2505.10292", "pdf": "https://arxiv.org/pdf/2505.10292", "abs": "https://arxiv.org/abs/2505.10292", "authors": ["Daniel A. P. Oliveira", "David Martins de Matos"], "title": "StoryReasoning Dataset: Using Chain-of-Thought for Scene Understanding and Grounded Story Generation", "categories": ["cs.CV", "cs.CL", "I.2.10; I.2.7"], "comment": "31 pages, 14 figures", "summary": "Visual storytelling systems struggle to maintain character identity across\nframes and link actions to appropriate subjects, frequently leading to\nreferential hallucinations. These issues can be addressed through grounding of\ncharacters, objects, and other entities on the visual elements. We propose\nStoryReasoning, a dataset containing 4,178 stories derived from 52,016 movie\nimages, with both structured scene analyses and grounded stories. Each story\nmaintains character and object consistency across frames while explicitly\nmodeling multi-frame relationships through structured tabular representations.\nOur approach features cross-frame object re-identification using visual\nsimilarity and face recognition, chain-of-thought reasoning for explicit\nnarrative modeling, and a grounding scheme that links textual elements to\nvisual entities across multiple frames. We establish baseline performance by\nfine-tuning Qwen2.5-VL 7B, creating Qwen Storyteller, which performs end-to-end\nobject detection, re-identification, and landmark detection while maintaining\nconsistent object references throughout the story. Evaluation demonstrates a\nreduction from 4.06 to 3.56 (-12.3%) hallucinations on average per story when\ncompared to a non-fine-tuned model."}
{"id": "2505.10083", "pdf": "https://arxiv.org/pdf/2505.10083", "abs": "https://arxiv.org/abs/2505.10083", "authors": ["Chengsen Wang", "Qi Qi", "Zhongwen Rao", "Lujia Pan", "Jingyu Wang", "Jianxin Liao"], "title": "ChronoSteer: Bridging Large Language Model and Time Series Foundation Model via Synthetic Data", "categories": ["cs.LG"], "comment": null, "summary": "Conventional forecasting methods rely on unimodal time series data, limiting\ntheir ability to exploit rich textual information. Recently, large language\nmodels (LLMs) and time series foundation models (TSFMs) have demonstrated\npowerful capability in textual reasoning and temporal modeling, respectively.\nIntegrating the strengths of both to construct a multimodal model that\nconcurrently leverages both temporal and textual information for future\ninference has emerged as a critical research challenge. To address the scarcity\nof event-series paired data, we propose a decoupled framework: an LLM is\nemployed to transform textual events into revision instructions, which are then\nused to steer the output of TSFM. To implement this framework, we introduce\nChronoSteer, a multimodal TSFM that can be steered through textual revision\ninstructions, effectively bridging LLM and TSFM. Moreover, to mitigate the\nshortage of cross-modal instruction-series paired data, we devise a two-stage\ntraining strategy based on synthetic data. In addition, we also construct a\nhigh-quality multimodal time series forecasting benchmark to address the\ninformation leakage concerns during evaluation. After integrating with an LLM,\nChronoSteer, which is trained exclusively on synthetic data, achieves a 25.7%\nimprovement in prediction accuracy compared to the unimodal backbone and a\n22.5% gain over the previous state-of-the-art multimodal method."}
{"id": "2505.09901", "pdf": "https://arxiv.org/pdf/2505.09901", "abs": "https://arxiv.org/abs/2505.09901", "authors": ["Ziyuan Zhang", "Darcy Wang", "Ningyuan Chen", "Rodrigo Mansur", "Vahid Sarhangian"], "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.HC"], "comment": null, "summary": "Large language models (LLMs) are increasingly used to simulate or automate\nhuman behavior in complex sequential decision-making tasks. A natural question\nis then whether LLMs exhibit similar decision-making behavior to humans, and\ncan achieve comparable (or superior) performance. In this work, we focus on the\nexploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic\ndecision-making under uncertainty. We employ canonical multi-armed bandit (MAB)\ntasks introduced in the cognitive science and psychiatry literature to conduct\na comparative study of the E&E strategies of LLMs, humans, and MAB algorithms.\nWe use interpretable choice models to capture the E&E strategies of the agents\nand investigate how explicit reasoning, through both prompting strategies and\nreasoning-enhanced models, shapes LLM decision-making. We find that reasoning\nshifts LLMs toward more human-like behavior, characterized by a mix of random\nand directed exploration. In simple stationary tasks, reasoning-enabled LLMs\nexhibit similar levels of random and directed exploration compared to humans.\nHowever, in more complex, non-stationary environments, LLMs struggle to match\nhuman adaptability, particularly in effective directed exploration, despite\nachieving similar regret in certain scenarios. Our findings highlight both the\npromise and limits of LLMs as simulators of human behavior and tools for\nautomated decision-making and point to potential areas of improvements."}
{"id": "2505.09935", "pdf": "https://arxiv.org/pdf/2505.09935", "abs": "https://arxiv.org/abs/2505.09935", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Quoc Dai Tran"], "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users."}
{"id": "2505.10294", "pdf": "https://arxiv.org/pdf/2505.10294", "abs": "https://arxiv.org/abs/2505.10294", "authors": ["Guillaume Balezo", "Roger Trullo", "Albert Pla Planas", "Etienne Decenciere", "Thomas Walter"], "title": "MIPHEI-ViT: Multiplex Immunofluorescence Prediction from H&E Images using ViT Foundation Models", "categories": ["cs.CV", "q-bio.TO", "68T07 (Primary), 92C55 (Secondary)", "I.4.9; I.2.10; I.5.4; J.3"], "comment": null, "summary": "Histopathological analysis is a cornerstone of cancer diagnosis, with\nHematoxylin and Eosin (H&E) staining routinely acquired for every patient to\nvisualize cell morphology and tissue architecture. On the other hand, multiplex\nimmunofluorescence (mIF) enables more precise cell type identification via\nproteomic markers, but has yet to achieve widespread clinical adoption due to\ncost and logistical constraints. To bridge this gap, we introduce MIPHEI\n(Multiplex Immunofluorescence Prediction from H&E), a U-Net-inspired\narchitecture that integrates state-of-the-art ViT foundation models as encoders\nto predict mIF signals from H&E images. MIPHEI targets a comprehensive panel of\nmarkers spanning nuclear content, immune lineages (T cells, B cells, myeloid),\nepithelium, stroma, vasculature, and proliferation. We train our model using\nthe publicly available ORION dataset of restained H&E and mIF images from\ncolorectal cancer tissue, and validate it on two independent datasets. MIPHEI\nachieves accurate cell-type classification from H&E alone, with F1 scores of\n0.88 for Pan-CK, 0.57 for CD3e, 0.56 for SMA, 0.36 for CD68, and 0.30 for CD20,\nsubstantially outperforming both a state-of-the-art baseline and a random\nclassifier for most markers. Our results indicate that our model effectively\ncaptures the complex relationships between nuclear morphologies in their tissue\ncontext, as visible in H&E images and molecular markers defining specific cell\ntypes. MIPHEI offers a promising step toward enabling cell-type-aware analysis\nof large-scale H&E datasets, in view of uncovering relationships between\nspatial cellular organization and patient outcomes."}
{"id": "2505.10117", "pdf": "https://arxiv.org/pdf/2505.10117", "abs": "https://arxiv.org/abs/2505.10117", "authors": ["JieHao Wu", "Ziwei Wang", "Junjie Sheng", "Wenhao Li", "Xiangfei Wang", "Jun Luo"], "title": "Learning Virtual Machine Scheduling in Cloud Computing through Language Agents", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "In cloud services, virtual machine (VM) scheduling is a typical Online\nDynamic Multidimensional Bin Packing (ODMBP) problem, characterized by\nlarge-scale complexity and fluctuating demands. Traditional optimization\nmethods struggle to adapt to real-time changes, domain-expert-designed\nheuristic approaches suffer from rigid strategies, and existing learning-based\nmethods often lack generalizability and interpretability. To address these\nlimitations, this paper proposes a hierarchical language agent framework named\nMiCo, which provides a large language model (LLM)-driven heuristic design\nparadigm for solving ODMBP. Specifically, ODMBP is formulated as a Semi-Markov\nDecision Process with Options (SMDP-Option), enabling dynamic scheduling\nthrough a two-stage architecture, i.e., Option Miner and Option Composer.\nOption Miner utilizes LLMs to discover diverse and useful non-context-aware\nstrategies by interacting with constructed environments. Option Composer\nemploys LLMs to discover a composing strategy that integrates the\nnon-context-aware strategies with the contextual ones. Extensive experiments on\nreal-world enterprise datasets demonstrate that MiCo achieves a 96.9\\%\ncompetitive ratio in large-scale scenarios involving more than 10,000 virtual\nmachines. It maintains high performance even under nonstationary request flows\nand diverse configurations, thus validating its effectiveness in complex and\nlarge-scale cloud environments."}
{"id": "2505.09949", "pdf": "https://arxiv.org/pdf/2505.09949", "abs": "https://arxiv.org/abs/2505.09949", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Samgyu Yang", "Abdulrahman Faden"], "title": "Advanced Crash Causation Analysis for Freeway Safety: A Large Language Model Approach to Identifying Key Contributing Factors", "categories": ["cs.LG", "cs.CL", "stat.AP"], "comment": null, "summary": "Understanding the factors contributing to traffic crashes and developing\nstrategies to mitigate their severity is essential. Traditional statistical\nmethods and machine learning models often struggle to capture the complex\ninteractions between various factors and the unique characteristics of each\ncrash. This research leverages large language model (LLM) to analyze freeway\ncrash data and provide crash causation analysis accordingly. By compiling 226\ntraffic safety studies related to freeway crashes, a training dataset\nencompassing environmental, driver, traffic, and geometric design factors was\ncreated. The Llama3 8B model was fine-tuned using QLoRA to enhance its\nunderstanding of freeway crashes and their contributing factors, as covered in\nthese studies. The fine-tuned Llama3 8B model was then used to identify crash\ncausation without pre-labeled data through zero-shot classification, providing\ncomprehensive explanations to ensure that the identified causes were reasonable\nand aligned with existing research. Results demonstrate that LLMs effectively\nidentify primary crash causes such as alcohol-impaired driving, speeding,\naggressive driving, and driver inattention. Incorporating event data, such as\nroad maintenance, offers more profound insights. The model's practical\napplicability and potential to improve traffic safety measures were validated\nby a high level of agreement among researchers in the field of traffic safety,\nas reflected in questionnaire results with 88.89%. This research highlights the\ncomplex nature of traffic crashes and how LLMs can be used for comprehensive\nanalysis of crash causation and other contributing factors. Moreover, it\nprovides valuable insights and potential countermeasures to aid planners and\npolicymakers in developing more effective and efficient traffic safety\npractices."}
{"id": "2505.09945", "pdf": "https://arxiv.org/pdf/2505.09945", "abs": "https://arxiv.org/abs/2505.09945", "authors": ["Deeksha Prahlad", "Chanhee Lee", "Dongha Kim", "Hokeun Kim"], "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)", "summary": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time."}
{"id": "2505.10351", "pdf": "https://arxiv.org/pdf/2505.10351", "abs": "https://arxiv.org/abs/2505.10351", "authors": ["Jie Zhu", "Jirong Zha", "Ding Li", "Leye Wang"], "title": "A Unified and Scalable Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability", "categories": ["cs.CV"], "comment": "An extension of our ACM CCS2024 conference paper (arXiv:2404.02462).\n  We show the impacts of scaling from both data and model aspects on membership\n  inference for self-supervised visual encoders", "summary": "Self-supervised learning shows promise in harnessing extensive unlabeled\ndata, but it also confronts significant privacy concerns, especially in vision.\nIn this paper, we perform membership inference on visual self-supervised models\nin a more realistic setting: self-supervised training method and details are\nunknown for an adversary when attacking as he usually faces a black-box system\nin practice. In this setting, considering that self-supervised model could be\ntrained by completely different self-supervised paradigms, e.g., masked image\nmodeling and contrastive learning, with complex training details, we propose a\nunified membership inference method called PartCrop. It is motivated by the\nshared part-aware capability among models and stronger part response on the\ntraining data. Specifically, PartCrop crops parts of objects in an image to\nquery responses within the image in representation space. We conduct extensive\nattacks on self-supervised models with different training protocols and\nstructures using three widely used image datasets. The results verify the\neffectiveness and generalization of PartCrop. Moreover, to defend against\nPartCrop, we evaluate two common approaches, i.e., early stop and differential\nprivacy, and propose a tailored method called shrinking crop scale range. The\ndefense experiments indicate that all of them are effective. Finally, besides\nprototype testing on toy visual encoders and small-scale image datasets, we\nquantitatively study the impacts of scaling from both data and model aspects in\na realistic scenario and propose a scalable PartCrop-v2 by introducing two\nstructural improvements to PartCrop. Our code is at\nhttps://github.com/JiePKU/PartCrop."}
{"id": "2505.10120", "pdf": "https://arxiv.org/pdf/2505.10120", "abs": "https://arxiv.org/abs/2505.10120", "authors": ["Guillaume Godin"], "title": "All You Need Is Synthetic Task Augmentation", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 3 Figures, 6 tables", "summary": "Injecting rule-based models like Random Forests into differentiable neural\nnetwork frameworks remains an open challenge in machine learning. Recent\nadvancements have demonstrated that pretrained models can generate efficient\nmolecular embeddings. However, these approaches often require extensive\npretraining and additional techniques, such as incorporating posterior\nprobabilities, to boost performance. In our study, we propose a novel strategy\nthat jointly trains a single Graph Transformer neural network on both sparse\nmultitask molecular property experimental targets and synthetic targets derived\nfrom XGBoost models trained on Osmordred molecular descriptors. These synthetic\ntasks serve as independent auxiliary tasks. Our results show consistent and\nsignificant performance improvement across all 19 molecular property prediction\ntasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms\nthe XGBoost single-task learner. This demonstrates that synthetic task\naugmentation is an effective method for enhancing neural model performance in\nmultitask molecular property prediction without the need for feature injection\nor pretraining."}
{"id": "2505.10093", "pdf": "https://arxiv.org/pdf/2505.10093", "abs": "https://arxiv.org/abs/2505.10093", "authors": ["Hsuan-Lei Shao"], "title": "From Text to Network: Constructing a Knowledge Graph of Taiwan-Based China Studies Using Generative AI", "categories": ["cs.AI", "cs.CL", "I.2.4; H.3.3; J.5"], "comment": "4 pages, 4 figures", "summary": "Taiwanese China Studies (CS) has developed into a rich, interdisciplinary\nresearch field shaped by the unique geopolitical position and long standing\nacademic engagement with Mainland China. This study responds to the growing\nneed to systematically revisit and reorganize decades of Taiwan based CS\nscholarship by proposing an AI assisted approach that transforms unstructured\nacademic texts into structured, interactive knowledge representations. We apply\ngenerative AI (GAI) techniques and large language models (LLMs) to extract and\nstandardize entity relation triples from 1,367 peer reviewed CS articles\npublished between 1996 and 2019. These triples are then visualized through a\nlightweight D3.js based system, forming the foundation of a domain specific\nknowledge graph and vector database for the field. This infrastructure allows\nusers to explore conceptual nodes and semantic relationships across the corpus,\nrevealing previously uncharted intellectual trajectories, thematic clusters,\nand research gaps. By decomposing textual content into graph structured\nknowledge units, our system enables a paradigm shift from linear text\nconsumption to network based knowledge navigation. In doing so, it enhances\nscholarly access to CS literature while offering a scalable, data driven\nalternative to traditional ontology construction. This work not only\ndemonstrates how generative AI can augment area studies and digital humanities\nbut also highlights its potential to support a reimagined scholarly\ninfrastructure for regional knowledge systems."}
{"id": "2505.09952", "pdf": "https://arxiv.org/pdf/2505.09952", "abs": "https://arxiv.org/abs/2505.09952", "authors": ["Tianyu Huai", "Jie Zhou", "Yuxuan Cai", "Qin Chen", "Wen Wu", "Xingjiao Wu", "Xipeng Qiu", "Liang He"], "title": "Task-Core Memory Management and Consolidation for Long-term Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Submitted to Neurips2025", "summary": "In this paper, we focus on a long-term continual learning (CL) task, where a\nmodel learns sequentially from a stream of vast tasks over time, acquiring new\nknowledge while retaining previously learned information in a manner akin to\nhuman learning. Unlike traditional CL settings, long-term CL involves handling\na significantly larger number of tasks, which exacerbates the issue of\ncatastrophic forgetting. Our work seeks to address two critical questions: 1)\nHow do existing CL methods perform in the context of long-term CL? and 2) How\ncan we mitigate the catastrophic forgetting that arises from prolonged\nsequential updates? To tackle these challenges, we propose a novel framework\ninspired by human memory mechanisms for long-term continual learning (Long-CL).\nSpecifically, we introduce a task-core memory management strategy to\nefficiently index crucial memories and adaptively update them as learning\nprogresses. Additionally, we develop a long-term memory consolidation mechanism\nthat selectively retains hard and discriminative samples, ensuring robust\nknowledge retention. To facilitate research in this area, we construct and\nrelease two multi-modal and textual benchmarks, MMLongCL-Bench and\nTextLongCL-Bench, providing a valuable resource for evaluating long-term CL\napproaches. Experimental results show that Long-CL outperforms the previous\nstate-of-the-art by 7.4\\% and 6.5\\% AP on the two benchmarks, respectively,\ndemonstrating the effectiveness of our approach."}
{"id": "2505.10352", "pdf": "https://arxiv.org/pdf/2505.10352", "abs": "https://arxiv.org/abs/2505.10352", "authors": ["Shihao Zou", "Qingfeng Li", "Wei Ji", "Jingjing Li", "Yongkui Yang", "Guoqi Li", "Chao Dong"], "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer"}
{"id": "2505.10125", "pdf": "https://arxiv.org/pdf/2505.10125", "abs": "https://arxiv.org/abs/2505.10125", "authors": ["Wujun Zhou", "Shu Ding", "ZeLin Li", "Wei Wang"], "title": "Enhancing the Performance of Global Model by Improving the Adaptability of Local Models in Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning enables the clients to collaboratively train a global\nmodel, which is aggregated from local models. Due to the heterogeneous data\ndistributions over clients and data privacy in federated learning, it is\ndifficult to train local models to achieve a well-performed global model. In\nthis paper, we introduce the adaptability of local models, i.e., the average\nperformance of local models on data distributions over clients, and enhance the\nperformance of the global model by improving the adaptability of local models.\nSince each client does not know the data distributions over other clients, the\nadaptability of the local model cannot be directly optimized. First, we provide\nthe property of an appropriate local model which has good adaptability on the\ndata distributions over clients. Then, we formalize the property into the local\ntraining objective with a constraint and propose a feasible solution to train\nthe local model. Extensive experiments on federated learning benchmarks\ndemonstrate that our method significantly improves the adaptability of local\nmodels and achieves a well-performed global model that consistently outperforms\nthe baseline methods."}
{"id": "2505.10117", "pdf": "https://arxiv.org/pdf/2505.10117", "abs": "https://arxiv.org/abs/2505.10117", "authors": ["JieHao Wu", "Ziwei Wang", "Junjie Sheng", "Wenhao Li", "Xiangfei Wang", "Jun Luo"], "title": "Learning Virtual Machine Scheduling in Cloud Computing through Language Agents", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "In cloud services, virtual machine (VM) scheduling is a typical Online\nDynamic Multidimensional Bin Packing (ODMBP) problem, characterized by\nlarge-scale complexity and fluctuating demands. Traditional optimization\nmethods struggle to adapt to real-time changes, domain-expert-designed\nheuristic approaches suffer from rigid strategies, and existing learning-based\nmethods often lack generalizability and interpretability. To address these\nlimitations, this paper proposes a hierarchical language agent framework named\nMiCo, which provides a large language model (LLM)-driven heuristic design\nparadigm for solving ODMBP. Specifically, ODMBP is formulated as a Semi-Markov\nDecision Process with Options (SMDP-Option), enabling dynamic scheduling\nthrough a two-stage architecture, i.e., Option Miner and Option Composer.\nOption Miner utilizes LLMs to discover diverse and useful non-context-aware\nstrategies by interacting with constructed environments. Option Composer\nemploys LLMs to discover a composing strategy that integrates the\nnon-context-aware strategies with the contextual ones. Extensive experiments on\nreal-world enterprise datasets demonstrate that MiCo achieves a 96.9\\%\ncompetitive ratio in large-scale scenarios involving more than 10,000 virtual\nmachines. It maintains high performance even under nonstationary request flows\nand diverse configurations, thus validating its effectiveness in complex and\nlarge-scale cloud environments."}
{"id": "2505.09955", "pdf": "https://arxiv.org/pdf/2505.09955", "abs": "https://arxiv.org/abs/2505.09955", "authors": ["Jaeho Kim", "Seulki Lee"], "title": "TransPL: VQ-Code Transition Matrices for Pseudo-Labeling of Time Series Unsupervised Domain Adaptation", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 Accept", "summary": "Unsupervised domain adaptation (UDA) for time series data remains a critical\nchallenge in deep learning, with traditional pseudo-labeling strategies failing\nto capture temporal patterns and channel-wise shifts between domains, producing\nsub-optimal pseudo-labels. As such, we introduce TransPL, a novel approach that\naddresses these limitations by modeling the joint distribution $P(\\mathbf{X},\ny)$ of the source domain through code transition matrices, where the codes are\nderived from vector quantization (VQ) of time series patches. Our method\nconstructs class- and channel-wise code transition matrices from the source\ndomain and employs Bayes' rule for target domain adaptation, generating\npseudo-labels based on channel-wise weighted class-conditional likelihoods.\nTransPL offers three key advantages: explicit modeling of temporal transitions\nand channel-wise shifts between different domains, versatility towards\ndifferent UDA scenarios (e.g., weakly-supervised UDA), and explainable\npseudo-label generation. We validate TransPL's effectiveness through extensive\nanalysis on four time series UDA benchmarks and confirm that it consistently\noutperforms state-of-the-art pseudo-labeling methods by a strong margin (6.1%\naccuracy improvement, 4.9% F1 improvement), while providing interpretable\ninsights into the domain adaptation process through its learned code transition\nmatrices."}
{"id": "2505.10420", "pdf": "https://arxiv.org/pdf/2505.10420", "abs": "https://arxiv.org/abs/2505.10420", "authors": ["Andrei Arhire", "Radu Timofte"], "title": "Learned Lightweight Smartphone ISP with Unpaired Data", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at CVPRW 2025", "summary": "The Image Signal Processor (ISP) is a fundamental component in modern\nsmartphone cameras responsible for conversion of RAW sensor image data to RGB\nimages with a strong focus on perceptual quality. Recent work highlights the\npotential of deep learning approaches and their ability to capture details with\na quality increasingly close to that of professional cameras. A difficult and\ncostly step when developing a learned ISP is the acquisition of pixel-wise\naligned paired data that maps the raw captured by a smartphone camera sensor to\nhigh-quality reference images. In this work, we address this challenge by\nproposing a novel training method for a learnable ISP that eliminates the need\nfor direct correspondences between raw images and ground-truth data with\nmatching content. Our unpaired approach employs a multi-term loss function\nguided by adversarial training with multiple discriminators processing feature\nmaps from pre-trained networks to maintain content structure while learning\ncolor and texture characteristics from the target RGB dataset. Using\nlightweight neural network architectures suitable for mobile devices as\nbackbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm\nUltraISP datasets. Compared to paired training methods, our unpaired learning\nstrategy shows strong potential and achieves high fidelity across multiple\nevaluation metrics. The code and pre-trained models are available at\nhttps://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data ."}
{"id": "2505.10128", "pdf": "https://arxiv.org/pdf/2505.10128", "abs": "https://arxiv.org/abs/2505.10128", "authors": ["Huy Q. Le", "Latif U. Khan", "Choong Seon Hong"], "title": "Robust Federated Learning on Edge Devices with Domain Heterogeneity", "categories": ["cs.LG", "cs.AI"], "comment": "IWCMC 2025", "summary": "Federated Learning (FL) allows collaborative training while ensuring data\nprivacy across distributed edge devices, making it a popular solution for\nprivacy-sensitive applications. However, FL faces significant challenges due to\nstatistical heterogeneity, particularly domain heterogeneity, which impedes the\nglobal mode's convergence. In this study, we introduce a new framework to\naddress this challenge by improving the generalization ability of the FL global\nmodel under domain heterogeneity, using prototype augmentation. Specifically,\nwe introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a\nprototype-based FL framework designed to enhance feature diversity and model\nrobustness. FedAPC leverages prototypes derived from the mean features of\naugmented data to capture richer representations. By aligning local features\nwith global prototypes, we enable the model to learn meaningful semantic\nfeatures while reducing overfitting to any specific domain. Experimental\nresults on the Office-10 and Digits datasets illustrate that our framework\noutperforms SOTA baselines, demonstrating superior performance."}
{"id": "2505.10118", "pdf": "https://arxiv.org/pdf/2505.10118", "abs": "https://arxiv.org/abs/2505.10118", "authors": ["Yangfu Li", "Hongjian Zhan", "Tianyi Chen", "Qi Liu", "Yue Lu"], "title": "Why 1 + 1 < 1 in Visual Token Pruning: Beyond Naive Integration via Multi-Objective Balanced Covering", "categories": ["cs.CV", "cs.CL"], "comment": "31 pages,9 figures,conference", "summary": "Existing visual token pruning methods target prompt alignment and visual\npreservation with static strategies, overlooking the varying relative\nimportance of these objectives across tasks, which leads to inconsistent\nperformance. To address this, we derive the first closed-form error bound for\nvisual token pruning based on the Hausdorff distance, uniformly characterizing\nthe contributions of both objectives. Moreover, leveraging $\\epsilon$-covering\ntheory, we reveal an intrinsic trade-off between these objectives and quantify\ntheir optimal attainment levels under a fixed budget. To practically handle\nthis trade-off, we propose Multi-Objective Balanced Covering (MoB), which\nreformulates visual token pruning as a bi-objective covering problem. In this\nframework, the attainment trade-off reduces to budget allocation via greedy\nradius trading. MoB offers a provable performance bound and linear scalability\nwith respect to the number of input visual tokens, enabling adaptation to\nchallenging pruning scenarios. Extensive experiments show that MoB preserves\n96.4% of performance for LLaVA-1.5-7B using only 11.1% of the original visual\ntokens and accelerates LLaVA-Next-7B by 1.3-1.5$\\times$ with negligible\nperformance loss. Additionally, evaluations on Qwen2-VL and Video-LLaVA confirm\nthat MoB integrates seamlessly into advanced MLLMs and diverse vision-language\ntasks."}
{"id": "2505.09969", "pdf": "https://arxiv.org/pdf/2505.09969", "abs": "https://arxiv.org/abs/2505.09969", "authors": ["Ali Azimi Lamir", "Shiva Razzagzadeh", "Zeynab Rezaei"], "title": "A Comprehensive Machine Learning Framework for Heart Disease Prediction: Performance Evaluation and Future Perspectives", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This study presents a machine learning-based framework for heart disease\nprediction using the heart-disease dataset, comprising 303 samples with 14\nfeatures. The methodology involves data preprocessing, model training, and\nevaluation using three classifiers: Logistic Regression, K-Nearest Neighbors\n(KNN), and Random Forest. Hyperparameter tuning with GridSearchCV and\nRandomizedSearchCV was employed to enhance model performance. The Random Forest\nclassifier outperformed other models, achieving an accuracy of 91% and an\nF1-score of 0.89. Evaluation metrics, including precision, recall, and\nconfusion matrix, revealed balanced performance across classes. The proposed\nmodel demonstrates strong potential for aiding clinical decision-making by\neffectively predicting heart disease. Limitations such as dataset size and\ngeneralizability underscore the need for future studies using larger and more\ndiverse datasets. This work highlights the utility of machine learning in\nhealthcare, offering insights for further advancements in predictive\ndiagnostics."}
{"id": "2505.10453", "pdf": "https://arxiv.org/pdf/2505.10453", "abs": "https://arxiv.org/abs/2505.10453", "authors": ["Tyler Tran", "Sangeet Khemlani", "J. G. Trafton"], "title": "Vision language models have difficulty recognizing virtual objects", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision language models (VLMs) are AI systems paired with both language and\nvision encoders to process multimodal input. They are capable of performing\ncomplex semantic tasks such as automatic captioning, but it remains an open\nquestion about how well they comprehend the visuospatial properties of scenes\ndepicted in the images they process. We argue that descriptions of virtual\nobjects -- objects that are not visually represented in an image -- can help\ntest scene comprehension in these AI systems. For example, an image that\ndepicts a person standing under a tree can be paired with the following prompt:\nimagine that a kite is stuck in the tree. VLMs that comprehend the scene should\nupdate their representations and reason sensibly about the spatial relations\nbetween all three objects. We describe systematic evaluations of\nstate-of-the-art VLMs and show that their ability to process virtual objects is\ninadequate."}
{"id": "2505.10147", "pdf": "https://arxiv.org/pdf/2505.10147", "abs": "https://arxiv.org/abs/2505.10147", "authors": ["Yash", "Nikhil Karamchandani", "Avishek Ghosh"], "title": "Near Optimal Best Arm Identification for Clustered Bandits", "categories": ["cs.LG", "cs.MA"], "comment": "To be published in ICML 2025", "summary": "This work investigates the problem of best arm identification for multi-agent\nmulti-armed bandits. We consider $N$ agents grouped into $M$ clusters, where\neach cluster solves a stochastic bandit problem. The mapping between agents and\nbandits is a priori unknown. Each bandit is associated with $K$ arms, and the\ngoal is to identify the best arm for each agent under a $\\delta$-probably\ncorrect ($\\delta$-PC) framework, while minimizing sample complexity and\ncommunication overhead.\n  We propose two novel algorithms: Clustering then Best Arm Identification\n(Cl-BAI) and Best Arm Identification then Clustering (BAI-Cl). Cl-BAI uses a\ntwo-phase approach that first clusters agents based on the bandit problems they\nare learning, followed by identifying the best arm for each cluster. BAI-Cl\nreverses the sequence by identifying the best arms first and then clustering\nagents accordingly. Both algorithms leverage the successive elimination\nframework to ensure computational efficiency and high accuracy.\n  We establish $\\delta$-PC guarantees for both methods, derive bounds on their\nsample complexity, and provide a lower bound for this problem class. Moreover,\nwhen $M$ is small (a constant), we show that the sample complexity of a variant\nof BAI-Cl is minimax optimal in an order-wise sense. Experiments on synthetic\nand real-world datasets (MovieLens, Yelp) demonstrate the superior performance\nof the proposed algorithms in terms of sample and communication efficiency,\nparticularly in settings where $M \\ll N$."}
{"id": "2505.10222", "pdf": "https://arxiv.org/pdf/2505.10222", "abs": "https://arxiv.org/abs/2505.10222", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "Beiwen Zhang", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "ComplexFormer: Disruptively Advancing Transformer Inference Ability via Head-Specific Complex Vector Attention", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Transformer models rely on self-attention to capture token dependencies but\nface challenges in effectively integrating positional information while\nallowing multi-head attention (MHA) flexibility. Prior methods often model\nsemantic and positional differences disparately or apply uniform positional\nadjustments across heads, potentially limiting representational capacity. This\npaper introduces ComplexFormer, featuring Complex Multi-Head Attention-CMHA.\nCMHA empowers each head to independently model semantic and positional\ndifferences unified within the complex plane, representing interactions as\nrotations and scaling. ComplexFormer incorporates two key improvements: (1) a\nper-head Euler transformation, converting real-valued query/key projections\ninto polar-form complex vectors for head-specific complex subspace operation;\nand (2) a per-head adaptive differential rotation mechanism,\nexp[i(Adapt(ASmn,i) + Delta(Pmn),i)], allowing each head to learn distinct\nstrategies for integrating semantic angle differences (ASmn,i) with relative\npositional encodings (Delta(Pmn),i). Extensive experiments on language\nmodeling, text generation, code generation, and mathematical reasoning show\nComplexFormer achieves superior performance, significantly lower generation\nperplexity , and improved long-context coherence compared to strong baselines\nlike RoPE-Transformers. ComplexFormer demonstrates strong parameter efficiency,\noffering a more expressive, adaptable attention mechanism."}
{"id": "2505.10016", "pdf": "https://arxiv.org/pdf/2505.10016", "abs": "https://arxiv.org/abs/2505.10016", "authors": ["Shijie Lyu"], "title": "Application of YOLOv8 in monocular downward multiple Car Target detection", "categories": ["cs.CV", "cs.AI", "I.4.8; I.2.10"], "comment": "Accepted by the 5th International Conference on Signal Processing and\n  Machine Learning (CONF-SPML 2025), to appear in Applied and Computational\n  Engineering", "summary": "Autonomous driving technology is progressively transforming traditional car\ndriving methods, marking a significant milestone in modern transportation.\nObject detection serves as a cornerstone of autonomous systems, playing a vital\nrole in enhancing driving safety, enabling autonomous functionality, improving\ntraffic efficiency, and facilitating effective emergency responses. However,\ncurrent technologies such as radar for environmental perception, cameras for\nroad perception, and vehicle sensor networks face notable challenges, including\nhigh costs, vulnerability to weather and lighting conditions, and limited\nresolution.To address these limitations, this paper presents an improved\nautonomous target detection network based on YOLOv8. By integrating structural\nreparameterization technology, a bidirectional pyramid structure network model,\nand a novel detection pipeline into the YOLOv8 framework, the proposed approach\nachieves highly efficient and precise detection of multi-scale, small, and\nremote objects. Experimental results demonstrate that the enhanced model can\neffectively detect both large and small objects with a detection accuracy of\n65%, showcasing significant advancements over traditional methods.This improved\nmodel holds substantial potential for real-world applications and is\nwell-suited for autonomous driving competitions, such as the Formula Student\nAutonomous China (FSAC), particularly excelling in scenarios involving\nsingle-target and small-object detection."}
{"id": "2505.10473", "pdf": "https://arxiv.org/pdf/2505.10473", "abs": "https://arxiv.org/abs/2505.10473", "authors": ["Fengdi Zhang", "Hongkun Cao", "Ruqi Huang"], "title": "Consistent Quantity-Quality Control across Scenes for Deployment-Aware Gaussian Splatting", "categories": ["cs.CV"], "comment": null, "summary": "To reduce storage and computational costs, 3D Gaussian splatting (3DGS) seeks\nto minimize the number of Gaussians used while preserving high rendering\nquality, introducing an inherent trade-off between Gaussian quantity and\nrendering quality. Existing methods strive for better quantity-quality\nperformance, but lack the ability for users to intuitively adjust this\ntrade-off to suit practical needs such as model deployment under diverse\nhardware and communication constraints. Here, we present ControlGS, a 3DGS\noptimization method that achieves semantically meaningful and cross-scene\nconsistent quantity-quality control while maintaining strong quantity-quality\nperformance. Through a single training run using a fixed setup and a\nuser-specified hyperparameter reflecting quantity-quality preference, ControlGS\ncan automatically find desirable quantity-quality trade-off points across\ndiverse scenes, from compact objects to large outdoor scenes. It also\noutperforms baselines by achieving higher rendering quality with fewer\nGaussians, and supports a broad adjustment range with stepless control over the\ntrade-off."}
{"id": "2505.10167", "pdf": "https://arxiv.org/pdf/2505.10167", "abs": "https://arxiv.org/abs/2505.10167", "authors": ["Saikat Barua", "Mostafizur Rahman", "Shehenaz Khaled", "Md Jafor Sadek", "Rafiul Islam", "Shahnewaz Siddique"], "title": "QuXAI: Explainers for Hybrid Quantum Machine Learning Models", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": "16 pages, 6 figures, 7 equations", "summary": "The emergence of hybrid quantum-classical machine learning (HQML) models\nopens new horizons of computational intelligence but their fundamental\ncomplexity frequently leads to black box behavior that undermines transparency\nand reliability in their application. Although XAI for quantum systems still in\nits infancy, a major research gap is evident in robust global and local\nexplainability approaches that are designed for HQML architectures that employ\nquantized feature encoding followed by classical learning. The gap is the focus\nof this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an\nexplainer for explaining feature importance in these hybrid systems. Our model\nentails the creation of HQML models incorporating quantum feature maps, the use\nof Q-MEDLEY, which combines feature based inferences, preserving the quantum\ntransformation stage and visualizing the resulting attributions. Our result\nshows that Q-MEDLEY delineates influential classical aspects in HQML models, as\nwell as separates their noise, and competes well against established XAI\ntechniques in classical validation settings. Ablation studies more\nsignificantly expose the virtues of the composite structure used in Q-MEDLEY.\nThe implications of this work are critically important, as it provides a route\nto improve the interpretability and reliability of HQML models, thus promoting\ngreater confidence and being able to engage in safer and more responsible use\nof quantum-enhanced AI technology."}
{"id": "2505.10231", "pdf": "https://arxiv.org/pdf/2505.10231", "abs": "https://arxiv.org/abs/2505.10231", "authors": ["Haozhe Luo", "Ziyu Zhou", "Zixin Shu", "Aurélie Pahud de Mortanges", "Robert Berke", "Mauricio Reyes"], "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner."}
{"id": "2505.10027", "pdf": "https://arxiv.org/pdf/2505.10027", "abs": "https://arxiv.org/abs/2505.10027", "authors": ["Shijie Lyu"], "title": "ORL-LDM: Offline Reinforcement Learning Guided Latent Diffusion Model Super-Resolution Reconstruction", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by the 4th International Conference on Computing Innovation\n  and Applied Physics (CONF-CIAP 2025), and will be published in EAI Community\n  Research Series-CORE or Theoretical and Natural Science (TNS)", "summary": "With the rapid advancement of remote sensing technology, super-resolution\nimage reconstruction is of great research and practical significance. Existing\ndeep learning methods have made progress but still face limitations in handling\ncomplex scenes and preserving image details. This paper proposes a\nreinforcement learning-based latent diffusion model (LDM) fine-tuning method\nfor remote sensing image super-resolution. The method constructs a\nreinforcement learning environment with states, actions, and rewards,\noptimizing decision objectives through proximal policy optimization (PPO)\nduring the reverse denoising process of the LDM model. Experiments on the\nRESISC45 dataset show significant improvements over the baseline model in PSNR,\nSSIM, and LPIPS, with PSNR increasing by 3-4dB, SSIM improving by 0.08-0.11,\nand LPIPS reducing by 0.06-0.10, particularly in structured and complex natural\nscenes. The results demonstrate the method's effectiveness in enhancing\nsuper-resolution quality and adaptability across scenes."}
{"id": "2505.10481", "pdf": "https://arxiv.org/pdf/2505.10481", "abs": "https://arxiv.org/abs/2505.10481", "authors": ["Ilya Ovodov", "Petr Surovtsev", "Karina Kvanchiani", "Alexander Kapitanov", "Alexander Nagaev"], "title": "Logos as a Well-Tempered Pre-train for Sign Language Recognition", "categories": ["cs.CV"], "comment": null, "summary": "This paper examines two aspects of the isolated sign language recognition\n(ISLR) task. First, despite the availability of a number of datasets, the\namount of data for most individual sign languages is limited. It poses the\nchallenge of cross-language ISLR model training, including transfer learning.\nSecond, similar signs can have different semantic meanings. It leads to\nambiguity in dataset labeling and raises the question of the best policy for\nannotating such signs. To address these issues, this study presents Logos, a\nnovel Russian Sign Language (RSL) dataset, the most extensive ISLR dataset by\nthe number of signers and one of the largest available datasets while also the\nlargest RSL dataset in size and vocabulary. It is shown that a model,\npre-trained on the Logos dataset can be used as a universal encoder for other\nlanguage SLR tasks, including few-shot learning. We explore cross-language\ntransfer learning approaches and find that joint training using multiple\nclassification heads benefits accuracy for the target lowresource datasets the\nmost. The key feature of the Logos dataset is explicitly annotated visually\nsimilar sign groups. We show that explicitly labeling visually similar signs\nimproves trained model quality as a visual encoder for downstream tasks. Based\non the proposed contributions, we outperform current state-of-the-art results\nfor the WLASL dataset and get competitive results for the AUTSL dataset, with a\nsingle stream model processing solely RGB video. The source code, dataset, and\npre-trained models are publicly available."}
{"id": "2505.10172", "pdf": "https://arxiv.org/pdf/2505.10172", "abs": "https://arxiv.org/abs/2505.10172", "authors": ["Zeyan Li", "Libing Chen", "Yin Tang"], "title": "Does Scaling Law Apply in Time Series Forecasting?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Rapid expansion of model size has emerged as a key challenge in time series\nforecasting. From early Transformer with tens of megabytes to recent\narchitectures like TimesNet with thousands of megabytes, performance gains have\noften come at the cost of exponentially increasing parameter counts. But is\nthis scaling truly necessary? To question the applicability of the scaling law\nin time series forecasting, we propose Alinear, an ultra-lightweight\nforecasting model that achieves competitive performance using only k-level\nparameters. We introduce a horizon-aware adaptive decomposition mechanism that\ndynamically rebalances component emphasis across different forecast lengths,\nalongside a progressive frequency attenuation strategy that achieves stable\nprediction in various forecasting horizons without incurring the computational\noverhead of attention mechanisms. Extensive experiments on seven benchmark\ndatasets demonstrate that Alinear consistently outperforms large-scale models\nwhile using less than 1% of their parameters, maintaining strong accuracy\nacross both short and ultra-long forecasting horizons. Moreover, to more fairly\nevaluate model efficiency, we propose a new parameter-aware evaluation metric\nthat highlights the superiority of ALinear under constrained model budgets. Our\nanalysis reveals that the relative importance of trend and seasonal components\nvaries depending on data characteristics rather than following a fixed pattern,\nvalidating the necessity of our adaptive design. This work challenges the\nprevailing belief that larger models are inherently better and suggests a\nparadigm shift toward more efficient time series modeling."}
{"id": "2505.10292", "pdf": "https://arxiv.org/pdf/2505.10292", "abs": "https://arxiv.org/abs/2505.10292", "authors": ["Daniel A. P. Oliveira", "David Martins de Matos"], "title": "StoryReasoning Dataset: Using Chain-of-Thought for Scene Understanding and Grounded Story Generation", "categories": ["cs.CV", "cs.CL", "I.2.10; I.2.7"], "comment": "31 pages, 14 figures", "summary": "Visual storytelling systems struggle to maintain character identity across\nframes and link actions to appropriate subjects, frequently leading to\nreferential hallucinations. These issues can be addressed through grounding of\ncharacters, objects, and other entities on the visual elements. We propose\nStoryReasoning, a dataset containing 4,178 stories derived from 52,016 movie\nimages, with both structured scene analyses and grounded stories. Each story\nmaintains character and object consistency across frames while explicitly\nmodeling multi-frame relationships through structured tabular representations.\nOur approach features cross-frame object re-identification using visual\nsimilarity and face recognition, chain-of-thought reasoning for explicit\nnarrative modeling, and a grounding scheme that links textual elements to\nvisual entities across multiple frames. We establish baseline performance by\nfine-tuning Qwen2.5-VL 7B, creating Qwen Storyteller, which performs end-to-end\nobject detection, re-identification, and landmark detection while maintaining\nconsistent object references throughout the story. Evaluation demonstrates a\nreduction from 4.06 to 3.56 (-12.3%) hallucinations on average per story when\ncompared to a non-fine-tuned model."}
{"id": "2505.10037", "pdf": "https://arxiv.org/pdf/2505.10037", "abs": "https://arxiv.org/abs/2505.10037", "authors": ["Takafumi Ito", "Lysenko Artem", "Tatsuhiko Tsunoda"], "title": "Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction", "categories": ["cs.LG", "cs.AI", "cs.ET", "quant-ph"], "comment": "10 pages, 3 figures", "summary": "Quantum-classical Hybrid Machine Learning (QHML) models are recognized for\ntheir robust performance and high generalization ability even for relatively\nsmall datasets. These qualities offer unique advantages for anti-cancer drug\nresponse prediction, where the number of available samples is typically small.\nHowever, such hybrid models appear to be very sensitive to the data encoding\nused at the interface of a neural network and a quantum circuit, with\nsuboptimal choices leading to stability issues. To address this problem, we\npropose a novel strategy that uses a normalization function based on a\nmoderated gradient version of the $\\tanh$. This method transforms the outputs\nof the neural networks without concentrating them at the extreme value ranges.\nOur idea was evaluated on a dataset of gene expression and drug response\nmeasurements for various cancer cell lines, where we compared the prediction\nperformance of a classical deep learning model and several QHML models. These\nresults confirmed that QHML performed better than the classical models when\ndata was optimally normalized. This study opens up new possibilities for\nbiomedical data analysis using quantum computers."}
{"id": "2505.10483", "pdf": "https://arxiv.org/pdf/2505.10483", "abs": "https://arxiv.org/abs/2505.10483", "authors": ["Yi Li", "Haonan Wang", "Qixiang Zhang", "Boyu Xiao", "Chenchang Hu", "Hualiang Wang", "Xiaomeng Li"], "title": "UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation", "categories": ["cs.CV", "cs.AI"], "comment": "UniEval is the first evaluation framework designed for unified\n  multimodal models, including a holistic benchmark UniBench and the UniScore\n  metric", "summary": "The emergence of unified multimodal understanding and generation models is\nrapidly attracting attention because of their ability to enhance\ninstruction-following capabilities while minimizing model redundancy. However,\nthere is a lack of a unified evaluation framework for these models, which would\nenable an elegant, simplified, and overall evaluation. Current models conduct\nevaluations on multiple task-specific benchmarks, but there are significant\nlimitations, such as the lack of overall results, errors from extra evaluation\nmodels, reliance on extensive labeled images, benchmarks that lack diversity,\nand metrics with limited capacity for instruction-following evaluation. To\ntackle these challenges, we introduce UniEval, the first evaluation framework\ndesigned for unified multimodal models without extra models, images, or\nannotations. This facilitates a simplified and unified evaluation process. The\nUniEval framework contains a holistic benchmark, UniBench (supports both\nunified and visual generation models), along with the corresponding UniScore\nmetric. UniBench includes 81 fine-grained tags contributing to high diversity.\nExperimental results indicate that UniBench is more challenging than existing\nbenchmarks, and UniScore aligns closely with human evaluations, surpassing\ncurrent metrics. Moreover, we extensively evaluated SoTA unified and visual\ngeneration models, uncovering new insights into Univeral's unique values."}
{"id": "2505.10192", "pdf": "https://arxiv.org/pdf/2505.10192", "abs": "https://arxiv.org/abs/2505.10192", "authors": ["Prashant P. Shinde", "Priyadarshini P. Pai", "Shashishekar P. Adiga", "K. Subramanya Mayya", "Yongbeom Seo", "Myungsoo Hwang", "Heeyoung Go", "Changmin Park"], "title": "Defect Detection in Photolithographic Patterns Using Deep Learning Models Trained on Synthetic Data", "categories": ["cs.LG"], "comment": null, "summary": "In the photolithographic process vital to semiconductor manufacturing,\nvarious types of defects appear during EUV pattering. Due to ever-shrinking\npattern size, these defects are extremely small and cause false or missed\ndetection during inspection. Specifically, the lack of defect-annotated quality\ndata with good representation of smaller defects has prohibited deployment of\ndeep learning based defect detection models in fabrication lines. To resolve\nthe problem of data unavailability, we artificially generate scanning electron\nmicroscopy (SEM) images of line patterns with known distribution of defects and\nautonomously annotate them. We then employ state-of-the-art object detection\nmodels to investigate defect detection performance as a function of defect\nsize, much smaller than the pitch width. We find that the real-time object\ndetector YOLOv8 has the best mean average precision of 96% as compared to\nEfficientNet, 83%, and SSD, 77%, with the ability to detect smaller defects. We\nreport the smallest defect size that can be detected reliably. When tested on\nreal SEM data, the YOLOv8 model correctly detected 84.6% of Bridge defects and\n78.3% of Break defects across all relevant instances. These promising results\nsuggest that synthetic data can be used as an alternative to real-world data in\norder to develop robust machine-learning models."}
{"id": "2505.10465", "pdf": "https://arxiv.org/pdf/2505.10465", "abs": "https://arxiv.org/abs/2505.10465", "authors": ["Yizhou liu", "Ziming Liu", "Jeff Gore"], "title": "Superposition Yields Robust Neural Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages, 23 figures", "summary": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters."}
{"id": "2505.10050", "pdf": "https://arxiv.org/pdf/2505.10050", "abs": "https://arxiv.org/abs/2505.10050", "authors": ["Fahad Almalki", "Mehedi Masud"], "title": "Financial Fraud Detection Using Explainable AI and Stacking Ensemble Methods", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Traditional machine learning models often prioritize predictive accuracy,\noften at the expense of model transparency and interpretability. The lack of\ntransparency makes it difficult for organizations to comply with regulatory\nrequirements and gain stakeholders trust. In this research, we propose a fraud\ndetection framework that combines a stacking ensemble of well-known gradient\nboosting models: XGBoost, LightGBM, and CatBoost. In addition, explainable\nartificial intelligence (XAI) techniques are used to enhance the transparency\nand interpretability of the model's decisions. We used SHAP (SHapley Additive\nExplanations) for feature selection to identify the most important features.\nFurther efforts were made to explain the model's predictions using Local\nInterpretable Model-Agnostic Explanation (LIME), Partial Dependence Plots\n(PDP), and Permutation Feature Importance (PFI). The IEEE-CIS Fraud Detection\ndataset, which includes more than 590,000 real transaction records, was used to\nevaluate the proposed model. The model achieved a high performance with an\naccuracy of 99% and an AUC-ROC score of 0.99, outperforming several recent\nrelated approaches. These results indicate that combining high prediction\naccuracy with transparent interpretability is possible and could lead to a more\nethical and trustworthy solution in financial fraud detection."}
{"id": "2505.10496", "pdf": "https://arxiv.org/pdf/2505.10496", "abs": "https://arxiv.org/abs/2505.10496", "authors": ["Raman Dutt", "Pedro Sanchez", "Yongchen Yao", "Steven McDonagh", "Sotirios A. Tsaftaris", "Timothy Hospedales"], "title": "CheXGenBench: A Unified Benchmark For Fidelity, Privacy and Utility of Synthetic Chest Radiographs", "categories": ["cs.CV"], "comment": null, "summary": "We introduce CheXGenBench, a rigorous and multifaceted evaluation framework\nfor synthetic chest radiograph generation that simultaneously assesses\nfidelity, privacy risks, and clinical utility across state-of-the-art\ntext-to-image generative models. Despite rapid advancements in generative AI\nfor real-world imagery, medical domain evaluations have been hindered by\nmethodological inconsistencies, outdated architectural comparisons, and\ndisconnected assessment criteria that rarely address the practical clinical\nvalue of synthetic samples. CheXGenBench overcomes these limitations through\nstandardised data partitioning and a unified evaluation protocol comprising\nover 20 quantitative metrics that systematically analyse generation quality,\npotential privacy vulnerabilities, and downstream clinical applicability across\n11 leading text-to-image architectures. Our results reveal critical\ninefficiencies in the existing evaluation protocols, particularly in assessing\ngenerative fidelity, leading to inconsistent and uninformative comparisons. Our\nframework establishes a standardised benchmark for the medical AI community,\nenabling objective and reproducible comparisons while facilitating seamless\nintegration of both existing and future generative models. Additionally, we\nrelease a high-quality, synthetic dataset, SynthCheX-75K, comprising 75K\nradiographs generated by the top-performing model (Sana 0.6B) in our benchmark\nto support further research in this critical domain. Through CheXGenBench, we\nestablish a new state-of-the-art and release our framework, models, and\nSynthCheX-75K dataset at https://raman1121.github.io/CheXGenBench/"}
{"id": "2505.10198", "pdf": "https://arxiv.org/pdf/2505.10198", "abs": "https://arxiv.org/abs/2505.10198", "authors": ["Mariano Ferrero", "José Omar Chelotti", "Luciano Sebastián Martinez-Rau", "Leandro Vignolo", "Martín Pires", "Julio Ricardo Galli", "Leonardo Luis Giovanini", "Hugo Leonardo Rufiner"], "title": "A multi-head deep fusion model for recognition of cattle foraging events using sound and movement signals", "categories": ["cs.LG"], "comment": "Preprint submitted to Engineering Applications of Artificial\n  Intelligence", "summary": "Monitoring feeding behaviour is a relevant task for efficient herd management\nand the effective use of available resources in grazing cattle. The ability to\nautomatically recognise animals' feeding activities through the identification\nof specific jaw movements allows for the improvement of diet formulation, as\nwell as early detection of metabolic problems and symptoms of animal\ndiscomfort, among other benefits. The use of sensors to obtain signals for such\nmonitoring has become popular in the last two decades. The most frequently\nemployed sensors include accelerometers, microphones, and cameras, each with\nits own set of advantages and drawbacks. An unexplored aspect is the\nsimultaneous use of multiple sensors with the aim of combining signals in order\nto enhance the precision of the estimations. In this direction, this work\nintroduces a deep neural network based on the fusion of acoustic and inertial\nsignals, composed of convolutional, recurrent, and dense layers. The main\nadvantage of this model is the combination of signals through the automatic\nextraction of features independently from each of them. The model has emerged\nfrom an exploration and comparison of different neural network architectures\nproposed in this work, which carry out information fusion at different levels.\nFeature-level fusion has outperformed data and decision-level fusion by at\nleast a 0.14 based on the F1-score metric. Moreover, a comparison with\nstate-of-the-art machine learning methods is presented, including traditional\nand deep learning approaches. The proposed model yielded an F1-score value of\n0.802, representing a 14% increase compared to previous methods. Finally,\nresults from an ablation study and post-training quantization evaluation are\nalso reported."}
{"id": "2505.10475", "pdf": "https://arxiv.org/pdf/2505.10475", "abs": "https://arxiv.org/abs/2505.10475", "authors": ["Mouxiang Chen", "Binyuan Hui", "Zeyu Cui", "Jiaxi Yang", "Dayiheng Liu", "Jianling Sun", "Junyang Lin", "Zhongxin Liu"], "title": "Parallel Scaling Law for Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "It is commonly believed that scaling language models should commit a\nsignificant space or time cost, by increasing the parameters (parameter\nscaling) or output tokens (inference-time scaling). We introduce the third and\nmore inference-efficient scaling paradigm: increasing the model's parallel\ncomputation during both training and inference time. We apply $P$ diverse and\nlearnable transformations to the input, execute forward passes of the model in\nparallel, and dynamically aggregate the $P$ outputs. This method, namely\nparallel scaling (ParScale), scales parallel computation by reusing existing\nparameters and can be applied to any model structure, optimization procedure,\ndata, or task. We theoretically propose a new scaling law and validate it\nthrough large-scale pre-training, which shows that a model with $P$ parallel\nstreams is similar to scaling the parameters by $O(\\log P)$ while showing\nsuperior inference efficiency. For example, ParScale can use up to 22$\\times$\nless memory increase and 6$\\times$ less latency increase compared to parameter\nscaling that achieves the same performance improvement. It can also recycle an\noff-the-shelf pre-trained model into a parallelly scaled one by post-training\non a small amount of tokens, further reducing the training budget. The new\nscaling law we discovered potentially facilitates the deployment of more\npowerful models in low-resource scenarios, and provides an alternative\nperspective for the role of computation in machine learning."}
{"id": "2505.10055", "pdf": "https://arxiv.org/pdf/2505.10055", "abs": "https://arxiv.org/abs/2505.10055", "authors": ["Ijazul Haq", "Yingjie Zhang", "Irfan Ali Khan"], "title": "PsOCR: Benchmarking Large Multimodal Models for Optical Character Recognition in Low-resource Pashto Language", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "This paper evaluates the performance of Large Multimodal Models (LMMs) on\nOptical Character Recognition (OCR) in the low-resource Pashto language.\nNatural Language Processing (NLP) in Pashto faces several challenges due to the\ncursive nature of its script and a scarcity of structured datasets. To address\nthis, we developed a synthetic Pashto OCR dataset, PsOCR, consisting of one\nmillion images annotated with bounding boxes at word, line, and document\nlevels, suitable for training and evaluating models based on different\narchitectures, including Convolutional Neural Networks (CNNs) and Transformers.\nPsOCR covers variations across 1,000 unique font families, colors, image sizes,\nand layouts. A benchmark subset of 10K images was selected to evaluate the\nperformance of several LMMs, including seven open-source models: DeepSeek's\nJanus, InternVL, MiniCPM, Florence, and Qwen (3B and 7B), and four\nclosed-source models: GPT-4o, Gemini, Claude, and Grok. Experimental results\ndemonstrate that Gemini achieves the best performance among all models, whereas\namong open-source models, Qwen-7B stands out. This work provides an insightful\nassessment of the capabilities and limitations of current LMMs for OCR tasks in\nPashto and establishes a foundation for further research not only in Pashto OCR\nbut also for other similar scripts such as Arabic, Persian, and Urdu. PsOCR is\navailable at https://github.com/zirak-ai/PashtoOCR."}
{"id": "2505.10497", "pdf": "https://arxiv.org/pdf/2505.10497", "abs": "https://arxiv.org/abs/2505.10497", "authors": ["Iurii Medvedev", "Nuno Goncalves"], "title": "MorphGuard: Morph Specific Margin Loss for Enhancing Robustness to Face Morphing Attacks", "categories": ["cs.CV"], "comment": null, "summary": "Face recognition has evolved significantly with the advancement of deep\nlearning techniques, enabling its widespread adoption in various applications\nrequiring secure authentication. However, this progress has also increased its\nexposure to presentation attacks, including face morphing, which poses a\nserious security threat by allowing one identity to impersonate another.\nTherefore, modern face recognition systems must be robust against such attacks.\n  In this work, we propose a novel approach for training deep networks for face\nrecognition with enhanced robustness to face morphing attacks. Our method\nmodifies the classification task by introducing a dual-branch classification\nstrategy that effectively handles the ambiguity in the labeling of face morphs.\nThis adaptation allows the model to incorporate morph images into the training\nprocess, improving its ability to distinguish them from bona fide samples.\n  Our strategy has been validated on public benchmarks, demonstrating its\neffectiveness in enhancing robustness against face morphing attacks.\nFurthermore, our approach is universally applicable and can be integrated into\nexisting face recognition training pipelines to improve classification-based\nrecognition methods."}
{"id": "2505.10213", "pdf": "https://arxiv.org/pdf/2505.10213", "abs": "https://arxiv.org/abs/2505.10213", "authors": ["Mohammadmahdi Ghasemloo", "Alireza Moradi"], "title": "Informed Forecasting: Leveraging Auxiliary Knowledge to Boost LLM Performance on Time Series Forecasting", "categories": ["cs.LG", "stat.AP"], "comment": null, "summary": "With the widespread adoption of Large Language Models (LLMs), there is a\ngrowing need to establish best practices for leveraging their capabilities\nbeyond traditional natural language tasks. In this paper, a novel cross-domain\nknowledge transfer framework is proposed to enhance the performance of LLMs in\ntime series forecasting -- a task of increasing relevance in fields such as\nenergy systems, finance, and healthcare. The approach systematically infuses\nLLMs with structured temporal information to improve their forecasting\naccuracy. This study evaluates the proposed method on a real-world time series\ndataset and compares it to a naive baseline where the LLM receives no auxiliary\ninformation. Results show that knowledge-informed forecasting significantly\noutperforms the uninformed baseline in terms of predictive accuracy and\ngeneralization. These findings highlight the potential of knowledge transfer\nstrategies to bridge the gap between LLMs and domain-specific forecasting\ntasks."}
{"id": "2505.10495", "pdf": "https://arxiv.org/pdf/2505.10495", "abs": "https://arxiv.org/abs/2505.10495", "authors": ["Vibha Belavadi", "Tushar Vatsa", "Dewang Sultania", "Suhas Suresha", "Ishita Verma", "Cheng Chen", "Tracy Holloway King", "Michael Friedrich"], "title": "RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs", "categories": ["cs.LG", "cs.CL"], "comment": "Proceedings of the 4th International Workshop on Knowledge-Augmented\n  Methods for Natural Language Processing", "summary": "This paper addresses fine-tuning Large Language Models (LLMs) for function\ncalling tasks when real user interaction data is unavailable. In digital\ncontent creation tools, where users express their needs through natural\nlanguage queries that must be mapped to API calls, the lack of real-world\ntask-specific data and privacy constraints for training on it necessitate\nsynthetic data generation. Existing approaches to synthetic data generation\nfall short in diversity and complexity, failing to replicate real-world data\ndistributions and leading to suboptimal performance after LLM fine-tuning. We\npresent a novel router-based architecture that leverages domain resources like\ncontent metadata and structured knowledge graphs, along with text-to-text and\nvision-to-text language models to generate high-quality synthetic training\ndata. Our architecture's flexible routing mechanism enables synthetic data\ngeneration that matches observed real-world distributions, addressing a\nfundamental limitation of traditional approaches. Evaluation on a comprehensive\nset of real user queries demonstrates significant improvements in both function\nclassification accuracy and API parameter selection. Models fine-tuned with our\nsynthetic data consistently outperform traditional approaches, establishing new\nbenchmarks for function calling tasks."}
{"id": "2505.10066", "pdf": "https://arxiv.org/pdf/2505.10066", "abs": "https://arxiv.org/abs/2505.10066", "authors": ["Michael Fire", "Yitzhak Elbazis", "Adi Wasenstein", "Lior Rokach"], "title": "Dark LLMs: The Growing Threat of Unaligned AI Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50, 68T05, 68P25", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated."}
{"id": "2505.10533", "pdf": "https://arxiv.org/pdf/2505.10533", "abs": "https://arxiv.org/abs/2505.10533", "authors": ["Aaryan Sharma", "Shivansh Gupta", "Samar Agarwal", "Vishak Prasad C.", "Ganesh Ramakrishnan"], "title": "Enhancing Multi-Image Question Answering via Submodular Subset Selection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Large multimodal models (LMMs) have achieved high performance in\nvision-language tasks involving single image but they struggle when presented\nwith a collection of multiple images (Multiple Image Question Answering\nscenario). These tasks, which involve reasoning over large number of images,\npresent issues in scalability (with increasing number of images) and retrieval\nperformance. In this work, we propose an enhancement for retriever framework\nintroduced in MIRAGE model using submodular subset selection techniques. Our\nmethod leverages query-aware submodular functions, such as GraphCut, to\npre-select a subset of semantically relevant images before main retrieval\ncomponent. We demonstrate that using anchor-based queries and augmenting the\ndata improves submodular-retriever pipeline effectiveness, particularly in\nlarge haystack sizes."}
{"id": "2505.10222", "pdf": "https://arxiv.org/pdf/2505.10222", "abs": "https://arxiv.org/abs/2505.10222", "authors": ["Jintian Shao", "Hongyi Huang", "Jiayi Wu", "Beiwen Zhang", "ZhiYu Wu", "You Shan", "MingKai Zheng"], "title": "ComplexFormer: Disruptively Advancing Transformer Inference Ability via Head-Specific Complex Vector Attention", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Transformer models rely on self-attention to capture token dependencies but\nface challenges in effectively integrating positional information while\nallowing multi-head attention (MHA) flexibility. Prior methods often model\nsemantic and positional differences disparately or apply uniform positional\nadjustments across heads, potentially limiting representational capacity. This\npaper introduces ComplexFormer, featuring Complex Multi-Head Attention-CMHA.\nCMHA empowers each head to independently model semantic and positional\ndifferences unified within the complex plane, representing interactions as\nrotations and scaling. ComplexFormer incorporates two key improvements: (1) a\nper-head Euler transformation, converting real-valued query/key projections\ninto polar-form complex vectors for head-specific complex subspace operation;\nand (2) a per-head adaptive differential rotation mechanism,\nexp[i(Adapt(ASmn,i) + Delta(Pmn),i)], allowing each head to learn distinct\nstrategies for integrating semantic angle differences (ASmn,i) with relative\npositional encodings (Delta(Pmn),i). Extensive experiments on language\nmodeling, text generation, code generation, and mathematical reasoning show\nComplexFormer achieves superior performance, significantly lower generation\nperplexity , and improved long-context coherence compared to strong baselines\nlike RoPE-Transformers. ComplexFormer demonstrates strong parameter efficiency,\noffering a more expressive, adaptable attention mechanism."}
{"id": "2505.10526", "pdf": "https://arxiv.org/pdf/2505.10526", "abs": "https://arxiv.org/abs/2505.10526", "authors": ["Mugilan Ganesan", "Shane Segal", "Ankur Aggarwal", "Nish Sinnadurai", "Sean Lie", "Vithursan Thangarasa"], "title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Main paper: 11 pp., 4 figs., 3 tabs.; Supplementary: 2 pp", "summary": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs."}
{"id": "2505.10120", "pdf": "https://arxiv.org/pdf/2505.10120", "abs": "https://arxiv.org/abs/2505.10120", "authors": ["Guillaume Godin"], "title": "All You Need Is Synthetic Task Augmentation", "categories": ["cs.LG", "cs.AI"], "comment": "14 pages, 3 Figures, 6 tables", "summary": "Injecting rule-based models like Random Forests into differentiable neural\nnetwork frameworks remains an open challenge in machine learning. Recent\nadvancements have demonstrated that pretrained models can generate efficient\nmolecular embeddings. However, these approaches often require extensive\npretraining and additional techniques, such as incorporating posterior\nprobabilities, to boost performance. In our study, we propose a novel strategy\nthat jointly trains a single Graph Transformer neural network on both sparse\nmultitask molecular property experimental targets and synthetic targets derived\nfrom XGBoost models trained on Osmordred molecular descriptors. These synthetic\ntasks serve as independent auxiliary tasks. Our results show consistent and\nsignificant performance improvement across all 19 molecular property prediction\ntasks. For 16 out of 19 targets, the multitask Graph Transformer outperforms\nthe XGBoost single-task learner. This demonstrates that synthetic task\naugmentation is an effective method for enhancing neural model performance in\nmultitask molecular property prediction without the need for feature injection\nor pretraining."}
{"id": "2505.10541", "pdf": "https://arxiv.org/pdf/2505.10541", "abs": "https://arxiv.org/abs/2505.10541", "authors": ["Pengfei Wang", "Guohai Xu", "Weinong Wang", "Junjie Yang", "Jie Lou", "Yunhua Xue"], "title": "Exploring Implicit Visual Misunderstandings in Multimodal Large Language Models through Attention Analysis", "categories": ["cs.CV"], "comment": null, "summary": "Recent advancements have enhanced the capability of Multimodal Large Language\nModels (MLLMs) to comprehend multi-image information. However, existing\nbenchmarks primarily evaluate answer correctness, overlooking whether models\ngenuinely comprehend the visual input. To address this, we define implicit\nvisual misunderstanding (IVM), where MLLMs provide correct answers without\nfully comprehending the visual input. Through our analysis, we decouple the\nvisual and textual modalities within the causal attention module, revealing\nthat attention distribution increasingly converges on the image associated with\nthe correct answer as the network layers deepen. This insight leads to the\nintroduction of a scale-agnostic metric, \\textit{attention accuracy}, and a\nnovel benchmark for quantifying IVMs. Attention accuracy directly evaluates the\nmodel's visual understanding via internal mechanisms, remaining robust to\npositional biases for more reliable assessments. Furthermore, we extend our\napproach to finer granularities and demonstrate its effectiveness in unimodal\nscenarios, underscoring its versatility and generalizability."}
{"id": "2505.10259", "pdf": "https://arxiv.org/pdf/2505.10259", "abs": "https://arxiv.org/abs/2505.10259", "authors": ["Xiangwen Zhuge", "Xu Shen", "Zeyu Wang", "Fan Dang", "Xuan Ding", "Danyang Li", "Yahui Han", "Tianxiang Hao", "Zheng Yang"], "title": "SpecOffload: Unlocking Latent GPU Capacity for LLM Inference on Resource-Constrained Devices", "categories": ["cs.LG"], "comment": null, "summary": "Efficient LLM inference on resource-constrained devices presents significant\nchallenges in compute and memory utilization. Due to limited GPU memory,\nexisting systems offload model weights to CPU memory, incurring substantial I/O\noverhead between the CPU and GPU. This leads to two major inefficiencies: (1)\nGPU cores are underutilized, often remaining idle while waiting for data to be\nloaded; and (2) GPU memory has low impact on performance, as reducing its\ncapacity has minimal effect on overall throughput.In this paper, we propose\nSpecOffload, a high-throughput inference engine that embeds speculative\ndecoding into offloading. Our key idea is to unlock latent GPU resources for\nstoring and executing a draft model used for speculative decoding, thus\naccelerating inference at near-zero additional cost. To support this, we\ncarefully orchestrate the interleaved execution of target and draft models in\nspeculative decoding within the offloading pipeline, and propose a planner to\nmanage tensor placement and select optimal parameters. Compared to the best\nbaseline, SpecOffload improves GPU core utilization by 4.49x and boosts\ninference throughput by 2.54x. Our code is available at\nhttps://github.com/MobiSense/SpecOffload ."}
{"id": "2505.10543", "pdf": "https://arxiv.org/pdf/2505.10543", "abs": "https://arxiv.org/abs/2505.10543", "authors": ["Annie Wong", "Thomas Bäck", "Aske Plaat", "Niki van Stein", "Anna V. Kononova"], "title": "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "While large language models demonstrate impressive performance on static\nbenchmarks, the true potential of large language models as self-learning and\nreasoning agents in dynamic environments remains unclear. This study\nsystematically evaluates the efficacy of self-reflection, heuristic mutation,\nand planning as prompting techniques to test the adaptive capabilities of\nagents. We conduct experiments with various open-source language models in\ndynamic environments and find that larger models generally outperform smaller\nones, but that strategic prompting can close this performance gap. Second, a\ntoo-long prompt can negatively impact smaller models on basic reactive tasks,\nwhile larger models show more robust behaviour. Third, advanced prompting\ntechniques primarily benefit smaller models on complex games, but offer less\nimprovement for already high-performing large language models. Yet, we find\nthat advanced reasoning methods yield highly variable outcomes: while capable\nof significantly improving performance when reasoning and decision-making\nalign, they also introduce instability and can lead to big performance drops.\nCompared to human performance, our findings reveal little evidence of true\nemergent reasoning. Instead, large language model performance exhibits\npersistent limitations in crucial areas such as planning, reasoning, and\nspatial coordination, suggesting that current-generation large language models\nstill suffer fundamental shortcomings that may not be fully overcome through\nself-reflective prompting alone. Reasoning is a multi-faceted task, and while\nreasoning methods like Chain of thought improves multi-step reasoning on math\nword problems, our findings using dynamic benchmarks highlight important\nshortcomings in general reasoning capabilities, indicating a need to move\nbeyond static benchmarks to capture the complexity of reasoning."}
{"id": "2505.10128", "pdf": "https://arxiv.org/pdf/2505.10128", "abs": "https://arxiv.org/abs/2505.10128", "authors": ["Huy Q. Le", "Latif U. Khan", "Choong Seon Hong"], "title": "Robust Federated Learning on Edge Devices with Domain Heterogeneity", "categories": ["cs.LG", "cs.AI"], "comment": "IWCMC 2025", "summary": "Federated Learning (FL) allows collaborative training while ensuring data\nprivacy across distributed edge devices, making it a popular solution for\nprivacy-sensitive applications. However, FL faces significant challenges due to\nstatistical heterogeneity, particularly domain heterogeneity, which impedes the\nglobal mode's convergence. In this study, we introduce a new framework to\naddress this challenge by improving the generalization ability of the FL global\nmodel under domain heterogeneity, using prototype augmentation. Specifically,\nwe introduce FedAPC (Federated Augmented Prototype Contrastive Learning), a\nprototype-based FL framework designed to enhance feature diversity and model\nrobustness. FedAPC leverages prototypes derived from the mean features of\naugmented data to capture richer representations. By aligning local features\nwith global prototypes, we enable the model to learn meaningful semantic\nfeatures while reducing overfitting to any specific domain. Experimental\nresults on the Office-10 and Digits datasets illustrate that our framework\noutperforms SOTA baselines, demonstrating superior performance."}
{"id": "2505.10551", "pdf": "https://arxiv.org/pdf/2505.10551", "abs": "https://arxiv.org/abs/2505.10551", "authors": ["Yiwen Liu", "Jessica Bader", "Jae Myung Kim"], "title": "Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data", "categories": ["cs.CV", "cs.AI"], "comment": "CVPRW 2025", "summary": "With the development of photorealistic diffusion models, models trained in\npart or fully on synthetic data achieve progressively better results. However,\ndiffusion models still routinely generate images that would not exist in\nreality, such as a dog floating above the ground or with unrealistic texture\nartifacts. We define the concept of feasibility as whether attributes in a\nsynthetic image could realistically exist in the real-world domain; synthetic\nimages containing attributes that violate this criterion are considered\ninfeasible. Intuitively, infeasible images are typically considered\nout-of-distribution; thus, training on such images is expected to hinder a\nmodel's ability to generalize to real-world data, and they should therefore be\nexcluded from the training set whenever possible. However, does feasibility\nreally matter? In this paper, we investigate whether enforcing feasibility is\nnecessary when generating synthetic training data for CLIP-based classifiers,\nfocusing on three target attributes: background, color, and texture. We\nintroduce VariReal, a pipeline that minimally edits a given source image to\ninclude feasible or infeasible attributes given by the textual prompt generated\nby a large language model. Our experiments show that feasibility minimally\naffects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference\nin top-1 accuracy across three fine-grained datasets. Also, the attribute\nmatters on whether the feasible/infeasible images adversarially influence the\nclassification performance. Finally, mixing feasible and infeasible images in\ntraining datasets does not significantly impact performance compared to using\npurely feasible or infeasible datasets."}
{"id": "2505.10262", "pdf": "https://arxiv.org/pdf/2505.10262", "abs": "https://arxiv.org/abs/2505.10262", "authors": ["Jiaju Qi", "Lei Lei", "Thorsteinn Jonsson", "Lajos Hanzo"], "title": "Electric Bus Charging Schedules Relying on Real Data-Driven Targets Based on Hierarchical Deep Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "The charging scheduling problem of Electric Buses (EBs) is investigated based\non Deep Reinforcement Learning (DRL). A Markov Decision Process (MDP) is\nconceived, where the time horizon includes multiple charging and operating\nperiods in a day, while each period is further divided into multiple time\nsteps. To overcome the challenge of long-range multi-phase planning with sparse\nreward, we conceive Hierarchical DRL (HDRL) for decoupling the original MDP\ninto a high-level Semi-MDP (SMDP) and multiple low-level MDPs. The Hierarchical\nDouble Deep Q-Network (HDDQN)-Hindsight Experience Replay (HER) algorithm is\nproposed for simultaneously solving the decision problems arising at different\ntemporal resolutions. As a result, the high-level agent learns an effective\npolicy for prescribing the charging targets for every charging period, while\nthe low-level agent learns an optimal policy for setting the charging power of\nevery time step within a single charging period, with the aim of minimizing the\ncharging costs while meeting the charging target. It is proved that the flat\npolicy constructed by superimposing the optimal high-level policy and the\noptimal low-level policy performs as well as the optimal policy of the original\nMDP. Since jointly learning both levels of policies is challenging due to the\nnon-stationarity of the high-level agent and the sampling inefficiency of the\nlow-level agent, we divide the joint learning process into two phases and\nexploit our new HER algorithm to manipulate the experience replay buffers for\nboth levels of agents. Numerical experiments are performed with the aid of\nreal-world data to evaluate the performance of the proposed algorithm."}
{"id": "2505.10557", "pdf": "https://arxiv.org/pdf/2505.10557", "abs": "https://arxiv.org/abs/2505.10557", "authors": ["Ke Wang", "Junting Pan", "Linda Wei", "Aojun Zhou", "Weikang Shi", "Zimu Lu", "Han Xiao", "Yunqiao Yang", "Houxing Ren", "Mingjie Zhan", "Hongsheng Li"], "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder."}
{"id": "2505.10167", "pdf": "https://arxiv.org/pdf/2505.10167", "abs": "https://arxiv.org/abs/2505.10167", "authors": ["Saikat Barua", "Mostafizur Rahman", "Shehenaz Khaled", "Md Jafor Sadek", "Rafiul Islam", "Shahnewaz Siddique"], "title": "QuXAI: Explainers for Hybrid Quantum Machine Learning Models", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": "16 pages, 6 figures, 7 equations", "summary": "The emergence of hybrid quantum-classical machine learning (HQML) models\nopens new horizons of computational intelligence but their fundamental\ncomplexity frequently leads to black box behavior that undermines transparency\nand reliability in their application. Although XAI for quantum systems still in\nits infancy, a major research gap is evident in robust global and local\nexplainability approaches that are designed for HQML architectures that employ\nquantized feature encoding followed by classical learning. The gap is the focus\nof this work, which introduces QuXAI, an framework based upon Q-MEDLEY, an\nexplainer for explaining feature importance in these hybrid systems. Our model\nentails the creation of HQML models incorporating quantum feature maps, the use\nof Q-MEDLEY, which combines feature based inferences, preserving the quantum\ntransformation stage and visualizing the resulting attributions. Our result\nshows that Q-MEDLEY delineates influential classical aspects in HQML models, as\nwell as separates their noise, and competes well against established XAI\ntechniques in classical validation settings. Ablation studies more\nsignificantly expose the virtues of the composite structure used in Q-MEDLEY.\nThe implications of this work are critically important, as it provides a route\nto improve the interpretability and reliability of HQML models, thus promoting\ngreater confidence and being able to engage in safer and more responsible use\nof quantum-enhanced AI technology."}
{"id": "2505.10557", "pdf": "https://arxiv.org/pdf/2505.10557", "abs": "https://arxiv.org/abs/2505.10557", "authors": ["Ke Wang", "Junting Pan", "Linda Wei", "Aojun Zhou", "Weikang Shi", "Zimu Lu", "Han Xiao", "Yunqiao Yang", "Houxing Ren", "Mingjie Zhan", "Hongsheng Li"], "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder."}
{"id": "2505.10264", "pdf": "https://arxiv.org/pdf/2505.10264", "abs": "https://arxiv.org/abs/2505.10264", "authors": ["Francesco Diana", "André Nusser", "Chuan Xu", "Giovanni Neglia"], "title": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated Learning (FL) enables collaborative training of machine learning\nmodels across distributed clients without sharing raw data, ostensibly\npreserving data privacy. Nevertheless, recent studies have revealed critical\nvulnerabilities in FL, showing that a malicious central server can manipulate\nmodel updates to reconstruct clients' private training data. Existing data\nreconstruction attacks have important limitations: they often rely on\nassumptions about the clients' data distribution or their efficiency\nsignificantly degrades when batch sizes exceed just a few tens of samples.\n  In this work, we introduce a novel data reconstruction attack that overcomes\nthese limitations. Our method leverages a new geometric perspective on fully\nconnected layers to craft malicious model parameters, enabling the perfect\nrecovery of arbitrarily large data batches in classification tasks without any\nprior knowledge of clients' data. Through extensive experiments on both image\nand tabular datasets, we demonstrate that our attack outperforms existing\nmethods and achieves perfect reconstruction of data batches two orders of\nmagnitude larger than the state of the art."}
{"id": "2505.10169", "pdf": "https://arxiv.org/pdf/2505.10169", "abs": "https://arxiv.org/abs/2505.10169", "authors": ["Matthias Kümmerer", "Harneet Khanuja", "Matthias Bethge"], "title": "Modeling Saliency Dataset Bias", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes."}
{"id": "2505.10562", "pdf": "https://arxiv.org/pdf/2505.10562", "abs": "https://arxiv.org/abs/2505.10562", "authors": ["Wenxuan Wang", "Fan Zhang", "Yufeng Cui", "Haiwen Diao", "Zhuoyan Luo", "Huchuan Lu", "Jing Liu", "Xinlong Wang"], "title": "End-to-End Vision Tokenizer Tuning", "categories": ["cs.CV"], "comment": null, "summary": "Existing vision tokenization isolates the optimization of vision tokenizers\nfrom downstream training, implicitly assuming the visual tokens can generalize\nwell across various tasks, e.g., image generation and visual question\nanswering. The vision tokenizer optimized for low-level reconstruction is\nagnostic to downstream tasks requiring varied representations and semantics.\nThis decoupled paradigm introduces a critical misalignment: The loss of the\nvision tokenization can be the representation bottleneck for target tasks. For\nexample, errors in tokenizing text in a given image lead to poor results when\nrecognizing or generating them. To address this, we propose ETT, an end-to-end\nvision tokenizer tuning approach that enables joint optimization between vision\ntokenization and target autoregressive tasks. Unlike prior autoregressive\nmodels that use only discrete indices from a frozen vision tokenizer, ETT\nleverages the visual embeddings of the tokenizer codebook, and optimizes the\nvision tokenizers end-to-end with both reconstruction and caption objectives.\nETT can be seamlessly integrated into existing training pipelines with minimal\narchitecture modifications. Our ETT is simple to implement and integrate,\nwithout the need to adjust the original codebooks or architectures of the\nemployed large language models. Extensive experiments demonstrate that our\nproposed end-to-end vision tokenizer tuning unlocks significant performance\ngains, i.e., 2-6% for multimodal understanding and visual generation tasks\ncompared to frozen tokenizer baselines, while preserving the original\nreconstruction capability. We hope this very simple and strong method can\nempower multimodal foundation models besides image generation and\nunderstanding."}
{"id": "2505.10271", "pdf": "https://arxiv.org/pdf/2505.10271", "abs": "https://arxiv.org/abs/2505.10271", "authors": ["Rafael Pablos Sarabia", "Joachim Nyborg", "Morten Birk", "Jeppe Liborius Sjørup", "Anders Lillevang Vesterholt", "Ira Assent"], "title": "RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We present a deep learning model for high-resolution probabilistic\nprecipitation forecasting over an 8-hour horizon in Europe, overcoming the\nlimitations of radar-only deep learning models with short forecast lead times.\nOur model efficiently integrates multiple data sources - including radar,\nsatellite, and physics-based numerical weather prediction (NWP) - while\ncapturing long-range interactions, resulting in accurate forecasts with robust\nuncertainty quantification through consistent probabilistic maps. Featuring a\ncompact architecture, it enables more efficient training and faster inference\nthan existing models. Extensive experiments demonstrate that our model\nsurpasses current operational NWP systems, extrapolation-based methods, and\ndeep-learning nowcasting models, setting a new standard for high-resolution\nprecipitation forecasting in Europe, ensuring a balance between accuracy,\ninterpretability, and computational efficiency."}
{"id": "2505.10172", "pdf": "https://arxiv.org/pdf/2505.10172", "abs": "https://arxiv.org/abs/2505.10172", "authors": ["Zeyan Li", "Libing Chen", "Yin Tang"], "title": "Does Scaling Law Apply in Time Series Forecasting?", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Rapid expansion of model size has emerged as a key challenge in time series\nforecasting. From early Transformer with tens of megabytes to recent\narchitectures like TimesNet with thousands of megabytes, performance gains have\noften come at the cost of exponentially increasing parameter counts. But is\nthis scaling truly necessary? To question the applicability of the scaling law\nin time series forecasting, we propose Alinear, an ultra-lightweight\nforecasting model that achieves competitive performance using only k-level\nparameters. We introduce a horizon-aware adaptive decomposition mechanism that\ndynamically rebalances component emphasis across different forecast lengths,\nalongside a progressive frequency attenuation strategy that achieves stable\nprediction in various forecasting horizons without incurring the computational\noverhead of attention mechanisms. Extensive experiments on seven benchmark\ndatasets demonstrate that Alinear consistently outperforms large-scale models\nwhile using less than 1% of their parameters, maintaining strong accuracy\nacross both short and ultra-long forecasting horizons. Moreover, to more fairly\nevaluate model efficiency, we propose a new parameter-aware evaluation metric\nthat highlights the superiority of ALinear under constrained model budgets. Our\nanalysis reveals that the relative importance of trend and seasonal components\nvaries depending on data characteristics rather than following a fixed pattern,\nvalidating the necessity of our adaptive design. This work challenges the\nprevailing belief that larger models are inherently better and suggests a\nparadigm shift toward more efficient time series modeling."}
{"id": "2505.10565", "pdf": "https://arxiv.org/pdf/2505.10565", "abs": "https://arxiv.org/abs/2505.10565", "authors": ["Zehan Wang", "Siyu Chen", "Lihe Yang", "Jialei Wang", "Ziang Zhang", "Hengshuang Zhao", "Zhou Zhao"], "title": "Depth Anything with Any Prior", "categories": ["cs.CV"], "comment": "Home page: https://prior-depth-anything.github.io/", "summary": "This work presents Prior Depth Anything, a framework that combines incomplete\nbut precise metric information in depth measurement with relative but complete\ngeometric structures in depth prediction, generating accurate, dense, and\ndetailed metric depth maps for any scene. To this end, we design a\ncoarse-to-fine pipeline to progressively integrate the two complementary depth\nsources. First, we introduce pixel-level metric alignment and distance-aware\nweighting to pre-fill diverse metric priors by explicitly using depth\nprediction. It effectively narrows the domain gap between prior patterns,\nenhancing generalization across varying scenarios. Second, we develop a\nconditioned monocular depth estimation (MDE) model to refine the inherent noise\nof depth priors. By conditioning on the normalized pre-filled prior and\nprediction, the model further implicitly merges the two complementary depth\nsources. Our model showcases impressive zero-shot generalization across depth\ncompletion, super-resolution, and inpainting over 7 real-world datasets,\nmatching or even surpassing previous task-specific methods. More importantly,\nit performs well on challenging, unseen mixed priors and enables test-time\nimprovements by switching prediction models, providing a flexible\naccuracy-efficiency trade-off while evolving with advancements in MDE models."}
{"id": "2505.10272", "pdf": "https://arxiv.org/pdf/2505.10272", "abs": "https://arxiv.org/abs/2505.10272", "authors": ["Niklas Dexheimer", "Sascha Gaudlitz", "Johannes Schmidt-Hieber"], "title": "Spike-timing-dependent Hebbian learning as noisy gradient descent", "categories": ["cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Hebbian learning is a key principle underlying learning in biological neural\nnetworks. It postulates that synaptic changes occur locally, depending on the\nactivities of pre- and postsynaptic neurons. While Hebbian learning based on\nneuronal firing rates is well explored, much less is known about learning rules\nthat account for precise spike-timing. We relate a Hebbian\nspike-timing-dependent plasticity rule to noisy gradient descent with respect\nto a natural loss function on the probability simplex. This connection allows\nus to prove that the learning rule eventually identifies the presynaptic neuron\nwith the highest activity. We also discover an intrinsic connection to noisy\nmirror descent."}
{"id": "2505.10185", "pdf": "https://arxiv.org/pdf/2505.10185", "abs": "https://arxiv.org/abs/2505.10185", "authors": ["Seongyun Lee", "Seungone Kim", "Minju Seo", "Yongrae Jo", "Dongyoung Go", "Hyeonbin Hwang", "Jinho Park", "Xiang Yue", "Sean Welleck", "Graham Neubig", "Moontae Lee", "Minjoon Seo"], "title": "The CoT Encyclopedia: Analyzing, Predicting, and Controlling how a Reasoning Model will Think", "categories": ["cs.CL", "cs.AI"], "comment": "Work in progress", "summary": "Long chain-of-thought (CoT) is an essential ingredient in effective usage of\nmodern large language models, but our understanding of the reasoning strategies\nunderlying these capabilities remains limited. While some prior works have\nattempted to categorize CoTs using predefined strategy types, such approaches\nare constrained by human intuition and fail to capture the full diversity of\nmodel behaviors. In this work, we introduce the CoT Encyclopedia, a bottom-up\nframework for analyzing and steering model reasoning. Our method automatically\nextracts diverse reasoning criteria from model-generated CoTs, embeds them into\na semantic space, clusters them into representative categories, and derives\ncontrastive rubrics to interpret reasoning behavior. Human evaluations show\nthat this framework produces more interpretable and comprehensive analyses than\nexisting methods. Moreover, we demonstrate that this understanding enables\nperformance gains: we can predict which strategy a model is likely to use and\nguide it toward more effective alternatives. Finally, we provide practical\ninsights, such as that training data format (e.g., free-form vs.\nmultiple-choice) has a far greater impact on reasoning behavior than data\ndomain, underscoring the importance of format-aware model design."}
{"id": "2505.10566", "pdf": "https://arxiv.org/pdf/2505.10566", "abs": "https://arxiv.org/abs/2505.10566", "authors": ["Yen-Chi Cheng", "Krishna Kumar Singh", "Jae Shin Yoon", "Alex Schwing", "Liangyan Gui", "Matheus Gadelha", "Paul Guerrero", "Nanxuan Zhao"], "title": "3D-Fixup: Advancing Photo Editing with 3D Priors", "categories": ["cs.CV"], "comment": "SIGGRAPH 2025. Project page: https://3dfixup.github.io/", "summary": "Despite significant advances in modeling image priors via diffusion models,\n3D-aware image editing remains challenging, in part because the object is only\nspecified via a single image. To tackle this challenge, we propose 3D-Fixup, a\nnew framework for editing 2D images guided by learned 3D priors. The framework\nsupports difficult editing situations such as object translation and 3D\nrotation. To achieve this, we leverage a training-based approach that harnesses\nthe generative power of diffusion models. As video data naturally encodes\nreal-world physical dynamics, we turn to video data for generating training\ndata pairs, i.e., a source and a target frame. Rather than relying solely on a\nsingle trained model to infer transformations between source and target frames,\nwe incorporate 3D guidance from an Image-to-3D model, which bridges this\nchallenging task by explicitly projecting 2D information into 3D space. We\ndesign a data generation pipeline to ensure high-quality 3D guidance throughout\ntraining. Results show that by integrating these 3D priors, 3D-Fixup\neffectively supports complex, identity coherent 3D-aware edits, achieving\nhigh-quality results and advancing the application of diffusion models in\nrealistic image manipulation. The code is provided at\nhttps://3dfixup.github.io/"}
{"id": "2505.10296", "pdf": "https://arxiv.org/pdf/2505.10296", "abs": "https://arxiv.org/abs/2505.10296", "authors": ["Jiaju Qi", "Lei Lei", "Thorsteinn Jonsson", "Dusit Niyato"], "title": "Optimizing Electric Bus Charging Scheduling with Uncertainties Using Hierarchical Deep Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "The growing adoption of Electric Buses (EBs) represents a significant step\ntoward sustainable development. By utilizing Internet of Things (IoT) systems,\ncharging stations can autonomously determine charging schedules based on\nreal-time data. However, optimizing EB charging schedules remains a critical\nchallenge due to uncertainties in travel time, energy consumption, and\nfluctuating electricity prices. Moreover, to address real-world complexities,\ncharging policies must make decisions efficiently across multiple time scales\nand remain scalable for large EB fleets. In this paper, we propose a\nHierarchical Deep Reinforcement Learning (HDRL) approach that reformulates the\noriginal Markov Decision Process (MDP) into two augmented MDPs. To solve these\nMDPs and enable multi-timescale decision-making, we introduce a novel HDRL\nalgorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization\nEnhancement (DAC-MAPPO-E). Scalability challenges of the Double Actor-Critic\n(DAC) algorithm for large-scale EB fleets are addressed through enhancements at\nboth decision levels. At the high level, we redesign the decentralized actor\nnetwork and integrate an attention mechanism to extract relevant global state\ninformation for each EB, decreasing the size of neural networks. At the low\nlevel, the Multi-Agent Proximal Policy Optimization (MAPPO) algorithm is\nincorporated into the DAC framework, enabling decentralized and coordinated\ncharging power decisions, reducing computational complexity and enhancing\nconvergence speed. Extensive experiments with real-world data demonstrate the\nsuperior performance and scalability of DAC-MAPPO-E in optimizing EB fleet\ncharging schedules."}
{"id": "2505.10231", "pdf": "https://arxiv.org/pdf/2505.10231", "abs": "https://arxiv.org/abs/2505.10231", "authors": ["Haozhe Luo", "Ziyu Zhou", "Zixin Shu", "Aurélie Pahud de Mortanges", "Robert Berke", "Mauricio Reyes"], "title": "On the Interplay of Human-AI Alignment,Fairness, and Performance Trade-offs in Medical Imaging", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Deep neural networks excel in medical imaging but remain prone to biases,\nleading to fairness gaps across demographic groups. We provide the first\nsystematic exploration of Human-AI alignment and fairness in this domain. Our\nresults show that incorporating human insights consistently reduces fairness\ngaps and enhances out-of-domain generalization, though excessive alignment can\nintroduce performance trade-offs, emphasizing the need for calibrated\nstrategies. These findings highlight Human-AI alignment as a promising approach\nfor developing fair, robust, and generalizable medical AI systems, striking a\nbalance between expert guidance and automated efficiency. Our code is available\nat https://github.com/Roypic/Aligner."}
{"id": "2505.10271", "pdf": "https://arxiv.org/pdf/2505.10271", "abs": "https://arxiv.org/abs/2505.10271", "authors": ["Rafael Pablos Sarabia", "Joachim Nyborg", "Morten Birk", "Jeppe Liborius Sjørup", "Anders Lillevang Vesterholt", "Ira Assent"], "title": "RainPro-8: An Efficient Deep Learning Model to Estimate Rainfall Probabilities Over 8 Hours", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We present a deep learning model for high-resolution probabilistic\nprecipitation forecasting over an 8-hour horizon in Europe, overcoming the\nlimitations of radar-only deep learning models with short forecast lead times.\nOur model efficiently integrates multiple data sources - including radar,\nsatellite, and physics-based numerical weather prediction (NWP) - while\ncapturing long-range interactions, resulting in accurate forecasts with robust\nuncertainty quantification through consistent probabilistic maps. Featuring a\ncompact architecture, it enables more efficient training and faster inference\nthan existing models. Extensive experiments demonstrate that our model\nsurpasses current operational NWP systems, extrapolation-based methods, and\ndeep-learning nowcasting models, setting a new standard for high-resolution\nprecipitation forecasting in Europe, ensuring a balance between accuracy,\ninterpretability, and computational efficiency."}
{"id": "2505.10297", "pdf": "https://arxiv.org/pdf/2505.10297", "abs": "https://arxiv.org/abs/2505.10297", "authors": ["Chibueze Peace Obioma", "Youcheng Sun", "Mustafa A. Mustafa"], "title": "Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Submitted to ESORICS 2025", "summary": "Federated learning (FL) enhances privacy and reduces communication cost for\nresource-constrained edge clients by supporting distributed model training at\nthe edge. However, the heterogeneous nature of such devices produces diverse,\nnon-independent, and identically distributed (non-IID) data, making the\ndetection of backdoor attacks more challenging. In this paper, we propose a\nnovel federated representative-attention-based defense mechanism, named FeRA,\nthat leverages cross-client attention over internal feature representations to\ndistinguish benign from malicious clients. FeRA computes an anomaly score based\non representation reconstruction errors, effectively identifying clients whose\ninternal activations significantly deviate from the group consensus. Our\nevaluation demonstrates FeRA's robustness across various FL scenarios,\nincluding challenging non-IID data distributions typical of edge devices.\nExperimental results show that it effectively reduces backdoor attack success\nrates while maintaining high accuracy on the main task. The method is\nmodel-agnostic, attack-agnostic, and does not require labeled reference data,\nmaking it well suited to heterogeneous and resource-limited edge deployments."}
{"id": "2505.10260", "pdf": "https://arxiv.org/pdf/2505.10260", "abs": "https://arxiv.org/abs/2505.10260", "authors": ["Poli Apollinaire Nemkova", "Solomon Ubani", "Mark V. Albert"], "title": "Comparing LLM Text Annotation Skills: A Study on Human Rights Violations in Social Media Data", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "In the era of increasingly sophisticated natural language processing (NLP)\nsystems, large language models (LLMs) have demonstrated remarkable potential\nfor diverse applications, including tasks requiring nuanced textual\nunderstanding and contextual reasoning. This study investigates the\ncapabilities of multiple state-of-the-art LLMs - GPT-3.5, GPT-4, LLAMA3,\nMistral 7B, and Claude-2 - for zero-shot and few-shot annotation of a complex\ntextual dataset comprising social media posts in Russian and Ukrainian.\nSpecifically, the focus is on the binary classification task of identifying\nreferences to human rights violations within the dataset.\n  To evaluate the effectiveness of these models, their annotations are compared\nagainst a gold standard set of human double-annotated labels across 1000\nsamples. The analysis includes assessing annotation performance under different\nprompting conditions, with prompts provided in both English and Russian.\nAdditionally, the study explores the unique patterns of errors and\ndisagreements exhibited by each model, offering insights into their strengths,\nlimitations, and cross-linguistic adaptability.\n  By juxtaposing LLM outputs with human annotations, this research contributes\nto understanding the reliability and applicability of LLMs for sensitive,\ndomain-specific tasks in multilingual contexts. It also sheds light on how\nlanguage models handle inherently subjective and context-dependent judgments, a\ncritical consideration for their deployment in real-world scenarios."}
{"id": "2505.10441", "pdf": "https://arxiv.org/pdf/2505.10441", "abs": "https://arxiv.org/abs/2505.10441", "authors": ["Filippo Leveni", "Luca Magri", "Giacomo Boracchi", "Cesare Alippi"], "title": "PIF: Anomaly detection via preference embedding", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)", "summary": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space."}
{"id": "2505.10307", "pdf": "https://arxiv.org/pdf/2505.10307", "abs": "https://arxiv.org/abs/2505.10307", "authors": ["Yiyang Zhao", "Chengpei Wu", "Lilin Zhang", "Ning Yang"], "title": "Negative Metric Learning for Graphs", "categories": ["cs.LG"], "comment": null, "summary": "Graph contrastive learning (GCL) often suffers from false negatives, which\ndegrades the performance on downstream tasks. The existing methods addressing\nthe false negative issue usually rely on human prior knowledge, still leading\nGCL to suboptimal results. In this paper, we propose a novel Negative Metric\nLearning (NML) enhanced GCL (NML-GCL). NML-GCL employs a learnable Negative\nMetric Network (NMN) to build a negative metric space, in which false negatives\ncan be distinguished better from true negatives based on their distance to\nanchor node. To overcome the lack of explicit supervision signals for NML, we\npropose a joint training scheme with bi-level optimization objective, which\nimplicitly utilizes the self-supervision signals to iteratively optimize the\nencoder and the negative metric network. The solid theoretical analysis and the\nextensive experiments conducted on widely used benchmarks verify the\nsuperiority of the proposed method."}
{"id": "2505.10261", "pdf": "https://arxiv.org/pdf/2505.10261", "abs": "https://arxiv.org/abs/2505.10261", "authors": ["Rui Yang", "Huitao Li", "Matthew Yu Heng Wong", "Yuhe Ke", "Xin Li", "Kunyu Yu", "Jingchi Liao", "Jonathan Chong Kai Liew", "Sabarinath Vinod Nair", "Jasmine Chiat Ling Ong", "Irene Li", "Douglas Teodoro", "Chuan Hong", "Daniel Shu Wei Ting", "Nan Liu"], "title": "The Evolving Landscape of Generative Large Language Models and Traditional Natural Language Processing in Medicine", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Natural language processing (NLP) has been traditionally applied to medicine,\nand generative large language models (LLMs) have become prominent recently.\nHowever, the differences between them across different medical tasks remain\nunderexplored. We analyzed 19,123 studies, finding that generative LLMs\ndemonstrate advantages in open-ended tasks, while traditional NLP dominates in\ninformation extraction and analysis tasks. As these technologies advance,\nethical use of them is essential to ensure their potential in medical\napplications."}
{"id": "2505.10457", "pdf": "https://arxiv.org/pdf/2505.10457", "abs": "https://arxiv.org/abs/2505.10457", "authors": ["Matteo Gambella", "Vicente Javier Castro Solar", "Manuel Roveri"], "title": "SEAL: Searching Expandable Architectures for Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "comment": "8 pages, 5 figures", "summary": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios."}
{"id": "2505.10322", "pdf": "https://arxiv.org/pdf/2505.10322", "abs": "https://arxiv.org/abs/2505.10322", "authors": ["Yijie Zhou", "Shi Pu"], "title": "Asynchronous Decentralized SGD under Non-Convexity: A Block-Coordinate Descent Framework", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "Decentralized optimization has become vital for leveraging distributed data\nwithout central control, enhancing scalability and privacy. However, practical\ndeployments face fundamental challenges due to heterogeneous computation speeds\nand unpredictable communication delays. This paper introduces a refined model\nof Asynchronous Decentralized Stochastic Gradient Descent (ADSGD) under\npractical assumptions of bounded computation and communication times. To\nunderstand the convergence of ADSGD, we first analyze Asynchronous Stochastic\nBlock Coordinate Descent (ASBCD) as a tool, and then show that ADSGD converges\nunder computation-delay-independent step sizes. The convergence result is\nestablished without assuming bounded data heterogeneity. Empirical experiments\nreveal that ADSGD outperforms existing methods in wall-clock convergence time\nacross various scenarios. With its simplicity, efficiency in memory and\ncommunication, and resilience to communication and computation delays, ADSGD is\nwell-suited for real-world decentralized learning tasks."}
{"id": "2505.10264", "pdf": "https://arxiv.org/pdf/2505.10264", "abs": "https://arxiv.org/abs/2505.10264", "authors": ["Francesco Diana", "André Nusser", "Chuan Xu", "Giovanni Neglia"], "title": "Cutting Through Privacy: A Hyperplane-Based Data Reconstruction Attack in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Federated Learning (FL) enables collaborative training of machine learning\nmodels across distributed clients without sharing raw data, ostensibly\npreserving data privacy. Nevertheless, recent studies have revealed critical\nvulnerabilities in FL, showing that a malicious central server can manipulate\nmodel updates to reconstruct clients' private training data. Existing data\nreconstruction attacks have important limitations: they often rely on\nassumptions about the clients' data distribution or their efficiency\nsignificantly degrades when batch sizes exceed just a few tens of samples.\n  In this work, we introduce a novel data reconstruction attack that overcomes\nthese limitations. Our method leverages a new geometric perspective on fully\nconnected layers to craft malicious model parameters, enabling the perfect\nrecovery of arbitrarily large data batches in classification tasks without any\nprior knowledge of clients' data. Through extensive experiments on both image\nand tabular datasets, we demonstrate that our attack outperforms existing\nmethods and achieves perfect reconstruction of data batches two orders of\nmagnitude larger than the state of the art."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.10325", "pdf": "https://arxiv.org/pdf/2505.10325", "abs": "https://arxiv.org/abs/2505.10325", "authors": ["Athanasios Tziouvaras", "Blaz Bertalanic", "George Floros", "Kostas Kolomvatsos", "Panagiotis Sarigiannidis", "Carolina Fortuna"], "title": "A Representation Learning Approach to Feature Drift Detection in Wireless Networks", "categories": ["cs.LG"], "comment": null, "summary": "AI is foreseen to be a centerpiece in next generation wireless networks\nenabling enabling ubiquitous communication as well as new services. However, in\nreal deployment, feature distribution changes may degrade the performance of AI\nmodels and lead to undesired behaviors. To counter for undetected model\ndegradation, we propose ALERT; a method that can detect feature distribution\nchanges and trigger model re-training that works well on two wireless network\nuse cases: wireless fingerprinting and link anomaly detection. ALERT includes\nthree components: representation learning, statistical testing and utility\nassessment. We rely on MLP for designing the representation learning component,\non Kolmogorov-Smirnov and Population Stability Index tests for designing the\nstatistical testing and a new function for utility assessment. We show the\nsuperiority of the proposed method against ten standard drift detection methods\navailable in the literature on two wireless network use cases."}
{"id": "2505.10297", "pdf": "https://arxiv.org/pdf/2505.10297", "abs": "https://arxiv.org/abs/2505.10297", "authors": ["Chibueze Peace Obioma", "Youcheng Sun", "Mustafa A. Mustafa"], "title": "Defending the Edge: Representative-Attention for Mitigating Backdoor Attacks in Federated Learning", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": "Submitted to ESORICS 2025", "summary": "Federated learning (FL) enhances privacy and reduces communication cost for\nresource-constrained edge clients by supporting distributed model training at\nthe edge. However, the heterogeneous nature of such devices produces diverse,\nnon-independent, and identically distributed (non-IID) data, making the\ndetection of backdoor attacks more challenging. In this paper, we propose a\nnovel federated representative-attention-based defense mechanism, named FeRA,\nthat leverages cross-client attention over internal feature representations to\ndistinguish benign from malicious clients. FeRA computes an anomaly score based\non representation reconstruction errors, effectively identifying clients whose\ninternal activations significantly deviate from the group consensus. Our\nevaluation demonstrates FeRA's robustness across various FL scenarios,\nincluding challenging non-IID data distributions typical of edge devices.\nExperimental results show that it effectively reduces backdoor attack success\nrates while maintaining high accuracy on the main task. The method is\nmodel-agnostic, attack-agnostic, and does not require labeled reference data,\nmaking it well suited to heterogeneous and resource-limited edge deployments."}
{"id": "2505.10526", "pdf": "https://arxiv.org/pdf/2505.10526", "abs": "https://arxiv.org/abs/2505.10526", "authors": ["Mugilan Ganesan", "Shane Segal", "Ankur Aggarwal", "Nish Sinnadurai", "Sean Lie", "Vithursan Thangarasa"], "title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Main paper: 11 pp., 4 figs., 3 tabs.; Supplementary: 2 pp", "summary": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs."}
{"id": "2505.10330", "pdf": "https://arxiv.org/pdf/2505.10330", "abs": "https://arxiv.org/abs/2505.10330", "authors": ["Jonathan Clifford Balloch"], "title": "Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change", "categories": ["cs.LG", "cs.AI"], "comment": "PhD Dissertation, 131 pages", "summary": "Real-world autonomous decision-making systems, from robots to recommendation\nengines, must operate in environments that change over time. While deep\nreinforcement learning (RL) has shown an impressive ability to learn optimal\npolicies in stationary environments, most methods are data intensive and assume\na world that does not change between training and test time. As a result,\nconventional RL methods struggle to adapt when conditions change. This poses a\nfundamental challenge: how can RL agents efficiently adapt their behavior when\nencountering novel environmental changes during deployment without\ncatastrophically forgetting useful prior knowledge? This dissertation\ndemonstrates that efficient online adaptation requires two key capabilities:\n(1) prioritized exploration and sampling strategies that help identify and\nlearn from relevant experiences, and (2) selective preservation of prior\nknowledge through structured representations that can be updated without\ndisruption to reusable components."}
{"id": "2505.10320", "pdf": "https://arxiv.org/pdf/2505.10320", "abs": "https://arxiv.org/abs/2505.10320", "authors": ["Chenxi Whitehouse", "Tianlu Wang", "Ping Yu", "Xian Li", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 8 tables, 11 figures", "summary": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses."}
{"id": "2505.10331", "pdf": "https://arxiv.org/pdf/2505.10331", "abs": "https://arxiv.org/abs/2505.10331", "authors": ["Luca Muscarnera", "Luigi Loreti", "Giovanni Todeschini", "Alessio Fumagalli", "Francesco Regazzoni"], "title": "Emergence of Structure in Ensembles of Random Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Randomness is ubiquitous in many applications across data science and machine\nlearning. Remarkably, systems composed of random components often display\nemergent global behaviors that appear deterministic, manifesting a transition\nfrom microscopic disorder to macroscopic organization. In this work, we\nintroduce a theoretical model for studying the emergence of collective\nbehaviors in ensembles of random classifiers. We argue that, if the ensemble is\nweighted through the Gibbs measure defined by adopting the classification loss\nas an energy, then there exists a finite temperature parameter for the\ndistribution such that the classification is optimal, with respect to the loss\n(or the energy). Interestingly, for the case in which samples are generated by\na Gaussian distribution and labels are constructed by employing a teacher\nperceptron, we analytically prove and numerically confirm that such optimal\ntemperature does not depend neither on the teacher classifier (which is, by\nconstruction of the learning problem, unknown), nor on the number of random\nclassifiers, highlighting the universal nature of the observed behavior.\nExperiments on the MNIST dataset underline the relevance of this phenomenon in\nhigh-quality, noiseless, datasets. Finally, a physical analogy allows us to\nshed light on the self-organizing nature of the studied phenomenon."}
{"id": "2505.10330", "pdf": "https://arxiv.org/pdf/2505.10330", "abs": "https://arxiv.org/abs/2505.10330", "authors": ["Jonathan Clifford Balloch"], "title": "Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change", "categories": ["cs.LG", "cs.AI"], "comment": "PhD Dissertation, 131 pages", "summary": "Real-world autonomous decision-making systems, from robots to recommendation\nengines, must operate in environments that change over time. While deep\nreinforcement learning (RL) has shown an impressive ability to learn optimal\npolicies in stationary environments, most methods are data intensive and assume\na world that does not change between training and test time. As a result,\nconventional RL methods struggle to adapt when conditions change. This poses a\nfundamental challenge: how can RL agents efficiently adapt their behavior when\nencountering novel environmental changes during deployment without\ncatastrophically forgetting useful prior knowledge? This dissertation\ndemonstrates that efficient online adaptation requires two key capabilities:\n(1) prioritized exploration and sampling strategies that help identify and\nlearn from relevant experiences, and (2) selective preservation of prior\nknowledge through structured representations that can be updated without\ndisruption to reusable components."}
{"id": "2505.10344", "pdf": "https://arxiv.org/pdf/2505.10344", "abs": "https://arxiv.org/abs/2505.10344", "authors": ["Alan Jeffares", "Liyuan Liu"], "title": "An Introduction to Discrete Variational Autoencoders", "categories": ["cs.LG"], "comment": "Tutorial paper", "summary": "Variational Autoencoders (VAEs) are well-established as a principled approach\nto probabilistic unsupervised learning with neural networks. Typically, an\nencoder network defines the parameters of a Gaussian distributed latent space\nfrom which we can sample and pass realizations to a decoder network. This model\nis trained to reconstruct its inputs and is optimized through the evidence\nlower bound. In recent years, discrete latent spaces have grown in popularity,\nsuggesting that they may be a natural choice for many data modalities (e.g.\ntext). In this tutorial, we provide a rigorous, yet practical, introduction to\ndiscrete variational autoencoders -- specifically, VAEs in which the latent\nspace is made up of latent variables that follow a categorical distribution. We\nassume only a basic mathematical background with which we carefully derive each\nstep from first principles. From there, we develop a concrete training recipe\nand provide an example implementation, hosted at\nhttps://github.com/alanjeffares/discreteVAE."}
{"id": "2505.10331", "pdf": "https://arxiv.org/pdf/2505.10331", "abs": "https://arxiv.org/abs/2505.10331", "authors": ["Luca Muscarnera", "Luigi Loreti", "Giovanni Todeschini", "Alessio Fumagalli", "Francesco Regazzoni"], "title": "Emergence of Structure in Ensembles of Random Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Randomness is ubiquitous in many applications across data science and machine\nlearning. Remarkably, systems composed of random components often display\nemergent global behaviors that appear deterministic, manifesting a transition\nfrom microscopic disorder to macroscopic organization. In this work, we\nintroduce a theoretical model for studying the emergence of collective\nbehaviors in ensembles of random classifiers. We argue that, if the ensemble is\nweighted through the Gibbs measure defined by adopting the classification loss\nas an energy, then there exists a finite temperature parameter for the\ndistribution such that the classification is optimal, with respect to the loss\n(or the energy). Interestingly, for the case in which samples are generated by\na Gaussian distribution and labels are constructed by employing a teacher\nperceptron, we analytically prove and numerically confirm that such optimal\ntemperature does not depend neither on the teacher classifier (which is, by\nconstruction of the learning problem, unknown), nor on the number of random\nclassifiers, highlighting the universal nature of the observed behavior.\nExperiments on the MNIST dataset underline the relevance of this phenomenon in\nhigh-quality, noiseless, datasets. Finally, a physical analogy allows us to\nshed light on the self-organizing nature of the studied phenomenon."}
{"id": "2505.10347", "pdf": "https://arxiv.org/pdf/2505.10347", "abs": "https://arxiv.org/abs/2505.10347", "authors": ["Gabriel S. Gama", "Valdir Grassi Jr"], "title": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task\nLearning by addressing issues like conflicting gradients and differing gradient\nnorms, which hinder equal-weighted task training. However, recent critiques\nsuggest that equally weighted tasks can achieve competitive results compared to\nSMTOs, arguing that previous SMTO results were influenced by poor\nhyperparameter optimization and lack of regularization. In this work, we\nevaluate these claims through an extensive empirical evaluation of SMTOs,\nincluding some of the latest methods, on more complex multi-task problems to\nclarify this behavior. Our findings indicate that SMTOs perform well compared\nto uniform loss and that fixed weights can achieve competitive performance\ncompared to SMTOs. Furthermore, we demonstrate why uniform loss perform\nsimilarly to SMTOs in some instances. The code will be made publicly available."}
{"id": "2505.10347", "pdf": "https://arxiv.org/pdf/2505.10347", "abs": "https://arxiv.org/abs/2505.10347", "authors": ["Gabriel S. Gama", "Valdir Grassi Jr"], "title": "Uniform Loss vs. Specialized Optimization: A Comparative Analysis in Multi-Task Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Specialized Multi-Task Optimizers (SMTOs) balance task learning in Multi-Task\nLearning by addressing issues like conflicting gradients and differing gradient\nnorms, which hinder equal-weighted task training. However, recent critiques\nsuggest that equally weighted tasks can achieve competitive results compared to\nSMTOs, arguing that previous SMTO results were influenced by poor\nhyperparameter optimization and lack of regularization. In this work, we\nevaluate these claims through an extensive empirical evaluation of SMTOs,\nincluding some of the latest methods, on more complex multi-task problems to\nclarify this behavior. Our findings indicate that SMTOs perform well compared\nto uniform loss and that fixed weights can achieve competitive performance\ncompared to SMTOs. Furthermore, we demonstrate why uniform loss perform\nsimilarly to SMTOs in some instances. The code will be made publicly available."}
{"id": "2505.10360", "pdf": "https://arxiv.org/pdf/2505.10360", "abs": "https://arxiv.org/abs/2505.10360", "authors": ["Victor Petrén Bach Hansen", "Lasse Krogsbøll", "Jonas Lyngsø", "Mathias Baltzersen", "Andreas Motzfeldt", "Kevin Pelgrims", "Lars Maaløe"], "title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": null, "summary": "There are now a multitude of AI-scribing solutions for healthcare promising\nthe utilization of large language models for ambient documentation. However,\nthese AI scribes still rely on one-shot, or few-shot prompts for generating\nnotes after the consultation has ended, employing little to no reasoning. This\nrisks long notes with an increase in hallucinations, misrepresentation of the\nintent of the clinician, and reliance on the proofreading of the clinician to\ncatch errors. A dangerous combination for patient safety if vigilance is\ncompromised by workload and fatigue. In this paper, we introduce a method for\nextracting salient clinical information in real-time alongside the healthcare\nconsultation, denoted Facts, and use that information recursively to generate\nthe final note. The FactsR method results in more accurate and concise notes by\nplacing the clinician-in-the-loop of note generation, while opening up new use\ncases within real-time decision support."}
{"id": "2505.10352", "pdf": "https://arxiv.org/pdf/2505.10352", "abs": "https://arxiv.org/abs/2505.10352", "authors": ["Shihao Zou", "Qingfeng Li", "Wei Ji", "Jingjing Li", "Yongkui Yang", "Guoqi Li", "Chao Dong"], "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer"}
{"id": "2505.10392", "pdf": "https://arxiv.org/pdf/2505.10392", "abs": "https://arxiv.org/abs/2505.10392", "authors": ["Aryan Mishra", "Lizhen Lin"], "title": "Schreier-Coset Graph Propagation", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 1 figure , preprint", "summary": "Graph Neural Networks (GNNs) offer a principled framework for learning over\ngraph-structured data, yet their expressive capacity is often hindered by\nover-squashing, wherein information from distant nodes is compressed into\nfixed-size vectors. Existing solutions, including graph rewiring and\nbottleneck-resistant architectures such as Cayley and expander graphs, avoid\nthis problem but introduce scalability bottlenecks. In particular, the Cayley\ngraphs constructed over $SL(2,\\mathbb{Z}_n)$ exhibit strong theoretical\nproperties, yet suffer from cubic node growth $O(n^3)$, leading to high memory\nusage. To address this, this work introduces Schrier-Coset Graph Propagation\n(SCGP), a group-theoretic augmentation method that enriches node features\nthrough Schreier-coset embeddings without altering the input graph topology.\nSCGP embeds bottleneck-free connectivity patterns into a compact feature space,\nimproving long-range message passing while maintaining computational\nefficiency. Empirical evaluations across standard node and graph classification\nbenchmarks demonstrate that SCGP achieves performance comparable to, or\nexceeding, expander graph and rewired GNN baselines. Furthermore, SCGP exhibits\nparticular advantages in processing hierarchical and modular graph structures,\noffering reduced inference latency, improved scalability, and a low memory\nfootprint, making it suitable for real-time and resource-constrained\napplications."}
{"id": "2505.10360", "pdf": "https://arxiv.org/pdf/2505.10360", "abs": "https://arxiv.org/abs/2505.10360", "authors": ["Victor Petrén Bach Hansen", "Lasse Krogsbøll", "Jonas Lyngsø", "Mathias Baltzersen", "Andreas Motzfeldt", "Kevin Pelgrims", "Lars Maaløe"], "title": "FactsR: A Safer Method for Producing High Quality Healthcare Documentation", "categories": ["cs.LG", "cs.AI", "stat.AP"], "comment": null, "summary": "There are now a multitude of AI-scribing solutions for healthcare promising\nthe utilization of large language models for ambient documentation. However,\nthese AI scribes still rely on one-shot, or few-shot prompts for generating\nnotes after the consultation has ended, employing little to no reasoning. This\nrisks long notes with an increase in hallucinations, misrepresentation of the\nintent of the clinician, and reliance on the proofreading of the clinician to\ncatch errors. A dangerous combination for patient safety if vigilance is\ncompromised by workload and fatigue. In this paper, we introduce a method for\nextracting salient clinical information in real-time alongside the healthcare\nconsultation, denoted Facts, and use that information recursively to generate\nthe final note. The FactsR method results in more accurate and concise notes by\nplacing the clinician-in-the-loop of note generation, while opening up new use\ncases within real-time decision support."}
{"id": "2505.10407", "pdf": "https://arxiv.org/pdf/2505.10407", "abs": "https://arxiv.org/abs/2505.10407", "authors": ["Wenhao Ding", "Choon Hwai Yap", "Kangjun Ji", "Simão Castro"], "title": "Two-Stage Generative Model for Intracranial Aneurysm Meshes with Morphological Marker Conditioning", "categories": ["cs.LG", "68T07"], "comment": "10 pages, 2 figures", "summary": "A generative model for the mesh geometry of intracranial aneurysms (IA) is\ncrucial for training networks to predict blood flow forces in real time, which\nis a key factor affecting disease progression. This need is necessitated by the\nabsence of a large IA image datasets. Existing shape generation methods\nstruggle to capture realistic IA features and ignore the relationship between\nIA pouches and parent vessels, limiting physiological realism and their\ngeneration cannot be controlled to have specific morphological measurements. We\npropose AneuG, a two-stage Variational Autoencoder (VAE)-based IA mesh\ngenerator. In the first stage, AneuG generates low-dimensional Graph Harmonic\nDeformation (GHD) tokens to encode and reconstruct aneurysm pouch shapes,\nconstrained to morphing energy statistics truths. GHD enables more accurate\nshape encoding than alternatives. In the second stage, AneuG generates parent\nvessels conditioned on GHD tokens, by generating vascular centreline and\npropagating the cross-section. AneuG's IA shape generation can further be\nconditioned to have specific clinically relevant morphological measurements.\nThis is useful for studies to understand shape variations represented by\nclinical measurements, and for flow simulation studies to understand effects of\nspecific clinical shape parameters on fluid dynamics. Source code and\nimplementation details are available at\nhttps://github.com/anonymousaneug/AneuG."}
{"id": "2505.10392", "pdf": "https://arxiv.org/pdf/2505.10392", "abs": "https://arxiv.org/abs/2505.10392", "authors": ["Aryan Mishra", "Lizhen Lin"], "title": "Schreier-Coset Graph Propagation", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 1 figure , preprint", "summary": "Graph Neural Networks (GNNs) offer a principled framework for learning over\ngraph-structured data, yet their expressive capacity is often hindered by\nover-squashing, wherein information from distant nodes is compressed into\nfixed-size vectors. Existing solutions, including graph rewiring and\nbottleneck-resistant architectures such as Cayley and expander graphs, avoid\nthis problem but introduce scalability bottlenecks. In particular, the Cayley\ngraphs constructed over $SL(2,\\mathbb{Z}_n)$ exhibit strong theoretical\nproperties, yet suffer from cubic node growth $O(n^3)$, leading to high memory\nusage. To address this, this work introduces Schrier-Coset Graph Propagation\n(SCGP), a group-theoretic augmentation method that enriches node features\nthrough Schreier-coset embeddings without altering the input graph topology.\nSCGP embeds bottleneck-free connectivity patterns into a compact feature space,\nimproving long-range message passing while maintaining computational\nefficiency. Empirical evaluations across standard node and graph classification\nbenchmarks demonstrate that SCGP achieves performance comparable to, or\nexceeding, expander graph and rewired GNN baselines. Furthermore, SCGP exhibits\nparticular advantages in processing hierarchical and modular graph structures,\noffering reduced inference latency, improved scalability, and a low memory\nfootprint, making it suitable for real-time and resource-constrained\napplications."}
{"id": "2505.10422", "pdf": "https://arxiv.org/pdf/2505.10422", "abs": "https://arxiv.org/abs/2505.10422", "authors": ["Daniel Weitekamp", "Christopher MacLellan", "Erik Harpstead", "Kenneth Koedinger"], "title": "Decomposed Inductive Procedure Learning: Learning Academic Tasks with Human-Like Data Efficiency", "categories": ["cs.LG"], "comment": "To appear in CogSci 2025", "summary": "Human learning relies on specialization -- distinct cognitive mechanisms\nworking together to enable rapid learning. In contrast, most modern neural\nnetworks rely on a single mechanism: gradient descent over an objective\nfunction. This raises the question: might human learners' relatively rapid\nlearning from just tens of examples instead of tens of thousands in data-driven\ndeep learning arise from our ability to use multiple specialized mechanisms of\nlearning in combination? We investigate this question through an ablation\nanalysis of inductive human learning simulations in online tutoring\nenvironments. Comparing reinforcement learning to a more data-efficient\n3-mechanism symbolic rule induction approach, we find that decomposing learning\ninto multiple distinct mechanisms significantly improves data efficiency,\nbringing it in line with human learning. Furthermore, we show that this\ndecomposition has a greater impact on efficiency than the distinction between\nsymbolic and subsymbolic learning alone. Efforts to align data-driven machine\nlearning with human learning often overlook the stark difference in learning\nefficiency. Our findings suggest that integrating multiple specialized learning\nmechanisms may be key to bridging this gap."}
{"id": "2505.10402", "pdf": "https://arxiv.org/pdf/2505.10402", "abs": "https://arxiv.org/abs/2505.10402", "authors": ["Yihong Dong", "Yuchen Liu", "Xue Jiang", "Zhi Jin", "Ge Li"], "title": "Rethinking Repetition Problems of LLMs in Code Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to ACL 2025 (main)", "summary": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code."}
{"id": "2505.10423", "pdf": "https://arxiv.org/pdf/2505.10423", "abs": "https://arxiv.org/abs/2505.10423", "authors": ["Ari Karchmer", "Eran Malach"], "title": "The Power of Random Features and the Limits of Distribution-Free Gradient Descent", "categories": ["cs.LG"], "comment": null, "summary": "We study the relationship between gradient-based optimization of parametric\nmodels (e.g., neural networks) and optimization of linear combinations of\nrandom features. Our main result shows that if a parametric model can be\nlearned using mini-batch stochastic gradient descent (bSGD) without making\nassumptions about the data distribution, then with high probability, the target\nfunction can also be approximated using a polynomial-sized combination of\nrandom features. The size of this combination depends on the number of gradient\nsteps and numerical precision used in the bSGD process. This finding reveals\nfundamental limitations of distribution-free learning in neural networks\ntrained by gradient descent, highlighting why making assumptions about data\ndistributions is often crucial in practice. Along the way, we also introduce a\nnew theoretical framework called average probabilistic dimension complexity\n(adc), which extends the probabilistic dimension complexity developed by Kamath\net al. (2020). We prove that adc has a polynomial relationship with statistical\nquery dimension, and use this relationship to demonstrate an infinite\nseparation between adc and standard dimension complexity."}
{"id": "2505.10420", "pdf": "https://arxiv.org/pdf/2505.10420", "abs": "https://arxiv.org/abs/2505.10420", "authors": ["Andrei Arhire", "Radu Timofte"], "title": "Learned Lightweight Smartphone ISP with Unpaired Data", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted at CVPRW 2025", "summary": "The Image Signal Processor (ISP) is a fundamental component in modern\nsmartphone cameras responsible for conversion of RAW sensor image data to RGB\nimages with a strong focus on perceptual quality. Recent work highlights the\npotential of deep learning approaches and their ability to capture details with\na quality increasingly close to that of professional cameras. A difficult and\ncostly step when developing a learned ISP is the acquisition of pixel-wise\naligned paired data that maps the raw captured by a smartphone camera sensor to\nhigh-quality reference images. In this work, we address this challenge by\nproposing a novel training method for a learnable ISP that eliminates the need\nfor direct correspondences between raw images and ground-truth data with\nmatching content. Our unpaired approach employs a multi-term loss function\nguided by adversarial training with multiple discriminators processing feature\nmaps from pre-trained networks to maintain content structure while learning\ncolor and texture characteristics from the target RGB dataset. Using\nlightweight neural network architectures suitable for mobile devices as\nbackbones, we evaluated our method on the Zurich RAW to RGB and Fujifilm\nUltraISP datasets. Compared to paired training methods, our unpaired learning\nstrategy shows strong potential and achieves high fidelity across multiple\nevaluation metrics. The code and pre-trained models are available at\nhttps://github.com/AndreiiArhire/Learned-Lightweight-Smartphone-ISP-with-Unpaired-Data ."}
{"id": "2505.10425", "pdf": "https://arxiv.org/pdf/2505.10425", "abs": "https://arxiv.org/abs/2505.10425", "authors": ["Jingyao Wang", "Wenwen Qiang", "Zeen Song", "Changwen Zheng", "Hui Xiong"], "title": "Learning to Think: Information-Theoretic Reinforcement Fine-Tuning for LLMs", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) excel at complex tasks thanks to advances in\nreasoning abilities. However, existing methods overlook the trade-off between\nreasoning effectiveness and computational efficiency, often encouraging\nunnecessarily long reasoning chains and wasting tokens. To address this, we\npropose Learning to Think (L2T), an information-theoretic reinforcement\nfine-tuning framework for LLMs to make the models achieve optimal reasoning\nwith fewer tokens. Specifically, L2T treats each query-response interaction as\na hierarchical session of multiple episodes and proposes a universal dense\nprocess reward, i.e., quantifies the episode-wise information gain in\nparameters, requiring no extra annotations or task-specific evaluators. We\npropose a method to quickly estimate this reward based on PAC-Bayes bounds and\nthe Fisher information matrix. Theoretical analyses show that it significantly\nreduces computational complexity with high estimation accuracy. By immediately\nrewarding each episode's contribution and penalizing excessive updates, L2T\noptimizes the model via reinforcement learning to maximize the use of each\nepisode and achieve effective updates. Empirical results on various reasoning\nbenchmarks and base models demonstrate the advantage of L2T across different\ntasks, boosting both reasoning effectiveness and efficiency."}
{"id": "2505.10441", "pdf": "https://arxiv.org/pdf/2505.10441", "abs": "https://arxiv.org/abs/2505.10441", "authors": ["Filippo Leveni", "Luca Magri", "Giacomo Boracchi", "Cesare Alippi"], "title": "PIF: Anomaly detection via preference embedding", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)", "summary": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space."}
{"id": "2505.10432", "pdf": "https://arxiv.org/pdf/2505.10432", "abs": "https://arxiv.org/abs/2505.10432", "authors": ["Randy J. Chase", "Katherine Haynes", "Lander Ver Hoef", "Imme Ebert-Uphoff"], "title": "Score-based diffusion nowcasting of GOES imagery", "categories": ["cs.LG", "physics.ao-ph"], "comment": null, "summary": "Clouds and precipitation are important for understanding weather and climate.\nSimulating clouds and precipitation with traditional numerical weather\nprediction is challenging because of the sub-grid parameterizations required.\nMachine learning has been explored for forecasting clouds and precipitation,\nbut early machine learning methods often created blurry forecasts. In this\npaper we explore a newer method, named score-based diffusion, to nowcast (zero\nto three hour forecast) clouds and precipitation. We discuss the background and\nintuition of score-based diffusion models - thus providing a starting point for\nthe community - while exploring the methodology's use for nowcasting\ngeostationary infrared imagery. We experiment with three main types of\ndiffusion models: a standard score-based diffusion model (Diff); a residual\ncorrection diffusion model (CorrDiff); and a latent diffusion model (LDM). Our\nresults show that the diffusion models are able to not only advect existing\nclouds, but also generate and decay clouds, including convective initiation.\nThese results are surprising because the forecasts are initiated with only the\npast 20 mins of infrared satellite imagery. A case study qualitatively shows\nthe preservation of high resolution features longer into the forecast than a\nconventional mean-squared error trained U-Net. The best of the three diffusion\nmodels tested was the CorrDiff approach, outperforming all other diffusion\nmodels, the traditional U-Net, and a persistence forecast by one to two kelvin\non root mean squared error. The diffusion models also enable out-of-the-box\nensemble generation, which shows skillful calibration, with the spread of the\nensemble correlating well to the error."}
{"id": "2505.10453", "pdf": "https://arxiv.org/pdf/2505.10453", "abs": "https://arxiv.org/abs/2505.10453", "authors": ["Tyler Tran", "Sangeet Khemlani", "J. G. Trafton"], "title": "Vision language models have difficulty recognizing virtual objects", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Vision language models (VLMs) are AI systems paired with both language and\nvision encoders to process multimodal input. They are capable of performing\ncomplex semantic tasks such as automatic captioning, but it remains an open\nquestion about how well they comprehend the visuospatial properties of scenes\ndepicted in the images they process. We argue that descriptions of virtual\nobjects -- objects that are not visually represented in an image -- can help\ntest scene comprehension in these AI systems. For example, an image that\ndepicts a person standing under a tree can be paired with the following prompt:\nimagine that a kite is stuck in the tree. VLMs that comprehend the scene should\nupdate their representations and reason sensibly about the spatial relations\nbetween all three objects. We describe systematic evaluations of\nstate-of-the-art VLMs and show that their ability to process virtual objects is\ninadequate."}
{"id": "2505.10438", "pdf": "https://arxiv.org/pdf/2505.10438", "abs": "https://arxiv.org/abs/2505.10438", "authors": ["David Grasev"], "title": "Identification and Optimal Nonlinear Control of Turbojet Engine Using Koopman Eigenfunction Model", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "51 pages, 28 figures", "summary": "Gas turbine engines represent complex highly nonlinear dynamical systems.\nDeriving their physics-based models can be challenging as it requires\nperformance characteristics, that are not always available, and one often has\nto make many simplifying assumptions. In this paper, the limitations of\nconventional experimental methods used to derive component-level and locally\nlinear parameter-varying models are discussed and addressed by employing\nidentification techniques based on data collected from standard engine\noperation under closed-loop control. The rotor dynamics were estimated using\nthe sparse identification of nonlinear dynamics. Subsequently, the autonomous\npart of the dynamics was mapped into an optimally constructed Koopman\neigenfunction space. The process included eigenvalue optimization using\nmetaheuristic algorithms and temporal projection, followed by gradient-based\neigenfunction identification. The resulting Koopman model was validated against\nan in-house reference component-level model. A globally optimal nonlinear\nfeedback controller and a Kalman estimator were then designed in the\neigenfunction space and compared to the classical and gain-scheduled\nproportional-integral controllers, as well as a proposed internal model control\napproach. The eigenmode structure allowed targeting individual modes during the\noptimization process, resulting in a better performance tuning. The results\nshowed that the Koopman-based controller outperformed the other benchmark\ncontrollers in both reference tracking and disturbance rejection, under\nsea-level and varying flight conditions, due to its global nature."}
{"id": "2505.10457", "pdf": "https://arxiv.org/pdf/2505.10457", "abs": "https://arxiv.org/abs/2505.10457", "authors": ["Matteo Gambella", "Vicente Javier Castro Solar", "Manuel Roveri"], "title": "SEAL: Searching Expandable Architectures for Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "comment": "8 pages, 5 figures", "summary": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios."}
{"id": "2505.10441", "pdf": "https://arxiv.org/pdf/2505.10441", "abs": "https://arxiv.org/abs/2505.10441", "authors": ["Filippo Leveni", "Luca Magri", "Giacomo Boracchi", "Cesare Alippi"], "title": "PIF: Anomaly detection via preference embedding", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "comment": "Accepted at International Conference on Pattern Recognition (ICPR\n  2020)", "summary": "We address the problem of detecting anomalies with respect to structured\npatterns. To this end, we conceive a novel anomaly detection method called PIF,\nthat combines the advantages of adaptive isolation methods with the flexibility\nof preference embedding. Specifically, we propose to embed the data in a high\ndimensional space where an efficient tree-based method, PI-Forest, is employed\nto compute an anomaly score. Experiments on synthetic and real datasets\ndemonstrate that PIF favorably compares with state-of-the-art anomaly detection\ntechniques, and confirm that PI-Forest is better at measuring arbitrary\ndistances and isolate points in the preference space."}
{"id": "2505.10465", "pdf": "https://arxiv.org/pdf/2505.10465", "abs": "https://arxiv.org/abs/2505.10465", "authors": ["Yizhou liu", "Ziming Liu", "Jeff Gore"], "title": "Superposition Yields Robust Neural Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages, 23 figures", "summary": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters."}
{"id": "2505.10457", "pdf": "https://arxiv.org/pdf/2505.10457", "abs": "https://arxiv.org/abs/2505.10457", "authors": ["Matteo Gambella", "Vicente Javier Castro Solar", "Manuel Roveri"], "title": "SEAL: Searching Expandable Architectures for Incremental Learning", "categories": ["cs.LG", "cs.AI", "cs.CV", "68T07"], "comment": "8 pages, 5 figures", "summary": "Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios."}
{"id": "2505.10482", "pdf": "https://arxiv.org/pdf/2505.10482", "abs": "https://arxiv.org/abs/2505.10482", "authors": ["Ningyuan Yang", "Jiaxuan Gao", "Feng Gao", "Yi Wu", "Chao Yu"], "title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages for main text, 23 pages in total, submitted to Neurips, 13\n  figures", "summary": "Diffusion policies, widely adopted in decision-making scenarios such as\nrobotics, gaming and autonomous driving, are capable of learning diverse skills\nfrom demonstration data due to their high representation power. However, the\nsub-optimal and limited coverage of demonstration data could lead to diffusion\npolicies that generate sub-optimal trajectories and even catastrophic failures.\nWhile reinforcement learning (RL)-based fine-tuning has emerged as a promising\nsolution to address these limitations, existing approaches struggle to\neffectively adapt Proximal Policy Optimization (PPO) to diffusion models. This\nchallenge stems from the computational intractability of action likelihood\nestimation during the denoising process, which leads to complicated\noptimization objectives. In our experiments starting from randomly initialized\npolicies, we find that online tuning of Diffusion Policies demonstrates much\nlower sample efficiency compared to directly applying PPO on MLP policies\n(MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework\nthat reformulates Diffusion Policy as a noise-conditioned deterministic policy.\nBy treating each denoising step as a differentiable transformation conditioned\non pre-sampled noise, NCDPO enables tractable likelihood evaluation and\ngradient backpropagation through all diffusion timesteps. Our experiments\ndemonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when\ntraining from scratch, outperforming existing methods in both sample efficiency\nand final performance across diverse benchmarks, including continuous robot\ncontrol and multi-agent game scenarios. Furthermore, our experimental results\nshow that our method is robust to the number denoising timesteps in the\nDiffusion Policy."}
{"id": "2505.10465", "pdf": "https://arxiv.org/pdf/2505.10465", "abs": "https://arxiv.org/abs/2505.10465", "authors": ["Yizhou liu", "Ziming Liu", "Jeff Gore"], "title": "Superposition Yields Robust Neural Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "30 pages, 23 figures", "summary": "The success of today's large language models (LLMs) depends on the\nobservation that larger models perform better. However, the origin of this\nneural scaling law -- the finding that loss decreases as a power law with model\nsize -- remains unclear. Starting from two empirical principles -- that LLMs\nrepresent more things than the model dimensions (widths) they have (i.e.,\nrepresentations are superposed), and that words or concepts in language occur\nwith varying frequencies -- we constructed a toy model to study the loss\nscaling with model size. We found that when superposition is weak, meaning only\nthe most frequent features are represented without interference, the scaling of\nloss with model size depends on the underlying feature frequency; if feature\nfrequencies follow a power law, so does the loss. In contrast, under strong\nsuperposition, where all features are represented but overlap with each other,\nthe loss becomes inversely proportional to the model dimension across a wide\nrange of feature frequency distributions. This robust scaling behavior is\nexplained geometrically: when many more vectors are packed into a lower\ndimensional space, the interference (squared overlaps) between vectors scales\ninversely with that dimension. We then analyzed four families of open-sourced\nLLMs and found that they exhibit strong superposition and quantitatively match\nthe predictions of our toy model. The Chinchilla scaling law turned out to also\nagree with our results. We conclude that representation superposition is an\nimportant mechanism underlying the observed neural scaling laws. We anticipate\nthat these insights will inspire new training strategies and model\narchitectures to achieve better performance with less computation and fewer\nparameters."}
{"id": "2505.10483", "pdf": "https://arxiv.org/pdf/2505.10483", "abs": "https://arxiv.org/abs/2505.10483", "authors": ["Yi Li", "Haonan Wang", "Qixiang Zhang", "Boyu Xiao", "Chenchang Hu", "Hualiang Wang", "Xiaomeng Li"], "title": "UniEval: Unified Holistic Evaluation for Unified Multimodal Understanding and Generation", "categories": ["cs.CV", "cs.AI"], "comment": "UniEval is the first evaluation framework designed for unified\n  multimodal models, including a holistic benchmark UniBench and the UniScore\n  metric", "summary": "The emergence of unified multimodal understanding and generation models is\nrapidly attracting attention because of their ability to enhance\ninstruction-following capabilities while minimizing model redundancy. However,\nthere is a lack of a unified evaluation framework for these models, which would\nenable an elegant, simplified, and overall evaluation. Current models conduct\nevaluations on multiple task-specific benchmarks, but there are significant\nlimitations, such as the lack of overall results, errors from extra evaluation\nmodels, reliance on extensive labeled images, benchmarks that lack diversity,\nand metrics with limited capacity for instruction-following evaluation. To\ntackle these challenges, we introduce UniEval, the first evaluation framework\ndesigned for unified multimodal models without extra models, images, or\nannotations. This facilitates a simplified and unified evaluation process. The\nUniEval framework contains a holistic benchmark, UniBench (supports both\nunified and visual generation models), along with the corresponding UniScore\nmetric. UniBench includes 81 fine-grained tags contributing to high diversity.\nExperimental results indicate that UniBench is more challenging than existing\nbenchmarks, and UniScore aligns closely with human evaluations, surpassing\ncurrent metrics. Moreover, we extensively evaluated SoTA unified and visual\ngeneration models, uncovering new insights into Univeral's unique values."}
{"id": "2505.10472", "pdf": "https://arxiv.org/pdf/2505.10472", "abs": "https://arxiv.org/abs/2505.10472", "authors": ["Agnik Saha", "Victoria Churchill", "Anny D. Rodriguez", "Ugur Kursuncu", "Muhammed Y. Idris"], "title": "Large Language Models for Cancer Communication: Evaluating Linguistic Quality, Safety, and Accessibility in Generative AI", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Effective communication about breast and cervical cancers remains a\npersistent health challenge, with significant gaps in public understanding of\ncancer prevention, screening, and treatment, potentially leading to delayed\ndiagnoses and inadequate treatments. This study evaluates the capabilities and\nlimitations of Large Language Models (LLMs) in generating accurate, safe, and\naccessible cancer-related information to support patient understanding. We\nevaluated five general-purpose and three medical LLMs using a mixed-methods\nevaluation framework across linguistic quality, safety and trustworthiness, and\ncommunication accessibility and affectiveness. Our approach utilized\nquantitative metrics, qualitative expert ratings, and statistical analysis\nusing Welch's ANOVA, Games-Howell, and Hedges' g. Our results show that\ngeneral-purpose LLMs produced outputs of higher linguistic quality and\naffectiveness, while medical LLMs demonstrate greater communication\naccessibility. However, medical LLMs tend to exhibit higher levels of potential\nharm, toxicity, and bias, reducing their performance in safety and\ntrustworthiness. Our findings indicate a duality between domain-specific\nknowledge and safety in health communications. The results highlight the need\nfor intentional model design with targeted improvements, particularly in\nmitigating harm and bias, and improving safety and affectiveness. This study\nprovides a comprehensive evaluation of LLMs for cancer communication, offering\ncritical insights for improving AI-generated health content and informing\nfuture development of accurate, safe, and accessible digital health tools."}
{"id": "2505.10515", "pdf": "https://arxiv.org/pdf/2505.10515", "abs": "https://arxiv.org/abs/2505.10515", "authors": ["Seongun Kim", "Sol A Kim", "Geonhyeong Kim", "Enver Menadjiev", "Chanwoo Lee", "Seongwook Chung", "Nari Kim", "Jaesik Choi"], "title": "PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, post hoc explanation methods have emerged to enhance model\ntransparency by attributing model outputs to input features. However, these\nmethods face challenges due to their specificity to certain neural network\narchitectures and data modalities. Existing explainable artificial intelligence\n(XAI) frameworks have attempted to address these challenges but suffer from\nseveral limitations. These include limited flexibility to diverse model\narchitectures and data modalities due to hard-coded implementations, a\nrestricted number of supported XAI methods because of the requirements for\nlayer-specific operations of attribution methods, and sub-optimal\nrecommendations of explanations due to the lack of evaluation and optimization\nphases. Consequently, these limitations impede the adoption of XAI technology\nin real-world applications, making it difficult for practitioners to select the\noptimal explanation method for their domain. To address these limitations, we\nintroduce \\textbf{PnPXAI}, a universal XAI framework that supports diverse data\nmodalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI\nautomatically detects model architectures, recommends applicable explanation\nmethods, and optimizes hyperparameters for optimal explanations. We validate\nthe framework's effectiveness through user surveys and showcase its versatility\nacross various domains, including medicine and finance."}
{"id": "2505.10475", "pdf": "https://arxiv.org/pdf/2505.10475", "abs": "https://arxiv.org/abs/2505.10475", "authors": ["Mouxiang Chen", "Binyuan Hui", "Zeyu Cui", "Jiaxi Yang", "Dayiheng Liu", "Jianling Sun", "Junyang Lin", "Zhongxin Liu"], "title": "Parallel Scaling Law for Language Models", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "It is commonly believed that scaling language models should commit a\nsignificant space or time cost, by increasing the parameters (parameter\nscaling) or output tokens (inference-time scaling). We introduce the third and\nmore inference-efficient scaling paradigm: increasing the model's parallel\ncomputation during both training and inference time. We apply $P$ diverse and\nlearnable transformations to the input, execute forward passes of the model in\nparallel, and dynamically aggregate the $P$ outputs. This method, namely\nparallel scaling (ParScale), scales parallel computation by reusing existing\nparameters and can be applied to any model structure, optimization procedure,\ndata, or task. We theoretically propose a new scaling law and validate it\nthrough large-scale pre-training, which shows that a model with $P$ parallel\nstreams is similar to scaling the parameters by $O(\\log P)$ while showing\nsuperior inference efficiency. For example, ParScale can use up to 22$\\times$\nless memory increase and 6$\\times$ less latency increase compared to parameter\nscaling that achieves the same performance improvement. It can also recycle an\noff-the-shelf pre-trained model into a parallelly scaled one by post-training\non a small amount of tokens, further reducing the training budget. The new\nscaling law we discovered potentially facilitates the deployment of more\npowerful models in low-resource scenarios, and provides an alternative\nperspective for the role of computation in machine learning."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.10482", "pdf": "https://arxiv.org/pdf/2505.10482", "abs": "https://arxiv.org/abs/2505.10482", "authors": ["Ningyuan Yang", "Jiaxuan Gao", "Feng Gao", "Yi Wu", "Chao Yu"], "title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages for main text, 23 pages in total, submitted to Neurips, 13\n  figures", "summary": "Diffusion policies, widely adopted in decision-making scenarios such as\nrobotics, gaming and autonomous driving, are capable of learning diverse skills\nfrom demonstration data due to their high representation power. However, the\nsub-optimal and limited coverage of demonstration data could lead to diffusion\npolicies that generate sub-optimal trajectories and even catastrophic failures.\nWhile reinforcement learning (RL)-based fine-tuning has emerged as a promising\nsolution to address these limitations, existing approaches struggle to\neffectively adapt Proximal Policy Optimization (PPO) to diffusion models. This\nchallenge stems from the computational intractability of action likelihood\nestimation during the denoising process, which leads to complicated\noptimization objectives. In our experiments starting from randomly initialized\npolicies, we find that online tuning of Diffusion Policies demonstrates much\nlower sample efficiency compared to directly applying PPO on MLP policies\n(MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework\nthat reformulates Diffusion Policy as a noise-conditioned deterministic policy.\nBy treating each denoising step as a differentiable transformation conditioned\non pre-sampled noise, NCDPO enables tractable likelihood evaluation and\ngradient backpropagation through all diffusion timesteps. Our experiments\ndemonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when\ntraining from scratch, outperforming existing methods in both sample efficiency\nand final performance across diverse benchmarks, including continuous robot\ncontrol and multi-agent game scenarios. Furthermore, our experimental results\nshow that our method is robust to the number denoising timesteps in the\nDiffusion Policy."}
{"id": "2505.10551", "pdf": "https://arxiv.org/pdf/2505.10551", "abs": "https://arxiv.org/abs/2505.10551", "authors": ["Yiwen Liu", "Jessica Bader", "Jae Myung Kim"], "title": "Does Feasibility Matter? Understanding the Impact of Feasibility on Synthetic Training Data", "categories": ["cs.CV", "cs.AI"], "comment": "CVPRW 2025", "summary": "With the development of photorealistic diffusion models, models trained in\npart or fully on synthetic data achieve progressively better results. However,\ndiffusion models still routinely generate images that would not exist in\nreality, such as a dog floating above the ground or with unrealistic texture\nartifacts. We define the concept of feasibility as whether attributes in a\nsynthetic image could realistically exist in the real-world domain; synthetic\nimages containing attributes that violate this criterion are considered\ninfeasible. Intuitively, infeasible images are typically considered\nout-of-distribution; thus, training on such images is expected to hinder a\nmodel's ability to generalize to real-world data, and they should therefore be\nexcluded from the training set whenever possible. However, does feasibility\nreally matter? In this paper, we investigate whether enforcing feasibility is\nnecessary when generating synthetic training data for CLIP-based classifiers,\nfocusing on three target attributes: background, color, and texture. We\nintroduce VariReal, a pipeline that minimally edits a given source image to\ninclude feasible or infeasible attributes given by the textual prompt generated\nby a large language model. Our experiments show that feasibility minimally\naffects LoRA-fine-tuned CLIP performance, with mostly less than 0.3% difference\nin top-1 accuracy across three fine-grained datasets. Also, the attribute\nmatters on whether the feasible/infeasible images adversarially influence the\nclassification performance. Finally, mixing feasible and infeasible images in\ntraining datasets does not significantly impact performance compared to using\npurely feasible or infeasible datasets."}
{"id": "2505.10484", "pdf": "https://arxiv.org/pdf/2505.10484", "abs": "https://arxiv.org/abs/2505.10484", "authors": ["Andrea Baisero", "Rupali Bhati", "Shuo Liu", "Aathira Pillai", "Christopher Amato"], "title": "Fixing Incomplete Value Function Decomposition for Multi-Agent Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Value function decomposition methods for cooperative multi-agent\nreinforcement learning compose joint values from individual per-agent\nutilities, and train them using a joint objective. To ensure that the action\nselection process between individual utilities and joint values remains\nconsistent, it is imperative for the composition to satisfy the\nindividual-global max (IGM) property. Although satisfying IGM itself is\nstraightforward, most existing methods (e.g., VDN, QMIX) have limited\nrepresentation capabilities and are unable to represent the full class of IGM\nvalues, and the one exception that has no such limitation (QPLEX) is\nunnecessarily complex. In this work, we present a simple formulation of the\nfull class of IGM values that naturally leads to the derivation of QFIX, a\nnovel family of value function decomposition models that expand the\nrepresentation capabilities of prior models by means of a thin \"fixing\" layer.\nWe derive multiple variants of QFIX, and implement three variants in two\nwell-known multi-agent frameworks. We perform an empirical evaluation on\nmultiple SMACv2 and Overcooked environments, which confirms that QFIX (i)\nsucceeds in enhancing the performance of prior methods, (ii) learns more stably\nand performs better than its main competitor QPLEX, and (iii) achieves this\nwhile employing the simplest and smallest mixing models."}
{"id": "2505.10557", "pdf": "https://arxiv.org/pdf/2505.10557", "abs": "https://arxiv.org/abs/2505.10557", "authors": ["Ke Wang", "Junting Pan", "Linda Wei", "Aojun Zhou", "Weikang Shi", "Zimu Lu", "Han Xiao", "Yunqiao Yang", "Houxing Ren", "Mingjie Zhan", "Hongsheng Li"], "title": "MathCoder-VL: Bridging Vision and Code for Enhanced Multimodal Mathematical Reasoning", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "Accepted to ACL 2025 Findings", "summary": "Natural language image-caption datasets, widely used for training Large\nMultimodal Models, mainly focus on natural scenarios and overlook the intricate\ndetails of mathematical figures that are critical for problem-solving,\nhindering the advancement of current LMMs in multimodal mathematical reasoning.\nTo this end, we propose leveraging code as supervision for cross-modal\nalignment, since code inherently encodes all information needed to generate\ncorresponding figures, establishing a precise connection between the two\nmodalities. Specifically, we co-develop our image-to-code model and dataset\nwith model-in-the-loop approach, resulting in an image-to-code model,\nFigCodifier and ImgCode-8.6M dataset, the largest image-code dataset to date.\nFurthermore, we utilize FigCodifier to synthesize novel mathematical figures\nand then construct MM-MathInstruct-3M, a high-quality multimodal math\ninstruction fine-tuning dataset. Finally, we present MathCoder-VL, trained with\nImgCode-8.6M for cross-modal alignment and subsequently fine-tuned on\nMM-MathInstruct-3M for multimodal math problem solving. Our model achieves a\nnew open-source SOTA across all six metrics. Notably, it surpasses GPT-4o and\nClaude 3.5 Sonnet in the geometry problem-solving subset of MathVista,\nachieving improvements of 8.9% and 9.2%. The dataset and models will be\nreleased at https://github.com/mathllm/MathCoder."}
{"id": "2505.10495", "pdf": "https://arxiv.org/pdf/2505.10495", "abs": "https://arxiv.org/abs/2505.10495", "authors": ["Vibha Belavadi", "Tushar Vatsa", "Dewang Sultania", "Suhas Suresha", "Ishita Verma", "Cheng Chen", "Tracy Holloway King", "Michael Friedrich"], "title": "RouteNator: A Router-Based Multi-Modal Architecture for Generating Synthetic Training Data for Function Calling LLMs", "categories": ["cs.LG", "cs.CL"], "comment": "Proceedings of the 4th International Workshop on Knowledge-Augmented\n  Methods for Natural Language Processing", "summary": "This paper addresses fine-tuning Large Language Models (LLMs) for function\ncalling tasks when real user interaction data is unavailable. In digital\ncontent creation tools, where users express their needs through natural\nlanguage queries that must be mapped to API calls, the lack of real-world\ntask-specific data and privacy constraints for training on it necessitate\nsynthetic data generation. Existing approaches to synthetic data generation\nfall short in diversity and complexity, failing to replicate real-world data\ndistributions and leading to suboptimal performance after LLM fine-tuning. We\npresent a novel router-based architecture that leverages domain resources like\ncontent metadata and structured knowledge graphs, along with text-to-text and\nvision-to-text language models to generate high-quality synthetic training\ndata. Our architecture's flexible routing mechanism enables synthetic data\ngeneration that matches observed real-world distributions, addressing a\nfundamental limitation of traditional approaches. Evaluation on a comprehensive\nset of real user queries demonstrates significant improvements in both function\nclassification accuracy and API parameter selection. Models fine-tuned with our\nsynthetic data consistently outperform traditional approaches, establishing new\nbenchmarks for function calling tasks."}
{"id": "2505.10559", "pdf": "https://arxiv.org/pdf/2505.10559", "abs": "https://arxiv.org/abs/2505.10559", "authors": ["Ziming Liu", "Yizhou Liu", "Jeff Gore", "Max Tegmark"], "title": "Neural Thermodynamic Laws for Large Language Model Training", "categories": ["cs.LG", "cs.AI", "physics.data-an", "stat.ML"], "comment": "18 pages, 10 figures", "summary": "Beyond neural scaling laws, little is known about the laws underlying large\nlanguage models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new\nframework that offers fresh insights into LLM training dynamics. On the\ntheoretical side, we demonstrate that key thermodynamic quantities (e.g.,\ntemperature, entropy, heat capacity, thermal conduction) and classical\nthermodynamic principles (e.g., the three laws of thermodynamics and the\nequipartition theorem) naturally emerge under river-valley loss landscape\nassumptions. On the practical side, this scientific perspective yields\nintuitive guidelines for designing learning rate schedules."}
{"id": "2505.10515", "pdf": "https://arxiv.org/pdf/2505.10515", "abs": "https://arxiv.org/abs/2505.10515", "authors": ["Seongun Kim", "Sol A Kim", "Geonhyeong Kim", "Enver Menadjiev", "Chanwoo Lee", "Seongwook Chung", "Nari Kim", "Jaesik Choi"], "title": "PnPXAI: A Universal XAI Framework Providing Automatic Explanations Across Diverse Modalities and Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Recently, post hoc explanation methods have emerged to enhance model\ntransparency by attributing model outputs to input features. However, these\nmethods face challenges due to their specificity to certain neural network\narchitectures and data modalities. Existing explainable artificial intelligence\n(XAI) frameworks have attempted to address these challenges but suffer from\nseveral limitations. These include limited flexibility to diverse model\narchitectures and data modalities due to hard-coded implementations, a\nrestricted number of supported XAI methods because of the requirements for\nlayer-specific operations of attribution methods, and sub-optimal\nrecommendations of explanations due to the lack of evaluation and optimization\nphases. Consequently, these limitations impede the adoption of XAI technology\nin real-world applications, making it difficult for practitioners to select the\noptimal explanation method for their domain. To address these limitations, we\nintroduce \\textbf{PnPXAI}, a universal XAI framework that supports diverse data\nmodalities and neural network models in a Plug-and-Play (PnP) manner. PnPXAI\nautomatically detects model architectures, recommends applicable explanation\nmethods, and optimizes hyperparameters for optimal explanations. We validate\nthe framework's effectiveness through user surveys and showcase its versatility\nacross various domains, including medicine and finance."}
{"id": "2505.10526", "pdf": "https://arxiv.org/pdf/2505.10526", "abs": "https://arxiv.org/abs/2505.10526", "authors": ["Mugilan Ganesan", "Shane Segal", "Ankur Aggarwal", "Nish Sinnadurai", "Sean Lie", "Vithursan Thangarasa"], "title": "MASSV: Multimodal Adaptation and Self-Data Distillation for Speculative Decoding of Vision-Language Models", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "Main paper: 11 pp., 4 figs., 3 tabs.; Supplementary: 2 pp", "summary": "Speculative decoding significantly accelerates language model inference by\nenabling a lightweight draft model to propose multiple tokens that a larger\ntarget model verifies simultaneously. However, applying this technique to\nvision-language models (VLMs) presents two fundamental challenges: small\nlanguage models that could serve as efficient drafters lack the architectural\ncomponents to process visual inputs, and their token predictions fail to match\nthose of VLM target models that consider visual context. We introduce\nMultimodal Adaptation and Self-Data Distillation for Speculative Decoding of\nVision-Language Models (MASSV), which transforms existing small language models\ninto effective multimodal drafters through a two-phase approach. MASSV first\nconnects the target VLM's vision encoder to the draft model via a lightweight\ntrainable projector, then applies self-distilled visual instruction tuning\nusing responses generated by the target VLM to align token predictions.\nComprehensive experiments across the Qwen2.5-VL and Gemma3 model families\ndemonstrate that MASSV increases accepted length by up to 30% and delivers\nend-to-end inference speedups of up to 1.46x on visually-grounded tasks. MASSV\nprovides a scalable, architecture-compatible method for accelerating both\ncurrent and future VLMs."}
{"id": "2505.10545", "pdf": "https://arxiv.org/pdf/2505.10545", "abs": "https://arxiv.org/abs/2505.10545", "authors": ["Amira Alakhdar", "Barnabas Poczos", "Newell Washburn"], "title": "Pharmacophore-Conditioned Diffusion Model for Ligand-Based De Novo Drug Design", "categories": ["cs.LG"], "comment": null, "summary": "Developing bioactive molecules remains a central, time- and cost-heavy\nchallenge in drug discovery, particularly for novel targets lacking structural\nor functional data. Pharmacophore modeling presents an alternative for\ncapturing the key features required for molecular bioactivity against a\nbiological target. In this work, we present PharmaDiff, a\npharmacophore-conditioned diffusion model for 3D molecular generation.\nPharmaDiff employs a transformer-based architecture to integrate an atom-based\nrepresentation of the 3D pharmacophore into the generative process, enabling\nthe precise generation of 3D molecular graphs that align with predefined\npharmacophore hypotheses. Through comprehensive testing, PharmaDiff\ndemonstrates superior performance in matching 3D pharmacophore constraints\ncompared to ligand-based drug design methods. Additionally, it achieves higher\ndocking scores across a range of proteins in structure-based drug design,\nwithout the need for target protein structures. By integrating pharmacophore\nmodeling with 3D generative techniques, PharmaDiff offers a powerful and\nflexible framework for rational drug design."}
{"id": "2505.10556", "pdf": "https://arxiv.org/pdf/2505.10556", "abs": "https://arxiv.org/abs/2505.10556", "authors": ["Nazanin Zounemat Kermani", "Sadjad Naderi", "Claire H. Dilliway", "Claire E. Heaney", "Shrreya Behll", "Boyang Chen", "Hisham Abubakar-Waziri", "Alexandra E. Porter", "Marc Chadeau-Hyam", "Fangxin Fang", "Ian M. Adcock", "Kian Fan Chung", "Christopher C. Pain"], "title": "An AI-driven framework for the prediction of personalised health response to air pollution", "categories": ["cs.LG", "physics.ao-ph"], "comment": "Kermani and Naderi share first authorship. 20 pages, 6 figures and 1\n  table", "summary": "Air pollution poses a significant threat to public health, causing or\nexacerbating many respiratory and cardiovascular diseases. In addition, climate\nchange is bringing about more extreme weather events such as wildfires and\nheatwaves, which can increase levels of pollution and worsen the effects of\npollution exposure. Recent advances in personal sensing have transformed the\ncollection of behavioural and physiological data, leading to the potential for\nnew improvements in healthcare. We wish to capitalise on this data, alongside\nnew capabilities in AI for making time series predictions, in order to monitor\nand predict health outcomes for an individual. Thus, we present a novel\nworkflow for predicting personalised health responses to pollution by\nintegrating physiological data from wearable fitness devices with real-time\nenvironmental exposures. The data is collected from various sources in a secure\nand ethical manner, and is used to train an AI model to predict individual\nhealth responses to pollution exposure within a cloud-based, modular framework.\nWe demonstrate that the AI model -- an Adversarial Autoencoder neural network\nin this case -- accurately reconstructs time-dependent health signals and\ncaptures nonlinear responses to pollution. Transfer learning is applied using\ndata from a personal smartwatch, which increases the generalisation abilities\nof the AI model and illustrates the adaptability of the approach to real-world,\nuser-generated data."}
{"id": "2505.10559", "pdf": "https://arxiv.org/pdf/2505.10559", "abs": "https://arxiv.org/abs/2505.10559", "authors": ["Ziming Liu", "Yizhou Liu", "Jeff Gore", "Max Tegmark"], "title": "Neural Thermodynamic Laws for Large Language Model Training", "categories": ["cs.LG", "cs.AI", "physics.data-an", "stat.ML"], "comment": "18 pages, 10 figures", "summary": "Beyond neural scaling laws, little is known about the laws underlying large\nlanguage models (LLMs). We introduce Neural Thermodynamic Laws (NTL) -- a new\nframework that offers fresh insights into LLM training dynamics. On the\ntheoretical side, we demonstrate that key thermodynamic quantities (e.g.,\ntemperature, entropy, heat capacity, thermal conduction) and classical\nthermodynamic principles (e.g., the three laws of thermodynamics and the\nequipartition theorem) naturally emerge under river-valley loss landscape\nassumptions. On the practical side, this scientific perspective yields\nintuitive guidelines for designing learning rate schedules."}
{"id": "2505.09649", "pdf": "https://arxiv.org/pdf/2505.09649", "abs": "https://arxiv.org/abs/2505.09649", "authors": ["Abisha Thapa Magar", "Anup Shakya"], "title": "Next Word Suggestion using Graph Neural Network", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Language Modeling is a prevalent task in Natural Language Processing. The\ncurrently existing most recent and most successful language models often tend\nto build a massive model with billions of parameters, feed in a tremendous\namount of text data, and train with enormous computation resources which\nrequire millions of dollars. In this project, we aim to address an important\nsub-task in language modeling, i.e., context embedding. We propose an approach\nto exploit the Graph Convolution operation in GNNs to encode the context and\nuse it in coalition with LSTMs to predict the next word given a local context\nof preceding words. We test this on the custom Wikipedia text corpus using a\nvery limited amount of resources and show that this approach works fairly well\nto predict the next word."}
{"id": "2505.09666", "pdf": "https://arxiv.org/pdf/2505.09666", "abs": "https://arxiv.org/abs/2505.09666", "authors": ["Yumin Choi", "Jinheon Baek", "Sung Ju Hwang"], "title": "System Prompt Optimization with Meta-Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have shown remarkable capabilities, with\noptimizing their input prompts playing a pivotal role in maximizing their\nperformance. However, while LLM prompts consist of both the task-agnostic\nsystem prompts and task-specific user prompts, existing work on prompt\noptimization has focused on user prompts specific to individual queries or\ntasks, and largely overlooked the system prompt that is, once optimized,\napplicable across different tasks and domains. Motivated by this, we introduce\nthe novel problem of bilevel system prompt optimization, whose objective is to\ndesign system prompts that are robust to diverse user prompts and transferable\nto unseen tasks. To tackle this problem, we then propose a meta-learning\nframework, which meta-learns the system prompt by optimizing it over various\nuser prompts across multiple datasets, while simultaneously updating the user\nprompts in an iterative manner to ensure synergy between them. We conduct\nexperiments on 14 unseen datasets spanning 5 different domains, on which we\nshow that our approach produces system prompts that generalize effectively to\ndiverse user prompts. Also, our findings reveal that the optimized system\nprompt enables rapid adaptation even to unseen tasks, requiring fewer\noptimization steps for test-time user prompts while achieving improved\nperformance."}
{"id": "2505.09932", "pdf": "https://arxiv.org/pdf/2505.09932", "abs": "https://arxiv.org/abs/2505.09932", "authors": ["Kevin J McNamara", "Rhea Pritham Marpu"], "title": "Demystifying AI Agents: The Final Generation of Intelligence", "categories": ["cs.AI", "cs.ET", "cs.LG", "cs.MA"], "comment": null, "summary": "The trajectory of artificial intelligence (AI) has been one of relentless\nacceleration, evolving from rudimentary rule-based systems to sophisticated,\nautonomous agents capable of complex reasoning and interaction. This whitepaper\nchronicles this remarkable journey, charting the key technological\nmilestones--advancements in prompting, training methodologies, hardware\ncapabilities, and architectural innovations--that have converged to create the\nAI agents of today. We argue that these agents, exemplified by systems like\nOpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in\nAI development, potentially constituting the \"final generation\" of intelligence\nas we currently conceive it. We explore the capabilities and underlying\ntechnologies of these agents, grounded in practical examples, while also\nexamining the profound societal implications and the unprecedented pace of\nprogress that suggests intelligence is now doubling approximately every six\nmonths. The paper concludes by underscoring the critical need for wisdom and\nforesight in navigating the opportunities and challenges presented by this\npowerful new era of intelligence."}
{"id": "2505.09935", "pdf": "https://arxiv.org/pdf/2505.09935", "abs": "https://arxiv.org/abs/2505.09935", "authors": ["Ahmed S. Abdelrahman", "Mohamed Abdel-Aty", "Quoc Dai Tran"], "title": "VRU-CIPI: Crossing Intention Prediction at Intersections for Improving Vulnerable Road Users Safety", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Understanding and predicting human behavior in-thewild, particularly at urban\nintersections, remains crucial for enhancing interaction safety between road\nusers. Among the most critical behaviors are crossing intentions of Vulnerable\nRoad Users (VRUs), where misinterpretation may result in dangerous conflicts\nwith oncoming vehicles. In this work, we propose the VRU-CIPI framework with a\nsequential attention-based model designed to predict VRU crossing intentions at\nintersections. VRU-CIPI employs Gated Recurrent Unit (GRU) to capture temporal\ndynamics in VRU movements, combined with a multi-head Transformer\nself-attention mechanism to encode contextual and spatial dependencies critical\nfor predicting crossing direction. Evaluated on UCF-VRU dataset, our proposed\nachieves state-of-the-art performance with an accuracy of 96.45% and achieving\nreal-time inference speed reaching 33 frames per second. Furthermore, by\nintegrating with Infrastructure-to-Vehicles (I2V) communication, our approach\ncan proactively enhance intersection safety through timely activation of\ncrossing signals and providing early warnings to connected vehicles, ensuring\nsmoother and safer interactions for all road users."}
{"id": "2505.09945", "pdf": "https://arxiv.org/pdf/2505.09945", "abs": "https://arxiv.org/abs/2505.09945", "authors": ["Deeksha Prahlad", "Chanhee Lee", "Dongha Kim", "Hokeun Kim"], "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "To appear in the Companion Proceedings of the ACM Web Conference 2025\n  (WWW Companion '25)", "summary": "The advent of large language models (LLMs) has allowed numerous applications,\nincluding the generation of queried responses, to be leveraged in chatbots and\nother conversational assistants. Being trained on a plethora of data, LLMs\noften undergo high levels of over-fitting, resulting in the generation of extra\nand incorrect data, thus causing hallucinations in output generation. One of\nthe root causes of such problems is the lack of timely, factual, and\npersonalized information fed to the LLM. In this paper, we propose an approach\nto address these problems by introducing retrieval augmented generation (RAG)\nusing knowledge graphs (KGs) to assist the LLM in personalized response\ngeneration tailored to the users. KGs have the advantage of storing\ncontinuously updated factual information in a structured way. While our KGs can\nbe used for a variety of frequently updated personal data, such as calendar,\ncontact, and location data, we focus on calendar data in this paper. Our\nexperimental results show that our approach works significantly better in\nunderstanding personal information and generating accurate responses compared\nto the baseline LLMs using personal data as text inputs, with a moderate\nreduction in response time."}
{"id": "2505.10030", "pdf": "https://arxiv.org/pdf/2505.10030", "abs": "https://arxiv.org/abs/2505.10030", "authors": ["Miit Daga", "Dhriti Parikh", "Swarna Priya Ramu"], "title": "DeepSeqCoco: A Robust Mobile Friendly Deep Learning Model for Detection of Diseases in Cocos nucifera", "categories": ["cs.CV", "cs.LG"], "comment": "This paper is accepted for publication in IEEE Access journal and is\n  currently pending revisions before publication", "summary": "Coconut tree diseases are a serious risk to agricultural yield, particularly\nin developing countries where conventional farming practices restrict early\ndiagnosis and intervention. Current disease identification methods are manual,\nlabor-intensive, and non-scalable. In response to these limitations, we come up\nwith DeepSeqCoco, a deep learning based model for accurate and automatic\ndisease identification from coconut tree images. The model was tested under\nvarious optimizer settings, such as SGD, Adam, and hybrid configurations, to\nidentify the optimal balance between accuracy, minimization of loss, and\ncomputational cost. Results from experiments indicate that DeepSeqCoco can\nachieve as much as 99.5% accuracy (achieving up to 5% higher accuracy than\nexisting models) with the hybrid SGD-Adam showing the lowest validation loss of\n2.81%. It also shows a drop of up to 18% in training time and up to 85% in\nprediction time for input images. The results point out the promise of the\nmodel to improve precision agriculture through an AI-based, scalable, and\nefficient disease monitoring system."}
{"id": "2505.10066", "pdf": "https://arxiv.org/pdf/2505.10066", "abs": "https://arxiv.org/abs/2505.10066", "authors": ["Michael Fire", "Yitzhak Elbazis", "Adi Wasenstein", "Lior Rokach"], "title": "Dark LLMs: The Growing Threat of Unaligned AI Models", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG", "68T50, 68T05, 68P25", "I.2.7"], "comment": null, "summary": "Large Language Models (LLMs) rapidly reshape modern life, advancing fields\nfrom healthcare to education and beyond. However, alongside their remarkable\ncapabilities lies a significant threat: the susceptibility of these models to\njailbreaking. The fundamental vulnerability of LLMs to jailbreak attacks stems\nfrom the very data they learn from. As long as this training data includes\nunfiltered, problematic, or 'dark' content, the models can inherently learn\nundesirable patterns or weaknesses that allow users to circumvent their\nintended safety controls. Our research identifies the growing threat posed by\ndark LLMs models deliberately designed without ethical guardrails or modified\nthrough jailbreak techniques. In our research, we uncovered a universal\njailbreak attack that effectively compromises multiple state-of-the-art models,\nenabling them to answer almost any question and produce harmful outputs upon\nrequest. The main idea of our attack was published online over seven months\nago. However, many of the tested LLMs were still vulnerable to this attack.\nDespite our responsible disclosure efforts, responses from major LLM providers\nwere often inadequate, highlighting a concerning gap in industry practices\nregarding AI safety. As model training becomes more accessible and cheaper, and\nas open-source LLMs proliferate, the risk of widespread misuse escalates.\nWithout decisive intervention, LLMs may continue democratizing access to\ndangerous knowledge, posing greater risks than anticipated."}
{"id": "2505.10169", "pdf": "https://arxiv.org/pdf/2505.10169", "abs": "https://arxiv.org/abs/2505.10169", "authors": ["Matthias Kümmerer", "Harneet Khanuja", "Matthias Bethge"], "title": "Modeling Saliency Dataset Bias", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "Recent advances in image-based saliency prediction are approaching gold\nstandard performance levels on existing benchmarks. Despite this success, we\nshow that predicting fixations across multiple saliency datasets remains\nchallenging due to dataset bias. We find a significant performance drop (around\n40%) when models trained on one dataset are applied to another. Surprisingly,\nincreasing dataset diversity does not resolve this inter-dataset gap, with\nclose to 60% attributed to dataset-specific biases. To address this remaining\ngeneralization gap, we propose a novel architecture extending a mostly\ndataset-agnostic encoder-decoder structure with fewer than 20 dataset-specific\nparameters that govern interpretable mechanisms such as multi-scale structure,\ncenter bias, and fixation spread. Adapting only these parameters to new data\naccounts for more than 75% of the generalization gap, with a large fraction of\nthe improvement achieved with as few as 50 samples. Our model sets a new\nstate-of-the-art on all three datasets of the MIT/Tuebingen Saliency Benchmark\n(MIT300, CAT2000, and COCO-Freeview), even when purely generalizing from\nunrelated datasets, but with a substantial boost when adapting to the\nrespective training datasets. The model also provides valuable insights into\nspatial saliency properties, revealing complex multi-scale effects that combine\nboth absolute and relative sizes."}
{"id": "2505.10182", "pdf": "https://arxiv.org/pdf/2505.10182", "abs": "https://arxiv.org/abs/2505.10182", "authors": ["Yoichi Ishibashi", "Taro Yano", "Masafumi Oyamada"], "title": "Mining Hidden Thoughts from Texts: Evaluating Continual Pretraining with Synthetic Data for LLM Reasoning", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated significant improvements in\nreasoning capabilities through supervised fine-tuning and reinforcement\nlearning. However, when training reasoning models, these approaches are\nprimarily applicable to specific domains such as mathematics and programming,\nwhich imposes fundamental constraints on the breadth and scalability of\ntraining data. In contrast, continual pretraining (CPT) offers the advantage of\nnot requiring task-specific signals. Nevertheless, how to effectively\nsynthesize training data for reasoning and how such data affect a wide range of\ndomains remain largely unexplored. This study provides a detailed evaluation of\nReasoning CPT, a form of CPT that uses synthetic data to reconstruct the hidden\nthought processes underlying texts, based on the premise that texts are the\nresult of the author's thinking process. Specifically, we apply Reasoning CPT\nto Gemma2-9B using synthetic data with hidden thoughts derived from STEM and\nLaw corpora, and compare it to standard CPT on the MMLU benchmark. Our analysis\nreveals that Reasoning CPT consistently improves performance across all\nevaluated domains. Notably, reasoning skills acquired in one domain transfer\neffectively to others; the performance gap with conventional methods widens as\nproblem difficulty increases, with gains of up to 8 points on the most\nchallenging problems. Furthermore, models trained with hidden thoughts learn to\nadjust the depth of their reasoning according to problem difficulty."}
{"id": "2505.10223", "pdf": "https://arxiv.org/pdf/2505.10223", "abs": "https://arxiv.org/abs/2505.10223", "authors": ["Puru Vaish", "Felix Meister", "Tobias Heimann", "Christoph Brune", "Jelmer M. Wolterink"], "title": "Data-Agnostic Augmentations for Unknown Variations: Out-of-Distribution Generalisation in MRI Segmentation", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted at MIDL 2025", "summary": "Medical image segmentation models are often trained on curated datasets,\nleading to performance degradation when deployed in real-world clinical\nsettings due to mismatches between training and test distributions. While data\naugmentation techniques are widely used to address these challenges,\ntraditional visually consistent augmentation strategies lack the robustness\nneeded for diverse real-world scenarios. In this work, we systematically\nevaluate alternative augmentation strategies, focusing on MixUp and Auxiliary\nFourier Augmentation. These methods mitigate the effects of multiple variations\nwithout explicitly targeting specific sources of distribution shifts. We\ndemonstrate how these techniques significantly improve out-of-distribution\ngeneralization and robustness to imaging variations across a wide range of\ntransformations in cardiac cine MRI and prostate MRI segmentation. We\nquantitatively find that these augmentation methods enhance learned feature\nrepresentations by promoting separability and compactness. Additionally, we\nhighlight how their integration into nnU-Net training pipelines provides an\neasy-to-implement, effective solution for enhancing the reliability of medical\nsegmentation models in real-world applications."}
{"id": "2505.10267", "pdf": "https://arxiv.org/pdf/2505.10267", "abs": "https://arxiv.org/abs/2505.10267", "authors": ["Pavel Korotaev", "Petr Surovtsev", "Alexander Kapitanov", "Karina Kvanchiani", "Aleksandr Nagaev"], "title": "HandReader: Advanced Techniques for Efficient Fingerspelling Recognition", "categories": ["cs.CV", "cs.LG"], "comment": "https://github.com/ai-forever/handreader", "summary": "Fingerspelling is a significant component of Sign Language (SL), allowing the\ninterpretation of proper names, characterized by fast hand movements during\nsigning. Although previous works on fingerspelling recognition have focused on\nprocessing the temporal dimension of videos, there remains room for improving\nthe accuracy of these approaches. This paper introduces HandReader, a group of\nthree architectures designed to address the fingerspelling recognition task.\nHandReader$_{RGB}$ employs the novel Temporal Shift-Adaptive Module (TSAM) to\nprocess RGB features from videos of varying lengths while preserving important\nsequential information. HandReader$_{KP}$ is built on the proposed Temporal\nPose Encoder (TPE) operated on keypoints as tensors. Such keypoints composition\nin a batch allows the encoder to pass them through 2D and 3D convolution\nlayers, utilizing temporal and spatial information and accumulating keypoints\ncoordinates. We also introduce HandReader_RGB+KP - architecture with a joint\nencoder to benefit from RGB and keypoint modalities. Each HandReader model\npossesses distinct advantages and achieves state-of-the-art results on the\nChicagoFSWild and ChicagoFSWild+ datasets. Moreover, the models demonstrate\nhigh performance on the first open dataset for Russian fingerspelling, Znaki,\npresented in this paper. The Znaki dataset and HandReader pre-trained models\nare publicly available."}
{"id": "2505.10320", "pdf": "https://arxiv.org/pdf/2505.10320", "abs": "https://arxiv.org/abs/2505.10320", "authors": ["Chenxi Whitehouse", "Tianlu Wang", "Ping Yu", "Xian Li", "Jason Weston", "Ilia Kulikov", "Swarnadeep Saha"], "title": "J1: Incentivizing Thinking in LLM-as-a-Judge via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "10 pages, 8 tables, 11 figures", "summary": "The progress of AI is bottlenecked by the quality of evaluation, and powerful\nLLM-as-a-Judge models have proved to be a core solution. Improved judgment\nability is enabled by stronger chain-of-thought reasoning, motivating the need\nto find the best recipes for training such models to think. In this work we\nintroduce J1, a reinforcement learning approach to training such models. Our\nmethod converts both verifiable and non-verifiable prompts to judgment tasks\nwith verifiable rewards that incentivize thinking and mitigate judgment bias.\nIn particular, our approach outperforms all other existing 8B or 70B models\nwhen trained at those sizes, including models distilled from DeepSeek-R1. J1\nalso outperforms o1-mini, and even R1 on some benchmarks, despite training a\nsmaller model. We provide analysis and ablations comparing Pairwise-J1 vs\nPointwise-J1 models, offline vs online training recipes, reward strategies,\nseed prompts, and variations in thought length and content. We find that our\nmodels make better judgments by learning to outline evaluation criteria,\ncomparing against self-generated reference answers, and re-evaluating the\ncorrectness of model responses."}
{"id": "2505.10352", "pdf": "https://arxiv.org/pdf/2505.10352", "abs": "https://arxiv.org/abs/2505.10352", "authors": ["Shihao Zou", "Qingfeng Li", "Wei Ji", "Jingjing Li", "Yongkui Yang", "Guoqi Li", "Chao Dong"], "title": "SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\\mathcal{O}(T)$ Complexity", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Accepted by ICML 2025", "summary": "Spiking Neural Networks (SNNs) have shown competitive performance to\nArtificial Neural Networks (ANNs) in various vision tasks, while offering\nsuperior energy efficiency. However, existing SNN-based Transformers primarily\nfocus on single-image tasks, emphasizing spatial features while not effectively\nleveraging SNNs' efficiency in video-based vision tasks. In this paper, we\nintroduce SpikeVideoFormer, an efficient spike-driven video Transformer,\nfeaturing linear temporal complexity $\\mathcal{O}(T)$. Specifically, we design\na spike-driven Hamming attention (SDHA) which provides a theoretically guided\nadaptation from traditional real-valued attention to spike-driven attention.\nBuilding on SDHA, we further analyze various spike-driven space-time attention\ndesigns and identify an optimal scheme that delivers appealing performance for\nvideo tasks, while maintaining only linear temporal complexity. The\ngeneralization ability and efficiency of our model are demonstrated across\ndiverse downstream video tasks, including classification, human pose tracking,\nand semantic segmentation. Empirical results show our method achieves\nstate-of-the-art (SOTA) performance compared to existing SNN approaches, with\nover 15\\% improvement on the latter two tasks. Additionally, it matches the\nperformance of recent ANN-based methods while offering significant efficiency\ngains, achieving $\\times 16$, $\\times 10$ and $\\times 5$ improvements on the\nthree tasks. https://github.com/JimmyZou/SpikeVideoFormer"}
{"id": "2505.10361", "pdf": "https://arxiv.org/pdf/2505.10361", "abs": "https://arxiv.org/abs/2505.10361", "authors": ["David Abel", "Michael Bowling", "André Barreto", "Will Dabney", "Shi Dong", "Steven Hansen", "Anna Harutyunyan", "Khimya Khetarpal", "Clare Lyle", "Razvan Pascanu", "Georgios Piliouras", "Doina Precup", "Jonathan Richens", "Mark Rowland", "Tom Schaul", "Satinder Singh"], "title": "Plasticity as the Mirror of Empowerment", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Agents are minimally entities that are influenced by their past observations\nand act to influence future observations. This latter capacity is captured by\nempowerment, which has served as a vital framing concept across artificial\nintelligence and cognitive science. This former capacity, however, is equally\nfoundational: In what ways, and to what extent, can an agent be influenced by\nwhat it observes? In this paper, we ground this concept in a universal\nagent-centric measure that we refer to as plasticity, and reveal a fundamental\nconnection to empowerment. Following a set of desiderata on a suitable\ndefinition, we define plasticity using a new information-theoretic quantity we\ncall the generalized directed information. We show that this new quantity\nstrictly generalizes the directed information introduced by Massey (1990) while\npreserving all of its desirable properties. Our first finding is that\nplasticity is the mirror of empowerment: The agent's plasticity is identical to\nthe empowerment of the environment, and vice versa. Our second finding\nestablishes a tension between the plasticity and empowerment of an agent,\nsuggesting that agent design needs to be mindful of both characteristics. We\nexplore the implications of these findings, and suggest that plasticity,\nempowerment, and their relationship are essential to understanding agency."}
{"id": "2505.10399", "pdf": "https://arxiv.org/pdf/2505.10399", "abs": "https://arxiv.org/abs/2505.10399", "authors": ["Kaivalya Rawal", "Zihao Fu", "Eoin Delaney", "Chris Russell"], "title": "Evaluating Model Explanations without Ground Truth", "categories": ["cs.AI", "cs.LG", "I.2.6"], "comment": "https://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth", "summary": "There can be many competing and contradictory explanations for a single model\nprediction, making it difficult to select which one to use. Current explanation\nevaluation frameworks measure quality by comparing against ideal \"ground-truth\"\nexplanations, or by verifying model sensitivity to important inputs. We outline\nthe limitations of these approaches, and propose three desirable principles to\nground the future development of explanation evaluation strategies for local\nfeature importance explanations. We propose a ground-truth Agnostic eXplanation\nEvaluation framework (AXE) for evaluating and comparing model explanations that\nsatisfies these principles. Unlike prior approaches, AXE does not require\naccess to ideal ground-truth explanations for comparison, or rely on model\nsensitivity - providing an independent measure of explanation quality. We\nverify AXE by comparing with baselines, and show how it can be used to detect\nexplanation fairwashing. Our code is available at\nhttps://github.com/KaiRawal/Evaluating-Model-Explanations-without-Ground-Truth."}
{"id": "2505.10402", "pdf": "https://arxiv.org/pdf/2505.10402", "abs": "https://arxiv.org/abs/2505.10402", "authors": ["Yihong Dong", "Yuchen Liu", "Xue Jiang", "Zhi Jin", "Ge Li"], "title": "Rethinking Repetition Problems of LLMs in Code Generation", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SE"], "comment": "Accepted to ACL 2025 (main)", "summary": "With the advent of neural language models, the performance of code generation\nhas been significantly boosted. However, the problem of repetitions during the\ngeneration process continues to linger. Previous work has primarily focused on\ncontent repetition, which is merely a fraction of the broader repetition\nproblem in code generation. A more prevalent and challenging problem is\nstructural repetition. In structural repetition, the repeated code appears in\nvarious patterns but possesses a fixed structure, which can be inherently\nreflected in grammar. In this paper, we formally define structural repetition\nand propose an efficient decoding approach called RPG, which stands for\nRepetition Penalization based on Grammar, to alleviate the repetition problems\nin code generation for LLMs. Specifically, RPG first leverages grammar rules to\nidentify repetition problems during code generation, and then strategically\ndecays the likelihood of critical tokens that contribute to repetitions,\nthereby mitigating them in code generation. To facilitate this study, we\nconstruct a new dataset CodeRepetEval to comprehensively evaluate approaches\nfor mitigating the repetition problems in code generation. Extensive\nexperimental results demonstrate that RPG substantially outperforms the\nbest-performing baselines on CodeRepetEval dataset as well as HumanEval and\nMBPP benchmarks, effectively reducing repetitions and enhancing the quality of\ngenerated code."}
{"id": "2505.10518", "pdf": "https://arxiv.org/pdf/2505.10518", "abs": "https://arxiv.org/abs/2505.10518", "authors": ["Anastasios Gerontopoulos", "Spyros Gidaris", "Nikos Komodakis"], "title": "Multi-Token Prediction Needs Registers", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "comment": null, "summary": "Multi-token prediction has emerged as a promising objective for improving\nlanguage model pretraining, but its benefits have not consistently generalized\nto other settings such as fine-tuning. In this paper, we propose MuToR, a\nsimple and effective approach to multi-token prediction that interleaves\nlearnable register tokens into the input sequence, each tasked with predicting\nfuture targets. Compared to existing methods, MuToR offers several key\nadvantages: it introduces only a negligible number of additional parameters,\nrequires no architectural changes--ensuring compatibility with off-the-shelf\npretrained language models--and remains aligned with the next-token pretraining\nobjective, making it especially well-suited for supervised fine-tuning.\nMoreover, it naturally supports scalable prediction horizons. We demonstrate\nthe effectiveness and versatility of MuToR across a range of use cases,\nincluding supervised fine-tuning, parameter-efficient fine-tuning (PEFT), and\npretraining, on challenging generative tasks in both language and vision\ndomains. Our code will be available at: https://github.com/nasosger/MuToR."}
{"id": "2505.10533", "pdf": "https://arxiv.org/pdf/2505.10533", "abs": "https://arxiv.org/abs/2505.10533", "authors": ["Aaryan Sharma", "Shivansh Gupta", "Samar Agarwal", "Vishak Prasad C.", "Ganesh Ramakrishnan"], "title": "Enhancing Multi-Image Question Answering via Submodular Subset Selection", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Large multimodal models (LMMs) have achieved high performance in\nvision-language tasks involving single image but they struggle when presented\nwith a collection of multiple images (Multiple Image Question Answering\nscenario). These tasks, which involve reasoning over large number of images,\npresent issues in scalability (with increasing number of images) and retrieval\nperformance. In this work, we propose an enhancement for retriever framework\nintroduced in MIRAGE model using submodular subset selection techniques. Our\nmethod leverages query-aware submodular functions, such as GraphCut, to\npre-select a subset of semantically relevant images before main retrieval\ncomponent. We demonstrate that using anchor-based queries and augmenting the\ndata improves submodular-retriever pipeline effectiveness, particularly in\nlarge haystack sizes."}
