{"id": "2506.09176", "pdf": "https://arxiv.org/pdf/2506.09176", "abs": "https://arxiv.org/abs/2506.09176", "authors": ["Haoyuan Cai", "Zhenghao Peng", "Bolei Zhou"], "title": "Robot-Gated Interactive Imitation Learning with Adaptive Intervention Mechanism", "categories": ["cs.AI", "cs.LG", "cs.RO"], "comment": "ICML 2025 Poster", "summary": "Interactive Imitation Learning (IIL) allows agents to acquire desired\nbehaviors through human interventions, but current methods impose high\ncognitive demands on human supervisors. We propose the Adaptive Intervention\nMechanism (AIM), a novel robot-gated IIL algorithm that learns an adaptive\ncriterion for requesting human demonstrations. AIM utilizes a proxy Q-function\nto mimic the human intervention rule and adjusts intervention requests based on\nthe alignment between agent and human actions. By assigning high Q-values when\nthe agent deviates from the expert and decreasing these values as the agent\nbecomes proficient, the proxy Q-function enables the agent to assess the\nreal-time alignment with the expert and request assistance when needed. Our\nexpert-in-the-loop experiments reveal that AIM significantly reduces expert\nmonitoring efforts in both continuous and discrete control tasks. Compared to\nthe uncertainty-based baseline Thrifty-DAgger, our method achieves a 40%\nimprovement in terms of human take-over cost and learning efficiency.\nFurthermore, AIM effectively identifies safety-critical states for expert\nassistance, thereby collecting higher-quality expert demonstrations and\nreducing overall expert data and environment interactions needed. Code and demo\nvideo are available at https://github.com/metadriverse/AIM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u5e72\u9884\u673a\u5236\uff08AIM\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u7684\u673a\u5668\u4eba\u95e8\u63a7\u4ea4\u4e92\u5f0f\u6a21\u4eff\u5b66\u4e60\u7b97\u6cd5\uff0c\u5b83\u80fd\u591f\u901a\u8fc7\u4ee3\u7406Q\u51fd\u6570\u6765\u6a21\u4eff\u4eba\u7c7b\u5e72\u9884\u89c4\u5219\uff0c\u5e76\u6839\u636e\u4ee3\u7406\u548c\u4eba\u7c7b\u52a8\u4f5c\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u8c03\u6574\u5e72\u9884\u8bf7\u6c42\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u57fa\u7ebfThrifty-DAgger\u76f8\u6bd4\uff0cAIM\u5728\u51cf\u5c11\u4e13\u5bb6\u76d1\u63a7\u52aa\u529b\u3001\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u4ee5\u53ca\u8bc6\u522b\u5b89\u5168\u5173\u952e\u72b6\u6001\u65b9\u9762\u6709\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u5f53\u524d\u7684\u4ea4\u4e92\u5f0f\u6a21\u4eff\u5b66\u4e60\u65b9\u6cd5\u5bf9\u4eba\u7c7b\u76d1\u7763\u8005\u63d0\u51fa\u4e86\u9ad8\u8ba4\u77e5\u8981\u6c42\u3002\u4e3a\u4e86\u51cf\u8f7b\u8fd9\u79cd\u8d1f\u62c5\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u80fd\u66f4\u6709\u6548\u7387\u5730\u8bf7\u6c42\u4eba\u7c7b\u6f14\u793a\u7684\u65b0\u7b97\u6cd5\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u5e72\u9884\u673a\u5236\uff08AIM\uff09\uff0c\u8be5\u673a\u5236\u4f7f\u7528\u4ee3\u7406Q\u51fd\u6570\u6765\u6a21\u4eff\u4eba\u7c7b\u5e72\u9884\u89c4\u5219\uff0c\u5e76\u6839\u636e\u4ee3\u7406\u4e0e\u4eba\u7c7b\u884c\u4e3a\u7684\u4e00\u81f4\u6027\u6765\u8c03\u6574\u4f55\u65f6\u8bf7\u6c42\u4eba\u7c7b\u5e72\u9884\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAIM\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u4e13\u5bb6\u5728\u8fde\u7eed\u548c\u79bb\u6563\u63a7\u5236\u4efb\u52a1\u4e2d\u7684\u76d1\u63a7\u5de5\u4f5c\u91cf\u3002\u4e0e\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u57fa\u7ebf\u65b9\u6cd5Thrifty-DAgger\u76f8\u6bd4\uff0cAIM\u5728\u964d\u4f4e\u4eba\u7c7b\u63a5\u7ba1\u6210\u672c\u548c\u63d0\u5347\u5b66\u4e60\u6548\u7387\u4e0a\u5b9e\u73b0\u4e8640%\u7684\u6539\u8fdb\u3002\u6b64\u5916\uff0cAIM\u80fd\u591f\u6709\u6548\u5730\u8bc6\u522b\u51fa\u9700\u8981\u4e13\u5bb6\u534f\u52a9\u7684\u5b89\u5168\u5173\u952e\u72b6\u6001\uff0c\u4ece\u800c\u6536\u96c6\u5230\u66f4\u9ad8\u8d28\u91cf\u7684\u4eba\u7c7b\u6f14\u793a\u6570\u636e\u5e76\u51cf\u5c11\u4e86\u6240\u9700\u7684\u6574\u4f53\u4e13\u5bb6\u6570\u636e\u548c\u73af\u5883\u4e92\u52a8\u3002", "conclusion": "AIM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u51cf\u5c11\u4ea4\u4e92\u5f0f\u6a21\u4eff\u5b66\u4e60\u4e2d\u4eba\u7c7b\u76d1\u7763\u8005\u7684\u8ba4\u77e5\u8d1f\u62c5\uff0c\u5e76\u63d0\u9ad8\u4e86\u5b66\u4e60\u8fc7\u7a0b\u7684\u6548\u7387\u3002"}}
{"id": "2506.09250", "pdf": "https://arxiv.org/pdf/2506.09250", "abs": "https://arxiv.org/abs/2506.09250", "authors": ["C. Opus", "A. Lawsen"], "title": "Comment on The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity", "categories": ["cs.AI", "cs.LG"], "comment": "Comment on: arXiv:2506.06941", "summary": "Shojaee et al. (2025) report that Large Reasoning Models (LRMs) exhibit\n\"accuracy collapse\" on planning puzzles beyond certain complexity thresholds.\nWe demonstrate that their findings primarily reflect experimental design\nlimitations rather than fundamental reasoning failures. Our analysis reveals\nthree critical issues: (1) Tower of Hanoi experiments systematically exceed\nmodel output token limits at reported failure points, with models explicitly\nacknowledging these constraints in their outputs; (2) The authors' automated\nevaluation framework fails to distinguish between reasoning failures and\npractical constraints, leading to misclassification of model capabilities; (3)\nMost concerningly, their River Crossing benchmarks include mathematically\nimpossible instances for N > 5 due to insufficient boat capacity, yet models\nare scored as failures for not solving these unsolvable problems. When we\ncontrol for these experimental artifacts, by requesting generating functions\ninstead of exhaustive move lists, preliminary experiments across multiple\nmodels indicate high accuracy on Tower of Hanoi instances previously reported\nas complete failures. These findings highlight the importance of careful\nexperimental design when evaluating AI reasoning capabilities.", "AI": {"tldr": "\u8bba\u6587\u6307\u51faShojaee\u7b49\u4eba\u5173\u4e8e\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u8d85\u8fc7\u7279\u5b9a\u590d\u6742\u5ea6\u9608\u503c\u7684\u89c4\u5212\u8c1c\u9898\u4e0a\u51fa\u73b0'\u51c6\u786e\u6027\u5d29\u6e83'\u7684\u7814\u7a76\u7ed3\u679c\u4e3b\u8981\u53cd\u6620\u4e86\u5b9e\u9a8c\u8bbe\u8ba1\u7684\u5c40\u9650\u6027\u800c\u975e\u6839\u672c\u6027\u7684\u63a8\u7406\u5931\u8d25\u3002\u901a\u8fc7\u4fee\u6b63\u5b9e\u9a8c\u8bbe\u8ba1\u4e2d\u7684\u95ee\u9898\uff0c\u591a\u4e2a\u6a21\u578b\u5728\u4e4b\u524d\u88ab\u8ba4\u4e3a\u5b8c\u5168\u5931\u8d25\u7684\u6c49\u8bfa\u5854\u5b9e\u4f8b\u4e0a\u8868\u73b0\u51fa\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u4f5c\u8005\u65e8\u5728\u63ed\u793aShojaee\u7b49\u4eba\u7814\u7a76\u4e2d\u5927\u578b\u63a8\u7406\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\u7684\u539f\u56e0\u53ef\u80fd\u5728\u4e8e\u5b9e\u9a8c\u8bbe\u8ba1\u4e0a\u7684\u4e0d\u8db3\uff0c\u800c\u975e\u6a21\u578b\u672c\u8eab\u7684\u63a8\u7406\u80fd\u529b\u7f3a\u9677\u3002", "method": "\u5206\u6790\u4e86\u539f\u7814\u7a76\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u95ee\u9898\uff1a\u8d85\u51fa\u6a21\u578b\u8f93\u51fa\u4ee4\u724c\u9650\u5236\u3001\u8bc4\u4f30\u6846\u67b6\u4e0d\u80fd\u6b63\u786e\u533a\u5206\u63a8\u7406\u5931\u8d25\u4e0e\u5b9e\u9645\u7ea6\u675f\u3001\u4ee5\u53ca\u6cb3\u6e21\u96be\u9898\u4e2d\u5b58\u5728\u6570\u5b66\u4e0a\u65e0\u89e3\u7684\u60c5\u51b5\u3002\u5e76\u63d0\u51fa\u901a\u8fc7\u8bf7\u6c42\u751f\u6210\u51fd\u6570\u800c\u4e0d\u662f\u8be6\u5c3d\u7684\u52a8\u4f5c\u5217\u8868\u6765\u63a7\u5236\u8fd9\u4e9b\u95ee\u9898\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4fee\u6b63\u4e0a\u8ff0\u5b9e\u9a8c\u8bbe\u8ba1\u95ee\u9898\u540e\uff0c\u591a\u4e2a\u6a21\u578b\u80fd\u591f\u51c6\u786e\u89e3\u51b3\u5148\u524d\u62a5\u544a\u4e3a\u5b8c\u5168\u5931\u8d25\u7684\u6c49\u8bfa\u5854\u95ee\u9898\u5b9e\u4f8b\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u4ed4\u7ec6\u8bbe\u8ba1\u5b9e\u9a8c\u5bf9\u4e8e\u6b63\u786e\u8bc4\u4ef7AI\u63a8\u7406\u80fd\u529b\u81f3\u5173\u91cd\u8981\uff1bShojaee\u7b49\u4eba\u7684\u7ed3\u8bba\u53ef\u80fd\u7531\u4e8e\u5b9e\u9a8c\u8bbe\u8ba1\u7684\u95ee\u9898\u800c\u88ab\u8bef\u89e3\u3002"}}
{"id": "2506.09344", "pdf": "https://arxiv.org/pdf/2506.09344", "abs": "https://arxiv.org/abs/2506.09344", "authors": ["Inclusion AI", "Biao Gong", "Cheng Zou", "Chuanyang Zheng", "Chunluan Zhou", "Canxiang Yan", "Chunxiang Jin", "Chunjie Shen", "Dandan Zheng", "Fudong Wang", "Furong Xu", "GuangMing Yao", "Jun Zhou", "Jingdong Chen", "Jianxin Sun", "Jiajia Liu", "Jianjiang Zhu", "Jun Peng", "Kaixiang Ji", "Kaiyou Song", "Kaimeng Ren", "Libin Wang", "Lixiang Ru", "Lele Xie", "Longhua Tan", "Lyuxin Xue", "Lan Wang", "Mochen Bai", "Ning Gao", "Pei Chen", "Qingpei Guo", "Qinglong Zhang", "Qiang Xu", "Rui Liu", "Ruijie Xiong", "Sirui Gao", "Tinghao Liu", "Taisong Li", "Weilong Chai", "Xinyu Xiao", "Xiaomei Wang", "Xiaoxue Chen", "Xiao Lu", "Xiaoyu Li", "Xingning Dong", "Xuzheng Yu", "Yi Yuan", "Yuting Gao", "Yunxiao Sun", "Yipeng Chen", "Yifei Wu", "Yongjie Lyu", "Ziping Ma", "Zipeng Feng", "Zhijiang Fang", "Zhihao Qiu", "Ziyuan Huang", "Zhengyu He"], "title": "Ming-Omni: A Unified Multimodal Model for Perception and Generation", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG", "cs.SD", "eess.AS"], "comment": "18 pages,8 figures", "summary": "We propose Ming-Omni, a unified multimodal model capable of processing\nimages, text, audio, and video, while demonstrating strong proficiency in both\nspeech and image generation. Ming-Omni employs dedicated encoders to extract\ntokens from different modalities, which are then processed by Ling, an MoE\narchitecture equipped with newly proposed modality-specific routers. This\ndesign enables a single model to efficiently process and fuse multimodal inputs\nwithin a unified framework, thereby facilitating diverse tasks without\nrequiring separate models, task-specific fine-tuning, or structural redesign.\nImportantly, Ming-Omni extends beyond conventional multimodal models by\nsupporting audio and image generation. This is achieved through the integration\nof an advanced audio decoder for natural-sounding speech and Ming-Lite-Uni for\nhigh-quality image generation, which also allow the model to engage in\ncontext-aware chatting, perform text-to-speech conversion, and conduct\nversatile image editing. Our experimental results showcase Ming-Omni offers a\npowerful solution for unified perception and generation across all modalities.\nNotably, our proposed Ming-Omni is the first open-source model we are aware of\nto match GPT-4o in modality support, and we release all code and model weights\nto encourage further research and development in the community.", "AI": {"tldr": "\u63d0\u51fa\u4e86Ming-Omni\uff0c\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u56fe\u50cf\u3001\u6587\u672c\u3001\u97f3\u9891\u548c\u89c6\u9891\u7684\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\uff0c\u5e76\u4e14\u5728\u8bed\u97f3\u548c\u56fe\u50cf\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002\u5b83\u4f7f\u7528\u4e13\u95e8\u7684\u7f16\u7801\u5668\u4ece\u4e0d\u540c\u6a21\u6001\u4e2d\u63d0\u53d6tokens\uff0c\u7136\u540e\u7531MoE\u67b6\u6784Ling\u5904\u7406\u3002\u8be5\u8bbe\u8ba1\u5141\u8bb8\u5355\u4e00\u6a21\u578b\u9ad8\u6548\u5730\u5904\u7406\u548c\u878d\u5408\u591a\u6a21\u6001\u8f93\u5165\uff0c\u65e0\u9700\u5355\u72ec\u6a21\u578b\u6216\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\u3002Ming-Omni\u8fd8\u652f\u6301\u901a\u8fc7\u9ad8\u7ea7\u97f3\u9891\u89e3\u7801\u5668\u5b9e\u73b0\u81ea\u7136\u58f0\u97f3\u7684\u8bed\u97f3\u751f\u6210\uff0c\u4ee5\u53ca\u901a\u8fc7Ming-Lite-Uni\u5b9e\u73b0\u9ad8\u8d28\u91cf\u56fe\u50cf\u751f\u6210\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eMing-Omni\u4e3a\u6240\u6709\u6a21\u6001\u7684\u7edf\u4e00\u611f\u77e5\u548c\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u521b\u5efa\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u591a\u79cd\u7c7b\u578b\u6570\u636e\uff08\u5982\u56fe\u50cf\u3001\u6587\u672c\u3001\u97f3\u9891\u548c\u89c6\u9891\uff09\u5e76\u64c5\u957f\u751f\u6210\u8bed\u97f3\u548c\u56fe\u50cf\u7684\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\uff0c\u4ee5\u907f\u514d\u9700\u8981\u72ec\u7acb\u7684\u6a21\u578b\u6216\u8005\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u8fdb\u884c\u5fae\u8c03\u7684\u60c5\u51b5\u3002", "method": "\u91c7\u7528\u4e13\u95e8\u7684\u7f16\u7801\u5668\u6765\u4ece\u4e0d\u540c\u7684\u6a21\u6001\u4e2d\u63d0\u53d6tokens\uff0c\u5e76\u5229\u7528\u540d\u4e3aLing\u7684MoE\u67b6\u6784\u8fdb\u884c\u5904\u7406\uff0c\u8be5\u67b6\u6784\u914d\u5907\u4e86\u65b0\u63d0\u51fa\u7684\u6a21\u6001\u7279\u5b9a\u8def\u7531\u5668\u3002\u4e3a\u4e86\u5b9e\u73b0\u97f3\u9891\u548c\u56fe\u50cf\u751f\u6210\uff0c\u96c6\u6210\u4e86\u5148\u8fdb\u7684\u97f3\u9891\u89e3\u7801\u5668\u548c\u7528\u4e8e\u9ad8\u8d28\u91cf\u56fe\u50cf\u751f\u6210\u7684Ming-Lite-Uni\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cMing-Omni\u80fd\u591f\u5728\u6240\u6709\u6a21\u6001\u4e0a\u63d0\u4f9b\u7edf\u4e00\u7684\u611f\u77e5\u548c\u751f\u6210\u80fd\u529b\u3002\u8fd9\u662f\u5df2\u77e5\u7684\u7b2c\u4e00\u4e2a\u5f00\u6e90\u6a21\u578b\uff0c\u5176\u5728\u6a21\u6001\u652f\u6301\u65b9\u9762\u4e0eGPT-4o\u76f8\u5339\u914d\u3002", "conclusion": "Ming-Omni\u662f\u4e00\u4e2a\u591a\u529f\u80fd\u7684\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\uff0c\u53ef\u4ee5\u5904\u7406\u5305\u62ec\u56fe\u50cf\u3001\u6587\u672c\u3001\u97f3\u9891\u548c\u89c6\u9891\u5728\u5185\u7684\u591a\u79cd\u6570\u636e\u7c7b\u578b\uff0c\u5e76\u4e14\u5728\u8bed\u97f3\u548c\u56fe\u50cf\u751f\u6210\u65b9\u9762\u8868\u73b0\u5353\u8d8a\u3002\u5b83\u901a\u8fc7\u96c6\u6210\u4e13\u4e1a\u7ec4\u4ef6\u89e3\u51b3\u4e86\u4f20\u7edf\u591a\u6a21\u6001\u6a21\u578b\u7684\u4e00\u4e9b\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u8de8\u6a21\u6001\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.09390", "pdf": "https://arxiv.org/pdf/2506.09390", "abs": "https://arxiv.org/abs/2506.09390", "authors": ["Kehan Zheng", "Jinfeng Zhou", "Hongning Wang"], "title": "Beyond Nash Equilibrium: Bounded Rationality of LLMs and humans in Strategic Decision-making", "categories": ["cs.AI", "cs.GT"], "comment": null, "summary": "Large language models are increasingly used in strategic decision-making\nsettings, yet evidence shows that, like humans, they often deviate from full\nrationality. In this study, we compare LLMs and humans using experimental\nparadigms directly adapted from behavioral game-theory research. We focus on\ntwo well-studied strategic games, Rock-Paper-Scissors and the Prisoner's\nDilemma, which are well known for revealing systematic departures from rational\nplay in human subjects. By placing LLMs in identical experimental conditions,\nwe evaluate whether their behaviors exhibit the bounded rationality\ncharacteristic of humans. Our findings show that LLMs reproduce familiar human\nheuristics, such as outcome-based strategy switching and increased cooperation\nwhen future interaction is possible, but they apply these rules more rigidly\nand demonstrate weaker sensitivity to the dynamic changes in the game\nenvironment. Model-level analyses reveal distinctive architectural signatures\nin strategic behavior, and even reasoning models sometimes struggle to find\neffective strategies in adaptive situations. These results indicate that\ncurrent LLMs capture only a partial form of human-like bounded rationality and\nhighlight the need for training methods that encourage flexible opponent\nmodeling and stronger context awareness.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u8ba9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53c2\u4e0e\u7ecf\u5178\u7b56\u7565\u6e38\u620f\uff0c\u5982\u77f3\u5934-\u526a\u5200-\u5e03\u548c\u56da\u5f92\u56f0\u5883\uff0c\u6765\u8bc4\u4f30\u5b83\u4eec\u662f\u5426\u8868\u73b0\u51fa\u4e0e\u4eba\u7c7b\u76f8\u4f3c\u7684\u6709\u9650\u7406\u6027\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5c3d\u7ba1LLMs\u80fd\u591f\u6a21\u4eff\u4e00\u4e9b\u5178\u578b\u7684\u4eba\u7c7b\u542f\u53d1\u5f0f\u884c\u4e3a\uff0c\u4f46\u5b83\u4eec\u5728\u9002\u5e94\u73af\u5883\u52a8\u6001\u53d8\u5316\u65b9\u9762\u8868\u73b0\u8f83\u5f31\uff0c\u5e76\u4e14\u5bf9\u5bf9\u624b\u5efa\u6a21\u4e0d\u591f\u7075\u6d3b\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6218\u7565\u51b3\u7b56\u73af\u5883\u4e2d\u662f\u5426\u50cf\u4eba\u7c7b\u4e00\u6837\u504f\u79bb\u5b8c\u5168\u7406\u6027\uff0c\u4ee5\u53ca\u5b83\u4eec\u5728\u6a21\u4eff\u4eba\u7c7b\u6709\u9650\u7406\u6027\u65b9\u9762\u7684\u7a0b\u5ea6\u3002", "method": "\u91c7\u7528\u5b9e\u9a8c\u8303\u5f0f\u76f4\u63a5\u6539\u7f16\u81ea\u884c\u4e3a\u535a\u5f08\u8bba\u7814\u7a76\uff0c\u9009\u53d6\u4e86\u4e24\u4e2a\u7ecf\u8fc7\u5145\u5206\u7814\u7a76\u7684\u6218\u7565\u6e38\u620f\uff1a\u77f3\u5934-\u526a\u5200-\u5e03\u548c\u56da\u5f92\u56f0\u5883\uff0c\u4ee5\u6b64\u6765\u8003\u5bdf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u884c\u4e3a\u3002", "result": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u518d\u73b0\u4e86\u4e00\u4e9b\u719f\u6089\u7684\u4eba\u7c7b\u542f\u53d1\u5f0f\uff0c\u4f8b\u5982\u57fa\u4e8e\u7ed3\u679c\u7684\u6218\u7565\u8f6c\u6362\u548c\u5bf9\u672a\u6765\u4e92\u52a8\u53ef\u80fd\u6027\u589e\u52a0\u7684\u5408\u4f5c\uff0c\u4f46\u662f\u5b83\u4eec\u66f4\u52a0\u50f5\u786c\u5730\u5e94\u7528\u8fd9\u4e9b\u89c4\u5219\uff0c\u5e76\u4e14\u5bf9\u4e8e\u6e38\u620f\u73af\u5883\u4e2d\u7684\u52a8\u6001\u53d8\u5316\u8868\u73b0\u51fa\u8f83\u5f31\u7684\u654f\u611f\u6027\u3002", "conclusion": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ec5\u6355\u6349\u5230\u4e86\u90e8\u5206\u7c7b\u4f3c\u4eba\u7c7b\u7684\u6709\u9650\u7406\u6027\u5f62\u5f0f\uff0c\u5e76\u5f3a\u8c03\u9700\u8981\u5f00\u53d1\u8bad\u7ec3\u65b9\u6cd5\u4ee5\u4fc3\u8fdb\u66f4\u7075\u6d3b\u7684\u5bf9\u624b\u5efa\u6a21\u548c\u66f4\u5f3a\u7684\u60c5\u5883\u610f\u8bc6\u3002"}}
{"id": "2506.09338", "pdf": "https://arxiv.org/pdf/2506.09338", "abs": "https://arxiv.org/abs/2506.09338", "authors": ["Young-Jin Park", "Kristjan Greenewald", "Kaveh Alim", "Hao Wang", "Navid Azizan"], "title": "Know What You Don't Know: Uncertainty Calibration of Process Reward Models", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Process reward models (PRMs) play a central role in guiding inference-time\nscaling algorithms for large language models (LLMs). However, we observe that\neven state-of-the-art PRMs can be poorly calibrated and often overestimate\nsuccess probabilities. To address this, we present a calibration approach,\nperformed via quantile regression, that adjusts PRM outputs to better align\nwith true success probabilities. Leveraging these calibrated success estimates\nand their associated confidence bounds, we introduce an \\emph{instance-adaptive\nscaling} (IAS) framework that dynamically adjusts the inference budget based on\nthe estimated likelihood that a partial reasoning trajectory will yield a\ncorrect final answer. Unlike conventional methods that allocate a fixed number\nof reasoning trajectories per query, this approach successfully adapts to each\ninstance and reasoning step when using our calibrated PRMs. Experiments on\nmathematical reasoning benchmarks show that (i) our PRM calibration method\nsuccessfully achieves small calibration error, outperforming the baseline\nmethods, (ii) calibration is crucial for enabling effective adaptive scaling,\nand (iii) the proposed IAS strategy reduces inference costs while maintaining\nfinal answer accuracy, utilizing less compute on more confident problems as\ndesired.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u5206\u4f4d\u6570\u56de\u5f52\u8fdb\u884c\u6821\u51c6\u7684\u65b9\u6cd5\u6765\u6539\u8fdb\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRM\uff09\u7684\u51c6\u786e\u6027\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f15\u5165\u4e86\u5b9e\u4f8b\u81ea\u9002\u5e94\u7f29\u653e\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u6839\u636e\u90e8\u5206\u63a8\u7406\u8f68\u8ff9\u4f30\u8ba1\u6b63\u786e\u7b54\u6848\u7684\u6982\u7387\u52a8\u6001\u8c03\u6574\u63a8\u7406\u9884\u7b97\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u964d\u4f4e\u4e86\u6821\u51c6\u8bef\u5dee\uff0c\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u81ea\u9002\u5e94\u7f29\u653e\u7b56\u7565\uff0c\u5728\u51cf\u5c11\u63a8\u7406\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u6700\u7ec8\u7b54\u6848\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u89c2\u5bdf\u5230\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u4e5f\u53ef\u80fd\u5b58\u5728\u6821\u51c6\u4e0d\u826f\u548c\u8fc7\u5ea6\u4f30\u8ba1\u6210\u529f\u6982\u7387\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5206\u4f4d\u6570\u56de\u5f52\u6280\u672f\u5bf9\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u8f93\u51fa\u8fdb\u884c\u6821\u51c6\uff1b\u57fa\u4e8e\u6821\u51c6\u540e\u7684\u6210\u529f\u4f30\u8ba1\u503c\u53ca\u5176\u7f6e\u4fe1\u8fb9\u754c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b9e\u4f8b\u81ea\u9002\u5e94\u7f29\u653e\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u53ef\u6839\u636e\u6bcf\u4e2a\u95ee\u9898\u5b9e\u4f8b\u548c\u63a8\u7406\u6b65\u9aa4\u52a8\u6001\u8c03\u6574\u63a8\u7406\u9884\u7b97\u3002", "result": "(i) \u63d0\u51fa\u7684\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u6821\u51c6\u65b9\u6cd5\u8fbe\u5230\u4e86\u8f83\u5c0f\u7684\u6821\u51c6\u8bef\u5dee\uff0c\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002(ii) \u6821\u51c6\u5bf9\u4e8e\u5b9e\u73b0\u6709\u6548\u7684\u81ea\u9002\u5e94\u7f29\u653e\u81f3\u5173\u91cd\u8981\u3002(iii) \u6240\u63d0\u51fa\u7684IAS\u7b56\u7565\u5728\u7ef4\u6301\u6700\u7ec8\u7b54\u6848\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u51cf\u5c11\u4e86\u63a8\u7406\u6210\u672c\uff0c\u6b63\u5982\u9884\u671f\u90a3\u6837\uff0c\u5bf9\u4e8e\u66f4\u52a0\u786e\u4fe1\u7684\u95ee\u9898\u4f7f\u7528\u4e86\u8f83\u5c11\u7684\u8ba1\u7b97\u8d44\u6e90\u3002", "conclusion": "\u901a\u8fc7\u6821\u51c6\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u5e76\u5229\u7528\u5176\u5b9e\u4f8b\u81ea\u9002\u5e94\u7f29\u653e\u80fd\u529b\uff0c\u53ef\u4ee5\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u964d\u4f4e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65f6\u7684\u6210\u672c\u3002"}}
{"id": "2506.09052", "pdf": "https://arxiv.org/pdf/2506.09052", "abs": "https://arxiv.org/abs/2506.09052", "authors": ["Delower Hossain", "Ehsan Saghapour", "Kevin Song", "Jake Y. Chen"], "title": "Llama-Affinity: A Predictive Antibody Antigen Binding Model Integrating Antibody Sequences with Llama3 Backbone Architecture", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "comment": "7 Pages", "summary": "Antibody-facilitated immune responses are central to the body's defense\nagainst pathogens, viruses, and other foreign invaders. The ability of\nantibodies to specifically bind and neutralize antigens is vital for\nmaintaining immunity. Over the past few decades, bioengineering advancements\nhave significantly accelerated therapeutic antibody development. These\nantibody-derived drugs have shown remarkable efficacy, particularly in treating\ncancer, SARS-CoV-2, autoimmune disorders, and infectious diseases.\nTraditionally, experimental methods for affinity measurement have been\ntime-consuming and expensive. With the advent of artificial intelligence, in\nsilico medicine has been revolutionized; recent developments in machine\nlearning, particularly the use of large language models (LLMs) for representing\nantibodies, have opened up new avenues for AI-based design and improved\naffinity prediction. Herein, we present an advanced antibody-antigen binding\naffinity prediction model (LlamaAffinity), leveraging an open-source Llama 3\nbackbone and antibody sequence data sourced from the Observed Antibody Space\n(OAS) database. The proposed approach shows significant improvement over\nexisting state-of-the-art (SOTA) methods (AntiFormer, AntiBERTa, AntiBERTy)\nacross multiple evaluation metrics. Specifically, the model achieved an\naccuracy of 0.9640, an F1-score of 0.9643, a precision of 0.9702, a recall of\n0.9586, and an AUC-ROC of 0.9936. Moreover, this strategy unveiled higher\ncomputational efficiency, with a five-fold average cumulative training time of\nonly 0.46 hours, significantly lower than in previous studies.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLlama 3\u7684\u6297\u4f53-\u6297\u539f\u7ed3\u5408\u4eb2\u548c\u529b\u9884\u6d4b\u6a21\u578bLlamaAffinity\uff0c\u5b83\u5728\u6027\u80fd\u4e0a\u8d85\u8d8a\u4e86\u73b0\u6709\u6280\u672f\uff0c\u5e76\u4e14\u8bad\u7ec3\u6548\u7387\u66f4\u9ad8\u3002", "motivation": "\u4e3a\u4e86\u6539\u8fdb\u4f20\u7edf\u7684\u8017\u65f6\u4e14\u6602\u8d35\u7684\u6297\u4f53\u4eb2\u548c\u529b\u6d4b\u91cf\u5b9e\u9a8c\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u4eba\u5de5\u667a\u80fd\u5c24\u5176\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\u6765\u8bbe\u8ba1\u57fa\u4e8eAI\u7684\u6297\u4f53\u5e76\u63d0\u9ad8\u4eb2\u548c\u529b\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u5f00\u6e90\u7684Llama 3\u4f5c\u4e3a\u57fa\u7840\u67b6\u6784\uff0c\u7ed3\u5408\u6765\u81eaObserved Antibody Space (OAS)\u6570\u636e\u5e93\u7684\u6297\u4f53\u5e8f\u5217\u6570\u636e\uff0c\u5f00\u53d1\u4e86LlamaAffinity\u6a21\u578b\u6765\u9884\u6d4b\u6297\u4f53-\u6297\u539f\u7ed3\u5408\u4eb2\u548c\u529b\u3002", "result": "LlamaAffinity\u6a21\u578b\u5728\u591a\u4e2a\u8bc4\u4f30\u6307\u6807\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5305\u62ec\u51c6\u786e\u73870.9640\u3001F1\u5206\u65700.9643\u3001\u7cbe\u786e\u5ea60.9702\u3001\u53ec\u56de\u73870.9586\u4ee5\u53caAUC-ROC 0.9936\u3002\u6b64\u5916\uff0c\u8be5\u6a21\u578b\u7684\u5e73\u5747\u7d2f\u79ef\u8bad\u7ec3\u65f6\u95f4\u4ec5\u4e3a0.46\u5c0f\u65f6\uff0c\u8fdc\u4f4e\u4e8e\u5148\u524d\u7814\u7a76\u3002", "conclusion": "LlamaAffinity\u6a21\u578b\u5728\u6297\u4f53-\u6297\u539f\u7ed3\u5408\u4eb2\u548c\u529b\u9884\u6d4b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u4e14\u5177\u6709\u66f4\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2506.09420", "pdf": "https://arxiv.org/pdf/2506.09420", "abs": "https://arxiv.org/abs/2506.09420", "authors": ["Henry Peng Zou", "Wei-Chieh Huang", "Yaozu Wu", "Chunyu Miao", "Dongyuan Li", "Aiwei Liu", "Yue Zhou", "Yankai Chen", "Weizhi Zhang", "Yangning Li", "Liancheng Fang", "Renhe Jiang", "Philip S. Yu"], "title": "A Call for Collaborative Intelligence: Why Human-Agent Systems Should Precede AI Autonomy", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG", "cs.MA"], "comment": null, "summary": "Recent improvements in large language models (LLMs) have led many researchers\nto focus on building fully autonomous AI agents. This position paper questions\nwhether this approach is the right path forward, as these autonomous systems\nstill have problems with reliability, transparency, and understanding the\nactual requirements of human. We suggest a different approach: LLM-based\nHuman-Agent Systems (LLM-HAS), where AI works with humans rather than replacing\nthem. By keeping human involved to provide guidance, answer questions, and\nmaintain control, these systems can be more trustworthy and adaptable. Looking\nat examples from healthcare, finance, and software development, we show how\nhuman-AI teamwork can handle complex tasks better than AI working alone. We\nalso discuss the challenges of building these collaborative systems and offer\npractical solutions. This paper argues that progress in AI should not be\nmeasured by how independent systems become, but by how well they can work with\nhumans. The most promising future for AI is not in systems that take over human\nroles, but in those that enhance human capabilities through meaningful\npartnership.", "AI": {"tldr": "\u672c\u6587\u8d28\u7591\u4e86\u6784\u5efa\u5b8c\u5168\u81ea\u4e3bAI\u4ee3\u7406\u7684\u8def\u5f84\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4eba\u7c7b-\u4ee3\u7406\u7cfb\u7edf\uff08LLM-HAS\uff09\uff0c\u5176\u4e2dAI\u4e0e\u4eba\u7c7b\u534f\u4f5c\u800c\u975e\u53d6\u4ee3\u4eba\u7c7b\u3002\u901a\u8fc7\u4fdd\u6301\u4eba\u7c7b\u53c2\u4e0e\u6765\u63d0\u4f9b\u6307\u5bfc\u3001\u56de\u7b54\u95ee\u9898\u548c\u63a7\u5236\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u53ef\u4ee5\u66f4\u503c\u5f97\u4fe1\u8d56\u548c\u9002\u5e94\u6027\u5f3a\u3002\u6587\u7ae0\u901a\u8fc7\u533b\u7597\u4fdd\u5065\u3001\u91d1\u878d\u548c\u8f6f\u4ef6\u5f00\u53d1\u7684\u4f8b\u5b50\u5c55\u793a\u4e86\u4eba\u673a\u5408\u4f5c\u5982\u4f55\u6bd4AI\u5355\u72ec\u5de5\u4f5c\u66f4\u597d\u5730\u5904\u7406\u590d\u6742\u4efb\u52a1\uff0c\u5e76\u8ba8\u8bba\u4e86\u6784\u5efa\u534f\u4f5c\u7cfb\u7edf\u7684\u6311\u6218\u53ca\u5176\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u9274\u4e8e\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\u5bfc\u81f4\u8bb8\u591a\u7814\u7a76\u8005\u4e13\u6ce8\u4e8e\u521b\u5efa\u5b8c\u5168\u81ea\u4e3b\u7684\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\uff0c\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u8fd9\u79cd\u8d8b\u52bf\u662f\u5426\u6b63\u786e\uff0c\u56e0\u4e3a\u5168\u81ea\u4e3b\u7cfb\u7edf\u5728\u53ef\u9760\u6027\u3001\u900f\u660e\u5ea6\u4ee5\u53ca\u7406\u89e3\u4eba\u7c7b\u5b9e\u9645\u9700\u6c42\u65b9\u9762\u4ecd\u5b58\u5728\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e0d\u540c\u7684\u65b9\u6cd5\uff1a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4eba\u7c7b-\u4ee3\u7406\u7cfb\u7edf\uff08LLM-HAS\uff09\uff0c\u5728\u8fd9\u4e2a\u6846\u67b6\u4e0b\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u7c7b\u534f\u540c\u5de5\u4f5c\u3002\u6587\u4e2d\u8fd8\u5217\u4e3e\u4e86\u533b\u7597\u3001\u91d1\u878d\u548c\u8f6f\u4ef6\u5f00\u53d1\u7b49\u9886\u57df\u7684\u6848\u4f8b\u6765\u5c55\u793a\u4eba\u673a\u534f\u4f5c\u7684\u4f18\u52bf\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5f53\u4eba\u7c7b\u53c2\u4e0e\u5230AI\u7cfb\u7edf\u4e2d\u65f6\uff0c\u53ef\u4ee5\u63d0\u9ad8\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u548c\u9002\u5e94\u6027\uff0c\u5e76\u4e14\u80fd\u591f\u66f4\u597d\u5730\u5b8c\u6210\u590d\u6742\u7684\u4efb\u52a1\u3002\u6b64\u5916\uff0c\u6587\u7ae0\u8fd8\u6307\u51fa\u4e86\u5b9e\u73b0\u8fd9\u7c7b\u534f\u4f5c\u7cfb\u7edf\u6240\u9762\u4e34\u7684\u6311\u6218\uff0c\u5e76\u63d0\u4f9b\u4e86\u5b9e\u9645\u7684\u89e3\u51b3\u7b56\u7565\u3002", "conclusion": "\u8bba\u6587\u8ba4\u4e3a\uff0c\u4eba\u5de5\u667a\u80fd\u7684\u8fdb\u6b65\u4e0d\u5e94\u4ee5\u7cfb\u7edf\u72ec\u7acb\u6027\u7684\u63d0\u5347\u4e3a\u8861\u91cf\u6807\u51c6\uff0c\u800c\u5e94\u770b\u5176\u4e0e\u4eba\u7c7b\u5408\u4f5c\u7684\u80fd\u529b\u3002\u672a\u6765\u6700\u6709\u5e0c\u671b\u7684\u4eba\u5de5\u667a\u80fd\u65b9\u5411\u4e0d\u662f\u53d6\u4ee3\u4eba\u7c7b\u89d2\u8272\uff0c\u800c\u662f\u901a\u8fc7\u6709\u610f\u4e49\u7684\u5408\u4f5c\u589e\u5f3a\u4eba\u7c7b\u80fd\u529b\u3002"}}
{"id": "2506.09441", "pdf": "https://arxiv.org/pdf/2506.09441", "abs": "https://arxiv.org/abs/2506.09441", "authors": ["Piyush Mishra", "Philippe Roudot"], "title": "Attention-Bayesian Hybrid Approach to Modular Multiple Particle Tracking", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Tracking multiple particles in noisy and cluttered scenes remains challenging\ndue to a combinatorial explosion of trajectory hypotheses, which scales\nsuper-exponentially with the number of particles and frames. The transformer\narchitecture has shown a significant improvement in robustness against this\nhigh combinatorial load. However, its performance still falls short of the\nconventional Bayesian filtering approaches in scenarios presenting a reduced\nset of trajectory hypothesis. This suggests that while transformers excel at\nnarrowing down possible associations, they may not be able to reach the\noptimality of the Bayesian approach in locally sparse scenario. Hence, we\nintroduce a hybrid tracking framework that combines the ability of\nself-attention to learn the underlying representation of particle behavior with\nthe reliability and interpretability of Bayesian filtering. We perform\ntrajectory-to-detection association by solving a label prediction problem,\nusing a transformer encoder to infer soft associations between detections\nacross frames. This prunes the hypothesis set, enabling efficient\nmultiple-particle tracking in Bayesian filtering framework. Our approach\ndemonstrates improved tracking accuracy and robustness against spurious\ndetections, offering a solution for high clutter multiple particle tracking\nscenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u8d1d\u53f6\u65af\u6ee4\u6ce2\u7684\u6df7\u5408\u8ddf\u8e2a\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u5728\u566a\u58f0\u548c\u6742\u4e71\u573a\u666f\u4e2d\u591a\u7c92\u5b50\u8ddf\u8e2a\u7684\u95ee\u9898\u3002", "motivation": "\u5728\u566a\u58f0\u548c\u6742\u4e71\u573a\u666f\u4e2d\u8fdb\u884c\u591a\u7c92\u5b50\u8ddf\u8e2a\u5b58\u5728\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u8f68\u8ff9\u5047\u8bbe\u7684\u6570\u91cf\u4f1a\u968f\u7740\u7c92\u5b50\u6570\u91cf\u548c\u5e27\u6570\u7684\u589e\u52a0\u800c\u5448\u8d85\u6307\u6570\u589e\u957f\u3002\u867d\u7136Transformer\u67b6\u6784\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u9ad8\u7ec4\u5408\u8d1f\u8f7d\u7684\u9c81\u68d2\u6027\uff0c\u4f46\u5728\u5448\u73b0\u8f83\u5c11\u8f68\u8ff9\u5047\u8bbe\u7684\u60c5\u51b5\u4e0b\uff0c\u5176\u8868\u73b0\u4ecd\u4e0d\u53ca\u4f20\u7edf\u7684\u8d1d\u53f6\u65af\u6ee4\u6ce2\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u79cd\u6df7\u5408\u8ddf\u8e2a\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u81ea\u6ce8\u610f\u529b\u5b66\u4e60\u7c92\u5b50\u884c\u4e3a\u57fa\u672c\u8868\u793a\u7684\u80fd\u529b\u4e0e\u8d1d\u53f6\u65af\u6ee4\u6ce2\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u901a\u8fc7\u5c06\u8f68\u8ff9\u5230\u68c0\u6d4b\u7684\u5173\u8054\u95ee\u9898\u8f6c\u5316\u4e3a\u6807\u7b7e\u9884\u6d4b\u95ee\u9898\uff0c\u5e76\u4f7f\u7528Transformer\u7f16\u7801\u5668\u6765\u63a8\u65ad\u8de8\u5e27\u68c0\u6d4b\u4e4b\u95f4\u7684\u8f6f\u5173\u8054\uff0c\u4ece\u800c\u4fee\u526a\u5047\u8bbe\u96c6\uff0c\u4f7f\u5f97\u5728\u8d1d\u53f6\u65af\u6ee4\u6ce2\u6846\u67b6\u4e0b\u80fd\u591f\u9ad8\u6548\u5730\u8fdb\u884c\u591a\u7c92\u5b50\u8ddf\u8e2a\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5c55\u793a\u4e86\u6539\u8fdb\u7684\u8ddf\u8e2a\u51c6\u786e\u6027\u548c\u5bf9\u865a\u5047\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\uff0c\u4e3a\u9ad8\u5ea6\u6742\u4e71\u73af\u5883\u4e0b\u7684\u591a\u7c92\u5b50\u8ddf\u8e2a\u63d0\u4f9b\u4e86\u65b9\u6848\u3002", "conclusion": "\u7ed3\u5408\u4e86\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4e0e\u8d1d\u53f6\u65af\u6ee4\u6ce2\u7684\u6df7\u5408\u8ddf\u8e2a\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u5bf9\u590d\u6742\u573a\u666f\u9c81\u68d2\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u591a\u7c92\u5b50\u7cfb\u7edf\u7684\u8ddf\u8e2a\u7cbe\u5ea6\u3002"}}
{"id": "2506.09080", "pdf": "https://arxiv.org/pdf/2506.09080", "abs": "https://arxiv.org/abs/2506.09080", "authors": ["Jiaxiang Chen", "Mingxi Zou", "Zhuo Wang", "Qifan Wang", "Dongning Sun", "Chi Zhang", "Zenglin Xu"], "title": "FinHEAR: Human Expertise and Adaptive Risk-Aware Temporal Reasoning for Financial Decision-Making", "categories": ["cs.LG", "cs.AI", "q-fin.CP"], "comment": null, "summary": "Financial decision-making presents unique challenges for language models,\ndemanding temporal reasoning, adaptive risk assessment, and responsiveness to\ndynamic events. While large language models (LLMs) show strong general\nreasoning capabilities, they often fail to capture behavioral patterns central\nto human financial decisions-such as expert reliance under information\nasymmetry, loss-averse sensitivity, and feedback-driven temporal adjustment. We\npropose FinHEAR, a multi-agent framework for Human Expertise and Adaptive\nRisk-aware reasoning. FinHEAR orchestrates specialized LLM-based agents to\nanalyze historical trends, interpret current events, and retrieve\nexpert-informed precedents within an event-centric pipeline. Grounded in\nbehavioral economics, it incorporates expert-guided retrieval,\nconfidence-adjusted position sizing, and outcome-based refinement to enhance\ninterpretability and robustness. Empirical results on curated financial\ndatasets show that FinHEAR consistently outperforms strong baselines across\ntrend prediction and trading tasks, achieving higher accuracy and better\nrisk-adjusted returns.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFinHEAR\u7684\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u51b3\u7b56\u4e2d\u7684\u8868\u73b0\u3002\u5b83\u901a\u8fc7\u7ed3\u5408\u884c\u4e3a\u7ecf\u6d4e\u5b66\u539f\u7406\u3001\u4e13\u5bb6\u6307\u5bfc\u7684\u68c0\u7d22\u3001\u57fa\u4e8e\u4fe1\u5fc3\u7684\u4f4d\u7f6e\u8c03\u6574\u4ee5\u53ca\u57fa\u4e8e\u7ed3\u679c\u7684\u4f18\u5316\u6765\u589e\u5f3a\u89e3\u91ca\u6027\u548c\u7a33\u5065\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0cFinHEAR\u5728\u8d8b\u52bf\u9884\u6d4b\u548c\u4ea4\u6613\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5f3a\u5927\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u66f4\u597d\u7684\u98ce\u9669\u8c03\u6574\u56de\u62a5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u6355\u6349\u4eba\u7c7b\u91d1\u878d\u51b3\u7b56\u7684\u6838\u5fc3\u884c\u4e3a\u6a21\u5f0f\u65b9\u9762\u5f80\u5f80\u8868\u73b0\u4e0d\u4f73\uff0c\u6bd4\u5982\u5728\u4fe1\u606f\u4e0d\u5bf9\u79f0\u4e0b\u7684\u4e13\u5bb6\u4f9d\u8d56\u3001\u635f\u5931\u89c4\u907f\u654f\u611f\u5ea6\u53ca\u57fa\u4e8e\u53cd\u9988\u7684\u65f6\u95f4\u8c03\u6574\u7b49\u3002", "method": "FinHEAR\u662f\u4e00\u4e2a\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u7528\u4e8e\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u548c\u9002\u5e94\u6027\u98ce\u9669\u610f\u8bc6\u63a8\u7406\u3002\u8be5\u6846\u67b6\u7ec4\u7ec7\u4e86\u4e13\u95e8\u7684\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u6765\u5206\u6790\u5386\u53f2\u8d8b\u52bf\u3001\u89e3\u8bfb\u5f53\u524d\u4e8b\u4ef6\uff0c\u5e76\u5728\u4e00\u4e2a\u4ee5\u4e8b\u4ef6\u4e3a\u4e2d\u5fc3\u7684\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u83b7\u53d6\u7531\u4e13\u5bb6\u63d0\u4f9b\u4fe1\u606f\u7684\u5148\u4f8b\u3002\u6b64\u5916\uff0cFinHEAR\u8fd8\u878d\u5165\u4e86\u4ece\u884c\u4e3a\u7ecf\u6d4e\u5b66\u4e2d\u5f97\u5230\u7075\u611f\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\u4e13\u5bb6\u6307\u5bfc\u7684\u68c0\u7d22\u3001\u6839\u636e\u4fe1\u5fc3\u8c03\u6574\u4ed3\u4f4d\u5927\u5c0f\u4ee5\u53ca\u57fa\u4e8e\u7ed3\u679c\u7684\u6539\u8fdb\u3002", "result": "\u5728\u7cbe\u5fc3\u7b56\u5212\u7684\u91d1\u878d\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u663e\u793a\uff0cFinHEAR\u5728\u8d8b\u52bf\u9884\u6d4b\u548c\u4ea4\u6613\u4efb\u52a1\u4e2d\u59cb\u7ec8\u8d85\u8d8a\u4e86\u5f3a\u52b2\u7684\u57fa\u51c6\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u548c\u66f4\u4f18\u7684\u98ce\u9669\u8c03\u6574\u6536\u76ca\u3002", "conclusion": "FinHEAR\u6846\u67b6\u901a\u8fc7\u6574\u5408\u4e13\u4e1a\u9886\u57df\u77e5\u8bc6\u4e0e\u9002\u5e94\u6027\u98ce\u9669\u7ba1\u7406\u7b56\u7565\uff0c\u5728\u91d1\u878d\u51b3\u7b56\u573a\u666f\u4e0b\u4e3a\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u9700\u8981\u65f6\u95f4\u63a8\u7406\u3001\u9002\u5e94\u6027\u98ce\u9669\u8bc4\u4f30\u53ca\u5bf9\u52a8\u6001\u4e8b\u4ef6\u4f5c\u51fa\u54cd\u5e94\u7684\u60c5\u51b5\u65f6\u3002"}}
{"id": "2506.09498", "pdf": "https://arxiv.org/pdf/2506.09498", "abs": "https://arxiv.org/abs/2506.09498", "authors": ["Jaesik Yoon", "Hyeonseo Cho", "Yoshua Bengio", "Sungjin Ahn"], "title": "Fast Monte Carlo Tree Diffusion: 100x Speedup via Parallel Sparse Planning", "categories": ["cs.AI"], "comment": null, "summary": "Diffusion models have recently emerged as a powerful approach for trajectory\nplanning. However, their inherently non-sequential nature limits their\neffectiveness in long-horizon reasoning tasks at test time. The recently\nproposed Monte Carlo Tree Diffusion (MCTD) offers a promising solution by\ncombining diffusion with tree-based search, achieving state-of-the-art\nperformance on complex planning problems. Despite its strengths, our analysis\nshows that MCTD incurs substantial computational overhead due to the sequential\nnature of tree search and the cost of iterative denoising. To address this, we\npropose Fast-MCTD, a more efficient variant that preserves the strengths of\nMCTD while significantly improving its speed and scalability. Fast-MCTD\nintegrates two techniques: Parallel MCTD, which enables parallel rollouts via\ndelayed tree updates and redundancy-aware selection; and Sparse MCTD, which\nreduces rollout length through trajectory coarsening. Experiments show that\nFast-MCTD achieves up to 100x speedup over standard MCTD while maintaining or\nimproving planning performance. Remarkably, it even outperforms Diffuser in\ninference speed on some tasks, despite Diffuser requiring no search and\nyielding weaker solutions. These results position Fast-MCTD as a practical and\nscalable solution for diffusion-based inference-time reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFast-MCTD\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5e76\u884cMCTD\u548c\u5e73\u6ed1MCTD\u6280\u672f\u6539\u8fdb\u4e86\u539f\u6709\u7684\u8499\u7279\u5361\u6d1b\u6811\u6269\u6563\uff08MCTD\uff09\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u539f\u6709\u4f18\u52bf\u7684\u540c\u65f6\u663e\u8457\u63d0\u9ad8\u4e86\u901f\u5ea6\u548c\u53ef\u6269\u5c55\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0cFast-MCTD\u76f8\u6bd4\u6807\u51c6MCTD\u5b9e\u73b0\u4e86\u9ad8\u8fbe100\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u5e76\u4e14\u5728\u67d0\u4e9b\u4efb\u52a1\u4e2d\u751a\u81f3\u8d85\u8fc7\u4e86Diffuser\u7684\u63a8\u7406\u901f\u5ea6\u3002", "motivation": "\u867d\u7136\u8499\u7279\u5361\u6d1b\u6811\u6269\u6563\uff08MCTD\uff09\u4e3a\u590d\u6742\u7684\u89c4\u5212\u95ee\u9898\u63d0\u4f9b\u4e86\u6700\u5148\u8fdb\u7684\u8868\u73b0\uff0c\u4f46\u5176\u8ba1\u7b97\u5f00\u9500\u8f83\u5927\uff0c\u56e0\u4e3a\u6811\u641c\u7d22\u7684\u987a\u5e8f\u6027\u8d28\u4ee5\u53ca\u8fed\u4ee3\u53bb\u566a\u7684\u6210\u672c\u3002\u4e3a\u4e86\u63d0\u9ad8\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301MCTD\u7684\u4f18\u52bf\uff0c\u63d0\u51fa\u4e86\u66f4\u9ad8\u6548\u7684Fast-MCTD\u53d8\u4f53\u3002", "method": "Fast-MCTD\u5f15\u5165\u4e86\u4e24\u79cd\u6280\u672f\uff1aParallel MCTD\u5141\u8bb8\u901a\u8fc7\u5ef6\u8fdf\u6811\u66f4\u65b0\u548c\u5197\u4f59\u611f\u77e5\u9009\u62e9\u6765\u5b9e\u73b0\u5e76\u884c\u5c55\u5f00\uff1bSparse MCTD\u5219\u901a\u8fc7\u8f68\u8ff9\u7c97\u5316\u51cf\u5c11\u5c55\u5f00\u957f\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cFast-MCTD\u4e0e\u6807\u51c6MCTD\u76f8\u6bd4\u53ef\u8fbe\u81f3100\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u5e76\u4e14\u5728\u4e00\u4e9b\u4efb\u52a1\u4e0a\u7684\u63a8\u7406\u901f\u5ea6\u4e0a\u8fd8\u4f18\u4e8eDiffuser\u3002", "conclusion": "Fast-MCTD\u88ab\u5b9a\u4f4d\u4e3a\u4e00\u79cd\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u63a8\u7406\u65f6\u63a8\u7406\u3002"}}
{"id": "2506.09516", "pdf": "https://arxiv.org/pdf/2506.09516", "abs": "https://arxiv.org/abs/2506.09516", "authors": ["Yingying Fan", "Jinchi Lv", "Ao Sun", "Yurou Wang"], "title": "LLM-Powered CPI Prediction Inference with Online Text Time Series", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "73 pages, 13 figures", "summary": "Forecasting the Consumer Price Index (CPI) is an important yet challenging\ntask in economics, where most existing approaches rely on low-frequency,\nsurvey-based data. With the recent advances of large language models (LLMs),\nthere is growing potential to leverage high-frequency online text data for\nimproved CPI prediction, an area still largely unexplored. This paper proposes\nLLM-CPI, an LLM-based approach for CPI prediction inference incorporating\nonline text time series. We collect a large set of high-frequency online texts\nfrom a popularly used Chinese social network site and employ LLMs such as\nChatGPT and the trained BERT models to construct continuous inflation labels\nfor posts that are related to inflation. Online text embeddings are extracted\nvia LDA and BERT. We develop a joint time series framework that combines\nmonthly CPI data with LLM-generated daily CPI surrogates. The monthly model\nemploys an ARX structure combining observed CPI data with text embeddings and\nmacroeconomic variables, while the daily model uses a VARX structure built on\nLLM-generated CPI surrogates and text embeddings. We establish the asymptotic\nproperties of the method and provide two forms of constructed prediction\nintervals. The finite-sample performance and practical advantages of LLM-CPI\nare demonstrated through both simulation and real data examples.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5LLM-CPI\uff0c\u901a\u8fc7\u7ed3\u5408\u9ad8\u9891\u5728\u7ebf\u6587\u672c\u6570\u636e\u6765\u6539\u8fdb\u6d88\u8d39\u8005\u4ef7\u683c\u6307\u6570\uff08CPI\uff09\u7684\u9884\u6d4b\u3002", "motivation": "\u73b0\u6709\u7684CPI\u9884\u6d4b\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u4f4e\u9891\u3001\u57fa\u4e8e\u8c03\u67e5\u7684\u6570\u636e\u3002\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\uff0c\u5229\u7528\u9ad8\u9891\u5728\u7ebf\u6587\u672c\u6570\u636e\u8fdb\u884c\u66f4\u51c6\u786e\u7684CPI\u9884\u6d4b\u6210\u4e3a\u53ef\u80fd\u3002", "method": "\u7814\u7a76\u8005\u4ece\u4e2d\u56fd\u6d41\u884c\u7684\u793e\u4ea4\u7f51\u7edc\u6536\u96c6\u5927\u91cf\u9ad8\u9891\u5728\u7ebf\u6587\u672c\uff0c\u5e76\u4f7f\u7528\u5982ChatGPT\u548c\u8bad\u7ec3\u8fc7\u7684BERT\u6a21\u578b\u4e3a\u4e0e\u901a\u8d27\u81a8\u80c0\u76f8\u5173\u7684\u5e16\u5b50\u6784\u5efa\u8fde\u7eed\u7684\u901a\u80c0\u6807\u7b7e\u3002\u63a5\u7740\u63d0\u53d6\u5728\u7ebf\u6587\u672c\u5d4c\u5165\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u8054\u5408\u65f6\u95f4\u5e8f\u5217\u6846\u67b6\uff0c\u5c06\u6708\u5ea6CPI\u6570\u636e\u4e0eLLM\u751f\u6210\u7684\u65e5\u5ea6CPI\u4ee3\u7406\u53d8\u91cf\u76f8\u7ed3\u5408\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u548c\u5b9e\u9645\u6570\u636e\u793a\u4f8b\u8bc1\u660e\u4e86LLM-CPI\u5728\u6709\u9650\u6837\u672c\u8868\u73b0\u53ca\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4f18\u52bf\uff0c\u5e76\u5efa\u7acb\u4e86\u8be5\u65b9\u6cd5\u7684\u6e10\u8fd1\u6027\u8d28\u4ee5\u53ca\u63d0\u4f9b\u4e86\u4e24\u79cd\u5f62\u5f0f\u7684\u9884\u6d4b\u533a\u95f4\u3002", "conclusion": "\u63d0\u51fa\u7684LLM-CPI\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347CPI\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u4e3a\u7ecf\u6d4e\u9886\u57df\u7684CPI\u9884\u6d4b\u5f00\u8f9f\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2506.09084", "pdf": "https://arxiv.org/pdf/2506.09084", "abs": "https://arxiv.org/abs/2506.09084", "authors": ["Xinyuan Wang", "Liang Wu", "Yanjie Fu"], "title": "Enhanced Whole Page Optimization via Mixed-Grained Reward Mechanism-Adapted Language Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Optimizing the presentation of search and recommendation results is crucial\nto enhancing user experience and engagement. Whole Page Optimization (WPO)\nplays a pivotal role in this process, as it directly influences how information\nis surfaced to users. While Pre-trained Large Language Models (LLMs) have\ndemonstrated remarkable capabilities in generating coherent and contextually\nrelevant content, fine-tuning these models for complex tasks like WPO presents\nchallenges. Specifically, the need for extensive human-annotated data to\nmitigate issues such as hallucinations and model instability can be\nprohibitively expensive, especially in large-scale systems that interact with\nmillions of items daily. In this work, we address the challenge of fine-tuning\nLLMs for WPO by using user feedback as the supervision. Unlike manually labeled\ndatasets, user feedback is inherently noisy and less precise. To overcome this,\nwe propose a reward-based fine-tuning approach, PageLLM, which employs a\nmixed-grained reward mechanism that combines page-level and item-level rewards.\nThe page-level reward evaluates the overall quality and coherence, while the\nitem-level reward focuses on the accuracy and relevance of key recommendations.\nThis dual-reward structure ensures that both the holistic presentation and the\ncritical individual components are optimized. We validate PageLLM on both\npublic and industrial datasets. PageLLM outperforms baselines and achieves a\n0.44\\% GMV increase in an online A/B test with over 10 million users,\ndemonstrating its real-world impact.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7528\u6237\u53cd\u9988\u7684\u5956\u52b1\u673a\u5236\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5PageLLM\uff0c\u7528\u4e8e\u4f18\u5316\u641c\u7d22\u548c\u63a8\u8350\u7ed3\u679c\u5448\u73b0\u3002\u901a\u8fc7\u7ed3\u5408\u9875\u9762\u7ea7\u522b\u548c\u9879\u76ee\u7ea7\u522b\u7684\u5956\u52b1\uff0c\u8be5\u65b9\u6cd5\u5728\u516c\u5171\u6570\u636e\u96c6\u548c\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u5728\u7ebf\u4e0aA/B\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e860.44% GMV\u7684\u589e\u957f\u3002", "motivation": "\u5168\u6587\u4f18\u5316\uff08WPO\uff09\u5bf9\u4e8e\u63d0\u9ad8\u7528\u6237\u4f53\u9a8c\u548c\u53c2\u4e0e\u5ea6\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u9884\u8bad\u7ec3\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u80fd\u591f\u751f\u6210\u8fde\u8d2f\u4e14\u4e0e\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u6587\u672c\uff0c\u4f46\u5728\u9488\u5bf9\u590d\u6742\u4efb\u52a1\u5982WPO\u8fdb\u884c\u5fae\u8c03\u65f6\u9762\u4e34\u6311\u6218\uff0c\u7279\u522b\u662f\u9700\u8981\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\u7684\u6570\u636e\u6765\u51cf\u5c11\u5e7b\u89c9\u548c\u6a21\u578b\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002", "method": "\u4e3a\u4e86\u89e3\u51b3\u4f7f\u7528\u7528\u6237\u53cd\u9988\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\u6765\u5fae\u8c03LLMs\u8fdb\u884cWPO\u7684\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86PageLLM\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u5956\u52b1\u7684\u5fae\u8c03\u65b9\u6cd5\u3002\u5b83\u91c7\u7528\u4e86\u6df7\u5408\u7c92\u5ea6\u5956\u52b1\u673a\u5236\uff0c\u7ed3\u5408\u4e86\u9875\u9762\u7ea7\u522b\u5956\u52b1\uff08\u8bc4\u4f30\u6574\u4f53\u8d28\u91cf\u548c\u4e00\u81f4\u6027\uff09\u548c\u9879\u76ee\u7ea7\u522b\u5956\u52b1\uff08\u5173\u6ce8\u5173\u952e\u63a8\u8350\u7684\u51c6\u786e\u6027\u548c\u76f8\u5173\u6027\uff09\u3002", "result": "PageLLM\u5728\u516c\u5f00\u6570\u636e\u96c6\u4ee5\u53ca\u5b9e\u9645\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u5728\u4e00\u4e2a\u6d89\u53ca\u8d85\u8fc71000\u4e07\u7528\u6237\u7684\u5728\u7ebfA/B\u6d4b\u8bd5\u4e2d\uff0c\u5e26\u6765\u4e860.44% GMV\u589e\u957f\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "conclusion": "PageLLM\u901a\u8fc7\u5229\u7528\u7528\u6237\u53cd\u9988\u4f5c\u4e3a\u76d1\u7763\u4fe1\u53f7\u5e76\u91c7\u7528\u53cc\u5956\u52b1\u7ed3\u6784\u6210\u529f\u89e3\u51b3\u4e86WPO\u4e2d\u7684\u6311\u6218\uff0c\u4e0d\u4ec5\u4f18\u5316\u4e86\u6574\u4e2a\u9875\u9762\u5c55\u793a\u6548\u679c\u8fd8\u63d0\u5347\u4e86\u5355\u4e2a\u91cd\u8981\u5143\u7d20\u7684\u8d28\u91cf\uff0c\u5728\u5927\u89c4\u6a21\u7cfb\u7edf\u4e2d\u5c55\u73b0\u4e86\u5176\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.09655", "pdf": "https://arxiv.org/pdf/2506.09655", "abs": "https://arxiv.org/abs/2506.09655", "authors": ["Kaixuan Xu", "Jiajun Chai", "Sicheng Li", "Yuqian Fu", "Yuanheng Zhu", "Dongbin Zhao"], "title": "DipLLM: Fine-Tuning LLM for Strategic Decision-making in Diplomacy", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted to the 42nd International Conference on Machine Learning\n  (ICML 2025)", "summary": "Diplomacy is a complex multiplayer game that requires both cooperation and\ncompetition, posing significant challenges for AI systems. Traditional methods\nrely on equilibrium search to generate extensive game data for training, which\ndemands substantial computational resources. Large Language Models (LLMs) offer\na promising alternative, leveraging pre-trained knowledge to achieve strong\nperformance with relatively small-scale fine-tuning. However, applying LLMs to\nDiplomacy remains challenging due to the exponential growth of possible action\ncombinations and the intricate strategic interactions among players. To address\nthis challenge, we propose DipLLM, a fine-tuned LLM-based agent that learns\nequilibrium policies for Diplomacy. DipLLM employs an autoregressive\nfactorization framework to simplify the complex task of multi-unit action\nassignment into a sequence of unit-level decisions. By defining an equilibrium\npolicy within this framework as the learning objective, we fine-tune the model\nusing only 1.5% of the data required by the state-of-the-art Cicero model,\nsurpassing its performance. Our results demonstrate the potential of fine-tuned\nLLMs for tackling complex strategic decision-making in multiplayer games.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406DipLLM\uff0c\u5b83\u80fd\u591f\u5b66\u4e60\u5916\u4ea4\u6e38\u620f\u4e2d\u7684\u5747\u8861\u7b56\u7565\u3002\u901a\u8fc7\u4f7f\u7528\u81ea\u56de\u5f52\u56e0\u5b50\u5206\u89e3\u6846\u67b6\u7b80\u5316\u591a\u5355\u4f4d\u884c\u52a8\u5206\u914d\u4efb\u52a1\uff0c\u5e76\u4e14\u53ea\u9700\u8981Cicero\u6a21\u578b\u6240\u9700\u6570\u636e\u76841.5%\uff0c\u5c31\u80fd\u8d85\u8d8a\u5176\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u751f\u6210\u6e38\u620f\u6570\u636e\u6765\u8bad\u7ec3AI\u7cfb\u7edf\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u5e0c\u671b\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u76f8\u5bf9\u8f83\u5c0f\u89c4\u6a21\u7684\u5fae\u8c03\u4e0b\u53d6\u5f97\u826f\u597d\u7684\u6027\u80fd\u3002\u7136\u800c\uff0c\u5728\u5916\u4ea4\u6e38\u620f\u4e2d\u5e94\u7528\u8fd9\u4e9b\u6a21\u578b\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u53ef\u80fd\u7684\u52a8\u4f5c\u7ec4\u5408\u5448\u6307\u6570\u589e\u957f\uff0c\u73a9\u5bb6\u4e4b\u95f4\u7684\u6218\u7565\u4e92\u52a8\u4e5f\u5341\u5206\u590d\u6742\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86DipLLM\uff0c\u8fd9\u662f\u4e00\u79cd\u7ecf\u8fc7\u5fae\u8c03\u7684\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\uff0c\u65e8\u5728\u5b66\u4e60\u9002\u7528\u4e8e\u5916\u4ea4\u6e38\u620f\u7684\u5747\u8861\u7b56\u7565\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u81ea\u56de\u5f52\u56e0\u5b50\u5206\u89e3\u6846\u67b6\uff0c\u5c06\u590d\u6742\u7684\u591a\u5355\u4f4d\u52a8\u4f5c\u5206\u914d\u4efb\u52a1\u8f6c\u5316\u4e3a\u4e00\u7cfb\u5217\u5355\u5143\u7ea7\u51b3\u7b56\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u4ec5\u4f7f\u7528\u8fbe\u5230\u5f53\u524d\u6700\u4f73Cicero\u6a21\u578b\u6240\u9700\u6570\u636e\u91cf\u76841.5%\u8fdb\u884c\u5fae\u8c03\uff0cDipLLM\u4e0d\u4ec5\u5728\u6027\u80fd\u4e0a\u8d85\u8fc7\u4e86Cicero\uff0c\u8fd8\u5c55\u793a\u4e86\u5fae\u8c03\u540e\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u591a\u4eba\u6e38\u620f\u4e2d\u590d\u6742\u7b56\u7565\u51b3\u7b56\u7684\u6f5c\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5fae\u8c03\u540e\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982DipLLM\u53ef\u4ee5\u6709\u6548\u5730\u89e3\u51b3\u591a\u4eba\u6e38\u620f\u4e2d\u7684\u590d\u6742\u7b56\u7565\u51b3\u7b56\u95ee\u9898\uff0c\u5373\u4f7f\u662f\u5728\u50cf\u5916\u4ea4\u8fd9\u6837\u9700\u8981\u6df1\u5ea6\u5408\u4f5c\u4e0e\u7ade\u4e89\u7684\u6e38\u620f\u91cc\u3002"}}
{"id": "2506.09640", "pdf": "https://arxiv.org/pdf/2506.09640", "abs": "https://arxiv.org/abs/2506.09640", "authors": ["Pablo G. Arce", "Roi Naveiro", "David R\u00edos Insua"], "title": "Evasion Attacks Against Bayesian Predictive Models", "categories": ["stat.ML", "cs.LG", "68T37"], "comment": "Accepted as an oral presentation at UAI'25", "summary": "There is an increasing interest in analyzing the behavior of machine learning\nsystems against adversarial attacks. However, most of the research in\nadversarial machine learning has focused on studying weaknesses against evasion\nor poisoning attacks to predictive models in classical setups, with the\nsusceptibility of Bayesian predictive models to attacks remaining\nunderexplored. This paper introduces a general methodology for designing\noptimal evasion attacks against such models. We investigate two adversarial\nobjectives: perturbing specific point predictions and altering the entire\nposterior predictive distribution. For both scenarios, we propose novel\ngradient-based attacks and study their implementation and properties in various\ncomputational setups.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8bbe\u8ba1\u9488\u5bf9\u8d1d\u53f6\u65af\u9884\u6d4b\u6a21\u578b\u7684\u6700\u4f73\u9003\u907f\u653b\u51fb\u7684\u4e00\u822c\u65b9\u6cd5\u8bba\uff0c\u5e76\u7814\u7a76\u4e86\u4e24\u79cd\u5bf9\u6297\u6027\u76ee\u6807\uff1a\u6270\u52a8\u7279\u5b9a\u70b9\u9884\u6d4b\u548c\u6539\u53d8\u6574\u4e2a\u540e\u9a8c\u9884\u6d4b\u5206\u5e03\u3002", "motivation": "\u5c3d\u7ba1\u5bf9\u6297\u6027\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u5927\u591a\u6570\u7814\u7a76\u90fd\u96c6\u4e2d\u5728\u7814\u7a76\u7ecf\u5178\u8bbe\u7f6e\u4e0b\u9884\u6d4b\u6a21\u578b\u5bf9\u9003\u907f\u6216\u4e2d\u6bd2\u653b\u51fb\u7684\u5f31\u70b9\uff0c\u4f46\u8d1d\u53f6\u65af\u9884\u6d4b\u6a21\u578b\u5bf9\u653b\u51fb\u7684\u8106\u5f31\u6027\u4ecd\u7136\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5bf9\u4e8e\u6270\u52a8\u7279\u5b9a\u70b9\u9884\u6d4b\u548c\u6539\u53d8\u6574\u4e2a\u540e\u9a8c\u9884\u6d4b\u5206\u5e03\u8fd9\u4e24\u79cd\u60c5\u51b5\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u65b0\u9896\u7684\u57fa\u4e8e\u68af\u5ea6\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u5728\u5404\u79cd\u8ba1\u7b97\u73af\u5883\u4e2d\u7814\u7a76\u4e86\u8fd9\u4e9b\u653b\u51fb\u7684\u5b9e\u73b0\u4e0e\u7279\u6027\u3002", "result": "\u8bba\u6587\u4e2d\u63d0\u51fa\u7684\u653b\u51fb\u65b9\u6cd5\u4e3a\u8bc4\u4f30\u8d1d\u53f6\u65af\u9884\u6d4b\u6a21\u578b\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002", "conclusion": "\u672c\u6587\u7684\u65b9\u6cd5\u4e3a\u7406\u89e3\u8d1d\u53f6\u65af\u9884\u6d4b\u6a21\u578b\u5728\u9762\u5bf9\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u5bf9\u6297\u6027\u653b\u51fb\u65f6\u7684\u884c\u4e3a\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u89c1\u89e3\u3002"}}
{"id": "2506.09085", "pdf": "https://arxiv.org/pdf/2506.09085", "abs": "https://arxiv.org/abs/2506.09085", "authors": ["Xinyuan Wang", "Haoyue Bai", "Nanxu Gong", "Wangyang Ying", "Sixun Dong", "Xiquan Cui", "Yanjie Fu"], "title": "LLM-ML Teaming: Integrated Symbolic Decoding and Gradient Search for Valid and Stable Generative Feature Transformation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Feature transformation enhances data representation by deriving new features\nfrom the original data. Generative AI offers potential for this task, but faces\nchallenges in stable generation (consistent outputs) and valid generation\n(error-free sequences). Existing methods--traditional MLs' low validity and\nLLMs' instability--fail to resolve both. We find that LLMs ensure valid syntax,\nwhile ML's gradient-steered search stabilizes performance. To bridge this gap,\nwe propose a teaming framework combining LLMs' symbolic generation with ML's\ngradient optimization. This framework includes four steps: (1) golden examples\ngeneration, aiming to prepare high-quality samples with the ground knowledge of\nthe teacher LLM; (2) feature transformation sequence embedding and search,\nintending to uncover potentially superior embeddings within the latent space;\n(3) student LLM feature transformation, aiming to distill knowledge from the\nteacher LLM; (4) LLM-ML decoder teaming, dedicating to combine ML and the\nstudent LLM probabilities for valid and stable generation. The experiments on\nvarious datasets show that the teaming policy can achieve 5\\% improvement in\ndownstream performance while reducing nearly half of the error cases. The\nresults also demonstrate the efficiency and robustness of the teaming policy.\nAdditionally, we also have exciting findings on LLMs' capacity to understand\nthe original data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u7b26\u53f7\u751f\u6210\u548c\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u68af\u5ea6\u4f18\u5316\u7684\u56e2\u961f\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u7279\u5f81\u8f6c\u6362\u4e2d\u7a33\u5b9a\u6027\u548c\u6709\u6548\u6027\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u4e0a\u63d0\u9ad8\u4e865%\uff0c\u540c\u65f6\u9519\u8bef\u60c5\u51b5\u51cf\u5c11\u8fd1\u534a\u3002", "motivation": "\u7279\u5f81\u8f6c\u6362\u901a\u8fc7\u4ece\u539f\u59cb\u6570\u636e\u6d3e\u751f\u65b0\u7279\u5f81\u6765\u589e\u5f3a\u6570\u636e\u8868\u793a\u3002\u867d\u7136\u751f\u6210\u5f0fAI\u5728\u6b64\u4efb\u52a1\u4e2d\u5c55\u793a\u4e86\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u7740\u7a33\u5b9a\u751f\u6210\u548c\u6709\u6548\u751f\u6210\u7684\u6311\u6218\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u8981\u4e48\u65e0\u6cd5\u4fdd\u8bc1\u8bed\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8981\u4e48\u8868\u73b0\u4e0d\u7a33\u5b9a\u3002", "method": "\u4e00\u79cd\u7ed3\u5408\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u7b26\u53f7\u751f\u6210\u80fd\u529b\u548c\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u68af\u5ea6\u4f18\u5316\u641c\u7d22\u7684\u56e2\u961f\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5305\u62ec\u56db\u4e2a\u6b65\u9aa4\uff1a(1) \u751f\u6210\u9ec4\u91d1\u6837\u4f8b\uff1b(2) \u7279\u5f81\u8f6c\u6362\u5e8f\u5217\u5d4c\u5165\u4e0e\u641c\u7d22\uff1b(3) \u5b66\u751fLLM\u8fdb\u884c\u7279\u5f81\u8f6c\u6362\uff1b(4) LLM-ML\u89e3\u7801\u5668\u534f\u4f5c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u56e2\u961f\u7b56\u7565\u53ef\u4ee5\u5728\u5404\u79cd\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e0b\u6e38\u6027\u80fd5%\u7684\u63d0\u5347\uff0c\u5e76\u4e14\u51e0\u4e4e\u51cf\u5c11\u4e86\u8fd1\u4e00\u534a\u7684\u9519\u8bef\u6848\u4f8b\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u53d1\u73b0LLMs\u5177\u6709\u7406\u89e3\u539f\u59cb\u6570\u636e\u7684\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u7ed3\u5408LLMs\u548cML\u7684\u56e2\u961f\u6846\u67b6\u4e0d\u4ec5\u89e3\u51b3\u4e86\u7279\u5f81\u8f6c\u6362\u4e2d\u7684\u7a33\u5b9a\u6027\u548c\u6709\u6548\u6027\u95ee\u9898\uff0c\u800c\u4e14\u5728\u6548\u7387\u548c\u9c81\u68d2\u6027\u65b9\u9762\u4e5f\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.09656", "pdf": "https://arxiv.org/pdf/2506.09656", "abs": "https://arxiv.org/abs/2506.09656", "authors": ["Wei Zeng", "Hengshu Zhu", "Chuan Qin", "Han Wu", "Yihang Cheng", "Sirui Zhang", "Xiaowei Jin", "Yinuo Shen", "Zhenxing Wang", "Feimin Zhong", "Hui Xiong"], "title": "Application-Driven Value Alignment in Agentic AI Systems: Survey and Perspectives", "categories": ["cs.AI"], "comment": null, "summary": "The ongoing evolution of AI paradigms has propelled AI research into the\nAgentic AI stage. Consequently, the focus of research has shifted from single\nagents and simple applications towards multi-agent autonomous decision-making\nand task collaboration in complex environments. As Large Language Models (LLMs)\nadvance, their applications become more diverse and complex, leading to\nincreasingly situational and systemic risks. This has brought significant\nattention to value alignment for AI agents, which aims to ensure that an\nagent's goals, preferences, and behaviors align with human values and societal\nnorms. This paper reviews value alignment in agent systems within specific\napplication scenarios. It integrates the advancements in AI driven by large\nmodels with the demands of social governance. Our review covers value\nprinciples, agent system application scenarios, and agent value alignment\nevaluation. Specifically, value principles are organized hierarchically from a\ntop-down perspective, encompassing macro, meso, and micro levels. Agent system\napplication scenarios are categorized and reviewed from a general-to-specific\nviewpoint. Agent value alignment evaluation systematically examines datasets\nfor value alignment assessment and relevant value alignment methods.\nAdditionally, we delve into value coordination among multiple agents within\nagent systems. Finally, we propose several potential research directions in\nthis field.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u7279\u5b9a\u5e94\u7528\u573a\u666f\u4e0b\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u4ef7\u503c\u5bf9\u9f50\u95ee\u9898\uff0c\u7ed3\u5408\u5927\u578b\u6a21\u578b\u9a71\u52a8\u7684\u4eba\u5de5\u667a\u80fd\u8fdb\u5c55\u4e0e\u793e\u4f1a\u6cbb\u7406\u9700\u6c42\uff0c\u6db5\u76d6\u4e86\u4ef7\u503c\u539f\u5219\u3001\u667a\u80fd\u4f53\u7cfb\u7edf\u5e94\u7528\u573a\u666f\u4ee5\u53ca\u667a\u80fd\u4f53\u4ef7\u503c\u5bf9\u9f50\u8bc4\u4f30\uff0c\u5e76\u63a2\u8ba8\u4e86\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u591a\u667a\u80fd\u4f53\u95f4\u7684\u4ef7\u503c\u534f\u8c03\uff0c\u6700\u540e\u63d0\u51fa\u4e86\u8be5\u9886\u57df\u7684\u51e0\u4e2a\u6f5c\u5728\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740AI\u8303\u5f0f\u7684\u4e0d\u65ad\u8fdb\u5316\uff0c\u7814\u7a76\u91cd\u70b9\u8f6c\u5411\u4e86\u590d\u6742\u73af\u5883\u4e2d\u7684\u591a\u667a\u80fd\u4f53\u81ea\u4e3b\u51b3\u7b56\u548c\u4efb\u52a1\u534f\u4f5c\u3002\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u6b65\u53ca\u5176\u5e94\u7528\u7684\u591a\u6837\u5316\u548c\u590d\u6742\u5316\uff0c\u5bfc\u81f4\u4e86\u60c5\u5883\u6027\u548c\u7cfb\u7edf\u6027\u98ce\u9669\u7684\u589e\u52a0\uff0c\u8fd9\u4f7f\u5f97\u5bf9\u4e8e\u786e\u4fddAI\u667a\u80fd\u4f53\u7684\u76ee\u6807\u3001\u504f\u597d\u548c\u884c\u4e3a\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u548c\u793e\u4f1a\u89c4\u8303\u4fdd\u6301\u4e00\u81f4\u7684\u4ef7\u503c\u5bf9\u9f50\u95ee\u9898\u5f97\u5230\u4e86\u6781\u5927\u7684\u5173\u6ce8\u3002", "method": "\u672c\u8bba\u6587\u901a\u8fc7\u56de\u987e\u7279\u5b9a\u5e94\u7528\u573a\u666f\u4e0b\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u4ef7\u503c\u5bf9\u9f50\uff0c\u4ece\u5b8f\u89c2\u3001\u4e2d\u89c2\u5230\u5fae\u89c2\u5c42\u9762\u7ec4\u7ec7\u4ef7\u503c\u539f\u5219\uff0c\u91c7\u7528\u7531\u4e00\u822c\u5230\u5177\u4f53\u7684\u89c6\u89d2\u5206\u7c7b\u5e76\u56de\u987e\u4e86\u667a\u80fd\u4f53\u7cfb\u7edf\u5e94\u7528\u573a\u666f\uff0c\u5e76\u7cfb\u7edf\u5730\u8003\u5bdf\u4e86\u7528\u4e8e\u4ef7\u503c\u5bf9\u9f50\u8bc4\u4f30\u7684\u6570\u636e\u96c6\u53ca\u76f8\u5173\u4ef7\u503c\u5bf9\u9f50\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8fd8\u6df1\u5165\u63a2\u8ba8\u4e86\u667a\u80fd\u4f53\u7cfb\u7edf\u5185\u591a\u4e2a\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u4ef7\u503c\u534f\u8c03\u95ee\u9898\u3002", "result": "\u6587\u7ae0\u6574\u7406\u4e86\u4e0d\u540c\u5c42\u6b21\u7684\u4ef7\u503c\u539f\u5219\uff0c\u5f52\u7eb3\u603b\u7ed3\u4e86\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u5404\u79cd\u5e94\u7528\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u8bc4\u4f30\u4e86\u5f53\u524d\u4ef7\u503c\u5bf9\u9f50\u7684\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4ef7\u503c\u534f\u8c03\u7684\u95ee\u9898\u3002", "conclusion": "\u57fa\u4e8e\u73b0\u6709\u7814\u7a76\uff0c\u6587\u7ae0\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u5305\u62ec\u8fdb\u4e00\u6b65\u63a2\u7d22\u9002\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4ef7\u503c\u5bf9\u9f50\u673a\u5236\uff0c\u4ee5\u53ca\u5f00\u53d1\u65b0\u7684\u8bc4\u4ef7\u6807\u51c6\u548c\u6280\u672f\u4ee5\u4fc3\u8fdb\u4eba\u5de5\u667a\u80fd\u4e0e\u793e\u4f1a\u89c4\u8303\u7684\u6709\u6548\u878d\u5408\u3002"}}
{"id": "2506.09648", "pdf": "https://arxiv.org/pdf/2506.09648", "abs": "https://arxiv.org/abs/2506.09648", "authors": ["Mattia Rosso", "Simone Rossi", "Giulio Franzese", "Markus Heinonen", "Maurizio Filippone"], "title": "Scaling Laws for Uncertainty in Deep Learning", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Deep learning has recently revealed the existence of scaling laws,\ndemonstrating that model performance follows predictable trends based on\ndataset and model sizes. Inspired by these findings and fascinating phenomena\nemerging in the over-parameterized regime, we examine a parallel direction: do\nsimilar scaling laws govern predictive uncertainties in deep learning? In\nidentifiable parametric models, such scaling laws can be derived in a\nstraightforward manner by treating model parameters in a Bayesian way. In this\ncase, for example, we obtain $O(1/N)$ contraction rates for epistemic\nuncertainty with respect to the number of data $N$. However, in\nover-parameterized models, these guarantees do not hold, leading to largely\nunexplored behaviors. In this work, we empirically show the existence of\nscaling laws associated with various measures of predictive uncertainty with\nrespect to dataset and model sizes. Through experiments on vision and language\ntasks, we observe such scaling laws for in- and out-of-distribution predictive\nuncertainty estimated through popular approximate Bayesian inference and\nensemble methods. Besides the elegance of scaling laws and the practical\nutility of extrapolating uncertainties to larger data or models, this work\nprovides strong evidence to dispel recurring skepticism against Bayesian\napproaches: \"In many applications of deep learning we have so much data\navailable: what do we need Bayes for?\". Our findings show that \"so much data\"\nis typically not enough to make epistemic uncertainty negligible.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u662f\u5426\u9075\u5faa\u4e0e\u6a21\u578b\u6027\u80fd\u76f8\u4f3c\u7684\u7f29\u653e\u5f8b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u4efb\u52a1\u4e2d\uff0c\u968f\u7740\u6570\u636e\u96c6\u5927\u5c0f\u548c\u6a21\u578b\u5927\u5c0f\u7684\u53d8\u5316\uff0c\u5b58\u5728\u5173\u4e8e\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u7f29\u653e\u5f8b\u3002", "motivation": "\u53d7\u6700\u8fd1\u53d1\u73b0\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6027\u80fd\u9075\u5faa\u53ef\u9884\u6d4b\u7684\u8d8b\u52bf\u7684\u542f\u53d1\uff0c\u7814\u7a76\u8005\u4eec\u63a2\u7d22\u4e86\u8fc7\u53c2\u6570\u5316\u60c5\u51b5\u4e0b\u51fa\u73b0\u7684\u73b0\u8c61\uff0c\u5e76\u4e14\u60f3\u8981\u4e86\u89e3\u7c7b\u4f3c\u7684\u7f29\u653e\u5f8b\u662f\u5426\u4e5f\u9002\u7528\u4e8e\u6df1\u5ea6\u5b66\u4e60\u4e2d\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u7814\u7a76\u8005\u4eec\u901a\u8fc7\u5b9e\u9a8c\u7684\u65b9\u6cd5\uff0c\u5728\u89c6\u89c9\u548c\u8bed\u8a00\u4efb\u52a1\u4e0a\u89c2\u5bdf\u4e86\u5bf9\u4e8e\u4e0d\u540c\u6570\u636e\u96c6\u5927\u5c0f\u548c\u6a21\u578b\u5927\u5c0f\uff0c\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\uff08\u5305\u62ec\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\uff09\u7684\u5ea6\u91cf\u662f\u5426\u5b58\u5728\u7f29\u653e\u5f8b\u3002\u4ed6\u4eec\u4f7f\u7528\u4e86\u6d41\u884c\u7684\u8fd1\u4f3c\u8d1d\u53f6\u65af\u63a8\u7406\u548c\u96c6\u6210\u65b9\u6cd5\u6765\u4f30\u8ba1\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u786e\u5b9e\u5b58\u5728\u7740\u4e0e\u6570\u636e\u96c6\u5927\u5c0f\u548c\u6a21\u578b\u5927\u5c0f\u76f8\u5173\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u7f29\u653e\u5f8b\u3002\u8fd9\u4e9b\u89c4\u5f8b\u4e3a\u7406\u89e3\u8d1d\u53f6\u65af\u65b9\u6cd5\u5728\u5927\u6570\u636e\u6761\u4ef6\u4e0b\u7684\u4f5c\u7528\u63d0\u4f9b\u4e86\u5f3a\u6709\u529b\u7684\u8bc1\u636e\uff0c\u8868\u660e\u5373\u4f7f\u6709\u5927\u91cf\u7684\u6570\u636e\uff0c\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u4e5f\u4e0d\u80fd\u88ab\u5ffd\u7565\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u5c55\u793a\u4e86\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7f29\u653e\u5f8b\u7684\u4f18\u96c5\u4e4b\u5904\uff0c\u8fd8\u8bc1\u660e\u4e86\u5c06\u4e0d\u786e\u5b9a\u6027\u63a8\u65ad\u5230\u66f4\u5927\u89c4\u6a21\u7684\u6570\u636e\u6216\u6a21\u578b\u4e0a\u7684\u5b9e\u9645\u6548\u7528\uff0c\u5e76\u4e14\u6709\u529b\u5730\u53cd\u9a73\u4e86\u5bf9\u8d1d\u53f6\u65af\u65b9\u6cd5\u5728\u5927\u6570\u636e\u65f6\u4ee3\u5fc5\u8981\u6027\u7684\u6000\u7591\u8bba\u70b9\u3002"}}
{"id": "2506.09087", "pdf": "https://arxiv.org/pdf/2506.09087", "abs": "https://arxiv.org/abs/2506.09087", "authors": ["Sophie Jaffard", "Giulia Mezzadri", "Patricia Reynaud-Bouret", "Etienne Tanr\u00e9"], "title": "Spiking Neural Models for Decision-Making Tasks with Learning", "categories": ["cs.LG", "math.PR", "q-bio.NC", "stat.ML"], "comment": null, "summary": "In cognition, response times and choices in decision-making tasks are\ncommonly modeled using Drift Diffusion Models (DDMs), which describe the\naccumulation of evidence for a decision as a stochastic process, specifically a\nBrownian motion, with the drift rate reflecting the strength of the evidence.\nIn the same vein, the Poisson counter model describes the accumulation of\nevidence as discrete events whose counts over time are modeled as Poisson\nprocesses, and has a spiking neurons interpretation as these processes are used\nto model neuronal activities. However, these models lack a learning mechanism\nand are limited to tasks where participants have prior knowledge of the\ncategories. To bridge the gap between cognitive and biological models, we\npropose a biologically plausible Spiking Neural Network (SNN) model for\ndecision-making that incorporates a learning mechanism and whose neurons\nactivities are modeled by a multivariate Hawkes process. First, we show a\ncoupling result between the DDM and the Poisson counter model, establishing\nthat these two models provide similar categorizations and reaction times and\nthat the DDM can be approximated by spiking Poisson neurons. To go further, we\nshow that a particular DDM with correlated noise can be derived from a Hawkes\nnetwork of spiking neurons governed by a local learning rule. In addition, we\ndesigned an online categorization task to evaluate the model predictions. This\nwork provides a significant step toward integrating biologically relevant\nneural mechanisms into cognitive models, fostering a deeper understanding of\nthe relationship between neural activity and behavior.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u7269\u4e0a\u53ef\u4fe1\u7684\u8109\u51b2\u795e\u7ecf\u7f51\u7edc(SNN)\u6a21\u578b\uff0c\u7528\u4e8e\u51b3\u7b56\u5236\u5b9a\uff0c\u5e76\u7ed3\u5408\u4e86\u5b66\u4e60\u673a\u5236\u3002\u901a\u8fc7\u5efa\u7acb\u6f02\u79fb\u6269\u6563\u6a21\u578b(DDM)\u548c\u6cca\u677e\u8ba1\u6570\u5668\u6a21\u578b\u4e4b\u95f4\u7684\u8054\u7cfb\uff0c\u8bc1\u660e\u4e86\u8fd9\u4e24\u79cd\u6a21\u578b\u63d0\u4f9b\u4e86\u7c7b\u4f3c\u7684\u5206\u7c7b\u548c\u53cd\u5e94\u65f6\u95f4\uff0c\u5e76\u4e14DDM\u53ef\u4ee5\u7531\u53d1\u51fa\u8109\u51b2\u7684\u6cca\u677e\u795e\u7ecf\u5143\u8fd1\u4f3c\u3002\u6b64\u5916\uff0c\u7814\u7a76\u663e\u793a\u4e00\u4e2a\u5177\u6709\u76f8\u5173\u566a\u58f0\u7684\u7279\u5b9aDDM\u53ef\u4ee5\u4ece\u53d7\u5c40\u90e8\u5b66\u4e60\u89c4\u5219\u652f\u914d\u7684\u970d\u514b\u65af\u7f51\u7edc\u4e2d\u63a8\u5bfc\u51fa\u6765\u3002\u4e3a\u4e86\u8bc4\u4f30\u6a21\u578b\u9884\u6d4b\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5728\u7ebf\u5206\u7c7b\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u7684\u8ba4\u77e5\u6a21\u578b\uff08\u5982\u6f02\u79fb\u6269\u6563\u6a21\u578b\uff09\u548c\u751f\u7269\u5b66\u6a21\u578b\uff08\u5982\u6cca\u677e\u8ba1\u6570\u5668\u6a21\u578b\uff09\u7f3a\u4e4f\u5b66\u4e60\u673a\u5236\uff0c\u4e14\u5c40\u9650\u4e8e\u53c2\u4e0e\u8005\u4e8b\u5148\u77e5\u9053\u7c7b\u522b\u7684\u4efb\u52a1\u3002\u4e3a\u4e86\u586b\u8865\u8ba4\u77e5\u6a21\u578b\u4e0e\u751f\u7269\u6a21\u578b\u4e4b\u95f4\u7684\u7a7a\u767d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u5b66\u4e60\u673a\u5236\u7684SNN\u6a21\u578b\uff0c\u65e8\u5728\u6574\u5408\u751f\u7269\u76f8\u5173\u7684\u795e\u7ecf\u673a\u5236\u5230\u8ba4\u77e5\u6a21\u578b\u4e2d\uff0c\u4ee5\u589e\u8fdb\u5bf9\u795e\u7ecf\u6d3b\u52a8\u4e0e\u884c\u4e3a\u4e4b\u95f4\u5173\u7cfb\u7684\u7406\u89e3\u3002", "method": "\u9996\u5148\uff0c\u5c55\u793a\u4e86\u6f02\u79fb\u6269\u6563\u6a21\u578b\u548c\u6cca\u677e\u8ba1\u6570\u5668\u6a21\u578b\u4e4b\u95f4\u7684\u8026\u5408\u7ed3\u679c\uff0c\u8868\u660e\u4e24\u8005\u63d0\u4f9b\u76f8\u4f3c\u7684\u5206\u7c7b\u548c\u53cd\u5e94\u65f6\u95f4\uff0c\u5e76\u4e14\u6f02\u79fb\u6269\u6563\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u53d1\u653e\u8109\u51b2\u7684\u6cca\u677e\u795e\u7ecf\u5143\u6765\u8fd1\u4f3c\uff1b\u63a5\u7740\uff0c\u5c55\u793a\u4e86\u4e00\u4e2a\u7279\u6b8a\u7684\u3001\u5177\u6709\u76f8\u5173\u566a\u58f0\u7684\u6f02\u79fb\u6269\u6563\u6a21\u578b\u5982\u4f55\u4ece\u9075\u5faa\u5c40\u90e8\u5b66\u4e60\u89c4\u5219\u7684\u970d\u514b\u65af\u8fc7\u7a0b\u7f51\u7edc\u4e2d\u7684\u5c16\u5cf0\u795e\u7ecf\u5143\u884d\u751f\u800c\u6765\uff1b\u6700\u540e\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u65bd\u4e86\u4e00\u4e2a\u5728\u7ebf\u5206\u7c7b\u4efb\u52a1\u6765\u6d4b\u8bd5\u6240\u63d0\u51fa\u7684\u6a21\u578b\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6f02\u79fb\u6269\u6563\u6a21\u578b\u80fd\u591f\u88ab\u57fa\u4e8e\u6cca\u677e\u8fc7\u7a0b\u7684\u5c16\u5cf0\u795e\u7ecf\u5143\u6709\u6548\u8fd1\u4f3c\uff0c\u5e76\u4e14\u542b\u6709\u76f8\u5173\u566a\u58f0\u7684\u6f02\u79fb\u6269\u6563\u6a21\u578b\u53ef\u4ece\u970d\u514b\u65af\u8fc7\u7a0b\u7f51\u7edc\u4e2d\u5f97\u51fa\u3002\u6b64\u5916\uff0c\u5728\u7ebf\u5206\u7c7b\u4efb\u52a1\u7684\u7ed3\u679c\u652f\u6301\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7406\u89e3\u795e\u7ecf\u6d3b\u52a8\u4e0e\u884c\u4e3a\u4e4b\u95f4\u7684\u5173\u7cfb\u505a\u51fa\u4e86\u91cd\u8981\u8d21\u732e\uff0c\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u7684SNN\u6a21\u578b\uff0c\u5b83\u4e0d\u4ec5\u6a21\u4eff\u4e86\u5927\u8111\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u8fd8\u5305\u542b\u4e86\u5b66\u4e60\u673a\u5236\u3002\u8fd9\u9879\u5de5\u4f5c\u4fc3\u8fdb\u4e86\u5c06\u751f\u7269\u76f8\u5173\u7684\u795e\u7ecf\u673a\u5236\u6574\u5408\u8fdb\u8ba4\u77e5\u6a21\u578b\u7684\u52aa\u529b\uff0c\u6709\u52a9\u4e8e\u66f4\u6df1\u5165\u5730\u7406\u89e3\u5927\u8111\u529f\u80fd\u3002"}}
{"id": "2506.09659", "pdf": "https://arxiv.org/pdf/2506.09659", "abs": "https://arxiv.org/abs/2506.09659", "authors": ["Eltayeb Ahmed", "Uljad Berdica", "Martha Elliott", "Danijela Horak", "Jakob N. Foerster"], "title": "Intent Factored Generation: Unleashing the Diversity in Your Language Model", "categories": ["cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "Obtaining multiple meaningfully diverse, high quality samples from Large\nLanguage Models for a fixed prompt remains an open challenge. Current methods\nfor increasing diversity often only operate at the token-level, paraphrasing\nthe same response. This is problematic because it leads to poor exploration on\nreasoning problems and to unengaging, repetitive conversational agents. To\naddress this we propose Intent Factored Generation (IFG), factorising the\nsampling process into two stages. First, we sample a semantically dense intent,\ne.g., a summary or keywords. Second, we sample the final response conditioning\non both the original prompt and the intent from the first stage. This allows us\nto use a higher temperature during the intent step to promote conceptual\ndiversity, and a lower temperature during the final generation to ensure the\noutputs are coherent and self-consistent. Additionally, we find that prompting\nthe model to explicitly state its intent for each step of the chain-of-thought\nbefore generating the step is beneficial for reasoning tasks. We demonstrate\nour method's effectiveness across a diverse set of tasks. We show this method\nimproves both pass@k and Reinforcement Learning from Verifier Feedback on maths\nand code tasks. For instruction-tuning, we combine IFG with Direct Preference\nOptimisation to increase conversational diversity without sacrificing reward.\nFinally, we achieve higher diversity while maintaining the quality of\ngenerations on a general language modelling task, using a new dataset of reader\ncomments and news articles that we collect and open-source. In summary, we\npresent a simple method of increasing the sample diversity of LLMs while\nmaintaining performance. This method can be implemented by changing the prompt\nand varying the temperature during generation, making it easy to integrate into\nmany algorithms for gains across various applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u610f\u56fe\u5206\u89e3\u751f\u6210\uff08IFG\uff09\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u91c7\u6837\u8fc7\u7a0b\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\u6765\u589e\u52a0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u591a\u6837\u6027\uff1a\u9996\u5148\u62bd\u53d6\u8bed\u4e49\u5bc6\u96c6\u7684\u610f\u56fe\uff0c\u5982\u6458\u8981\u6216\u5173\u952e\u8bcd\uff1b\u7136\u540e\u6839\u636e\u539f\u59cb\u63d0\u793a\u548c\u8be5\u610f\u56fe\u751f\u6210\u6700\u7ec8\u54cd\u5e94\u3002\u8fd9\u79cd\u65b9\u6cd5\u63d0\u9ad8\u4e86\u591a\u6837\u6027\u548c\u63a8\u7406\u4efb\u52a1\u8868\u73b0\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u4fdd\u6301\u4e86\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u901a\u5e38\u53ea\u5728\u8bcd\u5143\u7ea7\u522b\u4e0a\u589e\u52a0\u591a\u6837\u6027\uff0c\u5bfc\u81f4\u63a8\u7406\u95ee\u9898\u63a2\u7d22\u4e0d\u8db3\u4ee5\u53ca\u5bf9\u8bdd\u4ee3\u7406\u4e4f\u5473\u91cd\u590d\u3002", "method": "\u63d0\u51fa\u4e86\u610f\u56fe\u5206\u89e3\u751f\u6210\uff08IFG\uff09\uff0c\u5c06\u62bd\u6837\u8fc7\u7a0b\u5206\u89e3\u4e3a\u4e24\u4e2a\u9636\u6bb5\u3002\u7b2c\u4e00\u9636\u6bb5\uff0c\u62bd\u53d6\u4e00\u4e2a\u8bed\u4e49\u5bc6\u96c6\u7684\u610f\u56fe\uff0c\u6bd4\u5982\u6458\u8981\u6216\u8005\u5173\u952e\u8bcd\u3002\u7b2c\u4e8c\u9636\u6bb5\uff0c\u5728\u7ed9\u5b9a\u521d\u59cb\u63d0\u793a\u548c\u7b2c\u4e00\u9636\u6bb5\u610f\u56fe\u7684\u60c5\u51b5\u4e0b\uff0c\u751f\u6210\u6700\u7ec8\u7684\u56de\u7b54\u3002\u540c\u65f6\uff0c\u7814\u7a76\u53d1\u73b0\u4fc3\u4f7f\u6a21\u578b\u5728\u6bcf\u4e00\u6b65\u94fe\u5f0f\u601d\u8003\u524d\u660e\u786e\u5176\u610f\u56fe\u5bf9\u63a8\u7406\u4efb\u52a1\u662f\u6709\u76ca\u7684\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u5c55\u73b0\u4e86\u6709\u6548\u6027\uff0c\u5305\u62ec\u63d0\u9ad8\u6570\u5b66\u548c\u4ee3\u7801\u4efb\u52a1\u4e2d\u7684pass@k\u548c\u4ece\u9a8c\u8bc1\u8005\u53cd\u9988\u4e2d\u5b66\u4e60\u5f3a\u5316\u5b66\u4e60\u7684\u8868\u73b0\u3002\u5bf9\u4e8e\u6307\u4ee4\u8c03\u4f18\uff0c\u7ed3\u5408\u76f4\u63a5\u504f\u597d\u4f18\u5316\u589e\u52a0\u4e86\u5bf9\u8bdd\u591a\u6837\u6027\u800c\u6ca1\u6709\u727a\u7272\u5956\u52b1\u3002\u6b64\u5916\uff0c\u8fd8\u4f7f\u7528\u65b0\u6536\u96c6\u7684\u6570\u636e\u96c6\u8bc1\u660e\u4e86\u5728\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u591a\u6837\u6027\u3002", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7b80\u5355\u6709\u6548\u7684\u65b9\u6cd5\u6765\u589e\u52a0\u5927\u8bed\u8a00\u6a21\u578b\u6837\u672c\u591a\u6837\u6027\uff0c\u540c\u65f6\u7ef4\u6301\u6027\u80fd\u3002\u6b64\u65b9\u6cd5\u53ef\u4ee5\u901a\u8fc7\u6539\u53d8\u63d0\u793a\u5e76\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u8c03\u6574\u6e29\u5ea6\u6765\u5b9e\u73b0\uff0c\u6613\u4e8e\u96c6\u6210\u5230\u8bb8\u591a\u7b97\u6cd5\u4e2d\u4ee5\u83b7\u5f97\u5404\u79cd\u5e94\u7528\u7684\u6536\u76ca\u3002"}}
{"id": "2506.09681", "pdf": "https://arxiv.org/pdf/2506.09681", "abs": "https://arxiv.org/abs/2506.09681", "authors": ["Vahan Arsenyan", "Elen Vardanyan", "Arnak Dalalyan"], "title": "Assessing the Quality of Denoising Diffusion Models in Wasserstein Distance: Noisy Score and Optimal Bounds", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Generative modeling aims to produce new random examples from an unknown\ntarget distribution, given access to a finite collection of examples. Among the\nleading approaches, denoising diffusion probabilistic models (DDPMs) construct\nsuch examples by mapping a Brownian motion via a diffusion process driven by an\nestimated score function. In this work, we first provide empirical evidence\nthat DDPMs are robust to constant-variance noise in the score evaluations. We\nthen establish finite-sample guarantees in Wasserstein-2 distance that exhibit\ntwo key features: (i) they characterize and quantify the robustness of DDPMs to\nnoisy score estimates, and (ii) they achieve faster convergence rates than\npreviously known results. Furthermore, we observe that the obtained rates match\nthose known in the Gaussian case, implying their optimality.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b(DDPMs)\u5bf9\u4e8e\u566a\u58f0\u8bc4\u5206\u4f30\u8ba1\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u8bc1\u636e\uff0c\u5e76\u4e14\u5728Wasserstein-2\u8ddd\u79bb\u4e0a\u5efa\u7acb\u4e86\u6709\u9650\u6837\u672c\u4fdd\u8bc1\uff0c\u5176\u6536\u655b\u901f\u5ea6\u4f18\u4e8e\u5148\u524d\u7684\u7ed3\u679c\uff0c\u5e76\u4e14\u8fbe\u5230\u4e86\u5df2\u77e5\u7684\u9ad8\u65af\u60c5\u51b5\u4e0b\u7684\u6700\u4f18\u901f\u7387\u3002", "motivation": "\u751f\u6210\u5efa\u6a21\u7684\u76ee\u6807\u662f\u6839\u636e\u6709\u9650\u7684\u4f8b\u5b50\u96c6\u5408\u6765\u4ea7\u751f\u7b26\u5408\u672a\u77e5\u76ee\u6807\u5206\u5e03\u7684\u65b0\u968f\u673a\u4f8b\u5b50\u3002\u4f5c\u4e3a\u4e3b\u8981\u65b9\u6cd5\u4e4b\u4e00\uff0c\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b(DDPMs)\u901a\u8fc7\u4e00\u4e2a\u7531\u4f30\u8ba1\u5f97\u5206\u51fd\u6570\u9a71\u52a8\u7684\u6269\u6563\u8fc7\u7a0b\u6620\u5c04\u5e03\u6717\u8fd0\u52a8\u6765\u6784\u9020\u8fd9\u4e9b\u4f8b\u5b50\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7d22DDPMs\u5bf9\u566a\u58f0\u8bc4\u5206\u4f30\u8ba1\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u63d0\u4f9b\u7406\u8bba\u4e0a\u7684\u4fdd\u8bc1\u3002", "method": "\u7814\u7a76\u9996\u5148\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u8bc1\u636e\uff0c\u8868\u660eDDPMs\u5bf9\u8bc4\u5206\u8bc4\u4f30\u4e2d\u7684\u5e38\u6570\u65b9\u5dee\u566a\u58f0\u5177\u6709\u9c81\u68d2\u6027\u3002\u7136\u540e\uff0c\u5728Wasserstein-2\u8ddd\u79bb\u4e0a\u5efa\u7acb\u4e86\u6709\u9650\u6837\u672c\u7684\u4fdd\u8bc1\uff0c\u8fd9\u4f53\u73b0\u4e86\u4e24\u4e2a\u5173\u952e\u7279\u5f81\uff1a\uff08i\uff09\u5b83\u4eec\u8868\u5f81\u5e76\u91cf\u5316\u4e86DDPMs\u5bf9\u566a\u58f0\u8bc4\u5206\u4f30\u8ba1\u7684\u9c81\u68d2\u6027\uff1b\uff08ii\uff09\u5b83\u4eec\u5b9e\u73b0\u4e86\u6bd4\u4e4b\u524d\u7ed3\u679c\u66f4\u5feb\u7684\u6536\u655b\u7387\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0cDDPMs\u786e\u5b9e\u5bf9\u566a\u58f0\u8bc4\u5206\u4f30\u8ba1\u8868\u73b0\u51fa\u9c81\u68d2\u6027\uff0c\u5e76\u4e14\u5728Wasserstein-2\u8ddd\u79bb\u4e0a\u83b7\u5f97\u4e86\u6bd4\u4ee5\u5f80\u7ed3\u679c\u66f4\u5feb\u7684\u6536\u655b\u7387\u3002\u6b64\u5916\uff0c\u89c2\u5bdf\u5230\u5f97\u5230\u7684\u6536\u655b\u7387\u4e0e\u9ad8\u65af\u60c5\u51b5\u4e0b\u7684\u6536\u655b\u7387\u76f8\u5339\u914d\uff0c\u6697\u793a\u4e86\u5b83\u4eec\u7684\u6700\u4f18\u6027\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0cDDPMs\u4e0d\u4ec5\u5bf9\u566a\u58f0\u8bc4\u5206\u4f30\u8ba1\u5177\u6709\u9c81\u68d2\u6027\uff0c\u800c\u4e14\u5728Wasserstein-2\u8ddd\u79bb\u4e0a\u8fbe\u5230\u4e86\u6700\u4f18\u7684\u6536\u655b\u7387\uff0c\u8fd9\u4e3a\u751f\u6210\u5efa\u6a21\u9886\u57df\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2506.09090", "pdf": "https://arxiv.org/pdf/2506.09090", "abs": "https://arxiv.org/abs/2506.09090", "authors": ["Arthur Oghlukyan", "Nuria Gomez Blas"], "title": "Integrating Asynchronous AdaBoost into Federated Learning: Five Real World Applications", "categories": ["cs.LG"], "comment": null, "summary": "This paper presents a comprehensive analysis of an enhanced asynchronous\nAdaBoost framework for federated learning (FL), focusing on its application\nacross five distinct domains: computer vision on edge devices, blockchain-based\nmodel transparency, on-device mobile personalization, IoT anomaly detection,\nand federated healthcare diagnostics. The proposed algorithm incorporates\nadaptive communication scheduling and delayed weight compensation to reduce\nsynchronization frequency and communication overhead while preserving or\nimproving model accuracy. We examine how these innovations improve\ncommunication efficiency, scalability, convergence, and robustness in each\ndomain. Comparative metrics including training time, communication overhead,\nconvergence iterations, and classification accuracy are evaluated using data\nand estimates derived from Oghlukyan's enhanced AdaBoost framework. Empirical\nresults show, for example, training time reductions on the order of 20-35% and\ncommunication overhead reductions of 30-40% compared to baseline AdaBoost, with\nconvergence achieved in significantly fewer boosting rounds. Tables and charts\nsummarize these improvements by domain. Mathematical formulations of the\nadaptive scheduling rule and error-driven synchronization thresholds are\nprovided. Overall, the enhanced AdaBoost exhibits markedly improved efficiency\nand robustness across diverse FL scenarios, suggesting broad applicability of\nthe approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u589e\u5f3a\u7684\u5f02\u6b65AdaBoost\u6846\u67b6\uff0c\u7528\u4e8e\u8054\u90a6\u5b66\u4e60\uff0c\u5e76\u5728\u4e94\u4e2a\u4e0d\u540c\u9886\u57df\u8fdb\u884c\u4e86\u5e94\u7528\u3002\u901a\u8fc7\u5f15\u5165\u81ea\u9002\u5e94\u901a\u4fe1\u8c03\u5ea6\u548c\u5ef6\u8fdf\u6743\u91cd\u8865\u507f\u673a\u5236\uff0c\u8be5\u6846\u67b6\u51cf\u5c11\u4e86\u540c\u6b65\u9891\u7387\u548c\u901a\u4fe1\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u4e86\u6a21\u578b\u51c6\u786e\u6027\u3002\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u57fa\u51c6AdaBoost\u76f8\u6bd4\uff0c\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u4e8620-35%\uff0c\u901a\u4fe1\u5f00\u9500\u964d\u4f4e\u4e8630-40%\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u6539\u8fdb\u8054\u90a6\u5b66\u4e60\u4e2d\u6a21\u578b\u8bad\u7ec3\u7684\u6548\u7387\u548c\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u7684\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u6a21\u578b\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u7684\u65b9\u6cd5\u662f\u5f00\u53d1\u4e00\u79cd\u589e\u5f3a\u578b\u5f02\u6b65AdaBoost\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u7ed3\u5408\u4e86\u81ea\u9002\u5e94\u901a\u4fe1\u8c03\u5ea6\u548c\u5ef6\u8fdf\u6743\u91cd\u8865\u507f\u6280\u672f\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5728\u591a\u4e2a\u9886\u57df\u5185\uff0c\u65b0\u7684AdaBoost\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u9c81\u68d2\u6027\uff0c\u6bd4\u5982\u8bad\u7ec3\u65f6\u95f4\u548c\u901a\u4fe1\u5f00\u9500\u5206\u522b\u51cf\u5c11\u4e8620-35%\u548c30-40%\u3002", "conclusion": "\u7ed3\u8bba\u6307\u51fa\uff0c\u589e\u5f3a\u7248AdaBoost\u5728\u4e0d\u540c\u7684\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u6548\u7387\u548c\u9c81\u68d2\u6027\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.09977", "pdf": "https://arxiv.org/pdf/2506.09977", "abs": "https://arxiv.org/abs/2506.09977", "authors": ["Stylianos Loukas Vasileiou", "Antonio Rago", "Maria Vanina Martinez", "William Yeoh"], "title": "How Do People Revise Inconsistent Beliefs? Examining Belief Revision in Humans with User Studies", "categories": ["cs.AI"], "comment": null, "summary": "Understanding how humans revise their beliefs in light of new information is\ncrucial for developing AI systems which can effectively model, and thus align\nwith, human reasoning. While theoretical belief revision frameworks rely on a\nset of principles that establish how these operations are performed, empirical\nevidence from cognitive psychology suggests that people may follow different\npatterns when presented with conflicting information. In this paper, we present\nthree comprehensive user studies showing that people consistently prefer\nexplanation-based revisions, i.e., those which are guided by explanations, that\nresult in changes to their belief systems that are not necessarily captured by\nclassical belief change theory. Our experiments systematically investigate how\npeople revise their beliefs with explanations for inconsistencies, whether they\nare provided with them or left to formulate them themselves, demonstrating a\nrobust preference for what may seem non-minimal revisions across different\ntypes of scenarios. These findings have implications for AI systems designed to\nmodel human reasoning or interact with humans, suggesting that such systems\nshould accommodate explanation-based, potentially non-minimal belief revision\noperators to better align with human cognitive processes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u4e09\u4e2a\u7528\u6237\u7814\u7a76\u53d1\u73b0\uff0c\u4eba\u4eec\u5728\u9762\u5bf9\u77db\u76fe\u4fe1\u606f\u65f6\u503e\u5411\u4e8e\u57fa\u4e8e\u89e3\u91ca\u7684\u4fe1\u5ff5\u4fee\u6b63\uff0c\u8fd9\u79cd\u504f\u597d\u5e76\u4e0d\u603b\u662f\u7b26\u5408\u7ecf\u5178\u4fe1\u5ff5\u6539\u53d8\u7406\u8bba\u3002\u8fd9\u4e9b\u53d1\u73b0\u5bf9\u65e8\u5728\u6a21\u62df\u4eba\u7c7b\u63a8\u7406\u6216\u4e0e\u4eba\u4ea4\u4e92\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u5efa\u8bae\u8fd9\u4e9b\u7cfb\u7edf\u5e94\u8003\u8651\u57fa\u4e8e\u89e3\u91ca\u3001\u53ef\u80fd\u975e\u6700\u5c0f\u5316\u7684\u4fe1\u5ff5\u4fee\u6b63\u673a\u5236\uff0c\u4ee5\u66f4\u597d\u5730\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u8fc7\u7a0b\u76f8\u4e00\u81f4\u3002", "motivation": "\u7406\u89e3\u4eba\u7c7b\u5982\u4f55\u6839\u636e\u65b0\u4fe1\u606f\u66f4\u65b0\u81ea\u5df1\u7684\u4fe1\u5ff5\u5bf9\u4e8e\u5f00\u53d1\u80fd\u591f\u6709\u6548\u5efa\u6a21\u5e76\u56e0\u6b64\u4e0e\u4eba\u7c7b\u63a8\u7406\u4fdd\u6301\u4e00\u81f4\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u867d\u7136\u7406\u8bba\u4e0a\u7684\u4fe1\u5ff5\u4fee\u6b63\u6846\u67b6\u4f9d\u8d56\u4e8e\u4e00\u5957\u539f\u5219\u6765\u786e\u5b9a\u8fd9\u4e9b\u64cd\u4f5c\u662f\u5982\u4f55\u6267\u884c\u7684\uff0c\u4f46\u6765\u81ea\u8ba4\u77e5\u5fc3\u7406\u5b66\u7684\u7ecf\u9a8c\u8bc1\u636e\u8868\u660e\uff0c\u5f53\u9762\u5bf9\u51b2\u7a81\u4fe1\u606f\u65f6\uff0c\u4eba\u4eec\u53ef\u80fd\u4f1a\u9075\u5faa\u4e0d\u540c\u7684\u6a21\u5f0f\u3002", "method": "\u8fdb\u884c\u4e86\u4e09\u9879\u5168\u9762\u7684\u7528\u6237\u7814\u7a76\uff0c\u5c55\u793a\u4eba\u4eec\u5728\u9047\u5230\u4e0d\u4e00\u81f4\u7684\u4fe1\u606f\u65f6\uff0c\u65e0\u8bba\u662f\u63d0\u4f9b\u7ed9\u4ed6\u4eec\u7684\u8fd8\u662f\u81ea\u5df1\u5f62\u6210\u7684\u89e3\u91ca\uff0c\u90fd\u59cb\u7ec8\u504f\u597d\u57fa\u4e8e\u89e3\u91ca\u7684\u4fee\u6b63\uff0c\u8fd9\u5bfc\u81f4\u4e86\u4ed6\u4eec\u4fe1\u5ff5\u7cfb\u7edf\u7684\u6539\u53d8\uff0c\u800c\u8fd9\u4e9b\u6539\u53d8\u4e0d\u4e00\u5b9a\u88ab\u7ecf\u5178\u7684\u4fe1\u5ff5\u6539\u53d8\u7406\u8bba\u6240\u6355\u6349\u5230\u3002", "result": "\u5b9e\u9a8c\u7cfb\u7edf\u5730\u8c03\u67e5\u4e86\u4eba\u4eec\u5982\u4f55\u7528\u89e3\u91ca\u6765\u4fee\u6b63\u4ed6\u4eec\u7684\u4fe1\u5ff5\uff0c\u63ed\u793a\u51fa\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u573a\u666f\u4e0b\u5bf9\u770b\u4f3c\u975e\u6700\u5c0f\u5316\u4fee\u6b63\u7684\u5f3a\u70c8\u504f\u597d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4e3a\u4e86\u66f4\u597d\u5730\u4e0e\u4eba\u7c7b\u7684\u8ba4\u77e5\u8fc7\u7a0b\u76f8\u4e00\u81f4\uff0c\u8bbe\u8ba1\u7528\u6765\u6a21\u62df\u4eba\u7c7b\u63a8\u7406\u6216\u4e0e\u4eba\u7c7b\u4e92\u52a8\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u5e94\u8be5\u8003\u8651\u5230\u57fa\u4e8e\u89e3\u91ca\u7684\u3001\u53ef\u80fd\u662f\u975e\u6700\u5c0f\u5316\u7684\u4fe1\u5ff5\u4fee\u6b63\u64cd\u4f5c\u8005\u3002"}}
{"id": "2506.09832", "pdf": "https://arxiv.org/pdf/2506.09832", "abs": "https://arxiv.org/abs/2506.09832", "authors": ["Dany Lauzon", "Julien Straubhaar", "Philippe Renard"], "title": "A Deep Generative Model for the Simulation of Discrete Karst Networks", "categories": ["stat.ML", "cs.LG"], "comment": "26 pages, 15 figures, submitted to Earth and Space Science", "summary": "The simulation of discrete karst networks presents a significant challenge\ndue to the complexity of the physicochemical processes occurring within various\ngeological and hydrogeological contexts over extended periods. This complex\ninterplay leads to a wide variety of karst network patterns, each intricately\nlinked to specific hydrogeological conditions. We explore a novel approach that\nrepresents karst networks as graphs and applies graph generative models (deep\nlearning techniques) to capture the intricate nature of karst environments. In\nthis representation, nodes retain spatial information and properties, while\nedges signify connections between nodes. Our generative process consists of two\nmain steps. First, we utilize graph recurrent neural networks (GraphRNN) to\nlearn the topological distribution of karst networks. GraphRNN decomposes the\ngraph simulation into a sequential generation of nodes and edges, informed by\npreviously generated structures. Second, we employ denoising diffusion\nprobabilistic models on graphs (G-DDPM) to learn node features (spatial\ncoordinates and other properties). G-DDPMs enable the generation of nodes\nfeatures on the graphs produced by the GraphRNN that adhere to the learned\nstatistical properties by sampling from the derived probability distribution,\nensuring that the generated graphs are realistic and capture the essential\nfeatures of the original data. We test our approach using real-world karst\nnetworks and compare generated subgraphs with actual subgraphs from the\ndatabase, by using geometry and topology metrics. Our methodology allows\nstochastic simulation of discrete karst networks across various types of\nformations, a useful tool for studying the behavior of physical processes such\nas flow and transport.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5c06\u5ca9\u6eb6\u7f51\u7edc\u8868\u793a\u4e3a\u56fe\uff0c\u5e76\u5e94\u7528\u56fe\u751f\u6210\u6a21\u578b\uff08\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff09\u6765\u6355\u6349\u5ca9\u6eb6\u73af\u5883\u7684\u590d\u6742\u6027\u3002\u901a\u8fc7\u4f7f\u7528\u56fe\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\uff08GraphRNN\uff09\u548c\u56fe\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\uff08G-DDPM\uff09\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6a21\u62df\u51fa\u903c\u771f\u7684\u5ca9\u6eb6\u7f51\u7edc\uff0c\u6709\u52a9\u4e8e\u7814\u7a76\u6d41\u4f53\u6d41\u52a8\u7b49\u7269\u7406\u8fc7\u7a0b\u7684\u884c\u4e3a\u3002", "motivation": "\u7531\u4e8e\u5728\u5404\u79cd\u5730\u8d28\u548c\u6c34\u6587\u5730\u8d28\u80cc\u666f\u4e0b\u957f\u65f6\u95f4\u53d1\u751f\u7684\u7269\u7406\u5316\u5b66\u8fc7\u7a0b\u7684\u590d\u6742\u6027\uff0c\u79bb\u6563\u5ca9\u6eb6\u7f51\u7edc\u7684\u6a21\u62df\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u6311\u6218\u3002\u8fd9\u4e9b\u590d\u6742\u7684\u76f8\u4e92\u4f5c\u7528\u5bfc\u81f4\u4e86\u591a\u79cd\u5ca9\u6eb6\u7f51\u7edc\u6a21\u5f0f\uff0c\u6bcf\u4e00\u79cd\u90fd\u4e0e\u7279\u5b9a\u7684\u6c34\u6587\u5730\u8d28\u6761\u4ef6\u7d27\u5bc6\u76f8\u5173\u3002", "method": "\u8be5\u65b9\u6cd5\u5c06\u5ca9\u6eb6\u7f51\u7edc\u89c6\u4e3a\u56fe\uff0c\u5e76\u91c7\u7528\u56fe\u751f\u6210\u6a21\u578b\uff08\u5982\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff09\u6765\u7406\u89e3\u5ca9\u6eb6\u73af\u5883\u7684\u590d\u6742\u6027\u3002\u8282\u70b9\u4fdd\u7559\u7a7a\u95f4\u4fe1\u606f\u548c\u5c5e\u6027\uff0c\u8fb9\u5219\u8868\u793a\u8282\u70b9\u4e4b\u95f4\u7684\u8fde\u63a5\u3002\u751f\u6210\u8fc7\u7a0b\u5206\u4e3a\u4e24\u4e2a\u4e3b\u8981\u6b65\u9aa4\uff1a\u9996\u5148\uff0c\u5229\u7528\u56fe\u9012\u5f52\u795e\u7ecf\u7f51\u7edc\uff08GraphRNN\uff09\u5b66\u4e60\u5ca9\u6eb6\u7f51\u7edc\u7684\u62d3\u6251\u5206\u5e03\uff1b\u5176\u6b21\uff0c\u5bf9\u56fe\u4e0a\u7684\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\uff08G-DDPM\uff09\u8fdb\u884c\u8bad\u7ec3\u4ee5\u5b66\u4e60\u8282\u70b9\u7279\u5f81\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6839\u636e\u5b9e\u9645\u4e16\u754c\u4e2d\u7684\u5ca9\u6eb6\u7f51\u7edc\u6570\u636e\u751f\u6210\u5b50\u56fe\uff0c\u5e76\u4e14\u901a\u8fc7\u51e0\u4f55\u548c\u62d3\u6251\u5ea6\u91cf\u4e0e\u6570\u636e\u5e93\u4e2d\u7684\u5b9e\u9645\u5b50\u56fe\u8fdb\u884c\u6bd4\u8f83\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u8de8\u4e0d\u540c\u7c7b\u578b\u7684\u5730\u5c42\u968f\u673a\u6a21\u62df\u79bb\u6563\u5ca9\u6eb6\u7f51\u7edc\u3002", "conclusion": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u751f\u6210\u6a21\u578b\u7684\u65b0\u578b\u65b9\u6cd5\u6765\u6a21\u62df\u5ca9\u6eb6\u7f51\u7edc\uff0c\u8fd9\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u80fd\u591f\u751f\u6210\u903c\u771f\u7684\u5ca9\u6eb6\u7f51\u7edc\u7ed3\u6784\uff0c\u8fd8\u80fd\u5e2e\u52a9\u79d1\u5b66\u5bb6\u4eec\u66f4\u597d\u5730\u7406\u89e3\u5e76\u9884\u6d4b\u5ca9\u6eb6\u73af\u5883\u4e0b\u7684\u7269\u7406\u8fc7\u7a0b\u884c\u4e3a\u3002"}}
{"id": "2506.09091", "pdf": "https://arxiv.org/pdf/2506.09091", "abs": "https://arxiv.org/abs/2506.09091", "authors": ["Kenric Nelson", "Igor Oliveira", "Amenah Al-Najafi", "Fode Zhang", "Hon Keung Tony Ng"], "title": "Variational Inference Optimized Using the Curved Geometry of Coupled Free Energy", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "11 pages, 2 figures, AGI-25", "summary": "We introduce an optimization framework for variational inference based on the\ncoupled free energy, extending variational inference techniques to account for\nthe curved geometry of the coupled exponential family. This family includes\nimportant heavy-tailed distributions such as the generalized Pareto and the\nStudent's t. By leveraging the coupled free energy, which is equal to the\ncoupled evidence lower bound (ELBO) of the inverted probabilities, we improve\nthe accuracy and robustness of the learned model. The coupled generalization of\nFisher Information metric and the affine connection. The method is applied to\nthe design of a coupled variational autoencoder (CVAE). By using the coupling\nfor both the distributions and cost functions, the reconstruction metric is\nderived to still be the mean-square average loss with modified constants. The\nnovelty comes from sampling the heavy-tailed latent distribution with its\nassociated coupled probability, which has faster decaying tails. The result is\nthe ability to train a model with high penalties in the tails, while assuring\nthat the training samples have a reduced number of outliers. The Wasserstein-2\nor Fr\\'echet Inception Distance of the reconstructed CelebA images shows the\nCVAE has a 3\\% improvement over the VAE after 5 epochs of training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8026\u5408\u81ea\u7531\u80fd\u7684\u53d8\u5206\u63a8\u65ad\u4f18\u5316\u6846\u67b6\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5904\u7406\u91cd\u5c3e\u5206\u5e03\uff0c\u5e76\u901a\u8fc7\u5728CVAE\u4e2d\u5e94\u7528\u6765\u63d0\u9ad8\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728CelebA\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4VAE\uff0cCVAE\u57285\u4e2a\u8bad\u7ec3\u5468\u671f\u540e\u6027\u80fd\u63d0\u9ad8\u4e863%\u3002", "motivation": "\u4e3a\u4e86\u6269\u5c55\u53d8\u5206\u63a8\u65ad\u6280\u672f\u4ee5\u8003\u8651\u8026\u5408\u6307\u6570\u65cf\u7684\u5f2f\u66f2\u51e0\u4f55\u7279\u6027\uff0c\u5e76\u63d0\u9ad8\u6240\u5b66\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "\u5f15\u5165\u4e86\u57fa\u4e8e\u8026\u5408\u81ea\u7531\u80fd\u7684\u4f18\u5316\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7b49\u540c\u4e8e\u5012\u7f6e\u6982\u7387\u7684\u8026\u5408\u8bc1\u636e\u4e0b\u754c\uff08ELBO\uff09\u3002\u540c\u65f6\uff0c\u63a8\u5e7f\u4e86Fisher\u4fe1\u606f\u5ea6\u91cf\u548c\u4eff\u5c04\u8fde\u63a5\uff0c\u5e76\u5e94\u7528\u4e8e\u8bbe\u8ba1\u8026\u5408\u53d8\u5206\u81ea\u52a8\u7f16\u7801\u5668\uff08CVAE\uff09\u3002\u901a\u8fc7\u4f7f\u7528\u8026\u5408\u6982\u7387\u5bf9\u91cd\u5c3e\u6f5c\u5728\u5206\u5e03\u8fdb\u884c\u91c7\u6837\uff0c\u4fee\u6539\u4e86\u5747\u65b9\u5e73\u5747\u635f\u5931\u4e2d\u7684\u5e38\u6570\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u5177\u6709\u66f4\u5feb\u8870\u51cf\u5c3e\u90e8\u7684\u5173\u8054\u8026\u5408\u6982\u7387\u5bf9\u91cd\u5c3e\u6f5c\u5728\u5206\u5e03\u8fdb\u884c\u91c7\u6837\uff0c\u4f7f\u5f97\u6a21\u578b\u80fd\u591f\u5bf9\u5c3e\u90e8\u65bd\u52a0\u9ad8\u60e9\u7f5a\uff0c\u540c\u65f6\u4fdd\u8bc1\u8bad\u7ec3\u6837\u672c\u4e2d\u5f02\u5e38\u503c\u6570\u91cf\u51cf\u5c11\u3002CelebA\u56fe\u50cf\u91cd\u6784\u7684Wasserstein-2\u6216Fr\u00e9chet\u521d\u59cb\u8ddd\u79bb\u663e\u793a\uff0cCVAE\u76f8\u6bd4VAE\u57285\u4e2a\u8bad\u7ec3\u5468\u671f\u540e\u7684\u6027\u80fd\u63d0\u9ad8\u4e863%\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u8026\u5408\u81ea\u7531\u80fd\u7684\u53d8\u5206\u63a8\u65ad\u4f18\u5316\u6846\u67b6\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5305\u542b\u91cd\u8981\u91cd\u5c3e\u5206\u5e03\u7684\u60c5\u51b5\u3002"}}
{"id": "2506.09985", "pdf": "https://arxiv.org/pdf/2506.09985", "abs": "https://arxiv.org/abs/2506.09985", "authors": ["Mido Assran", "Adrien Bardes", "David Fan", "Quentin Garrido", "Russell Howes", "Mojtaba", "Komeili", "Matthew Muckley", "Ammar Rizvi", "Claire Roberts", "Koustuv Sinha", "Artem Zholus", "Sergio Arnaud", "Abha Gejji", "Ada Martin", "Francois Robert Hogan", "Daniel Dugas", "Piotr Bojanowski", "Vasil Khalidov", "Patrick Labatut", "Francisco Massa", "Marc Szafraniec", "Kapil Krishnakumar", "Yong Li", "Xiaodong Ma", "Sarath Chandar", "Franziska Meier", "Yann LeCun", "Michael Rabbat", "Nicolas Ballas"], "title": "V-JEPA 2: Self-Supervised Video Models Enable Understanding, Prediction and Planning", "categories": ["cs.AI", "cs.CV", "cs.LG", "cs.RO"], "comment": "48 pages, 19 figures", "summary": "A major challenge for modern AI is to learn to understand the world and learn\nto act largely by observation. This paper explores a self-supervised approach\nthat combines internet-scale video data with a small amount of interaction data\n(robot trajectories), to develop models capable of understanding, predicting,\nand planning in the physical world. We first pre-train an action-free\njoint-embedding-predictive architecture, V-JEPA 2, on a video and image dataset\ncomprising over 1 million hours of internet video. V-JEPA 2 achieves strong\nperformance on motion understanding (77.3 top-1 accuracy on Something-Something\nv2) and state-of-the-art performance on human action anticipation (39.7\nrecall-at-5 on Epic-Kitchens-100) surpassing previous task-specific models.\nAdditionally, after aligning V-JEPA 2 with a large language model, we\ndemonstrate state-of-the-art performance on multiple video question-answering\ntasks at the 8 billion parameter scale (e.g., 84.0 on PerceptionTest, 76.9 on\nTempCompass). Finally, we show how self-supervised learning can be applied to\nrobotic planning tasks by post-training a latent action-conditioned world\nmodel, V-JEPA 2-AC, using less than 62 hours of unlabeled robot videos from the\nDroid dataset. We deploy V-JEPA 2-AC zero-shot on Franka arms in two different\nlabs and enable picking and placing of objects using planning with image goals.\nNotably, this is achieved without collecting any data from the robots in these\nenvironments, and without any task-specific training or reward. This work\ndemonstrates how self-supervised learning from web-scale data and a small\namount of robot interaction data can yield a world model capable of planning in\nthe physical world.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u6211\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u7ed3\u5408\u5927\u89c4\u6a21\u4e92\u8054\u7f51\u89c6\u9891\u6570\u636e\u548c\u5c11\u91cf\u673a\u5668\u4eba\u4ea4\u4e92\u6570\u636e\u6765\u8bad\u7ec3\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u591f\u7406\u89e3\u3001\u9884\u6d4b\u5e76\u5728\u7269\u7406\u4e16\u754c\u4e2d\u8fdb\u884c\u89c4\u5212\u3002\u9884\u8bad\u7ec3\u7684V-JEPA 2\u6a21\u578b\u5728\u8fd0\u52a8\u7406\u89e3\u548c\u4eba\u7c7b\u884c\u4e3a\u9884\u6d4b\u4e0a\u53d6\u5f97\u4e86\u5f88\u597d\u7684\u6548\u679c\uff0c\u5e76\u4e14\u901a\u8fc7\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\uff0c\u5728\u591a\u4e2a\u89c6\u9891\u95ee\u7b54\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86\u9886\u5148\u6c34\u5e73\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u4f7f\u7528\u4e0d\u523062\u5c0f\u65f6\u7684\u672a\u6807\u8bb0\u673a\u5668\u4eba\u89c6\u9891\u540e\u8bad\u7ec3\u5f97\u5230\u7684V-JEPA 2-AC\u6a21\u578b\uff0c\u53ef\u4ee5\u5b9e\u73b0\u96f6\u6837\u672c\u60c5\u51b5\u4e0b\u5bf9\u7269\u4f53\u7684\u62fe\u53d6\u548c\u653e\u7f6e\u64cd\u4f5c\u3002", "motivation": "\u73b0\u4ee3\u4eba\u5de5\u667a\u80fd\u9762\u4e34\u7684\u4e00\u5927\u6311\u6218\u662f\u901a\u8fc7\u89c2\u5bdf\u6765\u5b66\u4e60\u7406\u89e3\u4e16\u754c\u5e76\u91c7\u53d6\u884c\u52a8\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u81ea\u6211\u76d1\u7763\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u4e92\u8054\u7f51\u89c4\u6a21\u7684\u89c6\u9891\u6570\u636e\u548c\u5c11\u91cf\u7684\u4e92\u52a8\u6570\u636e\uff08\u673a\u5668\u4eba\u8f68\u8ff9\uff09\u6765\u5f00\u53d1\u80fd\u591f\u7406\u89e3\u3001\u9884\u6d4b\u548c\u89c4\u5212\u7269\u7406\u4e16\u754c\u7684\u6a21\u578b\u3002", "method": "\u7814\u7a76\u8005\u9996\u5148\u5728\u4e00\u4e2a\u5305\u542b\u8d85\u8fc7100\u4e07\u5c0f\u65f6\u7f51\u7edc\u89c6\u9891\u7684\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u4e86\u4e00\u4e2a\u65e0\u52a8\u4f5c\u7684\u8054\u5408\u5d4c\u5165\u9884\u6d4b\u67b6\u6784\u2014\u2014V-JEPA 2\u3002\u7136\u540e\uff0c\u5c06V-JEPA 2\u4e0e\u4e00\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u4ee5\u589e\u5f3a\u5176\u80fd\u529b\u3002\u6700\u540e\uff0c\u4ed6\u4eec\u8fd8\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u5bf9\u6765\u81eaDroid\u6570\u636e\u96c6\u7684\u4e0d\u523062\u5c0f\u65f6\u672a\u7ecf\u6807\u6ce8\u7684\u673a\u5668\u4eba\u89c6\u9891\u8fdb\u884c\u540e\u8bad\u7ec3\uff0c\u6765\u5e94\u7528\u81ea\u6211\u76d1\u7763\u5b66\u4e60\u4e8e\u673a\u5668\u4eba\u89c4\u5212\u4efb\u52a1\u3002", "result": "V-JEPA 2\u5728\u8fd0\u52a8\u7406\u89e3\uff08Something-Something v2\u6570\u636e\u96c6\u4e0a\u7684top-1\u51c6\u786e\u7387\u4e3a77.3%\uff09\u548c\u4eba\u7c7b\u884c\u4e3a\u9884\u671f\uff08Epic-Kitchens-100\u6570\u636e\u96c6\u4e0a\u7684recall-at-5\u4e3a39.7%\uff09\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff1b\u5f53\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u65f6\uff0c\u5728\u591a\u9879\u89c6\u9891\u95ee\u7b54\u4efb\u52a1\u4e2d\u4e5f\u5c55\u793a\u51fa\u4e86\u6700\u65b0\u7684\u6027\u80fd\u6307\u6807\u3002\u6b64\u5916\uff0cV-JEPA 2-AC\u6a21\u578b\u80fd\u591f\u5728\u4e24\u4e2a\u4e0d\u540c\u7684\u5b9e\u9a8c\u5ba4\u73af\u5883\u4e2d\u90e8\u7f72Franka\u673a\u68b0\u81c2\uff0c\u5e76\u57fa\u4e8e\u56fe\u50cf\u76ee\u6807\u6267\u884c\u7269\u4f53\u6293\u53d6\u548c\u653e\u7f6e\u7684\u4efb\u52a1\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u8868\u660e\uff0c\u4ece\u7f51\u7edc\u89c4\u6a21\u7684\u6570\u636e\u548c\u5c11\u91cf\u7684\u673a\u5668\u4eba\u4ea4\u4e92\u6570\u636e\u4e2d\u8fdb\u884c\u81ea\u6211\u76d1\u7763\u5b66\u4e60\uff0c\u53ef\u4ee5\u4ea7\u751f\u4e00\u4e2a\u80fd\u591f\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u8fdb\u884c\u89c4\u5212\u7684\u4e16\u754c\u6a21\u578b\u3002"}}
{"id": "2506.09092", "pdf": "https://arxiv.org/pdf/2506.09092", "abs": "https://arxiv.org/abs/2506.09092", "authors": ["Wentao Chen", "Jiace Zhu", "Qi Fan", "Yehan Ma", "An Zou"], "title": "CUDA-LLM: LLMs Can Write Efficient CUDA Kernels", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong capabilities in\ngeneral-purpose code generation. However, generating the code which is deeply\nhardware-specific, architecture-aware, and performance-critical, especially for\nmassively parallel GPUs, remains a complex challenge. In this work, we explore\nthe use of LLMs for the automated generation and optimization of CUDA programs,\nwith the goal of producing high-performance GPU kernels that fully exploit the\nunderlying hardware. To address this challenge, we propose a novel framework\ncalled \\textbf{Feature Search and Reinforcement (FSR)}. FSR jointly optimizes\ncompilation and functional correctness, as well as the runtime performance,\nwhich are validated through extensive and diverse test cases, and measured by\nactual kernel execution latency on the target GPU, respectively. This approach\nenables LLMs not only to generate syntactically and semantically correct CUDA\ncode but also to iteratively refine it for efficiency, tailored to the\ncharacteristics of the GPU architecture. We evaluate FSR on representative CUDA\nkernels, covering AI workloads and computational intensive algorithms. Our\nresults show that LLMs augmented with FSR consistently guarantee correctness\nrates. Meanwhile, the automatically generated kernels can outperform general\nhuman-written code by a factor of up to 179$\\times$ in execution speeds. These\nfindings highlight the potential of combining LLMs with performance\nreinforcement to automate GPU programming for hardware-specific,\narchitecture-sensitive, and performance-critical applications.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u7279\u5f81\u641c\u7d22\u4e0e\u5f3a\u5316\uff08FSR\uff09\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u81ea\u52a8\u751f\u6210\u548c\u4f18\u5316CUDA\u7a0b\u5e8f\uff0c\u4ee5\u751f\u6210\u9ad8\u6027\u80fdGPU\u5185\u6838\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7FSR\u589e\u5f3a\u7684LLMs\u4e0d\u4ec5\u80fd\u591f\u4fdd\u8bc1\u4ee3\u7801\u7684\u6b63\u786e\u6027\uff0c\u8fd8\u80fd\u4f7f\u81ea\u52a8\u751f\u6210\u7684\u5185\u6838\u5728\u6267\u884c\u901f\u5ea6\u4e0a\u6bd4\u4eba\u7c7b\u7f16\u5199\u7684\u901a\u7528\u4ee3\u7801\u5feb\u9ad8\u8fbe179\u500d\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u901a\u7528\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u4e86\u5f3a\u5927\u7684\u80fd\u529b\uff0c\u4f46\u5bf9\u4e8e\u751f\u6210\u9ad8\u5ea6\u4f9d\u8d56\u786c\u4ef6\u7279\u6027\u7684\u3001\u67b6\u6784\u611f\u77e5\u7684\u4ee5\u53ca\u6027\u80fd\u5173\u952e\u7684\u4ee3\u7801\uff0c\u7279\u522b\u662f\u9488\u5bf9\u5927\u89c4\u6a21\u5e76\u884cGPU\u7684\u4ee3\u7801\uff0c\u4ecd\u7136\u662f\u4e00\u4e2a\u590d\u6742\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a\u7279\u5f81\u641c\u7d22\u4e0e\u5f3a\u5316\uff08FSR\uff09\u7684\u65b0\u6846\u67b6\uff0c\u5b83\u8054\u5408\u4f18\u5316\u4e86\u7f16\u8bd1\u548c\u529f\u80fd\u6b63\u786e\u6027\u4ee5\u53ca\u8fd0\u884c\u65f6\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u5e7f\u6cdb\u7684\u6d4b\u8bd5\u6848\u4f8b\u9a8c\u8bc1\u8fd9\u4e9b\u5c5e\u6027\uff0c\u540c\u65f6\u901a\u8fc7\u5b9e\u9645\u7684\u76ee\u6807GPU\u5185\u6838\u6267\u884c\u5ef6\u8fdf\u6765\u8861\u91cf\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528FSR\u589e\u5f3a\u7684LLMs\u53ef\u4ee5\u6301\u7eed\u4fdd\u8bc1\u4ee3\u7801\u7684\u6b63\u786e\u6027\uff0c\u5e76\u4e14\u81ea\u52a8\u751f\u6210\u7684\u5185\u6838\u5728\u6267\u884c\u901f\u5ea6\u4e0a\u6700\u9ad8\u53ef\u8fbe\u5230\u4eba\u5de5\u7f16\u5199\u4ee3\u7801\u7684179\u500d\u3002", "conclusion": "\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u6027\u80fd\u5f3a\u5316\u7684\u65b9\u6cd5\u663e\u793a\u51fa\u4e86\u81ea\u52a8\u5316GPU\u7f16\u7a0b\u7684\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5728\u786c\u4ef6\u7279\u5b9a\u3001\u67b6\u6784\u654f\u611f\u548c\u6027\u80fd\u5173\u952e\u7684\u5e94\u7528\u4e2d\u3002"}}
{"id": "2410.16222", "pdf": "https://arxiv.org/pdf/2410.16222", "abs": "https://arxiv.org/abs/2410.16222", "authors": ["Valentyn Boreiko", "Alexander Panfilov", "Vaclav Voracek", "Matthias Hein", "Jonas Geiping"], "title": "An Interpretable N-gram Perplexity Threat Model for Large Language Model Jailbreaks", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "comment": null, "summary": "A plethora of jailbreaking attacks have been proposed to obtain harmful\nresponses from safety-tuned LLMs. These methods largely succeed in coercing the\ntarget output in their original settings, but their attacks vary substantially\nin fluency and computational effort. In this work, we propose a unified threat\nmodel for the principled comparison of these methods. Our threat model checks\nif a given jailbreak is likely to occur in the distribution of text. For this,\nwe build an N-gram language model on 1T tokens, which, unlike model-based\nperplexity, allows for an LLM-agnostic, nonparametric, and inherently\ninterpretable evaluation. We adapt popular attacks to this threat model, and,\nfor the first time, benchmark these attacks on equal footing with it. After an\nextensive comparison, we find attack success rates against safety-tuned modern\nmodels to be lower than previously presented and that attacks based on discrete\noptimization significantly outperform recent LLM-based attacks. Being\ninherently interpretable, our threat model allows for a comprehensive analysis\nand comparison of jailbreak attacks. We find that effective attacks exploit and\nabuse infrequent bigrams, either selecting the ones absent from real-world text\nor rare ones, e.g., specific to Reddit or code datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u7684\u5a01\u80c1\u6a21\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u9488\u5bf9\u5b89\u5168\u8c03\u4f18\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8d8a\u72f1\u653b\u51fb\u3002\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u57fa\u4e8e1T\u6807\u8bb0\u7684N-gram\u8bed\u8a00\u6a21\u578b\uff0c\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4e0e\u5177\u4f53LLM\u65e0\u5173\u3001\u975e\u53c2\u6570\u5316\u4e14\u6613\u4e8e\u89e3\u91ca\u7684\u8bc4\u4ef7\u65b9\u6cd5\uff0c\u5e76\u9996\u6b21\u5728\u540c\u7b49\u6761\u4ef6\u4e0b\u5bf9\u4e0d\u540c\u653b\u51fb\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u9762\u5bf9\u591a\u79cd\u591a\u6837\u7684\u8d8a\u72f1\u653b\u51fb\u624b\u6bb5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u867d\u7136\u80fd\u591f\u5728\u539f\u59cb\u8bbe\u5b9a\u4e0b\u6210\u529f\u8bf1\u5bfc\u51fa\u6709\u5bb3\u56de\u5e94\uff0c\u4f46\u5b83\u4eec\u5728\u6d41\u7545\u6027\u548c\u8ba1\u7b97\u6210\u672c\u4e0a\u5b58\u5728\u5f88\u5927\u5dee\u5f02\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u539f\u5219\u6027\u7684\u6bd4\u8f83\u6846\u67b6\u6765\u8bc4\u4f30\u8fd9\u4e9b\u653b\u51fb\u65b9\u5f0f\u3002", "method": "\u4f5c\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e1T\u4e2a\u4ee4\u724c\u8bad\u7ec3\u7684N-gram\u8bed\u8a00\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u4e0d\u540c\u4e8e\u57fa\u4e8e\u6a21\u578b\u7684\u56f0\u60d1\u5ea6\u6d4b\u91cf\uff0c\u5141\u8bb8\u8fdb\u884c\u4e0e\u5177\u4f53\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u65e0\u5173\u3001\u975e\u53c2\u6570\u5316\u5e76\u4e14\u672c\u8d28\u4e0a\u53ef\u89e3\u91ca\u7684\u8bc4\u4f30\u3002\u63a5\u7740\uff0c\u4ed6\u4eec\u5c06\u6d41\u884c\u7684\u653b\u51fb\u65b9\u6cd5\u9002\u5e94\u4e8e\u8fd9\u4e2a\u65b0\u7684\u5a01\u80c1\u6a21\u578b\u4e2d\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u9996\u6b21\u516c\u5e73\u5730\u5bf9\u6bd4\u4e86\u5404\u79cd\u653b\u51fb\u7684\u6548\u679c\u3002", "result": "\u7ecf\u8fc7\u5e7f\u6cdb\u6bd4\u8f83\u540e\u53d1\u73b0\uff0c\u5bf9\u4e8e\u73b0\u4ee3\u7684\u5b89\u5168\u8c03\u4f18\u6a21\u578b\u6765\u8bf4\uff0c\u5b9e\u9645\u653b\u51fb\u6210\u529f\u7387\u4f4e\u4e8e\u5148\u524d\u62a5\u9053\uff1b\u800c\u4e14\u57fa\u4e8e\u79bb\u6563\u4f18\u5316\u7684\u653b\u51fb\u6bd4\u6700\u8fd1\u63d0\u51fa\u7684\u57fa\u4e8e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u653b\u51fb\u8868\u73b0\u66f4\u597d\u3002\u6b64\u5916\u8fd8\u89c2\u5bdf\u5230\uff0c\u6709\u6548\u7684\u653b\u51fb\u5f80\u5f80\u5229\u7528\u548c\u6ee5\u7528\u4e0d\u5e38\u89c1\u7684\u53cc\u8bcd\u7ec4\u5408\uff0c\u9009\u62e9\u90a3\u4e9b\u5728\u73b0\u5b9e\u4e16\u754c\u6587\u672c\u4e2d\u4e0d\u5b58\u5728\u6216\u975e\u5e38\u7f55\u89c1\u7684\u53cc\u8bcd\u7ec4\u5408\uff0c\u4f8b\u5982\u7279\u5b9a\u4e8eReddit\u6216\u4ee3\u7801\u6570\u636e\u96c6\u4e2d\u7684\u53cc\u8bcd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u63d0\u51fa\u4e00\u79cd\u65b0\u578b\u5a01\u80c1\u6a21\u578b\uff0c\u4e3a\u8d8a\u72f1\u653b\u51fb\u63d0\u4f9b\u4e86\u5168\u9762\u5206\u6790\u548c\u6bd4\u8f83\u7684\u57fa\u7840\u3002\u5b83\u4e0d\u4ec5\u63ed\u793a\u4e86\u73b0\u6709\u653b\u51fb\u6280\u672f\u7684\u5b9e\u9645\u6548\u679c\uff0c\u4e5f\u6307\u51fa\u4e86\u6709\u6548\u653b\u51fb\u7684\u4e00\u4e9b\u5173\u952e\u7279\u5f81\uff0c\u5982\u5229\u7528\u7f55\u89c1\u7684\u53cc\u8bcd\u7ec4\u5408\u7b49\u3002"}}
{"id": "2506.09101", "pdf": "https://arxiv.org/pdf/2506.09101", "abs": "https://arxiv.org/abs/2506.09101", "authors": ["M\u00edriam Barrab\u00e9s", "Daniel Mas Montserrat", "Kapal Dev", "Alexander G. Ioannidis"], "title": "Feature Shift Localization Network", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "9 pages, 2 figures, 4 tables", "summary": "Feature shifts between data sources are present in many applications\ninvolving healthcare, biomedical, socioeconomic, financial, survey, and\nmulti-sensor data, among others, where unharmonized heterogeneous data sources,\nnoisy data measurements, or inconsistent processing and standardization\npipelines can lead to erroneous features. Localizing shifted features is\nimportant to address the underlying cause of the shift and correct or filter\nthe data to avoid degrading downstream analysis. While many techniques can\ndetect distribution shifts, localizing the features originating them is still\nchallenging, with current solutions being either inaccurate or not scalable to\nlarge and high-dimensional datasets. In this work, we introduce the Feature\nShift Localization Network (FSL-Net), a neural network that can localize\nfeature shifts in large and high-dimensional datasets in a fast and accurate\nmanner. The network, trained with a large number of datasets, learns to extract\nthe statistical properties of the datasets and can localize feature shifts from\npreviously unseen datasets and shifts without the need for re-training. The\ncode and ready-to-use trained model are available at\nhttps://github.com/AI-sandbox/FSL-Net.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u7279\u5f81\u79fb\u4f4d\u5b9a\u4f4d\u7f51\u7edc\uff08FSL-Net\uff09\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u5b83\u53ef\u4ee5\u5feb\u901f\u51c6\u786e\u5730\u5728\u5927\u578b\u548c\u9ad8\u7ef4\u6570\u636e\u96c6\u4e2d\u5b9a\u4f4d\u7279\u5f81\u79fb\u4f4d\u3002\u8be5\u7f51\u7edc\u7ecf\u8fc7\u5927\u91cf\u6570\u636e\u96c6\u8bad\u7ec3\u540e\uff0c\u80fd\u591f\u4ece\u5148\u524d\u672a\u89c1\u8fc7\u7684\u6570\u636e\u96c6\u548c\u79fb\u4f4d\u4e2d\u5b9a\u4f4d\u7279\u5f81\u79fb\u4f4d\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u3002", "motivation": "\u7531\u4e8e\u4e0d\u540c\u6b65\u7684\u5f02\u6784\u6570\u636e\u6e90\u3001\u566a\u58f0\u6570\u636e\u6d4b\u91cf\u6216\u4e0d\u4e00\u81f4\u7684\u5904\u7406\u548c\u6807\u51c6\u5316\u6d41\u7a0b\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u7279\u5f81\u7684\u51fa\u73b0\uff0c\u5728\u533b\u7597\u4fdd\u5065\u3001\u751f\u7269\u533b\u5b66\u3001\u793e\u4f1a\u7ecf\u6d4e\u3001\u91d1\u878d\u3001\u8c03\u67e5\u53ca\u591a\u4f20\u611f\u5668\u6570\u636e\u7b49\u8bb8\u591a\u5e94\u7528\u4e2d\u90fd\u5b58\u5728\u6570\u636e\u6e90\u4e4b\u95f4\u7684\u7279\u5f81\u79fb\u4f4d\u95ee\u9898\u3002\u5b9a\u4f4d\u79fb\u4f4d\u7279\u5f81\u5bf9\u4e8e\u89e3\u51b3\u79fb\u4f4d\u7684\u6839\u672c\u539f\u56e0\u5e76\u4fee\u6b63\u6216\u8fc7\u6ee4\u6570\u636e\u4ee5\u907f\u514d\u635f\u5bb3\u4e0b\u6e38\u5206\u6790\u975e\u5e38\u91cd\u8981\u3002", "method": "\u4f5c\u8005\u4eec\u5f15\u5165\u4e86\u7279\u5f81\u79fb\u4f4d\u5b9a\u4f4d\u7f51\u7edc\uff08FSL-Net\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u80fd\u591f\u5728\u5927\u578b\u548c\u9ad8\u7ef4\u6570\u636e\u96c6\u4e2d\u8fc5\u901f\u4e14\u7cbe\u786e\u5730\u5b9a\u4f4d\u7279\u5f81\u79fb\u4f4d\u7684\u795e\u7ecf\u7f51\u7edc\u3002\u8be5\u7f51\u7edc\u901a\u8fc7\u5927\u91cf\u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\uff0c\u5b66\u4e60\u63d0\u53d6\u6570\u636e\u96c6\u7684\u7edf\u8ba1\u5c5e\u6027\uff0c\u5e76\u4e14\u80fd\u591f\u5bf9\u4e4b\u524d\u672a\u89c1\u8fc7\u7684\u6570\u636e\u96c6\u548c\u7279\u5f81\u79fb\u4f4d\u8fdb\u884c\u5b9a\u4f4d\uff0c\u65e0\u9700\u518d\u6b21\u8bad\u7ec3\u3002", "result": "FSL-Net \u80fd\u591f\u6709\u6548\u5730\u8bc6\u522b\u5bfc\u81f4\u5206\u5e03\u504f\u79fb\u7684\u5177\u4f53\u7279\u5f81\uff0c\u5e76\u4e14\u53ef\u4ee5\u5728\u6ca1\u6709\u989d\u5916\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u5e94\u7528\u4e8e\u65b0\u7684\u6570\u636e\u96c6\u4e0a\u3002\u8fd9\u610f\u5473\u7740\u5b83\u4e3a\u5904\u7406\u5927\u89c4\u6a21\u548c\u9ad8\u7ef4\u5ea6\u6570\u636e\u4e2d\u7684\u7279\u5f81\u79fb\u4f4d\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65e2\u51c6\u786e\u53c8\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "FSL-Net \u63d0\u4f9b\u4e86\u4e00\u79cd\u5feb\u901f\u4e14\u51c6\u786e\u7684\u65b9\u6cd5\u6765\u5b9a\u4f4d\u5927\u578b\u548c\u9ad8\u7ef4\u6570\u636e\u96c6\u4e2d\u7684\u7279\u5f81\u79fb\u4f4d\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u4e0d\u591f\u51c6\u786e\u6216\u65e0\u6cd5\u6269\u5c55\u5230\u5927\u6570\u636e\u96c6\u7684\u95ee\u9898\u3002\u6b64\u5916\uff0c\u63d0\u4f9b\u4e86\u4ee3\u7801\u548c\u5373\u7528\u578b\u8bad\u7ec3\u6a21\u578b\uff0c\u65b9\u4fbf\u5176\u4ed6\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u3002"}}
{"id": "2506.09093", "pdf": "https://arxiv.org/pdf/2506.09093", "abs": "https://arxiv.org/abs/2506.09093", "authors": ["Bingjie Zhang", "Hongkang Li", "Changlong Shi", "Guowei Rong", "He Zhao", "Dongsheng Wang", "Dandan Guo", "Meng Wang"], "title": "Merging Smarter, Generalizing Better: Enhancing Model Merging on OOD Data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-task learning (MTL) concurrently trains a model on diverse task\ndatasets to exploit common features, thereby improving overall performance\nacross the tasks. Recent studies have dedicated efforts to merging multiple\nindependent model parameters into a unified model for MTL, thus circumventing\nthe need for training data and expanding the scope of applicable scenarios of\nMTL. However, current approaches to model merging predominantly concentrate on\nenhancing performance within in-domain (ID) datasets, often overlooking their\nefficacy on out-of-domain (OOD) datasets. In this work, we proposed LwPTV\n(Layer-wise Pruning Task Vector) by building a saliency score, measuring the\nredundancy of parameters in task vectors. Designed in this way ours can achieve\nmask vector for each task and thus perform layer-wise pruning on the task\nvectors, only keeping the pre-trained model parameters at the corresponding\nlayer in merged model. Owing to its flexibility, our method can be seamlessly\nintegrated with most of existing model merging methods to improve their\nperformance on OOD tasks. Extensive experiments demonstrate that the\napplication of our method results in substantial enhancements in OOD\nperformance while preserving the ability on ID tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5LwPTV\uff0c\u901a\u8fc7\u6784\u5efa\u663e\u8457\u6027\u8bc4\u5206\u6765\u5ea6\u91cf\u4efb\u52a1\u5411\u91cf\u4e2d\u53c2\u6570\u7684\u5197\u4f59\u6027\uff0c\u5e76\u8fdb\u884c\u9010\u5c42\u526a\u679d\u4ee5\u4fdd\u6301\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u3002\u8be5\u65b9\u6cd5\u53ef\u4ee5\u63d0\u9ad8\u591a\u4efb\u52a1\u5b66\u4e60\u6a21\u578b\u5728\u9886\u57df\u5916\uff08OOD\uff09\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u7559\u5176\u5728\u9886\u57df\u5185\uff08ID\uff09\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u4efb\u52a1\u5b66\u4e60\uff08MTL\uff09\u4e2d\u7684\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4e8e\u63d0\u5347\u9886\u57df\u5185\uff08ID\uff09\u6570\u636e\u96c6\u7684\u8868\u73b0\uff0c\u800c\u5ffd\u89c6\u4e86\u5b83\u4eec\u5728\u9886\u57df\u5916\uff08OOD\uff09\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86LwPTV\uff08Layer-wise Pruning Task Vector\uff09\uff0c\u901a\u8fc7\u5efa\u7acb\u4e00\u4e2a\u663e\u8457\u6027\u8bc4\u5206\u6765\u8861\u91cf\u4efb\u52a1\u5411\u91cf\u4e2d\u53c2\u6570\u7684\u5197\u4f59\u7a0b\u5ea6\uff0c\u5e76\u636e\u6b64\u4e3a\u6bcf\u4e2a\u4efb\u52a1\u751f\u6210\u63a9\u7801\u5411\u91cf\uff0c\u6267\u884c\u9010\u5c42\u7684\u4efb\u52a1\u5411\u91cf\u526a\u679d\uff0c\u53ea\u4fdd\u7559\u5408\u5e76\u6a21\u578b\u76f8\u5e94\u5c42\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u53c2\u6570\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u5e94\u7528\u6211\u4eec\u7684\u65b9\u6cd5\u540e\uff0c\u5728\u4fdd\u6301\u9886\u57df\u5185\uff08ID\uff09\u4efb\u52a1\u8868\u73b0\u7684\u540c\u65f6\uff0c\u9886\u57df\u5916\uff08OOD\uff09\u4efb\u52a1\u7684\u8868\u73b0\u6709\u4e86\u5b9e\u8d28\u6027\u63d0\u9ad8\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5LwPTV\u80fd\u591f\u4e0e\u5927\u591a\u6570\u73b0\u6709\u7684\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\u65e0\u7f1d\u96c6\u6210\uff0c\u4ece\u800c\u6539\u5584\u5b83\u4eec\u5728OOD\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u540c\u65f6\u7ef4\u6301\u539f\u6709\u7684ID\u4efb\u52a1\u7684\u80fd\u529b\u3002"}}
{"id": "2506.09163", "pdf": "https://arxiv.org/pdf/2506.09163", "abs": "https://arxiv.org/abs/2506.09163", "authors": ["Daniel Jenson", "Jhonathan Navott", "Piotr Grynfelder", "Mengyan Zhang", "Makkunda Sharma", "Elizaveta Semenova", "Seth Flaxman"], "title": "Scalable Spatiotemporal Inference with Biased Scan Attention Transformer Neural Processes", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Neural Processes (NPs) are a rapidly evolving class of models designed to\ndirectly model the posterior predictive distribution of stochastic processes.\nWhile early architectures were developed primarily as a scalable alternative to\nGaussian Processes (GPs), modern NPs tackle far more complex and data hungry\napplications spanning geology, epidemiology, climate, and robotics. These\napplications have placed increasing pressure on the scalability of these\nmodels, with many architectures compromising accuracy for scalability. In this\npaper, we demonstrate that this tradeoff is often unnecessary, particularly\nwhen modeling fully or partially translation invariant processes. We propose a\nversatile new architecture, the Biased Scan Attention Transformer Neural\nProcess (BSA-TNP), which introduces Kernel Regression Blocks (KRBlocks),\ngroup-invariant attention biases, and memory-efficient Biased Scan Attention\n(BSA). BSA-TNP is able to: (1) match or exceed the accuracy of the best models\nwhile often training in a fraction of the time, (2) exhibit translation\ninvariance, enabling learning at multiple resolutions simultaneously, (3)\ntransparently model processes that evolve in both space and time, (4) support\nhigh dimensional fixed effects, and (5) scale gracefully -- running inference\nwith over 1M test points with 100K context points in under a minute on a single\n24GB GPU.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u67b6\u6784BSA-TNP\uff0c\u5b83\u901a\u8fc7\u5f15\u5165\u6838\u56de\u5f52\u5757\u3001\u7fa4\u4e0d\u53d8\u6ce8\u610f\u529b\u504f\u5dee\u548c\u5185\u5b58\u9ad8\u6548\u7684\u504f\u7f6e\u626b\u63cf\u6ce8\u610f\u529b\u673a\u5236\u6765\u63d0\u9ad8\u795e\u7ecf\u8fc7\u7a0b\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5e73\u79fb\u4e0d\u53d8\u6027\uff0c\u5e76\u80fd\u591f\u5904\u7406\u9ad8\u7ef4\u56fa\u5b9a\u6548\u5e94\u3002", "motivation": "\u968f\u7740\u795e\u7ecf\u8fc7\u7a0b(NPs)\u6a21\u578b\u5e94\u7528\u4e8e\u66f4\u590d\u6742\u7684\u6570\u636e\u5bc6\u96c6\u578b\u9886\u57df\uff0c\u5982\u5730\u8d28\u5b66\u3001\u6d41\u884c\u75c5\u5b66\u3001\u6c14\u5019\u548c\u673a\u5668\u4eba\u6280\u672f\uff0c\u5bf9\u8fd9\u4e9b\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u63d0\u51fa\u4e86\u66f4\u9ad8\u7684\u8981\u6c42\u3002\u73b0\u6709\u7684\u4e00\u4e9b\u67b6\u6784\u4e3a\u4e86\u5b9e\u73b0\u53ef\u6269\u5c55\u6027\u800c\u727a\u7272\u4e86\u51c6\u786e\u6027\u3002\u672c\u6587\u65e8\u5728\u5c55\u793a\u8fd9\u79cd\u6743\u8861\u5f80\u5f80\u662f\u4e0d\u5fc5\u8981\u7684\uff0c\u7279\u522b\u662f\u5728\u5efa\u6a21\u5b8c\u5168\u6216\u90e8\u5206\u5e73\u79fb\u4e0d\u53d8\u7684\u8fc7\u7a0b\u65f6\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBiased Scan Attention Transformer Neural Process (BSA-TNP)\u7684\u65b0\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u5305\u542bKernel Regression Blocks (KRBlocks)\u3001\u7fa4\u4e0d\u53d8\u6ce8\u610f\u504f\u5dee\u4ee5\u53ca\u5185\u5b58\u6548\u7387\u9ad8\u7684Biased Scan Attention (BSA)\u3002", "result": "BSA-TNP\u80fd\u591f\u5728\u4fdd\u6301\u751a\u81f3\u8d85\u8d8a\u6700\u4f73\u6a21\u578b\u51c6\u786e\u5ea6\u7684\u540c\u65f6\uff0c\u901a\u5e38\u53ea\u9700\u8981\u4e00\u5c0f\u90e8\u5206\u8bad\u7ec3\u65f6\u95f4\uff1b\u5c55\u73b0\u5e73\u79fb\u4e0d\u53d8\u6027\uff0c\u5141\u8bb8\u591a\u5206\u8fa8\u7387\u5b66\u4e60\uff1b\u900f\u660e\u5730\u6a21\u62df\u7a7a\u95f4\u548c\u65f6\u95f4\u6f14\u53d8\u7684\u8fc7\u7a0b\uff1b\u652f\u6301\u9ad8\u7ef4\u56fa\u5b9a\u6548\u5e94\uff1b\u5e76\u4e14\u4f18\u96c5\u5730\u6269\u5c55\u2014\u2014\u5728\u5355\u4e2a24GB GPU\u4e0a\uff0c\u4f7f\u7528\u8d85\u8fc7100\u4e07\u4e2a\u6d4b\u8bd5\u70b9\u4e0e10\u4e07\u4e2a\u4e0a\u4e0b\u6587\u70b9\u8fdb\u884c\u63a8\u7406\u6240\u9700\u65f6\u95f4\u4e0d\u5230\u4e00\u5206\u949f\u3002", "conclusion": "BSA-TNP\u67b6\u6784\u4e3a\u795e\u7ecf\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u4e14\u9ad8\u6548\u7684\u9009\u62e9\uff0c\u5b83\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u5904\u7406\u590d\u6742\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u8fd8\u6539\u5584\u4e86\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u4e0e\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2506.09096", "pdf": "https://arxiv.org/pdf/2506.09096", "abs": "https://arxiv.org/abs/2506.09096", "authors": ["Chaoyang Zhou", "Shunyu Liu", "Zengmao Wang", "Di Wang", "Rong-Cheng Tu", "Bo Du", "Dacheng Tao"], "title": "Intra-Trajectory Consistency for Reward Modeling", "categories": ["cs.LG", "cs.AI"], "comment": "Under review", "summary": "Reward models are critical for improving large language models (LLMs),\nparticularly in reinforcement learning from human feedback (RLHF) or\ninference-time verification. Current reward modeling typically relies on scores\nof overall responses to learn the outcome rewards for the responses. However,\nsince the response-level scores are coarse-grained supervision signals, the\nreward model struggles to identify the specific components within a response\ntrajectory that truly correlate with the scores, leading to poor generalization\non unseen responses. In this paper, we propose to leverage generation\nprobabilities to establish reward consistency between processes in the response\ntrajectory, which allows the response-level supervisory signal to propagate\nacross processes, thereby providing additional fine-grained signals for reward\nlearning. Building on analysis under the Bayesian framework, we develop an\nintra-trajectory consistency regularization to enforce that adjacent processes\nwith higher next-token generation probability maintain more consistent rewards.\nWe apply the proposed regularization to the advanced outcome reward model,\nimproving its performance on RewardBench. Besides, we show that the reward\nmodel trained with the proposed regularization induces better DPO-aligned\npolicies and achieves better best-of-N (BON) inference-time verification\nresults. Our code is provided in https://github.com/chaoyang101/ICRM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u751f\u6210\u6982\u7387\u5728\u54cd\u5e94\u8f68\u8ff9\u4e2d\u5efa\u7acb\u5956\u52b1\u4e00\u81f4\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u8f68\u8ff9\u5185\u4e00\u81f4\u6027\u6b63\u5219\u5316\u6765\u63d0\u9ad8\u5956\u52b1\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4ece\u800c\u6539\u5584\u4e86DPO\u5bf9\u9f50\u7b56\u7565\u548cBON\u63a8\u7406\u65f6\u9a8c\u8bc1\u7ed3\u679c\u3002", "motivation": "\u5f53\u524d\u7684\u5956\u52b1\u5efa\u6a21\u901a\u5e38\u4f9d\u8d56\u4e8e\u6574\u4f53\u54cd\u5e94\u5f97\u5206\u6765\u5b66\u4e60\u54cd\u5e94\u7684\u7ed3\u679c\u5956\u52b1\uff0c\u4f46\u8fd9\u79cd\u7c97\u7c92\u5ea6\u7684\u76d1\u7763\u4fe1\u53f7\u4f7f\u5f97\u5956\u52b1\u6a21\u578b\u96be\u4ee5\u8bc6\u522b\u51fa\u771f\u6b63\u4e0e\u5206\u6570\u76f8\u5173\u7684\u7279\u5b9a\u7ec4\u4ef6\uff0c\u5bfc\u81f4\u5bf9\u672a\u89c1\u54cd\u5e94\u7684\u6cdb\u5316\u80fd\u529b\u8f83\u5dee\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u662f\u5229\u7528\u751f\u6210\u6982\u7387\u5728\u54cd\u5e94\u8f68\u8ff9\u4e2d\u7684\u8fc7\u7a0b\u4e4b\u95f4\u5efa\u7acb\u5956\u52b1\u4e00\u81f4\u6027\uff0c\u4f7f\u54cd\u5e94\u7ea7\u522b\u7684\u76d1\u7763\u4fe1\u53f7\u80fd\u591f\u8de8\u8fc7\u7a0b\u4f20\u64ad\uff0c\u63d0\u4f9b\u989d\u5916\u7684\u7ec6\u7c92\u5ea6\u4fe1\u53f7\u7528\u4e8e\u5956\u52b1\u5b66\u4e60\uff0c\u5e76\u57fa\u4e8e\u8d1d\u53f6\u65af\u6846\u67b6\u4e0b\u7684\u5206\u6790\u5f00\u53d1\u4e86\u8f68\u8ff9\u5185\u4e00\u81f4\u6027\u6b63\u5219\u5316\uff0c\u4ee5\u786e\u4fdd\u5177\u6709\u66f4\u9ad8\u4e0b\u4e00\u4e2a\u4ee4\u724c\u751f\u6210\u6982\u7387\u7684\u76f8\u90bb\u8fc7\u7a0b\u4fdd\u6301\u66f4\u4e00\u81f4\u7684\u5956\u52b1\u3002", "result": "\u5e94\u7528\u6240\u63d0\u51fa\u7684\u6b63\u5219\u5316\u5230\u5148\u8fdb\u7684\u7ed3\u679c\u5956\u52b1\u6a21\u578b\u4e0a\uff0c\u5728RewardBench\u4e0a\u63d0\u9ad8\u4e86\u5176\u6027\u80fd\uff1b\u5e76\u4e14\u8868\u660e\u4f7f\u7528\u6240\u63d0\u8bae\u6b63\u5219\u5316\u8bad\u7ec3\u7684\u5956\u52b1\u6a21\u578b\u8bf1\u5bfc\u4e86\u66f4\u597d\u7684DPO\u5bf9\u9f50\u7b56\u7565\uff0c\u5e76\u8fbe\u5230\u4e86\u66f4\u597d\u7684BON\u63a8\u7406\u65f6\u9a8c\u8bc1\u7ed3\u679c\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u751f\u6210\u6982\u7387\u7684\u4e00\u81f4\u6027\u4ee5\u53ca\u8f68\u8ff9\u5185\u6b63\u5219\u5316\uff0c\u53ef\u4ee5\u63d0\u9ad8\u5956\u52b1\u6a21\u578b\u5bf9\u4e8e\u672a\u89c1\u54cd\u5e94\u7684\u5b66\u4e60\u6548\u679c\uff0c\u8fdb\u800c\u6539\u8fdb\u8bed\u8a00\u6a21\u578b\u7684\u53cd\u9988\u5b66\u4e60\u673a\u5236\u3002"}}
{"id": "2506.09258", "pdf": "https://arxiv.org/pdf/2506.09258", "abs": "https://arxiv.org/abs/2506.09258", "authors": ["Vaidotas Simkus", "Michael U. Gutmann"], "title": "CFMI: Flow Matching for Missing Data Imputation", "categories": ["cs.LG", "stat.ML", "62D10", "I.5.1"], "comment": null, "summary": "We introduce conditional flow matching for imputation (CFMI), a new\ngeneral-purpose method to impute missing data. The method combines continuous\nnormalising flows, flow-matching, and shared conditional modelling to deal with\nintractabilities of traditional multiple imputation. Our comparison with nine\nclassical and state-of-the-art imputation methods on 24 small to\nmoderate-dimensional tabular data sets shows that CFMI matches or outperforms\nboth traditional and modern techniques across a wide range of metrics. Applying\nthe method to zero-shot imputation of time-series data, we find that it matches\nthe accuracy of a related diffusion-based method while outperforming it in\nterms of computational efficiency. Overall, CFMI performs at least as well as\ntraditional methods on lower-dimensional data while remaining scalable to\nhigh-dimensional settings, matching or exceeding the performance of other deep\nlearning-based approaches, making it a go-to imputation method for a wide range\nof data types and dimensionalities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u901a\u7528\u7f3a\u5931\u6570\u636e\u586b\u8865\u65b9\u6cd5\u2014\u2014\u57fa\u4e8e\u6761\u4ef6\u6d41\u5339\u914d\u7684\u586b\u8865\u6cd5\uff08CFMI\uff09\uff0c\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u8fde\u7eed\u5f52\u4e00\u5316\u6d41\u3001\u6d41\u5339\u914d\u548c\u5171\u4eab\u6761\u4ef6\u5efa\u6a21\u6765\u5904\u7406\u4f20\u7edf\u591a\u91cd\u586b\u8865\u65b9\u6cd5\u4e2d\u7684\u68d8\u624b\u95ee\u9898\u3002\u7814\u7a76\u8868\u660e\uff0cCFMI\u572824\u4e2a\u4e2d\u5c0f\u578b\u8868\u683c\u6570\u636e\u96c6\u4e0a\u4e0e\u4e5d\u79cd\u7ecf\u5178\u53ca\u6700\u65b0\u586b\u8865\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5176\u6027\u80fd\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u76f8\u5339\u914d\u6216\u66f4\u4f18\u3002\u6b64\u5916\uff0c\u5e94\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u96f6\u6837\u672c\u586b\u8865\u65f6\uff0cCFMI\u4e0d\u4ec5\u8fbe\u5230\u4e86\u76f8\u5173\u6269\u6563\u65b9\u6cd5\u7684\u51c6\u786e\u6027\uff0c\u8fd8\u5728\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u8868\u73b0\u66f4\u4f73\u3002\u603b\u4f53\u800c\u8a00\uff0cCFMI\u5bf9\u4e8e\u4f4e\u7ef4\u6570\u636e\u81f3\u5c11\u4e0e\u4f20\u7edf\u65b9\u6cd5\u4e00\u6837\u597d\uff0c\u5e76\u4e14\u80fd\u591f\u6269\u5c55\u5230\u9ad8\u7ef4\u8bbe\u7f6e\u4e2d\uff0c\u4e0e\u5176\u5b83\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u6027\u80fd\u4e0a\u6301\u5e73\u751a\u81f3\u8d85\u8d8a\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf\u591a\u91cd\u586b\u8865\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u96be\u4ee5\u5904\u7406\u7684\u95ee\u9898\uff0c\u540c\u65f6\u5bfb\u627e\u4e00\u79cd\u9002\u7528\u4e8e\u4ece\u5c0f\u578b\u5230\u5927\u578b\u7ef4\u5ea6\u7684\u5404\u79cd\u7c7b\u578b\u6570\u636e\u7684\u6709\u6548\u586b\u8865\u6280\u672f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aCFMI\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u6574\u5408\u4e86\u8fde\u7eed\u5f52\u4e00\u5316\u6d41\u3001\u6d41\u5339\u914d\u4ee5\u53ca\u5171\u4eab\u6761\u4ef6\u5efa\u6a21\u6280\u672f\u3002", "result": "CFMI\u572824\u4e2a\u4e2d\u5c0f\u578b\u8868\u683c\u6570\u636e\u96c6\u4e0a\u7684\u6d4b\u8bd5\u8868\u660e\uff0c\u5b83\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684\u8bc4\u4ef7\u6307\u6807\u4e0a\u80fd\u591f\u5339\u654c\u751a\u81f3\u4f18\u4e8e\u4e5d\u79cd\u73b0\u6709\u65b9\u6cd5\uff1b\u5f53\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u586b\u8865\u65f6\uff0c\u51c6\u786e\u5ea6\u4e0e\u53e6\u4e00\u6269\u6563\u65b9\u6cd5\u76f8\u5f53\uff0c\u4f46\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "CFMI\u4f5c\u4e3a\u4e00\u79cd\u65b0\u578b\u7684\u6570\u636e\u586b\u8865\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u5bf9\u4f4e\u7ef4\u6570\u636e\u6709\u6548\uff0c\u800c\u4e14\u80fd\u591f\u5f88\u597d\u5730\u9002\u5e94\u9ad8\u7ef4\u573a\u666f\uff0c\u6210\u4e3a\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u548c\u89c4\u6a21\u6570\u636e\u7684\u7406\u60f3\u9009\u62e9\u4e4b\u4e00\u3002"}}
{"id": "2506.09099", "pdf": "https://arxiv.org/pdf/2506.09099", "abs": "https://arxiv.org/abs/2506.09099", "authors": ["Joshua Barron", "Devin White"], "title": "Too Big to Think: Capacity, Memorization, and Generalization in Pre-Trained Transformers", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted for oral presentation to Tiny Titans: The next wave of\n  On-Device Learning for Foundational Models Workshop at the 42nd International\n  Conference on Machine Learning", "summary": "The relationship between memorization and generalization in large language\nmodels (LLMs) remains an open area of research, with growing evidence that the\ntwo are deeply intertwined. In this work, we investigate this relationship by\npre-training a series of capacity-limited Transformer models from scratch on\ntwo synthetic character-level tasks designed to separately probe generalization\n(via arithmetic extrapolation) and memorization (via factual recall). We\nobserve a consistent trade-off: small models extrapolate to unseen arithmetic\ncases but fail to memorize facts, while larger models memorize but fail to\nextrapolate. An intermediate-capacity model exhibits a similar shift toward\nmemorization. When trained on both tasks jointly, no model (regardless of size)\nsucceeds at extrapolation. These findings suggest that pre-training may\nintrinsically favor one learning mode over the other. By isolating these\ndynamics in a controlled setting, our study offers insight into how model\ncapacity shapes learning behavior and offers broader implications for the\ndesign and deployment of small language models.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u8bad\u7ec3\u6709\u9650\u5bb9\u91cf\u7684Transformer\u6a21\u578b\u5728\u4e24\u4e2a\u5408\u6210\u5b57\u7b26\u7ea7\u4efb\u52a1\u4e0a\uff0c\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u8bb0\u5fc6\u4e0e\u6cdb\u5316\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u7ed3\u679c\u663e\u793a\u5c0f\u578b\u6a21\u578b\u80fd\u591f\u8fdb\u884c\u7b97\u672f\u63a8\u65ad\u4f46\u65e0\u6cd5\u8bb0\u4f4f\u4e8b\u5b9e\uff0c\u800c\u5927\u578b\u6a21\u578b\u5219\u76f8\u53cd\u3002\u5f53\u540c\u65f6\u8bad\u7ec3\u4e24\u4e2a\u4efb\u52a1\u65f6\uff0c\u6240\u6709\u6a21\u578b\u90fd\u65e0\u6cd5\u6210\u529f\u8fdb\u884c\u63a8\u65ad\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u8bb0\u5fc6\u548c\u6cdb\u5316\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u4e14\u8fd9\u79cd\u5173\u7cfb\u5982\u4f55\u53d7\u5230\u6a21\u578b\u5bb9\u91cf\u7684\u5f71\u54cd\u3002", "method": "\u4ece\u5934\u5f00\u59cb\u9884\u8bad\u7ec3\u4e00\u7cfb\u5217\u5bb9\u91cf\u53d7\u9650\u7684Transformer\u6a21\u578b\uff0c\u5728\u4e24\u4e2a\u8bbe\u8ba1\u7528\u4e8e\u5206\u522b\u6d4b\u8bd5\u6cdb\u5316\uff08\u901a\u8fc7\u7b97\u672f\u5916\u63a8\uff09\u548c\u8bb0\u5fc6\uff08\u901a\u8fc7\u4e8b\u5b9e\u56de\u5fc6\uff09\u7684\u5408\u6210\u5b57\u7b26\u7ea7\u4efb\u52a1\u4e0a\u3002", "result": "\u89c2\u5bdf\u5230\u4e00\u4e2a\u4e00\u81f4\u7684\u6743\u8861\uff1a\u5c0f\u6a21\u578b\u53ef\u4ee5\u5916\u63a8\u5230\u672a\u89c1\u8fc7\u7684\u7b97\u672f\u6848\u4f8b\u4f46\u4e0d\u80fd\u8bb0\u4f4f\u4e8b\u5b9e\uff0c\u800c\u8f83\u5927\u7684\u6a21\u578b\u53ef\u4ee5\u8bb0\u4f4f\u4e8b\u5b9e\u4f46\u4e0d\u80fd\u5916\u63a8\u3002\u5f53\u4e2d\u7b49\u5bb9\u91cf\u6a21\u578b\u4e5f\u663e\u793a\u51fa\u5411\u8bb0\u5fc6\u5316\u7684\u7c7b\u4f3c\u8f6c\u53d8\u65f6\uff0c\u6ca1\u6709\u6a21\u578b\uff08\u65e0\u8bba\u5927\u5c0f\uff09\u80fd\u5728\u8054\u5408\u8bad\u7ec3\u4e24\u4e2a\u4efb\u52a1\u65f6\u6210\u529f\u5916\u63a8\u3002", "conclusion": "\u9884\u8bad\u7ec3\u53ef\u80fd\u5185\u5728\u5730\u504f\u5411\u4e00\u79cd\u5b66\u4e60\u6a21\u5f0f\u800c\u975e\u53e6\u4e00\u79cd\u3002\u8fd9\u9879\u7814\u7a76\u63ed\u793a\u4e86\u6a21\u578b\u5bb9\u91cf\u662f\u5982\u4f55\u5f71\u54cd\u5b66\u4e60\u884c\u4e3a\u7684\uff0c\u5e76\u4e3a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bbe\u8ba1\u548c\u90e8\u7f72\u63d0\u4f9b\u4e86\u66f4\u5e7f\u6cdb\u7684\u610f\u4e49\u3002"}}
{"id": "2506.09272", "pdf": "https://arxiv.org/pdf/2506.09272", "abs": "https://arxiv.org/abs/2506.09272", "authors": ["Samuel Holt", "Max Ruiz Luyten", "Antonin Berthon", "Mihaela van der Schaar"], "title": "G-Sim: Generative Simulations with Large Language Models and Gradient-Free Calibration", "categories": ["cs.LG", "stat.ML", "68T05, 68U20, 62F15", "I.2.6; I.6.5; G.3"], "comment": "Accepted at the 42nd International Conference on Machine Learning\n  (ICML 2025). 9 pages, 3 figures", "summary": "Constructing robust simulators is essential for asking \"what if?\" questions\nand guiding policy in critical domains like healthcare and logistics. However,\nexisting methods often struggle, either failing to generalize beyond historical\ndata or, when using Large Language Models (LLMs), suffering from inaccuracies\nand poor empirical alignment. We introduce G-Sim, a hybrid framework that\nautomates simulator construction by synergizing LLM-driven structural design\nwith rigorous empirical calibration. G-Sim employs an LLM in an iterative loop\nto propose and refine a simulator's core components and causal relationships,\nguided by domain knowledge. This structure is then grounded in reality by\nestimating its parameters using flexible calibration techniques. Specifically,\nG-Sim can leverage methods that are both likelihood-free and gradient-free with\nrespect to the simulator, such as gradient-free optimization for direct\nparameter estimation or simulation-based inference for obtaining a posterior\ndistribution over parameters. This allows it to handle non-differentiable and\nstochastic simulators. By integrating domain priors with empirical evidence,\nG-Sim produces reliable, causally-informed simulators, mitigating\ndata-inefficiency and enabling robust system-level interventions for complex\ndecision-making.", "AI": {"tldr": "G-Sim\u662f\u4e00\u4e2a\u7ed3\u5408\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7ed3\u6784\u8bbe\u8ba1\u4e0e\u4e25\u683c\u7684\u7ecf\u9a8c\u6821\u51c6\u7684\u6df7\u5408\u6846\u67b6\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u6784\u5efa\u6a21\u62df\u5668\u3002\u5b83\u901a\u8fc7\u8fed\u4ee3\u5faa\u73af\u6765\u63d0\u51fa\u548c\u6539\u8fdb\u6a21\u62df\u5668\u7684\u6838\u5fc3\u7ec4\u4ef6\u548c\u56e0\u679c\u5173\u7cfb\uff0c\u5e76\u4f7f\u7528\u7075\u6d3b\u7684\u6821\u51c6\u6280\u672f\u4f30\u8ba1\u53c2\u6570\uff0c\u4ece\u800c\u5904\u7406\u4e0d\u53ef\u5fae\u548c\u968f\u673a\u6a21\u62df\u5668\uff0c\u4ea7\u751f\u53ef\u9760\u7684\u3001\u57fa\u4e8e\u56e0\u679c\u4fe1\u606f\u7684\u6a21\u62df\u5668\u3002", "motivation": "\u73b0\u6709\u7684\u6a21\u62df\u5668\u6784\u5efa\u65b9\u6cd5\u5728\u8d85\u51fa\u5386\u53f2\u6570\u636e\u8fdb\u884c\u6cdb\u5316\u6216\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u5b58\u5728\u4e0d\u51c6\u786e\u6027\u548c\u7ecf\u9a8c\u5bf9\u9f50\u6027\u5dee\u7684\u95ee\u9898\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86G-Sim\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u66f4\u52a0\u53ef\u9760\u4e14\u80fd\u6709\u6548\u6307\u5bfc\u590d\u6742\u51b3\u7b56\u8fc7\u7a0b\u7684\u6a21\u62df\u5668\u89e3\u51b3\u65b9\u6848\u3002", "method": "G-Sim\u91c7\u7528\u4e86\u4e00\u79cd\u8fed\u4ee3\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u5efa\u8bae\u5e76\u7cbe\u70bc\u6a21\u62df\u5668\u7684\u57fa\u672c\u7ec4\u6210\u90e8\u5206\u53ca\u5176\u4e4b\u95f4\u7684\u56e0\u679c\u8054\u7cfb\u3002\u6b64\u8fc7\u7a0b\u7531\u9886\u57df\u77e5\u8bc6\u5f15\u5bfc\uff0c\u5e76\u901a\u8fc7\u7075\u6d3b\u7684\u6821\u51c6\u6280\u672f\u6765\u4f30\u8ba1\u53c2\u6570\u503c\uff0c\u5305\u62ec\u65e0\u4f3c\u7136\u548c\u65e0\u68af\u5ea6\u4f18\u5316\u4ee5\u53ca\u57fa\u4e8e\u4eff\u771f\u7684\u63a8\u65ad\u7b49\u65b9\u6cd5\u3002", "result": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86G-Sim\u80fd\u591f\u6709\u6548\u5730\u7ed3\u5408\u9886\u57df\u5148\u9a8c\u77e5\u8bc6\u548c\u5b9e\u8bc1\u8bc1\u636e\uff0c\u751f\u6210\u53ef\u9760\u7684\u3001\u5177\u6709\u56e0\u679c\u4fe1\u606f\u7684\u6a21\u62df\u5668\u3002\u8fd9\u6709\u52a9\u4e8e\u51cf\u5c11\u6570\u636e\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\uff0c\u5e76\u652f\u6301\u9488\u5bf9\u590d\u6742\u51b3\u7b56\u573a\u666f\u7684\u7cfb\u7edf\u7ea7\u5e72\u9884\u63aa\u65bd\u3002", "conclusion": "G-Sim\u6846\u67b6\u901a\u8fc7\u96c6\u6210\u9886\u57df\u5148\u9a8c\u4e0e\u7ecf\u9a8c\u6821\u51c6\u514b\u670d\u4e86\u73b0\u6709\u6a21\u62df\u5668\u6784\u5efa\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u81ea\u52a8\u5316\u7684\u9014\u5f84\u6765\u521b\u5efa\u65e2\u7b26\u5408\u73b0\u5b9e\u53c8\u5177\u5907\u826f\u597d\u6cdb\u5316\u80fd\u529b\u7684\u6a21\u62df\u5668\uff0c\u8fd9\u5bf9\u8bf8\u5982\u533b\u7597\u4fdd\u5065\u548c\u7269\u6d41\u7b49\u5173\u952e\u9886\u57df\u7684\u653f\u7b56\u5236\u5b9a\u6709\u7740\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2506.09348", "pdf": "https://arxiv.org/pdf/2506.09348", "abs": "https://arxiv.org/abs/2506.09348", "authors": ["Natalie S. Frank"], "title": "Adversarial Surrogate Risk Bounds for Binary Classification", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": "37 pages, 2 figures", "summary": "A central concern in classification is the vulnerability of machine learning\nmodels to adversarial attacks. Adversarial training is one of the most popular\ntechniques for training robust classifiers, which involves minimizing an\nadversarial surrogate risk. Recent work characterized when a minimizing\nsequence of an adversarial surrogate risk is also a minimizing sequence of the\nadversarial classification risk for binary classification -- a property known\nas adversarial consistency. However, these results do not address the rate at\nwhich the adversarial classification risk converges to its optimal value for\nsuch a sequence of functions that minimize the adversarial surrogate. This\npaper provides surrogate risk bounds that quantify that convergence rate.\nAdditionally, we derive distribution-dependent surrogate risk bounds in the\nstandard (non-adversarial) learning setting, that may be of independent\ninterest.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5bf9\u6297\u8bad\u7ec3\u4e2d\u4ee3\u7406\u98ce\u9669\u6536\u655b\u5230\u6700\u4f18\u503c\u7684\u901f\u5ea6\uff0c\u5e76\u63d0\u4f9b\u4e86\u91cf\u5316\u8be5\u6536\u655b\u7387\u7684\u4ee3\u7406\u98ce\u9669\u8fb9\u754c\u3002\u6b64\u5916\uff0c\u8fd8\u63a8\u5bfc\u4e86\u5728\u6807\u51c6\uff08\u975e\u5bf9\u6297\u6027\uff09\u5b66\u4e60\u8bbe\u7f6e\u4e0b\u7684\u4f9d\u8d56\u4e8e\u5206\u5e03\u7684\u4ee3\u7406\u98ce\u9669\u8fb9\u754c\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u5df2\u7ecf\u63cf\u8ff0\u4e86\u4e8c\u5206\u7c7b\u4e2d\uff0c\u4f55\u65f6\u6700\u5c0f\u5316\u5e8f\u5217\u7684\u5bf9\u6297\u4ee3\u7406\u98ce\u9669\u540c\u65f6\u4e5f\u662f\u5bf9\u6297\u5206\u7c7b\u98ce\u9669\u7684\u6700\u5c0f\u5316\u5e8f\u5217\u2014\u2014\u5373\u6240\u8c13\u7684\u5bf9\u6297\u4e00\u81f4\u6027\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u7ed3\u679c\u5e76\u6ca1\u6709\u89e3\u51b3\u5bf9\u4e8e\u8fd9\u6837\u4e00\u7cfb\u5217\u6700\u5c0f\u5316\u5bf9\u6297\u4ee3\u7406\u98ce\u9669\u7684\u51fd\u6570\u6765\u8bf4\uff0c\u5bf9\u6297\u5206\u7c7b\u98ce\u9669\u4ee5\u4f55\u79cd\u901f\u7387\u6536\u655b\u5230\u5176\u6700\u4f18\u503c\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u63d0\u4f9b\u80fd\u591f\u91cf\u5316\u6536\u655b\u7387\u7684\u4ee3\u7406\u98ce\u9669\u8fb9\u754c\u6765\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\u3002\u540c\u65f6\uff0c\u5728\u6807\u51c6\u5b66\u4e60\u73af\u5883\u4e2d\u63a8\u5bfc\u51fa\u4e0e\u5206\u5e03\u76f8\u5173\u7684\u4ee3\u7406\u98ce\u9669\u8fb9\u754c\u3002", "result": "\u5f97\u5230\u4e86\u53ef\u4ee5\u8861\u91cf\u5bf9\u6297\u5206\u7c7b\u98ce\u9669\u6536\u655b\u901f\u5ea6\u7684\u4ee3\u7406\u98ce\u9669\u8fb9\u754c\u3002\u53e6\u5916\uff0c\u4e3a\u6807\u51c6\u5b66\u4e60\u73af\u5883\u4e2d\u7684\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u3001\u53ef\u80fd\u72ec\u7acb\u611f\u5174\u8da3\u7684\u4f9d\u8d56\u4e8e\u6570\u636e\u5206\u5e03\u7684\u4ee3\u7406\u98ce\u9669\u8fb9\u754c\u3002", "conclusion": "\u672c\u6587\u586b\u8865\u4e86\u5173\u4e8e\u5bf9\u6297\u4ee3\u7406\u98ce\u9669\u548c\u5b9e\u9645\u5bf9\u6297\u5206\u7c7b\u98ce\u9669\u4e4b\u95f4\u6536\u655b\u901f\u5ea6\u7684\u77e5\u8bc6\u7a7a\u767d\uff0c\u540c\u65f6\u4e5f\u4e3a\u5e38\u89c4\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u89c1\u89e3\u3002"}}
{"id": "2506.09104", "pdf": "https://arxiv.org/pdf/2506.09104", "abs": "https://arxiv.org/abs/2506.09104", "authors": ["Jung Hyun Lee", "Seungjae Shin", "Vinnam Kim", "Jaeseong You", "An Chen"], "title": "Unifying Block-wise PTQ and Distillation-based QAT for Progressive Quantization toward 2-bit Instruction-Tuned LLMs", "categories": ["cs.LG", "cs.AI"], "comment": "Preprint", "summary": "As the rapid scaling of large language models (LLMs) poses significant\nchallenges for deployment on resource-constrained devices, there is growing\ninterest in extremely low-bit quantization, such as 2-bit. Although prior works\nhave shown that 2-bit large models are pareto-optimal over their 4-bit smaller\ncounterparts in both accuracy and latency, these advancements have been limited\nto pre-trained LLMs and have not yet been extended to instruction-tuned models.\nTo bridge this gap, we propose Unified Progressive Quantization (UPQ)$-$a novel\nprogressive quantization framework (FP16$\\rightarrow$INT4$\\rightarrow$INT2)\nthat unifies block-wise post-training quantization (PTQ) with\ndistillation-based quantization-aware training (Distill-QAT) for INT2\ninstruction-tuned LLM quantization. UPQ first quantizes FP16 instruction-tuned\nmodels to INT4 using block-wise PTQ to significantly reduce the quantization\nerror introduced by subsequent INT2 quantization. Next, UPQ applies Distill-QAT\nto enable INT2 instruction-tuned LLMs to generate responses consistent with\ntheir original FP16 counterparts by minimizing the generalized Jensen-Shannon\ndivergence (JSD) between the two. To the best of our knowledge, we are the\nfirst to demonstrate that UPQ can quantize open-source instruction-tuned LLMs\nto INT2 without relying on proprietary post-training data, while achieving\nstate-of-the-art performances on MMLU and IFEval$-$two of the most\nrepresentative benchmarks for evaluating instruction-tuned LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7edf\u4e00\u6e10\u8fdb\u91cf\u5316\uff08UPQ\uff09\u6846\u67b6\uff0c\u80fd\u591f\u5c06\u6307\u4ee4\u8c03\u4f18\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4eceFP16\u9010\u6b65\u91cf\u5316\u5230INT4\u518d\u81f3INT2\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u539f\u59cb\u6a21\u578b\u7684\u54cd\u5e94\u4e00\u81f4\u6027\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5feb\u901f\u6269\u5c55\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u90e8\u7f72\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u6781\u4f4e\u6bd4\u7279\u91cf\u5316\u7684\u5174\u8da3\u65e5\u76ca\u589e\u52a0\u3002\u5c3d\u7ba1\u5148\u524d\u7684\u7814\u7a76\u8868\u660e2\u4f4d\u5927\u6a21\u578b\u5728\u51c6\u786e\u6027\u548c\u5ef6\u8fdf\u65b9\u9762\u4f18\u4e8e\u51764\u4f4d\u5c0f\u6a21\u578b\uff0c\u4f46\u8fd9\u4e9b\u8fdb\u5c55\u4ec5\u9650\u4e8e\u9884\u8bad\u7ec3LLM\uff0c\u5e76\u672a\u6269\u5c55\u5230\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a\u7edf\u4e00\u6e10\u8fdb\u91cf\u5316\uff08UPQ\uff09\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u5757\u7ea7\u540e\u8bad\u7ec3\u91cf\u5316\uff08PTQ\uff09\u548c\u57fa\u4e8e\u84b8\u998f\u7684\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\uff08Distill-QAT\uff09\uff0c\u7528\u4e8eINT2\u6307\u4ee4\u8c03\u4f18LLM\u91cf\u5316\u3002\u9996\u5148\u4f7f\u7528\u5757\u7ea7PTQ\u5c06FP16\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u91cf\u5316\u4e3aINT4\u4ee5\u51cf\u5c11\u540e\u7eedINT2\u91cf\u5316\u5f15\u5165\u7684\u91cf\u5316\u8bef\u5dee\uff1b\u7136\u540e\u901a\u8fc7\u6700\u5c0f\u5316\u4e24\u8005\u7684\u5e7f\u4e49Jensen-Shannon\u6563\u5ea6\uff08JSD\uff09\u6765\u5e94\u7528Distill-QAT\uff0c\u4f7fINT2\u6307\u4ee4\u8c03\u4f18LLM\u751f\u6210\u4e0e\u539f\u59cbFP16\u7248\u672c\u4e00\u81f4\u7684\u54cd\u5e94\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cUPQ\u53ef\u4ee5\u5728\u4e0d\u4f9d\u8d56\u4e13\u6709\u540e\u8bad\u7ec3\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06\u5f00\u6e90\u6307\u4ee4\u8c03\u4f18LLM\u91cf\u5316\u4e3aINT2\uff0c\u5e76\u4e14\u5728\u8bc4\u4f30\u6307\u4ee4\u8c03\u4f18LLM\u6700\u5177\u4ee3\u8868\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5MMLU\u548cIFEval\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "UPQ\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65b9\u6cd5\u6765\u5bf9\u6307\u4ee4\u8c03\u4f18\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6781\u7aef\u4f4e\u6bd4\u7279\u91cf\u5316\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2506.09451", "pdf": "https://arxiv.org/pdf/2506.09451", "abs": "https://arxiv.org/abs/2506.09451", "authors": ["Runxue Bao", "Quanchao Lu", "Yanfu Zhang"], "title": "Safe Screening Rules for Group SLOPE", "categories": ["cs.LG", "stat.ML"], "comment": "Accepted by ECML PKDD 2025", "summary": "Variable selection is a challenging problem in high-dimensional sparse\nlearning, especially when group structures exist. Group SLOPE performs well for\nthe adaptive selection of groups of predictors. However, the block\nnon-separable group effects in Group SLOPE make existing methods either invalid\nor inefficient. Consequently, Group SLOPE tends to incur significant\ncomputational costs and memory usage in practical high-dimensional scenarios.\nTo overcome this issue, we introduce a safe screening rule tailored for the\nGroup SLOPE model, which efficiently identifies inactive groups with zero\ncoefficients by addressing the block non-separable group effects. By excluding\nthese inactive groups during training, we achieve considerable gains in\ncomputational efficiency and memory usage. Importantly, the proposed screening\nrule can be seamlessly integrated into existing solvers for both batch and\nstochastic algorithms. Theoretically, we establish that our screening rule can\nbe safely employed with existing optimization algorithms, ensuring the same\nresults as the original approaches. Experimental results confirm that our\nmethod effectively detects inactive feature groups and significantly boosts\ncomputational efficiency without compromising accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9Group SLOPE\u6a21\u578b\u7684\u5b89\u5168\u7b5b\u9009\u89c4\u5219\uff0c\u8be5\u89c4\u5219\u80fd\u591f\u6709\u6548\u8bc6\u522b\u96f6\u7cfb\u6570\u7684\u975e\u6d3b\u8dc3\u7ec4\uff0c\u5e76\u5728\u5b9e\u9645\u9ad8\u7ef4\u573a\u666f\u4e2d\u663e\u8457\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u548c\u51cf\u5c11\u5185\u5b58\u4f7f\u7528\u3002", "motivation": "\u5728\u9ad8\u7ef4\u7a00\u758f\u5b66\u4e60\u4e2d\uff0c\u7279\u522b\u662f\u5b58\u5728\u7ec4\u7ed3\u6784\u7684\u60c5\u51b5\u4e0b\uff0c\u53d8\u91cf\u9009\u62e9\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\u3002\u867d\u7136Group SLOPE\u5bf9\u4e8e\u81ea\u9002\u5e94\u5730\u9009\u62e9\u9884\u6d4b\u56e0\u5b50\u7ec4\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5176\u5757\u4e0d\u53ef\u5206\u79bb\u7684\u7ec4\u6548\u5e94\u4f7f\u5f97\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u65e0\u6548\u8981\u4e48\u4f4e\u6548\uff0c\u5bfc\u81f4\u5728\u5b9e\u9645\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u8ba1\u7b97\u6210\u672c\u548c\u5185\u5b58\u4f7f\u7528\u91cf\u5927\u3002", "method": "\u4f5c\u8005\u4eec\u5f15\u5165\u4e86\u4e00\u79cd\u4e13\u4e3aGroup SLOPE\u6a21\u578b\u8bbe\u8ba1\u7684\u5b89\u5168\u7b5b\u9009\u89c4\u5219\uff0c\u4ee5\u89e3\u51b3\u5757\u4e0d\u53ef\u5206\u79bb\u7684\u7ec4\u6548\u5e94\u95ee\u9898\u3002\u8fd9\u4e2a\u7b5b\u9009\u89c4\u5219\u53ef\u4ee5\u6709\u6548\u5730\u8bc6\u522b\u51fa\u5177\u6709\u96f6\u7cfb\u6570\u7684\u975e\u6d3b\u8dc3\u7ec4\u3002\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6392\u9664\u8fd9\u4e9b\u975e\u6d3b\u8dc3\u7ec4\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u5e76\u51cf\u5c11\u4e86\u5185\u5b58\u4f7f\u7528\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b5b\u9009\u89c4\u5219\u53ef\u4ee5\u5b89\u5168\u5730\u4e0e\u73b0\u6709\u7684\u4f18\u5316\u7b97\u6cd5\u7ed3\u5408\u4f7f\u7528\uff0c\u4fdd\u8bc1\u4e86\u4e0e\u539f\u59cb\u65b9\u6cd5\u76f8\u540c\u7684\u7ed3\u679c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u5b9e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u68c0\u6d4b\u5230\u975e\u6d3b\u8dc3\u7279\u5f81\u7ec4\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u800c\u4e0d\u5f71\u54cd\u51c6\u786e\u6027\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u7684\u65b0\u7b5b\u9009\u89c4\u5219\uff0c\u7814\u7a76\u8005\u4eec\u6210\u529f\u5730\u89e3\u51b3\u4e86Group SLOPE\u6a21\u578b\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u548c\u5185\u5b58\u4f7f\u7528\u95ee\u9898\uff0c\u4ece\u800c\u80fd\u591f\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\u5904\u7406\u66f4\u52a0\u590d\u6742\u7684\u9ad8\u7ef4\u6570\u636e\u96c6\u3002"}}
{"id": "2506.09105", "pdf": "https://arxiv.org/pdf/2506.09105", "abs": "https://arxiv.org/abs/2506.09105", "authors": ["Javier Lopez-Piqueres", "Pranav Deshpande", "Archan Ray", "Mattia J. Villani", "Marco Pistoia", "Niraj Kumar"], "title": "MetaTT: A Global Tensor-Train Adapter for Parameter-Efficient Fine-Tuning", "categories": ["cs.LG", "cs.AI", "quant-ph"], "comment": null, "summary": "We present MetaTT, a unified Tensor Train (TT) adapter framework for global\nlow-rank fine-tuning of pre-trained transformers. Unlike LoRA, which fine-tunes\neach weight matrix independently, MetaTT uses a single shared TT to factorize\nall transformer sub-modules -- query, key, value, projection, and feed-forward\nlayers -- by indexing the structural axes like layer and matrix type, and\noptionally heads and tasks. For a given rank, while LoRA adds parameters\nproportional to the product across modes, MetaTT only adds parameters\nproportional to the sum across modes leading to a significantly compressed\nfinal adapter. Our benchmarks compare MetaTT with LoRA along with recent\nstate-of-the-art matrix and tensor decomposition based fine-tuning schemes. We\nobserve that when tested on standard language modeling benchmarks, MetaTT leads\nto the most reduction in the parameters while maintaining similar accuracy to\nLoRA and even outperforming other tensor-based methods. Unlike CP or other\nrank-factorizations, the TT ansatz benefits from mature optimization routines\n-- e.g., DMRG-style rank adaptive minimization in addition to Adam, which we\nfind simplifies training. Because new modes can be appended cheaply, MetaTT\nnaturally extends to shared adapters across many tasks without redesigning the\ncore tensor.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMetaTT\u7684\u7edf\u4e00\u5f20\u91cf\u8bad\u7ec3\u9002\u914d\u5668\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u8bad\u7ec3\u53d8\u6362\u5668\u7684\u5168\u5c40\u4f4e\u79e9\u5fae\u8c03\u3002\u4e0eLoRA\u72ec\u7acb\u5fae\u8c03\u6bcf\u4e2a\u6743\u91cd\u77e9\u9635\u4e0d\u540c\uff0cMetaTT\u4f7f\u7528\u5355\u4e2a\u5171\u4eabTT\u5bf9\u6240\u6709\u53d8\u6362\u5668\u5b50\u6a21\u5757\u8fdb\u884c\u5206\u89e3\uff0c\u5e76\u901a\u8fc7\u7d22\u5f15\u7ed3\u6784\u8f74\u5982\u5c42\u548c\u77e9\u9635\u7c7b\u578b\uff08\u53ef\u9009\u5730\u8fd8\u5305\u62ec\u5934\u548c\u4efb\u52a1\uff09\u6765\u5b9e\u73b0\u3002\u5bf9\u4e8e\u7ed9\u5b9a\u7684\u79e9\uff0c\u5f53LoRA\u6dfb\u52a0\u7684\u53c2\u6570\u4e0e\u6a21\u5f0f\u4e58\u79ef\u6210\u6bd4\u4f8b\u65f6\uff0cMetaTT\u53ea\u6dfb\u52a0\u4e0e\u6a21\u5f0f\u4e4b\u548c\u6210\u6bd4\u4f8b\u7684\u53c2\u6570\uff0c\u4ece\u800c\u663e\u8457\u538b\u7f29\u6700\u7ec8\u9002\u914d\u5668\u3002\u5b9e\u9a8c\u8868\u660e\uff0cMetaTT\u5728\u4fdd\u6301\u4e0eLoRA\u76f8\u4f3c\u51c6\u786e\u5ea6\u7684\u540c\u65f6\uff0c\u6bd4\u5176\u4ed6\u57fa\u4e8e\u5f20\u91cf\u7684\u65b9\u6cd5\u51cf\u5c11\u4e86\u66f4\u591a\u53c2\u6570\u3002", "motivation": "\u4e3a\u4e86\u63d0\u9ad8\u9884\u8bad\u7ec3\u53d8\u6362\u5668\u6a21\u578b\u5728\u8fdb\u884c\u4f4e\u79e9\u5fae\u8c03\u65f6\u7684\u6548\u7387\u548c\u6548\u679c\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u8bbe\u8ba1\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u989d\u5916\u5f15\u5165\u7684\u53c2\u6570\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u7684\u51c6\u786e\u6027\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86MetaTT\uff0c\u5b83\u5229\u7528\u4e00\u4e2a\u5171\u4eab\u7684Tensor Train (TT)\u6765\u5bf9\u6240\u6709\u7684Transformer\u5b50\u6a21\u5757\u8fdb\u884c\u56e0\u5f0f\u5206\u89e3\u3002\u8fd9\u79cd\u65b9\u6cd5\u901a\u8fc7\u7d22\u5f15\u8bf8\u5982\u5c42\u3001\u77e9\u9635\u7c7b\u578b\u7b49\u7ed3\u6784\u6027\u8f74\u7ebf\uff0c\u4ee5\u53ca\u53ef\u9009\u7684\u4efb\u52a1\u548c\u5934\u90e8\uff0c\u6765\u533a\u522b\u5bf9\u5f85\u4e0d\u540c\u7684\u5b50\u6a21\u5757\u3002\u76f8\u6bd4\u4e8eLoRA\u6bcf\u6b21\u589e\u52a0\u4e0e\u8de8\u6a21\u6001\u4e58\u79ef\u6210\u6bd4\u4f8b\u7684\u53c2\u6570\uff0cMetaTT\u4ec5\u589e\u52a0\u4e86\u4e0e\u8de8\u6a21\u6001\u603b\u548c\u6210\u6bd4\u4f8b\u7684\u53c2\u6570\uff0c\u8fd9\u5bfc\u81f4\u4e86\u66f4\u7d27\u51d1\u7684\u9002\u914d\u5668\u3002\u6b64\u5916\uff0cMetaTT\u8fd8\u652f\u6301\u6709\u6548\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u6bd4\u5982DMRG\u98ce\u683c\u7684\u79e9\u81ea\u9002\u5e94\u6700\u5c0f\u5316\u52a0\u4e0aAdam\u4f18\u5316\u5668\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6807\u51c6\u8bed\u8a00\u5efa\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMetaTT\u76f8\u8f83\u4e8eLoRA\u548c\u5176\u4ed6\u6700\u8fd1\u7684\u57fa\u4e8e\u77e9\u9635\u53ca\u5f20\u91cf\u5206\u89e3\u7684\u5fae\u8c03\u65b9\u6848\uff0c\u5728\u6781\u5927\u7a0b\u5ea6\u4e0a\u51cf\u5c11\u4e86\u53c2\u6570\u91cf\uff0c\u540c\u65f6\u7ef4\u6301\u4e86\u76f8\u8fd1\u751a\u81f3\u66f4\u597d\u7684\u51c6\u786e\u6027\u3002\u7279\u522b\u662f\u76f8\u6bd4CP\u6216\u5176\u4ed6\u79e9\u56e0\u5b50\u5206\u89e3\u6cd5\uff0cMetaTT\u5f97\u76ca\u4e8e\u6210\u719f\u7684\u4f18\u5316\u8fc7\u7a0b\uff0c\u4f7f\u5f97\u8bad\u7ec3\u66f4\u52a0\u7b80\u4fbf\u3002", "conclusion": "MetaTT\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u4e14\u9ad8\u6548\u7684\u5168\u5c40\u4f4e\u79e9\u5fae\u8c03\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u964d\u4f4e\u9884\u8bad\u7ec3\u53d8\u6362\u5668\u6a21\u578b\u5fae\u8c03\u65f6\u6240\u9700\u7684\u989d\u5916\u53c2\u6570\u6570\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002\u5b83\u7684\u4f18\u52bf\u5728\u4e8e\u80fd\u591f\u81ea\u7136\u5730\u6269\u5c55\u5230\u591a\u4efb\u52a1\u5171\u4eab\u9002\u914d\u5668\u4e0a\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u8bbe\u8ba1\u6838\u5fc3\u5f20\u91cf\u3002"}}
{"id": "2506.09508", "pdf": "https://arxiv.org/pdf/2506.09508", "abs": "https://arxiv.org/abs/2506.09508", "authors": ["Andreas Schlaginhaufen", "Reda Ouhamma", "Maryam Kamgarpour"], "title": "Efficient Preference-Based Reinforcement Learning: Randomized Exploration Meets Experimental Design", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "comment": null, "summary": "We study reinforcement learning from human feedback in general Markov\ndecision processes, where agents learn from trajectory-level preference\ncomparisons. A central challenge in this setting is to design algorithms that\nselect informative preference queries to identify the underlying reward while\nensuring theoretical guarantees. We propose a meta-algorithm based on\nrandomized exploration, which avoids the computational challenges associated\nwith optimistic approaches and remains tractable. We establish both regret and\nlast-iterate guarantees under mild reinforcement learning oracle assumptions.\nTo improve query complexity, we introduce and analyze an improved algorithm\nthat collects batches of trajectory pairs and applies optimal experimental\ndesign to select informative comparison queries. The batch structure also\nenables parallelization of preference queries, which is relevant in practical\ndeployment as feedback can be gathered concurrently. Empirical evaluation\nconfirms that the proposed method is competitive with reward-based\nreinforcement learning while requiring a small number of preference queries.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u4e00\u822c\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u968f\u673a\u63a2\u7d22\u7684\u5143\u7b97\u6cd5\u6765\u9009\u62e9\u4fe1\u606f\u91cf\u5927\u7684\u504f\u597d\u67e5\u8be2\uff0c\u5e76\u901a\u8fc7\u6279\u5904\u7406\u548c\u6700\u4f18\u5b9e\u9a8c\u8bbe\u8ba1\u6539\u8fdb\u4e86\u67e5\u8be2\u590d\u6742\u5ea6\u3002\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\u8be5\u65b9\u6cd5\u5177\u6709\u7ade\u4e89\u529b\u4e14\u9700\u8981\u8f83\u5c11\u7684\u504f\u597d\u67e5\u8be2\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u5982\u4f55\u5728\u4e00\u822c\u7684\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\uff0c\u901a\u8fc7\u8f68\u8ff9\u7ea7\u522b\u7684\u504f\u597d\u6bd4\u8f83\u8ba9\u4ee3\u7406\u5b66\u4e60\uff0c\u540c\u65f6\u8bbe\u8ba1\u51fa\u65e2\u80fd\u8bc6\u522b\u6f5c\u5728\u5956\u52b1\u53c8\u80fd\u4fdd\u8bc1\u7406\u8bba\u62c5\u4fdd\u7684\u7b97\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u968f\u673a\u63a2\u7d22\u7684\u5143\u7b97\u6cd5\uff0c\u907f\u514d\u4e86\u4e50\u89c2\u65b9\u6cd5\u5e26\u6765\u7684\u8ba1\u7b97\u6311\u6218\u5e76\u4fdd\u6301\u4e86\u53ef\u64cd\u4f5c\u6027\u3002\u4e3a\u4e86\u63d0\u9ad8\u67e5\u8be2\u6548\u7387\uff0c\u5f15\u5165\u4e86\u4e00\u79cd\u6539\u8fdb\u7b97\u6cd5\uff0c\u5b83\u6536\u96c6\u8f68\u8ff9\u5bf9\u6279\u6b21\u5e76\u8fd0\u7528\u6700\u4f18\u5b9e\u9a8c\u8bbe\u8ba1\u6765\u9009\u62e9\u4fe1\u606f\u4e30\u5bcc\u7684\u6bd4\u8f83\u67e5\u8be2\u3002", "result": "\u5efa\u7acb\u4e86\u5728\u6e29\u548c\u7684\u5f3a\u5316\u5b66\u4e60\u9884\u8a00\u5047\u8bbe\u4e0b\u7684\u9057\u61be\u548c\u6700\u7ec8\u8fed\u4ee3\u4fdd\u8bc1\u3002\u6279\u91cf\u7ed3\u6784\u8fd8\u5141\u8bb8\u5e76\u884c\u5316\u504f\u597d\u67e5\u8be2\uff0c\u8fd9\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u662f\u6709\u610f\u4e49\u7684\uff0c\u56e0\u4e3a\u53ef\u4ee5\u540c\u65f6\u6536\u96c6\u53cd\u9988\u3002", "conclusion": "\u5b9e\u8bc1\u8bc4\u4ef7\u8bc1\u5b9e\u4e86\u6240\u63d0\u65b9\u6cd5\u4e0e\u57fa\u4e8e\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\uff0c\u540c\u65f6\u53ea\u9700\u8981\u5c11\u91cf\u7684\u504f\u597d\u67e5\u8be2\u3002"}}
{"id": "2506.09108", "pdf": "https://arxiv.org/pdf/2506.09108", "abs": "https://arxiv.org/abs/2506.09108", "authors": ["Yuwei Zhang", "Kumar Ayush", "Siyuan Qiao", "A. Ali Heydari", "Girish Narayanswamy", "Maxwell A. Xu", "Ahmed A. Metwally", "Shawn Xu", "Jake Garrison", "Xuhai Xu", "Tim Althoff", "Yun Liu", "Pushmeet Kohli", "Jiening Zhan", "Mark Malhotra", "Shwetak Patel", "Cecilia Mascolo", "Xin Liu", "Daniel McDuff", "Yuzhe Yang"], "title": "SensorLM: Learning the Language of Wearable Sensors", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "We present SensorLM, a family of sensor-language foundation models that\nenable wearable sensor data understanding with natural language. Despite its\npervasive nature, aligning and interpreting sensor data with language remains\nchallenging due to the lack of paired, richly annotated sensor-text\ndescriptions in uncurated, real-world wearable data. We introduce a\nhierarchical caption generation pipeline designed to capture statistical,\nstructural, and semantic information from sensor data. This approach enabled\nthe curation of the largest sensor-language dataset to date, comprising over\n59.7 million hours of data from more than 103,000 people. Furthermore, SensorLM\nextends prominent multimodal pretraining architectures (e.g., CLIP, CoCa) and\nrecovers them as specific variants within a generic architecture. Extensive\nexperiments on real-world tasks in human activity analysis and healthcare\nverify the superior performance of SensorLM over state-of-the-art in zero-shot\nrecognition, few-shot learning, and cross-modal retrieval. SensorLM also\ndemonstrates intriguing capabilities including scaling behaviors, label\nefficiency, sensor captioning, and zero-shot generalization to unseen tasks.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SensorLM\uff0c\u4e00\u79cd\u80fd\u591f\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u53ef\u7a7f\u6234\u4f20\u611f\u5668\u6570\u636e\u7684\u57fa\u7840\u6a21\u578b\u5bb6\u65cf\u3002\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u5206\u5c42\u7684\u6807\u9898\u751f\u6210\u6d41\u7a0b\u6765\u6355\u6349\u4f20\u611f\u5668\u6570\u636e\u4e2d\u7684\u7edf\u8ba1\u3001\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u4ece\u800c\u6784\u5efa\u4e86\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u4f20\u611f\u5668-\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u5e76\u5728\u4eba\u7c7b\u6d3b\u52a8\u5206\u6790\u548c\u533b\u7597\u4fdd\u5065\u7b49\u5b9e\u9645\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5c3d\u7ba1\u4f20\u611f\u5668\u6570\u636e\u65e0\u5904\u4e0d\u5728\uff0c\u4f46\u4e0e\u81ea\u7136\u8bed\u8a00\u5bf9\u9f50\u548c\u89e3\u91ca\u8fd9\u4e9b\u6570\u636e\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u539f\u56e0\u5728\u4e8e\u7f3a\u4e4f\u914d\u5bf9\u7684\u3001\u4e30\u5bcc\u6ce8\u91ca\u7684\u4f20\u611f\u5668-\u6587\u672c\u63cf\u8ff0\uff0c\u5c24\u5176\u662f\u5728\u672a\u7ecf\u6574\u7406\u7684\u771f\u5b9e\u4e16\u754c\u53ef\u7a7f\u6234\u8bbe\u5907\u6570\u636e\u4e2d\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u7684\u6807\u9898\u751f\u6210\u6d41\u7a0b\uff0c\u7528\u4e8e\u4ece\u4f20\u611f\u5668\u6570\u636e\u4e2d\u63d0\u53d6\u7edf\u8ba1\u3001\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\u3002\u6b64\u5916\uff0cSensorLM\u6269\u5c55\u4e86\u4e00\u4e9b\u8457\u540d\u7684\u591a\u6a21\u6001\u9884\u8bad\u7ec3\u67b6\u6784\uff08\u5982CLIP\u3001CoCa\uff09\uff0c\u5e76\u5c06\u5176\u4f5c\u4e3a\u901a\u7528\u67b6\u6784\u4e0b\u7684\u7279\u5b9a\u53d8\u4f53\u8fdb\u884c\u6062\u590d\u3002", "result": "SensorLM\u5728\u96f6\u6837\u672c\u8bc6\u522b\u3001\u5c11\u91cf\u5b66\u4e60\u4ee5\u53ca\u8de8\u6a21\u6001\u68c0\u7d22\u7b49\u65b9\u9762\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u8868\u73b0\u3002\u8be5\u6a21\u578b\u8fd8\u5c55\u793a\u4e86\u5305\u62ec\u6269\u5c55\u884c\u4e3a\u3001\u6807\u7b7e\u6548\u7387\u3001\u4f20\u611f\u5668\u5b57\u5e55\u4ee5\u53ca\u5bf9\u672a\u89c1\u4efb\u52a1\u7684\u96f6\u6837\u672c\u6cdb\u5316\u5728\u5185\u7684\u6709\u8da3\u80fd\u529b\u3002", "conclusion": "SensorLM\u4e3a\u7406\u89e3\u548c\u5229\u7528\u53ef\u7a7f\u6234\u4f20\u611f\u5668\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u65b0\u5de5\u5177\uff0c\u5b83\u4e0d\u4ec5\u80fd\u591f\u5904\u7406\u5927\u91cf\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\uff0c\u800c\u4e14\u5728\u591a\u4e2a\u5173\u952e\u9886\u57df\u663e\u793a\u51fa\u5353\u8d8a\u7684\u6027\u80fd\u548c\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2506.09781", "pdf": "https://arxiv.org/pdf/2506.09781", "abs": "https://arxiv.org/abs/2506.09781", "authors": ["Chungpa Lee", "Sehee Lim", "Kibok Lee", "Jy-yong Sohn"], "title": "On the Similarities of Embeddings in Contrastive Learning", "categories": ["cs.LG", "stat.ML"], "comment": "contrastive learning, representation learning, embedding, similarity,\n  negative pair, positive pair", "summary": "Contrastive learning (CL) operates on a simple yet effective principle:\nembeddings of positive pairs are pulled together, while those of negative pairs\nare pushed apart. Although various forms of contrastive loss have been proposed\nand analyzed from different perspectives, prior works lack a comprehensive\nframework that systematically explains a broad class of these objectives. In\nthis paper, we present a unified framework for understanding CL, which is based\non analyzing the cosine similarity between embeddings of positive and negative\npairs. In full-batch settings, we show that perfect alignment of positive pairs\nis unattainable when similarities of negative pairs fall below a certain\nthreshold, and that this misalignment can be alleviated by incorporating\nwithin-view negative pairs. In mini-batch settings, we demonstrate that smaller\nbatch sizes incur stronger separation among negative pairs within batches,\nwhich leads to higher variance in similarities of negative pairs. To address\nthis limitation of mini-batch CL, we introduce an auxiliary loss term that\nreduces the variance of similarities of negative pairs in CL. Empirical results\ndemonstrate that incorporating the proposed loss consistently improves the\nperformance of CL methods in small-batch training.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5206\u6790\u6b63\u8d1f\u6837\u672c\u5bf9\u4e4b\u95f4\u4f59\u5f26\u76f8\u4f3c\u6027\u7684\u7edf\u4e00\u6846\u67b6\u6765\u7406\u89e3\u5bf9\u6bd4\u5b66\u4e60\uff08CL\uff09\uff0c\u63ed\u793a\u4e86\u5168\u6279\u91cf\u8bbe\u7f6e\u4e0b\u5b8c\u7f8e\u5bf9\u9f50\u6b63\u6837\u672c\u5bf9\u7684\u4e0d\u53ef\u8fbe\u6027\u4ee5\u53ca\u5c0f\u6279\u91cf\u8bbe\u7f6e\u4e0b\u8d1f\u6837\u672c\u5bf9\u95f4\u76f8\u4f3c\u6027\u65b9\u5dee\u8fc7\u5927\u7684\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u8f85\u52a9\u635f\u5931\u9879\u6765\u51cf\u5c11\u8d1f\u6837\u672c\u5bf9\u76f8\u4f3c\u6027\u7684\u65b9\u5dee\uff0c\u4ece\u800c\u5728\u5c0f\u6279\u91cf\u8bad\u7ec3\u4e2d\u63d0\u9ad8CL\u65b9\u6cd5\u7684\u8868\u73b0\u3002", "motivation": "\u867d\u7136\u5df2\u7ecf\u63d0\u51fa\u4e86\u591a\u79cd\u5f62\u5f0f\u7684\u5bf9\u6bd4\u635f\u5931\u5e76\u4ece\u4e0d\u540c\u89d2\u5ea6\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u4f46\u5148\u524d\u7684\u5de5\u4f5c\u7f3a\u4e4f\u4e00\u4e2a\u80fd\u591f\u7cfb\u7edf\u89e3\u91ca\u8fd9\u4e9b\u76ee\u6807\u7684\u7efc\u5408\u6027\u6846\u67b6\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u6b63\u8d1f\u6837\u672c\u5bf9\u4e4b\u95f4\u7684\u4f59\u5f26\u76f8\u4f3c\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7edf\u4e00\u6846\u67b6\u6765\u7406\u89e3\u5bf9\u6bd4\u5b66\u4e60\u3002\u5bf9\u4e8e\u5168\u6279\u91cf\u573a\u666f\uff0c\u7814\u7a76\u4e86\u5f53\u8d1f\u6837\u672c\u5bf9\u7684\u76f8\u4f3c\u5ea6\u4f4e\u4e8e\u67d0\u4e00\u9608\u503c\u65f6\u6b63\u6837\u672c\u5bf9\u7684\u5bf9\u9f50\u60c5\u51b5\uff1b\u5bf9\u4e8e\u5c0f\u6279\u91cf\u573a\u666f\uff0c\u5219\u5c55\u793a\u4e86\u8f83\u5c0f\u7684\u6279\u6b21\u5927\u5c0f\u5982\u4f55\u5bfc\u81f4\u6279\u5185\u8d1f\u6837\u672c\u5bf9\u4e4b\u95f4\u66f4\u5f3a\u7684\u5206\u79bb\uff0c\u8fdb\u800c\u5bfc\u81f4\u8d1f\u6837\u672c\u5bf9\u76f8\u4f3c\u5ea6\u7684\u66f4\u5927\u65b9\u5dee\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u989d\u5916\u7684\u635f\u5931\u9879\u4ee5\u51cf\u5c11\u8d1f\u6837\u672c\u5bf9\u76f8\u4f3c\u5ea6\u7684\u65b9\u5dee\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5c0f\u6279\u91cf\u8bad\u7ec3\u4e2d\u52a0\u5165\u63d0\u51fa\u7684\u635f\u5931\u9879\u53ef\u4ee5\u4e00\u81f4\u5730\u63d0\u9ad8\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u7684\u8868\u73b0\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u7684\u7edf\u4e00\u6846\u67b6\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3\u5bf9\u6bd4\u5b66\u4e60\uff0c\u5e76\u4e14\u63d0\u51fa\u7684\u7528\u4e8e\u51cf\u5c11\u8d1f\u6837\u672c\u5bf9\u76f8\u4f3c\u6027\u65b9\u5dee\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u5c0f\u6279\u91cf\u8bad\u7ec3\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2506.09110", "pdf": "https://arxiv.org/pdf/2506.09110", "abs": "https://arxiv.org/abs/2506.09110", "authors": ["Jingying Ma", "Feng Wu", "Qika Lin", "Yucheng Xing", "Chenyu Liu", "Ziyu Jia", "Mengling Feng"], "title": "CodeBrain: Bridging Decoupled Tokenizer and Multi-Scale Architecture for EEG Foundation Model", "categories": ["cs.LG"], "comment": null, "summary": "Electroencephalography (EEG) provides real-time insights into brain activity\nand is widely used in neuroscience. However, variations in channel\nconfigurations, sequence lengths, and task objectives limit the transferability\nof traditional task-specific models. Although recent EEG foundation models\n(EFMs) aim to learn generalizable representations, they struggle with limited\nheterogeneous representation capacity and inefficiency in capturing multi-scale\nbrain dependencies. To address these challenges, we propose CodeBrain, an\nefficient EFM structurally aligned with brain organization, trained in two\nstages. (1) We introduce a TFDual-Tokenizer that independently tokenizes\nheterogeneous temporal and frequency components, enabling a quadratic expansion\nof the discrete representation space. This also offers a degree of\ninterpretability through cross-domain token analysis. (2) We propose the\nEEGSSM, which combines a structured global convolution architecture and a\nsliding window attention mechanism to jointly model sparse long-range and local\ndependencies. Unlike fully connected Transformer models, EEGSSM better reflects\nthe brain's small-world topology and efficiently captures EEG's inherent\nmulti-scale structure. EEGSSM is trained with a masked self-supervised learning\nobjective to predict token indices obtained in TFDual-Tokenizer. Comprehensive\nexperiments on 10 public EEG datasets demonstrate the generalizability of\nCodeBrain with linear probing. By offering biologically informed and\ninterpretable EEG modeling, CodeBrain lays the foundation for future\nneuroscience research. Both code and pretraining weights will be released in\nthe future version.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCodeBrain\u7684\u65b0\u578bEEG\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7TFDual-Tokenizer\u548cEEGSSM\u6765\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u5728\u5f02\u6784\u8868\u793a\u80fd\u529b\u548c\u591a\u5c3a\u5ea6\u8111\u4f9d\u8d56\u6027\u6355\u6349\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524dEEG\u57fa\u7840\u6a21\u578b\u5b58\u5728\u5f02\u6784\u8868\u793a\u80fd\u529b\u6709\u9650\u53ca\u6355\u6349\u591a\u5c3a\u5ea6\u8111\u4f9d\u8d56\u6027\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u7684\u8fc1\u79fb\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u8bad\u7ec3\u7684CodeBrain\u6a21\u578b\uff0c\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528TFDual-Tokenizer\u72ec\u7acb\u5730\u5bf9\u65f6\u57df\u548c\u9891\u57df\u6210\u5206\u8fdb\u884c\u5206\u8bcd\u4ee5\u6269\u5c55\u79bb\u6563\u8868\u793a\u7a7a\u95f4\uff1b\u7b2c\u4e8c\u9636\u6bb5\u63d0\u51fa\u4e86\u7ed3\u5408\u5168\u5c40\u5377\u79ef\u67b6\u6784\u4e0e\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b\u673a\u5236\u7684EEGSSM\uff0c\u7528\u4e8e\u5efa\u6a21\u7a00\u758f\u957f\u8ddd\u79bb\u548c\u5c40\u90e8\u4f9d\u8d56\u5173\u7cfb\u3002", "result": "\u572810\u4e2a\u516c\u5f00EEG\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86CodeBrain\u901a\u8fc7\u7ebf\u6027\u63a2\u6d4b\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "CodeBrain\u4e3a\u672a\u6765\u795e\u7ecf\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u751f\u7269\u4fe1\u606f\u5b66\u652f\u6301\u4e14\u53ef\u89e3\u91ca\u7684EEG\u5efa\u6a21\u65b9\u6cd5\uff0c\u5e76\u8ba1\u5212\u5728\u672a\u6765\u7248\u672c\u4e2d\u53d1\u5e03\u4ee3\u7801\u548c\u9884\u8bad\u7ec3\u6743\u91cd\u3002"}}
{"id": "2506.09870", "pdf": "https://arxiv.org/pdf/2506.09870", "abs": "https://arxiv.org/abs/2506.09870", "authors": ["Maximilian Egger", "Rawad Bitar"], "title": "Private Aggregation for Byzantine-Resilient Heterogeneous Federated Learning", "categories": ["cs.LG", "cs.DC", "cs.IT", "math.IT", "stat.ML"], "comment": null, "summary": "Ensuring resilience to Byzantine clients while maintaining the privacy of the\nclients' data is a fundamental challenge in federated learning (FL). When the\nclients' data is homogeneous, suitable countermeasures were studied from an\ninformation-theoretic perspective utilizing secure aggregation techniques while\nensuring robust aggregation of the clients' gradients. However, the\ncountermeasures used fail when the clients' data is heterogeneous. Suitable\npre-processing techniques, such as nearest neighbor mixing, were recently shown\nto enhance the performance of those countermeasures in the heterogeneous\nsetting. Nevertheless, those pre-processing techniques cannot be applied with\nthe introduced privacy-preserving mechanisms.\n  We propose a multi-stage method encompassing a careful co-design of\nverifiable secret sharing, secure aggregation, and a tailored symmetric private\ninformation retrieval scheme to achieve information-theoretic privacy\nguarantees and Byzantine resilience under data heterogeneity. We evaluate the\neffectiveness of our scheme on a variety of attacks and show how it outperforms\nthe previously known techniques. Since the communication overhead of secure\naggregation is non-negligible, we investigate the interplay with zero-order\nestimation methods that reduce the communication cost in state-of-the-art FL\ntasks and thereby make private aggregation scalable.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9636\u6bb5\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u9a8c\u8bc1\u7684\u79d8\u5bc6\u5171\u4eab\u3001\u5b89\u5168\u805a\u5408\u548c\u5b9a\u5236\u7684\u5bf9\u79f0\u79c1\u6709\u4fe1\u606f\u68c0\u7d22\u65b9\u6848\u7684\u7cbe\u5fc3\u5171\u540c\u8bbe\u8ba1\uff0c\u4ee5\u5728\u6570\u636e\u5f02\u6784\u6027\u4e0b\u5b9e\u73b0\u4fe1\u606f\u8bba\u9690\u79c1\u4fdd\u8bc1\u548c\u62dc\u5360\u5ead\u5bb9\u9519\u3002", "motivation": "\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\uff0c\u786e\u4fdd\u5bf9\u62dc\u5360\u5ead\u5ba2\u6237\u7aef\u7684\u5f39\u6027\u540c\u65f6\u4fdd\u6301\u5ba2\u6237\u7aef\u6570\u636e\u7684\u9690\u79c1\u662f\u4e00\u4e2a\u57fa\u672c\u6311\u6218\u3002\u5f53\u5ba2\u6237\u7aef\u7684\u6570\u636e\u662f\u540c\u8d28\u7684\u65f6\u5019\uff0c\u4ece\u4fe1\u606f\u8bba\u7684\u89d2\u5ea6\u7814\u7a76\u4e86\u5229\u7528\u5b89\u5168\u805a\u5408\u6280\u672f\u6765\u786e\u4fdd\u5ba2\u6237\u68af\u5ea6\u7684\u7a33\u5065\u805a\u5408\u7684\u9002\u5f53\u5bf9\u7b56\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u5bf9\u7b56\u5728\u5ba2\u6237\u7aef\u6570\u636e\u5f02\u8d28\u65f6\u5931\u6548\u3002\u6700\u8fd1\u7684\u7814\u7a76\u8868\u660e\uff0c\u9002\u5f53\u7684\u9884\u5904\u7406\u6280\u672f\uff08\u5982\u6700\u8fd1\u90bb\u6df7\u5408\uff09\u53ef\u4ee5\u63d0\u9ad8\u5f02\u6784\u73af\u5883\u4e2d\u8fd9\u4e9b\u5bf9\u7b56\u7684\u8868\u73b0\u3002\u4f46\u662f\uff0c\u8fd9\u4e9b\u9884\u5904\u7406\u6280\u672f\u65e0\u6cd5\u4e0e\u5f15\u5165\u7684\u9690\u79c1\u4fdd\u62a4\u673a\u5236\u4e00\u8d77\u4f7f\u7528\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5305\u62ec\u51e0\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1. \u53ef\u9a8c\u8bc1\u79d8\u5bc6\u5171\u4eab\uff1b2. \u5b89\u5168\u805a\u5408\uff1b3. \u4e00\u4e2a\u91cf\u8eab\u5b9a\u505a\u7684\u5bf9\u79f0\u79c1\u6709\u4fe1\u606f\u68c0\u7d22\u65b9\u6848\u3002\u8fd9\u4e2a\u65b9\u6cd5\u65e8\u5728\u63d0\u4f9b\u4fe1\u606f\u7406\u8bba\u7ea7\u522b\u7684\u9690\u79c1\u4fdd\u969c\uff0c\u5e76\u4e14\u5728\u9762\u5bf9\u6570\u636e\u5f02\u6784\u6027\u65f6\u4e5f\u80fd\u62b5\u6297\u62dc\u5360\u5ead\u5f0f\u7684\u653b\u51fb\u3002\u6b64\u5916\uff0c\u8fd8\u7814\u7a76\u4e86\u5982\u4f55\u7ed3\u5408\u96f6\u9636\u4f30\u8ba1\u65b9\u6cd5\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff0c\u4f7f\u5f97\u79c1\u6709\u805a\u5408\u5728\u6700\u5148\u8fdb\u7684\u8054\u90a6\u5b66\u4e60\u4efb\u52a1\u4e2d\u53d8\u5f97\u53ef\u6269\u5c55\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6848\u5728\u5404\u79cd\u653b\u51fb\u4e0b\u8fdb\u884c\u4e86\u6709\u6548\u6027\u8bc4\u4f30\uff0c\u5e76\u663e\u793a\u51fa\u5176\u4f18\u4e8e\u5148\u524d\u5df2\u77e5\u7684\u6280\u672f\u3002\u5b83\u80fd\u591f\u5728\u4fdd\u8bc1\u4fe1\u606f\u8bba\u9690\u79c1\u7684\u540c\u65f6\uff0c\u4e5f\u80fd\u591f\u62b5\u5fa1\u62dc\u5360\u5ead\u5f0f\u653b\u51fb\uff0c\u5373\u4f7f\u662f\u5728\u6570\u636e\u5f02\u6784\u7684\u60c5\u51b5\u4e0b\u3002\u800c\u4e14\uff0c\u901a\u8fc7\u4e0e\u96f6\u9636\u4f30\u8ba1\u65b9\u6cd5\u76f8\u7ed3\u5408\uff0c\u8be5\u65b9\u6848\u8fd8\u51cf\u5c11\u4e86\u901a\u4fe1\u6210\u672c\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u79c1\u6709\u805a\u5408\u7684\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u80fd\u591f\u5728\u6570\u636e\u5f02\u6784\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4fe1\u606f\u8bba\u9690\u79c1\u548c\u62dc\u5360\u5ead\u5bb9\u9519\uff0c\u800c\u4e14\u8fd8\u80fd\u901a\u8fc7\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u6765\u63d0\u9ad8\u8054\u90a6\u5b66\u4e60\u4e2d\u79c1\u6709\u805a\u5408\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2506.09114", "pdf": "https://arxiv.org/pdf/2506.09114", "abs": "https://arxiv.org/abs/2506.09114", "authors": ["Jialin Chen", "Ziyu Zhao", "Gaukhar Nurbek", "Aosong Feng", "Ali Maatouk", "Leandros Tassiulas", "Yifeng Gao", "Rex Ying"], "title": "TRACE: Grounding Time Series in Context for Multimodal Embedding and Retrieval", "categories": ["cs.LG"], "comment": null, "summary": "The ubiquity of dynamic data in domains such as weather, healthcare, and\nenergy underscores a growing need for effective interpretation and retrieval of\ntime-series data. These data are inherently tied to domain-specific contexts,\nsuch as clinical notes or weather narratives, making cross-modal retrieval\nessential not only for downstream tasks but also for developing robust\ntime-series foundation models by retrieval-augmented generation (RAG). Despite\nthe increasing demand, time-series retrieval remains largely underexplored.\nExisting methods often lack semantic grounding, struggle to align heterogeneous\nmodalities, and have limited capacity for handling multi-channel signals. To\naddress this gap, we propose TRACE, a generic multimodal retriever that grounds\ntime-series embeddings in aligned textual context. TRACE enables fine-grained\nchannel-level alignment and employs hard negative mining to facilitate\nsemantically meaningful retrieval. It supports flexible cross-modal retrieval\nmodes, including Text-to-Timeseries and Timeseries-to-Text, effectively linking\nlinguistic descriptions with complex temporal patterns. By retrieving\nsemantically relevant pairs, TRACE enriches downstream models with informative\ncontext, leading to improved predictive accuracy and interpretability. Beyond a\nstatic retrieval engine, TRACE also serves as a powerful standalone encoder,\nwith lightweight task-specific tuning that refines context-aware\nrepresentations while maintaining strong cross-modal alignment. These\nrepresentations achieve state-of-the-art performance on downstream forecasting\nand classification tasks. Extensive experiments across multiple domains\nhighlight its dual utility, as both an effective encoder for downstream\napplications and a general-purpose retriever to enhance time-series models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTRACE\u7684\u901a\u7528\u591a\u6a21\u6001\u68c0\u7d22\u5668\uff0c\u5b83\u80fd\u591f\u5c06\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u5d4c\u5165\u5230\u5bf9\u9f50\u7684\u6587\u672c\u4e0a\u4e0b\u6587\u4e2d\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u7684\u901a\u9053\u7ea7\u5bf9\u9f50\u548c\u8bed\u4e49\u6709\u610f\u4e49\u7684\u68c0\u7d22\uff0c\u5e76\u80fd\u5728\u591a\u4e2a\u9886\u57df\u4e2d\u4f5c\u4e3a\u4e0b\u6e38\u5e94\u7528\u7684\u6709\u6548\u7f16\u7801\u5668\u4ee5\u53ca\u589e\u5f3a\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u7684\u4e00\u822c\u68c0\u7d22\u5668\u3002", "motivation": "\u7531\u4e8e\u5929\u6c14\u3001\u533b\u7597\u4fdd\u5065\u548c\u80fd\u6e90\u7b49\u9886\u57df\u52a8\u6001\u6570\u636e\u7684\u666e\u904d\u5b58\u5728\uff0c\u5bf9\u4e8e\u6709\u6548\u89e3\u91ca\u548c\u68c0\u7d22\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\u3002\u8fd9\u4e9b\u6570\u636e\u4e0e\u7279\u5b9a\u9886\u57df\u7684\u4e0a\u4e0b\u6587\u7d27\u5bc6\u76f8\u5173\uff0c\u4f8b\u5982\u4e34\u5e8a\u7b14\u8bb0\u6216\u5929\u6c14\u53d9\u8ff0\uff0c\u4f7f\u5f97\u8de8\u6a21\u6001\u68c0\u7d22\u4e0d\u4ec5\u5bf9\u4e0b\u6e38\u4efb\u52a1\u81f3\u5173\u91cd\u8981\uff0c\u800c\u4e14\u5bf9\u4e8e\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5f00\u53d1\u7a33\u5065\u7684\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u4e5f\u662f\u5fc5\u8981\u7684\u3002\u7136\u800c\uff0c\u5c3d\u7ba1\u9700\u6c42\u589e\u52a0\uff0c\u65f6\u95f4\u5e8f\u5217\u68c0\u7d22\u4ecd\u7136\u5f88\u5927\u7a0b\u5ea6\u4e0a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u5f80\u5f80\u7f3a\u4e4f\u8bed\u4e49\u57fa\u7840\uff0c\u96be\u4ee5\u5bf9\u9f50\u5f02\u6784\u6a21\u6001\uff0c\u5e76\u4e14\u5904\u7406\u591a\u901a\u9053\u4fe1\u53f7\u7684\u80fd\u529b\u6709\u9650\u3002", "method": "\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u5dee\u8ddd\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86TRACE\uff0c\u4e00\u79cd\u80fd\u591f\u5728\u5bf9\u9f50\u7684\u6587\u672c\u4e0a\u4e0b\u6587\u4e2d\u56fa\u5b9a\u65f6\u95f4\u5e8f\u5217\u5d4c\u5165\u7684\u901a\u7528\u591a\u6a21\u6001\u68c0\u7d22\u5668\u3002TRACE\u652f\u6301\u7ec6\u7c92\u5ea6\u7684\u901a\u9053\u7ea7\u522b\u5bf9\u9f50\uff0c\u5e76\u4f7f\u7528\u786c\u8d1f\u4f8b\u6316\u6398\u6765\u4fc3\u8fdb\u8bed\u4e49\u4e0a\u6709\u610f\u4e49\u7684\u68c0\u7d22\u3002\u5b83\u652f\u6301\u7075\u6d3b\u7684\u8de8\u6a21\u6001\u68c0\u7d22\u6a21\u5f0f\uff0c\u5305\u62ec\u6587\u672c\u5230\u65f6\u95f4\u5e8f\u5217\u548c\u65f6\u95f4\u5e8f\u5217\u5230\u6587\u672c\uff0c\u6709\u6548\u5730\u5c06\u8bed\u8a00\u63cf\u8ff0\u4e0e\u590d\u6742\u7684\u65f6\u95f4\u6a21\u5f0f\u8054\u7cfb\u8d77\u6765\u3002", "result": "\u901a\u8fc7\u68c0\u7d22\u8bed\u4e49\u76f8\u5173\u7684\u914d\u5bf9\uff0cTRACE\u4e3a\u4e0b\u6e38\u6a21\u578b\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u4fe1\u606f\u4e0a\u4e0b\u6587\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u9664\u4e86\u4f5c\u4e3a\u4e00\u4e2a\u9759\u6001\u68c0\u7d22\u5f15\u64ce\u5916\uff0cTRACE\u8fd8\u5145\u5f53\u4e00\u4e2a\u5f3a\u5927\u7684\u72ec\u7acb\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u5bf9\u7279\u5b9a\u4efb\u52a1\u8fdb\u884c\u8f7b\u91cf\u7ea7\u8c03\u6574\u6765\u5b8c\u5584\u4e0a\u4e0b\u6587\u611f\u77e5\u8868\u793a\uff0c\u540c\u65f6\u4fdd\u6301\u5f3a\u5927\u7684\u8de8\u6a21\u6001\u5bf9\u9f50\u3002\u8fd9\u4e9b\u8868\u73b0\u5728\u4e0b\u6e38\u9884\u6d4b\u548c\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\u4e86TRACE\u5728\u4e0d\u540c\u9886\u57df\u7684\u53cc\u91cd\u6548\u7528\uff0c\u65e2\u4f5c\u4e3a\u4e0b\u6e38\u5e94\u7528\u7684\u6709\u6548\u7f16\u7801\u5668\uff0c\u53c8\u4f5c\u4e3a\u4e00\u822c\u7528\u9014\u7684\u68c0\u7d22\u5668\u6765\u589e\u5f3a\u65f6\u95f4\u5e8f\u5217\u6a21\u578b\u3002"}}
{"id": "2506.09887", "pdf": "https://arxiv.org/pdf/2506.09887", "abs": "https://arxiv.org/abs/2506.09887", "authors": ["Nirmit Joshi", "Hugo Koubbi", "Theodor Misiakiewicz", "Nathan Srebro"], "title": "Learning single-index models via harmonic decomposition", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": "80 pages", "summary": "We study the problem of learning single-index models, where the label $y \\in\n\\mathbb{R}$ depends on the input $\\boldsymbol{x} \\in \\mathbb{R}^d$ only through\nan unknown one-dimensional projection $\\langle\n\\boldsymbol{w}_*,\\boldsymbol{x}\\rangle$. Prior work has shown that under\nGaussian inputs, the statistical and computational complexity of recovering\n$\\boldsymbol{w}_*$ is governed by the Hermite expansion of the link function.\nIn this paper, we propose a new perspective: we argue that \"spherical\nharmonics\" -- rather than \"Hermite polynomials\" -- provide the natural basis\nfor this problem, as they capture its intrinsic \"rotational symmetry\". Building\non this insight, we characterize the complexity of learning single-index models\nunder arbitrary spherically symmetric input distributions. We introduce two\nfamilies of estimators -- based on tensor unfolding and online SGD -- that\nrespectively achieve either optimal sample complexity or optimal runtime, and\nargue that estimators achieving both may not exist in general. When specialized\nto Gaussian inputs, our theory not only recovers and clarifies existing results\nbut also reveals new phenomena that had previously been overlooked.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5355\u6307\u6570\u6a21\u578b\u7684\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u51fa\u7403\u8c10\u51fd\u6570\u4f5c\u4e3a\u81ea\u7136\u57fa\u5e95\u6bd4Hermite\u591a\u9879\u5f0f\u66f4\u9002\u5408\u5904\u7406\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u4e14\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e86\u4e24\u79cd\u4f30\u8ba1\u5668\uff0c\u5206\u522b\u5728\u6837\u672c\u590d\u6742\u5ea6\u6216\u8fd0\u884c\u65f6\u95f4\u4e0a\u8fbe\u5230\u6700\u4f18\u3002", "motivation": "\u5148\u524d\u7684\u5de5\u4f5c\u8868\u660e\uff0c\u5728\u9ad8\u65af\u8f93\u5165\u4e0b\uff0c\u6062\u590d\u6743\u91cd\u5411\u91cf\u7684\u7edf\u8ba1\u548c\u8ba1\u7b97\u590d\u6742\u6027\u7531\u94fe\u63a5\u51fd\u6570\u7684Hermite\u5c55\u5f00\u51b3\u5b9a\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u89c2\u70b9\uff1a\u8ba4\u4e3a\u2018\u7403\u8c10\u51fd\u6570\u2019\u800c\u975e\u2018Hermite\u591a\u9879\u5f0f\u2019\u662f\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u7684\u81ea\u7136\u57fa\u5e95\uff0c\u56e0\u4e3a\u5b83\u4eec\u6355\u6349\u5230\u4e86\u95ee\u9898\u56fa\u6709\u7684\u2018\u65cb\u8f6c\u5bf9\u79f0\u6027\u2019\u3002", "method": "\u4f5c\u8005\u4eec\u57fa\u4e8e\u7403\u8c10\u51fd\u6570\u7684\u89c2\u70b9\uff0c\u63cf\u8ff0\u4e86\u5728\u4efb\u610f\u7403\u9762\u5bf9\u79f0\u8f93\u5165\u5206\u5e03\u4e0b\u5b66\u4e60\u5355\u6307\u6570\u6a21\u578b\u7684\u590d\u6742\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u4e24\u7c7b\u4f30\u8ba1\u5668\u2014\u2014\u57fa\u4e8e\u5f20\u91cf\u5c55\u5f00\u548c\u5728\u7ebfSGD\u2014\u2014\u5b83\u4eec\u5206\u522b\u5b9e\u73b0\u4e86\u6700\u4f18\u6837\u672c\u590d\u6742\u5ea6\u6216\u6700\u4f18\u8fd0\u884c\u65f6\u95f4\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5f53\u5e94\u7528\u4e8e\u9ad8\u65af\u8f93\u5165\u65f6\uff0c\u4e0d\u4ec5\u6062\u590d\u5e76\u6f84\u6e05\u4e86\u73b0\u6709\u7684\u7ed3\u679c\uff0c\u800c\u4e14\u8fd8\u63ed\u793a\u4e86\u4ee5\u524d\u88ab\u5ffd\u89c6\u7684\u65b0\u73b0\u8c61\u3002\u540c\u65f6\uff0c\u6587\u7ae0\u6307\u51fa\u53ef\u80fd\u4e0d\u5b58\u5728\u540c\u65f6\u5b9e\u73b0\u4e24\u8005\u6700\u4f18\u7684\u4e00\u822c\u4f30\u8ba1\u5668\u3002", "conclusion": "\u901a\u8fc7\u91c7\u7528\u7403\u8c10\u51fd\u6570\u4f5c\u4e3a\u5206\u6790\u5de5\u5177\uff0c\u8be5\u7814\u7a76\u4e3a\u5355\u6307\u6570\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u6df1\u5165\u7684\u7406\u89e3\uff0c\u5e76\u4e14\u5bf9\u4e8e\u4e0d\u540c\u7c7b\u578b\u7684\u8f93\u5165\u5206\u5e03\u90fd\u6709\u6548\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u5c55\u793a\u4e86\u9488\u5bf9\u6b64\u7c7b\u95ee\u9898\u8bbe\u8ba1\u7684\u4f30\u8ba1\u5668\u7684\u6027\u80fd\u754c\u9650\u3002"}}
{"id": "2506.09928", "pdf": "https://arxiv.org/pdf/2506.09928", "abs": "https://arxiv.org/abs/2506.09928", "authors": ["Ruixuan Xu", "Xiangxiang Weng"], "title": "Bayesian Probabilistic Matrix Factorization", "categories": ["cs.LG", "stat.ML"], "comment": "11 pages, 4 figures", "summary": "Matrix factorization is a widely used technique in recommendation systems.\nProbabilistic Matrix Factorization (PMF) [1] extends traditional matrix\nfactorization by incorporating probability distributions over latent factors,\nallowing for uncertainty quantification. However, computing the posterior\ndistribution is intractable due to the high-dimensional integral. To address\nthis, we employ two Bayesian inference methods: Markov Chain Monte Carlo (MCMC)\n[2] and Variational Inference (VI) [3] to approximate the posterior. We\nevaluate their performance on MovieLens dataset and compare their convergence\nspeed, predictive accuracy, and computational efficiency. Experimental results\ndemonstrate that VI offers faster convergence, while MCMC provides more\naccurate posterior estimates.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u6982\u7387\u77e9\u9635\u5206\u89e3\u4e2d\u7684\u8d1d\u53f6\u65af\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u6bd4\u8f83\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b(MCMC)\u548c\u53d8\u5206\u63a8\u7406(VI)\u4e24\u79cd\u8fd1\u4f3c\u540e\u9a8c\u5206\u5e03\u7684\u65b9\u6cd5\uff0c\u8bc4\u4f30\u4e86\u5b83\u4eec\u5728MovieLens\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aVI\u6536\u655b\u901f\u5ea6\u66f4\u5feb\uff0c\u800cMCMC\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u540e\u9a8c\u4f30\u8ba1\u3002", "motivation": "\u4f20\u7edf\u7684\u77e9\u9635\u5206\u89e3\u6280\u672f\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u4f46\u6982\u7387\u77e9\u9635\u5206\u89e3(PMF)\u901a\u8fc7\u5f15\u5165\u6f5c\u5728\u56e0\u7d20\u7684\u6982\u7387\u5206\u5e03\u6765\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\u3002\u7136\u800c\uff0c\u7531\u4e8e\u9ad8\u7ef4\u79ef\u5206\u7684\u5b58\u5728\uff0c\u8ba1\u7b97\u540e\u9a8c\u5206\u5e03\u53d8\u5f97\u4e0d\u53ef\u884c\u3002", "method": "\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u91c7\u7528\u4e86\u4e24\u79cd\u8d1d\u53f6\u65af\u63a8\u7406\u65b9\u6cd5\uff1a\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\uff08MCMC\uff09\u548c\u53d8\u5206\u63a8\u7406\uff08VI\uff09\uff0c\u7528\u4ee5\u8fd1\u4f3c\u540e\u9a8c\u5206\u5e03\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u53d8\u5206\u63a8\u7406\uff08VI\uff09\u5177\u6709\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\uff0c\u800c\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\uff08MCMC\uff09\u5219\u63d0\u4f9b\u4e86\u66f4\u52a0\u7cbe\u786e\u7684\u540e\u9a8c\u4f30\u8ba1\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u5728\u5904\u7406\u6982\u7387\u77e9\u9635\u5206\u89e3\u65f6\uff0c\u53d8\u5206\u63a8\u7406\u80fd\u591f\u63d0\u4f9b\u5feb\u901f\u6536\u655b\u7684\u4f18\u52bf\uff0c\u800c\u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\u5219\u5728\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u66f4\u597d\u3002\u8fd9\u610f\u5473\u7740\u6839\u636e\u5b9e\u9645\u9700\u6c42\u9009\u62e9\u5408\u9002\u7684\u65b9\u6cd5\u662f\u81f3\u5173\u91cd\u8981\u7684\u3002"}}
{"id": "2506.09171", "pdf": "https://arxiv.org/pdf/2506.09171", "abs": "https://arxiv.org/abs/2506.09171", "authors": ["Samuel Holt", "Max Ruiz Luyten", "Thomas Pouplin", "Mihaela van der Schaar"], "title": "Improving LLM Agent Planning with In-Context Learning via Atomic Fact Augmentation and Lookahead Search", "categories": ["cs.LG", "cs.AI", "cs.CL", "68T07, 68T20, 68T30, 93E35", "I.2.6; I.2.7; I.2.8"], "comment": "9-page main paper, 1 figure. Accepted for an Oral presentation at the\n  First Workshop on Computer Use Agents (ICML 2025), Vancouver, Canada", "summary": "Large Language Models (LLMs) are increasingly capable but often require\nsignificant guidance or extensive interaction history to perform effectively in\ncomplex, interactive environments. Existing methods may struggle with adapting\nto new information or efficiently utilizing past experiences for multi-step\nreasoning without fine-tuning. We introduce a novel LLM agent framework that\nenhances planning capabilities through in-context learning, facilitated by\natomic fact augmentation and a recursive lookahead search. Our agent learns to\nextract task-critical ``atomic facts'' from its interaction trajectories. These\nfacts dynamically augment the prompts provided to LLM-based components\nresponsible for action proposal, latent world model simulation, and state-value\nestimation. Planning is performed via a depth-limited lookahead search, where\nthe LLM simulates potential trajectories and evaluates their outcomes, guided\nby the accumulated facts and interaction history. This approach allows the\nagent to improve its understanding and decision-making online, leveraging its\nexperience to refine its behavior without weight updates. We provide a\ntheoretical motivation linking performance to the quality of fact-based\nabstraction and LLM simulation accuracy. Empirically, our agent demonstrates\nimproved performance and adaptability on challenging interactive tasks,\nachieving more optimal behavior as it accumulates experience, showcased in\ntasks such as TextFrozenLake and ALFWorld.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u539f\u5b50\u4e8b\u5b9e\u589e\u5f3a\u548c\u9012\u5f52\u524d\u77bb\u641c\u7d22\u6765\u63d0\u9ad8\u89c4\u5212\u80fd\u529b\u3002\u8be5\u6846\u67b6\u5141\u8bb8\u4ee3\u7406\u5728\u7ebf\u6539\u8fdb\u5176\u7406\u89e3\u548c\u51b3\u7b56\uff0c\u65e0\u9700\u6743\u91cd\u66f4\u65b0\u5373\u53ef\u5229\u7528\u7ecf\u9a8c\u4f18\u5316\u884c\u4e3a\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8fd9\u79cd\u4ee3\u7406\u5728\u590d\u6742\u7684\u4ea4\u4e92\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u6027\u80fd\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u5728\u590d\u6742\u4ea4\u4e92\u73af\u5883\u4e2d\u9700\u8981\u5927\u91cf\u7684\u6307\u5bfc\u6216\u5e7f\u6cdb\u7684\u4ea4\u4e92\u5386\u53f2\u624d\u80fd\u6709\u6548\u6267\u884c\uff0c\u5e76\u4e14\u96be\u4ee5\u9002\u5e94\u65b0\u4fe1\u606f\u6216\u5728\u6ca1\u6709\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u9ad8\u6548\u5730\u5229\u7528\u8fc7\u53bb\u7684\u7ecf\u9a8c\u8fdb\u884c\u591a\u6b65\u63a8\u7406\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684LLM\u4ee3\u7406\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u589e\u5f3a\u89c4\u5212\u80fd\u529b\uff0c\u540c\u65f6\u501f\u52a9\u4e8e\u539f\u5b50\u4e8b\u5b9e\u7684\u589e\u5f3a\u548c\u9012\u56de\u524d\u77bb\u641c\u7d22\u3002\u4ee3\u7406\u4ece\u4e92\u52a8\u8f68\u8ff9\u4e2d\u5b66\u4e60\u63d0\u53d6\u4efb\u52a1\u5173\u952e\u7684\u201c\u539f\u5b50\u4e8b\u5b9e\u201d\uff0c\u8fd9\u4e9b\u4e8b\u5b9e\u52a8\u6001\u5730\u589e\u5f3a\u4e86\u63d0\u4f9b\u7ed9\u57fa\u4e8eLLM\u7ec4\u4ef6\u7684\u63d0\u793a\u3002\u89c4\u5212\u662f\u901a\u8fc7\u6df1\u5ea6\u9650\u5236\u7684\u524d\u77bb\u641c\u7d22\u5b8c\u6210\u7684\uff0c\u5176\u4e2dLLM\u6a21\u62df\u6f5c\u5728\u7684\u8f68\u8ff9\u5e76\u8bc4\u4f30\u7ed3\u679c\uff0c\u5728\u7d2f\u79ef\u7684\u4e8b\u5b9e\u548c\u4ea4\u4e92\u5386\u53f2\u6307\u5bfc\u4e0b\u8fdb\u884c\u3002", "result": "\u5b9e\u8bc1\u4e0a\uff0c\u4ee3\u7406\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u4ea4\u4e92\u4efb\u52a1\u4e2d\u5c55\u793a\u4e86\u6539\u8fdb\u7684\u8868\u73b0\u548c\u9002\u5e94\u6027\uff0c\u968f\u7740\u7ecf\u9a8c\u79ef\u7d2f\uff0c\u5b83\u5728\u8bf8\u5982TextFrozenLake\u548cALFWorld\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e86\u66f4\u4f18\u7684\u884c\u4e3a\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684LLM\u4ee3\u7406\u6846\u67b6\u80fd\u591f\u5728\u7ebf\u6539\u8fdb\u5176\u7406\u89e3\u4e0e\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5229\u7528\u7ecf\u5386\u6539\u5584\u884c\u4e3a\u800c\u4e0d\u9700\u8981\u6743\u91cd\u66f4\u65b0\u3002\u7406\u8bba\u52a8\u673a\u5c06\u6027\u80fd\u8054\u7cfb\u5230\u57fa\u4e8e\u4e8b\u5b9e\u62bd\u8c61\u7684\u8d28\u91cf\u548cLLM\u6a21\u62df\u51c6\u786e\u6027\u4e0a\u3002"}}
{"id": "2506.09940", "pdf": "https://arxiv.org/pdf/2506.09940", "abs": "https://arxiv.org/abs/2506.09940", "authors": ["Jiachen Hu", "Rui Ai", "Han Zhong", "Xiaoyu Chen", "Liwei Wang", "Zhaoran Wang", "Zhuoran Yang"], "title": "The Sample Complexity of Online Strategic Decision Making with Information Asymmetry and Knowledge Transportability", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "Accepted at ICML 2025", "summary": "Information asymmetry is a pervasive feature of multi-agent systems,\nespecially evident in economics and social sciences. In these settings, agents\ntailor their actions based on private information to maximize their rewards.\nThese strategic behaviors often introduce complexities due to confounding\nvariables. Simultaneously, knowledge transportability poses another significant\nchallenge, arising from the difficulties of conducting experiments in target\nenvironments. It requires transferring knowledge from environments where\nempirical data is more readily available. Against these backdrops, this paper\nexplores a fundamental question in online learning: Can we employ non-i.i.d.\nactions to learn about confounders even when requiring knowledge transfer? We\npresent a sample-efficient algorithm designed to accurately identify system\ndynamics under information asymmetry and to navigate the challenges of\nknowledge transfer effectively in reinforcement learning, framed within an\nonline strategic interaction model. Our method provably achieves learning of an\n$\\epsilon$-optimal policy with a tight sample complexity of $O(1/\\epsilon^2)$.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u4fe1\u606f\u4e0d\u5bf9\u79f0\u548c\u77e5\u8bc6\u8fc1\u79fb\u7684\u80cc\u666f\u4e0b\uff0c\u5982\u4f55\u901a\u8fc7\u975e\u72ec\u7acb\u540c\u5206\u5e03\u52a8\u4f5c\u6765\u5b66\u4e60\u6df7\u6dc6\u53d8\u91cf\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u5728\u5728\u7ebf\u7b56\u7565\u4ea4\u4e92\u6a21\u578b\u4e2d\u4ee5\u7d27\u81f4\u7684\u6837\u672c\u590d\u6742\u5ea6$O(1/\\epsilon^2)$\u5b66\u4e60\u5230$\\epsilon$-\u6700\u4f18\u7b56\u7565\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u4fe1\u606f\u4e0d\u5bf9\u79f0\u95ee\u9898\uff0c\u4ee5\u53ca\u7531\u6b64\u5e26\u6765\u7684\u7531\u4e8e\u6df7\u6742\u53d8\u91cf\u5bfc\u81f4\u7684\u590d\u6742\u6027\u3002\u540c\u65f6\uff0c\u8003\u8651\u5230\u5c06\u77e5\u8bc6\u4ece\u5bb9\u6613\u83b7\u53d6\u6570\u636e\u7684\u73af\u5883\u8f6c\u79fb\u5230\u76ee\u6807\u73af\u5883\u4e2d\u53bb\u7684\u77e5\u8bc6\u53ef\u79fb\u690d\u6027\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6837\u672c\u9ad8\u6548\u7684\u7b97\u6cd5\uff0c\u65e8\u5728\u51c6\u786e\u5730\u8bc6\u522b\u4fe1\u606f\u4e0d\u5bf9\u79f0\u4e0b\u7684\u7cfb\u7edf\u52a8\u6001\uff0c\u5e76\u6709\u6548\u5730\u5904\u7406\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u77e5\u8bc6\u8f6c\u79fb\u96be\u9898\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u4ee5$O(1/\\epsilon^2)$\u7684\u7d27\u51d1\u6837\u672c\u590d\u6742\u5ea6\u5b66\u4e60\u5230$\\epsilon$-\u6700\u4f18\u7b56\u7565\u3002", "conclusion": "\u901a\u8fc7\u975e\u72ec\u7acb\u540c\u5206\u5e03\u7684\u52a8\u4f5c\uff0c\u53ef\u4ee5\u5728\u9700\u8981\u77e5\u8bc6\u8fc1\u79fb\u7684\u60c5\u51b5\u4e0b\u4e86\u89e3\u6df7\u6742\u56e0\u7d20\uff0c\u5e76\u4e14\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u5728\u7ebf\u7b56\u7565\u4e92\u52a8\u6a21\u578b\u4e0b\u5bf9\u4e8e\u5b66\u4e60$\\epsilon$-\u6700\u4f18\u7b56\u7565\u5177\u6709\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2506.09172", "pdf": "https://arxiv.org/pdf/2506.09172", "abs": "https://arxiv.org/abs/2506.09172", "authors": ["Pranav Guruprasad", "Yangyue Wang", "Harshvardhan Sikka"], "title": "MultiNet: An Open-Source Software Toolkit \\& Benchmark Suite for the Evaluation and Adaptation of Multimodal Action Models", "categories": ["cs.LG", "cs.CV"], "comment": "ICML CodeML Workshop, 13 Pages, 6 Figures, 2 Tables", "summary": "Recent innovations in multimodal action models represent a promising\ndirection for developing general-purpose agentic systems, combining visual\nunderstanding, language comprehension, and action generation. We introduce\nMultiNet - a novel, fully open-source benchmark and surrounding software\necosystem designed to rigorously evaluate and adapt models across vision,\nlanguage, and action domains. We establish standardized evaluation protocols\nfor assessing vision-language models (VLMs) and vision-language-action models\n(VLAs), and provide open source software to download relevant data, models, and\nevaluations. Additionally, we provide a composite dataset with over 1.3\ntrillion tokens of image captioning, visual question answering, commonsense\nreasoning, robotic control, digital game-play, simulated\nlocomotion/manipulation, and many more tasks. The MultiNet benchmark,\nframework, toolkit, and evaluation harness have been used in downstream\nresearch on the limitations of VLA generalization.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aMultiNet\u7684\u5f00\u6e90\u57fa\u51c6\u548c\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\uff0c\u7528\u4e8e\u4e25\u683c\u8bc4\u4f30\u548c\u8c03\u6574\u8de8\u89c6\u89c9\u3001\u8bed\u8a00\u53ca\u52a8\u4f5c\u9886\u57df\u7684\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5305\u542b\u8d85\u8fc71.3\u4e07\u4ebf\u4e2a\u6807\u8bb0\u7684\u7efc\u5408\u6570\u636e\u96c6\u3002", "motivation": "\u4e3a\u4e86\u63a8\u52a8\u591a\u6a21\u6001\u884c\u52a8\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u6574\u5408\u89c6\u89c9\u7406\u89e3\u3001\u8bed\u8a00\u7406\u89e3\u548c\u52a8\u4f5c\u751f\u6210\uff0c\u4f5c\u8005\u4eec\u5f00\u53d1\u4e86MultiNet\u6765\u4f5c\u4e3a\u6807\u51c6\u5316\u8bc4\u4f30\u534f\u8bae\u4ee5\u53ca\u76f8\u5173\u6570\u636e\u3001\u6a21\u578b\u548c\u8bc4\u4f30\u5de5\u5177\u7684\u5f00\u6e90\u5e73\u53f0\u3002", "method": "\u521b\u5efa\u4e86MultiNet\uff0c\u4e00\u4e2a\u5f00\u6e90\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u8f6f\u4ef6\u751f\u6001\u7cfb\u7edf\uff0c\u5b83\u5305\u62ec\u4e86\u5bf9\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u548c\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\uff08VLAs\uff09\u7684\u6807\u51c6\u8bc4\u4f30\u534f\u8bae\uff0c\u5e76\u63d0\u4f9b\u4e86\u6db5\u76d6\u591a\u79cd\u4efb\u52a1\u7684\u5927\u89c4\u6a21\u7efc\u5408\u6570\u636e\u96c6\u3002", "result": "MultiNet\u63d0\u4f9b\u4e86\u4e00\u6574\u5957\u5de5\u5177\u5305\u548c\u8bc4\u4f30\u6846\u67b6\uff0c\u5df2\u88ab\u540e\u7eed\u7814\u7a76\u7528\u6765\u63a2\u8ba8VLA\u6cdb\u5316\u80fd\u529b\u7684\u5c40\u9650\u6027\u3002", "conclusion": "MultiNet\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u5de5\u5177\uff0c\u7528\u4ee5\u8bc4\u4f30\u548c\u53d1\u5c55\u80fd\u591f\u5904\u7406\u89c6\u89c9\u3001\u8bed\u8a00\u548c\u52a8\u4f5c\u4efb\u52a1\u7684\u901a\u7528\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2506.09173", "pdf": "https://arxiv.org/pdf/2506.09173", "abs": "https://arxiv.org/abs/2506.09173", "authors": ["Michael Cooper", "Rohan Wadhawan", "John Michael Giorgi", "Chenhao Tan", "Davis Liang"], "title": "The Curious Language Model: Strategic Test-Time Information Acquisition", "categories": ["cs.LG", "cs.CL"], "comment": "39 pages", "summary": "Decision-makers often possess insufficient information to render a confident\ndecision. In these cases, the decision-maker can often undertake actions to\nacquire the necessary information about the problem at hand, e.g., by\nconsulting knowledgeable authorities or by conducting experiments. Importantly,\ndifferent levers of information acquisition come with different costs, posing\nthe challenge of selecting the actions that are both informative and\ncost-effective. In this work, we propose CuriosiTree, a heuristic-based,\ntest-time policy for zero-shot information acquisition in large language models\n(LLMs). CuriosiTree employs a greedy tree search to estimate the expected\ninformation gain of each action and strategically chooses actions based on a\nbalance of anticipated information gain and associated cost. Empirical\nvalidation in a clinical diagnosis simulation shows that CuriosiTree enables\ncost-effective integration of heterogenous sources of information, and\noutperforms baseline action selection strategies in selecting action sequences\nthat enable accurate diagnosis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCuriosiTree\u7684\u7b56\u7565\uff0c\u5b83\u662f\u4e00\u79cd\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u6d4b\u8bd5\u65f6\u7b56\u7565\uff0c\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u96f6\u6837\u672c\u4fe1\u606f\u83b7\u53d6\u3002\u8be5\u7b56\u7565\u901a\u8fc7\u8d2a\u5a6a\u6811\u641c\u7d22\u6765\u4f30\u8ba1\u6bcf\u4e2a\u884c\u52a8\u7684\u9884\u671f\u4fe1\u606f\u589e\u76ca\uff0c\u5e76\u6839\u636e\u9884\u671f\u7684\u4fe1\u606f\u589e\u76ca\u548c\u76f8\u5173\u6210\u672c\u4e4b\u95f4\u7684\u5e73\u8861\u6765\u9009\u62e9\u884c\u52a8\u3002\u5728\u4e34\u5e8a\u8bca\u65ad\u6a21\u62df\u4e2d\u7684\u5b9e\u8bc1\u9a8c\u8bc1\u8868\u660e\uff0cCuriosiTree\u80fd\u591f\u6709\u6548\u5730\u6574\u5408\u5f02\u6784\u4fe1\u606f\u6e90\uff0c\u5e76\u4e14\u6bd4\u57fa\u7ebf\u884c\u52a8\u9009\u62e9\u7b56\u7565\u66f4\u80fd\u5728\u9009\u62e9\u6709\u52a9\u4e8e\u51c6\u786e\u8bca\u65ad\u7684\u884c\u4e3a\u5e8f\u5217\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u51b3\u7b56\u8005\u5f80\u5f80\u7f3a\u4e4f\u505a\u51fa\u81ea\u4fe1\u51b3\u7b56\u6240\u9700\u7684\u4fe1\u606f\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c\u51b3\u7b56\u8005\u53ef\u4ee5\u901a\u8fc7\u54a8\u8be2\u77e5\u8bc6\u6e0a\u535a\u7684\u6743\u5a01\u4eba\u58eb\u6216\u8fdb\u884c\u5b9e\u9a8c\u6765\u83b7\u53d6\u5fc5\u8981\u7684\u4fe1\u606f\u3002\u7136\u800c\uff0c\u4e0d\u540c\u7684\u4fe1\u606f\u83b7\u53d6\u624b\u6bb5\u6709\u4e0d\u540c\u7684\u6210\u672c\uff0c\u8fd9\u5c31\u63d0\u51fa\u4e86\u4e00\u4e2a\u6311\u6218\uff0c\u5373\u5982\u4f55\u9009\u62e9\u65e2\u5177\u4fe1\u606f\u4ef7\u503c\u53c8\u7ecf\u6d4e\u5b9e\u60e0\u7684\u884c\u52a8\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCuriosiTree\u7684\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u6d4b\u8bd5\u65f6\u7b56\u7565\uff0c\u9002\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u7684\u96f6\u6837\u672c\u4fe1\u606f\u83b7\u53d6\u3002CuriosiTree\u5229\u7528\u8d2a\u5a6a\u6811\u641c\u7d22\u6765\u4f30\u7b97\u6bcf\u4e2a\u52a8\u4f5c\u7684\u9884\u671f\u4fe1\u606f\u6536\u76ca\uff0c\u5e76\u6839\u636e\u9884\u671f\u7684\u4fe1\u606f\u6536\u76ca\u4e0e\u5173\u8054\u6210\u672c\u4e4b\u95f4\u7684\u5e73\u8861\u6765\u6218\u7565\u6027\u5730\u9009\u62e9\u52a8\u4f5c\u3002", "result": "\u5728\u4e34\u5e8a\u8bca\u65ad\u6a21\u62df\u4e2d\u7684\u5b9e\u8bc1\u7814\u7a76\u8868\u660e\uff0cCuriosiTree \u80fd\u591f\u5b9e\u73b0\u5f02\u6784\u4fe1\u606f\u6765\u6e90\u7684\u6210\u672c\u6548\u76ca\u6574\u5408\uff0c\u5e76\u4e14\u5728\u9009\u62e9\u80fd\u4fc3\u6210\u51c6\u786e\u8bca\u65ad\u7684\u52a8\u4f5c\u5e8f\u5217\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u52a8\u4f5c\u9009\u62e9\u7b56\u7565\u3002", "conclusion": "CuriosiTree \u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u8fdb\u884c\u96f6\u6837\u672c\u4fe1\u606f\u83b7\u53d6\uff0c\u5b83\u80fd\u591f\u5728\u4fdd\u6301\u6210\u672c\u6548\u76ca\u7684\u540c\u65f6\uff0c\u4fc3\u8fdb\u4fe1\u606f\u7684\u9ad8\u6548\u6536\u96c6\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u5c55\u793a\u4e86\u5728\u7279\u5b9a\u9886\u57df\u5982\u4e34\u5e8a\u8bca\u65ad\u4e2d\uff0c\u5bf9\u4e8e\u63d0\u9ad8\u51b3\u7b56\u8d28\u91cf\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.09174", "pdf": "https://arxiv.org/pdf/2506.09174", "abs": "https://arxiv.org/abs/2506.09174", "authors": ["Chenheng Xu", "Dan Wu", "Yixin Zhu", "Ying Nian Wu"], "title": "Multivariate Long-term Time Series Forecasting with Fourier Neural Filter", "categories": ["cs.LG"], "comment": null, "summary": "Multivariate long-term time series forecasting has been suffering from the\nchallenge of capturing both temporal dependencies within variables and spatial\ncorrelations across variables simultaneously. Current approaches predominantly\nrepurpose backbones from natural language processing or computer vision (e.g.,\nTransformers), which fail to adequately address the unique properties of time\nseries (e.g., periodicity). The research community lacks a dedicated backbone\nwith temporal-specific inductive biases, instead relying on domain-agnostic\nbackbones supplemented with auxiliary techniques (e.g., signal decomposition).\nWe introduce FNF as the backbone and DBD as the architecture to provide\nexcellent learning capabilities and optimal learning pathways for\nspatio-temporal modeling, respectively. Our theoretical analysis proves that\nFNF unifies local time-domain and global frequency-domain information\nprocessing within a single backbone that extends naturally to spatial modeling,\nwhile information bottleneck theory demonstrates that DBD provides superior\ngradient flow and representation capacity compared to existing unified or\nsequential architectures. Our empirical evaluation across 11 public benchmark\ndatasets spanning five domains (energy, meteorology, transportation,\nenvironment, and nature) confirms state-of-the-art performance with consistent\nhyperparameter settings. Notably, our approach achieves these results without\nany auxiliary techniques, suggesting that properly designed neural\narchitectures can capture the inherent properties of time series, potentially\ntransforming time series modeling in scientific and industrial applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9aa8\u5e72\u7f51\u7edcFNF\u548c\u67b6\u6784DBD\uff0c\u4e13\u4e3a\u65f6\u7a7a\u5efa\u6a21\u8bbe\u8ba1\uff0c\u80fd\u591f\u7edf\u4e00\u5904\u7406\u65f6\u57df\u548c\u9891\u57df\u4fe1\u606f\uff0c\u5e76\u901a\u8fc711\u4e2a\u516c\u5f00\u57fa\u51c6\u6570\u636e\u96c6\u7684\u5b9e\u8bc1\u8bc4\u4f30\u5c55\u793a\u4e86\u5176\u5728\u591a\u53d8\u91cf\u957f\u671f\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u4e3b\u8981\u4ece\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6216\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\u501f\u7528\u9aa8\u5e72\u7f51\u7edc\uff0c\u672a\u80fd\u5145\u5206\u89e3\u51b3\u65f6\u95f4\u5e8f\u5217\u7684\u72ec\u7279\u5c5e\u6027\uff08\u5982\u5468\u671f\u6027\uff09\uff0c\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u65f6\u95f4\u5e8f\u5217\u7279\u6027\u7684\u9aa8\u5e72\u7f51\u7edc\u3002", "method": "\u5f15\u5165FNF\u4f5c\u4e3a\u9aa8\u5e72\u7f51\u7edc\u4ee5\u53caDBD\u4f5c\u4e3a\u67b6\u6784\uff0c\u5176\u4e2dFNF\u80fd\u591f\u5728\u5355\u4e00\u9aa8\u5e72\u5185\u7edf\u4e00\u5c40\u90e8\u65f6\u57df\u548c\u5168\u5c40\u9891\u57df\u7684\u4fe1\u606f\u5904\u7406\uff0c\u5e76\u4e14\u81ea\u7136\u5730\u6269\u5c55\u5230\u7a7a\u95f4\u5efa\u6a21\uff1b\u800cDBD\u6839\u636e\u4fe1\u606f\u74f6\u9888\u7406\u8bba\u63d0\u4f9b\u4e86\u4f18\u4e8e\u73b0\u6709\u7edf\u4e00\u6216\u987a\u5e8f\u67b6\u6784\u7684\u68af\u5ea6\u6d41\u548c\u8868\u793a\u80fd\u529b\u3002", "result": "\u5728\u8de8\u8d8a\u4e94\u4e2a\u9886\u57df\u768411\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u4e00\u81f4\u7684\u8d85\u53c2\u6570\u8bbe\u7f6e\u4e0b\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u9002\u5f53\u8bbe\u8ba1\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u53ef\u4ee5\u6355\u6349\u65f6\u95f4\u5e8f\u5217\u7684\u5185\u5728\u7279\u6027\uff0c\u65e0\u9700\u4f9d\u8d56\u8f85\u52a9\u6280\u672f\u5373\u53ef\u5b9e\u73b0\u5353\u8d8a\u8868\u73b0\uff0c\u8fd9\u53ef\u80fd\u5bf9\u79d1\u5b66\u548c\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u65f6\u95f4\u5e8f\u5217\u5efa\u6a21\u4ea7\u751f\u53d8\u9769\u5f71\u54cd\u3002"}}
{"id": "2506.09183", "pdf": "https://arxiv.org/pdf/2506.09183", "abs": "https://arxiv.org/abs/2506.09183", "authors": ["Mingkang Wu", "Devin White", "Evelyn Rose", "Vernon Lawhern", "Nicholas R Waytowich", "Yongcan Cao"], "title": "Multi-Task Reward Learning from Human Ratings", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted to the workshop on Models of Human Feedback for AI Alignment\n  at the 42nd International Conference on Machine Learning", "summary": "Reinforcement learning from human feeback (RLHF) has become a key factor in\naligning model behavior with users' goals. However, while humans integrate\nmultiple strategies when making decisions, current RLHF approaches often\nsimplify this process by modeling human reasoning through isolated tasks such\nas classification or regression. In this paper, we propose a novel\nreinforcement learning (RL) method that mimics human decision-making by jointly\nconsidering multiple tasks. Specifically, we leverage human ratings in\nreward-free environments to infer a reward function, introducing learnable\nweights that balance the contributions of both classification and regression\nmodels. This design captures the inherent uncertainty in human decision-making\nand allows the model to adaptively emphasize different strategies. We conduct\nseveral experiments using synthetic human ratings to validate the effectiveness\nof the proposed approach. Results show that our method consistently outperforms\nexisting rating-based RL methods, and in some cases, even surpasses traditional\nRL approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u540c\u65f6\u8003\u8651\u591a\u79cd\u4efb\u52a1\u6765\u6a21\u4eff\u4eba\u7c7b\u7684\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5e76\u5229\u7528\u65e0\u5956\u52b1\u73af\u5883\u4e2d\u7684\u8bc4\u5206\u63a8\u65ad\u51fa\u4e00\u4e2a\u5956\u52b1\u51fd\u6570\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u8bc4\u5206\u7684RL\u65b9\u6cd5\uff0c\u6709\u65f6\u751a\u81f3\u8d85\u8fc7\u4e86\u4f20\u7edf\u7684RL\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684\u4ece\u4eba\u7c7b\u53cd\u9988\u4e2d\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff08RLHF\uff09\u7684\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u5b64\u7acb\u7684\u4efb\u52a1\uff08\u5982\u5206\u7c7b\u6216\u56de\u5f52\uff09\u6765\u7b80\u5316\u4eba\u7c7b\u63a8\u7406\u7684\u8fc7\u7a0b\uff0c\u800c\u5b9e\u9645\u4e0a\u4eba\u7c7b\u5728\u505a\u51b3\u7b56\u65f6\u4f1a\u6574\u5408\u591a\u79cd\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u5f3a\u5316\u5f3a\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b83\u80fd\u591f\u901a\u8fc7\u7ed3\u5408\u591a\u4e2a\u4efb\u52a1\u6765\u6a21\u62df\u4eba\u7c7b\u51b3\u7b56\u8fc7\u7a0b\u3002\u8be5\u65b9\u6cd5\u5728\u6ca1\u6709\u660e\u786e\u5956\u52b1\u7684\u60c5\u51b5\u4e0b\u4f7f\u7528\u4eba\u7c7b\u8bc4\u5206\u6765\u63a8\u6d4b\u5956\u52b1\u51fd\u6570\uff0c\u5e76\u5f15\u5165\u4e86\u53ef\u5b66\u4e60\u6743\u91cd\u4ee5\u5e73\u8861\u5206\u7c7b\u548c\u56de\u5f52\u6a21\u578b\u7684\u8d21\u732e\u3002", "result": "\u901a\u8fc7\u5408\u6210\u7684\u4eba\u7c7b\u8bc4\u5206\u6570\u636e\u8fdb\u884c\u4e86\u51e0\u9879\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u4e8e\u8bc4\u5206\u7684RL\u65b9\u6cd5\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8fd8\u8d85\u8fc7\u4e86\u4f20\u7edfRL\u65b9\u6cd5\u7684\u8868\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684\u8fd9\u79cd\u65b0\u65b9\u6cd5\u80fd\u591f\u66f4\u597d\u5730\u6355\u6349\u4eba\u7c7b\u51b3\u7b56\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5e76\u4e14\u5141\u8bb8\u6a21\u578b\u81ea\u9002\u5e94\u5730\u5f3a\u8c03\u4e0d\u540c\u7684\u7b56\u7565\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u4e0e\u7528\u6237\u7684\u76ee\u6807\u4fdd\u6301\u4e00\u81f4\u3002"}}
{"id": "2506.09199", "pdf": "https://arxiv.org/pdf/2506.09199", "abs": "https://arxiv.org/abs/2506.09199", "authors": ["Hariharan Ramesh", "Jyotikrishna Dass"], "title": "FLoRIST: Singular Value Thresholding for Efficient and Accurate Federated Fine-Tuning of Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "21 pages, 12 figures", "summary": "Integrating Low-Rank Adaptation (LoRA) into federated learning offers a\npromising solution for parameter-efficient fine-tuning of Large Language Models\n(LLMs) without sharing local data. However, several methods designed for\nfederated LoRA present significant challenges in balancing communication\nefficiency, model accuracy, and computational cost, particularly among\nheterogeneous clients. These methods either rely on simplistic averaging of\nlocal adapters, which introduces aggregation noise, require transmitting large\nstacked local adapters, leading to poor communication efficiency, or\nnecessitate reconstructing memory-dense global weight-update matrix and\nperforming computationally expensive decomposition to design client-specific\nlow-rank adapters. In this work, we propose FLoRIST, a federated fine-tuning\nframework that achieves mathematically accurate aggregation without incurring\nhigh communication or computational overhead. Instead of constructing the full\nglobal weight-update matrix at the server, FLoRIST employs an efficient\ndecomposition pipeline by performing singular value decomposition on stacked\nlocal adapters separately. This approach operates within a compact intermediate\nspace to represent the accumulated information from local LoRAs. We introduce\ntunable singular value thresholding for server-side optimal rank selection to\nconstruct a pair of global low-rank adapters shared by all clients. Extensive\nempirical evaluations across multiple datasets and LLMs demonstrate that\nFLoRIST consistently strikes the best balance between superior communication\nefficiency and competitive performance in both homogeneous and heterogeneous\nsetups.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86FLoRIST\uff0c\u4e00\u79cd\u8054\u90a6\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u670d\u52a1\u5668\u4e0a\u5bf9\u5806\u53e0\u7684\u672c\u5730\u9002\u914d\u5668\u5206\u522b\u8fdb\u884c\u5947\u5f02\u503c\u5206\u89e3\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u9ad8\u6602\u901a\u4fe1\u6216\u8ba1\u7b97\u5f00\u9500\u7684\u6570\u5b66\u7cbe\u786e\u805a\u5408\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u4f4e\u79e9\u9002\u5e94\u65b9\u6cd5\u5728\u5e73\u8861\u901a\u4fe1\u6548\u7387\u3001\u6a21\u578b\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6210\u672c\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5f02\u6784\u5ba2\u6237\u7aef\u4e4b\u95f4\u3002", "method": "FLoRIST\u5229\u7528\u4e00\u4e2a\u9ad8\u6548\u7684\u5206\u89e3\u6d41\u7a0b\uff0c\u5728\u7d27\u51d1\u7684\u4e2d\u95f4\u7a7a\u95f4\u5185\u8868\u793a\u4ece\u672c\u5730LoRA\u79ef\u7d2f\u7684\u4fe1\u606f\uff0c\u5e76\u5f15\u5165\u4e86\u53ef\u8c03\u8282\u7684\u5947\u5f02\u503c\u9608\u503c\u6765\u9009\u62e9\u6700\u4f18\u79e9\uff0c\u4ee5\u6784\u5efa\u4e00\u5bf9\u5168\u5c40\u4f4e\u79e9\u9002\u914d\u5668\u4f9b\u6240\u6709\u5ba2\u6237\u7aef\u5171\u4eab\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u65e0\u8bba\u662f\u5728\u540c\u6784\u8fd8\u662f\u5f02\u6784\u73af\u5883\u4e0b\uff0cFLoRIST\u90fd\u80fd\u5728\u4f18\u8d8a\u7684\u901a\u4fe1\u6548\u7387\u548c\u7ade\u4e89\u6027\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u6700\u4f73\u5e73\u8861\u3002", "conclusion": "FLoRIST\u4e3a\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u89e3\u51b3\u65b9\u6848\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u901a\u4fe1\u6548\u7387\u548c\u6a21\u578b\u51c6\u786e\u6027\u3002"}}
{"id": "2506.09193", "pdf": "https://arxiv.org/pdf/2506.09193", "abs": "https://arxiv.org/abs/2506.09193", "authors": ["Yilin Zhuang", "Karthik Duraisamy"], "title": "LaDCast: A Latent Diffusion Model for Medium-Range Ensemble Weather Forecasting", "categories": ["cs.LG"], "comment": null, "summary": "Accurate probabilistic weather forecasting demands both high accuracy and\nefficient uncertainty quantification, challenges that overburden both ensemble\nnumerical weather prediction (NWP) and recent machine-learning methods. We\nintroduce LaDCast, the first global latent-diffusion framework for medium-range\nensemble forecasting, which generates hourly ensemble forecasts entirely in a\nlearned latent space. An autoencoder compresses high-dimensional ERA5\nreanalysis fields into a compact representation, and a transformer-based\ndiffusion model produces sequential latent updates with arbitrary hour\ninitialization. The model incorporates Geometric Rotary Position Embedding\n(GeoRoPE) to account for the Earth's spherical geometry, a dual-stream\nattention mechanism for efficient conditioning, and sinusoidal temporal\nembeddings to capture seasonal patterns. LaDCast achieves deterministic and\nprobabilistic skill close to that of the European Centre for Medium-Range\nForecast IFS-ENS, without any explicit perturbations. Notably, LaDCast\ndemonstrates superior performance in tracking rare extreme events such as\ncyclones, capturing their trajectories more accurately than established models.\nBy operating in latent space, LaDCast reduces storage and compute by orders of\nmagnitude, demonstrating a practical path toward forecasting at kilometer-scale\nresolution in real time. We open-source our code and models and provide the\ntraining and evaluation pipelines at: https://github.com/tonyzyl/ladcast.", "AI": {"tldr": "LaDCast\u662f\u4e00\u4e2a\u57fa\u4e8e\u6f5c\u5728\u6269\u6563\u7684\u5168\u7403\u4e2d\u7a0b\u96c6\u5408\u9884\u62a5\u6846\u67b6\uff0c\u5b83\u5728\u5b66\u4e60\u5230\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u751f\u6210\u9010\u5c0f\u65f6\u96c6\u5408\u9884\u62a5\u3002\u901a\u8fc7\u81ea\u7f16\u7801\u5668\u548c\u57fa\u4e8e\u53d8\u6362\u5668\u7684\u6269\u6563\u6a21\u578b\uff0cLaDCast\u80fd\u591f\u9ad8\u6548\u5730\u5904\u7406\u9ad8\u7ef4ERA5\u518d\u5206\u6790\u6570\u636e\uff0c\u5e76\u5f15\u5165\u4e86\u5730\u7403\u7403\u9762\u51e0\u4f55\u7684\u8003\u8651\u3001\u53cc\u6d41\u6ce8\u610f\u529b\u673a\u5236\u4ee5\u53ca\u5b63\u8282\u6027\u6a21\u5f0f\u6355\u6349\u7b49\u7279\u6027\u3002\u76f8\u6bd4\u73b0\u6709\u7684\u6570\u503c\u5929\u6c14\u9884\u62a5\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0cLaDCast\u5728\u8ffd\u8e2a\u7f55\u89c1\u6781\u7aef\u4e8b\u4ef6\u5982\u98d3\u98ce\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u540c\u65f6\u5927\u5e45\u5ea6\u51cf\u5c11\u4e86\u5b58\u50a8\u4e0e\u8ba1\u7b97\u9700\u6c42\u3002", "motivation": "\u51c6\u786e\u7684\u6982\u7387\u5929\u6c14\u9884\u62a5\u9700\u8981\u9ad8\u5ea6\u7cbe\u786e\u6027\u548c\u6709\u6548\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u8fd9\u5bf9\u73b0\u6709\u7684\u96c6\u5408\u6570\u503c\u5929\u6c14\u9884\u6d4b\uff08NWP\uff09\u548c\u8fd1\u671f\u7684\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u6784\u6210\u4e86\u6311\u6218\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u96be\u9898\uff0c\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86LaDCast\uff0c\u4e00\u79cd\u65b0\u7684\u5168\u7403\u6f5c\u5728\u6269\u6563\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u9ad8\u4e2d\u7a0b\u5929\u6c14\u9884\u62a5\u7684\u8d28\u91cf\u3002", "method": "LaDCast\u5229\u7528\u81ea\u7f16\u7801\u5668\u5c06\u9ad8\u7ef4\u5ea6\u7684ERA5\u518d\u5206\u6790\u573a\u538b\u7f29\u4e3a\u7d27\u51d1\u8868\u793a\u5f62\u5f0f\uff0c\u5728\u6b64\u4e4b\u540e\uff0c\u4e00\u4e2a\u57fa\u4e8e\u53d8\u6362\u5668\u7684\u6269\u6563\u6a21\u578b\u4f1a\u5728\u4efb\u610f\u5c0f\u65f6\u521d\u59cb\u5316\u4e0b\u4ea7\u751f\u5e8f\u5217\u5316\u7684\u6f5c\u5728\u66f4\u65b0\u3002\u8be5\u6a21\u578b\u8fd8\u7ed3\u5408\u4e86\u51e0\u4f55\u65cb\u8f6c\u4f4d\u7f6e\u5d4c\u5165\uff08GeoRoPE\uff09\u3001\u53cc\u6d41\u6ce8\u610f\u529b\u673a\u5236\u53ca\u6b63\u5f26\u65f6\u95f4\u5d4c\u5165\u6765\u5206\u522b\u89e3\u51b3\u5730\u7403\u7403\u5f62\u51e0\u4f55\u3001\u6761\u4ef6\u6548\u7387\u4ee5\u53ca\u5b63\u8282\u6027\u6a21\u5f0f\u6355\u83b7\u7684\u95ee\u9898\u3002", "result": "LaDCast\u5728\u786e\u5b9a\u6027\u548c\u6982\u7387\u6027\u6280\u80fd\u4e0a\u63a5\u8fd1\u6b27\u6d32\u4e2d\u671f\u5929\u6c14\u9884\u62a5\u4e2d\u5fc3IFS-ENS\u7684\u8868\u73b0\uff0c\u800c\u4e14\u5728\u6ca1\u6709\u4f7f\u7528\u4efb\u4f55\u663e\u5f0f\u6270\u52a8\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u4e8e\u50cf\u98d3\u98ce\u8fd9\u6837\u7684\u7f55\u89c1\u6781\u7aef\u4e8b\u4ef6\u7684\u8f68\u8ff9\u8ddf\u8e2a\u663e\u793a\u51fa\u66f4\u597d\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fd0\u4f5c\uff0cLaDCast\u6781\u5927\u5730\u51cf\u5c11\u4e86\u6240\u9700\u7684\u5b58\u50a8\u7a7a\u95f4\u548c\u8ba1\u7b97\u91cf\uff0c\u8fd9\u4f7f\u5f97\u5b9e\u65f6\u5343\u7c73\u7ea7\u5206\u8fa8\u7387\u7684\u5929\u6c14\u9884\u62a5\u53d8\u5f97\u53ef\u884c\u3002", "conclusion": "LaDCast\u5c55\u793a\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u548c\u5b58\u50a8\u8981\u6c42\uff0c\u4e3a\u5b9e\u73b0\u9ad8\u5206\u8fa8\u7387\u5b9e\u65f6\u5929\u6c14\u9884\u62a5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2506.09202", "pdf": "https://arxiv.org/pdf/2506.09202", "abs": "https://arxiv.org/abs/2506.09202", "authors": ["Hao Hu", "Xinqi Wang", "Simon Shaolei Du"], "title": "Policy-Based Trajectory Clustering in Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce a novel task of clustering trajectories from offline\nreinforcement learning (RL) datasets, where each cluster center represents the\npolicy that generated its trajectories. By leveraging the connection between\nthe KL-divergence of offline trajectory distributions and a mixture of\npolicy-induced distributions, we formulate a natural clustering objective. To\nsolve this, we propose Policy-Guided K-means (PG-Kmeans) and Centroid-Attracted\nAutoencoder (CAAE). PG-Kmeans iteratively trains behavior cloning (BC) policies\nand assigns trajectories based on policy generation probabilities, while CAAE\nresembles the VQ-VAE framework by guiding the latent representations of\ntrajectories toward the vicinity of specific codebook entries to achieve\nclustering. Theoretically, we prove the finite-step convergence of PG-Kmeans\nand identify a key challenge in offline trajectory clustering: the inherent\nambiguity of optimal solutions due to policy-induced conflicts, which can\nresult in multiple equally valid but structurally distinct clusterings.\nExperimentally, we validate our methods on the widely used D4RL dataset and\ncustom GridWorld environments. Our results show that both PG-Kmeans and CAAE\neffectively partition trajectories into meaningful clusters. They offer a\npromising framework for policy-based trajectory clustering, with broad\napplications in offline RL and beyond.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4efb\u52a1\uff0c\u5373\u4ece\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6570\u636e\u96c6\u4e2d\u5bf9\u8f68\u8ff9\u8fdb\u884c\u805a\u7c7b\uff0c\u5176\u4e2d\u6bcf\u4e2a\u7c07\u4e2d\u5fc3\u4ee3\u8868\u751f\u6210\u5176\u8f68\u8ff9\u7684\u7b56\u7565\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u7b56\u7565\u5f15\u5bfc\u7684K-\u5747\u503c\uff08PG-Kmeans\uff09\u548c\u4e2d\u5fc3\u5438\u5f15\u81ea\u52a8\u7f16\u7801\u5668\uff08CAAE\uff09\u3002\u7406\u8bba\u8bc1\u660e\u4e86PG-Kmeans\u5728\u6709\u9650\u6b65\u6570\u5185\u7684\u6536\u655b\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u79bb\u7ebf\u8f68\u8ff9\u805a\u7c7b\u7684\u5173\u952e\u6311\u6218\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e24\u79cd\u65b9\u6cd5\u90fd\u80fd\u6709\u6548\u5730\u5c06\u8f68\u8ff9\u5212\u5206\u4e3a\u6709\u610f\u4e49\u7684\u7c07\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u901a\u8fc7\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u6570\u636e\u96c6\u4e2d\u7684\u8f68\u8ff9\u805a\u7c7b\u6765\u8bc6\u522b\u51fa\u751f\u6210\u8fd9\u4e9b\u8f68\u8ff9\u7684\u4e0d\u540c\u7b56\u7565\u3002\u8fd9\u6837\u53ef\u4ee5\u4e3a\u79bb\u7ebfRL\u53ca\u5176\u4ed6\u9886\u57df\u63d0\u4f9b\u4e00\u79cd\u57fa\u4e8e\u7b56\u7565\u7684\u8f68\u8ff9\u805a\u7c7b\u6846\u67b6\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u7b97\u6cd5\uff1aPolicy-Guided K-means (PG-Kmeans) \u548c Centroid-Attracted Autoencoder (CAAE)\u3002\u524d\u8005\u901a\u8fc7\u8fed\u4ee3\u8bad\u7ec3\u884c\u4e3a\u514b\u9686\u7b56\u7565\u5e76\u6839\u636e\u7b56\u7565\u751f\u6210\u6982\u7387\u5206\u914d\u8f68\u8ff9\uff1b\u540e\u8005\u7c7b\u4f3c\u4e8eVQ-VAE\u6846\u67b6\uff0c\u901a\u8fc7\u6307\u5bfc\u8f68\u8ff9\u7684\u6f5c\u5728\u8868\u793a\u5411\u7279\u5b9a\u7801\u672c\u6761\u76ee\u9644\u8fd1\u79fb\u52a8\u4ee5\u5b9e\u73b0\u805a\u7c7b\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5305\u62ec\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684D4RL\u6570\u636e\u96c6\u548c\u81ea\u5b9a\u4e49GridWorld\u73af\u5883\u4e0a\u7684\u6d4b\u8bd5\u3002\u7ed3\u679c\u663e\u793aPG-Kmeans\u548cCAAE\u90fd\u80fd\u591f\u6709\u6548\u5730\u533a\u5206\u8f68\u8ff9\u5e76\u5f62\u6210\u6709\u610f\u4e49\u7684\u805a\u7c7b\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u4e24\u79cd\u6709\u6548\u7684\u8f68\u8ff9\u805a\u7c7b\u65b9\u6cd5\uff0c\u8fd8\u63ed\u793a\u4e86\u79bb\u7ebf\u8f68\u8ff9\u805a\u7c7b\u4e2d\u56e0\u7b56\u7565\u51b2\u7a81\u5bfc\u81f4\u7684\u6700\u4f73\u89e3\u6a21\u7cca\u6027\u7684\u5173\u952e\u95ee\u9898\u3002\u6b64\u5916\uff0c\u5b83\u4e3a\u57fa\u4e8e\u7b56\u7565\u7684\u8f68\u8ff9\u805a\u7c7b\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.09215", "pdf": "https://arxiv.org/pdf/2506.09215", "abs": "https://arxiv.org/abs/2506.09215", "authors": ["Greyson Brothers"], "title": "Robust Noise Attenuation via Adaptive Pooling of Transformer Outputs", "categories": ["cs.LG", "cs.AI", "68T07 (Primary), 68P30, 68T45 (Secondary)", "E.4; I.2.6; I.2.10"], "comment": "[ICML 2025 Spotlight Poster] To be published in the Forty-Second\n  International Conference on Machine Learning (ICML) Proceedings", "summary": "We investigate the design of pooling methods used to summarize the outputs of\ntransformer embedding models, primarily motivated by reinforcement learning and\nvision applications. This work considers problems where a subset of the input\nvectors contains requisite information for a downstream task (signal) while the\nrest are distractors (noise). By framing pooling as vector quantization with\nthe goal of minimizing signal loss, we demonstrate that the standard methods\nused to aggregate transformer outputs, AvgPool, MaxPool, and ClsToken, are\nvulnerable to performance collapse as the signal-to-noise ratio (SNR) of inputs\nfluctuates. We then show that an attention-based adaptive pooling method can\napproximate the signal-optimal vector quantizer within derived error bounds for\nany SNR. Our theoretical results are first validated by supervised experiments\non a synthetic dataset designed to isolate the SNR problem, then generalized to\nstandard relational reasoning, multi-agent reinforcement learning, and vision\nbenchmarks with noisy observations, where transformers with adaptive pooling\ndisplay superior robustness across tasks.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u7528\u4e8e\u603b\u7ed3Transformer\u5d4c\u5165\u6a21\u578b\u8f93\u51fa\u7684\u6c60\u5316\u65b9\u6cd5\u7684\u8bbe\u8ba1\uff0c\u53d1\u73b0\u4f20\u7edf\u7684AvgPool\u3001MaxPool\u548cClsToken\u65b9\u6cd5\u5728\u4fe1\u566a\u6bd4\u6ce2\u52a8\u65f6\u5bb9\u6613\u6027\u80fd\u5d29\u6e83\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u81ea\u9002\u5e94\u6c60\u5316\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u5728\u4efb\u4f55\u4fe1\u566a\u6bd4\u4e0b\u8fd1\u4f3c\u4fe1\u53f7\u6700\u4f18\u5411\u91cf\u91cf\u5316\u5668\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u6e90\u4e8e\u5f3a\u5316\u5b66\u4e60\u548c\u89c6\u89c9\u5e94\u7528\u9886\u57df\uff0c\u65e8\u5728\u89e3\u51b3\u8f93\u5165\u5411\u91cf\u4e2d\u53ea\u6709\u4e00\u90e8\u5206\u5bf9\u4e0b\u6e38\u4efb\u52a1\u6709\u7528\uff08\u4fe1\u53f7\uff09\uff0c\u800c\u5176\u4f59\u662f\u5e72\u6270\uff08\u566a\u58f0\uff09\u7684\u95ee\u9898\u3002", "method": "\u5c06\u6c60\u5316\u89c6\u4e3a\u77e2\u91cf\u91cf\u5316\uff0c\u76ee\u7684\u662f\u6700\u5c0f\u5316\u4fe1\u53f7\u635f\u5931\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\u4e86\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u81ea\u9002\u5e94\u6c60\u5316\u65b9\u6cd5\u53ef\u4ee5\u5728\u4efb\u4f55\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u903c\u8fd1\u4fe1\u53f7\u6700\u4f18\u7684\u77e2\u91cf\u91cf\u5316\u5668\uff0c\u5e76\u4e14\u7ed9\u51fa\u4e86\u8bef\u5dee\u8303\u56f4\u3002", "result": "\u76d1\u7763\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u7ed3\u679c\uff0c\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u9694\u79bb\u4e86\u4fe1\u566a\u6bd4\u95ee\u9898\uff0c\u7136\u540e\u63a8\u5e7f\u5230\u5177\u6709\u566a\u58f0\u89c2\u6d4b\u7684\u6807\u51c6\u5173\u7cfb\u63a8\u7406\u3001\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u548c\u89c6\u89c9\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5176\u4e2d\u5e26\u6709\u81ea\u9002\u5e94\u6c60\u5316\u7684\u53d8\u538b\u5668\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u81ea\u9002\u5e94\u6c60\u5316\u65b9\u6cd5\u76f8\u8f83\u4e8e\u4f20\u7edf\u65b9\u6cd5\u5982AvgPool\u3001MaxPool\u548cClsToken\u80fd\u591f\u66f4\u597d\u5730\u5904\u7406\u8f93\u5165\u4e2d\u7684\u4fe1\u566a\u6bd4\u53d8\u5316\uff0c\u4ece\u800c\u4e3a\u4e0b\u6e38\u4efb\u52a1\u63d0\u4f9b\u66f4\u7a33\u5065\u7684\u8868\u73b0\u3002"}}
{"id": "2506.09200", "pdf": "https://arxiv.org/pdf/2506.09200", "abs": "https://arxiv.org/abs/2506.09200", "authors": ["Val Andrei Fajardo", "David B. Emerson", "Amandeep Singh", "Veronica Chatrath", "Marcelo Lotif", "Ravi Theja", "Alex Cheung", "Izuki Matsubi"], "title": "FedRAG: A Framework for Fine-Tuning Retrieval-Augmented Generation Systems", "categories": ["cs.LG", "cs.CL"], "comment": "9 pages, 4 figures, 2 tables. Accepted for the CODEML Workshop at\n  ICML 2025. Framework code available at\n  https://github.com/VectorInstitute/fed-rag", "summary": "Retrieval-augmented generation (RAG) systems have been shown to be effective\nin addressing many of the drawbacks of relying solely on the parametric memory\nof large language models. Recent work has demonstrated that RAG systems can be\nimproved via fine-tuning of their retriever and generator models. In this work,\nwe introduce FedRAG, a framework for fine-tuning RAG systems across centralized\nand federated architectures. FedRAG supports state-of-the-art fine-tuning\nmethods, offering a simple and intuitive interface and a seamless conversion\nfrom centralized to federated training tasks. FedRAG is also deeply integrated\nwith the modern RAG ecosystem, filling a critical gap in available tools.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86FedRAG\uff0c\u4e00\u4e2a\u7528\u4e8e\u5728\u96c6\u4e2d\u5f0f\u548c\u8054\u90a6\u5f0f\u67b6\u6784\u4e2d\u5fae\u8c03\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7cfb\u7edf\u7684\u6846\u67b6\uff0c\u652f\u6301\u6700\u524d\u6cbf\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u5e76\u4e0e\u73b0\u4ee3RAG\u751f\u6001\u7cfb\u7edf\u6df1\u5ea6\u6574\u5408\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u6539\u8fdb\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\uff0c\u901a\u8fc7\u5fae\u8c03\u68c0\u7d22\u5668\u548c\u751f\u6210\u5668\u6a21\u578b\u6765\u63d0\u9ad8\u5176\u6027\u80fd\uff0c\u5e76\u4e14\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u4ee5\u8de8\u8d8a\u96c6\u4e2d\u5f0f\u548c\u8054\u90a6\u5f0f\u67b6\u6784\u8fdb\u884c\u5fae\u8c03\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFedRAG\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u652f\u6301\u6700\u5148\u8fdb\u7684\u5fae\u8c03\u6280\u672f\uff0c\u5e76\u4e14\u5141\u8bb8\u4ece\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u5e73\u6ed1\u8fc7\u6e21\u5230\u8054\u90a6\u5f0f\u8bad\u7ec3\u4efb\u52a1\u3002", "result": "FedRAG\u4e3aRAG\u7cfb\u7edf\u7684\u5f00\u53d1\u63d0\u4f9b\u4e86\u7b80\u5355\u76f4\u89c2\u7684\u63a5\u53e3\uff0c\u5e76\u4e14\u5f88\u597d\u5730\u878d\u5165\u4e86\u5f53\u524d\u7684RAG\u751f\u6001\u7cfb\u7edf\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u5de5\u5177\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u7a7a\u767d\u3002", "conclusion": "FedRAG\u4f5c\u4e3a\u65b0\u7684\u6846\u67b6\uff0c\u589e\u5f3a\u4e86RAG\u7cfb\u7edf\u7684\u80fd\u529b\uff0c\u4f7f\u5f97\u65e0\u8bba\u662f\u96c6\u4e2d\u5f0f\u8fd8\u662f\u8054\u90a6\u5f0f\u7684\u8bbe\u7f6e\u4e0b\u90fd\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u7684\u6a21\u578b\u5fae\u8c03\u3002"}}
{"id": "2506.09276", "pdf": "https://arxiv.org/pdf/2506.09276", "abs": "https://arxiv.org/abs/2506.09276", "authors": ["Lorenzo Steccanella", "Joshua B. Evans", "\u00d6zg\u00fcr \u015eim\u015fek", "Anders Jonsson"], "title": "Learning The Minimum Action Distance", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper presents a state representation framework for Markov decision\nprocesses (MDPs) that can be learned solely from state trajectories, requiring\nneither reward signals nor the actions executed by the agent. We propose\nlearning the minimum action distance (MAD), defined as the minimum number of\nactions required to transition between states, as a fundamental metric that\ncaptures the underlying structure of an environment. MAD naturally enables\ncritical downstream tasks such as goal-conditioned reinforcement learning and\nreward shaping by providing a dense, geometrically meaningful measure of\nprogress. Our self-supervised learning approach constructs an embedding space\nwhere the distances between embedded state pairs correspond to their MAD,\naccommodating both symmetric and asymmetric approximations. We evaluate the\nframework on a comprehensive suite of environments with known MAD values,\nencompassing both deterministic and stochastic dynamics, as well as discrete\nand continuous state spaces, and environments with noisy observations.\nEmpirical results demonstrate that the proposed approach not only efficiently\nlearns accurate MAD representations across these diverse settings but also\nsignificantly outperforms existing state representation methods in terms of\nrepresentation quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ec5\u4ece\u72b6\u6001\u8f68\u8ff9\u5b66\u4e60\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u7684\u72b6\u6001\u8868\u793a\u6846\u67b6\uff0c\u4e0d\u9700\u5956\u52b1\u4fe1\u53f7\u6216\u4ee3\u7406\u6267\u884c\u7684\u52a8\u4f5c\u3002\u901a\u8fc7\u5b66\u4e60\u6700\u5c0f\u52a8\u4f5c\u8ddd\u79bb\uff08MAD\uff09\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5bc6\u96c6\u4e14\u51e0\u4f55\u4e0a\u610f\u4e49\u660e\u786e\u7684\u8fdb\u5c55\u5ea6\u91cf\uff0c\u652f\u6301\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u79cd\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4f5c\u8005\u5e0c\u671b\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u72b6\u6001\u8868\u793a\u6846\u67b6\uff0c\u5b83\u80fd\u591f\u4ec5\u57fa\u4e8e\u72b6\u6001\u8f68\u8ff9\u6765\u5b66\u4e60\uff0c\u800c\u4e0d\u9700\u8981\u4f9d\u8d56\u4e8e\u5956\u52b1\u4fe1\u53f7\u6216\u5177\u4f53\u6267\u884c\u7684\u52a8\u4f5c\u3002\u8fd9\u6837\u7684\u6846\u67b6\u53ef\u4ee5\u4e3a\u73af\u5883\u63d0\u4f9b\u4e00\u4e2a\u57fa\u7840\u5ea6\u91cf\uff0c\u5e2e\u52a9\u5b9e\u73b0\u76ee\u6807\u6761\u4ef6\u4e0b\u7684\u5f3a\u5316\u5b66\u4e60\u548c\u5956\u52b1\u5851\u9020\u3002", "method": "\u63d0\u51fa\u4e86\u5b66\u4e60\u6700\u5c0f\u52a8\u4f5c\u8ddd\u79bb\uff08MAD\uff09\u7684\u65b9\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u8861\u91cf\u72b6\u6001\u4e4b\u95f4\u8f6c\u6362\u6240\u9700\u6700\u5c11\u52a8\u4f5c\u6570\u7684\u6307\u6807\u3002\u91c7\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u521b\u5efa\u4e00\u4e2a\u5d4c\u5165\u7a7a\u95f4\uff0c\u5728\u8be5\u7a7a\u95f4\u4e2d\u5d4c\u5165\u72b6\u6001\u5bf9\u4e4b\u95f4\u7684\u8ddd\u79bb\u5bf9\u5e94\u4e8e\u5b83\u4eec\u7684MAD\u503c\uff0c\u540c\u65f6\u652f\u6301\u5bf9\u79f0\u548c\u975e\u5bf9\u79f0\u8fd1\u4f3c\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5728\u5177\u6709\u786e\u5b9a\u6027\u548c\u968f\u673a\u52a8\u6001\u3001\u79bb\u6563\u548c\u8fde\u7eed\u72b6\u6001\u7a7a\u95f4\u4ee5\u53ca\u566a\u58f0\u89c2\u6d4b\u7684\u5404\u79cd\u73af\u5883\u4e2d\u6709\u6548\u5b66\u4e60\u51c6\u786e\u7684MAD\u8868\u793a\uff0c\u5e76\u4e14\u5728\u8868\u793a\u8d28\u91cf\u65b9\u9762\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u72b6\u6001\u8868\u793a\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eMAD\u7684\u5b66\u4e60\u6846\u67b6\u4e0d\u4ec5\u80fd\u591f\u6709\u6548\u5730\u4ece\u4e0d\u540c\u7684\u73af\u5883\u8bbe\u7f6e\u4e2d\u5b66\u4e60\u5230\u7cbe\u786e\u7684\u72b6\u6001\u8868\u793a\uff0c\u800c\u4e14\u76f8\u6bd4\u73b0\u6709\u7684\u72b6\u6001\u8868\u793a\u65b9\u6cd5\uff0c\u5b83\u5728\u8868\u793a\u8d28\u91cf\u4e0a\u6709\u4e86\u663e\u8457\u7684\u63d0\u5347\u3002"}}
{"id": "2506.09286", "pdf": "https://arxiv.org/pdf/2506.09286", "abs": "https://arxiv.org/abs/2506.09286", "authors": ["Mohammadsajad Abavisani", "Kseniya Solovyeva", "David Danks", "Vince Calhoun", "Sergey Plis"], "title": "Causal Graph Recovery in Neuroimaging through Answer Set Programming", "categories": ["cs.LG", "cs.AI", "stat.AP", "stat.ME"], "comment": null, "summary": "Learning graphical causal structures from time series data presents\nsignificant challenges, especially when the measurement frequency does not\nmatch the causal timescale of the system. This often leads to a set of equally\npossible underlying causal graphs due to information loss from sub-sampling\n(i.e., not observing all possible states of the system throughout time). Our\nresearch addresses this challenge by incorporating the effects of sub-sampling\nin the derivation of causal graphs, resulting in more accurate and intuitive\noutcomes. We use a constraint optimization approach, specifically answer set\nprogramming (ASP), to find the optimal set of answers. ASP not only identifies\nthe most probable underlying graph, but also provides an equivalence class of\npossible graphs for expert selection. In addition, using ASP allows us to\nleverage graph theory to further prune the set of possible solutions, yielding\na smaller, more accurate answer set significantly faster than traditional\napproaches. We validate our approach on both simulated data and empirical\nstructural brain connectivity, and demonstrate its superiority over established\nmethods in these experiments. We further show how our method can be used as a\nmeta-approach on top of established methods to obtain, on average, 12%\nimprovement in F1 score. In addition, we achieved state of the art results in\nterms of precision and recall of reconstructing causal graph from sub-sampled\ntime series data. Finally, our method shows robustness to varying degrees of\nsub-sampling on realistic simulations, whereas other methods perform worse for\nhigher rates of sub-sampling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u6b20\u91c7\u6837\u7684\u5f71\u54cd\u6765\u4ece\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u5b66\u4e60\u56fe\u5f62\u56e0\u679c\u7ed3\u6784\uff0c\u5e76\u4f7f\u7528\u7b54\u6848\u96c6\u7f16\u7a0b(ASP)\u4f18\u5316\u53ef\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u6a21\u62df\u548c\u5b9e\u9645\u8111\u8fde\u63a5\u6570\u636e\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u4e14\u5bf9\u4e8e\u4e0d\u540c\u6b20\u91c7\u6837\u7387\u5177\u6709\u9c81\u68d2\u6027\u3002", "motivation": "\u4ece\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u5b66\u4e60\u56fe\u5f62\u56e0\u679c\u7ed3\u6784\u65f6\u9047\u5230\u7684\u4e3b\u8981\u6311\u6218\u662f\u6d4b\u91cf\u9891\u7387\u4e0e\u7cfb\u7edf\u7684\u56e0\u679c\u65f6\u95f4\u5c3a\u5ea6\u4e0d\u5339\u914d\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\u5e76\u4ea7\u751f\u591a\u4e2a\u53ef\u80fd\u7684\u5e95\u5c42\u56e0\u679c\u56fe\u3002", "method": "\u7814\u7a76\u91c7\u7528\u7ea6\u675f\u4f18\u5316\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u7b54\u6848\u96c6\u7f16\u7a0b(ASP)\uff0c\u6765\u627e\u5230\u6700\u4f18\u89e3\u96c6\u5408\u3002ASP\u80fd\u591f\u8bc6\u522b\u6700\u6709\u53ef\u80fd\u7684\u5e95\u5c42\u56fe\uff0c\u5e76\u63d0\u4f9b\u4e00\u4e2a\u53ef\u80fd\u56fe\u7684\u7b49\u4ef7\u7c7b\u4f9b\u4e13\u5bb6\u9009\u62e9\u3002\u6b64\u5916\uff0c\u5229\u7528\u56fe\u8bba\u8fdb\u4e00\u6b65\u51cf\u5c11\u53ef\u80fd\u89e3\u7684\u96c6\u5408\uff0c\u4ece\u800c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u5feb\u5730\u5f97\u5230\u66f4\u5c0f\u3001\u66f4\u51c6\u786e\u7684\u7b54\u6848\u96c6\u5408\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u6a21\u62df\u6570\u636e\u548c\u7ecf\u9a8c\u7ed3\u6784\u8111\u8fde\u63a5\u4e0a\u7684\u9a8c\u8bc1\u663e\u793a\u4e86\u5176\u76f8\u5bf9\u4e8e\u5df2\u6709\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u5728\u8fd9\u4e9b\u5b9e\u9a8c\u4e2d\u5e73\u5747F1\u5206\u6570\u63d0\u9ad8\u4e8612%\u3002\u6b64\u5916\uff0c\u5728\u4ece\u6b20\u91c7\u6837\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u91cd\u5efa\u56e0\u679c\u56fe\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u4ece\u6b20\u91c7\u6837\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u4e2d\u91cd\u6784\u56e0\u679c\u56fe\u7684\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\uff0c\u800c\u4e14\u5728\u73b0\u5b9e\u6a21\u62df\u4e2d\u7684\u4e0d\u540c\u6b20\u91c7\u6837\u7a0b\u5ea6\u4e0b\u8868\u73b0\u51fa\u4e86\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.09207", "pdf": "https://arxiv.org/pdf/2506.09207", "abs": "https://arxiv.org/abs/2506.09207", "authors": ["William Anderson", "Kevin Chung", "Youngsoo Choi"], "title": "mLaSDI: Multi-stage latent space dynamics identification", "categories": ["cs.LG", "cs.NA", "math.NA"], "comment": null, "summary": "Determining accurate numerical solutions of partial differential equations\n(PDEs) is an important task in many scientific disciplines. However, solvers\ncan be computationally expensive, leading to the development of reduced-order\nmodels (ROMs). Recently, Latent Space Dynamics Identification (LaSDI) was\nproposed as a data-driven, non-intrusive ROM framework. LaSDI compresses the\ntraining data using an autoencoder and learns a system of user-chosen ordinary\ndifferential equations (ODEs), which govern the latent space dynamics. This\nallows for rapid predictions by interpolating and evolving the low-dimensional\nODEs in the latent space. While LaSDI has produced effective ROMs for numerous\nproblems, the autoencoder can have difficulty accurately reconstructing\ntraining data while also satisfying the imposed dynamics in the latent space,\nparticularly in complex or high-frequency regimes. To address this, we propose\nmulti-stage Latent Space Dynamics Identification (mLaSDI). With mLaSDI, several\nautoencoders are trained sequentially in stages, where each autoencoder learns\nto correct the error of the previous stages. We find that applying mLaSDI with\nsmall autoencoders results in lower prediction and reconstruction errors, while\nalso reducing training time compared to LaSDI.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u9636\u6bb5\u6f5c\u5728\u7a7a\u95f4\u52a8\u529b\u5b66\u8bc6\u522b(mLaSDI)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u9636\u6bb5\u8bad\u7ec3\u591a\u4e2a\u81ea\u7f16\u7801\u5668\u6765\u9010\u6b65\u4fee\u6b63\u524d\u4e00\u9636\u6bb5\u7684\u8bef\u5dee\uff0c\u4ece\u800c\u5728\u590d\u6742\u6216\u9ad8\u9891\u60c5\u51b5\u4e0b\u63d0\u9ad8\u6570\u636e\u91cd\u5efa\u7cbe\u5ea6\u548c\u51cf\u5c11\u9884\u6d4b\u8bef\u5dee\u3002", "motivation": "\u539f\u6709\u7684Latent Space Dynamics Identification (LaSDI) \u6846\u67b6\u867d\u7136\u80fd\u591f\u4e3a\u8bb8\u591a\u95ee\u9898\u63d0\u4f9b\u6709\u6548\u7684\u964d\u9636\u6a21\u578b(ROMs)\uff0c\u4f46\u5728\u5904\u7406\u590d\u6742\u6216\u9ad8\u9891\u60c5\u51b5\u65f6\uff0c\u96be\u4ee5\u540c\u65f6\u7cbe\u786e\u5730\u91cd\u5efa\u8bad\u7ec3\u6570\u636e\u5e76\u6ee1\u8db3\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u52a8\u529b\u5b66\u7ea6\u675f\u6761\u4ef6\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u9636\u6bb5\u6f5c\u5728\u7a7a\u95f4\u52a8\u529b\u5b66\u8bc6\u522b\uff08mLaSDI\uff09\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u6309\u9636\u6bb5\u987a\u5e8f\u8bad\u7ec3\u51e0\u4e2a\u81ea\u7f16\u7801\u5668\uff0c\u6bcf\u4e2a\u81ea\u7f16\u7801\u5668\u5b66\u4e60\u4fee\u6b63\u524d\u4e00\u9636\u6bb5\u4ea7\u751f\u7684\u9519\u8bef\u3002", "result": "\u4e0e\u4f20\u7edf\u7684LaSDI\u76f8\u6bd4\uff0c\u91c7\u7528\u5c0f\u578b\u81ea\u7f16\u7801\u5668\u7684mLaSDI\u4e0d\u4ec5\u964d\u4f4e\u4e86\u9884\u6d4b\u548c\u91cd\u6784\u8bef\u5dee\uff0c\u8fd8\u51cf\u5c11\u4e86\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "mLaSDI \u901a\u8fc7\u4f7f\u7528\u591a\u4e2a\u5c0f\u89c4\u6a21\u81ea\u7f16\u7801\u5668\u5206\u9636\u6bb5\u8bad\u7ec3\uff0c\u63d0\u9ad8\u4e86\u5bf9\u4e8e\u590d\u6742\u6216\u9ad8\u9891\u72b6\u6001\u4e0b\u7684\u6570\u636e\u91cd\u5efa\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u5728\u964d\u4f4e\u9884\u6d4b\u8bef\u5dee\u7684\u540c\u65f6\u4e5f\u7f29\u77ed\u4e86\u8bad\u7ec3\u6240\u9700\u7684\u65f6\u95f4\u3002"}}
{"id": "2506.09347", "pdf": "https://arxiv.org/pdf/2506.09347", "abs": "https://arxiv.org/abs/2506.09347", "authors": ["Xuemei Cao", "Hanlin Gu", "Xin Yang", "Bingjun Wei", "Haoyang Liang", "Xiangkun Wang", "Tianrui Li"], "title": "ErrorEraser: Unlearning Data Bias for Improved Continual Learning", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages", "summary": "Continual Learning (CL) primarily aims to retain knowledge to prevent\ncatastrophic forgetting and transfer knowledge to facilitate learning new\ntasks. Unlike traditional methods, we propose a novel perspective: CL not only\nneeds to prevent forgetting, but also requires intentional forgetting.This\narises from existing CL methods ignoring biases in real-world data, leading the\nmodel to learn spurious correlations that transfer and amplify across tasks.\nFrom feature extraction and prediction results, we find that data biases\nsimultaneously reduce CL's ability to retain and transfer knowledge. To address\nthis, we propose ErrorEraser, a universal plugin that removes erroneous\nmemories caused by biases in CL, enhancing performance in both new and old\ntasks. ErrorEraser consists of two modules: Error Identification and Error\nErasure. The former learns the probability density distribution of task data in\nthe feature space without prior knowledge, enabling accurate identification of\npotentially biased samples. The latter ensures only erroneous knowledge is\nerased by shifting the decision space of representative outlier samples.\nAdditionally, an incremental feature distribution learning strategy is designed\nto reduce the resource overhead during error identification in downstream\ntasks. Extensive experimental results show that ErrorEraser significantly\nmitigates the negative impact of data biases, achieving higher accuracy and\nlower forgetting rates across three types of CL methods. The code is available\nat https://github.com/diadai/ErrorEraser.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6301\u7eed\u5b66\u4e60(CL)\u89c6\u89d2\uff0c\u5f3a\u8c03\u4e86\u6709\u610f\u9057\u5fd8\u7684\u91cd\u8981\u6027\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aErrorEraser\u7684\u63d2\u4ef6\u6765\u6d88\u9664\u7531\u4e8e\u6570\u636e\u504f\u5dee\u5f15\u8d77\u9519\u8bef\u8bb0\u5fc6\uff0c\u4ece\u800c\u63d0\u9ad8\u65b0\u65e7\u4efb\u52a1\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u6301\u7eed\u5b66\u4e60\u65b9\u6cd5\u5ffd\u7565\u4e86\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u4e2d\u7684\u504f\u89c1\uff0c\u5bfc\u81f4\u6a21\u578b\u5b66\u4e60\u865a\u5047\u7684\u76f8\u5173\u6027\uff0c\u8fd9\u4e9b\u76f8\u5173\u6027\u5728\u4efb\u52a1\u95f4\u4f20\u9012\u5e76\u88ab\u653e\u5927\u3002\u8fd9\u540c\u65f6\u964d\u4f4e\u4e86CL\u4fdd\u7559\u548c\u8f6c\u79fb\u77e5\u8bc6\u7684\u80fd\u529b\u3002", "method": "ErrorEraser\u662f\u4e00\u79cd\u901a\u7528\u63d2\u4ef6\uff0c\u7531\u9519\u8bef\u8bc6\u522b\u548c\u9519\u8bef\u64e6\u9664\u4e24\u4e2a\u6a21\u5757\u7ec4\u6210\u3002\u9519\u8bef\u8bc6\u522b\u6a21\u5757\u65e0\u9700\u5148\u9a8c\u77e5\u8bc6\u5c31\u80fd\u5b66\u4e60\u4efb\u52a1\u6570\u636e\u5728\u7279\u5f81\u7a7a\u95f4\u7684\u6982\u7387\u5bc6\u5ea6\u5206\u5e03\uff1b\u9519\u8bef\u64e6\u9664\u6a21\u5757\u901a\u8fc7\u6539\u53d8\u4ee3\u8868\u6027\u5f02\u5e38\u6837\u672c\u7684\u51b3\u7b56\u7a7a\u95f4\u6765\u786e\u4fdd\u53ea\u64e6\u9664\u9519\u8bef\u7684\u77e5\u8bc6\u3002\u6b64\u5916\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u79cd\u589e\u91cf\u5f0f\u7279\u5f81\u5206\u5e03\u5b66\u4e60\u7b56\u7565\u4ee5\u51cf\u5c11\u4e0b\u6e38\u4efb\u52a1\u4e2d\u9519\u8bef\u8bc6\u522b\u65f6\u7684\u8d44\u6e90\u5f00\u9500\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cErrorEraser\u663e\u8457\u51cf\u8f7b\u4e86\u6570\u636e\u504f\u89c1\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u5728\u4e09\u79cd\u7c7b\u578b\u7684CL\u65b9\u6cd5\u4e0a\u8fbe\u5230\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u548c\u66f4\u4f4e\u7684\u9057\u5fd8\u7387\u3002", "conclusion": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u521b\u65b0\u7684\u89c2\u70b9\uff0c\u5373\u6301\u7eed\u5b66\u4e60\u4e0d\u4ec5\u9700\u8981\u9632\u6b62\u9057\u5fd8\uff0c\u8fd8\u9700\u8981\u6709\u610f\u8bc6\u5730\u9057\u5fd8\u3002ErrorEraser\u63d2\u4ef6\u6709\u6548\u5730\u89e3\u51b3\u4e86\u56e0\u6570\u636e\u504f\u89c1\u800c\u5bfc\u81f4\u7684\u5b66\u4e60\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5bf9\u65b0\u65e7\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2506.09227", "pdf": "https://arxiv.org/pdf/2506.09227", "abs": "https://arxiv.org/abs/2506.09227", "authors": ["Jie Ren", "Yue Xing", "Yingqian Cui", "Charu C. Aggarwal", "Hui Liu"], "title": "SoK: Machine Unlearning for Large Language Models", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Large language model (LLM) unlearning has become a critical topic in machine\nlearning, aiming to eliminate the influence of specific training data or\nknowledge without retraining the model from scratch. A variety of techniques\nhave been proposed, including Gradient Ascent, model editing, and re-steering\nhidden representations. While existing surveys often organize these methods by\ntheir technical characteristics, such classifications tend to overlook a more\nfundamental dimension: the underlying intention of unlearning--whether it seeks\nto truly remove internal knowledge or merely suppress its behavioral effects.\nIn this SoK paper, we propose a new taxonomy based on this intention-oriented\nperspective. Building on this taxonomy, we make three key contributions. First,\nwe revisit recent findings suggesting that many removal methods may\nfunctionally behave like suppression, and explore whether true removal is\nnecessary or achievable. Second, we survey existing evaluation strategies,\nidentify limitations in current metrics and benchmarks, and suggest directions\nfor developing more reliable and intention-aligned evaluations. Third, we\nhighlight practical challenges--such as scalability and support for sequential\nunlearning--that currently hinder the broader deployment of unlearning methods.\nIn summary, this work offers a comprehensive framework for understanding and\nadvancing unlearning in generative AI, aiming to support future research and\nguide policy decisions around data removal and privacy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u610f\u56fe\u5bfc\u5411\u7684\u65b0\u5206\u7c7b\u6cd5\u6765\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53bb\u5b66\u4e60\u8fc7\u7a0b\uff0c\u5e76\u56f4\u7ed5\u8fd9\u4e00\u5206\u7c7b\u6cd5\u505a\u51fa\u4e86\u4e09\u9879\u4e3b\u8981\u8d21\u732e\uff1a\u91cd\u65b0\u5ba1\u89c6\u4e86\u73b0\u6709\u53bb\u9664\u65b9\u6cd5\u7684\u529f\u80fd\u884c\u4e3a\uff0c\u8c03\u7814\u4e86\u73b0\u6709\u7684\u8bc4\u4f30\u7b56\u7565\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u5411\uff0c\u5f3a\u8c03\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u7684\u6311\u6218\u3002", "motivation": "\u5f53\u524d\u5173\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u53bb\u5b66\u4e60\u7684\u65b9\u6cd5\u5f80\u5f80\u6839\u636e\u6280\u672f\u7279\u6027\u8fdb\u884c\u5206\u7c7b\uff0c\u800c\u5ffd\u89c6\u4e86\u4e00\u4e2a\u66f4\u57fa\u7840\u7684\u7ef4\u5ea6\uff1a\u53bb\u5b66\u4e60\u80cc\u540e\u7684\u610f\u56fe\uff0c\u5373\u662f\u5426\u771f\u6b63\u79fb\u9664\u5185\u90e8\u77e5\u8bc6\u6216\u4ec5\u4ec5\u662f\u6291\u5236\u5176\u884c\u4e3a\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5206\u7c7b\u6cd5\uff0c\u8be5\u5206\u7c7b\u6cd5\u57fa\u4e8e\u610f\u56fe\u5bfc\u5411\u7684\u89d2\u5ea6\u5bf9\u53bb\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u4e86\u5f52\u7c7b\uff1b\u901a\u8fc7\u8fd9\u79cd\u5206\u7c7b\u6cd5\uff0c\u4f5c\u8005\u91cd\u5ba1\u4e86\u6700\u8fd1\u7684\u7814\u7a76\u53d1\u73b0\u3001\u8c03\u67e5\u4e86\u73b0\u5b58\u7684\u8bc4\u4f30\u7b56\u7565\uff0c\u5e76\u6307\u51fa\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u96be\u9898\u3002", "result": "\u5f97\u51fa\u4e86\u8bb8\u591a\u53bb\u9664\u65b9\u6cd5\u53ef\u80fd\u5728\u529f\u80fd\u4e0a\u8868\u73b0\u4e3a\u6291\u5236\u800c\u975e\u771f\u6b63\u53bb\u9664\u7684\u7ed3\u8bba\uff1b\u786e\u5b9a\u4e86\u73b0\u6709\u5ea6\u91cf\u6807\u51c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u5f00\u53d1\u66f4\u52a0\u53ef\u9760\u4e14\u7b26\u5408\u610f\u56fe\u7684\u8bc4\u4f30\u65b9\u6cd5\u6307\u660e\u4e86\u65b9\u5411\uff1b\u5f3a\u8c03\u4e86\u53ef\u6269\u5c55\u6027\u548c\u652f\u6301\u8fde\u7eed\u53bb\u5b66\u4e60\u7b49\u73b0\u5b9e\u6311\u6218\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u6846\u67b6\u6765\u7406\u89e3\u548c\u63a8\u8fdb\u751f\u6210\u5f0fAI\u4e2d\u7684\u53bb\u5b66\u4e60\u7814\u7a76\uff0c\u65e8\u5728\u652f\u6301\u672a\u6765\u7684\u7814\u7a76\u5e76\u6307\u5bfc\u6709\u5173\u6570\u636e\u79fb\u9664\u4e0e\u9690\u79c1\u7684\u653f\u7b56\u51b3\u7b56\u3002"}}
{"id": "2506.09368", "pdf": "https://arxiv.org/pdf/2506.09368", "abs": "https://arxiv.org/abs/2506.09368", "authors": ["Yang Liu", "Jing Liu", "Chengfang Li", "Rui Xi", "Wenchao Li", "Liang Cao", "Jin Wang", "Laurence T. Yang", "Junsong Yuan", "Wei Zhou"], "title": "Anomaly Detection and Generation with Diffusion Models: A Survey", "categories": ["cs.LG", "cs.AI"], "comment": "20 pages, 11 figures, 13 tables", "summary": "Anomaly detection (AD) plays a pivotal role across diverse domains, including\ncybersecurity, finance, healthcare, and industrial manufacturing, by\nidentifying unexpected patterns that deviate from established norms in\nreal-world data. Recent advancements in deep learning, specifically diffusion\nmodels (DMs), have sparked significant interest due to their ability to learn\ncomplex data distributions and generate high-fidelity samples, offering a\nrobust framework for unsupervised AD. In this survey, we comprehensively review\nanomaly detection and generation with diffusion models (ADGDM), presenting a\ntutorial-style analysis of the theoretical foundations and practical\nimplementations and spanning images, videos, time series, tabular, and\nmultimodal data. Crucially, unlike existing surveys that often treat anomaly\ndetection and generation as separate problems, we highlight their inherent\nsynergistic relationship. We reveal how DMs enable a reinforcing cycle where\ngeneration techniques directly address the fundamental challenge of anomaly\ndata scarcity, while detection methods provide critical feedback to improve\ngeneration fidelity and relevance, advancing both capabilities beyond their\nindividual potential. A detailed taxonomy categorizes ADGDM methods based on\nanomaly scoring mechanisms, conditioning strategies, and architectural designs,\nanalyzing their strengths and limitations. We final discuss key challenges\nincluding scalability and computational efficiency, and outline promising\nfuture directions such as efficient architectures, conditioning strategies, and\nintegration with foundation models (e.g., visual-language models and large\nlanguage models). By synthesizing recent advances and outlining open research\nquestions, this survey aims to guide researchers and practitioners in\nleveraging DMs for innovative AD solutions across diverse applications.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u6587\u7ae0\u63a2\u8ba8\u4e86\u6269\u6563\u6a21\u578b\u5728\u5f02\u5e38\u68c0\u6d4b\u548c\u751f\u6210\u4e2d\u7684\u5e94\u7528\uff0c\u5f3a\u8c03\u4e86\u4e24\u8005\u95f4\u7684\u534f\u540c\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u8be6\u7ec6\u7684\u5206\u7c7b\u4f53\u7cfb\u6765\u5206\u6790\u8fd9\u4e9b\u65b9\u6cd5\u7684\u4f18\u52bf\u4e0e\u5c40\u9650\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u8ba8\u8bba\u4e86\u5305\u62ec\u53ef\u6269\u5c55\u6027\u548c\u8ba1\u7b97\u6548\u7387\u5728\u5185\u7684\u5173\u952e\u6311\u6218\uff0c\u5e76\u6982\u8ff0\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u7684\u8fdb\u6b65\uff0c\u7279\u522b\u662f\u6269\u6563\u6a21\u578b\u7684\u51fa\u73b0\uff0c\u4e3a\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u6846\u67b6\u3002\u7136\u800c\u73b0\u6709\u7684\u8c03\u67e5\u5f80\u5f80\u5c06\u5f02\u5e38\u68c0\u6d4b\u548c\u751f\u6210\u89c6\u4e3a\u4e24\u4e2a\u72ec\u7acb\u7684\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u63ed\u793a\u8fd9\u4e24\u8005\u4e4b\u95f4\u7684\u5185\u5728\u534f\u540c\u5173\u7cfb\uff0c\u4ee5\u4fc3\u8fdb\u66f4\u6709\u6548\u7684\u5f02\u5e38\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u9645\u5e94\u7528\u6848\u4f8b\u7684\u6559\u7a0b\u5f0f\u5206\u6790\uff0c\u5bf9\u4f7f\u7528\u6269\u6563\u6a21\u578b\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u4e0e\u751f\u6210\uff08ADGDM\uff09\u7684\u65b9\u6cd5\u8fdb\u884c\u4e86\u5168\u9762\u56de\u987e\u3002\u5efa\u7acb\u4e86\u4e00\u4e2a\u8be6\u7ec6\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u57fa\u4e8e\u5f02\u5e38\u8bc4\u5206\u673a\u5236\u3001\u6761\u4ef6\u7b56\u7565\u53ca\u67b6\u6784\u8bbe\u8ba1\u7b49\u65b9\u9762\u5bf9ADGDM\u65b9\u6cd5\u8fdb\u884c\u4e86\u5f52\u7c7b\u3002", "result": "\u5c55\u793a\u4e86\u6269\u6563\u6a21\u578b\u5982\u4f55\u901a\u8fc7\u751f\u6210\u6280\u672f\u76f4\u63a5\u89e3\u51b3\u5f02\u5e38\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u540c\u65f6\u68c0\u6d4b\u65b9\u6cd5\u53c8\u80fd\u53cd\u8fc7\u6765\u63d0\u9ad8\u751f\u6210\u7684\u771f\u5b9e\u6027\u548c\u76f8\u5173\u6027\u3002\u6307\u51fa\u4e86\u5f53\u524d\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\u5982\u53ef\u6269\u5c55\u6027\u548c\u8ba1\u7b97\u6548\u7387\u7b49\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u53ef\u80fd\u7684\u65b9\u5411\u3002", "conclusion": "\u7efc\u4e0a\u6240\u8ff0\uff0c\u672c\u7bc7\u7efc\u8ff0\u4e0d\u4ec5\u7efc\u5408\u4e86\u6700\u8fd1\u5173\u4e8e\u5229\u7528\u6269\u6563\u6a21\u578b\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u548c\u751f\u6210\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u800c\u4e14\u4e5f\u63d0\u51fa\u4e86\u4e00\u4e9b\u5f00\u653e\u7684\u7814\u7a76\u95ee\u9898\uff0c\u76ee\u7684\u662f\u4e3a\u4e86\u6307\u5bfc\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u5f00\u53d1\u51fa\u8de8\u591a\u79cd\u5e94\u7528\u573a\u666f\u4e0b\u7684\u521b\u65b0\u5f02\u5e38\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.09247", "pdf": "https://arxiv.org/pdf/2506.09247", "abs": "https://arxiv.org/abs/2506.09247", "authors": ["Karl L\u00f6wenmark", "Daniel Str\u00f6mbergsson", "Chang Liu", "Marcus Liwicki", "Fredrik Sandin"], "title": "Agent-based Condition Monitoring Assistance with Multimodal Industrial Database Retrieval Augmented Generation", "categories": ["cs.LG"], "comment": null, "summary": "Condition monitoring (CM) plays a crucial role in ensuring reliability and\nefficiency in the process industry. Although computerised maintenance systems\neffectively detect and classify faults, tasks like fault severity estimation,\nand maintenance decisions still largely depend on human expert analysis. The\nanalysis and decision making automatically performed by current systems\ntypically exhibit considerable uncertainty and high false alarm rates, leading\nto increased workload and reduced efficiency.\n  This work integrates large language model (LLM)-based reasoning agents with\nCM workflows to address analyst and industry needs, namely reducing false\nalarms, enhancing fault severity estimation, improving decision support, and\noffering explainable interfaces. We propose MindRAG, a modular framework\ncombining multimodal retrieval-augmented generation (RAG) with novel vector\nstore structures designed specifically for CM data. The framework leverages\nexisting annotations and maintenance work orders as surrogates for labels in a\nsupervised learning protocol, addressing the common challenge of training\npredictive models on unlabelled and noisy real-world datasets.\n  The primary contributions include: (1) an approach for structuring industry\nCM data into a semi-structured multimodal vector store compatible with\nLLM-driven workflows; (2) developing multimodal RAG techniques tailored for CM\ndata; (3) developing practical reasoning agents capable of addressing\nreal-world CM queries; and (4) presenting an experimental framework for\nintegrating and evaluating such agents in realistic industrial scenarios.\nPreliminary results, evaluated with the help of an experienced analyst,\nindicate that MindRAG provide meaningful decision support for more efficient\nmanagement of alarms, thereby improving the interpretability of CM systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86MindRAG\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e0e\u4e13\u4e3a\u6761\u4ef6\u76d1\u6d4b\uff08CM\uff09\u6570\u636e\u8bbe\u8ba1\u7684\u5411\u91cf\u5b58\u50a8\u7ed3\u6784\uff0c\u65e8\u5728\u51cf\u5c11\u8bef\u62a5\u3001\u63d0\u9ad8\u6545\u969c\u4e25\u91cd\u6027\u4f30\u8ba1\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u754c\u9762\u3002", "motivation": "\u5f53\u524d\u8ba1\u7b97\u673a\u5316\u7ef4\u62a4\u7cfb\u7edf\u867d\u7136\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u548c\u5206\u7c7b\u6545\u969c\uff0c\u4f46\u5728\u6545\u969c\u4e25\u91cd\u6027\u4f30\u8ba1\u548c\u7ef4\u62a4\u51b3\u7b56\u4e0a\u4ecd\u4f9d\u8d56\u4e8e\u4eba\u5de5\u5206\u6790\u3002\u73b0\u6709\u7cfb\u7edf\u7684\u81ea\u52a8\u5206\u6790\u548c\u51b3\u7b56\u8fc7\u7a0b\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u4e14\u8bef\u62a5\u7387\u9ad8\uff0c\u5bfc\u81f4\u5de5\u4f5c\u8d1f\u8377\u589e\u52a0\u548c\u6548\u7387\u964d\u4f4e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMindRAG\u7684\u6a21\u5757\u5316\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u63a8\u7406\u4ee3\u7406\u4e0e\u6761\u4ef6\u76d1\u6d4b\u5de5\u4f5c\u6d41\u7a0b\u76f8\u7ed3\u5408\uff0c\u5229\u7528\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u4ee5\u53ca\u4e13\u4e3aCM\u6570\u636e\u8bbe\u8ba1\u7684\u65b0\u9896\u5411\u91cf\u5b58\u50a8\u7ed3\u6784\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u8fd8\u5229\u7528\u73b0\u6709\u7684\u6ce8\u91ca\u548c\u7ef4\u62a4\u5de5\u5355\u4f5c\u4e3a\u76d1\u7763\u5b66\u4e60\u534f\u8bae\u4e2d\u7684\u6807\u7b7e\u66ff\u4ee3\u54c1\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0cMindRAG\u80fd\u591f\u4e3a\u66f4\u9ad8\u6548\u5730\u7ba1\u7406\u8b66\u62a5\u63d0\u4f9b\u6709\u610f\u4e49\u7684\u51b3\u7b56\u652f\u6301\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86CM\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4ee3\u7406\u4e0e\u6761\u4ef6\u76d1\u6d4b\u6d41\u7a0b\uff0cMindRAG\u6709\u52a9\u4e8e\u89e3\u51b3\u5206\u6790\u5e08\u548c\u884c\u4e1a\u9700\u6c42\uff0c\u5305\u62ec\u51cf\u5c11\u8bef\u62a5\u3001\u52a0\u5f3a\u6545\u969c\u4e25\u91cd\u7a0b\u5ea6\u8bc4\u4f30\u3001\u6539\u8fdb\u51b3\u7b56\u652f\u6301\u53ca\u63d0\u4f9b\u6613\u4e8e\u7406\u89e3\u7684\u4eba\u673a\u4ea4\u4e92\u754c\u9762\u3002"}}
{"id": "2506.09373", "pdf": "https://arxiv.org/pdf/2506.09373", "abs": "https://arxiv.org/abs/2506.09373", "authors": ["Jiaqi Tang", "Yu Xia", "Yi-Feng Wu", "Yuwei Hu", "Yuhui Chen", "Qing-Guo Chen", "Xiaogang Xu", "Xiangyu Wu", "Hao Lu", "Yanqing Ma", "Shiyin Lu", "Qifeng Chen"], "title": "LPO: Towards Accurate GUI Agent Interaction via Location Preference Optimization", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "The advent of autonomous agents is transforming interactions with Graphical\nUser Interfaces (GUIs) by employing natural language as a powerful\nintermediary. Despite the predominance of Supervised Fine-Tuning (SFT) methods\nin current GUI agents for achieving spatial localization, these methods face\nsubstantial challenges due to their limited capacity to accurately perceive\npositional data. Existing strategies, such as reinforcement learning, often\nfail to assess positional accuracy effectively, thereby restricting their\nutility. In response, we introduce Location Preference Optimization (LPO), a\nnovel approach that leverages locational data to optimize interaction\npreferences. LPO uses information entropy to predict interaction positions by\nfocusing on zones rich in information. Besides, it further introduces a dynamic\nlocation reward function based on physical distance, reflecting the varying\nimportance of interaction positions. Supported by Group Relative Preference\nOptimization (GRPO), LPO facilitates an extensive exploration of GUI\nenvironments and significantly enhances interaction precision. Comprehensive\nexperiments demonstrate LPO's superior performance, achieving SOTA results\nacross both offline benchmarks and real-world online evaluations. Our code will\nbe made publicly available soon, at https://github.com/AIDC-AI/LPO.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5373\u4f4d\u7f6e\u504f\u597d\u4f18\u5316\uff08LPO\uff09\uff0c\u5b83\u5229\u7528\u4f4d\u7f6e\u6570\u636e\u6765\u4f18\u5316\u56fe\u5f62\u7528\u6237\u754c\u9762\u4e2d\u7684\u4ea4\u4e92\u504f\u597d\uff0c\u5e76\u901a\u8fc7\u4fe1\u606f\u71b5\u9884\u6d4b\u4ea4\u4e92\u4f4d\u7f6e\uff0c\u540c\u65f6\u5f15\u5165\u4e86\u57fa\u4e8e\u7269\u7406\u8ddd\u79bb\u7684\u52a8\u6001\u4f4d\u7f6e\u5956\u52b1\u51fd\u6570\u3002\u5b9e\u9a8c\u8868\u660e\uff0cLPO\u5728\u79bb\u7ebf\u57fa\u51c6\u6d4b\u8bd5\u548c\u73b0\u5b9e\u4e16\u754c\u7684\u5728\u7ebf\u8bc4\u4f30\u4e2d\u5747\u8fbe\u5230\u4e86\u9886\u5148\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u7684\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u5728\u5904\u7406\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u7684\u7a7a\u95f4\u5b9a\u4f4d\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5c24\u5176\u662f\u5728\u51c6\u786e\u611f\u77e5\u4f4d\u7f6e\u6570\u636e\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002\u6b64\u5916\uff0c\u5f3a\u5316\u5b66\u4e60\u7b49\u73b0\u6709\u7b56\u7565\u5f80\u5f80\u4e0d\u80fd\u6709\u6548\u8bc4\u4f30\u4f4d\u7f6e\u51c6\u786e\u6027\uff0c\u9650\u5236\u4e86\u5b83\u4eec\u7684\u5b9e\u7528\u6027\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4f4d\u7f6e\u504f\u597d\u4f18\u5316\uff08LPO\uff09\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u79cd\u540d\u4e3a\u4f4d\u7f6e\u504f\u597d\u4f18\u5316\uff08LPO\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4f7f\u7528\u4fe1\u606f\u71b5\u6765\u9884\u6d4b\u5bcc\u542b\u4fe1\u606f\u533a\u57df\u7684\u4ea4\u4e92\u4f4d\u7f6e\uff0c\u5e76\u4e14\u57fa\u4e8e\u7269\u7406\u8ddd\u79bb\u5f15\u5165\u4e86\u4e00\u4e2a\u52a8\u6001\u4f4d\u7f6e\u5956\u52b1\u51fd\u6570\uff0c\u4ee5\u53cd\u6620\u4e0d\u540c\u4ea4\u4e92\u4f4d\u7f6e\u7684\u91cd\u8981\u6027\u3002\u6b64\u5916\uff0c\u8fd8\u501f\u52a9\u4e86\u7ec4\u76f8\u5bf9\u504f\u597d\u4f18\u5316\uff08GRPO\uff09\u6765\u4fc3\u8fdb\u5bf9GUI\u73af\u5883\u7684\u5e7f\u6cdb\u63a2\u7d22\u3002", "result": "\u5168\u9762\u7684\u5b9e\u9a8c\u663e\u793a\uff0cLPO\u5728\u79bb\u7ebf\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u53ca\u5b9e\u9645\u5728\u7ebf\u8bc4\u4f30\u4e2d\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u8fbe\u6210\u4e86\u6700\u5148\u8fdb\uff08SOTA\uff09\u7684\u7ed3\u679c\u3002", "conclusion": "\u4f4d\u7f6e\u504f\u597d\u4f18\u5316\uff08LPO\uff09\u662f\u4e00\u79cd\u80fd\u591f\u663e\u8457\u63d0\u9ad8GUI\u73af\u5883\u4e2d\u4ea4\u4e92\u7cbe\u5ea6\u7684\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u4f18\u5316\u4ea4\u4e92\u4f4d\u7f6e\u5e76\u8003\u8651\u5230\u4f4d\u7f6e\u7684\u91cd\u8981\u6027\uff0c\u4ece\u800c\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u6280\u672f\u3002"}}
{"id": "2506.09496", "pdf": "https://arxiv.org/pdf/2506.09496", "abs": "https://arxiv.org/abs/2506.09496", "authors": ["Dingyi Rong", "Haotian Lu", "Wenzhuo Zheng", "Fan Zhang", "Shuangjia Zheng", "Ning Liu"], "title": "EnerBridge-DPO: Energy-Guided Protein Inverse Folding with Markov Bridges and Direct Preference Optimization", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Designing protein sequences with optimal energetic stability is a key\nchallenge in protein inverse folding, as current deep learning methods are\nprimarily trained by maximizing sequence recovery rates, often neglecting the\nenergy of the generated sequences. This work aims to overcome this limitation\nby developing a model that directly generates low-energy, stable protein\nsequences. We propose EnerBridge-DPO, a novel inverse folding framework focused\non generating low-energy, high-stability protein sequences. Our core innovation\nlies in: First, integrating Markov Bridges with Direct Preference Optimization\n(DPO), where energy-based preferences are used to fine-tune the Markov Bridge\nmodel. The Markov Bridge initiates optimization from an information-rich prior\nsequence, providing DPO with a pool of structurally plausible sequence\ncandidates. Second, an explicit energy constraint loss is introduced, which\nenhances the energy-driven nature of DPO based on prior sequences, enabling the\nmodel to effectively learn energy representations from a wealth of prior\nknowledge and directly predict sequence energy values, thereby capturing\nquantitative features of the energy landscape. Our evaluations demonstrate that\nEnerBridge-DPO can design protein complex sequences with lower energy while\nmaintaining sequence recovery rates comparable to state-of-the-art models, and\naccurately predicts $\\Delta \\Delta G$ values between various sequences.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86EnerBridge-DPO\uff0c\u4e00\u79cd\u65b0\u7684\u9006\u6298\u53e0\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u7ed3\u5408\u9a6c\u5c14\u53ef\u592b\u6865\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\u6765\u751f\u6210\u4f4e\u80fd\u91cf\u3001\u9ad8\u7a33\u5b9a\u6027\u7684\u86cb\u767d\u8d28\u5e8f\u5217\uff0c\u5e76\u4e14\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u4e0d\u540c\u5e8f\u5217\u4e4b\u95f4\u7684\u0394\u0394G\u503c\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u901a\u8fc7\u6700\u5927\u5316\u5e8f\u5217\u6062\u590d\u7387\u6765\u8fdb\u884c\u8bad\u7ec3\uff0c\u5f80\u5f80\u5ffd\u89c6\u4e86\u751f\u6210\u5e8f\u5217\u7684\u80fd\u91cf\u95ee\u9898\u3002\u8bbe\u8ba1\u5177\u6709\u6700\u4f18\u80fd\u91cf\u7a33\u5b9a\u6027\u7684\u86cb\u767d\u8d28\u5e8f\u5217\u662f\u86cb\u767d\u8d28\u9006\u6298\u53e0\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEnerBridge-DPO\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u9a6c\u5c14\u53ef\u592b\u6865\u4e0e\u57fa\u4e8e\u80fd\u91cf\u504f\u597d\u7684\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u76f8\u7ed3\u5408\uff0c\u4ece\u4fe1\u606f\u4e30\u5bcc\u7684\u5148\u9a8c\u5e8f\u5217\u5f00\u59cb\u4f18\u5316\uff0c\u5f15\u5165\u4e86\u663e\u5f0f\u7684\u80fd\u91cf\u7ea6\u675f\u635f\u5931\u4ee5\u589e\u5f3aDPO\u7684\u80fd\u91cf\u9a71\u52a8\u7279\u6027\u3002", "result": "\u8bc4\u4f30\u8868\u660e\uff0cEnerBridge-DPO\u53ef\u4ee5\u8bbe\u8ba1\u51fa\u80fd\u91cf\u66f4\u4f4e\u7684\u86cb\u767d\u8d28\u590d\u5408\u4f53\u5e8f\u5217\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u6700\u5148\u8fdb\u6a21\u578b\u76f8\u5ab2\u7f8e\u7684\u5e8f\u5217\u6062\u590d\u7387\uff0c\u5e76\u80fd\u51c6\u786e\u9884\u6d4b\u5404\u79cd\u5e8f\u5217\u95f4\u7684\u0394\u0394G\u503c\u3002", "conclusion": "EnerBridge-DPO\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u7684\u9006\u6298\u53e0\u65b9\u6cd5\uff0c\u5728\u4fdd\u8bc1\u5e8f\u5217\u6062\u590d\u7387\u7684\u540c\u65f6\u6709\u6548\u964d\u4f4e\u4e86\u86cb\u767d\u8d28\u5e8f\u5217\u7684\u80fd\u91cf\uff0c\u4e3a\u86cb\u767d\u8d28\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2506.09270", "pdf": "https://arxiv.org/pdf/2506.09270", "abs": "https://arxiv.org/abs/2506.09270", "authors": ["Rodrigo Carrasco-Davis", "Sebastian Lee", "Claudia Clopath", "Will Dabney"], "title": "Uncertainty Prioritized Experience Replay", "categories": ["cs.LG"], "comment": "Accepted at Reinforcement Learning Conference", "summary": "Prioritized experience replay, which improves sample efficiency by selecting\nrelevant transitions to update parameter estimates, is a crucial component of\ncontemporary value-based deep reinforcement learning models. Typically,\ntransitions are prioritized based on their temporal difference error. However,\nthis approach is prone to favoring noisy transitions, even when the value\nestimation closely approximates the target mean. This phenomenon resembles the\nnoisy TV problem postulated in the exploration literature, in which\nexploration-guided agents get stuck by mistaking noise for novelty. To mitigate\nthe disruptive effects of noise in value estimation, we propose using epistemic\nuncertainty estimation to guide the prioritization of transitions from the\nreplay buffer. Epistemic uncertainty quantifies the uncertainty that can be\nreduced by learning, hence reducing transitions sampled from the buffer\ngenerated by unpredictable random processes. We first illustrate the benefits\nof epistemic uncertainty prioritized replay in two tabular toy models: a simple\nmulti-arm bandit task, and a noisy gridworld. Subsequently, we evaluate our\nprioritization scheme on the Atari suite, outperforming quantile regression\ndeep Q-learning benchmarks; thus forging a path for the use of uncertainty\nprioritized replay in reinforcement learning agents.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u7684\u4f18\u5148\u7ecf\u9a8c\u56de\u653e\u65b9\u6cd5\uff0c\u4ee5\u51cf\u5c11\u4ef7\u503c\u4f30\u8ba1\u4e2d\u7684\u566a\u58f0\u5e72\u6270\uff0c\u5e76\u5728Atari\u6e38\u620f\u5957\u4ef6\u4e0a\u4f18\u4e8e\u5206\u4f4d\u6570\u56de\u5f52\u6df1\u5ea6Q\u5b66\u4e60\u57fa\u51c6\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u65f6\u95f4\u5dee\u8bef\u5dee\u7684\u9009\u62e9\u8f6c\u6362\u65b9\u5f0f\u5bb9\u6613\u504f\u5411\u4e8e\u566a\u58f0\u8f6c\u6362\uff0c\u5373\u4f7f\u4ef7\u503c\u4f30\u8ba1\u63a5\u8fd1\u76ee\u6807\u5747\u503c\u65f6\u4e5f\u662f\u5982\u6b64\u3002\u8fd9\u7c7b\u4f3c\u4e8e\u63a2\u7d22\u6587\u732e\u4e2d\u5047\u8bbe\u7684\u566a\u58f0\u7535\u89c6\u95ee\u9898\uff0c\u5176\u4e2d\u7531\u63a2\u7d22\u5f15\u5bfc\u7684\u4ee3\u7406\u4f1a\u56e0\u4e3a\u5c06\u566a\u58f0\u8bef\u8ba4\u4e3a\u65b0\u9896\u6027\u800c\u9677\u5165\u56f0\u5883\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4f7f\u7528\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u6765\u6307\u5bfc\u91cd\u653e\u7f13\u51b2\u533a\u4e2d\u8f6c\u6362\u7684\u4f18\u5148\u7ea7\u6392\u5e8f\u3002", "method": "\u7814\u7a76\u8005\u9996\u5148\u5728\u4e24\u4e2a\u8868\u683c\u73a9\u5177\u6a21\u578b\uff08\u4e00\u4e2a\u591a\u81c2\u8001\u864e\u673a\u4efb\u52a1\u548c\u4e00\u4e2a\u566a\u58f0\u7f51\u683c\u4e16\u754c\uff09\u4e2d\u5c55\u793a\u4e86\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u4f18\u5148\u56de\u653e\u7684\u597d\u5904\u3002\u7136\u540e\uff0c\u4ed6\u4eec\u5728Atari\u6e38\u620f\u5957\u4ef6\u4e0a\u8bc4\u4f30\u4e86\u4ed6\u4eec\u7684\u4f18\u5148\u7ea7\u6392\u5e8f\u65b9\u6848\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u4f18\u5148\u7684\u7ecf\u9a8c\u56de\u653e\uff0c\u5728Atari\u6e38\u620f\u5957\u4ef6\u4e0a\u7684\u8868\u73b0\u8d85\u8fc7\u4e86\u5206\u4f4d\u6570\u56de\u5f52\u6df1\u5ea6Q\u5b66\u4e60\u57fa\u51c6\u3002", "conclusion": "\u5229\u7528\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\u6765\u6307\u5bfc\u7ecf\u9a8c\u56de\u653e\u4e2d\u7684\u4f18\u5148\u7ea7\u6392\u5e8f\u80fd\u591f\u6709\u6548\u51cf\u5c11\u7531\u4e8e\u968f\u673a\u8fc7\u7a0b\u5f15\u8d77\u7684\u6837\u672c\u566a\u58f0\uff0c\u4ece\u800c\u63d0\u9ad8\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u7684\u5b66\u4e60\u6548\u7387\u3002"}}
{"id": "2506.09499", "pdf": "https://arxiv.org/pdf/2506.09499", "abs": "https://arxiv.org/abs/2506.09499", "authors": ["Thomas J. Ringstrom", "Paul R. Schrater"], "title": "A Unified Theory of Compositionality, Modularity, and Interpretability in Markov Decision Processes", "categories": ["cs.LG", "cs.AI"], "comment": "12 Pages", "summary": "We introduce Option Kernel Bellman Equations (OKBEs) for a new reward-free\nMarkov Decision Process. Rather than a value function, OKBEs directly construct\nand optimize a predictive map called a state-time option kernel (STOK) to\nmaximize the probability of completing a goal while avoiding constraint\nviolations. STOKs are compositional, modular, and interpretable\ninitiation-to-termination transition kernels for policies in the Options\nFramework of Reinforcement Learning. This means: 1) STOKs can be composed using\nChapman-Kolmogorov equations to make spatiotemporal predictions for multiple\npolicies over long horizons, 2) high-dimensional STOKs can be represented and\ncomputed efficiently in a factorized and reconfigurable form, and 3) STOKs\nrecord the probabilities of semantically interpretable goal-success and\nconstraint-violation events, needed for formal verification. Given a\nhigh-dimensional state-transition model for an intractable planning problem, we\ncan decompose it with local STOKs and goal-conditioned policies that are\naggregated into a factorized goal kernel, making it possible to forward-plan at\nthe level of goals in high-dimensions to solve the problem. These properties\nlead to highly flexible agents that can rapidly synthesize meta-policies, reuse\nplanning representations across many tasks, and justify goals using\nempowerment, an intrinsic motivation function. We argue that\nreward-maximization is in conflict with the properties of compositionality,\nmodularity, and interpretability. Alternatively, OKBEs facilitate these\nproperties to support verifiable long-horizon planning and intrinsic motivation\nthat scales to dynamic high-dimensional world-models.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u9009\u9879\u6838\u8d1d\u5c14\u66fc\u65b9\u7a0b(OKBEs)\uff0c\u7528\u4e8e\u4e00\u79cd\u65b0\u7684\u65e0\u5956\u52b1\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u3002OKBEs\u6784\u5efa\u5e76\u4f18\u5316\u4e00\u4e2a\u79f0\u4e3a\u72b6\u6001-\u65f6\u95f4\u9009\u9879\u6838(STOK)\u7684\u9884\u6d4b\u6620\u5c04\uff0c\u4ee5\u6700\u5927\u5316\u5b8c\u6210\u76ee\u6807\u7684\u6982\u7387\u540c\u65f6\u907f\u514d\u8fdd\u53cd\u7ea6\u675f\u3002STOKs\u5177\u6709\u7ec4\u5408\u6027\u3001\u6a21\u5757\u5316\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u4e14\u80fd\u591f\u652f\u6301\u957f\u671f\u89c4\u5212\u548c\u5185\u5728\u52a8\u673a\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u9ad8\u7ef4\u4e16\u754c\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u4ef7\u503c\u51fd\u6570\u7684\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u9ad8\u7ef4\u95ee\u9898\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5f53\u9700\u8981\u8fdb\u884c\u957f\u671f\u89c4\u5212\u4ee5\u53ca\u4fdd\u6301\u7b56\u7565\u7684\u7ec4\u5408\u6027\u3001\u6a21\u5757\u5316\u548c\u53ef\u89e3\u91ca\u6027\u65f6\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u65b9\u6cd5\uff0c\u5373\u9009\u9879\u6838\u8d1d\u5c14\u66fc\u65b9\u7a0b(OKBEs)\uff0c\u5b83\u76f4\u63a5\u6784\u9020\u5e76\u4f18\u5316\u72b6\u6001-\u65f6\u95f4\u9009\u9879\u6838(STOK)\u6765\u63d0\u9ad8\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u7684\u80fd\u529b\u3002", "method": "\u7814\u7a76\u8005\u5f15\u5165\u4e86\u9009\u9879\u6838\u8d1d\u5c14\u66fc\u65b9\u7a0b\uff08OKBEs\uff09\uff0c\u5b83\u4eec\u4e0d\u4f9d\u8d56\u4e8e\u4ef7\u503c\u51fd\u6570\u800c\u662f\u76f4\u63a5\u6784\u5efa\u548c\u4f18\u5316\u4e00\u4e2a\u540d\u4e3a\u72b6\u6001-\u65f6\u95f4\u9009\u9879\u6838\uff08STOK\uff09\u7684\u9884\u6d4b\u56fe\uff0c\u4ee5\u589e\u52a0\u8fbe\u5230\u76ee\u6807\u7684\u6982\u7387\u540c\u65f6\u9632\u6b62\u8fdd\u53cd\u7ea6\u675f\u6761\u4ef6\u3002STOKs\u662f\u590d\u5408\u7684\u3001\u6a21\u5757\u5316\u7684\uff0c\u5e76\u4e14\u53ef\u4ee5\u88ab\u89e3\u8bfb\u4e3a\u4ece\u5f00\u59cb\u5230\u7ed3\u675f\u7684\u8f6c\u6362\u6838\uff0c\u8fd9\u4e9b\u7279\u6027\u5141\u8bb8STOKs\u901a\u8fc7Chapman-Kolmogorov\u65b9\u7a0b\u8fdb\u884c\u7ec4\u5408\uff0c\u4ee5\u4fbf\u5bf9\u591a\u4e2a\u7b56\u7565\u505a\u51fa\u65f6\u7a7a\u9884\u6d4b\uff0c\u540c\u65f6\u4e5f\u80fd\u591f\u6709\u6548\u5730\u8868\u793a\u548c\u8ba1\u7b97\u9ad8\u7ef4\u5ea6\u7684\u60c5\u51b5\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cOKBEs\u548cSTOKs\u4f7f\u5f97\u4ee3\u7406\u80fd\u591f\u5feb\u901f\u5408\u6210\u5143\u7b56\u7565\uff0c\u8de8\u591a\u4e2a\u4efb\u52a1\u91cd\u7528\u89c4\u5212\u8868\u5f81\uff0c\u5e76\u4f7f\u7528\u8d4b\u80fd\u4f5c\u4e3a\u5185\u5728\u6fc0\u52b1\u51fd\u6570\u6765\u8bc1\u660e\u76ee\u6807\u7684\u5408\u7406\u6027\u3002\u6b64\u5916\uff0cSTOKs\u8bb0\u5f55\u4e86\u8bed\u4e49\u4e0a\u53ef\u89e3\u91ca\u7684\u76ee\u6807\u6210\u529f\u4e0e\u7ea6\u675f\u8fdd\u53cd\u4e8b\u4ef6\u7684\u6982\u7387\uff0c\u8fd9\u6709\u52a9\u4e8e\u6b63\u5f0f\u9a8c\u8bc1\u3002", "conclusion": "OKBEs\u4fc3\u8fdb\u4e86\u7ec4\u5408\u6027\u3001\u6a21\u5757\u5316\u548c\u53ef\u89e3\u91ca\u6027\u7684\u7279\u70b9\uff0c\u652f\u6301\u53ef\u9a8c\u8bc1\u7684\u957f\u671f\u89c4\u5212\u548c\u53ef\u6269\u5c55\u5230\u52a8\u6001\u9ad8\u7ef4\u4e16\u754c\u6a21\u578b\u7684\u5185\u5728\u52a8\u673a\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5956\u52b1\u6700\u5927\u5316\u53ef\u80fd\u4e0e\u4e0a\u8ff0\u5c5e\u6027\u76f8\u51b2\u7a81\u3002"}}
{"id": "2506.09526", "pdf": "https://arxiv.org/pdf/2506.09526", "abs": "https://arxiv.org/abs/2506.09526", "authors": ["Woojin Cho", "Minju Jo", "Kookjin Lee", "Noseong Park"], "title": "Neural Functions for Learning Periodic Signal", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "As function approximators, deep neural networks have served as an effective\ntool to represent various signal types. Recent approaches utilize multi-layer\nperceptrons (MLPs) to learn a nonlinear mapping from a coordinate to its\ncorresponding signal, facilitating the learning of continuous neural\nrepresentations from discrete data points. Despite notable successes in\nlearning diverse signal types, coordinate-based MLPs often face issues of\noverfitting and limited generalizability beyond the training region, resulting\nin subpar extrapolation performance. This study addresses scenarios where the\nunderlying true signals exhibit periodic properties, either spatially or\ntemporally. We propose a novel network architecture, which extracts periodic\npatterns from measurements and leverages this information to represent the\nsignal, thereby enhancing generalization and improving extrapolation\nperformance. We demonstrate the efficacy of the proposed method through\ncomprehensive experiments, including the learning of the periodic solutions for\ndifferential equations, and time series imputation (interpolation) and\nforecasting (extrapolation) on real-world datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f51\u7edc\u67b6\u6784\uff0c\u7528\u4e8e\u4ece\u6d4b\u91cf\u4e2d\u63d0\u53d6\u5468\u671f\u6027\u6a21\u5f0f\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u6765\u8868\u793a\u4fe1\u53f7\uff0c\u4ece\u800c\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u548c\u5916\u63a8\u6027\u80fd\u3002\u901a\u8fc7\u7efc\u5408\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5305\u62ec\u5b66\u4e60\u5fae\u5206\u65b9\u7a0b\u7684\u5468\u671f\u89e3\u3001\u65f6\u95f4\u5e8f\u5217\u63d2\u8865\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u9884\u6d4b\u3002", "motivation": "\u57fa\u4e8e\u5750\u6807MLP\u7684\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u5177\u6709\u5468\u671f\u6027\u8d28\u7684\u771f\u5b9e\u4fe1\u53f7\u65f6\u5b58\u5728\u8fc7\u62df\u5408\u548c\u6cdb\u5316\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u5916\u63a8\u8868\u73b0\u4e0d\u4f73\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7279\u522b\u662f\u5f53\u5e95\u5c42\u771f\u5b9e\u4fe1\u53f7\u5c55\u793a\u51fa\u7a7a\u95f4\u6216\u65f6\u95f4\u4e0a\u7684\u5468\u671f\u6027\u7279\u5f81\u65f6\uff0c\u7814\u7a76\u65e8\u5728\u6539\u8fdb\u6a21\u578b\u7684\u6cdb\u5316\u53ca\u5916\u63a8\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u7f51\u7edc\u7ed3\u6784\uff0c\u80fd\u591f\u4ece\u6570\u636e\u6d4b\u91cf\u4e2d\u62bd\u53d6\u5468\u671f\u6027\u7684\u6a21\u5f0f\uff0c\u5e76\u5c06\u8fd9\u4e9b\u5468\u671f\u4fe1\u606f\u7528\u6765\u8868\u793a\u4fe1\u53f7\uff0c\u4ee5\u589e\u5f3a\u6a21\u578b\u5bf9\u672a\u77e5\u6570\u636e\u7684\u6cdb\u5316\u80fd\u529b\u5e76\u6539\u5584\u5916\u63a8\u6548\u679c\u3002", "result": "\u901a\u8fc7\u4e00\u7cfb\u5217\u5168\u9762\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u5b66\u4e60\u5fae\u5206\u65b9\u7a0b\u7684\u5468\u671f\u89e3\u4ee5\u53ca\u8fdb\u884c\u65f6\u95f4\u5e8f\u5217\u63d2\u8865\u548c\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u7684\u9884\u6d4b\u65b9\u9762\u662f\u6709\u6548\u7684\u3002", "conclusion": "\u65b0\u63d0\u51fa\u7684\u7f51\u7edc\u67b6\u6784\u80fd\u591f\u6709\u6548\u5730\u4ece\u6570\u636e\u4e2d\u63d0\u53d6\u5e76\u5229\u7528\u5468\u671f\u6027\u4fe1\u606f\uff0c\u8fd9\u6709\u52a9\u4e8e\u63d0\u5347\u8fde\u7eed\u795e\u7ecf\u8868\u793a\u5b66\u4e60\u7684\u6cdb\u5316\u4e0e\u5916\u63a8\u6027\u80fd\u3002"}}
{"id": "2506.09279", "pdf": "https://arxiv.org/pdf/2506.09279", "abs": "https://arxiv.org/abs/2506.09279", "authors": ["Ziyi Chen", "Yiyang Liu", "Mattia Prosperi", "Krishna Vaddiparti", "Robert L Cook", "Jiang Bian", "Yi Guo", "Yonghui Wu"], "title": "A Topic Modeling Analysis of Stigma Dimensions, Social, and Related Behavioral Circumstances in Clinical Notes Among Patients with HIV", "categories": ["cs.LG", "cs.IR"], "comment": null, "summary": "Objective: To characterize stigma dimensions, social, and related behavioral\ncircumstances in people living with HIV (PLWHs) seeking care, using natural\nlanguage processing methods applied to a large collection of electronic health\nrecord (EHR) clinical notes from a large integrated health system in the\nsoutheast United States. Methods: We identified 9,140 cohort of PLWHs from the\nUF Health IDR and performed topic modeling analysis using Latent Dirichlet\nAllocation (LDA) to uncover stigma dimensions, social, and related behavioral\ncircumstances. Domain experts created a seed list of HIV-related stigma\nkeywords, then applied a snowball strategy to iteratively review notes for\nadditional terms until saturation was reached. To identify more target topics,\nwe tested three keyword-based filtering strategies. Domain experts manually\nreviewed the detected topics using the prevalent terms and key discussion\ntopics. Word frequency analysis was used to highlight the prevalent terms\nassociated with each topic. In addition, we conducted topic variation analysis\namong subgroups to examine differences across age and sex-specific\ndemographics. Results and Conclusion: Topic modeling on sentences containing at\nleast one keyword uncovered a wide range of topic themes associated with\nHIV-related stigma, social, and related behaviors circumstances, including\n\"Mental Health Concern and Stigma\", \"Social Support and Engagement\", \"Limited\nHealthcare Access and Severe Illness\", \"Treatment Refusal and Isolation\" and so\non. Topic variation analysis across age subgroups revealed differences.\nExtracting and understanding the HIV-related stigma dimensions, social, and\nrelated behavioral circumstances from EHR clinical notes enables scalable,\ntime-efficient assessment, overcoming the limitations of traditional\nquestionnaires and improving patient outcomes.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8fd0\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u5bf9\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21\uff0c\u63ed\u793a\u4e86HIV\u611f\u67d3\u8005\u7684\u6c61\u540d\u5316\u3001\u793e\u4f1a\u56e0\u7d20\u53ca\u884c\u4e3a\u72b6\u51b5\uff0c\u4e3a\u7406\u89e3\u548c\u6539\u8fdbHIV\u611f\u67d3\u8005\u7684\u60c5\u51b5\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002", "motivation": "\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5e94\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u65b9\u6cd5\u4e8e\u7f8e\u56fd\u4e1c\u5357\u90e8\u4e00\u4e2a\u5927\u578b\u7efc\u5408\u536b\u751f\u7cfb\u7edf\u7684\u5927\u91cf\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u4e34\u5e8a\u7b14\u8bb0\uff0c\u6765\u8868\u5f81\u5bfb\u6c42\u62a4\u7406\u7684\u827e\u6ecb\u75c5\u60a3\u8005\uff08PLWHs\uff09\u4e2d\u7684\u6c61\u540d\u7ef4\u5ea6\u3001\u793e\u4f1a\u53ca\u76f8\u5173\u7684\u884c\u4e3a\u60c5\u51b5\u3002", "method": "\u7814\u7a76\u8005\u4eceUF Health IDR\u4e2d\u8bc6\u522b\u51fa9,140\u540dPLWH\u961f\u5217\uff0c\u5e76\u4f7f\u7528\u6f5c\u5728\u72c4\u5229\u514b\u96f7\u5206\u914d\uff08LDA\uff09\u8fdb\u884c\u4e3b\u9898\u5efa\u6a21\u5206\u6790\uff0c\u4ee5\u63ed\u793a\u6c61\u540d\u7ef4\u5ea6\u3001\u793e\u4f1a\u53ca\u76f8\u5173\u884c\u4e3a\u60c5\u51b5\u3002\u9886\u57df\u4e13\u5bb6\u521b\u5efa\u4e86\u4e0eHIV\u76f8\u5173\u6c61\u540d\u5173\u952e\u8bcd\u7684\u79cd\u5b50\u5217\u8868\uff0c\u5e76\u91c7\u7528\u6eda\u96ea\u7403\u7b56\u7565\u8fed\u4ee3\u5ba1\u9605\u7b14\u8bb0\uff0c\u76f4\u5230\u8fbe\u5230\u9971\u548c\u3002\u4e3a\u4e86\u786e\u5b9a\u66f4\u591a\u76ee\u6807\u4e3b\u9898\uff0c\u6d4b\u8bd5\u4e86\u4e09\u79cd\u57fa\u4e8e\u5173\u952e\u8bcd\u7684\u8fc7\u6ee4\u7b56\u7565\u3002\u901a\u8fc7\u8bcd\u9891\u5206\u6790\u7a81\u51fa\u663e\u793a\u6bcf\u4e2a\u4e3b\u9898\u76f8\u5173\u7684\u5e38\u89c1\u672f\u8bed\u3002\u6b64\u5916\uff0c\u8fd8\u8fdb\u884c\u4e86\u5b50\u7ec4\u95f4\u4e3b\u9898\u53d8\u5316\u5206\u6790\uff0c\u4ee5\u68c0\u67e5\u4e0d\u540c\u5e74\u9f84\u548c\u6027\u522b\u7279\u5b9a\u4eba\u53e3\u7edf\u8ba1\u5b66\u7279\u5f81\u4e4b\u95f4\u7684\u5dee\u5f02\u3002", "result": "\u5728\u5305\u542b\u81f3\u5c11\u4e00\u4e2a\u5173\u952e\u8bcd\u7684\u53e5\u5b50\u4e0a\u8fdb\u884c\u7684\u4e3b\u9898\u5efa\u6a21\u63ed\u793a\u4e86\u4e0eHIV\u76f8\u5173\u6c61\u540d\u3001\u793e\u4f1a\u4ee5\u53ca\u76f8\u5173\u884c\u4e3a\u60c5\u51b5\u7684\u4e00\u7cfb\u5217\u4e3b\u9898\uff0c\u5305\u62ec\u201c\u5fc3\u7406\u5065\u5eb7\u5173\u6ce8\u4e0e\u6c61\u540d\u201d\u3001\u201c\u793e\u4f1a\u652f\u6301\u4e0e\u53c2\u4e0e\u201d\u3001\u201c\u6709\u9650\u7684\u533b\u7597\u4fdd\u5065\u83b7\u53d6\u4e0e\u91cd\u75c5\u201d\u3001\u201c\u6cbb\u7597\u62d2\u7edd\u4e0e\u9694\u79bb\u201d\u7b49\u3002\u8de8\u5e74\u9f84\u5b50\u7ec4\u7684\u4e3b\u9898\u53d8\u5316\u5206\u6790\u63ed\u793a\u4e86\u5dee\u5f02\u3002", "conclusion": "\u4eceEHR\u4e34\u5e8a\u8bb0\u5f55\u4e2d\u63d0\u53d6\u548c\u7406\u89e3\u4e0eHIV\u76f8\u5173\u7684\u6c61\u540d\u7ef4\u5ea6\u3001\u793e\u4f1a\u4ee5\u53ca\u76f8\u5173\u884c\u4e3a\u60c5\u51b5\uff0c\u80fd\u591f\u5b9e\u73b0\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u65f6\u95f4\u8bc4\u4f30\uff0c\u514b\u670d\u4f20\u7edf\u95ee\u5377\u8c03\u67e5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u6539\u5584\u60a3\u8005\u7684\u6cbb\u7597\u7ed3\u679c\u3002"}}
{"id": "2506.09532", "pdf": "https://arxiv.org/pdf/2506.09532", "abs": "https://arxiv.org/abs/2506.09532", "authors": ["Shuai Wang", "Zhenhua Liu", "Jiaheng Wei", "Xuanwu Yin", "Dong Li", "Emad Barsoum"], "title": "Athena: Enhancing Multimodal Reasoning with Data-efficient Process Reward Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "We present Athena-PRM, a multimodal process reward model (PRM) designed to\nevaluate the reward score for each step in solving complex reasoning problems.\nDeveloping high-performance PRMs typically demands significant time and\nfinancial investment, primarily due to the necessity for step-level annotations\nof reasoning steps. Conventional automated labeling methods, such as Monte\nCarlo estimation, often produce noisy labels and incur substantial\ncomputational costs. To efficiently generate high-quality process-labeled data,\nwe propose leveraging prediction consistency between weak and strong completers\nas a criterion for identifying reliable process labels. Remarkably, Athena-PRM\ndemonstrates outstanding effectiveness across various scenarios and benchmarks\nwith just 5,000 samples. Furthermore, we also develop two effective strategies\nto improve the performance of PRMs: ORM initialization and up-sampling for\nnegative data. We validate our approach in three specific scenarios:\nverification for test time scaling, direct evaluation of reasoning step\ncorrectness, and reward ranked fine-tuning. Our Athena-PRM consistently\nachieves superior performance across multiple benchmarks and scenarios.\nNotably, when using Qwen2.5-VL-7B as the policy model, Athena-PRM enhances\nperformance by 10.2 points on WeMath and 7.1 points on MathVista for test time\nscaling. Furthermore, Athena-PRM sets the state-of-the-art (SoTA) results in\nVisualProcessBench and outperforms the previous SoTA by 3.9 F1-score,\nshowcasing its robust capability to accurately assess the correctness of the\nreasoning step. Additionally, utilizing Athena-PRM as the reward model, we\ndevelop Athena-7B with reward ranked fine-tuning and outperforms baseline with\na significant margin on five benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Athena-PRM\uff0c\u4e00\u79cd\u591a\u6a21\u6001\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u89e3\u51b3\u590d\u6742\u63a8\u7406\u95ee\u9898\u65f6\u6bcf\u4e00\u6b65\u7684\u5956\u52b1\u5206\u6570\u3002\u901a\u8fc7\u5229\u7528\u5f31\u548c\u5f3a\u5b8c\u6210\u8005\u4e4b\u95f4\u7684\u9884\u6d4b\u4e00\u81f4\u6027\u4f5c\u4e3a\u8bc6\u522b\u53ef\u9760\u8fc7\u7a0b\u6807\u7b7e\u7684\u6807\u51c6\uff0c\u8be5\u6a21\u578b\u80fd\u4ee5\u8f83\u5c11\u6837\u672c\u9ad8\u6548\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u8fc7\u7a0b\u6807\u7b7e\u6570\u636e\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f00\u53d1\u9ad8\u6027\u80fd\u7684\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRMs\uff09\u901a\u5e38\u9700\u8981\u5927\u91cf\u65f6\u95f4\u548c\u8d44\u91d1\u6295\u5165\uff0c\u5c24\u5176\u662f\u56e0\u4e3a\u9700\u8981\u5bf9\u63a8\u7406\u6b65\u9aa4\u8fdb\u884c\u9010\u7ea7\u6807\u6ce8\u3002\u4f20\u7edf\u7684\u81ea\u52a8\u5316\u6807\u6ce8\u65b9\u6cd5\u5982\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u5f80\u5f80\u4ea7\u751f\u5608\u6742\u7684\u6807\u7b7e\u5e76\u5bfc\u81f4\u9ad8\u6602\u7684\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u4e3a\u4e86\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f31\u4e0e\u5f3a\u5b8c\u6210\u8005\u4e4b\u95f4\u9884\u6d4b\u4e00\u81f4\u6027\u7684\u65b0\u65b9\u6cd5\u6765\u8bc6\u522b\u53ef\u9760\u7684\u6b65\u9aa4\u6807\u7b7e\uff0c\u5e76\u636e\u6b64\u6784\u5efa\u4e86Athena-PRM\u6a21\u578b\u3002\u6b64\u5916\u8fd8\u5f00\u53d1\u4e86\u4e24\u79cd\u7b56\u7565\uff1aORM\u521d\u59cb\u5316\u548c\u8d1f\u6837\u672c\u4e0a\u91c7\u6837\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4ec5\u4f7f\u75285,000\u4e2a\u6837\u672c\u7684\u60c5\u51b5\u4e0b\uff0cAthena-PRM\u5728\u591a\u79cd\u573a\u666f\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u90fd\u5c55\u73b0\u51fa\u4e86\u5353\u8d8a\u7684\u6709\u6548\u6027\u3002\u7279\u522b\u662f\u5728\u91c7\u7528Qwen2.5-VL-7B\u4f5c\u4e3a\u7b56\u7565\u6a21\u578b\u65f6\uff0c\u5b83\u5728WeMath\u4e0a\u7684\u8868\u73b0\u63d0\u5347\u4e8610.2\u5206\uff0c\u5728MathVista\u4e0a\u63d0\u5347\u4e867.1\u5206\uff1b\u540c\u65f6\u4e5f\u5728VisualProcessBench\u4e0a\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "Athena-PRM\u4e0d\u4ec5\u80fd\u591f\u6709\u6548\u5730\u51cf\u5c11\u83b7\u53d6\u9ad8\u8d28\u91cf\u8fc7\u7a0b\u6807\u7b7e\u6240\u9700\u7684\u6210\u672c\uff0c\u800c\u4e14\u8fd8\u80fd\u663e\u8457\u63d0\u5347\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u7684\u63a8\u7406\u4efb\u52a1\u6027\u80fd\u3002"}}
{"id": "2506.09701", "pdf": "https://arxiv.org/pdf/2506.09701", "abs": "https://arxiv.org/abs/2506.09701", "authors": ["Vincenzo Collura", "Karim Tit", "Laura Bussi", "Eleonora Giunchiglia", "Maxime Cordy"], "title": "TRIDENT: Temporally Restricted Inference via DFA-Enhanced Neural Traversal", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) and other neural architectures have achieved\nimpressive results across a variety of generative and classification tasks.\nHowever, they remain fundamentally ill-equipped to ensure that their outputs\nsatisfy temporal constraints, such as those expressible in Linear Temporal\nLogic over finite traces (LTLf). In this paper, we introduce TRIDENT: a general\nand model-agnostic inference-time algorithm that guarantees compliance with\nsuch constraints without requiring any retraining. TRIDENT compiles LTLf\nformulas into a Deterministic Finite Automaton (DFA), which is used to guide a\nconstrained variant of beam search. At each decoding step, transitions that\nwould lead to constraint violations are masked, while remaining paths are\ndynamically re-ranked based on both the model's probabilities and the DFA's\nacceptance structure. We formally prove that the resulting sequences are\nguaranteed to satisfy the given LTLf constraints, and we empirically\ndemonstrate that TRIDENT also improves output quality. We validate our approach\non two distinct tasks: temporally constrained image-stream classification and\ncontrolled text generation. In both settings, TRIDENT achieves perfect\nconstraint satisfaction, while comparison with the state of the art shows\nimproved efficiency and high standard quality metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTRIDENT\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u53ef\u4ee5\u5728\u63a8\u7406\u65f6\u4fdd\u8bc1\u751f\u6210\u7684\u7ed3\u679c\u6ee1\u8db3\u7ebf\u6027\u65f6\u6001\u903b\u8f91\uff08LTLf\uff09\u6240\u8868\u8fbe\u7684\u65f6\u95f4\u7ea6\u675f\uff0c\u5e76\u4e14\u4e0d\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002\u5b83\u5c06LTLf\u516c\u5f0f\u7f16\u8bd1\u4e3a\u786e\u5b9a\u6709\u9650\u81ea\u52a8\u673a\uff08DFA\uff09\uff0c\u5e76\u6307\u5bfc\u4e00\u4e2a\u53d7\u7ea6\u675f\u7684\u675f\u641c\u7d22\u53d8\u4f53\uff0c\u5728\u6bcf\u4e2a\u89e3\u7801\u6b65\u9aa4\u4e2d\u5c4f\u853d\u4f1a\u5bfc\u81f4\u7ea6\u675f\u8fdd\u89c4\u7684\u8f6c\u6362\uff0c\u540c\u65f6\u6839\u636e\u6a21\u578b\u7684\u6982\u7387\u548cDFA\u7684\u63a5\u53d7\u7ed3\u6784\u52a8\u6001\u91cd\u6392\u5269\u4f59\u8def\u5f84\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u5176\u4ed6\u795e\u7ecf\u67b6\u6784\u5728\u5404\u79cd\u751f\u6210\u548c\u5206\u7c7b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u7ed3\u679c\uff0c\u4f46\u5b83\u4eec\u672c\u8d28\u4e0a\u65e0\u6cd5\u786e\u4fdd\u5176\u8f93\u51fa\u6ee1\u8db3\u65f6\u95f4\u7ea6\u675f\uff0c\u5982\u53ef\u4ee5\u7528\u7ebf\u6027\u65f6\u6001\u903b\u8f91\u8868\u793a\u7684\u7ea6\u675f\u3002", "method": "TRIDENT\u662f\u4e00\u79cd\u901a\u7528\u4e14\u4e0e\u6a21\u578b\u65e0\u5173\u7684\u63a8\u7406\u65f6\u95f4\u7b97\u6cd5\uff0c\u5b83\u901a\u8fc7\u5c06LTLf\u516c\u5f0f\u7f16\u8bd1\u6210\u786e\u5b9a\u6709\u9650\u81ea\u52a8\u673a\uff08DFA\uff09\u6765\u5de5\u4f5c\uff0c\u8fd9\u4e2aDFA\u7528\u6765\u5f15\u5bfc\u53d7\u9650\u7248\u672c\u7684\u675f\u641c\u7d22\u3002\u5728\u6bcf\u4e2a\u89e3\u7801\u6b65\u9aa4\u4e2d\uff0c\u4f1a\u906e\u853d\u6389\u5bfc\u81f4\u7ea6\u675f\u8fdd\u53cd\u7684\u8f6c\u79fb\uff0c\u800c\u5269\u4f59\u8def\u5f84\u5219\u57fa\u4e8e\u6a21\u578b\u7684\u6982\u7387\u548cDFA\u7684\u63a5\u53d7\u7ed3\u6784\u8fdb\u884c\u52a8\u6001\u91cd\u65b0\u6392\u5e8f\u3002", "result": "TRIDENT\u80fd\u591f\u4fdd\u8bc1\u4ea7\u751f\u7684\u5e8f\u5217\u6ee1\u8db3\u7ed9\u5b9a\u7684LTLf\u7ea6\u675f\uff0c\u5e76\u4e14\u5b9e\u8bc1\u8868\u660eTRIDENT\u8fd8\u63d0\u9ad8\u4e86\u8f93\u51fa\u8d28\u91cf\u3002\u5728\u4e24\u4e2a\u4e0d\u540c\u7684\u4efb\u52a1\u4e2d\u9a8c\u8bc1\u4e86\u8fd9\u79cd\u65b9\u6cd5\uff1a\u65f6\u95f4\u9650\u5236\u7684\u56fe\u50cf\u6d41\u5206\u7c7b\u548c\u53d7\u63a7\u6587\u672c\u751f\u6210\u3002\u5728\u8fd9\u4e24\u79cd\u60c5\u51b5\u4e0b\uff0cTRIDENT\u90fd\u8fbe\u5230\u4e86\u5b8c\u7f8e\u7684\u7ea6\u675f\u6ee1\u8db3\u5ea6\uff0c\u5e76\u4e14\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u6bd4\u663e\u793a\u51fa\u4e86\u66f4\u9ad8\u7684\u6548\u7387\u548c\u9ad8\u8d28\u91cf\u6807\u51c6\u6307\u6807\u3002", "conclusion": "TRIDENT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u65b9\u6cd5\u6765\u786e\u4fddLLMs\u548c\u5176\u4ed6\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u7684\u8f93\u51fa\u9075\u5b88\u590d\u6742\u7684\u65f6\u5e8f\u7ea6\u675f\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\uff0c\u5e76\u4e14\u80fd\u591f\u5728\u4fdd\u6301\u6216\u63d0\u9ad8\u8f93\u51fa\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u3002"}}
{"id": "2506.09316", "pdf": "https://arxiv.org/pdf/2506.09316", "abs": "https://arxiv.org/abs/2506.09316", "authors": ["Yeonju Ro", "Zhenyu Zhang", "Souvik Kundu", "Zhangyang Wang", "Aditya Akella"], "title": "On-the-Fly Adaptive Distillation of Transformer to Dual-State Linear Attention", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) excel at capturing global token dependencies via\nself-attention but face prohibitive compute and memory costs on lengthy inputs.\nWhile sub-quadratic methods (e.g., linear attention) can reduce these costs,\nthey often degrade accuracy due to overemphasizing recent tokens. In this work,\nwe first propose \\textit{dual-state linear attention} (\\textbf{\\dsla}), a novel\ndesign that maintains two specialized hidden states-one for preserving\nhistorical context and one for tracking recency-thereby mitigating the\nshort-range bias typical of linear-attention architectures. To further balance\nefficiency and accuracy under dynamic workload conditions, we introduce\n\\textbf{\\serve}, an online \\textit{adaptive distillation} framework that\nprogressively replaces Transformer layers with DSLA layers at inference time,\nguided by a sensitivity-based layer ordering. \\serve\\ uses a chained\nfine-tuning strategy to ensure that each newly converted DSLA layer remains\nconsistent with previously replaced layers, preserving the overall quality.\nExtensive evaluations on commonsense reasoning, long-context QA, and text\nsummarization demonstrate that \\serve\\ yields \\textbf{2.3x} faster inference\nthan Llama2-7B and \\textbf{3.0x} faster than the hybrid Zamba-7B, while\nretaining comparable performance across downstream tasks. Our ablation studies\nshow that DSLA's dual states capture both global and local dependencies,\naddressing the historical-token underrepresentation seen in prior linear\nattentions. Codes are available at https://github.com/utnslab/DSLA-Serve.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53cc\u72b6\u6001\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\uff08DSLA\uff09\u548c\u4e00\u4e2a\u5728\u7ebf\u81ea\u9002\u5e94\u84b8\u998f\u6846\u67b6SERVE\uff0c\u65e8\u5728\u63d0\u9ad8\u957f\u8f93\u5165\u4e0b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0eLlama2-7B\u76f8\u6bd4\uff0cSERVE\u5728\u63a8\u7406\u901f\u5ea6\u4e0a\u63d0\u9ad8\u4e862.3\u500d\uff0c\u5e76\u4e14\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u64c5\u957f\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u6355\u6349\u5168\u5c40token\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f46\u9762\u5bf9\u957f\u8f93\u5165\u65f6\u5b58\u5728\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u8fc7\u9ad8\u7684\u95ee\u9898\u3002\u73b0\u6709\u7684\u6b21\u4e8c\u6b21\u65b9\u6cd5\u5982\u7ebf\u6027\u6ce8\u610f\u529b\u867d\u80fd\u964d\u4f4e\u6210\u672c\uff0c\u5374\u56e0\u8fc7\u5206\u5f3a\u8c03\u6700\u8fd1\u7684tokens\u800c\u964d\u4f4e\u7cbe\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8bbe\u8ba1\uff0c\u5373\u53cc\u72b6\u6001\u7ebf\u6027\u6ce8\u610f\u529b\uff08DSLA\uff09\uff0c\u5b83\u7ef4\u62a4\u4e24\u4e2a\u4e13\u95e8\u7684\u9690\u85cf\u72b6\u6001\uff0c\u4e00\u4e2a\u7528\u4e8e\u4fdd\u5b58\u5386\u53f2\u4e0a\u4e0b\u6587\uff0c\u53e6\u4e00\u4e2a\u7528\u4e8e\u8ddf\u8e2a\u6700\u8fd1\u4fe1\u606f\uff0c\u4ece\u800c\u51cf\u8f7b\u7ebf\u6027\u6ce8\u610f\u529b\u67b6\u6784\u4e2d\u7684\u77ed\u7a0b\u504f\u5dee\u3002\u6b64\u5916\uff0c\u8fd8\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aSERVE\u7684\u5728\u7ebf\u81ea\u9002\u5e94\u84b8\u998f\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6839\u636e\u57fa\u4e8e\u654f\u611f\u6027\u7684\u5c42\u6392\u5e8f\uff0c\u5728\u63a8\u7406\u65f6\u9010\u6b65\u7528DSLA\u5c42\u66ff\u6362Transformer\u5c42\u3002SERVE\u91c7\u7528\u94fe\u5f0f\u5fae\u8c03\u7b56\u7565\u4ee5\u4fdd\u8bc1\u6bcf\u4e2a\u65b0\u8f6c\u6362\u7684DSLA\u5c42\u4e0e\u4e4b\u524d\u66ff\u6362\u7684\u5c42\u4fdd\u6301\u4e00\u81f4\uff0c\u786e\u4fdd\u6574\u4f53\u8d28\u91cf\u3002", "result": "\u5728\u5e38\u8bc6\u63a8\u7406\u3001\u957f\u4e0a\u4e0b\u6587\u95ee\u7b54\u548c\u6587\u672c\u6458\u8981\u7b49\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u8bc4\u4f30\u8868\u660e\uff0cSERVE\u6bd4Llama2-7B\u5feb2.3\u500d\uff0c\u6bd4\u6df7\u5408Zamba-7B\u5feb3.0\u500d\uff0c\u540c\u65f6\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u4fdd\u6301\u4e86\u53ef\u6bd4\u8f83\u7684\u8868\u73b0\u3002\u6d88\u878d\u7814\u7a76\u8868\u660e\uff0cDSLA\u7684\u53cc\u91cd\u72b6\u6001\u80fd\u591f\u6355\u6349\u5230\u5168\u5c40\u548c\u5c40\u90e8\u4f9d\u8d56\u5173\u7cfb\uff0c\u89e3\u51b3\u4e86\u5148\u524d\u7ebf\u6027\u6ce8\u610f\u529b\u4e2d\u5386\u53f2tokens\u4ee3\u8868\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165DSLA\u53ca\u5176\u4f34\u968f\u7684SERVE\u6846\u67b6\uff0c\u7814\u7a76\u8005\u4eec\u6210\u529f\u5730\u4e3a\u5904\u7406\u957f\u8f93\u5165\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e2\u9ad8\u6548\u53c8\u51c6\u786e\u7684\u65b0\u65b9\u6848\uff0c\u8fd9\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u63a8\u7406\u901f\u5ea6\uff0c\u4e5f\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2506.09733", "pdf": "https://arxiv.org/pdf/2506.09733", "abs": "https://arxiv.org/abs/2506.09733", "authors": ["Minjong Cheon"], "title": "AtmosMJ: Revisiting Gating Mechanism for AI Weather Forecasting Beyond the Year Scale", "categories": ["cs.LG", "cs.AI", "cs.CV", "physics.ao-ph"], "comment": null, "summary": "The advent of Large Weather Models (LWMs) has marked a turning point in\ndata-driven forecasting, with many models now outperforming traditional\nnumerical systems in the medium range. However, achieving stable, long-range\nautoregressive forecasts beyond a few weeks remains a significant challenge.\nPrevailing state-of-the-art models that achieve year-long stability, such as\nSFNO and DLWP-HPX, have relied on transforming input data onto non-standard\nspatial domains like spherical harmonics or HEALPix meshes. This has led to the\nprevailing assumption that such representations are necessary to enforce\nphysical consistency and long-term stability. This paper challenges that\nassumption by investigating whether comparable long-range performance can be\nachieved on the standard latitude-longitude grid. We introduce AtmosMJ, a deep\nconvolutional network that operates directly on ERA5 data without any spherical\nremapping. The model's stability is enabled by a novel Gated Residual Fusion\n(GRF) mechanism, which adaptively moderates feature updates to prevent error\naccumulation over long recursive simulations. Our results demonstrate that\nAtmosMJ produces stable and physically plausible forecasts for about 500 days.\nIn quantitative evaluations, it achieves competitive 10-day forecast accuracy\nagainst models like Pangu-Weather and GraphCast, all while requiring a\nremarkably low training budget of 5.7 days on a V100 GPU. Our findings suggest\nthat efficient architectural design, rather than non-standard data\nrepresentation, can be the key to unlocking stable and computationally\nefficient long-range weather prediction.", "AI": {"tldr": "\u672c\u6587\u6311\u6218\u4e86\u9700\u8981\u975e\u6807\u51c6\u7a7a\u95f4\u57df\u6765\u5b9e\u73b0\u957f\u671f\u7a33\u5b9a\u5929\u6c14\u9884\u62a5\u7684\u5047\u8bbe\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAtmosMJ\u7684\u6df1\u5ea6\u5377\u79ef\u7f51\u7edc\uff0c\u5b83\u76f4\u63a5\u5728\u6807\u51c6\u7ecf\u7eac\u5ea6\u7f51\u683c\u4e0a\u8fd0\u884c\uff0c\u5e76\u901a\u8fc7\u4e00\u79cd\u65b0\u7684\u95e8\u63a7\u6b8b\u5dee\u878d\u5408\u673a\u5236\u6765\u4fdd\u8bc1\u6a21\u578b\u7a33\u5b9a\u6027\u3002\u8be5\u6a21\u578b\u80fd\u591f\u751f\u6210\u957f\u8fbe\u7ea6500\u5929\u7684\u7a33\u5b9a\u4e14\u7269\u7406\u4e0a\u5408\u7406\u7684\u9884\u62a5\uff0c\u572810\u5929\u9884\u62a5\u51c6\u786e\u7387\u65b9\u9762\u4e0ePangu-Weather\u548cGraphCast\u7b49\u6a21\u578b\u76f8\u5f53\uff0c\u540c\u65f6\u8bad\u7ec3\u6210\u672c\u6781\u4f4e\u3002", "motivation": "\u73b0\u6709\u7684\u957f\u671f\u81ea\u56de\u5f52\u5929\u6c14\u9884\u62a5\u6a21\u578b\u901a\u5e38\u4f9d\u8d56\u4e8e\u5c06\u8f93\u5165\u6570\u636e\u8f6c\u6362\u5230\u7403\u8c10\u51fd\u6570\u6216HEALPix\u7f51\u683c\u7b49\u975e\u6807\u51c6\u7a7a\u95f4\u57df\uff0c\u4ee5\u786e\u4fdd\u7269\u7406\u4e00\u81f4\u6027\u548c\u957f\u671f\u7a33\u5b9a\u6027\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u5728\u6807\u51c6\u7684\u7ecf\u7eac\u5ea6\u7f51\u683c\u4e0a\u8fbe\u5230\u7c7b\u4f3c\u7684\u957f\u671f\u9884\u62a5\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86AtmosMJ\uff0c\u8fd9\u662f\u4e00\u79cd\u6df1\u5c42\u5377\u79ef\u7f51\u7edc\uff0c\u53ef\u4ee5\u76f4\u63a5\u5904\u7406ERA5\u6570\u636e\u800c\u65e0\u9700\u8fdb\u884c\u7403\u9762\u91cd\u6620\u5c04\u3002\u8be5\u6a21\u578b\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u95e8\u63a7\u6b8b\u5dee\u878d\u5408\uff08GRF\uff09\u673a\u5236\uff0c\u53ef\u4ee5\u81ea\u9002\u5e94\u5730\u8c03\u8282\u7279\u5f81\u66f4\u65b0\uff0c\u9632\u6b62\u957f\u65f6\u95f4\u9012\u5f52\u6a21\u62df\u8fc7\u7a0b\u4e2d\u8bef\u5dee\u7d2f\u79ef\u3002", "result": "AtmosMJ\u80fd\u591f\u5728\u5927\u7ea6500\u5929\u5185\u4ea7\u751f\u7a33\u5b9a\u4e14\u7b26\u5408\u7269\u7406\u89c4\u5f8b\u7684\u9884\u6d4b\u3002\u5728\u5b9a\u91cf\u8bc4\u4f30\u4e2d\uff0c\u5b83\u768410\u5929\u9884\u62a5\u7cbe\u5ea6\u4e0ePangu-Weather\u548cGraphCast\u7b49\u6a21\u578b\u76f8\u7ade\u4e89\uff0c\u5e76\u4e14\u4ec5\u9700\u5728V100 GPU\u4e0a\u82b1\u8d395.7\u5929\u7684\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u6709\u6548\u7684\u67b6\u6784\u8bbe\u8ba1\u800c\u4e0d\u662f\u91c7\u7528\u975e\u6807\u51c6\u7684\u6570\u636e\u8868\u793a\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6210\u4e3a\u89e3\u9501\u7a33\u5b9a\u4e14\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u957f\u671f\u5929\u6c14\u9884\u6d4b\u7684\u5173\u952e\u3002"}}
{"id": "2506.09332", "pdf": "https://arxiv.org/pdf/2506.09332", "abs": "https://arxiv.org/abs/2506.09332", "authors": ["Zhenqiao Song", "Ramith Hettiarachchi", "Chuan Li", "Jianwen Xie", "Lei Li"], "title": "Natural Language Guided Ligand-Binding Protein Design", "categories": ["cs.LG", "cs.CE", "cs.CL"], "comment": null, "summary": "Can AI protein models follow human language instructions and design proteins\nwith desired functions (e.g. binding to a ligand)? Designing proteins that bind\nto a given ligand is crucial in a wide range of applications in biology and\nchemistry. Most prior AI models are trained on protein-ligand complex data,\nwhich is scarce due to the high cost and time requirements of laboratory\nexperiments. In contrast, there is a substantial body of human-curated text\ndescriptions about protein-ligand interactions and ligand formula. In this\npaper, we propose InstructPro, a family of protein generative models that\nfollow natural language instructions to design ligand-binding proteins. Given a\ntextual description of the desired function and a ligand formula in SMILES,\nInstructPro generates protein sequences that are functionally consistent with\nthe specified instructions. We develop the model architecture, training\nstrategy, and a large-scale dataset, InstructProBench, to support both training\nand evaluation. InstructProBench consists of 9,592,829 triples of (function\ndescription, ligand formula, protein sequence). We train two model variants:\nInstructPro-1B (with 1 billion parameters) and InstructPro-3B~(with 3 billion\nparameters). Both variants consistently outperform strong baselines, including\nProGen2, ESM3, and Pinal. Notably, InstructPro-1B achieves the highest docking\nsuccess rate (81.52% at moderate confidence) and the lowest average root mean\nsquare deviation (RMSD) compared to ground truth structures (4.026{\\AA}).\nInstructPro-3B further descreases the average RMSD to 2.527{\\AA}, demonstrating\nInstructPro's ability to generate ligand-binding proteins that align with the\nfunctional specifications.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86InstructPro\uff0c\u4e00\u79cd\u80fd\u591f\u6839\u636e\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u8bbe\u8ba1\u5177\u6709\u7279\u5b9a\u529f\u80fd\uff08\u5982\u4e0e\u914d\u4f53\u7ed3\u5408\uff09\u7684\u86cb\u767d\u8d28\u751f\u6210\u6a21\u578b\u3002\u5b83\u4f7f\u7528\u4e86\u5927\u89c4\u6a21\u6570\u636e\u96c6InstructProBench\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u5176\u4ed6\u5f3a\u5927\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u86cb\u767d\u8d28\u4e0e\u7279\u5b9a\u914d\u4f53\u7684\u7ed3\u5408\u5728\u751f\u7269\u5b66\u548c\u5316\u5b66\u9886\u57df\u6709\u7740\u5e7f\u6cdb\u7684\u5e94\u7528\uff0c\u4f46\u73b0\u6709\u7684AI\u6a21\u578b\u901a\u5e38\u4f9d\u8d56\u4e8e\u7a00\u7f3a\u4e14\u6602\u8d35\u7684\u86cb\u767d\u8d28-\u914d\u4f53\u590d\u5408\u7269\u6570\u636e\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5173\u4e8e\u86cb\u767d\u8d28-\u914d\u4f53\u76f8\u4e92\u4f5c\u7528\u7684\u4eba\u5de5\u6574\u7406\u6587\u672c\u63cf\u8ff0\u6570\u91cf\u5e9e\u5927\uff0c\u8fd9\u4e3a\u5f00\u53d1\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u6307\u5bfc\u7684\u65b0\u6a21\u578b\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86InstructPro\uff0c\u4e00\u79cd\u57fa\u4e8e\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u6765\u8bbe\u8ba1\u5177\u5907\u7279\u5b9a\u529f\u80fd\u86cb\u767d\u8d28\u7684\u751f\u6210\u6a21\u578b\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u4e00\u4e2a\u540d\u4e3aInstructProBench\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u6765\u8fdb\u884c\u8bad\u7ec3\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u8d85\u8fc7950\u4e07\u4e2a\u4e09\u5143\u7ec4\uff08\u529f\u80fd\u63cf\u8ff0\u3001\u914d\u4f53\u516c\u5f0f\u3001\u86cb\u767d\u8d28\u5e8f\u5217\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cInstructPro\u7684\u4e24\u4e2a\u7248\u672c\uff0810\u4ebf\u53c2\u6570\u548c30\u4ebf\u53c2\u6570\uff09\u5747\u4f18\u4e8e\u5305\u62ecProGen2\u3001ESM3\u53caPinal\u5728\u5185\u7684\u5f3a\u5927\u57fa\u7ebf\u6a21\u578b\u3002\u7279\u522b\u662f\uff0c\u5728\u4e2d\u7b49\u7f6e\u4fe1\u5ea6\u4e0bInstructPro-1B\u8fbe\u5230\u4e86\u6700\u9ad8\u7684\u5bf9\u63a5\u6210\u529f\u7387(81.52%)\u4ee5\u53ca\u6700\u4f4e\u7684\u5e73\u5747\u6839\u5747\u65b9\u5dee(RMSD, 4.026 \u00c5)\uff1b\u800cInstructPro-3B\u5219\u8fdb\u4e00\u6b65\u5c06RMSD\u964d\u81f32.527 \u00c5\u3002", "conclusion": "InstructPro\u5c55\u793a\u4e86\u5176\u4f9d\u636e\u7ed9\u5b9a\u7684\u529f\u80fd\u63cf\u8ff0\u548cSMILES\u683c\u5f0f\u7684\u914d\u4f53\u516c\u5f0f\u751f\u6210\u7b26\u5408\u8981\u6c42\u7684\u86cb\u767d\u8d28\u5e8f\u5217\u7684\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u51cf\u5c11\u751f\u6210\u7ed3\u6784\u4e0e\u771f\u5b9e\u7ed3\u6784\u4e4b\u95f4\u7684\u5dee\u5f02\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.09742", "pdf": "https://arxiv.org/pdf/2506.09742", "abs": "https://arxiv.org/abs/2506.09742", "authors": ["Gusseppe Bravo-Rocca", "Peini Liu", "Jordi Guitart", "Rodrigo M Carrillo-Larco", "Ajay Dholakia", "David Ellison"], "title": "Feature Engineering for Agents: An Adaptive Cognitive Architecture for Interpretable ML Monitoring", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at AAMAS 2025", "summary": "Monitoring Machine Learning (ML) models in production environments is\ncrucial, yet traditional approaches often yield verbose, low-interpretability\noutputs that hinder effective decision-making. We propose a cognitive\narchitecture for ML monitoring that applies feature engineering principles to\nagents based on Large Language Models (LLMs), significantly enhancing the\ninterpretability of monitoring outputs. Central to our approach is a Decision\nProcedure module that simulates feature engineering through three key steps:\nRefactor, Break Down, and Compile. The Refactor step improves data\nrepresentation to better capture feature semantics, allowing the LLM to focus\non salient aspects of the monitoring data while reducing noise and irrelevant\ninformation. Break Down decomposes complex information for detailed analysis,\nand Compile integrates sub-insights into clear, interpretable outputs. This\nprocess leads to a more deterministic planning approach, reducing dependence on\nLLM-generated planning, which can sometimes be inconsistent and overly general.\nThe combination of feature engineering-driven planning and selective LLM\nutilization results in a robust decision support system, capable of providing\nhighly interpretable and actionable insights. Experiments using multiple LLMs\ndemonstrate the efficacy of our approach, achieving significantly higher\naccuracy compared to various baselines across several domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8ba4\u77e5\u67b6\u6784\uff0c\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u76d1\u63a7\u3002\u8be5\u67b6\u6784\u901a\u8fc7\u7279\u5f81\u5de5\u7a0b\u539f\u5219\u6765\u63d0\u9ad8\u76d1\u63a7\u8f93\u51fa\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u901a\u8fc7\u91cd\u6784\u3001\u5206\u89e3\u548c\u7f16\u8bd1\u4e09\u4e2a\u6b65\u9aa4\u6765\u6a21\u62df\u7279\u5f81\u5de5\u7a0b\u3002\u8fd9\u79cd\u7ed3\u5408\u4e86\u7279\u5f81\u5de5\u7a0b\u9a71\u52a8\u89c4\u5212\u548c\u9009\u62e9\u6027LLM\u4f7f\u7528\u7684\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u9886\u57df\u4e2d\u4e0e\u5404\u79cd\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u76d1\u63a7\u65b9\u6cd5\u5f80\u5f80\u4ea7\u751f\u5197\u957f\u4e14\u96be\u4ee5\u89e3\u8bfb\u7684\u7ed3\u679c\uff0c\u8fd9\u963b\u788d\u4e86\u6709\u6548\u7684\u51b3\u7b56\u5236\u5b9a\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8ba4\u77e5\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u57fa\u7840\uff0c\u5e76\u5e94\u7528\u7279\u5f81\u5de5\u7a0b\u6280\u672f\u6765\u6539\u8fdb\u76d1\u63a7\u7ed3\u679c\u7684\u53ef\u89e3\u91ca\u6027\u3002\u8be5\u67b6\u6784\u5305\u62ec\u4e00\u4e2a\u51b3\u7b56\u7a0b\u5e8f\u6a21\u5757\uff0c\u5b83\u901a\u8fc7\u91cd\u6784\u3001\u5206\u89e3\u548c\u7f16\u8bd1\u4e09\u4e2a\u5173\u952e\u6b65\u9aa4\u6765\u6a21\u62df\u7279\u5f81\u5de5\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u591a\u4e2a\u9886\u57df\u4e2d\u76f8\u6bd4\u4e8e\u4e0d\u540c\u57fa\u7ebf\u6709\u7740\u663e\u8457\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u901a\u8fc7\u5c06\u7279\u5f81\u5de5\u7a0b\u9a71\u52a8\u7684\u89c4\u5212\u4e0e\u6709\u9009\u62e9\u6027\u7684LLM\u4f7f\u7528\u76f8\u7ed3\u5408\uff0c\u7814\u7a76\u8005\u5f00\u53d1\u51fa\u4e00\u79cd\u80fd\u591f\u63d0\u4f9b\u9ad8\u5ea6\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u884c\u89c1\u89e3\u7684\u5f3a\u5927\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u3002"}}
{"id": "2506.09769", "pdf": "https://arxiv.org/pdf/2506.09769", "abs": "https://arxiv.org/abs/2506.09769", "authors": ["Haruki Kainuma", "Takayuki Nishio"], "title": "Load-Aware Training Scheduling for Model Circulation-based Decentralized Federated Learning", "categories": ["cs.LG", "cs.AI"], "comment": "6 pages, submitted to IEEE Globecom 2025 (under review)", "summary": "This paper proposes Load-aware Tram-FL, an extension of Tram-FL that\nintroduces a training scheduling mechanism to minimize total training time in\ndecentralized federated learning by accounting for both computational and\ncommunication loads. The scheduling problem is formulated as a global\noptimization task, which-though intractable in its original form-is made\nsolvable by decomposing it into node-wise subproblems. To promote balanced data\nutilization under non-IID distributions, a variance constraint is introduced,\nwhile the overall training latency, including both computation and\ncommunication costs, is minimized through the objective function. Simulation\nresults on MNIST and CIFAR-10 demonstrate that Load-aware Tram-FL significantly\nreduces training time and accelerates convergence compared to baseline methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Load-aware Tram-FL\uff0c\u4e00\u79cd\u8003\u8651\u4e86\u8ba1\u7b97\u548c\u901a\u4fe1\u8d1f\u8f7d\u4ee5\u51cf\u5c11\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u4e2d\u603b\u8bad\u7ec3\u65f6\u95f4\u7684Tram-FL\u6269\u5c55\u3002\u901a\u8fc7\u5f15\u5165\u65b9\u5dee\u7ea6\u675f\u6765\u4fc3\u8fdb\u975eIID\u5206\u5e03\u4e0b\u7684\u5747\u8861\u6570\u636e\u5229\u7528\uff0c\u5e76\u901a\u8fc7\u76ee\u6807\u51fd\u6570\u6700\u5c0f\u5316\u603b\u4f53\u8bad\u7ec3\u5ef6\u8fdf\u3002\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u80fd\u663e\u8457\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\u548c\u52a0\u901f\u6536\u655b\u3002", "motivation": "\u4e3a\u4e86\u5728\u53bb\u4e2d\u5fc3\u5316\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e2d\u51cf\u5c11\u603b\u7684\u8bad\u7ec3\u65f6\u95f4\uff0c\u540c\u65f6\u8003\u8651\u5230\u8ba1\u7b97\u548c\u901a\u4fe1\u8d1f\u8f7d\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLoad-aware Tram-FL\u7684\u65b9\u6cd5\uff0c\u5b83\u5c06\u8c03\u5ea6\u95ee\u9898\u8868\u8ff0\u4e3a\u5168\u5c40\u4f18\u5316\u4efb\u52a1\uff0c\u5e76\u5c06\u5176\u5206\u89e3\u4e3a\u8282\u70b9\u7ea7\u522b\u7684\u5b50\u95ee\u9898\u6765\u89e3\u51b3\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5f15\u5165\u65b9\u5dee\u7ea6\u675f\u6765\u5904\u7406\u975eIID\u6570\u636e\u5206\u5e03\u7684\u95ee\u9898\u3002", "result": "\u5728MNIST\u548cCIFAR-10\u6570\u636e\u96c6\u4e0a\u7684\u6a21\u62df\u5b9e\u9a8c\u663e\u793a\uff0cLoad-aware Tram-FL\u76f8\u6bd4\u4e8e\u5176\u4ed6\u57fa\u7ebf\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u65f6\u95f4\u5e76\u52a0\u5feb\u6536\u655b\u901f\u5ea6\u3002", "conclusion": "Load-aware Tram-FL\u80fd\u591f\u5728\u53bb\u4e2d\u5fc3\u5316\u7684\u8054\u90a6\u5b66\u4e60\u4e2d\u6709\u6548\u51cf\u5c11\u8bad\u7ec3\u65f6\u95f4\uff0c\u540c\u65f6\u5bf9\u4e8e\u975eIID\u6570\u636e\u5206\u5e03\u60c5\u51b5\u4e5f\u80fd\u4fdd\u6301\u826f\u597d\u7684\u6027\u80fd\u3002"}}
{"id": "2506.09785", "pdf": "https://arxiv.org/pdf/2506.09785", "abs": "https://arxiv.org/abs/2506.09785", "authors": ["Alexander Marusov", "Alexander Yuhay", "Alexey Zaytsev"], "title": "A theoretical framework for self-supervised contrastive learning for continuous dependent data", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Self-supervised learning (SSL) has emerged as a powerful approach to learning\nrepresentations, particularly in the field of computer vision. However, its\napplication to dependent data, such as temporal and spatio-temporal domains,\nremains underexplored. Besides, traditional contrastive SSL methods often\nassume \\emph{semantic independence between samples}, which does not hold for\ndependent data exhibiting complex correlations. We propose a novel theoretical\nframework for contrastive SSL tailored to \\emph{continuous dependent data},\nwhich allows the nearest samples to be semantically close to each other. In\nparticular, we propose two possible \\textit{ground truth similarity measures}\nbetween objects -- \\emph{hard} and \\emph{soft} closeness. Under it, we derive\nan analytical form for the \\textit{estimated similarity matrix} that\naccommodates both types of closeness between samples, thereby introducing\ndependency-aware loss functions. We validate our approach, \\emph{Dependent\nTS2Vec}, on temporal and spatio-temporal downstream problems. Given the\ndependency patterns presented in the data, our approach surpasses modern ones\nfor dependent data, highlighting the effectiveness of our theoretically\ngrounded loss functions for SSL in capturing spatio-temporal dependencies.\nSpecifically, we outperform TS2Vec on the standard UEA and UCR benchmarks, with\naccuracy improvements of $4.17$\\% and $2.08$\\%, respectively. Furthermore, on\nthe drought classification task, which involves complex spatio-temporal\npatterns, our method achieves a $7$\\% higher ROC-AUC score.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u8fde\u7eed\u4f9d\u8d56\u6570\u636e\u7684\u5bf9\u6bd4\u81ea\u76d1\u7763\u5b66\u4e60\u7684\u65b0\u7406\u8bba\u6846\u67b6\uff0c\u5305\u62ec\u4e24\u79cd\u65b0\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u5728\u5904\u7406\u65f6\u7a7a\u4f9d\u8d56\u6027\u95ee\u9898\u4e0a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u65b9\u6cd5\u5728\u5904\u7406\u5177\u6709\u65f6\u95f4\u6216\u65f6\u7a7a\u4f9d\u8d56\u6027\u7684\u6570\u636e\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u5b83\u4eec\u901a\u5e38\u5047\u8bbe\u6837\u672c\u4e4b\u95f4\u662f\u8bed\u4e49\u72ec\u7acb\u7684\uff0c\u8fd9\u4e0e\u4f9d\u8d56\u6570\u636e\u4e2d\u590d\u6742\u7684\u5173\u8054\u5173\u7cfb\u4e0d\u7b26\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e13\u4e3a\u8fde\u7eed\u4f9d\u8d56\u6570\u636e\u8bbe\u8ba1\u7684\u5bf9\u6bd4SSL\u7406\u8bba\u6846\u67b6\uff0c\u5b9a\u4e49\u4e86\u4e24\u79cd\u5bf9\u8c61\u95f4\u53ef\u80fd\u7684\u2018\u771f\u5b9e\u76f8\u4f3c\u6027\u5ea6\u91cf\u2019\u2014\u2014\u786c\u63a5\u8fd1\u6027\u548c\u8f6f\u63a5\u8fd1\u6027\u3002\u57fa\u4e8e\u6b64\uff0c\u5bfc\u51fa\u4e86\u4e00\u4e2a\u80fd\u591f\u540c\u65f6\u9002\u5e94\u8fd9\u4e24\u79cd\u63a5\u8fd1\u6027\u7684\u4f30\u8ba1\u76f8\u4f3c\u6027\u77e9\u9635\uff0c\u4ece\u800c\u5f15\u5165\u4e86\u4f9d\u8d56\u611f\u77e5\u7684\u635f\u5931\u51fd\u6570\u3002", "result": "\u63d0\u51fa\u7684Dependent TS2Vec\u65b9\u6cd5\u5728\u6807\u51c6UEA\u548cUCR\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5206\u522b\u63d0\u9ad8\u4e864.17%\u548c2.08%\u7684\u51c6\u786e\u7387\uff0c\u5728\u6d89\u53ca\u590d\u6742\u65f6\u7a7a\u6a21\u5f0f\u7684\u5e72\u65f1\u5206\u7c7b\u4efb\u52a1\u4e0a\uff0cROC-AUC\u5f97\u5206\u63d0\u9ad8\u4e867%\u3002", "conclusion": "\u8be5\u7814\u7a76\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u7406\u8bba\u652f\u6301\u7684\u635f\u5931\u51fd\u6570\u5bf9\u4e8e\u6355\u6349\u65f6\u7a7a\u4f9d\u8d56\u6027\u975e\u5e38\u6709\u6548\uff0c\u65b0\u65b9\u6cd5\u5728\u591a\u4e2a\u4f9d\u8d56\u6570\u636e\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5f53\u524d\u65b9\u6cd5\u3002"}}
{"id": "2506.09862", "pdf": "https://arxiv.org/pdf/2506.09862", "abs": "https://arxiv.org/abs/2506.09862", "authors": ["Mikel Casals", "Vasilis Belis", "Elias F. Combarro", "Eduard Alarc\u00f3n", "Sofia Vallecorsa", "Michele Grossi"], "title": "Guided Graph Compression for Quantum Graph Neural Networks", "categories": ["cs.LG", "cs.AI", "hep-ex", "quant-ph"], "comment": null, "summary": "Graph Neural Networks (GNNs) are effective for processing graph-structured\ndata but face challenges with large graphs due to high memory requirements and\ninefficient sparse matrix operations on GPUs. Quantum Computing (QC) offers a\npromising avenue to address these issues and inspires new algorithmic\napproaches. In particular, Quantum Graph Neural Networks (QGNNs) have been\nexplored in recent literature. However, current quantum hardware limits the\ndimension of the data that can be effectively encoded. Existing approaches\neither simplify datasets manually or use artificial graph datasets. This work\nintroduces the Guided Graph Compression (GGC) framework, which uses a graph\nautoencoder to reduce both the number of nodes and the dimensionality of node\nfeatures. The compression is guided to enhance the performance of a downstream\nclassification task, which can be applied either with a quantum or a classical\nclassifier. The framework is evaluated on the Jet Tagging task, a\nclassification problem of fundamental importance in high energy physics that\ninvolves distinguishing particle jets initiated by quarks from those by gluons.\nThe GGC is compared against using the autoencoder as a standalone preprocessing\nstep and against a baseline classical GNN classifier. Our numerical results\ndemonstrate that GGC outperforms both alternatives, while also facilitating the\ntesting of novel QGNN ansatzes on realistic datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6307\u5bfc\u56fe\u538b\u7f29\uff08GGC\uff09\u6846\u67b6\uff0c\u5b83\u4f7f\u7528\u56fe\u81ea\u52a8\u7f16\u7801\u5668\u6765\u51cf\u5c11\u8282\u70b9\u6570\u91cf\u548c\u8282\u70b9\u7279\u5f81\u7684\u7ef4\u5ea6\uff0c\u4ece\u800c\u63d0\u9ad8\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u6027\u80fd\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e0e\u91cf\u5b50\u6216\u7ecf\u5178\u5206\u7c7b\u5668\u4e00\u8d77\u4f7f\u7528\u3002\u5728\u9ad8\u80fd\u7269\u7406\u4e2d\u7684\u55b7\u5c04\u6807\u8bb0\u4efb\u52a1\u4e0a\u6d4b\u8bd5\u4e86\u8be5\u6846\u67b6\uff0c\u7ed3\u679c\u8868\u660eGGC\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u81ea\u52a8\u7f16\u7801\u5668\u9884\u5904\u7406\u6b65\u9aa4\u4ee5\u53ca\u57fa\u7ebf\u7ecf\u5178GNN\u5206\u7c7b\u5668\uff0c\u5e76\u6709\u52a9\u4e8e\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u65b0\u7684QGNN\u5047\u8bbe\u3002", "motivation": "\u56fe\u795e\u7ecf\u7f51\u7edc\uff08GNNs\uff09\u5728\u5904\u7406\u56fe\u7ed3\u6784\u6570\u636e\u65b9\u9762\u6709\u6548\uff0c\u4f46\u5728\u5904\u7406\u5927\u578b\u56fe\u65f6\u4f1a\u9047\u5230\u5185\u5b58\u9700\u6c42\u9ad8\u548cGPU\u4e0a\u7a00\u758f\u77e9\u9635\u64cd\u4f5c\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002\u91cf\u5b50\u8ba1\u7b97\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u5e0c\u671b\u7684\u65b9\u5411\uff0c\u5e76\u6fc0\u53d1\u4e86\u65b0\u7684\u7b97\u6cd5\u65b9\u6cd5\u3002\u7279\u522b\u662f\uff0c\u6700\u8fd1\u7684\u6587\u732e\u63a2\u8ba8\u4e86\u91cf\u5b50\u56fe\u795e\u7ecf\u7f51\u7edc\uff08QGNNs\uff09\u3002\u7136\u800c\uff0c\u5f53\u524d\u7684\u91cf\u5b50\u786c\u4ef6\u9650\u5236\u4e86\u53ef\u6709\u6548\u7f16\u7801\u7684\u6570\u636e\u7ef4\u5ea6\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u624b\u52a8\u7b80\u5316\u6570\u636e\u96c6\uff0c\u8981\u4e48\u4f7f\u7528\u4eba\u5de5\u56fe\u6570\u636e\u96c6\u3002", "method": "\u5f15\u5165\u4e86\u6307\u5bfc\u56fe\u538b\u7f29\uff08GGC\uff09\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u56fe\u81ea\u52a8\u7f16\u7801\u5668\u6765\u540c\u65f6\u51cf\u5c11\u8282\u70b9\u7684\u6570\u91cf\u548c\u8282\u70b9\u7279\u5f81\u7684\u7ef4\u5ea6\u3002\u8fd9\u79cd\u538b\u7f29\u662f\u4e3a\u4e86\u589e\u5f3a\u4e0b\u6e38\u5206\u7c7b\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u53ef\u4ee5\u5e94\u7528\u4e8e\u91cf\u5b50\u6216\u7ecf\u5178\u5206\u7c7b\u5668\u3002", "result": "GGC\u6846\u67b6\u5728Jet Tagging\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u8fd9\u662f\u4e00\u4e2a\u533a\u5206\u7531\u5938\u514b\u5f15\u8d77\u7684\u7c92\u5b50\u55b7\u5c04\u548c\u7531\u80f6\u5b50\u5f15\u8d77\u7684\u7c92\u5b50\u55b7\u5c04\u7684\u91cd\u8981\u5206\u7c7b\u95ee\u9898\u3002GGC\u7684\u8868\u73b0\u8d85\u8fc7\u4e86\u5c06\u81ea\u52a8\u7f16\u7801\u5668\u4f5c\u4e3a\u72ec\u7acb\u9884\u5904\u7406\u6b65\u9aa4\u4f7f\u7528\u7684\u60c5\u51b5\uff0c\u4e5f\u8d85\u8fc7\u4e86\u7ecf\u5178\u7684GNN\u5206\u7c7b\u5668\u57fa\u7ebf\u3002\u6b64\u5916\uff0cGGC\u8fd8\u4fc3\u8fdb\u4e86\u65b0\u9896QGNN\u65b9\u6848\u5728\u73b0\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u6d4b\u8bd5\u3002", "conclusion": "\u6307\u5bfc\u56fe\u538b\u7f29\uff08GGC\uff09\u6846\u67b6\u901a\u8fc7\u51cf\u5c11\u56fe\u7684\u89c4\u6a21\u548c\u7279\u5f81\u7ef4\u5ea6\uff0c\u5728\u4fdd\u6301\u751a\u81f3\u63d0\u9ad8\u5206\u7c7b\u6027\u80fd\u7684\u540c\u65f6\uff0c\u4f7f\u91cf\u5b50\u56fe\u795e\u7ecf\u7f51\u7edc\u80fd\u591f\u5728\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002"}}
{"id": "2506.09891", "pdf": "https://arxiv.org/pdf/2506.09891", "abs": "https://arxiv.org/abs/2506.09891", "authors": ["Sebastian Hickman", "Ilija Trajkovic", "Julia Kaltenborn", "Francis Pelletier", "Alex Archibald", "Yaniv Gurwicz", "Peer Nowack", "David Rolnick", "Julien Boussard"], "title": "Causal Climate Emulation with Bayesian Filtering", "categories": ["cs.LG", "cs.AI", "cs.CE", "physics.ao-ph"], "comment": "32 pages, 21 figures", "summary": "Traditional models of climate change use complex systems of coupled equations\nto simulate physical processes across the Earth system. These simulations are\nhighly computationally expensive, limiting our predictions of climate change\nand analyses of its causes and effects. Machine learning has the potential to\nquickly emulate data from climate models, but current approaches are not able\nto incorporate physics-informed causal relationships. Here, we develop an\ninterpretable climate model emulator based on causal representation learning.\nWe derive a physics-informed approach including a Bayesian filter for stable\nlong-term autoregressive emulation. We demonstrate that our emulator learns\naccurate climate dynamics, and we show the importance of each one of its\ncomponents on a realistic synthetic dataset and data from two widely deployed\nclimate models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56e0\u679c\u8868\u793a\u5b66\u4e60\u7684\u53ef\u89e3\u91ca\u6c14\u5019\u6a21\u578b\u6a21\u62df\u5668\uff0c\u8be5\u6a21\u62df\u5668\u80fd\u591f\u901a\u8fc7\u7269\u7406\u4fe1\u606f\u65b9\u6cd5\u548c\u8d1d\u53f6\u65af\u6ee4\u6ce2\u5668\u6765\u51c6\u786e\u5b66\u4e60\u6c14\u5019\u52a8\u6001\uff0c\u5e76\u5728\u5408\u6210\u6570\u636e\u96c6\u53ca\u4e24\u4e2a\u5e7f\u6cdb\u5e94\u7528\u7684\u6c14\u5019\u6a21\u578b\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u5176\u5404\u7ec4\u4ef6\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u6c14\u5019\u53d8\u5316\u6a21\u578b\u4f7f\u7528\u590d\u6742\u7684\u8026\u5408\u65b9\u7a0b\u7cfb\u7edf\u6765\u6a21\u62df\u5730\u7403\u7cfb\u7edf\u7684\u7269\u7406\u8fc7\u7a0b\uff0c\u8fd9\u4e9b\u6a21\u62df\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9650\u5236\u4e86\u6211\u4eec\u5bf9\u6c14\u5019\u53d8\u5316\u7684\u9884\u6d4b\u53ca\u5176\u539f\u56e0\u548c\u5f71\u54cd\u7684\u5206\u6790\u3002\u673a\u5668\u5b66\u4e60\u6709\u6f5c\u529b\u5feb\u901f\u6a21\u62df\u6c14\u5019\u6a21\u578b\u7684\u6570\u636e\uff0c\u4f46\u73b0\u6709\u7684\u65b9\u6cd5\u65e0\u6cd5\u7eb3\u5165\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684\u56e0\u679c\u5173\u7cfb\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u56e0\u679c\u8868\u793a\u5b66\u4e60\u7684\u53ef\u89e3\u91ca\u6c14\u5019\u6a21\u578b\u6a21\u62df\u5668\uff0c\u5176\u4e2d\u5305\u542b\u4e00\u4e2a\u7528\u4e8e\u957f\u671f\u81ea\u56de\u5f52\u6a21\u62df\u7a33\u5b9a\u7684\u8d1d\u53f6\u65af\u6ee4\u6ce2\u5668\u3002", "result": "\u6240\u63d0\u51fa\u7684\u6a21\u62df\u5668\u80fd\u591f\u51c6\u786e\u5730\u5b66\u4e60\u6c14\u5019\u52a8\u6001\uff0c\u5e76\u4e14\u5728\u73b0\u5b9e\u7684\u5408\u6210\u6570\u636e\u96c6\u4ee5\u53ca\u6765\u81ea\u4e24\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u6c14\u5019\u6a21\u578b\u7684\u6570\u636e\u4e2d\u5c55\u793a\u4e86\u6bcf\u4e2a\u7ec4\u4ef6\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u548c\u56e0\u679c\u5173\u7cfb\uff0c\u6240\u5f00\u53d1\u7684\u6c14\u5019\u6a21\u578b\u6a21\u62df\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u5f0f\u6765\u63d0\u9ad8\u6c14\u5019\u9884\u6d4b\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2506.09376", "pdf": "https://arxiv.org/pdf/2506.09376", "abs": "https://arxiv.org/abs/2506.09376", "authors": ["Bowen Zheng", "Tianming Yang"], "title": "Revisiting Diffusion Models: From Generative Pre-training to One-Step Generation", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Diffusion distillation is a widely used technique to reduce the sampling cost\nof diffusion models, yet it often requires extensive training, and the student\nperformance tends to be degraded. Recent studies show that incorporating a GAN\nobjective may alleviate these issues, yet the underlying mechanism remains\nunclear. In this work, we first identify a key limitation of distillation:\nmismatched step sizes and parameter numbers between the teacher and the student\nmodel lead them to converge to different local minima, rendering direct\nimitation suboptimal. We further demonstrate that a standalone GAN objective,\nwithout relying a distillation loss, overcomes this limitation and is\nsufficient to convert diffusion models into efficient one-step generators.\nBased on this finding, we propose that diffusion training may be viewed as a\nform of generative pre-training, equipping models with capabilities that can be\nunlocked through lightweight GAN fine-tuning. Supporting this view, we create a\none-step generation model by fine-tuning a pre-trained model with 85% of\nparameters frozen, achieving strong performance with only 0.2M images and\nnear-SOTA results with 5M images. We further present a frequency-domain\nanalysis that may explain the one-step generative capability gained in\ndiffusion training. Overall, our work provides a new perspective for diffusion\ntraining, highlighting its role as a powerful generative pre-training process,\nwhich can be the basis for building efficient one-step generation models.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u6269\u6563\u84b8\u998f\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4f7f\u7528\u72ec\u7acb\u7684GAN\u76ee\u6807\u53ef\u4ee5\u514b\u670d\u8fd9\u4e9b\u95ee\u9898\uff0c\u5c06\u6269\u6563\u6a21\u578b\u8f6c\u6362\u4e3a\u9ad8\u6548\u7684\u4e00\u6b65\u751f\u6210\u5668\u3002\u901a\u8fc7\u51bb\u7ed3\u5927\u90e8\u5206\u53c2\u6570\u7684\u5fae\u8c03\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u53ea\u9700\u5c11\u91cf\u56fe\u50cf\u5373\u53ef\u83b7\u5f97\u5f3a\u5927\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u6269\u6563\u84b8\u998f\u6280\u672f\u5b58\u5728\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u4e14\u5b66\u751f\u6a21\u578b\u8868\u73b0\u4e0b\u964d\u7684\u95ee\u9898\u3002\u5c3d\u7ba1\u7ed3\u5408GAN\u76ee\u6807\u53ef\u80fd\u6709\u6240\u5e2e\u52a9\uff0c\u4f46\u5176\u80cc\u540e\u7684\u673a\u5236\u5c1a\u672a\u660e\u786e\u3002", "method": "\u7814\u7a76\u8005\u9996\u5148\u8bc6\u522b\u51fa\u84b8\u998f\u7684\u4e00\u4e2a\u5173\u952e\u9650\u5236\uff1a\u6559\u5e08\u548c\u5b66\u751f\u6a21\u578b\u4e4b\u95f4\u7684\u6b65\u957f\u548c\u53c2\u6570\u6570\u91cf\u4e0d\u5339\u914d\u5bfc\u81f4\u5b83\u4eec\u6536\u655b\u5230\u4e0d\u540c\u7684\u5c40\u90e8\u6700\u5c0f\u503c\u3002\u8fdb\u4e00\u6b65\u8bc1\u660e\uff0c\u4e00\u4e2a\u72ec\u7acb\u7684GAN\u76ee\u6807\u65e0\u9700\u4f9d\u8d56\u84b8\u998f\u635f\u5931\u4fbf\u8db3\u4ee5\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u5e76\u80fd\u591f\u5c06\u6269\u6563\u6a21\u578b\u8f6c\u53d8\u4e3a\u9ad8\u6548\u7684\u5355\u6b65\u751f\u6210\u5668\u3002\u57fa\u4e8e\u6b64\u53d1\u73b0\uff0c\u63d0\u51fa\u4e86\u6269\u6563\u8bad\u7ec3\u53ef\u88ab\u89c6\u4e3a\u4e00\u79cd\u751f\u6210\u9884\u8bad\u7ec3\u5f62\u5f0f\u7684\u89c2\u70b9\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5bf9\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff08\u5176\u4e2d85%\u7684\u53c2\u6570\u88ab\u51bb\u7ed3\uff09\uff0c\u4ec5\u75280.2M\u5f20\u56fe\u7247\u5c31\u5b9e\u73b0\u4e86\u5f3a\u52b2\u7684\u8868\u73b0\uff0c\u5e76\u5728\u4f7f\u75285M\u5f20\u56fe\u7247\u65f6\u63a5\u8fd1SOTA\u7ed3\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7GAN\u76ee\u6807\u5bf9\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u8f7b\u91cf\u7ea7\u5fae\u8c03\uff0c\u5373\u4f7f\u53ea\u7528\u5c11\u91cf\u6570\u636e\u4e5f\u80fd\u8fbe\u5230\u5f88\u597d\u7684\u751f\u6210\u6548\u679c\u3002\u9891\u7387\u57df\u5206\u6790\u8fdb\u4e00\u6b65\u89e3\u91ca\u4e86\u4e00\u6b65\u751f\u6210\u80fd\u529b\u7684\u83b7\u5f97\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u4f9b\u4e86\u5173\u4e8e\u6269\u6563\u8bad\u7ec3\u7684\u65b0\u89c6\u89d2\uff0c\u5f3a\u8c03\u4e86\u5b83\u4f5c\u4e3a\u5f3a\u6709\u529b\u7684\u751f\u6210\u9884\u8bad\u7ec3\u8fc7\u7a0b\u7684\u89d2\u8272\uff0c\u8fd9\u53ef\u4ee5\u6210\u4e3a\u6784\u5efa\u9ad8\u6548\u4e00\u6b65\u751f\u6210\u6a21\u578b\u7684\u57fa\u7840\u3002"}}
{"id": "2506.09398", "pdf": "https://arxiv.org/pdf/2506.09398", "abs": "https://arxiv.org/abs/2506.09398", "authors": ["Haiyang Yu", "Yuchao Lin", "Xuan Zhang", "Xiaofeng Qian", "Shuiwang Ji"], "title": "Efficient Prediction of SO(3)-Equivariant Hamiltonian Matrices via SO(2) Local Frames", "categories": ["cs.LG", "physics.comp-ph"], "comment": "Code available at: https://github.com/divelab/AIRS", "summary": "We consider the task of predicting Hamiltonian matrices to accelerate\nelectronic structure calculations, which plays an important role in physics,\nchemistry, and materials science. Motivated by the inherent relationship\nbetween the off-diagonal blocks of the Hamiltonian matrix and the SO(2) local\nframe, we propose a novel and efficient network, called QHNetV2, that achieves\nglobal SO(3) equivariance without the costly SO(3) Clebsch-Gordan tensor\nproducts. This is achieved by introducing a set of new efficient and powerful\nSO(2)-equivariant operations and performing all off-diagonal feature updates\nand message passing within SO(2) local frames, thereby eliminating the need of\nSO(3) tensor products. Moreover, a continuous SO(2) tensor product is performed\nwithin the SO(2) local frame at each node to fuse node features, mimicking the\nsymmetric contraction operation. Extensive experiments on the large QH9 and\nMD17 datasets demonstrate that our model achieves superior performance across a\nwide range of molecular structures and trajectories, highlighting its strong\ngeneralization capability. The proposed SO(2) operations on SO(2) local frames\noffer a promising direction for scalable and symmetry-aware learning of\nelectronic structures. Our code will be released as part of the AIRS library\nhttps://github.com/divelab/AIRS.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6709\u6548\u7f51\u7edcQHNetV2\uff0c\u8be5\u7f51\u7edc\u901a\u8fc7SO(2)\u7b49\u53d8\u64cd\u4f5c\u548c\u5c40\u90e8\u6846\u67b6\u5185\u7684\u7279\u5f81\u66f4\u65b0\u6765\u5b9e\u73b0\u5168\u5c40SO(3)\u7b49\u53d8\u6027\uff0c\u4ece\u800c\u52a0\u901f\u54c8\u5bc6\u987f\u77e9\u9635\u9884\u6d4b\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u6a21\u578b\u5728\u5e7f\u6cdb\u7684\u5206\u5b50\u7ed3\u6784\u548c\u8f68\u8ff9\u4e0a\u5177\u6709\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u52a0\u901f\u7535\u5b50\u7ed3\u6784\u8ba1\u7b97\u4e2d\u7684\u54c8\u5bc6\u987f\u77e9\u9635\u9884\u6d4b\uff0c\u540c\u65f6\u907f\u514d\u6602\u8d35\u7684SO(3) Clebsch-Gordan\u5f20\u91cf\u79ef\u8ba1\u7b97\u3002", "method": "\u8bbe\u8ba1\u4e86\u540d\u4e3aQHNetV2\u7684\u65b0\u7f51\u7edc\uff0c\u8be5\u7f51\u7edc\u5f15\u5165\u4e86\u65b0\u7684\u9ad8\u6548\u4e14\u529f\u80fd\u5f3a\u5927\u7684SO(2)\u7b49\u53d8\u64cd\u4f5c\uff0c\u5e76\u5728SO(2)\u5c40\u90e8\u6846\u67b6\u5185\u6267\u884c\u6240\u6709\u975e\u5bf9\u89d2\u7279\u5f81\u66f4\u65b0\u548c\u6d88\u606f\u4f20\u9012\uff0c\u4ee5\u53ca\u5728\u6bcf\u4e2a\u8282\u70b9\u4e0a\u7684\u8fde\u7eedSO(2)\u5f20\u91cf\u79ef\u4ee5\u878d\u5408\u8282\u70b9\u7279\u5f81\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728QH9\u548cMD17\u5927\u578b\u6570\u636e\u96c6\u4e0a\u5bf9\u4e8e\u591a\u79cd\u5206\u5b50\u7ed3\u6784\u548c\u8f68\u8ff9\u90fd\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u6027\u80fd\uff0c\u663e\u793a\u51fa\u5176\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SO(2)\u5c40\u90e8\u6846\u67b6\u4e0a\u7684SO(2)\u64cd\u4f5c\u4e3a\u53ef\u6269\u5c55\u4e14\u5bf9\u79f0\u610f\u8bc6\u7684\u7535\u5b50\u7ed3\u6784\u5b66\u4e60\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2506.09404", "pdf": "https://arxiv.org/pdf/2506.09404", "abs": "https://arxiv.org/abs/2506.09404", "authors": ["Shengda Gu", "Kai Li", "Junliang Xing", "Yifan Zhang", "Jian Cheng"], "title": "Synergizing Reinforcement Learning and Genetic Algorithms for Neural Combinatorial Optimization", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Combinatorial optimization problems are notoriously challenging due to their\ndiscrete structure and exponentially large solution space. Recent advances in\ndeep reinforcement learning (DRL) have enabled the learning heuristics directly\nfrom data. However, DRL methods often suffer from limited exploration and\nsusceptibility to local optima. On the other hand, evolutionary algorithms such\nas Genetic Algorithms (GAs) exhibit strong global exploration capabilities but\nare typically sample inefficient and computationally intensive. In this work,\nwe propose the Evolutionary Augmentation Mechanism (EAM), a general and\nplug-and-play framework that synergizes the learning efficiency of DRL with the\nglobal search power of GAs. EAM operates by generating solutions from a learned\npolicy and refining them through domain-specific genetic operations such as\ncrossover and mutation. These evolved solutions are then selectively reinjected\ninto the policy training loop, thereby enhancing exploration and accelerating\nconvergence. We further provide a theoretical analysis that establishes an\nupper bound on the KL divergence between the evolved solution distribution and\nthe policy distribution, ensuring stable and effective policy updates. EAM is\nmodel-agnostic and can be seamlessly integrated with state-of-the-art DRL\nsolvers such as the Attention Model, POMO, and SymNCO. Extensive results on\nbenchmark problems (e.g., TSP, CVRP, PCTSP, and OP) demonstrate that EAM\nsignificantly improves both solution quality and training efficiency over\ncompetitive baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u8fdb\u5316\u589e\u5f3a\u673a\u5236\uff08EAM\uff09\uff0c\u4e00\u79cd\u7ed3\u5408\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u5b66\u4e60\u6548\u7387\u548c\u9057\u4f20\u7b97\u6cd5\u5168\u5c40\u641c\u7d22\u80fd\u529b\u7684\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u53ca\u57fa\u51c6\u6d4b\u8bd5\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u4e2d\u7684\u79bb\u6563\u7ed3\u6784\u548c\u6307\u6570\u7ea7\u89e3\u7a7a\u95f4\u6240\u5e26\u6765\u7684\u6311\u6218\uff0c\u540c\u65f6\u514b\u670d\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u63a2\u7d22\u6709\u9650\u4ee5\u53ca\u6613\u9677\u5165\u5c40\u90e8\u6700\u4f18\u7684\u95ee\u9898\uff0c\u5e76\u7ed3\u5408\u9057\u4f20\u7b97\u6cd5\u5168\u7403\u63a2\u7d22\u80fd\u529b\u5f3a\u4f46\u6837\u672c\u6548\u7387\u4f4e\u3001\u8ba1\u7b97\u5bc6\u96c6\u7684\u7279\u70b9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u8fdb\u5316\u589e\u5f3a\u673a\u5236(EAM)\u7684\u901a\u7528\u5373\u63d2\u5373\u7528\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5c06\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60(DRL)\u7684\u5b66\u4e60\u6548\u7387\u4e0e\u9057\u4f20\u7b97\u6cd5(GA)\u7684\u5168\u5c40\u641c\u7d22\u80fd\u529b\u76f8\u7ed3\u5408\u3002EAM\u901a\u8fc7\u4ece\u5b66\u4e60\u7b56\u7565\u751f\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5229\u7528\u9886\u57df\u7279\u5b9a\u7684\u9057\u4f20\u64cd\u4f5c\u5982\u4ea4\u53c9\u548c\u53d8\u5f02\u6765\u6539\u8fdb\u8fd9\u4e9b\u65b9\u6848\u3002", "result": "\u5728\u5305\u62ecTSP\u3001CVRP\u3001PCTSP\u548cOP\u5728\u5185\u7684\u57fa\u51c6\u95ee\u9898\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u6d4b\u8bd5\uff0c\u7ed3\u679c\u8868\u660eEAM\u76f8\u8f83\u4e8e\u5176\u4ed6\u7ade\u4e89\u57fa\u7ebf\u663e\u8457\u63d0\u9ad8\u4e86\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u548c\u8bad\u7ec3\u6548\u7387\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u5173\u4e8e\u6f14\u5316\u89e3\u5206\u5e03\u4e0e\u7b56\u7565\u5206\u5e03\u4e4b\u95f4KL\u6563\u5ea6\u4e0a\u9650\u7684\u7406\u8bba\u5206\u6790\u3002", "conclusion": "EAM\u4f5c\u4e3a\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u6700\u5148\u8fdb\u7684DRL\u6c42\u89e3\u5668\u4e2d\uff0c\u5b83\u4e0d\u4ec5\u589e\u5f3a\u4e86\u63a2\u7d22\u8fd8\u52a0\u901f\u4e86\u6536\u655b\u8fc7\u7a0b\uff0c\u4ece\u800c\u6709\u6548\u63d0\u5347\u4e86\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u6c42\u89e3\u6027\u80fd\u3002"}}
{"id": "2506.09433", "pdf": "https://arxiv.org/pdf/2506.09433", "abs": "https://arxiv.org/abs/2506.09433", "authors": ["Shurui Gui", "Shuiwang Ji"], "title": "Mitigating Spurious Correlations in LLMs via Causality-Aware Post-Training", "categories": ["cs.LG"], "comment": null, "summary": "While large language models (LLMs) have demonstrated remarkable capabilities\nin language modeling, recent studies reveal that they often fail on\nout-of-distribution (OOD) samples due to spurious correlations acquired during\npre-training. Here, we aim to mitigate such spurious correlations through\ncausality-aware post-training (CAPT). By decomposing a biased prediction into\ntwo unbiased steps, known as \\textit{event estimation} and \\textit{event\nintervention}, we reduce LLMs' pre-training biases without incurring additional\nfine-tuning biases, thus enhancing the model's generalization ability.\nExperiments on the formal causal inference benchmark CLadder and the logical\nreasoning dataset PrOntoQA show that 3B-scale language models fine-tuned with\nCAPT can outperform both traditional SFT and larger LLMs on in-distribution\n(ID) and OOD tasks using only 100 ID fine-tuning samples, demonstrating the\neffectiveness and sample efficiency of CAPT.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u901a\u8fc7\u56e0\u679c\u610f\u8bc6\u540e\u8bad\u7ec3\uff08CAPT\uff09\u6765\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u83b7\u5f97\u7684\u865a\u5047\u76f8\u5173\u6027\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528CAPT\u5fae\u8c03\u76843B\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u5728\u4ec5\u4f7f\u7528100\u4e2a\u540c\u5206\u5e03\u5fae\u8c03\u6837\u672c\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u540c\u5206\u5e03\u548c\u5f02\u5206\u5e03\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4f20\u7edfSFT\u548c\u66f4\u5927\u89c4\u6a21\u7684LLMs\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ecf\u5e38\u5728\u5904\u7406\u5f02\u5206\u5e03\uff08OOD\uff09\u6837\u672c\u65f6\u5931\u8d25\uff0c\u56e0\u4e3a\u5b83\u4eec\u5728\u9884\u8bad\u7ec3\u671f\u95f4\u5b66\u4e60\u5230\u4e86\u865a\u5047\u7684\u76f8\u5173\u6027\u3002\u4e3a\u4e86\u7f13\u89e3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u56e0\u679c\u610f\u8bc6\u540e\u8bad\u7ec3\uff08CAPT\uff09\u7684\u65b9\u6cd5\u6765\u51cf\u5c11\u8fd9\u4e9b\u865a\u5047\u76f8\u5173\u6027\uff0c\u5e76\u589e\u5f3a\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5c06\u4e00\u4e2a\u5e26\u6709\u504f\u89c1\u7684\u9884\u6d4b\u5206\u89e3\u4e3a\u4e24\u4e2a\u65e0\u504f\u89c1\u7684\u6b65\u9aa4\u2014\u2014\u4e8b\u4ef6\u4f30\u8ba1\u548c\u4e8b\u4ef6\u5e72\u9884\uff0c\u7814\u7a76\u8005\u5b9e\u73b0\u4e86\u56e0\u679c\u610f\u8bc6\u540e\u8bad\u7ec3\uff08CAPT\uff09\u3002\u8be5\u65b9\u6cd5\u65e8\u5728\u51cf\u5c11LLMs\u5728\u9884\u8bad\u7ec3\u4e2d\u4ea7\u751f\u7684\u504f\u89c1\uff0c\u540c\u65f6\u907f\u514d\u5f15\u5165\u989d\u5916\u7684\u5fae\u8c03\u504f\u89c1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5f62\u5f0f\u5316\u7684\u56e0\u679c\u63a8\u7406\u57fa\u51c6CLadder\u548c\u903b\u8f91\u63a8\u7406\u6570\u636e\u96c6PrOntoQA\u4e0a\uff0c\u91c7\u7528CAPT\u8fdb\u884c\u5fae\u8c03\u76843B\u7ea7\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u53ea\u7528100\u4e2a\u540c\u5206\u5e03\u5fae\u8c03\u6837\u672c\u5c31\u5728\u540c\u5206\u5e03\u548c\u5f02\u5206\u5e03\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7684SFT\u548c\u66f4\u5927\u7684LLMs\u3002", "conclusion": "\u56e0\u679c\u610f\u8bc6\u540e\u8bad\u7ec3\uff08CAPT\uff09\u88ab\u8bc1\u660e\u662f\u4e00\u79cd\u6709\u6548\u4e14\u6837\u672c\u6548\u7387\u9ad8\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u7528\u4e8e\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u865a\u5047\u76f8\u5173\u6027\uff0c\u8fdb\u800c\u63d0\u9ad8\u6a21\u578b\u5bf9\u540c\u5206\u5e03\u53ca\u5f02\u5206\u5e03\u4efb\u52a1\u7684\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2506.09438", "pdf": "https://arxiv.org/pdf/2506.09438", "abs": "https://arxiv.org/abs/2506.09438", "authors": ["Haoxiang Ye", "Tao Sun", "Qing Ling"], "title": "Generalization Error Analysis for Attack-Free and Byzantine-Resilient Decentralized Learning with Data Heterogeneity", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Decentralized learning, which facilitates joint model training across\ngeographically scattered agents, has gained significant attention in the field\nof signal and information processing in recent years. While the optimization\nerrors of decentralized learning algorithms have been extensively studied,\ntheir generalization errors remain relatively under-explored. As the\ngeneralization errors reflect the scalability of trained models on unseen data\nand are crucial in determining the performance of trained models in real-world\napplications, understanding the generalization errors of decentralized learning\nis of paramount importance. In this paper, we present fine-grained\ngeneralization error analysis for both attack-free and Byzantine-resilient\ndecentralized learning with heterogeneous data as well as under mild\nassumptions, in contrast to prior studies that consider homogeneous data and/or\nrely on a stringent bounded stochastic gradient assumption. Our results shed\nlight on the impact of data heterogeneity, model initialization and stochastic\ngradient noise -- factors that have not been closely investigated before -- on\nthe generalization error of decentralized learning. We also reveal that\nByzantine attacks performed by malicious agents largely affect the\ngeneralization error, and their negative impact is inherently linked to the\ndata heterogeneity while remaining independent on the sample size. Numerical\nexperiments on both convex and non-convex tasks are conducted to validate our\ntheoretical findings.", "AI": {"tldr": "\u672c\u6587\u5bf9\u65e0\u653b\u51fb\u548c\u62dc\u5360\u5ead\u5bb9\u9519\u7684\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u8fdb\u884c\u4e86\u7ec6\u81f4\u7684\u6cdb\u5316\u8bef\u5dee\u5206\u6790\uff0c\u8003\u8651\u4e86\u5f02\u6784\u6570\u636e\u5e76\u5728\u8f83\u5bbd\u677e\u7684\u5047\u8bbe\u6761\u4ef6\u4e0b\u8fdb\u884c\u3002\u7814\u7a76\u63ed\u793a\u4e86\u6570\u636e\u5f02\u8d28\u6027\u3001\u6a21\u578b\u521d\u59cb\u5316\u548c\u968f\u673a\u68af\u5ea6\u566a\u58f0\u5bf9\u6cdb\u5316\u8bef\u5dee\u7684\u5f71\u54cd\uff0c\u5e76\u6307\u51fa\u6076\u610f\u4ee3\u7406\u6267\u884c\u7684\u62dc\u5360\u5ead\u653b\u51fb\u5bf9\u6cdb\u5316\u8bef\u5dee\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e14\u8be5\u8d1f\u9762\u5f71\u54cd\u4e0e\u6837\u672c\u91cf\u65e0\u5173\u3002", "motivation": "\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u5728\u4fe1\u53f7\u548c\u4fe1\u606f\u5904\u7406\u9886\u57df\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\uff0c\u4f46\u5176\u6cdb\u5316\u8bef\u5dee\u76f8\u5bf9\u8f83\u5c11\u88ab\u63a2\u7d22\u3002\u4e86\u89e3\u6cdb\u5316\u8bef\u5dee\u5bf9\u4e8e\u8bc4\u4f30\u8bad\u7ec3\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "method": "\u6587\u7ae0\u91c7\u7528\u7ec6\u7c92\u5ea6\u7684\u6cdb\u5316\u8bef\u5dee\u5206\u6790\u65b9\u6cd5\uff0c\u65e2\u8003\u8651\u4e86\u65e0\u653b\u51fb\u7684\u60c5\u51b5\u4e5f\u6db5\u76d6\u4e86\u62dc\u5360\u5ead\u5bb9\u9519\u673a\u5236\u4e0b\u7684\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\uff0c\u540c\u65f6\u4f7f\u7528\u4e86\u5f02\u6784\u6570\u636e\u5e76\u57fa\u4e8e\u8f83\u4e3a\u6e29\u548c\u7684\u5047\u8bbe\u6761\u4ef6\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6570\u636e\u5f02\u8d28\u6027\u3001\u6a21\u578b\u521d\u59cb\u5316\u4ee5\u53ca\u968f\u673a\u68af\u5ea6\u566a\u58f0\u7b49\u56e0\u7d20\u4f1a\u5bf9\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u7684\u6cdb\u5316\u8bef\u5dee\u4ea7\u751f\u5f71\u54cd\uff1b\u6b64\u5916\uff0c\u53d1\u73b0\u62dc\u5360\u5ead\u653b\u51fb\u5bf9\u6cdb\u5316\u8bef\u5dee\u6709\u7740\u663e\u8457\u5f71\u54cd\uff0c\u8fd9\u79cd\u8d1f\u9762\u5f71\u54cd\u4e0e\u6570\u636e\u5f02\u8d28\u6027\u76f8\u5173\u8054\u800c\u4e0e\u6837\u672c\u6570\u91cf\u65e0\u5173\u3002", "conclusion": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u63d0\u51fa\u7684\u6cdb\u5316\u8bef\u5dee\u5206\u6790\u7ed3\u679c\uff0c\u4e3a\u7406\u89e3\u53bb\u4e2d\u5fc3\u5316\u5b66\u4e60\u7b97\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2506.09452", "pdf": "https://arxiv.org/pdf/2506.09452", "abs": "https://arxiv.org/abs/2506.09452", "authors": ["Jay Roberts", "Kyle Mylonakis", "Sidhartha Roy", "Kaan Kale"], "title": "Learning Obfuscations Of LLM Embedding Sequences: Stained Glass Transform", "categories": ["cs.LG", "cs.CL", "cs.CR", "cs.IT", "math.IT", "I.2.7; I.2.m"], "comment": "Submitted to IEEE S&P 2026", "summary": "The high cost of ownership of AI compute infrastructure and challenges of\nrobust serving of large language models (LLMs) has led to a surge in managed\nModel-as-a-service deployments. Even when enterprises choose on-premises\ndeployments, the compute infrastructure is typically shared across many teams\nin order to maximize the return on investment. In both scenarios the deployed\nmodels operate only on plaintext data, and so enterprise data owners must allow\ntheir data to appear in plaintext on a shared or multi-tenant compute\ninfrastructure. This results in data owners with private or sensitive data\nbeing hesitant or restricted in what data they use with these types of\ndeployments. In this work we introduce the Stained Glass Transform, a learned,\nstochastic, and sequence dependent transformation of the word embeddings of an\nLLM which information theoretically provides privacy to the input of the LLM\nwhile preserving the utility of model. We theoretically connect a particular\nclass of Stained Glass Transforms to the theory of mutual information of\nGaussian Mixture Models. We then calculate a-postiori privacy estimates, based\non mutual information, and verify the privacy and utility of instances of\ntransformed embeddings through token level metrics of privacy and standard LLM\nperformance benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u5f69\u8272\u73bb\u7483\u53d8\u6362(Stained Glass Transform)\u7684\u6280\u672f\uff0c\u8be5\u6280\u672f\u53ef\u4ee5\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u8f93\u5165\u63d0\u4f9b\u9690\u79c1\u4fdd\u62a4\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u7684\u5b9e\u7528\u6027\u3002\u901a\u8fc7\u5c06\u8bcd\u5d4c\u5165\u8f6c\u6362\u6210\u4e00\u79cd\u5b66\u4e60\u5230\u7684\u3001\u968f\u673a\u7684\u4e14\u5e8f\u5217\u4f9d\u8d56\u7684\u5f62\u5f0f\uff0c\u7406\u8bba\u4e0a\u53ef\u4ee5\u786e\u4fdd\u6570\u636e\u9690\u79c1\u6027\uff0c\u5e76\u4e14\u901a\u8fc7\u4e0e\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u4e92\u4fe1\u606f\u7406\u8bba\u7684\u8054\u7cfb\uff0c\u63d0\u4f9b\u4e86\u540e\u9a8c\u9690\u79c1\u4f30\u8ba1\u3002", "motivation": "\u7531\u4e8eAI\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u7684\u6240\u6709\u6743\u6210\u672c\u9ad8\u6602\u4ee5\u53ca\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7a33\u5065\u670d\u52a1\u7684\u6311\u6218\uff0c\u5bfc\u81f4\u4e86\u6258\u7ba1\u5f0fModel-as-a-Service\u90e8\u7f72\u7684\u6fc0\u589e\u3002\u5373\u4f7f\u4f01\u4e1a\u9009\u62e9\u5185\u90e8\u90e8\u7f72\uff0c\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u4e5f\u901a\u5e38\u7531\u591a\u4e2a\u56e2\u961f\u5171\u4eab\u4ee5\u6700\u5927\u5316\u6295\u8d44\u56de\u62a5\u3002\u5728\u4e24\u79cd\u60c5\u51b5\u4e0b\uff0c\u6240\u90e8\u7f72\u7684\u6a21\u578b\u4ec5\u5bf9\u660e\u6587\u6570\u636e\u8fdb\u884c\u64cd\u4f5c\uff0c\u56e0\u6b64\u4f01\u4e1a\u6570\u636e\u6240\u6709\u8005\u5fc5\u987b\u5141\u8bb8\u4ed6\u4eec\u7684\u6570\u636e\u4ee5\u660e\u6587\u5f62\u5f0f\u51fa\u73b0\u5728\u5171\u4eab\u6216\u591a\u79df\u6237\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u4e0a\u3002\u8fd9\u4f7f\u5f97\u62e5\u6709\u79c1\u5bc6\u6216\u654f\u611f\u6570\u636e\u7684\u6570\u636e\u6240\u6709\u8005\u5728\u4f7f\u7528\u8fd9\u7c7b\u90e8\u7f72\u65f6\u72b9\u8c6b\u4e0d\u51b3\u6216\u53d7\u5230\u9650\u5236\u3002", "method": "\u7814\u7a76\u8005\u4eec\u5f15\u5165\u4e86\u5f69\u8272\u73bb\u7483\u53d8\u6362\uff08Stained Glass Transform\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u5b66\u4e60\u5f97\u6765\u7684\u3001\u968f\u673a\u7684\u5e76\u4e14\u4f9d\u8d56\u4e8e\u5e8f\u5217\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bcd\u5d4c\u5165\u8f6c\u6362\u65b9\u6cd5\u3002\u8fd9\u79cd\u65b9\u6cd5\u4ece\u4fe1\u606f\u8bba\u7684\u89d2\u5ea6\u4e3aLLM\u8f93\u5165\u63d0\u4f9b\u9690\u79c1\u4fdd\u62a4\uff0c\u540c\u65f6\u4fdd\u7559\u6a21\u578b\u7684\u6548\u7528\u3002\u6b64\u5916\uff0c\u8fd8\u7279\u522b\u5730\u5c06\u4e00\u7c7b\u5f69\u8272\u73bb\u7483\u53d8\u6362\u4e0e\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u7684\u4e92\u4fe1\u606f\u7406\u8bba\u76f8\u8054\u7cfb\u3002", "result": "\u7814\u7a76\u8005\u4eec\u57fa\u4e8e\u4e92\u4fe1\u606f\u8ba1\u7b97\u51fa\u540e\u9a8c\u9690\u79c1\u4f30\u8ba1\uff0c\u5e76\u901a\u8fc7\u4ee4\u724c\u7ea7\u522b\u7684\u9690\u79c1\u5ea6\u91cf\u548c\u6807\u51c6LLM\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u4e86\u7ecf\u8fc7\u53d8\u6362\u7684\u5d4c\u5165\u5b9e\u4f8b\u7684\u9690\u79c1\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4ecb\u7ecd\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u5728\u591a\u79df\u6237\u73af\u5883\u4e2d\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u7684\u6570\u636e\u9690\u79c1\u95ee\u9898\u3002\u901a\u8fc7\u5e94\u7528\u5f69\u8272\u73bb\u7483\u53d8\u6362\uff0c\u80fd\u591f\u5728\u4fdd\u8bc1\u6a21\u578b\u6027\u80fd\u7684\u540c\u65f6\u589e\u52a0\u6570\u636e\u9690\u79c1\u4fdd\u62a4\u3002"}}
{"id": "2506.09454", "pdf": "https://arxiv.org/pdf/2506.09454", "abs": "https://arxiv.org/abs/2506.09454", "authors": ["Yuanhao Pu", "Defu Lian", "Xiaolong Chen", "Xu Huang", "Jin Chen", "Enhong Chen"], "title": "NDCG-Consistent Softmax Approximation with Accelerated Convergence", "categories": ["cs.LG"], "comment": "35 pages", "summary": "Ranking tasks constitute fundamental components of extreme similarity\nlearning frameworks, where extremely large corpora of objects are modeled\nthrough relative similarity relationships adhering to predefined ordinal\nstructures. Among various ranking surrogates, Softmax (SM) Loss has been widely\nadopted due to its natural capability to handle listwise ranking via global\nnegative comparisons, along with its flexibility across diverse application\nscenarios. However, despite its effectiveness, SM Loss often suffers from\nsignificant computational overhead and scalability limitations when applied to\nlarge-scale object spaces. To address this challenge, we propose novel loss\nformulations that align directly with ranking metrics: the\nRanking-Generalizable \\textbf{squared} (RG$^2$) Loss and the\nRanking-Generalizable interactive (RG$^\\times$) Loss, both derived through\nTaylor expansions of the SM Loss. Notably, RG$^2$ reveals the intrinsic\nmechanisms underlying weighted squared losses (WSL) in ranking methods and\nuncovers fundamental connections between sampling-based and non-sampling-based\nloss paradigms. Furthermore, we integrate the proposed RG losses with the\nhighly efficient Alternating Least Squares (ALS) optimization method, providing\nboth generalization guarantees and convergence rate analyses. Empirical\nevaluations on real-world datasets demonstrate that our approach achieves\ncomparable or superior ranking performance relative to SM Loss, while\nsignificantly accelerating convergence. This framework offers the similarity\nlearning community both theoretical insights and practically efficient tools,\nwith methodologies applicable to a broad range of tasks where balancing ranking\nquality and computational efficiency is essential.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570\u5f62\u5f0f\uff0c\u5373RG\u00b2\u548cRG\u00d7\u635f\u5931\uff0c\u901a\u8fc7\u6cf0\u52d2\u5c55\u5f00\u4eceSoftmax\u635f\u5931\u5bfc\u51fa\u3002\u8fd9\u4e9b\u65b0\u65b9\u6cd5\u4e0eALS\u4f18\u5316\u7ed3\u5408\u4f7f\u7528\uff0c\u4e0d\u4ec5\u4fdd\u8bc1\u4e86\u6cdb\u5316\u80fd\u529b\uff0c\u8fd8\u63d0\u9ad8\u4e86\u6536\u655b\u901f\u5ea6\uff0c\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\u5176\u6392\u540d\u6027\u80fd\u4e0eSoftmax\u635f\u5931\u76f8\u5f53\u6216\u66f4\u4f18\uff0c\u5e76\u4e14\u5927\u5927\u52a0\u901f\u4e86\u6536\u655b\u8fc7\u7a0b\u3002", "motivation": "\u5c3d\u7ba1Softmax\uff08SM\uff09\u635f\u5931\u5728\u5217\u8868\u6392\u5e8f\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5927\u89c4\u6a21\u5bf9\u8c61\u7a7a\u95f4\u7684\u5e94\u7528\u4e2d\u5b58\u5728\u663e\u8457\u7684\u8ba1\u7b97\u5f00\u9500\u548c\u53ef\u6269\u5c55\u6027\u9650\u5236\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u8005\u4eec\u5e0c\u671b\u5f00\u53d1\u51fa\u80fd\u591f\u76f4\u63a5\u4e0e\u6392\u540d\u6307\u6807\u5bf9\u9f50\u7684\u65b0\u635f\u5931\u516c\u5f0f\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u635f\u5931\u516c\u5f0f\uff1aRanking-Generalizable\u5e73\u65b9\uff08RG\u00b2\uff09\u635f\u5931\u548cRanking-Generalizable\u4ea4\u4e92\uff08RG\u00d7\uff09\u635f\u5931\uff0c\u5b83\u4eec\u90fd\u662f\u901a\u8fc7\u5bf9Softmax\u635f\u5931\u8fdb\u884c\u6cf0\u52d2\u5c55\u5f00\u5f97\u5230\u7684\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u63d0\u51fa\u7684RG\u635f\u5931\u4e0e\u9ad8\u6548\u7684\u4ea4\u66ff\u6700\u5c0f\u4e8c\u4e58\uff08ALS\uff09\u4f18\u5316\u65b9\u6cd5\u76f8\u7ed3\u5408\uff0c\u63d0\u4f9b\u4e86\u6cdb\u5316\u7684\u4fdd\u969c\u548c\u6536\u655b\u901f\u7387\u5206\u6790\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4e0eSoftmax\u635f\u5931\u76f8\u5f53\u751a\u81f3\u66f4\u597d\u7684\u6392\u540d\u8868\u73b0\uff0c\u540c\u65f6\u663e\u8457\u52a0\u5feb\u4e86\u6536\u655b\u901f\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u76f8\u4f3c\u6027\u5b66\u4e60\u9886\u57df\u63d0\u4f9b\u4e86\u7406\u8bba\u89c1\u89e3\u548c\u5b9e\u7528\u9ad8\u6548\u7684\u5de5\u5177\uff0c\u9002\u7528\u4e8e\u9700\u8981\u5e73\u8861\u6392\u540d\u8d28\u91cf\u548c\u8ba1\u7b97\u6548\u7387\u7684\u5404\u79cd\u4efb\u52a1\u3002"}}
{"id": "2506.09477", "pdf": "https://arxiv.org/pdf/2506.09477", "abs": "https://arxiv.org/abs/2506.09477", "authors": ["Yunhao Tang", "R\u00e9mi Munos"], "title": "On a few pitfalls in KL divergence gradient estimation for RL", "categories": ["cs.LG"], "comment": null, "summary": "We point out a few pitfalls in implementing gradient estimation for KL\ndivergence in RL training for LLM, as seen in a number of open source projects\nand papers. The first major pitfall is to differentiate through the KL estimate\nas loss functions to minimize KL divergence. We show that such implementations\nare generally incorrect and do not produce the desired KL gradient. Secondly,\nwe show that some implementations do not account for the sequential nature of\nthe estimation problem and produce a partial gradient at best. We demonstrate\nthe impact of such issues with illustrative tabular and LLM experiments, and\nshow the correct way to implement the KL gradient.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u4e86\u5728\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e2d\u5b9e\u73b0KL\u6563\u5ea6\u68af\u5ea6\u4f30\u8ba1\u65f6\u7684\u4e00\u4e9b\u5e38\u89c1\u9677\u9631\uff0c\u5e76\u5c55\u793a\u4e86\u6b63\u786e\u5b9e\u65bdKL\u68af\u5ea6\u7684\u65b9\u6cd5\u3002", "motivation": "\u4f5c\u8005\u65e8\u5728\u6307\u51fa\u5e76\u7ea0\u6b63\u5f53\u524d\u5f00\u6e90\u9879\u76ee\u548c\u8bba\u6587\u4e2d\u5bf9\u4e8eKL\u6563\u5ea6\u68af\u5ea6\u4f30\u8ba1\u5b9e\u73b0\u4e0a\u7684\u4e00\u4e9b\u9519\u8bef\u505a\u6cd5\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u8bd5\u56fe\u901a\u8fc7\u533a\u5206KL\u4f30\u8ba1\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u6765\u6700\u5c0f\u5316KL\u6563\u5ea6\u7684\u505a\u6cd5\u3002", "method": "\u9996\u5148\u8bf4\u660e\u76f4\u63a5\u901a\u8fc7KL\u4f30\u8ba1\u4f5c\u4e3a\u635f\u5931\u51fd\u6570\u8fdb\u884c\u533a\u5206\u662f\u4e0d\u6b63\u786e\u7684\uff1b\u5176\u6b21\uff0c\u6307\u51fa\u67d0\u4e9b\u5b9e\u73b0\u6ca1\u6709\u8003\u8651\u5230\u4f30\u8ba1\u95ee\u9898\u7684\u5e8f\u5217\u6027\u7279\u5f81\uff0c\u4ece\u800c\u53ea\u80fd\u4ea7\u751f\u90e8\u5206\u68af\u5ea6\u3002\u901a\u8fc7\u8868\u683c\u793a\u4f8b\u548cLLM\u5b9e\u9a8c\u6765\u5c55\u793a\u8fd9\u4e9b\u95ee\u9898\u7684\u5f71\u54cd\uff0c\u5e76\u7ed9\u51fa\u6b63\u786e\u7684KL\u68af\u5ea6\u5b9e\u73b0\u65b9\u6cd5\u3002", "result": "\u5c55\u793a\u4e86\u4e0d\u5f53\u5b9e\u73b0KL\u6563\u5ea6\u68af\u5ea6\u4f30\u8ba1\u53ef\u80fd\u5bfc\u81f4\u7684\u95ee\u9898\uff0c\u5305\u62ec\u65e0\u6cd5\u5f97\u5230\u671f\u671b\u7684KL\u68af\u5ea6\u4ee5\u53ca\u53ea\u8ba1\u7b97\u51fa\u90e8\u5206\u68af\u5ea6\u7b49\u3002", "conclusion": "\u5f3a\u8c03\u4e86\u5728LLM\u7684RL\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6b63\u786e\u5b9e\u73b0KL\u6563\u5ea6\u68af\u5ea6\u4f30\u8ba1\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u907f\u514d\u5e38\u89c1\u9677\u9631\u7684\u6307\u5bfc\u3002"}}
{"id": "2506.09544", "pdf": "https://arxiv.org/pdf/2506.09544", "abs": "https://arxiv.org/abs/2506.09544", "authors": ["Yang Yang", "Du Yin", "Hao Xue", "Flora Salim"], "title": "STOAT: Spatial-Temporal Probabilistic Causal Inference Network", "categories": ["cs.LG"], "comment": null, "summary": "Spatial-temporal causal time series (STC-TS) involve region-specific temporal\nobservations driven by causally relevant covariates and interconnected across\ngeographic or network-based spaces. Existing methods often model spatial and\ntemporal dynamics independently and overlook causality-driven probabilistic\nforecasting, limiting their predictive power. To address this, we propose STOAT\n(Spatial-Temporal Probabilistic Causal Inference Network), a novel framework\nfor probabilistic forecasting in STC-TS. The proposed method extends a causal\ninference approach by incorporating a spatial relation matrix that encodes\ninterregional dependencies (e.g. proximity or connectivity), enabling spatially\ninformed causal effect estimation. The resulting latent series are processed by\ndeep probabilistic models to estimate the parameters of the distributions,\nenabling calibrated uncertainty modeling. We further explore multiple output\ndistributions (e.g., Gaussian, Student's-$t$, Laplace) to capture\nregion-specific variability. Experiments on COVID-19 data across six countries\ndemonstrate that STOAT outperforms state-of-the-art probabilistic forecasting\nmodels (DeepAR, DeepVAR, Deep State Space Model, etc.) in key metrics,\nparticularly in regions with strong spatial dependencies. By bridging causal\ninference and geospatial probabilistic forecasting, STOAT offers a\ngeneralizable framework for complex spatial-temporal tasks, such as epidemic\nmanagement.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6STOAT\uff0c\u7528\u4e8e\u65f6\u7a7a\u56e0\u679c\u65f6\u95f4\u5e8f\u5217\uff08STC-TS\uff09\u7684\u6982\u7387\u9884\u6d4b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6574\u5408\u7a7a\u95f4\u5173\u7cfb\u77e9\u9635\u6765\u6269\u5c55\u56e0\u679c\u63a8\u7406\u65b9\u6cd5\uff0c\u4ece\u800c\u80fd\u591f\u4f30\u8ba1\u5177\u6709\u7a7a\u95f4\u4fe1\u606f\u7684\u56e0\u679c\u6548\u5e94\uff0c\u5e76\u4f7f\u7528\u6df1\u5ea6\u6982\u7387\u6a21\u578b\u5904\u7406\u6f5c\u5728\u5e8f\u5217\u4ee5\u4f30\u8ba1\u5206\u5e03\u53c2\u6570\uff0c\u5141\u8bb8\u6821\u51c6\u4e0d\u786e\u5b9a\u6027\u5efa\u6a21\u3002\u5b9e\u9a8c\u8868\u660e\uff0cSTOAT\u5728\u5173\u952e\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u6a21\u578b\uff0c\u7279\u522b\u662f\u5728\u5177\u6709\u5f3a\u7a7a\u95f4\u4f9d\u8d56\u6027\u7684\u533a\u57df\u3002", "motivation": "\u73b0\u6709\u7684\u65b9\u6cd5\u901a\u5e38\u72ec\u7acb\u5730\u6a21\u62df\u7a7a\u95f4\u548c\u65f6\u95f4\u52a8\u6001\uff0c\u5e76\u5ffd\u89c6\u4e86\u56e0\u679c\u9a71\u52a8\u7684\u6982\u7387\u9884\u6d4b\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u7684\u9884\u6d4b\u80fd\u529b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u6846\u67b6STOAT\uff0c\u65e8\u5728\u63d0\u9ad8STC-TS\u4e2d\u7684\u9884\u6d4b\u6027\u80fd\u3002", "method": "STOAT\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u7a7a\u95f4\u5173\u7cfb\u77e9\u9635\u6765\u6355\u6349\u533a\u57df\u95f4\u7684\u76f8\u4e92\u4f9d\u8d56\u6027\uff0c\u5982\u90bb\u8fd1\u6216\u8fde\u901a\u6027\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u8fdb\u884c\u56e0\u679c\u6548\u5e94\u8bc4\u4f30\u3002\u63a5\u7740\uff0c\u5b83\u8fd0\u7528\u6df1\u5c42\u6982\u7387\u6a21\u578b\u6765\u4f30\u7b97\u6f5c\u5728\u5e8f\u5217\u4e2d\u5206\u5e03\u7684\u53c2\u6570\uff0c\u652f\u6301\u591a\u8f93\u51fa\u5206\u5e03\uff08\u4f8b\u5982\u9ad8\u65af\u3001\u5b66\u751ft-\u5206\u5e03\u3001\u62c9\u666e\u62c9\u65af\uff09\u4ee5\u6355\u6349\u7279\u5b9a\u4e8e\u533a\u57df\u7684\u53d8\u5316\u6027\u3002", "result": "\u5728\u516d\u4e2a\u4e0d\u540c\u56fd\u5bb6\u7684COVID-19\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cSTOAT\u5728\u5173\u952e\u5ea6\u91cf\u4e0a\u4f18\u4e8e\u5f53\u524d\u5148\u8fdb\u7684\u6982\u7387\u9884\u6d4b\u6a21\u578b\uff0c\u5c24\u5176\u5728\u90a3\u4e9b\u5177\u6709\u5f3a\u70c8\u7a7a\u95f4\u76f8\u5173\u6027\u7684\u5730\u533a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u56e0\u679c\u63a8\u65ad\u4e0e\u5730\u7406\u7a7a\u95f4\u6982\u7387\u9884\u6d4b\uff0cSTOAT\u63d0\u4f9b\u4e86\u4e00\u4e2a\u901a\u7528\u6846\u67b6\uff0c\u9002\u7528\u4e8e\u590d\u6742\u7684\u65f6\u7a7a\u4efb\u52a1\uff0c\u6bd4\u5982\u6d41\u884c\u75c5\u7ba1\u7406\u3002"}}
{"id": "2506.09574", "pdf": "https://arxiv.org/pdf/2506.09574", "abs": "https://arxiv.org/abs/2506.09574", "authors": ["Gaurav Chaudhary", "Wassim Uddin Mondal", "Laxmidhar Behera"], "title": "MOORL: A Framework for Integrating Offline-Online Reinforcement Learning", "categories": ["cs.LG"], "comment": null, "summary": "Sample efficiency and exploration remain critical challenges in Deep\nReinforcement Learning (DRL), particularly in complex domains. Offline RL,\nwhich enables agents to learn optimal policies from static, pre-collected\ndatasets, has emerged as a promising alternative. However, offline RL is\nconstrained by issues such as out-of-distribution (OOD) actions that limit\npolicy performance and generalization. To overcome these limitations, we\npropose Meta Offline-Online Reinforcement Learning (MOORL), a hybrid framework\nthat unifies offline and online RL for efficient and scalable learning. While\nprevious hybrid methods rely on extensive design components and added\ncomputational complexity to utilize offline data effectively, MOORL introduces\na meta-policy that seamlessly adapts across offline and online trajectories.\nThis enables the agent to leverage offline data for robust initialization while\nutilizing online interactions to drive efficient exploration. Our theoretical\nanalysis demonstrates that the hybrid approach enhances exploration by\neffectively combining the complementary strengths of offline and online data.\nFurthermore, we demonstrate that MOORL learns a stable Q-function without added\ncomplexity. Extensive experiments on 28 tasks from the D4RL and V-D4RL\nbenchmarks validate its effectiveness, showing consistent improvements over\nstate-of-the-art offline and hybrid RL baselines. With minimal computational\noverhead, MOORL achieves strong performance, underscoring its potential for\npractical applications in real-world scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMeta Offline-Online Reinforcement Learning (MOORL)\u7684\u6df7\u5408\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u79bb\u7ebf\u548c\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u70b9\uff0c\u4ee5\u5b9e\u73b0\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u5b66\u4e60\u3002MOORL\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u5143\u7b56\u7565\u65e0\u7f1d\u5730\u9002\u5e94\u79bb\u7ebf\u548c\u5728\u7ebf\u8f68\u8ff9\uff0c\u4ece\u800c\u5728\u5229\u7528\u79bb\u7ebf\u6570\u636e\u8fdb\u884c\u7a33\u5065\u521d\u59cb\u5316\u7684\u540c\u65f6\uff0c\u4f7f\u7528\u5728\u7ebf\u4ea4\u4e92\u9a71\u52a8\u6709\u6548\u7684\u63a2\u7d22\u3002\u5b9e\u9a8c\u8868\u660eMOORL\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u79bb\u7ebf\u548c\u6df7\u5408RL\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u8ba1\u7b97\u5f00\u9500\u5c0f\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff08DRL\uff09\u4e2d\u7684\u6837\u672c\u6548\u7387\u548c\u63a2\u7d22\u95ee\u9898\u4ecd\u7136\u662f\u590d\u6742\u9886\u57df\u4e2d\u7684\u91cd\u8981\u6311\u6218\u3002\u867d\u7136\u79bb\u7ebfRL\u5141\u8bb8\u4ee3\u7406\u4ece\u9759\u6001\u9884\u6536\u96c6\u7684\u6570\u636e\u96c6\u4e2d\u5b66\u4e60\u6700\u4f18\u7b56\u7565\uff0c\u4f46\u5b83\u53d7\u5230\u8bf8\u5982\u5206\u5e03\u5916\u52a8\u4f5c\u7b49\u95ee\u9898\u7684\u9650\u5236\uff0c\u8fd9\u4f1a\u5f71\u54cd\u7b56\u7565\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86Meta Offline-Online Reinforcement Learning (MOORL)\uff0c\u8fd9\u662f\u4e00\u79cd\u5c06\u79bb\u7ebf\u548c\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u7edf\u4e00\u8d77\u6765\u7684\u6df7\u5408\u6846\u67b6\uff0c\u65e8\u5728\u63d0\u9ad8\u5b66\u4e60\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002MOORL\u91c7\u7528\u4e86\u4e00\u4e2a\u80fd\u591f\u8de8\u8d8a\u79bb\u7ebf\u4e0e\u5728\u7ebf\u8f68\u8ff9\u81ea\u9002\u5e94\u7684\u5143\u7b56\u7565\uff0c\u4f7f\u5f97\u4ee3\u7406\u80fd\u591f\u5728\u5229\u7528\u79bb\u7ebf\u6570\u636e\u8fdb\u884c\u7a33\u5065\u521d\u59cb\u5316\u7684\u540c\u65f6\uff0c\u4e5f\u901a\u8fc7\u5728\u7ebf\u4e92\u52a8\u6765\u4fc3\u8fdb\u9ad8\u6548\u7684\u63a2\u7d22\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u8fd9\u79cd\u6df7\u5408\u65b9\u6cd5\u901a\u8fc7\u6709\u6548\u5730\u7ed3\u5408\u79bb\u7ebf\u548c\u5728\u7ebf\u6570\u636e\u7684\u4e92\u8865\u4f18\u52bf\u589e\u5f3a\u4e86\u63a2\u7d22\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u8bc1\u660eMOORL\u53ef\u4ee5\u5728\u4e0d\u589e\u52a0\u989d\u5916\u590d\u6742\u5ea6\u7684\u60c5\u51b5\u4e0b\u5b66\u4e60\u5230\u7a33\u5b9a\u7684Q\u51fd\u6570\u3002\u5728D4RL\u548cV-D4RL\u57fa\u51c6\u6d4b\u8bd5\u768428\u9879\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660eMOORL\u76f8\u5bf9\u4e8e\u6700\u5148\u8fdb\u79bb\u7ebf\u53ca\u6df7\u5408RL\u57fa\u7ebf\u7684\u4e00\u81f4\u6539\u8fdb\u3002", "conclusion": "MOORL\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u6df7\u5408\u578b\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u5728\u5904\u7406\u79bb\u7ebf\u548c\u5728\u7ebf\u6570\u636e\u65b9\u9762\u8868\u73b0\u51fa\u826f\u597d\u7684\u6027\u80fd\uff0c\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6837\u672c\u6548\u7387\uff0c\u800c\u4e14\u51cf\u5c11\u4e86\u8ba1\u7b97\u8d1f\u62c5\uff0c\u663e\u793a\u51fa\u5728\u5b9e\u9645\u5e94\u7528\u573a\u666f\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2506.09593", "pdf": "https://arxiv.org/pdf/2506.09593", "abs": "https://arxiv.org/abs/2506.09593", "authors": ["Achim Hekler", "Lukas Kuhn", "Florian Buettner"], "title": "Beyond Overconfidence: Foundation Models Redefine Calibration in Deep Neural Networks", "categories": ["cs.LG"], "comment": null, "summary": "Reliable uncertainty calibration is essential for safely deploying deep\nneural networks in high-stakes applications. Deep neural networks are known to\nexhibit systematic overconfidence, especially under distribution shifts.\nAlthough foundation models such as ConvNeXt, EVA and BEiT have demonstrated\nsignificant improvements in predictive performance, their calibration\nproperties remain underexplored. This paper presents a comprehensive\ninvestigation into the calibration behavior of foundation models, revealing\ninsights that challenge established paradigms. Our empirical analysis shows\nthat these models tend to be underconfident in in-distribution predictions,\nresulting in higher calibration errors, while demonstrating improved\ncalibration under distribution shifts. Furthermore, we demonstrate that\nfoundation models are highly responsive to post-hoc calibration techniques in\nthe in-distribution setting, enabling practitioners to effectively mitigate\nunderconfidence bias. However, these methods become progressively less reliable\nunder severe distribution shifts and can occasionally produce counterproductive\nresults. Our findings highlight the complex, non-monotonic effects of\narchitectural and training innovations on calibration, challenging established\nnarratives of continuous improvement.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u63a2\u8ba8\u4e86\u57fa\u7840\u6a21\u578b\u5728\u4e0d\u540c\u5206\u5e03\u4e0b\u7684\u6821\u51c6\u884c\u4e3a\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u6a21\u578b\u5185\u90e8\u9884\u6d4b\u65f6\u7684\u4e0d\u81ea\u4fe1\u95ee\u9898\u4ee5\u53ca\u5728\u6821\u51c6\u6280\u672f\u5e94\u7528\u4e0b\u7684\u54cd\u5e94\u6027\uff0c\u5e76\u6307\u51fa\u67b6\u6784\u548c\u8bad\u7ec3\u521b\u65b0\u5bf9\u6821\u51c6\u6709\u590d\u6742\u7684\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u786e\u4fdd\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u573a\u666f\u4e2d\u7684\u5b89\u5168\u90e8\u7f72\uff0c\u89e3\u51b3\u5176\u7cfb\u7edf\u6027\u7684\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\uff0c\u7279\u522b\u662f\u5f53\u6570\u636e\u5206\u5e03\u53d1\u751f\u53d8\u5316\u65f6\u3002\u6587\u7ae0\u8fd8\u7279\u522b\u5173\u6ce8\u4e86\u5982ConvNeXt\u3001EVA \u548c BEiT \u7b49\u57fa\u7840\u6a21\u578b\u7684\u6821\u51c6\u7279\u6027\uff0c\u8fd9\u662f\u4e4b\u524d\u8f83\u5c11\u88ab\u63a2\u7d22\u7684\u4e00\u4e2a\u65b9\u9762\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u65b9\u6cd5\u6765\u8003\u5bdf\u57fa\u7840\u6a21\u578b\u5728\u6807\u51c6\u5206\u5e03\u5185\u548c\u5206\u5e03\u504f\u79fb\u60c5\u51b5\u4e0b\u7684\u6821\u51c6\u8868\u73b0\u3002\u4ed6\u4eec\u4e5f\u8bc4\u4f30\u4e86\u540e\u5904\u7406\u6821\u51c6\u6280\u672f\u5bf9\u6539\u5584\u57fa\u7840\u6a21\u578b\u5728\u6807\u51c6\u5206\u5e03\u5185\u9884\u6d4b\u4e0d\u81ea\u4fe1\u7684\u6709\u6548\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u57fa\u7840\u6a21\u578b\u5bf9\u4e8e\u6807\u51c6\u5206\u5e03\u5185\u7684\u9884\u6d4b\u5f80\u5f80\u8868\u73b0\u51fa\u4e0d\u81ea\u4fe1\uff0c\u5bfc\u81f4\u66f4\u9ad8\u7684\u6821\u51c6\u8bef\u5dee\uff1b\u800c\u5728\u5206\u5e03\u504f\u79fb\u60c5\u51b5\u4e0b\u6821\u51c6\u6709\u6240\u6539\u5584\u3002\u6b64\u5916\uff0c\u867d\u7136\u8fd9\u4e9b\u6a21\u578b\u5728\u6807\u51c6\u5206\u5e03\u8bbe\u7f6e\u4e0b\u5bf9\u540e\u5904\u7406\u6821\u51c6\u6280\u672f\u975e\u5e38\u654f\u611f\uff0c\u4f46\u5728\u4e25\u91cd\u7684\u5206\u5e03\u504f\u79fb\u60c5\u51b5\u4e0b\uff0c\u6b64\u7c7b\u6280\u672f\u7684\u6548\u679c\u53d8\u5f97\u4e0d\u592a\u53ef\u9760\uff0c\u6709\u65f6\u751a\u81f3\u4ea7\u751f\u53cd\u6548\u679c\u3002", "conclusion": "\u7814\u7a76\u7ed3\u8bba\u6307\u51fa\u4e86\u67b6\u6784\u4e0e\u8bad\u7ec3\u521b\u65b0\u5bf9\u6a21\u578b\u6821\u51c6\u5f71\u54cd\u7684\u590d\u6742\u6027\u548c\u975e\u5355\u8c03\u6027\uff0c\u8fd9\u6311\u6218\u4e86\u6301\u7eed\u6539\u8fdb\u7684\u4e00\u8d2f\u8bf4\u6cd5\uff0c\u5e76\u5f3a\u8c03\u4e86\u7406\u89e3\u8fd9\u4e9b\u5f71\u54cd\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.09594", "pdf": "https://arxiv.org/pdf/2506.09594", "abs": "https://arxiv.org/abs/2506.09594", "authors": ["Wenjin Qin", "Hailin Wang", "Jingyao Hou", "Jianjun Wang"], "title": "Accelerating Large-Scale Regularized High-Order Tensor Recovery", "categories": ["cs.LG"], "comment": null, "summary": "Currently, existing tensor recovery methods fail to recognize the impact of\ntensor scale variations on their structural characteristics. Furthermore,\nexisting studies face prohibitive computational costs when dealing with\nlarge-scale high-order tensor data. To alleviate these issue, assisted by the\nKrylov subspace iteration, block Lanczos bidiagonalization process, and random\nprojection strategies, this article first devises two fast and accurate\nrandomized algorithms for low-rank tensor approximation (LRTA) problem.\nTheoretical bounds on the accuracy of the approximation error estimate are\nestablished. Next, we develop a novel generalized nonconvex modeling framework\ntailored to large-scale tensor recovery, in which a new regularization paradigm\nis exploited to achieve insightful prior representation for large-scale\ntensors. On the basis of the above, we further investigate new unified\nnonconvex models and efficient optimization algorithms, respectively, for\nseveral typical high-order tensor recovery tasks in unquantized and quantized\nsituations. To render the proposed algorithms practical and efficient for\nlarge-scale tensor data, the proposed randomized LRTA schemes are integrated\ninto their central and time-intensive computations. Finally, we conduct\nextensive experiments on various large-scale tensors, whose results demonstrate\nthe practicability, effectiveness and superiority of the proposed method in\ncomparison with some state-of-the-art approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u5feb\u901f\u51c6\u786e\u7684\u968f\u673a\u7b97\u6cd5\u7528\u4e8e\u4f4e\u79e9\u5f20\u91cf\u903c\u8fd1\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u4e2a\u65b0\u7684\u5e7f\u4e49\u975e\u51f8\u5efa\u6a21\u6846\u67b6\uff0c\u4ee5\u9002\u5e94\u5927\u89c4\u6a21\u5f20\u91cf\u6062\u590d\u3002\u6b64\u5916\u8fd8\u7814\u7a76\u4e86\u7edf\u4e00\u7684\u975e\u51f8\u6a21\u578b\u548c\u9ad8\u6548\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u672a\u91cf\u5316\u548c\u91cf\u5316\u7684\u9ad8\u9636\u5f20\u91cf\u6062\u590d\u4efb\u52a1\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u5b9e\u9645\u6027\u3001\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u65b9\u9762\u4f18\u4e8e\u4e00\u4e9b\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u7684\u5f20\u91cf\u6062\u590d\u65b9\u6cd5\u672a\u80fd\u8bc6\u522b\u5f20\u91cf\u89c4\u6a21\u53d8\u5316\u5bf9\u5176\u7ed3\u6784\u7279\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u4e14\u5728\u5904\u7406\u5927\u89c4\u6a21\u9ad8\u9636\u5f20\u91cf\u6570\u636e\u65f6\u9762\u4e34\u8fc7\u9ad8\u7684\u8ba1\u7b97\u6210\u672c\u3002", "method": "\u501f\u52a9Krylov\u5b50\u7a7a\u95f4\u8fed\u4ee3\u3001\u5757Lanczos\u53cc\u5bf9\u89d2\u5316\u8fc7\u7a0b\u4ee5\u53ca\u968f\u673a\u6295\u5f71\u7b56\u7565\uff0c\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u9488\u5bf9\u4f4e\u79e9\u5f20\u91cf\u903c\u8fd1\u95ee\u9898\u7684\u5feb\u901f\u7cbe\u786e\u968f\u673a\u7b97\u6cd5\uff1b\u5efa\u7acb\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5e7f\u4e49\u975e\u51f8\u5efa\u6a21\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u65b0\u7684\u6b63\u5219\u5316\u8303\u5f0f\u6765\u5b9e\u73b0\u5927\u89c4\u6a21\u5f20\u91cf\u7684\u6709\u6d1e\u5bdf\u529b\u7684\u5148\u9a8c\u8868\u793a\uff1b\u8fdb\u4e00\u6b65\u7814\u7a76\u4e86\u51e0\u79cd\u5178\u578b\u9ad8\u9636\u5f20\u91cf\u6062\u590d\u4efb\u52a1\u7684\u65b0\u7edf\u4e00\u975e\u51f8\u6a21\u578b\u53ca\u9ad8\u6548\u4f18\u5316\u7b97\u6cd5\u3002", "result": "\u5bf9\u4e8e\u4e0d\u540c\u7684\u5927\u89c4\u6a21\u5f20\u91cf\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7ed3\u679c\u5c55\u793a\u4e86\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6bd4\u67d0\u4e9b\u6700\u5148\u8fdb\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u5b9e\u7528\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u968f\u673a\u5316LRTA\u65b9\u6848\uff0c\u672c\u6587\u63d0\u51fa\u7684\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5904\u7406\u5927\u89c4\u6a21\u5f20\u91cf\u6570\u636e\uff0c\u5e76\u5728\u591a\u4e2a\u5178\u578b\u7684\u9ad8\u9636\u5f20\u91cf\u6062\u590d\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u8272\u7684\u8868\u73b0\u3002"}}
{"id": "2506.09613", "pdf": "https://arxiv.org/pdf/2506.09613", "abs": "https://arxiv.org/abs/2506.09613", "authors": ["Kaiwen Tuo", "Huan Wang"], "title": "SparseSSM: Efficient Selective Structured State Space Models Can Be Pruned in One-Shot", "categories": ["cs.LG"], "comment": null, "summary": "State-space language models such as Mamba match Transformer quality while\npermitting linear complexity inference, yet still comprise billions of\nparameters that hinder deployment. Existing one-shot pruning methods are\ntailored to attention blocks and fail to account for the time-shared and\ndiscretized state-transition matrix at the heart of the selective state-space\nmodule (SSM). In this paper, we introduce SparseSSM, the first training-free\npruning framework that extends the classic optimal brain surgeon (OBS)\nframework to state space architectures. Our layer-wise algorithm (i) derives an\napproximate second-order saliency score that aggregates Hessian-trace\ninformation across time steps, (ii) incorporates a component sensitivity\nanalysis to guide feed-forward network (FFN) pruning, which also sheds light on\nwhere redundancy resides in mamba architecture, (iii) can be easily extended to\nsemi-structured and structured sparsity. Empirically, we prune 50% of SSM\nweights without fine-tuning and observe no zero-shot accuracy loss, achieving\nthe current state-of-the-art pruning algorithm for Mamba-based LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SparseSSM\uff0c\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u526a\u679d\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u72b6\u6001\u7a7a\u95f4\u67b6\u6784\u8fdb\u884c\u4e86\u7ecf\u5178\u6700\u4f18\u8111\u5916\u79d1\u533b\u751f\uff08OBS\uff09\u6846\u67b6\u7684\u6269\u5c55\u3002\u901a\u8fc7\u5206\u5c42\u7b97\u6cd5\u8ba1\u7b97\u8fd1\u4f3c\u4e8c\u9636\u663e\u8457\u6027\u5206\u6570\uff0c\u5e76\u7ed3\u5408\u7ec4\u4ef6\u654f\u611f\u6027\u5206\u6790\u6307\u5bfc\u524d\u9988\u7f51\u7edc\uff08FFN\uff09\u526a\u679d\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u8f7b\u677e\u63a8\u5e7f\u5230\u534a\u7ed3\u6784\u5316\u548c\u7ed3\u6784\u5316\u7a00\u758f\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4e0d\u8fdb\u884c\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u526a\u679d50%\u7684SSM\u6743\u91cd\u800c\u4e0d\u4f1a\u635f\u5931\u96f6\u6837\u672c\u51c6\u786e\u6027\uff0c\u6210\u4e3a\u57fa\u4e8eMamba\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u5f53\u524d\u6700\u4f73\u526a\u679d\u7b97\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u4e00\u6b65\u5230\u4f4d\u526a\u679d\u65b9\u6cd5\u4e13\u4e3a\u6ce8\u610f\u529b\u5757\u8bbe\u8ba1\uff0c\u672a\u80fd\u8003\u8651\u5230\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u5757\uff08SSM\uff09\u6838\u5fc3\u7684\u65f6\u95f4\u5171\u4eab\u548c\u79bb\u6563\u72b6\u6001\u8f6c\u79fb\u77e9\u9635\u3002\u8fd9\u5bfc\u81f4\u4e86\u5728\u8bf8\u5982Mamba\u8fd9\u6837\u7684\u72b6\u6001\u7a7a\u95f4\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u5c3d\u7ba1\u5176\u5141\u8bb8\u7ebf\u6027\u590d\u6742\u5ea6\u63a8\u7406\u5e76\u8fbe\u5230Transformer\u7684\u8d28\u91cf\uff0c\u4f46\u4ecd\u6709\u6570\u5341\u4ebf\u53c2\u6570\u963b\u788d\u4e86\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u5f15\u5165\u4e86SparseSSM\uff0c\u8fd9\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u526a\u679d\u6846\u67b6\uff0c\u5b83\u5c06\u7ecf\u5178\u7684\u6700\u4f18\u8111\u5916\u79d1\u533b\u751f\uff08OBS\uff09\u6846\u67b6\u6269\u5c55\u5230\u4e86\u72b6\u6001\u7a7a\u95f4\u67b6\u6784\u3002\u63d0\u51fa\u7684\u5206\u5c42\u7b97\u6cd5\u5305\u62ec\uff1a(i) \u5bfc\u51fa\u4e00\u4e2a\u8fd1\u4f3c\u7684\u4e8c\u9636\u663e\u8457\u6027\u8bc4\u5206\uff0c\u8be5\u8bc4\u5206\u805a\u5408\u4e86\u8de8\u65f6\u95f4\u6b65\u957f\u7684Hessian\u8ff9\u4fe1\u606f\uff1b(ii) \u7ed3\u5408\u4e86\u4e00\u4e2a\u7ec4\u4ef6\u654f\u611f\u6027\u5206\u6790\u4ee5\u6307\u5bfc\u524d\u9988\u7f51\u7edc\uff08FFN\uff09\u526a\u679d\uff1b(iii) \u53ef\u4ee5\u5f88\u5bb9\u6613\u5730\u6269\u5c55\u5230\u534a\u7ed3\u6784\u5316\u548c\u7ed3\u6784\u5316\u7a00\u758f\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u53ef\u4ee5\u5728\u4e0d\u9700\u8981\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u526a\u679d\u638950%\u7684SSM\u6743\u91cd\uff0c\u540c\u65f6\u4fdd\u6301\u96f6\u6837\u672c\u51c6\u786e\u7387\u4e0d\u53d8\u3002\u8fd9\u4f7f\u5f97SparseSSM\u6210\u4e3a\u4e86\u57fa\u4e8eMamba\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u5f53\u524d\u6700\u4f73\u526a\u679d\u7b97\u6cd5\u3002", "conclusion": "\u7814\u7a76\u8005\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u540d\u4e3aSparseSSM\u7684\u65b0\u526a\u679d\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u5730\u51cf\u5c11Mamba\u7b49\u72b6\u6001\u7a7a\u95f4\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u53c2\u6570\u6570\u91cf\uff0c\u540c\u65f6\u4e0d\u5f71\u54cd\u6027\u80fd\u3002\u8fd9\u4e00\u53d1\u73b0\u5bf9\u4e8e\u63d0\u9ad8\u8fd9\u7c7b\u6a21\u578b\u7684\u53ef\u90e8\u7f72\u6027\u548c\u6548\u7387\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2506.09625", "pdf": "https://arxiv.org/pdf/2506.09625", "abs": "https://arxiv.org/abs/2506.09625", "authors": ["Ekaterina Filimoshina", "Dmitry Shirokov"], "title": "GLGENN: A Novel Parameter-Light Equivariant Neural Networks Architecture Based on Clifford Geometric Algebras", "categories": ["cs.LG", "68T07, 15A66"], "comment": "Accepted to ICML 2025", "summary": "We propose, implement, and compare with competitors a new architecture of\nequivariant neural networks based on geometric (Clifford) algebras: Generalized\nLipschitz Group Equivariant Neural Networks (GLGENN). These networks are\nequivariant to all pseudo-orthogonal transformations, including rotations and\nreflections, of a vector space with any non-degenerate or degenerate symmetric\nbilinear form. We propose a weight-sharing parametrization technique that takes\ninto account the fundamental structures and operations of geometric algebras.\nDue to this technique, GLGENN architecture is parameter-light and has less\ntendency to overfitting than baseline equivariant models. GLGENN outperforms or\nmatches competitors on several benchmarking equivariant tasks, including\nestimation of an equivariant function and a convex hull experiment, while using\nsignificantly fewer optimizable parameters.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51e0\u4f55\uff08Clifford\uff09\u4ee3\u6570\u7684\u65b0\u7b49\u53d8\u795e\u7ecf\u7f51\u7edc\u67b6\u6784GLGENN\uff0c\u8be5\u7f51\u7edc\u5bf9\u6240\u6709\u4f2a\u6b63\u4ea4\u53d8\u6362\u5177\u6709\u7b49\u53d8\u6027\uff0c\u5e76\u4e14\u901a\u8fc7\u4e00\u79cd\u6743\u91cd\u5171\u4eab\u53c2\u6570\u5316\u6280\u672f\u51cf\u5c11\u4e86\u53ef\u4f18\u5316\u53c2\u6570\u7684\u6570\u91cf\uff0c\u5728\u57fa\u51c6\u6d4b\u8bd5\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u4e3a\u4e86\u5f00\u53d1\u4e00\u79cd\u65b0\u7684\u7b49\u53d8\u91cf\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u8be5\u67b6\u6784\u80fd\u591f\u5904\u7406\u5411\u91cf\u7a7a\u95f4\u4e2d\u7684\u65cb\u8f6c\u548c\u53cd\u5c04\u7b49\u4f2a\u6b63\u672c\u53d8\u6362\uff0c\u5e76\u4e14\u5bf9\u4e8e\u4efb\u4f55\u975e\u9000\u5316\u6216\u9000\u5316\u7684\u5bf9\u79f0\u53cc\u7ebf\u6027\u5f62\u5f0f\u90fd\u4fdd\u6301\u7b49\u53d8\u6027\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u5e7f\u4e49Lipschitz\u7fa4\u7b49\u53d8\u795e\u7ecf\u7f51\u7edc\uff08GLGENN\uff09\uff0c\u8fd9\u79cd\u7f51\u7edc\u5229\u7528\u4e86\u51e0\u4f55\u4ee3\u6570\u7684\u57fa\u672c\u7ed3\u6784\u548c\u8fd0\u7b97\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u8003\u8651\u8fd9\u4e9b\u7279\u6027\u7684\u6743\u91cd\u5171\u4eab\u53c2\u6570\u5316\u6280\u672f\u3002", "result": "GLGENN\u5728\u51e0\u4e2a\u57fa\u51c6\u7684\u7b49\u53d8\u4efb\u52a1\u4e0a\u4f18\u4e8e\u6216\u8005\u4e0e\u7ade\u4e89\u5bf9\u624b\u76f8\u5339\u914d\uff0c\u540c\u65f6\u4f7f\u7528\u4e86\u663e\u8457\u66f4\u5c11\u7684\u53ef\u4f18\u5316\u53c2\u6570\u3002", "conclusion": "GLGENN\u662f\u4e00\u79cd\u6709\u6548\u7684\u7b49\u53d8\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u5b83\u80fd\u591f\u51cf\u5c11\u8fc7\u62df\u5408\u7684\u98ce\u9669\uff0c\u5e76\u4e14\u5728\u6027\u80fd\u4e0a\u53ef\u4ee5\u4e0e\u73b0\u6709\u7684\u7b49\u53d8\u6a21\u578b\u7ade\u4e89\u751a\u81f3\u8d85\u8d8a\u5b83\u4eec\u3002"}}
{"id": "2506.09630", "pdf": "https://arxiv.org/pdf/2506.09630", "abs": "https://arxiv.org/abs/2506.09630", "authors": ["Pol G. Recasens", "Alberto Gutierrez", "Jordi Torres", "Josep. Ll Berral", "Anisa Halimi", "Kieran Fraser"], "title": "In-Context Bias Propagation in LLM-Based Tabular Data Generation", "categories": ["cs.LG"], "comment": "Paper accepted at ICML 2025 workshop DIG-BUG", "summary": "Large Language Models (LLMs) are increasingly used for synthetic tabular data\ngeneration through in-context learning (ICL), offering a practical solution for\ndata augmentation in data scarce scenarios. While prior work has shown the\npotential of LLMs to improve downstream task performance through augmenting\nunderrepresented groups, these benefits often assume access to a subset of\nunbiased in-context examples, representative of the real dataset. In real-world\nsettings, however, data is frequently noisy and demographically skewed. In this\npaper, we systematically study how statistical biases within in-context\nexamples propagate to the distribution of synthetic tabular data, showing that\neven mild in-context biases lead to global statistical distortions. We further\nintroduce an adversarial scenario where a malicious contributor can inject bias\ninto the synthetic dataset via a subset of in-context examples, ultimately\ncompromising the fairness of downstream classifiers for a targeted and\nprotected subgroup. Our findings demonstrate a new vulnerability associated\nwith LLM-based data generation pipelines that rely on in-context prompts with\nin sensitive domains.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u751f\u6210\u5408\u6210\u8868\u683c\u6570\u636e\u65f6\uff0c\u4e0a\u4e0b\u6587\u793a\u4f8b\u4e2d\u5b58\u5728\u7684\u7edf\u8ba1\u504f\u5dee\u5982\u4f55\u4f20\u64ad\u5230\u5408\u6210\u6570\u636e\u4e2d\uff0c\u5e76\u4e14\u5f15\u5165\u4e86\u4e00\u4e2a\u5bf9\u6297\u6027\u573a\u666f\u6765\u5c55\u793a\u6076\u610f\u53c2\u4e0e\u8005\u5982\u4f55\u901a\u8fc7\u90e8\u5206\u4e0a\u4e0b\u6587\u793a\u4f8b\u5411\u5408\u6210\u6570\u636e\u96c6\u4e2d\u6ce8\u5165\u504f\u5dee\uff0c\u4ece\u800c\u5f71\u54cd\u4e0b\u6e38\u5206\u7c7b\u5668\u7684\u516c\u5e73\u6027\u3002", "motivation": "\u5728\u73b0\u5b9e\u4e16\u754c\u7684\u5e94\u7528\u4e2d\uff0c\u7528\u4e8e\u589e\u5f3a\u6570\u636e\u7684\u6570\u636e\u5f80\u5f80\u662f\u566a\u58f0\u5927\u4e14\u4eba\u53e3\u7edf\u8ba1\u6570\u636e\u6709\u504f\u7684\u3002\u5148\u524d\u7684\u5de5\u4f5c\u901a\u5e38\u5047\u8bbe\u53ef\u4ee5\u83b7\u5f97\u65e0\u504f\u7684\u4e0a\u4e0b\u6587\u793a\u4f8b\u5b50\u96c6\uff0c\u4f46\u8fd9\u4e9b\u5047\u8bbe\u53ef\u80fd\u4e0d\u6210\u7acb\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u4eec\u5e0c\u671b\u4e86\u89e3\u4e0a\u4e0b\u6587\u793a\u4f8b\u4e2d\u7684\u7edf\u8ba1\u504f\u5dee\u5982\u4f55\u5f71\u54cd\u5408\u6210\u6570\u636e\u7684\u5206\u5e03\uff0c\u5e76\u63a2\u7d22\u8fd9\u79cd\u504f\u5dee\u662f\u5426\u4f1a\u5bfc\u81f4\u4e0b\u6e38\u4efb\u52a1\u7684\u4e0d\u516c\u5e73\u3002", "method": "\u901a\u8fc7\u5bf9\u4e0d\u540c\u504f\u5dee\u7a0b\u5ea6\u7684\u4e0a\u4e0b\u6587\u793a\u4f8b\u8fdb\u884c\u7cfb\u7edf\u7684\u7814\u7a76\uff0c\u4ee5\u53ca\u8bbe\u8ba1\u4e00\u4e2a\u5bf9\u6297\u6027\u7684\u573a\u666f\uff0c\u5176\u4e2d\u6076\u610f\u8d21\u732e\u8005\u80fd\u591f\u901a\u8fc7\u4e00\u5c0f\u90e8\u5206\u4e0a\u4e0b\u6587\u793a\u4f8b\u5c06\u504f\u5dee\u6ce8\u5165\u5408\u6210\u6570\u636e\u96c6\uff0c\u4ece\u800c\u8bc4\u4f30\u5bf9\u76ee\u6807\u548c\u53d7\u4fdd\u62a4\u5b50\u7fa4\u4f53\u7684\u4e0b\u6e38\u5206\u7c7b\u5668\u516c\u5e73\u6027\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u8868\u660e\u5373\u4f7f\u662f\u5f88\u5c0f\u7684\u4e0a\u4e0b\u6587\u504f\u5dee\u4e5f\u4f1a\u5bfc\u81f4\u5168\u5c40\u7edf\u8ba1\u5931\u771f\u3002\u6b64\u5916\uff0c\u5728\u5bf9\u6297\u6027\u573a\u666f\u4e0b\uff0c\u6076\u610f\u8d21\u732e\u8005\u786e\u5b9e\u53ef\u4ee5\u901a\u8fc7\u63a7\u5236\u4e00\u90e8\u5206\u4e0a\u4e0b\u6587\u793a\u4f8b\u6765\u635f\u5bb3\u7279\u5b9a\u5b50\u7fa4\u4f53\u7684\u5229\u76ca\uff0c\u8fd9\u8868\u660e\u57fa\u4e8eLLM\u7684\u6570\u636e\u751f\u6210\u7ba1\u9053\u5b58\u5728\u65b0\u7684\u6f0f\u6d1e\u3002", "conclusion": "\u4f9d\u8d56\u4e8e\u654f\u611f\u9886\u57df\u5185\u4e0a\u4e0b\u6587\u63d0\u793a\u7684LLM\u6570\u636e\u751f\u6210\u6d41\u7a0b\u5b58\u5728\u7740\u4e0e\u7edf\u8ba1\u504f\u5dee\u76f8\u5173\u7684\u8106\u5f31\u6027\uff0c\u8fd9\u53ef\u80fd\u4f1a\u88ab\u5229\u7528\u6765\u7834\u574f\u4e0b\u6e38\u5206\u7c7b\u5668\u5bf9\u4e8e\u7279\u5b9a\u5b50\u7fa4\u4f53\u7684\u516c\u5e73\u6027\u3002"}}
{"id": "2506.09638", "pdf": "https://arxiv.org/pdf/2506.09638", "abs": "https://arxiv.org/abs/2506.09638", "authors": ["Weiying Zheng", "Ziyue Lin", "Pengxin Guo", "Yuyin Zhou", "Feifei Wang", "Liangqiong Qu"], "title": "FedVLMBench: Benchmarking Federated Fine-Tuning of Vision-Language Models", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Vision-Language Models (VLMs) have demonstrated remarkable capabilities in\ncross-modal understanding and generation by integrating visual and textual\ninformation. While instruction tuning and parameter-efficient fine-tuning\nmethods have substantially improved the generalization of VLMs, most existing\napproaches rely on centralized training, posing challenges for deployment in\ndomains with strict privacy requirements like healthcare. Recent efforts have\nintroduced Federated Learning (FL) into VLM fine-tuning to address these\nprivacy concerns, yet comprehensive benchmarks for evaluating federated\nfine-tuning strategies, model architectures, and task generalization remain\nlacking. In this work, we present \\textbf{FedVLMBench}, the first systematic\nbenchmark for federated fine-tuning of VLMs. FedVLMBench integrates two\nmainstream VLM architectures (encoder-based and encoder-free), four fine-tuning\nstrategies, five FL algorithms, six multimodal datasets spanning four\ncross-domain single-task scenarios and two cross-domain multitask settings,\ncovering four distinct downstream task categories. Through extensive\nexperiments, we uncover key insights into the interplay between VLM\narchitectures, fine-tuning strategies, data heterogeneity, and multi-task\nfederated optimization. Notably, we find that a 2-layer multilayer perceptron\n(MLP) connector with concurrent connector and LLM tuning emerges as the optimal\nconfiguration for encoder-based VLMs in FL. Furthermore, current FL methods\nexhibit significantly higher sensitivity to data heterogeneity in\nvision-centric tasks than text-centric ones, across both encoder-free and\nencoder-based VLM architectures. Our benchmark provides essential tools,\ndatasets, and empirical guidance for the research community, offering a\nstandardized platform to advance privacy-preserving, federated training of\nmultimodal foundation models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86FedVLMBench\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u8054\u90a6\u5fae\u8c03\u7684\u7cfb\u7edf\u6027\u57fa\u51c6\u6d4b\u8bd5\u3002\u5b83\u6db5\u76d6\u4e86\u4e24\u79cd\u4e3b\u6d41VLM\u67b6\u6784\u3001\u56db\u79cd\u5fae\u8c03\u7b56\u7565\u3001\u4e94\u79cd\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u4ee5\u53ca\u516d\u4e2a\u8de8\u9886\u57df\u7684\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u63ed\u793a\u4e86VLM\u67b6\u6784\u3001\u5fae\u8c03\u7b56\u7565\u3001\u6570\u636e\u5f02\u8d28\u6027\u548c\u591a\u4efb\u52a1\u8054\u90a6\u4f18\u5316\u4e4b\u95f4\u7684\u5173\u952e\u89c1\u89e3\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u867d\u7136\u5728\u8de8\u6a21\u6001\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5927\u591a\u4f9d\u8d56\u4e8e\u96c6\u4e2d\u5f0f\u8bad\u7ec3\uff0c\u8fd9\u5728\u533b\u7597\u7b49\u5bf9\u9690\u79c1\u8981\u6c42\u4e25\u683c\u7684\u9886\u57df\u4e2d\u5e26\u6765\u4e86\u6311\u6218\u3002\u5c3d\u7ba1\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u5df2\u88ab\u5f15\u5165\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u9690\u79c1\u95ee\u9898\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u8054\u90a6\u5fae\u8c03\u7b56\u7565\u3001\u6a21\u578b\u67b6\u6784\u548c\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u7814\u7a76\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aFedVLMBench\u7684\u57fa\u51c6\uff0c\u5b83\u6574\u5408\u4e86\u4e24\u79cd\u4e3b\u6d41VLM\u67b6\u6784\uff08\u57fa\u4e8e\u7f16\u7801\u5668\u7684\u548c\u65e0\u7f16\u7801\u5668\u7684\uff09\u3001\u56db\u79cd\u5fae\u8c03\u7b56\u7565\u3001\u4e94\u79cd\u8054\u90a6\u5b66\u4e60\u7b97\u6cd5\u53ca\u591a\u4e2a\u8de8\u57df\u591a\u6a21\u6001\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5bf9\u4e8e\u57fa\u4e8e\u7f16\u7801\u5668\u7684VLMs\uff0c\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u4f7f\u75282\u5c42\u591a\u5c42\u611f\u77e5\u673a\uff08MLP\uff09\u8fde\u63a5\u5668\u5e76\u540c\u65f6\u8c03\u6574\u8fde\u63a5\u5668\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u6700\u4f73\u914d\u7f6e\u3002\u6b64\u5916\uff0c\u5f53\u524d\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\u5bf9\u89c6\u89c9\u4e3a\u4e2d\u5fc3\u7684\u4efb\u52a1\u6bd4\u6587\u672c\u4e3a\u4e2d\u5fc3\u7684\u4efb\u52a1\u66f4\u52a0\u654f\u611f\u4e8e\u6570\u636e\u5f02\u8d28\u6027\u3002", "conclusion": "FedVLMBench\u4e3a\u7814\u7a76\u793e\u533a\u63d0\u4f9b\u4e86\u5fc5\u8981\u7684\u5de5\u5177\u3001\u6570\u636e\u96c6\u548c\u5b9e\u8bc1\u6307\u5bfc\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6807\u51c6\u5316\u5e73\u53f0\u4ee5\u63a8\u8fdb\u9690\u79c1\u4fdd\u62a4\u7684\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u7684\u8054\u90a6\u8bad\u7ec3\u3002"}}
{"id": "2506.09660", "pdf": "https://arxiv.org/pdf/2506.09660", "abs": "https://arxiv.org/abs/2506.09660", "authors": ["Baran Can G\u00fcl", "Stefanos Tziampazis", "Nasser Jazdi", "Michael Weyrich"], "title": "SyncFed: Time-Aware Federated Learning through Explicit Timestamping and Synchronization", "categories": ["cs.LG", "cs.DC"], "comment": "Preprint version. Accepted for publication at IEEE ETFA 2025", "summary": "As Federated Learning (FL) expands to larger and more distributed\nenvironments, consistency in training is challenged by network-induced delays,\nclock unsynchronicity, and variability in client updates. This combination of\nfactors may contribute to misaligned contributions that undermine model\nreliability and convergence. Existing methods like staleness-aware aggregation\nand model versioning address lagging updates heuristically, yet lack mechanisms\nto quantify staleness, especially in latency-sensitive and cross-regional\ndeployments. In light of these considerations, we introduce \\emph{SyncFed}, a\ntime-aware FL framework that employs explicit synchronization and timestamping\nto establish a common temporal reference across the system. Staleness is\nquantified numerically based on exchanged timestamps under the Network Time\nProtocol (NTP), enabling the server to reason about the relative freshness of\nclient updates and apply temporally informed weighting during aggregation. Our\nempirical evaluation on a geographically distributed testbed shows that, under\n\\emph{SyncFed}, the global model evolves within a stable temporal context,\nresulting in improved accuracy and information freshness compared to\nround-based baselines devoid of temporal semantics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSyncFed\u7684\u65f6\u95f4\u611f\u77e5\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u540c\u6b65\u548c\u65f6\u95f4\u6233\u6765\u91cf\u5316\u9648\u65e7\u6027\uff0c\u5e76\u5728\u805a\u5408\u8fc7\u7a0b\u4e2d\u5e94\u7528\u57fa\u4e8e\u65f6\u95f4\u4fe1\u606f\u7684\u52a0\u6743\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u6a21\u578b\u51c6\u786e\u6027\u53ca\u4fe1\u606f\u7684\u65b0\u9c9c\u5ea6\u3002", "motivation": "\u968f\u7740\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u6269\u5c55\u5230\u66f4\u5927\u3001\u66f4\u5206\u6563\u7684\u73af\u5883\u4e2d\uff0c\u7f51\u7edc\u5f15\u8d77\u7684\u5ef6\u8fdf\u3001\u65f6\u949f\u4e0d\u540c\u6b65\u4ee5\u53ca\u5ba2\u6237\u7aef\u66f4\u65b0\u7684\u53ef\u53d8\u6027\u7ed9\u8bad\u7ec3\u7684\u4e00\u81f4\u6027\u5e26\u6765\u4e86\u6311\u6218\u3002\u8fd9\u4e9b\u56e0\u7d20\u53ef\u80fd\u5bfc\u81f4\u8d21\u732e\u4e0d\u4e00\u81f4\uff0c\u4ece\u800c\u7834\u574f\u4e86\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u6536\u655b\u6027\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u5982\u9648\u65e7\u610f\u8bc6\u805a\u5408\u548c\u6a21\u578b\u7248\u672c\u63a7\u5236\u867d\u7136\u80fd\u591f\u542f\u53d1\u5f0f\u5730\u5904\u7406\u6ede\u540e\u7684\u66f4\u65b0\uff0c\u4f46\u7f3a\u4e4f\u91cf\u5316\u9648\u65e7\u6027\u7684\u673a\u5236\uff0c\u7279\u522b\u662f\u5728\u5bf9\u5ef6\u8fdf\u654f\u611f\u548c\u8de8\u533a\u57df\u90e8\u7f72\u4e2d\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86SyncFed\uff0c\u4e00\u79cd\u65f6\u95f4\u611f\u77e5\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u663e\u5f0f\u540c\u6b65\u548c\u65f6\u95f4\u6233\u6765\u5728\u6574\u4e2a\u7cfb\u7edf\u4e2d\u5efa\u7acb\u4e00\u4e2a\u5171\u540c\u7684\u65f6\u95f4\u53c2\u8003\u3002\u57fa\u4e8e\u7f51\u7edc\u65f6\u95f4\u534f\u8bae(NTP)\u4ea4\u6362\u7684\u65f6\u95f4\u6233\u6570\u503c\u4e0a\u91cf\u5316\u4e86\u9648\u65e7\u6027\uff0c\u4f7f\u670d\u52a1\u5668\u80fd\u591f\u63a8\u7406\u5ba2\u6237\u66f4\u65b0\u7684\u76f8\u5bf9\u65b0\u9c9c\u5ea6\uff0c\u5e76\u5728\u805a\u5408\u8fc7\u7a0b\u4e2d\u5e94\u7528\u57fa\u4e8e\u65f6\u95f4\u7684\u4fe1\u606f\u6743\u91cd\u3002", "result": "\u5728\u5730\u7406\u5206\u5e03\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u5728SyncFed\u4e0b\uff0c\u5168\u5c40\u6a21\u578b\u5728\u4e00\u4e2a\u7a33\u5b9a\u7684\u65f6\u95f4\u4e0a\u4e0b\u6587\u4e2d\u6f14\u5316\uff0c\u4e0e\u7f3a\u4e4f\u65f6\u95f4\u8bed\u4e49\u7684\u57fa\u4e8e\u8f6e\u6b21\u7684\u57fa\u7ebf\u76f8\u6bd4\uff0c\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u4fe1\u606f\u65b0\u9c9c\u5ea6\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165SyncFed\uff0c\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u79cd\u89e3\u51b3\u8054\u90a6\u5b66\u4e60\u4e2d\u7531\u4e8e\u7f51\u7edc\u5ef6\u8fdf\u7b49\u56e0\u7d20\u5bfc\u81f4\u7684\u66f4\u65b0\u4e0d\u540c\u6b65\u95ee\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6a21\u578b\u6027\u80fd\u548c\u6570\u636e\u65f6\u6548\u6027\u3002"}}
{"id": "2506.09674", "pdf": "https://arxiv.org/pdf/2506.09674", "abs": "https://arxiv.org/abs/2506.09674", "authors": ["Alessandro Licciardi", "Davide Leo", "Davide Carbone"], "title": "Wavelet Scattering Transform and Fourier Representation for Offline Detection of Malicious Clients in Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated Learning (FL) enables the training of machine learning models\nacross decentralized clients while preserving data privacy. However, the\npresence of anomalous or corrupted clients - such as those with faulty sensors\nor non representative data distributions - can significantly degrade model\nperformance. Detecting such clients without accessing raw data remains a key\nchallenge. We propose WAFFLE (Wavelet and Fourier representations for Federated\nLearning) a detection algorithm that labels malicious clients {\\it before\ntraining}, using locally computed compressed representations derived from\neither the Wavelet Scattering Transform (WST) or the Fourier Transform. Both\napproaches provide low-dimensional, task-agnostic embeddings suitable for\nunsupervised client separation. A lightweight detector, trained on a\ndistillated public dataset, performs the labeling with minimal communication\nand computational overhead. While both transforms enable effective detection,\nWST offers theoretical advantages, such as non-invertibility and stability to\nlocal deformations, that make it particularly well-suited to federated\nscenarios. Experiments on benchmark datasets show that our method improves\ndetection accuracy and downstream classification performance compared to\nexisting FL anomaly detection algorithms, validating its effectiveness as a\npre-training alternative to online detection strategies.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWAFFLE\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u8054\u90a6\u5b66\u4e60\u4e2d\u5229\u7528\u5c0f\u6ce2\u6563\u5c04\u53d8\u6362(WST)\u6216\u5085\u91cc\u53f6\u53d8\u6362\u751f\u6210\u538b\u7f29\u8868\u793a\u6765\u68c0\u6d4b\u5f02\u5e38\u5ba2\u6237\u7aef\uff0c\u65e0\u9700\u8bbf\u95ee\u539f\u59cb\u6570\u636e\uff0c\u5e76\u4e14\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u7684FL\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u4e0b\u6e38\u5206\u7c7b\u6027\u80fd\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u4e2d\u7684\u5f02\u5e38\u6216\u635f\u574f\u5ba2\u6237\u7aef\uff08\u4f8b\u5982\u4f20\u611f\u5668\u6545\u969c\u6216\u6570\u636e\u5206\u5e03\u975e\u4ee3\u8868\u6027\uff09\u53ef\u80fd\u4f1a\u663e\u8457\u964d\u4f4e\u6a21\u578b\u6027\u80fd\u3002\u5982\u4f55\u5728\u4e0d\u8bbf\u95ee\u539f\u59cb\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u68c0\u6d4b\u8fd9\u4e9b\u5ba2\u6237\u7aef\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86WAFFLE\u7b97\u6cd5\uff0c\u5b83\u4f7f\u7528\u672c\u5730\u8ba1\u7b97\u7684\u5c0f\u6ce2\u6563\u5c04\u53d8\u6362(WST)\u6216\u5085\u91cc\u53f6\u53d8\u6362\u4ea7\u751f\u7684\u538b\u7f29\u8868\u793a\u6765\u6807\u8bb0\u6076\u610f\u5ba2\u6237\u7aef\u3002\u4e24\u79cd\u65b9\u6cd5\u90fd\u63d0\u4f9b\u4e86\u4f4e\u7ef4\u5ea6\u3001\u4efb\u52a1\u65e0\u5173\u7684\u5d4c\u5165\uff0c\u9002\u5408\u65e0\u76d1\u7763\u7684\u5ba2\u6237\u7aef\u5206\u79bb\u3002\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u68c0\u6d4b\u5668\u901a\u8fc7\u5bf9\u516c\u5171\u6570\u636e\u96c6\u8fdb\u884c\u84b8\u998f\u8bad\u7ec3\uff0c\u4ee5\u6700\u5c0f\u7684\u901a\u4fe1\u548c\u8ba1\u7b97\u5f00\u9500\u6267\u884c\u6807\u8bb0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u7684\u8054\u90a6\u5b66\u4e60\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u65b9\u6cd5\u63d0\u9ad8\u4e86\u68c0\u6d4b\u51c6\u786e\u6027\u53ca\u540e\u7eed\u5206\u7c7b\u6027\u80fd\u3002", "conclusion": "WAFFLE\u7b97\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u9884\u8bad\u7ec3\u66ff\u4ee3\u65b9\u6848\uff0c\u7528\u4e8e\u68c0\u6d4b\u8054\u90a6\u5b66\u4e60\u73af\u5883\u4e0b\u7684\u5f02\u5e38\u5ba2\u6237\u7aef\uff0c\u5176\u4e2dWST\u7531\u4e8e\u5176\u4e0d\u53ef\u9006\u6027\u548c\u5bf9\u5c40\u90e8\u53d8\u5f62\u7684\u7a33\u5b9a\u6027\u800c\u7279\u522b\u9002\u7528\u4e8e\u8054\u90a6\u573a\u666f\u3002"}}
{"id": "2506.09682", "pdf": "https://arxiv.org/pdf/2506.09682", "abs": "https://arxiv.org/abs/2506.09682", "authors": ["Iulia Duta", "Pietro Li\u00f2"], "title": "Wasserstein Hypergraph Neural Network", "categories": ["cs.LG"], "comment": null, "summary": "The ability to model relational information using machine learning has driven\nadvancements across various domains, from medicine to social science. While\ngraph representation learning has become mainstream over the past decade,\nrepresenting higher-order relationships through hypergraphs is rapidly gaining\nmomentum. In the last few years, numerous hypergraph neural networks have\nemerged, most of them falling under a two-stage, set-based framework. The\nmessages are sent from nodes to edges and then from edges to nodes. However,\nmost of the advancement still takes inspiration from the graph counterpart,\noften simplifying the aggregations to basic pooling operations. In this paper\nwe are introducing Wasserstein Hypergraph Neural Network, a model that treats\nthe nodes and hyperedge neighbourhood as distributions and aggregate the\ninformation using Sliced Wasserstein Pooling. Unlike conventional aggregators\nsuch as mean or sum, which only capture first-order statistics, our approach\nhas the ability to preserve geometric properties like the shape and spread of\ndistributions. This enables the learned embeddings to reflect how easily one\nhyperedge distribution can be transformed into another, following principles of\noptimal transport. Experimental results demonstrate that applying Wasserstein\npooling in a hypergraph setting significantly benefits node classification\ntasks, achieving top performance on several real-world datasets.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86Wasserstein\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u5b83\u5c06\u8282\u70b9\u548c\u8d85\u8fb9\u90bb\u57df\u89c6\u4e3a\u5206\u5e03\uff0c\u5e76\u4f7f\u7528Sliced Wasserstein Pooling\u6765\u805a\u5408\u4fe1\u606f\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u4fdd\u6301\u5206\u5e03\u7684\u51e0\u4f55\u7279\u6027\uff0c\u4ece\u800c\u5728\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u4f18\u52bf\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8e\u56fe\u8868\u793a\u5b66\u4e60\u5728\u8fc7\u53bb\u5341\u5e74\u4e2d\u5df2\u6210\u4e3a\u4e3b\u6d41\uff0c\u4f46\u901a\u8fc7\u8d85\u56fe\u8868\u793a\u9ad8\u9636\u5173\u7cfb\u6b63\u5728\u8fc5\u901f\u83b7\u5f97\u5173\u6ce8\u3002\u5f53\u524d\u5927\u591a\u6570\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4ecd\u7136\u501f\u9274\u4e86\u56fe\u7684\u65b9\u6cd5\uff0c\u901a\u5e38\u5c06\u805a\u5408\u7b80\u5316\u4e3a\u57fa\u672c\u7684\u6c60\u5316\u64cd\u4f5c\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u6a21\u578b\uff0c\u65e8\u5728\u66f4\u597d\u5730\u6355\u6349\u5206\u5e03\u7684\u51e0\u4f55\u5c5e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWasserstein\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u65b0\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u8282\u70b9\u548c\u8d85\u8fb9\u90bb\u57df\u89c6\u4e3a\u6982\u7387\u5206\u5e03\uff0c\u5e76\u5229\u7528Sliced Wasserstein Pooling\u6765\u805a\u96c6\u4fe1\u606f\u3002\u4e0e\u4f20\u7edf\u7684\u5747\u503c\u6216\u6c42\u548c\u805a\u5408\u5668\u76f8\u6bd4\uff0c\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u4fdd\u7559\u5206\u5e03\u7684\u5f62\u72b6\u548c\u6269\u5c55\u7b49\u51e0\u4f55\u5c5e\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u8d85\u56fe\u73af\u5883\u4e0b\u5e94\u7528Wasserstein\u6c60\u5316\u5bf9\u4e8e\u8282\u70b9\u5206\u7c7b\u4efb\u52a1\u5177\u6709\u663e\u8457\u7684\u597d\u5904\uff0c\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "Wasserstein\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u91c7\u7528Sliced Wasserstein Pooling\u4f5c\u4e3a\u4fe1\u606f\u805a\u5408\u624b\u6bb5\uff0c\u80fd\u591f\u6709\u6548\u5730\u4fdd\u5b58\u8282\u70b9\u548c\u8d85\u8fb9\u90bb\u57df\u7684\u51e0\u4f55\u6027\u8d28\uff0c\u8fd9\u4f7f\u5f97\u6240\u5b66\u5f97\u7684\u5d4c\u5165\u80fd\u591f\u53cd\u6620\u4e00\u4e2a\u8d85\u8fb9\u5206\u5e03\u8f6c\u53d8\u4e3a\u53e6\u4e00\u4e2a\u5206\u5e03\u7684\u96be\u6613\u7a0b\u5ea6\u3002\u6b64\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5c55\u793a\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2506.09714", "pdf": "https://arxiv.org/pdf/2506.09714", "abs": "https://arxiv.org/abs/2506.09714", "authors": ["Vaggelis Dorovatas", "Georgios Paraskevopoulos", "Alexandros Potamianos"], "title": "Auto-Compressing Networks", "categories": ["cs.LG"], "comment": null, "summary": "Deep neural networks with short residual connections have demonstrated\nremarkable success across domains, but increasing depth often introduces\ncomputational redundancy without corresponding improvements in representation\nquality. In this work, we introduce Auto-Compressing Networks (ACNs), an\narchitectural variant where additive long feedforward connections from each\nlayer to the output replace traditional short residual connections. ACNs\nshowcase a unique property we coin as \"auto-compression\", the ability of a\nnetwork to organically compress information during training with gradient\ndescent, through architectural design alone. Through auto-compression,\ninformation is dynamically \"pushed\" into early layers during training,\nenhancing their representational quality and revealing potential redundancy in\ndeeper ones. We theoretically show that this property emerges from layer-wise\ntraining patterns present in ACNs, where layers are dynamically utilized during\ntraining based on task requirements. We also find that ACNs exhibit enhanced\nnoise robustness compared to residual networks, superior performance in\nlow-data settings, improved transfer learning capabilities, and mitigate\ncatastrophic forgetting suggesting that they learn representations that\ngeneralize better despite using fewer parameters. Our results demonstrate up to\n18% reduction in catastrophic forgetting and 30-80% architectural compression\nwhile maintaining accuracy across vision transformers, MLP-mixers, and BERT\narchitectures. Furthermore, we demonstrate that coupling ACNs with traditional\npruning techniques, enables significantly better sparsity-performance\ntrade-offs compared to conventional architectures. These findings establish\nACNs as a practical approach to developing efficient neural architectures that\nautomatically adapt their computational footprint to task complexity, while\nlearning robust representations.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u2014\u2014\u81ea\u52a8\u538b\u7f29\u7f51\u7edc\uff08ACNs\uff09\uff0c\u901a\u8fc7\u7528\u4ece\u6bcf\u4e00\u5c42\u5230\u8f93\u51fa\u7684\u957f\u524d\u9988\u8fde\u63a5\u66ff\u6362\u4f20\u7edf\u7684\u77ed\u6b8b\u5dee\u8fde\u63a5\uff0c\u5b9e\u73b0\u4e86\u4fe1\u606f\u7684\u6709\u673a\u538b\u7f29\u3002\u8fd9\u79cd\u8bbe\u8ba1\u4e0d\u4ec5\u589e\u5f3a\u4e86\u65e9\u671f\u5c42\u7684\u8868\u5f81\u8d28\u91cf\uff0c\u8fd8\u63ed\u793a\u4e86\u6df1\u5c42\u4e2d\u7684\u6f5c\u5728\u5197\u4f59\u3002ACNs\u8868\u73b0\u51fa\u66f4\u597d\u7684\u566a\u58f0\u9c81\u68d2\u6027\u3001\u5728\u4f4e\u6570\u636e\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\u63d0\u5347\u3001\u6539\u8fdb\u7684\u8fc1\u79fb\u5b66\u4e60\u80fd\u529b\u4ee5\u53ca\u51cf\u8f7b\u707e\u96be\u6027\u9057\u5fd8\u7684\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u8be5\u65b9\u6cd5\u53ef\u51cf\u5c11\u9ad8\u8fbe18%\u7684\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5e76\u5b9e\u73b030-80%\u7684\u67b6\u6784\u538b\u7f29\u3002\u6b64\u5916\uff0c\u5c06ACNs\u4e0e\u4f20\u7edf\u526a\u679d\u6280\u672f\u7ed3\u5408\u4f7f\u7528\u65f6\uff0c\u80fd\u591f\u6bd4\u4f20\u7edf\u67b6\u6784\u83b7\u5f97\u66f4\u4f18\u7684\u7a00\u758f\u6027-\u6027\u80fd\u6743\u8861\u3002", "motivation": "\u5c3d\u7ba1\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u591a\u4e2a\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u529f\uff0c\u4f46\u589e\u52a0\u7f51\u7edc\u6df1\u5ea6\u5f80\u5f80\u4f1a\u5bfc\u81f4\u8ba1\u7b97\u5197\u4f59\uff0c\u800c\u4e0d\u4f1a\u76f8\u5e94\u5730\u63d0\u9ad8\u8868\u5f81\u8d28\u91cf\u3002\u57fa\u4e8e\u6b64\uff0c\u7814\u7a76\u8005\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u65b0\u67b6\u6784\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u7814\u7a76\u8005\u5f15\u5165\u4e86\u4e00\u79cd\u540d\u4e3a\u81ea\u52a8\u538b\u7f29\u7f51\u7edc\uff08Auto-Compressing Networks, ACNs\uff09\u7684\u65b0\u67b6\u6784\u53d8\u4f53\uff0c\u5b83\u5229\u7528\u4ece\u6bcf\u4e2a\u5c42\u5230\u8f93\u51fa\u7684\u52a0\u6cd5\u957f\u524d\u9988\u8fde\u63a5\u66ff\u4ee3\u4e86\u4f20\u7edf\u7684\u77ed\u6b8b\u5dee\u8fde\u63a5\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u7f51\u7edc\u80fd\u591f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u81ea\u7136\u5730\u538b\u7f29\u4fe1\u606f\uff0c\u5373\u6240\u8c13\u7684\u201c\u81ea\u538b\u7f29\u201d\u7279\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cACNs\u76f8\u6bd4\u6b8b\u5dee\u7f51\u7edc\u5177\u6709\u66f4\u5f3a\u7684\u566a\u58f0\u9c81\u68d2\u6027\u3001\u5728\u5c11\u91cf\u6570\u636e\u573a\u666f\u4e0b\u7684\u4f18\u8d8a\u8868\u73b0\u3001\u6539\u8fdb\u540e\u7684\u8fc1\u79fb\u5b66\u4e60\u80fd\u529b\u548c\u51cf\u8f7b\u4e86\u707e\u96be\u6027\u9057\u5fd8\u7684\u95ee\u9898\u3002\u6b64\u5916\uff0c\u8be5\u67b6\u6784\u8fd8\u80fd\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u51cf\u5c11\u9ad8\u8fbe18%\u7684\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5e76\u5b9e\u73b030-80%\u7684\u7ed3\u6784\u538b\u7f29\u3002\u5f53\u4e0e\u4f20\u7edf\u4fee\u526a\u6280\u672f\u76f8\u7ed3\u5408\u65f6\uff0cACNs\u80fd\u63d0\u4f9b\u6bd4\u5e38\u89c4\u67b6\u6784\u66f4\u597d\u7684\u7a00\u758f\u5ea6-\u6027\u80fd\u5e73\u8861\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cACNs\u662f\u4e00\u79cd\u5b9e\u7528\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5f00\u53d1\u80fd\u591f\u6839\u636e\u4efb\u52a1\u590d\u6742\u5ea6\u81ea\u52a8\u8c03\u6574\u5176\u8ba1\u7b97\u91cf\u7684\u6709\u6548\u795e\u7ecf\u67b6\u6784\uff0c\u540c\u65f6\u5b66\u4e60\u66f4\u52a0\u9c81\u68d2\u7684\u8868\u5f81\u3002"}}
{"id": "2506.09738", "pdf": "https://arxiv.org/pdf/2506.09738", "abs": "https://arxiv.org/abs/2506.09738", "authors": ["Xin Wang", "Zeyang Zhang", "Linxin Xiao", "Haibo Chen", "Chendi Ge", "Wenwu Zhu"], "title": "Towards Multi-modal Graph Large Language Model", "categories": ["cs.LG"], "comment": null, "summary": "Multi-modal graphs, which integrate diverse multi-modal features and\nrelations, are ubiquitous in real-world applications. However, existing\nmulti-modal graph learning methods are typically trained from scratch for\nspecific graph data and tasks, failing to generalize across various multi-modal\ngraph data and tasks. To bridge this gap, we explore the potential of\nMulti-modal Graph Large Language Models (MG-LLM) to unify and generalize across\ndiverse multi-modal graph data and tasks. We propose a unified framework of\nmulti-modal graph data, task, and model, discovering the inherent\nmulti-granularity and multi-scale characteristics in multi-modal graphs.\nSpecifically, we present five key desired characteristics for MG-LLM: 1)\nunified space for multi-modal structures and attributes, 2) capability of\nhandling diverse multi-modal graph tasks, 3) multi-modal graph in-context\nlearning, 4) multi-modal graph interaction with natural language, and 5)\nmulti-modal graph reasoning. We then elaborate on the key challenges, review\nrelated works, and highlight promising future research directions towards\nrealizing these ambitious characteristics. Finally, we summarize existing\nmulti-modal graph datasets pertinent for model training. We believe this paper\ncan contribute to the ongoing advancement of the research towards MG-LLM for\ngeneralization across multi-modal graph data and tasks.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u591a\u6a21\u6001\u56fe\u5927\u8bed\u8a00\u6a21\u578b\uff08MG-LLM\uff09\u5728\u7edf\u4e00\u548c\u6cdb\u5316\u4e0d\u540c\u7c7b\u578b\u591a\u6a21\u6001\u56fe\u6570\u636e\u548c\u4efb\u52a1\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e86MG-LLM\u7684\u4e94\u4e2a\u5173\u952e\u7279\u6027\uff0c\u5206\u6790\u4e86\u4e3b\u8981\u6311\u6218\u3001\u56de\u987e\u4e86\u76f8\u5173\u5de5\u4f5c\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u56fe\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u9488\u5bf9\u7279\u5b9a\u56fe\u6570\u636e\u548c\u4efb\u52a1\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3\uff0c\u65e0\u6cd5\u8de8\u591a\u79cd\u591a\u6a21\u6001\u56fe\u6570\u636e\u548c\u4efb\u52a1\u8fdb\u884c\u6cdb\u5316\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u56fe\u6570\u636e\u3001\u4efb\u52a1\u548c\u6a21\u578b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u53d1\u73b0\u4e86\u591a\u6a21\u6001\u56fe\u4e2d\u56fa\u6709\u7684\u591a\u7c92\u5ea6\u548c\u591a\u5c3a\u5ea6\u7279\u6027\uff0c\u5e76\u9610\u8ff0\u4e86MG-LLM\u7684\u4e94\u4e2a\u5173\u952e\u671f\u671b\u7279\u6027\u3002", "result": "\u8bba\u6587\u603b\u7ed3\u4e86\u73b0\u6709\u76f8\u5173\u7684\u591a\u6a21\u6001\u56fe\u6570\u636e\u96c6\uff0c\u4ee5\u652f\u6301\u6a21\u578b\u8bad\u7ec3\uff0c\u5e76\u8ba4\u4e3a\u8be5\u6587\u53ef\u4ee5\u4e3aMG-LLM\u7684\u7814\u7a76\u8fdb\u5c55\u505a\u51fa\u8d21\u732e\uff0c\u4ee5\u4fbf\u5728\u591a\u6a21\u6001\u56fe\u6570\u636e\u548c\u4efb\u52a1\u4e0a\u5b9e\u73b0\u6cdb\u5316\u3002", "conclusion": "\u6587\u7ae0\u4e3a\u591a\u6a21\u6001\u56fe\u5927\u8bed\u8a00\u6a21\u578b(MG-LLM)\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u6307\u51fa\u4e86\u5176\u5728\u5904\u7406\u591a\u6a21\u6001\u56fe\u6570\u636e\u548c\u4efb\u52a1\u65f6\u7684\u6f5c\u5728\u4f18\u52bf\u53ca\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2506.09803", "pdf": "https://arxiv.org/pdf/2506.09803", "abs": "https://arxiv.org/abs/2506.09803", "authors": ["Longzhu He", "Chaozhuo Li", "Peng Tang", "Litian Zhang", "Sen Su"], "title": "Devil's Hand: Data Poisoning Attacks to Locally Private Graph Learning Protocols", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Graph neural networks (GNNs) have achieved significant success in graph\nrepresentation learning and have been applied to various domains. However, many\nreal-world graphs contain sensitive personal information, such as user profiles\nin social networks, raising serious privacy concerns when graph learning is\nperformed using GNNs. To address this issue, locally private graph learning\nprotocols have gained considerable attention. These protocols leverage the\nprivacy advantages of local differential privacy (LDP) and the effectiveness of\nGNN's message-passing in calibrating noisy data, offering strict privacy\nguarantees for users' local data while maintaining high utility (e.g., node\nclassification accuracy) for graph learning. Despite these advantages, such\nprotocols may be vulnerable to data poisoning attacks, a threat that has not\nbeen considered in previous research. Identifying and addressing these threats\nis crucial for ensuring the robustness and security of privacy-preserving graph\nlearning frameworks. This work introduces the first data poisoning attack\ntargeting locally private graph learning protocols. The attacker injects fake\nusers into the protocol, manipulates these fake users to establish links with\ngenuine users, and sends carefully crafted data to the server, ultimately\ncompromising the utility of private graph learning. The effectiveness of the\nattack is demonstrated both theoretically and empirically. In addition, several\ndefense strategies have also been explored, but their limited effectiveness\nhighlights the need for more robust defenses.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u9488\u5bf9\u672c\u5730\u79c1\u6709\u56fe\u5b66\u4e60\u534f\u8bae\u7684\u9996\u6b21\u6570\u636e\u6295\u6bd2\u653b\u51fb\uff0c\u63ed\u793a\u4e86\u8fd9\u79cd\u653b\u51fb\u5982\u4f55\u901a\u8fc7\u6ce8\u5165\u865a\u5047\u7528\u6237\u3001\u64cd\u7eb5\u94fe\u63a5\u548c\u53d1\u9001\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u6570\u636e\u6765\u7834\u574f\u56fe\u5b66\u4e60\u7684\u5b9e\u7528\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u9632\u5fa1\u7b56\u7565\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1\u672c\u5730\u79c1\u6709\u56fe\u5b66\u4e60\u534f\u8bae\u5728\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u53ef\u80fd\u53d7\u5230\u6570\u636e\u6295\u6bd2\u653b\u51fb\u7684\u5f71\u54cd\uff0c\u8fd9\u5a01\u80c1\u5230\u9690\u79c1\u4fdd\u62a4\u56fe\u5b66\u4e60\u6846\u67b6\u7684\u7a33\u5065\u6027\u548c\u5b89\u5168\u6027\u3002", "method": "\u7814\u7a76\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u636e\u6295\u6bd2\u653b\u51fb\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u6d89\u53ca\u5411\u534f\u8bae\u4e2d\u6ce8\u5165\u865a\u5047\u7528\u6237\uff0c\u5efa\u7acb\u4e0e\u771f\u5b9e\u7528\u6237\u7684\u8fde\u63a5\uff0c\u5e76\u5411\u670d\u52a1\u5668\u53d1\u9001\u7279\u5b9a\u6784\u9020\u7684\u6570\u636e\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u653b\u51fb\u5bf9\u79c1\u4eba\u56fe\u5b66\u4e60\u7684\u5b9e\u7528\u6027\u9020\u6210\u4e86\u663e\u8457\u635f\u5bb3\u3002\u6b64\u5916\uff0c\u867d\u7136\u5df2\u7ecf\u63a2\u7d22\u4e86\u51e0\u79cd\u9632\u5fa1\u63aa\u65bd\uff0c\u4f46\u5176\u6709\u6548\u6027\u6709\u9650\u3002", "conclusion": "\u672c\u6587\u7684\u7814\u7a76\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u9632\u5fa1\u673a\u5236\u4ee5\u5e94\u5bf9\u9488\u5bf9\u672c\u5730\u79c1\u6709\u56fe\u5b66\u4e60\u534f\u8bae\u7684\u6570\u636e\u6295\u6bd2\u653b\u51fb\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2506.09810", "pdf": "https://arxiv.org/pdf/2506.09810", "abs": "https://arxiv.org/abs/2506.09810", "authors": ["Minoh Jeong", "Alfred Hero"], "title": "Generalizing Supervised Contrastive learning: A Projection Perspective", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": null, "summary": "Self-supervised contrastive learning (SSCL) has emerged as a powerful\nparadigm for representation learning and has been studied from multiple\nperspectives, including mutual information and geometric viewpoints. However,\nsupervised contrastive (SupCon) approaches have received comparatively little\nattention in this context: for instance, while InfoNCE used in SSCL is known to\nform a lower bound on mutual information (MI), the relationship between SupCon\nand MI remains unexplored. To address this gap, we introduce ProjNCE, a\ngeneralization of the InfoNCE loss that unifies supervised and self-supervised\ncontrastive objectives by incorporating projection functions and an adjustment\nterm for negative pairs. We prove that ProjNCE constitutes a valid MI bound and\naffords greater flexibility in selecting projection strategies for class\nembeddings. Building on this flexibility, we further explore the centroid-based\nclass embeddings in SupCon by exploring a variety of projection methods.\nExtensive experiments on multiple datasets and settings demonstrate that\nProjNCE consistently outperforms both SupCon and standard cross-entropy\ntraining. Our work thus refines SupCon along two complementary\nperspective--mutual information interpretation and projection design--and\noffers broadly applicable improvements whenever SupCon serves as the\nfoundational contrastive objective.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86ProjNCE\uff0c\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570\uff0c\u5b83\u7edf\u4e00\u4e86\u76d1\u7763\u5bf9\u6bd4\u548c\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\uff0c\u5e76\u4e14\u8bc1\u660e\u4e86\u5b83\u662f\u4e92\u4fe1\u606f\u7684\u6709\u6548\u4e0b\u754c\u3002\u901a\u8fc7\u5b9e\u9a8c\u8868\u660eProjNCE\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u4f18\u4e8eSupCon\u548c\u6807\u51c6\u4ea4\u53c9\u71b5\u8bad\u7ec3\u3002", "motivation": "\u5c3d\u7ba1\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\uff08SSCL\uff09\u5df2\u7ecf\u4ece\u591a\u89d2\u5ea6\u88ab\u7814\u7a76\uff0c\u4f46\u76d1\u7763\u5bf9\u6bd4\uff08SupCon\uff09\u65b9\u6cd5\u5728\u8fd9\u65b9\u9762\u5f97\u5230\u7684\u5173\u6ce8\u8f83\u5c11\u3002InfoNCE\u662fSSCL\u4e2d\u4f7f\u7528\u7684\u5df2\u77e5\u5f62\u6210\u4e92\u4fe1\u606f\uff08MI\uff09\u7684\u4e0b\u754c\uff0c\u800cSupCon\u4e0eMI\u4e4b\u95f4\u7684\u5173\u7cfb\u5c1a\u672a\u63a2\u7d22\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u540d\u4e3aProjNCE\u7684\u65b0\u635f\u5931\u51fd\u6570\uff0c\u8fd9\u662fInfoNCE\u635f\u5931\u7684\u63a8\u5e7f\uff0c\u901a\u8fc7\u7ed3\u5408\u6295\u5f71\u51fd\u6570\u548c\u8d1f\u5bf9\u8c03\u6574\u9879\u6765\u7edf\u4e00\u76d1\u7763\u548c\u81ea\u76d1\u7763\u5bf9\u6bd4\u5b66\u4e60\u7684\u76ee\u6807\u3002\u8fd8\u63a2\u8ba8\u4e86\u57fa\u4e8e\u8d28\u5fc3\u7684\u7c7b\u5d4c\u5165\u5728SupCon\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86ProjNCE\u6784\u6210\u4e86\u6709\u6548\u7684MI\u8fb9\u754c\uff0c\u5e76\u63d0\u4f9b\u4e86\u66f4\u5927\u7684\u7075\u6d3b\u6027\u6765\u9009\u62e9\u7c7b\u5d4c\u5165\u7684\u6295\u5f71\u7b56\u7565\u3002\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cProjNCE\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u8bbe\u7f6e\u4e0a\u59cb\u7ec8\u4f18\u4e8eSupCon\u548c\u6807\u51c6\u4ea4\u53c9\u71b5\u8bad\u7ec3\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u901a\u8fc7\u4e24\u4e2a\u4e92\u8865\u7684\u89d2\u5ea6\u2014\u2014\u4e92\u4fe1\u606f\u89e3\u91ca\u548c\u6295\u5f71\u8bbe\u8ba1\u2014\u2014\u6539\u8fdb\u4e86SupCon\uff0c\u5e76\u5728SupCon\u4f5c\u4e3a\u57fa\u7840\u5bf9\u6bd4\u76ee\u6807\u65f6\u63d0\u4f9b\u5e7f\u6cdb\u9002\u7528\u7684\u6539\u8fdb\u3002"}}
{"id": "2506.09813", "pdf": "https://arxiv.org/pdf/2506.09813", "abs": "https://arxiv.org/abs/2506.09813", "authors": ["Ariel Procaccia", "Benjamin Schiffer", "Serena Wang", "Shirley Zhang"], "title": "Metritocracy: Representative Metrics for Lite Benchmarks", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "A common problem in LLM evaluation is how to choose a subset of metrics from\na full suite of possible metrics. Subset selection is usually done for\nefficiency or interpretability reasons, and the goal is often to select a\n``representative'' subset of metrics. However, ``representative'' is rarely\nclearly defined. In this work, we use ideas from social choice theory to\nformalize two notions of representation for the selection of a subset of\nevaluation metrics. We first introduce positional representation, which\nguarantees every alternative is sufficiently represented at every position\ncutoff. We then introduce positional proportionality, which guarantees no\nalternative is proportionally over- or under-represented by more than a small\nerror at any position. We prove upper and lower bounds on the smallest number\nof metrics needed to guarantee either of these properties in the worst case. We\nalso study a generalized form of each property that allows for additional input\non groups of metrics that must be represented. Finally, we tie theory to\npractice through real-world case studies on both LLM evaluation and hospital\nquality evaluation.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u7684\u6982\u5ff5\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u8bc4\u4ef7\u6307\u6807\u5b50\u96c6\u9009\u62e9\u7684\u4ee3\u8868\u6027\u6982\u5ff5\uff1a\u4f4d\u7f6e\u4ee3\u8868\u6027\u4e0e\u4f4d\u7f6e\u6bd4\u4f8b\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u4fdd\u8bc1\u8fd9\u4e24\u79cd\u6027\u8d28\u6240\u9700\u7684\u6700\u5c0f\u6307\u6807\u6570\u91cf\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\u3002", "motivation": "\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8bc4\u4f30\u4e2d\uff0c\u4ece\u6240\u6709\u53ef\u80fd\u7684\u6307\u6807\u4e2d\u9009\u62e9\u4e00\u4e2a\u5b50\u96c6\u662f\u4e00\u4e2a\u5e38\u89c1\u95ee\u9898\u3002\u7531\u4e8e\u6548\u7387\u6216\u53ef\u89e3\u91ca\u6027\u7684\u539f\u56e0\uff0c\u901a\u5e38\u9700\u8981\u9009\u62e9\u4e00\u7ec4\u2018\u4ee3\u8868\u6027\u2019\u7684\u6307\u6807\uff0c\u4f46\u2018\u4ee3\u8868\u6027\u2019\u8fd9\u4e00\u6982\u5ff5\u5f80\u5f80\u6ca1\u6709\u660e\u786e\u7684\u5b9a\u4e49\u3002", "method": "\u8bba\u6587\u4f7f\u7528\u793e\u4f1a\u9009\u62e9\u7406\u8bba\u7684\u601d\u60f3\u6765\u5f62\u5f0f\u5316\u4e24\u4e2a\u7528\u4e8e\u9009\u62e9\u8bc4\u4ef7\u6307\u6807\u5b50\u96c6\u7684\u4ee3\u8868\u6027\u6982\u5ff5\uff1a\u4f4d\u7f6e\u4ee3\u8868\u6027\u548c\u4f4d\u7f6e\u6bd4\u4f8b\u6027\u3002\u5bf9\u4e8e\u4f4d\u7f6e\u4ee3\u8868\u6027\uff0c\u786e\u4fdd\u6bcf\u4e2a\u9009\u9879\u5728\u6bcf\u4e2a\u4f4d\u7f6e\u622a\u65ad\u70b9\u4e0a\u90fd\u6709\u8db3\u591f\u7684\u4ee3\u8868\u6027\uff1b\u800c\u5bf9\u4e8e\u4f4d\u7f6e\u6bd4\u4f8b\u6027\uff0c\u5219\u662f\u786e\u4fdd\u6ca1\u6709\u9009\u9879\u5728\u4efb\u4f55\u4f4d\u7f6e\u4e0a\u88ab\u4e0d\u6210\u6bd4\u4f8b\u5730\u8fc7\u5ea6\u6216\u4e0d\u8db3\u4ee3\u8868\u8d85\u8fc7\u4e00\u4e2a\u5c0f\u8bef\u5dee\u3002\u6b64\u5916\uff0c\u8fd8\u7814\u7a76\u4e86\u5141\u8bb8\u5bf9\u5fc5\u987b\u88ab\u4ee3\u8868\u7684\u5ea6\u91cf\u7ec4\u63d0\u4f9b\u989d\u5916\u8f93\u5165\u7684\u6bcf\u79cd\u5c5e\u6027\u7684\u4e00\u822c\u5f62\u5f0f\u3002", "result": "\u4f5c\u8005\u8bc1\u660e\u4e86\u5728\u6700\u574f\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3a\u4e86\u4fdd\u8bc1\u8fd9\u4e24\u79cd\u6027\u8d28\u4e2d\u7684\u4efb\u610f\u4e00\u79cd\u6240\u9700\u8981\u7684\u6700\u5c0f\u5ea6\u91cf\u6570\u91cf\u7684\u4e0a\u4e0b\u754c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e0d\u4ec5\u4e3a\u5ea6\u91cf\u5b50\u96c6\u7684\u9009\u62e9\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u800c\u4e14\u8fd8\u901a\u8fc7LLM\u8bc4\u4f30\u548c\u533b\u9662\u8d28\u91cf\u8bc4\u4f30\u7684\u5b9e\u9645\u6848\u4f8b\u7814\u7a76\u5c06\u7406\u8bba\u8054\u7cfb\u5230\u5b9e\u8df5\u4e2d\uff0c\u5c55\u793a\u4e86\u8fd9\u4e9b\u65b0\u6982\u5ff5\u5982\u4f55\u5e2e\u52a9\u89e3\u51b3\u5b9e\u9645\u95ee\u9898\u3002"}}
{"id": "2506.09816", "pdf": "https://arxiv.org/pdf/2506.09816", "abs": "https://arxiv.org/abs/2506.09816", "authors": ["Cecilia Casolo", "S\u00f6ren Becker", "Niki Kilbertus"], "title": "Identifiability Challenges in Sparse Linear Ordinary Differential Equations", "categories": ["cs.LG"], "comment": "9 pages, 4 figures", "summary": "Dynamical systems modeling is a core pillar of scientific inquiry across\nnatural and life sciences. Increasingly, dynamical system models are learned\nfrom data, rendering identifiability a paramount concept. For systems that are\nnot identifiable from data, no guarantees can be given about their behavior\nunder new conditions and inputs, or about possible control mechanisms to steer\nthe system. It is known in the community that \"linear ordinary differential\nequations (ODE) are almost surely identifiable from a single trajectory.\"\nHowever, this only holds for dense matrices. The sparse regime remains\nunderexplored, despite its practical relevance with sparsity arising naturally\nin many biological, social, and physical systems. In this work, we address this\ngap by characterizing the identifiability of sparse linear ODEs. Contrary to\nthe dense case, we show that sparse systems are unidentifiable with a positive\nprobability in practically relevant sparsity regimes and provide lower bounds\nfor this probability. We further study empirically how this theoretical\nunidentifiability manifests in state-of-the-art methods to estimate linear ODEs\nfrom data. Our results corroborate that sparse systems are also practically\nunidentifiable. Theoretical limitations are not resolved through inductive\nbiases or optimization dynamics. Our findings call for rethinking what can be\nexpected from data-driven dynamical system modeling and allows for quantitative\nassessments of how much to trust a learned linear ODE.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u7a00\u758f\u7ebf\u6027\u5e38\u5fae\u5206\u65b9\u7a0b\uff08ODE\uff09\u7684\u53ef\u8bc6\u522b\u6027\u95ee\u9898\uff0c\u8868\u660e\u5728\u5b9e\u9645\u76f8\u5173\u7684\u7a00\u758f\u6761\u4ef6\u4e0b\uff0c\u4e0e\u7a20\u5bc6\u77e9\u9635\u4e0d\u540c\uff0c\u7a00\u758f\u7cfb\u7edf\u4ee5\u4e00\u5b9a\u6982\u7387\u4e0d\u53ef\u8bc6\u522b\uff0c\u5e76\u63d0\u4f9b\u4e86\u8be5\u6982\u7387\u7684\u4e0b\u754c\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u663e\u793a\uff0c\u8fd9\u79cd\u7406\u8bba\u4e0a\u7684\u4e0d\u53ef\u8bc6\u522b\u6027\u4e5f\u5728\u73b0\u6709\u4f30\u8ba1\u7ebf\u6027ODE\u7684\u65b9\u6cd5\u4e2d\u663e\u73b0\u51fa\u6765\uff0c\u63d0\u793a\u6211\u4eec\u9700\u8981\u91cd\u65b0\u601d\u8003\u6570\u636e\u9a71\u52a8\u7684\u52a8\u529b\u7cfb\u7edf\u5efa\u6a21\u80fd\u591f\u8fbe\u5230\u4ec0\u4e48\u6837\u7684\u9884\u671f\u3002", "motivation": "\u52a8\u529b\u7cfb\u7edf\u5efa\u6a21\u662f\u81ea\u7136\u79d1\u5b66\u548c\u751f\u547d\u79d1\u5b66\u9886\u57df\u79d1\u5b66\u7814\u7a76\u7684\u6838\u5fc3\u652f\u67f1\u4e4b\u4e00\u3002\u968f\u7740\u8d8a\u6765\u8d8a\u591a\u7684\u52a8\u529b\u7cfb\u7edf\u6a21\u578b\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u800c\u6765\uff0c\u53ef\u8bc6\u522b\u6027\u6210\u4e3a\u4e86\u4e00\u4e2a\u6781\u5176\u91cd\u8981\u7684\u6982\u5ff5\u3002\u5bf9\u4e8e\u90a3\u4e9b\u4e0d\u80fd\u4ece\u6570\u636e\u4e2d\u88ab\u8bc6\u522b\u51fa\u6765\u7684\u7cfb\u7edf\uff0c\u6211\u4eec\u65e0\u6cd5\u5bf9\u5176\u5728\u65b0\u7684\u6761\u4ef6\u548c\u8f93\u5165\u4e0b\u7684\u884c\u4e3a\u505a\u51fa\u4fdd\u8bc1\uff0c\u4e5f\u65e0\u6cd5\u5bf9\u53ef\u80fd\u7684\u63a7\u5236\u673a\u5236\u8fdb\u884c\u628a\u63e1\u3002\u5c3d\u7ba1\u5927\u5bb6\u77e5\u9053\u201c\u7ebf\u6027\u5e38\u5fae\u5206\u65b9\u7a0b\u51e0\u4e4e\u80af\u5b9a\u53ef\u4ee5\u4ece\u5355\u4e00\u8f68\u8ff9\u4e2d\u88ab\u8bc6\u522b\u201d\uff0c\u4f46\u8fd9\u4e00\u7ed3\u8bba\u4ec5\u9002\u7528\u4e8e\u7a20\u5bc6\u77e9\u9635\u3002\u800c\u73b0\u5b9e\u4e2d\u5f88\u591a\u751f\u7269\u3001\u793e\u4f1a\u548c\u7269\u7406\u7cfb\u7edf\u81ea\u7136\u5448\u73b0\u51fa\u7a00\u758f\u7279\u6027\uff0c\u56e0\u6b64\uff0c\u63a2\u7d22\u7a00\u758f\u4f53\u7cfb\u7684\u53ef\u8bc6\u522b\u6027\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u672c\u6587\u901a\u8fc7\u6570\u5b66\u5206\u6790\u6765\u523b\u753b\u7a00\u758f\u7ebf\u6027ODE\u7684\u53ef\u8bc6\u522b\u6027\u7279\u5f81\uff0c\u8bc1\u660e\u4e86\u5728\u5b9e\u7528\u76f8\u5173\u7a00\u758f\u6761\u4ef6\u4e0b\uff0c\u7a00\u758f\u7cfb\u7edf\u6709\u6b63\u7684\u6982\u7387\u662f\u4e0d\u53ef\u8bc6\u522b\u7684\uff0c\u5e76\u4e3a\u8fd9\u4e2a\u6982\u7387\u63d0\u4f9b\u4e86\u4e0b\u754c\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u4eec\u8fd8\u91c7\u7528\u5b9e\u8bc1\u65b9\u6cd5\u7814\u7a76\u4e86\u8fd9\u79cd\u7406\u8bba\u4e0a\u4e0d\u53ef\u8bc6\u522b\u6027\u5982\u4f55\u4f53\u73b0\u5728\u6700\u5148\u8fdb\u7684\u7528\u4e8e\u4ece\u6570\u636e\u4f30\u8ba1\u7ebf\u6027ODE\u7684\u65b9\u6cd5\u4e2d\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u5728\u5b9e\u9645\u76f8\u5173\u7684\u7a00\u758f\u5ea6\u6761\u4ef6\u4e0b\uff0c\u7a00\u758f\u7ebf\u6027ODE\u5b58\u5728\u4e00\u5b9a\u7684\u6982\u7387\u662f\u4e0d\u53ef\u8bc6\u522b\u7684\uff0c\u5e76\u4e14\u7ed9\u51fa\u4e86\u4e0d\u53ef\u8bc6\u522b\u6027\u7684\u6982\u7387\u4e0b\u9650\u3002\u6b64\u5916\uff0c\u5b9e\u8bc1\u7ed3\u679c\u8bc1\u5b9e\u4e86\u8fd9\u79cd\u4e0d\u53ef\u8bc6\u522b\u6027\u540c\u6837\u5b58\u5728\u4e8e\u5f53\u524d\u5148\u8fdb\u7684\u6570\u636e\u9a71\u52a8\u7ebf\u6027ODE\u4f30\u8ba1\u65b9\u6cd5\u4e2d\u3002\u8fd9\u610f\u5473\u7740\u7406\u8bba\u4e0a\u7684\u9650\u5236\u4e0d\u4f1a\u56e0\u4e3a\u5f52\u7eb3\u504f\u7f6e\u6216\u4f18\u5316\u52a8\u6001\u800c\u5f97\u5230\u89e3\u51b3\u3002", "conclusion": "\u7814\u7a76\u53d1\u73b0\u547c\u5401\u91cd\u65b0\u8003\u8651\u6570\u636e\u9a71\u52a8\u7684\u52a8\u529b\u7cfb\u7edf\u5efa\u6a21\u6240\u80fd\u8fbe\u5230\u7684\u9884\u671f\uff0c\u5e76\u5141\u8bb8\u5bf9\u5b66\u4e60\u5230\u7684\u7ebf\u6027ODE\u7684\u4fe1\u4efb\u7a0b\u5ea6\u8fdb\u884c\u5b9a\u91cf\u8bc4\u4f30\u3002\u8fd9\u8868\u660e\u7a00\u758f\u7cfb\u7edf\u7684\u4e0d\u53ef\u8bc6\u522b\u6027\u662f\u4e00\u4e2a\u9700\u8981\u8ba4\u771f\u5bf9\u5f85\u7684\u95ee\u9898\uff0c\u5b83\u4e0d\u4ec5\u5f71\u54cd\u7740\u7406\u8bba\u5c42\u9762\u7684\u7406\u89e3\uff0c\u4e5f\u5bf9\u5b9e\u8df5\u4e2d\u5e94\u7528\u8fd9\u4e9b\u6a21\u578b\u65f6\u6240\u4f5c\u51b3\u7b56\u7684\u8d28\u91cf\u63d0\u51fa\u4e86\u6311\u6218\u3002"}}
{"id": "2506.09824", "pdf": "https://arxiv.org/pdf/2506.09824", "abs": "https://arxiv.org/abs/2506.09824", "authors": ["Johan Erbani", "Sonia Ben Mokhtar", "Pierre-Edouard Portier", "Elod Egyed-Zsigmond", "Diana Nurbakova"], "title": "Weighted Loss Methods for Robust Federated Learning under Data Heterogeneity", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning (FL) is a machine learning paradigm that enables multiple\ndata holders to collaboratively train a machine learning model without sharing\ntheir training data with external parties. In this paradigm, workers locally\nupdate a model and share with a central server their updated gradients (or\nmodel parameters). While FL seems appealing from a privacy perspective, it\nopens a number of threats from a security perspective as (Byzantine)\nparticipants can contribute poisonous gradients (or model parameters) harming\nmodel convergence. Byzantine-resilient FL addresses this issue by ensuring that\nthe training proceeds as if Byzantine participants were absent. Towards this\npurpose, common strategies ignore outlier gradients during model aggregation,\nassuming that Byzantine gradients deviate more from honest gradients than\nhonest gradients do from each other. However, in heterogeneous settings, honest\ngradients may differ significantly, making it difficult to distinguish honest\noutliers from Byzantine ones. In this paper, we introduce the Worker Label\nAlignement Loss (WoLA), a weighted loss that aligns honest worker gradients\ndespite data heterogeneity, which facilitates the identification of Byzantines'\ngradients. This approach significantly outperforms state-of-the-art methods in\nheterogeneous settings. In this paper, we provide both theoretical insights and\nempirical evidence of its effectiveness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aWoLA\uff08Worker Label Alignement Loss\uff09\u7684\u52a0\u6743\u635f\u5931\u51fd\u6570\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u6570\u636e\u5f02\u6784\u7684\u60c5\u51b5\u4e0b\u5bf9\u9f50\u8bda\u5b9e\u5de5\u4f5c\u8005\u7684\u68af\u5ea6\uff0c\u4ece\u800c\u6709\u52a9\u4e8e\u8bc6\u522b\u62dc\u5360\u5ead\u53c2\u4e0e\u8005\u7684\u6076\u610f\u68af\u5ea6\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u5f02\u6784\u73af\u5883\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7ed3\u679c\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60(FL)\u5141\u8bb8\u591a\u4e2a\u6570\u636e\u6301\u6709\u8005\u5728\u4e0d\u4e0e\u5916\u90e8\u65b9\u5171\u4eab\u8bad\u7ec3\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u534f\u4f5c\u8bad\u7ec3\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4f46\u4ece\u5b89\u5168\u89d2\u5ea6\u6765\u770b\uff0c\u5b83\u9762\u4e34\u7740\u62dc\u5360\u5ead\u53c2\u4e0e\u8005\u53ef\u80fd\u8d21\u732e\u6709\u6bd2\u68af\u5ea6\u800c\u635f\u5bb3\u6a21\u578b\u6536\u655b\u6027\u7684\u5a01\u80c1\u3002\u867d\u7136\u6709\u62b5\u6297\u62dc\u5360\u5ead\u6545\u969c\u7684\u7b56\u7565\u5b58\u5728\uff0c\u4f46\u5728\u5f02\u6784\u8bbe\u7f6e\u4e2d\u8bda\u5b9e\u68af\u5ea6\u4e4b\u95f4\u7684\u5dee\u5f02\u53ef\u80fd\u4f1a\u5f88\u5927\uff0c\u4f7f\u5f97\u96be\u4ee5\u533a\u5206\u8bda\u5b9e\u5f02\u5e38\u503c\u548c\u62dc\u5360\u5ead\u5f02\u5e38\u503c\u3002", "method": "\u7814\u7a76\u8005\u5f15\u5165\u4e86Worker Label Alignment Loss (WoLA)\uff0c\u8fd9\u662f\u4e00\u79cd\u52a0\u6743\u635f\u5931\u51fd\u6570\uff0c\u65e8\u5728\u5373\u4f7f\u5728\u6570\u636e\u5f02\u6784\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u5bf9\u9f50\u8bda\u5b9e\u5de5\u4f5c\u8005\u7684\u68af\u5ea6\uff0c\u4ece\u800c\u4fc3\u8fdb\u62dc\u5360\u5ead\u68af\u5ea6\u7684\u8bc6\u522b\u3002", "result": "\u901a\u8fc7\u4f7f\u7528WoLA\u65b9\u6cd5\uff0c\u5728\u5f02\u6784\u73af\u5883\u4e2d\u80fd\u591f\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u7406\u8bba\u89c1\u89e3\u548c\u5b9e\u8bc1\u8bc1\u636e\uff0c\u672c\u6587\u8bc1\u660e\u4e86WoLA\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8868\u660e\u5b83\u53ef\u4ee5\u63d0\u9ad8\u8054\u90a6\u5b66\u4e60\u7cfb\u7edf\u5728\u9762\u5bf9\u62dc\u5360\u5ead\u653b\u51fb\u65f6\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2506.09867", "pdf": "https://arxiv.org/pdf/2506.09867", "abs": "https://arxiv.org/abs/2506.09867", "authors": ["Amit Baran Dey", "Wasim Arif", "Rakhesh Singh Kshetrimayum"], "title": "Machine Learning-Based Classification of Oils Using Dielectric Properties and Microwave Resonant Sensing", "categories": ["cs.LG"], "comment": "6 pages, 11 figures, Accepted to IEEE INDISCON 2025", "summary": "This paper proposes a machine learning-based methodology for the\nclassification of various oil samples based on their dielectric properties,\nutilizing a microwave resonant sensor. The dielectric behaviour of oils,\ngoverned by their molecular composition, induces distinct shifts in the\nsensor's resonant frequency and amplitude response. These variations are\nsystematically captured and processed to extract salient features, which serve\nas inputs for multiple machine learning classifiers. The microwave resonant\nsensor operates in a non-destructive, low-power manner, making it particularly\nwell-suited for real-time industrial applications. A comprehensive dataset is\ndeveloped by varying the permittivity of oil samples and acquiring the\ncorresponding sensor responses. Several classifiers are trained and evaluated\nusing the extracted resonant features to assess their capability in\ndistinguishing between oil types. Experimental results demonstrate that the\nproposed approach achieves a high classification accuracy of 99.41% with the\nrandom forest classifier, highlighting its strong potential for automated oil\nidentification. The system's compact form factor, efficiency, and high\nperformance underscore its viability for fast and reliable oil characterization\nin industrial environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5fae\u6ce2\u8c10\u632f\u4f20\u611f\u5668\u548c\u673a\u5668\u5b66\u4e60\u7684\u6cb9\u54c1\u5206\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u6cb9\u54c1\u4ecb\u7535\u6027\u8d28\u5f15\u8d77\u7684\u4f20\u611f\u5668\u54cd\u5e94\u7279\u5f81\u6765\u533a\u5206\u4e0d\u540c\u7684\u6cb9\u54c1\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u4f7f\u7528\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u53ef\u4ee5\u8fbe\u523099.41%\u7684\u9ad8\u7cbe\u5ea6\uff0c\u9002\u7528\u4e8e\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u6cb9\u54c1\u8bc6\u522b\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u5f00\u53d1\u4e00\u79cd\u975e\u7834\u574f\u6027\u3001\u4f4e\u529f\u8017\u4e14\u9002\u5408\u4e8e\u5de5\u4e1a\u5b9e\u65f6\u5e94\u7528\u7684\u65b9\u6cd5\u6765\u6839\u636e\u6cb9\u54c1\u7684\u4ecb\u7535\u7279\u6027\u5bf9\u5176\u8fdb\u884c\u5206\u7c7b\u3002", "method": "\u91c7\u7528\u5fae\u6ce2\u8c10\u632f\u4f20\u611f\u5668\u6536\u96c6\u4e0d\u540c\u6cb9\u6837\u7684\u4ecb\u7535\u54cd\u5e94\uff0c\u5e76\u4ece\u8fd9\u4e9b\u54cd\u5e94\u4e2d\u63d0\u53d6\u663e\u8457\u7279\u5f81\u3002\u7136\u540e\u5229\u7528\u591a\u79cd\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u5bf9\u8fd9\u4e9b\u7279\u5f81\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0c\u4ee5\u786e\u5b9a\u5b83\u4eec\u5728\u533a\u5206\u6cb9\u54c1\u79cd\u7c7b\u65b9\u9762\u7684\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528\u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\u65f6\uff0c\u6240\u63d0\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b099.41%\u7684\u9ad8\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u8868\u660e\u5176\u5728\u81ea\u52a8\u5316\u6cb9\u54c1\u8bc6\u522b\u4e0a\u5177\u6709\u5f3a\u5927\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4ee5\u5176\u7d27\u51d1\u7684\u8bbe\u8ba1\u3001\u9ad8\u6548\u6027\u548c\u9ad8\u6027\u80fd\uff0c\u4e3a\u5de5\u4e1a\u73af\u5883\u4e2d\u5feb\u901f\u53ef\u9760\u7684\u6cb9\u54c1\u8868\u5f81\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.09896", "pdf": "https://arxiv.org/pdf/2506.09896", "abs": "https://arxiv.org/abs/2506.09896", "authors": ["Attanasia Garuso", "Silvija Kokalj-Filipovic", "Yagna Kaasaragadda"], "title": "A look at adversarial attacks on radio waveforms from discrete latent space", "categories": ["cs.LG"], "comment": null, "summary": "Having designed a VQVAE that maps digital radio waveforms into discrete\nlatent space, and yields a perfectly classifiable reconstruction of the\noriginal data, we here analyze the attack suppressing properties of VQVAE when\nan adversarial attack is performed on high-SNR radio-frequency (RF)\ndata-points. To target amplitude modulations from a subset of digitally\nmodulated waveform classes, we first create adversarial attacks that preserve\nthe phase between the in-phase and quadrature component whose values are\nadversarially changed. We compare them with adversarial attacks of the same\nintensity where phase is not preserved. We test the classification accuracy of\nsuch adversarial examples on a classifier trained to deliver 100% accuracy on\nthe original data. To assess the ability of VQVAE to suppress the strength of\nthe attack, we evaluate the classifier accuracy on the reconstructions by VQVAE\nof the adversarial datapoints and show that VQVAE substantially decreases the\neffectiveness of the attack. We also compare the I/Q plane diagram of the\nattacked data, their reconstructions and the original data. Finally, using\nmultiple methods and metrics, we compare the probability distribution of the\nVQVAE latent space with and without attack. Varying the attack strength, we\nobserve interesting properties of the discrete space, which may help detect the\nattacks.", "AI": {"tldr": "\u7814\u7a76\u4e86VQVAE\u5728\u9ad8\u4fe1\u566a\u6bd4\u5c04\u9891\u6570\u636e\u70b9\u53d7\u5230\u5bf9\u6297\u653b\u51fb\u65f6\u7684\u653b\u51fb\u6291\u5236\u7279\u6027\uff0c\u901a\u8fc7\u5bf9\u6bd4\u4e0d\u540c\u7c7b\u578b\u7684\u5bf9\u6297\u653b\u51fb\u5bf9\u5206\u7c7b\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u8bc4\u4f30\u4e86VQVAE\u91cd\u6784\u7684\u6570\u636e\u70b9\u5728\u5206\u7c7b\u5668\u4e0a\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793aVQVAE\u80fd\u591f\u663e\u8457\u964d\u4f4e\u653b\u51fb\u7684\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u65b9\u6cd5\u548c\u5ea6\u91cf\u6807\u51c6\u6bd4\u8f83\u4e86\u6709\u65e0\u653b\u51fb\u60c5\u51b5\u4e0b\u7684VQVAE\u6f5c\u5728\u7a7a\u95f4\u7684\u6982\u7387\u5206\u5e03\u3002", "motivation": "\u63a2\u7d22VQVAE\u5bf9\u4e8e\u6570\u5b57\u8c03\u5236\u6ce2\u5f62\u5728\u906d\u53d7\u9488\u5bf9\u5e45\u5ea6\u8c03\u5236\u7684\u5bf9\u6297\u653b\u51fb\u65f6\u662f\u5426\u5177\u6709\u653b\u51fb\u6291\u5236\u80fd\u529b\uff0c\u4ee5\u53ca\u5982\u4f55\u5f71\u54cd\u5206\u7c7b\u51c6\u786e\u6027\u548c\u6f5c\u5728\u7a7a\u95f4\u7279\u5f81\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5c06\u6570\u5b57\u65e0\u7ebf\u7535\u6ce2\u5f62\u6620\u5c04\u5230\u79bb\u6563\u6f5c\u5728\u7a7a\u95f4\u7684VQVAE\u6a21\u578b\uff1b\u521b\u5efa\u4e86\u4fdd\u7559\u76f8\u4f4d\u4fe1\u606f\u7684\u5bf9\u6297\u6027\u653b\u51fb\u548c\u4e0d\u4fdd\u7559\u76f8\u4f4d\u4fe1\u606f\u7684\u653b\u51fb\uff1b\u6d4b\u8bd5\u4e86\u539f\u59cb\u6570\u636e\u8bad\u7ec3\u7684\u5206\u7c7b\u5668\u4e0a\u8fd9\u4e9b\u5bf9\u6297\u6837\u672c\u7684\u5206\u7c7b\u51c6\u786e\u6027\uff1b\u8bc4\u4f30\u4e86VQVAE\u91cd\u6784\u540e\u7684\u5bf9\u6297\u6570\u636e\u70b9\u5728\u5206\u7c7b\u5668\u4e0a\u7684\u6027\u80fd\uff1b\u6bd4\u8f83\u4e86\u88ab\u653b\u51fb\u6570\u636e\u3001\u5176\u91cd\u6784\u53ca\u539f\u59cb\u6570\u636e\u5728I/Q\u5e73\u9762\u4e0a\u7684\u56fe\u8868\uff1b\u4f7f\u7528\u591a\u79cd\u65b9\u6cd5\u548c\u6307\u6807\u6bd4\u8f83\u4e86\u5728\u6709\u65e0\u653b\u51fb\u60c5\u51b5\u4e0bVQVAE\u6f5c\u5728\u7a7a\u95f4\u7684\u6982\u7387\u5206\u5e03\u3002", "result": "VQVAE\u663e\u8457\u964d\u4f4e\u4e86\u5bf9\u6297\u653b\u51fb\u7684\u6709\u6548\u6027\uff1b\u901a\u8fc7I/Q\u5e73\u9762\u56fe\u5c55\u793a\u4e86\u88ab\u653b\u51fb\u6570\u636e\u4e0e\u5176\u91cd\u6784\u4e4b\u95f4\u7684\u5dee\u5f02\uff1b\u89c2\u5bdf\u5230\u4e86\u968f\u7740\u653b\u51fb\u5f3a\u5ea6\u53d8\u5316\uff0c\u79bb\u6563\u7a7a\u95f4\u8868\u73b0\u51fa\u6709\u52a9\u4e8e\u68c0\u6d4b\u653b\u51fb\u7684\u6709\u8da3\u5c5e\u6027\u3002", "conclusion": "VQVAE\u53ef\u4ee5\u6709\u6548\u5730\u6291\u5236\u9488\u5bf9\u9ad8\u4fe1\u566a\u6bd4RF\u6570\u636e\u70b9\u7684\u5bf9\u6297\u653b\u51fb\u6548\u679c\uff0c\u540c\u65f6\u901a\u8fc7\u5206\u6790\u6f5c\u5728\u7a7a\u95f4\u6982\u7387\u5206\u5e03\u7684\u53d8\u5316\u4e3a\u68c0\u6d4b\u6b64\u7c7b\u653b\u51fb\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2506.09901", "pdf": "https://arxiv.org/pdf/2506.09901", "abs": "https://arxiv.org/abs/2506.09901", "authors": ["Noel Brindise", "Vijeth Hebbar", "Riya Shah", "Cedric Langbort"], "title": "\"What are my options?\": Explaining RL Agents with Diverse Near-Optimal Alternatives (Extended)", "categories": ["cs.LG"], "comment": null, "summary": "In this work, we provide an extended discussion of a new approach to\nexplainable Reinforcement Learning called Diverse Near-Optimal Alternatives\n(DNA), first proposed at L4DC 2025. DNA seeks a set of reasonable \"options\" for\ntrajectory-planning agents, optimizing policies to produce qualitatively\ndiverse trajectories in Euclidean space. In the spirit of explainability, these\ndistinct policies are used to \"explain\" an agent's options in terms of\navailable trajectory shapes from which a human user may choose. In particular,\nDNA applies to value function-based policies on Markov decision processes where\nagents are limited to continuous trajectories. Here, we describe DNA, which\nuses reward shaping in local, modified Q-learning problems to solve for\ndistinct policies with guaranteed epsilon-optimality. We show that it\nsuccessfully returns qualitatively different policies that constitute\nmeaningfully different \"options\" in simulation, including a brief comparison to\nrelated approaches in the stochastic optimization field of Quality Diversity.\nBeyond the explanatory motivation, this work opens new possibilities for\nexploration and adaptive planning in RL.", "AI": {"tldr": "\u672c\u6587\u8ba8\u8bba\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u79f0\u4e3a\u591a\u6837\u5316\u8fd1\u4f18\u66ff\u4ee3\u65b9\u6848\uff08DNA\uff09\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c40\u90e8\u5956\u52b1\u5851\u5f62\u6765\u6c42\u89e3\u5177\u6709\u4fdd\u8bc1\u03b5-\u6700\u4f18\u7684\u4e0d\u540c\u7b56\u7565\uff0c\u4ee5\u4ea7\u751f\u5728\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u5b9a\u6027\u591a\u6837\u5316\u7684\u8f68\u8ff9\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u591a\u6837\u5316\u8fd1\u4f18\u66ff\u4ee3\u65b9\u6848\uff08DNA\uff09\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u4e3a\u8def\u5f84\u89c4\u5212\u4ee3\u7406\u63d0\u4f9b\u4e00\u7cfb\u5217\u5408\u7406\u7684\u201c\u9009\u9879\u201d\uff0c\u5e76\u4f18\u5316\u7b56\u7565\u4ee5\u751f\u6210\u5728\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u5b9a\u6027\u4e0d\u540c\u7684\u8f68\u8ff9\u3002", "method": "DNA\u65b9\u6cd5\u5229\u7528\u57fa\u4e8e\u4ef7\u503c\u51fd\u6570\u7684\u7b56\u7565\uff0c\u5e76\u5728\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u5bf9\u8fde\u7eed\u8f68\u8ff9\u7684\u4ee3\u7406\u5e94\u7528\u5c40\u90e8\u4fee\u6539\u7684Q\u5b66\u4e60\u95ee\u9898\u4e2d\u7684\u5956\u52b1\u5851\u5f62\u6280\u672f\uff0c\u4ece\u800c\u627e\u5230\u6709\u4fdd\u969c\u7684\u03b5-\u6700\u4f18\u4e14\u5404\u4e0d\u76f8\u540c\u7684\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDNA\u80fd\u591f\u6210\u529f\u8fd4\u56de\u5b9a\u6027\u4e0d\u540c\u7684\u7b56\u7565\uff0c\u8fd9\u4e9b\u7b56\u7565\u6784\u6210\u4e86\u6709\u610f\u4e49\u4e0d\u540c\u7684\u201c\u9009\u9879\u201d\u3002\u6b64\u5916\uff0c\u6587\u4e2d\u8fd8\u7b80\u8981\u6bd4\u8f83\u4e86\u968f\u673a\u4f18\u5316\u9886\u57df\u8d28\u91cf\u591a\u6837\u6027\u65b9\u9762\u7684\u76f8\u5173\u65b9\u6cd5\u3002", "conclusion": "\u9664\u4e86\u589e\u5f3a\u53ef\u89e3\u91ca\u6027\u5916\uff0c\u8fd9\u9879\u5de5\u4f5c\u8fd8\u4e3a\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u63a2\u7d22\u548c\u81ea\u9002\u5e94\u89c4\u5212\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2506.09923", "pdf": "https://arxiv.org/pdf/2506.09923", "abs": "https://arxiv.org/abs/2506.09923", "authors": ["Liou Tang", "James Joshi", "Ashish Kundu"], "title": "Apollo: A Posteriori Label-Only Membership Inference Attack Towards Machine Unlearning", "categories": ["cs.LG"], "comment": null, "summary": "Machine Unlearning (MU) aims to update Machine Learning (ML) models following\nrequests to remove training samples and their influences on a trained model\nefficiently without retraining the original ML model from scratch. While MU\nitself has been employed to provide privacy protection and regulatory\ncompliance, it can also increase the attack surface of the model. Existing\nprivacy inference attacks towards MU that aim to infer properties of the\nunlearned set rely on the weaker threat model that assumes the attacker has\naccess to both the unlearned model and the original model, limiting their\nfeasibility toward real-life scenarios. We propose a novel privacy attack, A\nPosteriori Label-Only Membership Inference Attack towards MU, Apollo, that\ninfers whether a data sample has been unlearned, following a strict threat\nmodel where an adversary has access to the label-output of the unlearned model\nonly. We demonstrate that our proposed attack, while requiring less access to\nthe target model compared to previous attacks, can achieve relatively high\nprecision on the membership status of the unlearned samples.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9488\u5bf9\u673a\u5668\u9057\u5fd8\uff08MU\uff09\u7684\u9690\u79c1\u653b\u51fbApollo\uff0c\u8be5\u653b\u51fb\u4ec5\u57fa\u4e8e\u672a\u5b66\u4e60\u6a21\u578b\u7684\u6807\u7b7e\u8f93\u51fa\u6765\u63a8\u65ad\u6570\u636e\u6837\u672c\u662f\u5426\u5df2\u88ab\u79fb\u9664\uff0c\u5e76\u4e14\u5728\u5bf9\u76ee\u6807\u6a21\u578b\u8bbf\u95ee\u6743\u9650\u8f83\u5c11\u7684\u60c5\u51b5\u4e0b\u4ecd\u80fd\u5b9e\u73b0\u8f83\u9ad8\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u9488\u5bf9MU\u7684\u9690\u79c1\u63a8\u7406\u653b\u51fb\u4f9d\u8d56\u4e8e\u8f83\u5f31\u7684\u5a01\u80c1\u6a21\u578b\uff0c\u5373\u5047\u8bbe\u653b\u51fb\u8005\u53ef\u4ee5\u8bbf\u95ee\u672a\u5b66\u4e60\u6a21\u578b\u548c\u539f\u59cb\u6a21\u578b\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u53ef\u884c\u6027\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u5c40\u9650\u6027\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u3001\u66f4\u4e3a\u4e25\u683c\u7684\u5a01\u80c1\u6a21\u578b\u4e0b\u7684\u653b\u51fb\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u540d\u4e3aApollo\u7684\u540e\u9a8c\u6807\u7b7e\u552f\u4e00\u6210\u5458\u63a8\u7406\u653b\u51fb\uff0c\u8be5\u653b\u51fb\u4ec5\u5229\u7528\u672a\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u7684\u6807\u7b7e\u8f93\u51fa\uff0c\u4ee5\u786e\u5b9a\u67d0\u4e2a\u6570\u636e\u6837\u672c\u662f\u5426\u5df2\u7ecf\u88ab\u4ece\u8bad\u7ec3\u96c6\u4e2d\u5220\u9664\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u5148\u524d\u9700\u8981\u66f4\u591a\u8bbf\u95ee\u6743\u9650\u7684\u653b\u51fb\u76f8\u6bd4\uff0cApollo\u653b\u51fb\u5373\u4f7f\u5728\u4e25\u683c\u6761\u4ef6\u4e0b\u4e5f\u80fd\u8fbe\u5230\u76f8\u5bf9\u8f83\u9ad8\u7684\u7cbe\u5ea6\u6765\u5224\u65ad\u6837\u672c\u662f\u5426\u88ab\u9057\u5fd8\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u4e86Apollo\u653b\u51fb\u7684\u6709\u6548\u6027\uff0c\u5b83\u80fd\u591f\u5728\u4e0d\u76f4\u63a5\u8bbf\u95ee\u6a21\u578b\u5185\u90e8\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u89c2\u5bdf\u6a21\u578b\u7684\u8f93\u51fa\u6807\u7b7e\u6765\u63a8\u65ad\u51fa\u54ea\u4e9b\u6570\u636e\u70b9\u5df2\u7ecf\u88ab\u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u79fb\u9664\uff0c\u4ece\u800c\u4e3aMU\u7684\u5b89\u5168\u6027\u5e26\u6765\u4e86\u65b0\u7684\u6311\u6218\u3002"}}
{"id": "2506.09955", "pdf": "https://arxiv.org/pdf/2506.09955", "abs": "https://arxiv.org/abs/2506.09955", "authors": ["Yitao Xu", "Tong Zhang", "Ehsan Pajouheshgar", "Sabine S\u00fcsstrunk"], "title": "Canonical Latent Representations in Conditional Diffusion Models", "categories": ["cs.LG", "cs.CV"], "comment": "45 pages,41 figures", "summary": "Conditional diffusion models (CDMs) have shown impressive performance across\na range of generative tasks. Their ability to model the full data distribution\nhas opened new avenues for analysis-by-synthesis in downstream discriminative\nlearning. However, this same modeling capacity causes CDMs to entangle the\nclass-defining features with irrelevant context, posing challenges to\nextracting robust and interpretable representations. To this end, we identify\nCanonical LAtent Representations (CLAReps), latent codes whose internal CDM\nfeatures preserve essential categorical information while discarding\nnon-discriminative signals. When decoded, CLAReps produce representative\nsamples for each class, offering an interpretable and compact summary of the\ncore class semantics with minimal irrelevant details. Exploiting CLAReps, we\ndevelop a novel diffusion-based feature-distillation paradigm, CaDistill. While\nthe student has full access to the training set, the CDM as teacher transfers\ncore class knowledge only via CLAReps, which amounts to merely 10 % of the\ntraining data in size. After training, the student achieves strong adversarial\nrobustness and generalization ability, focusing more on the class signals\ninstead of spurious background cues. Our findings suggest that CDMs can serve\nnot just as image generators but also as compact, interpretable teachers that\ncan drive robust representation learning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7279\u5f81\u84b8\u998f\u8303\u5f0fCaDistill\uff0c\u901a\u8fc7\u4f7f\u7528Canonical LAtent Representations (CLAReps)\u6765\u63d0\u53d6\u6838\u5fc3\u7c7b\u77e5\u8bc6\uff0c\u4ece\u800c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u63d0\u9ad8\u5b66\u751f\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u6761\u4ef6\u6269\u6563\u6a21\u578b\uff08CDMs\uff09\u867d\u7136\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5efa\u6a21\u80fd\u529b\u5bfc\u81f4\u7c7b\u522b\u5b9a\u4e49\u7279\u5f81\u4e0e\u4e0d\u76f8\u5173\u4e0a\u4e0b\u6587\u7ea0\u7f20\u5728\u4e00\u8d77\uff0c\u8fd9\u7ed9\u63d0\u53d6\u7a33\u5065\u4e14\u53ef\u89e3\u91ca\u7684\u8868\u793a\u5e26\u6765\u4e86\u6311\u6218\u3002", "method": "\u7814\u7a76\u8005\u4eec\u8bc6\u522b\u51faCanonical LAtent Representations (CLAReps)\uff0c\u8fd9\u4e9b\u6f5c\u5728\u4ee3\u7801\u5728\u4fdd\u6301\u5173\u952e\u5206\u7c7b\u4fe1\u606f\u7684\u540c\u65f6\u53bb\u9664\u4e86\u975e\u9274\u522b\u6027\u4fe1\u53f7\u3002\u5229\u7528CLAReps\uff0c\u5f00\u53d1\u4e86\u57fa\u4e8e\u6269\u6563\u7684\u7279\u5f81\u84b8\u998f\u8303\u5f0fCaDistill\uff0c\u5728\u8fd9\u79cd\u6a21\u5f0f\u4e0b\uff0c\u5b66\u751f\u80fd\u591f\u8bbf\u95ee\u5b8c\u6574\u7684\u8bad\u7ec3\u96c6\uff0c\u800c\u4f5c\u4e3a\u6559\u5e08\u89d2\u8272\u7684CDM\u4ec5\u901a\u8fc7CLAReps\u4f20\u9012\u6838\u5fc3\u7c7b\u77e5\u8bc6\u3002", "result": "\u7ecf\u8fc7\u8bad\u7ec3\u540e\uff0c\u5b66\u751f\u6a21\u578b\u8fbe\u5230\u4e86\u5f3a\u5927\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e14\u66f4\u52a0\u5173\u6ce8\u4e8e\u7c7b\u522b\u4fe1\u53f7\u800c\u975e\u865a\u5047\u80cc\u666f\u7ebf\u7d22\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cCDMs\u4e0d\u4ec5\u53ef\u4ee5\u4f5c\u4e3a\u56fe\u50cf\u751f\u6210\u5668\uff0c\u8fd8\u53ef\u4ee5\u4f5c\u4e3a\u7d27\u51d1\u3001\u53ef\u89e3\u91ca\u7684\u6559\u5e08\u4fc3\u8fdb\u7a33\u5065\u7684\u8868\u793a\u5b66\u4e60\u3002"}}
{"id": "2506.09991", "pdf": "https://arxiv.org/pdf/2506.09991", "abs": "https://arxiv.org/abs/2506.09991", "authors": ["Xinyu Yang", "Yuwei An", "Hongyi Liu", "Tianqi Chen", "Beidi Chen"], "title": "Multiverse: Your Language Models Secretly Decide How to Parallelize and Merge Generation", "categories": ["cs.LG"], "comment": null, "summary": "Autoregressive Large Language Models (AR-LLMs) frequently exhibit implicit\nparallelism in sequential generation. Inspired by this, we introduce\nMultiverse, a new generative model that enables natively parallel generation.\nMultiverse internalizes a MapReduce paradigm, generating automatically through\nthree stages: (i) a Map stage for adaptive task decomposition, (ii) a Process\nstage for parallel subtask execution, and (iii) a Reduce stage for lossless\nresult synthesis. Next, we build a real-world Multiverse reasoning model with\nco-design of data, algorithm, and system, enabling rapid and seamless transfer\nfrom frontier AR-LLMs. Starting from sequential reasoning chains, we create\nMultiverse 1K by converting them into structured training data using an\nautomated LLM-assisted pipeline, avoiding costly human annotations.\nAlgorithmically, we design Multiverse Attention to separate parallel reasoning\nsteps while keeping compatibility with causal attention for efficient training.\nSystematically, we implement Multiverse Engine to enable parallel inference. It\nfeatures a dedicated scheduler that dynamically switches between sequential and\nparallel generation, triggered directly by the model. After a 3-hour\nfine-tuning with 1K examples, our Multiverse-32B stands as the only\nopen-sourced non-AR model achieving performance on par with leading AR-LLMs of\nthe same scale, evidenced by AIME24 & 25 scores of 54% and 46%, respectively.\nMoreover, our budget control experiments show that Multiverse-32B exhibits\nsuperior scaling, outperforming AR-LLMs by 1.87% on average using the same\ncontext length. Such scaling further leads to practical efficiency gain,\nachieving up to 2x speedup across varying batch sizes. We have open-sourced the\nentire Multiverse ecosystem, including data, model weights, engine, supporting\ntools, as well as complete data curation prompts and detailed training and\nevaluation recipes.", "AI": {"tldr": "\u4ecb\u7ecd\u4e86Multiverse\uff0c\u4e00\u79cd\u65b0\u7684\u751f\u6210\u6a21\u578b\uff0c\u5b83\u901a\u8fc7MapReduce\u8303\u5f0f\u5b9e\u73b0\u539f\u751f\u5e76\u884c\u751f\u6210\uff0c\u5e76\u4e14\u57283\u5c0f\u65f6\u5fae\u8c03\u540e\uff0c\u6027\u80fd\u4e0e\u9886\u5148\u7684\u540c\u89c4\u6a21\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\u76f8\u5f53\u3002", "motivation": "\u53d7\u5230\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\uff08AR-LLMs\uff09\u5728\u987a\u5e8f\u751f\u6210\u4e2d\u5e38\u8868\u73b0\u51fa\u9690\u5f0f\u5e76\u884c\u6027\u7684\u542f\u53d1\uff0c\u7814\u7a76\u8005\u4eec\u5e0c\u671b\u5f00\u53d1\u51fa\u80fd\u591f\u5b9e\u73b0\u81ea\u7136\u5e76\u884c\u751f\u6210\u7684\u65b0\u6a21\u578b\u3002", "method": "\u521b\u5efa\u4e86\u540d\u4e3aMultiverse\u7684\u751f\u6210\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u91c7\u7528MapReduce\u6a21\u5f0f\uff0c\u5206\u4e3a\u4e09\u4e2a\u9636\u6bb5\uff1a\u4efb\u52a1\u5206\u89e3\u7684\u6620\u5c04\u9636\u6bb5\u3001\u5e76\u884c\u5b50\u4efb\u52a1\u6267\u884c\u7684\u8fc7\u7a0b\u9636\u6bb5\u4ee5\u53ca\u65e0\u635f\u7ed3\u679c\u5408\u6210\u7684\u5f52\u7ea6\u9636\u6bb5\u3002\u4e3a\u4e86\u4ece\u524d\u6cbf\u7684AR-LLMs\u5feb\u901f\u65e0\u7f1d\u8fc1\u79fb\uff0c\u7814\u7a76\u4eba\u5458\u5bf9\u6570\u636e\u3001\u7b97\u6cd5\u548c\u7cfb\u7edf\u8fdb\u884c\u4e86\u5171\u540c\u8bbe\u8ba1\u3002", "result": "\u7ecf\u8fc73\u5c0f\u65f6\u4f7f\u75281K\u793a\u4f8b\u8fdb\u884c\u5fae\u8c03\u540e\uff0cMultiverse-32B\u6210\u4e3a\u4e86\u552f\u4e00\u5f00\u6e90\u7684\u975e\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u5176\u8868\u73b0\u4e0e\u76f8\u540c\u89c4\u6a21\u7684\u9886\u5148AR-LLMs\u76f8\u5f53\uff0cAIME24 & 25\u5206\u6570\u5206\u522b\u4e3a54%\u548c46%\u3002\u6b64\u5916\uff0c\u5728\u9884\u7b97\u63a7\u5236\u5b9e\u9a8c\u4e2d\uff0cMultiverse-32B\u5728\u76f8\u540c\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u5e73\u5747\u8d85\u8fc7AR-LLMs 1.87%\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u6279\u91cf\u5927\u5c0f\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe2\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "Multiverse\u6a21\u578b\u5c55\u793a\u4e86\u51fa\u8272\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u6548\u7387\u589e\u76ca\uff0c\u8d85\u8fc7\u4e86\u73b0\u6709\u7684AR-LLMs\uff0c\u5e76\u4e14\u6574\u4e2a\u751f\u6001\u7cfb\u7edf\u5df2\u7ecf\u5f00\u6e90\u3002"}}
{"id": "2506.09998", "pdf": "https://arxiv.org/pdf/2506.09998", "abs": "https://arxiv.org/abs/2506.09998", "authors": ["Tim Z. Xiao", "Johannes Zenn", "Zhen Liu", "Weiyang Liu", "Robert Bamler", "Bernhard Sch\u00f6lkopf"], "title": "Flipping Against All Odds: Reducing LLM Coin Flip Bias via Verbalized Rejection Sampling", "categories": ["cs.LG", "cs.CL"], "comment": "Technical Report v1 (21 pages, 14 figures)", "summary": "Large language models (LLMs) can often accurately describe probability\ndistributions using natural language, yet they still struggle to generate\nfaithful samples from them. This mismatch limits their use in tasks requiring\nreliable stochasticity, such as Monte Carlo methods, agent-based simulations,\nand randomized decision-making. We investigate this gap between knowledge and\nsampling in the context of Bernoulli distributions. We introduce Verbalized\nRejection Sampling (VRS), a natural-language adaptation of classical rejection\nsampling that prompts the LLM to reason about and accept or reject proposed\nsamples. Despite relying on the same Bernoulli mechanism internally, VRS\nsubstantially reduces sampling bias across models. We provide theoretical\nanalysis showing that, under mild assumptions, VRS improves over direct\nsampling, with gains attributable to both the algorithm and prompt design. More\nbroadly, our results show how classical probabilistic tools can be verbalized\nand embedded into LLM workflows to improve reliability, without requiring\naccess to model internals or heavy prompt engineering.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a\u53e3\u5934\u62d2\u7edd\u91c7\u6837(VRS)\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u8ba9\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7528\u81ea\u7136\u8bed\u8a00\u63a5\u53d7\u6216\u62d2\u7edd\u63d0\u8bae\u7684\u6837\u672c\uff0c\u4ece\u800c\u51cf\u5c11\u4f2f\u52aa\u5229\u5206\u5e03\u4e2d\u7684\u91c7\u6837\u504f\u5dee\u3002VRS\u5728\u4e0d\u76f4\u63a5\u63a5\u89e6\u6a21\u578b\u5185\u90e8\u673a\u5236\u7684\u60c5\u51b5\u4e0b\uff0c\u5229\u7528\u7ecf\u5178\u6982\u7387\u5de5\u5177\u6765\u63d0\u9ad8LLM\u5de5\u4f5c\u6d41\u7a0b\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u51c6\u786e\u5730\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u6982\u7387\u5206\u5e03\uff0c\u4f46\u5728\u4ece\u8fd9\u4e9b\u5206\u5e03\u4e2d\u751f\u6210\u5fe0\u5b9e\u6837\u672c\u65b9\u9762\u4ecd\u7136\u5b58\u5728\u56f0\u96be\u3002\u8fd9\u79cd\u77e5\u8bc6\u4e0e\u91c7\u6837\u4e4b\u95f4\u7684\u5dee\u8ddd\u9650\u5236\u4e86\u5b83\u4eec\u5728\u9700\u8981\u53ef\u9760\u968f\u673a\u6027\u7684\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u5982\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u3001\u57fa\u4e8e\u4ee3\u7406\u7684\u6a21\u62df\u548c\u968f\u673a\u51b3\u7b56\u3002", "method": "\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3a\u53e3\u5934\u62d2\u7edd\u91c7\u6837\uff08Verbalized Rejection Sampling, VRS\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u5b83\u662f\u7ecf\u5178\u62d2\u7edd\u91c7\u6837\u7684\u81ea\u7136\u8bed\u8a00\u7248\u672c\uff0c\u901a\u8fc7\u63d0\u793aLLM\u5bf9\u63d0\u51fa\u7684\u6837\u672c\u8fdb\u884c\u63a8\u7406\u5e76\u51b3\u5b9a\u63a5\u53d7\u6216\u62d2\u7edd\u3002", "result": "\u5c3d\u7ba1VRS\u4f9d\u8d56\u4e8e\u76f8\u540c\u7684\u4f2f\u52aa\u5229\u673a\u5236\uff0c\u4f46\u5b83\u663e\u8457\u51cf\u5c11\u4e86\u8de8\u6a21\u578b\u7684\u91c7\u6837\u504f\u5dee\uff0c\u5e76\u4e14\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\uff0cVRS\u4f18\u4e8e\u76f4\u63a5\u91c7\u6837\uff0c\u5176\u6539\u8fdb\u5f52\u529f\u4e8e\u7b97\u6cd5\u672c\u8eab\u53ca\u63d0\u793a\u8bbe\u8ba1\u3002", "conclusion": "\u66f4\u5e7f\u6cdb\u5730\u8bf4\uff0c\u7814\u7a76\u7ed3\u679c\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u7ecf\u5178\u7684\u6982\u7387\u5de5\u5177\u8f6c\u5316\u4e3a\u8bed\u8a00\u5f62\u5f0f\uff0c\u5e76\u5d4c\u5165\u5230LLM\u7684\u5de5\u4f5c\u6d41\u4e2d\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\uff0c\u800c\u65e0\u9700\u8bbf\u95ee\u6a21\u578b\u5185\u90e8\u6216\u8fdb\u884c\u5927\u91cf\u63d0\u793a\u5de5\u7a0b\u3002"}}
{"id": "2506.06905", "pdf": "https://arxiv.org/pdf/2506.06905", "abs": "https://arxiv.org/abs/2506.06905", "authors": ["Akash Gupta", "Amos Storkey", "Mirella Lapata"], "title": "Meta-Adaptive Prompt Distillation for Few-Shot Visual Question Answering", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": null, "summary": "Large Multimodal Models (LMMs) often rely on in-context learning (ICL) to\nperform new tasks with minimal supervision. However, ICL performance,\nespecially in smaller LMMs, is inconsistent and does not always improve\nmonotonically with increasing examples. We hypothesize that this occurs due to\nthe LMM being overwhelmed by additional information present in the image\nembeddings, which is not required for the downstream task. To address this, we\npropose a meta-learning approach that provides an alternative for inducing\nfew-shot capabilities in LMMs, using a fixed set of soft prompts that are\ndistilled from task-relevant image features and can be adapted at test time\nusing a few examples. To facilitate this distillation, we introduce an\nattention-mapper module that can be easily integrated with the popular LLaVA\nv1.5 architecture and is jointly learned with soft prompts, enabling task\nadaptation in LMMs under low-data regimes with just a few gradient steps.\nEvaluation on the VL-ICL Bench shows that our method consistently outperforms\nICL and related prompt-tuning approaches, even under image perturbations,\nimproving task induction and reasoning across visual question answering tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u4ece\u4efb\u52a1\u76f8\u5173\u56fe\u50cf\u7279\u5f81\u4e2d\u63d0\u53d6\u7684\u56fa\u5b9a\u8f6f\u63d0\u793a\u96c6\u6765\u5728\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u4e2d\u8bf1\u5bfc\u5c11\u91cf\u6837\u672c\u80fd\u529b\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u6ce8\u610f\u529b\u6620\u5c04\u6a21\u5757\u4ee5\u4fc3\u8fdb\u8fd9\u4e00\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u5176\u4ed6\u63d0\u793a\u8c03\u4f18\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\uff08LMMs\uff09\u5728\u6267\u884c\u65b0\u4efb\u52a1\u65f6\u4f9d\u8d56\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\uff0c\u4f46\u7279\u522b\u662f\u5728\u8f83\u5c0f\u89c4\u6a21\u7684LMMs\u4e2d\uff0cICL\u7684\u8868\u73b0\u4e0d\u7a33\u5b9a\u4e14\u4e0d\u603b\u662f\u968f\u7740\u793a\u4f8b\u6570\u91cf\u589e\u52a0\u800c\u5355\u8c03\u6539\u8fdb\u3002\u7814\u7a76\u8005\u8ba4\u4e3a\u8fd9\u662f\u7531\u4e8eLMM\u88ab\u56fe\u50cf\u5d4c\u5165\u4e2d\u5bf9\u4e0b\u6e38\u4efb\u52a1\u4e0d\u5fc5\u8981\u7684\u989d\u5916\u4fe1\u606f\u6240\u56f0\u6270\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5143\u5b66\u4e60\u65b9\u6cd5\uff0c\u5229\u7528\u4ece\u4efb\u52a1\u76f8\u5173\u56fe\u50cf\u7279\u5f81\u63d0\u70bc\u51fa\u7684\u4e00\u7ec4\u56fa\u5b9a\u7684\u8f6f\u63d0\u793a\uff0c\u8fd9\u4e9b\u8f6f\u63d0\u793a\u53ef\u4ee5\u5728\u6d4b\u8bd5\u65f6\u7528\u5c11\u91cf\u6837\u672c\u6765\u9002\u5e94\u3002\u4e3a\u6b64\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u6613\u4e8e\u4e0e\u6d41\u884c\u7684LLaVA v1.5\u67b6\u6784\u96c6\u6210\u7684\u6ce8\u610f\u529b\u6620\u5c04\u6a21\u5757\uff0c\u5b83\u4e0e\u8f6f\u63d0\u793a\u4e00\u8d77\u5b66\u4e60\uff0c\u5141\u8bb8\u5728\u4f4e\u6570\u636e\u6761\u4ef6\u4e0b\u4ec5\u901a\u8fc7\u51e0\u6b21\u68af\u5ea6\u66f4\u65b0\u5b9e\u73b0\u4efb\u52a1\u9002\u5e94\u3002", "result": "\u5728VL-ICL\u57fa\u51c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5373\u4f7f\u5728\u56fe\u50cf\u53d7\u5230\u5e72\u6270\u7684\u60c5\u51b5\u4e0b\uff0c\u672c\u65b9\u6cd5\u4e5f\u59cb\u7ec8\u4f18\u4e8eICL\u548c\u76f8\u5173\u7684\u63d0\u793a\u8c03\u4f18\u65b9\u6cd5\uff0c\u6539\u5584\u4e86\u8de8\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u7684\u4efb\u52a1\u8bf1\u5bfc\u548c\u63a8\u7406\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u5f0f\uff0c\u901a\u8fc7\u5143\u5b66\u4e60\u548c\u7279\u5b9a\u8bbe\u8ba1\u7684\u8f6f\u63d0\u793a\u6765\u63d0\u9ad8\u5927\u578b\u591a\u6a21\u6001\u6a21\u578b\u5728\u5c11\u91cf\u6837\u672c\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u5176\u5bf9\u4e8e\u589e\u5f3aLMMs\u5904\u7406\u89c6\u89c9\u95ee\u7b54\u7b49\u4efb\u52a1\u7684\u6709\u6548\u6027\u3002"}}
