{"id": "2506.13771", "pdf": "https://arxiv.org/pdf/2506.13771", "abs": "https://arxiv.org/abs/2506.13771", "authors": ["Banseok Lee", "Dongkyu Kim", "Youngcheon You", "Youngmin Kim"], "title": "LittleBit: Ultra Low-Bit Quantization via Latent Factorization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Deploying large language models (LLMs) often faces challenges from\nsubstantial memory and computational costs. Quantization offers a solution, yet\nperformance degradation in the sub-1-bit regime remains particularly difficult.\nThis paper introduces LittleBit, a novel method for extreme LLM compression. It\ntargets levels like 0.1 bits per weight (BPW), achieving nearly 31$\\times$\nmemory reduction, e.g., Llama2-13B to under 0.9 GB. LittleBit represents\nweights in a low-rank form using latent matrix factorization, subsequently\nbinarizing these factors. To counteract information loss from this extreme\nprecision, it integrates a multi-scale compensation mechanism. This includes\nrow, column, and an additional latent dimension that learns per-rank\nimportance. Two key contributions enable effective training: Dual\nSign-Value-Independent Decomposition (Dual-SVID) for stable quantization-aware\ntraining (QAT) initialization, and integrated Residual Compensation to mitigate\nerrors. Extensive experiments confirm LittleBit's superiority in sub-1-bit\nquantization: e.g., its 0.1 BPW performance on Llama2-7B surpasses the leading\nmethod's 0.7 BPW. This establishes a superior size-performance trade-off, with\nkernel-level benchmarks indicating potential for a 5$\\times$ speedup compared\nto FP16. LittleBit paves the way for deploying powerful LLMs in\nresource-constrained environments."}
{"id": "2506.13772", "pdf": "https://arxiv.org/pdf/2506.13772", "abs": "https://arxiv.org/abs/2506.13772", "authors": ["Zhenyan Lu", "Daliang Xu", "Dongqi Cai", "Zexi Li", "Wei Liu", "Fangming Liu", "Shangguang Wang", "Mengwei Xu"], "title": "MobiEdit: Resource-efficient Knowledge Editing for Personalized On-device LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are deployed on mobile devices to power killer\napplications such as intelligent assistants. LLMs pre-trained on general\ncorpora often hallucinate when handling personalized or unseen queries, leading\nto incorrect or outdated responses. Knowledge editing addresses this by\nidentifying and adjusting a small crucial portion of model weights, without\ncompromising the general knowledge. However, prior knowledge editing methods\nare impractical to run on local devices due to the resource-heavy\nbackpropagation (BP) needed for updates. We present MobiEdit, the first mobile\nknowledge editing framework that enables efficient LLM personalization on\ncommercial off-the-shelf (COTS) mobile devices. MobiEdit replaces\nfull-precision BP with quantized forward-only gradient estimation, thus\ncompatible with the energy-efficient mobile neural processing units (NPUs).\nMobiEdit replaces full-precision backpropagation with quantized forward-only\ngradient estimation, making it compatible with energy-efficient mobile NPUs. To\nfurther improve gradient estimation efficiency, we introduce two optimizations:\nan early stoping mechanism that adaptively terminates editing upon success and\na prefix cache that reuses computation across steps. Our approach enables\nreal-time editing of a 3B-parameter model (Qwen2.5-3B-Instruct) on COTS mobile\ndevices with 7.6$\\times$ less memory, 14.7 $\\times$ less energy and 3.6$\\times$\nless latency compared to previous knowledge editing methods."}
{"id": "2506.13781", "pdf": "https://arxiv.org/pdf/2506.13781", "abs": "https://arxiv.org/abs/2506.13781", "authors": ["Pablo Ariño Fernández", "Carlos Quesada González"], "title": "Solving the Job Shop Scheduling Problem with Graph Neural Networks: A Customizable Reinforcement Learning Environment", "categories": ["cs.LG", "cs.AI", "cs.DM", "90-04 (Primary), 90B35, 68T05 (Secondary)", "I.2.8; I.2.6; D.0; G.2.1; G.2.2"], "comment": "Bachelor's thesis, Universidad Polit\\'ecnica de Madrid, 2025. 150\n  pages, 23 figures", "summary": "The job shop scheduling problem is an NP-hard combinatorial optimization\nproblem relevant to manufacturing and timetabling. Traditional approaches use\npriority dispatching rules based on simple heuristics. Recent work has\nattempted to replace these with deep learning models, particularly graph neural\nnetworks (GNNs), that learn to assign priorities from data. However, training\nsuch models requires customizing numerous factors: graph representation, node\nfeatures, action space, and reward functions. The lack of modular libraries for\nexperimentation makes this research time-consuming. This work introduces\nJobShopLib, a modular library that allows customizing these factors and\ncreating new components with its reinforcement learning environment. We trained\nseveral dispatchers through imitation learning to demonstrate the environment's\nutility. One model outperformed various graph-based dispatchers using only\nindividual operation features, highlighting the importance of feature\ncustomization. Our GNN model achieved near state-of-the-art results on\nlarge-scale problems. These results suggest significant room for improvement in\ndeveloping such models. JobShopLib provides the necessary tools for future\nexperimentation."}
{"id": "2506.13786", "pdf": "https://arxiv.org/pdf/2506.13786", "abs": "https://arxiv.org/abs/2506.13786", "authors": ["Vuong M. Ngo", "Tran Quang Vinh", "Patricia Kearney", "Mark Roantree"], "title": "Enhancing Bagging Ensemble Regression with Data Integration for Time Series-Based Diabetes Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "17th International Conference on Computational Collective\n  Intelligence, LNAI, Springer, 11 pages", "summary": "Diabetes is a chronic metabolic disease characterized by elevated blood\nglucose levels, leading to complications like heart disease, kidney failure,\nand nerve damage. Accurate state-level predictions are vital for effective\nhealthcare planning and targeted interventions, but in many cases, data for\nnecessary analyses are incomplete. This study begins with a data engineering\nprocess to integrate diabetes-related datasets from 2011 to 2021 to create a\ncomprehensive feature set. We then introduce an enhanced bagging ensemble\nregression model (EBMBag+) for time series forecasting to predict diabetes\nprevalence across U.S. cities. Several baseline models, including SVMReg,\nBDTree, LSBoost, NN, LSTM, and ERMBag, were evaluated for comparison with our\nEBMBag+ algorithm. The experimental results demonstrate that EBMBag+ achieved\nthe best performance, with an MAE of 0.41, RMSE of 0.53, MAPE of 4.01, and an\nR2 of 0.9."}
{"id": "2506.13768", "pdf": "https://arxiv.org/pdf/2506.13768", "abs": "https://arxiv.org/abs/2506.13768", "authors": ["Stefan Reimann"], "title": "'Memory States' from Almost Nothing: Representing and Computing in a Non-associative Algebra", "categories": ["cs.AI"], "comment": "27 pages, 6 figures, journal article (accepted)", "summary": "This note presents a non-associative algebraic framework for the\nrepresentation and computation of information items in high-dimensional space.\nThis framework is consistent with the principles of spatial computing and with\nthe empirical findings in cognitive science about memory. Computations are\nperformed through a process of multiplication-like binding and non-associative\ninterference-like bundling. Models that rely on associative bundling typically\nlose order information, which necessitates the use of auxiliary order\nstructures, such as position markers, to represent sequential information that\nis important for cognitive tasks. In contrast, the non-associative bundling\nproposed allows the construction of sparse representations of arbitrarily long\nsequences that maintain their temporal structure across arbitrary lengths. In\nthis operation, noise is a constituent element of the representation of order\ninformation, rather than a means of obscuring it. The non-associative nature of\nthe proposed framework results in the representation of a single sequence by\ntwo distinct states. The L-state, generated through left-associative bundling,\ncontinuously updates and emphasises a recency effect, while the R-state, formed\nthrough right-associative bundling, encodes finite sequences or chunks,\ncapturing a primacy effect. The construction of these states may be associated\nwith activity in the prefrontal cortex in relation to short-term memory and\nhippocampal encoding in long-term memory, respectively. The accuracy of\nretrieval is contingent upon a decision-making process that is based on the\nmutual information between the memory states and the cue. The model is able to\nreplicate the Serial Position Curve, which reflects the empirical recency and\nprimacy effects observed in cognitive experiments."}
{"id": "2506.13900", "pdf": "https://arxiv.org/pdf/2506.13900", "abs": "https://arxiv.org/abs/2506.13900", "authors": ["Marouane Il Idrissi", "Agathe Fernandes Machado", "Arthur Charpentier"], "title": "Beyond Shapley Values: Cooperative Games for the Interpretation of Machine Learning Models", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Cooperative game theory has become a cornerstone of post-hoc interpretability\nin machine learning, largely through the use of Shapley values. Yet, despite\ntheir widespread adoption, Shapley-based methods often rest on axiomatic\njustifications whose relevance to feature attribution remains debatable. In\nthis paper, we revisit cooperative game theory from an interpretability\nperspective and argue for a broader and more principled use of its tools. We\nhighlight two general families of efficient allocations, the Weber and Harsanyi\nsets, that extend beyond Shapley values and offer richer interpretative\nflexibility. We present an accessible overview of these allocation schemes,\nclarify the distinction between value functions and aggregation rules, and\nintroduce a three-step blueprint for constructing reliable and\ntheoretically-grounded feature attributions. Our goal is to move beyond fixed\naxioms and provide the XAI community with a coherent framework to design\nattribution methods that are both meaningful and robust to shifting\nmethodological trends."}
{"id": "2506.13828", "pdf": "https://arxiv.org/pdf/2506.13828", "abs": "https://arxiv.org/abs/2506.13828", "authors": ["Abdullah Burkan Bereketoglu"], "title": "Hybrid Meta-Learning Framework for Anomaly Forecasting in Nonlinear Dynamical Systems via Physics-Inspired Simulation and Deep Ensembles", "categories": ["cs.LG", "cs.SY", "eess.SY", "physics.acc-ph"], "comment": "6 pages, 5 figures, 5 algorithms", "summary": "We propose a hybrid meta-learning framework for forecasting and anomaly\ndetection in nonlinear dynamical systems characterized by nonstationary and\nstochastic behavior. The approach integrates a physics-inspired simulator that\ncaptures nonlinear growth-relaxation dynamics with random perturbations,\nrepresentative of many complex physical, industrial, and cyber-physical\nsystems. We use CNN-LSTM architectures for spatio-temporal feature extraction,\nVariational Autoencoders (VAE) for unsupervised anomaly scoring, and Isolation\nForests for residual-based outlier detection in addition to a Dual-Stage\nAttention Recurrent Neural Network (DA-RNN) for one-step forecasting on top of\nthe generated simulation data. To create composite anomaly forecasts, these\nmodels are combined using a meta-learner that combines forecasting outputs,\nreconstruction errors, and residual scores. The hybrid ensemble performs better\nthan standalone models in anomaly localization, generalization, and robustness\nto nonlinear deviations, according to simulation-based experiments. The\nframework provides a broad, data-driven approach to early defect identification\nand predictive monitoring in nonlinear systems, which may be applied to a\nvariety of scenarios where complete physical models might not be accessible."}
{"id": "2506.13773", "pdf": "https://arxiv.org/pdf/2506.13773", "abs": "https://arxiv.org/abs/2506.13773", "authors": ["Milapji Singh Gill", "Tom Jeleniewski", "Felix Gehlhoff", "Alexander Fay"], "title": "Representing Time-Continuous Behavior of Cyber-Physical Systems in Knowledge Graphs", "categories": ["cs.AI"], "comment": null, "summary": "Time-continuous dynamic models are essential for various Cyber-Physical\nSystem (CPS) applications. To ensure effective usability in different lifecycle\nphases, such behavioral information in the form of differential equations must\nbe contextualized and integrated with further CPS information. While knowledge\ngraphs provide a formal description and structuring mechanism for this task,\nthere is a lack of reusable ontological artifacts and methods to reduce manual\ninstantiation effort. Hence, this contribution introduces two artifacts:\nFirstly, a modular semantic model based on standards is introduced to represent\ndifferential equations directly within knowledge graphs and to enrich them\nsemantically. Secondly, a method for efficient knowledge graph generation is\npresented. A validation of these artifacts was conducted in the domain of\naviation maintenance. Results show that differential equations of a complex\nElectro-Hydraulic Servoactuator can be formally represented in a knowledge\ngraph and be contextualized with other lifecycle data, proving the artifacts'\npractical applicability."}
{"id": "2506.13946", "pdf": "https://arxiv.org/pdf/2506.13946", "abs": "https://arxiv.org/abs/2506.13946", "authors": ["Nikola Sandrić"], "title": "Rademacher learning rates for iterated random functions", "categories": ["stat.ML", "cs.LG", "math.PR", "68W40, 68T10, 60J05"], "comment": null, "summary": "Most existing literature on supervised machine learning assumes that the\ntraining dataset is drawn from an i.i.d. sample. However, many real-world\nproblems exhibit temporal dependence and strong correlations between the\nmarginal distributions of the data-generating process, suggesting that the\ni.i.d. assumption is often unrealistic. In such cases, models naturally include\ntime-series processes with mixing properties, as well as irreducible and\naperiodic ergodic Markov chains. Moreover, the learning rates typically\nobtained in these settings are independent of the data distribution, which can\nlead to restrictive choices of hypothesis classes and suboptimal sample\ncomplexities for the learning algorithm. In this article, we consider the case\nwhere the training dataset is generated by an iterated random function (i.e.,\nan iteratively defined time-homogeneous Markov chain) that is not necessarily\nirreducible or aperiodic. Under the assumption that the governing function is\ncontractive with respect to its first argument and subject to certain\nregularity conditions on the hypothesis class, we first establish a uniform\nconvergence result for the corresponding sample error. We then demonstrate the\nlearnability of the approximate empirical risk minimization algorithm and\nderive its learning rate bound. Both rates are data-distribution dependent,\nexpressed in terms of the Rademacher complexities of the underlying hypothesis\nclass, allowing them to more accurately reflect the properties of the\ndata-generating distribution."}
{"id": "2506.13831", "pdf": "https://arxiv.org/pdf/2506.13831", "abs": "https://arxiv.org/abs/2506.13831", "authors": ["Jitian Zhao", "Chenghui Li", "Frederic Sala", "Karl Rohe"], "title": "Quantifying Structure in CLIP Embeddings: A Statistical Framework for Concept Interpretation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Concept-based approaches, which aim to identify human-understandable concepts\nwithin a model's internal representations, are a promising method for\ninterpreting embeddings from deep neural network models, such as CLIP. While\nthese approaches help explain model behavior, current methods lack statistical\nrigor, making it challenging to validate identified concepts and compare\ndifferent techniques. To address this challenge, we introduce a hypothesis\ntesting framework that quantifies rotation-sensitive structures within the CLIP\nembedding space. Once such structures are identified, we propose a post-hoc\nconcept decomposition method. Unlike existing approaches, it offers theoretical\nguarantees that discovered concepts represent robust, reproducible patterns\n(rather than method-specific artifacts) and outperforms other techniques in\nterms of reconstruction error. Empirically, we demonstrate that our\nconcept-based decomposition algorithm effectively balances reconstruction\naccuracy with concept interpretability and helps mitigate spurious cues in\ndata. Applied to a popular spurious correlation dataset, our method yields a\n22.6% increase in worst-group accuracy after removing spurious background\nconcepts."}
{"id": "2506.13774", "pdf": "https://arxiv.org/pdf/2506.13774", "abs": "https://arxiv.org/abs/2506.13774", "authors": ["Nell Watson", "Ahmed Amer", "Evan Harris", "Preeti Ravindra", "Shujun Zhang"], "title": "Personalized Constitutionally-Aligned Agentic Superego: Secure AI Behavior Aligned to Diverse Human Values", "categories": ["cs.AI", "cs.CY", "cs.MA"], "comment": "39 pages, 5 figures", "summary": "Agentic AI systems, possessing capabilities for autonomous planning and\naction, exhibit immense potential across diverse domains. However, their\npractical deployment is significantly hampered by challenges in aligning their\nbehavior with varied human values, complex safety requirements, and specific\ncompliance needs. Existing alignment methodologies often falter when faced with\nthe intricate task of providing deep, personalized contextual information\nwithout inducing confabulation or operational inefficiencies. This paper\nintroduces a novel solution: a 'superego' agent, designed as a personalized\noversight mechanism for agentic AI. This system dynamically steers AI planning\nby referencing user-selected \"Creed Constitutions\"-encapsulating diverse rule\nsets-with adjustable adherence levels to fit non-negotiable values. A real-time\ncompliance enforcer validates plans against these constitutions and a universal\nethical floor before execution. We present a functional system, including a\ndemonstration interface (www.Creed.Space) with a prototypical\nconstitution-sharing portal, and successful integration with third-party models\nvia the Model Context Protocol (MCP). Comprehensive benchmark evaluations\n(HarmBench, AgentHarm) demonstrate that our Superego agent dramatically reduces\nharmful outputs, achieving up to a 98.3% harm score reduction and near-perfect\nrefusal rates (e.g., 100% with Claude Sonnet 4 on AgentHarm's harmful set) for\nleading LLMs like Gemini 2.5 Flash and GPT-4o. This approach substantially\nsimplifies personalized AI alignment, rendering agentic systems more reliably\nattuned to individual and cultural contexts, while also enabling substantial\nsafety improvements. An overview on this research with examples is available at\nhttps://superego.creed.space."}
{"id": "2506.13947", "pdf": "https://arxiv.org/pdf/2506.13947", "abs": "https://arxiv.org/abs/2506.13947", "authors": ["Kazuto Fukuchi"], "title": "Meta Optimality for Demographic Parity Constrained Regression via Post-Processing", "categories": ["stat.ML", "cs.LG"], "comment": "ICML2025", "summary": "We address the regression problem under the constraint of demographic parity,\na commonly used fairness definition. Recent studies have revealed fair minimax\noptimal regression algorithms, the most accurate algorithms that adhere to the\nfairness constraint. However, these analyses are tightly coupled with specific\ndata generation models. In this paper, we provide meta-theorems that can be\napplied to various situations to validate the fair minimax optimality of the\ncorresponding regression algorithms. Furthermore, we demonstrate that fair\nminimax optimal regression can be achieved through post-processing methods,\nallowing researchers and practitioners to focus on improving conventional\nregression techniques, which can then be efficiently adapted for fair\nregression."}
{"id": "2506.13834", "pdf": "https://arxiv.org/pdf/2506.13834", "abs": "https://arxiv.org/abs/2506.13834", "authors": ["Zhao Wei", "Chin Chun Ooi", "Abhishek Gupta", "Jian Cheng Wong", "Pao-Hsiung Chiu", "Sheares Xue Wen Toh", "Yew-Soon Ong"], "title": "Evolvable Conditional Diffusion", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper presents an evolvable conditional diffusion method such that\nblack-box, non-differentiable multi-physics models, as are common in domains\nlike computational fluid dynamics and electromagnetics, can be effectively used\nfor guiding the generative process to facilitate autonomous scientific\ndiscovery. We formulate the guidance as an optimization problem where one\noptimizes for a desired fitness function through updates to the descriptive\nstatistic for the denoising distribution, and derive an evolution-guided\napproach from first principles through the lens of probabilistic evolution.\nInterestingly, the final derived update algorithm is analogous to the update as\nper common gradient-based guided diffusion models, but without ever having to\ncompute any derivatives. We validate our proposed evolvable diffusion algorithm\nin two AI for Science scenarios: the automated design of fluidic topology and\nmeta-surface. Results demonstrate that this method effectively generates\ndesigns that better satisfy specific optimization objectives without reliance\non differentiable proxies, providing an effective means of guidance-based\ndiffusion that can capitalize on the wealth of black-box, non-differentiable\nmulti-physics numerical models common across Science."}
{"id": "2506.13776", "pdf": "https://arxiv.org/pdf/2506.13776", "abs": "https://arxiv.org/abs/2506.13776", "authors": ["Kevin L. Wei", "Patricia Paskov", "Sunishchal Dev", "Michael J. Byun", "Anka Reuel", "Xavier Roberts-Gaal", "Rachel Calcott", "Evie Coxon", "Chinmay Deshpande"], "title": "Recommendations and Reporting Checklist for Rigorous & Transparent Human Baselines in Model Evaluations", "categories": ["cs.AI", "cs.CY"], "comment": "A version of this paper has been accepted to ICML 2025 as a position\n  paper (spotlight), with the title: \"Position: Human Baselines in Model\n  Evaluations Need Rigor and Transparency (With Recommendations & Reporting\n  Checklist).\"", "summary": "In this position paper, we argue that human baselines in foundation model\nevaluations must be more rigorous and more transparent to enable meaningful\ncomparisons of human vs. AI performance, and we provide recommendations and a\nreporting checklist towards this end. Human performance baselines are vital for\nthe machine learning community, downstream users, and policymakers to interpret\nAI evaluations. Models are often claimed to achieve \"super-human\" performance,\nbut existing baselining methods are neither sufficiently rigorous nor\nsufficiently well-documented to robustly measure and assess performance\ndifferences. Based on a meta-review of the measurement theory and AI evaluation\nliteratures, we derive a framework with recommendations for designing,\nexecuting, and reporting human baselines. We synthesize our recommendations\ninto a checklist that we use to systematically review 115 human baselines\n(studies) in foundation model evaluations and thus identify shortcomings in\nexisting baselining methods; our checklist can also assist researchers in\nconducting human baselines and reporting results. We hope our work can advance\nmore rigorous AI evaluation practices that can better serve both the research\ncommunity and policymakers. Data is available at:\nhttps://github.com/kevinlwei/human-baselines"}
{"id": "2506.13955", "pdf": "https://arxiv.org/pdf/2506.13955", "abs": "https://arxiv.org/abs/2506.13955", "authors": ["Matthew Lau", "Tian-Yi Zhou", "Xiangchi Yuan", "Jizhou Chen", "Wenke Lee", "Xiaoming Huo"], "title": "Bridging Unsupervised and Semi-Supervised Anomaly Detection: A Theoretically-Grounded and Practical Framework with Synthetic Anomalies", "categories": ["stat.ML", "cs.CR", "cs.LG", "stat.AP"], "comment": null, "summary": "Anomaly detection (AD) is a critical task across domains such as\ncybersecurity and healthcare. In the unsupervised setting, an effective and\ntheoretically-grounded principle is to train classifiers to distinguish normal\ndata from (synthetic) anomalies. We extend this principle to semi-supervised\nAD, where training data also include a limited labeled subset of anomalies\npossibly present in test time. We propose a theoretically-grounded and\nempirically effective framework for semi-supervised AD that combines known and\nsynthetic anomalies during training. To analyze semi-supervised AD, we\nintroduce the first mathematical formulation of semi-supervised AD, which\ngeneralizes unsupervised AD. Here, we show that synthetic anomalies enable (i)\nbetter anomaly modeling in low-density regions and (ii) optimal convergence\nguarantees for neural network classifiers -- the first theoretical result for\nsemi-supervised AD. We empirically validate our framework on five diverse\nbenchmarks, observing consistent performance gains. These improvements also\nextend beyond our theoretical framework to other classification-based AD\nmethods, validating the generalizability of the synthetic anomaly principle in\nAD."}
{"id": "2506.13836", "pdf": "https://arxiv.org/pdf/2506.13836", "abs": "https://arxiv.org/abs/2506.13836", "authors": ["Dang Viet Anh Nguyen", "Carlos Lima Azevedo", "Tomer Toledo", "Filipe Rodrigues"], "title": "Robustness of Reinforcement Learning-Based Traffic Signal Control under Incidents: A Comparative Study", "categories": ["cs.LG", "cs.AI", "90B20, 90C39, 68T05, 62P30", "I.2.6; I.2.8; G.3; J.4"], "comment": "35 pages, 5 figures, 3 tables", "summary": "Reinforcement learning-based traffic signal control (RL-TSC) has emerged as a\npromising approach for improving urban mobility. However, its robustness under\nreal-world disruptions such as traffic incidents remains largely underexplored.\nIn this study, we introduce T-REX, an open-source, SUMO-based simulation\nframework for training and evaluating RL-TSC methods under dynamic, incident\nscenarios. T-REX models realistic network-level performance considering\ndrivers' probabilistic rerouting, speed adaptation, and contextual\nlane-changing, enabling the simulation of congestion propagation under\nincidents. To assess robustness, we propose a suite of metrics that extend\nbeyond conventional traffic efficiency measures. Through extensive experiments\nacross synthetic and real-world networks, we showcase T-REX for the evaluation\nof several state-of-the-art RL-TSC methods under multiple real-world deployment\nparadigms. Our findings show that while independent value-based and\ndecentralized pressure-based methods offer fast convergence and generalization\nin stable traffic conditions and homogeneous networks, their performance\ndegrades sharply under incident-driven distribution shifts. In contrast,\nhierarchical coordination methods tend to offer more stable and adaptable\nperformance in large-scale, irregular networks, benefiting from their\nstructured decision-making architecture. However, this comes with the trade-off\nof slower convergence and higher training complexity. These findings highlight\nthe need for robustness-aware design and evaluation in RL-TSC research. T-REX\ncontributes to this effort by providing an open, standardized and reproducible\nplatform for benchmarking RL methods under dynamic and disruptive traffic\nscenarios."}
{"id": "2506.13790", "pdf": "https://arxiv.org/pdf/2506.13790", "abs": "https://arxiv.org/abs/2506.13790", "authors": ["Tapio Pitkäranta"], "title": "The NordDRG AI Benchmark for Large Language Models", "categories": ["cs.AI"], "comment": "15 pages, 4 figures", "summary": "Large language models (LLMs) are already being piloted for clinical coding\nand decision support. However, until now, no open benchmark has targeted the\nhospital funding layer where Diagnosis-Related Groups (DRG) determine\nreimbursement across many countries. We release NordDRG-AI-Benchmark, the first\npublic test-bed that captures a complete DRG rule set and evaluates an LLM's\nability to reason over multilingual diagnosis, procedure, and tariff logic.\n  The benchmark bundles three classes of artefacts: (i) definition tables with\n20 interlinked tables covering DRG logic, ICD and NCSP codes, age/sex splits,\nand country flags; (ii) expert manuals and changelog templates describing real\ngovernance workflows; and (iii) a prompt pack of 14 CaseMix tasks that span\ncode lookup, cross-table inference, multilingual terminology, and\nquality-assurance audits.\n  All artefacts are available at:\nhttps://github.com/longshoreforrest/norddrg-ai-benchmark\n  A baseline demonstration shows that five state-of-the-art LLMs perform very\ndifferently on the nine automatically verifiable tasks: o3 (OpenAI) scores 9\nout of 9, GPT-4o and o4-mini-high score 7 out of 9, while Gemini 2.5 Pro and\nGemini 2.5 Flash solve only 5 out of 9 and 3 out of 9, respectively. These\nresults confirm that NordDRG-AI-Benchmark highlights domain-specific strengths\nand weaknesses that remain hidden in generic LLM benchmarks, offering a\nreproducible baseline for research on trustworthy automation in hospital\nfunding."}
{"id": "2506.13984", "pdf": "https://arxiv.org/pdf/2506.13984", "abs": "https://arxiv.org/abs/2506.13984", "authors": ["Andrzej Cichocki"], "title": "Mirror Descent Using the Tempesta Generalized Multi-parametric Logarithms", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "In this paper, we develop a wide class Mirror Descent (MD) algorithms, which\nplay a key role in machine learning. For this purpose we formulated the\nconstrained optimization problem, in which we exploits the Bregman divergence\nwith the Tempesta multi-parametric deformation logarithm as a link function.\nThis link function called also mirror function defines the mapping between the\nprimal and dual spaces and is associated with a very-wide (in fact,\ntheoretically infinite) class of generalized trace-form entropies. In order to\nderive novel MD updates, we estimate generalized exponential function, which\nclosely approximates the inverse of the multi-parametric Tempesta generalized\nlogarithm. The shape and properties of the Tempesta logarithm and its\ninverse-deformed exponential functions can be tuned by several hyperparameters.\nBy learning these hyperparameters, we can adapt to distribution or geometry of\ntraining data, and we can adjust them to achieve desired properties of MD\nalgorithms. The concept of applying multi-parametric logarithms allow us to\ngenerate a new wide and flexible family of MD and mirror-less MD updates."}
{"id": "2506.13838", "pdf": "https://arxiv.org/pdf/2506.13838", "abs": "https://arxiv.org/abs/2506.13838", "authors": ["Lorena Poenaru-Olaru", "June Sallou", "Luis Cruz", "Jan Rellermeyer", "Arie van Deursen"], "title": "Sustainable Machine Learning Retraining: Optimizing Energy Efficiency Without Compromising Accuracy", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": "12 pages. Accepted at ICT4Sustainability 2025 conference", "summary": "The reliability of machine learning (ML) software systems is heavily\ninfluenced by changes in data over time. For that reason, ML systems require\nregular maintenance, typically based on model retraining. However, retraining\nrequires significant computational demand, which makes it energy-intensive and\nraises concerns about its environmental impact. To understand which retraining\ntechniques should be considered when designing sustainable ML applications, in\nthis work, we study the energy consumption of common retraining techniques.\nSince the accuracy of ML systems is also essential, we compare retraining\ntechniques in terms of both energy efficiency and accuracy. We showcase that\nretraining with only the most recent data, compared to all available data,\nreduces energy consumption by up to 25\\%, being a sustainable alternative to\nthe status quo. Furthermore, our findings show that retraining a model only\nwhen there is evidence that updates are necessary, rather than on a fixed\nschedule, can reduce energy consumption by up to 40\\%, provided a reliable data\nchange detector is in place. Our findings pave the way for better\nrecommendations for ML practitioners, guiding them toward more energy-efficient\nretraining techniques when designing sustainable ML software systems."}
{"id": "2506.13792", "pdf": "https://arxiv.org/pdf/2506.13792", "abs": "https://arxiv.org/abs/2506.13792", "authors": ["Gonçalo Hora de Carvalho", "Lazar S. Popov", "Sander Kaatee", "Kristinn R. Thórisson", "Tangrui Li", "Pétur Húni Björnsson", "Jilles S. Dibangoye"], "title": "ICE-ID: A Novel Historical Census Data Benchmark Comparing NARS against LLMs, \\& a ML Ensemble on Longitudinal Identity Resolution", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.AP"], "comment": null, "summary": "We introduce ICE-ID, a novel benchmark dataset for historical identity\nresolution, comprising 220 years (1703-1920) of Icelandic census records.\nICE-ID spans multiple generations of longitudinal data, capturing name\nvariations, demographic changes, and rich genealogical links. To the best of\nour knowledge, this is the first large-scale, open tabular dataset specifically\ndesigned to study long-term person-entity matching in a real-world population.\nWe define identity resolution tasks (within and across census waves) with\nclearly documented metrics and splits. We evaluate a range of methods:\nhandcrafted rule-based matchers, a ML ensemble as well as LLMs for structured\ndata (e.g. transformer-based tabular networks) against a novel approach to\ntabular data called NARS (Non-Axiomatic Reasoning System) - a general-purpose\nAI framework designed to reason with limited knowledge and resources. Its core\nis Non-Axiomatic Logic (NAL), a term-based logic. Our experiments show that\nNARS is suprisingly simple and competitive with other standard approaches,\nachieving SOTA at our task. By releasing ICE-ID and our code, we enable\nreproducible benchmarking of identity resolution approaches in longitudinal\nsettings and hope that ICE-ID opens new avenues for cross-disciplinary research\nin data linkage and historical analytics."}
{"id": "2506.14051", "pdf": "https://arxiv.org/pdf/2506.14051", "abs": "https://arxiv.org/abs/2506.14051", "authors": ["Jiyuan Tan", "Jose Blanchet", "Vasilis Syrgkanis"], "title": "Estimation of Treatment Effects in Extreme and Unobserved Data", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": null, "summary": "Causal effect estimation seeks to determine the impact of an intervention\nfrom observational data. However, the existing causal inference literature\nprimarily addresses treatment effects on frequently occurring events. But what\nif we are interested in estimating the effects of a policy intervention whose\nbenefits, while potentially important, can only be observed and measured in\nrare yet impactful events, such as extreme climate events? The standard causal\ninference methodology is not designed for this type of inference since the\nevents of interest may be scarce in the observed data and some degree of\nextrapolation is necessary. Extreme Value Theory (EVT) provides methodologies\nfor analyzing statistical phenomena in such extreme regimes. We introduce a\nnovel framework for assessing treatment effects in extreme data to capture the\ncausal effect at the occurrence of rare events of interest. In particular, we\nemploy the theory of multivariate regular variation to model extremities. We\ndevelop a consistent estimator for extreme treatment effects and present a\nrigorous non-asymptotic analysis of its performance. We illustrate the\nperformance of our estimator using both synthetic and semi-synthetic data."}
{"id": "2506.13842", "pdf": "https://arxiv.org/pdf/2506.13842", "abs": "https://arxiv.org/abs/2506.13842", "authors": ["Yuanlong Wang", "Pengqi Wang", "Changchang Yin", "Ping Zhang"], "title": "SatHealth: A Multimodal Public Health Dataset with Satellite-based Environmental Factors", "categories": ["cs.LG", "I.2.6; J.3; E.0"], "comment": "18 pages, 6 figures. To be published in SIGKDD 2025 Datasets and\n  Benchmarks Track", "summary": "Living environments play a vital role in the prevalence and progression of\ndiseases, and understanding their impact on patient's health status becomes\nincreasingly crucial for developing AI models. However, due to the lack of\nlong-term and fine-grained spatial and temporal data in public and population\nhealth studies, most existing studies fail to incorporate environmental data,\nlimiting the models' performance and real-world application. To address this\nshortage, we developed SatHealth, a novel dataset combining multimodal\nspatiotemporal data, including environmental data, satellite images,\nall-disease prevalences estimated from medical claims, and social determinants\nof health (SDoH) indicators. We conducted experiments under two use cases with\nSatHealth: regional public health modeling and personal disease risk\nprediction. Experimental results show that living environmental information can\nsignificantly improve AI models' performance and temporal-spatial\ngeneralizability on various tasks. Finally, we deploy a web-based application\nto provide an exploration tool for SatHealth and one-click access to both our\ndata and regional environmental embedding to facilitate plug-and-play\nutilization. SatHealth is now published with data in Ohio, and we will keep\nupdating SatHealth to cover the other parts of the US. With the web application\nand published code pipeline, our work provides valuable angles and resources to\ninclude environmental data in healthcare research and establishes a\nfoundational framework for future research in environmental health informatics."}
{"id": "2506.13793", "pdf": "https://arxiv.org/pdf/2506.13793", "abs": "https://arxiv.org/abs/2506.13793", "authors": ["Zongxian Yang", "Jiayu Qian", "Zegao Peng", "Haoyu Zhang", "Zhi-An Huang"], "title": "Med-REFL: Medical Reasoning Enhancement via Self-Corrected Fine-grained Reflection", "categories": ["cs.AI"], "comment": null, "summary": "Large reasoning models have recently made significant strides in mathematical\nand code reasoning, yet their success has not transferred smoothly to the\nmedical domain. While multiple factors contribute to this disparity, a critical\nissue is the inadequate focus on the quality of intermediate reflection steps,\nwhich is particularly crucial in high-stakes medical scenarios. To address this\nchallenge, we propose Med-REFL, a \\underline{\\textbf{Med}}ical\n\\underline{\\textbf{R}}easoning \\underline{\\textbf{E}}nhancement via\nself-corrected \\underline{\\textbf{F}}ine-grained\nref\\underline{\\textbf{L}}ection. Our method leverages a tree-of-thought\napproach to decompose medical questions into fine-grained reasoning paths,\nquantitatively evaluating each step and its subsequent reflections. These\nassessments enable automatic construction of direct preference optimization\ndata, reducing reliance on expensive expert annotations while guiding models to\nidentify and correct reasoning errors. Experimental results on the MedQA-USMLE\nbenchmark demonstrate Med-REFL achieves consistent improvements, with average\ngains up to 4.11\\%. Notably, it further boosts the state-of-the-art performance\nof 7B/8B models by an additional 4.13\\%. Furthermore, Med-REFL exhibits strong\ngeneralization capabilities and robustness across several challenging medical\nquestion-answering datasets. Our work illustrates that prioritizing reflection\nquality leads to more accurate and trustworthy reasoning in medical AI\napplications. Checkpoints, code, and data can be found\n\\href{https://github.com/TianYin123/Med-REFL}{here}."}
{"id": "2506.14110", "pdf": "https://arxiv.org/pdf/2506.14110", "abs": "https://arxiv.org/abs/2506.14110", "authors": ["Steve Hanneke", "Mingyue Xu"], "title": "Universal Rates of ERM for Agnostic Learning", "categories": ["stat.ML", "cs.LG"], "comment": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2025", "summary": "The universal learning framework has been developed to obtain guarantees on\nthe learning rates that hold for any fixed distribution, which can be much\nfaster than the ones uniformly hold over all the distributions. Given that the\nEmpirical Risk Minimization (ERM) principle being fundamental in the PAC theory\nand ubiquitous in practical machine learning, the recent work of\narXiv:2412.02810 studied the universal rates of ERM for binary classification\nunder the realizable setting. However, the assumption of realizability is too\nrestrictive to hold in practice. Indeed, the majority of the literature on\nuniversal learning has focused on the realizable case, leaving the\nnon-realizable case barely explored.\n  In this paper, we consider the problem of universal learning by ERM for\nbinary classification under the agnostic setting, where the ''learning curve\"\nreflects the decay of the excess risk as the sample size increases. We explore\nthe possibilities of agnostic universal rates and reveal a compact trichotomy:\nthere are three possible agnostic universal rates of ERM, being either\n$e^{-n}$, $o(n^{-1/2})$, or arbitrarily slow. We provide a complete\ncharacterization of which concept classes fall into each of these categories.\nMoreover, we also establish complete characterizations for the target-dependent\nuniversal rates as well as the Bayes-dependent universal rates."}
{"id": "2506.13862", "pdf": "https://arxiv.org/pdf/2506.13862", "abs": "https://arxiv.org/abs/2506.13862", "authors": ["Alena Shilova", "Alex Davey", "Brahim Driss", "Riad Akrour"], "title": "StaQ it! Growing neural networks for Policy Mirror Descent", "categories": ["cs.LG", "cs.AI"], "comment": "44 pages, 12 figures", "summary": "In Reinforcement Learning (RL), regularization has emerged as a popular tool\nboth in theory and practice, typically based either on an entropy bonus or a\nKullback-Leibler divergence that constrains successive policies. In practice,\nthese approaches have been shown to improve exploration, robustness and\nstability, giving rise to popular Deep RL algorithms such as SAC and TRPO.\nPolicy Mirror Descent (PMD) is a theoretical framework that solves this general\nregularized policy optimization problem, however the closed-form solution\ninvolves the sum of all past Q-functions, which is intractable in practice. We\npropose and analyze PMD-like algorithms that only keep the last $M$ Q-functions\nin memory, and show that for finite and large enough $M$, a convergent\nalgorithm can be derived, introducing no error in the policy update, unlike\nprior deep RL PMD implementations. StaQ, the resulting algorithm, enjoys strong\ntheoretical guarantees and is competitive with deep RL baselines, while\nexhibiting less performance oscillation, paving the way for fully stable deep\nRL algorithms and providing a testbed for experimentation with Policy Mirror\nDescent."}
{"id": "2506.13795", "pdf": "https://arxiv.org/pdf/2506.13795", "abs": "https://arxiv.org/abs/2506.13795", "authors": ["Boshen Shi", "Yongqing Wang", "Fangda Guo", "Jiangli Shao", "Huawei Shen", "Xueqi Cheng"], "title": "BotTrans: A Multi-Source Graph Domain Adaptation Approach for Social Bot Detection", "categories": ["cs.AI", "cs.SI"], "comment": "Accetpted to ECML-PKDD 2025 Research Track as oral; Code&data:\n  https://github.com/Skyorca/BotTrans", "summary": "Transferring extensive knowledge from relevant social networks has emerged as\na promising solution to overcome label scarcity in detecting social bots and\nother anomalies with GNN-based models. However, effective transfer faces two\ncritical challenges. Firstly, the network heterophily problem, which is caused\nby bots hiding malicious behaviors via indiscriminately interacting with human\nusers, hinders the model's ability to learn sufficient and accurate bot-related\nknowledge from source domains. Secondly, single-source transfer might lead to\ninferior and unstable results, as the source network may embody weak relevance\nto the task and provide limited knowledge. To address these challenges, we\nexplore multiple source domains and propose a multi-source graph domain\nadaptation model named \\textit{BotTrans}. We initially leverage the labeling\nknowledge shared across multiple source networks to establish a\ncross-source-domain topology with increased network homophily. We then\naggregate cross-domain neighbor information to enhance the discriminability of\nsource node embeddings. Subsequently, we integrate the relevance between each\nsource-target pair with model optimization, which facilitates knowledge\ntransfer from source networks that are more relevant to the detection task.\nAdditionally, we propose a refinement strategy to improve detection performance\nby utilizing semantic knowledge within the target domain. Extensive experiments\non real-world datasets demonstrate that \\textit{BotTrans} outperforms the\nexisting state-of-the-art methods, revealing its efficacy in leveraging\nmulti-source knowledge when the target detection task is unlabeled."}
{"id": "2506.14329", "pdf": "https://arxiv.org/pdf/2506.14329", "abs": "https://arxiv.org/abs/2506.14329", "authors": ["Rickmer Schulte", "David Rügamer", "Thomas Nagler"], "title": "Adjustment for Confounding using Pre-Trained Representations", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.CO", "stat.ME"], "comment": "Accepted at ICML 2025", "summary": "There is growing interest in extending average treatment effect (ATE)\nestimation to incorporate non-tabular data, such as images and text, which may\nact as sources of confounding. Neglecting these effects risks biased results\nand flawed scientific conclusions. However, incorporating non-tabular data\nnecessitates sophisticated feature extractors, often in combination with ideas\nof transfer learning. In this work, we investigate how latent features from\npre-trained neural networks can be leveraged to adjust for sources of\nconfounding. We formalize conditions under which these latent features enable\nvalid adjustment and statistical inference in ATE estimation, demonstrating\nresults along the example of double machine learning. We discuss critical\nchallenges inherent to latent feature learning and downstream parameter\nestimation arising from the high dimensionality and non-identifiability of\nrepresentations. Common structural assumptions for obtaining fast convergence\nrates with additive or sparse linear models are shown to be unrealistic for\nlatent features. We argue, however, that neural networks are largely\ninsensitive to these issues. In particular, we show that neural networks can\nachieve fast convergence rates by adapting to intrinsic notions of sparsity and\ndimension of the learning problem."}
{"id": "2506.13892", "pdf": "https://arxiv.org/pdf/2506.13892", "abs": "https://arxiv.org/abs/2506.13892", "authors": ["Samuel Beaussant", "Mehdi Mounsif"], "title": "Scaling Algorithm Distillation for Continuous Control with Mamba", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Algorithm Distillation (AD) was recently proposed as a new approach to\nperform In-Context Reinforcement Learning (ICRL) by modeling across-episodic\ntraining histories autoregressively with a causal transformer model. However,\ndue to practical limitations induced by the attention mechanism, experiments\nwere bottlenecked by the transformer's quadratic complexity and limited to\nsimple discrete environments with short time horizons. In this work, we propose\nleveraging the recently proposed Selective Structured State Space Sequence (S6)\nmodels, which achieved state-of-the-art (SOTA) performance on long-range\nsequence modeling while scaling linearly in sequence length. Through four\ncomplex and continuous Meta Reinforcement Learning environments, we demonstrate\nthe overall superiority of Mamba, a model built with S6 layers, over a\ntransformer model for AD. Additionally, we show that scaling AD to very long\ncontexts can improve ICRL performance and make it competitive even with a SOTA\nonline meta RL baseline."}
{"id": "2506.13799", "pdf": "https://arxiv.org/pdf/2506.13799", "abs": "https://arxiv.org/abs/2506.13799", "authors": ["Soroush Vahidi"], "title": "Feedforward Ordering in Neural Connectomes via Feedback Arc Minimization", "categories": ["cs.AI"], "comment": "This is a preliminary paper", "summary": "We present a suite of scalable algorithms for minimizing feedback arcs in\nlarge-scale weighted directed graphs, with the goal of revealing biologically\nmeaningful feedforward structure in neural connectomes. Using the FlyWire\nConnectome Challenge dataset, we demonstrate the effectiveness of our ranking\nstrategies in maximizing the total weight of forward-pointing edges. Our\nmethods integrate greedy heuristics, gain-aware local refinements, and global\nstructural analysis based on strongly connected components. Experiments show\nthat our best solution improves the forward edge weight over previous\ntop-performing methods. All algorithms are implemented efficiently in Python\nand validated using cloud-based execution on Google Colab Pro+."}
{"id": "2506.14479", "pdf": "https://arxiv.org/pdf/2506.14479", "abs": "https://arxiv.org/abs/2506.14479", "authors": ["Wonyoung Kim"], "title": "Adaptive Data Augmentation for Thompson Sampling", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In linear contextual bandits, the objective is to select actions that\nmaximize cumulative rewards, modeled as a linear function with unknown\nparameters. Although Thompson Sampling performs well empirically, it does not\nachieve optimal regret bounds. This paper proposes a nearly minimax optimal\nThompson Sampling for linear contextual bandits by developing a novel estimator\nwith the adaptive augmentation and coupling of the hypothetical samples that\nare designed for efficient parameter learning. The proposed estimator\naccurately predicts rewards for all arms without relying on assumptions for the\ncontext distribution. Empirical results show robust performance and significant\nimprovement over existing methods."}
{"id": "2506.13903", "pdf": "https://arxiv.org/pdf/2506.13903", "abs": "https://arxiv.org/abs/2506.13903", "authors": ["Christel Sirocchi", "Damiano Verda"], "title": "Enhancing interpretability of rule-based classifiers through feature graphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In domains where transparency and trustworthiness are crucial, such as\nhealthcare, rule-based systems are widely used and often preferred over\nblack-box models for decision support systems due to their inherent\ninterpretability. However, as rule-based models grow complex, discerning\ncrucial features, understanding their interactions, and comparing feature\ncontributions across different rule sets becomes challenging. To address this,\nwe propose a comprehensive framework for estimating feature contributions in\nrule-based systems, introducing a graph-based feature visualisation strategy, a\nnovel feature importance metric agnostic to rule-based predictors, and a\ndistance metric for comparing rule sets based on feature contributions. By\nexperimenting on two clinical datasets and four rule-based methods (decision\ntrees, logic learning machines, association rules, and neural networks with\nrule extraction), we showcase our method's capability to uncover novel insights\non the combined predictive value of clinical features, both at the dataset and\nclass-specific levels. These insights can aid in identifying new risk factors,\nsignature genes, and potential biomarkers, and determining the subset of\npatient information that should be prioritised to enhance diagnostic accuracy.\nComparative analysis of the proposed feature importance score with\nstate-of-the-art methods on 15 public benchmarks demonstrates competitive\nperformance and superior robustness. The method implementation is available on\nGitHub: https://github.com/ChristelSirocchi/rule-graph."}
{"id": "2506.13803", "pdf": "https://arxiv.org/pdf/2506.13803", "abs": "https://arxiv.org/abs/2506.13803", "authors": ["Richard D. Lange", "Konrad P. Kording"], "title": "Causality in the human niche: lessons for machine learning", "categories": ["cs.AI", "cs.LG"], "comment": "23 pages, 2 figures", "summary": "Humans interpret the world around them in terms of cause and effect and\ncommunicate their understanding of the world to each other in causal terms.\nThese causal aspects of human cognition are thought to underlie humans' ability\nto generalize and learn efficiently in new domains, an area where current\nmachine learning systems are weak. Building human-like causal competency into\nmachine learning systems may facilitate the construction of effective and\ninterpretable AI. Indeed, the machine learning community has been importing\nideas on causality formalized by the Structural Causal Model (SCM) framework,\nwhich provides a rigorous formal language for many aspects of causality and has\nled to significant advances. However, the SCM framework fails to capture some\nsalient aspects of human causal cognition and has likewise not yet led to\nadvances in machine learning in certain critical areas where humans excel. We\ncontend that the problem of causality in the ``human niche'' -- for a social,\nautonomous, and goal-driven agent sensing and acting in the world in which\nhumans live -- is quite different from the kind of causality captured by SCMs.\nFor example, everyday objects come in similar types that have similar causal\nproperties, and so humans readily generalize knowledge of one type of object\n(cups) to another related type (bowls) by drawing causal analogies between\nobjects with similar properties, but such analogies are at best awkward to\nexpress in SCMs. We explore how such causal capabilities are adaptive in, and\nmotivated by, the human niche. By better appreciating properties of human\ncausal cognition and, crucially, how those properties are adaptive in the niche\nin which humans live, we hope that future work at the intersection of machine\nlearning and causality will leverage more human-like inductive biases to create\nmore capable, controllable, and interpretable systems."}
{"id": "2506.14530", "pdf": "https://arxiv.org/pdf/2506.14530", "abs": "https://arxiv.org/abs/2506.14530", "authors": ["Anastasis Kratsios", "Tin Sum Cheng", "Aurelien Lucchi", "Haitz Sáez de Ocáriz Borde"], "title": "Sharp Generalization Bounds for Foundation Models with Asymmetric Randomized Low-Rank Adapters", "categories": ["stat.ML", "cs.AI", "cs.LG", "cs.NE", "math.ST", "stat.TH"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) has emerged as a widely adopted\nparameter-efficient fine-tuning (PEFT) technique for foundation models. Recent\nwork has highlighted an inherent asymmetry in the initialization of LoRA's\nlow-rank factors, which has been present since its inception and was presumably\nderived experimentally. This paper focuses on providing a comprehensive\ntheoretical characterization of asymmetric LoRA with frozen random factors.\nFirst, while existing research provides upper-bound generalization guarantees\nbased on averages over multiple experiments, the behaviour of a single\nfine-tuning run with specific random factors remains an open question. We\naddress this by investigating the concentration of the typical LoRA\ngeneralization gap around its mean. Our main upper bound reveals a sample\ncomplexity of $\\tilde{\\mathcal{O}}\\left(\\frac{\\sqrt{r}}{\\sqrt{N}}\\right)$ with\nhigh probability for rank $r$ LoRAs trained on $N$ samples. Additionally, we\nalso determine the fundamental limits in terms of sample efficiency,\nestablishing a matching lower bound of\n$\\mathcal{O}\\left(\\frac{1}{\\sqrt{N}}\\right)$. By more closely reflecting the\npractical scenario of a single fine-tuning run, our findings offer crucial\ninsights into the reliability and practicality of asymmetric LoRA."}
{"id": "2506.13906", "pdf": "https://arxiv.org/pdf/2506.13906", "abs": "https://arxiv.org/abs/2506.13906", "authors": ["Milad Ramezankhani", "Janak M. Patel", "Anirudh Deodhar", "Dagnachew Birru"], "title": "GITO: Graph-Informed Transformer Operator for Learning Complex Partial Differential Equations", "categories": ["cs.LG"], "comment": null, "summary": "We present a novel graph-informed transformer operator (GITO) architecture\nfor learning complex partial differential equation systems defined on irregular\ngeometries and non-uniform meshes. GITO consists of two main modules: a hybrid\ngraph transformer (HGT) and a transformer neural operator (TNO). HGT leverages\na graph neural network (GNN) to encode local spatial relationships and a\ntransformer to capture long-range dependencies. A self-attention fusion layer\nintegrates the outputs of the GNN and transformer to enable more expressive\nfeature learning on graph-structured data. TNO module employs linear-complexity\ncross-attention and self-attention layers to map encoded input functions to\npredictions at arbitrary query locations, ensuring discretization invariance\nand enabling zero-shot super-resolution across any mesh. Empirical results on\nbenchmark PDE tasks demonstrate that GITO outperforms existing\ntransformer-based neural operators, paving the way for efficient, mesh-agnostic\nsurrogate solvers in engineering applications."}
{"id": "2506.13810", "pdf": "https://arxiv.org/pdf/2506.13810", "abs": "https://arxiv.org/abs/2506.13810", "authors": ["Olivier Saidi"], "title": "Bridging Pattern-Aware Complexity with NP-Hard Optimization: A Unifying Framework and Empirical Study", "categories": ["cs.AI"], "comment": null, "summary": "NP hard optimization problems like the Traveling Salesman Problem (TSP) defy\nefficient solutions in the worst case, yet real-world instances often exhibit\nexploitable patterns. We propose a novel patternaware complexity framework that\nquantifies and leverages structural regularities e.g., clustering, symmetry to\nreduce effective computational complexity across domains, including financial\nforecasting and LLM optimization. With rigorous definitions, theorems, and a\nmeta learning driven solver pipeline, we introduce metrics like Pattern\nUtilization Efficiency (PUE) and achieve up to 79 percent solution quality\ngains in TSP benchmarks (22 to 2392 cities). Distinct from theoretical NP\nhardness, our approach offers a unified, practical lens for pattern-driven\nefficiency."}
{"id": "2506.14673", "pdf": "https://arxiv.org/pdf/2506.14673", "abs": "https://arxiv.org/abs/2506.14673", "authors": ["Mikael Møller Høgsgaard", "Andrea Paudice"], "title": "Uniform Mean Estimation for Heavy-Tailed Distributions via Median-of-Means", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The Median of Means (MoM) is a mean estimator that has gained popularity in\nthe context of heavy-tailed data. In this work, we analyze its performance in\nthe task of simultaneously estimating the mean of each function in a class\n$\\mathcal{F}$ when the data distribution possesses only the first $p$ moments\nfor $p \\in (1,2]$. We prove a new sample complexity bound using a novel\nsymmetrization technique that may be of independent interest. Additionally, we\npresent applications of our result to $k$-means clustering with unbounded\ninputs and linear regression with general losses, improving upon existing\nworks."}
{"id": "2506.13909", "pdf": "https://arxiv.org/pdf/2506.13909", "abs": "https://arxiv.org/abs/2506.13909", "authors": ["Xinyuan Tu", "Haocheng Zhang", "Tao Chengxu", "Zuyi Chen"], "title": "Few-Shot Learning for Industrial Time Series: A Comparative Analysis Using the Example of Screw-Fastening Process Monitoring", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Few-shot learning (FSL) has shown promise in vision but remains largely\nunexplored for \\emph{industrial} time-series data, where annotating every new\ndefect is prohibitively expensive. We present a systematic FSL study on\nscrew-fastening process monitoring, using a 2\\,300-sample multivariate torque\ndataset that covers 16 uni- and multi-factorial defect types. Beyond\nbenchmarking, we introduce a \\textbf{label-aware episodic sampler} that\ncollapses multi-label sequences into multiple single-label tasks, keeping the\noutput dimensionality fixed while preserving combinatorial label information.\n  Two FSL paradigms are investigated: the metric-based \\emph{Prototypical\nNetwork} and the gradient-based \\emph{Model-Agnostic Meta-Learning} (MAML),\neach paired with three backbones: 1D CNN, InceptionTime and the 341 M-parameter\ntransformer \\emph{Moment}. On 10-shot, 3-way evaluation, the InceptionTime +\nPrototypical Network combination achieves a \\textbf{0.944 weighted F1} in the\nmulti-class regime and \\textbf{0.935} in the multi-label regime, outperforming\nfinetuned Moment by up to 5.3\\% while requiring two orders of magnitude fewer\nparameters and training time. Across all backbones, metric learning\nconsistently surpasses MAML, and our label-aware sampling yields an additional\n1.7\\% F1 over traditional class-based sampling.\n  These findings challenge the assumption that large foundation models are\nalways superior: when data are scarce, lightweight CNN architectures augmented\nwith simple metric learning not only converge faster but also generalize\nbetter. We release code, data splits and pre-trained weights to foster\nreproducible research and to catalyze the adoption of FSL in high-value\nmanufacturing inspection."}
{"id": "2506.13825", "pdf": "https://arxiv.org/pdf/2506.13825", "abs": "https://arxiv.org/abs/2506.13825", "authors": ["Gnankan Landry Regis N'guessan", "Issa Karambal"], "title": "The Reflexive Integrated Information Unit: A Differentiable Primitive for Artificial Consciousness", "categories": ["cs.AI"], "comment": null, "summary": "Research on artificial consciousness lacks the equivalent of the perceptron:\na small, trainable module that can be copied, benchmarked, and iteratively\nimproved. We introduce the Reflexive Integrated Information Unit (RIIU), a\nrecurrent cell that augments its hidden state $h$ with two additional vectors:\n(i) a meta-state $\\mu$ that records the cell's own causal footprint, and (ii) a\nbroadcast buffer $B$ that exposes that footprint to the rest of the network. A\nsliding-window covariance and a differentiable Auto-$\\Phi$ surrogate let each\nRIIU maximize local information integration online. We prove that RIIUs (1) are\nend-to-end differentiable, (2) compose additively, and (3) perform\n$\\Phi$-monotone plasticity under gradient ascent. In an eight-way Grid-world, a\nfour-layer RIIU agent restores $>90\\%$ reward within 13 steps after actuator\nfailure, twice as fast as a parameter-matched GRU, while maintaining a non-zero\nAuto-$\\Phi$ signal. By shrinking \"consciousness-like\" computation down to unit\nscale, RIIUs turn a philosophical debate into an empirical mathematical\nproblem."}
{"id": "2506.14002", "pdf": "https://arxiv.org/pdf/2506.14002", "abs": "https://arxiv.org/abs/2506.14002", "authors": ["Siyu Chen", "Heejune Sheen", "Xuyuan Xiong", "Tianhao Wang", "Zhuoran Yang"], "title": "Taming Polysemanticity in LLMs: Provable Feature Recovery via Sparse Autoencoders", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ML", "I.2.6"], "comment": "136 pages, 21 figures", "summary": "We study the challenge of achieving theoretically grounded feature recovery\nusing Sparse Autoencoders (SAEs) for the interpretation of Large Language\nModels. Existing SAE training algorithms often lack rigorous mathematical\nguarantees and suffer from practical limitations such as hyperparameter\nsensitivity and instability. To address these issues, we first propose a novel\nstatistical framework for the feature recovery problem, which includes a new\nnotion of feature identifiability by modeling polysemantic features as sparse\nmixtures of underlying monosemantic concepts. Building on this framework, we\nintroduce a new SAE training algorithm based on ``bias adaptation'', a\ntechnique that adaptively adjusts neural network bias parameters to ensure\nappropriate activation sparsity. We theoretically \\highlight{prove that this\nalgorithm correctly recovers all monosemantic features} when input data is\nsampled from our proposed statistical model. Furthermore, we develop an\nimproved empirical variant, Group Bias Adaptation (GBA), and\n\\highlight{demonstrate its superior performance against benchmark methods when\napplied to LLMs with up to 1.5 billion parameters}. This work represents a\nfoundational step in demystifying SAE training by providing the first SAE\nalgorithm with theoretical recovery guarantees, thereby advancing the\ndevelopment of more transparent and trustworthy AI systems through enhanced\nmechanistic interpretability."}
{"id": "2506.13911", "pdf": "https://arxiv.org/pdf/2506.13911", "abs": "https://arxiv.org/abs/2506.13911", "authors": ["Arie Soeteman", "Balder ten Cate"], "title": "Logical Expressiveness of Graph Neural Networks with Hierarchical Node Individualization", "categories": ["cs.LG", "cs.AI", "cs.LO", "I.2.6; F.2.0"], "comment": "Submitted to NeurIPS 2025, 28 pages, 5 figures", "summary": "We propose and study Hierarchical Ego Graph Neural Networks (HEGNNs), an\nexpressive extension of graph neural networks (GNNs) with hierarchical node\nindividualization, inspired by the Individualization-Refinement paradigm for\ngraph isomorphism testing. HEGNNs generalize subgraph-GNNs and form a hierarchy\nof increasingly expressive models that, in the limit, can distinguish graphs up\nto isomorphism. We provide a logical characterization of HEGNN node\nclassifiers, with and without subgraph restrictions, using graded hybrid logic.\nThis characterization enables us to relate the separating power of HEGNNs to\nthat of higher-order GNNs, GNNs enriched with local homomorphism count\nfeatures, and color refinement algorithms based on\nIndividualization-Refinement. Our experimental results confirm the practical\nfeasibility of HEGNNs and show benefits in comparison with traditional GNN\narchitectures, both with and without local homomorphism count features."}
{"id": "2506.13841", "pdf": "https://arxiv.org/pdf/2506.13841", "abs": "https://arxiv.org/abs/2506.13841", "authors": ["Miho Koda", "Yu Zheng", "Ruixian Ma", "Mingyang Sun", "Devesh Pansare", "Fabio Duarte", "Paolo Santi"], "title": "LocationReasoner: Evaluating LLMs on Real-World Site Selection Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs), particularly those enhanced\nthrough reinforced post-training, have demonstrated impressive reasoning\ncapabilities, as exemplified by models such as OpenAI o1 and DeepSeek-R1.\nHowever, these capabilities are predominantly benchmarked on domains like\nmathematical problem solving and code generation -- leaving open the question\nof whether such reasoning skills generalize to complex, real-world scenarios.\nIn this paper, we introduce LocationReasoner, a benchmark designed to evaluate\nLLMs' reasoning abilities in the context of real-world site selection, where\nmodels must identify feasible locations by reasoning over diverse and\ncomplicated spatial, environmental, and logistical constraints. The benchmark\ncomprises over 300 carefully crafted queries of varying difficulty levels,\nsupported by a sandbox environment with in-house tools for constraint-based\nlocation search. Extensive evaluations reveal that state-of-the-art reasoning\nmodels offer limited improvement over their non-reasoning predecessors in\nreal-world contexts, with even the latest OpenAI o4 model failing on 30% of\nsite selection tasks. Moreover, agentic strategies such as ReAct and Reflexion\noften suffer from over-reasoning, leading to worse outcomes than direct\ncode-generation prompting. With key limitations of LLMs in holistic and\nnon-linear reasoning highlighted, we release LocationReasoner to foster the\ndevelopment of LLMs and agents capable of robust, grounded reasoning in\nreal-world decision-making tasks. Codes and data for our benchmark are\navailable at https://github.com/miho-koda/LocationReasoner."}
{"id": "2506.14020", "pdf": "https://arxiv.org/pdf/2506.14020", "abs": "https://arxiv.org/abs/2506.14020", "authors": ["Keyue Jiang", "Jiahao Cui", "Xiaowen Dong", "Laura Toni"], "title": "Bures-Wasserstein Flow Matching for Graph Generation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Graph generation has emerged as a critical task in fields ranging from\nmolecule design to drug discovery. Contemporary approaches, notably diffusion\nand flow-based models, have achieved solid graph generative performance through\nconstructing a probability path that interpolates between a reference\ndistribution and the data distribution. However, these methods typically model\nthe evolution of individual nodes and edges independently and use linear\ninterpolations to build the path assuming that the data lie in Euclidean space.\nWe show that this is suboptimal given the intrinsic non-Euclidean structure and\ninterconnected patterns of graphs, and it poses risks to the sampling\nconvergence. To build a better probability path, we model the joint evolution\nof the nodes and edges by representing graphs as connected systems\nparameterized by Markov random fields (MRF). We then leverage the optimal\ntransport displacement between MRF objects to design the probability path for\ngraph generation. Based on this, we introduce BWFlow, a flow-matching framework\nfor graph generation that respects the underlying geometry of graphs and\nprovides smooth velocities in the probability path. The novel framework can be\nadapted to both continuous and discrete flow-matching algorithms. Experimental\nevaluations in plain graph generation and 2D/3D molecule generation validate\nthe effectiveness of BWFlow in graph generation with competitive performance,\nstable training, and guaranteed sampling convergence."}
{"id": "2506.13916", "pdf": "https://arxiv.org/pdf/2506.13916", "abs": "https://arxiv.org/abs/2506.13916", "authors": ["Isaias Banales", "Arturo Jaramillo", "Heli Ricalde Guerrero"], "title": "Branching Stein Variational Gradient Descent for sampling multimodal distributions", "categories": ["cs.LG", "stat.CO", "62F15, 65C05, 65C35"], "comment": null, "summary": "We propose a novel particle-based variational inference method designed to\nwork with multimodal distributions. Our approach, referred to as Branched Stein\nVariational Gradient Descent (BSVGD), extends the classical Stein Variational\nGradient Descent (SVGD) algorithm by incorporating a random branching mechanism\nthat encourages the exploration of the state space. In this work, a theoretical\nguarantee for the convergence in distribution is presented, as well as\nnumerical experiments to validate the suitability of our algorithm. Performance\ncomparisons between the BSVGD and the SVGD are presented using the Wasserstein\ndistance between samples and the corresponding computational times."}
{"id": "2506.13917", "pdf": "https://arxiv.org/pdf/2506.13917", "abs": "https://arxiv.org/abs/2506.13917", "authors": ["Miguel A. Lago", "Ghada Zamzmi", "Brandon Eich", "Jana G. Delfino"], "title": "Evaluating Explainability: A Framework for Systematic Assessment and Reporting of Explainable AI Features", "categories": ["cs.AI"], "comment": null, "summary": "Explainability features are intended to provide insight into the internal\nmechanisms of an AI device, but there is a lack of evaluation techniques for\nassessing the quality of provided explanations. We propose a framework to\nassess and report explainable AI features. Our evaluation framework for AI\nexplainability is based on four criteria: 1) Consistency quantifies the\nvariability of explanations to similar inputs, 2) Plausibility estimates how\nclose the explanation is to the ground truth, 3) Fidelity assesses the\nalignment between the explanation and the model internal mechanisms, and 4)\nUsefulness evaluates the impact on task performance of the explanation.\nFinally, we developed a scorecard for AI explainability methods that serves as\na complete description and evaluation to accompany this type of algorithm. We\ndescribe these four criteria and give examples on how they can be evaluated. As\na case study, we use Ablation CAM and Eigen CAM to illustrate the evaluation of\nexplanation heatmaps on the detection of breast lesions on synthetic\nmammographies. The first three criteria are evaluated for clinically-relevant\nscenarios. Our proposed framework establishes criteria through which the\nquality of explanations provided by AI models can be evaluated. We intend for\nour framework to spark a dialogue regarding the value provided by\nexplainability features and help improve the development and evaluation of\nAI-based medical devices."}
{"id": "2506.14113", "pdf": "https://arxiv.org/pdf/2506.14113", "abs": "https://arxiv.org/abs/2506.14113", "authors": ["Yitian Zhang", "Liheng Ma", "Antonios Valkanas", "Boris N. Oreshkin", "Mark Coates"], "title": "SKOLR: Structured Koopman Operator Linear RNN for Time-Series Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Koopman operator theory provides a framework for nonlinear dynamical system\nanalysis and time-series forecasting by mapping dynamics to a space of\nreal-valued measurement functions, enabling a linear operator representation.\nDespite the advantage of linearity, the operator is generally\ninfinite-dimensional. Therefore, the objective is to learn measurement\nfunctions that yield a tractable finite-dimensional Koopman operator\napproximation. In this work, we establish a connection between Koopman operator\napproximation and linear Recurrent Neural Networks (RNNs), which have recently\ndemonstrated remarkable success in sequence modeling. We show that by\nconsidering an extended state consisting of lagged observations, we can\nestablish an equivalence between a structured Koopman operator and linear RNN\nupdates. Building on this connection, we present SKOLR, which integrates a\nlearnable spectral decomposition of the input signal with a multilayer\nperceptron (MLP) as the measurement functions and implements a structured\nKoopman operator via a highly parallel linear RNN stack. Numerical experiments\non various forecasting benchmarks and dynamical systems show that this\nstreamlined, Koopman-theory-based design delivers exceptional performance."}
{"id": "2506.13923", "pdf": "https://arxiv.org/pdf/2506.13923", "abs": "https://arxiv.org/abs/2506.13923", "authors": ["Vaskar Nath", "Elaine Lau", "Anisha Gunjal", "Manasi Sharma", "Nikhil Baharte", "Sean Hendryx"], "title": "Adaptive Guidance Accelerates Reinforcement Learning of Reasoning Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "We study the process through which reasoning models trained with\nreinforcement learning on verifiable rewards (RLVR) can learn to solve new\nproblems. We find that RLVR drives performance through two main means: (1) by\ncompressing pass@$k$ into pass@1 and (2) via \"capability gain\" in which models\nlearn to solve new problems that they previously could not solve even at high\n$k$. We find that while capability gain exists across model scales, learning to\nsolve new problems is primarily driven through self-distillation. We\ndemonstrate these findings across model scales ranging from 0.5B to 72B on\n>500,000 reasoning problems with prompts and verifiable final answers across\nmath, science, and code domains. We further show that we can significantly\nimprove pass@$k$ rates by leveraging natural language guidance for the model to\nconsider within context while still requiring the model to derive a solution\nchain from scratch. Based of these insights, we derive $\\text{Guide}$ - a new\nclass of online training algorithms. $\\text{Guide}$ adaptively incorporates\nhints into the model's context on problems for which all rollouts were\ninitially incorrect and adjusts the importance sampling ratio for the\n\"off-policy\" trajectories in order to optimize the policy for contexts in which\nthe hints are no longer present. We describe variants of $\\text{Guide}$ for\nGRPO and PPO and empirically show that Guide-GRPO on 7B and 32B parameter\nmodels improves generalization over its vanilla counterpart with up to 4$\\%$\nmacro-average improvement across math benchmarks. We include careful ablations\nto analyze $\\text{Guide}$'s components and theoretically analyze Guide's\nlearning efficiency."}
{"id": "2506.13920", "pdf": "https://arxiv.org/pdf/2506.13920", "abs": "https://arxiv.org/abs/2506.13920", "authors": ["Mbithe Nzomo", "Deshendran Moodley"], "title": "Integrating Knowledge Graphs and Bayesian Networks: A Hybrid Approach for Explainable Disease Risk Prediction", "categories": ["cs.AI"], "comment": "This work has been accepted for presentation at the 49th IEEE\n  International Conference on Computers, Software, and Applications (COMPSAC\n  2025). The final published version will be available via IEEE Xplore", "summary": "Multimodal electronic health record (EHR) data is useful for disease risk\nprediction based on medical domain knowledge. However, general medical\nknowledge must be adapted to specific healthcare settings and patient\npopulations to achieve practical clinical use. Additionally, risk prediction\nsystems must handle uncertainty from incomplete data and non-deterministic\nhealth outcomes while remaining explainable. These challenges can be alleviated\nby the integration of knowledge graphs (KGs) and Bayesian networks (BNs). We\npresent a novel approach for constructing BNs from ontology-based KGs and\nmultimodal EHR data for explainable disease risk prediction. Through an\napplication use case of atrial fibrillation and real-world EHR data, we\ndemonstrate that the approach balances generalised medical knowledge with\npatient-specific context, effectively handles uncertainty, is highly\nexplainable, and achieves good predictive performance."}
{"id": "2506.14202", "pdf": "https://arxiv.org/pdf/2506.14202", "abs": "https://arxiv.org/abs/2506.14202", "authors": ["Makoto Shing", "Takuya Akiba"], "title": "DiffusionBlocks: Blockwise Training for Generative Models via Score-Based Diffusion", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "To appear at TTODLer-FM Workshop of the 42nd International Conference\n  on Machine Learning", "summary": "Training large neural networks with end-to-end backpropagation creates\nsignificant memory bottlenecks, limiting accessibility to state-of-the-art AI\nresearch. We propose $\\textit{DiffusionBlocks}$, a novel training framework\nthat interprets neural network blocks as performing denoising operations in a\ncontinuous-time diffusion process. By partitioning the network into\nindependently trainable blocks and optimizing noise level assignments based on\nequal cumulative probability mass, our approach achieves significant memory\nefficiency while maintaining competitive performance compared to traditional\nbackpropagation in generative tasks. Experiments on image generation and\nlanguage modeling tasks demonstrate memory reduction proportional to the number\nof blocks while achieving superior performance. DiffusionBlocks provides a\npromising pathway for democratizing access to large-scale neural network\ntraining with limited computational resources."}
{"id": "2506.13935", "pdf": "https://arxiv.org/pdf/2506.13935", "abs": "https://arxiv.org/abs/2506.13935", "authors": ["Vishesh Kumar Tanwar", "Soumik Sarkar", "Asheesh K. Singh", "Sajal K. Das"], "title": "ReinDSplit: Reinforced Dynamic Split Learning for Pest Recognition in Precision Agriculture", "categories": ["cs.LG", "cs.DC", "cs.ET"], "comment": null, "summary": "To empower precision agriculture through distributed machine learning (DML),\nsplit learning (SL) has emerged as a promising paradigm, partitioning deep\nneural networks (DNNs) between edge devices and servers to reduce computational\nburdens and preserve data privacy. However, conventional SL frameworks'\none-split-fits-all strategy is a critical limitation in agricultural ecosystems\nwhere edge insect monitoring devices exhibit vast heterogeneity in\ncomputational power, energy constraints, and connectivity. This leads to\nstraggler bottlenecks, inefficient resource utilization, and compromised model\nperformance. Bridging this gap, we introduce ReinDSplit, a novel reinforcement\nlearning (RL)-driven framework that dynamically tailors DNN split points for\neach device, optimizing efficiency without sacrificing accuracy. Specifically,\na Q-learning agent acts as an adaptive orchestrator, balancing workloads and\nlatency thresholds across devices to mitigate computational starvation or\noverload. By framing split layer selection as a finite-state Markov decision\nprocess, ReinDSplit convergence ensures that highly constrained devices\ncontribute meaningfully to model training over time. Evaluated on three insect\nclassification datasets using ResNet18, GoogleNet, and MobileNetV2, ReinDSplit\nachieves 94.31% accuracy with MobileNetV2. Beyond agriculture, ReinDSplit\npioneers a paradigm shift in SL by harmonizing RL for resource efficiency,\nprivacy, and scalability in heterogeneous environments."}
{"id": "2506.13980", "pdf": "https://arxiv.org/pdf/2506.13980", "abs": "https://arxiv.org/abs/2506.13980", "authors": ["Shahaf David", "Yair Meidan", "Ido Hersko", "Daniel Varnovitzky", "Dudu Mimran", "Yuval Elovici", "Asaf Shabtai"], "title": "ProfiLLM: An LLM-Based Framework for Implicit Profiling of Chatbot Users", "categories": ["cs.AI"], "comment": null, "summary": "Despite significant advancements in conversational AI, large language model\n(LLM)-powered chatbots often struggle with personalizing their responses\naccording to individual user characteristics, such as technical expertise,\nlearning style, and communication preferences. This lack of personalization is\nparticularly problematic in specialized knowledge-intense domains like\nIT/cybersecurity (ITSec), where user knowledge levels vary widely. Existing\napproaches for chatbot personalization primarily rely on static user categories\nor explicit self-reported information, limiting their adaptability to an\nevolving perception of the user's proficiency, obtained in the course of\nongoing interactions. In this paper, we propose ProfiLLM, a novel framework for\nimplicit and dynamic user profiling through chatbot interactions. This\nframework consists of a taxonomy that can be adapted for use in diverse domains\nand an LLM-based method for user profiling in terms of the taxonomy. To\ndemonstrate ProfiLLM's effectiveness, we apply it in the ITSec domain where\ntroubleshooting interactions are used to infer chatbot users' technical\nproficiency. Specifically, we developed ProfiLLM[ITSec], an ITSec-adapted\nvariant of ProfiLLM, and evaluated its performance on 1,760 human-like chatbot\nconversations from 263 synthetic users. Results show that ProfiLLM[ITSec]\nrapidly and accurately infers ITSec profiles, reducing the gap between actual\nand predicted scores by up to 55--65\\% after a single prompt, followed by minor\nfluctuations and further refinement. In addition to evaluating our new implicit\nand dynamic profiling framework, we also propose an LLM-based persona\nsimulation methodology, a structured taxonomy for ITSec proficiency, our\ncodebase, and a dataset of chatbot interactions to support future research."}
{"id": "2506.14262", "pdf": "https://arxiv.org/pdf/2506.14262", "abs": "https://arxiv.org/abs/2506.14262", "authors": ["Mohammad Emtiyaz Khan"], "title": "Knowledge Adaptation as Posterior Correction", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Adaptation is the holy grail of intelligence, but even the best AI models\n(like GPT) lack the adaptivity of toddlers. So the question remains: how can\nmachines adapt quickly? Despite a lot of progress on model adaptation to\nfacilitate continual and federated learning, as well as model merging, editing,\nunlearning, etc., little is known about the mechanisms by which machines can\nnaturally learn to adapt in a similar way as humans and animals. Here, we show\nthat all such adaptation methods can be seen as different ways of `correcting'\nthe approximate posteriors. More accurate posteriors lead to smaller\ncorrections, which in turn imply quicker adaptation. The result is obtained by\nusing a dual-perspective of the Bayesian Learning Rule of Khan and Rue (2023)\nwhere interference created during adaptation is characterized by the\nnatural-gradient mismatch over the past data. We present many examples to\ndemonstrate the use of posterior-correction as a natural mechanism for the\nmachines to learn to adapt quickly."}
{"id": "2506.13958", "pdf": "https://arxiv.org/pdf/2506.13958", "abs": "https://arxiv.org/abs/2506.13958", "authors": ["Leonardo Guiducci", "Antonio Rizzo", "Giovanna Maria Dimitri"], "title": "Toward Explainable Offline RL: Analyzing Representations in Intrinsically Motivated Decision Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Elastic Decision Transformers (EDTs) have proved to be particularly\nsuccessful in offline reinforcement learning, offering a flexible framework\nthat unifies sequence modeling with decision-making under uncertainty. Recent\nresearch has shown that incorporating intrinsic motivation mechanisms into EDTs\nimproves performance across exploration tasks, yet the representational\nmechanisms underlying these improvements remain unexplored. In this paper, we\nintroduce a systematic post-hoc explainability framework to analyze how\nintrinsic motivation shapes learned embeddings in EDTs. Through statistical\nanalysis of embedding properties (including covariance structure, vector\nmagnitudes, and orthogonality), we reveal that different intrinsic motivation\nvariants create fundamentally different representational structures. Our\nanalysis demonstrates environment-specific correlation patterns between\nembedding metrics and performance that explain why intrinsic motivation\nimproves policy learning. These findings show that intrinsic motivation\noperates beyond simple exploration bonuses, acting as a representational prior\nthat shapes embedding geometry in biologically plausible ways, creating\nenvironment-specific organizational structures that facilitate better\ndecision-making."}
{"id": "2506.13983", "pdf": "https://arxiv.org/pdf/2506.13983", "abs": "https://arxiv.org/abs/2506.13983", "authors": ["Adarsh Gupta", "Bhabesh Mali", "Chandan Karfa"], "title": "SANGAM: SystemVerilog Assertion Generation via Monte Carlo Tree Self-Refine", "categories": ["cs.AI"], "comment": "Adarsh Gupta and Bhabesh Mali contributed equally to this work", "summary": "Recent advancements in the field of reasoning using Large Language Models\n(LLMs) have created new possibilities for more complex and automatic Hardware\nAssertion Generation techniques. This paper introduces SANGAM, a SystemVerilog\nAssertion Generation framework using LLM-guided Monte Carlo Tree Search for the\nautomatic generation of SVAs from industry-level specifications. The proposed\nframework utilizes a three-stage approach: Stage 1 consists of multi-modal\nSpecification Processing using Signal Mapper, SPEC Analyzer, and Waveform\nAnalyzer LLM Agents. Stage 2 consists of using the Monte Carlo Tree Self-Refine\n(MCTSr) algorithm for automatic reasoning about SVAs for each signal, and\nfinally, Stage 3 combines the MCTSr-generated reasoning traces to generate SVA\nassertions for each signal. The results demonstrated that our framework,\nSANGAM, can generate a robust set of SVAs, performing better in the evaluation\nprocess in comparison to the recent methods."}
{"id": "2506.14280", "pdf": "https://arxiv.org/pdf/2506.14280", "abs": "https://arxiv.org/abs/2506.14280", "authors": ["Bai Cong", "Nico Daheim", "Yuesong Shen", "Rio Yokota", "Mohammad Emtiyaz Khan", "Thomas Möllenhoff"], "title": "Improving LoRA with Variational Learning", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": "16 pages, 4 figures", "summary": "Bayesian methods have recently been used to improve LoRA finetuning and,\nalthough they improve calibration, their effect on other metrics (such as\naccuracy) is marginal and can sometimes even be detrimental. Moreover, Bayesian\nmethods also increase computational overheads and require additional tricks for\nthem to work well. Here, we fix these issues by using a recently proposed\nvariational algorithm called IVON. We show that IVON is easy to implement and\nhas similar costs to AdamW, and yet it can also drastically improve many\nmetrics by using a simple posterior pruning technique. We present extensive\nresults on billion-scale LLMs (Llama and Qwen series) going way beyond the\nscale of existing applications of IVON. For example, we finetune a Llama-3.2-3B\nmodel on a set of commonsense reasoning tasks and improve accuracy over AdamW\nby 1.3% and reduce ECE by 5.4%, outperforming AdamW and other recent Bayesian\nmethods like Laplace-LoRA and BLoB. Overall, our results show that variational\nlearning with IVON can effectively improve LoRA finetuning."}
{"id": "2506.13972", "pdf": "https://arxiv.org/pdf/2506.13972", "abs": "https://arxiv.org/abs/2506.13972", "authors": ["Zhiqi Wang", "Chengyu Zhang", "Yuetian Chen", "Nathalie Baracaldo", "Swanand Kadhe", "Lei Yu"], "title": "Membership Inference Attacks as Privacy Tools: Reliability, Disparity and Ensemble", "categories": ["cs.LG"], "comment": null, "summary": "Membership inference attacks (MIAs) pose a significant threat to the privacy\nof machine learning models and are widely used as tools for privacy assessment,\nauditing, and machine unlearning. While prior MIA research has primarily\nfocused on performance metrics such as AUC, accuracy, and TPR@low FPR - either\nby developing new methods to enhance these metrics or using them to evaluate\nprivacy solutions - we found that it overlooks the disparities among different\nattacks. These disparities, both between distinct attack methods and between\nmultiple instantiations of the same method, have crucial implications for the\nreliability and completeness of MIAs as privacy evaluation tools. In this\npaper, we systematically investigate these disparities through a novel\nframework based on coverage and stability analysis. Extensive experiments\nreveal significant disparities in MIAs, their potential causes, and their\nbroader implications for privacy evaluation. To address these challenges, we\npropose an ensemble framework with three distinct strategies to harness the\nstrengths of state-of-the-art MIAs while accounting for their disparities. This\nframework not only enables the construction of more powerful attacks but also\nprovides a more robust and comprehensive methodology for privacy evaluation."}
{"id": "2506.13990", "pdf": "https://arxiv.org/pdf/2506.13990", "abs": "https://arxiv.org/abs/2506.13990", "authors": ["Hamidou Tembine"], "title": "Machine Mirages: Defining the Undefined", "categories": ["cs.AI"], "comment": "Submitted", "summary": "As multimodal machine intelligence systems started achieving average\nanimal-level and average human-level fluency in many measurable tasks in\nprocessing images, language, and sound, they began to exhibit a new class of\ncognitive aberrations: machine mirages. These include delusion, illusion,\nconfabulation, hallucination, misattribution error, semantic drift, semantic\ncompression, exaggeration, causal inference failure, uncanny valley of\nperception, bluffing-patter-bullshitting, cognitive stereotypy, pragmatic\nmisunderstanding, hypersignification, semantic reheating-warming, simulated\nauthority effect, fallacious abductive leap, contextual drift, referential\nhallucination, semiotic Frankenstein effect, calibration failure, spurious\ncorrelation, bias amplification, concept drift sensitivity, misclassification\nunder uncertainty, adversarial vulnerability, overfitting, prosodic\nmisclassification, accent bias, turn boundary failure, semantic boundary\nconfusion, noise overfitting, latency-induced decision drift, ambiguity\ncollapse and other forms of error that mimic but do not replicate human or\nanimal fallibility. This article presents some of the errors and argues that\nthese failures must be explicitly defined and systematically assessed.\nUnderstanding machine mirages is essential not only for improving machine\nintelligence reliability but also for constructing a multiscale ethical,\nco-evolving intelligence ecosystem that respects the diverse forms of life,\ncognition, and expression it will inevitably touch."}
{"id": "2506.14291", "pdf": "https://arxiv.org/pdf/2506.14291", "abs": "https://arxiv.org/abs/2506.14291", "authors": ["Ben Finkelshtein", "İsmail İlkan Ceylan", "Michael Bronstein", "Ron Levie"], "title": "Equivariance Everywhere All At Once: A Recipe for Graph Foundation Models", "categories": ["cs.LG", "cs.SI", "stat.ML"], "comment": null, "summary": "Graph machine learning architectures are typically tailored to specific tasks\non specific datasets, which hinders their broader applicability. This has led\nto a new quest in graph machine learning: how to build graph foundation models\ncapable of generalizing across arbitrary graphs and features? In this work, we\npresent a recipe for designing graph foundation models for node-level tasks\nfrom first principles. The key ingredient underpinning our study is a\nsystematic investigation of the symmetries that a graph foundation model must\nrespect. In a nutshell, we argue that label permutation-equivariance alongside\nfeature permutation-invariance are necessary in addition to the common node\npermutation-equivariance on each local neighborhood of the graph. To this end,\nwe first characterize the space of linear transformations that are equivariant\nto permutations of nodes and labels, and invariant to permutations of features.\nWe then prove that the resulting network is a universal approximator on\nmultisets that respect the aforementioned symmetries. Our recipe uses such\nlayers on the multiset of features induced by the local neighborhood of the\ngraph to obtain a class of graph foundation models for node property\nprediction. We validate our approach through extensive experiments on 29\nreal-world node classification datasets, demonstrating both strong zero-shot\nempirical performance and consistent improvement as the number of training\ngraphs increases."}
{"id": "2506.13974", "pdf": "https://arxiv.org/pdf/2506.13974", "abs": "https://arxiv.org/abs/2506.13974", "authors": ["Michael Crawshaw", "Blake Woodworth", "Mingrui Liu"], "title": "Constant Stepsize Local GD for Logistic Regression: Acceleration by Instability", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Existing analysis of Local (Stochastic) Gradient Descent for heterogeneous\nobjectives requires stepsizes $\\eta \\leq 1/K$ where $K$ is the communication\ninterval, which ensures monotonic decrease of the objective. In contrast, we\nanalyze Local Gradient Descent for logistic regression with separable,\nheterogeneous data using any stepsize $\\eta > 0$. With $R$ communication rounds\nand $M$ clients, we show convergence at a rate $\\mathcal{O}(1/\\eta K R)$ after\nan initial unstable phase lasting for $\\widetilde{\\mathcal{O}}(\\eta K M)$\nrounds. This improves upon the existing $\\mathcal{O}(1/R)$ rate for general\nsmooth, convex objectives. Our analysis parallels the single machine analysis\nof~\\cite{wu2024large} in which instability is caused by extremely large\nstepsizes, but in our setting another source of instability is large local\nupdates with heterogeneous objectives."}
{"id": "2506.14045", "pdf": "https://arxiv.org/pdf/2506.14045", "abs": "https://arxiv.org/abs/2506.14045", "authors": ["Martin Klissarov", "Akhil Bagaria", "Ziyan Luo", "George Konidaris", "Doina Precup", "Marlos C. Machado"], "title": "Discovering Temporal Structure: An Overview of Hierarchical Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Developing agents capable of exploring, planning and learning in complex\nopen-ended environments is a grand challenge in artificial intelligence (AI).\nHierarchical reinforcement learning (HRL) offers a promising solution to this\nchallenge by discovering and exploiting the temporal structure within a stream\nof experience. The strong appeal of the HRL framework has led to a rich and\ndiverse body of literature attempting to discover a useful structure. However,\nit is still not clear how one might define what constitutes good structure in\nthe first place, or the kind of problems in which identifying it may be\nhelpful. This work aims to identify the benefits of HRL from the perspective of\nthe fundamental challenges in decision-making, as well as highlight its impact\non the performance trade-offs of AI agents. Through these benefits, we then\ncover the families of methods that discover temporal structure in HRL, ranging\nfrom learning directly from online experience to offline datasets, to\nleveraging large language models (LLMs). Finally, we highlight the challenges\nof temporal structure discovery and the domains that are particularly\nwell-suited for such endeavours."}
{"id": "2506.14597", "pdf": "https://arxiv.org/pdf/2506.14597", "abs": "https://arxiv.org/abs/2506.14597", "authors": ["Thomas Newman", "Christopher Nemeth", "Matthew Jones", "Philip Jonathan"], "title": "Deep Learning Surrogates for Real-Time Gas Emission Inversion", "categories": ["cs.LG", "stat.AP", "stat.ML"], "comment": "3 figures, 11 pages", "summary": "Real-time identification and quantification of greenhouse-gas emissions under\ntransient atmospheric conditions is a critical challenge in environmental\nmonitoring. We introduce a spatio-temporal inversion framework that embeds a\ndeep-learning surrogate of computational fluid dynamics (CFD) within a\nsequential Monte Carlo algorithm to perform Bayesian inference of both emission\nrate and source location in dynamic flow fields. By substituting costly\nnumerical solvers with a multilayer perceptron trained on high-fidelity CFD\noutputs, our surrogate captures spatial heterogeneity and temporal evolution of\ngas dispersion, while delivering near-real-time predictions. Validation on the\nChilbolton methane release dataset demonstrates comparable accuracy to full CFD\nsolvers and Gaussian plume models, yet achieves orders-of-magnitude faster\nruntimes. Further experiments under simulated obstructed-flow scenarios confirm\nrobustness in complex environments. This work reconciles physical fidelity with\ncomputational feasibility, offering a scalable solution for industrial\nemissions monitoring and other time-sensitive spatio-temporal inversion tasks\nin environmental and scientific modeling."}
{"id": "2506.13981", "pdf": "https://arxiv.org/pdf/2506.13981", "abs": "https://arxiv.org/abs/2506.13981", "authors": ["Thanh Dan Bui"], "title": "HAELT: A Hybrid Attentive Ensemble Learning Transformer Framework for High-Frequency Stock Price Forecasting", "categories": ["cs.LG", "cs.AI", "I.2.6; I.5.4; I.6.5; J.4"], "comment": null, "summary": "High-frequency stock price prediction is challenging due to non-stationarity,\nnoise, and volatility. To tackle these issues, we propose the Hybrid Attentive\nEnsemble Learning Transformer (HAELT), a deep learning framework combining a\nResNet-based noise-mitigation module, temporal self-attention for dynamic focus\non relevant history, and a hybrid LSTM-Transformer core that captures both\nlocal and long-range dependencies. These components are adaptively ensembled\nbased on recent performance. Evaluated on hourly Apple Inc. (AAPL) data from\nJan 2024 to May 2025, HAELT achieves the highest F1-Score on the test set,\neffectively identifying both upward and downward price movements. This\ndemonstrates HAELT's potential for robust, practical financial forecasting and\nalgorithmic trading."}
{"id": "2506.14070", "pdf": "https://arxiv.org/pdf/2506.14070", "abs": "https://arxiv.org/abs/2506.14070", "authors": ["Xinglei Wang", "Tao Cheng", "Stephen Law", "Zichao Zeng", "Ilya Ilyankou", "Junyuan Liu", "Lu Yin", "Weiming Huang", "Natchapon Jongwiriyanurak"], "title": "Into the Unknown: Applying Inductive Spatial-Semantic Location Embeddings for Predicting Individuals' Mobility Beyond Visited Places", "categories": ["cs.AI"], "comment": "10 pages, 5 figures", "summary": "Predicting individuals' next locations is a core task in human mobility\nmodelling, with wide-ranging implications for urban planning, transportation,\npublic policy and personalised mobility services. Traditional approaches\nlargely depend on location embeddings learned from historical mobility\npatterns, limiting their ability to encode explicit spatial information,\nintegrate rich urban semantic context, and accommodate previously unseen\nlocations. To address these challenges, we explore the application of CaLLiPer\n-- a multimodal representation learning framework that fuses spatial\ncoordinates and semantic features of points of interest through contrastive\nlearning -- for location embedding in individual mobility prediction.\nCaLLiPer's embeddings are spatially explicit, semantically enriched, and\ninductive by design, enabling robust prediction performance even in scenarios\ninvolving emerging locations. Through extensive experiments on four public\nmobility datasets under both conventional and inductive settings, we\ndemonstrate that CaLLiPer consistently outperforms strong baselines,\nparticularly excelling in inductive scenarios. Our findings highlight the\npotential of multimodal, inductive location embeddings to advance the\ncapabilities of human mobility prediction systems. We also release the code and\ndata (https://github.com/xlwang233/Into-the-Unknown) to foster reproducibility\nand future research."}
{"id": "2506.14746", "pdf": "https://arxiv.org/pdf/2506.14746", "abs": "https://arxiv.org/abs/2506.14746", "authors": ["Nataly Brukhim", "Aldo Pacchiano", "Miroslav Dudik", "Robert Schapire"], "title": "On the Hardness of Bandit Learning", "categories": ["cs.LG", "stat.ML"], "comment": "13 main pages", "summary": "We study the task of bandit learning, also known as best-arm identification,\nunder the assumption that the true reward function f belongs to a known, but\narbitrary, function class F. We seek a general theory of bandit learnability,\nakin to the PAC framework for classification. Our investigation is guided by\nthe following two questions: (1) which classes F are learnable, and (2) how\nthey are learnable. For example, in the case of binary PAC classification,\nlearnability is fully determined by a combinatorial dimension - the VC\ndimension- and can be attained via a simple algorithmic principle, namely,\nempirical risk minimization (ERM). In contrast to classical learning-theoretic\nresults, our findings reveal limitations of learning in structured bandits,\noffering insights into the boundaries of bandit learnability. First, for the\nquestion of \"which\", we show that the paradigm of identifying the learnable\nclasses via a dimension-like quantity fails for bandit learning. We give a\nsimple proof demonstrating that no combinatorial dimension can characterize\nbandit learnability, even in finite classes, following a standard definition of\ndimension introduced by Ben-David et al. (2019). For the question of \"how\", we\nprove a computational hardness result: we construct a reward function class for\nwhich at most two queries are needed to find the optimal action, yet no\nalgorithm can do so in polynomial time unless RP=NP. We also prove that this\nclass admits efficient algorithms for standard algorithmic operations often\nconsidered in learning theory, such as an ERM. This implies that computational\nhardness is in this case inherent to the task of bandit learning. Beyond these\nresults, we investigate additional themes such as learning under noise,\ntrade-offs between noise models, and the relationship between query complexity\nand regret minimization."}
{"id": "2506.13987", "pdf": "https://arxiv.org/pdf/2506.13987", "abs": "https://arxiv.org/abs/2506.13987", "authors": ["Md Abrar Jahin", "Adiba Abid", "M. F. Mridha"], "title": "Quantum-Informed Contrastive Learning with Dynamic Mixup Augmentation for Class-Imbalanced Expert Systems", "categories": ["cs.LG"], "comment": null, "summary": "Expert systems often operate in domains characterized by class-imbalanced\ntabular data, where detecting rare but critical instances is essential for\nsafety and reliability. While conventional approaches, such as cost-sensitive\nlearning, oversampling, and graph neural networks, provide partial solutions,\nthey suffer from drawbacks like overfitting, label noise, and poor\ngeneralization in low-density regions. To address these challenges, we propose\nQCL-MixNet, a novel Quantum-Informed Contrastive Learning framework augmented\nwith k-nearest neighbor (kNN) guided dynamic mixup for robust classification\nunder imbalance. QCL-MixNet integrates three core innovations: (i) a Quantum\nEntanglement-inspired layer that models complex feature interactions through\nsinusoidal transformations and gated attention, (ii) a sample-aware mixup\nstrategy that adaptively interpolates feature representations of semantically\nsimilar instances to enhance minority class representation, and (iii) a hybrid\nloss function that unifies focal reweighting, supervised contrastive learning,\ntriplet margin loss, and variance regularization to improve both intra-class\ncompactness and inter-class separability. Extensive experiments on 18\nreal-world imbalanced datasets (binary and multi-class) demonstrate that\nQCL-MixNet consistently outperforms 20 state-of-the-art machine learning, deep\nlearning, and GNN-based baselines in macro-F1 and recall, often by substantial\nmargins. Ablation studies further validate the critical role of each\narchitectural component. Our results establish QCL-MixNet as a new benchmark\nfor tabular imbalance handling in expert systems. Theoretical analyses\nreinforce its expressiveness, generalization, and optimization robustness."}
{"id": "2506.14079", "pdf": "https://arxiv.org/pdf/2506.14079", "abs": "https://arxiv.org/abs/2506.14079", "authors": ["Matthew Toles", "Rattandeep Singh", "Isaac Song Zhou Yu"], "title": "FormGym: Doing Paperwork with Agents", "categories": ["cs.AI"], "comment": null, "summary": "Completing paperwork is a challenging and time-consuming problem. Form\nfilling is especially challenging in the pure-image domain without access to\nOCR, typeset PDF text, or a DOM. For computer agents, it requires multiple\nabilities, including multi-modal understanding, information retrieval, and\ntool-use. We present a novel form-filling benchmark consisting of 432 fields\nspread across 55 documents and 3 tasks, requiring knowledge of 236 features per\nuser. We find that baseline VLAs achieve less than 1% accuracy in most cases,\nprimarily due to poor localization ability. GUI agents also struggle, scoring\nbetween 10.6-68.0% despite high cost and latency. Therefore, we also contribute\nFieldFinder, a tool to assist LLMs in identifying where to place text on a\nform. With FieldFinder, all models achieve equal or better performance in all\nsix study conditions, with a maximum increase from 2% to 56%."}
{"id": "2506.13992", "pdf": "https://arxiv.org/pdf/2506.13992", "abs": "https://arxiv.org/abs/2506.13992", "authors": ["An Luo", "Xun Xian", "Jin Du", "Fangqiao Tian", "Ganghua Wang", "Ming Zhong", "Shengchun Zhao", "Xuan Bi", "Zirui Liu", "Jiawei Zhou", "Jayanth Srinivasa", "Ashish Kundu", "Charles Fleming", "Mingyi Hong", "Jie Ding"], "title": "AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ME", "62-07, 62-08, 68T05, 68T07, 68T01, 68T50", "I.2.0; I.2.6; I.2.7; I.5.1; I.5.4; H.2.8; G.3"], "comment": null, "summary": "Large language models (LLMs) have advanced the automation of data science\nworkflows. Yet it remains unclear whether they can critically leverage external\ndomain knowledge as human data scientists do in practice. To answer this\nquestion, we introduce AssistedDS (Assisted Data Science), a benchmark designed\nto systematically evaluate how LLMs handle domain knowledge in tabular\nprediction tasks. AssistedDS features both synthetic datasets with explicitly\nknown generative mechanisms and real-world Kaggle competitions, each\naccompanied by curated bundles of helpful and adversarial documents. These\ndocuments provide domain-specific insights into data cleaning, feature\nengineering, and model selection. We assess state-of-the-art LLMs on their\nability to discern and apply beneficial versus harmful domain knowledge,\nevaluating submission validity, information recall, and predictive performance.\nOur results demonstrate three key findings: (1) LLMs frequently exhibit an\nuncritical adoption of provided information, significantly impairing their\npredictive performance when adversarial content is introduced, (2) helpful\nguidance is often insufficient to counteract the negative influence of\nadversarial information, and (3) in Kaggle datasets, LLMs often make errors in\nhandling time-series data, applying consistent feature engineering across\ndifferent folds, and interpreting categorical variables correctly. These\nfindings highlight a substantial gap in current models' ability to critically\nevaluate and leverage expert knowledge, underscoring an essential research\ndirection for developing more robust, knowledge-aware automated data science\nsystems."}
{"id": "2506.14084", "pdf": "https://arxiv.org/pdf/2506.14084", "abs": "https://arxiv.org/abs/2506.14084", "authors": ["Taehee Jeong"], "title": "Lightweight Relevance Grader in RAG", "categories": ["cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) addresses limitations of large language\nmodels (LLMs) by leveraging a vector database to provide more accurate and\nup-to-date information. When a user submits a query, RAG executes a vector\nsearch to find relevant documents, which are then used to generate a response.\nHowever, ensuring the relevance of retrieved documents with a query would be a\nbig challenge. To address this, a secondary model, known as a relevant grader,\ncan be served to verify its relevance. To reduce computational requirements of\na relevant grader, a lightweight small language model is preferred. In this\nwork, we finetuned llama-3.2-1b as a relevant grader and achieved a significant\nincrease in precision from 0.1301 to 0.7750. Its precision is comparable to\nthat of llama-3.1-70b. Our code is available at\nhttps://github.com/taeheej/Lightweight-Relevance-Grader-in-RAG."}
{"id": "2506.13996", "pdf": "https://arxiv.org/pdf/2506.13996", "abs": "https://arxiv.org/abs/2506.13996", "authors": ["Stas Bekman", "Samyam Rajbhandari", "Michael Wyatt", "Jeff Rasley", "Tunji Ruwase", "Zhewei Yao", "Aurick Qiao", "Yuxiong He"], "title": "Arctic Long Sequence Training: Scalable And Efficient Training For Multi-Million Token Sequences", "categories": ["cs.LG"], "comment": "19 pages, 13 figures", "summary": "Long sequences are critical for applications like RAG, long document\nsummarization, multi-modality, etc., and modern LLMs, like Llama 4 Scout,\nsupport max sequence length of up to 10 million tokens. However, outside of\nenterprise labs, long sequence training is challenging for the AI community\nwith limited system support in the open-source space.\n  Out-of-box, even on a modern NVIDIA H100 80GB GPU cluster, training Llama 8B\nmodel with sequence over 32K runs out of memory on a basic Hugging Face (HF)\nmodel due to two reasons: i) LLM training workloads are not optimized to fully\nleverage a single GPU memory, ii) existing solutions for leveraging multiple\nGPU memory are not easily available to HF models, making long sequence training\ninaccessible.\n  We address this with Arctic Long Sequence Training (ALST). It offers a\ncombination of attention-agnostic single GPU and multi-GPU memory\noptimizations, that enables it to support out-of-box training of multi-million\nsequence length for a wide variety of HF models.\n  ALST supports training Meta's Llama 8B model with 500K sequence length on a\nsingle H100 GPU, 3.7M on a single 8xH100 GPU node, and over 15M on a 4 node\ncluster, an increase of over 400x compared to the 32K baseline for the latter.\nALST is fully compatible with HF models and open-sourced via Deepspeed\nhttps://www.deepspeed.ai/tutorials/ulysses-alst-sequence-pallellism/ and Arctic\nTraining\nhttps://github.com/snowflakedb/ArcticTraining/blob/main/projects/sequence-parallelism/README.md."}
{"id": "2506.14092", "pdf": "https://arxiv.org/pdf/2506.14092", "abs": "https://arxiv.org/abs/2506.14092", "authors": ["Haonan Yin", "Shai Vardi", "Vidyanand Choudhary"], "title": "Fragile Preferences: A Deep Dive Into Order Effects in Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly used in decision-support\nsystems across high-stakes domains such as hiring and university admissions,\nwhere decisions often involve selecting among competing alternatives. While\nprior work has noted positional order biases in LLM-driven comparisons, these\nbiases have not been systematically dissected or linked to underlying\npreference structures. We provide the first comprehensive investigation of\npositional biases across multiple LLM architectures and domains, uncovering\nstrong and consistent order effects, including a novel centrality bias not\npreviously documented in human or machine decision-making. We also find a\nquality-dependent shift: when options are high quality, models exhibit primacy\nbias, but favor latter options when option quality is low. We further identify\na previously undocumented bias favoring certain names over others. To\ndistinguish superficial tie-breaking from true distortions of judgment, we\nintroduce a framework that classifies pairwise preferences as robust, fragile,\nor indifferent. We show that order effects can lead models to select strictly\ninferior options, and that positional biases are typically stronger than gender\nbiases. These findings suggest that LLMs are not merely inheriting human-like\nbiases, but exhibit distinct failure modes not seen in human decision-making.\nWe propose targeted mitigation strategies, including a novel use of the\ntemperature parameter, to reduce order-driven distortions."}
{"id": "2506.14002", "pdf": "https://arxiv.org/pdf/2506.14002", "abs": "https://arxiv.org/abs/2506.14002", "authors": ["Siyu Chen", "Heejune Sheen", "Xuyuan Xiong", "Tianhao Wang", "Zhuoran Yang"], "title": "Taming Polysemanticity in LLMs: Provable Feature Recovery via Sparse Autoencoders", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ML", "I.2.6"], "comment": "136 pages, 21 figures", "summary": "We study the challenge of achieving theoretically grounded feature recovery\nusing Sparse Autoencoders (SAEs) for the interpretation of Large Language\nModels. Existing SAE training algorithms often lack rigorous mathematical\nguarantees and suffer from practical limitations such as hyperparameter\nsensitivity and instability. To address these issues, we first propose a novel\nstatistical framework for the feature recovery problem, which includes a new\nnotion of feature identifiability by modeling polysemantic features as sparse\nmixtures of underlying monosemantic concepts. Building on this framework, we\nintroduce a new SAE training algorithm based on ``bias adaptation'', a\ntechnique that adaptively adjusts neural network bias parameters to ensure\nappropriate activation sparsity. We theoretically \\highlight{prove that this\nalgorithm correctly recovers all monosemantic features} when input data is\nsampled from our proposed statistical model. Furthermore, we develop an\nimproved empirical variant, Group Bias Adaptation (GBA), and\n\\highlight{demonstrate its superior performance against benchmark methods when\napplied to LLMs with up to 1.5 billion parameters}. This work represents a\nfoundational step in demystifying SAE training by providing the first SAE\nalgorithm with theoretical recovery guarantees, thereby advancing the\ndevelopment of more transparent and trustworthy AI systems through enhanced\nmechanistic interpretability."}
{"id": "2506.14125", "pdf": "https://arxiv.org/pdf/2506.14125", "abs": "https://arxiv.org/abs/2506.14125", "authors": ["Libo Zhang", "Yang Chen", "Toru Takisaka", "Kaiqi Zhao", "Weidong Li", "Jiamou Liu"], "title": "Situational-Constrained Sequential Resources Allocation via Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Sequential Resource Allocation with situational constraints presents a\nsignificant challenge in real-world applications, where resource demands and\npriorities are context-dependent. This paper introduces a novel framework,\nSCRL, to address this problem. We formalize situational constraints as logic\nimplications and develop a new algorithm that dynamically penalizes constraint\nviolations. To handle situational constraints effectively, we propose a\nprobabilistic selection mechanism to overcome limitations of traditional\nconstraint reinforcement learning (CRL) approaches. We evaluate SCRL across two\nscenarios: medical resource allocation during a pandemic and pesticide\ndistribution in agriculture. Experiments demonstrate that SCRL outperforms\nexisting baselines in satisfying constraints while maintaining high resource\nefficiency, showcasing its potential for real-world, context-sensitive\ndecision-making tasks."}
{"id": "2506.14003", "pdf": "https://arxiv.org/pdf/2506.14003", "abs": "https://arxiv.org/abs/2506.14003", "authors": ["Yiwei Chen", "Soumyadeep Pal", "Yimeng Zhang", "Qing Qu", "Sijia Liu"], "title": "Unlearning Isn't Invisible: Detecting Unlearning Traces in LLMs from Model Outputs", "categories": ["cs.LG"], "comment": null, "summary": "Machine unlearning (MU) for large language models (LLMs), commonly referred\nto as LLM unlearning, seeks to remove specific undesirable data or knowledge\nfrom a trained model, while maintaining its performance on standard tasks.\nWhile unlearning plays a vital role in protecting data privacy, enforcing\ncopyright, and mitigating sociotechnical harms in LLMs, we identify a new\nvulnerability post-unlearning: unlearning trace detection. We discover that\nunlearning leaves behind persistent ''fingerprints'' in LLMs, detectable traces\nin both model behavior and internal representations. These traces can be\nidentified from output responses, even when prompted with forget-irrelevant\ninputs. Specifically, a simple supervised classifier can reliably determine\nwhether a model has undergone unlearning based solely on its textual outputs.\nFurther analysis shows that these traces are embedded in intermediate\nactivations and propagate nonlinearly to the final layer, forming\nlow-dimensional, learnable manifolds in activation space. Through extensive\nexperiments, we show that forget-relevant prompts enable over 90% accuracy in\ndetecting unlearning traces across all model sizes. Even with forget-irrelevant\ninputs, large LLMs maintain high detectability, demonstrating the broad\napplicability of unlearning trace detection. These findings reveal that\nunlearning leaves measurable signatures, introducing a new risk of\nreverse-engineering forgotten information when a model is identified as\nunlearned given an input query. Codes are available at [this\nURL](https://github.com/OPTML-Group/Unlearn-Trace)."}
{"id": "2506.14146", "pdf": "https://arxiv.org/pdf/2506.14146", "abs": "https://arxiv.org/abs/2506.14146", "authors": ["Kaiwen Tang", "Aitong Wu", "Yao Lu", "Guangda Sun"], "title": "Collaborative Editable Model", "categories": ["cs.AI"], "comment": null, "summary": "Vertical-domain large language models (LLMs) play a crucial role in\nspecialized scenarios such as finance, healthcare, and law; however, their\ntraining often relies on large-scale annotated data and substantial\ncomputational resources, impeding rapid development and continuous iteration.\nTo address these challenges, we introduce the Collaborative Editable Model\n(CoEM), which constructs a candidate knowledge pool from user-contributed\ndomain snippets, leverages interactive user-model dialogues combined with user\nratings and attribution analysis to pinpoint high-value knowledge fragments,\nand injects these fragments via in-context prompts for lightweight domain\nadaptation. With high-value knowledge, the LLM can generate more accurate and\ndomain-specific content. In a financial information scenario, we collect 15k\nfeedback from about 120 users and validate CoEM with user ratings to assess the\nquality of generated insights, demonstrating significant improvements in\ndomain-specific generation while avoiding the time and compute overhead of\ntraditional fine-tuning workflows."}
{"id": "2506.14020", "pdf": "https://arxiv.org/pdf/2506.14020", "abs": "https://arxiv.org/abs/2506.14020", "authors": ["Keyue Jiang", "Jiahao Cui", "Xiaowen Dong", "Laura Toni"], "title": "Bures-Wasserstein Flow Matching for Graph Generation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Graph generation has emerged as a critical task in fields ranging from\nmolecule design to drug discovery. Contemporary approaches, notably diffusion\nand flow-based models, have achieved solid graph generative performance through\nconstructing a probability path that interpolates between a reference\ndistribution and the data distribution. However, these methods typically model\nthe evolution of individual nodes and edges independently and use linear\ninterpolations to build the path assuming that the data lie in Euclidean space.\nWe show that this is suboptimal given the intrinsic non-Euclidean structure and\ninterconnected patterns of graphs, and it poses risks to the sampling\nconvergence. To build a better probability path, we model the joint evolution\nof the nodes and edges by representing graphs as connected systems\nparameterized by Markov random fields (MRF). We then leverage the optimal\ntransport displacement between MRF objects to design the probability path for\ngraph generation. Based on this, we introduce BWFlow, a flow-matching framework\nfor graph generation that respects the underlying geometry of graphs and\nprovides smooth velocities in the probability path. The novel framework can be\nadapted to both continuous and discrete flow-matching algorithms. Experimental\nevaluations in plain graph generation and 2D/3D molecule generation validate\nthe effectiveness of BWFlow in graph generation with competitive performance,\nstable training, and guaranteed sampling convergence."}
{"id": "2506.14212", "pdf": "https://arxiv.org/pdf/2506.14212", "abs": "https://arxiv.org/abs/2506.14212", "authors": ["Lance Ying", "Daniel Xu", "Alicia Zhang", "Katherine M. Collins", "Max H. Siegel", "Joshua B. Tenenbaum"], "title": "What's in the Box? Reasoning about Unseen Objects from Multimodal Cues", "categories": ["cs.AI"], "comment": "Paper published at CogSci 2025", "summary": "People regularly make inferences about objects in the world that they cannot\nsee by flexibly integrating information from multiple sources: auditory and\nvisual cues, language, and our prior beliefs and knowledge about the scene. How\nare we able to so flexibly integrate many sources of information to make sense\nof the world around us, even if we have no direct knowledge? In this work, we\npropose a neurosymbolic model that uses neural networks to parse open-ended\nmultimodal inputs and then applies a Bayesian model to integrate different\nsources of information to evaluate different hypotheses. We evaluate our model\nwith a novel object guessing game called ``What's in the Box?'' where humans\nand models watch a video clip of an experimenter shaking boxes and then try to\nguess the objects inside the boxes. Through a human experiment, we show that\nour model correlates strongly with human judgments, whereas unimodal ablated\nmodels and large multimodal neural model baselines show poor correlation."}
{"id": "2506.14036", "pdf": "https://arxiv.org/pdf/2506.14036", "abs": "https://arxiv.org/abs/2506.14036", "authors": ["Tatthapong Srikitrungruang", "Sina Aghaee Dabaghan Fard", "Matthew Lemon", "Jaesung Lee", "Yuxiao Zhou"], "title": "Robust Physics-Informed Neural Network Approach for Estimating Heterogeneous Elastic Properties from Noisy Displacement Data", "categories": ["cs.LG"], "comment": null, "summary": "Accurately estimating spatially heterogeneous elasticity parameters,\nparticularly Young's modulus and Poisson's ratio, from noisy displacement\nmeasurements remains significantly challenging in inverse elasticity problems.\nExisting inverse estimation techniques are often limited by instability,\npronounced sensitivity to measurement noise, and difficulty in recovering\nabsolute-scale Young's modulus. This work presents a novel Inverse Elasticity\nPhysics-Informed Neural Network (IE-PINN) specifically designed to robustly\nreconstruct heterogeneous distributions of elasticity parameters from noisy\ndisplacement data based on linear elasticity physics. IE-PINN integrates three\ndistinct neural network architectures dedicated to separately modeling\ndisplacement fields, strain fields, and elasticity distributions, thereby\nsignificantly enhancing stability and accuracy against measurement noise.\nAdditionally, a two-phase estimation strategy is introduced: the first phase\nrecovers relative spatial distributions of Young's modulus and Poisson's ratio,\nand the second phase calibrates the absolute scale of Young's modulus using\nimposed loading boundary conditions. Additional methodological innovations,\nincluding positional encoding, sine activation functions, and a sequential\npretraining protocol, further enhance the model's performance and robustness.\nExtensive numerical experiments demonstrate that IE-PINN effectively overcomes\ncritical limitations encountered by existing methods, delivering accurate\nabsolute-scale elasticity estimations even under severe noise conditions. This\nadvancement holds substantial potential for clinical imaging diagnostics and\nmechanical characterization, where measurements typically encounter substantial\nnoise."}
{"id": "2506.14224", "pdf": "https://arxiv.org/pdf/2506.14224", "abs": "https://arxiv.org/abs/2506.14224", "authors": ["Xinyang Li", "Siqi Liu", "Bochao Zou", "Jiansheng Chen", "Huimin Ma"], "title": "From Black Boxes to Transparent Minds: Evaluating and Enhancing the Theory of Mind in Multimodal Large Language Models", "categories": ["cs.AI"], "comment": "24 pages, 22 figures, accepted at ICML 2025, project page: see\n  https://annaisavailable.github.io/GridToM/", "summary": "As large language models evolve, there is growing anticipation that they will\nemulate human-like Theory of Mind (ToM) to assist with routine tasks. However,\nexisting methods for evaluating machine ToM focus primarily on unimodal models\nand largely treat these models as black boxes, lacking an interpretative\nexploration of their internal mechanisms. In response, this study adopts an\napproach based on internal mechanisms to provide an interpretability-driven\nassessment of ToM in multimodal large language models (MLLMs). Specifically, we\nfirst construct a multimodal ToM test dataset, GridToM, which incorporates\ndiverse belief testing tasks and perceptual information from multiple\nperspectives. Next, our analysis shows that attention heads in multimodal large\nmodels can distinguish cognitive information across perspectives, providing\nevidence of ToM capabilities. Furthermore, we present a lightweight,\ntraining-free approach that significantly enhances the model's exhibited ToM by\nadjusting in the direction of the attention head."}
{"id": "2506.14038", "pdf": "https://arxiv.org/pdf/2506.14038", "abs": "https://arxiv.org/abs/2506.14038", "authors": ["Nabil Omi", "Siddhartha Sen", "Ali Farhadi"], "title": "Load Balancing Mixture of Experts with Similarity Preserving Routers", "categories": ["cs.LG"], "comment": null, "summary": "Sparse Mixture of Experts (MoE) models offer a scalable and efficient\narchitecture for training large neural networks by activating only a subset of\nparameters (\"experts\") for each input. A learned router computes a distribution\nover these experts, and assigns input tokens to a small subset. However,\nwithout auxiliary balancing mechanisms, routers often converge to using only a\nfew experts, severely limiting model capacity and degrading performance. Most\ncurrent load balancing mechanisms encourage a distribution over experts that\nresembles a roughly uniform distribution of experts per token. During training,\nthis can result in inconsistent routing behavior, resulting in the model\nspending its capacity to learn redundant knowledge. We address this by\nintroducing a novel load balancing loss that preserves token-wise relational\nstructure, encouraging consistent expert choices for similar inputs during\ntraining. Our experimental results show that applying our loss to the router\nresults in 36% faster convergence and lower redundancy compared to a popular\nload balancing loss."}
{"id": "2506.14231", "pdf": "https://arxiv.org/pdf/2506.14231", "abs": "https://arxiv.org/abs/2506.14231", "authors": ["Omri Haller", "Yair Meidan", "Dudu Mimran", "Yuval Elovici", "Asaf Shabtai"], "title": "ImpReSS: Implicit Recommender System for Support Conversations", "categories": ["cs.AI", "cs.IR"], "comment": null, "summary": "Following recent advancements in large language models (LLMs), LLM-based\nchatbots have transformed customer support by automating interactions and\nproviding consistent, scalable service. While LLM-based conversational\nrecommender systems (CRSs) have attracted attention for their ability to\nenhance the quality of recommendations, limited research has addressed the\nimplicit integration of recommendations within customer support interactions.\nIn this work, we introduce ImpReSS, an implicit recommender system designed for\ncustomer support conversations. ImpReSS operates alongside existing support\nchatbots, where users report issues and chatbots provide solutions. Based on a\ncustomer support conversation, ImpReSS identifies opportunities to recommend\nrelevant solution product categories (SPCs) that help resolve the issue or\nprevent its recurrence -- thereby also supporting business growth. Unlike\ntraditional CRSs, ImpReSS functions entirely implicitly and does not rely on\nany assumption of a user's purchasing intent. Our empirical evaluation of\nImpReSS's ability to recommend relevant SPCs that can help address issues\nraised in support conversations shows promising results, including an MRR@1\n(and recall@3) of 0.72 (0.89) for general problem solving, 0.82 (0.83) for\ninformation security support, and 0.85 (0.67) for cybersecurity\ntroubleshooting. To support future research, our data and code will be shared\nupon request."}
{"id": "2506.14054", "pdf": "https://arxiv.org/pdf/2506.14054", "abs": "https://arxiv.org/abs/2506.14054", "authors": ["Joshua Fan", "Haodi Xu", "Feng Tao", "Md Nasim", "Marc Grimson", "Yiqi Luo", "Carla P. Gomes"], "title": "Scientifically-Interpretable Reasoning Network (ScIReN): Uncovering the Black-Box of Nature", "categories": ["cs.LG", "cs.AI"], "comment": "28 pages, 9 figures, submitted to NeurIPS 2025", "summary": "Neural networks are a powerful tool for learning patterns from data. However,\nthey do not respect known scientific laws, nor can they reveal novel scientific\ninsights due to their black-box nature. In contrast, scientific reasoning\ndistills biological or physical principles from observations and controlled\nexperiments, and quantitatively interprets them with process-based models made\nof mathematical equations. Yet, process-based models rely on numerous free\nparameters that must be set in an ad-hoc manner, and thus often fit\nobservations poorly in cross-scale predictions. While prior work has embedded\nprocess-based models in conventional neural networks, discovering interpretable\nrelationships between parameters in process-based models and input features is\nstill a grand challenge for scientific discovery. We thus propose\nScientifically-Interpretable Reasoning Network (ScIReN), a fully-transparent\nframework that combines interpretable neural and process-based reasoning. An\ninterpretable encoder predicts scientifically-meaningful latent parameters,\nwhich are then passed through a differentiable process-based decoder to predict\nlabeled output variables. ScIReN also uses a novel hard-sigmoid constraint\nlayer to restrict latent parameters to meaningful ranges defined by scientific\nprior knowledge, further enhancing its interpretability. While the embedded\nprocess-based model enforces established scientific knowledge, the encoder\nreveals new scientific mechanisms and relationships hidden in conventional\nblack-box models. We apply ScIReN on two tasks: simulating the flow of organic\ncarbon through soils, and modeling ecosystem respiration from plants. In both\ntasks, ScIReN outperforms black-box networks in predictive accuracy while\nproviding substantial scientific interpretability -- it can infer latent\nscientific mechanisms and their relationships with input features."}
{"id": "2506.14239", "pdf": "https://arxiv.org/pdf/2506.14239", "abs": "https://arxiv.org/abs/2506.14239", "authors": ["Louis Vervoort", "Vitaly Nikolaev"], "title": "Causes in neuron diagrams, and testing causal reasoning in Large Language Models. A glimpse of the future of philosophy?", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted by Journal for General Philosophy of Science", "summary": "We propose a test for abstract causal reasoning in AI, based on scholarship\nin the philosophy of causation, in particular on the neuron diagrams\npopularized by D. Lewis. We illustrate the test on advanced Large Language\nModels (ChatGPT, DeepSeek and Gemini). Remarkably, these chatbots are already\ncapable of correctly identifying causes in cases that are hotly debated in the\nliterature. In order to assess the results of these LLMs and future dedicated\nAI, we propose a definition of cause in neuron diagrams with a wider validity\nthan published hitherto, which challenges the widespread view that such a\ndefinition is elusive. We submit that these results are an illustration of how\nfuture philosophical research might evolve: as an interplay between human and\nartificial expertise."}
{"id": "2506.14067", "pdf": "https://arxiv.org/pdf/2506.14067", "abs": "https://arxiv.org/abs/2506.14067", "authors": ["Minjae Lee", "Yoonjae Jung", "Sangdon Park"], "title": "A Regret Perspective on Online Selective Generation", "categories": ["cs.LG"], "comment": "10 pages", "summary": "Large language generative models increasingly interact with humans, while\ntheir falsified responses raise concerns. To address this hallucination effect,\nselectively abstaining from answering, called selective generation, provides an\neffective way for generators to control the hallucination when it is unsure of\ntheir answers. However, as selective generators are interacting under\nnon-stochastic environments and having partial feedback from users on selective\ngeneration (e.g., thumbs up or down on the selected answer), learning methods\nfor selective generation under such practical setups are crucial but currently\nmissing. To address these limitations, we propose an online learning algorithm\nfor selective generation under partial feedback. In particular, as learning\nunder partial feedback is well-studied by multi-armed bandit problems, we\nreduce selective generation to bandits and provide a novel conversion lemma\nfrom bandits back to selective generation to leverage any known bandit\nalgorithms and theoretical properties. This mainly connects regret guarantees\nof bandits to false discovery rate (FDR) guarantees of selective generation for\ncontrolling hallucination. However, naively exploiting known bandit algorithms\nand their regret bounds suffers from slow convergence speed in practice due the\nnature of partial feedback. To overcome this, we exploit a unique structure of\narms in selective generation for feedback unlocking, i.e., unlocking unknown\nfeedback from observed feedback. We theoretically and empirically evaluate the\nefficacy of the proposed online selective generation algorithm under partial\nfeedback over diverse data environment setups, resulting in controlling a\ndesired FDR, while maintaining reasonable selection efficiency, i.e., the ratio\nof non-abstaining answers, compared to baselines."}
{"id": "2506.14245", "pdf": "https://arxiv.org/pdf/2506.14245", "abs": "https://arxiv.org/abs/2506.14245", "authors": ["Xumeng Wen", "Zihan Liu", "Shun Zheng", "Zhijian Xu", "Shengyu Ye", "Zhirong Wu", "Xiao Liang", "Yang Wang", "Junjie Li", "Ziming Miao", "Jiang Bian", "Mao Yang"], "title": "Reinforcement Learning with Verifiable Rewards Implicitly Incentivizes Correct Reasoning in Base LLMs", "categories": ["cs.AI", "cs.CL"], "comment": "Preprint", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a\npromising paradigm for advancing the reasoning capabilities of Large Language\nModels (LLMs). However, a critical paradox clouds its efficacy: RLVR-tuned\nmodels often underperform their base models on the $Pass@K$ metric for\nsolution-finding, leading to the hypothesis that RLVR merely re-weights\nexisting reasoning paths at the cost of reasoning diversity. In this work, we\nresolve this contradiction by identifying the source of the problem: the\n$Pass@K$ metric itself is a flawed measure of reasoning, as it credits correct\nfinal answers that probably arise from inaccurate or incomplete chains of\nthought (CoTs). To address this, we introduce a more precise evaluation metric,\n$CoT$-$Pass@K$, which mandates that both the reasoning path and the final\nanswer be correct. We provide a new theoretical foundation that formalizes how\nRLVR, unlike traditional RL, is uniquely structured to incentivize logical\nintegrity. Our empirical results are supportive: using $CoT$-$Pass@K$, we\nobserve that RLVR can incentivize the generalization of correct reasoning for\nall values of $K$. Furthermore, by analyzing the training dynamics, we find\nthat this enhanced reasoning capability emerges early in the training process\nand smoothly generalizes. Our work provides a clear perspective on the role of\nRLVR, offers a more reliable method for its evaluation, and confirms its\npotential to genuinely advance machine reasoning."}
{"id": "2506.14074", "pdf": "https://arxiv.org/pdf/2506.14074", "abs": "https://arxiv.org/abs/2506.14074", "authors": ["Nathaniel Pinckney", "Chenhui Deng", "Chia-Tung Ho", "Yun-Da Tsai", "Mingjie Liu", "Wenfei Zhou", "Brucek Khailany", "Haoxing Ren"], "title": "Comprehensive Verilog Design Problems: A Next-Generation Benchmark Dataset for Evaluating Large Language Models and Agents on RTL Design and Verification", "categories": ["cs.LG", "cs.AR"], "comment": "16 pages with appendix", "summary": "We present the Comprehensive Verilog Design Problems (CVDP) benchmark, a new\ndataset and infrastructure to advance LLM and agent research in hardware design\nand verification. CVDP includes 783 problems across 13 task categories,\ncovering RTL generation, verification, debugging, specification alignment, and\ntechnical Q&A authored by experienced hardware engineers. Problems are offered\nin both non-agentic and agentic formats. The benchmark introduces more\nrealistic and challenging contexts than prior work, with state-of-the-art\nmodels achieving no more than 34% pass@1 on code generation. Agentic\ntasks$\\unicode{x2013}$especially those involving RTL reuse and\nverification$\\unicode{x2013}$are particularly difficult. Evaluation uses\nopen-source tools and model scoring infrastructure, with comprehension tasks\nassessed via BLEU and LLM-based judging. CVDP reveals substantial gaps in\ncurrent model capabilities, underscoring the need for continued research toward\nrobust, real-world hardware design automation."}
{"id": "2506.14246", "pdf": "https://arxiv.org/pdf/2506.14246", "abs": "https://arxiv.org/abs/2506.14246", "authors": ["Lingfeng Li", "Yunlong Lu", "Yongyi Wang", "Qifan Zheng", "Wenxin Li"], "title": "Mxplainer: Explain and Learn Insights by Imitating Mahjong Agents", "categories": ["cs.AI"], "comment": null, "summary": "People need to internalize the skills of AI agents to improve their own\ncapabilities. Our paper focuses on Mahjong, a multiplayer game involving\nimperfect information and requiring effective long-term decision-making amidst\nrandomness and hidden information. Through the efforts of AI researchers,\nseveral impressive Mahjong AI agents have already achieved performance levels\ncomparable to those of professional human players; however, these agents are\noften treated as black boxes from which few insights can be gleaned. This paper\nintroduces Mxplainer, a parameterized search algorithm that can be converted\ninto an equivalent neural network to learn the parameters of black-box agents.\nExperiments conducted on AI and human player data demonstrate that the learned\nparameters provide human-understandable insights into these agents'\ncharacteristics and play styles. In addition to analyzing the learned\nparameters, we also showcase how our search-based framework can locally explain\nthe decision-making processes of black-box agents for most Mahjong game states."}
{"id": "2506.14087", "pdf": "https://arxiv.org/pdf/2506.14087", "abs": "https://arxiv.org/abs/2506.14087", "authors": ["Zhongzheng Qiao", "Chenghao Liu", "Yiming Zhang", "Ming Jin", "Quang Pham", "Qingsong Wen", "P. N. Suganthan", "Xudong Jiang", "Savitha Ramasamy"], "title": "Multi-Scale Finetuning for Encoder-based Time Series Foundation Models", "categories": ["cs.LG"], "comment": null, "summary": "Time series foundation models (TSFMs) demonstrate impressive zero-shot\nperformance for time series forecasting. However, an important yet\nunderexplored challenge is how to effectively finetune TSFMs on specific\ndownstream tasks. While naive finetuning can yield performance gains, we argue\nthat it falls short of fully leveraging TSFMs' capabilities, often resulting in\noverfitting and suboptimal performance. Given the diverse temporal patterns\nacross sampling scales and the inherent multi-scale forecasting capabilities of\nTSFMs, we adopt a causal perspective to analyze finetuning process, through\nwhich we highlight the critical importance of explicitly modeling multiple\nscales and reveal the shortcomings of naive approaches. Focusing on\n\\textit{encoder-based} TSFMs, we propose \\textbf{M}ulti\\textbf{\\textsc{s}}cale\n\\textbf{\\textsc{f}}ine\\textbf{\\textsc{t}}uning (\\textbf{MSFT}), a simple yet\ngeneral framework that explicitly integrates multi-scale modeling into the\nfinetuning process. Experimental results on three different backbones (\\moirai,\n\\moment\\ and \\units) demonstrate that TSFMs finetuned with MSFT not only\noutperform naive and typical parameter efficient finetuning methods but also\nsurpass state-of-the-art deep learning methods."}
{"id": "2506.14276", "pdf": "https://arxiv.org/pdf/2506.14276", "abs": "https://arxiv.org/abs/2506.14276", "authors": ["Jack Cole", "Mohamed Osman"], "title": "Don't throw the baby out with the bathwater: How and why deep learning for ARC", "categories": ["cs.AI", "cs.LG"], "comment": "13 pages, 6 figures", "summary": "The Abstraction and Reasoning Corpus (ARC-AGI) presents a formidable\nchallenge for AI systems. Despite the typically low performance on ARC, the\ndeep learning paradigm remains the most effective known strategy for generating\nskillful (state-of-the-art) neural networks (NN) across varied modalities and\ntasks in vision, language etc. The deep learning paradigm has proven to be able\nto train these skillful neural networks and learn the abstractions needed in\nthese diverse domains. Our work doubles down on that and continues to leverage\nthis paradigm by incorporating on-the-fly NN training at test time. We\ndemonstrate that fully committing to deep learning's capacity to acquire novel\nabstractions yields state-of-the-art performance on ARC. Specifically, we treat\nboth the neural network and the optimizer (rather than just a pre-trained\nnetwork) as integral components of the inference process, fostering\ngeneralization to unseen tasks. Concretely, we propose a methodology for\ntraining on ARC, starting from pretrained LLMs, and enhancing their ARC\nreasoning. We also propose Test-Time Fine-Tuning (TTFT) and the Augment\nInference Reverse-Augmentation and Vote (AIRV) as effective test-time\ntechniques. We are the first to propose and show deep learning can be used\neffectively for ARC, showing boosts of up to 260% in accuracy with AIRV and a\nfurther 300% boost with TTFT. An early version of this approach secured first\nplace in the 2023 ARCathon competition, while the final version achieved the\ncurrent best score on the ARC private test-set (58%). Our findings highlight\nthe key ingredients of a robust reasoning system in unfamiliar domains,\nunderscoring the central mechanisms that improve broad perceptual reasoning."}
{"id": "2506.14095", "pdf": "https://arxiv.org/pdf/2506.14095", "abs": "https://arxiv.org/abs/2506.14095", "authors": ["Parikshit Ram", "Kenneth L. Clarkson", "Tim Klinger", "Shashanka Ubaru", "Alexander G. Gray"], "title": "Transformers Learn Faster with Semantic Focus", "categories": ["cs.LG"], "comment": null, "summary": "Various forms of sparse attention have been explored to mitigate the\nquadratic computational and memory cost of the attention mechanism in\ntransformers. We study sparse transformers not through a lens of efficiency but\nrather in terms of learnability and generalization. Empirically studying a\nrange of attention mechanisms, we find that input-dependent sparse attention\nmodels appear to converge faster and generalize better than standard attention\nmodels, while input-agnostic sparse attention models show no such benefits -- a\nphenomenon that is robust across architectural and optimization hyperparameter\nchoices. This can be interpreted as demonstrating that concentrating a model's\n\"semantic focus\" with respect to the tokens currently being considered (in the\nform of input-dependent sparse attention) accelerates learning. We develop a\ntheoretical characterization of the conditions that explain this behavior. We\nestablish a connection between the stability of the standard softmax and the\nloss function's Lipschitz properties, then show how sparsity affects the\nstability of the softmax and the subsequent convergence and generalization\nguarantees resulting from the attention mechanism. This allows us to\ntheoretically establish that input-agnostic sparse attention does not provide\nany benefits. We also characterize conditions when semantic focus\n(input-dependent sparse attention) can provide improved guarantees, and we\nvalidate that these conditions are in fact met in our empirical evaluations."}
{"id": "2506.14299", "pdf": "https://arxiv.org/pdf/2506.14299", "abs": "https://arxiv.org/abs/2506.14299", "authors": ["Fanzhi Zeng", "Siqi Wang", "Chuzhao Zhu", "Li Li"], "title": "ADRD: LLM-Driven Autonomous Driving Based on Rule-based Decision Systems", "categories": ["cs.AI"], "comment": null, "summary": "How to construct an interpretable autonomous driving decision-making system\nhas become a focal point in academic research. In this study, we propose a\nnovel approach that leverages large language models (LLMs) to generate\nexecutable, rule-based decision systems to address this challenge.\nSpecifically, harnessing the strong reasoning and programming capabilities of\nLLMs, we introduce the ADRD(LLM-Driven Autonomous Driving Based on Rule-based\nDecision Systems) framework, which integrates three core modules: the\nInformation Module, the Agents Module, and the Testing Module. The framework\noperates by first aggregating contextual driving scenario information through\nthe Information Module, then utilizing the Agents Module to generate rule-based\ndriving tactics. These tactics are iteratively refined through continuous\ninteraction with the Testing Module. Extensive experimental evaluations\ndemonstrate that ADRD exhibits superior performance in autonomous driving\ndecision tasks. Compared to traditional reinforcement learning approaches and\nthe most advanced LLM-based methods, ADRD shows significant advantages in terms\nof interpretability, response speed, and driving performance. These results\nhighlight the framework's ability to achieve comprehensive and accurate\nunderstanding of complex driving scenarios, and underscore the promising future\nof transparent, rule-based decision systems that are easily modifiable and\nbroadly applicable. To the best of our knowledge, this is the first work that\nintegrates large language models with rule-based systems for autonomous driving\ndecision-making, and our findings validate its potential for real-world\ndeployment."}
{"id": "2506.14098", "pdf": "https://arxiv.org/pdf/2506.14098", "abs": "https://arxiv.org/abs/2506.14098", "authors": ["Ziyuan Tang", "Jie Chen"], "title": "Toward a Graph Foundation Model: Pre-Training Transformers With Random Walks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "A foundation model like GPT elicits many emergent abilities, owing to the\npre-training with broad inclusion of data and the use of the powerful\nTransformer architecture. While foundation models in natural languages are\nprevalent, can we build similar models for graphs? This paper describes an\napproach toward a graph foundation model that is pre-trained with diverse graph\ndatasets by adapting the Transformer backbone. A central challenge toward this\nend is how a sequence model encodes graphs of varying sizes and from different\ndomains. We propose representing a node as multiple random walks, such that the\nTransformer can extract node representations from sequences, which in turn form\nedge and graph representations. We develop a novel context prediction loss for\nthese random walks and theoretically analyze their expressive power in\ndistinguishing neighborhoods and graphs. We also demonstrate the pre-training\nof our model and its adaptation to downstream tasks, showcasing its potential\nas a foundation for processing and reasoning with graph-structured data."}
{"id": "2506.14336", "pdf": "https://arxiv.org/pdf/2506.14336", "abs": "https://arxiv.org/abs/2506.14336", "authors": ["Jia'ang Wan", "Feng Shen", "Fujuan Li", "Yanjin Sun", "Yan Li", "Shiwen Zhang"], "title": "AviationLLM: An LLM-based Knowledge System for Aviation Training", "categories": ["cs.AI"], "comment": null, "summary": "Aviation training is a core link in ensuring flight safety, improving\nindustry efficiency and promoting sustainable development. It not only involves\nflight simulation but also requires the learning of a great deal of\nprofessional aviation theory knowledge. In the existing training system, the\nknowledge is mainly imparted by the the instructors. However, the number of\ninstructors is limited and the professional answers obtained from the Internet\nare not accurate enough, resulting in low training efficiency. To address this,\nwe introduced LLM, but the basic pre-trained model cannot provide accurate\nanswers to professional fields, so we fine-tuned it. Traditional Supervised\nFine-Tuning (SFT) risk generating superficially plausible but factually\nincorrect responses due to insufficient data coverage. To address this, we\nemploy Direct Preference Optimization(DPO). This paper proposes\nRetrieval-Augmented LLM Alignment via Direct Preference Optimization(RALA-DPO).\nWe select open source pre-trained LLM Qwen and adapt it to aviation theory\ntraining through DPO-based domain alignment. Simultaneously, to mitigate\nhallucinations caused by training data biases, knowledge obsolescence, or\ndomain knowledge gaps, we implement Retrieval-Augmented Generation(RAG)\ntechnology that combines generative and retrieval models. RALA-DPO effectively\nretrieves relevant information from external knowledge bases and delivers\nprecise and high-quality responses through the generative model. Experimental\nresults demonstrate that RALA-DPO can improve accuracy in response to\nprofessional aviation knowledge. With integrated RAG mechanisms, this system\ncan further improve the accuracy of answers and achieve zero-cost knowledge\nupdates simultaneously."}
{"id": "2506.14113", "pdf": "https://arxiv.org/pdf/2506.14113", "abs": "https://arxiv.org/abs/2506.14113", "authors": ["Yitian Zhang", "Liheng Ma", "Antonios Valkanas", "Boris N. Oreshkin", "Mark Coates"], "title": "SKOLR: Structured Koopman Operator Linear RNN for Time-Series Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Koopman operator theory provides a framework for nonlinear dynamical system\nanalysis and time-series forecasting by mapping dynamics to a space of\nreal-valued measurement functions, enabling a linear operator representation.\nDespite the advantage of linearity, the operator is generally\ninfinite-dimensional. Therefore, the objective is to learn measurement\nfunctions that yield a tractable finite-dimensional Koopman operator\napproximation. In this work, we establish a connection between Koopman operator\napproximation and linear Recurrent Neural Networks (RNNs), which have recently\ndemonstrated remarkable success in sequence modeling. We show that by\nconsidering an extended state consisting of lagged observations, we can\nestablish an equivalence between a structured Koopman operator and linear RNN\nupdates. Building on this connection, we present SKOLR, which integrates a\nlearnable spectral decomposition of the input signal with a multilayer\nperceptron (MLP) as the measurement functions and implements a structured\nKoopman operator via a highly parallel linear RNN stack. Numerical experiments\non various forecasting benchmarks and dynamical systems show that this\nstreamlined, Koopman-theory-based design delivers exceptional performance."}
{"id": "2506.14387", "pdf": "https://arxiv.org/pdf/2506.14387", "abs": "https://arxiv.org/abs/2506.14387", "authors": ["William F. Shen", "Xinchi Qiu", "Nicola Cancedda", "Nicholas D. Lane"], "title": "Don't Make It Up: Preserving Ignorance Awareness in LLM Fine-Tuning", "categories": ["cs.AI"], "comment": null, "summary": "Existing work on mitigating catastrophic forgetting in large language model\n(LLM) fine-tuning has primarily focused on preserving specific data or tasks,\nwhile critically overlooking the degradation of essential capabilities\ninstilled through safety alignment, particularly the model's ability to\nfaithfully express ignorance. In this work, we show that this capability is\nsignificantly degraded during conventional fine-tuning, leading to undesired\nbehaviors such as hallucinations. To address this novel but highly practical\nproblem, we propose SEAT, a simple and effective fine-tuning approach that\npreserves both fine-tuning performance and the model's inherent ability to\nacknowledge its ignorance. SEAT integrates two key components: (1) sparse\ntraining that constrains activation drift, and (2) a novel entity perturbation\nmethod with KL-divergence regularization, designed to counter knowledge\nentanglement. Experimental results demonstrate that SEAT significantly\noutperforms baselines in preserving ignorance awareness while retaining\nfine-tuning performance, offering a more robust solution for LLM fine-tuning."}
{"id": "2506.14114", "pdf": "https://arxiv.org/pdf/2506.14114", "abs": "https://arxiv.org/abs/2506.14114", "authors": ["Khushnood Abbas", "Ruizhe Hou", "Zhou Wengang", "Dong Shi", "Niu Ling", "Satyaki Nan", "Alireza Abbasi"], "title": "Evaluating Loss Functions for Graph Neural Networks: Towards Pretraining and Generalization", "categories": ["cs.LG"], "comment": "ACM single column 633 pages", "summary": "Graph Neural Networks (GNNs) became useful for learning on non-Euclidean\ndata. However, their best performance depends on choosing the right model\narchitecture and the training objective, also called the loss function.\nResearchers have studied these parts separately, but a large-scale evaluation\nhas not looked at how GNN models and many loss functions work together across\ndifferent tasks. To fix this, we ran a thorough study - it included seven\nwell-known GNN architectures. We also used a large group of 30 single plus\nmixed loss functions. The study looked at both inductive and transductive\nsettings. Our evaluation spanned three distinct real-world datasets, assessing\nperformance in both inductive and transductive settings using 21 comprehensive\nevaluation metrics. From these extensive results (detailed in supplementary\ninformation 1 \\& 2), we meticulously analyzed the top ten model-loss\ncombinations for each metric based on their average rank. Our findings reveal\nthat, especially for the inductive case: 1) Hybrid loss functions generally\nyield superior and more robust performance compared to single loss functions,\nindicating the benefit of multi-objective optimization. 2) The GIN architecture\nalways showed the highest-level average performance, especially with\nCross-Entropy loss. 3) Although some combinations had overall lower average\nranks, models such as GAT, particularly with certain hybrid losses,\ndemonstrated incredible specialized strengths, maximizing the most top-1\nresults among the individual metrics, emphasizing subtle strengths for\nparticular task demands. 4) On the other hand, the MPNN architecture typically\nlagged behind the scenarios it was tested against."}
{"id": "2506.14470", "pdf": "https://arxiv.org/pdf/2506.14470", "abs": "https://arxiv.org/abs/2506.14470", "authors": ["Zixian Zhang", "Takfarinas Saber"], "title": "AST-Enhanced or AST-Overloaded? The Surprising Impact of Hybrid Graph Representations on Code Clone Detection", "categories": ["cs.AI", "cs.SE"], "comment": null, "summary": "As one of the most detrimental code smells, code clones significantly\nincrease software maintenance costs and heighten vulnerability risks, making\ntheir detection a critical challenge in software engineering. Abstract Syntax\nTrees (ASTs) dominate deep learning-based code clone detection due to their\nprecise syntactic structure representation, but they inherently lack semantic\ndepth. Recent studies address this by enriching AST-based representations with\nsemantic graphs, such as Control Flow Graphs (CFGs) and Data Flow Graphs\n(DFGs). However, the effectiveness of various enriched AST-based\nrepresentations and their compatibility with different graph-based machine\nlearning techniques remains an open question, warranting further investigation\nto unlock their full potential in addressing the complexities of code clone\ndetection. In this paper, we present a comprehensive empirical study to\nrigorously evaluate the effectiveness of AST-based hybrid graph representations\nin Graph Neural Network (GNN)-based code clone detection. We systematically\ncompare various hybrid representations ((CFG, DFG, Flow-Augmented ASTs\n(FA-AST)) across multiple GNN architectures. Our experiments reveal that hybrid\nrepresentations impact GNNs differently: while AST+CFG+DFG consistently\nenhances accuracy for convolution- and attention-based models (Graph\nConvolutional Networks (GCN), Graph Attention Networks (GAT)), FA-AST\nfrequently introduces structural complexity that harms performance. Notably,\nGMN outperforms others even with standard AST representations, highlighting its\nsuperior cross-code similarity detection and reducing the need for enriched\nstructures."}
{"id": "2506.14122", "pdf": "https://arxiv.org/pdf/2506.14122", "abs": "https://arxiv.org/abs/2506.14122", "authors": ["Tianming Zhang", "Renbo Zhang", "Zhengyi Yang", "Yunjun Gao", "Bin Cao", "Jing Fan"], "title": "CLGNN: A Contrastive Learning-based GNN Model for Betweenness Centrality Prediction on Temporal Graphs", "categories": ["cs.LG", "cs.AI", "I.2.6; G.2.2; I.5.1"], "comment": null, "summary": "Temporal Betweenness Centrality (TBC) measures how often a node appears on\noptimal temporal paths, reflecting its importance in temporal networks.\nHowever, exact computation is highly expensive, and real-world TBC\ndistributions are extremely imbalanced. The severe imbalance leads\nlearning-based models to overfit to zero-centrality nodes, resulting in\ninaccurate TBC predictions and failure to identify truly central nodes.\nExisting graph neural network (GNN) methods either fail to handle such\nimbalance or ignore temporal dependencies altogether. To address these issues,\nwe propose a scalable and inductive contrastive learning-based GNN (CLGNN) for\naccurate and efficient TBC prediction. CLGNN builds an instance graph to\npreserve path validity and temporal order, then encodes structural and temporal\nfeatures using dual aggregation, i.e., mean and edge-to-node multi-head\nattention mechanisms, enhanced by temporal path count and time encodings. A\nstability-based clustering-guided contrastive module (KContrastNet) is\nintroduced to separate high-, median-, and low-centrality nodes in\nrepresentation space, mitigating class imbalance, while a regression module\n(ValueNet) estimates TBC values. CLGNN also supports multiple optimal path\ndefinitions to accommodate diverse temporal semantics. Extensive experiments\ndemonstrate the effectiveness and efficiency of CLGNN across diverse\nbenchmarks. CLGNN achieves up to a 663.7~$\\times$ speedup compared to\nstate-of-the-art exact TBC computation methods. It outperforms leading static\nGNN baselines with up to 31.4~$\\times$ lower MAE and 16.7~$\\times$ higher\nSpearman correlation, and surpasses state-of-the-art temporal GNNs with up to\n5.7~$\\times$ lower MAE and 3.9~$\\times$ higher Spearman correlation."}
{"id": "2506.14477", "pdf": "https://arxiv.org/pdf/2506.14477", "abs": "https://arxiv.org/abs/2506.14477", "authors": ["Jingqi Yang", "Zhilong Song", "Jiawei Chen", "Mingli Song", "Sheng Zhou", "linjun sun", "Xiaogang Ouyang", "Chun Chen", "Can Wang"], "title": "GUI-Robust: A Comprehensive Dataset for Testing GUI Agent Robustness in Real-World Anomalies", "categories": ["cs.AI"], "comment": "10 pages, 4 figures, submitted to NIPS 2025", "summary": "The development of high-quality datasets is crucial for benchmarking and\nadvancing research in Graphical User Interface (GUI) agents. Despite their\nimportance, existing datasets are often constructed under idealized conditions,\noverlooking the diverse anomalies frequently encountered in real-world\ndeployments. To address this limitation, we introduce GUI-Robust, a novel\ndataset designed for comprehensive GUI agent evaluation, explicitly\nincorporating seven common types of anomalies observed in everyday GUI\ninteractions. Furthermore, we propose a semi-automated dataset construction\nparadigm that collects user action sequences from natural interactions via RPA\ntools and then generate corresponding step and task descriptions for these\nactions with the assistance of MLLMs. This paradigm significantly reduces\nannotation time cost by a factor of over 19 times. Finally, we assess\nstate-of-the-art GUI agents using the GUI-Robust dataset, revealing their\nsubstantial performance degradation in abnormal scenarios. We anticipate that\nour work will highlight the importance of robustness in GUI agents and inspires\nmore future research in this direction. The dataset and code are available at\nhttps://github.com/chessbean1/GUI-Robust.."}
{"id": "2506.14126", "pdf": "https://arxiv.org/pdf/2506.14126", "abs": "https://arxiv.org/abs/2506.14126", "authors": ["Stefan Horoi", "Guy Wolf", "Eugene Belilovsky", "Gintare Karolina Dziugaite"], "title": "Less is More: Undertraining Experts Improves Model Upcycling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Modern deep learning is increasingly characterized by the use of open-weight\nfoundation models that can be fine-tuned on specialized datasets. This has led\nto a proliferation of expert models and adapters, often shared via platforms\nlike HuggingFace and AdapterHub. To leverage these resources, numerous model\nupcycling methods have emerged, enabling the reuse of fine-tuned models in\nmulti-task systems. A natural pipeline has thus formed to harness the benefits\nof transfer learning and amortize sunk training costs: models are pre-trained\non general data, fine-tuned on specific tasks, and then upcycled into more\ngeneral-purpose systems. A prevailing assumption is that improvements at one\nstage of this pipeline propagate downstream, leading to gains at subsequent\nsteps. In this work, we challenge that assumption by examining how expert\nfine-tuning affects model upcycling. We show that long fine-tuning of experts\nthat optimizes for their individual performance leads to degraded merging\nperformance, both for fully fine-tuned and LoRA-adapted models, and to worse\ndownstream results when LoRA adapters are upcycled into MoE layers. We trace\nthis degradation to the memorization of a small set of difficult examples that\ndominate late fine-tuning steps and are subsequently forgotten during merging.\nFinally, we demonstrate that a task-dependent aggressive early stopping\nstrategy can significantly improve upcycling performance."}
{"id": "2506.14496", "pdf": "https://arxiv.org/pdf/2506.14496", "abs": "https://arxiv.org/abs/2506.14496", "authors": ["Muhammad Atta Ur Rahman", "Melanie Schranz"], "title": "LLM-Powered Swarms: A New Frontier or a Conceptual Stretch?", "categories": ["cs.AI"], "comment": "This is the author's version of a paper submitted to IEEE Intelligent\n  Systems. 6 Tables, 3 Figures", "summary": "Swarm intelligence traditionally refers to systems of simple, decentralized\nagents whose local interactions lead to emergent, collective behavior.\nRecently, the term 'swarm' has been extended to describe AI systems like\nOpenAI's Swarm, where large language models (LLMs) act as collaborative agents.\nThis paper contrasts traditional swarm algorithms with LLM-driven swarms\nexploring how decentralization, scalability, and emergence are redefined in\nmodern artificial intelligence (AI). We implement and compare both paradigms\nusing Boids and Ant Colony Optimization (ACO), evaluating latency, resource\nusage, and behavioral accuracy. The suitability of both cloud-based and local\nLLMs is assessed for the agent-based use in swarms. Although LLMs offer\npowerful reasoning and abstraction capabilities, they introduce new constraints\nin computation and coordination that challenge traditional notions of swarm\ndesign. This study highlights the opportunities and limitations of integrating\nLLMs into swarm systems and discusses the evolving definition of 'swarm' in\nmodern AI research."}
{"id": "2506.14143", "pdf": "https://arxiv.org/pdf/2506.14143", "abs": "https://arxiv.org/abs/2506.14143", "authors": ["Hayden McTavish", "Zachery Boner", "Jon Donnelly", "Margo Seltzer", "Cynthia Rudin"], "title": "Leveraging Predictive Equivalence in Decision Trees", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Decision trees are widely used for interpretable machine learning due to\ntheir clearly structured reasoning process. However, this structure belies a\nchallenge we refer to as predictive equivalence: a given tree's decision\nboundary can be represented by many different decision trees. The presence of\nmodels with identical decision boundaries but different evaluation processes\nmakes model selection challenging. The models will have different variable\nimportance and behave differently in the presence of missing values, but most\noptimization procedures will arbitrarily choose one such model to return. We\npresent a boolean logical representation of decision trees that does not\nexhibit predictive equivalence and is faithful to the underlying decision\nboundary. We apply our representation to several downstream machine learning\ntasks. Using our representation, we show that decision trees are surprisingly\nrobust to test-time missingness of feature values; we address predictive\nequivalence's impact on quantifying variable importance; and we present an\nalgorithm to optimize the cost of reaching predictions."}
{"id": "2506.14502", "pdf": "https://arxiv.org/pdf/2506.14502", "abs": "https://arxiv.org/abs/2506.14502", "authors": ["Xiao Wang", "Junru Yu", "Jun Huang", "Qiong Wu", "Ljubo Vacic", "Changyin Sun"], "title": "Toward Safety-First Human-Like Decision Making for Autonomous Vehicles in Time-Varying Traffic Flow", "categories": ["cs.AI"], "comment": null, "summary": "Despite the recent advancements in artificial intelligence technologies have\nshown great potential in improving transport efficiency and safety, autonomous\nvehicles(AVs) still face great challenge of driving in time-varying traffic\nflow, especially in dense and interactive situations. Meanwhile, human have\nfree wills and usually do not make the same decisions even situate in the\nexactly same scenarios, leading to the data-driven methods suffer from poor\nmigratability and high search cost problems, decreasing the efficiency and\neffectiveness of the behavior policy. In this research, we propose a\nsafety-first human-like decision-making framework(SF-HLDM) for AVs to drive\nsafely, comfortably, and social compatiblely in effiency. The framework\nintegrates a hierarchical progressive framework, which combines a\nspatial-temporal attention (S-TA) mechanism for other road users' intention\ninference, a social compliance estimation module for behavior regulation, and a\nDeep Evolutionary Reinforcement Learning(DERL) model for expanding the search\nspace efficiently and effectively to make avoidance of falling into the local\noptimal trap and reduce the risk of overfitting, thus make human-like decisions\nwith interpretability and flexibility. The SF-HLDM framework enables autonomous\ndriving AI agents dynamically adjusts decision parameters to maintain safety\nmargins and adhering to contextually appropriate driving behaviors at the same\ntime."}
{"id": "2506.14162", "pdf": "https://arxiv.org/pdf/2506.14162", "abs": "https://arxiv.org/abs/2506.14162", "authors": ["Amirhossein Rajabpour", "Kiarash Aghakasiri", "Sandra Zilles", "Levi H. S. Lelis"], "title": "Common Benchmarks Undervalue the Generalization Power of Programmatic Policies", "categories": ["cs.LG"], "comment": "17 pages, 5 figures", "summary": "Algorithms for learning programmatic representations for sequential\ndecision-making problems are often evaluated on out-of-distribution (OOD)\nproblems, with the common conclusion that programmatic policies generalize\nbetter than neural policies on OOD problems. In this position paper, we argue\nthat commonly used benchmarks undervalue the generalization capabilities of\nprogrammatic representations. We analyze the experiments of four papers from\nthe literature and show that neural policies, which were shown not to\ngeneralize, can generalize as effectively as programmatic policies on OOD\nproblems. This is achieved with simple changes in the neural policies training\npipeline. Namely, we show that simpler neural architectures with the same type\nof sparse observation used with programmatic policies can help attain OOD\ngeneralization. Another modification we have shown to be effective is the use\nof reward functions that allow for safer policies (e.g., agents that drive\nslowly can generalize better). Also, we argue for creating benchmark problems\nhighlighting concepts needed for OOD generalization that may challenge neural\npolicies but align with programmatic representations, such as tasks requiring\nalgorithmic constructs like stacks."}
{"id": "2506.14539", "pdf": "https://arxiv.org/pdf/2506.14539", "abs": "https://arxiv.org/abs/2506.14539", "authors": ["Daewon Kang", "YeongHwan Shin", "Doyeon Kim", "Kyu-Hwan Jung", "Meong Hi Son"], "title": "Doppelgänger Method: Breaking Role Consistency in LLM Agent via Prompt-based Transferable Adversarial Attack", "categories": ["cs.AI", "cs.CR"], "comment": null, "summary": "Since the advent of large language models, prompt engineering now enables the\nrapid, low-effort creation of diverse autonomous agents that are already in\nwidespread use. Yet this convenience raises urgent concerns about the safety,\nrobustness, and behavioral consistency of the underlying prompts, along with\nthe pressing challenge of preventing those prompts from being exposed to user's\nattempts. In this paper, we propose the ''Doppelg\\\"anger method'' to\ndemonstrate the risk of an agent being hijacked, thereby exposing system\ninstructions and internal information. Next, we define the ''Prompt Alignment\nCollapse under Adversarial Transfer (PACAT)'' level to evaluate the\nvulnerability to this adversarial transfer attack. We also propose a ''Caution\nfor Adversarial Transfer (CAT)'' prompt to counter the Doppelg\\\"anger method.\nThe experimental results demonstrate that the Doppelg\\\"anger method can\ncompromise the agent's consistency and expose its internal information. In\ncontrast, CAT prompts enable effective defense against this adversarial attack."}
{"id": "2506.14164", "pdf": "https://arxiv.org/pdf/2506.14164", "abs": "https://arxiv.org/abs/2506.14164", "authors": ["Hanzhong Cao"], "title": "Light Aircraft Game : Basic Implementation and training results analysis", "categories": ["cs.LG", "cs.MA"], "comment": null, "summary": "This paper investigates multi-agent reinforcement learning (MARL) in a\npartially observable, cooperative-competitive combat environment known as LAG.\nWe describe the environment's setup, including agent actions, hierarchical\ncontrols, and reward design across different combat modes such as No Weapon and\nShootMissile. Two representative algorithms are evaluated: HAPPO, an on-policy\nhierarchical variant of PPO, and HASAC, an off-policy method based on soft\nactor-critic. We analyze their training stability, reward progression, and\ninter-agent coordination capabilities. Experimental results show that HASAC\nperforms well in simpler coordination tasks without weapons, while HAPPO\ndemonstrates stronger adaptability in more dynamic and expressive scenarios\ninvolving missile combat. These findings provide insights into the trade-offs\nbetween on-policy and off-policy methods in multi-agent settings."}
{"id": "2506.14568", "pdf": "https://arxiv.org/pdf/2506.14568", "abs": "https://arxiv.org/abs/2506.14568", "authors": ["Eliott Thomas", "Mickael Coustaty", "Aurelie Joseph", "Gaspar Deloin", "Elodie Carel", "Vincent Poulain D'Andecy", "Jean-Marc Ogier"], "title": "QUEST: Quality-aware Semi-supervised Table Extraction for Business Documents", "categories": ["cs.AI"], "comment": "Accepted at ICDAR 2025", "summary": "Automating table extraction (TE) from business documents is critical for\nindustrial workflows but remains challenging due to sparse annotations and\nerror-prone multi-stage pipelines. While semi-supervised learning (SSL) can\nleverage unlabeled data, existing methods rely on confidence scores that poorly\nreflect extraction quality. We propose QUEST, a Quality-aware Semi-supervised\nTable extraction framework designed for business documents. QUEST introduces a\nnovel quality assessment model that evaluates structural and contextual\nfeatures of extracted tables, trained to predict F1 scores instead of relying\non confidence metrics. This quality-aware approach guides pseudo-label\nselection during iterative SSL training, while diversity measures (DPP, Vendi\nscore, IntDiv) mitigate confirmation bias. Experiments on a proprietary\nbusiness dataset (1000 annotated + 10000 unannotated documents) show QUEST\nimproves F1 from 64% to 74% and reduces empty predictions by 45% (from 12% to\n6.5%). On the DocILE benchmark (600 annotated + 20000 unannotated documents),\nQUEST achieves a 50% F1 score (up from 42%) and reduces empty predictions by\n19% (from 27% to 22%). The framework's interpretable quality assessments and\nrobustness to annotation scarcity make it particularly suited for business\ndocuments, where structural consistency and data completeness are paramount."}
{"id": "2506.14167", "pdf": "https://arxiv.org/pdf/2506.14167", "abs": "https://arxiv.org/abs/2506.14167", "authors": ["Prithvi Raj"], "title": "Structured and Informed Probabilistic Modeling with the Thermodynamic Kolmogorov-Arnold Model", "categories": ["cs.LG"], "comment": null, "summary": "We adapt the Kolmogorov-Arnold Representation Theorem to generative modeling\nby reinterpreting its inner functions as a Markov Kernel between probability\nspaces via inverse transform sampling. We present a generative model that is\ninterpretable, easy to design, and efficient. Our approach couples a\nKolmogorov-Arnold Network generator with independent energy-based priors,\ntrained via Maximum Likelihood. Inverse sampling enables fast inference, while\nprior knowledge can be incorporated before training to better align priors with\nposteriors, thereby improving learning efficiency and sample quality. The\nlearned prior is also recoverable and visualizable post-training, offering an\nempirical Bayes perspective. To address inflexibility and mitigate\nprior-posterior mismatch, we introduce scalable extensions based on mixture\ndistributions and Langevin Monte Carlo methods, admitting a trade-off between\nflexibility and training efficiency. Our contributions connect classical\nrepresentation theorems with modern probabilistic modeling, while balancing\ntraining stability, inference speed, and the quality and diversity of\ngenerations."}
{"id": "2506.14569", "pdf": "https://arxiv.org/pdf/2506.14569", "abs": "https://arxiv.org/abs/2506.14569", "authors": ["Stephen Roth", "Lennart Baur", "Derian Boer", "Stefan Kramer"], "title": "Enhancing Symbolic Machine Learning by Subsymbolic Representations", "categories": ["cs.AI", "cs.LO"], "comment": null, "summary": "The goal of neuro-symbolic AI is to integrate symbolic and subsymbolic AI\napproaches, to overcome the limitations of either. Prominent systems include\nLogic Tensor Networks (LTN) or DeepProbLog, which offer neural predicates and\nend-to-end learning. The versatility of systems like LTNs and DeepProbLog,\nhowever, makes them less efficient in simpler settings, for instance, for\ndiscriminative machine learning, in particular in domains with many constants.\nTherefore, we follow a different approach: We propose to enhance symbolic\nmachine learning schemes by giving them access to neural embeddings. In the\npresent paper, we show this for TILDE and embeddings of constants used by TILDE\nin similarity predicates. The approach can be fine-tuned by further refining\nthe embeddings depending on the symbolic theory. In experiments in three\nreal-world domain, we show that this simple, yet effective, approach\noutperforms all other baseline methods in terms of the F1 score. The approach\ncould be useful beyond this setting: Enhancing symbolic learners in this way\ncould be extended to similarities between instances (effectively working like\nkernels within a logical language), for analogical reasoning, or for\npropositionalization."}
{"id": "2506.14194", "pdf": "https://arxiv.org/pdf/2506.14194", "abs": "https://arxiv.org/abs/2506.14194", "authors": ["Sudeepta Mondal", "Zhuolin Jiang", "Ganesh Sundaramoorthi"], "title": "A Variational Information Theoretic Approach to Out-of-Distribution Detection", "categories": ["cs.LG"], "comment": null, "summary": "We present a theory for the construction of out-of-distribution (OOD)\ndetection features for neural networks. We introduce random features for OOD\nthrough a novel information-theoretic loss functional consisting of two terms,\nthe first based on the KL divergence separates resulting in-distribution (ID)\nand OOD feature distributions and the second term is the Information\nBottleneck, which favors compressed features that retain the OOD information.\nWe formulate a variational procedure to optimize the loss and obtain OOD\nfeatures. Based on assumptions on OOD distributions, one can recover properties\nof existing OOD features, i.e., shaping functions. Furthermore, we show that\nour theory can predict a new shaping function that out-performs existing ones\non OOD benchmarks. Our theory provides a general framework for constructing a\nvariety of new features with clear explainability."}
{"id": "2506.14570", "pdf": "https://arxiv.org/pdf/2506.14570", "abs": "https://arxiv.org/abs/2506.14570", "authors": ["Mohammad Hashemi", "Andreas Zufle"], "title": "From Points to Places: Towards Human Mobility-Driven Spatiotemporal Foundation Models via Understanding Places", "categories": ["cs.AI"], "comment": null, "summary": "Capturing human mobility is essential for modeling how people interact with\nand move through physical spaces, reflecting social behavior, access to\nresources, and dynamic spatial patterns. To support scalable and transferable\nanalysis across diverse geographies and contexts, there is a need for a\ngeneralizable foundation model for spatiotemporal data. While foundation models\nhave transformed language and vision, they remain limited in handling the\nunique challenges posed by the spatial, temporal, and semantic complexity of\nmobility data. This vision paper advocates for a new class of spatial\nfoundation models that integrate geolocation semantics with human mobility\nacross multiple scales. Central to our vision is a shift from modeling discrete\npoints of interest to understanding places: dynamic, context-rich regions\nshaped by human behavior and mobility that may comprise many places of\ninterest. We identify key gaps in adaptability, scalability, and multi-granular\nreasoning, and propose research directions focused on modeling places and\nenabling efficient learning. Our goal is to guide the development of scalable,\ncontext-aware models for next-generation geospatial intelligence. These models\nunlock powerful applications ranging from personalized place discovery and\nlogistics optimization to urban planning, ultimately enabling smarter and more\nresponsive spatial decision-making."}
{"id": "2506.14202", "pdf": "https://arxiv.org/pdf/2506.14202", "abs": "https://arxiv.org/abs/2506.14202", "authors": ["Makoto Shing", "Takuya Akiba"], "title": "DiffusionBlocks: Blockwise Training for Generative Models via Score-Based Diffusion", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "To appear at TTODLer-FM Workshop of the 42nd International Conference\n  on Machine Learning", "summary": "Training large neural networks with end-to-end backpropagation creates\nsignificant memory bottlenecks, limiting accessibility to state-of-the-art AI\nresearch. We propose $\\textit{DiffusionBlocks}$, a novel training framework\nthat interprets neural network blocks as performing denoising operations in a\ncontinuous-time diffusion process. By partitioning the network into\nindependently trainable blocks and optimizing noise level assignments based on\nequal cumulative probability mass, our approach achieves significant memory\nefficiency while maintaining competitive performance compared to traditional\nbackpropagation in generative tasks. Experiments on image generation and\nlanguage modeling tasks demonstrate memory reduction proportional to the number\nof blocks while achieving superior performance. DiffusionBlocks provides a\npromising pathway for democratizing access to large-scale neural network\ntraining with limited computational resources."}
{"id": "2506.14728", "pdf": "https://arxiv.org/pdf/2506.14728", "abs": "https://arxiv.org/abs/2506.14728", "authors": ["Jiahao Qiu", "Xinzhe Juan", "Yimin Wang", "Ling Yang", "Xuan Qi", "Tongcheng Zhang", "Jiacheng Guo", "Yifu Lu", "Zixin Yao", "Hongru Wang", "Shilong Liu", "Xun Jiang", "Liu Leqi", "Mengdi Wang"], "title": "AgentDistill: Training-Free Agent Distillation with Generalizable MCP Boxes", "categories": ["cs.AI"], "comment": "10 pages, 5 figures", "summary": "While knowledge distillation has become a mature field for compressing large\nlanguage models (LLMs) into smaller ones by aligning their outputs or internal\nrepresentations, the distillation of LLM-based agents, which involve planning,\nmemory, and tool use, remains relatively underexplored. Existing agent\ndistillation methods typically replay full teacher trajectories or imitate\nstep-by-step teacher tool usage, but they often struggle to train student\nagents to dynamically plan and act in novel environments. We propose\nAgentDistill, a novel, training-free agent distillation framework that enables\nefficient and scalable knowledge transfer via direct reuse of\nModel-Context-Protocols (MCPs), which are structured and reusable task-solving\nmodules autonomously generated by teacher agents. The reuse of these distilled\nMCPs enables student agents to generalize their capabilities across domains and\nsolve new problems with minimal supervision or human intervention. Experiments\non biomedical and mathematical benchmarks demonstrate that our distilled\nstudent agents, built on small language models, can achieve performance\ncomparable to advanced systems using large LLMs such as OctoTools (GPT-4o),\nhighlighting the effectiveness of our framework in building scalable and\ncost-efficient intelligent agents."}
{"id": "2506.14217", "pdf": "https://arxiv.org/pdf/2506.14217", "abs": "https://arxiv.org/abs/2506.14217", "authors": ["Dipesh Tharu Mahato", "Rohan Poudel", "Pramod Dhungana"], "title": "TriGuard: Testing Model Safety with Attribution Entropy, Verification, and Drift", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 6 tables, 6 figures", "summary": "Deep neural networks often achieve high accuracy, but ensuring their\nreliability under adversarial and distributional shifts remains a pressing\nchallenge. We propose TriGuard, a unified safety evaluation framework that\ncombines (1) formal robustness verification, (2) attribution entropy to\nquantify saliency concentration, and (3) a novel Attribution Drift Score\nmeasuring explanation stability. TriGuard reveals critical mismatches between\nmodel accuracy and interpretability: verified models can still exhibit unstable\nreasoning, and attribution-based signals provide complementary safety insights\nbeyond adversarial accuracy. Extensive experiments across three datasets and\nfive architectures show how TriGuard uncovers subtle fragilities in neural\nreasoning. We further demonstrate that entropy-regularized training reduces\nexplanation drift without sacrificing performance. TriGuard advances the\nfrontier in robust, interpretable model evaluation."}
{"id": "2506.14755", "pdf": "https://arxiv.org/pdf/2506.14755", "abs": "https://arxiv.org/abs/2506.14755", "authors": ["Zhengxiang Cheng", "Dongping Chen", "Mingyang Fu", "Tianyi Zhou"], "title": "Optimizing Length Compression in Large Reasoning Models", "categories": ["cs.AI", "cs.CL"], "comment": "16 pages, 7 figures, 4 tables", "summary": "Large Reasoning Models (LRMs) have achieved remarkable success, yet they\noften suffer from producing unnecessary and verbose reasoning chains. We\nidentify a core aspect of this issue as \"invalid thinking\" -- models tend to\nrepeatedly double-check their work after having derived the correct answer. To\naddress this specific inefficiency, we move beyond the general principles of\nEfficacy and Efficiency to propose two new, fine-grained principles: Brevity,\nwhich advocates for eliminating redundancy, and Sufficiency, which ensures\ncritical reasoning steps are preserved. Guided by these principles, we\nintroduce LC-R1, a post-training method based on Group Relative Policy\nOptimization (GRPO). LC-R1 employs a novel combination of a Length Reward for\noverall conciseness and a Compress Reward that is specifically designed to\nremove the invalid portion of the thinking process. Extensive experiments on\nmultiple reasoning benchmarks demonstrate that LC-R1 achieves a significant\nreduction in sequence length (~50%) with only a marginal (~2%) drop in\naccuracy, achieving a favorable trade-off point on the Pareto frontier that\nprioritizes high compression. Our analysis further validates the robustness of\nLC-R1 and provides valuable insights for developing more powerful yet\ncomputationally efficient LRMs. Our code is released at\nhttps://github.com/zxiangx/LC-R1."}
{"id": "2506.14220", "pdf": "https://arxiv.org/pdf/2506.14220", "abs": "https://arxiv.org/abs/2506.14220", "authors": ["Kangkang Lu", "Yanhua Yu", "Zhiyong Huang", "Tat-Seng Chua"], "title": "Can Large Language Models Improve Spectral Graph Neural Networks?", "categories": ["cs.LG"], "comment": null, "summary": "Spectral Graph Neural Networks (SGNNs) have attracted significant attention\ndue to their ability to approximate arbitrary filters. They typically rely on\nsupervision from downstream tasks to adaptively learn appropriate filters.\nHowever, under label-scarce conditions, SGNNs may learn suboptimal filters,\nleading to degraded performance. Meanwhile, the remarkable success of Large\nLanguage Models (LLMs) has inspired growing interest in exploring their\npotential within the GNN domain. This naturally raises an important question:\n\\textit{Can LLMs help overcome the limitations of SGNNs and enhance their\nperformance?} In this paper, we propose a novel approach that leverages LLMs to\nestimate the homophily of a given graph. The estimated homophily is then used\nto adaptively guide the design of polynomial spectral filters, thereby\nimproving the expressiveness and adaptability of SGNNs across diverse graph\nstructures. Specifically, we introduce a lightweight pipeline in which the LLM\ngenerates homophily-aware priors, which are injected into the filter\ncoefficients to better align with the underlying graph topology. Extensive\nexperiments on benchmark datasets demonstrate that our LLM-driven SGNN\nframework consistently outperforms existing baselines under both homophilic and\nheterophilic settings, with minimal computational and monetary overhead."}
{"id": "2506.13771", "pdf": "https://arxiv.org/pdf/2506.13771", "abs": "https://arxiv.org/abs/2506.13771", "authors": ["Banseok Lee", "Dongkyu Kim", "Youngcheon You", "Youngmin Kim"], "title": "LittleBit: Ultra Low-Bit Quantization via Latent Factorization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Deploying large language models (LLMs) often faces challenges from\nsubstantial memory and computational costs. Quantization offers a solution, yet\nperformance degradation in the sub-1-bit regime remains particularly difficult.\nThis paper introduces LittleBit, a novel method for extreme LLM compression. It\ntargets levels like 0.1 bits per weight (BPW), achieving nearly 31$\\times$\nmemory reduction, e.g., Llama2-13B to under 0.9 GB. LittleBit represents\nweights in a low-rank form using latent matrix factorization, subsequently\nbinarizing these factors. To counteract information loss from this extreme\nprecision, it integrates a multi-scale compensation mechanism. This includes\nrow, column, and an additional latent dimension that learns per-rank\nimportance. Two key contributions enable effective training: Dual\nSign-Value-Independent Decomposition (Dual-SVID) for stable quantization-aware\ntraining (QAT) initialization, and integrated Residual Compensation to mitigate\nerrors. Extensive experiments confirm LittleBit's superiority in sub-1-bit\nquantization: e.g., its 0.1 BPW performance on Llama2-7B surpasses the leading\nmethod's 0.7 BPW. This establishes a superior size-performance trade-off, with\nkernel-level benchmarks indicating potential for a 5$\\times$ speedup compared\nto FP16. LittleBit paves the way for deploying powerful LLMs in\nresource-constrained environments."}
{"id": "2506.14251", "pdf": "https://arxiv.org/pdf/2506.14251", "abs": "https://arxiv.org/abs/2506.14251", "authors": ["Xiyu Zhao", "Qimei Cui", "Weicai Li", "Wei Ni", "Ekram Hossain", "Quan Z. Sheng", "Xiaofeng Tao", "Ping Zhang"], "title": "Convergence-Privacy-Fairness Trade-Off in Personalized Federated Learning", "categories": ["cs.LG", "cs.DC"], "comment": null, "summary": "Personalized federated learning (PFL), e.g., the renowned Ditto, strikes a\nbalance between personalization and generalization by conducting federated\nlearning (FL) to guide personalized learning (PL). While FL is unaffected by\npersonalized model training, in Ditto, PL depends on the outcome of the FL.\nHowever, the clients' concern about their privacy and consequent perturbation\nof their local models can affect the convergence and (performance) fairness of\nPL. This paper presents PFL, called DP-Ditto, which is a non-trivial extension\nof Ditto under the protection of differential privacy (DP), and analyzes the\ntrade-off among its privacy guarantee, model convergence, and performance\ndistribution fairness. We also analyze the convergence upper bound of the\npersonalized models under DP-Ditto and derive the optimal number of global\naggregations given a privacy budget. Further, we analyze the performance\nfairness of the personalized models, and reveal the feasibility of optimizing\nDP-Ditto jointly for convergence and fairness. Experiments validate our\nanalysis and demonstrate that DP-Ditto can surpass the DP-perturbed versions of\nthe state-of-the-art PFL models, such as FedAMP, pFedMe, APPLE, and FedALA, by\nover 32.71% in fairness and 9.66% in accuracy."}
{"id": "2506.13772", "pdf": "https://arxiv.org/pdf/2506.13772", "abs": "https://arxiv.org/abs/2506.13772", "authors": ["Zhenyan Lu", "Daliang Xu", "Dongqi Cai", "Zexi Li", "Wei Liu", "Fangming Liu", "Shangguang Wang", "Mengwei Xu"], "title": "MobiEdit: Resource-efficient Knowledge Editing for Personalized On-device LLMs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are deployed on mobile devices to power killer\napplications such as intelligent assistants. LLMs pre-trained on general\ncorpora often hallucinate when handling personalized or unseen queries, leading\nto incorrect or outdated responses. Knowledge editing addresses this by\nidentifying and adjusting a small crucial portion of model weights, without\ncompromising the general knowledge. However, prior knowledge editing methods\nare impractical to run on local devices due to the resource-heavy\nbackpropagation (BP) needed for updates. We present MobiEdit, the first mobile\nknowledge editing framework that enables efficient LLM personalization on\ncommercial off-the-shelf (COTS) mobile devices. MobiEdit replaces\nfull-precision BP with quantized forward-only gradient estimation, thus\ncompatible with the energy-efficient mobile neural processing units (NPUs).\nMobiEdit replaces full-precision backpropagation with quantized forward-only\ngradient estimation, making it compatible with energy-efficient mobile NPUs. To\nfurther improve gradient estimation efficiency, we introduce two optimizations:\nan early stoping mechanism that adaptively terminates editing upon success and\na prefix cache that reuses computation across steps. Our approach enables\nreal-time editing of a 3B-parameter model (Qwen2.5-3B-Instruct) on COTS mobile\ndevices with 7.6$\\times$ less memory, 14.7 $\\times$ less energy and 3.6$\\times$\nless latency compared to previous knowledge editing methods."}
{"id": "2506.14261", "pdf": "https://arxiv.org/pdf/2506.14261", "abs": "https://arxiv.org/abs/2506.14261", "authors": ["Rohan Gupta", "Erik Jenner"], "title": "RL-Obfuscation: Can Language Models Learn to Evade Latent-Space Monitors?", "categories": ["cs.LG"], "comment": null, "summary": "Latent-space monitors aim to detect undesirable behaviours in large language\nmodels by leveraging internal model representations rather than relying solely\non black-box outputs. These methods have shown promise in identifying\nbehaviours such as deception and unsafe completions, but a critical open\nquestion remains: can LLMs learn to evade such monitors? To study this, we\nintroduce RL-Obfuscation, in which LLMs are finetuned via reinforcement\nlearning to bypass latent-space monitors while maintaining coherent\ngenerations. We apply RL-Obfuscation to LLMs ranging from 7B to 14B parameters\nand evaluate evasion success against a suite of monitors. We find that\ntoken-level latent-space monitors are highly vulnerable to this attack. More\nholistic monitors, such as max-pooling or attention-based probes, remain\nrobust. Moreover, we show that adversarial policies trained to evade a single\nstatic monitor generalise to unseen monitors of the same type. Finally, we\nstudy how the policy learned by RL bypasses these monitors and find that the\nmodel can also learn to repurpose tokens to mean something different\ninternally."}
{"id": "2506.13781", "pdf": "https://arxiv.org/pdf/2506.13781", "abs": "https://arxiv.org/abs/2506.13781", "authors": ["Pablo Ariño Fernández", "Carlos Quesada González"], "title": "Solving the Job Shop Scheduling Problem with Graph Neural Networks: A Customizable Reinforcement Learning Environment", "categories": ["cs.LG", "cs.AI", "cs.DM", "90-04 (Primary), 90B35, 68T05 (Secondary)", "I.2.8; I.2.6; D.0; G.2.1; G.2.2"], "comment": "Bachelor's thesis, Universidad Polit\\'ecnica de Madrid, 2025. 150\n  pages, 23 figures", "summary": "The job shop scheduling problem is an NP-hard combinatorial optimization\nproblem relevant to manufacturing and timetabling. Traditional approaches use\npriority dispatching rules based on simple heuristics. Recent work has\nattempted to replace these with deep learning models, particularly graph neural\nnetworks (GNNs), that learn to assign priorities from data. However, training\nsuch models requires customizing numerous factors: graph representation, node\nfeatures, action space, and reward functions. The lack of modular libraries for\nexperimentation makes this research time-consuming. This work introduces\nJobShopLib, a modular library that allows customizing these factors and\ncreating new components with its reinforcement learning environment. We trained\nseveral dispatchers through imitation learning to demonstrate the environment's\nutility. One model outperformed various graph-based dispatchers using only\nindividual operation features, highlighting the importance of feature\ncustomization. Our GNN model achieved near state-of-the-art results on\nlarge-scale problems. These results suggest significant room for improvement in\ndeveloping such models. JobShopLib provides the necessary tools for future\nexperimentation."}
{"id": "2506.14262", "pdf": "https://arxiv.org/pdf/2506.14262", "abs": "https://arxiv.org/abs/2506.14262", "authors": ["Mohammad Emtiyaz Khan"], "title": "Knowledge Adaptation as Posterior Correction", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Adaptation is the holy grail of intelligence, but even the best AI models\n(like GPT) lack the adaptivity of toddlers. So the question remains: how can\nmachines adapt quickly? Despite a lot of progress on model adaptation to\nfacilitate continual and federated learning, as well as model merging, editing,\nunlearning, etc., little is known about the mechanisms by which machines can\nnaturally learn to adapt in a similar way as humans and animals. Here, we show\nthat all such adaptation methods can be seen as different ways of `correcting'\nthe approximate posteriors. More accurate posteriors lead to smaller\ncorrections, which in turn imply quicker adaptation. The result is obtained by\nusing a dual-perspective of the Bayesian Learning Rule of Khan and Rue (2023)\nwhere interference created during adaptation is characterized by the\nnatural-gradient mismatch over the past data. We present many examples to\ndemonstrate the use of posterior-correction as a natural mechanism for the\nmachines to learn to adapt quickly."}
{"id": "2506.13786", "pdf": "https://arxiv.org/pdf/2506.13786", "abs": "https://arxiv.org/abs/2506.13786", "authors": ["Vuong M. Ngo", "Tran Quang Vinh", "Patricia Kearney", "Mark Roantree"], "title": "Enhancing Bagging Ensemble Regression with Data Integration for Time Series-Based Diabetes Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "17th International Conference on Computational Collective\n  Intelligence, LNAI, Springer, 11 pages", "summary": "Diabetes is a chronic metabolic disease characterized by elevated blood\nglucose levels, leading to complications like heart disease, kidney failure,\nand nerve damage. Accurate state-level predictions are vital for effective\nhealthcare planning and targeted interventions, but in many cases, data for\nnecessary analyses are incomplete. This study begins with a data engineering\nprocess to integrate diabetes-related datasets from 2011 to 2021 to create a\ncomprehensive feature set. We then introduce an enhanced bagging ensemble\nregression model (EBMBag+) for time series forecasting to predict diabetes\nprevalence across U.S. cities. Several baseline models, including SVMReg,\nBDTree, LSBoost, NN, LSTM, and ERMBag, were evaluated for comparison with our\nEBMBag+ algorithm. The experimental results demonstrate that EBMBag+ achieved\nthe best performance, with an MAE of 0.41, RMSE of 0.53, MAPE of 4.01, and an\nR2 of 0.9."}
{"id": "2506.14263", "pdf": "https://arxiv.org/pdf/2506.14263", "abs": "https://arxiv.org/abs/2506.14263", "authors": ["Qingyu Song", "Wei Lin", "Juncheng Wang", "Hong Xu"], "title": "Towards Robust Learning to Optimize with Theoretical Guarantees", "categories": ["cs.LG", "math.OC"], "comment": "Published in CVPR 2024, 55 pages, 17 figures, this version fixed some\n  typo", "summary": "Learning to optimize (L2O) is an emerging technique to solve mathematical\noptimization problems with learning-based methods. Although with great success\nin many real-world scenarios such as wireless communications, computer\nnetworks, and electronic design, existing L2O works lack theoretical\ndemonstration of their performance and robustness in out-of-distribution (OOD)\nscenarios. We address this gap by providing comprehensive proofs. First, we\nprove a sufficient condition for a robust L2O model with homogeneous\nconvergence rates over all In-Distribution (InD) instances. We assume an L2O\nmodel achieves robustness for an InD scenario. Based on our proposed\nmethodology of aligning OOD problems to InD problems, we also demonstrate that\nthe L2O model's convergence rate in OOD scenarios will deteriorate by an\nequation of the L2O model's input features. Moreover, we propose an L2O model\nwith a concise gradient-only feature construction and a novel gradient-based\nhistory modeling method. Numerical simulation demonstrates that our proposed\nmodel outperforms the state-of-the-art baseline in both InD and OOD scenarios\nand achieves up to 10 $\\times$ convergence speedup. The code of our method can\nbe found from https://github.com/NetX-lab/GoMathL2O-Official."}
{"id": "2506.13831", "pdf": "https://arxiv.org/pdf/2506.13831", "abs": "https://arxiv.org/abs/2506.13831", "authors": ["Jitian Zhao", "Chenghui Li", "Frederic Sala", "Karl Rohe"], "title": "Quantifying Structure in CLIP Embeddings: A Statistical Framework for Concept Interpretation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Concept-based approaches, which aim to identify human-understandable concepts\nwithin a model's internal representations, are a promising method for\ninterpreting embeddings from deep neural network models, such as CLIP. While\nthese approaches help explain model behavior, current methods lack statistical\nrigor, making it challenging to validate identified concepts and compare\ndifferent techniques. To address this challenge, we introduce a hypothesis\ntesting framework that quantifies rotation-sensitive structures within the CLIP\nembedding space. Once such structures are identified, we propose a post-hoc\nconcept decomposition method. Unlike existing approaches, it offers theoretical\nguarantees that discovered concepts represent robust, reproducible patterns\n(rather than method-specific artifacts) and outperforms other techniques in\nterms of reconstruction error. Empirically, we demonstrate that our\nconcept-based decomposition algorithm effectively balances reconstruction\naccuracy with concept interpretability and helps mitigate spurious cues in\ndata. Applied to a popular spurious correlation dataset, our method yields a\n22.6% increase in worst-group accuracy after removing spurious background\nconcepts."}
{"id": "2506.14280", "pdf": "https://arxiv.org/pdf/2506.14280", "abs": "https://arxiv.org/abs/2506.14280", "authors": ["Bai Cong", "Nico Daheim", "Yuesong Shen", "Rio Yokota", "Mohammad Emtiyaz Khan", "Thomas Möllenhoff"], "title": "Improving LoRA with Variational Learning", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": "16 pages, 4 figures", "summary": "Bayesian methods have recently been used to improve LoRA finetuning and,\nalthough they improve calibration, their effect on other metrics (such as\naccuracy) is marginal and can sometimes even be detrimental. Moreover, Bayesian\nmethods also increase computational overheads and require additional tricks for\nthem to work well. Here, we fix these issues by using a recently proposed\nvariational algorithm called IVON. We show that IVON is easy to implement and\nhas similar costs to AdamW, and yet it can also drastically improve many\nmetrics by using a simple posterior pruning technique. We present extensive\nresults on billion-scale LLMs (Llama and Qwen series) going way beyond the\nscale of existing applications of IVON. For example, we finetune a Llama-3.2-3B\nmodel on a set of commonsense reasoning tasks and improve accuracy over AdamW\nby 1.3% and reduce ECE by 5.4%, outperforming AdamW and other recent Bayesian\nmethods like Laplace-LoRA and BLoB. Overall, our results show that variational\nlearning with IVON can effectively improve LoRA finetuning."}
{"id": "2506.13834", "pdf": "https://arxiv.org/pdf/2506.13834", "abs": "https://arxiv.org/abs/2506.13834", "authors": ["Zhao Wei", "Chin Chun Ooi", "Abhishek Gupta", "Jian Cheng Wong", "Pao-Hsiung Chiu", "Sheares Xue Wen Toh", "Yew-Soon Ong"], "title": "Evolvable Conditional Diffusion", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "This paper presents an evolvable conditional diffusion method such that\nblack-box, non-differentiable multi-physics models, as are common in domains\nlike computational fluid dynamics and electromagnetics, can be effectively used\nfor guiding the generative process to facilitate autonomous scientific\ndiscovery. We formulate the guidance as an optimization problem where one\noptimizes for a desired fitness function through updates to the descriptive\nstatistic for the denoising distribution, and derive an evolution-guided\napproach from first principles through the lens of probabilistic evolution.\nInterestingly, the final derived update algorithm is analogous to the update as\nper common gradient-based guided diffusion models, but without ever having to\ncompute any derivatives. We validate our proposed evolvable diffusion algorithm\nin two AI for Science scenarios: the automated design of fluidic topology and\nmeta-surface. Results demonstrate that this method effectively generates\ndesigns that better satisfy specific optimization objectives without reliance\non differentiable proxies, providing an effective means of guidance-based\ndiffusion that can capitalize on the wealth of black-box, non-differentiable\nmulti-physics numerical models common across Science."}
{"id": "2506.14291", "pdf": "https://arxiv.org/pdf/2506.14291", "abs": "https://arxiv.org/abs/2506.14291", "authors": ["Ben Finkelshtein", "İsmail İlkan Ceylan", "Michael Bronstein", "Ron Levie"], "title": "Equivariance Everywhere All At Once: A Recipe for Graph Foundation Models", "categories": ["cs.LG", "cs.SI", "stat.ML"], "comment": null, "summary": "Graph machine learning architectures are typically tailored to specific tasks\non specific datasets, which hinders their broader applicability. This has led\nto a new quest in graph machine learning: how to build graph foundation models\ncapable of generalizing across arbitrary graphs and features? In this work, we\npresent a recipe for designing graph foundation models for node-level tasks\nfrom first principles. The key ingredient underpinning our study is a\nsystematic investigation of the symmetries that a graph foundation model must\nrespect. In a nutshell, we argue that label permutation-equivariance alongside\nfeature permutation-invariance are necessary in addition to the common node\npermutation-equivariance on each local neighborhood of the graph. To this end,\nwe first characterize the space of linear transformations that are equivariant\nto permutations of nodes and labels, and invariant to permutations of features.\nWe then prove that the resulting network is a universal approximator on\nmultisets that respect the aforementioned symmetries. Our recipe uses such\nlayers on the multiset of features induced by the local neighborhood of the\ngraph to obtain a class of graph foundation models for node property\nprediction. We validate our approach through extensive experiments on 29\nreal-world node classification datasets, demonstrating both strong zero-shot\nempirical performance and consistent improvement as the number of training\ngraphs increases."}
{"id": "2506.13836", "pdf": "https://arxiv.org/pdf/2506.13836", "abs": "https://arxiv.org/abs/2506.13836", "authors": ["Dang Viet Anh Nguyen", "Carlos Lima Azevedo", "Tomer Toledo", "Filipe Rodrigues"], "title": "Robustness of Reinforcement Learning-Based Traffic Signal Control under Incidents: A Comparative Study", "categories": ["cs.LG", "cs.AI", "90B20, 90C39, 68T05, 62P30", "I.2.6; I.2.8; G.3; J.4"], "comment": "35 pages, 5 figures, 3 tables", "summary": "Reinforcement learning-based traffic signal control (RL-TSC) has emerged as a\npromising approach for improving urban mobility. However, its robustness under\nreal-world disruptions such as traffic incidents remains largely underexplored.\nIn this study, we introduce T-REX, an open-source, SUMO-based simulation\nframework for training and evaluating RL-TSC methods under dynamic, incident\nscenarios. T-REX models realistic network-level performance considering\ndrivers' probabilistic rerouting, speed adaptation, and contextual\nlane-changing, enabling the simulation of congestion propagation under\nincidents. To assess robustness, we propose a suite of metrics that extend\nbeyond conventional traffic efficiency measures. Through extensive experiments\nacross synthetic and real-world networks, we showcase T-REX for the evaluation\nof several state-of-the-art RL-TSC methods under multiple real-world deployment\nparadigms. Our findings show that while independent value-based and\ndecentralized pressure-based methods offer fast convergence and generalization\nin stable traffic conditions and homogeneous networks, their performance\ndegrades sharply under incident-driven distribution shifts. In contrast,\nhierarchical coordination methods tend to offer more stable and adaptable\nperformance in large-scale, irregular networks, benefiting from their\nstructured decision-making architecture. However, this comes with the trade-off\nof slower convergence and higher training complexity. These findings highlight\nthe need for robustness-aware design and evaluation in RL-TSC research. T-REX\ncontributes to this effort by providing an open, standardized and reproducible\nplatform for benchmarking RL methods under dynamic and disruptive traffic\nscenarios."}
{"id": "2506.14306", "pdf": "https://arxiv.org/pdf/2506.14306", "abs": "https://arxiv.org/abs/2506.14306", "authors": ["Ata Yalcin", "Asli Umay Ozturk", "Yigit Sever", "Viktoria Pauw", "Stephan Hachinger", "Ismail Hakki Toroslu", "Pinar Karagoz"], "title": "Fair for a few: Improving Fairness in Doubly Imbalanced Datasets", "categories": ["cs.LG", "cs.CY"], "comment": "33 pages, 3 figures, submitted to AI Review", "summary": "Fairness has been identified as an important aspect of Machine Learning and\nArtificial Intelligence solutions for decision making. Recent literature offers\na variety of approaches for debiasing, however many of them fall short when the\ndata collection is imbalanced. In this paper, we focus on a particular case,\nfairness in doubly imbalanced datasets, such that the data collection is\nimbalanced both for the label and the groups in the sensitive attribute.\nFirstly, we present an exploratory analysis to illustrate limitations in\ndebiasing on a doubly imbalanced dataset. Then, a multi-criteria based solution\nis proposed for finding the most suitable sampling and distribution for label\nand sensitive attribute, in terms of fairness and classification accuracy"}
{"id": "2506.13838", "pdf": "https://arxiv.org/pdf/2506.13838", "abs": "https://arxiv.org/abs/2506.13838", "authors": ["Lorena Poenaru-Olaru", "June Sallou", "Luis Cruz", "Jan Rellermeyer", "Arie van Deursen"], "title": "Sustainable Machine Learning Retraining: Optimizing Energy Efficiency Without Compromising Accuracy", "categories": ["cs.LG", "cs.AI", "cs.SE"], "comment": "12 pages. Accepted at ICT4Sustainability 2025 conference", "summary": "The reliability of machine learning (ML) software systems is heavily\ninfluenced by changes in data over time. For that reason, ML systems require\nregular maintenance, typically based on model retraining. However, retraining\nrequires significant computational demand, which makes it energy-intensive and\nraises concerns about its environmental impact. To understand which retraining\ntechniques should be considered when designing sustainable ML applications, in\nthis work, we study the energy consumption of common retraining techniques.\nSince the accuracy of ML systems is also essential, we compare retraining\ntechniques in terms of both energy efficiency and accuracy. We showcase that\nretraining with only the most recent data, compared to all available data,\nreduces energy consumption by up to 25\\%, being a sustainable alternative to\nthe status quo. Furthermore, our findings show that retraining a model only\nwhen there is evidence that updates are necessary, rather than on a fixed\nschedule, can reduce energy consumption by up to 40\\%, provided a reliable data\nchange detector is in place. Our findings pave the way for better\nrecommendations for ML practitioners, guiding them toward more energy-efficient\nretraining techniques when designing sustainable ML software systems."}
{"id": "2506.14375", "pdf": "https://arxiv.org/pdf/2506.14375", "abs": "https://arxiv.org/abs/2506.14375", "authors": ["Muhammad Hamza Yousuf", "Jason Li", "Sahar Vahdati", "Raphael Theilen", "Jakob Wittenstein", "Jens Lehmann"], "title": "IntelliLung: Advancing Safe Mechanical Ventilation using Offline RL with Hybrid Actions and Clinically Aligned Rewards", "categories": ["cs.LG", "cs.AI"], "comment": "under review, PAIS track @ ECAI 2025", "summary": "Invasive mechanical ventilation (MV) is a life-sustaining therapy for\ncritically ill patients in the intensive care unit (ICU). However, optimizing\nits settings remains a complex and error-prone process due to patient-specific\nvariability. While Offline Reinforcement Learning (RL) shows promise for MV\ncontrol, current stateof-the-art (SOTA) methods struggle with the hybrid\n(continuous and discrete) nature of MV actions. Discretizing the action space\nlimits available actions due to exponential growth in combinations and\nintroduces distribution shifts that can compromise safety. In this paper, we\npropose optimizations that build upon prior work in action space reduction to\naddress the challenges of discrete action spaces. We also adapt SOTA offline RL\nalgorithms (IQL and EDAC) to operate directly on hybrid action spaces, thereby\navoiding the pitfalls of discretization. Additionally, we introduce a\nclinically grounded reward function based on ventilator-free days and\nphysiological targets, which provides a more meaningful optimization objective\ncompared to traditional sparse mortality-based rewards. Our findings\ndemonstrate that AI-assisted MV optimization may enhance patient safety and\nenable individualized lung support, representing a significant advancement\ntoward intelligent, data-driven critical care solutions."}
{"id": "2506.13862", "pdf": "https://arxiv.org/pdf/2506.13862", "abs": "https://arxiv.org/abs/2506.13862", "authors": ["Alena Shilova", "Alex Davey", "Brahim Driss", "Riad Akrour"], "title": "StaQ it! Growing neural networks for Policy Mirror Descent", "categories": ["cs.LG", "cs.AI"], "comment": "44 pages, 12 figures", "summary": "In Reinforcement Learning (RL), regularization has emerged as a popular tool\nboth in theory and practice, typically based either on an entropy bonus or a\nKullback-Leibler divergence that constrains successive policies. In practice,\nthese approaches have been shown to improve exploration, robustness and\nstability, giving rise to popular Deep RL algorithms such as SAC and TRPO.\nPolicy Mirror Descent (PMD) is a theoretical framework that solves this general\nregularized policy optimization problem, however the closed-form solution\ninvolves the sum of all past Q-functions, which is intractable in practice. We\npropose and analyze PMD-like algorithms that only keep the last $M$ Q-functions\nin memory, and show that for finite and large enough $M$, a convergent\nalgorithm can be derived, introducing no error in the policy update, unlike\nprior deep RL PMD implementations. StaQ, the resulting algorithm, enjoys strong\ntheoretical guarantees and is competitive with deep RL baselines, while\nexhibiting less performance oscillation, paving the way for fully stable deep\nRL algorithms and providing a testbed for experimentation with Policy Mirror\nDescent."}
{"id": "2506.14386", "pdf": "https://arxiv.org/pdf/2506.14386", "abs": "https://arxiv.org/abs/2506.14386", "authors": ["Christian H. X. Ali Mehmeti-Göpel", "Michael Wand"], "title": "ResNets Are Deeper Than You Think", "categories": ["cs.LG", "cs.AI"], "comment": "NeurIPS 2025 Submission", "summary": "Residual connections remain ubiquitous in modern neural network architectures\nnearly a decade after their introduction. Their widespread adoption is often\ncredited to their dramatically improved trainability: residual networks train\nfaster, more stably, and achieve higher accuracy than their feedforward\ncounterparts. While numerous techniques, ranging from improved initialization\nto advanced learning rate schedules, have been proposed to close the\nperformance gap between residual and feedforward networks, this gap has\npersisted. In this work, we propose an alternative explanation: residual\nnetworks do not merely reparameterize feedforward networks, but instead inhabit\na different function space. We design a controlled post-training comparison to\nisolate generalization performance from trainability; we find that\nvariable-depth architectures, similar to ResNets, consistently outperform\nfixed-depth networks, even when optimization is unlikely to make a difference.\nThese results suggest that residual connections confer performance advantages\nbeyond optimization, pointing instead to a deeper inductive bias aligned with\nthe structure of natural data."}
{"id": "2506.13892", "pdf": "https://arxiv.org/pdf/2506.13892", "abs": "https://arxiv.org/abs/2506.13892", "authors": ["Samuel Beaussant", "Mehdi Mounsif"], "title": "Scaling Algorithm Distillation for Continuous Control with Mamba", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "Algorithm Distillation (AD) was recently proposed as a new approach to\nperform In-Context Reinforcement Learning (ICRL) by modeling across-episodic\ntraining histories autoregressively with a causal transformer model. However,\ndue to practical limitations induced by the attention mechanism, experiments\nwere bottlenecked by the transformer's quadratic complexity and limited to\nsimple discrete environments with short time horizons. In this work, we propose\nleveraging the recently proposed Selective Structured State Space Sequence (S6)\nmodels, which achieved state-of-the-art (SOTA) performance on long-range\nsequence modeling while scaling linearly in sequence length. Through four\ncomplex and continuous Meta Reinforcement Learning environments, we demonstrate\nthe overall superiority of Mamba, a model built with S6 layers, over a\ntransformer model for AD. Additionally, we show that scaling AD to very long\ncontexts can improve ICRL performance and make it competitive even with a SOTA\nonline meta RL baseline."}
{"id": "2506.14390", "pdf": "https://arxiv.org/pdf/2506.14390", "abs": "https://arxiv.org/abs/2506.14390", "authors": ["Conrad Orglmeister", "Erik Bochinski", "Volker Eiselein", "Elvira Fleig"], "title": "Enclosing Prototypical Variational Autoencoder for Explainable Out-of-Distribution Detection", "categories": ["cs.LG", "cs.CV"], "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in Computer Safety, Reliability and Security - SAFECOMP 2024\n  Workshops - DECSoS, SASSUR, TOASTS, and WAISE, and is available online at\n  https://doi.org/10.1007/978-3-031-68738-9_29", "summary": "Understanding the decision-making and trusting the reliability of Deep\nMachine Learning Models is crucial for adopting such methods to safety-relevant\napplications. We extend self-explainable Prototypical Variational models with\nautoencoder-based out-of-distribution (OOD) detection: A Variational\nAutoencoder is applied to learn a meaningful latent space which can be used for\ndistance-based classification, likelihood estimation for OOD detection, and\nreconstruction. The In-Distribution (ID) region is defined by a Gaussian\nmixture distribution with learned prototypes representing the center of each\nmode. Furthermore, a novel restriction loss is introduced that promotes a\ncompact ID region in the latent space without collapsing it into single points.\nThe reconstructive capabilities of the Autoencoder ensure the explainability of\nthe prototypes and the ID region of the classifier, further aiding the\ndiscrimination of OOD samples. Extensive evaluations on common OOD detection\nbenchmarks as well as a large-scale dataset from a real-world railway\napplication demonstrate the usefulness of the approach, outperforming previous\nmethods."}
{"id": "2506.13900", "pdf": "https://arxiv.org/pdf/2506.13900", "abs": "https://arxiv.org/abs/2506.13900", "authors": ["Marouane Il Idrissi", "Agathe Fernandes Machado", "Arthur Charpentier"], "title": "Beyond Shapley Values: Cooperative Games for the Interpretation of Machine Learning Models", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Cooperative game theory has become a cornerstone of post-hoc interpretability\nin machine learning, largely through the use of Shapley values. Yet, despite\ntheir widespread adoption, Shapley-based methods often rest on axiomatic\njustifications whose relevance to feature attribution remains debatable. In\nthis paper, we revisit cooperative game theory from an interpretability\nperspective and argue for a broader and more principled use of its tools. We\nhighlight two general families of efficient allocations, the Weber and Harsanyi\nsets, that extend beyond Shapley values and offer richer interpretative\nflexibility. We present an accessible overview of these allocation schemes,\nclarify the distinction between value functions and aggregation rules, and\nintroduce a three-step blueprint for constructing reliable and\ntheoretically-grounded feature attributions. Our goal is to move beyond fixed\naxioms and provide the XAI community with a coherent framework to design\nattribution methods that are both meaningful and robust to shifting\nmethodological trends."}
{"id": "2506.14391", "pdf": "https://arxiv.org/pdf/2506.14391", "abs": "https://arxiv.org/abs/2506.14391", "authors": ["Yaqiao Zhu", "Hongkai Wen", "Geyong Min", "Man Luo"], "title": "HiLight: A Hierarchical Reinforcement Learning Framework with Global Adversarial Guidance for Large-Scale Traffic Signal Control", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Efficient traffic signal control (TSC) is essential for mitigating urban\ncongestion, yet existing reinforcement learning (RL) methods face challenges in\nscaling to large networks while maintaining global coordination. Centralized RL\nsuffers from scalability issues, while decentralized approaches often lack\nunified objectives, resulting in limited network-level efficiency. In this\npaper, we propose HiLight, a hierarchical reinforcement learning framework with\nglobal adversarial guidance for large-scale TSC. HiLight consists of a\nhigh-level Meta-Policy, which partitions the traffic network into subregions\nand generates sub-goals using a Transformer-LSTM architecture, and a low-level\nSub-Policy, which controls individual intersections with global awareness. To\nimprove the alignment between global planning and local execution, we introduce\nan adversarial training mechanism, where the Meta-Policy generates challenging\nyet informative sub-goals, and the Sub-Policy learns to surpass these targets,\nleading to more effective coordination. We evaluate HiLight across both\nsynthetic and real-world benchmarks, and additionally construct a large-scale\nManhattan network with diverse traffic conditions, including peak transitions,\nadverse weather, and holiday surges. Experimental results show that HiLight\nexhibits significant advantages in large-scale scenarios and remains\ncompetitive across standard benchmarks of varying sizes."}
{"id": "2506.13903", "pdf": "https://arxiv.org/pdf/2506.13903", "abs": "https://arxiv.org/abs/2506.13903", "authors": ["Christel Sirocchi", "Damiano Verda"], "title": "Enhancing interpretability of rule-based classifiers through feature graphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "In domains where transparency and trustworthiness are crucial, such as\nhealthcare, rule-based systems are widely used and often preferred over\nblack-box models for decision support systems due to their inherent\ninterpretability. However, as rule-based models grow complex, discerning\ncrucial features, understanding their interactions, and comparing feature\ncontributions across different rule sets becomes challenging. To address this,\nwe propose a comprehensive framework for estimating feature contributions in\nrule-based systems, introducing a graph-based feature visualisation strategy, a\nnovel feature importance metric agnostic to rule-based predictors, and a\ndistance metric for comparing rule sets based on feature contributions. By\nexperimenting on two clinical datasets and four rule-based methods (decision\ntrees, logic learning machines, association rules, and neural networks with\nrule extraction), we showcase our method's capability to uncover novel insights\non the combined predictive value of clinical features, both at the dataset and\nclass-specific levels. These insights can aid in identifying new risk factors,\nsignature genes, and potential biomarkers, and determining the subset of\npatient information that should be prioritised to enhance diagnostic accuracy.\nComparative analysis of the proposed feature importance score with\nstate-of-the-art methods on 15 public benchmarks demonstrates competitive\nperformance and superior robustness. The method implementation is available on\nGitHub: https://github.com/ChristelSirocchi/rule-graph."}
{"id": "2506.14400", "pdf": "https://arxiv.org/pdf/2506.14400", "abs": "https://arxiv.org/abs/2506.14400", "authors": ["Roland Roller", "Michael Hahn", "Ajay Madhavan Ravichandran", "Bilgin Osmanodja", "Florian Oetke", "Zeineb Sassi", "Aljoscha Burchardt", "Klaus Netter", "Klemens Budde", "Anne Herrmann", "Tobias Strapatsas", "Peter Dabrock", "Sebastian Möller"], "title": "One Size Fits None: Rethinking Fairness in Medical AI", "categories": ["cs.LG", "cs.CY"], "comment": "Accepted at the 6th Workshop on Gender Bias in Natural Language\n  Processing at ACL 2025", "summary": "Machine learning (ML) models are increasingly used to support clinical\ndecision-making. However, real-world medical datasets are often noisy,\nincomplete, and imbalanced, leading to performance disparities across patient\nsubgroups. These differences raise fairness concerns, particularly when they\nreinforce existing disadvantages for marginalized groups. In this work, we\nanalyze several medical prediction tasks and demonstrate how model performance\nvaries with patient characteristics. While ML models may demonstrate good\noverall performance, we argue that subgroup-level evaluation is essential\nbefore integrating them into clinical workflows. By conducting a performance\nanalysis at the subgroup level, differences can be clearly identified-allowing,\non the one hand, for performance disparities to be considered in clinical\npractice, and on the other hand, for these insights to inform the responsible\ndevelopment of more effective models. Thereby, our work contributes to a\npractical discussion around the subgroup-sensitive development and deployment\nof medical ML models and the interconnectedness of fairness and transparency."}
{"id": "2506.13909", "pdf": "https://arxiv.org/pdf/2506.13909", "abs": "https://arxiv.org/abs/2506.13909", "authors": ["Xinyuan Tu", "Haocheng Zhang", "Tao Chengxu", "Zuyi Chen"], "title": "Few-Shot Learning for Industrial Time Series: A Comparative Analysis Using the Example of Screw-Fastening Process Monitoring", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Few-shot learning (FSL) has shown promise in vision but remains largely\nunexplored for \\emph{industrial} time-series data, where annotating every new\ndefect is prohibitively expensive. We present a systematic FSL study on\nscrew-fastening process monitoring, using a 2\\,300-sample multivariate torque\ndataset that covers 16 uni- and multi-factorial defect types. Beyond\nbenchmarking, we introduce a \\textbf{label-aware episodic sampler} that\ncollapses multi-label sequences into multiple single-label tasks, keeping the\noutput dimensionality fixed while preserving combinatorial label information.\n  Two FSL paradigms are investigated: the metric-based \\emph{Prototypical\nNetwork} and the gradient-based \\emph{Model-Agnostic Meta-Learning} (MAML),\neach paired with three backbones: 1D CNN, InceptionTime and the 341 M-parameter\ntransformer \\emph{Moment}. On 10-shot, 3-way evaluation, the InceptionTime +\nPrototypical Network combination achieves a \\textbf{0.944 weighted F1} in the\nmulti-class regime and \\textbf{0.935} in the multi-label regime, outperforming\nfinetuned Moment by up to 5.3\\% while requiring two orders of magnitude fewer\nparameters and training time. Across all backbones, metric learning\nconsistently surpasses MAML, and our label-aware sampling yields an additional\n1.7\\% F1 over traditional class-based sampling.\n  These findings challenge the assumption that large foundation models are\nalways superior: when data are scarce, lightweight CNN architectures augmented\nwith simple metric learning not only converge faster but also generalize\nbetter. We release code, data splits and pre-trained weights to foster\nreproducible research and to catalyze the adoption of FSL in high-value\nmanufacturing inspection."}
{"id": "2506.14411", "pdf": "https://arxiv.org/pdf/2506.14411", "abs": "https://arxiv.org/abs/2506.14411", "authors": ["John Wikman", "Alexandre Proutiere", "David Broman"], "title": "Adaptive Reinforcement Learning for Unobservable Random Delays", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "In standard Reinforcement Learning (RL) settings, the interaction between the\nagent and the environment is typically modeled as a Markov Decision Process\n(MDP), which assumes that the agent observes the system state instantaneously,\nselects an action without delay, and executes it immediately. In real-world\ndynamic environments, such as cyber-physical systems, this assumption often\nbreaks down due to delays in the interaction between the agent and the system.\nThese delays can vary stochastically over time and are typically unobservable,\nmeaning they are unknown when deciding on an action. Existing methods deal with\nthis uncertainty conservatively by assuming a known fixed upper bound on the\ndelay, even if the delay is often much lower. In this work, we introduce the\ninteraction layer, a general framework that enables agents to adaptively and\nseamlessly handle unobservable and time-varying delays. Specifically, the agent\ngenerates a matrix of possible future actions to handle both unpredictable\ndelays and lost action packets sent over networks. Building on this framework,\nwe develop a model-based algorithm, Actor-Critic with Delay Adaptation (ACDA),\nwhich dynamically adjusts to delay patterns. Our method significantly\noutperforms state-of-the-art approaches across a wide range of locomotion\nbenchmark environments."}
{"id": "2506.13911", "pdf": "https://arxiv.org/pdf/2506.13911", "abs": "https://arxiv.org/abs/2506.13911", "authors": ["Arie Soeteman", "Balder ten Cate"], "title": "Logical Expressiveness of Graph Neural Networks with Hierarchical Node Individualization", "categories": ["cs.LG", "cs.AI", "cs.LO", "I.2.6; F.2.0"], "comment": "Submitted to NeurIPS 2025, 28 pages, 5 figures", "summary": "We propose and study Hierarchical Ego Graph Neural Networks (HEGNNs), an\nexpressive extension of graph neural networks (GNNs) with hierarchical node\nindividualization, inspired by the Individualization-Refinement paradigm for\ngraph isomorphism testing. HEGNNs generalize subgraph-GNNs and form a hierarchy\nof increasingly expressive models that, in the limit, can distinguish graphs up\nto isomorphism. We provide a logical characterization of HEGNN node\nclassifiers, with and without subgraph restrictions, using graded hybrid logic.\nThis characterization enables us to relate the separating power of HEGNNs to\nthat of higher-order GNNs, GNNs enriched with local homomorphism count\nfeatures, and color refinement algorithms based on\nIndividualization-Refinement. Our experimental results confirm the practical\nfeasibility of HEGNNs and show benefits in comparison with traditional GNN\narchitectures, both with and without local homomorphism count features."}
{"id": "2506.14420", "pdf": "https://arxiv.org/pdf/2506.14420", "abs": "https://arxiv.org/abs/2506.14420", "authors": ["Ting Xiao", "Jiakun Zheng", "Rushuai Yang", "Kang Xu", "Qiaosheng Zhang", "Peng Liu", "Chenjia Bai"], "title": "Unsupervised Skill Discovery through Skill Regions Differentiation", "categories": ["cs.LG"], "comment": null, "summary": "Unsupervised Reinforcement Learning (RL) aims to discover diverse behaviors\nthat can accelerate the learning of downstream tasks. Previous methods\ntypically focus on entropy-based exploration or empowerment-driven skill\nlearning. However, entropy-based exploration struggles in large-scale state\nspaces (e.g., images), and empowerment-based methods with Mutual Information\n(MI) estimations have limitations in state exploration. To address these\nchallenges, we propose a novel skill discovery objective that maximizes the\ndeviation of the state density of one skill from the explored regions of other\nskills, encouraging inter-skill state diversity similar to the initial MI\nobjective. For state-density estimation, we construct a novel conditional\nautoencoder with soft modularization for different skill policies in\nhigh-dimensional space. Meanwhile, to incentivize intra-skill exploration, we\nformulate an intrinsic reward based on the learned autoencoder that resembles\ncount-based exploration in a compact latent space. Through extensive\nexperiments in challenging state and image-based tasks, we find our method\nlearns meaningful skills and achieves superior performance in various\ndownstream tasks."}
{"id": "2506.13923", "pdf": "https://arxiv.org/pdf/2506.13923", "abs": "https://arxiv.org/abs/2506.13923", "authors": ["Vaskar Nath", "Elaine Lau", "Anisha Gunjal", "Manasi Sharma", "Nikhil Baharte", "Sean Hendryx"], "title": "Adaptive Guidance Accelerates Reinforcement Learning of Reasoning Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "We study the process through which reasoning models trained with\nreinforcement learning on verifiable rewards (RLVR) can learn to solve new\nproblems. We find that RLVR drives performance through two main means: (1) by\ncompressing pass@$k$ into pass@1 and (2) via \"capability gain\" in which models\nlearn to solve new problems that they previously could not solve even at high\n$k$. We find that while capability gain exists across model scales, learning to\nsolve new problems is primarily driven through self-distillation. We\ndemonstrate these findings across model scales ranging from 0.5B to 72B on\n>500,000 reasoning problems with prompts and verifiable final answers across\nmath, science, and code domains. We further show that we can significantly\nimprove pass@$k$ rates by leveraging natural language guidance for the model to\nconsider within context while still requiring the model to derive a solution\nchain from scratch. Based of these insights, we derive $\\text{Guide}$ - a new\nclass of online training algorithms. $\\text{Guide}$ adaptively incorporates\nhints into the model's context on problems for which all rollouts were\ninitially incorrect and adjusts the importance sampling ratio for the\n\"off-policy\" trajectories in order to optimize the policy for contexts in which\nthe hints are no longer present. We describe variants of $\\text{Guide}$ for\nGRPO and PPO and empirically show that Guide-GRPO on 7B and 32B parameter\nmodels improves generalization over its vanilla counterpart with up to 4$\\%$\nmacro-average improvement across math benchmarks. We include careful ablations\nto analyze $\\text{Guide}$'s components and theoretically analyze Guide's\nlearning efficiency."}
{"id": "2506.14436", "pdf": "https://arxiv.org/pdf/2506.14436", "abs": "https://arxiv.org/abs/2506.14436", "authors": ["Shen Yuan", "Yin Zheng", "Taifeng Wang", "Binbin Liu", "Hongteng Xu"], "title": "MoORE: SVD-based Model MoE-ization for Conflict- and Oblivion-Resistant Multi-Task Adaptation", "categories": ["cs.LG"], "comment": "23 pages, 6 figures", "summary": "Adapting large-scale foundation models in multi-task scenarios often suffers\nfrom task conflict and oblivion. To mitigate such issues, we propose a novel\n''model MoE-ization'' strategy that leads to a conflict- and oblivion-resistant\nmulti-task adaptation method. Given a weight matrix of a pre-trained model, our\nmethod applies SVD to it and introduces a learnable router to adjust its\nsingular values based on tasks and samples. Accordingly, the weight matrix\nbecomes a Mixture of Orthogonal Rank-one Experts (MoORE), in which each expert\ncorresponds to the outer product of a left singular vector and the\ncorresponding right one. We can improve the model capacity by imposing a\nlearnable orthogonal transform on the right singular vectors. Unlike low-rank\nadaptation (LoRA) and its MoE-driven variants, MoORE guarantees the experts'\northogonality and maintains the column space of the original weight matrix.\nThese two properties make the adapted model resistant to the conflicts among\nthe new tasks and the oblivion of its original tasks, respectively. Experiments\non various datasets demonstrate that MoORE outperforms existing multi-task\nadaptation methods consistently, showing its superiority in terms of conflict-\nand oblivion-resistance. The code of the experiments is available at\nhttps://github.com/DaShenZi721/MoORE."}
{"id": "2506.13958", "pdf": "https://arxiv.org/pdf/2506.13958", "abs": "https://arxiv.org/abs/2506.13958", "authors": ["Leonardo Guiducci", "Antonio Rizzo", "Giovanna Maria Dimitri"], "title": "Toward Explainable Offline RL: Analyzing Representations in Intrinsically Motivated Decision Transformers", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Elastic Decision Transformers (EDTs) have proved to be particularly\nsuccessful in offline reinforcement learning, offering a flexible framework\nthat unifies sequence modeling with decision-making under uncertainty. Recent\nresearch has shown that incorporating intrinsic motivation mechanisms into EDTs\nimproves performance across exploration tasks, yet the representational\nmechanisms underlying these improvements remain unexplored. In this paper, we\nintroduce a systematic post-hoc explainability framework to analyze how\nintrinsic motivation shapes learned embeddings in EDTs. Through statistical\nanalysis of embedding properties (including covariance structure, vector\nmagnitudes, and orthogonality), we reveal that different intrinsic motivation\nvariants create fundamentally different representational structures. Our\nanalysis demonstrates environment-specific correlation patterns between\nembedding metrics and performance that explain why intrinsic motivation\nimproves policy learning. These findings show that intrinsic motivation\noperates beyond simple exploration bonuses, acting as a representational prior\nthat shapes embedding geometry in biologically plausible ways, creating\nenvironment-specific organizational structures that facilitate better\ndecision-making."}
{"id": "2506.14438", "pdf": "https://arxiv.org/pdf/2506.14438", "abs": "https://arxiv.org/abs/2506.14438", "authors": ["Pol Arévalo", "Alexis Molina", "Álvaro Ciudad"], "title": "sHGCN: Simplified hyperbolic graph convolutional neural networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Hyperbolic geometry has emerged as a powerful tool for modeling complex,\nstructured data, particularly where hierarchical or tree-like relationships are\npresent. By enabling embeddings with lower distortion, hyperbolic neural\nnetworks offer promising alternatives to Euclidean-based models for capturing\nintricate data structures. Despite these advantages, they often face\nperformance challenges, particularly in computational efficiency and tasks\nrequiring high precision. In this work, we address these limitations by\nsimplifying key operations within hyperbolic neural networks, achieving notable\nimprovements in both runtime and performance. Our findings demonstrate that\nstreamlined hyperbolic operations can lead to substantial gains in\ncomputational speed and predictive accuracy, making hyperbolic neural networks\na more viable choice for a broader range of applications."}
{"id": "2506.13981", "pdf": "https://arxiv.org/pdf/2506.13981", "abs": "https://arxiv.org/abs/2506.13981", "authors": ["Thanh Dan Bui"], "title": "HAELT: A Hybrid Attentive Ensemble Learning Transformer Framework for High-Frequency Stock Price Forecasting", "categories": ["cs.LG", "cs.AI", "I.2.6; I.5.4; I.6.5; J.4"], "comment": null, "summary": "High-frequency stock price prediction is challenging due to non-stationarity,\nnoise, and volatility. To tackle these issues, we propose the Hybrid Attentive\nEnsemble Learning Transformer (HAELT), a deep learning framework combining a\nResNet-based noise-mitigation module, temporal self-attention for dynamic focus\non relevant history, and a hybrid LSTM-Transformer core that captures both\nlocal and long-range dependencies. These components are adaptively ensembled\nbased on recent performance. Evaluated on hourly Apple Inc. (AAPL) data from\nJan 2024 to May 2025, HAELT achieves the highest F1-Score on the test set,\neffectively identifying both upward and downward price movements. This\ndemonstrates HAELT's potential for robust, practical financial forecasting and\nalgorithmic trading."}
{"id": "2506.14439", "pdf": "https://arxiv.org/pdf/2506.14439", "abs": "https://arxiv.org/abs/2506.14439", "authors": ["Rikiya Takehi", "Masahiro Asami", "Kosuke Kawakami", "Yuta Saito"], "title": "A General Framework for Off-Policy Learning with Partially-Observed Reward", "categories": ["cs.LG", "62L05, 68T05", "I.2.6; G.3"], "comment": "10 pages, 5 figures. Published as a conference paper at ICLR 2025", "summary": "Off-policy learning (OPL) in contextual bandits aims to learn a\ndecision-making policy that maximizes the target rewards by using only\nhistorical interaction data collected under previously developed policies.\nUnfortunately, when rewards are only partially observed, the effectiveness of\nOPL degrades severely. Well-known examples of such partial rewards include\nexplicit ratings in content recommendations, conversion signals on e-commerce\nplatforms that are partial due to delay, and the issue of censoring in medical\nproblems. One possible solution to deal with such partial rewards is to use\nsecondary rewards, such as dwelling time, clicks, and medical indicators, which\nare more densely observed. However, relying solely on such secondary rewards\ncan also lead to poor policy learning since they may not align with the target\nreward. Thus, this work studies a new and general problem of OPL where the goal\nis to learn a policy that maximizes the expected target reward by leveraging\ndensely observed secondary rewards as supplemental data. We then propose a new\nmethod called Hybrid Policy Optimization for Partially-Observed Reward (HyPeR),\nwhich effectively uses the secondary rewards in addition to the\npartially-observed target reward to achieve effective OPL despite the\nchallenging scenario. We also discuss a case where we aim to optimize not only\nthe expected target reward but also the expected secondary rewards to some\nextent; counter-intuitively, we will show that leveraging the two objectives is\nin fact advantageous also for the optimization of only the target reward. Along\nwith statistical analysis of our proposed methods, empirical evaluations on\nboth synthetic and real-world data show that HyPeR outperforms existing methods\nin various scenarios."}
{"id": "2506.13984", "pdf": "https://arxiv.org/pdf/2506.13984", "abs": "https://arxiv.org/abs/2506.13984", "authors": ["Andrzej Cichocki"], "title": "Mirror Descent Using the Tempesta Generalized Multi-parametric Logarithms", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "In this paper, we develop a wide class Mirror Descent (MD) algorithms, which\nplay a key role in machine learning. For this purpose we formulated the\nconstrained optimization problem, in which we exploits the Bregman divergence\nwith the Tempesta multi-parametric deformation logarithm as a link function.\nThis link function called also mirror function defines the mapping between the\nprimal and dual spaces and is associated with a very-wide (in fact,\ntheoretically infinite) class of generalized trace-form entropies. In order to\nderive novel MD updates, we estimate generalized exponential function, which\nclosely approximates the inverse of the multi-parametric Tempesta generalized\nlogarithm. The shape and properties of the Tempesta logarithm and its\ninverse-deformed exponential functions can be tuned by several hyperparameters.\nBy learning these hyperparameters, we can adapt to distribution or geometry of\ntraining data, and we can adjust them to achieve desired properties of MD\nalgorithms. The concept of applying multi-parametric logarithms allow us to\ngenerate a new wide and flexible family of MD and mirror-less MD updates."}
{"id": "2506.14449", "pdf": "https://arxiv.org/pdf/2506.14449", "abs": "https://arxiv.org/abs/2506.14449", "authors": ["Lucas Kreiss", "Amey Chaware", "Maryam Roohian", "Sarah Lemire", "Oana-Maria Thoma", "Birgitta Carlé", "Maximilian Waldner", "Sebastian Schürmann", "Oliver Friedrich", "Roarke Horstmeyer"], "title": "Detecting immune cells with label-free two-photon autofluorescence and deep learning", "categories": ["cs.LG", "physics.optics"], "comment": null, "summary": "Label-free imaging has gained broad interest because of its potential to omit\nelaborate staining procedures which is especially relevant for in vivo use.\nLabel-free multiphoton microscopy (MPM), for instance, exploits two-photon\nexcitation of natural autofluorescence (AF) from native, metabolic proteins,\nmaking it ideal for in vivo endomicroscopy. Deep learning (DL) models have been\nwidely used in other optical imaging technologies to predict specific target\nannotations and thereby digitally augment the specificity of these label-free\nimages. However, this computational specificity has only rarely been\nimplemented for MPM. In this work, we used a data set of label-free MPM images\nfrom a series of different immune cell types (5,075 individual cells for binary\nclassification in mixed samples and 3,424 cells for a multi-class\nclassification task) and trained a convolutional neural network (CNN) to\nclassify cell types based on this label-free AF as input. A low-complexity\nsqueezeNet architecture was able to achieve reliable immune cell classification\nresults (0.89 ROC-AUC, 0.95 PR-AUC, for binary classification in mixed samples;\n0.689 F1 score, 0.697 precision, 0.748 recall, and 0.683 MCC for six-class\nclassification in isolated samples). Perturbation tests confirmed that the\nmodel is not confused by extracellular environment and that both input AF\nchannels (NADH and FAD) are about equally important to the classification. In\nthe future, such predictive DL models could directly detect specific immune\ncells in unstained images and thus, computationally improve the specificity of\nlabel-free MPM which would have great potential for in vivo endomicroscopy."}
{"id": "2506.13992", "pdf": "https://arxiv.org/pdf/2506.13992", "abs": "https://arxiv.org/abs/2506.13992", "authors": ["An Luo", "Xun Xian", "Jin Du", "Fangqiao Tian", "Ganghua Wang", "Ming Zhong", "Shengchun Zhao", "Xuan Bi", "Zirui Liu", "Jiawei Zhou", "Jayanth Srinivasa", "Ashish Kundu", "Charles Fleming", "Mingyi Hong", "Jie Ding"], "title": "AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ME", "62-07, 62-08, 68T05, 68T07, 68T01, 68T50", "I.2.0; I.2.6; I.2.7; I.5.1; I.5.4; H.2.8; G.3"], "comment": null, "summary": "Large language models (LLMs) have advanced the automation of data science\nworkflows. Yet it remains unclear whether they can critically leverage external\ndomain knowledge as human data scientists do in practice. To answer this\nquestion, we introduce AssistedDS (Assisted Data Science), a benchmark designed\nto systematically evaluate how LLMs handle domain knowledge in tabular\nprediction tasks. AssistedDS features both synthetic datasets with explicitly\nknown generative mechanisms and real-world Kaggle competitions, each\naccompanied by curated bundles of helpful and adversarial documents. These\ndocuments provide domain-specific insights into data cleaning, feature\nengineering, and model selection. We assess state-of-the-art LLMs on their\nability to discern and apply beneficial versus harmful domain knowledge,\nevaluating submission validity, information recall, and predictive performance.\nOur results demonstrate three key findings: (1) LLMs frequently exhibit an\nuncritical adoption of provided information, significantly impairing their\npredictive performance when adversarial content is introduced, (2) helpful\nguidance is often insufficient to counteract the negative influence of\nadversarial information, and (3) in Kaggle datasets, LLMs often make errors in\nhandling time-series data, applying consistent feature engineering across\ndifferent folds, and interpreting categorical variables correctly. These\nfindings highlight a substantial gap in current models' ability to critically\nevaluate and leverage expert knowledge, underscoring an essential research\ndirection for developing more robust, knowledge-aware automated data science\nsystems."}
{"id": "2506.14457", "pdf": "https://arxiv.org/pdf/2506.14457", "abs": "https://arxiv.org/abs/2506.14457", "authors": ["Freya Behrens", "Lenka Zdeborová"], "title": "Dataset distillation for memorized data: Soft labels can leak held-out teacher knowledge", "categories": ["cs.LG"], "comment": "9 pages, 21 figures", "summary": "Dataset distillation aims to compress training data into fewer examples via a\nteacher, from which a student can learn effectively. While its success is often\nattributed to structure in the data, modern neural networks also memorize\nspecific facts, but if and how such memorized information is can transferred in\ndistillation settings remains less understood. In this work, we show that\nstudents trained on soft labels from teachers can achieve non-trivial accuracy\non held-out memorized data they never directly observed. This effect persists\non structured data when the teacher has not generalized.To analyze it in\nisolation, we consider finite random i.i.d. datasets where generalization is a\npriori impossible and a successful teacher fit implies pure memorization.\nStill, students can learn non-trivial information about the held-out data, in\nsome cases up to perfect accuracy. In those settings, enough soft labels are\navailable to recover the teacher functionally - the student matches the\nteacher's predictions on all possible inputs, including the held-out memorized\ndata. We show that these phenomena strongly depend on the temperature with\nwhich the logits are smoothed, but persist across varying network capacities,\narchitectures and dataset compositions."}
{"id": "2506.14002", "pdf": "https://arxiv.org/pdf/2506.14002", "abs": "https://arxiv.org/abs/2506.14002", "authors": ["Siyu Chen", "Heejune Sheen", "Xuyuan Xiong", "Tianhao Wang", "Zhuoran Yang"], "title": "Taming Polysemanticity in LLMs: Provable Feature Recovery via Sparse Autoencoders", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ML", "I.2.6"], "comment": "136 pages, 21 figures", "summary": "We study the challenge of achieving theoretically grounded feature recovery\nusing Sparse Autoencoders (SAEs) for the interpretation of Large Language\nModels. Existing SAE training algorithms often lack rigorous mathematical\nguarantees and suffer from practical limitations such as hyperparameter\nsensitivity and instability. To address these issues, we first propose a novel\nstatistical framework for the feature recovery problem, which includes a new\nnotion of feature identifiability by modeling polysemantic features as sparse\nmixtures of underlying monosemantic concepts. Building on this framework, we\nintroduce a new SAE training algorithm based on ``bias adaptation'', a\ntechnique that adaptively adjusts neural network bias parameters to ensure\nappropriate activation sparsity. We theoretically \\highlight{prove that this\nalgorithm correctly recovers all monosemantic features} when input data is\nsampled from our proposed statistical model. Furthermore, we develop an\nimproved empirical variant, Group Bias Adaptation (GBA), and\n\\highlight{demonstrate its superior performance against benchmark methods when\napplied to LLMs with up to 1.5 billion parameters}. This work represents a\nfoundational step in demystifying SAE training by providing the first SAE\nalgorithm with theoretical recovery guarantees, thereby advancing the\ndevelopment of more transparent and trustworthy AI systems through enhanced\nmechanistic interpretability."}
{"id": "2506.14459", "pdf": "https://arxiv.org/pdf/2506.14459", "abs": "https://arxiv.org/abs/2506.14459", "authors": ["Md. Mortuza Ahmmed", "Abdullah Al Noman", "Mahin Montasir Afif", "K. M. Tahsin Kabir", "Md. Mostafizur Rahman", "Mufti Mahmud"], "title": "A Model-Mediated Stacked Ensemble Approach for Depression Prediction Among Professionals", "categories": ["cs.LG"], "comment": null, "summary": "Depression is a significant mental health concern, particularly in\nprofessional environments where work-related stress, financial pressure, and\nlifestyle imbalances contribute to deteriorating well-being. Despite increasing\nawareness, researchers and practitioners face critical challenges in developing\naccurate and generalizable predictive models for mental health disorders.\nTraditional classification approaches often struggle with the complexity of\ndepression, as it is influenced by multifaceted, interdependent factors,\nincluding occupational stress, sleep patterns, and job satisfaction. This study\naddresses these challenges by proposing a stacking-based ensemble learning\napproach to improve the predictive accuracy of depression classification among\nprofessionals. The Depression Professional Dataset has been collected from\nKaggle. The dataset comprises demographic, occupational, and lifestyle\nattributes that influence mental well-being. Our stacking model integrates\nmultiple base learners with a logistic regression-mediated model, effectively\ncapturing diverse learning patterns. The experimental results demonstrate that\nthe proposed model achieves high predictive performance, with an accuracy of\n99.64% on training data and 98.75% on testing data, with precision, recall, and\nF1-score all exceeding 98%. These findings highlight the effectiveness of\nensemble learning in mental health analytics and underscore its potential for\nearly detection and intervention strategies."}
{"id": "2506.14020", "pdf": "https://arxiv.org/pdf/2506.14020", "abs": "https://arxiv.org/abs/2506.14020", "authors": ["Keyue Jiang", "Jiahao Cui", "Xiaowen Dong", "Laura Toni"], "title": "Bures-Wasserstein Flow Matching for Graph Generation", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Graph generation has emerged as a critical task in fields ranging from\nmolecule design to drug discovery. Contemporary approaches, notably diffusion\nand flow-based models, have achieved solid graph generative performance through\nconstructing a probability path that interpolates between a reference\ndistribution and the data distribution. However, these methods typically model\nthe evolution of individual nodes and edges independently and use linear\ninterpolations to build the path assuming that the data lie in Euclidean space.\nWe show that this is suboptimal given the intrinsic non-Euclidean structure and\ninterconnected patterns of graphs, and it poses risks to the sampling\nconvergence. To build a better probability path, we model the joint evolution\nof the nodes and edges by representing graphs as connected systems\nparameterized by Markov random fields (MRF). We then leverage the optimal\ntransport displacement between MRF objects to design the probability path for\ngraph generation. Based on this, we introduce BWFlow, a flow-matching framework\nfor graph generation that respects the underlying geometry of graphs and\nprovides smooth velocities in the probability path. The novel framework can be\nadapted to both continuous and discrete flow-matching algorithms. Experimental\nevaluations in plain graph generation and 2D/3D molecule generation validate\nthe effectiveness of BWFlow in graph generation with competitive performance,\nstable training, and guaranteed sampling convergence."}
{"id": "2506.14460", "pdf": "https://arxiv.org/pdf/2506.14460", "abs": "https://arxiv.org/abs/2506.14460", "authors": ["Junbin Qiu", "Zhengpeng Xie", "Xiangda Yan", "Yongjie Yang", "Yao Shu"], "title": "Zeroth-Order Optimization is Secretly Single-Step Policy Optimization", "categories": ["cs.LG"], "comment": null, "summary": "Zeroth-Order Optimization (ZOO) provides powerful tools for optimizing\nfunctions where explicit gradients are unavailable or expensive to compute.\nHowever, the underlying mechanisms of popular ZOO methods, particularly those\nemploying randomized finite differences, and their connection to other\noptimization paradigms like Reinforcement Learning (RL) are not fully\nelucidated. This paper establishes a fundamental and previously unrecognized\nconnection: ZOO with finite differences is equivalent to a specific instance of\nsingle-step Policy Optimization (PO). We formally unveil that the implicitly\nsmoothed objective function optimized by common ZOO algorithms is identical to\na single-step PO objective. Furthermore, we show that widely used ZOO gradient\nestimators, are mathematically equivalent to the REINFORCE gradient estimator\nwith a specific baseline function, revealing the variance-reducing mechanism in\nZOO from a PO perspective.Built on this unified framework, we propose ZoAR\n(Zeroth-Order Optimization with Averaged Baseline and Query Reuse), a novel ZOO\nalgorithm incorporating PO-inspired variance reduction techniques: an averaged\nbaseline from recent evaluations and query reuse analogous to experience\nreplay. Our theoretical analysis further substantiates these techniques reduce\nvariance and enhance convergence. Extensive empirical studies validate our\ntheory and demonstrate that ZoAR significantly outperforms other methods in\nterms of convergence speed and final performance. Overall, our work provides a\nnew theoretical lens for understanding ZOO and offers practical algorithmic\nimprovements derived from its connection to PO."}
{"id": "2506.14054", "pdf": "https://arxiv.org/pdf/2506.14054", "abs": "https://arxiv.org/abs/2506.14054", "authors": ["Joshua Fan", "Haodi Xu", "Feng Tao", "Md Nasim", "Marc Grimson", "Yiqi Luo", "Carla P. Gomes"], "title": "Scientifically-Interpretable Reasoning Network (ScIReN): Uncovering the Black-Box of Nature", "categories": ["cs.LG", "cs.AI"], "comment": "28 pages, 9 figures, submitted to NeurIPS 2025", "summary": "Neural networks are a powerful tool for learning patterns from data. However,\nthey do not respect known scientific laws, nor can they reveal novel scientific\ninsights due to their black-box nature. In contrast, scientific reasoning\ndistills biological or physical principles from observations and controlled\nexperiments, and quantitatively interprets them with process-based models made\nof mathematical equations. Yet, process-based models rely on numerous free\nparameters that must be set in an ad-hoc manner, and thus often fit\nobservations poorly in cross-scale predictions. While prior work has embedded\nprocess-based models in conventional neural networks, discovering interpretable\nrelationships between parameters in process-based models and input features is\nstill a grand challenge for scientific discovery. We thus propose\nScientifically-Interpretable Reasoning Network (ScIReN), a fully-transparent\nframework that combines interpretable neural and process-based reasoning. An\ninterpretable encoder predicts scientifically-meaningful latent parameters,\nwhich are then passed through a differentiable process-based decoder to predict\nlabeled output variables. ScIReN also uses a novel hard-sigmoid constraint\nlayer to restrict latent parameters to meaningful ranges defined by scientific\nprior knowledge, further enhancing its interpretability. While the embedded\nprocess-based model enforces established scientific knowledge, the encoder\nreveals new scientific mechanisms and relationships hidden in conventional\nblack-box models. We apply ScIReN on two tasks: simulating the flow of organic\ncarbon through soils, and modeling ecosystem respiration from plants. In both\ntasks, ScIReN outperforms black-box networks in predictive accuracy while\nproviding substantial scientific interpretability -- it can infer latent\nscientific mechanisms and their relationships with input features."}
{"id": "2506.14472", "pdf": "https://arxiv.org/pdf/2506.14472", "abs": "https://arxiv.org/abs/2506.14472", "authors": ["Fabien Bernier", "Maxime Cordy", "Yves Le Traon"], "title": "Leveraging External Factors in Household-Level Electrical Consumption Forecasting using Hypernetworks", "categories": ["cs.LG", "cs.AI"], "comment": "ECML PKDD 2025", "summary": "Accurate electrical consumption forecasting is crucial for efficient energy\nmanagement and resource allocation. While traditional time series forecasting\nrelies on historical patterns and temporal dependencies, incorporating external\nfactors -- such as weather indicators -- has shown significant potential for\nimproving prediction accuracy in complex real-world applications. However, the\ninclusion of these additional features often degrades the performance of global\npredictive models trained on entire populations, despite improving individual\nhousehold-level models. To address this challenge, we found that a hypernetwork\narchitecture can effectively leverage external factors to enhance the accuracy\nof global electrical consumption forecasting models, by specifically adjusting\nthe model weights to each consumer.\n  We collected a comprehensive dataset spanning two years, comprising\nconsumption data from over 6000 luxembourgish households and corresponding\nexternal factors such as weather indicators, holidays, and major local events.\nBy comparing various forecasting models, we demonstrate that a hypernetwork\napproach outperforms existing methods when associated to external factors,\nreducing forecasting errors and achieving the best accuracy while maintaining\nthe benefits of a global model."}
{"id": "2506.14098", "pdf": "https://arxiv.org/pdf/2506.14098", "abs": "https://arxiv.org/abs/2506.14098", "authors": ["Ziyuan Tang", "Jie Chen"], "title": "Toward a Graph Foundation Model: Pre-Training Transformers With Random Walks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "A foundation model like GPT elicits many emergent abilities, owing to the\npre-training with broad inclusion of data and the use of the powerful\nTransformer architecture. While foundation models in natural languages are\nprevalent, can we build similar models for graphs? This paper describes an\napproach toward a graph foundation model that is pre-trained with diverse graph\ndatasets by adapting the Transformer backbone. A central challenge toward this\nend is how a sequence model encodes graphs of varying sizes and from different\ndomains. We propose representing a node as multiple random walks, such that the\nTransformer can extract node representations from sequences, which in turn form\nedge and graph representations. We develop a novel context prediction loss for\nthese random walks and theoretically analyze their expressive power in\ndistinguishing neighborhoods and graphs. We also demonstrate the pre-training\nof our model and its adaptation to downstream tasks, showcasing its potential\nas a foundation for processing and reasoning with graph-structured data."}
{"id": "2506.14515", "pdf": "https://arxiv.org/pdf/2506.14515", "abs": "https://arxiv.org/abs/2506.14515", "authors": ["Prabhav Sanga", "Jaskaran Singh", "Arun K. Dubey"], "title": "Train Once, Forget Precisely: Anchored Optimization for Efficient Post-Hoc Unlearning", "categories": ["cs.LG", "cs.CV"], "comment": "Accepted at ICML MUGen'25", "summary": "As machine learning systems increasingly rely on data subject to privacy\nregulation, selectively unlearning specific information from trained models has\nbecome essential. In image classification, this involves removing the influence\nof particular training samples, semantic classes, or visual styles without full\nretraining. We introduce \\textbf{Forget-Aligned Model Reconstruction (FAMR)}, a\ntheoretically grounded and computationally efficient framework for post-hoc\nunlearning in deep image classifiers. FAMR frames forgetting as a constrained\noptimization problem that minimizes a uniform-prediction loss on the forget set\nwhile anchoring model parameters to their original values via an $\\ell_2$\npenalty. A theoretical analysis links FAMR's solution to\ninfluence-function-based retraining approximations, with bounds on parameter\nand output deviation. Empirical results on class forgetting tasks using\nCIFAR-10 and ImageNet-100 demonstrate FAMR's effectiveness, with strong\nperformance retention and minimal computational overhead. The framework\ngeneralizes naturally to concept and style erasure, offering a scalable and\ncertifiable route to efficient post-hoc forgetting in vision models."}
{"id": "2506.14113", "pdf": "https://arxiv.org/pdf/2506.14113", "abs": "https://arxiv.org/abs/2506.14113", "authors": ["Yitian Zhang", "Liheng Ma", "Antonios Valkanas", "Boris N. Oreshkin", "Mark Coates"], "title": "SKOLR: Structured Koopman Operator Linear RNN for Time-Series Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Koopman operator theory provides a framework for nonlinear dynamical system\nanalysis and time-series forecasting by mapping dynamics to a space of\nreal-valued measurement functions, enabling a linear operator representation.\nDespite the advantage of linearity, the operator is generally\ninfinite-dimensional. Therefore, the objective is to learn measurement\nfunctions that yield a tractable finite-dimensional Koopman operator\napproximation. In this work, we establish a connection between Koopman operator\napproximation and linear Recurrent Neural Networks (RNNs), which have recently\ndemonstrated remarkable success in sequence modeling. We show that by\nconsidering an extended state consisting of lagged observations, we can\nestablish an equivalence between a structured Koopman operator and linear RNN\nupdates. Building on this connection, we present SKOLR, which integrates a\nlearnable spectral decomposition of the input signal with a multilayer\nperceptron (MLP) as the measurement functions and implements a structured\nKoopman operator via a highly parallel linear RNN stack. Numerical experiments\non various forecasting benchmarks and dynamical systems show that this\nstreamlined, Koopman-theory-based design delivers exceptional performance."}
{"id": "2506.14518", "pdf": "https://arxiv.org/pdf/2506.14518", "abs": "https://arxiv.org/abs/2506.14518", "authors": ["Elif Yılmaz", "Christos Dimitrakakis"], "title": "Two-Player Zero-Sum Games with Bandit Feedback", "categories": ["cs.LG", "cs.GT"], "comment": null, "summary": "We study a two-player zero-sum game (TPZSG) in which the row player aims to\nmaximize their payoff against an adversarial column player, under an unknown\npayoff matrix estimated through bandit feedback. We propose and analyze two\nalgorithms: ETC-TPZSG, which directly applies ETC to the TPZSG setting and\nETC-TPZSG-AE, which improves upon it by incorporating an action pair\nelimination (AE) strategy that leverages the $\\varepsilon$-Nash Equilibrium\nproperty to efficiently select the optimal action pair. Our objective is to\ndemonstrate the applicability of ETC in a TPZSG setting by focusing on learning\npure strategy Nash Equilibrium. A key contribution of our work is a derivation\nof instance-dependent upper bounds on the expected regret for both algorithms,\nhas received limited attention in the literature on zero-sum games.\nParticularly, after $T$ rounds, we achieve an instance-dependent regret upper\nbounds of $O(\\Delta + \\sqrt{T})$ for ETC-TPZSG and $O(\\frac{\\log (T\n\\Delta^2)}{\\Delta})$ for ETC-TPZSG-AE, where $\\Delta$ denotes the suboptimality\ngap. Therefore, our results indicate that ETC-based algorithms perform\neffectively in adversarial game settings, achieving regret bounds comparable to\nexisting methods while providing insights through instance-dependent analysis."}
{"id": "2506.14122", "pdf": "https://arxiv.org/pdf/2506.14122", "abs": "https://arxiv.org/abs/2506.14122", "authors": ["Tianming Zhang", "Renbo Zhang", "Zhengyi Yang", "Yunjun Gao", "Bin Cao", "Jing Fan"], "title": "CLGNN: A Contrastive Learning-based GNN Model for Betweenness Centrality Prediction on Temporal Graphs", "categories": ["cs.LG", "cs.AI", "I.2.6; G.2.2; I.5.1"], "comment": null, "summary": "Temporal Betweenness Centrality (TBC) measures how often a node appears on\noptimal temporal paths, reflecting its importance in temporal networks.\nHowever, exact computation is highly expensive, and real-world TBC\ndistributions are extremely imbalanced. The severe imbalance leads\nlearning-based models to overfit to zero-centrality nodes, resulting in\ninaccurate TBC predictions and failure to identify truly central nodes.\nExisting graph neural network (GNN) methods either fail to handle such\nimbalance or ignore temporal dependencies altogether. To address these issues,\nwe propose a scalable and inductive contrastive learning-based GNN (CLGNN) for\naccurate and efficient TBC prediction. CLGNN builds an instance graph to\npreserve path validity and temporal order, then encodes structural and temporal\nfeatures using dual aggregation, i.e., mean and edge-to-node multi-head\nattention mechanisms, enhanced by temporal path count and time encodings. A\nstability-based clustering-guided contrastive module (KContrastNet) is\nintroduced to separate high-, median-, and low-centrality nodes in\nrepresentation space, mitigating class imbalance, while a regression module\n(ValueNet) estimates TBC values. CLGNN also supports multiple optimal path\ndefinitions to accommodate diverse temporal semantics. Extensive experiments\ndemonstrate the effectiveness and efficiency of CLGNN across diverse\nbenchmarks. CLGNN achieves up to a 663.7~$\\times$ speedup compared to\nstate-of-the-art exact TBC computation methods. It outperforms leading static\nGNN baselines with up to 31.4~$\\times$ lower MAE and 16.7~$\\times$ higher\nSpearman correlation, and surpasses state-of-the-art temporal GNNs with up to\n5.7~$\\times$ lower MAE and 3.9~$\\times$ higher Spearman correlation."}
{"id": "2506.14521", "pdf": "https://arxiv.org/pdf/2506.14521", "abs": "https://arxiv.org/abs/2506.14521", "authors": ["Korbinian Pfab", "Marcel Rothering"], "title": "Towards Improved Research Methodologies for Industrial AI: A case study of false call reduction", "categories": ["cs.LG", "I.2"], "comment": "Submitted and accepted to IEEE COMPSAC 2025", "summary": "Are current artificial intelligence (AI) research methodologies ready to\ncreate successful, productive, and profitable AI applications? This work\npresents a case study on an industrial AI use case called false call reduction\nfor automated optical inspection to demonstrate the shortcomings of current\nbest practices. We identify seven weaknesses prevalent in related peer-reviewed\nwork and experimentally show their consequences. We show that the best-practice\nmethodology would fail for this use case. We argue amongst others for the\nnecessity of requirement-aware metrics to ensure achieving business objectives,\nclear definitions of success criteria, and a thorough analysis of temporal\ndynamics in experimental datasets. Our work encourages researchers to\ncritically assess their methodologies for more successful applied AI research."}
{"id": "2506.14126", "pdf": "https://arxiv.org/pdf/2506.14126", "abs": "https://arxiv.org/abs/2506.14126", "authors": ["Stefan Horoi", "Guy Wolf", "Eugene Belilovsky", "Gintare Karolina Dziugaite"], "title": "Less is More: Undertraining Experts Improves Model Upcycling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Modern deep learning is increasingly characterized by the use of open-weight\nfoundation models that can be fine-tuned on specialized datasets. This has led\nto a proliferation of expert models and adapters, often shared via platforms\nlike HuggingFace and AdapterHub. To leverage these resources, numerous model\nupcycling methods have emerged, enabling the reuse of fine-tuned models in\nmulti-task systems. A natural pipeline has thus formed to harness the benefits\nof transfer learning and amortize sunk training costs: models are pre-trained\non general data, fine-tuned on specific tasks, and then upcycled into more\ngeneral-purpose systems. A prevailing assumption is that improvements at one\nstage of this pipeline propagate downstream, leading to gains at subsequent\nsteps. In this work, we challenge that assumption by examining how expert\nfine-tuning affects model upcycling. We show that long fine-tuning of experts\nthat optimizes for their individual performance leads to degraded merging\nperformance, both for fully fine-tuned and LoRA-adapted models, and to worse\ndownstream results when LoRA adapters are upcycled into MoE layers. We trace\nthis degradation to the memorization of a small set of difficult examples that\ndominate late fine-tuning steps and are subsequently forgotten during merging.\nFinally, we demonstrate that a task-dependent aggressive early stopping\nstrategy can significantly improve upcycling performance."}
{"id": "2506.14529", "pdf": "https://arxiv.org/pdf/2506.14529", "abs": "https://arxiv.org/abs/2506.14529", "authors": ["Xiaohan Zheng", "Lanning Wei", "Yong Li", "Quanming Yao"], "title": "Automated Decision-Making on Networks with LLMs through Knowledge-Guided Evolution", "categories": ["cs.LG"], "comment": null, "summary": "Effective decision-making on networks often relies on learning from\ngraph-structured data, where Graph Neural Networks (GNNs) play a central role,\nbut they take efforts to configure and tune. In this demo, we propose LLMNet,\nshowing how to design GNN automated through Large Language Models. Our system\ndevelops a set of agents that construct graph-related knowlege bases and then\nleverages Retrieval-Augmented Generation (RAG) to support automated\nconfiguration and refinement of GNN models through a knowledge-guided evolution\nprocess. These agents, equipped with specialized knowledge bases, extract\ninsights into tasks and graph structures by interacting with the knowledge\nbases. Empirical results show LLMNet excels in twelve datasets across three\ngraph learning tasks, validating its effectiveness of GNN model designing."}
{"id": "2506.14202", "pdf": "https://arxiv.org/pdf/2506.14202", "abs": "https://arxiv.org/abs/2506.14202", "authors": ["Makoto Shing", "Takuya Akiba"], "title": "DiffusionBlocks: Blockwise Training for Generative Models via Score-Based Diffusion", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": "To appear at TTODLer-FM Workshop of the 42nd International Conference\n  on Machine Learning", "summary": "Training large neural networks with end-to-end backpropagation creates\nsignificant memory bottlenecks, limiting accessibility to state-of-the-art AI\nresearch. We propose $\\textit{DiffusionBlocks}$, a novel training framework\nthat interprets neural network blocks as performing denoising operations in a\ncontinuous-time diffusion process. By partitioning the network into\nindependently trainable blocks and optimizing noise level assignments based on\nequal cumulative probability mass, our approach achieves significant memory\nefficiency while maintaining competitive performance compared to traditional\nbackpropagation in generative tasks. Experiments on image generation and\nlanguage modeling tasks demonstrate memory reduction proportional to the number\nof blocks while achieving superior performance. DiffusionBlocks provides a\npromising pathway for democratizing access to large-scale neural network\ntraining with limited computational resources."}
{"id": "2506.14540", "pdf": "https://arxiv.org/pdf/2506.14540", "abs": "https://arxiv.org/abs/2506.14540", "authors": ["Gerardo A. Flores", "Alyssa H. Smith", "Julia A. Fukuyama", "Ashia C. Wilson"], "title": "Aligning Evaluation with Clinical Priorities: Calibration, Label Shift, and Error Costs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Machine learning-based decision support systems are increasingly deployed in\nclinical settings, where probabilistic scoring functions are used to inform and\nprioritize patient management decisions. However, widely used scoring rules,\nsuch as accuracy and AUC-ROC, fail to adequately reflect key clinical\npriorities, including calibration, robustness to distributional shifts, and\nsensitivity to asymmetric error costs. In this work, we propose a principled\nyet practical evaluation framework for selecting calibrated thresholded\nclassifiers that explicitly accounts for the uncertainty in class prevalences\nand domain-specific cost asymmetries often found in clinical settings. Building\non the theory of proper scoring rules, particularly the Schervish\nrepresentation, we derive an adjusted variant of cross-entropy (log score) that\naverages cost-weighted performance over clinically relevant ranges of class\nbalance. The resulting evaluation is simple to apply, sensitive to clinical\ndeployment conditions, and designed to prioritize models that are both\ncalibrated and robust to real-world variations."}
{"id": "2506.14217", "pdf": "https://arxiv.org/pdf/2506.14217", "abs": "https://arxiv.org/abs/2506.14217", "authors": ["Dipesh Tharu Mahato", "Rohan Poudel", "Pramod Dhungana"], "title": "TriGuard: Testing Model Safety with Attribution Entropy, Verification, and Drift", "categories": ["cs.LG", "cs.AI"], "comment": "12 pages, 6 tables, 6 figures", "summary": "Deep neural networks often achieve high accuracy, but ensuring their\nreliability under adversarial and distributional shifts remains a pressing\nchallenge. We propose TriGuard, a unified safety evaluation framework that\ncombines (1) formal robustness verification, (2) attribution entropy to\nquantify saliency concentration, and (3) a novel Attribution Drift Score\nmeasuring explanation stability. TriGuard reveals critical mismatches between\nmodel accuracy and interpretability: verified models can still exhibit unstable\nreasoning, and attribution-based signals provide complementary safety insights\nbeyond adversarial accuracy. Extensive experiments across three datasets and\nfive architectures show how TriGuard uncovers subtle fragilities in neural\nreasoning. We further demonstrate that entropy-regularized training reduces\nexplanation drift without sacrificing performance. TriGuard advances the\nfrontier in robust, interpretable model evaluation."}
{"id": "2506.14563", "pdf": "https://arxiv.org/pdf/2506.14563", "abs": "https://arxiv.org/abs/2506.14563", "authors": ["Jesse St. Amand", "Leonardo Gizzi", "Martin A. Giese"], "title": "Single-Example Learning in a Mixture of GPDMs with Latent Geometries", "categories": ["cs.LG"], "comment": "13 pages, 2 figures, 3 tables", "summary": "We present the Gaussian process dynamical mixture model (GPDMM) and show its\nutility in single-example learning of human motion data. The Gaussian process\ndynamical model (GPDM) is a form of the Gaussian process latent variable model\n(GPLVM), but optimized with a hidden Markov model dynamical prior. The GPDMM\ncombines multiple GPDMs in a probabilistic mixture-of-experts framework,\nutilizing embedded geometric features to allow for diverse sequences to be\nencoded in a single latent space, enabling the categorization and generation of\neach sequence class. GPDMs and our mixture model are particularly advantageous\nin addressing the challenges of modeling human movement in scenarios where data\nis limited and model interpretability is vital, such as in patient-specific\nmedical applications like prosthesis control. We score the GPDMM on\nclassification accuracy and generative ability in single-example learning,\nshowcase model variations, and benchmark it against LSTMs, VAEs, and\ntransformers."}
{"id": "2506.14262", "pdf": "https://arxiv.org/pdf/2506.14262", "abs": "https://arxiv.org/abs/2506.14262", "authors": ["Mohammad Emtiyaz Khan"], "title": "Knowledge Adaptation as Posterior Correction", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Adaptation is the holy grail of intelligence, but even the best AI models\n(like GPT) lack the adaptivity of toddlers. So the question remains: how can\nmachines adapt quickly? Despite a lot of progress on model adaptation to\nfacilitate continual and federated learning, as well as model merging, editing,\nunlearning, etc., little is known about the mechanisms by which machines can\nnaturally learn to adapt in a similar way as humans and animals. Here, we show\nthat all such adaptation methods can be seen as different ways of `correcting'\nthe approximate posteriors. More accurate posteriors lead to smaller\ncorrections, which in turn imply quicker adaptation. The result is obtained by\nusing a dual-perspective of the Bayesian Learning Rule of Khan and Rue (2023)\nwhere interference created during adaptation is characterized by the\nnatural-gradient mismatch over the past data. We present many examples to\ndemonstrate the use of posterior-correction as a natural mechanism for the\nmachines to learn to adapt quickly."}
{"id": "2506.14574", "pdf": "https://arxiv.org/pdf/2506.14574", "abs": "https://arxiv.org/abs/2506.14574", "authors": ["Mingkang Zhu", "Xi Chen", "Zhongdao Wang", "Bei Yu", "Hengshuang Zhao", "Jiaya Jia"], "title": "TGDPO: Harnessing Token-Level Reward Guidance for Enhancing Direct Preference Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "ICML 2025", "summary": "Recent advancements in reinforcement learning from human feedback have shown\nthat utilizing fine-grained token-level reward models can substantially enhance\nthe performance of Proximal Policy Optimization (PPO) in aligning large\nlanguage models. However, it is challenging to leverage such token-level reward\nas guidance for Direct Preference Optimization (DPO), since DPO is formulated\nas a sequence-level bandit problem. To address this challenge, this work\ndecomposes the sequence-level PPO into a sequence of token-level proximal\npolicy optimization problems and then frames the problem of token-level PPO\nwith token-level reward guidance, from which closed-form optimal token-level\npolicy and the corresponding token-level reward can be derived. Using the\nobtained reward and Bradley-Terry model, this work establishes a framework of\ncomputable loss functions with token-level reward guidance for DPO, and\nproposes a practical reward guidance based on the induced DPO reward. This\nformulation enables different tokens to exhibit varying degrees of deviation\nfrom reference policy based on their respective rewards. Experiment results\ndemonstrate that our method achieves substantial performance improvements over\nDPO, with win rate gains of up to 7.5 points on MT-Bench, 6.2 points on\nAlpacaEval 2, and 4.3 points on Arena-Hard. Code is available at\nhttps://github.com/dvlab-research/TGDPO."}
{"id": "2506.14280", "pdf": "https://arxiv.org/pdf/2506.14280", "abs": "https://arxiv.org/abs/2506.14280", "authors": ["Bai Cong", "Nico Daheim", "Yuesong Shen", "Rio Yokota", "Mohammad Emtiyaz Khan", "Thomas Möllenhoff"], "title": "Improving LoRA with Variational Learning", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": "16 pages, 4 figures", "summary": "Bayesian methods have recently been used to improve LoRA finetuning and,\nalthough they improve calibration, their effect on other metrics (such as\naccuracy) is marginal and can sometimes even be detrimental. Moreover, Bayesian\nmethods also increase computational overheads and require additional tricks for\nthem to work well. Here, we fix these issues by using a recently proposed\nvariational algorithm called IVON. We show that IVON is easy to implement and\nhas similar costs to AdamW, and yet it can also drastically improve many\nmetrics by using a simple posterior pruning technique. We present extensive\nresults on billion-scale LLMs (Llama and Qwen series) going way beyond the\nscale of existing applications of IVON. For example, we finetune a Llama-3.2-3B\nmodel on a set of commonsense reasoning tasks and improve accuracy over AdamW\nby 1.3% and reduce ECE by 5.4%, outperforming AdamW and other recent Bayesian\nmethods like Laplace-LoRA and BLoB. Overall, our results show that variational\nlearning with IVON can effectively improve LoRA finetuning."}
{"id": "2506.14577", "pdf": "https://arxiv.org/pdf/2506.14577", "abs": "https://arxiv.org/abs/2506.14577", "authors": ["Abdul Rahman Jacob", "Avinash Kori", "Emanuele De Angelis", "Ben Glocker", "Maurizio Proietti", "Francesca Toni"], "title": "Object-Centric Neuro-Argumentative Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Proceedings of Machine Learning Research, 2025 19th Conference on\n  Neurosymbolic Learning and Reasoning", "summary": "Over the last decade, as we rely more on deep learning technologies to make\ncritical decisions, concerns regarding their safety, reliability and\ninterpretability have emerged. We introduce a novel Neural Argumentative\nLearning (NAL) architecture that integrates Assumption-Based Argumentation\n(ABA) with deep learning for image analysis. Our architecture consists of\nneural and symbolic components. The former segments and encodes images into\nfacts using object-centric learning, while the latter applies ABA learning to\ndevelop ABA frameworks enabling predictions with images. Experiments on\nsynthetic data show that the NAL architecture can be competitive with a\nstate-of-the-art alternative."}
{"id": "2506.14329", "pdf": "https://arxiv.org/pdf/2506.14329", "abs": "https://arxiv.org/abs/2506.14329", "authors": ["Rickmer Schulte", "David Rügamer", "Thomas Nagler"], "title": "Adjustment for Confounding using Pre-Trained Representations", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.CO", "stat.ME"], "comment": "Accepted at ICML 2025", "summary": "There is growing interest in extending average treatment effect (ATE)\nestimation to incorporate non-tabular data, such as images and text, which may\nact as sources of confounding. Neglecting these effects risks biased results\nand flawed scientific conclusions. However, incorporating non-tabular data\nnecessitates sophisticated feature extractors, often in combination with ideas\nof transfer learning. In this work, we investigate how latent features from\npre-trained neural networks can be leveraged to adjust for sources of\nconfounding. We formalize conditions under which these latent features enable\nvalid adjustment and statistical inference in ATE estimation, demonstrating\nresults along the example of double machine learning. We discuss critical\nchallenges inherent to latent feature learning and downstream parameter\nestimation arising from the high dimensionality and non-identifiability of\nrepresentations. Common structural assumptions for obtaining fast convergence\nrates with additive or sparse linear models are shown to be unrealistic for\nlatent features. We argue, however, that neural networks are largely\ninsensitive to these issues. In particular, we show that neural networks can\nachieve fast convergence rates by adapting to intrinsic notions of sparsity and\ndimension of the learning problem."}
{"id": "2506.14587", "pdf": "https://arxiv.org/pdf/2506.14587", "abs": "https://arxiv.org/abs/2506.14587", "authors": ["Shuo Yang", "Bardh Prenkaj", "Gjergji Kasneci"], "title": "SCISSOR: Mitigating Semantic Bias through Cluster-Aware Siamese Networks for Robust Classification", "categories": ["cs.LG"], "comment": "20 pages", "summary": "Shortcut learning undermines model generalization to out-of-distribution\ndata. While the literature attributes shortcuts to biases in superficial\nfeatures, we show that imbalances in the semantic distribution of sample\nembeddings induce spurious semantic correlations, compromising model\nrobustness. To address this issue, we propose SCISSOR (Semantic Cluster\nIntervention for Suppressing ShORtcut), a Siamese network-based debiasing\napproach that remaps the semantic space by discouraging latent clusters\nexploited as shortcuts. Unlike prior data-debiasing approaches, SCISSOR\neliminates the need for data augmentation and rewriting. We evaluate SCISSOR on\n6 models across 4 benchmarks: Chest-XRay and Not-MNIST in computer vision, and\nGYAFC and Yelp in NLP tasks. Compared to several baselines, SCISSOR reports\n+5.3 absolute points in F1 score on GYAFC, +7.3 on Yelp, +7.7 on Chest-XRay,\nand +1 on Not-MNIST. SCISSOR is also highly advantageous for lightweight models\nwith ~9.5% improvement on F1 for ViT on computer vision datasets and ~11.9% for\nBERT on NLP. Our study redefines the landscape of model generalization by\naddressing overlooked semantic biases, establishing SCISSOR as a foundational\nframework for mitigating shortcut learning and fostering more robust,\nbias-resistant AI systems."}
{"id": "2506.14375", "pdf": "https://arxiv.org/pdf/2506.14375", "abs": "https://arxiv.org/abs/2506.14375", "authors": ["Muhammad Hamza Yousuf", "Jason Li", "Sahar Vahdati", "Raphael Theilen", "Jakob Wittenstein", "Jens Lehmann"], "title": "IntelliLung: Advancing Safe Mechanical Ventilation using Offline RL with Hybrid Actions and Clinically Aligned Rewards", "categories": ["cs.LG", "cs.AI"], "comment": "under review, PAIS track @ ECAI 2025", "summary": "Invasive mechanical ventilation (MV) is a life-sustaining therapy for\ncritically ill patients in the intensive care unit (ICU). However, optimizing\nits settings remains a complex and error-prone process due to patient-specific\nvariability. While Offline Reinforcement Learning (RL) shows promise for MV\ncontrol, current stateof-the-art (SOTA) methods struggle with the hybrid\n(continuous and discrete) nature of MV actions. Discretizing the action space\nlimits available actions due to exponential growth in combinations and\nintroduces distribution shifts that can compromise safety. In this paper, we\npropose optimizations that build upon prior work in action space reduction to\naddress the challenges of discrete action spaces. We also adapt SOTA offline RL\nalgorithms (IQL and EDAC) to operate directly on hybrid action spaces, thereby\navoiding the pitfalls of discretization. Additionally, we introduce a\nclinically grounded reward function based on ventilator-free days and\nphysiological targets, which provides a more meaningful optimization objective\ncompared to traditional sparse mortality-based rewards. Our findings\ndemonstrate that AI-assisted MV optimization may enhance patient safety and\nenable individualized lung support, representing a significant advancement\ntoward intelligent, data-driven critical care solutions."}
{"id": "2506.14597", "pdf": "https://arxiv.org/pdf/2506.14597", "abs": "https://arxiv.org/abs/2506.14597", "authors": ["Thomas Newman", "Christopher Nemeth", "Matthew Jones", "Philip Jonathan"], "title": "Deep Learning Surrogates for Real-Time Gas Emission Inversion", "categories": ["cs.LG", "stat.AP", "stat.ML"], "comment": "3 figures, 11 pages", "summary": "Real-time identification and quantification of greenhouse-gas emissions under\ntransient atmospheric conditions is a critical challenge in environmental\nmonitoring. We introduce a spatio-temporal inversion framework that embeds a\ndeep-learning surrogate of computational fluid dynamics (CFD) within a\nsequential Monte Carlo algorithm to perform Bayesian inference of both emission\nrate and source location in dynamic flow fields. By substituting costly\nnumerical solvers with a multilayer perceptron trained on high-fidelity CFD\noutputs, our surrogate captures spatial heterogeneity and temporal evolution of\ngas dispersion, while delivering near-real-time predictions. Validation on the\nChilbolton methane release dataset demonstrates comparable accuracy to full CFD\nsolvers and Gaussian plume models, yet achieves orders-of-magnitude faster\nruntimes. Further experiments under simulated obstructed-flow scenarios confirm\nrobustness in complex environments. This work reconciles physical fidelity with\ncomputational feasibility, offering a scalable solution for industrial\nemissions monitoring and other time-sensitive spatio-temporal inversion tasks\nin environmental and scientific modeling."}
{"id": "2506.14386", "pdf": "https://arxiv.org/pdf/2506.14386", "abs": "https://arxiv.org/abs/2506.14386", "authors": ["Christian H. X. Ali Mehmeti-Göpel", "Michael Wand"], "title": "ResNets Are Deeper Than You Think", "categories": ["cs.LG", "cs.AI"], "comment": "NeurIPS 2025 Submission", "summary": "Residual connections remain ubiquitous in modern neural network architectures\nnearly a decade after their introduction. Their widespread adoption is often\ncredited to their dramatically improved trainability: residual networks train\nfaster, more stably, and achieve higher accuracy than their feedforward\ncounterparts. While numerous techniques, ranging from improved initialization\nto advanced learning rate schedules, have been proposed to close the\nperformance gap between residual and feedforward networks, this gap has\npersisted. In this work, we propose an alternative explanation: residual\nnetworks do not merely reparameterize feedforward networks, but instead inhabit\na different function space. We design a controlled post-training comparison to\nisolate generalization performance from trainability; we find that\nvariable-depth architectures, similar to ResNets, consistently outperform\nfixed-depth networks, even when optimization is unlikely to make a difference.\nThese results suggest that residual connections confer performance advantages\nbeyond optimization, pointing instead to a deeper inductive bias aligned with\nthe structure of natural data."}
{"id": "2506.14607", "pdf": "https://arxiv.org/pdf/2506.14607", "abs": "https://arxiv.org/abs/2506.14607", "authors": ["Ziyu Gong", "Jim Lim", "David I. Inouye"], "title": "Expressive Score-Based Priors for Distribution Matching with Geometry-Preserving Regularization", "categories": ["cs.LG", "cs.CY"], "comment": "32 pages, 20 figures. Accepted to ICML 2025", "summary": "Distribution matching (DM) is a versatile domain-invariant representation\nlearning technique that has been applied to tasks such as fair classification,\ndomain adaptation, and domain translation. Non-parametric DM methods struggle\nwith scalability and adversarial DM approaches suffer from instability and mode\ncollapse. While likelihood-based methods are a promising alternative, they\noften impose unnecessary biases through fixed priors or require explicit\ndensity models (e.g., flows) that can be challenging to train. We address this\nlimitation by introducing a novel approach to training likelihood-based DM\nusing expressive score-based prior distributions. Our key insight is that\ngradient-based DM training only requires the prior's score function -- not its\ndensity -- allowing us to train the prior via denoising score matching. This\napproach eliminates biases from fixed priors (e.g., in VAEs), enabling more\neffective use of geometry-preserving regularization, while avoiding the\nchallenge of learning an explicit prior density model (e.g., a flow-based\nprior). Our method also demonstrates better stability and computational\nefficiency compared to other diffusion-based priors (e.g., LSGM). Furthermore,\nexperiments demonstrate superior performance across multiple tasks,\nestablishing our score-based method as a stable and effective approach to\ndistribution matching. Source code available at\nhttps://github.com/inouye-lab/SAUB."}
{"id": "2506.14391", "pdf": "https://arxiv.org/pdf/2506.14391", "abs": "https://arxiv.org/abs/2506.14391", "authors": ["Yaqiao Zhu", "Hongkai Wen", "Geyong Min", "Man Luo"], "title": "HiLight: A Hierarchical Reinforcement Learning Framework with Global Adversarial Guidance for Large-Scale Traffic Signal Control", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Efficient traffic signal control (TSC) is essential for mitigating urban\ncongestion, yet existing reinforcement learning (RL) methods face challenges in\nscaling to large networks while maintaining global coordination. Centralized RL\nsuffers from scalability issues, while decentralized approaches often lack\nunified objectives, resulting in limited network-level efficiency. In this\npaper, we propose HiLight, a hierarchical reinforcement learning framework with\nglobal adversarial guidance for large-scale TSC. HiLight consists of a\nhigh-level Meta-Policy, which partitions the traffic network into subregions\nand generates sub-goals using a Transformer-LSTM architecture, and a low-level\nSub-Policy, which controls individual intersections with global awareness. To\nimprove the alignment between global planning and local execution, we introduce\nan adversarial training mechanism, where the Meta-Policy generates challenging\nyet informative sub-goals, and the Sub-Policy learns to surpass these targets,\nleading to more effective coordination. We evaluate HiLight across both\nsynthetic and real-world benchmarks, and additionally construct a large-scale\nManhattan network with diverse traffic conditions, including peak transitions,\nadverse weather, and holiday surges. Experimental results show that HiLight\nexhibits significant advantages in large-scale scenarios and remains\ncompetitive across standard benchmarks of varying sizes."}
{"id": "2506.14619", "pdf": "https://arxiv.org/pdf/2506.14619", "abs": "https://arxiv.org/abs/2506.14619", "authors": ["Paolo Ascia", "Elena Raponi", "Thomas Bäck", "Fabian Duddeck"], "title": "Feasibility-Driven Trust Region Bayesian Optimization", "categories": ["cs.LG"], "comment": "Accepted for publication at AutoML2025", "summary": "Bayesian optimization is a powerful tool for solving real-world optimization\ntasks under tight evaluation budgets, making it well-suited for applications\ninvolving costly simulations or experiments. However, many of these tasks are\nalso characterized by the presence of expensive constraints whose analytical\nformulation is unknown and often defined in high-dimensional spaces where\nfeasible regions are small, irregular, and difficult to identify. In such\ncases, a substantial portion of the optimization budget may be spent just\ntrying to locate the first feasible solution, limiting the effectiveness of\nexisting methods. In this work, we present a Feasibility-Driven Trust Region\nBayesian Optimization (FuRBO) algorithm. FuRBO iteratively defines a trust\nregion from which the next candidate solution is selected, using information\nfrom both the objective and constraint surrogate models. Our adaptive strategy\nallows the trust region to shift and resize significantly between iterations,\nenabling the optimizer to rapidly refocus its search and consistently\naccelerate the discovery of feasible and good-quality solutions. We empirically\ndemonstrate the effectiveness of FuRBO through extensive testing on the full\nBBOB-constrained COCO benchmark suite and other physics-inspired benchmarks,\ncomparing it against state-of-the-art baselines for constrained black-box\noptimization across varying levels of constraint severity and problem\ndimensionalities ranging from 2 to 60."}
{"id": "2506.14411", "pdf": "https://arxiv.org/pdf/2506.14411", "abs": "https://arxiv.org/abs/2506.14411", "authors": ["John Wikman", "Alexandre Proutiere", "David Broman"], "title": "Adaptive Reinforcement Learning for Unobservable Random Delays", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "In standard Reinforcement Learning (RL) settings, the interaction between the\nagent and the environment is typically modeled as a Markov Decision Process\n(MDP), which assumes that the agent observes the system state instantaneously,\nselects an action without delay, and executes it immediately. In real-world\ndynamic environments, such as cyber-physical systems, this assumption often\nbreaks down due to delays in the interaction between the agent and the system.\nThese delays can vary stochastically over time and are typically unobservable,\nmeaning they are unknown when deciding on an action. Existing methods deal with\nthis uncertainty conservatively by assuming a known fixed upper bound on the\ndelay, even if the delay is often much lower. In this work, we introduce the\ninteraction layer, a general framework that enables agents to adaptively and\nseamlessly handle unobservable and time-varying delays. Specifically, the agent\ngenerates a matrix of possible future actions to handle both unpredictable\ndelays and lost action packets sent over networks. Building on this framework,\nwe develop a model-based algorithm, Actor-Critic with Delay Adaptation (ACDA),\nwhich dynamically adjusts to delay patterns. Our method significantly\noutperforms state-of-the-art approaches across a wide range of locomotion\nbenchmark environments."}
{"id": "2506.14698", "pdf": "https://arxiv.org/pdf/2506.14698", "abs": "https://arxiv.org/abs/2506.14698", "authors": ["Sidney Bender", "Jan Herrmann", "Klaus-Robert Müller", "Grégoire Montavon"], "title": "Towards Desiderata-Driven Design of Visual Counterfactual Explainers", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Visual counterfactual explainers (VCEs) are a straightforward and promising\napproach to enhancing the transparency of image classifiers. VCEs complement\nother types of explanations, such as feature attribution, by revealing the\nspecific data transformations to which a machine learning model responds most\nstrongly. In this paper, we argue that existing VCEs focus too narrowly on\noptimizing sample quality or change minimality; they fail to consider the more\nholistic desiderata for an explanation, such as fidelity, understandability,\nand sufficiency. To address this shortcoming, we explore new mechanisms for\ncounterfactual generation and investigate how they can help fulfill these\ndesiderata. We combine these mechanisms into a novel 'smooth counterfactual\nexplorer' (SCE) algorithm and demonstrate its effectiveness through systematic\nevaluations on synthetic and real data."}
{"id": "2506.14438", "pdf": "https://arxiv.org/pdf/2506.14438", "abs": "https://arxiv.org/abs/2506.14438", "authors": ["Pol Arévalo", "Alexis Molina", "Álvaro Ciudad"], "title": "sHGCN: Simplified hyperbolic graph convolutional neural networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Hyperbolic geometry has emerged as a powerful tool for modeling complex,\nstructured data, particularly where hierarchical or tree-like relationships are\npresent. By enabling embeddings with lower distortion, hyperbolic neural\nnetworks offer promising alternatives to Euclidean-based models for capturing\nintricate data structures. Despite these advantages, they often face\nperformance challenges, particularly in computational efficiency and tasks\nrequiring high precision. In this work, we address these limitations by\nsimplifying key operations within hyperbolic neural networks, achieving notable\nimprovements in both runtime and performance. Our findings demonstrate that\nstreamlined hyperbolic operations can lead to substantial gains in\ncomputational speed and predictive accuracy, making hyperbolic neural networks\na more viable choice for a broader range of applications."}
{"id": "2506.14746", "pdf": "https://arxiv.org/pdf/2506.14746", "abs": "https://arxiv.org/abs/2506.14746", "authors": ["Nataly Brukhim", "Aldo Pacchiano", "Miroslav Dudik", "Robert Schapire"], "title": "On the Hardness of Bandit Learning", "categories": ["cs.LG", "stat.ML"], "comment": "13 main pages", "summary": "We study the task of bandit learning, also known as best-arm identification,\nunder the assumption that the true reward function f belongs to a known, but\narbitrary, function class F. We seek a general theory of bandit learnability,\nakin to the PAC framework for classification. Our investigation is guided by\nthe following two questions: (1) which classes F are learnable, and (2) how\nthey are learnable. For example, in the case of binary PAC classification,\nlearnability is fully determined by a combinatorial dimension - the VC\ndimension- and can be attained via a simple algorithmic principle, namely,\nempirical risk minimization (ERM). In contrast to classical learning-theoretic\nresults, our findings reveal limitations of learning in structured bandits,\noffering insights into the boundaries of bandit learnability. First, for the\nquestion of \"which\", we show that the paradigm of identifying the learnable\nclasses via a dimension-like quantity fails for bandit learning. We give a\nsimple proof demonstrating that no combinatorial dimension can characterize\nbandit learnability, even in finite classes, following a standard definition of\ndimension introduced by Ben-David et al. (2019). For the question of \"how\", we\nprove a computational hardness result: we construct a reward function class for\nwhich at most two queries are needed to find the optimal action, yet no\nalgorithm can do so in polynomial time unless RP=NP. We also prove that this\nclass admits efficient algorithms for standard algorithmic operations often\nconsidered in learning theory, such as an ERM. This implies that computational\nhardness is in this case inherent to the task of bandit learning. Beyond these\nresults, we investigate additional themes such as learning under noise,\ntrade-offs between noise models, and the relationship between query complexity\nand regret minimization."}
{"id": "2506.14472", "pdf": "https://arxiv.org/pdf/2506.14472", "abs": "https://arxiv.org/abs/2506.14472", "authors": ["Fabien Bernier", "Maxime Cordy", "Yves Le Traon"], "title": "Leveraging External Factors in Household-Level Electrical Consumption Forecasting using Hypernetworks", "categories": ["cs.LG", "cs.AI"], "comment": "ECML PKDD 2025", "summary": "Accurate electrical consumption forecasting is crucial for efficient energy\nmanagement and resource allocation. While traditional time series forecasting\nrelies on historical patterns and temporal dependencies, incorporating external\nfactors -- such as weather indicators -- has shown significant potential for\nimproving prediction accuracy in complex real-world applications. However, the\ninclusion of these additional features often degrades the performance of global\npredictive models trained on entire populations, despite improving individual\nhousehold-level models. To address this challenge, we found that a hypernetwork\narchitecture can effectively leverage external factors to enhance the accuracy\nof global electrical consumption forecasting models, by specifically adjusting\nthe model weights to each consumer.\n  We collected a comprehensive dataset spanning two years, comprising\nconsumption data from over 6000 luxembourgish households and corresponding\nexternal factors such as weather indicators, holidays, and major local events.\nBy comparing various forecasting models, we demonstrate that a hypernetwork\napproach outperforms existing methods when associated to external factors,\nreducing forecasting errors and achieving the best accuracy while maintaining\nthe benefits of a global model."}
{"id": "2506.13792", "pdf": "https://arxiv.org/pdf/2506.13792", "abs": "https://arxiv.org/abs/2506.13792", "authors": ["Gonçalo Hora de Carvalho", "Lazar S. Popov", "Sander Kaatee", "Kristinn R. Thórisson", "Tangrui Li", "Pétur Húni Björnsson", "Jilles S. Dibangoye"], "title": "ICE-ID: A Novel Historical Census Data Benchmark Comparing NARS against LLMs, \\& a ML Ensemble on Longitudinal Identity Resolution", "categories": ["cs.AI", "cs.CL", "cs.LG", "stat.AP"], "comment": null, "summary": "We introduce ICE-ID, a novel benchmark dataset for historical identity\nresolution, comprising 220 years (1703-1920) of Icelandic census records.\nICE-ID spans multiple generations of longitudinal data, capturing name\nvariations, demographic changes, and rich genealogical links. To the best of\nour knowledge, this is the first large-scale, open tabular dataset specifically\ndesigned to study long-term person-entity matching in a real-world population.\nWe define identity resolution tasks (within and across census waves) with\nclearly documented metrics and splits. We evaluate a range of methods:\nhandcrafted rule-based matchers, a ML ensemble as well as LLMs for structured\ndata (e.g. transformer-based tabular networks) against a novel approach to\ntabular data called NARS (Non-Axiomatic Reasoning System) - a general-purpose\nAI framework designed to reason with limited knowledge and resources. Its core\nis Non-Axiomatic Logic (NAL), a term-based logic. Our experiments show that\nNARS is suprisingly simple and competitive with other standard approaches,\nachieving SOTA at our task. By releasing ICE-ID and our code, we enable\nreproducible benchmarking of identity resolution approaches in longitudinal\nsettings and hope that ICE-ID opens new avenues for cross-disciplinary research\nin data linkage and historical analytics."}
{"id": "2506.14530", "pdf": "https://arxiv.org/pdf/2506.14530", "abs": "https://arxiv.org/abs/2506.14530", "authors": ["Anastasis Kratsios", "Tin Sum Cheng", "Aurelien Lucchi", "Haitz Sáez de Ocáriz Borde"], "title": "Sharp Generalization Bounds for Foundation Models with Asymmetric Randomized Low-Rank Adapters", "categories": ["stat.ML", "cs.AI", "cs.LG", "cs.NE", "math.ST", "stat.TH"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) has emerged as a widely adopted\nparameter-efficient fine-tuning (PEFT) technique for foundation models. Recent\nwork has highlighted an inherent asymmetry in the initialization of LoRA's\nlow-rank factors, which has been present since its inception and was presumably\nderived experimentally. This paper focuses on providing a comprehensive\ntheoretical characterization of asymmetric LoRA with frozen random factors.\nFirst, while existing research provides upper-bound generalization guarantees\nbased on averages over multiple experiments, the behaviour of a single\nfine-tuning run with specific random factors remains an open question. We\naddress this by investigating the concentration of the typical LoRA\ngeneralization gap around its mean. Our main upper bound reveals a sample\ncomplexity of $\\tilde{\\mathcal{O}}\\left(\\frac{\\sqrt{r}}{\\sqrt{N}}\\right)$ with\nhigh probability for rank $r$ LoRAs trained on $N$ samples. Additionally, we\nalso determine the fundamental limits in terms of sample efficiency,\nestablishing a matching lower bound of\n$\\mathcal{O}\\left(\\frac{1}{\\sqrt{N}}\\right)$. By more closely reflecting the\npractical scenario of a single fine-tuning run, our findings offer crucial\ninsights into the reliability and practicality of asymmetric LoRA."}
{"id": "2506.13803", "pdf": "https://arxiv.org/pdf/2506.13803", "abs": "https://arxiv.org/abs/2506.13803", "authors": ["Richard D. Lange", "Konrad P. Kording"], "title": "Causality in the human niche: lessons for machine learning", "categories": ["cs.AI", "cs.LG"], "comment": "23 pages, 2 figures", "summary": "Humans interpret the world around them in terms of cause and effect and\ncommunicate their understanding of the world to each other in causal terms.\nThese causal aspects of human cognition are thought to underlie humans' ability\nto generalize and learn efficiently in new domains, an area where current\nmachine learning systems are weak. Building human-like causal competency into\nmachine learning systems may facilitate the construction of effective and\ninterpretable AI. Indeed, the machine learning community has been importing\nideas on causality formalized by the Structural Causal Model (SCM) framework,\nwhich provides a rigorous formal language for many aspects of causality and has\nled to significant advances. However, the SCM framework fails to capture some\nsalient aspects of human causal cognition and has likewise not yet led to\nadvances in machine learning in certain critical areas where humans excel. We\ncontend that the problem of causality in the ``human niche'' -- for a social,\nautonomous, and goal-driven agent sensing and acting in the world in which\nhumans live -- is quite different from the kind of causality captured by SCMs.\nFor example, everyday objects come in similar types that have similar causal\nproperties, and so humans readily generalize knowledge of one type of object\n(cups) to another related type (bowls) by drawing causal analogies between\nobjects with similar properties, but such analogies are at best awkward to\nexpress in SCMs. We explore how such causal capabilities are adaptive in, and\nmotivated by, the human niche. By better appreciating properties of human\ncausal cognition and, crucially, how those properties are adaptive in the niche\nin which humans live, we hope that future work at the intersection of machine\nlearning and causality will leverage more human-like inductive biases to create\nmore capable, controllable, and interpretable systems."}
{"id": "2506.14540", "pdf": "https://arxiv.org/pdf/2506.14540", "abs": "https://arxiv.org/abs/2506.14540", "authors": ["Gerardo A. Flores", "Alyssa H. Smith", "Julia A. Fukuyama", "Ashia C. Wilson"], "title": "Aligning Evaluation with Clinical Priorities: Calibration, Label Shift, and Error Costs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Machine learning-based decision support systems are increasingly deployed in\nclinical settings, where probabilistic scoring functions are used to inform and\nprioritize patient management decisions. However, widely used scoring rules,\nsuch as accuracy and AUC-ROC, fail to adequately reflect key clinical\npriorities, including calibration, robustness to distributional shifts, and\nsensitivity to asymmetric error costs. In this work, we propose a principled\nyet practical evaluation framework for selecting calibrated thresholded\nclassifiers that explicitly accounts for the uncertainty in class prevalences\nand domain-specific cost asymmetries often found in clinical settings. Building\non the theory of proper scoring rules, particularly the Schervish\nrepresentation, we derive an adjusted variant of cross-entropy (log score) that\naverages cost-weighted performance over clinically relevant ranges of class\nbalance. The resulting evaluation is simple to apply, sensitive to clinical\ndeployment conditions, and designed to prioritize models that are both\ncalibrated and robust to real-world variations."}
{"id": "2506.13900", "pdf": "https://arxiv.org/pdf/2506.13900", "abs": "https://arxiv.org/abs/2506.13900", "authors": ["Marouane Il Idrissi", "Agathe Fernandes Machado", "Arthur Charpentier"], "title": "Beyond Shapley Values: Cooperative Games for the Interpretation of Machine Learning Models", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Cooperative game theory has become a cornerstone of post-hoc interpretability\nin machine learning, largely through the use of Shapley values. Yet, despite\ntheir widespread adoption, Shapley-based methods often rest on axiomatic\njustifications whose relevance to feature attribution remains debatable. In\nthis paper, we revisit cooperative game theory from an interpretability\nperspective and argue for a broader and more principled use of its tools. We\nhighlight two general families of efficient allocations, the Weber and Harsanyi\nsets, that extend beyond Shapley values and offer richer interpretative\nflexibility. We present an accessible overview of these allocation schemes,\nclarify the distinction between value functions and aggregation rules, and\nintroduce a three-step blueprint for constructing reliable and\ntheoretically-grounded feature attributions. Our goal is to move beyond fixed\naxioms and provide the XAI community with a coherent framework to design\nattribution methods that are both meaningful and robust to shifting\nmethodological trends."}
{"id": "2506.14574", "pdf": "https://arxiv.org/pdf/2506.14574", "abs": "https://arxiv.org/abs/2506.14574", "authors": ["Mingkang Zhu", "Xi Chen", "Zhongdao Wang", "Bei Yu", "Hengshuang Zhao", "Jiaya Jia"], "title": "TGDPO: Harnessing Token-Level Reward Guidance for Enhancing Direct Preference Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "ICML 2025", "summary": "Recent advancements in reinforcement learning from human feedback have shown\nthat utilizing fine-grained token-level reward models can substantially enhance\nthe performance of Proximal Policy Optimization (PPO) in aligning large\nlanguage models. However, it is challenging to leverage such token-level reward\nas guidance for Direct Preference Optimization (DPO), since DPO is formulated\nas a sequence-level bandit problem. To address this challenge, this work\ndecomposes the sequence-level PPO into a sequence of token-level proximal\npolicy optimization problems and then frames the problem of token-level PPO\nwith token-level reward guidance, from which closed-form optimal token-level\npolicy and the corresponding token-level reward can be derived. Using the\nobtained reward and Bradley-Terry model, this work establishes a framework of\ncomputable loss functions with token-level reward guidance for DPO, and\nproposes a practical reward guidance based on the induced DPO reward. This\nformulation enables different tokens to exhibit varying degrees of deviation\nfrom reference policy based on their respective rewards. Experiment results\ndemonstrate that our method achieves substantial performance improvements over\nDPO, with win rate gains of up to 7.5 points on MT-Bench, 6.2 points on\nAlpacaEval 2, and 4.3 points on Arena-Hard. Code is available at\nhttps://github.com/dvlab-research/TGDPO."}
{"id": "2506.13946", "pdf": "https://arxiv.org/pdf/2506.13946", "abs": "https://arxiv.org/abs/2506.13946", "authors": ["Nikola Sandrić"], "title": "Rademacher learning rates for iterated random functions", "categories": ["stat.ML", "cs.LG", "math.PR", "68W40, 68T10, 60J05"], "comment": null, "summary": "Most existing literature on supervised machine learning assumes that the\ntraining dataset is drawn from an i.i.d. sample. However, many real-world\nproblems exhibit temporal dependence and strong correlations between the\nmarginal distributions of the data-generating process, suggesting that the\ni.i.d. assumption is often unrealistic. In such cases, models naturally include\ntime-series processes with mixing properties, as well as irreducible and\naperiodic ergodic Markov chains. Moreover, the learning rates typically\nobtained in these settings are independent of the data distribution, which can\nlead to restrictive choices of hypothesis classes and suboptimal sample\ncomplexities for the learning algorithm. In this article, we consider the case\nwhere the training dataset is generated by an iterated random function (i.e.,\nan iteratively defined time-homogeneous Markov chain) that is not necessarily\nirreducible or aperiodic. Under the assumption that the governing function is\ncontractive with respect to its first argument and subject to certain\nregularity conditions on the hypothesis class, we first establish a uniform\nconvergence result for the corresponding sample error. We then demonstrate the\nlearnability of the approximate empirical risk minimization algorithm and\nderive its learning rate bound. Both rates are data-distribution dependent,\nexpressed in terms of the Rademacher complexities of the underlying hypothesis\nclass, allowing them to more accurately reflect the properties of the\ndata-generating distribution."}
{"id": "2506.14577", "pdf": "https://arxiv.org/pdf/2506.14577", "abs": "https://arxiv.org/abs/2506.14577", "authors": ["Abdul Rahman Jacob", "Avinash Kori", "Emanuele De Angelis", "Ben Glocker", "Maurizio Proietti", "Francesca Toni"], "title": "Object-Centric Neuro-Argumentative Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Proceedings of Machine Learning Research, 2025 19th Conference on\n  Neurosymbolic Learning and Reasoning", "summary": "Over the last decade, as we rely more on deep learning technologies to make\ncritical decisions, concerns regarding their safety, reliability and\ninterpretability have emerged. We introduce a novel Neural Argumentative\nLearning (NAL) architecture that integrates Assumption-Based Argumentation\n(ABA) with deep learning for image analysis. Our architecture consists of\nneural and symbolic components. The former segments and encodes images into\nfacts using object-centric learning, while the latter applies ABA learning to\ndevelop ABA frameworks enabling predictions with images. Experiments on\nsynthetic data show that the NAL architecture can be competitive with a\nstate-of-the-art alternative."}
{"id": "2506.13947", "pdf": "https://arxiv.org/pdf/2506.13947", "abs": "https://arxiv.org/abs/2506.13947", "authors": ["Kazuto Fukuchi"], "title": "Meta Optimality for Demographic Parity Constrained Regression via Post-Processing", "categories": ["stat.ML", "cs.LG"], "comment": "ICML2025", "summary": "We address the regression problem under the constraint of demographic parity,\na commonly used fairness definition. Recent studies have revealed fair minimax\noptimal regression algorithms, the most accurate algorithms that adhere to the\nfairness constraint. However, these analyses are tightly coupled with specific\ndata generation models. In this paper, we provide meta-theorems that can be\napplied to various situations to validate the fair minimax optimality of the\ncorresponding regression algorithms. Furthermore, we demonstrate that fair\nminimax optimal regression can be achieved through post-processing methods,\nallowing researchers and practitioners to focus on improving conventional\nregression techniques, which can then be efficiently adapted for fair\nregression."}
{"id": "2506.13955", "pdf": "https://arxiv.org/pdf/2506.13955", "abs": "https://arxiv.org/abs/2506.13955", "authors": ["Matthew Lau", "Tian-Yi Zhou", "Xiangchi Yuan", "Jizhou Chen", "Wenke Lee", "Xiaoming Huo"], "title": "Bridging Unsupervised and Semi-Supervised Anomaly Detection: A Theoretically-Grounded and Practical Framework with Synthetic Anomalies", "categories": ["stat.ML", "cs.CR", "cs.LG", "stat.AP"], "comment": null, "summary": "Anomaly detection (AD) is a critical task across domains such as\ncybersecurity and healthcare. In the unsupervised setting, an effective and\ntheoretically-grounded principle is to train classifiers to distinguish normal\ndata from (synthetic) anomalies. We extend this principle to semi-supervised\nAD, where training data also include a limited labeled subset of anomalies\npossibly present in test time. We propose a theoretically-grounded and\nempirically effective framework for semi-supervised AD that combines known and\nsynthetic anomalies during training. To analyze semi-supervised AD, we\nintroduce the first mathematical formulation of semi-supervised AD, which\ngeneralizes unsupervised AD. Here, we show that synthetic anomalies enable (i)\nbetter anomaly modeling in low-density regions and (ii) optimal convergence\nguarantees for neural network classifiers -- the first theoretical result for\nsemi-supervised AD. We empirically validate our framework on five diverse\nbenchmarks, observing consistent performance gains. These improvements also\nextend beyond our theoretical framework to other classification-based AD\nmethods, validating the generalizability of the synthetic anomaly principle in\nAD."}
{"id": "2506.13984", "pdf": "https://arxiv.org/pdf/2506.13984", "abs": "https://arxiv.org/abs/2506.13984", "authors": ["Andrzej Cichocki"], "title": "Mirror Descent Using the Tempesta Generalized Multi-parametric Logarithms", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "In this paper, we develop a wide class Mirror Descent (MD) algorithms, which\nplay a key role in machine learning. For this purpose we formulated the\nconstrained optimization problem, in which we exploits the Bregman divergence\nwith the Tempesta multi-parametric deformation logarithm as a link function.\nThis link function called also mirror function defines the mapping between the\nprimal and dual spaces and is associated with a very-wide (in fact,\ntheoretically infinite) class of generalized trace-form entropies. In order to\nderive novel MD updates, we estimate generalized exponential function, which\nclosely approximates the inverse of the multi-parametric Tempesta generalized\nlogarithm. The shape and properties of the Tempesta logarithm and its\ninverse-deformed exponential functions can be tuned by several hyperparameters.\nBy learning these hyperparameters, we can adapt to distribution or geometry of\ntraining data, and we can adjust them to achieve desired properties of MD\nalgorithms. The concept of applying multi-parametric logarithms allow us to\ngenerate a new wide and flexible family of MD and mirror-less MD updates."}
{"id": "2506.14051", "pdf": "https://arxiv.org/pdf/2506.14051", "abs": "https://arxiv.org/abs/2506.14051", "authors": ["Jiyuan Tan", "Jose Blanchet", "Vasilis Syrgkanis"], "title": "Estimation of Treatment Effects in Extreme and Unobserved Data", "categories": ["stat.ML", "cs.LG", "math.ST", "stat.ME", "stat.TH"], "comment": null, "summary": "Causal effect estimation seeks to determine the impact of an intervention\nfrom observational data. However, the existing causal inference literature\nprimarily addresses treatment effects on frequently occurring events. But what\nif we are interested in estimating the effects of a policy intervention whose\nbenefits, while potentially important, can only be observed and measured in\nrare yet impactful events, such as extreme climate events? The standard causal\ninference methodology is not designed for this type of inference since the\nevents of interest may be scarce in the observed data and some degree of\nextrapolation is necessary. Extreme Value Theory (EVT) provides methodologies\nfor analyzing statistical phenomena in such extreme regimes. We introduce a\nnovel framework for assessing treatment effects in extreme data to capture the\ncausal effect at the occurrence of rare events of interest. In particular, we\nemploy the theory of multivariate regular variation to model extremities. We\ndevelop a consistent estimator for extreme treatment effects and present a\nrigorous non-asymptotic analysis of its performance. We illustrate the\nperformance of our estimator using both synthetic and semi-synthetic data."}
{"id": "2506.14110", "pdf": "https://arxiv.org/pdf/2506.14110", "abs": "https://arxiv.org/abs/2506.14110", "authors": ["Steve Hanneke", "Mingyue Xu"], "title": "Universal Rates of ERM for Agnostic Learning", "categories": ["stat.ML", "cs.LG"], "comment": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2025", "summary": "The universal learning framework has been developed to obtain guarantees on\nthe learning rates that hold for any fixed distribution, which can be much\nfaster than the ones uniformly hold over all the distributions. Given that the\nEmpirical Risk Minimization (ERM) principle being fundamental in the PAC theory\nand ubiquitous in practical machine learning, the recent work of\narXiv:2412.02810 studied the universal rates of ERM for binary classification\nunder the realizable setting. However, the assumption of realizability is too\nrestrictive to hold in practice. Indeed, the majority of the literature on\nuniversal learning has focused on the realizable case, leaving the\nnon-realizable case barely explored.\n  In this paper, we consider the problem of universal learning by ERM for\nbinary classification under the agnostic setting, where the ''learning curve\"\nreflects the decay of the excess risk as the sample size increases. We explore\nthe possibilities of agnostic universal rates and reveal a compact trichotomy:\nthere are three possible agnostic universal rates of ERM, being either\n$e^{-n}$, $o(n^{-1/2})$, or arbitrarily slow. We provide a complete\ncharacterization of which concept classes fall into each of these categories.\nMoreover, we also establish complete characterizations for the target-dependent\nuniversal rates as well as the Bayes-dependent universal rates."}
{"id": "2506.14239", "pdf": "https://arxiv.org/pdf/2506.14239", "abs": "https://arxiv.org/abs/2506.14239", "authors": ["Louis Vervoort", "Vitaly Nikolaev"], "title": "Causes in neuron diagrams, and testing causal reasoning in Large Language Models. A glimpse of the future of philosophy?", "categories": ["cs.AI", "cs.LG"], "comment": "Accepted by Journal for General Philosophy of Science", "summary": "We propose a test for abstract causal reasoning in AI, based on scholarship\nin the philosophy of causation, in particular on the neuron diagrams\npopularized by D. Lewis. We illustrate the test on advanced Large Language\nModels (ChatGPT, DeepSeek and Gemini). Remarkably, these chatbots are already\ncapable of correctly identifying causes in cases that are hotly debated in the\nliterature. In order to assess the results of these LLMs and future dedicated\nAI, we propose a definition of cause in neuron diagrams with a wider validity\nthan published hitherto, which challenges the widespread view that such a\ndefinition is elusive. We submit that these results are an illustration of how\nfuture philosophical research might evolve: as an interplay between human and\nartificial expertise."}
{"id": "2506.14276", "pdf": "https://arxiv.org/pdf/2506.14276", "abs": "https://arxiv.org/abs/2506.14276", "authors": ["Jack Cole", "Mohamed Osman"], "title": "Don't throw the baby out with the bathwater: How and why deep learning for ARC", "categories": ["cs.AI", "cs.LG"], "comment": "13 pages, 6 figures", "summary": "The Abstraction and Reasoning Corpus (ARC-AGI) presents a formidable\nchallenge for AI systems. Despite the typically low performance on ARC, the\ndeep learning paradigm remains the most effective known strategy for generating\nskillful (state-of-the-art) neural networks (NN) across varied modalities and\ntasks in vision, language etc. The deep learning paradigm has proven to be able\nto train these skillful neural networks and learn the abstractions needed in\nthese diverse domains. Our work doubles down on that and continues to leverage\nthis paradigm by incorporating on-the-fly NN training at test time. We\ndemonstrate that fully committing to deep learning's capacity to acquire novel\nabstractions yields state-of-the-art performance on ARC. Specifically, we treat\nboth the neural network and the optimizer (rather than just a pre-trained\nnetwork) as integral components of the inference process, fostering\ngeneralization to unseen tasks. Concretely, we propose a methodology for\ntraining on ARC, starting from pretrained LLMs, and enhancing their ARC\nreasoning. We also propose Test-Time Fine-Tuning (TTFT) and the Augment\nInference Reverse-Augmentation and Vote (AIRV) as effective test-time\ntechniques. We are the first to propose and show deep learning can be used\neffectively for ARC, showing boosts of up to 260% in accuracy with AIRV and a\nfurther 300% boost with TTFT. An early version of this approach secured first\nplace in the 2023 ARCathon competition, while the final version achieved the\ncurrent best score on the ARC private test-set (58%). Our findings highlight\nthe key ingredients of a robust reasoning system in unfamiliar domains,\nunderscoring the central mechanisms that improve broad perceptual reasoning."}
{"id": "2506.14329", "pdf": "https://arxiv.org/pdf/2506.14329", "abs": "https://arxiv.org/abs/2506.14329", "authors": ["Rickmer Schulte", "David Rügamer", "Thomas Nagler"], "title": "Adjustment for Confounding using Pre-Trained Representations", "categories": ["stat.ML", "cs.AI", "cs.LG", "stat.CO", "stat.ME"], "comment": "Accepted at ICML 2025", "summary": "There is growing interest in extending average treatment effect (ATE)\nestimation to incorporate non-tabular data, such as images and text, which may\nact as sources of confounding. Neglecting these effects risks biased results\nand flawed scientific conclusions. However, incorporating non-tabular data\nnecessitates sophisticated feature extractors, often in combination with ideas\nof transfer learning. In this work, we investigate how latent features from\npre-trained neural networks can be leveraged to adjust for sources of\nconfounding. We formalize conditions under which these latent features enable\nvalid adjustment and statistical inference in ATE estimation, demonstrating\nresults along the example of double machine learning. We discuss critical\nchallenges inherent to latent feature learning and downstream parameter\nestimation arising from the high dimensionality and non-identifiability of\nrepresentations. Common structural assumptions for obtaining fast convergence\nrates with additive or sparse linear models are shown to be unrealistic for\nlatent features. We argue, however, that neural networks are largely\ninsensitive to these issues. In particular, we show that neural networks can\nachieve fast convergence rates by adapting to intrinsic notions of sparsity and\ndimension of the learning problem."}
{"id": "2506.14479", "pdf": "https://arxiv.org/pdf/2506.14479", "abs": "https://arxiv.org/abs/2506.14479", "authors": ["Wonyoung Kim"], "title": "Adaptive Data Augmentation for Thompson Sampling", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "In linear contextual bandits, the objective is to select actions that\nmaximize cumulative rewards, modeled as a linear function with unknown\nparameters. Although Thompson Sampling performs well empirically, it does not\nachieve optimal regret bounds. This paper proposes a nearly minimax optimal\nThompson Sampling for linear contextual bandits by developing a novel estimator\nwith the adaptive augmentation and coupling of the hypothetical samples that\nare designed for efficient parameter learning. The proposed estimator\naccurately predicts rewards for all arms without relying on assumptions for the\ncontext distribution. Empirical results show robust performance and significant\nimprovement over existing methods."}
{"id": "2506.14530", "pdf": "https://arxiv.org/pdf/2506.14530", "abs": "https://arxiv.org/abs/2506.14530", "authors": ["Anastasis Kratsios", "Tin Sum Cheng", "Aurelien Lucchi", "Haitz Sáez de Ocáriz Borde"], "title": "Sharp Generalization Bounds for Foundation Models with Asymmetric Randomized Low-Rank Adapters", "categories": ["stat.ML", "cs.AI", "cs.LG", "cs.NE", "math.ST", "stat.TH"], "comment": null, "summary": "Low-Rank Adaptation (LoRA) has emerged as a widely adopted\nparameter-efficient fine-tuning (PEFT) technique for foundation models. Recent\nwork has highlighted an inherent asymmetry in the initialization of LoRA's\nlow-rank factors, which has been present since its inception and was presumably\nderived experimentally. This paper focuses on providing a comprehensive\ntheoretical characterization of asymmetric LoRA with frozen random factors.\nFirst, while existing research provides upper-bound generalization guarantees\nbased on averages over multiple experiments, the behaviour of a single\nfine-tuning run with specific random factors remains an open question. We\naddress this by investigating the concentration of the typical LoRA\ngeneralization gap around its mean. Our main upper bound reveals a sample\ncomplexity of $\\tilde{\\mathcal{O}}\\left(\\frac{\\sqrt{r}}{\\sqrt{N}}\\right)$ with\nhigh probability for rank $r$ LoRAs trained on $N$ samples. Additionally, we\nalso determine the fundamental limits in terms of sample efficiency,\nestablishing a matching lower bound of\n$\\mathcal{O}\\left(\\frac{1}{\\sqrt{N}}\\right)$. By more closely reflecting the\npractical scenario of a single fine-tuning run, our findings offer crucial\ninsights into the reliability and practicality of asymmetric LoRA."}
{"id": "2506.14673", "pdf": "https://arxiv.org/pdf/2506.14673", "abs": "https://arxiv.org/abs/2506.14673", "authors": ["Mikael Møller Høgsgaard", "Andrea Paudice"], "title": "Uniform Mean Estimation for Heavy-Tailed Distributions via Median-of-Means", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "The Median of Means (MoM) is a mean estimator that has gained popularity in\nthe context of heavy-tailed data. In this work, we analyze its performance in\nthe task of simultaneously estimating the mean of each function in a class\n$\\mathcal{F}$ when the data distribution possesses only the first $p$ moments\nfor $p \\in (1,2]$. We prove a new sample complexity bound using a novel\nsymmetrization technique that may be of independent interest. Additionally, we\npresent applications of our result to $k$-means clustering with unbounded\ninputs and linear regression with general losses, improving upon existing\nworks."}
